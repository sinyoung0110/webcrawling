title,date,keywords,abstract,multilingual_abstract
Mary Shelley’s Frankenstein: The Link Between Frankenstein’s Creation of an Intelligent Being and Machine Learning of Artificial Intelligence,2019,"['Frankenstein', 'human', 'intelligent being', 'artificial intelligence', 'machine learning']",,"Science and technology in the 21st century is accelerating the humanization of machines (artificial intelligence and humanoid) and the mechanization of humans (artificial prosthetics and human cloning) and allowing us to view humans and machines in successive spectra. There are many works in literature and movies that deal with both of them, inspired by Frankenstein’s creation in Mary Shelley’s Frankenstein. For the 20th and 21st centuries, Frankenstein has been reinterpreted and recreated as science developed. The novel Frankenstein began with “warning us about future developments” (Kellner 302) and has now evolved into cyberpunk fiction and movie. First of all, this paper will examine the limitation of Frankenstein’s creation in the process of his development into a human being, compared to an authentic human; next, in terms of literary and scientific imagination, attempt to shed new light on Frankenstein’s creation by comparing it with machine learning of artificial intelligence from a mechanical point of view; lastly, from the humanities point of view, try to discuss scientists’ ethical responsibility in the production process of artificial intelligence. This paper will specifically compare the learning process of Frankenstein’s creation with the machine learning of artificial intelligence, and try to present a direct link between Frankenstein’s intelligent being and artificial intelligence."
Identifying Suicide Notes Using Forensic Linguistics and Machine Learning,2019,"['suicide notes', 'forensic linguistics', 'Linguistic Inquiry and Word Count', 'principal component analysis', 'machine learning']",,"This paper presents how to identify the characteristic properties of suicide notes using the analysis methods in forensic linguistics and how to apply the knowledge to the machine learning research. For this purpose, a corpus was compiled with Virginia Woolf’s literary works and suicide notes, which contained six texts. Then, each text was analyzed with the LIWC (Linguistic Inquiry and Word Count) software. Since the analysis results were complicated, a dimensionality reduction was conducted using a Principal Component Analysis (PCA). In the PCA analysis, it was found that, even though all the texts were written by the same author, the suicide notes were clearly identified from the literary works. The analysis results of LIWC analyses were applied to a machine learning technique (especially a Support Vector Machine; SVM), and the classification accuracy was measured using six real texts and three hypothetical texts. Through the analysis, it was found that the SVM machine identified the suicide notes from the literary works with 100% of accuracy. The current study demonstrates that the linguistic properties of texts can be used to identify the suicides notes from the other types of writings and that they can be used in machine learning research."
Predictive Modeling of Outcomes After Traumatic and Nontraumatic Spinal Cord Injury Using Machine Learning: Review of Current Progress and Future Directions,2019,"['Machine learning', 'Spinal cord injury', 'Outcomes', 'Degenerative cervical myelopathy', 'Magnetic resonance imaging']",,"Machine learning represents a promising frontier in epidemiological research on spine surgery. It consists of a series of algorithms that determines relationships between data. Machine learning maintains numerous advantages over conventional regression techniques, such as a reduced requirement for a priori knowledge on predictors and better ability to manage large datasets. Current studies have made extensive strides in employing machine learning to a greater capacity in spinal cord injury (SCI). Analyses using machine learning algorithms have been done on both traumatic SCI and nontraumatic SCI, the latter of which typically represents degenerative spine disease resulting in spinal cord compression, such as degenerative cervical myelopathy. This article is a literature review of current studies published in traumatic and nontraumatic SCI that employ machine learning for the prediction of a host of outcomes. The studies described utilize machine learning in a variety of capacities, including imaging analysis and prediction in large epidemiological data sets. We discuss the performance of these machine learning-based clinical prognostic models relative to conventional statistical prediction models. Finally, we detail the future steps needed for machine learning to become a more common modality for statistical analysis in SCI."
Machine Learning Approaches for the Prediction of Prostate Cancer according to Age and the Prostate-Specific Antigen Level,2019,"['Prediction', 'Prostate cancer', 'Machine learning', 'Prostate biopsy']",,"Purpose: The aim of this study was to evaluate the applicability of machine learning methods that combine data on age and prostate-specific antigen (PSA) levels for predicting prostate cancer.Materials and Methods: We analyzed 943 patients who underwent transrectal ultrasonography (TRUS)-guided prostate biopsy at Chungnam National University Hospital between 2014 and 2018 because of elevated PSA levels and/or abnormal digital rectal examination and/or TRUS findings. We retrospectively reviewed the patients’ medical records, analyzed the prediction rate of prostate cancer, and identified 20 feature importances that could be compared with biopsy results using 5 different algorithms, viz., logistic regression (LR), support vector machine, random forest (RF), extreme gradient boosting, and light gradient boosting machine.Results: Overall, the cancer detection rate was 41.8%. In patients younger than 75 years and with a PSA level less than 20 ng/mL, the best prediction model for prostate cancer detection was RF among the machine learning methods based on LR analysis. The PSA density was the highest scored feature importances in the same patient group.Conclusions: These results suggest that the prediction rate of prostate cancer using machine learning methods not inferior to that using LR and that these methods may increase the detection rate for prostate cancer and reduce unnecessary prostate biopsy, as they take into consideration feature importances affecting the prediction rate for prostate cancer."
Machine Learning Approaches for the Prediction of Prostate Cancer according to Age and the Prostate-Specific Antigen Level,2019,"['Prediction', 'Prostate cancer', 'Machine learning', 'Prostate biopsy']",,"Purpose: The aim of this study was to evaluate the applicability of machine learning methods that combine data on age and prostate-specific antigen (PSA) levels for predicting prostate cancer.Materials and Methods: We analyzed 943 patients who underwent transrectal ultrasonography (TRUS)-guided prostate biopsy at Chungnam National University Hospital between 2014 and 2018 because of elevated PSA levels and/or abnormal digital rectal examination and/or TRUS findings. We retrospectively reviewed the patients’ medical records, analyzed the prediction rate of prostate cancer, and identified 20 feature importances that could be compared with biopsy results using 5 different algorithms, viz., logistic regression (LR), support vector machine, random forest (RF), extreme gradient boosting, and light gradient boosting machine.Results: Overall, the cancer detection rate was 41.8%. In patients younger than 75 years and with a PSA level less than 20 ng/mL, the best prediction model for prostate cancer detection was RF among the machine learning methods based on LR analysis. The PSA density was the highest scored feature importances in the same patient group.Conclusions: These results suggest that the prediction rate of prostate cancer using machine learning methods not inferior to that using LR and that these methods may increase the detection rate for prostate cancer and reduce unnecessary prostate biopsy, as they take into consideration feature importances affecting the prediction rate for prostate cancer."
A Study on Comparison of Lung Cancer Prediction Using Ensemble Machine Learning,2019,"['Lung Cancer', 'Machine Learning', 'Two-Class Support Vector Machine', 'Two-Class Decision Jungle', 'Multi-Class Decision Jungle']",,"Lung cancer is a chronic disease which ranks fourth in cancer incidence with 11 percent of the total cancer incidence in Korea. To deal with such issues, there is an active study on the usefulness and utilization of the Clinical Decision Support System (CDSS) which utilizes machine learning. Thus, this study reviews existing studies on artificial intelligence technology that can be used in determining the lung cancer, and conducted a study on the applicability of machine learning in determination of the lung cancer by comparison and analysis using Azure ML provided by Microsoft. The results of this study show different predictions yielded by three algorithms: Support Vector Machine (SVM), Two-Class Support Decision Jungle and Multiclass Decision Jungle. This study has its limitations in the size of the Big data used in Machine Learning. Although the data provided by Kaggle is the most suitable one for this study, it is assumed that there is a limit in learning the data fully due to the lack of absolute figures. Therefore, it is claimed that if the agency's cooperation in the subsequent research is used to compare and analyze various kinds of algorithms other than those used in this study, a more accurate screening machine for lung cancer could be created."
"Relative importance of symptoms, cognition, and other multilevel variables for psychiatric disease classifications by machine learning",2019,"['Machine learning', 'Nosology', 'Schizophrenia', 'Schizoaffective disorder', 'Major depressive disorder', 'Bipolar disorder']",,"<P><B>Abstract</B></P>  <P>This study used machine-learning algorithms to make unbiased estimates of the relative importance of various multilevel data for classifying cases with schizophrenia (<I>n</I> = 60), schizoaffective disorder (<I>n</I> = 19), bipolar disorder (<I>n</I> = 20), unipolar depression (<I>n</I> = 14), and healthy controls (<I>n</I> = 51) into psychiatric diagnostic categories. The Random Forest machine learning algorithm, which showed best efficacy (92.9% SD: 0.06), was used to generate variable importance ranking of positive, negative, and general psychopathology symptoms, cognitive indexes, global assessment of function (GAF), and parental ages at birth for sorting participants into diagnostic categories. Symptoms were ranked most influential for separating cases from healthy controls, followed by cognition and maternal age. To separate schizophrenia/schizoaffective disorder from bipolar/unipolar depression, GAF was most influential, followed by cognition and paternal age. For classifying schizophrenia from all other psychiatric disorders, low GAF and paternal age were similarly important, followed by cognition, psychopathology and maternal age. Controls misclassified as schizophrenia cases showed lower nonverbal abilities, mild negative and general psychopathology symptoms, and younger maternal or older paternal age. The importance of symptoms for classification of cases and lower GAF for diagnosing schizophrenia, notably more important and distinct from cognition and symptoms, concurs with current practices. The high importance of parental ages is noteworthy and merits further study.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Machine-learning algorithms estimated importance of multilevel data for diagnostic classification. </LI> <LI>  Symptoms were most influential for differentiating psychiatric cases from healthy controls. </LI> <LI>  Function was most important for separating the schizophrenias from affective disorder cases. </LI> <LI>  Function and paternal age were equally important for separating schizophrenia from all other cases. </LI> <LI>  Misclassified controls had mild symptoms, lower cognition, and/or younger mothers/older fathers. </LI> </UL> </P>"
Machine Learning-Based Prediction of Korean Triage and Acuity Scale Level in Emergency Department Patients,2019,"['Triage', 'Hospital Emergency Service', 'Machine Learning', 'Natural Language Processing']",,"Objectives: Triage is a process to accurately assess and classify symptoms to identify and provide rapid treatment to patients.The Korean Triage and Acuity Scale (KTAS) is used as a triage instrument in all emergency centers. The aim of this study was to train and compare machine learning models to predict KTAS levels. Methods: This was a cross-sectional study using data from a single emergency department of a tertiary university hospital. Information collected during triage was used in the analysis. Logistic regression, random forest, and XGBoost were used to predict the KTAS level. Results: The models with the highest area under the receiver operating characteristic curve (AUROC) were the random forest and XGBoost models trained on the entire dataset (AUROC = 0.922, 95% confidence interval 0.917–0.925 and AUROC = 0.922, 95% confidence interval 0.918–0.925, respectively). The AUROC of the models trained on the clinical data was higher than that of models trained on text data only, but the models trained on all variables had the highest AUROC among similar machine learning models. Conclusions: Machine learning can robustly predict the KTAS level at triage, which may have many possibilities for use, and the addition of text data improves the predictive performance compared to that achieved by using structured data alone."
A Study on Learning Mathematics for Machine Learning,2019,"['Mathematics', 'Machine learning', 'Mathematics Education method', 'Speech recognition systems', 'Automatic driving', 'Process automation']",,"This paper is a study on mathematical aspects that can be basic for understanding and applying the contents of machine learning. If you are familiar with mathematics in the field of computer science, you can create algorithms that can diversify researches and implement them faster, so you can implement many real-life ideas. There is no curriculum standard for mathematics in the field of machine learning, and there are many absolutely lacking mathematical contents that are taught in the curriculum presented at existing universities. Machine learning now includes speech recognition systems, search engines, automatic driving systems, process automation, object recognition, and more. Many applications that you want to implement combine a large amount of data with many variables into the components that the programmer generates. In this course, the mathematical areas required for computer engineer (CS) practitioners and computer engineering educators have become diverse and complex. It is important to analyze the mathematical content required by engineers and educators and the mathematics required in the field. This paper attempts to present an effective range design for the essential processes from the basic education content to the deepening education content for the development of many researches."
Data-Driven Machine-Learning Quantifies Differences in the Voiding Initiation Network in Neurogenic Voiding Dysfunction in Women With Multiple Sclerosis,2019,"['Neurogenic lower urinary tract dysfunction', 'Multiple sclerosis', 'Functional magnetic resonance imaging', 'Machine learning']",,"Purpose: To quantify the relative importance of brain regions responsible for reduced functional connectivity (FC) in their Voiding Initiation Network in female multiple sclerosis (MS) patients with neurogenic lower urinary tract dysfunction (NLUTD) and voiding dysfunction (VD). A data-driven machine-learning approach is utilized for quantification.Methods: Twenty-seven ambulatory female patients with MS and NLUTD (group 1: voiders, n=15 and group 2: VD, n=12) participated in a functional magnetic resonance imaging (fMRI) voiding study. Brain activity was recorded by fMRI with simultaneous urodynamic testing. The Voiding Initiation Network was identified from averaged fMRI activation maps. Four machine-learning algorithms were employed to optimize the area under curve (AUC) of the receiver-operating characteristic curve. The optimal model was used to identify the relative importance of relevant brain regions.Results: The Voiding Initiation Network exhibited stronger FC for voiders in frontal regions and stronger disassociation in cerebellar regions. Highest AUC values were obtained with ‘random forests’ (0.86) and ‘partial least squares’ algorithms (0.89).While brain regions with highest relative importance (>75%) included superior, middle, inferior frontal and cingulate regions, relative importance was larger than 60% for 186 of the 227 brain regions of the Voiding Initiation Network, indicating a global effect.Conclusions: Voiders and VD patients showed distinctly different FC in their Voiding Initiation Network. Machine-learning is able to identify brain centers contributing to these observed differences. Knowledge of these centers and their connectivity may allow phenotyping patients to centrally focused treatments such as cortical modulation."
Application of machine learning in rheumatic disease research,2019,"['Rheumatology', 'Machine learning', 'Prediction']",,"Over the past decade, there has been a paradigm shift in how clinical data are collected, processed and utilized. Machine learning and artificial intelligence, fueled by breakthroughs in high-performance computing, data availability and algorithmic innovations, are paving the way to effective analyses of large, multi-dimensional collections of patient histories, laboratory results, treatments, and outcomes. In the new era of machine learning and predictive analytics, the impact on clinical decision-making in all clinical areas, including rheumatology, will be unprecedented. Here we provide a critical review of the machine-learning methods currently used in the analysis of clinical data, the advantages and limitations of these methods, and how they can be leveraged within the field of rheumatology."
Fault Diagnosis Management Model using Machine Learning,2019,"['Data analysis', 'Fault diagnosis', 'Machine learning', 'SVM']",,"Based on the concept of Industry 4.0, various sensors are attached to facilities and equipment to collect data in real time and diagnose faults using analyzing techniques. Diagnostic technology continuously monitors faults or performance degradation of facilities and equipment in operation and diagnoses abnormal symptoms to ensure safety and availability through maintenance before failure occurs. In this paper, we propose a model to analyze the data and diagnose the state or failure using machine learning. The diagnosis model is based on a support vector machine (SVM)-based diagnosis model and a self-learning one-class SVM-based diagnostic model. In the future, it is expected that this model can be applied to facilities used in the entire industry by applying the actual data to the diagnostic model proposed in this paper, conducting the experiment, and verifying it through the model performance evaluation index."
Development of Predictive Models in Patients with Epiphora Using Lacrimal Scintigraphy and Machine Learning,2019,['Epiphora . Dacryocystography . Lacrimal scintigraphy . Machine learning . Deep learning . Convolutional neural network'],,"Purpose We developed predictive models using different programming languages and different computing platforms for machine learning (ML) and deep learning (DL) that classify clinical diagnoses in patients with epiphora.We evaluated the diagnostic performance of these models.Methods Between January 2016 and September 2017, 250 patients with epiphora who underwent dacryocystography (DCG) and lacrimal scintigraphy (LS) were included in the study.We developed five different predictive models usingMLtools, Pythonbased TensorFlow, R, and Microsoft Azure Machine Learning Studio (MAMLS). A total of 27 clinical characteristics and parameters including variables related to epiphora (VE) and variables related to dacryocystography (VDCG) were used as input data. Apart from this, we developed two predictive convolutional neural network (CNN) models for diagnosing LS images. We conducted this study using supervised learning.Results Among 500 eyes of 250 patients, 59 eyes had anatomical obstruction, 338 eyes had functional obstruction, and the remaining 103 eyes were normal. For the data set that excluded VE and VDCG, the test accuracies in Python-based TensorFlow, R, multiclass logistic regression in MAMLS, multiclass neural network in MAMLS, and nuclear medicine physician were 81.70%, 80.60%, 81.70%, 73.10%, and 80.60%, respectively. The test accuracies of CNN models in three-class classification diagnosis and binary classification diagnosis were 72.00% and 77.42%, respectively.Conclusions ML-based predictive models using different programming languages and different computing platforms were useful for classifying clinical diagnoses in patients with epiphora and were similar to a clinician’s diagnostic ability."
Machine-Learning Based Automatic and Real-time Detection of Mouse Scratching Behaviors,2019,"['Machine learning', 'Decision tree', 'Mouse', 'Scratching', 'Pruritus', 'Itch']",,"Scratching is a main behavioral response accompanied by acute and chronic itch conditions, and has been quantified as an objective correlate to assess itch in studies using laboratory animals. Scratching has been counted mostly by human annotators, which is a time-consuming and laborious process. It has been attempted to develop automated scoring methods using various strategies, but they often require specialized equipment, costly software, or implantation of device which may disturb animal behaviors. To complement limitations of those methods, we have adapted machine learning-based strategy to develop a novel automated and real-time method detecting mouse scratching from experimental movies captured using monochrome cameras such as a webcam. Scratching is identified by characteristic changes in pixels, body position, and body size by frame as well as the size of body. To build a training model, a novel two-step J48 decision tree-inducing algorithm along with a C4.5 post-pruning algorithm was applied to three 30-min video recordings in which a mouse exhibits scratching following an intradermal injection of a pruritogen, and the resultant frames were then used for the next round of training. The trained method exhibited, on average, a sensitivity and specificity of 95.19% and 92.96%, respectively, in a performance test with five new recordings. This result suggests that it can be used as a non-invasive, automated and objective tool to measure mouse scratching from video recordings captured in general experimental settings, permitting rapid and accurate analysis of scratching for preclinical studies and high throughput drug screening."
A Study on Machine Learning-based Grass Demand Forecasting,2019,"['Machine Learning', 'Water demand', 'Forecasting', 'Irrigation Schedule']",,"The origin of the grass varies between regions and countries, but in the West, crops, which have been widely used for feed, have long been adapted to livestock grazing, and are derived from plants and perennials with good land cover capacity. In Korea, the origin of grass is different from that of the West. It has been used to decorate and cover the tomb's ground. Thus, Grass is one of the essential elements in our life. Grass is the major resource of various ecosystems and it also provides a space to relax. Nevertheless, Recently, Korea is recognized as a recession due to the reduction of new golf course construction and the slowdown of construction industry. However, since the 5-day system was implemented due to economic development and national income improvement after the Olympic and World Cup, the demand for grass as a green space for recreation and sports Is increasing. In particular, the use of new towns, the West Coast Saemangeum project, neighborhood parks, school grounds, and general residential gardens is increasing. Grass is expected to increase the value added of social indirect capital such as highways, the increase of golf population, the greening of urban and national lands using grass such as the increase of recreational activities and urban grass parks. In addition, the grass industry is a comprehensive field that includes the development, production, composition and management of garden, slope and sports. However, the grass industry is limited to production. This situation is lacking, and there is also a lack of basic data on the system or industry that can support the grass industry. Accordingly, we are necessary to have a research how we improve to use of grass and suggest newly methods with water demand."
A novel estimation approach for the solar radiation potential with its complex spatial pattern via machine-learning techniques,2019,"['Monthly average daily solar radiation', 'Solar radiation zone', 'k-means clustering', 'Advanced case-based reasoning', 'Prediction accuracy', 'Decision-making']",,"<P><B>Abstract</B></P>  <P>As a clean and sustainable energy resource with lower environmental impact, the Chinese government encourages the application of solar energy system. The global solar radiation on the horizontal surface in the specific site should be investigated in advance so that the solar energy system could be implemented properly and efficiently. However, the monthly average daily solar radiation (MADSR) in China has complex spatial patterns, and its observation stations are still lacking due to the high cost of equipment. To address these challenges, this study aimed to develop a novel estimation approach for the MADSR with its complex spatial pattern over a vast area in China via machine-learning techniques (i.e. a clustering method (<I>k-means</I>) and an advanced case-based reasoning (A-CBR) model). The MADSR and the relevant information were collected from 97 cities in China for 10 years (from 2006 to 2015). The average prediction accuracy of the proposed approach was determined at 93.23%, showing a promising way. The proposed novel approach is expected to be generalized via the interpolation methods (e.g. <I>kriging</I> method in a geographical information system) so that decision-makers (e.g. construction manager or facility manager) can determine the appropriate location, size and form in implementing the solar energy system.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A novel estimation approach was proposed to estimate the solar radiation in China. </LI> <LI>   <I>k-means</I> method was used to form the solar radiation zones with its spatial pattern. </LI> <LI>  The A-CBR model was developed to estimate the monthly solar radiation by zone. </LI> <LI>  The proposed approach can accurately estimate the solar radiation with references. </LI> <LI>  The average prediction accuracy of the proposed approach was determined at 93.23%. </LI> </UL> </P>"
Molecular force fields with gradient-domain machine learning: Construction and application to dynamics of small molecules with coupled cluster forces,2019,,,
Machine learning approaches for wind speed forecasting using  long-term monitoring data: a comparative study,2019,"['structural health monitoring', 'wind speed prediction', 'machine learning', 'optimization algorithm', 'finite mixture method']",,"Wind speed forecasting is critical for a variety of engineering tasks, such as wind energy harvesting, scheduling of a wind power system, and dynamic control of structures (e.g., wind turbine, bridge, and building). Wind speed, which has characteristics of random, nonlinear and uncertainty, is difficult to forecast. Nowadays, machine learning approaches (generalized regression neural network (GRNN), back propagation neural network (BPNN), and extreme learning machine (ELM)) are widely used for wind speed forecasting. In this study, two schemes are proposed to improve the forecasting performance of machine learning approaches. One is that optimization algorithms, i.e., cross validation (CV), genetic algorithm (GA), and particle swarm optimization (PSO), are used to automatically find the optimal model parameters. The other is that the combination of different machine learning methods is proposed by finite mixture (FM) method. Specifically, CV-GRNN, GA-BPNN, PSO-ELM belong to optimization algorithm-assisted machine learning approaches, and FM is a hybrid machine learning approach consisting of GRNN, BPNN, and ELM. The effectiveness of these machine learning methods in wind speed forecasting are fully investigated by one-year field monitoring data, and their performance is comprehensively compared."
Lifelong Machine Learning 기반 스팸 메시지 필터링 방법,2019,"['Spam Filtering', 'Naive Bayes Classifier', 'Lifelong Machine Learning', 'ELLA']","인터넷의 급속한 성장으로 데이터의 송수신의 편리성과 비용이 들지 않는다는 장점 때문에 매일 수백만 건의 무차별적인 광고성 스팸 문자와 메일이 발송되고 있다. 아직은 스팸 단어나 스팸 번호를 차단하는 방법을 주로 사용하지만, 기계 학습이 떠오름에 따라 스팸을 필터링하는 방법에 대해 다양한 방식으로 활발히 연구되고 있다. 그러나 스팸에서만 등장하는 단어나 패턴은 스팸 필터링 시스템에 의해 걸러지지 않기 위해 지속적으로 변화하고 있기 때문에, 기존 기계 학습 메커니즘으로는 새로운 단어와 패턴을 감지, 적응할 수 없다. 최근 이러한 기존 기계 학습의 한계점을 극복하기 위해 기존의 지식을 활용하여 새로운 지식을 지속적으로 학습하도록 하는 Lifelong Learning(이하 LL)의 개념이 대두되었다. 본 논문에서는 문서 분류에 가장 많이 사용되는 나이브 베이즈와 Lifelong Machine Learning(이하 LLML)의 앙상블 기법을 이용한 스팸 메시지 필터링 방법을 제안한다. 우리는 기존 스팸 필터링 시스템에 가장 많이 사용되는 나이브 베이즈와, LLML 모델 중 ELLA를 적용하여 LL의 성능을 검증한다.","With the rapid growth of the Internet, millions of indiscriminate advertising SMS are sent every day because of the convenience of sending and receiving data. Although we still use methods to block spam words manually, we have been actively researching how to filter spam in a various ways as machine learning emerged. However, spam words and patterns are constantly changing to avoid being filtered, so existing machine learning mechanisms cannot detect or adapt to new words and patterns. Recently, the concept of Lifelong Learning emerged to overcome these limitations, using existing knowledge to keep learning new knowledge continuously. In this paper, we propose a method of spam filtering system using ensemble techniques of naive bayesian which is most commonly used in document classification and LLML(Lifelong Machine Learning). We validate the performance of lifelong learning by applying the model ELLA and the Naive Bayes most commonly used in existing spam filters."
Machine Learning Model to Predict Osteoporotic Spine with Hounsfield Units on Lumbar Computed Tomography,2019,"['Artificial intelligence', 'Machine learning', 'Tensor flow', 'Osteoporosis', 'Spine', 'Hounsfield unit']",,"Objective : Bone mineral density (BMD) is an important consideration during fusion surgery. Although dual X-ray absorptiometry is considered as the gold standard for assessing BMD, quantitative computed tomography (QCT) provides more accurate data in spine osteoporosis. However, QCT has the disadvantage of additional radiation hazard and cost. The present study was to demonstrate the utility of artificial intelligence and machine learning algorithm for assessing osteoporosis using Hounsfield units (HU) of preoperative lumbar CT coupling with data of QCT. Methods : We reviewed 70 patients undergoing both QCT and conventional lumbar CT for spine surgery. The T-scores of 198 lumbar vertebra was assessed in QCT and the HU of vertebral body at the same level were measured in conventional CT by the picture archiving and communication system (PACS) system. A multiple regression algorithm was applied to predict the T-score using three independent variables (age, sex, and HU of vertebral body on conventional CT) coupling with T-score of QCT. Next, a logistic regression algorithm was applied to predict osteoporotic or non-osteoporotic vertebra. The Tensor flow and Python were used as the machine learning tools. The Tensor flow user interface developed in our institute was used for easy code generation. Results : The predictive model with multiple regression algorithm estimated similar T-scores with data of QCT. HU demonstrates the similar results as QCT without the discordance in only one non-osteoporotic vertebra that indicated osteoporosis. From the training set, the predictive model classified the lumbar vertebra into two groups (osteoporotic vs. non-osteoporotic spine) with 88.0% accuracy. In a test set of 40 vertebrae, classification accuracy was 92.5% when the learning rate was 0.0001 (precision, 0.939; recall, 0.969; F1 score, 0.954; area under the curve, 0.900). Conclusion : This study is a simple machine learning model applicable in the spine research field. The machine learning model can predict the T-score and osteoporotic vertebrae solely by measuring the HU of conventional CT, and this would help spine surgeons not to under-estimate the osteoporotic spine preoperatively. If applied to a bigger data set, we believe the predictive accuracy of our model will further increase. We propose that machine learning is an important modality of the medical research field."
Applications of Machine Learning Using Electronic Medical Records in Spine Surgery,2019,"['Machine learning', 'Deep learning', 'Artificial intelligence', 'Electronic medical records', 'Spine surgery']",,"Developments in machine learning in recent years have precipitated a surge in research on the applications of artificial intelligence within medicine. Machine learning algorithms are beginning to impact medicine broadly, and the field of spine surgery is no exception. Electronic medical records are a key source of medical data that can be leveraged for the creation of clinically valuable machine learning algorithms. This review examines the current state of machine learning using electronic medical records as it applies to spine surgery. Studies across the electronic medical record data domains of imaging, text, and structured data are reviewed. Discussed applications include clinical prognostication, preoperative planning, diagnostics, and dynamic clinical assistance, among others. The limitations and future challenges for machine learning research using electronic medical records are also discussed."
Machine learning application for predicting the strawberry harvesting time,2019,"['big data', 'image classification', 'machine learning', 'smart farm', 'TensorFlow']",,"A smart farm is a system that combines information and communication technology (ICT), internet of things (IoT), and agricultural technology that enable a farm to operate with minimal labor and to automatically control of a greenhouse environment. Machine learning based on recently data-driven techniques has emerged with big data technologies and high-performance computing to create opportunities to quantify data intensive processes in agricultural operational environments. This paper presents research on the application of machine learning technology to diagnose the growth status of crops and predicting the harvest time of strawberries in a greenhouse according to image processing techniques. To classify the growth stages of the strawberries, we used object inference and detection with machine learning model based on deep learning neural networks and TensorFlow. The classification accuracy was compared based on the training data volume and training epoch. As a result, it was able to classify with an accuracy of over 90% with 200 training images and 8,000 training steps. The detection and classification of the strawberry maturities could be identified with an accuracy of over 90% at the mature and over mature stages of the strawberries. Concurrently, the experimental results are promising, and they show that this approach can be applied to develop a machine learning model for predicting the strawberry harvesting time and can be used to provide key decision support information to both farmers and policy makers about optimal harvest times and harvest planning."
A Study on Predicting Cryptocurrency Distribution Prices Using Machine Learning Techniques,2019,"['Blockchain', 'Cryptocurrency', 'Blockchain information', 'Machine Learning', 'Price Prediction', 'Distribution management']",,"Purpose: Blockchain technology suggests ways to solve the problems in the existing industry. Among them, Cryptocurrency system, which is an element of Blockchain technology, is a very important factor for operating Blockchain. While Blockchain cryptocur rency has attracted at tention, studies on cryptocurrency prices have been mainly conducted, however previous studies mainly conducted on Bitcoin prices. On the other hand, in the context of the creation and trading of various cryptocurrencies based on the Blockc hain system, lit tle research has been done on cryptocurrencies other than Bitcoin. Hence, this study attempts to find variables related to th the prices of Dash, Litecoin, and Monero cryptocurrencies using machine learning techniques. We also attempt to find differences in t he variables related to the prices for each cryptocurrencies and to examine machine learning techniques that can provide better performance. Research design, data, and methodology methodology: This study performed Dash, Litecoin, and Monero price prediction analysis of cryptocurrency using Blockchain information and machine learning techniques. We employed number of transactions in Blockchain, amount of generated cryptocurrency, transaction fees, number of activity accounts in Blockchain, Block creation difficulty, blo ck size, umber of created blocks as independent variables. This study tried to ensure the reliability of the analysis results through 10 10-fold cross validation. Blockchain information was hierarchically added for price prediction, and the analysis result wa s measured as RMSE and MAPE. ResultsResults: The analysis shows that the prices of Dash, Litecoin and Monero cryptocurrency are related to Blockchain information. Also, we found that different Blockchain information improves the analysis results for each cryptocu rrency. In addition, this study found that the neural network machine learning technique provides better analysis results tha than supportsupport-vector m"
Identifying Suicide Notes Using Forensic Linguistics and Machine Learning,2019,"['forensic linguistics', 'LIWC', 'machine learning', 'principal component analysis', 'suicide note', 'Virginia Woolf']",,"This paper presents how to identify the characteristic properties of suicide notes using the analysis methods in forensic linguistics and how to apply the knowledge to the machine learning research. For this purpose, a corpus was compiled with Virginia Woolf’s literary works and suicide notes, which contained six texts. Then, each text was analyzed with the LIWC (Linguistic Inquiry and Word Count) software. Since the analysis results were complicated, a dimensionality reduction was conducted using a Principal Component Analysis (PCA). In the PCA analysis, it was found that, even though all the texts were written by the same author, the suicide notes were clearly identified from the literary works. The analysis results of LIWC analyses was applied to a machine learning technique (especially a Support Vector Machine; SVM), and the classification accuracy was measured using six real texts and three hypothetical texts. Through the analysis, it was found that the SVM machine identified the suicide notes from the literary works with 100% of accuracy. The current study demonstrated that the linguistic properties of texts could be used to identify the suicides notes from the other types of writings and that they could be used in machine learning research."
Applications of Machine Learning Models on Yelp Data,2019,"['Machine learning', 'Yelp', 'Recommender', 'Predictive analytics', 'Text analysis']",,
Machine Learning for the Prediction of New-Onset Diabetes Mellitus during 5-Year Follow-up in Non-Diabetic Patients with Cardiovascular Risks,2019,"['Type 2 diabetes mellitus', 'diabetes', 'machine learning', 'prediction', 'big data']",,"Purpose: Many studies have proposed predictive models for type 2 diabetes mellitus (T2DM). However, these predictive modelshave several limitations, such as user convenience and reproducibility. The purpose of this study was to develop a T2DM predictivemodel using electronic medical records (EMRs) and machine learning and to compare the performance of this model withtraditional statistical methods.Materials and Methods: In this study, a total of available 8454 patients who had no history of diabetes and were treated at the cardiovascularcenter of Korea University Guro Hospital were enrolled. All subjects completed 5 years of follow up. The prevalence ofT2DM during follow up was 4.78% (404/8454). A total of 28 variables were extracted from the EMRs. In order to verify the crossvalidationtest according to the prediction model, logistic regression (LR), linear discriminant analysis (LDA), quadratic discriminantanalysis (QDA), and K-nearest neighbor (KNN) algorithm models were generated. The LR model was considered as the existingstatistical analysis method.Results: All predictive models maintained a change within the standard deviation of area under the curve (AUC) <0.01 in theanalysis after a 10-fold cross-validation test. Among all predictive models, the LR learning model showed the highest prediction performance,with an AUC of 0.78. However, compared to the LR model, the LDA, QDA, and KNN models did not show a statisticallysignificant difference.Conclusion: We successfully developed and verified a T2DM prediction system using machine learning and an EMR database,and it predicted the 5-year occurrence of T2DM similarly to with a traditional prediction model. In further study, it is necessary toapply and verify the prediction model through clinical research."
Prediction of Citizens’ Emotions on Home Mortgage Rates Using Machine Learning Algorithms,2019,"['Machine Learning', 'Algorithm', 'Mortgage Rates', 'Akman', 'Emotion Classification', 'AdaBoost', 'Classifier', 'Naive Bayes', 'Performance Level', '기계학습', '알고리즘', '모기지 금리', 'Akman', '감정분류', 'AdaBoost', '분류기', 'Naive Bayes', '성능수준']",,"This study attempted to predict citizens' emotions regarding mortgage rates using machine learning algorithms. To accomplish the research purpose, I reviewed the related literature and then set up two research questions. To find the answers to the research questions, I classified emotions according to Akman's classification and then predicted citizens' emotions on mortgage rates using six machine learning algorithms. The results showed that AdaBoost was the best classifier in all evaluation categories. However, the performance level of Naive Bayes was found to be lower than those of other classifiers. Also, this study conducted a ROC analysis to identify which classifier predicts each emotion category well. The results demonstrated that AdaBoost was the best predictor of the residents' emotions on home mortgage rates in all emotion categories. However, in the sadness class, the performance levels of the six algorithms used in this study were much lower than those in the other emotion categories."
Review of Machine Learning Algorithms for Diagnosing Mental Illness,2019,"['Machine learning', 'Mental illness', 'Big data']",,"<P><B>Objective</B></P><P> Enhanced technology in computer and internet has driven scale and quality of data to be improved in various areas including healthcare sectors. Machine Learning (ML) has played a pivotal role in efficiently analyzing those big data, but a general misunderstanding of ML algorithms still exists in applying them (e.g., ML techniques can settle a problem of small sample size, or deep learning is the ML algorithm). This paper reviewed the research of diagnosing mental illness using ML algorithm and suggests how ML techniques can be employed and worked in practice. </P><P><B>Methods</B></P><P> Researches about mental illness diagnostic using ML techniques were carefully reviewed. Five traditional ML algorithms-Support Vector Machines (SVM), Gradient Boosting Machine (GBM), Random Forest, Naïve Bayes, and K-Nearest Neighborhood (KNN)-frequently used for mental health area researches were systematically organized and summarized. </P><P><B>Results</B></P><P> Based on literature review, it turned out that Support Vector Machines (SVM), Gradient Boosting Machine (GBM), Random Forest, Naïve Bayes, and K-Nearest Neighborhood (KNN) were frequently employed in mental health area, but many researchers did not clarify the reason for using their ML algorithm though every ML algorithm has its own advantages. In addition, there were several studies to apply ML algorithms without fully understanding the data characteristics. </P><P><B>Conclusion</B></P><P> Researchers using ML algorithms should be aware of the properties of their ML algorithms and the limitation of the results they obtained under restricted data conditions. This paper provides useful information of the properties and limitation of each ML algorithm in the practice of mental health.</P>"
Modeling with Thin Film Thickness using Machine Learning,2019,"['Modeling', 'Machine learning', 'Amorphous carbon layer', 'Film thickness', 'Box-Behnken']",,"Virtual metrology, which is one of APC techniques, is a method to predict characteristics of manufactured films using machine learning with saving time and resources. As the photoresist is no longer a mask material for use in high aspect ratios as the CD is reduced, hard mask is introduced to solve such problems. Among many types of hard mask materials, amorphous carbon layer(ACL) is widely investigated due to its advantages of high etch selectivity than conventional photoresist, high optical transmittance, easy deposition process, and removability by oxygen plasma. In this study, VM using different machine learning algorithms is applied to predict the thickness of ACL and trained models are evaluated which model shows best prediction performance. ACL specimens are deposited by plasma enhanced chemical vapor deposition(PECVD) with four different process parameters(Pressure, RF power, $C_3H_6$ gas flow, $N_2$ gas flow). Gradient boosting regression(GBR) algorithm, random forest regression(RFR) algorithm, and neural network(NN) are selected for modeling. The model using gradient boosting algorithm shows most proper performance with higher R-squared value. A model for predicting the thickness of the ACL film within the abovementioned conditions has been successfully constructed."
An efficient machine learning approach to establish structure-property linkages,2019,"['Microstructure', 'Machine learning', 'Gaussian process regression', 'Optimization']",,"<P><B>Abstract</B></P>  <P>Full-field simulations with synthetic microstructure offer unique opportunities in predicting and understanding the linkage between microstructural variables and properties of a material prior to or in conjunction with experimental efforts. Nevertheless, the computational cost restrains the application of full-field simulations in optimizing materials microstructures or in establishing comprehensive structure-property linkages. To address this issue, we propose the use of machine learning technique, namely Gaussian process regression, with a small number of full-field simulation results to construct structure-property linkages that are accurate over a wide range of microstructures. Furthermore, we demonstrate that with the implementation of expected improvement algorithm, microstructures that exhibit most desirable properties can be identified using even smaller number of full-field simulations.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Machine learning approach to efficiently utilize microstructure based simulations. </LI> <LI>  Structure-property linkages were made with few full-field simulations. </LI> <LI>  Optimal structures were found with few full-field simulations. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
Modeling with Thin Film Thickness using Machine Learning,2019,"['Modeling', 'Machine learning', 'Amorphous carbon layer', 'Film thickness', 'Box-Behnken']",,"Virtual metrology, which is one of APC techniques, is a method to predict characteristics of manufactured films using machine learning with saving time and resources. As the photoresist is no longer a mask material for use in high aspect ratios as the CD is reduced, hard mask is introduced to solve such problems. Among many types of hard mask materials, amorphous carbon layer(ACL) is widely investigated due to its advantages of high etch selectivity than conventional photoresist, high optical transmittance, easy deposition process, and removability by oxygen plasma. In this study, VM using different machine learning algorithms is applied to predict the thickness of ACL and trained models are evaluated which model shows best prediction performance. ACL specimens are deposited by plasma enhanced chemical vapor deposition(PECVD) with four different process parameters(Pressure, RF power, C3H6 gas flow, N2 gas flow). Gradient boosting regression(GBR) algorithm, random forest regression(RFR) algorithm, and neural network(NN) are selected for modeling. The model using gradient boosting algorithm shows most proper performance with higher R-squared value. A model for predicting the thickness of the ACL film within the abovementioned conditions has been successfully constructed."
Pullout Strength Predictor: A Machine Learning Approach,2019,"['Pedicle screw', 'Machine learning', 'Osteoporosis', 'Decision support', 'Pullout', 'Polyurethane foam', 'Implant', 'Spine', 'Spine fusion']",,"Study Design: A biomechanical study.Purpose: To develop a predictive model for pullout strength.Overview of Literature: Spine fusion surgeries are performed to correct joint deformities by restricting motion between two or more unstable vertebrae. The pedicle screw provides a corrective force to the unstable spinal segment and arrests motions at the unit that are being fused. To determine the hold of a screw, surgeons depend on a subjective perioperative feeling of insertion torque. The objective of the paper was to develop a machine learning based model using density of foam, insertion angle, insertion depth, and reinsertion to predict the pullout strength of pedicle screw.Methods: To predict the pullout strength of pedicle screw, an experimental dataset of 48 data points was used as training data to construct a model based on different machine learning algorithms. A total of five algorithms were tested in the Weka environment and the performance was evaluated based on correlation coefficient and error matrix. A sensitive study of various parameters for obtaining the best combination of parameters for predicting the pullout strength was also preformed using the L9 orthogonal array of Taguchi Design of Experiments.Results: Random forest performed the best with a correlation coefficient of 0.96, relative absolute error of 0.28, and root relative squared error of 0.29. The difference between the experimental and predicted value for the six test cases was not significant (p>0.05).Conclusions: This model can be used clinically for understanding the failure of pedicle screw pullout and pre-surgical planning for spine surgeon."
Selection of Machine Learning Techniques for Network Lifetime Parameters and Synchronization Issues in Wireless Networks,2019,"['Congestion', 'Energy Harvesting', 'Machine Learning Algorithms', 'Network Lifetime', 'Wireless Networks']",,"In real time applications, due to their effective cost and small size, wireless networks play an important role in receiving particular data and transmitting it to a base station for analysis, a process that can be easily deployed. Due to various internal and external factors, networks can change dynamically, which impacts the localisation of nodes, delays, routing mechanisms, geographical coverage, cross-layer design, the quality of links, fault detection, and quality of service, among others. Conventional methods were programmed, for static networks which made it difficult for networks to respond dynamically. Here, machine learning strategies can be applied for dynamic networks effecting self-learning and developing tools to react quickly and efficiently, with less human intervention and reprogramming. In this paper, we present a wireless networks survey based on different machine learning algorithms and network lifetime parameters, and include the advantages and drawbacks of such a system. Furthermore, we present learning algorithms and techniques for congestion, synchronisation, energy harvesting, and for scheduling mobile sinks. Finally, we present a statistical evaluation of the survey, the motive for choosing specific techniques to deal with wireless network problems, and a brief discussion on the challenges inherent in this area of research."
Selection of Machine Learning Techniques for Network Lifetime Parameters and Synchronization Issues in Wireless Networks,2019,"['Congestion', 'Energy Harvesting', 'Machine Learning Algorithms', 'Network Lifetime', 'Wireless Networks']",,"In real time applications, due to their effective cost and small size, wireless networks play an important role inreceiving particular data and transmitting it to a base station for analysis, a process that can be easily deployed.Due to various internal and external factors, networks can change dynamically, which impacts the localisationof nodes, delays, routing mechanisms, geographical coverage, cross-layer design, the quality of links, faultdetection, and quality of service, among others. Conventional methods were programmed, for static networkswhich made it difficult for networks to respond dynamically. Here, machine learning strategies can be appliedfor dynamic networks effecting self-learning and developing tools to react quickly and efficiently, with lesshuman intervention and reprogramming. In this paper, we present a wireless networks survey based ondifferent machine learning algorithms and network lifetime parameters, and include the advantages anddrawbacks of such a system. Furthermore, we present learning algorithms and techniques for congestion,synchronisation, energy harvesting, and for scheduling mobile sinks. Finally, we present a statistical evaluationof the survey, the motive for choosing specific techniques to deal with wireless network problems, and a briefdiscussion on the challenges inherent in this area of research."
"What makes the difference between memory and face of a landscape? A machine learning approach applied to the federal state Brandenburg, Germany",2019,"['Feature selection', 'Historical forest', 'Machine learning', 'Spatial modeling', 'XGBoost']",,"The paper introduces two types of models: the ‘‘memory of a landscape’’ and the ‘‘face of a landscape’’.The memory of a landscape refers to the development of a landscape as a result of many small and some major events.It can be described by a multitude of features that are difficult to change by humans, such as the initial geological substrate and the availability of nutrients linked to it. The implementation of the ‘‘memory model’’ leads to a scientific modelling approach that models the influence of the basic factors on forest distribution. The face of a landscape on the other hand implements a Big Data approach. The face can be changed more easily, e.g. by clearing forest areas and converting them into arable land. Both types of models are used to conclude from today’s perspective on the development of historical forests around 1880. A machine learning algorithm is used to implement both model types and evaluate the importance of features. Both models show differences in accuracy and simulation, which are discussed in detail. The inherent evaluation of the importance of the model inputs can be used to critically review some doctrines. The combination of machine learning with the knowledge of experts who help to select and prepare the data can be used in the future to depict the memory of a landscape more comprehensively in a model than is possible with previous approaches."
Artificial Intelligence Applications in Type 2 Diabetes Mellitus Care: Focus on Machine Learning Methods,2019,"['Artificial Intelligence', 'Diabetes Mellitus', 'Machine Learning', 'Diabetes Care', 'Health Informatics']",,"Objectives: The incidence of type 2 diabetes mellitus has increased significantly in recent years. With the development of artificial intelligence applications in healthcare, they are used for diagnosis, therapeutic decision making, and outcome prediction, especially in type 2 diabetes mellitus. This study aimed to identify the artificial intelligence (AI) applications for type 2 diabetes mellitus care. Methods: This is a review conducted in 2018. We searched the PubMed, Web of Science, and Embase scientific databases, based on a combination of related mesh terms. The article selection process was based on Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). Finally, 31 articles were selected after inclusion and exclusion criteria were applied. Data gathering was done by using a data extraction form. Data were summarized and reported based on the study objectives. Results: The main applications of AI for type 2 diabetes mellitus care were screening and diagnosis in different stages.Among all of the reviewed AI methods, machine learning methods with 71% (n = 22) were the most commonly applied techniques. Many applications were in multi method forms (23%). Among the machine learning algorithms applications, support vector machine (21%) and naive Bayesian (19%) were the most commonly used methods. The most important variables that were used in the selected studies were body mass index, fasting blood sugar, blood pressure, HbA1c, triglycerides, low-density lipoprotein, high-density lipoprotein, and demographic variables. Conclusions: It is recommended to select optimal algorithms by testing various techniques. Support vector machine and naive Bayesian might achieve better performance than other applications due to the type of variables and targets in diabetes-related outcomes classification."
Detection of Suicide Attempters among Suicide Ideators Using Machine Learning,2019,"['Suicide attempt', 'Suicide ideation', 'Machine learning', 'Public health data.']",,"Objective We aimed to develop predictive models to identify suicide attempters among individuals with suicide ideation using a machine learning algorithm.Methods Among 35,116 individuals aged over 19 years from the Korea National Health & Nutrition Examination Survey, we selected 5,773 subjects who reported experiencing suicide ideation and had answered a survey question about suicide attempts. Then, we performed resampling with the Synthetic Minority Over-sampling TEchnique (SMOTE) to obtain data corresponding to 1,324 suicide attempters and 1,330 non-suicide attempters. We randomly assigned the samples to a training set (n=1,858) and a test set (n=796). In the training set, random forest models were trained with features selected through recursive feature elimination with 10-fold cross validation.Subsequently, the fitted model was used to predict suicide attempters in the test set.Results In the test set, the prediction model achieved very good performance [area under receiver operating characteristic curve (AUC)=0.947] with an accuracy of 88.9%.Conclusion Our results suggest that a machine learning approach can enable the prediction of individuals at high risk of suicide through the integrated analysis of various suicide risk factors."
Prediction and Staging of Hepatic Fibrosis in Children with Hepatitis C Virus: A Machine Learning Approach,2019,"['Chronic Hepatitis C', 'Liver Fibrosis', 'Medical Informatics', 'Machine Learning', 'Pediatrics']",,"Objectives: The aim of this study is to develop an intelligent diagnostic system utilizing machine learning for data cleansing, then build an intelligent model and obtain new cutoff values for APRI (aspartate aminotransferase-to-platelet ratio) and FIB- 4 (fibrosis score) for the prediction and staging of fibrosis in children with chronic hepatitis C (CHC). Methods: Random forest (RF) was utilized in this study for data cleansing; then, prediction and staging of fibrosis, APRI and FIB-4 scores and their areas under the ROC curve (AUC) have been obtained on the cleaned dataset. A cohort of 166 Egyptian children with CHC was studied. Results: RF, APRI, and FIB-4 achieved high AUCs; where APRI had AUCs of 0.78, 0.816, and 0.77; FIB- 4 had AUCs of 0.74, 0.828, and 0.78; and RF had AUCs of 0.903, 0.894, and 0.822, for the prediction of any type of fibrosis, advanced fibrosis, and differentiating between mild and advanced fibrosis, respectively. Conclusions: Machine learning is a valuable addition to non-invasive methods of liver fibrosis prediction and staging in pediatrics. Furthermore, the obtained cutoff values for APRI and FIB-4 showed good performance and are consistent with some previously obtained cutoff values.There was some agreement between the predictions of RF, APRI and FIB-4 for the prediction and staging of fibrosis."
An Analysis of Forest Health Using Machine Learning Algorithms,2019,"['숲', '건강', 'UAV', 'WEKA', 'RGBVI', 'GLI', 'NGRDI', 'ExGR', '기계학습', '알고리즘', 'Random Forest', 'forest', 'health', 'UAV', 'WEKA', 'RGBVI', 'GLI', 'NGRDI', 'ExGR', 'machine learning', 'algorithm', 'Random Forest']",,"The primary purpose of this study was to predict and classify the health status of forests using machine learning algorithms. To accomplish the research goals, I selected a forest of Jeongjung-ri, Cheongju city as a study area and captured the UAV images of this area. In this research, I split UAV images into RGB bands and then extracted RGBVI values based on them. RGBVI is generally used as an indicator of the health status of crops and vegetation. This study used the regression analysis algorithm of WEKA to predict the health status of forests. The results of the analysis showed that GLI, NGRDI, and ExGR had a positive impact on forest health, but ExG and ExR had a negative effect on forest health. This research also classified the health status of forests using four machine learning algorithms and compared the performance of each algorithm. The result of the analysis shows that Random Forest is the most effective algorithm in all categories. The results of this research can be used as a reference for policymakers to predict the health problems of forests and to prepare measures for them. Despite this usefulness, however, this study has some limitations. These limitations can be overcome to some extent by using time-series analysis."
An Analysis of Forest Health Using Machine Learning Algorithms,2019,"['숲', '건강', 'UAV', 'WEKA', 'RGBVI', 'GLI', 'NGRDI', 'ExGR', '기계학습', '알고리즘', 'Random Forest', 'forest', 'health', 'machine learning', 'algorithm', 'Random Forest']","본 연구의 주된 목적은 기계학습알고리즘을 이용하여 숲의 건강상태를 예측하고 분류하는 것이었다. 연구목적을 달성하기 위해 본 연구는 청주시 정중리의 한 숲을 연구지역으로 선정하고 이 지역에 대한 UAV영상을 촬영하였다. 본 연구는 UAV영상을 RGB 밴드로 분리시킨 다음 이를 기반으로 RGBVI값을 도출하였다. RGBVI는 일반적으로 농작물이나 식생의 건강상태를 나타내주는 지표로 이용되고 있다. 숲의 건강상태를 예측하기 위해 본 연구는 WEKA의 회귀분석 알고리즘을 이용하였다. 분석의 결과 GLI, NGRDI, ExGR은 숲의 건강에 정의 영향을 미치지만, ExG와 ExR은 숲의 건강에 부의 영향을 미치고 있음이 확인되었다. 또한 본 연구는 4개의 기계학습알고리즘을 이용하여 숲의 건강상태를 분류해보고 각 알고리즘의 성능을 비교하였다. 분석의 결과 Random Forest가 모든 범주에서 가장 효과적인 알고리즘임이 확인되었다. 본연구의 결과는 정책결정자들이 숲의 건강문제를 예측하고 이에 대한 대책을 세우는데 있어서 참고자료로 활용될 수 있을 것이다. 그러나 이러한 유용성에도 불구하고 본 연구는 몇 가지 한계점들을 지니고 있다. 이러한 한계들은 앞으로 시계열분석을 이용하면 어느 정도 극복될 수 있을 것이다.","The primary purpose of this study was to predict and classify the health status of forests using machine learning algorithms. To accomplish the research goals, I selected a forest of Jeongjung-ri, Cheongju city as a study area and captured the UAV images of this area. In this research, I split UAV images into RGB bands and then extracted RGBVI values based on them. RGBVI is generally used as an indicator of the health status of crops and vegetation. This study used the regression analysis algorithm of WEKA to predict the health status of forests. The results of the analysis showed that GLI, NGRDI, and ExGR had a positive impact on forest health, but ExG and ExR had a negative effect on forest health. This research also classified the health status of forests using four machine learning algorithms and compared the performance of each algorithm. The result of the analysis shows that Random Forest is the most effective algorithm in all categories. The results of this research can be used as a reference for policymakers to predict the health problems of forests and to prepare measures for them. Despite this usefulness, however, this study has some limitations. These limitations can be overcome to some extent by using time-series analysis."
DEVELOPMENT OF A MACHINE LEARNING BASED FAST RUNNING MODEL TO DETERMINE RAPIDLY THE PROCESS CONDITIONS IN DRAWING PROCESS,2019,"['Machine learning', 'ANN', 'Fast running model', 'Elastic-plastic FE simulation', 'Laboratory bar drawing test']",,"This study proposes a fast running model that interconnects input and output data for a single-pass cold bar drawing process through the use of Artificial Neural Network (ANN) and automatically generated a large volume of elasticplastic finite element (FE) analysis results. The prediction accuracy of the FE analysis was verified by comparing the FE analysis with measurements from a drawing experiment. A Python-based script that automatically controls ABAQUS was coded to sequentially produce output data that varies according to the input data, which is a combination of 18 grades of steel and 1,000 process conditions. The ANN was trained using input and output data, and then a nine-dimensional fast running model was developed. The fast running model predicted the values of output variables (drawing force, strain at the center, strain on the surface, accumulated damage at the center, contact pressure, and the fracture (or non-fracture) of the material) in 0.1 second no matter how the mechanical properties of the steels and process conditions change. With this fast running model, engineers in the drawing industry can easily determine or modify the process conditions to improve productivity and product quality even when a grade of steel that has never been employed before is drawn."
Machine Learning Analysis for the Soliton Formation in Resonant Nonlinear Three-Wave Interactions,2019,"['Solitons', 'Raman backscattering', 'Machine learning']",,"For the prediction of nonlinear phenomena in a three-wave Raman backscattering for laser amplification, a machine learning technology is applied to predict the generation of solitons in complicated multi-dimensional parameter spaces. The generation of the soliton in the resonant three-wave system is simulated with one-dimensional fluid equations. The solitons are generated in the early phase of the three-wave interaction, and the slow propagation speeds play an important role. Using a pattern matching method comparing the simulation data with the analytic solution, the generation of solitons are automatically detected. After collecting enough data sets by autonomous parameter scanning in the numerical simulation, nonlinear regression and k-nearest neighbor algorithms are utilized for the prediction of the existence of solitons."
Prediction of survival outcomes in patients with epithelial ovarian cancer using machine learning methods,2019,"['.', 'Machine Learning', 'CA-125 Antigen', 'Ovarian Neoplasms', 'Prognosis', 'Survival']",,"Objectives: The aim of this study was to develop a new prognostic classification for epithelial ovarian cancer (EOC) patients using gradient boosting (GB) and to compare the accuracy of the prognostic model with the conventional statistical method.Methods: Information of EOC patients from Samsung Medical Center (training cohort, n=1,128) was analyzed to optimize the prognostic model using GB. The performance of the final model was externally validated with patient information from Asan Medical Center (validation cohort, n=229). The area under the curve (AUC) by the GB model was compared to that of the conventional Cox proportional hazard regression analysis (CoxPHR) model.Results: In the training cohort, the AUC of the GB model for predicting second year overall survival (OS), with the highest target value, was 0.830 (95% confidence interval [CI]=0.802–0.853). In the validation cohort, the GB model also showed high AUC of 0.843 (95% CI=0.833–0.853). In comparison, the conventional CoxPHR method showed lower AUC (0.668 (95% CI=0.617–0.719) for the training cohort and 0.597 (95% CI=0.474–0.719) for the validation cohort) compared to GB. New classification according to survival probability scores of the GB model identified four distinct prognostic subgroups that showed more discriminately classified prediction than the International Federation of Gynecology and Obstetrics staging system.Conclusion: Our novel GB-guided classification accurately identified the prognostic subgroups of patients with EOC and showed higher accuracy than the conventional method. This approach would be useful for accurate estimation of individual outcomes of EOC patients."
Comparative Study to Measure the Performance of Commonly Used Machine Learning Algorithms in Diagnosis of Alzheimer's Disease,2019,"[""Alzheimer's disease"", 'KNN', 'Machine learning', 'Neurodegeneration']",,"In machine learning, the performance of the system depends upon the nature of input data. The efficiency of the system improves when the behavior of the input data changes from un-normalized to normalized form. This paper experimentally demonstrated the performance of KNN, SVM, LDA and NB on Alzheimer's dataset. The dataset undertaken for the study consisted of 3 classes, i.e. Demented, Converted and Non-Demented. Analysis shows that LDA and NB gave an accuracy of 89.83% and 88.19% respectively in both the cases whereas the accuracy of KNN and SVM improved from 46.87% to 82.80% and 53.40% to 88.75% respectively when input data changed from un-normalized to normalized state. From the above results it was observed that KNN and SVM show significant improvement in classification accuracy on normalized data as compared to un-normalized data, whereas LDA and NB reflect no such change in their performance."
A Machine Learning Based Approach for Automatic Rebar Detection and Quantification of Deterioration in Concrete Bridge Deck Ground Penetrating Radar B-scan Images,2019,"['ground penetrating radar', 'GPR', 'rebar detection', 'deterioration mapping', 'HOG', 'AdaBoost']",,"Ground penetrating radar (GPR) is a non-destructive method (NDT) for subsurface object identification. Interpretation of GPR data is often done manually by an engineer, which is a time-intensive task and requires moderate to significant level of training. The authors proposed a novel machine learning based processing for automatic interpretation and quantification of concrete bridge deck GPR B-scan images. The proposed method is based on combination of image processing, machine learning (ML) data classification, data filtering, and spatial pattern analysis for quantification of deterioration in concrete bridge decks. For the first time, the authors introduced a dataset of 4,000 B-scan images cropped from real bridge deck GPR field data, named DECKGPRH1.0. The proposed method is tested on bridge deck GPR data collected from three bridges with different NBI (National Bridge Inventory) ratings. The results presented indicate that by implementing a ML based classifier and a fine tuned filter, the proposed approach provides a robust solution for automatic quantification GPR field data."
Calibration of Portable Particulate Matter–Monitoring Device using Web Query and Machine Learning,2019,"['Calibration', 'Machine learning', 'Monitoring and control', 'Particulate matter', 'Web query']",,"Background: Monitoring and control of PM2.5 are being recognized as key to address health issues attributed to PM2.5. Availability of low-cost PM2.5 sensors made it possible to introduce a number of portable PM2.5 monitors based on light scattering to the consumer market at an affordable price. Accuracy of light scatteringebased PM2.5 monitors significantly depends on the method of calibration.Static calibration curve is used as the most popular calibration method for low-cost PM2.5 sensors particularly because of ease of application. Drawback in this approach is, however, the lack of accuracy.Methods: This study discussed the calibration of a low-cost PM2.5-monitoring device (PMD) to improve the accuracy and reliability for practical use. The proposed method is based on construction of the PM2.5 sensor network using Message Queuing Telemetry Transport (MQTT) protocol and web query of reference measurement data available at government-authorized PM monitoring station (GAMS) in the republic of Korea. Four machine learning (ML) algorithms such as support vector machine, k-nearest neighbors, random forest, and extreme gradient boosting were used as regression models to calibrate the PMD measurements of PM2.5. Performance of each ML algorithm was evaluated using stratified K-fold cross-validation, and a linear regression model was used as a reference.Results: Based on the performance of ML algorithms used, regression of the output of the PMD to PM2.5 concentrations data available from the GAMS through web query was effective. The extreme gradient boosting algorithm showed the best performance with a mean coefficient of determination (R2) of 0.78 and standard error of 5.0 mg/m3, corresponding to 8% increase in R2 and 12% decrease in root mean square error in comparison with the linear regression model. Minimum 100 hours of calibration period was found required to calibrate the PMD to its full capacity. Calibration method proposed poses a limitation on the location of the PMD being in the vicinity of the GAMS. As the number of the PMD participating in the sensor network increases, however, calibrated PMDs can be used as reference devices to nearby PMDs that require calibration, forming a calibration chain through MQTT protocol.Conclusions: Calibration of a low-cost PMD, which is based on construction of PM2.5 sensor network using MQTT protocol and web query of reference measurement data available at a GAMS, significantly improves the accuracy and reliability of a PMD, thereby making practical use of the low-cost PMD possible."
Calibration of Portable Particulate Mattere-Monitoring Device using Web Query and Machine Learning,2019,"['Calibration', 'Machine learning', 'Monitoring and control', 'Particulate matter', 'Web query']",,"Background: Monitoring and control of PM<sub>2.5</sub> are being recognized as key to address health issues attributed to PM<sub>2.5</sub>. Availability of low-cost PM<sub>2.5</sub> sensors made it possible to introduce a number of portable PM<sub>2.5</sub> monitors based on light scattering to the consumer market at an affordable price. Accuracy of light scatteringe-based PM<sub>2.5</sub> monitors significantly depends on the method of calibration. Static calibration curve is used as the most popular calibration method for low-cost PM<sub>2.5</sub> sensors particularly because of ease of application. Drawback in this approach is, however, the lack of accuracy. Methods: This study discussed the calibration of a low-cost PM<sub>2.5</sub>-monitoring device (PMD) to improve the accuracy and reliability for practical use. The proposed method is based on construction of the PM<sub>2.5</sub> sensor network using Message Queuing Telemetry Transport (MQTT) protocol and web query of reference measurement data available at government-authorized PM monitoring station (GAMS) in the republic of Korea. Four machine learning (ML) algorithms such as support vector machine, k-nearest neighbors, random forest, and extreme gradient boosting were used as regression models to calibrate the PMD measurements of PM<sub>2.5</sub>. Performance of each ML algorithm was evaluated using stratified K-fold cross-validation, and a linear regression model was used as a reference. Results: Based on the performance of ML algorithms used, regression of the output of the PMD to PM<sub>2.5</sub> concentrations data available from the GAMS through web query was effective. The extreme gradient boosting algorithm showed the best performance with a mean coefficient of determination (R<sup>2</sup>) of 0.78 and standard error of 5.0 ㎍/㎥, corresponding to 8% increase in R<sup>2</sup> and 12% decrease in root mean square error in comparison with the linear regression model. Minimum 100 hours of calibration period was found required to calibrate the PMD to its full capacity. Calibration method proposed poses a limitation on the location of the PMD being in the vicinity of the GAMS. As the number of the PMD participating in the sensor network increases, however, calibrated PMDs can be used as reference devices to nearby PMDs that require calibration, forming a calibration chain through MQTT protocol. Conclusions: Calibration of a low-cost PMD, which is based on construction of PM<sub>2.5</sub> sensor network using MQTT protocol and web query of reference measurement data available at a GAMS, significantly improves the accuracy and reliability of a PMD, thereby making practical use of the low-cost PMD possible."
Analyzing Impact of Bitcoin Features to Bitcoin Price via Machine Learning Techniques,2019,"['비트코인', '블록체인', '머신러닝', '예측분석', '다항 회귀', 'bitcoin', 'blockchain', 'machine learning', 'analysis of prediction', 'polynomial regression']","2009년에 처음 소개된 비트코인은 전 세계적으로 출시되어있는 암호 화폐들 중 가장 대중적이다. 출시 될 당시에 가치는 아주 낮았고, 다른 암호 화폐처럼 대중적이지도 않았다. 비트코인에 오늘날 많은 사람들이 관심을 가지고 있다. 비트코인은 일반 화폐와 교환될 수도 있고 지불 용도로 사용할 수도 있다. 비트코인은 많은 온라인 상점들과 온라인 서비스에서 통용되고 있다. 암호 화폐는 특정 당국에 의해 규정되지 않고 일반적인 수요와 공급에 따라 규정되지도 않는다. 비트코인은 최근에 상당한 성공을 이루었다. 비트코인 가격이 어느 주요한 요소들에 의해 결정되는지에 대한 호기심이 본 연구를 진행하게 되었다. 가장 대중적인 비트코인 디지털 월렛(www.blockchain.com) 으로부터 Blockchain Wallet API에 기반해서 데이터셋으로부터 특징들을 뽑았다. 머신러닝 기법으로 polynomial regression을 이용하여 특징들의 영향도를 계산하였다. 결과적으로 어떤 특징들이 비트코인 가격 변동과 연관이 깊은지 살펴봤다.","Bitcoin (BTC ticker) is the most popular crypto-currency in the world, the first release of which took place in 2009. In this respect, in a release date for this currency the price was equal basically to none and was not considered as popular as other known crypto-currency available at the time. Today bitcoin is in high demand from users around the globe. It can be exchanged through special exchanges for ordinary money, or used directly as a means of payment for anything of choice by the users. Bitcoin is accepted by many of the largest online stores and online services for products, goods and services worldwide. Quotes of crypto currency are not regulated by any legislative or legal authorities, and therefore are considered fluid, whereby the value depends totally on the current natural demand and supply. Recently, bitcoin has achieved a great success in use within open global markets. By being motivated from a review of these factors, we decided to take a deep look into the main factors and features characteristic of bitcoin. In this project, we tried to take a vision regarding the use and impact of bitcoin features from a dataset based on Blockchain Wallet API, which is derived from one of the most popular bitcoin digital wallets – Blockchain Wallet API [1]. As a target, we set different phases for the analysis and gathering of relevant data from API. In these terms, for calculating the impact of feature we have used machine learning techniques; which included a pure linear regression and expended version of a linear regression-polynomial regression."
Application of machine learning to an early warning system for very short-term heavy rainfall,2019,"['Early warning system', 'Heavy rainfall nowcasting', 'Machine learning', 'Discretization', 'Classification']",,"<P><B>Abstract</B></P>  <P>The purpose of an early warning system (EWS) is to issue warning signals prior to extreme events. Extreme weather events, however, are hard to predict due to their chaotic behavior. This paper suggests a method for an effective EWS for very short-term heavy rainfall with machine learning techniques. The EWS produces a warning signal when it is expected to reach the criterion for a heavy rain advisory within the next 3 h. We devised a selective discretization method that converts a subset of continuous input variables to nominal ones. Meteorological data obtained from automatic weather stations are preprocessed by the selective discretization and principal component analysis. As a classifier, logistic regression is used to predict whether or not a warning is required. A comparative evaluation was performed on the EWS models generated by various classifiers. The tests were run for 652 locations in South Korea from 2007 to 2012. The empirical results showed that the preprocessing methods improved the prediction quality and logistic regression works well on heavy rainfall nowcasting in terms of F-measure and equitable threat score.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  An early warning system (EWS) for heavy rainfall nowcasting is proposed. </LI> <LI>  Discretizing input variables selectively can improve the prediction quality of the EWS. </LI> <LI>  Principal component analysis matches well with the selective discretization. </LI> <LI>  A comparative analysis was conducted on various classifiers. </LI> <LI>  Logistic regression is well suited for heavy rainfall nowcasting. </LI> </UL> </P>"
Radiomics MRI Phenotyping with Machine Learning to Predict the Grade of Lower-Grade Gliomas: A Study Focused on Nonenhancing Tumors,2019,"['Grade', 'Lower-grade glioma', 'Magnetic resonance imaging', 'Radiomics', 'The Cancer Genome Atlas']",,"ObjectiveTo assess whether radiomics features derived from multiparametric MRI can predict the tumor grade of lower-grade gliomas (LGGs; World Health Organization grade II and grade III) and the nonenhancing LGG subgroup.Materials and MethodsTwo-hundred four patients with LGGs from our institutional cohort were allocated to training (n = 136) and test (n = 68) sets. Postcontrast T1-weighted images, T2-weighted images, and fluid-attenuated inversion recovery images were analyzed to extract 250 radiomics features. Various machine learning classifiers were trained using the radiomics features to predict the glioma grade. The trained classifiers were internally validated on the institutional test set and externally validated on a separate cohort (n = 99) from The Cancer Genome Atlas (TCGA). Classifier performance was assessed by determining the area under the curve (AUC) from receiver operating characteristic curve analysis. An identical process was performed in the nonenhancing LGG subgroup (institutional training set, n = 73; institutional test set, n = 37; and TCGA cohort, n = 37) to predict the glioma grade.ResultsThe performance of the best classifier was good in the internal validation set (AUC, 0.85) and fair in the external validation set (AUC, 0.72) to predict the LGG grade. For the nonenhancing LGG subgroup, the performance of the best classifier was good in the internal validation set (AUC, 0.82), but poor in the external validation set (AUC, 0.68).ConclusionRadiomics feature-based classifiers may be useful to predict LGG grades. However, radiomics classifiers may have a limited value when applied to the nonenhancing LGG subgroup in a TCGA cohort."
Application of Extreme Learning Machine (ELM) and Genetic Programming (GP) to design steel-concrete composite floor systems at elevated temperatures,2019,"['elevated temperature', 'channel shear connector', 'extreme learning machine', 'genetic programming', 'artificial neural network']",,"This study is aimed to predict the behaviour of channel shear connectors in composite floor systems at different temperatures. For this purpose, a soft computing approach is adopted. Two novel intelligence methods, including an Extreme Learning Machine (ELM) and a Genetic Programming (GP), are developed. In order to generate the required data for the intelligence methods, several push-out tests were conducted on various channel connectors at different temperatures. The dimension of the channel connectors, temperature, and slip are considered as the inputs of the models, and the strength of the connector is predicted as the output. Next, the performance of the ELM and GP is evaluated by developing an Artificial Neural Network (ANN). Finally, the performance of the ELM, GP, and ANN is compared with each other. Results show that ELM is capable of achieving superior performance indices in comparison with GP and ANN in the case of load prediction. Also, it is found that ELM is not only a very fast algorithm but also a more reliable model."
PyQSAR: A Fast QSAR Modeling Platform Using Machine Learning and Jupyter Notebook,2019,"['QSA(P)R', 'Chemoinformatics', 'Machine learning', 'Hierarchical clustering', 'Genetic algorithm']",,"Understanding the relationship between structure and property is important in current research works. The QSAR/QSPR (Quantitative Structure?Activity Relationship/Quantitative Structure?Property Relationship) is a common method for finding the relationships between the structure and property of compounds. However, traditional methods of performing QSAR analysis rely on multiple software platforms for each step. Here, an integrated standalone python package, PyQSAR, is proposed that combines all QSAR modeling process in one workbench. The efficiency of the package was verified by comparing to 10 previously published works. The results showed high performance of PyQSAR in terms of R 2 with less than half an hour execution time with a typical desktop PC for each test case. The main goal of PyQSAR is the production of reliable QSAR models on a single platform with an easy-to-follow workflow."
Moment rotation prediction of precast beam to column connections using extreme learning machine,2019,"['moment rotation', 'forecasting', 'extreme learning machine', 'precast beam to column connection', 'partly hidden corbel']",,"The performance of precast concrete structures is greatly influenced by the behaviour of beam-to-column connections. A single connection may be required to transfer several loads simultaneously so each one of those loads must be considered in the design. A good connection combines practicality and economy, which requires an understanding of several factors; including strength, serviceability, erection and economics. This research work focuses on the performance aspect of a specific type of beam-to-column connection using partly hidden corbel in precast concrete structures. In this study, the results of experimental assessment of the proposed beam-to-column connection in precast concrete frames was used. The purpose of this research is to develop and apply the Extreme Learning Machine (ELM) for moment-rotation prediction of precast beam-to-column connections. The ELM results are compared with genetic programming (GP) and artificial neural network (ANN). The reliability of the computational models was accessed based on simulation results and using several statistical indicators."
Development of Supervised Machine Learning based Catalog Entry Classification and Recommendation System,2019,"['카테고리 자동 추천', '온라인 B2B 소핑몰', '지도학습 기반 머신 러닝', '형태소 분석', 'Naïve Bayes 분류.', 'Catalog Entry Auto-Recommendation', 'Online B2B Shopping Mall', 'Supervised Machine Learning', 'Morphological Analysis', 'Naive Bayes Classification Algorithm.']",,"In the case of Domeggook B2B online shopping malls, it has a market share of over 70% with more than 2 million members and 800,000 items are sold per one day. However, since the same or similar items are stored and registered in different catalog entries, it is difficult for the buyer to search for items, and problems are also encountered in managing B2B large shopping malls. Therefore, in this study, we developed a catalog entry auto classification and recommendation system for products by using semi-supervised machine learning method based on previous huge shopping mall purchase information. Specifically, when the seller enters the item registration information in the form of natural language, KoNLPy morphological analysis process is performed, and the Naïve Bayes classification method is applied to implement a system that automatically recommends the most suitable catalog information for the article. As a result, it was possible to improve both the search speed and total sales of shopping mall by building accuracy in catalog entry efficiently."
Development of Diagnosis Algorithm for Cam Wear of Paper Container Using Machine Learning,2019,"['Cam wear (캠 마모)', 'Machine learning (기계학습)', 'Paper cup forming machine (종이용기 성형기)', 'Failure diagnosis (고장 진단)', 'K-Nearest neighbor classifier (K 근접 이웃 분류기)']",,
Drivers of Late Pleistocene human survival and dispersal: an agent-based modeling and machine learning approach,2019,"['Out of Africa', 'Human dispersal', 'Model validation', 'Machine learning', 'Sensitivity analysis', 'Pleistocene', 'Global', 'Climate dynamics', 'Paleogeography', 'Data treatment', 'Data analysis']",,"<P><B>Abstract</B></P>  <P>Understanding Late Pleistocene human dispersals from Africa requires understanding a multifaceted problem with factors varying in space and time, such as climate, ecology, human behavior, and population dynamics. To understand how these factors interact to affect human survival and dispersal, we have developed a realistic agent-based model that includes geographic features, climate change, and time-varying vegetation and food resources. To enhance computational efficiency, we further apply machine learning algorithms. Our approach is new in that it is designed to systematically evaluate a large-scale agent-based model, and identify its key parameters and sensitivities. Results show that parameter interactions are the major source in generating variability in human dispersal and survival/extinction scenarios. In realistic scenarios with geographical features and time-evolving climatic conditions, random fluctuations become a major source of variability in arrival times and success. Furthermore, parameter settings as different as 92% of maximum possible difference, and occupying more than 30% of parameter space can result in similar dispersal scenarios. This suggests that historical contingency (similar causes – different effects) and equifinality (different causes – similar effects) are primary constituents of human dispersal scenarios. While paleoanthropology, archaeology and paleogenetics now provide insights into patterns of human dispersals at an unprecedented level of detail, elucidating the causes underlying these patterns remains a major challenge.</P>"
Rockfall Source Identification Using a Hybrid Gaussian Mixture-Ensemble Machine Learning Model and LiDAR Data,2019,"['Rockfall source identification', 'Gaussian mixture model', 'ensemble machine learning', 'GIS', 'LiDAR']",,"The availability of high-resolution laser scanning data and advanced machine learning algorithms has enabled an accurate potential rockfall source identification. However, the presence of other mass movements, such as landslides within the same region of interest, poses additional challenges to this task. Thus, this research presents a method based on an integration of Gaussian mixture model (GMM) and ensemble artificial neural network (bagging ANN [BANN]) for automatic detection of potential rockfall sources at Kinta Valley area, Malaysia. The GMM was utilised to determine slope angle thresholds of various geomorphological units. Different algorithms (ANN, support vector machine [SVM] and k nearest neighbour [kNN]) were individually tested with various ensemble models (bagging, voting and boosting). Grid search method was adopted to optimise the hyperparameters of the investigated base models. The proposed model achieves excellent results with success and prediction accuracies at 95% and 94%, respectively. In addition, this technique has achieved excellent accuracies (ROC = 95%) over other methods used. Moreover, the proposed model has achieved the optimal prediction accuracies (92%) on the basis of testing data, thereby indicating that the model can be generalised and replicated in different regions, and the proposed method can be applied to various landslide studies."
Continuous Time Quantum Monte Carlo in Combination with Machine Learning on the Hubbard Model,2019,"['Hubbard model', 'Continuous time quantum Monte Carlo', 'Machine learning', 'Dynamical mean field theory']",,"The acceleration of exact continuous time quantum Monte Carlo (CTQMC) approaches in multisite or multi-orbital systems is extremely interesting work, because these approaches are very timeconsuming in terms of numerical computation and might account for the nature of exotic behaviors such as high-temperature superconductivity and Mott insulator behavior observed in the strongly correlated materials. We extend the recently developed interaction-expansion CTQMC method in combination with a machine learning (CTQMC+ML) approach for the single-site and single-orbital systems to multi-site and multi-orbital ones. This method can be applied to explore the nonlocal correlation effects in lattice models and to study the electronic structure of real materials via an ab-initio density functional theory plus dynamical mean field theory approach. We find that our CTQMC+ML method for multi-site (and multi-orbital) systems accurately predicts the impurity Green’s function with less computational time than the CTQMC approaches, as in the case of the single-site and single-orbital version."
Prediction of short-term algal bloom using the M5P model-tree and extreme learning machine,2019,"['Algal bloom', 'Chlorophyll-a', 'Extreme learning machine', 'Juksan weir', 'M5P model tree', 'Water quality']",,"In this study, we designed a data-driven model to predict chlorophyll-a using M5P model tree and extreme learning machine (ELM). The Juksan weir in the Youngsan River has high chlorophyll-a, which is the primary indicator of algal bloom every year. Short-term algal bloom prediction is important for environmental management and ecological assessment. Two models were developed and evaluated for short-term algal bloom prediction. M5P is a classification and regression-analysis-based method, and ELM is a feed-forward neural network with fast learning using the least square estimate for regression. The dataset used in this study includes water temperature, rainfall, solar radiation, total nitrogen, total phosphorus, N/P ratio, and chlorophyll-a, which were collected on a daily basis from January 2013 to December 2016. The M5P model showed that the prediction model after one day had the highest performance power and dropped off rapidly starting with predictions after three days. Comparing the performance power of the ELM model with the M5P model, it was found that the performance power of the 1-7 d chlorophyll-a prediction model was higher. Moreover, in a period of rapidly increasing algal blooms, the ELM model showed higher accuracy than the M5P model."
Rockfall Source Identification Using a Hybrid Gaussian Mixture-Ensemble Machine Learning Model and LiDAR Data,2019,"['Rockfall source identification', 'Gaussian mixture model', 'ensemble machine learning', 'GIS', 'LiDAR']",,"The availability of high-resolution laser scanning data and advanced machine learning algorithms has enabled an accurate potential rockfall source identification. However, the presence of other mass movements, such as landslides within the same region of interest, poses additional challenges to this task. Thus, this research presents a method based on an integration of Gaussian mixture model (GMM) and ensemble artificial neural network (bagging ANN [BANN]) for automatic detection of potential rockfall sources at Kinta Valley area, Malaysia. The GMM was utilised to determine slope angle thresholds of various geomorphological units. Different algorithms(ANN, support vector machine [SVM] and k nearest neighbour [kNN]) were individually tested with various ensemble models (bagging, voting and boosting). Grid search method was adopted to optimise the hyperparameters of the investigated base models. The proposed model achieves excellent results with success and prediction accuracies at 95% and 94%, respectively. In addition, this technique has achieved excellent accuracies (ROC = 95%) over other methods used. Moreover, the proposed model has achieved the optimal prediction accuracies (92%) on the basis of testing data, thereby indicating that the model can be generalised and replicated in different regions, and the proposed method can be applied to various landslide studies."
Prediction of Acquired Taxane Resistance Using a Personalized Pathway-Based Machine Learning Method,2019,"['Taxoids', 'Paclitaxel', 'Docetaxel', 'Drug resistance', 'Molecular diagnosis', 'Machine learning']",,"Purpose This study was conducted to develop and validate an individualized prediction model for automated detection of acquired taxane resistance (ATR).Materials and Methods Penalized regression, combined with an individualized pathway score algorithm, was applied to construct a predictive model using publically available genomic cohorts of ATR and intrinsic taxane resistance (ITR). To develop a model with enhanced generalizability, we merged multiple ATR studies then updated the learning parameter via robust cross-study validation.Results For internal cross-study validation, the ATR model produced a perfect performance with an overall area under the receiver operating curve (AUROC) of 1.000 with an area under the precision-recall curve (AUPRC) of 1.000, a Brier score of 0.007, a sensitivity and a specificity of 100%. The model showed an excellent performance on two independent blind ATR cohorts (overall AUROC of 0.940, AUPRC of 0.940, a Brier score of 0.127). When we applied our algorithm to two large-scale pharmacogenomic resources for ITR, the Cancer Genome Project (CGP) and the Cancer Cell Line Encyclopedia (CCLE), an overall ITR cross-study AUROC was 0.70, which is a far better accuracy than an almost random level reported by previous studies. Furthermore, this model had a high transferability on blind ATR cohorts with an AUROC of 0.69, suggesting that general predictive features may be at work across both ITR and ATR.Conclusion We successfully constructed a multi-study–derived personalized prediction model for ATR with excellent accuracy, generalizability, and transferability."
Classification of radiographic lung pattern based on texture analysis and machine learning,2019,"['Neural network model', 'visual pattern recognition', 'thoracic radiography']",,"This study evaluated the feasibility of using texture analysis and machine learning to distinguish radiographic lung patterns. A total of 1200 regions of interest (ROIs) including four specific lung patterns (normal, alveolar, bronchial, and unstructured interstitial) were obtained from 512 thoracic radiographs of 252 dogs and 65 cats. Forty-four texture parameters based on eight methods of texture analysis (first-order statistics, spatial gray-level-dependence matrices, gray-level-difference statistics, gray-level run length image statistics, neighborhood gray-tone difference matrices, fractal dimension texture analysis, Fourier power spectrum, and Law's texture energy measures) were used to extract textural features from the ROIs. The texture parameters of each lung pattern were compared and used for training and testing of artificial neural networks. Classification performance was evaluated by calculating accuracy and the area under the receiver operating characteristic curve (AUC). Forty texture parameters showed significant differences between the lung patterns. The accuracy of lung pattern classification was 99.1% in the training dataset and 91.9% in the testing dataset. The AUCs were above 0.98 in the training set and above 0.92 in the testing dataset. Texture analysis and machine learning algorithms may potentially facilitate the evaluation of medical images."
Plant Species Identification based on Plant Leaf Using Computer Vision and Machine Learning Techniques,2019,"['Feature Extraction', 'Plant Species Identification', 'Segmentation', 'SVM']",,"Plants are very crucial for life on Earth. There is a wide variety of plant species available, and the number is increasing every year. Species knowledge is a necessity of various groups of society like foresters, farmers, environmentalists, educators for different work areas. This makes species identification an interdisciplinary interest. This, however, requires expert knowledge and becomes a tedious and challenging task for the non-experts who have very little or no knowledge of the typical botanical terms. However, the advancements in the fields of machine learning and computer vision can help make this task comparatively easier. There is still not a system so developed that can identify all the plant species, but some efforts have been made. In this study, we also have made such an attempt. Plant identification usually involves four steps, i.e. image acquisition, pre-processing, feature extraction, and classification. In this study, images from Swedish leaf dataset have been used, which contains 1,125 images of 15 different species. This is followed by pre-processing using Gaussian filtering mechanism and then texture and color features have been extracted. Finally, classification has been done using Multiclass-support vector machine, which achieved accuracy of nearly 93.26%, which we aim to enhance further."
The roles of differencing and dimension reduction in machine learning forecasting of employment level using the FRED big data,2019,"['employment forecast', 'deep neural network', 'differencing', 'dimension reduction', 'long short term memory', 'gated recurrent unit']",,"Forecasting the U.S. employment level is made using machine learning methods of the artificial neural network: deep neural network, long short term memory (LSTM), gated recurrent unit (GRU). We consider the big data of the federal reserve economic data among which 105 important macroeconomic variables chosen by McCracken and Ng (Journal of Business and Economic Statistics, 34, 574-589, 2016) are considered as predictors. We investigate the influence of the two statistical issues of the dimension reduction and time series differencing on the machine learning forecast. An out-of-sample forecast comparison shows that (LSTM, GRU) with differencing performs better than the autoregressive model and the dimension reduction improves long-term forecasts and some short-term forecasts."
Plant Species Identification based on Plant Leaf Using Computer Vision and Machine Learning Techniques,2019,"['Feature Extraction', 'Plant Species Identification', 'Segmentation', 'SVM']",,"Plants are very crucial for life on Earth. There is a wide variety of plant species available, and the number is increasing every year. Species knowledge is a necessity of various groups of society like foresters, farmers, environmentalists, educators for different work areas. This makes species identification an interdisciplinary interest. This, however, requires expert knowledge and becomes a tedious and challenging task for the non-experts who have very little or no knowledge of the typical botanical terms. However, the advancements in the fields of machine learning and computer vision can help make this task comparatively easier. There is still not a system so developed that can identify all the plant species, but some efforts have been made. In this study, we also have made such an attempt. Plant identification usually involves four steps, i.e. image acquisition, pre-processing, feature extraction, and classification. In this study, images from Swedish leaf dataset have been used, which contains 1,125 images of 15 different species. This is followed by pre-processing using Gaussian filtering mechanism and then texture and color features have been extracted. Finally, classification has been done using Multiclass-support vector machine, which achieved accuracy of nearly 93.26%, which we aim to enhance further."
Injection mold design of reverse engineering using injection molding analysis and machine learning,2019,"['Computer-aided engineering', 'Injection molding', 'Warpage', 'Reverse engineering', 'Multilayer perceptron', 'Artificial neural networks']",,"Plastic composites are used in vehicle components to improve fuel efficiency. Thus, the warpage of injection-molded plastic parts has become a quality issue. Factors, such as product shape and thickness, resin, and other injection molding conditions, can be modified to improve the warpage problem. However, if these factors are set with no possible adjustments, reverse engineering may be required.Reverse engineering is a difficult process that requires many trials and errors; thus, it is only used as a last resort. With respect to the warpage issue, reverse engineering considers the following: (1) Predicting and (2) modeling the warpage in opposite directions. Autodesk Moldflow Insight accommodates these key considerations, but many researchers are reluctant to use it. Although existing injectionmolding analysis programs are mainly used to predict qualitative results, computer-aided engineering (CAE) for reverse engineering requires quantitative analysis. Hence, the considerations are different from the existing analyses. An error in warpage prediction may lead to a costly mold modification because of the molds' complex structures. Quantitative warpage prediction for reverse engineering depends on process variables; thus, understanding how warpages are affected by uncertain process variables is important to improve the reliability of reverse engineering. Moreover, even if appropriate process variables are set, they cannot be applied due to tolerance in lengths. For this reason, mold shrinkage must be identified before designing a mold. This study conducted injection molding analysis for a radiator tank that uses glass fiber-reinforced plastic using Autodesk Moldflow Insight 2018.2. Data for warpage prediction were generated in accordance with five process variables to identify the relationship between the level of warpage and process variables. CAE also showed the level of mold shrinkage that can reduce warpage. In addition, a predictive model was created using the multilayer perceptron (MLP)-supervised learning technique, which is a deep learning method for artificial neural networks. The predictive model was compared with typical regression models, such as polynomial regression (also known as response surface model), EDT and RBF, to determine the optimal approximation model. The real modeling time for a radiator tank product is 1 h, but the MLP approximation model required only 1 min and 8 s to perform 8530 iterations with a similar reliability."
Estimation of moment and rotation of steel rack connections using extreme learning machine,2019,"['steel racks', 'moment rotation behavior', 'upright column', 'beam-end connector', 'ELM']",,"The estimation of moment and rotation in steel rack connections could be significantly helpful parameters for designers and constructors in the initial designing and construction phases. Accordingly, Extreme Learning Machine (ELM) has been optimized to estimate the moment and rotation in steel rack connection based on variable input characteristics as beam depth, column thickness, connector depth, moment and loading. The prediction and estimating of ELM has been juxtaposed with genetic programming (GP) and artificial neural networks (ANNs) methods. Test outcomes have indicated a surpass in accuracy predicting and the capability of generalization in ELM approach than GP or ANN. Therefore, the application of ELM has been basically promised as an alternative way to estimate the moment and rotation of steel rack connection. Further particulars are presented in details in results and discussion."
On the learning machine with compensatory aggregation based neurons in quaternionic domain,2019,['Quaternionic multi-layer perceptron Quaternionic back-propagation 3D transformation Time series prediction'],,"The nonlinear spatial grouping process of synapses is one of the fascinating methodologies for neuro-computing researchers to achieve the computational power of a neuron. Generally, researchers use neu-ron models that are based on summation (linear), product (linear) or radial basis (nonlinear) aggregation for the processing of synapses, to construct multi-layered feed-forward neural networks, but all these neuron models and their corresponding neural networks have their advantages or disadvantages. The multi-layered network generally uses for accomplishing the global approximation of input–output map-ping but sometimes getting stuck into local minima, while the nonlinear radial basis function (RBF) net-work is based on exponentially decaying that uses for local approximation to input–output mapping. Their advantages and disadvantages motivated to design two new artiﬁcial neuron models based on com-pensatory aggregation functions in the quaternionic domain. The net internal potentials of these neuron models are developed with the compositions of basic summation (linear) and radial basis (nonlinear) operations on quaternionic-valued input signals. The neuron models based on these aggregation func-tions ensure faster convergence, better training, and prediction accuracy. The learning and generalization capabilities of these neurons are veriﬁed through various three-dimensional transformations and time series predictions as benchmark problems."
Traffic-Profile and Machine Learning Based Regional Data Center Design and Operation for 5G Network,2019,"['Big data', 'cellular traffic', 'data centers', 'recurrent neural networks', 'traffic prediction', '5G.']",,"Data center in the fifth generation (5G) network will serveas a facilitator to move the wireless communication industry froma proprietary hardware based approach to a more software orientedenvironment. Techniques such as Software defined networking(SDN) and network function virtualization (NFV) would beable to deploy network functionalities such as service and packetgateways as software. These virtual functionalities however wouldrequire computational power from data centers. Therefore, thesedata centers need to be properly placed and carefully designedbased on the volume of traffic they are meant to serve. In this work,we first divide the city of Milan, Italy into different zones using Kmeansclustering algorithm. We then analyse the traffic profiles ofthese zones in the city using a network operator’s Open Big Dataset. We identify the optimal placement of data centers as a facilitylocation problem and propose the use of Weiszfeld’s algorithmto solve it. Furthermore, based on our analysis of traffic profilesin different zones, we heuristically determine the ideal dimensionof the data center in each zone. Additionally, to aid operation andfacilitate dynamic utilization of data center resources, we use thestate of the art recurrent neural network models to predict thefuture traffic demands according to past demand profiles of eacharea."
Optimization Calculations and Machine Learning Aimed at Reduction of Wind Forces Acting on Tall Buildings and Mitigation of Wind Environment,2019,"['Optimization calculation', 'CFD', 'CNN', 'Wind force', 'Wind environment']",,"We performed calculations combining optimization technologies and Computational Fluid Dynamics (CFD) aimed at reducing wind forces and mitigating wind environments (local strong winds) around buildings. However, the Reynolds Averaged Navier-stokes Simulation (RANS), which seems somewhat inaccurate, needs to be used to create a realistic CFD optimization tool. Therefore, in this study we explored the possibilities of optimizing calculations using RANS. We were able to demonstrate that building configurations advantageous to wind forces could be predicted even with RANS. We also demonstrated that building layouts was more effective than building configurations in mitigating local strong winds around tall buildings. Additionally, we used the Convolutional Neural Network (CNN) as an airflow prediction method alternative to CFD in order to increase the speed of optimization calculations, and validated its prediction accuracy."
Selection of CDMA and OFDM using machine learning in underwater wireless networks,2019,['Underwater communicationMachine learningCDMAOFDM'],,"Underwater acoustic (UWA) channels have long propagation delays and irregular Doppler shifts, which make the design of communication scheme difficult. Even though two transceivers are fixed, UWA channels dramatically vary by time since speed velocity profile in UWA channel is changed by day and night. This paper proposes a selection method between CDMA and OFDM modulations using a convolutional neural network (CNN) for estimating channel parameters and Random Forest (RF) for modulation selection based on the CNN results. Computer simulations demonstrate that the parameter estimation of the proposed method is better than that of the conventional least square (LS) estimation, and RF selection method exhibits better detection results than the conventional DNN."
Continuous Time Quantum Monte Carlo in Combination with Machine Learning on the Hubbard Model,2019,,,
Data Mining in Spine Surgery: Leveraging Electronic Health Records for Machine Learning and Clinical Research,2019,['.'],,.
A Review of Deep Learning Research,2019,"['Deep learning', 'machine learning', 'artificial intelligence', 'learning model', 'neural network', 'optimization method']",,"With the advent of big data, deep learning technology has become an important research direction in the field of machine learning, which has been widely applied in the image processing, natural language processing, speech recognition and online advertising and so on. This paper introduces deep learning techniques from various aspects, including common models of deep learning and their optimization methods, commonly used open source frameworks, existing problems and future research directions. Firstly, we introduce the applications of deep learning; Secondly, we introduce several common models of deep learning and optimization methods; Thirdly, we describe several common frameworks and platforms of deep learning; Finally, we introduce the latest acceleration technology of deep learning and highlight the future work of deep learning."
BERT Transformer와 Deep Learning을 활용한 전이학습 효과 검증 연구 :법률상담데이터 분류문제 적용,2019,"['Transfer Learning', 'Natural Language Processing', 'BERT', 'Deep Learning', 'Classification', 'Neural Network']",,"As AI(artificial intelligence) is actively researched, it is being applied in various fields such as natural language processing, video and voice processing. However, voices pointing out the technical limitations of deep learning are spreading, and accordingly, researches for solving the technical limitations of deep learning are being actively conducted. In this paper, BERT, well known as the pre-training model of natural language processing, was applied to the classification problem of legal counseling data to verify the effect of transfer learning. Using BERT pre-trained data, the Transformer classification model was implemented and applied to the problem of legal counseling data classification, which showed higher accuracy than the traditional machine learning algorithm."
Playing with Machine Translation in Language Classroom: Affordances and Constraints,2019,"['machine translation', 'mediation', 'google translate', 'computer-assisted language learning']",,"With recent developments in artificial intelligence, students are starting to actively embrace machine translation for a variety of purposes. However, English teachers feel ambivalent about introducing this new technology into classroom settings, raising concern about its educational value and effectiveness. The situation requires an empirical investigation into the affordances and constraints of machine translation within specific educational contexts. Given these intersecting developments, the present study reports on a pedagogical experiment which traced students’ exploration of using machine translation services, and analyzes their evaluations of this emerging technology. Results suggest that teachers and students can benefit from the use of this emerging technology if they collaboratively explore machine translation as a context-sensitive tool, while paying close attention to crosslinguistic features, culture-specific phrases, lexical and grammatical characteristics, genre types, and the criticality of a given task. Based on these results some possible classroom tasks incorporating machine translation are proposed. It is also suggested that educators initiate a productive discussion on the use of machine translation and other artificial intelligence-driven technologies in the classroom and design effective pedagogical practices within a broader conceptual framework of literacy, rather than giving into unexamined hope or fear of the technology."
Two person Interaction Recognition Based on Effective Hybrid Learning,2019,"['Action Recognition', 'Convolutional Neural Network', 'Deep Architecture', 'Transfer Learning']",,"Action recognition is an essential task in computer vision due to the variety of prospective applications, such as security surveillance, machine learning, and human-computer interaction. The availability of more video data than ever before and the lofty performance of deep convolutional neural networks also make it essential for action recognition in video. Unfortunately, limited crafted video features and the scarcity of benchmark datasets make it challenging to address the multi-person action recognition task in video data. In this work, we propose a deep convolutional neural network-based Effective Hybrid Learning (EHL) framework for two-person interaction classification in video data. Our approach exploits a pre-trained network model (the VGG16 from the University of Oxford Visual Geometry Group) and extends the Faster R-CNN (region-based convolutional neural network a state-of-the-art detector for image classification). We broaden a semi-supervised learning method combined with an active learning method to improve overall performance. Numerous types of two-person interactions exist in the real world, which makes this a challenging task. In our experiment, we consider a limited number of actions, such as hugging, fighting, linking arms, talking, and kidnapping in two environment such simple and complex. We show that our trained model with an active semi-supervised learning architecture gradually improves the performance. In a simple environment using an Intelligent Technology Laboratory (ITLab) dataset from Inha University, performance increased to 95.6% accuracy, and in a complex environment, performance reached 81% accuracy. Our method reduces data-labeling time, compared to supervised learning methods, for the ITLab dataset. We also conduct extensive experiment on Human Action Recognition benchmarks such as UT-Interaction dataset, HMDB51 dataset and obtain better performance than state-of-the-art approaches."
Deep Learning in Drebin: Android malware Image Texture Median Filter Analysis and Detection,2019,"['malware', 'Image Texture Median Filter', 'Malware Activity Embedding in Vector Space']",,"This paper proposes an Image Texture Median Filter (ITMF) to analyze and detect Android malware on Drebin datasetsMedian Filter (MF) to reflect the similarity of the malware binary file block. At the same time, using the MAEVS (Malware Activity Embedding in Vector Space) to reflect the potential dynamic activity of malware. In order to ensure the improvement of the classification accuracy, the above-mentioned features(ITMF feature and MAEVS feature)are studied to train Restricted Boltzmann Machine (RBM) and Back Propagation (BP). The experimental results show that the model has an average accuracy rate of 95.43% 1. We design a model of “ITMF” combined with Image Processing of with few false alarms. to Android malicious code, which is significantly higher than 95.2% of without ITMF, 93.8% of shallow machine learning model SVM, 94.8% of KNN, 94.6% of ANN."
A Multi-Stage Convolution Machine with Scaling and Dilation for Human Pose Estimation,2019,"['CNN', 'Human pose estimation', 'Multi-stage', 'Pyramid stacking', 'Dilation', 'Gating']",,"Vision-based Human Pose Estimation has been considered as one of challenging research subjects due to problems including confounding background clutter, diversity of human appearances and illumination changes in scenes. To tackle these problems, we propose to use a new multi-stage convolution machine for estimating human pose. To provide better heatmap prediction of body joints, the proposed machine repeatedly produces multiple predictions according to stages with receptive field large enough for learning the long-range spatial relationship. And stages are composed of various modules according to their strategic purposes. Pyramid stacking module and dilation module are used to handle problem of human pose at multiple scales. Their multi-scale information from different receptive fields are fused with concatenation, which can catch more contextual information from different features. And spatial and channel information of a given input are converted to gating factors by squeezing the feature maps to a single numeric value based on its importance in order to give each of the network channels different weights. Compared with other ConvNet-based architectures, we demonstrated that our proposed architecture achieved higher accuracy on experiments using standard benchmarks of LSP and MPII pose datasets."
Variable Selection of Feature Pattern using SVM-based Criterion with Q-Learning in Reinforcement Learning,2019,"['서포트-벡터-머신', 'RNA시퀀싱', '빅-데이터', 'SVM-RFE알고리즘', 'Q-learning', '강화학습', 'Support-Vector Machine', 'RNA sequencing Big-Data', 'Support Vector Machine-Recursive Feature Elimination', 'Q-learning', 'Reinforcement Learning']",,"Selection of feature pattern gathered from the observation of the RNA sequencing data (RNA-seq) are not all equally informative for identification of differential expressions: some of them may be noisy, correlated or irrelevant because of redundancy in Big-Data sets. Variable selection of feature pattern aims at differential expressed gene set that is significantly relevant for a special task. This issues are complex and important in many domains, for example. In terms of a computational research field of machine learning, selection of feature pattern has been studied such as Random Forest, K-Nearest and Support Vector Machine (SVM). One of most the well-known machine learning algorithms is SVM, which is classical as well as original. The one of a member of SVM-criterion is Support Vector Machine-Recursive Feature Elimination (SVM-RFE), which have been utilized in our research work. We propose a novel algorithm of the SVM-RFE with Q-learning in reinforcement learning for better variable selection of feature pattern. By comparing our proposed algorithm with the well-known SVM-RFE combining Welch’ T in published data, our result can show that the criterion from weight vector of SVM-RFE enhanced by Q-learning has been improved by an off-policy by a more exploratory scheme of Q-learning."
Quark Gluon Jet Discrimination with Weakly Supervised Learning,2019,"['QCD', 'Jet', 'Fragmentation', 'Weakly supervised learning', 'Machine learning']",,"Deep learning techniques are currently being investigated for high energy physics experiments, to tackle a wide range of problems, with quark and gluon discrimination becoming a benchmark for new algorithms. One weakness is the traditional reliance on Monte Carlo simulations, which may not be well modelled at the detail required by deep learning algorithms. The weakly supervised learning paradigm gives an alternate route to classication, by using samples with different quark{ gluon proportions instead of fully labeled samples. This paradigm has, therefore, huge potential for particle physics classication problems as these weakly supervised learning methods can be applied directly to collision data. In this study, we show that realistically simulated samples of dijet and Z+jet events can be used to discriminate between quark and gluon jets by using weakly supervised learning. We implement and compare the performance of weakly supervised learning for quark{gluon jet classication using three different machine learning methods: the jet image-based convolutional neural network, the particle-based recurrent neural network and and the feature-based boosted decision tree."
Applications of deep learning for the analysis of medical data,2019,"['Artificial intelligence', 'Deep neural networks', 'Drug discovery', 'Medical image analysis']",,"Over the past decade, deep learning has demonstrated superior performances in solving many problems in various fields of medicine compared with other machine learning methods. To understand how deep learning has surpassed traditional machine learning techniques, in this review, we briefly explore the basic learning algorithms underlying deep learning. In addition, the procedures for building deep learning-based classifiers for seizure electroencephalograms and gastric tissue slides are described as examples to demonstrate the simplicity and effectiveness of deep learning applications. Finally, we review the clinical applications of deep learning in radiology, pathology, and drug discovery, where deep learning has been actively adopted. Considering the great advantages of deep learning techniques, deep learning will be increasingly and widely utilized in a wide variety of different areas in medicine in the coming decades."
Supervised learning‐based DDoS attacks detection: Tuning hyperparameters,2019,"['accuracy of detection', 'DDoS attack', 'long short‐term memory', 'machine learning', 'tensorflow']",,"Two supervised learning algorithms, a basic neural network and a long short‐term memory recurrent neural network, are applied to traffic including DDoS attacks. The joint effects of preprocessing methods and hyperparameters for machine learning on performance are investigated. Values representing attack characteristics are extracted from datasets and preprocessed by two methods. Binary classification and two optimizers are used. Some hyperparameters are obtained exhaustively for fast and accurate detection, while others are fixed with constants to account for performance and data characteristics. An experiment is performed via TensorFlow on three traffic datasets. Three scenarios are considered to investigate the effects of learning former traffic on sequential traffic analysis and the effects of learning one dataset on application to another dataset, and determine whether the algorithms can be used for recent attack traffic. Experimental results show that the used preprocessing methods, neural network architectures and hyperparameters, and the optimizers are appropriate for DDoS attack detection. The obtained results provide a criterion for the detection accuracy of attacks."
Development and Validation of Deep-Learning Algorithm for Electrocardiography-Based Heart Failure Identification,2019,"['Deep learning', 'Heart failure', 'Electrocardiography', 'Machine learning', 'Artificial intelligence']",,"Background and Objectives: Screening and early diagnosis for heart failure (HF) are critical. However, conventional screening diagnostic methods have limitations, and electrocardiography (ECG)-based HF identification may be helpful. This study aimed to develop and validate a deep-learning algorithm for ECG-based HF identification (DEHF).Methods: The study involved 2 hospitals and 55,163 ECGs of 22,765 patients who performed echocardiography within 4 weeks were study subjects. ECGs were divided into derivation and validation data. Demographic and ECG features were used as predictive variables. The primary endpoint was detection of HF with reduced ejection fraction (HFrEF; ejection fraction [EF]≤40%), and the secondary endpoint was HF with mid-range to reduced EF (≤50%). We developed the DEHF using derivation data and the algorithm representing the risk of HF between 0 and 1. We confirmed accuracy and compared logistic regression (LR) and random forest (RF) analyses using validation data.Results: The area under the receiver operating characteristic curves (AUROCs) of DEHF for identification of HFrEF were 0.843 (95% confidence interval, 0.840–0.845) and 0.889 (0.887–0.891) for internal and external validation, respectively, and these results significantly outperformed those of LR (0.800 [0.797–0.803], 0.847 [0.844–0.850]) and RF (0.807 [0.804–0.810], 0.853 [0.850–0.855]) analyses. The AUROCs of deep learning for identification of the secondary endpoint was 0.821 (0.819–0.823) and 0.850 (0.848–0.852) for internal and external validation, respectively, and these results significantly outperformed those of LR and RF.Conclusions: The deep-learning algorithm accurately identified HF using ECG features and outperformed other machine-learning methods."
Support Vector Machine과 Gradient Boosting Machine 기반의 풍력발전량 예측 알고리즘 개발과 전력거래소 풍력발전량 예측 대회를 통한 알고리즘 성능 검증,2019,"['Gradient boosting machine', 'Support vector machine', 'Short-term forecasting', 'Ensemble', 'Wind power forecasting']",,"We propose a new method that improves the prediction accuracy of wind power generation by using two machine learning algorithms, support vector machine (SVM) and gradient boosting machine (GBM). We participate in the wind power forecasting competition held by KPX to verify the performance. First, we construct individual models in parallel using the data only at the corresponding target time since the data quality of weather data decreases as the target time increases. Second, we use the ensemble method by using two machine learning algorithms, SVM and GBM. Third, we extend the wind power generation data by interpolation to reduce the variation and estimate actual wind power generation. Fourth, we reconstruct the extended wind power generation data to prevent from converging to the average value and. We describe characteristics of stepwise model and present each result with normalized mean absolute error."
A review on deep learning-based structural health monitoring  of civil infrastructures,2019,"['structural health monitoring', 'deep learning', 'convolutional neural network', 'structural damage detection', 'structural condition assessment', 'artificial intelligence', 'machine learning', 'computer vision']",,"In the past two decades, structural health monitoring (SHM) systems have been widely installed on various civil infrastructures for the tracking of the state of their structural health and the detection of structural damage or abnormality, through long-term monitoring of environmental conditions as well as structural loadings and responses. In an SHM system, there are plenty of sensors to acquire a huge number of monitoring data, which can factually reflect the in-service condition of the target structure. In order to bridge the gap between SHM and structural maintenance and management (SMM), it is necessary to employ advanced data processing methods to convert the original multi-source heterogeneous field monitoring data into different types of specific physical indicators in order to make effective decisions regarding inspection, maintenance and management. Conventional approaches to data analysis are confronted with challenges from environmental noise, the volume of measurement data, the complexity of computation, etc., and they severely constrain the pervasive application of SHM technology. In recent years, with the rapid progress of computing hardware and image acquisition equipment, the deep learning-based data processing approach offers a new channel for excavating the massive data from an SHM system, towards autonomous, accurate and robust processing of the monitoring data. Many researchers from the SHM community have made efforts to explore the applications of deep learning-based approaches for structural damage detection and structural condition assessment. This paper gives a review on the deep learning-based SHM of civil infrastructures with the main content, including a brief summary of the history of the development of deep learning, the applications of deep learning-based data processing approaches in the SHM of many kinds of civil infrastructures, and the key challenges and future trends of the strategy of deep learning-based SHM."
Learning-based automatic sensing and size classification of microparticles using smartphone holographic microscopy,2019,,,"<P>The accurate and fast size classification of microparticles is important in environmental monitoring and biomedical applications. Conventional methods for sensing and classifying microparticles require bulky optical setups and generally show medium performance. Accordingly, the development of a portable and smart platform for accurate particle size classification is essential. In this study, we propose a new sensing platform for automatic identification of microparticle types through the synergistic integration of smartphone-based digital in-line holographic microscopy (DIHM) and machine-learning algorithms. The smartphone-based DIHM system consists of a coherent laser beam, a pinhole, a sample holder, a three-dimensional printed attachment, and a modified built-in smartphone camera module. The portable device has a physical dimension of 4 × 8 × 10 cm<SUP>3</SUP> and 220 g in weight. Holograms of various polystyrene microparticles with different sizes (<I>d</I> = 2-50 μm) were recorded with a wide field-of-view and high spatial resolution. To establish a proper classification model, tens of features including geometrical parameters and light-intensity distributions were extracted from holograms of individual particles, and five machine-learning algorithms were used. After examining the performance of several classifiers, the resulting support vector machine model trained by using three geometrical parameters and three extracted parameters from light-intensity distributions shows the highest accuracy in the particle classification of the training and test sets (>98%). Therefore, the developed handheld smartphone-based platform can be potentially utilized to cope with various imaging needs in mobile healthcare and environmental monitoring.</P>"
Learner Perceptions of Using Machine Translation Tools in the EFL Classroom,2019,"['machine translation', 'pre-service teachers', 'EAP', 'reading-writing connection']",,"There is growing interest in the use of machine translation (MT) as tools to scaffold second and foreign language learning. However, at present, there is minimal investigation of EFL learners’ perceptions of using MT tools to facilitate their academic reading in EAP classes. To explore EFL learners’ views on using MT in an EAP class, participants were introduced to online translation tools and given time to read research articles. They then completed a survey of their perceptions of MT. In accordance with previous research, results indicated that most participants spent less than a quarter of their time using MT. They typically used MT to translate the articles they were required to read for the class and translated materials tended to be words and phrases. In general, as with findings from prior studies, learners perceived MT to be useful as well as facilitating their L2 literacy. Particular strengths mentioned included convenience and ability to read text faster. Limitations mentioned included doubts about the veracity of translations, over-reliance on MT, and suspicions about longterm retention of new vocabulary learned through MT. Based on these findings, we can conclude that MT has the potential to be a valuable tool in the EAP classroom."
LEARNING TO RECOGNIZE DRIVING PATTERNS FOR COLLECTIVELY CHARACTERIZING ELECTRIC VEHICLE DRIVING BEHAVIORS,2019,"['Electric vehicles', 'Data mining', 'Energy management', 'Battery management systems', 'Machine learning']",,"As electric vehicle (EV) emerges, it is important to understand how driver’s driving behavior is influencing power consumption in an electric vehicle. Driver’s personal driving behavior is usually quite distinctive and can be recognized by means of driving patterns after some driving cycles. This paper presents a method combining several machine learning approaches to characterize driving behaviors of electric vehicles. The driving patterns are modeled according to power consumption monitored by the battery management system (BMS), in aspects of individual driver’s personal and EV-fleet operations. First, we apply an unsupervised clustering approach to characterize a driver's behaviors by formulating driving patterns. Subsequently, the resulting clustered datasets were used to train machine-learning based classifiers for classification of dataset of EV and EV-fleet driving patterns. The work aims to provide a robust solution to help identify the characteristics of specific types of EVs and their driver behaviors, in order to allow automakers and EV-subsystem providers to gather valuable driving information for product improvement."
Deep-Learning Seat Selection on a Tour Bus Based on Scenery and Sunlight Information,2019,"['Deep learning', 'Transfer learning', 'Google Street View', 'Tour']",,"When traveling on a tour bus, the seat one chooses for viewing scenery is one of the main factors affecting one’s enjoyment of a trip. However, such scenery information is not available in advance. Therefore, it is necessary to predict the scenery for a tour bus route. In previous research, such predictions have been attempted through machine learning. However, the prediction result has only informed users about which direction is best, not about how good that direction is. Moreover, no information was given about sunlight, which can also affect the viewing of scenery. Therefore, in this paper, we propose the Beautiful Scenery & Cool Shade system that quantifies the information about scenery and sunlight in four directions using deep learning and the azimuth theory. More specifically, we used ResNet-152, DenseNet-161, and Inception v3 for the prediction, and we used Google Street View for the input data. After building the system, we tested its applications to two existing tour bus routes. The results showed that our system outperformed the previous system. The proposed system allows tourists to make satisfactory travel plans and allows tour companies to develop more valuable tour services, ultimately contributing to the development of the global tourism industry."
PharmacoNER Tagger: a deep learning-based tool for automatically finding chemicals and drugs in Spanish medical texts,2019,"['machine learning', 'natural language processing', 'neural networks (computer)']",,"Automatically detecting mentions of pharmaceutical drugs and chemical substances is key for the subsequent extraction of relations of chemicals with other biomedical entities such as genes, proteins, diseases, adverse reactions or symptoms. The identification of drug mentions is also a prior step for complex event types such as drug dosage recognition, duration of medical treatments or drug repurposing. Formally, this task is known as named entity recognition (NER), meaning automatically identifying mentions of predefined entities of interest in running text. In the domain of medical texts, for chemical entity recognition (CER), techniques based on hand-crafted rules and graph-based models can provide adequate performance. In the recent years, the field of natural language processing has mainly pivoted to deep learning and state-of-the-art results for most tasks involving natural language are usually obtained with artificial neural networks. Competitive resources for drug name recognition in English medical texts are already available and heavily used, while for other languages such as Spanish these tools, although clearly needed were missing. In this work, we adapt an existing neural NER system, NeuroNER, to the particular domain of Spanish clinical case texts, and extend the neural network to be able to take into account additional features apart from the plain text. NeuroNER can be considered a competitive baseline system for Spanish drug and CER promoted by the Spanish national plan for the advancement of language technologies (Plan TL)."
VS3‐NET: Neural variational inference model for machine‐reading comprehension,2019,"['machine reading comprehension', 'question answering', 'SQuAD', 'variational inference', 'VS3‐NET']",,"We propose the VS3‐NET model to solve the task of question answering questions with machine‐reading comprehension that searches for an appropriate answer in a given context. VS3‐NET is a model that trains latent variables for each question using variational inferences based on a model of a simple recurrent unit‐based sentences and self‐matching networks. The types of questions vary, and the answers depend on the type of question. To perform efficient inference and learning, we introduce neural question‐type models to approximate the prior and posterior distributions of the latent variables, and we use these approximated distributions to optimize a reparameterized variational lower bound. The context given in machine‐reading comprehension usually comprises several sentences, leading to performance degradation caused by context length. Therefore, we model a hierarchical structure using sentence encoding, in which as the context becomes longer, the performance degrades. Experimental results show that the proposed VS3‐NET model has an exact‐match score of 76.8% and an F1 score of 84.5% on the SQuAD test set."
PharmacoNER Tagger: a deep learning-based tool for automatically finding chemicals and drugs in Spanish medical texts,2019,"['machine learning', 'natural language processing', 'neural networks (computer)']",,"Automatically detecting mentions of pharmaceutical drugs and chemical substances is key for the subsequent extraction of relations of chemicals with other biomedical entities such as genes, proteins, diseases, adverse reactions or symptoms. The identification of drug mentions is also a prior step for complex event types such as drug dosage recognition, duration of medical treatments or drug repurposing. Formally, this task is known as named entity recognition (NER), meaning automatically identifying mentions of predefined entities of interest in running text. In the domain of medical texts, for chemical entity recognition (CER), techniques based on hand-crafted rules and graph-based models can provide adequate performance. In the recent years, the field of natural language processing has mainly pivoted to deep learning and state-of-the-art results for most tasks involving natural language are usually obtained with artificial neural networks. Competitive resources for drug name recognition in English medical texts are already available and heavily used, while for other languages such as Spanish these tools, although clearly needed were missing. In this work, we adapt an existing neural NER system, NeuroNER, to the particular domain of Spanish clinical case texts, and extend the neural network to be able to take into account additional features apart from the plain text. NeuroNER can be considered a competitive baseline system for Spanish drug and CER promoted by the Spanish national plan for the advancement of language technologies (Plan TL)."
The Unsupervised Learning-based Language Modeling of Word Comprehension in Korean,2019,"['Unsupervised learning', 'Morfessor', 'Surprisal', 'Lexical processing', 'Word recognition', '비지도 학습', '모페써', '놀라움', '선형 혼합 회귀 모형', '단어 판독']",,"We are to build an unsupervised machine learning-based language model which can estimate the amount of information that are in need to process words consisting of subword-level morphemes and syllables. We are then to investigate whether the reading times of words reflecting their morphemic and syllabic structures are predicted by an information-theoretic measure such as surprisal. Specifically, the proposed Morfessor-based unsupervised machine learning model is first to be trained on the large dataset of sentences on Sejong Corpus and is then to be applied to estimate the information-theoretic measure on each word in the test data of Korean words. The reading times of the words in the test data are to be recruited from Korean Lexicon Project (KLP) Database. A comparison between the information-theoretic measures of the words in point and the corresponding reading times by using a linear mixed effect model reveals a reliable correlation between surprisal and reading time. We conclude that surprisal is positively related to the processing effort (i.e. reading time), confirming the surprisal hypothesis."
Deep Learning–based Number Detection and Recognition for Gas Meter Reading,2019,"['Gas meter?reading system', 'Computer vision', 'Image processing', 'Convolutional neural network']",,"The meter reading.system field has been researched from conventional methods centered on image processing technology to techniques based on learning methods such as machine learning or deep learning. The biggest problem for meter reading systems based on computer vision is difficulty in recognizing the various kinds of meters. In fact, there are more than five major manufacturers for the meters installed in Korea. There are different meter reading areas, ID regions, and number formats by version. Because of these problems, most of the meter reading is still done hands-on. In this paper, we present an automatic meter.reading system that can work simply and efficiently, compared to existing meter reading systems that need a skilled worker. Our meter reading system consists of three parts: i) detection of meter-reading and ID regions using You Only Look Once (YOLO), ii) digit segmentation for recognition, and iii) convolutional neural network (CNN)-based digit recognition. It is possible to robustly detect and recognize various meter types by using the method presented here. Therefore, it can provide an environment where gas meter checkers can work efficiently without inconvenient procedures."
A Hybrid Learning-based Predictive Process Planning Mechanism for Cyber-Physical Production Systems,2019,"['Cyber-physical production systems (사이버-물리 생산시스템)', 'Self-learning factory (자가학습 공장)', 'Machine learning (기계학습)', 'Transfer learning (전이학습)', 'Holonic manufacturing systems (홀로닉 제조시스템)', 'Process planning (공정계획)']",,
Towards cross-platform interoperability for machine-assisted text annotation,2019,"['annotation software', 'biomedical text mining', 'interoperability']",,"In this paper, we investigate cross-platform interoperability for natural language processing (NLP) and, in particular, annotation of textual resources, with an eye toward identifying the design elements of annotation models and processes that are particularly problematic for, or amenable to, enabling seamless communication across different platforms. The study is conducted in the context of a specific annotation methodology, namely machine-assisted interactive annotation (also known as human-in-the-loop annotation). This methodology requires the ability to freely combine resources from different document repositories, access a wide array of NLP tools that automatically annotate corpora for various linguistic phenomena, and use a sophisticated annotation editor that enables interactive manual annotation coupled with on-the-fly machine learning. We consider three independently developed platforms, each of which utilizes a different model for representing annotations over text, and each of which performs a different role in the process."
Pigeon Inspired Optimization of Bayesian Network Structure Learning and a Comparative Evaluation,2019,"['Bayesian network', 'structure learning', 'pigeon inspired optimization', 'global search', 'local search', 'search and score.']",,"Bayesian networks are useful analytical models for designing the structure of knowledge in machine learning. Probabilistic dependency relationships among the variables can be represented by Bayesian networks. One strategy of a structure learning Bayesian Networks is the score and search technique. In this paper, we present a new method for structure learning of the Bayesian network which is based on Pigeon Inspired Optimization (PIO) Algorithm. The proposed algorithm is a simple one with fast convergence rate. In nature, the navigational ability of pigeons is unbelievable and highly impressive. In accordance with the PIO search algorithm, a set of directed acyclic graphs is defined. Every graph owns a score which shows its fitness. The algorithm is iterated until it gets the best solution or a satisfactory network structure using map and compass, and landmark operator. In this work, the proposed method compared with Simulated Annealing, Bee optimization and Simulated Annealing as a hybrid algorithm, Bee optimization and Greedy search as a hybrid algorithm, and Greedy Search using BDeu score function. We also investigated the confusion matrix performances of the methods. The paper presents the results of extensive evaluations of these algorithms based on common benchmark data sets. The results indicate that the proposed algorithm has better performance than the other algorithms and produces higher scores and accuracy values."
Towards cross-platform interoperability for machine-assisted text annotation,2019,"['annotation software', 'biomedical text mining', 'interoperability']",,"In this paper, we investigate cross-platform interoperability for natural language processing (NLP) and, in particular, annotation of textual resources, with an eye toward identifying the design elements of annotation models and processes that are particularly problematic for, or amenable to, enabling seamless communication across different platforms. The study is conducted in the context of a specific annotation methodology, namely machine-assisted interactive annotation (also known as human-in-the-loop annotation). This methodology requires the ability to freely combine resources from different document repositories, access a wide array of NLP tools that automatically annotate corpora for various linguistic phenomena, and use a sophisticated annotation editor that enables interactive manual annotation coupled with on-the-fly machine learning. We consider three independently developed platforms, each of which utilizes a different model for representing annotations over text, and each of which performs a different role in the process."
Real-time quality monitoring and control system using an integrated cost effective support vector machine,2019,"['Cost effectiveness', 'Cost of quality', 'Machine learning', 'Quality control', 'SVM']",,"The quality monitoring and control (QMC) has been an essential process in the manufacturing industries. With the advancements in data analytics, machine-learning based QMC has become popular in various manufacturing industries. At the same time, the cost effectiveness (CE) of the QMC is perceived as a main decision criterion that explicitly accounts for inspection efforts and has a direct relationship with the QMC capability. In this paper, the cost-effective support vector machine (CESVM)-based automated QMC system (QMCS) is proposed. Unlike existing models, the proposed CESVM explicitly incorporates inspection-related expenses and error types in the SVM algorithm. The proposed automated QMCS is verified and validated using an automotive door-trim manufacturing process.Next, we perform a design of experiment to assess the sensitivity analysis of the proposed framework. The proposed model is found to be effective and could be viewed as an alternative or complementary tool for the traditional quality inspection system."
Structural Damage Detection using Deep Convolutional Neural Network and Transfer Learning,2019,"['hydro-junction infrastructure', 'damage detection', 'deep convolutional neural network', 'transfer learning', 'structural health monitoring', 'concrete surface defect']",,"During the long-term operation of hydro-junction infrastructure, water flow erosion causes concrete surfaces to crack, resulting in seepage, spalling, and rebar exposure. To ensure infrastructure safety, detecting such damage is critical. We propose a highly accurate damage detection method using a deep convolutional neural network with transfer learning. First, we collectedimages from hydro-junction infrastructure using a high-definition camera. Second, we preprocessed the images using an imageexpansion method. Finally, we modified the structure of Inception-v3 and trained the network using transfer learning to detectdamage. The experiments show that the accuracy of the proposed damage detection method is 96.8%, considerably higher thanthe accuracy of a support vector machine. The results demonstrate that our damage detection method achieves better damagedetection performance."
Deep Learning in MR Image Processing,2019,"['Deep learning', 'Machine learning', 'Image processing']",,"Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
Deep Learning in MR Image Processing,2019,"['Deep learning', 'Machine learning', 'Image processing']",,"Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
Deep Learning and Linguistics: Language & Translation Education Measures,2019,"['딥 러닝', '언어', '번역', '인공 지능', '4차 산업혁명', 'Deep Learning', 'language', 'translation', 'Artificial intelligence', 'The fourth industrial revolution']",,"The fourth industrial revolution is on hyperconnectivity. Hyper connectivity refers to connection between men, between men and system, and between systems, and artificial intelligence takes the role of intermediation. Artificial intelligence is completed based on the artificial part that is computer and robot, and intellectual part that is mathematics and linguistics. Deep learning that learns by itself by emulating the structure of neural network of human; as humans use five senses to receive information, self-learning deep learning takes information from visual stimulation. Recent artificial neural network machine translation technology is gradually minimizing translation errors. On the other hand, to such rapid development of language and translation, the school s education is not keeping up with the pace. For this reason, it is obvious that it is the time to seriously think through about the language education and conduct studies. In addition, in regards to language and translation issues, in the machine translation era, translators should be able to offer translation total service that professionally handles not only translation but pre-editing and post-editing to minimize errors of machine translation."
최적 기상 데이터 및 관측소 선정을 활용한 Gradient Boosting Machine 기반의 전력수요 예측 알고리즘 개발,2019,"['Gradient boosting machine', 'Short-term demand forecasting', 'Support vector machine']",,"We predict electricity demand in a very high accuracy with various machine learning algorithms by designing optimal combinations of weather data, stations, and years. First, we create a novel forecasting structure by taking advantage of stair-wise structure of predicted weather data to increase the forecasting accuracy. Second, we test various machine learning algorithms : ridge regression, support vector machine, and gradient boosting machine (GBM). We find that the GBM has the best forecasting accuracy. Third, we select weather data, years of data, and weather stations based on root mean square errors. We also choose the weather stations by identifying a correlation between weather data and demand to compare two station-selecting methods. Accordingly, we increase the computation speed and forecasting accuracy by filtering out unrelated data. Finally, we verify our proposed algorithm by participating in the 2018 world electricity demand forecasting competition held in France."
Application of Deep Learning System into the Development of Communication Device for Quadriplegic Patient,2019,"['Eye', 'Artificial intelligence', 'Unsupervised machine learning', 'Quadriplegia', 'Caregiver']",,"ObjectiveIn general, quadriplegic patients use their voices to call the caregiver. However, severe quadriplegic patients are in a state of tracheostomy, and cannot generate a voice. These patients require other communication tools to call caregivers. Recently, monitoring of eye status using artificial intelligence (AI) has been widely used in various fields. We made eye status monitoring system using deep learning, and developed a communication system for quadriplegic patients can call the caregiver.MethodsThe communication system consists of 3 programs. The first program was developed for automatic capturing of eye images from the face using a webcam. It continuously captured and stored 15 eye images per second. Secondly, the captured eye images were evaluated for open or closed status by deep learning, which is a type of AI. Google TensorFlow was used as a machine learning tool or library for convolutional neural network. A total of 18,000 images were used to train deep learning system. Finally, the program was developed to utter a sound when the left eye was closed for 3 seconds.ResultsThe test accuracy of eye status was 98.7%. In practice, when the quadriplegic patient looked at the webcam and closed his left eye for 3 seconds, the sound for calling a caregiver was generated.ConclusionOur eye status detection software using AI is very accurate, and the calling system for the quadriplegic patient was satisfactory."
A Study on the Effectiveness of Machine Translators for University Freshmen in Translating Korean Writing into English,2019,"['university freshmen composition', 'machine translators', 'essential English course', 'descriptive writing', 'learning tool', '교양필수영어', '서술적 글쓰기', '기계번역기', '학습도구', '대학생 영작문']","본 연구는 대학교 신입생들이 수강하는 교양 필수 영어 교과목에서 서술적 영어 글쓰기를 연습할 때 번역기의 사용 시기와 방법이 영어 작문에 미치는 효과에 대해 주요하게 탐구되었다. 이 연구는 2018년 가을학기 총 15주에 걸쳐 진행되었다. 학습 도구로서의 기계번역기의 효과성을 살펴보기 위해 대학 신입생 17명을 대상으로 4개의 주제 쓰여진 총 1548개 한국어 문장을 두 가지 번역 방법으로 영작 하도록 했다. 첫 번째 영어 번역 방법은 한국어 작문을 한 뒤, 사전을 이용해서 영작한 뒤 번역기를 사용해서 영어 작문을 완성하는 세 단계 번역과정의 절차를 거쳤고, 두 번째 방법은 한국어로 작문한 다음 바로 번역기를 사용해서 자신의 서술적 글쓰기를 영작하도록 했다. 본 연구에서는 두 가지 영작 방법 중 어떤 방법이 학생들 영어 작문에 더 효과적인지를 연구하였다. 또한, 학생들이 영어로 작문할 때 번역기를 학습 도구로 사용했을 때 유용했는지에 대해 의견을 조사하였다. 두 가지 영작 방법의 효과성을 비교하기 위해 실시한 대응표본 t 검정 결과는 p=0.026로 나타났다. 두 단계 과정을 거친 영작문 학습이 세 단계 과정을 거친 영작문 학습보다 영작문의 정확도가 유의미한 효과가 있음을 보여주었다. 이 연구 결과는 영작을 하기 위해 긴 글쓰기 과정이 학생들의 영작에 큰 도움이 되지 않았다는 것을 시사한다. 또한 학생들의 설문조사에 따르면 기계번역기를 학습 도구로 사용해서 영작했을 때 총 17명의 학생 중 13명 (76.5%)이 풍부한 어휘, 정확한 문장구조, 심리적인 안정감등에 도움이 되었다는 의견을 제시했다. 또한, 52.9%의 학생이 영어 작문할 때 불안감과, 부담이 감소되었다고 하였다. 그러나 단지 29.4% 학생들만 기계번역기의 정확도를 신뢰할 수 있다고 하였다. 따라서 대학 신입생들이 더 많은 영어 학습을 통해 영어 능력을 향상시키고 영어에 대한 직관을 길렀을 때 글쓰기 학습 도구로서의 기계번역기 사용은 더욱 큰 가치를 발할 것으로 기대된다.","This research investigated the effectiveness of machine translators as learning tools by conducting a study using two writing processes involving 17 university freshmen, and their perceptions regarding it. This was done over 15 weeks during a fall semester in 2018 as part of their descriptive writing in the Essential English course. With the guidance of the researchers, the students used two methods when translating their Korean compositions into English. These compositions covered four topics and included 1,548 sentences. One method involved translation with the use of dictionaries first, then machine translators. The other utilized machine translators directly. The results of the paired t-test that covered both methods was p=0.017 (p<0.05). It showed that a longer translation process is not helpful in yielding a more accurate result. Furthermore, a survey showed that the use of a machine translator led to the students experiencing an improvement in their writing skills, with 76.5% of the respondents agreeing positively. However, only 29.4% of students were convinced that machine translators were reliable. These findings suggest that the students need to develop their English skills and level of intuition through further study in order for them to properly benefit from the use of machine translators"
An Extensive Review on Recent Deep Learning Applications,2019,"['Artificial Intelligence', 'Neural Networks', 'Machine learning', 'Deep Learning', 'Cars', 'Convolutional Neural Networks', 'IoT.']",,"Artificial Intelligence and its related technologies like Machine learning and deep learning are getting the momentum very fast in the recent days. The development of these technologies was very fast compared to other technologies. The usage of such technologies in research and other technologies was growing more and more. By the implementation of such technologies, the development of the gadgets and other applications which were already existed in the market are becoming more and more sophisticated and more human friendly for usage. The mobile phones are getting smarter and the utility of such devices are getting increased in a notable number. Now days, the people can be able to process the applications and other tasks very easily with the help of these advanced technologies. These technologies are getting more and more advanced as the artificial neural networks concept is using highly in these models. Hence, in the current paper, some of the important applications in which the deep learning and other related techniques and methods are being used today."
Modeling the compressive strength of high-strength concrete: An extreme learning approach,2019,"['High-strength concrete', 'Artificial neural network', 'Extreme learning machine', 'Compressive strength', 'Regression']",,"<P><B>Abstract</B></P>  <P>Compressive strength is a major and significant mechanical property of concrete which is considered as one of the important parameters in many design codes and standards. Early and accurate estimation of it can save in time and cost. In this study, extreme learning machine (ELM) was used to predict the compressive strength of high-strength concrete (HSC). ELM is a relatively new method for training artificial neural networks (ANN), showing good generalization performance and fast learning speed in many regression applications. ELM model was developed using 324 data records obtained from laboratory experiments. The compressive strength was modeled as a function of five input variables: water, cement, fine aggregate, coarse aggregate, and superplasticizer. The performance of the developed ELM model was compared with that of ANN model trained by using back propagation (BP) algorithm. The simulation results show that the proposed ELM model has a strong potential for predicting the compressive strength of HSC.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Extreme learning machine (ELM) was used to predict the compressive strength of High strength concrete. </LI> <LI>  The developed ELM model is compared with BP model. </LI> <LI>  The ELM model has good prediction accuracy and fast learning speed. </LI> <LI>  The results show the potential use of ELM for predicting the compressive strength. </LI> </UL> </P>"
Acoustic spectral imaging and transfer learning for reliable bearing fault diagnosis under variable speed conditions,2019,"['Acoustic emission signal', 'Spectrum imaging', 'Feature extraction and classification', 'Fault diagnosis', 'Convolution neural network', 'Transfer learning']",,"<P><B>Abstract</B></P>  <P>Incipient fault diagnosis of a bearing requires robust feature representation for an accurate condition-based monitoring system. Existing fault diagnosis schemes are mostly confined to manual features and traditional machine learning approaches such as artificial neural networks (ANN) and support vector machines (SVM). These handcrafted features require substantial human expertise and domain knowledge. In addition, these feature characteristics vary with the bearing’s rotational speed. Thus, such methods do not yield the best results under variable speed conditions. To address this issue, this paper presents a reliable fault diagnosis scheme based on acoustic spectral imaging (ASI) of acoustic emission (AE) signals as a precise health state. These health states are further utilized with transfer learning, which is a machine learning technique, which shares knowledge with convolutional neural networks (CNN) for accurate diagnosis under variable operating conditions. In ASI, the amplitudes of the spectral components of the windowed time-domain acoustic emission signal are transformed into spectrum imaging. ASI provides a visual representation of acoustic emission spectral features in images. This ensures enhanced spectral images for transfer learning (TL) testing and training, and thus provides a robust classifier technique with high diagnostic accuracy.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Feature characteristics vary with the bearing’s rotational speed. </LI> <LI>  This paper proposes a reliable fault diagnosis scheme based on acoustic spectral imaging (ASI) of acoustic emission signals. </LI> <LI>  ASI provides a visual representation of acoustic emission spectral features in images. </LI> <LI>  The proposed approach provides a robust classifier technique with high diagnostic accuracy. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
A Comparative Study of Alzheimer’s Disease Classification using Multiple Transfer Learning Models,2019,"['Alzheimer’s disease', 'CNN', 'MR images', 'Transfer learning.']",,"Over the past decade, researchers were able to solve complex medical problems as well as acquire deeper understanding of entire issue due to the availability of machine learning techniques, particularly predictive algorithms and automatic recognition of patterns in medical imaging. In this study, a technique called transfer learning has been utilized to classify Magnetic Resonance (MR) images by a pre-trained Convolutional Neural Network (CNN). Rather than training an entire model from scratch, transfer learning approach uses the CNN model by fine-tuning them, to classify MR images into Alzheimer’s disease (AD), mild cognitive impairment (MCI) and normal control (NC). The performance of this method has been evaluated over Alzheimer’s Disease Neuroimaging (ADNI) dataset by changing the learning rate of the model. Moreover, in this study, in order to demonstrate the transfer learning approach we utilize different pre-trained deep learning models such as GoogLeNet, VGG-16, AlexNet and ResNet-18, and compare their efficiency to classify AD. The overall classification accuracy resulted by GoogLeNet for training and testing was 99.84% and 98.25% respectively, which was exceptionally more than other models training and testing accuracies."
Deep Learning Based Tree Recognition rate improving Method for Elementary and Middle School Learning,2019,"['Machine Learning', 'Deep Learning', 'Convolutional Neural Network', 'CNN', 'Inception V3', 'Smart Device Education', '머신러닝', '딥러닝', '컨볼루션 신경망', '인셉션V3', '스마트기기교육']",,"The goal of this study is to propose an efficient model for recognizing and classifying tree images to measure the accuracy that can be applied to smart devices during class. From the 2009 revised textbook to the 2015 revised textbook, the learning objective to the fourth-grade science textbook of elementary schools was added to the plant recognition utilizing smart devices. In this study, we compared the recognition rates of trees before and after retraining using a pre-trained inception V3 model, which is the support of the Google Inception V3. In terms of tree recognition, it can distinguish several features, including shapes, bark, leaves, flowers, and fruits that may lead to the recognition rate. Furthermore, if all the leaves of trees may fall during winter, it may challenge to identify the type of tree, as only the bark of the tree will remain some leaves. Therefore, the effective tree classification model is presented through the combination of the images by tree type and the method of combining the model for the accuracy of each tree type. I hope that this model will apply to smart devices used in educational settings."
Deep Learning in Medical Imaging,2019,"['Artificial intelligence', 'Deep learning', 'Machine learning', 'Precision medicine', 'Radiology']",,"The artificial neural network (ANN), one of the machine learning (ML) algorithms, inspired by the human brain system, was developed by connecting layers with artificial neurons. However, due to the low computing power and insufficient learnable data, ANN has suffered from overfitting and vanishing gradient problems for training deep networks. The advancement of computing power with graphics processing units and the availability of large data acquisition, deep neural network outperforms human or other ML capabilities in computer vision and speech recognition tasks. These potentials are recently applied to healthcare problems, including computer-aided detection/diagnosis, disease prediction, image segmentation, image generation, etc. In this review article, we will explain the history, development, and applications in medical imaging"
Autonomous-Driving Vehicle Learning Environments using Unity Real-time Engine and End-to-End CNN Approach,2019,"['Autonomous Shuttle Vehicle', 'Artificial Intelligence', 'Virtual Environment', 'Behavior Learning']",,"Collecting a rich but meaningful training data plays a key role in machine learning and deep learning researches for a self-driving vehicle. This paper introduces a detailed overview of existing open-source simulators which could be used for training self-driving vehicles. After reviewing the simulators, we propose a new effective approach to make a synthetic autonomous vehicle simulation platform suitable for learning and training artificial intelligence algorithms. Specially, we develop a synthetic simulator with various realistic situations and weather conditions which make the autonomous shuttle to learn more realistic situations and handle some unexpected events. The virtual environment is the mimics of the activity of a genuine shuttle vehicle on a physical world. Instead of doing the whole experiment of training in the real physical world, scenarios in 3D virtual worlds are made to calculate the parameters and training the model. From the simulator, the user can obtain data for the various situation and utilize it for the training purpose. Flexible options are available to choose sensors, monitor the output and implement any autonomous driving algorithm. Finally, we verify the effectiveness of the developed simulator by implementing an end-to-end CNN algorithm for training a self-driving shuttle."
Robust appearance feature learning using pixel‐wise discrimination for visual tracking,2019,"['convolutional neural networks', 'detection', 'pixel‐wise feature learning', 'support vector machines', 'visual tracking']",,"Considering the high dimensions of video sequences, it is often challenging to acquire a sufficient dataset to train the tracking models. From this perspective, we propose to revisit the idea of hand‐crafted feature learning to avoid such a requirement from a dataset. The proposed tracking approach is composed of two phases, detection and tracking, according to how severely the appearance of a target changes. The detection phase addresses severe and rapid variations by learning a new appearance model that classifies the pixels into foreground (or target) and background. We further combine the raw pixel features of the color intensity and spatial location with convolutional feature activations for robust target representation. The tracking phase tracks a target by searching for frame regions where the best pixel‐level agreement to the model learned from the detection phase is achieved. Our two‐phase approach results in efficient and accurate tracking, outperforming recent methods in various challenging cases of target appearance changes."
Recurrent neural network-based semantic variational autoencoder for Sequence-to-sequence learning,2019,"['Sequence-to-sequence learning', 'Recurrent neural network', 'Auto-encoder', 'Variational method', 'Document information vector', 'Self attention mechanism', 'Natural language processing']",,"<P><B>Abstract</B></P>  <P>Sequence-to-sequence (Seq2seq) models have played an important role in the recent success of various natural language processing methods, such as machine translation, text summarization, and speech recognition. However, current Seq2seq models have trouble preserving global latent information from a long sequence of words. Variational autoencoder (VAE) alleviates this problem by learning a continuous semantic space of the input sentence. However, it does not solve the problem completely. In this paper, we propose a new recurrent neural network (RNN)-based Seq2seq model, RNN semantic variational autoencoder (RNN–SVAE), to better capture the global latent information of a sequence of words. To suitably reflect the meanings of words in a sentence regardless of their position within the sentence, we utilized two approaches: (1) constructing a document information vector based on the attention information between the final state of the encoder and every prior hidden state, and (2) extracting the semantic vector based on the self-attention mechanism. Then, the mean and standard deviation of the continuous semantic space are learned by using this vector to take advantage of the variational method. By using the document information vector and the self-attention mechanism to find the semantic space of the sentence, it becomes possible to better capture the global latent feature of the sentence. Experimental results of three natural language tasks (i.e., language modeling, missing word imputation, paraphrase identification) confirm that the proposed RNN–SVAE yields higher performance than two benchmark models.</P>"
Detection of Moving Direction using PIR Sensors and Deep Learning Algorithm,2019,"['Passive infrared', 'movement direction detection', 'deep learning', 'machine learning', 'convolutional neural network']",,"In this paper, we propose a method to recognize the moving direction in the indoor environment by using the sensing system equipped with passive infrared (PIR) sensors and a deep learning algorithm. A PIR sensor generates a signal that can be distinguished according to the direction of movement of the user. A sensing system with four PIR sensors deployed by 45° increments is developed and installed in the ceiling of the room. The PIR sensor signals from 6 users with 10-time experiments for 8 directions were collected. We extracted the raw data sets and performed experiments varying the number of sensors fed into the deep learning algorithm. The proposed sensing system using deep learning algorithm can recognize the users’ moving direction by 99.2 %. In addition, with only one PIR senor, the recognition accuracy reaches 98.4%."
Probabilistic Bloom Filter for Online Learning in Personalized Recommender Systems,2019,"['블룸 필터', '디케이', '임베딩', '온라인 러닝', '추천 시스템', 'Bloom Filter', 'Decay', 'Embedding', 'Online Learning', 'Recommender System']",,"Bloom filters are used as embeddings in machine learning domain because of its characteristic of remembering items with less storage. As to online learning, a specific kind of bloom filter is needed, which can prevent filters being full as new items appear by decay. We compared bloom filters which can decay in perspective of precision and the degree of preservation of similarities between items using dataset for personalized recommendation. We also suggested a new bloom filter named as 'probabilistic bloom filter', which has two advantages. First, it showed higher precision than other filters at the expense of similarities between items while overall performance was the second to 'stable bloom filter' when it comes to precision-similarity trade-off. Second, even in a long term, it ensures that filters are not full or empty without continuous parameter calibration."
Prediction of Compound-Protein Interactions Using Deep Learning,2019,"['기계 번역', '딥러닝', '신약 개발', '화합물-단백질 상호작용', '분류분석', 'Machine translation', 'deep learning', 'drug development', 'compound-protein interaction', 'classification']",,
Web access prediction based on parallel deep learning,2019,"['Apache Spark', 'Neural network', 'Parallel deep learning', 'Parameter tuning', 'Web access prediction', '아파치 스파크', '신경망', '병렬 딥러닝', '파라미터 튜닝', '웹 접근 예측']",,"Due to the exponential growth of access information on the web, the need for predicting web users’ next access has increased. Various models such as markov models, deep neural networks, support vector machines, and fuzzy inference models were proposed to handle web access prediction. For deep learning based on neural network models, training time on large-scale web usage data is very huge. To address this problem, deep neural network models are trained on cluster of computers in parallel. In this paper, we investigated impact of several important spark parameters related to data partitions, shuffling, compression, and locality (basic spark parameters) for training Multi-Layer Perceptron model on Spark standalone cluster. Then based on the investigation, we tuned basic spark parameters for training Multi-Layer Perceptron model and used it for tuning Spark when training Multi-Layer Perceptron model for web access prediction. Through experiments, we showed the accuracy of web access prediction based on our proposed web access prediction model. In addition, we also showed performance improvement in training time based on our spark basic parameters tuning for training Multi-Layer Perceptron model over default spark parameters configuration."
A Infectious Diseases Control Multi-Agent System using Artificial Intelligence Learning Algorithm,2019,"['멀티 에이전트 시스템', '반응성 아키텍처', 'BDI (Belief-Desire-Intention) 아키텍처', '머신 러닝', 'Multi-Agent System', 'Reactive Architecture', 'Belief-Desire-Intention (BDI) Architecture', 'Machine Learning']",,"Emerging infectious diseases have become a threat to humanity and it is still a challenging problem. Epidemiology is one of the important topics in health industry to be addressed to find fast solutions with different researches. Multi-Agent healthcare systems provide considerable solutions but such systems are not properly developed for control infectious diseases. In this dissertation, we propose a multi-agent system for control infectious diseases with extended capabilities for identify and remove infected people from a population. This system prevents an infected person to be in a population by predicting and identifying them so that further spreading of the infectious diseases can be greatly reduced. The goal of this work is to improve the quality of service in healthcare and to protect healthy people from epidemics."
Knowledge Base Associated with Autism Construction Using CRFs Learning,2019,"['Autism', 'Biological Molecular', 'Conditional Random Fields', 'Knowledge Base']",,"Knowledge base means a library stored in computer system providing useful information or appropriate solutions to specific area. Knowledge base associated with autism is the complex multidimensional information set related to the disease autism for its pathogenic factor and therapy. This paper focuses on the knowledge of biological molecular information extracted from massive biomedical texts with the aid of widespread used machine learning methods. Six classes of biological molecular information (such as protein, DNA, RNA, cell line, cell component, and cell type) are concerned and the probability statistics method, conditional random fields (CRFs), is utilized to discover these knowledges in this work. The knowledge base can help biologists to etiological analysis and pharmacists to drug development, which can at least answer four questions in question-answering (QA) system, i.e., which proteins are most related to the disease autism, which DNAs play important role to the development of autism, which cell types have the correlation to autism and which cell components participate the process to autism. The work can be visited by the address http://134.175.110.97/bioinfo/index.jsp."
A Infectious Diseases Control Multi-Agent System using Artificial Intelligence Learning Algorithm,2019,"['멀티 에이전트 시스템', '반응성 아키텍처', 'BDI (Belief-Desire-Intention) 아키텍처', '머신 러닝', 'Multi-Agent System', 'Reactive Architecture', 'Belief-Desire-Intention (BDI) Architecture', 'Machine Learning']",,
Modelling the Torque with Artificial Neural Networks on a Tunnel Boring Machine,2019,"['artificial neural networks', 'tunnelling', 'TBM', 'EPB', 'foam']",,"The performance of earth pressure balanced tunnel boring machines (EPB-TBM) is dependent of a variety of parameters. Moreover, these parameters interact in a rather challenging way, making it difficult to adequately model their behaviour. Artificial neural networks have the aptitude to model complex problems and have been used in a variety of construction engineering problems. They can learn from existing data and then be used to predict the results, which makes them adequate for modelling problems where large amount of data is generated. In this work, a multilayer feedforward artificial neural network has been used to predict the torque at the cutter head of an EPB-TBM. A time series neural network has been used, where torque was predicted as a function of the measured torque and the volume of the injected foam on previous time steps. Results indicate that feedforward artificial neural network can be used to predict the torque at the cutter head in a EPB-TBM"
머신러닝에 관한 OSS 라이선스 연구,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'Open Source Software', 'License', 'Open Source License', 'Apache License', 'Copyright', '인공지능', '머신러닝', '딥러닝', '텐서플로', '오픈소스 소트웨어', '라이선스', '오픈소스 라이선스', '아파치 라이선스', '저작권']","인공지능에 관한 산업적 관심이 높아지고 시장이 확대되면서 국내에서 인공지능에 관한 컴퓨터프로그램(이하 “프로그램”이라 한다)의 활용이 점차 확대되고 있다. 인공 지능을 구현하기 위해 머신러닝 기술이 활용되는데, 이 분야의 주요한 머신러닝 관련 프로그램으로 TensorFlow를 비롯하여 scikit-learn, Machine Learning Library (MLlib), Weka 3 등이 있다. 그리고 이것들에는 오픈소스 라이선스인 Apache License v.2.0, MIT License 및 New BSD License(3-Clause BSD License)이 적용되었다. 특히, Apache License v.2.0에 관하여서는 국제적으로 높은 사용률을 보이면서도 국내에 참고문헌이 많지 않다. 그리고 프로그램의 법적 문제는 이것에 적용된 라이선스의 해석에 기초해 야 하므로, 적용된 라이선스들의 구체적인 해석이 필요하다. 그렇지만 관련 산업에서 오픈소스 소프트웨어에 대한 법적 문제의식은 상당히 낮은 상황이다. 따라서 오픈소 스 소프트웨어에 적용된 라이선스들에 대한 법적 해석론을 제시함에 의해 관련 산업 에서의 잠재적인 법적 문제들을 해결할 수 있을 것이다. 그래서 이 논문은 머신러닝 에 관한 오픈소스 소프트웨어에 적용된 오픈소스 라이선스들에 대해 간략히 살펴보 고, 라이선스에 사용된 중요한 용어들을 검토한 후에, 라이선스의 주요한 법적 문제들 을 검토하다. Apache License v.2.0, MIT License 및 New BSD License는 퍼미시브 라이선스이고, 이 중 Apache License v.2.0은 정의, 저작권, 특허, 상표 등을 포함하여 상당히 구체적으로 규 정되어 있다. 그리고 라이선시는 재배포 시에 라이선스를 함께 배포하고, 저작권 외에도 특허권, 상표권 등에 관하여 고려해야 한다. 그런데 이 라이선스는 오픈소스 이니셔티브 의 오픈소스의 정의에 부합하도록 정의되어 있으면서, 퍼미시브 라이선스로 오픈소스 소프트웨어의 이용자 측면에서 비교적 유연한 내용들을 포함한다. 예를 들어 TensorFlow 와 같이 이 라이선스가 적용된 프로그램의 변경물이나 2차적저작물의 일부 또는 전체에 추가적인 또는 별도의 라이선스 규정 및 조건을 부여할 수 있다. 다만, 카피레프트 조항 을 포함하는 라이선스와의 양립성의 문제는 카피레프트 라이선스로의 일방적인 통합을 의미한다. 결론적으로, Apache License v.2.0은 개발자나 사업자의 관점에서는 다양한 선택지를 갖도록 한다. 그렇지만 오픈소스 라이선스가 적용된 머신러닝 관련 프로그램들을 이용할 때 라 이선스와 관련한 사안들에 유의해야 할 필요가 있다. 우선, 조합저작물 또는 2차적저 작물에 대해 권리 및 귀속 고지의 의무를 반드시 준수해야 한다. 그리고 작은 분량의 프로그램도 저작권이 있을 수 있으므로 권리 및 귀속에 관한 고지를 소스 형태 내에 반드시 포함시키도록 한다. 또한 머신러닝 관련 프로그램들을 조합하거나 이 프로그 램을 다른 프로그램에 포함시키는 경우에 라이선스 간의 양립성 문제가 발생할 수 있 으므로, 라이선스의 양립성에 대해 유의해야 한다. 이에 더해 라이선시는 머신러닝에 관한 오픈소스 소프트웨어를 활용하여 발명을 하고 이것에 대해 특허를 취득한 경우 에, 특허 소송에 대한 보복조항이 있을 수 있고 없더라도 묵시적 실시허락이 인정될 수 있으므로, 특허 소송은 신중하게 접근할 필요가 있다.","As the industrial interest on artificial intelligence(AI) increases and the market related to AI expands, the application of computer programs on AI is gradually expanding in Korea. Machine learning technology is used to implement AI, and major machine learning programs in this field include scikit-learn, Machine Learning Library (MLlib), and Weka 3 in addition to TensorFlow, which are covered by the Apache License v.2.0, MIT License and New BSD License(3-Clause BSD License). In particular, Apache License v.2.0 has a high usage rate internationally, but there are not many references in the country. And the copyright issue of the program must be based on the interpretation of the license applied to it, so a specific interpretation of the applied licenses is necessary. However, legal awareness of open source software (OSS) in the related industry is very low. Therefore, we expect to be able to solve the potential legal problems in the related industry by presenting the legal interpretation related to the licenses applied to the OSS. So, this paper briefly reviews the open source licenses applied to OSS for machine learning, reviews the key terms used in the licenses, and then reviews the major legal issues of the licenses. The Apache License v.2.0, MIT License, and New BSD License are Permissive licenses, of which the Apache License v.2.0 was prescribed in considerable detail, including definitions, copyright, patent, and trademark. And Licensee shall distribute the Licenses at the time of redistribution and take into account patents, trademarks, etc. in addition to copyrights. However, this license is defined to conform to Open Source Initiative’s open source definition, and it also includes relatively flexible content in terms of users of the OSS as a permissive license. For example, Licensee of programs such as TensorFlow may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole under certain conditions. However, the issue of compatibility with licenses including copyleft terms implies a one way integration into copyleft licenses. In conclusion, the Apache license v.2.0 allows a wide variety of choices from the developer or business perspective. Nevertheless, you need to be aware of issues related to OSS licenses when using programs licensed by OSS licenses. First of all, you shall comply with the obligations of the rights and attribution notices for the combined or Derivative works. And a small amount of programs can be copyrighted, so you shall be sure to include notices of rights and attribution in the source form. In addition, compatibility between licenses may occur when combining machine learning-related programs or including them in other programs, so you shall be careful about licenses’ compatibility. In addition, if a licensee invents and patents using an open source software related to machine learning, patent litigation needs to be taken with caution, as there may be retaliation provision for patent litigation and implied licenses may be admitted."
머신러닝 및 딥러닝 연구동향 분석: 토픽모델링을 중심으로,2019,"['Machine Learning', 'Deep Learning', 'Artificial Neural Network', 'Text Mining']",,"The purpose of this study is to examine the trends on machine learning and deep learning research in the published journals from the Web of Science Database. To achieve the study purpose, we used the abstracts of 20,664 articles published between 1990 and 2017, which include the word 'machine learning', 'deep learning', and 'artificial neural network' in their titles. Twenty major research topics were identified from topic modeling analysis and they were inclusive of classification accuracy, machine learning, optimization problem, time series model, temperature flow, engine variable, neuron layer, spectrum sample, image feature, strength property, extreme machine learning, control system, energy power, cancer patient, descriptor compound, fault diagnosis, soil map, concentration removal, protein gene, and job problem. The analysis of the time-series linear regression showed that all identified topics in machine learning research were 'hot' ones."
수문학적 활용을 위한 머신러닝 기반의 강우보정기술 개발,2019,"['Heavy rainfall', 'Machine learning', 'Rainfall correction', 'LightGBM', 'XGBoost']",,"For the purposes of enhancing usability of Numerical Weather Prediction (NWP), the quantitative precipitation prediction scheme by machine learning has been proposed. In this study, heavy rainfall was corrected for by utilizing rainfall predictors from LENS and Radar from 2017 to 2018, as well as machine learning tools LightGBM and XGBoost. The results were analyzed using Mean Absolute Error (MAE), Normalized Peak Error (NPE), and Peak Timing Error (PTE) for rainfall corrected through machine learning. Machine learning results (i.e. using LightGBM and XGBoost) showed improvements in the overall correction of rainfall and maximum rainfall compared to LENS. For example, the MAE of case 5 was found to be 24.252 using LENS, 11.564 using LightGBM, and 11.693 using XGBoost, showing excellent error improvement in machine learning results. This rainfall correction technique can provide hydrologically meaningful rainfall information such as predictions of flooding. Future research on the interpretation of various hydrologic processes using machine learning is necessary."
머신러닝을 이용한 신경계통의 질환 퇴원환자의 중증도 보정 재원일수 예측 모형 개발,2019,"['재원일수', '신경계통의 질환', '동반상병 보정', '머신러닝', '중증도 보정 예측 모형', 'Length of Stay', 'Diseases of the Nervous System', 'Comorbidity Index', 'Machine Learning', 'Severity-Adjusted Predictive Model']","본 연구는 머신러닝을 이용하여 동반상병 보정 방법에 따른 중증도 보정 재원일수 예측 모형을 개발하고 이를 평가하여 중증도 보정 재원일수 예측 모형 개발의 알고리즘을 제시하기 위해 수행되었다. 본 연구를 위해 2006년부터 2015년까지 10년간의 질병관리본부 퇴원손상심층조사 자료를 수집하였으며, 재원일수 관리가 시급한 신경계통의 질환을 대상으로 중증도 보정 재원일수 예측 모형을 개발하였다. 신경계통의 질환 퇴원환자의 중증도 보정 재원일수 예측 모형 개발 시 동반상병 보정 방법은 CCI, ECI, CCS 진단군 분류 기준 등 3가지, 머신러닝 분석기법으로는 회귀분석, 의사결정나무, 랜덤 포레스트, 서포트 백터 회귀분석, 신경망 등 5가지를 적용하여 모형을 개발하고 개발된 모형을 평가하였다. 모형 평가 결과 CCS 진단군 분류 기준 동반상병 보정 방법 및 신경망을 이용하여 개발한 중증도 보정 예측 모형의 모형 설명력(R-square)이 가장 높았으며, 모형의 예측력이 가장 우수한 것으로 나타났다. 따라서 중증도 보정 재원일수 예측 모형 개발 시 CCS 진단군 분류 변수를 이용한 동반상병 보정 방법을 이용하여 중증도 보정 예측 모형을 개발하는 것이 필요하며, 머신러닝의 다양한 분석 기법 등을 이용하여 예측력 높은 중증도 보정 예측 모형을 개발하여 재원일수 변이요인 파악 등 재원일수 관리를 위해 활용하는 것이 필요하다.","This study aims to develop a severity-adjusted length of stay predictive model according to comorbidity index by using machine learning and propose a algorithm of severity-adjusted length of stay (LOS) predictive model. The dataset was taken from Korea Centers for Disease Control and Prevention database of the hospital discharge survey from 2006 to 2015 and the severity-adjusted length of stay predictive model was developed for the nervous system patients to need a urgent management for length of stay. when it comes to the severity-adjusted length of stay predictive model about nervous system discharging patients, three tools were used for the severity-adjustment of comorbidity: the CCI, the ECI, and the CCS. The models using Regression, Decision Tree, Random Forest, Support Vector Regression, Neural Network as a Machine learning analysis methods were developed and then evaluate. As a result, Severity-adjusted predictive model using CCS as the severity-adjustment of comorbidity and Neural Network method has the highest R-square and has the most excellent prediction capability. In conclusion, there is a need to develop a severity-adjusted predictive model using CCS as the severity-adjustment of comorbidity and make use of severity-adjusted predictive model to has high prediction capability by using various machine-learning analytics."
머신러닝 기법의 산림 총일차생산성 예측 모델 비교,2019,"['Machine learning', 'Gross primary production', 'MODIS', 'GPP modeling', 'Eddy covariance', 'KoFlux']","산림생태계에서 총일차생산성(Gross Primary Production, GPP)은 기후변화에 따른 산림의 생산성과 그에 영향을 미치는 식물계절, 건강성, 탄소 순환 등을 대표하는 지표이다. 총일차생산성을 추정하기 위해서는 에디공분산 타워 자료나 위성영상관측자료를 이용하기도 하고 물리지형적 한계나 기후변화 등을 고려하기 위해 기작기반모델링을 활용하기도 한다. 그러나 총일차생산성을 포함한 산림 탄소 순환의 기작기반 모델링은 식물의 생물, 생리, 화학적 기작들의 반응과 지형, 기후 및 시간 등과 같은 환경 조건들이 복잡하게 얽혀 있어 비선형적이고 유연성이 떨어져 반응에 영향을 주는 조건들을 모두 적용하기가 어렵다. 본 연구에서는 산림 생산성 추정 모델을 에디공분산 자료와 인공위성영상 정보를 사용하여 기계학습 알고리즘을 사용한 모델들로 구축해 보고 그 사용 및 확장 가능성을 검토해 보고자 하였다. 설명변수들로는 에디공분산자료와 인공위성자료에서 나온 대기기상인자들을 사용하였고 검증자료로 에디공분산 타워에서 관측된 총일차생산성을 사용하였다. 산림생산성 추정 모델은 1) 에디공분산 관측 기온(Tair), 태양복사(Rd), 상대습도(RH), 강수(PPT), 증발산(ET) 자료, 2) MODIS 관측기온(T), 일사량(Rsd), VPD 자료(개량식생지수 제외), 3) MODIS 관측 기온(T), 일사량(Rsd), VPD, 개량식생지수(EVI) 자료를 사용하는 세 가지 경우로 나누어 구축하여 2006 – 2013년 자료로 훈련시키고 2014, 2015년 자료로 검증하였다. 기계학습 알고리즘은 support vector machine (SVM), random forest (RF), artificial neural network (ANN)를 사용하였고 단순비교를 위해 고전적 방법인 multiple linear regression model (LM)을 사용하였다. 그 결과, 에디공분산 입력자료로 훈련시킨 모델의 예측력은 피어슨 상관계수 0.89 – 0.92 (MSE = 1.24 – 1.62), MODIS 입력자료로 훈련시킨 모델의 예측력은 개량식생지수 제외된 모델은 0.82 – 0.86 (MSE = 1.99 – 2.45), 개량식생지수가 포함된 모델은 0.92 – 0.93(MSE = 1.00 – 1.24)을 보였다. 이러한 결과는 산림총일차생산성 추정 모델 구축에 있어 MODIS인공위성 영상 정보 기반으로 기계학습 알고리즘을 사용하는 것에 대한 높은 활용가능성을 보여주었다.","Terrestrial Gross Primary Production (GPP) is the largest global carbon flux, and forest ecosystems are important because of the ability to store much more significant amounts of carbon than other terrestrial ecosystems. There have been several attempts to estimate GPP using mechanism-based models. However, mechanism-based models including biological, chemical, and physical processes are limited due to a lack of flexibility in predicting non-stationary ecological processes, which are caused by a local and global change. Instead mechanism-free methods are strongly recommended to estimate nonlinear dynamics that occur in nature like GPP. Therefore, we used the mechanism-free machine learning techniques to estimate the daily GPP. In this study, support vector machine (SVM), random forest (RF) and artificial neural network (ANN) were used and compared with the traditional multiple linear regression model (LM). MODIS products and meteorological parameters from eddy covariance data were employed to train the machine learning and LM models from 2006 to 2013. GPP prediction models were compared with daily GPP from eddy covariance measurement in a deciduous forest in South Korea in 2014 and 2015. Statistical analysis including correlation coefficient (R), root mean square error (RMSE) and mean squared error (MSE) were used to evaluate the performance of models. In general, the models from machine-learning algorithms (R = 0.85 – 0.93, MSE = 1.00 – 2.05, p < 0.001) showed better performance than linear regression model (R = 0.82 – 0.92, MSE = 1.24 – 2.45, p < 0.001). These results provide insight into high predictability and the possibility of expansion through the use of the mechanism-free machine-learning models and remote sensing for predicting non-stationary ecological processes such as seasonal GPP."
머신러닝을 활용한 개인의 교통수단 선택 예측모형 구축,2019,"['Machine learning', 'prediction model', 'support vector machine', 'travel mode', '교통수단 선택', '머신러닝', '서포트 벡터 머신', '예측모형']","교통수단 선택을 예측하는 것은 해당 지역의 교통 관련 정책 수립에 있어서 중요하기 때문에, 이와 관련된 연구는 과거부터 많이 진행되어 왔다. 해외에서는 다양한 머신러닝 기법을 적용하여 개인의 교통수단 선택을 예측하는 연구가 활발히 진행된 반면, 우리나라에서는 아직까지 이러한 연구가 부족한 상황이다. 따라서 본 연구에서는 2016년 서울시 가구통행실태조사 데이터를 바탕으로 다항로짓모형, 의사결정나무, 서포트 벡터 머신의 세 가지 머신러닝 기법을 적용하고, 최적의 예측모형을 도출하고자 하였다. 각 모형의 예측 결과는 혼동행렬을 통해 검증하였으며, 서포트 벡터 머신, 다항로짓모형, 의사결정나무 순으로 높은 예측 정확도를 나타냈다. 이러한 개인의 교통수단 선택 예측모형은 교통 정책의 확대와 의사결정 과정에도 기여할 수 있을 것으로 기대된다.","A reliable prediction of individual travel mode choices is an important factor for implementing transportation polices, because it is directly related to the demand for transport services and infrastructure. While machine learning methods have become increasingly popular in this field, it is not widely applied in the Korea context. In this paper, we attempt to develop a model that can predict individual travel mode choices by comparing three different machine learning techniques, multinomial logistic regression, decision tree and support vector machine. The performance of the prediction models is evaluated using a confusion matrix, and the results show that the model developed by support vector machine performs better than other methods. Our analysis can contribute to the expansion of transportation policies and support management decision-making."
머신러닝을 이용한 에너지 선택적 유방촬영의 진단 정확도 향상에 관한 연구,2019,"['Machine learning', 'Digital mammography', 'Dual-energy', 'Classification', 'Tumor thickness', '머신러닝', '디지털 유방촬영', '이중에너지', '분류', '종양 두께']",,"Although digital mammography is a representative method for breast cancer detection. It has a limitation in detecting and classifying breast tumor due to superimposed structures. Machine learning, which is a part of artificial intelligence fields, is a method for analysing a large amount of data using complex algorithms, recognizing patterns and making prediction. In this study, we proposed a technique to improve the diagnostic accuracy of energy-selective mammography by training data using the machine learning algorithm and using dual-energy measurements. A dual-energy images obtained from a photon-counting detector were used for the input data of machine learning algorithms, and we analyzed the accuracy of predicted tumor thickness for verifying the machine learning algorithms. The results showed that the classification accuracy of tumor thickness was above 95% and was improved with an increase of imput data.Therefore, we expect that the diagnostic accuracy of energy-selective mammography can be improved by using machine learning."
머신러닝을 위한 불균형 데이터 처리 방법 : 샘플링을 위주로,2019,"['불균형데이터', '머신러닝', '언더샘플링', '오버샘플링', '이상탐지', 'Imbalance Data', 'Machine Learning', 'Under Sampling', 'Over Sampling', 'Anomaly Detection']","최근 학계, 산업계 등에서 접하는 기존의 문제를 머신러닝을 통해 해결하려는 시도가 증가하고 있다. 이에 따라 이탈, 사기탐지, 장애탐지 등 일반적이지 않은 상황을 머신러닝으로 해결하기 위한 다양한 연구가 이어지고 있다. 대부분의 일반적이지 않은 환경에서는 데이터가 불균형하게 분포하며, 이러한 불균형한 데이터는 머신러닝의 수행과정에서 오류를 야기하므로 이를 해결하기 위한 불균형 데이터 처리 기법이 필요하다. 본 논문에서는 머신러닝을 위한 불균형 데이터 처리 방법을 제안한다. 제안하는 방법은 샘플링 방법을 중심으로 다수 클래스(Major Class)의 모집단 분포를 효율적으로 추출하도록 검증하여 머신 러닝을 위한 불균형 데이터 문제를 해결한다. 본 논문에서는 성능평가를 통해 제안하는 기법이 기존 기법에 비해 성능이 우수함을 보인다.","Recently, more and more attempts have been made to solve the problems faced by academia and industry through machine learning. Accordingly, various attempts are being made to solve non-general situations through machine learning, such as deviance, fraud detection and disability detection. A variety of attempts have been made to resolve the non-normal situation in which data is distributed disproportionately, generally resulting in errors. In this paper, we propose handling method of imbalance data for machine learning. The proposed method to such problem of an imbalance in data by verifying that the population distribution of major class is well extracted. Performance Evaluations have proven the proposed method to be better than the existing methods."
텐서플로우 튜토리얼 방식의 머신러닝 신규 모델 개발 : 캐글 타이타닉 데이터 셋을 중심으로,2019,"['Machine learning', 'Feature engineering', 'Data preprocessing', 'Data visualization', 'Tensorflow']",,"The purpose of this study is to develop a model that can systematically study the whole learning process of machine learning. Since the existing model describes the learning process with minimum coding, it can learn the progress of machine learning sequentially through the new model, and can visualize each process using the tensor flow. The new model used all of the existing model algorithms and confirmed the importance of the variables that affect the target variable, survival. The used to classification training data into training and verification, and to evaluate the performance of the model with test data. As a result of the final analysis, the ensemble techniques is the all tutorial model showed high performance, and the maximum performance of the model was improved by maximum 5.2% when compared with the existing model using. In future research, it is necessary to construct an environment in which machine learning can be learned regardless of the data preprocessing method and OS that can learn a model that is better than the existing performance."
UX 디자인 과정에서의 머신러닝 활용 방법,2019,"['UX 디자인', '머신러닝', '디자인 프로세스', '디자인 방법론', 'UX Design', 'Machine Learning', 'Design Process', 'Design Methodology']","본 연구는 아직 초기 단계의 논의에 그치고 있는 UX 디자인 과정에서의 머신러닝 활용 현황에 대해 고찰하고 향후 디자이너가 UX 디자인 과정에서 머신러닝을 활용할 수 있는 방식에 대해 논의하고자 한다. 본 연구는 머신러닝 기반의 제품 및 서비스를 위한 디자인 방법 연구와는 구별되는 것으로 머신러닝을 디자인 과정 속에 이용해서 디자이너가 얻을 수 있는 가치에 대한 논의에 목적을 둔다. 이를 위해 문헌연구와 사례조사를 통해 디자인 방법의 종류를 1) UX 디자인 중심 ML 융합, 2) ML 시스템 중심 UX융합, 그리고 3) UX-ML 매치메이킹 방법에 대해 정리하고 분석하였다. 이후 실제 워크숍에서 디자인 전공자들이 실질적으로 활용가능한 1)과 3)의 방법을 시행하면서 각 방법의 과정, 장단점을 세부적으로 파악하였고, 이를 통해 머신러닝을 UX 디자인 과정에 접목하는 구체적 방법을 제시하였다.","This paper investigates applicable methods of using machine learning(ML) in design process that is currently at infant stage and discuss how designers can use machine learning in UX design process. This research is differentiated from design method for machine learning-based products or services. For this purpose, this paper conducted literature reviews and case investigation and discussed three categories of design method of combination with such as 1) UX design centered ML, 2) ML system centered UX, and 3) UX-ML matchmaking. With this investigation, the workshop was conducted with specifically applicable methods of 2) and 3) for designers. Throughout the workshop, this paper analyzed each method’ process with pros and cons in details. Throughout the process, this paper suggests precise methods of applying ML into UX design process."
미세먼지의 영향을 고려한 머신러닝 기반태양광 발전량 예측,2019,"['머신러닝', '태양광 발전량 예측', '미세먼지', '서포트 벡터 머신', 'Machine learning', 'Photovoltaic power forecasting', 'Particulate matter', 'Support vector machine']","태양광 발전과 같은 신재생에너지의 불확실성은 전력계통의 유연성을 저해하며, 이를 방지하기 위해서는 정확한 발전량의 사전 예측이 중요하다. 본 연구는 미세먼지 농도를 포함한 기상자료를 이용하여 태양광 발전량을 예측하는 것을 목적으로 한다. 본 연구에서는 2016년 1월 1일부터 2018년 9월 30일까지의 발전량, 기상자료, 미세먼지 농도 자료를 이용하고 머신러닝 기반의 RBF 커널 함수를 사용한 서포트 벡터 머신을 적용하여 태양광 발전량을 예측하였다. 예측변수에 미세먼지 농도 반영 유무에 따른 태양광 발전량 예측 모델의 성능을 비교한 결과 미세먼지 농도를 반영한 발전량 예측 모델의 성능이 더 우수한 것으로 나타났다. 미세먼지를 고려한 예측 모형은 미세먼지를 고려하지 않은 예측 모형 대비 6~20시 예측 모형에서는 1.43%, 12~14시 예측 모형에서는 3.60%, 13시 예측 모형에서는 3.88%만큼 오차가 감소하였다. 특히 발전량이 많은 주간 시간대에 미세먼지 농도를 반영하는 모형의 예측 정확도가 더 뛰어난 것으로 나타났다.","Uncertainty of renewable energy such as photovoltaic(PV) power is detrimental to the flexibility of the power system. Therefore, precise prediction of PV power generation is important to make the power system stable. The purpose of this study is to forecast PV power generation using meteorological data including particulate matter(PM). In this study, PV power generation is predicted by support vector machine using RBF kernel function based on machine learning. Comparing the forecasting performances by including or excluding PM variable in predictor variables, we find that the forecasting model considering PM is better. Forecasting models considering PM variable show error reduction of 1.43%, 3.60%, and 3.88% in forecasting power generation between 6am~8pm, between 12pm~2pm, and at 1pm, respectively. Especially, the accuracy of the forecasting model including PM variable is increased in daytime when PV power generation is high."
빅데이터의 영 과잉 문제를 위한 머신러닝 알고리즘,2019,"['빅데이터', '0과잉문제', '통계분석', '머신러닝알고리즘', '데이터정형화', '텍스트문서', 'Big data', 'zero inflated problem', 'statistical analysis', 'macnhei learning algorithm', 'structured data', 'text documents']","빅데이터 분석에서 텍스트 문서는 매우 큰 비중을 차지한다. 텍스트 기반의 빅데이터를 분석하기 위해서는 전처리 기법을이용하여 텍스트 문서 데이터를 정형화된 데이터 형태로 만들어야 한다. 왜냐하면 통계학 및 머신러닝에서 제공하는 데이터분석기법은 정형화된 데이터를 대상으로 하기 때문이다. 정형화된 데이터는 주로 행(문서, 관측치)과 열(단어, 변수)로이루어진 행렬 구조를 갖는다. 이 행렬의 개별 원소값은 하나의 문서에 나타난 특정 단어의 출현 빈도가 된다. 일반적으로이 과정에서 0 과잉 문제가 발생한다. 0 과잉 문제란 전체 데이터 값에서 0의 값이 차지하는 비율이 지나치게 큰 경우이다.0 과잉 문제는 분석모형의 설명력을 떨어뜨리고 예측의 정확도를 감소시킨다. 본 연구에서는 빅데이터의 과도한 0 과잉문제에 대처하기 위하여 통계학과 머신러닝에서 제공하는 다양한 데이터 분석 기법 간의 비교를 통하여 0 과잉 문제 해결을위한 효율적인 대처 방안에 대하여 제안한다. 특허 빅데이터를 이용한 실험 및 결과를 통하여 제안 방법의 성능평가를수행한다.","Text documents take a large part of big data analytics. To analyze text-based big data, text documents have to be transformed into structured data by preprocessing techniques. This is because the analytical methods based on statistics and machine learning need to the structured data. The structured data has a matrix mainly consisting of rows (documents, observations) and columns (words, variables). The value of each cell in this matrix is the occurred frequency value of a word in a document. Typically, zero inflated problem occurs during this process. This problem is that the ratio of zero values in all data values is too large. The zero inflated problem reduces the explanatory power of the analytical model and thus lowers the accuracy of the prediction. In this paper, to cope with the zero inflated problem of big data, we propose an efficient usage of data analysis techniques to solve the zero inflated problem by comparing the various data analysis techniques prodvied by statistics and machine learning. To evaluate the performance of the proposed approach, we make experiments using patent bidga ta, and show the experimental results."
머신러닝을 이용한 한국 스포츠산업 기업의 부실 예측에 관한 연구,2019,"['스포츠산업', '기업부실 예측', '머신러닝', 'Sports Industry', 'Prediction of Corporate Insolvency', 'Machine Learning']",,"The purpose of this study is to predict the insolvency of sports industry companies by machine learning. In order to predict corporate insolvency, we defined a company with a negative interest payment ratio for three years as a insolvency company and vice versa as a healthy company. We selected the variables that satisfy the equal variance among the financial indicators that can be analyzed for the insolvent and healthy companies, and then conducted a T-test to select the financial variables that showed significant differences between the two groups. Using the selected financial indicators, machine learning was performed using logistic regression and discriminant analysis methods. The five financial indicators, such as Total assets growth, Financial expenses / total liabilities, NWC to total assets, Total CF to total liabilities, NWC turnover, were used as input variables to predict corporate insolvency. The training was conducted using the training data, and the results of the training were verified using the validation data. As a result, the prediction accuracy of the logistic regression analysis was 88.5%, which is higher than the 80.3% of the discriminant analysis. Apply the results of this study to identify companies that may be insolvent. By providing a way to prevent the insolvency will be, directly or indirectly, reduce the damage caused by the company insolvent."
머신러닝 알고리즘 분석 및 비교를 통한 Big-5 기반 성격 분석 연구,2019,"['Big 5', 'WEKA', 'Datamining', 'Machine Learning', 'Select attributes', 'Supervised Learning']","본 연구에서는 설문지를 이용한 데이터 수집과 데이터 마이닝에서 클러스터링 기법으로 군집하여 지도학습을이용하여 유사성을 판단하고, 성격들의 상관 관계의 적합성을 분석하기 위해 특징 추출 알고리즘들과 지도학습을 이용하는 것을 목표로 진행한다. 연구 수행은 설문조사를 진행 후 그 설문조사를 토대로 모인 데이터들을 정제하고, 오픈 소스기반의 데이터 마이닝 도구인 WEKA의 클러스터링 기법들을 통해 데이터 세트를 분류하고 지도학습을 이용하여 유사성을 판단한다. 그리고 특징 추출 알고리즘들과 지도학습을 이용하여 성격에 대해 적합한 결과가 나오는지에 대한 적합성을 판단한다. 그 결과 유사성 판단에 가장 정확도 높게 도움을 주는 것은 EM 클러스터링으로 3개의 분류하고 Naïve Bayes 지도학습을 시킨 것이 가장 높은 유사성 분류 결과를 도출하였고, 적합성을 판단하는데 도움이 되도록 특징추출과 지도학습을 수행하였을 때, Big-5 각 성격마다 문항에 추가되고 삭제되는 것에 따라 정확도가 변하는 모습을 찾게되었고, 각 성격 마다 차이에 대한 분석을 완료하였다.","In this study, I use surveillance data collection and data mining, clustered by clustering method, and use supervised learning to judge similarity. I aim to use feature extraction algorithms and supervised learning to analyze the suitability of the correlations of personality. After conducting the questionnaire survey, the researchers refine the collected data based on the questionnaire, classify the data sets through the clustering techniques of WEKA, an open source data mining tool, and judge similarity using supervised learning. I then use feature extraction algorithms and supervised learning to determine the suitability of the results for personality. As a result, it was found that the highest degree of similarity classification was obtained by EM classification and supervised learning by Naïve Bayes. The results of feature classification and supervised learning were found to be useful for judging fitness. I found that the accuracy of each Big-5 personality was changed according to the addition and deletion of the items, and analyzed the differences for each personality."
인공신경망을 이용한 머신러닝 기반의 연료펌프 고장예지 연구,2019,"['Failure Prognostic(고장예지)', 'Machine Learning(머신러닝)', 'Fuel Pump(연료펌프)', 'Artificial Neural Network(인공신경망)', 'Sensor(센서)']",,"The key technology of the fourth industrial revolution is artificial intelligence and machine learning. In this study, FMEA was performed on fuel pumps used as key items in most systems to identify major failure components, and artificial neural networks were built using big data. The main failure mode of the fuel pump identified by the test was coil damage due to overheating. Based on the artificial neural network built, machine learning was conducted to predict the failure and the mean error rate was 4.9% when the number of hidden nodes in the artificial neural network was three and the temperature increased to 140 °C rapidly."
임베디드 시스템 환경에서의 머신러닝 기반 미술 작품 추천 서비스 구현,2019,"['Embedded System', 'Image Processing', 'Machine Learning', 'Art Work Recommendation', 'Art Gallery Service', '임베디드 시스템', '영상처리', '머신러닝', '미술 작품 추천', '미술관 서비스']",국민 소득의 증가로 인해 문화 생활에 대한 관심이 크게 증가하면서 전국 미술관의 수도 함께 증가하고 있다. 하지만 다른 서비스에 비해 미술관 만족도는 상대적으로 낮은 편이다. 본 논문에서는 미술관 만족도를 높이기 위해 임베디드 시스템 환경에서 머신러닝에 기반한 관중들의 선호도에 관련된 정보를 제공하는 서비스를 제안한다. 제안된 알고리즘은 라즈베리 파이를 이용하여 임베디드 시스템을 구현했다. 관람자가 선호하는 작품과 유사한 작품을 찾아내기 위해 머신러닝을 이용하였고 여러 머신러닝 모델을 비교하여 임베디드 시스템에 적용 가능한 모델을 선정했다. 관람자의 취향에 맞는 정보를 활용하여 갤러리 전시 내용을 효과적으로 구성하여 전시 만족도를 높이고 이는 미술관 재 방문율을 높일 수 있을 것이다.,"The number of galleries across the country is increasing as interest in cultural life increases due to the increase in national income. However, museum satisfaction is relatively low compared to other services. In this paper, we propose a service that provides preference information based on machine learning in embedded system environment in order to increase museum satisfaction. The proposed algorithm implements an embedded system using Raspberry Pi. Machine learning was used to find works similar to the viewer's favorite works, and several models were compared to select models applicable to embedded systems. By using the preference information, it is possible to effectively organize the gallery exhibition contents to increase the exhibition satisfaction and the re-visit rate of the museum."
제조 공정에서 센서와 머신러닝을 활용한 불량예측 방안에 대한 연구,2019,"['Smart Factory', 'Sensor Data', 'Machine Learning', 'Defect Prediction', '스마트 팩토리', '센서데이터', '기계학습', '불량 예측']","제조회사에서 생산되는 제품의 불량을 예측하는 것은 기업의 이익과 직접적으로 관련되기 때문에 매우 중요한 문제로 간주한다. 불량품을 판별하는 전통적인 방법은 사람이 직접 수작업으로 불량품을 식별하는 것이다. 이런 방법은 인적 오류에 의한 오류 발생의 가능성이 크고 많은 사람에게 의존해야 하므로 비용이 많이 발생하며 이미 불량이 발생한 후 불량품을 찾는 사후 처방적인 방법이다. 본 연구는 센서 기술과 머신러닝 기법을 활용하여 제품의 불량을 사전에 예측할 방법을 제안한다. 센서는 생산 설비의 중요 처리 부위에 부착하여 압력, 속도, 온도 등의 품질에 영향을 미칠 수 있는 데이터를 실시간으로 수집하였다. 제품의 불량 여부를 판별하기 위해 제품의 무게를 자동으로 계측하는 센서 장비를 사용하였고, 무게의 변동계수(Coefficient of Variation)를 종속 변수로 사용하였다. 수집된 데이터에 Linear Regression, Gradient Boosted Tree, Deep Learning 등의 알고리즘을 적용하여 예측 모델을 구축하였다. 분석 결과 Deep Learning이 제품 불량 예측에서 가장 탁월한 성과를 보였다.","Predicting product defects is a very important issue in a manufacturing company because it is directly related to the profit of the company. The traditional way of identifying defectsive products is to identify them manually. This method is costly because of the high probability of human error and the need to rely on a large number of people. This study proposes a method to predict product defects in advance using sensor technology and machine learning techniques. The sensors were attached to critical pro-cessing areas of the production facility to collect data, such as pressure, speed, temperature, in real time. In order to determine whether the product is defective, we used sensor equipment to measure the weight of the product automatically, and coefficient of variation was used as a dependent variable. A predictive model was constructed by applying algorithms such as linear regres-sion, gradient boosted tree, and deep learning to the collected data. The analysis showed that deep learning outperforms other al-gorithms in predicting product defects."
머신러닝을 이용한 기관 출력 예측 방법에 관한 연구,2019,"['선박', '저항', '예측', 'SVM', 'ISO15016', 'Ship', 'Resistance', 'Prediction', 'SVM', 'ISO15016']","본 연구는 운항선의 운항 빅데이터를 활용하여 머신러닝 기법의 선박 마력 예측에 관한 것이다. 현재 신조선에는 ISO15016법을 이용하여 외부환경 요인에 대하여 수식을 통해 저항을 예측하나 관련 계산식이 복잡하고 요구하는 입력변수들이 많아 운항하는 실선 적용에 많은 시간과 비용이 필요하다. 본 연구에서는 최근 예측, 인식 등에서 우수한 성능을 보이는 SVM(Support Vector Machine) 알고리즘을 이용하여 우수한 성능의 선박 출력 예측이 가능한 모델을 제안한다. 제안 예측 모델은 실선 운항 빅데이터만 확보된다면 ISO15016법 대비 우수한 성능의 예측이 가능한 장점이 있다. 본 연구에서는 178K 벌크캐리어의 운항 DATA를 활용하여 ISO15016 기법과 본 연구에서 제안하는 SVM 알고리즘 기반의 마력해석법을 비교하여 ISO15016의 단점인 선박 모델 데이터 준비 부분을 줄이고 부정확한 마력 예측 성능을 개선하였다.","This study is about ship horsepower prediction of machine learning method using the big data of ship. Currently, new ships use the ISO15016 method to predict external environmental resistance through mathematical equations but due to complicated equations and requires many input variables so it is less applicable to be used in ship. In this recent research, we propose a model capable of predicting ship performance with high performance using SVM (Support Vector Machine) algorithm which shows excellent performance in recent prediction and recognition. The proposed predictive model has the advantage of being able to predict better performance than ISO15016 only if secured big data is used. In this study, we compared the ISO15016 technique and the SVM algorithm-based horsepower analysis method using the 178K bulk carrier's voyage data to reduce ship model data preparation, which is a disadvantage of ISO15016, and improve inaccurate horsepower prediction performance."
머신러닝을 통한 가계의 재무스트레스 영향요인 예측 및 분석: XGBoost의 활용,2019,"['재무스트레스', '머신러닝', 'XGBoost', '객관적 재무상태', '주관적 인식', '재무행동', '가계재무복지', 'financial stress', 'machine learning', 'financial status', 'subjective perception', 'financial behavior', 'household well-being']",,"In this study, we explored how various factors influenced financial stress. Also, to suggest ways to improve the economic well-being of households we identified influence of the factors. For this purpose, 2,006 data were collected through online surveys. The analysis method was used XGBoost which is one of the algorithms using machine learning and multiple regression analysis. After analyzing the important predictors of financial stress through XGBoost, multiple regression analysis of financial stress was conducted to confirm the specific influence of variables. The results of the study are as follows. First, The level of financial stress that consumers perceive as subjective is about 2.3 points on average for 4 points. Therefore, it is necessary to constantly try to manage the consumer's financial stress at an appropriate level. Second, As a result of analyzing XGBoost to determine whether the consumer's financial stress level belongs to the high and low groups based on the average, it is confirmed that the variable indicating the objective financial state of the consumer and the variable indicating the subjective perception are all influenced. On the other hand, factors related to long - term savings and investment, long - term risk management insurance, and future prospects for the household economy are less important. Third, The effect of the major factors revealed that the subjective perception of consumers has a great influence on the financial stress level. Especially, we can confirm that the factors related to the emergency fund based on the short-term plan are influential. Households’ monthly income, savings and investment, and debt payment were more influential on financial stress level than stock such as household total assets. Based on the above results, it is necessary to support effective policy and consumer education so that consumers can manage financial stress level well."
유한요소 해석과 머신러닝을 이용한 직사각형 드로잉 제품의 미세면굴곡의 예측모델,2019,"['미세면굴곡', '머신러닝', '비선형 회귀분석', 'Surface Deflection', 'Machine Learning', 'Nonlinear Regression Analysis']","자동차의 외관상의 문제를 야기하는 미세면굴곡의 양의 예측은 곡률의 최대변화량으로 정량화할 수 있다. 재료물성치에 따른 미세면굴곡 양은 그 비선형성으로 인해 예측이 어렵다. 본 연구에서는 인공신경망 기법을 이용한 감독 학습을 통해 미세면굴곡의 예측 모델을 연구하였다. 유한요소 해석을 이용하여 미세면굴곡을 정량화 하였으며, 재료물성치 값에 변화를 주어 데이터 군을 생성하였다. 최적화된 인공 신경망을 구성하기 위해 다양한 기술과 도구의 효과가 연구되었다. 기존의 통계적 회귀분석 방법과 비교하여 인공신경망을 사용한 예측의 정확도를 비교한 결과 인공신경망을 이용하였을 때 평균 오차가 현저히 낮음을 확인했다.","The predicted amount of surface deflection that affects the appearance of the vehicle can be quantified as the maximum variation in the curvature. Prediction of the surface deflection according to the material properties is difficult owing to its nonlinearity. In this study, prediction model of surface deflection was studied using artificial neural network technique through supervised learning. Finite element analysis was used to quantify the microfine curvature, and data groups were generated through a variation in the material property values. The effect of various techniques and tools was studied for the construction of optimized artificial neural networks. Comparing the predictions using artificial neural networks with those of statistical regression, we found that the mean error was significantly lower when using such networks."
딥 러닝 기법을 이용한 오피니언 마이닝 분석과 성과에 관한 실증연구: 합성곱 신경망 모델과 머신러닝 모델간 성과비교를 중심으로,2019,"['Deep learning', 'Convolutional neural network', 'Sentiment analysis', 'Opinion mining', 'Machine learning classifiers', 'Financial supervisory policy', '딥 러닝', '합성곱 신경망', '감성분석', '오피니언 마이닝', '머신러닝 분류기']","본 연구는 딥 러닝 기법인 합성곱 신경망 (CNN: Convolutional Neural Network)을 이용하여 금융자료에 관한 사용자의 오피니언을 추정하는 오피니언 마이닝 (Opinion mining) 방법과 그 결과를 설명한다. 본 연구에서는 다음과 같이 합성곱 신경망의 효과성을 검증하였다. 첫째, 스터디1은 주식관련 온라인 리뷰 데이터를 분석하였다. 즉, 형태소 분석단계를 거쳐 속성벡터를 만들어 리뷰 문장의 감성점수를 산출하였다. 해당 문장의 감성점수에 따라 오피니언을 3-클라스, 5-클라스 문제로 구분하여 실증분석을 하였다. 둘째, 스터디2에서는 청와대 국민청원에 게시된 금융관련 국민청원 텍스트 문장을 분석하여 청원인원을 추정하였다. 청원게시판에 등재된 청원 인원을 분위 수에 따라 분류하여 2-클라스 문제 (50%이상, 50% 미만) 4-클라스 문제 (75%이상, 50%이상, 25%이상, 25%미만)로 분류하였다. 스터디1, 2의 실증분석결과 정확도, 정밀도, 재현율, F1 점수 등 모든 성과지표에서 벤치마킹용 분류기와 비교할 때 합성곱 신경망이 더 우수한 성과를 보였다. 따라서, 합성곱 신경망을 이용함으로써 금융감독 관련 정책 및 활동을 효과적으로 수행할 수 있음을 실증적으로 확인하였다.",
강원경제 핵심 산업별 블록체인 기술 도입에 관한 주요 토픽: 빅데이터 머신 러닝 기반 토픽 모델링 및 토픽 네트워크 분석,2019,"['블록체인', '빅데이터', '머신 러닝', '토픽 모델링', '토픽 네트워크', '강원경제', 'Blockchain', 'Big Data', 'Machine Learning', 'Topic Modelling', 'Topic Network', 'Gangwon Economy']",,"This paper examines main topics accompanied by applying blockchain technology to the core industries of Gangwon economy such as healthcare, medical devices, tourism and food industries. Raw data has been collected from crawling texts concerning ‘blockchain’ in the main daily newspapers such as Chosun-, Chungang-, Donga- and Gangwon Daily Newspaper, covering the research period of 1. Jan. 2016 to the current. Analytic tools cover the key words frequency analysis, machine learning LDA-based topic modelling, topic network & clustering analysis. The main findings are: 1) in the domestic level the application of blockchain technology gives weight to the first generation, 2) in the case of Gangwon economy the connectedness between topics is relatively low, 3) core topics of every single industries, the degree centrality of them and the connectedness between them are different.Therefore, it is possible to expect that the effect of adopting blockchain technology will occur through different input-output processes by industries."
3SC 실용트리즈와 머신러닝을 이용한 기공을 가진 인공지지체 제조문제 해결에 관한 연구,2019,"['3D Printer', 'Machine Learning', 'Regression', 'Scaffold', 'TRIZ']",,"In this paper, we have analyzed manufacturing problems of the scaffold with pores using FDM 3D printer and PLGA. We suggested the solutions using 3SC practical TRIZ. We selected the final solution used machine learning. We reduced number of experiments using most influential factor after analysis print factors. We printed the scaffold and measured pore size. We created the regression model using python tensorflow. The print condition data of measured pore size was used as training data . We predicted the pore size of printed condition using regression model. We printed the scaffold using the predicted the print condition data. We quantitatively compare the predicted scaffold pore size data and the measured scaffold pore size data. We got satisfactory result."
고빈도 자료를 이용한 머신러닝모형의 예측력 비교 ․ 분석: KOSPI200 선물시장을 중심으로,2019,"['High Frequency Data', 'Machine Learning', 'Microstructure', 'Bar', 'Private Information', '고빈도자료', '머신러닝', '미시구조론', '바(bar)', '사적정보']","본 연구에서는 KOSPI200 선물의 틱(tick) 데이터를 활용하여 머신러닝 모형의 예측력을 분석한다.첫째, 미시구조론(microstructure)의 함의를 이용해 바(bar)를 구성했을 경우와 둘째, support vector machine, random forest와 같은 머신러닝(machine learning) 모형을 이용했을 경우 선물가격의상승과 하락 방향에 대한 예측력이 향상되는지를 분석했다. 분석 결과 시장에 새로운 정보가유입되는 시점을 기준으로 봉을 구성했을 때, 그리고 머신러닝 모형을 이용했을 때 예측력이더욱 향상되는 것으로 나타났다. 머신러닝 모형의 예측력은 모형의 훈련에 사용되는 데이터의양이 많아짐에 따라 더욱 향상되는 것으로 나타났다. 특히 거래량의 표본추출 기간을 정보의유입여부에 따라 조정함으로써 예측력이 향상되었다는 결과는 통상적인 시간에 따라 가격의상승 하락을 기록하고 분석하는 것은 유의미한 정보의 손실이 있음을 알 수 있다.","This paper investigates the effectiveness of machine learning algorithms and microstructure theory in predicting high frequency price movement. While accurately predicting future prices of financial assets has always been a major concern for the financial sector, recent developments in analytics tools and accessibility to new data have stimulated academics to pursue research.There are two main ways in which machine learning algorithms are incorporated into financial research. The first is to increase the predictive power of models by adopting machine learning techniques that have not been used in previous studies (Yoon, 2019; Laborda and Laborda, 2017).Secondly, machine learning algorithms are also used to identify new predictive variables (Kim and Joh, 2019; Gentzkow et al., 2017).On the other hand, there is very little discussion regarding the criteria to construct structured dataset from raw financial data. While microstructure theory argues that active informed traders leave characteristic footprints in market data, incorrectly structured data may fail to extract this information effectively. In this aspect, de Prado(2018a) suggested VIB(volume imbalance bar) based on implications of microstructure theory, which sample bars when informed traders are active.Therefore, this study examines whether or not VIBs contain predictive information regarding future price movement. Using tick data of KOSPI 200 futures, we constructed VIBs and three standard bar types widely used by practitioners and academics: time bar, tick bar and volume bar. Then, we produced out of sample predictions of one-bar ahead price movement and compared prediction performances of different bar types. In order to test the effectiveness of machine learning algorithms, we used logistic regression as the benchmark and compared the prediction accuracy with SVM(support vector machine) and random forest, two machine learning algorithms widely applied in financial research.The results of the analysis can be summarized as follows. First, the prediction accuracies of time bar, tick bar and volume bar were no better than a random walk. On the other hand, the prediction accuracy of data constructed with VIB was 65% at least, implying that it contains predictive information regarding future price movement. Chinko et al.(2019) argues that predictive information of returns are sparse and short-lived. Therefore it is better to predict price movements when an information event takes place, and before that information is reflected in the price than predicting them at a random time. This result shows that while VIB incorporates predictive information by effectively identifying the presence of informed traders, standard bar types fail to capture this information.Second, as the size of training data increases, prediction accuracies of SVM and random forest outperform the prediction accuracy of logistic regression. While there is no significant difference when the training data is small, the gap widens with more training data and eventually resulting in a 5% difference in the biggest training data size. This result implies that machine learning algorithms may enhance prediction accuracy given large data.This study shows that even though the same raw data is used, prediction accuracy of machine learning algorithms may differ depending on the criteria of how the structured dataset is constructed. Synchronizing bar constructions with information flows may capture predictive information. On the other hand, sampling bars based on chronological time may lead to a significant loss of information. Therefore, while the majority of financial machine learning research focus on model implementation and producing new predictor variables, this research shows that proper construction of structured data is also an important feature."
머신러닝 적용 과일 수확시기 예측시스템 설계 및 구현,2019,"['머신러닝', '인류의 생존', '수확시기', '스마트 팜', '빅 데이터', 'Machine Learning', 'Smart Farm', 'Harvest Time', 'Big Data', 'Human Survival']","최근에 머신 러닝 기술은 의료, 제조, 마케팅, 금융, 방송, 농업 등 사회 전반에 많은 영향을 미치고 있고 미래에도 인류의생활에 많은 도움을 줄 것으로 예상된다. 본 논문에서는 인류의 생존에 가장 큰 영향을 주는 먹거리 즉, 농업 분야에 머신러닝기술을 적용하는 방법을 연구한다. 농업 분야에 IoT(Internet of Things) 기술을 접목하는 스마트 팜 (Smart Farm) 분야는생육환경을 실시간으로 모니터링 하여 농작물의 생육환경을 최적으로 유지 하는 방법을 중점적으로 연구한다. 최근 KT에서출시된 기가 스마트 팜 솔루션 2.0 에서는 머신러닝 기술을 사용하여 온실내의 온습도를 최적으로 유지하는 기술에 머신러닝을적용하였다. 기존의 스마트 팜 분야 연구가 생육환경 조절에 중점을 두어 생산성 증대에 집중되어 있지만 본 연구에서는 과일을최상의 품질 상태에서 수확하여 좋은 가격으로 출하할 수 있도록 수확시기에 머신러닝을 적용하는 방법을 연구한다. 스마트팜 분야에 머신러닝 기술을 적용하기 위해서는 풍부한 빅 데이터의 확보가 무엇보다 중요하므로 정확한 머신러닝 기술을 적용하기 위해서는 지속적으로 빅 데이터 수집이 가능해야 한다. 본 논문에서 수확시기 예측에 필요한 인자로는 온실 내에서 재배되는 과일의 색상 값과 무게 값, 내부 온습도 값을 색상센서 와 무게센서, 온습도센서를 사용하여 실시간으로 수집하여 확보한다.본 논문에서 제안하는 FPSML은 유사 과일 재배에 반복적으로 사용할 수 있는 아키텍처를 제공하며 지속적으로 빅 데이터가축적될수록 보다 정밀한 수확시기를 예측할 수 있다.","Recently, machine learning technology has had a significant impact on society, particularly in the medical,manufacturing, marketing, finance, broadcasting, and agricultural aspects of human lives. In this paper, we studyhow to apply machine learning techniques to foods, which have the greatest influence on the human survival. Inthe field of Smart Farm, which integrates the Internet of Things (IoT) technology into agriculture, we focus onoptimizing the crop growth environment by monitoring the growth environment in real time. KT Smart FarmSolution 2.0 has adopted machine learning to optimize temperature and humidity in the greenhouse. Most existingsmart farm businesses mainly focus on controlling the growth environment and improving productivity. On theother hand, in this study, we are studying how to apply machine learning with respect to harvest time so that wewill be able to harvest fruits of the highest quality and ship them at an excellent cost. In order to apply machinelearning techniques to the field of smart farms, it is important to acquire abundant voluminous data. Therefore, toapply accurate machine learning technology, it is necessary to continuously collect large data. Therefore, the color,value, internal temperature, and moisture of greenhouse-grown fruits are collected and secured in real time usingcolor, weight, and temperature/humidity sensors. The proposed FPSML provides an architecture that can be usedrepeatedly for a similar fruit crop. It allows for a more accurate harvest time as massive data is accumulatedcontinuously."
간접차별과 머신러닝에 의한 특성추론,2019,"['알고리즘에 의한 차별', '차별금지법', '특성 중심 모델', '대용물', '인공지능과 법', 'Discrimination by Algorithm', 'Anti-Discrimination Law', 'Feature-Centric Model', 'Proxy', 'AI and Law']","인공지능 연구에서 중요한 위치를 차지하고 있는 머신러닝 연구가 가져올 사회적 효능에 대한 기대의 이면에는 그 부작용으로서 사회의 데이터에 기반을두고 생성된 알고리즘이 차별을 재생산하거나 사회의 차별적 구조를 고착시킬수 있다는 우려가 문제로 제기된다. 이 글은 머신러닝에 의한 특성추론이 어떻게 그와 같은 문제로 이어질 수 있는지 복잡한 머신러닝의 작동원리를 염두에두면서 그에 못지않게 복잡한 차별 개념의 의미와 구조를 분석한다. 또한 머신러닝 알고리즘이 어떤 방식으로 차별에 관한 법 모델과 연결될 수 있는지 살펴봄으로써 이른바 ‘4차 산업혁명’의 기반이자 사회의 지배 조건 중 하나가 될 수있는 인공지능 기술이 갖는 법적 함의의 일부를 추적한다.차별 개념에는 사람 또는 사물의 차이를 인식하고 구별, 분리, 분류하는 맥락에서 사용될 경우 정당성이나 부당성의 평가에 종속되지 않는다는 측면에서 사실적이고, 정당성이나 부당성의 평가를 위해 전제된 상황을 묘사한다는 측면에서 서술적인 의미가 부여될 뿐만 아니라, 평등, 자유, 존엄성 등의 가치와 결합할 수 있다는 측면에서 규범적 의미 또한 중첩적으로 부여된다. 차별을 법적으로 규율하기 위한 차별금지법 모델을 구성하고 적용할 때 행위를 중심에 둘 것인지 아니면 결과에 중심을 둘 것인지, 그리고 각각의 행위와 결과를 구별 자체에 초점을 맞출 것인지 아니면 그 구별을 기초로 한 후행 조치에 초점을 맞출 것인지에 따라 차별의 불법성 여부도 첨예하게 갈라질 수 있다.특히 차별 개념을 폭넓게 이해하는 간접차별 개념을 차별의 한 유형으로 포착하는 차별금지법 모델의 경우 어떤 특성을 기준으로 한 구별, 분리, 분류 그자체 또는 이에 기초한 그 후속 결정들에 대한 법적 규제 가능성을 폭넓게 열어둔다. 그러나 역설적으로 어떤 특성을 기준으로 삼는 형식적 구조를 갖는 차별금지법 모델은 그러한 특성과 무관한 또는 통계적 관련성이 높아 합리적으로보이는 또 다른 특성들을 추론해 내는 머신러닝을 통해 어렵지 않게 우회될 수있다. 또한 합리적 차별을 불법으로 규정하지 않는 차별금지법 모델에서 간접차별 또는 차별효과는 그 간접성 또는 부수성으로 인해 쉽게 정당화되거나 합리화될 수 있다는 점에서 대용물을 자유자재로 사용할 수 있는 머신러닝은 차별의 양식도 대부분 간접차별의 형태로 만들어 불법적인 차별의 영역 자체를불명확하게 만들 수 있다.","Machine learning is very important area of study in artificial intelligence (AI). AI is emphasized as the leading technology in the process of so-called ‘fourth industry revolution.’ But it also can function as one of governing conditions to manage partial systems of society. From this point of view, this article focuses on the discrimination issues in relation of machine learning inference, especially indirect discrimination. Machine learning system trained from dataset, which is collected and selected in social communication systems, may reproduce and reinforce discrimination by discovering the differential structure of society.The conception of discrimination in legal models is as complex as the mechanism of machine learning is. Descriptive meanings of discrimination such as distinction, division, and classification make the legal models of anti-discrimination subscribe to cognitive operations. Then normative meanings of discrimination which are connected to the virtues such as liberty, equality, and dignity make these significant. It is possible that legal models of anti-discrimination are constituted to be action-centric or result-centric. We can also construct them to be applied to distinction as such or following decision on the basis of that.However, in case that machine learning systems infer new or statistically rational features in the dataset from social system, feature-centric or rationality-centric legal models of anti-discrimination may become useless. Because a lot of proxies, which are utilized in machine learning process to correlate data, mask the features on the basis of which prohibited to decide and make those rational reasons of decision-making. This is why that it should be addressed in terms of asking for a reflective review on the limitations of anti-discrimination law that form social system to protect human beings."
머신러닝 기술의 광업 분야 도입을 위한 활용사례 분석,2019,"['Machine learning', 'Mineral exploration', 'Mine development', 'Productivity', 'Safety', '머신러닝', '광상 탐사', '광산 개발', '생산성', '안전성']","본 연구에서는 국내 의료, 제조, 금융, 자동차, 도시 분야와 해외 광업 분야에서 머신러닝 기술이 활용된 사례를 조사하였다. 문헌 조사를 통해 머신러닝 기술이 의학영상 정보시스템 개발, 실시간 모니터링 및 이상진단 시스템 개발, 정보시스템의 보안 수준 개선, 자율주행차 개발, 도시 통합관리 시스템 개발 등에 광범위하게 활용되어왔음을 알 수 있었다. 현재까지 국내 광업 분야에서는 머신러닝 기술의 활용사례를 찾을 수 없었으나, 해외에서는 광상 탐사나 광산 개발의 생산성 및 안전성을 개선을 위해 머신러닝 기술을 도입한 프로젝트들을 찾을 수 있었다. 향후 머신러닝 기술의 광업 분야 도입은 점차 확산될 것으로 예상된다.","This study investigated use cases of machine learning technology in domestic medical, manufacturing, finance, automobile, urban sectors and those in overseas mining industry. Through a literature survey, it was found that the machine learning technology has been widely utilized for developing medical image information system, real-time monitoring and fault diagnosis system, security level of information system, autonomous vehicle and integrated city management system. Until now, the use cases have not found in the domestic mining industry, however, several overseas projects have found that introduce the machine learning technology to the mining industry for improving the productivity and safety of mineral exploration or mine development. In the future, the introduction of the machine learning technology to the mining industry is expected to spread gradually."
머신러닝 기법을 활용한 암호화폐 유통 가격 예측 연구,2019,"['Blockchain', 'Cryptocurrency', 'Blockchain information', 'Machine Learning', 'Price Prediction', 'Distribution management']",,"Purpose: Blockchain technology suggests ways to solve the problems in the existing industry. Among them, Cryptocurrency system, which is an element of Blockchain technology, is a very important factor for operating Blockchain. While Blockchain cryptocurrency has attracted attention, studies on cryptocurrency prices have been mainly conducted, however previous studies mainly conducted on Bitcoin prices. On the other hand, in the context of the creation and trading of various cryptocurrencies based on the Blockchain system, little research has been done on cryptocurrencies other than Bitcoin. Hence, this study attempts to find variables related to the prices of Dash, Litecoin, and Monero cryptocurrencies using machine learning techniques. We also attempt to find differences in the variables related to the prices for each cryptocurrencies and to examine machine learning techniques that can provide better performance. Research design, data, and methodology: This study performed Dash, Litecoin, and Monero price prediction analysis of cryptocurrency using Blockchain information and machine learning techniques. We employed number of transactions in Blockchain, amount of generated cryptocurrency, transaction fees, number of activity accounts in Blockchain, Block creation difficulty, block size, umber of created blocks as independent variables. This study tried to ensure the reliability of the analysis results through 10-fold cross validation. Blockchain information was hierarchically added for price prediction, and the analysis result was measured as RMSE and MAPE. Results: The analysis shows that the prices of Dash, Litecoin and Monero cryptocurrency are related to Blockchain information. Also, we found that different Blockchain information improves the analysis results for each cryptocurrency. In addition, this study found that the neural network machine learning technique provides better analysis results than support-vector machine in predicting cryptocurrency prices. Conclusion: This study concludes that the information of Blockchain should be considered for the prediction of the price of Dash, Litecoin, and Monero cryptocurrency. It also suggests that Blockchain information related to the price of cryptocurrency differs depending on the type of cryptocurrency. We suggest that future research on various types of cryptocurrencies is needed. The findings of this study can provide a theoretical basis for future cryptocurrency research in distribution management."
머신러닝 기법을 활용한 사교육 참여 예측 모형 탐색,2019,"['사교육', '머신러닝', '랜던 포레스트', '나이브 베이즈 분류', '서포트 벡터 머신', '인공신경망 모형 Demand for private tutoring', 'Random Forests', 'Naive Bayes Classifier', 'Support Vector Machine', 'and Artificial Neural Network']","그 동안 사교육 수요의 원인 분석과 해결 방안 모색을 위한 다양한 연구들이 수행되었지만, 학생들의 사교육 참여 및 사교육비 지출에 대한 논의는 여전히 하나의 결론에 도달하지 못하고 있다. 선행연구들 중에는 그러한 이유를 그 동안 사교육 수요를 설명하기 위해 사용된 분석 모형이나 변수들이 상당히 제한적이었으며, 그로 인해 중요한 변수를 간과하거나 보다 직접적인 변수들을 통합․분리해 내는데 실패했기 때문이라고 설명하고 있다. 이에 본 연구에서는 빅데이터 분석과 함께 최근 주목을 받고 있는 네 가지 머신러닝 기법 즉, ‘랜덤 포레스트’, ‘나이브 베이즈 분류’, ‘서포트 벡터 머신’, ‘인공신경망 모형’을 적용하여 고등학생들의 사교육 참여에 영향을 미치는 변수들을 탐색적으로 살펴보았다. 그리고 이들 각 기법들의 예측성과를 비교․분석함으로써 머신러닝 기법이 갖는 성능과 한계를 조망해 보고, 향후 사교육 영향 요인 연구를 비롯한 다양한 교육 분야의 연구로 확대 가능한지 여부를 함께 검토해 보았다. 분석을 위해 본 연구에서는 한국교육고용 패널 Ⅱ의 1차 년도 자료를 사용하였다. 분석 결과 첫째, 머신러닝 기법에 따라 고등학생들의 사교육 참여를 예측하는 변수는 상이하였으며, 네가지 기법의 분석 결과에 공통적으로 포함된 예측 변수는 하나도 존재하지 않았다. ‘방과후 자율학습 참여여부’ 변수가 그나마 세 가지 기법에 공통적으로 포함되었으나, 상대적인 중요도에는 상당한 차이가 있었다. 둘째, 시험 자료를 기반으로 각 머신러닝 기법의 사교육 참여 예측률을 산출한 결과, 랜덤 포레스트 기법과 나이브 베이즈 분류 기법이 서포트 벡터 머신 기법이나 인공신경망 기법보다 고등학생의 사교육 참여를 더욱 정확하게 예측하는 것으로 나타났다. 따라서 표본 및 변수 선정 과정에서의 편의를 줄이고 분석 결과의 일반화 가능성을 높이기 위한 방편으로 머신러닝 기법을 적극 활용할 수 있으나, 분석의 목적이나 자료의 구조에 적합한 머신러닝 기법을 선택하기 위한 적절한 검증 작업이 선행되어야 할 것으로 보인다.","There’s a plenty of literature on the demand of private tutoring across east-asian countries, particularly in the republic of Korea. To predict the demand for private tutoring more accurately, various methodologies have been proposed and applied. However, the methodologies have some deficits. First of all, they are unable to give a solution for which variables in the dataset should be considered as explanatory variables to effectively predict the demand for private tutoring. Also, they are easily exposed to over-fitting and risk being affected by outliers and noise. To overcome those limitations, this study proposes the application of multiple machine learning mechanisms including Random Forests(RF), Naive Bayes Classifier, Support Vector Machine, and Artificial Neural Network on the 1ST year dataset of the Korea Education and Employment Panel II. And to evaluate and compare our those results of multiple machine learning mechanisms, each model’s performance was calculated by Correct Classified Rate, Sensitivity, and Specificity based on test dataset.　Empirical results showed that RF outperforms other machine learning algorithms from the perspective of prediction accuracy."
머신러닝 기반 Lumpy 수요형태의 항공기 수리부속 수요예측 정확도 개선 연구,2019,"['Machine Learning', 'Aircraft Spare Parts', 'Demand Forecast']",,"For the spare parts of aircraft 'A' operated by ROKAF(Republic of Korea Air Force), this research suggests the application of machine learning technique rather than that of time series technique in order to improve demand forecast accuracy of spare parts whose demand pattern is lumpy. Demand patterns are divided into four categories by applying Average Inter-Demand Interval(ADI) and Coefficient of Variation(CV). Only for the lumpy parts, this study applies various analysis models selected from demand history, and the probability of demand occurrence for each period for lumpy parts is predicted by applying machine learning techniques. As a result of the experiment, lumpy or erratic pattern appeared to be higher in aircraft spare parts, and smooth parts with stable demand appeared relatively lower. In addition, logistics regression, linear discriminant analysis, and decision tree technique showed a relatively better accuracy, and machine learning technique improved prediction accuracy about 5% higher than time series technique, thus proving that machine learning technique is an effective technique to for lumpy spare parts demand forecast."
트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용,2019,"['Machine Learning', 'Deep Learning', 'Feature Engineering', 'Automated Feature Extraction', 'Transaction Data']",,"Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
머신러닝 기법을 이용한 산림의 층위구조 분류,2019,"['forest vertical structure', 'forest inventory', 'forestry', 'LiDAR', 'airborne photo', 'machine learning', 'SVM(Support Vector Machine)']","모든 식생 군락은 각자 층위구조를 가지고 있다. 이를 ‘식생층위구조’라 부른다. 요즈음은 이 층위구조가 산림의 활력도, 다양성, 그리고 환경영향을 평가하는데 중요한 식별자로 작용하기 때문에 산림조사에 있어서 식생층위구조는 필수적으로 조사되어야한다. 그런데, 식생층위구조는 일종의 내부구조이므로 일반적으로산림조사는 현장조사를 통해 이루어지는데, 이는 전통적인 방식으로 시간과 예산이 많이 든다. 따라서 본 연구에서는 산림의 층위구조를 조사하는데 드는 시간과 예산을 줄이기 위해 넓은 지역 탐사에 효과적인 원격탐사기법 중 항공촬영 사진과 대량의 데이터 마이닝(Data Mining)이 가능한 머신러닝(Machine Learning)기법 이용한층위구조의 분류 방법을 제시한다. 칼라 항공사진, LiDAR(Light Detection and Ranging) DSM(Digital Surface Model)과 DTM(Digital Terrain Model)을 이용하여 Support Vector Machine(SVM) 머신러닝 기법을 이용하여 층위분류 연구를 진행하였다. 현장조사 자료를 참조하여 SVM기법 분류 결과와 비교했을 때 픽셀수에 기반한 정확도는 66.22%로 확인 되었다. 층위 분류 정확도는 단층과 다층의 구분은 비교적 높게 나타났으나, 다층끼리의분류는 어렵다는 결론이 나타났다. 이러한 연구결과는 향후 다양한 식생데이터와 영상자료를 수집한다면 식생구조에 대한 머신러닝 연구분야에 더욱 발전이 가능할 것으로 기대된다.","All vegetation colonies have layered structure. This layer is called ‘forest vertical structure.’ Nowadays it is considered as an important indicator to estimate forest’s vital condition, diversity and environmental effect of forest. So forest vertical structure should be surveyed. However, vertical structure is a kind of inner structure, so forest surveys are generally conducted through field surveys, a traditional forest inventory method which costs plenty of time and budget. Therefore, in this study, we propose a useful method to classify the vertical structure of forests using remote sensing aerial photographs and machine learning capable of mass data mining in order to reduce time and budget for forest vertical structure investigation. We classified it as SVM (Support Vector Machine) using RGB airborne photos and LiDAR (Light Detection and Ranging) DSM (Digital Surface Model) DTM (Digital Terrain Model).Accuracy based on pixel count is 66.22% when compared to field survey results. It is concluded that classification accuracy of layer classification is relatively high for single-layer and multi-layer classification, but it was concluded that it is difficult in multi-layer classification. The results of this study are expected to further develop the field of machine learning research on vegetation structure by collecting various vegetation data and image data in the future."
머신러닝을 활용한 TV 오디션 프로그램의 우승자 예측 모형 개발: 프로듀스X 101 프로그램을 중심으로,2019,"['Machine learning', 'Supervised learning', 'Random forest', 'TV audition', 'Winner prediction', 'Entertainment industry']",,"In the entertainment industry which has great uncertainty, it is essential to predict public preference first. Thanks to various mass media channels such as cable TV and internet-based streaming services, the reality audition program has been getting big attention every day and it is being used as a new window to new entertainers’ debut. This phenomenon means that it is changing from a closed selection process to an open selection process, which delegates selection rights to the public. This is characterized by the popularity of the public being reflected in the selection process. Therefore, this study aims to implement a machine learning model which predicts the winner of <ProduceX 101>, which has recently been popular in South Korea. By doing so, this study is to extend the research method in the cultural industry and to suggest practical implications. We collected the data of winners from the 1st, 2nd, and 3rd seasons of the Produce 101 and implemented the predictive model through the machine learning method with the accumulated data. We tried to develop the best predictive model that can predict winners of <ProduceX 101> by using four machine learning methods such as Random Forest, Decision Tree, Support Vector Machine (SVM), and Neural Network. This study found that the audience voting and the amount of internet news articles on each participant were the main variables for predicting the winner and extended the discussion by analyzing the precision of prediction."
머신러닝 기법을 활용한 공장 에너지 사용량 데이터 분석,2019,"['Factory Energy', 'Power Consumption', 'Machine Learning', 'Factory Energy Management System', '공장에너지', '소비전력', '머신 러닝', '공장 에너지 관리 시스템']","본 연구에서는 머신 러닝 기법을 활용하여 공장에서 발생하는 에너지 사용량에 대한 데이터 분석 및 패턴 추출에 대해 다룬다. 통계학이나 기존의 방법들은 몇 가지 물리적 특성을 반영하는 수학적 모델을 구축하는 반면, 머신 러닝을 통한 접근방법은 데이터 학습을 통하여 모델의 계수들을 결정하게 된다. 기존의 방법들은 특정한 구조를 갖는 수학적 모델을 구축해야 한다는 어려움이 있으며 과연 데이터의 특징들을 잘 반영하는지에 대한 의문이 존재했다. 그러나 머신 러닝을 통한 방법은 사람이 구축하기 어려운 작업들을 용이하게 구축한다는 장점을 가지고 있기 때문에 데이터 간의 관계를 파악하기에 더 효율적이라는 장점을 가지고 있다. 공장의 에너지 소비에 직접적으로 영향을 끼치는 요소들이 존재하며 이러한 전력 소비는 시간에 따른 데이터로 나타나게 된다. 각 요소들로부터 발생하는 소비 전력을 계측하고 데이터 베이스를 구축하기 위해 각 요소에 센서를 장착하였다. 취득된 데이터에 대해 전처리 과정 및 통계적인 분석을 거친 뒤, 머신 러닝을 통해 패턴을 분석하는 과정을 거쳤다. 이를 통해 공장에서 발생하는 소비 전력 데이터에 대한 패턴 분석을 진행하였다.","This paper describes the pattern analysis for data of the factory energy consumption by using machine learning method. While usual statistical methods or approaches require specific equations to represent the physical characteristics of the plant, machine learning based approach uses historical data and calculate the result effectively. Although rule-based approach calculates energy usage with the physical equations, it is hard to identify the exact equations that represent the factory’s characteristics and hidden variables affecting the results. Whereas the machine learning approach is relatively useful to find the relations quickly between the data. The factory has several components directly affecting to the electricity consumption which are machines, light, computers and indoor systems like HVAC (heating, ventilation and air conditioning). The energy loads from those components are generated in real-time and these data can be shown in time-series. The various sensors were installed in the factory to construct the database by collecting the energy usage data from the components. After preliminary statistical analysis for data mining, time-series clustering techniques are applied to extract the energy load pattern. This research can attributes to develop Factory Energy Management System (FEMS)."
머신 러닝을 이용한 트윗 데이터의 위치 추정 연구,2019,"['트윗 데이터', '머신 러닝', '소셜 네트워크 서비스', '나이브 베이즈 분류', 'Tweet data', 'Machine learning', 'Social network service', 'Naive Bayesian classification']","공간 빅데이터 분석 과정에서 소셜 네트워크 서비스 데이터를 활용한 연구가 활발히 이루어지고 있다. 그러나 소셜 네트워크 서비스 데이터 중 위치 정보를 가진 데이터는 일부에 불과하다. 본 연구에서는 대표적인 소셜 네트워크 서비스인 트윗 데이터를 대상으로 머신 러닝 기법을 이용하여 위치 정보를 추정하였다. 서울특별시 지역의 트윗 데이터를 수집하여 머신 러닝에 필요한 훈련 데이터와 검증 데이터를 가공하고, 나이브 베이즈 분류를 적용하여 트윗 데이터의 위치를 서울특별시의 권역별로 추정하였다. 본 연구의 결과 머신 러닝을 이용하여 트윗 데이터의 위치 추정이 가능하였으며, 위치가 추정된 트윗 데이터는 지역의 특성이나 관심 분야를 분석할 때 활용될 수 있다.","In the process of analyzing spatial big data, researches using social network service data are being actively executed. However, only a part of social network service data has location information. In this study, location information was predicted using machine learning technique for tweet data, a representative social network service. By collecting tweet data of Seoul Metropolitan area, the training data and test data which is necessary for machine learning were processed, and the location of Tweet data was predicted by the Seoul Metropolitan area by applying Naive Bayesian classification. As a result of this study, it was possible to predict the location of tweet data using machine learning, and the tweet data which has predicted location can be used to analyze the characteristics and the interest by each region."
경험적 모델과 머신러닝 기법을 활용한 SNS 사용자 분류방법 비교: 플리커 데이터의 관광객 분류방법,2019,"['Flickr', 'Geotagged Photography', 'Tourist Classification', 'Empirical Model', 'Machine Learning Model', '플리커', '지오 태깅된 사진', '관Flickr', 'Geotagged Photography', 'Tourist Classification', 'Empirical Model', 'Machine Learning Model광객 구분', '경험적 모델', '기계학습 모델']","플리커는 위치, 시간, 사진 등의 정보를 포함하고 있어 관광 분야에서 활용이 높은 SNS 가운데 하나이다. 플리커 데이터를 활용하여 관광객의 특성을 분석하기 위해서는 플리커에 사진을 업로드한 사용자 가운데 관광객을 구분하는 것이 필수적이다. 실제 플리커의 메타데이타에는 사용자의 거주지 정보를 기재하게 되어 있지만 정확하게 기재한 사용자의 비율은 40% 미만이다. 본 연구는 플리커 사용자 가운데 관광객과 거주자를 구분하기 위해 경험적 모델과 기계학습 방법을 적용하고, 정확도를 평가하여 어떠한 방법을 사용할지 제안하고자 하였다. 경험적 방법에는 시간적 임계치, 최다 사진 촬영 국가, 최장 체류 국가, 최다 방문 국가를 기준으로 거주국을 추정하는 4가지 방법을, 기계학습 방법에는 로지스틱 회귀, 서포트벡터머신, 의사결정나무, 랜덤포레스트, 인공신경망 모델의 5가지 방법을 적용하였다. 적용 결과 경험적 방법에서는 최장 체류 국가를 기준으로 거주국을 추정하는 방법이, 기계학습 방법에서는 랜덤포레스트 방법이 가장 정확도가 높게 도출되었다. 그러나 관광객 구분에 있어서 정확도뿐 아니라 특이도도 주의 깊게 고려해야 할 항목임을 알 수 있었으며, 연구 목적에 따라 다른 방법이 선택될 수 있음을 제안하였다.","Flickr is one of the most utilized SNS in the field of tourism because it contains information such as location, time, and photos. In order to analyze the characteristics of tourists using Flickr data, it is essential to identify the tourists among the users who uploaded the photos to Flickr. Flicker's metadata is supposed to contain the owner’s location information, but the percentage of users accurately stated is less than 40%. The purpose of this study is to suggest a model which accurately distinguish between tourists and residents after experimenting various models. For empirical models, four methods were used to estimate the country of residence based on the time threshold, the highest photo-taking country, the longest-stay country, and the most visited country. Five machine learning methods are applied: logistic regression, support vector machine, decision tree, random forest, and artificial neural network model. As a result, the method of estimating the country of residence based on the longest stay nation in the empirical method and the random forest method in the machine learning method were found to be the most accurate. However, it was found that not only the accuracy but also the specificity should be considered carefully in the tourist category, and suggested that different methods could be selected according to the research purpose."
머신러닝을 이용한 급성심근경색증 환자의 퇴원 시 사망 중증도 보정 방법 개발에 대한 융복합 연구,2019,"['Severity-adjustment', 'Acute Myocardial Infarction', 'Comorbidity', 'Machine Learning', 'Convergence study', '중증도 보정', '급성심근경색', '동반질환', '머신러닝', '융복합 연구']","본 연구는 기존 동반질환을 이용한 중증도 보정 방법의 제한점을 보완하기 위해 급성심근경색증 환자의 맞춤형 중증도 보정방법을 개발하고, 이의 타당성을 평가하기 위해 수행되었다. 이를 위하여 질병관리본부에서 2006년부터 2015년까지 10년간 수집한 퇴원손상심층조사 자료 중 주진단이 급성심근경색증인 한국표준질병사인분류(KCD-7) 코드 I20.0~I20.9의 대상자를 추출하였고, 동반질환 중증도 보정 도구로는 기존 활용되고 있는 CCI(Charlson comorbidity index), ECI(Elixhauser comorbidity index)와 새로이 제안하는 CCS(Clinical Classification Software)를 사용하였다. 이에 대한 중증도 보정 사망예측모형 개발을 위하여 머신러닝 기법인 로지스틱 회귀분석, 의사결정나무, 신경망, 서포트 벡터 머신기법을 활용하여 비교하였고 각각의 AUC(Area Under Curve)를 이용하여 개발된 모형을 평가하였다. 이를 평가한 결과  중증도 보정도구로는 CCS 가 가장 우수한 것으로 나타났으며, 머신러닝 기법 중에서는 서포트 벡터 머신을 이용한 모형의 예측력이 가장 우수한 것으로 확인되었다. 이에 향후 의료서비스 결과평가 등 중증도 보정을 위한 연구에서는 본 연구에서 제시한 맞춤형 중증도 보정방법과 머신러닝 기법을 활용하도록 하는 것을 제안한다.","This study was conducted to develop a customized severity-adjustment method and to evaluate their validity for acute myocardial infarction(AMI) patients to complement the limitations of the existing severity-adjustment method  for comorbidities. For this purpose, the subjects of KCD-7 code I20.0 ~ I20.9, which is the main diagnosis of acute myocardial infarction were extracted using the Korean National Hospital Discharge In-depth Injury survey data from 2006 to 2015. Three tools were used for severity-adjustment method of  comorbidities : CCI (charlson comorbidity index), ECI (Elixhauser comorbidity index) and the newly proposed CCS (Clinical Classification Software). The results showed that CCS was the best tool for the severity correction, and that support vector machine model was the most predictable. Therefore, we propose the use of the customized method of severity correction and machine learning techniques from this study for the future research on severity adjustment such as assessment of results of medical service."
전력 거래량 예측에서의 머신 러닝 성능 비교,2019,"['Machine learning', 'Multi-perceptron', 'RNN', 'LSTM', 'ANFIS', 'Prediction', 'Power market 머신 러닝', '다중 퍼셉트론', '재귀 신경망', '중기 단기 기억', '퍼지추론 시스템 기반 적응 네트워크', '전력 거래량', '예측']","머신 러닝은 인력을 대체함으로써 업무 효율성을 크게 높일 수 있다. 특히 4차 산업혁명 시대의 요청에 따라 인공지능을 포함한 머신 러닝의 중요성은 점점 커지고 있다. 본 논문은 MLP, RNN, LSTM, ANFIS 신경망 알고리즘 이용하여, 월별 전력 거래량을 예측한다. 본 논문에서는 통계청에서 제공하는 월별 전력 거래량과 월별 전력 거래금액, 최종에너지 소비량, 자동차용 경유 가격에 대한 2001~2017년까지의 공공 데이터를 사용하였다. 본 논문은 제시하는 각각의 알고리즘들을 학습시키고, 알고리즘이 예측하는 시계열 그래프를 이용하여 예측 결과를 보여주고 RMSE를 이용하여 이들 중에서 가장 우수한 알고리즘 제시한다.","Machine learning can greatly improve the efficiency of work by replacing people. In particular, the importance of machine learning is increasing according to the requests of fourth industrial revolution. This paper predicts monthly power transactions using MLP, RNN, LSTM, and ANFIS of neural network algorithms. Also, this paper used monthly electricity transactions for mount and money, final energy consumption, and diesel fuel prices for vehicle provided by the National Statistical Office, from 2001 to 2017. This paper learns each algorithm, and then shows predicted result by using time series. Moreover, this paper proposed most excellent algorithm among them by using RMSE."
머신러닝 기반의 폐가전제품 무상방문수거 서비스 수거시간 수준 예측 방법론,2019,"['Free Visit and Pickup', 'Genetic Algorithm', 'Machine Learning', 'Grid-Search', 'F1 Score', 'Hyperparameter']",,"The Free Visit and Pickup Service collection drivers have been getting paid the national standard price for collecting End-of-Life (EOL) Consumer Electronics (CE) which is causing a deviation in wages and labor. In this study, 18 different factors affecting the collection of EOL CE was selected as the independent variable. The experiment was conducted to predict the collection time levels classified into five categories using machine learning models. In order to improve the performance levels of the models, variables were selected using genetic algorithm. As a result, 7 of 18 independent variables were selected for the study. The machine learning models used were Decision Tree, Random Forest, Gradient Boosting, Support Vector Classification, and Multi-Layer Perception, while the Hyper parameter was set based on the Grid search. The evaluation index used the F1 Score due to the data imbalance and the results identified the MLP model to have the highest F1 Score of 0.651."
머신러닝 알고리즘의 데이터 처리에 대한 법적 제한의 한계 :개인정보보호와 차별금지의 측면에서,2019,"['머신러닝 알고리즘', '통계적 데이터 분석', '개인정보보호', '차별금지', '인공지능 에이 전트의 법적 책임', 'Machine Learning Algorithm', 'Statistical Data Analysis', 'Data Privacy', 'Anti-Discrimination', 'Legal Responsibility to AI Agent']",,"This article addresses the issues of how the evolution of machine learning field has an impact on the legal system. In the area of automated data processing, a legal model for data privacy protection is applied in a manner that regulates the collection and use of personal data. This model assumes primarily with the personal identification or identifiability. However, if we look closely at the process of collecting and using these data, we can confirm that the legal model for anti-discrimination based on the principle of anti-classification can also be applied in an overlapping manner. I analyze several legal cases in order to identify the overlapping points. In each cases, there are some legal issues about automated data processing for data privacy and/or anti-discrimination. Data processing performed by machine learning algorithm which is trained with dataset, is divided into three steps: collection(or selection), analysis, and application. Based on these distinctions, limitations of legal regulations for data processing that can be encountered in each step are reviewed through models for data privacy protection and anti-discrimination."
불균형 데이터 환경에서 가계부채 상환연체 분류를 위한 머신러닝의 활용,2019,"['가계부채', '불균형 데이터', '상환연체', '머신러닝', '샘플링', 'Household Debt', 'Imbalanced Data', 'Household Insolvency', 'Machine Learning', 'Sampling']",,"This study aims to detect households at high risk of insolvency using The Survey of Household Finances and Living Conditions in 2018. For that purpose, this study uses two machine learning classifiers, Logistic Regression and Decision Tree model for binary classification. As a result of the descriptive statistics, the proportion of the household which fall behind on their debt payment, which can be regarded as households with a high risk of insolvency, accounted for about 11%. It is well known that when the proportion of one class in a dataset is dominant, the prediction performance of classifiers become problematic. It causes the machine learning classifiers to be more biased toward dominant classes. In order to address the degree of imbalance of two classes in data sets, several sampling methods were considered. This study found that Over-sampling techniques achieve in better prediction performance with a higher sensitivity. Based upon the sensitivity and ROC curve of the two techniques, the logistic regression model performed better than the decision tree model."
머신 러닝을 이용한 경제분석,2019,"['인공 지능', '머신 러닝', '지도 학습', '빅데이터', 'AI (Artificial Intelligence)', 'ML (Machine Learning)', 'supervised learning', 'big data']","본 논문은 경제학 전공자를 대상으로 인공 지능을 구현하는 핵심 기법인머신 러닝의 개념과 주요 방법론, 경제학과 경제에 미치는 영향을 개괄적으로 소개하고자 한다. 먼저 머신 러닝의 주요 범주인 지도 학습, 비지도학습, 강화 학습의 개념을 소개하고 기존 계량경제학 접근법과의 차이점을설명한다. 그리고 학계와 산업계에서 널리 연구되고 활용되는 지도 학습분야에서 분류 및 회귀를 위해 사용되는 주요 방법론을 예를 통해 설명한뒤 머신 러닝 기법이 활용된 경제학 분야의 최신 연구들, 노동시장에 미치는 영향, 데이터의 가치를 둘러싼 논쟁에 대해 살펴본다.","With the development of various AI (Artificial Intelligence) techniques and increased availability of big data, ML (Machine Learning) is expected to become the essential technology that would affect many aspects of our economy and society. With this in mind, the purpose of this paper is to provide an overview of ML techniques with emphasis on its application to economics.Contrasting the key differences in ML techniques and econometric methodologies, we first explain the key techniques used in supervised learning, which are widely used in industry and academia. Then we provide a survey of recent economic research that uses ML techniques and introduce debates on its impact on labor market and the value of data. We conclude with discussing the current limitations of ML technique in terms of economic research, while we believe that ML will fruitfully complement the current methodologies of economics."
머신러닝 기법을 적용한 기업 구성원의 직무만족 및 조직몰입에 영향을 미치는 요인 탐색,2019,"['조직만족', '직무몰입', '머신러닝', 'job satisfaction', 'organizational commitment', 'machine learning']","본 연구는 한국직업능력개발원의 인적자본기업패널(HCCP) 7차년도 데이터를 활용하여 기업 구성원의 직무만족 및 조직몰입에 영향을 미치는 요인을 탐색하는 데 목적이 있다. 이를 위해 본 연구는기업 구성원의 직무만족 및 조직몰입에 따른 잠재프로파일을 분류하였으며, 직무만족 잠재프로파일및 조직몰입 잠재프로파일 예측을 위해 LASSO, Ridge, Randomforest, Support Vector Machine 등 4 가지 머신러닝 기법을 적용하였다. 분석결과, 첫째, 직무만족과 조직몰입은 각각 3개의 잠재프로파일로 구분되었다. 직무만족의 경우 각 잠재프로파일의 특징에 따라 ‘중간 직무만족 집단(계층 1)’, ‘낮은직무만족 집단(계층 2)’, ‘높은 직무만족 집단(계층 3)’으로 명명하였다. 조직몰입도 ‘낮은 조직몰입 집단(계층 1)’, ‘높은 조직몰입 집단(계층 2)’, ‘중간 조직몰입 집단(계층 3)’으로 구분되었다. 둘째, 직무만족과 조직몰입 계층을 예측하는데 Randomforest의 예측정확도가 각각 70.1%와 69.3%로 가장 높았다. 셋째, Randomforest로 직무만족과 조직몰입에 영향을 미치는 주요 변수를 탐색한 결과, 직무만족의경우 연간 총 근로소득, 출생년도, 기업과 근로자의 커뮤니케이션 및 신뢰관계, 주당 평균 초과 근로시간, 스트레스 등의 변수가 도출되었다. 조직몰입도 기업과 근로자의 커뮤니케이션 및 신뢰관계, 연간 총 근로소득, 출생년도, 주당 평균 초과 근로시간 등과 같은 변수가 선택되었다. 마지막으로 본 연구결과를 바탕으로 직무만족 및 조직몰입 향상을 위한 다양한 시사점을 제공하였다.","The purpose of this study was to explore factors affecting job satisfaction and organizational commitment of employees using 7th wave of Human Capital Corporate Panel(HCCP) data. To do this, this study was to classify latent profiles based on job satisfaction and organizational commitment, and to apply four machine learing techniques(LASSO, Ridge, Randomforest and Support Vector Machine) to predict the identified latent profiles. As results, first, three different latent profiles were identified based on job satisfaction (middle job satisfaction, low job satisfaction and high job satisfaction) and three latent profiles were also identified based on organizational commitment(low organizational commitment, high organizational commitment, and middle organizational commitment). Second, Randomforest performed better than other techniques. Third. randomforest result revealed that main factors affecting job satisfaction were the annual earned income, year of birth, communication and trust relationship between the company and the worker, overtime work, stress and etc. For organizational commitment, communication and trust relationship, annual earned income, year of birth and overtime work were selected. Finally, based on the results, this study suggested implications to improve the employees’ job satisfaction and organizational commitment."
머신 러닝을 활용한 IDS 구축 방안 연구,2019,"['IDS', 'machine learning', 'cyber attack', 'big data', 'security', '침입탐지시스템', '기계학습', '사이버공격', '빅데이터', '보안']",,"Computing systems have various vulnerabilities to cyber attacks. In particular, various cyber attacks that are intelligent in the information society have caused serious social problems and economic losses.Traditional security systems are based on misuse-based technology, which requires the continuous updating of new attack patterns and the real-time analysis of vast amounts of data generated by numerous security devices in order to accurately detect. However, traditional security systems are unable to respond through detection and analysis in real time, which can delay the recognition of intrusions and cause a lot of damage. Therefore, there is a need for a new security system that can quickly detect, analyze, and predict the ever-increasing cyber security threats based on machine learning and big data analysis models. In this paper, we present a IDS model that combines machine learning and big data technology."
머신러닝 기반의 호우피해 발생확률 예측 모형 개발,2019,"['Machine Learning', 'Disaster Management', 'Natural Disaster', 'PM-HDOP', '머신러닝', '재난관리', '자연재난', '호우피해 발생확률 예측 모형']","본 연구에서는 수도권 지역을 대상으로 사전에 피해 발생 여부를 파악하기 위하여 머신러닝 기반의 호우피해 발생확률 예측 모형을 개발하였다. 종속변수로써 활용하는 호우피해 자료와 독립변수로써 활용하는 강우자료를 수집하였고, 학습기간(2005-2016)과 평가기간(2017)으로 자료를 구분하였다. 로지스틱 회귀모형, 인공신경망, 배깅, 랜덤포레스트, 부스팅 등의 머신러닝 기법들을 적용하여 모형을 개발하였다. 평가기간의 자료를 이용하여 각 모형들에 대해 피해 발생 여부를 예측하고, F1-Score를 통해 성능이 가장 우수한 모형을 선별하였다. 그 결과 경기도 지역과 서울 지역에서는 부스팅이 가장 우수한 성능을 보였고, 인천 지역에서는 배깅이 가장 우수한 성능을 나타냈다. 본 연구 결과를 활용하여 현재 국내에서 서비스되고 있지 않는 호우피해 발생 예측에 대한 서비스가 이루어진다면, 사전 대비 차원의 재난관리를 통해 효과적으로 피해를 저감할 수 있을 것이다.","In this study, a prediction model (heavy rain damage occurrence probability or PM-HDOP) was developed for a metropolitan area.The heavy rain damage and rainfall data were collected as dependent and independent variables, respectively. The dataset was divided into training (2005-2016) and test sections (2017). We developed the PM-HDOP using machine learning methods such as logistic regression, artificial neural network, bagging, random forest, and boosting to predict the occurrence of nonlinear natural disasters. An architectural model with the best performance was selected, and the PM-HDOP was subsequently used to predict the probability of occurrence. As a result, a boosting scheme showed the best performance in Gyeonggi-do and Seoul, and a bagging scheme showed the best performance in Incheon. If the results of this study are used to predict the occurrence of heavy rain damage, which is not currently being serviced in Korea, it is possible to effectively reduce the damages."
머신러닝 기법을 활용한 호텔산업 경기 동향 예측 연구,2019,"['호텔산업', '경기동향', '머신러닝', '벡터머신', 'Hotel Industry', 'Economic Trend', 'Machine Learning', 'Vector Machine']",,"For more accurate prediction of the future condition, various methods and approaches have been continuously studied throughout the most of areas. Especially in the business field which has characteristics of monetary value and rapid change related, the future prediction becomes the regular issues for solving.Hotel industry is one of the main areas to estimate and predict the economic trend due to the complexity of changes relation with each country’s economic condition and relationships among the countries. But most of relevant researches for predictive modeling are depending on the some assumptions which are sometimes unstable and improper.This study suggests the prediction model using the updated methodology so-called machine learning which is free from the assumptions. Among the machine learning methodologies, well-known and proper technique for the trends forecasting, support vector machine is applied with several parameters and also data based solution approach is suggested with prediction error comparison"
머신러닝 기반 체지방 측정정보를 이용한 고콜레스테롤혈증 예측모델,2019,"['머신러닝', '데이터마이닝', '예측모델', '콜레스테롤', '고콜레스테롤혈증', '고콜레스테롤', '체지방', 'Machine learning', 'Data mining', 'prediction model', 'Cholesterol', 'Hypercholesterolemia', 'High cholesterol', 'Body fat mass']","본 연구의 목적은 기존의 body fat mass 변수와 고콜레스테롤혈증의 연관성연구를 벗어나, 머신러닝기법을 기반으로 body fat mass 변수들의 조합을 이용하여 고콜레스테롤혈증 예측 모델을 개발하는 것이다. 이러한 연구를 위하여 국민건강영양조사 데이터를 기반으로 두 가지 variable selection 메소드와 머신러닝 알고리즘을 이용하여 총 6개의 모델을 생성하였고 질병 예측력을 비교분석하였다. 여러 body fat mass 관련 변수들 중에서 몸통지방량 변수가 고콜레스테롤혈증 예측력이 가장 우수한 변수인 것을 밝혀내었고, 머신러닝 기반 예측모델들 중에서 correlation-based feature subset selection 기반 naive Bayes 알고리즘을 이용한 모델이 0.739의 the area under the receiver operating characteristic curve 값과 0.36의 Matthews correlation coefficient 값을 얻었다. 이러한 연구의 결과는 향후 국내외 대규모 스크리닝 및 대중보건 연구에서 질병예측분야의 중요정보로 활용될 것으로 예상한다.","The purpose of the present study is to develop a model for predicting hypercholesterolemia using an integrated set of body fat mass variables based on machine learning techniques, beyond the study of the association between body fat mass and hypercholesterolemia. For this study, a total of six models were created using two variable subset selection methods and machine learning algorithms based on the Korea National Health and Nutrition Examination Survey (KNHANES) data. Among the various body fat mass variables, we found that trunk fat mass was the best variable for predicting hypercholesterolemia. Furthermore, we obtained the area under the receiver operating characteristic curve value of 0.739 and the Matthews correlation coefficient value of 0.36 in the model using the correlation-based feature subset selection and naive Bayes algorithm. Our findings are expected to be used as important information in the field of disease prediction in large-scale screening and public health research."
머신러닝을 통한 건축 도시 데이터 분석의 기초적 연구 - 딥러닝을 이용한 유동인구 모델 구축 -,2019,"['Machine learning', 'Deep learning', 'ANN', 'Urban planning', '머신러닝', '딥러닝', 'ANN', '도시 계획', '건축 계획']",,"In this paper, we construct a prototype model for city data prediction by using time series data of floating population, and use machine learning to analyze urban data of complex structure. A correlation prediction model was constructed using three of the 10 data (total flow population, male flow population, and Monday flow population), and the result was compared with the actual data. The results of the accuracy were evaluated. The results of this study show that the predicted model of the floating population predicts the correlation between the predicted floating population and the current state of commerce. It is expected that it will help efficient and objective design in the planning stages of architecture, landscape, and urban areas such as tree environment design and layout of trails. Also, it is expected that the dynamic population prediction using multivariate time series data and collected location data will be able to perform integrated simulation with time series data of various fields."
비지도학습 머신러닝에 기반한 베타파 상관관계 분석모델,2019,"['뇌파 파형', '베타파', '머신러닝', '비지도학습', 'KMeans', 'Machine Learning', 'Unsupervised Learning', 'KMeans', 'SPARK', 'EEG']","뇌파 파형중 베타파를 이용한 인간의 인지상태를 판별한다. 베타파는 인간의 인지상태중 스트레스 영역에 해당하는 특성이 있고, 이 영역에서 스트레스의 오버대역폭을 추출하기 위해서 저대역폭과 고대역폭 사이의 베타파간 상관관계를 분석해야 한다. 그러므로 본 논문에서는 효과적으로 베타파 상관관계를 분석하고 추출하기 위해 비지도학습 머신러닝을 이용한 Kmean 클러스터링 분석모델을 제시한다. 제시된 모델은 베타파 영역을 유사한 영역의 클러스터 군으로 분류하고 해당 클러스터링 범주에서 이상파형을 판별한다. 이상파형 판별을 위해 클러스터군의 밀집도와 정상범주 이탈영역을 기준으로 스트레스 위험군을 판별하고 판별된 스트레스 위험군에 대한 대처방안을 제공할 수 있다. 제시된 모델을 활용하면 뇌파파형을 통한 인지상태의 스트레스 지수분별이 가능하고, 개인의 인지상태에 대한 관리 및 응용이 가능하다. 또한 스트레스와 오피스증후군을 갖는 사람들에게 뇌파관리를 통해 개인의 삶에 대한 질적 향상에 도움을 준다.","The characteristic of the beta wave among the EEG waves corresponds to the stress area of ​​human perception. The over-bandwidth of the stress is extracted by analyzing the beta-wave correlation between the low-bandwidth and high-bandwidth. We present a KMeans clustering analysis model for unsupervised machine learning to construct an analytical model for analyzing and extracting the beta-wave correlation. The proposed model classifies the beta wave region into clusters of similar regions and identifies anomalous waveforms in the corresponding clustering category. The abnormal group of waveform clusters and the normal category leaving region are discriminated from the stress risk group. Using this model, it is possible to discriminate the degree of stress of the cognitive state through the EEG waveform, and it is possible to manage and apply the cognitive state of the individual."
베이지안 추론과 정규화를 이용한 회귀 머신러닝,2019,"['Bayesian Statistics', 'Machine Learning', 'Deep Learning', 'Patent Keyword Data', 'Technology Analysis', '베이지안 추론 및 정규화', '신경망', '회귀분석', '머신러닝', '심층학습', '딥러닝']","최근 심층학습에 기반 한 신경망 모형이 기존의 머신러닝 알고리즘을 대체하고 있다. 특히 컴퓨터비전, 자연어처리 등이미지와 음성 인식 문제를 위한 분류 작업에서 매우 우수한 성능을 보여주고 있다. 하지만 신경망 모형의 구조에서 은닉층을심층적으로 디자인함으로써 기존의 신경망에 비하여 더 많은 계산시간이 필요하게 되는 어려움이 있다. 분류문제가아닌 회귀문제에 있어서도 같은 문제가 있다. 이와 같은 심층 신경망에 비하여 본 연구에서 제시하는 베이지안 신경망은하나의 은닉층만을 사용하고 베이지안 추론 및 정규화를 이용하여 신경망 모형의 예측력을 유지하면서 동시에 계산시간을단축시키는 결과를 얻기 위하여 노력한다. 즉, 신경망 모형의 가중치를 모수의 사전 및 사후 분포를 이용하여 갱신한다.모의실험 데이터를 이용하여 베이지안 신경망과 심층 신경망의 예측의 정확성과 계산시간을 비교하여 제안 방법의 타당성을보인다","Recently, the neural network models based on deep learning are replacing the existing machine learning algorithm. In particular, they show excellent performance in classification tasks for image and speech recognition problems such as computer vision and natural language processing. However, because of the large size of hidden layer, the deep neural network model has a difficulty that requires more computation time than the conventional neural networks. The same problem exists for regression problems that are not classification problems. Compared with such deep neural networks, the Bayesian neural network proposed in this study uses only one hidden layer and uses Bayesian inference and regularization to maintain the predictive power of the neural network model while reducing the computation time. That is, the weights of the neural network model are updated by using the prior and posterior distributions of parameters. By using the simulation data, we compare the accuracy and computation time of Bayesian neural networks and deep neural networks to show the validity of the proposed method"
다양한 종류의 예측에서 머신러닝 성능 비교,2019,"['Artificial Intelligence', 'Machine learning', 'Prediction', 'K-nearest neighbors 인공 지능', '머신 러닝', '예측', 'K-최근접 이웃']","현재 인공지능의 한 영역인 머신러닝을 적용하여 다양한 예측을 수행하고 있으나 실제 현장에서 어떤 종류의 알고리즘을 사용하는 것이 가장 좋은 방법인지는 늘 문제가 된다. 본 논문은 여러 머신러닝 지도 학습 알고리즘을 이용하여 월별 전력 거래량, 전력 거래금액, 월별 생산 확산 지수, 최종 에너지 소비, 자동차용 경유를 예측하여 각 경우에 어떤 알고리즘이 가장 적합한 알고리즘인지를 알아본다. 이를 위해 통계청에 나와 있는 월별 전력 거래량과 월별 전력 거래금액, 월별 생산 확산 지수, 최종에너지 소비, 자동차용 경유로 머신 러닝이 예측하는 값의 확률을 보여주고 각각의 예측값을 평균화 하여 이들 중에서 어떤 기법이 가장 우수한 기법인지를 확인한다.","Now a day, we can perform various predictions by applying machine learning, which is a field of artificial intelligence; however, the finding of best algorithm in the field is always the problem. This paper predicts monthly power trading amount, monthly power trading amount of money, monthly index of production extension, final consumption of energy, and diesel for automotive using machine learning supervised algorithms. Then, we find most fit algorithm among them for each case. To do this we show the probability of predicting the value for monthly power trading amount and monthly power trading amount of money, monthly index of production extension, final consumption of energy, and diesel for automotive. Then, we try to average each predicting values. Finally, we confirm which algorithm is the most superior algorithm among them."
Big 5 성격 요소와 머신 러닝 알고리즘을 통한 창의적인 사람들의 특징 연구,2019,"['Big 5', 'WEKA', 'Datamining', 'Machine Learning', 'Select attributes']","창의적인 사람에 대한 정확한 기준이나 수치화를 사용하여 체계적인 분류와 분석 방법이 없었기에 정의하는 데에어려움이 많다. 이 문제를 해결하기 위하여 본 연구에서는 창의적인 사람을 어떻게 구분 지을 수 있을지에 대한 것과 어떤유사한 성격이 있는지 분석한다. 본 연구에서 우선 Big 5 성격 특성 기법을 이용하여 설문조사를 진행하고, 그 설문조사로얻은 데이터 세트를 가지고 데이터 마이닝 도구인 WEKA를 이용하여 데이터 세트를 분류하고 분석한 뒤, 창의적인 사람들과연관성 있는 성격 특징들을 다양한 머신 러닝 기법을 이용하여 분석하는 것을 목표로 진행하였다. 7개의 특징 선택 알고리즘을 활용하고, 특징 선택 알고리즘들로 분류된 특징 집단을 선택하여 머신 러닝 알고리즘에 적용하여 정확도를 알아냈고, 서포트 벡터 머신을 통해 나온 특징이 가장 높은 분류 결과를 도출하였다.","There are many difficulties to define because there is no systematic classification and analysis method using accurate criteria or numerical values for creative people. In order to solve this problem, this study attempts to analyze how to distinguish creative people and what kind of personality they have when distinguishing creative people. In this study, I first survey the Big 5 personality trait, classify and analyze the data set using the data mining tool WEKA, and then analyze the data set related to the creativity The goal is to analyze the features using various machine learning techniques. I use seven feature selection algorithms, select feature groups classified by feature selection algorithms, apply them to machine learning algorithms to find out the accuracy, and derive the results."
센서 어레이 시스템과 머신러닝을 이용한 차량 냄새 정량화 연구,2019,"['Measuring Odor Of Vehicle', 'Sensor-Array', 'Electronic Nose', 'Machine Learning']",,"Purpose: This study presents a method to quantify vehicle odors from interiors of new vehicles and air conditioners of old vehicles using machine learning with a sensor array system we named electronic nose.Methods: We developed a sensor array system (electronic nose) with 17 kinds of sensors that can detect major odors and harmful substances from vehicles. Odors from new vehicles’ interiors and old vehicles’ air conditioners, which are representative odors generated in vehicles, were measured by the sensor array system. K-means clustering algorithm of unsupervised learning and MLP ANN algorithm of supervised learning were applied to analyze odor data.Result: The sensor array based electronic nose and machine learning method were applied to obtain the results of clustering and intensity classification of vehicle odors.Conclusion: Time series data of odors from air conditioner and interiors of new cars were divided into ten species of odor by K-means clustering. Intensity of odor as sensed by human are classified into three levels by applying MLP ANN."
"융자성 기금관리를 위한 블록체인, 머신러닝 설계 연구",2019,,,"The government has operated financing fund under the National Finance Act for the smooth conduct of national policy. But, It is exposed to problems such as the possibility of abuse of fund and the lack of after-loan management. In this paper, It uses fintech such as the blockchain and machine learning to solve these problems. The fund operation procedure is designed as a consortium blockchain, and it suggests the application of PBFT negotiation algorithm and the smart contract. In case of the fund management, it suggests utilizing multilayer artificial neural network model of machine learning and a module of result interpretation. The introduction of this research approach will improve the transparency and efficiency of the financing fund, ensure the credibility and also contribute to the improvement of the fund management and the establishment of the fund policy."
레일 표면조도 데이터를 활용한 머신러닝 기반 전동소음 예측,2019,"['전동소음', '레일 표면조도', '기계학습', '레일 음향조도', '의사결정트리', 'Rolling noise', 'Surface roughness', 'Machine learning', 'Acoustic roughness', 'Decision tree']",,"In the measurement and analysis of railway noise and vibration, since rolling noise is the key element in thevarious noise sources, its prediction and sound pressure level analysis should be conducted through accurate measurement.In order to predict rolling noise precisely during railway vehicle operation, we have in this paper aggregated railsurface roughness data on various railway track sections and applied intelligent machine learning algorithms based onthe measured and collected data set. Particularly, acoustic roughness level was classified using supervised learningmethod according to the International Standard criteria, and data preprocessing techniques including feature engineering,Exploratory data analysis (EDA) and correlation analysis were applied to the machine learning algorithm. Furthermore,through model performance analysis, the decision tree method was selected as the optimal model. As a result, wehave verified that optimization using a pruning technique can improve the accuracy of rolling noise prediction with thesurveyed data set."
머신러닝을 활용한 대청수계 취수원 냄새물질 예측,2019,"['Artificial neural network', 'Machine Learning', 'Odor compounds forecasting', 'Random Forest']",,"The contamination of source water by odor compounds are one of the problems related to the water quality management, especially in Daecheong Reservoir, South Korea issued an algal alert system anually. This study investigated the efficiencies of 4 machine learning models, including Multi-parameter Regression Analysis(MRA), Decision Tree(DT), Artificial Neural Network (ANN) and Random Forest (RF), for odor compounds forecasting(Geosmin, 2-MIB) in the Daecheong Water Intake Station, where supply water treatment plants to source water. The models based on input variables considered correlation between target output and water quality parameter and hydrologic‧meteorological factors. The established models showed good results between observed and simulated values. For Geosmin models, ANN produced better forcasting results than others. RF showed the best results for 2-MIB models. These results and models are applied in work-site operations through the Daecheng Intergreted Water Quality Forecasting System since September, 2018."
LCD 검사 공정에서 가상 계측을 위한 머신 러닝 기반 예측 모델,2019,"['Virtual Metrology', 'LCD', 'Machine Learning', 'Prediction Model']",,"This paper proposes a machine learning based prediction model construction methodology for the virtual metrology in LCD manufacturing processes. The proposed prediction model construction methodology consists of four major steps; 1) data preprocessing, 2) feature selection, 3) deep learning model design, and 4) model validation. To extraction effective predictor variables at the feature selection stage, this paper employs three techniques including relative weight method, random forest method, and genetic algorithm. The constructed prediction model has been applied to LCD manufacturing data, and shows reasonably acceptable prediction accuracy which is higher than 90%."
아파트 가격 지수 산출에 관한 연구: 머신러닝 알고리즘을 중심으로,2019,"['머신러닝', '평활화', '금융위기', '반복매매모형', '가격지수', 'Machine Learning', 'Smoothing', 'Financial Crisis', 'Repetitive Trading Model', 'Price Index']","아파트 가격 지수가 정책 의사결정자에게 제공하는 정보의 적절성과 정확성은 매우 중요하다.하지만, 기존에 사용되어지고 있는 한국감정원(KAB) 아파트 가격 지수는 지역적 세분화, 외부요인의 미반영, 평활화(Smoothing) 문제 등 반복매매모형으로 인한 문제점을 가지고 있다. 이러한문제점은 선행연구에서도 인식되었지만 여전히 지역적 세분화 및 외부 요인은 반영은 고려하지않았다. 따라서, 본 연구에서는 서울시 공공데이터를 활용하여 주택 대출 금리, 자살율, 노인인구비율을 수집하였다. 이외에도 구면기하 삼각함수를 이용한 인근 지하철의 수와 같은 다양한외부 변수들을 활용해 지역별로 세분화하여 아파트 가격 지수에 반영하고자 하였다. 다음으로, 반복매매모형의 한계를 고려해 751,537개의 아파트 실거래 가격을 훈련데이터와 테스트데이터로각각 7:3의 비율로 나눈 후 다양한 머신러닝 알고리즘을 활용해 예측한 결과 그라디언트 부스팅모형(GBM)의 RMSE가 0.143으로 가장 낮게 나타났다. GBM 지수를 통해서 일부 투기지역에서부동산 규제 정책이나 금융위기 상황 속에서도 꾸준히 아파트 가격이 상승하는 이유를 아파트외부 변수들에 있음을 확인하였다. 또한, 부분조정 회귀모형을 통해 평활화 현상을 진단한 결과KAB 지수가 GBM 지수보다 크게 나타나고 있음을 살펴보았다. 이를 통해, GBM 지수를 아파트가격에 대한 지수로 사용한다면 다양한 금융상황 속에서 부동산 정책을 수립하는데 도움이 될수 있을 것이라고 기대된다.","The adequacy and accuracy of the information provided by the apartment price index to policy decision makers is critical. However, the previously used apartment price index of the Korea Appraisal Board (KAB) has problems due to repeated selling models, including regional segmentation, non-reflection of external factors, and smoothing problems.These problems were also recognized in the preceding study, but still regional segmentation and external factors were not taken into account Therefore, in this study, the rate of housing loans, suicide rate, and the ratio of senior citizens were collected using the public data of the Seoul Metropolitan Government. In addition, various external variables, such as the number of nearby subway stations using spherical substrates, were used to divide them into regions and reflect them in the apartment price index.Next, the actual transaction price of 751,537 apartments was divided by training and test data at a ratio of 7:3, respectively, and the RMSE of the gradient boosting model (GBM) was the lowest at 0.143.Through the GBM index, it was confirmed that the factors behind the steady rise in apartment prices in some speculative areas, even in the midst of real estate regulation policies and financial crisis situations, are the reasons for the apartment’s external variables outside In addition, after diagnosing smoothing through the partial adjustment regression model, the KAB index was found to be larger than the GBM index. By doing so, it is expected that the use of the GBM index as an index for apartment prices could help establish real estate policies amid various financial situations."
머신러닝을 이용한 반도체 웨이퍼 평탄화 공정품질 예측 및 해석 모형 개발,2019,"['Machine Learning', 'Prediction', 'Classification', 'Process Quality Interpretation', 'CMP', 'Wafer', '머신러닝', '예측', '분류', '공정 품질 해석', 'CMP', '웨이퍼']","반도체 웨이퍼의 표면을 연마하여 평탄화하는 Chemical Mechanical Planarization(CMP) 공정은 다양한 화학물질과 물리적인 기계장치에 의한 작용을 받기 때문에 공정을 안정적으로 관리하기 힘들다. CMP 공정에서 품질 지표로는 Material Removal Rate(MRR)를 많이 사용하고, CMP 공정의 안정적 관리를 위해서는 MRR을 예측하는 것이 중요하다. 본 연구에서는 머신러닝 기법들을 이용하여 CMP 공정에서 수집된 시계열 센서 데이터를 분석하여 MRR을 예측하는 모형과 공정 품질을 해석하기 위한 분류 모형을 개발한다. 나아가 분류 결과를 분석하여, CMP 공정 품질에 영향을 미치는 유의미한 변수를 파악하고 고품질을 유지하기 위한 공정 조건을 설명한다.",
머신 러닝을 통한 PIC 보의 강도 최적화,2019,"['k-NN Classification', 'Triaxiality', '3 Point Bending Analysis', 'k-NN 분류', '3축 특성', '3점 굽힘 해석']","PIC(Piecewise Integrated Composite) 보는 인장, 전단, 압축과 같은 하중 유형에 따라 구간을 나누어, 각 부분마다 복합재료의 적층 순서를 다르게 하여 조합한 보이다. 본 연구는 PIC 보의 구간을 머신 러닝을 통해 나누어 단일 적층 순서로 이루어진 보에 비해 우수한 충돌 특성을 갖게 하는 것이 목적이다. 먼저, 인장시험을 통하여 알루미늄 시편의 3축 특성(triaxiality)을 분석하였고, 알루미늄 보의 3점 굽힘 시, 하중 유형을 분석하기 위하여 3축 특성을 고려한 유한요소 해석이 수행되었다. 하중 유형 분석은 보의 전체 요소가 아닌 참조점에서의 3축 특성에 의해 판단되며, 참조점을 기반으로 k-Nearest Neighbor 분류를 보의 각 면에 대해 적용하여 어느 하중이 지배적인지 나누었다. PIC 보는 각 면을 지배적인 하중에 따라 적층 순서가 정해지도록 나누어 조합하였으며, PIC 보에 대한 유한요소 해석을 진행한 결과, 단일 적층 순서로 이루어진 보에 비해 흡수에너지와 최대하중이 커지는 특성을 보였다.","Piecewise integrated composite (PIC) beam is composed of several parts each of which has stacking sequence according to the dominant load among compression, tension and shear forces. The aim of current study is to divide PIC beam into several parts to have different stacking sequences through machine learning to have superior crashworthiness. Stress triaxiality was obtained through tensile tests of aluminum specimens. Three point bending analysis for aluminum beam using finite element method was done and the dominant loading type was determined based on triaxiality at reference points. Then, k-nearest neighbor classification model was built to divide the each face of the beam into tension, compression and shear dominant areas. By applying this model to PIC beam, it was found that PIC beam has higher absorbed energy and maximum loading than the uni-modal stacking sequence composite beam."
머신 러닝을 이용한 인공지지체 기공 크기 예측 모델에 관한 연구,2019,"['3D Printer', 'Machine Learning', 'Pore', 'Precision', 'Scaffold']",,"In this paper, We used the regression model of machine learning for improve the print quantity problem when which print scaffold with 400 ㎛ pore using FDM 3d printer. We have difficult to experiment with changing all factors in the field. So we reduced print quantity by selected two factors that most impact the pore size. We printed and measured scaffold 5 times under same conditions. We created regression model using scaffold pore size and print conditions. We predicted pore size of untested print condition using the regression model. After print scaffold with 400 ㎛ pore, we printed scaffold 5 times under same conditions. We compare the predicted scaffold pore size and the measured scaffold pore size. We confirmed that error is less than 1 % and we verified the results quantitatively."
초기 뇌졸중 검출을 위한 머신러닝 기반 시진분석모델,2019,"['Stroke Detection', 'AAM', 'Machine Learning', 'Face Feature Detection', '뇌졸중 검출', 'AAM', '머신러닝', '얼굴 특징 검출']","본 논문에서는 초기 뇌졸중 증상을 판단하기 위하여 얼굴의 좌/우 대칭 정도와 양 팔의 움직임을 시진 정보를 통하여 자동으로 분석할 수 있는 모델을 제안한다. 본 논문에서 제안하는 모델은 환자의 얼굴 영상과 팔의 움직임 동영상을 분석하여 뇌졸중 초기 증상 여부를 판단하고 의사에게 이러한 정보를 제공 하여 빠른 판단이 필요한 뇌졸중 진단에 보조적인 도움을 줄 수 있으며, 뇌졸중 환자 100명을 대상으로 한 실험 결과 90%이상의 검출 정확도를 보였다.","In this paper, we propose a model that can automatically analyze the degree of left / right symmetry of the face and both arms. The proposed model analyzes the patient's facial image and motion video of the arm to determine whether it is an early symptom of stroke and provides this information to the physician to assist in the diagnosis of stroke requiring quick judgment. The results of experiments on 100 subjects showed detection accuracy of more than 90%"
머신러닝 기술을 사용한 비트코인 특성들의 비트코인 가격에 미친 영향 분석,2019,"['비트코인', '블록체인', '머신러닝', '예측분석', '다항 회귀', 'bitcoin', 'blockchain', 'machine learning', 'analysis of prediction', 'polynomial regression']","2009년에 처음 소개된 비트코인은 전 세계적으로 출시되어있는 암호 화폐들 중 가장 대중적이다. 출시 될 당시에 가치는 아주 낮았고, 다른 암호 화폐처럼 대중적이지도 않았다. 비트코인에 오늘날 많은 사람들이 관심을 가지고 있다. 비트코인은 일반 화폐와 교환될 수도 있고 지불 용도로 사용할 수도 있다. 비트코인은 많은 온라인 상점들과 온라인 서비스에서 통용되고 있다. 암호 화폐는 특정 당국에 의해 규정되지 않고 일반적인 수요와 공급에 따라 규정되지도 않는다. 비트코인은 최근에 상당한 성공을 이루었다. 비트코인 가격이 어느 주요한 요소들에 의해 결정되는지에 대한 호기심이 본 연구를 진행하게 되었다.가장 대중적인 비트코인 디지털 월렛(www.blockchain.com) 으로부터 Blockchain Wallet API에 기반해서 데이터셋으로부터 특징들을 뽑았다. 머신러닝 기법으로 polynomial regression을 이용하여 특징들의 영향도를 계산하였다. 결과적으로 어떤 특징들이 비트코인 가격 변동과 연관이 깊은지 살펴봤다.","Bitcoin (BTC ticker) is the most popular crypto-currency in the world, the first release of which took place in 2009. In this respect, in a release date for this currency the price was equal basically to none and was not considered as popular as other known crypto-currency available at the time. Today bitcoin is in high demand from users around the globe. It can be exchanged through special exchanges for ordinary money, or used directly as a means of payment for anything of choice by the users. Bitcoin is accepted by many of the largest online stores and online services for products, goods and services worldwide. Quotes of crypto currency are not regulated by any legislative or legal authorities, and therefore are considered fluid, whereby the value depends totally on the current natural demand and supply. Recently, bitcoin has achieved a great success in use within open global markets.By being motivated from a review of these factors, we decided to take a deep look into the main factors and features characteristic of bitcoin. In this project, we tried to take a vision regarding the use and impact of bitcoin features from a dataset based on Blockchain Wallet API, which is derived from one of the most popular bitcoin digital wallets – Blockchain Wallet API [1]. As a target, we set different phases for the analysis and gathering of relevant data from API. In these terms, for calculating the impact of feature we have used machine learning techniques; which included a pure linear regression and expended version of a linear regression-polynomial regression."
머신러닝 기반 CFS(Correlation-based Feature Selection)기법과 Random Forest모델을 활용한 BMI(Benthic Macroinvertebrate Index) 예측에 관한 연구,2019,"['Aquatic ecology', 'BMI', 'CFS(Correlation-based Feature Selection)', 'Machine Running', 'Random Forest']",,"Recently, people have been attracting attention to the good quality of water resources as well as water welfare. to improve the quality of life. This study is a papers on the prediction of benthic macroinvertebrate index (BMI), which is a aquatic ecological health, using the machine learning based CFS (Correlation-based Feature Selection) method and the random forest model to compare the measured and predicted values ​​of the BMI. The data collected from the Han River’s branch for 10 years are extracted and utilized in 1312 data. Through the utilized data, Pearson correlation analysis showed a lack of correlation between single factor and BMI. The CFS method for multiple regression analysis was introduced. This study calculated 10 factors(water temperature, DO, electrical conductivity, turbidity, BOD, NH3-N, T-N, PO4-P, T-P, Average flow rate) that are considered to be related to the BMI. The random forest model was used based on the ten factors. In order to prove the validity of the model, R2, %Difference, NSE (Nash-Sutcliffe Efficiency) and RMSE (Root Mean Square Error) were used. Each factor ​​was 0.9438, -0.997, and 0,992, and accuracy rate was 71.6% level. As a result, These results can suggest the future direction of water resource management and Pre-review function for water ecological prediction."
머신러닝을 이용한 세금 계정과목 분류,2019,"['Random Forest', 'Data Mining', 'f1-score', 'Taxation Analysis', 'Machine Learning']",,"Data mining techniques can also be used to increase the efficiency of production in the tax sector, which requires professional skills. As tax-related computerization was carried out, large amounts of data were accumulated, creating a good environment for data mining. In this paper, we have developed a system that can help tax accountant who have existing professional abilities by using data mining techniques on accumulated tax related data. The data mining technique used is random forest and improved by using f1-score. Using the implemented system, data accumulated over two years was learned, showing high accuracy at prediction."
머신러닝 기반의 디지털 방송 프로그램 유형 분류 및 활용 방안 연구,2019,"['Digital content', 'Broadcast program classification', 'Machine learning', 'Clustering analysis', 'Spectral clustering algorithm']",,"With the recent spread of digital content, more people have been watching the digital content of TV programs on their PCs or mobile devices, rather than on TVs. With the change in such media use pattern, genres(types) of broadcast programs change in the flow of the times and viewers’ trends.The programs that were broadcast on TVs have been released in digital content, and thereby people watching such content change their perception. For this reason, it is necessary to newly and differently classify genres(types) of broadcast programs on the basis of digital content, from the conventional classification of program genres(types) in broadcasting companies or relevant industries. Therefore, this study suggests a plan for newly classifying broadcast programs through using machine learning with the log data of people watching the programs in online media and for applying the new classification.This study is academically meaningful in the point that it analyzes and classifies program types on the basis of digital content. In addition, it is meaningful in the point that it makes use of the program classification algorithm developed in relevant industries, and especially suggests the strategy and plan for applying it."
머신러닝을 이용한 시각장애인 도로 횡단 보조 임베디드 시스템 개발,2019,"['Visually-impaired', 'Street crossing', 'Assistive device', 'Pedestrian signal', 'Machine learning', 'Real-time object detection']","본 연구는 시각장애인들이 도로를 안전하게 횡단할 수 있도록 신호등 인식 및 음성안내를 제공해주는 임베디드 시스템의 설계를 제안한다. 시각장애인에게 독립보행은 큰 어려움으로 작용하고 있으며, 독립보행의 제한은 그들의 삶의 질을 저하시키는 요인으로 작용하고 있다. 도로횡단에서의 신호등 인식과 도로 및 차로의 구분 불가는 시각장애인의 독립보행을 방해하는 가장 큰 요인 중 하나이다. 본 연구에서 제안하는 스마트기기는 안경에 달린 초소형카메라로 GPU 보드에 탑재된 머신러닝 알고리즘을 이용하여 보행자 신호등을 검출 및 인식하며, 음성 안내를 유저에게 전달해준다. 휴대성을 위하여, 기기는 충분한 배터리 수명과 함께 소형 및 가볍게 디자인되었다. 또한, 안경 다리에는 외부 소리를 막지 않으면서 음성 안내를 전달해주는 골전도 스피커가 부착되어 있다. 본 연구에서 제안하는스마트기기는 실험을 통하여 보행자 신호의 초록 신호에 대하여 87.0%의 검출율(recall)과 100%의 정확도(precision) 를 가지며, 빨간 신호에 대하여, 94.4%의 검출율(recall) 값과 97.1%의 정확도(precision)를 가지는 것으로 유효성을확인하였다.","In this study, a smart assistive device is designed to recognize pedestrian signal and to provide audio instructions for visually impaired people in crossing streets safely. Walking alone is one of the biggest challenges to the visually impaired and it deteriorates their life quality. The proposed device has a camera attached on a pair of glasses which can detect traffic lights, recognize pedestrian signals in real-time using a machine learning algorithm on GPU board and provide audio instructions to the user. For the portability, the dimension of the device is designed to be compact and light but with sufficient battery life. The embedded processor of device is wired to the small camera which is attached on a pair of glasses. Also, on inner part of the leg of the glasses, a bone-conduction speaker is installed which can give audio instructions without blocking external sounds for safety reason. The performance of the proposed device was validated with experiments and it showed 87.0% recall and 100% precision for detecting pedestrian green light, and 94.4% recall and 97.1% precision for detecting pedestrian red light."
VARMA와 머신러닝 모형을 이용한 소양강댐 월유입량 예측,2019,"['기후변화', '댐 유입량', '월 유입량 예측', 'VARMA 모형', '머신러닝 모형', 'climate change', 'inflow of dam', 'monthly inflow forecasting', 'VARMA model', 'machine Learning model']",,"Water resources planning and management are, more and more, becoming important issue for water use and flood control due to the population increase, urbanization, and climate change. In particular, the estimating and the forecasting inflow of dam is the most important hydrologic issue for flood control and reliable water supply. Therefore, this study forecasted monthly inflow of Soyang river dam using VARMA model and 3 machine learning models. The forecasting models were constructed using monthly inflow data in the period of 1974 to 2016 and then the inflows were forecasted at 12- and 24-month ahead lead times.As a result, the forecasted monthly inflows by the models mostly were less than the observed ones, but the peak time and the variation pattern were well forecasted. Especially, the VARMA model showed very good performance in the forecasting. Therefore, the result of this study indicates that the VARMA model can be used efficiently to forecast hydrologic data and also used to establish water supply and management plan."
기상환경데이터와 머신러닝을 활용한 미세먼지농도 예측 모델,2019,"['Fine Dust', 'Machine Learning', 'Weather Data', 'Bigdata']",,"Recently, as the amount of fine dust has risen rapidly, our interest is increasing day by day. It is virtually impossible to remove fine dust. However, it is best to predict the concentration of fine dust and minimize exposure to it. In this study, we developed a mathematical model that can predict the concentration of fine dust using various information related to the weather and air quality, which is provided in real time in 'Air Korea (http://www.airkorea.or.kr/)' and 'Weather Data Open Portal (https://data.kma.go.kr/).' In the mathematical model, various domestic seasonal variables and atmospheric state variables are extracted by multiple regression analysis. The parameters that have significant influence on the fine dust concentration are extracted, and using ANN (Artificial　Neural　Network) and SVM (Support Vector Machine), which are machine learning techniques, we proposed a prediction model. The proposed model can verify its effectiveness by using past dust and weather big data."
이직을 경험한 근로자의 직장만족도 유형 분류 및 영향요인 탐색: 머신러닝 기법 적용,2019,"['잠재프로파일 분석', '머신러닝', '직장만족도', '이직경험', 'latent profile analysis', 'machine learning', 'job satisfaction', 'turnover experience']","본 연구는 청년패널조사의 1-11차년도의 자료를 활용하여 이직한 경험이 있는 근로자들의 직장만족도 유형을 분류하고, 직장만족도 유형 분류에 중요한 영향을 미치는 요인을 탐색하고자 수행되었다. 첫째, 잠재프로파일 분석 결과 4개의 집단이 도출되었으며, 각각의 집단을 ‘낮은 직장만족도 집단’, ‘중간 직장만족도 집단’, ‘높은 직장만족도 집단’, ‘최상 직장만족도 집단’으로 명명하였다. 둘째, 의사결정나무와 랜덤포레스트 두 가지 머신러닝 기법을 적용한 결과 랜덤포레스트의 집단 분류정확도가 더 좋은 것으로 나타났다. 랜덤포레스트 분석 결과 현 직장 임금, 주어진 연차휴가 일수, 가구 총 근로소득, 작년 평균 저축액, 연령, 스트레스, 현재 건강상태에 대한 주관적 평가, 업무내용과 전공일치도, 필요 교육수준, 이직 횟수 등이 중요도 지수가 높은 변인으로 도출되었다. 이러한 연구결과를 토대로 근로자의 직장만족도를 높이기 위한 시사점을 제공하였다.","The purpose of this study is to classify latent profiles of job satisfaction of employees with turnover experience, and to explore the factors affecting latent profiles by using a machine learning approach. To do this, Youth Panel (YP) data from the 1st to 11th waves were used. The results of this study include: first, according to latent profile analysis, the levels of job satisfaction were classified into four latent profiles, namely, ‘low job satisfaction,’ ‘middle job satisfaction,’ ‘high job satisfaction,’ and ‘highest job satisfaction.’ Second, the random forest method had a higher classification accuracy than the decision tree method. The random forest analysis revealed that the main factors associated with the classified latent profiles were wage, given annual leave, household earned income, average savings, age, stress, health status, job-major congruence, required level of education, and turnover frequency. Based on these results, this study suggested ways to improve the job satisfaction of employees."
이종센서 위성영상과 머신 러닝을 활용한 광릉지역 주요 수종 분류 모델 개발,2019,"['Random forest', 'Spectroscopy', 'Sentinel-2', 'PlanetScope', 'SRTM']","저자는 접근불능지역인 북한의 임상도 제작을 위한 첫 단계로 Hyperion과 Sentinel-2 위성영상과 질감정보와 지형정보를 활용하여 정확도 98% 이상의 잣나무 및 낙엽송 분류모델을 개발한 바 있다. 북한의 주요 수종점유율을 고려해 볼 때, 낙엽송(점유율 17.5%), 잣나무(5.8%) 뿐만 아니라 소나무(12.7%), 전나무(8.2%), 참나무류(29.5%)의 점유율이 크므로 수종분류 모델의 확장이 필요하다. 따라서 본 연구에서는 기존의 2개 수종에서주요 5개 수종으로 분류모델을 확장하기 위해 분광정보와 침엽수 및 활엽수의 수관특성을 고려한 질감정보 및수종별 생육특성을 고려한 지형정보를 투입하여 방법론을 개선하였다. 연구대상지인 광릉지역의 임상도에서 수종별 위치정보를 취득하여 11,039개의 훈련자료와 2,330개의 검증자료를 구축하였다. 분광정보는 Sentinel-2 영상을 통해 획득하였으며 질감정보는 고해상도인 PlanetScope 영상을, 지형정보는 북한지역으로의 확장 가능성을 고려하여 SRTM DEM을 활용하였다. 머신 러닝 모델은 기존 연구에서 정확도가 검증된 Random Forest 알고리즘을 활용하였다. 분류 결과 전체 80%(Kappa지수 0.80) 정확도로 수종이 분류되었다. 향후 백두산 지역과남북 고성지역을 대상으로 본 연구에서 개발된 수종분류모델의 확장성을 검토하여 한반도 지역의 수종 분류모델을 개발하고자 한다.","We had developed in preceding study a classification model for the Korean pine and Larch with an accuracy of 98 percent using Hyperion and Sentinel-2 satellite images, texture information, and geometric information as the first step for tree species mapping in the inaccessible North Korea.Considering a share of major tree species in North Korea, the classification model needs to be expanded as it has a large share of Oak(29.5%), Pine (12.7%), Fir (8.2%), and as well as Larch (17.5%) and Korean pine (5.8%). In order to classify 5 major tree species, national forest type map of South Korea was used to build 11,039 training and 2,330 validation data. Sentinel-2 data was used to derive spectral information, and PlanetScope data was used to generate texture information. Geometric information was built from SRTM DEM data. As a machine learning algorithm, Random forest was used. As a result, the overall accuracy of classification was 80% with 0.80 kappa statistics. Based on the training data and the classification model constructed through this study, we will extend the application to Mt. Baekdu and North and South Goseong areas to confirm the applicability of tree species classification on the Korean Peninsula."
제한적 수집 환경에서의 머신러닝 기법 예측력 비교 연구,2019,"['LR', 'ANN', 'SVM', 'RMSE', 'Multi-Way ANOVA']",,"Purpose: This study proposes data collection guidelines for potential restrictive environments.Methods: First, data were generated from a linear model, a nonlinear product convey model, and a nonlinear wind turbine model. The three data sets were then used for training three machine learning methods, namely, LR, ANN, and SVM, respectively. Then, compare with the RMSE of each method of the data generated from each model.Results: The LR analysis method showed better performance than the other methods, regardless of the effect of the data size and noise on the linear model. Among the nonlinear models, the ANN method is not recommended in the absence of noise. However, in the presence of noise, especially for high noise levels, this method is recommended over the other methods.Conclusion: Since noise significantly degrades the performance of the methods, effective noise management is recommended during the data collection process. In addition, key features can be extracted even with a small amount of data, and the generated data can be utilized for analysis. Therefore, data quality should be prioritized over data quantity."
빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발,2019,"['Pothole', 'Soil Settlement', 'Road Subsidence', 'Big Data', 'Machine Learning', '포트홀', '지반침하', '도로함몰', '빅데이터', '머신러닝']","본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다.","Potholes, soil settlement, and road subsidence have become major road safety hazards in South Korea. Such problems not only impede driver and pedestrian safety but also cause secondary accidents, economic losses, and damage the nation's image. To this end, we developed local predictive models that can be extrapolated to national estimation models. These models were developed from a specific area (Seoul Metropolitan City) that has the highest occurrences of potholes and road subsidence. This research utilized big data and artificial intelligence techniques to develop these models. The first step involved the dimensional reduction of independent variables using a mechanical-statistical approach. A data standardization process was then used for reducing the uncertainty of these variables. A total of 19 machine learning optimization methods were used to train the standardized variables.The optimized models were finally determined by an error comparison. As a result, the optimized prediction models for potholes, soil settlement, and road subsidence were found to be multiple regression analysis that showed an accuracy of 70% and robust regression analysis that showed an accuracy of 73%."
서울시 공공자전거 운행 거리 예측을 위한 머신 러닝 모델의 비교 연구,2019,"['Linear regression', 'XGboost', 'Random forest', 'Embedding', 'Haversine distance']",,"Cities in many countries offer public bicycle sharing services to help solve the health and traffic jams of citizens and to solve environmental problems caused by automobiles. Using the machine learning models, the public bike service in Seoul have been analyzed. To service the bike sharing efficiently, the prediction of trip distance or trip duration will be needed. The prediction of trip distances and durations has important roles to help the proper operations and improvement of the bike rental services. The trip distances are deeply related to the trip durations, and could be calculated accurately when including the positions of pickup and return places, environment information such as temperature, humidity, fine dust density, et., al. To build models, linear regression, Random Forest, XGBoost and deep learning techniques have been used. Random Forest and XGboost provides important features among features. Especially, XGBoost being interested in many data manipulating and anlysing areas shows improved accuracy and can utilized the GPU to boost speed. To apply the deep learning in analysis of structured data(tabula data), embedding of categorical features will be done and the remaining continuous features and embedded features put into the fully connected neural nets. The deep learning neural net model shows the best accuracy and then XGBoost model, Random Forest models followed."
머신러닝 기반 안드로이드 모바일 악성 앱의최적 특징점 선정 및 모델링 방안 제안,2019,"['안드로이드', '악성코드', 'APK', '인공지능', '앙상블 알고리즘', 'Android', 'Malware', 'APK', 'AI', 'Ensemble Algorithm']","모바일 운영체제 중 안드로이드의 점유율이 높아지면서 모바일 악성코드 위협은 대부분 안드로이드에서 발생하고 있다. 그러나 정상앱이나 악성앱이 진화하면서 권한 등의 단일 특징점으로 악성여부를 연구하는 방법은 유효성 문제가 발생하여 다양한 특징점 추출 및 기계학습을 통해 이를 극복하고자 한다. 본 논문에서는 APK 파일에서 구동에 필요한 다섯 종류의 특징점들을 안드로가드라는 정적분석 툴을 사용하여 학습데이터의 특성을 추출한다. 또한 추출된 중요 특징점을 기반으로 모델링을 하는 세 가지 방법을 제시한다. 첫 번째 방법은 보안 전문가에 의해 엄선된 132가지의 특징점 조합을 바탕으로 모델링하는 것이다. 두 번째는 학습 데이터 7,000개의 앱에서 발생 빈도수가 높은 상위 99%인 8,004가지의 특징점들 중 랜덤포레스트 분류기를 이용하여 특성중요도가 가장 높은 300가지를 선정 후 모델링 하는 방법이다. 마지막 방법은 300가지의 특징점을 학습한 다수의 모델을 통합하여 하나의 가중치 투표 모델을 구성하는 방법이다. 추가적으로 오탐률 및 미탐률을 개선하기 위해 권한 정보를 모두 제외하여 특징점을 재구성하고 위와 같은 환경으로 모델링하였다. 최종적으로 가중치 투표 모델인 앙상블 알고리즘 모델을 사용하여 97.8%로 정확도가 개선되었고 오탐률은 1.9%로 성능이 개선된 것이 확인되었다.",
랜덤포레스트와 서포트벡터머신 기법을 적용한 포인트 클라우드와 실감정사영상을 이용한 객체분류,2019,"['인공지능', '머신러닝', '공간정보', '수치지도', '실감정사영상', '정규수치표면모델', '밴드 퓨전', 'Artificial Intelligence', 'Machine Learning', 'Geospatial Information', 'Digital Map', 'True Ortho-image', 'Normalized Digital Surface Model', 'Band Fusion']","정보통신기술의 발달로 인하여 데이터의 생산과 처리 속도가 빨라지고 있다. 인공지능의 한 분야인 머신러닝을 이용하여 객체를 분류하기 위해, 학습에 필요한 데이터는 인터넷과 공간정보기술의 발달로 인하여 손쉽게 수집할 수 있게 되었다. 공간정보 분야에서도 머신러닝은 영상, 포인트 클라우드 등을 이용하여 객체를 분류 또는 인식하는 것에 적용되고 있다. 본 연구에서는 기 구축된 수치지도 버전 1.0을 활용하여 학습 데이터를 수동으로 구축하는 문제점을 개선하고 영상과 포인트 클라우드를 이용하여 도로, 건물, 식생을 분류하는 기법을 제안하였다. 실험을 통해서 RGB 밴드만을 갖고 있는 실감정사영상을 사용하였을 경우 색상을 뚜렷하게 구분할 수 있는 도로, 건물, 식생의 분류가 가능하였지만 색상이 유사한 경우에는 분류가 잘 되지 않는 한계를 확인할 수 있었다. 이를 개선하기 위해 실감정사영상과 정규수치표면모델을 밴드 퓨전한 후 랜덤포레스트와 서포트벡터머신 기법을 적용하였으며 이를 통해 85%이상의 정확도로 도로, 건물, 식생을 분류하였다.","Due to the development of information and communication technology, the production and processing speed of data is getting faster. To classify objects using machine learning, which is a field of artificial intelligence, data required for training can be easily collected due to the development of internet and geospatial information technology. In the field of geospatial information, machine learning is also being applied to classify or recognize objects using images and point clouds. In this study, the problem of manually constructing training data using existing digital map version 1.0 was improved, and the technique of classifying roads, buildings and vegetation using image and point clouds were proposed. Through experiments, it was possible to classify roads, buildings, and vegetation that could clearly distinguish colors when using true ortho-image with only RGB (Red, Green, Blue) bands. However, if the colors of the objects to be classified are similar, it was possible to identify the limitations of poor classification of the objects. To improve the limitations, random forest and support vector machine techniques were applied after band fusion of true ortho-image and normalized digital surface model, and roads, buildings, and vegetation were classified with more than 85% accuracy."
머신 러닝 기법을 활용한 건물 에너지 사용량 예측에 관한 연구,2019,"['Machine learning(머신러닝)', 'Training(학습)', 'Predict(예측)', 'Error(오차)']",,"In this study, the energy use of buildings was compared and analyzed by using weather data predicted with machine running techniques. Python was used as a predictive program to predict weather data and TRNSYS was used to simulate the energy usage of buildings. For weather forecasting, weather data from 1 August to 7 August were studied to forecast ambient air temperature and solar radiation. The lowest error came in seven days, with the outside air temperature standing at 1.8 percent and the solar radiation at 2.4 percent. The energy use of the building was simulated by using weather data predicted through the 7 days learning data with the lowest error. As a result , the error rate of cooling energy use was 1.92%, the sum of cooling energy and lighting energy use was 1.79%, and the building control by using predicted weather data didn’t show a big difference with just control."
조건적 제한된 볼츠만머신을 이용한 중기 전력 수요 예측,2019,"['Smart grid', 'Learning Algorithm', 'Energy Demand Forecast', 'RBM', 'CRBM']",미래에 스마트 그리드 도입을 위해 전력수요예측은 중요한 연구 분야 중 하나이다. 하지만 전력데이터는 많은 외부적 요소들에 영향을 받기 때문에 예측하기 어렵다. 기존의 전력수요예측 방법들은 가공되지 않은 전력데이터를 그대로 이용하기 때문에 정확도 높은 예측을 하는데 한계가 있어왔다. 본 논문에서는 가공되지 않은 전력데이터를 이용하는 전력수요예측의 문제를 해결하기 위해 확률기반 학습알고리즘을 제안한다. 확률 모델은 전력데이터의 확률적 특성을 분석하기에 적합하다. 제안한 모델의 중기 전력수요예측 성능을 비교하기 위해 신경망 네트워크 중 하나인 순환신경망과 성능 비교를 해보았다. 매사추세츠 대학에서 제공한 전력데이터를 이용하여 성능 비교를 한 결과 본 논문에서 제안한 확률기반 학습알고리즘이 중기 수요예측에 더 좋은 성능을 나타냄을 확인하였다.,"Electric power demand forecasting is one of the important research areas for future smart grid introduction. However,It is difficult to predict because it is affected by many external factors. Traditional methods of forecasting power demandhave been limited in making accurate prediction because they use raw power data. In this paper, a probability-basedCRBM is proposed to solve the problem of electric power demand prediction using raw power data. The stochastic modelis suitable to capture the probabilistic characteristics of electric power data. In order to compare the mid-term powerdemand forecasting performance of the proposed model, we compared the performance with Recurrent NeuralNetwork(RNN). Performance comparison using electric power data provided by the University of Massachusetts showedthat the proposed algorithm results in better performance in mid-term energy demand forecasting."
머신러닝을 사용한 양방향 LED-to-LED 가시광통신시스템,2019,"['Visible Light Communication(VLC)', 'Two-way LED-to-LED communication', 'Machine learning']",,
머신러닝 알고리듬을 적용한 차량 프런트도어의 재활용 적합성 정량적 평가기법 연구,2019,"['재활용 적합성', '머시러닝 알고리듬', '원리도화법', '재활용 공정', '분해성', 'Suitability of recycling process', 'Machine learning algorithm', 'Symbolic chart method', 'Recycling process', 'Disassemblability']",,"In this research, we evaluate on the disassemblability of recycling process for vehicle front door using the symbolic chart method and machine-learning algorithm. It is applied to the front door of 1600cc class vehicle, and then the conventional steel door and CFRP door were compared. Based on the principle symbolic chart method, the number of processes can be different according to decomposer proficiency of suitability of recycling process, so the evaluation method is required to supply this issue. The machine learning algorithm, and artificial intelligence method were applied and the applicable tools for each experiment were used to compensate the variations in the number of processes according to different proficiencies. Because CFRP front door has integrated components compare to steel door, so its disassemblability processes were decreased to 80 from 103 of the conventional steel door’s. It can be confirmed that the disassemblability was increased from the suitability of recycling equation. In case of the steel, disassemblability was approximately 60.6, in case of the CFRP is approximately 72 for car front door. Therefore, it can be concluded that the disassemblability of CFRP was better in the evaluation of suitability of recycling."
New Revolution in Fund Management: ETF/Index Design by Machines,2019,"['ETF', 'index', 'machine learning', 'artificial intelligence', 'fund management']",,Two ETFs were listed to track the secondary-battery industry on 12 September 2018 in the Korea Stock Exchange market. They are virtually identical except that one is designed by humans while the other is made by machines. This paper compares the two ETFs and find little difference in their investment strategies except that machines are more likely to pick high book-to-market stocks than humans. Machines are also more likely to pick past losers and outperform human-designed ETF afterwards. The results suggest that machines can do equally good as humans as ETF/index designers.
Vibration based bridge scour evaluation: A data-driven method using support vector machines,2019,"['bridge scour', 'modal properties', 'machine learning', 'feature extraction', 'feature selection', 'support vector machines']",,"Bridge scour is one of the predominant causes of bridge failure. Current climate deterioration leads to increase of flooding frequency and severity and thus poses a higher risk of bridge scour failure than before. Recent studies have explored extensively the vibration-based scour monitoring technique by analyzing the structural modal properties before and after damage. However, the state-of-art of this area lacks a systematic approach with sufficient robustness and credibility for practical decision making. This paper attempts to develop a data-driven methodology for bridge scour monitoring using support vector machines. This study extracts features from the bridge dynamic responses based on a generic sensitivity study on the bridge's modal properties and selects the features that are significantly contributive to bridge scour detection. Results indicate that the proposed data-driven method can quantify the bridge scour damage with satisfactory accuracy for most cases. This paper provides an alternative methodology for bridge scour evaluation using the machine learning method. It has the potential to be practically applied for bridge safety assessment in case that scour happens."
머신 러닝을 활용한 회사 SNS 메시지에 내포된 심리적 거리 추출 연구,2019,"['SNS 마케팅', '심리적 거리', '자연어 처리', '머신 러닝', '서포트 벡터 머신', 'SNS Marketing', 'Psychological Distance', 'Natural Language Processing', 'Machine  Learning', 'Support Vector Machine']",,
머신러닝 기법을 적용한 하드웨어 데이터 프리페치 기법 구현,2019,"['hardware', 'prefetch', 'cache', 'RNN', 'GRU']",,
A Study on Fault Classification of Machining Center using Acceleration Data Based on 1D CNN Algorithm,2019,"['Machining Center(머시닝센터)', 'Machine Learning(머신러닝)', 'Fault Signal Classification(고장신호 분류)', 'CNN(합성곱 신경망)']",,"The structure of the machinery industry due to the 4th industrial revolution is changing from precision and durability to intelligent and smart machinery through sensing and interconnection(IoT). There is a growing need for research on prognostics and health management(PHM) that can prevent abnormalities in processing machines and accurately predict and diagnose conditions. PHM is a technology that monitors the condition of a mechanical system, diagnoses signs of failure, and predicts the remaining life of the object. In this study, the vibration generated during machining is measured and a classification algorithm for normal and fault signals is developed. Arbitrary fault signal is collected by changing the conditions of un stable supply cutting oil and fixing jig. The signal processing is performed to apply the measured signal to the learning model. The sampling rate is changed for high speed operation and performed machine learning using raw signal without FFT. The fault classification algorithm for 1D convolution neural network composed of 2 convolution layers is developed."
광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교,2019,"['Classifier', 'Machine Learning', 'Pain Assessment', 'Photoplethysmogram']",,"This study examines the classification characteristics of various machine learning classifiers for pain assessment using photoplethysmogram. The presence of pain was assessed using waveform characteristics derived from photoplethysmogram obtained from 73 patients before and after surgery. Classification performance was evaluated using logistic regression, random forest, multilayer perceptron, and 1D convolutional neural network, and was validated with nested kfold cross validation. As a result, pain classification accuracy was highest in order of logistic regression, convolutional neural network, multilayer perceptron, and random forest classifier. In addition, logistic regression, random forest, multilayer perceptron, and convolutional neural network were shown to be robust to overfitting in order."
Multiobjective optimization for improving machinability of Ti-6Al-4V using RSM and advanced algorithms,2019,['Titanium alloys Response surface methodology Teaching learning based optimization ‘JAYA’ Cutting force Surface roughness'],,"This paper explores use of Teaching Learning Based Optimization (TLBO), ‘JAYA’ (Sanskrit word means Victory) and Genetic Algorithm (GA) for the combined minimization of roughness of machined surface and forces generated in cutting in turning of Ti-6Al-4V. Experimentation was carried out with Response Surface Methodology (RSM) and the Central Composite Design (CCD). Speed of cutting (m/min), feed rate (mm/min) and depth of cut (mm) were the design variables for optimization. Two responses (roughness of machined surface and force of cutting) were independently minimized. RSM was useful in ﬁnding empirical relations and the effect of each parameter and their interactions on the responses considered. Analysis of variance (ANOVA) was used to ﬁnd out the effective and non-effective factors and correctness of the models. Later on, a multi-objective optimization function was developed for minimizing both – roughness in machined surface and force generated in cutting using weights method and the correctness of weights were conﬁrmed by Analytical Hierarchy Process (AHP). After formulating the combined objective function, TLBO, ‘JAYA’ and GA methods were used for further parameter optimization of the turning process. Performance of TLBO and ‘JAYA’ algorithm was compared with that of Genetic Algorithm (GA). It is found that TLBO and ‘JAYA’ performed better than GA in the combined minimization of roughness and forces in while turning Ti-6Al-4V. It is also found from the results that higher cutting speed (171.4 m/min) and lower feed rate (55.6 mm/min) can produce better surface roughness and minimum cutting forces in machining of Ti-6Al-4V."
머신러닝을 활용한 실시간 리눅스 악성파일 탐지,2019,"['linux malware detection', 'data mining', 'machine learning', 'decision tree', 'elf ransomware detection']",,
머신 러닝을 이용한 고속 시변 OFDM 채널 예측의 성능 개선,2019,"['OFDM', 'fast time-varying channels', 'channel estimation', 'machine learning']",,
두 유저 MISO 간섭채널에서 머신러닝을 활용한 빔포밍 기술,2019,"['Machine learning', 'MISO interference channel', 'deep neural network', 'beamforming', 'artificial intelligence']",,
TransMotion: 신체적 자기효능감 향상을 도와주는 머신러닝 기반의 발레체험 시스템에 관한 연구,2019,"['머신러닝', '발레', '움직임의 미학', '신체적 자기효능감', '무용교육', 'Machine learning', 'Ballet', 'Aesthetics of movement', 'Physical self-efficacy', 'Dance education']",,
머신러닝 기반 자동 데이터 시각화를 위한 특징공학,2019,"['big data', 'data visualization', 'machine learning', 'feature engineering', 'meta data']",,
머신러닝을 이용한 공연문화예술 개인화 장르 추천 시스템,2019,"['공연문화예술', '머신러닝', '추천 시스템', '고객관계관리', '연관성 분석', '협업  필터링', '앙상블', 'Performing Arts', 'Machine Learning', 'Recommendation System', 'CRM', 'Association', 'Collaborative Filtering', 'Ensemble']",,
직무분석을 위한 머신러닝 기반 전자문서 자동 분류 모델,2019,"['machine learning', 'supervised learning', 'automatic classification', 'job analysis']",,
머신러닝을 이용한 관중 수요 예측에 관한 연구,2019,"['수요예측', '머신러닝', '딥러닝', '랜덤포레스트']","특정한 이벤트나 콘텐츠를 즐기기 위해 모인 사람들을 관중 또는 관객이라고 하고, 모임의 특성에 따라 다양한 성향을 나타낸다. 그러한 차이점은 있지만, 일반적으로 관중 수는 경영적인 측면과 직결되는 요소로써, 관람료부터 다른 시설의 이용료 등 다양한 수입을 통해 콘텐츠 판매를 위한 안정적인 재정 운영을 가능케 한다. 따라서 관중 수에 대한 예측은 마케팅과 예산 전략 수립에 주요한 요소로 활용될 수 있다. 본 연구에서는 관중 수에 대한 예측을 위한 여러 가지 기존 모델을 검토하고, 그 중에서 효율적인 머신러닝 모델을 제안하고자 한다. 또한 딥러닝과 랜덤포레스트 모델을 혼용하여 일별 관중 수 예측과 비정상적 관중 수 예측에 대한 연구를 진행하였다.","People who gathered to enjoy a specific event or content are called audiences or spectators, and show various propensity according to the characteristics of the crowd. Although there is such a difference, in general, the number of attendance is directly related to the business aspect, which enables stable financial operation for the sale of contents through various incomes, such as the admission fee and the use of other facilities. Therefore, prediction of audience can be used as a major factor in marketing and budgeting strategies. In this study, we review several existing models for predicting the number of attendance and propose an efficient machine learning model. In addition, we studied daily attendance prediction and abnormal attendance prediction using combine DNN(Deep Neural Network) and RF(Random Forest) model."
비지도 특징학습을 위한 커널 기반 제한된 볼츠만 머신,2019,"['feature learning', 'restricted Boltzmann machine', 'kernel method', 'image classification']",,
동해안 너울성 파도 예측을 위한 머신러닝 모델 연구,2019,"['swell', 'machine learning', 'classification algorithm', 'prediction model', 'accuracy']",,
LoRaWAN 환경에서의 머신러닝을 통한 네트워크 공격 탐지 구현,2019,"['LoRaWAN', 'Cyber Security', 'Machine Learning', 'Ⅰ. IntroductionAnomaly Detection']",,
기상 예보를 이용한 머신러닝 알고리즘 기반 태양광 발전량 예측 기법,2019,"['solar power', 'weather', 'machine learning', 'smart grid', 'renewable energy']",,
SDN/NFV 자동화를 위한 머신러닝기술 연구 동향,2019,"['Software Defined Networking (SDN)', 'Network Function Virtualization (NFV)', 'Machine Learning', 'Network intelligence', 'Network automation']",,
기계학습: 대용량/패널자료와 학습분석학 자료 분석으로의 활용,2019,"['machine learning', 'learning analytics', 'panel data', 'large-scale data', 'big data', '기계학습', '학습분석학', '패널자료', '대용량자료', '빅데이터']","컴퓨터공학을 비롯한 여러 학문에서 주목을 받고 있는 기계학습 기법은 전자상거래, 유전체학, 자연어 분석, 의료영상처리, 자율주행자동차 등의 다양한 분야에 성공적으로 응용되고 있다. 반면, 기계학습을 이용한 교육 연구는 상대적으로 많지 않으며, 기계학습 자체에 대한 교육 분야 연구자들의 이해 또한 높지 않다. 본 연구는 기계학습의 정의로부터 시작하여 주요 개념인 추론과 예측, 과적합, 편향-분산 상충 관계, 교차검증, 지도학습과 비지도학습 등을 설명하며 기계학습을 전반적으로 개관하였다. 이어서 2019년 현재 교육분야에서 기계학습 기법을 쓴 연구와 학습분석학 자료를 활용한 연구를 정리·분석함으로써, 교육 분야 연구자들의 기계학습에 대한 이해도를 높이고 교육 연구에서 기계학습의 저변을 넓히고자 하였다. 분석 결과, 기계학습 기법 중 지도학습 기법인 벌점회귀모형과 랜덤포레스트가 다양한 교육 대용량/패널 자료 분석에 활용되었으며 비지도학습의 경우 온라인 텍스트 자료 분석 위주로 실시된 것을 확인하였다. 학습분석학 자료의 경우 아직 기계학습 기법이 충분히 활용되지 못한 것으로 보인다. 마지막으로 기계학습을 활용하는 교육 연구의 향후 과제를 교육 대용량/패널자료의 특징과 연계하여 고찰하고, 학습분석학자료 분석과 관련한 기계학습 기법의 활용 방안을 논하였다.","Mainly developed in computer engineering/science, machine learning not only has been gaining popularity in academics, but also has been successfully applied to various fields of life including online retail business, genomics/health care, natural language processing, and self-driving cars. Nonetheless, there have been only a handful of machine learning studies in education, and accordingly educational researchers are not well-informed about machine learning. Starting with an overview of machine learning including its definition and key concepts such as prediction and overfitting, this article reviewed machine learning studies in education, which will help improve understanding of and propagate applications of machine learning techniques in the educational research community. Specifically, penalized regression and random forests have been employed to analyze large-scale/panel data as supervised learning, and text mining with LDA (Latent Dirichlet Allocation) has been frequently used as unsupervised learning in the field of education. Applying machine learning techniques to learning analytics data appears to need much improvement. Lastly, future research topics are discussed, particularly for researchers using large-scale/ panel data and learning analytics data."
IoT센서로 수집된 균질 시간 데이터를 이용한기계학습 기반의 품질관리 및 데이터 보정,2019,"['융합', '기계학습', '품질관리', '데이터보정', '서포트벡터회귀', '다층퍼셉트론', 'Convergence', 'Machine Learning', 'Quality Control', 'Data Correction', 'Weather Data']","본 논문은 온도 등 7 가지의 IoT 센서에서 수집된 기상데이터의 각 기상요소에 대하여 품질관리(Quality Control; QC)를 하였다. 또한, 우리는 측정된 값에 오류가 있는 데이터를 기계학습으로 의미있게 추정하는 방법을 제안한다. 수집된 기상데이터를 기본 QC 결과를 바탕으로 오류 데이터를 선형 보간하여 기계학습 QC를 진행하였으며, 기계학습 기법으로는 대표적인 서포트벡터회귀, 의사결정테이블, 다층퍼셉트론을 사용했다. 기본 QC의 적용 유무에 따라 비교해 보았을 때, 우리는 기본 QC를 거쳐 보간한 기계학습 모델들의 평균절대오차(MAE)가 21% 낮은 것을 확인할 수 있었다. 또한, 기계학습 기법에 따라 비교하여 서포트벡터회귀 모델을 적용하였을 때가, 모든 기상 요소에 대하여 MAE가 평균적으로 다층신경망은 24%, 의사결정테이블은 58% 낮은 것을 알 수 있었다.","In this paper, quality control (QC) is applied to each meteorological element of weather data collected from seven IoT sensors such as temperature. In addition, we propose a method for estimating the data regarded as error by means of machine learning. The collected meteorological data was linearly interpolated based on the basic QC results, and then machine learning-based QC was performed. Support vector regression, decision table, and multilayer perceptron were used as machine learning techniques. We confirmed that the mean absolute error (MAE) of the machine learning models through the basic QC is 21% lower than that of models without basic QC. In addition, when the support vector regression model was compared with other machine learning methods, it was found that the MAE is 24% lower than that of the multilayer neural network and 58% lower than that of the decision table on average."
인공지능 기계학습 방법 비교와 학습을 통한 디지털 신호변화,2019,"['Machine Learning', 'Artificial Intelligence', 'Digital Signal', 'Optimization', 'Method', '기계학습', '인공지능', '디지털 신호', '최적화', '방법']","앞으로의 시대는 인공지능을 이용한 다양한 분야에 다양한 제품이 생성될 것이다. 이러한 시대에 인공지능의 학습 방법의 동작 원리를 알고 이를 정확하게 활용하는 것은 상당히 중요한 문제이다. 이 논문은 지금까지 알려진 인공지능 학습 방법을 소개한다. 인공지능의 학습은 수학의 고정점 반복 방법(fixed point iteration method)을 기반으로 하고 있다. 이 방법을 기반으로 수렴 속도를 조절한 GD(Gradient Descent) 방법, 그리고 쌓여가는 양을 누적하는 Momentum 방법, 마지막으로 이러한 방법을 적절히 혼합한 Adam(Adaptive Moment Estimation) 방법 등이 있다. 이 논문에서는 각 방법의 장단점을 설명한다. 특히, Adam 방법은 조정 능력을 포함하고 있어 기계학습의 강도를 조정할 수 있다. 그리고 이러한 방법들이 디지털 신호에 어떠한 영향을 미치는 지에 대하여 분석한다. 이러한 디지털 신호의 학습과정에서의 변화는 앞으로 인공지능을 이용한 작업 및 연구를 수행함에 있어 정확한 활용과 정확한 판단의 기준이 될 것이다.","In the future, various products are created in various fields using artificial intelligence. In this age, it is a very important problem to know the operation principle of artificial intelligence learning method and to use it correctly. This paper introduces artificial intelligence learning methods that have been known so far. Learning of artificial intelligence is based on the fixed point iteration method of mathematics. The GD(Gradient Descent) method, which adjusts the convergence speed based on the fixed point iteration method, the Momentum method to summate the amount of gradient, and finally, the Adam method that mixed these methods. This paper describes the advantages and disadvantages of each method. In particularly, the Adam method having adaptivity controls learning ability of machine learning.  And we analyze how these methods affect digital signals. The changes in the learning process of digital signals are the basis of accurate application and accurate judgment in the future work and research using artificial intelligence."
앙상블 기계 학습을 이용한 기온 예측,2019,"['ensemble machine learning', 'LASSO', 'ridge regression', 'Super learner', '앙상블 기계학습', '라쏘', '능형회귀', '수퍼학습기']",,"In this study, we compared the prediction performances according to the bias and dispersion of temperature using ensemble machine learning. Ensemble machine learning is meta-algorithm that combines several base learners into one prediction model in order to improve prediction. Multiple linear regression, ridge regression, LASSO (Least Absolute Shrinkage and Selection Operator; Tibshirani, 1996) and nonnegative ride and LASSO were used as base learners. Super learner (van der Lann et al., 1997) was used to produce one optimal predictive model. The simulation and real data for temperature were used to compare the prediction skill of machine learning. The results showed that the prediction performances were different according to the characteristics of bias and dispersion and the prediction error was more improved in temperature with bias compared to dispersion. Also, ensemble machine learning method showed similar prediction performances in comparison to the base learners and showed better prediction skills than the ensemble mean."
빅데이터의 정규화 전처리과정이 기계학습의 성능에 미치는 영향,2019,"['AI', 'Machine Learning', 'BigData', 'Preprocessing', 'Performance Evaluation', '인공지능', '기계학습', '빅데이터', '전처리', '성능평가']","최근, 빅데이터 분야에서는 빅 데이터의 양적 팽창이 주요 이슈로 떠오르고 있다. 더군다나 이러한 빅데이터는 기계학습의 입력값으로 사용되어지고 있으며 이들의 성능을 향상시키기 위해 정규화 전처리가 필요하다. 이러한 성능은 빅데이터 컬럼의 범위나 정규화 전처리 방식에 따라 크게 좌우된다. 본 논문에서는 다양한 종류의 정규화 전처리 방식과 빅데이터 컬럼의 범위를 조절하면서 서포트벡터머신(SVM)의 기계학습방식에 적용함으로써 더욱 효과적인 정규화 전처리 방식을 파악하고자 하였다. 이를 위하여 파이썬언어와 주피터 노트북 환경에서 기계학습을 수행하고 분석하였다.","Recently, the massive growth in the scale of data has been observed as a major issue of the Big Data. Furthermore, the Big Data should be normalization preprocessed to get a high performance of the Machine learning since the Big Data is also an input of Machine Learning. The performance varies by many factors such as the scope of the columns in a Big Data or the methods of normalization preprocessing. In this paper, the various types of normalization preprocessing methods and the scopes of the Big Data columns will be applied to the SVM(Support Vector Machine) as a Machine Learning method to get the efficient environment for the normalization preprocessing. The Machine Learning experiment has been programmed in Python and the Jupyter Notebook."
정적 분석 기반 기계학습 기법을 활용한 악성코드 식별 시스템 연구,2019,"['Malware', 'Machine learning', 'Feature statistics', 'Packer', 'Similarity hashing']","신규 및 변종 악성코드의 발생으로 모바일, IoT, windows, mac 등 여러 환경에서 악성코드 침해 공격이 지속적으로 증가하고 있으며, 시그니처 기반 탐지의 대응만으로는 악성코드 탐지에 한계가 존재한다. 또한, 난독화, 패킹,Anti-VM 기법의 적용으로 분석 성능이 저하되고 있는 실정이다. 이에 유사성 해시 기반의 패턴 탐지 기술과 패킹에따른 파일 분류 후의 정적 분석 적용으로 기계학습 기반 악성코드 식별이 가능한 시스템을 제안한다. 이는 기존에 알려진 악성코드의 식별에 강한 패턴 기반 탐지와 신규 및 변종 악성코드 탐지에 유리한 기계학습 기반 식별 기술을 모두 활용하여 보다 효율적인 탐지가 가능하다. 본 연구 결과물은 정보보호 R&D 데이터 챌린지 2018 대회의 AI기반악성코드 탐지 트랙에서 제공하는 정상파일과 악성코드를 대상으로 95.79% 이상의 탐지정확도를 도출하여 분석 성능을 확인하였다. 향후 지속적인 연구를 통해 패킹된 파일의 특성에 맞는 feature vector와 탐지기법을 추가 적용하여 탐지 성능을 높이는 시스템 구축이 가능할 것으로 기대한다.","Malware infringement attacks are continuously increasing in various environments such as mobile, IOT, windows and macdue to the emergence of new and variant malware, and signature-based countermeasures have limitations in detection ofmalware. In addition, analytical performance is deteriorating due to obfuscation, packing, and anti-VM technique. In thispaper, we propose a system that can detect malware based on machine learning by using similarity hashing-based patterndetection technique and static analysis after file classification according to packing. This enables more efficient detectionbecause it utilizes both pattern-based detection, which is well-known malware detection, and machine learning-based detectiontechnology, which is advantageous for detecting new and variant malware. The results of this study were obtained bydetecting accuracy of 95.79% or more for benign sample files and malware sample files provided by the AI-based malwaredetection track of the Information Security R&D Data Challenge 2018 competition. In the future, it is expected that it willbe possible to build a system that improves detection performance by applying a feature vector and a detection method tothe characteristics of a packed file."
정형 데이터와 비정형 데이터를 동시에 고려하는 기계학습 기반의 직업훈련 중도탈락 예측 모형,2019,"['Vocational Training', 'Dropout', 'Machine Learning', 'Convolutional Neural Network', 'Word2vec', '직업훈련 교육', '중도탈락', '기계학습', '합성곱 신경망', 'Word2vec']","직업훈련 교육 현장에서 느끼는 가장 큰 어려움 중 하나는 중도탈락 문제이다. 훈련과정마다 많은 수의 학생들이 중도탈락을 하게 되어 국가 예산 낭비 및 청년 취업률 개선에 장애 요인이 되고 있다. 본 연구에서는 중도탈락의 원인을 주로 분석한 기존 연구들과 달리, 각종 수강생 정보를 활용하여 사전에 중도탈락을 예측할 수 있는 기계학습 기반 모형을 제안하고자 한다. 특히 본 연구의 제안모형은 수강생 관련 정형 데이터 뿐 아니라 비정형 데이터인 강사의 상담일지 정보까지 동시에 고려하여 모형의 예측정확도를 제고하고자 하였다. 이 때 비정형 데이터에 대한 분석은 최근 주목받고 있는 텍스트 분석 기술인 Word2vec과 합성곱 신경망을 이용해 수행하였다. 국내 한 직업훈련기관의 실제 데이터에 제안모형을 적용해 본 결과, 정형 데이터만을 사용하여 중도탈락을 예측할 때보다 비정형 데이터를 함께 고려했을 때 예측의 정확도가 최대 20%까지 향상됨을 확인할 수 있었다. 아울러, Support Vector Machine을 기반으로 정형 데이터와 비정형 데이터를 결합해 분석했을 때, 검증용 데이터셋 기준으로 90% 후반대의 높은 예측 정확도를 나타냄을 확인하였다.","One of the biggest difficulties in the vocational training field is the dropout problem. A large number of students drop out during the training process, which hampers the waste of the state budget and the improvement of the youth employment rate. Previous studies have mainly analyzed the cause of dropouts. The purpose of this study is to propose a machine learning based model that predicts dropout in advance by using various information of learners. In particular, this study aimed to improve the accuracy of the prediction model by taking into consideration not only structured data but also unstructured data. Analysis of unstructured data was performed using Word2vec and Convolutional Neural Network(CNN), which are the most popular text analysis technologies. We could find that application of the proposed model to the actual data of a domestic vocational training institute improved the prediction accuracy by up to 20%. In addition, the support vector machine-based prediction model using both structured and unstructured data showed high prediction accuracy of the latter half of 90%."
네트워크 데이터 정형화 기법을 통한 데이터 특성 기반 기계학습 모델 성능평가,2019,"['IDS', 'Deep learning', 'Data normalize']",최근 4차 산업 혁명 기술 중 하나인 딥러닝(Deep Learning) 기술은 보안 분야에서는 탐지하기 어려운 네트워크데이터의 숨겨진 의미를 식별하고 공격을 예측하는 데 사용되고 있다. 침입탐지에 사용될 딥러닝 알고리즘을 선택하기 전에 데이터의 속성과 품질 분석이 필요하다. 학습에 사용되는 데이터의 오염여부에 따라 탐지 방법에 영향을 주기 때문이다. 따라서 데이터의 특징을 파악하고 특성을 선정해야 한다. 본 논문에서는 네트워크 데이터 셋을 이용하여악성코드의 단계적 특징을 분석하고 특성을 추출하여 딥러닝 모델을 적용하였을 때 각 특성이 성능에 미치는 영향을분석하였다. 네트워크 특징에 따른 특성들의 비교에 대한 트래픽 분류 실험을 진행하였으며 선정한 특성을 기반으로96.52% 정확도를 분류하였다.,"Recently Deep Learning technology, one of the fourth industrial revolution technologies, is used to identify the hiddenmeaning of network data that is difficult to detect in the security arena and to predict attacks. Property and quality analysisof data sources are required before selecting the deep learning algorithm to be used for intrusion detection. This is becauseit affects the detection method depending on the contamination of the data used for learning. Therefore, the characteristics ofthe data should be identified and the characteristics selected. In this paper, the characteristics of malware were analyzedusing network data set and the effect of each feature on performance was analyzed when the deep learning model wasapplied. The traffic classification experiment was conducted on the comparison of characteristics according to networkcharacteristics and 96.52% accuracy was classified based on the selected characteristics."
기계학습 데이터세트 구축 공정 표준화에 관한 파일럿 연구,2019,"['Artificial Intelligence(AI)', 'Machine Learning Dataset(ML Dataset)', 'Standardization of ML Dataset Construction Process']",,"In this study, the processes required to build machine-learning dataset(ML dataset) were standardized or generalized. The target of the standardization process is to include all types of data used for machine learning, covering text, voice, images and video data. To this end, existing literature reviews and case studies on ML dataset construction have been carried out. In addition, various projects on domestic and international ML dataset construction were reviewed to derive a standardized construction process for each type of data. It also presented a summary table of the types of annotations that take up most of the time and cost in the ML dataset construction process and the cost for each task.Results presented in this study may be useful to assist in a more comprehensive understanding, compared to studies such as construction process studies centered on specific types of data previously performed or case studies on specific industries. In addition, the survey results comparing different types of annunciations by data type are assessed to be more likely to be used compared to previous studies. From a practical point of view, the results of this study could provide useful guidance for organizations interested in deploying ML datasets to plan and schedule at the time of their business initiatives."
기계학습을 이용한 유동가속부식 모델링: 랜덤 포레스트와 비선형 회귀분석과의 비교,2019,"['FAC', 'Statistical modeling', 'Machine learning', 'Random forest', 'Non-linear regression']",,"Flow-Accelerated Corrosion (FAC) is a phenomenon in which a protective coating on a metal surface is dissolved by a flow of fluid in a metal pipe, leading to continuous wall-thinning. Recently, many countries have developed computer codes to manage FAC in power plants, and the FAC prediction model in these computer codes plays an important role in predictive performance. Herein, the FAC prediction model was developed by applying a machine learning method and the conventional nonlinear regression method. The random forest, a widely used machine learning technique in predictive modeling led to easy calculation of FAC tendency for five input variables: flow rate, temperature, pH, Cr content, and dissolved oxygen concentration. However, the model showed significant errors in some input conditions, and it was difficult to obtain proper regression results without using additional data points. In contrast, nonlinear regression analysis predicted robust estimation even with relatively insufficient data by assuming an empirical equation and the model showed better predictive power when the interaction between DO and pH was considered. The comparative analysis of this study is believed to provide important insights for developing a more sophisticated FAC prediction model."
신경언어장애군의 동사 중재 자극 개발을 위한 기계학습 및 빅데이터 기반 한국어의 주격 및 목적격 명사 분석,2019,"['Corpus analysis', 'Machine learning', 'Subject ellipsis', 'Semantic distance', 'Verb treatment', '말뭉치분석', '기계학습', '주어생략', '의미거리. 동사중재']","배경 및 목적: 본 연구는 신경언어장애군의 동사 중재 자극으로 쓰이는 동사의 주격 및 목적격 명사의 한국어 특징을 빅데이터 기반으로 분석하였다. 또한 분석한 원자료는 향후 동사 중재 관련 연구에 활용할 수 있도록 클라우드에 배포하여 공유하였다. 방법: 교과서 말뭉치에서 목표 동사와 결합한 주격 및 목적격 명사 간 출현빈도수 및 유형수 차이를 분석하여 주어생략현상을 확인하였다. 또한 목표동사로부터 주격 및 목적격 명사까지의 의미거리를 기계학습으로 산출하여 의미거리 분포 차이를 분석하였다. 더불어 기계학습으로산출한 의미거리와 한국어 화자들이 인식하고 있는 의미거리 간 상관관계를 살펴보았다. 결과: 주격 명사는 목적격 명사보다 유의하게출현빈도수 및 유형수가 낮았으며, 동사와의 기계학습 기반 의미거리가 더 멀었다. 기계학습으로 산출한 의미거리는 행동데이터와 강한 정적 상관관계를 보였다. 논의 및 결론: 본 연구에서 밝힌 한국어의 주어생략현상은 한국어를 사용하는 신경언어장애군의 특징을설명하는 근거자료로 활용될 수 있다. 주격 명사와 동사 간 기계학습 기반 의미거리가 멀다는 결과는 앞으로 한국어를 사용하는 신경언어장애군을 위한 동사 중재에서 주격 명사의 활용 방안이 재고될 필요가 있음을 시사하였다. 더불어 기계학습으로 산출한 의미거리를중재자극선정에서하나의기준으로사용할수있는가능성을확인하였으나, 차후정밀한추가검증이필요하다.",
납기 위반 및 셋업 최소화를 위한 강화학습 기반의 설비 일정계획 모델,2019,"['일정계획', '강화학습', '납기', '셋업비용', '딥러닝', 'Scheduling', 'Reinforcement Learning', 'Due Date', 'Setup Cost', 'Deep Learning']","최근 제조업체들은 제품의 생산방식이 고도화 되고, 복잡해지면서 생산 장비를 효율적으로 사용하는데 어려움을 겪고 있다. 제조공정의 효율성을 방해하는 대표적인 요인들로는 작업물 종류 변경(job change)으로 인한 작업 준비 비용(Setup Cost) 등이 있다. 특히 반도체/LCD 공정과 같이 고가의 생산 장비를 사용하는 공정의 경우 장비의 효율적인 사용이 매우 중요한데, 상호 충돌하는 의사결정인 납기 준수를 최대화 하는 것과 작업물 종류 변경으로 인한 작업 준비 비용을 최소화 하는 것 사이에서 균형을 유지하는 것은 매우 어려운 일이다. 본 연구에서는 납기와 작업 준비 비용이 있는 병렬기계에서 강화학습을 활용하여 납기 및 셋업 비용의 최소화 목표를 달성하는 일정계획 모델을 개발하였다. 제안하는 모델은 DQN(Deep Q-Network) 일정계획 모델로 강화학습기반의 모델이다. 제안모델의 효율성을 측정하기 위해 DQN 모델과 기존에 개발하였던 심층 신경망 기반의 일정계획 생성기법과 휴리스틱 원칙의 결과를 비교하였다. 비교 결과 DQN 일정계획 생성기법이 심층신경망 방식과 휴리스틱 원칙에 비하여 납기 및 셋업 비용이 적은 것을 확인할 수 있었다.","Recently, manufacturers have been struggling to efficiently use production equipment as their production methods become more sophisticated and complex. Typical factors hinderingthe efficiency of the manufacturing process include setup cost due to job change. Especially, in the process of using expensive production equipment such as semiconductor / LCD process, efficient use of equipment is very important. Balancing the tradeoff between meeting the deadline and minimizing setup cost incurred by changes of work type is crucial planning task. In this study, we developed a scheduling model to achieve the goal of minimizing the duedate and setup costs by using reinforcement learning in parallel machines with duedate and work preparation costs. The proposed model is a Deep Q-Network (DQN) scheduling model and is a reinforcement learning-based model. To validate the effectiveness of our proposed model, we compared it against the heuristic model and DNN(deep neural network) based model. It was confirmed that our proposed DQN method causes less due date violation and setup costs than the benchmark methods."
기계학습 기반 비트코인 채굴 난이도 예측 연구,2019,"['Bitcoin', 'Mining difficulty', 'Time-series analysis', 'Predictive model', 'Machine learning']","비트코인은 탈중앙화와 분산원장을 특징으로 하는 암호화폐로서 “작업증명”이라는 채굴시스템을 통해 유지된다.채굴 시스템에서는 블록 생성시간을 일정하게 유지하기 위해 채굴 난이도를 조정하게 되는데, 기존의 채굴 난이도변경 방식은 미래의 해시파워를 반영할 수 없다는 문제가 있다. 따라서 실제시간과 예정시간 사이에 발생하는 오차로 인해 블록생성과 실세계 시간의 불일치를 가중시키게 되고, 결국 거래 기한을 맞추지 못하거나 코인 호핑 공격에취약점을 노출시키게 된다. 블록 생성시간을 일정하게 유지시키기 위한 기존 연구도 여전히 오차 문제를 갖는다. 본연구에서는 이러한 오차를 줄이기 위한 기계학습 기반 채굴 난이도 예측 방안을 제시한다. 이전 해시파워를 학습하여 미래의 해시파워를 예측하고 예측한 값을 이용하여 채굴 난이도를 조정한다. 우리의 실험 결과는 이와 같은 경우기존 채굴 난이도 조정방식보다 오차율을 약 36% 더 줄일 수 있음을 보여준다.","Bitcoin is a cryptocurrency with characteristics such as de-centralization and distributed ledger, and these features aremaintained through a mining system called ""proof of work"". In the mining system, mining difficulty is adjusted to keep theblock generation time constant. However, Bitcoin’s current method to update mining difficulty does not reflect the futurehash power, so the block generation time can not be kept constant and the error occurs between designed time and realtime. This increases the inconsistency between block generation and real world and causes problems such as not meetingdeadlines of transaction and exposing the vulnerability to coin-hopping attack. Previous studies to keep the block generationtime constant still have the error. In this paper, we propose a machine-learning based method to reduce the error. Bytraining with the previous hash power, we predict the future hash power and adjust the mining difficulty. Our experimentalresult shows that the error rate can be reduced by about 36% compared with the current method."
회계이익예측을 위한 기계학습 성과 비교,2019,"['회계이익예측', '기계학습', '예측 성능', 'earnings forecasting', 'machine learning', 'predict performance']","빅데이터와 기계학습 또는 인공지능의 대두로 4차 산업혁명이 촉발될 것으로 예견되고 있다. 이런 맥락에서 빅데이터는 원유로, 기계학습 등은 이 원유를 가공하는 기술로 비유되기도 하며, 의사결정에 유용한 정보를 추출하는 과학적 방법론 또는 프로세스를 지칭하는 데이터 과학이라는 개념도 등장하였다. 이와 같은 흐름에 대응하고자 회계학계에서도 빅데이터와 인공지능 등의 도입에 고심하고 있으나 아직 많은 연구가 이루어지지는 않은 것으로 파악된다. 특히, 국내에서는 이와 관련된 연구는 찾아보기 어려운 것이 현실이다.회계이익이 기업가치를 결정하는 근본 변수로써 회계정보이용자의 의사결정에 차이를 가져오는 정보력을 가진다는 연구는 충분히 이루어졌으나 예측 성능이 좋은 회계이익예측 모형의 개발과 관련된 연구는 많이 이루어지지 않은 것으로 판단된다. 본 연구에서는 기존에 개발된 회계이익예측 모형을 기계학습 맥락에서 재해석하고, 추가로 보다 높은 예측 성능을 나타낸다고 알려져 있는 예측 모형들과 그 성과를 비교하여 회계이익예측에 기계학습 기법의 도입 가능성을 검토하였다.본 연구의 목적을 달성하기 위해 제조업에 속하는 KOSPI 상장 기업 중 12월 결산 법인에 대한 재무비율을 추출하여 활용하였다. 로지스틱 모형에 기반한 Ou and Penman(1989)의 연구 내용을 바탕으로 이를 기계학습 기법으로 재해석한 모형을 기준으로 하고, 기계학습에 가장 일반적으로 사용되고 있는 나무 모형, 랜덤포레스트 모형, 부스팅 기법을 추가하여 이들의 예측성과를 비교하였다. 연구의 결과, 모형들간 예측성과 차이가 전반적으로 통계적 유의성을 가지며, 가장 높은 예측 성능을 나타낸 부스팅 기법을 이용한 경우 가장 낮은 예측력을 보이는 나무 모형에 비하여 약 10% 정도 더 높은 예측력을 갖는 것으로 나타났다.이와 같은 결과는 보다 정확한 회계이익예측 정보를 기계학습 기법을 활용하여 제공할 수 있다는 의의가 있으며, 회계이익예측 이외의 다양한 분야에서도 기계학습을 활용한 연구의 토대가 되기를 기대한다.","Many predict that the fourth industrial revolution will be triggered by the emergence of big data and machine learning(or artificial intelligence). In this context, big data is often likened to crude oil and machine learning is likened to the crude oil processing technology, and the concept of data science has also emerged, referring to scientific methodologies or processes that extract useful information for decision－making. In order to cope with such a trend, even in the field of accounting, researchers are struggling to introduce big data and artificial intelligence, but there are not many studies yet. In particular, it is difficult to find studies related to them in Korea.There have been enough studies that accounting earnings have the information contents that makes a difference in accounting information users’ decision making as a fundamental variable that determines the firm’s value. However, many studies have not been conducted that relate to the development of a predictive accounting earnings forecasting model. In this study, the accounting earnings forecasting model developed in the previous study was reinterpreted in the context of machine learning, and compared its performance with the predictive(machine learning) models known to represent further higher predictive performance to examine the possibility of introducing machine learning techniques in forecasting accounting earnings.To achieve the objective of this study, all 152 financial ratios for closing corporations in December were extracted and utilized from 2009 to 2018 among KOSPI companies belonging to the manufacturing sector provided by TS2000 of the Korea Listed Companies Association.This study reinterpret the findings of Ou and Penman(1989) that used the logistic model basically in the context of machine learning, and the predictability of these techniques was compared by adding the most commonly used models such as tree model, random forest model, and boosting method. As a result of this studies, the predictability difference between the models are statistically significant in overall, and the boosting technique with the highest predictive performance has about 10% higher predictive power than tree model that has lowest predictive power.These results are meaningful in that it is possible to provide more accurate accounting earnings forecast information using machine learning techniques, and it is expected this research to be the basis for the study using machine learning in various accounting research fields other than accounting earnings forecasting."
기계학습을 적용한 신체활동 웨어러블 디바이스의 정확성 검증,2019,"['측정도구', '타당도 검증', '분류 알고리즘', 'SenseWear Armband Mini', 'Measurement Tool', 'Classification Algorithm', 'SenseWear Armband mini']","기계학습 (machine learning)은 다양한 학문영역에서 빠르게 확산되고 있으나 신체활동 관련 자료 분석에는 한정적으로 적용되어 왔다. 이 연구에서는 기계학습 방식을 통해 신체활동 웨어러블 디바이스의 정확성을 검증하는데목적이 있다. 성인 남녀 48명을 대상으로 앉기, 서기, 물걸레질, 물건 옮기기, 걷기, 빠르게 걷기 등과 같은 일련의신체활동을 수행하는 동안 신체활동량을 측정하였다. 모든 신체활동 정보는 신체활동 웨어러블 디바이스 SenseWear Armband Mini (BodyMedia Inc, Jawbone, CA, USA)를 이용하여 수집되었고, 전용 소프트웨어 (SenseWear 8.0)를 통해 가속도기반 물리적 변인과 피부 온도와 같은 생리학적 변인의 자료가 60초 epoch으로 저장되었다. 얻어진 자료는 k-인접이웃분류 (k-Nearest Neighbor), 서포트 벡터 머신 (Support Vector Machine), 랜덤 포레스트 (Random Forest), 의사결정나무 (Decision Tree) 의 4가지 기계학습 알고리즘 분석방식과 전통적으로 이용된통계방법인 로지스틱 회귀 (Logistic Regression)이 적용되어 신체활동을 얼마나 정확하게 분류되는지 비교되었다. 분석결과에 의하면 랜덤 포레스트 (71.43%)와 서포트 벡터 머신 (70.12%)이 다른 알고리즘 보다 상대적으로 높은분류 정확도를 보였다. k-인접이웃분류와 의사결정나무는 각각 61.86%, 50.46%의 정확도를 보였고, 전통적 분석방법인 로지스틱 회귀분석 결과가 가장 낮은 정확도 (47.31%)를 보였다. 또한, 가속도계 기반 자료 하나만을 이용하는것보다 가속도 데이터, 피부 온도 및 피부 반사에 관한 정보를 동시에 사용하였을 때 상대적으로 높은 신체활동 분류 정확도를 보였다. 결론적으로 기계학습을 통한 신체활동 분류 시 랜덤 포레스트와 서포트 벡터 머신 방법 적용이보다 적절하고 가속도계 기반 변인 하나보다 다양한 생리학적 변인의 반영이 필요함을 시사한다.","The method of machine learning could serve as a powerful source to analyze the physical activity data more accurately than traditional analyses. The purpose of this study was to evaluate the accuracy of wearable physical activity tracker through several machine learning algorithms to classify different types of physical activity. A total of 48 participants were asked to perform a series of physical activity including sitting, standing, mopping, walking, brisk walking, and the moving object while wearing the SenseWear Mini Armband (BodyMedia Inc, Jawbone, CA, USA). The data from motion and heat-related sensors were processed and summarized into 1-min epoch by using the software (SenseWear 8.0). The machine learning algorithms of k-Nearest Neighbors (k-NN), Random Forest (RF), Support Vector Machine (SVM), logistic regression, and Decision Tree (DT) were applied to classify physical activity. The algorithm of RF (71.43%) and SVM (70.12%) were more accurate than others. k-NN, DT showed 61.86%, 50.46% accordingly which resulted in higher accuracy than logistic regression; the lowest accuracy of 47.31%. Also, the accuracy was the highest when information on accelerometer, skin temperature, and galvanic skin response was collectively included as feature variables. The use of machine learning algorithms, especially RF and SVM were proven to be useful for the classification of physical activity through the wearable physical activity tracker. Researchers need to consider applying the enhanced method of analyzing physical activity data."
기업부도예측과 기계학습,2019,"['기계학습', '기업부도', '부도예측', '신용위험', '인공신경망', 'Artificial Neural Networks', 'Credit Risk', 'Default', 'Default Prediction', 'Machine Learning']","기업부도에 대한 예측은 경제 전반의 각 분야에서 다양하게 활용된다. 기업은 예측결과를 토대로 경영상태를 진단하고 경영전략을 수립하며, 투자자는 신용위험을 관리하고 투자전략을 조정한다. 정부가 거시건전성 정책을 만들고 금융제도를 설계․개선하는 데에도 이러한 기업부도예측 방법론을 근거로 활용한다. 현재 기업부도예측은 수리통계 모형뿐만 아니라, 기계학습 알고리즘(machine learning algorithm)을 활용한 첨단 금융공학의 일선에 있다. 본 연구는 지금까지 진행된 기업부도예측에 관한 연구를 살펴보고, 통계적 모형과 기계학습 알고리즘의 대표적 방법론을 소개함으로써 관련 분야를 조망한다. 기업부도예측을 위한 주요 통계적 모형은 3세대로 구분할 수 있으며, 각 세대는 대표적으로 판별분석(discriminant analysis), 이항반응모형(binary response model), 위험모형(hazard model)을 사용하여 연구되었다. 기계학습 알고리즘에는 주로 분류방법론이 사용되었으며, SVM(support vector machine), 의사결정나무(decision tree), 인공신경망(artificial neural networks) 알고리즘이 대표적이다. 기계학습 방법론의 발달은 금융 분야의 혁신을 더욱 가속화하며, 이에 따라 새로운 금융서비스의 출현과 데이터 유통에 기반한 데이터 경제의 부상이 뒤따를 것으로 전망된다.","Corporate default predictions are essential in every economic sector. Based on these predictions, companies can diagnose their management statuses and establish management strategies. Investors can manage their credit risk and adjust their investment strategies. Governments can also use them to design macroeconomic policies and improve financial regulations. Currently, corporate default predictions are at the forefront of advanced financial engineering that utilizes not only statistical models but also machine learning algorithms. This study reviews the literature on corporate default predictions and the related field by introducing statistical and mathematical models and machine learning algorithms and their representative methodologies. Statistical models can be classified into three generations and can be studied using discriminant analyses, binary response models, and hazard models. For machine learning algorithms, classification methodologies such as support vector machines, decision trees, and artificial neural network algorithms are mainly used. The development of machine learning methodologies is expected to further accelerate innovation in the financial sector, which, in turn, will be followed by the emergence of new financial services and the rise of the data economy."
주택담보대출의 채무불이행 위험 연구: 기계학습접근법,2019,"['Mortgage Loan', 'Default', 'Machine Learning', 'Logistic Regression', 'Artificial Neural Network', 'Marginal Effect', '주택담보대출', '채무불이행', '기계학습', '로지스틱 회귀분석', '인공신경망', '한계 효과']","주택담보대출의 채무불이행에 영향을 미치는 요인을 분석하기 위해 주로 전통적 계량기법 위주의 분석이 이용되었다. 본 연구에서는 미국 프레디 맥(Freddie Mac)의 유동화된 주택담보대출 자료를 이용하여 기계학습 기반의 채무불이행 모형을 도출하고, 요인별 한계 효과를 계산함으로써 개별 요인이 갖는 통계적 유의성을 확인한다. 기존의 기계학습 모형은 예측력은 우수하나 모형이 현상을 제대로 설명할 수 없는 점은 한계로 지적되어 왔다. 본 연구는 그간 지적되어온 기계 학습의 한계를 넘어, 한계 효과의 개념을 도입함으로써 전통적인 계량 모형과 기계학습 모형의 개별 독립변수의 설명력을 비교하였다. 이를 통해 전통적 방법에 더하여 기계학습 기법이 실무에 보완적으로 활용할 수 있는 가능성을 확인하였다.","In general, to analyze the factors affecting default risk of residential mortgage loan, traditional econometrics based approach has been mainly used. In this study, we estimate a default risk model based on machine learning approach by using the securitized mortgage loan data from Freddie Mac, and confirm the statistical significance by calculating marginal effect of individual risk factors. A machine learning based model is excellent in terms of predicting power, but it is generally pointed out that the model is not good at explaining the causal relationship between variables. In order to overcome long lasting cavity of machine learning approach, this paper introduces the concept of marginal effect and will be able to compare and contrast the explanatory power of individual input variables. By comparing the explanatory powers between the two methods, we also find the possibility of practical use of machine learning techniques complementary to traditional econometrics methods."
작품 가격 추정을 위한 기계 학습 기법의 응용 및 가격 결정 요인 분석,2019,"['Artwork Price', 'K-nearest Neighbor', 'Machine Learning', 'Prediction']",,"Purpose: The purpose of this study is to investigate the interaction effects between price determinants of artworks. We expand the methodology in art market by applying machine learning techniques to estimate the price of artworks and compare linear regression and machine learning in terms of prediction accuracy.Methods: Moderated regression analysis was performed to verify the interaction effects of artistic characteristics on price. The moderating effects were studied by confirming the significance level of the interaction terms of the derived regression equation. In order to derive price estimation model, we use multiple linear regression analysis, which is a parametric statistical technique, and k-nearest neighbor (kNN) regression, which is a nonparametric statistical technique in machine learning methods.Results: Mostly, the influences of the price determinants of art are different according to the auction types and the artist 's reputation. However, the auction type did not control the influence of the genre of the work on the price. As a result of the analysis, the kNN regression was superior to the linear regression analysis based on the prediction accuracy.Conclusion: It provides a theoretical basis for the complexity that exists between pricing determinant factors of artworks. In addition, the nonparametric models and machine learning techniques as well as existing parameter models are implemented to estimate the artworks’ price."
기계학습을 이용한 한국어 대화시스템 도메인 분류,2019,"['한국어 대화시스템', '자연어이해', '도메인 분류', '기계학습', '랜덤 포레스트', 'Korean dialog system', 'Natural language understanding', 'Domain classification', 'Machine learning', 'Random forest']","대화시스템은 인간과 컴퓨터의 상호작용에 새로운 패러다임이 되고 있다. 자연어로써 상호작용함으로써 인간은 보다 자연스럽고 편리하게 각종 서비스를 누릴 수 있게 되었다. 대화시스템의 구조는 일반적으로 음성 인식, 자연어 이해, 문맥 파악 등의 여러 모듈의 파이프라인으로 이뤄지는데, 본 연구에서는 자연어 이해 모듈의 도메인 분류 문제를 풀기 위해 convolutional neural network, random forest 등의 기계학습 모델을 비교하였다. 사람이 직접 태깅한 총 7개 서비스 도메인 데이터에 대하여 각 문장의 도메인을 분류하는 실험을 수행하였고 random forest 모델이 F1 score 0.97 이상으로 가장 높은 성능을 달성한 것을 보였다. 향후 다른 기계학습 모델들을 추가 실험함으로써 도메인 분류 성능 개선을 지속할 계획이다.","Dialog system is becoming a new dominant interaction way between human and computer. It allows people to be provided with various services through natural language. The dialog system has a common structure of a pipeline consisting of several modules (e.g., speech recognition, natural language understanding, and dialog management). In this paper, we tackle a task of domain classification for the natural language understanding module by employing machine learning models such as convolutional neural network and random forest. For our dataset of seven service domains, we showed that the random forest model achieved the best performance (F1 score 0.97). As a future work, we will keep finding a better approach for domain classification by investigating other machine learning models."
분류 알고리즘과 NCA를 활용한 기계학습 기반 구조건전성 모니터링 시스템,2019,"['Classification', 'Dimensionality reduction', 'FBG sensor', 'Machine learning', 'Structural health monitoring.']","본 연구는 복합재 항공기의 비행 데이터를 활용한 기계학습 기반 구조건전성 모니터링 시스템 연구의 예비 연구이다. 본 연구에서는 구조건전성 모니터링에 이용되기에 가장 적합한 기계학습 알고리즘을 선별하고, 실 기체 데이터에 대한 적용을 위해 차원 축소를 수행하였다. 이를 위해 외팔보를 통해 모사된 항공기 날개 구조와 부가 질량을 통해 손상 모사 실험을 진행하고, 분류 알고리즘을 통해 데이터를 손상의 위치와 정도에 따라 구분하였다. 이를 위해 FBG (fiber bragg grating) 센서를 부착한 외팔보의 진동 실험을 통해 정상상태와 12개의 손상상태에 대한 데이터를 취득하고, MATLAB 환경에서 tree, discriminant, SVM (support vector machine), kNN, ensemble 알고리즘의 비교와 파라미터 튜닝을 통해 가장 적합한 알고리즘을 도출하였다. 또한 NCA (neighborhood component analysis)를 이용한 특징 선택을 통해, 실 기체에서 나올 수 있는 고차원 데이터의 관리를 위해 필요한 차원 축소를 수행하였다. 그 결과, quadratic SVM이 NCA를 적용하지 않은 모델에서 98.7%, NCA를 적용한 모델에서 95.9%로 가장 높은 정답률을 보였다. 또한 NCA 적용 후 모델의 예측 속도, 학습 시간, 용량이 모두 향상되었다.","This is a pilot study of machine learning based structural health monitoring system using flight data of composite aircraft. In this study, the most suitable machine learning algorithm for structural health monitoring was selected and dimensionality reduction method for application on the actual flight data was conducted. For these tasks, impact test on the cantilever beam with added mass, which is the simulation of damage in the aircraft wing structure was conducted and classification model for damage states (damage location and level) was trained. Through vibration test of cantilever beam with fiber bragg grating (FBG) sensor, data of normal and 12 damaged states were acquired, and the most suitable algorithm was selected through comparison between algorithms like tree, discriminant, support vector machine (SVM), kNN, ensemble. Besides, through neighborhood component analysis (NCA) feature selection, dimensionality reduction which is necessary to deal with high dimensional flight data was conducted. As a result, quadratic SVMs performed best with 98.7% for without NCA and 95.9% for with NCA. It is also shown that the application of NCA improved prediction speed, training time, and model memory."
기계학습의 미디어 산업 적용 :콘텐츠 평가 및 제작 자원을 중심으로,2019,"['산업조직론', '기계학습', '미디어산업', '문화콘텐츠 평가', '제작지원', 'Industrial Organization Theory', 'Machine Learning', 'Media Industry', 'Content Assessment Valuation', 'Production Support System']","이 연구는 기계학습의 도입이 미디어 산업구조에 어떠한 영향을 미칠 것인가에 대해 산업조직론적 관점에서 살펴보았다. 먼저 기계학습 기법이 미디어 산업에 성공적으로 도입되기 위해서는 각 산업 단계의 조직구성원 사이에서 기계학습 기반 시스템의 필요성에 대한 공감대 형성이 선행되어야 할 것으로 분석된다. 기계학습의 도입은 기존 방송 및 영화산업의 투자 의사결정과정과 제작 과정에 유의미한 변화를 가져올 것이며, 투자 측면에서는 객관적 데이터의 제공으로 인해 효율성이 증대될 것으로 보인다. 또한, 성과가 담보된 장르 및 형식의 콘텐츠에 투자가 집중됨에 따라 다양성이 감소할 가능성이 있다. 제작 측면에서는 창작자의 반복적 행위를 기계학습 시스템이 담당하는 역할을 한다면 생산효율성이 증대될 수 있다.","This study researched the effect of application systems for media industry by using machine learning method focusing on industrial organization theory. First, for applying the system successfully, formation of sympathy about needs is required. The introduction of machine learning can bring change in each stage of value chain especially, decision making process of investment and production process. In investment side, objective performance prediction data can enhance efficiency, and content diversity can decrease with concentrated investment phenomenon to secured content by the system. In production side, if the system support to make creators decrease simple repeat works, production efficiency will increase."
기계학습과 시스템 다이내믹스를 이용한 재난예측 및 대응정책효과 시뮬레이션: 경기도 단기가뭄을 사례로,2019,"['Machine Learning', 'System Dynamics', 'Drought Prediction', 'Climate Changes Mitigation', 'Increasing Residential Water Price', '머신러닝', '기계학습', '시스템 다이내믹스', '가뭄 예측', '기후변화 완화', '상수도 누진세']","우리나라는 홍수에 비해 가뭄에 대한 경험이 부족해 관련 정책이 미흡하다. 일반적으로 정책은 실행 후 효과가 확인되기까지 긴 시일이 걸릴 뿐만 아니라 빈번하게 수정되면 사회적 혼란이 야기되므로 이를 사전에 모의할 수 있는 새로운 방법이 필요하다. 본 연구는 기계학습과 시스템 다이내믹스를 이용하여 농업적 가뭄의 진행양상을 예측하고 이를 토대로 가상의 가뭄대응정책의 효과를 시뮬레이션 하는 전 과정을 다루었다. 연구 대상지는 경기도 남부이며, 연구 결과에 의하면 기계학습에 의해 예측된 3 개월간의 가뭄 후의 토양 수분지도는 농업적 가뭄 분포 패턴을 보여 주었다. 그리고 이 지도로부터 확인된 가뭄우심지역과 동일 취수원을 사용하는 모든 지자체를 대상으로 시스템 다이내믹스를 이용하여 가상의 수도가격 인상정책을 모의하였더니 확보 가능한 수자원양이 미미하여 가뭄완화에 거의 실효성이 없는 것으로 나타났다.","Korea has had fewer droughts than floods; thus, its drought mitigation policies are insufficient. Typically, it takes a long time to confirm the effects of any policy and frequent revisions to a policy can cause social disruption. Therefore, a new method is needed, with which we can simulate policies in advance based on drought situation forecasts. This study deals with policy evaluation, using machine learning and system dynamics, by forecasting agricultural drought trends and simulating the effects of drought mitigation policies. The study area was the southern part of Gyeonggi Province. As a result, the soil moisture map predicted by machine learning for a time after three months of no rainfall clearly showed the resultant agricultural drought distribution. Also, the water price increase policy was simulated using system dynamics and found to be ineffective for drought mitigation because of insufficient water security measures."
기계학습법을 이용한 동해 남서부해역의 표층 이산화탄소분압(fCO<sub>2</sub>) 추정,2019,"['Machine learning', '$fCO_2$', 'East sea', 'Random forest']",,"Accurate evaluation of sea-to-air $CO_2$ flux and its variability is crucial information to the understanding of global carbon cycle and the prediction of atmospheric $CO_2$ concentration. $fCO_2$ observations are sparse in space and time in the East Sea. In this study, we derived high resolution time series of surface $fCO_2$ values in the southwest East Sea, by feeding sea surface temperature (SST), salinity (SSS), chlorophyll-a (CHL), and mixed layer depth (MLD) values, from either satellite-observations or numerical model outputs, to three machine learning models. The root mean square error of the best performing model, a Random Forest (RF) model, was $7.1{\mu}atm$. Important parameters in predicting $fCO_2$ in the RF model were SST and SSS along with time information; CHL and MLD were much less important than the other parameters. The net $CO_2$ flux in the southwest East Sea, calculated from the $fCO_2$ predicted by the RF model, was $-0.76{\pm}1.15mol\;m^{-2}yr^{-1}$, close to the lower bound of the previous estimates in the range of $-0.66{\sim}-2.47mol\;m^{-2}yr^{-1}$. The time series of $fCO_2$ predicted by the RF model showed a significant variation even in a short time interval of a week. For accurate evaluation of the $CO_2$ flux in the Ulleung Basin, it is necessary to conduct high resolution in situ observations in spring when $fCO_2$ changes rapidly."
산림 총일차생산량 예측의 공간적 확장을 위한 인공위성 자료와 기계학습 알고리즘의 활용,2019,"['Gross Primary Production', 'Machine learning', 'MODIS', 'Remote-sensed data']","산림생태계 내의 총일차생산량은 산림 자원 생산량과 직결되고, 산림생태계의 건강성, 산림식물계절및 생태계 서비스의 중요한 지표가 된다. 이 연구에서는 인공위성 자료와 기계학습 알고리즘을 활용하여 우리나라의 산림유역의 총일차생산량을 연구하였다. 에디공분산 타워가 있는 6개 지점에서의 MODIS (Moderate Resolution Imaging Spectroradiometer) 산출물과 에디공분산타워의 총일차생산성으로 연구기간의 75%–80%에해당하는 자료로 기계학습 알고리즘을 훈련하고 나머지 기간으로 구축된 모델의 총일차생산성 예측 결과를검증하였다. 모델을 구축할 때 MODIS 지상 산출물과 대기 산출물을 조합하여 새로운 입력자료(e.g., 포화수증기압차)를 모델의 입력자료(Processed MODIS)로 사용하였을 때와 이러한 과정 없이 QC(Quality control)만 거친 MODIS 산출물을 그대로 입력자료(Unprocessed MODIS)로 사용하였을 때의 총일차생산량을 비교해 보고그 활용 가능성에 대해 고찰하였다. 추가로 MODIS 총일차생산량 산출물(MYD17)과 에디공분산 총일차생산성 및 기계학습 알고리즘 기반의 총일차생산성과의 상관관계를 보고 그 적합성에 대해 논의하였다. 이 연구에서 사용된 기계학습 알고리즘은 Support Vector Machine (SVM)으로 산림생태계 연구에서 가장 많이 사용되고있는 기계학습 알고리즘 중 하나이다. 기계학습 알고리즘 기반(SVM 모델)의 총일차생산량 예측 결과는MODIS 총일차생산량 산출물(MYD17)보다 에디공분산 총일차생산량과 전반적으로 높은 상관관계를 보였고특히 식생 성장을 시작하는 시점의 값을 좀 더 잘 예측하는 결과를 보였다. 단일 지역에서 Unprocessed MODIS 입력자료로 훈련된 SVM 모델 결과는 피어슨 상관계수 0.75 – 0.95 (p < 0.001), 6개의 연구 지점에서 훈련된 SVM 모델 결과는 피어슨 상관계수 0.77 – 0.94 (p < 0.001) 사이를 보였다. 이 결과는 훈련 자료에 다양한 이벤트들이포함되면 모델의 예측력이 향상되는 가능성을 보여주었고 위성영상의 산출물을 재계산하여 새로운 산출물을내는 과정을 거친 위성 자료가 아니어도 그 예측력에는 크게 문제가 없음을 보여주었다.","Forest covers 30% of the Earth’s land area and plays an important role in global carbon flux through its ability to store much greater amounts of carbon than other terrestrial ecosystems. The Gross Primary Production (GPP) represents the productivity of forest ecosystems according to climate change and its effect on the phenology, health, and carbon cycle. In this study, we estimated the daily GPP for a forest ecosystem using remote-sensed data from Moderate Resolution Imaging Spectroradiometer (MODIS) and machine learning algorithms Support Vector Machine (SVM). MODIS products were employed to train the SVM model from 75% to 80% data of the total study period and validated using eddy covariance measurement (EC) data at the six flux tower sites. We also compare the GPP derived from EC and MODIS (MYD17). The MODIS products made use of two data sets: one for Processed MODIS that included calculated by combined products (e.g., Vapor Pressure Deficit), another one for Unprocessed MODIS that used MODIS products without any combined calculation. Statistical analyses, including Pearson correlation coefficient (R), mean squared error (MSE), and root mean square error (RMSE) were used to evaluate the outcomes of the model. In general, the SVM model trained by the Unprocessed MODIS (R = 0.77 – 0.94, p < 0.001) derived from the multi-sites outperformed those trained at a single-site (R = 0.75 – 0.95, p < 0.001). These results show better performance trained by the data including various events and suggest the possibility of using remote-sensed data without complex processes to estimate GPP such as non-stationary ecological processes."
기계학습 기법을 이용한 CNC 공구 마모도 예측에 관한 연구,2019,"['CNC 설비', '머신러닝', '랜덤 포레스트', '서포터 벡터 머신', 'Random Forest', 'XGBoost', 'CNC', 'SVM', 'Machine Learning']","4차 산업혁명이 주목받고 있다. 특히 스마트 팩토리는 제조 분야에서 그 필요성이 강조되고 있다. 현재 제조 분야에서 CNC(Computerized Numeric Controller: 컴퓨터 수치 제어)에 관한 연구가 활발히 진행 중이다. 국내에서는 CNC 설비에 음향 센서, 진동 센서 등 여러 가지 센서를 부착하여 소음, 진동 등 설비 관련 데이터를 수집하는 방안에 관한 연구가 존재한다. 본 연구는 CNC 머신에서 발생하는 데이터를 중심으로 머신러닝 기법을 활용하여 설비 가동 조건이 공구 마모도에 미치는 영향을 분석한다. CNC 설비에서 발생하는 X축, Y축, Z축의 힘, 이동 속도 등 다양한 데이터를 수집한다. 데이터 탐색 기법을 통해 데이터의 특성 및 분포를 분석하였다. 데이터를 RF(Random Forest), XGB(Extreme Gradient Boost), SVM(Support Vector Machine)을 이용하여 CNC 설비 가동 조건이 공구 마모도에 미치는 영향을 분석하였다. 본 연구의 결과는 CNC 설비 가동에서 최적의 조건을 찾고, 이를 바탕으로 품질 향상 및 기계 손상을 예방하는데 활용될 수 있을 것으로 기대된다.","The fourth industrial revolution is noted. It is a smarter factory. At present, research on CNC (Computerized Numeric Controller) is actively underway in the manufacturing field. Domestic CNC equipment, acoustic sensors, vibration sensors, etc. This study can improve efficiency through CNC. Collect various data such as X-axis, Y-axis, Z-axis force, moving speed. Data exploration of the characteristics of the collected data. You can use your data as Random Forest (RF), Extreme Gradient Boost (XGB), and Support Vector Machine (SVM). The result of this study is CNC equipment."
블록체인을 활용한 양질의 기계학습용 데이터 수집 방안 연구,2019,,,"The accuracy of machine learning is greatly affected by amount of learning data and quality of data. Collecting existing Web-based learning data has danger that data unrelated to actual learning can be collected, and it is impossible to secure data transparency. In this paper, we propose a method for collecting data directly in parallel by blocks in a block - chain structure, and comparing the data collected by each block with data in other blocks to select only good data. In the proposed system, each block shares data with each other through a chain of blocks, utilizes the All-reduce structure of Parallel-SGD to select only good quality data through comparison with other block data to construct a learning data set. Also, in order to verify the performance of the proposed architecture, we verify that the original image is only good data among the modulated images using the existing benchmark data set."
기계학습 알고리즘을 활용한 베어링의 고장 예측 알고리즘 개발에 관한 연구,2019,"['기계학습', '고장 예측', '상태 모니터링 시스템', '잔여수명 예측', 'Machine learning', 'Fault diagnosis', 'Condition monitoring', 'Predicting residual life']","산업 현장에서의 기계 및 장비의 고장은 큰 인명피해 및 재산적 피해를 유발시키므로, 시스템의 상태를 실시간으로 파악하는 것이 매우 중요하다. 최근 4차 산업 혁명(Industry 4.0)으로 인해 기계 설비의 자동화/자율화를 위한 연구가 활발히 진행되고 있다. 특히, SVM(Support Vector Machine), RF(Random Forest) 알고리즘을 활용하여 기계 및 장비의 고장을 예측하고 대응할 수 있는 장비 예지보전 기술에 관해 많이 연구되고 있다. 본 논문에서는 기계학습(Machine learning; ML)을 이용한 베어링의 고장 예측에 관한 연구를 진행하였으며, DNN을 포함한 다양한 기계학습알고리즘의 적용을 통하여 베어링의 고장 예측에 적합한 알고리즘에 대하여 기술하였다. 베어링의 고장 예측 알고리즘을 5단계(데이터 전처리, 특징 선택, 데이터 분할, 예측 모델 구성, 예측 모델 개선)로 나누어 설명한다. 본 논문의결과를 활용하여 베어링의 고장 예측뿐만 아니라 다양한 기계 및 장비의 고장을 예측하는 문제에 적용할 수 있다. 또한, 본 논문의 결과를 활용하여 실시간 기계장비의 상태 모니터링 시스템 및 잔여수명 예측에 관한 연구로 확장해나갈 것이다.","Understanding the state of an industrial system in real time is critical because the failure of machines and equipment in the industrial field can cause great loss of life and property damage. Owing to the fourth industrial revolution (Industry 4.0), research on the automation and autonomization of machinery has been actively conducted. In particular, much research has been done on the technology of equipment maintenance and prediction, which can predict and cope with the failure of machines and equipment using support vector machine and random forest algorithms. In this study, we investigate the fault diagnosis of bearings using machine learning (ML). An algorithm suitable for predicting the failure of bearings is developed through the application of various ML algorithms, including deep neural networks. In this study, the fault diagnosis algorithm of the bearing is divided into five steps (data preprocessing, feature selection, data partitioning, configuring forecasting models, and improved forecasting model). The results of this study can be applied not only to the failure prediction of bearings but also to the problem of predicting the failure of various other machines and equipment. In addition, we will advance the research on condition monitoring systems and residual life prediction of real-time mechanical equipment using the results of this study."
기계 학습과 주요 변수를 활용한 열병합발전 시스템 열 수요량 예측,2019,"['Prediction of heating energy usage', 'CHP', 'Energy saving', 'Apartment houses', 'Machine learning', '난방 에너지 수요량 예측', '열병합 발전', '에너지 절약', '공동주택', '기계 학습']","본 연구 결과로 열 에너지 사용량을 미리 예측하여 하루 단위로 미리 운영 방식을 계획해 적용한다면 외기 온도를 이용하여 운전을 하는 기존과 달리, 계획적인 운전으로 열 에너지 공급과 사용량 차이를 최소화하여 환경적, 효율적으로 합리적인 결과를 도출할 수 있다. 또한 사용자의 만족도를 높일 뿐만 아니라 열 관리자에게 원활한 의사결정 판단에 도움을 줄 수 있다. 다만 본 연구 결과 도출을 위한 데이터 수집 시 스케줄 및 전날 열 에너지 사용량 데이터화는 실측 및 수기로 작성하기에 번거로움이 따른다. 또한, 예측 모델을 개발하는 기초 연구로서 열병합 발전시스템을 사용하는 특정 건물의 데이터를 사용하였는데 실증을 고려한 향후 연구에서는 특정 건물이 아닌 다양성이 확보된 연구로 진행되어야 한다.본 연구의 결과는 실제 측정된 열 에너지 수요량 데이터를 활용해 신뢰할 수 있는 수준의 다음 날 열 에너지 수요량을 예측할 수 있었다. 향후 예측한 모델이 열병합 발전시스템에서 적용하여 낭비되는 폐열을 최소화하여 에너지 절약을 도모하고, 전날 측정 가능한 간단한 데이터들을 이용해 열 공급자들의 열량 예측 및 운영 계획에 편의를 기여할 것으로 기대한다.","This study aimed to minimize the wasted heat by predicting the amount of heat energy consumed a day before heating. The flow rate and schedule variables data were measured in the apartment using cogeneration system. This study used ANN and SVM as machine learning prediction algorithms and was verified by CvRMSE and MBE based on the criteria provided by ASHRAE Guideline 14. As a result, ANN derived an error of CvRMSE 8.75% and MBE 7.13%, respectively. The SVM was classified into three cases, which satisfied all the criteria except for linear of CvRMSE. Thus, using the actual measured heating energy usage data, machine learning can be used to predict a reliable level of thermal energy usage."
기계학습을 이용한 원자로 중성미자 선별 연구,2019,"['기계학습', '중성미자', '액체섬광검출용액', '진동변환상수', '차세대 중성미자 검출기', 'Machine learning', 'Neutrino', 'Liquid scintillator', 'Neutrino mixing angle', 'Next generation neutrino detector']","차세대 대형 중성미자 검출 실험에서 배경사건과 원하는 신호를 효율적으로 선별하는 것은 매우 중요하다. 이를 위해서 현재 유용하게 사용되고 있는 분석 기술의 하나인 기계학습을 사용하여 중성미자 신호 선별에 적용하였을 때의 결과를 살펴보고자 한다. 이를 위해 비교적 특징이 잘 알려지고, 상대적으로통계량이 높은 원자로 중성미자의 역베타 붕괴 반응 이후 신호와 배경사건들을 몬테카를로 시뮬레이션을통하여 재현하고, 기계학습을 통한 신호선별 효율을 확인하였다. 최종적으로는 향후 차세대 중성미자실험에서 중요한 도구로 사용될 수 있을 것으로 기대한다.","For the next-generation massive neutrino experiments, selecting a signal in the background events is very important. To do this, we investigated the results of applying a machine learning technique to the selection of neutrino signals. The neutrino signal after inverse beta decay and the background events in a gadolinium-loaded liquid scintillation detector were reproduced by using Monte Carlo simulations. The inverse beta decay process is well-known and has relatively high statistical quantities for this simulation. In this study, an efficiency of signal selection through machine learning was obtained, and in this paper several results are briefly described. Finally, the machine learning technique is expected to become an important tool for use in the next-generation neutrino experiment."
웹 크롤링과 기계학습 기법을 이용한 경영학 분야 KCI 저널의 주제어 분석,2019,"['Business Administration', 'Keyword Analysis', 'Trend', 'Association Rules', 'Hierarchical Clustering', '경영학', '주제어 분석', '추세분석', '연관규칙 분석', '계층적 군집화']","경영학은 이론, 실천, 과학, 기술 네 가지 측면을 지닌 종합학문으로 다양한 연구 대상을 선정하여 활발하게연구되고 있는 분야이다. 시대의 흐름에 따라 학문이 진부화되는 걸 방지하기 위해 새로운 연구주제 발견과다른 분야와 융복합하여 새로운 방향으로 발전을 도모하고 있다. 이에 새로운 연구 분야를 탐색하고 소멸하는과정을 빠르게 탐색하기 위해 주제어 분석을 시행하였다. 최근 인터넷의 등장과 대규모 비정형 데이터를 다루는개념과 기술이 급속도로 발전하면서 양질의 정보를 시간적·물리적 제약 없이 빠르게 도출할 수 있게 되었다.본 연구에서는 2013년부터 2017년까지 5년간 KCI(Korea citation index) 등재지에 게재된 경영학 분야 논문을 웹 크롤러를 활용하여 총 8,185편의 논문을 수집하고, 데이터 클리닝 및 전처리 과정을 거쳐 4,210편에대한 논문의 주제어 분석하였다. 주제어는 두 가지로 방식으로 비교·분석하였다. 첫째, 말뭉치에서 작은 단위로나누는 토큰화 과정을 단일 명사로만 추출한 주제어 집합(a)과 저자들이 표현한 주제어 의미를 그대로 살린주제어 집합(b)으로 분류하였다. 둘째, 똑같은 뜻이지만 다양한 표현방식으로 분리된 단어를 유의어 사전을구축하여 한 단어로 통합하였다. 분석에 사용된 기법은 빈도 및 추세분석과 기계학습 기법인 연관규칙 분석과계층적 군집화를 사용하여 의미 있는 패턴을 발견하고자 하였다.분석 결과, 빈도분석에서 5년간 활발하게 연구된 연구주제는 기업의 사회적 책임, 기업가정신, 고객 만족, 직무 만족, 신뢰 순으로 도출되었고, 추세분석에서 시간의 흐름에 따라 인사와 조직에 관한 연구에서 2016년부터 스타트업 주제어가 상승하였다. 연관규칙 분석은 지지도를 기준으로 결과를 도출하고 의미 있는 규칙을발견하였으며, 계층적 군집화에서 혁신과 창의성은 빅데이터와 관련된 것으로 도출되었다. 결과적으로 주제어집합(a)과 집합(b)을 비교·분석한 결과 상당한 차이가 존재하였다.본 연구의 통해 개발된 웹 문서에서 자동으로 원하는 정보를 탐색하고 수집하는 웹 크롤러, 언어를 다루는자연어 처리 그리고 기계학습 기법을 적용하면 유의미한 결과를 짧은 시간 내에 도출할 수 있을 것으로 판단된다. 그리고 향후 경영학 분야의 연구 동향과 패턴을 발견하는데 이론적, 실무적 시사점을 제공하고 웹 크롤러와기계학습 기법이 경영학 분야에 활발히 적용될 수 있을 것으로 기대된다.","Business administration is a comprehensive study with four aspects of theory, practice, science, and technology, and various research subjects have selected and actively studied. However, in order to prevent the obsolescence of learning over time, we tried to develop into a new direction by combining with other fields. Therefore, we analyzed the keywords to quickly search for the process of exploring and disappearing new research fields. With the advent of the Internet and the rapid development of technologies and concepts that deal with unstructured data, it has become possible to derive high-quality information quickly.In this study, a total of 8,185 papers were collected by using a web crawler in the field of business administration published in KCI (Korea citation index) list for five years from 2013 to 2017, and 4,210 papers. The keywords were compared and analyzed in two ways. It has integrated the words that are the same meaning but separate in various expressions into one word by synonyms dictionary. Moreover, we have classified them into two sets. A set of keywords (a) was a tokenized word with the smallest unit of word separation, and a set of keywords (b) in which the meanings of the words of the authors expressed as they are.The techniques used in the analysis were to find meaningful patterns using frequency and trend analysis, machine learning methods such as association rules and hierarchical clustering. As a result of the analysis, the keywords that have actively researched for five years in the frequency analysis derived from corporate social responsibility, entrepreneurship, customer satisfaction, job satisfaction, and trust. In the trend analysis, from 2016, the start-up has risen. In the association rules, results were derived based on support and meaningful rules were found. In the hierarchical clustering, the big data was related to innovation and creativity. Consequentially, there was a significant difference between the result the keyword set (a) and (b).In this study, the web crawler that automatically searches and collects data from web documents, natural language processing of handling text data, and applied machine learning techniques are expected to be able to derive meaningful relationships in a short time. It is expected that the web crawler and machine learning techniques will be actively applied in the field of business administration by providing the theoretical and practical implications for finding research keywords trends and patterns in the field of business administration in the future."
기계학습을 활용한 항공표적 긴급표적처리 발전방안 연구,2019,"['Machine Learning(기계학습)', 'Dynamic Targeting(긴급표적처리)', 'Target Priority(표적 우선순위)', 'Decision Tree(의사결정 나무)']",,"In order to prepare for the future warfare environment, which requires a faster operational tempo, it is necessary to utilize the fourth industrial revolution technology in the field of military operations. This study propose a methodology, ‘machine learning based dynamic targeting’, which can contribute to reduce required man-hour for dynamic targeting. Specifically, a decision tree algorithm is considered to apply to dynamic targeting process. The algorithm learns target prioritization patterns from JIPTL(Joint Integrated Prioritized Target List) which is the result of the deliberate targeting, and then learned algorithm rapidly(almost real-time) determines priorities for new targets that occur during ATO(Air Tasking Order) execution. An experiment is performed with artificially generated data to demonstrate the applicability of the methodology."
기계학습 방법에 의한 프로스포츠에서의 관중 수 예측과 그 요인들 연구,2019,"['machine learning', 'pro sports', 'attendance', 'factor.', '기계학습', '프로스포츠', '관중', '요인.']","프로스포츠에서 관중은 리그 운영을 위해 중요한 존재이다. 본 연구에서는 기계학습 기법을 이용하여 관중 수와 관련된 연구를 수행하였다. 관련 연구에서 많이 활용되는 프로야구 외에 프로농구, 남자 프로배구, 여자 프로배구 등 여러 프로스포츠의 최근 4년 치 일별 경기 자료를 수집하여 분석에 활용하였다. 종목별로 관중 수에 영향을 주는 요인들을 변수 중요도를 활용하여 계산하였으며 다양한 예측 모형을 통해 관중 수 예측 모형을 구축하였다. 이를 통해 종목에 따라 관중 수에 영향을 미치는 요인들이 서로 다름을 파악하였다. 홈팀이 관중 수에 가장 큰 영향을 주는 변수이었으며 프로야구, 프로농구, 남자 프로배구의 경우 경기 일의 휴일 여부가 두 번째로 중요한 변수였다. 여자 프로배구는 시즌 진행 정도를 나타내는 변수가 관중 수에 두 번째로 영향을 미치는 변수였다. 또한, 여러 기계학습 기법 중에서 인공신경망을 적용한 관중 수 예측 모형이 가장 좋은 성능을 보이며 여자 프로배구의 경우 선형 회귀분석 모형이 인공신경망을 제외한 방법들보다 성능이 더 좋았다. 종목별로 비교했을 때 프로농구, 남자 프로배구, 프로야구, 여자 프로배구의 순으로 관중 수 예측 모형의 성능이 좋음을 확인하였다.","Spectators are important for league management. The number of spectators was studied using machine learning methods. The recent four years’ daily game data from professional baseball, professional basketball, male professional volleyball, and female professional volleyball were collected and analyzed. The variable importance was calculated to figure out the factors which affected the number of spectators for the different professional sports and the attendance prediction models were constructed through various classification techniques. It was found that the factors affecting the number of spectators were different for the different professional sports. The home team was the most influential factors on several professional sports and the next important factor was whether the game was open on holidays for professional baseball, professional basketball, and male professional volleyball except female professional volleyball. In addition, the attendance prediction model through an artificial neural networks showed best performance and the linear regression model was the second best model in female professional volleyball. The performance of the prediction of the number of spectators was better in the order of professional basketball, male professional volleyball, professional baseball, and female professional volleyball."
기계학습 기반의 실시간 악성코드 탐지를 위한 최적 특징 선택 방법,2019,"['Malware', 'Machine Learning', 'PEFeatureExtractor', 'Feature Selection', 'Real Time Detection', 'Intelligent Classifier']",,"The performance of an intelligent classifier for detecting malwares added to multimedia contents based on machine learning is highly dependent on the properties of feature set. Especially, in order to determine the malicious code in real time the size of feature set should be as short as possible without reducing the accuracy. In this paper, we introduce an optimal feature selection method to satisfy both high detection rate and the minimum length of feature set against the feature set provided by PEFeatureExtractor well known as a feature extraction tool. For the evaluation of the proposed method, we perform the experiments using Windows Portable Executables 32bits."
당뇨병 치료제 후보약물 정보를 이용한 기계 학습 모델과 주요 분자표현자 도출,2019,"['Candidate drug information', 'Partial least square', 'Variable importance in projection', 'Finding major molecular descriptor', 'Antidiabetic prediction', '후보약물 정보', '부분최소자승', '변수중요도척도', '주요 분자표현자 도출', '항당뇨 예측']","본 연구는 당뇨병 치료제 후보약물 정보를 이용하여 항당뇨에 영향을 미치는 물질구조를 발견하는데 목적이 있다. 정량적구조 활성관계를 이용한 기계 학습 모델을 만들고 부분최소자승 알고리즘을 통해 실험데이터 별로 결정계수를 파악한 후 변수중요도척도를 활용하여 주요 분자표현자를 도출하였다. 연구 결과, 후보약물 구조정보를 반영한 molecular access system fingerprint 데이터로 분석한 결과가 in vitro 데이터를 이용한 분석 결과보다 설명력이 높았으며, 항당뇨에 영향을 미치는 주요 분자표현자 역시 다양하게 도출할 수 있었다. 제안된 항당뇨 예측 및 주요인자 분석 방법을 활용한다면 유사한 과정을 반복 실험하는 기존 신약개발 방식과는 달리, 많은 비용과 시간이 소요되는 후보물질 스크리닝 (screening) 기간을 최소화하고, 신약개발 탐색기간도 단축하는 계기가 될 수 있을 것으로 기대한다.","The purpose of this study is to find out the structure of the substance that affects antidiabetic using the candidate drug information for diabetes treatment. A quantitative structure activity relationship model based on machine learning method was constructed and major molecular descriptors were determined for each experimental data variables from coefficient values using a partial least squares algorithm. The results of the analysis of the molecular access system fingerprint data reflecting the candidate drug structure information were higher than those of the in vitro data analysis in terms of goodness-of-fit, and the major molecular expression factors affecting the antidiabetic effect were also variously derived. If the proposed method is applied to the new drug development environment, it is possible to reduce the cost for conducting candidate screening experiment and to shorten the search time for new drug development."
기계학습 알고리즘을 이용한 보행만족도 예측모형 개발,2019,"['Pedestrian Satisfaction', 'Machine Learning', 'Logistic Regression', 'Random Forest', 'Artificial Neural Network', '보행만족도', '기계학습', '로지스틱 모형', '랜덤 포레스트', '인공신경망']","본 연구의 목적은 보행만족도 기반의 보행 경로 서비스 개발을위한, 기계학습 알고리즘 기반 보행만족도 예측모형 개발에 있다. 현재까지 몇몇 연구들에서 서울시 유동인구 조사에 포함된보행만족도 자료를 이용하여 보행만족도에 영향을 미치는 요인을 분석하였다(이수기 외, 2014; Kim et al., 2014). 이 연구들은전통적인 통계 기법을 이용하여 보행만족도에 영향을 미치는 요인들을 분석하였지만, 보행만족도 기반의 보행 경로 서비스 제공을 위해서는 특정한 보행환경에서 보행자가 느끼는 만족도를 예측하여야 서비스 이용자에게 적절한 경로를 제시할 수 있다.따라서 본 연구에서는 예측성능 최적화에 적합한 기계학습 알고리즘을 이용하여 보행만족도 예측모형을 개발하고자 한다. 이를 위해 서울시 유동인구 조사자료를 이용하여 로지스틱, 랜덤포레스트, 인공신경망 알고리즘 기반의 보행만족도 모형을 개발하고, 이 모형들의 예측성능을 비교하여 최적의 모형을 도출할것이다.더불어 보행만족도는 동일 환경에 대해서 신체 연령에 따라 다르게 평가될 수 있음을 고려하였다. 예를 들어 같은 경사도라도젊은 보행자와 고령 보행자가 느끼는 부담강의 정도가 다를 수 있다. 따라서 교통약자인 60세 이상 고령 보행자를 다른 연령대 보행자와 분리하여 보행만족도 모형을 구축하고, 이 두 보행자 집단의 보행만족도에 영향을 미치는 요인의 중요도를 비교 분석하고자 한다.",
타브 숫자 인식을 위한 기계 학습 알고리즘의 성능 비교,2019,"['숫자 인식', '기계학습', '프로토타입 선택', '영상처리', '교차평가', 'Digit Recognition', 'Machine Learning', 'Prototype Selection', 'Image Processing', 'Cross-Validation']",,"In this paper, the classification performance of learning algorithms is compared for TAB digit recognition. The TAB digits that are segmented from TAB musical notes contain TAB lines and musical symbols. The labeling method and non-linear filter are designed and applied to extract fret digits only. The shift operation of the 4 directions is applied to generate more data. The selected models are Bayesian classifier, support vector machine, prototype based learning, multi-layer perceptron, and convolutional neural network. The result shows that the mean accuracy of the Bayesian classifier is about 85.0% while that of the others reaches more than 99.0%. In addition, the convolutional neural network outperforms the others in terms of generalization and the step of the data preprocessing."
미세먼지 예측을 위한 기계 학습 알고리즘의 적합성 평가,2019,,,"Due to the human influence of particulate matter, various studies are being conducted to predict it using past data measured in the atmospheric environment monitoring network. However, it is difficult to precisely set the measurement environment and detailed conditions of the previously designed predictive model, and it is necessary to design a new predictive model based on the existing research results because of the problems such as the missing of the weather data. In this paper, as a previous study for particulate matter prediction, the conformity of the algorithm for particulate matter prediction was evaluated by designing the prediction model through the multiple linear regression and the artificial neural network, which are machine learning algorithms. As a result of the prediction performance comparison through RMSE, 18.13 for the MLR model and 14.31 for the MLP model, and the artificial neural network model was more conformable for predicting the particulate matter concentration."
기계학습 기반 비트코인 네트워크 트랜잭션 수 예측에 관한 연구,2019,"['Blockchain', 'Bitcoin transaction', 'Machine Learning']","블록체인 기술을 기반으로 만들어진 비트코인은 Satoshi Nagamoto에 의해 개발된 온라인 암호화폐이다. 2009년 1월 3일 최초로 발행된 비트코인은 트랜잭션 수의 증가와 함께 급속도로 발전 중이다. 그러나 비트코인 트랜잭션 수의 증가에 따른 부작용이 발생하고 있다. 비트코인 트랜잭션 수를 예측하는 것은 비트코인 네트워크에 발생하는 부작용에 대비하기 위해 중요하다. 본 논문은 두 가지 기계학습 알고리즘을 적용하여 비트코인 트랜잭션 수를 예측하는 모델을 설계한 뒤, 실험을 통해 비트코인 트랜잭션 수를 예측하는 모델을 제안한다.","Bitcoin, based on the blockchain technology is an online crypto-currency developed by Satoshi Nagamoto. Bitcoin, which was first issued on January 3, 2009, is rapidly evolving with increasing number of transactions. However, untoward incidents are occurring due to an increase in the number of Bitcoin transactions. Predicting the number of Bitcoin transactions is important to prepare for any issues that can occur in the Bitcoin network. This paper proposes to design model for predicting the number of Bitcoin transactions by applying two machine learning algorithms and then a model for predicting the number of Bitcoin transactions through experiments."
크라우드펀딩 성공 예측 모델에 대한 다시점 분석: 기계학습 기법 활용,2019,"['Crowdfunding', 'Prediction model', 'Machine learning', 'Kickstarter']",,"Considering financial risks for crowdfunding, it is important to predict the successful crowdfunding projects before the end of fundraising. Most of previous research on predictive models for crowdfunding success mainly analyzed crowdfunding projects which had ended fundraising. Therefore, there is a problem that creators and backers do not consider success timing of the projects. Examining crowdfunding projects in multi-phases, this research aims to develop a predictive model for successful crowdfunding projects in three stages. For this study, we collected 21,641 crowdfunding projects from Kickstarter, a representative crowdfunding platform, which were in fundraising process from August 15, 2016 to February 15, 2018. Then we applied several machine learning methods. Considering multi-phases in crowdfunding, we developed three stage prediction models and found difference from existing approaches. This study contributes to making three prediction models for success of crowdfunding projects in a different perspective and providing practical implications to both creators and backers of crowdfunding projects."
벽면 이동로봇의 자동 균열검출에 적합한 기계학습 알고리즘에 관한 연구,2019,"['Wall-Climbing Robot', 'Crack Detection Algorithms', 'Machine Learning', 'Localization', '벽면 이동로봇', '균열검출 알고리즘', '기계학습', '위치추정']","본 논문은 진공을 이용한 흡착방식과 바퀴형 이동방식을 사용하는 벽면 이동로봇의 구성과 이러한 임베디드 환경에 적합하고 기계학습에 기반한 벽면 균열 자동 검출 알고리즘의 성능 비교에 관한 연구이다. 임베디드 시스템 환경에서 객체 학습을 위해 YOLO 등 최근에 시도된 학습 방법들을 적용하여 성능을 비교, 검토하였으며 기존의 에지 검출 알고리즘들과도 성능을 비교하였다. 결국, 본 연구에서는 균열검출을 잘하며 임베디드 환경에도 적합한 최적의 기계학습방법을 선택하고 기존 방법과 성능을 비교하여 우수성을 제시하였다. 또한, 검출된 균열의 영상을 저장하고 위치 정보를 추정하여 균열에 대한 정보를 관리자 기기로 전송하는 지능적인 문제해결 기능을 구축하였다.",
특허기술 고객충성도에 대한 기계학습 예측모델링 연구,2019,"['Patent loyalty', 'Customer loyalty', 'Machine learning', 'Prediction', '특허기술', '고객충성도', '기계학습', '기술이전성과', '기업성과']","본 연구에서는 기계학습 알고리즘을 적용하여 특허기술의 고객충성도의 결정요인이 무엇인지를 탐색하고자 하였다. 기계학습 알고리즘인 선형모델, 선형회귀모델 및 인공신경망모델을 적용하여 예측모델링을 수행한 결과 인공신경망모델이 가장 예측력의 정도가 높은 것으로 분석되었다. 인공신경망모델을 통해 분석한 결과, 기술충성도의 영향요인으로 매출액 변화율과 연구개발비 변화율이 다른 예측변인들에 비해 중요한 것으로 나타났다.본 연구는 기술충성도의 예측을 위해서 기계학습 기법을 통한 예측모델링을 수행하고 실무적인 시사점을 도출했다는 점에서 의의가 있다. 특히 본 연구에서는 기술충성도 예측모델의 성능평가를 통해 선형회귀모델에 의한 것보다 인공신경망이 예측오차가 가장 적어서 예측성능이 우수하다는 것을 검증하였다. 이와 함께 기술충성도의 영향요인으로 매출액 변화율과 연구개발비 변화율 등이 다른 예측변인들에 비해 중요하다는 점을 알 수 있었다.본 연구는 기술충성도의 예측변수로 특허기술의 특성변수인 질적 우수성과 활용가능성 만을 채택했다는 점에서 한계가 있을 수 있다. 향후 연구에서는 다양한 예측변수(특허경영활동, 자원역량, 조직역량, 성과확산 역량 등)를 도입하여 연구할 필요가 있다. 또한 연구대상을 A연구원만으로 제한했다는 점에서 연구 결과를 일반화하는 데 한계가 있다고 볼 수 있다. 따라서 향후 연구에서는 연구대상 기관 수를 증가시키는 것이 필요할 것이다.",
지리변수 기반 기계학습을 이용한 산지 소유역 유기층 토양 영양분의 공간적 분포 예측,2019,"['mountainous soil', 'organic layer', 'geographical variable', 'machine learning', 'digital soil mapping', '산지토양', '유기층', '지리변수', '기계학습', '전자토양도 작성']","산지토양 내 유기층은 가장 큰 영양분 저장소이자 토양 관리에서 중요한 대상이다. 본 연구는 지리변수 기반 기계학습 모형을 이용하여 산지토양 유기층 영양분의 공간적 분포를 예측하고자 하였다. 이를 위해 총 90개의 유기층 토양 시료를강원도 소양강 일대 소유역에서 채취하였다. 토양예측 모형으로 랜덤포레스트(random forest)를 사용하였다. 지리변수로 지리좌표(XY)와 중앙점에서 유클리드 거리(CD), 표본 위치에서 유클리드 거리(EBD)를 사용하였다. 다양한 지리변수의 효과를 확인하기 위해 환경변수만 사용했을 때, 각 지리변수와 함께 사용했을 때(환경변수+XY, 환경변수+CD, 환경변수+EBD), 모든 지리변수와 환경변수를 사용했을 때(환경변수+XY+CD+EBD), 마지막으로 지리변수만 사용했을 때(XY+CD+EBD) 등 총 6가지 결과를 비교하였다. 연구 결과로 황을 제외하고 모든 영양분에 대해 환경변수와 지리변수를함께 고려했을 때 모형의 예측력이 상대적으로 높았고, 반대로 지리변수만을 고려했을 때 낮은 예측력을 보였다. 다양한 지리변수 중에서 모든 토양 영양분에 대해서 예측력이 높았던 단일한 지리변수는 없었다. 선택된 중요한 변수를 살펴보면 고도, 사면곡면률, 계곡깊이, 사면유역지수 등으로 지형변수가 산지토양 유기층 영양분의 공간적 분포에 주로 영향을 주었다고판단하였다. 본 연구는 산지 토양 생태계를 이해하고 관리하기 위한 중요한 정보로 향후 활용될 수 있을 것이다.","The organic soil layer in the mountainous area is one of the largest nutrient sinks and an important target in soil management. The purpose of this study is to predict the spatial distribution of organic layer nutrients in mountainous soils using the geographical variable-based machine learning model. A total of 90 organic soil samples were collected from the subwatershed area of the Soyang River in Gangwon Province. Random forest was used as a soil prediction model. Geographical coordinates (XY), euclidean distance to the center (CD), and euclidean distances from observation locations (Euclidean Buffer Distance, EBD) were used as geographical variables. In order to check the effect of various geographical variables, we compare the results of using only environment variables (EV), when used with each geographical variable (EV+XY, EV+CD, EV+EBD), when using all geographical variables and environment variables (EV+XY, EV+CD, EV+EBD), and finally when using only geographical variables (XY+CD+EBD). As a result, the predictive power of the models was high for all of the nutrients except for sulfur when environmental and geographical variables were considered together. On the other hand, low prediction power was obtained when only geographical variables were considered. Among the various geographical variables, there was no single geographical variable that was highly predictive for all soil nutrients. For the selected important variables, the topographic variables such as elevation, surface curvature, valley depth, and catchment area mainly affected the spatial distribution of soil organic layer nutrients in the mountainous area. It is expected that this study will be used as spatial information for understanding and managing the mountain soil ecosystem in the future."
기계학습을 이용한 필터의 성능 저하 예측,2019,"['Remaining useful life', 'Prognostics and health management', 'Condition based maintenance', 'Machine learning', 'Product usage']",,"Unexpected facility failures of heavy industry derive large cost so that it is important to prevent it beforehand by estimating machine health status, predicting remaining useful life (RUL), and determining proper time schedule of facility for inspection and replacement. Accordingly, active researches have been proceeding recently, such as prognostics and health management (PHM), condition based maintenance (CBM) method for failure prediction, and so on. The PHM and CBM are technologies that collect operating and environment data related to the failure/ lifetime of the equipment and predict failure in advance before failure. In accordance with this purpose, this study proposes a method to predict remaining useful life by collected operating and environment data. The methodology proposed in this study includes signal processing techniques to remove noise signal from sensor data, and clustering, support vector machine, and deep learning, which are used to calculate and predicting reduction rate according to usage environment."
기계학습방법을 활용한 대형 집단급식소의 식수 예측: S시청 구내직원식당의 실데이터를 기반으로,2019,"['institutional foodservice', 'meal forecasting', 'classification model', 'machine learning', 'big data analytics']",,"Predicting the number of meals in a foodservice organization is an important decision-making process that is essential for successful food production, such as reducing the amount of residue, preventing menu quality deterioration, and preventing rising costs. Compared to other demand forecasts, the menu of dietary personnel includes diverse menus, and various dietary supplements include a range of side dishes. In addition to the menus, diverse subjects for prediction are very difficult problems. Therefore, the purpose of this study was to establish a method for predicting the number of meals including predictive modeling and considering various factors in addition to menus which are actually used in the field. For this purpose, 63 variables in eight categories such as the daily available number of people for the meals, the number of people in the time series, daily menu details, weekdays or seasons, days before or after holidays, weather and temperature, holidays or year-end, and events were identified as decision variables. An ensemble model using six prediction models was then constructed to predict the number of meals. As a result, the prediction error rate was reduced from 10%∼11% to approximately 6∼7%, which was expected to reduce the residual amount by approximately 40%."
기계학습 기반의 P2P대출 마감 시간 예측 모델 연구,2019,"['P2P 대출', '투자정보', '기계학습', '시계열 분석', 'P2P lending', 'investment information', 'machine learning', 'time series analysis']","최근 온라인플랫폼을 통해 개인끼리의 대출 및 투자가 가능한 P2P대출 이용자가 급증하고 있다. 그러나 P2P대출은 투자자가 금전적 위험을 직접 부담하기 때문에 보다 신중한 투자판단으로 상품이 마감하면서 투자에 실패하기도 한다. 본 논문은 P2P대출 투자 상품에 대한 마감 시간 정보 제공을 위해 투자 상품이 일정 시점으로부터 마감까지 얼마나 걸리는지를 예측한다. 마감 시간을 예측하기 위하여 실제 P2P상품에 대한 투자정보를 기반으로 시계열 데이터와 Step 데이터로 변환하고 기계학습 알고리즘을 사용하여 회귀, 분류, 시계열 예측 모델을 생성하였다. 성능평가 결과 시계열 데이터 기반 모델은 Multi-layer Perceptron 회귀모델과 분류모델이 0.725, 0.703로 가장 높은 성능을 보였으며 Step 데이터 기반 모델 또한 Multi-layer Perceptron 회귀모델과 분류모델이 0.782, 0.651로 가장 높은 성능을 보였다.","Recently, there has been an increase in P2P lending users, a product that supports investments through lending among individuals using online platforms. However, since P2P lending's investors have to take financial risks, the investors may fail to investment due to the close of investment while they considering whether to invest or not. This paper predicts how long an investment product will take from a certain point to the close in order to provide deadline information for P2P loan investment products. To predicts the investment deadline, we have transforms into Timeseries data and Step data based on investment information on actual P2P products. The regression, classification, and time series prediction model were generated using machine learning algorithm. The results of the performance evaluation showed that in the Timeseries data-based model, the Multi-layer Perceptron regression model and the classification model showed the highest performance at 0.725 and 0.703 respectively. The Step data-based model was also the highest with the Multi-layer Perceptron regression model and the classification model at 0.782 and 0.651 respectively."
기계학습 기반 유전자 발현 데이터를 이용한 치주질환 예측,2019,,,"Periodontal disease is observed in many adult persons. However we has not clear know the molecular mechanism and how to treat the disease at the molecular levels. Here, we investigated the molecular differences between periodontal disease and normal controls using gene expression data. In particular, we checked whether the periodontal disease and normal tissues would be classified by machine learning algorithms using gene expression data. Moreover, we revealed the differentially expression genes and their function. As a result, we revealed that the periodontal disease and normal control samples were clearly clustered. In addition, by applying several classification algorithms, such as decision trees, random forests, support vector machines, the two samples were classified well with high accuracy, sensitivity and specificity, even though the dataset was imbalanced. Finally, we found that the genes which were related to inflammation and immune response, were usually have distinct patterns between the two classes."
기계학습 알고리즘에 기반한 뇌파 데이터의 감정분류 및 정확도 향상에 관한 연구,2019,"['DEAP dataset', 'ICA', 'Arousal-Valence plane', 'Random Forest', 'Attribute Selected Classifier', 'DEAP 데이터 세트', '독립성분분석', 'Arousal-Valence 평면', '랜덤 포레스트', '속성 선택적 분류기']","본 연구에서는 공개된 뇌파 데이터인 DEAP(A Database for Emotion Analysis using Physiological Signals) 데이터 세트를 활용한 감정분류·분석 및 정확도 향상에 대한 실험을 진행하였다. 실험에는 32명에 대한 32개의 뇌파측정 채널 데이터가 모두 사용되었다. 전처리과정에서는 뇌파데이터에 대한 256Hz 샘플링작업을 진행하였고, 유한 임펄스 응답 필터를 사용하여 주파수 대역별로 쎄타(4-8Hz), 슬로 알파(8-10Hz), 알파(8-12Hz), 베타(12-30Hz), 감마(31-45Hz) 파형에 대한 데이터를 추출하였다. 추출한 데이터는 시간-주파수 변형을 통하여 데이터의 상태를 구분한후에, 독립성분분석방법을 통해 잡음(Artifact)을 제거하여 데이터를 정제했다. 도출된 데이터는 분류기 기계학습 알고리즘 실험을 시행할 수있도록 CSV 파일로 변형 하였으며, 감정분류에는 Arousal-Valence 평면을 사용하였다. 감정은 “긍정적(Positive)”, “부정적(Negative)” 이외에 평온한 상태로 존재하는 “중립적(Neutral)”의 3가지 상태로 분류하였다. 정확도를 개선하기 위해서 랜덤 포레스트(Random Forest) 알고리즘에 속성 선택적 분류기(Attribute Selected Classifier: ASC) 방식에 의해 선택된 속성을 적용하여 실험하였다. 정확도는 “각성(Arousal)” 부분에서Koelstra의 결과보다 “32.48%” 높은 결과가 도출되었고, Liu의 실험의 “정서가(Valence)”와 비교해보면 ASC(Random Forest) 결과가 “8.13%” 더높은 결과를 도출하였다. 정확도를 개선하기 위해 ASC 방식을 적용한 랜덤 포레스트 분류기 실험결과에서는 전체평균을 기준으로 기존 연구결과와 대비하여 “2.68%” 높은 정확도가 도출되었다.","In this study, experiments on the improvement of the emotion classification, analysis and accuracy of EEG data were proceeded, which applied DEAP (a Database for Emotion Analysis using Physiological signals) dataset. In the experiment, total 32 of EEG channel data measured from 32 of subjects were applied. In pre-processing step, 256Hz sampling tasks of the EEG data were conducted, each wave range of the frequency (Hz); Theta, Slow-alpha, Alpha, Beta and Gamma were then extracted by using Finite Impulse Response Filter. After the extracted data were classified through Time-frequency transform, the data were purified through Independent Component Analysis to delete artifacts. The purified data were converted into CSV file format in order to conduct experiments of Machine learning algorithm and Arousal-Valence plane was used in the criteria of the emotion classification. The emotions were categorized into three-sections; ‘Positive’, ‘Negative’ and ‘Neutral’ meaning the tranquil (neutral) emotional condition. Data of ‘Neutral’ condition were classified by using Cz(Central zero) channel configured as Reference channel. To enhance the accuracy ratio, the experiment was performed by applying the attributes selected by ASC(Attribute Selected Classifier). In “Arousal” sector, the accuracy of this study’s experiments was higher at “32.48%” than Koelstra’s results. And the result of ASC showed higher accuracy at “8.13%” compare to the Liu’s results in “Valence”. In the experiment of Random Forest Classifier adapting ASC to improve accuracy, the higher accuracy rate at “2.68%” was confirmed than Total mean as the criterion compare to the existing researches."
공조기 가스 사용량 시계열 데이터의 기계 학습적 분석,2019,"['Time series data', 'Elman neural network', 'Conditioning equipment', 'Gas energy consumption', 'Non-linear model']",,"In this paper, we propose a recurrent neural network in order to predict the time series of the gas energy consumption in a conditioning equipment. We, in particular, characterize the time series data by using various method and find that the data contain a non-linear correlation. Based on the finding that the time series of the gas consumption contained a considerable amount of the non-linear correlation, we adopt the Elman neural network as a non-linear model for the prediction of the gas consumption. By tuning the parameters in the model, we demonstrate that the proposed model predicted the gas consumption with the relative errors and the average errors less than 1% and 0.5 - 3.2, respectively. The results of this study can be used to the gas energy management system in terms of the effective control of the conditioning energy in the dry process."
의사결정나무 분석을 이용한 심혈관질환자의 재입원 위험 요인에 대한 융합적 분석,2019,"['의사결정나무', '심근경색증', '협심증', '재입원', '위험 요인', 'Decision Trees', 'Myocardial Infarction', 'Angina Pectoris', 'Patients Readmission', 'Risk Factors']","본 연구는 의사결정나무 통계분석법을 톨해 국민건강영양조사 자료를 2차 분석하여 심혈관질환자의 재입원 위험 요인을 확인하는 기초자료를 마련하고자 하였다. 연구대상자는 국민건강영양조사 4-6기 자료대상자 총 65,973명 중 협심증이나 심근경색 진단 병력이 있는 총 1,037명의 성인이며, SPSS window 21 Program을 이용하여 분류 분석 중 CHAID 의사결정나무 방법으로 분석하였다. 뿌리 마디(Root node)는 경제활동상태((χ²=12.063, p=.001), 자식 마디(Child node)는 개인 소득수준(χ²=6.575, p=.031), 최근 1년간 체중 변화(χ²=12.758, p=.001), 거주지역(χ²=4.025, p=.045), 직접흡연(χ²=3.884, p=.049), 교육수준(χ²=9.630, p=.024)으로 확인되었다. 끝마디(Terminal node)는 고혈압(χ²=3.854, p=.050), 당뇨(χ²=6.056, p=.014), 직업형태(χ²=7.799, p=.037)로 분석되었다. 이를 통해 심혈관질환자의 재입원 관리를 위해 다양한 요인의 통합적 접근을 고려한 프로그램의 개발 및 운영이 필요함을 제언한다.","This is descriptive study to 2nd analysis data KNHANES Ⅳ-Ⅵ about risk factors of readmission among patients with cardiovascular disease. Among the total 65,973 adults, 1,037 with angina or myocardial infarction were analyzed. The analysis was conducted using SPSS window 21 Program and CHAID decision tree was used in the classification analysis. Root nodes are economic activity(χ²=12.063, p=.001), children's nodes are personal income(χ²=6.575, p=.031), weight change(χ²=12.758, p=.001), residential area(χ²=4.025, p=.045), direct smoking(χ²=3.884, p=.031). p=.049), level of education(χ²=9.630, p=.024). Terminal nodes are hypertension(χ²=3.854, p=.050), diabetes mellitus(χ²=6.056, p=.014), occupation type(χ²=7.799, p=.037). We suggest that the development and operation of programs considering the integrated approach of various factors is necessary for the readmission management of cardiovascular patients."
멀티 뷰 기법 리뷰: 이해와 응용,2019,"['멀티 뷰 학습', '딥 러닝', '기계학습', '데이터 통합', 'multi-view learning', 'multi-modal learning', 'deep learning', 'machine learning', 'data integration']","멀티 뷰 기법은 데이터를 다양한 관점에서 보려는 접근 방법이며 데이터의 다양한 정보를 통합하여 사용하려는 시도이다. 최근 많은 연구가 진행되고 있는 멀티 뷰 기법에서는 단일 뷰 만을 이용하여 모형을 학습시켰을 때 보다 좋은 성과를 보인 경우가 많았다. 멀티 뷰 기법에서 딥 러닝 기법의 도입으로 이미지, 텍스트, 음성, 영상 등 다양한 분야에서 좋은 성과를 보였다. 본 연구에서는 멀티 뷰 기법이 인간 행동 인식, 의학, 정보 검색, 표정 인식 분야에서 직면한 여러 가지 문제들을 어떻게 해결하고 있는지 소개하였다. 또한 전통적인 멀티 뷰 기법들을 데이터 차원, 분류기 차원, 표현 간의 통합으로 분류하여 멀티 뷰 기법의 데이터 통합 원리를 리뷰 하였다. 마지막으로 딥 러닝 기법 중 가장 범용적으로 사용되고 있는 CNN, RNN, RBM, Autoencoder, GAN 등이 멀티 뷰 기법에 어떻게 응용되고 있는지를 살펴보았다. 이때 CNN, RNN 기반 학습 모형을 지도학습 기법으로, RBM, Autoencoder, GAN 기반 학습 모형을 비지도 학습 기법으로 분류하여 이 방법들이 대한 이해를 돕고자 하였다.","Multi-view learning considers data from various viewpoints as well as attempts to integrate various information from data. Multi-view learning has been studied recently and has showed superior performance to a model learned from only a single view. With the introduction of deep learning techniques to a multi-view learning approach, it has showed good results in various fields such as image, text, voice, and video. In this study, we introduce how multi-view learning methods solve various problems faced in human behavior recognition, medical areas, information retrieval and facial expression recognition. In addition, we review data integration principles of multi-view learning methods by classifying traditional multi-view learning methods into data integration, classifiers integration, and representation integration. Finally, we examine how CNN, RNN, RBM, Autoencoder, and GAN, which are commonly used among various deep learning methods, are applied to multi-view learning algorithms. We categorize CNN and RNN-based learning methods as supervised learning, and RBM, Autoencoder, and GAN-based learning methods as unsupervised learning."
초보학습자의 AI 학습을 위한 블록 코딩 기반의 프로그래밍 학습방법,2019,"['Machine learning', 'Perceptron', 'SW education', 'Computational thinking', 'Algorithm', 'ENTRY programming', 'Python programming']","최근 기계학습의 관심이 커지며 학습의 필요성을 느끼고 있으나, 기계학습 개념 이해의 어려움과 초보학습자로써 프로그래밍 학습의어려움을 겪고 있다. 이에, 본 논문에서는 선행학습으로 블록을 조합하여 프로그래밍을 할 수 있는 블록형 코딩과 기계학습의 퍼셉트이론을 스크래치로 경험함으로써 인공지능을 학습하는 소프트웨어 교육모델을 제안한다. 제안 교육모델에서는 함수의 다양한 사용및 CT요소 및 알고리즘을 적용하여 프로그래밍을f구현 학습한다. 이는 text코딩을 바로 적용하는 초기학습자보다 진입장벽을 낮추고, 성공여부에 대한 기대감과 지속적으로 노력할 가치를 부여함으로써 학습동기를 높일 수 있다.","Recently, interest in machine learning has grown and I feel the necessity of learning, but I have difficulty understanding machine learning concept and difficulty in programming learning as a beginner. Thus, this paper proposes a software training model for learning artificial intelligence by experiencing block-type coding and machine learning's percept theory as scratch, which can combine blocks with prior learning. In the proposed training model, programming is implemented and learned by applying various use of functions and CT elements and algorithms. This can lower the entry barrier than the initial learners who apply text coding right away, and increase the motivation for learning by giving them expectations of success and value to make continuous efforts."
L2 작문 수정에 미친 기계번역의 효과성에 대한 한국 대학생 학습자의 인식,2019,"['machine translation', 'college students’ perception', 'effectiveness', 'L2 revision']",,"Recently, an increasing number of students are using machine translation in academic settings as well as in their daily lives. They use it for diverse purposes, such as vocabulary learning, L2 writing, reading, and speaking. Accordingly, a significant number of studies have been conducted regarding machine translation in foreign language education; however, studies conducted in the Korean context are rarely found in the field. Therefore, the current study investigates Korean college students’ perceptions toward the effectiveness of machine translation on L2 writing and revision. The study analyzed 169 college students’ responses to a survey, including three open-ended questions. The result showed that the students perceived the use of machine translation to help them with L2 revision in terms of vocabulary, grammar and error corrections. The students expressed the belief that their revisions significantly improved after using machine translation. They also reported about the strengths and weaknesses of using machine translation while revising. The study further discovered that the students’ perceived writing proficiency levels and confidence affected their perceptions toward using machine translation to make error corrections. Based on the results, several suggestions are made for future studies with respect to using machine translation for language learning."
딥러닝 개념을 위한 인공지능 교육 프로그램,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'CNN', 'SW education', '인공지능', '기계학습', '딥러닝 교육', '컨볼루션네트워크', '소프트웨어교육']","본 연구의 목적은 초등학생을 대상으로 한 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 먼저 문헌연구와 선행연구를 토대로 전문가 그룹 토의를 진행하여 프로그램 개발 방향을 위한 준거를 세웠다. 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가들의 타당도와 학습자 만족도 설문 검사를 통해 분석하였다. 전문가 타당도 분석 결과 최소 CVR값이 .56이상을 넘어 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 낯선 소재로 인해 교사들이 어려워하기는 하지만 기존 SW 교육에서 실시했던 언플러그드 CS 활용의 접근법을 통해 수업의 적용이 가능함을 보여주고 있음을 알 수 있었다. 학생들의 만족도 분석 결과 학습자들의 참여는 적극적으로 하였음을 알 수 있었고, 인공지능 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하였다. 이에 본 프로그램은 초등학교 현장에서의 인공지능 교수학습자료의 토대를 제공할 수 있음을 알 수 있다.","The purpose of this study is to develop an educational program for learning deep learning concepts for elementary school students. First of all, based on literature and previous research, a group of experts was discussed to establish the criteria for the direction of program development. The model of education program was developed the deep-learning teaching method based on CT element-oriented teaching and learning model. The subject of the developed program is the artificial intelligence image recognition CNN algorithm, and we have developed 9 educational programs.  We applied the program over six weeks to sixth graders. he test of learning suitability for the education program was analyzed through the validity of the experts and the survey on the satisfaction of learners. Expert validity analysis showed that the minimum CVR value was more than .56. The fitness level of learner level and the level of teacher guidance were less than .80, and the fitness of learning environment and media above .96 was high. Although it is difficult for teachers due to the unfamiliar material of artificial intelligence, it can be seen that the class can be applied through the approach of using the unplugged CS that was implemented in the existing SW education. The students' satisfaction analysis showed that the learners actively participated in the class. Students gave a positive evaluation of the average of 4.0 or higher on the understanding, benefit, interest, and learning materials of artificial intelligence learning. Therefore, it can be seen that the educational program developed in this study can provide a foundation for artificial intelligence teaching and learning materials in elementary school."
GAN과 DNN을 활용한 딥러닝 기반의 지능형 개인신용 평가모형,2019,"['FinTech', 'Deep Learning', 'Imbalance Data', 'GAN', 'DNN']",,"data using machine learning techniques such as decision trees, neural networks, deep learning, and GAN. We develop a personal credit rating model to resolve an issue from imbalanced data for machine learning by utilized the SMOTE and GAN. Personal credit rating is an important system for personal loans such as FinTech, and has been applied with many deep learning techniques. Therefore, the purpose of this study is to develop an intelligent personal credit rating model based on deep learning that can be effectively used in a small data set. Therefore, in this study, 5 samples of 10,000 data sets are sampled and the size of the data set is increased by utilizing the SMOTE and GAN, which is an over sampling technique. We applied classification techniques such as logit, decision tree, ANN, and DNN. Then, to solve the imbalanced data problems, we applied under sampling, SMOTE, and GAN, and compared which the performance of statistical techniques, machine learning, and deep learning. As a result, deep learning based on personal credit rating model of SMOTE + DNN showed the highest performance with 66.2%."
한국어 학습자의 온라인 기계번역 도구 사용 경험 및 태도에 관한 연구 - 초급 및 중급 학습자를 대상으로 -,2019,"['한국어 학습자', '기계번역 도구', '설문조사', '구글 번역', '네이버 파파고', 'Korean learners', 'Machine translation tools', 'Survey', 'Google translation', 'Naver Papago']",,"The purpose of this study is to examine the experience and attitude of Korean learners about using online machine translation tools. To accomplish this goal, 99 Korean learners of elementary and intermediate level were surveyed and their results were analyzed by each item. As a result, most Korean learners have experienced using machine translation tools in Korean language learning, and have found that a large part of Korean language learning relies on the use of machine translation tools. However, it was still recognized that the use of machine translation tools was an auxiliary means of Korean language learning. For some items, there was a difference in response outcome by proficiency. There was a significant difference between the types of machine translation tools used, the purpose of using machine translation tools, and the degree of dependence on machine translation tools. The results of this study showed that Korean learners have some experience and awareness about online machine translation tool. Also, we could see how these experiences and attitude differ according to learners’ level. This study has significance in that it is the first attempt as a specific research study on this field."
무선 애드혹 네트워크에서 노드분리 경로문제를 위한 강화학습,2019,['Q-'],,"This paper proposes reinforcement learning to solve the node-disjoint path problem which establishes multipath for reliable data transmission in wireless ad-hoc networks. The node-disjoint path problem is a problem of determining a plurality of paths so that the intermediate nodes do not overlap between the source and the destination. In this paper, we propose an optimization method considering transmission distance in a large-scale wireless ad-hoc network using Q-learning in reinforcement learning, one of machine learning. Especially, in order to solve the node-disjoint path problem in a large-scale wireless ad-hoc network, a large amount of computation is required, but the proposed reinforcement learning efficiently obtains appropriate results by learning the path. The performance of the proposed reinforcement learning is evaluated from the viewpoint of transmission distance to establish two node-disjoint paths. From the evaluation results, it showed better performance in the transmission distance compared with the conventional simulated annealing."
앙상블 학습과 온도 변수를 이용한 A 호텔의 전력소모량 예측,2019,"['ensemble learning', 'temperature', 'bagging', 'random forest', 'time series forecast', '앙상블 학습', '온도', '배깅', '랜덤 포레스트', '시계열 자료 예측']",과거의 전력소모량을 분석하여 미래의 전력소모량을 예측하는 것은 에너지 계획과 정책 결정에 있어 많은 이점을 가져다준다. 기계학습은 최근 전력소모량을 예측하는 분석 방법으로 많이 사용하고 있다. 그중 앙상블 학습은 모형의 과적합 현상을 방지하고 분산을 줄여 예측의 정확성을 높이는 방법으로 알려져 있다. 하지만 일별 데이터에 앙상블 학습을 적용했을 때 분석 방법의 특성으로 인해 피크를 잘 나타내지 못하고 중심값으로 예측하는 단점을 보였다. 본 연구에서는 앙상블 학습 전에 온도 변수와의 상관성을 고려하여 선형모형으로 적합함으로써 앙상블 학습의 단점을 보완한다. 그리고 9개의 모형을 비교한 결과 온도 변수를 선형모형으로 적합하고 랜덤포레스트를 사용한 모형이 결과가 가장 좋음을 보여준다.,"Forecasting the electricity consumption through analyzing the past electricity consumption a advantageous for energy planing and policy. Machine learning is widely used as a method to predict electricity consumption. Among them, ensemble learning is a method to avoid the overfitting of models and reduce variance to improve prediction accuracy. However, ensemble learning applied to daily data shows the disadvantages of predicting a center value without showing a peak due to the characteristics of ensemble learning. In this study, we overcome the shortcomings of ensemble learning by considering the temperature trend. We compare nine models and propose a model using random forest with the linear trend of temperature."
LQR 제어기와 PILCO 강화학습 융합 연구,2019,"['Reinforcement learning control system', 'Model-based learning', 'LQR (Linear Quadratic Regulator) control', 'UAV (Unmanned Aerial Vehicle)']",,"Reinforcement learning (RL) is a machine learning technique that autonomously learns a control policy for performing a desired mission. Probabilistic inference for learning control (PILCO) is known as one of the rapid RL methods because of its capability to build a data-efficient structure based on a Bayesian inference with a Gaussian process from which it guarantees an optimal solution without repetitive computations. However, PILCO still suffers from a number of training iterations when it is applied to an autonomous UAV control system. To boost the learning convergence rate, in this paper, we suggest a combination of linear quadratic regulator (LQR) control and PILCO reinforcement learning. The simulation study to learn a velocity command for quadrotor trajectory tracking in a reinforcement learning framework demonstrated that the proposed algorithm had a more rapid convergence rate and better tracking performance than the original PILCO algorithm."
납기와 작업준비비용을 고려한 병렬기계에서 딥러닝 기반의 일정계획 생성 모델,2019,"['Scheduling', 'Deep Neural Network', 'Due Date', 'Setup Cost', 'Machine Learning', '일정계획', '심층신경망', '납기', '작업준비용', '머신러닝']","4차 산업혁명이 진행되면서 제조업에서 사물인터넷(IoT), 머신러닝과 같은 지능정보기술을 적용하는 사례가 증가하고 있다. 반도체/LCD/타이어 제조공정에서는 납기일(due date)을 준수하면서 작업물 종류 변경(Job change)으로 인한 작업 준비 비용(Setup Cost)을 최소화 하는 일정계획을 수립하는 것이 효과적인 제품 생산을 위해 매우 중요하다. 따라서 본 연구에서는 병렬기계에서 딥러닝 기반의 납기 지연과 작업 준비 비용 최소화를 달성하는 일정계획 생성 모델을 제안한다. 제안한 모델은 과거의 많은 데이터를 이용하여 고려되어지는 주문에 대해 작업 준비와 납기 지연을 최소화하는 패턴을 학습한다. 따라서 세 가지 주문 리스트의 난이도에 따른 실험 결과, 본 연구에서 제안한 기법이 기존의 우선순위 규칙보다 성능이 우수하다는 것을 확인하였다.","As the 4th industrial revolution progressing, manufacturers are trying to apply intelligent information technologies such as IoT(internet of things) and machine learning. In the semiconductor/LCD/tire manufacturing process, schedule plan that minimizes setup change and due date violation is very important in order to ensure efficient production. Therefore,in this paper, we suggest the deep learning based scheduling generation model minimizes setup change and due date violation in parallel machines. The proposed model learns patternsof minimizing setup change and due date violation depending on considered order using the amount of historical data. Therefore, the experiment results using three dataset dependingon levels of the order list, the proposed model outperforms compared to priority rules."
인컴번트 사용자 채널 점유확률 변화에 따른 SVM 기반의 무선 트래픽 이용환경 추론기법,2019,"['Machine Learning', 'Support Vector Machine', 'Cognitive Radio Engine', 'Case-based Reasoning']",,"In this paper, we propose a case-based reasoning Cognitive Radio(CR) engine that uses limited resources efficiently in military tactical wireless communication environments. A CR engine should be able to learn and infer, and thus predict the available channel information of a secondary user based on information about traffic usage. To be able to do so, a low probability of channel collision should be associated with the engine. The engine should, thereby, be able to indicate the probability of channel occupancy of an incumbent user who requires interference protection. We used a Support Vector Machine(SVM) to measure the histogram-type wireless traffic usage environment in accordance with the change in the probably of channel occupancy of the incumbent user. SVM is a sorting algorithm of machine learning. Next, we calculated the histogram's skewness and kurtosis for traffic modeling. Finally, to analyze the performance of the SVM-based wireless traffic usage environment, we compared the inference accuracy and time complexity of the proposed SVM with those of k-Nearest Neighbors(k-NN)."
학습분석 기반 대학 신입생 대상 학습부진 위험학생 조기예측 모델 개발 및 군집별 특성 분석,2019,"['learning analytics', 'underachivement', 'predictictive modeling', 'freshmen', 'machine learning', '학습분석', '학습부진', '예측 모형', '신입생', '기계학습']","대학 첫 학기의 성적이 향후 학업성취와 지속에 영향을 미치며, 특히, 학령인구의 지속적 감소와 신입생들의 학업역량 약화를 고려할 때 신입생 대상의 학습 성과 예측을 통한 선제적 대응은 매우 중요하다. 이에 본 연구는 학습분석을 기반으로 2016년~2018학년도까지 A대학의 3개년 동안의 신입생 4,662명의 데이터를 수집·분석하여 학습부진 가능성이 있는 학생을 조기에 예측할 수 있는 예측모형을 개발하고, 위험 학생으로 예측된 학생들의 특성을 분석하여 중재 프로그램 설계를 위한 시사점을 도출하고자 하였다. 기계학습분석기법인 XGBoost를 활용한 최적모형 예측 결과 예측 모형의 재현도는 62.3%, 정밀도는 29.56%, F점수는 0.4, ROC곡선의 AUC는 0.733 으로 데이터가 제한적인 신입생 대상임을 고려할 때 의미 있는 모형이라고 할 수 있다. 예측을 위한 주요 변수로는 노력조절, 학생부사회/과학등급평균, 수능언어백분위, 수능수리백분위, 입시 서류전형 점수, 성별, 학교를 그만둘 의향, 지난해 한주동안 게임시간, 수능탐구백분위, 학생부등급평균 등인 것으로 나타났다. 또한, K-means 군집 분석을 통해 학습부진 학생들을 특징에 따라 6개 그룹으로 군집화하였으며, 군집을 구분하는 주요 변수들은 ‘학교만족도’와 ‘자기조절학습’과 관련된 변수들이었다. 이러한 연구결과를 바탕으로 예측 결과를 활용한 중재활동 시 고려사항과, 예측 정확도 및 중재 효과성 향상을 위한 고려 사항을 교육현장에서의 실천과 후속연구를 위하여 제언하였다.","It is highly important to make proactive interventions for students at-risk through early prediction by considering how the first semester GPA would effect the student’s overall academic success to higher education. In this research, we have collected, analyzed a data set of 4,662 freshmen students in “A” university from 2016 to 2018, and developed a machine learning prediction model to find students who are more likely to get bad grades at the end of first semester. Finally, we also drew implications to design intervention programs by analyzing characteristics of at-risk students. The performance of the prediction model using XGboost had a recall (62.3%), precision (29.56%), F-score (0.4), and AUC (0.733). This performance of the model can be acceptable in a situation where data on freshmen is insufficient. The most important predictor variables in this model were self-regulatory capabilities, the high-school GPA in social sciences, Korean language & mathematics scores in College Scholastic Ability Test, etc. Students at risk are clustered into six groups by K-means clustering analysis according to their level of satisfaction in college and self-regulated learning. From the research results, we suggested what should be considered to take intervention for practice in higher education and how to collect and analyze data to improve model performance for future work in this area of research."
압연기의 편심 원인 자동진단을 위한 신경망 설계,2019,"['Rolling Machine', 'Eccentricity', 'Neural Network', 'Productive Maintenance']",,"This paper presents a design of neural network for automatically diagnosing eccentric cause in rolling machine. An applicable structure of neural network for diagnosing eccentric cause is designed. A generating method of input and output data relating each type of eccentricity is proposed for learning neural network. The suggested neural network worked within the specified error range through learning input and output data for learning. According to computer simulation, the suggested neural network outputs stably desired eccentricity diagnosis results for input data."
인공신경망을 이용한 DWT 전력스펙트럼 밀도 기반 자동화 기계 고장 진단 기법,2019,"['인공신경망', '이산 웨이브릿 변환', '기계 고장진단', '심층학습', '패턴 인식', 'Artificial Neural Network', 'Discrete Wavelet Transform', 'Machine Fault Diagnosis', 'Machine Learning', 'Pattern Recognition']",,"Sounds based machine fault diagnosis recovers all the studies that aim to detect automatically abnormal sound on machines using the acoustic emission by these machines. Conventional methods that use mathematical models have been found inaccurate because of the complexity of the industry machinery systems and the obvious existence of nonlinear factors such as noises. Therefore, any fault diagnosis issue can be treated as a pattern recognition problem. We propose here an automatic fault diagnosis method of hand drills using discrete wavelet transform(DWT) and pattern recognition techniques such as artificial neural networks(ANN). We first conduct a filtering analysis based on DWT. The power spectral density(PSD) is performed on the wavelet subband except for the highest and lowest low frequency subband. The PSD of the wavelet coefficients are extracted as our features for classifier based on ANN the pattern recognition part. The results show that the proposed method can be effectively used not only to detect defects but also to various automatic diagnosis system based on sound"
딥러닝 알고리즘 개발과정을 통해 본 영상의학분야에서 딥러닝의 최신 경향,2019,"['Artificial Intelligence', 'Deep Learning', 'Algorithms']","최근 인공지능은 지각정보를 해석하는데 있어 상당한 진보를 이루었으며, 이를 통해 기계는매우 복잡한 데이터를 보다 잘 해석할 수 있게 되었다. 최근 몇 년간 딥러닝 기술로 대표되는인공지능의 의료 및 생물의학 연구분야로의 적용이 기하급수적으로 증가하고 있다. 이번 기고문에서는 의료영상분야의 딥러닝 알고리즘 개발 단계를 주제선정, 데이터 수집, 데이터 탐색 및 정제, 알고리즘 개발, 알고리즘 평가 그리고 임상적용의 단계로 나누어 설명하고, 각각의 단계에서 최신의 동향을 소개하고자 한다","Recently, considerable progress has been made in interpreting perceptual information through artificial intelligence, allowing better interpretation of highly complex data by machines. Furthermore, the applications of artificial intelligence, represented by deep learning technology, to the fields of medical and biomedical research are increasing exponentially. In this article, we will explain the stages of deep learning algorithm development in the field of medical imaging, namely topic selection, data collection, data exploration and refinement, algorithm development, algorithm evaluation, and clinical application; we will also discuss the latest trends for each stage."
폴립 가중치 영상 생성을 통한 캡슐내시경 영상의학습 성능 비교 연구,2019,"['기계학습', '진단 보조', '의료 영상', '캡슐내시경', 'Machine Learning', 'Diagnostic Assistant', 'Medical Lmages', 'Capsule Endoscopy']",,"A capsule endoscopy is a medical device that can capture an entire digestive organ from the esophagus to the anus at one time. It produces a vast amount of images consisted of about 8∼12 hours in length and more than 50,000 frames on a single examination. However, since the analysis of endoscopic images is performed manually by a medical imaging specialist, the automation requirements of the analysis are increasing to assist diagnosis of the disease in the image. Among them, this study focused on automatic detection of polyp images. A polyp is a protruding lesion that can be found in the gastrointestinal tract. In this paper, we propose a weighted-image generation method to enhance the polyp image learning by multi-scale analysis. It is a way to extract the suspicious region of the polyp through the multi-scale analysis and combine it with the original image to generate a weighted image, that can enhance the polyp image learning. We experimented with SVM and RF which is one of the machine learning methods for 452 pieces of collected data. The F1-score of detecting the polyp with only original images was 89.3%, but when combined with the weighted images generated by the proposed method, the F1-score was improved to about 93.1%."
딥러닝 기반 자연어 처리에서 도메인 지식의 역할,2019,"['domain knowledge', 'natural language processing', 'tagging', 'segmentation', 'deep learning', '도메인 지식', '자연어처리', '형태소분석', '분절', '딥러닝']",,"In Symbolic AI, the domain knowledge was considered indispensable. In rule-based NLP, likewise, the linguistic knowledge played an important role. As probabilistic NLP and machine learning techniques develop, the role of domain knowledge shrank. As deep learning appears, even the role of feature engineering and domain knowledge has become almost zero.In order to prove the importance of domain knowledge even in this deep learning age, I built a parts-of-speech tagger of Korean. This task in Korean is challenging, due to morphophonological alternations, deletions and contractions. I reformulated this task of segmentation as that of classification. For this purpose, I examined a large corpus, and found empirically 200 types of mapping between an input syllable and an output string. Based on these categories, I built and trained an LSTM-based neural network. With this model of segmentation, the parts-of-speech tagging model is easily trained by the familiar sequence tagging algorithm. By combining these two models and a few dictionaries, I got 98.0% of the F1 score."
"생명과 기계를 구분하는 세 가지 방식: 개념, 은유, 작동",2019,"['칸트', '라이프니츠', '데리다', '들뢰즈', '마투라나', '비비시스템', 'Kant', 'Leibniz', 'Derrida', 'Deleuze', 'Maturana', 'vivi-system']","오늘날 생명과 기계는 수렴하고 있다. 이 혼합을 이해하고 대응하기 위해서는 생명과 기계를 구분하는 세 가지 방식을 식별해야 할 것으로 보인다. 그것은 개념, 은유, 작동을 중심으로 양자를 구분하는 상이한 체제를 의미한다. 첫째, 개념을 중심으로 볼 때, 칸트와 라이프니츠 사이의 대조가 오늘날 중요한 의미를 지닌다. 칸트는 생명체의 신체 구조는 이해의 대상이지만, 그 목적성과 통일성은 인간의 이해 범위 바깥에서 존중의 대상이라는 점을 주장했다. 반면, 라이프니츠는 기계와 유기체는 모두 기술적 대상이지만, 다만 전자는 인간의 유한한 기계인 반면, 후자는 신의 무한한 기계라는 점이 다를 뿐이라고 말했다. 이 생각이 보다 현대적인 사유에 가깝다고 할 수 있다. 둘째, 은유를 중심으로 볼 때, 생명과 기계는 같은 존재자에 대해 관찰하고 서술하는 상이한 관점이다. 어떤 행동이 외적 동기를 갖는다고 말하는 인과적 서사란 사후적으로 덧붙여진 이야기와 같다. 우리는 생명이 무엇인지 알지 못하며, 생명의 본성은 수없이 많은 이야기들 후에나 밝혀지게 될 것이다. 셋째, 오늘날 새롭게 이해하는 생명은 개체 단위가 아니라 분산적이고 병렬적이고 복합적인 전지구적 시스템이다. 그리고 인류는 피드백 제어 시스템, 딥러닝, 바텀-업 로봇 제작 방식을 통해 기계의 진화 자체를 유도할 수 있게 되었다. 라이프니츠가 말한 인간적 기계는 신적 기계에 점점 더 접근하고 있는 듯 보인다. 이렇듯 개념적 구분, 은유적 서사, 공학적 작동의 세 가지 체제를 구별하여 논의하는 것이 앞으로 불필요한 혼란을 막고 생산적이고 실천적인 대안을 만드는 데 요구된다.","Life and machine converge today. Il seems that three ways should be recognized to distinguish them in order to understand and react to this crossover or alliance. These are three different regimes of thinking around concept, metaphor and operation. In the first place, with regard to the concept, a confrontation of Kantian and Leibnizian thoughts will take on precious value for our contemporary thought. According to Kant, the structure of the living body is an object of understanding, while its purpose and unity is a matter of respect beyond the reach of human intelligence. On the other hand, Leibniz affirms that the mechanism and the organism are both a technical object, but that their difference consists precisely in this: the first is a finite machine which is manufactured by the human, while the last is an infinite machine by God. We can say that this idea is closer to our contemporary thought. In the second place, if we say around the metaphor, life and machine are two different perspectives according to which we observe and describe the same beings. The causal narrative which tells that a certain action comes from an external motive is actually like a story which is added after the fact. We do not know what life is, so that its nature will have been clarified only after countless stories. Third, life as understood today cannot be measured at the individual level, but it is a global terrestrial network or system that is distributive, parallel and complex. In addition, feedback control systems, deep learning, bottom-up robots encourage us to even evolve machines. The human machines that Leibniz spoke of seem to be getting closer and closer to the divine machines. We will thus have to discriminate and discuss these three regimes, that is to say the conceptual distinction, the metaphorical narration and the technological operation, to bring down redundant and unnecessary confusions, and to create productive and practical alternatives."
점진적 스마트 팩토리 환경 구축을 위한 CNC 절단 장비 기반 원격 제어 시스템 개발,2019,"['원고', '스마트 팩토리', 'CNC 절단 장비', '원격 제어', '모니터링', '자동화 공정', 'Manuscript', 'Smart Factory', 'CNC Cutting Machine', 'Remote Control', 'Monitoring', 'Automation Process']","통신, 센서, 인공지능 등의 기술 발전으로 인해 스마트 팩토리 구축이 진행되고 있다. 스마트 팩토리는 기존의 자동화 공정에서 생산되는 데이터를 대상으로 기계 학습과 같은 지능화 기술을 활용해 효율적인 공정 제어를 목표로 한다. 스마트 팩토리로의 구축으로 인해 생산성이 높아지지만 비용도 높아진다. 따라서 소규모 업체들은 스마트 팩토리로 단계별 전환이 효율적이다. CNC 절단기 기반의 소규모 스마트 팩토리 구축을 위해서 본 논문에서는 기존 제조 장비의 데이터를 수집, 모니터링 및 제어할 수 있는 원격 제어 시스템을 제안한다. 원격 제어 시스템의 구조 및 설계와 효율적인 센싱 데이터 전송 방법 등을 제시하였다. 실현 가능성을 검증하기 위해 CNC 절단 장비를 대상으로 시스템을 구현하였고 기능을 검증하였다. 성능 평가를 위해 모니터링 웹 페이지 접속시간을 측정하였고, 구현된 시스템이 사용 가능한 수준이라는 것을 확인하였다.","The technological advances such as communication, sensor, and artificial intelligence lead smart factory construction. Smart factory aims at efficient process control by utilizing data from the existing automation process and intelligence technology such as machine learning. As a result of constructing smart factory, productivity increases, but costs increase. Therefore, small companies try to make a step-by-step transition from existing process to smart factory. In this paper, we have proposed a remote control system that support data collection, monitoring, and control for manufacturing equipment to support the construction of CNC cutting machine based small-scale smart factory. We have proposed the structure and design of the proposed system and efficient sensing data transmission scheme. To check the feasibility, the system was implemented for CNC cutting machine and functionality verification was performed. For performance evaluation, the web page access time was measured. The results means that the implemented system is available level."
딥러닝 신경망을 이용한 신용카드 부도위험 예측의 효용성 분석,2019,"['딥러닝', '인공신경망', '신용카드', '부도위험', '머신러닝', 'Deep Learning', 'Artificial Neural Network', 'Credit Card', 'Default Risk', 'Machine Learning']","본 연구는 국내․외 금융시장에서 아직 활성화되지 못한 딥러닝 신경망(deep learning neural network) 알고리즘을 이용해 신용카드 부도위험 예측의 정확도 향상 가능성에 대해서 점검한다. 이를 위해 기존 머신러닝 알고리즘(Logistic, SVM, Random Forest, Lasso 등)을 딥러닝 신경망 분석의 성능 점검을 위한 비교 지표로 활용한다. 우선, 딥러닝 신경망은 두 개의 은닉층(hidden layers)과 다섯 개의 뉴런(neuron)으로 구축하고, 활성함수(activation function)와 초기값(initial value) 설정방법에 따른 예측정확도를 도출한다. 그 결과 딥러닝 신경망 분석이 기존 머신러닝 알고리즘 보다 최소 0.6%p에서 최대 6.6%p 성능이 향상된 것으로 나타났다. 이 중 가장 높은 예측 정확도를 보인 활성함수와 초기값 설정방식은 ReLU(rectified linear units)와 Xavier(2010)이고 이를 기준으로 은닉층과 뉴런의 수를 각각 최대 10개와 25개까지 늘려 분석한 결과에서도 유사한 결과가 나타났다. 다만, 기존 연구에서와 같이 은닉층과 뉴런의 수의 증가에 따른 뚜렷한 성능의 향상은 나타나지 않았다. 또한, 이미지 식별 분야에서 높은 성능을 보였던 Dropout과 CNN(convolution neural network) 모델도 예측 정확도에서 큰 차이를 보이지 않았다. 이는 여기에서 사용된 신용카드 데이터가 다수 픽셀(pixel)로 이루어진 이미지 데이터와 비교해 양적․질적 한계가 있기 때문으로 판단된다. 한편, 본 연구에서 사용된 개인의 신용카드 부도 데이터는 횡단면 자료이기 때문에 시계열 데이터에서 높은 성능을 나타내는 RNN(recurrent neural network) 및 LSTM(Long- Short Term Memory) 등의 딥러닝 신경망 알고리즘을 사용하지는 않았다. 따라서 추후 시계열 자료가 포함된 빅데이터를 통해 이들 딥러닝 신경망 방법론을 적용한다면, 현재의 다양한 금융시장의 식별문제(신용등급, 연체율, 금리산정)에 있어 보다 향상된 결과를 도출할 수 있을 것으로 기대된다.","This study aims to discuss the usefulness of the deep learning neural network and the possibility of the deep learning neural network analysis in judging credit information by using credit card default data. Deep learning neural network analysis in the financial sector excluding the current stock price prediction model is under limited research. It is mainly used for upgrading models of the credit rating (Kvamme et al., 2016, 2018; Tran, 2016; Luo, 2017) and the delinquency rate (Sirignano et al., 2018).In the credit card market, it is focused on credit card issuance and fraud detection model (Ramanathan, 2014, Niimi, 2015). As mentioned earlier, there has not been much analysis of deep learning neural network using financial market data. This is because the study of deep learning neural networks is actively carried out mainly in the field of computer science such as image, speech recognition, natural language processing. Additionally, Researchers in the financial sector have difficulty learning deep learning algorithms and setting up a computer runtime environment. It is also difficult to apply the algorithm to financial data due to lower dimension than the image. Nowadays, financial companies have been interested in machine learning and are increasing their recruitment, but it is still in the stage of verifying the possibility of deep learning neural network.Therefore, This study examines the possibility of improving the accuracy of credit card default risk prediction by using a deep learning neural network algorithm. To do this, we use existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.) as a comparison index for performance check of deep learning neural network analysis. Firstly, the deep learning neural network is constructed with two hidden layers and five neurons, and derives the prediction accuracy according to the activation function and the initial value setting method. There are Sigmoid, ReLU, tanh and Maxout as active functions, and random value, Xavier, RBM, He’s as initialization methods. Based on this, we compare the accuracy of existing machine learning algorithms. As a result, the deep learning neural network analysis showed performance improvement between 0.6% and 6.6%p compared to the existing machine learning algorithms (Logistic, SVM, Random Forest, Lasso, etc.). Among these results, the active function and the initial value setting method with the highest prediction accuracy are ReLU (rectified linear units) and Xavier initialization. However, there is no significant improvement in performance with increasing number of hidden layers and neurons up to 10 and 25, respectively. Also, the dropout and CNN (convolution neural network) models, which showed high performance in the field of image identification, showed no significant difference in prediction accuracy.Nevertheless, it could be interpreted that the increase of hidden layers can improve the accuracy of estimation because the highest accuracy (0.8161) and the AUC (0.7726) are observed for 10 hidden nodes and 15 neurons.However, we can’t say that accuracy increases linearly by the number of hidden layers and neurons. These limitation could be due to the quantitative and qualitative limitations of the credit card data used here. We did not use recurrent neural network (RNN) and long-short term memory (LSTM) models since the personal default data for credit card used in this study is cross-sectional data. These method are for Time-Series data. Therefore, it is expected that it will be able to obtain better results in identification problems (credit rating, delinquency rate, interest rate calculation) of present various financial markets if these deep learning neural network methodologies are applied through big data including time series data.This study can be turned into a question of how deep learning analysis can lower the default risk and delinquency rate by using financial data from a practical point of ..."
언어학과 기계 번역-한문학 텍스트의 기계 번역과 관련하여,2019,"['Artificial Intelligence', 'Translation of Korean Literature Text in Classical Chinese', 'Rule Based Machine Translation', 'Neural Machine Translation', 'Translation Memory', '인공 지능', '한문학 번역', '규칙 기반 기계 번역', '신경망 기계 번역', '번역 메모리']","본 연구는 언어학과 관련하여 기계 번역의 역사를 살펴보고, 규칙 기반 기계 번역과 자료 기반 기계 번역의 알고리듬을 간략히 소개한다. 또한 이를 통해 한문학 텍스트의 기계 번역에 대한 제안과 전망을 하는 것이 본 연구의 목적이다. 기계 번역은 컴퓨터를 이용하여 하나의 언어를 다른 언어로 자동으로 변환하는 기술인데, 최근 인공 지능(AI)과 전산언어학 분야에서 활발히 연구되고 있다. 기계 번역은 Weaver(1949)에서 출발하였으며, 1980년대 초까지 언어학의 영향으로 어휘, 문법, 의미 생성에 필요한 많은 규칙을 적용한 시스템인 규칙 기반 기계 번역이 발전하였다. 1980년대 이후에는 컴퓨터의 발달과 대규모 코퍼스(corpus)의 구축이 가능해지면서 코퍼스를 기계 번역에 이용하려는 시도들이 나타났는데, 코퍼스를 기반으로 하는 자료 기반 기계 번역이 발전하였다. 최근에는 딥러닝(deep learning)을 통한 기계 번역의 인기가 매우 높아지고 있다. 그 중 주목받고 있는 기술은 ‘신경망 기계 번역(Neural Machine Translation)’이다. 그런데 한문학 텍스트는 어휘와 문법에 대한 정확한 정의와 분류가 합의된 상황도 아닐 뿐만 아니라 이를 규칙화한 시스템도 구축하지 못한 상황이기 때문에 규칙 기반 기계 번역을 활용하기 어렵다. 한편 충분한 병렬 코퍼스도 부족하기 때문에 통계적 기계 번역이나 신경망 기계 번역을 활용하기도 어렵다. 따라서 현재 한문학 텍스트의 기계 번역에서 가장 합리적인 방법은 번역 메모리를 활용하는 방법이다. 이를 통해 현재 한문학 텍스트의 번역에 대한 시간과 비용을 최소화 할 수 있고, 향후 신경망 기계 번역에서 필요로 하는 대용량의 병렬 코퍼스를 생성해 낼 수 있을 것이다.","This study examines the history of machine translation in relation to linguistics and briefly introduces algorithms for rule based machine translation and data based machine translation. And the purpose of this study is to propose and prospect a machine translation of Korean texts in classical Chinese. Machine translation is a technology that automatically transforms a language into another language. Recently, it has been actively researched in artificial intelligence(AI) and computational linguistics. Machine translation started with Weaver(1949), and until the early 1980’s, rule based machine translation developed which is a system that applied many rules for vocabulary, grammar, and meaning. Since the 1980’s, the attempts using corpus for machine translation come up with computer development and large corpus construction, then data base machine translation has developed. In recent years, the machine translations with AI has become very popular. One of them is ‘Neural Machine Translation’. However, it is difficult to use rule based machine translation because it is not the agreed-on situation about vocabulary and grammar on Korean literature text in classical Chinese. Also, since there are not enough parallel corpora, it is difficult to use statistical machine translation or neural machine translation. Therefore, the most reasonable method of machine translation on Korean literature text in classical Chinese is to use ‘translation memory’. It is possible to minimize the time and cost for translating the current Korean literature text in classical Chinese, and to generate a large amount of parallel corpus which is required in neural network machine translation in the future."
필기숫자 데이터에 대한 텐서플로우와 사이킷런의 인공지능 지도학습 방식의 성능비교 분석,2019,"['AI', 'Machine Learning', 'Supervised Learning', 'Tensorflow', 'Performance Evaluation', '인공 지능', '기계 학습', '지도 학습', '텐서플로', '성능 평가']","최근에는 인공지능의 도래로 인하여 수많은 산업과 일반적인 응용에 적용됨으로써 우리의 생활에 큰 영향을 발휘하고 있다. 이러한 분야에 다양한 기계학습의 방식들이 제공되고 있다. 기계학습의 한 종류인 지도학습은 학습의 과정 중에 특징값과 목표값을 입력으로 가진다. 지도학습에도 다양한 종류가 있으며 이들의 성능은 입력데이터인 빅데이터의 특성과 상태에 좌우된다. 따라서, 본 논문에서는 특정한 빅 데이터 세트에 대한 다수의 지도학습 방식들의 성능을 비교하기 위해 텐서플로우(Tensorflow)와 사이킷런(Scikit-Learn)에서 제공하는 대표적인 지도학습의 방식들을 이용하여 파이썬언어와 주피터 노트북 환경에서 시뮬레이션하고 분석하였다.","The advent of the AI(Artificial Intelligence) has applied to many industrial and general applications having an impact on our lives these days. Various types of machine learning methods are supported in this field. The supervised learning method of the machine learning has features and targets as an input in the learning process. There are many supervised learning methods as well and their performance varies depends on the characteristics and states of the big data type as an input data. Therefore, in this paper, in order to compare the performance of the various supervised learning method with a specific big data set, the supervised learning methods supported in the Tensorflow and the Sckit-Learn are simulated and analyzed in the Jupyter Notebook environment with python."
이미지 정보를 이용한 영어-한국어 자동 번역,2019,"['machine translation', 'multimodal', 'deep learning', 'image information', 'decoding gate', '기계 번역', '멀티모달', '딥러닝', '이미지 정보', '디코딩 게이트']","기계 번역 연구는 하나의 언어로 된 텍스트를 다른 언어로 자동 변환하는 기술이다. 기존의 기계 번역 연구는 번역을 위해 오직 텍스트 데이터만 사용하였다. 따라서 기존 기계 번역 연구는 입력 텍스트와 관련된 다양한 정보들을 활용할 수 없다는 단점이 있다. 최근에는 텍스트 데이터만 사용하는 기존 기계 번역과 달리 입력 텍스트와 관련된 이미지 정보를 기계 번역 시스템의 추가 입력으로 사용하는 멀티모달 기계 번역 모델이 등장했다. 본 연구에서는 최근 연구 동향에 맞추어 기계 번역의 디코딩 타임에 이미지 정보를 추가하고 이를 영어-한국어 자동 번역에 적용한다. 또한 디코딩 타임에 텍스트 정보와 이미지 정보를 적절히 조절하기 위한 별도의 게이트를 적용한 모델을 제안하고, 실험을 통해 게이트를 적용하지 않은 모델보다 더 좋은 성능을 나타냄을 보인다.","Machine translation automatically converts a text in one language into another language.Conventional machine translations use only texts for translation which is a disadvantage in that various information related to input text cannot be utilized. In recent years, multimodal machine translation models have emerged that use images related to input text as additional inputs, unlike conventional machine translations which use only textual data. In this paper, image information was added at decoding time of machine translation according to recent research trends and used for English-to-Korean automated translation. In addition, we propose a model with a decoding gate to adjust the textual and image information at the decoding time. Our experimental results show that the proposed method resulted in better performance than the non-gated model."
DQN을 이용한 트레이딩 예측을 위한 강화학습 모델 구현,2019,"['machine learning', 'reinforcement learning', 'deep learning', 'trading forecast', 'markov decision process']","본 연구는 주가 기본 데이터와 기술 분석 데이터 그리고 주가 변동 요소 데이터를 이용하여, 트레이딩 행동 예측을 위한 강화학습 모델을 구현하였다. 강화학습 모델은 에이전트를 인공신경망으로 사용하였으며, 환경은 현재 상태, 다음 상태, 행동, 보상, 에피소드 종료로 구축하였다. 본 연구는 세 가지 강화학습 모델을 구축하여 학습결과를 비교하였다. 첫 번째 모델은 버퍼의 학습 데이터를 랜덤하게 추출하고, 하나의 신공신경망으로 학습하였다. 두 번째 모델은 버퍼의 데이터를 순서적으로 추출하고, 두 개의 인공신경망으로 학습하였다. 세 번째 모델은 버퍼의 데이터를 랜덤하게 추출하고 두 개의 인공신경망으로 학습하였다. 실험 결과, 세 번째 방법이 근소하게 결과가 좋았으며, 학습 결과가 10배에서 1000배 까지의 이득을 남기는 행동을 하였다. 또한, 학습결과가 좋은 종목이 테스트 결과도 좋았으며, 이것은 종목별로 주가의 패턴에 기인한 것으로 추정된다.","This study implements a reinforcement learning model to predict trading actions efficiently using basic stock data, technical analysis data, and the stock fluctuation factor. The reinforcement learning model uses an artificial neural network as an agent and structures the environment as the current state, next state, action, reward, and termination of the episode. This study compares the training results of three constructed reinforcement training models. The first model extracts the training data of the buffer randomly and learns with a single artificial neural network. The second model extracts the training data of the buffer sequentially and learns with two artificial neural networks. The third model extracts the training data of the buffer randomly and learns with two artificial neural networks. The comparison indicates that the third method was slightly better. The results show a profit of 10 to 1000 times. Additionally, item with good training results have good test results, and estimates that this result is due to the patterns of each item."
기후 및 계절정보를 이용한 딥러닝 기반의 장기간 태양광 발전량 예측 기법,2019,"['태양광 발전량 예측', 'Deep Learning', 'Machine Learning', '시계열 분석', '계절형 ARIMA Model', 'Photovoltaic Power Prediction', 'Deep Learning', 'Machine Learning', 'Time Series Analysis', 'Seasonal ARIMA Model']","최근 온실가스의 증가로 인한 기후변화 대응의 필요성과 전력수요의 증가로 인해 태양광 발전량(PV) 예측의 중요성은 급격히 증가하고 있다. 특히, 태양광 발전량을 예측하는 것은 합리적인 전력 가격결정과 시스템 안정성 및 전력 생산 균형과 같은 문제를 효과적으로 해결하기 위해 전력생산 계획을 합리적으로 계획하는데 도움이 될 수 있다. 그러나 일사량, 운량, 온도 등과 같은 기후정보 및 계절 변화로 인한 태양광 발전량이 무작위적으로 변화하기 때문에 정확한 태양광 발전량을 예측하는 것은 도전적인 일이다. 따라서 본 논문에서는 딥러닝 모델을 통해 기후 및 계절정보를 이용하여 학습함으로써 장기간 태양광 발전량 예측 성능을 향상시킬 수 있는 기법을 제안한다. 본 연구에서는 대표적인 시계열 방법 중 하나인 계절형 ARIMA 모델과 하나의 은닉층으로 구성되어 있는 ANN 기반의 모델, 하나 이상의 은닉층으로 구성되어 있는 DNN 기반의 모델과의 비교를 통해 본 연구에서 제시한 모델의 성능을 평가한다. 실 데이터를 통한 실험 결과, 딥러닝 기반의 태양광 발전량 예측 기법이 가장 우수한 성능을 보였으며, 이는 본 연구에서 목표로 한 태양광 발전량 예측 성능 향상에 긍정적인 영향을 나타내었음을 보여준다.","Recently, since responding to meteorological changes depending on increasing greenhouse gas and electricity demand, the importance prediction of photovoltaic power (PV) is rapidly increasing. In particular, the prediction of PV power generation may help to determine a reasonable price of electricity, and solve the problem addressed such as a system stability and electricity production balance. However, since the dynamic changes of meteorological values such as solar radiation, cloudiness, and temperature, and seasonal changes, the accurate long-term PV power prediction is significantly challenging. Therefore, in this paper, we propose PV power prediction model based on deep learning that can be improved the PV power prediction performance by learning to use meteorological and seasonal information. We evaluate the performances using the proposed model compared to seasonal ARIMA (S-ARIMA) model, which is one of the typical time series methods, and ANN model, which is one hidden layer. As the experiment results using real-world dataset, the proposed model shows the best performance. It means that the proposed model shows positive impact on improving the PV power forecast performance."
반도체 제조라인 내 물류자동화시스템의 처리능력 향상을 위한 딥러닝 기반 디스패칭 방법론,2019,"['Scheduling', 'Deep learning', 'Semiconductor manufacturing', 'Lot targeting']",,"We present a deep-learning-based prediction method for the machine allocation problem of production scheduling in semiconductor manufacturing fabrication (FAB). This method is devised to improve the throughput capacity of the automated material handling system (AMHS). A prediction method is applied to determine the machine to perform the next process after a lot completes a process. Selecting the proper machine for the next process can shorten the travel distance of the overhead hoist transfers (OHTs), and this will eventually lead to reduced utilization and increased throughput capacity of the AMHS. The results confirm that the accuracy of our deep-learning-based machine selecting method is quite high and that it outperforms the other machine learning methods."
딥러닝 기반 항생제 내성균 감염 예측,2019,"['Antibiotic Resistance', 'Deep Learning', 'Neural Embedding Model', 'Matrix Factorization', 'Electronic Health Records', '항생제 내성', '딥러닝', '뉴럴 임베딩 모델', '행렬 분해', '전자의무기록']","세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염 확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반 분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding 하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염 간의 높은 연관성이 발견되었다.","The World Health Organization (WHO) and other government agencies aroundthe world have warned against antibiotic-resistant bacteria due to abuse of antibiotics and are strengthening their care and monitoring to prevent infection. However, it is highly necessary to develop an expeditious and accurate prediction and estimating method for preemptive measures. Because it takes several days to cultivate the infecting bacteria to identify the infection, quarantine and contact are not effective to prevent spread of infection. In this study, the disease diagnosis and antibiotic prescriptions included in Electronic Health Records were embedded through neural embedding model and matrix factorization, and deep learning based classification predictive model was proposed. The f1-score of the deep learning model increased from 0.525 to 0.617when embedding information on disease and antibiotics, whichare the main causes of antibiotic resistance, added to the patient’s basic information and hospital use information. And deep learning model outperformed the traditional machine hospital use information. And deep learning model outperformed the traditional machine learning models.As a result of analyzing the characteristics of antibiotic resistant patients, resistant patients were more likely to use antibiotics in J01 than nonresistant patients who were diagnosed with the same diseases and were prescribed 6.3 times more than DDD."
네트워크 공격 탐지 성능향상을 위한 딥러닝을 이용한 트래픽 데이터 생성 연구,2019,"['Network security', 'Intrusion detection', 'Network traffic data', 'Deep learning', 'GAN', '네트워크 보안', '침입탐지', '네트워크 트래픽 데이터', '딥러닝', 'GAN']","네트워크 공격을 탐지하기 위하여 기계학습을 이용한 다양한 연구가 최근 급격히 증가하고 있다. 이러한 기계학습 방법은 많은 데이터에 의존적이며 연구를 위해 다양한 실험 데이터가 공개되어 사용되고 있다. 하지만 실험 데이터 및 실제 환경에서 수집되는 데이터는 class간의 수량이 불균형하다는 문제점을 가지고 있다. 본 연구에서는 기계 학습을 이용한 침입탐지시스템의 한계점 중 학습데이터의 class간 불균형으로 인한 분류 성능 저하를 해결하기 위한 방법을 제안한다. 이를 위해 네트워크 트래픽 데이터를 처리하고 seqGAN를 이용하여 부족한 데이터를 생성하였다. 제안된 방법은 NSL-KDD, UNSW-NB15 데이터 셋을 대상으로 Text-CNN을 이용하여 분류하는 테스트를 실행한 결과 정밀도가 향상되는 것을 확인할 수 있었다.","Recently, various approaches to detect network attacks using machine learning have been studied and are being applied to detect new attacks and to increase precision. However, the machine learning method is dependent on feature extraction and takes a long time and complexity. It also has limitation of performace due to learning data imbalance. In this study, we propose a method to solve the degradation of classification performance due to imbalance of learning data among the limit points of detection system. To do this, we generate data using Generative Adversarial Networks (GANs) and propose a classification method using Convolutional Neural Networks (CNNs). Through this approach, we can confirm that the accuracy is improved when applied to the NSL-KDD and UNSW-NB15 datasets."
다중 패턴 인식 기법을 이용한 DWT 전력 스펙트럼 밀도 기반 기계 고장 진단 기법,2019,"['Atificial Neural Network', 'Discrete Wavelet Transform', 'Machine Fault Diagnosis', 'Machine Learning', 'Pattern Recognition']",,"The goal of the sound-based mechanical fault diagnosis technique is to automatically find abnormal signals in the machine using acoustic emission. Conventional methods of using mathematical models have been found to be inaccurate due to the complexity of industrial mechanical systems and the existence of nonlinear factors such as noise. Therefore, any fault diagnosis issue can be treated as a pattern recognition problem. We propose an automatic fault diagnosis method using discrete wavelet transform and power spectrum density using multi pattern recognition. First, we perform DWT-based filtering analysis for noise cancelling and effective feature extraction. Next, the power spectral density(PSD) is performed on each subband of the DWT in order to effectively extract feature vectors of sound. Finally, each PSD data is extracted with the features of the classifier using multi pattern recognition. The results show that the proposed method can not only be used effectively to detect faults as well as apply to various automatic diagnosis system based on sound."
포지션 인코딩 기반 S³-Net를 이용한 한국어 기계 독해,2019,"['S³-Net', '한국어 기계독해', '포지션 인코딩', '딥러닝', 'S³-Net', 'Korean machine reading comprehension', 'position encoding', 'deep learning']","S³-Net은 Simple Recurrent Unit (SRU)과 자기 자신의 RNN sequence에 대하여 어텐션 가중치(attention weight)를 계산하는 Self-Matching Networks를 기반으로 기계 독해 질의 응답을 해결하는 딥 러닝 모델이다. 기계 독해 질의 응답에서 질문에 대한 답은 문맥 내에서 발생하는데, 하나의 문맥은 여러 문장으로 이뤄지기 때문에 입력 시퀀스의 길이가 길어져 성능이 저하되는 문제가 있다. 본 논문에서는 이와 같이 문맥이 길어져 성능이 저하되는 문제를 해결하기 위하여 문장 단위의 인코딩을 추가한 계층 모델과, 단어 순서 정보를 확인하는 포지션 인코딩을 적용한 S³-Net을 제안한다. 실험 결과, 본 논문에서 제안한 S³-Net 모델이 한국어 기계 독해 데이터 셋에서 기존의 S²-Net보다 우수한(single test) EM 69.43%, F1 81.53%, (ensemble test) EM 71.28%, F1 82.67%의 성능을 보였다.","S³-Net is a deep learning model that is used in machine reading comprehension question answering (MRQA) based on Simple Recurrent Unit and Self-Matching Networks that calculates attention weight for own RNN sequence. The answers to the questions in the MRQA occur within the passage, because any passage is made up of several sentences, so the length of the input sequence becomes longer and the performance deteriorates. In this paper, a hierarchical model that adds sentence-level encoding and S³-Net that applies position encoding to check word order information to solve the problem of long-term context degradation are proposed. The experimental results show that the S³-Net model proposed in this paper has a performance of 69.43% in EM and 81.53% in F1 for single test, and 71.28% in EM and 82.67 in F1 for ensemble test."
비지도학습을 이용한 지능형 반도체 기술분석,2019,"['Unsupervised Learning', 'Neuromorphic Chip', 'Machine Learning', 'Technology Clustering', 'IP-R&D', '비지도학습', '지능형 반도체', '기계학습', '기술군집화', 'IP-R&D']","지능형 반도체(Neuromorphic chip)는 메모리와 비메모리로 나누어지는 기존 반도체와는 달리 하나의 반도체가 저장과 연산기능을 모두 수행하며, 인공지능 기술의 핵심인 비정형 데이터 인식과 패턴분석을 효과적으로 처리할 수 있다. 특히 사람의뇌신경을 모방한 시냅스 구조를 통해 4차 산업 혁명시대에 요구되는 복합적인 기능을 수행할 때 기존 반도체 대비 1억분의1 수준으로 전력 소비량을 줄일 수 있다. 이와 같은 특성은 지능형 반도체가 미래 반도체 시장의 핵심 기술이 될 것을 쉽게예측할 수 있게 해주고 있다. 따라서 성장한계에 부딪힌 기존 반도체 시장에서의 지속·혁신 성장과 미래 반도체 시장에서의경쟁우위를 선점하기 위해서는 지능형 반도체 분야의 기술경쟁력 확보가 필수적이다. 본 논문은 지능형 반도체 분야의기술경영전략을 수립하기 위해 한국, 유럽, 미국, 일본의 특허를 수집하고 비지도 기계학습을 이용한 정량적인 특허분석을수행하였다. 최적의 분석결과를 도출하기 위하여 주성분 분석, 계층적 기술군집화, 비계층적 기술군집화를 결합한 방법을이용하여 지능형 반도체소자 기술의 세부기술을 도출하고 기술경쟁력 확보를 위한 IP-R&D 전략을 제안하였다","Unlike conventional semiconductors, which are divided into memory and non-memory, a single Neuromorphic chip performs both storage and arithmetic functions, and can effectively process atypical data recognition and pattern analysis, which are the core of artificial intelligence technology. In particular, through the synaptic structure that mimics the human brain nerve, the power consumption can be reduced to one hundred millionth of that of conventional semiconductors when performing the complex functions required in the Fourth Industrial Revolution. These characteristics make it easy to predict that intelligent semiconductors will become the core technology of the future semiconductor market. Therefore, it is essential to secure technological competitiveness in the field of intelligent semiconductors in order to sustain continuous and innovative growth in the existing semiconductor market and face a competitive advantage in the future semiconductor market. This paper collects patents from Korea, Europe, USA, and Japan and conducts quantitative patent analysis using unsupervised machine learning to establish technology management strategies in the field of intelligent semiconductors.In order to derive the optimal analysis result, we derived the detailed technology of the intelligent semiconductor device technology using a combination of principal component analysis, hierarchical technology clustering and non-hierarchical technology clustering, and proposed IP-R &D strategy to secure technological competitiveness."
한문고전 인공지능 번역 연구의 필요성과 선결 과제,2019,"['Literary Sinitic', 'Translation', 'Machine Translation', 'Artificial intelligence(AI)', 'Big Data', 'Deep Learning', '한문고전', '번역', '기계번역', '인공지능', '빅데이터', '딥러닝']","기계번역 기술의 발달에 힘입어 한문고전을 현대 한국어로 옮기는 전통적인 번역 과정에서 인간의 역량을 인공지능으로 대체하는 것이 가능한 일일까? 본 논문은 이 물음에 대한 해결 방안을 제시하고자 하였다. 이것은 전통적인 한국의 한문 자료를 이해하는 데 있어서 획기적인 기술의 전환을 의미할 뿐만 아니라, 현대의 정보화 시대에서 한문 연구자 및 사용자들에게 기계번역을 통한 편의성 제고는 필수불가결한 시대적 흐름이 될 것이다.본고는 한문 기계번역의 도입과 연구 과정에서, 기존 한문학 관련 연구자들의 역할을 재조명하고, 현대의 정보화 시대에서 한문 기계번역의 활용도 및 효율성 제고를 위한 한문학 연구자들의 새로운 역할을 제시하였다.한문 기계번역 시스템이 활성화되기 위해서는 두 가지 선결 과제가 수행되어야 한다. 첫째, 한문번역 수행을 위한 다양하고 효율적인 도구를 개발하여 번역 공정에 필요한 도구 구축이 선행되어야 한다. 둘째, 질적 수준과 양적 수준이 구비된 병렬코퍼스를 구축하기 위한 방안 설정과 시행이 뒷받침되어야 한다. 본고의 연구 결과를 통해 ‘한문 언어학’과 같은 학문 영역의 새로운 연구 분야를 창출함으로써, 인간의 기억과 직관 능력에 의존해왔던 기존의 문학 연구 및 번역 분야에 획기적인 변화를 촉진할 수 있으며, 이는 곧 지식의 유통과 재생산의 의미에서 학문적인 기여와 효율성을 제고하게 될 것이다.","As machine translation technology develops, translation from Literary Sinitic to modern Korean language is now possible. This enhances the users' excellence in understanding the Literary Korean-Sinitic. Machine translation, in turn, becomes essential for scholars studying Literary Korean-Sinitic in the modern information era.We propose Linguistics of Literary Sinitic' which is a novel research area facilitating the usage of Literary Korean-Sinitic in the modern information era. This can catalyze change in the classical literature research and classical translation research which depended on human memory and intuition. This study contributes to information reproduction and transfer."
오차항과 러닝 기법을 활용한 예측진단 시스템 개선 방안 연구,2019,"['Support Vector Machine', 'Multi Layer Perception', 'Error Term']",,"Purpose: The purpose of this study is to apply the machine and deep learning methodology on error terms which are continuously auto-generated on the sensors with specific time period and prove the improvement effects of power generator prediction diagnosis system by comparing detection ability.Methods: The SVM(Support Vector Machine) and MLP(Multi Layer Perception) learning procedures were applied for predicting the target values and sequentially producing the error terms for confirming the detection improvement effects of suggested application. For checking the effectiveness of suggested procedures, several detection methodologies such as Cusum and EWMA were used for the comparison.Results: The statistical analysis result shows that without noticing the sequential trivial changes on current diagnosis system, suggested approach based on the error term diagnosis is sensing the changes in the very early stages.Conclusion: Using pattern of error terms as a diagnosis tool for the safety control process with SVM and MLP learning procedure, unusual symptoms could be detected earlier than current prediction system. By combining the suggested error term management methodology with current process seems to be meaningful for sustainable safety condition by early detecting the symptoms."
불균형 데이터 분류를 위한 딥러닝 기반 오버샘플링 기법,2019,"['불균형 데이터', 'CGAN', '딥러닝', '오버샘플링', 'Imbalanced Data', 'CGAN', 'Deep Learning', 'Over-Sampling']",,"Classification problem is to predict the class to which an input data belongs. One of the most popular methods to do this is training a machine learning algorithm using the given dataset. In this case, the dataset should have a well-balanced class distribution for the best performance. However, when the dataset has an imbalanced class distribution, its classification performance could be very poor. To overcome this problem, we propose an over-sampling scheme that balances the number of data by using Conditional Generative Adversarial Networks (CGAN). CGAN is a generative model developed from Generative Adversarial Networks (GAN), which can learn data characteristics and generate data that is similar to real data. Therefore, CGAN can generate data of a class which has a small number of data so that the problem induced by imbalanced class distribution can be mitigated, and classification performance can be improved. Experiments using actual collected data show that the over-sampling technique using CGAN is effective and that it is superior to existing over-sampling techniques."
스마트폰 다종 데이터를 활용한 딥러닝 기반의 사용자 동행 상태 인식,2019,"['사용자 행동 인식', '그룹 상호작용', '스마트폰 물리 센서', '컨볼루션 신경망', '장단기 기억 순환 신경망', 'human activity recognition', 'group interaction', 'smartphone multimodal sensors', 'convolutional neural network', 'long short-term memory recurrent network']","스마트폰이 널리 보급되고 현대인들의 생활 속에 깊이 자리 잡으면서, 스마트폰에서 수집된 다종 데이터를바탕으로 사용자 개인의 행동을 인식하고자 하는 연구가 활발히 진행되고 있다. 그러나 타인과의 상호작용 행동 인식에 대한 연구는 아직까지 상대적으로 미진하였다. 기존 상호작용 행동 인식 연구에서는 오디오, 블루투스, 와이파이 등의 데이터를 사용하였으나, 이들은 사용자 사생활 침해 가능성이 높으며 단시간 내에 충분한 양의 데이터를 수집하기 어렵다는 한계가 있다. 반면 가속도, 자기장, 자이로스코프 등의 물리 센서의 경우 사생활 침해 가능성이 낮으며 단시간 내에 충분한 양의 데이터를 수집할 수 있다. 본 연구에서는 이러한 점에 주목하여, 스마트폰 상의 다종 물리 센서 데이터만을 활용, 딥러닝 모델에 기반을 둔 사용자의 동행 상태 인식 방법론을 제안한다. 사용자의 동행 여부 및 대화 여부를 분류하는 동행 상태 분류 모델은 컨볼루션 신경망과 장단기기억 순환 신경망이 혼합된 구조를 지닌다. 먼저 스마트폰의 다종 물리 센서에서 수집한 데이터에 존재하는 타임 스태프의 차이를 상쇄하고, 정규화를 수행하여 시간에 따른 시퀀스 데이터 형태로 변환함으로써 동행 상태분류 모델의 입력 데이터를 생성한다. 이는 컨볼루션 신경망에 입력되며, 데이터의 시간적 국부 의존성이 반영된 요인 지도를 출력한다. 장단기 기억 순환 신경망은 요인 지도를 입력받아 시간에 따른 순차적 연관 관계를학습하며, 동행 상태 분류를 위한 요인을 추출하고 소프트맥스 분류기에서 이에 기반한 최종적인 분류를 수행한다. 자체 제작한 스마트폰 애플리케이션을 배포하여 실험 데이터를 수집하였으며, 이를 활용하여 제안한 방법론을 평가하였다. 최적의 파라미터를 설정하여 동행 상태 분류 모델을 학습하고 평가한 결과, 동행 여부와 대화 여부를 각각 98.74%, 98.83%의 높은 정확도로 분류하였다.","As smartphones are getting widely used, human activity recognition (HAR) tasks for recognizing personal activities of smartphone users with multimodal data have been actively studied recently. The research area is expanding from the recognition of the simple body movement of an individual user to the recognition of low-level behavior and high-level behavior. However, HAR tasks for recognizing interaction behavior with other people, such as whether the user is accompanying or communicating with someone else, have gotten less attention so far. And previous research for recognizing interaction behavior has usually depended on audio, Bluetooth, and Wi-Fi sensors, which are vulnerable to privacy issues and require much time to collect enough data. Whereas physical sensors including accelerometer, magnetic field and gyroscope sensors are less vulnerable to privacy issues and can collect a large amount of data within a short time. In this paper, a method for detecting accompanying status based on deep learning model by only using multimodal physical sensor data, such as an accelerometer, magnetic field and gyroscope, was proposed. The accompanying status was defined as a redefinition of a part of the user interaction behavior, including whether the user is accompanying with an acquaintance at a close distance and the user is actively communicating with the acquaintance. A framework based on convolutional neural networks (CNN) and long short-term memory (LSTM) recurrent networks for classifying accompanying and conversation was proposed.First, a data preprocessing method which consists of time synchronization of multimodal data fromdifferent physical sensors, data normalization and sequence data generation was introduced. We applied the nearest interpolation to synchronize the time of collected data from different sensors. Normalization was performed for each x, y, z axis value of the sensor data, and the sequence data was generated according to the sliding window method. Then, the sequence data became the input for CNN, where feature maps representing local dependencies of the original sequence are extracted. The CNN consisted of 3 convolutional layers and did not have a pooling layer to maintain the temporal information of the sequence data. Next, LSTM recurrent networks received the feature maps, learned long-term dependencies from them and extracted features. The LSTM recurrent networks consisted of two layers, each with 128 cells. Finally, the extracted features were used for classification by softmax classifier. The loss function of the model was cross entropy function and the weights of the model were randomly initialized on a normal distribution with an average of 0 and a standard deviation of 0.1. The model was trained using adaptive moment estimation (ADAM) optimization algorithm and the mini batch size was set to 128. We applied dropout to input values of the LSTM recurrent networks to prevent overfitting. The initial learning rate was set to 0.001, and it decreased exponentially by 0.99 at the end of each epoch training.An Android smartphone application was developed and released to collect data. We collected smartphone data for a total of 18 subjects. Using the data, the model classified accompanying and conversation by 98.74% and 98.83% accuracy each. Both the F1 score and accuracy of the model were higher than the F1 score and accuracy of the majority vote classifier, support vector machine, and deep recurrent neural network. In the future research, we will focus on more rigorous multimodal sensor data synchronization methods that minimize the time stamp differences. In addition, we will further study transfer learning method that enables transfer of trained models tailored to the training data to the evaluation data that follows a different distribution. It is expected that a model capable of exhibiting robust recognition performance against changes in data that is not considered in the model learning stage wil..."
심층학습 전처리를 통한 도면 문자 인식 성능 개선,2019,"['optical character recognition', 'deep learning', 'LSTM', 'pre-processing', 'mathematical morphology filtering']",,"An OCR(Optical Character Recognition) based on deep learning for recognition of characters and numbers on drawings for machine maintenance, is proposed. The proposed pre-processing uses mathematical morphology operation to reduce false detection and recognition due to the leading lines and small parts of the drawings. The LSTM model is used to train and infer drawings of parts book. The results of experiments show that the proposed OCR improves the performance by 6.95 % compared to the classical LSTM  In addition, the processing speed is improved compared to the conventional approaches."
CNN의 깊은 특징과 전이학습을 사용한 보행자 분류,2019,"['Pedestrian Classification', 'Transfer Learning', 'Deep Features', 'CNN', 'INRIA Person Data Set', '보행자 분류', '전이학습', '깊은 특징', 'CNN', 'INRIA Person데이터 세트']","자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning) 을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61% 로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다.그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금낮았지만 고정특징추출 기법보다는 높았다.",
딥 러닝을 활용한 인공지능의 예술표현 사례 연구,2019,"['Artificial Intelligence', 'Deep Learning', 'Art Expression', '인공지능', '딥 러닝', '예술표현']","본 논문은 최근 떠오르고 있는 인류 산업의 과제인 인공지능의 예술표현에 대해 연구하였다. 지금까지의 인공지능 예술표현 사례 분석을 통해 앞으로 과학기술의 예술적 수용에 있어 인공지능이 지니는 새로운 가능성과 한계점을 파악하여 인공지능을 활용한 예술이 발전할 수 있는 기반을 마련하는 데 그 목적이 있다. 이를 위해 딥 러닝의 개념과 인공지능 시대에서 예술의 전개 방향과 특징을 파악하고, 창의성과 행위의 주체성을 기준으로 인공지능의 예술표현 사례를 간접적 표현 측면과 직접적 표현 측면으로 나누어 Deep Dream, The Next Rembrandt, Aaron 등을 분석하였다. 사례 분석을 통해 인간의 신경활동을 본떠 만든 인공신경회로망을 기반으로 구축한 기계학습, 즉 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보처리 방식을 모방한 인공지능은 스스로 15세기부터 20세기에 이르기까지 다양한 이미지를 학습할 수 있으며, 축척된 방대한 데이터를 통해 원하는 형태의 그림을 자유롭게 그릴 수 있다는 사실을 알 수 있었다. 또한 인간과 비교할 수 없는 인공지능의 습득 속도에 따른 발달이 예술분야 전반에 미칠 영향으로 연구 필요성을 확인하였다.본 연구를 통해 과학기술을 활용하여 예술을 표현하는 것은 변화하는 시대 속에서 다르게 요구되는 상대적 속성인 예술의 의미를 구현하는 방식의 변화이자 표현양상임을 알 수 있었다. 따라서 본 연구를 기반으로 다각도에서 예술과 인공지능의 관계에 대해 생각한 인공지능의 예술표현 확장을 기대한다.","This study examined artistic expression by artificial intelligence(AI), which is one of the recently emerging topics in the human industries. By analyzing cases of artistic expression by AI up to the present, this study aims to ascertain the new possibilities and limitations presented by AI with regard to the artistic acceptance of science and technology. It also intends to provide the foundations for the future development of AI-based art. For this purpose, we first presented the concept of deep learning in addition to the direction and characteristics of how art is evolving in the age of AI. Based on this, we analyzed cases of AI-based artistic expression such as Deep Dream, The Next Rembrandt, and Aaron, making distinctions between the aspects of direct and indirect expression and based on the criteria of creativity and autonomy of action. This study’s case analysis revealed that machine learning systems built upon ANN, which mimics human neural activity, were able to imitate the information processing methods of the human brain—i.e., discovering patterns within the myriad data and identifying objects—such that they could learn diverse images from the 15th to the 20th century. We also found that they could use the vast accumulated data to freely draw pictures as they intended. Furthermore, we confirmed the need to study how the highly superior learning speed of AI, and the development thereof, would affect the arts in general. This study’s significance lies in that, by examining artistic expression through science and technology, it explores the changes in how the meaning of art—which is a relative attribute that changes with the times—is realized and expressed. Therefore, based on this research, we expect to expand the artistic expression of artificial intelligence that thought about the relation between art and artificial intelligence in various angles."
딥러닝을 이용한 번호판 검출과 인식 알고리즘,2019,"['License Plate', 'SVM', 'Machine Learning', 'Deep Learning', 'Intelligent Transportation System']",최근 지능형 교통관제 시스템에 관한 다양한 연구가 진행되고 있는 가운데 번호판 검출과 인식 알고리즘은 가장 중요한요소 중에 하나로 대두되고 있다. 번호판은 차량의 고유 식별값을 가지고 있기 때문이다. 기존의 차량 통행 관제 시스템은정차를 기반으로 하고 있으며 차량의 입출입 인식 방법으로 루프 코일을 사용하고 있다. 이러한 방법은 교통 정체를 유발하고 유지보수 비용이 상승하는 단점을 가지고 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 차량의 입출입 인식 방법으로 카메라 영상을 사용한다. 차량 통행 관제 시스템의 특성상 카메라가 고정되어 있다. 이에 차량이 접근하면 카메라의배경화면이 달라진다. 이 특징을 이용하여 배경화면의 차분영상을 구하면 차량의 입출입을 인식할 수 있다. 입출입 인식 후한국 번호판의 형태학적 특성을 이용하여 후보 이미지를 추정한다. 그리고 선형 SVM(Support Vector Machine)을 이용해서최종 번호판을 검출한다. 검출한 번호판의 글자와 숫자 인식 방법으로는 CNN(Convolutional Neural Network) 알고리즘을사용한다. 제안한 알고리즘은 기존의 시스템과 달리 검출 위치를 기준으로 글자와 숫자를 인식하기 때문에 번호판의 규격이변해도 인식할 수 있다. 실험한 결과 기존의 번호판 인식 알고리즘들 보다 제안한 알고리즘이 더 높은 인식률을 가진다.,"One of the most important research topics on intelligent transportation systems in recent years is detecting andrecognizing a license plate. The license plate has a unique identification data on vehicle information. The existing vehicletraffic control system is based on a stop and uses a loop coil as a method of vehicle entrance/exit recognition. Themethod has the disadvantage of causing traffic jams and rising maintenance costs. We propose to exploit differentialimage of camera background instead of loop coil as an entrance/exit recognition method of vehicles. After entrance/exitrecognition, we detect the candidate images of license plate using the morphological characteristics. The license plate canfinally be detected using SVM(Support Vector Machine). Letter and numbers of the detected license plate are recognizedusing CNN(Convolutional Neural Network). The experimental results show that the proposed algorithm has a higherrecognition rate than the existing license plate recognition algorithm."
신경망 모델의 학습 특성 반영을 통한 Successive Halving Algorithm 개선,2019,"['Successive Halving Algorithm', '초매개변수 탐색', '신경망', 'Convolutional Neural Network', 'Successive Halving Algorithm', 'Hyperparameter Search', 'Neural Network', 'Convolutional Neural Network']","초매개변수 탐색은 기계학습 모델의 최적 초매개변수를 찾기 위한 기법이다. Successive Halving Algorithm은 초매개변수탐색 기법의 하나로 신경망 모델의 초매개변수 탐색에 활용된다. 해당 기법은 다른 기법 대비 탐색이 빠르다는 장점을가지지만 최적 초매개변수를 찾기 어렵다는 단점이 있다. 본 논문에서는 신경망 모델의 학습 특성을 반영하여 Successive Halving Algorithm을 효과적으로 수행하는 기법을 제안한다. 제안 기법의 검증을 위하여 Convolutional Neural Network 구조 기반 이미지 분류 모델에 대한 초매개변수 탐색을 수행하였으며, 이를 통해 제안 기법이 기존 기법 대비 탐색을효과적으로 수행하는 것을 확인하였다.","Hyperparameter search is a field which aims to find the optimal hyperparameter of a machine learning model. The Successive Halving Algorithm is a one of the hyperparameter search methods for neural network. This method has the advantage of fast searching compared to other techniques, but it has a disadvantage that it is difficult to find the optimal hyperparameter. In this paper, we propose a technique to effectively perform the Successive Halving Algorithm by considering the learning characteristics of neural network. We validate our technique on hyperperameter search for the image classification model, achieving higher performance compared to other techniques."
스마트 구조물 균열 감지를 위한 1차원 합성곱신경망(1D CNN) 딥러닝을 이용한 파괴 신호 특정 기법,2019,"['구조물 모니터링', '기계 학습', '1D Convolution', '진동 센서', 'Structure Health Monitoring', 'Machine Learning', '1D Convolution Network', 'Accelerometer']","초고층 빌딩, 대형 구조물 등의 건설이 일반화됨에 따라 점차 노후화 및 지진, 태풍 등의 자연재해에 의한 구조물의 손상 모니터링에 대한 필요도가 증가하고 있다. 특히, 하부구조인 구조물 기초에서의 손상은 구조물 전체의 건전도에 부정적인 영향을 미칠 수 있기 때문에, 이에 대한 감지는 매우 중요하다. 구조물 건전도 비파괴검사 방법으로는 대표적으로 음향, 진동 감지기법 등이 제안되었으며, 이에 음향, 진동 감지기에 의해 수집된 신호를 해석하여 균열의 발생 위치 및 균열의 크기, 내구도 등을 역으로 추정하는 방법에 관한 연구가 실험실 스케일에서 많이 수행되어왔다. 하지만 실제로 현장에서는 적용되는 경우가 극히 드문 데 그 이유는 평소 발생하는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 구분하는 것이 어렵기 때문이다. 특히 노이즈 신호와 구조물 파괴 신호가 동시에 수집될 때 이를 구분하는 것은 더욱 어려워진다. 이에 본 연구에서는 노이즈 신호(정상 신호)와 손상파괴 신호(비정상 신호)를 수집하고, 무작위로 합성된 신호를 딥러닝 기법인 1D convolutional neural network model을 통해서 정상 신호와 비정상 신호를 구분하는 알고리즘을 개발하였다. 개발된 알고리즘을 사용하면 현장에서 실시간으로 수집된 신호를 구분할 수 있게 됨으로써 구조물 안전성 변화 예측을 통해 재산 및 인명 피해 위험성을 최소화할 수 있을 것으로 생각한다.","Structures can be damaged by natural disasters such as earthquakes and typhoons. In particular, any damage to the foundation of a structure can present critical problems. Therefore, a smart monitoring technique such as the acoustic emission method is required to detect internal cracks and other types of structural damage. Many laboratory studies on this method have been conducted to estimate the locations and sizes of cracks as well as the resulting changes in structural durability using collected acoustic signals. However, the method has rarely been applied in the field because identifying damage signals from acquired signals, which can contain ambient noise, is difficult. We developed a deep learning algorithm based on a one-dimensional convolutional neural network method that can identify damage or crack signals generated from concrete failure from randomly synthesized signals. Using the developed algorithm, we were able to distinguish damage signals from random ambient noise signals. This algorithm enables real-time monitoring of concrete structures, thus providing a smart monitoring strategy."
역번역을 통한 기계번역의 한계와 발전 가능성 제고: 『채식주의자』를 중심으로,2019,"['『채식주의자』', '기계번역', '역번역', '효용성', '번역품질', 'The Vegetarian', 'machine translation', 'back translation', 'efficacy', 'translational quality']",,"This study examines the differences and gaps between ST and BT of a Korean novel. For this, novelist Han Gang’s The Vegetarian is selected since it is well known for its English translation by Deborah Smith, who won the Man Booker Award in 2016. In this study, back translation is implemented to review the limits and prospects of machine translation. The purpose of back translation is to reveal the differences between linguistic structures and the meanings of words and sentences between ST and BT. To conduct this translation, Google Translate is utilized. Its main focus is on the characterization of its heroine Young-hae. In particular, the description and illumination of her unusual experiences reveals her bizarre choice to become a vegetarian. This serves as a pivotal part of this investigation. Through this analysis, it is found that the machine translation contains numerous errors, despite its recent epoch-making advances through deep learning systems. It still fails to employ a rich corpus, and contains many technical defects in identifying equivalent words and sentences to make sense."
영상처리와 딥러닝 기법을 사용한 채소의 등급별 자동 분류시스템 개발,2019,"['채소 자동분류 시스템', '기계학습 기법', 'CNN', 'VGGNet', '오이 실험영상.', 'vegetable automatic classification system', 'machine learning techniques', 'CNN', 'VGGNet', 'cucumber experiment image.']","농업에서 생산된 과수나 채소에 대한 질을 확인하고 향상시키는 작업은 영상처리에서 굉장히 중요한 부분이다. 실제 농가에서는 스마트팜(smart_farm)을 도입하여 생산량의 증가로 자연히 수익을 늘어나고 또 노동시간이 단축되며 여가시간이 늘어 농가의 삶의 질을 높일 수 있게 되었다. 본 논문에서는 영상처리 기법과 딥러닝 기술을 사용하여 채소의 등급을 자동 분류하기 위한 시스템을 소개한다. 이를 목적으로 농가에서 직접 재배한 오이를 동일한 배경에서 촬영하여 이미지 데이터와 데이터 증가(augmentation) 기법을 통해 데이터셋을 구성하고 3가지 등급으로 분류하기 위한 기계학습방법인 SVM과 딥러닝 방법인 CNN, VGGNet 등을 사용하였다. 또한 본 연구는 대규모 데이터에서 오이를 기계가 자동으로 중요한 패턴과 규칙을 학습하고 의사결정과 예측 등을 하기 위해 구조나 손실 및 활성화 함수들 그리고 학습비율과 같은 하이퍼 파라미터(hyper-parameter)등을 변경시켜 가며 더 좋은 분류 성능을 내는 알고리즘을 개발하였다. 또한 실험을 통해서 제안된 알고리즘이 농업현장에서 취득한 영상자료를 사용해서 오이를 등급별로 잘 구별하는 것을 확인 할 수 있었다. 앞으로 이를 발전시켜 더 좋은 데이터를 많이 확보하고 훈련을 시킨다면 자동분류 시스템의 개발에 더 좋은 성능이 기대되며, 다양한 방면에 활용이 가능 할 것이다.","Identifying and improving the quality of fruits and vegetables produced in agriculture is a very important part of image processing. The introduction of smart_farm in the farmhouse increased production and naturally increased profit of the farmer. In addition, their working hours have been shortened and leisure time has been increased, so that the quality of life of the farmers can be increased. In this paper, we introduce a system for automatically classifying vegetable grades using image processing and deep-learning techniques. For this purpose, We obtained image data of cucumber cultivated directly in a farmhouse on the same background and constructed a data set using data augmentation technique. In order to classify cucumber into three classes, we used SVM, which is a machine running method, and CNN and VGGNet, which are deep running methods. In this study, we also modified the hyper-parameters such as structure, loss and activation functions and learning rate in order to learn the important patterns and rules of the machine automatically from large data and to make decisions and predictions. Experimental results show that the proposed algorithm can distinguish the cucumber by grade using image data obtained from farming sites. If we improve the performance of the automatic classification system by securing much better data and training, then it can be applied to various aspects."
V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지,2019,"['malware detection', 'static analysis', 'disassemble', 'n-gram', 'feature hashing', '악성코드 탐지', '정적 분석', '디스어셈블', 'n-그램', '피쳐 해싱']","악성코드가 급증하여 기계 학습 기반의 자동 탐지 연구가 중요해지고 있다. 악성코드 실행파일로부터 추출되는 opcode 시퀀스는 악성코드 탐지에 좋은 특징이기 때문에 바이트 기반의 n-그램 처리 기법을 거쳐 기계 학습의 입력 데이터로서 폭넓게 사용되고 있다. 본 논문에서는 처리 속도와 저장 공간 측면에서 기존 n-그램 방식을 크게 향상시키는 기본 블록 단위의 딥러닝 입력 데이터 가공 기법인 V-그램을 새롭게 제안한다. V-그램은 opcode 시퀀스로부터 의미 없는 입력 데이터의 불필요한 생성을 막을 수 있다. 본 논문에서는 64,000개 이상의 실제 정상 및 악성코드 파일을 수집하여 진행한 실험을 통해서, V- 그램이 처리 속도와 저장 공간, 그리고 탐지 정확도 측면에서 모두 기존의 n-그램 기법보다 우수하다는 것을 검증하였다.","With the rapid increase in number of malwares, automatic detection based on machine learning becomes more important. Since the opcode sequence extracted from a malicious executable file is useful feature for malware detection, it is widely used as input data for machine learning through byte-based n-gram processing techniques. This study proposed a V-gram, a new data preprocessing technique for deep learning, which improves existing n-gram methods in terms of processing speed and storage space. V-gram can prevent unnecessary generation of meaningless input data from opcode sequences. It was verified that the V-gram is superior to the conventional n-gram method in terms of processing speed, storage space, and detection accuracy, through experiments conducted by collecting more than 64,000 normal and malicious code files."
AI의 중국 고전시가(古典詩歌) 창작 ―시어(詩語)의 학습과 생성,2019,"['AI', 'Chinese Ancient Poetry', 'Five-word quatrain', 'Seven-word quatrain', 'Poetry Creation', 'Machine Learning', 'Deep Learning', 'Poem Generation', 'Word Embedding', 'Word2Vec', 'Artificial Neural Network', 'Recurrent Neural Network', 'Big Data']",,"Is it possible that computers write Chinese poetry like a person? In the past, these questions were considered to be unrealistic. In the days when computers were merely a device for manipulating human commands inflexibly, these questions would have been considered somewhat erratic. In recent years, however, there has been a growing awareness that artificial intelligence algorithms based on Big Data have been utilized in a wide variety of ways, and that the creation of literary works is no longer possible.In this paper, we discussed the process of creating literary works of artificial intelligence, which has recently attracted attention. Especially, artificial intelligence algorithms based on Big Data are used in various fields today. If you have enough data, you can quickly and efficiently process the given conditions. The artificial neural network model is also applied to the field of literary creation, which is known as a human realm. The latest AI creation system introduced in this article writes a natural Chinese ancient poem that is hard to distinguish among the general public. AI creation based on artificial neural network model is a method to find optimal sheer through full learning of mass Chinese poetry data. In this process, the AI can generate a poem based on the information obtained from the deep learning of traditional Chinese ancient poetry. Because the AI creation system remembers all the poems written by thousands of poets, it can be used as a convenient tool to help people if they are specialized for the purpose of poetry creation. In addition, AI creative techniques can also help to broaden understanding of human poetry creation. Computers can play a role in creating new artistic values through methods different from human beings."
과학교과서 말뭉치(K-STeC) 학습을 통한 워드임베딩(word embedding) 모델의 정성적 성능 평가,2019,"['Science textbook corpus', 'Word embedding', 'Word2vec', '과학교과서 말뭉치', '워드임베딩', '워드투벡']","과학 교육의 맥락에서 인공지능의 기술이 도입되어 학생과 기계가 소통하고, 이를 기반으로 교육적전략을 수립하기 위해서는 과학교육에서 주로 다루는 과학 언어의 특징과 의미 관계, 개념적 연결 등이어떤 형태로, 얼마나 타당하게 기계적 표현으로 구현되는지에 대한 탐색과 연구가 필요하다. 최근 텍스트를대상으로 하는 머신 러닝과 관련하여 워드임베딩이 많은 관심을 받고 있는데, 본 연구는 과학교육분야에서머신러닝을 통해 텍스트를 다룸에 있어 적합한 모델의 도입과 활용을 위해 워드임베딩 모델의 성능을 평가하고 결과물이 제공하는 과학교육학적 의미를 탐색, 후속 연구 방향을 제시하고자 수행되었다. 연구방법으로는 워드임베딩 기법 가운데 Word2vec을 사용하였으며 python 3.6을 통해 Gensim 라이브러리를이용하였다. 입력 말뭉치로는 과학교과서 말뭉치(K-STeC) 가운데 중학교 과학 ‘힘과 운동’ 24개 대단원을사용하였다. 워드임베딩 결과물에 대한 성능 평가는 출력된 단어 목록을 하나하나 검토하여 과학적 의미를살펴 정성적으로 평가하였다. Word2vec의 반복 회수, 최소 빈도수, 맥락 범위의 세 가지 변인들에 대한결과의 차이, 입력 말뭉치의 형식형태소 유무, 입력 말뭉치의 크기에 따른 결과 값을 살펴보았는데, 그결과 과학적 개념이 잘 드러난 학습 결과를 출력하기 위한 변인 설정 값을 찾을 수 있었고, 형식형태소의포함 여부에 따라 각기 다른 의미를 가지는 단어 목록이 출력된다는 사실, 입력 말뭉치가 클수록 성능이우수해지나 과학교과서 텍스트의 경우 24개 대단원 약 15만 어절 규모의 말뭉치 정도면 어느 정도 활용가능한 성능이 나옴을 확인하였다.","In the context of science education, in order to communicate with students and machines and to establish educational strategies based on them, research on how the characteristics, semantic relationships, and conceptual connections of science language can be represented in machine type.Is required Recently, word embedding has been receiving much attention in relation to machine learning for text, so this study was carried out to evaluate the performance of the word-embedding model, to present the science educational meaning provided by the results, and to suggest followup research agendas. As a research methodology, from among the word embedding techniques, Word2vec was used and Gensim library was used through Python 3.6. The input corpus used 24 units on ‘Force and Motion’ at the junior high school level from the Korean science textbook corpus (K-STeC). The performance evaluation of the word-embedding results was done qualitatively by reviewing the list of words printed one by one examining the scientific meaning. We have looked at the result differences of the iteration, minimum frequency, and context range of Word2vec, whether or not the formality morpheme is present, and the size of the input corpus. As a result, we found the variable settings to extract scientific concepts well, add the facts that word lists with different meanings are produced depending on whether a formality morpheme is included or not, and the usable size of the corpus is about 150,000 words containing 24 units."
SVM을 이용한 GPS 재밍 탐지에 대한 연구,2019,"['GPS', 'GPS jammer', 'GPS jamming detection', 'multiple GPS receiver channel', 'SVM', 'kNN', 'machine learning']","기존의 GPS(Global Positioning System) 재밍탐지 방법으로 DGPS, ELINT 전자전수신기가 사용되었으나, 제한사항들이 존재한다. 본 논문은 이동형 장치를 이용하여 GPS 재밍을 탐지하는 것이 목적이다. 이러한 GPS 재밍탐지를 위해 GPS 재밍에 대한 내성이 다른 다중의 GPS 수신기 채널을 구성하고, 수신기에서 출력되는 경위도 좌표의 분포를 이용하여 GPS 재밍의 종류와 신호세기를 탐지하는 방법을 제시한다. 기계학습인 SVM(Support Vector Machine)을 이용하여 학습 및 시험을 수행하였다. 시험결과 94.29% 정확도로 재밍 종류와 신호세기를 탐지하였고, 다중 클래스 SVM의 모호성 해결을 위해 kNN(k Nearest Neighbors) 분류법을 적용한 결과 97.14%까지 정확도를 향상하였다. 제안 방법을 통해 이동형 장치에서 단독으로 GPS 재밍 종류와 신호세기를 탐지할 수 있고, 이러한 정보는 재밍을 경고하여 피해를 최소화하는데 사용 가능할 것으로 판단된다.","Although DGPS(Differential GPS), ELINT electronic warfare receivers were used as traditional GPS jamming detection methods, restrictions exist. This paper aims to detect GPS jamming using mobile equipment. For this GPS jamming detection, we configured a multiple GPS receiver channels with different tolerance against GPS jamming and suggest how to detect GPS jamming types and signal strength using the distribution of latitude and longitude coordinates output from the receiver. The learning and testing was performed using SVM(Support Vector Machine). The results showed 94.29% accuracy in jamming type and signal strength, and improved accuracy up to 97.14% as a result of applying the kNN(k Nearest Neighbors) classification method to resolve ambiguity of multi-class SVM. The proposed method allows the detection of GPS jamming types and signal strength alone on mobile equipment, which is judged to be available to give a warning and minimize damage."
영어 스토리 북 읽기를 통한 구어영어 학습 가능성 - 인공지능번역기 활용 과업을 중심으로 - 이 논문은 2018년 김천대학교 교내학술연구비지원에 의한 것임(gc18068),2019,"['기계번역(machine translation)', '인공지능 번역프로그램(AI translation program)', '대인간 기본적인 의사소통능력( BICS)', '인지/학문적 언어능력( CALP)']",,"The primary goal of this study was to investigate the students' perception on the efficacy of using the English story book in order to enhancing Spoken English ability and of using the AI translation program for studying English. The results  revealed the following: first, the preferred translation program came in order of Papago, Kakao and Google translation, and the reason for that most students mentioned was the highest quality of the translation. Second, they recognized the advantages of using a translator as being able to solve sentences or expressions that they did not know about. Third, the advantage of using English story books as teaching materials is that they are good because the next story is curious and interesting, and because there are many expressions that are not in the existing conversation materials. Fourth, it became easier for them to express in English, they have actual ability to use what they have learned, and they got to have confidence in English."
물체 간 연관 관계 학습을 통한 문장으로부터 장면 생성,2019,"['장면 생성', '이미지 생성', '위치 관계 추정', '심층 인공 신경망', 'scene generation', 'inferring location information', 'artificial neural network']","사람과 기계가 소통할 때 위치 정보는 중요한 역할을 하지만, 때때로 문장에서 생략되어 나타난다. 사람은 생략된 정보를 배경 지식을 통해서 알 수 있지만, 기계는 그렇지 않은 경우가 많기 때문에 문장으로부터 장면을 생성한다면 올바른 장면을 생성하지 못 한다. 이러한 문제를 해결하기 위해 기존의 연구들은 주어진 문장에서 구분 분석 방식을 통해 명시적인 위치 관계를 추정하고 사전 확률들을 이용하여 생략된 정보를 복원하여 장면을 생성하였으나, 이는 형태론적 생산성과 자유로운 어순 등 구문 분석방식을 사용하기에 여러 문제가 있는 한국어 문장에 적용하기에는 많은 어려움이 있다. 따라서 본 논문에서는 한국어 문장으로부터 장면을 생성하는 방법을 제안한다. 먼저 주어진 문장에 명시적으로 나타난 물체 및 위치 관계를 추정하기 위해 RNN 기반의 신경망을 이용한다. 그 다음 물체 간 연관 관계에 대한 사전확률 값들을 학습하여 문장에서 생략된 정보를 추정한다. 추정된 물체 및 위치 정보를 사용하여 장면 트리를 구성하고 이를 통해 장면을 생성한다. 장면 생성에 대한 평가를 위해서 문장에 존재하는 연관 관계를 다루는 모델의 정확도를 측정하고 생성한 장면에 대한 평가를 수행하였다. 그 결과 구문 분석 기반 방식보다 약 25%의 성능 향상이 있어 제안한 방법이 효과적임을 증명하였다.","In communication between humans and machines, location information is crucial.However, it is sometimes omitted. While humans can infer omitted information, machines cannot.Thus, certain problems can occur when generating scenes from sentences. In order to solve this problem, previous studies have found an explicit relation in the sentence, then inferred an implicit relation by using prior probability. However, such methods are not suitable for Korean, as it has morphologically productivity. In this paper, we suggest a scene-generation method for Korean. Frist, we find an explicit relation by using an RNN-based artificial neural network. Then, to infer implicit information, we use the prior probability of relations. Finally, we prepare a scene tree with the obtained information, then generate a scene using that tree. In order to evaluate the scene generation, we measure the accuracy of the model dealing with the relationship and assign a human score to the generated scene. As a result, the method is proven to be effective with excellent performance and evaluation."
오픈소스를 활용한 융합인재교육(STEAM) 사례분석 연구 : 니팅기의 활용을 중심으로,2019,"['오픈소스', '니팅기', '융합인재교육', '사례분석', '융합', 'Open Source', 'Knitting Machine', 'STEAM Education', 'Case analysis', 'Convergence']","본 연구는 다양한 분야에서 널리 활용되고 있는 오픈소스를 활용한 국내외 STEAM 교육의 현황·동향 및 사례분석을 통하여 향후 연구과제로서 설계될 오픈소스 기반의 니팅기를 활용한 STEAM 교육의 기대효과와 시사점을 파악하고자 하였다. 연구방법으로는 문헌연구를 바탕으로 이론적 고찰을 진행하였으며, 이후 국내외 오픈소스를 활용한 STEAM 교육의 현황·동향을 파악 후, 사례를 조사하고 분석하였다. 그 결과 오픈소스를 활용한 STEAM 교육에 대한 사회적 관심이 증가하고 있음을 확인할 수 있었으며, 흥미유발과 자기주도적학습 능력, 창의적 사고 배양을 목적으로 교육이 설계되며, 이에 따른 긍정적 효과가 가시화되고 있는 것을 알 수 있었다. 이러한 시사점을 토대로 오픈소스를 통하여 제작한 니팅기를 활용하였을 때의 기대효과를 제시하고, 향후에 설계될 STEAM 교육에 대한 설계 방향 및 의의를 검토하고자 한다.","This study was designed to identify the expected effects and implications of STEAM education using open source-based knitwear to be designed as an open source task in the future by analyzing the current status, trends and case studies of domestic and foreign STEAM education using open source widely used in various fields. As a research method, the theoretical examination was conducted based on the literature research, and the current status and trend of STEAM education using open source at home and abroad were investigated and analyzed. As a result, the social interest in STEAM education using open source was confirmed to be increasing, and the education was designed for the purpose of generating interest, self directed learning ability, and creative thinking development, and the positive effects of the education were visible. Based on these implications, the expected effects of using an open source made knitter are presented and the design direction and significance of the STEAM training to be designed in the future are reviewed."
정확히 재가중되는 온라인 전체 에러율 최소화 기반의 객체 추적,2019,"['Object Tracking', 'Online Learning', 'Total-Error-Rate Minimization', 'Exact Reweighting', '객체 추적', '온라인 학습', '전체 에러율 최소화', '정확한 재가중']","영상 기반의 보안 시스템의 증가함에 따라 각 용도마다 다른 다양한 객체들에 대한 처리들이 중요해지고 있다. 객체 추적은 객체 인식, 검출과 같은 작업들과 함께 필수적인 작업으로 다뤄진다. 이 객체 추적을 달성하기위해서 다양한 머신러닝이 적용될 수 있다. 성공적인 분류기로써 전체 에러율 최소화(total-error-rate minimization) 기반의 방법론이 사용될 수 있다. 이 전체 에러율 최소화 기반의 방법론은 오프라인 학습을 기반으로 하고 있다. 객체 추적은 실시간으로 처리하며 갱신해야하는 것이 필수적이므로 온라인 학습(online learning)을 기반으로 하는 것이 적합하다. 온라인 전체 에러율 최소화 방법론이 개발되었지만 점근적으로 재가중되는(approximately reweighted) 작업이 포함되어 에러를 누적시킬 수 있다는 단점이 있다. 본 논문에서는 정확하게 재가중되는(exactly reweighted) 방법론을 제안하면서 온라인 전체 에러율 최소화가 달성되었다. 이 제안된온라인 학습 방법론을 객체 추적에 적용하여 총 8개의 데이터베이스에서 다른 추적 방법론들 보다 좋은 성능이달성되었다.","Object tracking is one of important steps to achieve video-based surveillance systems. Object tracking is considered as an essential task similar to object detection and recognition. In order to perform object tracking, various machine learning methods (e.g., least-squares, perceptron and support vector machine) can be applied for different designs of tracking systems. In general, generative methods (e.g., principal component analysis) were utilized due to its simplicity and effectiveness. However, the generative methods were only focused on modeling the target object. Due to this limitation, discriminative methods (e.g., binary classification) were adopted to distinguish the target object and the background. Among the machine learning methods for binary classification, total error rate minimization can be used as one of successful machine learning methods for binary classification. The total error rate minimization can achieve a global minimum due to a quadratic approximation to a step function while other methods (e.g., support vector machine) seek local minima using nonlinear functions (e.g., hinge loss function). Due to this quadratic approximation, the total error rate minimization could obtain appropriate properties in solving optimization problems for binary classification. However, this total error rate minimization was based on a batch mode setting. The batch mode setting can be limited to several applications under offline learning.Due to limited computing resources, offline learning could not handle large scale data sets. Compared to offline learning, online learning can update its solution without storing all training samples in learning process. Due to increment of large scale data sets, online learning becomes one of essential properties for various applications. Since object tracking needs to handle data samples in real time, online learning based total error rate minimization methods are necessary to efficiently address object tracking problems. Due to the need of the online learning, an online learning based total error rate minimization method was developed. However, an approximately reweighted technique was developed. Although the approximation technique is utilized, this online version of the total error rate minimization could achieve good performances in biometric applications. However, this method is assumed that the total error rate minimization can be asymptotically achieved when only the number of training samples is infinite.Although there is the assumption to achieve the total error rate minimization, the approximation issue can continuously accumulate learning errors according to increment of training samples. Due to this reason, the approximated online learning solution can then lead a wrong solution. The wrong solution can make significant errors when it is applied to surveillance systems.In this paper, we propose an exactly reweighted technique to recursively update the solution of the total error rate minimization in online learning manner. Compared to the approximately reweighted online total error rate minimization, an exactly reweighted online total error rate minimization is achieved. The proposed exact online learning method based on the total error rate minimization is then applied to object tracking problems. In our object tracking system, particle filtering is adopted. In particle filtering, our observation model is consisted of both generative and discriminative methods to leverage the advantages between generative and discriminative properties. In our experiments, our proposed object tracking system achieves promising performances on 8 public video sequences over competing object tracking systems. The paired t-test is also reported to evaluate its quality of the results.Our proposed online learning method can be extended under the deep learning architecture which can cover the shallow and deep networks. Moreover, online learning methods, that need the exact reweighting pro..."
애드 테크 기반의 디지털 광고의 타깃팅에 관한 연구,2019,"['빅데이터', '머신러닝', '애드테크', '타깃팅', '디지털 광고', 'big data', 'machine learning', 'ad-tech', 'targeting', 'digital advertising']","본 연구는 사례연구를 통하여 빅데이터와 머신러닝의 애드태크 기술이 디지털광고의 타겟팅에 어떻게 활용되는가를 살펴보았다. 본 연구는 디지털광고의 타겟팅에 활용되는 사용자 데이터의 유형을 살펴보고 이러한 사용자 데이터가 머신러닝과 결합하여 어떻게 사용자 프로파일링과 타겟팅에 활용되는가를 살펴보았다. 연구 결과 가장 기본적인 데모 타겟팅부터 시작하여, 관심사 타겟팅, 행동 타겟팅, 주제 타겟팅, 키워드 타겟팅, 리타겟팅, 문맥 타겟팅, 유사 타겟팅, CRM 타겟팅, 게재위치 타겟팅, 위치 기반 타깃팅, 기타 타겟팅 등을 포함한 대부분의 타깃팅 기빕들은 타겟을 식별하고, 정교하게 분류하는 데에 대부분 빅데이터와 머신러닝을 활용하는 것을 나타났다. 또한 소비자의 구매로 가는 여정을 나타내는 브랜드 퍼널(brand funnel)의 각 단계별로 브랜드가 원하는 소비자의 특성에 따라 이러한 다양한 타겟팅 옵션들이 맞춤형 타겟팅으로 디자인될 수 있는 것으로 나타났다. 요약하면 제 4차 산업혁명의 핵심인 빅데이터와 머신러닝등의 에드테크들은 과거 대중매체 중심의 광고패러다임을 변화시키고 있으며, 특히 이러한 광고 패러다임의 변화는 디지털 광고의 타겟팅에서 두드러지게 나타나고 있는 것으로 나타났다. 즉 과거 대중매체 시대에서 광고주가 구매한 매체에 타겟들이 우연히 노출되기를 기다리는 수동적인 타겟팅 패러다임에서 벗어나서 개인 정보보호법에 저촉되지 않는 제 3자 데이터를 수집하여, 머신러닝을 활용하여 사용자들을 적극적으로 찾아나서는 능동적인 타겟팅 패러다임으로 변화하고 있는 것으로 나타났다.","This study examined how ad-techs such as big data and machine learning are used for digital advertising targeting through case studies. This study examines the types of user data used for digital advertising targeting and how these data are used for user profiling and targeting in combination with machine learning. Most targeting options including demo targeting, interest targeting, behavioral targeting, re-targeting, contextual targeting, topic targeting, keyword targeting, look alike targeting, CRM targeting have shown that they mostly use big data and machine learning to identify and refine targets. In addition, it was found that various targeting options can be designed as customized targeting according to the characteristics of the consumers desired by the brand at each stage of the brand funnel representing the journey to the consumer's purchase. In summary, ad-techs such as big data and machine learning, which are the core of the fourth industrial revolution, are changing the advertising paradigm centered on mass media in the past, and this paradigm shift is especially prominent in the targeting of digital advertising. n other words, in the past mass media era, advertisers waited for the targets to be accidentally exposed to the media purchased by them. However, in the era of ad-techs, advertisers collect third-party data that does not violate the Privacy Act and use them to identify targets. It turns out that it is changing to an active targeting paradigm."
참조점의 불규칙적 배치를 통한 PIC보의 하중 충실도 향상에 관한 연구,2019,"['PIC 보', '3점 굽힘 해석', '머신 러닝', '3축 특성', 'Piecewise Integrated Composite Beam', 'Three Point Bending Analysis', 'Machine Learning', 'Stress Triaxiality']","Piecewise Integrated Composite (PIC) 보는 하중 유형에 따라 구간을 나누어, 각 구간마다 하중 유형에 강한 복합재료의 적층 순서를 배열한 보이다. 본 연구에서는 보의 거동을 고려하여 PIC 보의 구간을 머신 러닝을 통해 나누어 기존에 제시되었던 PIC 보에 비해 우수한 굽힘 특성을 갖게 하는 것이 목적이다. FE 모델의 240개 요소가 참조점으로 선택되었다. 선행 유한요소해석은 머신 러닝의 학습데이터 생성을 위하여 규칙적으로 분포된 참조점에서 3축 특성 값(Triaxiality)으로 나타냈다. 3축 특성 값은 인장, 압축 그리고 전단의 하중유형을 나타낸다. 머신러닝 모델은 하이퍼파라미터(Hyperparameter)와 학습데이터로 구성되었으며, 하이퍼파라미터 튜닝을 통해 적절한 하중 충실도를 도출하였지만, 거동이 큰 보의 옆면에서는 적절하지 않은 하중 충실도가 도출되었다. 이를 해결하기 위하여 고르게 배치한 참조점을 보의 거동에 따라 배치하여 학습 데이터를 얻었고, 머신 러닝 모델이 생성되었다. 앞서 생성된 머신 러닝 모델을 통하여 보가 매핑 되었고, PIC 보에 대하여 유한요소 해석을 진행한 결과, 기존에 제시되었던 PIC 보에 비해 최대하중과 흡수 에너지가 커지는 특성이 나타났다.","Piecewise integrated composite (PIC) beam has different stacking sequences for several regions with respect to their superior load-resisting capabilities. On the interest of current research is to improve bending  characteristics of PIC beam, with assigning specific stacking sequence to a specific region with the help of machine learning techniques. 240 elements of from the FE model were chosen to be reference points. Preliminary FE analysis revealed triaxialities at those regularly distributed reference points to obtain learning data creation of machine learning. Triaxiality values catagorise the type of loading i.e. tension, compression or shear. Machine learning model  was formulated by learning data as well as hyperparameters and proper load fidelity was suggested by tuned values of hyperparameters, however, comparatively higher nonlinearity intensive region, such as side face of the beam showed poor load fidelity. Therefore, irregular distribution of reference points, i.e., dense reference points were distributed in the severe changes of loading, on the contrary, coarse distribution for rare changes of loading, was prepared for machine learning model. FE model with irregularly distributed reference points showed better load fidelity compared to the results from the model with regular distribution of reference points."
A Study on the Conceptual Model of an E-Voting System based on Blockchain,2019,"['Blockchain Technology', 'Decision Tree', 'e-Voting', 'Gaussian Naive Bayes', 'Machine Learning', 'SVM', 'Distributed Network']",,"Voting is an activity that involves choosing a preferred candidate in an election. There are several potential problems in the voting process, including cheating and security failures. The development of a secure electronic voting system that offers the fairness and privacy of existing voting schemes while simultaneously providing the transparency and flexibility offered by electronic systems has been a challenge for some time. To prevent problems in the voting process, we propose a robust technique that includes blockchain and machine learning. Blockchain employs a technique and concept similar to that used by digital currencies to secure transactions. Blockchain voter data is then used to predict votes based on past votes using a machine learning method. The purpose of this research was to provide a conceptual model for an e-voting system based on blockchain technology and machine learning(support vector machines, Gaussian Naive Bayes, and decision trees) to predict votes and provide vote security. The machine learning techniques used in this study predicted votes based on previous voter data with an average of 98% accuracy, while the blockchain improved and tightened e-voting system security using private networks and structures. This study contributes to the literature on e-voting by proposing improvements to vote security and prediction by combining blockchain technology and machine learning techniques. Its primary limitation is that this method has only been replicated on small-scale networks, such as school networks."
A Study on the Conceptual Model of an E-Voting System based on Blockchain,2019,"['Blockchain Technology', 'Decision Tree', 'e-Voting', 'Gaussian Naive Bayes', 'Machine Learning', 'SVM', 'Distributed Network']",,"Voting is an activity that involves choosing a preferred candidate in an election. There are several potential problems in the voting process, including cheating and security failures. The development of a secure electronic voting system that offers the fairness and privacy of existing voting schemes while simultaneously providing the transparency and flexibility offered by electronic systems has been a challenge for some time. To prevent problems in the voting process, we propose a robust technique that includes blockchain and machine learning. Blockchain employs a technique and concept similar to that used by digital currencies to secure transactions. Blockchain voter data is then used to predict votes based on past votes using a machine learning method. The purpose of this research was to provide a conceptual model for an e-voting system based on blockchain technology and machine learning(support vector machines, Gaussian Naive Bayes, and decision trees) to predict votes and provide vote security. The machine learning techniques used in this study predicted votes based on previous voter data with an average of 98% accuracy, while the blockchain improved and tightened e-voting system security using private networks and structures. This study contributes to the literature on e-voting by proposing improvements to vote security and prediction by combining blockchain technology and machine learning techniques. Its primary limitation is that this method has only been replicated on small-scale networks, such as school networks."
Bagging deep convolutional autoencoders trained with a mixture of real data and GAN-generated data,2019,"['representation learning', 'unsupervised learning', 'generative adversarial networks', 'deep convolutional autoencoders', 'bagging']",,"While deep neural networks have achieved remarkable performance in representation learning, a huge amount of labeled training data are usually required by supervised deep models such as convolutional neural networks. In this paper, we propose a new representation learning method, namely generative adversarial networks (GAN) based bagging deep convolutional autoencoders (GAN-BDCAE), which can map data to diverse hierarchical representations in an unsupervised fashion. To boost the size of training data, to train deep model and to aggregate diverse learning machines are the three principal avenues towards increasing the capabilities of representation learning of neural networks. We focus on combining those three techniques. To this aim, we adopt GAN for realistic unlabeled sample generation and bagging deep convolutional autoencoders (BDCAE) for robust feature learning. The proposed method improves the discriminative ability of learned feature embedding for solving subsequent pattern recognition problems. We evaluate our approach on three standard benchmarks and demonstrate the superiority of the proposed method compared to traditional unsupervised learning methods."
지식베이스 구축을 위한 한국어 위키피디아의 학습 기반 지식추출 방법론 및 플랫폼 연구,2019,"['Deep learning', 'Artificial Intelligence', 'Ontology', 'Knowledge base', 'Knowledge extraction', '딥러닝', '온톨로지', '인공지능', '지식베이스', '지식추출']","최근 4차 산업혁명과 함께 인공지능 기술에 대한 연구가 활발히 진행되고 있으며, 이전의 그 어느 때보다도기술의 발전이 빠르게 진행되고 있는 추세이다. 이러한 인공지능 환경에서 양질의 지식베이스는 인공지능 기술의 향상 및 사용자 경험을 높이기 위한 기반 기술로써 중요한 역할을 하고 있다. 특히 최근에는 인공지능 스피커를 통한 질의응답과 같은 서비스의 기반 지식으로 활용되고 있다. 하지만 지식베이스를 구축하는 것은 사람의 많은 노력을 요하며, 이로 인해 지식을 구축하는데 많은 시간과 비용이 소모된다. 이러한 문제를 해결하기위해 본 연구에서는 기계학습을 이용하여 지식베이스의 구조에 따라 학습을 수행하고, 이를 통해 자연어 문서로부터 지식을 추출하여 지식화하는 방법에 대해 제안하고자 한다. 이러한 방법의 적절성을 보이기 위해DBpedia 온톨로지의 구조를 기반으로 학습을 수행하여 지식을 구축할 것이다. 즉, DBpedia의 온톨로지 구조에따라 위키피디아 문서에 기술되어 있는 인포박스를 이용하여 학습을 수행하고 이를 바탕으로 자연어 텍스트로부터 지식을 추출하여 온톨로지화하기 위한 방법론을 제안하고자 한다. 학습을 바탕으로 지식을 추출하기 위한과정은 문서 분류, 적합 문장 분류, 그리고 지식 추출 및 지식베이스 변환의 과정으로 이루어진다. 이와 같은방법론에 따라 실제 지식 추출을 위한 플랫폼을 구축하였으며, 실험을 통해 본 연구에서 제안하고자 하는 방법론이 지식을 확장하는데 있어 유용하게 활용될 수 있음을 증명하였다. 이러한 방법을 통해 구축된 지식은 향후지식베이스를 기반으로 한 인공지능을 위해 활용될 수 있을 것으로 판단된다.","Development of technologies in artificial intelligence has been rapidly increasing with the Fourth Industrial Revolution, and researches related to AI have been actively conducted in a variety of fields such as autonomous vehicles, natural language processing, and robotics. These researches have been focused on solving cognitive problems such as learning and problem solving related to human intelligence from the 1950s. The field of artificial intelligence has achieved more technological advance than ever, due to recent interest in technology and research on various algorithms. The knowledge-based system is a sub-domain of artificial intelligence, and it aims to enable artificial intelligence agents to make decisions by using machine-readable and processible knowledge constructed from complex and informal human knowledge and rules in various fields. A knowledge base is used to optimize information collection, organization, and retrieval, and recently it is used with statistical artificial intelligence such as machine learning. Recently, the purpose of the knowledge base is to express, publish, and share knowledge on the web by describing and connecting web resources such as pages and data. These knowledge bases are used for intelligent processing in various fields of artificial intelligence such as question answering system of the smart speaker.However, building a useful knowledge base is a time-consuming task and still requires a lot of effort of the experts. In recent years, many kinds of research and technologies of knowledge based artificial intelligence use DBpedia that is one of the biggest knowledge base aiming to extract structured content from the various information of Wikipedia. DBpedia contains various information extracted from Wikipedia such as a title, categories, and links, but the most useful knowledge is from infobox of Wikipedia that presents a summary of some unifying aspect created by users. These knowledge are created by the mapping rule between infobox structures and DBpedia ontology schema defined in DBpedia Extraction Framework. In this way, DBpedia can expect high reliability in terms of accuracy of knowledge by using the method of generating knowledge from semi-structured infobox data created by users. However, since only about 50% of all wiki pages contain infobox in Korean Wikipedia, DBpedia has limitations in term of knowledge scalability. This paper proposes a method to extract knowledge from text documents according to the ontology schema using machine learning. In order to demonstrate the appropriateness of this method, we explain a knowledge extraction model according to the DBpedia ontology schema by learning Wikipedia infoboxes. Our knowledge extraction model consists of three steps, document classification as ontology classes, proper sentence classification to extract triples, and value selection and transformation into RDF triple structure. The structure of Wikipedia infobox are defined as infobox templates that provide standardized information across related articles, and DBpedia ontology schema can be mapped these infobox templates. Based on these mapping relations, we classify the input document according to infobox categories which means ontology classes. After determining the classification of the input document, we classify the appropriate sentence according to attributes belonging to the classification. Finally, we extract knowledge from sentences that are classified as appropriate, and we convert knowledge into a form of triples. In order to train models, we generated training data set from Wikipedia dump using a method to add BIO tags to sentences, so we trained about 200 classes and about 2,500 relations for extracting knowledge. Furthermore, we evaluated comparative experiments of CRF and Bi-LSTM-CRF for the knowledge extraction process. Through this proposed process, it is possible to utilize structured knowledge by extracting knowledge according to the ontology schema fro..."
Medical Image Analysis Using Artificial Intelligence,2019,"['Artificial Intelligence (AI)', 'Medical images', 'Deep-learning', 'Machine-learning', 'Convolutional Neural Network (CNN)', 'Big data']",,"Purpose: Automated analytical systems have begun to emerge as a database system that enables the scanning of medical images to be performed on computers and the construction of big data.Deep-learning artificial intelligence (AI) architectures have been developed and applied to medical images, making high-precision diagnosis possible.Materials and Methods: For diagnosis, the medical images need to be labeled and standardized.After pre-processing the data and entering them into the deep-learning architecture, the final diagnosis results can be obtained quickly and accurately. To solve the problem of overfitting because of an insufficient amount of labeled data, data augmentation is performed through rotation, using left and right flips to artificially increase the amount of data. Because various deeplearning architectures have been developed and publicized over the past few years, the results of the diagnosis can be obtained by entering a medical image.Results: Classification and regression are performed by a supervised machine-learning method and clustering and generation are performed by an unsupervised machine-learning method. When the convolutional neural network (CNN) method is applied to the deep-learning layer, feature extraction can be used to classify diseases very efficiently and thus to diagnose various diseases.Conclusions: AI, using a deep-learning architecture, has expertise in medical image analysis of the nerves, retina, lungs, digital pathology, breast, heart, abdomen, and musculo-skeletal system."
네트워크 침입탐지 기술 연구 동향,2019,"['Intrusion detection system', 'Data mining', 'Machine learning']",,
Power Quality Disturbances Identification Method Based on Novel Hybrid Kernel Function,2019,"['Hybrid Kernel Function', 'Power Quality Disturbance', 'Support Vector Machine', 'Wavelet Transform']",,"A hybrid kernel function of support vector machine is proposed to improve the classification performance of power quality disturbances. The kernel function mathematical model of support vector machine directly affects the classification performance. Different types of kernel functions have different generalization ability and learning ability. The single kernel function cannot have better ability both in learning and generalization. To overcome this problem, we propose a hybrid kernel function that is composed of two single kernel functions to improve both the ability in generation and learning. In simulations, we respectively used the single and multiple power quality disturbances to test classification performance of support vector machine algorithm with the proposed hybrid kernel function. Compared with other support vector machine algorithms, the improved support vector machine algorithm has better performance for the classification of power quality signals with single and multiple disturbances."
교차검증과 SVM을 이용한 도시침수 위험기준 추정 알고리즘 적용성 검토,2019,"['위험기준', '유역특성', '한계강우량', 'Support Vector Machine', '교차검증', 'Risk criteria', 'Watershed characteristic', 'Limit rainfall', 'Support Vector Machine', 'Cross-validation']","본 연구는 도시침수 위험기준이 산정되지 않은 지역의 예경보 기준을 예측하기 위해 유역특성 자료와 피해이력 기반으로 산정된 한계강우량을 활용하여 도시침수 위험기준을 추정하는 모델을 검토하였다. 위험기준 추정모델은 머신러닝 알고리즘의 하나인 Support Vector Machine을 이용하여 설계하였으며, 학습자료는 지역별 한계강우량과 유역특성으로 구성하였다. 학습자료는 정규화 한 후 SVM 알고리즘에 적용하였으며, SVM에 적용시 Leave-One-Out과 K-fold 교차검증 알고리즘을 이용하여 절대평균오차와 표준편차를 계산한 후 모델의 성능을 평가하였다. Leave-One-Out의 경우 표준편차가 작은 모델이 최적모델로 선정되었으며, K-fold의 경우 fold의 개수가 적은 모델이 선정되었다. 선정된 모델의 지속시간별 평균 정확도는 80% 이상으로 나타나 침수 위험기준 추정을 위해 SVM을 활용가능 할 것으로 판단된다.","This study reviews a urban flooding risk criteria estimation model to predict risk criteria in areas where flood risk criteria are not precalculated by using watershed characteristic data and limit rainfall based on damage history. The risk criteria estimation model was designed using Support Vector Machine, one of the machine learning algorithms. The learning data consisted of regional limit rainfall and watershed characteristic. The learning data were applied to the SVM algorithm after normalization. We calculated the mean absolute error and standard deviation using Leave-One-Out and K-fold cross-validation algorithms and evaluated the performance of the model. In Leave-One-Out, models with small standard deviation were selected as the optimal model, and models with less folds were selected in the K-fold. The average accuracy of the selected models by rainfall duration is over 80%, suggesting that SVM can be used to estimate flooding risk criteria."
Power Quality Disturbances Identification Method Based on Novel Hybrid Kernel Function,2019,"['Hybrid Kernel Function', 'Power Quality Disturbance', 'Support Vector Machine', 'Wavelet Transform']",,"A hybrid kernel function of support vector machine is proposed to improve the classification performance ofpower quality disturbances. The kernel function mathematical model of support vector machine directly affectsthe classification performance. Different types of kernel functions have different generalization ability andlearning ability. The single kernel function cannot have better ability both in learning and generalization. Toovercome this problem, we propose a hybrid kernel function that is composed of two single kernel functions toimprove both the ability in generation and learning. In simulations, we respectively used the single and multiplepower quality disturbances to test classification performance of support vector machine algorithm with theproposed hybrid kernel function. Compared with other support vector machine algorithms, the improvedsupport vector machine algorithm has better performance for the classification of power quality signals withsingle and multiple disturbances."
Analyzing Subjecthood Tests in Korean Using a Cross-Validation,2019,"['subjecthood diagnostics', 'multiple subject constructions', 'magnitude estimation', 'cross-validation', 'machine learning']",,"Many diagnostics have been proposed to examine subjecthood in Korean, some of which were investigated in terms of their validity as subject diagnostics through a series of experimental studies. This paper takes the experimental data from three experimental studies (Kim et al., 2015; Lee et al., 2015a; Kim et al., 2017) that were previously conducted, and examines the validity of six diagnostic tests using cross-validation and a machine learning method. The experimental data were evenly divided into ten parts (10-fold cross-validation): Nine of them were used for machine learning (training data set), and the remaining one was for the testing (test data set). The analysis was conducted ten times, and the average values were taken. A simple linear regression was conducted for machine learning. Through the analysis, the following results were observed: (i) The accuracy of the diagnostics for Single Subject Construction (SSC) was much higher than that of Multiple Subject Construction (MSC) (SSC: 81,78, MSC: 68.66), (ii) Adjunct Control was the most accurate for SSC, whereas Coordinated Deletion for MSC, (iii) HA and PL Showed low performance. The results also seem to imply that some parts cannot be explained by a simple linear model but can be analyzed with non-linear modeling of language. (Chungnam National University · Korea National University of Education)"
그래프 기반 준지도 학습을 이용한 속성값 전파 결측치 추정,2019,"['준지도 학습', '그래프 이론', '기계학습', '결측치 대체', 'semi-supervised learning', 'graph theory', 'machine learning', 'missing value imputation']","데이터의 레코드들 중에 하나 이상의 속성값이 없는 경우는 비일비재하다. 많은 경우에 있어서 데이터의 수 대비 결측치가 없는 완전레코드의 수의 비율이 적다. 이에 대하여 평균값, 최빈값, 그리고 중앙값 등으로 대체하는 통계적 방법이 가장 보편적으로 쓰이고 있다. 또한 기계학습에서도 k-최근접 이웃탐색이나 의사결정나무 등을 활용한 결측치 추정방법들이 자주 활용된다. 전자는 각 속성의 대표하는 값으로 대체하는 전역적 방법인데 반해 후자는 해당 레코드와 유사한 레코드들의 속성값으로 대체하는 지역적 방법이라 할 수 있다. 그러나 한 속성의 값이 대부분 결측된 경우라면 두 방법 모두 활용하기 어렵다. 이러한 한계를 극복하기 위하여, 본 연구에서는 결측치의 속성과 상관성이 큰 이웃 속성들로부터 값을 추정하는 방법을 제안한다. 속성 간 상관성을 기반으로 하여 한 속성의 대부분의 값이 결측이 되더라도 활용할 수 있다. 제안 방법론으로는 속성들 간의 상관계수로 이루어진 상관 그래프를 만들고, 그래프 기반 준지도 학습을 적용한다. 결측치는 다른 속성값들로부터 상관계수에 비례하여 전파되어 추정된다. 본 논문에서 제안한 결측치 대체 추정 방법과 기존에 결측치 대체에 많이 사용하는 통계적 방법과 기계학습을 비교하여 실험을 진행하였다.","The number of data records without one or more attributes is very large. In many cases, few complete records are available without missing the data values. Statistical methods that replace the missing values with mean, mode and median are commonly used. In machine learning algorithms such as K-nearest neighborhood or decision tree, the missing values are replaced by estimation methods. The statistical method is a global method that replaces each attribute with a representative value, whereas the machine learning algorithm is a local method that replaces the attribute values similar to the records. However, it is difficult to use both methods for records that contain almost all the missing values. In order to overcome these limitations, in this paper, we propose a method to estimate values from neighborhood properties associated with large correlation with the missing attribute. It is based on correlation between attributes, and can be used even if the attributes carry almost missing values. In this proposed method, a correlation graph representing correlation coefficients related to attribute values was constructed based on graph-based semi-supervised learning. Missing values were estimated in proportion to the correlation coefficient derived from related attributes. In this paper, the proposed method compared the statistical method and machine learning algorithm, which are generally used for missing value imputation."
딥러닝을 통한 이미지의 인식론 - 창발성의 비주얼 커뮤니케이션,2019,"['이미지 인식론', '딥러닝', '비주얼 커뮤니케이션', '미적 경험', '인식론적 창발성', 'Image Epistemology', 'Deep Learning', 'Visual Communication', 'Aesthetic  Experience', 'Epistemological Emergent Properties']","이 연구는 ‘인공지능과 빅데이터를 통한 이미지의 존재론과 창발성’이라는 본인의 선행 연구를 잇는다. 이전 연구에서는 ‘인공지능과 빅데이터를 통해 생산한 이미지’와 ‘예술 작품의 이미지’를 ‘이미지 생산 주 체’의 문제와 ‘생산된 이미지의 존재론’의 관점에서 비교, 연구했다. 전자가 현재까지는 예술이 아니지만, 예술이 될 가능성을, 양자가 공유하는 ‘예측 블가능성’을 키워드로 삼아, 이미지 존재론의 관점에서 제시 했다. ‘예측 불가능성’이 ‘인식론적 창발성’의 주요 특징이라는 점에서, 본 연구는 이미지 존재론에 관한 선행 연구를 인식론의 관점으로 확장하는 창발성의 비주얼 커뮤니케이션을 연구하기 위해 다음처럼 논문 을 구성한다. 구체적으로 2장에서는 ‘인식론의 이미지 인식’을 인식 주체인 인간과 대상인 이미지 사이에 상호 작용하는 입장으로 전개된 것으로 고찰한다. 3장에서는 ‘인지과학의 이미지 인식’을 ‘이미지 인지’ 의 차원에서 실행함으로써 인간 지능에 기능해 온 것으로 살펴본다. 4장에서는 ‘딥러닝의 이미지 인식’을 인공지능이 비지도학습이라는 자가 감독 학습을 실행함으로써 이미지의 외피적 판별에만 국한되는 것이 아닌 이미지가 내포한 의미론까지 파악하는 것으로 살펴본다. 마지막 6장에서는 ‘딥러닝을 통한 시각예 술의 이미지 인식’을 딥러닝을 실험하는 3인(팀)의 미술가들(하름 판 덴 도르펠, 레이체 아라, 포렌식 아 키텍처)이 발표한 실제의 작품을 분석하면서 살펴본다. 본 연구는 최근 인공지능이 생산하는 이미지에 대한 미적 경험과 의미 나아가 예술적 해석의 관계를 탐구하는데 기여할 것이다.","This study connects with my previous research, 'Image Ontology and Emergence Properties through AI and Big Data'. In that work, I compared an 'image produced through artificial intelligence and big data' with an 'image of visual artwork' from the viewpoint of 'subject of image production' and the 'ontology of the produced image'. Although the former is not considered art thus far, the possibility of it becoming art is presented from the viewpoint of image ontology using the keyword 'unpredictability', which exists on both sides. 'Unpredictability' is a key feature of 'epistemic emergence'. In this regard, this study proceeds as follows to study the visual communication of Emergent Properties that extend earlier work on image ontology to the perspective of epistemology. Specifically, in Chapter 2 we consider that the 'image recognition of epistemology' has developed into a position of interaction between humans as subjects of recognition and images as objects of recognition. In Chapter 3, we examine how the 'image recognition of cognitive science' has functioned in human intelligence through the concept of 'image cognition'. In Chapter 4, 'image recognition in early machine learning' is examined by considering images that are grasped by supervised learning. In Chapter 5, we examine 'image recognition of deep learning' as artificial intelligence learns self-supervised learning through unsupervised learning to understand the semantics implied by an image rather than being limited to external classifications of images. In the last chapter, chapter 6,""Realization of Visual Art through Deep Learning,"" an actual work of three artists (team members) who are experimenting with deep running (Ham vanden Dorpel, Rachel Ara, and Forensic Architecture), is analyzed. This study will contribute to explorations of the relationship between the aesthetic experience of artificial intelligence produced by artificial intelligence and meaning and artistic interpretation."
심층학습을 이용한 스포츠 사이버물리시스템 연구,2019,"['sports cyber physical system', 'sport data analysis', 'deep learning', 'deep neural network']",,"This paper deals with the analysis and application of sports data using deep learning. Entering the 4th Industrial Revolution, real-world information is digitally converted, stored in cloud servers in the cyber world, and analyzed by artificial intelligence technology. In this study, the Sports Cyber Physical System (CPS) is proposed, where digital transformation takes place, based on the 4th Industrial Revolution. Although ICT is already being introduced and used in sports, sports CPS features deep learning for smarter data analysis. Since deep learning methods were announced in 2012, they have produced remarkable results in natural language processing and video signal processing areas such as voice recognition, voice synthesis, machine translation, document summary, and communication systems. In this paper, we presented convergence technologies that apply deep learning techniques that are continuously developing in natural language processing to sports data analysis. While detailed and accurate perception of sports behavior is the ultimate goal through sports CPS, research using deep learning is now at the beginning stage. We investigate methods to recognize human behavior in daily life and sports actions in specific domain. This paper also discusses studies on the team motion recognition and applications using deep learning."
Analyzing Subjecthood Tests in Korean Using a Cross-Validation,2019,"['subjecthood diagnostics', 'multiple subject constructions', 'magnitude estimation', 'cross-validation', 'machine learning']",,"Many diagnostics have been proposed to examine subjecthood in Korean, some of which were investigated in terms of their validity as subject diagnostics through a series of experimental studies. This paper takes the experimental data from three experimental studies (Kim et al., 2015; Lee et al., 2015a; Kim et al., 2017) that were previously conducted and examines the validity of six diagnostic tests using a cross-validation and a machine learning method. The experimental data were evenly divided into 10 parts (10-fold cross-validation): Nine of them were used for machine learning (training data set) and the remaining one was for the testing (test data set). The analysis was conducted 10 times, and the average values were taken. A simple linear regression was conducted for machine learning. Through the analysis, the following results were observed: (i) The accuracy of the diagnostics for SSC was much higher than that of MSC (SSC: 81,78, MSC: 68.66), (ii) Adjunct Control was the most accurate for SSC, whereas Coordinated Deletion for MSC, (iii) HA and PL had low performance. The results also seem to imply that there are some parts which cannot be explained by a simple linear model but can be analyzed with non-linear modeling of language."
화상인식을 이용한 Al-Si 주조용 합금의 화학조성 예측,2019,"['artificial intelligence', 'image recognition', 'chemical composition', 'microstructure', 'aluminum alloy']",,"In this study, we analyzed the chemical composition of Al-Si cast alloys from microstructural images, using image recognition and machine learning. Binary Al-Si alloys of Si = 1~10 wt% were cast and prepared as reference images in the dataset used for machine learning. The machine learning procedure was constructed with Inception V3 model. Repeated training to relate the microstructural images to their chemical composition was carried out, for up to 10,000 steps, to increase the reliability of the analysis. The peaks of similarity existed in the dataset with chemical compositions corresponding to the known target composition. The heights of the peaks became higher and the distribution of similarity became sharper with further training steps. This means that the weighted average of the chemical composition approached the target composition with increasing training steps. The correctness of the analysis increased with training steps up to 10,000, then was saturated.It was found that the chemical composition outside the dataset range could not be analyzed correctly. Analysis of the compositions between the datasets showed incorrect but reasonable results. The reliability of the chemical composition analysis using machine learning and image recognition developed in this study will increase when a vast range of reference images are collected and verified."
트리 기반 컨볼루션 신경망을 이용한 BigCloneBench 개선,2019,"['코드 클론', '클론 검사', '기계 학습', '벤치마크', '합성곱 신경망', 'code clone', 'clone checking', 'machine learning', 'benchmark', 'Convolutional Neural Network']",,"BigCloneBench has recently been used for performance evaluation of code clone detection tool using machine learning. However, since BigCloneBench is not a benchmark that is optimized for machine learning, incorrect learning data can be created. In this paper, we have shown through experiments using machine learning that the set of Type-4 clone methods provided by BigCloneBench can additionally be found. Experimental results using Tree-Based Convolutional Neural Network show that our proposed method is effective in improving BigCloneBench’s dataset."
폐암검진에서 인공지능 기술의 활용,2019,"['Lung Neoplasms', 'Screening', 'Computed Tomography', 'X-Ray', 'Artificial Intelligence']","저선량 CT를 이용한 폐암검진은 폐암 사망률 감소 효과가 입증되었으며, 국내에서도 시작되었다. 효과적인 폐암검진을 위해서는 저선량 CT에 대한 정확한 판독이 전제되어야 한다. 하지만, 추정 검사 건수와 경험 있는 전문가의 수를 고려했을 때 영상의학 진료에 큰 부담이 될것은 자명해 보인다. 이 문제의 해결 측면에서, 인공지능 기술을 활용한 저선량 CT 판독 보조시스템 개발과 적용에 학계와 관련 산업계의 관심이 모아지고 있다. 특히, 의학영상 분석에직접 적용이 가능한 딥러닝(deep learning) 기술은 기존 기계학습(machine learning) 기술보다 우수한 진단 성능을 보이고 있어, 그 잠재적 유용성에 대한 연구가 활발히 진행되고 있다. 폐암검진에서 딥러닝을 포함한 인공지능 기술을 적용할 수 있는 분야는 크게 컴퓨터 보조 병변 검출, 판독문 생성, 검출된 폐결절의 악성도 평가, 그리고 환자의 예후 예측으로 나누어 볼 수 있다. 이에 본 기고문에서는 현재 폐암검진에 활용할 수 있는 인공지능 기반 연구들을 살펴보고, 향후 이를 이용한 폐암검진의 가능성에 대해 논의하고자 한다.","Lung cancer is a leading cause of deaths due to cancer, worldwide. At present, low-dose computed tomography (CT) is the only established screening method for reducing lung cancer mortality.However, several challenges must be overcome, to ensure the implementation of lung cancer screening, which include a large number of expected low-dose CT examinations and relative shortage of experienced radiologists for interpreting them. The use of artificial intelligence has garnered attention in this regard. A deep learning technique, which is a subclass of machine learning methods, involving the learning of data representations in an end-to-end manner, has already demonstrated outstanding performance in medical image analysis. Several studies are exploring the possibility of deep learning-based applications in medical domains, including radiology.In lung cancer screening, computer-aided detection, report generation, prediction of malignancy in the detected nodules, and prognosis prediction can be considered for the application of artificial intelligence. This article will cover the current status of deep learning approaches, their limitations, and their potential in lung cancer screening programs."
한국어 텍스트 분석과 적용,2019,"['텍스트 분석', '한국어 어조', '머신러닝', '증권발행신고서', 'IPO 기업', 'Text Analysis', 'Korean Texts', 'Machine Learning', 'IPO', 'Registration Statement']","이 논문은 2009년 6월부터 2017년 12월까지 한국증권 시장에 신규 상장된 기업이 제출한 증권발행신고서의 텍스트를 머신러닝 기법을 통해 긍정적 또는 부정적으로 분류하는 작업을 수행하였다. 분류된 어조에 대한 분석 결과 증권발행신고서 중 투자위험요소에 있어 부정적인 어조가 많은 회사는 최초 공모희망가액에 대비 최종 공모가격 비율이 높게 설정하는 경향이 나타났다. 이런 결과는 최초 공모희망가액 밴드가 낮게 설정되었음을 시사한다. 한편, 증권발행신고서의 어조와 상장 직후 수익률 간에는 통계적으로 유의한 관계가 나타나지 않는다. 이 논문은 한국 금융시장에서 기업이 제출한 비정형화된 텍스트에 나타난 어조를 최초로 분석했다는 점에서 의미가 있다. 또한, 이 논문은 향후 한국어 텍스트 분석을 시도하는 학자들에게 도움이 되고자 비정형화된 텍스트 분석에 사용한 프로그램을 제시한 점에서 의미가 있다.","This paper analyzes the texts in registration statements that IPO firms filed when they issued securities in the Korean stock market during June 2009 to December 2017. We classify tones of texts as positive or negative via machine learning. An IPO firm with more negative tones in the risk factor section of registration statement tends to set its final offer price ratio higher than the initial offer price. However, the tone of the texts is not significantly related to the IPO’s initial returns.  This is the first paper to analyze tones of texts in the natural language submitted by companies in the Korean financial market. In addition, this paper provides the program used for the analysis of non-standardized text to help scholars analyze Korean texts in the future."
An Intrusion Detection Model based on a Convolutional Neural Network,2019,"['Intrusion detection', 'Deep learning', 'Convolutional neural network', 'Recurrent neural network.']",,"Machine-learning techniques have been actively employed to information security in recent years. Traditional rule-based security solutions are vulnerable to advanced attacks due to unpredictable behaviors and unknown vulnerabilities. By employing ML techniques, we are able to develop intrusion detection systems (IDS) based on anomaly detection instead of misuse detection. Moreover, threshold issues in anomaly detection can also be resolved through machine-learning. There are very few datasets for network intrusion detection compared to datasets for malicious code. KDD CUP 99 (KDD) is the most widely used dataset for the evaluation of IDS. Numerous studies on ML-based IDS have been using KDD or the upgraded versions of KDD. In this work, we develop an IDS model using CSE-CIC-IDS 2018, a dataset containing the most up-to-date common network attacks. We employ deep-learning techniques and develop a convolutional neural network (CNN) model for CSE-CIC-IDS 2018. We then evaluate its performance comparing with a recurrent neural network (RNN) model. Our experimental results show that the performance of our CNN model is higher than that of the RNN model when applied to CSE-CIC-IDS 2018 dataset. Furthermore, we suggest a way of improving the performance of our model."
1기 무한모선 시스템의 선로 고장판별을 위한 강화학습 기반 외란관측기 설계,2019,"['Single-machine infinite-bus system', 'Reinforcement learning', 'Deep Q-Network', 'Disturbance observer', 'Fault detection', 'Out-of-step']",,"According to the increase of electric power demand in the modern society the power system is gradually expanding. This results in a growing need for an intelligent method of fast determination and protection against various failures in the power system. As the computer platform is improved, the system fault detection and reliable protection devices have been trying to enhance their performances using artificial intelligence techniques. If a failure occurs in the single-machine infinite bus(SMIB) system. the electrical output of the generator changes, which can be regarded as a result of an external disturbance input. This paper presents a line fault detection method by using a reinforcement learning-based disturbance observer that estimates the magnitude of the equivalent disturbance. Reinforcement learning is an algorithm that models the relationship between the behavior of an agent and the reward from environment. This paper has adopted the Deep Q-Network for training of the proposed disturbance observer. The performance of the proposed reinforcement learning-based disturbance observer is verified by computer simulations. The results show that the disturbance can be estimated successfully and the estimate can be used to detect the line fault."
ML-based Interactive Data Visualization System for Diversity and Fairness Issues,2019,"['AI Art', 'Machine Learning', 'Data Visualization', 'Diversity', 'Fairness', 'Inclusiveness.']",,"As the recent developments of artificial intelligence, particularly machine-learning, impact every aspect of society, they are also increasingly influencing creative fields manifested as new artistic tools and inspirational sources. However, as more artists integrate the technology into their creative works, the issues of diversity and fairness are also emerging in the AI-based creative practice. The data dependency of machine-learning algorithms can amplify the social injustice existing in the real world. In this paper, we present an interactive visualization system for raising the awareness of the diversity and fairness issues. Rather than resorting to education, campaign, or laws on those issues, we have developed a web & ML-based interactive data visualization system. By providing the interactive visual experience on the issues in interesting ways as the form of web content which anyone can access from anywhere, we strive to raise the public awareness of the issues and alleviate the important ethical problems. In this paper, we present the process of developing the ML-based interactive visualization system and discuss the results of this project. The proposed approach can be applied to other areas requiring attention to the issues."
An Improved Text Classification Method for Sentiment Classification,2019,"['Sentiment Analysis', 'Machine Learning', 'Text Classification', 'k-Nearest Neighbor Method']",,"In recent years, sentiment analysis research has become popular. The research results of sentiment analysis have achieved remarkable results in practical applications, such as in Amazon's book recommendation system and the North American movie box office evaluation system. Analyzing big data based on user preferences and evaluations and recommending hot-selling books and hot-rated movies to users in a targeted manner greatly improve book sales and attendance rate in movies [1, 2]. However, traditional machine learning-based sentiment analysis methods such as the Classification and Regression Tree (CART), Support Vector Machine (SVM), and k-nearest neighbor classification (kNN) had performed poorly in accuracy. In this paper, an improved kNN classification method is proposed. Through the improved method and normalizing of data, the purpose of improving accuracy is achieved. Subsequently, the three classification algorithms and the improved algorithm were compared based on experimental data. Experiments show that the improved method performs best in the kNN classification method, with an accuracy rate of 11.5% and a precision rate of 20.3%."
문서 유사도를 통한 관련 문서 분류 시스템 연구,2019,"['Document analysis', 'Related document', 'Doc2Vec', 'Machine learning', 'Document classification']",,"This paper proposes using machine-learning technology to analyze and classify historical collected documents based on them. Data is collected based on keywords associated with a specific domain and the non-conceptuals such as special characters are removed. Then, tag each word of the document collected using a Korean-language morpheme analyzer with its nouns, verbs, and sentences. Embedded documents using Doc2Vec model that converts documents into vectors. Measure the similarity between documents through the embedded model and learn the document classifier using the machine running algorithm. The highest performance support vector machine measured 0.83 of F1-score as a result of comparing the classification model learned."
입력영상 변환에 의한 CNN 기반의 SMT 부품 결함 분류 방법,2019,"['surface mount technology', 'machine learning', 'deep learning', 'histogram stretching']",,"Surface Mount Technology (SMT) is a manufacturing process in which components are mounted on the surface of a printed circuit board (PCB). The automatic optical inspection system (AOI) has mainly used the learning-based method for the defect classification of the SMT process, and recently the CNN-based classification method has appeared. However, existing techniques do not consider the area margin of the part, so the classification accuracy decreases. In addition, the classification performance of the CNN classifier is degraded due to the uneven color distribution according to the position of the components. In this paper, we propose a system that can extract the component region and improve the color distribution by the input image transformation. We extract the correct component area through vertical and horizontal projection, and the color improvement enhance the brightness value distribution of the component image through local histogram stretching. By experimental result, we prove the performance of the proposed classification method."
인공신경망 번역 엔진을 활용한 멀티링구얼 문법 교육,2019,"['ニュ?ラル機械??エンジン(Neural machine translation engine)', 'グ?グル??(Google translate)', 'マルチリンガル文法?育(Education of multilingual grammar)', 'テンスとアスペクト(Tense and aspects)', '普遍性(Universalism)']",,"This paper aims to provide a Korean, Japanese, and English multilingual grammar education model using Google Translate. This research is conducted as part of a long-term research project called ‘Construction of Korean, Japanese, and English multilingual education models for Korean adult learners, especially university students majoring in Japanese language and literature’. Park (to appear) claims that the algorithm of the neural machine translation system and the multilingual education model are similar based on the following two points: (i) the theoretical background, (ii) transfer learning. Based on these facts, Park (to appear) states that we need to develop teaching methods of multilingual education using neural machine translation engines such as Google Translate in the future.　Therefore, this paper proposes that Google Translate is applicable to Korean, Japanese, and English multilingual grammar education. Further, marking the first attempt of the same, this paper deals with the grammatical category of ‘tense and aspect’. The study on the multilingual grammar teaching method using Google Translate is being considered for active usage in the future, because this research and Google Translate set the common goal of ‘multilingual use’."
비정형 Security Intelligence Report의 정형 정보 자동 추출,2019,"['보안 위협', '정보 추출', '머신러닝', '딥러닝', '문서 분류', 'Threat Information', 'Information Extraction', 'Machine Learning', 'Deep Learning', 'Document Analysis']","사이버 공격을 예측하고 대응하기 위해서 수많은 보안 기업 회사에서는 공격기법의 특성, 수법 유형을 빠르게 파악하고, 이에 대한 Security Intelligence Report(SIR)들을 배포한다. 하지만 각 기업에서 배포하는 SIR들은 방대하며, 형식이 맞춰져 있지 않다. 본 논문은 대량의 비정형한 SIR들에서 정보를 추출하는데 소요되는 시간을 줄이고 효율적으로 파악하기 위해 SIR들에 대해 정형화하고 주요 정보를 추출하기 위해 5가지 분석기술이 적용된 프레임워크를 제안한다. SIR들의 데이터는 정답 라벨이 없기 때문에 비지도 학습방식을 통해 키워드 추출, 토픽 모델링, 문서 요약, 유사 문서 검색 총 4가지 분석기술을 제안한다. 마지막으로 SIR들에서 위협 정보 추출하기 위해 데이터를 구축하였으며, 개체명 인식 기술에 적용하여 IP, Domain/URL, Hash, Malware에 속하는 단어를 인식하고 그 단어가 어떤 유형에 속하는지 판단하는 분석기술을 포함한 총 5가지 분석기술이 적용된 프레임워크를 제안한다.","In order to predict and respond to cyber attacks, a number of security companies quickly identify the methods, types and characteristics of attack techniques and are publishing Security Intelligence Reports(SIRs) on them. However, the SIRs distributed by each company are huge and unstructured. In this paper, we propose a framework that uses five analytic techniques to formulate a report and extract key information in order to reduce the time required to extract information on large unstructured SIRs efficiently. Since the SIRs data do not have the correct answer label, we propose four analysis techniques, Keyword Extraction, Topic Modeling, Summarization, and Document Similarity, through Unsupervised Learning. Finally, has built the data to extract threat information from SIRs, analysis applies to the Named Entity Recognition (NER) technology to recognize the words belonging to the IP, Domain/URL, Hash, Malware and determine if the word belongs to which type We propose a framework that applies a total of five analysis techniques, including technology."
귀납 추리를 이용한 침입 흔적 로그 순위 결정,2019,"['SVM(Support Vector Machine)', 'Forensic Analysis', 'Intrusion Log Ranking', 'Inductive Reasoning']","대량의 로그 자료로부터 가장 적합한 정보를 추출하기 위한 방법 중 귀납 추리를 이용한 방법이 있다. 본 논문에서는 디지털 포렌식 분석에서 침입 흔적 로그의 순위를 결정하기 위하여 귀납 추리를 이용한 방법 중 분류에 있어서 우수한 SVM(Support Vector Machine)을 이용한다. 이를 위하여, 훈련 로그 집합의 로그 데이터를 침입 흔적 로그와 정상 로그로 분류한다. 분류된 각 집합으로부터 연관 단어를 추출하여 연관 단어 사전을 생성하고, 생성된 사전을 기반으로 각 로그를 벡터로 표현한다. 다음으로, 벡터로 표현된 로그를 SVM을 이용하여 학습하고, 학습된 로그 집합을 기반으로 테스트 로그 집합을 정상 로그와 침입 흔적 로그로 분류한다. 최종적으로, 포렌식 분석가에게 침입 흔적 로그를 추천하기 위하여 침입 흔적 로그의 추천 순위를 결정한다.","Among the methods for extracting the most appropriate information from a large amount of log data, there is a method using inductive inference. In this paper, we use SVM (Support Vector Machine), which is an excellent classification method for inductive inference, in order to determine the ranking of intrusion logs in digital forensic analysis. For this purpose, the logs of the training log set are classified into intrusion logs and normal logs. The associated words are extracted from each classified set to generate a related word dictionary, and each log is expressed as a vector based on the generated dictionary. Next, the logs are learned using the SVM. We classify test logs into normal logs and intrusion logs by using the log set extracted through learning. Finally, the recommendation orders of  intrusion logs are determined to recommend intrusion logs to the forensic analyst."
딥러닝의 변수 중요도를 이용한 인공지능 기술 분석,2019,"['딥러닝', '변수중요도', '기술분석', '선형회귀분석', '인공지능', '특허데이터', 'Deep learning', 'Variable importance', 'Technology analysis', 'Linear regression analysis', 'Artificial intelligence', 'Patent data']",인공지능 기술은 빠른 속도로 발전하고 있다. 특히 인공지능 개발을 이끌고 있는 많은 세부기술 간의 관계를 파악하는 것은 인공지능 기술을 이해하는데 중요하다. 본 연구에서는 이와 같은 인공지능의 기술 분석을 위하여 딥러닝을 적용한다. 최근 전통적인 통계학 및 머신러닝 기법에 비해 딥러닝의 예측 성능이 더 우수함을 보여주는 다양한 연구결과가 발표되고 있다. 하지만 최종 예측과 함께 예측에 사용된 입력변수들의 상대적인 중요도를 파악하는 것은 기존의 통계적 기법에 비해 딥러닝이 가지고 있는 어려움 중 하나이다. 예측모형에서 입력변수가 출력변수에 어떤 형태로 영향을 주는지 확인하려는 연구는 여러 분야에서 이루어지고 있다. 선형회귀분석은 입력변수의 중요도를 확인하기 위하여 표준화 회귀계수를 이용한다. 본 논문에서는 가중치 분석을 통하여 딥러닝의 입력변수 중요도를 계산하여 인공지능 기술에 영향을 미치는 세부기술에 대한 기술 분석을 수행한다. 제안 방법의 타당성을 보이기 위하여 인공지능 기술관련 특허문서를 수집하고 분석하여 인공지능 세부기술간 기술 연관성을 확인한다.,"Artificial intelligence (AI) technology has been developed at a fast pace. In particular, understanding the relationship between various sub technologies leading to AI development is very important to understand AI. In this study, we use deep learning to analyze AI technology. Many studies have been published showing the prediction performance of deep running is superior to the conventional statistical and machine learning methods. However, understanding the relative importance of input variables used in the prediction of output variable is one of the difficulties of deep learning compared to the existing statistical methods. There are many studies in various fields to find out how the input variable affects the output variable in forecasting. For example, linear regression analysis uses standardized coefficients to determine the variable importance. This paper performs technology analysis on the sub technologies that influence AI technology using the variable importance of deep learning. To show the validity of the proposed methodology, we collect and analyze patent documents related to AI technology."
SVM을 이용한 가정용 협력 로봇의 조인트 위치 기반실행동작 예측 모델 개발,2019,"['기계학습', 'IoT', '디지털 트윈', '빅데이터', '협력로봇', 'Machine Learning', 'IoT', 'Digital Twin', 'Big Data', 'Co-Robot']",,"Digital twin is a technology that virtualizes physical objects of the real world on a computer. It is used by collecting sensor data through IoT, and using the collected data to connect physical objects and virtual objects in both directions. It has an advantage of minimizing risk by tuning an operation of virtual model through simulation and responding to varying environment by exploiting experiments in advance. Recently, artificial intelligence and machine learning technologies have been attracting attention, so that tendency to virtualize a behavior of physical objects, observe virtual models, and apply various scenarios is increasing. In particular, recognition of each robot's motion is needed to build digital twin for co-robot which is a heart of industry 4.0 factory automation. Compared with modeling based research for recognizing motion of co-robot, there are few attempts to predict motion based on sensor data. Therefore, in this paper, an experimental environment for collecting current and inertia data in co-robot to detect the motion of the robot is built, and a motion prediction model based on the collected sensor data is proposed. The proposed method classifies the co-robot's motion commands into 9 types based on joint position and uses current and inertial sensor values to predict them by accumulated learning. The data used for accumulating learning is the sensor values that are collected when the co-robot operates with margin in input parameters of the motion commands. Through this, the model is constructed to predict not only the nine movements along the same path but also the movements along the similar path. As a result of learning using SVM, the accuracy, precision, and recall factors of the model were evaluated as 97% on average."
기계학습 기법을 이용한 한국프로야구 승패 예측 모델,2019,"['Win/Lose Prediction Model', 'Baseball Strategy', 'Machine Learning', 'Deep Learning', 'Baseball Data Analysis']",,"In this paper, we propose a new model for predicting effective Win/Loss in professional baseball game in Korea using machine learning technique. we used basic baseball data and Sabermetrics data, which are highly correlated with score to predict and we used the deep learning technique to learn based on supervised learning. The Drop-Out algorithm and the ReLu activation function In the trained neural network, the expected odds was calculated using the predictions of the teams expected scores and expected loss. The team with the higher expected rate of victory was predicted as the winning team. In order to verify the effectiveness of the proposed model, we compared the actual percentage of win, pythagorean expectation, and win percentage of the proposed model."
지능형 클라우드 환경에서 프로세스를 위한 확장된 MRA를 이용한 협업 시스템,2019,"['Intelligent cloud', 'EMRA', 'Metadata', 'Enterprise process', 'Machine learning']","기업에서는 다양한 프로세스들을 운용하는 방법으로는 프로세스라는 기술이 있다. 일반적으로 엔터프라이즈급 협업에서는 프로세스가 효율적으로 운용되어야 하고, 로컬 시스템 간의 상호운용은 필수이다. 그러나 지능형 클라우드 환경에서 로컬 시스템들은 그 목적에 따라 운영되고 있어서 엔터프라이즈급 협업 특성에 맞게 프로세스들을 실제로 운용하기가 어렵다. 또한, 기업형 환경에서 로컬시스템 간의 프로세스를 운영하기 위해서는 서비스 기반의 전사적 데이터 통합이 필요하다.본 논문에서는 지능형 클라우드 환경에서엔터프라이즈급 프로세스가 협업에서 효율적으로 운용되는 방법으로써 확장된 EMRA(Extended Metadata Registry Access) 기반의시스템을 제안한다. 확장된 EMRA는 데이터 통합에 필요한 로컬 시스템 간의 상호운용이 가능하도록 한다. 또한, 프로세스 내부에 포함된 쿼리 간의 발생하는 메타데이터 정보 간의 매핑을 EMRA를 이용한다. 그리고 머신러닝을 이용하여 EMRA에서의 글로벌 스키마와 로컬 스키마 간의 매핑에 대한 분류 및 구성에 대한 기법을 제시한다","The company has a process called technology as a way to operate a variety of processes. Typically the process is to be operated efficiently in an enterprise-class collaboration and interoperability between the local system is required. However, the local system in intelligent cloud environments are difficult to actually operate the processes to enterprise-class collaboration and operational characteristics in accordance with its purpose. In addition, the enterprise data integration services based is necessary to operate the process between the local system in the enterprise environment. In this paper, we propose a system based on (Extended Metadata Registry Access) EMRA extended by how efficiently management in enterprise-class collaboration processes in intelligent cloud environments. The extended EMRA enables interoperability between local systems for data integration. Also, EMRA is used to map the metadata information that occurs between the queries contained in the process. And, we propose a classification and composition method for mapping between global schema and local schema in EMRA using machine learning."
번역 교육의 새로운 ‘통합’ 패러다임 제안,2019,"['번역교육 (translation teaching)', '‘통합’ 패러다임 (‘integration’ paradigm)', '기계 번역 (machine translation)', '창발성 (emergence)', '번역 윤리 (translation ethics)']",,"This paper aims at proposing a new ‘Integration paradigm’ in translator education, noting the rapidly changing business environment in translation industry. Under the new educational paradigm, certain key components need to be integrated in translation classroom for effective teaching and learning. This article begins with a discussion of a dramatic development of translation related technology and its impact on translation profession. Next, translation competence was redefined in consideration of recent challenges triggered by widely-used neural machine translation system. Then, the application of ‘emergence-based’ curriculum was proposed as an important step away from traditional module-based curriculum toward an innovative framework in education setting. After that, the need for ‘authenticity’ in translator training was emphasized with an in-depth discussion regarding ‘what to teach’ and ‘how to teach’. Then, various aspects of blended learning were explored to effectively integrate online and offline teaching. Finally, a close look was given to translation ethics and teacher re-education."
A Study on the Effect of the Document Summar ization Technique on the Fake News Detection Model,2019,"['Fake News Detection', 'Document Summarization', 'Automated Fact Checking', 'Machine Learning', 'Domestic News', '가짜뉴스', '문서요약', '자동화 팩트체킹', '기계학습', '국내뉴스']",,"Fake news has emerged as a significant issue over the last few years, igniting discussions and research on how to solve this problem. In particular, studies on automated fact-checking and fake news detection using artificial intelligence and text analysis techniques have drawn attention. Fake news detection research entails a form of document classification; thus, document classification techniques have been widely used in this type of research.However, document summarization techniques have been inconspicuous in this field. At the same time, automatic news summarization services have become popular, and a recent study found that the use of news summarized through abstractive summarization has strengthened the predictive performance of fake news detection models.Therefore, the need to study the integration of document summarization technology in the domestic news data environment has become evident. In order to examine the effect of extractive summarization on the fake news detection model, we first summarized news articles through extractive summarization. Second, we created a summarized news-based detection model. Finally, we compared our model with the full-text-based detection model.The study found that BPN(Back Propagation Neural Network) and SVM(Support Vector Machine) did not exhibit a large difference in performance; however, for DT(Decision Tree), the full-text-based model demonstrated a somewhat better performance. In the case of LR(Logistic Regression), our model exhibited the superior performance.Nonetheless, the results did not show a statistically significant difference between our model and the full-text-based model. Therefore, when the summary is applied, at least the core information of the fake news is preserved, and the LR-based model can confirm the possibility of performance improvement. This study features an experimental application of extractive summarization in fake news detection research by employing various machine-learning algorithms. The study’s limitations are, essentially, the relatively small amount of data and the lack of comparison between various summarization technologies. Therefore, an in-depth analysis that applies various analytical techniques to a larger data volume would be helpful in the future."
Study on Efficient Impulsive Noise Mitigation for Power Line Communication,2019,"['Power Line Communication', 'Smart Grid System', 'Noise Mitigation', 'Impulsive Noise', 'Machine Learning']",,"In this paper, we propose the efficient impulsive noise mitigation scheme for power line communication (PLC) systems in smart grid applications. The proposed scheme estimates the channel impulsive noise information of receiver by applying machine learning. Then, the estimated impulsive noise is updated in data base. In the modulator, the impulsive noise which reduces the PLC performance is effectively mitigated through proposed technique. As an impulsive noise model, Middleton Class A interference model was employed. The performance is evaluated in terms of bit error rate (BER). From the simulation results, it is confirmed that the proposed scheme has better BER performance compared to the conventional model. As a result, the proposed noise mitigation improves the signal quality of PLC systems by effectively removing the channel noise. The results of the paper can be applied to PLC systems for smart grid."
Study on Efficient Impulsive Noise Mitigation for Power Line Communication,2019,"['Power Line Communication', 'Smart Grid System', 'Noise Mitigation', 'Impulsive Noise', 'Machine Learning']",,"In this paper, we propose the efficient impulsive noise mitigation scheme for power line communication (PLC) systems in smart grid applications. The proposed scheme estimates the channel impulsive noise information of receiver by applying machine learning. Then, the estimated impulsive noise is updated in data base. In the modulator, the impulsive noise which reduces the PLC performance is effectively mitigated through proposed technique. As an impulsive noise model, Middleton Class A interference model was employed. The performance is evaluated in terms of bit error rate (BER). From the simulation results, it is confirmed that the proposed scheme has better BER performance compared to the conventional model. As a result, the proposed noise mitigation improves the signal quality of PLC systems by effectively removing the channel noise. The results of the paper can be applied to PLC systems for smart grid."
Determination of safe mud weight window based on well logging data using artificial intelligence,2019,"['Mechanical earth model', 'safe mud weight window', 'well logging data', 'machine learning', 'support vector machine']",,"Identification of different stresses applied to the environment surrounding wellbore via different processes, and combining these data with mechanical parameters of common formations in hydrocarbon reservoirs comprise a key for addressing a wide range of costly problems and issues in the oil industry. In the present research, first, an attempt was made to construct mechanical earth model based on well logging data, elastic moduli of rock, and appropriate failure criteria for the final purpose of calculating and determining safe mud weight window (SMWW). Finally, appropriate artificial intelligence and machine-learning algorithms were used to establish a relationship between well logging data and SMWW, which could be used to calculate and predict SMWW without using associated relationships with the mechanical earth model. This might end up with a decreased number of required parameters for calculating SMWW, including uniaxial compressive strength. In the present research, the learning process was conducted using datasets from three wells, two of which provided training data, with the other one used as testing data. The prepared model was finally used to predict corresponding pressures to SMWW and baseline pressures for hydraulic fracturing operation. The model gave a coefficient of determination of 0.93 when applied to the testing data using support vector regression algorithm with radial basis function kernel, indicating large capabilities of this algorithm in predicting non-foreseen data."
Parametric design and analysis of the arc motion of a user-interactive rollator handlebar with Hall sensors,2019,['Smart handle Arc motion User-interactive Hall sensor Support vector machine'],,"Most user-interactive rollator handles fabricated so far have had errors in classifying users’ walking intentions due to the structure not considering gravity, in addition to their usage not being intuitive. Here, we introduce a smart handle based on ‘arc motion’ horizontal to the ground to classify the user’s walking intentions accurately. In designing the handle, the limit of grip angle is adopted considering the arc motion. This minimizes the deflection of the handle by gravity and can allow the handle to be optimized for the grip motion. Moreover, we applied the results of our analysis of users’ walking intentions in the arc motion to machine learning. In understanding the user’s intentions to walk, we created two support vector machine classifiers from handle data collected through four Hall sensors. This combination of the arc motion and machine learning has significantly reduced classification errors. As a result, we ensured an accuracy of 0.95, which is a widely used standard in control."
로지스틱 회귀분석과 인공신경망을 이용한 유방암 분류 모델 비교연구,2019,"['로지스틱 회귀분석', '인공신경망', '유방암', '생체지표', 'k-fold', 'logistic regression', 'artificial neural network', 'breast cancer', 'biomarker', 'k-fold']","인공신경망은 유용한 머신러닝 기법으로 활용되고 있지만, 기존 통계분석기법과 비교했을 때 한계점도 있다. 분석결과를 해석하기가 어렵기 때문이다. 특히, 변수 간의 관계 파악이 중요한 보건의료정보 연구에서는 이러한 단점이 두드러진다. 본 연구의 목적은 전통적인 통계기법과 머신러닝기법을 비교하여 관련 있는 인자를 조사하고 어떤 분석기법이 더 적절한지 판단하는 데 있다. 기존 유방암의 발병 요인은 식습관, 비만, 음주, 방사선 등으로 알려져 있으며, 데이터 분석기법으로는 로지스틱 회귀분석이 자주 사용되었다. 로지스틱 회귀분석은 결과를 해석하기가 용이한 것이 장점이지만, 설정한 모델의 예측력이 높지 않을 때도 있다. 이를 보완하고자 본 연구에서는 인공신경망으로 추가분석을 진행했다. 그 결과, 유방암의 생체지표로서 Age, BMI, Glucose, Insulin, Resistin이 관련 있다는 결론을 도출했다. 또한, k-fold Cross Validation을 이용해 모델의 성능을 비교했을 때 로지스틱 회귀분석과 인공신경망 모델의 성능에 큰 차이는 없었으며, 결과해석이 용이한 로지스틱 회귀분석이 더 적합한 분석기법일 수 있다는 것을 확인했다.","Artificial neural networks are used as a useful machine-learning method, but they also have limitations compared to conventional statistical analysis. This is because it is difficult to interpret the results. In particular, this disadvantage is apparent in healthcare information studies where identifying relationships among variables is important. The purpose of this study is to compare conventional statistical analysis and machine-learning method to investigate significant factors and determine which analyzing method is more appropriate. Previously the identified risk factors for breast cancer include fat-centered nutrition, obesity, drinking, radiation, and age. Moreover, logistic regression was used in related studies. Applying to logistic regression model, it is easy to interpret the results, but sometimes its predictive power is not enough high. In order to overcome this problem, Artificial neural network was additionally used. As a result, we concluded that Age, BMI, Glucose, Insulin, and Resistin are variables related to breast cancer. In addition, we compared the performance of the model using k-fold Cross Validation and there was no significant difference. so we found that logistic regression with ease of interpretation may be a more suitable analyzing method."
Study on Efficient Impulsive Noise Mitigation for Power Line Communication,2019,"['Power Line Communication', 'Smart Grid System', 'Noise Mitigation', 'Impulsive Noise', 'Machine Learning']",,"In this paper, we propose the efficient impulsive noise mitigation scheme for power line communication (PLC) systems in smart grid applications. The proposed scheme estimates the channel impulsive noise information of receiver by applying machine learning. Then, the estimated impulsive noise is updated in data base. In the modulator, the impulsive noise which reduces the PLC performance is effectively mitigated through proposed technique. As an impulsive noise model, Middleton Class A interference model was employed. The performance is evaluated in terms of bit error rate (BER). From the simulation results, it is confirmed that the proposed scheme has better BER performance compared to the conventional model. As a result, the proposed noise mitigation improves the signal quality of PLC systems by effectively removing the channel noise. The results of the paper can be applied to PLC systems for smart grid."
실시간 사이버 위협 지능형 분석 및 예측 기술,2019,"['상관관계 분석', '위협 예측', '사이버 위협 인텔리전스', 'Bayesian Networks', '기계학습', 'correlation analysis', 'threat prediction', 'cyber threat intelligence', 'bayesian network', 'machine learning']","인터넷 및 내부망에 설치 운용 중인 각종 정보보호체계 및 통합보안관제체계에서 발생된 방대한 양의 위협 이벤트를 수집, 융합하여 전처리하며, 위협 경보에 대한 통계 기반의 상관관계 분석과 위협 경보 간 상호 인과관계를 학습하는 모델을 구축하여 지능형 분석 모델을 구축한다. 기계학습 기반의 위협 경보 상관분석을 통해 자동으로 공격 경로 재구성 및 예상되는 위협을 예측하며, OSINT를 통해 구축한 사이버 위협 인텔리전스와의 자동화된 연관분석을 통해 침투한 적과 공격에 대한 정보를 수집하고 예상되는 위험을 예측하여 결정권자의 결심을 지원하는 기술을 제안한다.","There is a wide variety of information security systems and integrated security control systems that are installed and operated in the internet and internal networks, and these systems collect substantial amounts of threat events. These collected events are fused and preprocessed to build an intelligent analysis model that learns the mutual causal relationship between the threat alarm and the statistical based correlation analysis. The machine learning-based threat correlation analysis enables the automatic prediction of path reconstruction and anticipated threats. The automated association analysis with cyber threat intelligence built through OSINT collects information on infiltrators and attacks, and also predicts expected risks. This paper suggests a technique to support the decision maker’s determination for the final purpose."
심층신경망을 통한 해파리 출현 예측,2019,"['심층신경망', '부트스트래핑', '데이터 확장', '전이학습', '랜덤포레스트', '연속 전진 선택법', 'Deep Neural Network', 'Bootstrapping', 'Data Expansion', 'Transfer learning', 'Random Forest', 'Sequence Forward Selection']","논문은 지구온난화로 인하여 수온이 상승되며 증가한 해파리의 피해를 감소하고자 연구를 진행하였다. 해수욕장에서 해파리의등장은 해파리의 쏘임 사고로 인한 인명피해와 폐장으로 인한 경제적 손실이 발생할 수 있다. 본 논문은 선행 연구들로부터 해파리의 출현 패턴을 머신러닝을 통하여 예측 가능함 확인하였다. SVM을 이용한 해파리 출현 예측 모델 연구를 확대하여 진행하였다. 심층신경망을 이용하여 해파리 출현 유무 예측인 이진 분류에서 지수화 된 방법인 다중 분류로 확장하고자 하였다. 수집된 데이터의크기가 작다는 한계점으로 인하여 84.57%라는 예측 정확도의 한계를 부트스트래핑을 이용하여 데이터 확장을 통해 해결하고자 하였다. 확장된 데이터는 원본 데이터보다 약 7% 이상의 높은 성능을 보여주었으며, Transfer learning과 비교하여 약 6% 이상의 좋은 성능을 보여주었다. 최종적으로 테스트 데이터를 통하여 해파리 출현 예측 성능을 확인한 결과, 해파리의 출현 유무를 예측할 시 높은정확도로 예측이 가능함을 확인하였으나, 지수화를 통한 예측에서는 의미 있는 결과를 얻지 못하였다.","This paper carried out a study to reduce damage from jellyfish whose population has increased due to global warming. The emergence of jellyfish on the beach could result in casualties from jellyfish stings and economic losses from closures. This paper confirmed from the preceding studies that the pattern of jellyfish's appearance is predictable through machine learning. This paper is an extension of The prediction model of emergence of Busan coastal jellyfish using SVM. In this paper, we used deep neural network to expand from the existing methods of predicting the existence of jellyfish to the classification by index. Due to the limitations of the small amount of data collected, the 84.57% prediction accuracy limit was sought to be resolved through data expansion using bootstraping. The expanded data showed about 7% higher performance than the original data, and about 6% better performance compared to the transfer learning. Finally, we used the test data to confirm the prediction performance of jellyfish appearance. As a result, although it has been confirmed that jellyfish emergence binary classification can be predicted with high accuracy, predictions through indexation have not produced meaningful results."
문화예술 콘텐츠 제작 및 유통에서의 빅데이터 활용 연구,2019,"['Bigdata', 'Video Contents', 'Algorithm', 'Culture Arts Industry', 'Netflix', 'FGI', '빅데이터', '알고리즘', '영상콘텐츠', '문화예술산업', 'Netflix', 'FGI']","4차 산업혁명 시대의 폭발적인 정보의 양을 다루는 빅데이터 관련 연구는 현재 활발히 진행되고 있다. 빅데이터는 머신러닝, 즉 딥러닝의 학습데이터가 되는 광범위한 데이터로 인공지능의 발달을 촉진하는 필수 요소이다. 다양한 분야에서 빅데이터의 활용은 유의미한 결과를 가져오고 있으며, 특히 문화예술 분야에서의 활용도 주목해 볼 필요가 있다. 이에 본 논문은 영상콘텐츠를 중심으로 문화예술 산업에서 빅데이터의 활용 사례를 알아보았다. 주목한 점은 문화예술 콘텐츠의 유통뿐만 아니라 제작단계까지 빅데이터가 활용되고 있는 점이다. 특히 미국의 Netflix가 OTT사업으로 어떤 성과와 변화를 가져왔는지를 먼저 알아보고 국내의 OTT 사업체의 현황도 함께 분석하였다. 그 후 Netflix가 축적된 고객의 데이터를 통해 딥러닝 방식의 ‘시네매치’, 즉 흥행 예측 알고리즘을 활용하여 제작/유통한 ‘House of Cards’의 성공 사례를 분석하였다. 그 후 문화예술 콘텐츠 전문가를 대상으로 FGI(Focus Group Interview)를 진행하였다. 이를 통해 국내 문화예술 산업에서 빅테이터의 향후 활용 전망을 기술적인 측면, 창의적인 측면, 윤리적인 측면으로 나눠서 고찰하였다.","Big data-related research that deals with the amount of explosive information in the era of the Fourth Industrial Revolution is actively underway. Big data is an essential element that promotes the development of artificial intelligence with a wide range of data that become learning data for machine learning, or deep learning. The use of deep learning and big data in various fields has produced meaningful results. In this paper, we have investigated the use of Big Data in the cultural arts industry, focusing on video contents. Noteworthy is that big data is used not only in the distribution of cultural and artistic contents but also in the production stage. In particular, we first looked at what kind of achievements and changes the Netflix in the US brought to the OTT business, and analyzed the current state of the OTT business in Korea. After that, Netflix analyzed the success stories of 'House of Cards', which was produced / circulated through 'Deep Learning' cinematique, which is a prediction algorithm, through accumulated customer data. After that, FGI (Focus Group Interview) was held for cultural and artistic contents experts. In this way, the future prospects of Big Data in the domestic culture and arts industry are divided into technical aspect, creative aspect, and ethical aspect."
인공지능의 법적 지위에 관한 논의 -전자인과 관련하여-,2019,"['인공지능', '전자인', '자율성', '과실책임', '위험책임', '제조물책임', 'artificial intelligence', 'electronic person', 'autonomy', 'principle of liability with fault', 'strict liability', 'product liability']","사람의 지적 활동(인지, 생각, 추론, 그에 근거한 행위 등)을 대체할 수 있는 인공지능 기술은 빅 데이터(big data)와 기계 학습에(machine learning)의해 급속한 발전을 하고 있으며, 자율 주행 자동차 및 의료 진단, 대화 에이전트(채팅 봇) 등의 구현도 진행되고 있다. 인공지능 기술은 4차 산업혁명의 중요한 기반 기술이며, 저출산 고령화가 가져올 노동력 부족 등의 사회 문제를 해결하고 사회에 엄청난 이익을 가져다 줄 것으로 예상하고 있다. 인공지능(artifcial intelligence: AI)은 상당한 추론 능력에 의하여 자율적 판단이 가능하기 때문에 스스로 현실적인 문제 상황에 대처 하거나 창의적 능력을 발현할 것으로 예상된다. 특히 이러한 자율적 판단을 하는 AI로 인하여 손해가 발생한 경우, 종전의 과실책임주의를 유지한다면 피해자 입장에서 AI의 하자나 관리주체의 주의의무 소홀을 입증하기가 어려운 문제가 발생하게 된다. 그리고 무과실 책임주의를 도입하더라도 AI 소유자 등의 입장에서는 예측 불가능한 규모의 손해배상책임을 부담할 법적 리스크에 노출되면서도 마땅히 이를 방지하기 위하여 주의를 기울일 방법도 없다. 즉, 어떠한 원칙에 의하더라도 AI가 초래할 상황을 규제하는 법질서로서 정당성이 인정되기 어렵다.  본 연구에서는 장기적으로 고도로 정교한 인공지능 내지 지능형 로봇의 경우 ‘전자 인(electronic person)’의 지위를 부여하여 불법행위에 대한 배상책임을 지우고 자율적인 의사결정을 하거나 제3자와 상호작용을 하도록 허용하는 유럽의회의 결의안과 계약관계에서 인공지능 로봇의 법 주체성이 문제되는 부분에 전자 대리인이란 개념을 도입하여 법제적 대응을 하고 있는 미국의 동향을 살펴보았다. 특히, 유럽의회 결의안은 강한 인공지능은 물론 초 인공지능에 관한 문제까지도 고려하고 있다는 점에서 상당히 미래지향적인 성향을 띤다. 이는 지능형 로봇에 대한 법적 책임을 규율하지 못하는 기존의 법체계가 가지는 난점을 포섭함과 동시에 선도적인 규제를 시도한 점에 의미가 있다고 할 수 있다. 그리고 2017년 7월 19일에 발의된 우리나라의 “로봇기본법안”의 주요 내용과 책임문제들을 검토 하였다. 자율성을 가진 정교한 인공지능 내지 지능형 로봇과 공존하는 사회에 대비하기 위한 그 이론적 전제연구로서 전자인 개념과 지위에 관한 기초적 연구는 큰 의미가 있다고 여겨진다. 끝으로, 현행 사람과 물건의 2분법적 체계에서 반려 동물을 구분하는 3분법 체계로 전환해 가는 것은 자율성 확대로 사람과 소통하게 되는 전자인의 법적 지위와 관련하여 시사점을 찾을 수 있을 것으로 생각된다.","At present, artificial intelligence technologies that can replace human intellectual activities (cognition, thought, reasoning, actions based on them, etc.) are rapidly developing by big data and machine learning. Materialization of autonomous cars and medical diagnosis, conversation agent (chat bot), and so forth are also in progress. Artificial intelligence technology is an important infrastructure technology of the 4th industrial revolution, and it expects to solve social problems such as labor shortage caused by low birthrate and population aging and bring great benefits to society. Artificial intelligence (AI) is expected to cope with practical problems or to express creative abilities because it can make autonomous judgment based on deduction skills. Especially when the damage is caused by AI with autonomous judgement and if principle of liability with fault is retained, it is difficult for the victim to prove the fault of AI or the negligence of the management authority. And even if the principle of liability without fault is imposed, there is no way for the positions such as the owner of AI to be cautious about being exposed to the legal risk of unpredictable size of liability for damages. In other words, under any principle it is hard to recognize legitimacy as a law regulating the circumstances that an AI can cause.In long term, this paper examines the resolution of the European Parliament which allows to clear liability for illegal acts, make autonomous decisions, or interact with third parties by giving the status of ‘electronic person’ in the case of highly sophisticated artificial intelligence or intelligent robots, and the trends of the United States, taking legal actions by adopting the concept of electronic agent where the legal subjectivity of the artificial intelligent robot is a problem in the contractual relationship. In particular, the resolution of European Parliament is highly future-oriented in that it considers issues of artificial intelligence as well as strong artificial intelligence. This is meaningful since it embraces the difficulties of the existing legal system that does not regulate the legal responsibility for intelligent robots, and at the same time, it has attempted leading regulation. Moreover, this paper reviews the main contents and responsibilities of Korean “Basic Law on Robot” initiated on July 19, 2017. As a theoretical premise to prepare for a society that coexists with sophisticated artificial intelligence or intelligent robots with autonomy, basic research on the concept and position of electronic person is considered to have great significance. Finally, it is thought that the transition from the current dichotomous system of person and object to the trichotomous system that distinguishes companion animals can provide implications for the legal status of the electronic person communicating with the people through the expansion of autonomy."
포스트휴먼적 존재인식론과 학습주체성의 변화,2019,"['posthumanism', 'learner subjectivity', 'neo-materialism', 'actor-network heory', 'object-oriented ontology', 'postphenomenology']",,"This paper intends to discuss how learner subjectivity tends to be shifting from human agency to technology-driven media, propelled by the sheer developments of informatics, neuroscience and artificial intelligence(AI). This issue is discussed by means of the following questions: first, is an artificial learning machine capable of thinking? Second, who get the ownership of learner subjectivity under the conditions of posthuman learning? Third, what could be the theoretical basis of posthuman learner subjectivity? The major arguments of the author on these questions are as follow. First, newly emerging technologies of cybernetics and computer neuroscience developed AI algorithms that exceed the capability of human brain and signalled the era of human-AI collaboration. Second, since the relationship between the human and the machine is not separable and AIs have the potentials of thinking, the human learner will share the learning subjectivity with those thinking machines. Third, this transition of learner subjectivity can be explicated by four onto-epistemological theories of posthumanism: neo-materialism, post-phenomenology, actor-network theory, and object-oriented ontology. This paper’s discussion may provide a room for philosophical deliberation, regarding the issue of subjectivity under the conditions of posthuman learning."
실내외 환경과 사용자의 행동을 고려한 스마트 홈 서비스 시스템,2019,"['Internet of things', 'Home smart', 'ESP 8266', 'Firebase', 'Android app.']","스마트 홈은 가정의 가전제품, 에너지 소비 장치, 보안기기 등 모든 사물을 통신망으로 연결해 모니터링 및 제어할 수 있는 기술이다. 스마트 홈은 자동제어 뿐 아니라 상황과 사용자의 취향을 학습하고, 이에 맞는 결과를 스스로 제공하는 방향으로 발전하고 있다. 본 논문은 사용자의 행동을 감지하여 사용자의 특성에 맞는 쾌적한 실내 환경 제어 서비스를 할 수 있는 모델을 제안하였다. 전체 시스템 구성은 센서와 와이파이를 탑재한 ESP8266, 실시간 데이터베이스인 firebase , 스마트 폰 어플로 구성된다. 본 모델은 사용자가 가전기기 작동시의 학습모드, 학습 결과를 통한 학습 제어, 실내와 실외 센서의 값을 이용한 자동 환기 등의 기능으로 구분된다. 학습은 에어컨, 가습기, 공기청정지 등 가전기기 제어시의 온도와 습도에 대한 이동 평균을 이용하였다. 본 시스템은 데이터베이스에 지속적으로 수집된 데이터를 다양한 기계학습과 딥 러닝을 통해 사용자의 특성을 분석하고 예측하여 보다 고 품질의 서비스를 제공할 수 있다.","The smart home is a technology that can monitor and control by connecting everything to a communication network in various fields such as home appliances, energy consumers, and security devices. The Smart home is developing not only automatic control but also learning situation and user's taste and providing the result accordingly. This paper proposes a model that can provide a comfortable indoor environment control service for the user's characteristics by detecting the user's behavior as well as the automatic remote control service. The whole system consists of ESP 8266 with sensor and Wi-Fi, Firebase as a real-time database, and a smartphone application. This model is divided into functions such as learning mode when the home appliance is operated, learning control through learning results, and automatic ventilation using indoor and outdoor sensor values. The study used moving averages for temperature and humidity in the control of home appliances such as air conditioners, humidifiers and air purifiers. This system can provide higher quality service by analyzing and predicting user's characteristics through various machine learning and deep learning."
에너지저장장치 운전 계획을 위한 전력 사용량 패턴 분류 알고리즘,2019,"['Clustering', 'Energy Storage System', 'Load Pattern', 'Pattern Classification Labeling', 'Peak Shaving', 'Scheduling']",,"Prediction of electricity usage patterns plays an essential role in managing the usage efficiently. The prediction needs to be done sophisticatedly and accurately in order to operate energy storage system efficiently since the accuracy of prediction has a big effect on the storage operation plan. In recent years, machine learning-based solutions are being developed because regression analyses have limits when electricity usage has irregular patterns. As the accuracy of machine learning-based predictions depends on the quality and quantity of data to be learned, however, preprocessing process that classifies and labels the usage pattern is important. In this study, we suggest a PCL (Pattern Classification Labeling) algorithm to improve the machine learning-based prediction. It analyzes an actual load data to compare the PCL algorithm with K-means algorithm that has been used widely. In the result, PCL algorithm shows less error rate than K-means algorithm does by 12.2%."
LSTM 알고리즘을 활용한 전기 수요고객의 온라인 질문에 대한 토픽분류,2019,"['LDA', 'LSTM', 'Topic Modeling', 'Confusion Matrix', 'e-CRM']",,"In response to questions or complaints posted by customers on the company""s homepage, the response time is an important measure of customer satisfaction. However, the time it takes for a customer to receive an answer includes a time for the article to be selected by the person in charge of the reply, which limits the shortening. In this study, we developed a model in which a machine, not a person, reads the article, classifies the topic, and delivers it to each person in charge of the article. The article posted on the KEPCO homepage used in this study is a short sentence consisting of an average of 49 words. Due to the scarcity of multi-frequency words, it was found that there is a limit in securing a certain level of topic modeling accuracy in unsupervised machine learning like LDA. To overcome this, we labeled topics and let the machine conduct supervised learning. Although there are limitations in improving accuracy because there are articles containing more than two topics in one article, the classification accuracy is secured up to 84% by using LSTM and Baysian Optimization. The result of this study suggests that topic classification is possible for short-term customer questions in specific fields such as the electric power industry. In addition, it is expected that a model will be developed that can provide optimal reference answers for newly received questions when the topic-labeled questions and answers are fully accumulated."
고장예지 및 건전성관리에서의 AI 기법,2019,"['AI(Artificial Intelligence)', 'PHM', 'Model Based Approach', 'Data Driven Approach']",,"Purpose: Today, prognostics and health management (PHM) is being focused upon in the manufacturing, aerospace, and defense industries. This study aimed to identify the characteristics of diagnosis and PHM, and review the artificial intelligence (AI) techniques used for their implementation.Methods: PHM involves both diagnosis and prognostics, and AI is used for the diagnosis and PHM of a component or a system. There are two approaches to PHM: model-based and data- based approaches. The former involves a system of differential equations, an expert system, a finite state machine, and qualitative reasoning, while the latter involves conventional numerical methods such as linear regression and Kalman filtering, and machine learning methods such as those involving a neural network, a decision tree, or a support vector machine. We review some of these approaches in this paper.Results: The historical maintenance paradigm is presented along with the evolution of the production paradigm. Diagnosis and PHM are essential for the efficient maintenance of a system, and methods for each of them are briefly described.Conclusion: A proper understanding of diagnosis and PHM and their appropriate implementation are essential for the efficient maintenance of a system. Model-based and data-based approaches to PHM are briefly described. Both types of approaches have their merits and demerits and they should be tried out."
국내외 허위정보 연구동향 비교분석,2019,"['가짜정보', '연구 동향', '네트워크 분석', '키워드 네트워크', '연결중심성', '매개중심성', '집중도분석', 'Disinformation', 'Research Trends', 'Network Analysis', 'Keyword Network', 'Degree Centrality', 'Betweenness Centrality', 'Centralization']","본 연구의 목적은 국내외 허위정보에 관한 연구동향을 비교분석하는 것이다. 이를 위하여 전학문 분야의 학술지를 대상으로 연구기간의 제한이 없이 국내논문 104편과 국외논문 861편에 나타난 저자가 부여한 영문키워드를 수집하였다. 국내논문에서 수집된 283개 영문키워드와 국외논문에서 수집된 3,551개 영문키워드는 NetMiner V.4를 사용하여 키워드 네트워크의 연결중심성과 매개중심성을 분석하였으며, 분석결과는 다음과 같다. 첫째, 연구 주제의 양적 측면에서 국내의 경우는 ‘Freedom of Expression’, ‘Fact Check’, ‘Regulation’, ‘Media Literacy’, ‘Information Literacy’로 순으로, 국외의 경우는 ‘Social Media’, ‘Post Truth’, ‘Propaganda’, ‘Information Literacy’, ‘Journalism’ 순으로 나타났다. 둘째, 연구 주제의 영향력 측면에서 국내의 경우는 ‘Fact Check’, ‘Freedom of Expression’, ‘Hoax’ 순으로, 국외의 경우는 ‘Social Media’, ‘Detection’ 순으로 확인되었다. 마지막으로 연구 주제의 확장성 측면에서 국내의 경우는 ‘Fact Check’, ‘Polarization’, ‘Freedom of Expression’, ‘Commercial’ 순으로 나타났다. 한편, 전체키워드에서 낮은 빈도를 보였던 ‘Commercial’이 ‘Media Literacy’, ‘Freedom of Expression’ 등을 매개하며 상대적으로 매개역할정도가 큰 것으로 확인되었다. 국외의 경우는 ‘Social Media’, ‘Detection’, ‘Machine Learning’이 주요 연결다리로 나타났다.","The aim of the present study was to compare the research trends on disinformation between Korean and abroad. To achieve this objective, a total of 283 author-assigned English keywords in 104 Korean papers and 3,551 author-assigned English keywords in 861 abroad papers were collected from the whole research fields and the publication periods. The collected data were analyzed using NetMiner V.4 to discover their ‘degree centrality’ and ‘betweenness centrality’of the keyword network. The result are as follows. First, the major research topics of disinformation in Korea were drawn such as ‘Freedom of Expression’, ‘Fact Check’, ‘Regulation’, ‘Media Literacy’, and ‘Information Literacy’ in order; whereas, in abroad were shown like ‘Social Media’, ‘Post Truth’, ‘Propaganda’, ‘Information Literacy’, and ‘Journalism’ in order. Second, in terms of the influence of research topics related to disinformation, in Korea were identified such as ‘Fact Check’, ‘Freedom of Expression’, and ‘Hoax’ in order; whereas, in abroad were shown such as ‘Social Media’ and ‘Detection’ in order. Finally, in an aspect of intervention of research topics related to disinformation, in Korea were ‘Fact Check’, ‘Polarization’, ‘Freedom of Expression’, and ‘Commercial’; whereas, in abroad were ‘Social Media’, ‘Detection’, and ‘Machine Learning’ in order."
An Ensemble Cascading Extremely Randomized Trees Framework for Short-Term Traffic Flow Prediction,2019,"['Ensemble learning', 'extremely randomized trees', 'traffic flow prediction']",,"Short-term traffic flow prediction plays an important role in intelligent transportation systems (ITS) in areas such as transportation management, traffic control and guidance. For short-term traffic flow regression predictions, the main challenge stems from the non-stationary property of traffic flow data. In this paper, we design an ensemble cascading prediction framework based on extremely randomized trees (extra-trees) using a boosting technique called EET to predict the short-term traffic flow under non-stationary environments. Extra-trees is a tree-based ensemble method. It essentially consists of strongly randomizing both the attribute and cut-point choices while splitting a tree node. This mechanism reduces the variance of the model and is, therefore, more suitable for traffic flow regression prediction in non-stationary environments. Moreover, the extra-trees algorithm uses boosting ensemble technique averaging to improve the predictive accuracy and control overfitting. To the best of our knowledge, this is the first time that extra-trees have been used as fundamental building blocks in boosting committee machines. The proposed approach involves predicting 5 min in advance using real-time traffic flow data in the context of inherently considering temporal and spatial correlations. Experiments demonstrate that the proposed method achieves higher accuracy and lower variance and computational complexity when compared to the existing methods."
RGB-D 카메라와 시맨틱 분할 기법을 이용한작업자의 안전 모니터링,2019,"['deep learning', 'semantic segmentation', 'safety monitoring', 'autonomous mobile robots']",,"This paper suggests a deep learning-based algorithm for monitoring workers’ safety in a smart factory environment. With thegrowth of smart factories in industry, the need for an AMR (autonomous mobile robot) that self-drives in a production line is increasing.Although most AMRs are designed to actively prevent a collision, there should be another monitoring solution to double-check workers’safety because not all machines are reliable. We use an RGB-D camera which provides both depth information and RGB color informationand a semantic segmentation method to monitor workers’ safety. The semantic segmentation algorithm is called Mask R-CNN and is usedto detect workers and moveable equipment including AMRs. Since Mask R-CNN can specify an object’s boundary in RGB images, we areable to determine an object’s position in 3D coordinates by using the camera’s depth information. We can monitor the workers’ safety bychecking whether they are close to hazardous equipment. We experimented with an AMR and manufacturing equipment to verify oursuggested algorithm."
Classification of schizophrenia and normal controls using 3D convolutional neural network and outcome visualization,2019,"['Classification accuracy', 'Convolutional neural network', 'Support vector machine', 'Saliency map', 'Schizophrenia']",,"<P><B>Abstract</B></P>  <P><B>Background</B></P> <P>The recent deep learning-based studies on the classification of schizophrenia (SCZ) using MRI data rely on manual extraction of feature vector, which destroys the 3D structure of MRI data. In order to both identify SCZ and find relevant biomarkers, preserving the 3D structure in classification pipeline is critical.</P>   <P><B>Objectives</B></P> <P>The present study investigated whether the proposed 3D convolutional neural network (CNN) model produces higher accuracy compared to the support vector machine (SVM) and other 3D-CNN models in distinguishing individuals with SCZ spectrum disorders (SSDs) from healthy controls. We sought to construct saliency map using class saliency visualization (CSV) method.</P>   <P><B>Methods</B></P> <P>Task-based fMRI data were obtained from 103 patients with SSDs and 41 normal controls. To preserve spatial locality, we used 3D activation map as input for the 3D convolutional autoencoder (3D-CAE)-based CNN model. Data on 62 patients with SSDs were used for unsupervised pretraining with 3D-CAE. Data on the remaining 41 patients and 41 normal controls were processed for training and testing with CNN. The performance of our model was analyzed and compared with SVM and other 3D-CNN models. The learned CNN model was visualized using CSV method.</P>   <P><B>Results</B></P> <P>Using task-based fMRI data, our model achieved 84.15%∼84.43% classification accuracies, outperforming SVM and other 3D-CNN models. The inferior and middle temporal lobes were identified as key regions for classification.</P>   <P><B>Conclusions</B></P> <P>Our findings suggest that the proposed 3D-CAE-based CNN can classify patients with SSDs and controls with higher accuracy compared to other models. Visualization of salient regions provides important clinical information.</P>"
Convolutional Neural Network with Expert Knowledge for Hyperspectral Remote Sensing Imagery Classification,2019,"['Hyperspectral imagery classification', 'convolutional neural network', 'principal component analysis', 'gray-level co-occurrence matrix', 'differential Mathematical morphology']",,"The recent interest in artificial intelligence and machine learning has partly contributed to an interest in the use of such approaches for hyperspectral remote sensing (HRS) imagery classification, as evidenced by the increasing number of deep framework with deep convolutional neural networks (CNN) structures proposed in the literature. In these approaches, the assumption of obtaining high quality deep features by using CNN is not always easy and efficient because of the complex data distribution and the limited sample size. In this paper, conventional handcrafted learning-based multi features based on expert knowledge are introduced as the input of a special designed CNN to improve the pixel description and classification performance of HRS imagery. The introduction of these handcrafted features can reduce the complexity of the original HRS data and reduce the sample requirements by eliminating redundant information and improving the starting point of deep feature training. It also provides some concise and effective features that are not readily available from direct training with CNN. Evaluations using three public HRS datasets demonstrate the utility of our proposed method in HRS classification."
Cognitive Collaboration with a Corpus System in English Composition: A Sociocultural Perspective,2019,"['인지 협업', '코퍼스', '언어사용자', '사회문화이론', '매개', 'cognitive collaboration', 'corpus', 'language users', 'mediation', 'Sociocultural theory']",,"Collaboration between human language users and intelligent machines becomes increasingly pervasive. This collaboration signifies an enhanced level of cognitive cooperation between human users and machines. Drawing on Sociocultural theory developed by a Russian psychologist Lev Vygotsky, this paper reports on a scenario in which users and a corpus system, an electronic database of language, interact and work together. The observation suggests that the collaboration facilitates autonomous problem-solving and learning, both highly complex and cognitive mental capacities.The case further suggests that an efficient computational mediation is a key to designing an intelligent corpus system that understands the users’ needs and suggests an effective feedback based on their learning behavior."
Distinguishing elliptic fibrations with AI,2019,,,"<P><B>Abstract</B></P>  <P>We use the latest techniques in machine-learning to study whether from the landscape of Calabi-Yau manifolds one can distinguish elliptically fibred ones. Using the dataset of complete intersections in products of projective spaces (CICY3 and CICY4, totalling about a million manifolds) as a concrete playground, we find that a relatively simple neural network with forward-feeding multi-layers can very efficiently distinguish the elliptic fibrations, much more so than using the traditional methods of manipulating the defining equations. We cross-check with control cases to ensure that the AI is not randomly guessing and is indeed identifying an inherent structure. Our result should prove useful in F-theory and string model building as well as in pure algebraic geometry.</P>"
다양한 구성요소 조합으로 만든 딥뉴럴넷 모델 성능 비교,2019,"['딥뉴럴넷', '가중치 최적화', '활성화 함수', '정규화', '성능 비교.', 'deep neural network', 'optimizer', 'activation function', 'regularization', 'performance comparison.']","머신러닝 모델 중에 하나인 딥뉴럴넷 모델은 최근 월등한 성능을 보이며, 자율주행, 자연어 처리 등 다양한 분야에서 많이 연구되고 있다. 딥뉴럴넷 모델은 그 구성요소가 다양하기 때문에, 모델을 어떻게 구성하는지에 따라서 그 성능이 크게 달라진다. 본 연구에서는 딥뉴럴넷 모델의 구성 요소 5 가지 - 가중치 최적화, 활성화 함수, 드롭아웃, 정규화, 가중치 초기화 - 를 정하고, 5 가지 구성요소의 가능한 조합 48가지의 딥뉴럴넷 모델을 만들었다. 만든 모델들의 성능 평가를 위해서, 음식의 성분들을 가지고 20개의 나라 중 하나를 예측하는 Kaggle의 what's cooking 데이터를 활용하였다. 결과적으로, 적응모멘트추정(adaptive moment estimation, Adam) 최적화 기법, 정류선형단위(rectified linear unit, ReLU) 활성화 함수, 릿지(ridge) 정규화 미사용, 드롭아웃 사용, He 가중치 초기화라는 구성으로 딥뉴럴넷을 구성했을 때 가장 좋은 성능(정확도: 79.45%)을 보였다. 각 요소 별로 성능을 비교하였을 때에는, Adam 최적화 기법이 경사하강(gradient descent) 최적화 기법을 사용한 모델들 보다 평균적으로 56%정도의 성능이 좋은 것으로 나타났고, ReLU 활성화 함수가 시그모이드(sigmoid) 활성화 함수를 사용한 모델들 보다 평균적으로 약 3% 정도 성능이 좋은 것으로 나타났다. 이 연구의 결과가 더 성능 좋은 딥뉴럴넷 모델을 만드는데 기여할 수 있기를 기대한다.","In these days, deep neural networks (DNN) yield the most remarkable performance among machine-learning algorithms. Many researchers claim that the performance of DNN might be different according to its constituents. In this paper, we thoroughly analyze the performance of 48 DNNs that consist of various constituents in regard to the five factors, i.e. optimizer, activation function, dropout, regularization and weight initialization. What’s cooking data in Kaggle that contains ingredients of food and its nation are employed to train and test the 48 models. As a result, among the 48 DNNs, the DNN composed of Adam optimizer, ReLU activation function, He weight initialization, use of dropout, and no use of ridge regularization produce the best performance (accuracy: 79.45%) in predicting the nation based on food ingredients. The DNNs using Adam optimizer averagely show 56% higher accuracy than those using gradient descent optimizer, and the DNNs using ReLU activation function averagely show 3% higher accuracy than those using sigmoid activation function. We expect that the result of this study can assist to construct better performance DNN models."
인공지능 음성챗봇기반 초등학교 영어 말하기 수업 연구,2019,"['artificial intelligence', 'chatbot', 'speaking', 'elementary English education', 'learner perception']",,"The present study examined the potential of AI-based chatbot for elementary-level students’ English learning. To this end, the authors developed an AI-based chatbot named “Ellie” based on Dialogflow, which is powered by machine learning and natural language processing technology of Google. The participants were 177 5th and 6th grade elementary-level students in Seoul and Gwangju, South Korea. In groups, the participants were asked to perform two types of conversation tasks with Ellie. The participants were also given a survey, and a subset of the participants was interviewed in groups. The results showed that the participants managed to make successful conversation with Ellie to some extent by employing several types of conversation strategies. However, the participants experienced some difficulties due to various factors on the voice recognition of the chatbot and its lengthy utterances. Finally, the majority of the participants responded positively to the survey regarding the value of Ellie as a conversation partner for English speaking practice as well as those related to performing the assigned tasks with Ellie in group format."
실시간 범죄 모니터링을 위한 CCTV 협업 추적시스템 개발 연구,2019,"['Real-Time Crime Monitoring', 'CCTV Cooperative Tracking', 'Crime Prevention Service', 'Smart CCTV', 'Integrated Control System']","본 논문에서는 CCTV를 통해 실시간 범죄에 대응할 수 있도록 CCTV 카메라 간 협업이 가능한 기술과 이를 활용한 실시간 범죄대응 서비스에 대해 연구하였다. 본 연구에서 개발하고자 하는 CCTV 협업 기술은 한 곳의 CCTV에서 추출된 이동 객체(용의자)가 범위를 벗어나 다른 CCTV로 이동했을 때 객체의 유사도 정보를 관제자에게 전달하여 선택된 객체를 추적하는 프로그램 모델이다. 일련의 유사도 정보 획득 과정은 객체 감지(object detection), 사전 분류(pre-classification), 특징 추출(feature extraction), 분류(classification)의 4단계의 프로세스로 진행된다. 이는 주로 사후처리용으로 사용되던 CCTV 모니터링을 긴박한 실시간 범죄에 대응하도록 개선시켜 범죄발생 초기대응 체계를 강화 할 수 있다. 또한 관제요원의 모니터링에만 의존하는 CCTV 관제시스템을 부분 자동화하여 지자체 관제센터 운영 효율성을 증대시킬 수 있다. 해당 기술 및 서비스는 안양시 테스트베드에 구축하여 시범운영할 예정으로, 서비스가 안정화가 되면 전국 지자체에 확산하여 상용화가 될 것으로 예상된다. 향후 CCTV 협업 뿐 아니라 실시간 개인 정밀위치결정, 스마트폰 연계 등 통합 방범서비스 연구가 진행되어 시민들이 보다 안전한 생활을 영위할 수 있기를 기대한다.","Typically, closed-circuit television (CCTV) monitoring is mainly used for post-processes (i.e. to provide evidence after an incident has occurred), but by using a streaming video feed, machine-based learning, and advanced image recognition techniques, current technology can be extended to respond to crimes or reports of missing persons in real time. The multi-CCTV cooperation technique developed in this study is a program model that delivers similarity information about a suspect (or moving object) extracted via CCTV at one location and sent to a monitoring agent to track the selected suspect or object when he, she, or it moves out of range to another CCTV camera. To improve the operating efficiency of local government CCTV control centers, we describe here the partial automation of a CCTV control system that currently relies upon monitoring by human agents. We envisage an integrated crime prevention service, which incorporates the cooperative CCTV network suggested in this study and that can easily be experienced by citizens in ways such as determining a precise individual location in real time and providing a crime prevention service linked to smartphones and/or crime prevention/safety information."
비즈니스 이메일 영작문에 나타난 학습자의 단어사용 오류,2019,"['영작문쓰기', '오류분석', '비즈니스 이메일영작문', '영작문단어사용', 'Business Email Writing', 'Error Analysis']","본 연구는 번역기를 활용한 비즈니스 이메일 영작문 수업에서 대학생들이 작성한 영작문에 나타난 단어사용 오류를 분석하고 설명하고자 하는 연구이다. 연구는 취업실무영어 수업을 수강한 7명의 대학생들이 3가지 과제에 대해 작성한 21개 이메일을 분석하여 이에 나타난 오류를 분석하였다. 연구결과 어색한 의미의 단어를 사용한 오류는 동사, 명사 형용사 순으로 빈번하게 나타났으며, 내용상으로는 수식어 사용이나 구체적인 표현기술에 부족한 경우도 빈번하게 나타나 학습자의 어휘실력이 부족해서 의도한대로 글을 구체적이고 자세하게 기술하지 못하고 있는 것으로 나타났다. 한편 불필요한 단어나 구를 삽입하여 논리적인 글의 전개에 모순을 보이는 경우도 있었다. 이러한 오류분석을 통하여 영어를 학습하고 있는 학습자가 어색한 의미의 동사를 사용하고 있고 어휘력이 부족해서 번역기를 사용함에도 불구하고 어려움을 겪고 있다는 결과를 보여줌으로 앞으로의 영어 쓰기교육의 연구와 교육에 방향성을 제시할 수 있을 것으로 본다.","This study aimed at providing a comprehensive account of the sources and causes of errors in business emails that Korean college students wrote using a translation machine. Data were collected from 21 emails written by the students taking a business English course. Findings showed that the students tended to make frequent errors in awkward verb use, one of substitution errors. Among awkward words, verb, noun, adjective errors appear in order by frequency. Considering meaning of the texts, students could not use enough modifier such as ajectives, ajective phrases, ajective clauses, and prepositional phrases, which fails to describe their ideas and thoughts more delicately. Also, they demonstrate they had difficulties describing in details due to their lack of vocaburary. Therefore, the study suggested that the students’ common errors imply that they experience some difficulties learning specific lexical meaning. Given that learners’ errors can give us valuable insights into teaching and learning how to write in English, pedagogical suggestions are put forward based on the study results. (Seowon University)"
국어교육과 『국어』 교과의 미래,2019,"['국어교육의 미래', '2022 교육과정', '평생학습', '언어적 특이점', '문제 해결 역량', '협업 역량', '메타 역량', 'Future of Korean Language Education', '2022 National Curriculum', 'Lifelong Learning', 'Linguistic Singularity', 'Problem Solving Competence', 'Collaboration Competence', 'Meta Competence']",,"The 2015 Revised National Curriculum was announced 120 years after the establishment of the Hansung Normal School and 60 years after the implementation of the First National Curriculum. This revised curriculum, however, remains as an extension of the Seventh Curriculum which represented 20th century education. The forthcoming 2022 National Curriculum should serve as a starting point for Korean language education to go beyond the boundaries of modern education and move towards the post-modern era. With respect to this, the paper examines pressing matters regarding the future of Korean language education, Korean as a school subject, and specific parts of the national curriculum revision process that must be addressed.The future of Korean language education entails technological, social, linguistic, and educational changes to bring about Linguistic Singularity. It must focus on developing cognitive, emotional, and social problem-solving skills; collaborative skills with humans and machines; and meta-capabilities from the perspective of lifelong learning. To achieve this, the Korean subject should be reorganized to prioritize the development of grade 1 to 12 students while taking into consideration the systematic nature of elective subjects. Likewise, we should set goals for our educational system, produce content that is adapted to the changing needs of society, and further improve our teaching-learning materials and evaluation to keep pace with developments in the educational and language environment. Rather than the conventional academic system of Korean language education, we need a “bumpy curriculum” that takes every necessary and possible condition into account and puts the needs of individuals, society, and the nation first."
Traffic Seasonality aware Threshold Adjustment for Effective Source-side DoS Attack Detection,2019,"['DoS attack', 'DoS detection', 'source-side detection', 'adaptive threshold', 'traffic seasonality']",,"In order to detect Denial of Service (DoS) attacks, victim-side detection methods are used popularly such as static threshold-based method and machine learning-based method. However, as DoS attacking methods become more sophisticated, these methods reveal some natural disadvantages such as the late detection and the difficulty of tracing back attackers. Recently, in order to mitigate these drawbacks, source-side DoS detection methods have been researched. But, the source-side DoS detection methods have limitations if the volume of attack traffic is relatively very small and it is blended into legitimate traffic. Especially, with the subtle attack traffic, DoS detection methods may suffer from high false positive, considering legitimate traffic as attack traffic. In this paper, we propose an effective source-side DoS detection method with traffic seasonality aware adaptive threshold. The threshold of detecting DoS attack is adjusted adaptively to the fluctuated legitimate traffic in order to detect subtle attack traffic. Moreover, by understanding the seasonality of legitimate traffic, the threshold can be updated more carefully even though subtle attack happens and it helps to achieve low false positive. The extensive evaluation with the real traffic logs presents that the proposed method achieves very high detection rate over 90% with low false positive rate down to 5%."
왕립학회에 관한 논쟁을 통해서 본 17세기 후반 잉글랜드에서의 과학과 종교의 관계,2019,"['왕립학회', '과학과 종교', '토마스 스프랫', '조셉 글랜빌', '메릭 카소본', '헨리 스텁', 'Royal Society', 'science and religion', 'Thomas Sprat', 'Joseph Glanvill', 'Meric Casaubon', 'Henry Stubb']",,"This paper examines the debate over the Royal Society established in England in 1660. The Royal Society did not enquire into metaphysical problems, but explored the perceptible natural world and sought to develop useful skills and machines. The fellows of the Royal Society believed that their works would illustrate God’s power and wisdom and prove beneficial to their society. However, the critics of the Royal Society thought that the new philosophy supported by the society would destroy the existing system of learning and the Christian faith. This controversy shows that there were disagreements among the people of the day over the relationship between religion and natural science.The Royal Society did not discuss religious issues and accepted as fellows those who were interested in scientific researches regardless of their religious denomination. This militates against a close connection between the scientific exploration of the Royal Society and any certain denomination. The critics were worried that the new philosophy focusing on the material objects would undermine the traditional metaphysics which had been propping up the Christian faith. Thus, to fully understand the attitude of the contemporaries towards natural philosophy, we might also need to take their views of the traditional learning into consideration."
A Text Mining Analysis of US-Chinese Leaders on Trade Policy,2019,"['Official speeches', 'Text mining', 'TF-IDF', 'Topic analysis', 'Word hierarchy analysis', 'Trade']",,"Using the methodologies of text mining, this paper examines the implications of US and Chinese policies on bilateral trade. Official speeches by political leaders of the U.S. and China on the issues of trade were collected and analytically examined for US-China gaps in major foreign policies, such as bilateral trade and the Belt and Road Initiative. In this paper, a term frequency-inverse document frequency word cloud, a network similarities index, machine learning-processed latent Dirichlet allocation (LDA), and structural equivalence are applied to examine the meanings of the speeches. The main arguments in this paper are as follows. First, the document similarity between the speeches of Chinese and US leaders appears to be completely different. Also, while the documents from Chinese leaders are considerably similar, the documents from US leaders differ by far. Secondly, LDA topic analysis indicates that China concentrates more on international and collaborative relationships, while the U.S. has more focus on domestic and economic interests. Third, from a word hierarchy analysis, the basic words used by American and Chinese leaders are also completely different. Agriculture, farmers, automobiles, and negotiations are the basic words for American leaders, but for Chinese leaders, the basic words are planning, markets, and education."
Improving methods for normalizing biomedical text entities with concepts from an ontology with (almost) no training data at BLAH5 the CONTES,2019,"['biomedical text mining', 'entity normalization', 'ontology', 'word embedding']",,"Entity normalization, or entity linking in the general domain, is an information extraction task that aims to annotate/bind multiple words/expressions in raw text with semantic references, such as concepts of an ontology. An ontology consists minimally of a formally organized vocabulary or hierarchy of terms, which captures knowledge of a domain. Presently, machine-learning methods, often coupled with distributional representations, achieve good performance. However, these require large training datasets, which are not always available, especially for tasks in specialized domains. CONTES (CONcept-TErm System) is a supervised method that addresses entity normalization with ontology concepts using small training datasets. CONTES has some limitations, such as it does not scale well with very large ontologies, it tends to overgeneralize predictions, and it lacks valid representations for the out-of-vocabulary words. Here, we propose to assess different methods to reduce the dimensionality in the representation of the ontology. We also propose to calibrate parameters in order to make the predictions more accurate, and to address the problem of out-of-vocabulary words, with a specific method."
사용자 니즈 기반의 챗봇 개발 프로세스: 디자인 사고방법론을 중심으로,2019,,"최근, 기업 및 공공기관에서는 고객 상담과 응대 분야에 챗봇(Chatbot)서비스를 적극적으로 도입하고 있다.챗봇 서비스의 도입은 기업이나 기관에게 있어서 인건비 절감 효과를 가져올 뿐만 아니라 고객과의 빠른 커뮤니케이션 효과를 기대할 수 있다. 데이터 분석 기술의 발전과 인공지능 기술의 고도화는 이런 챗봇 서비스의성장을 견인하고 있다. 하지만 기술중심으로 개발된 챗봇은 사용자가 내재적으로 원하는 바와 괴리가 있을 수있으므로, 챗봇이 단순히 기술의 영역이 아닌 사용자 경험의 영역에서 다루어질 필요가 있다. 본 연구는 사용자경험 분야의 대표적 방법론인 디자인 사고 접근법을 챗봇 개발에 적용하여, 사용자 니즈 기반의 챗봇 개발 프로세스를 제안하고자 한다. 사용자 관찰을 통해 팩트(Fact) 수집을 시작으로, 인사이트(Insight)를 도출하고 기회영역(Opportunity)을 발굴하는 추상화의 과정을 수행한다. 이어서 사용자의 멘탈모델에 맞는 기능을 제공하고원하는 정보를 구조화하는 구체화의 과정을 통해, 사용자의 니즈에 부합하는 챗봇을 개발할 수 있을 것으로 기대한다. 본 연구에서는 제안한 프로세스의 실효성을 확인하기 위하여 국내 화장품 시장을 대상으로 실제 구축사례를 함께 제시한다. 본 연구는 챗봇 개발 프로세스에 사용자 경험을 접목한 점에서 이론적 시사점을 가지며, 기업이나 기관이 바로 적용 가능한 현실적인 방법을 제안한다는 면에서 실무적 시사점을 가진다.","Recently, companies and public institutions have been actively introducing chatbot services in the field of customer counseling and response. The introduction of the chatbot service not only brings labor cost savings to companies and organizations, but also enables rapid communication with customers.Advances in data analytics and artificial intelligence are driving the growth of these chatbot services. The current chatbot can understand users’ questions and offer the most appropriate answers to questions through machine learning and deep learning. The advancement of chatbot core technologies such as NLP, NLU, and NLG has made it possible to understand words, understand paragraphs, understand meanings, and understand emotions. For this reason, the value of chatbots continues to rise.However, technology-oriented chatbots can be inconsistent with what users want inherently, so chatbots need to be addressed in the area of the user experience, not just in the area of technology. The Fourth Industrial Revolution represents the importance of the User Experience as well as the advancement of artificial intelligence, big data, cloud, and IoT technologies. The development of IT technology and the importance of user experience have provided people with a variety of environments and changed lifestyles.This means that experiences in interactions with people, services(products) and the environment become very important. Therefore, it is time to develop a user needs-based services(products) that can provide new experiences and values to people.This study proposes a chatbot development process based on user needs by applying the design thinking approach, a representative methodology in the field of user experience, to chatbot development.The process proposed in this study consists of four steps. The first step is ‘setting up knowledge domain’ to set up the chatbot's expertise. Accumulating the information corresponding to the configured domain and deriving the insight is the second step, 'Knowledge accumulation and Insight identification'. The third step is ‘Opportunity Development and Prototyping’. It is going to start full-scale development at this stage.Finally, the ‘User Feedback’ step is to receive feedback from users on the developed prototype. This creates a ""user needs-based service (product)"" that meets the process’s objectives.Beginning with the fact gathering through user observation, Perform the process of abstraction to derive insights and explore opportunities. Next, it is expected to develop a chatbot that meets the user's needs through the process of materializing to structure the desired information and providing the function that fits the user's mental model.In this study, we present the actual construction examples for the domestic cosmetics market to confirm the effectiveness of the proposed process. The reason why it chose the domestic cosmetics market as its case is because it shows strong characteristics of users' experiences, so it can quickly understand responses from users.This study has a theoretical implication in that it proposed a new chatbot development process by incorporating the design thinking methodology into the chatbot development process. This research is different from the existing chatbot development research in that it focuses on user experience, not technology. It also has practical implications in that companies or institutions propose realistic methods that can be applied immediately. In particular, the process proposed in this study can be accessed and utilized by anyone, since 'user needs-based chatbots' can be developed even if they are not experts.This study suggests that further studies are needed because only one field of study was conducted.In addition to the cosmetics market, additional research should be conducted in various fields in which the user experience appears, such as the smart phone and the automotive market. Through this, it will be able..."
Improving methods for normalizing biomedical text entities with concepts from an ontology with (almost) no training data at BLAH5 the CONTES,2019,"['biomedical text mining', 'entity normalization', 'ontology', 'word embedding']",,"Entity normalization, or entity linking in the general domain, is an information extraction task that aims to annotate/bind multiple words/expressions in raw text with semantic references, such as concepts of an ontology. An ontology consists minimally of a formally organized vocabulary or hierarchy of terms, which captures knowledge of a domain. Presently, machine-learning methods, often coupled with distributional representations, achieve good performance. However, these require large training datasets, which are not always available, especially for tasks in specialized domains. CONTES (CONcept-TErm System) is a supervised method that addresses entity normalization with ontology concepts using small training datasets. CONTES has some limitations, such as it does not scale well with very large ontologies, it tends to overgeneralize predictions, and it lacks valid representations for the out-of-vocabulary words. Here, we propose to assess different methods to reduce the dimensionality in the representation of the ontology. We also propose to calibrate parameters in order to make the predictions more accurate, and to address the problem of out-of-vocabulary words, with a specific method."
상품 추천 기법의 성능평가 분석,2019,"['Product Recommendation Technique', 'Accuracy', 'Recall', 'F1 Measure', 'Top-k']",,"In the vast product information of the e-commerce, the user needs a lot of effort to find the required product, and the seller may affect the sales if the product is not provided quickly to the user. Accordingly, the e-commerce company provides a recommendation service based on the user's past purchase information so that the user can provide a product required by the user. The recommendation techniques for providing recommendation services include a collaborative filtering recommendation technique that derives recommendation information through a relationship between users or products and a recommendation technique that utilizes a deep learning technology based on machine learning. In this paper, we study user-based collaborative filtering recommendation and item-based collaborative filtering recommendation as collaborative filtering recommendation techniques, and RNN, LSTM, and Word2Vec recommendation techniques as deep recommendation techniques. In this paper, we evaluate the recommendation performance based on the e-commerce purchase information for these recommendation techniques. As a metric for evaluating the recommendation performance, it analyzes the recommendation performance using accuracy, recall, and F1 measure. The results of the validation of the recommendation performance showed that the LSTM recommendation technique had the best recommendation performance, and that the recommendation performance was the best when the number of recommendations was Top-10. Based on the recommended performance evaluation procedure and evaluation results proposed in this study, it can be referred to when analyzing the performance of recommendations in various fields."
IoT based real time agriculture farming,2019,"['Agriculture', 'IoT', 'Sensors', 'Smart Farming', 'Raspberry Pi3']",,"The Internet of things (IOT) is remodeling the agribusiness empowering the agriculturists through the extensive range of strategies, for example, accuracy as well as practical farming to deal with challenges in the field. The paper aims making use of evolving technology i.e. IoT and smart agriculture using automation. The objective of this research paper to present tools and best practices for understanding the role of information and communication technologies in agriculture sector, motivate and make the illiterate farmers to understand the best insights given by the big data analytics using machine learning. The methodology used in this system can monitor the humidity, moisture level and can even detect motions. According to the data received from all the sensors the water pump, cutter and sprayer get automatically activated or deactivated. we investigate a remote monitoring system using Wi-Fi. These nodes send data wirelessly to a central server, which collects the data, stores it and will allow it to be analyzed then displayed as needed and can also be sent to the client mobile."
Motion Sickness Prediction in Stereoscopic Videos using 3D Convolutional Neural Networks,2019,,,"<P>In this paper, we propose a three-dimensional (3D) convolutional neural network (CNN)-based method for predicting the degree of motion sickness induced by a 360° stereoscopic video. We consider the user's eye movement as a new feature, in addition to the motion velocity and depth features of a video used in previous work. For this purpose, we use saliency, optical flow, and disparity maps of an input video, which represent eye movement, velocity, and depth, respectively, as the input of the 3D CNN. To train our machine-learning model, we extend the dataset established in the previous work using two data augmentation techniques: frame shifting and pixel shifting. Consequently, our model can predict the degree of motion sickness more precisely than the previous method, and the results have a more similar correlation to the distribution of ground-truth sickness.</P>"
4차 산업 시대 교육환경 변화에 따른 독서교육의 모색,2019,"['리터러시 교육', '중등독서교육', '고등독서교육', '4차 산업', '독서교육', '대학교육', '교양교육', 'MOOC', 'MOOC(Massive Open Online Course)', 'Minerva School', 'Reading Education', 'Literacy', 'Education in the Era of the Fourth Industrial Revolution']","MOOC(Massive Open Online Course)와 같은 새로운 교육 플랫폼, ‘미네르바 스쿨’과 같은 캠퍼스 없는 대학의 등장은 고등교육의 변화방향을 강력하게 시사한다. ‘대학의 미래’라고까지 평가받는 MOOC는 누구나 접속할 수 있을 뿐 아니라 언제 어디서나 닿을 수 있다는 점에서 교육의 패러다임을 바꾸었다. ‘미디어가 곧 메시지’임을 상기하면, 대학이 ‘분과지식의 전달’이라는 내용에 열중한 사이 대학이라는 미디어를 대체할 새로운 지식 유통 미디어가 등장한 것이다.4차 산업 시대의 문제를 완전히 예측할 수는 없지만, ‘학습자’가 전통적 의미의 ‘교수자’ 없이 학습할 수 있는 환경이 조성되는 것만은 분명하다. 우리의 고등교육도 ‘상아탑’이라는 전통적 인식에서 벗어나 학습자의 특성 변화와 요구 변화에 보다 민감할 필요가 있다.또한 각종 1인 미디어가 등장하고 다양한 형태의 콘텐츠가 쏟아져 나오는 등 리터러시 환경이 급속히 변하고 있다는 사실에 주목해야 한다. 새로 등장한 미디어는 사적 공간과 공적 공간 구별이 모호하여 갈등을 일으키거나, 유통 가능한 정보의 한계에 대한 생각이 저마다 달라 혼란을 초래하기도 한다. 새로운 미디어가 새로운 구조를 낳고 필연적으로 갈등을 불러온 것이다. 이러한 갈등은 이제 개인과 개인의 관계를 넘어 개인과 기계, 기계와 기계의 소통과 갈등으로 확산될 수밖에 없다. 따라서 지식의 학습 보다는 협력과 소통을 통한 갈등의 해결, 아이디어 생성을 위한 교육․훈련이 필요한 시점이다.이 논문은 학제적 지식의 함양뿐만 아니라 변화하는 리터러시 역량을 향상시킬 수 있는 독서교육에 주목하였다. 지식의 생존주기가 짧아져 평생학습이 시작되는 4차 산업시대, 경험의 축적을 통한 갈등조정과 공감 능력을 얻기 위한 방편으로 독서교육은 적절할 뿐 아니라 꼭 필요하다. 그리고 리터러시 역량의 단계적, 효과적 실행을 위해, 중등독서교육과 고등독서교육은 구별되면서도 연결된 교육이 될 필요가 있다.","The appearance of new educational platforms such as MOOCs(Massive Open Online Courses) and universities without campuses such as ‘Minerva School’ make strong implications for directions of change for higher education. MOOC, which is being evaluated as being ‘the future of college’, can be accessed by anyone, anywhere, at any time and because of this, it has changed the paradigm of education. If we recall that ‘the media is the message’, while universities focused on ‘the transfer of branched knowledge’, a new knowledge distribution media form that can replace universities appeared.While problems of the Fourth Industrial Revolution cannot completely be predicted, it is clear that environments have been created in which ‘learners’ can learn without ‘teachers’ as defined by their traditional meaning’. Our higher education should also break away from its traditional perceptions as an ‘ivory tower’ and be more sensitive to changes in the characteristics and demands of learners.Also, with the appearance of all sorts of personal media and various content forms, attention should be given to the fact that literacy environments are rapidly changing. Distinctions between personal spaces and public spaces are vague in newly appearing media, causing conflict or confusion because thoughts on the limitations of distributable information are different. New media bears new structures and inevitably causes conflict. This kind of conflict now transcends relationships among individuals and inevitably spreads to communication and conflict between individuals and machines and among machines. Therefore, education and training are needed for the resolution of conflict through cooperation and communication along with the creation of ideas. For this, there should be a series of processes that look into secondary education and design higher education.This thesis not only focused on the cultivation of interdisciplinary knowledge but on reading education that can improve changing literacy capacities. During the Fourth Industrial Revolution, in which the life span of knowledge has shortened and lifelong learning has begun, for reading education conducted to gain empathic abilities and for conflict resolution through the accumulation of experience to be effectively and gradually implemented, secondary and higher education should be distinct from each other but connected."
인간과 인공지능 로봇 캐릭터의 비교 연구-너도 인간이니? 기반으로,2019,"['인공지능', '인공지능 캐릭터', '동작 추출', '에니어그램', '성격 특성', 'Artificial intelligence', 'Artificial intelligence characters', 'Motion extraction', 'Behavioral Features', 'Enneagram', 'Personality characteristics']",제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터들의 역할을 수행해오고 있다. 이러한 인공지능의 등장은 과학기술의 발전과 동시에 영화나 드라마를 이끌 수 있는 하나의 중요한 소재로 사용된다. 이에 본 논문에서는 국내 드라마에서 한 인물이 인공지능 로봇 캐릭터와 인간 캐릭터를 연기한 내용을 기반으로 비교 분석하고자 한다. 특히 각 캐릭터의 외모를 기반으로 등장인물의 장면을 추출한 후 행동분석을 통해 캐릭터들의 성격과 행동 특징들을 분석한다. 이렇게 분석된 결과는 향후 다양한 캐릭터들을 체계적으로 분석하기 위한 기반 연구로 사용될 예정이다. 또한 캐릭터들의 동작들을 DB화하여 머신러닝 또는 딥러닝을 통해 효율적인 인물 행동 및 성격 분석이 가능한 시스템 구축에 활용하고자 한다.,"With the advent of the Fourth Industrial Revolution, artificial intelligence robots have been playing different characters of role in various movies and dramas. The emergence of such artificial intelligence will be used as an important material that can lead a movie or drama at the same time as the development of science and technology. In this paper, we would like to make a comparative analysis based on the story of a person playing an artificial intelligence robot character and a human character in a domestic drama. In particular, after extracting characters"" scenes based on the appearance of each character, analyze characters"" personality and behavior characteristics through behavioral analysis. The result of this analysis will be used as a base study to systematically analyze various characters in the future. Also, we want to database the actions of characters and use them as a system that enables efficient character behavior and character analysis through machine learning or deep learning."
한국의 계층의식 결정 요인: 탐색적 데이터분석,2019,"['subjective class identification', 'exploratory data analysis', 'random forest', 'ordered logit model', '계층의식', '탐색적 데이터분석', '랜덤 포레스트', '순서형 로짓 분석']","본 연구는 한국 사회의 주관적 계층의식에 어떤 요인들이 중요한 영향을 미치는지 탐색적 접근 방식으로 분석한다. 이에 관한 많은 선행 연구들과 달리 우리는 특정 이론이나 선험적 판단에 근거하지 않고 이용가능한 모든 변수들을 사용하여 탐색적 데이터분석 방법론을 사용하여 계층의식에 영향을 미치는 주요 변수들을 찾아낸 다음, 회귀분석을 통해 구체적 관련성을 규명한다. 통계청의 2017년 사회분석 데이터를 사용하며, 총 70개 전후의 변수에서 출발하여 머신러닝의 랜덤 포레스트 기법을 사용하여 주요 설명변수들을 추출한 다음, 회귀분석을 통해 계수의 부호와 통계적 유의성을 검토한다. 분석 결과, 계층의식은 소득이나 소비 등 어느 특정 부문의 특정 요소에 의해서만 결정되는 것이 아니라 사회 제반 분야 다양한 변수들의 영향을 받는 것으로 나타났다.","In this exploratory study, we analyze factors that affect individuals’ subjective class identification in Korea. While the majority of previous studies are based on a specific theory or a priori judgment, our approach is different: we begin with utilizing all available variables. First, we have employed the exploratory data analysis (EDA) to find out all possible variables that affect individuals’ subjective class identification. And then, a specific relationship is identified through the regression analysis. Using the 2017 Social Survey data provided by Statistics Korea, we extract the main explanatory variables from a total of about 70 variables using a random forest method of machine learning. The regression analysis is then used to examine the sign and statistical significance of the coefficients. The results suggest that individuals’ subjective class identification is influenced not only by certain factors, such as income or consumption but also by other various aspects existing in the social context."
휠체어 탄 인공지능: 자율적 기술에서 상호의존과 돌봄의 기술로,2019,"['Artificial Intelligence', 'Cultural imaginary', 'Matter of care', 'Autonomy', 'mediation and dependence', 'Care work', 'Disability', 'Artificial Intelligence in wheelchair', '인공지능', '문화적 상상', '돌봄물', '자율성', '매개와 의존', '돌봄노동', '장애', '휠체어 탄 인공지능']","이 글은 인공지능이 만들어내는 문화적 상상을 분석하면서 기술과 인간 사이의 새로운윤리를 모색한다. 과학기술을 돌봄물(matter of care)로 이해하는 페미니스트 과학기술학연구(Puig de la Bellacas, 2011)에 기댄 이 글은 우선 인공지능이 자율성을 문화적 상상으로강력하게 생산하고 있다는 점에 주목한다. 스스로의 경험과 학습을 통해 새로운 환경에적응할 수 있는 능력으로 정의된 이 자율성은 기술적 영역을 넘어 이상적인 인간상을 정의하고 있다. 하지만 데이터에 기반한 딥러닝 기법과 무장한 무인 비행기가 예증하듯, 인공지능 기술은 보이지 않는 인간노동과 복잡한 물질적 장치에 의존하고 있으며, 자율성은허구에 가깝다. 또한 이른바 ‘조수 기술 (assistant technology)’이 보여주듯, 가사노동을부불노동화하는 우리 사회의 오래된 젠더화된 노동인식에 기초해 수많은 인간의 돌봄노동은 비가시화되는 반면, 기계의 돌봄노동은 적극적으로 가시화되고 있다. 또한 인공지능의문화적 상상은 자율성과 행위능력을 이상적인 인간의 특질로 정의하면서 장애의 몸과 이몸이 갖는 가치인 연약함과 의존성의 연대는 가치 없는 것으로 만들고 있다. 인공지능과그 문화적 상상은 능력이 있는 몸(abled-bodies)을 이상화하고 기술의 자율성을 우선 가치로삼으면서 서로 의존하는 인간과 기술의 현실적 관계를 삭제하고 있다. 결론에서 저자는우리에게 필요한 기술은 타자의 비정형적인 몸과 인간의 돌봄노동을 가치 없게 여기도록하는 것이 아니라 이들을 있는 그대로 드러내면서 그 가치를 인정하는 것이어야 한다고주장한다. 책임 있게 응답하는 기술은 주변화된 존재들에 공감하고 의존성을 긍정하고연약성 사이의 연대를 촉진하는 것이어야 한다. 저자는 이런 대안적인 기술을 형상화하기위해 예술가 수 오스틴의 퍼포먼스에서 영감을 얻어 ‘휠체어 탄 인공지능’을 제안한다. ‘휠체어 탄 인공지능’은 자율성을 과시하기보다는 타자의 몸과 노동을 부정하지 않고 이들의존재론적 가능성을 함께 만들어가려 노력하는 상호의존과 돌봄의 기술이다.","This article seeks to explore new relationships and ethics of human and technology by analyzing a cultural imaginary produced by artificial intelligence. Drawing on theoretical reflections of the Feminist Scientific and Technological Studies which understand science and technology as the matter of care(Puig de la Bellacas, 2011), this paper focuses on the fact that artificial intelligence and robots materialize cultural imaginary such as autonomy. This autonomy, defined as the capacity to adapt to a new environment through self-learning, is accepted as a way to conceptualize an authentic human or an ideal subject. However, this article argues that artificial intelligence is mediated by and dependent on invisible human labor and complex material devices, suggesting that such autonomy is close to fiction. The recent growth of the so-called 'assistant technology' shows that it is differentially visualizing the care work of both machines and humans.Technology and its cultural imaginary hide the care work of human workers and actively visualize the one of the machine. And they make autonomy and agency ideal humanness, leaving disabled bodies and dependency as unworthy. Artificial intelligence and its cultural imaginary negate the value of disabled bodies while idealizing abled-bodies, and result in eliminating the real relationship between man and technology as mutually dependent beings. In conclusion, the author argues that the technology we need is not the one to exclude the non-typical bodies and care work of others, but the one to include them as they are. This technology responsibly empathizes marginalized beings and encourages solidarity between fragile beings. Inspired by an art performance of artist Sue Austin, the author finally comes up with and suggests 'artificial intelligence in wheelchair' as an alternative figuration for the currently dominant 'autonomous artificial intelligence'."
IoT based real time agriculture farming,2019,"['Agriculture', 'IoT', 'Sensors', 'Smart Farming', 'Raspberry Pi3']",,"The Internet of things (IOT) is remodeling the agribusiness empowering the agriculturists through the extensive range of strategies, for example, accuracy as well as practical farming to deal with challenges in the field. The paper aims making use of evolving technology i.e. IoT and smart agriculture using automation. The objective of this research paper to present tools and best practices for understanding the role of information and communication technologies in agriculture sector, motivate and make the illiterate farmers to understand the best insights given by the big data analytics using machine learning. The methodology used in this system can monitor the humidity, moisture level and can even detect motions. According to the data received from all the sensors the water pump, cutter and sprayer get automatically activated or deactivated. we investigate a remote monitoring system using Wi-Fi. These nodes send data wirelessly to a central server, which collects the data, stores it and will allow it to be analyzed then displayed as needed and can also be sent to the client mobile."
비실험 자료로부터의 인과 추론: 핵심 개념과 최근 동향,2019,"['인과 추론', '평균 처치 효과', '개별 처치 효과', '성향 점수', '구조적 인과 모형', 'causal inference', 'average treatment effect', 'conditional treatment effect', 'propensity score', 'structural causal model']","과학적 연구에서 핵심적인 연구 주제 또는 가설은 대부분 인과적 질문(causal question)을 포함한다. 예를 들어, 전염병 예방을 위한 치료법의 효과 연구, 특정 정책의 시행으로 인한 효용(utility)의 평가에 대한 연구, 특정 사용자를 대상으로 노출된 광고의 종류에 따른 광고의 효과성에 대한 연구는 모두인과 관계(causal relationship)의 추론이 요구된다. 이러한 인과 관계를 다루는 통계적 인과 추론(statistical causal inference)의 주요 관심사 중 하나는 모집단에 일종의 개입(정책 혹은 처치)을 적용한 후 개입의 효과를 정확하게 추정하는 것이다. 인과 추론은 임상실험과 정책결정에서 주로 이용되었으나, 이른바 빅데이터 시대의 도래로 가용한 관측자료가 폭발적으로 증가하였고 이로 인하여 인과 추론에 대한 잠재적 응용가치와 수요가 지속적으로 증가하고 있다. 하지만 가용한 대부분의 자료는 임의실험 기반의 자료와 달리 개입이 임의로 분배되지 않은 비실험 관측자료이다. 따라서, 본 논문은 비실험 관측자료로부터 개입의 효과를 추정하기 위한 인과 추론의 핵심 개념과 최근의 연구동향을 소개하고자 한다. 이를 위하여 본문에서는 먼저 개입의 효과를 Neyman-Rubin의 잠재 결과(potential outcome) 모형으로 나타내고, 개입의 효과를 추정하는 여러 접근법 중 특히 성향점수(propensity score) 기반 추정법과 회귀모형 기반 추정법을 중점적으로 소개한다. 최근 연구동향으로는 (1) 평균 효과 크기 추정을 넘어선 개인별 효과 크기의 추정, (2) 효과크기 추정에 있어서 자료 규모의 증대로 인한 차원의 저주가 야기하는 난제들과 이에 대한 해결방안들, (3) 복합적 인과관계를 반영하기 위한 Pearl의 구조적 인과 모형(structural causal model) 및 잠재 결과 모형과의 비교의 3가지 주제로 구분하여소개한다.","Causal questions are prevalent in scientific research, for example, how effective a treatment was for preventing an infectious disease, how much a policy increased utility, or which advertisement would give the highest click rate for a given customer.Causal inference theory in statistics interprets those questions as inferring the effect of a given intervention (treatment or policy) in the data generating process.Causal inference has been used in medicine, public health, and economics; in addition, it has received recent attention as a tool for data-driven decision making processes.Many recent datasets are observational, rather than experimental, which makes the causal inference theory more complex.This review introduces key concepts and recent trends of statistical causal inference in observational studies.We first introduce the Neyman-Rubin's potential outcome framework to formularize from causal questions to average treatment effects as well as discuss popular methods to estimate treatment effects such as propensity score approaches and regression approaches.For recent trends, we briefly discuss (1) conditional (heterogeneous) treatment effects and machine learning-based approaches, (2) curse of dimensionality on the estimation of treatment effect and its remedies, and (3) Pearl's structural causal model to deal with more complex causal relationships and its connection to the Neyman-Rubin's potential outcome model."
건물 가스에너지소비에 따른 여과성 및 응축성 먼지배출량 예측과 사례분석 연구,2019,"['Gas consumption', 'Filterable particulate matter', 'Condensable particulate matter', 'Dust emission prediction', 'Artificial neural network']",,"The TSP, PM10, PM2.5, which is calculated by NIER(National institute of environmental research)’s clean air policy support system(CAPSS), targets only filterable particulate matter(FPM) consisting of 2.5 to 10μm particles.However, it should be considered together as total particulate matter(TPM) emitted from workplaces, cars, heating and cooling will emit not only filterable PM but also condensable particulate matter(CPM). Therefore, in this study, filterable PM and condensable PM generated by the burning of LNG in buildings were calculated for each building use, using the emission factors announced by NIER. In addition, for the purpose of predicting the effects of PM by buildings, the prediction model of PM emissions was established and the case analysis was performed using machine learning.As a result, particulate matter per unit area of buildings was generally analyzed high in residential and commercial buildings and particularly high in the winter months due to increased LPG use caused by heating. And, since about 98% of the total PM was analyzed to be condensable PM, prevention and reduction measures for condensable PM should be expanded."
주성분 분석기법을 이용한 선박의 연료소비 예측에 관한 연구,2019,"['Ship Fuel Consumption', 'Energy Efficiency', 'Principal Component Analysis', 'Prediction Model', 'Ship Operational Data', '선박 연료소비량', '에너지 효율', '주성분 분석', '예측모델', '운항데이터']","최근 선박의 배기가스 규제가 강화되면서 연료소비량을 저감하기 위한 많은 방안들이 검토되고 있다. 그중에서도 선박으로부터 수집한 데이터를 활용하여 연료소모량을 예측하는 기계학습 모델을 개발하고자 하는 연구가 활발히 수행되고 있다. 하지만 많은 연구들이 학습모델의 주요 변수 선정이나 수집데이터의 처리 방법에 대한 고려가 미흡하였으며, 무분별한 데이터의 활용은 변수 간의 다중공선성 문제를 야기할 수도 있다. 본 연구에서는 이러한 문제점을 해결하기 위하여 주성분 분석을 이용하여 선박의 연료소비를 예측하는 방법을 제시하였다. 13K TEU 컨테이너 선박의 운항데이터에 주성분 분석을 수행하였으며, 추출한 주성분으로 회귀분석을 수행하여 연료소비 예측모델을 구현하였다. 평가용 데이터에 대한 모델의 설명력은 82.99%이었으며, 이러한 예측모델은 항해 계획 수립 시 운항자의 의사결정을 지원하고 항해 중 에너지 효율적인 운항상태 모니터링에 기여할 수 있을 것으로 기대된다.","As the regulations of ship exhaust gas have been strengthened recently, many measures are under consideration to reduce fuel consumption. Among them, research has been performed actively to develop a machine-learning model that predicts fuel consumption by using data collected from ships. However, many studies have not considered the methodology of the main parameter selection for the model or the processing of the collected data sufficiently, and the reckless use of data may cause problems such as multicollinearity between variables. In this study, we propose a method to predict the fuel consumption of the ship by using the principal component analysis to solve these problems. The principal component analysis was performed on the operational data of the 13K TEU container ship and the fuel consumption prediction model was implemented by regression analysis with extracted components. As the R-squared value of the model for the test data was 82.99%, this model would be expected to support the decision-making of operators in the voyage planning and contribute to the monitoring of energy-efficient operation of ships during voyages."
자본주의 리얼리즘 시대의 호모 데우스와 사이보그 글쓰기,2019,"['Cyborg', 'Access', 'Yihyung Yun', 'Homo-Deus', 'Capitalist Realism', '사이보그', '접속', '윤이형', '호모 데우스', '자본주의 리얼리즘']","이 글에서는 윤이형의 단편소설 <캠프 루비에 있었다>를 중심으로 미래세계에 대한 과학적 상상력을 고찰하였다. 등단 이후 최신의 과학담론을 소설의 구성요소로 적극 활용해 온 윤이형은 세 번째 작품집에서 안드로이드와 사이보그 등 비인간적 존재에 대한 성찰을 보여준다. 특이 <캠프 루비에 있었다>에서는 기존의 작품에서는 찾아볼 수 없었던 여성 사이보그가 등장한다. ‘비판적 포스트휴머니즘’을 선도한 도나 해러웨이는 이분법이 지배하는 완고한 세상의 질서에서 벗어나 새로운 사회학적 상상력을 발휘하기 위해서 사이보그가 주인공이 되는 신화가 필요하다고 주장한 바 있다. 사이보그 글쓰기는 이분법에 길들여진 우리에게 부분적 정체성과 모순을 받아들일 수 있는 언어와 상상력을 제공해준다는 것이다. 이 글에서는 자본주의적 폐해에 염증을 내면서도 더 이상 유토피아를 상상할 수 없는 자본주의 리얼리즘 시대에 사이보그적 글쓰기와 상상력은 과연 다른 세계를 상상할 수 있는 효과적인 매체가 될 수 있는가를 탐구하였다.한때 인간초능력자였던 진우가 업그레이드된 마음과 다운그레이드된 능력의 소유자라면 현재에 최적화된 사이보그 린은 업그레이드된 능력과 다운그레이드된 마음을 갖고 있는 호모 데우스이다. 이들이 서로에 대한 친근함에도 불구하고 상대를 낯선 존재로 인지할 수밖에 없는 이유는 이 때문이다. 이들에게 ‘하나’이면서 동시에 ‘여럿’인 붉은이들이 등장한다. 이들의 존재는 기계와 같은 존재였던 린이 마음을 업그레이드하는 계기를 마련해준다. ‘린’은 이들의 질문에 답하기 위해 ‘진우’의 마음 깊은 곳으로 접속해 들어가 그의 감정과 기억을 학습하고 이해한다. 이를 통해 ‘린’은 마음을 업그레이드할 수 있었고 결국 시스템의 부품이 되는 삶에서 벗어날 수 있었다. 이 작품에서 뚜렷하게 돋보이는 지점이 있다면 바로 다음 세대의 모습을 담고 있는 어린 사이보그가 과거인류의 마음과 접속하여 자신을 업그레이드한다는 부분일 것이다. 인간보다 더 인간적인 안드로이드 로봇, 자본의 압도로 기계만큼 획일화된 삶을 영위하는 인간군상들, 와이파이와의 단절을 두려워하는 접속불안현상 등은 오늘날 인간과 비인간, 유기체와 기계의 경계가 더 이상 자명하지 않음을 보여준다. 이 소설에 등장하는 사이보그는 이와 같은 현실을 담아내는 한편, 미래세계에 대한 미약하지만 전혀 불가능한 것도 아닌 가능성의 서사를 그린다.","This paper examines the scientific imagination of the future world, focusing on Yihyung Yun's novel, At Camp Ruby. Yihyung Yun, who has actively used the latest scientific discourse as a component of the novel since his departure, shows his reflection on inhuman beings such as Android and cyborg in his third collection. In this novel, there is a female cyborg that was not found in existing works. Donna Haraway, who led “critical post-humanism,” argued that cyborgs need a myth to cast new sociological imaginations out of the rigid world order of dichotomy. Cyborg writing provides us with the language and imagination to accept partial identity and contradiction. In this article, I explored whether cyborg writing and imagination could be an effective medium to imagine a different world in the age of capitalist realism, which is irritating capitalist damage and can no longer imagine utopia.In the past, ‘Jinwoo’ could read the human mind. He is the owner of upgraded minds and downgraded abilities. Cyborg ‘ Lin’ is Homo Deus with upgraded abilities and a downgraded mind. This is why they have no choice but to recognize each other as strangers despite their familiarity with each other. There are Redishes, one and many at the same time. Their presence provides the opportunity for Lin to upgrade his mind as a machine. To answer their questions, Lynn goes deep into Jinwoo's heart and learns and understands his feelings and memories. This allowed Lin to upgrade his mind and eventually escape life as a part of the system. What stands out in this work is that the young cyborg, which contains the figure of the next generation, upgrades himself by connecting with the human mind of the past. Android robots, which are more human than humans, human beings who live as uniformly as machines under the overwhelm of capital, and connection insecurity fearing disconnection from Wi-Fi, are no longer bounded by the boundaries between humans and non-humans, organisms and machines. Cyborg in this novel captures this reality while portraying a narrative of hope that is weak but not impossible for the future world"
보건의료에서의 인공지능 적용과 관련된 법적 과제에 대한 개관,2019,"['인공지능 알고리즘', '의료정보 빅데이터', '알고리즘 불투명성', '인공지능 거버넌스', '데이터 편향성', '왓슨 포 온콜로지', '수술로봇', 'AI algorithm', 'medical information big data', 'algorithm transparency', 'AI governance', 'data bias', 'watson for onology', 'surgical robot']","미래에는 인공지능 시스템이 더욱 발전하여 사람의 개입이나 입력 없이 더 넓은 범위의 작업을 수행할 수 있게 될 것이다. 이러한 경향은 보건의료분야에 더욱 실현된다면 환자의 이익이나 보건정책에 이득을 가져올 수 있지만 수반되는 위험의 정도도 더욱 심화될 수 있다. 첨단 인공지능 시스템으로의 혁신이 진일보할수록 인공지능의 알고리즘이 법주체성을 가질 수 있는지에 대한 논쟁은 계속적으로 이어질 것으로 보인다. 보건의료에서 인공지능 시스템이 안전하고 윤리적인 이용을 담보할 수 있을 것인지, 누가 이러한 윤리적 정의를 구현할 수 있도록 결정할 것인지 또는 인간에게 적용하는 어떠한 책무를 인공지능 시스템에 적용할 수 있거나 적용되어야 할 것인지 여부, 문제가 발생하였을 때 새로운 책임법리가 필요한지에 대해서는 계속적 논의가 진행되어야 할 필요가 있다. 결국 이러한 논의는 윤리적 과제이자 우리 사회가 당면한 법적 과제가 되는 것이다.보건의료에의 인공지능의 적용한계로서 신뢰도와 오류 그리고 이에 따른 안전의 문제를 간과할 수 없다. 인공지능 소프트웨어가 추천한 치료법과 의료진이 판단한 치료법간의 선택으로 인해 결과적으로 환자에게 악결과가 발생할 가능성이 상존하고 있다는 점에서 인공지능 시스템의 자동화된 의사결정에 책임이 있는 주체가 누구인지 여부와 부정확한 진단이나 처방결과로 인한 피해구제에 대한 손해배상 등의 법적 책임의 한계를 설정하는 것이 필요하다. 인공지능 프로그램의 제작자, 인공지능이 탑재된 의료기기의 소유자 또는 이들의 운용자 등이 손해발생에 기여한 정도에 따라 책임을 부담하여야 할 것이다.또한 데이터의 편향성을 통한 알고리즘 자체에 편향성이 포함될 수 있고 이를 증폭 · 강화하는 경향으로 진전될 수 있다. 알고리즘의 편향성으로 인해 직접·간접의 차별이 야기될 수 있고 그러한 차별로 인한 피해구제를 어떻게 접근할 것인가에 대해서는 아직 논의의 단계이기는 하지만, 알고리즘 자체의 불투명성으로 인해 전통적인 책임법리만으로 책임소재를 규명하거나 책임문제를 해결하기는 상당한 어려움이 있다. 알고리즘 불투명성에 따른 차별적 결과에 대해서는 알고리즘의 책무개념을 검토할 수 있으며, 행위를 논의의 중점에 두고 과연 행위과정에서 의무준수에 대한 숙지, 누가 책무를 부담할 것인지 여부를 판단하여 사전적으로 기술적, 법적, 제도적 관점에서 문제해결을 시도할 필요가 있다. 인공지능 적용으로 인한 위험 대응방안으로 규제의 수단을 상정할 수 있지만, 우선적으로는 전문위원회 또는 협의체 기구의 상설을 통해 기술혁신과 안전과 윤리적 이용 사이의 갈등을 조정하고 가이드라인을 설정하는 등의 인공지능 거버넌스 구축의 방법으로 접근하는 것이 합리적이라고 보인다.","AI has the potential to be used in planning and resource allocation in health and social care services. Using AI to analyse clinical data, research publications, and professional guidelines could also help to inform decisions about treatment.AI has applications in fields that are subject to regulation, such as data protection, research, and healthcare. However, AI is developing in a fast-moving and entrepreneurial manner that might challenge these established frameworks. The use of AI raises ethical and legal issues, including: the potential for AI to make erroneous decisions; the question of who is responsible when AI is used to support decision-making; inherent biases in the data used to train AI systems; ensuring the protection of potentially sensitive data; securing public trust in the development and use of AI technologies.AI applications in healthcare make use of data that many would consider to be sensitive and private. Using data that raise privacy concerns should go beyond compliance with the law to take account of people’s expectations about how their data will be used. Reliability and safety are key issues where AI is used to control equipment, deliver treatment, or make decisions in healthcare. Machine learning technologies can also be particularly opaque because of the way they continuously tweak their own parameters and rules as they learn. This creates problems for validating the outputs of AI systems, and identifying errors or biases in the data. Further challenges include the need to ensure that the way AI in healthcare is developed and used is transparent, accountable, and compatible with public interest, and balanced with the desire to drive innovation."
문자 인식 향상을 위한 회전 정렬 알고리즘에 관한 연구,2019,"['Convergence', 'Contour', 'Histogram Equalization', 'Object Recognition', 'Vision System', '융합', '컨투어', '히스토그램 평활화', '객체 인식', '비전 시스템']","영상을 기반으로 하는 기술들의 지속적인 발전으로 다양한 분야에서 활용되고 있고, 카메라를 통하여 획득한 영상의 객체를 분석하고 판별하는 비전 시스템의 기술 수요가 급속하게 증가하고 있다. 비전 시스템의 핵심 기술인 영상 처리는 반도체 생산 분야의 불량 검사, 타이어 표면의 숫자 및 심볼과 같은 객체 인식 검사 등에 사용되고 있고, 자동차 번호판 인식 등의 연구가 계속하여 이루어지고 있는 실정으로, 객체를 신속, 정확하게 인식할 필요가 있다. 본 논문에서는 곡면과 같은 곳에 마킹되어 있는 숫자나 심볼과 같이 기울어진 객체를 인식하기 위하여 입력된 영상 이미지의 객체 기울기에 대한 각도 값을 확인하여 객체의 회전 정렬을 통한 인식 모델을 제안한다. 제안 모델은 컨투어 알고리즘을 기반으로 객체 영역을 추출하고, 객체의 각도를 산출한 후, 회전 정렬된 이미지에 대한 객체 인식을 진행할 수 있는 모델이다. 향후 연구에서는 기계학습을 통한 탬플릿 매칭 연구가 필요하다.","Video image based technology is being used in various fields with continuous development. The demand for vision system technology that analyzes and discriminates image objects acquired through cameras is rapidly increasing. Image processing is one of the core technologies of vision systems, and is used for defect inspection in the semiconductor manufacturing field, object recognition inspection such as the number of tire surfaces and symbols. In addition, research into license plate recognition is ongoing, and it is necessary to recognize objects quickly and accurately. In this paper, propose a recognition model through the rotational alignment of objects after checking the angle value of the tilt of the object in the input video image for the recognition of inclined objects such as numbers or symbols marked on the surface. The proposed model can perform object recognition of the rotationally sorted image after extracting the object region and calculating the angle of the object based on the contour algorithm. The proposed model extracts the object region based on the contour algorithm, calculates the angle of the object, and then performs object recognition on the rotationally aligned image. In future research, it is necessary to study template matching through machine learning."
『전갈의아이』 읽기 ― 포스트휴먼 시대의 인간에 대한 고찰,2019,"['낸시파머', '『전갈의 아이』', '복제인간', '(포스트)휴먼', '(포스트)휴머니즘', 'Nancy Farmer', 'The House of the Scorpion', 'clone', '(post)human', '(post)humanism']","낸시 파머(Nancy Farmer)의 『전갈의 아이』(The House of the Scorpion, 2002)는 복제인간(clone)의 시각에서 인간 사회를 조명하는 포스트휴먼 청소년문학작품이다. 작가는 세포를 배양하여 태어난 맷(Matt Alacran)의 성장스토리를 통해 복제인간도 인간이라 할 수 있는가, 인간의 진정한 가치는 무엇인가, 나아가 인간은 과연 무엇인가 등의 문제를 고찰한다. 인간을 영혼을 지닌 유일무이한 존재이자 만물의 중심으로 여기는 휴머니즘은 복제인간, 사이보그, 인공지능 같은 포스트휴먼 존재의 출현으로 비판적 검토가 불가피하게 되었다. 이제 인류는 낯선 포스트휴먼 주체를 수용해야 하는 시대에 이르렀으며, 과학적 지식과 인문학적 사유의 통섭을 통해 이분법적 배타주의를 극복하고 모든 존재와 상생하는 법을 배워야 한다.  『전갈의 아이』에서 복제인간 맷은 다른 인간과의 관계에 의해 정체성이 다양하게 규정되는 열린 존재로 묘사된다. 그는 가축, 애완견, 복제품, 재산, 늑대인간, 괴물, 귀족 등 다양한 범주에 속하는 포스트휴먼 주체이지만, 비인간적 범주로 밀려난 모든 타자를 껴안는 인간성을 보인다. 『전갈의 아이』는 독자에게 인간의 진정한 가치를 일깨운다는 점에서 휴머니즘의 흐름에서 그리 벗어나지 않는 듯이 보인다. 그러나 인간과 비인간의 배타적 이분법을 비판적으로 성찰하고 해체한다는 점에서 이 작품은 비판적 포스트휴머니즘 이론과 같은 맥락에 위치한다.","With new developments in genetics, neuroscience, biotechnology, computer information technology, and cybernetics, we are facing a posthuman society with posthuman subjects. It’s time to rethink what ‘human’ really means, and how to deal with unfamiliar and unpleasing posthuman subjects. As the only beings that have the spiritual power of thinking and decision-making, humans have constructed great civilizations. This comprises the basic ideas of humanism, from which the strategy of inclusion and exclusion has resulted in the differentiation and discrimination among human society. Now, we have to reexamine the pitfalls of humanism based on the human/non-human dichotomy, and criticize its human-centered ideology. We must learn to embrace non-human subjects such as clones, cyborgs, A.I, and even animals, plants, and machines.  Nancy Farmer’s The House of Scorpion, if read as posthuman young adult literature, gives young readers the opportunity to catch glimpses of the inner mind of a posthuman subject. It makes us think of what ‘human’ really means, and by doing so, we learn how to embrace the excluded and despised non-humans as our equals.  Matt Alacran, El Patron’s clone is variously defined as “my vida,” “Alacran’s property,” “filthy beast,” “dirty clone,” “bad animal,” “photograph of the human,” “pet dog,” “werewolf,” or “aristocrat” by people who see him. His identity is unstable, fluid, and ever-changing. He is excluded from the ‘human’ category as the clone that might be killed and discarded anytime after being used for organ transplant. However, the clone Matt, having a noble mind and more integrity than any Alacran(Scorpion) family member, finally becomes the savior of the Opium Empire. The House of Scorpion blurs the human/nonhuman boundary and subverts and deconstructs its exclusive dichotomy by describing a young clone’s ordeal and growth. This posthuman young adult fiction has humanistic messages. In this cautionary posthuman young adult tale, humanism is not renounced, and rather posthumanism is suggested as a new extension of humanism."
공리적 설계의 독립공리를 위배하는 사례분석과 모순해결 원리,2019,"['Axiomatic design', 'Independence axiom', 'Contradiction solving', 'Butterfly diagram', '공리적 설계', '독립공리', '모순해결', '나비 다이어그램']","공리적 설계는 어떤 설계가 좋은지 나쁜지 평가할 수 있는 정량적인 기준을 제공한다. 공리적 설계에 관한 연구들은 독립공리를 바탕으로 이론을 전개했다. 독립공리는 기능적인 요구사항의 수와 물리적 특성인 설계 요소의 수가 일치하면서 아울러 각 설계 요소가 상호 독립적으로 기능적인 요구사항을 수행하는 비연성 설계(uncoupled design)가 최적이라고 제시한다. 공리적 설계에서는 지금까지 공리적 설계의 독립공리를 위배한 사례가 발견되지 않았다고 제시하였다. 본 연구는 공리적 설계의 독립공리를 충족하지 않아도 최적으로 문제가 해결되는 사례들을 모순해결 관점에서 분석하였다. 첫째, 기능적인 요구사항의 수와 설계 요소의 수가 일치할지라도 부분적인 설계 요소들이 모여서 전체 설계 요소를 구성하기 때문에 부분적인 설계 요소와 전체 설계 요소는 상호의존적인 관계를 가져 독립공리를 위배하게 된다. 본 연구는 Duncker의 방사선 문제와 계단을 오르는 카트 바퀴 사례를 분석하였다. 둘째, 기능적인 요구사항의 수보다 설계 요소의 수가 작아서 연성 설계(coupled design)에 해당하지만 한 개의 최적점에서 상충된 두 가지 기능적인 요구사항들을 충족하는 때도 있다. 본 연구는 경제학의 단기비용곡선과 기계학습의 편향-분산 트레이드오프 사례를 분석하였다. 셋째, 공리적 설계의 독립공리와 달리, 설계 요소들이 상호 독립적이지 않고 완벽하게 –1.0의 상관관계를 갖는 경우에 오히려 최적으로 문제를 해결하는 때도 있다. 본 연구는 투자대안들의 상관관계에 따라 투자 위험이 달라지는 Markowitz의 포트폴리오 이론을 분석하였다. Markowitz의 포트폴리오 이론은 투자 대안의 기대수익률과 위험에 대한 두 가지 기능적인 요구사항을 달성하는데 최적의 포트폴리오를 제시한다. 그의 이론에 의하면 투자대안들이 상호 독립적이지 않고 –1.0의 상관관계를 가질 때에 투자대안의 기대수익률을 낮추지 않으면서도 위험을 완전히 없앨 수 있는 것으로 나타났다.","Axiomatic Design provides quantitative criteria to evaluate whether a design is good or bad. Research works on Axiomatic Design have been based on the independence axiom. The independence axiom suggest that the uncoupled design is optimal, in which the number of functional requirements are the same as the number of design parameters, which are the physical characteristics, and each design parameter performs its function requirement independently of each other. In the Axiomatic Design, it is suggested that no case of violating the independence axiom of Axiomatic Design has been found yet. This paper analyzed the cases that were solved optimally without satisfying the independence axiom of the Axiomatic Design from the perspective of solution of contradiction. First, even though the number of function requirements and the number of design parameters are matched, partial design parameters are combined to constitute the whole design parameters. Therefore, the partial design parameters and the whole design parameters are interdependent and violate the independence axiom. This paper analyzed Duncker 's radiation problems and cart wheel cases climbing stairs. Second, although the number of design parameters is less than the number of functional requirements, which corresponds to a coupled design, there are cases where there are optimum points that satisfy two conflicting functional requirements. This paper analyzed the short-run cost curve in Economics and the bias-variance trade-offs in Machine Learning. Third, if a problem is the case that its design parameters are perfectly dependent of each other and have a -1.0 correlation, the problem may be resolved optimally. This paper analyzes Markowitz 's portfolio theory, which is based on the correlation of investment alternatives. Markowitz's portfolio theory presents an optimal portfolio for achieving the two functional requirements for expected return and risk for investment alternatives. According to the theory, when the investment alternatives are not mutually independent and have a -1.0 correlation, they can completely eliminate the risk without lowering the expected return on the investment alternative."
주거환경만족도 평가의 신뢰성 향상을 위한 기초연구 - 주거실태조사의 설문구성 방식을 중심으로 -,2019,"['설문구성', '주거환경만족도', '만족도조사', '신뢰도검증', '주거실태조사', 'Questionnaire Design', 'Residential Satisfaction', 'Satisfaction Survey', 'Reliability Verification', 'KHS (Korea Housing Survey)']",,"This paper aims to investigate the reliability verification of residential satisfaction evaluation in terms of the SP(Same-Pattern) responses suspected as outliers under the 2006-2017 KHS. Based on the research hypothesis developed from the distributional characteristics in the Same-Pattern (SP) responses obtained across 2006-2017 KHS, each of three distinctive questionnaires types (type B, R, and D) are prepared and distributed to 750 respondents (2,250 respondents in total) through online. The key findings are as follows:  First, the “Reduced type R”, in which the number of questionnaire items is reduced in an attempt to lower the likelihood of unreliable answers resulting from the fatigue effect, adversely affected the result and presented even greater tendency towards SP responses. It is concluded that such simple measures of reducing the number of questionnaires do not effectively address the problem of SP occurrence that is suspected of being outliers.  Second, the “Divided type D”, in which the questionnaire items were divided into multiple sub-groups in an attempt to increase the awareness of respondents and prod them into action, presented the lowest occurrence of SP responses. Moreover, this type is likely to have the lowest possibility of co-existing outliers, the result confirmed by the verification process using statistical and machine-learning analysis.  Third, it became clear that reducing the number of questionnaires while simultaneously inserting heterogeneous intermediary questionnaires is the most effective method to conduct the table-formulated satisfaction evaluation utilizing a Likert scale. However, since an excessive partition may cause unnecessary psychological pressure on respondents and increase the likelihood of SP outliers, it is highly recommended to utilize the carefully designed framework for the best result."
인공지능에 대한 전자인 제도 도입의 필요성과 실현방안에 관한 고찰,2019,"['전자인', '인공지능', '법인', '권리주체성', '법인격', 'E-Person', 'Artificial Intelligence', 'Juridical person', 'Legal personhood', 'Legal personality']","프로그램 개발자조차 반응을 더 이상 예측할 수 없고 학습능력에 의하여 진화하는 지능형 로봇과 인공지능의 자율성이 증가함에 따라 전자인 제도 및 이를 위한 책임기금의 도입을 생각해 보아야 하는 상황이 도래하였다. 즉, 자연인과 법인 외에 또 다른 권리주체로서의 “전자인”을 인정할 것인지가 문제된다. 인공지능이 계약당사자가 될 수 있는지, 책임의 주체가 될 수 있는지, 기본권의 향유자가 될 수 있는지는 모두 법인격의 유무와 관련되어 있다. 이미 선진국에서는 이 문제에 관하여 활발히 논의되어 왔다. 이 과정에서 법인격에 관한 매우 상이한 형성 가능성과 정당화 가능성이 제시되었다. 이에 본 연구는 우리 법과 사회적 현실을 고려하여 인공지능에 대한 법인격 부여 내지 전자인 제도의 도입 여부를 시론(試論)적으로 검토하였다. 논의의 주요 결과는 다음과 같다.  현행 민법의 법리로는 디지털 혁명에 적절히 대응할 수 없어 새로운 규칙 및 인공지능의 법인격의 도입이라고 하는 돌파구가 모색되어야 한다. 표의자 또는 의사표시의 귀속자를 자연인으로 국한하는 전통적 법률행위론은 4차산업혁명 및 인공지능과 같은 오늘날의 기술의 현실과 더 이상 조화를 이루지 못한다.  인공지능을 새로운 권리주체로 인정하는 것은 매우 근본적인 결단을 의미하지만, 전자인의 도입 내지 인공지능에 대한 법인격의 부여는 인공지능의 사용 시에 계약책임은 물론 불법행위책임에서도 법적 안정성을 제고하는 데이바지 할 것이다. 근대법이 법인제도를 창설할 때에도 초기에는 비판이 적지 않았지만 결국 관철되었다. 오늘날 법인제도의 창설은 근대법의 위대한 문화적 기여로 평가된다. 법인제도에 의하여 자연인의 행동반경이 크게 확장되었기 때문이다. 인공지능에 대한 법인격 부여도 이러한 기회를 제공할 수 있다.  먼저 법리적으로 보면 인공지능에 대한 법인격을 부여를 반대할 수 있는 논거가 마땅치 않다. 법인의 예에서 볼 수 있듯 법질서는 이미 인위적 존재에 대하여 법인격을 인정하고 있기 때문이다. 현행법상 인공지능의 행위를 누구에게 귀속시킬 것인지와 관련하여 법적 불안정성이 존재한다는 점은 인공지능에 대한 법인격 인정을 위한 중요한 논거이다. 그럼에도 인공지능에 대한 포괄적인 법인격 부여는 요청되지 않는다.  법윤리적 관점에서 우선 인간의 법적 지위나 우열관계를 훼손할 수 있다는 점과 함께 기계의 인간화에 대한 우려가 표명되고 있다. 그러나 인공지능에 대한 법인격 부여에 의하여 인간의 지위가 열악해지는 사태는 발생하지 않을 것이다. 인공지능의 법적 지위를 규정한 법질서는 궁극적으로 인간이 만들기 때문이다. 그리고 존재론적 의미에서의 권리주체와 법적 의미에서의 권리주체는 구별을 요한다. 그에 따라 인간과 인공지능의 우열관계는 법적으로도 규정될 수 있다. 인공지능은 법적 의미에서의 권리주체에 불과하여 존재론적 의미에서의 권리주체에 항상 귀속되어야 하기 때문이다. 인공지능은 특히 사회적 지능이 결여되어 있는 점에서 인간과 구별된다. 그리고 본질, 구성, 재생산 및 생명의 청사진과 관련하여서도 중대한 차이가 존재한다. 따라서 법윤리적·법철학적 관점에서 인공지능에 대한 법인격 부여를 반대할 이유가 없다.  인공지능의 취급과 관련하여 법적 안정성의 보장에 관한 사회적 요청은 법인격 부여를 위한 도덕적 자격 및 사회적 역량의 결여를 상쇄할 수 있다. 인공지능의 권리능력은 계약체결에 관한 능력으로 제한하고, 운용자인 자연인 또는 법인을 등록부에 명시하며, 전자서명에 의하여 인공지능의 행위가 운용자에게 귀속됨을 분명히 하고, 인공지능의 책임재산액을 정하며, 운용자에 대한 민사법적·형사법적 행위기준을 설정해야 할 것이다. 결론적으로 법질서는 인공지능에 대하여 법적 의미에서의 법인격을 부여할 수 있다.  대리(민법 제114조 이하), 이행보조자에 대한 책임(민법 제391조), 사용자책임(민법 제756조)은 대리인, 이행보조자 및 피용자로서의 인공지능에 대하여 법인격이 전제되는 경우에 한하여 유추 적용될 수 있다. 또한 인공지능의 기본권향유능력을 인정할 때에만 인공지능은 책임재산에 대하여 소유권을 갖게 될 수 있다. 인공지능에 대한 법인격의 부여는 사회와 잠재적 피해자는 물론 시스템운용자 모두에 대하여 “윈윈(win-win) 상황”을 가져올 것이다.","The question of the legal implications of increasing autonomy of intelligent agents was discussed for the first time in the context of contract conclusions on the Internet. The general question was whether such systems should have legal personality and thus legal personhood, as well as the concrete classification of the activities of the systems in a contractual context. Due to the autonomy and intelligence of an autonomous system, the question arises as to whether this makes its own declaration of intent. According to the concrete definition of legal personhood, this means the ability to be the bearer of rights and obligations. This question is closely linked to the examination of the existence of legal personhood. However, the Korean Civil Code recognizes these by nature only with natural persons and, in addition, attributes them to legal persons through recognition by the legal system. However, such recognition has not (yet) been made with respect to autonomous systems, and it is questionable whether this will ever succeed. This discussion is now revived, albeit under the auspices of even more autonomous, even more intelligent, more self-learning machines. It was regularly determined from the point of view of the declaration of intent, that it always presupposes a human act and then discusses the own “legal personality” or “legal personhood” of intelligent agents. Here, too, the “attribution paradigm”, as it plays a special role in today""s discussion, was at the center of the discussion.  The technology has meanwhile developed enormously. Nowadays, the question is increasingly raised as to whether it makes sense to attribute legal personhood to autonomous systems or at least to what extent the attribution rules change and shift due to the autonomy of the systems. The key question of all liability problems arising in the context of digitization is therefore seen in terms of whom a possible misbehavior of autonomous systems can be attributed and how risks associated with the production and use of autonomous systems can be distributed in an appropriate manner. This applies both in the area of legal attribution as well as in the area of liability.  It should, however, be essential to take sufficient account of the current technical development. Only by examining the concrete technical functionality of the systems can it be deduced how far they control their actions and “decisions” and how the conclusions can be drawn for their classification as attributable activities. Otherwise, attempts by critics of a future lack of imputation could not be explained."
텐서플로우를 이용한 미디어아트 제작 연구 -마젠타API의 응용을 중심으로-,2019,"['머신러닝', '텐서플로우', '미디어아트', 'Machine Learning', 'Tensorflow', 'Media Art']",,"Machine learning is the core technology of 4th industrial revolution and brought big changes in art and design creations. Media art is a form of art practice which converge cutting edge art and design and possibilities of creating art with machine learning is active in this field. This paper investigate the pratical possibilities of machine learning in art and design through analysing the creative process of interactive web art work FVTM:From Vera to Magenta(2019). The paper surveyed the development of artificial intelligence and machine learning technology and compared the characteristics of four major machine learning frameworks. Main study illustrates the characteristic of Google’s Tensorflow, the chosen framework for project and analyse two components of Magenta API which was developed based on Tensorflow especially for artists and designers; it’s sound models and image models. In creation stage, the paper illustrates evolution of open source remixing process for FVTM and explain the two main elements of the work; generation of sound applying pre-trained VAE model of Magenta API and creation and mapping process of visual elements which utilize the process of color value overlapping. Significance of FVTM work and possible of future work using new model build, train and mapping. By presenting the process of creating generative art work using machine learning API, the paper aim to stimulate more active collaboration between machine learning and art of various disciplines."
SVM 기법을 이용한 쉴드 TBM 디스크 커터 교환 주기 예측,2019,"['쉴드 TBM', '디스크 커터', 'Disc cutter', '머신러닝', 'SVM', 'Shield TBM', 'Machine learning', 'SVM']","본 연구에서는 쉴드 TBM (Tunnel Boring Machine) 터널 디스크 커터의 적절한 교체시기를 예측하기 위한 방법으로 머신러닝 기법을 사용한 방법을 제안하였으며, 이를 위해 국내 기 시공된 쉴드 TBM 현장의 데이터를 이용하여 다양한 머신러닝 알고리즘 중SVM (Support Vector Machine)을 이용하여 예측 모델을 구축하고 그 성능을 평가하였다. 지반 조건별 디스크 커터의 마모와 높은 상관성을 갖는 TBM 기계 데이터와 디스크 커터 교체 이력을 분류하고, 이들을 SVM의 변수로 사용하여 3종류의 분류 함수를 적용하여 각각 학습을 한 후 예측을수행한 결과, 각 지반 조건에 대해서 3종류의 SVM 분류 함수 중 전체적으로 RBF (Radial Basis Function) SVM의 예측성능이 가장 우수하며(평균적으로 80%의 정확도, 10% 오분류율), 지반 조건별로 구분 시 디스크 커터 교체 데이터의 수가 많을수록 예측 결과가 좋은 것으로 나타났다. 향후 많은 데이터를 축적하고 이를 모두 활용하여 학습모델을 지속적으로 발전시켜 나간다면 이와 같은 디스크 커터 교환주기를 예측하기 위한 머신러닝 기법의 실무 적용성이 매우 클 것으로기대한다.","In this study, a machine learning method was proposed to use in predicting optimal replacement period of shield TBM (Tunnel Boring Machine) disc cutter. To do this, a large dataset of ground condition, disc cutter replacement records and TBM excavation-related data, collected from a shield TBM tunnel site in Korea, was built and they were used to construct a disc cutter replacement period prediction model using a machine learning algorithm, SVM (Support Vector Machine) and to assess the performance of the model. The results showed that the performance of RBF (Radial Basis Function) SVM is the best among a total of three SVM classification functions (80% accuracy and 10% error rate on average). When compared between ground types, the more disc cutter replacement data existed, the better prediction results were obtained. From this results, it is expected that machine learning methods become very popularly used in practice in near future as more data is accumulated and the machine learning models continue to be fine-tuned."
데이터 크기에 따른 k-NN의 예측력 연구: 삼성전자주가를 사례로,2019,"['k-nearest neighbor', 'case based reasoning', 'stock market prediction', 'python', 'k-최근접 이웃 알고리즘', '사례기반추론', '주식시장 예측', '파이썬']","본 논문은 학습데이터의 크기에 따른 사례기반추론기법이 주가예측력에 어떻게 영향을 미치는지 살펴본다.삼성전자 주가를 대상을 학습데이터를 2000년부터 2017년까지 이용한 경우와 2015년부터 2017년까지 이용한경우를 비교하였다. 테스트데이터는 두 경우 모두 2018년 1월 1일부터 2018년 8월 31일까지 이용하였다. 시계열데이터의 경우 과거데이터가 얼마나 유용한지 살펴보는 측면과 유사사례개수의 중요성을 살펴보는 측면에서연구를 진행하였다. 실험결과 학습데이터가 많은 경우가 그렇지 않은 경우보다 예측력이 높았다. MAPE을 기준으로 비교할 때, 학습데이터가 적은 경우, 유사사례 개수와 상관없이 k-NN이 랜덤워크모델에 비해 좋은 결과를보여주지 못했다. 그러나 학습데이터가 많은 경우, 일반적으로 k-NN의 예측력이 랜덤워크모델에 비해 좋은 결과를 보여주었다. k-NN을 비롯한 다른 데이터마이닝 방법론들이 주가 예측력 제고를 위해 학습데이터의 크기를 증가시키는 것 이외에, 거시경제변수를 고려한 기간유사사례를 찾아 적용하는 것을 제안한다.","Statistical methods such as moving averages, Kalman filtering, exponential smoothing, regression analysis, and ARIMA (autoregressive integrated moving average) have been used for stock market predictions. However, these statistical methods have not produced superior performances. In recent years, machine learning techniques have been widely used in stock market predictions, including artificial neural network, SVM, and genetic algorithm. In particular, a case-based reasoning method, known as k-nearest neighbor is also widely used for stock price prediction. Case based reasoning retrieves several similar cases from previous cases when a new problem occurs, and combines the class labels of similar cases to create a classification for the new problem. However, case based reasoning has some problems. First, case based reasoning has a tendency to search for a fixed number of neighbors in the observation space and always selects the same number of neighbors rather than the best similar neighbors for the target case. So, case based reasoning may have to take into account more cases even when there are fewer cases applicable depending on the subject. Second, case based reasoning may select neighbors that are far away from the target case. Thus, case based reasoning does not guarantee an optimal pseudo-neighborhood for various target cases, and the predictability can be degraded due to a deviation from the desired similar neighbor.This paper examines how the size of learning data affects stock price predictability through k-nearest neighbor and compares the predictability of k-nearest neighbor with the random walk model according to the size of the learning data and the number of neighbors. In this study, Samsung electronics stock prices were predicted by dividing the learning dataset into two types. For the prediction of next day's closing price, we used four variables: opening value, daily high, daily low, and daily close. In the first experiment, data from January 1, 2000 to December 31, 2017 were used for the learning process. In the second experiment, data from January 1, 2015 to December 31, 2017 were used for the learning process. The test data is from January 1, 2018 to August 31, 2018 for both experiments.We compared the performance of k-NN with the random walk model using the two learning dataset.The mean absolute percentage error (MAPE) was 1.3497 for the random walk model and 1.3570 for the k-NN for the first experiment when the learning data was small. However, the mean absolute percentage error (MAPE) for the random walk model was 1.3497 and the k-NN was 1.2928 for the second experiment when the learning data was large. These results show that the prediction power when more learning data are used is higher than when less learning data are used. Also, this paper shows that k-NN generally produces a better predictive power than random walk model for larger learning datasets and does not when the learning dataset is relatively small.Future studies need to consider macroeconomic variables related to stock price forecasting including opening price, low price, high price, and closing price. Also, to produce better results, it is recommended that the k-nearest neighbor needs to find nearest neighbors using the second step filtering method considering fundamental economic variables as well as a sufficient amount of learning data."
Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법,2019,"['Big Data', '식스 시그마', '통계적 방법', '알고리즘 방법', 'DMAIC', 'DIDOV', 'DPELR', 'Six Sigma', 'Big Data', 'Statistical methods', 'Algorithmic techniques', 'DMAIC', 'DIDOV', 'DPELR']",최근 Big Data에 대한 관심이 높아짐에 따라 기업의 데이터 분석 역량이 새롭게 강조되고 있다. 이러한 추세에 맞추어 데이터 기반의 문제 해결 방법인 Six Sigma 품질 혁신 분야에서도 Big Data의 분석 방법으로 소개되는 Machine Learning 관련 방법론에 관심이 높아지고 있다. 일반적으로 Six Sigma 분석 방법은 명확한 대상 또는 프로세스에서 수집되는 정제된 데이터를 이용한 통계적 모형적용을 통한 높은 해석력을 중시하지만 Machine Learning 분야에서는 비정제 데이터의 전처리를 전제로 알고리즘 방법에 의한 예측 정확도를 강조한다. 제조 기업의 경우 명확한 프로세스가 정의되어야 하고 개발/운영/관리의 전 과정에서 정제된 데이터를 수집하고 현장 적용을 위한 해석력이 강조되므로 Six Sigma 분석 방법이 Machine Learning 분야의 분석 방법과 비교할 때 더 유용하다고 할 수 있다. 하지만 자동화된 프로세스의 센싱/로그 데이터의 증가 그리고 제품의 품질/신뢰성 특성과 고객/시장에 대한 비정형 데이터간의 연계성이 중요해 지면서 기존의프로젝트 실행 방법인 DMAIC만으로 충분하지 못한 경우가 있다. 본 논문에서는Big Data의 비중이 큰 Six Sigma 프로젝트의 새로운 실행 방법인 DPELR을 소개하고 각 단계별 세부 결과물을 제시해 보고자 한다.,"Recent focus on Big Data highlights the importance of organization’s data analytics capabilities. To meet the demand of such trend, research in Six Sigma quality innovation, a data driven solution, is becoming increasingly aware of Machine Learning and Big Data analytics. Traditionally, Six Sigma emphasizes the study of interpretable statistical models generated by designed data obtained through specified objects and processes. In contrast, the field of Machine Learning emphasizes predictability of a model generated with raw data and algorithmic techniques. For manufacturing industry, Six Sigma methodologies provide advantages over Machine Learning techniques because manufacturing industry requires clearly defined processes and high interpretability for applications on the field. Moreover, established processes in manufacturing industry facilitate collection of processed data from development, operation, and management stages. However, increase in sensing/log data from automated processes and elevated focus on association between quality/reliability and customer/market related raw data can impose limitations on DMAIC, one of Six Sigma breakthrough used for a project implementation. This paper introduces DPELR, a new Six Sigma breakthrough for project using Big Data, and presents details for proposed stages."
KISTI-ML Platform: A Community-based Rapid AI Model Development Tool for Scientific Data,2019,"['기계학습', '빅데이터', 'MLaaS', '플랫폼', '과학기술 데이터', 'Machine Learning', 'Big Data', 'MLaaS', 'Platform', 'Scientific Data']",,"Machine learning as a service, the so-called MLaaS, has recently attracted much attention in almost all industries and research groups. The main reason for this is that you do not need network servers, storage, or even data scientists, except for the data itself, to build a productive service model. However, machine learning is often very difficult for most developers, especially in traditional science due to the lack of well-structured big data for scientific data. For experiment or application researchers, the results of an experiment are rarely shared with other researchers, so creating big data in specific research areas is also a big challenge. In this paper, we introduce the KISTI-ML platform, a community-based rapid AI model development for scientific data. It is a place where machine learning beginners use their own data to automatically generate code by providing a user-friendly online development environment. Users can share datasets and their Jupyter interactive notebooks among authorized community members, including know-how such as data preprocessing to extract features, hidden network design, and other engineering techniques."
A Text Sentiment Classification Method Based on LSTM-CNN,2019,"['Machine Learning', 'CNN', 'LSTM', 'Text Sentiment Classification Methods', 'Deep Learning', '텍스트 정서 분류 방법']",,"With the in-depth development of machine learning, the deep learning method has made great progress, especially with the Convolution Neural Network(CNN). Compared with traditional text sentiment classification methods, deep learning based CNNs have made great progress in text classification and processing of complex multi-label and multi-classification experiments. However, there are also problems with the neural network for text sentiment classification. In this paper, we propose a fusion model based on Long-Short Term Memory networks(LSTM) and CNN deep learning methods, and applied to multi-category news datasets, and achieved good results. Experiments show that the fusion model based on deep learning has greatly improved the precision and accuracy of text sentiment classification. This method will become an important way to optimize the model and improve the performance of the model."
에너지 인터넷을 위한 GRU기반 전력사용량 예측,2019,"['Machine Learning', 'Deep Learning', 'RNN', 'GRU', 'Demand Forecasting']","최근 에너지 인터넷에서 지능형 원격검침 인프라를 이용하여 확보된 대량의 전력사용데이터를 기반으로 효과적인 전력수요 예측을 위해 다양한 기계학습기법에 관한 연구가 활발히 진행되고 있다. 본 연구에서는 전력량 데이터와 같은 시계열 데이터에 대해 효율적으로 패턴인식을 수행하는 인공지능 네트워크인 Gated Recurrent Unit(GRU)을 기반으로 딥 러닝 모델을제안하고, 실제 가정의 전력사용량 데이터를 토대로 예측 성능을 분석한다. 제안한 학습 모델의 예측 성능과 기존의 LongShort Term Memory (LSTM) 인공지능 네트워크 기반의 전력량 예측 성능을 비교하며, 성능평가 지표로써 Mean SquaredError (MSE), Mean Absolute Error (MAE), Forecast Skill Score, Normalized Root Mean Squared Error (RMSE),Normalized Mean Bias Error (NMBE)를 이용한다. 실험 결과에서 GRU기반의 제안한 시계열 데이터 예측 모델의 전력량 수요 예측 성능이 개선되는 것을 확인한다.","Recently, accurate prediction of power consumption based on machine learning techniques in Internet of Energy (IoE)has been actively studied using the large amount of electricity data acquired from advanced metering infrastructure(AMI). In this paper, we propose a deep learning model based on Gated Recurrent Unit (GRU) as an artificialintelligence (AI) network that can effectively perform pattern recognition of time series data such as the powerconsumption, and analyze performance of the prediction based on real household power usage data. In the performanceanalysis, performance comparison between the proposed GRU-based learning model and the conventional learning modelof Long Short Term Memory (LSTM) is described. In the simulation results, mean squared error (MSE), mean absoluteerror (MAE), forecast skill score, normalized root mean square error (RMSE), and normalized mean bias error (NMBE)are used as performance evaluation indexes, and we confirm that the performance of the prediction of the proposedGRU-based learning model is greatly improved."
Toward a grey box approach for cardiovascular physiome,2019,"['Machine learning', 'Mathematical model', 'Patient-specific modeling']",,"The physiomic approach is now widely used in the diagnosis of cardiovascular diseases. There are two possible methods for cardiovascular physiome: the traditional mathematical model and the machine learning (ML) algorithm. ML is used in almost every area of society for various tasks formerly performed by humans. Specifically, various ML techniques in cardiovascular medicine are being developed and improved at unprecedented speed. The benefits of using ML for various tasks is that the inner working mechanism of the system does not need to be known, which can prove convenient in situations where determining the inner workings of the system can be difficult. The computation speed is also often higher than that of the traditional mathematical models. The limitations with ML are that it inherently leads to an approximation, and special care must be taken in cases where a high accuracy is required. Traditional mathematical models are, however, constructed based on underlying laws either proven or assumed. The results from the mathematical models are accurate as long as the model is. Combining the advantages of both the mathematical models and ML would increase both the accuracy and efficiency of the simulation for many problems. In this review, examples of cardiovascular physiome where approaches of mathematical modeling and ML can be combined are introduced."
이미지 인식과 캡션을 위한 기계학습 모델 연구,2019,"['Machine learning model', 'Dataset', 'Chatbot', 'Image recognition', 'Image captioning']","인공지능, 로봇공학, 사물인터넷, 빅 데이터, 자율주행시스템 등은4차 산업혁명의 주요 기술군이다. 이들 기술은 대량의 비정형 데이터(이미지)나 스트리밍 데이터들을 다루게 되며, SNS 사용자들이 발생시키는 비정형 데이터들의 양도 지속적으로 증가하고 있다. 본 논문에서는 인공지능, 딥 러닝이나 비전 처리에서 많이 연구되는 이미지 데이터에 대한 기계학습 모델을 구축하고, 이미지 처리를 위한 인식 및 캡션 생성에 대한 실험을 수행하였다. 제안 모델은 챗봇(페이스북 앱), 모니터 서버와 모델 서버로 구성되며, 질의 종류는 이미지와 자연어 문장으로 구분하여 모델 서버의 ‘Captioning Model’과 ‘VQA Model’에서 각각 처리한다. 기계학습에 사용한 공개 훈련용 데이터 집합은 2017 MSCOCO이며, 캡션 생성의 성능 실험 결과 perplexity는 8.9의 우수한 결과를 확인할 수 있었다.","Artificial intelligence, Robotics, the Internet of Things, Big data and Self-driving systems are the major technological groups of the fourth industrial revolution. These technologies related to the fourth industrial revolution will deal with large amounts of formalization data(image) or streaming data. Also, the amount of image data occured by SNS users is increasing continuously. In this paper, we constructed a machine learning model for image data processing which is studied in Artificial Intelligence, Deep Learning and Vision Processing. We experimented on recognition and caption generation for image processing. The proposed model consists of three parts which have a Chatbot (Facebook app), a Monitor Server and a Model Server. The query types of Chatbot are classified into image and natural language sentences and processed in ‘Captioning Model’ and ‘VQA Model’ of model server respectively. The open training data set used on our machine learning system is 2017 MSCOCO, and the captioning performance is perplexity 8.9. We have obtained the good results from suggested machine learning system."
데이터 센터의 리소스를 효율적으로 관리하기 위한 인공지능 기반의 프레임워크,2019,"['데이터센터', '머신러닝', '리소스 관리', '하둡파일시스템', '분산처리 시스템', 'Data Center', 'Machine Learning', 'Recource Management', 'HDFS', 'Distributed Processing System']","최근 기술의 발전으로 인하여 서로 다른 영역에서 대규모의 데이터를 생성할 수 있게 되었고 이로 인하여 빅데이터 를 효율적으로 처리하고 분석할 수 있는 대규모 데이터 센터의 필요성이 대두되었다. 데이터 양이 증가함에 따라 작 업 스케줄링과 자원 관리는 매우 중요한 요소이다. 본 논문에서는 데이터 센터의 성능을 향상하기 위한 목적으로 자 원 관리 및 업무 스케줄링 매커니즘을 개선하는 새로운 인공지능 기반 프레임워크를 제안한다. 우리의 논문에서는 기계 학습을 사용하여 리소스 관리를 위한 특정기간 동안의 수요 리소스 활용도를 예측하고, 작업 스케줄링 개선을 위하여 향상된 개미 군체(ant colony) 알고리즘을 사용한다. 프레임워크 시뮬레이션을 통해 미래의 수요를 예측하 여 실행 중인 노드의 수를 10% 줄이고 전통적인 리소스 관리와 작업 스케줄링 방법보다 작업량이 15% 향상하는 결과를 확인할 수 있었다. 본 결과를 기초로 하여 우리는 인공지능과 기계학습을 사용한 효과적인 자원할당과 작업 스케줄링이 전반적인 성능이나 데이터센터를 개선할 수 있음을 알 수 있다.","Recent technological advancement has enabled the creation of large scale data (big data) in different domains which have raised the need for large data centers to process and analyze that big data in an efficient fashion. The incremental amount of data has made job scheduling and resource management an essential and challenging component of modern-day data centers. Therefore, in this paper, we have proposed a novel artificial intelligence based framework to enhance the data center performance by improving resource management and job scheduling mechanisms. We have used machine learning to predict resource utilization based on user demand over a particular time span for resource management and improved ant colony algorithm to job scheduling. Results generated from framework simulation demonstrates that predicting future demands aids prediction of future resource utilization and enables efficient job scheduling that reduce the number of running nodes by 10% and increase throughput by 15% from traditional resource management and job scheduling methods. Based on our simulation results be to argue that by using artificial intelligence and machine learning we can improve overall performance or modern-day data centers by efficient resource allocation and job scheduling."
인공지능 기술기반의 통합보안관제 서비스모델 개발방안,2019,"['인공지능', '머신러닝', '통합보안관제', '보안관제', '서비스모델', 'Artificial Intelligence', 'Machine Learning', 'Integrated Security Control', 'Security Control', 'Service Model']","본 논문에서는 인공지능기술을 통합보안관제 기술에 효율적으로 적용하는 방안을 제안하였다. 즉, 통합보안관제시스템에 수집된 빅 데이터를 기반으로 머신러닝 학습을 인공지능에 적용하여 사이버공격을 탐지하도록 하고 적절한 대응을 한다. 기술의 발달에 따라서 늘어나는 보안장비와 보안 프로그램들로부터 쌓이는 수많은 대용량의 로그들을 사람이 일일이 분석하기에는 한계에 부딪히고 있다. 분석방법 또한 한 가지 로그가 아닌 여러 가지 이기종간의 보안장비의 로그까지 서로 상관분석을 해야 하기 때문에 더욱 더 통합보안관제에 적용되어서 신속한 분석이 이루어져야 하겠다. 이런 행위를 분석하고 대응하는 과정들이 효과적인 학습방법을 통해서 점진적으로 진화를 거쳐 성숙해가는 인공지능기반 통합보안관제 서비스모델을 새롭게 제안하였다. 제안된 모델에서 예상되는 핵심적인 문제점들에 대한 해결방안을 모색하였다. 그리고 정상 행위기반의 학습모델을 개발하여 식별되지 않는 비 정상행위 위협에 대응력을 강화하는 학습방법을 도출하였다. 또한, 제안된 보안 서비스모델을 통하여 보안담당자들의 분석과 대응을 효율적으로 지원할 수 있는 보안관제에 대한 향후 연구방향을 제시하였다.","In this paper, we propose a method to apply artificial intelligence technology efficiently to integrated security control technology. In other words, by applying machine learning learning to artificial intelligence based on big data collected in integrated security control system, cyber attacks are detected and appropriately responded. As technology develops, many large capacity Is limited to analyzing individual logs. The analysis method should also be applied to the integrated security control more quickly because it needs to correlate the logs of various heterogeneous security devices rather than one log. We have newly proposed an integrated security service model based on artificial intelligence, which analyzes and responds to these behaviors gradually evolves and matures through effective learning methods. We sought a solution to the key problems expected in the proposed model. And we developed a learning method based on normal behavior based learning model to strengthen the response ability against unidentified abnormal behavior threat. In addition, future research directions for security management that can efficiently support analysis and correspondence of security personnel through proposed security service model are suggested."
Introduction to convolutional neural network using Keras; an understanding from a statistician,2019,"['deep neural network', 'convolutional neural network', 'image classification', 'machine learning', 'MNIST', 'CIFAR10', 'Keras']",,"Deep Learning is one of the machine learning methods to find features from a huge data using non-linear transformation. It is now commonly used for supervised learning in many fields. In particular, Convolutional Neural Network (CNN) is the best technique for the image classification since 2012. For users who consider deep learning models for real-world applications, Keras is a popular API for neural networks written in Python and also can be used in R. We try examine the parameter estimation procedures of Deep Neural Network and structures of CNN models from basics to advanced techniques. We also try to figure out some crucial steps in CNN that can improve image classification performance in the CIFAR10 dataset using Keras. We found that several stacks of convolutional layers and batch normalization could improve prediction performance. We also compared image classification performances with other machine learning methods, including K-Nearest Neighbors (K-NN), Random Forest, and XGBoost, in both MNIST and CIFAR10 dataset."
기계학습 기법을 활용한 지역아동센터 아동의 학교유형별 예측모형,2019,"['기계학습', '서포트벡터머신', '지역아동센터', '학교 유형', '학교 적응', 'Community child center', 'machine learning', 'school adaptation', 'school type', 'support vector machine']","본 연구는 지역아동센터 이용아동의 학교생활적응에 영향을 미치는 아동의 정서발달요인들을 탐색하고 이 과정에서 학교유형에 따라 조절효과가 있는지 검증한다. 또한 지역아동센터 이용아동의 정서발달요인들이 학교유형인 초등학생과 중학생에 따라 분류되는지를 기계학습(machine learning) 기법인 서포트벡터머신(SVM)을 이용하여 분류하고자 하였다. 본 연구의 데이터는 2014년부터 2017년까지 지역아동센터 아동패널에 참여한 응답자 중 초등학교 고학년 1,905명과 중학생 1,227명의 자료를 이용하였으며, 분석도구는 R(3.5.1)프로그램을 이용하였다. 본 연구결과 아동의 정서발달 등의 변수는 학교생활적응에 직접적인 영향을 미치는 것으로 나타났고, 지역아동센터 운영에 있어서 초등학생과 중학생에 대한 접근방법을 구분하는 것이 타당한 것으로 제시하였다.","This study explores children’s emotional development factors affecting the school life adaptation of children using community children center. And verify that there is a modulating effect on the type of school. The purpose of this study is to classify the emotional development factors of children using community children center by elementary school students and middle school students using the support vector machine (SVM), which is a machine learning technique. Data from this study used data from 1,905 elementary school students and 1,227 middle school students who participated in the community children center children’s panel from 2014 to 2017. The analysis tool used R (3.5.1) program. The results of this study showed that variables such as children’s emotional development directly affect school adaptation. Suggesting that it is appropriate to classify approaches to elementary and middle school students in the operation of community children centers."
Deeper Integrative Neural Network Analysis for Multi-level Omics Data,2019,"['Deep learning', 'Omics integration', 'Differential expressed genes']",,"Recently, various machine learning methods have emerged for analyzing and interpreting the ever-expanding genetic data. In addition, new analytical tools for machine learning using statistical models, are being developed. Lim et al. [1] proposed the integrative deep learning to find the differentially expressed (DE) biomarkers using deep neural network with a single hidden layer. This method consists of the input layer, a hidden layer, the consolidation layer, and the output layer. They found that integrative deep learning method is stable and robust for analysis of the variation in the simulation datasets. In this study, we expanded the integrative deep learning method by including an additional hidden layer. The present expanded method consists of the input layer, two hidden layers, the consolidation layer and the output layer. The purpose of this study is to investigate the effect of the additional hidden layers on the performance of the previous method (integrative deep learning). We conducted a simulation study and compared the results with those from deep neural network with one hidden layer."
Deeper Integrative Neural Network Analysis for Multi-level Omics Data,2019,"['Deep learning', 'Omics integration', 'Differential expressed genes']",,"Recently, various machine learning methods have emerged for analyzing and interpreting the ever-expanding genetic data. In addition, new analytical tools for machine learning using statistical models, are being developed. Lim et al. [1] proposed the integrative deep learning to find the differentially expressed (DE) biomarkers using deep neural network with a single hidden layer. This method consists of the input layer, a hidden layer, the consolidation layer, and the output layer. They found that integrative deep learning method is stable and robust for analysis of the variation in the simulation datasets. In this study, we expanded the integrative deep learning method by including an additional hidden layer. The present expanded method consists of the input layer, two hidden layers, the consolidation layer and the output layer. The purpose of this study is to investigate the effect of the additional hidden layers on the performance of the previous method (integrative deep learning). We conducted a simulation study and compared the results with those from deep neural network with one hidden layer."
Stacking Ensemble Technique for Classifying Breast Cancer,2019,"['Breast Cancer', 'Machine Learning', 'Data Analysis', 'Medical Informatics', 'Classification']",,"Objectives: Breast cancer is the second most common cancer among Korean women. Because breast cancer is strongly associated with negative emotional and physical changes, early detection and treatment of breast cancer are very important. As a supporting tool for classifying breast cancer, we tried to identify the best meta-learner model in a stacking ensemble when the same machine learning models for the base learner and meta-learner are used. Methods: We used machine learning models, such as the gradient boosted model, distributed random forest, generalized linear model, and deep neural network in a stacking ensemble. These models were used to construct a base learner, and each of them was used as a meta-learner again. Then, we compared the performance of machine learning models in the meta-learner to determine the best meta-learner model in the stacking ensemble. Results: Experimental results showed that using the GBM as a meta-learner led to higher accuracy than that achieved with any other model for breast cancer data and using the GLM as a meta learner led to low root-meansquared error for both sets of breast cancer data. Conclusions: We compared the performance of every meta-learner model in a stacking ensemble as a supporting tool for classifying breast cancer. The study showed that using specific models as a metalearner resulted in better performance than single classifiers, and using GBM and GLM as a meta-learner is appropriate as a supporting tool for classifying breast cancer data."
랜덤 포레스트를 활용한 장애인 취업 예측 모형: 취업 여부 및 정규직 취업을 중심으로,2019,"['장애인 취업', '머신 러닝', '랜덤 포레스트', '장애인고용패널', 'employment of persons with disabilities', 'machine Learning', 'random forest', 'PSED']","연구목적: 본 연구는 최근 새롭게 주목받고 있는 머신 러닝 기법을 적용하여 장애인의 취업 여부와 정규직 취업에 영향을 미치는 변수들을 탐색적으로 규명하고자 하였다. 연구방법: 장애인고용패널 2차 웨이브의 2차 연도(2017년) 자료를 대상으로 대표적인 머신러닝 기법 중 하나인 랜덤 포레스트(Random Forest)를 통하여 179개 설명변수를 활용한 장애인 취업 예측 모형의 성능을 확인하고, 장애인의 취업에 영향을 미치는 요인들을 탐색적으로 추정해보았다. 연구결과: 분석 결과, 기존의 직장경험 및 기대 임금 수준, 가계의 경제적 수준 등이 장애인의 취업에 중요한 요인임을 확인하였다. 그리고 장애인의 정규직 취업에는 직업 능력의 중요도가 상대적으로 높게 나타남을 확인하였다. 이와 함께 기존 선행연구들과 달리 주관적 인식 변수들이 장애인들의 취업 여부와 정규직 취업에 중요한 영향을 미치는 것 또한 확인하였다. 결론: 향후의 장애인 고용 지원 관련 연구 및 정책 입안에 있어 머신 러닝기법의 활용 가능성을 확인하였다는 점에서 연구의 의의를 찾을 수 있다. 그리고 그 과정에서 연구자는 단순히 머신 러닝의 결과물을 수동적으로 받아들이는 객체가 아니라 연구 과정을 주도해 나가는 주체로서 기능할 수 있도록 연구자 및 정책 입안자들의 지속적인 관심과 노력이 필요함을 제안하였다.","Objectives: The purpose of this paper is to exploratively investigate predictive variables on the employment status and quality of employment of persons with disabilities. Method: This study utilized the random forest method, one of the most representative machine learning approach. Results: Our results first show that previous working experience, expect wage, and economic status of family are the substantial variables in predicting the employment status of persons with disabilities. In terms of the quality of employment, vocational capacity of the disadvantaged has a more predictive performance relatively. Moreover, this study identified subjective variables, such as quality of life and conception regarding employment, have an important predictive power on the employment status and quality of employment of persons with disabilities. Conclusion: The findings of this study, based on new approach using machine learning method, provide useful policy implications for improving the employment status and quality of employment of persons withdisabilities."
Simulations in a Spiking Neural Network Model Based on the Free Energy Principle,2019,"['Neural network dynamics and learning', 'Free energy principle', 'Computational simulation method']",,"The Feynman machine is a neural network model in which the spike-timing-dependent firing process is described through a path integral formulation. In addition, the gradient descent in the free energy is proposed as an ideal learning rule of the model system. The unique formulation of the Feynman machine is useful for studying the substance of the firing and the learning process in a spiking neural network; however, the implementation of the Feynman machine is not a plan problem because of the difficulty in calculating the free energy. We here introduce how to perform the simulation of both the firing and the learning processes in the Feynman machine through the Monte Carlo or the numerical integral method. We demonstrate the adequacy of the methods by applying them to the firing and the learning processes in some neural systems."
자가학습 가능한 SVM 기반 가스 분류기의 설계,2019,"['gas classifier', 'machine learning', 'support vector machine', 'MSMO', 'FPGA']","본 논문은 실시간 자가학습과 분류 기능을 모두 지원하는 support vector machine (SVM) 기반 가스 분류기의 하드웨어 구조 설계 및 구현 결과를 제시한다. 제안된 가스 분류기는 학습 알고리즘으로 modified sequential minimal optimization(MSMO)을 사용하였고, 학습과 분류 기능을 공유구조를 사용하여 설계함으로써 기존 논문 대비 하드웨어 면적을 35% 감소시켰다. 설계된 가스 분류기는 Xilinx Zynq UltraScale+ FPGA를 사용하여 구현 및 검증되었고, 108MHz의 동작 주파수에서 3,337개의 CLB LUTs로 구현 가능함을 확인하였다.","In this paper, we propose a support vector machine (SVM) based gas classifier that can support real-time self-learning. The modified sequential minimal optimization (MSMO) algorithm is employed to train the proposed SVM. By using a shared structure for learning and classification, the proposed SVM reduced the hardware area by 35% compared to the existing architecture. Our system was implemented with 3,337 CLB (configurable logic block) LUTs (look-up table) with Xilinx Zynq UltraScale+ FPGA (field programmable gate array) and verified that it can operate at the clock frequency of 108MHz."
인공지능 기반 수요예측 기법의 리뷰,2019,"['빅데이터', '인공지능', '수요예측', '머신러닝', '딥 러닝', 'big data', 'artificial intelligence', 'demand forecasting', 'machine learning', 'deep learning']","최근 다양한 분야에서 ‘빅데이터’가 생성되었다. 많은 기업들은 인공지능(AI)을 기반으로 빅데이터 분석이 가능한 시스템을 구축하여 이익 창출을 시도하고 있다. 인공지능 기술을 접목함으로써 방대한 양의 데이터를 효율적으로 분석하고 효과적으로 활용하는 것은 점점 더 중요해지고 있다. 특히 재무, 조달, 생산 및 마케팅과 같은 다양한 분야에서 국가 및 기업 경영 관리에있어 최소의 오차와 최대의 정확도를 갖춘 수요예측은 절대적으로 중요한 요소이다. 이 때 각 분야의 수요패턴을 고려한 적절한 모델을 적용하는 것이 중요하다. 전통적으로 쓰이는 시계열모델이나 회귀모델로도 비대해진 실제 데이터의 복잡한 비선형적인 패턴을 분석할 수 있다.그러나 다양한 비선형 모델들 중에서 적절한 모델을 선택하는 것은 사전 지식 없이는 어려운 일이다. 최근에는 인공지능 기반의 기법들인 머신러닝이나 딥러닝 기법을 중심으로 이루어진 연구들이 이를 극복할 수 있음을 증명하고 있다. 뿐만 아니라 정형데이터와 이미지나 텍스트의 비정형 데이터 분석을 통한 수요예측도 높은 정확도를 갖춘 결과를 보이고 있다. 따라서 본 연구에서는 수요예측이 비교적 활발하게 일어나는 중요한 분야들을 나누어 설명하였다. 그리고 각 분야별로 갖는 특징적인 성격을 고려한 인공지능 기반의 수요예측 기법에 대해 머신러닝과 딥러닝 기법으로 나누어 소개하였다.","Big data has been generated in various fields. Many companies have now tried to make profits by building a system capable of analyzing big data based on artificial intelligence (AI) techniques. Integrating AI technology has made analyzing and utilizing vast amounts of data increasingly valuable. In particular, demand forecasting with maximum accuracy is critical to government and business management in various fields such as finance, procurement, production and marketing. In this case, it is important to apply an appropriate model that considers the demand pattern for each field. It is possible to analyze complex patterns of real data that can also be enlarged by a traditional time series model or regression model.However, choosing the right model among the various models is difficult without prior knowledge. Many studies based on AI techniques such as machine learning and deep learning have been proven to overcome these problems. In addition, demand forecasting through the analysis of stereotyped data and unstructured data of images or texts has also shown high accuracy. This paper introduces important areas where demand forecasts are relatively active as well as introduces machine learning and deep learning techniques that consider the characteristics of each field."
An Ensemble Approach to Domain Adaptation in Sentiment Analysis,2019,"['domain adaptation', 'ensemble learning', 'transfer learning', 'concept drift.']",,"Domain adaptation aims to predict a response variable accurately in a target domain where labeled instances are non-exist or scarce, if any, but unlabeled instances are plentiful, by utilizing as much as possible abundant labeled information in one or several related source domains. Therefore it can be considered as a transfer learning which is one of hot topics in machine learning community. Although a target domain is related to source domains in any way, the underlying distributions generating instances are different. This inevitably carries on the so called concept drift phenomenon which means the input-output dependency changes across the domains. Under the concept drift, many ensemble learning algorithms have been suggested and showed quite good results. In this paper, we apply an ensemble learning scheme for semi-supervised domain adaptation as in the concept drift learning where a penalized regression based ensemble combiner is utilized. The proposed method is applied to a sentiment classification and shows a good result."
Data analytic approach for bankruptcy prediction,2019,"['Bankruptcy prediction', 'Data analysis', 'Machine learning', 'Boosting', 'Preprocessing', 'Box&#x2013']",,"<P><B>Abstract</B></P>  <P>Bankruptcy prediction problem has been intensively studied over the past decades. From traditional statistical models to state of the art machine learning models, various predictive models are developed and applied to various datasets. However, models that use machine learning are not used in the field of business, for two main reasons. First, the prediction accuracy does not far exceed the statistical models and second, the results are not interpretable. In this study, we focused on solving the skewness which is a characteristic of financial data. By solving this problem, we obtained 17% average improvement in AUC over existing models. To address the second shortcoming, we analyze the importance of features identified by the XGBoost model. The interpretation of the model differs among categories of data. Our bankruptcy prediction model has high predictive accuracy with clear explanations and is therefore directly applicable to the industry.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Features to predict a company’s bankruptcy have highly skewed distributions. </LI> <LI>  A Box–Cox transformation is a powerful technique to remove skewness of data. </LI> <LI>  Machine learning algorithms are more suitable for bankruptcy prediction than statistical models. </LI> <LI>  By combining feature’s importance, we can understand the model. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
딥러닝 기술이 가지는 보안 문제점에 대한 분석,2019,"['인공지능', '기계학습', '딥러닝', '보안', '비즈니스모델', 'Convergence', 'AI', 'Machine Learning', 'Deep Learning', 'Security', 'Business Model']",본 논문에서는 딥러닝 기술이 인터넷과 연결된 다양한 비즈니스 분야에 새로운 형태의 비즈니스 업무에 활용할 수 있도록 보안에 관한 문제점을 분석하고자 한다. 우선 딥러닝이 비즈니스 영역에 보안 업무를 충분히 수행하기 위해서 는 많은 데이터를 가지고 반복적인 학습을 필요하게 된다. 본 논문에서 딥러닝이 안정적인 비즈니스 보안 업무를 완벽하 게 수행할 수 있는 학습적 능력을 얻기 위해서는 비정상 IP패킷에 대한 탐지 능력과 정상적인 소프트웨어와 악성코드를 탑재하여 감염 의도를 가지고 접근하는 공격을 탐지해낼 수 있는 인지 능력을 갖추고 있는지를 분석하였다. 이에 본 논문에서는 인공지능의 딥러닝 기술이 시스템에 접근하여 문제의 비즈니스 모델을 안정적으로 수행할 수 있게 하기 위해서는 시스템내의 비정상 데이터를 추출해 내고 시스템 데이터 침해를 구분해 낼 수 있는 수학적 역할의 문제점을 보완하기 위해 새로운 IP에 대한 세션 및 로그 분석을 수행할 수 있도록 보안 엔진이 탑재된 딥러닝 기술을 개발하여 비즈니스 모델에 적용시켜서 취약점을 제거하여 비즈니스 업무 능력을 향상시키도록 문제적 방안을 비교 분석하였다.,"In this paper, it will analyze security problems, so technology’s potential can apply to business security area. First, in order to deep learning do security tasks sufficiently in the business area, deep learning requires repetitive learning with large amounts of data. In this paper, to acquire learning ability to do stable business tasks, it must detect abnormal IP packets and attack such as normal software with malicious code. Therefore, this paper will analyze whether deep learning has the cognitive ability to detect various attack. In this paper, to deep learning to reach the system and reliably execute the business model which has problem, this paper will develop deep learning technology which is equipped with security engine to analyze new IP about Session and do log analysis and solve the problem of mathematical role which can extract abnormal data and distinguish infringement of system data. Then it will apply to business model to drop the vulnerability and improve the business performance."
공개 교통사고 데이터베이스와 기계 학습을 이용한 탑승자의 상해 등급 예측에 관한 연구,2019,"['NASS-CDS', 'Prediction of injury grade', 'Machine Learning', 'Decision Tree', 'Support Vector Machine', 'Logistic Regression', 'Principal Component Analysis', 'Linear Discriminant Analysis']",,"In this paper, we propose a prediction model for traffic accident injury grade using machine learning algorithm. We used machine learning models such as Decision Tree, Support Vector Machine, and Logistic Regression to predict injury grade. And to improve performance, Principal Component Analysis(PCA) or Linear Discriminant Analysis(LDA) was applied to each machine learning model. The data used in this study are based on NASS-CDS data that collects traffic accident investigation data and medical records of accident victims. According to the results, the proposed method is expected to be used in the automatic traffic accident notification system because of its reliable accuracy."
Prediction of pollution loads in the Geum River upstream using the recurrent neural network algorithm,2019,"['LSTM (long short-term memory)', 'machine learning', 'RNN (recurrent neural networks)', 'Tensorflow', 'water pollution prediction']",,"The purpose of this study was to predict the water quality using the RNN (recurrent neutral network) and LSTM (long short-term memory). These are advanced forms of machine learning algorithms that are better suited for time series learning compared to artificial neural networks; however, they have not been investigated before for water quality prediction. Three water quality indexes, the BOD (biochemical oxygen demand), COD (chemical oxygen demand), and SS (suspended solids) are predicted by the RNN and LSTM. TensorFlow, an open source library developed by Google, was used to implement the machine learning algorithm. The Okcheon observation point in the Geum River basin in the Republic of Korea was selected as the target point for the prediction of the water quality. Ten years of daily observed meteorological (daily temperature and daily wind speed) and hydrological (water level and flow discharge) data were used as the inputs, and irregularly observed water quality (BOD, COD, and SS) data were used as the learning materials. The irregularly observed water quality data were converted into daily data with the linear interpolation method. The water quality after one day was predicted by the machine learning algorithm, and it was found that a water quality prediction is possible with high accuracy compared to existing physical modeling results in the prediction of the BOD, COD, and SS, which are very non-linear. The sequence length and iteration were changed to compare the performances of the algorithms."
Character Classification with Triangular Distribution,2019,"['Image Comparison', 'Classification', 'Character Recognition', 'Feature Extraction', 'Distribution', 'Neural Network', 'Machine Learning']",,"Due to the development of artificial intelligence and image recognition technology that play important roles in the field of 4th industry, office automation systems and unmanned automation systems are rapidly spreading in human society. The proposed algorithm first finds the variances of the differences between the tile values constituting the learning characters and the experimental character and then recognizes the experimental character according to the distribution of the three learning characters with the smallest variances. In more detail, for 100 learning data characters and 10 experimental data characters, each character is defined as the number of black pixels belonging to 15 tile areas. For each character constituting the experimental data, the variance of the differences of the tile values of 100 learning data characters is obtained and then arranged in the ascending order. After that, three learning data characters with the minimum variance values are selected, and the final recognition result for the given experimental character is selected according to the distribution of these character types. Moreover, we compare the recognition result with the result made by a neural network of basic structure. It is confirmed that satisfactory recognition results are obtained through the processes that subdivide the learning characters and experiment characters into tile sizes and then select the recognition result using variances."
서울시 상업젠트리피케이션 영향요인에 관한 연구,2019,"['상권', '젠트리피케이션', '로짓분석', '기계학습', 'Commercial Area', 'Gentrification', 'Logit Analysis', 'Machine Learning']","본 연구는 2015년에서 2018년간, 자료가 축적된 서울시 158개 상권별 주요변수를 이용하여, 상업젠트리피케이션 발생에 영향을 미치는 요인을 로짓모형과 기계학습 방법론을 사용하여 분석하였다. 로짓분석 결과 log(상권 월평균임대료), 음식·소매업종 총매출대비 40세 이하 매출 비중이 유의수준 1%수준에서, 음식·소매업종 30대 여성 객단가 변화는 유의수준 5%에서, 프랜차이즈업종 2년이내 개업한 업소비율 변화는 유의수준 10%에서 유의하게 나타났다.기계학습 결과 중요도가 높은 순서는 상권 전체 바닥면적, 상권의 월평균 임대료, 40세 미만 유동인구 비율, 프랜차이즈 30대 객단가, 음식·소매업종 30대 여성 객단가 변화 등 5개이다.본 연구의 기여는 세 가지이다. 첫째, 본 연구는 서울시 전역의 상업 공간에 대한 자료를 분석하였다. 둘째, 본 연구는 상업젠트리피케이션의 발생에 영향을 미치는 요인을 실증하여, 예측지표 마련을 위한 기초연구를 제공하였다. 끝으로 기계학습 분석을 추가하여 다양한 접근방법을 소개하였다.","This study analyzes the factors that influence commercial gentrification in Seoul by using both logit model analysis and machine learning with data cumulated from 2015 to 2018 regarding 158 market areas. Logit analysis indicates that log(market area average monthly rent) and the ratio of the purchasing amount by customers aged 40 and younger to total sales in the restaurant and retail business category are statistically significant at 1%; the increase in sales per female customer aged between 30 and 39 in the restaurant and retail business category is statistically significant at 5%; and the increase in number of retailers with a business history of less than two years in the franchise business category is significant at 10%. Machine learning indicates that significant factors ordered by importance are the total retail area, the existence of an industrial complex within the market area, the existence of a traditional market within the market area, the location of subway stations within the market area, the increase of entertainment facilities such as movie theaters within the market area, average monthly rent, and the growth rate of average monthly rent.The contribution of this research is threefold. First, this study analyzes the entire commercial area of Seoul, Korea. Second, this study provides a foundation for future research on predictive indicators by empirically investigating the factors that influence commercial gentrification in Seoul. Lastly, this study introduces various methods of research by utilizing a machine learning approach."
Character Classification with Triangular Distribution,2019,"['Image Comparison', 'Classification', 'Character Recognition', 'Feature Extraction', 'Distribution', 'Neural Network', 'Machine Learning']",,"Due to the development of artificial intelligence and image recognition technology that play important roles in the field of 4th industry, office automation systems and unmanned automation systems are rapidly spreading in human society. The proposed algorithm first finds the variances of the differences between the tile values constituting the learning characters and the experimental character and then recognizes the experimental character according to the distribution of the three learning characters with the smallest variances. In more detail, for 100 learning data characters and 10 experimental data characters, each character is defined as the number of black pixels belonging to 15 tile areas. For each character constituting the experimental data, the variance of the differences of the tile values of 100 learning data characters is obtained and then arranged in the ascending order. After that, three learning data characters with the minimum variance values are selected, and the final recognition result for the given experimental character is selected according to the distribution of these character types. Moreover, we compare the recognition result with the result made by a neural network of basic structure. It is confirmed that satisfactory recognition results are obtained through the processes that subdivide the learning characters and experiment characters into tile sizes and then select the recognition result using variances."
공간 클래스 단순화를 이용한 의미론적 실내 영상 분할,2019,"['의미론적 영상 분할', '실내 공간 구조', '기계 학습', 'Semantic image segmentation', 'Indoor space structure', 'Machine Learning']","본 논문에서는 실내 공간 이미지의 의미론적 영상 분할을 위해 배경과 물체로 재설계된 클래스를 학습하는 방법을 제안한다. 의미론적 영상 분할은 이미지의 벽이나 침대 등 의미를 갖는 부분들을 픽셀 단위로 나누는 기술이다. 기존 의미론적 영상 분할에 대한 연구들은 신경망을 통해 이미지의 다양한 객체 클래스들을 학습하는 방법들을 제시해왔고, 긴 학습 시간에 비해 정확도가 부족하다는 문제가 지적되었다. 그러나 물체와 배경을 분리하는 문제에서는, 다양한 객체 클래스를 학습할 필요가 없다. 따라서 우리는 이 문제에 집중해, 클래스를 단순화 후에 학습하는 방법을 제안한다. 학습 방법의 실험 결과로 기존 방법들보다 정확도가 약 5~12% 정도 높았다. 그리고 같은 환경에서 클래스를 달리 구성했을 때 학습 시간이 약 14 ~ 60분 정도 단축됐으며, 이에 따라 물체와 배경을 분리하는 문제에 대해 제안하는 방법이 효율적임을 보인다.","In this paper, we propose a method to learn the redesigned class with background and object for semantic segmentation of indoor scene image. Semantic image segmentation is a technique that divides meaningful parts of an image, such as walls and beds, into pixels. Previous work of semantic image segmentation has proposed methods of learning various object classes of images through neural networks, and it has been pointed out that there is insufficient accuracy compared to long learning time. However, in the problem of separating objects and backgrounds, there is no need to learn various object classes. So we concentrate on separating objects and backgrounds, and propose method to learn after class simplification. The accuracy of the proposed learning method is about 5 ~ 12% higher than the existing methods. In addition, the learning time is reduced by about 14 ~ 60 minutes when the class is configured differently In the same environment, and it shows that it is possible to efficiently learn about the problem of separating the object and the background."
배경기계학습을 사용한 침입탐지시스템,2019,"['Intrusion Detection', 'network CCTV Image', 'Background Differencing Technique', 'Artificial Neural Network', 'Background Machine Learning']",,"The existing subtract image based intrusion detection system for CCTV digital images has a problem that it can not distinguish intruders from moving backgrounds that exist in the natural environment. In this paper, we tried to solve the problems of existing system by designing real - time intrusion detection system for CCTV digital image by combining subtract image based intrusion detection method and background learning artificial neural network technology. Our proposed system consists of three steps: subtract image based intrusion detection, background artificial neural network learning stage, and background artificial neural network evaluation stage. The final intrusion detection result is a combination of result of the subtract image based intrusion detection and the final intrusion detection result of the background artificial neural network.  The step of subtract image based intrusion detection is a step of determining the occurrence of intrusion by obtaining a difference image between the background cumulative average image and the current frame image. In the background artificial neural network learning, the background is learned in a situation in which no intrusion occurs, and it is learned by dividing into a detection window unit set by the user. In the background artificial neural network evaluation, the learned background artificial neural network is used to produce background recognition or intrusion detection in the detection window unit. The proposed background learning intrusion detection system is able to detect intrusion more precisely than existing subtract image based intrusion detection system and adaptively execute machine learning on the background so that it can be operated as highly practical intrusion detection system."
기술용어 분산표현을 활용한 특허문헌 분류에 관한 연구,2019,"['Patent Literature Classification', 'Distributed Representation', 'Word Embedding Vector', 'Deep Learning', '특허문헌 분류', '분산표현', '워드 임베딩 벡터', '딥러닝']","본 연구의 목적은 특허 문헌 분류에 가장 적합한 방법론을 발견하기 위하여 다양한 자질 추출 방법과 기계학습 및 딥러닝 모델을 살펴보고 실험을 통해 최적의 성능을 제공하는 방법론을 분석하는데 있다. 자질 추출 방법으로는 전통적인 BoW 방법과 분산표현 방식인 워드 임베딩 벡터를 비교 실험하고, 문헌 집합 구축 방식으로는 형태소 분석과 멀티그램을 이용하는 방식을 비교 검토하였다. 또한 전통적인 기계학습 모델과 딥러닝 모델을 이용하여 분류 성능을 검증하였다. 실험 결과, 분산표현 방법과 형태소 분석을 이용한 자질추출 방법을 기반으로 딥러닝 모델을 적용하였을 경우에 분류 성능이 가장 우수한 것으로 판명되었으며 섹션, 클래스, 서브클래스 분류 실험에서 전통적인 기계학습 방법에 비해 각각 5.71%, 18.84%, 21.53% 우수한 분류 성능을 보여주었다.","In this paper, we propose optimal methodologies for classifying patent literature by examining various feature extraction methods, machine learning and deep learning models, and provide optimal performance through experiments. We compared the traditional BoW method and a distributed representation method (word embedding vector) as a feature extraction, and compared the morphological analysis and multi gram as the method of constructing the document collection. In addition, classification performance was verified using traditional machine learning model and deep learning model. Experimental results show that the best performance is achieved when we apply the deep learning model with distributed representation and morphological analysis based feature extraction. In Section, Class and Subclass classification experiments, We improved the performance by 5.71%, 18.84% and 21.53%, respectively, compared with traditional classification methods."
심층신경망 알고리즘을 이용한 가상환경에서의 멀미 측정,2019,"['가상현실', '사이버 멀미', '뇌파', '딥러닝', 'Virtual Reality (VR)', 'Cybersickness', 'EEG', 'Deep Learning']","사이버 멀미는 VR 체험 중 발생하는 증상으로, 주로 감각과 인지 시스템 사이의 불일치로 인해 발생하는 것으로 추정된다. 하지만 감각 및 인지 시스템을 객관적으로 측정할 수 있는 방법이 없기 때문에, 사이버 멀미를 측정하는 것은 어렵다. 이를 해결하기 위해 사이버 멀미를 측정하기 위해 다양한 방법론들이 연구되고 있다. 기존의 멀미를 측정하기 위한 방법은 설문 방식을 이용하거나, 머신 러닝을 이용하여 뇌파 데이터를 분석하는 방식으로 진행되어 왔다. 하지만 설문을 이용한 방식은 객관성이 떨어지며, 머신 러닝을 사용하는 방식은 아직 정확한 측정이 불가능하다. 본 논문에서는 뇌파 데이터를 Deep Neural Network (DNN) 딥러닝 알고리즘에 적용하여 객관적인 사이버 멀미 측정 방식을 제안한다. 또한 우리는 더 정확한 사이버 멀미 측정 결과를 위하여 딥러닝 네트워크 구조와 뇌파 데이터 전처리 기법을 제안한다. 우리의 접근 방법은 최대 98.88%의 정확도로 사이버 멀미를 측정한다. 또한 우리는 실험에서 사이버 멀미를 유발하는 영상의 특성을 분석한다. 일반적으로 사이버 멀미는 상하 움직임이 심한 화면, 화면의 지속적이고 빠른 전환, 공중에 떠있는 상황에서 발생한다.","Cybersickness is a symptom of dizziness that occurs while experiencing Virtual Reality (VR) technology and it is presumed to occur mainly by crosstalk between the sensory and cognitive systems. However, since the sensory and cognitive systems cannot be measured objectively, it is difficult to measure cybersickness. Therefore, methodologies for measuring cybersickness have been studied in various ways. Traditional studies have collected answers to questionnaires or analyzed EEG data using machine learning algorithms. However, the system relying on the questionnaires lacks objectivity, and it is difficult to obtain highly accurate measurements with the machine learning algorithms. In this work, we apply Deep Neural Network (DNN) deep learning algorithm for objective cybersickness measurement from EEG data. We also propose a data preprocessing for learning and network structures allowing us to achieve high performance when learning EEG data with the deep learning algorithms. Our approach provides cybersickness measurement with an accuracy up to 98.88%. Besides, we analyze video characteristics where cybersickness occurs by examining the video segments causing cybersickness in the experiments. We discover that cybersickness happens even in unusually persistent changes in the darkness such as the light in a room keeps switching on and off."
에이다 부스트를 활용한 건설현장 추락재해의 강도 예측과 영향요인 분석,2019,"['건설안전', '추락재해', '데이터 사이언스', '기계학습', '에이다 부스트', 'Construction Safety', 'Fall Accidents', 'Data Science', 'Machine Learning', 'Adaboost']",본 연구는 추락재해에 영향을 미치는 다양한 변수들을 고려하여 특징 중요도를 도출하고 중대 재해 요인을 분석하였다. 추락재해로 인해 발생한 업무상 재해 정도를 예측하고 분류하기 위해 의사결정나무를 에이다 부스트에 결합하고 HyperOpt를 활용하여 하이퍼 파라미터를 최적화하고 계층별 k-겹 교차검증을 조합하여 일반화하였다. 특징 중요도는 Permutation 기법으로 추출하여 추락재해에 영향을 미치는 요인들을 분석하였다.,"The construction industry is the highest safety accident causing industry as 28.55% portion of all industries’ accidents in Korea. In particular,falling is the highest accidents type composed of 60.16% among the construction field accidents. Therefore, we analyzed the factors of majordisaster affecting the fall accident and then derived feature importances by considering various variables. We used data collected from KoreaOccupational Safety & Health Agency (KOSHA) for learning and predicting in the proposed model. We have an effort to predict the degree of occupational fall accidents by using the machine learning model, i.e., Adaboost, short forAdaptive Boosting. Adaboost is a machine learning meta-algorithm which can be used in conjunction with many other types of learningalgorithms to improve performance. Decision trees were combined with AdaBoost in this model to predict and classify the degree ofoccupational fall accidents. HyOperpt was also used to optimize hyperparameters and to combine k-fold cross validation by hierarchy. Weextracted and analyzed feature importances and affecting fall disaster by permutation technique. In this study, we verified the degree of fall accidents with predictive accuracy. The machine learning model was also confirmed to beapplicable to the safety accident analysis in construction site. In the future, if the safety accident data is accumulated automatically in thenetwork system using IoT(Internet of things) technology in real time in the construction site, it will be possible to analyze the factors andtypes of accidents according to the site conditions from the real time data."
"미국과 비교한 자율주행자동차의 개발 현황과 한국 개발규제체계의 개선 방향 -기술적 특성, 자동차안전기준, 규제기관, 도로시험주행을 중심으로",2019,"['automated vehicles', 'regulatory framework (on development of automated vehicles)', 'test drive on public roads', 'motor vehicle (automobile) safety standards', 'Machine Learning Artificial Intelligence', 'ride-sharing app', '자율주행자동차', '개발규제체계', '도로시험주행', '자동차안전기준', '머신러닝 인공지능', '승차공유 앱']","최근 미국에서는 사고 감소를 통한 안전성 향상을 목적으로 인간 운전자의 물리적 지배나 감시 없이도 운행할 수 있으며 때에 따라서는 인간 운전자를 운전에서 배제할 목적의 고수준의 자율주행자동차(이하 ‘HAVs’)를 바로 개발·시험하는 혁신적 접근법을 취하는 Google의 자회사인 Waymo 등 기술기업들의 주도로 자율주행자동차 개발이 급속히 진행되고 있다. 이에 비해 전통적 자동차 제조업체를 중심으로 진행되는 한국의 자율주행자동차 개발은 상대적으로 지지부진하다.다양한 센서에 의해 수집된 시각정보를 바탕으로 머신러닝 인공지능이 운행하는 HAVs는 급속히 개발 중인 혁신기술로 불확정성을 가진데다가 관련 빅데이터가 쌓일수록 학습에 따라 그 예측능력이 향상되는 머신러닝 인공지능의 소프트웨어로서의 특성에 영향을 강하게 받는다. 따라서 전통적인 자동차와 같이 공중으로부터 분리된 시험시설과 규제기관이 설정한 구체적 자동차안전기준을 통해 개발하기 보다는 HAVs의 개발을 촉진하기 위해서는 개발자들의 자율성을 바탕으로 다양한 차량과 보행자가 존재하는 공공도로에서 시험주행을 통한 기술개발과 안전성 입증이 최선일 수 있다. 또한 그 과정에서는 전통적 자동차에서 중요한 구조와 기능과 같은 자동차안전기준의 설정만이 아니라 HAVs 관련 교통사고의 발생을 조사할 중립성과 전문성을 가진 조사기관의 역할, HAVs의 발전단계에 따라 탄력적으로 도로시험주행을 허가·감독할 수 있는 도로시험주행 제도와 함께 HAVs의 개발 시 관련 빅데이터의 제공, 소비자의 수용을 촉진하는 역할을 하는 승차공유 앱의 도입과 같은 관련 제도의 개선 역시 개발규제체계에서 중요한 축을 담당한다.이 글은 미국 고속도로교통안전청을 중심으로 미국 연방정부가 자동차개발에 관해 연방자동차안전기준의 자기인증제를 바탕으로 HAVs에 개발에 관해 취하고 있는 자율적 규제체계와 상호 대비되는 도로시험주행 허가제도와 지향점을 가진 미시간주와 캘리포니아주의 경쟁을 중심으로 미국의 주 정부에서 자율주행자동차 개발규제체계 역할과 그에 따른 HAVs 개발에의 영향을 살펴보았다. 그리고 미국에서의 경험을 통해 상대적으로 경직적인 한국의 현재 자율주행자동차 개발규제체계가 시급히 개선해야 할 문제점을 제시해 보았다.","Recently, in seeking to improve safety by reducing car accidents, the development of automated vehicles has progressed rapidly in the U.S. led by tech companies like Waymo, subsidiary of Google, which pursue an aggressive all-in approach to immediately develop and test highly automated vehicles (hereafter “HAVs”) capable of driving without a human’s physical control or monitoring. On the contrary, Korea’s development of automated vehicles led by traditional automakers is stagnant.HAVs, operated by Machine Learning Artificial Intelligence (hereafter “Machine Learning AI”) based on visual information collected by various sensors, is one of the rapidly developing innovative technologies. Not only does it embody uncertainty, but also considerably influenced by the software characteristics of Machine Learning AI in which predictability enhances by learning as more Big Data is accumulated. Therefore, unlike how traditional automobiles are manufactured (i.e., based on test facilities separated from the public and specific automobile safety standards established by regulatory bodies), the most optimal means to accelerate the development of HAVs is by technological development and safety verification through test drives on public roads where diverse vehicles pass by and pedestrians walk across whilst ensuring developer autonomy. Moreover, the pillars of the regulatory framework on the development of HAVs include the need to establish vehicle safety standards related to vehicle structure and function as well as policy implementations and improvements pertaining to (i) the role of agencies capable of neutrally and professionally investigating car accidents, (ii) the flexible granting of permission and monitoring of test drives depending on the development phase of HAVs, and (iii) the introduction of a sharing-ride app that provides Big Data related to the development of HAVs and promotes customer acceptance.This paper explores: (a) the regulatory framework on the development of HAVs in the U.S. led by the National Highway Traffic Safety Administration (NHTSA), which is based on the self-certification of the Federal Motor Vehicle Safety Standards (FMVSS); (b) the regulatory role of state governments regarding the development of automated vehicles, namely, Michigan and California on opposite sides as to the permission of test driving HAVs on public roads; and (c) the issues of the slow-paced establishment of the regulatory framework on automated vehicles in Korea benchmarking the U.S."
에이다 부스트를 활용한 건설현장 추락재해의 강도 예측과 영향요인 분석,2019,"['건설안전', '추락재해', '데이터 사이언스', '기계학습', '에이다 부스트']",,"The construction industry is the highest safety accident causing industry as 28.55% portion of all industries' accidents in Korea. In particular, falling is the highest accidents type composed of 60.16% among the construction field accidents. Therefore, we analyzed the factors of major disaster affecting the fall accident and then derived feature importances by considering various variables. We used data collected from Korea Occupational Safety & Health Agency (KOSHA) for learning and predicting in the proposed model. We have an effort to predict the degree of occupational fall accidents by using the machine learning model, i.e., Adaboost, short for Adaptive Boosting. Adaboost is a machine learning meta-algorithm which can be used in conjunction with many other types of learning algorithms to improve performance. Decision trees were combined with AdaBoost in this model to predict and classify the degree of occupational fall accidents. HyOperpt was also used to optimize hyperparameters and to combine k-fold cross validation by hierarchy. We extracted and analyzed feature importances and affecting fall disaster by permutation technique. In this study, we verified the degree of fall accidents with predictive accuracy. The machine learning model was also confirmed to be applicable to the safety accident analysis in construction site. In the future, if the safety accident data is accumulated automatically in the network system using IoT(Internet of things) technology in real time in the construction site, it will be possible to analyze the factors and types of accidents according to the site conditions from the real time data."
Evaluation of Topology Optimization Objectives in IP Networks,2019,"['Machine learning', 'network optimization', 'neural networks', 'optimization objectives', 'topology optimization.']",,"In the past, various optimization objective functions havebeen proposed to help in network optimization, especially for usein traffic engineering (TE) and topology optimization. This varietyof optimization objectives resulted in the emergence of algorithmstargeting different objectives. However, the role of the objectivefunction has been largely overlooked. Because, the choiceof a particular objective function was not justified in most of thecases. Some researchers criticized this arbitrary selection of objectivefunctions. Even though some researchers intuitively suggestusing a specific objective, only few work tackled with the problemof evaluating the objectives. In this paper, we evaluate various networkoptimization objectives on topology optimization. Previously,a study analyzed the efficiency of some routing optimization objectivesusing linear programming (LP) by linear relaxation. However,some of the objective functions are nonlinear, and such a linear relaxationdoes not treat each objective equally.The difficulty arisesdue to the fact that optimization algorithms are objective functiontailored heuristics. To achieve fairness, we compare and analyzedifferent traffic optimization objectives for topology optimizationusing neural networks which are used to model nonlinear relations.By using neural networks, we strive to avoid any unfairness, suchas obviating linear approximation. Also, our work suggests whichfeatures are meaningful for machine learning in network optimization.Our method partially agrees with the previous work, and weconclude that delay is the best performing optimization objective."
Performance Analysis of Classification Techniques of Human Brain MRI Images,2019,"['Machine learning', 'Deep learning', 'Support vector machine', 'Discrete wavelet transformation', 'Convolutional neural network', 'Autoencoder']",,"Artificial intelligence enhances the boundaries and capabilities of medical imaging. Hence, researchers are continuously attempting to develop an efficient and automated diagnosis system to increase the accuracy and performance to diagnose the brain abnormality. Therefore, it is required that a suitable method to diagnose and classify brain-related diseases such as Alzheimer disease, cancer, dementia, etc. Magnetic resonance imaging (MRI) is a powerful imaging technique in neuroscience for studying brain images. In the past years, many brain MRI classification techniques were proposed. Machine learning and deep learning have demonstrated a wonderful performance in the classification task. In this paper, the study of various brain MRI classification techniques has been provided. The aim of this study is to help the doctors/neurologists in selection of appropriate classification method based on several parameters like accuracy, computer complexity, and low training data availability. We also analyze and compare the performance of different classification methods based on several evaluation metrics."
Toward a grey box approach for cardiovascular physiome,2019,"['Machine learning', 'Mathematical model', 'Patient-specific modeling']",,"The physiomic approach is now widely used in the diagnosis of cardiovascular diseases. There are two possible methods for cardiovascular physiome: the traditional mathematical model and the machine learning (ML) algorithm. ML is used in almost every area of society for various tasks formerly performed by humans. Specifically, various ML techniques in cardiovascular medicine are being developed and improved at unprecedented speed. The benefits of using ML for various tasks is that the inner working mechanism of the system does not need to be known, which can prove convenient in situations where determining the inner workings of the system can be difficult. The computation speed is also often higher than that of the traditional mathematical models. The limitations with ML are that it inherently leads to an approximation, and special care must be taken in cases where a high accuracy is required. Traditional mathematical models are, however, constructed based on underlying laws either proven or assumed. The results from the mathematical models are accurate as long as the model is. Combining the advantages of both the mathematical models and ML would increase both the accuracy and efficiency of the simulation for many problems. In this review, examples of cardiovascular physiome where approaches of mathematical modeling and ML can be combined are introduced."
안면 정보를 이용한 나이브 베이즈 기반 고중성지방혈증 예측 모델,2019,"['Machine Learning', 'Facial Characteristics', 'Hypertriglyceridemia', 'Predictive Model', '기계학습', '안면 정보', '고중성지방혈증', '예측 모델']",,"Recently, machine learning and data mining have been used for many disease prediction and diagnosis. Chronic diseases account for about 80% of the total mortality rate and are increasing gradually. In previous studies, the predictive model for chronic diseases use data such as blood glucose, blood pressure, and insulin levels. In this paper, world's first research, verifies the relationship between dyslipidemia and facial characteristics, and develops the predictive model using machine learning based facial characteristics. Clinical data were obtained from 5390 adult Korean men, and using hypertriglyceridemia and facial characteristics data. Hypertriglyceridemia is a measure of dyslipidemia. The result of this study, find the facial characteristics that highly correlated with hypertriglyceridemia. FD_43_143_aD (p<0.0001, Area Under the receiver operating characteristics Curve(AUC)=0.652) is the best indicator of this study. FD_43_143_aD means distance between mandibular. The model based on this result obtained AUC value of 0.662. These results will provide a basis for predicting various diseases with only facial characteristics in the screening stage of disease epidemiology and public health in the future."
제조공정 단말PC 작업자 접속 로그를 통한 이상 징후 탐지 모델 연구,2019,"['Machine Learning', 'Anomaly Detection', 'Feature Selection']","기업에서 내부자에 의한 기업 기밀 유출 방지는 기업의 생존을 위한 필수 과제이다. 내부자에 의한 정보유출 사고를 막기 위해 기업에서는 보안 솔류션을 도입하여 적용하고 있으나 접근 권한이 있는 내부자의 이상행위를 효과적으로 탐지하는 데에는 한계가 있다. 이번 연구에서는 기업의 제품 제조 이력, 품질 정보 등을 담고 있는 제조정보시스템의 작업자 작업화면 접근 로그 데이타를 기계학습 기법의 비지도학습 알고리즘을 활용하여 정상적인 접근 로그와비정상적인 접근 로그를 효과적으로 군집화하는 방법을 연구하여 이상징후 탐지를 위한 최적화된 속성 선택 모델을제시하고자 한다.","Prevention of corporate confidentiality leakage by insiders in enterprises is an essential task for the survival of enterprises.In order to prevent information leakage by insiders, companies have adopted security solutions, but there is a limit toeffectively detect abnormal behavior of insiders with access privileges. In this study, we use the Unsupervised Learningalgorithm of the machine learning technique to effectively and efficiently cluster the normal and abnormal access logs of theworker's work screen in the manufacturing information system, which includes the company's product manufacturing historyand quality information. We propose an optimal feature selection model for anomaly detection by studying clusteringmethods."
다중 클라이언트 환경에서 동형 암호를 이용한 프라이버시 보장형 K-평균 클러스터링,2019,"['Privacy preservation', 'K-means clustering', 'homomorphic encryption', '프라이버시 보장', 'K-평균 클러스터링', '동형 암호']","기계 학습은 다양한 현상의 예측 및 분석 등을 가장 정확하게 수행하는 기술 중 하나이다. K-평균 클러스터링은 주어진 데이터들을 비슷한 데이터들의 군집으로 분류하는 기계 학습 기법의 한 종류로 다양한 분야에서 사용된다. K-평균 클러스터링의 성능을 높이기 위해서는 가능하면 많은 데이터에 기반한 분석을 수행하는 것이 바람직하므로, K-평균 클러스터링은 데이터를 제공하는 다수의 클라이언트들과 제공받은 데이터들을 사용하여 클러스터의 중심값을 계산하는 서버가 있는 모델에서 수행될 수 있다. 그러나 이 모델은 클라이언트들의 데이터가 민감한 정보를 포함하고 있는 경우, 서버가 클라이언트들의 프라이버시를 침해할 수 있다는 문제점이 있다. 본 논문에서는 다수의 클라이언트가 있는 모델에서 이러한 문제를 해결하기 위해 동형 암호를 사용하여 클라이언트의 프라이버시를 보호하며 기계 학습을 수행할 수 있는 프라이버시 보장형 K-평균 클러스터링 방법을 제안한다.","Machine learning is one of the most accurate techniques to predict and analyze various phenomena. K-means clustering is a kind of machine learning technique that classifies given data into clusters of similar data. Because it is desirable to perform an analysis based on a lot of data for better performance, K-means clustering can be performed in a model with a server that calculates the centroids of the clusters, and a number of clients that provide data to server. However, this model has the problem that if the clients’ data are associated with private information, the server can infringe clients’ privacy. In this paper, to solve this problem in a model with a number of clients, we propose a privacy-preserving K-means clustering method that can perform machine learning, concealing private information using homomorphic encryption."
윈도우 기반의 광학문자인식을 이용한 영상 번역 시스템 구현,2019,"['Machine learning', 'Optical Character Recognition', 'Image translator', 'Machine translation', 'Video translation', '기계학습', '광학문자인식(OCR)', '이미지 번역기', '기계번역', '영상 번역']","기계학습 연구가 발달함에 따라 번역 분야 및, 광학 문자 인식(Optical Character Recognition, OCR) 등의이미지 분석 기술은 뛰어난 발전을 보였다. 하지만 이 두 가지를 접목시킨 영상 번역은 기존의 개발에 비해 그 진척이더딘 편이다. 본 논문에서는 기존의 OCR 기술과 번역기술을 접목시킨 이미지 번역기를 개발하고 그 효용성을 검증한다. 개발에 앞서 본 시스템을 구현하기 위하여 어떤 기능을 필요로 하는지, 기능을 구현하기 위한 방법은 어떤 것이있는지 제시한 뒤 각기 그 성능을 시험하였다. 본 논문을 통하여 개발된 응용프로그램으로 사용자들은 좀 더 편리하게번역에 접근할 수 있으며, 영상 번역이라는 특수한 환경으로 한정된 번역기능에서 벗어나 어떠한 환경에서라도 제공되는 편의성을 확보하는데 기여할 수 있을 것이다.","As the machine learning research has developed, the field of translation and image analysis such as optical character recognition has made great progress. However, video translation that combines these two is slower than previous developments. In this paper, we develop an image translator that combines existing OCR technology and translation technology and verify its effectiveness. Before developing, we presented what functions are needed to implement this system and how to implement them, and then tested their performance. With the application program developed through this paper, users can access translation more conveniently, and also can contribute to ensuring the convenience provided in any environment."
Toward a grey box approach for cardiovascular physiome,2019,"['Machine learning', 'Mathematical model', 'Patient-specific modeling']",,"The physiomic approach is now widely used in the diagnosis of cardiovascular diseases. There are two possible methods for cardiovascular physiome: the traditional mathematical model and the machine learning (ML) algorithm. ML is used in almost every area of society for various tasks formerly performed by humans. Specifically, various ML techniques in cardiovascular medicine are being developed and improved at unprecedented speed. The benefits of using ML for various tasks is that the inner working mechanism of the system does not need to be known, which can prove convenient in situations where determining the inner workings of the system can be difficult. The computation speed is also often higher than that of the traditional mathematical models. The limitations with ML are that it inherently leads to an approximation, and special care must be taken in cases where a high accuracy is required. Traditional mathematical models are, however, constructed based on underlying laws either proven or assumed. The results from the mathematical models are accurate as long as the model is. Combining the advantages of both the mathematical models and ML would increase both the accuracy and efficiency of the simulation for many problems. In this review, examples of cardiovascular physiome where approaches of mathematical modeling and ML can be combined are introduced."
지역별 정책제시를 위한 자기조직화지도 기반의 군집분석과 평가,2019,"['자기조직화지도', '머신러닝', '데이터마이닝', '군집분석', '지역정책제시', 'Self-Organising Map', 'Machine Learning', 'Data Mining', 'Cluster Analysis', 'Regional Policy Recommendation']","지역은 그들만의 고유한 특징을 가지고 있어 상이한 특성을 지닌 지역들은 일괄적으로 적용되는 정책이 아닌 지역적 차별성이 고려된 지역의 실정에 맞는 정책의 결정과 시행이 필요하다. 하지만 군집분석을 활용한 지역별 정책제시는 공간적 특성 도출을 위한 군집분석 방법의 선택, 사용된 데이터의 양과 질, 군집분석 결과에 따른 정책의 논리적 도출 등에서 한계를 보였다. 본 연구는 지역적, 공간적 특성을 대변하는 변수를 바탕으로 군집분석을 수행하기 위해 머신러닝기법 중 하나인 자기조직화지도(Self-Organising Map; SOM)를 활용하여 도시 공간구조가 복잡하며 사회분화의 정도가 높은 서울의 군집분석을 실시하고, 이를 활용한 지역별 정책제시 과정을 평가하였다. 서울시는 소득, 교육, 삶의 질 등의 측면에서 각 군집별로 확연한 차이를 보였으며, 지역적 특성이 서울시 내에서도 분화되어 다핵화 되고 있음을 확인할 수 있었다. 이를 바탕으로 군집의 공간적 맥락과 특성을 함께 고려하여 지역의 특성에 따라 우선적으로 제정 및 시행이 요구되는 정책들을 행정구역 단위로 도출하였다. 이러한 과정의 평가를 통해 ‘SOM을 통한 군집분석’이 빅데이터를 활용한 지역별 정책결정에 보다 객관적인 근거자료를 제공할 수 있음을 증명하였지만, 정책제시 과정에서 사용된 데이터의 잠재력을 충분히 반영하지 못할 수도 있음을 발견하였다. SOM을 다변량 데이터 분석에 적용해 도출된 본 연구의 결과는 지역의 특성을 고려한 정책수립 과정과 공간분석을 통한 정책제시 연구에 중요한 실무적, 학술적 시사점을 제공할 것으로 판단된다.","Regions have their own unique characteristics, yet it is not easy to effectively take account of such features when making policy to tackle various social and public issues. For that, it is necessary to establish and implement policies that are consistent with regional conditions. However, suggesting regional policy through cluster analyses showed limitations in selecting a cluster analysis method for deriving spatial characteristics, the amount and quality of data used, and linking cluster analysis results with policies that should be recommended. In this study, the Self-Organising Map (SOM), one of prominent machine learning techniques, was utilised to conduct a cluster analysis in Seoul, and the process of regional policy recommendations was evaluated. As a result of the cluster analysis, Seoul was divided into eight clusters representing unique characteristics. Based on this, policies were derived on a cluster basis, considering both the spatial context and characteristics of the clusters. Through the analysis process with SOM, which exploits big data, we demonstrated that it can provide more objective evidence for making regional policy decisions. However, it was also found that variables that did not exhibit noticeable characteristics were likely to be ignored when using SOM for performing such cluster analysis, and for making policy suggestions. It was anticipated that the results of this study could be used as a valuable reference when planning and establishing policies by taking account of regional characteristics."
결정트리와 전문가시스템을 이용한 BIM설계 공간용도 지식화 방안,2019,"['BIM', 'Machine Learning', 'Decision Tree', 'Expert System', 'Rule', 'Space Layout']",,This study is to intellectualize the existing building designs by extracting experience knowledge from BIM data not from human experts in order to secure expert knowledge in measuring the space layout quality. We extract expert rules from a decision tree generated by machine learning the space information in BIM data. This allows us to generate quantitative presentation of expert knowledge which has no concrete expression. Our study shows that it is possible to obtain rules only from data without any help of architects and overcome the challenge of securing their experience and knowledge in designs. This result suggests a way of measuring and evaluating the qualititive and logical space allocation which has been a challanging issue in the industry.
경영 시뮬레이션 게임에서 PPO 알고리즘을 적용한 강화학습의 유용성에 관한 연구,2019,"['Reinforcement Learning(강화학습)', 'Proximal Policy Optimization Algorithm(근위정책 최적화알고리즘)', 'Game Agent(게임 에이전트)']",본 논문에서는 경영 시뮬레이션 게임 분야에서 강화학습을 적용하여 게임 에이전트들이 자율적으로 주어진 목표를 달성하는지를 확인하고자 한다. 본 시스템에서는 Unity Machine Learning (ML) Agent 환경에서 PPO (Proximal Policy Optimization) 알고리즘을 적용하여 게임 에이전트가 목표를 달성하기 위해 자동으로 플레이 방법을 찾도록 설계하였다. 그 유용성을 확인하기 위하여 5가지의 게임 시나리오 시뮬레이션 실험을 수행하였다. 그 결과 게임 에이전트가 다양한 게임 내 환경 변수의 변화에도 학습을 통하여 목표를 달성한다는 것을 확인하였다.,"In this paper, we apply reinforcement learning in the field of management simulation game to check whether game agents achieve autonomously given goal. In this system, we apply PPO (Proximal Policy Optimization) algorithm in the Unity Machine Learning (ML) Agent environment and the game agent is designed to automatically find a way to play. Five game scenario simulation experiments were conducted to verify their usefulness. As a result, it was confirmed that the game agent achieves the goal through learning despite the change of environment variables in the game."
연극영화교과와 NCS 기반 교육과정: 서울방송고등학교 사례를 중심으로,2019,"['NCS learning module', 'curriculum', 'vocation schools', 'theater film', 'FGI', 'NCS 학습모듈', '교육과정', '특성화고', '연극영화', 'FGI(Focus Group Interview)']","‘학벌이 아닌 능력중심사회 구현’을 위해 2015년부터 시작된 국가직무능력표준(NCS) 기반으로 한 고교 직업교육과정 도입은 특성화고․마이스터고 전체대상으로 진행되고 있다. 기계, 전기․전자와 같은 현장 작업의 순서가 명확한 공업계에서는 NCS 교육과정이 효율적으로 자리 잡고 있지만, 예술의 특성을 가진 영상 관련 특성화고등학교에서는 NCS 학습모듈의 정형화된 접근이 창의성을 저해하는 요인으로 작용할 수 있다. 이러한 문제점을 바탕으로 서울방송고등학교에서 진행되고 있는 NCS 교육과정의 학습모듈, 학습내용의 문제점를분석하고, ‘일-교육-자격’이 연계될 수 있는 NCS 효율성 제고를 위한방안을 제안하고자 하였다.이를 위해 NCS 교육과정을 운영한 교사 5명을 선정하여 Focus Group Interview(FGI)를 실시했다. 분석결과, 산업체 수요를 반영한교육체제가 구성되어야 하며, 지속적인 모듈 개선 및 중소기업 중심의 실무협의 내용을 교육에 반영해야 하며, 세부적 기능보다는 생각중심의 교육과정, 기업에서 요구하는 인력체제 구축을 위해 실습 설비 및 기자재 구축이 시급한 요구사항으로 도출되었다. 본 연구의 제한점으로 서울방송고등학교에서 활용되는 두 개 학습모듈의 제한된범위 안에서 교육과정을 분석하였으며, 추후 후속연구에서 다양한 학습모듈에 대한 분석을 제안한다.","NCS (National Competence Standards) curriculum has been implemented to all vocation high schools and Meister high schools. While NCS curriculum has efficiently settled down in machine, electrical, and electronic fields which have clear working procedures, the stereotypical approach of learning models of NCS may hinder the creativity at art schools. In this study, we analyzed the NCS learning modules do Seoul Broadcasting Highschool and suggested the measures for enhancing the efficiency of NCS by the frame of ‘Work-Education-Qualification.’ As research methods, Focus Group Interview (FGI) was organized to discuss NCS curriculum. The research results show that education and training system need to be aligned with the demand of industries.Also, continuous module of NCS improvement is needed reflecting requests of labor markets and thought-centered education instead of specific technical skills. Furthermore, it is necessary to arrange classroom equipment and apparatus at the right place for skilled graduates required by labor makets. This study is limited in analyzing the curriculum of Seoul Broadcasting High School and suggests further analysis of related learning modules of NCS curriculum."
DANN : 이산 산술 신경망,2019,"['DANN', 'Discrete Arithmetic Neural Networks', 'Deep Learning', 'Machine Learning', 'Boolean Space', 'DANN', '이산 산술 신경망', '딥 러닝', '기계 학습', '부울 공간']",,"Deep learning is a kind of machine learning, and a proper function between the input value and the result value is obtained through the back propagation algorithm. However, deep running is a phenomenon that attempts to memorize the training value rather than deducing the pattern of the training value, which shows overfitting phenomenon that the reasoning ability is greatly reduced for the data that deviates from the training value. To solve this problem, we propose an DANN to solve the problem by limiting input and output values ​​of real space to Boolean space. DANN shows that if the input and output values ​​can be limited to boolean spaces, we can design a deep running using only Boolean algebra. However, since Boolean algebra alone can not implement a back propagation algorithm, it imitates a Boolean operation using the float appropriately. As a result, it shows better performance when using Boolean space than using existing deep running algorithms such as LSTM."
Artificial Intelligence based framework for efficient management of resources in data centers,2019,"['Data Center', 'Machine Learning', 'Recource Management', 'HDFS', 'Distributed Processing System', '데이터센터', '머신러닝', '리소스 관리', '하둡파일시스템', '분산처리 시스템']",,"Recent technological advancement has enabled the creation of large scale data (big data) in different domains which have raised the need for large data centers to process and analyze that big data in an efficient fashion. The incremental amount of data has made job scheduling and resource management an essential and challenging component of modern-day data centers. Therefore, in this paper, we have proposed a novel artificial intelligence based framework to enhance the data center performance by improving resource management and job scheduling mechanisms. We have used machine learning to predict resource utilization based on user demand over a particular time span for resource management and improved ant colony algorithm to job scheduling. Results generated from framework simulation demonstrates that predicting future demands aids prediction of future resource utilization and enables efficient job scheduling that reduce the number of running nodes by 10% and increase throughput by 15% from traditional resource management and job scheduling methods. Based on our simulation results be to argue that by using artificial intelligence and machine learning we can improve overall performance or modern-day data centers by efficient resource allocation and job scheduling."
Analysis of Open-Source Hyperparameter Optimization Software Trends,2019,"['Hyperparameter Optimization', 'Machine Learning', 'Deep Learning', 'AutoML']",,"Recently, research using artificial neural networks has further expanded the field of neural network optimization and automatic structuring from improving inference accuracy. The performance of the machine learning algorithm depends on how the hyperparameters are configured. Open-source hyperparameter optimization software can be an important step forward in improving the performance of machine learning algorithms. In this paper, we review open-source hyperparameter optimization softwares."
Artificial Intelligence for Adult Spinal Deformity,2019,"['Artificial intelligence', 'Machine learning', 'Spinal deformity', 'Technology']",,"Adult spinal deformity (ASD) is a complex disease that significantly affects the lives of many patients. Surgical correction has proven to be effective in achieving improvement of spinopelvic parameters as well as improving quality of life (QoL) for these patients. However, given the relatively high complication risk associated with ASD correction, it is of paramount importance to develop robust prognostic tools for predicting risk profile and outcomes. Historically, statistical models such as linear and logistic regression models were used to identify preoperative factors associated with postoperative outcomes. While these tools were useful for looking at simple associations, they represent generalizations across large populations, with little applicability to individual patients. More recently, predictive analytics utilizing artificial intelligence (AI) through machine learning for comprehensive processing of large amounts of data have become available for surgeons to implement. The use of these computational techniques has given surgeons the ability to leverage far more accurate and individualized predictive tools to better inform individual patients regarding predicted outcomes after ASD correction surgery. Applications range from predicting QoL measures to predicting the risk of major complications, hospital readmission, and reoperation rates. In addition, AI has been used to create a novel classification system for ASD patients, which will help surgeons identify distinct patient subpopulations with unique risk-benefit profiles. Overall, these tools will help surgeons tailor their clinical practice to address patients’ individual needs and create an opportunity for personalized medicine within spine surgery."
딥러닝을 활용한 에지 컴퓨팅 기반의 지능형 컨스트럭션 영상 관제 시스템,2019,"['edge computing', 'machine learning', 'deep learning', 'video management system', 'supervised learning']",,
초심자 안과 전문의가 시행한 수정체유화술 중 발생한 후낭파열빈도: 현미경 조명과 안구내 조명,2019,"['Intracameral illumination', 'Learning curve', 'Novice ophthalmologist', 'Phacoemulsification', 'Posterior capsule rupture']","목적: 초심자 안과 전문의에 의해 시행된 수정체유화술에서 현미경 조명 사용과 안구내 조명 사용의 차이에 따른 후낭파열의 빈도를 비교하고자 하였다.대상과 방법: 2012년 3월부터 2017년 10월까지 본원 전공의 수련 과정을 마치고 전문의를 취득한 6명의 안과의사가 본 대학병원 안과학교실에서 전임의 과정 중 단독으로 수정체유화술을 시행했던 300예, 211명을 대상으로 전자의무기록을 후향적으로 분석하였다. 동일한 수련 과정을 끝낸 초심자 전문의 6인 중 현미경 조명 사용자 4명과 안구내 조명 사용자 2명이었고, 모두 같은 수정체유화술기계 및 현미경을 사용하였다. 초심자 전문의 단독으로 시행한 첫 50예의 백내장수술에서의 후낭파열빈도를 안구내 조명의 사용 유무에 따라 비교하였고, 수술 건수별 후낭파열빈도를 비교하여 학습곡선(learning curve)을 분석해보았다.결과: 후낭파열은 현미경 조명 그룹에서 19.0% (38/200), 안구내 조명 그룹에서 4.0% (4/100)의 빈도를 보였다(p=0.001). 수술 건수별 후낭파열빈도는 현미경 조명 그룹은 10예당 22%, 18%, 16%, 12%, 8%로 감소하였고, 안구내 조명 그룹은 첫 10예에서 15%를 보인 후 이후 50예까지 0%를 보였다.결론: 안구내 조명을 사용한 초심자가 현미경 조명 사용자보다 수정체유화술에서 더 낮은 후낭파열빈도를 보였다. 학습곡선은 수술 케이스가 증가할수록 두 그룹 모두 감소하는 양상을 보였으나, 안구내 조명 사용에서 더 빠르게 감소하는 것으로 나타났다.","Purpose: We compared the posterior capsule rupture (PCR) rate between microscope versus intracameral illumination in phacoemulsification surgery performed by novice ophthalmologists.Methods: We conducted a retrospective chart review of 300 eyes of 211 patients who underwent phacoemulsification by novice ophthalmologists from March 2012 to October 2017. Novice ophthalmologists (n = 6) were divided into those using microscope illumination (n = 4) and intracameral illumination users (n = 2). The first 50 cataract surgery cases of each novice ophthalmologist were reviewed. The results using a phacoemulsification machine and microscopy were the same. The intraoperative complications and learning curve in each case were evaluated.Results: Phacoemulsifications performed by novice ophthalmologists showed a statistically significant difference in PCR rate between the microscope illumination (19.0%, 38/200) and intracameral illumination (4.0%, 4/100) groups (p = 0.001). The incidence of PCR was reduced to 22%, 18%, 16%, 12%, and 8% per 10 cases in the microscope group, while it was 15% in the first 10 cases and 0% in 50 cases thereafter in the intracameral illumination group.Conclusions: Novice surgeons had a lower PCR rate during cataract surgery using intracameral illumination than using microscope illumination. Both groups showed a tendency for the PCR to decrease with increasing surgical cases, but the intracameral illumination group showed a shorter learning curve."
Analysis of Open-Source Hyperparameter Optimization Software Trends,2019,"['Hyperparameter Optimization', 'Machine Learning', 'Deep Learning', 'AutoML']",,"Recently, research using artificial neural networks has further expanded the field of neural network optimization and automatic structuring from improving inference accuracy. The performance of the machine learning algorithm depends on how the hyperparameters are configured. Open-source hyperparameter optimization software can be an important step forward in improving the performance of machine learning algorithms. In this paper, we review open-source hyperparameter optimization softwares."
XGBoost 기법을 이용한 단기 전력 수요 예측 및 하이퍼파라미터 변화에 따른 영향 분석,2019,"['Load forecasting', 'Machine Learning', 'XGBoost', 'Hyperparameter']",,"Accurate load forecasting is getting vital with social and economic development to secure electricity supply and minimize redundant electricity generation. The load forecasting is also essential for efficient power system operation. As machine learning techniques become popular due to the breakthroughs in the application of intelligent systems such as speech or image recognition, variety of machine learning algorithms have also been applied to predict electricity demand. For load forecasting, this paper employs XGBoost algorithm that has recently been receiving attention. To yield the maximum performance of the XGBoost model, we performed grid search method to find optimal hyperparameters of XGBoost. The effects of the XGBoost model’s hyperparameters on the model are assessed and visualized."
Artificial Intelligence based Tumor detection System using Computational Pathology,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning Techniques', 'Medical Image Segmentation', 'CNNs']",,"Pathology is the motor that drives healthcare to understand diseases. The way pathologists diagnose diseases, which involves manual observation of images under a microscope has been used for the last 150 years, it's time to change. This paper is specifically based on tumor detection using deep learning techniques. Pathologist examine the specimen slides from the specific portion of body (e-g liver, breast, prostate region) and then examine it under the microscope to identify the effected cells among all the normal cells. This process is time consuming and not sufficiently accurate. So, there is a need of a system that can detect tumor automatically in less time. Solution to this problem is computational pathology: an approach to examine tissue data obtained through whole slide imaging using modern image analysis algorithms and to analyze clinically relevant information from these data. Artificial Intelligence models like machine learning and deep learning are used at the molecular levels to generate diagnostic inferences and predictions; and presents this clinically actionable knowledge to pathologist through dynamic and integrated reports. Which enables physicians, laboratory personnel, and other health care system to make the best possible medical decisions. I will discuss the techniques for the automated tumor detection system within the new discipline of computational pathology, which will be useful for the future practice of pathology and, more broadly, medical practice in general."
선형회귀분석 기법을 이용한 고교야구투수의 투구속도 예측,2019,"['Artificial intelligence', 'Machine-learning', 'Linear regression', 'Tensorflow', 'Gradient descent algorithm']",,"Recently, studies on artificial intelligence such as AlphaGo and machine learning have been actively conducted. In statistics, linear regression is a regression method that models the linear correlation between dependent variable y and one or more independent variables y. Generally, a linear regression model is established using least square method. In other words, linear regression analysis is a method of modeling the relationship between independent variables, dependent variables, and constant terms. There is a simple linear regression method that models the relationship between two variables and a multiple linear regression method based on two or more independent variables. In a baseball game, the pitcher must be good at ball speed, pitching control, pitching balance, etc., in order to get good results when dealing with batter. High school baseball player’s pitching speed is important factor to grow as excellent pitcher. Also, pitcher's ball speed is one of the important factors that determine the winning or defeat of the baseball game. In this paper, we use the Deep Learning Framework(Tensorflow) to measure ball speed of pitcher among high school baseball players and use it for athlete 's exercise and training rehabilitation. In this study, we generate training data about stride and speed of the pitcher and perform the linear regression prediction method using the gradient-descent method which is the optimization algorithm."
Audio Feature Extraction for Effective Emotion Classification,2019,"['Sentiment analysis', 'Machine learning', 'Audio feature', 'Feature selection/extraction']",,"Recently, there has been increasing interest in artificial intelligence and machine learning, where sentiment analysis has received considerable attention. In several studies, emotional states have been recognized using audio, text, or bio-signals that induce emotions, with audio being the most typical. There are several audio features, such as rhythm, dynamics, melody, harmony, and tonal color. The aim of our paper is finding critical audio features for effective emotion recognition. To do this, we select the existing audio features from elements of music, and investigate critical features using an iterative feature extraction method. For objective evaluation, the International Affective Digital Sounds system was used for training and testing. Crossvalidation evaluated the method in terms of classifier accuracy and computational complexity, and the results indicate the critical features for emotion classification."
랜덤 포레스트를 활용한 대학 수시 전형 선택 관련 예측 요인 탐색,2019,"['수시 전형', '머신 러닝', '랜덤 포레스트', '한국교육고용패널', 'Korean Type Early Decision Programs', 'machine Learning', 'random forest', 'KEEP']","본 연구는 대학 수시 전형 입학생들의 특성을 탐색적으로 확인하기 위하여 ‘입학한 대학에의 수시 입학 여부’ 및 ‘2015년 중앙일보 대학평가 기준 상위 30위권 대학으로의 수시 입학 여부’를 반응변수로 하여 이를 예측하는 설명변수를 탐색적으로 확인하였다. 이를 위해 본 연구는 한국교육고용패널 I 중학교 3학년 코호트의 4-12 차년도 자료를 활용하여, 해당 코호트가 대학에 진학하기 시작한 2008년부터 2015년 사이의 대학 신입생 수시입학 여부 변수를 최근 주목받고 있는 랜덤 포레스트 기법을 적용함으로써 대학생들의 수시 입학 및 소위 상위권 대학으로의 수시 입학을 예측하는 주요 변수들을 탐색하였다. 분석 결과, 예측성과 측면에서 랜덤 포레스트로부터 도출된 예측 모형이 적합한 모형임을 확인하였다. 다음으로 수시 입학 및 소위 상위권 대학 수시 입학에영향을 주는 설명변수들의 중요도를 확인한 결과 ‘서울 4년제 대학 진학자수’, ‘수능 등급’, ‘고등학교 유형’, ‘학교 규모’, ‘혼자 학습하는 시간’ 등의 설명변수들의 예측력이 상대적으로 높게 나타났다. 본 연구는 수시 입학에상대적으로 더 큰 예측력을 지니는 중요 설명변수를 탐색적으로 밝혀냄으로써, 향후 수시 전형의 개선 및 보완을 위한 정책적 판단에 의미있는 시사점을 제공할 것으로 기대된다.","The purpose of this paper was to predict variables related to the characteristics of freshmen who entered university through Korean-type Early Decision Programs (KEDP). This study utilized a random forest model, one of the most popular machine learning approaches. Results showed that in-Seoul, Korea, 4-year university applicants’ “SAT Score” and “school size” were the substantial variables in predicting university entrance through KEDP. In terms of the so-called prestigious university entrance through KEDP, each school’s characteristics such as school type, school size, and individual characteristics such as SAT score, were relatively more predictive variables. The findings of this study, based on a new approach using a machine learning method, provide useful policy implications for improving current university admission processes, including KEDP."
블록체인 기반 스펙트럼 관리 시스템에서의 전파수신 음영지역 판별을 위한 전파맵 보간 기법,2019,"['Support Vector Machine', 'Kriging Interpolation', 'Propagation Map', 'Black Chain', 'Smart Contract']","무선통신 서비스 간 공동의 주파수 대역을 상호 간섭 없이 효율적으로 사용하기 위해서는 사용자 간의 지역적 주파수 이용정보의 공유기술이 필요함과 동시에 보안 유지가 필수적이며, 신뢰할 수 있는 주파수 공존수준 달성을 위한 수신전계강도 예측방안이 필요하다. 본 논문에서는 주파수 이용정보의 보안 유지와 신뢰성 있는 주파수 공존을 위해 블록체인 플랫폼 기반의 스펙트럼 관리 시스템을 제안하였으며, 사용자가 요구하는 지역적 채널가용정보의 정확도 향상을 위해 크리깅 보간 기법(kriging interpolation)을 이용하여 전파수신 음역지역 판별을 위한 수신전계강도 예측과 전파맵을 생성하였다. 또한 전파맵의 성능향상과 자동화를 위해 기계학습 기반의 SVM(Support Vector Machine) 기법을 제안하였으며, 모의실험을 통해 크리깅 보간 기법의 표본 데이터 수에 따른 예측정확도와 전파맵 해상도 비교를 통한 성능분석을 수행하였다.","To incorporate common frequency bands in wireless communication services without mutual interference, sharing of frequency usage information is needed that requires security measures, and a method for predicting the local received field strength is required for achieving reliable frequency coexistence levels. In this paper, a spectrum management system based on block chain is proposed for securing frequency usage information, achieving reliable frequency coexistence, and creating a propagation map by employing kriging interpolation for improving the accuracy of channel availability information required by users. Additionally, a support vector machine based on machine learning is proposed for enhancing and automating the propagation map. Through simulation, performance analysis was conducted by comparing the prediction accuracy of kriging interpolation and the propagation map resolution."
Artificial Intelligence based Tumor detection System using Computational Pathology,2019,"['Artificial Intelligence', 'Machine Learning', 'Deep Learning Techniques', 'Medical Image Segmentation', 'CNNs']",,"Pathology is the motor that drives healthcare to understand diseases. The way pathologists diagnose diseases, which involves manual observation of images under a microscope has been used for the last 150 years, it’s time to change. This paper is specifically based on tumor detection using deep learning techniques. Pathologist examine the specimen slides from the specific portion of body (e-g liver, breast ,prostate region) and then examine it under the microscope to identify the effected cells among all the normal cells. This process is time consuming and not sufficiently accurate. So, there is a need of a system that can detect tumor automatically in less time. Solution to this problem is computational pathology: an approach to examine tissue data obtained through whole slide imaging using modern image analysis algorithms and to analyze clinically relevant information from these data. Artificial Intelligence models like machine learning and deep learning are used at the molecular levels to generate diagnostic inferences and predictions; and presents this clinically actionable knowledge to pathologist through dynamic and integrated reports. Which enables physicians, laboratory personnel, and other health care system to make the best possible medical decisions.I will discuss the techniques for the automated tumor detection system within the new discipline of computational pathology, which will be useful for the future practice of pathology and, more broadly, medical practice in general."
Utilization of Artificial Intelligence Techniques for Photovoltaic Applications,2019,"['Artificial Intelligence', 'Machine Learning', 'Photovoltaic Applications', 'Solar Panel', 'EL Imaging']",,"Renewable energy is emerging as a reliable alternative source of energy, it is much safer, cleaner than conventional sources and has contributed significantly in this sector. However, there are still some challenges that needed to address this evolving technology. Artificial Intelligence (A. I.) can assess the past, optimize the present, and forecast the future. Therefore, A. I. will resolve most of these problems. Artificial intelligence is complex in nature, but it reduces error and aims to reach a greater degree of precision which make renewables smarter. This paper provides an overview of frequently used A. I. methods in solar energy applications. A sample algorithm is also provided for literature purposes and knowledge transfer."
유전자 발현 데이터 기반 구강암에서의 세포 조성 차이 분석,2019,"['Oral cancer', 'Machine learning', 'Gene expression', 'Bio-IT convergence', 'Cell subtype composition', 'Immune cell infiltration', '구강암', '기계학습', '유전자 발현', '생명 정보 융합', '세포 구성', '면역 세포 침투']","암 조직에는 다양한 형태의 세포가 존재하지만, 이들의 조성을 실험적으로 확인하기는 매우 어렵다. 본 연구에서는 유전자 발현 데이터에 통계적 기계학습 모델을 적용하여 각 샘플의 세포 조성을 추론하고, 이러한 세포 조성이 암 조직과 정상 조직간에 차이가 있는지를 확인하였다. 두 가지 서로 다른 회귀 모델을 이용하여 세포 조성을 예측한 결과 CD8 T cell과 Neutrophil이 구강암 조직에서 정상 조직에 비해 증가함을 확인할 수 있었다. 또한 비지도학습 중 하나인 t-SNE를 적용하여, 유추된 세포 조성에 의해 정상 조직과 구강암 조직이 서로 군집을 이루고 있음을 확인하였고, 지도 학습 기반의 다양한 분류 알고리즘들을 이용하여 세포 조성 정보를 이용하여 구강암과 정상 조직을 예측하는 것이 가능함을 보였다. 이 연구는 구강암의 면역 세포 침투에 대한 이해도를 증진하는데에 도움을 줄 수 있을 것이다.","There are various subtypes of cells in cancer tissues, but it is hard to confirm their composition experimentally. Here, we estimated the cell composition of each sample from gene expression data by using statistical machine learning approaches, two different regression models and investigated whether the cell composition was different between cancer and normal tissue. As a result, we found that CD8 T cell and Neutrophil were increased in oral cancer tissues compared to normal tissues. In addition, we applied t-SNE, which is one of the unsupervised learning, to verify whether normal tissue and oral cancer tissue can be clustered by the derived cell composition. Moreover, we showed that it is possible to predict oral cancer and normal tissue by several supervised classification algorithms. The study would help to improve the understanding of the immune cell infiltration at oral cancer."
악성코드 분석의 Ground-Truth 향상을 위한 Unified Labeling과 Fine-Grained 검증,2019,"['Malware', 'Labeling', 'Machine Learning', 'Clustering']","최근 AV 벤더들의 악성코드 동향 보고서에 따르면 신종, 변종 악성코드의 출현 개수가 기하급수적으로 증가하고있다. 이에 따라 분석 속도가 떨어지는 수동적 분석방법을 대체하고자 기계학습을 적용하는 악성코드 분석 연구가 활발히 연구되고 있다. 하지만 지도학습기반의 기계학습을 이용할 때 많은 연구에서 AV 벤더가 제공하는 신뢰성이 낮은 악성코드 패밀리명을 레이블로 사용하고 있다. 이와 같이 악성코드 레이블의 낮은 신뢰성 문제를 해결하기 위해본 논문에서는 새로운 레이블링 기법인 “Unified Labeling”을 소개하고 나아가 Fine-grained 방식의 특징 분석을통해 악성 행위 유사성을 검증한다. 본 연구의 검증을 위해 다양한 기반의 클러스터링 알고리즘을 이용하여 기존의레이블링 기법과 비교하였다.","According to a recent report by anti-virus vendors, the number of new and modified malware increased exponentially.Therefore, malware analysis research using machine learning has been actively researched in order to replace passive analysismethod which has low analysis speed. However, when using supervised learning based machine learning, many studies uselow-reliability malware family name provided by the antivirus vendor as the label. In order to solve the problem oflow-reliability of malware label, this paper introduces a new labeling technique, “Unified Labeling”, and further verifies themalicious behavior similarity through the feature analysis of the fine-grained method. To verify this study, various clusteringalgorithms were used and compared with existing labeling techniques."
CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석,2019,"['CNN', 'LSTM', 'Deep Learning', 'Integrated Model', 'Movie Review', 'Sentiment Analysis', 'CNN', 'LSTM', '딥러닝', '조합모델', '영화리뷰', '감성분석']","인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.","Rapid growth of internet technology and social media is progressing. Data mining technology has evolved to enable unstructured document representations in a variety of applications. Sentiment analysis is an important technology that can distinguish poor or high-quality content through text data of products, and it has proliferated during text mining. Sentiment analysis mainly analyzes people's opinions in text data by assigning predefined data categories as positive and negative. This has been studied in various directions in terms of accuracy from simple rule-based to dictionary-based approaches using predefined labels. In fact, sentiment analysis is one of the most active researches in natural language processing and is widely studied in text mining. When real online reviews aren't available for others, it's not only easy to openly collect information, but it also affects your business. In marketing, real-world information from customers is gathered on websites, not surveys. Depending on whether the website's posts are positive or negative, the customer response is reflected in the sales and tries to identify the information. However, many reviews on a website are not always good, and difficult to identify. The earlier studies in this research area used the reviews data of the Amazon.com shopping mal, but the research data used in the recent studies uses the data for stock market trends, blogs, news articles, weather forecasts, IMDB, and facebook etc. However, the lack of accuracy is recognized because sentiment calculations are changed according to the subject, paragraph, sentiment lexicon direction, and sentence strength. This study aims to classify the polarity analysis of sentiment analysis into positive and negative categories and increase the prediction accuracy of the polarity analysis using the pretrained IMDB review data set. First, the text classification algorithm related to sentiment analysis adopts the popular machine learning algorithms such as NB (naive bayes), SVM (support vector machines), XGboost, RF (random forests), and Gradient Boost as comparative models.Second, deep learning has demonstrated discriminative features that can extract complex features of data. Representative algorithms are CNN (convolution neural networks), RNN (recurrent neural networks), LSTM (long-short term memory). CNN can be used similarly to BoW when processing a sentence in vector format, but does not consider sequential data attributes. RNN can handle well in order because it takes into account the time information of the data, but there is a long-term dependency on memory. To solve the problem of long-term dependence, LSTM is used. For the comparison, CNN and LSTM were chosen as simple deep learning models. In addition to classical machine learning algorithms, CNN, LSTM, and the integrated models were analyzed. Although there are many parameters for the algorithms, we examined the relationship between numerical value and precision to find the optimal combination. And, we tried to figure out how the models work well for sentiment analysis and how these models work. This study proposes integrated CNN and LSTM algorithms to extract the positive and negative features of text analysis. The reasons for mixing these two algorithms are as follows. CNN can extract features for the classification automatically by applying convolution layer and massively parallel processing. LSTM is not capable of highly parallel processing. Like faucets, the LSTM has input, output, and forget gates that can be moved and controlled at a desired time. These gates have the advantage of placing memory blocks on hidden nodes. The memory block of the LSTM may not store all the data, but it can solve the CNN's long-term dependency problem. Furthermore, when LSTM is used in CNN's pooling layer, it has an end-to-end structure, so that spatial and temporal features can be designed simultaneously. In combination with CNN-LSTM, 90.33% accuracy was measured. Thi..."
IOT 환경에서의 오토인코더 기반 특징 추출을 이용한 네트워크 침입탐지 시스템,2019,"['NIDS', 'IOT', 'Unsupervised Learning', 'Machine Learning', 'AutoEncoder', '네트워크 침입탐지시스템', '사물인터넷', '비지도학습', '기계학습', '오토인코더']",,"In the Network Intrusion Detection System (NIDS), the function of classification is very important, and detection performance depends on various features. Recently, a lot of research has been carried out on deep learning, but network intrusion detection system experience slowing down problems due to the large volume of traffic and a high dimensional features. Therefore, we do not use deep learning as a classification, but as a preprocessing process for feature extraction and propose a research method from which classifications can be made based on extracted features. A stacked AutoEncoder, which is a representative unsupervised learning of deep learning, is used to extract features and classifications using the Random Forest classification algorithm. Using the data collected in the IOT environment, the performance was more than 99% when normal and attack traffic are classified into multiclass, and the performance and detection rate were superior even when compared with other models such as AE-RF and Single-RF."
Comparison of Sentiment Analysis from Large Twitter Datasets by Naïve Bayes and Natural Language Processing Methods,2019,"['Big data processing', 'Machine learning', 'Naive Bayes algorithm', 'Sentiment analysis', 'SNS big data']",,"Recently, effort to obtain various information from the vast amount of social network services (SNS) big data generated in daily life has expanded. SNS big data comprise sentences classified as unstructured data, which complicates data processing. As the amount of processing increases, a rapid processing technique is required to extract valuable information from SNS big data. We herein propose a system that can extract human sentiment information from vast amounts of SNS unstructured big data using the naïve Bayes algorithm and natural language processing (NLP). Furthermore, we analyze the effectiveness of the proposed method through various experiments. Based on sentiment accuracy analysis, experimental results showed that the machine learning method using the naïve Bayes algorithm afforded a 63.5% accuracy, which was lower than that yielded by the NLP method. However, based on data processing speed analysis, the machine learning method by the naïve Bayes algorithm demonstrated a processing performance that was approximately 5.4 times higher than that by the NLP method."
인공지능은 기존 저작물을 자유롭게 이용할 수 있을까?,2019,"['fair use', 'artificial intelligence', 'machine learning', 'non-express use', 'idea-expression dichotomy', '공정이용', '인공지능', '기계학습', '비표현적 이용', '아이디어 표현 이분법']",,"Since John McCarthy proposed the definition of Artificial Intelligence in Dartmouth Conference, due to the function of computer, various learning systems such as machine learning, deep learning have been developed and people in various fields became interested in artificial intelligence. As a result, although various reports have been published in each country and research institute, most issues in the field of intellectual property are whether the copyright should be granted to works of art, such as music, news articles, short stories that are created by artificial intelligence, and if it should be, artificial intelligence should be protected the same as the human being under Copyright Act. However, decisions on these topics cannot be made under the level of individual countries or does not follow original theories of some scholars, and thus, they should be decided by scholars from various fields all over the world and from international organizations such as the WIPO and the United Nations. Therefore, this paper is analyzing whether the use of copyrighted works such as movies, music, novels, etc., for artificial intelligence should be allowed for the purposes of copyright system or fair use without permission of copyright holders.The purpose of fair use and the four elements are applied to works produced by artificial intelligence. and this paper decides although some use of existing copyrighted works are nonprofit, such as reporting, criticism, education, research, because most uses in artificial intelligence are to get make a profit as well as most existing works are creative, because artificial intelligence uses entire works, because consumers of works made by artificial intelligence are same as those of existing works and the relationship between works made by artificial intelligence and used works in artificial intelligence are directly competitive it is not fair use to use an existing work without the consent of the copyright owner."
Multi-Purpose Hybrid Recommendation System on Artificial Intelligence to Improve Telemarketing Performance,2019,"['Telemarketing', 'Recommendation', 'Artificial Intelligence', 'Machine Learning', 'Customer Relationship Management']",,"The purpose of this study is to incorporate telemarketing processes to improve telemarketing performance. For this application, we have attempted to mix the model of machine learning to extract potential customers with personalisation techniques to derive recommended products from actual contact. Most of traditional recommendation systems were mainly in ways such as collaborative filtering, which predicts items with a high likelihood of future purchase, based on existing purchase transactions or preferences for products. But, under these systems, new users or items added to the system do not have sufficient information, and generally cause problems such as a cold start that can not obtain satisfactory recommendation items. Also, indiscriminate telemarketing attempts can backfire as they increase the dissatisfaction and fatigue of customers who do not want to be contacted. To this purpose, this study presented a multi-purpose hybrid recommendation algorithm to achieve two goals: to select customers with high possibility of contact, and to recommend products to selected customers. In addition, we used subscription data from telemarketing agency that handles insurance products to derive realistic applicability of the proposed recommendation system. Our proposed recommendation system would certainly solve the cold start and scarcity problem of existing recommendation algorithm by using contents information such as customer master information and telemarketing history. Also. the model could show excellent performance not only in terms of overall performance but also in terms of the recommendation success rate of the unpopular product."
Predicting Crop Production for Agricultural Consultation Service,2019,"['Agricultural Consultation Service', 'Machine Learning', 'Prediction of Crop Production']",,"Smart Farming has been regarded as an important application in information and communications technology (ICT) fields. Selecting crops for cultivation at the pre-production stage is critical for agricultural producers' final profits because over-production and under-production may result in uncountable losses, and it is necessary to predict crop production to prevent these losses. The ITU-T Recommendation for Smart Farming (Y.4450/Y.2238) defines plan/production consultation service at the pre-production stage; this type of service must trace crop production in a predictive way. Several research papers present that machine learning technology can be applied to predict crop production after related data are learned, but these technologies have little to do with standardized ICT services. This paper clarifies the relationship between agricultural consultation services and predicting crop production. A prediction scheme is proposed, and the results confirm the usability and superiority of machine learning for predicting crop production."
Prediction of bolt fastening state using structural vibration signals,2019,"['Bolt fastening state', 'Classification', 'Machine learning', 'Piezoelectric sensor', 'Prognostics', 'Structural vibration']",,"We have proposed a new method to predict the state of bolt fastening connection using time-domain structural vibration signal and experimentally validated its effectivness. To obtain the structural vibration signal, non-contact type laser displcement sensor and contact type piezo film sensor were used, respectively. Two-beam structures with holes were prepared and fastened with a set of bolt and nut. By applying a random initial displacement at the free end of the cantilever beam structure, vibration signals were measured for three different bolt fastening states: fully fastened, half-loosened and 90 %-loosened. After extraction of features from the obtained vibration signals, the bolt fastening state was classified based on the k-nearest neighbor (k-NN) algorithm. It is experimentally verified that the bolt fastening state can be accurately predicted by using the structural vibration signals and machine learning algorithm."
다중 이벤트 센서 기반 스마트 홈에서 사람 행동 분류를 위한 효율적 의사결정평면 생성기법,2019,"['Smart home', 'IoT', 'Embedded machine learning', 'Light weight', 'High speed']",,"In this paper, we propose an efficient hyperplane generation technique to classify human activity from combination of events and sequence information obtained from multiple-event sensors. By generating hyperplane efficiently, our machine learning algorithm classify with less memory and run time than the LSVM (Linear Support Vector Machine) for embedded system. Because the fact that light weight and high speed algorithm is one of the most critical issue in the IoT, the study can be applied to smart home to predict human activity and provide related services. Our approach is based on reducing numbers of hyperplanes and utilizing robust string comparing algorithm. The proposed method results in reduction of memory consumption compared to the conventional ML (Machine Learning) algorithms; 252 times to LSVM and 34,033 times to LSTM (Long Short-Term Memory), although accuracy is decreased slightly. Thus our method showed outstanding performance on accuracy per hyperplane; 240 times to LSVM and 30,520 times to LSTM. The binarized image is then divided into groups, where each groups are converted to binary number, in order to reduce the number of comparison done in runtime process. The binary numbers are then converted to string. The test data is evaluated by converting to string and measuring similarity between hyperplanes using Levenshtein algorithm, which is a robust dynamic string comparing algorithm. This technique reduces runtime and enables the proposed algorithm to become 27% faster than LSVM, and 90% faster than LSTM."
예술에 적용된 인공지능 시스템 -현상학적 예술론을 중심으로-,2019,"['미적체험', '현상학적 예술론', '머신러닝', 'Aesthetic experience', 'Phenomenological art', 'Machine learning']",,"21st century art does not emphasize the artwork in a particular form of work. Today, art is more of an aesthetic experience than a distinction between what is a work of art and what is not.Art is an artificial thing, and the subject who creates it has been recognized as a unique area of human beings.At present, artificial intelligence, which is beyond human ability in certain fields, is appearing. The role of artificial intelligence in each sector of society has become very important.In this study, I tried to look at examples of artificial intelligence works using machine learning such as LSTM and GAN. And I wanted to reconsider the phenomenological meaning of AI art.In phenomenological aesthetics, imitation and expression are to recognize the essence of reality.Artworks that use algorithms such as deep learning and machine learning are different from the creative principles of art, which are human perception and sensations. AI art is enabling a new aesthetic experience that we have not experienced."
CNN 알고리즘을 이용한 체커스위치 불량 검출 시스템 개발,2019,"['Error Detection(불량 검출)', 'Machine Learning(머신러닝)', 'CNN', 'Checker Switch(체커스위치)']",,"Various automation studies have been conducted to detect defective products based on product images. In the case of machine vision-based studies, size and color error are detected through a preprocessing process. A situation may arise in which the main features are removed during the preprocessing process, thereby decreasing the accuracy. In addition, complex systems are required to detect various kinds of defects. In this study, we designed and developed a system to detect errors by analyzing various conditions of defective products. We designed the deep learning algorithm to detect the defective features from the product images during the automation process using a convolution neural network (CNN) and verified the performance by applying the algorithm to the checker-switch failure detection system. It was confirmed that all seven error characteristics were detected accurately, and it is expected that it will show excellent performance when applied to automation systems for error detection."
인공지능을 활용한 음악의 화성 생성 연구,2019,"['인공지능', '음악', '융합', '머신러닝', '편곡', 'artificial intelligence', 'music', 'fusion', 'machine learning', 'arrangement']","4차 산업혁명이 추구하는 인공지능의 활용과 융합에 있어 예술 분야 또한 음악 산업의 구조적 측면에서 인공지능의 활용을 피해갈 수 없음을 인지한다. 이를 통해 살펴본 인공지능 활용의 여러 방안 중 본 논문의 연구는 음악의 편곡에 있어 중요히 여겨지는 화성 생성의 연구에 관하여 살펴보았으며, 화성의 생성 과정은 머신러닝을 활용하여 멜로디와 코드의 관계를 알고리즘 하였다. 이러한 과정을 통해 온 음계적 4화음 코드와 디미니쉬 코드를 도출하는 연구가 진행되었고, 연구의 결과는 다음과 같다. 첫째, 3화음만으로 구성된 원곡에 비해 4화음의 코드가 생성됨으로 화성의 다양한 음악적 색채를 표현 할 수 있게 되었다. 둘째, 온 음계적 코드의 사이에 경과적으로 적용된 디미니쉬 코드를 통해 음악의 진행상 그 흐름이 더욱 다양화되는 효과를 가질 수 있게 되었다. 마지막으로, 생성된 코드를 악보에 표기하고 진행을 분석하였을 때, 생성된 코드들은 화성학적 규칙에 의거하여 실제 음악의 편곡에 유용하게 사용될 수 있음을 확인하였다.","In the use and fusion of artificial intelligence pursued by the Fourth Industrial Revolution, the arts sector also recognizes that it can not avoid the use of artificial intelligence in the structural aspect of the music industry. Among the various methods of artificial intelligence utilization through this study, the study of this paper examined the research on the generation of Mars, The generation process of Mars uses machine learning to algorithm the relationship between melody and chord. Through this process, a study was conducted to derive the qualitative four-chord and diminish chord. The results of the study are as follows. First, since the chords of four chords are generated compared to the original song consisting of only three chords, various musical colors of harmony can be expressed. Second, the diminish chords applied gradually between the whole chromatic chords have the effect of diversifying the flow of music. Finally, when marking the generated chord on the score and analyzing the progress, it was confirmed that the generated chords can be usefully used in the arrangement of actual music based on the rules."
The Applicability of Artificial Intelligence in International Law,2019,"['International Law', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Computational Law', 'Legal-Tech', 'ODR', 'Trial Prediction', 'Machine translation']",,
Does Big Data Matter?: Predicting Stock Returns using Online Stock Message Boards,2019,"['Online Stock Message Boards', 'Machine Learning', 'Microstructure']",,"Can online stock message boards predict the direction of stock returns? We investigate whether these boards contain predictive power regarding the direction of stock returns. Moreover, we verify the effectiveness of machine learning techniques for extracting predictive information from such message boards. Finally, we aim to identify the informational content of online these message boards using the implications of microstructure theory. Our results suggest that online stock message boards do contain predictive information, which can be extracted using machine learning techniques. Furthermore, this information is closely linked to public/private information arriving at the market."
빅데이터를 이용한 심리학 연구 방법,2019,"['Big Data', 'Artificial Intelligence', 'Machine Learning', 'Topic Modeling', 'Deep Learning', 'Data-driven Analysis', 'Model-driven analysis', '빅데이터', '인공지능', '기계학습', '주제모형', '딥러닝', '자료주도적 분석', '모형주도적 분석']","빅데이터, 기계학습, AI 등의 새로운 기술의 발달은 사람들의 사고와 행동을 변화시키고 이전에는 접근하기 힘들었던 인간에 대한 다양한 활동을 관찰하는 것을 가능하게 한다. 사람들이 인터넷을 광범위하게 사용함에 따라서, 개인의 행동도 인터넷에 저장되고 있다. 자료들은 매우 광범위하며 다양하기 때문에 이를 적절하게 분석하면 인간 심리를 이해하는 범위를 확대할 수 있을 것이다. 이 논문에서는 새롭게 발달된 이러한 기술들을 심리학 연구에 활용하는 방법에 대하여 모색하고자 하였다. 특히 기술의 발달로 가능해진 새로운 자료, 빅데이터의 특성과 심리학에서의 활용방안에 대하여 논의하였다. 이 논문에서는 첫째, 빅데이터의 특성과 빅데이터가 심리학에서 어떠한 역할을 할 수 있는지 살펴보았다. 심리학의 모형주도적 분석법과 다른 빅데이터의 자료주도적 분석법의 문제점들과 이러한 분석을 심리학연구에 어떻게 적용될 수 있는지에 대하여 논의하였다. 둘째, 자료의 분석 방법론에 대하여 살펴보았다. 기존 심리학 연구에서는 정교한 연구설계에 의해 자료가 수집되기 때문에 분석이 상대적으로 덜 중요하지만, 빅데이터 분석에서는 자료분석의 역할이 아주 중요해진다. 방대하고 구조화되지 않은 자료를 처리할 수 있어야 하고, 언어 자료와 같은 숫자 이외의 자료도 분석할 수 있어야 한다. 특히 주제 모형화, 능선 회귀분석과 라소 회귀분석, 지지벡터 기계, 신경망, 딥러닝 등에 대한 원리를 소개하고 심리학 연구에 적용되는 방법들에 대하여 논의하였다. 셋째, 심리학에서 빅데이터 분석 적용의 한계점을 살펴보고, 마지막으로 빅데이터의 심리학 연구의 적용에 대한 방법을 제안하였다.","The development of new technology such as big data, machine learning, and Artificial Intelligence changes human behaviors and thought. Increased use of the internet makes it possible to observe various human activities that were not observable before. Huge amounts of data about various types of human activities are being stored on the internet. Analyzing this information will help extend the scope of understanding human behaviors and psychology. The present paper attempts to find a way of applying new technology to psychological studies. Specifically, we focused on what big data are like and how they can be used for psychological research. This paper first reviewed the characteristics of big data and their role in psychological research. In this context, it discussed the problems of data-driven analysis techniques in which big data analysis is applied and the possibility of applying such methods to psychological research. In this context, it discussed the problems of the data-driven analytic scheme that big data analysis adapting and the possibilities of applying such a method to psychological research. Second, data analytic techniques used in big data analyses are reviewed. These techniques should be able to deal with big and unorganized data and unstructured data such as pictures, video clips, texts, etc. Specifically, it reviewed basic principles of topic modeling, ridge or lasso regression, support vector machine, neural network, and deep learning, and their application to psychological data. Third, the limitations of the use of big data in psychological research are discussed. Finally, it proposed ways of applying big data technology to psychological research."
Does Big Data Matter?: Predicting Stock Returns using Online Stock Message Boards,2019,"['Online Stock Message Boards', 'Machine Learning', 'Microstructure']",,"Can online stock message boards predict the direction of stock returns? We investigate whether these boards contain predictive power regarding the direction of stock returns. Moreover, we verify the effectiveness of machine learning techniques for extracting predictive information from such message boards.Finally, we aim to identify the informational content of online these message boards using the implications of microstructure theory. Our results suggest that online stock message boards do contain predictive information, which can be extracted using machine learning techniques. Furthermore, this information is closely linked to public/private information arriving at the market."
"항만 진출입 컨테이너 트럭의 터미널 도착량 예측에 관한 연구: 신선대, 감만 터미널을 대상으로",2019,"['컨테이너 터미널', '트럭 도착', '머신러닝', 'Container Terminal', 'Truck Arrival', 'Machine Learning']",,"Truck arrivals at a container terminal with a purpose of importing or exporting containers influence on a work plan in the terminal, which includes a management of traffics and safety in a seaport, plans of importing or exporting containers in the terminal, and assigning workers and equipments which are required for importing or exporting containers. Therefore truck arrivals are factors which influence on an efficient management plan for the container terminal. This paper develops a model which predicts truck arrival volume at Sinseondae and Gamman terminal, where are parts of Busan port in Korea, using a dataset of ship arrival and departure from these two terminals, a dataset of container import or export in the container terminal belongs to these terminals, and a machine learning method. And then the developed model is compared to a linear regression model with mean squared errors of the predicted values. Comparing to a linear regression model, the developed model shows a less mean squared error value. It is expected that the outputs from the model can be used for a management plan of the container terminal, and the developed model can be applied to other container terminals in Korea through an additional data collection."
Advanced insider threat detection model to apply periodic work atmosphere,2019,"['Insider threat detection', 'Machine learning', 'Unsupervised learning', 'Security', 'Privacy Behavior']",,"We developed an insider threat detection model to be used by organizations that repeat tasks at regular intervals. The model identifies the best combination of different feature selection algorithms, unsupervised learning algorithms, and standard scores. We derive a model specifically optimized for the organization by evaluating each combination in terms of accuracy, AUC (Area Under the Curve), and TPR (True Positive Rate). In order to validate this model, a four-year log was applied to the system handling sensitive information from public institutions. In the research target system, the user log was analyzed monthly based on the fact that the business process is processed at a cycle of one year, and the roles are determined for each person in charge. In order to classify the behavior of a user as abnormal, the standard scores of each organization were calculated and classified as abnormal when they exceeded certain thresholds. Using this method, we proposed an optimized model for the organization and verified it."
인공신경망 모델을 이용한 냉동기 및 공조기 최적 기동/정지 제어,2019,"['Artificial Neural Network', 'Machine Learning', 'BEMS', 'Model Predictive Control', 'Data-driven Model', '인공신경망', '기계학습', '건물 에너지 관리 시스템', '모델 기반 제어', '데이터 기반 모델']","건물 에너지 효율 향상을 위해서는 과학적, 정량적 분석을 기반으로 설비 시스템을 제어할 수 있어야 하며, 이를 위해 건물 시스템의 동적 거동을 설명할 수 있는 시뮬레이션 모델이 필요하다. 본 논문은 실제 업무용 건물의 BEMS 데이터를 활용하여 공조기와 냉동기의 동적 거동을 예측하는 인공신경망 모델을 개발하였으며, 이를 활용하여 공조기와 냉동기 최적 기동 및 정지 시점 결정 방안을 제시하고 에너지 절감 효과에 대해 분석하였다. 본 논문은 인공신경망 모델 개발 절차 및 에너지 절감 활용 방안에 대해 기술한다.","BEMS(Building Energy Management Systems) have been applied to office buildings and collect relevant building energy data, e.g.temperatures, mass flow rates and energy consumptions of building mechanical systems and indoor spaces. The aforementioned measured datacan be beneficially utilized for developing data-driven machine learning models which can be then used as part of MPC(Model PredictiveControl) and/or optimal control strategies. In this study, the authors developed ANN(Artificial Neural Network) models of an AHU (AirHandling Unit) and a chiller for a real-life office building using BEMS data. Based on the ANN models, the authors developed optimalcontrol strategies, e.g. daily operation schedule with regard to optimal start and stop of the AHU and the chiller (500 RT). It was found thatdue to the optimal start and stop of the AHU and the chiller, 4.5% and 16.4% of operation hours of the AHU and the chiller could besaved, compared to an existing operation."
Fault Diagnosis of Planetary Gear Carrier Packs: A Class Imbalance and Multiclass Classification Problem,2019,['Class imbalance Ensemble learning Fault diagnosis Machine learning Planetary gear carrier pack'],,"Fault diagnosis plays a key role in monitoring manufactured products for the purpose of quality control. Among the several fault diagnosis approaches, knowledge-based fault diagnosis, which uses signals from sensors and machine learning algorithms instead of a priori information, is widely employed to diagnose the status of products. In this paper, we propose a knowledge-based procedure to establish a fault diagnosis model. The model is aimed to diagnose planetary gear carrier packs, which have many fault types and an unbalanced number of samples in the sample classes, using transmission error. In the procedure, the best feature subset that contains the most important features is selected using two different feature selection processes. Several ensemble algorithms are used during the model training process. The imbalance ratio between classes of samples is addressed. The number of weak learners is automatically determined by a genetic algorithm. Finally, the performance of the proposed procedure is validated by comparison with other models trained without applying the proposed procedure. We observed that it is important to incorporate the class imbalance technique in the training process as it reduces the misclassification of faulty products as normal ones. This reduction is important in production quality control."
Network Intrusion Detection System Using Feature Extraction Based on AutoEncoder in IOT environment,2019,"['NIDS', 'IOT', 'Unsupervised Learning', 'Machine Learning', 'AutoEncoder', '네트워크 침입탐지시스템', '사물인터넷', '비지도학습', '기계학습', '오토인코더']",,"In the Network Intrusion Detection System (NIDS), the function of classification is very important, and detection performance depends on various features. Recently, a lot of research has been carried out on deep learning, but network intrusion detection system experience slowing down problems due to the large volume of traffic and a high dimensional features. Therefore, we do not use deep learning as a classification, but as a preprocessing process for feature extraction and propose a research method from which classifications can be made based on extracted features. A stacked AutoEncoder, which is a representative unsupervised learning of deep learning, is used to extract features and classifications using the Random Forest classification algorithm. Using the data collected in the IOT environment, the performance was more than 99% when normal and attack traffic are classified into multiclass, and the performance and detection rate were superior even when compared with other models such as AE-RF and Single-RF."
Multi-Purpose Hybrid Recommendation System on Artificial Intelligence to Improve Telemarketing Performance,2019,"['Telemarketing', 'Recommendation', 'Artificial Intelligence', 'Machine Learning', 'Customer Relationship Management']",,"The purpose of this study is to incorporate telemarketing processes to improve telemarketing performance. For this application, we have attempted to mix the model of machine learning to extract potential customers with personalisation techniques to derive recommended products from actual contact. Most of traditional recommendation systems were mainly in ways such as collaborative filtering, which predicts items with a high likelihood of future purchase, based on existing purchase transactions or preferences for products. But, under these systems, new users or items added to the system do not have sufficient information, and generally cause problems such as a cold start that can not obtain satisfactory recommendation items. Also, indiscriminate telemarketing attempts can backfire as they increase the dissatisfaction and fatigue of customers who do not want to be contacted. To this purpose, this study presented a multi-purpose hybrid recommendation algorithm to achieve two goals: to select customers with high possibility of contact, and to recommend products to selected customers. In addition, we used subscription data from telemarketing agency that handles insurance products to derive realistic applicability of the proposed recommendation system. Our proposed recommendation system would certainly solve the cold start and scarcity problem of existing recommendation algorithm by using contents information such as customer master information and telemarketing history. Also. the model could show excellent performance not only in terms of overall performance but also in terms of the recommendation success rate of the unpopular product."
A Review of Image Analysis in Biochemical Engineering,2019,"['image processing', 'morphology analysis', 'binarization', 'machine learning', 'densitometric analysis']",,"The purpose of image analysis is to extract useful information from images. Since modern image analysis allows fast, accurate, and reliable quantitative analysis, it is widely used at present in many areas of research and development. In this article, I review the image analysis methods that are commonly used in biochemical engineering, for which the subjects of the image analysis vary from molecules or cells to whole animals or biomaterials. Images captured by imaging hardware, which is not limited to digital cameras, are processed in multiple steps by applying various image processing algorithms to extract quantitative features.Image analysis has been successfully applied in diverse applications, ranging from simple densitometric evaluation to animal phenotyping and biomass analysis. Although machine learning is poised to become an increasingly common method of image analysis, traditional methods utilizing blob extraction from binarized images are likely to remain in use for the foreseeable future."
인공신경망을 사용한 수화영상인식시스템,2019,"['Sign Language Translation', 'Artificial Neural Network', 'Machine Learning', 'Image Recognition', 'Hearing Impaired Person']",,"Hearing impaired people are living in a voice culture area, but due to the difficulty of communicating with normal people using sign language, many people experience discomfort in daily life and social life and various disadvantages unlike their desires. Therefore, in this paper, we study a sign language translation system for communication between a normal person and a hearing impaired person using sign language and implement a prototype system for this. Previous studies on sign language translation systems for communication between normal people and hearing impaired people using sign language are classified into two types using video image system and shape input device. However, existing sign language translation systems have some problems that they do not recognize various sign language expressions of sign language users and require special devices. In this paper, we use machine learning method of artificial neural network to recognize various sign language expressions of sign language users. By using generalized smart phone and various video equipment for sign language image recognition, we intend to improve the usability of sign language translation system."
Augmentation of Doppler Radar Data Using Generative Adversarial Network for Human Motion Analysis,2019,"['Motion Perception', 'Data Visualization', 'Deep Learning', 'Big Data', 'Supervised Machine Learning']",,"Objectives: Human motion analysis can be applied to the diagnosis of musculoskeletal diseases, rehabilitation therapies, fall detection, and estimation of energy expenditure. To analyze human motion with micro-Doppler signatures measured by radar, a deep learning algorithm is one of the most effective approaches. Because deep learning requires a large data set, the high cost involved in measuring large amounts of human data is an intrinsic problem. The objective of this study is to augment human motion micro-Doppler data employing generative adversarial networks (GANs) to improve the accuracy of human motion classification. Methods: To test data augmentation provided by GANs, authentic data for 7 human activities were collected using micro-Doppler radar. Each motion yielded 144 data samples. Software including GPU driver, CUDA library, cuDNN library, and Anaconda were installed to train the GANs. Keras-GPU, SciPy, Pillow, OpenCV, Matplotlib, and Git were used to create an Anaconda environment. The data produced by GANs were saved every 300 epochs, and the training was stopped at 3,000 epochs. The images generated from each epoch were evaluated, and the best images were selected.Results: Each data set of the micro-Doppler signatures, consisting of 144 data samples, was augmented to produce 1,472 synthesized spectrograms of 64 × 64. Using the augmented spectrograms, the deep neural network was trained, increasing the accuracy of human motion classification. Conclusions: Data augmentation to increase the amount of training data was successfully conducted through the use of GANs. Thus, augmented micro-Doppler data can contribute to improving the accuracy of human motion recognition."
대용량 악성코드의 특징 추출 가속화를 위한 분산 처리시스템 설계 및 구현,2019,"['Distributed Processing System', 'Malware Detection', 'Feature Extraction', 'Machine Learning', '분산 처리 시스템', '악성코드 탐지', '특징 추출', '기계 학습']","기존 악성코드 탐지는 다형성 또는 난독화 기법이 적용된 변종 악성코드 탐지에 취약하다. 기계학습 알고리즘은 악성코드에 내재된 패턴을 학습시켜 유사 행위 탐지가 가능해 기존 탐지 방법을 대체할 수 있다. 시간에 따라 변화하는 악성코드 패턴을 학습시키기 위해 지속적으로 데이터를 수집해야한다. 그러나 대용량 악성코드 파일의 저장 및 처리 과정은 높은 공간과 시간 복잡도가 수반된다. 이 논문에서는 공간 복잡도를 완화하고 처리 시간을 가속화하기 위해 HDFS 기반 분산 처리 시스템을 설계한다. 분산 처리 시스템을 이용해 2-gram 특징과 필터링 기준에 따른 API 특징 2개, APICFG 특징을 추출하고 앙상블 학습 모델의 일반화 성능을 비교했다. 실험 결과로 특징 추출의 시간 복잡도는 컴퓨터 한 대의 처리 시간과 비교했을 때 약 3.75배 속도가 개선되었으며, 공간 복잡도는 약 5배의 효율성을 보였다. 특징 별 분류 성능을 비교했을 때 2-gram 특징이 가장 우수했으나 훈련 데이터 차원이 높아 학습 시간이 오래 소요되었다.","Traditional Malware Detection is susceptible for detecting malware which is modified by polymorphism or obfuscation technology. By learning patterns that are embedded in malware code, machine learning algorithms can detect similar behaviors and replace the current detection methods. Data must collected continuously in order to learn malicious code patterns that change over time. However, the process of storing and processing a large amount of malware files is accompanied by high space and time complexity. In this paper, an HDFS-based distributed processing system is designed to reduce space complexity and accelerate feature extraction time. Using a distributed processing system, we extract two API features based on filtering basis, 2-gram feature and APICFG feature and the generalization performance of ensemble learning models is compared. In experiments, the time complexity of the feature extraction was improved about 3.75 times faster than the processing time of a single computer, and the space complexity was about 5 times more efficient. The 2-gram feature was the best when comparing the classification performance by feature, but the learning time was long due to high dimensionality."
Elastic Net을 통한 교사의 직무만족도 관련 변수 탐색,2019,"['기계학습', '벌점회귀모형', '교직 만족도', '경기교육종단연구', 'elastic net', 'machine learning', 'penalized regression', 'teacher job satisfaction', 'Gyeonggi Education Panel Study (GEPS)']","본 연구의 목적은 직무만족도와 관련 있는 교사 변수를 탐색하는 것이었다. 이를 위하여 경기교육종단연구(GEPS) 5차년도 자료의 중학교 교사 패널 자료를 활용하였다. 연구에 투입된 교사 관련 변수는 총 223개로, 수백 개의 변수를 한 모형에서 분석할 수 있는 기계학습 기법이 적절하다고 판단되었다. 기계학습 기법 중 벌점회귀모형인 elastic net은 변수 선택뿐만 아니라 자료의 다중공선성까지 고려하는 기법이다. 특히 본 연구는 ‘relevance count’를 활용하여 100번의 elastic net 중 33번 이상 뽑히는 변수를 정리하였다. 그 결과 총 29개 변수가 교사 직무만족도와 관련 있는 변수로 선택되었으며, GEPS의 기준에 따라 크게 ‘교사 사기(열의) 및 효능감’, ‘현 학교 만족도’, ‘학교 풍토 및 조직 문화’, ‘공개수업에 대한 인식’, ‘개인적 특성’, ‘교육 정책에 대한 기대’의 6개 범주로 분류되었다. ‘교사 사기(열의) 및 효능감’, ‘현 학교 만족도’, ‘학교 풍토 및 조직 문화’, ‘개인적 특성’은 선행 연구에서 다뤄졌던 변수들이고, ‘공개수업에 대한 인식’, ‘교육 정책에 대한 기대’는 본 연구를 통해 새롭게 발견한 변수들이다. 본 연구 결과를 바탕으로 교사 만족도를 향상시키기 위한 교육정책의 방향성에 대하여 제언하였다.","The purpose of this study was to explore important variables to teacher job satisfaction. Elastic net, a machine learning technique, was employed to analyze the 5th wave GEPS data. Particularly, relevance count was obtained after 100 iterations, and variables selected 1 out of 3 were considered to be important. A total of 29 variables were such important variables, selected among 223 teacher variables. The selected variables were grouped into six categories according to the variable classification of GEPS: ‘Teacher morale (enthusiasm) and Efficacy’, ‘Current School Satisfaction’, ‘School climate and organizational culture’, ‘personal characteristic’, ‘Recognition of open class’, and finally ‘Expectation of educational policy’. Variables pertaining to ‘Teacher morale (enthusiasm) and Efficacy’, ‘Current School Satisfaction’, ‘School climate and Organizational culture’, ‘personal characteristic’ and ‘Recognition of open class’ have been investigated in the literature. Some variables in the ‘Recognition of open class’ and ‘Expectation of educational policy’ categories were newly found variables important to teacher job satisfaction. Implications of the study were discussed, particularly on education policy relating to teacher job satisfaction."
기어 이 파손 정도에 따른 진동신호의 특징기반 경향 감시,2019,"['Gear Tooth Breakage(기어 이 파손)', 'Machine Learning(기계학습)', 'Trend Monitoring(경향 감시)', 'Feature Based(특징기반)']",,
Review of statistical methods for survival analysis using genomic data,2019,"['censoring', 'Cox model', 'Kaplan-Meier curve', 'machine learning', 'regularization', 'survival time']",,"Survival analysis mainly deals with the time to event, including death, onset of disease, and bankruptcy. The common characteristic of survival analysis is that it contains ""censored"" data, in which the time to event cannot be completely observed, but instead represents the lower bound of the time to event. Only the occurrence of either time to event or censoring time is observed. Many traditional statistical methods have been effectively used for analyzing survival data with censored observations. However, with the development of high-throughput technologies for producing ""omics"" data, more advanced statistical methods, such as regularization, should be required to construct the predictive survival model with high-dimensional genomic data. Furthermore, machine learning approaches have been adapted for survival analysis, to fit nonlinear and complex interaction effects between predictors, and achieve more accurate prediction of individual survival probability. Presently, since most clinicians and medical researchers can easily assess statistical programs for analyzing survival data, a review article is helpful for understanding statistical methods used in survival analysis. We review traditional survival methods and regularization methods, with various penalty functions, for the analysis of high-dimensional genomics, and describe machine learning techniques that have been adapted to survival analysis."
전류 및 자속센서를 이용한 유도전동기 예방진단 알고리즘 개발에 관한 연구,2019,"['Current', 'Diagnostic system', 'Induction motor', 'Magnetic flux', 'Machine learning']","본 논문은 전류신호와 자속신호를 이용한 유도전동기 예방진단시스템을 개발하기 위한 머신러닝 알고리즘의 개발 및 적용 결과에 대하여 논하였다. 유도전동기의 결함 종류를 판별하기 위한 최적 특징추출단계를 통하여 총 29개의 특징을 도출하였다. 특히, 전류신호의 제7차 고조파 중심으로부터 사이드밴드까지의 주파수의 차이가 부하율 증가에 따라서 증가되는 경향을 이용하여 임의의 부하율 상태를 반영할 수 있는 알고리즘을 도출하였으며, KPCA 특징 축소 기법, k-NN 판단 알고리즘에 의한 분류 정확도를 조사한 결과, 약 84.6%의 분류 정확도를 보였다.","This paper discussed the results of the development and application of the machine learning algorithm to the induction motor for the preventive diagnostic system using current and magnetic flux signals. The optimal 29 features were extracted for identifying faulted types of induction motor. In particular, any load rate was derived using the tendency of the difference value from the center of the 7th harmonic frequency to the sideband of the current signal, and the corresponding classification accuracy showed about 84.6% by the KPCA feature reduction technique and the k-NN determination algorithm."
Systematic Review of Bug Report Processing Techniques to Improve Software Management Performance,2019,"['Bug Report', 'Clustering', 'Duplication Detection', 'Information Retrieval', 'Machine Learning', 'Priority', 'Severity', 'Software Developer Assignment', 'Software Management', 'Triage']",,"Bug report processing is a key element of bug fixing in modern software maintenance. Bug reports are not processed immediately after submission and involve several processes such as bug report deduplication and bug report triage before bug fixing is initiated; however, this method of bug fixing is very inefficient because all these processes are performed manually. Software engineers have persistently highlighted the need to automate these processes, and as a result, many automation techniques have been proposed for bug report processing; however, the accuracy of the existing methods is not satisfactory. Therefore, this study focuses on surveying to improve the accuracy of existing techniques for bug report processing. Reviews of each method proposed in this study consist of a description, used techniques, experiments, and comparison results. The results of this study indicate that research in the field of bug deduplication still lacks and therefore requires numerous studies that integrate clustering and natural language processing. This study further indicates that although all studies in the field of triage are based on machine learning, results of studies on deep learning are still insufficient."
Comparative Study of Prediction Models for High School Student Performance in Mathematics,2019,"['Student performance', 'Statistical analysis technique', 'Machine learning algorithms', 'Deep belief network']",,"Measuring students’ performance and observing their learning behaviors are challenging tasks that can assist students and teachers in keeping track of progress in academic performance. Predicting student performance in mathematics has gained considerable attention from many researchers. Because a single tool may not be easily scalable from one context to another, several learning algorithms have been observed and compared for selecting an optimized prediction model. In this paper, we proposed a comparative study of the statistical analysis (SA) technique, machines learning (ML) algorithms, and a deep learning architecture for predicting student performance in mathematics. A proposed predictive structural equation modeling of SA, five superior classifiers in ML, and a graphical model for deep learning were executed and compared. Three datasets named, DS1, DS2, and DS3 were used in this analysis. We applied two main evaluation metrics, accuracy and predictive mean square error (PMSE), to measure the performance of the proposed models. On the three datasets, random forest produced the highest accuracy and the smallest PMSE which shows its potential as the best prediction model for the problem."
적은 양의 데이터에 적용 가능한계층별 데이터 증강 알고리즘,2019,"['딥러닝', '데이터 증강', '고유값 분해', 'Deep learning', 'data augmentation', 'Eigen decomposition']","데이터 증강(Data Augmentation)은 적은 양의 데이터를 바탕으로 다양한 알고리즘을 통해 데이터의 양을 늘리는 기술이다. 현실 문제를 해결하기 위해 기계학습 및 딥러닝 기법을 사용하는 경우, 데이터 셋이 부족한 경우가 많다. 데이터의 부족은 모델 학습 시, 데이터 셋의 특징을 잘 반영하지 못하는 것 이외에도 과소적합 및 과적합에 빠질 위험이 크다. 따라서 본 논문에서는 오토인코더와 고유값 분해를 기반으로 하는 데이터 증강 기법을 통해 데이터를 증강 시키고 이를 심층 신경망의 각 층 마다 적용하여, 심층 신경망을 효과적으로 사전 학습하는 방법을 제시한다. 이후, WOBC 데이터와 WDBC 데이터에 대해 실험을 통하여 논문에서 제안하는 방법이 분류 정확도를 향상시키는지 측정하고 기존 연구들과 비교함으로써 제안한 방법이 실질적으로 의미가 있는 데이터를 생성하고 모델의 학습에 효과적임을 보인다.","Data augmentation is a method that increases the amount of data through various algorithms based on a small amount of sample data. When machine learning and deep learning techniques are used to solve real-world problems, there is often a lack of data sets. The lack of data is at greater risk of underfitting and overfitting, in addition to the poor reflection of the characteristics of the set of data when learning a model. Thus, in this paper, through the layer-wise data augmenting method at each layer of deep neural network, the proposed method produces augmented data that is substantially meaningful and shows that the method presented by the paper through experimentation is effective in the learning of the model by measuring whether the method presented by the paper improves classification accuracy."
Doc2Vec 단어 임베딩 언어 모델을 활용한 텍스트 장르 구분,2019,"['Text genre', 'word embedding', 'corpus linguistics', 'deep learning', 'machine learning']",,"According to Biber (1993) and Biber and Conrad (2009), multiple dimensional approach on several bi-polar features can classify genres founds in texts. Problem is that the process between feature extraction and statistical model building is exhaustively applicable when the machine learning system is dependent on frequency based language models. Following the machine learning approach of Kanaris and Stmatatos (2007), nearly 8,000 frequency-based models are used to induce genre distinction. If their whole process is not successful, they have to exhaustively redo the classification process.Upon such problem, we used a word embedding language model in order to deal feature extraction and model building at the same time. Among several word embedding models, our research is based on Doc2Vec model which captures paragraph feature of texts. We used the genre distinctions from the Project Gutenberg, deviding text databases into three parts in revealing distributional characteristics of linguistic features. Our method for detecting text genre is convenient in process as well as accurate in capturing feature distribution of text genre."
Digital Medicine in Thyroidology: A New Era of Managing Thyroid Disease,2019,"['Thyroid', 'Thyroid neoplasms', 'Hyperthyroidism', 'Hypothyroidism', 'Artificial intelligence', 'Machine learning', 'Database', 'Wearable electronic devices']",,"Digital medicine has the capacity to affect all aspects of medicine, including disease prediction, prevention, diagnosis, treatment, and post-treatment management. In the field of thyroidology, researchers are also investigating potential applications of digital technology for the thyroid disease. Recent studies using artificial intelligence (AI)/machine learning (ML) have reported reasonable performance for the classification of thyroid nodules based on ultrasonographic (US) images. AI/ML-based methods have also shown good diagnostic accuracy for distinguishing between benign and malignant thyroid lesions based on cytopathologic findings. Assistance from AI/ML methods could overcome the limitations of conventional thyroid US and fine-needle aspiration cytology. A webbased database has been developed for thyroid cancer care. In addition to its role as a nationwide registry of thyroid cancer, it is expected to serve as a clinical platform to facilitate better thyroid cancer care and as a research platform providing comprehensive disease-specific big data. Evidence has been found that biosignal monitoring with wearable devices may predict thyroid dysfunction. This real-world thyroid function monitoring could aid in the management and early detection of thyroid dysfunction. In the thyroidology field, research involving the range of digital medicine technologies and their clinical applications is expected to be even more active in the future."
Systematic Review of Bug Report Processing Techniques to Improve Software Management Performance,2019,"['Bug Report', 'Clustering', 'Duplication Detection', 'Information Retrieval', 'Machine Learning', 'Priority', 'Severity', 'Software Developer Assignment', 'Software Management', 'Triage']",,"Bug report processing is a key element of bug fixing in modern software maintenance. Bug reports are not processed immediately after submission and involve several processes such as bug report deduplication and bug report triage before bug fixing is initiated; however, this method of bug fixing is very inefficient because all these processes are performed manually. Software engineers have persistently highlighted the need to automate these processes, and as a result, many automation techniques have been proposed for bug report processing; however, the accuracy of the existing methods is not satisfactory. Therefore, this study focuses on surveying to improve the accuracy of existing techniques for bug report processing. Reviews of each method proposed in this study consist of a description, used techniques, experiments, and comparison results. The results of this study indicate that research in the field of bug deduplication still lacks and therefore requires numerous studies that integrate clustering and natural language processing. This study further indicates that although all studies in the field of triage are based on machine learning, results of studies on deep learning are still insufficient."
A Review of Intelligent Self-Driving Vehicle Software Research,2019,"['Self-driving vehicle', 'Road infrastructure', 'Deep learning', 'Machine learning', 'Localization']",,"Interest in self-driving vehicle research has been rapidly increasing, and related research has been continuously conducted. In such a fast-paced self-driving vehicle research area, the development of advanced technology for better convenience safety, and efficiency in road and transportation systems is expected. Here, we investigate research in self-driving vehicles and analyze the main technologies of driverless car software, including: technical aspects of autonomous vehicles, traffic infrastructure and its communications, research techniques with vision recognition, deep leaning algorithms, localization methods, existing problems, and future development directions. First, we introduce intelligent self-driving car and road infrastructure algorithms such as machine learning, image processing methods, and localizations. Second, we examine the intelligent technologies used in self-driving car projects, autonomous vehicles equipped with multiple sensors, and interactions with transport infrastructure. Finally, we highlight the future direction and challenges of self-driving vehicle transportation systems."
Multi-Layer Perceptron 기법을 이용한 전력 분석 공격 구현 및 분석,2019,"['Side-Channel Analysis', 'Power Analysis Attack', 'Deep Learning MLP', 'Machine Learning SVM']","본 논문에서는 기존 전력 분석 공격의 어려움과 비효율성을 극복하기 위해 딥 러닝 기반의 MLP(Multi-LayerPerceptron) 알고리즘을 기반으로 한 공격 모델을 사용하여 암호 디바이스의 비밀 키를 찾는 공격을 시도하였다.제안하는 전력 분석 공격 대상은 XMEGA128 8비트 프로세서 상에서 구현된 AES-128 암호 모듈이며, 16바이트의비밀 키 중 한 바이트씩 복구하는 방식으로 구현하였다. 실험 결과, MLP 기반의 전력 분석 공격은 89.51%의 정확도로 비밀 키를 추출하였으며 전처리 기법을 수행한 경우에는 94.51%의 정확도를 나타내었다. 제안하는 MLP 기반의 전력 분석 공격은 학습을 통한 feature를 추출할 수 있는 성질이 있어 SVM(Support Vector Machine)과 같은 머신 러닝 기반 모델보다 우수한 공격 특성을 보임을 확인하였다.","To overcome the difficulties and inefficiencies of the existing power analysis attack, we try to extract the secret keyembedded in a cryptographic device using attack model based on MLP(Multi-Layer Perceptron) method. The target of ourproposed power analysis attack is the AES-128 encryption module implemented on an 8-bit processor XMEGA128. We usethe divide-and-conquer method in bytes to recover the whole 16 bytes secret key. As a result, the MLP-based poweranalysis attack can extract the secret key with the accuracy of 89.51%. Additionally, this MLP model has the 94.51%accuracy when the pre-processing method on power traces is applied. Compared to the machine leaning-based modelSVM(Support Vector Machine), we show that the MLP can be a outstanding method in power analysis attacks due toexcellent ability for feature extraction."
Development of Wave Overtopping Formulas for Inclined Seawalls using GMDH Algorithm,2019,"['CLASH database', 'GMDH algorithm', 'inclined seawalls', 'machine learning', 'wave overtopping rate']",,"Since wave overtopping is a very complex phenomenon and is sensitive to hydraulic and structural parameters, hydraulic model tests have been used to estimate the wave overtopping rates at coastal structures. Efforts have also been made toward developing empirical formulas and machine learning models based on a large amount of accumulated data, e.g., the EurOtop formulas and Artificial Neural Network (ANN) models based on the CLASH database. In this study, new machine learning formulas for inclined seawalls are derived by using the Group Method of Data Handling (GMDH) algorithm with the CLASH and new EurOtop datasets. Because the GMDH formulas are more complex than other empirical formulas, an EXCEL calculator is provided so that engineers can easily use the formulas. The GMDH formulas are shown to be more accurate than other empirical formulas and equally accurate as the EurOtop-ANN model. The estimation errors of 95% confidence interval and the range of 95% prediction error are also given. The sensitivity analysis of the derived formulas shows that the parameters that more influence the wave overtopping rate are in theorder of crest freeboard, structure slope, wave period, and seabed slope."
블록형 프로그래밍 언어 기반 인공지능 교육이 학습자의 인공지능 기술 태도에 미치는 영향 분석,2019,"['인공지능 기술 태도', '인공지능 교육', '스크래치3.0', '머신러닝 모델 개발', 'Machine Learning for kids', 'Artificial Intelligence Technology Attitude', 'Artificial Intelligence Education', 'Scratch 3.0', 'Machine Learning Model Development', 'Machine Learning for kids']","인공지능이 우리 생활의 다양한 곳에 사용되기 시작하였으며, 최근 그 영역 또한 점차 확대되고 있다. 하지만 인공지능에 대한 교육이 초등학생을 대상으로 이루어지고 있지 않기 때문에 학생들이 인공지능 기술에 대해 어렵게 인식하는 경향이 있다. 이에 본 논문에서는 교육용 프로그래밍 언어와 인공지능 교육 방법을 고찰하고, 인공지능에 대한 교육을 실시함으로써 학생들의 인공지능 기술에 대한 태도의 변화를 살펴보았다. 이를 위해 학생들의 수준에 적절한 블록형 프로그래밍 언어 기반 인공지능 기술에 대한 교육을 실시하였다. 그리고 학생들의 인공지능 기술에 대한 태도를 단일집단 사전사후 검사를 통해 태도의 변화를 살펴보았다. 그 결과 인공지능에 대한 흥미, 인공지능 기술에 대한 접근 가능성, 학교에서 인공지능 기술에 대한 교육의 필요성에 있어 유의미한 향상을 가져왔다.","Artificial intelligence has begun to be used in various parts of our lives, and recently its sphere has been expanding. However, students tend to find it difficult to recognize artificial intelligence technology because education on artificial intelligence is not being conducted on elementary school students. This paper examined the teaching programming language and artificial intelligence teaching methods, and looked at the changes in students' attitudes toward artificial intelligence technology by conducting education on artificial intelligence. To this end, education on block-type programming language-based artificial intelligence technology was provided to students' level. And we looked at students' attitudes toward artificial intelligence technology through a single group pre-postmortem. As a result, it brought about significant improvements in interest in artificial intelligence, possible access to artificial intelligence technology and the need for education on artificial intelligence technology in schools."
컴퓨터 보조 진단 시스템 기반 치아우식증 검출 기법 비교 분석,2019,"['Dental caries', 'Caries detection', 'CADx', 'Machine learning']",,"Dental caries, a gradual bacterial damage to teeth, is one of the most common diseases and is still a major cause of tooth loss. It can be divided into 7 scores based on the ICDAS(International Caries Detection and Assessment System) according to the tooth condition. Early detection and treatment of dental caries can reduce the costs as well as time. As computer performance has been improved, machine learning and image processing technologies are introduced to detect and diagnose dental caries. Computer-aided Diagnosis(CADx) can assist dentists in the interpretation of several oral digital images or X-ray image. Dental caries detection system using CADx has four steps. First is image enhancement to improve the original image. Second is tooth detection which extract the tooth area from the oral structures. Third is caries detection which finds the caries lesion in tooth area. The fourth is classification which analyzes and classifies carious lesions. In this paper, we survey and introduce the various dental caries detection methods based on CADx."
Gradient-descent-based Velocity Observer with a Residual Displacement Term for ILSMC in Contour Following Applications,2019,['Disturbance compensation Velocity observer Iterative learning sliding mode control'],,"Industrial applications such as pick-and-place tasks and CNC machining often involve repetitive motions that may contain periodic disturbances. Due to the periodic nature of these applications, the idea of iterative learning control can be exploited to cope with external periodic disturbances so as to improve system performance. In addition, in order to ensure satisfactory motion accuracy for operation scenarios that may encounter significant disturbance, (e.g., machining and polishing), a robust controller is essential. In particular, iterative learning sliding mode control (ILSMC) is shown to be suitable for control applications that encounter periodic disturbances. However, when the disturbance contains high frequency components, ILSMC may become less effective in compensating for external disturbances if its velocity estimation is not accurate enough. In order to cope with the aforementioned problem, this paper develops a gradient-descent-based velocity observer with a residual displacement compensation term to provide accurate velocity feedback to be used in ILSMC. Both theoretical analysis and experimental results are provided to verify the effectiveness of the proposed approach."
토픽 모델링을 이용한 유튜브 설교 동영상 리뷰 분석,2019,"['토픽모델', '기계학습', '자연어처리', '설교 동영상', 'Topic Modeling', 'Machine Learning', 'Natural Language Processing', 'Sermon Topic']","다양한 대용량의 데이터를 처리하는 컴퓨터 기술의 발달로 텍스트 데이터를 분석하는 방법은 기계학습과 자연어처리에서 최근 토픽 모델링으로 큰 발전을 이루어 왔다. 토픽모델링은 문서에서 추상적인 ""주제""를 발견하기 위한 모델로 텍스트 본문의 숨겨진 의미구조를 발견하기 위해 사용하는 텍스트 마이닝 기법 중 하나이다.본 연구는 유튜브 설교 동영상의 리뷰를 토픽 모델링으로 설교에 대한 반응을 몇 개의 토픽별로 나누어 분석하였다. 분석결과 5개의 토픽으로 분류하였다. 토픽 5개 중 3개 토픽 1(감사와 은혜), 토픽 2(하나님의 마음), 토픽 4(감사설교)는 온라인 고객 리뷰들처럼 본 설교 동영상의 핵심 속성으로 볼 수 있지만, 다른 두 토픽 토픽 3(성도의 생각)과 토픽 5(존경과 기도)는 설교 동영상과는 거리가 있는 리뷰가 포함된 것을 볼 수 있다. 따라서 교회 입장에 볼 때 설교 동영상과 관련성이 높은 리뷰에 대한 체계적이고 객관적인 평가와 관리가 요구된다. 사용자들이 기록한 리뷰들을 토필별로 분류하여 긍정적인 리뷰들과 가장 관련성이 높은 리뷰들을 부각시키는 리뷰의 재배열이 필요하다. 또한 긍적적인 리뷰들을 포함한 토픽을 사용하여 해시태그 할 수 있는 방안을 검토하여 설교 동영상의 방문자 수를 확산시키는 방안을 강구할 수 있다.","With the development of computer technology to process various large amounts of data, the method of analyzing text data has made great progress in recent topic modeling in machine learning and natural language processing. Topic modeling is a model for discovering abstract ""topics"" in a document and is one of the text mining techniques used to discover the hidden semantics of text bodies. This study analyzed the response to the sermon by topic modeling based on the reviews of the YouTube sermon video. The results were classified into five topics. Three of the five topics, topics 1, 2, and 4 can be viewed as key attributes of this sermon video, like online customer reviews, while the other two topics 3 and 5 contain reviews that are far from the sermon video. This is not a sermon video but a review of the preacher's previous words or deeds. Therefore, from the church's point of view, systematic and objective evaluation and management of reviews is required. There is a need for a rearrangement method of reviews in which reviews recorded by users are classified by topic to highlight positive reviews. We can also consider ways to hashtag using topics that include positive reviews to find ways to spread the number of visitors to sermon videos."
낙하물에 기인한 안전사고의 연관규칙 분석,2019,"['construction safety', 'falling objects', 'data science', 'machine learning', 'association rules', 'hierarchical clustering', '건설안전', '낙하물', '데이터 사이언스', '기계 학습', '연관규칙 분석', '계층적 군집화']","건설업은 전체 산업 중에서 가장 많은 재해자를 발생시키는 산업 분야이다. 각 재해에서 발견되는 반복되는 요인들로 인해 재해가 발생하기 때문에 기존의 기술통계 분석 및 통계적 검정으로 업무상 재해 유형을 분석하는 데 한계가 있다. 이에 본 연구는 건설현장에서 발생하는 재해 유형 중 낙하물에 기인한 안전사고에 대하여 사망과 부상 사고로 구분하여 사고 원인들을 도출한다. 또한, 기계학습 기법 중 연관 규칙 분석 방법을 통하여 낙하물에 기인한 안전사고의 규칙을 발견하고, 낙하물의 요인들을 군집하여 중점 재해요인을 도출한다. 본 연구에서 제안한 낙하물에 기인한 사망과 부상 사고에 대한 규칙을 감안하여 낙하물에 기인한 안전사고에 대한 대처방안을 모색하면 보다 정확한 사고예방이 가능할 것으로 판단된다.","Construction industry is one of the most dangerous industry. As the construction accidents occur due to the repeated factors found in each accidents, there is a limitation in analyzing all types of occupational accidents by the existing descriptive analysis and statistical test. In this study, we classified safety accidents caused by falling objects among the accident types occurring at construction sites into fatal and nonfatal accidents and deduced the factors. In addition, we deduced the association rules among the safety accidents factors caused by falling objects through the association rule analysis method among the machine learning techniques. Therefore, considering the association rules for fatal and nonfatal accidents proposed in this study, it would be possible to prevent accidents by searching for countermeasures against safety accidents caused by falling objects."
[융합 컴퓨팅] 컴퓨팅 자원의 가용성을 보장하기 위한 기계 학습 기반의 실시간 장애 예측 프레임워크 연구,2019,"['Online failure prediction', 'System monitoring', 'Automated machine learning']",,
실제 컨버터 출력 데이터를 이용한 특정 지역 태양광 장단기 발전 예측,2019,"['Photovoltaic', 'linear regression', 'Support vector machine', 'Deep neural network', 'Recurrent neural network']","태양광 발전은 일사량만 있으면 전기에너지를 얻을 수 있기 때문에, 새로운 에너지 공급원으로 용도가 급증하고 있다. 본 논문은 실제 태양광 발전 시스템의 컨버터 출력을 이용하여 장단기 출력 예측을 하였다. 예측 알고리즘은 다중선형회귀와 머신러닝의 지도학습 중 분류모델인 서포트 벡터 머신 그리고 DNN과 LSTM 등 딥러닝을 이용하였다. 또한 기상요소의 입출력 구조에 따라 3개의 모델을 이용하였다. 장기 예측은 월별, 계절별, 연도별 예측을 하였으며, 단기 예측은 7일간의 예측을 하였다. 결과로서 RMSE 측도에 의한 예측 오차로 비교해 본 결과 다중선형회귀와 SVM 보다는 딥러닝 네트워크가 예측 정확도 측면에서 더 우수하였다. 또한, DNN 보다 시계열 예측에 우수한 모델인 LSTM이 예측 정확도 측면에서 우수하였다. 입출력 구조에 따른 실험 결과는 모델 1보다 모델 2가 오차가 적었으며, 모델 2보다는 모델 3이 오차가 적었다.","Solar photovoltaic can provide electrical energy with only radiation, and its use is expanding rapidly as a new energy source. This study predicts the short and long-term PV power generation using actual converter output data of photovoltaic system. The prediction algorithm uses multiple linear regression, support vector machine (SVM), and deep learning such as deep neural network (DNN) and long short-term memory (LSTM). In addition, three models are used according to the input and output structure of the weather element. Long-term forecasts are made monthly, seasonally and annually, and short-term forecasts are made for 7 days. As a result, the deep learning network is better in prediction accuracy than multiple linear regression and SVM. In addition, LSTM, which is a better model for time series prediction than DNN, is somewhat superior in terms of prediction accuracy. The experiment results according to the input and output structure appear Model 2 has less error than Model 1, and Model 3 has less error than Model 2."
설명 가능한 인공지능 기반의 프로세스 마이닝 분석 자동화 연구,2019,"['Process mining', 'Process analysis automation', 'Machine learning', 'eXplainable AI']","업무 혁신을 위한 경영기법 중 하나인 프로세스 마이닝은 정보 시스템 로그에서 실행 프로세스 모델을 작성하는 것을 자동화하였으나, 프로세스 내용을 분석하여 문제에 대한 원인을 분석하는 영역에서는 여전히 분석가의 관련 경험과 업무 도메인에 대한 지식에 많이 의존하고 있다. 특히 대부분의 도출된 프로세스 모델이 매우 복잡하기 때문에 사람의 인식 능력의 한계로 인해 정확한 분석이 불가능하여 프로세스 마이닝 알고리즘에서는 추상화 과정을 거치는데, 이 과정에서 왜곡이 발생하거나 정작 중요한 이슈를 놓치게 될 가능성이 있다. 본 연구에서는 먼저 머신러닝 모델 중 LSTM 알고리즘을 이용한 프로세스 예측 모델을 개발하여 프로세스의 수행결과를 예측하였고 다시 이 예측모델에 설명 가능한 인공지능 기법을 적용하여 분석함으로써 최종적으로 프로세스 수행결과에 가장 큰 영향을 미치는 원인을 탐색하는 작업을 자동화하였다. 이를 통해 프로세스 마이닝에 대한 원인 분석 과정에서 인간의 직관과 업무지식에 대한 의존을 획기적으로 낮추었으며 정량적이고 신속한 프로세스 분석이 가능하게 되었다.","Process mining is one of the business management techniques for business innovation. While it automates the creation of execution process models in the information system log, it still relies on the analyst's relevant experience and knowledge of the business domain in analyzing the process content and the root cause of the problem. Since most of the derived process models are very complicated, an accurate analysis is impossible due to the limitations of human cognition ability, and most of the process mining algorithms go through an abstraction process. There is a possibility that distortions may occur in this process, or important issues may be missed. Hence, in this study, we attempted to predict the process results by using the process prediction model incorporating a LSTM algorithm of machine learning, and then to apply an explainable artificial intelligence(XAI) technique. Thus, this study has drastically reduced the reliance on the human intuition and knowledge in the root cause analysis of process mining, enabling the quantitative and rapid analysis."
Safety Air Bag System for Motorcycle Using Parallel Neural Networks,2019,['Neural network IMU MPU Air bag Machine learning Motorcycle safety Artificial intelligence'],,"Due to the development of leisure sports industry and the increase in delivery demand, the demand for two-wheeled vehicles such as the motorcycle is increasing every year; moreover, the motorcycle accident rate is increasing. The motorcyclist’s body is exposed to the outside, and in cases of accidents, the head and the neck are particularly vulnerable. This paper proposes a study about an air bag equipped with Artificial Intelligence to protect the driver’s neck spine from motorcycle accidents. Through the six-axis sensor, it receives the driver’s motor condition data about the acceleration and angular velocity data and measures real time speed and angle; combines them with algorithms that can judge accidents through Artificial Intelligence learning to activate airbags in real time. Data were collected and learned by dividing the types of accidents; for Artificial Intelligence learning, the general Neural Network method was not used however, a mix of parallel Neural Network with an existing Neural Network were used instead. The Artificial Intelligence learning method proposed in this paper has been found to have more improved accuracy, stability and learning time compared to the existing Neural Network."
Multivariate Time Frequency Analysis of Electrohysterogram for Classification of Term and Preterm Labor,2019,['Preterm birth detection · EHG · Uterine EMG · Machine learning classifi cation · NA-MEMD'],,"Non-invasive electrohysterogram (EHG) could be a promising technique for the preterm birth prediction, which could enable us to diagnose the preterm birth before the labor and reduces the infant mortality and morbidity. Previous studies on the preterm birth prediction with EHG have conducted comprehensive researches on various signal features and classifi cation algorithms, but most of them adopted prefi lters based on the linear transforms using fi xed basis function, although they are suboptimal for the nonlinearity and nonstationarity of the EHG signal. In this paper, multivariate empirical mode decomposition (MEMD) is applied to decompose the electrical activity signal measured on the uterus. After the decomposition, features are calculated for the corresponding oscillations to the uterine contraction. To investigate the performance of the features, three-channel EHG signals of 254 patients (224 term, 30 preterm) are chosen among 300 patients from Physionet term-preterm electrohysterogram (TPEHG) database to extract features from the EHG signals and classify the features using machine learning algorithms. Classifi cation results shows that the proposed method with MEMD achieved 94.66% correctly classifi ed rate (CCR) and 0.987 area under the curve (AUC), which outperformed those with IIR fi lter implying MEMD provides a new prospect to improve the current preterm birth prediction approach."
Vibration signal based condition monitoring of mechanical equipment with scattering transform,2019,"['Bearing fault diagnosis', 'Scattering convolution network', 'Scattering transform', 'Support vector machine']",,"Scattering transform is proposed using machine learning to extract translational, rotational and deformation invariant information for the first time from vibration signals obtained from rolling element bearings (REBs). The core idea of scattering transform lies in the construction of a scattering network which is formed from a stack of signal processing layers of increasing width. Each layer is formed from the association of a linear filter bank with a non-linear operator. It uses a cascade of wavelet filter bank, modulus rectifiers and averaging operators to build a deep convolution network and computes multi-scale co-occurrence coefficients which are invariant to translation in time, rotation and deformation. The scattering transform coefficients are extracted as features from seven stages of a vibration signal prognosis data repository which are then input to a support vector machine (SVM) classifier. Vibration signals from the intelligent management system (IMS) bearing data centre are used to validate the proposed algorithm. Test results analysis and solution show that scattering transform can be used to obtain distinguishing features from seven bearing health stages with an average accuracy of 99 %. The results were compared with other feature extraction strategies on the same data and were found to be superior."
Control of Seesaw balancing using decision boundary based on classification method,2019,"['logistic regression', 'brushless motor', 'gradient', 'cost function', 'machine learning']",,"One of the key objectives of control systems is to maintain a system in a specific stable state.To achieve this goal, a variety ofcontrol techniques can be used and it is often uses a feedback control method. As known this kind of control methods requires mathematical model of the system. This article presents seesaw unstable system with two propellers which are controlled without use of a mathematical model instead. The goal was to control it using training data. For system control we use a logistic regression technique which is one of machine learning method. We tested our controller on the real model created in our laboratory and the experimental results show that instability of the seesaw system can be fixed at a given angle using the decision boundary estimated from the classification method. The results show that this control method for structural equilibrium can be used with relatively moreaccuracy of the decision boundary."
Differentiation of Aphasic Patients from the Normal Control Via a Computational Analysis of Korean Utterances,2019,"['Aphasia', 'Automatic Speech Analysis', 'Computational Analysis', 'PCA', 'Machine Learning']",,"Spontaneous speech provides rich information defining the linguistic characteristics of individuals. As such, computational analysis of speech would enhance the efficiency involved in evaluating patients’ speech. This study aims to provide a method to differentiate the persons with and without aphasia based on language usage. Ten aphasic patients and their counterpart normal controls participated, and they were all tasked to describe a set of given words. Their utterances were linguistically processed and compared to each other. Computational analyses from PCA (Principle Component Analysis) to machine learning were conducted to select the relevant linguistic features, and consequently to classify the two groups based on the features selected. It was found that functional words, not content words, were the main differentiator of the two groups. The most viable discriminators were demonstratives, function words, sentence final endings, and postpositions. The machine learning classification model was found to be quite accurate (90%), and to impressively be stable. This study is noteworthy as it is the first attempt that uses computational analysis to characterize the word usage patterns in Korean aphasic patients, thereby discriminating from the normal group."
빅데이터 분석을 활용한 GPS 전파교란 대응방안,2019,"['GPS', 'Elecromagnetic Interference', 'OODA LOOP', 'Autonomous System', 'Machine Learning.']","인공지능은 우리 실생활과 밀접하게 연관되어 다양한 분야에서 혁신을 주도하고 있다. 특히 인공지능을 보유한 이동수단으로서, 자율무인이동체의 연구가 활발하게 이루어지고 곧 실용화를 앞두고 있다. 자율자동차와 무인기 등이 스스로 경로를 설정하고 목적지까지 이동하기 위해서는 정확한 위치정보를 제공하는 항법장비가 필수적이다. 현재 운용되고 있는 이동수단들의 항법은 대부분 GPS에 의존하고 있다. 그러나 GPS는 외부 교란에 취약하다. 지난 2010년부터 북한은 수차례 GPS교란을 감행하여 우리 측에 이동통신, 항공기 운항 등에 심각한 장애를 유발했다. 따라서 자율무인이동체의 안전성을 보장하고 교란으로 인한 피해를 방지하기 위해서는 신속한 상황판단과 대응이 요구된다. 본 논문에서는 빅데이터, 머신러닝 기술을 기반으로 John Boyd의 OODA LOOP Cycle(탐지-방향설정-결심-행동)을 적용한 조치방안 도출과 결심을 지원하는 GPS 전파교란 대응체계를 제시하였다.","Artificial intelligence is closely linked to our real lives, leading innovation in various fields. Especially, as a means of transportation possessing artificial intelligence, autonomous unmanned vehicles are actively researched and are expected to be put into practical use soon. Autonomous cars and autonomous unmanned aerial vehicles are required to equip accurate navigation system so that they can find out their present position and move to their destination. At present, the navigation of transportation that we operate is mostly dependent on GPS. However, GPS is vulnerable to external intereference. In fact, since 2010, North Korea has jammed GPS several times, causing serious disruptions to mobile communications and aircraft operations. Therefore, in order to ensure safety in the operation of the autonomous unmanned vehicles and to prevent serious accidents caused by the intereference, rapid situation judgment and countermeasure are required. In this paper, based on big data and machine learning technology, we propose a countermeasure system for GPS interference that supports decision making by applying John Boyd 's OODA loop cycle (detection - direction setting - determination – action)."
Systematic Review of Bug Report Processing Techniques to Improve Software Management Performance,2019,"['Bug Report', 'Clustering', 'Duplication Detection', 'Information Retrieval', 'Machine Learning', 'Priority', 'Severity', 'Software Developer Assignment', 'Software Management', 'Triage']",,"Bug report processing is a key element of bug fixing in modern software maintenance. Bug reports are notprocessed immediately after submission and involve several processes such as bug report deduplication andbug report triage before bug fixing is initiated; however, this method of bug fixing is very inefficient because allthese processes are performed manually. Software engineers have persistently highlighted the need to automatethese processes, and as a result, many automation techniques have been proposed for bug report processing;however, the accuracy of the existing methods is not satisfactory. Therefore, this study focuses on surveying toimprove the accuracy of existing techniques for bug report processing. Reviews of each method proposed inthis study consist of a description, used techniques, experiments, and comparison results. The results of thisstudy indicate that research in the field of bug deduplication still lacks and therefore requires numerous studiesthat integrate clustering and natural language processing. This study further indicates that although all studiesin the field of triage are based on machine learning, results of studies on deep learning are still insufficient."
CNN을 이용한 레이다 신호 자동 분류,2019,"['Radar Signal Classification', 'Jamming Technique', 'Machine Learning', 'Convolution Neural Network', '-']",,"In this paper, we propose a classification method for radar signals depending on the type of threat by applying machine learning to parameter data of radar signals . Currently, the army uses a library of mapping relations between the parameters and the types of threat to recognize threat signals. This approach has certain limitations when classifying signals and recognizing new types of threat or types of threat that do not exist in the current libraries. In this paper, we propose an automatic radar signal classification method depending on the type of threat that uses only parameter data without a library. A convolutional neural network is used as the classifier and machine learning is applied to train the classifier. The proposed method does not use a library, and hence, can classify threat signals that are new or do not exist in the current library."
입력 패턴 학습을 통해 터치 영역 최적화를 지원하는 가상키보드의 사용성 평가,2019,"['Virtual keyboard', 'Touch area optimization', 'Text input', 'Machine learning']",,"Objective: The purpose of this study was to verify the usability of two typical smartphone virtual keyboards that optimize the touch area of each key by learning touch input patterns.Background: Virtual keyboards have many limitations due to their small size and lack of tactile feedback. Therefore, many studies have been conducted to improve the usability of the virtual keyboard. Among them, the verification on the usefulness of a virtual keyboard, with which optimizes the user’s touch area by learning his or her input pattern, is still insufficient.Method: In this study, the participants performed the task of inputting presented sentences using three virtual keyboards (Nota, AL, and Smartboard) that provide different levels of touch optimization support. Through the experiment, sentence matching ratio and typing time data were collected, and subjective satisfaction were also rated after the typing task was finished.Results: There were significant differences in the sentence matching ratio, typing time, and subjective satisfaction between Nota, AL and Smartboard. The Nota keyboard showed significantly better performances than the Smartboard in all respects. However, the AL keyboard showed no significant difference in sentence matching ratio and typing time compared to the Smartboard without such optimization function. Rather, the AL keyboard was less satisfied than the Smartboard.Conclusion: Automatically optimizing the touch area based on users"" input pattern was more useful to the users than predicting, visually expanding and highlighting the keys that will be entered next.Application: In the future, smart phone manufacturers or virtual keyboard makers can use this result as a reference when they want to provide a similar function for touch area optimization."
주문생산시스템에서 고객가치평가에 기반 한 고객계층화 모형,2019,"['Customer value evaluation', 'Customer order classification', 'Machine learning', 'Make-to-order', 'Exploratory data analysis']",,"This paper presents a customer order classification model based on the customer value evaluation for make-to-order manufacturing systems. In the first stage with customer value evaluation, we derive the valuation factors and perform uni-variate and multi-variate variable analysis. In the second stage with customer order classification, we determine cut-off values for the classification of customers, based on the results from the first stage and present the probability distribution of the values of customers.The development of customer value evaluation model relies on the ensemble method, one of the machine learning techniques. We present a whole process of performing customer value evaluation and customer order classification and rating customers, using the public financial statement data of the audited/non-audited corporate firms from 2001 to 2010, provided by the electronic disclosure system DART of the Financial Supervisory Service."
1인 가구 거주자의 생활패턴이 고려된 에너지소요량 유형 분석,2019,"['Building energy efficiency rating', 'Single person household', 'Energy Plus', 'Machine Learning', 'User Clustering', '건축물에너지효율등급', '1인 가구', '에너지 플러스', '머신러닝', '유저 클러스터링']","연구의 목적은 동일건물 내에서 건축물 사용자의 활동에 따른 에너지사용량의 차이정도를 파악하고 사용자의 활동과 인구·사회·경제적 특성과의 관계를 분석하는 것이다. 연구를 위해서 실제 사용자의 활동 스케줄을 기반으로 에너지 시뮬레이션을 실행하고, 머신러닝 기법인 K-Means Clustering을 이용하여 사용자가 실내에서 사용하는 에너지를 변수로 사용하여 에너지사용량을 분류하였다. 그 결과, 에너지사용량에 따라 4가지의 사용자 유형이 도출되었다. 에너지사용량이 많은 클러스터일수록 소득수준이 낮으며 나이가 많다. 재실시간이 길어질수록 에너지사용량이 높으며 이러한 활동은 사용자의 특성과 관계가 있다. 가장 적은 에너지를 사용하는 그룹과 많은 에너지를 사용하는 그룹은 2배 이상의 차이가 존재한다.","The energy of the building is influenced by the user 's activity due to the population, society, and economic characteristics of the building user. In order to obtain accurate energy information, the difference in the amount of energy consumption by the activities and characteristics of building users should be identified. The purpose of the study is to identify the difference in the amount of energy consumption by the user's activities in the same building, and to analyse the relationship between user's activities and demographic, social and economic characteristics. For research, energy simulation is performed based on actual user activity schedule. The results of the simulation were clustered by using K-Means clustering, a machine learning technique. As a result, four types of users were derived based on the amount of energy consumption. The more energy used in a cluster, the lower the user's income level and older. The longer a user's indoor activity times, the higher the energy use, and these activities relate to the user's characteristics. There is more than twice the difference between the group that uses the least energy consumption and the group that uses the most energy consumption."
A Cross-Platform Malware Variant Classification based on Image Representation,2019,"['CSGM', 'Internet security', 'Grayscale image', 'CP-MVCS', 'Malware Detection', 'Machine Learning']",,"Recent internet development is helping malware researchers to generate malicious code variants through automated tools. Due to this reason, the number of malicious variants is increasing day by day. Consequently, the performance improvement in malware analysis is the critical requirement to stop the rapid expansion of malware. The existing research proved that the similarities among malware variants could be used for detection and family classification. In this paper, a Cross-Platform Malware Variant Classification System (CP-MVCS) proposed that converted malware binary into a grayscale image. Further, malicious features extracted from the grayscale image through Combined SIFT-GIST Malware (CSGM) description. Later, these features used to identify the relevant family of malware variant. CP-MVCS reduced computational time and improved classification accuracy by using CSGM feature description along machine learning classification. The experiment performed on four publically available datasets of Windows OS and Android OS. The experimental results showed that the computation time and malware classification accuracy of CP-MVCS was higher than traditional methods. The evaluation also showed that CP-MVCS was not only differentiated families of malware variants but also identified both malware and benign samples in mix fashion efficiently."
학습 데이터 개선을 통한 Anomaly-based IDS의 성능 향상 방안,2019,"['Anomaly based Intrusion Detection System', 'Artificial Neural Network', 'Machine learning']","최근 Anomaly 기반 침입탐지시스템에서의 탐지 기준점 생성을 위해 인공지능 기술을 적용하려는 시도가 활발하게 진행되고 있다. 그러나 인공지능 기술의 적용을 제안한 기존 연구들은 대부분 인공 신경망의 구조 개선과 최적의 하이퍼파라미터 값을 찾는데 중점을 두고 있으며, 학습 데이터의 잘못된 구성으로 인해 발생할 수 있는 다양한 문제점들은 해결하지 못하고 있다. 이에 본 논문에서는 학습 데이터의 잘못된 구성으로 인해 나타날 수 있는 주요 문제점을 실험을 통해 식별하고 학습 데이터의 재구성을 통해 그러한 문제점을 개선함으로써 침입탐지 성능을 향상시킬 수 있는 방안을 제안한다.","Recently, attempts to apply artificial intelligence technology to create the normal profile in Anomaly-based intrusion detection systems have been made actively. But existing studies that proposed the application of artificial intelligence technology mostly focus on improving the structure of artificial neural networks and finding optimal hyper-parameter values, and fail to address various problems that may arise from the misconfiguration of learning data. In this paper, we identify the main problems that may arise due to the misconfiguration of learning data through experiment. And we also propose a novel approach that can address such problems and improve the detection performance through reconstruction of learning data."
PMU 빅데이터를 활용한 계통고장분류 모델 개발,2019,"['WAMS', 'PMU', 'Big-Data', 'CNN', 'Fault Classification']",,"Recently, innovative techniques in artificial intelligence such as machine learning have emerged to efficiently process huge amounts of big data delivered from PMUs to WAMS. Through processing raw data and analyzing big data, It delivers highly useful and valuable system status information to system operators. The types of machine learning vary depending on the usage, but the CNN (Convolution Neural Network) model is mainly used for the post analysis and fault detection(classification) in the power system. In this paper, based on PMU big data, we study the power system fault classification model by using CNN Model. Using Convolution neural network model based on KERAS, the database for each fault type was built and supervised learning was conducted for the model. The constructed model was verified with test data and the validity of the model was verified by inputting the actual power system fault data for the trained model. As a result, developed model classified correctly for the actual fault."
시맨틱 텐서공간모델 기반 텍스트데이터 증식기법,2019,"['Data Augmentation', 'Text Data', 'Semantic Tensor Space Model', 'Machine Learning', 'Training Data', '데이터 증식', '텍스트데이터', '시맨틱 텐서공간모델', '기계학습. 학습데이터']","데이터 증식은 기존의 데이터에서 약간의 변형을 갖는 새로운 데이터를 생성하는 과정이다. 데이터 증식은 데이터의 다양성을 확보함으로써 기계학습에서 모델의 과적합을 방지하고 성능을 향상시키는 데 도움을 준다. 컴퓨터 비전 분야에서 데이터 증식이 활발히 활용되는 데 반해, 텍스트마이닝 분야에서는 데이터 증식의 사용이 제한적이다. 이는 임베딩을 필요로 하는 텍스트데이터의 특성상, 증식 과정에서 원본과 전혀 다른 의미를 갖는 데이터가 생성될 위험이 있기 때문이다. 이에 본 논문은 시맨틱 텐서공간모델을 활용한 텍스트데이터 증식기법을 제안한다. 제안하는 증식기법은 텍스트데이터가 갖는 증식문제에서 자유롭고, 기존의 증식기법들과 달리 간단한 연산만을 활용하기 때문에 간편하게 수행할 수 있는 장점이 있다. 본 논문은 문서분류 실험을 통해 제안한 증식기법으로 생성한 데이터들이 모델의 성능향상을 이끌어냄을 보임으로써 제안기법의 유효성을 검증한다.","Data augmentation is the process of generating new data with little variation to existing data.Data augmentation helps to prevent model's overfitting and improve performance in machine learning by ensuring data diversity. While data augmentation is actively used in computer vision, the use of data augmentation is limited in text mining. This is because, due to the nature of text data requiring embedding, there is a risk that data having a completely different meaning from the original is generated during the augmentation process. In this paper, we propose a text data augmentation technique based on semantic tensor space model. The proposed augmentation technique does not cause the augmentation problem of text data, and unlike the existing augmentation techniques, it can be easily performed because it uses only simple operations. This paper verifies the validity of the proposed augmentation technique by showing that the data generated by the proposed technique leads to the performance improvement of the model."
사용자 얼굴인식을 통한 자동출석체크 시스템,2019,"['사용자인식', '얼굴인식', '하르 캐스케이드', '기계학습', 'User recognition', 'Face recognition', 'Haar Cascade', 'Machine learning']","본 논문은 입력 영상으로부터 사용자들의 얼굴을 찾아내고 찾아낸 얼굴을 바탕으로 사용자를 인식해 출석을 확인할 수있는 방법에 대한 연구이다. 우선 기계학습 이론에 기초한 얼굴 찾기 방법을 통해 얼굴인식이 이루어진다. 제안된 시스템은특징 값들이 분명한 각 얼굴에 대해서는 기존 데이터베이스에 존재하는 등록된 얼굴 사진과의 비교를 통해 자동으로 출석체크를 해주고, 특징 값들이 불분명한 얼굴에 대해서는 추후 필요시 수동으로 출석 체크가 가능하도록 미처리 얼굴로 별도분류해준다. 제안한 알고리즘에 대한 사용자 인식 실험 결과 정확도가 매우 높진 않았지만 성공적으로 인식을 하였으며 이에따른 정확도 문제를 개선하기 위해 성능 분석을 진행하여 향후 필요한 연구에 대하여 논하였다.","This paper proposes a method to identify users by recognizing users' faces from input images and recognizing users based on detected faces. Facial recognition is done through face finding method based on machine learning theory. The proposed system automatically checks attendance by comparing the registered facial photographs existing in the database for each face with clear feature values, and can check the attendance manually if necessary for faces whose characteristic values are unclear. Although the accuracy of the user recognition experiment for the proposed algorithm is not very high, but this paper have successfully recognized it. To solve the accuracy problem, performance analysis was conducted and necessary researches were discussed."
개인신용정보 표본DB 기반의 대출 현황 분석 및 채무불이행 예측성능 비교,2019,"['statistic analysis', 'default predict', 'credit information', 'recurrent neural network', 'machine learning', '통계 분석', '채무불이행 예측', '신용정보', '순환신경망', '기계학습']","본 논문은 한국신용정보원의 신용정보 표본DB 시범서비스의 일환인 개인신용정보 표본DB를 이용하여 차주들의 성별, 연령, 기준월, 업권 등에 따른 대출 및 채무불이행 현황을 분석하고 통계자료를 제시한다. 또한, 국내외 은행은 대출 차입자의 채무불이행에 따른 손실을 최소화하는데 주목하고 있음에 따라 개인신용정보 표본DB를 사용하여 차주의 채무불이행을 예측 모델을 생성하고 성능을 평가한다. 특정 달의 채무불이행을 예측하기 위하여 직전 6개월의 차주의 정보 및 대출 정보를 가공하여 특징 데이터를 생성하고 Recurrent Neural Network와 기계학습 알고리즘을 사용하여 채무불이행 예측 모델을 생성하였다. 각 모델의 성능 측정 결과, Recurrent Neural Network가 채무불이행 차주에 대한 Recall이 0.96, AUC가 0.85로 가장 좋은 성능을 보였다.","In this paper, we analyze the status of loans and defaults and present statistical data according to the borrower's gender, age, month, etc. by using the personal credit information sample database offered as a trial service from Korea Credit Information Services. In addition, since domestic and foreign banks are paying attention to minimize the loss caused by default of the borrower, we used the personal credit information sample database to create a predicting model of borrower default and evaluated the model performance. To predict the default for a certain month, the borrower's demographic information and loan information for the previous six months were processed to generate characteristic data, and a default prediction model was created using Recurrent Neural Network and machine learning algorithm. Based on the performance of each model, Recurrent Neural Network was showed as the model to demonstrate the best performance with Recall of 0.96 and AUC of 0.85 for the default borrower."
공공부문에서 인공지능 활용에 관한 연구,2019,"['인공지능', '공공부문', '기계학습', '심층학습', '인공지능 활용의 기대효과와 우려점', 'Artificial Intelligence', 'Public Sector', 'Machine Learning', 'Deep Learning', 'Expected Effects and Anxieties of Utilizing Artificial Intelligence']",,"Artificial intelligence technology has been developing rapidly since the mid-2010s. Artificial intelligence technologies such as machine learning, computer vision, natural language processing, and robotics are naturally integrated into various fields to help human life. The private sector has achieved remarkable results, including the introduction of artificial intelligent speakers and the introduction of self-propelled drivers, but the public sector is still in its early stages as a pilot project in chatbots and waste disposalAlthough it is expected that artificial intelligence will be the most destructive innovation tool when it will be applied to the public sector, it is still in the pilot project level because it is in the technology development stage, and the accuracy of the chatbot service is about 70%.There is no need to worry too much about the consequences of artificial intelligence being applied to the public sector in earnest. Only a few principles can be suggested. First, all groups should share the burden and benefits equally. Second, we should create programs based on citizens. Artificial intelligence should not be implemented unilaterally by the government because its impact on each area of the people is very large. Artificial intelligence should be provided as a tool to solve a given problem. Third, we avoid ethical risks and reduce decision making by artificial intelligence. It should be used to avoid ethical problems that may be caused by bias, privacy invasion, and lack of explanatory power of artificial intelligence. Finally, since the development of artificial intelligence technology is very fast and its impact on human life is very large, it is necessary to establish governance in which participate the public sector, industry, research institute related to it is established to understand the technology trend.The question of whether to act as a medicine or a poison in the use of artificial intelligence in the public sector depends on human choice."
Design of Artificial Intelligence Education Program based on Design-based Research,2019,"['DBR(Design-based Research)', 'AI(Artificial Intelligence)', 'SW Education', 'Machine Learning for Kids']",,"Recently, the artificial intelligence(AI) is used in various environments in life, and research on this is being actively conducted in education. In this paper, we designed a Design-Based Research(DBR)-based AI programming education program and analyzed the application of the program for the improvement of understanding of AI in elementary school. In the artificial intelligence education program in elementary school, we should considerthat itshould be used in conjunction with software education through programming activities, rather than creating interest through simple AI experiences. The designed education program reflects the collaborative problem-solving procedures following the DBR process of analysis - design - execution - redesign, allowing the real-world problem-solving activities using AI experiences and block-type programming language. This paper also examined the examples of education programs to improve understanding of AI by using Machine Learning for Kids and to draw implications for developing and operating such a program."
Labor Market Performance in OECD Countries: The Role of Institutional Interdependencies,2019,"['Labor market regulation', 'unemployment', 'institutional interdependencies', 'model selection', 'heuristic optimization', 'machine learning']",,Reducing rigidity in labor markets is key to lowering unemployment.Theoretical models suggest that the impact of such reforms depends on the country-specific regulatory framework. We test this hypothesis by estimating the impact of changes in six categories of regulation conditional on the country-specific regulatory environment for 26 OECD countries. We overcome problems of modeling a large set of institutional interdependencies by applying a machine learning type model selection approach. We provide evidence for the existence of higher-order institutional interdependencies. We further document that especially for changes in employment protection and the unemployment benefit system the impact on unemployment is mixed across countries.
타이어/노면 마찰소음을 이용한 포장상태등급 평가,2019,"['Pavement management', 'Pavement condition rating', 'Tire-surface fiction noise', 'Machine learning', 'ISO11819-21']",,"PURPOSES : This paper is aimed at suggesting a novel approach for determining the pavement condition rating based on the tire-surface friction noise using a machine learning algorithm as a low-end pavement condition monitoring system.METHODS : Vehicle on-board type noise measurement system according to the ISO11819-2, and the K-nearest neighbors with dynamic time warping algorithm were applied. The system and algorithm were empirically tested with a field study.RESULTS : The developed AI- and noise-based pavement condition monitoring system demonstrated significantly positive results with a precision 90.8%, recall 84.8%, and f1-score 86.1%.CONCLUSIONS: We herein confirmed that the acoustic property between the tire and road surface can be used for monitoring pavement conditions. It is believed this finding presented a new paradigm for monitoring pavement conditions based on visual information. However, extensive studies focused on the practical application of this method are required."
원자력발전소 기동 및 정지 운전을 위한 순환 신경망 기반 인공지능 프레임워크 개발,2019,"['automation system', 'nuclear power plant', 'artificial intelligence', 'deep learning']",,"In order to reduce operator workload from startup and shutdown operations for existing Nuclear Power Plants (NPPs), it is necessary to develop an automation system based on deep learning, the leading approach in current Artificial Intelligence (AI) technology. From existing research, it is challenging to develop an automation system using conventional machine learning for startup and shutdown operation since the automation system needs to be able to handle many instances of both monitoring and control variables in NPPs. Deep learning is able to simulate a variety of operating actions based on the experience of each operator. In this study, an AI framework for an automation system for startup operation in NPPs has been developed using a Recurrent Neural Network (RNN), which is a robust deep learning method for time series analysis. A feasibility study for an AI framework for the automation system is conducted using a Compact Nuclear Simulator (CNS) based on Westinghouse three-loop NPPs. The target scenario for the feasibility study is operation under bubble creation conditions in a pressurizer under startup."
국방용 합성이미지 데이터셋 생성을 위한대립훈련신경망 기술 적용 연구,2019,"['Generative Adversarial Networks(대립훈련신경망)', 'Synthetic Image(합성이미지)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Dataset(데이터셋)']",,"Generative adversarial networks(GANs) have received great attention in the machine learning field for their capacity to model high-dimensional and complex data distribution implicitly and generate new data samples from the model distribution. This paper investigates the model training methodology, architecture, and various applications of generative adversarial networks. Experimental evaluation is also conducted for generating synthetic image dataset for defense using two types of GANs. The first one is for military image generation utilizing the deep convolutional generative adversarial networks(DCGAN). The other is for visible-to-infrared image translation utilizing the cycle-consistent generative adversarial networks(CycleGAN). Each model can yield a great diversity of high-fidelity synthetic images compared to training ones. This result opens up the possibility of using inexpensive synthetic images for training neural networks while avoiding the enormous expense of collecting large amounts of hand-annotated real dataset."
전기화학촉매의 제일원리 계산 및 하이스루풋 스크리닝 연구 동향: 리뷰,2019,"['electrocatalysts', 'density functional theory', 'first principle calculation', 'high-throughput screening', 'machine learning']",,"There are many ongoing efforts to develop sustainable, clean, efficient, and economical pathways to produce renewable energy sources to satisfy worldwide energy demands. Electrochemical conversion processes, such as water splitting, CO2 conversion and N2 electroreduction, have been considered as successful approaches to solve these energy issues. Over the past decade, combining of theory and experiment has proven to be an innovative strategy, providing a framework for the design of high-performance catalysts and to investigate their mechanisms. This review introduces recent progress in theoretical strategies for state-of-theart heterogeneous electrocatalysts. Theoretical approaches are essential for grasping the intrinsic nature of the catalytic materials. Various levels of model system, with corresponding descriptions to capture the realistic environment, are addressed. Meanwhile, machine learning using data obtained by high-throughput screening, exploited as a new scientific approach, is discussed. Based on this review, it is expected that theoretical approaches will shed light on the future design of electrocatalysts, allowing for the development of sustainable energy sources."
Design of Artificial Intelligence Education Program based on Design-based Research,2019,"['DBR(Design-based Research)', 'AI(Artificial Intelligence)', 'SW Education', 'Machine Learning for Kids']",,"Recently, the artificial intelligence(AI) is used in various environments in life, and research on this is being actively conducted in education. In this paper, we designed a Design-Based Research(DBR)-based AI programming education program and analyzed the application of the program for the improvement of understanding of AI in elementary school. In the artificial intelligence education program in elementary school, we should consider that it should be used in conjunction with software education through programming activities, rather than creating interest through simple AI experiences. The designed education program reflects the collaborative problem-solving procedures following the DBR process of analysis - design - execution - redesign, allowing the real-world problem-solving activities using AI experiences and block-type programming language.This paper also examined the examples of education programs to improve understanding of AI by using Machine Learning for Kids and to draw implications for developing and operating such a program."
공공데이터를 활용한 아파트 매매 가격 결정 모형의 예측 능력 비교 : 서울 강남구 지역을 중심으로,2019,"['Public Data', 'Multiple Linear Regression', 'Random Forest', 'Support Vector Machine', '공공데이터', '다중선형회귀', '랜덤포레스트', '서포트벡터머신']","본 연구는 국토교통부의 아파트 실거래가 데이터 등 부동산 관련 공공데이터로 다양한 기계학습 알고리즘을 활용하여 서울특별시 강남구 지역의 아파트 매매 가격 결정 모형 간 예측 능력을 비교하였다. 다중선형회귀모형은 이해하기 쉽다는 장점이 있으나 오차의 정규성과 독립성 등의 가정을 충족하기 어렵다는 단점이 있으며 특히 예측 능력 면에서 기계학습 알고리즘에 비해 성능이 낮다. 본 연구에서는 아파트 매매 가격의 추정 성능을 비교하기 위하여 랜덤 포레스트 및 서포트 벡터 머신 알고리즘을 사용하였고, 그 결과 다중회귀분석 모형에 비해 예측 능력이 크게 향상된 결과를 보였다.","This study compares the forecasting ability of apartment sale pricing models in Gangnam-gu, Seoul, using various machine learning algorithms for real estate public data such as apartment transaction prices from the Ministry of Land, Infrastructure and Transport. The multiple linear regression model has advantages that it is easy to understand, but it has a disadvantage that it can’t easily meet assumptions such as normality and independence of residuals. Especially, it has lower performance than machine learning algorithms in prediction ability. In this study, random forest and support vector machine algorithms were used to compare the estimation performance of apartment sale prices. As a result, the predictive power was significantly improved compared to the multiple regression model."
XGBoost 모형을 활용한 코스피 200 주가지수 등락 예측에 관한 연구,2019,"['기계학습', '자기회귀모형', '주가예측', 'LSTM 신경망', 'XGBoost 모델', 'Autoregressive model', 'LSTM neural network', 'machine learning', 'Stock price prediction', 'XGBoost model']","주식시장은 자본주의 경제 체제를 나타내는 대표적인 시장으로써 금융시장에서 중요한 경제적 기능을 수행한다. 또한, 주식시장은 기업뿐만 아니라 개인 투자자들에게 자본을 획득할 수 있는 유용한 수단으로 여겨지고 있다. 이러한 인식 속에서 주가의 흐름을 정확하게 예측하는 것은 현재까지도 중요한 연구 과제로 남아있다. 최근 기계학습을 활용한 주가예측에 대한 연구들이 활발하게 진행되고 있는 가운데, 본 연구에서는 다양한 분야에서 우수성을 입증하고 있는 XGBoost (extreme gradient boosting) 모델을 주가 등락 예측에 활용하고자 한다. XGBoost 모델의 유용성을 입증하기 위해 시계열 데이터 분석에 강점을 가지고 있다고 알려진 LSTM (long-short term memory) 신경망과 전통적으로 가장 널리 사용되었던 시계열 분석 기법인 자기회귀모형의 예측 결과들을 비교 및 분석하였다. 실증분석 결과 주가등락 예측에 있어서 XGBoost 모델의 유용성을 확인할 수 있다.","The stock market is a representative market representing the capitalist economic system and performs important economic functions in the financial market. The stock market also plays a role of acquiring capital for both individual and corporate investors. Accurately predicting the stock prices remains an important research task. In recent years, studies on stock price prediction using machine learning have progressed. In this study, we will use the XGBoost (extreme gradient boosting) model, which has been used in various fields recently and proved its excellence to predict stock price fluctuation. In order to demonstrate the superiority of the XGBoost model, we compared and analyzed the results of the LSTM (long-short term memory) neural network which showed good performance in the previous studies and the autoregressive model which is a conventional time series analysis technique. The empirical analysis shows that the XGBoost model is competitive in predicting stock price movements."
ICT 응용 서비스 지능화를 지원하는 클라우드-네이티브 기반 SmartX AI 컴퓨팅 클러스터 설계 및 검증,2019,"['cloud-native computing', 'distributed AI computing', 'bigdata computing', 'machine learning', 'container-enabled cluster', 'and open-source software collaboration', '클라우드-네이티브 컴퓨팅', '분산 인공지능 컴퓨팅', '빅데이터 컴퓨팅', '머신러닝', '컨테이너 기반클러스터', '오픈소스 소프트웨어']","최근 마이크로 서비스 구조(Micro Service Architecture: MSA)를 적용한 지능형 ICT 응용 서비스가 크게 증가하면서, 이들과 효과적(Effectively)이고 유연하게(Flexibly) 연계될 수 있는 AI 컴퓨팅 자원들에 대한 요구 또한 크게 증가하고 있다. 본 논문에서는 상기한 AI 수요에 효과적으로 대응할 수 있는 클라우드-네이티브(Cloud-native) 기반의 SmartX AI 컴퓨팅 클러스터(SmartX AI Computing Cluster)의 개념을 제안한다. 여기서 클라우드-네이티브 컴퓨팅의 핵심 기술인 컨테이너 가상화와 컨테이너 오케스트레이션 기술은 분산 빅데이터/머신러닝 워크로드를 더욱 유연하고 동적으로 배포/운용할 수 있도록 도움을 준다. 제안하는 클러스터의 구성은 AI 컴퓨팅에 특화된 고성능 하드웨어와 오픈소스 소프트웨어를 중심으로 한다. 본 논문에서는 제시한 클러스터의 개념에 따라 실제 클러스터를 구축하기 위해 필요한 구체적인 하드웨어의 구성과 소프트웨어의 스택을 설계하고 제시한다. 그리고 제시한 설계에 따라 소규모 클러스터를 시험적으로 구축하여 보고, 구축된 클러스터의 기능들과 활용 방안에 대해 살펴본다. 또한 실제 빅데이터 및 분산 머신러닝 트레이닝 워크로드 운용 실험을 통해 스토리지와 네트워킹 측면에서 발생하는 병목(Bottleneck Points)을 도출하여 보고, 이를 개선하기 위한 소프트웨어 구성과 설정을 제안한다. 상기한 시도를 통해 제안하는 SmartX AI 컴퓨팅 클러스터와 실제 ICT 응용 서비스들과의 연계를 통해 효과적인 서비스 지능화의 가능성을 살펴본다.","With the increasing adoption of Intelligent ICT Application Services on Micro Service Architecture (MSA), there has been a rising need for an effective and flexible AI Computing Resource.In this paper, we propose an alternative concept of a Cloud-native-based SmartX AI Computing cluster that can effectively cope with the rising AI demands. Container virtualization & container orchestration, which are key components of cloud-native computing, enable the dynamical and flexible deployment and operation of distributed BigData/ML workloads. The proposed cluster components are based on AI-driven high-performance hardware and open-source software. In this paper, we design the hardware structure and the software stack required to adopt the proposed cluster concept into actual real-world clusters. We also implement a small cluster to examine its functionality and possible uses.The paper further expands the topic by providing the results of the experiments running real-distributed BigData/Machine-learning training workloads as well as identifying bottleneck points caused by storage and networking issues. The bottleneck points are used to propose the optimized software stack and configuration required to overcome such issues. The potential of effective intelligent service is presented in the proposed SmartX AI computing cluster when linked to actual ICT application services."
Medical Big Data Is Not Yet Available - Why We Need Realism Rather Than Exaggeration,2019,"['Artificial intelligence', 'Big data', 'Data science', 'Medical informatics', 'Deep learning', 'Machine learning']",,"Most people are now familiar with the concepts of big data, deep learning, machine learning, and artificial intelligence (AI) and havea vague expectation that AI using medical big data can be used to improve the quality of medical care. However, the expectation thatbig data could change the field of medicine is inconsistent with the current reality. The clinical meaningfulness of the results of research using medical big data needs to be examined. Medical staff needs to be clear about the purpose of AI that utilizes medical bigdata and to focus on the quality of this data, rather than the quantity. Further, medical professionals should understand the necessaryprecautions for using medical big data, as well as its advantages. No doubt that someday, medical big data will play an essential rolein healthcare; however, at present, it seems too early to actively use it in clinical practice. The field continues to work toward developing medical big data and making it appropriate for healthcare. Researchers should continue to engage in empirical research to ensure that appropriate processes are in place to empirically evaluate the results of its use in healthcare."
관상동맥질환 위험인자 유무 판단을 위한 심박변이도 매개변수 기반 심층 신경망의 성능 평가,2019,"['Autonomic nervous system (ANS)', 'Cardiovascular risk factors', 'Heart rate variability (HRV)', 'Deep learning', 'Deep neural network (DNN)']",,"The purpose of this study was to evaluate the performance of deep neural network model in order to determine whether there is a risk factor for coronary artery disease based on the cardiac variation parameter. The study used unidentifiable 297 data to evaluate the performance of the model. Input data consists of heart rate parameters, which are SDNN (standard deviation of the N-N intervals), PSI (physical stress index), TP (total power), VLF (very low frequency), LF (low frequency), HF (high frequency), RMSSD (root mean square of successive difference) APEN (approximate entropy) and SRD (successive R-R interval difference), the age group and sex. Output data are divided into normal and patient groups, and the patient group consists of those diagnosed with diabetes, high blood pressure, and hyperlipidemia among the various risk factors that can cause coronary artery disease. Based on this, a binary classification model was applied using Deep Neural Network of deep learning techniques to classify normal and patient groups efficiently. To evaluate the effectiveness of the model used in this study, Kernel SVM (support vector machine), one of the classification models in machine learning, was compared and evaluated using same data. The results showed that the accuracy of the proposed deep neural network was train set 91.79% and test set 85.56% and the specificity was 87.04% and the sensitivity was 83.33% from the point of diagnosis. These results suggest that deep learning is more efficient when classifying these medical data because the train set accuracy in the deep neural network was 7.73% higher than the comparative model Kernel SVM."
Your Opinions Let us Know: Mining Social Network Sites to Evolve Software Product Lines,2019,"['Software product line evolution', 'Social network sites', 'Requirements-driven', 'Architecture design', 'classification', 'machine learning']",,"Software product lines (SPLs) are complex software systems by nature due to their common reference architecture and interdependencies. Therefore, any form of evolution can lead to a more complex situation than a single system. On the other hand, software product lines are developed keeping long-term perspectives in mind, which are expected to have a considerable lifespan and a long-term investment. SPL development organizations need to consider software evolution in a systematic way due to their complexity and size. Addressing new user requirements over time is one of the most crucial factors in the successful implementation SPL. Thus, the addition of new requirements or the rapid context change is common in SPL products. To cope with rapid change several researchers have discussed the evolution of software product lines. However, for the evolution of an SPL, the literature did not present a systematic process that would define activities in such a way that would lead to the rapid evolution of software. Our study aims to provide a requirements-driven process that speeds up the requirements engineering process using social network sites in order to achieve rapid software evolution. We used classification, topic modeling, and sentiment extraction to elicit user requirements. Lastly, we conducted a case study on the smartwatch domain to validate our proposed approach. Our results show that users’ opinions can contain useful information which can be used by software SPL organizations to evolve their products. Furthermore, our investigation results demonstrate that machine learning algorithms have the capacity to identify relevant information automatically."
클러스터링 기법을 이용한 암호화 화폐의 시각화 패턴 분석,2019,"['기계 학습', '데이터 시각화', '클러스터링', '자기조직화지도', '암호화 화폐', '방사형 차트', 'Machine learning', 'Data visualization', 'Clustering', 'Self organizing Map', 'Cryptocurrency']","본 연구는 가상화폐 중에서 일별 거래량이 가장 많은 비트코인을 대상으로 총 26개의 기술적자료를 바탕으로 클러스터링을 진행하였다. 클러스터링의 방법론은 자기조직화지도를 이용하였고, 총실험 기간은 비트코인 가격이 급등과 급락이 동반했던 690일을 대상으로 하였다. 또한 클러스터링을위해서 클러스터 개수를 설정해야 하는데 본 연구에서는 선행적 연구에 의거해 총 10개로 정의한다.그 결과 상승 및 하락 구간에서 특정 패턴들이 형성되는 것을 알 수 있었으며, 각 패턴들을 방사형 차트로 나타낸 결과 동일한 패턴을 갖고 있는 방상형 차트는 서로 매우 유사한 이미지를 보이고 있음을확인했다. 더불어 각 그룹의 패턴들이 갖는 의미를 분석하기 위해서 각 패턴이 가상화폐 가격 움직임에 어떠한 연관이 있는지 분석한 결과, 특정 패턴 이후에 비트코인 가격이 상승 및 하락 모멘텀 그리고 급등 및 급락하는 모습을 발견할 수 있었다. 본 연구에서 제안하는 방사형 차트와 각 패턴이 갖는의미는 향후 인공신경망과 같은 기계 학습 기법을 이용하여 정량적인 금융 상품 매매 전략을 취하는데 참고가 되는 연구라 사료된다.","This study aims to cluster the price patterns of the most daily traded cryptocurrency, the Bitcoin. The clustering is conducted based on 26 technical indicators including from commonly used indicators such as Envelopes and MACD (Moving Average Convergence/Divergence) to those that are closely related to the value of cryptocurrencies such as the Bitcoin mining difficulty, the hash rate and the gold price. The self-organizing map (SOM) algorithm is used as the methodology for clustering and the total study period is 690 days where there are many ups and downs of the Bitcoin prices. A total of 10 clusters are selected for analysis of and it is found that certain patterns are formed in ascending and descending trends of the Bitcoin prices. A radar chart is used to visualize the representative pattern for each cluster, and it is found that the radar charts that exhibit similar patterns are analogous to each other. In addition, the movements of the Bitcoin prices between the patterns are analyzed in order to assess the meaning of the patterns of each cluster.The result reveals that the prices of Bitcoin rise, fall and crash after a specific pattern. The data visualization using radar chart and the analysis of each cluster pattern proposed in this study can be considered as a reference for a quantitative cryptocurrency trading strategy by using machine learning techniques such as artificial neural network."
Reality and Existence of Language: 1)Media literacy and Translation,2019,"['4차 산업혁명', '언어', '번역', '미디어 리터러시', '인공 지능', 'The 4th Industrial Revolution', 'Language', 'Translation', 'Media Literacy', 'Artificial intelligence']",,"Recently the education from college reflecting the changing 4th Industrial Revolution period, artificial intelligence, machine running, deep running AI artificial intelligence take a very important role. With the rapidly developed machine translation, quick translation of sentence measure is possible, but understanding the intensional and emotional understanding of context is hard. Along with the language issue of Maghreb area as the learning information of different culture accommodated through media increases the concern about the application of language upon media abuse may continue to exist or increase. However it is not doubt that various language issues will be brought out. As the 4th Industrial Revolution takes place the machine will replace the repetitive, simple works. In a changing world of not simple knowledge and techniques the value of translation which can create new value through ability of communication (media literacy) and fusion is expect to increase. The globalization of Korean culture through translation, the boundary between countries will disappear and if various language culture can be accommodated."
기계번역 기술을 고려한 전공 프랑스어 문법 교과과정의 설계,2019,"['프랑스어 문법 교과과정', '문법 교수-학습', '기계번역 기술', '프-한 기계번역', '인간번역', 'Undergraduate Curriculum', 'Major French', 'French Grammar Courses', 'Machine Translation Technology', 'French-Korean Machine Translation', 'Human Translation']","기계번역 기술은 2010년대 중반부터 전세계적으로 급속하게 발전했으며, 국내에도 2018년을 기점으로 기계번역기가 일상생활에 자리잡기 시작했다. 이 기술의 발전은 외국어 학습의 필요성, 외국어 관련 학과의 존재이유와 목표에 대해 끊임없이 재고하도록 요구할 것이다. 현재의 전망으로는, 일반적인 정보 전달은 기계번역기 사용이 보편화될 것이고, 인간번역은 범위가 아주 축소되고, 매우 전문적인 영역에서 지속될 것으로 보인다. 앞으로 통 · 번역 관련 일을 하게 될 현재의 학생들은 고도의 외국어 숙달도와 해당 분야의 전문지식이라는 두 마리 토끼를 모두 잡아야 한다. 또한 당장 통번역을 하지 않더라도 졸업 후 필요할 때 언제라도 프랑스어와 같은 제2 외국어를 사용하려는 전공자들은, 기계번역 결과를 수정할 수 있을 정도의 복원력이 강한 지식 구조를 갖춰야 한다.  본 연구는 성인의 외국어 학습에서 효율적으로 알려진 문법 지식에 주목하고, 국내 대학의 프랑스어 교수-학습 상황과 기계번역 기술의 발전방향을 충분히 고려한 문법의 교과과정을 제안했다. 그 특징은 다음과 같이 요약할 수 있다. 첫째, 거시적 관점에서 필수 교과목을 중심으로 선택 교과목을 나선형으로 배열함으로써, 수강하는 교과목의 수와 순서에 따른 모든 경우에 문법 지식을 점층적으로 확장할 수 있도록 했다. 둘째, 미시적 관점에서는 각 교과목의 세부적인 교수-학습 내용 간 치밀한 연계성을 기획하여, 교과과정의 확장성을 강화할 수 있도록 설계했다. 셋째, 암기에 기반한 학습과 평가를 지양하고, 전자사전 등 검색 프로그램과 기계번역 기술을 적극적으로 교수-학습 과정과 성취도 평가에 활용하는 방법론의 적용 원칙을 제안했다.","Machine translation (hereafter, MT) technology has developed rapidly around the world since the mid-2010s, and Korean users are now using MT applications/software on their online devices in daily life, especially since 2018. The development of MT technology increases skeptism about the need for foreign language learning, and requires to revisit constantly the rationale of foreign language departments. According to numerous MT experts, human translation will continue to exist in a narrow scope and in specialized domains, while a majority of general information will be translated through MT systems. Future human translators will have both advanced language proficiency and expertise in the field. Any current French student who wants to use French at any time after graduation, should have a robust and resilient knowledge-structure, on the basis of which (s)he can evaluate correctly MT results.  In this study, focusing on ‘grammar’ which is known to be effective in adult language learning, we design an undergraduate curriculum of major French grammar courses. Its characteristics can be summarized as follows. First, from a macro perspective, the spiral arrangement of the 2 facultative courses around the 1 obligatory course enables students expand their grammar-knowledge in all cases depending on the number and order of courses taken. Second, from a micro perspective, the fine-grained teaching-learning contents of the 3 different courses are planned in advance in order to enhance the scalability of the curriculum. Third, we propose some principles for adopting teaching-learning and evaluation methodologies which encourage students to take advantage of the prospering AI-based language-processing technology such as electronic dictionaries, MT systems, etc."
계산과학공학 시뮬레이션의 효율화를 위한 기계 학습 기반의 실행 시간 추정 방법,2019,"['계산과학공학', '시뮬레이션', '플랫폼', '이력 데이터', '기계 학습', '실행 시간 추정', 'Computational Science and Engineering', 'Simulation', 'Platform', 'Provenance Data', 'Machine Learning', 'Execution Time Estimation']","EDISON은 한국과학기술정보연구원에서 개발된 계산과학공학 시뮬레이션 수행 플랫폼으로, 온라인에서 사용자들이 손쉽게 고성능 컴퓨팅 (HPC) 시뮬레이션을 수행할 수 있게 한다. EDISON의 활발한 사용에도 불구하고, 때때로 EDISON에서 실행되는 HPC 시뮬레이션은 입력 파라미터에 따라 수 일, 수 주, 심지어 수개월이 걸리는 매우 큰 실행 비용을 요구한다. 이러한 큰 실행 비용은 시뮬레이션이 언제 끝날지 모른 채 사용자들이 무작정 기다리게 한다. 이러한 불편함은 결국 EDISON 시뮬레이션의 효율성을 저해시킨다. 시뮬레이션에서 이와 같은 예측불가능성을 해소하기 위해, 본 논문은 기계 학습 기법을 통한 시뮬레이션 시간 추정 방법을 제안한다. 제안된 방법에서, EDISON에서 실행된 다양한 종류의 시뮬레이션에서 실행된 이력 데이터를 기반으로, 기계 학습 모델들을 훈련시킨 다음, 그 모델들을 활용하여 지정된 입력 파라미터에 대한 시뮬레이션의 실행 시간을 추정한다.그 결과, 우리의 모델은 추정된 시간에 대해 평균 73%의 정확도로 양호한 성능을 보였다. 본 논문에서 제안하는 모델을 통해 사용자들은 잘못된 입력 파라미터에 따른 시뮬레이션 실행의 잠재적 위험을 줄이고 더 효율적인 시뮬레이션을 위한 더 나은 일정을 계획할 수 있다.","EDISON is a computational science engineering simulation platform, which is developed by KISTI, enabling its users to easily perform high-performance computing (HPC) simulations online.Despite its vibrant use, occasionally, the HPC simulations on EDISON require a huge amount of execution cost, taking several days, weeks, or even months, depending on their input parameters.Such large execution cost leads to letting users wait for an unacceptably long time, without knowing when their simulations are finished. This inconvenience eventually hinders efficiency of EDISON simulations. To resolve such unpredictability in simulation, this paper proposes a simulation time estimation method via machine learning (ML) techniques. In the proposed method, we train ML models based on provenance data obtained from a variety of simulations running on EDISON and then leverage the models to predict the execution time of simulations on specified input parameters. As a result, our models showed decent performance with an average accuracy of about 73% on estimated time. By utilizing our trained models, the users can reduce the potential risk of simulation execution by erroneous input parameters and plan a better schedule for more efficient simulations."
바이두(百度) 번역기의 한문고전 번역 수준과 향후의 과제,2019,"['한문', '한문번역', '바이두', '기계번역', '번역오류', '코퍼스', '오류유형', 'Classical Chinese', 'Classical Chinese Translation', 'Baidu', 'Machine Translation', 'Translation Error', 'Corpus', 'Error Type']","본고는 문언문 번역 기능이 탑재된 바이두 번역기를 통해 문언문의 번역 수준을 살펴보고 더 나은 번역 결과를 얻기 위해 보완되어야 할 내용을 살펴본 것이다. 중국의 바이두 기계번역 시스템은 강력한 신경망 엔진이 장착되어 있으며 다양한 언어의 병렬코퍼스를 하나로 합쳐 학습하도록 설계되었다. 신경망 기반의 기계 번역 모델은 언어의 자질 정보를 스스로 추출하여 별도의 언어학적 전처리 과정이 없이 종단간 학습이 가능하다.그러므로 본고에서는 형태소 분석 이하의 과정은 생략하고 전처리 과정에 해당하는 표점을 한 경우와 표점을 하지 않은 경우로 나누고 문언문의 유형 및 난이도에 따라 번역 결과에 어떤 차이가 발생하는지 살펴본 후, 번역상의 주요 오류 양상을 구체적으로 분석하였다.분석에는 중국의 선진시기부터 명대에 이르기까지 46종의 문헌과 한국의 『조선왕조실록』을 활용하였으며, 그 결과는 다음과 같다.첫째, 다량의 문언문 코퍼스를 심층학습한 정황은 찾을 수 없었다. 다만 중문 번역문을 문언문으로 역번역했을 때 원문과 동일하게 번역되는 것으로 볼 때 일정 정도의 문언문 데이터를 확보하여 번역에 적용하고 있는 것으로 판단된다.둘째, 상세표점 텍스트, 방점 텍스트, 기본 표점 텍스트에서 대체로 동일한 번역 결과를 보였다. 이것은 바이두 번역기가 기본 표점만으로도 전후 문맥을 스스로 판단하여 상세표점에 준하는 번역을 해내고 있음을 의미한다. 그러나 표점이 없는 텍스트에서는 띄어쓰기와 붙여 쓰기 모두 번역이 제대로 이루어지지 않았다.셋째, 문장 성분을 올바로 파악하지 못하거나 어휘의 의미를 잘못 선택한 경우가 빈번하게 발생하였으며, 그 밖에도 전후에 위치한 다른 어휘의 간섭으로 인한 오류, 결역, 고유명사를 잘못 파악한 오류 등이 있었다.이와 같은 문제를 해결하기 위한 제언은 다음과 같다.첫째, 양질의 코퍼스를 최대한 많이 확보하여야 한다. 하지만 개인이나 소규모 연구기관에서는 양질의 코퍼스를 충분히 확보하기가 쉽지 않다. 따라서 국가기관의 주도 하에 수집된 번역물을 신경망 기계번역기에 활용할 수 있도록 정제‧가공하는 작업을 동시에 수행해야 한다.둘째, 알고리즘에 최적화된 병렬코퍼스 가공에 대해 깊이 있는 연구를 수행해야 한다. 문언문은 코퍼스의 양이 절대적으로 부족한 만큼, 표점 문제를 비롯하여 기본적인 문장성분을 태깅하거나 체언/용언/관계언 등만 태깅하는 방법 등을 다각도로 살펴 코퍼스의 빈곤으로 인한 문제를 해결하는 방안을 찾아야 한다.셋째, 문언문을 한국어로 옮길 때 필요한 정보들을 면밀하게 살펴서 문언문－한국어 번역에 최적화된 알고리즘이 적용될 수 있도록 해야 한다. 고립어인 문언문과 교착어인 한국어의 번역 과정에서 얻을 수 있는 정보들을 독자적으로 확보해 활용할 수 없게 될 것이기 때문이다.아울러 어휘의 의미를 올바로 선택하지 못하는 오류나 전후에 위치한 다른 어휘의 간섭으로 인한 오류, 고유명사를 판독하지 못해 발생한 오류 등을 줄이기 위해서는 사전을 포함한 문언문에서의 사용빈도가 반영된 자료를 제공해주는 것도 필요하다.","In this paper, we analyze the quality of translations of Chinese classics in Baidu translation system and examine a few aspects to get better results in enhancing the translation quality. Baidu Translate is a multilingual neural network-based machine translation service, designed to simultaneously learn multilingual models trained on parallel corpora. The neural machine translation model extracts linguistic features without any preprocessing on the language data, which is an end-to-end learning approach for automated translation.In the analysis, 46 kinds of documents from the Pre-Qin period of China to the Ming Dynasty and the Annals of the Joseon Dynasty in Korea were used. The results of the analysis are as follows: First, deep learning approaches using a massive amount of classical Chinese corpora were hardly seen in the system. However, the translation closely followed the original when using back-translations, which implies that the system was trained on Chinese classic data to some degree.Another important point to note is that almost the same level translations were shown in the translation system on the texts with special marks, side dots, and common marks. The implication is that Baidu translation system was able to learn meanings of sentences from the context and translate the original text containing common marks well as much as the text with special marks. On the text without marks, however, the sentences were not properly translated in terms of word spacing.Third, translation mistakes coming from misunderstanding of constituents or lexical meanings occurred frequently. Other translation errors include the interruption from words that come before and after, loss of meaning, and misunderstanding of the different types of proper nouns.The details of our proposal are as follows: A large set of good quality training data should be offered to produce good translations. It is hard, however, to collect high quality language data at the individual or small-scale research institute level. In this sense, the initiatives led by government institutions for data preprocessing, refinement should be backed so that high quality corpora can be collected and used in the neural machine translation system.In addition, more research on preprocessing of parallel corpora best-fitted to algorithms should be conducted. Given that literal texts are definitely lacking, we should examine methods to tag basic elements, substantives, predicates, and function words of sentences along with the marking system problem from every angle and fine more fundamental solutions.Thirdly, it is imperative to examine all the necessary information when translating literary Chinese to Korean so that the best-fitting algorithm can be used for translation. The reason for this is that it will be unavailable to obtain and utilize information that can be obtained in the process of translation from the isolated language, or Chinese classics, to the agglutinative language, Korean."
RNN을 이용한 제2형 당뇨병 예측모델 개발,2019,"['제2형 당뇨병', '질병 예측', '기계 학습', '딥러닝', 'RNN', '의료 인공지능', 'T2DM', 'Disease Prediction', 'Machine Learning', 'Deep Learning', 'RNN', 'Medical AI']","제2형 당뇨병은 고혈당이 특징인 대사성 분비 장애로 여러 합병증을 야기하는 질병이며, 장기적인 치료가 필요하기 때문에 매년 많은 의료비를 지출한다. 이를 해결하기 위해 많은 연구들이 있어왔지만, 기존의 연구들은 한 시점에서의 데이터를 학습시켜 예측함으로써 정확도가 높지 않았다. 그래서 본 연구는 제2형 당뇨병 발생 예측에 대한 정확도를 높이기 위하여 RNN을 이용한 모델을 제안하였다. 본 모델을 개발하기 위해 한국인유전체역학조사 지역사회 코호트(안산·안성) 데이터를 이용하였으며, 시간의 흐름에 따른 데이터들을 모두 학습시켜 당뇨병 발생 예측모델을 만들었다. 예측 모델의 성능을 검증하기 위해 기존의 기계 학습 방법인 LR, k-NN, SVM과 정확도를 비교하였다. 비교한 결과 제안한 예측모델의 accuracy는 0.92, AUC는 0.92로 다른 기계 학습 방법보다 높은 정확도를 보였다. 따라서 본 연구에서 제안한 제2형 당뇨병 발생 예측 모델을 활용하여 발병을 조기 예측함으로써 생활습관 개선 및 혈당조절을 통해 당뇨병 발병을 예방하고 늦출 수 있을 것이다.","Type 2 diabetes mellitus(T2DM) is included in metabolic disorders characterized by hyperglycemia, which causes many complications, and requires long-term treatment resulting in massive medical expenses each year. There have been many studies to solve this problem, but the existing studies have not been accurate by learning and predicting the data at specific time point. Thus, this study proposed a model using RNN to increase the accuracy of prediction of T2DM. This work propose a T2DM prediction model based on Korean Genome and Epidemiology study(Ansan, Anseong Korea). We trained all of the data over time to create prediction model of diabetes. To verify the results of the prediction model, we compared the accuracy with the existing machine learning methods, LR, k-NN, and SVM. Proposed prediction model accuracy was 0.92 and the AUC was 0.92, which were higher than the other. Therefore predicting the onset of T2DM by using the proposed diabetes prediction model in this study, it could lead to healthier lifestyle and hyperglycemic control resulting in lower risk of diabetes by alerted diabetes occurrence."
피아제의 명제논리적 학습이론과 베이즈주의 인과추론적 학습이론 사이의 논쟁 넘어서기,2019,"['베이즈주의', '베이지안 인지이론', '피아제 학습이론', '발생학적 인식론', '인과성', '확률 추론', 'Bayesian probabilistic model', 'Piaget', 'Theory of learning', 'Causality', 'Cognitive science']","15년 전부터 등장한 베이지안 확률론적 추론 모형은 통계학, 과학철학, 심리학, 인지과학, 컴퓨터과학, 신경과학 등에서 학계의 연구를 지배하는 강력한 핵심논제가 된 후로 이젠 교육학과 심지어는 논리학 분야에까지 큰 반향을 일으키고 있다. 이러한 다양화로 인해, 굿에 따르면, 베이즈주의 유형은 46,656 가지로 분류된다. 이러한 다양한 모형들 중에서 베이지안 확률모형을 학습이론에 적용하려는 학자들은 학습자의 학습 과정이 정확히 베이지안 확률추론 과정을 항상 따른다고 주장한다. 그런데 이러한 확률론적 모형은 피아제의 구성주의적 전망을 계승한 것은 분명하다. 왜냐하면, 이 모델을 지지하는 학자들 자신이 자신들의 학적 운동을 “새로운 합리적 구성주의”라고 명시적으로 명명하기 때문이다. 그럼에도 불구하고, 이러한 확률론적 학습모형은 “지식은 인과성을 중심으로 구조화된다.”라는 가설을 확고하게 지지하면서, 피아제의 명제 논리적 모형에 의한 학습이론을 강하게 비판한다. 그러나 베이지안 학습 이론가들은 경험을 통한 새로운 항들의 연결로서의 학습, 그리고 학습에서 모순 및 인과성의 역할 등에 대한 피아제의 세부적인 연구 성과들을 놓치고 있다. 다른 한편으로 베이지안 학습이론은 여러 가지 점에서 온전한 발달 이론을 제공하기에는 아직 미흡하다. 이런 점에서, 필자는 현상 없이는 구조를 이해할 수 없듯이, 구조 없이는 현상을 이해할 수 없다는 사실을 강조하면서, 인과성 추론을 핵심으로 하는 베이지안 학습 모델과 인과적 물리적 인식뿐만 아니라, 동시에 논리-수학적 인식 모델을 강조하는 피아제의 학습 모델은 새로이 종합되어야 한다는 것을 논증하고자 한다.","For more than 15 years, Bayesian probabilistic models have been dominant ones not only in the field of statistics, computational sciences, and machine learning, but also in epistemology, philosophy of sciences, and in cognitive sciences. This revolution extended in pedagogical circle and logics has tried to offer a renewal of the theories of learning, especially criticizing Piagetian theory. According to Bayesian learning theory, almost all our knowledge is only probable, and the core way of arriving at the truth, such as induction and analogy, is based on probabilities. But, in my opinion, the supporters of probabilistic models was so quick that they could not have the enough time to explore the rich works of Piaget. So, I will reexamine and compare the works of Piaget with those of the probabilistic models.  I will show that the back and forth movement between data and hypotheses of Bayesian models is coherent with the learning through experience and especially contradiction which are important in Piaget"" dynamic theory of assimilation and accommodation. I will then suppose that the probabilistic models are not enough to provide the global developmental models, such as the dynamic systems perspective attempting to offer the circular causality that governs part-part, part-whole, and whole-part relations. I will finally emphasize that the probabilistic models and Piagetian ones of logico-mathematical operations should be synthesized."
Action recognition using optimized deep autoencoder and CNN for surveillance data streams of non-stationary environments,2019,"['Big data processing', 'Action recognition', 'Online data stream analysis', 'Optimized deep autoencoder', 'Convolutional neural network', 'Machine learning', 'Non-stationary environment']",,"<P><B>Abstract</B></P>  <P>Action recognition is a challenging research area in which several convolutional neural networks (CNN) based action recognition methods are recently presented. However, such methods are inefficient for real-time online data stream processing with satisfied accuracy. Therefore, in this paper we propose an efficient and optimized CNN based system to process data streams in real-time, acquired from visual sensor of non-stationary surveillance environment. Firstly, frame level deep features are extracted using a pre-trained CNN model. Next, an optimized deep autoencoder (DAE) is introduced to learn temporal changes of the actions in the surveillance stream. Furthermore, a non-linear learning approach, quadratic SVM is trained for the classification of human actions. Finally, an iterative fine-tuning process is added in the testing phase that can update the parameters of trained model using the newly accumulated data of non-stationary environment. Experiments are conducted on benchmark datasets and results reveal the better performance of our system in terms of accuracy and running time compared to state-of-the-art methods. We believe that our proposed system is a suitable candidate for action recognition in surveillance data stream of non-stationary environments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Action recognition in online data stream acquired from non-stationary surveillance. </LI> <LI>  Efficient CNN model is used for frame-level representation. </LI> <LI>  An optimized deep autoencoder is presented for learning sequences and squeezing high. dimensional features. </LI> <LI>  Investigated a non-linear learning approach for action recognition. </LI> <LI>  Iterative fine-tuning of the trained recognition model for newly accumulated data. </LI> </UL> </P>"
고령자 일상행위의 예측에 기반한 주거서비스 모델,2019,"['일상행위', '라이프로그', '스마트 환경', '기계학습', '성능-행위 융합모델', '주거서비스', 'Daily Activities', 'Life-log', 'Smart Environment', 'Machine Learning', 'Performance-Behavior Hybrid Model', 'Dwelling Service']",,"The purpose of this study is to propose a process that can provide the residential service by predicting the behaviors by time of the elderly using the life log data.In order to accomplish this purpose, first, the characteristics of daily life-log data and daily behavior patterns of elderly people were analyzed using the life-log data of previous studies which was collected through the 24 - hour self - filling questionnaire. Second, using the Weka program based on the collected life-log data, the behavior of the elderly by time of day was predicted and the accuracy of prediction was analyzed. Third, the process was simulated to provide the dwelling service in the elderly housing by extracting some of the predicted daily activities of elderly people and applying them to the Performance-Behavior Hybrid Model. A total of 1008 behaviors were analyzed. In order to propose a Performance-Behavior Hybrid Model, two behaviors (sleep, working out) with high prediction accuracy and two behaviors up washing, shower) behavior were extracted to provide light environmental dwelling service.The method was studied to provide dwelling services automatically using historical data of residents. In addition, it is meaningful that the possibility and the process of predicting the daily activities of the elderly through machine learning were explored. However, delicate techniques for detecting behavior and data collection that is large enough to improve prediction accuracy must be complemented."
Reality and Existence of Language:Media literacy and Translation,2019,"['The 4th Industrial Revolution(4차 산업혁명)', 'Language(언어)', 'Translation(번역)', 'Media Literacy(미디어 리터러시)', 'Artificial intelligence(인공 지능)']",,"Recently the education from college reflecting the changing 4th Industrial Revolution period, artificial intelligence, machine running, deep running AI artificial intelligence take a very important role. With the rapidly developed machine translation, quick translation of sentence measure is possible, but understanding the intensional and emotional understanding of context is hard. Along with the language issue of Maghreb area as the learning information of different culture accommodated through media increases the concern about the application of language upon media abuse may continue to exist or increase. However it is not doubt that various language issues will be brought out. As the 4th Industrial Revolution takes place the machine will replace the repetitive, simple works. In a changing world of not simple knowledge and techniques the value of translation which can create new value through ability of communication (media literacy) and fusion is expect to increase. The globalization of Korean culture through translation, the boundary between countries will disappear and if various language culture can be accommodated."
음성과 영상 데이터 Key 를 사용한 이중 암호화 및 실시간 지능형 복호화,2019,"['암호화', '복호화', '푸리에 변환', '웨이블릿 변환', '기계학습', '랩뷰', 'Encryption', 'Decryption', 'Fourier Transform', 'Wavelet Transform', 'Machine Learning', 'LabVIEW']",,"In this paper, double encryption and decryption algorithm which uses facial data and voice data as keys was proposed and implemented in real time through LabVIEW programming. Encryption is a sequential multiplication process for each Fourier transformed data on an input data and two key data. Decryption is performed in two steps. First, the similarity between two newly captured key data and two key data already used in encryption is checked for an identical examination. Specially in case of voice key data, Wavelet Transform was used to extract features of data, then machine learning ANN was applied to those features to improve the accuracy of discrimination. Next, only when all similarities are recognized, the input data is restored through the reverse process of encryption. The experiment showed that the run-time for decryption is under 5 second. Compared to the existing scheme only with one static key, the proposed can provide higher security in that facial and voice data captured in real time, that is, two dynamic biometric data are used as keys."
Fast k-NN based Malware Analysis in a Massive Malware Environment,2019,"['k-Nearest Neighbor', 'Clustering', 'Malware']",,"It is a challenge for the current security industry to respond to a large number of malicious codes distributed indiscriminately as well as intelligent APT attacks. As a result, studies using machine learning algorithms are being conducted as proactive prevention rather than post processing. The k-NN algorithm is widely used because it is intuitive and suitable for handling malicious code as unstructured data. In addition, in the malicious code analysis domain, the k-NN algorithm is easy to classify malicious codes based on previously analyzed malicious codes. For example, it is possible to classify malicious code families or analyze malicious code variants through similarity analysis with existing malicious codes. However, the main disadvantage of the k-NN algorithm is that the search time increases as the learning data increases. We propose a fast k-NN algorithm which improves the computation speed problem while taking the value of the k-NN algorithm. In the test environment, the k-NN algorithm was able to perform with only the comparison of the average of similarity of 19.71 times for 6.25 million malicious codes. Considering the way the algorithm works, Fast k-NN algorithm can also be used to search all data that can be vectorized as well as malware and SSDEEP. In the future, it is expected that if the k-NN approach is needed, and the central node can be effectively selected for clustering of large amount of data in various environments, it will be possible to design a sophisticated machine learning based system."
인공지능과 서화예술의 생명성에 관한 연구,2019,"['인공지능예술', '서화예술', '주역미학', '생명성', '음양사상', 'Artificial Intelligence Art', 'Calligraphy and Painting', 'Aesthetics in the Book of the Changes', 'Life', 'Thought of Yin and Yang']",,"Artificial intelligence has a lot of influence in the art field, and its value is recognized as the works of art are sold in the auction market. There is the deep learning method which has been recently used in AlphaGo, and it is a system that mimics the process of human’s perceiving the world and recognizing the object. As AI begins to use this deep learning method, artificial intelligence wrote jazz music, completed the work of Rembrandt by learning the styles of famous artists, and produced Chun Lian(春聯). Such artificial intelligence is expected to have an influence in the field of calligraphy and painting. In this study, thus, to evaluate and diagnose such phenomena aesthetically, I investigated the unique worldview of calligraphy and painting and examined the possibility of artificial intelligence in realizing the spirit in the worldview.The aesthetic consciousness of calligraphy and painting can be examined through the Book of the Changes which tries to clarify the origin of life and the principle of life through which all things are made. The correlative relationship of yin and yang is a life principle of all things and embraces the aesthetic possibility as a principle of change and creation of art. That can be confirmed through the theory of calligraphy and painting of Kim Jeong-hui, Bu Yantu(布顔圖), and Shao Meichen(邵梅臣). They said that the vitality of the nature could be reproduced when understanding the creating principle of the universe based on ‘the Way that yin and yang successively move[一陰一陽之謂道]’. In addition, they decided that the artistic creativity, which had ‘the Spirit that they cannot assess yin and yang[陰陽不測之謂神]’, could emerge when they understand and express the principle of change which yin and yang complement and embrace each other.On the other hand, until now, the driving system of deep learning basically finds the correct answer by recognizing the small unit in the lower level and the higher unit as it goes up. In this process, the answers found by the neurons in the lower level are often inaccurate. Therefore, because of its narrow view, it causes distortions like they perceived Michelangelo’s <The Creation of Adam>. As such, at the current level of artificial intelligence technology, it seems to be difficult for AI to recognize the significance of ‘stroke’, which is important in calligraphy and painting, and to expect a form that is full of vitality. In addition, because the calligrapher’s or painter’s love for life is not based on a copy and a logical understanding but a stage of experience and inspiration, there is a limit to make the machine learn it. Ultimately, even if artificial intelligence can reach a level that mimics an artist’s consciousness, so that fundamental learning about East Asian art becomes possible, it still remains a question of judging whether or not it is merely the manifestation of an artist by AI."
네트워크 비정상 탐지를 위한 속성 축소를 반영한 의사결정나무 기술,2019,"['Network Anomaly Detection', 'NSL-KDD Data Set', 'Decision Tree', 'Feature Selection']","최근 알려지지 않은 공격에 대처하기 위한 네트워크 비정상(anomaly) 탐지 기술에 대한 관심이 한층 높아지고있다. 이러한 기술 개발을 위해 데이터 마이닝(data mining), 기계학습(machine learning), 그리고 딥러닝(deep learning)등을 활용한 다양한 연구가 진행되고 있다. 본 논문에서는 분류(classification) 문제를 다루는 데이터 마이닝 기술 중 가장 전통적인 방법 중 하나인 의사결정나무(decision tree)를 이용하여 NSL-KDD 데이터셋을 대상으로 네트워크 비정상 탐지 가능성을 보여준다. 의사결정나무의 과대적합(over-fitting) 단점을 해소하기위해 카이-제곱(chi-square) 테스트를 통해 최적의 속성 선택(feature selection)을 수행하고, 선택된 13개의 속성을 사용한 의사결정나무 모델 환경에서 NSL-KDD 시험 데이터 셋 KDDTest+에 대해 84% 그리고KDDTest-21에 대해 70%의 네트워크 비정상 검출 정확도를 보였다. 제시된 정확도는 기존 의사결정나무 모델 적용 시 이들 시험 데이터 셋을 대상으로 알려진 정확도 81% 그리고 64% 수준과 비교해 약 3% 그리고 6% 각각 향상된 결과다.","Recently, there is a growing interest in network anomaly detection technology to tackle unknown attacks. For thispurpose, diverse studies using data mining, machine learning, and deep learning have been applied to detect networkanomalies. In this paper, we evaluate the decision tree to see its feasibility for network anomaly detection on NSL-KDDdata set, which is one of the most popular data mining techniques for classification. In order to handle the over-fittingproblem of decision tree, we select 13 features from the original 41 features of the data set using chi-square test, and thenmodel the decision tree using TensorFlow and Scik-Learn, yielding 84% and 70% of binary classification accuracies on theKDDTest+ and KDDTest-21 of NSL-KDD test data set. This result shows 3% and 6% improvements compared to theprevious 81% and 64% of binary classification accuracies by decision tree technologies, respectively."
랜덤 포레스트를 활용한 고교생의 독서활동 예측 요인 분석,2019,"['독서활동', '독서 여부', '독서량', '랜덤 포레스트', 'reading activity', 'reading', 'number of books read by students', 'randomforest']","본 연구는 머신러닝 기법 중 하나인 랜덤 포레스트를 활용하여 우리나라 고등학생들의 독서활동을 예측하는 설명 변수들을 추정하는 데 목적을 두었다. 이를 위해 본 연구는 한국교육고용패널Ⅱ 1차년도(2016년) 자료에 포함된 354개의 설명변수 중 고등학생들의 독서 여부와 독서량에 대한 예측력이 상대적으로 큰 변수들을 도출하였으며, 도출된 예측 모형의 예측성과를 확인함으로써 모형의 적정성 또한 확인하였다. 분석 결과, 우리나라 고등학생들의 독서 여부를 예측하는 주요 변수로는 모형정확도 개선 지수를 기준으로 중학교 3학년 때의 성적, 혼자 공부하는 시간, 사교육 경험 여부, 활동 중인 동아리 개수, 여가시간을 아르바이트로 보내는 빈도 등인 것으로 나타났으며, 고교생의 한 달 평균 독서량을 예측하는 주요 변수는 평균제곱오차를 기준으로 혼자 공부하는 시간, 국어 과목을 좋아하거나 재미있다고 생각하는 정도, 여가시간을 오락으로 보내는 빈도, 가구 소득 등인 것으로 나타났다. 본 연구는 이러한 분석 결과를 근거로 학생의 시간 활용, 가정 환경 등 독서 여부 및 독서량과 관련된 주요 요인들을 제시하였고, 또한 기존 선행연구에서 확인되지 않은 다양한 변수들의 영향력을 확인함으로써 고교생의 독서 장려를 위한 새로운 정책적 접근에 대한 고려가 필요함을 제안하였다.","The purpose of this paper is to exploratively investigate the factors influencing reading activities of high school students. This study utilized the random forest method, one of the most representative machine learning approach. Our results first show that grades in the third grade of middle school, time spent studying alone, experience in private education, the number of active clubs, and the frequency of spending leisure time as part-time jobs are the substantial variables in predicting whether or not to read the book. In terms of students average monthly reading, time spent studying alone, degree of interest in Korean subjects, frequency of spending leisure time as entertainment, and household income are the substantial variables in predicting whether or not to read the book have a more predictive performance relatively. The findings of this study, based on new approach using machine learning method, provide useful policy implications for improving reading activities of high school students."
Effective Parameters for Gait Analysis in Experimental Models for Evaluating Peripheral Nerve Injuries in Rats,2019,"['Peripheral nerve injury', 'Mononeuropathy', 'Chronic constriction injury', 'Sciatic nerve', 'Motor deficits functions', 'Gait analysis']",,"Objective: Chronic constriction injury (CCI) of the sciatic nerve is a peripheral nerve injury widely used to induce mononeuropathy. This study used machine learning methods to identify the best gait analysis parameters for evaluating peripheral nerve injuries.Methods: Twenty-eight male Wistar rats (weighing 270±10 g), were used in the present study and divided into the following 4 groups: CCI with 4 ligatures around the sciatic nerve (CCI-4L; n=7), a modified CCI model with 1 ligature (CCI-1L; n=7), a sham group (n=7), and a healthy control group (n=7). All rats underwent gait analysis 7 and 28 days postinjury. The data were evaluated using Kinovea and WeKa software (machine learning and neural networks).Results: In the machine learning analysis of the experimental groups, the pre-swing (PS) angle showed the highest ranking in all 3 analyses (sensitivity, specificity, and area under the receiver operating characteristics curve using the Naive Bayes, k-nearest neighbors, radial basis function classifiers). Initial contact (IC), step length, and stride length also performed well. Between 7 and 28 days after injury, there was an increase in the total course time, step length, stride length, stride speed, and IC, and a reduction in PS and IC-PS. Statistically significant differences were found between the control group and experimental groups for all parameters except speed. Interactions between time after injury and nerve injury type were only observed for IC, PS, and IC-PS.Conclusion: PS angle of the ankle was the best gait parameter for differentiating nonlesions from nerve injuries and different levels of injury."
암 예후를 효과적으로 예측하기 위한 Node2Vec 기반의 유전자 발현량 이미지 표현기법,2019,"['Bioinformatics', 'Gene Expression', 'Node2Vec', 'Cancer Prognostic Prediction', 'Personalized Medicine', '생물정보학', '유전자 발현량', 'Node2Vec', '암 예후 예측', '맞춤형 의학']",,"Accurately predicting cancer prognosis to provide appropriate treatment strategies for patients is one of the critical challenges in bioinformatics. Many researches have suggested machine learning models to predict patients’ outcomes based on their gene expression data. Gene expression data is high-dimensional numerical data containing about 17,000 genes, so traditional researches used feature selection or dimensionality reduction approaches to elevate the performance of prognostic prediction models. These approaches, however, have an issue of making it difficult for the predictive models to grasp any biological interaction between the selected genes because feature selection and model training stages are performed independently. In this paper, we propose a novel two-dimensional image formatting approach for gene expression data to achieve feature selection and prognostic prediction effectively. Node2Vec is exploited to integrate biological interaction network and gene expression data and a convolutional neural network learns the integrated two-dimensional gene expression image data and predicts cancer prognosis. We evaluated our proposed model through double cross-validation and confirmed superior prognostic prediction accuracy to traditional machine learning models based on raw gene expression data. As our proposed approach is able to improve prediction models without loss of information caused by feature selection steps, we expect this will contribute to development of personalized medicine."
Onset Classification in Hemodynamic Signals Measured During Three Working Memory Tasks Using Wireless Functional Near-Infrared Spectroscopy,2019,,,"<P>Wireless wearable functional near-infrared spectroscopy (fNIRS) has attracted growing attention as a candidate for real-life brain monitoring systems. It is important to determine the onsets at which neuronal activation is evoked by cognitive status in real-time analysis. We propose a machine learning approach for the classification of cognitive event onsets (CogEOs) in hemodynamic signals during three cognitive tasks. The approach does not require a threshold to be set or additional measurement for the rest state. A support vector machine is trained by labeled features obtained from the mean amplitude of hemodynamic changes and then predicts the type of onset points. The problems caused by the imbalance between CogEOs and non-event onsets (NonEO) are solved by oversampling the feature samples labeled by cognitive events. By oversampling, the classification accuracy from an average of five classification scores reaches 74%, 77%, and 75% for the simple arithmetic, 1-back, and 2-back tasks. We achieve the best onset classification performance when the NonEOs are randomly distributed and when the subject is performing the 1-back task. Our study extends fNIRS to real-life applications by detecting the time point when brain activation starts among random observations using machine learning without additional triggers or threshold.</P>"
Work life balance practices and the link to innovation and productivity,2019,"['work life balance', 'innovation', 'productivity']",,"The purpose of this paper is to review recent literature, by conducting a thorough investigation of the limitations and implications for future research on work-life balance with the focus and linkages between work-life balance practices, machine learning and emotional intelligence, work-life conflict, the correlations between work-life enrichment and work-life balance practices, the relationships between employee job satisfaction and work-life balance, the links between work-life balance and the managerial support. The paper will further detail linkages between work-life balance and organizational performance outcomes productivity and innovation. Previous literatures have paid attentions to the link of HR practices and organizational outcomes such as productivity, flexibility, and financial performance, but the understanding needs to be extended to involve innovation performance.. Dealing with employees emotions using different machine learning techniques is one of the phenomenal researches in today's world. Here, we examine how far the employees are conscious of their own self and found the ideas and views of an individual about themselves and others. Without proper knowledge about their personality it will be very difficult for an individual to manage their own emotions. This study also aims at finding out the individual abilities to manage their emotions in order to perform well. A theoretical conceptual framework has been built by integrating the existing literature to explain a number of factors which are closely associated with work-life balance. The conceptual model illustrates how the work-life balance interplays with performance and interrelates with the aforementioned factors."
일본의 한적 정보화와 코퍼스 구축 현황,2019,"['Digitization of texts in Chinese', 'Chinese Character(漢文) Materials Corpus', 'The Institute for Research in Humanities', 'Kyoto University', 'The National Institute for Japanese Language and Linguistics', 'Kundoku Corpus', '한적정보화', '한자 코퍼스', '교토대학교 인문과학연구소', '국립국어 연구소', '훈독 코퍼스']","국내 한문 자료의 경우 국가 주도의 한문고전 전산화 사업을 통해 원시 코퍼스는 확보되었으나 주석, 병렬 코퍼스 구축 작업은 크게 관심을 받지 못하였다. 국내 한문 자료의 코퍼스 구축 및 기계번역은 단계적으로 진행된 것이 아니라 최근 인공지능 번역의 개발에 힘입어 단기간에 발전되어 온 것이라고 할 수 있다. 현 단계의 인공지능 번역은 기계가 원문 번역문 데이터를 기반으로 문장 간의 연관성을 자동적으로 학습하는 단계이기 때문에 문법, 품사, 표점 등 일정한 기준에 의해 주석을 가하는 주석 코퍼스를 구축하는 작업은 불필요하게 여겨진다.이러한 상황은 같은 한자문화권인 중국과 일본의 상황과 견주어 보았을 때 무척 상이하다. 중국과 일본은 기계번역을 대비하여 한적 정보화와 코퍼스 구축 사업이 단계적으로 진행되고 왔다. 이들의 코퍼스 구축 작업은 기계 번역의 효율성을 제고하는 것뿐 아니라 국학 연구의 긍정적 기여를 하는 것을 목표로 하고 있다. 이를 볼 때 국내 한적 자료의 코퍼스 구축 작업이 과연 불필요한 것인지에 대한 재고가 필요하다.일본에서는 교토대학교 인문과학연구소와 국립국어 연구소의 주도로 한문 원전 코퍼스 구축 작업이 진행되어왔다. 인문과학연구소는 Mecab 형태소 분석기를 활용하여 주석 코퍼스를 구축하였으며, 전통적인 훈독 방식을 응용하여 Universal Dependencies에 의한 依存文法解析을 시도하였다. 일본 국립국어 연구소의 연구는 코퍼스 구축을 통해 번역 결과물을 생성해내는 작업뿐 아니라, 이를 바탕으로 시대와 학파, 문단에 따른 학문적, 문예적 경향을 추출해 내었다. 이러한 성과를 볼 때 한국의 원전 자료에서도 주석, 병렬 코퍼스를 구축하는 작업에 관심이 필요하다.","In the case of Korean domestic resources for classic literature written in Chinese characters, the government-driven project for digitization of classical texts has secured the raw corpus, but the development of tagged corpus and parallel corpus has not received as much attention.The development of corpus and the machine translation of Korean domestic Chinese character text resources were not a phased development over time, but rather a short-term advancement helped by recent developments in artificial intelligence translation. Artificial intelligence translation at the current stage is processed by machines automatically learning the relationship between sentences based on the data of original and translated texts, and therefore developing a tagged corpus, which is adding annotations according to certain criteria such as grammar, word class, and punctuation, is deemed an unnecessary task.In comparison, the situation is very different in China and Japan, which are also within the Chinese character cultural sphere. China and Japan have been phasing in with projects in digitalization of texts in Chinese characters and development of corpora in preparation for machine translations. The goals of developing corpora in China and Japan is not only to improve the efficiency of machine translations, but also to positively contribute to the national studies of each country. This situation prompts us to reconsider whether it is truly unnecessary to develop corpora for Korean texts in Chinese characters.In Japan, Kyoto University Institute for Research in Humanities Library, and the National Institute for Japanese Language and Linguistics have led the corpus development work from original texts in Chinese characters. The Institute for Research in Humanities have developed a tagged corpus utilizing the Mecab Morphological Analyzer and attempted dependency parsing based on Universal Dependencies with application of the traditional Japanese reading method(Kundoku) of Chinese characters. The studies of the National Institute for Japanese Language and Linguistics not only created translation results by developing corpora, but also extracted scholarly, literary styles depending on the era, the schools of theory, the literary circles in Japan from this foundation. Considering such examples, the development of tagged, parallel corpora from Korean original text resources in Chinese characters is still a meaningful task."
PSD 응용 카툰 캐릭터 페이셜리깅 연구,2019,"['facial rigging', 'facial mocap', 'FACS', 'PSD', 'VFX', 'CG animation', '페이셜리깅', 'FACS', 'PSD', '모션캡쳐']",페이셜 애니메이션을 위한 리깅기술은 CG 기술의 발전과 함께 지속적으로 발전해오고 있다. 디지털 캐릭터를 제작 시 얼굴 표정의 정확함과 자연스러운 표정 구현은 점점 더 중요해지고 있다. 최근에는 모션 캡쳐를 이용한 FACS(Facial Action Coding System) 분석을 이용한 페이셜 리깅의 등장으로 영화 VFX에 사실성을 더해주고 있다. 최근 영화 “알리타:배틀엔젤(Alita:Battle Angel)”에서 등장하는 디지털 캐릭터들이 이 방법을 사용해서 제작 되었다. 하지만 이 방법은 FACS 솔버(Solver)와 머신러닝(Machine learning) 등의 기술을 이용한 것으로 작은 스튜디오와 개인 창작자들이 기술을 이용하는 것이 쉽지 않다. 위에 언급한 기술들은 많은 자본과 시간 그리고 숙련된 아티스트가 필요한 작업으로 헐리웃에서도 거대한 규모의 스튜디오에서만 실행이 되고 있는 방법이다. 하지만 우리는 본 연구를 통해 새로운 기술 적용의 부담을 줄이고 페이셜 캡쳐와 FACS를 이용한 방법과 결과는 유사하지만 소규모 스튜디오와 일반 아티스트도 개발이 가능한 카툰 캐릭터의 페이셜 리깅을 제안해 보려 하였다. 본 연구는 상용 소프트웨어의 포즈에디터(Pose Editor) 기능이 특정한 애니메이션 포즈에서 사전에 제작 된 블랜드 쉐입 타겟을 적용 시킨다는 아이디어에 근간하여 이를 얼굴의 페이셜 포즈에 적용 할 수 있는 방법을 연구하였다. 몸(Body)의 애니메이션 동작 수정을 위해 만들어진 포즈 에디터(Pose Editor)지만 본 연구에서는 얼굴의 표정으로 만들어지는 포즈 또한 수정할 수 있게 만드는 방법을 연구하여 페이셜 리깅에 이 방법을 적용했다. 본 연구의 리깅 기술은 기존의 상용화 툴이 가지고 있는 포즈 에디터(Pose edit) 기능과 PSD(Pose Space Deformation)를 이용해 제작이 되었고 페이셜 모션 캡쳐를 사용하더라도 기존 클러스터만을 이용한 리깅보다 보다 정확한 표정을 만들 수 있는 것을 목표로 한다. 또한 본 연구의 결과는 모션 캡쳐를 이용하여 사실적인 형태의 디지털 크리쳐의 표정 뿐만 아니라 카툰 스타일의 과장된 표정 적용에도 가능하다는 것을 보여준다. 이는 본 연구의 방향인 사전에 미리 제작된 페이셜 타겟을 페이셜 리깅에 적용하는 방법 때문에 가능하며 심하게 과장되거나 인간의 얼굴 형태를 벗어난 캐릭터에도 적용이 가능하다. 또한 실시간 모션 캡쳐 애니메이션에 적용이 가능하기 때문에 일반 아티스트들이 실시간 방송이나 게임에도 쉽게 적용시켜 사용할 수 있다.,"Rigging technology for facial animation is advancing with the development of CG technology. The precision of the facial expression and the natural expression becomes more important when producing digital characters. Recent motion capture with FACS (Facial Action Coding System) add more realistic facial motion to digital character in movie VFX. In the recent film ""Alita: Battle Angel"", all digital characters are made by FACS method. This method uses techniques such as FACS solver and machine learning, and it is not easy for small studios and individual creators to use the technology. The techniques mentioned above are a way to run a huge studio in Hollywood with a lot of capital, time, and skilled artists. However, we tried to propose facial rigging of cartoon character that can reduce the burden of applying new technology and develop similar method and results using facial capture and FACS. This study is based on the idea that the Pose Editor function of commercial software applies a blend shape target that was made beforehand in a specific animation pose and studied how to apply it to facial pose of face. In our study, we applied this method originally developed for body rigging to facial rigging by studying how to make the pose made by facial expressions. The rigging technique of this study was made by using Pose edit function and PSD (Pose Space Deformation) of existing commercialization tool and it is possible to make more accurate expression than rigging using existing cluster deformer. In addition, the results of this study show that it is possible to apply not only realistic digital creature expressions but also cartoon style exaggerated facial expressions using motion capture. This is possible because of the method of applying facial target pre-made to the facial rigging in advance, which is the direction of this study, and it can be applied to characters which are exaggerated or out of human face form. In addition, real-time motion capture animation can be applied to ordinary artists can easily apply to real-time broadcasting or games."
M&W 파동 패턴과 유전자 알고리즘을 이용한 주식 매매 시스템 개발,2019,"['Stock Trading System', 'M&W Wave Patterns', 'Genetic Algorithm', 'Walk-Forward Analysis', 'Portfolio Optimization', '주식 매매 시스템', 'M&W 파동 패턴', '유전자 알고리즘', '전진 분석', '포트폴리오 최적화']","투자자들은 기업의 내재가치 분석, 기술적 보조지표 분석 등 복잡한 분석보다 차트(chart)에 나타난 그래프(graph)의 모양으로 매매 시점을 찾는 직관적인 방법을 더 선호하는 편이다. 하지만 패턴(pattern) 분석 기법은IT 구현의 난이도 때문에 사용자들의 요구에 비해 전산화가 덜 된 분야로 여겨진다. 최근에는 인공지능(artificial intelligence, AI) 분야에서 신경망을 비롯한 다양한 기계학습(machine learning) 기법을 사용하여 주가의 패턴을연구하는 사례가 많아졌다. 특히 IT 기술의 발전으로 방대한 차트 데이터를 분석하여 주가 예측력이 높은 패턴을 발굴하는 것이 예전보다 쉬워졌다. 지금까지의 성과로 볼 때 가격의 단기 예측력은 높아졌지만, 장기 예측력은 한계가 있어서 장기 투자보다 단타 매매에서 활용되는 수준이다. 이외에 과거 기술력으로 인식하지 못했던패턴을 기계적으로 정확하게 찾아내는 데 초점을 맞춘 연구도 있지만 찾아진 패턴이 매매에 적합한지 아닌지는별개의 문제이기 때문에 실용적인 부분에서 취약할 수 있다. 본 연구는 주가 예측력이 있는 패턴을 찾으려는기존 연구 방법과 달리 패턴들을 먼저 정의해 놓고 확률기반으로 선택해서 매매하는 방법을 제안한다. 5개의전환점으로 정의한 Merrill(1980)의 M&W 파동 패턴은 32가지의 패턴으로 시장 국면 대부분을 설명할 수 있다.전환점만으로 패턴을 분류하기 때문에 패턴 인식의 정확도를 높이기 위해 드는 비용을 줄일 수 있다. 32개 패턴으로 만들 수 있는 조합의 수는 전수 테스트가 불가능한 수준이다. 그래서 최적화 문제와 관련한 연구들에서가장 많이 사용되고 있는 인공지능 알고리즘(algorithm) 중 하나인 유전자 알고리즘(genetic algorithm, GA)을 이용하였다. 그리고 미래의 주가가 과거를 반영한다 해도 같게 움직이지 않기 때문에 전진 분석(walk-forward analysis, WFA)방법을 적용하여 과최적화(overfitting)의 실수를 줄이도록 하였다. 20종목씩 6개의 포트폴리오(portfolio)를 구성하여 테스트해 본 결과에 따르면 패턴 매매에서 가격 변동성이 어느 정도 수반되어야 하며 패턴이 진행 중일 때보다 패턴이 완성된 후에 진입, 청산하는 것이 효과적임을 확인하였다.","Investors prefer to look for trading points based on the graph shown in the chart rather than complex analysis, such as corporate intrinsic value analysis and technical auxiliary index analysis. However, the pattern analysis technique is difficult and computerized less than the needs of users. In recent years, there have been many cases of studying stock price patterns using various machine learning techniques including neural networks in the field of artificial intelligence(AI). In particular, the development of IT technology has made it easier to analyze a huge number of chart data to find patterns that can predict stock prices.Although short-term forecasting power of prices has increased in terms of performance so far, long-term forecasting power is limited and is used in short-term trading rather than long-term investment. Other studies have focused on mechanically and accurately identifying patterns that were not recognized by past technology, but it can be vulnerable in practical areas because it is a separate matter whether the patterns found are suitable for trading. When they find a meaningful pattern, they find a point that matches the pattern. They then measure their performance after n days, assuming that they have bought at that point in time. Since this approach is to calculate virtual revenues, there can be many disparities with reality.The existing research method tries to find a pattern with stock price prediction power, but this study proposes to define the patterns first and to trade when the pattern with high success probability appears.The M & W wave pattern published by Merrill(1980) is simple because we can distinguish it by five turning points. Despite the report that some patterns have price predictability, there were no performance reports used in the actual market. The simplicity of a pattern consisting of five turning points has the advantage of reducing the cost of increasing pattern recognition accuracy. In this study, 16 patterns of up conversion and 16 patterns of down conversion are reclassified into ten groups so that they can be easily implemented by the system. Only one pattern with high success rate per group is selected for trading. Patterns that had a high probability of success in the past are likely to succeed in the future. So we trade when such a pattern occurs. It is a real situation because it is measured assuming that both the buy and sell have been executed.We tested three ways to calculate the turning point. The first method, the minimum change rate zig-zag method, removes price movements below a certain percentage and calculates the vertex. In the second method, high-low line zig-zag, the high price that meets the n-day high price line is calculated at the peak price, and the low price that meets the n-day low price line is calculated at the valley price. In the third method, the swing wave method, the high price in the center higher than n high prices on the left and right is calculated as the peak price. If the central low price is lower than the n low price on the left and right, it is calculated as valley price. The swing wave method was superior to the other methods in the test results. It is interpreted that the transaction after checking the completion of the pattern is more effective than the transaction in the unfinished state of the pattern.Genetic algorithms(GA) were the most suitable solution, although it was virtually impossible to find patterns with high success rates because the number of cases was too large in this simulation. We also performed the simulation using the Walk-forward Analysis(WFA) method, which tests the test section and the application section separately. So we were able to respond appropriately to market changes. In this study, we optimize the stock portfolio because there is a risk of over-optimized if we implement the variable optimality for each individual stock. Therefore, we selected the number of constituent stocks as 20 to in..."
음주운전 사건시 프로야구단의 위기커뮤니케이션 전략 분석: LG트윈스 및 SK와이번스의 2019년 사건 사례를 중심으로,2019,"['Sport Crisis Communication Strategy', 'Crisis Response Strategy', 'Strategic communications', 'Big Data Analytics tools', '프로스포츠구단 위기대응', '위기커뮤니케이션 전략', '프로야구 음주운전', '스포츠 커뮤니케이션', '빅데이터 분석기법']","본 연구는 2019년 발생한 LG트윈스 윤대영 및 SK와이번스 강승호 등 유사한 특성을 가진 2건의 프로야구선수 음주운전사건에서 기사에 반영된 각 구단의 대 언론메시지를 비교 분석했다. 이를 통해, 소속선수의 일탈행위 발생시 프로스포츠구단의 효과적 위기커뮤니케이션에 관한 의미있는 시사점을 발견하고자 했다. 연구방법으로는 파이썬(python) 코딩을 활용한 자동화(automated)된 방법과 수동화(manual) 방법을 병행해 웹스크래핑(web scraping), 전처리(preprocessing), 주제어 빈도분석(keyword frequency analysis)을 수행했다. 수집된 30개 매체 149개 기사의 총 489개 문장을 9개의 위기커뮤니케이션 전략 카테고리로 분류했고, 머신러닝 알고리즘(machine learning algorithm)중 베이시안 필터(bayesian filter)를 적용해 검수했다. 텍스트 데이터를 구단별로 위기 진행단계에 따라 3단계로 구분한 후, X축(시간대)과 Y축(위기커뮤니케이션 전략)의 2사분면에 mapping해 전략 패턴을 추출했고, 기사수와 댓글수를 척도로 효과성을 측정했다. 연구결과, LG구단 메시지에서는 ‘음주운전’, ‘선수’, ‘행위’, ‘사회’ 등이, SK에서는 ‘KBO’, ‘선수’, ‘강승호’, ‘징계’ 등의 단어가 많이 사용된 것으로 나타났고, 특히 LG에 비해 SK가 소속선수의 실명을 대 언론 메시지에 많이 포함시켰던 것으로 확인됐다. 전략 mapping 결과, LG는 전 단계에 걸쳐 수용적 전략 위주로 대응했고, SK도 수용적 전략을 전 단계에 걸쳐 사용했지만, 특히 방어적 전략인 희생양(scapegoating) 전략을 중반부터 후반부까지 선택했던 것으로 나타났다. 전략패턴 및 효과성 분석결과, LG는 위기발생 단계에서는 성급한 대응으로 효과적이지 못했으나, 위기상황 및 사후단계에서는 비교적 효과적인 대응을 했던 것으로 나타났다. SK는 위기발생 단계에서는 효과적이지 못한 대응을 했고, 위기상황 및 사후단계에서 기사수 조절에는 성공했으나 댓글수 조절에는 실패했던 것으로 확인됐다. 본 연구에서 SK의 사례를 통해 선수들의 음주운전 사건에서 희생양 전략은, 구단의 책임성을 제거하지 못하는 상황에서는 효과적 전략이 되기 어렵다는 선행연구 결과와 부합했던 것을 확인할 수 있었다. 또한, 과거 유사한 위반 사례를 가졌던 LG는 자신들의 예전 위반행위를 스스로 언급하는 사과전략을 사용했고 효과적이었던 것으로 나타났는데, 이는 부정적 이력을 가진 구단은 선수들의 일탈행위로 인한 위기상황에서 과거 잘못된 사례를 기억하는 이해관계자들을 고려해 대응하는 것이 효과적일 수 있다는 선행연구 결과와 일치했던 것으로 나타났다. SK는 선수의 음주운전이 인사사고가 아니었는데도, 사후단계에서 교통사고 피해자들의 보상과 결부시키는 일종의 사죄전략을 사용했으며 효과적이지 못했던 것으로 나타났는데, 피해자가 없는 위반상황에서 지나친 사과 전략은 적절치 않다는 점도 유추할 수 있었다.","The purpose of this study is to find valuable implications for effective crisis communication of professional sports clubs in case of athlete transgressions. The study analyzed the professional baseball clubs media message in the drunk driving accidents of two professional baseball players involved in LG Twins Yoon Dae-young and SK Wyverns Kang Seung-ho, which happened in South Korea in 2019. As a research method, web scraping, preprocessing, and keyword frequency analysis were carried out using Python coding. The 489 text data collected from 149 articles were categorized into nine crisis communication strategy categories, and examined them by the Bayesian filter of the machine learning algorithms. Dividing the text data into three stages according to  the progress of the crisis by each team, the strategy patterns were extracted by mapping them to the two quadrants of the X-axis (time zone) and Y-axis (crisis communication strategy),  and measured the effectiveness by measuring the number of articles and comments. As a result of the study, the words of 'drink driving', 'athlete', 'act' and 'society' are used in the message of LG Twins, and the words 'KBO', 'athlete', 'Kang Seung-ho' and 'disciplinary action' are used in SK Wyverns. SK was more likely to include their player name in the message. LG responded with an accommodative strategy at all stages, and SK also used an accommodative strategy at all stages, but chose a strategy for scapegoating, which is a defensive strategy, from the crisis event to the post crisis stages. According to analysis of strategic patterns and effectiveness, LG did not have an effective response in the break out stage, but it did so in the crisis event and post crisis stages. SK made an ineffective response at the crisis stage and succeeded in controlling the number of articles in the crisis event and post crisis stages, but failed to control the number of comments. SK's case could be inferred that the scapegoating strategy would not be an effective strategy in situations where the team's responsibilities could not be removed from the players' drunk driving cases. LG used an apology to mention their past transgressions and proved to be effective. It can be inferred that it is effective for a team with a negative history to comment on the wrong cases of the past. In the case of SK, the strategy of mortification is not effective in the case that the player's drunk driving did not cause any personal damage."
뉴럴네트워크(NEWFM)를 이용한 심근경색의 특징추출과 분류,2019,"['classification', 'heart attack', 'feature selection', 'Neural Network']","최근 심근경색은 중장년층의 돌연사의 80%로 밝혀졌다. 심근경색의 발병 원인은 복합적이고 갑자기 발생하게되어 예방이나 건강검진을 하더라도 발병을 예측하기 어렵다. 따라서 빠른 진단과 적절한 치료가 가장 중요하다. 이 논문에서는 심근경색에 대한 정확하고 빠른 진단을 위해 가중퍼지소속함수를 이용한 신경망으로 정상과 비정상 분류에 대한정확도를 나타내었다. 실험에 사용된 데이터는 14개의 특징과 303개의 샘플 데이터로 이루어진 UCI Machine Learning Repository에서 제공하는 데이터 사용하였다. 2개의 특징을 선택하여 제거하였다. 특징선택을 위한 알고리즘은 average of weight method를 사용하였다. 가중퍼지소속함수를 이용하여 심근경색을 정상과 비정상으로 분류(1-nomal, 2-abnormal)하였다. 실험 결과 정확도가 87.66%가 나왔다.","Recently heart attack is 80% of the sudden death of elderly. The causes of a heart attack are complex and sudden, and it is difficult to predict the onset even if prevention or medical examination is performed. Therefore, early diagnosis and proper treatment are the most important. In this paper, we show the accuracy of normal and abnormal classification with neural network using weighted fuzzy function for accurate and rapid diagnosis of myocardial infarction. The data used in the experiment was data from the UCI Machine Learning Repository, which consists of 14 features and 303 sample data. The algorithm for feature selection uses the average of weight method. Two features were selected and removed. Heart attack was classified into normal and abnormal(1-normal, 2-abnormal) using the average of weight method. The test result for the diagnosis of heart attack using a weighted fuzzy neural network showed 87.66% accuracy."
인공지능과 법체계–전자인격론의 모순과 정보권한과의 갈등을 중심으로–,2019,"['artificial intelligence', 'non-personal intelligence', 'electronic personhood', 'digital right to information', 'right to disappear', 'Cartesian ghost in the brain', 'digital fairness', 'net neutrality', '인공지능', '비인격적 지능', '전자 인격', '디지털 정보권', '잊혀질 권리', '전자귀신론', '디지털 공정성', '망 중립성']","인공지능은 간략하게 말하면 비인격적 인지체계(the intelligence exhibited by machine or software)이다. 인공지능은 의도된 단일 기술이 아니라 의도와 달리 실현된 것도 있고, 계획과 달리 우연히 활성화된 요소도 있다. 그래서 현재와 같은 모습으로 나타나기까지 많은 계획과 경험의 통합이 필요했다. 최근 철학이나 법학에서도 인공지능의 지위 문제를 포스트 휴먼, 인공지능, 제4차 산업혁명 등의 주제로 논의하고 있다. 인공지능의 현실 분석을 넘어서 비인격적 지능에 대한 법적 승인(법인격) 가능성을 언급하기도 한다. 또한 인공지능이 적용된 기술결과를 가상으로 전제하여 그에 대한 미래 법적 책임을 다루기도 한다. 어떠한 경우이던 비인격적 지능은 딜레마를 가지고 있다. 프로그램된 기계의 오류를 파악하지 못하는 경우는 별로 없다. 반면에 인간의 정신적 이상 현상은 그 누구도 원인을 분명히 설명하지 못한다. 우리가 ‘지능’이라는 단어를 사용하기 위해서는 최소한 지능이 발현되는 인간의 의식(마음)의 요소가 기계에 의해 어떻게 재현되는지 설명해야 한다. 인간의 마음이 분석되지 못하면, 그 재현 가능성도 함께 애매해진다. 이 글은 인공지능 기술은 완성된 것도 아니고, 향후 그럴 가능성도 희박할 수 있다는 가설에서 출발한다. 현재의 논의를 보면 인공지능의 재현능력에 대한 환상에 의존하거나 불충분한 기술적 이해로 인한 오류와 혼란도 있는 듯하다. 최종적으로 기술의 가치와 사회적 수용은 별개이다. 또한 인공지능 기술의 기반을 위한 법적 여건이 최근 변화되고 있는 점도 감안해야 한다.","Today we can run across articles without saying Artificial Intelligence(AI) will change everything. Is this true in the context of the legal profession? Some claim an “AI apocalypse” or “Doomsday.” Even some serious legal experts add up and enchant the scenario. Much of press reporting is hype or clickbait, however the debate within the practice of law is that we need to look upclose to AI and its substantial impact.Simply, AI means the intelligence exhibited by machine or software. Software can analyze words: It can automatically classify and search for paragraphs, and compare documents and highlight changes. Technically it is not a firm entity as it firstly planned. Some realized; the others accidently done. It is a huge leftover in many purposes and projects. Legal and philosophical assessments reach its status in various aspects. Legal approaches are dominated by negative voices; small group provocate that the impact of AI on the legal practice will be tremendously. It could learn over time human-like task: AI/machine learning can use big data to understand, then the learning makes it go beyond human.We do not believe this. AI is an algorithm-based program driven by many electric devices. Furthermore there is a wild river between the value of technology and legal premise. Whether it gets or not is always in our hands. It casts a doubt that the debate goes through unexpected vaguness."
다양한 환경에 강인한 컬러기반 실시간 손 영역 검출,2019,"['Hand image processing', 'Image processing', 'Real-time performance', 'Background subtraction']",,"The smart product market is growing year by year and is being used in many areas. There are various ways of interacting with smart products and users by inputting voice recognition, touch and finger movements. It is most important to detect an accurate hand region as a whole step to recognize hand movement. In this paper, we propose a method to detect accurate hand region in real time in various environments. A conventional method of detecting a hand region includes a method using depth information of a multi-sensor camera, a method of detecting a hand through machine learning, and a method of detecting a hand region using a color model. Among these methods, a method using a multi-sensor camera or a method using a machine learning requires a large amount of calculation and a high-performance PC is essential. Many computations are not suitable for embedded systems, and high-end PCs increase or decrease the price of smart products. The algorithm proposed in this paper detects the hand region using the color model, corrects the problems of the existing hand detection algorithm, and detects the accurate hand region based on various experimental environments."
SW융합영재 담당교원 역량 강화를 위한 텐서플로우 기반인공지능 교육 콘텐츠 개발,2019,"['SW융합영재', '담당교원 역량 강화', '텐서플로우', '인공지능', '교육 콘텐츠', 'SW Convergence Gifted', 'Reinforcing Competence of Teacher', 'TensorFlow', 'Artificial Intelligence', 'Education Contents']","미래사회에서의 국가 경쟁력 강화는 뛰어난 SW융합영재 발굴과 양성이다. 이러한 SW융합영재를 양성하기 위해서는 담당교원의 역량 강화가 선결되어야 할 것이다. 이를 위하여 본 논문에서는 SW융합영재 담당교원의 역량 강화를 위한 4차 산업혁명 시대의 핵심 기술 중에 하나인 인공지능 교육 콘텐츠를 개발하였다. 인공지능 교육 콘텐츠의 방향을 설정 후, 인공지능 중에서도 중등 SW융합영재 교육에 적합한 교육 콘텐츠를 구성하여 상세 설계 및 개발하였다. 인공지능 교육 콘텐츠의 구성은 머신러닝과 텐서플로우의 이해, 수치 예측을 위한 선형 회귀 머신러닝 구현, 다중 선형 회귀 기반의 가격 예측 머신러닝 구현으로 이루어져 있다. 개발한 인공지능 교육 콘텐츠는 전문가에게 질적인 측면의 검증을 실시하였다. 향후 본 논문에서 제안한 인공지능 교육 콘텐츠는 SW융합영재 담당교원의 역량 강화에 도움을 줄 것으로 기대한다.","The enhancement of national competitiveness in future society is the discovery and training of excellent SW convergence gifted. In order to cultivate these SW convergence gifted, reinforcing competence of teachers in charge should be made first. Therefore, in this paper, artificial intelligence education contents, one of the core technologies of the 4th Industrial Revolution era, were developed to reinforcing competence of SW convergence gifted teachers. After setting the direction of artificial intelligence education content, we constructed educational content suitable for secondary SW convergence gifted education, and designed and developed it in detail. The composition of artificial intelligence education content consists of machine learning and tensor flow understanding, linear regression machine learning implementation for numerical prediction, and multiple linear regression-based price prediction machine learning implementations. The developed educational contents were verified by experts with qualitative aspects. In the future, we expect that the educational content of artificial intelligence proposed in this paper will be useful for strengthening the ability of SW convergence gifted teachers."
Gaussian mixture model for automated tracking of  modal parameters of long-span bridge,2019,"['Gaussian Mixture Model (GMM)', 'baseline modal properties', 'automated mode tracking', 'long-span bridge', 'structural health monitoring (SHM)']",,"Determination of the most meaningful structural modes and gaining insight into how these modes evolve are important issues for long-term structural health monitoring of the long-span bridges. To address this issue, modal parameters identified throughout the life of the bridge need to be compared and linked with each other, which is the process of mode tracking. The modal frequencies for a long-span bridge are typically closely-spaced, sensitive to the environment (e.g., temperature, wind, traffic, etc.), which makes the automated tracking of modal parameters a difficult process, often requiring human intervention. Machine learning methods are well-suited for uncovering complex underlying relationships between processes and thus have the potential to realize accurate and automated modal tracking. In this study, Gaussian mixture model (GMM), a popular unsupervised machine learning method, is employed to automatically determine and update baseline modal properties from the identified unlabeled modal parameters. On this foundation, a new mode tracking method is proposed for automated mode tracking for long-span bridges. Firstly, a numerical example for a three-degree-of-freedom system is employed to validate the feasibility of using GMM to automatically determine the baseline modal properties. Subsequently, the field monitoring data of a long-span bridge are utilized to illustrate the practical usage of GMM for automated determination of the baseline list. Finally, the continuously monitoring bridge acceleration data during strong typhoon events are employed to validate the reliability of proposed method in tracking the changing modal parameters. Results show that the proposed method can automatically track the modal parameters in disastrous scenarios and provide valuable references for condition assessment of the bridge structure."
로직에 기반 한 트리 구조의 퍼지 뉴럴 네트워크를이용한 복합 화력 발전소의 출력 예측,2019,"['fuzzy neural networks', 'combined cycle power plant', 'output power prediction']","오늘날 복합 화력 발전소는 전력 생산을 위해 많이 사용되고 있고, 최근에는 운전 매개 변수를 기반으로 발전 출력을 예측하는 것이 주요 관심사이다. 본 논문에서는 복합 화력 발전소의 출력을 예측하기 위해 컴퓨터 지능 기법을 이용하는 방법을제시한다. 컴퓨터 지능 기술은 지속적으로 발전되어 많은 실제 문제에 적용되어 왔다. 본 논문에서는 트리 구조의 퍼지 뉴럴네트워크를 이용하여 발전 출력을 예측하고자 한다. 트리 구조의 퍼지 뉴럴 네트워크는 퍼지 뉴런을 노드로 선택하고 관련입력을 최적으로 선택하여 규칙 수를 줄이는 장점이 있다. 네트워크의 최적화를 위해 2 단계 최적화 방법이 사용된다. 유전알고리즘은 최적의 노드와 리프를 선택하여 네트워크의 이진 구조를 최적화 한 다음 랜덤 신호 기반 학습을 수행하여 최적화 된 이진 연결을 단위 구간에서 미세 학습한다. 제안 된 방법의 유용성을 검증하기 위해 UCI Machine LearningRepository Database에서 얻은 복합 화력 발전소 데이터를 사용한다.","Combined cycle power plants are often used to produce power. These days prediction of power plant output based onoperating parameters is a major concern. This paper presents an approach to using computational intelligence techniqueto predict the output power of combined cycle power plant. Computational intelligence techniques have been developedand applied to many real world problems. In this paper, tree architectures of fuzzy neural networks are considered topredict the output power. Tree architectures of fuzzy neural networks have an advantage of reducing the number of rulesby selecting fuzzy neurons as nodes and relevant inputs as leaves optimally. For the optimization of the networks,two-step optimization method is used. Genetic algorithms optimize the binary structure of the networks by selecting thenodes and leaves as binary, and followed by random signal-based learning further refines the optimized binaryconnections in the unit interval. To verify the effectiveness of the proposed method, combined cycle power plant datasetobtained from the UCI Machine Learning Repository Database is considered."
Current and Future Status of GIS-based Landslide Susceptibility Mapping: A Literature Review,2019,"['Landslide susceptibility', 'GIS', 'trend', 'literature review']",,"Landslides are one of the most damaging geological hazards worldwide, threating both humans and property. Hence, there have been many efforts to prevent landslides and mitigate the damage that they cause. Among such efforts, there have been many studies on mapping landslide susceptibility. Geographic information system (GIS)-based techniques have been developed and applied widely, and are now the main tools used to map landslide susceptibility. We reviewed the status of landslide susceptibility mapping using GIS by number of papers, year, study area, number of landslides, cause, and models applied, based on 776 articles over the last 20 years (1999-2018). The number of studies published annually increased rapidly over time. The total study area spanned 65 countries, and 47.7% of study areas were in China, India, South Korea, and Iran, where more than 500 landslides, 27.3% of all landslides, have occurred. Slope (97.6% of total articles) and geology (82.7% of total articles) were most often implicated as causes, and logistic regression (26.9% of total articles) and frequency ratio (24.7% of total article) models were the most widely used models. We analyzed trends in the causes of and models used to simulate landslides. The main causes were similar each year, but machine learning models have increased in popularity over time. In the future, more study areas should be investigated to improve the generalizability and accuracy of the results. Furthermore, more causes, especially those related to topography and soil, should be considered and more machine learning models should be applied. Finally, landslide hazard and risk maps should be studied in addition to landslide susceptibility maps."
Current and Future Status of GIS-based Landslide Susceptibility Mapping: A Literature Review,2019,"['Landslide susceptibility', 'GIS', 'trend', 'literature review']",,"Landslides are one of the most damaging geological hazards worldwide, threating both humans and property. Hence, there have been many efforts to prevent landslides and mitigate the damage that they cause. Among such efforts, there have been many studies on mapping landslide susceptibility. Geographic information system (GIS)-based techniques have been developed and applied widely, and are now the main tools used to map landslide susceptibility. We reviewed the status of landslide susceptibility mapping using GIS by number of papers, year, study area, number of landslides, cause, and models applied, based on 776 articles over the last 20 years (1999– 2018). The number of studies published annually increased rapidly over time. The total study area spanned 65 countries, and 47.7% of study areas were in China, India, South Korea, and Iran, where more than 500 landslides, 27.3% of all landslides, have occurred. Slope (97.6% of total articles) and geology (82.7% of total articles) were most often implicated as causes, and logistic regression (26.9% of total articles) and frequency ratio (24.7% of total article) models were the most widely used models. We analyzed trends in the causes of and models used to simulate landslides. The main causes were similar each year, but machine learning models have increased in popularity over time. In the future, more study areas should be investigated to improve the generalizability and accuracy of the results. Furthermore, more causes, especially those related to topography and soil, should be considered and more machine learning models should be applied. Finally, landslide hazard and risk maps should be studied in addition to landslide susceptibility maps."
Quark-Gluon Jet Discrimination Using Convolutional Neural Networks,2019,"['Machine learning', 'Jet tagging', 'QCD', 'Jet', 'Fragmentation']",,"Currently, newly developed articial intelligence techniques, in particular convolutional neural networks, are being investigated for use in data-processing and classication of particle physics collider data. One such challenging task is to distinguish quark-initiated jets from gluon-initiated jets. Following previous work, we treat the jet as an image by pixelizing track information and calorimeter deposits as reconstructed by the detector. We test the deep learning paradigm by training several recently developed, state-of-the-art convolutional neural networks on the quarkgluon discrimination task. We compare the results obtained using various network architectures trained for quark-gluon discrimination and also a boosted decision tree (BDT) trained on summary variables."
Motion Region Detection and Pattern Extraction Algorithm of a Motion Image Based on a Radar Sensor,2019,"['Machine Learning', 'Motion Detection', 'Motion Recognition', 'Pattern Extraction', 'Radar Image Processing']",,"In this paper, a motion region detection and pattern extraction algorithm is proposed for motion recognition based on the image as the distance changes between the radar sensor and human motion. This algorithm, which was developed by combining the characteristics of the radar motion image and image processing techniques, compensates for the discontinuous data that can occur when removing clutter for motion data detection and extracts motion patterns applicable to the recognition learning field. According to the motion data measured by a radar sensor, the algorithm performance is verified by an experiment."
통계적 전처리 과정을 통한 분류기 성능 향상에 관한 연구,2019,"['machine learning', 'emotion recognition', 'feature selection', 'EEG']",,"One of the most significant current discussion in AI (Artificial Intelligence) and HCI (Human Computer Interface) is the pattern recognition algorithm. Many methods are available for this purpose, such as, the support vector machine, artificial neural network, and Bayesian decision rule. In these methods, the number of features is the most critical factor affecting the classifier performance. Therefore, we herein propose feature selection and extraction methods to obtain a more effective classifier (higher accuracy and less complexity). To do this, we apply a statistical algorithm. Before we use pattern recognition algorithms, we select features using variance and correlation coefficient. Additionally, we extract the features using the dimension reduction method. We could filter out critical features and reduce the number of features using above process. For an objective evaluation, we use electroencephalogram and the survey data of the DEAP (dataset for emotion analysis using physiological signals). Additionally, we perform a comparison with the existing study. According to the performance evaluation, a classifier with higher accuracy and less computational complexity is obtained."
FEEDFORWARD NEURAL NETWORKS AND SEPARATION OF GEOMETRIC REGIONS,2019,"['machine learning', 'feedforward neural network']",,"We investigate how a feedforward neural network works to separate a geometric region from its complement. Our investigations are restricted to regions in R or R2 including an interval, a triangular region, a disk and the union of two disjoint disks. We also examine what happens at each layer of the network."
A Study on Prediction of Baseball Game Based on Linear Regression,2019,"['Machine Learning', 'Linear Regression', 'Baseball Game']",,"Currently, the sports market continues to grow every year, and among them, professional baseball's entry income is larger than the rest of the professional league. In sports, strategies are used differently in different situations, and the analysis is based on data to decide which direction to implement. There is a part that a person misses in an analysis, and there is a possibility of a false analysis by subjective judgment. So, if this data analysis is done through artificial intelligence, the objective analysis is possible, and the strategy can be more rationalized, which helps to win the game. The most popular baseball to be applied to artificial intelligence to analyze athletes' strengths and weaknesses and then efficiently establish strategies to ease the competition. The data applied to the experiment were provided on the KBO official website, and the algorithms for forecasting applied linear regression. The results showed that the accuracy was 87%, and the standard error was ±5. Although the results of the experiment were not enough data, it would be possible to effectively use baseball strategies and predict the results of the game if the amount of data and regular data can be applied in the future."
Evaluation of Subtractive Clustering based Adaptive Neuro-Fuzzy Inference System with Fuzzy C-Means based ANFIS System in Diagnosis of Alzheimer,2019,"['AD', 'ANFIS', 'Fuzzy C-Means', 'Subtractive Clustering']",,"Machine learning techniques have been applied in almost all the domains of human life to aid and enhance the problem solving capabilities of the system. The field of medical science has improved to a greater extent with the advent and application of these techniques. Efficient expert systems using various soft computing techniques like artificial neural network, Fuzzy Logic, Genetic algorithm, Hybrid system, etc. are being developed to equip medical practitioner with better and effective diagnosing capabilities. In this paper, a comparative study to evaluate the predictive performance of subtractive clustering based ANFIS hybrid system (SCANFIS) with Fuzzy C-Means (FCM) based ANFIS system (FCMANFIS) for Alzheimer disease (AD) has been taken. To evaluate the performance of these two systems, three parameters i.e. root mean square error (RMSE), prediction accuracy and precision are implemented. Experimental results demonstrated that the FCMANFIS model produce better results when compared to SCANFIS model in predictive analysis of Alzheimer disease (AD)."
센싱데이터와 기상기후 빅데이터를 융합한 태양광발전량의 회귀모델 예측분석,2019,"['Machine learning', 'Linear Regression', 'SVR', 'DNN', 'Predcition']",,"In this paper, a model for predicting photovoltaic power based on collecting weather big-data and data from photovoltaic power plants is proposed with linear regression models of machining technique. The temperature, humidity, illumination, and fine dust data of photovoltaic power plants were collected and the values fused with the weather big-data were utilized as the regression model learning data. The three regression models of LR, SVR and DNN were compared and the results and accuracy of the error function were predicted by applying photovoltaic power data to each model. When using the DNN model, it was confirmed that it would have the highest accuracy from the data for predicting photovoltaic power generation. Using the designed DNN model, photovoltaic power can be predicted in any area, and accuracy can be improved according to the seasonal climate and standards of the area and the quality of comparative data."
오픈 플랫폼 기반의 스마트 주차시스템 설계 연구,2019,"['Machine learning', 'Raspberry pi', 'System design', 'IoT']","전기차, 공유경제, 무인주행 등을 이슈로 하는 교통 생태계의 변화가 예상되고 있는 동시에, 초연결사회로의 진입에 맞추어 자동차 역시 IT기술로 무장된 스마트 카로의 진화 발전 중에 있어, 지능형 주차관제의 발전은 필연적이라 할 수 있다. 특히 도심 내 교통체증의 주원인 중 하나가 주차과정에서 발생하는 것으로 조사 보고될 정도로 매우 중요한 이슈가 되고 있는데 반해 충분한 주차장과 주차장 관련 시설의 확보는 매우 어려운 실정이다. 이러한 주차 공간 확보 문제 해결을 위한 다양한 방법이 제시되어 왔으나, 기존의 과도한 구축비용의 문제로 인해 보급 및 확산이 저조했다. 본 논문에서는 이러한 개별주차정보시스템의 문제를 해결하기 위하여 소규모 주차장에 적용 가능한 저비용, 고효율의 오픈소스 기반 경량 주차시스템의 설계를 통해 도심 주차문제 해결의 방향성을 제시하고자 한다. 구체적으로, 노상주차 공간에 대한 주차정보를 스마트 카메라를 통해 수집하고 IoT 네트워크를 통해 클라우드로 실시간 전달을 통한 관제 및 사용자에게 정보를 제공할 수 있는 경량 주차관리 시스템을 설계하고자 한다. 본 시스템은 차량의 감지를 위한 라즈베리파이 기반의 CCTV, 수집된 정보를 분석하기 위한 지도학습 주차인식 알고리즘, 정보를 전송하기 위한 IoT 통신기술, 사용자에게 정보를 전달하기 위한 클라우드 시스템 등으로 구성되어 있다.","It is expected that changes in the transportation ecosystem will be made based on issues such as electric vehicles, shared economy, and unmanned driving while adapting to the entry into a hyper-connected society. As cars are evolving into IT-armed Smart Cars, in particular, one of the main causes of traffic congestion in the city center has become a very important issue to be investigated and reported during the parking process. It is very difficult to secure enough parking lots and related facilities. the development of intelligent parking controls is inevitable. Various methods have been suggested to address these parking spaces, but problems with the existing excessive cost of deployment have led to poor penetration and diffusion. In order to solve the problem of an individual parking information system, the design of low-cost, high-efficiency open-source-based light parking system for small parking lots is designed in this paper, and thus presenting the direction of solving the city parking problem. Specifically, parking information on the street parking spaces is collected through smart cameras. It is planning to design a lightweight parking management system that can provide information to users and control through real-time delivery to the cloud system through the IoT network. The system consists of a raspberry pie-based CCTV for detecting vehicles, a map-learning parking recognition algorithm for analyzing collected information, IoT communication technology for transmitting information and a cloud system."
상용 부품 비정형 데이터와 인공 신경망을 이용한 부품 단종 예측 방안 연구,2019,"['Machine Learning', 'Big Data', 'Fasttext', 'Neural Network', 'DMSMS', 'LC Risk', 'YTEOL']","기술의 발전으로 다양한 부품의 개발 및 상용화는 가능 하였으나, 이에 따라 부품의 단종 주기는 단축 되었다. 이는 수천 품목 이상의 부품을 활용하여 개발하고, 장기간 운영하는 무기체계의 수리 부속 보급을 어렵게 하였으며, 무기체계 운용 가용도 저하의 주요 원인으로 작용하였다. 이러한 문제를 해결하기 위하여 미국 등은 전담 기구를 만들어 대응하고 있으며, 국내에서는 상용 부품단종 예측도구를 활용하여 단종을 예측하고 관리하고 있다. 하지만 상용 부품단종 예측도구에서 단종 정보가 제시되지 않는 부품에 대한 대응 및 관리는 부재한 실정이다. 이에 본 연구에서는 상용부품단종 예측도구에서 제공하는 부품에 대한 정형, 비정형 빅데이터를 수집하고, 데이터 전처리 및 Embedding 과정을 거쳐, 신경망 학습 알고리즘을 적용하여, 상용 부품에 대한 단종 정보 (LC Risk, YTEOL)를 예측하는 방안을 제시하였다. 또한 제시된 모델의 예측 성능을 데이터 기술 통계량과 비교 평가 하여. 본 연구에서 제시한 학습 모델의 타당성을 검증 하였다. 결론에는 본 연구의 활용 방안과 한계점 및 발전 방향에 대하여 기술 하였다.","Advances in technology have allowed the development and commercialization of various parts; however this has shortened the discontinuation cycle of the components. This means that repair and logistic support of weapon system which is applied to thousands of part components and operated over the long-term is difficult, which is the one of main causes of the decrease in the availability of weapon system. To improve this problem, the United States has created a special organization for this problem, whereas in Korea, commercial tools are used to predict and manage DMSMS. However, there is rarely a method to predict life cycle of parts that are not presented DMSMS information at the commercial tools. In this study, the structured and unstructured data of parts of a commercial tool were gathered, preprocessed, and embedded using neural network algorithm. Then, a method is suggested to predict the life cycle risk (LC Risk) and year to end of life (YTEOL). In addition, to validate the prediction performance of LC Risk and YTEOL, the prediction value is compared with descriptive statistics."
FEEDFORWARD NEURAL NETWORKS AND SEPARATION OF GEOMETRIC REGIONS,2019,"['machine learning', 'feedforward neural network']",,"We investigate how a feedforward neural network works to separate a geometric region from its complement. Our investigations are restricted to regions in ${\mathbb{R}}$ or ${\mathbb{R}}^2$ including an interval, a triangular region, a disk and the union of two disjoint disks. We also examine what happens at each layer of the network."
Random Forest 기법을 이용한 산사태 취약성 평가 시 훈련 데이터 선택이 결과 정확도에 미치는 영향,2019,"['산사태 취약성', '머신러닝', 'Random Forest', '훈련 데이터', '샘플링 전략', 'landslide susceptibility', 'machine learning', 'Random Forest', 'training data', 'sampling strategy']","머신러닝 기법을 활용한 분석에서 훈련 데이터의 샘플링 전략은 예측 정확도 뿐 만 아니라 일반화 능력에도 많은영향을 미친다. 특히, 산사태 취약성 분석의 경우, 산사태 발생부에 대한 정보에 비해 산사태 미발생부에 대한 정보가과도하게 많은 데이터 불균형 현상이 발생하며, 이에 따라 분석 모델의 훈련 데이터 설계 시 데이터 샘플링 과정이필수적이다. 그러나 기존의 연구들은 대부분 산사태 미발생부 선택 시 발생부 데이터와 1:1의 비율을 갖도록 무작위로 선택하는 방법을 적용하였을 뿐, 특정한 선택 기준에 따라 분석을 수행하지 않았다. 따라서 본 연구에서는 훈련 데이터의 샘플링 전략이 모델의 예측 성능에 미치는 결과를 확인하기 위하여 산사태 발생부와 미발생부의 샘플링 전략기준에 따라 서로 다른 6개의 시나리오를 만들어 Random Forest 모델의 훈련에 사용하였다. 또한 Random Forest의결과 중 하나인 변수 중요도를 각 산사태 유발인자들에 가중치로 곱하여 줌으로써 산사태 취약지수 값을 산정하였으며, 취약지수 값을 이용해 산사태 취약성도를 제작하고 각 결과 지도의 정확도를 비교 분석하였다. 분석 결과, 훈련데이터의 샘플링 방법에 상관없이 두 지역의 산사태 취약성 분석 결과는 모두 70~80%의 정확도를 보였다. 이를 통해 Random Forest 기법의 산사태 취약성 분석기법으로서의 적용 가능성을 확인하였으며, Random Forest 모델이 제공하는 입력변수의 중요도를 산사태 유발인자 가중치로 활용할 수 있음을 확인하였다. 또한 훈련 시나리오 간의 정확도를 비교한 결과, 특정한 기준에 의해 훈련 데이터를 설계하는 것이 기존의 랜덤 선택 방법보다 높은 예측 정확도를기대할 수 있음을 확인하였다.",
YOLO-v3을 활용한 건설 장비 주변 위험 상황 인지 알고리즘 개발,2019,"['Deep Learning', 'Image Processing', 'Construction Safety', 'Sensor', 'Construction Equipment']","최근 정부는 건설 산업의 재해율과 사고 사망률이 전체 산업 중 높은 비율을 차지한다는 점을 개선하기 위하여 새로운 대책을 강구하고 있다. 특히 4차 산업혁명의 시대적 흐름에 맞춰 ICT 기술과 융합된 건설 기술 개발에 집중적으로 투자하고 있다. 이런 상황에 대응하고자 본 논문에서는 건설 기계를 사용하는 작업에서 작업자의 안전성 향상을 위한 방법으로, 건설 기계 운전자와 주변 작업자 간의 작업 상황 정보를 공유하고 인지할 수 있는 개념을 제시하였다. 그리고 해당 개념의 일부를 실현하고자 카메라를 이용한 인공 지능 기반 영상처리 기술을 활용하여 토공 작업에 접목시켰다. 그 중에서도 다짐 장비를 이용한 실험을 통해 YOLO-v3 기반의 영상 처리 알고리즘으로 토공 작업 중에 주변 작업자 상황을 인지하고 위험 상황 여부를 판단할 수 있는 알고리즘을 구현하였다. 그 결과 본 알고리즘은 동영상에서 초당 15.06프레임을 처리하며 90.48%의 정확도로 건설 기계 주변 위험 상황을 인지할 수 있다. 향후 이 같은 기술을 활용하여 건설 현장의 안전사고 예방에 기여하고자 한다.","Recently, the government is taking new approaches to change the fact that the accident rate and accident death rate of the construction industry account for a high percentage of the whole industry. Especially, it is investing heavily in the development of construction technology that is fused with ICT technology in line with the current trend of the 4th Industrial Revolution. In order to cope with this situation, this paper proposed a concept to recognize and share the work situation information between the construction machine driver and the surrounding worker to enhance the safety in the place where construction machines are operated. In order to realize the part of the concept, we applied image processing technology using camera based on artificial intelligence to earth-moving work. Especially, we implemented an algorithm that can recognize the surrounding worker’s circumstance and identify the risk situation through the experiment using the compaction equipment. and image processing algorithm based on YOLO-v3. This algorithm processes 15.06 frames per second in video and can recognize danger situation around construction machine with accuracy of 90.48%. We will contribute to the prevention of safety accidents at the construction site by utilizing this technology in the future."
시공간 특성을 활용한 랜덤 포레스트 기반 도로 노면 상태 예측,2019,"['빅데이터', '머신러닝', '랜덤 포레스트', '도로 노면 상태', '도로 위험', 'big data', 'machine learning', 'random forest', 'road surface condition', 'road safety']","최근 비나 눈과 같은 강수가 발생한 날의 교통사고 건수가 증가하고 있다. 교통사고 건수를 감소시키기 위해서는 지속적인 도로 유지 보수 활동뿐만 아니라, 운전자의 도로 위험에 대한 인식도 필요하다. 운전자가 도로 위험을 인지하기 위해서는 운전자가 운전하고 있는 도로의 노면 상태가 젖어 있거나 결빙되었는지 알 필요가 있다. 본 연구에서는 서울, 인천, 경기 지역에서 수집한 기상과 노면 상태 정보를 사용하여 시공간 정보를 포함한 특성으로 가공하였고, 랜덤 포레스트 모델에 학습하였고 95%의 정확도로 노면 상태를 예측하였다. 특히 공간 특성인 공간 색인 값은 학습한 데이터의 양에 따라 학습 효율이 향상하였으며, 공간 색인을 사용하지 않은 경우보다 최대 5% 예측 정확도 상승률을 보였다. 본 연구는 지점이 아닌 특정 범위 안에 속하는 모든 도로의 노면 상태 정보를 운전자에게 제공할 수 있다는 점에서 그 의의가 있다. 마지막으로 다른 주변 환경 정보를 학습할 수 있도록 노면 상태 정보 수집 지역을 확장한다면, 더 넓은 범위의 도로에 대한 노면 상태를 예측 가능할 것으로 기대한다.","Recently the number of car accidents has been increasing when the precipitation such as rain or snow has occurred. To reduce the number of car accidents, not only continuous activity for road maintenance but also driver’s perception of road risk is necessary. In this paper, we engineered spatio-temporal features using weather and spatial information collected in the area of Seoul, Gyeonggi-do and Incheon, and trained random forest model predicting road surface conditions up to accuracy of 95%. Spatial index, which is a feature of explaining spatial information, is more efficient in proportion to the size of trained data, and achieved at most 5% of accuracy increase rate compared to a prediction model where spatial index has not been trained. Because the prediction model predicts not point but area, our research contributes to providing road surface condition information to any drivers in the trained area. Finally, expanding the collecting area of road surface conditions in order to train other surrounding environments, the prediction model is expected to predict road surface conditions of wider area."
Conditional Molecular Design with Deep Generative Models,2019,,,"<P>Although machine learning has been successfully used to propose novel molecules that satisfy desired properties, it is still challenging to explore a large chemical space efficiently. In this paper, we present a conditional molecular design method that facilitates generating new molecules with desired properties. The proposed model, which simultaneously performs both property prediction and molecule generation, is built as a semisupervised variational autoencoder trained on a set of existing molecules with only a partial annotation. We generate new molecules with desired properties by sampling from the generative distribution estimated by the model. We demonstrate the effectiveness of the proposed model by evaluating it on drug-like molecules. The model improves the performance of property prediction by exploiting unlabeled molecules and efficiently generates novel molecules fulfilling various target conditions.</P>[FIG OMISSION]</BR>"
빅데이터 구축을 위한 알루미나 테이프 캐스팅 공정 최적화,2019,"['Big data', 'Al2O3', 'Tape casting', 'Slurry viscosity', 'Coating speed', 'Gap size', 'Packing density']","머신 러닝 기법에 표준화 된 빅데이터를 구축하기 위해서는 경향성을 갖춘 양질의 데이터가 지도학습되어야 한다. 본 연구에서는 테이프 캐스팅 방법으로 알루미나 테잎을 제작하였으며, 슬러리 점도, 갭 높이, 코팅속도에 따른 최적화를 진행하였다. 슬러리 점도 1000-6000 cps, 갭 높이 300-1000 ㎛, 코팅속도는 0.5-2.0 m/s 범위에서 알루미나 테잎을 제조하였다. 그 결과, 코팅속도가 늦을수록 그리고 슬러리 점도와 갭 높이가 낮을수록 기공이 없고 충진밀도가 높은 테잎을 제조할 수 있었다. 그리고 슬러리 점도 대역에 따라 구현 가능한 테잎 두께에는 한계가 있었다. 점도가 1000~6000 cps인 슬러리에서 코팅속도가 0.5 m/min, 갭 높이 300-500㎛ 일 때 충진밀도가 높은 우수한 테잎을 제작할 수 있었다. 슬러리 점도 1000 cps 경우에는 갭 300-700 ㎛ 범위에서 약 64%, 점도 3300 cps 경우에는 갭 300-500 ㎛에서 약 61%, 그리고 점도 6000 cps 경우에는 갭 300-500 ㎛에서 약 64%의 높은 충진밀도를 나타내었다.","For machine learning techniques, a large amount of high-quality material property data should be accumulated. In this study, several data for an alumina tape casting process were produced with the variables of slurry viscosity, gap size, and coating speed. The alumina tapes were manufactured in the range of 1,000~6,000 cps for slurry viscosity, 300~1,000 ㎛ for gap size, and 0.5~2.0 m/min for coating speed. As a result, the lower the viscosity, coating speed, and gap size, the more pore-free tapes could be manufactured. The viscosity of the slurry limited the minimum thickness of the tape. Green sheets with high packing density were manufactured from the slurry of 100~6,000 cps slurry viscosity, coating speed of 0.5 m/min, and a 300~500 ㎛ gap size."
Identification of tissue‑specific tumor biomarker using different optimization algorithms,2019,['Biomarker · Machine learning tools · Messenger RNA · Optimization algorithm · Pathway analysis'],,"Background Identification of differentially expressed genes, i.e., genes whose transcript abundance level differs across different biological or physiological conditions, was indeed a challenging task. However, the inception of transcriptome sequencing (RNA-seq) technology revolutionized the simultaneous measurement of the transcript abundance levels for thousands of genes.Objective In this paper, such next-generation sequencing (NGS) data is used to identify biomarker signatures for several of the most common cancer types (bladder, colon, kidney, brain, liver, lung, prostate, skin, and thyroid) Methods Here, the problem is mapped into the comparison of optimization algorithms for selecting a set of genes that lead to the highest classification accuracy of a two-class classification task between healthy and tumor samples. As the optimization algorithms Artificial Bee Colony (ABC), Ant Colony Optimization, Differential Evolution, and Particle Swarm Optimization are chosen for this experiment. A standard statistical method called DESeq2 is used to select differentially expressed genes before being feed to the optimization algorithms. Classification of healthy and tumor samples is done by support vector machine Results Cancer-specific validation yields remarkably good results in terms of accuracy. Highest classification accuracy is achieved by the ABC algorithm for Brain lower grade glioma data is 99.10%. This validation is well supported by a statistical test, gene ontology enrichment analysis, and KEGG pathway enrichment analysis for each cancer biomarker signature Conclusion The current study identified robust genes as biomarker signatures and these identified biomarkers might be helpful to accurately identify tumors of unknown origin"
SDN 환경의 트래픽 분류를 위한 특징 선택 기법,2019,"['SDN', 'machine learning', 'feature selection', 'network traffic', 'classification accuracy']",,
인공지능 피아노 교습 기술의 분석과 전망,2019,"['인공지능', '머신러닝', '피아노', '교습', '음악교육', 'Artificial Intelligence', 'machine learning', 'piano', 'tutor', 'music education']","본 연구에서는 인공지능 피아노 교습 기술을 검토함으로써 인공지능이 예술과 교육 분야에 줄 수 있는 영향을 알아보고자 한다. 특허와 상용화된 소프트웨어를 통하여 현재의 기술 수준을 검토하였으며, 3단계의 기술 수준으로 분석되었다. 1단계는 악보 데이터화를 통한 악보 추천 기술이다. 2단계는 소리를 비교하여 정오를 판단하여 오류를 알려주는 기술이다. 3단계는 지속적 오류를 확인하여 연주자의 습관 여부를 판단하여 알려주는 기술이다. 이들을 통하여, 인공지능 피아노 교습 기술은 반복 훈련에 의한 연주 스킬 향상에 도움을 준다는 것을 알 수 있다. 하지만 인공지능 피아노 교습 기술의 한계는 인간의 신체 움직임을 판단하지 못하고 감정을 확인할 수 없다는 점이다. 이러한 한계는, 인공지능 피아노 교습 기술이 음악 본질보다는 표현물인 소리 분석에 집중되어 있음에 기인한 것으로 판단된다. 표현물 이면에 존재하는 인간의 감정을 이해하고 분류하여 인공지능이 학습 가능한 데이터로 가공하고 그 구분 기준을 설정할 수 있어야 한다. 이러한 발전 방향이 인공지능과 예술을 융합하는 정도일 것으로 판단된다.","In this study, the effects of artificial intelligence on the arts and education were researched by studying artificial intelligence piano teaching skills. The current level of technology was reviewed through patents and commercially available software. They have three steps of technology. The first step is sheet music recommendation technology. The second step is to compare the sounds to determine and inform the error. The third step is a technology that determines and informs the habits of the player by checking the continuous error. Through these, the AI piano teaching technique helps to improve the playing skills by repetitive training. but cannot determine human body movements and identify emotions yet. This limitation is believed to be due to the fact that AI piano teaching technology is focused on sound analysis rather than music essence. In order to be the stage where artificial intelligence and art are truly converged, it is necessary to understand and classify human emotions that exist behind expressions."
이분형 자료의 분류문제에서 불균형을 다루기 위한 표본재추출 방법 비교,2019,"['imbalanced-learn', 'imbalanced binary data', 'under-sampling', 'over-sampling', '불균형 학습', '불균형 이분형 자료', '언더샘플링', '오버샘플링']","이분형 자료의 분류에서 자료의 불균형 정도가 심한 경우 분류 결과가 좋지 않을 수 있다.이런 문제 해결을 위해 학습 자료를 변형시키는 등의 연구가 활발히 진행되고 있다. 본 연구에서는 이러한 이분형 자료의 분류문제에서 불균형을 다루기 위한 방법들 중 표본재추출 방법들을 비교하였다. 이를 통해 자료에서 희소계급의 탐지를 보다 효과적으로 하는 방법을 찾고자 하였다. 모의실험을 통하여 여러 오버샘플링, 언더샘플링, 오버샘플링과 언더샘플링 혼합방법의 총 20가지를 비교하였다. 분류문제에서 대표적으로 쓰이는 로지스틱 회귀분석, support vector machine, 랜덤포레스트 모형을 분류기로 사용하였다. 모의실험 결과, 정확도가 0.5 이상이면서 민감도가 높았던 표본재추출 방법은 random under sampling (RUS)였다. 그 다음으로 민감도가 높았던 방법은 오버샘플링 ADASYN (adaptive synthetic sampling approach)이었다. 이를 통해 RUS 방법이 희소계급값을 찾기 위한 방안으로는 적합했다는 것을 알 수 있었다. 몇 가지 실제 자료에 적용한 결과도 모의실험의 결과와 비슷한 양상을 보였다.","A class imbalance problem arises when one class outnumbers the other class by a large proportion in binary data. Studies such as transforming the learning data have been conducted to solve this imbalance problem. In this study, we compared resampling methods among methods to deal with an imbalance in the classification problem. We sought to find a way to more effectively detect the minority class in the data. Through simulation, a total of 20 methods of over-sampling, under-sampling, and combined method of over- and under-sampling were compared. The logistic regression, support vector machine, and random forest models, which are commonly used in classification problems, were used as classifiers. The simulation results showed that the random under sampling (RUS) method had the highest sensitivity with an accuracy over 0.5. The next most sensitive method was an over-sampling adaptive synthetic sampling approach. This revealed that the RUS method was suitable for finding minority class values. The results of applying to some real data sets were similar to those of the simulation."
Feasibility Study of the Fluence-to-Dose Network (FDNet) for Patient-Specic IMRT Quality Assurance,2019,"['Deep-learning', 'Dynalog  le', 'Dose prediction', 'Patient-speci c quality assurance']",,"The aim of this study is to predict the delivered dose distribution [Ddelivered(x; y)] with the use of a uence-to-dose network (FDNet) to conduct patient-specic intensity-modulated radiation therapy (IMRT) quality assurance (pQA). The architecture of the FDNet was based on a convolutional neu- ral network. Forty-four IMRT clinical cases of planned dose distributions for pQA [Dplanned(x; y)] and dynamic multileaf collimator (MLC) log les (Dynalog les) were collected. Using the Dynalog les, the expected uence stack [Fexpected(x; y; t)] and the actual uence stack [Factual(x; y; t)] were created from the expected and the actual machine parameters, respectively. The actual uence stack, which was reconstructed from the partial information of the Dynalog le, corresponded to the control points of the Digital Imaging and Communications in Medicine radiation treatment plan and was denoted as [Factual(x; y; tpartial)]. The entire dataset was split into 11 subsets for the k-fold averaging cross-validation (k = 11). Ten (out of the 11) folds were used to train 10 candidate optimal FDNet models, and an ultimate FDNet was determined by averaging the parameters of the optimal models. The pQA was performed using the test data of the remaining fold with the ul- timate FDNet. The dose distributions predicted using Factual(x; y; t) [Dpredicted(Factual(x; y; t))] and Factual(x; y; tpartial) [Dpredicted(Factual(x; y; tpartial))] were acquired. To evaluate the pre- dicted pQA results, we conducted dosimetry using EBT3 lms and an ion-chamber array de- tector (MatriXX). These dose distributions were compared with the Dplanned(x; y) by using a gamma analysis. The average gamma passing rates were determined based on the 3%/3 mm gamma criterion and were, respectively, equal to 98.49%, 97.21%, 97.23%, and 98.03%, for the Dpredicted(Factual(x; y; t)), Dpredicted(Factual(x; y; tpartial)), EBT3 lm, and MatriXX. According to this study, the feasibility of the dose prediction method using the FDNet with complete Dynalog information was veried for the pQA. The respective differences of the average gamma passing rates for the Dpredicted(Factual(x; y; t)), and Dpredicted(Factual(x; y; tpartial)) were equal, respectively, to 1.28% and 2.88% according to the 3%/3 mm and the 2%/2 mm gamma criteria."
심층 CNN을 활용한 영상 분위기 분류 및 이를 활용한 동영상 자동 생성,2019,"['Convergence', 'Machine Learning', 'Multi-class Classification', 'Mood Classification', 'Convolutional Neural Network', 'Multilayer Perceptron', '융합', '기계학습', '다중 클래스 분류', '감정 분류', '합성곱 신경망', '다층 퍼셉트론']","본 연구에서는 영상의 분위기를 심층 합성곱 신경망을 통해 8 가지로 분류하고, 이에 맞는 배경 음악을 적용하여 동영상을 자동적으로 생성하였다. 수집된 이미지 데이터를 바탕으로 다층퍼셉트론을 사용하여 분류 모델을 학습한다. 이를 활용하여 다중 클래스 분류를 통해 동영상 생성에 사용할 이미지의 분위기를 예측하며, 미리 분류된 음악을 매칭시켜 동영상을 생성한다. 10겹 교차 검증의 결과, 72.4%의 정확도를 얻을 수 있었고, 실제 영상에 대한 실험에서 64%의 오차 행렬 정확도를 얻을 수 있었다. 오답의 경우, 주변의 비슷한 분위기로 분류하여 동영상에서 나오는 음악과 크게 위화감이 없음을 확인하였다.","In this paper, the mood of images was classified into eight categories through a deep convolutional neural network and video was automatically generated using proper background music. Based on the collected image data, the classification model is learned using a multilayer perceptron (MLP). Using the MLP, a video is generated by using multi-class classification to predict image mood to be used for video generation, and by matching pre-classified music. As a result of 10-fold cross-validation and result of experiments on actual images, each 72.4% of accuracy and 64% of confusion matrix accuracy was achieved. In the case of misclassification, by classifying video into a similar mood, it was confirmed that the music from the video had no great mismatch with images."
Bytedance: The Road to Success of a Global Influential Social Media Platforms Creator,2019,"['Bytedance', 'Machine Learning', 'Artificial Intelligence', 'social media', 'Toutiao', 'TikTok']",,"Started an AI-powered news aggregation company in 2012, Bytedance has developed into a global technology enterprise with a valuation of over $75 billion dollar in less than 10 years. This case study analyzes Bytedance’s remarkable success that is rarely achieved by China’s tech giants. The great success of Bytedance can be attributed to its dedication of the founder, people and continuous innovation of the short video app, TikTok. Despite TikTok has reached global popularity, this short video app is criticized for causing smartphone addiction due to its content stickiness. At the same time, stiff competition from local competitors is forcing Bytedance to expand into other markets. The global expansion of Bytedance via the usage of the TikTok app did not go well after TikTok was criticized for spreading offensive content and fake news. Eventually, Bytedance has to address these prevailing challenges"
Text Classification Using Parallel Word-level and Character-level Embeddings in Convolutional Neural Networks,2019,"['Word-level Embedding', 'Character-level Embedding', 'Convolutional Neural Network', 'Text Classification']",,"Deep learning techniques such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) show superior performance in text classification than traditional approaches such as Support Vector Machines (SVMs) and Naïve Bayesian approaches. When using CNNs for text classification tasks, word embedding or character embedding is a step to transform words or characters to fixed size vectors before feeding them into convolutional layers. In this paper, we propose a parallel word-level and character-level embedding approach in CNNs for text classification. The proposed approach can capture word-level and character-level patterns concurrently in CNNs. To show the usefulness of proposed approach, we perform experiments with two English and three Korean text datasets. The experimental results show that character-level embedding works better in Korean and word-level embedding performs well in English. Also the experimental results reveal that the proposed approach provides better performance than traditional CNNs with word-level embedding or character-level embedding in both Korean and English documents. From more detail investigation, we find that the proposed approach tends to perform better when there is relatively small amount of data comparing to the traditional embedding approaches."
"Predictive Analytics in Spine Oncology Research: First Steps, Limitations, and Future Directions",2019,"['Predictive analytics', 'Machine learning', 'Artificial intelligence', 'Spine tumor', 'Spine metastases', 'Primary spine tumor']",,"The potential of big data analytics to improve the quality of care for patients with spine tumors is significant. At this moment, the application of big data analytics to oncology and spine surgery is at a nascent stage. As such, efforts are underway to advance data-driven oncologic care, improve patient outcomes, and guide clinical decision making. This is both relevant and critical in the practice of spine oncology as clinical decision making is often made in isolation looking at select variables deemed relevant by the physician. With rapidly evolving therapeutics in surgery, radiation, interventional radiology, and oncology, there is a need to better develop decision-making algorithms utilizing the vast data available for each patient. The challenges and limitations inherent to big data analyses are presented with an eye towards future directions."
SVR 기반 단기 전력수요 예측 알고리즘 개발,2019,"['Load forecasting', 'Machine Learning', 'Support Vector Regression']",,"In recent years, precise power demand has become more important due to the constant increase in demand for electricity and abnormal weather conditions. Due to the abnormal weather conditions such as heat wave during summer season, electric power demand forecast error is increasing due to increase of heating and cooling load and this leads to economic losses due to the lowering of the stability of the power system and the increase in the cost of additional power purchase. In this paper, we propose a short-term power demand prediction algorithm based on Support Vector Regression which is an artificial intelligence technique. We implemented a short-term prediction model based on public data through correlation analysis such as temperature, time, and past electricity demand. In order to analyze the model performance, we analyzed the kernel function and slack variable value which are SVR parameter values. Finally, cross validation was performed to solve the overfitting problem."
안드로이드 악성코드 분류를 위한 Flow Analysis기반의 API 그룹화 및 빈도 분석 기법,2019,"['Android malware', 'Malware classification', 'Feature selection', 'API grouping', 'Flow analysis']","본 논문에서는 머신러닝 기반의 악성코드 분류에 있어 오버피팅 문제를 비롯하여 실제로 실행되지 않는 코드가APK에 포함되는 문제 등을 해결하기 위해 모든 API들의 연관성을 통해 그룹화하며, 제어 흐름 분석을 통해 실제로실행되는 코드에 대한 분석을 수행하는 툴을 개발하였다. 툴은 약 1,500라인으로 이루어진 자바 기반의 소프트웨어로, 전체 API에 대한 빈도 분석을 수행하거나 생성된 제어 흐름 그래프를 바탕으로 빈도 분석을 수행한다. 툴을 이용하여 모든 버전에서의 총 39032개의 메서드에 대해 4972개의 그룹으로 축소할 수 있으며, 클래스를 포함한 결과로는 총 12123개의 그룹으로 축소할 수 있다. 결과 분석을 위해서 본 논문에서는 총 7개의 패밀리에서 7,000개의APK를 랜덤으로 수집하였으며, 수집된 APK를 이용하여 feature를 축소하는 기법을 검증하였다. 또한, 추출된 데이터에서 빈도가 20% 이상으로 나타난 API만을 선별하여 feature를 더욱 축소하여 최종적으로 263개의 feature로 축소하였다.","While several machine learning technique has been implemented for Android malware categorization, there is stilldifficulty in analyzing due to overfitting problem and including of un-executable code, etc. In this paper, we introduce ourimplemented tool to address these problems. Tool is consists of approximately 1,500 lines of Java code, and perform Flowanalysis on set of APIs, or on control flow graph. Our tool groups all the API by its relationship and only perform analysison actually executing code. Using our tool, we grouped 39032 APIs into 4972 groups, and 12123 groups with result ofincluding class names. We collected 7,000 APKs from 7 families and evaluated our feature reduction technique, and we alsoreduced features again with selecting APIs that have frequency more than 20%. We finally reduced features to 263-numbersof feature for our collected APKs."
합성 곱 신경망 기반 웹 응용 트래픽 분류 모델 설계,2019,"['트래픽 분류', '머신러닝', '합성 곱 신경망', '응용 트래픽', 'Traffic Classification', 'Machine Learning', 'Convolution Neural Network', 'Application Traffic']",,
기어박스의 예측정비를 위한 인공지능 기반의 이상탐지 및 결함분류에 관한 연구,2019,"['기어박스', '상태기반정비', '머신러닝', '이상탐지', '결함모드', 'Gear Box', 'Condition Based Maintenance', 'machine-learning', 'anomaly detection', 'Failure Mode']","기존의 회전설비 진동상태감시 시스템은 비즈니스 룰 기반으로 수집된 진동신호에 대해 전문가의 경험과 공학적 지식을 바탕으로 진동신호를 처리하고 이상신호의 탐지 및 결함모드 분류를 수행하였다. 그러나 설비의 상태를 나타내는 인자들은 그 종류가 매우 다양하고 자료의 해석을 위해 신호처리 및 공학적인 배경지식이 필요해 비전문가는 어떠한 결함이 발생하였는지 알기 어렵다.본 논문에서는 설비에서 발생하는 진동신호의 결함이력에 대한 지도학습을 통해 이상신호를 분류하고, 분류된 이상신호에 대한 프로파일링에 대한 지도학습을 통해 결함모드를 분류하는 머신러닝 기반의 이상탐지 및 결함분류 시스템을 제안한다.",
Analysis of Open-Source Hyperparameter Optimization Software Trends,2019,"['Hyperparameter Optimization', 'Machine Learning', 'Deep Learning', 'AutoML']",,
Design Characteristics of Studies Reporting the Performance of Artificial Intelligence Algorithms for Diagnostic Analysis of Medical Images: Results from Recently Published Papers,2019,"['Artificial intelligence', 'Machine learning', 'Deep learning', 'Clinical validation', 'Clinical trial', 'Accuracy', 'Study design', 'Quality', 'Appropriateness', 'Systematic review', 'Meta-analysis']",,"Objective: To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images.Materials and Methods: PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journalsResults: Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals.Conclusion: Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms."
텐서 처리부의 분석 및 파이썬을 이용한 모의실행,2019,"['neural network', 'machine learning', 'matrix multiply unit']","컴퓨터 구조의 연구 결과, 특정 영역의 하드웨어를 개발하는 과정에서 가격 대 에너지 성능의 획기적인 개선이이뤄진다고 알려져 있다. 본 논문은 인공신경망(NN)의 추론을 가속화시킬 수 있는 텐서 처리부(TPU) ASIC에 대한 분석을 수행하였다. 텐서 처리부의 핵심장치는 고속의 연산이 가능한 MAC 행렬곱셈기와 소프트웨어로 관리되는 온칩 메모리이다. 텐서 처리부의 실행모델은 기존의 CPU와 GPU의 실행모델보다 인공신경망의 반응시간 요구사항을 제대로 충족시킬 수 있으며, 수많은 MAC과 큰 메모리를 장착함에도 불구하고 면적이 작고 전력 소비가 낮다. 텐서플로우 벤치마크프레임워크에 대하여 텐서 처리부를 활용함으로써, CPU 또는 GPU보다 높은 성능과 전력 효율을 나타낼 수가 있다.본 논문에서는 텐서 처리부를 분석하고, 파이썬을 이용하여 모델링한 OpenTPU에 대하여 모의실행을 하였으며, 그 핵심장치인 행렬 곱셈부에 대한 합성을 시행하였다.","The study of the computer architecture has shown that major improvements in price-to-energy performance stems from domain-specific hardware development. This paper analyzes the tensor processing unit (TPU) ASIC which can accelerate the reasoning of the artificial neural network (NN). The core device of the TPU is a MAC matrix multiplier capable of high-speed operation and software-managed on-chip memory. The execution model of the TPU can meet the reaction time requirements of the artificial neural network better than the existing CPU and the GPU execution models, with the small area and the low power consumption even though it has many MAC and large memory. Utilizing the TPU for the tensor flow benchmark framework, it can achieve higher performance and better power efficiency than the CPU or CPU. In this paper, we analyze TPU, simulate the Python modeled OpenTPU, and synthesize the matrix multiplication unit, which is the key hardware."
인공지능 기반 식생활 습관 개선 다이어트 애플리케이션,2019,"['다이어트 애플리케이션', '머신러닝 기반 추천 시스템', '딥러닝 기반 음식 인식 인터페이스', 'Diet Applications', 'Machine learning-Based Recommended system', 'Deep learning-Based Food recognition inter']",,
핑거프린트 방식의 자기 공진형 무선전력전송코일 정렬 상태 개선 기법 연구,2019,"['-', 'Positioning Method', 'Machine Learning', 'Wireless Power Transfer', 'Time-Varying Magnetic Field']",,"This paper proposes fingerprint-based positioning methods which can be used in a magnetic resonant wireless power transfer(WPT) system and verifies their performance. A new receiver coil with small orthogonal auxiliary coils is proposed to measure magnetic field signals in three axial directions. The magnitude and phase characteristics of the three-axis electromotive force can be obtained by using the proposed coil. To predict a position with the measured values, we propose a lookup table-based method and linear discriminant analysis-based method. For verification, the proposed methods are applied to predict 75 positions of the 6.78 MHz WPT system, and the performances such as accuracy and computation time are compared."
컨볼루션 신경망 기반 유해 네트워크 트래픽 탐지 기법평가,2019,"['Convolutional Neural Network', 'Traffic Classification', 'Image Transform', 'Configuration']","최근 유해 네트워크 트래픽을 탐지하기 위해 머신러닝 기법을 활용하는 다양한 방법론들이 주목을 받고 있다. 이 논문에서는 컨볼루션 신경망 (Convolutioanl Neural Network)을 기반으로 유해 네트워크 트래픽을 분류하는 기법을 소개하고 그 성능을 평가한다. 이미지 처리에 강한 컨볼루션 신경망의 활용을 위해, 네트워크 트래픽의 주요 정보를 규격화된 이미지로 변환하는 방법을 제안하고, 변환된 이미지를 입력으로 컨볼루션 신경망을 학습시켜 유해 네트워크 트래픽의 분류를 수행하도록 한다. 실제 네트워크 트래픽 관련 데이터셋을 활용하여 이미지 변환 및 컨볼루션 신경망 기반 네트워크 트래픽 분류 기법의 성능을 검증하였다. 특히, 다양한 컨볼루션 신경망 기반 네트워크 모델 구성에 따른 트래픽 분류 기법의 성능을 평가하였다.","Recently, various machine learning based traffic classification methods are focused on detecting malicious network traffic. In this paper, convolutional neural network based malicious network traffic classification method is introduced and its performance is evaluated. In order to utilize the convolutional neural network which is excellent in analyzing images, a image transform method from important information of network traffic to a standardized image is proposed, and the transformed images are used as learning input of a CNN network traffic classifier. By using the real network traffic dataset, the proposed image transform method and CNN based network traffic classification method are evaluated. Especially, under various configurations of CNN, the performance of the proposed method is evaluated."
정적 분석과 앙상블 기반의 리눅스 악성코드 분류 연구,2019,"['Linux Malware', 'Machine Learning', 'Static Analysis']","IoT 시장의 성장과 더불어 linux 아키텍쳐를 사용하는 디바이스들에 대해 악성코드 보안 위협이 꾸준히 증가하고있다. 하지만, Mirai 등의 심각한 보안피해를 야기한 주요 악성코드들을 제외하면 linux 악성코드에 대한 보안 커뮤니티의 관련 기술이나 연구는 전무한 수준이다. 또한, IoT 환경의 디바이스, 벤더, 아키텍쳐 등의 다양성이 더욱 심화됨에 따라 linux 악성코드 대응 난이도 또한 심화되고 있다. 따라서, 본 논문에서는 linux 아키텍쳐의 주요 포맷인 ELF를 분석하고 이를 기반으로 한 분석 시스템과, IoT 환경을 고려한 바이너리 기반의 분석 시스템을 제안한다.ELF 기반의 분석 시스템은 상대적으로 고속으로 다수의 악성코드에 대해 전처리 분류 할 수 있으며 상대적으로 저속의 바이너리 기반의 분석 시스템은 전처리 하지 못한 데이터에 대해 모두 분류 가능하다. 이러한 두 개의 프로세스는 서로 상호보완되어 효과적으로 linux 기반의 악성코드를 분류할 수 있을 것이라 기대한다.","With the growth of the IoT market, malware security threats are steadily increasing for devices that use the linuxarchitecture. However, except for the major malware causing serious security damage such as Mirai, there is no relatedtechnology or research of security community about linux malware. In addition, the diversity of devices, vendors, andarchitectures in the IoT environment is further intensifying, and the difficulty in handling linux malware is also increasing.Therefore, in this paper, we propose an analysis system based on ELF which is the main format of linux architecture, and abinary based analysis system considering IoT environment. The ELF-based analysis system can be pre-classified for a largenumber of malicious codes at a relatively high speed and a relatively low-speed binary-based analysis system can classify allthe data that are not preprocessed. These two processes are supposed to complement each other and effectively classifylinux-based malware."
Data-Driven Materials Modeling with XGBoost Algorithm and Statistical Inference Analysis for Prediction of Fatigue Strength of Steels,2019,['Fatigue strength\xa0Machine learning\xa0Data mining\xa0Materials informatics\xa0Materials database\xa0Data-driven model'],,"With the rapid development of the industry, the demand for new materials is increasing. However, new material development is time-consuming and costly. In this study, we proposed a workflow that uses data to create a materials model that accurately reflects the properties of materials. Six different numerical models for predicting the fatigue strength of steels were constructed with an empirical dataset extracted from a certified database (NIMS MatNavi material database). Because it is very difficult to understand the structure and patterns of large amounts of datasets and develop good predictive models at once, we have sought reliable models through statistical inference analysis, which has not been done in previous studies. We also chose the highest performance model with the accuracy (R2 = 0.9850) by applying the latest XGBoost algorithm. Through further study, we believe that this workflow can be used to develop predictive models on various properties of materials."
심층신경망을 활용한 Cochlodinium polykrikoides 적조 발생 예측 연구,2019,"['Red Tide', 'Machine Learning', 'Harmful Algal Bloom Prediction', '적조', '기계 학습', '유해 조류 발생 예측']",본 연구에서는 심층 신경망을 이용하여 Cochlodinium polykrikoides 적조 발생을 예측하는 모델을 제안한다. 적조 발생 예측을 위해 8개의 은닉층을 가진 심층 신경망을 구축하였다. 위성 재분석 자료와 기상수치모델 자료를 이용하여 과거 적조 발생해역의 해양 및 기상인자 총 59개를 추출하여 신경망 모델 학습에 활용하였다. 전체 데이터셋 중 적조 발생 사례는 적조 미발생 사례에 비해 매우 적어 불균형 데이터 문제가 발생하였다. 본 연구에서는 이를 해결하기 위해 과표집화(Over sampling) 기반 데이터 증식(Data augmentation) 기법을 적용하였다. 과거자료를 활용하여 모형의 정확도를 평가한 결과 약 97%의 정확도를 보였다.,"In this study, we propose a model for predicting Cochlodinium polykrikoides red tide occurrence using deep neural networks. A deep neural network with eight hidden layers was constructed to predict red tide occurrence. The 59 marine and meteorological factors were extracted and used for neural network model training using satellite reanalysis data and meteorological model data. The red tide occurred in the entire dataset is very small compared to the case of no red tide, resulting in an unbalanced data problem. In this study, we applied over sampling with adding noise based data augmentation to solve this problem. As a result of evaluating the accuracy of the model using test data, the accuracy was about 97%."
이미지 기반 품질 관리 기법의 스마트 팩토리 현장 적용 이슈와 전략,2019,"['Quality Management', 'Machine Learning', 'Convolution Neural Network', 'Smart Factory', '품질 경영', '기계 학습', '합성곱 신경망', '스마트 팩토리']","콘볼루션 신경망 기술의 발전이 영상 기반 품질 경영에서의 전처리 부담을 많이 줄여주는 의미가 있지만, 콘볼루션 신경망의 발전이 전처리 노력을 완전히 제거해주지는 못한다. 그러나, 조금만 훈련받으면 컴퓨터 비전 전문가가 아니더라도 영상 기반의 품질 관리를 할 수 있으며, 이에 기반하여 가변적인 생산체계에 빠르게 적응할 수 있다. 스마트 팩토리에서 자동화된 품질관리를 현실에서 실제 적용하는 것은, 이 방법론들을 이해하고, 이를 일부 구현하여 적용하거나, 통합적으로 구현하여 완전 자동화하는 형태로 진행된다. 이 논문은 스마트 팩토리 환경에서 자동화된 품질 검사를 위한 이미지 기반 품질 관리 기법들을 개관하고 현실에 이러한 기법을 실제 적용하는 데에서 나타나는 이슈와 전략에 대해 토론한다.","Although the development of convolutional neural network technology reduces a lot of preprocessing burden in image-based quality management, it does not completely eliminate the preprocessing effort. However, with a little training, even non-computer vision specialists can perform image-based quality management, which allows them to quickly adapt to variable manufacturing systems. The actual application of automated quality control at the smart factory in the real world is based on understanding, implementing, and integrating these methodologies. This paper provides an overview of image-based quality management techniques for automated quality inspection in a smart factory environment and discusses the issues and strategies of applying these techniques in practice."
Design Characteristics of Studies Reporting the Performance of Artificial Intelligence Algorithms for Diagnostic Analysis of Medical Images: Results from Recently Published Papers,2019,"['Artificial intelligence', 'Machine learning', 'Deep learning', 'Clinical validation', 'Clinical trial', 'Accuracy', 'Study design', 'Quality', 'Appropriateness', 'Systematic review', 'Meta-analysis']",,"<P><B>Objective</B></P><P>To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images.</P><P><B>Materials and Methods</B></P><P>PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journals.</P><P><B>Results</B></P><P>Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals.</P><P><B>Conclusion</B></P><P>Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms.</P>"
A novel CNN based security guaranteed image watermarking generation scenario for smart city applications,2019,"['Convolutional neural network', 'Image watermark', 'Generation scenario', 'Algorithm design', 'Smart cities']",,"<P><B>Abstract</B></P>  <P>The rise of machine learning increases the current computing capabilities and paves the way to novel disruptive applications. In the current era of big data, the application of image retrieval technology for large-scale data is a popular research area. To ensure the robustness and security of digital image watermarking, we propose a novel algorithm using synergetic neural networks. The algorithm first processes a meaningful gray watermark image, then embeds it as a watermark signal into the block Discrete Cosine Transform (DCT) component. The companion algorithm for detection and extraction of the watermark uses a cooperative neural network, where the suspected watermark signal is used as the input while the output consists in the result of the recognition process. The simulation experiments show that the algorithm can complete certain image processing operations with improved performance, not only simultaneously completing watermark detection and extraction, but also efficiently determining the watermark attribution. Compared with other state-of-the-art models, the proposed model obtains an optimal Peak Signal-to-noise ratio (PSNR).</P>"
Simultaneous Localization and Mapping in the Epoch of Semantics: A Survey,2019,"['Bundle adjustment', 'deep learning', 'pose graph optimization', 'semantics', 'SLAM']",,"Simultaneous Localization and Mapping (SLAM) with an astonishing research history of over threedecades has brought the concept to the door step of truly autonomous robotic systems. The concept has advancedbeyond the map building and self-localization of robot on the map. On the other hand, the long-standing challengespertaining to the provision of out of the box solution for range of conditions still needs to be addressed. However, thetechnological advancements in the area is steadily making its ways into industry. This paper surveys state-of-the-artSLAM and discuss the insights of existing methods. Starting with a classical definition of SLAM, a brief conceptualoverview, and formulation of a standard SLAM system is carried out. While discussing the auxiliaries for solvingSLAM, the influx of machine learning into SLAM is also addressed. Moreover, recent SLAM algorithms havebeen reviewed with a focus on emerging concept of semantics to augment the system. In this paper a taxonomyof recently developed SLAM algorithms with a detailed comparison metrics, is presented. Furthermore, openchallenges, future directions and emerging research issues have also been laid down."
실생활 사용을 위한 뇌-컴퓨터 인터페이스 연구동향,2019,"['brain-computer interface', 'brain-machine interface', 'intention prediction', 'brain signal analysis', 'machine learning']",,"In recent decades, brain-computer interfaces (BCIs) have been an active area of study. BCI is a technology designed to predict the user’s intention by analyzing brain signals and to control a computer according to that predicted intention. Using BCI technology, patients with limb paralysis can perform various actions such as moving, expressing thoughts, drinking water, and so on. Moreover, the technology is also useful for healthy subjects because it allows them to control various electrical devices without physical movements. In this paper, the representative principles of BCIs are summarized, including slow cortical potentials, sensorimotor rhythms, P300, steady-state visually evoked potential, and directional tuning. Moreover, novel BCI studies are introduced. The convergence of these BCI methods will enable the development of BCIs that can be used in real life."
Anthropomorphic Animal Face Masking using Deep Convolutional Neural Network based Animal Face Classification,2019,"['Animal Face Classification', 'Machine Learning', 'Deep Learning', 'Anthropomorphism', 'Morphism', 'Viola-Jones Algorithm', 'Artificial Neural Network']",,"Anthropomorphism is the attribution of human traits, emotions, or intentions to non-human entities. Anthropomorphic animal face masking is the process by which human characteristics are plotted on the animal kind. In this research, we are proposing a compact system which finds the resemblance between a human face and animal face using Deep Convolutional Neural Network (DCNN) and later applies morphism between them. The whole process is done by firstly finding which animal most resembles the particular human face through a DCNN based animal face classification. And secondly, doing triangulation based morphing between the particular human face and the most resembled animal face. Compared to the conventional manual Control Point Selection system using an animator, we are proposing a Viola-Jones algorithm based Control Point selection process which detects facial features for the human face and takes the Control Points automatically. To initiate our approach, we built our own dataset containing ten thousand animal faces and a fourteen layer DCNN. The simulation results firstly demonstrate that the accuracy of our proposed DCNN architecture outperforms the related methods for the animal face classification. Secondly, the proposed morphing method manages to complete the morphing process with less deformation and without any human assistance."
엔지니어링 서비스 지원을 위한 클라우드 기반 빅데이터 플랫폼 개발 연구,2019,"['빅데이터', '엔지니어링', '오픈소스', '머신러닝', 'Big Data', 'Engineering', 'Open Source', 'Machine Learning']","본 연구는 엔지니어링 분야에서 생성되는 대용량의 빅데이터를 효율적으로 저장, 관리, 분석하는 클라우드 기반 빅데이터 플랫폼을 제안하고자 한다. 클라우드 기반 빅데이터 플랫폼은 HPC 클라우드 환경, 엔지니어링 빅데이터 분석 플랫폼, 데이터 수집 및 처리 모듈, 인공지능 기반 분석 라이브러리, 응용서비스로 구성된다.이를 통해 데이터 분석에 대한 전문지식이 없는 엔지니어링 전문가가 IoT 빅데이터를 수집 및 분석함으로써 산업적으로 활용이 가능하다. 마지막으로 응용서비스에서는 빅데이터 플랫폼 적용 사례를 제시하기 위해 하수처리플랜트 데이터를 이용하여 서비스를 구현하였다.",
Feature Extraction based on DBN-SVM for Tone Recognition,2019,"['Deep Belief Networks', 'Deep Learning', 'Feature Fusion', 'Support Vector Machine', 'Tone Feature Extraction']",,"An innovative tone modeling framework based on deep neural networks in tone recognition was proposed inthis paper. In the framework, both the prosodic features and the articulatory features were firstly extracted asthe raw input data. Then, a 5-layer-deep deep belief network was presented to obtain high-level tone features.Finally, support vector machine was trained to recognize tones. The 863-data corpus had been applied inexperiments, and the results show that the proposed method helped improve the recognition accuracysignificantly for all tone patterns. Meanwhile, the average tone recognition rate reached 83.03%, which is 8.61%higher than that of the original method."
장단기메모리 기반 에너지 효율적 다중 기지국 대용량 안테나 시스템,2019,"['Massive MIMO', 'Multiple basestations', 'Machine learning', 'Long Short-Term Memory', 'Energy efficiency']",,
신경망을 이용한 소프트웨어 취약 여부 예측 시스템,2019,"['Artificial Intelligence', 'Neural Network', 'Machine Learning', 'Fuzzing', 'Software Vulnerability']","소프트웨어의 증가에 따라 소프트웨어의 취약점도 함께 증가하고 있다. 다양한 소프트웨어는 다수의 취약점이 존재할 수 있으며 취약점을 통해 많은 피해를 받을 수 있기 때문에 빠르게 탐지하여 제거해야 한다. 현재 소프트웨어의취약점을 발견하기 위해 다양한 연구가 진행되고 있지만, 수행 속도가 느리거나 예측 정확도가 높지 않다. 따라서 본논문에서는 신경망 알고리즘을 이용하여 소프트웨어의 취약 여부를 효율적으로 예측하는 방법을 제안하며 나아가 기계학습 알고리즘을 이용한 기존의 시스템과 예측 정확도를 비교한다. 실험 결과 본 논문에서 제안하는 예측 시스템이가장 높은 예측률을 보였다.","As the number and type of software increases, those security vulnerabilities are also increasing. Various types of softwaremay have multiple vulnerabilities and those vulnerabilities as they can cause irrecoverable significant damage must bedetected and deleted quickly. Various studies have been carried out to detect the vulnerability of the current software, but itis slow, and prediction accuracy is low. Therefore, in this paper, we describe a method to efficiently predict softwarevulnerability by using neural network algorithm and compare prediction accuracy with conventional system using machinelearning algorithm. As a result of the experiment, the prediction system proposed in this paper showed the highest predictionrate."
Raspberry Pi assisted facial expression recognition framework for smart security in law-enforcement services,2019,"['Facial expression analysis', 'Machine learning', 'Smart security', 'Suspicious activity recognition', 'Smart cities']",,"<P><B>Abstract</B></P>  <P>Facial expression recognition is an active research area for which the research community has presented a number of approaches due to its diverse applicability in different real-world situations such as real-time suspicious activity recognition for smart security, monitoring, marketing, and group sentiment analysis. However, developing a robust application with high accuracy is still a challenging task mainly due to the inherent problems related to human emotions, lack of sufficient data, and computational complexity. In this paper, we propose a novel, cost-effective, and energy-efficient framework designed for suspicious activity recognition based on facial expression analysis for smart security in law-enforcement services. The Raspberry Pi camera captures the video stream and detects faces using the Viola Jones algorithm. The face region is pre-processed using Gabor filter and median filter prior to feature extraction. Oriented FAST and Rotated BRIEF (ORB) features are then extracted and the support vector machine (SVM) classifier is trained, which predicts the known emotions (Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise). Based on the collective emotions of the faces, we predict the sentiment behind the scene. Using this approach, we predict if a certain situation is hostile and can prevent it prior to its occurrence. The system is tested on three publically available datasets: Cohen Kande (CK+), MMI, and JAFEE. A detailed comparative analysis based on SURF, SIFT, and ORB is also presented. Experimental results verify the efficiency and effectiveness of the proposed system in accurate recognition of suspicious activity compared to state-of-the-art methods and validate its superiority for enhancing security in law enforcement services.</P>"
"Detonation cell size model based on deep neural network for hydrogen, methane and propane mixtures with air and oxygen",2019,"['Detonation', 'Cell size model', 'Machine learning', 'Artificial neural network']",,"The aim of the present study was to develop model for detonation cell sizes prediction based on a deepartificial neural network of hydrogen, methane and propane mixtures with air and oxygen. The discussionabout the currently available algorithms compared existing solutions and resulted in a conclusionthat there is a need for a new model, free from uncertainty of the effective activation energy and thereaction length definitions. The model offers a better and more feasible alternative to the existing ones.Resulting predictions were validated against experimental data obtained during the investigation ofdetonation parameters, as well as with data collected from the literature. Additionally, separate modelsfor individual mixtures were created and compared with the main model. The comparison showed nodrawbacks caused by fitting one model to many mixtures. Moreover, it was demonstrated that the modelmay be easily extended by including more independent variables. As an example, dependency onpressure was examined. The preparation of experimental data for deep neural network training wasdescribed in detail to allow reproducing the results obtained and extending the model to differentmixtures and initial conditions. The source code of ready to use models is also provided"
약물 관련 정보를 이용한 약물 부작용 예측,2019,"['side effect prediction', 'indication', 'machine learning', 'systems biology']",,
심층 신경망을 이용한 대기질 예측,2019,"['Deep neural network model', 'Machine learning', 'TensorFlow', 'Air quality model', 'Numerical model', 'National air quality monitoring station']",,"A deep neural network (DNN) model of multi-layer perceptron with 3 or 4 hidden layers is developed to predict the air qualities. The DNN model takes the past 3 days of the hourly concentration measurements of the pollutants (CO, SO2, NO2, O3, PM10, PM2.5) and the meteorology data (wind speed, wind direction, air temperature, air humidity), and then predicts the hourly concentration of the pollutants for the next 24 hours. The DNN model was compared against the observations from all nationwide air quality monitoring stations which includes 115 sites in 7 metropolitan cities in South Korea. The index of agreement (IOA) was found to be 0.7~0.8, based upon the 6,505 comparison data sets from January 1, 2017 to September 30, 2017. In the unit of air quality grade, which can be evaluated from the pollutant concentration level, 60%～80% cases of the DNN predictions agree with those of the observations. For the region-wide PM10 grade, the DNN predicts exactly the 75%～85% cases of the observations, which is in about the same accuracy range of the numerical air quality models of the current operative use. Yet, for the region-wide PM2.5 grade, the cases of the accurate predictions of DNN is about twice of those of the numerical model. In the metropolitan Gwangju, for an example, the DNN predicts exactly the 211 next days of the PM2.5 grade, while the numerical model forecasts just 120 days correctly."
네트워크 프로토콜에 대한 역공학을 통한 상태추론,2019,"['Protocol', 'Reverse Engineering', 'Machine Learning']",,
혼성 표본 추출과 적층 딥 네트워크에 기반한 은행 텔레마케팅 고객 예측 방법,2019,"['Bank Telemarketing', 'Deep Learning', 'Stacked Networks', 'Class Imbalance']",,"Telemarketing has been used in finance due to the reduction of offline channels. In order to select telemarketing target customers, various machine learning techniques have emerged to maximize the effect of minimum cost. However, there are problems that the class imbalance, which the number of marketing success customers is smaller than the number of failed customers, and the recall rate is lower than accuracy. In this paper, we propose a method that solve the imbalanced class problem and increase the recall rate to improve the efficiency. The hybrid sampling method is applied to balance the data in the class, and the stacked deep network is applied to improve the recall and precision as well as the accuracy. The proposed method is applied to actual bank telemarketing data. As a result of the comparison experiment, the accuracy, the recall, and the precision is improved higher than that of the conventional methods."
Reproducibility and Generalizability in Radiomics Modeling: Possible Strategies in Radiologic and Statistical Perspectives,2019,"['Radiomics', 'Reproducibility', 'Generalizability', 'Machine learning']",,"Radiomics, which involves the use of high-dimensional quantitative imaging features for predictive purposes, is a powerful tool for developing and testing medical hypotheses. Radiologic and statistical challenges in radiomics include those related to the reproducibility of imaging data, control of overfitting due to high dimensionality, and the generalizability of modeling. The aims of this review article are to clarify the distinctions between radiomics features and other omics and imaging data, to describe the challenges and potential strategies in reproducibility and feature selection, and to reveal the epidemiological background of modeling, thereby facilitating and promoting more reproducible and generalizable radiomics research."
"미세먼지, 악취 농도 예측을 위한 앙상블 방법",2019,"['Particulate Matter', 'Odor', 'Machine Learning', 'Ensemble', 'Prediction']",,"Recently, a number of researchers have produced research and reports in order to forecast more exactly air quality such as particulate matter and odor. However, such research mainly focuses on the atmospheric diffusion models that have been used for the air quality prediction in environmental engineering area. Even though it has various merits, it has some limitation in that it uses very limited spatial attributes such as geographical attributes. Thus, we propose the new approach to forecast an air quality using a deep learning based ensemble model combining temporal and spatial predictor. The temporal predictor employs the RNN LSTM and the spatial predictor is based on the geographically weighted regression model. The ensemble model also uses the RNN LSTM that combines two models with stacking structure. The ensemble model is capable of inferring the air quality of the areas without air quality monitoring station, and even forecasting future air quality. We installed the IoT sensors measuring PM2.5, PM10, H2S, NH3, VOC at the 8 stations in Jeonju in order to gather air quality data. The numerical results showed that our new model has very exact prediction capability with comparison to the real measured data. It implies that the spatial attributes should be considered to more exact air quality prediction."
Application of power spectral density function for damage diagnosis of bridge piers,2019,"['moment-rotation', 'forecasting', 'extreme learning machine', 'precast beam-to-column connection', 'partly hidden corbel']",,"During the last two decades, much joint research regarding vibration based methods has been done, leading to developing various algorithms and techniques. These algorithms and techniques can be divided into modal methods and signal methods. Although modal methods have been widely used for health monitoring and damage detection, signal methods due to higher efficiency have received considerable attention in various fields, including aerospace, mechanical and civil engineering. Signal-based methods are derived directly from the recorded responses through signal processing algorithms to detect damage. According to different signal processing techniques, signal-based methods can be divided into three categories including time domain methods, frequency domain methods, and time-frequency domain methods. The frequency domain methods are well-known and interest in using them has increased in recent years. To determine dynamic behaviours, to identify systems and to detect damages of bridges, different methods and algorithms have been proposed by researchers. In this study, a new algorithm to detect seismic damage in the bridge’s piers is suggested. To evaluate the algorithm, an analytical model of a bridge with simple spans is used. Based on the algorithm, before and after damage, the bridge is excited by a sine force, and the piers’ responses are measured. The dynamic specifications of the bridge are extracted by Power Spectral Density function. In addition, the Least Square Method is used to detect damage in the bridge’s piers. The results indicate that the proposed algorithm can identify the seismic damage effectively. The algorithm is output-only method and measuring the excitation force is not needed. Moreover, the proposed approach does not need numerical models."
A review of computational drug repurposing,2019,"['Computational drug repurposing', 'Deep learning', 'Drug repositioning', 'Machine learning', 'Text mining']",,"Although sciences and technology have progressed rapidly, de novo drug development has been a costly and time-consuming process over the past decades. In view of these circumstances, ‘drug repurposing’ (or ‘drug repositioning’) has appeared as an alternative tool to accelerate drug development process by seeking new indications for already approved drugs rather than discovering de novo drug compounds, nowadays accounting for 30% of newly marked drugs in the U.S. In the meantime, the explosive and large-scale growth of molecular, genomic and phenotypic data of pharmacological compounds is enabling the development of new area of drug repurposing called computational drug repurposing. This review provides an overview of recent progress in the area of computational drug repurposing. First, it summarizes available repositioning strategies, followed by computational methods commonly used. Then, it describes validation techniques for repurposing studies. Finally, it concludes by discussing the remaining challenges in computational repurposing."
Anthropomorphic Animal Face Masking using Deep Convolutional Neural Network based Animal Face Classification,2019,"['Animal Face Classification', 'Machine Learning', 'Deep Learning', 'Anthropomorphism', 'Morphism', 'Viola-Jones Algorithm', 'Artificial Neural Network']",,
Feature Extraction Based on DBN-SVM for Tone Recognition,2019,"['Deep Belief Networks', 'Deep Learning', 'Feature Fusion', 'Support Vector Machine', 'Tone Feature Extraction']",,"An innovative tone modeling framework based on deep neural networks in tone recognition was proposed in this paper. In the framework, both the prosodic features and the articulatory features were firstly extracted as the raw input data. Then, a 5-layer-deep deep belief network was presented to obtain high-level tone features. Finally, support vector machine was trained to recognize tones. The 863-data corpus had been applied in experiments, and the results show that the proposed method helped improve the recognition accuracy significantly for all tone patterns. Meanwhile, the average tone recognition rate reached 83.03%, which is 8.61% higher than that of the original method."
Anthropomorphic Animal Face Masking using Deep Convolutional Neural Network based Animal Face Classification,2019,"['Animal Face Classification', 'Machine Learning', 'Deep Learning', 'Anthropomorphism', 'Morphism', 'Viola-Jones Algorithm', 'Artificial Neural Network.']",,"Anthropomorphism is the attribution of human traits, emotions, or intentions to non-human entities. Anthropomorphic animal face masking is the process by which human characteristics are plotted on the animal kind. In this research, we are proposing a compact system which finds the resemblance between a human face and animal face using Deep Convolutional Neural Network (DCNN) and later applies morphism between them. The whole process is done by firstly finding which animal most resembles the particular human face through a DCNN based animal face classification. And secondly, doing triangulation based morphing between the particular human face and the most resembled animal face. Compared to the conventional manual Control Point Selection system using an animator, we are proposing a Viola-Jones algorithm based Control Point selection process which detects facial features for the human face and takes the Control Points automatically. To initiate our approach, we built our own dataset containing ten thousand animal faces and a fourteen layer DCNN. The simulation results firstly demonstrate that the accuracy of our proposed DCNN architecture outperforms the related methods for the animal face classification. Secondly, the proposed morphing method manages to complete the morphing process with less deformation and without any human assistance."
정보 소득율 기반의 변수 선택을 통한 영화 관객 수 예측,2019,"['Information Gain Ratio', 'Machine Learning', 'Movie Audiences']",,"In this study, we propose a methodology for predicting the movie audience based on movie information that can be easily acquired before opening and effectively distinguishing qualitative variables. In addition, we constructed a model to estimate the number of movie audiences at the time of data acquisition through the configured variables. Another purpose of this study is to provide a criterion for categorizing success of movies with qualitative characteristics. As an evaluation criterion, we used information gain ratio which is the node selection criterion of C4.5 algorithm. Through the procedure we have selected 416 movie data features. As a result of the multiple linear regression model, the performance of the regression model using the variables selection method based on the information gain ratio was excellent."
기댓값 최대화 알고리즘을 적용한 네트워크 임베딩 기반 링크 예측,2019,"['AUC', 'Expectation maximization (EM) algorithm', 'Link prediction', 'Machine learning', 'Network embedding']",,
Volumetric-Modulated Arc Radiotherapy Using Knowledge-Based Planning: Application to Spine Stereotactic Body Radiotherapy,2019,"['Radiotherapy', 'Intensity-modulated', 'Radiotherapy planning', 'computer-assisted', 'Machine learning', 'Radiosurgery']",,"Purpose: To evaluate the clinical feasibility of knowledge-based planning (KBP) for volumetricmodulated arc radiotherapy (VMAT) in spine stereotactic body radiotherapy (SBRT).Methods: Forty-eight VMAT plans for spine SBRT was studied. Two planning target volumes (PTVs) were defined for simultaneous integrated boost: PTV for boost (PTV-B: 27 Gy/3fractions) and PTV elective (PTV-E: 24 Gy/3fractions). The expert VMAT plans were manually generated by experienced planners. Twenty-six plans were used to train the KBP model using Varian RapidPlan.With the trained KBP model each KBP plan was automatically generated by an individual with little experience and compared with the expert plan (closed-loop validation). Twenty-two plans that had not been used for KBP model training were also compared with the KBP results (open-loop validation).Results: Although the minimal dose of PTV-B and PTV-E was lower and the maximal dose was higher than those of the expert plan, the difference was no larger than 0.7 Gy. In the closed-loop validation, D1.2cc, D0.35cc, and Dmean of the spinal cord was decreased by 0.9 Gy, 0.6 Gy, and 0.9 Gy, respectively, in the KBP plans (P<0.05). In the open-loop validation, only Dmean of the spinal cord was significantly decreased, by 0.5 Gy (P<0.05).Conclusions: The dose coverage and uniformity for PTV was slightly worse in the KBP for spine SBRT while the dose to the spinal cord was reduced, but the differences were small. Thus, inexperienced planners could easily generate a clinically feasible plan for spine SBRT by using KBP."
미니트램의 자율 주행을 위한 시스템 개발,2019,"['mini-tram', 'autonomous driving', 'navigation', 'localization', 'recognition', 'machine learning']",,"This article describes a system development for autonomous driving of mini-tram and its experimental results on outdoor autonomous driving. The mini-tram was provided by KRRI (Korea Railroad Research Institute). For the pose estimation, we fused an IMU and a GPS sensor using extended Kalman filter. We chose an NVIDIA Drive PX2 and LiDAR to recognize the outdoor environment. In order to verify the feasibility of the developed system, we performed outdoor autonomous driving experiments."
Prediction of Obstructive Sleep Apnea Based on Respiratory Sounds Recorded Between Sleep Onset and Sleep Offset,2019,"['Obstructive Sleep Apnea', 'Respiratory Sounds', 'Polysomnography', 'Machine Learning']",,"Objectives. To develop a simple algorithm for prescreening of obstructive sleep apnea (OSA) on the basis of respiratory sounds recorded during polysomnography during all sleep stages between sleep onset and offset.Methods. Patients who underwent attended, in-laboratory, full-night polysomnography were included. For all patients, audio recordings were performed with an air-conduction microphone during polysomnography. Analyses included all sleep stages (i.e., N1, N2, N3, rapid eye movement, and waking). After noise reduction preprocessing, data were segmented into 5-s windows and sound features were extracted. Prediction models were established and validated with 10-fold cross-validation by using simple logistic regression. Binary classifications were separately conducted for three different threshold criteria at apnea hypopnea index (AHI) of 5, 15, or 30. Prediction model characteristics, including accuracy, sensitivity, specificity, positive predictive value (precision), negative predictive value, and area under the curve (AUC) of the receiver operating characteristic were computed.Results. A total of 116 subjects were included; their mean age, body mass index, and AHI were 50.4 years, 25.5 kg/m2, and 23.0/hr, respectively. A total of 508 sound features were extracted from respiratory sounds recorded throughout sleep. Accuracies of binary classifiers at AHIs of 5, 15, and 30 were 82.7%, 84.4%, and 85.3%, respectively. Prediction performances for the classifiers at AHIs of 5, 15, and 30 were AUC, 0.83, 0.901, and 0.91; sensitivity, 87.5%, 81.6%, and 60%; and specificity, 67.8%, 87.5%, and 94.1%. Respective precision values of the classifiers were 89.5%, 87.5%, and 78.2% for AHIs of 5, 15, and 30.Conclusion. This study showed that our binary classifier predicted patients with AHI of ≥15 with sensitivity and specificity of >80% by using respiratory sounds during sleep. Since our prediction model included all sleep stage data, algorithms based on respiratory sounds may have a high value for prescreening OSA with mobile devices."
GPS 재밍탐지를 위한 기계학습 적용 및 성능 분석,2019,"['GPS Jamming', 'Multiple GPS Receiver', 'Machine Learning', 'Adaptive Boosting', 'Support Vector Machine', 'Decision Tree', 'kNN']",,
Deciphering Monetary Policy Board Minutes with Text Mining: The Case of South Korea,2019,"['Monetary Policy', 'Text Mining', 'Taylor Rule', 'Machine Learning', 'Bank of Korea']",,"We quantify the Monetary Policy Board minutes of the Bank of Korea (BOK) by using text mining. We propose a novel approach that uses a field-specific Korean dictionary and contiguous sequences of words (n-grams) to capture the subtlety of central bank communications. Our text-based indicator helps explain the current and future BOK monetary policy decisions when considering an augmented Taylor rule, suggesting that it contains additional information beyond the currently available macroeconomic variables.In explaining the current and future monetary policy decisions, our indicator remarkably outperforms English-based textual classifications, a media-based measure of economic policy uncertainty, and a data-based measure of macroeconomic uncertainty. Our empirical results also emphasize the importance of using a field-specific dictionary and the original Korean text."
The Effect of Bias in Data Set for Conceptual Clustering Algorithms,2019,"['COBWEB model', 'Data ordering', 'Clustering', 'Conceptual learning', 'Bias problem']",,"When a partitioned structure is derived from a data set using a clustering algorithm, it is not unusual to have a different set of outcomes when it runs with a different order of data. This problem is known as the order bias problem. Many algorithms in machine learning fields try to achieve optimized result from available training and test data. Optimization is determined by an evaluation function which has also a tendency toward a certain goal. It is inevitable to have a tendency in the evaluation function both for efficiency and for consistency in the result. But its preference for a specific goal in the evaluation function may sometimes lead to unfavorable consequences in the final result of the clustering. To overcome this bias problems, the first clustering process proceeds to construct an initial partition. The initial partition is expected to imply the possible range in the number of final clusters. We apply the data centric sorting to the data objects in the clusters of the partition to rearrange them in a new order. The same clustering procedure is reapplied to the newly arranged data set to build a new partition. We have developed an algorithm that reduces bias effect resulting from how data is fed into the algorithm. Experiment results have been presented to show that the algorithm helps minimize the order bias effects. We have also shown that the current evaluation measure used for the clustering algorithm is biased toward favoring a smaller number of clusters and a larger size of clusters as a result."
Spreadsheet Calculators for Stability Number of Armor Units Based on Artificial Neural Network Models,2019,"['armor unit', 'artificial neural network', 'machine learning', 'spreadsheet calculator', 'stability number']",,"Since Van der Meer proposed new empirical formulas to calculate the stability number of rock armor based on his own experimental data in 1987, the data have also been used for the development of artificial neural network (ANN) models. However, the ANN models are seldom used because they are not easy to verify in spite of high accuracy. In this study, an accurate easy-to-use ANN-based model is developed. The stability number is calculated by ensemble-averaging the outputs of 500 ANN models which were developed with different training data. The accuracy of the model is markedly improved compared with previous empirical formulas or ANN models. A spreadsheet calculator is also provided so that it can be easily used by engineers without a deep knowledge of ANN. It calculates the stability number by using the pre-determined weights and biases of the 500 ANN models. The confidence intervals of several confidence levels are also calculated by the standard deviation or the quantiles of the 500 model outputs. A similar model is developed for Tetrapod as well."
기계학습을 이용한 스마트폰 이용이 보행속도에 미치는 영향 분석,2019,"['기계학습', '의사결정나무', '다중회귀분석', '스마트폰', '보행속도', 'Machine Learning', 'Decision tree', 'Multiple regression', 'Smartphone', 'Walking speed']",,
User Modeling Using User Preference and User Life Pattern Based on Personal Bio Data and SNS Data,2019,"['Bio Data', 'Data Tracking', 'Life Pattern', 'Machine Learning', 'Social Behavior Analysis', 'User Modeling']",,"The purpose of this study was to collect and analyze personal bio data and social network services (SNS) data, derive user preference and user life pattern, and propose intuitive and precise user modeling. This study not only tried to conduct eye tracking experiments using various smart devices to be the ground of the recommendation system considering the attribute of smart devices, but also derived classification preference by analyzing eye tracking data of collected bio data and SNS data. In addition, this study intended to combine and analyze preference of the common classification of the two types of data, derive final preference by each smart device, and based on user life pattern extracted from final preference and collected bio data (amount of activity, sleep), draw the similarity between users using Pearson correlation coefficient. Through derivation of preference considering the attribute of smart devices, it could be found that users would be influenced by smart devices. With user modeling using user behavior pattern, eye tracking, and user preference, this study tried to contribute to the research on the recommendation system that should precisely reflect user tendency."
조정절차에서 인공지능(AI)을 활용하는 방안,2019,"['communication intelligence', 'Mediation', 'ODR(Online Dispute Resolution)', 'Machine Learning', 'Automating Mediation.', '대화지능', '조정', '온라인 분쟁해결', '기계학습', '조정 자동화']","조정은 조정인이 당사자들간의 분쟁에 개입하여 언어 및 비언어적 의사소통방식을 적극 활용하여 천편일률적인 법적용으로 얻을 수 없는 창조적인 분쟁해결을 해 낸다는 점에 장점이 있다. 그 과정에서 조정인은 당사자들의 표면적인 언어나 몸짓의 뒷면에 숨어있는 맥락을 좀 더 깊이 이해할 수 있어야 한다. 조정절차에서 당사자들의 분쟁이 근본적으로 해소되는 경우는 많은 경우 당사자들을 설득시키는 조정인의 언변에 있기보다는 당사자들을 배려하고 그들이 진정으로 원하는 것을 찾아내어 당사자들이 스스로 깨닫게 하는 조정인의 진정성 있는 조정자세에 있기 때문이다. 이러한 조정인의 역량은 조정교육이나 조정경험을 통하여 증진되기도 한다. 그러나 조정인 스스로의 그 당시 마음상태와 당사자들의 태도나 자세에 분위기가 좌우될 수 있는 조정절차의 특성 때문에 조정합의가 실패로 돌아간 뒤 많은 조정인들이 후회를 하거나 심리적인 아픔을 겪기도 한다. 이 때 수많은 선배조정인들의 지혜를 모아서 그 사건에 도움이 될 수 있는 조언을 해주는 인공지능기술이나 인공지능의 지혜가 있다면 조정제도의 발전은 한 단계의 결정적인 도약을 할 수 있을 것이다. 조정은 재판과 달리 절차가 엄격하지 않으며 결과를 당사자들에게 강제하지 않는다는 점에서 재판에 비해 인공지능기술을 적용하기가 한결 수월하다. 서구에서 말하는 조정(mediation)에서는 최종 결론은 당사자들이 내리는 것으로, 재판처럼 법관이 일방적으로 심판을 하고 당사자들에게 강제하는 것이 아니기 때문이다. 이에 필자는 어느 절차보다 당사자들의 자율성이 중시되는 조정절차에서 먼저 인공지능기술을 적극 활용할 것을 제안한다. 초보적인 인공지능 기술만 활용해도 조정절차에서는 그 효용이 매우 클 것으로 생각되고 부작용은 크게 우려하지 않아도 될 것으로 판단되기 때문이다.","Mediation process have advantages that mediator could intervene each party’s disputes and use verbal and/or nonverbal communication to create voluntary and creative dispute resolution which is hard to get from the litigation process. In this process, the mediator need to understand more deeply in the hidden context of parties behind the party’s verbal language or gestures. In many cases, in the mediation process, mediator could persuade parties with sincere mediating attitudes rather than mediator's communication skills. Many nonverbal signals of parties could help mediator to find what they really want and mediator could also help the parties to realize themselves what they really want. The capacity of these mediatiors may be enhance their ability through mediation training and/or a lot of mediation experiences. However, many mediators regret or sometimes suffer psychological pain after the mediation agreement fails because of the nature of the mediation process, which could affect each other the mood and attitudes of the mediator and of the parties. At this case, in case there is artificial intelligence technology’s and/or intelligence wisdom’s help which gathered from the wisdom of many senior mediators, the development of the mediation skills could take a great leap. Mediation is easier to apply to AI skills than litigation in that the mediation process is not so strict and the mediation agreement is not forced on the parties. In the mediation, the mediation agreement is up to the parties voluntary. Therefore, I suggest how about using artificial intelligence technology in the mediation process first, where the parties' autonomy is indispensable. That’s because the use of entry level artificial intelligence technology also very useful in the mediation process and the side effects are not so greatly worried due to the characteristics of voluntary mediation agreement."
"[인공지능, 신경망 및 퍼지시스템] 인공지능 본인 인증에 의한 블록체인 기반 선거 시스템",2019,"['Block chain', 'Smart contract', 'Aritificial intelligence', 'Machine learning', 'Web']",,
The Effect of Bias in Data Set for Conceptual Clustering Algorithms,2019,"['COBWEB model', 'Data ordering', 'Clustering', 'Conceptual learning', 'Bias problem']",,"When a partitioned structure is derived from a data set using a clustering algorithm, it is not unusual to have a different set of outcomes when it runs with a different order of data. This problem is known as the order bias problem. Many algorithms in machine learning fields try to achieve optimized result from available training and test data. Optimization is determined by an evaluation function which has also a tendency toward a certain goal. It is inevitable to have a tendency in the evaluation function both for efficiency and for consistency in the result. But its preference for a specific goal in the evaluation function may sometimes lead to unfavorable consequences in the final result of the clustering. To overcome this bias problems, the first clustering process proceeds to construct an initial partition. The initial partition is expected to imply the possible range in the number of final clusters. We apply the data centric sorting to the data objects in the clusters of the partition to rearrange them in a new order. The same clustering procedure is reapplied to the newly arranged data set to build a new partition. We have developed an algorithm that reduces bias effect resulting from how data is fed into the algorithm. Experiment results have been presented to show that the algorithm helps minimize the order bias effects. We have also shown that the current evaluation measure used for the clustering algorithm is biased toward favoring a smaller number of clusters and a larger size of clusters as a result."
교정된 기계학습을 이용한 사용자 특화 제스처 인식 방법,2019,"['Calibrated random forest', 'Gesture recognition', 'Customizing algorithm', 'Machine learning']",,
다변량 시계열 자료를 이용한 부정맥 예측,2019,"['arrhythmia prediction', 'multivariate time series', '1-nearest neighbor', 'time series distance function', 'ventricular tachycardia', '부정맥예측', '다변량 시계열', '최근접이웃방법', '시계열 간 거리함수', '심실빈맥']",최근에 부정맥 환자가 증가하면서 머신러닝을 이용한 부정맥을 예측하는 연구가 활발하게 진행되고 있다. 기존의 많은 연구들은 특정한 시점의 RR 간격 데이터에서 추출한 특징변수 다변량 데이터에 기반하여 부정맥을 예측하였다. 본 연구에서는 심장 상태가 시간에 따라 변해가는 패턴도 부정맥 예측에 중요한 정보가 될 수 있다고 생각하여 일정한 시간 간격을 두고 특징변수의 다변량 벡터를 추출하여 쌓음으써 얻어지는 다변량 시계열 데이터로 부정맥을 예측하는 것의 유용성에 대해 살펴보았다. 1-Nearest Neighbor 방법과 그것을 앙상블(ensemble)한 learner를 중심으로 비교했을 경우 시계열의 특징을 고려한 적절한 시계열 거리함수를 선택하여 시계열 정보를 활용한 다변량 시계열 데이터 기반 방법의 분류 성능이 더 좋게 나오는 것을 확인하였다.,"Studies on predicting arrhythmia using machine learning have been actively conducted with increasing number of arrhythmia patients. Existing studies have predicted arrhythmia based on multivariate data of feature variables extracted from RR interval data at a specific time point. In this study, we consider that the pattern of the heart state changes with time can be important information for the arrhythmia prediction. Therefore, we investigate the usefulness of predicting the arrhythmia with multivariate time series data obtained by extracting and accumulating the multivariate vectors of the feature variables at various time points. When considering 1-nearest neighbor classification method and its ensemble for comparison, it is confirmed that the multivariate time series data based method can have better classification performance than the multivariate data based method if we select an appropriate time series distance function."
The Effect of Bias in Data Set for Conceptual Clustering Algorithms,2019,"['COBWEB model', 'Data ordering', 'Clustering', 'Conceptual learning', 'Bias problem']",,"When a partitioned structure is derived from a data set using a clustering algorithm, it is not unusual to have a different set of outcomes when it runs with a different order of data. This problem is known as the order bias problem. Many algorithms in machine learning fields try to achieve optimized result from available training and test data. Optimization is determined by an evaluation function which has also a tendency toward a certain goal. It is inevitable to have a tendency in the evaluation function both for efficiency and for consistency in the result. But its preference for a specific goal in the evaluation function may sometimes lead to unfavorable consequences in the final result of the clustering. To overcome this bias problems, the first clustering process proceeds to construct an initial partition. The initial partition is expected to imply the possible range in the number of final clusters. We apply the data centric sorting to the data objects in the clusters of the partition to rearrange them in a new order. The same clustering procedure is reapplied to the newly arranged data set to build a new partition. We have developed an algorithm that reduces bias effect resulting from how data is fed into the algorithm. Experiment results have been presented to show that the algorithm helps minimize the order bias effects. We have also shown that the current evaluation measure used for the clustering algorithm is biased toward favoring a smaller number of clusters and a larger size of clusters as a result."
인공 신경망과 웨이블릿 변환을 이용한 주가 지수 예측,2019,"['웨이블릿 변환', '주가 지수 예측', '인공 신경망', '시계열 분석', 'wavelet transform', 'forecasting stock market price', 'artificial neural network', 'time series analysis']","기계학습 기술과 인공신경망 기술의 발전과 함께 주식시장의 흐름을 예측하려는 연구가 다양하게 시도되어 왔다. 특히 영상, 음성 처리를 위한 인공신경망 기술들이 주식시장 예측에 도입되어 예측의 정확도를 향상시키고 있다. 본 논문에서는 KOSPI의 지수변화와 방향성을 예측하기 위해 추출한 기술적 지표를 웨이블릿 변환을 이용하여 고주파수부분과 저주파수부분으로 나누어 인공신경망에서 각각 독립적으로 학습하고 예측한 다음, 고주파수부분과 저주파수부분을 합하여 지수와 방향성을 최종 예측하였다. 인공신경망으로 합성곱신경망, Dual Path Network 그리고 LSTM을 사용하여 인공신경망 간의 성능비교와 웨이블릿 변환의 효용성을 분석하였다. 지수예측에서는 합성곱신경망이 MAPE 0.51%, 등락예측에서는 LSTM이 정확도 81.7%로 최적의 결과를 보였고, 웨이블릿 변환으로 향상된 성능은 지수 예측의 경우 평균 38%, 등락 예측의 경우 평균 25%를 얻어 웨이블릿 변환의 효용성을 확인하였다.","With advancements in technologies on machine learning and artificial neural network, various researches have attempted to predict the changes in the price of the stock market. The prediction accuracy has improved with adoption of new artificial neural network technologies that have been developed for image and voice signal processing. In the present work, the technical indices from KOSPI were decomposed for the prediction of index and movement direction of KOSPI into high-frequency part and low-frequency part using wavelet transform, then used to predict KOSPI independently by using artificial neural networks. For the final prediction, the prediction result of each frequency part was added. CNN, DPN, and LSTM were employed as artificial neural network; the performance of each model was compared and the efficiency of the wavelet transform of input variables was analyzed. CNN with 0.51% of MAPE for the index prediction and LSTM with 81.7% of accuracy for movement prediction showed the best performance among the three models. The efficiency of wavelet transform was confirmed with averaged 38% of the improved performance for the index prediction and averaged 25% of the improved performance for the movement prediction."
Faster R-CNN 기반의 관심영역 유사도를 이용한 후방접근차량 검출 연구,2019,"['Deep lerning', 'Faster r-cnn', 'Agricultural machine', 'Vehicle detection', 'Structure similarity']",본 논문에서는 농업 기계 시스템에서 사용하기 위한 딥러닝 알고리즘 기반의 프레임 내의 관심 영역 유사성을 이용한 새로운 후방 접근 차량 검출 알고리즘을 제안한다. 농업 기계 시스템은 후방에서 접근하는 차량만 검출해야 한다. 지나가는 자동차가 검출되면 혼란을 야기할 수 있다. 논문에서는 차량 검출을 위해 딥러닝에서 뛰어난 검출률을 나타내는 FasterR-CNN 모델을 사용하였다. 딥러닝은 뒤에서 접근하는 차량뿐만 아니라 지나가는 차량도 검출하므로 긍정오류 차량을 배제해야 한다. 본 논문에서 이를 해결하기 위해 검출된 프레임에서 관심 영역에 대한 유사성과 평균 에러를 피라미드 형태로 이용하여 접근하는 자동차만 검출하는 알고리즘을 제안하였다. 실험을 통하여 제안된 방법이 평균 98.8%의 높은 검출률을 나타내었다.,"In this paper, we propose a new algorithm to detect rear-approaching vehicle using the frame similarity of ROI(Regionof Interest) based on deep learning algorithm for use in agricultural machinery systems. Since the vehicle detectionsystem for agricultural machinery needs to detect only a vehicle approaching from the rear. we use Faster R-CNN modelthat shows excellent accuracy rate in deep learning for vehicle detection. And we proposed an algorithm that uses theframe similarity for ROI using constrained conditions. Experimental results show that the proposed method has adetection rate of 99.9% and reduced the false positive values."
User Modeling Using User Preference and User Life Pattern Based on Personal Bio Data and SNS Data,2019,"['Bio Data', 'Data Tracking', 'Life Pattern', 'Machine Learning', 'Social Behavior Analysis', 'User Modeling']",,"The purpose of this study was to collect and analyze personal bio data and social network services (SNS) data,derive user preference and user life pattern, and propose intuitive and precise user modeling. This study notonly tried to conduct eye tracking experiments using various smart devices to be the ground of therecommendation system considering the attribute of smart devices, but also derived classification preferenceby analyzing eye tracking data of collected bio data and SNS data. In addition, this study intended to combineand analyze preference of the common classification of the two types of data, derive final preference by eachsmart device, and based on user life pattern extracted from final preference and collected bio data (amount ofactivity, sleep), draw the similarity between users using Pearson correlation coefficient. Through derivation ofpreference considering the attribute of smart devices, it could be found that users would be influenced by smartdevices. With user modeling using user behavior pattern, eye tracking, and user preference, this study tried tocontribute to the research on the recommendation system that should precisely reflect user tendency."
RFM 다차원 분석 기법을 활용한 암시적 사용자 피드백 기반 협업 필터링 개선 연구,2019,"['Collaborative Filtering', 'Personalized Marketing', 'Recommendation System', 'Machine Learning', 'Demand forecast', '협업 필터링', '개인화상품추천', '추천시스템', '기계학습', '수요예측']","전자상거래 시장의 이용이 보편화 되며 고객들에게 좋은 품질의 물건을 어디서, 얼마나 합리적으로 구매할수 있는지가 중요해졌다. 이러한 구매 심리의 변화는 방대한 정보 속에서 오히려 고객들의 구매 의사결정을 어렵게 만드는 경향이 있다. 이때 추천 시스템은 고객의 구매 행동을 분석하여 정보 검색에 드는 비용을 줄이고만족도를 높이는 효과가 있다. 하지만 대부분 추천 시스템은 책이나 영화 등 동종 상품 분류 내에서만 추천이이뤄진다. 왜냐하면 추천 시스템은 특정 상품에 매긴 구매 평점 데이터를 기반으로 해당 상품 분류 내 유사한상품에 대한 구매 만족도를 추정하기 때문이다. 그밖에 추천 시스템에서 사용하는 구매 평점의 신뢰성에 대한문제도 제시되고 있으며 오프라인에선 평점 확보 자체가 어렵다. 이에 본 연구에서는 일련의 문제를 개선하기위해 RFM 다차원 분석 기법을 활용하여 기존에 사용하던 고객의 구매 평점을 객관적으로 대체할 수 있는 새로운 지표의 활용 가능성을 제안하는 바이다. 실제 기업의 구매 이력 데이터에 해당 지표를 적용해서 검증해본결과 높게는 약 55%에 해당하는 정확도를 기록했다. 이는 총 4,386종에 달하는 이종 상품들 중 한번도 이용해본 적 없는 상품을 추천한 결과이기 때문에 검증 결과는 상대적으로 높은 정확도와 활용가치를 의미한다. 그리고 본 연구는 오프라인의 다양한 상품데이터에서도 적용할 수 있는 범용적인 추천 시스템의 가능성을 시사한다. 향후 추가적인 데이터를 확보한다면 제안하는 추천 시스템의 정확도 향상도 기대할 수 있다.","The utilization of the e-commerce market has become a common life style in today. It has become important part to know where and how to make reasonable purchases of good quality products for customers. This change in purchase psychology tends to make it difficult for customers to make purchasing decisions in vast amounts of information. In this case, the recommendation system has the effect of reducing the cost of information retrieval and improving the satisfaction by analyzing the purchasing behavior of the customer. Amazon and Netflix are considered to be the well-known examples of sales marketing using the recommendation system. In the case of Amazon, 60% of the recommendation is made by purchasing goods, and 35% of the sales increase was achieved. Netflix, on the other hand, found that 75% of movie recommendations were made using services.This personalization technique is considered to be one of the key strategies for one-to-one marketing that can be useful in online markets where salespeople do not exist. Recommendation techniques that are mainly used in recommendation systems today include collaborative filtering and content-based filtering.Furthermore, hybrid techniques and association rules that use these techniques in combination are also being used in various fields. Of these, collaborative filtering recommendation techniques are the most popular today. Collaborative filtering is a method of recommending products preferred by neighbors who have similar preferences or purchasing behavior, based on the assumption that users who have exhibited similar tendencies in purchasing or evaluating products in the past will have a similar tendency to other products. However, most of the existed systems are recommended only within the same category of products such as books and movies. This is because the recommendation system estimates the purchase satisfaction about new item which have never been bought yet using customer's purchase rating points of a similar commodity based on the transaction data. In addition, there is a problem about the reliability of purchase ratings used in the recommendation system.Reliability of customer purchase ratings is causing serious problems. In particular, 'Compensatory Review' refers to the intentional manipulation of a customer purchase rating by a company intervention.In fact, Amazon has been hard-pressed for these ""compassionate reviews"" since 2016 and has worked hard to reduce false information and increase credibility. The survey showed that the average rating for products with 'Compensated Review' was higher than those without 'Compensation Review'. And it turns out that 'Compensatory Review' is about 12 times less likely to give the lowest rating, and about 4 times less likely to leave a critical opinion. As such, customer purchase ratings are full of various noises. This problem is directly related to the performance of recommendation systems aimed at maximizing profits by attracting highly satisfied customers in most e-commerce transactions.In this study, we propose the possibility of using new indicators that can objectively substitute existing customer 's purchase ratings by using RFM multi-dimensional analysis technique to solve a series of problems. RFM multi-dimensional analysis technique is the most widely used analytical method in customer relationship management marketing(CRM), and is a data analysis method for selecting customers who are likely to purchase goods.As a result of verifying the actual purchase history data using the relevant index, the accuracy was as high as about 55%. This is a result of recommending a total of 4,386 different types of products that have never been bought before, thus the verification result means relatively high accuracy and utilization value. And this study suggests the possibility of general recommendation system that can be applied to various offline product data. If additional data is acquired in the future, the accuracy of..."
비전 기반 측위 보조 알고리즘의 성능 분석,2019,"['Vehicle Positioning', 'Extended Kalman Filter', 'Stereo Vision', 'Machine Learning', '자동차 측위', '확장형 칼만필터', '스테레오 비전', '머신 러닝']","최근 컴퓨터 처리 속도의 향상과 영상 처리 기술의 발달로 인해 카메라에서 획득하는 정보를 기존의 GNSS (Global Navigation Satellite System), 추측 항법 기반의 측위 기술과 결합하여 안정적인 위치를 결정하기 위한 연구가 활발히 진행 중이다. 기존 연구에서는 단안 카메라를 이용한 연구가 주로 수행되었으나 이 경우 관심 객체의 절대좌표가 구축이 되어 있어야 한다는 한계점이 있다. 이러한 한계를 극복하기 위해 본 연구에서는 스테레오 영상으로부터 삼각측량법을 적용하여 카메라와 관심 객체간 거리를 추정하는 비전 기반 측위 보조 알고리즘을 개발하고 성능 분석을 수행하였다. 또한, 추정된 거리와 카메라 영상 획득 간격을 이용해 상대적인 속도를 계산하고 이를 기존에 개발된 GNSS/이동체 내부 센서 기반 측위 알고리즘과 결합하여 통합 측위 알고리즘을 구현하였다. 실제 주행 자료를 기반으로 통합측위 알고리즘에 대한 성능을 분석한 결과 기존에 개발된 GNSS/이동체 내부 센서 기반 측위 알고리즘에 비해 속도 정보를 항법해 보정에 활용하였을 때 약 4%의 미미한 위치 정확도 향상 효과를 확인하였다. 이는 영상으로부터 추정된 속도 정보의 정밀도가 낮고, 터널 등을 지날 때는 영상으로부터 적절한 정보를 추출할 수 없다는 한계가 있어 이를 보완한 추가 연구가 필요하다고 판단된다.","Due to recent improvements in computer processing speed and image processing technology, researches are being actively carried out to combine information from camera with existing GNSS (Global Navigation Satellite System) and dead reckoning. In this study, developed a vision-based positioning assistant algorithm to estimate the distance to the object from stereo images. In addition, GNSS/on-board vehicle sensor/vision based positioning algorithm is developed by combining vision based positioning algorithm with existing positioning algorithm. For the performance analysis, the velocity calculated from the actual driving test was used for the navigation solution correction, simulation tests were performed to analyse the effects of velocity precision. As a result of analysis, it is confirmed that about 4% of position accuracy is improved when vision information is added compared to existing GNSS/on-board based positioning algorithm."
기상위성을 이용한 태양광발전 일사량 예측,2019,"['Python', 'CNN(Convolutional Neural Network)', 'Deep Learning Technique', 'Solar power generation']",,"Recently, due to the depletion of fossil fuel resources and the regulation of CO2 emissions, attention and demand for solar power generation are increasing. The solar power generation has begun to be applied to small-scale power generation, and recently, large- scale power plants have been built and sold to utility companies or power demand has been supplied to cities. In addition, facilities for microgrid for energy self-reliance through renewable energy such as solar power, wind power, and tidal power are being constructed and studied in places where electricity supply is difficult, such as island or inland countryside. The solar power generation is advantageous in that it has no pollution, is easy to maintain, and has a long life. However, the power generation depends on the weather, the installation site is limited, and the initial investment cost and the power generation cost are high. Particularly, since it depends on the weather condition, the generation amount is very intermittent and it is difficult to adjust the power generation amount, and it is difficult to establish a power generation plan in advance. Therefore, high accuracy solar power generation forecasting is essential to reduce the uncertainty of solar power generation and to improve the economical efficiency of solar power generation. Existing solar power generation forecasting has been conducted to predict power generation using Extreme Learning Machine (ELM), Support Vector Regression (SVR), and neural network. However, in this paper, we forecast the solar power generation using the meteorological satellite data from 2011 to 2017 and forecasting method using the CNN (Convolutional Neural Network) which is one of the deep running algorithms. And the feasibility of the proposed method was verified using the meteorological satellite data in 2018. For the forecasting program, we programmed using Python, which is specialized for deep running."
기계 장치와의 상호작용을 위한 실시간 저비용 손동작 제어 시스템,2019,"['Gesture Control', 'Fourier Descriptor', 'TOF Camera', 'Real-time', 'Hand Gesture']","최근에, 효율적인 상호작용을 지원하는 시스템 인 휴먼 머신 인터페이스(HMI)가 인기를 끌고있다. 본 논문에서는 차량 상호작용방법 중 하나로 새로운 실시간 저비용 손동작 제어 시스템을 제안한다. 계산 시간을 줄이기 위해 RGB 카메라를 사용하여 손 영역을 감지할 때 많은 계산이 필요하므로 TOF (Time-of-Flight) 카메라를 사용하여 깊이 정보를 취득한다. 또한, 푸리에 기술자를 사용하여 학습 모델을 줄였다. 푸리에 디스크립터는 전체 이미지에서 적은 수의 포인트만 사용하므로 학습 모델을 소형화 할 수 있다. 제안 된 기법의 성능을 평가하기 위해 데스크탑과 라즈베리 pi 2의 속도를 비교했다. 실험 결과에 따르면 소형 임베디드와 데스크탑의 성능 차이는 크지 않다. 제스처 인식 실험에서 95.16 %의 인식률이 확인되었다.","Recently, a system that supports efficient interaction, a human machine interface (HMI), has become a hot topic. In this paper, we propose a new real time low-cost hand gesture control system as one of vehicle interaction methods. In order to reduce computation time, depth information was acquired using a time-of-flight (TOF) camera because it requires a large amount of computation when detecting hand regions using an RGB camera. In addition, fourier descriptor were used to reduce the learning model. Since the Fourier descriptor uses only a small number of points in the whole image, it is possible to miniaturize the learning model. In order to evaluate the performance of the proposed technique, we compared the speeds of desktop and raspberry pi2. Experimental results show that performance difference between small embedded and desktop is not significant. In the gesture recognition experiment, the recognition rate of 95.16% is confirmed."
An Extensive Review on Recent Emerging Applications of Artificial Intelligence,2019,"['Artificial Intelligence', 'Applications of AI', 'Machine Learning', 'Robotics', 'Astronomy', 'Construction.']",,"In recent days, the applications of artificial intelligence are growing in number by day to day. In the present paper, the authors gave the brief idea about artificial intelligence and the various applications of artificial intelligence. The utilization of artificial intelligence and its related technologies had encouraged and providing various facilities for researchers and scientists to develop and implement the artificial intelligence techniques in various emerging sectors of the market today. As the technology is growing day to day, the utilization of various applications by using the technology is also growing. Hence, the authors gave a clear idea and discussed in detail about the applications of artificial intelligence with the help of some diagrams."
스포츠 기사 댓글에서 수사의문문으로 표현된 풍자 표현의 자동인식,2019,"['sentiment analysis', 'sarcasm', 'rhetorical question', 'sports domain', 'machine learning', 'classification']",,"This paper presents an experiment of automatic detection of Korean sarcastic expressions appeared in the comments of Korean sports articles. When sarcasm is expressed in text, its automatic detection becomes challenging since the accurate interpretation can be identified only by figuring out its underlying meaning. However, the sentences implying sarcasm can be detected utilizing a set of features which is selected considering the characteristics of the domain in question. This research focuses on identifying sarcastic meaning expressed in text of sports domain in which sarcasm is frequently expressed in the form of rhetorical question. In particular, a sentence final suffix‘nya’is adopted to construct rhetorical question expressing mostly negative sentiment although the suffix itself does not represent any sentiment at all. A set of relevant features including the suffix is selected from the data and classified. A series of experiments utilizing the classified features have proven that non-sentiment bearing words such as a function word or a suffix can be contributed to identify implicit sentiment, such as sarcasm."
k-최근접 이웃 알고리즘을 이용한 입찰가격예측,2019,"['Electronic Bidding', 'Python', 'KNN', 'Deep Learning', 'Prediction f oBidding', '전자 입찰', '파이썬', 'KNN', '딥러닝', '입찰 예측']","우리나라는 입찰에서 전자입찰을 기본으로 사용하고 있다. 전자입찰은 발주처에 직접 찾아가서 입찰 서류를 제출해야했던 번거로움을 간소화하고, 조달업체와 공공기관에 대면접촉에 의한 부정입찰을 방지할 수 있다는 장점이 있다. 그러나전자입찰에서 입찰 가격을 예측하는 것은 쉬운 일이 아니다. 본 논문은 전자입찰에 적용할 수 있는 파이썬을 이용해머신러닝을 적용한 입찰프로그램을 제안한다. 입찰 프로그램은 k-최근접 이웃(k-Nearest Neighbors : KNN) 알고리즘의KNeighborsRegressor를 이용하여 기존의 낙찰현황 데이터를 분류한 후, 이를 분석하여 훈련 세트와 테스트 세트의 정확도를통해 KNN 알고리즘을 이용한 모델을 구성하고, 기존낙찰가 분석을 통해 낙찰금액을 예측하였다.","In Korea, we have used electronic bidding as basics in the bidding. The electronic bidding has the advantages to simplify the troublesome of submitting bidding document directly to the client and to prevent unfair bidding due to fact-to-face contact between procurement company and public institution. However, it is not easy that predict the price tendered in the electric bidding. This paper proposes a bidding program with machine learning using python that can be applied to the electronic bidding. The bidding program classifies the data of existing bid status by using KNeighborsRegressor of k-Nearest Neighbors (KNN) algorithm. After we analyze the data of existing bid status, we compose a model using KNN algorithm through the accuracy of training set and test set.Finally we predict price tendered by analyzing the existing b idprice."
Artificial Neural Network를 이용한 사출압력과 사출성형품의 무게 예측에 대한 연구,2019,"['Artificial neural network', 'Injection molding', 'Machine learning', 'Weight']",,"This paper presents Artificial Neural Network(ANN) method to predict maximum injection pressure of injection molding machine and weights of injection molding products. 5 hidden layers with 10 neurons is used in the ANN. The ANN was conducted with 5 Input parameters and 2 response data. The input parameters, i.e., melt temperature, mold temperature, fill time, packing pressure, and packing time were selected. The combination of the orthogonal array L27 data set and 23 randomly generated data set were applied in order to train and test for ANN. According to the experimental result, error of the ANN for weights was %. In case of maximum injection pressure, error of the ANN was %. This value showed that ANN can be successfully predict the injection pressure and the weights of injection molding products."
광학 및 레이더 위성영상으로부터 인공신경망을 이용한 공주시 산림의 층위구조 분류,2019,"['forest vertical structure', 'Forest Survey', 'machine learning', 'Artificial Neural Network']",,"Since the forest type map in Korea has been mostly constructed every five years, the forest information from the map lacks up-to-date information. Forest research has been carried out by aerial photogrammetry and field surveys, and hence it took a lot of times and money. The vertical structure of forests is an important factor in evaluating forest diversity and environment. The vertical structure is essential information, but the observation of the vertical structure is not easy because the vertical structure indicates the internal structure of forests. In this study, the index map and texture map produced from KOMPSAT-3/3A/5 satellite images and the canopy information generated by the difference between DSM (Digital Surface Model) and DTM (Digital Terrain Model) were classified using the artificial neural network. The vertical structure of forests of single and multi-layer forests was classified to identify 81.59% of the final classification result."
Analyzing and Visualizing Knowledge Structures of Health Informatics from 1974 to 2018: A Bibliometric and Social Network Analysis,2019,"['Medical Informatics', 'Data Mining', 'Algorithms', 'Machine Learning', 'Publicati']",,"Objectives: This paper aims to provide a theoretical clarification of the health informatics field by conducting a quantitative review analysis of the health informatics literature. And this paper aims to map scientific networks; to uncover the explicit and hidden patterns, knowledge structures, and sub-structures in scientific networks; to track the flow and burst of scientific topics; and to discover what effects they have on the scientific growth of health informatics. Methods: This study was a quantitative literature review of the health informatics field, employing text mining and bibliometric research methods. This paper reviews 30,115 articles with health informatics as their topic, which are indexed in the Web of Science Core Collection Database from 1974 to 2018. This study analyzed and mapped four networks: author co-citation network, co-occurring author keywords and keywords plus, co-occurring subject categories, and country co-citation network. We used CiteSpace 5.3 and VOSviewer to analyze data, and we used Gephi 0.9.2 and VOSviewer to visualize the networks. Results: This study found that the three major themes of the literature from 1974 to 2018 were the utilization of computer science in healthcare, the impact of health informatics on patient safety and the quality of healthcare, and decision support systems. The study found that, since 2016, health informatics has entered a new era to provide predictive, preventative, personalized, and participatory healthcare systems. Conclusions: This study found that the future strands of research may be patient-generated health data, deep learning algorithms, quantified self and self-tracking tools, and Internet of Things based decision support systems."
Advances in automated tongue diagnosis techniques,2019,"['Automated tongue diagnosis', 'Image processing', 'Machine learning', 'Mobile-enabled systems', 'Clinical decision support systems']",,"Tongue diagnosis can be an effective, noninvasive method to perform an auxiliary diagnosis any time anywhere, which can support the global need in the primary healthcare system. This work reviews the recent advances in tongue diagnosis, which is a significant constituent of traditional oriental medicinal technology, and explores the literature to evaluate the works done on the various aspects of computerized tongue diagnosis, namely preprocessing, tongue detection, segmentation, feature extraction, tongue analysis, especially in traditional Chinese medicine (TCM). In spite of huge volume of work done on automatic tongue diagnosis (ATD), there is a lack of adequate survey, especially to combine it with the current diagnosis trends. This paper studies the merits, capabilities, and associated research gaps in current works on ATD systems. After exploring the algorithms used in tongue diagnosis, the current trend and global requirements in health domain motivates us to propose a conceptual framework for the automated tongue diagnostic system on mobile enabled platform. This framework will be able to connect tongue diagnosis with the future point-of-care health system."
Deciphering Monetary Policy Board Minutes with Text Mining: The Case of South Korea,2019,"['Monetary Policy', 'Text Mining', 'Taylor Rule', 'Machine Learning', 'Bank of Korea']",,"We quantify the Monetary Policy Board minutes of the Bank of Korea (BOK) by using text mining. We propose a novel approach that uses a field-specific Korean dictionary and contiguous sequences of words (n-grams) to capture the subtlety of central bank communications. Our text-based indicator helps explain the current and future BOK monetary policy decisions when considering an augmented Taylor rule, suggesting that it contains additional information beyond the currently available macroeconomic variables. In explaining the current and future monetary policy decisions, our indicator remarkably outperforms English-based textual classifications, a media-based measure of economic policy uncertainty, and a data-based measure of macroeconomic uncertainty. Our empirical results also emphasize the importance of using a field-specific dictionary and the original Korean text."
Convolutional neural network based surface inspection system for non-patterned welding defects,2019,['Defect detection Automatic inspection Convolutional neural network Machine vision Image processing Deep learning'],,"In this paper, we propose a convolutional neural network (CNN) based method that inspects non-patterned welding defects (craters, pores, foreign substances and fissures) on the surface of the engine transmission using a single RGB camera. The proposed method consists of two steps: first, extracting the welding area to be inspected from the captured image, and then determining whether the extracted area includes defects. In the first step, to extract the welding area from the captured image, a CNN based approach is proposed to detect a center of the engine transmission in the image. In the second stage, the extracted area is identified by another CNN as defective or non-defective. To train the second stage CNN stably, we propose a class-specific batch sampling method. With our sampling method, biased learning caused by data imbalance (number of collected defective images is much less than that of non-defective images) is effectively prevented. We evaluated our system with a large amount of samples (about 32,000 images) collected manually from the production line, and our system shows a remarkable performance in all experiments."
올림픽의 사회적 소통 유발효과:2016 리우하계올림픽 온라인 언론 보도와 댓글 분석,2019,"['Olympic', 'sports journalism', 'communication volume', 'interactive communication', 'machine learning', 'language sentimental analysis', '올림픽', '스포츠 저널리즘', '소통성', '상호작용', '머신러닝', '언어 감성분석']","이 연구는 온라인 뉴스 포털 사이트에 게시된 올림픽 관련 기사가 타 장르(정치, 경제, 사회, 문화) 기사와 비교하여 온라인 소통을 더 효과적으로 유발하였는지 여부를 검증함으로써 올림픽콘텐츠의 사회적 소통유발 효과를 검증하는 것을 목적으로 한다. 구체적으로 2016년 리우올림픽 기간 중 온라인 포털사이트에 게시된 총 29,784개의 언론 보도 기사와 1,620,420개의 댓글, 그리고 독자들의 미디어 반응과 관련된 다양한 정보를 파이선(Phython) 언어를 사용하여 수집하였고 올림픽 기사 대비 정치, 경제, 사회, 문화로 구성된 타 장르 기사의 소통 유발효과를 검증하였다. 종속변수인 사회적 소통량은 기사에 직접 댓글을 다는 방식 등 기사에 대한 독자들의 직접적인 소통행동을 반영하는 ‘직접 소통량’과 기사의 댓글에 대한 추천과 비추천 등 독자들 사이의 소통행동을 반영하는 ‘상호작용 소통량’으로 측정하였다. 자료 분석을 위해서 총 9개의 통제변인과 기사 장르를 독립변인으로 투입하여 각각의 소통량을 종속변인으로 하는 2개의 회귀모형과, 종속변인을 로그 치환한 2개의 추가적인 회귀모형을 분석하였다. 주요 분석 결과로 타 장르 기사에 비해 올림픽 기사의 소통증진 효과가 대체적으로 큰 것으로 나타났다. 정치기사 대비 올림픽 기사가 로그 치환한 상호작용 소통량에 미치는 영향만 유의하지 않았을 뿐, 그 밖의 모든 회귀분석 결과는 예측한 방향으로 유의한 결과를 보여줘 올림픽 기사가 타 장르에 비해 사회적 소통 유발효과가 유의미하게 크다는 것을 보여 주었다. 연구결과는 올림픽의 무형의 유산으로 사회적 소통 유발효과가 유의미하게 존재한다는 실증자료로 학술적, 실무적 의미가 크다.","The study aims to examine the social communication effects of Olympic contents by investigating whether news articles related to the Olympics posted on online news portals have triggered online communication more effectively compared to articles in other genres (political, economic, social, and cultural). A total of 29,784 online news articles along with 1,620,420 audience comments to the articles and associated audience response data were collected using Python program to examine the impact of Olympic articles on social communication, as compared to politics, economy, social and culture articles. The amount of social communication was measured by 'direct communication volume' reflecting the direct communication behavior of readers, including direct replies to articles, and 'interactive communication volume' reflecting the communication behavior among readers such as recommendation of other readers’ comments on articles. For the data analysis, a total of nine control variables and article genres were regressed on the two communication volume variables. Overall the findings suggest that Olympic articles had a greater influence on generating social communication than other genres. The result of this study demonstrates that the intangible legacy of the Olympics by way of generating significant amount of social communication. Theoretical and practical implication along with limitations and future research directions are discussed."
CT Image Conversion among Different Reconstruction Kernels without a Sinogram by Using a Convolutional Neural Network,2019,"['Multidetector computed tomography', 'Image reconstruction', 'Machine learning', 'Emphysema', 'CNN']",,"Objective: The aim of our study was to develop and validate a convolutional neural network (CNN) architecture to convert CT images reconstructed with one kernel to images with different reconstruction kernels without using a sinogram.Materials and Methods: This retrospective study was approved by the Institutional Review Board. Ten chest CT scans were performed and reconstructed with the B10f, B30f, B50f, and B70f kernels. The dataset was divided into six, two, and two examinations for training, validation, and testing, respectively. We constructed a CNN architecture consisting of six convolutional layers, each with a 3 x 3 kernel with 64 filter banks. Quantitative performance was evaluated using root mean square error (RMSE) values. To validate clinical use, image conversion was conducted on 30 additional chest CT scans reconstructed with the B30f and B50f kernels. The influence of image conversion on emphysema quantification was assessed with Bland–Altman plots.Results: Our scheme rapidly generated conversion results at the rate of 0.065 s/slice. Substantial reduction in RMSE was observed in the converted images in comparison with the original images with different kernels (mean reduction, 65.7%; range, 29.5–82.2%). The mean emphysema indices for B30f, B50f, converted B30f, and converted B50f were 5.4 ± 7.2%, 15.3 ± 7.2%, 5.9 ± 7.3%, and 16.8 ± 7.5%, respectively. The 95% limits of agreement between B30f and other kernels (B50f and converted B30f) ranged from -14.1% to -2.6% (mean, -8.3%) and -2.3% to 0.7% (mean, -0.8%), respectively.Conclusion: CNN-based CT kernel conversion shows adequate performance with high accuracy and speed, indicating its potential clinical use."
스마트 제조 시대 효과적인 데이터 사이언티스트 양성 전략,2019,"['데이터 사이언스', '데이터 사이언티스트', '디지털 전환', '머신러닝', '내부혁신', 'Data Science', 'Data Scientist', 'Digital Transformation', 'Machine Learning', 'Internal Innovation']","인공지능과 디지털 전환이 산업의 생태계를 크게 변화시키고 있는 현재 기업의 고민은 이에 어떻게 효과적으로 대비하는가이다. 제조업에서도 지난 수십 년 동안 정보화, 자동화, 로봇화 등을 통하여 디지털 혁신에 대응하고 있지만, 본격적인 빅데이터 활용과 인공지능 도입은 아직 미흡한 실정이다. 디지털 전환에서 사용되는 가장 중요한 기술은 데이터 사이언스이며 이를 수행하는 데이터 사이언티스트를 핵심 인재로서 어떻게 확보하는지가 기업의 경쟁력이 되고 있다. 데이터 사이언티스트는 현업 도메인의 문제를 이해하는 능력, 해결해야 할 문제를 명확히 정의하는 능력, 문제해결형 프로젝트를 만들고 관련자들과 협력하여 이를 해결하는 능력이 필요하다. 이는 단순히 프로그래밍 기술 이상을 요구한다. 본 고에서는 기업의 데이터 사이언티스트 양성이 어려운 이유를 파악하고, 내부 인력을 데이터 사이언티스트로 양성하기 위한 효과적인 교육 방법을 제시한다. 또한 교육을 통한 기업 내부혁신 방안을 소개하겠다. 기업에서 사용할 수 있는 데이터 사이언스 교육 프로세스 예로PSDMTR (Problem Setting, Strategy, Data, Modeling, Test, Report) 전략을 소개하겠다.","Recently, AI and digital transformation are changing the ecosystem of the industry. The company’s concern is how to prepare effectively for this change. The manufacturing industry has been responding to digital innovation through informatization, automation, and robotization for decades, but the use of big data and introduction of artificial intelligence are still insufficient. The key technology used in digital transformation is data science. Cultivating data scientists is becoming a competitive advantage for companies. Data scientists need the ability to understand problems in the domain, to clearly define the problems, and to create problem-solving projects and work with stakeholders. This requires more than just programming skills. In this paper, we suggest effective training methods for educating internal personnel as data scientists. In addition, we will introduce the internal innovation plan through training. As an example of the data science training process, we introduce the PSDMTR (Problem Setting, Strategy, Data, Modeling, Test, Report) strategy."
User Modeling Using User Preference and User Life Pattern Based on Personal Bio Data and SNS Data,2019,"['Bio Data', 'Data Tracking', 'Life Pattern', 'Machine Learning', 'Social Behavior Analysis', 'User Modeling']",,"The purpose of this study was to collect and analyze personal bio data and social network services (SNS) data, derive user preference and user life pattern, and propose intuitive and precise user modeling. This study not only tried to conduct eye tracking experiments using various smart devices to be the ground of the recommendation system considering the attribute of smart devices, but also derived classification preference by analyzing eye tracking data of collected bio data and SNS data. In addition, this study intended to combine and analyze preference of the common classification of the two types of data, derive final preference by each smart device, and based on user life pattern extracted from final preference and collected bio data (amount of activity, sleep), draw the similarity between users using Pearson correlation coefficient. Through derivation of preference considering the attribute of smart devices, it could be found that users would be influenced by smart devices. With user modeling using user behavior pattern, eye tracking, and user preference, this study tried to contribute to the research on the recommendation system that should precisely reflect user tendency."
수화번역시스템을 위한 인공신경망의 응용,2019,"['Sign Language Translation', 'Artificial Neural Network', 'Machine Learning', 'Hearing Impaired Person']",,"In the case of a hearing impaired person using sign language, there are many difficulties in communicating with a normal person who does not understand sign language. The sign language translation system is a system that enables communication between the hearing impaired person using sign language and the normal person who does not understand sign language in this situation. Previous studies on sign language translation systems for communication between normal people and hearing impaired people using sign language are classified into two types using video image system and shape input device. However, the existing sign language translation system does not solve such difficulties due to some problems. Existing sign language translation systems have some problems that they do not recognize various sign language expressions of sign language users and require special devices. Therefore, in this paper, a sign language translation system using an artificial neural network is devised to overcome the problems of the existing system."
User Identification Using Real Environmental Human Computer Interaction Behavior,2019,"['User Identification', 'Biometric', 'Multiple Kernel Learning (MKL)', 'Keystroke Dynamic', 'Mouse Dynamic']",,"In this paper, a new user identification method is presented using real environmental human-computer-interaction (HCI) behavior data to improve method usability. User behavior data in this paper are collected continuously without setting experimental scenes such as text length, action number, etc. To illustrate the characteristics of real environmental HCI data, probability density distribution and performance of keyboard and mouse data are analyzed through the random sampling method and Support Vector Machine(SVM) algorithm. Based on the analysis of HCI behavior data in a real environment, the Multiple Kernel Learning (MKL) method is first used for user HCI behavior identification due to the heterogeneity of keyboard and mouse data. All possible kernel methods are compared to determine the MKL algorithm’s parameters to ensure the robustness of the algorithm. Data analysis results show that keyboard data have a narrower range of probability density distribution than mouse data. Keyboard data have better performance with a 1-min time window, while that of mouse data is achieved with a 10-min time window. Finally, experiments using the MKL algorithm with three global polynomial kernels and ten local Gaussian kernels achieve a user identification accuracy of 83.03% in a real environmental HCI dataset, which demonstrates that the proposed method achieves an encouraging performance."
A model-free soft classification with a functional predictor,2019,"['functional data', 'Fisher consistency', 'support vector machines', 'probability estimation']",,"Class probability is a fundamental target in classification that contains complete classification information. In this article, we propose a class probability estimation method when the predictor is functional. Motivated by Wang et al. (Biometrika, 95, 149-167, 2007), our estimator is obtained by training a sequence of functional weighted support vector machines (FWSVM) with different weights, which can be justified by the Fisher consistency of the hinge loss. The proposed method can be extended to multiclass classification via pairwise coupling proposed by Wu et al. (Journal of Machine Learning Research, 5, 975-1005, 2004). The use of FWSVM makes our method model-free as well as computationally efficient due to the piecewise linearity of the FWSVM solutions as functions of the weight. Numerical investigation to both synthetic and real data show the advantageous performance of the proposed method."
Heterogeneous Ensemble of Classifiers from Under-Sampled and Over-Sampled Data for Imbalanced Data,2019,"['Over-sampling', 'Under-sampling', 'Heterogeneous ensemble', 'Imbalanced data.']",,"Data imbalance problem is common and causes serious problem in machine learning process. Sampling is one of the effective methods for solving data imbalance problem. Over-sampling increases the number of instances, so when over-sampling is applied in imbalanced data, it is applied to minority instances.Under-sampling reduces instances, which usually is performed on majority data. We apply under-sampling and over-sampling to imbalanced data and generate sampled data sets. From the generated data sets from sampling and original data set, we construct a heterogeneous ensemble of classifiers. We apply five different algorithms to the heterogeneous ensemble. Experimental results on an intrusion detection dataset as an imbalanced datasets show that our approach shows effective results."
선박평형수 내 동물플랑크톤(>50 ㎛ 생물) 분류를 위한 인공지능 적용,2019,"['Ballast water(선박평형수)', 'Zooplankton(동물플랑크톤)', 'Artificial Intelligence(인공지능)', 'Machine Learning(기계학습)', 'International Maritime Organization(IMO / 국제해사기구)']",,
Extraction of Critical Low-Level Image Features for Effective Emotion Analysis,2019,"['pattern recognition', 'sentiment analysis', 'low-level image feature', 'deep learning']",,"Sentiment analysis has received considerable critical attention in machine learning, artificial intelligence, human-computer interface, etc. In these fields, many studies have analyzed emotions using images, audio, and bio-signals as features. Among them, those that utilize image features are the most typical for emotion recognition. There are two types of image features: high-level and low-level. Low-level features are more robust than high-level in sentiment analysis. Therefore, in this paper, we investigated the critical features for effective sentiment analysis in low-level image features. For an objective performance evaluation, we utilized the International Affective Picture System dataset for training and testing. We applied the iterative Han and Cha’s feature selection/extraction algorithms and used a multilayer perceptron classification. We also carried out cross-validation by replacing features. Our evaluation items consisted of two elements: accuracy and computational time. According to our results, we were able to find the critical features in sentiment analysis and our method proved more competitive compared with existing algorithms in terms of accuracy and operation time."
Heterogeneous Ensemble of Classifiers from Under-Sampled and Over-Sampled Data for Imbalanced Data,2019,"['Over-sampling', 'Under-sampling', 'Heterogeneous ensemble', 'Imbalanced data']",,"Data imbalance problem is common and causes serious problem in machine learning process. Sampling is one of the effective methods for solving data imbalance problem. Over-sampling increases the number of instances, so when over-sampling is applied in imbalanced data, it is applied to minority instances. Under-sampling reduces instances, which usually is performed on majority data. We apply under-sampling and over-sampling to imbalanced data and generate sampled data sets. From the generated data sets from sampling and original data set, we construct a heterogeneous ensemble of classifiers. We apply five different algorithms to the heterogeneous ensemble. Experimental results on an intrusion detection dataset as an imbalanced datasets show that our approach shows effective results."
고차원 볼의 적도 부근의 체적 분포에 대한 정밀 근사,2019,"['high dimensional space', 'dimensional ball', 'volume distribution', 'data mining', 'machine learning']",,"In high-dimensional space, the volume of an -dimensional ball defined in Euclidean space tends to concentrate near the surface and the equator of the ball. The purpose of this paper is to show that the volume distribution of a high-dimensional ball near the equator can be accurately approximated with a standard normal distribution. Based on the volume formulas of an -dimensional ball, Stirling’s approximation and binomial approximation are used for a straightforward derivation of the accurate approximation of the ball distribution. Numerical data are given to demonstrate the non-intuitive phenomenon of the volume concentration and the accuracy of the volume distribution approximation. At the end, some discussions are made on the implications of the volume distribution of a high-dimensional ball toward the data search problem in high-dimensional space."
Application of Google Search Queries for Predicting the Unemployment Rate for Koreans in Their 30s and 40s,2019,"['30~40대 실업률', '웹 검색어', '예측', 'SARIMA 모형', '머신러닝', '30s and 40s Unemployment', 'Web Search Query', 'Prediction', 'SARIMA Model', 'Machine Learning']",,
앙상블 기법을 활용한 온라인 음식 상품 리뷰 감성 분석,2019,"['텍스트 마이닝', '감성 분석', '앙상블 기법', '온라인 마켓', '머신러닝', 'Text mining', 'Sentiment analysis', 'Ensemble technique', 'Online market', 'Machine learning']","온라인 마켓에서 소비자는 다양한 상품을 접하고 이에 대한 의견을 자유롭게 기술한다. 소비자의 상품 리뷰가 다른 소비자와 온라인 마켓의 성공에 큰 영향을 주는 만큼 온라인 마켓은 판매 상품에 대한 소비자의 감성을 정확하게 분석할 필요가 있다. 데이터 분석 기법 중 하나인 텍스트 마이닝은 상품에 대한 소비자 리뷰를 분석하여 상품을 효율적으로 관리할 수 있게 해준다. 선행 연구들은 데이터 도메인과 사이즈에 따라 분석 결과의 정확도가 다르게 나타남에도 불구하고 특정 도메인과 2만개 미만의 데이터를 분석해왔다. 또한, 분석의 정확도를 향상 시킬 수 있는 추가 요인에 대한 연구는 거의 수행하지 않았다. 본 연구는 앙상블 기법을 활용하여 기존 연구에서 주로 다루지 않은 음식 상품 도메인의 72,530개 리뷰 데이터를 분석하였다. 또한, 분석 정확도 향상과 관련하여 요약 리뷰의 영향력을 살펴보았다. 연구 결과, 본 연구는 기존 연구와 다르게 부스팅 앙상블 기법이 가장 높은 분석 정확도를 보인다는 사실을 발견하였다. 또한, 요약 리뷰는 분석의 정확도 향상에 기여하는 것으로 나타났다.","In the online marketplace, consumers are exposed to various products and freely express opinions. As consumer product reviews have a important effect on the success of online markets and other consumers, online market needs to accurately analyze the consumers' emotions about their products. Text mining, which is one of the data analysis techniques, can analyze the consumer's reviews on the products and efficiently manage the products. Previous studies have analyzed specific domains and less than 20,000 data, despite the different accuracy of the analysis results depending on the data domain and size. Further, there are few studies on additional factors that can improve the accuracy of analysis. This study analyzed 72,530 review data of food product domain that was not mainly covered in previous studies by using ensemble technique. We also examined the influence of summary review on improving accuracy of analysis. As a result of the study, this study found that Boosting ensemble technique has the highest accuracy of analysis. In addition, the summary review contributed to improving accuracy of the analysis."
속성선택방법과 워드임베딩 및 BOW (Bag-of-Words)를 결합한 오피니언 마이닝 성과에 관한 연구,2019,"['Word embedding', 'Opinion mining', 'Sentiment analysis', 'Feature selection', 'Machine learning', '워드 임베딩', '오피니언 마이닝', '감성분석', '속성선택', '머신러닝']","과거 10년은 웹의 발달로 인한 데이터가 폭발적으로 생성되었다. 데이터마이닝에서는 대용량의 데이터에서 무의미한 데이터를 구분하고 가치 있는 데이터를 추출하는 단계가 중요한 부분을 차지한다. 본 연구는 감성분석을 위한 재표현 방법과 속성선택 방법을 적용한 오피니언 마이닝 모델을 제안한다. 본 연구에서 사용한 재표현 방법은 백 오즈 워즈(Bag-of-words)와 Word embedding to vector(Word2vec)이다. 속성선택(Feature selection) 방법은 상관관계 기반 속성선택(Correlation based feature selection), 정보획득 속성선택(Information gain)을 사용했다. 본 연구에서 사용한 분류기는 로지스틱 회귀분석(Logistic regression), 인공신경망(Neural network), 나이브 베이지안 네트워크(naive Bayesian network), 랜덤포레스트(Random forest), 랜덤서브스페이스(Random subspace), 스태킹(Stacking)이다. 실증분석 결과, electronics, kitchen 데이터 셋에서는 백 오즈 워즈의 정보획득 속성선택의 로지스틱 회귀분석과 스태킹이 높은 성능을 나타냄을 확인했다. laptop, restaurant 데이터 셋은 Word2vec의 정보획득 속성선택을 적용한 랜덤포레스트가 가장 높은 성능을 나타내는 조합이라는 것을 확인했다. 다음과 같은 결과는 오피니언 마이닝 모델 구축에 있어서 모델의 성능을 향상시킬 수 있음을 나타낸다.","Over the past decade, the development of the Web explosively increased the data. Feature selection step is an important step in extracting valuable data from a large amount of data. This study proposes a novel opinion mining model based on combining feature selection (FS) methods with Word embedding to vector (Word2vec) and BOW (Bag-of-words). FS methods adopted for this study are CFS (Correlation based FS) and IG (Information Gain). To select an optimal FS method, a number of classifiers ranging from LR (logistic regression), NN (neural network), NBN (naive Bayesian network) to RF (random forest), RS (random subspace), ST (stacking). Empirical results with electronics and kitchen datasets showed that LR and ST classifiers combined with IG applied to BOW features yield best performance in opinion mining. Results with laptop and restaurant datasets revealed that the RF classifier using IG applied to Word2vec features represents best performance in opinion mining."
한국의 이념갈등과 이념분류 기준 탐색: 의사결정나무(Decision Tree Analysis) 활용 가능성,2019,"['나무의사결정모델', '정치이념', '역대대통령선호', '한국정치', '기계학습', 'political ideology', 'Korean politics', 'decision tree model', 'machine learning', 'preference for former presidents']","한국민의 정치이념은 서구 민주주의와 다르게 형성되어 왔으며 다차원적 측면이 있어 정확히 파악하는 데는 한계가 있다. 이 연구는 새로운 분석방식을 한국민의 이념 분류에 적용해보려는 기초 작업에 그 목적을 두고 있다. 한국인의 이념을 어떻게 분류하는 것이 가장 적절하며 그렇다면 어떤 요인들이 가장 중요한 것인지를 찾아보는 것에서 시작되었다. 이를 위해 의사결정나무모형을 선택하였다.2007년 대선, 2012년 대선, 2017년 대선에 대한 여론조사 자료에서 한국 정치이념을 구분할 수 있는 가장 중요한 변수가 무엇인가를 찾기 위해 나무의사결정모델을 활용하였고, 그 결과 응답자의 이념성향을 구분하는 가장 중요한 요인은 2007년의 경우 국가보안법 폐지나 개정에 관한 의견이었고, 2012년과 2017년은 역대선호대통령에 대한 선호였다. 2012년과 2017년의 분석결과에서는 과거의 이념적 핵심균열 기준이었던 안보와 대북이슈 대신 역대대통령 중 가장 선호하는 대통령에 대한 개인적 선호도가 가장 중요인 이념 분류기준이 되었다. 한국정치의 역사적 특징, 한국 정치제도, 그리고 새로운 정치환경은 인물중심적 정치를 강화하고 있는데 이를 잘 보여주고 있다고 할 수 있다. 위 조사결과의 의미는 한국민의 정치이념 즉 보수, 중도, 진보로 분류한다면 역대 대통령 선호도를 물어보면 가장 쉽게 파악할 수 있다는 의미이다. 이 연구는 보다 직관적이고 쉽게 한국민의 정치이념을 분류, 예측할 수 있는 새로운 분석방법을 적용해보고 그 결과를 제시하였다는 점에서 의미를 둘 수 있다.","The political ideology of the Korean people has been shaped differently from the Western democracy, and there are limitations in grasping it precisely because of the multidimensional aspect. The purpose of this research is to apply the new analysis method to the ideological classification of Koreans. It began by looking at how to classify Korean idealology and what factors are most important. For this purpose, decision tree model was selected. In the polls of the 2007 presidential election, the 2012 presidential election, and the 2017 presidential election, a decision tree model was used to find out the most important variables that could distinguish Korean’s political ideologies. As a result, the most important factor was the abolition or revision of the National Security Law in 2007, and the preference for the former president in 2012 and 2017.In the analysis results of 2012 and 2017, the personal preference of the most favorite president among the past presidents became the most important ideological classification standard instead of the security and the North Korea issue which were the ideological key criteria of the past. The historical features of Korean politics, Korean political system, and the new political environment are reinforcing character – person-centered politics. If the results of the above survey are classified into the political ideology of the Korean people such as conservative, moderate, and progressive, it means that it can be easily grasped by asking about people’s preferences for former president. This study can be meaningful in that it applied the new analysis method which can classify and predict Korean people’s political ideology more intuitively and easily."
효율적인 고차원 데이터 처리를 위한 차원 볼의 체적 집중에 대한 분석,2019,"['High-dimensional data', '\ue00d -dimensional ball', 'Volume concentration', 'Data sample distribution', 'Machine learning']",,"This paper presents the volume concentration analysis of an n-dimensional ball (n-ball) defined in Euclidean space, near the surface and the equator, for efficient high-dimensional data processing. To quantify the volume concentration of an n-ball, two measures are defined: one measure as the volume ratio of a whole n-ball to the differential slice near the surface, and the other as the volume ratio of a whole n-ball to the differential slice near the equator. Without direct computation of the volumes of n-dimensional geometrical objects, both measures can be obtained as a function of the dimension of ball and the thickness of differential slice. According to computer simulation results for an n-ball, the surface volume concentration and the equator volume concentration show the changing patterns similar to each other, but the surface volume concentration is significantly stronger than the equator volume concentration. Finally, by interpreting the volume concentration of an n-ball as the distribution of high-dimensional data samples, a theoretical basis is provided for the planning of efficient high-dimensional data processing."
Character Classification with Triangular Distribution,2019,"['Image Comparison', 'Classification', 'Character Recognition', 'Feature Extraction', 'Distribution', 'Neural Network', 'Machine Learning']",,
Heterogeneous Ensemble of Classifiers from Under-Sampled and Over-Sampled Data for Imbalanced Data,2019,"['Over-sampling', 'Under-sampling', 'Heterogeneous ensemble', 'Imbalanced data.']",,"Data imbalance problem is common and causes serious problem in machine learning process. Sampling is one of the effective methods for solving data imbalance problem. Over-sampling increases the number of instances, so when over-sampling is applied in imbalanced data, it is applied to minority instances. Under-sampling reduces instances, which usually is performed on majority data. We apply under-sampling and over-sampling to imbalanced data and generate sampled data sets. From the generated data sets from sampling and original data set, we construct a heterogeneous ensemble of classifiers. We apply five different algorithms to the heterogeneous ensemble. Experimental results on an intrusion detection dataset as an imbalanced datasets show that our approach shows effective results."
Exploring the Performance of Synthetic Minority Over-sampling Technique (SMOTE) to Predict Good Borrowers in P2P Lending,2019,"['P2P 대부', '대출자 예측 신용위험평가', '빅데이터', '분류', '합성 소수집단 오버샘플링 기법', 'P2P lending', 'Predicting borrowers', 'Credit risk Assessment', 'Big Data', 'Classification', 'Synthetic Minority Over-sampling Technique']",,
IBM 왓슨 챗봇을 활용한 노동법 상담 시스템,2019,"['앱', '모바일', '챗봇', '기계학습', '고용노동법', 'App', 'Mobile', 'Chatbot', 'Machine Learning', 'Labor Law']",,
Manhole Cover Detection from Natural Scene Based on Imaging Environment Perception,2019,"['Manhole cover detection', 'UAV', 'environment perception', 'image enhancement', 'deep learning']",,"A multi-rotor Unmanned Aerial Vehicle (UAV) system is developed to solve the manhole cover detection problem for the infrastructure maintenance in the suburbs of big city. The visible light sensor is employed to collect the ground image data and a series of image processing and machine learning methods are used to detect the manhole cover. First, the image enhancement technique is employed to improve the imaging effect of visible light camera. An imaging environment perception method is used to increase the computation robustness: the blind Image Quality Evaluation Metrics (IQEMs) are used to percept the imaging environment and select the images which have a high imaging definition for the following computation. Because of its excellent processing effect the adaptive Multiple Scale Retinex (MSR) is used to enhance the imaging quality. Second, the Single Shot multi-box Detector (SSD) method is utilized to identify the manhole cover for its stable processing effect. Third, the spatial coordinate of manhole cover is also estimated from the ground image. The practical applications have verified the outdoor environment adaptability of proposed algorithm and the target detection correctness of proposed system. The detection accuracy can reach 99% and the positioning accuracy is about 0.7 meters."
연구자의 논문 게재 이력을 고려한 저널 결정 요인별 중요도 학습 기반의 저널 추천 방법론,2019,"['저널 추천', '결정 요인별 중요도', '논문 게재 이력', '머신러닝', '데이터 분석', 'journal recommendation', 'importance by decision factors', 'paper publication history', 'machine learning', 'data analysis']","연구자는 논문을 투고할 저널을 선택하는 과정에서 저널의 수가 방대하다는 점, 고려할 저널 결정 요인이 다양하다는 점에서 어려움을 겪는다. 이러한 어려움을 해소하기 위해 IRA(intelligent research assistant)의 한 종류로 연구자별로 논문 투고에 적합한 저널을 추천해주는 저널 추천 서비스를 활용할 수 있다. 하지만 현재 운영 중인 저널 추천 서비스의 경우 주제 유사도 및 수치적 필터링을 기반으로 저널 추천을 실행하고 있으며, 이 경우 연구자가 논문 데이터를 입력하지 않으면 주제 유사도를 고려할 수 없고, 수치적 필터링기능도 연구자 스스로 결정 요인별 수치 범위를 명확하게 정하기에 어려움이 있다는 한계점이 존재한다. 따라서 본 논문에서는 연구자의 논문 게재 이력을 이용해 선호도 행렬을 형성하고, 이를 기반으로 저널 별 선호 점수를 고려한 저널 추천 방법론을 제안한다.연구자는 다수의 저널 결정 요인에 대해 상이한 중요도를 가지고 있는데, 결정 요인 별 선호 민감도를 계산해 중요도를 학습한 뒤이를 기반으로 모든 저널에 대한 선호 점수를 도출하여 저널을 추천한다는 점에서 의의가 있다. 실제 데이터를 이용하여 저널 추천실험을 수행했으며 제안 방법론의 우수한 성능을 확인하였다.","Selecting a proper journal to submit a research paper is a difficult task for researchers since there are many journals and various decision factors to consider during the decision process. For this reason, journal recommendation services are exist as a kind of intelligent research assistant which recommend potential journals. The existing services are executing a recommendation based on topic similarity and numerical filtering. However, it is impossible to calculate topic similarity when a researcher does not input paper data, and difficult to input clear numerical values for researchers. Therefore, the journal recommendation method which consider the importance of decision factors is proposed by constructing the preference matrix based on the paper publication history of a researcher. The proposed method was evaluated by using the actual publication history of researchers. The experiment results showed that the proposed method outperformed the compared methods."
Heterogeneous Ensemble of Classifiers from Under-Sampled and Over-Sampled Data for Imbalanced Data,2019,"['Over-sampling', 'Under-sampling', 'Heterogeneous ensemble', 'Imbalanced data.']",,"Data imbalance problem is common and causes serious problem in machine learning process. Sampling is one of the effective methods for solving data imbalance problem. Over-sampling increases the number of instances, so when over-sampling is applied in imbalanced data, it is applied to minority instances. Under-sampling reduces instances, which usually is performed on majority data. We apply under-sampling and over-sampling to imbalanced data and generate sampled data sets. From the generated data sets from sampling and original data set, we construct a heterogeneous ensemble of classifiers. We apply five different algorithms to the heterogeneous ensemble. Experimental results on an intrusion detection dataset as an imbalanced datasets show that our approach shows effective results."
협업필터링과 스태킹 모형을 이용한 상품추천시스템 개발,2019,"['추천시스템', '협업필터링', '기계학습', '앙상블', '스태킹', 'Recommender system', 'Collaborative filtering', 'Machine learning', 'Ensemble', 'Stacking']",,
An Analysis of Korean-English Translation Errors in Google Translate,2019,"['Google Translate', 'error analysis', 'Korean to English translation', 'machine translation']",,"The purpose of this study is to identify types of errors that occur when using Google Translate and to suggest more effective ways to benefit from machine translation translators. The topics in the 30 news articles dealt with health and diet. The researchers directed the error analysis by comparing the English translation of the original Korean text with the eleven categories and their sub-categories. Among those translated by the Google Translate Program, according to our research, the number of sentences that contained errors was 365 (67.2%) and that of correct sentences was 178 (32.8%). Sentence structure errors, the highest of the eleven categories, recorded 172 (21.31%) cases, followed by nouns with 143 (17.72%), and verbs with 119 (14.75%). The findings emphasize the need to learn how to use machine translators effectively. Finally, Google Translate users need to avoid using complex sentences and vague words when translating Korean text into English."
Anomalous Vessel Behavior Detection Based on SVR Seaway Model,2019,"['Vessel Traffic Services', 'Anomalous behavior', 'Seaway model', 'Support vector regression', 'Machine learning']",,"The identification of anomalous behavior of own vessel and its targets is one of the most important task to ensure safety of navigation. In particular, it is essential to determine the anomalous behavior of a ship in the decision-making process. The existing anomalous behavior detection method defines the anomalous behavior by judging the abrupt changes of a ship’s movement. However, the navigational data that observed in actual marine accidents were often showed as a normal condition. It means that if there were persistent differences at certain duration, the accumulated data could become large enough to cause of an accident. In this study, the ship’s anomalous behavior was determined based on the SVR seaway model and its route extraction method. It was intended to propose a method of defining acceptable maximum and minimum values to determine the anomalous behavior by assigning navigational data to the location basis. For the verification of the proposed method, it was constructed that virtual route and targets which are similar to the actual navigational environment. As a result of the simulation, anomaly detection data on the anomalous behavior were presented. It is expected that the proposed method could be a decision-making support tool to mariners and contributes to the reduction of marine accidents related on the anomalous behavior."
인지 라디오 시스템용 협업 기계학습기반 무선접속 식별 기술,2019,"['Radio Access Technology (RAT)', 'Cognitive Radio (CR)', 'Collaborative Sensing', 'Machine Learning (ML)', 'Support Vector Machine (SVM)']",,
시각-기억 순환 모델링을 위한 시각 자극의 저차원 추상화 표현,2019,"['기계 지능', '기억 순환 모델', '희소 분포 표현', '매니폴드 학습', 'Machine intelligence', 'Memory circulation model', 'Sparse distributed representation', 'Manifold learning']","본 논문에서는 사람의 기억 순환 메커니즘에 대한 소프트웨어적 구현에 있어서 인지과학적 기억의 관점, 시각 데이터 처리의 관점 및 신호처리의 관점에서 새로운 시각 자극의 표현 기법을 제안한다. 특히, 사람의 시각과 기억의 순환 모델링을 위해 높은 차원의 시각 자극에 대해 낮은 차원의 추상화 및 개념화 과정을 통해 표현하는 새로운 기법을 제안한다. 제안 기법은 생성 모델 기반 오토 인코더와 클러스터링을 통해 고차원의 시각 입력 데이터에 대해 저차원의 속성 데이터로 표현한다. 이때, 저차원 속성 데이터 표현에 있어 시맨틱의 임베딩 및 클래스 간 거리 유지에 유리한 희소 분포 표현 (SDR: Sparse Distributed Representation)을 사용한다. 본 논문에서는 28x28 화소로 구성되는 MNIST와 Fashion MNIST 데이터셋에 대해 적용한 실험 결과 각 클래스에 대해 변환된 저차원 SDR이 고차원 데이터 특성을 잘 반영함을 분류기 관점에서 확인하였다. 실험에서 784차원을 10차원으로 변경하더라도 2% 이하 분류 에러 수준에서 변환된 저차원 표현이 고차원 입력을 충분히 표현할 수 있음을 확인하였다.","This paper proposes a new representation scheme for visual stimuli in the software implementation for human memory circular mechanism using memory model, visual data processing, and signal processing in cognitive science. Especially, this paper proposes a noble scheme for a lower dimensional abstracted and conceptualized representation of higher dimensional visual stimuli in human vision-memory circular model. The proposed scheme employes generative model based auto encoder and clustering for representing high-dimension visual input data as low-dimension attribute data. In this process, SDR (Sparse Distributed Representation) is used for low-dimension attribute representation, because it can guarantee semantic embedding and distance between classes. In this paper, the experimental results applied to the MNIST and Fashion MNIST datasets, which consist of 28x28 pixels, confirmed from the classifier point of view that the low-dimensional SDRs for each class obtained well reflect their respective characteristics. The experiment confirmed that even if 784 dimensions were changed to 10 dimensions, low-dimensional expressions converted at a classification error level of less than 2% could sufficiently express high-dimensional inputs."
SNS 사용자 특성과 확증 편향을 통한 자동화된 팩트체킹의 가능성 : 정치인 관련 트윗 데이터를 중심으로,2019,"['팩트체크', '소셜 미디어', '기계 학습', '거짓 정보', '확증 편향', 'Fact-checking', 'machine learning', 'SNS', 'confirmation bias']",,
An Analysis of Korean-English Translation Errors in Google Translate,2019,"['Google Translate', 'error analysis', 'Korean to English translation', 'machine translation']",,"The purpose of this study is to identify types of errors that occur when using Google Translate and to suggest more effective ways to benefit from machine translation translators. The topics in the 30 news articles dealt with health and diet. The researchers directed the error analysis by comparing the English translation of the original Korean text with the eleven categories and their sub-categories. Among those translated by the Google Translate Program, according to our research, the number of sentences that contained errors was 365 (67.2%) and that of correct sentences was 178 (32.8%). Sentence structure errors, the highest of the eleven categories, recorded 172 (21.31%) cases, followed by nouns with 143 (17.72%), and verbs with 119 (14.75%). The findings emphasize the need to learn how to use machine translators effectively. Finally, Google Translate users need to avoid using complex sentences and vague words when translating Korean text into English."
Principal weighted logistic regression for sufficient dimension reduction in binary classification,2019,"['Binary classification', 'Model-free feature extraction', 'Weighted logistic regression']",,"Sufficient dimension reduction (SDR) is a popular supervised machine learning technique that reduces the predictor dimension and facilitates subsequent data analysis in practice. In this article, we propose principal weighted logistic regression (PWLR), an efficient SDR method in binary classification where inverse-regression-based SDR methods often suffer. We first develop linear PWLR for linear SDR and study its asymptotic properties. We then extend it to nonlinear SDR and propose the kernel PWLR. Evaluations with both simulated and real data show the promising performance of the PWLR for SDR in binary classification."
환경요인을 이용한 다층 퍼셉트론 기반 온실 내 기온 및 상대습도 예측,2019,"['기계학습', '딥러닝', '비모델 예측', '인공신경망', 'artificial neural network', 'deep learning', 'machine learning', 'mango', 'model-free prediction']","온도와 상대습도는 작물 재배에 있어서 중요한 요소로써, 수량과 품질의 증대를 위해서는 적절히 제어 되어야한다. 그리고 정확한 환경 제어를 위해서는 환경이 어떻게 변화할지 예측할 필요가 있다. 본 연구의 목적은 현시점의 환경 데이터를 이용한 다층 퍼셉트론(multilayer perceptrons, MLP)을 기반으로 미래 시점의 기온 및 상대습도를 예측하는 것이다. MLP 학습에 필요한 데이터는 어윈 망고(Mangifera indica cv. Irwin)을 재배하는 8 연동 온실(1,032m2)에서 2016년 10월 1일부터 2018년 2 월 28일까지 10분 간격으로 수집되었다. MLP는 온실내부 환경 데이터, 온실 외 기상 데이터, 온실 내 장치의 설정 및 작동 값을 사용하여 10~120분 후 기온 및상대습도를 예측하기 위한 학습을 진행하였다. 사계절이뚜렷한 우리나라의 계절에 따른 예측 정확도를 분석하기위해서 테스트 데이터로 계절별로 3일간의 데이터를 사용했다. MLP는 기온의 경우 은닉층이 4개, 노드 수가128개일 때(R2 = 0.988), 상대습도는 은닉층 4개, 노드수 64개에서 가장 높은 정확도를 보였다(R2 = 0.990).MLP 특성상 예측 시점이 멀어질수록 정확도는 감소하였지만, 계절에 따른 환경 변화에 무관하게 기온과 상대습도를 적절히 예측하였다. 그러나 온실 내 환경 제어 요소 중 분무 관수처럼 특이적인 데이터의 경우, 학습 데이터 수가 적기 때문에 예측 정확도가 낮았다. 본 연구에서는 MLP의 최적화를 통해서 기온 및 상대습도를 적절히예측하였지만 실험에 사용된 온실에만 국한되었다. 따라서 보다 일반화를 위해서 다양한 장소의 온실 데이터 이용과 이에 따른 신경망 구조의 변형이 필요하다.","Temperature and relative humidity are important factors in crop cultivation and should be properly controlled for improving crop yield and quality. In order to control the environment accurately, we need to predict how the environment will change in the future. The objective of this study was to predict air temperature and relative humidity at a future time by using a multilayer perceptron (MLP). The data required to train MLP was collected every 10 min from Oct. 1, 2016 to Feb. 28, 2018 in an eight-span greenhouse (1,032 m2) cultivating mango (Mangifera indica cv. Irwin). The inputs for the MLP were greenhouse inside and outside environment data, and set-up and operating values of environment control devices. By using these data, the MLP was trained to predict the air temperature and relative humidity at a future time of 10 to 120 min. Considering typical four seasons in Korea, three-day data of the each season were compared as test data. The MLP was optimized with four hidden layers and 128 nodes for air temperature (R2 = 0.988) and with four hidden layers and 64 nodes for relative humidity (R2 = 0.990). Due to the characteristics of MLP, the accuracy decreased as the prediction time became longer. However, air temperature and relative humidity were properly predicted regardless of the environmental changes varied from season to season.For specific data such as spray irrigation, however, the numbers of trained data were too small, resulting in poor predictive accuracy. In this study, air temperature and relative humidity were appropriately predicted through optimization of MLP, but were limited to the experimental greenhouse. Therefore, it is necessary to collect more data from greenhouses at various places and modify the structure of neural network for generalization."
자동화기반의 가짜 뉴스 탐지를 위한 연구 분석,2019,"['Fake news', 'Fake Information', 'Fake News Challenge', 'Maching Learning', 'Deep Learning', '가짜 뉴스', '가짜정보', '가짜 뉴스 챌린지', '머신러닝', '딥러닝']","가짜 정보를 탐지하기 위한 연구는 2016년 미국 대통령 선거 이후 본격적으로 시작되었다. 정확한 출처를 알 수 없는 정보들이 뉴스 형식으로 생산되고, 이는 자극적이고 흥미로운 소재에 많은 관심을 보이는 대중의 특성에 따라 빠른 속도로 확산되고 있다. 또한, 소셜 네트워크 서비스 등 정보를 전달하기 쉬운 플랫폼의 대중화는 이러한 현상을 더욱 악화시킨다. Poynter는 IFCN(International Fact Checking Network)를 만들어 숙련된 전문가들이 사실 여부를 판단할 수 있는 가이드라인을 제시하고, 팩트 체크 기관을 위한 강령을 제공하고 있다. 하지만 이러한 접근 방법은 하나의 기사에 대한 진위 여부를 검증하기 위해 다수의 전문가 인력이 투입되어야 하므로 시간 및 금전적 비용이 크다. 따라서 지속적으로 증가하는 가짜 뉴스에 효율적으로 대응할 수 있는 자동화된 가짜 뉴스 탐지 기술에 대한 연구가 주목받고 있다. 본 논문에서는 최근 딥러닝 기술의 접목으로 인해 빠르게 발전하고 있는 가짜 뉴스 탐지 시스템과 연구들을 정리 및 분석한다. 또한, 많은 연구가 필요한 본 분야에 연구자들이 쉽게 접근할 수 있도록 다양한 형태로 주어지는 학습 말뭉치 및 챌린지들도 정리한다.","Research in detecting fake information gained a lot of interest after the US presidential election in 2016. Information from unknown sources are produced in the shape of news, and its rapid spread is fueled by the interest of public drawn to stimulating and interesting issues. In addition, the wide use of mass communication platforms such as social network services makes this phenomenon worse. Poynter Institute created the International Fact Checking Network (IFCN) to provide guidelines for judging the facts of skilled professionals and releasing “Code of Ethics” for fact check agencies. However, this type of approach is costly because of the large number of experts required to test authenticity of each article. Therefore, research in automated fake news detection technology that can efficiently identify it is gaining more attention. In this paper, we investigate fake news detection systems and researches that are rapidly developing, mainly thanks to recent advances in deep learning technology. In addition, we also organize shared tasks and training corpus that are released in various forms, so that researchers can easily participate in this field, which deserves a lot of research effort."
유사 날씨 정보를 이용한 건물의 난방 부하 예측 방법,2019,"['prediction of heating load', 'data-driven model', 'KNN algorithm', 'machine learning', '난방 부하 예측', '데이터 기반 모델', 'K-최근접 이웃 알고리즘', '기계학습']","건물의 냉난방 부하 예측은 다음날의 냉난방 공조 장치의 효율적인 운영 계획을 수립하기 위한 필수요소이며, 정확한 냉난방 부하 예측은 건물의 에너지 절감을 이끌어낸다. 본 연구는 기상정보 데이터를 기반으로 유사한 날씨를 보인 날의 실측 냉난방 부하를 K-Nearest Neighbor Algorithm으로 분류하고, 이를 입력 변수에 포함한다. 제안하는 방법의 성능을 검증하기 위해 기상정보 데이터만 이용하여 Artificial Neural Network, Recurrent Neural Network, Particle Swarm Optimization Neural Network 알고리즘을 적용한 방법과 체감온도와 유사한 날씨의 실측 난방부하를 추가한 본 제안 방법의 결과를 비교하였다. 또한 동적해석법을 이용한 난방 부하 예측 방법과도 비교하였으며, 비교결과 본 연구에서 제안하는 방법이 가장 정확한 난방 부하 예측 성능을 보였다.","Prediction of the heating load of a building is essential for planning the efficient next-day operation of heating, ventilation, and air conditioning equipment. Accurate prediction of heating and cooling load leads to energy saving in buildings. This paper classifies the heating and cooling loads under similar weather conditions with a K-nearest neighbor algorithm based on weather information data and uses it as an input variable. To verify the performance of the proposed method with the added heating load under similar weather conditions, we compared the method with the results of an artificial neural network, a recurrent neural network, and a particle swarm optimization neural network algorithms using only weather information data were employed. In addition, we compared the proposed method with heating load prediction using dynamic analysis, and It was observed that the proposed method led to accurate results."
LSTM 모델기반 리튬이온 배터리 SOH 예측알고리즘 구현,2019,"['vehicle(EV)', 'Urban dynamometer driving schedule(UDDS)', 'State-of-health(SOH)', 'Machine learning', 'Artificial neural network(ANN)', 'Long short term memory(LSTM)']",,"The state-of-health(SOH) information of a rechargeable lithium-ion battery is dependent on variable electric vehicle(EV)’s output features caused by frequent discharging/charging current, temperature, and state-of-charge(SOC) operating range. Above all, the most important thing to be checked is this SOH information should be correctly predicted for providing guarantee lithium-ion battery statuses to EV users. For this goal, critical aging factors that results in battery management system(BMS) performance should be obtained by various experiments and be reflected in a sophisticated study. Therefore, this paper introduces two steps for accomplishing an improved SOH prediction of a rechargeable lithium-ion battery. The first step is to perform aging factors extraction and their correlation analyses based on experiments using urban dynamometer driving schedule(UDDS) current profile. From this step, the long short term memory(LSTM) used to predict nonlinear and time-series datasets is newly proposed in the second step. According to the comparison with the recurrent neural network(RNN)-based SOH and clear verification, this paper provides the effectiveness of the SOH prediction."
이산 월시 변환이 메타모델을 사용한 유전 알고리즘에 미치는 영향,2019,"['이산 월시 변환', '메타모델', '유전 알고리즘', '기계 학습', '서포트 벡터 머신', 'Discrete Walsh Transform', 'Metamodel', 'Genetic Algorithms', 'Machine Learning', 'Support Vector Machine']","유전 알고리즘에서 해의 적합도를 계산하는 시간이 오래 걸린다면 메타모델을 만드는 것은 필수적이다. 이에 메타모델의 성능을 높여 유전 알고리즘이 더 좋을 해를 찾게 하기 위한 연구가 진행되어 왔다. 본 연구에서 우리는 이산적인 도메인에서 이산 월시 변환을 사용해 메타모텔의 성능을 높이고자 하였다. 이산 월시 변환을 통해 해의 기저를 변환했고 변환된 해를 사용해 메타모델을 만들었다. 의사-불리언 함수의 대표적인 함수인 NK 모형을 대상으로 실험했고 제안된 모델의 성능에 대한 실증적인 증거를 제공했다. 제안된 모델을 사용해 유전 알고리즘을 수행했을 때, 유전알고리즘이 더 좋은 해를 찾음을 확인했다. 특히, 선행 연구인 유사도 함수를 이산적인 도메인에 적합하게 수정한 방사기저 함수 네트워크보다 좋은 성능을 보였다.","If it takes much time to calculate the fitness of the solution in genetic algorithms, it is essential to create a metamodel. Much research has been completed to improve the performance of metamodels. In this study, we tried to get a better performance of metamotel using discrete Walsh transform in discrete domain. We transforms the basis of the solution and creates a metamodel using the transformed solution. We experimented with NK-landscape, a representative function of the pseudo-boolean function, and provided empirical evidence on the performance of the proposed model. When we performed the genetic algorithm using the proposed model, we confirmed that the genetic algorithm found a better solution. In particular, our metamodel showed better performance than that using the radial basis function network that modified the similarity function for the discrete domain."
효율적인 고차원 데이터 처리를 위한 N차원 볼의 체적 집중에 대한 분석,2019,"['High-dimensional data', 'N-dimensional ball', 'Volume concentration', 'Data sample distribution', 'Machine learning']",,"This paper presents the volume concentration analysis of an n-dimensional ball (n-ball) defined in Euclidean space, near the surface and the equator, for efficient high-dimensional data processing. To quantify the volume concentration of an n-ball, two measures are defined: one measure as the volume ratio of a whole n-ball to the differential slice near the surface, and the other as the volume ratio of a whole n-ball to the differential slice near the equator. Without direct computation of the volumes of n-dimensional geometrical objects, both measures can be obtained as a function of the dimension of ball and the thickness of differential slice. According to computer simulation results for an n-ball, the surface volume concentration and the equator volume concentration show the changing patterns similar to each other, but the surface volume concentration is significantly stronger than the equator volume concentration. Finally, by interpreting the volume concentration of an n-ball as the distribution of high-dimensional data samples, a theoretical basis is provided for the planning of efficient high-dimensional data processing."
국방 AI 지휘통제 플랫폼 구축방안,2019,"['Artificial Intelligence System', 'Command&amp', 'Control', 'Decision-Making', 'C4I', 'Machine Learning &amp', 'Training']",,
컨볼루션 신경망 기반 운동심상을 이용한 뇌의 연결성 분석 및 분류방법,2019,"['brain-computer interface', 'brain connectivity', 'convolutional neural network', 'machine learning', '뇌-컴퓨터 인터페이스', '뇌 연결성', '컨볼루션 신경망', '기계학습']","뇌-컴퓨터 인터페이스 (brain-computer interface; BCI)란 뇌에서 발생한 전기신호를 인공지능 알고리즘을 통해 사용자의의도를 예측하고, 그에 따라 로봇이나 컴퓨터를 제어해주는 기술로 세계 다양한 기관에서 미래 핵심 기술로 손꼽히는기술이다. BCI는 구현하는 방법 (Slow Cortical Potentials, Sensorimotor Rhythms, P300, Steady-State Visually Evoked Potential, Directional Tuning 등)에 따라 다양한 어플리케이션에 이용되고 있다. 하지만 BCI를 실생활에 사용하기 위해서는상황에 따라 시스템을 켜거나 꺼주거나 시스템의 모드 (typing, 로봇 제어, 전동 휠체어 제어 등)를 변경해주어야 한다. 본논문에서는 일반인 피험자 10명을 대상으로 EEG (Electroencephalography)를 측정 및 분석하여 피험자의 다양한 상태(resting, speech imagery, legs-motor imagery, hands-motor imagery)를 구분해내는 알고리즘을 개발하고 그 결과 88.25%의정확도로 상태를 구분할 수 있었다. 이는 BCI 모드 변경을 위한 핵심 알고리즘으로 BCI 기술의 실용화를 앞당길 것으로기대한다.","The brain-computer interface (BCI) is a technology that predicts user’s intention through artificial intelligent algorithm and control robot or computer accordingly and is recognized as a core technology for the future by various organizations around the world. BCI is used in various applications according to the implementation method (Slow Cortical Potentials, Sensorimotor Rhythms, P300, Steady State Visually Evoked Potential, Directional Tuning, etc). However, to use BCI in real life, it is necessary to turn on/off the system according to the situation or to change the system mode (typing, robot control, electric wheelchair control, etc). In this paper, we developed an algorithm to measure various states (resting, speech imagery, legs-motor imagery, hands-motor imagery) of subjects by measuring and analyzing EEG in 10 subjects and as a result, we were able to distinguish the state with an accuracy of 88.25%. We expected that BCI technology would be put into practical use as a critical algorithm for changing BCI mode."
Adaptive LASSO를 통한 진로결정 관련 변수 탐색,2019,"['진로결정', '벌점회귀모형', '기계학습', 'LASSO', 'adaptive LASSO', '한국아동청소년패널(KCYPS) career decision', 'penalized regression', 'machine learning', 'LASSO', 'adaptive LASSO', 'KCYPS']","본 연구는 한국청소년정책연구원의 한국아동청소년패널(Korea Children Youth Panel Survey; KCYPS) 중1패널 6차년도 자료에 기계학습 기법 중 벌점회귀모형으로 분류되는 adaptive LASSO를 적용하여 진로결정 관련 변수를 탐색하였다. Adaptive LASSO는 LASSO를 개선한 방법으로 변수 선택과 회귀계수 산출이 동시에 가능하며, 변수 선택 일치성을 충족한다는 장점이 있다. KCYPS의 고등학교 3학년 1,938명이 응답한 326개의 설명변수 중 학교/학력, 지적발달, 사회정서발달, 진로계획 영역(이상 개인발달) 변수 17개, 가정환경, 교육환경, 지역사회환경, 매체환경, 활동/문화 환경 영역(이상 발달환경) 변수 14개의 총 31개의 변수가 진로결정 관련 변수로 선택되었다. 본 연구 결과, 정서문제, 진로정체감, 양육방식, 학교생활적응과 같이 선행연구에서 연구된바 있는 기존 변수들을 확인하였으며, 이와 함께 직업관, 지역사회 인식, 휴대전화 보유여부, 체험활동 및 동아리 활동 참여 유무와 같은 새로운 변수들을 탐색할 수 있었다. 자신의 적성을 인지하고 직업의 세계를 탐색하도록 돕는 진로교육의 중요성이 증대되고 있는 시점에 본 연구는 교육적 개입이 어떤 방향으로 나아가야할지 제시하였으며, 심층 연구가 필요한 일부 변수에 대한 후속 연구 또한 제안하였다.","The current study explored variables relating to students’ career decisions, using 7th graders’ 6th wave panel of KCYPS. In particular, adaptive LASSO was employed among penalized regression techniques. Despite its strength in variable selection, LASSO is known to produce inconsistent coefficient estimates. In response to the LASSO shortcoming, adaptive LASSO was proposed as a technique to yield consistent estimates. A total of 326 variables responded by 1,938 12th graders were investigated in the adaptive LASSO model and 31 variables were selected as important after relevance counts. The selected 31 variables included 17 and 14 variables from personal development and development environment sections, respectively. Among the 31 selected variables, those regarding emotional problems, career identity, parents’ parenting style, and school adaptation have been investigated in previous research. Newly found variables included variables relating to sense of occupation, community awareness, cell phone possession, and extracurricular activities. The importance of career education is increasingly stressed, as career education helps students recognize their aptitudes and explore possible occupations. Some of the selected variables have practical implications, as educational intervention is possible with them. Further research topics were also suggested."
Diagnostic and Therapeutic Model for Korean Major Depressive Disorder Using Multi-Modal Data,2019,"['우울증', '진단 모델', '약물 반응성', '기계 학습', 'depression', 'diagnostic model', 'drug response', 'machine learning']",,
영상에서 다중 객체 추적을 위한 CNN 기반의 다중 객체 검출에 관한 연구,2019,"['Object Detection', 'Object Tracking', 'Convolutional Neural Network(CNN)', 'Machine Learning']",,"Recently, video monitoring system technology has been rapidly developed to monitor and respond quickly to various situations. In particular, computer vision and related research are being actively carried out to track objects in the video. This paper proposes an efficient multiple objects detection method based on convolutional neural network (CNN) for multiple objects tracking. The results of the experiment show that multiple objects can be detected and tracked in the video in the proposed method, and that our method is also good performance in complex environments."
Design of Video Advertisement Analysis via Analysis of Internet Term Sensitivity,2019,"['기계학습', '오피니언 마이닝', '광고 효과 분석 시스템', '동영상', '유튜브', '감성 분석', 'machine learning', 'opinion mining', 'advertisement analysis service', 'video', 'youtube']",,
Exploring Simultaneous Presentation in Online Restaurant Reviews : An Analysis of Textual and Visual Content,2019,"['Online Restaurant Review', 'Simultaneous Presentation', 'Image Mining', 'Topic Modeling', 'Machine Learning']",,
IR-UWB 레이다를 이용한 모션 인식에 관한 연구,2019,"['IR-UWB Radar', 'Motion Recognition', 'Radar Signal Processing', 'Machine Learning', 'HOG/SVM']",,"Ultra-wideband(UWB) is a technology that can transmit and receive signals at high speeds using a very short signal of wideband of several GHz, and has been recently used in the field of radar technology. Impulse radio(IR)-UWB radar is used in the field of motion recognition with high resolution. In this work, we studied motion recognition using IR-UWB radar. We constructed a development environment to acquire data about motion and implemented a signal processing algorithm for performance enhancement. Based on the signal processing result, the performance was verified through feature extraction and learning of motion."
심층인공신경망(DNN)과 다각도 상황 정보 기반의 서울시 도로 링크별 교통 혼잡도 예측,2019,"['심층 인공 신경망', '기계학습', '도로 혼잡도 예측', '빅데이터', '상황인지', 'Deep Neural Networks', 'Machine Learning', 'Prediction of Traffic Congestion', 'Big Data Analysis', 'Multi-lateral Context Awareness']","여러 대도시에서 교통 혼잡 문제를 해결하기 위해 정확한 교통 흐름을 예측하는 다양한 연구가 진행되었다. 대부분의 연구가 과거의 교통 흐름 패턴이 미래에도 반복될 것이라는 가정하에 예측 모델을 개발하였으나 교통사고 등과 같은 뜻하지 않은 비반복적 교통 패턴을 예측하는 데에는 신뢰성이 낮게 나타났다. 이런 문제를 해결하기 위한 대안으로 지능형 교통 시스템(ITS)을 통해 얻은 빅데이터와 인공지능을 접목한 교통 흐름 예측 연구가 진행되어 왔다. 하지만 시계열 분석에 일반적으로 사용되는 알고리즘인 RNN의 경우, 단기 예측에 최적화되어장기 예측 정확도가 낮다는 단점을 가지고 있다. 이런 문제를 해결하기 위해 본 논문에서는기온과 강수량 등의 기상 정보 외에도 각종 외부 요인들을 고려하여 장기적 시점에서 교통 혼잡도를 예측하는 '심층 인공 신경망 모델'을 제안하였다. TOPIS 자료를 이용한 사례 연구 결과서울시 주요 도로 링크의 교통 혼잡도를 90%에 가까운 정확도로 예측이 가능하였다. 추후 교통사고나 도로 공사와 같은 도로에 영향을 미치는 이벤트 데이터를 추가로 확보할 수 있다면정확도는 더욱 높아질 것으로 예상된다.","Various studies have been conducted to solve traffic congestions in many metropolitan cities through accurate traffic flow prediction. Most studies are based on the assumption that past traffic patterns repeat in the future. Models based on such an assumption fall short in case irregular traffic patterns abruptly occur. Instead, the approaches such as predicting traffic pattern through big data analytics and artificial intelligence have emerged. Specifically, deep learning algorithms such as RNN have been prevalent for tackling the problems of predicting temporal traffic flow as a time series.However, these algorithms do not perform well in terms of long-term prediction. In this paper, we take into account various external factors that may affect the traffic flows. We model the correlation between the multi-dimensional context information with temporal traffic speed pattern using deep neural networks. Our model trained with the traffic data from TOPIS system by Seoul, Korea can predict traffic speed on a specific date with the accuracy reaching nearly 90%. We expect that the accuracy can be improved further by taking into account additional factors such as accidents and constructions for the prediction."
Application of Google Search Queries for Predicting the Unemployment Rate for Koreans in Their 30s and 40s,2019,"['30s and 40s Unemployment', 'Web Search Query', 'Prediction', 'SARIMA Model', 'Machine Learning', '30~40대 실업률', '웹 검색어', '예측', 'SARIMA 모형', '머신러닝']",,"Prolonged recession has caused the youth unemployment rate in Korea to remain at a high level of approximately 10% for years. Recently, the number of unemployed Koreans in their 30s and 40s has shown an upward trend. To expand the government’s employment promotion and unemployment benefits from youth-centered policies to diverse age groups, including people in their 30s and 40s, prediction models for different age groups are required. Thus, we aimed to develop unemployment prediction models for specific age groups (30s and 40s) using available unemployment rates provided by Statistics Korea and Google search queries related to them. We first estimated multiple linear regressions (Model 1) using seasonal autoregressive integrated moving average approach with relevant unemployment rates. Then, we introduced Google search queries to obtain improved models (Model 2). For both groups, consequently, Model 2 additionally using web queries outperformed Model 1 during training and predictive periods. This result indicates that a web search query is still significant to improve the unemployment predictive models for Koreans. For practical application, this study needs to be furthered but will contribute to obtaining age-wise unemployment predictions."
데이터 기반 경로 선별을 통한 상용 정적분석기의 성능 향상 방법,2019,"['static program analysis', 'path-sensitivity', 'data-driven program analysis', 'machine learning', '프로그램 정적 분석', '경로 민감 분석', '데이터 기반 프로그램 분석', '기계학습']","데이터에 기반한 경로 선별을 통해 상용 정적분석기의 성능을 높이는 방법을 제안한다. 경로에 민감한(path-sensitive) 분석은 상용 정적분석기가 일반적으로 채택하는 기법이며, 어떤 경로를 골라 분석하느냐에 따라 분석비용과 검출하는 오류 수가 달라진다. 이 논문은 손수 튜닝된 경로 선별 휴리스틱을 장착한 기존 상용 정적분석기로부터 비용 대비 효과가 좋은 새로운 경로 선별 휴리스틱을 자동으로 학습하는 방법을 제안한다. 분석기 코드에서 추출한 특징(feature)과 벤치마크 프로그램의 분석결과에 기대어 학습한다. 이 방법을 스패로우(Sparrow)의 상용 C 소스코드 정적분석기와 17개의 C 오픈소스 벤치마크에 적용한 결과, 대표적인 17종 대상오류에 대해 기존 분석 대비 90.8%의 오류를 38%의 분석시간에 검출할 수 있었다. 이는 기존 분석기의 경로 선별 휴리스틱을 따르되 탐색하는 경로의 개수만 유사한 조건으로 제한했을 때보다 더 많은 오류를 더 짧은 시간에 검출한 것이다.","We propose a data-driven method to improve path-sensitive industrial-strength static analyzers. Most industrial static analyzers adopt path-sensitive techniques and path selection holds the key to their performance. We propose a method to automatically learn new cost-effective path-selection heuristics from an existing analyzer with a manually tuned path-selection heuristic. We evaluated our method on an industrial static C code bug-finder from Sparrow as a baseline analyzer with 17 C open-source benchmark programs. The experimental results showed that with the newly-learned path-selection heuristic, the analyzer reported 90.8% of the defects in only 38% of the analysis time, compared to the baseline analysis. This method reported more defects in less time than the baseline path-selection heuristic under similar path search space constraints."
소셜 미디어 참여에 관한 연구 동향과 쟁점의 변화: 네트워크 분석과 클러스터링 기법을 활용한 메타 분석을 중심으로,2019,"['Social Media', 'Online Participation', 'Meta-analysis', 'Main Path Analysis', 'Social Network Analysis', 'Machine Learning', 'Natural Language Processing', '소셜 미디어 참여', '온라인 참여', '메타분석', '주경로 분석', '사회 연결망 분석', '머신러닝', '클러스터링', '자연어 처리']",본 연구는 소셜 미디어 참여 관련 연구 베타분석을 위해 네트워크 분석과 클러스터링 기법을 활용하였다.주경로 분석 결과 37개의 주요 연구가 추출되었고 커뮤니티 관련 네트워크와 뉴 미디어 관련 네트워크 두 가지로 구분되었다. 연결망 분석과 클러스터링 결과 네가지 클러스터가 형성되었다. 본 연구는 학술 데이터를 활용해 연구 동향을 거시적으로 파악하며 그 방법론으로 네트워크 분석과 기계학습을 활용하였다는 학술적 의의를 가진다.,
금융 데이터 및 텍스트 데이터를 활용한 금융 기업 조기 경보 모형 개발 : 부실은행 예측을 중심으로,2019,"['Early Warning Model', 'Unstructured Text Data', 'Text Mining', 'Machine Learning']",,"The early warning model, one of the risk management models for financial companies, was introduced to detect inadvance the capital adequacy crisis of financial institutions. The existing early warning models have mainly usedpredictive models with structured data-based variables such as various macroeconomic indicators and enterpriseinternal indicators. The purpose of this study is to further improve the performance of the early warning models byapplying customer complaints data and news articles related to individual financial institutions to machinelearning-based model. As a result of applying this technique to actual data over the period of 2001 to 2017, themethodology proposed in this study has demonstrated a performance improvement up to 20%p compared to theexisting methodology in certain evaluation metrics."
The extension of the largest generalized-eigenvalue based distance metric D<sub>ij</sub>(γ<sub>1</sub>) in arbitrary feature spaces to classify composite data points,2019,"['classification', 'clustering', 'composite data points', 'limiting dispersion map', 'linear(non-linear) transformation function', 'sets of sequences', 'statistical learning']",,"Analyzing patterns in data points embedded in linear and non-linear feature spaces is considered as one of the common research problems among different research areas, for example: data mining, machine learning, pattern recognition, and multivariate analysis. In this paper, data points are heterogeneous sets of biosequences (composite data points). A composite data point is a set of ordinary data points (e.g., set of feature vectors). We theoretically extend the derivation of the largest generalized eigenvalue-based distance metric D<sub>ij</sub>(γ<sub>1</sub>) in any linear and non-linear feature spaces. We prove that D<sub>ij</sub>(γ<sub>1</sub>) is a metric under any linear and non-linear feature transformation function. We show the sufficiency and efficiency of using the decision rule $\bar{{\delta}}_{{\Xi}i}$(i.e., mean of D<sub>ij</sub>(γ<sub>1</sub>)) in classification of heterogeneous sets of biosequences compared with the decision rules min<sub>𝚵i</sub>and median<sub>𝚵i</sub>. We analyze the impact of linear and non-linear transformation functions on classifying/clustering collections of heterogeneous sets of biosequences. The impact of the length of a sequence in a heterogeneous sequence-set generated by simulation on the classification and clustering results in linear and non-linear feature spaces is empirically shown in this paper. We propose a new concept: the limiting dispersion map of the existing clusters in heterogeneous sets of biosequences embedded in linear and nonlinear feature spaces, which is based on the limiting distribution of nucleotide compositions estimated from real data sets. Finally, the empirical conclusions and the scientific evidences are deduced from the experiments to support the theoretical side stated in this paper."
Development of a UAV Object Tracking OpenCV for Smart Security,2019,"['드론', '농업', '소프트웨어 아키텍처', '기계 학습', 'OpenCV', '모델기반 테스팅', 'Drone', 'ICT Agriculture', 'Software Architecture', 'Machine Learning', 'OpenCV', 'ModelBased Test']",,"Lions and elephant, cows roam around the farm to kill and destroy farmer livestock now in africa area. For this reason, productivity in agriculture decreases over time resulting in poor production of crops and even killing of poultry animals. The Development Drone for Driven Agriculture based on IoT Technology provides an effective way to ensure the protection of farms and agriculture against wild animals. An automatic Drone fly after receiving a signal from server Open CV to hunt wild animals outside the farm. The output of Object detection is also the highlight of this project.In this paper, we also discuss the Open CV harr Cascades using Python for image detection and Drone operation to meet farm’s requirement. The UAV Drone is flown for hunting wild animals outside farm which is to prevent breach in farm security. Furthermore, the UAV Drone was developed through UAV technologies, with functionalities necessary for the successful deployment of a fully autonomous UAV operation over agriculture and traffic networks. The UAV is able to navigate autonomously at different altitudes, plan for mission goals such as locating, identifying, tracking and the development of reliable software and hardware architectures. This paper proposes a UML diagram including the design of the Unmanned Aerial Vehicle system and software in it. The software is called embedded software. Model-based testing is a resolution for testing embedded software."
Change detection in urban landscapes: a tensor factorization approach,2019,"['Data mining', 'Spatiotemporal mining', 'Change detection', 'Remote sensing']",,"Analysis of urban landscape has been an interesting research challenge for decades. The advent of machine learning and data mining techniques have geared the problem from simple analysis of data to knowledge discovery from data. This work attempts to mine urban landscapes to find the change pattern which has happened over the region for a period of interest. The work proposes a spatiotemporal-metric miner, which uses the spatial, temporal and landscape metric data to discover the change that has occurred in a region. The model works on a hierarchical basis, wherein, the regions of interest are chosen in a landscape and are aggregated to find the change that has happened over the entire region. The entire model is built by taking advantage of the tensorized representation of data, and thus resulting in the effective mining of tensors. The growth of a landscape is evaluated regarding two parameters, namely, Inter-class Growth Index and Intra-class Growth Index. Experiments are performed on the landscape regions of Indian cities, and a ranking of cities is presented based on the growth indices, which are validated against standards. In the experiments, Jaipur city showed the highest Inter-class Growth Index value of 2.68 and Surat city had an Intra-class Growth Index of 0.78."
Teat detection algorithm: YOLO vs. Haar-cascade,2019,"['Automatic milking systems', 'Haar-cascade', 'Teat detection', 'YOLO']",,"In this study we have developed and experimented with two methods of teat detection based on machine learning approach in image recognition and object detection. Automatic milking systems rely strongly on the vision system for successful milking operation initiation which is the attachment of the teat cups correctly. Teat detection method currently employed in the industry is based on laser assisted edge detection mechanism, making the current systems less advanced than the existing methods in the field of image processing and robotic vision. By experimenting on a basic object detection method based on Haar-like features, viz. Haar cascade classification method and a latest state-of-the-art method based on convolutional neural nets, viz. YOLO-object detection method, we have compared the results of detection on a fake teat model casted from silicon, especially for indoor environments. This study is in extension to the successful real time detection in a cow farm using Haar-cascade based algorithm."
공무원 이직의도의 연관요인에 대한 추론과 예측에 관한 연구,2019,"['공무원 이직의도', '연관요인', '예측', 'Lasso', 'Public Officer’s Turnover Intention', 'Association Factors', 'Prediction', 'Lasso Regressionmachine learning']","정부 조직의 변화가 계속되면서 조직 안정성이 흔들리고 이에 따라 조직 구성원인 공무원들이 이직의도를 품거나 실제 이직을 결정할 가능성이 높아지고 있다. 이에 따라 공무원들의 이직의도와 연관이 있는 요인들을 찾아 인사관리에 적극 반영하여 공무원들의 이직을 줄일 필요가 있다. 본 연구에서는 한국행정연구원의 ‘2018 공직생활실태조사’ 결과를 이용하여, 공무원의 이직의도와 연관이 있는 요인들을 살펴보고 또 공무원들의 이직의도에 대한 예측을 해보고자 하였다. 로지스틱 회귀분석 모형을 사용한 결과, 공무원들의 이직의도와 통계적으로 유의미한 연관이 있는 요인으로 승진이나 보수, 복지뿐만 아니라 리더십, 조직문화, 직무스트레스, 조직몰입, 공직만족도 등의 26가지 요인들이 제시되었다. 또 로지스틱 회귀분석 모형과 함께, 머신러닝 기법 중 하나인 Lasso 회귀분석 방법을 이용하여 실제로 공무원들의 이직의도를 예측할 수 있는 방법을 살펴보았다. 예측 실행 결과, Lasso 로지스틱 회귀분석 모형이 일반 로지스틱 회귀분석 모형보다 근소하게 예측력이 높았으나, 두 모형 다 약 70%를 약간 상회하는 정도의 정확성을 보였다.","The continuing changes occurring in the government organization shake the organization’s stability, increasing the risk of public officers’ turnover. To reduce the potential harm that a high turnover rate of public officers may impose on the organization, an active approach to public personnel management by addressing known turnover-related factors in the personnel system is required. This study attempts to infer the factors associated with public officer’s turnover intention and to predict their actual turnover intention, using a large-sized public officer survey conducted in 2018 and the ordinary and Lasso logistic regression methods. For the association factor inference, we identified 26 factors, including promotion, wages, leadership, organization culture, job stress, and job commitment, that were statistically significantly associated with the public officer’s turnover intention by using the ordinary logistic regression methods. For the turnover intention prediction based on the association factors, both the ordinary and Lasso logistic regression models predicted whether a public officer had a turnover intention correctly for over 70% of the new test sample, but the Lasso logistic regression model had a slightly better prediction power than the ordinary logistic regression model had."
에어비앤비(Airbnb) 웹 로그 데이터를 이용한 고객 행동 예측,2019,"['웹 로그', '고객 행동 예측', '기계학습', '데이터 마이닝', 'web log', 'customer behavior prediction', 'machine learning', 'data mining']","그동안의 고객 행동에 대한 예측은 주로 고객이 가지는 고정적인 특성을 이용해왔다. 최근에는 점차 고객들의 활동이 오프라인에서 온라인으로 이동하면서 각 고객의 웹 로그를 추적하는 일이 가능해졌다. 그러나 방대한 양의 웹 로그 데이터를 수집할 수 있게 된 반면, 이에 대한 연구는 로그 데이터를 정리하거나 기술적인 특성만을 설명하는 것에 그쳤다. 본 연구에서는 웹사이트 Kaggle에서 제공하는 Airbnb 고객들의 성별, 연령 등의 기본 정보 및 웹 로그가 포함된 데이터셋을 이용하여 첫 숙소 예약까지 걸리는 개인의 의사 결정 시간을 예측하였다. Lasso, SVM, Random Forest, XGBoost 등 다양한 방법론을 활용하여 최적의 모형을 찾고, 웹 로그 데이터의 유무에 따른 예측오차를 비교하여 웹 로그의 효용성을 확인하였다. 결과적으로 오분류율이 약 20%로 낮은 랜덤 포레스트 분류모형을 최적모형으로 선택하였다. 또한, 웹 로그 데이터를 이용하여 고객 개개인의 행동을 예측한 결과 사용하지 않은 경우와 비교해 예측의 정확도가 최대 두 배 더 높아진 것을 확인할 수 있었다.","Customers' fixed characteristics have often been used to predict customer behavior. It has recently become possible to track customer web logs as customer activities move from offline to online. It has become possible to collect large amounts of web log data; however, the researchers only focused on organizing the log data or describing the technical characteristics. In this study, we predict the decision-making time until each customer makes the first reservation, using Airbnb customer data provided by the Kaggle website. This data set includes basic customer information such as gender, age, and web logs. We use various methodologies to find the optimal model and compare prediction errors for cases with web log data and without it. We consider six models such as Lasso, SVM, Random Forest, and XGBoost to explore the effectiveness of the web log data. As a result, we choose Random Forest as our optimal model with a misclassification rate of about 20%. In addition, we confirm that using web log data in our study doubles the prediction accuracy in predicting customer behavior compared to not using it."
레이더 추정 및 재밍효과도 분석을 위한 전자전 시뮬레이터 구현,2019,"['전자전 모델링 및 시뮬레이션', '기계학습', '레이더 추정', '재밍효과도 분석', 'Modeling and Simulation of Electronic Warfare', 'Machine Learning', 'Estimation of Radar', 'Analysis of Jamming Effects']","전자전 환경에서 아군 항공기는 생존율 향상을 위하여 적의 레이더 위협을 정확하게 파악하는 것이 필수적이다. 레이더 위협이 존재하는 상황에서 아군 항공기는 레이더가 발산하는 전자정보를 수신하며, 이로부터 레이더의 정체를 추정한다. 본 논문은 추정한 레이더 위협의 검증을 위하여 수집한 전자정보와 재밍결과를 기반으로 유사도 계산을 수행하며, 역추정한 레이더 위협과 가장 유사한 레이더를 데이터베이스로부터 추천한다. 또한, 이러한 전자전 구성요소를 모델링하고 다양한 전자전 환경에서 레이더 위협체에 대한 역추정 및 검증을 반복적으로 수행할 수 있는 전자전 시뮬레이터를 설계 및 구현한다. 개발한 시뮬레이터를 활용하여 유사한 레이더의 추정과 레이더 위협체에 대한 재밍효과도를 분석하는 실험을 수행하였다. 실험에서 역추정한 레이더 위협체와 85%이상의 유사도를 갖는 레이더를 추천함을 확인하였으며, 레이더 시스템의 구성요소 차이에 따른 다양한 재밍의 응답특성을 확인할 수 있었다.","To improve our flight agents’ survivability in electronic warfare settings, it is essential that they should correctly identify what an enemy’s radar is. As our agents perceive electronic information emitted from the radar, they need to reversely extrapolate the radar for their exact situation awareness. This paper proposes a method to recommend the radar from a set of radars in database, which is the most similar to the radar threat, for the purpose of verifying the reverse extrapolation process. The method of recommendation is to compute the degree of similarity using the variables of electronic information perceived and the results of jamming toward the enemy’s radar. We have designed and implemented an electronic warfare simulator that models the components of electronic warfare, i.e., receivers, radars, and jammings, and that repeatedly tests the identification of a radar. Using the simulator, we have also experimented the estimation process of a radar and a series of jamming effectiveness toward the radar threat. It turned out that the similarities between a radar and the enemy threat extrapolated were measured by over 85% of the same radar itself in all of scenarios, and that the resulting feature of jamming with different hardware components of radar could be identified."
토픽 모델링을 이용한 건설현장 추락재해 분석,2019,"['Construction Safety', 'Fall Accident', 'Frequent Analysis', 'Topic Modeling', 'Latent Dirichlet Allocation', '건설안전', '추락재해', '빈도 분석', '토픽 모델링', '잠재 디리클레 할당']","본 연구는 기계학습 기법 중 토픽 모델링을 활용하여 건설현장에서 발생하는 추락재해에 대한 토픽을 분류하고 각 토픽에 따른 재해요인을 분석하였다. 잠재 디리클레 할당 기반의 토픽 모델링을 적용하기 위해 텍스트 데이터의 전처리를 하였고 Perplexity 점수로 평가하여 모형의 신뢰성을 높였다. 각 토픽에서 공통으로 도출된 추락재해의 대부분은 소규모 사업장에 속한 일용직 작업자들에게 발생하였다. 추락재해의 대부분의 원인은 안전장비 미착용, 현장 정리·정돈 미흡, 안전장비의 성능 및 착용 상태로 인해 제대로 작동하지 않은 것으로 판단되었다. 추락재해를 예방하고 절감하기 위해서는 소규모 사업장에 맞는 안전교육과 작업장의 정리·정돈과 개인 안전장비의 적절한 착용 상태 및 성능을 확인하는 것이 중요한 것으로 도출되었다.","We classify topics on fall incidents occurring in construction sites using topic modeling among machine learning techniques and analyze the causes of the accidents according to each topic. In order to apply topic modeling based on latent dirichlet allocation, text data was preprocessed and evaluated with Perplexity score to improve the reliability of the model. The most common falling accidents happened to the daily workers belonging to small construction site. Most of the causes were not operated properly due to lack of safety equipment, inadequacy of arrangement and wearing, and low performance of safety equipment. In order to prevent and reduce the falling accidents, it is important to educate the daily workers of small construction site, arrange the workplace, and check the wearing of personal safety equipment and device."
Support Vector Regression(SVR) 기반의 단기 태양광발전 예측시스템 개발에 관한 연구,2019,"['Photovoltaic Power Forecasting', 'Support Vector Regression(SVR)', 'Day-ahead Forecasting', 'Short-Term Forecasting', 'Machine Learning']",,"Uncertainty and variability in photovoltaic power generation can cause instability in the power system. Accurate photovoltaic power generation forecasts are needed to reduce instability in the system of solar power generation. Forecasting is the most cost-effective method of improving the reliability of the system. In this paper, we propose the short-term photovoltaic power forecasting using support vector regression. Kriging method is used to estimate the solar irradiance of the solar plant. When forecasting solar power through the support vector regression model, the accuracy of the forecasting was high compared to other models."
객체 Attention을 이용한 이미지 캡션 생성,2019,"['어텐션 매커니즘', '심층 학습', '이미지 캡셔닝', '자연어 처리', '기계 학습', 'attention mechanism', 'deep learning', 'image captioning', 'natural language processing', 'machine learning']","이미지 데이터가 폭발적으로 증가함에 따라 이미지를 자연어로 표현하기 위한 이미지 캡션 생성 기술에 대한 연구도 활발하게 이루어지고 있다. 기존 한국어 이미지 캡션 생성 기술에서는 영어권 데이터를 번역하여 사용함으로 인해 동시 발생 객체들에 의한 오류가 있다. 본 논문에서는 입력 이미지에 대한 캡션을 생성하여 추출한 명사와 이미지의 정답 캡션에서 추출한 명사를 이용하는 attention 함수를 새로운 손실 함수로 사용하는 이미지 캡션 모델을 제안한다. 공개된 실험 데이터를 사용한 실험에서 BLEU1 0.686, BLEU2 0.557, BLEU3 0.456, BLEU4 0.372를 보였다. 이를 이용하여 제안된 모델이 고빈도 동시 발생 객체 오류 해결에 효과적임을 입증하고 기존 연구보다 높은 성능을 얻음을 보이며 중복된 출력 문장을 줄임으로써 이미지 캡션의 다양한 표현들이 생성에 효과적임을 보였다. 또한 본 논문에서 제안하는 방법을 이용하여 이미지 캡션 모델을 학습하기 위한 코퍼스를 생성할 수 있다.","Explosive increases in image data have led studies investigating the role of image caption generation in image expression of natural language. The current technologies for generating Korean image captions contain errors associated with object concurrence attributed to dataset translation from English datasets. In this paper, we propose a model of image caption generation employing attention as a new loss function using the extracted nouns of image references. The proposed method displayed BLEU1 0.686, BLEU2 0.557, BLEU3 0.456, BLEU4 0.372, which proves that the proposed model facilitates the resolution of high-frequency word-pair errors. We also showed that it enhances the performance compared with previous studies and reduces redundancies in the sentences. As a result, the proposed method can be used to generate a caption corpus effectively."
드론 및 열화상을 활용한 구조물 재난 안전 평가 SMART SKY EYE 시스템,2019,,,
영화산업에서 빅데이터의 활용방안 연구 - ‘넷플릭스(Netflix)’ 분석기술 중심으로,2019,"['영화산업', '빅데이터', '넷플릭스', '자연어 처리분석', '기계학습 기법', 'Film industry', 'Big data', 'Netflix', 'Natural language processing analysis', 'Machine learning']","최근 문화예술콘텐츠 전반에 빅데이터의 활용은 다양하게 적용되고 있다. 본고에서는 영화산업 분야에서 급속도로 발전되고 있는 거대 공룡기업인 온라인 추천서비스 넷플릭스의 빅데이터 분석기술에 대해 살펴보고, 비슷한 형태의 온라인 추천서비스 기업인 ‘아마존’의 프라임 비디오(Prime Video), 지니(Jinni)와 국내기업 왓챠(Watcha), 애플(Apple)TV+까지 어떠한 분석기술로 서비스를 하는지에 대한 형태도 살펴본다. 앞으로의 빅데이터는 데이터 자체가 스마트화 되며 IoT를 통해 생산량이 급격히 증가될 것으로 기술적으로는 알고리즘과 인공지능이 발달하면서 대용량 데이터 처리에 가속도가 붙을 것으로 전망되며, 개인정보 보호 문제와 함께 미디어 업계와 IT 기술 업계의 긴밀한 협력을 통한 빅데이터 관리전문 인력 확보가 선행되어야 할 것으로 보인다.","Big data is widely applied to cultural and arts content. In this article, we will look at how Netflix, a rapidly developing media company, uses big data by examining their analytical tools as well as those of Amazon’s ‘Prime Video’, ‘Jinni’ the domestic company ‘Watcha’, and ‘Apple TV+’ as points of comparison. In the future, big data will become smarter, and rapidly increase through the popularization of IoT devices. Technically speaking, algorithms and artificial intelligence are expected to improve the processing power of large amounts of data. Finally, media companies and I.T companies must work together to protect data privacy and experts in big data analysis must be recruited as a matter of priority."
"언론학 교육 60년, 어디로 가고 있는가, 어디로 가야 하는 것일까?",2019,"['디지털 혁신', '언론학 교육', '실천적 지식', '디지털 미디어', '기자교육', 'media education', 'digital disruption', 'teaching and learning', 'practical knowledge']","이 연구의 목적은 디지털 테크놀로지의 파괴적 혁신에 당면해서 언론학이 처한 위기의 내용에 주목하였다. 그런 위기의 맥락에서 언론학 교육을 혁신하는 틀을 만들 것이냐는 질문에 대한 답을 찾고자 했다. 미래 언론학 교육의 혁신을 위해 세 가지 제안했다. 첫째, 서열화된 대학위계구조에서 언론학과는 어떻게 무엇을 가르쳐야 할까라는 질문에 답하고자 했다. 이론과 실무라는 이분법을 넘어서서, ‘분과학문을 넘어선 분과학문’ (a discipline beyond discipline)으로 언론학을 설정할 것을 주장했다. 둘째, 포스트휴먼 시대에 기계와 인간의 관계에 대한 철학적 인식론의 재설정이 요구됨을 설명하고, 언론학 교육의 입장에서 다양한 분과학문과 협력을 위해 프로그램 단위의 주제별 모듈이라는 교육틀을 도입할 것을 제안하였다. 마지막으로는 디지털 저널리즘 노동의 불안정성(precarity)에 대응하기 위해 ‘작업에 기반한 교육’을 대안으로 제안하였다.","The purpose of this study is to examine the reform of media education in the context of digital disruption. Looking back at the sixty-year historical trajectory of media and journalism education, this study attempts to illuminate the scope of and the ways in which the media educator re-formulates the changing nature of teaching and learning in the coming age of digital disruption. Three proposals for media education reform were presented. First, this study proposes the integration of theory and production education into the education of practical knowledge. Such an integrated approach is validly applicable even within the hierarchical arrangement of South Korean universities along SAT scores. Second, the study suggests 1) the need to reestablish the philosophical epistemology of the relationship between machines and humans in the post-human era, and 2) the introduction of an educational framework, called ’thematic module of the program unit’, so as to encourage cooperation across various disciplines from the perspective of media education reform. Finally, the study proposes ‘work-based education’ as an alternative to cope with the intensifying precarious nature of the digital media industry’s labor market."
새로운 기술혁명 시대의 임상심리학 -최근 연구 동향을 중심으로-,2019,"['임상심리학', '4차 산업혁명', '심리평가', '심리치료', '인공지능', '기능성 게임', '공유자료', '개인정보보호', 'Clinical psychology', 'The 4th industrial revolution', 'Psychological assessment', 'Psychotherapy', 'Artificial intelligence', 'Serious game', 'Data sharing', 'Privacy protection']","소위 4차 산업혁명은 인공지능, 기계학습과, 빅데이터와 같은 기존에 존재하지 않았던 새로운 기술로 시작되는 혁명이며 임상심리학은 4번째 산업혁명이라는 인류 역사에 중요한 분기점이 되는 거대한 패러다임 변화에 직면해 있다. 본 연구에서는 먼저 4차 산업혁명과 관련된 비인간화를 중심으로 인간과 사회 변화를 살펴보았다. 이어 최근 5년 연구 중심으로 임상심리학의 주요 영역인 심리평가와 심리치료에서 인공지능을 비롯한 새로운 기술들이 어떠한 영향을 미치고 있는지 탐색해 보았다. 더불어 다양한 신기술이 집약되어 있는 기능성 게임 기반 심리평가와 심리치료에 대한 최근 연구들을 탐색하였다. 마지막으로 여러 신기술들 중에서 한국임상심리학자들이 특별한 관심을 가지고 전문 영역에 적용할 필요가 있는 공유데이터와 개인정보 보호에 대한 최근 경향과 의견을 제시하였다.","The Fourth Industrial Revolution is a revolution that begins with new technologies that never existed, such as machine learning, big data, and artificial intelligence. Consequently, clinical psychology should face a huge paradigm shift that is an important turning point in human history. First, this paper briefly introduced human and social changes focusing on dehumanization associated with the Fourth Industrial Revolution. Primarily, it reviewed based on recent 5 years studies how new technologies are influencing on psychological assessment and psychotherapy in the field of clinical psychology. In addition, recent researches on serious game-based psychological assessment and psychotherapy, which are concentrated on various new technologies, were explored. Lastly, it presented current trends and opinions related to the data sharing and the privacy protection which Korean clinical psychologists should pay attention to special interest among the new technologies."
특징선택 기법에 기반한 UNSW-NB15 데이터셋의 분류 성능 개선,2019,"['침입탐지', '특징선택', '데이터 전처리', '희소 클래스', '기계학습', 'IDS', 'Feature selection', 'Data preprocessing', 'Rare class', 'Machine learning']","최근 사물인터넷과 다양한 웨어러블 기기들이 등장하면서 인터넷 기술은 보다 편리하게 정보를 얻고 업무를 수행하는데 기여하고 있으나 인터넷이 다양한 부분에 이용되면서 공격에 노출되는 Attack Surface 지점이 증가하고 있으며 개인정보 획득, 위조, 사이버 테러 등 부당한 이익을 취하기 위한 목적의 네트워크 침입 시도 또한 증가하고 있다. 본 논문에서는 네트워크에서 발생하는 트래픽에서 비정상적인 행동을 분류하기 위한 희소클래스의 분류 성능을 개선하는 특징선택을 제안한다. UNSW-NB15 데이터셋은 다른 클래스에 비해 상대적으로 적은 인스턴스를 가지는 희 소클래스 불균형 문제가 발생하며 이를 제거하기 위해 언더샘플링 방법을 사용한다. 학습 알고리즘으로 SVM, k-NN 및 decision tree를 사용하고 훈련과 검증을 통하여 탐지 정확도와 RMSE가 우수한 조합의 서브셋들을 추출한다. 서브 셋들은 래퍼 기반의 실험을 통해 재현률 98%이상의 유효성을 입증하였으며 DT_PSO 방법이 가장 우수한 성능을 보였다.","Recently, as the Internet and various wearable devices have appeared, Internet technology has contributed to obtaining more convenient information and doing business. However, as the internet is used in various parts, the attack surface points that are exposed to attacks are increasing, Attempts to invade networks aimed at taking unfair advantage, such as cyber terrorism, are also increasing. In this paper, we propose a feature selection method to improve the classification performance of the class to classify the abnormal behavior in the network traffic. The UNSW-NB15 dataset has a rare class imbalance problem with relatively few instances compared to other classes, and an undersampling method is used to eliminate it. We use the SVM, k-NN, and decision tree algorithms and extract a subset of combinations with superior detection accuracy and RMSE through training and verification. The subset has recall values of more than 98% through the wrapper based experiments and the DT_PSO showed the best performance."
일본 기계설계분야 어휘분석 - 기계설계기술자 시험을 중심으로 -,2019,"['lexicon', 'word type', 'basic vocabulary', 'mechanical design', '어휘', '어종', '기본어휘', '기계설계', '語彙、語種、基本語彙、機械設計']",,"This article aims to help learners wishing to work in Japanese machinery and automobile design and manufacturing industries learn vocabulary effectively, and to enhance their work efficiency as well as enhance their Japanese employment capacity.The five-year history of the Japanese Mechanical Design Engineer’s Examination was used as analysis data, and the analysis was limited to nouns. A ratio of words in the upper 25th, 50th, 75th, and 100th positions is investigated by each word type. They also examined the consistency of the analyzed words with the “Basic Bictionary Survey for Japanese Language Education,” which is a survey data of the National Institute of Japanese Language.The results analyzed are as follows: First, the total number of nouns analyzed was 9,276 and the number of different words was 1,622; in the word classification, 65.4% Chinese words, 14.5% foreign words, 12.1% Japanese words, and 8.0% mixed words.Second, by examining the coverage of words by word type, it is confirmed that systematic vocabulary learning is necessary.Thirdly, words within the top 100 of each word category were presented, and many words related to machine design were confirmed except for the basic vocabulary presented by the National Institute of Japanese Language.Fourthly, it was confirmed that the degree of conformity with the basic vocabulary in foreign languages was low. This can be said to indicate that foreign words have many technical terms in the mechanical design field."
최대 수요 전력 저감을 위한 LSTM 기반 ESS 운영 스케줄링 기법,2019,"['에너지 저장 시스템', 'ESS', '최대 수요 전력', 'long short-term memory', 'LSTM', '기계학습', '시계열 데이터', 'energy storage system', 'ESS', 'peak demand', 'long short-term memory', 'LSTM', 'machine learning', 'time-series data']","최근 우리나라의 최대 수요 전력 부하가 급격히 증가함에 따라 정전 확률이 올라가고 있다. 이에 대응하기 위해 energy storage system(ESS)에 저장한 전력을 활용하여 최대 수요 전력을 저감하는 ESS 운영 스케줄링 기법이 연구되고 있다. 수요 전력 정보를 미리 알고 있다면, ESS에 저장된 전력과 앞으로 발생할 수요 전력을 모두 고려하여 최적의 ESS 운영 스케줄링 기법을 적용할 수 있을 것이다. 그러나, 최대 수요 전력은 상대적으로 짧은 시간 구간에서만 발생하며 발생 시간도 일정하지 않아 예측이 매우 어렵다. 따라서, 미래의 수요 전력 정보를 미리 알고 있어야만 구현 가능한 최적의 ESS 운영 스케줄링 기법은 실질적으로 적용이 어렵다. 본 논문에서는 과거에 측정된 수요 전력 정보만을 이용하는 ESS 운영 스케줄링 기법을 제안하였다. 구체적으로, 과거에 측정된 수요 전력과 이에 대응되는 ESS의 최적 방전 전력을 입･출력 데이터로 활용하여 long short-term memory(LSTM) 신경망을 훈련하고 이를 ESS 운영 스케줄링에 적용하였다. 제안 기법의 유효성을 검증하기 위해, 4곳의 전력 수용가들에 대한 수요 전력 데이터를 이용하여 실험을 수행하였다. 구체적으로, 제안 기법은 정확한 전력 수요 정보를 미리 알고 있어야만 구현 가능한 최적 운영스케줄링 기법 대비 최대 약 82.42%까지 연간 최대 수요 전력 감소를 달성할 수 있음을 확인하였다.","In recent years, blackouts have become more likely in South Korea as the peak demand has sharply increased. In order to address this issue, an energy storage system (ESS) operation scheduling technique has been investigated for its ability to reduce the peak demand by utilizing the power stored in the ESS. If the power demand information is known in advance, an optimal ESS operation scheduling technique can be applied in consideration of both the power stored in the ESS and the power demand to be generated in the future. However, it is difficult to predict the peak demand in advance because it only occurs in a relatively short time period, and the instance of its occurrence differs substantially from day-to-day. Therefore, it is very difficult to implement an optimal ESS operation scheduling technique that requires exact information on power demands in advance. Thus, in this paper, we proposed an ESS operation scheduling method with which to reduce the peak demand by using only historical power demands. Specifically, we employed a long short-term memory (LSTM) network and trained it using the historical power demands and their corresponding optimal ESS discharge powers. Then, we applied the trained network to approximate the optimal ESS operation scheduling. We showed the validity of the proposed method through computer simulations using historical power demand data from four customers. In particular, it was shown that the proposed scheme reduced the peak demand per year by up to about 82.42% compared to the optimal scheme that is only feasible when the exact future power demands are available."
고밀도 SNP 칩 유전자형 데이터 기계학습 기반 반려견 품종 식별 유전마커 선발,2019,"['고밀도 SNP 칩', '기계 학습', '유전 마커 선발', '특징 선택', '품종 식별', 'Breed identification', 'Feature selection', 'High-density SNP array', 'Machine learning', 'Marker selection']",,
Simultaneous feature selection and discretization based on mutual information,2019,"['Feature selection', 'Mutual information', 'Bias', 'Dynamic discretization']",,"<P><B>Abstract</B></P>  <P>Recently mutual information based feature selection criteria have gained popularity for their superior performances in different applications of pattern recognition and machine learning areas. However, these methods do not consider the correction while computing mutual information for finite samples. Again, finding appropriate discretization of features is often a necessary step prior to feature selection. However, existing researches rarely discuss both discretization and feature selection simultaneously. To solve these issues, Joint Bias corrected Mutual Information (JBMI) is firstly proposed in this paper for feature selection. Secondly, a framework namely modified discretization and feature selection based on mutual information is proposed that incorporates JBMI based feature selection and dynamic discretization, both of which use a <I>χ</I> <SUP>2</SUP> based searching method. Experimental results on thirty benchmark datasets show that in most of the cases, the proposed methods outperform the state-of-the-art methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We address discretization and feature selection jointly with a single criteria. </LI> <LI>  The proposed discretization method is dynamic and independent of classification algorithms. </LI> <LI>  The amount of errors introduced for Relevancy, Redundancy and Complementary Information are derived analytically. </LI> <LI>  It is also analytically shown that Relevancy, Redundancy and Complementary follows χ<SUP>2</SUP>-distribution. </LI> <LI>  A χ<SUP>2</SUP>-based search is introduced to select a small set of features and to discretize them with small number of intervals. </LI> </UL> </P>"
EXCUTE REAL-TIME PROCESSING IN RTOS ON 8BIT MCU WITH TEMP AND HUMIDITY SENSOR,2019,"['Real Time', 'IoT RTOS', 'IoT System', 'Real Time Os', 'Real Time System', 'IoT Sensor', '실시간', 'IOT실시간 운영체제', 'IOT 시스템', '실시간 운영체제', '실시간 시스템', 'IOT센서']",,"Recently, embedded systems have been introduced in various fields such as smart factories, industrial drones, and medical robots. Since sensor data collection and IoT functions for machine learning and big data processing are essential in embedded systems, it is essential to port the operating system that is suitable for the function requirements. However, in embedded systems, it is necessary to separate the hard real-time system, which must process within a fixed time according to service characteristics, and the flexible real-time system, which is more flexible in processing time. It is difficult to port the operating system to a low-performance embedded device such as 8BIT MCU to perform simultaneous real-time. When porting a real-time OS (RTOS) to a low-specification MCU and performing a number of tasks, the performance of the real-time and general processing greatly deteriorates, causing a problem of re-designing the hardware and software if a hard real-time system is required for an operating system ported to a low-performance MCU such as an 8BIT MCU. Research on the technology that can process real-time processing system requirements on RTOS (ported in low-performance MCU) is needed."
물리 화학적 구조에 기초한 약물 독성 예측 방법,2019,"['Toxicity prediction', 'Physical / chemical structure', 'Simulation', 'New drug development', 'SVM Classifier', '독성 예측', '하이브리드 예측', '시뮬레이션', '신약 개발', '상태 벡터 머신 분류기']","신약 개발의 과정에서 화합물 또는 후보 약물의 독성을 판별해내는 것은 필수적인 단계이다. 그러나 모든 후보 약물에대하여 독성이 있는지 실험을 통해 검증하는 것에는 많은 비용이 필요하다. 최근에는 컴퓨터 시뮬레이션을 통해 후보 약물의독성이 명확한 것들을 1차로 판별하고 그 외의 것에 대해 실험을 수행하므로 비용을 낮추는 방법을 사용하고 있다. 그러나시뮬레이션 모델에 따라 상이한 독성 예측 결과를 나타내는 경우가 있어, 독성 예측의 정확도를 높이는 연구가 필요하다. 본논문에서는 신약 개발을 위한 후보 약물 선정에서 보다 신뢰성 높은 약물 독성 예측을 위한 예측 방법을 제안한다. 제안하는방법은 기존에 알려진 물리 / 화학적 구조에 기반한 독성 예측 시뮬레이션 프로그램에서 주는 정보를 기반으로 독성인지아닌지에 대한 학습을 수행하고, 학습된 결과를 이용하여 후보 약물의 독성을 예측하므로 더 높은 정확도를 보인다.","Identifying the toxicity of a compound or candidate drug in the course of drug development is an essential step. However, it is costly to experimentally verify that all candidate drugs are toxic. In recent years, computer simulation has been used to first determine the toxicity of candidate drugs, and then to experiment with others to lower costs. However, there are cases where different simulation results show different toxicity prediction results. In this paper, we propose a method for predicting drug toxicity more reliably in candidate drug selection for new drug development. The proposed method performs learning about whether toxicity is based on the information given in the model based on the known physical / chemical structure, and predicts the toxicity of the candidate drug using the learned result."
전통항해술과 전통지식-강진 옹기배 사공 신연호의 사례-,2019,"['traditional navigation', 'native knowledge', 'folklore knowledge', 'folklore climatology', 'onggibae', 'oral statement', 'intangible cultural asset', 'knowledge about the nature and the universe', 'cultural diversity', '전통항해술', '민속지식', '토착지식', '민속기후학', '옹기배', '구술자료', '무형문화유산', '자연과 우주에 대한 지식', '문화다양성']","옹기배 사공 신연호의 사례를 중심으로 전통항해술과 전통지식에 대해 살펴보고자 한다. 전통지식에 대한 논의가 여럿 있으나 전통항해술과 관련된 연구는 별로 없으므로 근본적인 문제들을 환기하고 연구방향을 모색할 필요가 있다. 전통항해술은 자연의 힘이나 인력 위주로 운용되는 항해술이다. 전통항해술에서는 바람의 상태를 세밀하게 파악하고 그것에 맞게 돛을 잘 조작하는 것이 핵심 기술로 간주된다. 전통배 사공들은 민속기후학적 지식을 토대로 항해의 적절성을 판단했으며, 자연조건을 입체적으로 파악하고 기술 및 도구와 연계해서 지식화하고 현장에서 활용했다. 이 글에서는 그 색다른 양상들을 살펴보았다.전통항해술은 항해자들이 변화무쌍한 바다에서 생존을 건 항해를 하면서 탐구하고 전승해온 전통생태지식이다. 그리고 공동체가 생활 속에서 공유해온 민속지식으로서, 한자어나 외래어가 아닌 우리말 고유의 언어적 표현으로 구성돼 있다는 점이 색다르다. 또한 규격화된 지식이 아니라 실제의 항해 현장에서 배우고 전승해온 까닭에 상황적인 조건과 긴밀하게 연계돼 있고 구체적이다. 이런 점에서 전통항해술은 민속 전승의 다양성과 개성을 보여주는 각별한 무형문화유산이라고 할 수 있다.","This article aims to examine traditional navigation and traditional knowledge by centering on the case of Shin Yeonho, a Onggibae boatman. Traditional navigation is a kind of navigation that does not use powered machine, but uses the forces of nature and manpower. Through the oral statement of Mr. Shin, ‘folklore climate knowledge that judges the appropriateness of a voyage’ and ‘wind and sailing : cognitive system and navigation with regard to win’ are examined.In traditional navigation, the ability to deftly learn the status of wind and dexterously maneuver accordingly is considered a core skill. The boatmen of traditional boats understand the status and characteristics of wind and the connection of wind and other climate conditions in order to perform the apapted ‘sailing’. They were well-versed with the skill to move the sail according to the wind. It shows how to document knowledge in relation to the technique and tools to grasp the natural condition and how to employ in the field.Traditional navigation is a traditional ecological knowledge that is learned and shared by sailors through voyages in the incessant ocean who adapted and amassed knowledge over a long period of time in the nature. Traditional navigation is a folklore knowledge that is shared by a community in everyday life and a linguistic constitution that contains the liveliness of unique Korean, not Chinese characters or foreign language. It is also a folklore language that is sometimes full of imagination and poetic expressions. In this sense, traditional navigation is a precious intangible asset that displays the variety and personality of folklore transmission."
White striping degree assessment using computer vision system and consumer acceptance test,2019,"['Appearance', 'Broiler Breast Fillet', 'Classification', 'Digital Image', 'Sensory Analysis']",,"Objective: The objective of this study was to evaluate three different degrees of white striping (WS) addressing their automatic assessment and customer acceptance. The WS classification was performed based on a computer vision system (CVS), exploring different machine learning (ML) algorithms and the most important image features. Moreover, it was verified by consumer acceptance and purchase intent.Methods: The samples for image analysis were classified by trained specialists, according to severity degrees regarding visual and firmness aspects. Samples were obtained with a digital camera, and 25 features were extracted from these images. ML algorithms were applied aiming to induce a model capable of classifying the samples into three severity degrees. In addition, two sensory analyses were performed: 75 samples properly grilled were used for the first sensory test, and 9 photos for the second. All tests were performed using a 10-cm hybrid hedonic scale (acceptance test) and a 5-point scale (purchase intention).Results: The information gain metric ranked 13 attributes. However, just one type of image feature was not enough to describe the phenomenon. The classification models support vector machine, fuzzy-W, and random forest showed the best results with similar general accuracy (86.4%). The worst performance was obtained by multilayer perceptron (70.9%) with the high error rate in normal (NORM) sample predictions. The sensory analysis of acceptance verified that WS myopathy negatively affects the texture of the broiler breast fillets when grilled and the appearance attribute of the raw samples, which influenced the purchase intention scores of raw samples.Conclusion: The proposed system has proved to be adequate (fast and accurate) for the classification of WS samples. The sensory analysis of acceptance showed that WS myopathy negatively affects the tenderness of the broiler breast fillets when grilled, while the appearance attribute of the raw samples eventually influenced purchase intentions."
Deep multiple kernel least squares support vector regression using PSO,2019,"['Back propagation algorithm', 'deep neural network', 'generalized cross validation function', 'grid search', 'least squares support vector regression', 'multilayer neural network', 'particle swarm optimization']",,"In this paper, we propose a deep multiple kernel least squares support vector regression (DMK-LSSVR) using particle swarm optimization (PSO). Unlike multilayer neural networks (MNN), each LSSVR in the DMK-LSSVR is trained to minimize the penalized objective function. Therefore, the learning of DMK-LSSVR is completely different from that of MNN that minimizes only the final objective function. In DMK-LSSVR the grid search using GCV function is used to find optimal values of hyperparameters of each LSSVR, which has a disadvantage that takes a lot of computational time. And the back propagation algorithm is used for the optimal values of weights and biases, which has a weakness to results in local minima. In DMK-LSSVR which utilizes PSO (DMK-LSSVR-PSO), we find the optimal values of hyperparameters of LSSVRs, weights and biases using PSO in one process. Using PSO, the only needed on hyperparameters are the lower and upper bound, and estimating weights and biases results in global minimizers. Numerical studies show that DMK-LSSVR-PSO has advantages over DMK-LSSVR and other machine learning models that use back propagation algorithm and grid search for regression problems."
A Stochastic Model for Virtual Data Generation of Crack Patterns in the Ceramics Manufacturing Process,2019,"['Cracks', 'Random walk', 'Virtual big data', 'AI']",,"Artificial intelligence with a sufficient amount of realistic big data in certain applications has been demonstrated to play an important role in designing new materials or in manufacturing high-quality products. To reduce cracks in ceramic products using machine learning, it is desirable to utilize big data in recently developed data-driven optimization schemes. However, there is insufficient big data for ceramic processes. Therefore, we developed a numerical algorithm to make ""virtual"" manufacturing data sets using indirect methods such as computer simulations and image processing. In this study, a numerical algorithm based on the random walk was demonstrated to generate images of cracks by adjusting the conditions of the random walk process such as the number of steps, changes in direction, and the number of cracks."
"Reliability analysis of simply supported beam using GRNN, ELM and GPR",2019,"['beam', 'deflection', 'ELM', 'GPR', 'GRNN', 'prediction']",,"This article deals with the application of reliability analysis for determining the safety of simply supported beam under the uniformly distributed load. The uncertainties of the existing methods were taken into account and hence reliability analysis has been adopted. To accomplish this aim, Generalized Regression Neural Network (GRNN), Extreme Learning Machine (ELM) and Gaussian Process Regression (GPR) models are developed. Reliability analysis is the probabilistic style to determine the possibility of failure free operation of a structure. The application of probabilistic mathematics into the quantitative aspects of a structure and improve the qualitative aspects of a structure. In order to construct the GRNN, ELM and GPR models, the dataset contains Modulus of Elasticity (E), Load intensity (w) and performance function () in which E and w are inputs and  is the output. The achievement of the developed models was weighed by various statistical parameters; one among the most primitive parameter is Coefficient of Determination (R2) which has 0.998 for training and 0.989 for testing. The GRNN outperforms the other ELM and GPR models. Other different statistical computations have been carried out, which speaks out the errors and prediction performance in order to justify the capability of the developed models."
종교적 인공지능 시뮬레이션 — 스타크-베인브릿지와 뒤르켐의 종교적 인지 모형 비교연구,2019,"['종교적 인공지능', '초자연자 의식', '사회의 실재성', '종교적 인지범주', '자기보존본능', 'Artificial Religious Intelligence', 'Consciousness of the Supernatural', 'Reality of Society', 'Categories of Religious Cognition', 'Conatus Essendi']","오늘날 제기되고 있는 인공지능의 가능성과 한계에 대한 물음들 가운데는 인간의 종교성과 관련된 물음이 속해 있다. “과연 인공지능은종교적 신앙을 재현할 수 있는가?” 본 연구는 종교사회학자이자 인지과학자인 윌리엄 심스 베인브릿지(William Sims Bainbridge)가 인간의종교성과 초자연자에 대한 신앙을 시뮬레이션하기 위해 2006년경 이행한 기계학습 실험을 주요 탐구사례로 선정한다. 그리고 해당 실험에반영된 인간의 종교성과 신앙에 대한 사회인지 이론, 이를 기계학습 시뮬레이션으로 현실화하기 위해 기획된 시나리오, 실험에 활용된 일부수학적-통계적 기법과 그 원리에 대한 종교학적 고찰과 반성을 수행하는 데 초점을 맞춘다. 이를 위해 본 연구는 스타크-베인브릿지와 뒤르켐의 종교론과 종교적 인지 모형을 비교해 고찰한다. 이를 통해 본 연구는 다음과 같은 결론을 내린다. 양측 간 다소 중대한 이견들이 존재하긴 해도, 베인브릿지의 인공지능 시뮬레이션에 반영된 스타크-베인브릿지 종교론의 통찰들은 뒤르켐의 종교학 방법론 관점으로 볼 때 상당부분 타당성을 가진 것으로 인정될 가능성이 높다. 무엇보다 원초적종교성의 발원지를 사회로부터, 지속적으로 수행되는 사회적 행위로부터 찾고, 이를 종교적 인지의 범주적 준거로 전환하는 방식을 통해 인간의 종교적 본성을 탐구한다는 점에서 양측은 공감대를 형성하고 있는 것으로 확인된다.","One of the important contemporary questions about the possibilities and limits of artificial intelligence is concerned with human religiosity. “Can artificial intelligence simulate religious faith?” The present study investigates the implications of a machine learning experiment of William Sims Bainbridge, an outstanding researcher in the field of the sociology of religion and cognitive science. He attempted to simulate human religiosity and faith in supernatural beings in 2006. The focus is on three factors: his social cognitive theory to explain human religiosity and faith, a scenario for the actualization of this theory, and a mathematical-statistical strategy and its principles applied to experiment. In this comparative analysis of the Stark-Bainbridge model of religion and religious cognition and that of Durkheim, it is demonstrated that the insights of Stark and Bainbridge found in Bainbridge’s artificial intelligence simulation would likely be acknowledged as valid from the perspective of the Durkheimian methodology of religious studies, despite some significant differences between them. Most importantly, it seems certain that what Stark-Bainbridge and the Durkheimian model of religious cognition have in common is that they locate the origin of primitive religiosity in society, in continuous social processes. It also seems certain that they both translate the social processes into the categorizing norms of religious cognition so as to illuminate the religious nature of human kind."
"Evidential Belief Function, Weight of Evidence 및 Artificial Neural Network 모델을 이용한 산사태 공간 취약성 예측 연구",2019,"['Landslide', 'Evidential Belief Function', 'Weight of Evidence', 'Artificial Neural Network', 'GIS']","본 연구는 지리정보시스템(GIS) 환경에서 확률 모델인 Weight Of Evidence (WOE)와 Evidential Belief Function (EBF), 기계학습 모델인 Artificial Neural Networks (ANN) 모델을 이용하여 평창지역의 산사태 취약성도를 공간적으로 분석하고 예측하였다. 본 연구지역은 2006년 태풍 에위니아에 의한 집중호우로 산사태가 많이 발생하여 많은 재산 및 인명피해가 발생하였다. 산사태 취약성도를 작성하기 위해 항공사진을 이용하여3,955개의 방대한 산사태 발생 위치를 탐지하였고, 환경공간정보인 지형, 지질, 토양, 산림 및 토지이용 등의 공간 데이터를 수집하여 공간데이터베이스에 구축하였다. 이러한 공간데이터베이스를 이용하여 산사태에 영향을 줄 수 있는 인자 17개를 추출하여 입력 인자와 EBF, WOE, ANN 모델을 이용하여 산사태 취약성도를 작성하고 검증하였다. 작성 및 검증을 위해 산사태 자료는 각각 50%씩 나누어서 훈련 및 검증을 실시하였고, 검증결과 WOE 모델의 경우는 74.73%, EBF 모델의 경우는 75.03%, ANN 모델의 경우는 70.87%의 예측 정확도를나타내었다. 본 연구에 사용된 모델 중 EBF 모델이 가장 높은 정확도를 나타냈으며, 모든 모델에서 70% 이상의 예측 정확도를 보여 본 연구에서 사용된 기법이 산사태 취약성도 작성에 유효함을 나타내었다. 본 연구에서제안된 WOE, EBF, ANN 모델과 산사태 취약성도는 이전에 산사태가 발생하지 않은 지역의 산사태를 예측하는 데 사용될 수 있다. 이러한 취약성도는 산사태 위험 감소를 촉진하고, 토지 이용 정책 및 개발을 위한 기초자료 역할을 할 수 있으며, 궁극적으로 산사태 재해 예방을 위한 시간과 비용을 절약할 수 있다. 향후 보다 많은지역에서 산사태 취약성도 작성 방법을 적용하여 산사태 위험 예측을 위한 일반화된 모델을 이끌어 내야 한다.","The purpose of this study was to analyze landslide susceptibility in the Pyeongchang area using Weight of Evidence (WOE) and Evidential Belief Function (EBF) as probability models and Artificial Neural Networks (ANN) as a machine learning model in a geographic information system (GIS). This study examined the widespread shallow landslides triggered by heavy rainfall during Typhoon Ewiniar in 2006, which caused serious property damage and significant loss of life. For the landslide susceptibility mapping, 3,955 landslide occurrences were detected using aerial photographs, and environmental spatial data such as terrain, geology, soil, forest, and land use were collected and constructed in a spatial database. Seventeen factors that could affect landsliding were extracted from the spatial database. All landslides were randomly separated into two datasets, a training set (50%) and validation set (50%), to establish and validate the EBF, WOE, and ANN models. According to the validation results of the area under the curve (AUC) method, the accuracy was 74.73%, 75.03%, and 70.87% for WOE, EBF, and ANN, respectively. The EBF model had the highest accuracy. However, all models had predictive accuracy exceeding 70%, the level that is effective for landslide susceptibility mapping. These models can be applied to predict landslide susceptibility in an area where landslides have not occurred previously based on the relationships between landslide and environmental factors. This susceptibility map can help reduce landslide risk, provide guidance for policy and land use development, and save time and expense for landslide hazard prevention. In the future, more generalized models should be developed by applying landslide susceptibility mapping in various areas."
Optimised ML-based System Model for Adult-Child Actions Recognition,2019,"['Human action recognition', '2D Skeleton features', '3D Projection', 'Reduced data structure', 'Compound features selection method']",,"Many critical applications require accurate real-time human action recognition. However, there are many hurdles associated with capturing and pre-processing image data, calculating features, and classification because they consume significant resources for both storage and computation. To circumvent these hurdles, this paper presents a recognition machine learning (ML) based system model which uses reduced data structure features by projecting real 3D skeleton modality on virtual 2D space. The MMU VAAC dataset is used to test the proposed ML model. The results show a high accuracy rate of 97.88% which is only slightly lower than the accuracy when using the original 3D modality-based features but with a 75% reduction ratio from using RGB modality. These results motivate implementing the proposed recognition model on an embedded system platform in the future."
Deep multiple kernel LSSVR using PSO,2019,"['Back propagation algorithm', 'deep neural network', 'generalized cross validation function', 'grid search', 'least squares support vector regression', 'multilayer neural network', 'particle swarm optimization']",,"In this paper, we propose a deep multiple kernel least squares support vector regression (DMK-LSSVR) using particle swarm optimization (PSO). Unlike multilayer neural networks (MNN), each LSSVR in the DMK-LSSVR is trained to minimize the penalized objective function. Therefore, the learning of DMK-LSSVR is completely different from that of MNN that minimizes only the final objective function. In DMK-LSSVR the grid search using GCV function is used to find optimal values of hyperparameters of each LSSVR, which has a disadvantage that takes a lot of computational time. And the back propagation algorithm is used for the optimal values of weights and biases, which has a weakness to results in local minima. In DMK-LSSVR which utilizes PSO (DMK-LSSVR-PSO), we find the optimal values of hyperparameters of LSSVRs, weights and biases using PSO in one process. Using PSO, the only needed on hyperparameters are the lower and upper bound, and estimating weights and biases results in global minimizers. Numerical studies show that DMK-LSSVR-PSO has advantages over DMK-LSSVR and other machine learning models that use back propagation algorithm and grid search for regression problems."
R 언어 기반의 REST API 구현 및 보안문제의 해결 방안,2019,"['R', 'Data analysis', 'plumber', 'REST', 'API']","최근 빅 데이터의 중요성이 부각되면서 데이터 분석에 대한 수요가 증가하고 있다. R 언어는 데이터 분석을 목적으로 고안된 언어로서, 사용자들은 R언어의 다양한 통계, 머신러닝, 데이터 마이닝 패키지의 알고리즘을 활용하여 데이터를 효과적으로 분석 할 수 있다. 그러나 R 언어는 분석 결과를 어플리케이션으로 만들어 활용하기 어렵다는 단점이 있다. 이를 보완하기 위해 PHP, Java등과 같은 다른 언어를 통해 R 스크립트를 호출하는 법이 제안되었다. 그러나 이러한 개발 방식은 R 이외에도 다른 언어를 혼용해서 작성해야 하는 번거로움이 있다. 본 연구에서는 R 언어의 Plumber 패키지를 활용하여 다른 언어를 사용하지 않고 오직 R 언어만을 이용하여 API를 작성하는 방법을 제안하였다. 또한 API를 구현할 때 고려해야할 보안 이슈와 해결 방안에 대해서도 제시하였다. 본 연구에서 제안한 기술을 이용하여 웹 응용 프로그램을 개발 한다면 높은 생산성과 개발의 편리성, 운영의 효율성을 기대할 수 있다.","Recently, the importance of big data has been increased, and demand for data analysis ​​for the big data is also increased. R language is developed for data analysis, and users are analyzing data by using algorithms of various statistics, machine learning and data mining packages in R language. However, it is difficult to develop an application using R. Early study proposed a method to call R script through another language such as PHP, Java, and so on. However, it is troublesome to write such a development method in addition to R in combination with other languages. In this study, we introduce how to write API using only R language without using another language by using Plumber package. We also propose a solution for security issues related with R API. If we use propose technology for developing web application, we can expect high productivity, easy of use, and easy of maintenance."
Real-Time Cattle Action Recognition for Estrus Detection,2019,"['Action Recognition', 'Cow Behavior', 'Surveillance', 'Monitoring Cattle', 'SVM']",,"In this paper, we present a real-time cattle action recognition algorithm to detect the estrus phase of cattle from a live video stream. In order to classify cattle movement, specifically, to detect the mounting action, the most observable sign of the estrus phase, a simple yet effective feature description exploiting motion history images (MHI) is designed. By learning the proposed features using the support vector machine framework, various representative cattle actions, such as mounting, walking, tail wagging, and foot stamping, can be recognized robustly in complex scenes. Thanks to low complexity of the proposed action recognition algorithm, multiple cattle in three enclosures can be monitored simultaneously using a single fisheye camera. Through extensive experiments with real video streams, we confirmed that the proposed algorithm outperforms a conventional human action recognition algorithm by 18% in terms of recognition accuracy even with much smaller dimensional feature description."
교통사고 지점 예측을 위한 기댓값 최대화 클러스터링 및 주성분 분석 기반의 주요 변인 식별 및 시각화 방안,2019,"['Feature Selection', 'Traffic Accident', 'Expectation-Maximization', 'PCA', 'Visualization']","클라우드 컴퓨팅, 스마트폰, 소셜 네트워크 서비스, 사물인터넷 등의 영향으로 실시간으로 다양한 대용량 데이터가 생성되고 있으며, 이러한 빅데이터(Big Data)를 처리하기 위한 기술들이 각광받고 있다. 그 중, 기계 학습 기법을 이용한 빅데이터 분석 기술은 가지고 있는 데이터로부터 변인(feature)을 선정하고 이를 기계 학습 모델을 학습시키는 데 사용한 다음, 학습된 모델을 이용해 고객 취향에 따른 추천 서비스를 제공하거나 교통사고와 같은 사회현상을 분석하기도 한다. 따라서 좋은 변인을 선택하는 것은 기계 학습 모델의 정확도와 밀접한 관계를 가지고, 이는 서비스 품질에 직접적인 영향을 준다. 본 논문에서는 대구시에서 발생한 교통사고에 대한 데이터를 수집한 후, ‘기댓값-최대화 클러스터링 기법’을 사용하여 데이터를 클러스터링한 다음, 각 클러스터에 대한 주성분 분석을 통해 교통사고 데이터로부터 좋은 변인을 선택한다. 선택된 변인을 검증하기 위하여 대구시 교통사고 데이터를 학습한기계 학습 모델을 대표적인 기계 학습 문제인 분류(classification)문제에 적용하고 제안 방안이 교통사고 예측을 위한 기계 학습 모델에 긍정적인 영향을 줄 수 있음을 정량적으로 평가한다.","These days, a large amount of various data are being generated in real-time by means of cloud computing, smart devices, social networking services, and the Internet of Things. To handle such Big Data, big data processing technologies are getting more and more important because end-users can intuitively understand complex and difficult analysis results.Among them, machine learning, which is the technique that selects features from the data and trains them to a model, is used to provide some useful services, such as the recommendation based on customer preferences and the social analysis. As the result, how to select good features from data is related to the model’s accuracy, and this accuracy affects the quality of services. In this paper, we collected data on traffic accidents occurred in Daegu city, clustered the input data using the Expectation-Maximization (EM) clustering method, and analyzed the important traffic accident factor of each cluster through Principal Component Analysis (PCA). Finally, we selected some good features. Also, we evaluated the influence of selected features by measuring the accuracy about how much helpful to predict the accident region."
INT 기반 네트워크 이상 상태 탐지 기술 연구,2019,"['NIDS', 'In-band Network Telemetry (INT)', 'Software-Defined Networking (SDN)', 'P4']","네트워크 이상 상태 탐지는 네트워크 상의 플로우에 대한 정보를 수집하여 네트워크에서 발생하는 악의적인 공격을 실시간으로 탐지하는 기술이다. 실시간으로 패킷 단위의 세부적인 네트워크 정보를 제공하는 INT (In-band Network Telemetry) 기술을 이용하면 네트워크 홉 단위 지연 (hop latency)과 큐 점유율 (queue occupancy) 등 기존 네트워크에서 제공하지 않는, 보다 세부적인 정보를 실시간으로 수집 가능하여 네트워크 이상 상태 탐지에 활용할 수 있다. 본 논문에서는 INT를 이용하여 추출한 네트워크 상태 정보를 머신 러닝의 입력 특징으로 사용하여 더 높은 성능을 가진 이상 상태 탐지 시스템을 구현하는 방법을 제안하고 이를 실험을 통해 검증한다.","Network anomaly detection is a technology that collects information about flows on a network and detects malicious attacks occurring in a network in real time. In-band Network Telemetry (INT) technology provides more detailed information  in real time, that is not provided by existing networks, such as hop latency and queue occupancy. In this paper, we propose the method to implement an anomaly detection system with higher performance by using INT as an input feature of machine learning and verify it through experiments."
Artificial Neural Network Analysis of Spontaneous Preterm Labor and Birth and Its Major Determinants,2019,"['Preterm Birth', 'Hypertension', 'Diabetes Mellitus', 'Prior Conization', 'Cervical-Length Screening']",,"Background: Little research based on the artificial neural network (ANN) is done on preterm birth (spontaneous preterm labor and birth) and its major determinants. This study uses an ANN for analyzing preterm birth and its major determinants.Methods: Data came from Anam Hospital in Seoul, Korea, with 596 obstetric patients during March 27, 2014 - August 21, 2018. Six machine learning methods were applied and compared for the prediction of preterm birth. Variable importance, the effect of a variable on model performance, was used for identifying major determinants of preterm birth. Analysis was done in December, 2018.Results: The accuracy of the ANN (0.9115) was similar with those of logistic regression and the random forest (0.9180 and 0.8918, respectively). Based on variable importance from the ANN, major determinants of preterm birth are body mass index (0.0164), hypertension (0.0131) and diabetes mellitus (0.0099) as well as prior cone biopsy (0.0099), prior placenta previa (0.0099), parity (0.0033), cervical length (0.0001), age (0.0001), prior preterm birth (0.0001) and myomas & adenomyosis (0.0001).Conclusion: For preventing preterm birth, preventive measures for hypertension and diabetes mellitus are required alongside the promotion of cervical-length screening with different guidelines across the scope/type of prior conization."
Classification of 18F-Florbetaben Amyloid Brain PET Image using PCA-SVM,2019,"[""Alzheimer's disease"", 'Gray matter', 'β-Amyloid', 'PCA', 'SVM', '18F-FBB PET']",,"Amyloid positron emission tomography (PET) allows early and accurate diagnosis in suspected cases of Alzheimer's disease (AD) and contributes to future treatment plans. In the present study, a method of implementing a diagnostic system to distinguish β-Amyloid (Aβ) positive from Aβ negative with objectiveness and accuracy was proposed using a machine learning approach, such as the Principal Component Analysis (PCA) and Support Vector Machine (SVM). 18F-Florbetaben (FBB) brain PET images were arranged in control and patients (total n = 176) with mild cognitive impairment and AD.An SVM was used to classify the slices of registered PET image using PET template, and a system was created to diagnose patients comprehensively from the output of the trained model. To compare the per-slice classification, the PCA-SVM model observing the whole brain (WB) region showed the highest performance (accuracy 92.38, specificity 92.87, sensitivity 92.87), followed by SVM with gray matter masking (GMM) (accuracy 92.22, specificity 92.13, sensitivity 92.28) for Aβ positivity. To compare according to per-subject classification, the PCA-SVM with WB also showed the highest performance (accuracy 89.21, specificity 71.67, sensitivity 98.28), followed by PCA-SVM with GMM (accuracy 85.80, specificity 61.67, sensitivity 98.28) for Aβ positivity. When comparing the area under curve (AUC), PCA-SVM with WB was the highest for per-slice classifiers (0.992), and the models except for SVM with WM were highest for the per-subject classifier (1.000). We can classify 18F-Florbetaben amyloid brain PET image for Aβ positivity using PCA-SVM model, with no additional effects on GMM."
IT행정에서 자동화행정행위에 관한 일반적 고찰,2019,"['전자정부(Electronic Government)', 'IT행정절차(IT Administrative Procedures)', '인공지능(Artificial Intelligence)', '완전자동행정행위(Completely Automated Administrative Activities)', '전자문서(Electronic Documents)', '개인정보보호(Personal Information Protection)', '정보접근권(Right to Access Information)', '송달문서의 효력발생(Effectuation of Delivered Documents)', '전자행정시스템(Electronic administrative system)', '제4차 산업혁명(Fourth Industrial Revolution)', '행정절차기본법(FRAMEWORK ACT ADMINISTRATIVE PROCEDURES).']","오늘날의 사회는 과학기술 발달에 따른 산업화, 정보화, 복잡화, 다원화로 인해 국민의 생활환경이 빠르게 변화하고 있다. 행정영역에 있어서도 그러한 환경변화에 대응하여 과학적이고 실용적인 행정체계의 마련이 요구되며, 특히 정보통신기술 활용에 대한 행정법제의 유연한 대응체계 마련이 시급하다. 먼저 통합적 전자행정체계의 올바른 구현을 위하여는 완전자동행정행위에 대해 명시적 규정을 마련하여 법적효력을 부여할 필요가 있다. 그리고 자동행정을 실행하는 프로그램이 머신러닝기술을 적용한 것인지, 딥러닝기술을 적용한 것인지 여부에 따라 각각의 특수성을 고려한 구체적 기준을 마련하여 규율할 필요가 있다. 또한 공정한 데이터의 자동수집이 이루어지도록 데이터의 편향성 방지를 위한 데이터수집 및 범위 등에 대한 객관성 확보기준을 마련하여 이를 공개함은 물론 지속적인 관리기준도 마련되어야 한다. 이와 같이 완전자동행정행위에 법적효력을 부여하고 공정하고 지속적인 관리기준을 마련하여 객관성과 예측가능성이 확보되는 경우에 한하여 이를 전제로 그 기술수준에 따라 제한적으로 허용을 고려해 볼 수 있겠다. 행정절차법 제15조는 송달문서의 효력발생시점을 ‘송달받을 자에게 도달’로 규정하고 있고 동법 제21조 처분의 사전통지는 ‘당사자 등에게 통지’라고 규정하고 있다. 여기서 ‘당사자에게’의 의미를 대상적 관점으로 한정할 것인지 장소적 관점까지 확대하는 것이 타당한지가 문제이다. 동법의 제정목적이 행정과정에서 국민의 행정참여 및 국민의 권익보호라는 취지에서 본다면 처분문서 등이 당사자에게 전달된 때 즉 실질적인 지배권내에 들어간때로 개선하는 것이 바람직하다고 본다. 마찬가지로 전자문서의 경우에도 송신받을 자(수신자)의 수신확인 여부에 따라 효력발생시기를 규정하는 것이 민원사무서비스에 관한 국민의 편의성을 지향하는 전자정부의 목적에 부합하는 것이라고 본다. 현대사회에서 정보통신망을 이용한 공공부문에 대한 접근은 국민에게 매우 중요한 권리이며 이러한 정보접근권은 헌법이론상 표형의 자유에서 거론되는 엑세스권에서 도출되고 또한 지역적, 경제적, 신체적 이유로 차별이 있어서는 안된다. 따라서 전자정부체계의 확립에 관한 기본원칙으로 규율할 필요가 있다. 이에 따라 현행 전자정부법상 누구에게나 평 등한 정보접근권보장 의무화를 전자정부의 기본원칙으로 명시하고 공공기관에 대하여는 유비쿼터스 기반 정보접근체계의 구축을 의무화하여 누구라도 전자적 정보접근성에 제한이 없도록 개선할 필요가 있다고 본다. 정보주체의 개인정보자기결정권은 헌법상 열거되지 아니한 기본권으로서 정보주체가 자신에 관한 개인정보 이용의 범위와 한계 등을 스스로 결정할 수 있는 권리이다. 이러한 개인정보자기결정권은 불가침적인 절대적 권리라기보다는 다른 권리 또는 다른 가치(공동체에서의 공공성)와의 비교형량에 따라 보호범위와 내용에 제한이 있다. 이를 실효적으로 구현하기 위해서는 개인정보의 개념을 구분하고 동의제도의 개선이 필요하다고 본다. 즉 개인정보의 개념을 성명, 주민등록번호, 영상 등 개인을 알아볼 수 있는 정보와 해당 정보만으로는 특정 개인을 알아볼 수 없더라도 다른 정보와 결합하여 알아볼 수 있는 정보로 구 분하고, 전자의 경우 동의제도의 단순화 실질화를 통한 개선과 함께 후자의 경우 개인정보보호위원회의 인증을 통한 사전통제와 옵트아웃 방식을 채택하는 것이 과학기술 발전에 대응하는 유연한 규율체계의 형성에 기여할 수 있다고 본다. 제4차 산업혁명의 상징이라 할 수 있는 컴퓨터 등의 정보통신기술 기반의 인공지능형 자동장치의 출현에도 불구하고 그에 대응하는 법제도적 체계의 미비는 전자행정환경체계의 부조화 내지 불균형을 초래하게 된다. 이러한 현실적 문제에도 불구하고 자동화된 행정행위의 법적규율에 관한 명시적 규정의 마련이 늦어지는 것은 상대적으로 전자정부의 목적에도 부합되기 어렵다고 본다. 따라서 인공지능시대의 도래에 즈음하여 행정법제가 이에 대응할 수 있도록 행정활동에 필요한 공통적인 사항의 체계화 등 선진적 행정절차의 구체적 형성이 시급하다.","Due to industrialization, informatization, complication, and diversification following the advances in science and technology, the living environment of people in today’s world is changing rapidly. Administrative services are also required to respond to such environmental changes by establishing scientific and practical administrative systems, with a particular urgency in the development of flexible administrative laws regarding the utilization of information and communication technologies. First, to implement a properly integrated electronic administrative system, it is necessary to specify regulations regarding automated administrative activities and to support them via legal authorities. Another requirement is to create detailed criteria for automated administration programs depending on their characteristics, such as whether they are based on machine learning technology or deep-learning technology. In addition, a standard to ensure the objectivity of data collection, as well as sustained management procedures for the collection of data, must be established and disclosed to prevent bias in the collected data and to ensure a fair automated collection of data. Therefore, given that automated administrative activities are endowed with legal effects and a fair and sustained management standard is created to ensure their objectivity and predictability, completely automated administrative activities can be allowed in a limited manner depending on their technological levels. According to Article 15 of the Administrative Procedures Act, the delivered document becomes effective “upon arrival of the relevant document to the person to receive the service,” and Article 21 of the same law stipulates that prior notice of disposition shall be given “to such parties” referring to people who are affected by the disposition. Then, the issue is whether the meaning of “to such parties” should be restricted to individuals receiving the disposition or should be extended to the location of such individuals. Considering that the legislative intent of the Administrative Procedures Act is to protect the rights of citizens and to ensure their participation in the administrative process, it will be more appropriate to amend the phrase in the law to mean the moment at which the administrative documents or the like are delivered to parties that the disposition of the government agency affects. In the same way, the time at which the recipient of the electronic document confirms the receipt should determine the effectuation of dispositions delivered electronically, in order to meet the objectives of the electronic government, which is to enhance the citizens’ administrative service convenience. Access to the public sector via the information and communication network is a crucial right for people living in the contemporary era. Such a right to access information is deduced from the access rights when discussing the freedom of expression in constitutional theory; there must also be no discrimination on the basis of the region, economic status, or physical condition of an individual. Therefore, such elements must be incorporated into the basic principles on the establishment of the electronic government system. Thus, the Electronic Government Act should be amended to make it mandatory to consider enhancing the right to access information for socially marginalized groups or such groups of people, thereby bringing a related impact to other laws. The right to information self-determination held by data subjects is a basic right not enumerated in the constitution; it guarantees that data subjects may determine for themselves the scope and limitation regarding the use of their personal information. This is not an inviolable and absolute right, and in comparison, with other rights or values (publicness in the community), the scope and details of its protection is limited. To implement this concept in practical terms, the concepts of"
Human Stress Monitoring through Measurement of Physiological Signals,2019,"['Arduino based stress detection', 'physiological sensors', 'human mental stress estimation', 'stress level analysis', 'stress monitoring application', 'stress relief application']",,"As the human population increases in the world, the ratio of health doctors is rapidly decreasing. Therefore, it is an urgent need to create new technologies to monitor the physical and mental health of people during their daily life. In particular, negative mental states like depression and anxiety are big problems in modern societies. Usually this happens due to stressful situations during everyday activities including work. This paper presents a machine learning approach to reliably estimating the level of human mental stress using wearable physiological sensors. And also, this paper presents an Android- and Arduino-based stress monitoring and relief system."
노면 적응형 대퇴 의족개발을 위한 발목 관절 부하가변형 하퇴 의족 적용에 대한 연구,2019,"['above-knee prosthesis', 'control ankle joint', 'decision tree', 'random forest', 'walking imbalance']",,"This study is the method which is adapted to control ankle joint movement for resolving the problem of gait imbalancein intervals where gait environments are changed and slope walking, as applying terrain-adaptive technique to intelligentabove-knee prosthesis. In this development of above-knee prosthesis, to classify the gait modes is essential. Fordistinguishing the stance phases and the swing phase depending on roads, a machine learning which combines decisiontree and random forest from knee angle data and inertial sensor data, is proposed and adapted. By using this method, theankle movement state of the prosthesis is controlled. This study verifies whether the problem is resolved throughbutterfly diagram."
"Paddy acreage mapping and yield prediction using sentinel-based optical and SAR data in Sahibganj district, Jharkhand (India)",2019,"['Acreage mapping', 'Yield estimation', 'Random Forest classifier', 'SAR data']",,"Rice is an important staple food for the billions of world population. Mapping the spatial distribution of paddy and predicting yields are crucial for food security measures. Over the last three decades, remote sensing techniques have been widely used for monitoring and management of agricultural systems. This study has employed Sentinel-based both optical (Sentinel-2B) and SAR (Sentinel-1A) sensors data for paddy acreage mapping in Sahibganj district, Jharkhand during the monsoon season in 2017. A robust machine learning Random Forest (RF) classification technique was deployed for the paddy acreage mapping. A simple linear regression yield model was developed for predicting yields. The key findings showed that the paddy acreage was about 68.3–77.8 thousand hectares based on Sentinel-1A and 2B satellite data, respectively. Accordingly, the paddy production of the district was estimated as 108–126 thousand tonnes. The paddy yield was predicted as 1.60 tonnes/hectare. The spatial distribution of paddy based on RF classifier and accuracy assessment of LULC maps revealed that the SAR-based classified paddy map was more consistent than the optical data. Nevertheless, this comprehensive study concluded that the SAR data could be more pronounced in acreage mapping and yield estimation for providing timely information to decision makers."
"IoT and Smart City Technology: Challenges, Opportunities, and Solutions",2019,"['Internet of Things', 'Smart City']",,"Internet of Things (IoT) technology has been recently utilized in diverse fields. Smart city is one of the IoT application domains with a lot of research topics and which is operated by integrated IoT applications. In this paper, diverse kinds of solutions, processes, and frameworks to address the existing challenges in information technology are introduced. Such solutions involve various future track topics including blockchain, security, steganography, optimization, machine learning, smart system, and so on. In the subsequent paragraphs, we describe each topic in a summarized way in terms of the existing challenges and their solutions. Specifically, this paper introduced 18 novel and enhanced research studies from different countries in the world. We present diverse kinds of paradigms to subjects that tackle diverse kinds of research areas such as IoT and Smart City, and so on."
EEG 기반 감정인식을 위한 주석 레이블링과 EEG Topography 레이블링 기법의 비교 고찰,2019,"['EEG', 'Bio signal', 'Emotion Recognition', 'Topography', 'SVM', 'kNN', 'Human-Robot Interaction(HRI)', 'EEG', '생체 신호', '감정 인식', 'Topography', 'SVM', 'kNN', '인간-로봇 상호작용']","최근 뇌파를 기반으로 한 인간의 감정을 인식하는 연구가 인간-로봇 상호작용 분야에서 활발히 진행되고 있다. 본 논문에서는 MAHNOB-HCI에서 사용된 자기평가와 주석 레이블링 방법과는 다른, 이미지 기반의 뇌파 Topography를 이용한 레이블링을 통해 감정을 평가하는 방법을 제안한다. 제안한 방법은 뇌파 신호를 Topography의 이미지로 변환하여 기계학습 모델을 학습하고 이를 기반으로 Valence 기반의 감정을 평가한다. 제안한 방법은 레이블링 과정을 자동화하여 지연 시간을 없애고 객관적인 레이블링을 제공할 수 있다. MAHNOB-HCI 데이터베이스를 적용한 실험에서 SVM, kNN의 기계학습 모델을 학습하여 주석 레이블링과 성능 비교를 하였으며, 제안 방법의 감정인식 정확도를 SVM에서 54.2%, kNN에서 57.7%로 확인하였다.","Recently, research on emotion recognition based on EEG has attracted great interest from human-robot interaction field. In this paper, we propose a method of labeling using image-based EEG topography instead of evaluating emotions through self-assessment and annotation labeling methods used in MAHNOB HCI. The proposed method evaluates the emotion by machine learning model that learned EEG signal transformed into topographical image. In the experiments using MAHNOB-HCI database, we compared the performance of training EEG topography labeling models of SVM and kNN. The accuracy of the proposed method was 54.2% in SVM and 57.7% in kNN."
T-EBOW를 이용한 취업알선 챗봇용 단문 분류 연구,2019,"['Job placement', 'Chatbot', 'Short text', 'Classification', '취업알선', '챗봇', '단문', '분류']",최근 각종 사업 분야에서 기업들은 기존 메신저 플랫폼에 인공지능을 더하여 다양한 환경을 대상으로 챗봇 서비스 지원에 주력하고 있다. 취업알선 분야의 기관에서도 취업상담 서비스 품질 제고와 상담 인력 해소를 위해 챗봇 서비스를 요구한다. 일반적인 텍스트 기반 챗봇은 입력된 사용자 문장을 학습된 문장으로 분류하여 적합한 답변을 사용자에게 제공한다. 최근 소셜 네트워크 서비스의활성화 영향으로 챗봇에 입력되는 사용자 문장은 단문으로 입력되는 경향이 있다. 따라서 단문 분류의 성능향상은 챗봇 서비스의성능향상에 기여할 수 있다. 본 연구는 취업알선 챗봇을 위한 단문 분류 강화를 위해 기존 연구의 개념 정보뿐만 아니라 번역문 정보를 활용하는 방법인 T-EBOW (Translation-Extended Bag Of Words)를 제안한다. T-EBOW를 기계학습 분류 모델에 적용한 단문 분류의성능은 기존 방법에 비해 우수한 성능 평가 결과를 보였다.,"Recently, in various business fields, companies are concentrating on providing chatbot services to various environments by adding artificial intelligence to existing messenger platforms. Organizations in the field of job placement also require chatbot services to improve the quality of employment counseling services and to solve the problem of agent management. A text-based general chatbot classifies input user sentences into learned sentences and provides appropriate answers to users. Recently, user sentences inputted to chatbots are inputted as short texts due to the activation of social network services. Therefore, performance improvement of short text classification can contribute to improvement of chatbot service performance. In this paper, we propose T-EBOW (Translation-Extended Bag Of Words), which is a method to add translation information as well as concept information of existing researches in order to strengthen the short text classification for employment chatbot. The performance evaluation results of the T-EBOW applied to the machine learning classification model are superior to those of the conventional method."
End-to-End Partial Discharge Detection in Power Cables via Time-Domain Convolutional Neural Networks,2019,['Partial discharges · Fault detection · Power cable · Deep neural networks · Convolutional neural networks'],,"The analysis of partial discharge (PD) signals has been identifi ed as a standardized diagnostic tool in monitoring the condition of diff erent electrical apparatus nowadays. In this paper, we propose a novel data-driven approach to detect PD pulses in power cables using one-dimensional convolutional neural networks (CNNs), a successful deep neural network approach.Applying this deep learning method, an end-to-end framework has been proposed considering the propagations of PD signals and noises in power cables. The proposed method uses PD pulses as input, automatically extracts meaningful features for waveforms of PD pulses, and fi nally detects PD. Most of the existing methods, which use traditional classifi ers, such as support vector machines (SVMs) and multi-layer perceptron (MLP) have mainly focused on improving feature representation and extraction manually for this task. However, the proposed CNN-based detection algorithm captures important latent features for waveforms of PD pulses with the help of its automatic feature extraction capability from raw inputs. Our experimental results show that the proposed method is better than conventional SVMs and achieves 97.38% and 93.23% detection accuracies in end-to-end settings based on our theoretical model-generated and empirical real-world PD signals, respectively."
"IoT and Smart City Technology: Challenges, Opportunities, and Solutions",2019,"['Internet of Things', 'Smart City']",,"Internet of Things (IoT) technology has been recently utilized in diverse fields. Smart city is one of the IoT application domains with a lot of research topics and which is operated by integrated IoT applications. In this paper, diverse kinds of solutions, processes, and frameworks to address the existing challenges in information technology are introduced. Such solutions involve various future track topics including blockchain, security, steganography, optimization, machine learning, smart system, and so on. In the subsequent paragraphs, we describe each topic in a summarized way in terms of the existing challenges and their solutions. Specifically, this paper introduced 18 novel and enhanced research studies from different countries in the world. We present diverse kinds of paradigms to subjects that tackle diverse kinds of research areas such as IoT and Smart City, and so on."
미시추 구간의 지반 층상정보 예측을 위한 정규 크리깅 및 인공신경망 기법의 비교,2019,"['지반조사', '지반층상', '토공량', '정규크리깅', '인공신경망', 'Site investigation', 'Ground profile', 'Earthwork-volume', 'Ordinary kriging', 'Artificial neural network']","확한 토공량 설계를 위해서는 충분한 량의 지반조사 자료가 필요하나 비용적인 문제로 인하여 제한적인 지반조사가 수행되고 있다. 정확한 토공량 예측을 위해서 지반의 층상정보를 추정하는 것은 중요한 사항이며, 이러한 제한적인 지반조사 데이터로부터 정확한 토공량 예측을 위해서는 지구통계학적(geo-statistical) 분석방법으로 지반 층상정보를 예측할 수 있다. 또한, 기시추된 지반 층상정보를 활용하여 기계학습을 통하여 모델을 학습하여 미시추된 지반 층상정보를 예측할 수도 있는데, 본 논문에서는 인공신경망을 통하여 미시추된 지반 층상정보를 예측하고 기존의 정규 크리깅 기법과 성능을 비교한다. 이를 위하여, 84공의 지반 층상정보를 활용한다. 84공의 지반 층상정보의 데이터셋 중에서 75공을 학습 데이터셋으로 활용하였고, 나머지 9공을 검증 데이터셋으로 활용하였다. 검증 데이터셋의 실측된 지반 층상정보와 정규 크리깅 기법과 인공신경망으로 예측된 지반 층상정보를 비교 분석한다.","A large amount of site investigation data is essential to obtain reliable design value. However, site investigations are generally insufficient due to economic problems. It is important to estimate the ground profile information in unboring region for accurate earthwork-volume prediction, and such ground profile information can be estimated by using the geo-statistical approach. Furthermore, the ground profile information in unboring region can be estimated by training a model via machine learning technique such as artificial neural network. In this paper, artificial neural network-based model estimated the ground profile information in unboring region, and this results were compared with that of ordinary kriging technique, which is referred to the geo-statistical approach. Accordingly, a total of 84 ground profile information in an actual bridge environment was split into 75 training and 9 test databases. The observed ground profile information of the test database was compared with those of the ordinary kriging technique and artificial neural network."
Altmetrics: Factor Analysis for Assessing the Popularity of Research Articles on Twitter,2019,"['altmetrics', 'twitter metric', 'factor analysis', 'negative binomial regression']",,"Altmetrics measure the frequency of references about an article on social media platforms, like Twitter. This paper studies a variety of factors that affect the popularity of articles (i.e., the number of article mentions) in the field of psychology on Twitter. Firstly, in this study, we classify Twitter users mentioning research articles as academic versus non-academic users and experts versus non-experts, using a machine learning approach. Then we build a negative binomial regression model with the number of Twitter mentions of an article as a dependant variable, and nine Twitter related factors (the number of followers, number of friends, number of status, number of lists, number of favourites, number of retweets, number of likes, ratio of academic users, and ratio of expert users) and seven article related factors (the number of authors, title length, abstract length, abstract readability, number of institutions, citation count, and availability of research funding) as independent variables. From our findings, if a research article is mentioned by Twitter users with a greater number of friends, status, favourites, and lists, by tweets with a large number of retweets and likes, and largely by Twitter users with academic and expertise knowledge on the field of psychology, the article gains more Twitter mentions. In addition, articles with a greater number of authors, title length, abstract length, and citation count, and articles with research funding get more attention from Twitter users."
"River streamflow prediction using a deep neural network: a case study on the Red River, Vietnam",2019,"['deep neural network (DNN)', 'flood forecasting', 'long short-term memory (LSTM)', 'recurrent neural network (RNN)', 'Red River']",,"Real-time flood prediction has an important role in significantly reducing potential damage caused by floods for urban residential areas located downstream of river basins. This paper presents an effective approach for flood forecasting based on the construction of a deep neural network (DNN) model. In addition, this research depends closely on the open-source software library, TensorFlow, which was developed by Google for machine and deep learning applications and research. The proposed model was applied to forecast the flowrate one, two, and three days in advance at the Son Tay hydrological station on the Red River, Vietnam. The input data of the model was a series of discharge data observed at five gauge stations on the Red River system, without requiring rainfall data, water levels and topographic characteristics. The research results indicate that the DNN model achieved a high performance for flood forecasting even though only a modest amount of data is required. When forecasting one and two days in advance, the Nash-Sutcliffe Efficiency (NSE) reached 0.993 and 0.938, respectively. The findings of this study suggest that the DNN model can be used to construct a real-time flood warning system on the Red River and for other river basins in Vietnam."
문장 위치를 고려한 고객 리뷰 감성 분석 모형,2019,"['Sentiment analysis', 'Opinion mining', 'Sentence position', 'Sentiment dictionary']",,"Consumers use online user reviews as important decision-making tools when purchasing products or services, and companies analyze consumer opinions on their products and services to derive business insights. Thus, analyzing online user reviews effectively and intelligently using text mining techniques like sentiment analysis has been a popular research topic. This study aims to enhance the accuracy of sentiment analysis on online user reviews by considering the constitutive characteristics of writing through an integrated approach combining machine learning and vocabulary-based approaches. As the Internet and mobile technology evolves, communication habits are changing in online, and people’s writing behavior is also changing. Especially, recent writing structure is changing into the writing form of deductive or inductive composition reflecting the characteristics of speaking. Thus, we tried to improve the prediction accuracy of sentiment analysis by amplifying the weights of the words included in the first sentence or the last sentence in our study. Specifically, we applied 1.5 to 10 times weight to the first sentence and the last sentence to find the optimal weights with the highest accuracy. As a result, we found that the proposed algorithm improved the prediction accuracy when the weight of the first sentence is doubled, and the weight of the last sentence is three times. We also found that the performance of the proposed algorithm was higher in neutral reviews rather than in positive or negative reviews."
The Sequence Labeling Approach for Text Alignment of Plagiarism Detection,2019,"['Plagiarism Detection', 'Text Alignment', 'Sequence Labeling', 'Probabilistic Graphical Model', 'Conditional Random Fields']",,"Plagiarism detection is increasingly exploiting text alignment. Text alignment involves extracting the plagiarism passages in a pair of the suspicious document and its source document. The heuristics have achieved excellent performance in text alignment. However, the further improvements of the heuristic methods mainly depends more on the experiences of experts, which makes the heuristics lack of the abilities for continuous improvements. To address this problem, machine learning maybe a proper way. Considering the position relations and the context of text segments pairs, we formalize the text alignment task as a problem of sequence labeling, improving the current methods at the model level. Especially, this paper proposes to use the probabilistic graphical model to tag the observed sequence of pairs of text segments. Hence we present the sequence labeling approach for text alignment in plagiarism detection based on Conditional Random Fields. The proposed approach is evaluated on the PAN@CLEF 2012 artificial high obfuscation plagiarism corpus and the simulated paraphrase plagiarism corpus, and compared with the methods achieved the best performance in PAN@CLEF 2012, 2013 and 2014. Experimental results demonstrate that the proposed approach significantly outperforms the state of the art methods."
인공지능 기술 랜드스케이프 : 기술 구조와 기업별 경쟁우위,2019,"['Artificial Intelligence (AI)', 'Patent Analysis', 'Technology Trend', 'Topic Modeling', 'Latent Dirichlet Allocation (LDA)', '인공지능', '특허 분석', '기술동향', '토픽모델링', 'LDA(Latent Dirichlet Allocation)']","본 연구는 특허 데이터를 활용하여 인공지능 기술의 구조를 파악하고 주요 글로벌 IT 기업들의 인공 지능 기술역량을 분석한다. 2007년부터 2017년까지 미국 특허청에 등록된 2,589개의 인공지능 특허를 바탕으로 LDA 토픽모델링을 수행하여 인공지능 분야의 20개의 기술 토픽을 도출하였다. 인공지능 기 술 분야 중 언어이해, 음성처리보다는 시각이해, 데이터분석, 동작제어, 그리고 기계학습 분야의 연구 개발이 최근 활발한 것으로 나타났다. 또한 기업별 인공지능 기술 역량을 분석하여 인공지능 기술 분야 별로 우수 역량을 보유한 기업을 도출하고, 기업별로 강점을 가지고 있는 세부 기술 분야를 도출하였 다. 본 연구 결과는 인공지능 기업들의 기술기획 및 전략 수립에 유용하게 활용될 수 있을 것으로 기대 된다.","This study analyzes the technological structure of artificial intelligence (AI) and technological capabilities of AI companies based on patent information. 2589 AI patents registered in USPTO from 2007 to 2017 were collected and analyzed by the Latent Dirichlet Allocation (LDA) to derive 20 AI technology topics. Analysis of technology development trends by AI technology reveals that visual understanding, data analysis, motion control, and machine learning are growing, while language understanding and speech technology are sluggish. In addition, we also investigated leading companies in each sub-field of AI as well as core competencies of global IT companies. The findings of this study are expected to be fruitfully used for formulation and implementation of technology strategy of AI companies."
"IoT and Smart City Technology: Challenges, Opportunities, and Solutions",2019,"['Internet of Things', 'Smart City']",,"Internet of Things (IoT) technology has been recently utilized in diverse fields. Smart city is one of the IoT application domains with a lot of research topics and which is operated by integrated IoT applications. In this paper, diverse kinds of solutions, processes, and frameworks to address the existing challenges in information technology are introduced. Such solutions involve various future track topics including blockchain, security, steganography, optimization, machine learning, smart system, and so on. In the subsequent paragraphs, we describe each topic in a summarized way in terms of the existing challenges and their solutions. Specifically, this paper introduced 18 novel and enhanced research studies from different countries in the world. We present diverse kinds of paradigms to subjects that tackle diverse kinds of research areas such as IoT and Smart City, and so on."
다층퍼셉트론 기법을 이용한 ECMWF 예측자료의 강수예측 정확도 향상,2019,"['S2S', 'ECMWF', 'Multi-layer perceptron', '계절내-계절 예측', '기계학습', '다층퍼셉트론']","2주에서 2개월까지 선행기간을 가지는 계절내-계절(Subseasonal-to-Seasonal, S2S) 예측결과는 산업전반에 걸쳐 다양한 분야에 활용이 가능할 것으로 기대되고 있으나, 일기예보나 중장기 예보대비 낮은 예측성으로 인하여 현재까지 활용성이 매우 낮은 실정이다. 본 연구에서는 기계학습 기법중 비선형회귀 분야에서 좋은 결과를 보여주는 다층퍼셉트론 기법을 이용하여 S2S 예측자료의 후처리를 통한 국내 영역에서의 강수예측성 향상에 관한 연구를 수행하였다. 후처리 모형의 학습을 위한 입력자료로는 ECMWF의 S2S 과거예측(Hindcast) 정보를 이용하였으며 양분예보기법에 기반하여 학습된 다층퍼셉트론 모델을 이용한 후처리 결과와의 비교 분석이 수행되었다. 비교분석 결과 편차도(Bias score)는 평균 59.7% 감소하였고, 정확도(Accuracy)는 124.3% 증가하였으며, 임계성공지수(Critical Success Index)는 88.5% 향상된 것으로 분석되었다. 탐지확률(Probability of detection)의 경우 원자료 대비 평균 9.5% 감소하였으나 이는 ECMWF의 예측모델이 강수의 발생일을 과도하게 예측하였기 때문인 것으로 분석되었다. 본 연구 수행 결과 비록 ECMWF의 S2S 예측자료의 예측성이 낮더라도 후처리를 통해 예측성을 향상 시킬 수 있음을 확인하였으며, 본 연구 결과는 향후 수자원과 농업 분야에서 S2S 자료의 활용성을 높이는데 도움이 될 수 있을 것으로 판단된다.","Subseasonal-to-Seasonal (S2S) prediction information which have 2 weeks to 2 months lead time are expected to be used through many parts of industry fields, but utilizability is not reached to expectation because of lower predictability than weather forecast and mid- / long-term forecast. In this study, we used multi-layer perceptron (MLP) which is one of machine learning technique that was built for regression training in order to improve predictability of S2S precipitation data at South Korea through post-processing. Hindcast information of ECMWF was used for MLP training and the original data were compared with trained outputs based on dichotomous forecast technique. As a result, Bias score, accuracy, and Critical Success Index (CSI) of trained output were improved on average by 59.7%, 124.3% and 88.5%, respectively. Probability of detection (POD) score was decreased on average by 9.5% and the reason was analyzed that ECMWF’s model excessively predicted precipitation days. In this study, we confirmed that predictability of ECMWF’s S2S information can be improved by post-processing using MLP even the predictability of original data was low. The results of this study can be used to increase the capability of S2S information in water resource and agricultural fields."
Analyzing Dissatisfaction Factors of Weather Service Users Using Twitter and News Headlines,2019,"['Korean Meteorological Administration (KMA)', 'Weather Service', 'Sentiment Analysis', 'Twitter.']",,"Social media is a massive dataset in which individuals' thoughts are freely recorded. So there have been a variety of efforts to analyze it and to understand the social phenomenon. In this study, Twitter was used to define the moments when negative perceptions of the Korean Meteorological Administration (KMA) were displayed and the reasons people were dissatisfied with the KMA. Machine learning methods were used for sentiment analysis to automatically train the implied awareness on Twitter which mentioned the KMA July-October 2011-2014. The trained models were used to validate sentiments on Twitter 2015–2016, and the frequency of negative sentiments was compared with the satisfaction of forecast users. It was found that the frequency of the negative sentiments increased before satisfaction decreased sharply. And the tweet keywords and the news headlines were qualitatively compared to analyze the cause of negative sentiments. As a result, it was revealed that the individual caused the increase in the monthly negative sentiments increase in 2016. This study represents the value of sentiment analysis that can complement user satisfaction surveys. Also, combining Twitter and news headlines provided the idea of analyzing the causes of dissatisfaction that are difficult to identify with only satisfaction surveys. The results contribute to improving user satisfaction with weather services by efficiently managing changes in satisfaction."
Partially smooth linear pretopological and topological operators for Fuzzy sets,2019,"['Topology', 'Pretopology', 'Fuzzy Set']",,"We introduce here pretopological operators for closure (C ) and inte- rior (I ) based on partially smooth linear maps applied on the mem- bership functions of any fuzzy set. Through a couple of theorems we also describe explicitly the correspondent topologies dened by the pretopological operators. The results from the current paper will be further extended in two directions - application in machine learning like clustering and classication, and generalization in the framework of intuitionistic fuzzy sets."
중국어 어휘 유사도 계산과 언어학적 고찰,2019,"['synonym', 'word similarity computation', 'semantic feature', 'distributional semantics', 'HowNet', 'word embedding', '유의어', '어휘 유사도 계산', '의미자질', '분포의미론', '知网(HowNet)', '워드 임베딩']","언어학계에서 유의어 연구는 주로 동의어, 유사어, 반의어 및 상⋅하위어의 의미 관계를 살펴보는 것을 논의의 주요 대상으로 삼아 왔다. 이와 달리 본고에서는 전산언어학의 관점에서 컴퓨터가 어떻게 어휘 간의 유사성 판단이라는 문제를 해결하는지 살펴본다. 이를 위해 중국　학계의 어휘유사도 계산 관련 주요 선행 연구들을 어휘 유사성 판단 전략에 따라 자질 기반 모델링과 분포 기반 모델링의 두 가지 유형으로 분류하고, 그 이론적 토대가 되는 언어학적 전통과 사상적 견해를 언어학사의 흐름 속에서 되짚어 본다. 또한, 대표적 중국어 어휘의미자원인 HowNet과 빅데이터 기반 기계학습 방법인 Word embedding을 집중 조명함으로써 두 가지 모델의 어휘 유사도 계산 기법과 그 언어학적 함의를 밝힌다. 마지막으로, PKU-500 유사어 어휘쌍에 대한 실험을 통해 각 모델별 특징과 장⋅단점을 분석하고 장점을 극대화할 수 있는 혼합 모델의 가능성을 탐색한다.","Previous linguistic researches on word similarity have mainly focused on the semantic relations such as synonyms, antonyms, hypernym and hyponym. This paper, on the other hand, examines how to assess the degree of semantic similarity between Chinese words from a computational perspective. For this purpose, previous major studies on Chinese word similarity computation are classified into two types of approaches, namely feature-based and distribution-based modeling. The linguistic tradition and philosophical view supporting theoretical basis also are reviewed in the flow of history. Moreover, we introduce Chinese word similarity computation methods and discover its linguistic implication by focusing on HowNet, a representative Chinese lexical semantic resource, and Word embedding, which is a big data-based machine learning method. Finally, we analyze the features, advantages and disadvantages of each model and explore the possibility of the combined model through brief experiments on PKU-500 similar word pairs."
변형된 한글 금칙어에 대한 실시간 필터링 시스템,2019,"['Filtering Vulgar Words', 'Online Chat Censorship', 'Korean Encoding', 'Natural Language Processing', 'Artificial Neural Network']",,"The level of psychological damage caused by verbal abuse among cyberbully victims is very serious. It is going to introduce a system that determines the level of sanctions against chatting in real time using the automatic prohibited words filtering based on artificial neural network. In this paper, we propose a keyword filtering method that detects the modified prohibited words and determines whether the corresponding chat should be sanctioned in real time, and a real-time chatting screening system using it. The accuracy of filtering through machine learning was improved by processing data in advance through coding techniques that express consonants and vowels of similar pronunciation at close distances. After comparing and analyzing Mahalanobis-based clustering algorithms and artificial neural network- based algorithms, algorithms that utilize artificial neural networks showed high performance. If it is applied to Internet chatting, comments or online games, it is expected that it will be able to filter more effectively than the existing filtering method and that this will ease communication inconvenience due to existing indiscriminate filtering methods."
기업근로자 경력성공 인식의 다차원성과 차이: 토픽모델링의 적용,2019,"['경력성공', '토픽모델링', '다차원성', '비정형 데이터 분석', 'Career Success', 'Topic Modeling', 'Analysis of Unstructured Data', 'Multi-dimensionality']","이 연구는 우리나라 기업근로자가 인식하는 경력성공의 다차원성과 개인특성에 따른 차이를 토픽모델링 방법을 적용하여 탐색하고자 하는 목적으로 수행되었다. 연구목적을 달성하기 위해 경력성공에 대한 인식을 개방형 설문을 통해 수집하였으며 126명의 기업근로자들의 응답자료를 바탕으로 R 프로그램을 활용하여 분석하였다. 분석결과 한국 근로자의 경력성공 인식에 대한 5가지 토픽이 도출되었다. 구체적으로, 토픽1은 사회적으로 인정받는 직장에 다니는 것(사회적 인정), 토픽 2는 조직 내에서 자신의 업무에 충실하며 견디는 것(조직 내 근속), 토픽 3은 자기 분야에 지식과 노하우를 갖고 전문성을 갖는 것(전문성), 토픽 4는 일한 만큼 경제적 보상과 성과를 얻는 것(경제적 보상), 토픽 5는 일을 통해 보람과 성취감 같은 개인적 의미를 추구하는 것(개인적 의미 추구)으로 나타났다. 또한, 성별, 연령, 학력에 따른 각 토픽별 발현비율 차이가 확인되었다. 이 연구를 통해 경력성공 인식의 다차원성과 개인특성에 따른 경력성공 인식 차이를 확인하였으며, 개방형 설문자료와 같은 비정형 데이터 분석에서 토픽모델링 방법을 활용가능성을 제시하였다.","The purpose of this study is to explore the multi-dimensionality and the differences of the career success that is revealed by the employee's perception. In order to fulfill the research purpose, LDA topic modeling has applied to extract latent topics of career success from 126 Korean employees' open-end survey questionnaires. The extracted latent topics are social recognition, continuing service within an organization, expertise, financial rewards, and pursuing personal meaning. The occurrence probability of each topic was different by individual characteristics such as gender, education, position. Study findings showed there is multi-dimensionality in career success, and there are differences of topic occurrence probability by demographic characteristics. Additionally, this study showed how to apply the recently developed machine learning approach in order to reduce the researcher's bias by adapting the LDA topic modeling to the qualitative open-ended survey data."
‘고전’번역이론의 살아 숨 쉬는 가치를 찾아서: 환경의 변화에도 통번역교육에 있어 잊지 말아야할 것들,2019,"['recent developments in T&I', 'translator education', 'expertise in T&I', 'conceptual tools', 'translation theory', '통번역을 둘러싼 환경 변화', '통번역교육', '통번역 전문성', '개념적 도구', '번역이론']",,"This article is presented as part of an effort to rediscover the value of translation theory. In light of recent developments in the world of translation and interpreting (T&I), which is especially propelled by technological advancements, many argue for swift adaptation of T&I-related technology and some even voice concerns over the future of T&I. Against this backdrop, the present article examines these recent developments and their implications drawing on the literature in translation studies. In particular, the literature on remote interpreting, machine translation, machine translation post-editing, and transcreation are reviewed. Despite these recent developments as well as the call for introducing these T&I-related technology to the T&I curricula, this article argues that the very essence of T&I education should not be overlooked. In other words, although students should learn how to incorporate T&I-related technological tools in their daily T&I activities, they have and will always have to internalize the very mechanism of the act of T&I. And for this, translation theory provides a sturdy framework based on which students can further improve their T&I competence. Several student translations and ensuing corrective feedback are illustrated to demonstrate the role of conceptual tools as examples of how translation theory can serve this pedagogical purpose. The author hopes that this article is construed as an effort to rediscover and underscore the value of translation theory that may otherwise be shelved in our minds because it’s considered to be simply ‘classical’."
4차산업혁명시대의 정부부처 간 협력에 관한 연구,2019,"['4차산업혁명', '부처 간 협력', '협업행정', '융합행정', '제도의 유연성', 'The Fourth Industrial Revolution(4IR)', 'The collaboration between ministries', 'Integrated Administration', 'Flexibility of the institutions']","본 연구목적은 4차산업혁명시대를 준비하는 공무원 인식과 부처간 협력의 성공 및 제약요소들을 확인하고자 하였다. 연구분석 방법은 공무원 인식조사를 바탕으로 평균값 분석을 실시했으며, 연구결과는 다음과 같다. 첫째, 4차산업혁명을 대응하고 있는 9개부처 공무원들은 4차산업혁명에 대해 잘 알고 있다고 인식하였으며, 4차산업혁명이 새로운 기회이지만 제대로 대응하지 못하면 위기가 올 수 있다는 불안감을 가지고 있었다. 둘째, 4차산업혁명시대의 집중지원기술로 빅데이터 1순위, 인공지능 및 머신러닝 2순위, 클라우드 컴퓨팅기술 3순위로 인식하고 있다. 셋째, 4차산업혁명 대응을 위해 가장 시급하게 변화해야 하는 요소로 ‘제도의 유연성’과 ‘인재확보’를 언급하였다. 향후 연구에서는 민간, 일반시민 등 조사집단을 확대하여 4차산업혁명의 협력체계를 모색할 필요가 있다.","This study was conducted to identify the determing factors of the success and constraints based on the perception of public officials preparing for the Fourth Industrial Revolution(4IR) and the collaboration among ministries. The analytic method performed an average value analysis based on the survey of public officials' awareness, and the results of the study are as follows. First, officials from nine ministries who are responsible for the 4IR recognized that they were regarded that the 4IR as a new opportunity, but if it failed to respond properly, there might be a crisis. Second, it recognizes the era of 4IR as the number one priority in big data, second in artificial intelligence and machine learning, and third in cloud computing technology. Third, they recognized that ‘flexibility of the institutions’ and ‘recruitment of experts'’ were needed to prepare for the 4IR effectively."
대용량 텍스트 자원을 활용한 한국어 형태소 임베딩의 모델별 성능 비교 분석,2019,"['word embedding', 'NLP(Natural Language Processing)', 'Word2Vec', 'GloVe', 'FastText', '단어 임베딩', '자연어 처리', 'Word2Vec', 'GloVe', 'FastText']","단어 임베딩은 컴퓨터가 자연어를 인식할 수 있도록 하는 변환 기법으로 기계번역, 개체명 인식 등 기계학습을 바탕으로 하는 자연어 처리 분야에서 다양하게 사용되고 있다. 단어 임베딩을 생성하는 다양한 단어 임베딩 모델들이 존재하지만 이러한 모델들을 동일한 조건에서 성능을 비교 분석한 연구가 미비하다. 본 논문에서는 한국어 형태소 단위 띄어쓰기를 기반으로 하여 활발하게 사용되고 있는 모델인 Word2Vec의 Skip-Gram과 CBOW, GloVe, FastText의 성능을 비교 분석한다. 뉴스 대용량 말뭉치 및 세종 말뭉치를 바탕으로 실험한 결과 FastText가 가장 높은 성능을 확인할 수 있었다.","Word embedding is a transformation technique that enables a computer to recognize natural language. It is used in various fields of natural language processing based on machine learning such as machine translation and named-entity recognition. Various word-embedding models are available; however, few studies have compared the performance of these models under similar conditions. In this paper, we compare and analyze the performance of Word2Vec Skip-Gram, CBOW, Glove, and FastText, which are actively used according to Korean morpheme spacing. Based on experimental results with large news corpus and Sejong corpus, FastText yielded the best performance among CBOW, Skip-gram, Glove, and FastText of Word2Vec."
TV드라마 참여 인물의 계량 능력지표에 기반한 첫 회 시청률 상대적 우위 예측,2019,"['드라마', '제작진', '출연자', '시청률', '예측', 'Drama', 'Crew', 'Cast', 'TV Ratings', 'Predicting']","TV 드라마 한 시즌 제작에 최소 수십 억 원이 투입되지만 투자 대비 효과 예측은 쉽지 않으며 참여 인력의 중요성에도 불구하고 그들에 대한 적절한 평가지표는 아직 존재하지 않는다. 그 동안 콘텐츠 평가지표로 널리 사용되어온 시청률 절대 수치는 지속 감소하고 있지만 대체할만한 지표는 아직 없는 상태다. 본 연구에서는 시청률 절대 수치가 아니라 개별 드라마 시청률 간 상대적 우위를 반응변수로 하고, 드라마 참여 인력이 과거에 획득하여 축적한 상대적 우위를 계량 능력지표화 하여 설명변수로 설계함으로써 드라마의 상대적 흥행성을 예측하는 모형을 개발하였다. 예측 모형으로는 다양한 머신러닝 알고리즘을 활용하였고 예측 성능을 높이기 위해 기존 연구에서 유용한 것으로 판명된 설명변수를 추가하여 조합하였다. 결과적으로 본 연구에서 설계한 설명변수와 기존 연구의 설명변수로부터 최적의 조합을 탐색하여 구축한 예측 모형은 84%의 높은 정분류율로 우수한 예측 성능을 보여주었다. 이렇게 본 연구에서는 TV 드라마 참여 인력 능력지표와 시청률을 활용하여 콘텐츠의 상대적 흥행성을 예측함으로써 콘텐츠 산업 전반 투자 효율화와 활성화를 촉진하려 한다.","It is not easy to predict the return on investment in the content business, and there is no index to evaluate cast & crew. The absolute number of TV ratings is steadily declining, but there is no substitute index yet. In this study, we tried to predict the relative popularity of the drama by designing the relative superiority of the individual drama viewership as the response variable and designing the relative superiority of the drama participants as the explanatory variables. We used various machine learning algorithms and added explanatory variables that were found to be useful in previous studies. As a result, with properly combined explanatory variables, a high prediction accuracy of 84% is obtained. In this study, we intend to promote the investment efficiency of the entire contents industry by predicting the relative popularity of the contents."
OryzaGP: rice gene and protein dataset for named-entity recognition,2019,"['named-entity recognition', 'natural language processing', 'Oryza sativa', 'plant molecular biology', 'rice', 'text mining']",,"Text mining has become an important research method in biology, with its original purpose to extract biological entities, such as genes, proteins and phenotypic traits, to extend knowledge from scientific papers. However, few thorough studies on text mining and application development, for plant molecular biology data, have been performed, especially for rice, resulting in a lack of datasets available to solve named-entity recognition tasks for this species. Since there are rare benchmarks available for rice, we faced various difficulties in exploiting advanced machine learning methods for accurate analysis of the rice literature. To evaluate several approaches to automatically extract information from gene/protein entities, we built a new dataset for rice as a benchmark. This dataset is composed of a set of titles and abstracts, extracted from scientific papers focusing on the rice species, and is downloaded from PubMed. During the 5th Biomedical Linked Annotation Hackathon, a portion of the dataset was uploaded to PubAnnotation for sharing. Our ultimate goal is to offer a shared task of rice gene/protein name recognition through the BioNLP Open Shared Tasks framework using the dataset, to facilitate an open comparison and evaluation of different approaches to the task."
제한된 모션 센서와 애니메이션 데이터를 이용한 캐릭터 동작 제어,2019,"['Character Animation', 'Interactive Motion Control', 'Virtual Reality', '캐릭터 애니메이션', '실시간 동작 제어', '가상현실']",디지털 스토리텔링에 등장하는 3차원 가상 캐릭터에는 외형뿐만 아니라 자세나 동작에서도 캐릭터의 개성이 반영된 고유의 스타일이 부여된다. 그러나 사용자가 웨어러블 동작센서를 사용하여 직접 캐릭터의 신체 동작을 제어하는 경우 캐릭터 고유 의 스타일이 무시될 수 있다. 본 연구에서는 가상 캐릭터를 위해 제작된 소량의 애니메이션 데이터만을 이용하는 검색 기반 캐릭터 동작 제어 기술을 사용하여 캐릭터 고유의 스타일을 유지하는 기술을 제시한다. 대량의 학습 데이터를 필요로하는 기계학습법을 피하는 대신 소량의 애니메이션 데이터로부터 사용자의 자세와 유사한 캐릭터 자세를 직접 검색하여 사용하는 기술을 제안한다. 제시된 방법을 검증하기 위해 전문가에 의해 제작된 가상현실 게임용 캐릭터 모델과 애니메이션 데이터 를 사용하여 실험하였다. 평범한 사람의 모션캡쳐 데이터를 사용했을 때와의 결과를 비교하여 캐릭터 스타일이 보존됨을 증명하였다. 또한 동작센서의 개수를 달리한 실험을 통해 제시된 방법의 확장성을 증명하였다.,"A 3D virtual character playing a role in a digital story-telling has a unique style in its appearance and motion. Because the style reflects the unique personality of the character, it is very important to preserve the style and keep its consistency. However, when the character’s motion is directly controlled by a user’s motion who is wearing motion sensors, the unique style can be discarded. We present a novel character motion control method that uses only a small amount of animation data created only for the character to preserve the style of the character motion. Instead of machine learning approaches requiring a large amount of training data, we suggest a search-based method, which directly searches the most similar character pose from the animation data to the current user’s pose. To show the usability of our method, we conducted our experiments with a character model and its animation data created by an expert designer for a virtual reality game. To prove that our method preserves well the original motion style of the character, we compared our result with the result obtained by using general human motion capture data. In addition, to show the scalability of our method, we presented experimental results with different numbers of motion sensors."
주제 균형 지능형 텍스트 요약 기법,2019,"['문서 자동 요약', '워드 임베딩', '토픽 모델링', '텍스트 마이닝', '리뷰 요약', 'Document Summarization', 'Review Summarization', 'Text Mining', 'Topic Modeling', 'Word Embedding']",,"Recently, channels like social media and SNS create enormous amount of data. In all kinds of data, portions of unstructured data which represented as text data has increased geometrically. But there are some difficulties to check all text data, so it is important to access those data rapidly and grasp key points of text. Due to needs of efficient understanding, many studies about text summarization for handling and using tremendous amounts of text data have been proposed. Especially, a lot of summarization methods using machine learning and artificial intelligence algorithms have been proposed lately to generate summary objectively and effectively which called “automatic summarization”. However almost text summarization methods proposed up to date construct summary focused on frequency of contents in original documents. Those summaries have a limitation for contain small-weight subjects that mentioned less in original text. If summaries include contents with only major subject, bias occurs and it causes loss of information so that it is hard to ascertain every subject documents have. To avoid those bias, it is possible to summarize in point of balance between topics document have so all subject in document can be ascertained, but still unbalance of distribution between those subjects remains. To retain balance of subjects in summary, it is necessary to consider proportion of every subject documents originally have and also allocate the portion of subjects equally so that even sentences of minor subjects can be included in summary sufficiently.  In this study, we propose “subject-balanced” text summarization method that procure balance between all subjects and minimize omission of low-frequency subjects. For subject-balanced summary, we use two concept of summary evaluation metrics “completeness” and “succinctness”. Completeness is the feature that summary should include contents of original documents fully and succinctness means summary has minimum duplication with contents in itself. Proposed method has 3-phases for summarization. First phase is constructing subject term dictionaries. Topic modeling is used for calculating topic-term weight which indicates degrees that each terms are related to each topic. From derived weight, it is possible to figure out highly related terms for every topic and subjects of documents can be found from various topic composed similar meaning terms. And then, few terms are selected which represent subject well. In this method, it is called “seed terms”. However, those terms are too small to explain each subject enough, so sufficient similar terms with seed terms are needed for well-constructed subject dictionary. Word2Vec is used for word expansion, finds similar terms with seed terms. Word vectors are created after Word2Vec modeling, and from those vectors, similarity between all terms can be derived by using cosine-similarity. Higher cosine similarity between two terms calculated, higher relationship between two terms defined. So terms that have high similarity values with seed terms for each subjects are selected and filtering those expanded terms subject dictionary is finally constructed. Next phase is allocating subjects to every sentences which original documents have. To grasp contents of all sentences first, frequency analysis is conducted with specific terms that subject dictionaries compose. TF-IDF weight of each subjects are calculated after frequency analysis, and it is possible to figure out how much sentences are explaining about each subjects. However, TF-IDF weight has limitation that the weight can be increased infinitely, so by normalizing TF-IDF weights for every subject sentences have, all values are changed to 0 to 1 values. Then allocating subject for every sentences with maximum TF-IDF weight between all subjects, sentence group are constructed for each subjects finally. Last phase is summary generation parts. Sen2Vec is used to figure out similarity between subject-se"
Special Issue on Cyber Security and AI,2019,"['Cybersecurity', 'AI']",,"We are facing a big data world, embedded with interconnected IoT (Internet of Things) devices that generate large volumes of data. They pose a significant challenge to academia and industries focused on digital security: A variety of new malware and other threats are emerging at a fast pace, and existing preventive methods are struggling to deal with them within the golden time by depending solely on the known attack signature. Recently, there has been considerable advancement in computing, particularly in the field of Artificial Intelligence (AI). Advanced technologies such as Machine Learning and Deep Learning are being actively deployed in cyber security, and new results and issues have been reported."
Relational algorithm interpreting symptoms to demographic sign of patient medical history,2019,"['Medical Education', 'Educational Concept Map', 'Health Communication', 'Artificial Intelligence in Medicine', 'Simulation in Medicine.']",,"Doctor-patient communication is a skill to be thought in medical education. Challenges in performing an effective communication pressurizes medical students to focus on how to earn accurate patient history by using different methods of communication which is a challenging issue toward quality of care. Time pressure of waiting patients, irrelevant patient dialogue requiring sympathy, less accurate patient response, none categorized set of quick answers which needs to be specified and might be totally irrelevant to the care are sets of examples of frustration in communication within clinical care. Although many studies through machine learning, artificial intelligent and virtual reality addressed communication challenges, there are still rooms yet to establish an accurate communication channel for improving quality of care. This paper introduces a new method as a domain concept to interpret sign values as graphical interface for medical care providers so that information exchange with an enhanced and clear history taking symptoms relevant to both patients and disease category for an improved quality care environment. Designing a medical terminology interpretation software that relates medical history to graphical interface of various and easy to understand signs to reduce communication error of patients having difficulty relating different signs to their existing symptoms."
Relational algorithm interpreting symptoms to demographic sign of patient medical history,2019,"['Medical Education', 'Educational Concept Map', 'Health Communication', 'Artificial Intelligence in Medicine', 'Simulation in Medicine']",,"Doctor-patient communication is a skill to be thought in medical education. Challenges in performing an effective communication pressurizes medical students to focus on how to earn accurate patient history by using different methods of communication which is a challenging issue toward quality of care. Time pressure of waiting patients, irrelevant patient dialogue requiring sympathy, less accurate patient response, none categorized set of quick answers which needs to be specified and might be totally irrelevant to the care are sets of examples of frustration in communication within clinical care. Although many studies through machine learning, artificial intelligent and virtual reality addressed communication challenges, there are still rooms yet to establish an accurate communication channel for improving quality of care. This paper introduces a new method as a domain concept to interpret sign values as graphical interface for medical care providers so that information exchange with an enhanced and clear history taking symptoms relevant to both patients and disease category for an improved quality care environment. Designing a medical terminology interpretation software that relates medical history to graphical interface of various and easy to understand signs to reduce communication error of patients having difficulty relating different signs to their existing symptoms."
cGANs 기반 3D 포인트 클라우드 데이터의 실시간 전송 기법,2019,"['GANs', '3D point cloud', 'conditional-GANs', 'hologram', 'tele presence']",,"We present a method for transmitting 3D object information in real time in a telepresence system. Three-dimensional object information consists of a large amount of point cloud data, which requires high performance computing power and ultra-wideband network transmission environment to process and transmit such a large amount of data in real time. In this paper, multiple users can transmit object motion and facial expression information in real time even in small network bands by using GANs (Generative Adversarial Networks), a non-supervised learning machine learning algorithm, for real-time transmission of 3D point cloud data. In particular, we propose the creation of an object similar to the original using only the feature information of 3D objects using conditional GANs."
OryzaGP: rice gene and protein dataset for named-entity recognition,2019,"['named-entity recognition', 'natural language processing', 'Oryza sativa', 'plant molecular biology', 'rice', 'text mining']",,"Text mining has become an important research method in biology, with its original purpose to extract biological entities, such as genes, proteins and phenotypic traits, to extend knowledge from scientific papers. However, few thorough studies on text mining and application development, for plant molecular biology data, have been performed, especially for rice, resulting in a lack of datasets available to solve named-entity recognition tasks for this species. Since there are rare benchmarks available for rice, we faced various difficulties in exploiting advanced machine learning methods for accurate analysis of the rice literature. To evaluate several approaches to automatically extract information from gene/protein entities, we built a new dataset for rice as a benchmark. This dataset is composed of a set of titles and abstracts, extracted from scientific papers focusing on the rice species, and is downloaded from PubMed. During the 5th Biomedical Linked Annotation Hackathon, a portion of the dataset was uploaded to PubAnnotation for sharing. Our ultimate goal is to offer a shared task of rice gene/protein name recognition through the BioNLP Open Shared Tasks framework using the dataset, to facilitate an open comparison and evaluation of different approaches to the task."
문장에 포함된 외국어의 자연스러운 발음 표현을 위한 LSTM 방법,2019,"['조사', 'LSTM', '드롭아웃', '과적합', '종성', 'Postposition', 'LSTM', 'Dropout', 'Overfitting', 'Final Consonant Pronunciation of Nouns']",,"Korea language has postpositions such as eul, reul, yi, ga, wa, and gwa, which are attached to nouns and add meaning to the sentence. When foreign notations or abbreviations are included in sentences, the appropriate postposition for the pronunciation of the foreign words may not be used. Sometimes, for natural expression of the sentence, two postpositions are used with one in parentheses as in “eul(reul)” so that both postpositions can be acceptable. This study finds examples of using unnatural postpositions when foreign words are included in Korean sentences and proposes a method for using natural postpositions by learning the final consonant pronunciation of nouns. The proposed method uses a recurrent neural network model to naturally express postpositions connected to foreign words. Furthermore, the proposed method is proven by learning and testing with the proposed method. It will be useful for composing perfect sentences for machine translation by using natural postpositions for English abbreviations or new foreign words included in Korean sentences in the future."
Radiomics in Oncological PET/CT: a Methodological Overview,2019,['Radiomics . Texture analysis . Intratumoral heterogeneity . FDG PET/CT . Oncology'],,"Radiomics is a medical imaging analysis approach based on computer-vision. Metabolic radiomics in particular analyses the spatial distribution patterns of molecular metabolism on PET images. Measuring intratumoral heterogeneity via image is one of the main targets of radiomics research, and it aims to build a image-based model for better patient management. The workflow of radiomics using texture analysis follows these steps: 1) imaging (image acquisition and reconstruction); 2) preprocessing (segmentation & quantization); 3) quantification (texture matrix design & texture feature extraction); and 4) analysis (statistics and/or machine learning). The parameters or conditions at each of these steps are effect on the results. In statistical testing or modeling, problems such as multiple comparisons, dependence on other variables, and high dimensionality of small sample size data should be considered. Standardization of methodology and harmonization of image quality are one of the most important challenges with radiomics methodology. Even though there are current issues in radiomics methodology, it is expected that radiomics will be clinically useful in personalized medicine for oncology."
3D 캐릭터의 모션 생성 및 제어를 위한 최신 기술 동향,2019,"['Computer graphics', 'Motion capture', 'Data-based animation', 'Physics-based animation', 'Artificial intelligence']",,"In this study, we study the development and control of motion of 3D character animation and discuss the development direction of technology. Character animation has been developed as a data-based method and a physics-based method. The animation generation technique based on the keyframe method has been made possible by the development of the hardware technology, and the motion capture device has been used. Various techniques for effectively editing the motion data have appeared. At the same time, animation techniques based on physics have emerged, which realistically generate the motion of the character by physically optimized numerical computation. Recently, animation techniques using machine learning have shown new possibilities for creating characters that can be controlled by the user in real time and are expected to be developed in the future."
언어 정보의 계량화와 시각화: 감성 어휘의 분포 의미 표현,2019,"['linguistic information', 'distributional semantics', 'sentiment lexicon', 'word embedding', 'visualisation', '언어 정보', '분포 의미', '감성 어휘', '단어 임베딩', '시각화']",,"The purpose of this article is to examine the whole process of a methodology of quantifying and visualising linguistic information as a case study of sentiment lexicon building. Sentiment lexicons are one of the core language resources in sentiment analysis which aims to detect and classify the sentiments based on semantic concepts similar to human sensibility as an application of language analysis. More recently, the application of linguistic information is going from proposing the quantification of lexical information of frequency to developing a language model using machine learning methods, so-called deep learning, and inferencing linguistic categories. Thus, this study shows word embedding and its visualization for expressing lexical information used for sentiment analysis."
하이브리드 드롭아웃,2019,"['deep neural network', 'dropout', 'co-adaptation', 'overfitting', 'hybrid method', '심층신경망', '드롭아웃', '공적응', '과적합', '하이브리드방법']",수 많은 모수들을 가지고 있는 방대한 심층신경망은 매우 강력한 기계학습 방법이지만 모형의 과도한 융통성으로 인하여 과적합문제를 내포하고 있다. 드롭아웃 방법은 크기가 큰 신경망의 과적합 문제를 해결하는 다양한 방법들 중 하나이며 매우 효과적인 방법으로 알려져 있다. 드롭아웃 방법은 훈련과정에서 각각의 표본에 다른 모형을 적용하는데 이들 모형은 입력과 은닉층의 노드들을 무작위로 제거한 모형들 중에 임의로 선택된다. 본 연구에서는 임의로 선택된 모형에 둘 이상의 표본을 적용하여 모형의 가중치들에 대한 추정치의 안정성을 높이는 하이브리드 드롭아웃 방법을 제시하였다. 실제 자료를 이용한 시뮬레이션 결과 노드의 선택확률과 모형의 적합에 사용되는 표본의 수를 적절하게 선택하여 기존의 방법에 비하여 추정치의 변동성이 감소시킬 수 있었으며 동시에 검증자료에 대한 최저오차도 줄일 수 있음을 보였다.,"Massive in-depth neural networks with numerous parameters are powerful machine learning methods, but they have overfitting problems due to the excessive flexibility of the models. Dropout is one methods to overcome the problem of oversized neural networks. It is also an effective method that randomly drops input and hidden nodes from the neural network during training. Every sample is fed to a thinned network from an exponential number of different networks. In this study, instead of feeding one sample for each thinned network, two or more samples are used in fitting for one thinned network known as a Hybrid Dropout. Simulation results using real data show that the new method improves the stability of estimates and reduces the minimum error for the verification data."
의사결정나무를 이용한 낙동강 본류 구간의 남조류 발생특성 연구,2019,"['Nakdong river', 'Cyanobacteria', 'Visualization analysis', 'Decision trees', 'Algal bloom warning system', '낙동강', '남조류', '시각화분석', '의사결정나무', '조류경보제']","남조류의 대발생은 대량 번성 및 사멸에 따라 수체 내 산소 고갈 및 유기물 증가와 같은 문제를 야기하고 있다. 매년 여름철폭염 및 가뭄의 영향으로 조류대경보가 발령되고 있으며, 낙동강 본류 구간의 선제적 녹조관리를 위해 남조류 발생특성을 정량적으로 규명할 필요가 있다. 본 연구에서는 시각화 분석 및 상관관계 분석을 이용한 남조류 발생 주요 영향인자 분석과더불어 머신러닝 기법인 의사결정나무를 이용하여 영향인자에 따른 남조류 발생조건을 정량적으로 분석하였다. 8개 보 모든지점에서 기상학적 요인인 기온과 SPI 가뭄지수는 남조류 세포수와 유의한 상관관계 특성을 보였다. 이는 폭염일수 증가 및가뭄에 따른 수체 내 물의 혼합 차단 및 성층현상이 지속되어 남조류 발생을 촉진시키는 것으로 보여지며, 장기적으로 기상학적 영향을 고려한 남조류 발생의 선제적 관리도 필요할 것으로 판단된다.","The occurrence of cyanobacteria causes problems such as oxygen depletion and increase of organic matter in the water body due to mass prosperity and death. Each year, Algae bloom warning System is issued due to the effects of summer heat and drought. It is necessary to quantitatively characterize the occurrence of cyanobacteria for proactive green algae management in the main Nakdong river. In this study, we analyzed the major influencing factors on cyanobacteria bloom using visualization and correlation analysis. A decision tree, a machine learning method, was used to quantitatively analyze the conditions of cyanobacteria according to the influence factors. In all the weirs, meteorological factors, temperature and SPI drought index, were significantly correlated with cyanobacterial cell number. Increasing the number of days of heat wave and drought block the mixing of water in the water body and the stratification phenomenon to promote the development of cyanobacteria. In the long term, it is necessary to proactively manage cyanobacteria considering the meteorological impacts."
Sugarcane ORF finder: the web‑application for mining genes from sugarcane genome,2019,"['Sugarcane', 'ORF', 'web‑application', 'genome']",,"Sugarcane is one of the most important multi-purpose crops that are native to tropical regions. As commercial sugarcane is an interspecific hybrid between Saccharum officianarum and Saccharum spontaneum, the genome size of sugarcane has been reported around 10 Gbase. From this reason, it has been hard to build the reference level assembly resulting in partial contigs. With the advance of third generation sequencers and assembly strategies, recently, two sugarcane genome assemblies were published representing monoploidy of sugarcane cultivar and whole genome of S. spontaneum. Synergetically, the genome-editing technology is advanced that can eventually facilitate the sugarcane breeding and the necessity of utilizing genome sequence is also arising for sugarcane researchers to find guide-RNA binding site by the machine learning algorithms or human inspection. Here, we built web-application for the researchers to find the open reading frame (ORF) of sugarcane genes easily with a query gene ID and catalog candidate gene list by query sentences (http://pgl.gnu.ac.kr/sugar cane_orf_finde r/). This enables the researchers to find their genes of interest and directly observe the ORF structure of the query gene and design precise guide RNA for genome editing."
"안전도, 뇌파도, 근전도 분석을 통한 수면 단계 분류",2019,"['Sleep Stage Classification', 'CNN Algorithm', 'DNN Algorithm', 'EEG', 'EOG', 'EMG', 'Polysomnography']",,"Insufficient sleep time and bad sleep quality causes many illnesses and it’s research became more and more important. The most common method for measuring sleep quality is the polysomnography(PSG). The PSG is a test used to diagnose sleep disorders. The most common PSG data is obtained from the examiner, which attaches several sensors on a body and takes sleep overnight. However, most of the sleep stage classification in PSG are low accuracy of the classification. In this paper, we have studied algorithm for sleep level classification based on machine learning which can replace PSG. EEG, EOG, and EMG channel signals are studied and tested by using CNN algorithm. In order to compensate the performance, a mixed model using both CNN and DNN models is designed and tested for performance."
Estimation of ground-level particulate matter concentrations through the synergistic use of satellite observations and process-based models over South Korea,2019,,,"<P><p><strong>Abstract.</strong> Long-term exposure to particulate matter (PM) with aerodynamic diameters &lt;<span class='thinspace'></span>10 (PM<span class='inline-formula'><sub>10</sub></span>) and 2.5<span class='thinspace'></span><span class='inline-formula'>µ</span>m (PM<span class='inline-formula'><sub>2.5</sub></span>) has negative effects on human health. Although station-based PM monitoring has been conducted around the world, it is still challenging to provide spatially continuous PM information for vast areas at high spatial resolution. Satellite-derived aerosol information such as aerosol optical depth (AOD) has been frequently used to investigate ground-level PM concentrations. In this study, we combined multiple satellite-derived products including AOD with model-based meteorological parameters (i.e., dew-point temperature, wind speed, surface pressure, planetary boundary layer height, and relative humidity) and emission parameters (i.e., NO, <span class='inline-formula'>NH<sub>3</sub></span>, <span class='inline-formula'>SO<sub>2</sub></span>, primary organic aerosol (POA), and HCHO) to estimate surface PM concentrations over South Korea. Random forest (RF) machine learning was used to estimate both PM<span class='inline-formula'><sub>10</sub></span> and PM<span class='inline-formula'><sub>2.5</sub></span> concentrations with a total of 32 parameters for 2015-2016. The results show that the RF-based models produced good performance resulting in <span class='inline-formula'><i>R</i><sup>2</sup></span> values of 0.78 and 0.73 and root mean square errors (RMSEs) of 17.08 and 8.25<span class='thinspace'></span><span class='inline-formula'>µ</span>g<span class='thinspace'></span>m<span class='inline-formula'><sup>−3</sup></span> for PM<span class='inline-formula'><sub>10</sub></span> and PM<span class='inline-formula'><sub>2.5</sub></span>, respectively. In particular, the proposed models successfully estimated high PM concentrations. AOD was identified as the most significant for estimating ground-level PM concentrations, followed by wind speed, solar radiation, and dew-point temperature. The use of aerosol information derived from a geostationary satellite sensor (i.e., Geostationary Ocean Color Imager, GOCI) resulted in slightly higher accuracy for estimating PM concentrations than that from a polar-orbiting sensor system (i.e., the Moderate Resolution Imaging Spectroradiometer, MODIS). The proposed RF models yielded better performance than the process-based approaches, particularly in improving on the underestimation of the process-based models (i.e., GEOS-Chem and the Community Multiscale Air Quality Modeling System, CMAQ).</p> </P>"
Developing a Big Data Analytic Model and a Platform for Particulate Matter Prediction: A Case Study,2019,"['Particulate matter', 'Big data', 'Prediction model', 'Artificial intelligence', 'Fine dust']",,"While we’ve made progress over the last century, qualities of air and drinking water are getting worse. For the health of the people, many countries recommend to wear a mask or not to go out in case of bad air quality. However, the lack of real-time measurement and poor prediction of the concentration of fine dust provide inaccurate alarm and information to residents. The real-time air quality measurement data is the big data of new field which should be complemented with the national meteorological data in order to meet the demands for the customers and public through the other relevant data. In this study we aim to build a system to predict PM (particulate matter)—microscopic dust generated by human activities, such as the burning of fossil fuels in vehicles, power plants and various industrial processes. We also develop an optimized path of sprinkler vehicles to improve air condition in a local city. The density of PM is affected by meteorological variables such as temperature, rainfall, humidity and wind speed. To predict the density of (fine) PM, we use machine learning techniques considering not only meteorological data from observatories, but spatial factors like pollutants, floating populations and traffic volumes of a certain location using LTE(Long Term Evolution) signals. We suggested a conceptual architecture of a system and illustrate a case study of preprocessing and analyzing the data gathering from a local province with results and discussions."
Prediction Model of User Physical Activity using Data Characteristics-based Long Short-term Memory Recurrent Neural Networks,2019,"['Data Mining', 'Neural Networks', 'LSTM', 'Prediction', 'Mobile Healthcare']",,"Recently, mobile healthcare services have attracted significant attention because of the emerging development and supply of diverse wearable devices. Smartwatches and health bands are the most common type of mobile-based wearable devices and their market size is increasing considerably. However, simple value comparisons based on accumulated data have revealed certain problems, such as the standardized nature of health management and the lack of personalized health management service models. The convergence of information technology (IT) and biotechnology (BT) has shifted the medical paradigm from continuous health management and disease prevention to the development of a system that can be used to provide ground-based medical services regardless of the user’s location. Moreover, the IT-BT convergence has necessitated the development of lifestyle improvement models and services that utilize big data analysis and machine learning to provide mobile healthcare-based personal health management and disease prevention information. Users’ health data, which are specific as they change over time, are collected by different means according to the users’ lifestyle and surrounding circumstances. In this paper, we propose a prediction model of user physical activity that uses data characteristics-based long short-term memory (DC-LSTM) recurrent neural networks (RNNs). To provide personalized services, the characteristics and surrounding circumstances of data collectable from mobile host devices were considered in the selection of variables for the model. The data characteristics considered were ease of collection, which represents whether or not variables are collectable, and frequency of occurrence, which represents whether or not changes made to input values constitute significant variables in terms of activity. The variables selected for providing personalized services were activity, weather, temperature, mean daily temperature, humidity, UV, fine dust, asthma and lung disease probability index, skin disease probability index, cadence, travel distance, mean heart rate, and sleep hours. The selected variables were classified according to the data characteristics. To predict activity, an LSTM RNN was built that uses the classified variables as input data and learns the dynamic characteristics of time series data. LSTM RNNs resolve the vanishing gradient problem that occurs in existing RNNs. They are classified into three different types according to data characteristics and constructed through connections among the LSTMs. The constructed neural network learns training data and predicts user activity. To evaluate the proposed model, the root mean square error (RMSE) was used in the performance evaluation of the user physical activity prediction method for which an autoregressive integrated moving average (ARIMA) model, a convolutional neural network (CNN), and an RNN were used. The results show that the proposed DC-LSTM RNN method yields an excellent mean RMSE value of 0.616. The proposed method is used for predicting significant activity considering the surrounding circumstances and user status utilizing the existing standardized activity prediction services. It can also be used to predict user physical activity and provide personalized healthcare based on the data collectable from mobile host devices."
SW교육에서 중학생의 핵심 역량 분석,2019,"['SW교육', '컴퓨팅 사고력', '정보문화소양', '중학교', 'software education', 'computational thinking skills', 'information ethics', 'middle schools']","본 연구는 SW교육을 통하여 길러질 수 있는 중학생의 핵심 역량을 분석하기 위하여 수행되었다. 2015년에 국가 교육 정책으로 시작된 SW교육은 2018년에 2015 개정 정보과 교육과정이 학교 현장에 적용되면서 본격적으로 확대되었다. 현재 SW교육은 초등학교에서는 실과 수업에서 17시간 이상, 중학교에서는 정보 수업에서 34시간 이상으로 편성되어 운영되고 있다. SW교육의 목적은 컴퓨팅 사고력을 가진 창의 인재 양성에 있으며, 핵심 역량은 컴퓨팅 사고력과 정보문화소양이다. 우리나라에서 SW교육이 전방위적으로 실행되면서, 교육 전문가들은 SW교육의 교육내용과 방법, 평가 방법 등에 관한 다양한 연구를 수행하고 있다. 이러한 흐름에 맞추어 본 연구는 정보 교육의 실행 첫해에 중학생을 대상으로 SW교육 역량을 평가하고 그 결과를 분석하였다. 본 연구에 참여한 대상은 2018년에 2015 개정 정보과 교육과정에 따라 정보 교육을 받은 중학교 1학년 2,949명이다. 본 연구에서 사용한 평가 도구의 내용은 자동판매기를 소재로 한 문제해결 과제이며, 총 13개의 5지 선다형 문항으로 구성되었다. 학생들의 정보 교과에 대한 흥미와 효능감 평가 도구는 5단계 라이커트 척도를 이용한 10개 문항으로 구성되었다. 전체 평가 시간은 약 50분 내외로 소요되었다. 그 결과, 중학교 학생들의 SW교육 역량은 평균 5.45점(13점 만점)으로 조사되었다. 학습자 특성 변인에 따른 분석에서, 여학생이 남학생보다 더 높은 점수를 얻었다. 정보 교과에 대한 흥미와 효능감이 높은 학생들이 그렇지 않은 학생들보다 SW교육 역량이 더 높았다. 하지만, 교육 환경 변인에 따른 분석에서는 집단 간의 차이가 통계적으로 유의미하지 않았다. 이러한 결과를 바탕으로 후속 연구를 위한 시사점을 제시하였다.","This study was conducted for analyzing core competencies of middle school students in SW education. Since 2015, Korean government has implemented SW education as a nation-wide educational policy. Middle schools have operated information classes as a core subject of the 2015 revised national curriculum in 2018. Over 34 class hours for the information subject were organized in middle schools and 17 hours in elementary schools. The purpose of the SW education is to foster creative individuals with computational thinking. The core competency enhanced in SW education includes computational thinking skills and information ethics. This study measured the competencies of the first-year middle school students who had received information classes in 2018. In total, 2,949 middle school students were participated in the study. The content of the assessment tool was related to the problems about a vending machine, and the type of test items was a multiple choice type with five options. Also, the interest and self-efficacy about the information subject of the participants was measured using 10 items with five-point Likert scale. The measurement took about 50 minutes in total. As a result, the SW education competency of the middle school students was 5.45 out of 13 points. In the additional analysis of learner characteristics, girls students outperformed boy students. Also, students who have more interest and self-efficacy on information subject outperformed students who have less interest and self-efficacy. However, such factors as class hours and learning content had little significant influence on the students’ competency in SW education. Based on the result, some implications were discussed for further studies."
Time Series Classification of Cryptocurrency Price Trend Based on a Recurrent LSTM Neural Network,2019,"['Classification', 'Gradient Boosting', 'Long Short-Term Memory', 'Time Series Analysis']",,"In this study, we applied the long short-term memory (LSTM) model to classify the cryptocurrency price time series. We collected historic cryptocurrency price time series data and preprocessed them in order to make them clean for use as train and target data. After such preprocessing, the price time series data were systematically encoded into the three-dimensional price tensor representing the past price changes of cryptocurrencies. We also presented our LSTM model structure as well as how to use such price tensor as input data of the LSTM model. In particular, a grid search-based k-fold cross-validation technique was applied to find the most suitable LSTM model parameters. Lastly, through the comparison of the f1-score values, our study showed that the LSTM model outperforms the gradient boosting model, a general machine learning model known to have relatively good prediction performance, for the time series classification of the cryptocurrency price trend. With the LSTM model, we got a performance improvement of about 7% compared to using the GB model."
인공생명과 포스트휴먼 사회의 윤리 : 테드 창의 「소프트웨어 객체의 생애주기」를 중심으로,2019,"['테드 창', '인공생명', '인공적 도덕 행위자', '상향식 발달 접근법', '포스트휴머니즘', 'Ted Chiang', 'artificial life', 'artificial moral agent', 'bottom-up developmental approach', 'posthumanism']",,"This paper examines the ethical issues accompanied by the emergence of artificial life represented in Ted Chiang’s “The Lifecycle of the Software Objects.” While depicting the rise and fall of a software vendor in near-future society, this novella explores the social interest regarding how we act to forge a new relationship within the posthuman society. In focusing on the social status of artificial life, Chiang argues the definition of person should be amended so as to embrace artificial agent as a new part of it. For developing the concept of responsibility and agency, this paper investigates the form of education for artificial agents to show how it affects each phase of cognitive development. Specifically, this story instantiates the bottom-up approach for machine learning programs. Chiang delineates the strengths and limitations of this method to indicate the various stages of social development in artificial life. Having invoked the idea of posthuman ethics, this paper notes a conceptual shift in morality is required to accept an extended range of social interaction."
Epigenetics and Depression: An Update,2019,"['Depression', 'Biomarkers', 'Epigenetics', 'Gene-environment interactions', 'Stress.']",,"Objective Depression is associated with various environmental risk factors such as stress, childhood maltreatment experiences, and stressful life events. Current approaches to assess the pathophysiology of depression, such as epigenetics and gene-environment (GxE) interactions, have been widely leveraged to determine plausible markers, genes, and variants for the risk of developing depression.Methods We focus on the most recent developments for genomic research in epigenetics and GxE interactions.Results In this review, we first survey a variety of association studies regarding depression with consideration of GxE interactions. We then illustrate evidence of epigenetic mechanisms such as DNA methylation, microRNAs, and histone modifications to influence depression in terms of animal models and human studies. Finally, we highlight their limitations and future directions.Conclusion In light of emerging technologies in artificial intelligence and machine learning, future research in epigenetics and GxE interactions promises to achieve novel innovations that may lead to disease prevention and future potential therapeutic treatments for depression."
Performance Counter Monitor를 이용한 FLUSH+RELOAD 공격 실시간 탐지 기법,2019,"['캐시 부채널 공격', 'FLUSH+RELOAD 공격', 'Performance Counter Monitor', '공격 탐지', 'Cache-Side Channel Attack', 'FLUSH+RELOAD Attack', 'Performance Counter Monitor', 'Attack Detection']","캐시 부채널 공격 중 하나인 FLUSH+RELOAD 공격은 높은 해상도와 적은 노이즈로 여러 악성 프로그램에서도 활용되는 등 비밀 정보의 유출에 대한 위험성이 높은 공격이다. 따라서 이 공격을 막기 위해 실시간으로 공격을 탐지하는 기술을 개발할 필요가 있다. 본 논문에서는 프로세서의 PCM (Performance Counter Monitor)를 이용한 실시간 FLUSH+RELOAD 공격 탐지 기법을 제안한다. 탐지 방법의 개발을 위해 우선 공격이 발생하는 동안 PCM의 여러 카운터들의 값들의 변화를 4가지 실험을 통해 관찰하였다. 그 결과, 3가지 중요한 요인에 의해 공격 탐지를 할 수 있다는 것을 발견하였다. 이를 바탕으로 머신 러닝의 logistic regression과 ANN(Artificial Neural Network)를 사용해 결과에 대한 각각 학습을 시킨 뒤 실시간으로 공격에 대한 탐지를 할 수 있는 알고리즘을 개발하였다. 이 탐지 알고리즘은 일정한 시간동안 공격을 진행하여 모든 공격을 감지하는데 성공하였고 상대적으로 적은 오탐률을 보여주었다.","FLUSH+RELOAD attack exposes the most serious security threat among cache side channel attacks due to its high resolution and low noise. This attack is exploited by a variety of malicious programs that attempt to leak sensitive information. In order to prevent such information leakage, it is necessary to detect FLUSH+RELOAD attack in real time. In this paper, we propose a novel run-time detection technique for FLUSH+RELOAD attack by utilizing PCM (Performance Counter Monitor) of processors. For this, we conducted four kinds of experiments to observe the variation of each counter value of PCM during the execution of the attack. As a result, we found that it is possible to detect the attack by exploiting three kinds of important factors. Then, we constructed a detection algorithm based on the experimental results. Our algorithm utilizes machine learning techniques including a logistic regression and ANN(Artificial Neural Network) to learn from different execution environments. Evaluation shows that the algorithm successfully detects all kinds of attacks with relatively low false rate."
선박의 기관실에서의 연기 검출을 위한 LBP-GLCM 알고리즘에 관한 연구,2019,"['Engine room vision', 'Video-based', 'Smoke detection', 'LBP', 'GLCM', '기관실', '영상기반', '연기 검출', 'LBP', 'GLCM']",선박의 기관실에서 사용하고 있는 화재 검출기는 연기나 열이 검출기에 도달해야 하지만 기관실의 공기 흐름은 기기의 사용유무에 따라 매우 유동적이기 때문에 상부에 설치된 검출기에 도달하기에는 많은 시간이 필요하다. 이러한 단점을 보완하기 위해 근래에는 영상을 기반으로 화재를 검지하는 연구가 이루어지고 있다. 영상기반의 연기 검지는 공기의 흐름에 영향을 받지 않으며 전송속도가 빠르기 때문에 화재의 초기 검지에 효율적이다. 본 연구는 기관실에서 연기 발생기로 발생시킨 연기의 확산모습을 녹화한 영상으로 실험을 수행하였다. 연기의 질감특징을 추출하는 LBP와 GLCM연산자를 사용하여 생성된 학습 데이터를 기계학습 분류기인 SVM으로 학습한 후 분류하여 검출 성능을 평가함으로서 연기가 상부에 설치되어 있는 검출기까지 상승하지 않더라도 영상기반으로 먼저 검지 가능함을 확인하였다.,"The fire detectors used in the engine rooms of ships offer only a slow response to emergencies because smoke or heat must reach detectors installed on ceilings, but the air flow in engine rooms can be very fluid depending on the use of equipment. In order to overcome these disadvantages, much research on video-based fire detection has been conducted in recent years. Video-based fire detection is effective for initial detection of fire because it is not affected by air flow and transmission speed is fast. In this paper, experiments were performed using images of smoke from a smoke generator in an engine room. Data generated using LBP and GLCM operators that extract the textural features of smoke was classified using SVM, which is a machine learning classifier. Even if smoke did not rise to the ceiling, where detectors were installed, smoke detection was confirmed using the image-based technique."
손목형 웨어러블 디바이스에서 사람의 심박변화와 활동강도를 이용한 운동 검출 방법,2019,"['웨어러블 디바이스', '운동 검출', '생체원리', '생체신호', '행동 인식', 'Wearable Device', 'Exercise Detection', 'Physiological Principal', 'Physiological Signal', 'Activity Recognition']","웰니스에 대한 관심이 증대됨에 따라 개인의 건강상태를 웨어러블 디바이스로 모니터링하는 연구들이 늘어나고 있다. 이에 따라 웨어러블 디바이스에서 운동과 일상 활동을 구분하는 다양한 방법들이 연구되어 왔다. 이러한 기존 연구는 대부분 기계학습을 활용한 방식이다. 하지만 개인별 학습 데이터에 의존적인 과적합 문제와 연속적인 사건으로 구성되는 사람의 행동을 독립적으로 취급하여 인식 결과가 중간에 끊기고 오인행동이 생기는 문제가 있다. 이에 본 연구는 운동 시 심박이 오르내리는 생체반응 원리를 기반으로 한 운동 상태 검출 방법을 제안한다. 제안하는 방법은 3축 가속도 센서와 PPG 센서를 통해 활동강도 및 심박 수를 산출하여 심박 회복기를 판단한 후, 활동강도 검사 또는 심박 상승기 검사를 통해 운동 상태를 검출한다. 실험 결과에서 제안하는 알고리즘은 평균 정확도 98.64%, 정밀도 98.05%, 재현율 98.62%로 기존 알고리즘보다 개선된 모습을 보였다.","As interest in wellness grows, There is a lot of research about monitoring individual health using wearable devices. Accordingly, a variety of methods have been studied to distinguish exercise from daily activities using wearable devices. Most of these existing studies are machine learning methods. However, there are problems with over-fitting on individual person’s learning, data discontinuously recognition by independent segmenting and fake activity. This paper suggests a detection method for exercise activity based on the physiological response principle of heart rate up and down during exercise. This proposed method calculates activity intensity and heart rate from triaxial and photoplethysmography sensor to determine a heart rate recovery, then detects exercise by estimating activity intensity or detecting a heart rate rising state. Experimental results show that our proposed algorithm has 98.64% of averaged accuracy, 98.05% of averaged precision and 98.62% of averaged recall."
Time Series Classification of Cryptocurrency Price Trend Based on a Recurrent LSTM Neural Network,2019,"['Classification', 'Gradient Boosting', 'Long Short-Term Memory', 'Time Series Analysis']",,"In this study, we applied the long short-term memory (LSTM) model to classify the cryptocurrency price timeseries. We collected historic cryptocurrency price time series data and preprocessed them in order to makethem clean for use as train and target data. After such preprocessing, the price time series data weresystematically encoded into the three-dimensional price tensor representing the past price changes ofcryptocurrencies. We also presented our LSTM model structure as well as how to use such price tensor as inputdata of the LSTM model. In particular, a grid search-based k-fold cross-validation technique was applied to findthe most suitable LSTM model parameters. Lastly, through the comparison of the f1-score values, our studyshowed that the LSTM model outperforms the gradient boosting model, a general machine learning modelknown to have relatively good prediction performance, for the time series classification of the cryptocurrencyprice trend. With the LSTM model, we got a performance improvement of about 7% compared to using the GBmodel."
미국 모기지 대출의 인종차별성에 대한 랜덤 포리스트 분석,2019,"['랜덤 포레스트', '모기지 대출', '변수 중요성 평가', '인종차별', 'Mortgage lending', 'race discrimination', 'random forest', 'variable importance measures']","1990년대 미국에서는 주택 모기지 대출에 인종차별이 존재하는지를 둘러싸고 많은 실증분석과 논쟁이 전개되었다. 특히 FRB 보스턴은 금융감독 당국으로서 1990년 HMDA 데이터에 자체 수집한 신용관련 정보 등을 보완하여 로짓 모형으로 분석한 결과, 은행의 대출 결정에 인종적 차별이 존재한다고 밝혔다. 본 연구는 이러한 전통적 회귀분석 방법이 인종 변수의 계수 크기와 통계적 유의성만을 검증하는 것일 뿐, 대출 결정에서 인종이라는 요소가 다른 요소들에 비해 얼마나 중요한 역할을 하는지를 검증하는 것은 아니라는 문제점을 제기한다. 이러한 문제의식 하에서 본 연구는 머신러닝의 핵심 방법론 중의 하나인 랜덤 포리스트 기법에서 변수의 중요성을 평가하는 방법을 사용하여 과연 인종 변수가 대출의 성공을 결정하는 데 얼마만큼 중요한 역할을 하는지 평가한다. 분석 결과, 로짓 모형에서는 인종 변수가 0.1% 수준에서 유의함에도 불구하고, 랜덤 포리스트의 중요성 평가에서는 중간보다 낮은 중요도를 가진 것으로 나오는 등 기존 연구들이 주장한 인종차별성을 반박하는 결과를 얻었다.","In the 1990s, there were many empirical analyses and debates surrounding the existence of racial discrimination in home mortgage lending in the United States. In particular, FRB Boston, a financial supervisory authority, analyzed 1990 HMDA data using a logit model by supplementing the credit information collected by itself, and found that racial discrimination existed in bank lending decisions. This study raises the problem that the traditional regression method only cares about the coefficient magnitude and statistical significance of the race variable, but does not verify how important the factor of race is in the loan decision than the other factors. Therefore, this study uses the method of evaluating the importance of variables in the random forest technique, one of the core methodologies of machine learning, to measure how important race variable plays in determining the success of the loan. Estimation results show that in the logit estimation, race variable is statistically significant at the 0.1% level, but in the variable importance measures by the random forest technique, it is found that the importance of race variable is lower than medium. This is in contrast to the racial discrimination in mortgage lending that the previous studies claim."
객체 인식에서의 속도 향상을 위한 모델 앙상블,2019,"['Object detection', 'Ensemble method', 'Convolutional neural network']",,
데이터 비식별화를 이용한 빅데이터 통합,2019,"['비식별화', '빅데이터 플랫폼', '개인정보', 'k 익명성', '최적 절단값', 'De-identification', 'big data plotform', 'privacy', 'k anonymity', 'optimal cutoff value']","여러 곳에 흩어져 있는 방대한 데이터를 통합하여 빅데이터 플랫폼을 구축하고 분석하려는 시도가 공공부문에서 민간부문에 이르기까지 활발하게 진행되고 있다. 공공 빅데이터 플랫폼은 국가발전과 국민 삶의 질을 높이기 위하여 구축되고 민간 빅데이터 플랫폼은 고객정보를 마케팅에 활용하여 기업의 이익추구와 성장을 위하여 도입되고 있다. 빅데이터 플랫폼 구축을 위하여 공공기관 및 기업이 보유한 데이터들이 서로 통합되는 과정에서 개인정보가 개인의 동의없이 조금이라도 공개되는 것은 불법이다. 이와 같은 경우에 비식별화 처리기법을 통하여 개인정보가 나타나지 않도록 가공한 후 빅데이터 플랫폼 구축작업이 진행되지만 이 과정에서 정보 손실이 발생한다. 즉, 데이터를 제공하는 입장에서는 개인정보 보호를 위해 비식별 처리 수준을 높게 하길 원하고 데이터를 제공받는 입장에서는 예측력 높은 분석모형을 만들기 위하여 정보손실이 작은 형태의 데이터를 원한다. 이와 같은 이해관계의 상충으로 인하여 비식별 처리 데이터의 활용 자체가 불가능할 경우도 발생한다. 본 논문에서는 최적 절단값을 이용하여 빅데이터 통합 플랫폼 구축을 위한 데이터 비식별 과정에서 데이터를 제공하는 입장과 받는 입장을 동시에 만족시킬 수 있는 방법을 제안한다. 제안 방법의 성능평가를 위하여 UCI 머신러닝 저장소의 데이터를 이용한 실험을 수행한다.","Attempts to build and analyze big data platforms by integrating vast amounts of data scattered across multiple locations have been actively conducted from the public sector to the private sector. The Public big data platform is established to improve the national development and quality of life of the people, and the private big data platform is being introduced for the pursuit and profit of the enterprise by utilizing customer information for marketing. It is illegal for personal information to be disclosed without any personal consent in the process of integrating data held by public organizations and companies to build big data platform. In such a case, the big data platform construction work is performed after the personal information is not displayed through the de-identification processing technique, but information loss occurs in this process. That is, from the viewpoint of providing data, in order to protect personal information, it is desired to increase the level of de-identification processing. In the case of receiving data, in order to make a predictive analysis model. Such conflicts of interest may result in non-use of de-identified data. In this paper, we propose a method to satisfy both the position and the receiving position in data de-identification process for constructing big data platform using optimal cutoff value. Experiments using data from UCI machine learning repository are performed to evaluate the performance of the proposed method."
시각예술에서 인공지능과 빅데이터의 역할,2019,"['인공지능 창작', 'CAN', '이미지 빅데이터', '창작의도', '라벨링 데이터', 'AI art', 'CAN', 'Big data images', 'Concept of creativity', 'Labeled data']",본고는 시각예술분야에서 인공지능과 빅데이터가 이미지 분석 연구와 창작에서 어떠한 역할을 할 수 있는가에 대해 논하고 기술 도입의 선행 과제인 라벨링 데이터 구축을 제안하는 것을 목적으로 한다. 먼저 인공지능의 개념에 대해 검토하고 이미지 연구 동향과 이미지 생성 과정에 대하여 기술적 측면을 알아보았다. 인공지능 개념 분석을 통해 이미지 생성에서 인공지능의 역할을 설명하였다. 특히 인공지능은 사유의 주체가 아닌 행동의 대행자임을 논하여 창작의 주체로서의 작가의 위치와 도구로서의 인공지능의 역할을 분명히 하였다. 컴퓨터와 알고리즘을 활용한 창작사례를 살펴보면서 실행보다는 개념을 중시하는 시각예술분야의 흐름과 인공지능 창작 수용의 이론적 근거를 검토하였다. 한편 시각예술분야 분석연구의 인공지능 활용사례로 양식연구 및 독창성 연구 동향에 대해 살펴보았다. 인공지능의 양식 구분이 전통적 방법론 분류결과와 유사하며 통계적 유의성을 확보하고 있음을 논하고 이를 통해 독창성을 확보한 창작 가능성에 대하여 알아보았다. 또한 인공지능의 활용을 위해 선행 과제로서의 라벨링 이미지 빅데이터 구축의 필요성을 피력하였다.,"This paper examines the possible role that Artificial Intelligence(AI) and big data could play in the field of visual arts and aims to suggest information architecture as a preparatory stage prior to the adoption of the technology. First of all, the paper explores the concept of AI and the technical aspects of visual trends and visual production processes. The paper further explicates the role of AI in visual production processes through a conceptual analysis of AI. Specifically, if AI is simply an agent which performs assigned tasks, and not a rational being, the creative role of the author in relation to AI’s role as a tool of production is clear. By looking at case studies where computers and algorithms were employed in the creative process, this paper explores the flow of visual arts, in which concept is more important than process, and examines the theoretical foundation for accepting AI creativity. This paper suggests that visual images generated by AI through machine learning are original art works if they contain originality and creativity. Further, this paper concludes that a preparatory phase of information architecture is necessary before any attempt to use AI."
"Using toponym co-occurrences to measure relationships between places: review, application and evaluation",2019,"['Urban system', 'place name disambiguation', 'city network', 'gravity model', 'semantic relatedness', 'Randstad']",,"While there is consensus that network embeddedness of cities is of great importance for their development, the precise effect is difficult to assess because of a lack of consistent information on relations between cities. This paper presents, applies and evaluates a rather novel method to establish the strength of relationships between places, a method we refer to as ‘the toponym co-occurrence method’. This approach builds the urban system on the basis of co-occurrences of place names in a text corpus. We innovate by exploiting a so far unparalleled amount of data, namely the billions of web pages contained in the commoncrawl web archive, and by applying the method also to small places that tend to be ignored by other methods. The entire settlement system of the Netherlands is consequently explored. In addition, we innovatively apply machine learning techniques to classify these relations. Much attention is paid to solving biases deriving from place name disambiguation. Gravity modelling is employed to assess the resulting spatial organization of the Netherlands. It turns out that the gravity model fits very well with the pattern of relationships between places as found in digital space, which contributes to our assessment that the toponym co-occurrence method is a solid proxy for relationships in real space. Using the method, it is established that the relationships in the Randstad region, by many considered a coherent metropolitan entity, are actually somewhat less strong than expected. In contrast, historically important, but nowadays small cities in the periphery tend to have maintained their prominent position in the pattern of relationships. Suburban, relatively new places in the shadow of a larger city tend to be weakly related to other places. Several suggestions to further improve the method, in particular the classification of relationships, are discussed."
Analysis of Spontaneous Preterm Labor and Birth and Its Major Causes Using Artificial Neural Network,2019,['Analysis of Spontaneous Preterm Labor and Birth and Its Major Causes Using Artificial Neural Network'],,"Spontaneous preterm birth refers to the onset of labor before 37 weeks with intact fetal membranes, the causes are too diverse. Recently, there has been an increase in the number of preterm labor and birth due to aged pregnancy, multiple pregnancy through assisted reproductive technology. Newborns born before 37 weeks suffer various morbidities and mortalities, largely due to organ system immaturity.1 Therefore, it is best to analyze and predict the causes of preterm labor and prevent it through early interventions. However, the causes are so diverse and sometimes complex that it is very difficult to attempt a study to analyze the causes. Until now, most conventional existing studies have attempted to predict preterm birth through logistic regression and the random forest (under an unrealistic assumption that all other variables stay constant), focusing on identifying individual risk factors of these many causes.2 However, since the predictive power of these methods are too low, researches are being conducted to apply the artificial neural network(ANN) through machine learning techniques using large datasets for identifying major determinants of preterm birth. According to predicting high-risk preterm birth using ANN by Catley et al.,3 this method is presented a reengineered approach to the early prediction of preterm birth as a complimentary technique to the conventional procedure. This study showed that the training on the refined high-risk preterm birth model increased the network's sensitivity to 54.8%, compared to just over 20% for the non-artificially distributed preterm birth model.The purpose of this Lee and Ahn's study4 is to investigate the major determinants of preterm labor and preterm birth using ANN for Korean pregnant women. The results show that in addition to cervical length screening and previous history of preterm birth, diabetes mellitus (DM), and hypertension are the main predictors of preterm delivery, and the accuracy of this ANN method is similar to that of classic regression analysis. According to the conclusion of this study, it is important to preventive measure for DM and hypertension as well as periodic screen cervical length to prevent preterm birth. An ANN trained on selected and predictive input variables describing the preterm patient's obstetrical history can more accurately predict the risk of preterm birth.5 In the future, if we try to develop an ANN that predicts preterm labor early and accurately with more diverse and precise important causal variables (predictors) through machine training techniques using big data of many institutions, it will be a great help to create a “preterm birth prevention program”"
Time Series Classification of Cryptocurrency Price Trend Based on a Recurrent LSTM Neural Network,2019,"['Classification', 'Gradient Boosting', 'Long Short-Term Memory', 'Time Series Analysis']",,"In this study, we applied the long short-term memory (LSTM) model to classify the cryptocurrency price time series. We collected historic cryptocurrency price time series data and preprocessed them in order to make them clean for use as train and target data. After such preprocessing, the price time series data were systematically encoded into the three-dimensional price tensor representing the past price changes of cryptocurrencies. We also presented our LSTM model structure as well as how to use such price tensor as input data of the LSTM model. In particular, a grid search-based k-fold cross-validation technique was applied to find the most suitable LSTM model parameters. Lastly, through the comparison of the f1-score values, our study showed that the LSTM model outperforms the gradient boosting model, a general machine learning model known to have relatively good prediction performance, for the time series classification of the cryptocurrency price trend. With the LSTM model, we got a performance improvement of about 7% compared to using the GB model."
Analysis of the Factors Influencing Architectural Time-Predictability of Superscalar Processors,2019,"['Real-time systems', 'Time-predictability', 'Cycles per instruction', 'Standard deviation', 'Design of experiments']",,"Architectural time-predictability (ATP) is a major component in the design of real-time systems (RTS). In these systems, it is imperative to maintain temporal and logical accuracy. Hence, designers need to estimate the worst-case behavior of such systems before deploying them in real-life applications. This paper presents an experimental framework to quantify the ATP of modern superscalar processors. In addition, it aims at characterizing, modeling, and analyzing the factors that influence the ATP of such processors. Hence, a total of 33 benchmark programs derived from the Malardalen WCET benchmark suite have been simulated on a specialized superscalar processor simulator. The standard deviation of the cycles per instruction (CPI) of the simulated superscalar processor has been used to quantify ATP. In addition, an unsupervised machine learning approach has been employed to classify the benchmark programs into several clusters based on their sensitivity to different processor components. Moreover, a design of experiment (DoE) methodology has been utilized for factor screening, sensitivity analysis, model building, and design space navigation. It has been shown that the benchmark programs exhibit a varying degree of dissimilarity in their temporal behavior. In addition, the proposed framework can be used to model the ATP of superscalar processors adequately and optimize their design to increase their ATP levels."
Object Detection from Mongolian Nomadic Environmental Images,2019,"['Image processing', 'Rock-drawing image', 'Objects detection and classification.']",,"Mongolian historical and cultural monuments on settlement areas of stone inscriptions, stone images, rock-drawings, remains of cities, architecture are still telling us their stories. These monuments depict the understanding of the word, philosophical and artistic outlook, beliefs, religion, national art, language, culture and traditions of Mongols [1]. Nowadays computer science, especially computer vision is applying in the other science fields. The main problem is how to apply and which algorithm can detect and classify the objects correctly. In this paper, we propose a method to detect object from Mongolian nomadic environment images. This work proposes a method for object detection that is the combination of the binary operations in the edge detection results. We found out the best method and parameters of state-of-the-art machine learning algorithms. In experimental result, we evaluate our results with 10-fold cross validation and split 66% strategies."
시각장애인을 위한 음성 도우미 장치,2019,"['visually impaired people', 'optical camera', 'infrared camera']","시작장애인은 일상생활에서 시각저하로 인하여 색상, 지폐 금액 확인, 온도 판별 등의 불편을 겪는다. 그리하여 시각장애인을 도와주기 위한, 광학 카메라와 열화상 카메라를 이용한 시스템을 제안한다. 광학카메라는 특징 추출을 이용하여 색상 판별, 지폐 금액 확인하며, 온도 판별을 위해서 열화상 카메라를 이용한다. 버튼을 이용하여 색상, 지폐, 온도 모드를 선택하면, 해당 정보를 스피커를 통하여 음성으로 알려준다. 색상은 16가지, 지폐는 4가지, 온도는 4단계로 구분할 수 있으며, 각기 정확도는 90%이다. 향후 입력 영상 블록화, 머신러닝, 열화상 카메라 상위 버전을 통해 정확도를 개선할 수 있다. 또한, 휴대하기 편하게 지팡이에 부착하여 시각 장애인들이 더 편리하게 사용 할 수 있도록 개선 예정이다.","People with compromised visual ability suffer from many inconveniences in daily life, such as distinguishing colors, identifying currency notes and realizing the atmospheric temperature. Therefore, to assist the visually impaired people, we propose a system by utilizing optical and infrared cameras. In the proposed system, an optical camera is used to collect features related to colors and currency notes while an infrared camera is utilized to get temperature information. The user is enabled to select the desired service by pushing the button and the appreciate voice information are provided through the speaker. The device can distinguish 16 kinds of colors, four different currency notes, and temperature information in four steps and the current accuracy is around 90%. It can be improved further through block-wise input image, machine learning, and a higher version of the infrared camera. In addition, it will be attached to the stick for easy carrying and to use it more conveniently."
충격공진을 이용한 콘크리트 상태 평가를 위한 주성분 분석의 적용,2019,"['principal component analysis', 'impact resonance', 'concrete', 'delamination', 'nondestructive test']",,"Non-destructive methods such as rebound hardness method and ultrasonic method are widely studied for evaluating the physical properties, condition and damage of concrete, but are not suitable for detecting delamination and cracks near the surface due to various constraints of the site as well as the accuracy. Therefore, in this study, the impact resonance method was applied to detect the separation cracks occurring near the surface of the concrete slab and bridge deck. As a next step, the principal component analysis were performed by extracting various features using the FFT data.As a result of principal component analysis, it was analyzed that the reliability was high in distinguishing defects in concrete. This feature extraction and application of principal component analysis can be used as basic data for future use of machine learning technique for the better accuracy."
저작권법상 인공지능 창작물의 저작자와 입법적 보완,2019,"['인공지능', '프로그래머', '이용자', '저작권', '전자인간', 'artificial intelligence', 'copyright', 'programmer', 'users', 'electronic person']","인공지능이 저작권법의 영역에 가져온 가장 큰 난제는 누가 인공지능 창작물의 저작자인가이다. 인공지능은 인간의 도구로 이용되는 것부터 인간의 개입 없이 독자적으로 창작과정을 수행하는 것까지 매우 다양하게 존재하고, 그 경계도 매우 불분명하다. 저작권법상 저작자는 저작물을 창작한 자이다. 따라서 인공지능 창작물에 대하여 누가 저작자인지 여부는 인공지능에 적용된 프로그램과 인공지능의 창작에 기여한 인간들의 개입 정도에 따라 구체적으로 판단할 문제이다. 현행 저작권법의 해석론 또는 입법론으로 인공지능을 저작자로 보아야 한다는 견해, 이용자 또는 프로그래머를 저작자로 보아야 한다는 견해와 인공지능 창작물은 저작권법상의 보호대상이 아니라는 견해 등이 제시되고 있다.본고에서는 인공지능 창작물에 대하여 프로그래머를 저작자로 보아야 할 특단의 사정이 없는 이상, 인공지능의 이용자를 저작자로 보아야 한다고 하였다. 그 근거는 다음과 같다. 첫째, 이용자는 인공지능에게 필요한 지시를 하거나 일정한 자료를 입력하여 인공지능으로 하여금 자신이 원하는 창작을 하도록 한 자이므로 인공지능 창작물은 이용자의 메시지를 반영하고 있다고 볼 수 있고, 따라서 이용자를 인공지능 창작물의 기원자로 볼 수 있다는 점이다. 둘째, 공리주의적 인센티브 관점에서 볼 때에도 인공지능을 이용하여 더 많은 창작을 할 것인가 여부를 결정할 수 있는 재량권은 이용자에게 있으므로 프로그래머보다는 이용자에게 인센티브를 주는 것이 훨씬 더 효율적이라는 점이다. 셋째, 현실적으로나 기술적으로 인공지능 창작물과 인간의 창작물의 구별이 곤란하다는 점을 고려하면 인공지능 창작물을 보호하지 않을 경우 인공지능 창작물임을 스스로 공개한 자는 법적으로 보호받을 수 없는 반면에 이를 공개하지 않는 자는 사실상 보호되는 불합리한 결과가 도출될 수 있다는 점이다.한편 인공지능 창작물에 대한 입법론적 보완과 관련하여 인공지능이 자율적으로 예측이 불가능한 작품을 창작한 경우에 인공지능에게 법인격을 인정하여 저작자로 인정할 것인지(소위 전자인간)에 대하여 공리주의적 인센티브의 관점에서 본다면 이때에도 인공지능보다는 이용자에게 저작권을 주는 것이 타당하다고 보았다. 또한 인공지능 창작물의 특수성을 고려하여 인공지능 창작물의 보호기간을 제한하고, 인공지능 창작물의 등록과 식별체계를 의무화할 필요성에 대해서는 긍정하나 인공지능 창작물과 인간의 창작물을 구별한다는 것이 현실적으로 매우 어려운 점을 고려하면 그 실효성에는 한계가 있다고 보았다. 따라서 인공지능 창작물을 인간의 창작물에 비교하여 법적 보호에 있어서 차등을 둔다면 이에 대한 보완책으로 인공지능 자체에 대한 등록제도도 함께 검토할 것을 제시하였다. 마지막으로 본고에서는 인공지능의 발전 속도를 고려하면 인공지능에 의하여 야기된 여러 가지 법률문제를 입법적으로 따라 간다는 것은 한계가 있으므로 당분간 인공지능이 저작권법에 미치는 영향을 지켜보는 것도 좋은 방안이라고 보았다.","The biggest question that AI has brought to the realm of copyright law is whether AI‘s works can be protected by copyright law. There are also questions about who the authors are and whether they need the same protection as human works. However, the spectrum of artificial intelligence varies and therefore it will have to be decided specifically based on the level of the program applied to artificial intelligence and the intervention of the good man behind AI.  For example, there are various stakeholders such as programmers, users, and owners who contribute to the creation of artificial intelligence. Thus, various views are presented in terms of the interpretation of copyright law on who the creator of artificial intelligence’ work is. However, artificial intelligence is not a human being under the current copyright law, so it cannot be a author.In this paper, I thought that under the current law programmers and users could be authors. However, AIs are now evolving by Deep Learning or Machine Learning, so even if a programmer created an AI’s program, it is hard to say that the programmer could have predicted the content of works that an AI created. Therefore, this paper proposed that it be reasonable to regard users of AI as authors of AI’s works in general. It is because users use artificial intelligences for a certain purpose, and he contributes more than a trivial change by giving some instructions or inputs to the AI and/or adopting  the creative results of the AI. In addition, it is reasonable to see users as authors in light of the purpose of copyright law.This paper also observed that it is necessary to limit the protection requirements or the period of protection of AI’s works, in comparison to human works, considering the possible impact that the mass production of artificial intelligence has brought to the copyrighted works market.However, pointing out that there are practical limitations, it suggested that the registration of artificial intelligence itself be reviewed along with legislative supplementations mentioned above."
Word2Vec과 WordNet 기반 불확실성 단어 간의 네트워크 분석에 관한 연구,2019,"['텍스트 마이닝', '계량정보학', '불확실성', 'Word2Vec', '워드넷', '네트워크 분석', 'Text Mining', 'Bibliometrics', 'Uncertainty', 'Word2Vec', 'WordNet', 'Network Analysis']","과학에서 지식의 불확실성은 명제가 현재 상태로는 참도 거짓도 아닌 불확실한 상태를 의미한다. 기존의 연구들은 학술 문헌에 표현된 명제를 분석하여 불확실성을 의미하는 단어를 수동적으로 구축하고 구축한 코퍼스를 대상으로 규칙 기반, 기계 학습 기반의 성능평가를 수행해왔다. 불확실성 단어 구축의 중요성은 인지하고 있지만 단어의 의미를 분석하여 자동적으로 확장하고자 하는 시도들은 부족했다. 한편, 계량정보학이나 텍스트 마이닝 기법을 이용하여 네트워크의 구조를 파악하는 연구들은 다양한 학문분야에서 지적 구조와 관계성을 파악하기 위한 방법으로 널리 활용되고 있다. 따라서, 본 연구에서는 기존의 불확실성 단어를 대상으로 Word2Vec을 적용하여 의미적 관계성을 분석하였고, 영어 어휘 데이터베이스이자 시소러스인 WordNet을 적용하여 불확실성 단어와 연결된 상위어, 하위어 관계와 동의어 기반 네트워크 분석을 수행하였다. 이를 통해 불확실성 단어의 의미적, 어휘적 관계성을 구조적으로 파악하였으며, 향후 불확실성 단어의 자동 구축의 확장 가능성을 제시하였다.","Uncertainty in scientific knowledge means an uncertain state where propositions are neither true or false at present. The existing studies have analyzed the propositions written in the academic literature, and have conducted the performance evaluation based on the rule based and machine learning based approaches by using the corpus. Although they recognized that the importance of word construction, there are insufficient attempts to expand the word by analyzing the meaning of uncertainty words. On the other hand, studies for analyzing the structure of networks by using bibliometrics and text mining techniques are widely used as methods for understanding intellectual structure and relationship in various disciplines. Therefore, in this study, semantic relations were analyzed by applying Word2Vec to existing uncertainty words. In addition, WordNet, which is an English vocabulary database and thesaurus, was applied to perform a network analysis based on hypernyms, hyponyms, and synonyms relations linked to uncertainty words. The semantic and lexical relationships of uncertainty words were structurally identified. As a result, we identified the possibility of automatically expanding uncertainty words."
딥페이크의 이미지 조작: 심층적 자동화에 따른 사실의 위기와 푼크툼의 생성,2019,"['deepfake', 'image manipulation', 'deep automation', 'factuality', 'punctum', '딥페이크', '이미지 조작', '심층적 자동화', '사실성', '푼크툼']","딥페이크(Deepfake) 기술에 대한 우려가 커지고 있다. 딥페이크는 기계학습을 통해 원본 이미지나 동영상 위에 다른 이미지를 중첩함으로써 조작된 영상을 만들어내는 기술이다. 회화, 아날로그 사진, 디지털 이미지와 영상에 이르기까지 이미지를조작하는 기술은 과거에도 있었지만, 딥페이크는 조작 기법과 도구, 수행자 등의 측면에서 독특한 속성을 가진다. 특히 이미지 조작의 진정한 가내화를 야기한다는 점에서 과거의 조작 기술들과 근본적인 차이를 보인다. 이 글은 이를 ‘심층적 자동화’ 의 논리로 개념화하여 설명하고, 딥페이크의 문화적 의미를 ‘정체성의 도용과 사실의 위기’, ‘관계성에 기반을 둔 푼크툼의 생성’이라는 두 차원으로 제시하였다. 여기에 더해 알고리즘 기반의 이미지 조작 기술이 더 발전할 경우 야기되는 문제점을간략히 살피고 이에 대응할 수 있는 방안을 검토하였다. 이를 통해 일상 생활에 급격히 진입하고 있는 새로운 기술에 대한 이해를 높이고 사회적 관심을 환기하는 데 기여하고자 하였다.","Concerns about ‘Deepfake’ tachnology are growing. Deepfake is a technique that creates manipulated images by superimposing images onto original images or videos using a machine learning algorithm. In contrast with the previous techniques that have manipulated paintings, analog photos, digital images, and videos, Deepfake has its own characteristics in terms of its tools, operation principle, and operators. The fundamental difference is that Deepfake truly ‘domesticates’ image manipulation works.Conceptualizing the process as ‘deep automation’, this paper interprets cultural meanings of the logic in two dimensions: ‘crisis of factuality’ and ‘creation of punctum’. In addition, this paper tries to anticipate the possible problems caused by the development of algorithm-based image manipulation techniques to examine countermeasures. In this way, we intend to contribute to the understanding of new technologies that are rapidly penetrating every area of everyday life."
인공지능의 개인정보 자동화 처리가 야기하는 차별 문제에 관한 연구,2019,,"대한민국 헌법 제10조는 인간의 존엄과 행복추구권을, 또한 동법 제11조 제1항은 “모든 국민은 법 앞에 평등하다. 누구든지 성별⋅종교 또는 사회적 신분에 의하여 정치적⋅경제적⋅사회적⋅문화적 생활의 모든 영역에 있어서 차별을 받지 아니한다”라고 각 명시함으로써 인간의 존엄을 중심으로 자유와 권리를 보장받도록 하고 있다.인공지능을 앞세운 4차 산업혁명시대 우리는 법 앞에 평등하고, 각종 차별로부터 자유로울까? 특히 빅데이터 기반의 인공지능 시스템에서 자동화 처리로 인하여 정보주체가 받는 차별은 이미 우리 사회 깊숙이 자리하고 있지만, 우리는 차별을 당하고 있다는 것조차 지각하지 못하는 듯하다. 개인정보의 수집부터 삭제에 이르기까지 처리 메커니즘이 명확했던 과거와 달리, 거의 전 과정이 자동화된 오늘날 누구도 처리과정을 알 수 없는 이른바 ‘블랙박스화’로 인한 투명성 및 공정성의 문제는 새로운 사회문제로 자리 잡았다.개인정보는 개인정보보호원칙에 따라 최소한의 정보만 투명하게 수집⋅처리되어야 하지만, 첨단 기술발전으로 인한 자동화 처리로 자신의 정보가 어디서 어떻게 수집⋅처리되는지 알기 어려워 정보주체의 개인정보자기결정권 행사가 사실상 불가능해지고 있다. 이러한 자동화 처리는 정보주체의 차별로 이어져 인종 간의 갈등으로 비화될 수 있고, 나아가 자동화 처리로 대표되는 인공지능에 대한 막연한 거부감으로 기술발전을 가로막는 장벽이 될 수 있다. 그러나 인공지능은 인간이 만든 알고리즘에 의해 작동한다는 사실을 간과해서는 안되는바, 자동화 처리로 인한 정보주체의 차별 문제를 해결하기 위한 연구가 필요하다. 이에 본고에서는 알고리즘의 편향성을 알고리즘 설계⋅제작자가 의도한 경우와 의도치 못한 경우로 나누어 살펴보고, 차별의 개념 및 정의를 통한 인공지능의 차별에 대한 국내외 사례를 살펴볼 것이다. 인공지능의 차별로부터 어떻게 정보주체를 보호할지 개인정보보호관점에서 바라보기 위해 EU의 GDPR을 중심으로 살펴보고, 이를 통하여 현재 인공지능의 주류인 머신러닝으로부터 비롯된 불투명성을 알고리즘의 본질로부터 해결하는 방안을 찾아보도록 하겠다.","Article 10. of the Constitution of the Republic of Korea provides human dignity and the right to pursue happiness, and Article 11. paragraph 1 of the same law states, “All people are equal before the law. No one is discriminated against in all areas of political, economic, social or cultural life by gender, religion or social status.” In each case, freedom and rights are guaranteed around human dignity.Will we be equal before the law and free from all kinds of discrimination during the fourth industrial revolution era with artificial intelligence? The discrimination that data subject receive from automated processing, especially in big data-based artificial intelligence systems, is already deep in our society, but we do not seem to be even aware that we are being discriminated against. Unlike in the past when the mechanisms for processing personal data from personal data collection to deletion were clear, the issue of transparency and fairness caused by so-called ‘black boxing’, where no one knows the process of handling it, has emerged as a new social issue.Although the minimum amount of personal data should be collected and processed transparently according to the principles of relating to processing of personal data, it is becoming virtually impossible for the data subject to exercise its own personal data decision-making authority because it is difficult to know where and how to collect and process its data through automated processing due to advanced technology development. This automated processing can lead to bias and discrimination of data subjects, which can escalate into racial conflict, and further become a barrier to technological development with a vague sense of rejection of artificial intelligence represented by automated processing. However, we should not overlook the fact that artificial intelligence works by human-made algorithms, and research is needed to solve the problem of bias and discrimination in data subjects due to automated processing.In this paper, we will divide the bias of algorithms into the intended and unintended cases of algorithms, and look at domestic and foreign cases of discrimination of artificial intelligence through the definition of discrimination. In order to see how to protect the data subject from discrimination of artificial intelligence, we will focus on the EU’s GDPR from a personal data protection perspective, and look for solutions based on the nature of the algorithm for the opacity derived from the machine learning algorithm, which is currently the mainstream of artificial intelligence."
민간경비 경쟁력 강화를 위한 경비업법령의 개선방안,2019,"['Private Security', 'Security', 'Law of Security', 'Education', 'Training', 'Competitiveness', '민간경비', '경비원', '경비업법', '교육훈련', '경쟁력 강화']",,"Purpose : The purpose of this study is to revise the Security Business Act to meet the level of social needs so that the competitiveness of private expenses can be strengthened. Quantitative and qualitative growth of private expenses will require systematic readjustment of the law on the security industry. Method : This study focused on analyzing the existing generally presented dissertations, and conducted extensive literature research methods through various research reports, policy reports, books, and search on the Internet. Further, the police white paper and the police statistics yearbook published by the National Police Agency were additionally referenced to find out the overall status of the security law. Conclusion : The conclusions of this study are as follows. First, the criteria for reasons of disqualification should be strengthened along with the requirements for permission for the security business, and the criteria for irregularities related to the permit should be revised to strictly apply administrative punishments so that strong penalties can be made. In addition, the Security Business Act should be amended so that a review of actual permits can be made without any formal screening regulations. Second, the system for responding to machine expenses should be defined as 15 minutes from dispatch to on-site arrival and on-site response, and the system for cooperation with the private security service should be enacted so that it can be connected to the police and be available at the same time. In addition, the treatment of private security personnel should be improved so that they can have a companion status, not an assistant to the police. Third, the Security Business Act should be revised so that private security education can become a reality. It should be allowed to be on-site learning based on practice rather than theory, and the same subjects that were completed during the new training sessions should be minimized between job training, and the rest of the time should be organized into practical-based courses related to on-site practice."
Predictive gas sensor based on thermal fingerprints from Pt-SnO<sub>2</sub> nanowires,2019,"['Gas sensor', 'Nanowire', 'Tin oxide', 'Platinum', 'Selectivity', 'Thermal fingerprint']",,"<P><B>Abstract</B></P>  <P>The detection of volatile compounds is important for a broad variety of applications. Metal oxide gas nanosensors are tiny, inexpensive devices that can be integrated into any application, but they lack selectivity. On the other hand, electronic noses consisting of sensors arrays comprised of different active materials are complex as well as expensive to fabricate and use. This paper presents a novel approach using Pt-decorated tin oxide (SnO<SUB>2</SUB>) nanowires at different working temperatures to produce a virtual sensor array exploiting the thermal fingerprints of the different gases. With only one nanostructured material (Pt-SnO<SUB>2</SUB>) and 5 temperature values, the system could qualitatively and quantitatively discriminate all the gasestested (all reducing gases). The sensor could detect selectively which gas is present (with an accuracy of 100%) at what concentration (with an overall average error of approximately 14%, down to 3.7% for benzene). The results showed that single metal oxide resistive nanosensors could achieve a good level of real selectivity exploiting the thermal fingerprints from a temperature gradient.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  SnO<SUB>2</SUB> nanowires are grown via chemical vapor deposition in a horizontal quartz tube. </LI> <LI>  Nanowires are decorated with Pt nanoparticles through γ-ray radiolysis. </LI> <LI>  Response values at different temperatures are combined and used as gas fingerprint. </LI> <LI>  Different machine learning techniques are used to classify 5 different gases. </LI> <LI>  Support vector regression is used to estimate the gas concentration of each gas. </LI> </UL> </P>"
Segment 단위 PPG 신호 기반 본인 인식,2019,"['PPG', 'Biometric', 'Wearable device', 'Random Forest', '기계학습']",,
섹스로봇 (Sex robot)의 상용화가 갖는 윤리적 문제와 윤리적 정당성 확보에 대하여,2019,"['섹스로봇의 상용화', '데이비드 레비 (David Levy)', '이익평등고려의 원칙', '캐이틀린 리차드슨 (Katheleen Richardson)', '매춘', 'Roboethics', 'Sex robots', 'Practical Ethics', 'Kathleen Richardson']","레비 (David Levy)는 2007년 그의 저서 Love and Sex with Robot 에서 인간이 로봇과 성관계를 갖는 것이 일상화 될 날이 멀지 않았고, 매춘과 같은 부분에 있어 로봇이 인간을 대체하게 될 것이라고 주장한다. 실제로 2010년 기존의 섹스돌(sex doll)에 인공지능을 탑재한 트루컴퍼니언(Truecompanion)사의 ‘록시(Roxxxy)’로부터 성적 교감뿐만 아니라 철학, 과학, 음악에 이르는 다양한 분야의 대화와 일상적인 농담 역시 가능한 2015년 리얼보틱스(Realbotix) 사의 ‘하모니(Harmony)’에 이르기까지 섹스로봇산업의 규모와 기술력은 나날이 발전하고 있다. 이에 섹스로봇이 인간의 모든 성생활에 있어 중요한 역할을 담당하게 될 것이라는 예측 역시 가능할 수 있다. 하지만 이에 대한 우려도 적지 않다. 대표적으로 리차드슨(Kathleen Richardoson)은 레비의 주장에 내재된 심각한 윤리적 문제에 주목하며 섹스로봇의 개발과 상용화를 반대한다. 특히, 레비가 예를 들고 있는 매춘 산업에 있어 섹스로봇이 사람을 대신할 수 있다는 주장에 대하여, “여러 관계 속에서 마주하게 되는 사람을 권리를 가진 인격체(person)가 아닌 사물(things)로 간주하게 되는 문제가 발생할 수 있다”며 섹스로봇의 개발과 사용은 윤리적으로 정당하지도 안전하지도 않다고 주장한다. 본 논문은 이들 중 하나의 입장을 견지하거나 옹호하지 않는다. 본 논문의 목적은 섹스로봇의 개발과 사용이 갖는 이점과 리차드슨이 제시한 윤리적 문제점 등을 검토하고, 이에 대해 취할 수 있는 윤리적 관점을 제시하는 것이다. 본 논문의 말미에는 피터 싱어의 ‘이익평등고려의 원칙 (The principle of equal consideration of interests)’에 근거하여 섹스로봇의 개발과 사용은 윤리적으로 정당화 될 가능성이 있음을 조심스럽게 검토해 볼 것이다.","David Levy, in his book Love and Sex with Robots (2007), argues that it is not too long before humans will have sex and fall in love with robots and that robots will replace humans in prostitution. In fact, in 2010, ‘Roxxxy’ of Truecompanion, which is basically a developed version of the existing sex doll, was created. It comes with an A.I. system that can learn the user’s sexual interests. The ’Harmony’ (2015) of Realbotix is capable of dialogues in many different fields from philosophy to science. It also has the capacity to feel and to learn its user’s orgasmic pattern. Like this, the size and technology of the sex robot industry is growing rapidly. It may also be possible to predict that sex robots will play an important role in the sex life of all humans. However, Kathleen Richardson focuses on the serious ethical issues involved in the commercialization of sex robots and Levy’s argument. In particular, with regards to the claim that sex robots will become a substitute for the prostitution industry, she argues that “extending relations of prostitution into machines is neither ethical, nor is it safe,” and that the “development of sex robots will further reinforce relations of power that do not recognise both parties as human subjects.” If she is right, then the commercialization of sex robots may disrespect human dignity because she consistently claims that “you can have sex without love, you can have love without sex, but you cannot have love and sex outside of personhood”.  This study does not endorse or advocate Levy’s or Richardson’s positions. The main aim of this study is to present ethical perspectives that can be considered in terms of the ethical issue presented by Richardson. By examining the advantages of the development and use of sex robots and the ethical problems presented by Richardson, I will carefully suggest the possibility of ethical justification for the development and use of sex robots based on Peter Singer’s principle of equal consideration of interests."
한국어 음소 최소대립쌍의 계량언어학적 연구: 초성 자음을 중심으로,2019,"['minimal pair', 'dictionary', 'syllable-initial', 'consonant', 'part of speech', 'functional load']",,"The paper investigates the minimal pair of Korean phonemes quantitatively. To achieve this goal, I calculated the number of consonant minimal pairs in the syllable-initial position as both raw counts and relative counts, and analyzed the part of speech relations of the two words in the minimal pair. 『Urimalsaem』 was chosen as the object of this study because it was judged that the minimal pair analysis should be done through a dictionary and it is the largest among Korean dictionaries. The results of the study are summarized as follows. First, there were 153 types of minimal pairs out of 337,135 examples. The ranking of phoneme pairs from highest to lowest was ‘ㅅ-ㅈ, ㄱ-ㅅ, ㄱ-ㅈ, ㄱ-ㅂ, ㄱ-ㅎ, ..., ㅆ-ㅋ, ㄸ-ㅋ, ㅉ-ㅋ, ㄹㅃ, ㅃ-ㅋ’. The phonemes that played a major role in the formation of the minimal pair were /ㄱ, ㅅ, ㅈ, ㅂ, ㅊ/, in that order, which showed a high proportion of palatals. The correlation between the raw count of minimal pairs and the relative count of minimal pairs was found to be quite high r=0.937. Second, 87.91% of the minimal pairs shared the part of speech (same syntactic category). The most frequently observed type has been ‘noun-noun’ pair (70.25%), and ‘vowel-vowel’ pair (14.77%) was the next ranking. It can be indicated that the minimal pair could be grouped into similar categories in terms of semantics. The results of this study can be useful for various research in Korean linguistics, speech-language pathology, language education, language acquisition, speech synthesis, and artificial intelligence-machine learning as basic data related to Korean phonemes."
지능형 전망모형을 결합한 로보어드바이저 알고리즘,2019,"['로보어드바이저', '평균분산모형', '지능형 전망모형', '블랙리터만모형', 'Robo-Advisor', 'Mean-Variance Optimization', 'Intelligent View Model', 'Black-Litterman Model']",,"Recently banks and large financial institutions have introduced lots of Robo-Advisor products. Robo-Advisor is a Robot to produce the optimal asset allocation portfolio for investors by using the financial engineering algorithms without any human intervention. Since the first introduction in Wall Street in 2008, the market size has grown to 60 billion dollars and is expected to expand to 2,000 billion dollars by 2020. Since Robo-Advisor algorithms suggest asset allocation output to investors, mathematical or statistical asset allocation strategies are applied. Mean variance optimization model developed by Markowitz is the typical asset allocation model. The model is a simple but quite intuitive portfolio strategy. For example, assets are allocated in order to minimize the risk on the portfolio while maximizing the expected return on the portfolio using optimization techniques. Despite its theoretical background, both academics and practitioners find that the standard mean variance optimization portfolio is very sensitive to the expected returns calculated by past price data. Corner solutions are often found to be allocated only to a few assets.  The Black-Litterman Optimization model overcomes these problems by choosing a neutral Capital Asset Pricing Model equilibrium point. Implied equilibrium returns of each asset are derived from equilibrium market portfolio through reverse optimization. The Black-Litterman model uses a Bayesian approach to combine the subjective views on the price forecast of one or more assets with implied equilibrium returns, resulting a new estimates of risk and expected returns. These new estimates can produce optimal portfolio by the well-known Markowitz mean-variance optimization algorithm. If the investor does not have any views on his asset classes, the Black-Litterman optimization model produce the same portfolio as the market portfolio. What if the subjective views are incorrect? A survey on reports of stocks performance recommended by securities analysts show very poor results. Therefore the incorrect views combined with implied equilibrium returns may produce very poor portfolio output to the Black-Litterman model users.  This paper suggests an objective investor views model based on Support Vector Machines(SVM), which have showed good performance results in stock price forecasting. SVM is a discriminative classifier defined by a separating hyper plane. The linear, radial basis and polynomial kernel functions are used to learn the hyper planes. Input variables for the SVM are returns, standard deviations, Stochastics %K and price parity degree for each asset class. SVM output returns expected stock price movements and their probabilities, which are used as input variables in the intelligent views model. The stock price movements are categorized by three phases; down, neutral and up. The expected stock returns make P matrix and their probability results are used in Q matrix. Implied equilibrium returns vector is combined with the intelligent views matrix, resulting the Black-Litterman optimal portfolio. For comparisons, Markowitz mean-variance optimization model and risk parity model are used. The value weighted market portfolio and equal weighted market portfolio are used as benchmark indexes.  We collect the 8 KOSPI 200 sector indexes from January 2008 to December 2018 including 132 monthly index values. Training period is from 2008 to 2015 and testing period is from 2016 to 2018. Our suggested intelligent view model combined with implied equilibrium returns produced the optimal Black-Litterman portfolio. The out of sample period portfolio showed better performance compared with the well-known Markowitz mean-variance optimization portfolio, risk parity portfolio and market portfolio. The total return from 3 year-period Black-Litterman portfolio records 6.4%, which is the highest value. The maximum draw down is -20.8%, which is also the lowest value. Sharpe Ratio shows the highest"
한반도 모자이크 영상의 토지피복분류 활용 가능성 탐색을 위한 비교 연구,2019,"['Object-based', 'Classification', 'KOMPSAT-3', 'Mosaic image']","한국항공우주연구원은 지속적으로 증가하는 공공분야의 위성영상 수요에 대응하기 위해 정부 위성정보활용협의체를 운영하고 있으며, 사용자 편의성 증진 및 위성영상 활용 활성화를 위해 매년 한반도 모자이크영상을 제작하여 제공하는 등 다양한 지원사업을 수행하고 있다. 특히 한반도 모자이크 영상의 활용도를 높이고 사용자가 손쉽게 분류 영상을 현업에 활용할 수 있도록 모자이크 영상을 분류 및 갱신하는 방안을 모색하고자 하였다. 그러나 한반도 모자이크 영상은 영상 융합 및 컬러 밸런싱 등을 적용하기 때문에 분광정보, 즉 색상왜곡이 발생하고 R, G, B 밴드만 보유하고 있다는 한계점이 있기 때문에 모자이크 영상으로 만들어낸 분류 결과가 현업에서 활용될 수 있는 수준인지 확인 및 검증이 필요하다. 따라서 본 연구에서는 모자이크 영상으로분류를 수행했을 때 그 결과물의 신뢰도를 KOMPSAT-3 영상과 비교하여 확인해보고자 하였다.연구 결과, KOMPSAT-3 영상의 분류 정확도는 약 81~86%(전체 정확도 약 85%)로 나타난 반면, 모자이크 영상분류 결과의 정확도는 약 69~72%(전체 정확도 약 72%)로 다소 낮게 나타났다. 이러한 현상은 모자이크 영상을생성하는 과정에서 영상 융합과 모자이크 과정을 거치며 본래의 분광정보가 왜곡되었을 뿐만 아니라, 컬러밴드인 R, G, B 세 가지의 밴드만 제공함에 따라 NDVI나 NDWI 정보를 실제 모자이크 영상이 아닌 KOMPSAT- 3 영상에서 추출하였기 때문으로 해석된다. 비록 현재로서는 모자이크 영상으로 토지피복분류를 수행하여 사용자에게 배포하기에는 무리가 있을 것으로 판단되나, 추후 모자이크 영상을 제작할 때 분광정보 왜곡을 최소화할 수 있는 방법을 모색하고 R, G, B 밴드뿐만 아니라 NIR 밴드도 함께 제공하거나 모자이크 영상에 적합한영상분류 기술을 개발할 필요가 있을 것으로 생각된다. 또한 지형특성별 분류결과 비교분석과 관심객체별 기계학습 등을 통한 영상분류 방법을 개발하는 등 관련 연구를 지속한다면, 추후 분광정보가 제한된 영상들도 활용도가 높아질 수 있을 것으로 기대된다.","The KARI (Korea Aerospace Research Institute) operates the government satellite information application consultation to cope with ever-increasing demand for satellite images in the public sector, and carries out various support projects including the generation and provision of mosaic images on the Korean Peninsula every year to enhance user convenience and promote the use of satellite images. In particular, the government has wanted to increase the utilization of mosaic images on the Korean Peninsula and seek to classify and update mosaic images so that users can use them in their businesses easily. However, it is necessary to test and verify whether the classification results of the mosaic images can be utilized in the field since the original spectral information is distorted during pan-sharpening and color balancing, and there is a limitation that only R, G, and B bands are provided. Therefore, in this study, the reliability of the classification result of the mosaic image was compared to the result of KOMPSAT-3 image. The study found that the accuracy of the classification result of KOMPSAT-3 image was between 81~86% (overall accuracy is about 85%), while the accuracy of the classification result of mosaic image was between 69~72% (overall accuracy is about 72%). This phenomenon is interpreted not only because of the distortion of the original spectral information through pan-sharpening and mosaic processes, but also because NDVI and NDWI information were extracted from KOMPSAT- 3 image rather than from the mosaic image, as only three color bands (R, G, B) were provided. Although it is deemed inadequate to distribute classification results extracted from mosaic images at present, it is believed that it will be necessary to explore ways to minimize the distortion of spectral information when making mosaic images and to develop classification techniques suitable for mosaic images as well as the provision of NIR band information. In addition, it is expected that the utilization of images with limited spectral information could be increased in the future if related research continues, such as the comparative analysis of classification results by geomorphological characteristics and the development of machine learning methods for image classification by objects of interest."
증거수집 방식으로서 작동중인 정보시스템에서의 포렌식 절차의 검토,2019,"['디지털 포렌식', '휘발성 데이터', '메모리 덤프', '암호키', '재현가능성', '암호화', 'digital forensics', 'volatile data', 'memory dumps', 'encryption keys', 'reproducibility', 'encryption']","지금까지 작동중인 정보시스템에서의 포렌식은 사고 대응의 수법의 1개로 알려졌지만 실제로는 조사 담당자의 역량 부족 및 유효성의 인식부족 등의 이유로 많이 활용되지 않았다. 하지만 현재는 사이버 범죄가 빈발하기 때문에 작동중인 정보시스템에서의 포렌식은 피해 단말기에 대한 사고대응에서 뿐만 아니라, 공격자 단말기에 대한 해석에서도 빠뜨릴 수 없는 기술이다. 그러므로 현장의 요구에 대응하기 위해서 작동중인 정보시스템에서의 포렌식의 유효성을 명확히 이해한 후에 그 구체적 실시 기법을 체계적으로 정리하고 그것을 업무처리 지침으로 제정할 필요성이 요구되고 있다.빅 데이터에 대응한 디지털 포렌식이 주목받고 있으며, 대량의 데이터를 효율적으로 해석하기 위한 연구가 진행되고 있다. 또, 인공지능을 바탕으로 한 기계학습 기술에 의한 자동분석 툴의 연구가 이루어지고 있으며 상용도구로서 제품화도 이루어지고 있다.기존 디지털 포렌식에서는 현장에서의 해석을 피하고, 일단 보전작업자가 현장에서 증거품인 단말기를 가져간 뒤 분석센터에서 고도의 스킬을 가진 조사담당자가 시간을 들여 해석을 해왔다. 그러나 이러한 종래의 기법에서는 조사를 원활하게 진행할 수 없기 때문에 현장에서 할 수 있는 것은 가능한 현장에서 처리한다는 새로운 포렌식의 기법이 필요하게 되었다. 그래서 본 연구에서는 최근 유력한 해석기법으로 주목 받고 있는 실시간 대응이나 메모리 포렌식 기술에 주목하고 작동중인 정보시스템이나 단말기에 대한 실시간 포렌식을 실시할 경우 그 유효성을 검토한 뒤, 작동중인 정보시스템에서의 포렌식의 기법을 체계적으로 정비하고 구체적 실시 기법을 제안함을 목적으로 한다.본 연구의 결론으로 조사담당자는 적극적으로 작동중인 정보시스템에서의 포렌식을 실시해야 한다. 본 연구에서는 실시간 대응이나 메모리 포렌식의 기술에 주목하고 작동상태 포렌식의 유효성 검토 및 구체적 실시기법의 제안을 했다. 향후의 과제로서는 새로 개발되는 도구나 법률 개정 등의 상황변화에 대해서 조사담당자가 뒤처짐이 없이 대응해야 할 점을 지적할 수 있다.","Until now, live forensics has been known as one of the ways of responding to accidents, but in practice it has been rarely implemented due to lack of skill of investigators and lack of awareness of effectiveness. However, due to the high frequency of cyber crime, live forensics is an indispensable technique not only for responding to accidental terminals but also for interpreting attacker terminals. Therefore, in order to respond to the needs of the field, it is necessary to clearly understand the effectiveness of live forensics, and then systematically organize the specific implementation techniques and establish them as guidelines. Digital forensics corresponding to big data is attracting attention, and researches for efficiently analyzing large amounts of data are being conducted. In addition, research on automatic analysis tools based on machine learning technology based on artificial intelligence is being con-ducted, and commercialization is being made as a commercial tool. In the existing digital forensics, the analysis is avoided in the field, and once the maintenance worker takes the terminal as evidence in the field, the investigator with high skill in the analysis center spends time analyzing it. However, such a conventional method cannot be conducted smoothly, so a new forensic method that requires what can be done on site is required. Therefore, this study focuses on the technology of live response or memory forensics, which is attracting attention as a most promising interpretation technique, and examines the validity of live forensics for mobile terminals. The purpose of this study is to systematically improve the live forensic technique and to propose a concrete implementation technique. As a conclusion of this study, investigators should actively conduct live forensics. In this study, I focused on the technology of live response and memory forensics, and examined the validity of live forensics and suggested concrete implementation methods. As a future task, it is possible to point out that the investigators should respond to changes in the situation such as newly developed tools or legal amendments without delay."
시스템적인 군집 확인과 뉴스를 이용한 주가 예측,2019,"['온라인 뉴스', '주가 예측', '무작위 행렬 이론', '계층적 군집 분석', 'Online News', 'Stock prediction', 'Random matrix theory', 'hierarchical clustering']","빅데이터 시대에 정보의 양이 급증하고, 그중 많은 부분을 차지하는 문자열 정보를 정량화하여 의미를 찾아낼 수 있는 인공지능 방법론이 함께 발전하면서, 텍스트 마이닝을 통해 주가 예측에 적용해 온라인 뉴스로 주가를 예측하려는 시도가 다양해지고 있다. 이러한 주가 예측의 방법은 대개 예측하고자 하는 기업의 뉴스로 주가를 예측하는 방식이다. 하지만 특정 회사의 뉴스만이 그 회사의 주가에 영향을 주는 것이 아니라, 그 회사와 관련성이 높은 회사들의 뉴스 또한 주가에 영향을 줄 수 있다. 그러나 관련성이 높은 기업을 찾는 것은 시장 전반의 공통적인 영향과 무작위 신호 때문에 쉽지 않다. 따라서 기존 연구들은 주로 미리 정해진 국제 산업 분류표준에 기반을 둬 관련성이 높은 기업을 찾았다. 하지만 최근 연구에 따르면, 국제 산업 분류 표준은 섹터에 따라 동질성이 다르며, 동질성이 낮은 섹터는 그들을 모두 함께 고려하여 주가를 예측하는 것이 성능에 악영향을줄 수 있다는 한계점을 가진다.이러한 한계점을 극복하기 위해, 본 논문에서는 주가 예측 연구에서 처음으로 경제물리학에서 주로 사용되는 무작위 행렬 이론을 사용하여 시장 전반 효과와 무작위 신호를 제거하고 군집 분석을 시행하여 관련성이 높은 회사를 찾는 방법을 제시하였다. 또한, 이를 기반으로 관련성이 높은 회사의 뉴스를 함께 고려하며 다중 커널 학습을 사용하는 인공지능 모형을 제시한다. 본 논문의 결과는 무작위 행렬 이론을 통해 시장 전반의 효과와무작위 신호를 제거하여 정확한 상관 계수를 찾아 군집 분석을 시행한다면 기존 연구보다 더 좋은 성능을 보여준다는 것을 보여준다.","Because stock price forecasting is an important issue both academically and practically, research in stock price prediction has been actively conducted. The stock price forecasting research is classified into using structured data and using unstructured data. With structured data such as historical stock price and financial statements, past studies usually used technical analysis approach and fundamental analysis. In the big data era, the amount of information has rapidly increased, and the artificial intelligence methodology that can find meaning by quantifying string information, which is an unstructured data that takes up a large amount of information, has developed rapidly. With these developments, many attempts with unstructured data are being made to predict stock prices through online news by applying text mining to stock price forecasts.The stock price prediction methodology adopted in many papers is to forecast stock prices with the news of the target companies to be forecasted. However, according to previous research, not only news of a target company affects its stock price, but news of companies that are related to the company can also affect the stock price. However, finding a highly relevant company is not easy because of the market-wide impact and random signs. Thus, existing studies have found highly relevant companies based primarily on pre-determined international industry classification standards. However, according to recent research, global industry classification standard has different homogeneity within the sectors, and it leads to a limitation that forecasting stock prices by taking them all together without considering only relevant companies can adversely affect predictive performance.To overcome the limitation, we first used random matrix theory with text mining for stock prediction.Wherever the dimension of data is large, the classical limit theorems are no longer suitable, because the statistical efficiency will be reduced. Therefore, a simple correlation analysis in the financial market does not mean the true correlation. To solve the issue, we adopt random matrix theory, which is mainly used in econophysics, to remove market-wide effects and random signals and find a true correlation between companies. With the true correlation, we perform cluster analysis to find relevant companies.Also, based on the clustering analysis, we used multiple kernel learning algorithm, which is an ensemble of support vector machine to incorporate the effects of the target firm and its relevant firms simultaneously. Each kernel was assigned to predict stock prices with features of financial news of the target firm and its relevant firms.The results of this study are as follows. The results of this paper are as follows. (1) Following the existing research flow, we confirmed that it is an effective way to forecast stock prices using news from relevant companies. (2) When looking for a relevant company, looking for it in the wrong way can lower AI prediction performance. (3) The proposed approach with random matrix theory shows better performance than previous studies if cluster analysis is performed based on the true correlation by removing market-wide effects and random signals.The contribution of this study is as follows. First, this study shows that random matrix theory, which is used mainly in economic physics, can be combined with artificial intelligence to produce good methodologies. This suggests that it is important not only to develop AI algorithms but also to adopt physics theory. This extends the existing research that presented the methodology by integrating artificial intelligence with complex system theory through transfer entropy. Second, this study stressed that finding the right companies in the stock market is an important issue. This suggests that it is not only important to study artificial intelligence algorithms, but how to theoretically adjust the input values. Third, we confirmed ..."
프로세스 마이닝을 이용한 공공서비스의 품질 측정: N시의 건축 인허가 민원 서비스를 중심으로,2019,"['Process mining', 'Process map', 'Process pattern', 'Building licensing complaint service', 'Public service quality measure', '프로세스 마이닝', '프로세스 맵', '프로세스 패턴', '건축 인허가 민원 서비스', '공공서비스 품질 측정']","전자정부를 포함한 다양한 형태의 공공서비스가 제공됨에 따라 공공서비스 품질에 대한 국민의 요구 수준이점점 높아지고 있다. 공공서비스의 품질을 높이기 위해서 공공서비스 품질에 대한 상시적 측정과 개선이 필요함에도 불구하고 전통적인 설문조사는 비용과 시간이 많이 소요되어 한계가 있다. 따라서 공공서비스에서 발생하는 데이터를 기반으로 원하는 시점에 언제라도 공공서비스의 품질을 빠르고 정확하게 측정할 수 있는 분석적기법이 필요하다.본 연구에서 공공서비스의 품질을 데이터 기반으로 분석하기 위해 N시의 건축 인허가 민원 서비스를 대상으로 프로세스 마이닝 기법을 이용하여 분석하였다. N시의 건축 인허가 민원 서비스는 분석에 필요한 데이터를확보할 수 있고 공공서비스 품질관리를 통해 타 기관으로 확산 가능할 것으로 판단되었기 때문이다.본 연구는 2014년 1월부터 2년 동안 N시에서 발생한 총 3678건의 건축 인허가 민원 서비스에 대해 프로세스마이닝을 실시하여 프로세스 맵을 그리고 빈도가 높은 부서와 평균작업시간이 긴 부서를 파악하였다. 분석 결과에 따르면 특정 시점에 한 부서별로 업무가 몰리거나 상대적으로 업무가 적은 경우가 발생하였다. 또한 민원의 부하가 늘 경우 민원완료까지 걸리는 시간이 늘어날 것이라는 합리적인 의심을 하였으나 분석 결과 상관관계는 크게 없었다. 분석 결과에 따르면 민원완료까지 걸리는 시간은 당일처리에서 1년 146일까지 매우 다양하게 분포하였다. ‘하수처리과,’ ‘수도과,’ ‘도시디자인과,’ ‘녹색성장과’의 상위 4개 부서의 누적빈도가 전체의50%를 넘고 상위 9개 부서의 누적빈도가 70%를 넘어서는 등 빈도가 높은 부서는 한정적이며 부서 간 부하의불균형이 심했다. 대부분의 민원 서비스는 서로 다른 다양한 패턴의 프로세스를 갖고 있었다.본 연구의 결과를 활용하면 특정 시점에 민원의 부하가 큰 부서를 찾아내 부서 간 인력 배치를 탄력적으로운영할 수 있을 것이다. 또한 민원 특성별 협의에 참여하는 부서의 패턴을 분석한 결과, 협의 부서 요청 시 자동화 혹은 추천에 활용할 수 있는 가능성이 보인다. 본 연구는 민원 서비스에 대한 프로세스 마이닝 분석을 통해 향후 공공서비스 품질 개선방향을 제시하는데 활용될 것으로 기대한다.","As public services are provided in various forms, including e-government, the level of public demand for public service quality is increasing. Although continuous measurement and improvement of the quality of public services is needed to improve the quality of public services, traditional surveys are costly and time-consuming and have limitations. Therefore, there is a need for an analytical technique that can measure the quality of public services quickly and accurately at any time based on the data generated from public services.In this study, we analyzed the quality of public services based on data using process mining techniques for civil licensing services in N city. It is because the N city's building license complaint service can secure data necessary for analysis and can be spread to other institutions through public service quality management.This study conducted process mining on a total of 3678 building license complaint services in N city for two years from January 2014, and identified process maps and departments with high frequency and long processing time. According to the analysis results, there was a case where a department was crowded or relatively few at a certain point in time. In addition, there was a reasonable doubt that the increase in the number of complaints would increase the time required to complete the complaints.According to the analysis results, the time required to complete the complaint was varied from the same day to a year and 146 days. The cumulative frequency of the top four departments of the Sewage Treatment Division, the Waterworks Division, the Urban Design Division, and the Green Growth Division exceeded 50% and the cumulative frequency of the top nine departments exceeded 70%. Higher departments were limited and there was a great deal of unbalanced load among departments. Most complaint services have a variety of different patterns of processes.Research shows that the number of ‘complementary’ decisions has the greatest impact on the length of a complaint. This is interpreted as a lengthy period until the completion of the entire complaint is required because the 'complement' decision requires a physical period in which the complainant supplements and submits the documents again. In order to solve these problems, it is possible to drastically reduce the overall processing time of the complaints by preparing thoroughly before the filing of the complaints or in the preparation of the complaints, or the 'complementary' decision of other complaints. By clarifying and disclosing the cause and solution of one of the important data in the system, it helps the complainant to prepare in advance and convinces that the documents prepared by the public information will be passed.The transparency of complaints can be sufficiently predictable. Documents prepared by pre-disclosed information are likely to be processed without problems, which not only shortens the processing period but also improves work efficiency by eliminating the need for renegotiation or multiple tasks from the point of view of the processor.The results of this study can be used to find departments with high burdens of civil complaints at certain points of time and to flexibly manage the workforce allocation between departments. In addition, as a result of analyzing the pattern of the departments participating in the consultation by the characteristics of the complaints, it is possible to use it for automation or recommendation when requesting the consultation department. In addition, by using various data generated during the complaint process and using machine learning techniques, the pattern of the complaint process can be found. It can be used for automation / intelligence of civil complaint processing by making this algorithm and applying it to the system. This study is expected to be used to suggest future public service quality improvement through process mining analysis on civil service."
인공지능 창작과 저작권법의 딜레마,2019,"['인공지능', '인공지능 법제도', '인공지능 창작물', '창작적 기여자', '컴퓨터 생성 저작물', '가상인간 저자', '변형적 이용', '중간 복제 행위', 'Artificial Intelligence', 'AI Legal System', 'AI Creative Works', 'Creative Contributor', 'Computer-Generated Works', 'fictional human author', 'Transformative Use', 'Intermediate Copying']","최근 급부상하고 있는 인공지능 기술이 불러오는 사회, 경제, 산업에의 파괴적 변화는 제반의 법제도 및 전통적 법률 체계에도 그 변혁의 필요성을 부추기고 있다. 인공지능은 이제 단순 반복 업무나 일정한 규칙을 두고 경쟁하는 특정 영역에서 벗어나 인간의 전유물로 여겨지던 예술창작 분야에서까지 날로 발전된 결과물을 선보이고 있다. 특정 예술가의 특징 및 기법을 모방하는 창작 수준에 그치지 않고, 주어진 주제에 맞게 독창적인 작곡을 하는 ‘IAMUS’처럼 진보된 형태의 창작 알고리즘이 등장하고 있는 것이다. 이제 AI는 창조적 기계로서 이른바 ‘테크노 크레아투라(Techno Creatura)’로 불러도 무방할 것 같다.그러나 현행 저작권법은 인간의 창작물만을 보호대상으로 삼고 있어 AI 창작물이 외견상 인간의 창작물과 구별이 어려운 수준에 이르렀음에도 불구하고 권리 적격을 결한다고 해석할 수밖에 없다. 이에 따라 본 고에서는 저작권법의 입법 취지상 AI 산업 및 기술개발에 대한 투자를 촉진하는 정책적 관점도 내재될 필요가 있다는 것을 전제로, AI 생성 작품의 창작성 요건을 어떻게 요구할지(저작물성 문제), 어느 주체에게 권리를 귀속시킬지(권리귀속 문제), AI가 저작물 학습 시 공정이용에 해당하는지(공정이용 문제), AI 생성물이 타인의 보호받는 표현을 포함하게 될 경우 저작권 침해인지(침해 문제) 등의 쟁점을 검토하였다. 이에 대한 정치한 분석을 통해 내린 결론의 핵심적 논지는 다음과 같다.첫째, 기존의 저작권 제도 하에 기능적 저작물 또는 편집저작물 등의 경우 창작성을 엄격히 판단하는 것과 같이 AI 창작물도 연구개발 및 투자 지원을 통해 기계적 구동 및 처리 수준을 고도화한 기술적 성과라는 차원에서 접근하여 기존 저작물의 성립요건 및 범위와는 별개의 차별적인 법리를 새롭게 구성할 필요가 있다는 점이다. 그리고 엄격한 요건을 결하는 AI 생성물은 공유의 영역에서 널리 이용되도록 하는 것이 공공의 이익에도 부합될 것으로 보았다.둘째, 독자적인 창작이 가능한 고도화된 알고리즘으로부터 생성된 AI 창작물의 경우 창작적 기여자로서 프로그래머에게 권리를 부여할 필요가 있다. 다만 과잉 보호를 방지하기 위하여 데이터베이스권의 존속기간인 5년보다도 단기인 3년의 존속기간을 부여할 필요성을 주장하였다.셋째, AI 창작권의 인정 여부와 관계없이 인간 창작물과의 오인·혼동을 방지하기 위하여 임의(任意)의 등록 표시제도 도입이 반드시 필요하다고 보았다. 또한 AI 기술을 접목시켜 자동적으로 유사성을 판단해주는 시스템을 개발하는 것도 제도적 차원에서 고려할 수 있는 대안으로 제시하였다.넷째, AI 창작의 활성화를 위하여 학습과정 및 서비스 이용 단계에서 저작물 이용에 대한 침해를 면제하는 조항이 필요하다. 비영리 목적의 경우 현행법 제35조의3의 공정이용에 해당할 것으로 추측되나, 이는 일반조항일 뿐이며 실제 영리 목적에 있어서 제약이 발생하므로 관련하여 공정이용에 관한 특칙 조항의 마련이 필요할 것이다.AI 창작물의 보호에 관한 논의에 있어서 현 저작권 제도 내에서 창작에의 직접적 기여가 없더라도 상당한 투자 및 노력에 따른 기술적 성과를 보호하는 데이터베이스권을 인정하고 있고, 원저작물을 토대로 새로운 창작적 가치를 창출하거나 매개, 전달 등의 일정한 노력에 대하여 권리를 인정하고 있는 2차적작성권이나 ...","The disruptive changes in society, economy and industry brought on by the rapidly emerging artificial intelligence technology are also fueling the need for innovation in all legal systems. Artificial intelligence is now showing its ever-evolving results in the field of art creation, which has been regarded as the preserve of human beings. Moving from the level of creation that imitates the characteristics and techniques of a particular artist, advanced forms of creative algorithms such as IAMUS, which makes original compositions to a given subject are emerging. AI is now a creative machine and can be called the “Techno Creatura.” However, the current Copyright law only protects human creations, so AI creations cannot be protected by Copyright laws even if they reach the level of human creations. Therefore, the legislative intent of the Copyright law also needs to include a policy perspective that facilitates investment in AI industry and technology development. Accordingly, this paper reviewed issues such as the requirement for recognition of the creativity of AI-generated works, the attribution of the rights of AI-generated works, whether they belong to Fair Use if AI learns protected works, and if the AI products are copyright infringement if they include protected expressions of others. The key arguments for the conclusions reached through the analysis are as follows.First, just as the creativity of functional or editorial works was strictly determined in existing Copyright laws, AI creations need to be approached in terms of technological achievements that have enhanced the level of mechanical processing, and the legal principles separate from the requirements and scope of existing works need to be newly formulated. And AI works that do not meet strict requirements should be used as shares.Second, for AI creations generated from advanced algorithms that enable independent creation, it is necessary to grant the programmer rights as creative contributors. However, it would be reasonable to grant three years of right, which is shorter than the five years of the database right, to prevent excessive protection.Third, it is imperative to introduce a voluntary registration marking system to prevent misunderstanding or confusion with human creations regardless of whether or not AI creative rights are recognized. It can also be considered institutionally to develop a system that automatically determines similarities by incorporating AI technologies.Fourth, clauses exempting infringement on the use of works during the learning process and service use phase are needed to promote AI creation. For non-profit purposes, it is assumed to be Fair Use under current law, but this is only a general provision and will require special provisions on Fair Use, since restrictions arise in practice for profit.In discussing the protection of AI creations, it is necessary to refer to database rights, adaptation rights and neighboring rights under the current Copyright law. Because AI creations have never been traded at high prices and there are few cases where they are actively used for actual businesses in Korea, the rights issue for AI creations has not progressed to the legislative stage. As the paper noted, however, it is time to form a new legal principle through the creation of AI, which is separate from human copyright."
인공지능 기반 자동행정과 법치주의,2019,"['Artificial intelligence', 'Automatic Administration', 'Rule of law', 'National compensation', 'AI Algorithm', '인공지능', '자동행정', '법치주의', '국가배상', '인공지능 알고리즘']","행정은 헌법적 가치의 실현이라는 본연의 목적에 충실하기 위해 다양한 기술을 통해 행정의 효율성과 합리성, 민주성을 제고해 왔다. 최근 정보통신 기술과 인공지능 기술이 서로 접목되면서 우리사회는 산업혁명, 정보혁명을 넘어 이제 지능정보기술에 기반해 인간과 사물의 인지･사고 능력을 강화시키는 지능혁명을 맞이하고 있다. 이러한 변화는 최근 종종 4차산업혁명으로 총칭되기도 한다.인공지능을 활용한 새로운 정보기술은 엔터테인먼트, 의료, 금융, 주식투자, 자동차 운전, 건축 설계, 우주항공 등 사회전반에서 인공지능을 통하여 처리할 수 있는 영역을 확대하고 있다.4차산업혁명을 견인하는 대표적인 기술로 주목받고 있는 인공지능기술은 민간의 영역은 물론 치안, 교통관리, 재난대응, 안전관리 등 다양한 행정의 영역에서 그 활용가능성이 주목받고 있다. 아직은 기술적인 수준이 기존 전자적 행정과 본질적으로 다르지 않는 현실적 한계를 가지고 있지만, 인공지능기술이 규제행정에 있어 합리성과 효율성을 제고하는데 크게 기여할 수 있을 것이라는 기대는 향후 공행정 분야에 있어 인공지능기술의 활용 범위를 확대시켜 나갈 것으로 예상된다.그러나 기존 업무에 대한 인공지능의 기술적 대체가능성, 비용 및 편익 등과 같은 현실적인 기준이 중요한 일반 민간분야와 달리 행정의 책임성과 공공성을 본질적 요소로 하는 공공분야에서는 과연 행정작용에 있어 인공지능을 활용할 수 있는가에 대해서는 다른 측면의 검토가 필요하다. 특히, 인공지능기술에 따라 산출된 자동적 행정결정의 경우에는 기존의 단순한 행정자동결정(예: 과속단속카메라에 의한 과속단속, 컴퓨터추첨에 따른 학교배정 등)과 달리 알고리즘의 복잡성, 결과예측곤란성 등으로 인해 전통적인 행정법이론의 적용에 적지 않은 논란을 야기할 것으로 예상된다. 즉, 행정작용이 인공지능시스템을 활용해 자동적으로 이루어지는 행정(이하 ‘인공지능 기반 자동행정’이라 한다)의 경우, 그에 따라 산출된 행정작용의 법적 성질, 재량행위의 영역에서의 제한성, 법치주의 관점에서의 수용성과 합법성 조건 등에 관한 법이론적 검토가 요구된다. 아울러 인공지능기반 자동행정에 의해 국민이 손해를 입은 경우 현행 국가배상법의 규정과 법리를 고려할 때 구제상 장애는 없는지도 살펴야 할 것이다.이에 아래에서는 인공지능의 기술적 특성과 활용 현황을 살펴보고, 인공지능기술이 공행정의 영역에서 가지는 가능성과 한계는 무엇이며, 행정에 있어서 인공지능기술 활용시 담보되어야 할 합헌성･합법성 요소는 무엇인지에 대해 논한다. 비록 현재 인공지능 기반 행정 사례의 현실적인 제한성으로 말미암아 불가피하게 일정한 가정과 추상성을 토대로 분석하는 한계를 지닐 것이나 인공지능기술을 공행정 분야에 활용하는데 최소한의 공법적 기준을 제시하고, 향후 법이론적 발전의 단초를 제공하는 시론적 고찰의 의미를 가질 것으로 기대한다.","Administrations have improved the efficiency, rationality and democracy of administration through various technologies in order to be faithful to the purpose of realizing constitutional values. Recently, with the integration of ICT and artificial intelligence technology, our society is going beyond the industrial revolution and the information revolution, and now it is intellectual revolution that strengthens the recognition and thinking ability of people and things based on intelligent information technology. These changes are often referred to as the fourth industrial revolution in recent years.A few administrative agencies have already begun to adopt this technology, while others have clear potential in the near term to use algorithms to shape official decisions over both rulemaking and adjudication. It is no longer fanciful to envision a future in which government agencies could effectively make law by robot, a prospect that understandably conjures up dystopian images of individuals surrendering their liberty to the control of computerized overlords. The idea of algorithmic regulation might appear to offend one or more traditional doctrines, such as the nondelegation doctrine, procedural due process, equal protection, or principles of reason-giving and transparency. Governmental reliance on machine learning should be approached with measured optimism about the potential benefits such technology can offer society by making government smarter and its decisions more efficient and just.In the following, we examine the technical characteristics of artificial intelligence and its application, what are the possibilities and limitations of artificial intelligence in the field of public administration, and what are the constitutional and legitimate elements to be secured in the use of artificial intelligence."
