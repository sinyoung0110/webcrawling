title,date,keywords,abstract,multilingual_abstract
RNN을 활용한 태양광 발전량 예측 알고리즘 설계,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Recognition of English letters Using RNN and CNN,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
스켈레톤 데이터의 상관관계를 활용한 RNN기반 행위 인식 기법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
대화 단위의 화행 분석을 위한 RNN-CNN 기반 한국어 화행 분석 시스템,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
반복 구매제품의 재구매시기 예측을 위한 다층퍼셉트론(MLP) 모형과 순환신경망(RNN) 모형의 성능비교,2017,"['Purchase Timing', 'Recommender', 'Neural Network', 'Recurrent Neural Network', 'Franchise Business', 'Repurchase Product']",국문 초록 정보 없음,"Existing studies for recommender have focused on recommending an appropriate item based on the customer preference. However, it has not yet been studied actively to recommend purchase timing for the repurchase product despite of its importance. This study aims to propose MLP and RNN models based on the only simple purchase history data to predict the timing of customer repurchase and compare performances in the perspective of prediction accuracy and quality. As an experiment result, RNN model showed outstanding performance compared to MLP model. The proposed model can be used to develop CRM system which can offer SMS or app based promotion to the customer at the right time. This model also can be used to increase sales for repurchase product business by balancing the level of order as well as inducing repurchase of customer."
RNN LSTM과 ACO를 이용한 감성 분석을 통한 컨텐츠 추천 시스템에 관한 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
RNN 을 이용한 소스코드 언어 변환 모델,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
RNN 알고리즘을 이용한 보행분석 기반 개인 식별방법 구현,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
RNN 기반 음성 감정인식 기계학습 알고리즘,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
확장된 RNN을 활용한 사람재인식 시스템에 관한 연구,2017,"['CNN', 'RNN', 'Unsupervised Learning', 'Person-Reidentification']","사람의 빈번한 자세 변화, 그리고 background clutter과 occlusion으로 인해 Person Re-identificatio는 컴퓨 터 비전 분야에서 가장 어려운 부분이다. 비겹침 카메라의 이미지는 어떤 사람을 다른 사람과 구별하기 어렵게 한다. 더욱 나은 성능 일치를 달성하기 위해 대부분의 방법은 특징 선택과 거리 메트릭을 개별적으로 사용한다. 그렇게 차별 화된 표현과 적절한 거리를 얻을 수 있고, 사람과 중요한 특징의 무시 사이의 유사성을 설명할 수 있다. 이러한 상황은 우리가 이 문제를 다루는 새로운 방법을 고려하도록 한다. 본 논문에서는 Person Re-identification를 위한 3단 계층 네트워크를 갖는 향상되고 반복적인 신경 회로망을 제안하였다. 특히 RNN(Revurrent Neural Network) 모델은 반복 적인 EM(Expectation Maximum) 알고리즘과 3단 계층 네트워크를 포함하고, 차별적 특징과 지표 거리를 공동으로 학습한다. 반복적인 EM 알고리즘은 RNN 이전에 연속해 있는 CNN(Convoutional Neural Network)의 특징 추출 능 력을 충분히 사용할 수 있다. 자율 학습을 통해 EM 프레임 워크는 패치의 레이블을 변경하고 더 큰 데이터 세트를 훈 련할 수 있다. 네트워크를 더 잘 훈련시키기 위해 3단 계층 네트워크를 통해 CNN, RNN 및 풀링 계층이 공동으로 특 징 추출을 할 수 있다. 실험 결과에 따르면 비전처리 분야에서 다른 연구자의 접근 방식과 비교할 때 이 방법은 경쟁 력 있는 정확도를 얻을 수 있다. 이 방법에 대한 다른 요소의 영향은 향후 연구에서 분석되고 평가될 것이다.","The person Re-identification is the most challenging part of computer vision due to the significant changes in human pose and background clutter with occlusions. The picture from non-overlapping cameras  enhance the difficulty to distinguish some person from the other. To reach a better performance match, most methods use feature selection and distance metrics separately to get discriminative representations and proper distance to  describe the similarity between person and kind of ignoring some significant features. This situation has encouraged us to consider a novel method to deal with this problem. In this paper, we proposed an enhanced recurrent neural network with three-tier hierarchical network for person re-identification. Specifically, the proposed recurrent neural network (RNN) model contain an iterative expectation maximum (EM) algorithm and three-tier Hierarchical network to jointly learn both the discriminative features and metrics distance. The iterative EM algorithm can fully use of the feature extraction ability of convolutional neural network (CNN) which is in series before the RNN. By unsupervised learning, the EM framework can change the labels of the patches and train larger datasets. Through the three-tier hierarchical network, the convolutional neural network, recurrent network and pooling layer can jointly be a feature extractor to better train the network. The experimental result shows that comparing with other researchers’ approaches in this field, this method also can get a competitive accuracy. The influence of different component of this method will be analyzed and evaluated in the future research."
EVS 코덱에서 보청기를 위한 RNN 기반의 음성/음악 분류 성능 향상,2017,"['Speech/Music Classification', 'Recurrent Neural Network (RNN)', 'Enhanced Voice Services (EVS)', 'Hearing Aids']","본 논문에서는 recurrent neural network (RNN)을 이용하여 보청기 시스템을 위한 기존의 3GPP enhanced voice services (EVS) 코덱의 음성/음악 분류 성능을 향상시키는 방법을 제시한다. 구체적으로, EVS의 음성/음악 분류 알고리즘에서 사용된 특징벡터만을 사용하여 효과적으로 RNN을 구성한 분류기법을 제시한다. 다양한 음악장르 및 잡음 환경에 대해 시스템의 성능을 평가한 결과 RNN을 이용하였을 때 기존의 EVS의 방법보다 우수한 음성/음악 분류 성능을 보였다.","In this paper, a novel approach is proposed to improve the performance of speech/music classification using the recurrent neural network (RNN) in the enhanced voice services (EVS) of 3GPP for hearing aids. Feature vectors applied to the RNN are selected from the relevant parameters of the EVS for efficient speech/music classification. The performance of the proposed algorithm is evaluated under various conditions and large speech/music data. The proposed algorithm yields better results compared with the conventional scheme implemented in the EVS."
RNN(Recurrent Neural Network)을 이용한 기업부도예측모형에서 회계정보의 동적 변화 연구,2017,"['순환 신경망', '부도 예측', '시계열 모형', 'Recurrent Neural Network', 'Bankruptcy Prediction', 'Time-Series model']",국문 초록 정보 없음,"Corporate bankruptcy can cause great losses not only to stakeholders but also to many related sectors in society. Through the economic crises, bankruptcy have increased and bankruptcy prediction models have become more and more important. Therefore, corporate bankruptcy has been regarded as one of the major topics of research in business management. Also, many studies in the industry are in progress and important.  Previous studies attempted to utilize various methodologies to improve the bankruptcy prediction accuracy and to resolve the overfitting problem, such as Multivariate Discriminant Analysis (MDA), Generalized Linear Model (GLM). These methods are based on statistics. Recently, researchers have used machine learning methodologies such as Support Vector Machine (SVM), Artificial Neural Network (ANN). Furthermore, fuzzy theory and genetic algorithms were used. Because of this change, many of bankruptcy models are developed. Also, performance has been improved.  In general, the company’s financial and accounting information will change over time. Likewise, the market situation also changes, so there are many difficulties in predicting bankruptcy only with information at a certain point in time. However, even though traditional research has problems that don’t take into account the time effect, dynamic model has not been studied much. When we ignore the time effect, we get the biased results. So the static model may not be suitable for predicting bankruptcy. Thus, using the dynamic model, there is a possibility that bankruptcy prediction model is improved.  In this paper, we propose RNN (Recurrent Neural Network) which is one of the deep learning methodologies. The RNN learns time series data and the performance is known to be good. Prior to experiment, we selected non-financial firms listed on the KOSPI, KOSDAQ and KONEX markets from 2010 to 2016 for the estimation of the bankruptcy prediction model and the comparison of forecasting performance. In order to prevent a mistake of predicting bankruptcy by using the financial information already reflected in the deterioration of the financial condition of the company, the financial information was collected with a lag of two years, and the default period was defined from January to December of the year. Then we defined the bankruptcy. The bankruptcy we defined is the abolition of the listing due to sluggish earnings. We confirmed abolition of the list at KIND that is corporate stock information website. Then we selected variables at previous papers. The first set of variables are Z-score variables. These variables have become traditional variables in predicting bankruptcy. The second set of variables are dynamic variable set. Finally we selected 240 normal companies and 226 bankrupt companies at the first variable set. Likewise, we selected 229 normal companies and 226 bankrupt companies at the second variable set.  We created a model that reflects dynamic changes in time-series financial data and by comparing the suggested model with the analysis of existing bankruptcy predictive models, we found that the suggested model could help to improve the accuracy of bankruptcy predictions. We used financial data in KIS Value (Financial database) and selected Multivariate Discriminant Analysis (MDA), Generalized Linear Model called logistic regression (GLM), Support Vector Machine (SVM), Artificial Neural Network (ANN) model as benchmark.   The result of the experiment proved that RNN’s performance was better than comparative model. The accuracy of RNN was high in both sets of variables and the Area Under the Curve (AUC) value was also high. Also when we saw the hit-ratio table, the ratio of RNNs that predicted a poor company to be bankrupt was higher than that of other comparative models. However the limitation of this paper is that an overfitting problem occurs during RNN learning. But we expect to be able to solve the overfitting problem by selecting more lear"
RNN과 LSTM을 이용한 주가 예측율 향상을 위한 딥러닝 모델,2017,"['technical analysis', 'fundamental analysis', 'artificial neural network', 'deep neural network', 'RNN', 'LSTM']",국문 초록 정보 없음,"Recently, stock price prediction using deep learning has basically used assistance index as a prediction factors. However assistance index is necessary to examine whether it is suitable as prediction factors because it is subjective viewpoint of researcher. In this study, we examine the suitability as prediction factors with various combinations of existing assistance indexes through the R neural network package, and studied the optimal combinations of assistance indexes and environmental prediction factors like exchange rate, exchange rate moving average, and whole industrial production index in order to improve the prediction rate. In addition, we proposed a deep learning model like DNN, RNN, LSTM which have input-output with extracted prediction factors. As a result, most of the assistance indexes decreased the prediction rate and the prediction rate was improved through additional environmental prediction factors. Also, RNN and LSTM, which are time series deep learning networks, were learned quickly and steadily compared to DNN. Although there is a difference by items, the prediction rate improvement is about 15%."
Word2vec을 활용한 RNN기반의 문서 분류에 관한 연구,2017,"['Text Mining', 'Information Retrieval', 'Deep Learning', 'DocumenCt lassification', '텍스트 마이닝', '정보검색', '딥 러닝', '문서분류']","자연어 처리 분야에서도 심층 신경망 기술이 주목되고 있으며, 최근에는 convolutional neural network (CNN)기반의 심층신경망 구조가 이미지 분류뿐만 아니라 자연어 처리의 문서 분류에서도 좋은 성능이 입증되었다. 하지만 convolutional neural network (CNN)을 이용한 문서 분류 연구에서는 문장의 평균 단어 수가 16개로 이루어진 짧은 문장에 한하여 적용되었으며, 구문 전체와 의미론적 관계가 복잡한 전체 문장을 다루기 어렵다는 단점을 가지고 있다. 본 논문은 기존 연구의 한계점을극복하고 더 정확한 문서 분류 성능을 위하여 word2vec를 활용한 recurrent neural network (RNN)기반의 심층 신경망의접근법을 새롭게 제안한다. 이를 위해 장기 의존성 문제를 해결한 long short-term memory (LSTM)을 사용하여 긴 시퀀스의입력에서도 효과적인 문서 분류가 가능하도록 하였고, 제안 방식의 효율성을 검증하기 위해 영문 데이터 뿐 아니라 한국어영화 리뷰 데이터에 대해서도 실험을 수행하였다. 그 결과 장문을 포함하고 있는 영문 신문 기사에서는 87%, 단문으로구성된 영문 영화 리뷰 문서에서는 90%, 한국어 영화 리뷰에서는 88%의 문서 분류 정확도를 보였다","Deep neural network based methods have obtained remarkable progress on natural language processing (NLP) task. Recently, convolutional neural network (CNN) based approaches often outperform not only in image classification, but also in document classification. However, convolutional neural network (CNN) based methods is applied only to a short sentence composed of 16 words in average, and it has a disadvantage that it is difficult to deal with a sentence having a complicated semantic relationship with the whole sentence. In this paper, we propose a new method based on recurrent neural network (RNN) using word2vec to overcome the limitations of previous related work and to get much higher accuracy of document classification. By using long short-term memory (LSTM) to solve the long-term dependency problem, effective document classification is also possible for long sequence input. To validate performance of our proposed method in various data, we tested our proposed method both with English sentence and Korean movie review dataset. As a result, 87% of the English newspaper articles containing the long texts, 90% of the English movie review and 88% of the Korean movie reviewsh owed the accuracy of document classification"
CTC를 이용한 LSTM RNN 기반 한국어 음성인식 시스템,2017,"['Connectionist temporal classification', 'Long short term memory', 'Recurrent neural network', 'Acoustic model', 'Speech recognition', '음향모델', '음성인식']",국문 초록 정보 없음,"A hybrid approach using Long Short Term Memory (LSTM) Recurrent Neural Network (RNN) has showed great improvement in speech recognition accuracy. For training acoustic model based on hybrid approach, it requires forced alignment of HMM state sequence from Gaussian Mixture Model (GMM)-Hidden Markov Model (HMM). However, high computation time for training GMM-HMM is required. This paper proposes an end-to-end approach for LSTM RNN-based Korean speech recognition to improve learning speed. A Connectionist Temporal Classification (CTC) algorithm is proposed to implement this approach. The proposed method showed almost equal performance in recognition rate, while the learning speed is 1.27 times faster."
CNN과 RNN의 기초 및 응용 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning : CNN과 RNN을 중심으로,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Novel Discriminative Feature Extraction for Acoustic Scene Classification Using RNN Based Source Separation,2017,[],국문 초록 정보 없음,"<P>Various types of classifiers and feature extraction methods for acoustic scene classification have been recently proposed in the IEEE Detection and Classification of Acoustic Scenes and Events (DCASE) 2016 Challenge Task 1. The results of the final evaluation, however, have shown that even top 10 ranked teams, showed extremely low accuracy performance in particular class pairs with similar sounds. Due to such sound classes being difficult to distinguish even by human ears, the conventional deep learning based feature extraction methods, as used by most DCASE participating teams, are considered facing performance limitations. To address the low performance problem in similar class pair cases, this letter proposes to employ a recurrent neural network (RNN) based source separation for each class prior to the classification step. Based on the fact that the system can effectively extract trained sound components using the RNN structure, the mid-layer of the RNN can be considered to capture discriminative information of the trained class. Therefore, this letter proposes to use this mid-layer information as novel discriminative features. The proposed feature shows an average classification rate improvement of 2.3% compared to the conventional method, which uses additional classifiers for the similar class pair issue.</P>"
Effective Spectral and Excitation Modeling Techniques for LSTM-RNN-Based Speech Synthesis Systems,2017,[],국문 초록 정보 없음,"<P>In this paper, we report research results on modeling the parameters of an improved time-frequency trajectory excitation (ITFTE) and spectral envelopes of an LPC vocoder with a long short-term memory (LSTM)-based recurrent neural network (RNN) for high-quality text-to-speech (TTS) systems. The ITFTE vocoder has been shown to significantly improve the perceptual quality of statistical parameter-based TTS systems in our prior works. However, a simple feed-forward deep neural network (DNN) with a finite window length is inadequate to capture the time evolution of the ITFTE parameters. We propose to use the LSTM to exploit the time-varying nature of both trajectories of the excitation and filter parameters, where the LSTM is implemented to use the linguistic text input and to predict both ITFTE and LPC parameters holistically. In the case of LPC parameters, we further enhance the generated spectrum by applying LP bandwidth expansion and line spectral frequency-sharpening filters. These filters are not only beneficial for reducing unstable synthesis filter conditions but also advantageous toward minimizing the muffling problem in the generated spectrum. Experimental results have shown that the proposed LSTM-RNN system with the ITFTE vocoder significantly outperforms both similarly configured band aperiodicity-based systems and our best prior DNN-trainecounterpart, both objectively and subjectively.</P>"
순환인공신경망(RNN)을 이용한 대도시 도심부 교통혼잡 예측,2017,"['순환 인공 신경망', '기계학습', '실시간 소통상황 예측', '반복정체', 'Recurrent Neural Network', 'machine learning', 'realtime traffic congestion estimation', 'recurrent congestion']",국문 초록 정보 없음,다국어 초록 정보 없음
RNN based Energy Demand Prediction for Smart-Home in Smart-Grid Framework,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
RNN(Recurrent Neural Network)을 이용한 기업부도예측모형에서 회계정보의 동적 변화 연구,2017,"['Recurrent Neural Network', '부도예측', '시계열모형']",국문 초록 정보 없음,다국어 초록 정보 없음
K-NNDD by DTW distance를 통한 데이터 클러스터링과 RNN LSTM을 활용한 공정 이상 패턴 분류 모델 제안,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Safe-Region Approach to a Moving <i>k</i> -RNN Queries in a Directed Road Network,2017,"['Safe region', 'directed road network', 'uncertain location', 'moving query', 'spatial network']",국문 초록 정보 없음,"<P>In road networks, <TEX>$ k$</TEX>-range nearest neighbor (<TEX>$ k$</TEX>-RNN) queries locate the <TEX>$ k$</TEX>-closest neighbors for every point on the road segments, within a given query region defined by the user, based on the network distance. This is an important task because the user's location information may be inaccurate; furthermore, users may be unwilling to reveal their exact location for privacy reasons. Therefore, under this type of specific situation, the server returns candidate objects for every point on the road segments and the client evaluates and chooses exact <TEX>$ k$</TEX> nearest objects from the candidate objects. Evaluating the query results at each timestamp to keep the freshness of the query answer, while the query object is moving, will create significant computation burden for the client. We therefore propose an efficient approach called a safe-region-based approach (SRA) for computing a safe segment region and the safe exit points of a moving nearest neighbor (NN) query in a road network. SRA avoids evaluation of candidate answers returned by the location-based server since it will have high computation cost in the query side. Additionally, we applied SRA for a directed road network, where each road network has a particular orientation and the network distances are not symmetric. Our experimental results demonstrate that SRA significantly outperforms a conventional solution in terms of both computational and communication costs.</P>"
LSTM-RNN 기반 음성합성을 위한 파라미터 생성 알고리즘,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
기계학습 기반 내부자위협 탐지기술,2017,"['Insider threat', 'Machine learning', 'Neural network', 'Anomaly detect', 'Information security']","최근 몇 년 동안 지속적으로 개인정보유출, 기술유출 사고가 빈번하게 발생하고 있다. 조사에 따르면 이러한 유출 사고의 주체로 가장 많은 부분을 차지하고 있는 것이 조직 내부에 있는 ‘내부자’로, 내부자에 의한 기술유출은 조직에 막대한 피해를 주기 때문에 점점 더 중요한 문제로 여겨지고 있다. 본 논문에서는 내부자위협을 방지하기 위해 기계학습을 이용하여 직원들의 일반적인 정상행위를 학습하고, 이에 벗어나는 비정상 행위를 탐지하기 방법에 대한 연구를 하고자한다. Neural Network 모델 중 시계열 데이터의 학습에 적합한 Recurrent Neural Network로 구성한 Autoencoder를 구현하여 비정상 행위를 탐지하는 방법에 대한 실험을 진행하였고, 이 방법에 대한 유효성을 검증하였다.","In recent years, personal information leakage and technology leakage accidents are frequently occurring. According to the survey, the most important part of this spill is the ""insider"" within the organization, and the leakage of technology by insiders is considered to be an increasingly important issue because it causes huge damage to the organization. In this paper, we try to learn the normal behavior of employees using machine learning to prevent insider threats, and to investigate how to detect abnormal behavior. Experiments on the detection of abnormal behavior by implementing an Autoencoder composed of Recurrent Neural Network suitable for learning time series data among the neural network models were conducted and the validity of this method was verified."
순환신경망과 WAVENET의 음성 인식 성능 비교,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
엔드 투 엔드 재귀인공신경망 학습을 통한 심전도 분류,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
음원 분리 기반 새로운 감정 특징 추출 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Study on Word Sense Disambiguation Using Bidirectional Recurrent Neural Network for Korean Language,2017,"['Word Sense Disambiguation', 'Neural Network Language Model', 'Context Vector', 'Bidirectional Recurrent Neural Network']",국문 초록 정보 없음,"Word sense disambiguation(WSD) that determines the exact meaning of homonym which can be used in different meanings even in one form is very important to understand the semantical meaning of text document. Many recent researches on WSD have widely used NNLM(Neural Network Language Model) in which neural network is used to represent a document into vectors and to analyze its semantics. Among the previous WSD researches using NNLM, RNN(Recurrent Neural Network) model has better performance than other models because RNN model can reflect the occurrence order of words in addition to the word appearance information in a document. However, since RNN model uses only the forward order of word occurrences in a document, it is not able to reflect natural language's characteristics that later words can affect the meanings of the preceding words. In this paper, we propose a WSD scheme using Bidirectional RNN that can reflect not only the forward order but also the backward order of word occurrences in a document. From the experiments, the accuracy of the proposed model is higher than that of previous method using RNN. Hence, it is confirmed that bidirectional order information of word occurrences is useful for WSD in Korean language."
Recurrent Neural Networks를 활용한 Baltic Dry Index (BDI) 예측,2017,"['장단기 메모리', '순환형 신경망', '건화물운임지수', '인공신경망', '시계열 분석', 'Long Short-Term Memory', 'Recurrent Neural Networks', 'BDI (Baltic Dry Index)', 'Artificial Neural Networks', 'Time-Series Analysis']",장기 해운불황에 따라 불확실성이 증폭되고 있는 상황에서 경기추세의 이해뿐만 아니라 예측 또한 중요해지고 있는 실정이다. 본 논문에서는 최근 특정 복잡한 문제에 대해서 각광받고 있는 인공신경망을 적용하여 BDI 예측을 연구하였다. 사용된 인공신경망은 순환신경망으로 RNN과 LSTM 그리고 비교의 목적으로 MLP를 통해 2009.04.01.부터 2017.07.31.의 기간을 대상으로 연구를 진행하였다. 또한 전통적 시계열 예측방법론인 ARIMA 분석을 실시해 인공신경망들의 예측성능과 비교하였다. 결과로 순환신경망인 RNN의 성능이 가장 뛰어났으며 LSTM의 특정 시계열(BDI)에의 적용가능성을 확인할 수 있었다.,"Not only growth of importance to understanding economic trends, but also the prediction to overcome the uncertainty is coming up for long-term maritime recession. This paper discussed about the prediction of BDI with artificial neural networks (ANN). ANN is one of emerging applications that can be the finest solution to the knotty problems that may not easy to achieve by humankind. Proposed a prediction by implementing neural networks that have recurrent architecture which are a Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). And for the reason of comparison, trained Multi Layer Perceptron (MLP) from 2009.04.01 to 2017.07.31. Also made a comparison with conventional statistics, prediction tools; ARIMA. As a result, recurrent net, especially RNN outperformed and also could discover the applicability of LSTM to specific time-series (BDI)."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",국문 초록 정보 없음,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM's. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",국문 초록 정보 없음,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",국문 초록 정보 없음,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long short-term memory recurrent neural network-based acoustic model using connectionist temporal classification on a large-scale training corpus,2017,[],국문 초록 정보 없음,"<P>A Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) has driven tremendous improvements on an acoustic model based on Gaussian Mixture Model (GMM). However, these models based on a hybrid method require a forced aligned Hidden Markov Model (HMM) state sequence obtained from the GMM-based acoustic model. Therefore, it requires a long computation time for training both the GMM-based acoustic model and a deep learning-based acoustic model. In order to solve this problem, an acoustic model using CTC algorithm is proposed. CTC algorithm does not require the GMM-based acoustic model because it does not use the forced aligned HMM state sequence. However, previous works on a LSTM RNN-based acoustic model using CTC used a small-scale training corpus. In this paper, the LSTM RNN-based acoustic model using CTC is trained on a large-scale training corpus and its performance is evaluated. The implemented acoustic model has a performance of 6.18% and 15.01% in terms of Word Error Rate (WER) for clean speech and noisy speech, respectively. This is similar to a performance of the acoustic model based on the hybrid method.</P>"
한국어를 위한 Recurrent Neural Network 기반 동형이의어 중의성 해소 연구,2017,[],"영어에 대한 동형이의어의 중의성 해소를 위해 NNLM(Neural Network Language Model)을 사용하는 연구가 이루어지고 있으며, 최근에는 순서정보를 반영하는 신경망 모델인 RNN(Recuurent Neural Network)을 사용한 연구가 진행되고 있다. 본 연구에서는 신경망에 대한 한국어의 특성을 반영해 RNN을 한국어에 대한 동형이의어의 중의성 해소에 적용할 것을 제안하였으며, 실험을 통해 한국어에서도 순서 정보를 반영하는 RNN 기반 동형이의어 중의성 해소 모델이 유효함을 확인하였다.",다국어 초록 정보 없음
Fabrication of ZnV₂O₄ Nanoparticles Embedded in Carbon Nanofibers as a Cathode Material for High-Performance Aqueous Zn-Ion Batteries,2022,"['Zn-Ion Battery', 'Cathode Material', 'Electrospinning']",국문 초록 정보 없음,다국어 초록 정보 없음
음소기반의 순환 신경망 음성 검출기를 이용한 음성 향상,2017,"['RNN', 'GMM', 'Phoneme', 'VAD', 'MMSE']",국문 초록 정보 없음,다국어 초록 정보 없음
LSTM 모델 기반 주행 모드 인식을 통한 자율 주행에 관한 연구,2017,"['자율주행', '주행모드', '딥러닝', 'RNN', 'LSTM', 'autonomous driving', 'maneuvering modes', 'deep learning', 'RNN', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
퍼지와 인공 신경망을 이용한 침입탐지시스템의 탐지 성능 비교 연구,2017,"['침입탐지', '퍼지', '신경망', 'RNN', 'KDD CUP 1999 dataset', 'Intrusion Detection', 'Fuzzy', 'Neural Network', 'RNN', 'KDD CUP 1999 dataset']",국문 초록 정보 없음,다국어 초록 정보 없음
심층학습을 이용한 기계번역 기술과 정확도 연구,2017,"['Deep Neural Network', 'Machine Translation', 'Google Translator', 'Recurrent Neural Network', 'Autoencoder']",국문 초록 정보 없음,"In this study, we discuss the basic technology of machine learning of the deep neural network for natural language processing(NLP). We explain the distributed vector representation of words. Distributed vector representation is proved to be able to carry semantic meanings and are useful in various NLP tasks. The recurrent neural network(RNN) is employed to get the vector representation of sentences. We discuss the RNN encoder-decoder model and some modifications of the RNN structure to improve the accuracy of the machine translations. To test and verify the accuracy of Google translator, we performed the translation among Korean, English, and Japanese, and examined the meaning change between the original and the translated sentence. In neural network translation, we showed some inaccuracies of the translation such as wrong relation between subject and object, or some omission or repetition of the original meaning. In order to increase the performance and accuracy of machine translation, it is necessary to acquire more data for training."
How can a recurrent neurodynamic predictive coding model cope with fluctuation in temporal patterns? Robotic experiments on imitative interaction,2017,"['Neuro-robotics', 'Predictive coding', 'Recurrent neural networks', 'Synchronized imitation', 'Time-warping', 'Error regression']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>The current paper examines how a recurrent neural network (RNN) model using a dynamic predictive coding scheme can cope with fluctuations in temporal patterns through generalization in learning. The conjecture driving this present inquiry is that a RNN model with multiple timescales (MTRNN) learns by extracting patterns of change from observed temporal patterns, developing an internal dynamic structure such that variance in initial internal states account for modulations in corresponding observed patterns. We trained a MTRNN with low-dimensional temporal patterns, and assessed performance on an imitation task employing these patterns. Analysis reveals that imitating fluctuated patterns consists in inferring optimal internal states by error regression. The model was then tested through humanoid robotic experiments requiring imitative interaction with human subjects. Results show that spontaneous and lively interaction can be achieved as the model successfully copes with fluctuations naturally occurring in human movement patterns.</P>"
Comparative analysis of two recurrent neural networks for predicting the Lorenz system,2017,"['Recurrent neural network', 'Echo state network', 'Lorenz attractor', 'Reservoir computing']",국문 초록 정보 없음,"In this paper, a brief comparison of two recurrent neural networks (RNN) is presented. We compare a single hidden layer network with lateral connection trained by backpropagation algorithm and the echo state network(ESN). Both networks have similar structures, yet different training algorithms. We focus on predicting the solution of Lorenz dynamical system. In the simulation, in order to make sure that both networks have equal number of trainable weights, the number of nodes was set different for each of two networks. As expected RNN with back-propagation outperforms ESN, however, the backpropagation algorithm is more computationally demanding and its convergence is not guaranteed, hence, ESN is appropriate choice as a first approximation in predicting dynamics systems."
AWS 사물 인터넷 환경에서 딥러닝을 이용한 시계열 센서 데이터의 실시간 예측 서비스 아키텍처,2017,"['아마존 웹서비스', '사물인터넷', '딥러닝', 'LSTM', '순환형 신경망', 'AWS', 'IoT', 'Deep Learning', 'LSTM', 'RNN']",국문 초록 정보 없음,"With the advent of Internet of Things (IoT), the use of various devices connected to Internet has generated a large amount of data, and the importance of big data analysis has rapidly been increasing. In particular, it is necessary to analyze various IoT data generated in real-time and to provide various services through new meaningful future prediction analysis. Therefore, this paper presents the direction of Amazon Web Service (AWS) for real-time prediction service in IoT environment. Also, in this paper, we propose an architecture in AWS IoT environment for analyzing sensor data such as power, temperature, humidity, wind speed, and so on, received from IoT devices using recurrent neural networks (RNN) suitable for time series data among various algorithms, and providing users with necessary services using prediction data. The proposed architecture extracts new information from the time series IoT data and can create new business value by applying real-time IoT service to sports, cultural contents, and so on as well as real-time prediction model."
Evaluation of Recurrent Neural Network Variants for Person Re-identification,2017,"['Person re-identification', 'Multi-shot', 'Recurrent neural network', 'Optimization']",국문 초록 정보 없음,"Instead of using only spatial features from a single frame for person re-identification, a combination of spatial and temporal factors boosts the performance of the system. A recurrent neural network (RNN) shows its effectiveness in generating highly discriminative sequence-level human representations. In this work, we implement RNN, three Long Short Term Memory (LSTM) network variants, and Gated Recurrent Unit (GRU) on Caffe deep learning framework, and we then conduct experiments to compare performance in terms of size and accuracy for person reidentification. We propose using GRU for the optimized choice as the experimental results show that the GRU achieves the highest accuracy despite having fewer parameters than the others."
자질 보강과 양방향 LSTM-CNN-CRF 기반의 한국어 개체명 인식 모델,2017,"['개체명 인식', '자연어 처리', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Natural Language Processing', 'Deep Learning', 'Feature Augmentation']","개체명 인식(Named Entity Recognition) 시스템은 문서에서 인명(PS), 지명(LC), 단체명(OG)과 같은 개체명을 가지는 단어나 어구를 해당 개체명으로 인식하는 시스템이다. 개체명 인식을 하기위한 전통적인 연구방법으로는 hand-craft된 자질(feature)을 기반으로 모델을 학습하는 통계 기반의 모델이 있다. 최근에는 딥러닝 기반의 RNN(Recurrent Neural Networks), LSTM(Long-short Term Memory)과 같은 모델을 이용하여 문장을 표현하는 자질을 구성하고 이를 개체명 인식과 같이 순서 라벨링(sequence labeling) 문제 해결에 이용한 연구가 제안되었다. 본 연구에서는 한국어 개체명 인식 시스템의 성능 향상을 위해, end-to-end learning 방식이 가능한 딥러닝 기반의 모델에 미리 구축되어 있는 hand-craft된 자질이나 품사 태깅 정보 및 기구축 사전(lexicon) 정보를 추가로 활용하여 자질을 보강(augmentation)하는 방법을 제안한다. 실험 결과 본 논문에서 제안하는 방법에 따라 자질을 보강한 한국어 개체명 인식 시스템의 성능 향상을 확인하였다. 또한 본 연구의 결과를 한국어 자연어처리(NLP) 및 개체명 인식 시스템을 연구하는 연구자들과의 향후 협업 연구를 위해 github를 통해 공개하였다.","The Named Entity Recognition system is a system that recognizes words or phrases with object names such as personal name (PS), place name (LC), and group name (OG) in the document as corresponding object names. Traditional approaches to named entity recognition include statistical-based models that learn models based on hand-crafted features. Recently, it has been proposed to construct the qualities expressing the sentence using models such as deep-learning based Recurrent Neural Networks (RNN) and long-short term memory (LSTM) to solve the problem of sequence labeling. In this research, to improve the performance of the Korean named entity recognition system, we used a hand-crafted feature, part-of-speech tagging information, and pre-built lexicon information to augment features for representing sentence. Experimental results show that the proposed method improves the performance of Korean named entity recognition system. The results of this study are presented through github for future collaborative research with researchers studying Korean Natural Language Processing (NLP) and named entity recognition system."
전통문화 이미지를 위한 세부 자질 주목형 이미지 자동 분석기,2017,"['Image Processing', 'Image Classifier', 'Deep Learning', 'Artificial Neural Networks', 'Natural Language Processing', 'Machine Learning', 'Artificial Intelligence', '이미지 처리', '이미지 분류기', '딥러닝', '인공신경망', '자연어처리', '기계학습', '인공지능']","이 논문에서는 최근 전통문화의 늘어나는 콘텐츠와 대조적으로 전통문화에 대한 접근성이 떨어지는 점에 주목하여 이러한 콘텐츠의 접근성의 향상을 위해 지속된 관리와 연구를 위하여 전통문화 이미지를 위한 이미지 자동 분석기를 소개한다. 이 논문에서 소개하는 이미지 자동 분석기는 인공신경망을 기반으로 입력 이미지의 자질들을 벡터스페이스로 변환하여 이를 RNN 기반의 모델을 통하여 세부 자질들을 파악하여 전통문화 이미지의 분류를 행한다. 이러한 방법을 통하여 전체적으로 비슷하게 보이는 전통문화 이미지들의 분류를 가능케 한다. 해당 모델의 훈련을 위하여 한민족정보문화마당 기반의 형식을 토대로 넓은 폭의 이미지 데이터를 수집 및 정리하여 차후 전통문화 이미지 관련 분야에서 사용할 수 있는 데이터셋의 구축에 기여를 하였다. 또한 이러한 연구가 최종적으로 전통문화와 관련된 수요, 공급 및 연구가 한층 더 활발해지는 것에 기여를 한다.","As accessibility toward traditional cultural contents drops compared to its increase in production, the need for higher accessibility for continued management and research to exist. For this, this paper introduces an image classifier model for traditional images based on artificial neural networks, which converts the input image's features into a vector space and by utilizing a RNN based model it recognizes and compares the details of the input which enables the classification of traditional images. This enables the classifiers to classify similarly looking traditional images more precisely by focusing on the details. For the training of this model, a wide range of images were arranged and collected based on the format of the Korean information culture field, which contributes to other researches related to the fields of using traditional cultural images. Also, this research contributes to the further activation of demand, supply, and researches related to traditional culture."
전자상거래 추천시스템을 위한 순환신경망 알고리즘들의 성능평가,2017,"['전자상거래', '추천시스템', '머신러닝', '순환신경망', '최적화 알고리즘', '텐서플로우', 'e-commerce', 'recommendation system', 'machine learning', 'recurrent neural network', 'optimization algorithm', 'TensorFlow']","전자상거래 발전에 따라 온라인 쇼핑을 이용하는 사람들이 증가하였고 제품 또한 다양해지고 있다. 이러한 추세로 구매자가 만족할 수 있는 정확한 추천시스템의 중요성이 증대되었으며 정확도를 높이기 위한 새로운 방법의 연구가 계속되고 있다. 순환신경망은 시퀀스 학습에 적합한 딥 러닝 방법 중 하나이며 본 연구에서는 추천시스템의 정확도를 높이는 방법으로 구매자의 제품 접근순서를 순환신경망에 적용하여 알고리즘 성능평가를 하였다. 알고리즘 성능평가에는 대표적인 순환신경망 알고리즘과 최적화 알고리즘으로 진행하였다. 순환신경망 알고리즘으로는 RNN, LSTM, GRU 그리고 최적화 알고리즘으로는 Adagrad, RMSProp, Adam optimizer를 사용하였다. 실험 도구로는 구글의 오픈소스 라이브러리인 텐서플로우를 사용하였고 데이터는 RecSys Challenge 2015에서 제공하는 e-commerce session 데이터를 활용하였다. 실험 결과 실험 데이터에 적합한 최적의 하이퍼파라미터를 발굴하고 적용하여 RecSys Challenge 2015 참가자들의 결과와 비교하였다. 상품 접근 순서만을 학습시킨 결과이기 때문에 등수가 높지는 않았지만 기존 추천시스템에 접목한다면 정확도 향상에 기여할 수 있을 것으로 보인다.","Due to the advance of e-commerce systems, the number of people using online shopping and products has significantly increased. Therefore, the need for an accurate recommendation system is becoming increasingly more important. Recurrent neural network is a deep-learning algorithm that utilizes sequential information in training. In this paper, an evaluation is performed on the application of recurrent neural networks to recommendation systems. We evaluated three recurrent algorithms (RNN, LSTM and GRU) and three optimal algorithms(Adagrad, RMSProp and Adam) which are commonly used. In the experiments, we used the TensorFlow open source library produced by Google and e-commerce session data from RecSys Challenge 2015. The results using the optimal hyper-parameters found in this study are compared with those of RecSys Challenge 2015 participants."
Recurrent Neural Network Models for Prediction of the inside Temperature and Humidity in Greenhouse,2017,"['Neural Networks', 'Greenhouse modeling', 'MIMO', 'Microclimate']",국문 초록 정보 없음,"Greenhouse have been developed to provide the plants with good environmental conditions for cultivation crop, two major factors of which are the inside air temperature and humidity. The inside temperature are influenced by the heating systems, ventilators and for systems among others, which in turn are geverned by some type of controller. Likewise, humidity environment is the result of complex mass exchanges between the inside air and the several elements of the greenhouse and the outside boundaries. Most of the existing models are based on the energy balance method and heat balance equation for modelling the heat and mass fluxes and generating dynamic elements. However, greenhouse are classified as complex system, and need to make a sophisticated modeling. Furthermore, there is a difficulty in using classical control methods for complex process system due to the process are non linear and multi-output(MIMO) systems. In order to predict the time evolution of conditions in certain greenhouse as a function, we present here to use of recurrent neural networks(RNN) which has been used to implement the direct dynamics of the inside temperature and inside humidity of greenhouse. For the training, we used algorithm of a backpropagation Through Time (BPTT). Because the environmental parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. The training data was emulated to 13 input variables during March 1 to 7, and the model was tested with database file of March 8. The RMSE of results of the temperature modeling was 0.976℃, and the RMSE of humidity simulation was 4.11%, which will be given to prove the performance of RNN in prediction of the greenhouse environment."
Generative adversarial nets를 이용한 빈센트 반 고흐 이미지 생성 시스템,2017,"['Generative Adversarial Nets', 'CNN', 'DCGANs']",국문 초록 정보 없음,"CNN and RNN are classifiers for image and speech recognition, and are used in many computer vision. However, this model alone does not produce images or voices. So we used GAN (Generative Adversarial Nets), which is a non-biped learning, to create and restore objects. To determine the distribution of the assumed model data, we use the generative model G and the Discriminator model D to judge the probability of each case in order to distinguish whether the sample came from the training data from the actual or model G Respectively. This is called minimax two -player game. The model G makes a mistake maximize in order to make a mistake, and the model D makes a mistake minimize in order not to make a mistake. Model D uses technology such as recognition technology, which is a conventional prayer learning method. Through this technique, the damaged or modified objects are compared with the training sample to classify and confirm what kind of object is the first type. There is no need for another network to generate the sample through training and it will be evaluated and confirmed through experiments."
End-to-end Korean Document Summarization using Copy Mechanism and Input-feeding,2017,"['문서요약', '인공신경망', '기계학습', '딥러닝', 'RNN', 'Deep Learning', 'GRU', 'Document Summarization']",국문 초록 정보 없음,다국어 초록 정보 없음
Water Level Forecasting based on Deep Learning : A Use Case of Trinity River-Texas-The United States,2017,"['침수 예측', '딥러닝', 'RNN', 'BPTT', 'LSTM', 'water level forecasting', 'deep learning', 'recurrent neural networks', 'back propagationthrough time', 'long short-term memory']",국문 초록 정보 없음,다국어 초록 정보 없음
장단기 메모리 순환신경망 기반의 비침입적 음성 명료도 추정 방법,2017,"['Deep neural network (DNN)', 'Recurrent neural network (RNN)', 'Long short-term memory (LSTM)', 'Non-Intrusive', 'Speech intelligibility estimation', 'STOI', 'P.563']",국문 초록 정보 없음,다국어 초록 정보 없음
로고우스키형 부분방전 센서를 이용한 ANN 기반 파티클 재질 판별,2023,"['Artificial neural network', 'Defect identification', 'Partial discharge', 'Particle materials', 'Rogowski-type PD sensor', '적재 위반 차량 검출', '딥러닝', '객체 인식', '빅데이터']","최근 증가하고 있는 도로 위 적재 불량 화물차는 비정상적인 무게 중심으로 인해 물체 낙하, 도로 파손, 연쇄 추돌 등 교통안전에 위해가 되고 한번 사고가 발생하면 큰 피해가 유발할 수 있다. 하지만 이러한 비정상적인 무게 중심은 적재 불량 차량 인식을 위한 주행 중 축중 시스템으로는 검출이 불가능하다는 한계점이 있다. 본 논문에서는 이러한 사회 문제를 야기하는 적재 불량 차량을 관리하기 위한 객체 인식 기반 AI 모델을 구축하고자 한다. 또한 AI-Hub에 공개된 약 40만 장의 데이터셋을 비교 분석하여 전처리를 통해 적재 불량 차량 검지 AI 모델의 성능을 향상시키는 방법을 제시한다. 또한 객체 추적을 통해 실시간 검지를 수행하는 방법을 제안한다. 이를 통해, 원시 데이터를 활용한 학습 성능 대비 약 23% 향상된 적재 불량 차량의 검출 성능을 나타냄을 보였다. 본 연구 결과를 통해 공개 빅데이터를 보다 효율적으로 활용하여, 객체 인식 기반 적재 불량 차량 탐지 모델 개발에 적용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
LSTM 기반 Model-Free LKAS 조향 각 생성,2017,"['Long Short-Term Memory (LSTM)', 'Recurrent Neural Network (RNN)', 'steering angle prediction', 'Lane Kepping Assistance System (LKAS)']",국문 초록 정보 없음,"In this paper, we propose a lateral upper controller that predicts vehicle motion and generates a model-free LKAS steering angle by applying long-term memory (LSTM), one of the deep learning techniques. The apparent and distinct advantage of this LSTM model is that the relationship of nonlinear sensor data can be grasped and learned devoid of a mathematical model while using the time information. In this sense, the LKAS steering angle can be generated by predicting the movement of the vehicle in consideration of the past vehicle motion based on the sensor data. In addition, the time delay problem due to the difference of sampling time on each sensor can be simply solved by learning based on a time table which has a synchronized sampling time. The input values of the upper controller are the coefficient of the road model and the vehicle dynamic characteristics are obtained from the image processing data from the camera sensor. As for the target values, the steering angles in the next state are selected. The learning model was developed by learning the many-to-one LSTM prediction model with serial connection of LSTM and Fully-Connected (FC) Multilayer Perceptron (MLP). For implementation of the learning model, Tensorflow is employed and the data from a real test road was used. With this model, the learning is conducted and its effectiveness is shown by comparing with a LKAS lateral controller using a model-based multi rate Kalman Filter (MKF)."
온도와 코너 변화에 영향이 작은 차동 구조의 포락선 검출기를 활용한 60-GHz 비동기 광대역 수신기,2023,"['Envelope detector', 'Low-noise amplifier', 'Millimeter-wave', 'PAM4', 'RF receiver', '인공지능', '정보보안', '오버샘플링', 'VAE']","최근 인공지능 기술이 발전하면서 해킹 공격을 탐지하기 위해 인공지능을 이용하려는 연구가 활발히 진행되고 있다. 하지만, 인공지능 모델 개발에 핵심인 학습데이터를 구성하는데 있어서 보안데이터가 대표적인 불균형 데이터라는 점이 큰 장애물로 인식되고 있다. 이에 본 눈문에서는 오버샘플링을 위한 데이터 추출에 딥러닝 생성 모델인 VAE를 적용하고 K-NN을 이용한 가중치 계산을 통해 클래스별 오버샘플링 개수를 설정하여 샘플링을 하는 W-VAE 오버샘플링 기법을 제안한다. 본 논문에서는 공개 네트워크 보안 데이터셋인 NSL-KDD를 통해 ROS, SMOTE, ADASYN 등 총 5가지 오버샘플링 기법을 적용하였으며 본 논문에서 제안한 오버샘플링 기법이 F1-Score 평가지표를 통해 기존 오버샘플링 기법과 비교하여 가장 효과적인 샘플링 기법임을 증명하였다.",다국어 초록 정보 없음
[A 9.4] Combinatorial optimization with recurrent neural networks,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM-CRF Models for Named Entity Recognition,2017,[],국문 초록 정보 없음,"<P>Recurrent neural networks (RNNs) are a powerful model for sequential data. RNNs that use long short-term memory (LSTM) cells have proven effective in handwriting recognition, language modeling, speech recognition, and language comprehension tasks. In this study, we propose LSTM conditional random fields (LSTM-CRF); it is an LSTM-based RNN model that uses output-label dependencies with transition features and a CRF-like sequence-level objective function. We also propose variations to the LSTM-CRF model using a gate recurrent unit (GRU) and structurally constrained recurrent network (SCRN). Empirical results reveal that our proposed models attain state-of-the-art performance for named entity recognition.</P>"
Large-Scale Text Classification with Deep Neural Networks,2017,"['deep learning', 'large-scale text classification', 'natural language processing', 'artificial neural networks', '딥러닝', '대용량 문서 분류', '자연어 처리', '인공신경망']",국문 초록 정보 없음,"The classification problem in the field of Natural Language Processing has been studied for a long time. Continuing forward with our previous research, which classifies large-scale text using Convolutional Neural Networks (CNN), we implemented Recurrent Neural Networks (RNN), Long- Short Term Memory (LSTM) and Gated Recurrent Units (GRU). The experiment’s result revealed that the performance of classification algorithms was Multinomial Naïve Bayesian Classifier < Support Vector Machine (SVM) < LSTM < CNN < GRU, in order. The result can be interpreted as follows: First, the result of CNN was better than LSTM. Therefore, the text classification problem might be related more to feature extraction problem than to natural language understanding problems. Second, judging from the results the GRU showed better performance in feature extraction than LSTM. Finally, the result that the GRU was better than CNN implies that text classification algorithms should consider feature extraction and sequential information. We presented the results of fine-tuning in deep neural networks to provide some intuition regard natural language processing to future researchers."
한국어 음소 단위 LSTM 언어모델을 이용한 문장 생성,2017,"['언어 모델', '순환 신경망 모형', 'LSTM 모형', '문장 생성 모형', 'Language model', 'Recurrent neural network', 'Long short-term memory model', 'Sentence generation model']",국문 초록 정보 없음,"Language models were originally developed for speech recognition and language processing. Using a set of example sentences, a language model predicts the next word or character based on sequential input data. N-gram models have been widely used but this model cannot model the correlation between the input units efficiently since it is a probabilistic model which are based on the frequency of each unit in the training set. Recently, as the deep learning algorithm has been developed, a recurrent neural network (RNN) model and a long short-term memory (LSTM) model have been widely used for the neural language model (Ahn, 2016; Kim et al., 2016; Lee et al., 2016). These models can reflect dependency between the objects that are entered sequentially into the model (Gers and Schmidhuber, 2001; Mikolov et al., 2010; Sundermeyer et al., 2012). In order to learning the neural language model, texts need to be decomposed into words or morphemes. Since, however, a training set of sentences includes a huge number of words or morphemes in general, the size of dictionary is very large and so it increases model complexity. In addition, word-level or morpheme-level models are able to generate vocabularies only which are contained in the training set. Furthermore, with highly morphological languages such as Turkish, Hungarian, Russian, Finnish or Korean, morpheme analyzers have more chance to cause errors in decomposition process (Lankinen et al., 2016).  Therefore, this paper proposes a phoneme-level language model for Korean language based on LSTM models. A phoneme such as a vowel or a consonant is the smallest unit that comprises Korean texts. We construct the language model using three or four LSTM layers. Each model was trained using Stochastic Gradient Algorithm and more advanced optimization algorithms such as Adagrad, RMSprop, Adadelta, Adam, Adamax, and Nadam. Simulation study was done with Old Testament texts using a deep learning package Keras based the Theano. After pre-processing the texts, the dataset included 74 of unique characters including vowels, consonants, and punctuation marks. Then we constructed an input vector with 20 consecutive characters and an output with a following 21st character. Finally, total 1,023,411 sets of input-output vectors were included in the dataset and we divided them into training, validation, testsets with proportion 70:15:15. All the simulation were conducted on a system equipped with an Intel Xeon CPU (16 cores) and a NVIDIA GeForce GTX 1080 GPU.  We compared the loss function evaluated for the validation set, the perplexity evaluated for the test set, and the time to be taken for training each model. As a result, all the optimization algorithms but the stochastic gradient algorithm showed similar validation loss and perplexity, which are clearly superior to those of the stochastic gradient algorithm. The stochastic gradient algorithm took the longest time to be trained for both 3- and 4-LSTM models. On average, the 4-LSTM layer model took 69% longer training time than the 3-LSTM layer model. However, the validation loss and perplexity were not improved significantly or became even worse for specific conditions. On the other hand, when comparing the automatically generated sentences, the 4-LSTM layer model tended to generate the sentences which are closer to the natural language than the 3-LSTM model. Although there were slight differences in the completeness of the generated sentences between the models, the sentence generation performance was quite satisfactory in any simulation conditions: they generated only legitimate Korean letters and the use of postposition and the conjugation of verbs were almost perfect in the sense of grammar. The results of this study are expected to be widely used for the processing of Korean language in the field of language processing and speech recognition, which are the basis of artificial intelligence systems."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",다국어 초록 정보 없음
Continuous Timescale Long-Short Term Memory Neural Network for Human Intent Understanding,2017,"['continuous timescale', 'recurrent neural network', 'LSTM', 'classification', 'dynamic sequence']",국문 초록 정보 없음,"<P>Understanding of human intention by observing a series of human actions has been a challenging task. In order to do so, we need to analyze longer sequences of human actions related with intentions and extract the context from the dynamic features. The multiple timescales recurrent neural network (MTRNN) model, which is believed to be a kind of solution, is a useful tool for recording and regenerating a continuous signal for dynamic tasks. However, the conventional MTRNN suffers from the vanishing gradient problem which renders it impossible to be used for longer sequence understanding. To address this problem, we propose a new model named Continuous Timescale Long-Short Term Memory (CTLSTM) in which we inherit the multiple timescales concept into the Long-Short Term Memory (LSTM) recurrent neural network (RNN) that addresses the vanishing gradient problem. We design an additional recurrent connection in the LSTM cell outputs to produce a time-delay in order to capture the slow context. Our experiments show that the proposed model exhibits better context modeling ability and captures the dynamic features on multiple large dataset classification tasks. The results illustrate that the multiple timescales concept enhances the ability of our model to handle longer sequences related with human intentions and hence proving to be more suitable for complex tasks, such as intention recognition.</P>"
Deep Recurrent Neural Network for Multiple Time Slot Frequency Spectrum Predictions of Cognitive Radio,2017,"['cognitive radio', 'spectrum sensing', 'recurrent neural network', 'time series']",국문 초록 정보 없음,"The main processes of a cognitive radio system include spectrum sensing, spectrum decision, spectrum sharing, and spectrum conversion. Experimental results show that these stages introduce a time delay that affects the spectrum sensing accuracy, reducing its efficiency. To reduce the time delay, the frequency spectrum prediction was proposed to alleviate the burden on the spectrum sensing. In this paper, the deep recurrent neural network (DRNN) was proposed to predict the spectrum of multiple time slots, since the existing methods only predict the spectrum of one time slot. The continuous state of a channel is divided into a many time slots, forming a time series of the channel state. Since there are more hidden layers in the DRNN than in the RNN, the DRNN has fading memory in its bottom layer as well as in the past input. In addition, the extended Kalman filter was used to train the DRNN, which overcomes the problem of slow convergence and the vanishing gradient of the gradient descent method. The spectrum prediction based on the DRNN was verified with a WiFi signal, and the error of the prediction was analyzed. The simulation results proved that the multiple slot spectrum prediction improved the spectrum efficiency and reduced the energy consumption of spectrum sensing."
순환신경망을 이용한 한글 필기체 인식,2017,"['순환신경망', '한글필기체 인식', '딥러닝 응용', '한글 구성 원리를 고려한 인식', '온라인 필기체 인식', 'recurrent neural networks', 'Hangul handwriting recognition', 'deep learning application', 'online handwriting recognition']","온라인 방식의 한글 필기체 인식 문제를 분석하고 순환신경망 기반의 해법을 모색한다. 한글 낱글자 인식 문제를 순서데이터 레이블링의 관점에서 서열 분류, 구간 분류, 시간별 분류의 세 단계로 구분하여 각각에 대한 해법을 살펴보며, 한글의 구성 원리를 고려한 해결 방안을 정리한다. 한글 2350글자에 대한 온라인 필기체 데이터에 GRU(gated recurrent unit)의 다층 구조를 가지는 서열 분류모델을 적용한 결과, 낱글자 인식 정확도는 86.2%, 초･중･종성 구성에 따른 6가지 유형 분류 정확도는 98.2%로 측정되었다. 유형 분류 모델로 획의 진행에 따른 유형 변화 역시 높은 정확도로 인식하는 결과를 통해, 순환신경망을 이용하여 순서 데이터에서 한글의 구조와 같은 고차원적 지식을 학습할 수 있음을 확인하였다.","We analyze the online Hangul handwriting recognition problem (HHR) and present solutions based on recurrent neural networks. The solutions are organized according to the three kinds of sequence labeling problem - sequence classifications, segment classification, and temporal classification, with additional consideration of the structural constitution of Hangul characters. We present a stacked gated recurrent unit (GRU) based model as the natural HHR solution in the sequence classification level. The proposed model shows 86.2% accuracy for recognizing 2350 Hangul characters and 98.2% accuracy for recognizing the six types of Hangul characters. We show that the type recognizing model successfully follows the type change as strokes are sequentially written. These results show the potential for RNN models to learn high-level structural information from sequential data."
딥러닝 프레임워크의 비교,2017,"['딥러닝 프레임워크', '자동미분', '티아노', '텐서플로', 'Cognitive toolkit', 'CNN', 'deep learning framework', 'Theano', 'TensorFlow', 'CNTK', 'computational graph', 'CIFAR-10']",국문 초록 정보 없음,"The deep learning framework is software designed to help develop deep learning models. Some of its important functions include “automatic differentiation” and “utilization of GPU”. The list of popular deep learning framework includes Caffe (BVLC) and Theano (University of Montreal). And recently, Microsofts deep learning framework, Microsoft Cognitive Toolkit, was released as open-source license, following Google’s Tensorflow a year earlier. The early deep learning frameworks have been developed mainly for research at universities. Beginning with the inception of Tensorflow, however, it seems that companies such as Microsoft and Facebook have started to join the competition of framework development. Given the trend, Google and other companies are expected to continue investing in the deep learning framework to bring forward the initiative in the artificial intelligence business. From this point of view, we think it is a good time to compare some of deep learning frameworks. So we compare three deep learning frameworks which can be used as a Python library. Those are Googles Tensorflow, Microsoft’s CNTK, and Theano which is sort of a predecessor of the preceding two.  The most common and important function of deep learning frameworks is the ability to perform automatic differentiation. Basically all the mathematical expressions of deep learning models can be represented as computational graphs, which consist of nodes and edges. Partial derivatives on each edge of a computational graph can then be obtained. With the partial derivatives, we can let software compute differentiation of any node with respect to any variable by utilizing chain rule of Calculus.  First of all, the convenience of coding is in the order of CNTK, Tensorflow, and Theano. The criterion is simply based on the lengths of the codes and the learning curve and the ease of coding are not the main concern. According to the criteria, Theano was the most difficult to implement with, and CNTK and Tensorflow were somewhat easier. With Tensorflow, we need to define weight variables and biases explicitly. The reason that CNTK and Tensorflow are easier to implement with is that those frameworks provide us with more abstraction than Theano. We, however, need to mention that low-level coding is not always bad. It gives us flexibility of coding. With the low-level coding such as in Theano, we can implement and test any new deep learning models or any new search methods that we can think of.  The assessment of the execution speed of each framework is that there is not meaningful difference. According to the experiment, execution speeds of Theano and Tensorflow are very similar, although the experiment was limited to a CNN model. In the case of CNTK, the experimental environment was not maintained as the same. The code written in CNTK has to be run in PC environment without GPU where codes execute as much as 50 times slower than with GPU. But we concluded that the difference of execution speed was within the range of variation caused by the different hardware setup.  In this study, we compared three types of deep learning framework: Theano, Tensorflow, and CNTK. According to Wikipedia, there are 12 available deep learning frameworks. And 15 different attributes differentiate each framework. Some of the important attributes would include interface language (Python, C ++, Java, etc.) and the availability of libraries on various deep learning models such as CNN, RNN, DBN, and etc. And if a user implements a large scale deep learning model, it will also be important to support multiple GPU or multiple servers. Also, if you are learning the deep learning model, it would also be important if there are enough examples and references."
빅데이터를 이용한 딥러닝 기반의 기업 부도예측 연구,2017,[],"Ⅰ. 연구배경 및 목적▣ 부도예측 모형은 금융 산업에서 항상 중요한 과제로 인식되어 지속적으로 발전하여 왔으나 여전히 중요한 연구 과제로 인식되고 있음.· 부도예측 모형은 그간의 많은 연구로 정확도가 많이 향상되었으나. 거시경제 여건, 기업 경영환경 등이 급속하게 변화하여 부도 기업에 대한 정확한 예측은 여전히 어려운 과제임.▣ 과거의 많은 연구는 기업에 대한 재무 정보와 시장 정보를 기반으로 부도예측을 수행· 재무 정보는 가장 객관적이고 세부적인 기업에 대한 정보임. 하지만 데이터 생성 주기가 상대적으로 길어(연도, 분기) 부도 예측의 적시성이 떨어지는 근원적인 한계가 있음.· 시장 정보는 유가증권 시장 참여자에 의하여 기업에 대한 정보가 가장 빠르게 반영된다는 장점이 있음. 하지만 유가증권시장 상장 기업만 활용이 가능하고, 주가에 영향을 주는 다른 요인에 대하여 영향을 통제하지 못하는 단점이 있음.▣ IT 기술 및 데이터 분석 기법, 인공지능 기법의 발달로 인하여 새로운 데이터 원천인 뉴스 정보를 부도 예측 과정에 활용할 수 있음.· 빅데이터 연구 분야에 활용되는 텍스트마이닝과 인공지능기법을 활용하여 텍스트 정보를 측정 가능한 변수로 계량화하는 방법 적용· 뉴스 정보는 기업에 대한 가장 빠른 정보 원천 중 하나로 기업 부실의 징후를 사전적으로 알 수 있는 정보로서 충분한 가치가 있음.▣ 본 연구는 기존의 연구를 기반으로 부도 예측 과정에서 1) 뉴스텍스트와 같은 새로운 정보 원천이 적용에 따라 부도 예측력을 높일 수 있는지, 2) 인공지능(딥러닝) 기법과 같은 새로운 방법론이 기존의 방법론에 비하여 예측 성능이 향상되는지 두가지 측면을 중점적으로 연구Ⅱ. 빅데이터 및 인공지능의 금융 관련 분야 활용 현황▣ 빅데이터 및 인공지능 분야는 활용 가능한 데이터의 확대와 IT 기술 혁신을 기반으로 발전· 1) 분석가능한 데이터 양의 급격한 증가, 2) 복잡하고 방대한 데이터 분석을 위한 방법론의 발전, 3) 컴퓨터 과학의 진화· 빅데이터는 데이터의 크기(Volume)가 크고, 분석 과정에서 실시간에 준하는 빠른 속도(Velocity) 및 데이터의 원천이 매우 다양(Variety)한 특성을 가지고 있음· 빅데이터는 정보 원천에 따라 개인정보, 비즈니스 정보, 센서에 의한 정보로 구분▣ 금융 산업 또한 빅데이터가 여러 경로를 통하여 수집 및 관리되고 있음.· 금융 산업의 주요 데이터 원천은 증권거래소 등의 자본 시장과 금융 감독 기관과 같은 공공기관의 공시 데이터임.· 금융 관련 데이터는 대부분 시간의 흐름에 따라 입력되어 관리되는 시계열(Time-Series) 데이터의 형태가 많음. 최근에는 데이터 수집 주기를 매우 짧은 기간으로 설정하여 시계열데이터 발생 빈도를 크게 늘린 고빈도(high-frequency) 데이터도 많이 활용됨.· 금융 데이터 수집 과정에서 금융 위기 기간은 반드시 별도로 고려되어야 함. 금융 위기 기간의 데이터가 정상적 기간의 데이터와 구분되지 않는 경우 경우 완전히 다른 분석 결과를 얻을 수 있음.· 기존의 활용되지 못하던 신규 생성 데이터의 확보로 데이터 확장도 가능하지만, 이미 존재하고 있는 이종 데이터 간의 결합을 통해서도 데이터가 확대되는 효과를 얻을 수도 있음.· 수집된 데이터는 분석 방법에 따라 필요한 정제 작업을 거쳐 데이터 분석 과정에 활용됨.▣ 인공지능은 새로운 개념은 아니지만, 최근 매우 큰 관심을 받고 있고 매우 급속하게 발전하는 분야임.· 인공지능은 인간이 지정한 방법에 따라 학습하여 의사결정을 수행하는 ‘지도학습’과 컴퓨터가 스스로 경험한 내용에 대하여 학습을 할 수 있도록 설계하는 ‘비지도 학습’으로 구분· 인공신경망 이론을 기반으로 복잡한 비선형 문제를 ‘비지도 학습’ 방식으로 해결하는 방법을 ‘딥러닝’으로 기존의 ‘머신러닝’ 분야와 구별하고 있음. 하지만 이러한 구분은 절대적인 기준은 아님.· 인공지능 관련 시장 규모는 연평균 44%의 성장 중에 있으며, 2020년에는 전 세계적으로 약 240조원의 시장 규모를 형성할 것으로 예측(일본 EY 연구소)· 국내 또한 인공지능 시장은 2020년에 2.2조원, 2030년 27.5조원 시장으로 급격한 성장이 예상되고 있음(KT 경영연구소).▣ 빅데이터는 복잡하고 방대한 양의 데이터를 기반으로 발전된 기법이므로 소매 금융 데이터 분석에 활용 효과가 높음.· 소매 금융은 개인 및 소규모 기업 고객을 대상으로 하는 금융 서비스로서, 기업 고객에 비하여 상대적으로 데이터의 양이 많으며 다양한 속성이 복잡하게 나타나는 특성이 있음.· 기존의 고객이 제공하던 데이터의 수집을 넘어서, 고객에 대한 정보를 직/간접적으로 확보하는 방향으로 정보 원천을 확대함.· 소매 금융 부문 중 본 연구와 관련된 ‘신용 평가’ 부분은 가장 빅데이터가 활발하게 활용되는 분야 중 하나임.▣ 인공지능 알고리즘은 신용 평가모형의 예측 성능을 개선하기 위한 목적으로 활용도가 증가하고 있음.· 미국의 ‘제스트 파이낸스’ 는 1만개 이상의 대용량 변수를 신용 평가모형에 활용· 독일의 ‘크레디테크’, 홍콩의 ‘렌도’, 일본의 ‘소프트뱅크’, ‘미즈호뱅크’ 등도 비슷한 수준· 미국 ‘FICO’는 인공지능의 도입으로 신용 평가모형에 비선형변수의 반영, 다양한 변수 결합에 의한 고객 특성 반영 등으로 10~25%의 모형 개선 효과가 있다고 보고· 미국 및 글로벌 핀테크 업체를 중심으로 신용 평가 및 금융기관 운영 과정에서 인공지능을 다양하게 활용하고 있음.· 국내의 경우 여러 기관이 현재의 신용평가 모형을 인공지능을 활용하여 개선하고 있으나 아직은 선도적인 결과를 보고하는 기관을 찾기 어려움.▣ 빅데이터 및 인공지능 도입은 비용 증가, 예측결과 해석의 어려움, 평가 모형의 신뢰성 부족 및 관련 규제 미비 등의 한계요인도 가지고 있음.· 데이터의 확보, 처리, 분석 등에 시간, 인원, 컴퓨터 하드웨어 등의 추가 비용 요인 발생· 전통적인 통계 분석 기법과 달리 예측 결과에 대한 원인 분석이 쉽지 않음.· 과거 모형에 비하여 구축 및 적용된 기간이 길지 않아, 아직은 신뢰성에 대한 의문 존재· 관련 산업에 대한 규제가 많아 관련 산업 발전의 장애 요인으로 작용 중Ⅲ. 부도 예측 연구 방법론1. 선행연구▣ Altman(1968)의 다변량 판별분석과 Ohlson(1980)의 로짓 모형으로 대표되는 전통적인 기업부도예측 연구는 다양한 방법론을 적용하여 예측 성과를 높이는 방향으로 발전하여 왔음.· McQuown(1993)은 자본시장의 시장 가격을 바탕으로 옵션가격 평가모형을 적용하여 기업의 부도 위험 수준인 EDF(Expected default frequency)를 측정하는 모형(KMV 모형)을 제시· 오세경(2001)은 국내 기업을 대상으로 로짓(Logit) 모형을 이용한 다변량 판별분석과 함께 옵션가격 평가모형을 이용하여 EDF의 시간별 변화 추이를 분석▣ 각각 부도예측 과정에 활용되던 재무 정보와 시장 정보는 두 원천을 통합하여 부도예측력을 높일 수 있는 방법에 대한 연구로 발전· Shumway(2001)가 회계 정보와 시장 정보를 헤저드 모형으로 통합하여 부도예측력을 높일 수 있는 방법을 처음 제안· Campbell et al(2008) 또한 회계모형과 시장 정보를 결합한 헤저드 모형이 기존의 각각의 모형보다 부도예측력이 우수하다는 것을 실증· 이인로·김동철(2015), 최정원·오세경(2016)은 국내 기업을 대상으로 재무정보와 시장정보를 통합하면 기존의 모형보다 예측력이 우수한 것을 실증· Nam et al(2008)은 시간 가변적인(Time-varying) 헤저드 모형을 사용하여 재무정보와 시장정보 및 거시경제 정보가 기업의 부도 예측 가능성을 높일 수 있음을 실증▣ 빅데이터를 활용한 예측 모형 연구는 최근 관련 분야의 대내외적인 관심 증가로 인하여 폭발적으로 증가하고 있음.· 배상진·박철균(2003), 김근형·오성렬(2009) 등은 텍스트 마이닝 및 텍스트 데이터 전처리 과정 등을 세부적인 절차로 제시· 김유신·김남규·정승렬(2012), Martinez et al(2012)은 텍스트 정보를 이용한 분석 과정에서 텍스트가 담고 있는 감성(Opinion)을 분석하고 이를 연구 과정에 활용함.· 이광석(2014), 최정원·한호선·이미영·안준모(2015), 조남옥·신경식(2016)은 텍스트 정보를 활용한 기업 부도예측모형의 유용성을 실증함.· Chen et al(2014), 김민수·구평회(2013), 안성원·조성배(2010)는 뉴스 텍스트마이닝 기법을 주가예측 모형에 활용▣ 인공지능(딥러닝) 기법은 비교적 최신의 방법론으로서 금융 및 재무 분야에서는 전통적인 방법론에 의한 예측 방법론에 비하여 연구의 양과 질 모두 부족하지만 최근 기술의 발전 및 전 세계적인 관심 증가와 함께 관련 연구가 매우 급격하게 증가하고 있음.· 이재식·한재홍(1995)은 기존의 재무정보만 활용한 부도예측의 한계가 있음을 지적하고 이를 보완하기 위하여 비재무정보를 활용한 인공신경망 기반의 부도예측 모형을 제시· Kim and So(2010)는 SVM 기법으로 부도예측을 수행하고, 정보가 상대적으로 부족한 중소기업의 경우 기존의 방법론보다 인공지능 기법의 예측 성능이 더욱 우수함을 실증· 김성진·안현철(2016)은 금융기관의 신용위험관리의 중요한 도구인 기업신용등급 예측 과정에 인공지능 기법 중 랜덤 포레스트(Random Forests) 방법을 적용· Yeh et al.(2015)은 딥러닝 개념의 인공신경망 기법 중 하나인 Deep Belief Networks (DBN)이 기존의 머신러닝 중 대표적 기법인 SVM보다 기업 부도예측 성능이 더 우수함을 실증· Addal(2016)은 인공신경망, K 근접 군집분석 등의 방법론을 이용하여 기업부도예측 모형이 우수한 예측력을 보이는 것을 실증2. 연구방법론▣ 선행연구를 참고하여 확보 가능한 다양한 정보 원천을 모두 포괄하여 예측 모형에 활용· 재무 정보의 경우 기업에 대한 가장 기본적이고 객관적인 실적 지표로서 기업 부도예측에 반드시 활용되는 정보· 시장 정보는 분석 시점의 기업에 대한 최신 정보를 반영하고 있다는 특성이 있으므로 재무 정보의 적시성 부족 문제를 보완하나 유가증권 시장에 상장되어 주식이 거래되고 있는 기업들만의 정보를 이용한다는 한계· 재무 정보와 시장 정보는 두 정보를 결합하여 모형에 반영이 가능함. Nam et al.(2008)의 연구는 Hazard 모형을 활용하여 재무정보와 시장정보를 결합한 부도 예측 모형 제시· 거시경제 지표의 경우 과거 일부 부도 예측 연구에서 설명변수로 활용은 되고 있으나, 그 빈도가 재무지표나 시장지표에 비하여 많이 떨어짐.· 여러 선행연구에서 적용하는 비정형 정보는 그간에 연구들이 주로 사용하지 못하였던 뉴스 및 인터넷 등의 텍스트 정보를 원천으로 활용하는 경우가 많음.▣ 본 연구 분석 과정에서 활용한 예측 방법론의 종류와 각 방법론의 특징▣ 텍스트 데이터를 예측 모형 등에 활용하기 위해서는 계량화된 변수로 측정하는 과정이 필요· ‘Word2vec’은 단어들 간의 연관된 규칙을 찾아서 각 단어의 관계를 계량적으로 산출하는 방법론으로서, 각 단어 간의 앞뒤 관계를 보고 근접도를 벡터의 형태로 계산하는 알고리즘 · ‘Word2vec’을 활용하여 뉴스 기사 내에 언급된 단어 간의 관계를 계량적으로 분석할 수 있음.· 본 연구에서는 부도와 연관된 기사에서 나타나는 ‘부도’의 의미를 가지는 다른 단어들을 객관적으로 판단(‘부도 연관어휘’)하는 근거를 마련하여 위하여 ‘Word2vec’ 활용· 산출된 ‘부도 관련 기사 비율’과 ‘부도 유사도’ 지표는 수준이 높게 나타날 경우 이를 사전적인 ‘부도’의 징후로 판단할 수 있음.▣ 여러 가지 방법론을 적용하여 기업 부도예측을 수행할 경우 모형의 성능을 비교하기 위해서는 동일한 개념으로 적용이 가능한 객관적인 모형 평가 방법 필요· 본 연구의 기업 부도예측과 같은 이진 분류 예측의 상황은 두 범주(부도, 정상)간의 정확한 분류가 가능한지를 여러 모형 간에 비교하여 봄으로써 모형 평가를 수행· 기업예측 모형과 같은 이진 판별 예측은 할 때, 예측 모형의 추정 값들은 0에서 1 사이에서 판별 값(Threshold)이 변함에 따라 정확도가 변동함. 따라서 최적의 판별 값 수준 결정필요▣ 예측 모형을 도출하여 모형의 예측력을 평가하는 과정에서 Sample data를 학습 세트(training set)와 평가 세트(test set)으로 나누어 예측 정확도(Accuracy)를 산출하고 이를 근거로 모형의 성능을 평가하여야 함(out of sample test).· 본 연구도 학습 세트와 평가 세트를 전체 표본 중 중복되지 않도록 70% 대 30%의 비중으로 배분하여 모형 추정과 예측력 평가 과정에 각각 사용· 과거 부도예측 연구에서는 부도 기업의 표본(sample) 수가 너무 적어 표본의 불균형에 의한 모형 예측력 평가의 어려움이 있음을 한계로 지적하였음.· 본 연구는 부도 기업의 표본을 고정하고, 정상 기업의 표본을 부도 기업 수만큼만 Random 형태로 Sampling하여 균형(equal-weighted. 50% 대50%) 표본을 구성하여 모형의 추정과 평가에 활용하는 방안을 적용.· 다만 이러한 Sampling 방식을 사용할 경우 정상 기업 표본에서 표본 선택에 따른 편의(bias)가 발생할 수 있으므로, 평가 과정의 강건성을 얻기 위하여 정상 기업 표본을 반복적으로 총 100 세트(set)를 임의 확률(random)로 구성하여 모형평가 과정에 활용· 각 방법론의 예측 수준 평가를 위한 정확도 값은 모든 평가세트(100 set)에서 산출된 정확도의 평균 수준으로 산출Ⅳ. 실증분석1. 부도 사건의 정의▣ 기업 부도예측 연구 과정에서 보다 유용한 결과를 얻기 위해서는 기업의 부도(부실)에 대한 명확한 정의를 하는 것이 매우 중요▣ 유가증권시장에서 ‘상장폐지’가 결정된 기업들 중 부도에 관련된 공시가 발생한 기업들을 부도 발생기업으로 인식하고 분석을 진행· 이인로·김동철(2015), 최정원·오세경(2016) 등의 선행연구와 동일한 가정· 상장폐지 사건은 부도와 반드시 연결된다고 볼 수는 없으나, 부도와 관련된 이유로 상장폐지가 발생한 대부분의 기업은 특수한 상황을 제외하고 부도가 발생하거나 부도에 준하는 재무상황이 발생함.2. 데이터 수집 및 정제▣ 2001년부터 2015년 까지 부도 정의에 따라 유가증권 시장에 상장된 기업을 대상으로 분석▣ 비정형 정보인 뉴스 텍스트 데이터 수집을 위하여, 네이버 뉴스 검색 홈페이지를 활용하여, 분석 대상 기업들에 대한 2010년 1월부터 2016년 12월까지의 84기간의 뉴스 컨텐츠를 수집· 인터넷 뉴스 서버에 DB가 구축되지 않아 기사를 확보할 수 없거나, 총 집계기간 동안 기사 수가 부족한 기업, 검색이 불가능한 이름의 기업, 명확한 구별이 어려운 기업 등의 기사는 수집 과정에서 제외· 제외 후 텍스트 정보 수집 대상 기업은 총 1,788개의 기업으로 총 2,506,080건의 기사를 텍스트 DB로 확보함. 기업당 평균적으로 약 1,401건, 1개월 당 평균적으로 약 16.6건· 텍스트 DB는 집계 이후 자연어 처리, 분석 Sample 수 미달제외, 특정 의미 단어 제외 등의 정제 과정을 거쳐 최종 텍스트 분석 DB로 산출됨.▣ 텍스트 분석 DB를 기반으로 ‘부도’ 및 ‘상장폐지’와 기사 내에 언급된 단어 간의 유사도를 ‘Word2vec’을 이용하여 산출· ‘부도’ 혹은 ‘부도’ 및 ‘상장폐지’로 ‘Word2vec’ 유사도 기준상위 20개 단어 선별· 선정된 부도 유사 단어가 포함된 경우 해당 기사를 부도 연관 기사로 간주하고, 전체 기사 대비 부도 연관 기사 비율을 산출하여 ‘부도 기사 비율’을 산출함.· 기사를 구성하고 있는 개별 단어별로 ‘부도’ 및 ‘상장폐지’ 유사도를 부여하고, 각 기사별 ‘부도 유사도(평균수준)’을 산출함.· ‘부도 기사 비율’ 과 ‘부도 유사도’ 는 부도 기사에 대한 계량화된 텍스트 분석 결과로서 향후 부도 예측 모형 추정 과정에서 설명 변수로 활용▣ 정보 원천별로 모형 예측의 영향을 평가하기 위하여 취합된 분석 DB를 4가지의 데이터 세트로 분류하여 각각의 모형에 적용하고 가용한 데이터 수준에 따라 기간을 나누어 분석함.· 총 7개의 분석 Set가 구성되어 각각의 예측 방법론에 적용됨1) Set A(2001~2016년) : 재무, 시장, 거시경제 정보. 총 2291개 (부도 502개) 기업 대상2) Set B(2010~2016년) : 재무, 시장, 거시경제 정보. 총 1586개 (부도 258개) 기업 대상3. 연간 예측 모형▣ 각 분석 DB Set를 예측 방법론별 모형에 적합(Fitting) 하고 최적 모형을 도출함.▣ SET A 결과(분석기간 2001년~2016년 적용)· 가장 높은 정확도를 나타낸 방법론은 Random Forests 방법론 · 로지스틱 모형과 SVM 또한 0.9에 상회하는 높은 정확도가 산출· 의사결정나무(Dtree)와 인공신경망(DNN, RNN) 등은 0.9에 다소 못 미치는 정확도· 기업의 재무정보, 거시 경제정보, 시장정보를 포괄하여 가장 정보가 많이 활용된 < SET3 >의 정확도는 타 데이터 세트에 비하여 다소 높게 산출. 하지만 유의미한 수준은 아님.▣ SET B 결과(분석기간 2010년~2016년 적용)· Random Forests 방법론이 가장 우수한 예측력. SVM, 인공신경망(DNN) 순· 로지스틱 모형은 상대적으로 모형 예측력이 하락. 인공지능 기법들의 예측력은 유지되거나 오히려 다소 상승· 기존 전통적 정보 원천이 반영된 < SET B_3 >에 뉴스 텍스트 정보까지 추가로 반영된 < SET B_4 >가 타 모형에 비하여 모형 예측력이 높게 산출. 비정형 정보도 부도예측 성능 향상에 영향을 줄 수 있음을 실증하는 결과임. 유의성은 떨어짐.▣ 연관 예측 모형 추정 결과 인공지능 중 Random Forests 방법론이 두 데이터 SET 모두 가장 높은 수준의 예측력 나타남.· 데이터 수가 상대적으로 적은 < SET B >에서도 우수한 예측력을 유지함으로써 인공지능 기법이 강건하게 기업의 부도에 대한 예측을 잘 수행할 수 있음을 실증· 인공지능_DNN의 예측 성능이 기대 수준에 미치지 못함. 컴퓨터 하드웨어를 보강하고 추가적인 효율화 방안을 도입하여 이러한 구조를 개선하면 현재보다 더 높은 예측 정확도를 얻을 가능성이 있음.▣ 텍스트 데이터를 추가로 반영한 < SET B_4 >의 예측 정확도는 방법론에 따라 약간의 차이는 있지만 전반적으로 텍스트 데이터를 반영하지 않은 SET에 비하여 유의한 수준의 정확도 차이가 나타나지 않음.· 재무정보만 활용한 < SET A_1 >, < SET B_1 >의 예측력도 타SET에 비하여 큰 차이가 없음.· 이는 상장 기업의 경우 다양한 공시 요구 및 규제에 의하여 기업의 정보가 재무정보에 이미 충분히 반영되어 나타나는 결과라 판단됨.4. 월간 예측 모형▣ 미디어의 뉴스 기사는 시장 정보(주가)와 마찬가지로 실시간으로 공개되는 정보임. 따라서 시장정보를 활용한 예측 모형인 KMV 모형과 유사한 형태의 부도예측 모형 구축 가능· 기업의 부도 관련 뉴스가 실제 부도가 발생하는 시점 이전에 부도 가능성을 선제적으로 알려줄 수 있는지, 조기 경보 지표(early warning index)로서 활용 가치가 있는지 연구· 분석 가능 대상 Sample : 부도 기업 52개, 정상기업 855개 확보· KMV모형 및 텍스트 기반 모형의 부도예측 단위는 월간이며, 부도 기준 직전 12개월의 추이를 분석함.· 부도 기업의 경우 부도 발생 1년전부터 점진적으로 평균 수준에 비하여 다소 낮은 수준으로 D.D. 가 하락하다가, 부도발생 3개월 전부터 급격하게 하락함.▣ 텍스트 정보기반 예측 모형 산출 결과(부도 기사 비율 추이)· 동일한 기간과 동일한 기업에 대하여 기사 텍스트 DB를 기반으로 산출한 부도 기사 비율· KMV 모형과 마찬가지로 부도기사 비율은 부도 발생 12개월 이전부터 점진적으로 상승하여 지속적으로 정상기업에 비하여 높은 수준으로 산출▣ 텍스트 정보기반 예측 모형 산출 결과(부도 유사도 추이)· 동일한 기간과 동일한 기업에 대하여 기사 텍스트 DB를 기반으로 산출한 부도 유사도· 부도 유사도 역시 부도기사비율과 마찬가지로 부도발생 이전부터 정상기업과 차이가 나타남.· 단, KMV 와 부도기사비율과는 달리 점진적 상승 추세가 다소 약하고, 부도 시점에 가까워지면서 오히려 정상기업보다 떨어지는 수준도 나타나는 것을 확인할 수 있음.▣ KMV 모형과 텍스트 정보기반의 예측 모형은 각각 부도 발생 이전 시점부터 부도 가능성이 상승함을 보여주는 것을 확인할 수 있음.· 선제적 예측 성능을 비교하기 위하여 두 모형을 함께 그래프로 도식화· 부도 기사 비율은 KMV 모형의 결과인 D.D. 와 비슷한 형태로 부도 가능성에 대한 신호가 나타남.· 특히 부도 발생 6개월 이전 시점부터는 지속적으로 KMV모형보다 다소 높은 수준으로 부도 기사 비율이 나타남.▣ ‘부도 기사비율’과 ‘부도 유사도’를 활용할 경우 KMV 모형과 유사한 형태로 부도 예측이 가능하며 추가적인 확장도 가능함.· 부도 발생 시점을 기준으로 KMV 모형 보다 이전 기간에 부도 유사도가 상승하여 기업 부도에 대한 조기경보 지표로서 충분히 활용 가능성이 있음.· 텍스트 정보 기반의 부도예측은 주가 정보가 없는 비상장기업에도 활용이 가능하다는 점에서 KMV 의 단점을 보완하는 방법론으로 더욱 의미가 있음.▣ 텍스트 기반의 부도 예측 방법 또한 기업관련 뉴스의 편중 문제가 나타나는 단점이 있음.· 대부분의 기업 뉴스는 일부 매우 우량하고 유명한 대기업에 대한 기사가 많이 생성되고, 정작 부도가 많이 발생하는 규모가 작은 기업에 대한 뉴스는 상대적으로 매우 적음.· 향후 이를 보완하기 위해서는 텍스트 데이터 확보 정보 원천을 미디어 뉴스뿐만 아니라 기업 공시자료, 증권/투자 관련게시판, 해당기업 홈페이지 등으로 확대하여 보다 광범위한 텍스트 데이터의 확보가 필요함.Ⅴ. 결론 및 시사점▣ 기업 부도 예측 과정에서 우선 비정형 데이터인 뉴스 텍스트 데이터를 계량화하여 새로운 정보 원천으로 활용할 수 있는 방법을 제시▣ 기존 정보 원천과 함께 텍스트 정보를 포함한 인공지능 기반의 예측 방법론을 제시하고 기존의 방법론과 예측력을 비교분석▣ 연구 결과, 연간 모형에서는 인공지능 기법인 Random forests 기법이 가장 우수한 예측력이 나타나는 것으로 분석· 인공지능을 이용한 다른 방법론들도 전반적으로 기존의 전통적인 예측 방법보다 예측력이 우수함.▣ 또한 뉴스 텍스트를 추가적인 정보 원천으로 추정한 월간 예측 모형의 경우 시장 정보 기반의 예측 모형인 KMV 모형과 유사한 결론을 도출할 수 있는 것으로 나타남.· 기업 부도 예측 과정에서 텍스트 정보 기반의 부도 예측 모형은 조기 경보 모형으로 충분히 활용이 가능함.▣ 중소기업(SME)과 개인에 대한 부도 예측 모형으로 연구의 확장이 필요· 현재 분석 대상인 상장기업의 경우 재무 정보가 기업 현황을 비교적 잘 반영하고 있고, 기업에 대하여 발생하는 정보 또한 주가에 즉각 반영되고 있는 편이기 때문에 텍스트 정보 및 인공지능 도입에 대한 예측 증가 수준이 미미할 수 있음.· 재무정보의 신뢰도가 떨어지고 시장 정보의 확보가 어려운 중소기업이나 개인에 대하여 본 연구의 부도 예측 방법을 적용한다면 기존의 방법에 대하여 추가적인 예측 수준 증대를 얻을 수 있을 것으로 기대됨.· 기업을 대상으로 하는 연구의 경우, 뉴스 텍스트 정보와 함께 웹 페이지, 공시자료 등 추가적인 정보 원천을 포괄하여 적용하면 추가적인 예측 수준 개선이 기대됨.▣ 빅데이터 및 딥-러닝 분야는 아직까지 국내 금융, 재무 분야에서 관련 연구가 부족함.· 본 연구에서 활용한 방법론은 타 연구에서도 충분히 응용하여 활용이 가능하므로 향후 관련 된 연구가 많이 발전할 것이라 기대할 수 있음.",다국어 초록 정보 없음
Nonintrusive Load Monitoring Based on Advanced Deep Learning and Novel Signature,2017,[],국문 초록 정보 없음,"<P>Monitoring electricity consumption in the home is an important way to help reduce energy usage. Nonintrusive Load Monitoring (NILM) is existing technique which helps us monitor electricity consumption effectively and costly. NILM is a promising approach to obtain estimates of the electrical power consumption of individual appliances from aggregate measurements of voltage and/or current in the distribution system. Among the previous studies, Hidden Markov Model (HMM) based models have been studied very much. However, increasing appliances, multistate of appliances, and similar power consumption of appliances are three big issues in NILM recently. In this paper, we address these problems through providing our contributions as follows. First, we proposed state-of-the-art energy disaggregation based on Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) model and additional advanced deep learning. Second, we proposed a novel signature to improve classification performance of the proposed model in multistate appliance case. We applied the proposed model on two datasets such as UK-DALE and REDD. Via our experimental results, we have confirmed that our model outperforms the advanced model. Thus, we show that our combination between advanced deep learning and novel signature can be a robust solution to overcome NILM's issues and improve the performance of load identification.</P>"
