title,date,keywords,abstract,multilingual_abstract
반복 구매제품의 재구매시기 예측을 위한 다층퍼셉트론(MLP) 모형과 순환신경망(RNN) 모형의 성능비교,2017,"['Purchase Timing', 'Recommender', 'Neural Network', 'Recurrent Neural Network', 'Franchise Business', 'Repurchase Product']",,"Existing studies for recommender have focused on recommending an appropriate item based on the customer preference. However, it has not yet been studied actively to recommend purchase timing for the repurchase product despite of its importance. This study aims to propose MLP and RNN models based on the only simple purchase history data to predict the timing of customer repurchase and compare performances in the perspective of prediction accuracy and quality. As an experiment result, RNN model showed outstanding performance compared to MLP model. The proposed model can be used to develop CRM system which can offer SMS or app based promotion to the customer at the right time. This model also can be used to increase sales for repurchase product business by balancing the level of order as well as inducing repurchase of customer."
확장된 RNN을 활용한 사람재인식 시스템에 관한 연구,2017,"['CNN', 'RNN', 'Unsupervised Learning', 'Person-Reidentification']","사람의 빈번한 자세 변화, 그리고 background clutter과 occlusion으로 인해 Person Re-identificatio는 컴퓨 터 비전 분야에서 가장 어려운 부분이다. 비겹침 카메라의 이미지는 어떤 사람을 다른 사람과 구별하기 어렵게 한다. 더욱 나은 성능 일치를 달성하기 위해 대부분의 방법은 특징 선택과 거리 메트릭을 개별적으로 사용한다. 그렇게 차별 화된 표현과 적절한 거리를 얻을 수 있고, 사람과 중요한 특징의 무시 사이의 유사성을 설명할 수 있다. 이러한 상황은 우리가 이 문제를 다루는 새로운 방법을 고려하도록 한다. 본 논문에서는 Person Re-identification를 위한 3단 계층 네트워크를 갖는 향상되고 반복적인 신경 회로망을 제안하였다. 특히 RNN(Revurrent Neural Network) 모델은 반복 적인 EM(Expectation Maximum) 알고리즘과 3단 계층 네트워크를 포함하고, 차별적 특징과 지표 거리를 공동으로 학습한다. 반복적인 EM 알고리즘은 RNN 이전에 연속해 있는 CNN(Convoutional Neural Network)의 특징 추출 능 력을 충분히 사용할 수 있다. 자율 학습을 통해 EM 프레임 워크는 패치의 레이블을 변경하고 더 큰 데이터 세트를 훈 련할 수 있다. 네트워크를 더 잘 훈련시키기 위해 3단 계층 네트워크를 통해 CNN, RNN 및 풀링 계층이 공동으로 특 징 추출을 할 수 있다. 실험 결과에 따르면 비전처리 분야에서 다른 연구자의 접근 방식과 비교할 때 이 방법은 경쟁 력 있는 정확도를 얻을 수 있다. 이 방법에 대한 다른 요소의 영향은 향후 연구에서 분석되고 평가될 것이다.","The person Re-identification is the most challenging part of computer vision due to the significant changes in human pose and background clutter with occlusions. The picture from non-overlapping cameras  enhance the difficulty to distinguish some person from the other. To reach a better performance match, most methods use feature selection and distance metrics separately to get discriminative representations and proper distance to  describe the similarity between person and kind of ignoring some significant features. This situation has encouraged us to consider a novel method to deal with this problem. In this paper, we proposed an enhanced recurrent neural network with three-tier hierarchical network for person re-identification. Specifically, the proposed recurrent neural network (RNN) model contain an iterative expectation maximum (EM) algorithm and three-tier Hierarchical network to jointly learn both the discriminative features and metrics distance. The iterative EM algorithm can fully use of the feature extraction ability of convolutional neural network (CNN) which is in series before the RNN. By unsupervised learning, the EM framework can change the labels of the patches and train larger datasets. Through the three-tier hierarchical network, the convolutional neural network, recurrent network and pooling layer can jointly be a feature extractor to better train the network. The experimental result shows that comparing with other researchers’ approaches in this field, this method also can get a competitive accuracy. The influence of different component of this method will be analyzed and evaluated in the future research."
EVS 코덱에서 보청기를 위한 RNN 기반의 음성/음악 분류 성능 향상,2017,"['Speech/Music Classification', 'Recurrent Neural Network (RNN)', 'Enhanced Voice Services (EVS)', 'Hearing Aids']","본 논문에서는 recurrent neural network (RNN)을 이용하여 보청기 시스템을 위한 기존의 3GPP enhanced voice services (EVS) 코덱의 음성/음악 분류 성능을 향상시키는 방법을 제시한다. 구체적으로, EVS의 음성/음악 분류 알고리즘에서 사용된 특징벡터만을 사용하여 효과적으로 RNN을 구성한 분류기법을 제시한다. 다양한 음악장르 및 잡음 환경에 대해 시스템의 성능을 평가한 결과 RNN을 이용하였을 때 기존의 EVS의 방법보다 우수한 음성/음악 분류 성능을 보였다.","In this paper, a novel approach is proposed to improve the performance of speech/music classification using the recurrent neural network (RNN) in the enhanced voice services (EVS) of 3GPP for hearing aids. Feature vectors applied to the RNN are selected from the relevant parameters of the EVS for efficient speech/music classification. The performance of the proposed algorithm is evaluated under various conditions and large speech/music data. The proposed algorithm yields better results compared with the conventional scheme implemented in the EVS."
RNN(Recurrent Neural Network)을 이용한 기업부도예측모형에서 회계정보의 동적 변화 연구,2017,"['순환 신경망', '부도 예측', '시계열 모형', 'Recurrent Neural Network', 'Bankruptcy Prediction', 'Time-Series model']",,"Corporate bankruptcy can cause great losses not only to stakeholders but also to many related sectors in society. Through the economic crises, bankruptcy have increased and bankruptcy prediction models have become more and more important. Therefore, corporate bankruptcy has been regarded as one of the major topics of research in business management. Also, many studies in the industry are in progress and important.  Previous studies attempted to utilize various methodologies to improve the bankruptcy prediction accuracy and to resolve the overfitting problem, such as Multivariate Discriminant Analysis (MDA), Generalized Linear Model (GLM). These methods are based on statistics. Recently, researchers have used machine learning methodologies such as Support Vector Machine (SVM), Artificial Neural Network (ANN). Furthermore, fuzzy theory and genetic algorithms were used. Because of this change, many of bankruptcy models are developed. Also, performance has been improved.  In general, the company’s financial and accounting information will change over time. Likewise, the market situation also changes, so there are many difficulties in predicting bankruptcy only with information at a certain point in time. However, even though traditional research has problems that don’t take into account the time effect, dynamic model has not been studied much. When we ignore the time effect, we get the biased results. So the static model may not be suitable for predicting bankruptcy. Thus, using the dynamic model, there is a possibility that bankruptcy prediction model is improved.  In this paper, we propose RNN (Recurrent Neural Network) which is one of the deep learning methodologies. The RNN learns time series data and the performance is known to be good. Prior to experiment, we selected non-financial firms listed on the KOSPI, KOSDAQ and KONEX markets from 2010 to 2016 for the estimation of the bankruptcy prediction model and the comparison of forecasting performance. In order to prevent a mistake of predicting bankruptcy by using the financial information already reflected in the deterioration of the financial condition of the company, the financial information was collected with a lag of two years, and the default period was defined from January to December of the year. Then we defined the bankruptcy. The bankruptcy we defined is the abolition of the listing due to sluggish earnings. We confirmed abolition of the list at KIND that is corporate stock information website. Then we selected variables at previous papers. The first set of variables are Z-score variables. These variables have become traditional variables in predicting bankruptcy. The second set of variables are dynamic variable set. Finally we selected 240 normal companies and 226 bankrupt companies at the first variable set. Likewise, we selected 229 normal companies and 226 bankrupt companies at the second variable set.  We created a model that reflects dynamic changes in time-series financial data and by comparing the suggested model with the analysis of existing bankruptcy predictive models, we found that the suggested model could help to improve the accuracy of bankruptcy predictions. We used financial data in KIS Value (Financial database) and selected Multivariate Discriminant Analysis (MDA), Generalized Linear Model called logistic regression (GLM), Support Vector Machine (SVM), Artificial Neural Network (ANN) model as benchmark.   The result of the experiment proved that RNN’s performance was better than comparative model. The accuracy of RNN was high in both sets of variables and the Area Under the Curve (AUC) value was also high. Also when we saw the hit-ratio table, the ratio of RNNs that predicted a poor company to be bankrupt was higher than that of other comparative models. However the limitation of this paper is that an overfitting problem occurs during RNN learning. But we expect to be able to solve the overfitting problem by selecting more lear"
RNN과 LSTM을 이용한 주가 예측율 향상을 위한 딥러닝 모델,2017,"['technical analysis', 'fundamental analysis', 'artificial neural network', 'deep neural network', 'RNN', 'LSTM']",,"Recently, stock price prediction using deep learning has basically used assistance index as a prediction factors. However assistance index is necessary to examine whether it is suitable as prediction factors because it is subjective viewpoint of researcher. In this study, we examine the suitability as prediction factors with various combinations of existing assistance indexes through the R neural network package, and studied the optimal combinations of assistance indexes and environmental prediction factors like exchange rate, exchange rate moving average, and whole industrial production index in order to improve the prediction rate. In addition, we proposed a deep learning model like DNN, RNN, LSTM which have input-output with extracted prediction factors. As a result, most of the assistance indexes decreased the prediction rate and the prediction rate was improved through additional environmental prediction factors. Also, RNN and LSTM, which are time series deep learning networks, were learned quickly and steadily compared to DNN. Although there is a difference by items, the prediction rate improvement is about 15%."
Word2vec을 활용한 RNN기반의 문서 분류에 관한 연구,2017,"['Text Mining', 'Information Retrieval', 'Deep Learning', 'DocumenCt lassification', '텍스트 마이닝', '정보검색', '딥 러닝', '문서분류']","자연어 처리 분야에서도 심층 신경망 기술이 주목되고 있으며, 최근에는 convolutional neural network (CNN)기반의 심층신경망 구조가 이미지 분류뿐만 아니라 자연어 처리의 문서 분류에서도 좋은 성능이 입증되었다. 하지만 convolutional neural network (CNN)을 이용한 문서 분류 연구에서는 문장의 평균 단어 수가 16개로 이루어진 짧은 문장에 한하여 적용되었으며, 구문 전체와 의미론적 관계가 복잡한 전체 문장을 다루기 어렵다는 단점을 가지고 있다. 본 논문은 기존 연구의 한계점을극복하고 더 정확한 문서 분류 성능을 위하여 word2vec를 활용한 recurrent neural network (RNN)기반의 심층 신경망의접근법을 새롭게 제안한다. 이를 위해 장기 의존성 문제를 해결한 long short-term memory (LSTM)을 사용하여 긴 시퀀스의입력에서도 효과적인 문서 분류가 가능하도록 하였고, 제안 방식의 효율성을 검증하기 위해 영문 데이터 뿐 아니라 한국어영화 리뷰 데이터에 대해서도 실험을 수행하였다. 그 결과 장문을 포함하고 있는 영문 신문 기사에서는 87%, 단문으로구성된 영문 영화 리뷰 문서에서는 90%, 한국어 영화 리뷰에서는 88%의 문서 분류 정확도를 보였다","Deep neural network based methods have obtained remarkable progress on natural language processing (NLP) task. Recently, convolutional neural network (CNN) based approaches often outperform not only in image classification, but also in document classification. However, convolutional neural network (CNN) based methods is applied only to a short sentence composed of 16 words in average, and it has a disadvantage that it is difficult to deal with a sentence having a complicated semantic relationship with the whole sentence. In this paper, we propose a new method based on recurrent neural network (RNN) using word2vec to overcome the limitations of previous related work and to get much higher accuracy of document classification. By using long short-term memory (LSTM) to solve the long-term dependency problem, effective document classification is also possible for long sequence input. To validate performance of our proposed method in various data, we tested our proposed method both with English sentence and Korean movie review dataset. As a result, 87% of the English newspaper articles containing the long texts, 90% of the English movie review and 88% of the Korean movie reviewsh owed the accuracy of document classification"
CTC를 이용한 LSTM RNN 기반 한국어 음성인식 시스템,2017,"['Connectionist temporal classification', 'Long short term memory', 'Recurrent neural network', 'Acoustic model', 'Speech recognition', '음향모델', '음성인식']",,"A hybrid approach using Long Short Term Memory (LSTM) Recurrent Neural Network (RNN) has showed great improvement in speech recognition accuracy. For training acoustic model based on hybrid approach, it requires forced alignment of HMM state sequence from Gaussian Mixture Model (GMM)-Hidden Markov Model (HMM). However, high computation time for training GMM-HMM is required. This paper proposes an end-to-end approach for LSTM RNN-based Korean speech recognition to improve learning speed. A Connectionist Temporal Classification (CTC) algorithm is proposed to implement this approach. The proposed method showed almost equal performance in recognition rate, while the learning speed is 1.27 times faster."
순환인공신경망(RNN)을 이용한 대도시 도심부 교통혼잡 예측,2017,"['순환 인공 신경망', '기계학습', '실시간 소통상황 예측', '반복정체', 'Recurrent Neural Network', 'machine learning', 'realtime traffic congestion estimation', 'recurrent congestion']",,
기계학습 기반 내부자위협 탐지기술,2017,"['Insider threat', 'Machine learning', 'Neural network', 'Anomaly detect', 'Information security']","최근 몇 년 동안 지속적으로 개인정보유출, 기술유출 사고가 빈번하게 발생하고 있다. 조사에 따르면 이러한 유출 사고의 주체로 가장 많은 부분을 차지하고 있는 것이 조직 내부에 있는 ‘내부자’로, 내부자에 의한 기술유출은 조직에 막대한 피해를 주기 때문에 점점 더 중요한 문제로 여겨지고 있다. 본 논문에서는 내부자위협을 방지하기 위해 기계학습을 이용하여 직원들의 일반적인 정상행위를 학습하고, 이에 벗어나는 비정상 행위를 탐지하기 방법에 대한 연구를 하고자한다. Neural Network 모델 중 시계열 데이터의 학습에 적합한 Recurrent Neural Network로 구성한 Autoencoder를 구현하여 비정상 행위를 탐지하는 방법에 대한 실험을 진행하였고, 이 방법에 대한 유효성을 검증하였다.","In recent years, personal information leakage and technology leakage accidents are frequently occurring. According to the survey, the most important part of this spill is the ""insider"" within the organization, and the leakage of technology by insiders is considered to be an increasingly important issue because it causes huge damage to the organization. In this paper, we try to learn the normal behavior of employees using machine learning to prevent insider threats, and to investigate how to detect abnormal behavior. Experiments on the detection of abnormal behavior by implementing an Autoencoder composed of Recurrent Neural Network suitable for learning time series data among the neural network models were conducted and the validity of this method was verified."
A Study on Word Sense Disambiguation Using Bidirectional Recurrent Neural Network for Korean Language,2017,"['Word Sense Disambiguation', 'Neural Network Language Model', 'Context Vector', 'Bidirectional Recurrent Neural Network']",,"Word sense disambiguation(WSD) that determines the exact meaning of homonym which can be used in different meanings even in one form is very important to understand the semantical meaning of text document. Many recent researches on WSD have widely used NNLM(Neural Network Language Model) in which neural network is used to represent a document into vectors and to analyze its semantics. Among the previous WSD researches using NNLM, RNN(Recurrent Neural Network) model has better performance than other models because RNN model can reflect the occurrence order of words in addition to the word appearance information in a document. However, since RNN model uses only the forward order of word occurrences in a document, it is not able to reflect natural language's characteristics that later words can affect the meanings of the preceding words. In this paper, we propose a WSD scheme using Bidirectional RNN that can reflect not only the forward order but also the backward order of word occurrences in a document. From the experiments, the accuracy of the proposed model is higher than that of previous method using RNN. Hence, it is confirmed that bidirectional order information of word occurrences is useful for WSD in Korean language."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM's. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
음소기반의 순환 신경망 음성 검출기를 이용한 음성 향상,2017,"['RNN', 'GMM', 'Phoneme', 'VAD', 'MMSE']",,
LSTM 모델 기반 주행 모드 인식을 통한 자율 주행에 관한 연구,2017,"['자율주행', '주행모드', '딥러닝', 'RNN', 'LSTM', 'autonomous driving', 'maneuvering modes', 'deep learning', 'RNN', 'LSTM']",,
퍼지와 인공 신경망을 이용한 침입탐지시스템의 탐지 성능 비교 연구,2017,"['침입탐지', '퍼지', '신경망', 'RNN', 'KDD CUP 1999 dataset', 'Intrusion Detection', 'Fuzzy', 'Neural Network', 'RNN', 'KDD CUP 1999 dataset']",,
심층학습을 이용한 기계번역 기술과 정확도 연구,2017,"['Deep Neural Network', 'Machine Translation', 'Google Translator', 'Recurrent Neural Network', 'Autoencoder']",,"In this study, we discuss the basic technology of machine learning of the deep neural network for natural language processing(NLP). We explain the distributed vector representation of words. Distributed vector representation is proved to be able to carry semantic meanings and are useful in various NLP tasks. The recurrent neural network(RNN) is employed to get the vector representation of sentences. We discuss the RNN encoder-decoder model and some modifications of the RNN structure to improve the accuracy of the machine translations. To test and verify the accuracy of Google translator, we performed the translation among Korean, English, and Japanese, and examined the meaning change between the original and the translated sentence. In neural network translation, we showed some inaccuracies of the translation such as wrong relation between subject and object, or some omission or repetition of the original meaning. In order to increase the performance and accuracy of machine translation, it is necessary to acquire more data for training."
AWS 사물 인터넷 환경에서 딥러닝을 이용한 시계열 센서 데이터의 실시간 예측 서비스 아키텍처,2017,"['아마존 웹서비스', '사물인터넷', '딥러닝', 'LSTM', '순환형 신경망', 'AWS', 'IoT', 'Deep Learning', 'LSTM', 'RNN']",,"With the advent of Internet of Things (IoT), the use of various devices connected to Internet has generated a large amount of data, and the importance of big data analysis has rapidly been increasing. In particular, it is necessary to analyze various IoT data generated in real-time and to provide various services through new meaningful future prediction analysis. Therefore, this paper presents the direction of Amazon Web Service (AWS) for real-time prediction service in IoT environment. Also, in this paper, we propose an architecture in AWS IoT environment for analyzing sensor data such as power, temperature, humidity, wind speed, and so on, received from IoT devices using recurrent neural networks (RNN) suitable for time series data among various algorithms, and providing users with necessary services using prediction data. The proposed architecture extracts new information from the time series IoT data and can create new business value by applying real-time IoT service to sports, cultural contents, and so on as well as real-time prediction model."
Evaluation of Recurrent Neural Network Variants for Person Re-identification,2017,"['Person re-identification', 'Multi-shot', 'Recurrent neural network', 'Optimization']",,"Instead of using only spatial features from a single frame for person re-identification, a combination of spatial and temporal factors boosts the performance of the system. A recurrent neural network (RNN) shows its effectiveness in generating highly discriminative sequence-level human representations. In this work, we implement RNN, three Long Short Term Memory (LSTM) network variants, and Gated Recurrent Unit (GRU) on Caffe deep learning framework, and we then conduct experiments to compare performance in terms of size and accuracy for person reidentification. We propose using GRU for the optimized choice as the experimental results show that the GRU achieves the highest accuracy despite having fewer parameters than the others."
자질 보강과 양방향 LSTM-CNN-CRF 기반의 한국어 개체명 인식 모델,2017,"['개체명 인식', '자연어 처리', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Natural Language Processing', 'Deep Learning', 'Feature Augmentation']","개체명 인식(Named Entity Recognition) 시스템은 문서에서 인명(PS), 지명(LC), 단체명(OG)과 같은 개체명을 가지는 단어나 어구를 해당 개체명으로 인식하는 시스템이다. 개체명 인식을 하기위한 전통적인 연구방법으로는 hand-craft된 자질(feature)을 기반으로 모델을 학습하는 통계 기반의 모델이 있다. 최근에는 딥러닝 기반의 RNN(Recurrent Neural Networks), LSTM(Long-short Term Memory)과 같은 모델을 이용하여 문장을 표현하는 자질을 구성하고 이를 개체명 인식과 같이 순서 라벨링(sequence labeling) 문제 해결에 이용한 연구가 제안되었다. 본 연구에서는 한국어 개체명 인식 시스템의 성능 향상을 위해, end-to-end learning 방식이 가능한 딥러닝 기반의 모델에 미리 구축되어 있는 hand-craft된 자질이나 품사 태깅 정보 및 기구축 사전(lexicon) 정보를 추가로 활용하여 자질을 보강(augmentation)하는 방법을 제안한다. 실험 결과 본 논문에서 제안하는 방법에 따라 자질을 보강한 한국어 개체명 인식 시스템의 성능 향상을 확인하였다. 또한 본 연구의 결과를 한국어 자연어처리(NLP) 및 개체명 인식 시스템을 연구하는 연구자들과의 향후 협업 연구를 위해 github를 통해 공개하였다.","The Named Entity Recognition system is a system that recognizes words or phrases with object names such as personal name (PS), place name (LC), and group name (OG) in the document as corresponding object names. Traditional approaches to named entity recognition include statistical-based models that learn models based on hand-crafted features. Recently, it has been proposed to construct the qualities expressing the sentence using models such as deep-learning based Recurrent Neural Networks (RNN) and long-short term memory (LSTM) to solve the problem of sequence labeling. In this research, to improve the performance of the Korean named entity recognition system, we used a hand-crafted feature, part-of-speech tagging information, and pre-built lexicon information to augment features for representing sentence. Experimental results show that the proposed method improves the performance of Korean named entity recognition system. The results of this study are presented through github for future collaborative research with researchers studying Korean Natural Language Processing (NLP) and named entity recognition system."
전통문화 이미지를 위한 세부 자질 주목형 이미지 자동 분석기,2017,"['Image Processing', 'Image Classifier', 'Deep Learning', 'Artificial Neural Networks', 'Natural Language Processing', 'Machine Learning', 'Artificial Intelligence', '이미지 처리', '이미지 분류기', '딥러닝', '인공신경망', '자연어처리', '기계학습', '인공지능']","이 논문에서는 최근 전통문화의 늘어나는 콘텐츠와 대조적으로 전통문화에 대한 접근성이 떨어지는 점에 주목하여 이러한 콘텐츠의 접근성의 향상을 위해 지속된 관리와 연구를 위하여 전통문화 이미지를 위한 이미지 자동 분석기를 소개한다. 이 논문에서 소개하는 이미지 자동 분석기는 인공신경망을 기반으로 입력 이미지의 자질들을 벡터스페이스로 변환하여 이를 RNN 기반의 모델을 통하여 세부 자질들을 파악하여 전통문화 이미지의 분류를 행한다. 이러한 방법을 통하여 전체적으로 비슷하게 보이는 전통문화 이미지들의 분류를 가능케 한다. 해당 모델의 훈련을 위하여 한민족정보문화마당 기반의 형식을 토대로 넓은 폭의 이미지 데이터를 수집 및 정리하여 차후 전통문화 이미지 관련 분야에서 사용할 수 있는 데이터셋의 구축에 기여를 하였다. 또한 이러한 연구가 최종적으로 전통문화와 관련된 수요, 공급 및 연구가 한층 더 활발해지는 것에 기여를 한다.","As accessibility toward traditional cultural contents drops compared to its increase in production, the need for higher accessibility for continued management and research to exist. For this, this paper introduces an image classifier model for traditional images based on artificial neural networks, which converts the input image's features into a vector space and by utilizing a RNN based model it recognizes and compares the details of the input which enables the classification of traditional images. This enables the classifiers to classify similarly looking traditional images more precisely by focusing on the details. For the training of this model, a wide range of images were arranged and collected based on the format of the Korean information culture field, which contributes to other researches related to the fields of using traditional cultural images. Also, this research contributes to the further activation of demand, supply, and researches related to traditional culture."
전자상거래 추천시스템을 위한 순환신경망 알고리즘들의 성능평가,2017,"['전자상거래', '추천시스템', '머신러닝', '순환신경망', '최적화 알고리즘', '텐서플로우', 'e-commerce', 'recommendation system', 'machine learning', 'recurrent neural network', 'optimization algorithm', 'TensorFlow']","전자상거래 발전에 따라 온라인 쇼핑을 이용하는 사람들이 증가하였고 제품 또한 다양해지고 있다. 이러한 추세로 구매자가 만족할 수 있는 정확한 추천시스템의 중요성이 증대되었으며 정확도를 높이기 위한 새로운 방법의 연구가 계속되고 있다. 순환신경망은 시퀀스 학습에 적합한 딥 러닝 방법 중 하나이며 본 연구에서는 추천시스템의 정확도를 높이는 방법으로 구매자의 제품 접근순서를 순환신경망에 적용하여 알고리즘 성능평가를 하였다. 알고리즘 성능평가에는 대표적인 순환신경망 알고리즘과 최적화 알고리즘으로 진행하였다. 순환신경망 알고리즘으로는 RNN, LSTM, GRU 그리고 최적화 알고리즘으로는 Adagrad, RMSProp, Adam optimizer를 사용하였다. 실험 도구로는 구글의 오픈소스 라이브러리인 텐서플로우를 사용하였고 데이터는 RecSys Challenge 2015에서 제공하는 e-commerce session 데이터를 활용하였다. 실험 결과 실험 데이터에 적합한 최적의 하이퍼파라미터를 발굴하고 적용하여 RecSys Challenge 2015 참가자들의 결과와 비교하였다. 상품 접근 순서만을 학습시킨 결과이기 때문에 등수가 높지는 않았지만 기존 추천시스템에 접목한다면 정확도 향상에 기여할 수 있을 것으로 보인다.","Due to the advance of e-commerce systems, the number of people using online shopping and products has significantly increased. Therefore, the need for an accurate recommendation system is becoming increasingly more important. Recurrent neural network is a deep-learning algorithm that utilizes sequential information in training. In this paper, an evaluation is performed on the application of recurrent neural networks to recommendation systems. We evaluated three recurrent algorithms (RNN, LSTM and GRU) and three optimal algorithms(Adagrad, RMSProp and Adam) which are commonly used. In the experiments, we used the TensorFlow open source library produced by Google and e-commerce session data from RecSys Challenge 2015. The results using the optimal hyper-parameters found in this study are compared with those of RecSys Challenge 2015 participants."
End-to-end Korean Document Summarization using Copy Mechanism and Input-feeding,2017,"['문서요약', '인공신경망', '기계학습', '딥러닝', 'RNN', 'Deep Learning', 'GRU', 'Document Summarization']",,
Water Level Forecasting based on Deep Learning : A Use Case of Trinity River-Texas-The United States,2017,"['침수 예측', '딥러닝', 'RNN', 'BPTT', 'LSTM', 'water level forecasting', 'deep learning', 'recurrent neural networks', 'back propagationthrough time', 'long short-term memory']",,
장단기 메모리 순환신경망 기반의 비침입적 음성 명료도 추정 방법,2017,"['Deep neural network (DNN)', 'Recurrent neural network (RNN)', 'Long short-term memory (LSTM)', 'Non-Intrusive', 'Speech intelligibility estimation', 'STOI', 'P.563']",,
LSTM 기반 Model-Free LKAS 조향 각 생성,2017,"['Long Short-Term Memory (LSTM)', 'Recurrent Neural Network (RNN)', 'steering angle prediction', 'Lane Kepping Assistance System (LKAS)']",,"In this paper, we propose a lateral upper controller that predicts vehicle motion and generates a model-free LKAS steering angle by applying long-term memory (LSTM), one of the deep learning techniques. The apparent and distinct advantage of this LSTM model is that the relationship of nonlinear sensor data can be grasped and learned devoid of a mathematical model while using the time information. In this sense, the LKAS steering angle can be generated by predicting the movement of the vehicle in consideration of the past vehicle motion based on the sensor data. In addition, the time delay problem due to the difference of sampling time on each sensor can be simply solved by learning based on a time table which has a synchronized sampling time. The input values of the upper controller are the coefficient of the road model and the vehicle dynamic characteristics are obtained from the image processing data from the camera sensor. As for the target values, the steering angles in the next state are selected. The learning model was developed by learning the many-to-one LSTM prediction model with serial connection of LSTM and Fully-Connected (FC) Multilayer Perceptron (MLP). For implementation of the learning model, Tensorflow is employed and the data from a real test road was used. With this model, the learning is conducted and its effectiveness is shown by comparing with a LKAS lateral controller using a model-based multi rate Kalman Filter (MKF)."
Large-Scale Text Classification with Deep Neural Networks,2017,"['deep learning', 'large-scale text classification', 'natural language processing', 'artificial neural networks', '딥러닝', '대용량 문서 분류', '자연어 처리', '인공신경망']",,"The classification problem in the field of Natural Language Processing has been studied for a long time. Continuing forward with our previous research, which classifies large-scale text using Convolutional Neural Networks (CNN), we implemented Recurrent Neural Networks (RNN), Long- Short Term Memory (LSTM) and Gated Recurrent Units (GRU). The experiment’s result revealed that the performance of classification algorithms was Multinomial Naïve Bayesian Classifier < Support Vector Machine (SVM) < LSTM < CNN < GRU, in order. The result can be interpreted as follows: First, the result of CNN was better than LSTM. Therefore, the text classification problem might be related more to feature extraction problem than to natural language understanding problems. Second, judging from the results the GRU showed better performance in feature extraction than LSTM. Finally, the result that the GRU was better than CNN implies that text classification algorithms should consider feature extraction and sequential information. We presented the results of fine-tuning in deep neural networks to provide some intuition regard natural language processing to future researchers."
한국어 음소 단위 LSTM 언어모델을 이용한 문장 생성,2017,"['언어 모델', '순환 신경망 모형', 'LSTM 모형', '문장 생성 모형', 'Language model', 'Recurrent neural network', 'Long short-term memory model', 'Sentence generation model']",,"Language models were originally developed for speech recognition and language processing. Using a set of example sentences, a language model predicts the next word or character based on sequential input data. N-gram models have been widely used but this model cannot model the correlation between the input units efficiently since it is a probabilistic model which are based on the frequency of each unit in the training set. Recently, as the deep learning algorithm has been developed, a recurrent neural network (RNN) model and a long short-term memory (LSTM) model have been widely used for the neural language model (Ahn, 2016; Kim et al., 2016; Lee et al., 2016). These models can reflect dependency between the objects that are entered sequentially into the model (Gers and Schmidhuber, 2001; Mikolov et al., 2010; Sundermeyer et al., 2012). In order to learning the neural language model, texts need to be decomposed into words or morphemes. Since, however, a training set of sentences includes a huge number of words or morphemes in general, the size of dictionary is very large and so it increases model complexity. In addition, word-level or morpheme-level models are able to generate vocabularies only which are contained in the training set. Furthermore, with highly morphological languages such as Turkish, Hungarian, Russian, Finnish or Korean, morpheme analyzers have more chance to cause errors in decomposition process (Lankinen et al., 2016).  Therefore, this paper proposes a phoneme-level language model for Korean language based on LSTM models. A phoneme such as a vowel or a consonant is the smallest unit that comprises Korean texts. We construct the language model using three or four LSTM layers. Each model was trained using Stochastic Gradient Algorithm and more advanced optimization algorithms such as Adagrad, RMSprop, Adadelta, Adam, Adamax, and Nadam. Simulation study was done with Old Testament texts using a deep learning package Keras based the Theano. After pre-processing the texts, the dataset included 74 of unique characters including vowels, consonants, and punctuation marks. Then we constructed an input vector with 20 consecutive characters and an output with a following 21st character. Finally, total 1,023,411 sets of input-output vectors were included in the dataset and we divided them into training, validation, testsets with proportion 70:15:15. All the simulation were conducted on a system equipped with an Intel Xeon CPU (16 cores) and a NVIDIA GeForce GTX 1080 GPU.  We compared the loss function evaluated for the validation set, the perplexity evaluated for the test set, and the time to be taken for training each model. As a result, all the optimization algorithms but the stochastic gradient algorithm showed similar validation loss and perplexity, which are clearly superior to those of the stochastic gradient algorithm. The stochastic gradient algorithm took the longest time to be trained for both 3- and 4-LSTM models. On average, the 4-LSTM layer model took 69% longer training time than the 3-LSTM layer model. However, the validation loss and perplexity were not improved significantly or became even worse for specific conditions. On the other hand, when comparing the automatically generated sentences, the 4-LSTM layer model tended to generate the sentences which are closer to the natural language than the 3-LSTM model. Although there were slight differences in the completeness of the generated sentences between the models, the sentence generation performance was quite satisfactory in any simulation conditions: they generated only legitimate Korean letters and the use of postposition and the conjugation of verbs were almost perfect in the sense of grammar. The results of this study are expected to be widely used for the processing of Korean language in the field of language processing and speech recognition, which are the basis of artificial intelligence systems."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",
Deep Recurrent Neural Network for Multiple Time Slot Frequency Spectrum Predictions of Cognitive Radio,2017,"['cognitive radio', 'spectrum sensing', 'recurrent neural network', 'time series']",,"The main processes of a cognitive radio system include spectrum sensing, spectrum decision, spectrum sharing, and spectrum conversion. Experimental results show that these stages introduce a time delay that affects the spectrum sensing accuracy, reducing its efficiency. To reduce the time delay, the frequency spectrum prediction was proposed to alleviate the burden on the spectrum sensing. In this paper, the deep recurrent neural network (DRNN) was proposed to predict the spectrum of multiple time slots, since the existing methods only predict the spectrum of one time slot. The continuous state of a channel is divided into a many time slots, forming a time series of the channel state. Since there are more hidden layers in the DRNN than in the RNN, the DRNN has fading memory in its bottom layer as well as in the past input. In addition, the extended Kalman filter was used to train the DRNN, which overcomes the problem of slow convergence and the vanishing gradient of the gradient descent method. The spectrum prediction based on the DRNN was verified with a WiFi signal, and the error of the prediction was analyzed. The simulation results proved that the multiple slot spectrum prediction improved the spectrum efficiency and reduced the energy consumption of spectrum sensing."
순환신경망을 이용한 한글 필기체 인식,2017,"['순환신경망', '한글필기체 인식', '딥러닝 응용', '한글 구성 원리를 고려한 인식', '온라인 필기체 인식', 'recurrent neural networks', 'Hangul handwriting recognition', 'deep learning application', 'online handwriting recognition']","온라인 방식의 한글 필기체 인식 문제를 분석하고 순환신경망 기반의 해법을 모색한다. 한글 낱글자 인식 문제를 순서데이터 레이블링의 관점에서 서열 분류, 구간 분류, 시간별 분류의 세 단계로 구분하여 각각에 대한 해법을 살펴보며, 한글의 구성 원리를 고려한 해결 방안을 정리한다. 한글 2350글자에 대한 온라인 필기체 데이터에 GRU(gated recurrent unit)의 다층 구조를 가지는 서열 분류모델을 적용한 결과, 낱글자 인식 정확도는 86.2%, 초･중･종성 구성에 따른 6가지 유형 분류 정확도는 98.2%로 측정되었다. 유형 분류 모델로 획의 진행에 따른 유형 변화 역시 높은 정확도로 인식하는 결과를 통해, 순환신경망을 이용하여 순서 데이터에서 한글의 구조와 같은 고차원적 지식을 학습할 수 있음을 확인하였다.","We analyze the online Hangul handwriting recognition problem (HHR) and present solutions based on recurrent neural networks. The solutions are organized according to the three kinds of sequence labeling problem - sequence classifications, segment classification, and temporal classification, with additional consideration of the structural constitution of Hangul characters. We present a stacked gated recurrent unit (GRU) based model as the natural HHR solution in the sequence classification level. The proposed model shows 86.2% accuracy for recognizing 2350 Hangul characters and 98.2% accuracy for recognizing the six types of Hangul characters. We show that the type recognizing model successfully follows the type change as strokes are sequentially written. These results show the potential for RNN models to learn high-level structural information from sequential data."
딥러닝 프레임워크의 비교,2017,"['딥러닝 프레임워크', '자동미분', '티아노', '텐서플로', 'Cognitive toolkit', 'CNN', 'deep learning framework', 'Theano', 'TensorFlow', 'CNTK', 'computational graph', 'CIFAR-10']",,"The deep learning framework is software designed to help develop deep learning models. Some of its important functions include “automatic differentiation” and “utilization of GPU”. The list of popular deep learning framework includes Caffe (BVLC) and Theano (University of Montreal). And recently, Microsofts deep learning framework, Microsoft Cognitive Toolkit, was released as open-source license, following Google’s Tensorflow a year earlier. The early deep learning frameworks have been developed mainly for research at universities. Beginning with the inception of Tensorflow, however, it seems that companies such as Microsoft and Facebook have started to join the competition of framework development. Given the trend, Google and other companies are expected to continue investing in the deep learning framework to bring forward the initiative in the artificial intelligence business. From this point of view, we think it is a good time to compare some of deep learning frameworks. So we compare three deep learning frameworks which can be used as a Python library. Those are Googles Tensorflow, Microsoft’s CNTK, and Theano which is sort of a predecessor of the preceding two.  The most common and important function of deep learning frameworks is the ability to perform automatic differentiation. Basically all the mathematical expressions of deep learning models can be represented as computational graphs, which consist of nodes and edges. Partial derivatives on each edge of a computational graph can then be obtained. With the partial derivatives, we can let software compute differentiation of any node with respect to any variable by utilizing chain rule of Calculus.  First of all, the convenience of coding is in the order of CNTK, Tensorflow, and Theano. The criterion is simply based on the lengths of the codes and the learning curve and the ease of coding are not the main concern. According to the criteria, Theano was the most difficult to implement with, and CNTK and Tensorflow were somewhat easier. With Tensorflow, we need to define weight variables and biases explicitly. The reason that CNTK and Tensorflow are easier to implement with is that those frameworks provide us with more abstraction than Theano. We, however, need to mention that low-level coding is not always bad. It gives us flexibility of coding. With the low-level coding such as in Theano, we can implement and test any new deep learning models or any new search methods that we can think of.  The assessment of the execution speed of each framework is that there is not meaningful difference. According to the experiment, execution speeds of Theano and Tensorflow are very similar, although the experiment was limited to a CNN model. In the case of CNTK, the experimental environment was not maintained as the same. The code written in CNTK has to be run in PC environment without GPU where codes execute as much as 50 times slower than with GPU. But we concluded that the difference of execution speed was within the range of variation caused by the different hardware setup.  In this study, we compared three types of deep learning framework: Theano, Tensorflow, and CNTK. According to Wikipedia, there are 12 available deep learning frameworks. And 15 different attributes differentiate each framework. Some of the important attributes would include interface language (Python, C ++, Java, etc.) and the availability of libraries on various deep learning models such as CNN, RNN, DBN, and etc. And if a user implements a large scale deep learning model, it will also be important to support multiple GPU or multiple servers. Also, if you are learning the deep learning model, it would also be important if there are enough examples and references."
