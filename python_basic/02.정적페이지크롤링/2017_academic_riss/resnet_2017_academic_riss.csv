title,date,keywords,abstract,multilingual_abstract
딥러닝 기반 병충해 작물 이미지 분류에 관한 연구,2022,[],세계자원연구소에 따르면 꾸준히 증가하는 인구를 위해선 추후에 기존 생산량의 약 70% 이상의 식량을 확보해야 한다고 예상한다. 그러나 농업인들은 자연재해보다 자주 발생하는 병충해로 인한 피해로 원활한 작물 생산에 고충을 겪고 있다. 사람이 작물들의 상태를 매번 확인하는 데에 어려움이 있기에 병충해를 미리 예방하기란 쉽지 않다. 그래서 농가는 대체로 전문가에게 병충해 분류의 자문을 구한다. 하지만 시간이 오래 걸리고 병충해는 빠르게 번지기 때문에 피해가 커지는 경우가 있다. 이와 같은 농업의 고질적인 문제를 해결하고자 본 논문에서는 딥러닝을 기반으로 작물의 이미지 데이터를 이용해 병충해 피해를 입은 작물을 분류하는 연구를 제안한다. 이미지 분류 분야에 자주 쓰이는 컨볼루션 신경망(CNN)을 이용할 것이다. 그중에서도 기본적인 모델과 전이 학습 기반인 사전 훈련 모델 ResNet50으로 병충해 작물 이미지분류 성능을 평가할 것이다. 이러한 연구로 농가는 병충해 작물을 조기에 파악하고 이는 신속한 방제로 이어져 큰 피해를 예방할 수 있을 것이다.,
Instagram image classification with Deep Learning,2017,[],,"In this paper we introduce two experimental results from classification of Instagram images and some valuable lessons from them. We have tried some experiments for evaluating the competitive power of Convolutional Neural Network(CNN) in classification of real social network images such as Instagram images. We used AlexNet and ResNet, which showed the most outstanding capabilities in ImageNet Large Scale Visual Recognition Challenge(ILSVRC) 2012 and 2015, respectively. And we used 240 Instagram images and 12 pre-defined categories for classifying social network images. Also, we performed fine-tuning using Inception V3 model, and compared those results. In the results of four cases of AlexNet, ResNet, Inception V3 and fine-tuned Inception V3, the Top-1 error rates were 49.58%, 40.42%, 30.42%, and 5.00%. And the Top-5 error rates were 35.42%, 25.00%, 20.83%, and 0.00% respectively."
Comparison of Fine-Tuned Convolutional Neural Networks for Clipart Style Classification,2017,"['Clipart Classification', 'Convolutional neural network', 'Computer vision', 'Clipart', 'style search', 'Fine tuning', 'Deep learning']",,"Clipart is artificial visual contents that are created using various tools such as Illustrator to highlight some information. Here, the style of the clipart plays a critical role in determining how it looks. However, previous studies on clipart are focused only on the object recognition [16], segmentation, and retrieval of clipart images using hand-craft image features. Recently, some clipart classification researches based on the style similarity using CNN have been proposed, however, they have used different CNN-models and experimented with different benchmark dataset so that it is very hard to compare their performances. This paper presents an experimental analysis of the clipart classification based on the style similarity with two well-known CNN-models (Inception Resnet V2 [13] and VGG-16 [14] and transfers learning with the same benchmark dataset (Microsoft Style Dataset 3.6K). From this experiment, we find out that the accuracy of Inception Resnet V2 is better than VGG for clipart style classification because of its deep nature and convolution map with various sizes in parallel. We also find out that the end-to-end training can improve the accuracy more than 20% in both CNN models."
Comparison of Fine-Tuned Convolutional Neural Networks for Clipart Style Classification,2017,"['Clipart Classification', 'Convolutional neural network', 'Computer vision', 'Clipart', 'style search', 'Fine tuning', 'Deep learning']",,"Clipart is artificial visual contents that are created using various tools such as Illustrator to highlight some information. Here, the style of the clipart plays a critical role in determining how it looks. However, previous studies on clipart are focused only on the object recognition [16], segmentation, and retrieval of clipart images using hand-craft image features. Recently, some clipart classification researches based on the style similarity using CNN have been proposed, however, they have used different CNN-models and experimented with different benchmark dataset so that it is very hard to compare their performances. This paper presents an experimental analysis of the clipart classification based on the style similarity with two well-known CNN-models (Inception Resnet V2 [13] and VGG-16 [14] and transfers learning with the same benchmark dataset (Microsoft Style Dataset 3.6K). From this experiment, we find out that the accuracy of Inception Resnet V2 is better than VGG for clipart style classification because of its deep nature and convolution map with various sizes in parallel. We also find out that the end-to-end training can improve the accuracy more than 20% in both CNN models."
Comparison of Fine-Tuned Convolutional Neural Networks for Clipart Style Classification,2017,"['Clipart Classification', 'Convolutional neural network', 'Computer vision', 'Clipart', 'style search', 'Finetuning', 'Deep learning']",,"Clipart is artificial visual contents that are created using various tools such as  Illustrator to highlight some information. Here, the style of the clipart plays a critical role in determining how  it looks. However, previous studies on clipart are focused only on the object recognition [16],  segmentation, and retrieval of clipart images using hand-craft image features. Recently, some clipart classification  researches based on the style similarity using CNN have been proposed, however, they have used different  CNN-models and experimented with different benchmark dataset so that it is very hard to compare  their performances. This paper presents an experimental analysis of the clipart classification based on the  style similarity with two well-known CNN-models (Inception Resnet V2 [13] and VGG-16 [14] and transfers  learning with the same benchmark dataset (Microsoft Style Dataset 3.6K). From this experiment, we find out  that the accuracy of Inception Resnet V2 is better than VGG for clipart style classification because of its  deep nature and convolution map with various sizes in parallel. We also find out that the end-to-end  training can improve the accuracy more than 20% in both CNN models."
합성곱 신경망을 이용한 복잡한 형상을 가진 공의 인식,2017,"['deep learning', 'R-CNN', 'RoboCup', 'object classification', 'object localization']",,"Image processing is widely used not only in manufacturing industries, but also in advanced contexts such as RoboCup, an international robotics competition. Recently, in the image processing field, convolutional neural networks, which is a deep learning approach, became the mainstream of object recognition algorithms. In this paper, a convolutional neural network is designed and used to learn the features of the ball in the RoboCup soccer game. The convolutional neural network was named JeoNet. JeoNet was modified to learn fewer features than VGGNet and ResNet, but shows the same performance. In order to obtain the detected ball’s position, the Single Shot Multibox Detector was applied. To verify JeoNet, an experimental environment was constructed in which a soccer robot finds a ball in the sight. The benefits of JeoNet were shown by comparing the tracking time of the ball between JeoNet and conventional machine vision based ball finding algorithms."
딥 residual network를 이용한 선생-학생 프레임워크에서 힌트-KD 학습 성능 분석,2017,"['Knowledge distillation', 'Hint training', 'Deep residual networks', 'Caffe']",,
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 아토피피부염 중증도 진단 모델 개발,2017,"['아토피피부염', '딥러닝', '이미지 인식 알고리즘', 'Convolutional Neural Network', 'Convolutional Neural Network', 'Atopic Dermatitis', 'Deep Learning', 'Image Recognition Algorithm']","제4차 산업혁명의 등장과 경제성장으로 인한 ‘국민 삶의 질 향상’ 요구 증대로 인해 의료서비스의 질과 의료비용에 대한 국민들의 요구수준이 향상되고 있으며, 이로 인해 인공지능이 의료현장에 도입되고 있다. 하지만 인공지능이 의료분야에 활용된 사례를 살펴보면 ‘삶의 질’에 직접적인 영향을 끼치는 만성피부질환에 활용된 사례는 부족한 실정이며, 만성피부질환 중 대표적 질병인 아토피피부염은 정성적 진단 방법으로 인해 진단의 객관성을 확보할 수 없다는 한계가 존재한다. 본 연구에서는 아토피피부염의 객관적 중증도 평가 방법을 마련하여 아토피피부염 환자의 삶의 질을 향상시키고자 다음과 같은 연구를 수행하였다. 첫째, 가톨릭대학교 의과대학 성모병원의 데이터베이스로부터 아토피피부염 환자의 이미지 데이터를 수집했으며, 수집된 이미지 데이터에 대한 정제 및 라벨링 작업을 수행하여 모델 학습과 검증에 적합한 데이터를 확보했다. 둘째, 지능형 아토피피부염 중증도 진단 모형에 적합한 이미지 인식 알고리즘을 파악하기 위해 다양한 CNN 알고리즘들을 병변별 학습용 데이터로 학습시키고, 검증용 데이터를 활용하여 해당 모델의 이미지 인식 정확도를 측정했다. 실증분석 결과 홍반(Erythema)의 경우 ‘ResNet V1 101’, 긁은 정도(Excoriation)의 경우 ‘ResNet V2 50’이 90% 이상의 정확도를 기록하였으며, 태선화(Lichenification)의 경우 학습용 데이터 부족의 한계로 인해 두 병변보다 낮은 89%의 정확도를 보였다. 해당 결과를 통해 이미지 인식 알고리즘이 단순한 사물 인식 분야뿐만 아니라 전문적 지식이 요구되는 분야에도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 아토피피부염 환자의 이미지 데이터를 활용했다는 측면에서 실제 임상환경에서 활용성이 높을 것으로 사료된다.","With the advent of ‘The Forth Industrial Revolution’ and the growing demand for quality of life due to economic growth, needs for the quality of medical services are increasing. Artificial intelligence has been introduced in the medical field, but it is rarely used in chronic skin diseases that directly affect the quality of life. Also, atopic dermatitis, a representative disease among chronic skin diseases, has a disadvantage in that it is difficult to make an objective diagnosis of the severity of lesions. The aim of this study is to establish an intelligent severity recognition model of atopic dermatitis for improving the quality of patient’s life. For this, the following steps were performed. First, image data of patients with atopic dermatitis were collected from the Catholic University of Korea Seoul Saint Mary’s Hospital. Refinement and labeling were performed on the collected image data to obtain training and verification data that suitable for the objective intelligent atopic dermatitis severity recognition model. Second, learning and verification of various CNN algorithms are performed to select an image recognition algorithm that suitable for the objective intelligent atopic dermatitis severity recognition model. Experimental results showed that ‘ResNet V1 101’ and ‘ResNet V2 50’ were measured the highest performance with Erythema and Excoriation over 90% accuracy, and ‘VGG-NET’ was measured 89% accuracy lower than the two lesions due to lack of training data. The proposed methodology demonstrates that the image recognition algorithm has high performance not only in the field of object recognition but also in the medical field requiring expert knowledge. In addition, this study is expected to be highly applicable in the field of atopic dermatitis due to it uses image data of actual atopic dermatitis patients."
