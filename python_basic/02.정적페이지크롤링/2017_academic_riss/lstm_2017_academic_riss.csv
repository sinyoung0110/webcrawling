title,date,keywords,abstract,multilingual_abstract
자질 보강과 양방향 LSTM-CNN-CRF 기반의 한국어 개체명 인식 모델,2017,"['개체명 인식', '자연어 처리', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Natural Language Processing', 'Deep Learning', 'Feature Augmentation']","개체명 인식(Named Entity Recognition) 시스템은 문서에서 인명(PS), 지명(LC), 단체명(OG)과 같은 개체명을 가지는 단어나 어구를 해당 개체명으로 인식하는 시스템이다. 개체명 인식을 하기위한 전통적인 연구방법으로는 hand-craft된 자질(feature)을 기반으로 모델을 학습하는 통계 기반의 모델이 있다. 최근에는 딥러닝 기반의 RNN(Recurrent Neural Networks), LSTM(Long-short Term Memory)과 같은 모델을 이용하여 문장을 표현하는 자질을 구성하고 이를 개체명 인식과 같이 순서 라벨링(sequence labeling) 문제 해결에 이용한 연구가 제안되었다. 본 연구에서는 한국어 개체명 인식 시스템의 성능 향상을 위해, end-to-end learning 방식이 가능한 딥러닝 기반의 모델에 미리 구축되어 있는 hand-craft된 자질이나 품사 태깅 정보 및 기구축 사전(lexicon) 정보를 추가로 활용하여 자질을 보강(augmentation)하는 방법을 제안한다. 실험 결과 본 논문에서 제안하는 방법에 따라 자질을 보강한 한국어 개체명 인식 시스템의 성능 향상을 확인하였다. 또한 본 연구의 결과를 한국어 자연어처리(NLP) 및 개체명 인식 시스템을 연구하는 연구자들과의 향후 협업 연구를 위해 github를 통해 공개하였다.","The Named Entity Recognition system is a system that recognizes words or phrases with object names such as personal name (PS), place name (LC), and group name (OG) in the document as corresponding object names. Traditional approaches to named entity recognition include statistical-based models that learn models based on hand-crafted features. Recently, it has been proposed to construct the qualities expressing the sentence using models such as deep-learning based Recurrent Neural Networks (RNN) and long-short term memory (LSTM) to solve the problem of sequence labeling. In this research, to improve the performance of the Korean named entity recognition system, we used a hand-crafted feature, part-of-speech tagging information, and pre-built lexicon information to augment features for representing sentence. Experimental results show that the proposed method improves the performance of Korean named entity recognition system. The results of this study are presented through github for future collaborative research with researchers studying Korean Natural Language Processing (NLP) and named entity recognition system."
RNN과 LSTM을 이용한 주가 예측율 향상을 위한 딥러닝 모델,2017,"['technical analysis', 'fundamental analysis', 'artificial neural network', 'deep neural network', 'RNN', 'LSTM']",,"Recently, stock price prediction using deep learning has basically used assistance index as a prediction factors. However assistance index is necessary to examine whether it is suitable as prediction factors because it is subjective viewpoint of researcher. In this study, we examine the suitability as prediction factors with various combinations of existing assistance indexes through the R neural network package, and studied the optimal combinations of assistance indexes and environmental prediction factors like exchange rate, exchange rate moving average, and whole industrial production index in order to improve the prediction rate. In addition, we proposed a deep learning model like DNN, RNN, LSTM which have input-output with extracted prediction factors. As a result, most of the assistance indexes decreased the prediction rate and the prediction rate was improved through additional environmental prediction factors. Also, RNN and LSTM, which are time series deep learning networks, were learned quickly and steadily compared to DNN. Although there is a difference by items, the prediction rate improvement is about 15%."
Korean Semantic Role Labeling using Stacked Bidirectional LSTM-CRFs,2017,"['의미역 결정', '딥러닝', 'Stacked Bidirectional LSTM-CRFs', 'End-to-end SRL', 'Semantic Role Labeling', 'Deep-learning']",,
LSTM모델 기반 전기차용 2단 감속기 유압 예측,2022,"['Hydraulic Pressure(유압)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Long Short Term Memory(장단기 순환신경망)', 'Vehicle Control(차량 제어)']",,
한국어 음소 단위 LSTM 언어모델을 이용한 문장 생성,2017,"['언어 모델', '순환 신경망 모형', 'LSTM 모형', '문장 생성 모형', 'Language model', 'Recurrent neural network', 'Long short-term memory model', 'Sentence generation model']",,"Language models were originally developed for speech recognition and language processing. Using a set of example sentences, a language model predicts the next word or character based on sequential input data. N-gram models have been widely used but this model cannot model the correlation between the input units efficiently since it is a probabilistic model which are based on the frequency of each unit in the training set. Recently, as the deep learning algorithm has been developed, a recurrent neural network (RNN) model and a long short-term memory (LSTM) model have been widely used for the neural language model (Ahn, 2016; Kim et al., 2016; Lee et al., 2016). These models can reflect dependency between the objects that are entered sequentially into the model (Gers and Schmidhuber, 2001; Mikolov et al., 2010; Sundermeyer et al., 2012). In order to learning the neural language model, texts need to be decomposed into words or morphemes. Since, however, a training set of sentences includes a huge number of words or morphemes in general, the size of dictionary is very large and so it increases model complexity. In addition, word-level or morpheme-level models are able to generate vocabularies only which are contained in the training set. Furthermore, with highly morphological languages such as Turkish, Hungarian, Russian, Finnish or Korean, morpheme analyzers have more chance to cause errors in decomposition process (Lankinen et al., 2016).  Therefore, this paper proposes a phoneme-level language model for Korean language based on LSTM models. A phoneme such as a vowel or a consonant is the smallest unit that comprises Korean texts. We construct the language model using three or four LSTM layers. Each model was trained using Stochastic Gradient Algorithm and more advanced optimization algorithms such as Adagrad, RMSprop, Adadelta, Adam, Adamax, and Nadam. Simulation study was done with Old Testament texts using a deep learning package Keras based the Theano. After pre-processing the texts, the dataset included 74 of unique characters including vowels, consonants, and punctuation marks. Then we constructed an input vector with 20 consecutive characters and an output with a following 21st character. Finally, total 1,023,411 sets of input-output vectors were included in the dataset and we divided them into training, validation, testsets with proportion 70:15:15. All the simulation were conducted on a system equipped with an Intel Xeon CPU (16 cores) and a NVIDIA GeForce GTX 1080 GPU.  We compared the loss function evaluated for the validation set, the perplexity evaluated for the test set, and the time to be taken for training each model. As a result, all the optimization algorithms but the stochastic gradient algorithm showed similar validation loss and perplexity, which are clearly superior to those of the stochastic gradient algorithm. The stochastic gradient algorithm took the longest time to be trained for both 3- and 4-LSTM models. On average, the 4-LSTM layer model took 69% longer training time than the 3-LSTM layer model. However, the validation loss and perplexity were not improved significantly or became even worse for specific conditions. On the other hand, when comparing the automatically generated sentences, the 4-LSTM layer model tended to generate the sentences which are closer to the natural language than the 3-LSTM model. Although there were slight differences in the completeness of the generated sentences between the models, the sentence generation performance was quite satisfactory in any simulation conditions: they generated only legitimate Korean letters and the use of postposition and the conjugation of verbs were almost perfect in the sense of grammar. The results of this study are expected to be widely used for the processing of Korean language in the field of language processing and speech recognition, which are the basis of artificial intelligence systems."
LSTM 모델 기반 주행 모드 인식을 통한 자율 주행에 관한 연구,2017,"['자율주행', '주행모드', '딥러닝', 'RNN', 'LSTM', 'autonomous driving', 'maneuvering modes', 'deep learning', 'RNN', 'LSTM']",,
LSTM 기반 Model-Free LKAS 조향 각 생성,2017,"['Long Short-Term Memory (LSTM)', 'Recurrent Neural Network (RNN)', 'steering angle prediction', 'Lane Kepping Assistance System (LKAS)']",,"In this paper, we propose a lateral upper controller that predicts vehicle motion and generates a model-free LKAS steering angle by applying long-term memory (LSTM), one of the deep learning techniques. The apparent and distinct advantage of this LSTM model is that the relationship of nonlinear sensor data can be grasped and learned devoid of a mathematical model while using the time information. In this sense, the LKAS steering angle can be generated by predicting the movement of the vehicle in consideration of the past vehicle motion based on the sensor data. In addition, the time delay problem due to the difference of sampling time on each sensor can be simply solved by learning based on a time table which has a synchronized sampling time. The input values of the upper controller are the coefficient of the road model and the vehicle dynamic characteristics are obtained from the image processing data from the camera sensor. As for the target values, the steering angles in the next state are selected. The learning model was developed by learning the many-to-one LSTM prediction model with serial connection of LSTM and Fully-Connected (FC) Multilayer Perceptron (MLP). For implementation of the learning model, Tensorflow is employed and the data from a real test road was used. With this model, the learning is conducted and its effectiveness is shown by comparing with a LKAS lateral controller using a model-based multi rate Kalman Filter (MKF)."
CTC를 이용한 LSTM RNN 기반 한국어 음성인식 시스템,2017,"['Connectionist temporal classification', 'Long short term memory', 'Recurrent neural network', 'Acoustic model', 'Speech recognition', '음향모델', '음성인식']",,"A hybrid approach using Long Short Term Memory (LSTM) Recurrent Neural Network (RNN) has showed great improvement in speech recognition accuracy. For training acoustic model based on hybrid approach, it requires forced alignment of HMM state sequence from Gaussian Mixture Model (GMM)-Hidden Markov Model (HMM). However, high computation time for training GMM-HMM is required. This paper proposes an end-to-end approach for LSTM RNN-based Korean speech recognition to improve learning speed. A Connectionist Temporal Classification (CTC) algorithm is proposed to implement this approach. The proposed method showed almost equal performance in recognition rate, while the learning speed is 1.27 times faster."
Expansion of Word Representation for Named Entity Recognition Based on Bidirectional LSTM CRFs,2017,"['개체명 인식', '단어 표상', '음절', 'bi-LSTM-CRFs', 'Named Entity Recognition', 'Word Representation', 'Syllable']",,
딥 러닝을 이용한 부동산가격지수 예측,2017,"['딥 러닝', '부동산가격지수', '예측', 'DNN', 'LSTM', 'deep learning', 'real estate price index', 'predicting', 'DNN', 'LSTM']","본 연구의 목적은 딥 러닝 방법을 부동산가격지수 예측에 적용해보고, 기존의 시계열분석 방법과의 비교를 통해 부동산 시장 예측의 새로운 방법으로서 활용가능성을 확인하는 것이다. 딥 러닝(deep learning)방법인 DNN(Deep Neural Networks)모형 및 LSTM(Long Shot Term Memory networks)모형과 시계열분석 방법인 ARIMA(autoregressive integrated moving average)모형을 이용하여 여러 가지 부동산가격지수에 대한 예측을 시도하였다. 연구결과 첫째, 딥 러닝 방법의 예측력이 시계열분석 방법보다 우수한 것으로 나타났다. 둘째, 딥 러닝 방법 중에서는 DNN모형의 예측력이 LSTM모형의 예측력보다 우수하나 그 정도는 미미한 수준인 것으로 나타났다. 셋째, 딥 러닝 방법과 ARIMA모형은 부동산 가격지수(real estate price index) 중 아파트 실거래가격지수(housing sales price index)에 대한 예측력이 가장 부족한 것으로 나타났다. 향후 딥 러닝 방법을 활용함으로써 부동산 시장에 대한 예측의 정확성을 제고할 수 있을 것으로 기대된다.","The purpose of this study was to apply the deep running method to real estate price index predicting and to compare it with the time series analysis method to test the possibility of its application to real estate market forecasting. Various real estate price indices were predicted using the DNN (deep neural networks) and LSTM (long short term memory networks) models, both of which draw on the deep learning method, and the ARIMA (autoregressive integrated moving average) model, which is based on the time seies analysis method. The results of the study showed the following. First, the predictive power of the deep learning method is superior to that of the time series analysis method. Second, among the deep learning models, the predictability of the DNN model is slightly superior to that of the LSTM model. Third, the deep learning method and the ARIMA model are the least reliable tools for predicting the housing sales prices index among the real estate price indices. Drawing on the deep learning method, it is hoped that this study will help enhance the accuracy in predicting the real estate market dynamics."
특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델,2017,"['Machine learning', 'Deep learning', 'Artificial neural network', 'Power Electric demand prediction', 'LSTM']",,"This study analyze correlation between weekdays data and special days data of different power demand patterns, and builds a separate data set, and suggests ways to reduce power demand prediction error by using deep learning network suitable for each data set. In addition, we propose a method to improve the prediction rate by adding the environmental elements and the separating element to the meteorological element, which is a basic power demand prediction elements. The entire data predicted power demand using LSTM which is suitable for learning time series data, and the special day data predicted power demand using DNN. The experiment result show that the prediction rate is improved by adding prediction elements other than meteorological elements. The average RMSE of the entire dataset was 0.2597 for LSTM and 0.5474 for DNN, indicating that the LSTM showed a good prediction rate. The average RMSE of the special day data set was 0.2201 for DNN, indicating that the DNN had better prediction than LSTM. The MAPE of the LSTM of the whole data set was 2.74% and the MAPE of the special day was 3.07 %."
기술 용어에 대한 한국어 정의 문장 자동 생성을 위한 순환 신경망 모델 활용 연구,2017,"['Sentence Generation', 'Text Generation', 'Natural Language Generation(NLG)', 'Automatic Report Generation', 'Deep Learning', '문장 생성', '텍스트 생성', '자연어 생성', '보고서 자동 생성', '딥 러닝']","본 논문에서는 지속적으로 커져가는 산업․시장에 대해 관련 연구자들이 이를 효율적으로 분석할 수 있는 반자동 지원 체제 개발을 위한 기술 용어와 기술 개념에 대한 정의문 및 설명문을 자동으로 생성하는 한국어 문장 생성 모델을 제시한다. 한국어 정의 문장 생성을 위하여 딥러닝 기술 중 데이터의 전/후 관계를 포함한 시퀀스 레이블링이 가능한 LSTM을 활용한다. LSTM을 근간으로 한 두 가지 모델은 기술명을 입력할 시 그에 대한 정의문 및 설명문을 생성한다. 다양하게 수집된 대규모 학습 말뭉치를 이용해 실험한 결과, 본 논문에서 구현한 2가지 모델 중 CNN 음절 임베딩을 활용한 어절 단위 LSTM 모델이 용어에 대한 정의문 및 설명문을 생성하는데 더 나은 결과를 도출시킨다는 사실을 확인하였다. 본 논문의 연구 결과를 바탕으로 동일한 주제를 다루는 문장 집합을 생성할 수 있는 확장 모델을 개발할 수 있으며 더 나아가서는 기술에 대한 문헌을 자동으로 작성하는 인공지능 모델을 구현할 수 있으리라 사료된다.","In order to develop a semiautomatic support system that allows researchers concerned to efficiently analyze the technical trends for the ever-growing industry and market. This paper introduces a couple of Korean sentence generation models that can automatically generate definitional statements as well as descriptions of technical terms and concepts. The proposed models are based on a deep learning model called LSTM (Long Sort-Term Memory) capable of effectively labeling textual sequences by taking into account the contextual relations of each item in the sequences. Our models take technical terms as inputs and can generate a broad range of heterogeneous textual descriptions that explain the concept of the terms. In the experiments using large-scale training collections, we confirmed that more accurate and reasonable sentences can be generated by CHAR-CNN-LSTM model that is a word-based LSTM exploiting character embeddings based on convolutional neural networks (CNN). The results of this study can be a force for developing an extension model that can generate a set of sentences covering the same subjects, and furthermore, we can implement an artificial intelligence model that automatically creates technical literature."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
뜰개 이동 예측을 위한 신경망 및 통계 기반 기계학습 기법의 성능 비교,2017,"['유류 유출', '뜰개', '기계학습', '순환신경망', '예측', 'Oil Spill', 'Drifter', 'Machine learning', 'Recurrent neural network', 'LSTM', 'Prediction']","뜰개는 해양에서 해수의 특성 및 흐름을 관측하기 위한 장비로서, 해수의 흐름 관측을 이용해 유출유 확산 예측을 위해 사용될 수 있다. 본 논문에서는 관측기관에서 사용하는 뜰개가 특정 시간 간격으로 관측한 바람 및 해수의 특성과 이동경로를 기계학습 기법들을 이용하여 학습시키고 예측하는 모델을 제안한다. 서포트벡터 회귀, 방사기저함수 네트워크, 가우시안 프로세스, 다층 퍼셉트론, 순환신경망을 이용하여 뜰개의 이동경로 예측 방법을 제시한다. 기존 MOHID 수치모델과 비교하여 각 기법별로 4 개의 사례중 3 개에서 성능이 개선되었으며, 가장 좋은 개선율을 보인 기법은 LSTM으로 평균 47.59% 개선되었다. 추후 연구에서는 배깅과 부스팅을 이용하여 가중치를 부여하여 정확도를 개선할 예정이다.","Drifter is an equipment for observing the characteristics of seawater in the ocean, and it can be used to predict effluent oil diffusion and to observe ocean currents. In this paper, we design models or the prediction of drifter trajectory using machine learning. We propose methods for estimating the trajectory of drifter using support vector regression, radial basis function network, Gaussian process, multilayer perceptron, and recurrent neural network. When the propose mothods were compared with the existing MOHID numerical model, performance was improve on three of the four cases. In particular, LSTM, the best performed method, showed the imporvement by 47.59% Future work will improve the accuracy by weighting using bagging and boosting."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM's. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Large-Scale Text Classification with Deep Neural Networks,2017,"['deep learning', 'large-scale text classification', 'natural language processing', 'artificial neural networks', '딥러닝', '대용량 문서 분류', '자연어 처리', '인공신경망']",,"The classification problem in the field of Natural Language Processing has been studied for a long time. Continuing forward with our previous research, which classifies large-scale text using Convolutional Neural Networks (CNN), we implemented Recurrent Neural Networks (RNN), Long- Short Term Memory (LSTM) and Gated Recurrent Units (GRU). The experiment’s result revealed that the performance of classification algorithms was Multinomial Naïve Bayesian Classifier < Support Vector Machine (SVM) < LSTM < CNN < GRU, in order. The result can be interpreted as follows: First, the result of CNN was better than LSTM. Therefore, the text classification problem might be related more to feature extraction problem than to natural language understanding problems. Second, judging from the results the GRU showed better performance in feature extraction than LSTM. Finally, the result that the GRU was better than CNN implies that text classification algorithms should consider feature extraction and sequential information. We presented the results of fine-tuning in deep neural networks to provide some intuition regard natural language processing to future researchers."
A Study of Efficiency Information Filtering System using One-Hot Long Short-Term Memory,2017,"['information filtering system', 'spam filtering', 'region embedding', 'term weighting.']",,"In this paper, we propose an extended method of one-hot Long Short-Term Memory (LSTM)  and evaluate the performance on spam filtering task. Most of traditional methods proposed for spam filtering  task use word occurrences to represent spam or non-spam messages and all syntactic and semantic  information are ignored. Major issue appears when both spam and non-spam messages share many common  words and noise words. Therefore, it becomes challenging to the system to filter correct labels between  spam and non-spam. Unlike previous studies on information filtering task, instead of using only word  occurrence and word context as in probabilistic models, we apply a neural network-based approach to train the  system filter for a better performance. In addition to one-hot representation, using term weight with attention  mechanism allows classifier to focus on potential words which most likely appear in spam and non-spam  collection. As a result, we obtained some improvement over the performances of the previous methods. We  find out using region embedding and pooling features on the top of LSTM along with attention mechanism  allows system to explore a better document representation for filtering task in general."
360 영상으로부터 텍스트 정보를 이용한 자연스러운 사진 생성,2017,"['360 영상', '딥러닝', '자연어 처리', 'LSTM', '구도평가', '360 image', 'deep learning', 'natural language processing', 'photo composition']","360 영상은 상하좌우 모든 영역에 대한 정보를 갖고 있기 때문에 종종 지나치게 많은 정보를 포함하게 된다. 또한 360 영상의 내용을 2D 모니터를 이용하여 확인하기 위해서는 마우스를 이용하여 360 영상을 돌려 봐야 하거나, 또는 심하게 왜곡된 2D 영상으로 변환해서 봐야 하는 문제가 있다. 따라서 360 영상에서 사용자가 원하는 물체를 찾는 것은 상당히 까다로운 일이 될 수 있다. 본 논문은 물체나 영역을 묘사하는 문장이 주어졌을 때, 360 영상 내에서 문장과 가장 잘 어울리는 영상을 추출해내는 방법을 제시한다. 본 논문에서 제시한 방법은 주어진 문장 뿐 아니라 구도 역시 고려하여 구도 면에서도 보기 좋은 결과 영상을 생성한다. 본 논문에서 제시하는 방법은 우선 360 영상을 2D 큐브맵으로 변환한다. 일반적인 큐브맵은 큐브맵의 경계 부분에 걸쳐 있는 물체가 있을 경우, 이를 검출하기 어려운 문제가 있다. 따라서 더 정확한 물체 검출을 위해 본 논문에서는 변형된 큐브맵을 제시한다. 이렇게 변형된 큐브맵에 Long Short Term Memory (LSTM) 네트워크 기반의 자연어 문장을 이용한 물체 검출 방법을 적용한다. 최종적으로 원래의 360영상에서 검출된 영역을 포함하면서도 영상 구도 면에서 보기 좋은 영역을 찾아서 결과 영상을 생성한다.","As a 360-degree image carries information of all directions, it often has too much information. Moreover, in order to investigate a 360-degree image on a 2D display, a user has to either click and drag the image with a mouse, or project it to a 2D panorama image, which inevitably introduces severe distortions. In consequence, investigating a 360-degree image and finding an object of interest in such a 360-degree image could be a tedious task. To resolve this issue, this paper proposes a method to find a region of interest and produces a 2D naturally looking image from a given 360-degree image that best matches a description given by a user in a natural language sentence. Our method also considers photo composition so that the resulting image is aesthetically pleasing. Our method first converts a 360-degree image to a 2D cubemap. As objects in a 360-degree image may appear distorted or split into multiple pieces in a typical cubemap, leading to failure of detection of such objects, we introduce a modified cubemap. Then our method applies a Long Short Term Memory (LSTM) network based object detection method to find a region of interest with a given natural language sentence. Finally, our method produces an image that contains the detected region, and also has aesthetically pleasing composition."
AWS 사물 인터넷 환경에서 딥러닝을 이용한 시계열 센서 데이터의 실시간 예측 서비스 아키텍처,2017,"['아마존 웹서비스', '사물인터넷', '딥러닝', 'LSTM', '순환형 신경망', 'AWS', 'IoT', 'Deep Learning', 'LSTM', 'RNN']",,"With the advent of Internet of Things (IoT), the use of various devices connected to Internet has generated a large amount of data, and the importance of big data analysis has rapidly been increasing. In particular, it is necessary to analyze various IoT data generated in real-time and to provide various services through new meaningful future prediction analysis. Therefore, this paper presents the direction of Amazon Web Service (AWS) for real-time prediction service in IoT environment. Also, in this paper, we propose an architecture in AWS IoT environment for analyzing sensor data such as power, temperature, humidity, wind speed, and so on, received from IoT devices using recurrent neural networks (RNN) suitable for time series data among various algorithms, and providing users with necessary services using prediction data. The proposed architecture extracts new information from the time series IoT data and can create new business value by applying real-time IoT service to sports, cultural contents, and so on as well as real-time prediction model."
커널 모델과 장단기 기억 신경망을 결합한 보컬 및 비보컬 분리,2017,[],"본 논문에서는 커널 모델과 장단기 기억(Long-Short Term Memory, LSTM) 신경망을 결합한 보컬 및 비보컬 분리 방식을 제안한다. 기존의 음원 분리 방식은 비보컬 음원만 있는 구간에서 음원을 오추정하여 불필요한 비보컬 음원을 출력하는 한계가 있다. 따라서 본 논문에서는 커널 모델 기반의 보컬음 분리 방식에 LSTM 신경망 기반의 보컬 구간 분류 방식을 결합하여 보컬 음원의 오추정 문제를 개선하고 분리 성능을 향상시키고자 하였다. 또한 본 논문에서는 방식간의 결합 구조에 따라 병렬 결합형 분리 알고리즘과 직렬 결합형 분리 알고리즘을 제안하였으며, 실험을 통해 제안하는 방식들이 기존의 방식에 비해 더욱 향상된 분리 성능을 보이는 것을 확인할 수 있었다.",
A Study of Efficiency Information Filtering System using One-Hot Long Short-Term Memory,2017,"['information filtering system', 'spam filtering', 'region embedding', 'term weighting.']",,"In this paper, we propose an extended method of one-hot Long Short-Term Memory (LSTM) and evaluate the performance on spam filtering task. Most of traditional methods proposed for spam filtering task use word occurrences to represent spam or non-spam messages and all syntactic and semantic information are ignored. Major issue appears when both spam and non-spam messages share many common words and noise words. Therefore, it becomes challenging to the system to filter correct labels between spam and non-spam. Unlike previous studies on information filtering task, instead of using only word occurrence and word context as in probabilistic models, we apply a neural network-based approach to train the system filter for a better performance. In addition to one-hot representation, using term weight with attention mechanism allows classifier to focus on potential words which most likely appear in spam and non-spam collection. As a result, we obtained some improvement over the performances of the previous methods. We find out using region embedding and pooling features on the top of LSTM along with attention mechanism allows system to explore a better document representation for filtering task in general."
A Study of Efficiency Information Filtering System using One-Hot Long Short-Term Memory,2017,"['information filtering system', 'spam filtering', 'region embedding', 'term weighting']",,"In this paper, we propose an extended method of one-hot Long Short-Term Memory (LSTM) and evaluate the performance on spam filtering task. Most of traditional methods proposed for spam filtering task use word occurrences to represent spam or non-spam messages and all syntactic and semantic information are ignored. Major issue appears when both spam and non-spam messages share many common words and noise words. Therefore, it becomes challenging to the system to filter correct labels between spam and non-spam. Unlike previous studies on information filtering task, instead of using only word occurrence and word context as in probabilistic models, we apply a neural network-based approach to train the system filter for a better performance. In addition to one-hot representation, using term weight with attention mechanism allows classifier to focus on potential words which most likely appear in spam and non-spam collection. As a result, we obtained some improvement over the performances of the previous methods. We find out using region embedding and pooling features on the top of LSTM along with attention mechanism allows system to explore a better document representation for filtering task in general."
전자상거래 추천시스템을 위한 순환신경망 알고리즘들의 성능평가,2017,"['전자상거래', '추천시스템', '머신러닝', '순환신경망', '최적화 알고리즘', '텐서플로우', 'e-commerce', 'recommendation system', 'machine learning', 'recurrent neural network', 'optimization algorithm', 'TensorFlow']","전자상거래 발전에 따라 온라인 쇼핑을 이용하는 사람들이 증가하였고 제품 또한 다양해지고 있다. 이러한 추세로 구매자가 만족할 수 있는 정확한 추천시스템의 중요성이 증대되었으며 정확도를 높이기 위한 새로운 방법의 연구가 계속되고 있다. 순환신경망은 시퀀스 학습에 적합한 딥 러닝 방법 중 하나이며 본 연구에서는 추천시스템의 정확도를 높이는 방법으로 구매자의 제품 접근순서를 순환신경망에 적용하여 알고리즘 성능평가를 하였다. 알고리즘 성능평가에는 대표적인 순환신경망 알고리즘과 최적화 알고리즘으로 진행하였다. 순환신경망 알고리즘으로는 RNN, LSTM, GRU 그리고 최적화 알고리즘으로는 Adagrad, RMSProp, Adam optimizer를 사용하였다. 실험 도구로는 구글의 오픈소스 라이브러리인 텐서플로우를 사용하였고 데이터는 RecSys Challenge 2015에서 제공하는 e-commerce session 데이터를 활용하였다. 실험 결과 실험 데이터에 적합한 최적의 하이퍼파라미터를 발굴하고 적용하여 RecSys Challenge 2015 참가자들의 결과와 비교하였다. 상품 접근 순서만을 학습시킨 결과이기 때문에 등수가 높지는 않았지만 기존 추천시스템에 접목한다면 정확도 향상에 기여할 수 있을 것으로 보인다.","Due to the advance of e-commerce systems, the number of people using online shopping and products has significantly increased. Therefore, the need for an accurate recommendation system is becoming increasingly more important. Recurrent neural network is a deep-learning algorithm that utilizes sequential information in training. In this paper, an evaluation is performed on the application of recurrent neural networks to recommendation systems. We evaluated three recurrent algorithms (RNN, LSTM and GRU) and three optimal algorithms(Adagrad, RMSProp and Adam) which are commonly used. In the experiments, we used the TensorFlow open source library produced by Google and e-commerce session data from RecSys Challenge 2015. The results using the optimal hyper-parameters found in this study are compared with those of RecSys Challenge 2015 participants."
Preliminary Study of Deep Learning-based Precipitation Prediction,2017,"['Deep Learning', 'Global Navigation Satellite System', 'Precipitable Water Vapor', 'Meteorological Factors', 'Precipitation Prediction']",,"Recently, data analysis research has been carried out using the deep learning technique in various fields such as image interpretation and/or classification. Various types of algorithms are being developed for many applications. In this paper, we propose a precipitation prediction algorithm based on deep learning with high accuracy in order to take care of the possible severe damage caused by climate change. Since the geographical and seasonal characteristics of Korea are clearly distinct, the meteorological factors have repetitive patterns in a time series. Since the LSTM (Long Short-Term Memory) is a powerful algorithm for consecutive data, it was used to predict precipitation in this study. For the numerical test, we calculated the PWV (Precipitable Water Vapor) based on the tropospheric delay of the GNSS (Global Navigation Satellite System) signals, and then applied the deep learning technique to the precipitation prediction. The GNSS data was processed by scientific software with the troposphere model of Saastamoinen and the Niell mapping function. The RMSE (Root Mean Squared Error) of the precipitation prediction based on LSTM performs better than that of ANN (Artificial Neural Network). By adding GNSS-based PWV as a feature, the over-fitting that is a latent problem of deep learning was prevented considerably as discussed in this study."
Word2vec을 활용한 RNN기반의 문서 분류에 관한 연구,2017,"['Text Mining', 'Information Retrieval', 'Deep Learning', 'DocumenCt lassification', '텍스트 마이닝', '정보검색', '딥 러닝', '문서분류']","자연어 처리 분야에서도 심층 신경망 기술이 주목되고 있으며, 최근에는 convolutional neural network (CNN)기반의 심층신경망 구조가 이미지 분류뿐만 아니라 자연어 처리의 문서 분류에서도 좋은 성능이 입증되었다. 하지만 convolutional neural network (CNN)을 이용한 문서 분류 연구에서는 문장의 평균 단어 수가 16개로 이루어진 짧은 문장에 한하여 적용되었으며, 구문 전체와 의미론적 관계가 복잡한 전체 문장을 다루기 어렵다는 단점을 가지고 있다. 본 논문은 기존 연구의 한계점을극복하고 더 정확한 문서 분류 성능을 위하여 word2vec를 활용한 recurrent neural network (RNN)기반의 심층 신경망의접근법을 새롭게 제안한다. 이를 위해 장기 의존성 문제를 해결한 long short-term memory (LSTM)을 사용하여 긴 시퀀스의입력에서도 효과적인 문서 분류가 가능하도록 하였고, 제안 방식의 효율성을 검증하기 위해 영문 데이터 뿐 아니라 한국어영화 리뷰 데이터에 대해서도 실험을 수행하였다. 그 결과 장문을 포함하고 있는 영문 신문 기사에서는 87%, 단문으로구성된 영문 영화 리뷰 문서에서는 90%, 한국어 영화 리뷰에서는 88%의 문서 분류 정확도를 보였다","Deep neural network based methods have obtained remarkable progress on natural language processing (NLP) task. Recently, convolutional neural network (CNN) based approaches often outperform not only in image classification, but also in document classification. However, convolutional neural network (CNN) based methods is applied only to a short sentence composed of 16 words in average, and it has a disadvantage that it is difficult to deal with a sentence having a complicated semantic relationship with the whole sentence. In this paper, we propose a new method based on recurrent neural network (RNN) using word2vec to overcome the limitations of previous related work and to get much higher accuracy of document classification. By using long short-term memory (LSTM) to solve the long-term dependency problem, effective document classification is also possible for long sequence input. To validate performance of our proposed method in various data, we tested our proposed method both with English sentence and Korean movie review dataset. As a result, 87% of the English newspaper articles containing the long texts, 90% of the English movie review and 88% of the Korean movie reviewsh owed the accuracy of document classification"
딥러닝 기반의 다범주 감성분석 모델 개발,2017,"['Sentiment Analysis', 'Convolutional Neural Networks', 'Long Short-Term Memory', 'Word2vec']",,"Sentiment analysis is the process of determining whether a piece of document, text or conversation is positive, negative, neural or other emotion. Sentiment analysis has been applied for several real-world applications, such as chatbot. In the last five years, the practical use of the chatbot has been prevailing in many field of industry. In the chatbot applications, to recognize the user emotion, sentiment analysis must be performed in advance in order to understand the intent of speakers. The specific emotion is more than describing positive or negative sentences. In light of this context, we propose deep learning models for conducting multi-class sentiment analysis for identifying speaker’s emotion which is categorized to be joy, fear, guilt, sad, shame, disgust, and anger.Thus, we develop convolutional neural network (CNN), long short term memory (LSTM), and multi-layer neural network models, as deep neural networks models, for detecting emotion in a sentence. In addition, word embedding process was also applied in our research. In our experiments, we have found that long short term memory (LSTM) model performs best compared to convolutional neural networks and multi-layer neural networks. Moreover, we also show the practical applicability of the deep learning models to the sentiment analysis for chatbot."
온라인 뉴스 및 거시경제 변수를 활용한 주가예측,2017,"['주가예측', '딥러닝', '감성 분석', '경제 지표', 'Word2Vec', 'Stock price forecasting', 'Deep learning', 'Emotional analysis', 'Economic index', 'Word2Vec']","시장의 상태는 새로운 정보를 받으면서 변한다. 이는 투자자들의 결정에 영향을 주어 주식 시장의 변동을 만들어 내며, 주식 시장의 동향을 예측하는 데에 중요한 자료로써 사용된다. 외부의 정보는 크게 두 가지로 생각할 수 있는데, 뉴스의 정보와 거시 경제적인 지표이다. 하지만, 기존의 연구들은 뉴스만을 가지고 혹은 거시 경제 지표만을 가지고 예측을 하였으며, 뉴스의 정보와 거시 경제 지표를 함께 결합하여 외부의 영향을 모두 고려한 연구는 없었다. 본 논문에서는 주식 시장에 영향을 미치는 외부의 정보를 모두 고려하여 서로 다른 특성을 가지는 정보들을 딥러닝 알고리즘을 통해 통합하여 예측하는 방법을 제시한다. 뉴스 정보는 뉴욕타임스 2년 치 데이터를 Word2Vec 모형을 사용하여 정보 추출을 하였다. 거시 경제 지표는 다우 존스 지수에 영향을 줄 수 있는 지표들을 경제학적 이론에 기반을 두어 선정하였다. 이는 금값과 환율 시장이다. 뉴스에서 추출한 정보와 거시 경제적인 영향을 함께 통합하는 알고리즘은 시계열 데이터와 문자열 데이터를 다루기에 적절한 LSTM 네트워크를 응용하여 사용한다. 예측 기간을 바꾸며 실험을 진행한 결과, 단순 정보만을 가지고 예측한 결과나 거시 경제만을 가지고 예측한 결과보다 본 논문에서 제시한 두 가지를 통합하여 예측하는 것이 월등한 결과를 내었다. 또한, 기존의 연구에서 사용한 방법론과 제시한 딥러닝 알고리즘을 비교한 결과 본 논문에서 제시한 알고리즘이 기존 연구에서 사용한 방법론보다 월등한 결과를 나타냈다.","Market conditions change with new information. This affects investors' decisions and creates stock market volatility. This infor-mation is used as an important resource for forecasting stock market trends. At this time, there are two kinds of external information: news information and macroeconomic indicators. However, if we look at existing studies, they predicted only with news or macroe-conomic indicators. There was no study that considered all the external influences by combining news information and macroeconom-ic indicators together. Therefore, in this paper, we propose a method of integrating and forecasting information with different character-istics by considering the external information affecting the stock market through the deep learning algorithm. News information was extracted from the New York Times's 2-year data using the Word2vec model. Macroeconomic indicators are based on economic theo-ries that can influence the Dow Jones Index. This is the gold price and exchange rate market. Algorithms that integrate information ex-tracted from news and macroeconomic effects together are applied to LSTM networks suitable for handling time series data and string data. As a result of experimenting with changing the forecasting period, it is better to predict the results with only simple information and the macroeconomic results than with the results from this study. In addition, the algorithm proposed in this paper is superior to the methodology used in previous research."
이진 분류문제에서의 딥러닝 알고리즘의 활용 가능성 평가,2017,"['이진분류', '딥러닝', '다층 퍼셉트론', '합성곱 신경망', '장단기 기억', 'Binary Classification', 'Deep Learning', 'Multi-Layer Perceptron', 'Convolutional Neural Network', 'Long Short-Term Memory']",,"Recently, AlphaGo which is Bakuk (Go) artificial intelligence program by Google DeepMind, had a huge victory against Lee Sedol. Many people thought that machines would not be able to win a man in Go games because the number of paths to make a one move is more than the number of atoms in the universe unlike chess, but the result was the opposite to what people predicted. After the match, artificial intelligence technology was focused as a core technology of the fourth industrial revolution and attracted attentions from various application domains. Especially, deep learning technique have been attracted as a core artificial intelligence technology used in the AlphaGo algorithm.  The deep learning technique is already being applied to many problems. Especially, it shows good performance in image recognition field. In addition, it shows good performance in high dimensional data area such as voice, image and natural language, which was difficult to get good performance using existing machine learning techniques. However, in contrast, it is difficult to find deep leaning researches on traditional business data and structured data analysis. In this study, we tried to find out whether the deep learning techniques have been studied so far can be used not only for the recognition of high dimensional data but also for the binary classification problem of traditional business data analysis such as customer churn analysis, marketing response prediction, and default prediction. And we compare the performance of the deep learning techniques with that of traditional artificial neural network models.  The experimental data in the paper is the telemarketing response data of a bank in Portugal. It has input variables such as age, occupation, loan status, and the number of previous telemarketing and has a binary target variable that records whether the customer intends to open an account or not. In this study, to evaluate the possibility of utilization of deep learning algorithms and techniques in binary classification problem, we compared the performance of various models using CNN, LSTM algorithm and dropout, which are widely used algorithms and techniques in deep learning, with that of MLP models which is a traditional artificial neural network model. However, since all the network design alternatives can not be tested due to the nature of the artificial neural network, the experiment was conducted based on restricted settings on the number of hidden layers, the number of neurons in the hidden layer, the number of output data (filters), and the application conditions of the dropout technique. The F1 Score was used to evaluate the performance of models to show how well the models work to classify the interesting class instead of the overall accuracy.  The detail methods for applying each deep learning technique in the experiment is as follows. The CNN algorithm is a method that reads adjacent values from a specific value and recognizes the features, but it does not matter how close the distance of each business data field is because each field is usually independent. In this experiment, we set the filter size of the CNN algorithm as the number of fields to learn the whole characteristics of the data at once, and added a hidden layer to make decision based on the additional features. For the model having two LSTM layers, the input direction of the second layer is put in reversed position with first layer in order to reduce the influence from the position of each field. In the case of the dropout technique, we set the neurons to disappear with a probability of 0.5 for each hidden layer.  The experimental results show that the predicted model with the highest F1 score was the CNN model using the dropout technique, and the next best model was the MLP model with two hidden layers using the dropout technique. In this study, we were able to get some findings as the experiment had proceeded. First, models using dropout techniques have a"
Malware Classification Possibility based on Sequence Information,2017,"['악성코드 분류', 'LSTM', '시스템 콜', '순서 정보', '길이', 'malware classification', 'system call', 'sequence', 'length']",,
Water Level Forecasting based on Deep Learning : A Use Case of Trinity River-Texas-The United States,2017,"['침수 예측', '딥러닝', 'RNN', 'BPTT', 'LSTM', 'water level forecasting', 'deep learning', 'recurrent neural networks', 'back propagationthrough time', 'long short-term memory']",,
공용 데이터링크 시스템에서 딥러닝 기반 적응형 전력제어 기법,2017,"['Deep learning', 'Adaptive power control', 'Common data link', 'LSTM', 'CNN']",,
장단기 메모리 순환신경망 기반의 비침입적 음성 명료도 추정 방법,2017,"['Deep neural network (DNN)', 'Recurrent neural network (RNN)', 'Long short-term memory (LSTM)', 'Non-Intrusive', 'Speech intelligibility estimation', 'STOI', 'P.563']",,
Evaluation of Recurrent Neural Network Variants for Person Re-identification,2017,"['Person re-identification', 'Multi-shot', 'Recurrent neural network', 'Optimization']",,"Instead of using only spatial features from a single frame for person re-identification, a combination of spatial and temporal factors boosts the performance of the system. A recurrent neural network (RNN) shows its effectiveness in generating highly discriminative sequence-level human representations. In this work, we implement RNN, three Long Short Term Memory (LSTM) network variants, and Gated Recurrent Unit (GRU) on Caffe deep learning framework, and we then conduct experiments to compare performance in terms of size and accuracy for person reidentification. We propose using GRU for the optimized choice as the experimental results show that the GRU achieves the highest accuracy despite having fewer parameters than the others."
다채널 오디오 특징값 및 게이트형 순환 신경망을 사용한 다성 사운드 이벤트 검출,2017,[],,"In this paper, we propose an effective method of applying multichannel-audio feature values to GRNNs (Gated Recurrent Neural Networks) in polyphonic sound event detection. Real life sounds are often overlapped with each other, so that it is difficult to distinguish them by using a mono-channel audio features. In the proposed method, we tried to improve the performance of polyphonic sound event detection by using multi-channel audio features. In addition, we also tried to improve the performance of polyphonic sound event detection by applying a gated recurrent neural network which is simpler than LSTM (Long Short Term Memory), which shows the highest performance among the current recurrent neural networks. The experimental results show that the proposed method achieves better sound event detection performance than other existing methods."
이미지 캡션 생성을 위한 심층 신경망 모델의 설계,2017,"['이미지 캡션 생성', '심층 신경망 모델', '모델 전이', '멀티 모달 순환 신경망', 'Image Caption Generation', 'Deep Neural Network Model', 'Model Transfer', 'Multi-Modal Recurrent Neural Network']",,"In this paper, we propose an effective neural network model for image caption generation and model transfer. This model is a kind of multi-modal recurrent neural network models. It consists of five distinct layers: a convolution neural network layer for extracting visual information from images, an embedding layer for converting each word into a low dimensional feature, a recurrent neural network layer for learning caption sentence structure, and a multi-modal layer for combining visual and language information. In this model, the recurrent neural network layer is constructed by LSTM units, which are well known to be effective for learning and transferring sequence patterns. Moreover, this model has a unique structure in which the output of the convolution neural network layer is linked not only to the input of the initial state of the recurrent neural network layer but also to the input of the multimodal layer, in order to make use of visual information extracted from the image at each recurrent step for generating the corresponding textual caption. Through various comparative experiments using open data sets such as Flickr8k, Flickr30k, and MSCOCO, we demonstrated the proposed multimodal recurrent neural network model has high performance in terms of caption accuracy and model transfer effect."
미국 무역정책 변화가 국내 중공업 기업의 경영성과에 미치는 영향,2017,[],,"Since late 2016, protectionism has been a major trend in world trade with the Great Britain exiting the European Union and the United States electing Donald Trump as the 45th president. Consequently, there has been a huge public outcry regarding the negative prospects of heavy industry firms in Korea, which are highly dependent upon international trade with Western countries including the United States. In light of such trend and concerns, we have tried to predict business performance of heavy industry firms in Korea with data regarding trade policy of the United States. United States International Trade Commission (USITC) levies countervailing duties and anti-dumping duties to firms that violate its fair-trade regulations. In this study, we have performed data analysis with past records of countervailing duties and anti-dumping duties. With results from clustering analysis, it could be concluded that trade policy trends of the Unites States significantly affects the business performance of heavy industry firms in Korea. Furthermore, we have attempted to quantify such effects by employing long short-term memory (LSTM), a popular neural networks model that is well-suited to deal with sequential data. Our major contribution is that we have succeeded in empirically validating the intuitive argument and also predicting the future trend with rigorous data mining techniques. With some improvements, our results are expected to be highly relevant to designing regulations regarding heavy industry in Korea."
Accurate Human Localization for Automatic Labelling of Human from Fisheye Images,2017,"['Human Localization', 'Fisheye Camera', 'CNN (Convolutional Neural Networks)', 'GoogLeNet', 'Long Short Term Memory', 'Saliency Detection']",,"Deep learning networks like Convolutional Neural Networks (CNNs) show successful performances in many computer vision applications such as image classification, object detection, and so on. For implementation of deep learning networks in embedded system with limited processing power and memory, deep learning network may need to be simplified. However, simplified deep learning network cannot learn every possible scene. One realistic strategy for embedded deep learning network is to construct a simplified deep learning network model optimized for the scene images of the installation place. Then, automatic training will be necessitated for commercialization. In this paper, as an intermediate step toward automatic training under fisheye camera environments, we study more precise human localization in fisheye images, and propose an accurate human localization method, Automatic Ground-Truth Labelling Method (AGTLM). AGTLM first localizes candidate human object bounding boxes by utilizing GoogLeNet-LSTM approach, and after reassurance process by GoogLeNet-based CNN network, finally refines them more correctly and precisely(tightly) by applying saliency object detection technique. The performance improvement of the proposed human localization method, AGTLM with respect to accuracy and tightness is shown through several experiments."
