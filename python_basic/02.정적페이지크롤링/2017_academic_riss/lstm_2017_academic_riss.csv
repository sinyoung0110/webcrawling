title,date,keywords,abstract,multilingual_abstract
효율적인 도로 비산먼지 제거 경로 제안을 위한 LSTM 기반 미세먼지 예측,2017,[],"1 급 발암물질인 미세먼지 중 44.3%를 차지하고 있는 도로 비산먼지는 효과적인 미세먼지 농도 저감 대책의 방안 중 하나이다. 도로 비산먼지 제거는 일반적으로 특수 차량을 이용, 정해진 경로와 주기에 따라 운행된다. 이러한 운행방식은 도로의 오염 현황에 따른 효과적 경로 선정 및 운영이 어렵다. 본 논문에서는 도로 비산먼지 제거의 효율적인 경로 제안을 위해 대구지역에 분포된 KISTI 이동형 도시센싱 테스트베드에서 수집되는 고해상도의 실시간 지역별 오염 현황 데이터를 활용하여 실시간 오염도를 분석하고, LSTM(LONG SHORT-TERM MEMORY) 알고리즘을 활용하여 미래의 미세먼지 농도를 예측하였다. 기존 연구와 달리 지역별 상황을 고려한 데이터를 사용하여 선형 회귀 분석을 수행하였다. 실험 결과, 시간 속성을 고려한 LSTM 이 MLP 보다 평균제곱근 오차 값이 경우에 따라 최대 30% 더 작음을 확인했다. 본 연구를 기반으로 고해상도 사물 데이터 기반 예측 연구의 가능성을 보였으며, 미세먼지 예측 결과를 활용 유연하고 효과적인 도로 청소차량의 운행 경로를 설정에 활용될 수 있을 것으로 기대한다.",다국어 초록 정보 없음
자질 보강과 양방향 LSTM-CNN-CRF 기반의 한국어 개체명 인식 모델,2017,"['개체명 인식', '자연어 처리', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Natural Language Processing', 'Deep Learning', 'Feature Augmentation']","개체명 인식(Named Entity Recognition) 시스템은 문서에서 인명(PS), 지명(LC), 단체명(OG)과 같은 개체명을 가지는 단어나 어구를 해당 개체명으로 인식하는 시스템이다. 개체명 인식을 하기위한 전통적인 연구방법으로는 hand-craft된 자질(feature)을 기반으로 모델을 학습하는 통계 기반의 모델이 있다. 최근에는 딥러닝 기반의 RNN(Recurrent Neural Networks), LSTM(Long-short Term Memory)과 같은 모델을 이용하여 문장을 표현하는 자질을 구성하고 이를 개체명 인식과 같이 순서 라벨링(sequence labeling) 문제 해결에 이용한 연구가 제안되었다. 본 연구에서는 한국어 개체명 인식 시스템의 성능 향상을 위해, end-to-end learning 방식이 가능한 딥러닝 기반의 모델에 미리 구축되어 있는 hand-craft된 자질이나 품사 태깅 정보 및 기구축 사전(lexicon) 정보를 추가로 활용하여 자질을 보강(augmentation)하는 방법을 제안한다. 실험 결과 본 논문에서 제안하는 방법에 따라 자질을 보강한 한국어 개체명 인식 시스템의 성능 향상을 확인하였다. 또한 본 연구의 결과를 한국어 자연어처리(NLP) 및 개체명 인식 시스템을 연구하는 연구자들과의 향후 협업 연구를 위해 github를 통해 공개하였다.","The Named Entity Recognition system is a system that recognizes words or phrases with object names such as personal name (PS), place name (LC), and group name (OG) in the document as corresponding object names. Traditional approaches to named entity recognition include statistical-based models that learn models based on hand-crafted features. Recently, it has been proposed to construct the qualities expressing the sentence using models such as deep-learning based Recurrent Neural Networks (RNN) and long-short term memory (LSTM) to solve the problem of sequence labeling. In this research, to improve the performance of the Korean named entity recognition system, we used a hand-crafted feature, part-of-speech tagging information, and pre-built lexicon information to augment features for representing sentence. Experimental results show that the proposed method improves the performance of Korean named entity recognition system. The results of this study are presented through github for future collaborative research with researchers studying Korean Natural Language Processing (NLP) and named entity recognition system."
LSTM기반 반도체 제조 데이터 이상탐지,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM을 활용한 한국어의 문장단위 Grapheme-to-Phoneme 변환 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM을 이용한 sEMG 기반 웨어러블 디바이스 연구,2017,"['surface EMG', 'neural network', 'prediction']",국문 초록 정보 없음,다국어 초록 정보 없음
Skip-Connected LSTM을 이용한 감성 분석,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
RNN LSTM과 ACO를 이용한 감성 분석을 통한 컨텐츠 추천 시스템에 관한 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
문자 단위 단방향 LSTM을 이용한 데이터 중심의 띄어쓰기 오류 교정,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Input Attention 기반 LSTM-CNN 모델을 이용한 Relation Classification,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM 언어모델을 이용한 한국어 자연어 생성 모델,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
PIPs를 이용한 저차원 시계열데이터 분석 및 예측을 위한 LSTM 학습 모델,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
로봇의 서비스 학습을 위한 LSTM 기반의 절차적 텍스트 이해방법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
문자 기반 LSTM CRF를 이용한 한국어 의미역 결정,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
DeepRain: 레이더 데이터를 이용한 강우량 예측 LSTM 네트워크,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
개선된 워드 임베딩 모델과 사전을 이용한 Bidirectional LSTM CRF 기반의 한국어 개체명 인식기,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 모델을 이용한 도로 CCTV 영상의 강수량 판별 방법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
C-LSTM 신경망을 이용한 P2P 소셜대출 채무자 상환예측,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Generative Convolutional-LSTM 신경망 기반의 행동 분류와 새로운 클래스 탐지,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM-CRF Models for Named Entity Recognition,2017,[],국문 초록 정보 없음,"<P>Recurrent neural networks (RNNs) are a powerful model for sequential data. RNNs that use long short-term memory (LSTM) cells have proven effective in handwriting recognition, language modeling, speech recognition, and language comprehension tasks. In this study, we propose LSTM conditional random fields (LSTM-CRF); it is an LSTM-based RNN model that uses output-label dependencies with transition features and a CRF-like sequence-level objective function. We also propose variations to the LSTM-CRF model using a gate recurrent unit (GRU) and structurally constrained recurrent network (SCRN). Empirical results reveal that our proposed models attain state-of-the-art performance for named entity recognition.</P>"
Effective Spectral and Excitation Modeling Techniques for LSTM-RNN-Based Speech Synthesis Systems,2017,[],국문 초록 정보 없음,"<P>In this paper, we report research results on modeling the parameters of an improved time-frequency trajectory excitation (ITFTE) and spectral envelopes of an LPC vocoder with a long short-term memory (LSTM)-based recurrent neural network (RNN) for high-quality text-to-speech (TTS) systems. The ITFTE vocoder has been shown to significantly improve the perceptual quality of statistical parameter-based TTS systems in our prior works. However, a simple feed-forward deep neural network (DNN) with a finite window length is inadequate to capture the time evolution of the ITFTE parameters. We propose to use the LSTM to exploit the time-varying nature of both trajectories of the excitation and filter parameters, where the LSTM is implemented to use the linguistic text input and to predict both ITFTE and LPC parameters holistically. In the case of LPC parameters, we further enhance the generated spectrum by applying LP bandwidth expansion and line spectral frequency-sharpening filters. These filters are not only beneficial for reducing unstable synthesis filter conditions but also advantageous toward minimizing the muffling problem in the generated spectrum. Experimental results have shown that the proposed LSTM-RNN system with the ITFTE vocoder significantly outperforms both similarly configured band aperiodicity-based systems and our best prior DNN-trainecounterpart, both objectively and subjectively.</P>"
RNN과 LSTM을 이용한 주가 예측율 향상을 위한 딥러닝 모델,2017,"['technical analysis', 'fundamental analysis', 'artificial neural network', 'deep neural network', 'RNN', 'LSTM']",국문 초록 정보 없음,"Recently, stock price prediction using deep learning has basically used assistance index as a prediction factors. However assistance index is necessary to examine whether it is suitable as prediction factors because it is subjective viewpoint of researcher. In this study, we examine the suitability as prediction factors with various combinations of existing assistance indexes through the R neural network package, and studied the optimal combinations of assistance indexes and environmental prediction factors like exchange rate, exchange rate moving average, and whole industrial production index in order to improve the prediction rate. In addition, we proposed a deep learning model like DNN, RNN, LSTM which have input-output with extracted prediction factors. As a result, most of the assistance indexes decreased the prediction rate and the prediction rate was improved through additional environmental prediction factors. Also, RNN and LSTM, which are time series deep learning networks, were learned quickly and steadily compared to DNN. Although there is a difference by items, the prediction rate improvement is about 15%."
Named Entity Recognition on Knowledge based query using Bidirectional LSTM-CRF,2017,"['CRF', 'LSTM', 'Named Entity Recognition', 'QA System', 'Ontology']",국문 초록 정보 없음,다국어 초록 정보 없음
Korean Semantic Role Labeling using Stacked Bidirectional LSTM-CRFs,2017,"['의미역 결정', '딥러닝', 'Stacked Bidirectional LSTM-CRFs', 'End-to-end SRL', 'Semantic Role Labeling', 'Deep-learning']",국문 초록 정보 없음,다국어 초록 정보 없음
LSTM모델 기반 전기차용 2단 감속기 유압 예측,2022,"['Hydraulic Pressure(유압)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Long Short Term Memory(장단기 순환신경망)', 'Vehicle Control(차량 제어)']",국문 초록 정보 없음,다국어 초록 정보 없음
LSTM과 LDA를 이용한 자동 유지보수 매뉴얼 생성,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM-RNN 기반 음성합성을 위한 파라미터 생성 알고리즘,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
자유로운 문자열 기반의 사용자 인증을 위한 LSTM기반 이상치 탐지 기법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
K-NNDD by DTW distance를 통한 데이터 클러스터링과 RNN LSTM을 활용한 공정 이상 패턴 분류 모델 제안,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
한국어 음소 단위 LSTM 언어모델을 이용한 문장 생성,2017,"['언어 모델', '순환 신경망 모형', 'LSTM 모형', '문장 생성 모형', 'Language model', 'Recurrent neural network', 'Long short-term memory model', 'Sentence generation model']",국문 초록 정보 없음,"Language models were originally developed for speech recognition and language processing. Using a set of example sentences, a language model predicts the next word or character based on sequential input data. N-gram models have been widely used but this model cannot model the correlation between the input units efficiently since it is a probabilistic model which are based on the frequency of each unit in the training set. Recently, as the deep learning algorithm has been developed, a recurrent neural network (RNN) model and a long short-term memory (LSTM) model have been widely used for the neural language model (Ahn, 2016; Kim et al., 2016; Lee et al., 2016). These models can reflect dependency between the objects that are entered sequentially into the model (Gers and Schmidhuber, 2001; Mikolov et al., 2010; Sundermeyer et al., 2012). In order to learning the neural language model, texts need to be decomposed into words or morphemes. Since, however, a training set of sentences includes a huge number of words or morphemes in general, the size of dictionary is very large and so it increases model complexity. In addition, word-level or morpheme-level models are able to generate vocabularies only which are contained in the training set. Furthermore, with highly morphological languages such as Turkish, Hungarian, Russian, Finnish or Korean, morpheme analyzers have more chance to cause errors in decomposition process (Lankinen et al., 2016).  Therefore, this paper proposes a phoneme-level language model for Korean language based on LSTM models. A phoneme such as a vowel or a consonant is the smallest unit that comprises Korean texts. We construct the language model using three or four LSTM layers. Each model was trained using Stochastic Gradient Algorithm and more advanced optimization algorithms such as Adagrad, RMSprop, Adadelta, Adam, Adamax, and Nadam. Simulation study was done with Old Testament texts using a deep learning package Keras based the Theano. After pre-processing the texts, the dataset included 74 of unique characters including vowels, consonants, and punctuation marks. Then we constructed an input vector with 20 consecutive characters and an output with a following 21st character. Finally, total 1,023,411 sets of input-output vectors were included in the dataset and we divided them into training, validation, testsets with proportion 70:15:15. All the simulation were conducted on a system equipped with an Intel Xeon CPU (16 cores) and a NVIDIA GeForce GTX 1080 GPU.  We compared the loss function evaluated for the validation set, the perplexity evaluated for the test set, and the time to be taken for training each model. As a result, all the optimization algorithms but the stochastic gradient algorithm showed similar validation loss and perplexity, which are clearly superior to those of the stochastic gradient algorithm. The stochastic gradient algorithm took the longest time to be trained for both 3- and 4-LSTM models. On average, the 4-LSTM layer model took 69% longer training time than the 3-LSTM layer model. However, the validation loss and perplexity were not improved significantly or became even worse for specific conditions. On the other hand, when comparing the automatically generated sentences, the 4-LSTM layer model tended to generate the sentences which are closer to the natural language than the 3-LSTM model. Although there were slight differences in the completeness of the generated sentences between the models, the sentence generation performance was quite satisfactory in any simulation conditions: they generated only legitimate Korean letters and the use of postposition and the conjugation of verbs were almost perfect in the sense of grammar. The results of this study are expected to be widely used for the processing of Korean language in the field of language processing and speech recognition, which are the basis of artificial intelligence systems."
LSTM 모델 기반 주행 모드 인식을 통한 자율 주행에 관한 연구,2017,"['자율주행', '주행모드', '딥러닝', 'RNN', 'LSTM', 'autonomous driving', 'maneuvering modes', 'deep learning', 'RNN', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
LSTM 기반 Model-Free LKAS 조향 각 생성,2017,"['Long Short-Term Memory (LSTM)', 'Recurrent Neural Network (RNN)', 'steering angle prediction', 'Lane Kepping Assistance System (LKAS)']",국문 초록 정보 없음,"In this paper, we propose a lateral upper controller that predicts vehicle motion and generates a model-free LKAS steering angle by applying long-term memory (LSTM), one of the deep learning techniques. The apparent and distinct advantage of this LSTM model is that the relationship of nonlinear sensor data can be grasped and learned devoid of a mathematical model while using the time information. In this sense, the LKAS steering angle can be generated by predicting the movement of the vehicle in consideration of the past vehicle motion based on the sensor data. In addition, the time delay problem due to the difference of sampling time on each sensor can be simply solved by learning based on a time table which has a synchronized sampling time. The input values of the upper controller are the coefficient of the road model and the vehicle dynamic characteristics are obtained from the image processing data from the camera sensor. As for the target values, the steering angles in the next state are selected. The learning model was developed by learning the many-to-one LSTM prediction model with serial connection of LSTM and Fully-Connected (FC) Multilayer Perceptron (MLP). For implementation of the learning model, Tensorflow is employed and the data from a real test road was used. With this model, the learning is conducted and its effectiveness is shown by comparing with a LKAS lateral controller using a model-based multi rate Kalman Filter (MKF)."
LSTM 네트워크를 이용한 운전자 지원 시스템,2017,"['ADAS(첨단 운전자 지원 시스템)', 'TORCS(레이싱 시뮬레이터)', 'LSTM', 'driving performance(주행 성능)']",국문 초록 정보 없음,This paper proposes an advanced driver assistance system (ADAS) that provides drivers with useful information using a long short-term memory (LSTM) network. The ADAS predicts road events in order to improve driving performance using range finder sensors. We show the effectiveness of the proposed system through the experiment using the open racing car simulator (TORCS).
CTC를 이용한 LSTM RNN 기반 한국어 음성인식 시스템,2017,"['Connectionist temporal classification', 'Long short term memory', 'Recurrent neural network', 'Acoustic model', 'Speech recognition', '음향모델', '음성인식']",국문 초록 정보 없음,"A hybrid approach using Long Short Term Memory (LSTM) Recurrent Neural Network (RNN) has showed great improvement in speech recognition accuracy. For training acoustic model based on hybrid approach, it requires forced alignment of HMM state sequence from Gaussian Mixture Model (GMM)-Hidden Markov Model (HMM). However, high computation time for training GMM-HMM is required. This paper proposes an end-to-end approach for LSTM RNN-based Korean speech recognition to improve learning speed. A Connectionist Temporal Classification (CTC) algorithm is proposed to implement this approach. The proposed method showed almost equal performance in recognition rate, while the learning speed is 1.27 times faster."
One-Hot LSTM Pooling with IDF Attention for Information Filtering,2017,"['Information filtering', 'one-hot lstm', 'idf attention']",국문 초록 정보 없음,다국어 초록 정보 없음
Expansion of Word Representation for Named Entity Recognition Based on Bidirectional LSTM CRFs,2017,"['개체명 인식', '단어 표상', '음절', 'bi-LSTM-CRFs', 'Named Entity Recognition', 'Word Representation', 'Syllable']",국문 초록 정보 없음,다국어 초록 정보 없음
비정형 자연어 음성인식을 위한 LSTM 기반 래티스 리스코링 기술,2017,"['Speech Recognition(음성인식)', 'Lattice Rescoring(래티스 리스코링)']",국문 초록 정보 없음,다국어 초록 정보 없음
원거리 음성인식용 DNN-LSTM acoustic model 성능비교연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
딥 러닝을 이용한 부동산가격지수 예측,2017,"['딥 러닝', '부동산가격지수', '예측', 'DNN', 'LSTM', 'deep learning', 'real estate price index', 'predicting', 'DNN', 'LSTM']","본 연구의 목적은 딥 러닝 방법을 부동산가격지수 예측에 적용해보고, 기존의 시계열분석 방법과의 비교를 통해 부동산 시장 예측의 새로운 방법으로서 활용가능성을 확인하는 것이다. 딥 러닝(deep learning)방법인 DNN(Deep Neural Networks)모형 및 LSTM(Long Shot Term Memory networks)모형과 시계열분석 방법인 ARIMA(autoregressive integrated moving average)모형을 이용하여 여러 가지 부동산가격지수에 대한 예측을 시도하였다. 연구결과 첫째, 딥 러닝 방법의 예측력이 시계열분석 방법보다 우수한 것으로 나타났다. 둘째, 딥 러닝 방법 중에서는 DNN모형의 예측력이 LSTM모형의 예측력보다 우수하나 그 정도는 미미한 수준인 것으로 나타났다. 셋째, 딥 러닝 방법과 ARIMA모형은 부동산 가격지수(real estate price index) 중 아파트 실거래가격지수(housing sales price index)에 대한 예측력이 가장 부족한 것으로 나타났다. 향후 딥 러닝 방법을 활용함으로써 부동산 시장에 대한 예측의 정확성을 제고할 수 있을 것으로 기대된다.","The purpose of this study was to apply the deep running method to real estate price index predicting and to compare it with the time series analysis method to test the possibility of its application to real estate market forecasting. Various real estate price indices were predicted using the DNN (deep neural networks) and LSTM (long short term memory networks) models, both of which draw on the deep learning method, and the ARIMA (autoregressive integrated moving average) model, which is based on the time seies analysis method. The results of the study showed the following. First, the predictive power of the deep learning method is superior to that of the time series analysis method. Second, among the deep learning models, the predictability of the DNN model is slightly superior to that of the LSTM model. Third, the deep learning method and the ARIMA model are the least reliable tools for predicting the housing sales prices index among the real estate price indices. Drawing on the deep learning method, it is hoped that this study will help enhance the accuracy in predicting the real estate market dynamics."
특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델,2017,"['Machine learning', 'Deep learning', 'Artificial neural network', 'Power Electric demand prediction', 'LSTM']",국문 초록 정보 없음,"This study analyze correlation between weekdays data and special days data of different power demand patterns, and builds a separate data set, and suggests ways to reduce power demand prediction error by using deep learning network suitable for each data set. In addition, we propose a method to improve the prediction rate by adding the environmental elements and the separating element to the meteorological element, which is a basic power demand prediction elements. The entire data predicted power demand using LSTM which is suitable for learning time series data, and the special day data predicted power demand using DNN. The experiment result show that the prediction rate is improved by adding prediction elements other than meteorological elements. The average RMSE of the entire dataset was 0.2597 for LSTM and 0.5474 for DNN, indicating that the LSTM showed a good prediction rate. The average RMSE of the special day data set was 0.2201 for DNN, indicating that the DNN had better prediction than LSTM. The MAPE of the LSTM of the whole data set was 2.74% and the MAPE of the special day was 3.07 %."
기술 용어에 대한 한국어 정의 문장 자동 생성을 위한 순환 신경망 모델 활용 연구,2017,"['Sentence Generation', 'Text Generation', 'Natural Language Generation(NLG)', 'Automatic Report Generation', 'Deep Learning', '문장 생성', '텍스트 생성', '자연어 생성', '보고서 자동 생성', '딥 러닝']","본 논문에서는 지속적으로 커져가는 산업․시장에 대해 관련 연구자들이 이를 효율적으로 분석할 수 있는 반자동 지원 체제 개발을 위한 기술 용어와 기술 개념에 대한 정의문 및 설명문을 자동으로 생성하는 한국어 문장 생성 모델을 제시한다. 한국어 정의 문장 생성을 위하여 딥러닝 기술 중 데이터의 전/후 관계를 포함한 시퀀스 레이블링이 가능한 LSTM을 활용한다. LSTM을 근간으로 한 두 가지 모델은 기술명을 입력할 시 그에 대한 정의문 및 설명문을 생성한다. 다양하게 수집된 대규모 학습 말뭉치를 이용해 실험한 결과, 본 논문에서 구현한 2가지 모델 중 CNN 음절 임베딩을 활용한 어절 단위 LSTM 모델이 용어에 대한 정의문 및 설명문을 생성하는데 더 나은 결과를 도출시킨다는 사실을 확인하였다. 본 논문의 연구 결과를 바탕으로 동일한 주제를 다루는 문장 집합을 생성할 수 있는 확장 모델을 개발할 수 있으며 더 나아가서는 기술에 대한 문헌을 자동으로 작성하는 인공지능 모델을 구현할 수 있으리라 사료된다.","In order to develop a semiautomatic support system that allows researchers concerned to efficiently analyze the technical trends for the ever-growing industry and market. This paper introduces a couple of Korean sentence generation models that can automatically generate definitional statements as well as descriptions of technical terms and concepts. The proposed models are based on a deep learning model called LSTM (Long Sort-Term Memory) capable of effectively labeling textual sequences by taking into account the contextual relations of each item in the sequences. Our models take technical terms as inputs and can generate a broad range of heterogeneous textual descriptions that explain the concept of the terms. In the experiments using large-scale training collections, we confirmed that more accurate and reasonable sentences can be generated by CHAR-CNN-LSTM model that is a word-based LSTM exploiting character embeddings based on convolutional neural networks (CNN). The results of this study can be a force for developing an extension model that can generate a set of sentences covering the same subjects, and furthermore, we can implement an artificial intelligence model that automatically creates technical literature."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",다국어 초록 정보 없음
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",국문 초록 정보 없음,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
뜰개 이동 예측을 위한 신경망 및 통계 기반 기계학습 기법의 성능 비교,2017,"['유류 유출', '뜰개', '기계학습', '순환신경망', '예측', 'Oil Spill', 'Drifter', 'Machine learning', 'Recurrent neural network', 'LSTM', 'Prediction']","뜰개는 해양에서 해수의 특성 및 흐름을 관측하기 위한 장비로서, 해수의 흐름 관측을 이용해 유출유 확산 예측을 위해 사용될 수 있다. 본 논문에서는 관측기관에서 사용하는 뜰개가 특정 시간 간격으로 관측한 바람 및 해수의 특성과 이동경로를 기계학습 기법들을 이용하여 학습시키고 예측하는 모델을 제안한다. 서포트벡터 회귀, 방사기저함수 네트워크, 가우시안 프로세스, 다층 퍼셉트론, 순환신경망을 이용하여 뜰개의 이동경로 예측 방법을 제시한다. 기존 MOHID 수치모델과 비교하여 각 기법별로 4 개의 사례중 3 개에서 성능이 개선되었으며, 가장 좋은 개선율을 보인 기법은 LSTM으로 평균 47.59% 개선되었다. 추후 연구에서는 배깅과 부스팅을 이용하여 가중치를 부여하여 정확도를 개선할 예정이다.","Drifter is an equipment for observing the characteristics of seawater in the ocean, and it can be used to predict effluent oil diffusion and to observe ocean currents. In this paper, we design models or the prediction of drifter trajectory using machine learning. We propose methods for estimating the trajectory of drifter using support vector regression, radial basis function network, Gaussian process, multilayer perceptron, and recurrent neural network. When the propose mothods were compared with the existing MOHID numerical model, performance was improve on three of the four cases. In particular, LSTM, the best performed method, showed the imporvement by 47.59% Future work will improve the accuracy by weighting using bagging and boosting."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",국문 초록 정보 없음,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM's. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Long Short Term Memory based Political Polarity Analysis in Cyber Public Sphere,2017,"['Long short term memory (LSTM)', 'Word embedding', 'Recurrent neural network (RNN)', 'Softmax function']",국문 초록 정보 없음,"In this paper, we applied long short term memory(LSTM) for classifying political polarity in cyber public sphere. The data collected from the cyber public sphere is transformed into word corpus data through word embedding. Based on this word corpus data, we train recurrent neural network (RNN) which is connected by LSTM’s. Softmax function is applied at the output of the RNN. We conducted our proposed system to obtain experimental results, and we will enhance our proposed system by refining LSTM in our system."
Recurrent Neural Networks를 활용한 Baltic Dry Index (BDI) 예측,2017,"['장단기 메모리', '순환형 신경망', '건화물운임지수', '인공신경망', '시계열 분석', 'Long Short-Term Memory', 'Recurrent Neural Networks', 'BDI (Baltic Dry Index)', 'Artificial Neural Networks', 'Time-Series Analysis']",장기 해운불황에 따라 불확실성이 증폭되고 있는 상황에서 경기추세의 이해뿐만 아니라 예측 또한 중요해지고 있는 실정이다. 본 논문에서는 최근 특정 복잡한 문제에 대해서 각광받고 있는 인공신경망을 적용하여 BDI 예측을 연구하였다. 사용된 인공신경망은 순환신경망으로 RNN과 LSTM 그리고 비교의 목적으로 MLP를 통해 2009.04.01.부터 2017.07.31.의 기간을 대상으로 연구를 진행하였다. 또한 전통적 시계열 예측방법론인 ARIMA 분석을 실시해 인공신경망들의 예측성능과 비교하였다. 결과로 순환신경망인 RNN의 성능이 가장 뛰어났으며 LSTM의 특정 시계열(BDI)에의 적용가능성을 확인할 수 있었다.,"Not only growth of importance to understanding economic trends, but also the prediction to overcome the uncertainty is coming up for long-term maritime recession. This paper discussed about the prediction of BDI with artificial neural networks (ANN). ANN is one of emerging applications that can be the finest solution to the knotty problems that may not easy to achieve by humankind. Proposed a prediction by implementing neural networks that have recurrent architecture which are a Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). And for the reason of comparison, trained Multi Layer Perceptron (MLP) from 2009.04.01 to 2017.07.31. Also made a comparison with conventional statistics, prediction tools; ARIMA. As a result, recurrent net, especially RNN outperformed and also could discover the applicability of LSTM to specific time-series (BDI)."
Large-Scale Text Classification with Deep Neural Networks,2017,"['deep learning', 'large-scale text classification', 'natural language processing', 'artificial neural networks', '딥러닝', '대용량 문서 분류', '자연어 처리', '인공신경망']",국문 초록 정보 없음,"The classification problem in the field of Natural Language Processing has been studied for a long time. Continuing forward with our previous research, which classifies large-scale text using Convolutional Neural Networks (CNN), we implemented Recurrent Neural Networks (RNN), Long- Short Term Memory (LSTM) and Gated Recurrent Units (GRU). The experiment’s result revealed that the performance of classification algorithms was Multinomial Naïve Bayesian Classifier < Support Vector Machine (SVM) < LSTM < CNN < GRU, in order. The result can be interpreted as follows: First, the result of CNN was better than LSTM. Therefore, the text classification problem might be related more to feature extraction problem than to natural language understanding problems. Second, judging from the results the GRU showed better performance in feature extraction than LSTM. Finally, the result that the GRU was better than CNN implies that text classification algorithms should consider feature extraction and sequential information. We presented the results of fine-tuning in deep neural networks to provide some intuition regard natural language processing to future researchers."
Neural Network 기반 악기 보조 시스템,2017,[],"현재 초보적인 능력을 가진 악기 연주자가 접근할 수 있는 하드웨어, 소프트웨어를 사용해 악기 연주법을 연습할 수 있는 수단은 전무하다. 따라서 본 논문은 악기 연주자가 연습을 하기 위해 사용할 수 있는 음 인식과 악보 정보의 처리, LSTM을 통한 자동 악보 생성의 복합적 기능을 가진 악기 보조 시스템을 제안한다. 또한 본 시스템은 기존의 FFT와 같은 일반적인 Pitch Detection 알고리즘보다 더 우월한 음 인식 성능을 보유한 Autocorrelation 전처리를 거친 LeNet-5 Convolutional Neural Network 모델을 사용하여 음 인식 성능을 높이는 기법을 제안한다. 이 음 인식 모델은 실험 결과 기존의 음 인식 기법보다 최대 약 5.4%의 성능 증가를 이루어냈다.",다국어 초록 정보 없음
글로벌 라이프로그 미디어 클라우드 개발 및 구축,2017,[],"글로벌 라이프로그 미디어 클라우드 서비스를 위하여 네트워크 기술, 클라우드 기술 멀티미디어 App 기술 및 하이라이팅 엔진 기술이 요구된다. 본 논문에서는 미디어 클라우드 서비스를 위한 개발 기술 및 서비스 기술 개발 결과를 보였다. 하이라이팅 엔진은 표정인식기술, 이미지 분류기술, 주목도 지도 생성기술, 모션 분석기술, 동영상 분석 기술, 얼굴 인식 기술 및 오디오 분석기술 등을 포함하고 있다. 표정인식기술로는 Alexnet을 최적화하여 Alexnet 대비 1.82% 우수한 인식 성능을 보였으며 처리속도면에서 28배 빠른 결과를 보였다. 행동 인식 기술에 있어서는 기존 2D CNN 및 LSTM에 기반한 인식 방법에 비하여 제안하는 3D CNN 기법이 0.8% 향상된 결과를 보였다. ㈜판도라티비는 클라우드 기반 라이프로그 동영상 생성 서비스를 개발하여 현재 테스트 서비스를 진행하고 있다.",다국어 초록 정보 없음
Nonintrusive Load Monitoring Based on Advanced Deep Learning and Novel Signature,2017,[],국문 초록 정보 없음,"<P>Monitoring electricity consumption in the home is an important way to help reduce energy usage. Nonintrusive Load Monitoring (NILM) is existing technique which helps us monitor electricity consumption effectively and costly. NILM is a promising approach to obtain estimates of the electrical power consumption of individual appliances from aggregate measurements of voltage and/or current in the distribution system. Among the previous studies, Hidden Markov Model (HMM) based models have been studied very much. However, increasing appliances, multistate of appliances, and similar power consumption of appliances are three big issues in NILM recently. In this paper, we address these problems through providing our contributions as follows. First, we proposed state-of-the-art energy disaggregation based on Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) model and additional advanced deep learning. Second, we proposed a novel signature to improve classification performance of the proposed model in multistate appliance case. We applied the proposed model on two datasets such as UK-DALE and REDD. Via our experimental results, we have confirmed that our model outperforms the advanced model. Thus, we show that our combination between advanced deep learning and novel signature can be a robust solution to overcome NILM's issues and improve the performance of load identification.</P>"
A Study of Efficiency Information Filtering System using One-Hot Long Short-Term Memory,2017,"['information filtering system', 'spam filtering', 'region embedding', 'term weighting.']",국문 초록 정보 없음,"In this paper, we propose an extended method of one-hot Long Short-Term Memory (LSTM)  and evaluate the performance on spam filtering task. Most of traditional methods proposed for spam filtering  task use word occurrences to represent spam or non-spam messages and all syntactic and semantic  information are ignored. Major issue appears when both spam and non-spam messages share many common  words and noise words. Therefore, it becomes challenging to the system to filter correct labels between  spam and non-spam. Unlike previous studies on information filtering task, instead of using only word  occurrence and word context as in probabilistic models, we apply a neural network-based approach to train the  system filter for a better performance. In addition to one-hot representation, using term weight with attention  mechanism allows classifier to focus on potential words which most likely appear in spam and non-spam  collection. As a result, we obtained some improvement over the performances of the previous methods. We  find out using region embedding and pooling features on the top of LSTM along with attention mechanism  allows system to explore a better document representation for filtering task in general."
Long short-term memory recurrent neural network-based acoustic model using connectionist temporal classification on a large-scale training corpus,2017,[],국문 초록 정보 없음,"<P>A Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) has driven tremendous improvements on an acoustic model based on Gaussian Mixture Model (GMM). However, these models based on a hybrid method require a forced aligned Hidden Markov Model (HMM) state sequence obtained from the GMM-based acoustic model. Therefore, it requires a long computation time for training both the GMM-based acoustic model and a deep learning-based acoustic model. In order to solve this problem, an acoustic model using CTC algorithm is proposed. CTC algorithm does not require the GMM-based acoustic model because it does not use the forced aligned HMM state sequence. However, previous works on a LSTM RNN-based acoustic model using CTC used a small-scale training corpus. In this paper, the LSTM RNN-based acoustic model using CTC is trained on a large-scale training corpus and its performance is evaluated. The implemented acoustic model has a performance of 6.18% and 15.01% in terms of Word Error Rate (WER) for clean speech and noisy speech, respectively. This is similar to a performance of the acoustic model based on the hybrid method.</P>"
Continuous Timescale Long-Short Term Memory Neural Network for Human Intent Understanding,2017,"['continuous timescale', 'recurrent neural network', 'LSTM', 'classification', 'dynamic sequence']",국문 초록 정보 없음,"<P>Understanding of human intention by observing a series of human actions has been a challenging task. In order to do so, we need to analyze longer sequences of human actions related with intentions and extract the context from the dynamic features. The multiple timescales recurrent neural network (MTRNN) model, which is believed to be a kind of solution, is a useful tool for recording and regenerating a continuous signal for dynamic tasks. However, the conventional MTRNN suffers from the vanishing gradient problem which renders it impossible to be used for longer sequence understanding. To address this problem, we propose a new model named Continuous Timescale Long-Short Term Memory (CTLSTM) in which we inherit the multiple timescales concept into the Long-Short Term Memory (LSTM) recurrent neural network (RNN) that addresses the vanishing gradient problem. We design an additional recurrent connection in the LSTM cell outputs to produce a time-delay in order to capture the slow context. Our experiments show that the proposed model exhibits better context modeling ability and captures the dynamic features on multiple large dataset classification tasks. The results illustrate that the multiple timescales concept enhances the ability of our model to handle longer sequences related with human intentions and hence proving to be more suitable for complex tasks, such as intention recognition.</P>"
360 영상으로부터 텍스트 정보를 이용한 자연스러운 사진 생성,2017,"['360 영상', '딥러닝', '자연어 처리', 'LSTM', '구도평가', '360 image', 'deep learning', 'natural language processing', 'photo composition']","360 영상은 상하좌우 모든 영역에 대한 정보를 갖고 있기 때문에 종종 지나치게 많은 정보를 포함하게 된다. 또한 360 영상의 내용을 2D 모니터를 이용하여 확인하기 위해서는 마우스를 이용하여 360 영상을 돌려 봐야 하거나, 또는 심하게 왜곡된 2D 영상으로 변환해서 봐야 하는 문제가 있다. 따라서 360 영상에서 사용자가 원하는 물체를 찾는 것은 상당히 까다로운 일이 될 수 있다. 본 논문은 물체나 영역을 묘사하는 문장이 주어졌을 때, 360 영상 내에서 문장과 가장 잘 어울리는 영상을 추출해내는 방법을 제시한다. 본 논문에서 제시한 방법은 주어진 문장 뿐 아니라 구도 역시 고려하여 구도 면에서도 보기 좋은 결과 영상을 생성한다. 본 논문에서 제시하는 방법은 우선 360 영상을 2D 큐브맵으로 변환한다. 일반적인 큐브맵은 큐브맵의 경계 부분에 걸쳐 있는 물체가 있을 경우, 이를 검출하기 어려운 문제가 있다. 따라서 더 정확한 물체 검출을 위해 본 논문에서는 변형된 큐브맵을 제시한다. 이렇게 변형된 큐브맵에 Long Short Term Memory (LSTM) 네트워크 기반의 자연어 문장을 이용한 물체 검출 방법을 적용한다. 최종적으로 원래의 360영상에서 검출된 영역을 포함하면서도 영상 구도 면에서 보기 좋은 영역을 찾아서 결과 영상을 생성한다.","As a 360-degree image carries information of all directions, it often has too much information. Moreover, in order to investigate a 360-degree image on a 2D display, a user has to either click and drag the image with a mouse, or project it to a 2D panorama image, which inevitably introduces severe distortions. In consequence, investigating a 360-degree image and finding an object of interest in such a 360-degree image could be a tedious task. To resolve this issue, this paper proposes a method to find a region of interest and produces a 2D naturally looking image from a given 360-degree image that best matches a description given by a user in a natural language sentence. Our method also considers photo composition so that the resulting image is aesthetically pleasing. Our method first converts a 360-degree image to a 2D cubemap. As objects in a 360-degree image may appear distorted or split into multiple pieces in a typical cubemap, leading to failure of detection of such objects, we introduce a modified cubemap. Then our method applies a Long Short Term Memory (LSTM) network based object detection method to find a region of interest with a given natural language sentence. Finally, our method produces an image that contains the detected region, and also has aesthetically pleasing composition."
AWS 사물 인터넷 환경에서 딥러닝을 이용한 시계열 센서 데이터의 실시간 예측 서비스 아키텍처,2017,"['아마존 웹서비스', '사물인터넷', '딥러닝', 'LSTM', '순환형 신경망', 'AWS', 'IoT', 'Deep Learning', 'LSTM', 'RNN']",국문 초록 정보 없음,"With the advent of Internet of Things (IoT), the use of various devices connected to Internet has generated a large amount of data, and the importance of big data analysis has rapidly been increasing. In particular, it is necessary to analyze various IoT data generated in real-time and to provide various services through new meaningful future prediction analysis. Therefore, this paper presents the direction of Amazon Web Service (AWS) for real-time prediction service in IoT environment. Also, in this paper, we propose an architecture in AWS IoT environment for analyzing sensor data such as power, temperature, humidity, wind speed, and so on, received from IoT devices using recurrent neural networks (RNN) suitable for time series data among various algorithms, and providing users with necessary services using prediction data. The proposed architecture extracts new information from the time series IoT data and can create new business value by applying real-time IoT service to sports, cultural contents, and so on as well as real-time prediction model."
커널 모델과 장단기 기억 신경망을 결합한 보컬 및 비보컬 분리,2017,[],"본 논문에서는 커널 모델과 장단기 기억(Long-Short Term Memory, LSTM) 신경망을 결합한 보컬 및 비보컬 분리 방식을 제안한다. 기존의 음원 분리 방식은 비보컬 음원만 있는 구간에서 음원을 오추정하여 불필요한 비보컬 음원을 출력하는 한계가 있다. 따라서 본 논문에서는 커널 모델 기반의 보컬음 분리 방식에 LSTM 신경망 기반의 보컬 구간 분류 방식을 결합하여 보컬 음원의 오추정 문제를 개선하고 분리 성능을 향상시키고자 하였다. 또한 본 논문에서는 방식간의 결합 구조에 따라 병렬 결합형 분리 알고리즘과 직렬 결합형 분리 알고리즘을 제안하였으며, 실험을 통해 제안하는 방식들이 기존의 방식에 비해 더욱 향상된 분리 성능을 보이는 것을 확인할 수 있었다.",다국어 초록 정보 없음
Deep Learning : CNN과 RNN을 중심으로,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Study of Efficiency Information Filtering System using One-Hot Long Short-Term Memory,2017,"['information filtering system', 'spam filtering', 'region embedding', 'term weighting.']",국문 초록 정보 없음,"In this paper, we propose an extended method of one-hot Long Short-Term Memory (LSTM) and evaluate the performance on spam filtering task. Most of traditional methods proposed for spam filtering task use word occurrences to represent spam or non-spam messages and all syntactic and semantic information are ignored. Major issue appears when both spam and non-spam messages share many common words and noise words. Therefore, it becomes challenging to the system to filter correct labels between spam and non-spam. Unlike previous studies on information filtering task, instead of using only word occurrence and word context as in probabilistic models, we apply a neural network-based approach to train the system filter for a better performance. In addition to one-hot representation, using term weight with attention mechanism allows classifier to focus on potential words which most likely appear in spam and non-spam collection. As a result, we obtained some improvement over the performances of the previous methods. We find out using region embedding and pooling features on the top of LSTM along with attention mechanism allows system to explore a better document representation for filtering task in general."
A Study of Efficiency Information Filtering System using One-Hot Long Short-Term Memory,2017,"['information filtering system', 'spam filtering', 'region embedding', 'term weighting']",국문 초록 정보 없음,"In this paper, we propose an extended method of one-hot Long Short-Term Memory (LSTM) and evaluate the performance on spam filtering task. Most of traditional methods proposed for spam filtering task use word occurrences to represent spam or non-spam messages and all syntactic and semantic information are ignored. Major issue appears when both spam and non-spam messages share many common words and noise words. Therefore, it becomes challenging to the system to filter correct labels between spam and non-spam. Unlike previous studies on information filtering task, instead of using only word occurrence and word context as in probabilistic models, we apply a neural network-based approach to train the system filter for a better performance. In addition to one-hot representation, using term weight with attention mechanism allows classifier to focus on potential words which most likely appear in spam and non-spam collection. As a result, we obtained some improvement over the performances of the previous methods. We find out using region embedding and pooling features on the top of LSTM along with attention mechanism allows system to explore a better document representation for filtering task in general."
전자상거래 추천시스템을 위한 순환신경망 알고리즘들의 성능평가,2017,"['전자상거래', '추천시스템', '머신러닝', '순환신경망', '최적화 알고리즘', '텐서플로우', 'e-commerce', 'recommendation system', 'machine learning', 'recurrent neural network', 'optimization algorithm', 'TensorFlow']","전자상거래 발전에 따라 온라인 쇼핑을 이용하는 사람들이 증가하였고 제품 또한 다양해지고 있다. 이러한 추세로 구매자가 만족할 수 있는 정확한 추천시스템의 중요성이 증대되었으며 정확도를 높이기 위한 새로운 방법의 연구가 계속되고 있다. 순환신경망은 시퀀스 학습에 적합한 딥 러닝 방법 중 하나이며 본 연구에서는 추천시스템의 정확도를 높이는 방법으로 구매자의 제품 접근순서를 순환신경망에 적용하여 알고리즘 성능평가를 하였다. 알고리즘 성능평가에는 대표적인 순환신경망 알고리즘과 최적화 알고리즘으로 진행하였다. 순환신경망 알고리즘으로는 RNN, LSTM, GRU 그리고 최적화 알고리즘으로는 Adagrad, RMSProp, Adam optimizer를 사용하였다. 실험 도구로는 구글의 오픈소스 라이브러리인 텐서플로우를 사용하였고 데이터는 RecSys Challenge 2015에서 제공하는 e-commerce session 데이터를 활용하였다. 실험 결과 실험 데이터에 적합한 최적의 하이퍼파라미터를 발굴하고 적용하여 RecSys Challenge 2015 참가자들의 결과와 비교하였다. 상품 접근 순서만을 학습시킨 결과이기 때문에 등수가 높지는 않았지만 기존 추천시스템에 접목한다면 정확도 향상에 기여할 수 있을 것으로 보인다.","Due to the advance of e-commerce systems, the number of people using online shopping and products has significantly increased. Therefore, the need for an accurate recommendation system is becoming increasingly more important. Recurrent neural network is a deep-learning algorithm that utilizes sequential information in training. In this paper, an evaluation is performed on the application of recurrent neural networks to recommendation systems. We evaluated three recurrent algorithms (RNN, LSTM and GRU) and three optimal algorithms(Adagrad, RMSProp and Adam) which are commonly used. In the experiments, we used the TensorFlow open source library produced by Google and e-commerce session data from RecSys Challenge 2015. The results using the optimal hyper-parameters found in this study are compared with those of RecSys Challenge 2015 participants."
Preliminary Study of Deep Learning-based Precipitation Prediction,2017,"['Deep Learning', 'Global Navigation Satellite System', 'Precipitable Water Vapor', 'Meteorological Factors', 'Precipitation Prediction']",국문 초록 정보 없음,"Recently, data analysis research has been carried out using the deep learning technique in various fields such as image interpretation and/or classification. Various types of algorithms are being developed for many applications. In this paper, we propose a precipitation prediction algorithm based on deep learning with high accuracy in order to take care of the possible severe damage caused by climate change. Since the geographical and seasonal characteristics of Korea are clearly distinct, the meteorological factors have repetitive patterns in a time series. Since the LSTM (Long Short-Term Memory) is a powerful algorithm for consecutive data, it was used to predict precipitation in this study. For the numerical test, we calculated the PWV (Precipitable Water Vapor) based on the tropospheric delay of the GNSS (Global Navigation Satellite System) signals, and then applied the deep learning technique to the precipitation prediction. The GNSS data was processed by scientific software with the troposphere model of Saastamoinen and the Niell mapping function. The RMSE (Root Mean Squared Error) of the precipitation prediction based on LSTM performs better than that of ANN (Artificial Neural Network). By adding GNSS-based PWV as a feature, the over-fitting that is a latent problem of deep learning was prevented considerably as discussed in this study."
Word2vec을 활용한 RNN기반의 문서 분류에 관한 연구,2017,"['Text Mining', 'Information Retrieval', 'Deep Learning', 'DocumenCt lassification', '텍스트 마이닝', '정보검색', '딥 러닝', '문서분류']","자연어 처리 분야에서도 심층 신경망 기술이 주목되고 있으며, 최근에는 convolutional neural network (CNN)기반의 심층신경망 구조가 이미지 분류뿐만 아니라 자연어 처리의 문서 분류에서도 좋은 성능이 입증되었다. 하지만 convolutional neural network (CNN)을 이용한 문서 분류 연구에서는 문장의 평균 단어 수가 16개로 이루어진 짧은 문장에 한하여 적용되었으며, 구문 전체와 의미론적 관계가 복잡한 전체 문장을 다루기 어렵다는 단점을 가지고 있다. 본 논문은 기존 연구의 한계점을극복하고 더 정확한 문서 분류 성능을 위하여 word2vec를 활용한 recurrent neural network (RNN)기반의 심층 신경망의접근법을 새롭게 제안한다. 이를 위해 장기 의존성 문제를 해결한 long short-term memory (LSTM)을 사용하여 긴 시퀀스의입력에서도 효과적인 문서 분류가 가능하도록 하였고, 제안 방식의 효율성을 검증하기 위해 영문 데이터 뿐 아니라 한국어영화 리뷰 데이터에 대해서도 실험을 수행하였다. 그 결과 장문을 포함하고 있는 영문 신문 기사에서는 87%, 단문으로구성된 영문 영화 리뷰 문서에서는 90%, 한국어 영화 리뷰에서는 88%의 문서 분류 정확도를 보였다","Deep neural network based methods have obtained remarkable progress on natural language processing (NLP) task. Recently, convolutional neural network (CNN) based approaches often outperform not only in image classification, but also in document classification. However, convolutional neural network (CNN) based methods is applied only to a short sentence composed of 16 words in average, and it has a disadvantage that it is difficult to deal with a sentence having a complicated semantic relationship with the whole sentence. In this paper, we propose a new method based on recurrent neural network (RNN) using word2vec to overcome the limitations of previous related work and to get much higher accuracy of document classification. By using long short-term memory (LSTM) to solve the long-term dependency problem, effective document classification is also possible for long sequence input. To validate performance of our proposed method in various data, we tested our proposed method both with English sentence and Korean movie review dataset. As a result, 87% of the English newspaper articles containing the long texts, 90% of the English movie review and 88% of the Korean movie reviewsh owed the accuracy of document classification"
딥러닝 기반의 다범주 감성분석 모델 개발,2017,"['Sentiment Analysis', 'Convolutional Neural Networks', 'Long Short-Term Memory', 'Word2vec']",국문 초록 정보 없음,"Sentiment analysis is the process of determining whether a piece of document, text or conversation is positive, negative, neural or other emotion. Sentiment analysis has been applied for several real-world applications, such as chatbot. In the last five years, the practical use of the chatbot has been prevailing in many field of industry. In the chatbot applications, to recognize the user emotion, sentiment analysis must be performed in advance in order to understand the intent of speakers. The specific emotion is more than describing positive or negative sentences. In light of this context, we propose deep learning models for conducting multi-class sentiment analysis for identifying speaker’s emotion which is categorized to be joy, fear, guilt, sad, shame, disgust, and anger.Thus, we develop convolutional neural network (CNN), long short term memory (LSTM), and multi-layer neural network models, as deep neural networks models, for detecting emotion in a sentence. In addition, word embedding process was also applied in our research. In our experiments, we have found that long short term memory (LSTM) model performs best compared to convolutional neural networks and multi-layer neural networks. Moreover, we also show the practical applicability of the deep learning models to the sentiment analysis for chatbot."
온라인 뉴스 및 거시경제 변수를 활용한 주가예측,2017,"['주가예측', '딥러닝', '감성 분석', '경제 지표', 'Word2Vec', 'Stock price forecasting', 'Deep learning', 'Emotional analysis', 'Economic index', 'Word2Vec']","시장의 상태는 새로운 정보를 받으면서 변한다. 이는 투자자들의 결정에 영향을 주어 주식 시장의 변동을 만들어 내며, 주식 시장의 동향을 예측하는 데에 중요한 자료로써 사용된다. 외부의 정보는 크게 두 가지로 생각할 수 있는데, 뉴스의 정보와 거시 경제적인 지표이다. 하지만, 기존의 연구들은 뉴스만을 가지고 혹은 거시 경제 지표만을 가지고 예측을 하였으며, 뉴스의 정보와 거시 경제 지표를 함께 결합하여 외부의 영향을 모두 고려한 연구는 없었다. 본 논문에서는 주식 시장에 영향을 미치는 외부의 정보를 모두 고려하여 서로 다른 특성을 가지는 정보들을 딥러닝 알고리즘을 통해 통합하여 예측하는 방법을 제시한다. 뉴스 정보는 뉴욕타임스 2년 치 데이터를 Word2Vec 모형을 사용하여 정보 추출을 하였다. 거시 경제 지표는 다우 존스 지수에 영향을 줄 수 있는 지표들을 경제학적 이론에 기반을 두어 선정하였다. 이는 금값과 환율 시장이다. 뉴스에서 추출한 정보와 거시 경제적인 영향을 함께 통합하는 알고리즘은 시계열 데이터와 문자열 데이터를 다루기에 적절한 LSTM 네트워크를 응용하여 사용한다. 예측 기간을 바꾸며 실험을 진행한 결과, 단순 정보만을 가지고 예측한 결과나 거시 경제만을 가지고 예측한 결과보다 본 논문에서 제시한 두 가지를 통합하여 예측하는 것이 월등한 결과를 내었다. 또한, 기존의 연구에서 사용한 방법론과 제시한 딥러닝 알고리즘을 비교한 결과 본 논문에서 제시한 알고리즘이 기존 연구에서 사용한 방법론보다 월등한 결과를 나타냈다.","Market conditions change with new information. This affects investors' decisions and creates stock market volatility. This infor-mation is used as an important resource for forecasting stock market trends. At this time, there are two kinds of external information: news information and macroeconomic indicators. However, if we look at existing studies, they predicted only with news or macroe-conomic indicators. There was no study that considered all the external influences by combining news information and macroeconom-ic indicators together. Therefore, in this paper, we propose a method of integrating and forecasting information with different character-istics by considering the external information affecting the stock market through the deep learning algorithm. News information was extracted from the New York Times's 2-year data using the Word2vec model. Macroeconomic indicators are based on economic theo-ries that can influence the Dow Jones Index. This is the gold price and exchange rate market. Algorithms that integrate information ex-tracted from news and macroeconomic effects together are applied to LSTM networks suitable for handling time series data and string data. As a result of experimenting with changing the forecasting period, it is better to predict the results with only simple information and the macroeconomic results than with the results from this study. In addition, the algorithm proposed in this paper is superior to the methodology used in previous research."
이진 분류문제에서의 딥러닝 알고리즘의 활용 가능성 평가,2017,"['이진분류', '딥러닝', '다층 퍼셉트론', '합성곱 신경망', '장단기 기억', 'Binary Classification', 'Deep Learning', 'Multi-Layer Perceptron', 'Convolutional Neural Network', 'Long Short-Term Memory']",국문 초록 정보 없음,"Recently, AlphaGo which is Bakuk (Go) artificial intelligence program by Google DeepMind, had a huge victory against Lee Sedol. Many people thought that machines would not be able to win a man in Go games because the number of paths to make a one move is more than the number of atoms in the universe unlike chess, but the result was the opposite to what people predicted. After the match, artificial intelligence technology was focused as a core technology of the fourth industrial revolution and attracted attentions from various application domains. Especially, deep learning technique have been attracted as a core artificial intelligence technology used in the AlphaGo algorithm.  The deep learning technique is already being applied to many problems. Especially, it shows good performance in image recognition field. In addition, it shows good performance in high dimensional data area such as voice, image and natural language, which was difficult to get good performance using existing machine learning techniques. However, in contrast, it is difficult to find deep leaning researches on traditional business data and structured data analysis. In this study, we tried to find out whether the deep learning techniques have been studied so far can be used not only for the recognition of high dimensional data but also for the binary classification problem of traditional business data analysis such as customer churn analysis, marketing response prediction, and default prediction. And we compare the performance of the deep learning techniques with that of traditional artificial neural network models.  The experimental data in the paper is the telemarketing response data of a bank in Portugal. It has input variables such as age, occupation, loan status, and the number of previous telemarketing and has a binary target variable that records whether the customer intends to open an account or not. In this study, to evaluate the possibility of utilization of deep learning algorithms and techniques in binary classification problem, we compared the performance of various models using CNN, LSTM algorithm and dropout, which are widely used algorithms and techniques in deep learning, with that of MLP models which is a traditional artificial neural network model. However, since all the network design alternatives can not be tested due to the nature of the artificial neural network, the experiment was conducted based on restricted settings on the number of hidden layers, the number of neurons in the hidden layer, the number of output data (filters), and the application conditions of the dropout technique. The F1 Score was used to evaluate the performance of models to show how well the models work to classify the interesting class instead of the overall accuracy.  The detail methods for applying each deep learning technique in the experiment is as follows. The CNN algorithm is a method that reads adjacent values from a specific value and recognizes the features, but it does not matter how close the distance of each business data field is because each field is usually independent. In this experiment, we set the filter size of the CNN algorithm as the number of fields to learn the whole characteristics of the data at once, and added a hidden layer to make decision based on the additional features. For the model having two LSTM layers, the input direction of the second layer is put in reversed position with first layer in order to reduce the influence from the position of each field. In the case of the dropout technique, we set the neurons to disappear with a probability of 0.5 for each hidden layer.  The experimental results show that the predicted model with the highest F1 score was the CNN model using the dropout technique, and the next best model was the MLP model with two hidden layers using the dropout technique. In this study, we were able to get some findings as the experiment had proceeded. First, models using dropout techniques have a"
Malware Classification Possibility based on Sequence Information,2017,"['악성코드 분류', 'LSTM', '시스템 콜', '순서 정보', '길이', 'malware classification', 'system call', 'sequence', 'length']",국문 초록 정보 없음,다국어 초록 정보 없음
구조물 손상 예측 향상을 위한 순환신경망 방법론의 적용,2017,"['순환신경망', '머신러닝', '구조물 열화 및 노후화', 'LSTM', '의사결정']",국문 초록 정보 없음,다국어 초록 정보 없음
로고우스키형 부분방전 센서를 이용한 ANN 기반 파티클 재질 판별,2023,"['Artificial neural network', 'Defect identification', 'Partial discharge', 'Particle materials', 'Rogowski-type PD sensor', '적재 위반 차량 검출', '딥러닝', '객체 인식', '빅데이터']","최근 증가하고 있는 도로 위 적재 불량 화물차는 비정상적인 무게 중심으로 인해 물체 낙하, 도로 파손, 연쇄 추돌 등 교통안전에 위해가 되고 한번 사고가 발생하면 큰 피해가 유발할 수 있다. 하지만 이러한 비정상적인 무게 중심은 적재 불량 차량 인식을 위한 주행 중 축중 시스템으로는 검출이 불가능하다는 한계점이 있다. 본 논문에서는 이러한 사회 문제를 야기하는 적재 불량 차량을 관리하기 위한 객체 인식 기반 AI 모델을 구축하고자 한다. 또한 AI-Hub에 공개된 약 40만 장의 데이터셋을 비교 분석하여 전처리를 통해 적재 불량 차량 검지 AI 모델의 성능을 향상시키는 방법을 제시한다. 또한 객체 추적을 통해 실시간 검지를 수행하는 방법을 제안한다. 이를 통해, 원시 데이터를 활용한 학습 성능 대비 약 23% 향상된 적재 불량 차량의 검출 성능을 나타냄을 보였다. 본 연구 결과를 통해 공개 빅데이터를 보다 효율적으로 활용하여, 객체 인식 기반 적재 불량 차량 탐지 모델 개발에 적용할 수 있을 것으로 기대된다.",다국어 초록 정보 없음
Developing Chatbot for Training Seafarers for better Understanding and Communication by Using Real VTS Data,2017,"['Maritime Education', 'Chatbot Framework', 'Deeplearning', 'LSTM']",국문 초록 정보 없음,"The advent of the era of data age and advances inartificial intelligence technology has led to innovations in various business areas. In particular, many attempts have been made to improve the stability of the marine accident, which has not previously been applied by a data-drive approach. Most of the marine accidents happen at a time when the vessel isapproaching a port and preparing for berthing. Although the cause of the accident has many factors, it is often caused by the difficulties of communication between the ship navigator and the control center. In particular, communication in English makes difficulties for navigators, not English astheir first language. To do this, proper English conversation education forsailors is very important. In order to support the issue, this study presents data and framework for the development of a chatbot for ship safety education."
Water Level Forecasting based on Deep Learning : A Use Case of Trinity River-Texas-The United States,2017,"['침수 예측', '딥러닝', 'RNN', 'BPTT', 'LSTM', 'water level forecasting', 'deep learning', 'recurrent neural networks', 'back propagationthrough time', 'long short-term memory']",국문 초록 정보 없음,다국어 초록 정보 없음
공용 데이터링크 시스템에서 딥러닝 기반 적응형 전력제어 기법,2017,"['Deep learning', 'Adaptive power control', 'Common data link', 'LSTM', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
장단기 메모리 순환신경망 기반의 비침입적 음성 명료도 추정 방법,2017,"['Deep neural network (DNN)', 'Recurrent neural network (RNN)', 'Long short-term memory (LSTM)', 'Non-Intrusive', 'Speech intelligibility estimation', 'STOI', 'P.563']",국문 초록 정보 없음,다국어 초록 정보 없음
Evaluation of Recurrent Neural Network Variants for Person Re-identification,2017,"['Person re-identification', 'Multi-shot', 'Recurrent neural network', 'Optimization']",국문 초록 정보 없음,"Instead of using only spatial features from a single frame for person re-identification, a combination of spatial and temporal factors boosts the performance of the system. A recurrent neural network (RNN) shows its effectiveness in generating highly discriminative sequence-level human representations. In this work, we implement RNN, three Long Short Term Memory (LSTM) network variants, and Gated Recurrent Unit (GRU) on Caffe deep learning framework, and we then conduct experiments to compare performance in terms of size and accuracy for person reidentification. We propose using GRU for the optimized choice as the experimental results show that the GRU achieves the highest accuracy despite having fewer parameters than the others."
이미지 캡션 생성을 위한 심층 신경망 모델의 설계,2017,"['이미지 캡션 생성', '심층 신경망 모델', '모델 전이', '멀티 모달 순환 신경망', 'Image Caption Generation', 'Deep Neural Network Model', 'Model Transfer', 'Multi-Modal Recurrent Neural Network']",국문 초록 정보 없음,"In this paper, we propose an effective neural network model for image caption generation and model transfer. This model is a kind of multi-modal recurrent neural network models. It consists of five distinct layers: a convolution neural network layer for extracting visual information from images, an embedding layer for converting each word into a low dimensional feature, a recurrent neural network layer for learning caption sentence structure, and a multi-modal layer for combining visual and language information. In this model, the recurrent neural network layer is constructed by LSTM units, which are well known to be effective for learning and transferring sequence patterns. Moreover, this model has a unique structure in which the output of the convolution neural network layer is linked not only to the input of the initial state of the recurrent neural network layer but also to the input of the multimodal layer, in order to make use of visual information extracted from the image at each recurrent step for generating the corresponding textual caption. Through various comparative experiments using open data sets such as Flickr8k, Flickr30k, and MSCOCO, we demonstrated the proposed multimodal recurrent neural network model has high performance in terms of caption accuracy and model transfer effect."
다채널 오디오 특징값 및 게이트형 순환 신경망을 사용한 다성 사운드 이벤트 검출,2017,[],국문 초록 정보 없음,"In this paper, we propose an effective method of applying multichannel-audio feature values to GRNNs (Gated Recurrent Neural Networks) in polyphonic sound event detection. Real life sounds are often overlapped with each other, so that it is difficult to distinguish them by using a mono-channel audio features. In the proposed method, we tried to improve the performance of polyphonic sound event detection by using multi-channel audio features. In addition, we also tried to improve the performance of polyphonic sound event detection by applying a gated recurrent neural network which is simpler than LSTM (Long Short Term Memory), which shows the highest performance among the current recurrent neural networks. The experimental results show that the proposed method achieves better sound event detection performance than other existing methods."
미국 무역정책 변화가 국내 중공업 기업의 경영성과에 미치는 영향,2017,[],국문 초록 정보 없음,"Since late 2016, protectionism has been a major trend in world trade with the Great Britain exiting the European Union and the United States electing Donald Trump as the 45th president. Consequently, there has been a huge public outcry regarding the negative prospects of heavy industry firms in Korea, which are highly dependent upon international trade with Western countries including the United States. In light of such trend and concerns, we have tried to predict business performance of heavy industry firms in Korea with data regarding trade policy of the United States. United States International Trade Commission (USITC) levies countervailing duties and anti-dumping duties to firms that violate its fair-trade regulations. In this study, we have performed data analysis with past records of countervailing duties and anti-dumping duties. With results from clustering analysis, it could be concluded that trade policy trends of the Unites States significantly affects the business performance of heavy industry firms in Korea. Furthermore, we have attempted to quantify such effects by employing long short-term memory (LSTM), a popular neural networks model that is well-suited to deal with sequential data. Our major contribution is that we have succeeded in empirically validating the intuitive argument and also predicting the future trend with rigorous data mining techniques. With some improvements, our results are expected to be highly relevant to designing regulations regarding heavy industry in Korea."
환경 빅데이터 분석 및 서비스 개발,2017,"['빅데이터', '기계학습', '예측', '데이터 마이닝', '심층신경망', 'Big Data', 'Machine Learning', 'Estimation', 'Data Mining', 'Deep Learning']","본 연구는 단기예측 및 패턴 파악에 비교우위가 있는 빅데이터 연구 방법론의 환경정책연구에 대한 적용 가능성을 모색하였다. 본 연구는 환경연구 전 부문에 빅데이터 연구 방법론을 적용하는 ‘환경 빅데이터 연구’, 환경 관련 자료를 수집, 축적하는 ‘환경 빅데이터 플랫폼 구축 연구’, 연구성과를 이용하여 환경 서비스를 개발하는 ‘원내외 빅데이터 서비스 개발’의 3개 영역에 걸쳐서 3년간 3단계의 연구를 진행한다. 2017년에는 본 연구를 구성하는 3단계 연구 중 ‘환경 빅데이터 연구’에 중점을 두는 제1단계 연구를 시작하였다. 2017년에는 상대적으로 전처리 부담이 적은 수치 및 전산화된 텍스트 분석에 집중하여, 빅데이터 연구 방법론의 환경정책연구 가능성을 진단하였다. 그 결과 환경오염 추정 알고리듬 3개, 텍스트 자료 이용 환경연구 동향 파악 알고리듬 3개, 온라인 환경 관련 자료의 집적을 자동화하는 자료 수집 알고리듬 3개를 구축하였다.본 연구에서 개발한 환경오염 추정 3개 알고리듬은 ① 서울지역 측정소 단위 시간별 미세먼지 오염도를 예측하는 KNN 공간순환신경망 알고리듬, ② 기초지자체의 월별 장감염 발생 건수를 추정하는 심층신경망 알고리듬 ③ 기초지자체 월별 미세먼지 오염도 발생요인을 파악하는 의사결정나무 기반 알고리듬이다.서울지역 측정소 단위 시간별 미세먼지 농도 예측 KNN 공간순환신경망 알고리듬은 서울지역 39개 측정소의 2016년 1년간 미세먼지(PM10) 오염도 자료를 이용하여 구축하였으며, 미세먼지 농도를 2시간 전에 예측할 수 있도록 하였다. 설명변수로는 4개 대기오염물질오염도(SO<sub>2</sub>, CO, O<sub>3</sub>, NO<sub>2</sub>) 및 기상 정보(기온, 강수량, 풍속, 풍향)를 사용하였다. 분석결과 본 연구에서 개발한 KNN공간순환신경망 알고리듬은 통상적으로 시계열 예측에 사용하는 ARIMA 모델보다 예측치와 실측치 간 평균제곱근오차를 10.5% 축소하는 정확한 추정치를 제공할 수 있음을 확인하였다.기초지자체의 월별 장감염 발생 건수를 추정하는 심층신경망 알고리듬은 건강보험 코호트 DB를 이용하여 구축한 2009~2013년 월별 장감염 발생빈도를 기상자료, 대기오염 자료, 인구 통계적 자료, 위-경도 좌표를 이용하여 추정하는 심층신경망 알고리듬이다. 이 알고리듬은 노드가 500개인 3개의 은닉층을 지니며, 활성화 함수로는 ReLU 함수를 사용하였고, Epoch 30회에 걸쳐서 학습을 진행하여 도출한 모수 값을 이용하여 구축하였다. 이렇게 구축한 심층신경망 모델은 같은 변수를 사용한 선형회귀분석 모델보다 평균제곱근오차가 25% 낮은 정확한 추정치를 도출할 수 있었다.기초지자체 월별 미세먼지 농도 추정 의사결정나무 기반 알고리듬은 2001년 1월~2016년 9월 시군구 월평균 미세먼지(PM10) 농도 자료의 추정을 목적으로 구축하였다. 독립변수로는 대기오염물질 오염도, 대기오염물질 배출량, 기상변수, 황사일수, 중국 베이징, 상하이, 톈진의 대기오염 자료를 이용하였다. 자료의 가용성에 따라서 추정 시기와 독립변수의 집합을 달리하는 6개의 실험을 실시하였으며, 매 실험에 의사결정나무, 랜덤포레스트, 배깅, 부스팅 4개의 방법론을 적용하였다. 분석 결과 랜덤포레스트 및 부스팅 알고리듬은 선형회귀분석의 평균제곱오차를 각각 45.5%, 37.2% 개선하는 효과가 있었다. 그리고 독립변수에 황사일수, 베이징/상하이의 미세먼지 오염도, 베이징/톈진의 대기질 지수가 포함될 경우 추정치의 평균제곱오차가 크게 줄어든다는 사실을 확인하였다. 이는 국내 미세먼지오염도가 중국의 대기오염에 크게 영향을 받는다는 기존의 주장을 뒷받침하는 결과이다.본 연구에 개발한 텍스트 자료 분석 알고리듬은 모두 3개로 환경정보 문헌을 분석하여 문헌 토픽을 추출하는 LDA 분석 알고리듬, 문헌의 키워드 간 연관규칙을 발견하는 연관성 분석 및 키워드 네트워크 분석 알고리듬, 키워드 간 문장 내 관계를 분석하는 Word2Vec 알고리듬이다. 본 연구에서는 이상의 3개 알고리듬을 1993~2016년 KEI 연구보고서 및 2001~2016년 네이버 환경뉴스에 적용하여 두 종류의 문헌의 특성을 비교하였다.LDA 분석 결과는 다음과 같다. 2008~2012년간 KEI 연구 중 기후변화의 비중이 네이버 뉴스에서 기후변화 비중보다 상대적으로 높았으며, 폐기물, 에너지-자원, 수질오염 연구의 비중은 네이버 뉴스의 비중보다 낮았다. 그리고 2013년 이후에도 에너지-자원 및 폐기물 연구의 비중이 네이버 뉴스의 비중보다 낮은 수준으로 유지되고 있었다. 그리고 2013년 이후 네이버 뉴스에서 그 비중이 급증하고 있는 ‘유전자 변형-소음’, ‘보건-데이터’ 관련 연구가 KEI 연구동향에서는 독립된 토픽으로 나타나지 않아서, 이에 대한 연구가 필요한 것으로 파악되었다.연관성 분석 및 키워드 네트워크 분석 결과는 다음과 같다. 키워드 네트워크의 시기적 추이를 보면 KEI는 2003~2007년간 기후변화 연구를 선도하였으며, 기후변화 및 녹색성장에 대한 민간의 관심이 높았던 2008~2012년에는 해당 연구를 중심으로 연구를 수행하였다. 단, 2013년 이후에는 네이버 뉴스에서 기후변화 연관 키워드가 세부주제를 중심으로 분기하고 있는 것과 달리, KEI 연구보고서에서는 기후변화 키워드의 중심성이 강화되고 있어 최근 조류를 반영하는 연구가 필요한 것으로 파악되었다.Word2Vec 분석 결과는 다음과 같다. Word2Vec 분석에서는 기후변화의 세부현상인 온난화, 홍수, 가뭄 3개 단어와 문장 내 연관관계가 높은 단어들을 파악하여 매체 간 비교를 수행하였다. KEI 보고서는 온난화의 단기적인 영향, 온난화가 인간에 미치는 영향, 홍수의 국내 영향, 가뭄이 인간에 미치는 영향과 관계된 단어가 3개 단어와 연관성이 높은 것으로 파악되었고, 네이버 뉴스에서는 온난화의 초장기적인 영향, 온난화가 생물 및 식량에 미치는 영향, 해외 홍수의 피해, 가뭄이 농업에 미치는 영향과 관계된 단어의 연관성이 높은 것으로 파악되었다. 이러한 차이는 연구보고서가 국민의 삶에 질과 연관하여 기후변화를 연구하고 있는 데 비해, 네이버 뉴스는 기후변화로 인한 세계적인 피해를 중심으로 기사가 작성되고 있는 현상을 반영한다고 할 수 있다.이상에서 소개한 3개의 알고리듬을 2개의 텍스트 문헌에 적용한 텍스트 분석 결과로부터 환경 연구 수요 및 현재 연구 부족 분야를 파악하였다. 토픽 구성 변화를 보면, ‘에너지-자원’, ‘폐기물’, ‘유전자 변형/소음’, ‘보건/데이터’에 대한 민간의 관심이 제고되고 있는데 연구동향은 이를 담아내지 못하고 있었다. 그리고 키워드 분석의 결과를 보면 민간의 관심은 태풍, 한파, 대설 등 세분화된 기후변화 주제로 이동하고 있지만 연구동향은 기후변화 일반을 중심으로 전개되고 있었다. 따라서 환경연구의 외연을 기후변화 외부 영역으로 확장하고, 기후변화와 관계된 연구는 연구주제를 세분화하는 연구가 필요하다고 할 수 있다.환경 빅데이터 연구 인프라 구축의 일환으로 공공데이터포털(대기오염 및 기상정보), 한국환경공단 AirKorea, 기상자료개방포털 3개 웹페이지의 자료 수집 알고리듬을 개발하였다. 공공데이터포털 자료 수집 알고리듬은 공공데이터포털에서 제공하는 API 서비스를 이용하여 자료를 수집하는 알고리듬이다. 한국환경공단 AirKorea 자료 수집 알고리듬은 웹사이트에 직접 접속하여 자료를 수집하는 알고리듬이다. 이상 2개의 알고리듬은 데이터를 수집하고 추출하는 전 과정을 Python 코드로 작성하여 자동화하였다. 반면 기상자료개방포털 자료 수집 알고리듬은 셀레니움(Selenium) 프로그램을 이용하여 웹브라우저의 로그인 과정을 대행하고, 로그인 이후부터 압축파일(Zip)로 제공되는 자료를 다운로드하는 과정을 자동화한 알고리듬이다. 이 3개 알고리듬을 구축하여 자료가 직접 게시되는 경우, API를 통해 제공되는 경우, 압축파일 형태로만 제공되는 경우에 각각 대응 가능한 자료 추출 도구를 구비하였다.2017년 본 연구는 빅데이터 연구 방법론을 수치 자료에 적용하면 기존의 방법론보다 소규모 지역 단위에서 예측오차를 단축할 수 있고, 텍스트 자료에 적용하면 민간의 연구에 대한 수요(환경뉴스) 및 연구 공급 현황(연구보고서)을 비교·분석할 수 있음을 확인하였다. 본 연구가 제공하는 정교한 환경정보 예측치는 그 자체로서 민간 환경정보 서비스의 인프라로 기능할 수 있고, 단기 소규모 지역 단위 정책재원 운용의 기준으로 활용할 수 있다. 또한 의사결정나무를 이용하여 독립변수의 중요도를 파악하는 기법을 적용하면, 재정지출이 환경오염에 미치는 영향의 중요도를 평가하여 소규모 지역 단위 재정운용 성과평가 수단으로도 활용할 수 있다. 본 연구의 성과는 빅데이터 연구 방법론이 민간 환경정보사업의 인프라 구축, 정책운용의 효율성 제고, 정책평가 수단의 확충이라는 3가지 측면에서 잠재적으로 정책적 활용 가능성이 있음을 보여 주었다.본 연구의 성과는 본 연구에서 구축한 깃허브(https://github.com/keibigdata)에 공개하였으며, 향후 본 연구에서 개발하는 환경 빅데이터 분석플랫폼의 기초자료로 활용할 계획이다.","The key advantages of Machine Learning analysis using large data are 1) accurate forecast and 2) unknown-pattern finding In this report, we try to make use of these advantages in Environmental Research and Service. This research is composed of three components. First, we apply Machine learning algorithm to environmental research. (2017~19) Second, we accumulate data and algorithms developed in environmental research and combine them with environmental data web crawling algorithm to build environmental machine learning platform(2020~22). Third, we develop public environmental service using these research results and platform(2023~25).In 2017, we developed three machine learning algorithms applied to environment data - LSTM algorithm estimating hourly find dust pollution, Random Forest/Boosting ensemble algorithm estimating monthly find dust pollution, DNN algorithm estimating intestinal infection case numbers using climate data. Also we applied LDA/Association Rule Learning/word2vec algorithm to online news data and KEI report data, and found that KEI should pay more attention to generic mutation, noise, environmental health, environmental data and specific climate issues like typhoon, severe cold, heavy snow to catch up with public interests represented in online news data."
비분할 비디오로부터 행동 탐지를 위한 순환 신경망 학습,2017,[],"본 논문에서는 비분할 비디오로부터 이 비디오에 담긴 사람의 행동을 효과적으로 탐지해내기 위한 심층 신경망 모델을 제안한다. 일반적으로 비디오에서 사람의 행동을 탐지해내는 작업은 크게 비디오에서 행동 탐지에 효과적인 특징들을 추출해내는 과정과 이 특징들을 토대로 비디오에 담긴 행동을 탐지해내는 과정을 포함한다. 본 논문에서는 특징 추출 과정과 행동 탐지 과정에 이용할 심층 신경망모델을 제시한다. 특히 비디오로부터 각 행동별 시간적, 공간적 패턴을 잘 표현할 수 있는 특징들을 추출해내기 위해서는 C3D 및 I-ResNet 합성곱 신경망 모델을 이용하고, 시계열 특징 벡터들로부터 행동을 자동 판별해내기 위해서는 양방향 BI-LSTM 순환 신경망 모델을 이용한다. 대용량의 공개 벤치마크 데이터 집합인 ActivityNet 비디오 데이터를 이용한 실험을 통해, 본 논문에서 제안하는 심층 신경망 모델의 성능과 효과를 확인할 수 있었다.",다국어 초록 정보 없음
Accurate Human Localization for Automatic Labelling of Human from Fisheye Images,2017,"['Human Localization', 'Fisheye Camera', 'CNN (Convolutional Neural Networks)', 'GoogLeNet', 'Long Short Term Memory', 'Saliency Detection']",국문 초록 정보 없음,"Deep learning networks like Convolutional Neural Networks (CNNs) show successful performances in many computer vision applications such as image classification, object detection, and so on. For implementation of deep learning networks in embedded system with limited processing power and memory, deep learning network may need to be simplified. However, simplified deep learning network cannot learn every possible scene. One realistic strategy for embedded deep learning network is to construct a simplified deep learning network model optimized for the scene images of the installation place. Then, automatic training will be necessitated for commercialization. In this paper, as an intermediate step toward automatic training under fisheye camera environments, we study more precise human localization in fisheye images, and propose an accurate human localization method, Automatic Ground-Truth Labelling Method (AGTLM). AGTLM first localizes candidate human object bounding boxes by utilizing GoogLeNet-LSTM approach, and after reassurance process by GoogLeNet-based CNN network, finally refines them more correctly and precisely(tightly) by applying saliency object detection technique. The performance improvement of the proposed human localization method, AGTLM with respect to accuracy and tightness is shown through several experiments."
