title,date,keywords,abstract,multilingual_abstract
실시간 얼굴 검출을 위한 Cascade CNN의 CPU-FPGA 구조 연구,2017,"['Face Detection', 'Cascade Convolutional Neural Network (CNN)', 'Hybrid FPGA', 'Acceleration', 'Energy Efficient']","얼굴 검출에는 다양한 포즈, 빛의 세기, 얼굴이 가려지는 현상 등의 많은 변수가 존재하므로, 높은 성능의 검출 시스템이 요구된다. 이에 영상 분류에 뛰어난 Convolutional Neural Network (CNN)이 적절하나, CNN의 많은 연산은 고성능 하드웨어 자원을 필요로한다. 그러나 얼굴 검출을 위한 소형, 모바일 시스템의 개발에는 저가의 저전력 환경이 필수적이고, 이를 위해 본 논문에서는 소형의 FPGA를 타겟으로, 얼굴 검출에 적절한 3-Stage Cascade CNN 구조를 기반으로하는 CPU-FPGA 통합 시스템을 설계 구현한다. 가속을 위해 알고리즘 단계에서 Adaptive Region of Interest (ROI)를 적용했으며, Adaptive ROI는 이전 프레임에 검출된 얼굴 영역 정보를 활용하여 CNN이 동작해야할 횟수를 줄인다. CNN 연산 자체를 가속하기 위해서는 FPGA Accelerator를 이용한다. 가속기는 Bottleneck에 해당하는 Convolution 연산의 가속을 위해 FPGA 상에 다수의 FeatureMap을 한번에 읽어오고, Multiply-Accumulate (MAC) 연산을 병렬로 수행한다. 본 시스템은 Terasic사의 DE1-SoC 보드에서 ARM Cortex A-9와 Cyclone V FPGA를 이용하여 구현되었으며, HD (1280x720)급 입력영상에 대해 30FPS로 실시간 동작하였다. CPU-FPGA 통합 시스템은 CPU만을 이용한 시스템 대비 8.5배의 전력 효율성을 보였다.","Since there are many variables such as various poses, illuminations and occlusions in a face detection problem, a high performance detection system is required. Although CNN is excellent in image classification, CNN operatioin requires high-performance hardware resources. But low cost low power environments are essential for small and mobile systems. So in this paper, the CPU-FPGA integrated system is designed based on 3-stage cascade CNN architecture using small size FPGA. Adaptive Region of Interest (ROI) is applied to reduce the number of CNN operations using face information of the previous frame. We use a Field Programmable Gate Array(FPGA) to accelerate the CNN computations. The accelerator reads multiple featuremap at once on the FPGA and performs a Multiply-Accumulate (MAC) operation in parallel for convolution operation. The system is implemented on Altera Cyclone V FPGA in which ARM Cortex A-9 and on-chip SRAM are embedded. The system runs at 30FPS with HD resolution input images. The CPU-FPGA integrated system showed 8.5 times of the power efficiency compared to systems using CPU only."
"테러와 뉴스보도: CCTV, CNN, KBS의 뉴스 프레임 분석",2017,"['중국 테러보도', '뉴스 프레임', '중국 CCTV', '미국 CNN', '한국 KBS', 'Terror in China', 'News Frame', 'China’s CCTV', 'CNN in the United States', 'KBS in South Korea']","본 논문은 중국 CCTV, 미국 CNN, 그리고 한국 KBS가 2013-2014년 중국에서 발생한 테러를 어떻게 보도했는지 텔레비전 뉴스 프레임 분석을 통해 살펴본다. 특히 텔레비전 뉴스 프레임을 구성하는 정보채널, 정보소스, 스토리의 복합성 요인들을 뉴스 프레임 유형별로 분석함으로써 중국테러에 대한 한·미·중 3개국의 텔레비전 뉴스보도가 저널리즘 원칙에 따라 보도중립을 준수했는지를 탐구한다. 분석결과, CCTV, CNN, KBS 간에 중국테러에 대한 뉴스보도에 있어서 차이가 있는 것으로 나타났다. CCTV는 반테러주의, 중국내 위기관리 등의 프레임을 통해 테러를 조직적, 계획적, 전 세계적, 반인륜적 행위로 규정하고 단호한 대처를 표명하면서 테러 직후 중국 정부의 신속한 위기관리 능력을 보여주는 것으로 보도했다. CNN은 반테러주의, 중국내 위기관리뿐만 아니라 중국정부의 정보 비공개를 비판하는 프레임으로 보도하였다. KBS의 경우는 반테러주의, 중국내 위기관리 프레임과 더불어 신장 위구르족과 한족간의 민족갈등 프레임을 통해 반테러 입장과 동시에 테러의 원인이 민족갈등이라는 시각을 보여주었다. 또한 뉴스 스토리 구성방식에서 3개국의 방송보도 모두 에피소드를 전하는 일화적 뉴스 프레임을 사용하였다. 본 연구를 통해 각국의 정치, 외교적 이해관계가 뉴스보도에 영향을 미치는 보도행태를 지양하고 저널리즘 원칙에 따라 공정하고 중립적인 뉴스보도를 지향하는 방향으로 미디어의 뉴스보도 행태가 변화해야 한다고 본다.","Using framing analysis of news, this study explores methods for analyzing the television news reporting of CCTV, CNN, and KBS on recent terror incidents in China. Especially in the context of news reports on terrorism, the author postulates that“information channels”,“information source” and “complexity of news coverage”used in the coverage of terror are main factors in organizing television news frames. By analyzing these factors within each news framing category, the paper investigates whether or not television news reports in three nations—China, the United States, and South Korea—are neutral, and if they abide by fundamental principles of objective journalism. The results demonstrate that there are several differences in covering terror attacks in China among CCTV, CNN, and KBS. CCTV shows anti-terrorism and governmental crisis management in a China-oriented frame; it defines terror as an organizational and well-prepared“common enemy of humanity,”demands resolute confrontation, and reports rapid crisis management right after a terror act has occurred. The reporting by CNN reveals criticism of the Chinese government’s non-disclosure of information, as well as the frame of anti-terrorism and crisis management in China. KBS reports, in addition to the frame of anti-terrorism and crisis management in China, that of a sharp escalation in the Chinese state’s confrontation with Uyghurs in Xinjiang. Television news coverage by the three countries all use episodic frame-telling episodes of a specific incident. This study suggests that media news reports by political and diplomatic interests should be avoided, and those by fair and neutral principles should be oriented."
Efficient Swimmer Detection Algorithm using CNN-based SVM,2017,"['Object detection', 'HOG', 'SVM', 'CNN']",국문 초록 정보 없음,"In this paper, we propose a CNN-based swimmer detection algorithm. Every year, water safety accidents have been occurred frequently, and accordingly, intelligent video surveillance systems are being developed to prevent accidents. Intelligent video surveillance system is a real-time system that detects objects which users want to do. It classifies or detects objects in real-time using algorithms such as GMM (Gaussian Mixture Model), HOG (Histogram of Oriented Gradients), and SVM (Support Vector Machine). However, HOG has a problem that it cannot accurately detect the swimmer in a complex and dynamic environment such as a beach. In other words, there are many false positives that detect swimmers as waves and false negatives that detect waves as swimmers. To solve this problem, in this paper, we propose a swimmer detection algorithm using CNN (Convolutional Neural Network), specialized for small object sizes, in order to detect dynamic objects and swimmers more accurately and efficiently in complex environment. The proposed CNN sets the size of the input image and the size of the filter used in the convolution operation according to the size of objects. In addition, the aspect ratio of the input is adjusted according to the ratio of detected objects. As a result, experimental results show that the proposed CNN-based swimmer detection method performs better than conventional techniques."
CNN을 적용한 조명변화에 강인한 얼굴인식 연구,2017,"['Face Recognition', 'Deep Learning', 'Yale Face Database B', 'Convolutional Neural Network', '얼굴 인식', '딥러닝', '예일 페이스 데이터 베이스 B', '컨볼루션 신경망']","얼굴인식 기술은 지난 수십 년간 연구되어온 분야로서 보안, 엔터테인먼트, 모바일 서비스 등 다양한 영역에서 활용되고 있다. 얼굴인식 기술이 가진 주된 문제점은 밝기, 조명각도, 영상 회전등의 환경적 변화 요소에 따라 인식률이 현저하게 감소된다는 것이다. 따라서 본 논문에서는 최근 많은 계산량을 처리할 수 있는 컴퓨터 하드웨어와 알고리즘의 발전으로 재조명 받고 있는 CNN을 이용해  조명변화에 강인한 얼굴인식 방법을 제안하였다. 이후 성능검증을 위해 기존의 얼굴인식 알고리즘인 PCA, LBP, DCT와 결과 비교를 진행하였으며, 각각 9.82%, 11.6%, 4.54%의 성능 향상을 보였다. 또한 기존 신경망을 적용한 얼굴인식 연구결과 비교에서도 5.24%의 성능 향상을 기록하여 최종 인식률 99.25%를 달성하는 결과를 보였다.","Face recognition technology has been studied for decades and is being used in various areas such as security, entertainment, and mobile services. The main problem with face recognition technology is that the recognition rate is significantly reduced depending on the environmental factors such as brightness, illumination angle, and image rotation. Therefore, in this paper, we propose a robust face recognition against lighting variation using CNN which has been recently re-evaluated with the development of computer hardware and algorithms capable of processing a large amount of computation. For performance verification, PCA, LBP, and DCT algorithms were compared with the conventional face recognition algorithms. The recognition was improved by 9.82%, 11.6%, and 4.54%, respectively. Also, the recognition improvement of 5.24% was recorded in the comparison of the face recognition research result using the existing neural network, and the final recognition rate was 99.25%."
단어의 의미와 순서를 고려하는 문서색인방법을 이용한 CNN 기반 한글문서분류,2017,[],"본 논문에서는 컨볼루션 신경망 네트워크(CNN:Convolution Neural Network)을 기반으로 단어의 의 미와 순서를 고려하는 문서 색인 방법을 이용하여 한글 문서 분류 방법을 제안한다. 먼저 문서를 형태 소 분석하여 어절 단위로 분리 한 후, 불용어를 처리 하고, 문서의 단어 의미를 고려하는 문서 표현하고, 문서의 단어 순서까지 고려하여 CNN의 입력으로 사용하였다. 실험결과 CNN 분류기를 기반으로 본 논문에서 제안하는 문서 색인 방법은 TF-IDF를 이용하는 방법보다 4.2%, Word2vec만 단독으로 사 용하는 것보다 1.4%의 성능 상승을 이루었다. 이러한 결과를 통해 본 논문에서 제안하는 방법이 문서 범주화 데이터 셋에서 문서 분류 성능향상에 영향을 미친다는 것을 확인하였다.",다국어 초록 정보 없음
CNN을 이용한 영상 기반 다수 대상체 인식 및 위치 식별,2017,"['Detection (인식)', 'CNN (합성곱 신경망)', 'UAV (무인기)', 'Localization (위치 식별)', 'Vision (영상)']",국문 초록 정보 없음,다국어 초록 정보 없음
Word2vec과 CNN을 응용한 이미지 태깅 연구,2017,[],"데이터의 크기가 큰 이미지나 동영상 같은 멀티미디어 데이터들이 SNS를 통해 빠른 속도로 증가하고 있는 추세이지만, 이미지 데이터를 분리하는 방법은 소셜 태깅에 한정되어 있는 경우가 많다. 하지만 이런 소셜 태깅은 사용자가 키워드를 직접 입력하기 때문에 주관적이고 이미지와는 직접적인 관계가 없는 경우도 있어 활용하는 데에 어려움이 있다. 따라서 본 논문에서는 Word2vec 알고리즘과 CNN 네트워크를 적용한 인공신경망 학습을 통해 효율적인 이미지 태깅 방법을 제시한다. 이미지 태깅을 위한 네트워크 구축 과정을 나타내고, 네트워크 학습 과정과 학습 결과를 보인다. 마지막으로 완성된 네트워크에 이미지 데이터를 적용하여 해당 이미지가 완련된 단어에 대해 학습할 수 있음을 보이고 효과적인 이미지 태깅이 가능함을 증명한다.",다국어 초록 정보 없음
비정형화된 환경에서 차량 번호판 검출을 위한 CNN기반의 단일 파이프라인 검출 방법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
디스래깅 작업의 자동화를 위한 CNN기반 경로 라벨링 및 슬래그 제거 경로 추정,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
픽셀 회로 이미지의 불량 개체 필터링을 위한 CNN 기반 분류 방법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 운동선수 자세 분류,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 이미지 분류,2017,"['convolutional neural network', 'big data', 'tensorflow']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN기반 위조지문판별에서 시공간 정보의 영향분석,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Recognition of English letters Using RNN and CNN,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 위한 아날로그 회로 기반의 MAC 구현,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 대화와 같은 짧은 문장에서 개체명 인식,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM 모델을 이용한 도로 CCTV 영상의 강수량 판별 방법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 효율적인 입수자 검출 알고리즘,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 글자별 한글 필적감정 알고리즘,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 시스템의 건전성 관리를 위한 스펙트로그램 CNN 기반 전원 신호 분류 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CCTV 환경에서 CNN을 이용한 얼굴 검출에 관한 기존 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
HOG 알고리즘과 CNN을 이용한 화재인식,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
그래프 기반 영상 분할과 CNN의 결합을 통한 단안 영상의 3차원 재구성,2017,[],국문 초록 정보 없음,"3D reconstruction from a monocular image represents ambiguous depth cues because their ill-posed problems. On the other hand, some neural network approaches show impressive results on predicting the depth for certain images. in this paper, We extract robust image features with neural network and reconstruct using these features. The results indicate that we can estimate the more accurate depth with the proposed algorithm."
적외선 영상에서의 표적과 클러터 구분을 위한 Hybrid Machine Character 기반의 Du-CNN 설계,2017,"['적외선 영상', '합성곱신경망', '표적분류', '기계학습', '다중인격', 'Infrared Image', 'Convolutional Neural Network', 'Target Classification', 'Machine Learning', 'Multiple Personality']",국문 초록 정보 없음,"In this paper, we propose a robust duality of CNN(Du-CNN) method which can classify the target and clutter in coastal environment for IR Imaging Sensor. In coastal environment, there are various clutter that have many similarities with real target due to diverse change of air temperature, water temperature, weather and season. Also, real target have various feature due to the same reason. Thus, the proposed Du-CNN method adopts human’s multiple personality utilization and CNN technique to learn and classify target and clutter. This method has an advantage of the real time operation. Experimental results on sampled dataset of real infrared target and clutter demonstrate that the proposed method have better success rate to classify the target and clutter than general CNN method."
CNN 기반의 실시간 DNS DDoS 공격 탐지 시스템,2017,"['딥 러닝', 'DNS DDoS 공격', '실시간 탐지 시스템', 'DNS 증폭 공격', 'Deep Learning', 'DNS DDoS Attack', 'Real-Time Detection System', 'DNS Amplification Attack']",국문 초록 정보 없음,"DDoS (Distributed Denial of Service) exhausts the target server`s resources using the large number of zombie pc, As a result normal users don`t access to server. DDoS Attacks steadly increase by many attacker, and almost target of the attack is critical system such as IT Service Provider, Government Agency, Financial Institution. In this paper, We will introduce the CNN (Convolutional Neural Network) of deep learning based real-time detection system for DNS amplification Attack (DNS DDoS Attack). We use the dataset which is mixed with collected data in the real environment in order to overcome existing research limits that use only the data collected in the experiment environment. Also, we build a deep learning model based on Convolutional Neural Network (CNN) that is used in pattern recognition."
손 모양 인식을 위한 CNN 설계 및 구현,2017,"['CNN', 'hand shape', '손모양']",본문참고,다국어 초록 정보 없음
TORCS 환경에서 CNN 을 이용한 자율 주행 학습 및 테스트 시스템,2017,[],일반적으로 자율 주행에 딥러닝을 적용하기 위해서 실제 차량에 관련 장비를 설치하고 테스트한다. 본 논문에서는 The Open Racing Car Simulator(TORCS)에서 다양한 신경망 구조를 적용하도록 Convolutional Neural Network(CNN)을 통하여 학습 및 테스트할 수 있는 시스템을 제안한다. 가상 환경에서 테스트함으로써 하드웨어를 구매하거나 제작하지 않아도 되며 신경망 구조를 선택후 학습함으로써 다양한 데이터에 적합한 신경망 구조를 적용할 수 있다.,다국어 초록 정보 없음
CNN 알고리즘의 하드웨어 구현을 위한 고정 소수점 모델 구현 및 성능 분석,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기법을 이용한 공간정보 자동분류연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Text-CNN을 활용한 다중 감정 분류 모델 개발 및 챗봇 학습 데이터 연동 방안 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
파운데이션 두께 예측을 위한 CNN 모델,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
인셉션 모듈을 이용한 CNN 모델 구성,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
자질 보강과 양방향 LSTM-CNN-CRF 기반의 한국어 개체명 인식 모델,2017,"['개체명 인식', '자연어 처리', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Natural Language Processing', 'Deep Learning', 'Feature Augmentation']","개체명 인식(Named Entity Recognition) 시스템은 문서에서 인명(PS), 지명(LC), 단체명(OG)과 같은 개체명을 가지는 단어나 어구를 해당 개체명으로 인식하는 시스템이다. 개체명 인식을 하기위한 전통적인 연구방법으로는 hand-craft된 자질(feature)을 기반으로 모델을 학습하는 통계 기반의 모델이 있다. 최근에는 딥러닝 기반의 RNN(Recurrent Neural Networks), LSTM(Long-short Term Memory)과 같은 모델을 이용하여 문장을 표현하는 자질을 구성하고 이를 개체명 인식과 같이 순서 라벨링(sequence labeling) 문제 해결에 이용한 연구가 제안되었다. 본 연구에서는 한국어 개체명 인식 시스템의 성능 향상을 위해, end-to-end learning 방식이 가능한 딥러닝 기반의 모델에 미리 구축되어 있는 hand-craft된 자질이나 품사 태깅 정보 및 기구축 사전(lexicon) 정보를 추가로 활용하여 자질을 보강(augmentation)하는 방법을 제안한다. 실험 결과 본 논문에서 제안하는 방법에 따라 자질을 보강한 한국어 개체명 인식 시스템의 성능 향상을 확인하였다. 또한 본 연구의 결과를 한국어 자연어처리(NLP) 및 개체명 인식 시스템을 연구하는 연구자들과의 향후 협업 연구를 위해 github를 통해 공개하였다.","The Named Entity Recognition system is a system that recognizes words or phrases with object names such as personal name (PS), place name (LC), and group name (OG) in the document as corresponding object names. Traditional approaches to named entity recognition include statistical-based models that learn models based on hand-crafted features. Recently, it has been proposed to construct the qualities expressing the sentence using models such as deep-learning based Recurrent Neural Networks (RNN) and long-short term memory (LSTM) to solve the problem of sequence labeling. In this research, to improve the performance of the Korean named entity recognition system, we used a hand-crafted feature, part-of-speech tagging information, and pre-built lexicon information to augment features for representing sentence. Experimental results show that the proposed method improves the performance of Korean named entity recognition system. The results of this study are presented through github for future collaborative research with researchers studying Korean Natural Language Processing (NLP) and named entity recognition system."
Faster R-CNN을 이용한 해양에서의 선박 검출,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
심층 CNN 모델을 이용한 외부 및 내부 예시영상 기반의 고 해상도 복원 기법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster R-CNN에서의 원근 왜곡 보정을 통한 물체 검출,2017,"['robot vision', 'object recognition', 'convolutional neural network', 'perspective distortion']",국문 초록 정보 없음,다국어 초록 정보 없음
결함 검출을 위한 CNN 구조의 비교,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
<SUP>18</SUP>F-Fluorbetaben(FBB) PET 영상 편집 과정을 통해 얻어진 DB(Database)를 사용하여 Caffe를 이용한 CNN(Convolution Neural Network)기반의 의학용 Alzheimer’s Disease(AD) 영상 분석,2017,"['convolution neural network', 'amyloid', 'alzheimer', 'PET', 'deep learning', 'caffe', 'LMDB']",국문 초록 정보 없음,다국어 초록 정보 없음
SLIC를 적용한 개선된 R-CNN 알고리즘 설계,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Input Attention 기반 LSTM-CNN 모델을 이용한 Relation Classification,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
대화 단위의 화행 분석을 위한 RNN-CNN 기반 한국어 화행 분석 시스템,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
HS 알고리즘을 이용한 CNN의 Hyperparameter 결정 기법,2017,"['Convolutional Neural Network', 'Parameter-Setting-Free Harmony Search Algorithm', '메타 휴리스틱 알고리즘', 'Hyperparameter 최적화', 'Metaheuristic Algorithm', 'Hyperparameter Optimization']","Convolutional Neural Network(CNN)는 특징 추출과 분류의 두 단계로 나눌 수 있다. 그 중 특징 추출 단계의 커널의 크기, 채널의 수, stride 등의 hyperparameter는 CNN의 구조를 결정할 뿐만 아니라 특징을 추출하는 데에도 영향을 주기 때문에 CNN의 전체적인 성능에도 영향을 준다. 본 논문에서는 Parameter-Setting-Free Harmony Search(PSF-HS) 알고리즘을 이용하여 CNN의 특징 추출 단계에서의 hyperparameter를 최적화 하는 방법을 제안하였다. CNN의 전체 구조를 설정한 뒤 hyperparameter를 변수로 설정하였고 PSF-HS 알고리즘을 적용하여 hyperparameter를 최적화 하였다. 시뮬레이션은 MATLAB을 이용하여 진행하였고 CNN은 mnist 데이터를 이용하여 학습과 테스트를 했다. 총 500번 동안 변수를 업데이트했고 제안하는 방법을 이용하여 구한 CNN 구조 중 가장 높은 정확도를 가지는 구조는 99.28%의 정확도로 mnist 데이터를 분류하는 것을 확인할 수 있었다.","The Convolutional Neural Network(CNN) can be divided into two stages: feature extraction and classification. The hyperparameters such as kernel size, number of channels, and stride in the feature extraction step affect the overall performance of CNN as well as determining the structure of CNN. In this paper, we propose a method to optimize the hyperparameter in CNN feature extraction stage using Parameter-Setting-Free Harmony Search (PSF-HS) algorithm. After setting the overall structure of CNN, hyperparameter was set as a variable and the hyperparameter was optimized by applying PSF-HS algorithm. The simulation was conducted using MATLAB, and CNN learned and tested using mnist data. We update the parameters for a total of 500 times, and it is confirmed that the structure with the highest accuracy among the CNN structures obtained by the proposed method classifies the mnist data with an accuracy of 99.28%."
GPGPU와 Combined Layer를 이용한 필기체 숫자인식 CNN구조 구현,2017,"['기계학습', '스레드', '필기체인식', 'CNN', 'GPGPU', 'MNIST', 'machine learning', 'CNN', 'GPGPU', 'thread', 'Handwriting Recognition', 'MNIST']","CNN(Convolutional Nerual Network)는 기계학습 알고리즘 중에서도 이미지의 인식과 분류에 뛰어난 성능을 보이는 알고리즘 중 하나이다. CNN의 경우 간단하지만 많은 연산량을 가지고 있어 많은 시간이 소요된다. 따라서 본 논문에서는 CNN 수행과정에서 많은 처리시간이 소모되는 convolution layer와 pooling layer, fully connected layer의 연산수행을 SIMT(Single Instruction Multiple Thread)구조의 GPGPU(General-Purpose computing on Graphics Processing Units)를 통하여 병렬로 연산처리를 수행했다. 또한 convolution layer의 출력을 저장하지 않고 pooling layer의 입력으로 바로 사용함으로 메모리 접근횟수를 줄여 성능 향상을 기대했다. 본 논문에서는 이 실험검 증을 위하여 MNIST 데이터 셋을 사용하였고 이를 통하여 제안하는 CNN 구조가 기존의 구조보다 12.38% 더 좋은 성능을 보임을 확인했다.","CNN(Convolutional Nerual Network) is one of the algorithms that show superior performance in image recognition and classification among machine learning algorithms. CNN is simple, but it has a large amount of computation and it takes a lot of time. Consequently, in this paper we performed an parallel processing unit for the convolution layer, pooling layer and the fully connected layer , which consumes a lot of handling time in the process of CNN, through the SIMT(Single Instruction Multiple Thread)'s structure of GPGPU(General-Purpose computing on Graphics Processing Units).And we also expect to improve performance by reducing the number of memory accesses and directly using the output of convolution layer not storing it in pooling layer. In this paper, we use MNIST dataset to verify this experiment and confirm that the proposed CNN structure is 12.38% better than existing structure."
전자부품의 표면 결함 검출을 위한 CNN 기법,2017,"['표면 결함 검출', '전자 부품', 'CNN', '딥러닝', 'Surface Defects Detection', 'Electronic Parts', 'Convoultion Neural Network', 'Deep Learning']","전자 부품의 결함 검사에서 미세한 크랙이나, 표면이 균일하지 않은 경우, 그리고 결함과 주변의 구분이 명확치 않은 조건에서는 검출자 기반의 접근이 성능의 한계를 보이고 있다. 딥러닝 기법이 물체 인식에 널리 적용되고 있으며. 결함 검출에 대해서도 점차 적용이 시도되고 있다. 일반적으로 딥러닝은 방대한 규모의 학습 데이터를 필요로 하나, 일부 산업응용 문제에서는 데이터의 획득이 제한적일 수 있다. 검출 난이도가 높으면서 학습 데이터가 충분하지 않은 전자 부품의 표면 결함 검사에 대해서 딥러닝 접근법의 하나인 CNN을 적용하고 가능성을 검토한다. CNN 기법 외에 Otsu와 Gaussian blur 기법을 CNN에 결합하여 시도하였고, VOV 필터 기반의 데이터 재생성을 통해 데이터를 확충한 기법과 비교하였다. 이를 통해 검출 오류율을 5%까지 감소시킨 결과를 얻을 수 있었다.","A detector based approach shows the degraded performance for defect inspection of electronic parts in particular condition such as a fine crack, non-uniformity, an indiscernible difference between the defects and its surroundings. Deep learning technique is widely used for object recognition and it’s applications to detect defects have been gradually attempted. Deep learning requires huge scale of learning data, but an acquisition of data can be limited in some industrial application. The possibility of applying CNN (Convolution Neural Network), which is one of the deep learning approaches, for surface defect inspection is investigated for electronic parts whose detection difficulty is challenging and learning data is not sufficient. Integrating Otsu and Gaussian Blur method to CNN are experimented. VOV filter based data augmentation method is executed to supplement the insufficient data additionally. As a result, detection error rate is decreased to 5%."
Fire Detection System using Faster R-CNN,2017,"['Convolutional Neural Network', 'Deep Learning', 'Faster R-CNN', 'Fire detection', 'Object detection']",국문 초록 정보 없음,"Various fire detection systems have been constructed to prevent disastrous fire. However, existing fire detection systems are limited to practical applications due to lower detection accuracy and frequent alerts caused by incorrect operations. Previous fire detection systems have only focused on detecting flames. Therefore they can mistake the flames of candles or gas ranges as a fire. They also cannot provide additional life-saving information, such as the location of people or fire extinguishers. Thus, we have tried to construct a new fire detection system which can improve flame detection accuracy, does not incorrectly identify the flame of candles or gas ranges as a fire, and also provide additional lifesaving information.  Faster R-CNN is a deep learning algorithm that detects classes and locations of objects, as well as fires, in real-time by using CNN. We have built our fire detection system based on Faster R-CNN. In order to evaluate the performance of our fire detection system, we used various images such as forest fires, gas range fires, and candle flames. Consequently, the fire detection rate of our system was very good at 99.24%. In addition, we analyzed its object detection performance involving 14 classes, such as people, fire extinguishers, doors, pets, etc. Finally, the mAP (mean Average Precision) was relatively high at 0.7863."
The Research of Face Expression Recognition based on CNN using Tensorflow,2017,"['VGG', 'convolution neural network', 'expression recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep CNN-Based Super-Resolution Using External and Internal Examples,2017,[],국문 초록 정보 없음,"<P>The external example-driven single image super-resolution (SISR) method that uses a deep convolutional neural network (CNN) has exhibited superior performance as compared to previously developed SISR methods. However, the advantages of jointly using external and internal examples on a deep CNN framework have not been sufficiently investigated. In this letter, we present a novel method for single image super-resolution by exploiting a complementary relation between external and internal example-based SISR methods. The proposed deep CNN model consists of two subnetworks, a global residual network and a self-residual network, to utilize the advantages of both external and internal examples. In contrast with conventional joint SISR methods, the proposed method is the first deep CNN-based SISR method that does not require a retraining process, which tends to be inefficient. The proposed method outperformed existing methods in both quantitative and qualitative evaluations.</P>"
계층적 CNN을 이용한 방송 매체 내의 객체 인식 시스템 성능향상 방안,2017,"['컨볼루셔널 뉴럴 네트워크', '딥 러닝', '객체 인식', '풀링', 'T-Commerce', 'Convolutional Neural Network', 'T-Commerce', 'Deep Learning', 'Object Recognition', 'Pooling']",국문 초록 정보 없음,다국어 초록 정보 없음
피부색과 S-LGP와 U-LGP기반 CNN을 이용한 얼굴 검출 알고리즘 연구,2017,"['LBP', 'LGP', 'S-LGP', 'U-LGP', 'symmetry', 'uniform', 'YCbCr', 'XML', 'CNN']",국문 초록 정보 없음,"In this paper, we propose S-LGP and U-LGP based on LGP which is stronger against external factors such as illumination change, facial expression, background, etc. than LBP in order to make the facial recognition exactly. Because LGP has various feature values, it speeds up the complex feature value and extracts specific pattern to improve accuracy by Symmetry method and Uniform method. Then, we learn CNN through a cascaded classification detector that extracts positive and negative facial samples from skin color detection in YCbCr space at 1: 2 ratio. The algorithm proposed in this paper can improve the accuracy of face detection by learning two methods of face detection in CNN. The detection rate of the proposed algorithm is 97% and has higher detection rate than the existing LBP and LGP."
배경모델링과 CNN을 이용한 실시간 피플 카운팅 알고리즘,2017,"['Background Modeling', 'Object tracking', 'Convolutional Neural Network', 'People Counting']",국문 초록 정보 없음,다국어 초록 정보 없음
매니코어 프로세서에서 실시간 실행가능한 CNN(Convolutional Neural Network),2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
<SUP>18</SUP>F-Florbetaben PET 영상 편집을 통해 얻어진 데이터베이스를 사용하여 CNN기반의 치매 영상 학습 및 정확도 측정,2017,"['neural network', 'amyloid', 'alzheimer', 'PET', 'deep learning', 'caffe', 'lmdb']",국문 초록 정보 없음,"Deep Learning has developed various models and algorithms so far. In particular, CNN-based algorithms have shown remarkable effects in image analysis. However, it is important to minimize the unnecessary parts of a picture and to put the database into a file that the computer can recognize. In this study, we constructed a database of Alzheimer ’s disease amyloid PET images and images extracted from the image editing process, which were taken in the hospital, and conducted learning using algorithms based on the CNN program. The accuracy of the learning of the Alzheimer’s disease was measured and compared. As a result of measuring the accuracy by learning the image, we could confirm the accuracy and difference of the image through editing process, and it was able to confirm the accuracy of learning by building big data."
소 부류 객체 분류를 위한 CNN기반 학습망 설계,2017,[],국문 초록 정보 없음,"Recently, deep learning is used for intelligent processing and accuracy improvement of data. It is formed calculation model composed of multi data processing layer that train the data representation through an abstraction of the various levels. A category of deep learning, convolution neural network is utilized in various research fields, which are human pose estimation, face recognition, image classification, speech recognition. When using the deep layer and lots of class, CNN that show a good performance on image classification obtain higher classification rate but occur the overfitting problem, when using a few data. So, we design the training network based on convolution neural network and trained our image data set for object classification in few class problem. The experiment show the higher classification rate of 7.06% in average than the previous networks designed to classify the object in 1000 class problem."
CNN을 활용한 Semantic segmentation 기반의 패션 아이템 검출,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 RNN의 기초 및 응용 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 영화 포스터의 장르 분류,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
휴리스틱 CNN을 이용한 문서 인코딩 판별,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
동영상 분할과 CNN을 이용한 샷 경계 검출 방법,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
비분절 영상에서의 CNN기반 4D 실감효과 구간 검출,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
3차 투영법과 CNN을 이용한 360 비디오 썸네일 생성 방법,2017,"['360Video', 'Cubic Projection', 'Thumbnail Generation', 'Convolutional Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep Learning : CNN과 RNN을 중심으로,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
OpenCL을 이용한 블록기반 CNN의 FPGA 구현,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
동공크기 변화신호의 STFT와 CNN을 이용한 2차원 감성분류,2017,"['Emotion Classification', 'Short-Time Fourier Transform', 'Convolutional Neural Network', 'Arousal-Valence', 'Pupil Size Variation Signal']",국문 초록 정보 없음,다국어 초록 정보 없음
신호등 인식을 위한 CNN기반의 색 검출 방법,2017,"['Traffic light recognition', 'Convolutional Neural Network', 'Color based detection']",국문 초록 정보 없음,다국어 초록 정보 없음
객체의 움직임을 고려한 탐색영역 설정에 따른 가중치를 공유하는 CNN구조 기반의 객체 추적,2017,"['Object Tracking', 'Convolutional Neural Network', 'Search Area', 'Object Movement']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on the Recognition of Face Based on CNN Algorithms,2017,"['CNN algorithms', 'Recognition of Face', 'Deep learning', 'Tensorflow']",국문 초록 정보 없음,"Recently, technologies are being developed to recognize and authenticate users using bioinformatics to solve information security issues. Biometric information includes face, fingerprint, iris, voice, and vein. Among them, face recognition technology occupies a large part. Face recognition technology is applied in various fields. For example, it can be used for identity verification, such as a personal identification card, passport, credit card, security system, and personnel data. In addition, it can be used for security, including crime suspect search, unsafe zone monitoring, vehicle tracking crime.In this thesis, we conducted a study to recognize faces by detecting the areas of the face through a computer webcam. The purpose of this study was to contribute to the improvement in the accuracy of Recognition of Face Based on CNN Algorithms. For this purpose, We used data files provided by github to build a face recognition model. We also created data using CNN algorithms, which are widely used for image recognition. Various photos were learned by CNN algorithm. The study found that the accuracy of face recognition based on CNN algorithms was 77%. Based on the results of the study, We carried out recognition of the face according to the distance. Research findings may be useful if face recognition is required in a variety of situations. Research based on this study is also expected to improve the accuracy of face recognition."
A Study on the Recognition of Face Based on CNN Algorithms,2017,"['CNN algorithms', 'Recognition of Face', 'Deep learning', 'Tensorflow.']",국문 초록 정보 없음,"Recently, technologies are being developed to recognize and authenticate users using bioinformatics to solve information security issues. Biometric information includes face, fingerprint, iris, voice, and vein.Among them, face recognition technology occupies a large part. Face recognition technology is applied in various fields. For example, it can be used for identity verification, such as a personal identification card, passport, credit card, security system, and personnel data.In addition, it can be used for security, including crime suspect search, unsafe zone monitoring, vehicle tr acking crime.In this thesis, we conducted a study to recognize faces by detecting the areas of the face thr ough a computer webcam. The purpose of this study was to contribute to the improvement in the accuracy of Recognition of Face Based on CNN Algorithms. For this purpose, We used data files provided by github to build a face recognition model. We also created data using CNN algorithms, which are widely used for image recognition. Various photos were learned by CNN algorithm. The study found that the accuracy of face recognition based on CNN algorithms was 77%. Based on the results of the study, We carried out recognition of the face according to the distance. Research findings may be useful if face recognition is required in a variety of situations. Research based on this study is also expected to improve the accuracy of face recognition."
CNN 기법을 이용한 저해상도 하수관거의 균열 인식,2017,"['deep learning', 'convolutional neural networks', 'training options', 'sewer', 'low resolution image']",국문 초록 정보 없음,"Deep learning techniques have been studied and developed throughout the medical, agricultural, aviation, and automotive industries. It can be applied to construction fields such as concrete cracks and welding defects. One of the best performing techniques of deep running is CNN technique. CNN means convolutional neural network. In this study, we analyzed crack recognition of sewer with low recognition. Deep learning is generally more accurate with deeper layers, but analysis cost is high. In addition, many variations can occur depending on training options. Therefore, this study performed many parametric studies according to the variations of training options. When analyzed with appropriate training options, the accuracy was over 90% and stable results were obtained"
CNN Output Optimization for More Balanced Classification,2017,"['Convolutional neural networks', 'Image classification', 'Probability optimization']",국문 초록 정보 없음,"This paper proposes a convolutional neural networks (CNN) output optimization method to improve accuracies of low-accuracy classes. Since CNN classifiers are trained by datasets whose data distributions of individual classes are not even or similar, they have always suffered from imbalanced classification performances against classes. In this study, CNN output probabilities are optimized by applying weights and biases as if there is an additional layer after the softmax. We formulated the equations to optimize weights and biases for performance improvement. A na¨ıve optimization did not worked well, so we devised a more elaborated optimization to focus on the competitive probability range and low accuracy classes. As a result, the classification accuracies of lowest 20% classes in accuracy are improved 1.27% on average while maintaining the total accuracy."
3D CNN 기반 회전근개 파열 진단 및 활성화 맵 시각화,2017,"['Rotator Cuff Tear(회전근개 파열)', '3D CNN', 'Class Activation Map(활성화 맵)']",국문 초록 정보 없음,"When diagnosing Rotator Cuff Tear(RCT), magnetic resonance imaging(MRI) scanned 3D data is largely used. Compare to 2D-based medical image, 3D data can offer more detail information and intuitive visualization of patients condition. For example, three-dimensionally visualized MRI volume data of rotator cuff area can reveal not only presence or absence of the rupture, but also clear position and shape of it. However, only 2D-based slice images are used to diagnose RCT without taking advantage of 3D volume at the general medical field. Most of Convolutional Neural Network(CNN)-based medical image diagnosing methods are also using 2D data. We have proposed a RCT diagnosis method using 3D CNN that uses 3D information and take advantages of it to do the same task. The Voxception-Resnet(VRN) network was used to classify if volume has RCT or not. The data was preprocessed and resampled to 64x64x64 volume. and showed about 80 percent of accuracy when diagnosing test data. The 3D Class Activation Map(CAM) was also applied to visualize approximate location and shape of RCT. Our proposed method can automatically diagnose the presence of RCT using 3D data, and also visualize the activation map in 3D.This is less onerous and timeconsuming than using 2D data."
Convolutional Neural Network (CNN) 기반의 단백질 간 상호 작용 추출,2017,"['단백질간 상호작용 추출', '컨볼루션 네트워크', '정보추출', '딥 러닝', '기계학습', 'protein-protein interaction extraction', 'convolutional networks', 'information extraction', 'deep learning', 'machine learning']",본 논문에서는 학술 문헌에서 표현된 단백질 간 상호 작용(Protein-Protein Interaction) 정보를 자동으로 추출하기 위한 확장된 형태의 Convolutional Neural Network (CNN) 모델을 제안한다. 이 모델은 기존에 관계 추출(Relation Extraction)을 위해 고안된 단순 자질 기반의 CNN 모델을 확장하여 다양한 전역 자질들을 추가적으로 적용함으로써 성능을 개선할 수 있는 장점이 있다. PPI 추출 성능 평가를 위해서 많이 활용되고 있는 준거 평가 컬렉션인 AIMed를 이용한 실험에서 F-스코어 기준으로 78.0%를 나타내어 현재까지 도출된 세계 최고 성능에 비해 8.3% 높은 성능을 나타내었다. 추가적으로 CNN 모델이 복잡한 언어 처리를 통한 자질 추출 작업을 하지 않고도 단백질간 상호 작용 추출에 높은 성능을 나타냄을 보였다.,"In this paper, we propose a revised Deep Convolutional Neural Network (DCNN) model to extract Protein-Protein Interaction (PPIs) from the scientific literature. The proposed method has the merit of improving performance by applying various global features in addition to the simple lexical features used in conventional relation extraction approaches. In the experiments using AIMed, which is the most famous collection used for PPI extraction, the proposed model shows state-of-the art scores (78.0 F-score) revealing the best performance so far in this domain. Also, the paper shows that, without conducting feature engineering using complicated language processing, convolutional neural networks with embedding can achieve superior PPIE performance."
Image-based Hand Pose Classification using Faster R-CNN,2017,"['Hand pose', 'deep neural networks', 'Faster R-CNN', 'data augmentation']",국문 초록 정보 없음,"Recently, augmented reality and virtual reality (AR/VR) have been commercialized in game, industry and education fields. For the interaction of a human with virtual objects, hand pose is estimated by using remote controllers or depth sensors. However, using the controllers or sensors are inconvenient or impossible in outdoor environments. AR/VR devices such as smart phones and glasses are equipped with cameras, which are ready to be used in outdoor environments. For such devices to be controlled with human hands in outdoor environments, we propose an image-based hand-pose classification method based on Faster R-CNN. For the training and test of the Faster R-CNN, we newly collected a hand pose dataset with 111,362 images. The dataset consists of images of left hands, which are flipped to generate right hand images, resulting in 6 different classes. Segmented hand regions and their classes are also provided with the dataset. Our model shows mean Average Precision of 95%."
GP-GPU를 이용한 보행자 추론 CNN,2017,"['Pedestrian Inference', 'CNN', 'GP-GPU', 'Multithread', 'SIMT']",국문 초록 정보 없음,"In this paper, we implemented a convolution neural network using GP-GPU. After defining the structure, CNN performed inferencing using the GP-GPU with 256 threads, which was the previous study, using the weight obtained from the training. Training used Intel i7-4470 CPU and Matlab. Dataset used Daimler Pedestrian Dataset. The GP-GPU is controlled by the PC using PCIe and operates as an FPGA. We assigned a thread according to the depth and size of each layer. In the case of the pooling layer, we used over warpping pooling to perform additional operations on the horizontal and vertical regions. One inferencing takes about 12 ms."
CNN 기반 신발갑피 패턴인식 및 점착제 도포를 위한 경로점 생성,2017,"['shoe-upper fuse sewing', 'convex hull algorithm', 'image segmentation', 'canny edge detection', 'convolutional neural network']",국문 초록 정보 없음,"Although the manpower participating in the shoe-upper sewing process is more than 70% of the entire process, there is a shortage of manpower due to the lack of worker skills and the disadvantages of many avoidance processes. Globally, many companies have proposed a way to automate fuse sewing technology to solve this problem. It is necessary to fix the shoe-upper patterns before bonding the shoe-upper in the automated shoe-upper manufacturing process. We propose a method to create a path point for the adhesive application of the vision-based shoe-upper. We conducted experiments using vector images and real images. In the proposed method, the convex hull algorithm is applied to the input image to detect the shoe-upper region. Next, two center points are set in the shoe-upper region and a center line connecting the center points is detected. Then, a grid pattern is formed at regular intervals based on the direction of the center line, and the intersection of the grid pattern is detected. Finally, we removed the outlier of the intersection point of the grid pattern and the intersection points, except for the outlier, were set as the path points of the adhesive and recognized the shoe-upper pattern with 85% accuracy using a convolutional neural network (CNN)."
CNN 과 전이 학습을 이용한 다차선 검출,2017,"['lane detection', 'deep learning', 'convolutional neural networks', 'transfer learning']",국문 초록 정보 없음,"Multi-lane detection is essential in autonomous navigation. Conventional algorithms have difficulties due to diverse image variations caused by illumination variations, occlusions, and shadows. Recently, deep-learning algorithms which use large amounts of training data show dramatic improvements in many areas. In this paper, we address multi-lane detection using convolution neural networks (CNNs) and transfer learning. The CNNs’ architectures are used for the detection of multiple lanes, and transfer the learning using pre-learned models from ImageNet to reduce the learning time. A sliding window is used to detect lane candidates on an image and it requires heavy computation time. We present a method to reduce the detection time by changing the input structure when applying trained networks. Images from KITTI are used for training. Experiments are conducted applying trained networks to images obtained in other environments."
MSERs와 CNN 기반의 실시간 교통표지판 인식,2017,"['Traffic Signs Recognition', 'Dataset bias', 'Convolutional Neural Networks', 'Transfer learning']",국문 초록 정보 없음,"This paper proposes a traffic sign recognition algorithm that is robust in various environments. Color information is an important element in the traffic sign recognition system, as the performance depends on variations in weather conditions, illumination, and type of cameras used. Besides the above factors, traffic signs also differ across countries. To overcome these problems, our approach involves traffic sign detection, classification, and tracking. In the detection module, color enhancement with maximally stable extremal regions is performed to improve the extracting candidate regions of traffic signs. Support vector machine classifiers with distance to border and histogram of oriented gradient feature vectors are used to detect the traffic signs. Detected traffic signs are thereby classified using convolutional neural networks with fine-tuning. Additionally, Kalman filter-based multi-target tracking not only verifies traffic sign detection but also optimizes the detection of regions of interest. The result of traffic sign detection is 95.67% when trained on the Belgium Traffic Signs Dataset for Detection (BTSD) training dataset and tested on the Germany Traffic Signs Detection Benchmark test dataset. Moreover, while using the BTSD training dataset, the area under the curve of our method is 89.56%. In classification, the performance of INHA Traffic Signs Classification is increased to 97.48% by adding transfer learning."
Implementation of a GPU-based vehicle recognition system using a CNN learning algorithm,2017,"['Computer Vision', 'Deep learning', 'CNN', 'Vehicle detection']",국문 초록 정보 없음,"As the demand for vehicles increases in modern society, the necessity of monitoring systems for traffic networks is increasing. This paper proposes a vehicle identification system using a convolution neural network learning algorithm. First, optical flow and Ferns algorithm are used to detect and track vehicles. Vehicles are detected in the region of interest in the image through preprocessing for vehicle detection. Then, a video system is implemented that learns and classifies the features of vehicle images using a GPU-based convolution neural network learning algorithm. Using the proposed algorithm enables obtaining an improved vehicle recognition rate through the recognition of vehicles in an area of interest."
특징벡터클래스 기반 Ferns 알고리즘과 CNN 학습 알고리즘을 이용한 차량 인식 시스템에 관한 연구,2017,"['machine vision', 'ferns', 'CNN(Convolution Neural Network)', 'vehicle detection']",국문 초록 정보 없음,다국어 초록 정보 없음
전방 끼어들기 차량 감지를 위한 Faster R-CNN 적용 연구,2017,"['Cut-in(끼어들기)', 'deep learning(딥러닝)', 'CNN', 'ADAS(운전자보조시스템)', 'Caffe']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 HEVC 루프 필터의 성능 비교,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 알고리즘의 컨볼루션 계층 특성 변화에 따른 메모리 대역폭 요구량 분석,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 PLC 설비에서의 이상 탐지,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN based Mood Mining through IoT-based Physiological Sensors Observation,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
3D CNN 기반 전립선 MRI 영상 분할 기술,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Insight CNN,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
배경 차분과 CNN 기반의 CCTV 객체 검출,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 환경에서의 CNN 기반 FCWS 시스템 구현,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
GPU 기반의 CNN 알고리즘에 대한 메모리 접근패턴 분석,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망(CNN)을 이용한 차선 변경 의도 예측,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
카메라 및 레이더를 이용한 CNN 기반의 다중 객체검출,2022,"['Deep-Learning(딥러닝)', 'Self-Mving(자율주행)', 'Object-Detection(객체검출)', 'Perception(인식)']",국문 초록 정보 없음,다국어 초록 정보 없음
Convolutional Neural Network (CNN)을 이용한 엘니뇨 예측,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
웨어러블 응용을 위한 CNN 기반 손 제스처 인식,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
작은 dataset에 대한 효율적인 CNN 학습방법 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Implementation of Vehicle Recognition System Using Affine Rotation Transform Tracking Framework and CNN Algorithm Base on GPU,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Video identification based on common features in a scene segmented by CNN,2017,"['video identification', 'scene segmentation', 'scale invariant feature transform', 'deep learning', 'convolutional neural network']",국문 초록 정보 없음,"Video fingerprinting is an important issue in the copyright protection field as digital environment enables the copyright infringement to get easier and easier. Copyright owners want to identify contents on the net and to block infringed contents. In this paper, we propose an efficient algorithm to identify video contents even if we only have a video frame. The algorithm divides a video content into scenes using deep learning network and then extracts common feature from a scene. We use deep learning with convolution neural network for video scene segmentation. It can be more precise than traditional method that use histogram. The feature database contains only a set of common features per a scene. The proposed algorithm can reduce the size of the database by a factor of a hundred, which can reduce the database comparison time by a factor of a few."
Video identification based on common features in a scene segmented by CNN,2017,"['video identification', 'scene segmentation', 'scale invariant feature transform', 'deep learning', 'convolutional neural network']",국문 초록 정보 없음,"Video fingerprinting is an important issue in the copyright protection field as digital environment enables the copyright infringement to get easier and easier. Copyright owners want to identify contents on the net and to block infringed contents. In this paper, we propose an efficient algorithm to identify video contents even if we only have a video frame.The algorithm divides a video content into scenes using deep learning network and then extracts common feature from a scene. We use deep learning with convolution neural network for video scene segmentation. It can be more precise than traditional method that use histogram. The feature database contains only a set of common features per a scene. The proposed algorithm can reduce the size of the database by a factor of a hundred, which can reduce the database comparison time by a factor of a few."
Construction of Input Images for Indoor Path Loss Modeling using CNN in Wireless Communication,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
R-CNN 기반 특허 도면 내 도면 부호 인식에 관한 연구,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster R-CNN 기반의 물체 인식 및 심층 신경망 기반의 로봇 파지,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
블랙박스 영상으로부터 도로결함정보 검출을 위한 합성곱 신경망 기반 도로 노면 추출,2017,"['영상 전처리', '도로 차선 감지', '도로 노면 추출', '블랙박스 영상']",국문 초록 정보 없음,다국어 초록 정보 없음
다차원 도로정보 구축을 위한 MMS 노이즈 자동제거 알고리즘,2017,"['MMS', 'Deep Learning', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
컨볼루션 신경망과 AAE를 이용한 이미지 클러스터링,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
조합 스펙트로그램 기반 컨볼루션 신경망을 이용한 다중 전원 신호들에 대한 이상 현상 검출,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반 클라이언트 위성의 부분품 인식 기법 연구,2017,"['On orbit service(궤도상 서비스)', 'Proximity-operation(근접운용)', 'image recognition(영상인식)', 'Convolutional Neural Network(합성곱 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
워드임베딩과 텍스트 합성곱 신경망을 이용한 강의평가 감정 분석,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
패치기반 컨볼루션 뉴럴 네트워크 특징을 이용한 위조지문 검출,2017,"['fingerprint liveness detection', 'CNN', 'fake fingerprint detection', 'presentation attack']","최근 모바일 기기에서의 생체인증 시스템의 증가와 출입관리 시스템에서의 위조지문을 이용한 출입 기록 조작으로 인해 위조 지문 검출에 대한 논의가 다시 활발해지고 있다. 본 논문에서는 입력 지문영상을 패치들로 나누고, 각 패치들에 CNN을 적용하여 위조, 생체, 배경의 세 가지로 분류한다. 이 중 배경으로 분류된 패치들을 제외하고 위조와 생체로 분류된 패치들의 수를 세어서 더 많은 패치가 인식된 쪽으로 위조여부를 판단하게 된다. CNN에 배경 클래스를 추가하여 분류하기 때문에, 제안하는 방법은 영상분할과 같은 추가적인 전처리 과정이 필요하지 않다. 제안하는 방법은 LivDet2011, LivDet2013, LivDet2015에 대하여 실험을 진행하였으며 분류결과 3.06%의 평균 오검출을 보여 매우 우수한 성능을 나타냄을 확인하였다.","Nowadays, there have been an increasing number of illegal use cases where people try to fabricate the working hours by using fake fingerprints. So, the fingerprint liveness detection techniques have been actively studied and widely demanded in various applications. This paper proposes a new method to detect fake fingerprints using CNN (Convolutional Neural Ntworks) based on the patches of fingerprint images. Fingerprint image is divided into small square sized patches and each patch is classified as live, fake, or background by the CNN. Finally, the fingerprint image is classified into either live or fake based on the voting result between the numbers of fake and live patches. The proposed method does not need preprocessing steps such as segmentation because it includes the background class in the patch classification. This method shows promising results of 3.06% average classification errors on LivDet2011, LivDet2013 and LivDet2015 dataset."
20세기 전기 유성기 연극에 나타난 상대높임법 사용 양상 -언어 외적 요인에 따른 상대높임법 사용을 중심으로-,2023,"['addressee honorific', 'gramophone play', 'former part of 20th century', 'gender', 'social status', 'age', '상대높임법', '유성기 연극', '20세기 전기', '성별', '사회적 지위', '연령']",국문 초록 정보 없음,.
딥러닝 기반의 초분광영상 분류를 사용한 환경공간정보시스템 활용,2017,"['Deep Learning', 'Convolutional Neural Network', 'Hyperspectral image', 'Classification']","본 연구는 4차 산업의 핵심기술인 인공지능과 환경공간정보의 융합을 통한 정보생산 및 활용가능성을 제시하고자 대표적인 딥러닝(deep-learning) 기법인 CNN(Convolutional Neural Network)을 이용한 영상분류를 수행하였다. CNN은 학습을 통해 스스로 분류기준에 따른 커널의 속성을 결정하며, 최적의특징영상(feature map)을 추출하여 화소를 분류한다. 본 연구에서는 CNN network를 구성하여 기존의 영상처리 기법으로 해결이 어려웠던 분광특성이 유사한 물질간의 분류 및 GIS속성정보에 따른 분류를 수행하였으며, 항공초분광센서인 CASI(Compact Airborne Spectrographic imager)와 AISA(Airborne Imaging Spectrometer for Application)로 취득된 영상을 이용하였다. 실험대상지역은 총 3곳이며, Site 1과 Site 2 는 감자, 양파, 벼 등의 다양한 농작물을 포함하며, Site 3는 단독주거시설, 공동주거시설 등 세분류 토지피복도의 분류 항목으로 구성된 건물을 포함한다. 실험결과, 분류 정확도 96%, 99%로 농작물을 종류에 따라분류하였으며, 96%의 정확도로 건물을 용도에 따라 분류하였다. 본 연구의 결과를 환경공간정보 서비스에활용하기 위하여 계절별 농작물의 종류를 제공할 수 있는 환경주제도를 제안하였으며, 기존의 토지피복도와최신 GIS자료를 이용한 세분류 토피지복도 제작 및 갱신 가능성을 확인하였다.","In this study, images were classified using convolutional neural network (CNN)—a deep learning technique—to investigate the feasibility of information production through a combination of artificial intelligence and spatial data. CNN determines kernel attributes based on a classification criterion and extracts information from feature maps to classify each pixel. In this study, a CNN network was constructed to classify materials with similar spectral characteristics and attribute information; this is difficult to achieve by conventional image processing techniques. A Compact Airborne Spectrographic Imager (CASI) and an Airborne Imaging Spectrometer for Application (AISA) were used on the following three study sites to test this method: Site 1, Site 2, and Site 3. Site 1 and Site 2 were agricultural lands covered in various crops, such as potato, onion, and rice. Site 3 included different buildings, such as single and joint residential facilities. Results indicated that the classification of crop species at Site 1 and Site 2 using this method yielded accuracies of 96% and 99%, respectively. At Site 3, the designation of buildings according to their purpose yielded an accuracy of 96%. Using a combination of existing land cover maps and spatial data, we propose a thematic environmental map that provides seasonal crop types and facilitates the creation of a land cover map."
사람 재 식별을 위한 딥 피쳐를 사용한 보행자 파트 분석,2017,"['딥 기능', '사람 재식별', '이미지검색', '콘텐츠 기반 검색', 'Deep features', 'Person re-identification', 'Image retrieval', 'Content-based search']","컴퓨터 비전에서 사람을 재 식별하는 것은 지능형 감시 시스템 만드는데 있어 어려운 작업 중 하나이다. 사람 재 식별 시스템의 최신 기술은 여전히 HOG, SIFT, SURF, LBP 와 같은 전통적인 피처추출에 의존하고 있다. 본 연구에서는 감시영상에서 사람 식별을 위한 CNN(Convolution Neural Network)을 활용방안에 대해 제시한다. 우선CNN모델을 이용하여 re-id 데이터 셋을 학습한다. 그 다음 보행자 이미지를 상반신 하반신 두 부분으로 나누어 윗옷과 바지를 감시한다. 그리고 CNN으로 학습한 모델을 사용하여 두 부분의 특징을 추출한다. 유사도는 선택된 이미지와 데이터 셋 안의 이미지들과의 유클리드 거리를 활용하여 계산한다. ETHZ, CUHK, Market 데이터 셋을사용한 최신기술과 비교하였을 때 리콜값과 CMC(Cumulative Match Characteristic) 값에서 더 높은 성능으로나온 것을 확인 할 수 있다.","In computer vision, person re-identification is a challenging task in the context of making intelligent surveillance system. State-of-the-art techniques in person re-identification systems still rely on traditional features extraction such as HOG, SIFT, SURF, and LBP etc. In this study we present convolution neural network (CNN) features to represent persons in surveillance streams. Firstly, we trained a CNN model using person re-id dataset. Secondly, we divide pedestrian images into upper and lower body parts, keeping in view the format of clothing used to cover upper and lower parts. Further, we have extracted CNN features for both parts using the trained model. Similarity score is computed as Euclidean distance between query image and other images in the dataset. We succeeded to achieve higher precision scores on various recall levels, as well as higher Cumulative Match Characteristic (CMC) performance scores compared to other state-of-the-art techniques on ETHZ, CUHK, and Market datasets."
합성곱 신경망 연산 처리를 위한 ALU 설계,2017,"['합성곱 신경망', 'IPU', 'TPU', '수정 Booth 곱셈기', 'MNIST', 'CNN', 'IPU(Intelligent Processing Unit)', 'TPU', 'MBM(Modified Booth Multiplier)', 'MNIST']",이미지 인식 분야에서 탁월한 성능을 보이는 합성곱 신경망 CNN(Convolution Neural Network) 알고리즘은 많은 양의 연산 처리를 필요로 하고 있으며 데이터 학습이 누적될 때 마다 많은 학습 시간이 소요된다. 그러한 문제점을 해결하고자 최근에 들어 기존 CPU 및 GPU보다 수 배에서 수십 배 높은 신경 네트워크 연산을 가속화하려는 연구가 활발이 이루어져 다양한 IPU 및 TPU가 개발되고 있다. 본 논문에서는 CNN의 다중 곱셈과 덧셈을 효과적으로 계산하기 위한 ALU를 제안한다. ALU설계는 Verilog HDL을 사용하여 Xilinx VC-707 FPGA 보드에 구현하였다. 8비트 수정 Booth 곱셈기 25개를 정방행렬 구조로 설계하였으며 클럭당 200비트를 처리하게 하였다. 연산속도 향상을 위하여 연산기는 파이프라이닝을 이용한 병렬처리를 하였다. 실험은 MNIST의 숫자 이미지 데이터베이스를 대상으로 GPU와 제안한 구조를 비교하여 합성곱 신경망 처리 연산 시간을 측정하여 성능 검증 확인하였다.,"The CNN algorithm exhibits excellent performance in image recognition but requires a large amount of computation processing and requires a lot of learning time each time data learning is accumulated. To solve such problems, recently various IPU and TPU have been develop to accelerate the neural network operation which is several times to several tens times faster than conventional CPU and GPU. In this paper, we propose an ALU for efficient multiplication and addition of CNN. ALU design was implemented on the Xilinx VC-707 FPGA board using Verilog HDL. Twenty five 8bit modified booth multipliers were designed with a square matrix structure and processed 200 bits per clock. In order to improve the computation speed, the arithmetic unit performs parallel processing using pipelining. Experiments were performed to verify the performance of the GPU and proposed structure MNIST 's numerical image database by comparing and measuring the computation time of the composite neural network processing."
합성곱 신경망의 학습 가속화를 위한 방법,2017,"['합성곱', '맥스 풀링', 'CNN', 'CUDA', 'GPGPU', 'Convolutional Neural Network', 'Convolution', 'Max pooling', 'CUDA', 'GPGPU']",최근 CNN(Convolutional Neural Network)의 구조가 복잡해지고 신견망의 깊이가 깊어지고 있다. 이에 따라 신 경망의 학습에 요구되는 연산량 및 학습 시간이 증가하게 되었다. 최근 GPGPU 및 FPGA를 이용하여 신경망의 학습 속도를 가속화 하는 방법에 대한 연구가 활발히 진행되고 있다. 본 논문에서는 NVIDIA GPGPU를 제어하는 CUDA 를 이용하여 CNN의 특징추출부와 분류부에 대한 연산을 가속화하는 방법을 제시한다. 특징추출부와 분류부에 대한 연산을 GPGPU의 블록 및 스레드로 할당하여 병렬로 처리하였다. 본 논문에서 제안하는 방법과 기존 CPU를 이용하 여 CNN을 학습하여 학습 속도를 비교하였다. MNIST 데이터세트에 대하여 총 5 epoch을 학습한 결과 제안하는 방 법이 CPU를 이용하여 학습한 방법에 비하여 약 314% 정도 학습 속도가 향상된 것을 확인하였다.,"Recently, Training of the convolutional neural network (CNN) entails many iterative computations. Therefore, a method of accelerating the training speed through parallel processing using the hardware specifications of GPGPU is actively researched. In this paper, the operations of the feature extraction unit and the classification unit are divided into blocks and threads of GPGPU and processed in parallel. Convolution and Pooling operations of the feature extraction unit are processed in parallel at once without sequentially processing. As a result, proposed method improved the training time about 314%."
Classification Algorithms for Human and Dog Movement Based on Micro-Doppler Signals,2017,"['Moving object classification', 'UWB', 'SVM', 'CNN', 'AR spectrogram']",국문 초록 정보 없음,"We propose classification algorithms for human and dog movement. The proposed algorithms use micro-Doppler signals obtained from humans and dogs moving in four different directions. A two-stage classifier based on a support vector machine (SVM) is proposed, which uses a radial-based function (RBF) kernel and 16<SUP>th</SUP>-order linear predictive code (LPC) coefficients as feature vectors. With the proposed algorithms, we obtain the best classification results when a first-level SVM classifies the type of movement, and then, a second-level SVM classifies the moving object. We obtain the correct classification probability 95.54% of the time, on average. Next, to deal with the difficult classification problem of human and dog running, we propose a twolayer convolutional neural network (CNN). The proposed CNN is composed of six (6x6) convolution filters at the first and second layers, with (5x5) max pooling for the first layer and (2x2) max pooling for the second layer. The proposed CNN-based classifier adopts an auto regressive spectrogram as the feature image obtained from the 16<SUP>th</SUP>-order LPC vectors for a specific time duration. The proposed CNN exhibits 100% classification accuracy and outperforms the SVM-based classifier. These results show that the proposed classifiers can be used for human and dog classification systems and also for classification problems using data obtained from an ultrawideband (UWB) sensor."
Comparison of Fine-Tuned Convolutional Neural Networks for Clipart Style Classification,2017,"['Clipart Classification', 'Convolutional neural network', 'Computer vision', 'Clipart', 'style search', 'Finetuning', 'Deep learning']",국문 초록 정보 없음,"Clipart is artificial visual contents that are created using various tools such as  Illustrator to highlight some information. Here, the style of the clipart plays a critical role in determining how  it looks. However, previous studies on clipart are focused only on the object recognition [16],  segmentation, and retrieval of clipart images using hand-craft image features. Recently, some clipart classification  researches based on the style similarity using CNN have been proposed, however, they have used different  CNN-models and experimented with different benchmark dataset so that it is very hard to compare  their performances. This paper presents an experimental analysis of the clipart classification based on the  style similarity with two well-known CNN-models (Inception Resnet V2 [13] and VGG-16 [14] and transfers  learning with the same benchmark dataset (Microsoft Style Dataset 3.6K). From this experiment, we find out  that the accuracy of Inception Resnet V2 is better than VGG for clipart style classification because of its  deep nature and convolution map with various sizes in parallel. We also find out that the end-to-end  training can improve the accuracy more than 20% in both CNN models."
영상기반의 딥러닝을 활용한 드론-실내고도유지 알고리즘 개발,2017,"['드론', '자율고도주행', '딥러닝']","드론의 시장규모가 커짐에 따라 초창기 군사 목적에서 현재 민간부문으로 확대되고 있다. 현재 드론은 실외에서 사용될 목적으로 제작된 것이 많으나 실내에서도 드론의 활용 여부가 증가할 것으로 예상된다. 본 연구에서는 실외에서만 사용 가능한 GPS를 대신하여 영상 촬영으로 획득한 이미지를 CNN으로 학습을 시켜 자율고도제어비행을 하도록 한다.첫 번째로 수동 조작하는 드론에 IMU센서를 부착하여 획득한 고도 데이터를 표로 제시함으로써 GPS를 사용하지 않는 드론의 실내주행에서 일정한 고도 유지는 다소 무리가 있음을 보여준다.두 번째로 드론의 수동 조작은 일정하지 않은 고도 때문에 CNN의 학습할 영상 획득이 어렵다. 일정한 고도의 영상 획득을 위한 실험용 높이 조절 Base를 제작하여 고도별 영상을 획득한다. 획득한 영상을 통해 얻은 이미지를 CNN 학습을 시킨 후, 학습에 사용되지 않은 이미지를 사용하여 고도 판별을 확인한다. 대조군으로 실내장소를 바꾸어 미리 학습된 CNN으로 고도 판별을 확인한다. 학습에 사용된 이미지의 환경(생명공학관)과 대조군(제 2 공학관)이 촬영된 장소의 환경요소의 차이로 오차가 발생한다. 오차는 실내 장소의 총 높이의 차이 및 서로 상이한 천장 구조물에 따른 것으로 사료되며 Data crop을 통해 획득한 이미지의 천정 부분을 제거하여 노이즈를 줄여 고도 판별의 정확도를 높일 수 있을 것으로 예상한다.세 번째, CNN으로 학습을 통해 Model을 도출하여 자율 고도 제어 프로세스를 제시한다. 그리고 해당프로세스를 이용한 자율고도제어 주행과 수동조작을 통한 주행에서의 Z축 가속도 데이터의 표준편차를 비교하여 본 연구의 실효성을 보여준다.",다국어 초록 정보 없음
GPGPU 기반 Convolutional Neural Network의 효율적인 스레드 할당 기법,2017,"['Convolutional Neural Network', 'GPGPU', 'SIMT', 'Convolution layer', 'Pooling layer', 'Convolutional Neural Network', 'GPGPU', 'SIMT', '컨볼루션 레이어', '풀링 레이어']",많은 양의 데이터 기반으로 학습하는 neural network 중 이미지 분류나 음성 인식 등에 사용되어 지고 있는 CNN(Convolution neural network)는 현재까지도 우수한 성능을 가진 구조로 계속적으로 발전되고 있다. 제한된 자원을 가진 임베디드 시스템에서 활용하기에는 많은 어려움이 있다. 그래서 미리 학습된 가중치를 사용하지만 여전히 한계점이 있기 때문에 이를 해결하기 위해 GPU의 범용 연산을 위해서 사용하는 GP-GPU(General-Purpose computing on Graphics Processing Units)를 활용하는 추세다. CNN은 단순하고 반복적인 연산을 수행하기 때문에 SIMT(Single Instruction Multiple Thread)기반의 GPGPU에서 스레드 할당과 활용 방법에 따라 연산 속도가 많이 달라진다. 스레드로 Convolution 연산과 Pooling 연산을 수행할 때 쉬어야 하는 스레드가 발생하는 데 이러한 문제를 해결하기 위해 남은 스레드가 다음 피쳐맵과 커널 계산에 활용되는 방법을 사용함으로써 연산 속도를 증가시켰다.,"CNN (Convolution neural network), which is used for image classification and speech recognition among neural networks learning based on positive data, has been continuously developed to have a high performance structure to date. There are many difficulties to utilize in an embedded system with limited resources. Therefore, we use GPU (General-Purpose Computing on Graphics Processing Units), which is used for general-purpose operation of GPU to solve the problem because we use pre-learned weights but there are still limitations. Since CNN performs simple and iterative operations, the computation speed varies greatly depending on the thread allocation and utilization method in the Single Instruction Multiple Thread (SIMT) based GPGPU. To solve this problem, there is a thread that needs to be relaxed when performing Convolution and Pooling operations with threads. The remaining threads have increased the operation speed by using the method used in the following feature maps and kernel calculations."
그레이스케일 영상의 병렬가산 컨볼루션 알고리즘,2017,"['Chip Design', 'Convolution', 'CNN', 'Deep Learning', 'Parallel-Addition', 'Processing Time']","최근들어 CNN(Convolutional Neural Network)을 이용한 딥러닝 기술이 영상인식 등의 분야에서 널리 활용되고 있다. CNN에서 승산과 가산으로 수행되는 컨볼루션 처리는 단순한 연산이지만 하드웨어로 구현하는 데 문제가 되는 것은 승산을 수행하는데 필요한 계산시간이다. 컴퓨팅 파워의 사용에 문제가 없는 응용분야에서는 문제가 되지 않지만 임베디드용 딥러닝 시스템 등의 구현을 위한 하드웨어 칩설계에서는 많은 제한이 있다. 따라서 본 논문에서는 그레이스케일 영상을 2진영상의 중첩으로 표현한 후, 병렬로 가산만을 이용하여 컨볼루션을 수행하는 병렬가산 알고리즘을 제안하였다. 본 논문에서 새롭게 제안한 알고리즘의 유용성을 확인하기 위한 실험을 통해 처리시간의 감소가 가능한 병렬가산 방식으로 컨볼루션을 수행할 수 있음을 확인하였다.","Recently, deep learning using convolutional neural network (CNN) has been extensively studied in image recognition. Convolution consists of addition and multiplication. Multiplication is computationally expensive in hardware implementation, relative to addition. It is also important factor limiting a chip design in an embedded deep learning system. In this paper, I propose a parallel -addition processing algorithm that converts grayscale images to the superposition of binary images and performs convolution only with addition. It is confirmed that the convolution can be performed by a parallel-addition method capable of reducing the processing time in experiment for verifying the availability of proposed algorithm."
Energy-Efficient Design of Processing Element for Convolutional Neural Network,2017,[],국문 초록 정보 없음,"<P>Convolutional neural network (CNN) is the most prominent algorithm for its wide usage and good performance. Despite the fact that the processing element (PE) plays an important role in CNN processing, there has been no study focusing on PE design optimized for state-of-the-art CNN algorithms. In this brief, we propose an optimal PE implementation including a data representation scheme, circuit block configurations, and control signals for energy-efficient CNN. To validate the excellence of this brief, we compared our proposed design with several previous methods, and fabricated a silicon chip. The software simulation results demonstrated that we can reduce 54% of data bit lengths with negligible accuracy loss. Our optimization on PE achieves to save computing power up to 47%, and an accelerator exploiting our method shows superior results in terms of power, area, and external DRAM access.</P>"
딥러닝을 이용한 영상 수평 보정,2017,"['영상 수평 보정', '딥러닝', '다중 스케일 특징', 'horizon correction', 'deep learning', 'multi-scale features']","본 논문은 딥 러닝(deep learning)을 이용하여 입력 영상의 기울어진 정도를 측정하고 수평에 맞게 바로 세우는 방법을 제시한다. 기존 방법들은 일반적으로 영상 내에서 선분, 평면 등 하위 레벨의 특징들을 추출한 후 이를 이용해 영상의 기울어진 정도를 측정한다. 이러한 방법들은 영상 내에 선이나 평면이 존재하지 않는 경우에는 제대로 동작하지 않는다. 본 논문에서는 대규모 데이터 셋을 통해 영상의 다양한 특징들에 대해 학습 가능한 Convolutional Neural Network (CNN)를 이용하여 인물이나 복잡한 배경으로 구성된 기울어진 영상에 대해서도 강인하게 동작하는 프레임워크를 제시한다. 또한, 네트워크에 가변 공간적 (adaptive spatial) pooling 레이어를 추가하여 영상의 다중 스케일 특징을 동시에 고려할 수 있게 하여 영상의 기울어진 정도를 측정하는 성능을 높인다. 실험 결과를 통해 다양한 콘텐츠를 포함한 영상의 기울어짐을 높은 정확도로 바로 세울 수 있음을 확인할 수 있다.","Horizon correction is a crucial stage for image composition enhancement. In this paper, we propose a deep learning based method for estimating the slanted angle of a photograph and correcting it. To estimate and correct the horizon direction, existing methods use hand-crafted low-level features such as lines, planes, and gradient distributions. However, these methods may not work well on the images that contain no lines or planes. To tackle this limitation and robustly estimate the slanted angle, we propose a convolutional neural network (CNN) based method to estimate the slanted angle by learning more generic features using a huge dataset. In addition, we utilize multiple adaptive spatial pooling layers to extract multi-scale image features for better performance. In the experimental results, we show our CNN-based approach robustly and accurately estimates the slanted angle of an image regardless of the image content, even if the image contains no lines or planes at all."
Comparison of Fine-Tuned Convolutional Neural Networks for Clipart Style Classification,2017,"['Clipart Classification', 'Convolutional neural network', 'Computer vision', 'Clipart', 'style search', 'Fine tuning', 'Deep learning']",국문 초록 정보 없음,"Clipart is artificial visual contents that are created using various tools such as Illustrator to highlight some information. Here, the style of the clipart plays a critical role in determining how it looks. However, previous studies on clipart are focused only on the object recognition [16], segmentation, and retrieval of clipart images using hand-craft image features. Recently, some clipart classification researches based on the style similarity using CNN have been proposed, however, they have used different CNN-models and experimented with different benchmark dataset so that it is very hard to compare their performances. This paper presents an experimental analysis of the clipart classification based on the style similarity with two well-known CNN-models (Inception Resnet V2 [13] and VGG-16 [14] and transfers learning with the same benchmark dataset (Microsoft Style Dataset 3.6K). From this experiment, we find out that the accuracy of Inception Resnet V2 is better than VGG for clipart style classification because of its deep nature and convolution map with various sizes in parallel. We also find out that the end-to-end training can improve the accuracy more than 20% in both CNN models."
Comparison of Fine-Tuned Convolutional Neural Networks for Clipart Style Classification,2017,"['Clipart Classification', 'Convolutional neural network', 'Computer vision', 'Clipart', 'style search', 'Fine tuning', 'Deep learning']",국문 초록 정보 없음,"Clipart is artificial visual contents that are created using various tools such as Illustrator to highlight some information. Here, the style of the clipart plays a critical role in determining how it looks. However, previous studies on clipart are focused only on the object recognition [16], segmentation, and retrieval of clipart images using hand-craft image features. Recently, some clipart classification researches based on the style similarity using CNN have been proposed, however, they have used different CNN-models and experimented with different benchmark dataset so that it is very hard to compare their performances. This paper presents an experimental analysis of the clipart classification based on the style similarity with two well-known CNN-models (Inception Resnet V2 [13] and VGG-16 [14] and transfers learning with the same benchmark dataset (Microsoft Style Dataset 3.6K). From this experiment, we find out that the accuracy of Inception Resnet V2 is better than VGG for clipart style classification because of its deep nature and convolution map with various sizes in parallel. We also find out that the end-to-end training can improve the accuracy more than 20% in both CNN models."
조건부 랜덤 필드와 컨볼루션 신경망을 이용한 의미론적인 객체 분할 방법,2017,"['Segmentation', 'Semantic Segmentation', 'Convolutional Neural Network', 'Conditional Random Field', 'Fully Convolutional Neural Network\r\n분할', '의미론적 분할', '컨볼루션 신경망', '조건부 랜덤 필드', '풀리 컨볼루션 신경망']","컴퓨터비전에서 가장 기본적이고, 복잡한 문제를 수반하는 의미론적 분할(Semantic segmentation)은 이미지의 각 픽셀을 특정 객체로 분류하며, 레이블(label)을 지정하는 작업을 수행한다. 기존에 연구되어온 확률적 그래프 모델인 MRF와 CRF는 픽셀 수준의 라벨링 작업의 정확도를 높이는 효과적인 방법으로 연구되어왔다.본 논문에서는 최근 각광받고 있는 딥러닝의 한 부류인 CNN과 확률 모델인 CRF를 결합한 형태의 의미론적 분할 방법을 제안하였다. 학습과 성능 검증을 위하여 Pascal VOC 2012 이미지 데이터베이스를 사용하였고, 학습에 사용되지 않은 임의의 이미지를 이용하여 테스트를 진행 하였다. 연구의 결과로서 기존 의미론적 분할 알고리즘보다 더욱 뛰어난 분할 성능을 보여주었다.","Semantic segmentation, which is the most basic and complicated problem in computer vision, classifies each pixel of an image into a specific object and performs a task of specifying a label. MRF and CRF, which have been studied in the past, have been studied as effective methods for improving the accuracy of pixel level labeling. In this paper, we propose a semantic partitioning method that combines CNN, a kind of deep running, which is in thespotlight recently, and CRF, a probabilistic model. For learning and performance verification, Pascal VOC 2012 image database was used and the test was performed using arbitrary images not used for learning. As a result of the study, we showed better partitioning performance than existing semantic partitioning algorithm."
합성곱 신경망 기반 야간 차량 검출 방법,2017,"['Night-time vehicle detection', 'Convolutional neural network', 'Head-lamp detection', 'Rear-lamp detection']",국문 초록 정보 없음,"In this paper, we present a night-time vehicle detection method using CNN (Convolutional Neural Network) classification. The camera based night-time vehicle detection plays an important role on various advanced driver assistance systems (ADAS) such as automatic head-lamp control system. The method consists mainly of thresholding, labeling and classification steps. The classification step is implemented by existing CIFAR-10 model CNN. Through the simulations tested on real road video, we show that CNN classification is a good alternative for night-time vehicle detection."
의사 형태학적 연산을 사용한 이미지 변환,2017,[],국문 초록 정보 없음,"We attempt to combines concepts of Morphological Operator(MO) and Convolutional Neural Networks (CNN) to improve image-to-image translation. To do this, we propose an operation that approximates morphological operations. Also we propose S-Convolution, an operation that extends the operation to use multiple filters like CNN. The experiment result shows that it can learn MO with big filter using multiple S-convolution layer of small filter. To validate effectiveness of the proposed layer in image-to-image translation we experiment with GAN with S- convolution applied. The result showed that GAN with S-convolution can achieve distinct result from that of GAN with CNN."
주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식,2017,[],국문 초록 정보 없음,"In this paper, we propose a speech emotion recognition method using a deep neural network based on the attention mechanism. The proposed method consists of a combination of CNN (Convolution Neural Networks), GRU (Gated Recurrent Unit), DNN (Deep Neural Networks) and attention mechanism. The spectrogram of the speech signal contains characteristic patterns according to the emotion. Therefore, we modeled characteristic patterns according to the emotion by applying the tuned Gabor filters as convolutional filter of typical CNN. In addition, we applied the attention mechanism with CNN and FC (Fully-Connected) layer to obtain the attention weight by considering context information of extracted features and used it for emotion recognition. To verify the proposed method, we conducted emotion recognition experiments on six emotions. The experimental results show that the proposed method achieves higher performance in speech emotion recognition than the conventional methods."
딥러닝을 이용한 SAR영상 목표물 인식 연구 동향,2017,[],"다양한 컴퓨터 비전 문제들에서 딥러닝을 활용한 알고리즘들이 괄목할만한 성능을 보여주었고, 이에 따라서Synthetic Aperture Radar (SAR) 영상 목표물 인식을 위해 딥러닝 기법을 활용하는 연구들이 진행되어 왔다[1]-[5]. 본고에서는 딥러닝을 이용한 SAR영상 목표물 인식을 위한 연구 동향에 대해 조사하였다.  SAR(합성개구레이다)레이다는 짧은 파장의 Chirp 신호 같은 펄스 전자파를 대상 지역(영역)에 보내고 그 지역의 구조물 특성에 의해 결정되는 반사파를 레이다 안테나로 다시 수신하여 돌아오는 시간과 강도를 측정하여 영상을 구성하는 레이다 시스템이다. SAR 시스템은 날씨와 시간 조건에 상관없이 2차원 영상을 획득하는 것이 가능하기 때문에 주로 감시정찰 분야에 많이 활용되어 왔다.  자연영상의 경우와 달리 SAR영상은 획득과정이 매우 어렵고 시간과 비용이 많이 소요된다. 따라서, 획득된 데이터는 우리가 일반적으로 구할 수 있는 자연영상과는 비교 할 수 없을 정도로 양이 제한되어 있다. 특정 지역 및 목표물 등에 대한 SAR 데이터는 기밀사항으로 분류되어 접근이 제한되어 있는 경우가 많다.  최근 영상 인식 분야에서 괄목할 만한 성능 향상을 보인 딥러닝 기반 콘볼루션 뉴럴 네트워크(CNN: Convolution Neural Network)를 SAR 영상 분류 응용에 활용하는 연구가 활발히 진행되고 있다[1]-[5]. 기본적으로 많은 필터를 사용하여 특징 추출 및 특징 매핑, 특징 분류를 하나의 통합된 시스템에서 학습과정을 필터 파라미터 및 네트워크 연결 파라미터를 구하는 과정은 많은 훈련 데이터가 필요하다. 그러나 SAR 영상의 경우 전술한 바와 같이 영상 획득과정에 많은 비용과 시간이 소요되기 때문에 충분한 학습데이터를 확보하는 것이 매우 어렵고, 제한적인 데이터를 활용하여 CNN 기반 SAR 영상 인식 시스템을 학습하는 것은 과적합(over-fitting) 문제를 야기시킨다. SAR 영상 목표물 인식을 위하여 과적합문제를 해결하면서 딥러닝을 활용하는 알고리즘들이 연구되었다.  Chen은 auto-encoder를 활용하여 효율적으로 특징을 추출함으로써 SAR영상 목표물 인식 네트워크의 과적합문제를 해결하고자 하였다[1]. Li는 layer-by-layer 비지도 학습을 통하여 과적합문제를 완화하면서 깊은 네트워크를 학습시켰다[2]. Dong의 경우는 SAR영상을 위한 데이터 증대(data augmentation) 알고리즘을 고안하였고, 새로 생성된 많은 수의 학습데이터를 이용하여 깊은 네트워크를 학습시켜 높은 인식 성능을 보여주었다[3]. Chen은 CNN의 대부분의 학습 파라미터가 완전 연결층(fully connected (FC) layer)에서 발생한다는 점에 착안하여, 모든 계층이 콘볼루션(convolution) 계층인 A-Convnet을 고안하였다[4]. A-Convnet은 적은 수의 파라미터로 효율적인 특징 추출이 가능하여 높은 인식률을 보여주었다. 또한, Youm의 경우에는 통합된 하나의 네트워크가 다양한 편광(polarization) 타입의 SAR영상을 인식하게 학습할 수 있는 input scaling 알고리즘을 고안하였다[5]. Input scaling은 특징맵의 크기를 polarization 수에 변화에 강인하게 만들었으며, 이는 안정적인 네트워크 학습을 가능하게 하고, polarization간의 상관관계를 활용하게 하여 높은 인식률을 가지는 네트워크 학습을 가능하게 하였다.",다국어 초록 정보 없음
감성 분석을 위한 어휘 통합 합성곱 신경망에 관한 연구,2017,[],"최근 딥러닝의 발달로 인해 Sentiment analysis분야에서도 다양한 기법들이 적용되고 있다. 이미지, 음성인식 분야에서 높은 성능을 보여주었던 Convolutional Neural Networks (CNN)은 최근 자연어처리 분야에서도 활발하게 연구가 진행되고 있으며 Sentiment analysis에도 효과적인 것으로 알려져 있다. 기존의 머신러닝에서는 lexicon을 이용한 기법들이 활발하게 연구되었지만 word embedding이 등장하면서 이러한 시도가 점차 줄어들게 되었다. 그러나 lexicon은 여전히 sentiment analysis에서 유용한 정보를 제공한다. 본 연구에서는 SemEval 2017 Task4에서 제공한 Twitter dataset과 다양한 lexicon corpus를 사용하여 lexicon을 CNN과 결합하였을 때 모델의 성능이 얼마큼 향상되는지에 대하여 연구하였다. 또한 word embedding과 lexicon이 미치는 영향에 대하여 분석하였다. 모델을 평가하는 metric은 positive, negative, neutral 3가지 class에 대한 macroaveraged F1 score를 사용하였다.",다국어 초록 정보 없음
딥러닝 기반의 웨어러블 디바이스에서의 제스처 인식,2017,[],"본 연구는 비접촉식 센서 기반의 웨어러블 디바이스를 이용한 딥러닝 기반의 제스처 인식에 대한 연구이다. 이를 위하여 Flexible MSG 센서를 기반으로 한 Flexible Epidermal Tactile Sensor를 사용하였으며, Flexible Epidermal Tactile Sensor는 손, 손가락 제스처를 취했을 때 손목, 손가락과 연결되어 있는 근육들의 움직임에 따라 발생하는 피부 표면의 전극을 취득하는 센서이다. 실험을 위하여 7가지 손, 손가락 제스처를 정의하였으며, 손목의 꺾임, 손목의 뒤틀림, 손가락의 오므림과 펴짐, 아무 동작도 취하지 않은 기본 상태에 대한 제스처로 정의하였다. 실험 데이터 수집에는 손목이나 손가락에 부상, 장애등이 없는 일반적인 8명의 참가자가 참가하였으며 각각 한 제스처에 대하여 20번씩 반복하여 1120개의 샘플을 수집하였다. 입력신호에 대한 제스처를 학습하기 위해 본 논문에서는 1차원 Convolutional Neural Network를 제안하였으며, 성능 비교를 위해 신호의 크기를 반영하는 특징벡터인 Integral Absolute Value와 Difference Absolute Mean Value를 입력신호에서 추출하고 Support Vector  Machine을 사용하여 본 논문에서 제안한 1차원 CNN과 성능비교를 하였다. 그 결과 본 논문에서 제안한 1차원 CNN의 분류 정확도가 우수한 성능을 나타냈다.",다국어 초록 정보 없음
Fabrication of ZnV₂O₄ Nanoparticles Embedded in Carbon Nanofibers as a Cathode Material for High-Performance Aqueous Zn-Ion Batteries,2022,"['Zn-Ion Battery', 'Cathode Material', 'Electrospinning']",국문 초록 정보 없음,다국어 초록 정보 없음
"Science Technology - 뇌 임플란트 기술, 생각만으로 컴퓨터에 입력시켜요!",2017,[],"만약 생각한 내용을 키보드에 쓸 필요 없이 바로 뇌에서 컴퓨터로 옮겨주는 장치가 있다면 어떨까? 미래에나 가능할 것 같은 이야기지만, 네덜란드 위트레흐트대학의 닉 랩지 교수팀이 '근위축성 측삭경화증'에 걸린 '하네케 드 브라우너(60세)'를 대상으로 뇌 임플란트 수술을 실시해 컴퓨터에 의사를 전달할 수 있도록 하는 데 최초로 성공했다. 이를 통해 최근 환자가 의사소통 능력을 되찾게 되었다고 미국의 뉴스 전문 방송국 CNN은 전했다.",다국어 초록 정보 없음
Deep Convolutional Neural Models for Picture-Quality Prediction: Challenges and Solutions to Data-Driven Image Quality Assessment,2017,[],국문 초록 정보 없음,"<P>Convolutional neural networks (CNNs) have been shown to deliver standout performance on a wide variety of visual information processing applications. However, this rapidly developing technology has only recently been applied with systematic energy to the problem of picture-quality prediction, primarily because of limitations imposed by a lack of adequate ground-truth human subjective data. This situation has begun to change with the development of promising data-gathering methods that are driving new approaches to deep-learning-based perceptual picture-quality prediction. Here, we assay progress in this rapidly evolving field, focusing, in particular, on new ways to collect large quantities of ground-truth data and on recent CNN-based picture-quality prediction models that deliver excellent results in a large, real-world, picture-quality database.</P>"
손글씨 인식을 위한 딥러닝에서 훈련 옵션의 영향 분석,2017,"['deep learning', 'CNN', 'training options', 'handwriting', 'learning floor']",국문 초록 정보 없음,"Deep learning techniques are being studied and developed throughout the medical, agricultural, aviation, and automotive industries. It can be applied to construction fields such as concrete cracks and welding defects. One of the best performing techniques of deep running is CNN technique. In this study, we analyzed the classification of handwritten images using CNN technique before applying them to construction field. Deep running is generally more accurate with deeper layers, but analysis cost is high. In addition, many variations can occur depending on training options. Therefore, this study performed a parametric study to be a reference when CNN technique was applied through accuracy analysis according to training options."
딥러닝을 PC에 적용하기 위한 메모리 최적화에 관한 연구,2017,"['Image Processing', 'Machine Learning', 'Deep Learning', 'Reduced Learning Time', 'Data Reduction']","본 논문에서는 딥러닝을 PC에 적용하기 위한 메모리 최적화에 관한 알고리즘을 제안한다. 제안된 알고리즘은 일반 PC에서 기존의 딥러닝 구조에서 요구되는 연산처리 과정과 데이터 량을 감소시켜 메모리 및 연산처리 시간을 최소화한다. 본 논문에서 제안하는 알고리즘은 분별력이 있는 랜덤 필터를 이용한 컨볼루션 층 구성 과정, PCA를 이용한 데이터 축소 과정, SVM을 사용한 CNN 구조 생성 등의 3과정으로 이루어진다. 분별력이 있는 랜덤 필터를 이용한 컨볼루션 층 구성 과정에서는 학습과정이 필요치 않아서 전체적인 딥러닝의 학습시간을 단축시킨다. PCA를 이용한 데이터 축소 과정에서는 메모리량과 연산처리량을 감소시킨다. SVM을 사용한 CNN 구조 생성에서는 필요로 하는 메모리량과 연산 처리량의 감소 효과를 극대화 시킨다. 제안된 알고리즘의 성능을 평가하기 위하여 예일대학교의 Extended Yale B 얼굴 데이터베이스를 사용하여 실험한 결과, 본 논문에서 제안하는 알고리즘이 기존의 CNN 알고리즘과 비교하여 비슷한 성능의 인식률을 보이면서 연산 소요시간과 메모리 점유율에 있어 우수함이 확인되었다. 본 논문에서 제안한 알고리즘을 바탕으로 하여 일반 PC에서도 많은 데이터와 연산처리를 가진 딥러닝 알고리즘을 구현할 수 있으리라 기대된다.","In this paper, we propose an algorithm for memory optimization to apply deep learning to PC. The proposed algorithm minimizes the memory and computation processing time by reducing the amount of computation processing and data required in the conventional deep learning structure in a general PC. The algorithm proposed in this paper consists of three steps: a convolution layer configuration process using a random filter with discriminating power, a data reduction process using PCA, and a CNN structure creation using SVM. The learning process is not necessary in the convolution layer construction process using the discriminating random filter, thereby shortening the learning time of the overall deep learning. PCA reduces the amount of memory and computation throughput. The creation of the CNN structure using SVM maximizes the effect of reducing the amount of memory and computational throughput required. In order to evaluate the performance of the proposed algorithm, we experimented with Yale University""s Extended Yale B face database. The results show that the algorithm proposed in this paper has a similar performance recognition rate compared with the existing CNN algorithm. And it was confirmed to be excellent. Based on the algorithm proposed in this paper, it is expected that a deep learning algorithm with many data and computation processes can be implemented in a general PC."
"중, 소형시설물 지진피해평가·관리시스템 개발",2021,"['시설물', '지진피해', '지진가속도', '딥러닝', 'Infrastructure', 'Earthquake Damage', 'Ground acceleration', 'Deep Learning']","지진이 발생하면 시설물의 관리자는 구조물의 피해발생 여부를 조사하고 긴급복구를 실시하는 등 대응을 수행할 책임이 있다. 그러나 교량 및 건축물과 같은 대형의 사회기반시설에 대해서 지진발생 후 소수의 관리인원이 제한된 시간 내에 다수구조물의 지진피해를 확인하고 안전성을 평가하는데는 어려움이 있다. 국내에서는 지진재해대응시스템이 개발되어 있으나 확률론적 안전성 평가방법을 적용하고 있어 개별 시설물에 대한 피해 정도를 제공하지는 못하는 실정이다. 이에 본 연구에서는 중, 소형시설물의 지진피해평가·관리시스템을 개발함으로써 지진재해 발생 후 관리자에게 구조물의 피해발생 여부, 긴급점검 등 유지관리활동의 필요유무 정보를 제공하고자 한다.",다국어 초록 정보 없음
위조지문 판별률 향상을 위한 학습데이터 혼합 증강 방법,2017,"['fake fingerprint detection', 'data augmentation', 'CNN']","최근 모바일 및 핀테크(fin-tech) 분야의 최신 트렌드로 지문인식, 홍채인식과 같은 생체인식을 통한 사용자 본인 인증이 주목 받고 있다. 특히 지문인식을 이용한 인증 방식은 전통적인 생체인식 방식으로써 사용자들이 사용하는데 발생하는 거부감이 다른 생체인식에 비해 현저히 낮아 현재 가장 보편적으로 이용되는 방식이다. 이와 동시에 지문을 이용한 인증 시 보안에 대한 중요성이 부각되어 지문의 위조 여부 판별의 중요성 또한 증가하고 있다. 본 논문에서는 CNN(Convolutional Neural Networks) 특징을 이용한 위조 여부 판별 방법에 있어 판별률을 향상시키기 위한 새로운 방법을 제시한다. 학습데이터에 영향을 많이 받는 CNN 특성 상 기존에는 판별률을 향상시키기 위해 아핀 변환(affine transformation) 또는 수평 반전(horizontal reflection)을 사용하여 학습데이터의 양을 증가 시키는 것이 일반적인 방법이었으나 본 논문에서는 위조지문 판별 난이도를 기반으로 한 효과적인 학습데이터 증강(data augmentation) 방법을 제시하며 실험을 통해 제안하는 방법의 타당성을 확인하였다.","Recently, user authentication through biometric traits such as fingerprint and iris raise more and more attention especially in mobile commerce and fin-tech fields. In particular, commercialized authentication methods using fingerprint recognition are widely utilized mainly because customers are more adopted and used to fingerprint recognition applications. In the meantime, the security issues caused by fingerprint falsification bring lots of attention. In this paper, we propose a new method to improve the performance of fake fingerprint detection using CNN(Convolutional Neural Network). It is common practice to increase the amount of learning data by using affine transformation or horizontal reflection to improve the detection rate in CNN characteristics that are influenced by learning data. However, in this paper we propose an effective data augmentation method based on the database difficulty level. The experimental results confirm the validity of proposed method."
Automatic Wood Species Identification of Korean Softwood Based on Convolutional Neural Networks,2017,"['automatic wood species identification', 'convolutional neural networks', 'CNN', 'LeNet', 'MiniVGGNet']",국문 초록 정보 없음,"Automatic wood species identification systems have enabled fast and accurate identification of wood species outside of specialized laboratories with well-trained experts on wood species identification. Conventional auto-matic wood species identification systems consist of two major parts: a feature extractor and a classifier. Feature extractors require hand-engineering to obtain optimal features to quantify the content of an image. A Convolutional Neural Network (CNN), which is one of the Deep Learning methods, trained for wood species can extract intrinsic feature representations and classify them correctly. It usually outperforms classifiers built on top of extracted features with a hand-tuning process.We developed an automatic wood species identification system utilizing CNN models such as LeNet, MiniVGGNet, and their variants. A smartphone camera was used for obtaining macroscopic images of rough sawn surfaces from cross sections of woods. Five Korean softwood species (cedar, cypress, Korean pine, Korean red pine, and larch) were under classification by the CNN models. The highest and most stable CNN model was LeNet3 that is two additional layers added to the original LeNet architecture. The accuracy of species identi-fication by LeNet3 architecture for the five Korean softwood species was 99.3%. The result showed the auto-matic wood species identification system is sufficiently fast and accurate as well as small to be deployed to a mobile device such as a smartphone."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",다국어 초록 정보 없음
확장된 RNN을 활용한 사람재인식 시스템에 관한 연구,2017,"['CNN', 'RNN', 'Unsupervised Learning', 'Person-Reidentification']","사람의 빈번한 자세 변화, 그리고 background clutter과 occlusion으로 인해 Person Re-identificatio는 컴퓨 터 비전 분야에서 가장 어려운 부분이다. 비겹침 카메라의 이미지는 어떤 사람을 다른 사람과 구별하기 어렵게 한다. 더욱 나은 성능 일치를 달성하기 위해 대부분의 방법은 특징 선택과 거리 메트릭을 개별적으로 사용한다. 그렇게 차별 화된 표현과 적절한 거리를 얻을 수 있고, 사람과 중요한 특징의 무시 사이의 유사성을 설명할 수 있다. 이러한 상황은 우리가 이 문제를 다루는 새로운 방법을 고려하도록 한다. 본 논문에서는 Person Re-identification를 위한 3단 계층 네트워크를 갖는 향상되고 반복적인 신경 회로망을 제안하였다. 특히 RNN(Revurrent Neural Network) 모델은 반복 적인 EM(Expectation Maximum) 알고리즘과 3단 계층 네트워크를 포함하고, 차별적 특징과 지표 거리를 공동으로 학습한다. 반복적인 EM 알고리즘은 RNN 이전에 연속해 있는 CNN(Convoutional Neural Network)의 특징 추출 능 력을 충분히 사용할 수 있다. 자율 학습을 통해 EM 프레임 워크는 패치의 레이블을 변경하고 더 큰 데이터 세트를 훈 련할 수 있다. 네트워크를 더 잘 훈련시키기 위해 3단 계층 네트워크를 통해 CNN, RNN 및 풀링 계층이 공동으로 특 징 추출을 할 수 있다. 실험 결과에 따르면 비전처리 분야에서 다른 연구자의 접근 방식과 비교할 때 이 방법은 경쟁 력 있는 정확도를 얻을 수 있다. 이 방법에 대한 다른 요소의 영향은 향후 연구에서 분석되고 평가될 것이다.","The person Re-identification is the most challenging part of computer vision due to the significant changes in human pose and background clutter with occlusions. The picture from non-overlapping cameras  enhance the difficulty to distinguish some person from the other. To reach a better performance match, most methods use feature selection and distance metrics separately to get discriminative representations and proper distance to  describe the similarity between person and kind of ignoring some significant features. This situation has encouraged us to consider a novel method to deal with this problem. In this paper, we proposed an enhanced recurrent neural network with three-tier hierarchical network for person re-identification. Specifically, the proposed recurrent neural network (RNN) model contain an iterative expectation maximum (EM) algorithm and three-tier Hierarchical network to jointly learn both the discriminative features and metrics distance. The iterative EM algorithm can fully use of the feature extraction ability of convolutional neural network (CNN) which is in series before the RNN. By unsupervised learning, the EM framework can change the labels of the patches and train larger datasets. Through the three-tier hierarchical network, the convolutional neural network, recurrent network and pooling layer can jointly be a feature extractor to better train the network. The experimental result shows that comparing with other researchers’ approaches in this field, this method also can get a competitive accuracy. The influence of different component of this method will be analyzed and evaluated in the future research."
깊은 Convolutional Neural Network를 이용한 얼굴표정 분류 기법,2017,"['Convolutional neural network', 'face expression', 'data augmentation', 'data-set']",국문 초록 정보 없음,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. To overcome the disadvantages of existing facial expression databases, various databases are used. In the proposed technique, we construct six facial expression data sets such as expressionless, happiness, sadness, angry, surprise, and disgust. Pre-processing and data augmentation techniques are also applied to improve efficient learning and classification performance. In the existing CNN structure, the optimal CNN structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of fully-connected layer nodes. Experimental results show that the proposed scheme achieves the highest classification performance of 96.88% while it takes the least time to pass through the CNN structure compared to other models."
딥러닝 모델 성능 최적화를 통한 단일 보드 컴퓨터 기반 실시간 동공 추적 시스템 구현,2023,[],국문 초록 정보 없음,다국어 초록 정보 없음
Word2vec을 활용한 RNN기반의 문서 분류에 관한 연구,2017,"['Text Mining', 'Information Retrieval', 'Deep Learning', 'DocumenCt lassification', '텍스트 마이닝', '정보검색', '딥 러닝', '문서분류']","자연어 처리 분야에서도 심층 신경망 기술이 주목되고 있으며, 최근에는 convolutional neural network (CNN)기반의 심층신경망 구조가 이미지 분류뿐만 아니라 자연어 처리의 문서 분류에서도 좋은 성능이 입증되었다. 하지만 convolutional neural network (CNN)을 이용한 문서 분류 연구에서는 문장의 평균 단어 수가 16개로 이루어진 짧은 문장에 한하여 적용되었으며, 구문 전체와 의미론적 관계가 복잡한 전체 문장을 다루기 어렵다는 단점을 가지고 있다. 본 논문은 기존 연구의 한계점을극복하고 더 정확한 문서 분류 성능을 위하여 word2vec를 활용한 recurrent neural network (RNN)기반의 심층 신경망의접근법을 새롭게 제안한다. 이를 위해 장기 의존성 문제를 해결한 long short-term memory (LSTM)을 사용하여 긴 시퀀스의입력에서도 효과적인 문서 분류가 가능하도록 하였고, 제안 방식의 효율성을 검증하기 위해 영문 데이터 뿐 아니라 한국어영화 리뷰 데이터에 대해서도 실험을 수행하였다. 그 결과 장문을 포함하고 있는 영문 신문 기사에서는 87%, 단문으로구성된 영문 영화 리뷰 문서에서는 90%, 한국어 영화 리뷰에서는 88%의 문서 분류 정확도를 보였다","Deep neural network based methods have obtained remarkable progress on natural language processing (NLP) task. Recently, convolutional neural network (CNN) based approaches often outperform not only in image classification, but also in document classification. However, convolutional neural network (CNN) based methods is applied only to a short sentence composed of 16 words in average, and it has a disadvantage that it is difficult to deal with a sentence having a complicated semantic relationship with the whole sentence. In this paper, we propose a new method based on recurrent neural network (RNN) using word2vec to overcome the limitations of previous related work and to get much higher accuracy of document classification. By using long short-term memory (LSTM) to solve the long-term dependency problem, effective document classification is also possible for long sequence input. To validate performance of our proposed method in various data, we tested our proposed method both with English sentence and Korean movie review dataset. As a result, 87% of the English newspaper articles containing the long texts, 90% of the English movie review and 88% of the Korean movie reviewsh owed the accuracy of document classification"
Large-Scale Text Classification with Deep Neural Networks,2017,"['deep learning', 'large-scale text classification', 'natural language processing', 'artificial neural networks', '딥러닝', '대용량 문서 분류', '자연어 처리', '인공신경망']",국문 초록 정보 없음,"The classification problem in the field of Natural Language Processing has been studied for a long time. Continuing forward with our previous research, which classifies large-scale text using Convolutional Neural Networks (CNN), we implemented Recurrent Neural Networks (RNN), Long- Short Term Memory (LSTM) and Gated Recurrent Units (GRU). The experiment’s result revealed that the performance of classification algorithms was Multinomial Naïve Bayesian Classifier < Support Vector Machine (SVM) < LSTM < CNN < GRU, in order. The result can be interpreted as follows: First, the result of CNN was better than LSTM. Therefore, the text classification problem might be related more to feature extraction problem than to natural language understanding problems. Second, judging from the results the GRU showed better performance in feature extraction than LSTM. Finally, the result that the GRU was better than CNN implies that text classification algorithms should consider feature extraction and sequential information. We presented the results of fine-tuning in deep neural networks to provide some intuition regard natural language processing to future researchers."
A Study on Face Recognition using Convolution Neural Networks,2017,"['Face Detection', 'Face Recognition', 'Networks', 'Neural Network']",국문 초록 정보 없음,"In recent years, development of hardware and acquisition of big data has attracted the attention of deep learning technology that learns by self learning based on data in big data, distinguishes patterns, and distinguishes objects. As we enter the information society, the problem of information security is increasing. Among them, CNN developed to imitate the human visual processing process has been widely applied to the image recognition field and shows high performance. In this paper, based on the deep - running algorithm of CNN structure, we extract facial data from github and extract specific region (eye). In general, the image recognition rate through the CNN algorithm is about 70%. This paper has improved the recognition rate to 80% through the difference of illumination and distance. It can be applied to security technology using the result of the study. As a solution to this security problem, studies using deep learning have shown good performance. Among them, in the field of image recognition, CNN algorithm is used to face recognition. However, accuracy is low according to the current situation. However, we plan to apply and develop security related technology effectively through future research."
Detecting Anatomical Landmarks From Limited Medical Imaging Data Using Two-Stage Task-Oriented Deep Neural Networks,2017,[],국문 초록 정보 없음,"<P>One of the major challenges in anatomical landmark detection, based on deep neural networks, is the limited availability of medical imaging data for network learning. To address this problem, we present a two-stage task-oriented deep learning method to detect large-scale anatomical landmarks simultaneously in real time, using limited training data. Specifically, our method consists of two deep convolutional neural networks (CNN), with each focusing on one specific task. Specifically, to alleviate the problem of limited training data, in the first stage, we propose a CNN based regression model using millions of image patches as input, aiming to learn inherent associations between local image patches and target anatomical landmarks. To further model the correlations among image patches, in the second stage, we develop another CNN model, which includes a) a fully convolutional network that shares the same architecture and network weights as the CNN used in the first stage and also b) several extra layers to jointly predict coordinates of multiple anatomical landmarks. Importantly, our method can jointly detect large-scale (e.g., thousands of) landmarks in real time. We have conducted various experiments for detecting 1200 brain landmarks from the 3D T1-weighted magnetic resonance images of 700 subjects, and also 7 prostate landmarks from the 3D computed tomography images of 73 subjects. The experimental results show the effectiveness of our method regarding both accuracy and efficiency in the anatomical landmark detection.</P>"
컨볼루션 신경망을 이용한 동작 상상 뇌파 분류,2017,"['brain-computer interface', 'electroencephalogram', 'deep learning', 'convolutional neural network', 'short time fourier transform']",국문 초록 정보 없음,"Brain-computer interface (BCI) is a technology that can be used as augmentative and alternative communication (AAC) for people such as the elderly or the disabled who are restricted or impaired in physical function. In order for BCI to be used as AAC, it is important to select appropriate feature extraction and classification methods because the electroencephalogram (EEG) signal is non-linear and non-stationary. This study proposes a feature extraction and classification method of motor imagery EEG using convolutional neural network (CNN). The CNN, most commonly used in the field of images, uses a large number of training data to avoid the problem of overfitting. If the amount of training data is small, the CNN cause overfitting problems. Therefore, in this study, the CNN suitable with small amount of training data was designed for motor imagery based BCI, and then the motion imaginary EEG was learned and classified. The performance of the proposed method is shown to be about 3.8~4.5% in terms of average accuracy through comparison with existing machine learning methods."
이진 분류문제에서의 딥러닝 알고리즘의 활용 가능성 평가,2017,"['이진분류', '딥러닝', '다층 퍼셉트론', '합성곱 신경망', '장단기 기억', 'Binary Classification', 'Deep Learning', 'Multi-Layer Perceptron', 'Convolutional Neural Network', 'Long Short-Term Memory']",국문 초록 정보 없음,"Recently, AlphaGo which is Bakuk (Go) artificial intelligence program by Google DeepMind, had a huge victory against Lee Sedol. Many people thought that machines would not be able to win a man in Go games because the number of paths to make a one move is more than the number of atoms in the universe unlike chess, but the result was the opposite to what people predicted. After the match, artificial intelligence technology was focused as a core technology of the fourth industrial revolution and attracted attentions from various application domains. Especially, deep learning technique have been attracted as a core artificial intelligence technology used in the AlphaGo algorithm.  The deep learning technique is already being applied to many problems. Especially, it shows good performance in image recognition field. In addition, it shows good performance in high dimensional data area such as voice, image and natural language, which was difficult to get good performance using existing machine learning techniques. However, in contrast, it is difficult to find deep leaning researches on traditional business data and structured data analysis. In this study, we tried to find out whether the deep learning techniques have been studied so far can be used not only for the recognition of high dimensional data but also for the binary classification problem of traditional business data analysis such as customer churn analysis, marketing response prediction, and default prediction. And we compare the performance of the deep learning techniques with that of traditional artificial neural network models.  The experimental data in the paper is the telemarketing response data of a bank in Portugal. It has input variables such as age, occupation, loan status, and the number of previous telemarketing and has a binary target variable that records whether the customer intends to open an account or not. In this study, to evaluate the possibility of utilization of deep learning algorithms and techniques in binary classification problem, we compared the performance of various models using CNN, LSTM algorithm and dropout, which are widely used algorithms and techniques in deep learning, with that of MLP models which is a traditional artificial neural network model. However, since all the network design alternatives can not be tested due to the nature of the artificial neural network, the experiment was conducted based on restricted settings on the number of hidden layers, the number of neurons in the hidden layer, the number of output data (filters), and the application conditions of the dropout technique. The F1 Score was used to evaluate the performance of models to show how well the models work to classify the interesting class instead of the overall accuracy.  The detail methods for applying each deep learning technique in the experiment is as follows. The CNN algorithm is a method that reads adjacent values from a specific value and recognizes the features, but it does not matter how close the distance of each business data field is because each field is usually independent. In this experiment, we set the filter size of the CNN algorithm as the number of fields to learn the whole characteristics of the data at once, and added a hidden layer to make decision based on the additional features. For the model having two LSTM layers, the input direction of the second layer is put in reversed position with first layer in order to reduce the influence from the position of each field. In the case of the dropout technique, we set the neurons to disappear with a probability of 0.5 for each hidden layer.  The experimental results show that the predicted model with the highest F1 score was the CNN model using the dropout technique, and the next best model was the MLP model with two hidden layers using the dropout technique. In this study, we were able to get some findings as the experiment had proceeded. First, models using dropout techniques have a"
합성 곱 신경망의 병렬처리,2017,[],국문 초록 정보 없음,"Convolution Neural Networks(CNN) are very useful in image recognition and detection. However, convolution operation has a large amount of computation, so parallel processing should be applied to improve performance. In this paper, we will propose a suitable location for parallel processing in CNN and show accelerating method for CNN by using FPGA configured by OpenCL."
The Effect of Hyperparameter Choice on ReLU and SELU Activation Function,2017,"['Deep Learning', 'Convolutional Neural Network', 'Hyperparameter', 'Activation Function', 'ReLU', 'SELU']",국문 초록 정보 없음,"The Convolutional Neural Network (CNN) has shown an excellent performance in computer vision task. Applications of CNN include image classification, object detection in images, autonomous driving, etc. This paper will evaluate the performance of CNN model with ReLU and SELU as activation function. The evaluation will be performed on four different choices of hyperparameter which are initialization method, network configuration, optimization technique, and regularization. We did experiment on each choice of hyperparameter and show how it influences the network convergence and test accuracy. In this experiment, we also discover performance improvement when using SELU as activation function over ReLU."
The Effect of Hyperparameter Choice on ReLU and SELU Activation Function,2017,"['Deep Learning', 'Convolutional Neural Network', 'Hyperparameter', 'Activation Function', 'ReLU', 'SELU']",국문 초록 정보 없음,"The Convolutional Neural Network (CNN) has shown an excellent performance in computer vision task. Applications of CNN include image classification, object detection in images, autonomous driving, etc. This paper will evaluate the performance of CNN model with ReLU and SELU as activation function. The evaluation will be performed on four different choices of hyperparameter which are initialization method, network configuration, optimization technique, and regularization. We did experiment on each choice of hyperparameter and show how it influences the network convergence and test accuracy. In this experiment, we also discover performance improvement when using SELU as activation function over ReLU."
The Effect of Hyperparameter Choice on ReLU and SELU Activation Function,2017,"['Deep Learning', 'Convolutional Neural Network', 'Hyperparameter', 'Activation Function', 'ReLU', 'SELU']",국문 초록 정보 없음,"The Convolutional Neural Network (CNN) has shown an excellent performance in computer vision task.Applications of CNN include image classification, object detection in images, autonomous driving, etc. This paper will evaluate the performance of CNN model with ReLU and SELU as activation function. The evaluation will be performed on four different choices of hyperparameter which are initialization method, network configuration, optimization technique, and regularization. We did experiment on each choice of hyperparameter and show how it influences the network convergence and test accuracy. In this experiment, we also discover performance improvement when using SELU as activation function over ReLU."
합성곱 인공 신경망을 적용한 SAR 영상 표적 인식 알고리즘,2017,"['convolutional neural network', 'automatic target recognition', 'synthetic aperture radar']",국문 초록 정보 없음,"In this paper, we have designed an SAR automatic target recognition (SAR ATR) algorithm using the convolutional neural network (CNN), which has excellent image recognition performance. Previous SAR ATR methods are difficult to implement, because they include additional preprocessing processes or need prior SAR image information. To address these issues, we propose a CNN structure that is specialized for SAR image classification by modifying the structure of VGGNet. It is confirmed by simulation that the classification accuracy of the proposed method on the MSTAR SAR dataset is increased by 1–2% compared with the conventional VGGNet. Moreover, the classification performance is further improved when the train data is much smaller than the test data."
Plant Leaf Recognition Using a Convolution Neural Network,2017,"['Leaf', 'Classification', 'Visual system', 'CNN', 'GoogleNet']",국문 초록 정보 없음,"There are hundreds of kinds of trees in the natural ecosystem, and it can be very difficult to distinguish between them. Botanists and those who study plants however, are able to identify the type of tree at a glance by using the characteristics of the leaf. Machine learning is used to automatically classify leaf types. Studied extensively in 2012, this is a rapidly growing field based on deep learning. Deep learning is itself a self-learning technique used on large amounts of data, and recent developments in hardware and big data have made this technique more practical. We propose a method to classify leaves using the CNN model, which is often used when applying deep learning to image processing."
딥러닝 프레임워크의 비교,2017,"['딥러닝 프레임워크', '자동미분', '티아노', '텐서플로', 'Cognitive toolkit', 'CNN', 'deep learning framework', 'Theano', 'TensorFlow', 'CNTK', 'computational graph', 'CIFAR-10']",국문 초록 정보 없음,"The deep learning framework is software designed to help develop deep learning models. Some of its important functions include “automatic differentiation” and “utilization of GPU”. The list of popular deep learning framework includes Caffe (BVLC) and Theano (University of Montreal). And recently, Microsofts deep learning framework, Microsoft Cognitive Toolkit, was released as open-source license, following Google’s Tensorflow a year earlier. The early deep learning frameworks have been developed mainly for research at universities. Beginning with the inception of Tensorflow, however, it seems that companies such as Microsoft and Facebook have started to join the competition of framework development. Given the trend, Google and other companies are expected to continue investing in the deep learning framework to bring forward the initiative in the artificial intelligence business. From this point of view, we think it is a good time to compare some of deep learning frameworks. So we compare three deep learning frameworks which can be used as a Python library. Those are Googles Tensorflow, Microsoft’s CNTK, and Theano which is sort of a predecessor of the preceding two.  The most common and important function of deep learning frameworks is the ability to perform automatic differentiation. Basically all the mathematical expressions of deep learning models can be represented as computational graphs, which consist of nodes and edges. Partial derivatives on each edge of a computational graph can then be obtained. With the partial derivatives, we can let software compute differentiation of any node with respect to any variable by utilizing chain rule of Calculus.  First of all, the convenience of coding is in the order of CNTK, Tensorflow, and Theano. The criterion is simply based on the lengths of the codes and the learning curve and the ease of coding are not the main concern. According to the criteria, Theano was the most difficult to implement with, and CNTK and Tensorflow were somewhat easier. With Tensorflow, we need to define weight variables and biases explicitly. The reason that CNTK and Tensorflow are easier to implement with is that those frameworks provide us with more abstraction than Theano. We, however, need to mention that low-level coding is not always bad. It gives us flexibility of coding. With the low-level coding such as in Theano, we can implement and test any new deep learning models or any new search methods that we can think of.  The assessment of the execution speed of each framework is that there is not meaningful difference. According to the experiment, execution speeds of Theano and Tensorflow are very similar, although the experiment was limited to a CNN model. In the case of CNTK, the experimental environment was not maintained as the same. The code written in CNTK has to be run in PC environment without GPU where codes execute as much as 50 times slower than with GPU. But we concluded that the difference of execution speed was within the range of variation caused by the different hardware setup.  In this study, we compared three types of deep learning framework: Theano, Tensorflow, and CNTK. According to Wikipedia, there are 12 available deep learning frameworks. And 15 different attributes differentiate each framework. Some of the important attributes would include interface language (Python, C ++, Java, etc.) and the availability of libraries on various deep learning models such as CNN, RNN, DBN, and etc. And if a user implements a large scale deep learning model, it will also be important to support multiple GPU or multiple servers. Also, if you are learning the deep learning model, it would also be important if there are enough examples and references."
A Pedestrian Detection Method using Deep Neural Network,2017,"['보행자 검출', 'convolutional neural network', 'CNN', 'faster R-CNN', '딥러닝', 'pedestrian detection', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
인공신경망의 연결압축에 대한 연구,2017,"['딥러닝', '인공신경망', '컨벌류션날 네트워크', '다계층 신경망', '계산효율성', 'Deep Learning', 'Artificial Neural Network', 'CNN', 'MLP', 'Computation Efficiency']","최근 딥러닝, 즉 거대 또는 깊은 인공신경망을 사용한 기술이 놀라운 성능을 보이고 있고, 점차로 그 네트워크의 규모가 커지고 있다. 하지만, 신경망 크기의 증가는 계산양의 증가로 이어져서 회로의 복잡성, 가격, 발열, 실시간성 제약 등의 문제를 야기한다. 또한, 신경망 연결에는 많은 중복성이 존재한다, 본 연구에서는 이 중복성을 효과적으로 제거하여 이용하여 원 신경망의 성능과 원하는 범위안의 차이를 보이면서, 네트워크 연결의 수를 줄이는 방법을 제안하고 실험하였다. 특히, 재학습에 의하여 성능을 향상시키고, 각 계층별 차이를 고려하기 위하여 계층별 오류율을 할당하여 원하는 성능을 보장할 수 있는 간단한 방법을 제안하였다. 대표적인 영상인식 신경망구조인 FCN (전연결) 구조와 CNN (컨벌루션 신경망) 구조에서 대하여 실험한 결과 약 1/10 정도의 연결만으로도 원 신경망과 유사한 성능을 보일 수 있음을 확인하였다.","Recently Deep-learning, Technologies using Large or Deep Artificial Neural Networks, have Shown Remarkable Performance, and the Increasing Size of the Network Contributes to its Performance Improvement. However, the Increase in the Size of the Neural Network Leads to an Increase in the Calculation Amount, which Causes Problems Such as Circuit Complexity, Price, Heat Generation, and Real-time Restriction. In This Paper, We Propose and Test a Method to Reduce the Number of Network Connections by Effectively Pruning the Redundancy in the Connection and Showing the Difference between the Performance and the Desired Range of the Original Neural Network. In Particular, we Proposed a Simple Method to Improve the Performance by Re-learning and to Guarantee the Desired Performance by Allocating the Error Rate per Layer in Order to Consider the Difference of each Layer. Experiments have been Performed on a Typical Neural Network Structure such as FCN (full connection network) and CNN (convolution neural network) Structure and Confirmed that the Performance Similar to that of the Original Neural Network can be Obtained by Only about 1/10 Connection."
객체 검출 시스템 개발을 위한 Tracking-Learning-Detection 알고리즘과 학습알고리즘에 관한 연구,2017,"['object detection', 'TLD(Tracking-Learning-Detection)', 'optical flow', 'ferns', 'H-CNN(Hippocampus - Convolution Neural Network)']","현대에는 각종 사건 사고의 잦은 발생으로 인해 영상 처리 시스템의 수요는 날로 증가하고 있다. TLD (Tracking-Learning-Detection) 프레임워크는 현재 객체의 검출과 추적에 사용되는 알고리즘으로 객체의 추적, 검출 및 학습을 실시간으로 수행하는 알고리즘이다. 본 논문에서는 TLD프레임워크를 기반으로 학습 단계에서 H-CNN(Hippocampus - Convolution Neural Network) 모델링 기법을 제안한다. 먼저 입력 영상에서 Ferns알고리즘과 Optical flow 알고리즘을 이용하여 관심객체를 검출 및 추적한다. 그 후 기존의 learning 영역의 학습단계에 다층신경망 학습 알고리즘을 적용한다. 제안하는 알고리즘을 사용하여 학습시킨 신경망과 기존 알고리즘의 신경망의 성능을 비교하여 제안하는 학습 알고리즘의 향상된 성능을 증명하였다.","In recent years, demand for image processing systems has been increasing day by day due to frequent occurrence of various incidents. The Tracking-Learning-Detection (TLD) framework is an algorithm that is used for object detection and tracking. It is an algorithm that performs tracking, detection, and learning of objects in real time. In this paper, we propose H-CNN (Hippocampus-Convolution Neural Network) modeling method based on TLD framework. First, the object of interest is detected and tracked using the Ferns algorithm and the optical flow algorithm in the input image. Then, we apply a multi-layer neural network learning algorithm to the learning stage of the existing learning area. We compare the performance of the proposed neural network with that of the conventional neural network. Therefore, we prove the improved performance of the proposed learning algorithm."
합성곱 신경망(Convolutional Neural Network)을 활용한 지능형 아토피피부염 중증도 진단 모델 개발,2017,"['아토피피부염', '딥러닝', '이미지 인식 알고리즘', 'Convolutional Neural Network', 'Convolutional Neural Network', 'Atopic Dermatitis', 'Deep Learning', 'Image Recognition Algorithm']","제4차 산업혁명의 등장과 경제성장으로 인한 ‘국민 삶의 질 향상’ 요구 증대로 인해 의료서비스의 질과 의료비용에 대한 국민들의 요구수준이 향상되고 있으며, 이로 인해 인공지능이 의료현장에 도입되고 있다. 하지만 인공지능이 의료분야에 활용된 사례를 살펴보면 ‘삶의 질’에 직접적인 영향을 끼치는 만성피부질환에 활용된 사례는 부족한 실정이며, 만성피부질환 중 대표적 질병인 아토피피부염은 정성적 진단 방법으로 인해 진단의 객관성을 확보할 수 없다는 한계가 존재한다. 본 연구에서는 아토피피부염의 객관적 중증도 평가 방법을 마련하여 아토피피부염 환자의 삶의 질을 향상시키고자 다음과 같은 연구를 수행하였다. 첫째, 가톨릭대학교 의과대학 성모병원의 데이터베이스로부터 아토피피부염 환자의 이미지 데이터를 수집했으며, 수집된 이미지 데이터에 대한 정제 및 라벨링 작업을 수행하여 모델 학습과 검증에 적합한 데이터를 확보했다. 둘째, 지능형 아토피피부염 중증도 진단 모형에 적합한 이미지 인식 알고리즘을 파악하기 위해 다양한 CNN 알고리즘들을 병변별 학습용 데이터로 학습시키고, 검증용 데이터를 활용하여 해당 모델의 이미지 인식 정확도를 측정했다. 실증분석 결과 홍반(Erythema)의 경우 ‘ResNet V1 101’, 긁은 정도(Excoriation)의 경우 ‘ResNet V2 50’이 90% 이상의 정확도를 기록하였으며, 태선화(Lichenification)의 경우 학습용 데이터 부족의 한계로 인해 두 병변보다 낮은 89%의 정확도를 보였다. 해당 결과를 통해 이미지 인식 알고리즘이 단순한 사물 인식 분야뿐만 아니라 전문적 지식이 요구되는 분야에도 높은 성능을 나타낸다는 것을 실증적으로 입증했으며, 본 연구는 실제 아토피피부염 환자의 이미지 데이터를 활용했다는 측면에서 실제 임상환경에서 활용성이 높을 것으로 사료된다.","With the advent of ‘The Forth Industrial Revolution’ and the growing demand for quality of life due to economic growth, needs for the quality of medical services are increasing. Artificial intelligence has been introduced in the medical field, but it is rarely used in chronic skin diseases that directly affect the quality of life. Also, atopic dermatitis, a representative disease among chronic skin diseases, has a disadvantage in that it is difficult to make an objective diagnosis of the severity of lesions. The aim of this study is to establish an intelligent severity recognition model of atopic dermatitis for improving the quality of patient’s life. For this, the following steps were performed. First, image data of patients with atopic dermatitis were collected from the Catholic University of Korea Seoul Saint Mary’s Hospital. Refinement and labeling were performed on the collected image data to obtain training and verification data that suitable for the objective intelligent atopic dermatitis severity recognition model. Second, learning and verification of various CNN algorithms are performed to select an image recognition algorithm that suitable for the objective intelligent atopic dermatitis severity recognition model. Experimental results showed that ‘ResNet V1 101’ and ‘ResNet V2 50’ were measured the highest performance with Erythema and Excoriation over 90% accuracy, and ‘VGG-NET’ was measured 89% accuracy lower than the two lesions due to lack of training data. The proposed methodology demonstrates that the image recognition algorithm has high performance not only in the field of object recognition but also in the medical field requiring expert knowledge. In addition, this study is expected to be highly applicable in the field of atopic dermatitis due to it uses image data of actual atopic dermatitis patients."
영상 내 객체 식별률 향상을 위한 딥러닝 기반의 이미지 분류 개선에 위한 연구,2017,"['컨볼루션 신경망 네트워크', 'K-최근접 분류기', '랜덤 포레스트', 'AdaBoostClassifier', 'SIFT', 'Convolutional Neural Network(CNN)', 'K-NeighborsClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'SIFT']","사람의 인력으로는 한계가 있는 영상에서의 데이터 분석에 대한 다양한 연구가 진행됨에 따라 영상 데이터 내의 이미지 분류를 위한 특징 추출방법으로 SIFT, K-Nearest Neighbor(KNN) 알고리즘 등이 기존에 제시되어 있지만 이들 방법은 사람이 직접 설계한 것으로 영상 데이터의 복잡한 패턴을 모두 분석하기에는 어려움이 있다.이에 본 논문에서는 이미지 데이터 분류를 위해 딥러닝을 통한 컨볼루션 신경망 네트워크(CNN)를 영상데이터로 확장해 영상의 위상학적 구조를 학습하고 픽셀 영상으로부터의 최소한의 전처리기와 컨볼루션 신경망을 이용한 이미지 분류에서의 빠른 최적점을 찾기위한 파라미터 설정으로 인하여 이미지 분류에서의 정확성을 높임과 동시에 손실률을 줄인다.또한 훈련데이터와 평가데이터 의 정확성 평가에서 두 값의 차이를 줄여 Overfitting을 방지하는 연구를 진행하였다. 이와 동시에 컨볼루션 신경망 네트워크를 통한 이미지 분류와 AdaBoostClassifier, RandomForestClassifier 등 의 분류기를 통한 이미지 분류에서의 정확성과 손실률을 비교 분석하여 이미지 데이터 분류의 개선을 위한 파라미터 설정과 모델 인스턴스 화에 관하여 연구한다.","As a result of various studies on data analysis on images with limited human power, SIFT and K-Nearest Neighbor (KNN) algorithms have been proposed as feature extraction methods for image classification in image data. The method is designed by a person, and it is difficult to analyze all the complex patterns of the image data.In this paper, we extend the convolutional neural network (CNN) through deep learning to image data to learn the topological structure of the image and classify the image by using minimum preprocessor and convolution neural network The parameter setting for finding the fastest optimal point of the image improves the accuracy in image classification and reduces the loss rate.Also, in the evaluation of the accuracy of the training data and the evaluation data, a study was conducted to prevent the overfitting by reducing the difference between the two values. At the same time, we study the parameter setting and model instantiation for improvement of image data classification by comparing image classification through convolution neural network and accuracy and loss rate in image classification through classifiers such as AdaBoostClassifier and RandomForestClassifier."
컨벌루션 신경회로망과 ReLU 함수 기반 ELM 분류기를 이용한 영상 분류,2017,"['convolutional neural network', 'rectified linear unit', 'extreme learning machine', 'image classification']",국문 초록 정보 없음,"In this paper, we propose a method of image classification using Convolutional Neural Network(CNN) and Extreme Learning Machine Classifier(ELMC) based on ReLU (Rectified Linear Unit) activation function. To do this, we first extract features using CNN, which is one of pre-trained architecture CNN model. Next, the extracted features are classified by using ReLU-based ELMC. The databases used in this paper are Caltech-101 database and OxfordFlowers-17 database. As a result of experimenting with two databases, the experiment result showed good classification rate and rapid processing time in comparison with conventional machine learning algorithms and existing activation functions."
Automatic melody extraction algorithm using a convolutional neural network,2017,"['melody extraction', 'convolutional neural network', 'train-test framework']",국문 초록 정보 없음,"In this study, we propose an automatic melody extraction algorithm using deep learning. In this algorithm, feature images, generated using the energy of frequency band, are extracted from polyphonic audio files and a deep learning technique, a convolutional neural network (CNN), is applied on the feature images. In the training data, a short frame of polyphonic music is labeled as a musical note and a classifier based on CNN is learned in order to determine a pitch value of a short frame of audio signal. We want to build a novel structure of melody extraction, thus the proposed algorithm has a simple structure and instead of using various signal processing techniques for melody extraction, we use only a CNN to find a melody from a polyphonic audio. Despite of simple structure, the promising results are obtained in the experiments. Compared with state-of-the-art algorithms, the proposed algorithm did not give the best result, but comparable results were obtained and we believe they could be improved with the appropriate training data. In this paper, melody extraction and the proposed algorithm are introduced first, and the proposed algorithm is then further explained in detail. Finally, we present our experiment and the comparison of results follows."
Analyzing Pedestrian Parts using Deep Features for Person Re-Identification,2017,"['Deep features', 'Person re-identification', 'Image retrieval', 'Content-based search', '딥 기능', '사람 재식별', '이미지검색', '콘텐츠 기반 검색']",국문 초록 정보 없음,"In computer vision, person re-identification is a challenging task in the context of making intelligent surveillance system. State-of-the-art techniques in person re-identification systems still rely on traditional features extraction such as HOG, SIFT, SURF, and LBP etc. In this study we present convolution neural network (CNN) features to represent persons in surveillance streams.Firstly, we trained a CNN model using person re-id dataset. Secondly, we divide pedestrian images into upper and lower body parts, keeping in view the format of clothing used to cover upper and lower parts. Further, we have extracted CNN features for both parts using the trained model.Similarity score is computed as Euclidean distance between query image and other images in the dataset. We succeeded to achieve higher precision scores on various recall levels, as well as higher Cumulative Match Characteristic (CMC) performance scores compared to other state-of-the-art techniques on ETHZ, CUHK, and Market datasets."
딥러닝 기반의 돼지 호흡기 질병 식별,2017,[],"본 논문에서는 이유자돈의 건강에 심각한 문제를 발생시키고, 농가의 생산성을 급격하게 저하시키는 돼지 호흡기 질환을 효과적으로 식별하는 시스템을 제안한다. 제안된 시스템은 먼저, 돼지가 내는 소리에서 스펙트로그램 정보를 추출한다. 추출된 정보는 최근 각광을 받고 있는 딥러닝 기법 중 하나인CNN에 적용되어, 효과적인 특징으로 변환된 후 돼지 호흡기 질환을 탐지 및 식별한다. 세종시에 위치한 돼지농장에서 취득한 실제 소리 데이터 셋을 이용하여 본 논문에서 제안하는 소리 센서 환경에서의 돼지 호흡기 질병 탐지 시스템의 성능을 실험적으로 검증한다.",다국어 초록 정보 없음
폐 결절 검출을 위한 합성곱 신경망의 성능 개선,2017,"['Pulmonary nodule detection', 'Convolutional Neural Network', 'Machine learning']",국문 초록 정보 없음,"Early detection of the pulmonary nodule is important for diagnosis and treatment of lung cancer. Recently, CT has been used as a screening tool for lung nodule detection. And, it has been reported that computer aided detection(CAD) systems can improve the accuracy of the radiologist in detection nodules on CT scan. The previous study has been proposed a method using Convolutional Neural Network(CNN) in Lung CAD system. But the proposed model has a limitation in accuracy due to its sparse layer structure. Therefore, we propose a Deep Convolutional Neural Network to overcome this limitation. The model proposed in this work is consist of 14 layers including 8 convolutional layers and 4 fully connected layers. The CNN model is trained and tested with 61,404 regions-of-interest (ROIs) patches of lung image including 39,760 nodules and 21,644 non-nodules extracted from the Lung Image Database Consortium(LIDC) dataset. We could obtain the classification accuracy of 91.79% with the CNN model presented in this work. To prevent overfitting, we trained the model with Augmented Dataset and regularization term in the cost function. With L1, L2 regularization at Training process, we obtained 92.39%, 92.52% of accuracy respectively. And we obtained 93.52% with data augmentation. In conclusion, we could obtain the accuracy of 93.75% with L2 Regularization and Data Augmentation."
Robust object proposals re-ranking for object detection in autonomous driving using convolutional neural networks,2017,"['Object proposals', 'Autonomous driving', 'Object detection', 'Convolutional neural networks', 'Stereo vision.']",국문 초록 정보 없음,"<P>Object proposals have recently emerged as an essential cornerstone for object detection. The current state-of-the-art object detectors employ object proposals to detect objects within a modest set of candidate bounding box proposals instead of exhaustively searching across an image using the sliding window approach. However, achieving high recall and good localization with few proposals is still a challenging problem. The challenge becomes even more difficult in the context of autonomous driving, in which small objects, occlusion, shadows, and reflections usually occur. In this paper, we present a robust object proposals re-ranking algorithm that effectivity re-ranks candidates generated from a customized class-independent 3DOP (3D Object Proposals) method using a two-stream convolutional neural network (CNN). The goal is to ensure that those proposals that accurately cover the desired objects are amongst the few top-ranked candidates. The proposed algorithm, which we call DeepStereoOP, exploits not only RGB images as in the conventional CNN architecture, but also depth features including disparity map and distance to the ground. Experiments show that the proposed algorithm outperforms all existing object proposal algorithms on the challenging KITTI benchmark in terms of both recall and localization. Furthermore, the combination of DeepStereoOP and Fast R-CNN achieves one of the best detection results of all three KITTI object classes.</P>"
Deep auto-context convolutional neural networks for standard-dose PET image estimation from low-dose PET/MRI,2017,"['PET image restoration', 'Deep convolutional neural network', 'Auto-context strategy']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Positron emission tomography (PET) is an essential technique in many clinical applications such as tumor detection and brain disorder diagnosis. In order to obtain high-quality PET images, a standard-dose radioactive tracer is needed, which inevitably causes the risk of radiation exposure damage. For reducing the patient's exposure to radiation and maintaining the high quality of PET images, in this paper, we propose a deep learning architecture to estimate the high-quality standard-dose PET (SPET) image from the combination of the low-quality low-dose PET (LPET) image and the accompanying T1-weighted acquisition from magnetic resonance imaging (MRI). Specifically, we adapt the convolutional neural network (CNN) to account for the two channel inputs of LPET and T1, and directly learn the end-to-end mapping between the inputs and the SPET output. Then, we integrate multiple CNN modules following the auto-context strategy, such that the tentatively estimated SPET of an early CNN can be iteratively refined by subsequent CNNs. Validations on real human brain PET/MRI data show that our proposed method can provide competitive estimation quality of the PET images, compared to the state-of-the-art methods. Meanwhile, our method is highly efficient to test on a new subject, e.g., spending ∼2 s for estimating an entire SPET image in contrast to ∼16 min by the state-of-the-art method. The results above demonstrate the potential of our method in real clinical applications.</P>"
합성곱 신경망 기반 맨하탄 좌표계 추정,2017,"['카메라 캘리브레이션', '맨하탄 좌표계', '딥 러닝', '합성곱 신경망', 'camera calibration', 'Manhattan coordinate', 'deep learning', 'convolutional neural network']","본 논문에서는 도심 영상에 대해 맨하탄 좌표계를 추정하는 합성곱 신경망(Convolutional Neural Network) 기반의 시스템을 제안한다. 도심 영상에서 맨하탄 좌표계를 추정하는 것은 영상조정, 3차원 장면 복원 등 컴퓨터 그래픽스 및 비전 문계 해결의 기본이 된다. 제안하는 합성곱 신경망은 GoogLeNet[1]을 기반으로 구성한다. 합성곱 신경망을 훈련하기 위해 구글 스트리트 뷰 API로 영상을 수집하고 기존 캘리브레이션 방법으로 맨하탄 좌표계를 계산하여 데이터셋을 생성한다. 장면마다 새롭게 합성곱 신경망을 학습해야하는 PoseNet[2]과 달리, 본 논문에서 제안하는 시스템은 장면의 구조를 학습하여 맨하탄 좌표계를 추정하기 때문에 학습되지 않은 새로운 장면에 대해서도 맨하탄 좌표계를 추정한다. 제안하는 방법은 학습에 참여하지 않은 구글 스트리트 뷰 영상을 검증 데이터로 테스트하였을 때 3.157°의 중간 오차로 맨하탄 좌표계를 추정하였다. 또한, 동일 검증 데이터에 대해 제안하는 방법이 기존 맨하탄 좌표계 추정 알고리즘[3]보다 더 낮은 중간 오차를 보이는 것을 확인하였다.","In this paper, we propose a system which estimates Manhattan coordinate systems for urban scene images using a convolutional neural network (CNN). Estimating the Manhattan coordinate system from an image under the Manhattan world assumption is the basis for solving computer graphics and vision problems such as image adjustment and 3D scene reconstruction. We construct a CNN that estimates Manhattan coordinate systems based on GoogLeNet [1]. To train the CNN, we collect about 155,000 images under the Manhattan world assumption by using the Google Street View APIs and calculate Manhattan coordinate systems using existing calibration methods to generate dataset. In contrast to PoseNet [2] that trains per-scene CNNs, our method learns from images under the Manhattan world assumption and thus estimates Manhattan coordinate systems for new images that have not been learned. Experimental results show that our method estimates Manhattan coordinate systems with the median error of 3.157° for the Google Street View images of non-trained scenes, as test set. In addition, compared to an existing calibration method [3], the proposed method shows lower intermediate errors for the test set."
초분광 영상 및 딥러닝을 활용한 작물 수분 스트레스 조기 검출,2022,"['초분광 영상', '딥러닝', '영상분석', '작물 생육', '수분 스트레스', 'Hyperspectral Imaging', 'Plant Growth', 'Drought Stress', 'Dimensionality Reduction', 'Convolutional Neural Network']","지구 온난화와 관련된 이상 기후현상은 농작물 생육 장애에 원인이 되고 있다. 기상 등 환경 스트레스의 영향에 민감하지 않는 작물 개발과 스트레스 증상의 조기진단을 통한 처방은 안정적인 농작물 생산을 위해 필수적이다. 본 연구에서는 농작물 수확량 감소의 주요 원인 중 하나인 농작물 수분 스트레스 증상을 초분광 영상 및 딥러닝기술을 활용하여 조기에 검출할 수 있는 비파괴적 진단방법을 개발하고자 하였다. 토마토와 파프리카 작물을 대상으로 급수 중단 4일차부터 7일 동안 초분광 영상을 측정하였으며, 딥러닝 합성곱 신경망(Convolutional Neural Networks, CNN) 영상분석법을 활용하여 정상 및 스트레스 노출 작물을 구분할 수 있는 분석방법을 고찰하였다. CNN 모델인 EfficientNet과 ConvNext를 변형하여 초분광 영상을 학습할 수 있도록 하였고 차원이 축소된 초분광 영상 데이터 셋을 활용하여 분류 모델을 개발하였다. 분석 결과 PCA로 차원 축소된 초분광 이미지 데이터를 EfficientNet 모델을 통해 학습시켰을 때 테스트 세트의 분류 정확도는 94.4%로 나타났다. 초분광 영상 및 딥러닝 분류기술은 토마토 및 파프리카 작물에 대한 수분 스트레스 증상의 조기 검출에 활용될 수 있을 것으로 사료된다.","Abnormal climate phenomena linked to global warming are causing crop growth disorders. Development of crops that are not susceptible to the effects of environmental stress, such as weather, and prescription through early diagnosis of stress symptoms are important to ensure stable crop production. In this study, we aimed to develop a nondestructive diagnostic method that can detect crop drought stress symptoms, one of the main causes of crop yield reduction, at an early stage by using hyperspectral imaging and deep learning. Hyperspectral imaging was performed for seven days from the fourth day after watering was stopped for tomato and red pepper plants, and an analysis method that can distinguish between normal and stress-exposed plants using convolutional neural networks (CNNs) was investigated. The CNN models EfficientNet and ConvNext were modified for hyperspectral-image training, and a classification model was developed using dimensionally reduced hyperspectral datasets. When the principal component analysis dimensionally reduced hyperspectral-imaging data were trained through the EfficientNet model, the classification accuracy of the test set was 94.4%. Hyperspectral-imaging and deep-learning classification techniques are expected to be useful for early detection of drought stress symptoms in tomato and red pepper plants."
기술 용어에 대한 한국어 정의 문장 자동 생성을 위한 순환 신경망 모델 활용 연구,2017,"['Sentence Generation', 'Text Generation', 'Natural Language Generation(NLG)', 'Automatic Report Generation', 'Deep Learning', '문장 생성', '텍스트 생성', '자연어 생성', '보고서 자동 생성', '딥 러닝']","본 논문에서는 지속적으로 커져가는 산업․시장에 대해 관련 연구자들이 이를 효율적으로 분석할 수 있는 반자동 지원 체제 개발을 위한 기술 용어와 기술 개념에 대한 정의문 및 설명문을 자동으로 생성하는 한국어 문장 생성 모델을 제시한다. 한국어 정의 문장 생성을 위하여 딥러닝 기술 중 데이터의 전/후 관계를 포함한 시퀀스 레이블링이 가능한 LSTM을 활용한다. LSTM을 근간으로 한 두 가지 모델은 기술명을 입력할 시 그에 대한 정의문 및 설명문을 생성한다. 다양하게 수집된 대규모 학습 말뭉치를 이용해 실험한 결과, 본 논문에서 구현한 2가지 모델 중 CNN 음절 임베딩을 활용한 어절 단위 LSTM 모델이 용어에 대한 정의문 및 설명문을 생성하는데 더 나은 결과를 도출시킨다는 사실을 확인하였다. 본 논문의 연구 결과를 바탕으로 동일한 주제를 다루는 문장 집합을 생성할 수 있는 확장 모델을 개발할 수 있으며 더 나아가서는 기술에 대한 문헌을 자동으로 작성하는 인공지능 모델을 구현할 수 있으리라 사료된다.","In order to develop a semiautomatic support system that allows researchers concerned to efficiently analyze the technical trends for the ever-growing industry and market. This paper introduces a couple of Korean sentence generation models that can automatically generate definitional statements as well as descriptions of technical terms and concepts. The proposed models are based on a deep learning model called LSTM (Long Sort-Term Memory) capable of effectively labeling textual sequences by taking into account the contextual relations of each item in the sequences. Our models take technical terms as inputs and can generate a broad range of heterogeneous textual descriptions that explain the concept of the terms. In the experiments using large-scale training collections, we confirmed that more accurate and reasonable sentences can be generated by CHAR-CNN-LSTM model that is a word-based LSTM exploiting character embeddings based on convolutional neural networks (CNN). The results of this study can be a force for developing an extension model that can generate a set of sentences covering the same subjects, and furthermore, we can implement an artificial intelligence model that automatically creates technical literature."
Generative adversarial nets를 이용한 빈센트 반 고흐 이미지 생성 시스템,2017,"['Generative Adversarial Nets', 'CNN', 'DCGANs']",국문 초록 정보 없음,"CNN and RNN are classifiers for image and speech recognition, and are used in many computer vision. However, this model alone does not produce images or voices. So we used GAN (Generative Adversarial Nets), which is a non-biped learning, to create and restore objects. To determine the distribution of the assumed model data, we use the generative model G and the Discriminator model D to judge the probability of each case in order to distinguish whether the sample came from the training data from the actual or model G Respectively. This is called minimax two -player game. The model G makes a mistake maximize in order to make a mistake, and the model D makes a mistake minimize in order not to make a mistake. Model D uses technology such as recognition technology, which is a conventional prayer learning method. Through this technique, the damaged or modified objects are compared with the training sample to classify and confirm what kind of object is the first type. There is no need for another network to generate the sample through training and it will be evaluated and confirmed through experiments."
Accurate Human Localization for Automatic Labelling of Human from Fisheye Images,2017,"['Human Localization', 'Fisheye Camera', 'CNN (Convolutional Neural Networks)', 'GoogLeNet', 'Long Short Term Memory', 'Saliency Detection']",국문 초록 정보 없음,"Deep learning networks like Convolutional Neural Networks (CNNs) show successful performances in many computer vision applications such as image classification, object detection, and so on. For implementation of deep learning networks in embedded system with limited processing power and memory, deep learning network may need to be simplified. However, simplified deep learning network cannot learn every possible scene. One realistic strategy for embedded deep learning network is to construct a simplified deep learning network model optimized for the scene images of the installation place. Then, automatic training will be necessitated for commercialization. In this paper, as an intermediate step toward automatic training under fisheye camera environments, we study more precise human localization in fisheye images, and propose an accurate human localization method, Automatic Ground-Truth Labelling Method (AGTLM). AGTLM first localizes candidate human object bounding boxes by utilizing GoogLeNet-LSTM approach, and after reassurance process by GoogLeNet-based CNN network, finally refines them more correctly and precisely(tightly) by applying saliency object detection technique. The performance improvement of the proposed human localization method, AGTLM with respect to accuracy and tightness is shown through several experiments."
A Study on the Emoticon Extraction based on Facial Expression Recognition using Artificial Intelligence,2017,"['Deep Learning', 'Tensorflow', 'CNN(Convolutional Neural Network) Algorithm', 'Facial Expression Recognition', 'Anrdoid Smart Device']",국문 초록 정보 없음,"In this paper, I proposed a prototype model that extracts the same emoticon after facial expression recognition in Android smart device. Understanding and expressing facial expressions are important for the interaction between people and computers. Technologies for recognizing human facial expressions are gaining popularity. It is a useful technology because you can use the emoticons you want only with face recognition by using the camera without searching the emoticons one by one used by users. The technology proposed in this paper uses ‘FER2013’ dataset offered by Kaggle website and based on Tensorflow library for improving facial expression recognition accuracy CNN(Convolutional Neural Network) algorithm is used to make a recognition model. Using this model, facial expression is recognized by Android Smart Device and extracts the same emoticon as a result."
Plant Disease Identification using Deep Neural Networks,2017,"['Plant Leaf Disease', 'CNN', 'GoogLeNet']",국문 초록 정보 없음,"Automatic identification of disease in plants from their leaves is one of the most challenging task to researchers. Diseases among plants degrade their performance and results into a huge reduction of agricultural products. Therefore, early and accurate diagnosis of such disease is of the utmost importance. The advancement in deep Convolutional Neural Network (CNN) has change the way of processing images as compared to traditional image processing techniques. Deep learning architectures are composed of multiple processing layers that learn the representations of data with multiple levels of abstraction. Therefore, proved highly effective in comparison to many state-of-the-art works. In this paper, we present a plant disease identification methodology from their leaves using deep CNNs. For this, we have adopted GoogLeNet that is considered a powerful architecture of deep learning to identify the disease types. Transfer learning has been used to fine tune the pre-trained model. An accuracy of 85.04% has been recorded in the identification of four disease class in Apple plant leaves. Finally, a comparison with other models has been performed to show the effectiveness of the approach."
딥 러닝을 이용한 화재 감지 알고리즘,2017,"['smoke detection', 'deep learning', 'CNN(Convolutional Neural Network)', 'Alexnet CNN', 'GMM']",국문 초록 정보 없음,다국어 초록 정보 없음
Plant Leaf Recognition Using a Convolution Neural Network,2017,"['Leaf', 'Classification', 'Visual system', 'CNN', 'GoogleNet']",국문 초록 정보 없음,"There are hundreds of kinds of trees in the natural ecosystem, and it can be very difficult to distinguish between them. Botanists and those who study plants however, are able to identify the type of tree at a glance by using the characteristics of the leaf. Machine learning is used to automatically classify leaf types. Studied extensively in 2012, this is a rapidly growing field based on deep learning. Deep learning is itself a self-learning technique used on large amounts of data, and recent developments in hardware and big data have made this technique more practical. We propose a method to classify leaves using the CNN model, which is often used when applying deep learning to image processing"
Convolutional Neural Network 기반 실시간 자율 댄싱 로봇 시스템,2017,"['dancing robot', 'convolutional neural network', 'music genre classification', 'synchronization for motion and music']",국문 초록 정보 없음,"This paper proposes a real-time autonomous dancing robot system that listens to arbitrary music inputted in real time and then can dance according to the genre of the music. The proposed system autonomously performs the whole dancing by selecting the dancing motion that matches the music genre and predicting the beat-related information for synchronization between the robot motion and the music. The proposed system updates the data of the input audio signal every 5 second using the first-in first-out method. In addition, the updated data are used as the input for both the short-term music genre classifier based on CNN (Convolutional Neural Network) and the beat detector to detect the beat interval time and the beat start time. A rule-based decision algorithm is suggested to improve the decision success rates of both the genre classifier and the bit detector and to detect the change of music genre simultaneously. Also the proposed system is verified by some examples."
Drone Classification Using Convolutional Neural Networks With Merged Doppler Images,2017,[],국문 초록 정보 없음,"<P>We propose a drone classification method based on convolutional neural network (CNN) and micro-Doppler signature (MDS). The MDS only presents Doppler information in time domain. The frequency domain representation of MDS is called as cadence-velocity diagram (CVD). To analyze the Doppler information of drone in time and frequency domain, we propose a new image by merging MDS and CVD, as merged Doppler image. GoogLeNet, a CNN structure, is utilized for the proposed image data set because of its high performance and optimized computing resources. The image data set is generated by the returned Ku-band frequency modulation continuous wave radar signal. Proposed approach is tested and verified in two different environments, anechoic chamber and outdoor. First, we tested our approach with different numbers of operating motor and aspect angle of a drone. The proposed method improved the accuracy from 89.3% to 94.7%. Second, two types of drone at the 50 and 100 m height are classified and showed 100% accuracy due to distinct difference in the result images.</P>"
Low-Power Convolutional Neural Network Processor for a Face-Recognition System,2017,[],국문 초록 정보 없음,"<P>The authors propose a low-power convolutional neural network (CNN)-based face recognition system for user authentication in smart devices. The system comprises an always-on functional CMOS image sensor (CIS) for imaging and face detection, and a low-power CNN processor (CNNP) for face verification. Implemented in 65-nm CMOS technology, the system consumes 0.62 mW to evaluate one face at 1 fps and achieves 97 percent accuracy.</P>"
미디어의 미디어가 된 오페라: 존 아담스(John Adams)의 《닉슨 인 차이나》 (Nixon in China) 연구,2017,"['존 아담스(John Adams)', '《닉슨 인 차이나》 (Nixon in China)', 'CNN 오페라(CNN Opera)', '미디어 정향적(media-oriented)', '하이퍼리얼리티(hyper-reality)']","본고는 1972년 미국 닉슨 대통령의 중국방문을 다룬 존 아담스(John Adams)의 오페라 《닉슨인 차이나》(Nixon in China)를 미디어적 관점에서 분석한 연구이다. 《닉슨 인 차이나》는 동시대 사건을 다룬 뉴스를 오페라 무대 위에서 재현했다는 점 때문에 세간의 주목을 끌었다. 그러나 미디어와의 이러한 표면적 연관성은 오히려 작품이 가진 보다 본질적이고 심층적인 미디어와의 연관성에 대해서는 간과하도록 만들었다. 본 연구는 이러한 점에 착안하여 《닉슨 인 차이나》를 미디어이론의 틀에서 접근한 새로운 해석을 시도하였다. 즉 본 작품의 내용과 형식에서 모두 미디어적 속성이 반영되고 있으며 이를 통해 미디어가 현실에 영향력을 끼치는 모습을 작품 속에서 드러내고 있음을 밝히고자 하였다.미디어와의 다층적인 연관성이 《닉슨 인 차이나》의 리브레토, 음악, 연출에서 어떻게 나타나는지 분석하여 현대사회 속 미디어의 모습을 반영하는 오페라로서의 본 작품을 고찰하였다. 분석의 내용은 다음과 같다.첫째, 이 작품의 내용은 닉슨의 중국방문이 아니라, `미디어에 비친` 닉슨의 중국방문이라는 점을 핵심으로 한다. 등장인물들은 TV를 시종일관 인식하고 있으며 이에 따라 대조적인 모습을 보여주어 현대인의 삶과 미디어의 연관성을 포착한다. 둘째, 내용을 담는 작품의 형식을 보면, 뉴스나 쇼 등 구체적인 텔레비전 프로그램의 모방이 나타날 뿐 아니라 패스티시와 플로우 등 텔레비전이 취하는 전형적 구성형식을 취하고 있음을 알 수 있다. 이러한 특성은 《닉슨 인 차이나》에서의 파편적 극 구성과 음악구성, 긴장과 이완의 호흡을 고려하여 시종일관 관객의 시선을 놓치지 않도록 하는 배열 등에서 나타난다. 셋째, 내용과 형식을 통해 드러나는 작품의 주제는 미디어적 현실에 대한 비판적 반성으로 볼 수 있다. 이에 사로잡힌 현대인의 모습을 《닉슨 인 차이나》에서는 정신분열증과 노스탤지어를 통해서 포착한다. 통전적인 인식을 방해하는 미디어의 영향력은 분열된 자기의식, 기표의 언어유희인 정신분열증을 통해 나타난다. 노스탤지어는 현실도피를 위한 상품화된 가상인데 《닉슨 인 차이나》에서는 노스탤지어 속에서도 이미 자리 잡고 있는 미디어의 모습을 통해 그 무한 소급적 위력을 드러낸다. 미디어의 막강한 영향력은 하이퍼리얼리티의 생산에서 절정을 이룬다. 이는 현실보다 더 현실 같은 가상과 원본 없는 이미지의 유통을 의미하며 《닉슨 인 차이나》에서는 극중극 장면에서 첨예하게 나타난다. `낯설게하기`는 이러한 주제를 구현하기 위한 효과적 극적 장치로 사용되어 미디어의 영향력에 대한 객관적 거리를 확보하게 한다.이러한 분석을 근거로, 《닉슨 인 차이나》는 현대사회 속 미디어의 모습을 매개(mediate)하는 역할을 하는 오페라로서 독해가능하며 바로 이 점이 《닉슨 인 차이나》가 지닌 동시대적 오페라로서의 진정한 지위와 가치를 보장해 주는 것이라고 할 수 있다.","John Adams`s opera Nixon in China dealt with the event of President Nixon`s visit to China in 1972. In this study, Nixon in China is examined from a media perspective. The work is unique in opera history as it showed actual news clip on the opera stage for the first time. This superficial relevance of the media has hindered more fundamental study on the media relevance Nixon in China has. I consider the media relevance as a salient feature of Nixon in China. This study examined multiple aspects of the media that can be seen in Nixon in China through detailed analysis of its libretto, music and staging. What this analysis have found is as follows.Firstly, the material of Nixon in China is not `Nixon`s visit to China`, but `Nixon`s visit to China viewed on TV`. It is the key point we should pay attention. Characters are sensitively conscious of the media all the time. They act differently based on presence or absence of the media, which shows media-affected life of contemporary people.Secondly, the form which contains the material reflects that of TV media. Its format takes that of media; `pastiche` and `flow`. Nixon in China reflects pastiche in its unconnected events and fragmentary music. Also it uses the cycle of tension and relaxation very effectively to catch the eyes of the audience unfolding the story.Lastly, what is the core message of this opera through its media-oriented material and form? The theme of Nixon in China could be a critical reflection on media-oriented reality. The work captures media-oriented contemporary people in schizophrenia and nostalgia. Schizophrenia appears in split self consciousness and a word-play of signifier which lost meaning. Nostalgia works as an escape from reality. In Nixon in China, we could see nostalgia already includes TV, which reveals inexhaustible power of the media. This power reaches its peak in producing hyper-reality. Nixon in China reveals hyper-reality through play within a play. In showing the media through the opera, Verfremdung(Defamilarization) works effectively. It enables us to keep a distance from media by showing the content of media with its frame at the same time.Therefore Nixon in China could be read as an opera that mediates the media. It provides the profound reflection on media-oriented society and people. This is the core value of Nixon in China as a contemporary opera."
Speech-Act Classification Using a Convolutional Neural Network Based on POS Tag and Dependency-Relation Bigram Embedding,2017,[],국문 초록 정보 없음,"<P>In this paper, we propose a deep learning based model for classifying speech-acts using a convolutional neural network (CNN). The model uses some bigram features including parts-of-speech (POS) tags and dependency-relation bigrams, which represent syntactic structural information in utterances. Previous classification approaches using CNN have commonly exploited word embeddings using morpheme unigrams. However, the proposed model first extracts two different bigram features that well reflect the syntactic structure of utterances and then represents them as a vector representation using a word embedding technique. As a result, the proposed model using bigram embeddings achieves an accuracy of 89.05%. Furthermore, the accuracy of this model is relatively 2.8% higher than that of competitive models in previous studies.</P>"
Face alignment using a deep neural network with local feature learning and recurrent regression,2017,"['Local feature learning', 'Head pose estimation', 'Facial landmark tracking', 'Face alignment', 'Deep neural network', 'Convolutional neural network']",국문 초록 정보 없음,"We propose a face alignment method that uses a deep neural network employing both local feature learning and recurrent regression. This method is primarily based on a convolutional neural network(CNN), which automatically learns local feature descriptors from the local facial landmark dataset that we created. Our research is motivated by the belief that investigating a face from its low-level component features would produce more competitive face alignment results, just as a CNN is normally trained to automatically learn a feature hierarchy from the lowest to the highest levels of abstraction. Moreover, by separately training the feature extraction layers and the regression layers, we impose an explicit functional discrimination between the feature extraction and regression tasks. First, we train a feature extraction network that is used to classify the landmark patches in the dataset. Using this pre-trained feature extraction network, we build a face alignment network, which uses an entire face image rather than the local landmark patch as input, thus generating the global facial features. The subsequent local feature extraction layer extracts the local feature set from this global feature, finally generating the local feature descriptors, in which space the network learns a generic descent direction from the currently estimated landmark positions to the ground truth via linear regression applied recurrently. Head pose estimation network also applied to provide a good initial estimate to the local feature extraction layer for accurate convergence. We found that learning of the good local landmark features in pursuit of good landmark classification also leads to a higher face alignment accuracy and achieves state-of-the-art performance on several public benchmark dataset. It signifies the importance of learning not only the global features but the local features for face alignment. We further verify our method's effectiveness when applied to related problems such as head pose estimation, facial landmark tracking, and invisible landmark detection. We believe that good local learning enables a deeper understanding of the face or object resulting in higher performance."
Finger Motion Estimation Based on Frequency Conversion of EMG Signals and Image Recognition Using Convolutional Neural Network,2017,"['Finger motion estimation', 'electromyogram signal', 'frequency conversion', 'image recognition', 'convolutional neural network']",국문 초록 정보 없음,"We describe a method for estimating finger motion on the basis of the frequency conversion of electromyogram (EMG) signals and the image recognition by using a convolutional neural network (CNN). Since EMG signals are generated before finger motion, various EMG-based systems have been developed for smoothly controlling a robot hand. We used a simple CNN model for estimating finger motion by classifying images generated from a wavelet transform of EMG signals. The model has originally been used for document recognition, and it contains two pairs of convolution and pooling layers and two fully connected layers. A prototype system composed of inexpensive sensor devices was fabricated for acquiring EMG signals and capturing finger motion. The experimental results show that the test accuracy reached 83% in classifying EMG signals into four types; when a thumb opens or is closed, and fingers, except for the thumb, open or are closed."
Sensitive deep convolutional neural network for face recognition at large standoffs with small dataset,2017,"['Convolutional neural network', 'Gradient descent', 'Input-output mapping sensitivity error back propagation', 'Face recognition at long distances with small dataset', 'Sensitivity in cost function', 'Deep neural structures']",국문 초록 정보 없음,"In this paper, we propose a sensitive convolutional neural network which incorporates sensitivity term in the cost function of Convolutional Neural Network (CNN) to emphasize on the slight variations and high frequency components in highly blurred input image samples. The proposed cost function in CNN has a sensitivity part in which the conventional error is divided by the derivative of the activation function, and subsequently the total error is minimized by the gradient descent method during the learning process. Due to the proposed sensitivity term, the data samples at the decision boundaries appear more on the middle band or the high gradient part of the activation function. This highlights the slight changes in the highly blurred input images enabling better feature extraction resulting in better generalization and improved classification performance in the highly blurred images. To study the effect of the proposed sensitivity term, experiments were performed for the face recognition task on small dataset of facial images at different long standoffs in both night-time and day-time modalities."
Stacking PCANet +: An Overly Simplified ConvNets Baseline for Face Recognition,2017,[],국문 초록 정보 없음,"<P>The principal component analysis network (PCANet) is asserted as a parsimonious stacking-based convolutional neural networks (CNNs) instance for generic object recognition including face. However, to be regarded a CNN resemblance, PCANet lacks a nonlinearity in between two successive convolutional layers. The multilayer PCANet (by neglecting the nonlinearity pre-requisite) is also deemed far-fetched for the network depth beyond two, due to feature dimensionality explosion. We thus devise a PCANet alternative, dubbed PCANet+ in this letter, to untangle these constraints. To be more precise, conforming to the CNN essentials, PCANet+ conveys a mean-pooling unit manipulating each feature map. On top of that, we streamline the PCANet topology to permit a deep construction with an expanded PCA filter ensemble. We scrutinize the PCANet+ performance using face recognition technology and other two faces in the wild datasets, namely, labeled faces in the wild and YouTube faces. The experimental results reveal that the PCANet+ descriptor prevails over its predecessor and other stacking-based descriptors in face identification and verification, serving a baseline for ConvNets.</P>"
Rank-based voting with inclusion relationship for accurate image search,2017,[],국문 초록 정보 없음,"<P>We present a rank-based voting technique utilizing inclusion relationship for high-quality image search. Since images can have multiple regions of interest, we extract representative object regions using a state-of-the-art region proposal method tailored for our search problem. We then extract CNN features locally from those representative regions and identify inclusion relationship between those regions. To identify similar images given a query, we propose a novel similarity measure based on representative regions and their inclusion relationship. Our similarity measure gives a high score to a pair of images that contain similar object regions with similar spatial arrangement. To verify benefits of our method, we test our method in three standard benchmarks and compare it against the state-of-the-art image search methods using CNN features. Our experiment results demonstrate effectiveness and robustness of the proposed algorithm.</P>"
글로벌 라이프로그 미디어 클라우드 개발 및 구축,2017,[],"글로벌 라이프로그 미디어 클라우드 서비스를 위하여 네트워크 기술, 클라우드 기술 멀티미디어 App 기술 및 하이라이팅 엔진 기술이 요구된다. 본 논문에서는 미디어 클라우드 서비스를 위한 개발 기술 및 서비스 기술 개발 결과를 보였다. 하이라이팅 엔진은 표정인식기술, 이미지 분류기술, 주목도 지도 생성기술, 모션 분석기술, 동영상 분석 기술, 얼굴 인식 기술 및 오디오 분석기술 등을 포함하고 있다. 표정인식기술로는 Alexnet을 최적화하여 Alexnet 대비 1.82% 우수한 인식 성능을 보였으며 처리속도면에서 28배 빠른 결과를 보였다. 행동 인식 기술에 있어서는 기존 2D CNN 및 LSTM에 기반한 인식 방법에 비하여 제안하는 3D CNN 기법이 0.8% 향상된 결과를 보였다. ㈜판도라티비는 클라우드 기반 라이프로그 동영상 생성 서비스를 개발하여 현재 테스트 서비스를 진행하고 있다.",다국어 초록 정보 없음
A Hand Gesture Recognition Sensor Using Reflected Impulses,2017,[],국문 초록 정보 없음,"<P>This paper introduces a hand gesture recognition sensor using ultra-wideband impulse signals, which are reflected from a hand. The reflected waveforms in time domain are determined by the reflection surface of a target. Thus every gesture has its own reflected waveform. Thus we propose to use machine learning, such as convolutional neural network (CNN) for the gesture classification. The CNN extracts its own feature and constructs classification model then classifies the reflected waveforms. Six hand gestures from american sign language (ASL) are used for an experiment and the result shows more than 90% recognition accuracy. For fine movements, a rotating plaster model is measured with 10 degrees step. An average recognition accuracy is also above 90%.</P>"
컨볼루션 신경망 기반의 화재 감지,2017,[],국문 초록 정보 없음,"The conventional fire detection algorithms use rule-based models and feature vectors in order to detect fire in an image. It is usually difficult to define such rules that needs an expert, which leads to high false-alarm rate. In this paper, we uses a deep learning algorithm based on convolutional neural network (CNN) to extract distinct features found in fire images. Based on YOLO, which is one of the state-of-the-art CNN object detection model, our structure has the ability to perform fire detection and localization in a single model. The proposed method achieves up to 99.0% correct fire detection rate with 7.5% false-alarm rate. The results show much lower false-alarm rate compared to the previous methods."
S-FDS : 퍼지로직과 딥러닝 통합 기반의 스마트 화재감지 시스템,2017,"['fire detection', 'multi-sensors', 'fuzzy logic', 'deep learning', 'IoT']",국문 초록 정보 없음,다국어 초록 정보 없음
생의학 분야 학술 문헌에서의 이벤트 추출을 위한 심층 학습 모델 구조 비교 분석 연구,2017,"['생의학 이벤트', '이벤트 추출', '정보 추출', '자연어 처리', '심층 학습', 'Biomedical Event', 'Event Extraction', 'Information Extraction', 'Natural Language Processing(NLP)', 'Deep-Learning']","최근 생의학 분야의 학술 문헌이 기하급수적으로 급증함에 따라 관련 분야 연구자들은 선행 연구 및 연구 동향 파악에 어려움을 겪고 있다. 이에 효율적인 선행 연구 및 연구 동향 파악을 위한 정보 추출 기술이 요구되며, 학술 문헌의 정보 추출을 위한 개체 인식 및 개체 간의 생의학 이벤트 추출 연구가 활발히 진행되고 있다. 본 연구는 이에 심층 학습(Deep Learning)의 기법 중 하나인 컨볼루션 네트워크(Convolutional Neural Networks, CNN) 모델을 기반으로 이벤트 내의 개체 유형 정보의 적용 위치와 함께, 이벤트 식별 및 분류를 고려하여 총 8가지의 모델을 구성하여 실험하였다. 실험 결과, 본 연구에서 제안하는 모델 중 최고 성능을 보인 개체 유형 완전연결 모델이 이벤트 분류 실험에서 F-점수 72.09%의 높은 성능을 보였으나, 이벤트 추출 실험에서는 학습 컬렉션의 불균형 문제 및 이벤트 식별 모델의 성능 저조 등으로 인하여 F-점수 21.81%의 비교적 저조한 성능을 보였다.","A recent sharp increase of the biomedical literature causes researchers to struggle to grasp the current research trends and conduct creative studies based on the previous results. In order to alleviate their difficulties in keeping up with the latest scholarly trends, numerous attempts have been made to develop specialized analytic services that can provide direct, intuitive and formalized scholarly information by using various text mining technologies such as information extraction and event detection. This paper introduces and evaluates total 8 Convolutional Neural Network (CNN) models for extracting biomedical events from academic abstracts by applying various feature utilization approaches. Also, this paper conducts performance comparison evaluation for the proposed models. As a result of the comparison, we confirmed that the Entity-Type-Fully-Connected model, one of the introduced models in the paper, showed the most promising performance (72.09% in F-score) in the event classification task while it achieved a relatively low but comparable result (21.81%) in the entire event extraction process due to the imbalance problem of the training collections and event identify model's low performance."
CPU-FPGA 구조를 이용한 실시간 FCWS 구현,2017,"['Embedded system', 'ADAS', 'FPGA', 'Convolution Neural Network', 'Vehicle Detection']","최근 운전자의 편의와 안전을 위해 전방 차량 추돌 감지 시스템(Front Collision Warning System : FCWS)과 같은 다양한 운전자 보조 시스템(Advanced Driver Assistance System : ADAS)이 개발되고 있다. FCWS는 주행 중 실시간으로 동작해야 하기 때문에 높은 처리속도를 필요로 한다. 또한 자동차의 전장화에 따라 FCWS를 차량용 임베디드 시스템에서 동작시키기 위해 저전력 시스템이 필요하다. 본 논문에서는 FCWS를 CPU-FPGA 구조에서 실시간 처리가 가능하도록 구현하였다. 차선 검출은 Inverse Transform Perspective(IPM)와 슬라이딩 윈도우 방식을 이용하여 CPU에서도 빠른 속도로 동작할 수 있도록 하였다. 차량검출은 높은 인식률을 가지는 Convolutional Neural Network(CNN)을 이용하였고, FPGA에서 병렬처리로 가속하였다. 제안하는 구조는 저전력으로 동작하는 ARM-Core A9과 FPGA를 내장한 Intel FPGA Cyclone V SoC(System on Chip)에서 검증하였다. HD해상도에서 FCWS는 44FPS로 실시간으로 동작하며, 고성능 PC 환경보다 처리속도 대비 에너지 효율이 약 3.33배 높은 것을 확인했다.","Advanced Driver Assistance Systems(ADAS), such as Front Collision Warning System (FCWS) are currently being developed. FCWS require high processing speed because it must operate in real time while driving. In addition, a low–power system is required to operate in an automobile embedded system. In this paper, FCWS is implemented in CPU-FPGA architecture in embedded system to enable real-time processing. The lane detection enabled the use of the Inverse Transform Perspective (IPM) and sliding window methods to operate at fast speed. To detect the vehicle, a Convolutional Neural Network (CNN) with high recognition rate and accelerated by parallel processing in FPGA is used. The proposed architecture was verified using Intel FPGA Cyclone V SoC(System on Chip) with ARM-Core A9 which operates in low power and on-board FPGA. The performance of FCWS in HD resolution is 44FPS, which is real time, and energy efficiency is about 3.33 times higher than that of high performance PC enviroment."
A Convolutional Neural Network for Fault Classification and Diagnosis in Semiconductor Manufacturing Processes,2017,[],국문 초록 정보 없음,"<P>Many studies on the prediction of manufacturing results using sensor signals have been conducted in the field of fault detection and classification (FDC) for semiconductor manufacturing processes. However, fault diagnosis used to find clues as to root causes remains a challenging area. In particular, process monitoring using neural networks has been employed to only a limited extent because it is a black box model, making the relationships between input data and output results difficult to interpret in actual manufacturing settings, despite its high classification performance. In this paper, we propose a convolutional neural network (CNN) model, named FDC-CNN, in which a receptive field tailored to multivariate sensor signals slides along the time axis, to extract fault features. This approach enables the association of the output of the first convolutional layer with the structural meaning of the raw data, making it possible to locate the variable and time information that represents process faults. In an experiment on a chemical vapor deposition process, the proposed method outperformed other deep learning models.</P>"
교통 신호등 환경에서 얼굴 인식에 관한 기존 연구 분석,2017,"['CNN', 'Face recognition', 'Frontalization', 'Long distance']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on the Evaluation of Optimal Program Applicability for Face Recognition Using Machine Learning,2017,"['CNN', 'Machine Learning', 'Inception-V3', 'TF-SLIM', 'Image Recognition. CRM']",국문 초록 정보 없음,"This study is the first attempt to raise face recognition ability through machine learning algorithm and apply to CRM’s information gathering, analysis and application. In other words, through face recognition of VIP customer in distribution field, we can proceed more prompt and subdivided customized services. The interest in machine learning, which is used to implement artificial intelligence, has increased, and it has become an age to automate it by using machine learning beyond the way that a person directly models an object recognition process. Among them, Deep Learning is evaluated as an advanced technology that shows amazing performance in various fields, and is applied to various fields of image recognition. Face recognition, which is widely used in real life, has been developed to recognize criminals' faces and catch criminals. In this study, two image analysis models, TF-SLIM and Inception-V3, which are likely to be used for criminal face recognition, were selected, analyzed, and implemented. As an evaluation criterion, the image recognition model was evaluated based on the accuracy of the face recognition program which is already being commercialized. In this experiment, it was evaluated that the recognition accuracy was good when the accuracy of the image classification was more than 90%. A limit of our study which is a way to raise face recognition is left as a further research subjects."
컨볼루션 신경망을 사용한 영상 객체 추적에서 경계 박스 분할을 통한 효과적인 온라인 학습 알고리듬,2017,"['CNN', 'Deep learning', 'Visual tracking', 'Computer vision', 'machine learning', 'ANN']",국문 초록 정보 없음,다국어 초록 정보 없음
딥 컨볼루션 신경망을 이용한 자동차 번호판 영역 검출 시스템,2017,"['CNN', 'License Plate Detection', 'Optical Flow', 'Difference of Gaussian']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study of Pedestrian Detection using a Deep Neural Network and Multi-Feature Channel,2017,"['Pedestrian', 'CNN', 'Multi-Feature Channel']",국문 초록 정보 없음,다국어 초록 정보 없음
토너먼트식 구조를 적용한 병해충 진단 시스템 개발,2017,[],"본 논문에서는 CNN(Convolutional Neural Network) 구조에 캐스케이드 방식을 적용한 멀티모델 구조를 제안한다. 각각의 병징 모델을 이용하여 병해와 비병해를 구분하고, 병해를 구분하는 모델을 이용하여 최종적으로 진단 결과를 제공한다. 특징이 구체적이지 않아 잘 드러나지 않는 비병해를 미리 걸러냄으로써, 비병해를 고려할 필요 없이 특징을 비교할 수 있는 과정을 수행할 수 있게 된다.",다국어 초록 정보 없음
라벨링 기법을 활용한 병해충 진단 시스템 개발,2017,"['영상처리', '기계학습', '병해충']",본 논문에서는 CNN 알고리즘을 활용한 병해충진단 처방 시스템을 제안한다. 총 11 개층으로 설계하였으며 병해충 한 종류당 하나의 분류 방식을 사용하는 대신 종류당 여러 개의 특징을 학습하도록 설계하였다. 이렇게 분류된 결과를 라벨링 과정을 통해 병해충 단위로 묶는 과정을 수행하게 하였다. 이를 통해 방향에 따른 특징 차이를 보완할 수 있는 수단을 마련하였다.,다국어 초록 정보 없음
A Vehicle Detection Using Selective Multi-stage Features in Convolutional Neural Networks,2017,"['advanced driver assistant system', 'CNN', 'Adaboost', 'vehicle detection']",국문 초록 정보 없음,다국어 초록 정보 없음
Accurate Human Localization for Automatic Labelling of Human from Fisheye Images,2017,"['Human Localization', 'Fisheye Camera', 'CNN (Convolutional Neural Networks)', 'GoogLeNet Long Short Term Memory', 'Saliency Detection']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on the Emoticon Extraction based on Facial Expression Recognition using Deep Learning Technique,2017,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Smart Phone']",국문 초록 정보 없음,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the emoticons that users often use, you can identify facial expressions with acamera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, in order to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user s facial expressions and similar expressions, reached 66%.It doesn t need to search for emoticons. If you use the camera to recognize the expression, itwill appear emoticons immediately. So this service is the emoticons used when people send messages to others, and it can feel a lot of convenience. In countless emoticons, there is no need to find emoticons, which is an increasing trend in deep learning. So we need to use more suitable algorithm for expression recognition, and then improve accuracy."
컨볼루션 신경망의 특징맵을 사용한 객체 추적,2017,"['Object Tracking', 'Correlation Filter', 'CNN', 'Feature Map', 'Appearance Model']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 복잡한 형상을 가진 공의 인식,2017,"['deep learning', 'R-CNN', 'RoboCup', 'object classification', 'object localization']",국문 초록 정보 없음,"Image processing is widely used not only in manufacturing industries, but also in advanced contexts such as RoboCup, an international robotics competition. Recently, in the image processing field, convolutional neural networks, which is a deep learning approach, became the mainstream of object recognition algorithms. In this paper, a convolutional neural network is designed and used to learn the features of the ball in the RoboCup soccer game. The convolutional neural network was named JeoNet. JeoNet was modified to learn fewer features than VGGNet and ResNet, but shows the same performance. In order to obtain the detected ball’s position, the Single Shot Multibox Detector was applied. To verify JeoNet, an experimental environment was constructed in which a soccer robot finds a ball in the sight. The benefits of JeoNet were shown by comparing the tracking time of the ball between JeoNet and conventional machine vision based ball finding algorithms."
Convolutional encoder-decoder를 이용한 인쇄 회로 기판의 표면 실장 소자 분류,2017,[],국문 초록 정보 없음,"We propose a method for a SMD segmentation by using a convolutional encoder-decoder. Our method distinguishs an information and a location of a SMD on the PCB from an optical image. We use the encoder-decoder architecture. The encoding network is based on VGG net. The decoding network is composed of a convolutional transpose and a convolution layer. The proposed method achieves 98.8％, 96.8％ precisions about the register and the capacitor."
A NOVEL IDEA FOR LARGE-SCALE TEXTURE ANALYSIS AND SCENE RETRIEVAL,2017,"['RPN', 'texture analysis', 'scene retrieval', 'neural network', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Fingerprint Pattern Classification Using Convolution Neural Network,2017,"['Fingerprint recognition', 'Fingerpirnt classification', 'Batch normalization', 'Ensemble', 'CNN']",국문 초록 정보 없음,"Biometrics technology determines the correct identity of a person by extracting human biological or behavioral characteristic data. As the possibility of hacking increases with the development of IT technology, interest in biometrics and authentication technology is greatly increasing. Currently, the most popular authentication technology is fingerprint recognition. For the sake of efficiency, fingerprint recognition is divided into two stages. In the first step, the inputted fingerprint image is subjected to a complicated preprocessing stage, and the fingerprint image is then classified. In the second step, the feature points of the classified fingerprints are extracted and compared with the fingerprint feature points stored in a database. Human beings can easily classify fingerprint patterns without complicated image processing. In this paper, we propose the use of a convolution neural network model combined with an ensemble model and a batch normalization technique after minimizing the number of the quality improvement processes required for a fingerprint image, which operates more similarly to human perception."
Convolution Neural Network를 이용한 노후교량의 균열 위치 파악 방법론,2017,"['유지관리', '노후교량', '균열', 'Convolution Neural Network(CNN)', '머신러닝']",국문 초록 정보 없음,다국어 초록 정보 없음
Embedded Computer Vision with Nvidia TX2,2017,"['Deep Learning', 'GoogleNet', 'AlexaNet', 'Nvidia-Jetson', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
영상 인식을 위한 최신 Deep Learning 알고리즘 소개,2017,[],"Deep learning 알고리즘은 인공 신경망을 응용한 기술로써 최근 들어 컴퓨터 비전, 음식 인식 그리고 영상 인식과 같은 다양한 기계학습 분야에 적용되어 뛰어난 성능을 보여주고 있다. 본고에서는 영상 인식 분야에 적용된 최신 deep learning 알고리즘을 소개하고 연구 동향에 대해 알아본다.",다국어 초록 정보 없음
한반도 안보위기에 미치는 국제 언론의 영향력 고찰,2017,"['Korean Peninsula Crisis', 'International Media', 'News Framing', 'CNN Effect', 'Foreign Reporter']",국문 초록 정보 없음,"This article is based upon a underlying perspective that the Korean peninsula’s security crisis is closely related with the international media’s news coverage on it. With the perspective, the paper focuses on the distinctive aspects of news-framing of 2017’s escalations of military confrontations between North Korea and the USA. Specifically, the author points out that the news coverage on the crisis should not be regarded as a ‘fake news’, rather be accepted as a reflection of public opinion of the international community. Mainstream international media are not facts-oriented messengers but significant influencers in formulating national policies toward the Korean peninsula. Sometimes the media may act as amplifiers or check-valves for the crisis itself. While acknowledging these influences of international media, the North Korean regime have induced lots of foreign reporters into Pyongyang and tried to spread out its intended messages. Kim Jong-Un’s calculations of counter-positioning himself with US president Donald Trump have mixed with media-oriented propaganda maneuvers and assertive provocations. Therefore military and security leaders of South Korea should enhance the mind-set and capabilities of strategic communication with clear understanding of the role of international media’s news framing on the Korean security crisis."
A Study on the Emoticon Extraction based on Facial Expression Recognition using Deep Learning Technique,2017,"['Deep Learni ng', 'Tens or Fl ow', 'CNN', 'Faci al Ex pres si on Rec ogniti on', 'A ndroi d S mart P hone.']",국문 초록 정보 없음,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the emoticons that users often use, you can identify facial expressions with acamera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, in order to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar e xpressions, reached 66%.It doesn't need to search for emoticons. If you use the camera to recognize the expression, itwill appear emoticons immediately. So this service is the emoticons used when people send messages to others, and it can feel a lot of convenience. In countless emoticons, there is no need to find emoticons, which is an increasing trend in deep learning. So we need to use more suitable algorithm for expression recognition, and then improve accuracy."
WFSO 알고리즘을 이용한 인공 신경망의 학습,2017,"['WFSO', 'arificial neural network', 'local minimum', 'optimization', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 데이터스트림 환경에서의 개념 변화 검출 기법,2017,[],"본 논문에서는 데이터스트림 환경에서 개념 변화를 탐지하기 위해 합성곱 신경망(CNN)을 사용하는 방법을 제시한다. 데이터스트림 환경에서 입력될 수 있는 데이터를 패턴화하여 신경망 모델에 학습시키고, 패턴화한 데이터를 학습시킨 신경망 모델을 이용하여 스트림 환경에서 개념 변화를 검출 가능함을 보인다.",다국어 초록 정보 없음
Fine-grained Boat Classification using Convolutional Neural Networks,2017,"['Boat Data Set', 'Optical Tracking', 'Vessel Classification', 'Green VTS', 'Convolutional Neural Network']",국문 초록 정보 없음,"The use of radar-based systems for vessel monitoring is not suitable in populated areas, due to the high electromagnetic emissions. In this paper, a camera based vessel recognition system for application in the context of Vessel Traffic Services (VTS) and Homeland Protection (HP) is proposed. Our approach is designed to extend the functionality of traditional VTS systems by permitting the classification of both cooperative and non-cooperative targets, using camera images only. This allows enhancing the surveillance function in populated areas, where public opinion is strongly concerned about electromagnetic emissions and therefore antennas are suspiciously observed and radars are not allowed. Experiments have been carried out on a publicly available data set of images coming from the ARGOS boat traffic monitoring system in the City of Venice (Italy). The obtained classification accuracy of 89.6% (with 11 different classes of boats) demonstrates the effectiveness of the proposed approach."
"딥러닝 기반 얼굴 검출, 랜드마크 검출 및 얼굴 인식 기술 연구 동향",2017,[],"본 논문에서는 최근 각광받고 있는 Convolutional Neural Network(CNN)과 같은 딥러닝 기반의 얼굴 인식 연구 동향을 살펴 보고자 한다. 얼굴 인식은 입력 영상이 들어왔을 때 자동으로 누구인지 알아내는 알고리즘으로 크게 얼굴 검출, 얼굴 랜드마크 검출 및 얼굴 특징 추출로 나누어진다. 본 논문에서는 얼굴 검출, 랜드마크 검출 및 얼굴 특징 추출에 특화된 딥러닝 알고리즘을 하나씩 살펴보고 이들이 어떻게 발전해 왔는지를 확인하고자 한다. 특히, 딥러닝 기반 얼굴 인식알고리즘들은 딥러닝 기반 물체 인식의 발전 방향과 유사하게 진행되어 오다가 최근에는 얼굴 인식에 특화된 딥러닝 아키텍처 형태로 발전하고 있다. 어떤 방향이 얼굴 인식에 더 도움이 될지에 대해서도 확인하고 실제로 어떤 문제를 해결하고 있는지 확인하고자 한다.",다국어 초록 정보 없음
회선신경망을 이용한 이미지 자동 태깅 기반 모바일 비주얼 검색 서비스 설계 및 구현,2017,"['모바일(mobile)', '비주얼(visual)', '이미지(image)', '검색(Searching)', '회선신경망(CNN)']",국문 초록 정보 없음,다국어 초록 정보 없음
SAR영상 자동 표적 인식을 위한 심층 합성곱 신경망,2017,"['SAR(Sythetic Aperture Radar', '합성개구레이다)', 'ATR(Automatic Target Recognition', '자동표적 인식)', 'CNN(Convolutional Neural Network', '합성곱 신경망)', '과적합(over-fitting)']",국문 초록 정보 없음,다국어 초록 정보 없음
Categorization of Korean News Articles Based on Convolutional Neural Network Using Doc2Vec and Word2Vec,2017,"['doc2vec', 'word2vec', 'word piece model(wpm)', 'convolutional neural network(cnn)']",국문 초록 정보 없음,다국어 초록 정보 없음
독자 중심 철학에서 시작되는 혁신 - 미국 디지털 저널리즘 혁신 사례와 동향,2017,[],국문 초록 정보 없음,다국어 초록 정보 없음
공용 데이터링크 시스템에서 딥러닝 기반 적응형 전력제어 기법,2017,"['Deep learning', 'Adaptive power control', 'Common data link', 'LSTM', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
Deep Convolutional Neural Networks를 이용한 객체 검출 성능의 발전 동향,2017,[],"새로운 영상 미디어 서비스 기술의 발전으로 인해 다양한 영상 인식 기술이 요구되고 있으며, 특히 영상으로부터 특정 객체를 검출하는 기술은 객체와 관련된 광고나 서비스 등의 다양한 활용 분야를 창출하는 핵심 기술이다. 객체 검출 기술이 방송미디어 기술에 적극적으로 활용되기 위해서는 빠르면서도 정확한 성능을 가진 알고리즘 개발이 필수적이다. 본 논문에서는 전통적인 객체 검출 방법들에 비해 우수한 성능을 가지는 Deep Convolutional Neural Networks 기반 객체 검출 방법들을 분석한다. 최근에 소개된 주요 객체 검출 방법들의 연구 배경과 발전 동향을 소개하고, 각 방법의 핵심 알고리즘 및 장단점에 대해 분석한다. 또한 객체 검출의 성능을 평가하기 위해 사용되는 대표적인 데이터셋을 소개하고, 다양한 네트워크 구조/크기 및 학습 데이터 등의 관점에서 각 방법들의 성능을 비교한다. 마지막으로 기존의 객체 검출 방법들을 분석한 내용을 바탕으로 향후 객체 검출 방법들의 발전 방향 및 활용 가능성을 예측해보고자 한다.",다국어 초록 정보 없음
Convolutional Auto-Encoder를 이용한 X-Ray 영상의 Region of Interest 검출 기법 제안,2017,"['Machine Leaming', 'Convolutional Auto-Encoder', 'Region of lnterest', 'DICOM']",국문 초록 정보 없음,다국어 초록 정보 없음
Effects of media and destination image on the behavioral intention to visit Hwacheon Sancheoneo Ice Festival,2017,"['Media effects', 'Destination image (cognitive', 'affective', 'and unique image)', 'Extended theory of planned behavior', 'Decision-making process']",국문 초록 정보 없음,"After Hwacheon Sancheoneo Ice Festival was introduced as one of 7 Wonders of Winter on CNN America’s website in 2011, the festival has been covered by various media. The media effect brought an increase in visitors to HIF. This study aims to understand the festival visitors’ destination image according to the exposed media information, attitude, and behavioral intention by adopting the Extended Theory of Planned Behavior (ETPB) including additional constructs such as media information and destination image. An on-site survey was conducted among 423 visitors attending the festival from January 21 to January 27, 2013. A total of 451 questionnaires were used for empirical analysis. The survey results revealed that both media information and three aspects of the festival’s image (cognitive, affective, and unique) indirectly influenced the festival visitors’ behavioral intention. Specifically, media information had a significant influence on all three aspects of the image, and it had the greatest influence on the unique image. Affective image and unique image significantly affected festival visitors’ attitude. Although attitude and subjective norm had significant effects on behavioral intention to attend the festival, perceived behavioral control and frequency of past behavior was statistically insignificant on behavioral intention. Based on these research results, theoretical importance and practical implications are discussed in this paper."
자율주행차를 위한 장애물 탐지 및 인식 시스템,2017,"['도로주행', '광류 추정 알고리즘', '합성곱신경망', '알렉스넷', '블랙박스', 'Driving on the road', 'Optical Flow', 'CNN', 'AlexNet', 'Black Box']",국문 초록 정보 없음,다국어 초록 정보 없음
WFSO 알고리즘을 이용한 인공 신경망과 합성곱 신경망의 학습,2017,"['WFSO', '인공신경망', '지역 최소값', '최적화', '합성곱 신경망', 'Arificial Neural Network', 'Local Minimum', 'Optimization', 'CNN']",국문 초록 정보 없음,"This paper proposes the learning method of an artificial neural network and a convolutional neural network using the WFSO algorithm developed as an optimization algorithm. Since the optimization algorithm searches based on a number of candidate solutions, it has a drawback in that it is generally slow, but it rarely falls into the local optimal solution and it is easy to parallelize. In addition, the artificial neural networks with non-differentiable activation functions can be trained and the structure and weights can be optimized at the same time. In this paper, we describe how to apply WFSO algorithm to artificial neural network learning and compare its performances with error back-propagation algorithm in multilayer artificial neural networks and convolutional neural networks."
딥러닝 기법을 활용한 레이저 초음파 기반 배관 국부 손상 감지,2021,"['사회기반시설물', '배관유지보수', '딥러닝', 'SOC', 'Plumbing Maintenanc', 'Deep learning']","본 연구에서는 사회기반시설물과 건설 산업 외에 여러 산업에서도 많이 사용되는 배관의 효율적인 안전관리를 위해 배관 레이저 스캐닝 데이터를 기반으로 CNN Object detection 알고리즘을 이용한 배관 곡관부 자동 손상 탐지 시스템을 제안하였다. Q-switched Nd:YAG Pulse laser와 AE(음향 방출) Sensor를 이용하여, 배관 곡관부 손상을 대상으로 UWPI 영상 데이터를 검출하였다. 후처리를 통해 총 1280장의 학습데이터를 활용해 손상 검출 시스템을 구축하였다. 1280장의 이미지 데이터로는 학습을 진행하기에 부족함으로 미리 학습된 COCO2017 EfficientDet-d0 알고리즘을 사용하는 Transfer learning 기법을 적용하였다.",다국어 초록 정보 없음
Deep hybrid recommender systems via exploiting document context and statistics of items,2017,"['Collaborative filtering', 'Document modeling', 'Deep learning', 'Contextual information', 'Gaussian noise', 'Item statistics']",국문 초록 정보 없음,"<P>In this paper, we propose a robust document context-aware hybrid method, which integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF) with the statistics of items to both capture contextual information and consider Gaussian noise differently. Our extensive evaluations on three real-world dataset show that our variant recommendation models based on our proposed method significantly outperform the state-of-the-art recommendation models. (C) 2017 Elsevier Inc. All rights reserved.</P>"
ROV Manipulation from Observation and Exploration using Deep Reinforcement Learning,2017,"['Remotely operated vehicle (ROV)', 'Deep reinforcement learning (DRL)', 'Visual perception', 'Robot operating system(ROS)', 'Degree of freedom (DOF)', 'Convolutional neural network (CNN)']",국문 초록 정보 없음,"The paper presents dual arm ROV manipulation using deep reinforcement learning. The purpose of this underwater manipulator is to investigate and excavate natural resources in ocean, finding lost aircraft blackboxes and for performing other extremely dangerous tasks without endangering humans. This research work emphasizes on a self-learning approach using Deep Reinforcement Learning (DRL). DRL technique allows ROV to learn the policy of performing manipulation task directly, from raw image data. Our proposed architecture maps the visual inputs (images) to control actions (output) and get reward after each action, which allows an agent to learn manipulation skill through trial and error method. We have trained our network in simulation. The raw images and rewards are directly provided by our simple Lua simulator. Our simulator achieve accuracy by considering underwater dynamic environmental conditions. Major goal of this research is to provide a smart self-learning way to achieve manipulation in highly dynamic underwater environment. The results showed that a dual robotic arm trained for a 3DOF movement successfully achieved target reaching task in a 2D space by considering real environmental factor."
서베일런스에서 회선 신경망 기술을 이용한 사람 추적 기법,2017,"['보행자 추적', '사람 추적', '회선 신경망', '객체 추적', '딥 러닝', 'Pedestrian Tracking', 'Human Tracking', 'Convolution Neural Network', 'Object Tracking', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
인공신경망 기반 비주얼 서보잉 시스템의 모바일 매니퓰레이터 컴플라이언스 제어,2017,[],국문 초록 정보 없음,"A new flexible grasping scheme has been proposed in this research for a mobile manipulator to grasp an object located far away. The mobile manipulator consists of a 4 DOF manipulator, a camera on the end-effector of the manipulator. Using CNN for Image processing, the manipulator approaches to a suitable position and then grasping operation is realized with a compliant control. When the manipulator is located at a suitable position, it starts to grasp the object with the compliance control which can compensate for the position error of the object in an image plane. For the compliance control, the current sensors of servo motors are utilized to compensate for the position error instead of using an expensive force/torque sensor."
Instagram image classification with Deep Learning,2017,[],국문 초록 정보 없음,"In this paper we introduce two experimental results from classification of Instagram images and some valuable lessons from them. We have tried some experiments for evaluating the competitive power of Convolutional Neural Network(CNN) in classification of real social network images such as Instagram images. We used AlexNet and ResNet, which showed the most outstanding capabilities in ImageNet Large Scale Visual Recognition Challenge(ILSVRC) 2012 and 2015, respectively. And we used 240 Instagram images and 12 pre-defined categories for classifying social network images. Also, we performed fine-tuning using Inception V3 model, and compared those results. In the results of four cases of AlexNet, ResNet, Inception V3 and fine-tuned Inception V3, the Top-1 error rates were 49.58%, 40.42%, 30.42%, and 5.00%. And the Top-5 error rates were 35.42%, 25.00%, 20.83%, and 0.00% respectively."
Multi-Level and Multi-Scale Feature Aggregation Using Pretrained Convolutional Neural Networks for Music Auto-Tagging,2017,[],국문 초록 정보 없음,"<P>Music auto-tagging is often handled in a similar manner to image classification by regarding the two-dimensional audio spectrogram as image data. However, music auto-tagging is distinguished from image classification in that the tags are highly diverse and have different levels of abstraction. Considering this issue, we propose a convolutional neural networks (CNN)-based architecture that embraces multi-level and multi-scaled features. The architecture is trained in three steps. First, we conduct supervised feature learning to capture local audio features using a set of CNNs with different input sizes. Second, we extract audio features from each layer of the pretrained convolutional networks separately and aggregate them altogether giving a long audio clip. Finally, we put them into fully connected networks and make final predictions of the tags. Our experiments show that using the combination of multi-level and multi-scale features is highly effective in music auto-tagging and the proposed method outperforms the previous state-of-the-art methods on the MagnaTagATune dataset and the Million Song Dataset. We further show that the proposed architecture is useful in transfer learning.</P>"
Study on Object Recognition by Active Stereo Camera for Clean-up Robot,2017,"['Active stereo camera', 'Clean-up robot', 'Convolutional neural network', 'Object recognition']",국문 초록 정보 없음,"This paper describes a clean-up robot that is composed of a mobile base and a manipulator. An object recognition algorithm that is based on an active stereo camera system is also proposed for the clean-up robot. In order for the robot to clear a dining table, the stereo camera system must identify the objects on the dining table and evaluate their positions. For localizing and detecting objects, a convolutional neural network (CNN) that requires a large amount of image data and numerous computations is generally employed. In this study, we use a transfer learning method that is capable of omitting the huge data and the sliding window method that can extract the object area. The SUEF (speeded up robust features) feature points that are extracted by the right camera are compared with those obtained by the left camera, and the area where the number of matched points is the largest is outputted as the object that is to be identified by the left and right cameras. The effectiveness of the object recognition algorithm is verified through clean-up experiments."
Faster RCNN과 ACF를 이용한 사람검출의 성능비교 분석,2017,"['faster RCNN', 'ACF', 'people detection', 'DB construction', 'vehicle']",국문 초록 정보 없음,"This paper presents a performance comparison analysis of human detection using Faster RCNN(Region based Convolutional Neural Network) and ACF(Aggregate Channel Feature). The Faster RCNN consists of Region Proposal Network (RPN), which is merged with the existing Fast RCNN by sharing the convolutional feature. Fast RCNN deduces all of estimated regions of object through one computation of CNN on one image. The ACF obtains multiple channels from one image and combines the channels. The combined image is smoothed to obtain a low-resolution channel. Pixels are integrated and a feature vector is formed. It separates the background and the person by decision tree and boost. The used database is 10 videos on road driving situations downloaded on Youtube. Also, additional database obtained directly from two cameras in the road driving situation is used. Experimental results show that Faster RCNN detection is 2.86 times more accurate than ACF detection."
잡음에 강인한 돼지 호흡기 질병 탐지 시스템,2017,[],"돼지 호흡기 질병은 돈사에 막대한 경제적 손실을 초래하는 질병들 중 하나이다. 본 논문에서는 저비용으로도 구축이 가능한 소리 센서 기반의 돼지 호흡기 질병 탐지 시스템을 제안하며, 특히 잡음 환경에서도 강인한 시스템의 구성에 초점을 두었다. 제안하는 시스템은 먼저, 돈사 내의 소리 센서로부터 취득한 돼지 소리를 2차원 회색조 이미지로 변환한다. 이후, 잡음에 강인한 성능을 보이는 Dominant Neighborhood Structure(DNS) 알고리즘을 이용하여 질감정보를 추출한다. 마지막으로, 이미지 분류에서 그 성능이 이미 입증된 딥러닝의 대표적 모델인 Convolutional Neural Network(CNN)에 사용하여 돼지 호흡기 질병을 탐지 및 분류한다. 실제 국내 돈사에서 취득한 돼지 소리를 이용하여 제안하는 시스템의 성능을 실험적으로 검증한 바 96%가 넘는 안정적인 시스템임을 확인하였다.",다국어 초록 정보 없음
Classification of Osteoporosis from Phalanges CR Images Based on DCNN,2017,"['Computer Aided Diagnosis System', 'CR Images', 'Osteoporosis', 'Deep Convolutional Neural Network']",국문 초록 정보 없음,"Osteoporosis is known as a disease of bone. Visual screening using Computed Radiography (CR) images is an effective method for osteoporosis, however, there are many similar diseases that exhibit state of low bone mass. In this paper, we propose an automatic identification method of osteoporosis from phalanges CR images. In the proposed method, we implement a classifier based on Deep Convolutional Neural Network (DCNN), and identify unknown CR images as normal or abnormal. For training and evaluating of CNN, we use pseudo color images. In the experiment, we apply our proposal method to 101 cases and TPR of 64.7 [%] and FPR of 6.51 [%] were obtained."
저해상도 영상 얼굴인식을 위한 전처리 방법,2017,[],국문 초록 정보 없음,"Face recognition systems are characterized by low invasiveness of acquisition, and increasingly better reliability. Such systems may not be applied effectively, when the images are in low resolution (LR) as in the case that photos are taken from long distances, typically public surveillance. In theory, the high resolution (HR) image reconstructed from an LR face image, applying a super resolution (SR) method, can be used for face recognition. However, existing face SR algorithms may not give satisfactory results in face recognition. This article investigates the very low resolution face recognition problem and introduces a partial differential equation (PDE)-based SR method for a face recognition system of convolutional neural network (CNN)."
딥러닝 기반 병충해 작물 이미지 분류에 관한 연구,2022,[],세계자원연구소에 따르면 꾸준히 증가하는 인구를 위해선 추후에 기존 생산량의 약 70% 이상의 식량을 확보해야 한다고 예상한다. 그러나 농업인들은 자연재해보다 자주 발생하는 병충해로 인한 피해로 원활한 작물 생산에 고충을 겪고 있다. 사람이 작물들의 상태를 매번 확인하는 데에 어려움이 있기에 병충해를 미리 예방하기란 쉽지 않다. 그래서 농가는 대체로 전문가에게 병충해 분류의 자문을 구한다. 하지만 시간이 오래 걸리고 병충해는 빠르게 번지기 때문에 피해가 커지는 경우가 있다. 이와 같은 농업의 고질적인 문제를 해결하고자 본 논문에서는 딥러닝을 기반으로 작물의 이미지 데이터를 이용해 병충해 피해를 입은 작물을 분류하는 연구를 제안한다. 이미지 분류 분야에 자주 쓰이는 컨볼루션 신경망(CNN)을 이용할 것이다. 그중에서도 기본적인 모델과 전이 학습 기반인 사전 훈련 모델 ResNet50으로 병충해 작물 이미지분류 성능을 평가할 것이다. 이러한 연구로 농가는 병충해 작물을 조기에 파악하고 이는 신속한 방제로 이어져 큰 피해를 예방할 수 있을 것이다.,다국어 초록 정보 없음
심층 컨벌루션 신경망 기반의 실시간 드론 탐지 알고리즘,2017,"['Convolutional Neural Networks', 'Drone Detection']",국문 초록 정보 없음,"As drones gain more popularity these days, drone detection becomes more important part of the drone systems for safety, privacy, crime prevention and etc. However, existing drone detection systems are expensive and heavy so that they are only suitable for industrial or military purpose. This paper proposes a novel approach for training Convolutional Neural Networks to detect drones from images that can be used in embedded systems. Unlike previous works that consider the class probability of the image areas where the class object exists, the proposed approach takes account of all areas in the image for robust classification and object detection. Moreover, a novel loss function is proposed for the CNN to learn more effectively from limited amount of training data. The experimental results with various drone images show that the proposed approach performs efficiently in real drone detection scenarios."
Learning to Grasp Objects based on Ensemble Learning Combining Simulation Data and Real Data,2017,"['Robot grasping', 'Deep learning', 'Convolutional Neural Network', 'Simulator robot', 'Ensemble learning']",국문 초록 정보 없음,"In this study, deep learning based grasping using a robot has been discussed. A large amount of training data is required for good performance in deep learning. The training data is usually collected with a real robot. However, it is difficult to collect the data sufficient for training the network in terms of time and cost. Therefore, this study presents a method for collecting the training data based on a robot simulator as well as a real robot. The simulation system is composed of a robot, the work environment, and a 2-finger gripper. The convolutional neural network (CNN) was used for training where its input is the RGB image of the object and its output is the pose of the gripper. Furthermore, the ensemble learning method was used to combine real data and simulation data. It is shown that the ensemble learning method that combines multiple classifiers can lead to a higher grasping success rate than a single classifier."
이미지 인식 기반 향상된 개인정보 식별 및 마스킹 시스템 설계 및 구현,2017,"['Personal Information', 'Personal Information Recognition', 'Face Recognition', 'Masking', 'Deep Learning']",국문 초록 정보 없음,"Recently, with the development of ICT technology such as cloud and mobile, image utilization through social networks is increasing rapidly. These images contain personal information, and personal information leakage accidents may occur. As a result, studies are underway to recognize and mask personal information in images. However, optical character recognition, which recognizes personal information in images, varies greatly depending on brightness, contrast, and distortion, and Korean recognition is insufficient. Therefore, in this paper, we design and implement a personal information identification and masking system based on image recognition through deep learning application using CNN algorithm based on optical character recognition method. Also, the proposed system and optical character recognition compares and evaluates the recognition rate of personal information on the same image and measures the face recognition rate of the proposed system. Test results show that the recognition rate of personal information in the proposed system is 32.7% higher than that of optical character recognition and the face recognition rate is 86.6%."
Language Identification in Handwritten Words Using a Convolutional Neural Network,2017,"['Conventional Neural Network', 'Korean Text', 'English Text', 'Handwritten Document', 'Classification', 'Document Analysis']",국문 초록 정보 없음,"Documents of the last few decades typically include more than one kind of language, so linguistic classification of each word is essential, especially in terms of English and Korean in handwritten documents. Traditional methods mostly use conventional features of structural or stroke features, but sometimes they fail to identify many characteristics of words because of complexity introduced by handwriting. Therefore, traditional methods lead to a considerably more-complicated task and naturally lead to possibly poor results. In this study, convolutional neural network (CNN) is used for classification of English and Korean handwritten words in text documents. Experimental results reveal that the proposed method works effectively compared to previous methods."
욕설문장 분류의 불균형 데이터 해결을 위한 전이학습 방법,2017,"['자연어 분류', '클래스 불균형 문제', '전이학습', '문자수준 컨볼루션 신경망', 'natural language classification', 'class imbalance problem', 'transfer learning', 'characterlevel convolution neural network']","욕설문장을 지도학습 접근법으로 분류하기 위해서 욕설인지 아닌지 판별된 학습 문장이 필요하다. 문자수준의 컨볼루션 신경망이 각 문자에 대해 강건성을 가지기 때문에 욕설분류에 적합하지만, 학습에 많은 데이터가 필요하다는 단점이 있다. 본 논문에서는 이를 해결하기 위해 임의로 생성한 욕설/비욕설 문장 쌍을 컨볼루션 신경망을 기반으로 하는 분류기에 학습시켜 컨볼루션 신경망의 필터가 욕설의 특징을 분류하도록 조정한 후, 실제 훈련문장을 학습시킬 때 필터를 재사용하는 전이학습방법을 제안한다.이로써 데이터 부족과 클래스 불균형으로 인한 영향이 감소하여 분류 성능이 향상될 것이다. 실험 및 평가는 총 3가지 데이터에 대해 수행되었으며, 문자수준 컨볼루션 신경망을 활용한 분류기는 모든 데이터에서 전이학습을 적용했을 때 더 높은 F1 점수를 획득하였다.","The supervised learning approach is suitable for classification of insulting sentences, but pre-decided training sentences are necessary. Since a Character-level Convolution Neural Network is robust for each character, so is appropriate for classifying abusive sentences, however, has a drawback that demanding a lot of training sentences. In this paper, we propose transfer learning method that reusing the trained filters in the real classification process after the filters get the characteristics of offensive words by generated abusive/normal pair of sentences. We got higher performances of the classifier by decreasing the effects of data shortage and class imbalance. We executed experiments and evaluations for three datasets and got higher F1-score of character-level CNN classifier when applying transfer learning in all datasets."
Blind Deep S3D Image Quality Evaluation via Local to Global Feature Aggregation,2017,[],국문 초록 정보 없음,"<P>Previously, no-reference (NR) stereoscopic 3D (S3D) image quality assessment (IQA) algorithms have been limited to the extraction of reliable hand-crafted features based on an understanding of the insufficiently revealed human visual system or natural scene statistics. Furthermore, compared with full-reference (FR) S3D IQA metrics, it is difficult to achieve competitive quality score predictions using the extracted features, which are not optimized with respect to human opinion. To cope with this limitation of the conventional approach, we introduce a novel deep learning scheme for NR S3D IQA in terms of local to global feature aggregation. A deep convolutional neural network (CNN) model is trained in a supervised manner through two-step regression. First, to overcome the lack of training data, local patch-based CNNs are modeled, and the FR S3D IQA metric is used to approximate a reference ground-truth for training the CNNs. The automatically extracted local abstractions are aggregated into global features by inserting an aggregation layer in the deep structure. The locally trained model parameters are then updated iteratively using supervised global labeling, i.e., subjective mean opinion score (MOS). In particular, the proposed deep NR S3D image quality evaluator does not estimate the depth from a pair of S3D images. The S3D image quality scores predicted by the proposed method represent a significant improvement over those of previous NR S3D IQA algorithms. Indeed, the accuracy of the proposed method is competitive with FR S3D IQA metrics, having similar to 91% correlation in terms of MOS.</P>"
병 인식 및 보증금 환불을 위한 분류 알고리즘,2017,[],국문 초록 정보 없음,"We are striving to strengthen environmental regulations and reduce household waste in all countries around the world. Korea is also striving for the circulation of energy resources by enacting laws to promote resource saving and recycling. The government has implemented an empty bottle deposit system for the recycling of empty bottles, but there is a limit to the collection through manpower and the reverse vending machine is not localized. In this paper, we propose a recyclable bottle recognition and classification algorithm which is essential in the reverser vending machine to promote energy resource circulation. The proposed algorithm is a complex identification algorithm using OpenCV and CNN(Convolution Neural Network). In order to evaluate the effectiveness of the proposed algorithm, we implement a classification system that operates in an reverse vending machine, so that it can easily acquire information about bottles and reverse vending machine in various devices."
Embedded deep vision in smart cameras for multi-view objects representation and retrieval,2017,"['Embedded processing', 'Convolutional neural network', 'Transfer learning', 'Image retrieval']",국문 초록 정보 없음,"<P>Active large scale surveillance of indoor and outdoor environments with multiple cameras is becoming an undeniable necessity in today's connected world. Enhanced computational and storage capabilities in smart cameras establish them as promising platforms for implementing intelligent and autonomous surveillance networks. However, poor resolution, limited number of samples per object, and pose variation in multi-view surveillance streams, make the task of efficient image representation highly challenging. To address these issues, we propose an efficient and powerful convolutional neural network (CNN) based framework for features extraction using embedded processing on smart cameras. Efficient, high performance, pre-trained CNNs are separately fine-tuned on persons and vehicles to obtain discriminative, low dimensional features from segmented surveillance objects. Furthermore, multi-view queries of surveillance objects are used to improve retrieval performance. Experiments reveal better efficiency and retrieval performance in different surveillance datasets. (C) 2017 Elsevier Ltd. All rights reserved.</P>"
Language Identification in Handwritten Words Using a Convolutional Neural Network,2017,"['Conventional Neural Network', 'Korean Text', 'English Text', 'Handwritten Document', 'Classification', 'Document Analysis.']",국문 초록 정보 없음,"Documents of the last few decades typically include more than one kind of language, so linguistic classification of each word is essential, especially in terms of English and Korean in handwritten documents. Traditional methods mostly use conventional features of structural or stroke features, but sometimes they fail to identify many characteristics of words because of complexity introduced by handwriting. Therefore, traditional methods lead to a considerably more-complicated task and naturally lead to possibly poor results. In this study, convolutional neural network (CNN) is used for classification of English and Korean handwritten words in text documents. Experimental results reveal that the proposed method works effectively compared to previous methods."
Sitting Posture Classification of Children Using Convolutional Neural Network algorithm,2017,"['Sitting posture classification', 'Pressure distribution', 'Convolutional Neural Network']",국문 초록 정보 없음,"Objective: The aim of this study is to create a posture monitoring system by classifying the sitting postures of children so that they can develop proper postural habits. Background: Modern people spend a lot of time sitting on chairs in various situation. Since sitting in improper postures can cause musculoskeletal disorders, it is important to have proper sitting habits to prevent negative health issues. In addition, it can be difficult for adults to habituate themselves to proper sitting posture away from their posture habits established in childhood. Therefore, developing proper postural habits from childhood is essential, which can be assisted by the posture monitoring system for children to establish their proper life-time posture habits. Method: A pressure sensing mattress was mounted in a seating cushion to obtain the pressure distribution data. A total of 32 children participated in the experiment and pressure data for seven sitting postures of each participant was obtained. LeNet-5, one of the early CNN (Convolutional Neural Network) algorithm, was applied in order to predict t he postures. Results: As a result of cross validations, the average accuracy was 62% and the standard deviation of accuracy was 0.11. Conclusion: In this study, the applicability of deep-learning technique to classify the sitting postures of children was investigated to be feasible. Further studies may focus on the enhancement of model’s accuracy and the experiment environment to be more context-based. Application: The study results are expected to be used in posture monitoring system that assist children in establishing a recommendable sitting posture habit."
Human Face Tracking and Modeling using Active Appearance Model with Motion Estimation,2017,"['Image Processing', 'Human face tracking', 'Active Appearance Model']",국문 초록 정보 없음,"Images and Videos that include the human face contain a lot of information. Therefore, accurately extracting human face is a very important issue in the field of computer vision. However, in real life, human faces have various shapes and textures. To adapt to these variations, A model-based approach is one of the best ways in which unknown data can be represented by the model in which it is built. However, the model-based approach has its weaknesses when the motion between two frames is big, it can be either a sudden change of pose or moving with fast speed. In this paper, we propose an enhanced human face-tracking model. This approach included human face detection and motion estimation using Cascaded Convolutional Neural Networks, and continuous human face tracking and modeling correction steps using the Active Appearance Model. A proposed system detects human face in the first input frame and initializes the models. On later frames, Cascaded CNN face detection is used to estimate the target motion such as location or pose before applying the old model and fit new target."
딥러닝 기반의 다범주 감성분석 모델 개발,2017,"['Sentiment Analysis', 'Convolutional Neural Networks', 'Long Short-Term Memory', 'Word2vec']",국문 초록 정보 없음,"Sentiment analysis is the process of determining whether a piece of document, text or conversation is positive, negative, neural or other emotion. Sentiment analysis has been applied for several real-world applications, such as chatbot. In the last five years, the practical use of the chatbot has been prevailing in many field of industry. In the chatbot applications, to recognize the user emotion, sentiment analysis must be performed in advance in order to understand the intent of speakers. The specific emotion is more than describing positive or negative sentences. In light of this context, we propose deep learning models for conducting multi-class sentiment analysis for identifying speaker’s emotion which is categorized to be joy, fear, guilt, sad, shame, disgust, and anger.Thus, we develop convolutional neural network (CNN), long short term memory (LSTM), and multi-layer neural network models, as deep neural networks models, for detecting emotion in a sentence. In addition, word embedding process was also applied in our research. In our experiments, we have found that long short term memory (LSTM) model performs best compared to convolutional neural networks and multi-layer neural networks. Moreover, we also show the practical applicability of the deep learning models to the sentiment analysis for chatbot."
Human Face Tracking and Modeling using Active Appearance Model with Motion Estimation,2017,"['Image Processing', 'Human face tracking', 'Active Appearance Model']",국문 초록 정보 없음,"Images and Videos that include the human face contain a lot of information. Therefore, accurately extracting human face is a very important issue in the field of computer vision. However, in real life, human faces have various shapes and textures. To adapt to these variations, A model-based approach is one of the best ways in which unknown data can be represented by the model in which it is built. However, the model-based approach has its weaknesses when the motion between two frames is big, it can be either a sudden change of pose or moving with fast speed. In this paper, we propose an enhanced human face-tracking model. This approach included human face detection and motion estimation using Cascaded Convolutional Neural Networks, and continuous human face tracking and modeling correction steps using the Active Appearance Model. A proposed system detects human face in the first input frame and initializes the models. On later frames, Cascaded CNN face detection is used to estimate the target motion such as location or pose before applying the old model and fit new target."
Erythema severity scoring by deep neural network,2017,"['Erythema', 'Score', 'Deep convolution neural network', 'Artificial intelligence']",국문 초록 정보 없음,"Background: Erythema is one of common signs of inflammatory dermatologic diseases. It is one of the measured values which are needed to calculate the Eczema Area and Severity Index score or Psoriasis Area and Severity Index score. However, automated standardization of erythema severity using images has not been investigated yet.Objectives: Our aim was to determine whether the deep convolutional neural networks (CNNs) could assess erythema severity at the level of competence comparable to dermatologists’ scoring.Methods: We made a standard dataset of 4,000 clinical images showing erythema. These images were scored 0 to 4 by three dermatologists. First of all, we trained four CNNs (ResNet V1, ResNet V2, GoogLnet and VGG-Net) with the image dataset, and then examined which CNN was most suitable for erythema scoring.Results: : Among the 4 CNNs, ResNet V1 showed the highest accuracy. Compared to dermatologists’ scoring, the accuracy rates of ResNet V1, ResNet V2, GoogLnet and VGG-Net were 95.33%, 95.12%, 93.59% and 21.55%, respectively.Conclusion: These results suggest some CNNs have a performance capacity for erythema scoring at the level of competence comparable to dermatologists."
Deep neural networks perform equally and superiorly to dermatologists in onychomycosis diagnosis,2017,"['Deep learning', 'Region-based convolutional neural network', 'Onychomycosis', 'Nail dystrophy', 'Telemedicine']",국문 초록 정보 없음,"Background: Although there have been reports of the successful diagnosis of skin disorders using deep learning, unrealistically large clinical image datasets are required for artificial intelligence (AI) training.Objectives: We created datasets of standardized nail images using region-based convolutional neural network (R-CNN) trained to distinguish the nail from the background.Methods: We used R-CNN to generate training datasets of 49,567 images, which we then used to fine-tune the ResNet-152 and VGG-19 models. The validation datasets comprised 100 and 194 images from Inje University (B1 and B2 datasets, respectively), 125 images from Hallym University (C dataset), and 939 images from Seoul National University (D dataset).Results: AI’s results showed test sensitivity/specificity/ area under the curve of (96.0 / 94.7 / 0.98), (82.7 / 96.7 / 0.95), (92.3 / 79.3 / 0.93), (87.7 / 69.3 / 0.82) for the B1, B2, C, and D datasets. For the B1 and C datasets, the AI’s Youden index was significantly (p = 0.01) higher than that of dermatologists.Conclusion: By training with a dataset comprising 49,567 images, we achieved a diagnostic accuracy for onychomycosis superior to that of most dermatologists who participated in this study."
이미지 분석과 딥 러닝을 통한 영유아 위험물 탐지,2017,[],"본 논문은 이미지 탐지 모델인 Faster R-CNN 을 통해 영유아가 존재하는 어린이 집, 공원, 놀이터, 거실 등의 2D 이미지를 읽어 영유아에게 위험이 되는 요소를 인식해 위험상황을 감지하는 시스템을 구현하였다. 실생활에서 쉽게 구할 수 있는 데이터를 바탕으로 탐지 모델을 구현 했으며 현재 머신 러닝 분야가 음성인식과 행위데이터를 기반으로 상용화 되어있는 반면 본 모델은 이미지를 데이터로 한 탐지 모델이 다양한 서비스 분야에서 활용 될 수 있음을 보여준다.",다국어 초록 정보 없음
Data Augmentation using Synthesized Images for Object Detection,2017,"['data augmentation', 'synthesized images', 'deep learning', 'object detection']",국문 초록 정보 없음,"Recently deep learning-based research has been conducted in various fields. Deep learning algorithms require vast amounts of data for good performance. Therefore, collecting such a huge amount of high-quality data is crucial to the deep learning-based methods. Data collection is simple but very time-consuming. To cope with this difficulty, in this study we propose a method to generate a dataset by synthesizing the images of background and object. Various images can be generated through post-processes such as adding noise and changing brightness to the images of objects obtained from different viewpoints. Furthermore, we do not need to manually annotate the dataset for object detection because we can calculate the parameters of the bounding boxes from the location and size of object images during the synthesis process. Faster R-CNN, one of the deep learning algorithms for object recognition, was used to verify the proposed method. The performance based on the dataset generated by the proposed method is comparable to that based on the real dataset."
