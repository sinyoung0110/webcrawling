title,date,keywords,abstract,multilingual_abstract
전자상거래 추천시스템을 위한 순환신경망 알고리즘들의 성능평가,2017,"['전자상거래', '추천시스템', '머신러닝', '순환신경망', '최적화 알고리즘', '텐서플로우', 'e-commerce', 'recommendation system', 'machine learning', 'recurrent neural network', 'optimization algorithm', 'TensorFlow']","전자상거래 발전에 따라 온라인 쇼핑을 이용하는 사람들이 증가하였고 제품 또한 다양해지고 있다. 이러한 추세로 구매자가 만족할 수 있는 정확한 추천시스템의 중요성이 증대되었으며 정확도를 높이기 위한 새로운 방법의 연구가 계속되고 있다. 순환신경망은 시퀀스 학습에 적합한 딥 러닝 방법 중 하나이며 본 연구에서는 추천시스템의 정확도를 높이는 방법으로 구매자의 제품 접근순서를 순환신경망에 적용하여 알고리즘 성능평가를 하였다. 알고리즘 성능평가에는 대표적인 순환신경망 알고리즘과 최적화 알고리즘으로 진행하였다. 순환신경망 알고리즘으로는 RNN, LSTM, GRU 그리고 최적화 알고리즘으로는 Adagrad, RMSProp, Adam optimizer를 사용하였다. 실험 도구로는 구글의 오픈소스 라이브러리인 텐서플로우를 사용하였고 데이터는 RecSys Challenge 2015에서 제공하는 e-commerce session 데이터를 활용하였다. 실험 결과 실험 데이터에 적합한 최적의 하이퍼파라미터를 발굴하고 적용하여 RecSys Challenge 2015 참가자들의 결과와 비교하였다. 상품 접근 순서만을 학습시킨 결과이기 때문에 등수가 높지는 않았지만 기존 추천시스템에 접목한다면 정확도 향상에 기여할 수 있을 것으로 보인다.","Due to the advance of e-commerce systems, the number of people using online shopping and products has significantly increased. Therefore, the need for an accurate recommendation system is becoming increasingly more important. Recurrent neural network is a deep-learning algorithm that utilizes sequential information in training. In this paper, an evaluation is performed on the application of recurrent neural networks to recommendation systems. We evaluated three recurrent algorithms (RNN, LSTM and GRU) and three optimal algorithms(Adagrad, RMSProp and Adam) which are commonly used. In the experiments, we used the TensorFlow open source library produced by Google and e-commerce session data from RecSys Challenge 2015. The results using the optimal hyper-parameters found in this study are compared with those of RecSys Challenge 2015 participants."
순환신경망을 이용한 한글 필기체 인식,2017,"['순환신경망', '한글필기체 인식', '딥러닝 응용', '한글 구성 원리를 고려한 인식', '온라인 필기체 인식', 'recurrent neural networks', 'Hangul handwriting recognition', 'deep learning application', 'online handwriting recognition']","온라인 방식의 한글 필기체 인식 문제를 분석하고 순환신경망 기반의 해법을 모색한다. 한글 낱글자 인식 문제를 순서데이터 레이블링의 관점에서 서열 분류, 구간 분류, 시간별 분류의 세 단계로 구분하여 각각에 대한 해법을 살펴보며, 한글의 구성 원리를 고려한 해결 방안을 정리한다. 한글 2350글자에 대한 온라인 필기체 데이터에 GRU(gated recurrent unit)의 다층 구조를 가지는 서열 분류모델을 적용한 결과, 낱글자 인식 정확도는 86.2%, 초･중･종성 구성에 따른 6가지 유형 분류 정확도는 98.2%로 측정되었다. 유형 분류 모델로 획의 진행에 따른 유형 변화 역시 높은 정확도로 인식하는 결과를 통해, 순환신경망을 이용하여 순서 데이터에서 한글의 구조와 같은 고차원적 지식을 학습할 수 있음을 확인하였다.","We analyze the online Hangul handwriting recognition problem (HHR) and present solutions based on recurrent neural networks. The solutions are organized according to the three kinds of sequence labeling problem - sequence classifications, segment classification, and temporal classification, with additional consideration of the structural constitution of Hangul characters. We present a stacked gated recurrent unit (GRU) based model as the natural HHR solution in the sequence classification level. The proposed model shows 86.2% accuracy for recognizing 2350 Hangul characters and 98.2% accuracy for recognizing the six types of Hangul characters. We show that the type recognizing model successfully follows the type change as strokes are sequentially written. These results show the potential for RNN models to learn high-level structural information from sequential data."
순환인공신경망(RNN)을 이용한 대도시 도심부 교통혼잡 예측,2017,"['순환 인공 신경망', '기계학습', '실시간 소통상황 예측', '반복정체', 'Recurrent Neural Network', 'machine learning', 'realtime traffic congestion estimation', 'recurrent congestion']",,
반복 구매제품의 재구매시기 예측을 위한 다층퍼셉트론(MLP) 모형과 순환신경망(RNN) 모형의 성능비교,2017,"['Purchase Timing', 'Recommender', 'Neural Network', 'Recurrent Neural Network', 'Franchise Business', 'Repurchase Product']",,"Existing studies for recommender have focused on recommending an appropriate item based on the customer preference. However, it has not yet been studied actively to recommend purchase timing for the repurchase product despite of its importance. This study aims to propose MLP and RNN models based on the only simple purchase history data to predict the timing of customer repurchase and compare performances in the perspective of prediction accuracy and quality. As an experiment result, RNN model showed outstanding performance compared to MLP model. The proposed model can be used to develop CRM system which can offer SMS or app based promotion to the customer at the right time. This model also can be used to increase sales for repurchase product business by balancing the level of order as well as inducing repurchase of customer."
장단기 메모리 순환신경망 기반의 비침입적 음성 명료도 추정 방법,2017,"['Deep neural network (DNN)', 'Recurrent neural network (RNN)', 'Long short-term memory (LSTM)', 'Non-Intrusive', 'Speech intelligibility estimation', 'STOI', 'P.563']",,
음소기반의 순환 신경망 음성 검출기를 이용한 음성 향상,2017,"['RNN', 'GMM', 'Phoneme', 'VAD', 'MMSE']",,
순환 신경망 기술을 이용한 코스피 200 지수에 대한 예측 모델 개발 및 성능 분석 연구,2017,"['순환신경망', '코스피 200', '로보 어드바이저', 'Recurrent Neural Networks', 'kospi 200', 'RoboAdvisor']","Wealthfront, Betterment 등의 성공에 힘입어 전세계적으로 알고리즘을 통한 자동적인 자산분배 시스템인 로보어드바이저에 대한 관심이 증가하고 있다. 로보 어드바이저는 자산을 관리하는데 있어 사람의 개입을 최소화 하기 때문에 서비스를 이용하는데 드는 비용을 줄일 수 있으며 사람의 심리적 요인을 배제할 수 있다는 장점을 지닌다. 본 논문에서는 기존의 기술적 분석 기법을 대체하기 위하여 딥러닝 기술을 이용한 코스피 200 선물지수 예측 모델을 개발하고 그 성능을 분석하였다. 모델의 성능 분석 결과 제안하는 모델은 보합세에 놓인 종목의 방향성과 주가를 예측하는 문제에 활용 될 수 있음을 확인하였고, 향후 본 연구에서 제안하는 모델을 기존의 기술적 분석과 결합하여 로보어드바이저 서비스에 적용할 수 있음을 확인하였다.연구",
다채널 오디오 특징값 및 게이트형 순환 신경망을 사용한 다성 사운드 이벤트 검출,2017,[],,"In this paper, we propose an effective method of applying multichannel-audio feature values to GRNNs (Gated Recurrent Neural Networks) in polyphonic sound event detection. Real life sounds are often overlapped with each other, so that it is difficult to distinguish them by using a mono-channel audio features. In the proposed method, we tried to improve the performance of polyphonic sound event detection by using multi-channel audio features. In addition, we also tried to improve the performance of polyphonic sound event detection by applying a gated recurrent neural network which is simpler than LSTM (Long Short Term Memory), which shows the highest performance among the current recurrent neural networks. The experimental results show that the proposed method achieves better sound event detection performance than other existing methods."
순환 신경망 기반 언어 모델을 활용한 초등 영어 글쓰기 자동 평가,2017,[],,"We often use spellcheckers in order to correct the syntactic errors in our documents. However, these computer programs are not enough for elementary school students, because their sentences are not smooth even after correcting the syntactic errors in many cases. In this paper, we introduce an automated method for evaluating the smoothness of two synonymous sentences. This method uses a recurrent neural network to solve the problem of long-term dependencies and exploits subwords to cope with the rare word problem. We trained the recurrent neural network language model based on a monolingual corpus of about two million English sentences. In our experiments, the trained model successfully selected the more smooth sentences for all of nine types of test set. We expect that our approach will help in elementary school writing after being implemented as an application for smart devices."
기술 용어에 대한 한국어 정의 문장 자동 생성을 위한 순환 신경망 모델 활용 연구,2017,"['Sentence Generation', 'Text Generation', 'Natural Language Generation(NLG)', 'Automatic Report Generation', 'Deep Learning', '문장 생성', '텍스트 생성', '자연어 생성', '보고서 자동 생성', '딥 러닝']","본 논문에서는 지속적으로 커져가는 산업․시장에 대해 관련 연구자들이 이를 효율적으로 분석할 수 있는 반자동 지원 체제 개발을 위한 기술 용어와 기술 개념에 대한 정의문 및 설명문을 자동으로 생성하는 한국어 문장 생성 모델을 제시한다. 한국어 정의 문장 생성을 위하여 딥러닝 기술 중 데이터의 전/후 관계를 포함한 시퀀스 레이블링이 가능한 LSTM을 활용한다. LSTM을 근간으로 한 두 가지 모델은 기술명을 입력할 시 그에 대한 정의문 및 설명문을 생성한다. 다양하게 수집된 대규모 학습 말뭉치를 이용해 실험한 결과, 본 논문에서 구현한 2가지 모델 중 CNN 음절 임베딩을 활용한 어절 단위 LSTM 모델이 용어에 대한 정의문 및 설명문을 생성하는데 더 나은 결과를 도출시킨다는 사실을 확인하였다. 본 논문의 연구 결과를 바탕으로 동일한 주제를 다루는 문장 집합을 생성할 수 있는 확장 모델을 개발할 수 있으며 더 나아가서는 기술에 대한 문헌을 자동으로 작성하는 인공지능 모델을 구현할 수 있으리라 사료된다.","In order to develop a semiautomatic support system that allows researchers concerned to efficiently analyze the technical trends for the ever-growing industry and market. This paper introduces a couple of Korean sentence generation models that can automatically generate definitional statements as well as descriptions of technical terms and concepts. The proposed models are based on a deep learning model called LSTM (Long Sort-Term Memory) capable of effectively labeling textual sequences by taking into account the contextual relations of each item in the sequences. Our models take technical terms as inputs and can generate a broad range of heterogeneous textual descriptions that explain the concept of the terms. In the experiments using large-scale training collections, we confirmed that more accurate and reasonable sentences can be generated by CHAR-CNN-LSTM model that is a word-based LSTM exploiting character embeddings based on convolutional neural networks (CNN). The results of this study can be a force for developing an extension model that can generate a set of sentences covering the same subjects, and furthermore, we can implement an artificial intelligence model that automatically creates technical literature."
뜰개 이동 예측을 위한 신경망 및 통계 기반 기계학습 기법의 성능 비교,2017,"['유류 유출', '뜰개', '기계학습', '순환신경망', '예측', 'Oil Spill', 'Drifter', 'Machine learning', 'Recurrent neural network', 'LSTM', 'Prediction']","뜰개는 해양에서 해수의 특성 및 흐름을 관측하기 위한 장비로서, 해수의 흐름 관측을 이용해 유출유 확산 예측을 위해 사용될 수 있다. 본 논문에서는 관측기관에서 사용하는 뜰개가 특정 시간 간격으로 관측한 바람 및 해수의 특성과 이동경로를 기계학습 기법들을 이용하여 학습시키고 예측하는 모델을 제안한다. 서포트벡터 회귀, 방사기저함수 네트워크, 가우시안 프로세스, 다층 퍼셉트론, 순환신경망을 이용하여 뜰개의 이동경로 예측 방법을 제시한다. 기존 MOHID 수치모델과 비교하여 각 기법별로 4 개의 사례중 3 개에서 성능이 개선되었으며, 가장 좋은 개선율을 보인 기법은 LSTM으로 평균 47.59% 개선되었다. 추후 연구에서는 배깅과 부스팅을 이용하여 가중치를 부여하여 정확도를 개선할 예정이다.","Drifter is an equipment for observing the characteristics of seawater in the ocean, and it can be used to predict effluent oil diffusion and to observe ocean currents. In this paper, we design models or the prediction of drifter trajectory using machine learning. We propose methods for estimating the trajectory of drifter using support vector regression, radial basis function network, Gaussian process, multilayer perceptron, and recurrent neural network. When the propose mothods were compared with the existing MOHID numerical model, performance was improve on three of the four cases. In particular, LSTM, the best performed method, showed the imporvement by 47.59% Future work will improve the accuracy by weighting using bagging and boosting."
문서 분류의 개선을 위한 단어-문자 혼합 신경망 모델,2017,"['문서 분류', '딥 러닝', '컨볼루션 신경망', '순환 신경망', 'document classification', 'deep learning', 'convolutional neural network', 'recurrent neural network']","문서의 텍스트를 바탕으로 각 문서가 속한 분류를 찾아내는 문서 분류는 자연어 처리의 기본 분야 중 하나로 주제 분류, 감정 분류 등 다양한 분야에 이용될 수 있다. 문서를 분류하기 위한 신경망 모델은 크게 단어를 기본 단위로 다루는 단어 수준 모델과 문자를 기본 단위로 다루는 문자 수준 모델로 나누어진다. 본 논문에서는 문서를 분류하는 신경망 모델의 성능을 향상시키기 위하여 문자 수준과 단어 수준의 모델을 혼합한 신경망 모델을 제안한다. 제안하는 모델은 각 단어에 대하여 문자 수준의 신경망 모델로 인코딩한 정보와 단어들의 정보를 저장하고 있는 단어 임베딩 행렬의 정보를 결합하여 각 단어에 대한 특징 벡터를 만든다. 추출된 단어들에 대한 특징 벡터를 바탕으로, 주의(attention) 메커니즘을 이용한 순환 신경망을 단어 수준과 문장 수준에 각각 적용하는 계층적 신경망 구조를 통해 문서를 분류한다. 제안한 모델에 대하여 실생활 데이터를 바탕으로 한 실험으로 효용성을 검증한다.","Document classification, a task of classifying the category of each document based on text, is one of the fundamental areas for natural language processing. Document classification may be used in various fields such as topic classification and sentiment classification. Neural network models for document classification can be divided into two categories: word-level models and character-level models that treat words and characters as basic units respectively. In this study, we propose a neural network model that combines character-level and word-level models to improve performance of document classification. The proposed model extracts the feature vector of each word by combining information obtained from a word embedding matrix and information encoded by a character-level neural network. Based on feature vectors of words, the model classifies documents with a hierarchical structure wherein recurrent neural networks with attention mechanisms are used for both the word and the sentence levels. Experiments on real life datasets demonstrate effectiveness of our proposed model."
이미지 캡션 생성을 위한 심층 신경망 모델의 설계,2017,"['이미지 캡션 생성', '심층 신경망 모델', '모델 전이', '멀티 모달 순환 신경망', 'Image Caption Generation', 'Deep Neural Network Model', 'Model Transfer', 'Multi-Modal Recurrent Neural Network']",,"In this paper, we propose an effective neural network model for image caption generation and model transfer. This model is a kind of multi-modal recurrent neural network models. It consists of five distinct layers: a convolution neural network layer for extracting visual information from images, an embedding layer for converting each word into a low dimensional feature, a recurrent neural network layer for learning caption sentence structure, and a multi-modal layer for combining visual and language information. In this model, the recurrent neural network layer is constructed by LSTM units, which are well known to be effective for learning and transferring sequence patterns. Moreover, this model has a unique structure in which the output of the convolution neural network layer is linked not only to the input of the initial state of the recurrent neural network layer but also to the input of the multimodal layer, in order to make use of visual information extracted from the image at each recurrent step for generating the corresponding textual caption. Through various comparative experiments using open data sets such as Flickr8k, Flickr30k, and MSCOCO, we demonstrated the proposed multimodal recurrent neural network model has high performance in terms of caption accuracy and model transfer effect."
심층학습을 이용한 기계번역 기술과 정확도 연구,2017,"['Deep Neural Network', 'Machine Translation', 'Google Translator', 'Recurrent Neural Network', 'Autoencoder']",,"In this study, we discuss the basic technology of machine learning of the deep neural network for natural language processing(NLP). We explain the distributed vector representation of words. Distributed vector representation is proved to be able to carry semantic meanings and are useful in various NLP tasks. The recurrent neural network(RNN) is employed to get the vector representation of sentences. We discuss the RNN encoder-decoder model and some modifications of the RNN structure to improve the accuracy of the machine translations. To test and verify the accuracy of Google translator, we performed the translation among Korean, English, and Japanese, and examined the meaning change between the original and the translated sentence. In neural network translation, we showed some inaccuracies of the translation such as wrong relation between subject and object, or some omission or repetition of the original meaning. In order to increase the performance and accuracy of machine translation, it is necessary to acquire more data for training."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",
AWS 사물 인터넷 환경에서 딥러닝을 이용한 시계열 센서 데이터의 실시간 예측 서비스 아키텍처,2017,"['아마존 웹서비스', '사물인터넷', '딥러닝', 'LSTM', '순환형 신경망', 'AWS', 'IoT', 'Deep Learning', 'LSTM', 'RNN']",,"With the advent of Internet of Things (IoT), the use of various devices connected to Internet has generated a large amount of data, and the importance of big data analysis has rapidly been increasing. In particular, it is necessary to analyze various IoT data generated in real-time and to provide various services through new meaningful future prediction analysis. Therefore, this paper presents the direction of Amazon Web Service (AWS) for real-time prediction service in IoT environment. Also, in this paper, we propose an architecture in AWS IoT environment for analyzing sensor data such as power, temperature, humidity, wind speed, and so on, received from IoT devices using recurrent neural networks (RNN) suitable for time series data among various algorithms, and providing users with necessary services using prediction data. The proposed architecture extracts new information from the time series IoT data and can create new business value by applying real-time IoT service to sports, cultural contents, and so on as well as real-time prediction model."
Title Generation Model for which Sequence-to-Sequence RNNs with Attention and Copying Mechanisms are used,2017,"['sequence-to-sequence 모델', '주의집중 작용', '복사 작용', '제목 생성', '순환신경망', 'sequence-to-sequence model', 'attention mechanism', 'copying mechanism', 'title generation', 'recurrent neural network']",,
LSTM모델 기반 전기차용 2단 감속기 유압 예측,2022,"['Hydraulic Pressure(유압)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Long Short Term Memory(장단기 순환신경망)', 'Vehicle Control(차량 제어)']",,
RNN(Recurrent Neural Network)을 이용한 기업부도예측모형에서 회계정보의 동적 변화 연구,2017,"['순환 신경망', '부도 예측', '시계열 모형', 'Recurrent Neural Network', 'Bankruptcy Prediction', 'Time-Series model']",,"Corporate bankruptcy can cause great losses not only to stakeholders but also to many related sectors in society. Through the economic crises, bankruptcy have increased and bankruptcy prediction models have become more and more important. Therefore, corporate bankruptcy has been regarded as one of the major topics of research in business management. Also, many studies in the industry are in progress and important.  Previous studies attempted to utilize various methodologies to improve the bankruptcy prediction accuracy and to resolve the overfitting problem, such as Multivariate Discriminant Analysis (MDA), Generalized Linear Model (GLM). These methods are based on statistics. Recently, researchers have used machine learning methodologies such as Support Vector Machine (SVM), Artificial Neural Network (ANN). Furthermore, fuzzy theory and genetic algorithms were used. Because of this change, many of bankruptcy models are developed. Also, performance has been improved.  In general, the company’s financial and accounting information will change over time. Likewise, the market situation also changes, so there are many difficulties in predicting bankruptcy only with information at a certain point in time. However, even though traditional research has problems that don’t take into account the time effect, dynamic model has not been studied much. When we ignore the time effect, we get the biased results. So the static model may not be suitable for predicting bankruptcy. Thus, using the dynamic model, there is a possibility that bankruptcy prediction model is improved.  In this paper, we propose RNN (Recurrent Neural Network) which is one of the deep learning methodologies. The RNN learns time series data and the performance is known to be good. Prior to experiment, we selected non-financial firms listed on the KOSPI, KOSDAQ and KONEX markets from 2010 to 2016 for the estimation of the bankruptcy prediction model and the comparison of forecasting performance. In order to prevent a mistake of predicting bankruptcy by using the financial information already reflected in the deterioration of the financial condition of the company, the financial information was collected with a lag of two years, and the default period was defined from January to December of the year. Then we defined the bankruptcy. The bankruptcy we defined is the abolition of the listing due to sluggish earnings. We confirmed abolition of the list at KIND that is corporate stock information website. Then we selected variables at previous papers. The first set of variables are Z-score variables. These variables have become traditional variables in predicting bankruptcy. The second set of variables are dynamic variable set. Finally we selected 240 normal companies and 226 bankrupt companies at the first variable set. Likewise, we selected 229 normal companies and 226 bankrupt companies at the second variable set.  We created a model that reflects dynamic changes in time-series financial data and by comparing the suggested model with the analysis of existing bankruptcy predictive models, we found that the suggested model could help to improve the accuracy of bankruptcy predictions. We used financial data in KIS Value (Financial database) and selected Multivariate Discriminant Analysis (MDA), Generalized Linear Model called logistic regression (GLM), Support Vector Machine (SVM), Artificial Neural Network (ANN) model as benchmark.   The result of the experiment proved that RNN’s performance was better than comparative model. The accuracy of RNN was high in both sets of variables and the Area Under the Curve (AUC) value was also high. Also when we saw the hit-ratio table, the ratio of RNNs that predicted a poor company to be bankrupt was higher than that of other comparative models. However the limitation of this paper is that an overfitting problem occurs during RNN learning. But we expect to be able to solve the overfitting problem by selecting more lear"
한국어 음소 단위 LSTM 언어모델을 이용한 문장 생성,2017,"['언어 모델', '순환 신경망 모형', 'LSTM 모형', '문장 생성 모형', 'Language model', 'Recurrent neural network', 'Long short-term memory model', 'Sentence generation model']",,"Language models were originally developed for speech recognition and language processing. Using a set of example sentences, a language model predicts the next word or character based on sequential input data. N-gram models have been widely used but this model cannot model the correlation between the input units efficiently since it is a probabilistic model which are based on the frequency of each unit in the training set. Recently, as the deep learning algorithm has been developed, a recurrent neural network (RNN) model and a long short-term memory (LSTM) model have been widely used for the neural language model (Ahn, 2016; Kim et al., 2016; Lee et al., 2016). These models can reflect dependency between the objects that are entered sequentially into the model (Gers and Schmidhuber, 2001; Mikolov et al., 2010; Sundermeyer et al., 2012). In order to learning the neural language model, texts need to be decomposed into words or morphemes. Since, however, a training set of sentences includes a huge number of words or morphemes in general, the size of dictionary is very large and so it increases model complexity. In addition, word-level or morpheme-level models are able to generate vocabularies only which are contained in the training set. Furthermore, with highly morphological languages such as Turkish, Hungarian, Russian, Finnish or Korean, morpheme analyzers have more chance to cause errors in decomposition process (Lankinen et al., 2016).  Therefore, this paper proposes a phoneme-level language model for Korean language based on LSTM models. A phoneme such as a vowel or a consonant is the smallest unit that comprises Korean texts. We construct the language model using three or four LSTM layers. Each model was trained using Stochastic Gradient Algorithm and more advanced optimization algorithms such as Adagrad, RMSprop, Adadelta, Adam, Adamax, and Nadam. Simulation study was done with Old Testament texts using a deep learning package Keras based the Theano. After pre-processing the texts, the dataset included 74 of unique characters including vowels, consonants, and punctuation marks. Then we constructed an input vector with 20 consecutive characters and an output with a following 21st character. Finally, total 1,023,411 sets of input-output vectors were included in the dataset and we divided them into training, validation, testsets with proportion 70:15:15. All the simulation were conducted on a system equipped with an Intel Xeon CPU (16 cores) and a NVIDIA GeForce GTX 1080 GPU.  We compared the loss function evaluated for the validation set, the perplexity evaluated for the test set, and the time to be taken for training each model. As a result, all the optimization algorithms but the stochastic gradient algorithm showed similar validation loss and perplexity, which are clearly superior to those of the stochastic gradient algorithm. The stochastic gradient algorithm took the longest time to be trained for both 3- and 4-LSTM models. On average, the 4-LSTM layer model took 69% longer training time than the 3-LSTM layer model. However, the validation loss and perplexity were not improved significantly or became even worse for specific conditions. On the other hand, when comparing the automatically generated sentences, the 4-LSTM layer model tended to generate the sentences which are closer to the natural language than the 3-LSTM model. Although there were slight differences in the completeness of the generated sentences between the models, the sentence generation performance was quite satisfactory in any simulation conditions: they generated only legitimate Korean letters and the use of postposition and the conjugation of verbs were almost perfect in the sense of grammar. The results of this study are expected to be widely used for the processing of Korean language in the field of language processing and speech recognition, which are the basis of artificial intelligence systems."
교류협력국 교원 초청 교육정보화 연수의 성과 분석,2017,"['초등 글쓰기 자동 평가', '순환 신경망', '언어 모델', 'e-Learning Globalization Project', 'Training of ICT in Education for Teachers from Partner Country']","각 시·도교육청은 “이러닝 세계화 사업”의 일환으로 교류협력국의 교원을 초청하여 교육정보화 연수를 진행하 고 있다. 이 초청 연수의 목적은 이러닝 국가경쟁력 유지와 영향력 강화에 따른 국가 브랜드 제고, 우리의 선진 교육정보화 사례를 공유하여 국가 간 지식정보 격차 해소, 교육정보화 분야 교류협력을 통한 동반자적 관계 구 축, 교류협력국 선도 교원들이 자국의 교육정보화를 발전 및 확산할 수 있는 역량 강화 등이다. 2005년에 시작된 교류협력국의 교원 초청 교육정보화 연수가 10주년이 되는 시점을 맞이하여, 그간 진행된 연수 프로그램의 성과 를 반추하고 지속적인 발전 방안을 모색할 필요가 있다. 이를 위해 상황, 투입, 과정, 산출에 따른 현황을 분석하 기 위해 질적 연구를 수행하였다. 각 시·도교육청의 초청 연수 담당 장학사, 주무관, 그리고 해외 교원 등을 대 상으로 심층면담을 실시하였고, 그 면담 결과를 주제별로 구분하여 분석하였다.","Each City & Provincial office of education has provided educational informatization training, which invites its partner country’s teachers as part of ‘e-Learning Globalization Project.’ The purposes of this training program are, a) improving nation brand power by maintaining e-learning national competitiveness and strengthening influence, b) solving digital divide by sharing Korean best practices, c) establishing partnership through exchanges and  cooperation, d) capacity building which support partner country’s leading teachers can play key roles to spread educational informatization in their own country. It is necessary to reflect outcomes of training program until now and to find sustainable development plan, at 10th anniversary of Education ICT training program now. In order to fulfil purposes, qualitative research was conducted to analyze current status based on context, input, process, and product phases, and to find sustainable development alternative. In-depth interview(IDI) was conducted among  supervisor, officials, and teachers from partner countries. Also, the result of IDI was analyzed by themes."
Document Summarization Considering Entailment Relation between Sentences,2017,"['문서 요약', '수반 관계 추론', '자연어 처리', '텍스트 랭크', '순환 신경망', 'document summarization', 'entailment relation inference', 'natural language processing', 'TextRank', 'recurrent neural network']",,
