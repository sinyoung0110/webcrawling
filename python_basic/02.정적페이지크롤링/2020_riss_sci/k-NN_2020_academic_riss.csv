title,date,keywords,abstract,multilingual_abstract
k-NN 분류 모델의 학습 데이터 구성에 따른 PIC 보의 하중 충실도 향상에 관한 연구,2020,"['Piecewise Integrated Composite Beam', '3 point bending analysis', 'k-NN classification', 'Stress triaxiality', 'PIC 보', '3점 굽힘 해석', 'k-NN 분류', '3축 특성']","Piecewise Integrated Composite (PIC) 보는 하중 유형에 따라 구간을 나누어, 각 구간마다 하중 유형에 강한복합재료의 적층 순서를 배열한 보이다. 본 연구는 PIC 보의 구간을 머신 러닝의 일종인 k-NN(k-Nearest Neighbor) 분류를 통해 나누어 기존에 제시되었던 PIC 보에 비해 우수한 굽힘 특성을 갖게 하는 것이 목적이다. 먼저, 알루미늄 보의 3점 굽힘 해석을 통하여 참조점에서의 3축 특성(Triaxiality) 값 데이터를 얻었고, 이를 통해 인장, 전단, 압축의 레이블을 가진 학습 데이터가 만들어진다. 학습 데이터를 통해 각 면마다 독립적인 k-NN 분류 모델을 구성하는 방법(Each plane)과 전체 면에 대한 k-NN 분류 모델을 구성하는 방법(one part)을 이용하여 k-NN 분류 모델을 생성하였고, 하이퍼파라미터의 튜닝을 통하여 다양한 하중 충실도를 도출하였다. 가장 높은 하중 충실도를 가진 k-NN 분류 모델을 기반으로 보를 매핑(mapping)하였고, PIC 보에 대하여 유한요소 해석을 진행한 결과, 기존에 제시되었던 PIC 보에 비해 최대하중과 흡수 에너지가 커지는 특성을 보였다. 하중 충실도를 수동으로 조절하여 100%로 만든 PIC 보와 비교하였을 때, 최대하중과 흡수에너지가 미소한 차이가 나타났으며 이는 타당한 하중충실도로 보여진다.","Piecewise Integrated Composite (PIC) beam is composed of different stacking against loading type depending upon location. The aim of current study is to assign robust stacking sequences against external loading to every corresponding part of the PIC beam based on the value of stress triaxiality at generated reference points using the k-NN (k-Nearest Neighbor) classification, which is one of representative machine learning techniques, in order to excellent superior bending characteristics. The stress triaxiality at reference points is obtained by three-point bending analysis of the Al beam with training data categorizing the type of external loading, i.e., tension, compression or shear.Loading types of each plane of the beam were classified by independent plane scheme as well as total beam scheme.Also, loading fidelities were calibrated for each case with the variation of hyper-parameters. Most effective stacking sequences were mapped into the PIC beam based on the k-NN classification model with the highest loading fidelity.FE analysis result shows the PIC beam has superior external loading resistance and energy absorption compared to conventional beam."
클래스 불균형 데이터의 효과적인 분류를 위한 k-NN과 생성적 적대 신경망 기반의 오버샘플링,2020,"['Class Imbalance Dataset', 'Classifiers', 'Oversampling', 'GAN', 'k-Nearest Neighbor', 'N']",,"Class imbalanced dataset is common in real world and may degrade the performance of the classifier. To address this, oversampling method that artificially creates the samples of minority class is adopted but is known to be ineffective for the high-dimensional dataset because it generates the samples whose distribution is far different from that of existing samples. Novel oversampling methods based on the generative adversarial networks (GAN) have been recently developed, but generated samples may have different degrees of impact on the performance of the classifier. Therefore, more efficient method that can capture the characteristics of the generated samples and select those samples that will be used to train and improve the performance of the classifier is necessary. This study proposes a GAN-based new oversampling method which generates artificial samples based on the distribution of existing minority class samples and extracts only those which are effective to expand the realm of samples of minority class using the k-nearest neighbor. We show the proposed method outperforms existing methods with respect to F1-measure by several illustrative datasets."
DNN 모델을 이용한 기계 학습 기반 k-최근접 질의 처리 최적화 기법,2020,"['Machine learning', 'K-Recent Query Processing', 'DNN Model', 'Distributed Processing', 'Spark', '기계 학습', 'K-최근접 질의 처리', 'DNN 모델', '분산 처리', 'Spark']",본 논문에서는 고차원의 특징 벡터에서 질의와 가장 가까운 k개의 데이터를 찾는 k-최근접 질의 최적화 방법을 제안한다. k-최근접 질의는 k개의 데이터를 포함할 가능성이 있는 범위를 기반으로 범위 질의로 변환되어 처리하는 기법이다. 본 논문에서는 처리 비용을 감소시키고 검색 속도를 가속화 할 수 있는 최적의 범위를 도출하기 위해 k-최근접 질의 처리 시 DNN 모델을 이용한 최적화 기법을 제안한다. 제안하는 기법은 온라인 모듈과 오프라인 모듈로 구성된다. 온라인 모듈에서는 클라이언트로부터 요청을 받아 실제 질의를 처리한다. 오프라인 모듈에서는 과거 최적화 기법의 결과를 학습 로그로 사용한 DNN 모델로 최적의 범위를 도출하고 온라인 모듈로 전달한다. 제안하는 기법의 우수성 및 타당성의 입증을 위하여 다양한 성능 평가를 수행한다.,"In this paper, we propose an optimization scheme for a k-Nearest Neighbor(k-NN) query, which finds k objects closest to the query in the high dimensional feature vectors. The k-NN query is converted and processed into a range query based on the range that is likely to contain k data. In this paper, we propose an optimization scheme using DNN model to derive an optimal range that can reduce processing cost and accelerate search speed. The entire system of the proposed scheme is composed of online and offline modules. In the online module, a query is actually processed when it is issued from a client. In the offline module, an optimal range is derived for the query by using the DNN model and is delivered to the online module. It is shown through various performance evaluations that the proposed scheme outperforms the existing schemes."
온라인 리뷰 분석을 통한 상품 평가 기준 추출: LDA 및 k-최근접 이웃 접근법을 활용하여,2020,"['상품 평가 기준', '리뷰 분석', '평가기준 추출', 'LDA', 'k-NN', 'product evaluation criteria', 'review analysis', 'extracting evaluation criteria']",,"Product evaluation criteria is an indicator describing attributes or values of products, which enable users or manufacturers measure and understand the products. When companies analyze their products or compare them with competitors, appropriate criteria must be selected for objective evaluation. The criteria should show the features of products that consumers considered when they purchased, used and evaluated the products. However, current evaluation criteria do not reflect different consumers’ opinion from product to product. Previous studies tried to used online reviews from e-commerce sites that reflect consumer opinions to extract the features and topics of products and use them as evaluation criteria. However, there is still a limit that they produce irrelevant criteria to products due to extracted or improper words are not refined. To overcome this limitation, this research suggests LDA-k-NN model which extracts possible criteria words from online reviews by using LDA and refines them with k-nearest neighbor.  Proposed approach starts with preparation phase, which is constructed with 6 steps. At first, it collects review data from e-commerce websites. Most e-commerce websites classify their selling items by high-level, middle-level, and low-level categories. Review data for preparation phase are gathered from each middle-level category and collapsed later, which is to present single high-level category. Next, nouns, adjectives, adverbs, and verbs are extracted from reviews by getting part of speech information using morpheme analysis module. After preprocessing, words per each topic from review are shown with LDA and only nouns in topic words are chosen as potential words for criteria. Then, words are tagged based on possibility of criteria for each middle-level category. Next, every tagged word is vectorized by pre-trained word embedding model. Finally, k-nearest neighbor case-based approach is used to classify each word with tags.  After setting up preparation phase, criteria extraction phase is conducted with low-level categories. This phase starts with crawling reviews in the corresponding low-level category. Same preprocessing as preparation phase is conducted using morpheme analysis module and LDA. Possible criteria words are extracted by getting nouns from the data and vectorized by pre-trained word embedding model. Finally, evaluation criteria are extracted by refining possible criteria words using k-nearest neighbor approach and reference proportion of each word in the words set.  To evaluate the performance of the proposed model, an experiment was conducted with review on ‘11st’, one of the biggest e-commerce companies in Korea. Review data were from ‘Electronics/Digital’ section, one of high-level categories in 11st. For performance evaluation of suggested model, three other models were used for comparing with the suggested model; actual criteria of 11st, a model that extracts nouns by morpheme analysis module and refines them according to word frequency, and a model that extracts nouns from LDA topics and refines them by word frequency. The performance evaluation was set to predict evaluation criteria of 10 low-level categories with the suggested model and 3 models above. Criteria words extracted from each model were combined into a single words set and it was used for survey questionnaires. In the survey, respondents chose every item they consider as appropriate criteria for each category. Each model got its score when chosen words were extracted from that model. The suggested model had higher scores than other models in 8 out of 10 low-level categories. By conducting paired t-tests on scores of each model, we confirmed that the suggested model shows better performance in 26 tests out of 30. In addition, the suggested model was the best model in terms of accuracy.  This research proposes evaluation criteria extracting method that combines topic extraction using LDA and refinement with k-near"
Lazy Learning for Nonparametric Locally Weighted Regression,2020,"['k-nearest neighbors', 'Locally weighted regression', 'Weighted least square estimation', 'Lazy learning', 'Fuzzy C-means clustering']",,"In this study, a newly designed local model called locally weighted regression model is proposed for the regression problem. This model predicts the output for a newly submitted data point. In general, the local regression model focuses on an area of the input space specified by a certain kernel function (Gaussian function, in particular). The local area is defined as a region enclosed by a neighborhood of the given query point. The weights assigned to the local area are determined by the related entries of the partition matrix originating from the fuzzy C-means method. The local regression model related to the local area is constructed using a weighted estimation technique. The model exploits the concept of the nearest neighbor, and constructs the weighted least square estimation once a new query is provided given. We validate the modeling ability of the overall model based on several numeric experiments."
기업구조조정 혁신을 위한 선제적 한계기업 예측모형에 관한 연구,2020,"['기업 부실화', '기업 구조조정', '머신러닝', 'k-NN', '선제적 예측모형', 'Corporate Insolvency', 'Corporate Restructuring', 'Machine Learning', 'Preemptive Prediction Model']","기업 구조조정의 기반이라고 할 수 있는 워크아웃(Work-out)제도의 도입 이래, 기업 부실화에 대한 관리방안 및 제도는 금융시장 환경의 변화에 발맞춰 변모하고 있음에도 불구하고 사후관리에 치우쳐져 있다는 한계가 있다. 따라서, 본 연구에서는 이를 보완하기 위한 방안으로 기업 경영악화요인에 대한 사전 분석을 통해서 선제적 한계기업 예측모형을 구축하는 것을 목적으로 한다.  2015∼2018년을 기준으로 연도별 15만 여개의 기업에 대한 477,458건의 자료를 수집하고, 다양한 재무비율과 거시경제변수를 입력변수로 선정하였다. 또한 다양한 머신러닝을 활용한 방법론과 전통적 통계기법으로 예측 모형을 구축하고 성능을 비교함으로써, 부실 징후기업 예측에 대해 강건한 모델을 제안하고자 하였다. 실험 결과, k-NN(k-Nearest Neighbor) 알고리즘이 정상기업과 한계기업을 예측하는데 모두 강건한 모델을 제공하였으며, 특히 다른 방법론들과 달리 한계기업에 대한 연도별 예측 성능차이가 크지 않아 k-NN 알고리즘이 선제적 예측모형을 구축하고자 하는 본 연구의 목적과 가장 부합한 것으로 분석된다.","Since the introduction of the work-out system, which can be called the basis for corporate restructuring, the management system for corporate insolvency are shifting. But it has the limitation that they are biased toward follow-up management. Therefore, this study aims to build a preemptive prediction model for marginal companies through preliminary analysis of deteriorating factors in business.  As of 2015-2018, we have collected 477,458 data on about 150,000 companies per year and selected various financial ratios and macroeconomic variables as input variables. In addition, we intended to propose a robust model for the prediction of companies that are showing the signs of insolvency by comparing performance with methodologies using various machine learning and traditional statistical models. As a result of the experiment, k-NN(k-Nearest Neighbor) algorithm has established a robust model for both normal and marginal companies. In particular, for marginal companies, the prediction performance of k-NN algorithm is not significantly different from year to year unlike other methodologies, thus it is the most suitable for the purpose of this study to build a preemptive prediction model."
영화 관객 수 예측을 위한 기계학습 기법의 성능 평가 연구,2020,"['Box Office Forecasting', 'Machine Learning', 'Classification Model', 'Regression Model', 'Random Forest', 'K-NN', 'SVM', '영화 관객 수 예측', '기계학습', '분류 모형', '회귀 모형', 'Random Forest', 'k-NN', 'SVM']","영화 제작에 막대한 비용이 투입되지만 관객수요는 매우 불확실하기 때문에 개선된 수요예측은 수익 개선을 위한 의사결정의 중요 수단으로 활용될 수 있다. 본 연구에서는 영화의 개봉 후 수요를 예측함에 있어 기계학습 기법의 적용 타당성을 예측 성능의 관점에서 검증하였다. 분석결과를 종합하면 다음과 같다. 첫째, 대안변수에 대한 통계적 검증 결과 기본 영화 특성(감독, 배우)과 함께 개봉 후 2주차까지의 스크린수, 상영횟수, 관객수, 주요 배우에 대한 관심도 등 시계열 자료가 수요예측에 유의미한 것을 확인하였다. 둘째, Random Forest Classifier와 SVM(Support Vector Machine) 등 분류 기반 기계학습 기법과 Random Forest Regressor와 k-NN Regressor와 같은 회귀모형 기반 기계학습 기법에 적용하여 예측 성능을 평가한 결과, Random Forest 기법이 우수한 결과를 보였다. 셋째, 누적관객수가 1분위보다 작은 영화에서 회귀모형 기반 기법은 낮은 예측 정확도를 보였으며, 분류기반 기법은 반대로 가장 우수한 결과를얻었다. 즉, 영화 수요의 분포 특성에 따라서 차별화된 기계학습 기법을 적용하는 것이 필요하다.","The accurate prediction of box office in the early stage is crucial for film industry to make better managerial decision. With aims to improve the prediction performance, the purpose of this paper is to evaluate the use of machine learning methods. We tested both classification and regression based methods including k-NN, SVM and Random Forest. We first evaluate input variables, which show that reputation-related information generated during the first two-week period after release is significant. Prediction test results show that regression based methods provides lower prediction error, and Random Forest particularly outperforms other machine learning methods. Regression based method has better prediction power when films have small box office earnings. On the other hand, classification based method works better for predicting large box office earnings."
Human activity recognition with analysis of angles between skeletal joints using a RGB-depth sensor,2020,"['activity recognition', 'dimension reduction', 'Haar-wavelet transform', 'K-nearest neighbour', 'RGB-D sensor']",,"Human activity recognition (HAR) has become effective as a computer vision tool for video surveillance systems. In this paper, a novel biometric system that can detect human activities in 3D space is proposed. In order to implement HAR, joint angles obtained using an RGB-depth sensor are used as features. Because HAR is operated in the time domain, angle information is stored using the sliding kernel method. Haar-wavelet transform (HWT) is applied to preserve the information of the features before reducing the data dimension. Dimension reduction using an averaging algorithm is also applied to decrease the computational cost, which provides faster performance while maintaining high accuracy. Before the classification, a proposed thresholding method with inverse HWT is conducted to extract the final feature set. Finally, the K-nearest neighbor (k-NN) algorithm is used to recognize the activity with respect to the given data. The method compares favorably with the results using other machine learning algorithms."
위성영상과 머신러닝 모델을 이용한 폭염기간 고해상도 기온 추정 연구,2020,"['Remote Sensing', 'Machine Learning', 'Disaster Management', 'Heat Wave']","본 연구에서는 지상기상센서가 설치되지 않은 미 관측지점의 기온정보를 추정하기 위하여 K-최근접 이웃, 랜덤 포레스트, 신경망 알고리즘을 대상으로 위성영상을 이용하여 기온자료를 산출하고 그 정확성을 평가· 분석하고자 하였다. 위성영상자료는 2019년에 취득된 Landsat-8과 MODIS Aqua/Terra을 이용하였으며, 기상자료는 기상청과 산림청의 AWS/ASOS 자료를 이용하였다. 또한 추정 정확도를 향상시키기 위하여 수치표면 모델, 일사량, 경사방향, 경사도를 생성하여 이용하였다. 머신러닝 알고리즘 정확도 비교는 10-fold 교차검증을통하여 R2(결정계수) 및 RMSE(평균제곱근오차)의 통계량을 계산하여 대상지역별 추정결과를 비교하였다. 그결과 신경망 알고리즘이 R2=0.805, RMSE=0.508로 세 알고리즘 중 가장 안정적인 결과를 나타내었다. 신경망알고리즘을 구축된 위성영상 데이터셋에 적용하여 2019년 6월부터 9월까지의 평균기온 지도를 생성할 수 있었으며 세밀한 기온 정보를 관측할 수 있음을 확인하였다. 연구 성과는 폭염 대응 정책, 열섬완화 연구 등 국가재난안전 관리에 활용 될 수 있을 것으로 기대된다.","This study investigates the feasibility of three algorithms, K-Nearest Neighbors (K-NN), Random Forest (RF) and Neural Network (NN), for estimating the air temperature of an unobserved area where the weather station is not installed. The satellite image were obtained from Landsat-8 and MODIS Aqua/Terra acquired in 2019, and the meteorological ground weather data were from AWS/ASOS data of Korea Meteorological Administration and Korea Forest Service. In addition, in order to improve the estimation accuracy, a digital surface model, solar radiation, aspect and slope were used. The accuracy assessment of machine learning methods was performed by calculating the statistics of R2 (determination coefficient) and Root Mean Square Error (RMSE) through 10-fold cross-validation and the estimated values were compared for each target area. As a result, the neural network algorithm showed the most stable result among the three algorithms with R2 = 0.805 and RMSE = 0.508. The neural network algorithm was applied to each data set on Landsat imagery scene. It was possible to generate an mean air temperature map from June to September 2019 and confirmed that detailed air temperature information could be estimated. The result is expected to be utilized for national disaster safety management such as heat wave response policies and heat island mitigation research."
염색체 도식화와 imputation에 의한 GBS 기반 여교잡 회복률 계산 정확도 증진 방법,2020,"['tomato', 'a graphical representation', 'marker selection', 'marker-assisted backcrossing', 'marker-assisted selection']",,"Marker-assisted backcrossing is a powerful method for developing new cultivars. To develop genomic-wide markers, genotyping-by-sequencing(GBS) can be an efficient method. However, unrefined low-quality markers and missing data between markers can contribute to hamperingthe marker selection process, particularly in multi-way crosses. In this study, we aimed to calculate the recovery rate of offspring individualsand minimize errors that occur among a large number of markers. Initially, missing data were imputed by comparing samples using the k-nearestneighbor (k-NN) algorithm. Thereafter, low-quality single-nucleotide polymorphisms (SNPs) were corrected by applying the graphical representationmethod based on the k-NN algorithm in order of the SNPs in a chromosome designed for a multi-parental population. Four-way cross anddouble-backcrossed tomato BC1F1 (230 lines) and BC2F1 (96 lines) populations were genotyped by GBS. The genotype of samples of theBC1F1 and BC2F1 populations was determined based on the parental haplotype. Thus, the method of visualizing the genotype of offspringindividuals, generated via crosses of multiple parents, not only improves estimation of the recovery rate but also facilitates easier selectionin breeding programs."
스파크 환경에서 내용 기반 이미지 검색을 위한 효율적인 분산 인-메모리 고차원 색인 기법,2020,"['metric space', 'image similarity search', 'high dimensional indexing', 'distributed processing', 'spark', '거리 공간', '이미지 유사도 검색', '고차원 색인', '분산 처리', '스파크']",영상에서 범죄 행위 모니터링 및 추적을 위해서 이미지 내에 포함된 객체를 검색하는 내용 기반 검색이 활용되고 있다. 본 논문에서는 내용 기반 이미지 검색을 위해 이미지 또는 객체에서 추출한 대용량 특징 벡터를 이용한 유사도 검색을 지원하는 분산 인-메모리 기반 고차원 색인 기법을 제안한다. 대용량 분산 처리를 위해 빅데이터 플랫폼인 스파크를 활용하고 효율적인 분산 질의 처리 할당을 위해 마스터/슬레이브 모델을 활용한다. 마스터에서는 데이터 및 질의 분배를 수행하고 슬레이브에서는 데이터를 색인한다. 더불어 기존 분산 고차원 색인 기법에서 k-최근접 질의 처리의 성능 문제를 해결하기 위해서 밀집도 및 탐색 비용을 고려한 k-최근접 질의 최적화 기법을 제안한다. 제안하는 기법의 우수성 및 타당성을 입증하기 위해 다양한 성능 평가를 수행한다.,"Content-based image retrieval that searches an object in images has been utilizing for criminal activity monitoring and object tracking in video. In this paper, we propose a high-dimensional indexing scheme based on distributed in-memory for the content-based image retrieval. It provides similarity search by using massive feature vectors extracted from images or objects. In order to process a large amount of data, we utilized a big data platform called Spark. Moreover, we employed a master/slave model for efficient distributed query processing allocation. The master distributes data and queries. and the slaves index and process them. To solve k-NN query processing performance problems in the existing distributed high-dimension indexing schemes, we propose optimization methods for the k-NN query processing considering density and search costs. We conduct various performance evaluations to demonstrate the superiority of the proposed scheme."
한국인 영어 학습자의 쓰기능력별 어휘 및 연어 사용 양상 분석,2020,"['corpus analysis', 'vocabulary', 'productive vocabulary', 'collocation', 'writing proficiency', 'part of speech tagging']",,"This study examined both lexical and collocational knowledge of Korean college students in relation to their writing proficiency measured by a diagnostic writing test. The study analyzed essays written in response to two topics by college students at three different proficiency levels (high, mid, low). In a comparison of vocabulary used in the essays, the study noted differences between the proficiency levels in terms of token and type frequencies. However, the lexical distribution patterns in reference to graded word-lists were similar across the proficiency levels. Regardless of the topic, approximately 90% of words used in the essays were from the first 2K words, and about 95% of words from the first 3K words. As to learner use of collocation, collocational expressions were more frequently used by advanced learners, compared to intermediate- or low-level learners. Despite the difference, collocational distribution patterns according to the graded collocation-list were also similar across the three proficiency levels. Regarding part-of-speech-tagged collocation, students tended to overuse a limited set of patterns, such as AJ-NN, NN-NN, and VP-AVP. Findings are discussed in more detail, along with pedagogical implications."
도로 네트워크에서 랜드마크 다차원 척도법을 이용한 효율적인 M-트리 대량적재 알고리즘,2020,"['M-tree', 'bulk loading', 'road network', 'landmark multidimensional scaling', 'M-트리', '대량적재', '도로 네트워크', '랜드마크 다차원 척도법']","본 연구에서는 도로 네트워크를 위한 M-트리 대량적재(bulk loading) 알고리즘을 제안한다. 도로 네트워크는 매우 동적이며, 차량의 이동, 예측하지 못한 공사와 사고 등으로 인하여 교통 상황이 끊임없이 변화한다.도로 네트워크 응용에서는 이러한 변화를 반영하도록 인덱스를 주기적으로 재구성하는 것이 필수적이다. 각각의 변화에 대하여 기존의 인덱스를 수정하기보다는 전체 도로 네트워크 데이터셋에 대한 새로운 인덱스를빠르게 재구성하는 대량적재가 효율적이다. 기존의 M-트리 대량적재 알고리즘은 ‘비싼’ 최단경로 거리 계산과 디스크 페이지 엑세스를 과도하게 수행하여 충분한 성능을 거두지 못하였다. 본 연구에서 제안하는 M-트리 대량적재 알고리즘은 랜드마크 다차원 척도법(Landmark Multidimensional Scaling, LMDS)을 이용하여 최단경로 거리 계산을 대폭 줄인다. 또한, 각 노드를 한번씩만 디스크에 저장하고 더 이상 읽지 않음으로써 디스크 액세스 횟수를 크게 줄였다. 실험 결과, 제안된 알고리즘은 기존의 알고리즘에 비하여 단일 쓰레드버전은 최대 21.3배, 다중 쓰레드 버전(동시 쓰레드 64개)은 최대 106배까지 M-트리 생성 성능이 향상되었고, 제안된 알고리즘으로 생성한 M-트리를 이용한 k-최근접 객체(k-nearest neighbor) 검색의 성능이 최대 1.22 배까지 향상되었다.","In this study, we propose an algorithm for M-tree bulk loading in road networks. Road networks are highly dynamic; traffic situation changes constantly owing to vehicle movements and unpredicted constructions and accidents. Thus, it is crucial for road network applications to periodically reorganize the index to fully reflect the changes. In such a circumstance, rather than modifying the existing index for each of the changes, it is more efficient to quickly bulk load a new index for the entire road network. The previous M-tree bulk loading algorithms heavily conduct ‘expensive’ shortest-path distance computations and disk page accesses, thereby degrading their performances. The algorithm proposed in this study reduces the number of shortest-path distance computations using landmark multidimensional scaling (LMDS). In addition, since our algorithm stores M-tree nodes in disk and does not access them again, the number of disk page accesses is also dramatically reduced. Experimental results demonstrated that our algorithm outperformed the previous algorithm by up to 21.3 times (single-thread version) and 106 times (multi-thread version with 64 concurrent threads) for M-tree construction and that the performance of the k-nearest neighbor (k-NN) search using the M-tree built by our algorithm was also improved by up to 1.22 times."
인공지능 기법을 활용한 공직기강 감찰활동 효과성 향상에 관한 연구,2020,"['인공지능', '기계학습', '감사', '공직기강', '감찰활동']","광범위하게 확산되고 있는 디지털화에 따라 레그테크(RegTech)의 활용 가능성과 사례도점점 증가하고 있으며, 그중에서도 감사활동에 기계학습의 응용 가능성이 높음을 증명하는 사례들이 주목을 받고 있다.본 연구에서는 사후 적발 위주의 공직기강 감찰 활동의 문제점을 개선하고, 상시적 예방 감찰 활동 수행을 위하여 인공지능 기술을 활용하고자 한다. 구체적으로 기계학습 기법을 활용하여 특히 PC ON 초과 시간 여부 예측 모형을 만들었으며, 공직기강 감찰활동의 근태점검에 상시적으로 인공지능 기법의 활용 가능성에 대해서 연구하였다.본 실험을 위해서 2020년 2월부터 2020년 7월까지의 모공공기관 직원의 사내 PC ON 시간 데이터 88,723개를 사용하였으며, 전체데이터는 훈련데이터 75%와 테스트데이터 25%로각각 분리하였고, k-겹 교차검증(K-fold Cross-validation) 방법을 사용하여 예측 정확도를 향상시키기 위해 노력하였다.다양한 예측모형 생성 실험을 위해서 k-NN, 의사결정트리, 랜덤 포레스트, 그래디언트 부스팅, 신경망 등 5개의 기계학습 기법들을 사용하였으며, 각 기법들에 대한 최적화를 수행하여 최적화 모델의 정확도를 비교 분석하였다.실험 결과 PC ON 초과 시간 여부 예측 모델 생성시‘근무유형’, ‘사번’, ‘부서명’, ‘월’ 변수가 중요한 특성 요소로 선택되었음을 확인하였고, 예측 결과가 가장 좋은 모델은 94.4%의 정확도를 가진 최적화된 랜덤 포레스트 모델이였다.","With the widespread digitalization, the availability and cases of RegTech are also increasing. Among them, cases proving that machine learning is highly likely to be applied to audit activities are drawing attention.In this study, we aim to improve the problems of post-detection-oriented public discipline inspection activities and utilize artificial intelligence technology to carry out preventive inspection activities on a regular basis. Specifically, the machine learning techniques were used to create a prediction model for PC ON overtime, and the possibility of using artificial intelligence techniques on a regular basis was studied for checking the absenteeism and tardiness of public office discipline.For this experiment, in-house PC ON time data of employees of a public institution were used from February 2020 to July 2020, and the entire data were separated into 75% of training data and 25% of test data, respectively, with using k-fold cross-validation method for improving prediction accuracy.For various predictive model generation experiments, five machine learning techniques were used: k-NN, decision tree, random forest, gradient boosting, and neural network. Optimization of each technique was performed to compare the accuracy of the optimization model.The results of the experiment confirmed that the ‘work type’, ‘employee number’, ‘department’, and ‘month’variables were selected as important characteristic elements when the PC ON overtime classification prediction model was created. The best model in the forecast was the optimized random forest model with 94.4% accuracy."
Fast Leaf Recognition and Retrieval Using Multi-Scale Angular Description Method,2020,"['Image Retrieval', 'k-NN', 'Leaf Recognition', 'Multi-Scale', 'SVM']",,"Recognizing plant species based on leaf images is challenging because of the large inter-class variation andinter-class similarities among different plant species. The effective extraction of leaf descriptors constitutes themost important problem in plant leaf recognition. In this paper, a multi-scale angular description method isproposed for fast and accurate leaf recognition and retrieval tasks. The proposed method uses a novel scalegenerationrule to develop an angular description of leaf contours. It is parameter-free and can capture leaffeatures from coarse to fine at multiple scales. A fast Fourier transform is used to make the descriptor compactand is effective in matching samples. Both support vector machine and k-nearest neighbors are used to classifyleaves. Leaf recognition and retrieval experiments were conducted on three challenging datasets, namelySwedish leaf, Flavia leaf, and ImageCLEF2012 leaf. The results are evaluated with the widely used standardmetrics and compared with several state-of-the-art methods. The results and comparisons show that theproposed method not only requires a low computational time, but also achieves good recognition and retrievalaccuracies on challenging datasets."
사용자의 온오프 라인 쇼핑에서 상품 추천을 위한 전이학습 모델 비교,2020,"['Recommendation', 'Deep Learning', 'Transfer Learning', 'FCN', 'k-NN', 'Linear SVM']",,"Recently, deep learning based services has been actively developed in various fields. Especially, in the online distribution environment some Applications with deep learning based on large amounts of data and user information began to be applied to real systems. In this paper, we develop an application system which recommends goods after learning and predicting using deep learning by presenting good image that user wants to purchase in online market sites. At this time, we apply three revised models based on the transfer learning model for automatic image recognition. After image recognition of goods, the system produces candidate goods and requires filter condition input for goods he wants to purchase. Finally, the system recommends goods by content-based recommendation method. In this paper, we experiment three revised models of image recognition which are used as core techniques in the system. These models are fully connected network, k-nearest neighbors search and linear SVM and they act as a classifier within the transfer learning model architecture. We experiment and compare performance evaluation for the revised models."
119 신고 데이터를 이용한 자연어처리 기반 재난안전 상황 분류 알고리즘 분석,2020,"['인공지능', '재난 대응', '자연어처리', '상황 분류', '기계학습', 'Artificial Intelligence', 'Emergency Response', 'Natural Language Processing', 'Situation Classification', 'Machine Learning']",,"Due to the development of artificial intelligence, it is used as a disaster response support system in the field of disaster. Disasters can occur anywhere, anytime. In the event of a disaster, there are four types of reports: fire, rescue, emergency, and other call. Disaster response according to the 119 call also responds differently depending on the type and situation. In this paper, 1280 data set of 119 calls were tested with 3 classes of SVM, NB, k-NN, DT, SGD, and RF situation classification algorithms using a training data set. Classification performance showed the highest performance of 92% and minimum of 77%. In the future, it is necessary to secure an effective data set by disaster in various fields to study disaster response."
Activity and Safety Recognition using Smart Work Shoes for Construction Worksite,2020,"['Construction site', 'Worker', 'Safety', 'Conductive textile', 'Stairs']",,"Workers at construction sites are easily exposed to many dangers and accidents involving falls, tripping, and missteps on stairs. However, researches on construction site monitoring system to prevent work-related injuries are still insufficient. The purpose of this study was to develop a wearable textile pressure insole sensor and examine its effectiveness in managing the real-time safety of construction workers. The sensor was designed based on the principles of parallel capacitance measurement using conductive textile and the monitoring system was developed by C# language. Three separate experiments were carried out for performance evaluation of the proposed sensor: (1) varying the distance between two capacitance plates to examine changes in capacitance charges, (2) repeatedly applying 1 N of pressure for 5,000 times to evaluate consistency, and (3) gradually increasing force by 1 N (from 1 N to 46 N) to test the linearity of the sensor value. Five subjects participated in our pilot test, which examined whether ascending and descending the stairs can be distinguished by our sensor and by weka assessment tool using k-NN algorithm. The 10-fold cross-validation method was used for analysis and the results of accuracy in identifying stair ascending and descending were 87.2% and 90.9%, respectively. By applying our sensor, the type of activity, weight-shifting patterns for balance control, and plantar pressure distribution for postural changes of the construction workers can be detected. The results of this study can be the basis for future sensor-based monitoring device development studies and fall prediction researches for construction workers."
Genetic diversity and population structure of indigenous chicken of Bangladesh using microsatellite markers,2020,"['Indigenous Chicken', 'Genetic Diversity', 'Microsatellite Marker', 'Bangladesh']",,"Objective: The objectives of this study were to investigate the genetic diversity, population structure and relatedness among the five chicken populations of Bangladesh using microsatellite markers.Methods: A total of 161 individuals representing 5 chicken populations (non-descript Deshi [ND], naked neck [NN], hilly [HI], Aseel [AS], and red jungle fowl [JF]) were included in this study to investigate genetic diversity measures, population structure, genetic distance and phylogenetic relationships. Genotyping was performed using 16 selected polymorphic microsatellite markers distributed across 10 chromosomes.Results: The average observed and expected heterozygosity, mean number of alleles and polymorphic information content were found to be 0.67±0.01, 0.70±0.01, 10.7 and 0.748, respectively in the studied populations. The estimated overall fixation index across the loci (F), heterozygote deficiency within (FIS) and among (FIT) chicken populations were 0.04±0.02, 0.05 and 0.16, respectively. Analysis of molecular variance analysis revealed 88.07% of the total genetic diversity was accounted for within population variation and the rest 11.93% was incurred with population differentiation (FST). The highest pairwise genetic distance (0.154) was found between ND and AS while the lowest distance was between JF and AS (0.084). Structure analysis depicted that the studied samples can be categorized into four distinct types or varieties (ΔK = 3.74) such as ND, NN, and HI where AS and JF clustered together as an admixed population. The Neighbor-Joining phylogenetic tree and discriminant analysis of principal component also showed close relatedness among three chicken varieties namely AS, HI, and JF.Conclusion: The results reflected that indigenous chicken of Bangladesh still possess rich genetic diversity but weak differentiation among the studied populations. This finding provides some important insight on genetic diversity measures that could support the designing and implementing of future breeding plans for indigenous chickens of Bangladesh."
