title,date,keywords,abstract,multilingual_abstract
A novel visual tracking system with adaptive incremental extreme learning machine,2017,"['Extreme learning machine', 'visual tracking', 'overall output weights', 'random Haar-like features', 'adaptive learning rate']",,"This paper presents a novel discriminative visual tracking algorithm with an adaptive incremental extreme learning machine. The parameters for an adaptive incremental extreme learning machine are initialized at the first frame with a target that is manually assigned. At each frame, the training samples are collected and random Haar-like features are extracted. The proposed tracker updates the overall output weights for each frame, and the updated tracker is used to estimate the new location of the target in the next frame. The adaptive learning rate for the update of the overall output weights is estimated by using the confidence of the predicted target location at the current frame. Our experimental results indicate that the proposed tracker can manage various difficulties and can achieve better performance than other state-of-the-art trackers."
기계학습(machine learning) 기반 터널 영상유고 자동 감지 시스템 개발을 위한 사전검토 연구,2017,['CCTV'],,"In this study, a preliminary study was undertaken for development of a tunnel incident automatic detection system based on a machine learning algorithm which is to detect a number of incidents taking place in tunnel in real time and also to be able to identify the type of incident. Two road sites where CCTVs are operating have been selected and a part of CCTV images are treated to produce sets of training data. The data sets are composed of position and time information of moving objects on CCTV screen which are extracted by initially detecting and tracking of incoming objects into CCTV screen by using a conventional image processing technique available in this study. And the data sets are matched with 6 categories of events such as lane change, stoping, etc which are also involved in the training data sets. The training data are learnt by a resilience neural network where two hidden layers are applied and 9 architectural models are set up for parametric studies, from which the architectural model, 300(first hidden layer)-150(second hidden layer) is found to be optimum in highest accuracy with respect to training data as well as testing data not used for training. From this study, it was shown that the highly variable and complex traffic and incident features could be well identified without any definition of feature regulation by using a concept of machine learning. In addition, detection capability and accuracy of the machine learning based system will be automatically enhanced as much as big data of CCTV images in tunnel becomes rich."
A Machine-Learning Based Approach for Extracting Logical Structure of a Styled Document,2017,"['Logical Structure Analysis', 'Machine Learning', 'Feature Vector', 'Document Management System']",,"A styled document is a document that contains diverse decorating functions such as different font, colors, tables and images generally authored in a word processor (e.g., MS-WORD, Open Office). Compared to a plain-text document, a styled document enables a human to easily recognize a logical structure such as section, subsection and contents of a document. However, it is difficult for a computer to recognize the structure if a writer does not explicitly specify a type of an element by using the styling functions of a word processor. It is one of the obstacles to enhance document version management systems because they currently manage the document with a file as a unit, not the document elements as a management unit. This paper proposes a machine learning based approach to analyzing the logical structure of a styled document composing of sections, subsections and contents. We first suggest a feature vector for characterizing document elements from a styled document, composing of eight features such as font size, indentation and period, each of which is a frequently discovered item in a styled document. Then, we trained machine learning classifiers such as Random Forest and Support Vector Machine using the suggested feature vector. The trained classifiers are used to automatically identify logical structure of a styled document. Our experiment obtained 92.78% of precision and 94.02% of recall for analyzing the logical structure of 50 styled documents."
Prediction & Assessment of Change Prone Classes Using Statistical & Machine Learning Techniques,2017,"['Change Proneness', 'Empirical Validation', 'Machine Learning Techniques', 'Software Quality']",,"Software today has become an inseparable part of our life. In order to achieve the ever demanding needs of customers, it has to rapidly evolve and include a number of changes. In this paper, our aim is to study the relationship of object oriented metrics with change proneness attribute of a class. Prediction models based on this study can help us in identifying change prone classes of a software. We can then focus our efforts on these change prone classes during testing to yield a better quality software. Previously, researchers have used statistical methods for predicting change prone classes. But machine learning methods are rarely used for identification of change prone classes. In our study, we evaluate and compare the performances of ten machine learning methods with the statistical method. This evaluation is based on two open source software systems developed in Java language. We also validated the developed prediction models using other software data set in the same domain (3D modelling). The performance of the predicted models was evaluated using receiver operating characteristic analysis. The results indicate that the machine learning methods are at par with the statistical method for prediction of change prone classes. Another analysis showed that the models constructed for a software can also be used to predict change prone nature of classes of another software in the same domain. This study would help developers in performing effective regression testing at low cost and effort. It will also help the developers to design an effective model that results in less change prone classes, hence better maintenance."
COPD 코호트 자료에서의 Machine Learning 방법론 비교,2017,,,"Recently, Machine Learning Methods are widely used with high prediction performance. But if the limit of the data is solved by the statistical technique, It can, lead to higher prediction performance than the existing one. In this study, the SMOTE method is used to solve the imbalance problem in the longitudinal and imbalanced data. As a result, It, was confirmed that the prediction performance increases. Additionally, Although, studies on COPD have been actively conducted, only studies that are related to acute exacerbation have been conducted. So there are no studies on the prediction of acute exacerbation through multiple perspectives and predictive models for various factors. In this study, We examined the factors related to acute exacerbation of COPD and constructed a personalized specific disease prediction model."
XSSClassifier: An Efficient XSS Attack Detection Approach Based on Machine Learning Classifier on SNSs,2017,"['Cross-Site Scripting Attack Detection', 'Dataset', 'JavaScript', 'Machine Learning Classifier', 'Social Networking Services']",,"Social networking services (SNSs) such as Twitter, MySpace, and Facebook have become progressively significant with its billions of users. Still, alongside this increase is an increase in security threats such as crosssite scripting (XSS) threat. Recently, a few approaches have been proposed to detect an XSS attack on SNSs. Due to the certain recent features of SNSs webpages such as JavaScript and AJAX, however, the existing approaches are not efficient in combating XSS attack on SNSs. In this paper, we propose a machine learningbased approach to detecting XSS attack on SNSs. In our approach, the detection of XSS attack is performed based on three features: URLs, webpage, and SNSs. A dataset is prepared by collecting 1,000 SNSs webpages and extracting the features from these webpages. Ten different machine learning classifiers are used on a prepared dataset to classify webpages into two categories: XSS or non-XSS. To validate the efficiency of the proposed approach, we evaluated and compared it with other existing approaches. The evaluation results show that our approach attains better performance in the SNS environment, recording the highest accuracy of 0.972 and lowest false positive rate of 0.87."
건설산업 내 기계학습 알고리즘 (Machine Learning Algorithm) 활용 동향,2017,,,
Novel Approaches for Applying Linguistic Processing Techniques Based on Pattern Recognition and Machine Learning,2017,,,
Designing a Consumer Dispute Settlement System by Applying Machine Learning,2017,"['소비자피해', '분쟁조정시스템', '머신러닝', '중재', 'Consumer Damage', 'Dispute System', 'Machine Learning', 'Mediation']",,"Through the advancement of machine le arning technology, difficult problems in various fields have been resolved in an efficient and powerful manner. In the pa st, programs were only able to carry out commands that were strictly given by the code. Today, supervised machine learni ng enables programs to learn from any given set of data. Machine learning prog rams are capable of processing large a mounts of data and can make accurate predictions by finding new patterns with out continuous human supervision.This powerful ability can be applied in many different areas. This study in parti cular investigates how machine learning can be applied to resolve the problems in referencing the successful mediation cases in consumer disputes that are pro vided by the Korean Consumer Agency on their Consumer Dispute Mediation w ebsite. More specifically, this research utilizes library methods provided by sciki t-learn, an effective data analysis tool, in order to explain the process and appli cation of machine learning. By presenting the advantages of applying machine lea rning to successful mediation in consum er disputes, this research aims to explai n why a machine learning system would be appropriate for the Consumer Dispute Mediation system.The application of machine learning will allow the system to assume the burden of consumers in finding and analyzing the data provided by the Korean Consu mer Agency through a completely differ ent paradigm. The new system will effici ently learn, analyze, and solve the diffic ult problems of consumers, creating an overall improved user experience. As the system can easily obtain the information required by the consumer, it is expected that the utility of the system will continue to increase over time."
Large-scale machine learning of media outlets for understanding public reactions to nation-wide viral infection outbreaks,2017,"['Machine learning', 'Middle East respiratory syndrome (MERS)', 'Natural language processing', 'Sentiment analysis']",,"<P>From May to July 2015, there was a nation-wide outbreak of Middle East respiratory syndrome (MERS) in Korea. MERS is caused by MERS-CoV, an enveloped, positive-sense, single-stranded RNA virus belonging to the family Coronaviridae. Despite expert opinions that the danger of MERS might be exaggerated, there was an overreaction by the public according to the Korean mass media, which led to a noticeable reduction in social and economic activities during the outbreak. To explain this phenomenon, we presumed that machine learning-based analysis of media outlets would be helpful and collected a number of Korean mass media articles and short-text comments produced during the 10-week outbreak. To process and analyze the collected data (over 86 million words in total) effectively, we created a methodology composed of machine-learning and information-theoretic approaches. Our proposal included techniques for extracting emotions from emoticons and Internet slang, which allowed us to significantly (approximately 73%) increase the number of emotion-bearing texts needed for robust sentiment analysis of social media. As a result, we discovered a plausible explanation for the public overreaction to MERS in terms of the interplay between the disease, mass media, and public emotions. (C) 2017 Elsevier Inc. All rights reserved.</P>"
Automatic Machine Fault Diagnosis System using Discrete Wavelet Transform and Machine Learning,2017,"['Pattern Recognition', 'Machine Learning', 'Machine Fault Diagnosis', 'Discrete Wavelet Transform', 'Principal Component Analysis', 'Artificial Neural Network']",,"Sounds based machine fault diagnosis recovers all the studies that aim to detect automatically faults or damages on machines using the sounds emitted by these machines. Conventional methods that use mathematical models have been found inaccurate because of the complexity of the industry machinery systems and the obvious existence of nonlinear factors such as noises. Therefore, any fault diagnosis issue can be treated as a pattern recognition problem. We present here an automatic fault diagnosis system of hand drills using discrete wavelet transform (DWT) and pattern recognition techniques such as principal component analysis (PCA) and artificial neural networks (ANN). The diagnosis system consists of three steps. Because of the presence of many noisy patterns in our signals, we first conduct a filtering analysis based on DWT. Second, the wavelet coefficients of the filtered signals are extracted as our features for the pattern recognition part. Third, PCA is performed over the wavelet coefficients in order to reduce the dimensionality of the feature vectors. Finally, the very first principal components are used as the inputs of an ANN based classifier to detect the wear on the drills. The results show that the proposed DWT-PCA-ANN method can be used for the sounds based automated diagnosis system."
XSSClassifier: An Efficient XSS Attack Detection Approach Based on Machine Learning Classifier on SNSs,2017,"['Cross-Site Scripting Attack Detection', 'Dataset', 'JavaScript', 'Machine Learning Classifier', 'Social Networking Services']",,"Social networking services (SNSs) such as Twitter, MySpace, and Facebook have become progressively significant with its billions of users. Still, alongside this increase is an increase in security threats such as cross-site scripting (XSS) threat. Recently, a few approaches have been proposed to detect an XSS attack on SNSs. Due to the certain recent features of SNSs webpages such as JavaScript and AJAX, however, the existing approaches are not efficient in combating XSS attack on SNSs. In this paper, we propose a machine learning-based approach to detecting XSS attack on SNSs. In our approach, the detection of XSS attack is performed based on three features: URLs, webpage, and SNSs. A dataset is prepared by collecting 1,000 SNSs webpages and extracting the features from these webpages. Ten different machine learning classifiers are used on a prepared dataset to classify webpages into two categories: XSS or non-XSS. To validate the efficiency of the proposed approach, we evaluated and compared it with other existing approaches. The evaluation results show that our approach attains better performance in the SNS environment, recording the highest accuracy of 0.972 and lowest false positive rate of 0.87."
"Machine learning-based anomaly detection via integration of manufacturing, inspection and after-sales service data",2017,,,"<P>Originality/value-Through data integration, the actual customer-perceived quality from after-sales service is linked to data from manufacturing and inspection process. In terms of business application, data integration and machine learning-based anomaly detection can help manufacturers establish quality management policies that reflect the actual customer-perceived quality by predicting defective engines.</P>"
Machine learning-based identification of endogenous cellular microRNA sponges against viral microRNAs,2017,"['Machine learning', 'Hierarchical agglomerative clustering', 'microRNA sponge', 'Competing endogenous RNA (ceRNA)', 'Pseudogene']",,"<P>A 'miRNA sponge' is an artificial oligonucleotide-based miRNA inhibitor containing multiple binding sites for a specific miRNA. Each miRNA sponge can bind and sequester several miRNA copies, thereby decreasing the cellular levels of the target miRNA. In addition to developing artificial miRNA sponges, scientists have sought endogenous RNA transcripts and found that long non-coding RNAs, competing endogenous RNAs, pseudogenes, circular RNAs, and coding RNAs could act as miRNA sponges under precise conditions. Here we present a computational approach for the prediction of endogenous human miRNA sponge candidates targeting viral miRNAs derived from pathogenic human viruses. Viral miRNA binding sites were predicted using a newly-developed machine learning-based method, and candidate interactions between miRNAs and sponge RNAs were experimentally validated using luciferase reporter assay, western blot analysis, and flow cytometry. We found that BX649188.1 functions as a potential natural miRNA sponge against kshv-miR-K12-7-3p. (C) 2017 Elsevier Inc. All rights reserved.</P>"
Machine Learning Frameworks for Automated Software Testing Tools : A Study,2017,"['Software Testing', 'Machine Learning', 'Testing Automation', 'Software Testing Tool']",,"Increased use of software and complexity of software functions, as well as shortened software quality evaluation periods, have increased the importance and necessity for automation of software testing. Automating software testing by using machine learning not only minimizes errors in manual testing, but also allows a speedier evaluation. Research on machine learning in automated software testing has so far focused on solving special problems with algorithms, leading to difficulties for the software developers and testers, in applying machine learning to software testing automation. This paper, proposes a new machine learning framework for software testing automation through related studies. To maximize the performance of software testing, we analyzed and categorized the machine learning algorithms applicable to each software test phase, including the diverse data that can be used in the algorithms. We believe that our framework allows software developers or testers to choose a machine learning algorithm suitable for their purpose."
Machine Learning Frameworks for Automated Software Testing Tools : A Study,2017,"['Software Testing', 'Machine Learning', 'Testing Automation', 'Software Testing Tool']",,"Increased use of software and complexity of software functions, as well as shortened software quality evaluation periods, have increased the importance and necessity for automation of software testing. Automating software testing by using machine learning not only minimizes errors in manual testing, but also allows a speedier evaluation. Research on machine learning in automated software testing has so far focused on solving special problems with algorithms, leading to difficulties for the software developers and testers, in applying machine learning to software testing automation. This paper, proposes a new machine learning framework for software testing automation through related studies. To maximize the performance of software testing, we analyzed and categorized the machine learning algorithms applicable to each software test phase, including the diverse data that can be used in the algorithms. We believe that our framework allows software developers or testers to choose a machine learning algorithm suitable for their purpose."
Machine Learning Frameworks for Automated Software Testing Tools,2017,"['Software Testing', 'Machine Learning', 'Testing Automation', 'Software Testing Tool']",,"Increased use of software and complexity of software functions, as well as shortened software quality evaluation periods, have increased the importance and necessity for automation of software testing. Automating software testing by using machine learning not only minimizes errors in manual testing, but also allows a speedier evaluation. Research on machine learning in automated software testing has so far focused on solving special problems with algorithms, leading to difficulties for the software developers and testers, in applying machine learning to software testing automation. This paper, proposes a new machine learning framework for software testing automation through related studies. To maximize the performance of software testing, we analyzed and categorized the machine learning algorithms applicable to each software test phase, including the diverse data that can be used in the algorithms. We believe that our framework allows software developers or testers to choose a machine learning algorithm suitable for their purpose."
A Machine Learning Approach for Mechanical Motor Fault Diagnosis,2017,"['Motor Failure', 'Fault Diagnosis', 'Classification Method', 'Machine Learning']",,"In order to reduce damages to major railroad components, which have the potential to cause interruptions to railroad services and safety accidents and to generate unnecessary maintenance costs, the development of rolling stock maintenance technology is switching from preventive maintenance based on the inspection period to predictive maintenance technology, led by advanced countries. Furthermore, to enhance trust in accordance with the speedup of system and reduce maintenances cost simultaneously, the demand for fault diagnosis and prognostic health management technology is increasing.The objective of this paper is to propose a highly reliable learning model using various machine learning algorithms that can be applied to critical rolling stock components. This paper presents a model for railway rolling stock component fault diagnosis and conducts a mechanical failure diagnosis of motor components by applying the machine learning technique in order to ensure efficient maintenance support along with a data preprocessing plan for component fault diagnosis. This paper first defines a failure diagnosis model for rolling stock components. Function-based algorithms ANFIS and SMO were used as machine learning techniques for generating the failure diagnosis model. Two tree-based algorithms, RadomForest and CART, were also employed.In order to evaluate the performance of the algorithms to be used for diagnosing failures in motors as a critical railroad component, an experiment was carried out on 2 data sets with different classes (includes 6 classes and 3 class levels). According to the results of the experiment, the random forest algorithm, a tree-based machine learning technique, showed the best performance."
Predicting Foreign Exchange Rate Trend Using Machine Learning Technique,2017,"['ForReign Exchange Market (Forex)', 'Exchange Rates', 'Machine Learning', 'Support Vector Machine (SVM)', 'Classification', 'Prediction']",,"The trend of Foreign exchange rate values can be seen as a binary with the predicting of “uptrend” or “downtrend”. Machine learning techniques such as support vector machine can be used with the time series data like daily Forex values in order to predict a strategy of buying/selling exchange rates. By performing with alternative configurations in machine learning models of support vector machines, the predicting rates of EUR vs USD are shown. The machine learning models with the bigger set of features show the better results. These results might help the investors to make transaction decisions on the Forex Online Market to get the benefits or to stop losing their money."
Estimation of compressive strength of BFS and WTRP blended cement mortars with machine learning models,2017,"['blast furnace slag', 'waste tire rubber powder', 'compressive strength', 'random forest', 'ada boost', 'SVM', 'Bayes classifier models']",,"The aim of this study is to build Machine Learning models to evaluate the effect of blast furnace slag (BFS) and waste tire rubber powder (WTRP) on the compressive strength of cement mortars. In order to develop these models, 12 different mixes with 288 specimens of the 2, 7, 28, and 90 days compressive strength experimental results of cement mortars containing BFS, WTRP and BFS+WTRP were used in training and testing by Random Forest, Ada Boost, SVM and Bayes classifier machine learning models, which implement standard cement tests. The machine learning models were trained with 288 data that acquired from experimental results. The models had four input parameters that cover the amount of Portland cement, BFS, WTRP and sample ages. Furthermore, it had one output parameter which is compressive strength of cement mortars. Experimental observations from compressive strength tests were compared with predictions of machine learning methods. In order to do predictive experimentation, we exploit R programming language and corresponding packages. During experimentation on the dataset, Random Forest, Ada Boost and SVM models have produced notable good outputs with higher coefficients of determination of R2, RMS and MAPE. Among the machine learning algorithms, Ada Boost presented the best R2, RMS and MAPE values, which are 0.9831, 5.2425 and 0.1105, respectively. As a result, in the model, the testing results indicated that experimental data can be estimated to a notable close extent by the model."
Classifying Arm Movement with Embedded System and Machine Learning,2017,"['Machine learning', 'Embedded system', 'AWKNN', 'MEMS sensor']",,"This paper presents a method to classify the arm movements into 8 categories for the sensor data acquired from a micro-electro-mechenial sensor. The method uses the attribute weighted KNN (AWKNN) which is a kind of machine learning algorithm. The measurement system consists of gyroscopes and an accelerometer, attached to a human arm to measure arm movement. The system has been implemented with field-programmable gate array. The sensor data are pre-processed and handed over the AWKNN-based machine learning classifier to classify the sensed arm movements into 8 classes. The training data sets have been collected from the group of men and women who had exercised the predefined arm movements. The developed arm movement recognition system has achieved the accuracy higher than 90% in the experiments."
COMPARATIVE ANALYSIS ON MACHINE LEARNING MODELS FOR PREDICTING KOSPI200 INDEX RETURNS,2017,"['machine learning', 'support vector machine', 'arti¯cial neural network', 'ran- dom forest', 'k-nearest neighbor.']",,"In this paper, machine learning models employed in various ¯elds are discussed and applied to KOSPI200 stock index return forecasting. The results of hyperparameter analysis of the machine learning models are also reported and practical methods for each model are presented. As a result of the analysis, Support Vector Machine and Arti¯cial Neural Network showed a better performance than k-Nearest Neighbor and Random Forest."
Elongation Prediction of Steel-Strips in Annealing Furnace with Deep Learning via Improved Incremental Extreme Learning Machine,2017,"['Baldwinian learning', 'Clone selection algorithm', 'deep learning', 'elongation prediction', 'incremental extreme learning machine', 'Lamarckian learning']",,"The elongation of steel-strips in annealing furnace is an important factor that affects the position ofwelding line and safety of air-knife since there is no extra space to install welding line detector in field conditions.Therefore, predicting the elongation of steel-strips in the annealing process is important to fulfill the requirementsof eliminating security risks and improving economic performance. In this paper, we propose a deep architecturescalled I-ELM/MLCSA autoencoders with the concept of stacked generalization philosophy to solve large and complexdata mining problems. The comparison results of the case studies indicate that D-ELMs-AE/MLCSA is apromising prediction algorithm and can be employed for steel-strips elongation predictions with excellent performance."
Wine Quality Evaluation Using Machine Learning Algorithms,2017,"['wine quality', 'machine learning', 'supervised learning', 'linear regression', 'gradient descent.']",,"There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way."
Application of Machine Learning for Optimization of 3-D Integrated Circuits and Systems,2017,,,"<P>The 3-D integration helps improve performance and density of electronic systems. However, since electrical and thermal performance for 3-D integration is related to each other, their codesign is required. Machine learning, a promising approach in artificial intelligence, has recently shown promise for addressing engineering optimization problems. In this paper, we apply machine learning for the optimization of 3-D integrated systems where the electrical performance and thermal performance need to be analyzed together for maximizing performance. In such systems, modeling can be challenging due to the multiscale geometries involved, which increases computation time per iteration. In this paper, we show that machine learning can be applied to such systems where multiple parameters can be optimized to achieve the desired performance using the minimum number of iterations. These results have been compared with other promising optimization methods in this paper. The results show that on an average, 4.4%, 31.1%, and 6.9% improvement in temperature gradient, CPU time, and skew are possible using machine learning, as compared with other methods.</P>"
입자 군집 최적화 기법을 이용한 Kernel Extreme Learning Machine 설계,2017,"['Neural Networks', 'Extreme Learning Machine', 'Particle Swarm Optimization', 'Iterative Learning Method', 'Learning speed']",,
Extraction of Reference Seaway through Machine Learning of Ship Navigational Data and Trajectory,2017,"['Vessel Traffic Services', 'Machine learning', 'Sea traffic route', 'Decision making', 'Pattern recognition']",,"Vessel Traffic Services operators have kept sharp monitoring and provided the appropriate information to ensure safe and effective navigation. While attending the tasks, analysis of traffic patterns and navigational data is required to conduct accurate situation assessment in decision-making process of VTS operators (VTSO). Unfortunately, there are problems in the process of data analysis such as appropriateness of time, VTSO’s personal error and improper judgment. Therefore, objective and proper data analysis is necessary to solve above matters. However, it is virtually impossible to monitor all vessels because there are many vessels in the VTS area and at the same time complex traffic situations are produced. In this study, we proposed a machine learning algorithms for objective and accurate pattern recognition and data modeling. Support Vector Regression algorithm was used for data learning and modeling. The optimal parameters were selected through v-fold cross validation and grid search. The machine learning was conducted with virtual route and ship tracks that are similar with real navigational environment. As a result, we presented reference route and navigational patterns. We expect that the proposed modeling methods could be utilized for relevant tasks as the useful information to VTSO and/or ship’s mater."
Failure estimation of the composite laminates using machine learning techniques,2017,"['failure estimation', 'layup optimization', 'machine learning', 'finite element analysis', 'numerical analysis']",,"The problem of layup optimization of the composite laminates involves a very complex multidimensional solution space which is usually non-exhaustively explored using different heuristic computational methods such as genetic algorithms (GA). To ensure the convergence to the global optimum of the applied heuristic during the optimization process it is necessary to evaluate a lot of layup configurations. As a consequence the analysis of an individual layup configuration should be fast enough to maintain the convergence time range to an acceptable level. On the other hand the mechanical behavior analysis of composite laminates for any geometry and boundary condition is very convoluted and is performed by computational expensive numerical tools such as finite element analysis (FEA). In this respect some studies propose very fast FEA models used in layup optimization. However, the lower bound of the execution time of FEA models is determined by the global linear system solving which in some complex applications can be unacceptable. Moreover, in some situation it may be highly preferred to decrease the optimization time with the cost of a small reduction in the analysis accuracy. In this paper we explore some machine learning techniques in order to estimate the failure of a layup configuration. The estimated response can be qualitative (the configuration fails or not) or quantitative (the value of the failure factor). The procedure consists of generating a population of random observations (configurations) spread across solution space and evaluating using a FEA model. The machine learning method is then trained using this population and the trained model is then used to estimate failure in the optimization process. The results obtained are very promising as illustrated with an example where the misclassification rate of the qualitative response is smaller than 2%."
Prediction & Assessment of Change Prone Classes Using Statistical & Machine Learning Techniques,2017,"['Change Proneness', 'Empirical Validation', 'Machine Learning Techniques', 'Software Quality']",,"Software today has become an inseparable part of our life. In order to achieve the ever demanding needs of customers, it has to rapidly evolve and include a number of changes. In this paper, our aim is to study the relationship of object oriented metrics with change proneness attribute of a class. Prediction models based on this study can help us in identifying change prone classes of a software. We can then focus our efforts on these change prone classes during testing to yield a better quality software. Previously, researchers have used statistical methods for predicting change prone classes. But machine learning methods are rarely used for identification of change prone classes. In our study, we evaluate and compare the performances of ten machine learning methods with the statistical method. This evaluation is based on two open source software systems developed in Java language. We also validated the developed prediction models using other software data set in the same domain (3D modelling). The performance of the predicted models was evaluated using receiver operating characteristic analysis. The results indicate that the machine learning methods are at par with the statistical method for prediction of change prone classes. Another analysis showed that the models constructed for a software can also be used to predict change prone nature of classes of another software in the same domain. This study would help developers in performing effective regression testing at low cost and effort. It will also help the developers to design an effective model that results in less change prone classes, hence better maintenance."
Analysis of Precision and Accuracy in a Simple Model of Machine Learning,2017,"['Machine Learning', 'Regression', 'Inference Methods']",,"Machine learning is a procedure where a model for the world is constructed from a training set of examples. It is important that the model should capture relevant features of the training set, and at the same time make correct prediction for examples not included in the training set. I consider the polynomial regression, the simplest method of learning, and analyze the accuracy and precision for di®erent levels of the model complexity."
An Enhanced Technologies of Intelligent HVAC PID Controller by Parameter Tuning based on Machine Learning,2017,"['machine learning', 'PID controller', 'HVAC', 'comfortableable', 'parameter tuning']",,"Design of an intelligent controller for efficient control in smart building is one of the effective technologies to reduce energy consumption by reducing response time with keeping comfortable level for inhabitants. In this paper, we focus on how to find major parameters in order to enhance the ability of HVAC(heating, ventilation, air conditioning) PID controller. For the purpose of that, we use machine learning technologies for tuning HVAC devices. We show the simulation results to illustrate the behavioral relation of whole system and each control parameter while learning process."
Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance,2017,"['Medical Informatics', 'Health Informatics', 'Computational Biology', 'Artificial Intelligence', 'Clinical Informatics', 'Machine Learning']",,"Objectives: Human immunodeficiency virus infection and acquired immune deficiency syndrome (HIV/AIDS) is one of the major burdens of disease in developing countries, and the standard-of-care treatment includes prescribing antiretroviral drugs. However, antiretroviral drug resistance is inevitable due to selective pressure associated with the high mutation rate of HIV. Determining antiretroviral resistance can be done by phenotypic laboratory tests or by computer-based interpretation algorithms. Computer-based algorithms have been shown to have many advantages over laboratory tests. The ANRS (Agence Nationale de Recherches sur le SIDA) is regarded as a gold standard in interpreting HIV drug resistance using mutations in genomes. The aim of this study was to improve the prediction of the ANRS gold standard in predicting HIV drug resistance.Methods: A genome sequence and HIV drug resistance measures were obtained from the Stanford HIV database (http:// hivdb.stanford.edu/). Feature selection was used to determine the most important mutations associated with resistance prediction.These mutations were added to the ANRS rules, and the difference in the prediction ability was measured. Results: This study uncovered important mutations that were not associated with the original ANRS rules. On average, the ANRS algorithm was improved by 79% ± 6.6%. The positive predictive value improved by 28%, and the negative predicative value improved by 10%. Conclusions: The study shows that there is a significant improvement in the prediction ability of ANRS gold standard."
Machine Learning to Compare Frequent Medical Problems of African American and Caucasian Diabetic Kidney Patients,2017,"['Machine Learning', 'Electronic Health Records', 'Renal Insufficiency', 'Kidney Failure', 'Glomerular Filtration Rate']",,"Objectives: End-stage renal disease (ESRD), which is primarily a consequence of diabetes mellitus, shows an exemplary health disparity between African American and Caucasian patients in the United States. Because diabetic chronic kidney disease (CKD) patients of these two groups show differences in their medical problems, the markers leading to ESRD are also expected to differ. The purpose of this study was, therefore, to compare their medical complications at various levels of kidney function and to identify markers that can be used to predict ESRD. Methods: The data of type 2 diabetic patients was obtained from the 2012 Cerner database, which totaled 1,038,499 records. The data was then filtered to include only African American and Caucasian outpatients with estimated glomerular filtration rates (eGFR), leaving 4,623 records. A priori machine learning was used to discover frequently appearing medical problems within the filtered data. CKD is defined as abnormalities of kidney structure, present for >3 months. Results: This study found that African Americans have much higher rates of CKDrelated medical problems than Caucasians for all five stages, and prominent markers leading to ESRD were discovered only for the African American group. These markers are high glucose, high systolic blood pressure (BP), obesity, alcohol/drug use, and low hematocrit. Additionally, the roles of systolic BP and diastolic BP vary depending on the CKD stage. Conclusions: This research discovered frequently appearing medical problems across five stages of CKD and further showed that many of the markers reported in previous studies are more applicable to African American patients than Caucasian patients."
Automatic Machine Fault Diagnosis System using Discrete Wavelet Transform and Machine Learning,2017,"['Pattern Recognition', 'Machine Learning', 'Machine Fault Diagnosis', 'Discrete Wavelet Transform', 'Principal Component Analysis', 'Artificial Neural Network']",,
A Study on Efficient Memory Management Using Machine Learning Algorithm,2017,"['Data Mining', 'Weka', 'Machine Learning', 'Clustering', 'Memory Allocation', 'Efficient Memory']",,"As the industry grows, the amount of data grows exponentially, and data analysis using these serves as a predictable solution. As data size increases and processing speed increases, it has begun to be applied  to new fields by combining artificial intelligence technology as well as simple big data analysis. In this paper, we propose a method to quickly apply a machine learning based algorithm through efficient resource allocation. The proposed algorithm allocates memory for each attribute. Learning Distinct of Attribute and allocating the right memory. In order to compare the performance of the proposed algorithm, we compared it with the existing K-means algorithm. As a result of measuring the execution time, the speed was  improved."
A Study on Efficient Memory Management Using Machine Learning Algorithm,2017,"['Data Mining', 'Weka', 'Machine Learning', 'Clustering', 'Memory Allocation', 'Efficient Memory']",,"As the industry grows, the amount of data grows exponentially, and data analysis using these serves as a predictable solution. As data size increases and processing speed increases, it has begun to be applied to new fields by combining artificial intelligence technology as well as simple big data analysis. In this paper, we propose a method to quickly apply a machine learning based algorithm through efficient resource allocation. The proposed algorithm allocates memory for each attribute. Learning Distinct of Attribute and allocating the right memory. In order to compare the performance of the proposed algorithm, we compared it with the existing K-means algorithm. As a result of measuring the execution time, the speed was improved."
A Study on Efficient Memory Management Using Machine Learning Algorithm,2017,"['Data Mining', 'Weka', 'Machine Learning', 'Clustering', 'Memory Allocation', 'Efficient Memory']",,"As the industry grows, the amount of data grows exponentially, and data analysis using these serves as a predictable solution. As data size increases and processing speed increases, it has begun to be applied  to new fields by combining artificial intelligence technology as well as simple big data analysis. In this paper, we propose a method to quickly apply a machine learning based algorithm through efficient resource allocation. The proposed algorithm allocates memory for each attribute. Learning Distinct of Attribute and allocating the right memory. In order to compare the performance of the proposed algorithm, we compared it with the existing K-means algorithm. As a result of measuring the execution time, the speed was  improved."
Investigation of Topographic Characteristics of Parcels Using UAV and Machine Learning,2017,"['Unmanned Aerial Vehicle', 'Machine Learning', 'Spatial Analysis', 'Topographical Characteristics']",,"In this study, we propose a method to investigate topographic characteristics by applying machine learning which is an artificial intelligence analysis method based on the spatial data constructed using UAV and the training data created through spatial analysis. This method provides an alternative to the subjective judgment and accuracy of spatial data, which is a problem of existing topographic characteristics survey for officially assessed land price. The analysis method of this study is expected to improve the problems of topographic characteristics survey method of existing field researchers and contribute to more accurate decision of officially assessed land price by providing more objective land survey method."
Investigation of Topographic Characteristics of Parcels Using UAV and Machine Learning,2017,"['Unmanned Aerial Vehicle', 'Machine Learning', 'Spatial Analysis', 'Topographical Characteristics']",,
A Study on Efficient Memory Management Using Machine Learning Algorithm,2017,"['Data Mining', 'Weka', 'Machine Learning', 'Clustering', 'Memory Allocation', 'Efficient Memory']",,"As the industry grows, the amount of data grows exponentially, and data analysis using these serves as a predictable solution. As data size increases and processing speed increases, it has begun to be applied to new fields by combining artificial intelligence technology as well as simple big data analysis. In this paper, we propose a method to quickly apply a machine learning based algorithm through efficient resource allocation. The proposed algorithm allocates memory for each attribute. Learning Distinct of Attribute and allocating the right memory. In order to compare the performance of the proposed algorithm, we compared it with the existing K-means algorithm. As a result of measuring the execution time, the speed was improved."
Predicting Autism Spectrum Disorder Using Blood-based Gene Expression Signatures and Machine Learning,2017,"['Autism spectrum disorder', 'Blood', 'Microarray analysis', 'Transcriptome', 'Machine learning', 'Decision support techniques.']",,"Objective: The aim of this study was to identify a transcriptomic signature that could be used to classify subjects with autism spectrum disorder (ASD) compared to controls on the basis of blood gene expression profiles. The gene expression profiles could ultimately be used as diagnostic biomarkers for ASD.Methods: We used the published microarray data (GSE26415) from the Gene Expression Omnibus database, which included 21 young adults with ASD and 21 age- and sex-matched unaffected controls. Nineteen differentially expressed probes were identified from a training dataset (n=26, 13 ASD cases and 13 controls) using the limma package in R language (adjusted p value ＜0.05) and were further analyzed in a test dataset (n=16, 8 ASD cases and 8 controls) using machine learning algorithms.Results: Hierarchical cluster analysis showed that subjects with ASD were relatively well-discriminated from controls. Based on the support vector machine and K-nearest neighbors analysis, validation of 19-DE probes with a test dataset resulted in an overall class prediction accuracy of 93.8% as well as a sensitivity and specificity of 100% and 87.5%, respectively.Conclusion: The results of our exploratory study suggest that the gene expression profiles identified from the peripheral blood samples of young adults with ASD can be used to identify a biological signature for ASD. Further study using a larger cohort and more homogeneous datasets is required to improve the diagnostic accuracy."
Adaptive resource provisioning method using application-aware machine learning based on job history in heterogeneous infrastructures,2017,,,"<P>With the remarkable growth in cloud computing, computing resources can be manipulated on-demand in most scientific fields. This enables scientists to strategically select their experimental environment. Since it is hard to offer cloud resources in accordance with application characteristics, efficient resource provisioning methods are needed. This paper proposes an adaptive resource provisioning method using an application-aware machine learning technique that is based on the job history in heterogeneous infrastructures. The proposed resource provisioning method is built on two main concepts. First, it provides application-aware resource provisioning through the profiling of scientific application in a heterogeneous computing infrastructure. A resource provisioning model uses the resource usage profiles of scientific applications and job history data in heterogeneous computing infrastructures. In addition to the multilayer perceptron machine learning method, an error back-propagation approach is applied to analyze job history to re-learn the error of the output value. Second, it offers an adaptive resource scaling that is invoked by the availability of resource changes. An adaptive resource management method results in an enhancement of the overall balance between the performance and utilization of a system. For the experiments with the two CPU-intensive applications according to the method, a heterogeneous infrastructure comprising clusters and cloud environments is used. Experimental results indicate that the use of the proposed method can gratify user requests (cost and execution time) regarding its application and enhance resource usage effectiveness.</P>"
Multiple Crack Identification in Euler Beams using Extreme Learning Machine,2017,"['crack detection', 'ELM', 'modal strain energy', 'natural frequencies']",,"In this paper, a novel method proposed for multiple crack identification in Euler beams using extreme learning machine (ELM).For this purpose, the extreme learning machine used the modal strain energy and natural frequencies of cracked beam as input and crack states in beam elements as output. To illustrate the performance of the presented method in crack detection, Euler beam with different support conditions consist of cantilever, simply supported and fixed simply supported with single or several cracks in beam elements has been investigated. In other work, a validation study has been done using a simply supported beam. Also, noise effect on the measured modal data has been investigated. The obtained results show the capability of the proposed method for crack detection using ELM."
Re-anonymization Technique for Dynamic Data Using Decision Tree Based Machine Learning,2017,"['민감정보', '익명화', 'k-익명성', '결정트리', '기계학습', 'sensitive information', 'anonymization', 'k-anonymity', 'decision tree', 'machine learning']",,
Integration of Markov chain analysis and similarity-weighted instance-based machine learning algorithm (SimWeight) to simulate urban expansion,2017,,,"This study simulates urban expansion using Kaduna in North-West Nigeria as a case study. A hybrid model that integrates the similarity-weighted instance-based machine learning algorithm for transition potential modelling and the Markov chain model to quantify and allocate land-use change was used to overcome the identified weaknesses of known modelling techniques such as the cellular automata, Markov chain and standard logistic regression models. Environmental and urban physical variables that act as constraints and/or incentives to urban expansion were operationalized to create transition potentials for spatiotemporal states of built-up land use for the year 1990 and 2001. Model evaluation and validation was carried out using the relative operating characteristic and kappa index of agreement statistics. Having obtained satisfactory outcomes from the validation process, the modelled transition potentials were used to predict future urban expansion for forthcoming years. The simulated land-use maps provide valuable insights into the location and type of urban expansion that is likely to occur in Kaduna in the foreseeable future. This provides city managers and planners much needed information that could inform urban policy aimed at better planning and management of urban development."
Prediction of carbon dioxide emissions based on principal component analysis with regularized extreme learning machine,2017,"['CO&lt', 'SUB&gt', '2&lt', '/SUB&gt', 'emissions prediction', 'Influential factors', 'PACF', 'PCA', 'Pearson coefficient test', 'RELM']",,"Nowadays, with the burgeoning development of economy, CO2 emissions increase rapidly in China. It has become a common concern to seek effective methods to forecast CO2 emissions and put forward the targeted reduction measures. This paper proposes a novel hybrid model combined principal component analysis (PCA) with regularized extreme learning machine (RELM) to make CO2 emissions prediction based on the data from 1978 to 2014 in China. First eleven variables are selected on the basis of Pearson coefficient test. Partial autocorrelation function (PACF) is utilized to determine the lag phases of historical CO2 emissions so as to improve the rationality of input selection. Then PCA is employed to reduce the dimensionality of the influential factors. Finally RELM is applied to forecast CO2 emissions. According to the modeling results, the proposed model outperforms a single RELM model, extreme learning machine (ELM), back propagation neural network (BPNN), GM(1,1) and Logistic model in terms of errors. Moreover, it can be clearly seen that ELM-based approaches save more computing time than BPNN. Therefore the developed model is a promising technique in terms of forecasting accuracy and computing efficiency for CO2 emission prediction."
Analysis of precision and accuracy in a simple model of machine learning,2017,,,
Novel Approaches for Applying Linguistic Processing Techniques Based on Pattern Recognition and Machine Learning,2017,['.'],,
Novel Approaches for Applying Linguistic Processing Techniques Based on Pattern Recognition and Machine Learning,2017,,,
Deep Learning in Genomic and Medical Image Data Analysis: Challenges and Approaches,2017,"['Bioinformatics', 'Deep Learning', 'Deep Neural Networks', 'DNA Genome Analysis', 'Image Data Analysis', 'Machine Learning', 'lincRNA']",,"Artificial intelligence, especially deep learning technology, is penetrating the majority of research areas, including the field of bioinformatics. However, deep learning has some limitations, such as the complexity of parameter tuning, architecture design, and so forth. In this study, we analyze these issues and challenges in regards to its applications in bioinformatics, particularly genomic analysis and medical image analytics, and give the corresponding approaches and solutions. Although these solutions are mostly rule of thumb, they can effectively handle the issues connected to training learning machines. As such, we explore the tendency of deep learning technology by examining several directions, such as automation, scalability, individuality, mobility, integration, and intelligence warehousing."
Prototyping Training Program in Immersive Virtual Learning Environment with Head Mounted Displays and Touchless Interfaces for Hearing-Impaired Learners,2017,"['hearing-impaired learners', '3D virtual environment', 'head mounted display', 'contactless natural user interface', 'spatial reasoning']",,"The purpose of the study was to identify key design features of virtual reality with head-mounted displays (HMD) and touchless interface for the hearing-impaired and hard-of-hearing learners. The virtual reality based training program was aimed to help hearing-impaired learners in machine operating learning, which requires spatial understanding to operate. We developed an immersive virtual learning environment prototype with an HMD (Oculus Rift) and a touchless natural user interface (Leap Motion) to identify the key design features required to enhance virtual reality for the hearing-impaired and hard-of-hearing learners. Two usability tests of the prototype were conducted, which revealed that several features in the system need revision and that the technology presents an enormous potential to help hearing-impaired learners by providing realistic and immersive learning experiences. After the usability tests of hearing-impaired students` exploring the 3D virtual space, interviews were conducted, which also established that further revision of the system is needed, which would take into account the learners` physical as well as cognitive characteristics."
적외선 영상에서의 표적과 클러터 구분을 위한 Hybrid Machine Character 기반의 Du-CNN 설계,2017,"['적외선 영상', '합성곱신경망', '표적분류', '기계학습', '다중인격', 'Infrared Image', 'Convolutional Neural Network', 'Target Classification', 'Machine Learning', 'Multiple Personality']",,"In this paper, we propose a robust duality of CNN(Du-CNN) method which can classify the target and clutter in coastal environment for IR Imaging Sensor. In coastal environment, there are various clutter that have many similarities with real target due to diverse change of air temperature, water temperature, weather and season. Also, real target have various feature due to the same reason. Thus, the proposed Du-CNN method adopts human’s multiple personality utilization and CNN technique to learn and classify target and clutter. This method has an advantage of the real time operation. Experimental results on sampled dataset of real infrared target and clutter demonstrate that the proposed method have better success rate to classify the target and clutter than general CNN method."
Sound Based Machine Fault Diagnosis System Using Pattern Recognition Techniques,2017,"['Pattern Recognition', 'Machine Learning', 'Machine Fault Diagnosis', 'Sound Processing', 'Principal Component Analysis', 'Artificial Neural Network']",,"Machine fault diagnosis recovers all the studies that aim to detect automatically faults or damages on machines. Generally, it is very difficult to diagnose a machine fault by conventional methods based on mathematical models because of the complexity of the real world systems and the obvious existence of nonlinear factors. This study develops an automatic machine fault diagnosis system that uses pattern recognition techniques such as principal component analysis (PCA) and artificial neural networks (ANN). The sounds emitted by the operating machine, a drill in this case, are obtained and analyzed for the different operating conditions. The specific machine conditions considered in this research are the undamaged drill and the defected drill with wear. Principal component analysis is first used to reduce the dimensionality of the original sound data. The first principal components are then used as the inputs of a neural network based classifier to separate normal and defected drill sound data. The results show that the proposed PCA-ANN method can be used for the sounds based automated diagnosis system."
Deep Learning in Genomic and Medical Image Data Analysis: Challenges and Approaches,2017,"['Bioinformatics', 'Deep Learning', 'Deep Neural Networks', 'DNA Genome Analysis', 'Image Data Analysis', 'Machine Learning', 'lincRNA']",,"Artificial intelligence, especially deep learning technology, is penetrating the majority of research areas, including the field of bioinformatics. However, deep learning has some limitations, such as the complexity of parameter tuning, architecture design, and so forth. In this study, we analyze these issues and challenges in regards to its applications in bioinformatics, particularly genomic analysis and medical image analytics, and give the corresponding approaches and solutions. Although these solutions are mostly rule of thumb, they can effectively handle the issues connected to training learning machines. As such, we explore the tendency of deep learning technology by examining several directions, such as automation, scalability, individuality, mobility, integration, and intelligence warehousing."
Deep learning: from chemoinformatics to precision medicine,2017,"['Deep learning', 'Drug discovery and development', 'Chemoinformatics', 'Precision medicine']",,"Deep learning is a new machine learning paradigm that focuses on learning with deep hierarchical models of data. Chemoinformatics has been defined as the mixing of chemical information resources to transform into knowledge for the intended purpose of making better and faster decisions in the area of drug lead identification and optimization. Precision medicine includes disease prevention and treatment strategies that consider individual variability in healthcare. Researchers are now focusing on the convergence of genomics, epigenomics, metabolomics, informatics, and imaging, along with other technologies such as data mining, deep learning, and big data methodology; disciplines that are rapidly expanding the scope of precision medicine. Drug and diagnostic developers, physicians, health systems, and patients share interests in precision medicine. In this review, we provide an overview of recent studies on the application of the deep learning method in the pharmaceuticals and precision medicine fields. We briefly review the fields related to the history of deep learning, chemoinformatics, drug development, model based medicine, electronic healthcare records, wearable sensors, drug response variability, and precision medicine."
Limitations of Machine Translation : Focused on the Role of Cognitive Complements in Human Communication,2017,"['기계번역', '자동통역', '자연어처리', '언어외적 맥락', '인지적 보완소', 'machine translation MT', 'automated interpreting', 'natural language processing NLP', 'extra-linguistic context', 'cognitive complements']",,"Significant progress has been made in machine translation since the introduction of the Neural-based Machine Translation (NMT) algorithms. For Korean-English translation, there is growing evidence that the machine translation engines are rendering more and more acceptable translations with time through deep learning. The progress inevitably raises the question of whether human expertise will eventually be replaced by machines. This question depends on whether and how much of the inter-lingual mediation process depends on inherently human capabilities. To understand the potential boundaries of machines translation, this study draws on the role of cognitive complements in face-to-face communication, focusing on spoken as opposed to the commonly researched written texts. The first part of the study discusses the role of cognitive complements in human communication. Then to illustrate the important role played by cognitive complements in human communication, the second part of the study explains the errors made by NMT from the perspective of cognitive complements, based on a sample text analysis using Google Translate. The analysis indicate that applying the current engine to face-to-face encounters has serious pragmatic risks. From the perspective of machine translation, therefore, the ability to apply cognitive complements like human beings, with the ability to draw on extra-linguistic context may be the key to making NMT ready for real-world applications as far as the processing of spoken texts is concerned. While effort is underway to relate sensory experience to text processing, enormous computing power requirement may be another obstacle before human interpreters can be replaced completely. Pedagogic implications of this study for post-graduate interpreting programs are discussed in the final part of the paper."
QGeo: Q-Learning-Based Geographic <i>Ad Hoc</i> Routing Protocol for Unmanned Robotic Networks,2017,,,"<P>This letter proposes a novel protocol that uses Q-learning-based geographic routing (QGeo) to improve the network performance of unmanned robotic networks. A rapid and reliable network is essential for the remote control and monitoring of mobile robotic devices. However, controlling the network overhead required for route selection and repair is still a notable challenge, owing to high mobility of the devices. To alleviate this problem, we propose a machine-learning-based geographic routing scheme to reduce network overhead in high-mobility scenarios. We evaluate the performance of QGeo in comparison with other methods using the NS-3 simulator. We find that QGeo has a higher packet delivery ratio and a lower network overhead than existing methods.</P>"
Multi-view based unlabeled data selection using feature transformation methods for semiboost learning,2017,"['SemiBoost learning', 'Useful unlabeled data selection', 'Multiple views of feature set', 'Feature decomposition methods']",,"<P>SemiBoost Mallapragada et al. (2009) is a boosting framework for semi-supervised learning, in which unlabeled data as well as labeled data both contribute to learning. Various strategies have been proposed in the literature to perform the task of selecting useful unlabeled data in SemiBoost. Recently, a multi-view based strategy was proposed in Le and Kim (2016), in which the feature set of the data is decomposed into subsets (i.e., multiple views) using a feature-decomposition method. In the decomposition process, the strategy inevitably results in some loss of information. To avoid this drawback, this paper considered feature-transformation methods, rather than using the decomposition method, to obtain the multiple views. More specifically, in the feature-transformation method, a number of views were obtained from the entire feature set using the same number of different mapping functions. After deriving the number of views of the data, each of the views was used for measuring corresponding confidences, for first evaluating examples to be selected. Then, all the confidence levels measured from the multiple views were combined as a weighted average for deriving a target confidence. The experimental results, which were obtained using support vector machines for well-known benchmark data, demonstrate that the proposed mechanism can compensate for the shortcomings of the traditional strategies. In addition, the results demonstrate that when the data is transformed appropriately into multiple views, the strategy can achieve further improvement in results in terms of classification accuracy. (C) 2017 Elsevier B.V. All rights reserved.</P>"
Indoor Localization Without a Prior Map by Trajectory Learning From Crowdsourced Measurements,2017,,,"<P>Accommodation of a situation when a prior map is not available in an indoor localization system is valuable to cost-effective operations by removing a need for map drawing and map updating. This paper suggests a trajectory learning method using crowdsourced measurements in order to support the absence of map. A localization framework based on a particle filter is formalized by machine-learning-based feature extraction and Gaussian process (GP) regression. The feature extraction algorithm reduces dimensionality of sparse measurement vector, and it is applied to detect floor level and designated landmarks. Also, the combination of the feature extraction and the GP regression is used for modeling nonlinear relationship between location and measurement. By this combination, locations of Wi-Fi access points are not required to be known. From the field experimental results, we confirm that the detections of floor level and landmarks are accurate, the learned trajectories are close to the true map, and positioning accuracy is improved thanks to the learning-aided localization.</P>"
An Active Radial Compliance Method with Anisotropic Stiffness Learning for Precision Assembly,2017,"['Active compliance', 'Force control', 'Learning from experience', 'Vision measurement', 'Precision assembly']",,"Compliance is essential for precision assembly, which provides motion guidance and damage avoidance. Force control can offer flexible implementation of active compliance for manipulators. In this paper, an active radial compliance method is developed for the insertion task of thin walled millimeter-sized cylinders. A radial force controller is designed to satisfy the contact force constraint in the component's radial directions, which integrates the explicit force control with the high precision attitude measurement based on microscopic vision. An anisotropic stiffness learning method is proposed based on clustering and support vector machines. It can obtain the hidden anisotropic stiffness characteristics of the mechanical system from experience data. Experimental results verify the effectiveness of the proposed methods."
Simultaneous Kernel Learning and Label Imputation for Pattern Classification with Partially Labeled Data,2017,"['Kernel learning', 'Semi-supervised learning', 'Pattern classification', 'Optimization']",,"The kernel function plays a central role in modern pattern classification for its ability to capture the inherent affinity structure of the underlying data manifold. While the kernel function can be chosen by human experts with domain knowledge, it is often more principled and promising to learn it directly from data. This idea of kernel learning has been studied considerably in machine learning and pattern recognition. However, most kernel learning algorithms assume fully supervised setups requiring expensive class label annotation for the training data. In this paper we consider kernel learning in the semi-supervised setup where only a fraction of data points need to be labeled. We propose two approaches: the first extends the idea of label propagation along the data similarity graph, in which we simultaneously learn the kernel and impute the labels of the unlabeled data. The second aims to minimize the dual loss in the support vector machines (SVM) classifier learning with respect to the kernel parameters and the missing labels. We provide reasonable and effective approximate solution methods for these optimization problems. These approaches exploit both labeled and unlabeled data in kernel leaning, where we empirically demonstrate the effectiveness on several benchmark datasets with partially labeled learning setups."
Simultaneous Kernel Learning and Label Imputation for Pattern Classification with Partially Labeled Data,2017,"['Kernel learning', 'Semi-supervised learning', 'Pattern classification', 'Optimization']",,"The kernel function plays a central role in modern pattern classification for its ability to capture the inherent affinity structure of the underlying data manifold. While the kernel function can be chosen by human experts with domain knowledge, it is often more principled and promising to learn it directly from data. This idea of kernel learning has been studied considerably in machine learning and pattern recognition. However, most kernel learning algorithms assume fully supervised setups requiring expensive class label annotation for the training data. In this paper we consider kernel learning in the semi-supervised setup where only a fraction of data points need to be labeled. We propose two approaches: the first extends the idea of label propagation along the data similarity graph, in which we simultaneously learn the kernel and impute the labels of the unlabeled data. The second aims to minimize the dual loss in the support vector machines (SVM) classifier learning with respect to the kernel parameters and the missing labels. We provide reasonable and effective approximate solution methods for these optimization problems. These approaches exploit both labeled and unlabeled data in kernel leaning, where we empirically demonstrate the effectiveness on several benchmark datasets with partially labeled learning setups."
Design of a Fast Learning Classifier for Sleep Apnea Database based on Fuzzy SVM,2017,"['FSVM', 'SVM', 'Fuzzy membership function', 'Classifier', 'Time series data', 'Learning time', 'Sleep apnea']",,"In this paper, we compared the performance of support vector machine (SVM) and fuzzy SVM (FSVM) for reduction of learning time when classifying large-scale time series data into two classes. The fast learning time of the pattern classifier for large time series data is very useful in decision support systems. Considering the high interest in healthcare, including big data analysis, it is necessary to design a pattern classifier with a fast learning capability. We used large-scale time series data of 32 patients with sleep apnea (SA) for this study. The experiment was conducted by extending the parameter n, of the fuzzy membership function of FSVM, from 1 to 500. The result shows that the shortest learning time of FSVM is 3 s for radial base function (RBF), 17 s for a polynomial, and 35 s for a linear kernel, where the parameter n of the fuzzy membership function is n = 2, n = 433, and n = 4, respectively. The maximum classification hit rate of FSVM is 93.23%, and the learning time is significantly faster than conventional SVM. Therefore, FSVM can be used as a good classifier for the large-scale time series SA database."
Simultaneous Learning of Sentence Clustering and Class Prediction for Improved Document Classification,2017,"['Machine learning', 'Document classification', 'Sequence labeling', 'Term weighting']",,"In document classification it is common to represent a document as the so called bag-of-words form, which is essentially a global term distribution indicating how often certain terms appear in a text. Ignoring the spatial statistics (i.e., where in a text they appear) can potentially lead to a suboptimal solution. The key motivation or assumption in this paper is that there may exist underlying segmentation of sentences in a document, and perhaps this partitioning might be intuitively appealing (e.g., each group corresponds to a particular sentiment or gist of arguments). If the segmentation is known somehow, terms belonging to the same/different groups can potentially be treated in an equal/different manner for classification. Based on the idea, we build a novel document classification model comprised of two parts: a sentence tagger that predicts the group labels of sentences, and a classifier that forms the input features as a weighted term frequency vector that is aggregated from all sentences but weighed differently cluster-wise according to the prediction in the first model. We suggest an efficient learning strategy for this model. For several benchmark document classification problems, we demonstrate that the proposed approach yields significantly improved classification performance over several existing algorithms."
Q-learning을 이용한 모바일 로봇의 동적 장애물 회피 및 최적 경로 탐색 알고리즘,2017,"['machine learning', 'reinforcement learning', 'q-learning', 'mobile robot', 'dynamic obstacles']",,
Simultaneous Learning of Sentence Clustering and Class Prediction for Improved Document Classification,2017,"['Machine learning', 'Document classification', 'Sequence labeling', 'Term weighting']",,"In document classification it is common to represent a document as the so called bag-of-words form, which is essentially a global term distribution indicating how often certain terms appear in a text. Ignoring the spatial statistics (i.e., where in a text they appear) can potentially lead to a suboptimal solution. The key motivation or assumption in this paper is that there may exist underlying segmentation of sentences in a document, and perhaps this partitioning might be intuitively appealing (e.g., each group corresponds to a particular sentiment or gist of arguments). If the segmentation is known somehow, terms belonging to the same/different groups can potentially be treated in an equal/different manner for classification. Based on the idea, we build a novel document classification model comprised of two parts: a sentence tagger that predicts the group labels of sentences, and a classifier that forms the input features as a weighted term frequency vector that is aggregated from all sentences but weighed differently cluster-wise according to the prediction in the first model. We suggest an efficient learning strategy for this model. For several benchmark document classification problems, we demonstrate that the proposed approach yields significantly improved classification performance over several existing algorithms."
Nonlinear machine fault detection by semi-supervised Laplacian Eigenmaps,2017,"['Semi-supervised Laplacian Eigenmaps', 'Fault detection', 'Feature extraction', 'Manifold learning']",,"A semi-supervised Laplacian Eigenmaps algorithm for machine fault detection is proposed. The purpose of the algorithm is to efficiently extract the manifold geometric characteristics of nonlinear vibration signal samples, and to determine fault classification of operating equipment so that the accuracy of fault detection can be improved. The data acquisition and pre-processing of the vibration signal is firstly implemented from monitoring equipment, then hybrid domain feature is obtained, and the initial sample set can be built. This is followed by implementing the semi-supervised Laplacian Eigenmaps algorithm so that the sensitive nature characteristics of manifold can be obtained from the device initial sample set. In order to establish the intelligent diagnostic model, the Least square Support vector machine (LS-SVM) is then adopted, which fault diagnosis and decisions can be achieved in the feature space of the low-dimensional manifold. The experiment results of using the IRIS data, gearbox and compressor fault data show the proposed method has more advantage when compared with the PCA and Laplacian Eigenmaps on improving the accuracy of fault detection."
Deep Learning in Medical Imaging: General Overview,2017,"['Artificial intelligence', 'Machine learning', 'Convolutional neural network', 'Recurrent Neural Network', 'Computer-aided', 'Precision medicine', 'Radiology']",,"The artificial neural network (ANN)–a machine learning technique inspired by the human neuronal synapse system–was introduced in the 1950s. However, the ANN was previously limited in its ability to solve actual problems, due to the vanishing gradient and overfitting problems with training of deep architecture, lack of computing power, and primarily the absence of sufficient data to train the computer system. Interest in this concept has lately resurfaced, due to the availability of big data, enhanced computing power with the current graphics processing units, and novel algorithms to train the deep neural network. Recent studies on this technology suggest its potentially to perform better than humans in some visual and auditory recognition tasks, which may portend its applications in medicine and healthcare, especially in medical imaging, in the foreseeable future. This review article offers perspectives on the history, development, and applications of deep learning technology, particularly regarding its applications in medical imaging."
Dropout Genetic Algorithm Analysis for Deep Learning Generalization Error Minimization,2017,"['DGA', 'Deep Learning', 'Dropout', 'Genetic Algorithm', 'Overfitting', 'AI']",,"Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA(Dropout Genetic Algorithm) which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout."
Sound Based Machine Fault Diagnosis System Using Pattern Recognition Techniques,2017,"['Pattern Recognition', 'Machine Learning', 'Machine Fault Diagnosis', 'Sound Processing', 'Principal Component Analysis', 'Artificial Neural Network']",,
Dropout Genetic Algorithm Analysis for Deep Learning Generalization Error Minimization,2017,"['DGA', 'Deep Learning', 'Dropout', 'Genetic Algorithm', 'Overfitting', 'AI']",,"Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA(Dropout Genetic Algorithm) which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout."
Data-Driven Support Vector Machine with Optimization Techniques for Structural Health Monitoring and Damage Detection,2017,"['optimization', 'data-driven modeling', 'support vector machine learning', 'structural health monitoring and damage detection']",,"Rapid detecting damages/defeats in the large-scale civil engineering structures, assessing their conditions and timely decision making are crucial to ensure their health and ultimately enhance the level of public safety. Advanced sensor network techniques recently allow collecting large amounts of data for structural health monitoring and damage detection, while how to effectively interpret these complex sensor data to technical information posts many challenges. This paper presents three optimization-algorithm based support vector machines for damage detection. The optimization algorithms, including grid-search, partial swarm optimization and genetic algorithm, are used to optimize the penalty parameters and Gaussian kernel function parameters. Two types of feature extraction methods in terms of time-series data are selected to capture effective damage characteristics. A benchmark experimental data with the 17 different scenarios in the literature were used for verifying the proposed data-driven methods. Numerical results revealed that all three optimized machine learning methods exhibited significantly improvement in sensitivity, accuracy and effectiveness over conventional methods. The genetic algorithm based SVM had a better prediction than other methods. Two different feature methods used in this study also demonstrated the appropriate features are crucial to improve the sensitivity in detecting damage and assessing structural health conditions. The findings of this study are expected to help engineers to process big data and effectively detect the damage/defects, and thus enable them to make timely decision for supporting civil infrastructure management practices."
Prediction of Remaining Useful Life of Lithium-ion Battery based on Multi-kernel Support Vector Machine with Particle Swarm Optimization,2017,"['Lithium-ion battery RUL', 'Multi-kernel support vector machine', 'Particle swarm optimization algorithm', 'RUL prediction']",,"The estimation of the remaining useful life (RUL) of lithium-ion (Li-ion) batteries is important for intelligent battery management system (BMS). Data mining technology is becoming increasingly mature, and the RUL estimation of Li-ion batteries based on data-driven prognostics is more accurate with the arrival of the era of big data. However, the support vector machine (SVM), which is applied to predict the RUL of Li-ion batteries, uses the traditional single-radial basis kernel function. This type of classifier has weak generalization ability, and it easily shows the problem of data migration, which results in inaccurate prediction of the RUL of Li-ion batteries. In this study, a novel multi-kernel SVM (MSVM) based on polynomial kernel and radial basis kernel function is proposed. Moreover, the particle swarm optimization algorithm is used to search the kernel parameters, penalty factor, and weight coefficient of the MSVM model. Finally, this paper utilizes the NASA battery dataset to form the observed data sequence for regression prediction. Results show that the improved algorithm not only has better prediction accuracy and stronger generalization ability but also decreases training time and computational complexity."
Approaching the computational color constancy as a classification problem through deep learning,2017,"['Computational color constancy', 'White balancing', 'Illumination estimation', 'Machine learning', 'Convolutional neural network']",,"Computational color constancy refers to the problem of computing the illuminant color so that the images of a scene under varying illumination can be normalized to an image under the canonical illumination. In this paper, we adopt a deep learning framework for the illumination estimation problem. The proposed method works under the assumption of uniform illumination over the scene and aims for the accurate illuminant color computation. Specifically, we trained the convolutional neural network to solve the problem by casting the color constancy problem as an illumination classification problem. We designed the deep learning architecture so that the output of the network can be directly used for computing the color of the illumination. Experimental results show that our deep network is able to extract useful features for the illumination estimation and our method outperforms all previous color constancy methods on multiple test datasets."
Study on Automatic Bug Triage using Deep Learning,2017,"['버그 담당자 배정', '딥 러닝', '기계학습', '문서 분류', 'bug triage', 'deep learning', 'machine learning', 'text categorization']",,
A Reinforcement Learning Approach to Access Management in Wireless Cellular Networks,2017,,,"<P>In smart city applications, huge numbers of devices need to be connected in an autonomous manner. 3rd Generation Partnership Project (3GPP) specifies that Machine Type Communication (MTC) should be used to handle data transmission among a large number of devices. However, the data transmission rates are highly variable, and this brings about a congestion problem. To tackle this problem, the use of Access Class Barring (ACB) is recommended to restrict the number of access attempts allowed in data transmission by utilizing strategic parameters. In this paper, we model the problem of determining the strategic parameters with a reinforcement learning algorithm. In our model, the system evolves to minimize both the collision rate and the access delay. The experimental results show that our scheme improves system performance in terms of the access success rate, the failure rate, the collision rate, and the access delay.</P>"
Semiconductor Wafer Defect Classification Using Support Vector Machine with Weighted Dynamic Time Warping Kernel Function,2017,"['Wafer Map', 'Weighted Dynamic Time Warping Kernel', 'Support Vector Machines', 'Time Series Classification']",,"Semiconductor wafer maps provide vital information and clues to monitor and better understand the quality issues in the underlying manufacturing process. In post-fabrication, each chip undergoes a series of quality checks to determine whether the chip is in functional or defective state. Since each defect pattern is unique, automatically characterizing the various defect patterns in wafer map can provide significant insights to process engineers towards mitigating manufacturing defects and improve the effective yield rate. In this paper, we present a novel data mining and optimization-based supervised learning algorithm, called support vector machines with weighted dynamic time warping kernel (SVM-WDTWK), to classify defect patterns on semiconductor wafers. SVM-WDTWK provides a flexible and robust matching algorithm for time series classification, leading to an accurate match between non-aligned time series data. We present a numerical comparison to show that the proposed SVM-WDTWK algorithm is superior to several existing techniques on defect pattern classification on semiconductor wafer maps."
Semiconductor Wafer Defect Classification Using Support Vector Machine with Weighted Dynamic Time Warping Kernel Function,2017,"['Wafer Map', 'Weighted Dynamic Time Warping Kernel', 'Support Vector Machines', 'Time Series Classification']",,"Semiconductor wafer maps provide vital information and clues to monitor and better understand the quality issues in the underlying manufacturing process. In post-fabrication, each chip undergoes a series of quality checks to determine whether the chip is in functional or defective state. Since each defect pattern is unique, automatically characterizing the various defect patterns in wafer map can provide significant insights to process engineers towards mitigating manufacturing defects and improve the effective yield rate. In this paper, we present a novel data mining and optimization-based supervised learning algorithm, called support vector machines with weighted dynamic time warping kernel (SVM-WDTWK), to classify defect patterns on semiconductor wafers. SVM-WDTWK provides a flexible and robust matching algorithm for time series classification, leading to an accurate match between non-aligned time series data. We present a numerical comparison to show that the proposed SVM-WDTWK algorithm is superior to several existing techniques on defect pattern classification on semiconductor wafer maps."
Semiconductor Wafer Defect Classification Using Support Vector Machine with Weighted Dynamic Time Warping Kernel Function,2017,"['Wafer Map', 'Weighted Dynamic Time Warping Kernel', 'Support Vector Machines', 'Time Series Classification']",,"Semiconductor wafer maps provide vital information and clues to monitor and better understand the quality issues in the underlying manufacturing process. In post-fabrication, each chip undergoes a series of quality checks to determine whether the chip is in functional or defective state. Since each defect pattern is unique, automatically characterizing the various defect patterns in wafer map can provide significant insights to process engineers towards mitigating manufacturing defects and improve the effective yield rate. In this paper, we present a novel data mining and optimization-based supervised learning algorithm, called support vector machines with weighted dynamic time warping kernel (SVM-WDTWK), to classify defect patterns on semiconductor wafers. SVM-WDTWK provides a flexible and robust matching algorithm for time series classification, leading to an accurate match between non-aligned time series data. We present a numerical comparison to show that the proposed SVM-WDTWK algorithm is superior to several existing techniques on defect pattern classification on semiconductor wafer maps."
LBSN(Location-Based Social Network) 데이터와 머신러닝 기법을 이용한 토지이용 분류,2017,"['LBSN', '머신러닝', '토지이용분류', '공간분석', 'LBSN', 'Machine learning', 'Land use classification', 'Spatial analysis']","최근 머신러닝은 빅데이터에 대한 분석방법으로서 학습을 통한 지능화된 문제해결 방안으로서 관심이 증가하고 있다.본 논문은 LBSN 데이터와 머신러닝 방식을 이용하여 토지이용현황을 파악하는 분석을 시도하였다. 도시계획에 있어서 토지이용현황의 파악은 직접적인 현장 조사에 의존해 왔다. 최근 스마트폰 사용자가 증가하면서 등장하고 있는 위치기반 소셜미디어의 자료들은 토지이용의 상황을 반영하는 빅데이터로서, 머신러닝 방법론은 이들에 대한 자동화된 분석을 할 수 있게 한다. 본 연구에서는LBSN 자료와 머신러닝 기법을 이용하여 토지이용을 예측하는 모델을 개발하여 실제 토지이용현황 자료와의 비교분석을 수행하였다. 이러한 분석을 통해 LBSN자료를 이용한 토지이용현황의 자동화된 분석 방안에 대해 연구하였다.","Recently, machine learning is an analytical method for big data, and interest is increasing as an intelligent problem solving method through learning. In this paper, we tried to analyze land use status using LBSN data and machine learning method. The identification of land use status in urban planning has relied on direct field surveys. Recently, the data of location - based social media emerging as users of smartphone are big data reflecting the situation of land use, and machine learning methodology enables automated analysis of these. In this study, a model for predicting land use was developed using LBSN data and machine learning technique and compared with actual land use data. Through this analysis, an automated analysis method of land use status using LBSN data was studied."
머신러닝 기법을 적용한 지가 예측 연구,2017,"['지가 예측', '머신러닝', '의사결정나무', '서포트 벡터 머신', 'Prediction of Land Price', 'Machine Learning', 'Decision Tree', 'Support Vector Machine']","기존 개별공시지가는 표준지를 분석한 토지가격비준표의 다중 회귀식 결과로 산정되고 있다. 본 연구에서는 머신러닝 기법을 활용하여 토지특성과 토지의 국지적 공간패턴을 고려한 비선형적 모의방법을 제시하고자 한다. 경기도 용인시를 대상으로 100m 공간단위의 벡터 기반 격자와 지적도 및 수치표고자료를 융합하여 모의를 진행하였다. 모의결과 예측정확도는 C5.0 알고리즘을 활용한 의사결정나무 모형에서 75.8%(1996년), 70.3%(2005년)의 예측정확도를 나타냈다.그리고 RBF 커널 알고리즘을 활용한 서포트 벡터 머신 모형의 경우 63.5%(1996년), 54.3%(2005년)의 예측정확도를 나타냈다. 본 연구의 머신러닝 모의방법은 개별공시지가 산정을 위한 국지적 토지특성 분석에 활용할 수 있을 것이다.","The existing officially assessed individual land price is calculated as the multiple regression result of the land price index table which analyzed the officially assessed reference land price. The main purpose of this study is to suggest the nonlinear simulation method considering the characteristics of the land and the local spatial pattern by using the machine learning. The simulation model was performed by combining the 100m vector areal unit based cadastral map and the digital elevation model(DEM). The accuracy of prediction was 75.8%(1996) and 70.3%(2005) in decision trees of C5.0 algorithm. In the case of the support vector machine(SVM) model, prediction accuracy was 63.5%(1996) and 54.3%(2005). In the machine learning simulation, officially assessed individual land price grade was converted into nominal type data classified into 10 grades considering the distribution of officially assessed individual land price of Yongin city. Independent variables were constructed from 30,354 vector areal unit using geographical distances from hazardous aversion facilities, roads, schools, railways, parks, mountains, and land use. The machine learning simulation method of this study can be applied to the analysis of the local land characteristics for calculating the officially assessed individual land price."
머신러닝 기반의 부당청구 탐지시스템에 대한 연구,2017,"['보험사기', '부당청구', '머신러닝', '패턴 분류', '지능형 탐지', 'insurance fraud', 'unfair claim', 'machine-learning', 'patten classification', 'intelligence detection']",,"The existing insurance claim detection system is a method of deriving a rule based on the experience and knowledge of the inspectors about the insurance case charged based on the business rule. And it is divided into the subject rule to be investigated and the exclusion rule to be investigated. However, as insurance fraud becomes increasingly intelligent and sophisticated, it is necessary to continually update on new fraudulent claims patterns.In this paper, we classify the unfair claims patterns of unfair claims by labeling them and classify them as machine - learning based on the unfairness of new unfair claims through guidance learning about unfair claims. We propose intelligent fraud detection system."
머신러닝 기법을 활용한 유황별 LOADEST 모형의 적정 회귀식 선정 연구: 낙동강 수계를 중심으로,2017,"['LOADEST model', 'Machine-learning', 'Pollutant load', 'Flow conditions', 'Regression equation']",,"This study is to determine the coefficients of regression equations and to select the optimal regression equation in the LOADEST model after classifying the whole study period into 5 flow conditions for 16 watersheds located in the Nakdonggang waterbody. The optimized coefficients of regression equations were derived using the gradient descent method as a learning method in Tensorflow which is the engine of machine-learning method. In South Korea, the variability of streamflow is relatively high, and rainfall is concentrated in summer that can significantly affect the characteristic analysis of pollutant loads. Thus, unlike the previous application of the LOADEST model (adjusting whole study period), the study period was classified into 5 flow conditions to estimate the optimized coefficients and regression equations in the LOADEST model. As shown in the results, the equation #9 which has 7 coefficients related to flow and seasonal characteristics was selected for each flow condition in the study watersheds. When compared the simulated load (SS) to observed load, the simulation showed a similar pattern to the observation for the high flow condition due to the flow parameters related to precipitation directly. On the other hand, although the simulated load showed a similar pattern to observation in several watersheds, most of study watersheds showed large differences for the low flow conditions. This is because the pollutant load during low flow conditions might be significantly affected by baseflow or point-source pollutant load. Thus, based on the results of this study, it can be found that to estimate the continuous pollutant load properly the regression equations need to be determined with proper coefficients based on various flow conditions in watersheds. Furthermore, the machine-learning method can be useful to estimate the coefficients of regression equations in the LOADEST model."
초음파 펄스의 머신러닝과 딥러닝을 이용한 콘크리트의 열손상 평가,2022,"['열 손상', '딥러닝', 'Thermal Damage', 'Deep Learning']",,"The purpose of this study was to compare the applicability of using machine learning methods in detecting thermal damage in concrete structure. For this study, concrete cylinder specimens were fabricated with three different water-to-binder ratios and these cylinders exposed to different temperatures (20℃, 100℃, 200℃, 300℃, 400℃, and 600℃) inside an electric furnace. The results show that deep learning has potential in detecting thermal damage with higher accuracy than machine learning."
머신 러닝 기반 소셜 빅데이터 분석을 이용한 금융자산 트레이딩 모델의 성능 향상에 관한 연구,2017,"['Machine Learning', 'Big Data', 'Financial Trading', 'Trading', '머신 러닝', '빅데이터 분석', '금융자산', '트레이딩']","머신 러닝 기반 소셜 빅데이터 분석을 이용한 금융자산 트레이딩 모델의 성능향상에 관한 연구는 기존 연구들에 근간하여 사회를 구성하는 구성원들의 집단감성이 주가에 영향을 미친다는 가정하에서 출발했다. 최근 소셜 데이터가 양적인 측면에서 기하급수적으로 증가함에 따라 실시간으로 변화하는 사회구성원의 집단감성의 대표성을 갖게 되었다. 최근의 연구에 따르면, 인간의 의사결정이 이성과 깊은 성찰로부터 기인하기보다는 감성이 더 깊이 관여한다고 진단하고, 이러한 의사결정 모형을 경제사회로 확장시켜 Socio-economics라 명명한 바 있다. 본 연구는 시가총액이 한국 전체 주식시장의 70%를 차지하는 KOSPI200을 대상으로 한다. 본 모델은 자연언어처리를 이용하여 소셜 빅데이터로부터 주가의 전망과 관련성이 깊은 감성데이터를 추출한다. 머신 러닝을 활용해 각 기업의 Fundamental Ratio와 Technical Indicators, 소셜 감성데이터 등을 러닝하여 주식 시장을 전망한다. 현재 주요 펀드들의 운용에는 여러 시장 지표 데이터들이 활용되지만, 일반적으로는 펀드매니저 개개인의 지식과 경험을 활용한 통찰이 펀드의 운용에 결정적인 영향을 미친다. 본 모델에서는 사람의 개입 없이 머신 러닝을 통해 발굴된 종목들을 기반으로 포트폴리오를 형성한다. 이번 연구를 통해 소셜 빅데이터 분석을 이용한 머신 러닝 기반의 로보 트레이딩이 특정 기간 동안 한국의 주식시장에서 실제 시장지표 대비 높은 수익률을 보임을 확인했다.","This research aims to improve the performance of machine learning based on financial trading model applying social big data analy-sis. Based on the existing studies, it started from the assumption that collective emotions of society members have an impact on stock prices. As social data has been rapidly increasing to the extant that it can be called as ‘big data’, it could represent the real time flow of emotion from society members. According to recent studies, it is evident that people’s decisions result from neither rationality nor considerate introspection but emotion. This kind of decision making model has been extended to economics which was named as ‘So-cio-economics’. This study is conducted with KOSPI200 which occupies 70% of total Korea stock market capitalization. This model uses Natural Language Processing it extract emotion data closely related to stock prediction from social big data. It utilizes machine learning to learn fundamental ratio and social emotion data together with technical indicators of each company. On the current market, various indices are referred in managing major funds. However, it usually depends more on insights and knowledge of individual fund managers. In this study, portfolios are formulated based on confirmed stock items from machine learning without human intervention. Through this research, we proved machine learning based robot trading applying social big data analysis outperform higher than actual Korean stock market indices in a certain era."
정보 유출 탐지를 위한 머신 러닝 기반 내부자 행위 분석 연구,2017,"['Cyber', 'Insider Threat', 'Behavior Analysis', 'Machine Learning']",,"In this paper, we design and implement PADIL(Prediction And Detection of Information Leakage) system that predicts and detect information leakage behavior of insider by analyzing network traffic and applying a variety of machine learning methods. we defined the five-level information leakage model(Reconnaissance, Scanning, Access and Escalation, Exfiltration, Obfuscation) by referring to the cyber kill-chain model. In order to perform the machine learning for detecting information leakage, PADIL system extracts various features by analyzing the network traffic and extracts the behavioral features by comparing it with the personal profile information and extracts information leakage level features. We tested various machine learning methods and as a result, the DecisionTree algorithm showed excellent performance in information leakage detection and we showed that performance can be further improved by fine feature selection."
머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구,2017,,,"In this study, I propose a method to automate the method to diagnose the quality of big data. The reason for automating the quality diagnosis of Big Data is that as the Fourth Industrial Revolution becomes a issue, there is a growing demand for more volumes of data to be generated and utilized. Data is growing rapidly. However, if it takes a lot of time to diagnose the quality of the data, it can take a long time to utilize the data or the quality of the data may be lowered. If you make decisions or predictions from these low-quality data, then the results will also give you the wrong direction. To solve this problem, I have developed a model that can automate diagnosis for improving the quality of Big Data using machine learning which can quickly diagnose and improve the data. Machine learning is used to automate domain classification tasks to prevent errors that may occur during domain classification and reduce work time. Based on the results of the research, I can contribute to the improvement of data quality to utilize big data by continuing research on the importance of data conversion, learning methods for unlearned data, and development of classification models for each domain."
머신러닝을 이용한 공공시설 호우피해 예측함수 개발,2017,"['호우피해 예측함수', '머신러닝(기계학습)', '사회·경제적 요소', '공공시설', 'Heavy Rain Damage Prediction Function', 'Machine Learning', 'Socio-economic Variable', 'Public Facility']","본 연구에서는 머신러닝(기계학습)을 활용하여 경기도 지역의 호우로 인한 공공시설물 피해를 예측하는 함수를 개발하였다. 종속변수로 재해연보상의 공공시설 피해액을 사용하였고, 설명변수로 기상요소와 사회·경제적 요소를 고려하였다. 실제 호우피해액과 예측 호우피해액을 비교하여 예측력을 평가한 결과 NRMSE(Normalized Root Mean Squared Error)는 22.93~24.16%로 나타났으며, 배깅 방법을 이용한 함수가 가장 좋은 예측력을 보였다. 본 연구에서 개발된 함수를 이용하여 예방 및 대비 차원의 재난관리를 실시한다면, 호우피해를 줄이는데 큰 도움이 될 것으로 판단된다.","We developed heavy rain damage prediction functions for the prediction of public facility damage to be occurred by heavy rain in Gyeonggi-do province. This study used machine learning such as decision tree, bagging, and random forest models for the function development and data of public facility damages which can be obtained from annual reports for natural disaster damages published in Korea as a dependent variable. Also, meteorological factors and socio-economic factors were considered as explanatory variables then the prediction functions were developed. As a result of comparing the amount of actual heavy rain damages with the amount of predicted damages, the NRMSE(Normalized Root Mean Squared Error) was in the range of 22.93~24.16%. The function using the bagging method showed the best prediction performance. If the predicted damages by the developed functions are used for disaster prevention and preparation, it will be a great help to reduce heavy rain damage."
도시 형태 변화 모니터링을 위한 머신러닝 기법의 가능성 - 보스톤 사례연구를 중심으로 -,2017,"['Machine Learning', 'Urban Morphology', 'Main Street', 'Urban Monitoring']",,"This study explores potential capability of a machine learning approach for monitoring urban morphology based on an evident case study. The case study conveys year 2006 investigations on interpreting urban morphology of Boston Main Streets by applying a machine learning approach. From the lesson of the precedent study, in 2016, another field research and interview was conducted to compare changes in urban situation, data commons culture, and technology innovation during the decade. This paper describes open possibilities to advance urban monitoring for morphological changes. Most of all, a multi-participatory data platform enables managing urban data system in real time. Second, collaboration with machines with artificial intelligence can intervene the framework of the urban management system as well as transform it through new demands of innovative industries. Recently, urban regeneration became a dominant urban planning strategy in Korean, therefore, urban monitoring is on demand. It is timely important to correspond to in-situ problems based on empirical research."
무슬림 관광객 증대를 위한 머신러닝 기반의 할랄푸드 분류 프레임워크,2017,"['Machine learning', 'Halal food', 'food classification', 'Muslim', 'smart tourism']",,"PurposeThe purpose of this study is to introduce a framework that helps Muslims to determine whether a food can be consumed. It can complement existing Halal food classification services having a difficulty of constructing Halal food database.Design/methodology/approachThe proposed framework includes two components. First, OCR(Optical Character Recognition) technique is utilized to read the food additive information. Second, machine learning methods were used to trained and predicted to determine whether a food can be consumed using the provided information.FindingsAmong the compared machine learning methods, SVM(Support Vector Machine), DT(Decision Tree), and NB(Naive Bayes), SVM with linear kernel and DT had excellent performance in the Halal food classification. The framework which adopting the proposed framework will enhance the tourism experiences of Muslim tourists who consider keeping the Islamic law most importantly. Furthermore, it can eventually contribute to the enhancement of smart tourism ecosystem."
하이브리드 분석을 통한 머신러닝 기반의 랜섬웨어 탐지 모델,2017,"['랜섬웨어', '악성코드', '머신러닝', '로지스틱 회귀분석', 'K-평균 클러스터링', '하이브리드 분석', 'Ransomware', 'Malware', 'Machine Learning', 'Logistic Regression', 'K-means Clustering', 'Hybrid Analysis']","최근에 주목 받고 있는 랜섬웨어는 임의의 불특정 다수 공격부터 특정 대상 공격(Target Attack)까지 다양한 양상으로 진화하고 있으며, 수익이 되는 사업형 서비스인 RaaS(Ransomware as a Service)모델 형태의 신/변종 랜섬웨어도 증가하고 있다.본 연구에서는 Opcode Clustering 정보, API 정보를 독립변수로 사용하고, 랜섬웨어 판별을 종속변수로 사용하는 Logistic Regression Analysis 기법을 적용하였다. 이를 통해 정적분석, 동적분석을 이용한 탐지보다 하이브리드 분석방법이 더 높은 탐지율이 보임을 확인 하였으며, SVM, naïve Bayes 보다 Logistic Regression기법에서 높은 탐지율을 확인하였다.","Ransomware, which recently being highlighted is evolving in some diverse aspects from random attacks targeting civilians continue to specific target (target attack) attack. Ransomware has developed into a business-based service RaaS (Ransomware as a Service) model and a new ransomware variant is also increasing.In this paper, we propose a detective model for ransomware through Logistic Regression Analysis technique using Opcode information, the API information as an independent variable, determine the ransomware as a dependent variable. These results show that the hybrid detection rate outperformed the static and dynamic detection rate, and the logistic regression technique outperformed the SVM, naïve Bayes technique."
머신비전을 이용한 전복 치패 계수에 관한 연구,2017,"['Machine vision', 'Abalone young shells', 'Conveyor system', 'Region-based', 'Object counting', '머신비전', '전복 치패', '컨베이어 시스템', '영역기반', '객체 계수']","본 논문에서는 머신비전을 이용하여 컨베이어 시스템에서 이동하는 객체를 계수하는 알고리즘을 제안하였다. 영상처리를 이용한 객체 계수 시스템은 유동인구나 교통량 파악 등의 다양한 산업현장에서 사용되고 있으며, 주로 템플릿 매칭이나 기계학습의 방법으로 검출하여 추적 후 계수한다. 하지만 빠르게 움직이는 컨베이어 벨트위의 물체를 검출하기 위해서는 연산에 소요되는 시간이 짧아야 하므로 영역기반의 방법으로 영상처리를 하였다. 본 연구에서는 모양과 크기, 그리고 색깔이 비슷한 전복 치패를 계수하였다. 컨베이어 시스템은 한 방향으로 동작하는 특성을 이용하여 첫 번째 영역에서 치패를 검출하여 정보를 얻은 것을 기반으로 다음 프레임에서의 물체의 위치 범위를 계속적으로 변화하여 치패를 검출하고 각각의 획득한 정보를 비교하여 계수하였다. 치패가 간격을 두고 이동 시에는 정확하게 계수됨을 확인하였으며, 치패가 붙어서 오는 경우에는 크기정보를 이용하여 계수하여 중복되거나 누락됨을 방지하였다. 본 논문에서 제안한 알고리즘은 컨베이어 시스템 위에서 움직이는 다양한 객체 계수 제어에 적용할 수 있을 것이다.","In this paper, an algorithm for object counting via a conveyor system using machine vision is suggested. Object counting systems using image processing have been applied in a variety of industries for such purposes as measuring floating populations and traffic volume, etc. The methods of object counting mainly used involve template matching and machine learning for detecting and tracking. However, operational time for these methods should be short for detecting objects on quickly moving conveyor belts. To provide this characteristic, this algorithm for image processing is a region-based method. In this experiment, we counted young abalone shells that are similar in shape, size and color. We applied a characteristic conveyor system that operated in one direction. It obtained information on objects in the region of interest by comparing a second frame that continuously changed according to the information obtained with reference to objects in the first region. Objects were counted if the information between the first and second images matched. This count was exact when young shells were evenly spaced without overlap and missed objects were calculated using size information when objects moved without extra space. The proposed algorithm can be applied for various object counting controls on conveyor systems."
An Application of Support Vector Machines to Customer Loyalty Classification of Korean Retailing Company Using R Language,2017,"['Support Vector Machines', 'SVMs', 'Customer Relationship Management', 'CRM', 'Recursive Feature Elimination', 'RFE', 'Random Forest', 'RF', 'R Language', 'Loyalty', 'Korean Retailing', 'Customer Classification']",,"PurposeCustomer Loyalty is the most important factor of customer relationship management (CRM). Especially in retailing industry, where customers have many options of where to spend their money. Classifying loyal customers through customers’ data can help retailing companies build more efficient marketing strategies and gain competitive advantages. This study aims to construct classification models of distinguishing the loyal customers within a Korean retailing company using data mining techniques with R language.Design/methodology/approachIn order to classify retailing customers, we used combination of support vector machines (SVMs) and other classification algorithms of machine learning (ML) with the support of recursive feature elimination (RFE). In particular, we first clean the dataset to remove outlier and impute the missing value. Then we used a RFE framework for electing most significant predictors. Finally, we construct models with classification algorithms, tune the best parameters and compare the performances among them.FindingsThe results reveal that ML classification techniques can work well with CRM data in Korean retailing industry. Moreover, customer loyalty is impacted by not only unique factor such as net promoter score but also other purchase habits such as expensive goods preferring or multi-branch visiting and so on. We also prove that with retailing customer’s dataset the model constructed by SVMs algorithm has given better performance than others. We expect that the models in this study can be used by other retailing companies to classify their customers, then they can focus on giving services to these potential vip group. We also hope that the results of this ML algorithm using R language could be useful to other researchers for selecting appropriate ML algorithms."
머신 러닝을 이용한 영상 특징 기반 전기차 검출 및 분류 시스템,2017,"['Machine Learning', 'Supervised Learning', 'Vehicle Classification']",,"This paper proposes a novel way of vehicle detection and classification based on image features. There are two main processes in the proposed system, which are database construction and vehicle classification processes. In the database construction, there is a tight censorship for choosing appropriate images of the training set under the rigorous standard. These images are trained using Haar features for vehicle detection and histogram of oriented gradients extraction for vehicle classification based on the support vector machine. Additionally, in the vehicle detection and classification processes, the region of interest is reset using a number plate to reduce complexity. In the experimental results, the proposed system had the accuracy of 0.9776 and the F₁ score of 0.9327 for vehicle classification."
머신러닝 인공지능과 인간전문직의 협업의 의미와 법적 쟁점,2017,"['머신러닝 인공지능', '인간전문직', '협업', '의료과실', '의사의 진단책임', 'Machine learning artificial intelligence', 'Human professionals', 'Partnership', 'Medical malpractice', 'Physician’s liability in diagnosis']","머신러닝 인공지능의 출현은 오랫동안 인간전문직의 독점적 영역으로 알려졌던 분야에서 인공지능과 인간전문직의 협업을 현실로 만들고 있고 최근 IBM의 Watson이 보여주듯이 의료분야는 이러한 상업화가 앞선 분야이다.  하지만 머신러닝 인공지능과 인간전문직은 문제해결 접근방식에서 구체적 추론을 보면 그 과정을 알 수 없는 계산된 확률과 납득할 수 있는 해명에 기초한 상당성, 그리고 빅 데이터를 이용한 패턴인식과 자신의 경험을 바탕으로 한 귀추론의 적용이라는 명백한 차이가 존재한다. 그 위에 인간 언어 이해의 기술적 한계, 개발국가와 사용 국가 사이의 관행 차이의 존재 등은 인간전문직과 머신러닝 인공지능 사이의 충돌가능성을 높인다.  이러한 상황에서 인간전문직과 머신러닝 인공지능이 협업을 한다고 하더라도 머신러닝 인공지능의 역할은 인간이 실질적 운전자가 아닌 지위로 전환되면서 책임경감이 논의되는 자율주행 자동차에서와 달리 인간전문직을 보조함으로써 실수를 예방하고 관련비용을 낮추는 역할에 국한된다. 구체적 예로서 의료과실에서 의사의 책임에 관해 보면 전문직으로서 법률상 독점적인 지위를 보호받고 있는 의사의 지위, 의사의 충실한 설명의무에 기초할때만 성립할 수 있는 환자의 자기결정권과 같은 사정을 고려해 보면 의사를 보조하는 머신러닝 인공지능의 지위는 의료기기 정도로서 의사의 의료과실 책임체계에 변화를 가져오기는 어렵다. 오히려 의사의 진단과 치료법 선택에 관한 책임을 결과의 예견가능성을 전제로 인정하는 기존의 법원 판결에 비추어 머신러닝 인공지능과의 협업은 현재의 머신러닝 발전단계에서는 특히 머신러닝 인공지능과 의사의 진단이 다를 경우 그 책임범위를 확대시킬 가능성이 더 높다. 다만 머신러닝 인공지능이 상당한 수준에 올라갈 미래의 발전단계에서는 머신러닝 인공지능은 의사의 유력한 방어수단이 될 수 있을 것으로 보이고 그때 균형을 이루기 위한 법률상 책임체계에 대한 고민이 시작될 가능성이 크다.  인간의 실수방지와 전문직 활용 시 비용절감을 앞세운 머신러닝과 인간전문직의 협업은 점점 현실로 다가오고있다. 상대적으로 그 활용 및 발전에 다양한 가능성이 열려있는 현재 단계에서는 포괄적인 규제보다는 상업화에 따른 점진적인 규제를 통해 대응해야 하고, 인간전문직 집단 역시 머신러닝 인공지능의 영향이 집중될 미숙련자들에 대한 교육‧훈련체계 개선에 힘을 기울여야 한다.","The advent of machine learning artificial intelligence(hereafter “AI”) makes partnership between AI. and human professionals a reality in those areas that have long been regarded as a monopolistic area of human professionals and as the recent IBM Watson shows, the field of medicals is ahead of this commercialization trend.  However, there is a clear distinction in problem solving approach between machine learning AI and human professionals, where machine learning AI leads those outcomes by calculation of probability by black-box process and recognition of hidden pattern based on big data while human professionals lead those outcomes by the plausibility based on explanations and application of abductive reasoning based on his or her own experience. Above it, the technical limitations of AI in understanding human language, and the existence of differences in practice between AI developing and using countries and other factors increase the possibility of collision between human professionals and machine learning AI.  In this situation, even if human professionals and machine learning AI cooperate in partnership, the role of machine learning AI is limited to assist human professionals to prevent mistakes and lower the related costs unlike autonomous vehicles where human does not works as drivers practically anymore and human’s position changes from drivers to consumer actually so as to induce the discussion of the reduction in legal liability naturally  As a concrete example, the physician’s liability in medical malpractice can not be changed largely even in partnership with machine learning AI when considering the status of the physician who is protected by law as sole provider of medical service and the patient’s self-determination right that can only be established based on the faithful explanation duty of the doctor, because status of physician assisting AI is medical device at best. Rather, in view of the existing court precedents that find physician liable in malpractice only when there is a possibility of foreseeability of the bad outcome in physician’s diagnosis and the choice of treatment, partnership with machine learning AI in the current stage of machine learning development enlarge physician’s liability expecially when diagnosis of physician and machine learning AI is differed. However, in the future where machine learning AI will reach a considerable level, machine learning AI will afford a strong defense for the physician, and at that time real deliberation of legal responsibility to balance will rise. Partnership between machine learning AI and human professionals are becoming more and more reality in expectation of reduction of human error and cutting costs. In the current stage, where various possibilities for utilization and development are relatively open, it is better to adopt incremental regulation as commercialization steps rather than comprehensive regulation, and also the human professional group should improve the education and training system for the novice group whom will suffer from machine learning AI at large."
다중 도플러 레이다와 머신러닝을 이용한 손동작 인식,2017,"['Doppler Radar', 'Machine Learning', 'Hand Gesture', 'Hand Mouse', 'SVM']","본 논문에서는 사람의 손동작을 이용해 전자기기를 제어할 수 있도록 다중 도플러 레이다와 머신러닝의 일종인 SVM(Support Vector Machine)을 이용한 손동작 인식 기술을 제안하였다. 하나의 도플러 레이다는 간단한 손동작만을 인식할 수 있는데 반해, 다중 도플러 레이다는 레이다 위치에 따라 각각 다른 도플러 효과가 발생되므로, 이를 이용하여 다양한 손동작을 인식할 수 있다. 또한, 머신러닝 기법을 이용하여 손동작을 분류하면 손동작 인식의 성공률을 높일 수 있다. 다중 도플러 레이다와 머신러닝을 이용한 손동작 인식 시스템의 구현 가능성을 확인하기 위하여 두 개의 도플러 레이다, NI DAQ USB-6008, MATLAB을 이용한 실험 장치를 구성하였다. 구현된 실험 장치를 이용하여 Push, Pull, Right Slide 및 Left Slide의 4가지 손동작 인식 실험을 수행하였고, SVM 모델을 적용하여 손동작 인식의 높은 정확도를 확인하였다.","This paper suggests a hand gesture recognition technology to control smart devices using multiple Doppler radars and a support vector machine(SVM), which is one of the machine learning algorithms. Whereas single Doppler radar can recognize only simple hand gestures, multiple Doppler radar can recognize various and complex hand gestures by using various Doppler patterns as a function of time and each device. In addition, machine learning technology can enhance recognition accuracy. In order to determine the feasibility of the suggested technology, we implemented a test-bed using two Doppler radars, NI DAQ USB-6008, and MATLAB. Using this test-bed, we can successfully classify four hand gestures, which are Push, Pull, Right Slide, and Left Slide. Applying SVM machine learning algorithm, it was confirmed the high accuracy of the hand gesture recognition."
기계적 모터 고장진단을 위한 머신러닝 기법,2017,"['Motor Failure', 'Fault Diagnosis', 'Classification Method', 'Machine Learning']",,"In order to reduce damages to major railroad components, which have the potential to cause interruptions to railroad services and safety accidents and to generate unnecessary maintenance costs, the development of rolling stock maintenance technology is switching from preventive maintenance based on the inspection period to predictive maintenance technology, led by advanced countries. Furthermore, to enhance trust in accordance with the speedup of system and reduce maintenances cost simultaneously, the demand for fault diagnosis and prognostic health management technology is increasing. The objective of this paper is to propose a highly reliable learning model using various machine learning algorithms that can be applied to critical rolling stock components. This paper presents a model for railway rolling stock component fault diagnosis and conducts a mechanical failure diagnosis of motor components by applying the machine learning technique in order to ensure efficient maintenance support along with a data preprocessing plan for component fault diagnosis. This paper first defines a failure diagnosis model for rolling stock components. Function-based algorithms ANFIS and SMO were used as machine learning techniques for generating the failure diagnosis model. Two tree-based algorithms, RadomForest and CART, were also employed. In order to evaluate the performance of the algorithms to be used for diagnosing failures in motors as a critical railroad component, an experiment was carried out on 2 data sets with different classes (includes 6 classes and 3 class levels). According to the results of the experiment, the random forest algorithm, a tree-based machine learning technique, showed the best performance."
전력선 통신 시스템을 위한 머신러닝 기반의 원신호 예측 기법,2017,"['Machine learning', 'artificial neural network', 'power line communication system', 'additive white Gaussian noise channel', 'multi-layer perceptron']",본 논문에서는 머신러닝 알고리즘 중 하나인 다층 퍼셉트론을 기반으로 전력선통신 시스템에서의 수신 신호를 이용하여 송신단에서 전송한 원신호를 예측하는 시스템 모델을 제안한다. 전력망을 활용한 통신 방식을 사용하는 전력선통신 시스템은 일반적인 통신설 로를 활용하는 통신 방식에 비해 잡음이 많다. 이 때문에 전력선통신 시스템의 성능이 저하가 되는 문제가 발생한다. 이를 해결하기 위해 본 논문에서 제안하는 통신 시스템 모델을 이용하면 원신호 예측을 통해 잡음의 영향이 최소화되어 전력선통신 시스템의 성능 저하를 완화시킨다. 본 논문에서는 제안한 통신 시스템 모델을 백색 잡음 환경에 적용하여 시뮬레이션을 해봄으로써 원신호가 예측 되는지를 입증한다.,"In this paper, we propose a system model that predicts the original signal transmitted from the transmitter using the received signal in the power line communication system based on the multi - layer perceptron which is one of the machine learning algorithms. Power line communication system using communication system using power network has more noise than communication system using general communication line. It causes a problem that the performance of the power line communication system is degraded. In order to solve this problem, the communication system model proposed in this paper minimizes the influence of noise through original signal prediction and mitigates the performance degradation of the power line communication system. In this paper, we prove that the original signal is predicted by applying the proposed communication system model to the white noise environment."
머신러닝 기반의 최적 양식장 조건 검색에 관한 연구,2017,"['K-means clustering', 'Machine learning', 'Unsupervised learning', 'Aquaculture']",,
A neural network based approach for background noise reduction in airborne acoustic emission of a machining process,2017,"['Acoustic emission', 'Machining process', 'Noise', 'Machine learning', 'Neural network', 'Tool condition monitoring']",,"Tool wear prediction has become an indispensable technique to prevent downtime in manufacturing and production processes.Airborne emission from a machining process using a low-cost microphone may provide a vital signal of tool health. However, the effect of background noise results in anomaly in data that may lead to wrong prediction of tool health. The paper presents an adaptive approach using neural networks for background noise filtration in acoustic signal for a turning process. Acoustic signal of a turning process is mixed with background noise from four different machines and introduced at different RPMs and feed-rate at a constant depth of cut. A comparison of Backpropagation neural network (BPNN), Self-organizing map and k-means clustering algorithm for noise filtration is investigated in this paper. In this regard, back-propagation neural network showed better performance with an average accuracy for all the four sources. It shows 100 % accuracy for grinding machine signal, 94.78 % accuracy for background signal from 3-axis milling machine, 45.57 % and 12.69 % for motor and 4-axis milling machine, respectively. Signal reconstruction is then done using Discrete cosine transform (DCT). The proposed technique shows a promising future for noise filtration in airborne acoustic data of a machining process."
서포트 벡터 머신을 이용한 자연 연상 통계 기반 저작물 식별 알고리즘,2017,"['Publication Classification', 'Natural Scene Statistics', 'Support Vector Machine', 'Histogram-based Classification', 'Machine learning']",,
기계와 인간은 커뮤니케이션할 수 있는가?: 기계학습을 통해 본 쟁점과 대안,2017,"['Machine learning', 'Artificial intelligence', 'Communication', 'Learning process', 'Data accountability', '기계학습', '인공지능', '커뮤니케이션', '학습과정', '데이터 책무성※']","인공지능이 발전함에 따라 기계가 학습한 지식이 실질적인 영향력을 획득하고, 기계와 인간이 직접 커뮤니케이션하는 상황이 늘고 있다. 이 글은 이에 주목하고 기계학습이지닌 의미와 영향을 커뮤니케이션의 관점에서 비판적으로 논의하고자 한다. 이를 위해먼저 기계학습의 개념과 작동 방식을 설명하고, 이를 인간의 학습과정과 비교하여 유사성 및 차이점을 살펴본다. 이를 바탕으로 기계가 학습한 지식의 특수성을 통제 불가능성, 통역불가능성, 그리고 선제의 개념을 통해 제시한다. 이로부터 기계와 인간의 커뮤니케이션에 어떠한 쟁점이 존재하는지 논의하고, 기계와 인간의 커뮤니케이션을 위한 대안으로 ‘데이터 책무성’의 개념을 새롭게 제안하였다.","As artificial intelligence evolves, the knowledge learned by the machine acquires substantial influence, and direct communication between machines and humans is increasing. Focusing on the trends, this paper addresses the implications of machine learning from the perspective of communication.We first explain what machine learning is, and compare the learning process with that of humans to see similarities and differences. Based on the uniqueness of the knowledge learned by the machine, three concepts of uncontrollability, incommensurability, and preemption are presented to examine the machine-human communication issues. The concept of ‘data accountability’ is proposed as an alternative of the issues with further discussion."
기계학습 모델과 설문결과를 융합한 공격적 성향 운전자 탐색 연구,2017,"['공격적 운전성향', 'HMM', '운전행위설문지', '상관분석', '운전자보조시스템', 'Aggressive driver detection', 'HMM', 'DBQ', 'Correlation analysis', 'ADAS']","본 논문에서는 공격적 성향의 운전자를 판단할 수 있는 기계학습 방식과 설문지 방식을 융합한 운전자 성향 판단 연구의 일환으로 두 방법으로 결정된 운전자 성향정보의 상관성을 분석하였다. 30명의 운전자를 대상으로 설문지를 이용한 주관적 성향을 정보를 수집하고 기계학습 기반의 성향판단 시스템을 이용하여 객관적 성향을 취득하였다. 이 중에서 기계학습 기반의 성향판단 시스템은 운전자행위 성향 분류 모델을 기반으로 설계되었다. 모델을 도출하기 위하여 운전자의 가속 패달과 브레이크 패달 조작 데이터와 HMM 기법을 이용한 기계학습을 수행하였다. 두 가지 방법으로 추정한 공격적 성향정보를 Pearson 방식으로 상관관계를 분석한 결과 높은 상관관계가 있음을 확인하였다. 뿐만 아니라 객관적 성향은 동일한 운전자에 대하여 고유한 특성이 있음을 확인하였다. 본 논문의 실험결과는 향후 두 방법을 융합하는 연구를 수행하기 위한 참고자료가 될 것이다. 또한 운전자의 공격적 성향이 주의어시스트, 운전자 식별, 도난방지 등 지능형 운전자 보조시스템에도 응용 될 수 있음을 확인하였다.","In this paper, correlation analysis was performed between questionnaire and machine learning based aggressive tendency measurements. this study is part of a aggressive driver detection using machine learning and questionnaire. To collect two types tendency from questionnaire and measurements system, we constructed experiments environments and acquired the data from 30 drivers. In experiment, the machine learning based aggressive tendency measurements system was designed using a driver behavior detection model. And the model was constructed using accelerate and brake position data and hidden markov model method through supervised learning. We performed a correlation analysis between two types tendency using Pearson method. The result was represented to high correlation. The results will be utilize for fusing questionnaire and machine learning. Furthermore, It is verified that the machine learning based aggressive tendency is unique to each driver. The aggressive tendency of driver will be utilized as measurements for advanced driver assistance system such as attention assist, driver identification and anti-theft system."
기계학습을 이용한 기록 텍스트 자동분류 사례 연구,2017,"['자동분류', '인공지능', '지도학습', '분류체계', '한국전자통신연구원 엑소브레인', '기계학습', 'automatic classification', 'artificial intelligence', 'supervised learning', 'classification scheme', 'ETRI Exobrain', 'machine learning']",기록이나 문헌의 자동분류에 관한 연구는 오래 전부터 시작되었다. 최근에는 인공지능 기술이 발전하면서 기계학습이나 딥러닝을 접목한 연구로 발전되고 있다. 이 연구에서는 우선 문헌의 자동분류와 인공지능의 학습방식이 발전해 온 과정을 살펴보았다. 또 기계학습 중 특히 지도학습 방식의 특징과 다양한 사례를 통해 기록관리 분야에 인공지능 기술을 적용해야 할 필요성에 대해 알아보았다. 그리고 실제로 지도학습 방식으로 서울시의 결재문서를 ETRI의 엑소브레인을 통해 정부기능분류체계로 자동분류해 보았다. 이를 통해 기록을 다양한 방식의 분류체계로 자동분류하기 위한 각 과정의 고려사항을 도출하였다.,"Research on automatic classification of records and documents has been conducted for a long time. Recently, artificial intelligence technology has been developed to combine machine learning and deep learning. In this study, we first looked at the process of automatic classification of documents and learning method of artificial intelligence. We also discussed the necessity of applying artificial intelligence technology to records management using various cases of machine learning, especially supervised methods. And we conducted a test to automatically classify the public records of the Seoul metropolitan government into BRM using ETRI’s Exobrain, based on supervised machine learning method. Through this, we have drawn up issues to be considered in each step in records management agencies to automatically classify the records into various classification schemes."
기계학습 알고리즘 기반의 인공지능 장기 게임 개발,2017,"['Janggi Game', 'Reinforcement Learning', 'MCTS(Monte Carlo Tree Search) Algorithm', 'Artificial Intelligence Software', 'Machine Learning']",,"Researches on the Artificial Intelligence has been explosively activated in various fields since the advent of AlphaGo. Particularly, researchers on the application of multi-layer neural network such as deep learning, and various machine learning algorithms are being focused actively. In this paper, we described a development of an artificial intelligence Janggi game based on reinforcement learning algorithm and MCTS (Monte Carlo Tree Search) algorithm with accumulated game data. The previous artificial intelligence games are mostly developed based on mini-max algorithm, which depends only on the results of the tree search algorithms. They cannot use of the real data from the games experts, nor cannot enhance the performance by learning. In this paper, we suggest our approach to overcome those limitations as follows. First, we collects Janggi expert’s game data, which can reflect abundant real game results. Second, we create a graph structure by using the game data, which can remove redundant movement. And third, we apply the reinforcement learning algorithm and MCTS algorithm to select the best next move. In addition, the learned graph is stored by object serialization method to provide continuity of the game. The experiment of this study is done with two different types as follows. First, our system is confronted with other AI based system that is currently being served on the internet. Second, our system confronted with some Janggi experts who have winning records of more than 50%. Experimental results show that the rate of our system is significantly higher."
기계학습 기반의 주행중 운전자 자세교정을 위한 지능형 시트,2017,"['Piezoelectric Effect Element', 'Machine Learning', 'Smart Seat', 'Correction of Posture']",,"This paper presents a smart seat for correction of driver posture while driving. We introduce good postures with seat height, seat angle, head height, back of knees, distances of foot pedals, tilt of seat, etc. There have been some studies on correction of good posture while driving, effects of driving environment on driverʹs posture, sitting strategies based on seating pressure distribution, estimation of driverʹs standard postures, and others. However, there are a few studies on guide of good postures while driving for problem of driverʹs posture using machine leaning. Therefore, we suggest a smart seat for correction of driverʹs posture based on machine leaning, 1) developed the system to get postures by 10 piezoelectric effect element, 2) collect piezoelectric values from 37 drivers and 28 types of cars, 3) suggest 4 types of good postures while driving, 4) analyze test postures by kNN. As the results, we can guide good postures for bad or problems of postures while driving."
기계학습을 활용한 E-Sports 승·패 예측에 관한 연구,2017,"['Machine Learning', 'e-Sports', 'Prediction', '기계학습', 'e-Sports', '예측']","최근 온라인게임 시장 규모가 증가하고 사용자들이 다양해지면서 e-Sports의 규모와 인기도 나날이 증가하고 있다. 이에 e-Sports 경기의 승·패에 대한 사람들의 관심도 증가하게 되었지만 이와 관련된 연구는 부족한 것이 현실이다. 따라서 본 논문에서는 e-Sports경기 종목 중 하나인‘리그 오브 레전드’를 중심으로 기계학습을 활용한 승패 예측 모델을 제안한다. 데이터 수집은 op.gg 사이트를 통해 2016년 5월 기준 리그 오브 레전드 한국 서버 상위 1%의 사용자 1,000명의 최근 4 경기, 총 4,000경기 결과를 수집하였다. 구체적인 내용 및 방법은 다음과 같다. 수집된 경기 결과 데이터에서 기록관련 요인 중 경기 내적인 요인을 중심으로 경기 승·패에 밀접한 연관성을 가진 요인들을 기준으로 해당 경기 종목이 가지는 특징을 반영하여 팀의 역량을 나타낼 수 있는 데이터로 가공하였다. 이렇게 가공된 데이터를 바탕으로 기계학습을 시행한 결과 로지스틱 회귀분석 및 의사결정모형, Naive Bayes 모델에서 90% 이상의 예측 정확도를 보였다.",
인공지능 챗봇에 대한 선문답 알고리즘의 데이터 ‒ 심리치료 상담챗봇을 중심으로 ‒,2017,"['The fourth industrial revolution', 'Artificial intelligence', 'Chatbot', 'Machine learning algorithms for seon encounter dialogs', 'Psychotherapy', '제4차 산업혁명', '인공지능', '챗봇', '선문답 알고리즘', '심리치료']","이 논문은 제4차 산업혁명시대의 핵심기술로서 주목받고 있는 인공지능을 이용한 심리치료 상담‘챗봇’에 대하여 선문답 알고리즘의 데이터를 구축할수 있을 지에 대한 논의이다. 선문답과 알고리즘 사이에는 단순성, 목표지향성, 최적화성이라는 유사성이 있다. 이에 착안하여 ‘딥러닝’기술을 통해 방대한 선문답의 대화패턴에 ‘특징값’을 도출시켜 알고리즘화하고 그것들을 분류, 범주화시켜 데이터를 구축할 수 있다는 것이다. 그 범주화의 예로서 심리치료효과를 기대할 수 있는 해소알고리즘, 은유알고리즘, 화두알고리즘 등을 제시할 수 있다. 각 범주로 분류된 데이터들은 심리치료효과가 내포된 고유한 대화패턴을 보여준다. 현재의 심리치료 챗봇기술은 기존의 데이터 시스템 안에서만 자연어 학습과 활용을 하는 방식이다. 그러나 선문답 알고리즘의 데이터를 통해 그 일상적 답변 패턴을 넘어서는 창의적 답변패턴을 선문답의 논법으로부터 차용할 수 있다. 이를 통해 심리치료 챗봇은 광범위한 데이터를 확보하여 보다 효과적인 상담을 할 수 있고, 이용자들은 선불교 전통 속 선사들의 지혜에 보편적 접근이 가능해질 것이다.","This study is an examination about whether mental health chatbots using leading-edge AI technology in the fourth industrial revolution can incorporate a selection of algorithms producing human interactive data for Seon encounter dialogues (SEDs). This comes from the finding that such similarities as simplicity, goal-directedness, and optimization exist between SEDs and algorithms. Thus, “keywords” scanned from the vast SED-oriented conversational patterns could be algorithmized by using “deep learning.” It can, then, be clustered to build data sets. The possible domains of such mental “telepathy” may encompass algorithms that provide examples of non-logical mental representation, algorithms that provide metaphorical examples and algorithms that provide conversation topics (Hwadu). This data group might show individually unique dialogue patterns inclusive of psychotherapy effectiveness.The current chatbot metrics rely on natural language processing within the established database system; however, SED-specific algorithms reply with more creative keywords. This goes beyond conventional quasi-stereotyped response patterns. This means that SED algorithm『powered mental health chatbot can offer more effective counseling based on much more data, making them access the wisdom of meditation masters in the traditional Seon Buddhism."
의학교육에서 기계학습방법 교육: 석면 언론 프레임 연구사례를 중심으로,2017,"['Asbestos', 'Structured topic modelling', 'Automated text analysis', 'Machine learning', 'Big data']",,"There is a more urgent call for educational methods of machine learning in medical education, and therefore, new approaches of teaching and researching machine learning in medicine are needed. This paper presents a case using machine learning through text analysis. Topic modeling of news articles with the keyword 'asbestos' were examined. Two hypotheses were tested using this method, and the process of machine learning of texts is illustrated through this example. Using an automated text analysis method, all the news articles published from January 1, 1990 to November 15, 2016 in South Korea which included 'asbestos' in the title and the body were collected by web scraping. Differences in topics were analyzed by structured topic modelling (STM) and compared by press companies and periods. More articles were found in liberal media outlets. Differences were found in the number and types of topics in the articles according to the partisanship and period. STM showed that the conservative press views asbestos as a personal problem, while the progressive press views asbestos as a social problem. A divergence in the perspective for emphasizing the issues of asbestos between the conservative press and progressive press was also found. Social perspective influences the main topics of news stories. Thus, the patients' uneasiness and pain are not presented by both sources of media. In addition, topics differ between news media sources based on partisanship, and therefore cause divergence in readers' framing. The method of text analysis and its strengths and weaknesses are explained, and an application for the teaching and researching of machine learning in medical education using the methodology of text analysis is considered. An educational method of machine learning in medical education is urgent for future generations."
주제 기반 뉴스 기사 수집을 위한 메타 속성 융합형 기계학습 아키텍처,2017,"['machine learning', 'text classification', 'feature engineering', 'ensemble', 'web crawling', 'bag-of-words', '기계 학습', '문서 분류', '속성 엔지니어링', '앙상블', '웹 크롤링', 'bag-of-words']","기존의 키워드 매칭을 통한 주제 기반 크롤링(topical crawling) 기법은 주어진 주제에서 벗어난 다수의 문서들을 수집하는 문제점을 안고 있다. 본 논문은 화재 사건과 관련 없는 뉴스 기사를 걸러 내기 위해 기존bag-of-words 형태의 속성과 메타 속성 데이터를 융합한 형태의 속성 집합을 고려한 앙상블 과정을 수행하는 효과적인 기계학습 아키텍처를 제안한다. 두 가지 유형의 속성을 다양한 기계학습 알고리즘에 반영하여 얻은 여러 학습 모델들은 적절한 앙상블 과정을 거쳐 주제 기반 크롤링을 위한 효과적인 필터링 작업에 기여한다. 제안 기법의 앙상블 모델은 기존 기법의 분류 모델보다 우수한 성능을 보였다. 구체적으로 이는 기존 최고의 성능을 보이는 나이브 베이즈 기반 모델보다 정밀도 측면에서 8.1% 더 높은 93.9%, F1 측정치 측면에서1% 더 높은 91.1% 기록 하였다. 또한, 제안 기법으로 얻어진 학습 모델은 필터링에 보다 적합한 정밀도-재현율 곡선 (precision-recall curve)을 보였다.","The existing topical crawling method using keyword matching has a problem of collecting a number of documents deviating from a given topic. In this paper, we propose an effective machine learning architecture that performs an ensemble process considering a set of attributes that combine attributes of the bag-of-words type and meta-attribute data in order to filter out news articles that are not related to fire events. Several learning models, obtained by reflecting two types of attributes into various machine learning algorithms, contribute to the effective filtering job for topic-based crawling via proper ensemble process of learned models. The ensemble model of the proposed method shows better performance than the conventional method; specifically, it was 8.1% higher in accuracy and 1% higher in terms of F1-score than the naive Bayes model with the highest performance. In addition, the learned model obtained by the proposed method showed a better precision-recall curve for filtering."
제주 실시간 일사량의 기계학습 예측 기법 연구,2017,"['Solar radiation prediction', 'Machine learning', 'Data mining', 'Tree models', 'Conditional inference tree', 'Random forest', 'Support vector machine', 'Logistic regression']",,"Solar radiation forecasts are important for predicting the amount of ice on road and the potential solar energy. In an attempt to improve solar radiation predictability in Jeju, we conducted machine learning with various data mining techniques such as tree models, conditional inference tree, random forest, support vector machines and logistic regression. To validate machine learning models, the results from the simulation was compared with the solar radiation data observed over Jeju observation site. According to the model assesment, it can be seen that the solar radiation prediction using random forest is the most effective method. The error rate proposed by random forest data mining is 17%."
기계학습을 이용한 돈사 급수량 예측방안 개발,2017,,,"Recently, accumulation of data on pig farm is enabled through the wide spread of smart pig farm equipped with Internet-of-Things based sensors, and various machine learning algorithms are applied on the data in order to improve the productivity of pig farm. Herein, multiple machine learning schemes are used to predict the water usage in pig farm which is known to be one of the most important element in pig farm management. Especially, regression algorithms, which are linear regression, regression tree and AdaBoost regression, and classification algorithms which are logistic classification, decision tree and support vector machine, are applied to derive a prediction scheme which forecast the water usage based on the temperature and humidity of pig farm. Through performance evaluation, we find that the water usage can be predicted with high accuracy. The proposed scheme can be used to detect the malfunction of water system which prevents the death of pigs and reduces the loss of pig farm."
기계학습 기법을 이용한 소상공인 신용평가모형 구축에 관한 연구,2017,"['소상공인', '신용평가', '기계학습', '교차타당법', 'Small Business Owners', 'Credit Scoring', 'Machine Learning', 'Cross Validation']","본 논문은 로지스틱회귀모형, 의사결정나무모형, 신경망모형을 이용하여 소상공인 신용평가모형을 구축하고, 예측 성능이 가장 좋은 모형이 무엇인지를 확인하는 것이다. 모형 구축을 위한 분석 대상은 지역신용보증재단에서 보유하고 있는 자료이다. 이 자료를 이용하여 결측치와 특수값 등을 제거하고 통계적인 변수 선택 기법을 적용하여 최종적으로 15개의 독립변수와 67,308개의 차주의 자료가 모형 구축에 사용되었다. 구축된 세 가지 모형은 10중첩 교차타당법을 이용해 평가하였으며, 모형 평가 측도로는 오분류율, G-mean, F1 측도와 반응률을 이용하였다.  지역신용보증재단의 자료와 세 가지 기계학습 기법을 이용하여 3개의 모형을 구축한 결과, 로지스틱회귀모형을 적용했을 경우 예측 성능이 가장 우수한 것으로 나타났다. 또한 계급불균형인 자료를 이용하여 기계학습 모형 구축 시 예측 성능이 저하될 수 있다는 사실을 발견하였다.  본 논문은 소상공인 신용평가모형 구축에 대해 자료의 양과 신뢰성 부족 문제로 비재무 자료 이용이라는 기존 연구의 틀에서 벗어나, 기계학습기법 적용 가능성을 확인하였다는 점에서 의의가 있다.","The purpose of this paper is to construct a credit scoring model for small businesses using logistic regression model, decision tree model and neural network model, and to identify the model with the best prediction performance. The data used to build the model are data used by the Korea Credit Guarantee Foundation for credit evaluation. From the data, We removed the missing values and special values, selected variables by statistical procedure, and finally used 15 independent variables and 67,308 borrower’s data. The three models were evaluated using the 10-fold cross-validation method, and the error rate, G-mean, F1 measure, and reaction rate were used as the model evaluation measure.  As a result of constructing three models using the data of the Korea Credit Guarantee Foundation and three machine learning techniques, the predictive performance was the best when the logistic regression model was applied. And we found that the prediction performance can be degraded when constructing a machine learning model using class imbalance data."
기계학습과 데이터 시각화 기법을 이용한 주가 패턴 분석,2017,"['Machine Learning', 'Data Visualization', 'Clustering', 'Self Organizing Map', 'Radar Chart', 'Trading Strategy', '기계 학습', '데이터 시각화', '클러스터링', '자기조직화지도', '방사형 차트', '매매 전략']","본 연구는 KOSPI 시장에 상장된 주식을 대상으로 일별 시가, 종가, 저가, 고가를 포함한 총 26개의 기술적 지표를 바탕으로 주가 패턴을 클러스터화하고, 데이터 시각화를 통하여 각 패턴의 유형을 분석하는 것을 목적으로 한다. 따라서 향후 26개의 주가 특성치가 주어졌을 때 현재 주가 패턴이어떤 클러스터에 속하고 해당 클러스터의 속성이 무엇인지 파악함으로써 주식 매매 의사결정에 도움을 주고자 한다. 클러스터링의 방법론은 자기조직화지도(Self Organizing Map)를 이용하고 총 실험기간은 481일의 영업일을 대상으로 한다. 10개의 클러스터 중, 각 클러스터에 평균 약 48일 정도로분류가 되었으며 각 그룹에 대한 대표적인 결과를 방사형 차트로 시각화한 결과, 동일한 그룹에 속한방사형 차트는 매우 유사한 형태를 나타냄을 확인할 수 있다. 더불어 각 그룹의 패턴들이 갖는 의미를 분석하기 위해서 각 패턴의 발생이후 향후 주가의 움직임을 분석한 결과, 특정 패턴 이후에 주가가 상승, 하락 그리고 급락하는 모습을 발견할 수 있다. 본 연구에서 제안하는 방사형 차트를 활용한데이터 시각화와 클러스터별 패턴이 갖는 의미 등은 향후 인공신경망과 같은 기계 학습 기법을 이용하여 정량적인 주식 매매 전략을 취하는데 참고가 되는 연구라 사료된다.","This study aims to cluster the stock price patterns based on 26 technical indicatorsincluding daily open price, closing price, low price and high price for the stocks listed in the KOSPI,and to analyze the patterns within each cluster through data visualization. Therefore, when 26technical indicators are given, our method can make a trading decision by judging the cluster thatthe current price pattern belongs to. We uses Self Organizing Map with 10 clusters and the totalexperiment period is 481. In order to visualize the representative pattern for each cluster, we adopta radar charts. Radar charts that belong to the same group exhibit a very similar form. In addition,to analyze the meaning of the patterns of each cluster, we analyze the movements of stock pricesbetween patterns. As a result, we can find that the stock price rises, falls or crashes after a specific pattern. The data visualization using radar chart and the analysis of each cluster pattern proposedin this study are considered to be a reference for a quantitative stock trading strategy by usingmachine learning techniques such as artificial neural network."
제조 현장의 비정상 데이터 분류를 위한 기계학습 기반 접근 방안 연구,2017,,,"The manufacturing facility is generally operated by a pre-set program under the existing factory automation system. On the other hand, the manufacturing facility must decide how to operate autonomously in Industry 4.0. Determining the operation mode of the production facility itself means, for example, that it detects the abnormality such as the deterioration of the facility at the shop-floor, prediction of the occurrence of the problem, detection of the defect of the product, In this paper, we propose a manufacturing process modeling using a queue for detection of manufacturing process abnormalities at the shop-floor, and detect abnormalities in the modeling using SVM, one of the machine learning techniques. The queue was used for M / D / 1 and the conveyor belt manufacturing system was modeled based on ${\mu}$, ${\lambda}$, and ${\rho}$. SVM was used to detect anomalous signs through changes in ${\rho}$."
기계학습을 적용한 고해상도 강우량 추정에 관한 연구,2017,"['Machine learning', 'Spatial interpolation', 'Rainfall', 'Estimation', 'AWS']","다양한 기후변화 중 국지성 호우는 인명 피해 및 막대한 재산상의 피해를 유발하는 위험 기상이다. 기후변화에 따른 국지성호우는 정확한 예측이 우선되어야 한다. 현재 5km 해상도의 동네예보 서비스는 스톰 규모(200m~1km)에서 발생하는 국지성 호우를 예측하는데 한계가 있다. 다운스케일링을 위해 기상분야에서는 공간보간법을 활용하고 있으나 강우의 특성상 강우량 추정 정확도가 낮은 실정이다. 본 논문에서는 강우량 추정 정확도 향상을 위해 공간보간법과 기계학습 알고리즘을 대상으로 강우량을 추정하고 정확도를 비교분석하여 기상분야의 다운스케일링 기법으로 기계학습 알고리즘을 적용하고자 한다. 이를 위해 강우가 관측된 2015년 8월 16일 16시부터 20시까지의 자동기상관측장비 데이터를 활용하여 사례 분석을 수행하였다. 비교분석을 위한 검증방법은 RMSE, R-square, Correlation Coefficient, CSI, BIAS를 사용하였으며, 그 결과, 기계학습의 배깅 알고리즘이 가장 높은 정확도로 강우량을 추정함을 확인할 수 있었다.",
유동해석을 통한 스마트 제어밸브 학습 및 성능평가용 프로파일 모델링,2017,"['전산유체역학', '머신러닝', '제어밸브', '프로파일', '데이터베이스', 'CFD', 'AIArtificial Intelligence', 'Machine Learning', 'Control Valve', 'Profile', 'Data Base']",,"To evaluate performance of DB based control valve algorithm, CFD analysis was performed to generate any imaginary sensing data. Pressure loss coefficient(K) and flow-rate coefficient(Cv) of globe valve were acquired using CFD analysis results. Feasible 3-variable fitting(Dose-Response-2D relationship) was peformed to generate relationship with valve travel, pressure and flow-rate. Arbitrary valve travel profile could be acquired using relationship generated. The profile for learning and evaluation of AI valve algorithm can be plotted also through fitting method above."
저수지 co<sub>2</sub> 배출량 산정을 위한 기계학습 모델의 적용,2017,"['Artificial neural network', 'Carbon emission', 'Daecheong Reservoir', 'Machine learning', 'Random forest']",,"Lakes and reservoirs have been reported as significant sources of carbon emissions released into the atmosphere of many countries. Although field experiments and theoretical investigations based on the fundamental gas exchange theory have proposed quantitative amounts of Net Atmospheric Flux (NAF) in various climate regions, there is significant uncertainty about the global scale estimation. Mechanistic models can be manipulated for understanding and estimating temporal and spatial variations of NAFs for considering complex hydrodynamic and biogeochemical processes in a reservoir, but such models require extensive and costly datasets and model parameters. However, data driven machine learning (ML) algorithms are likely to be alternative tools to estimate NAFs in responding to independent environmental variables. The objective of this study was to develop random forest (RF) and multi-layer artificial neural network (ANN) models for the estimation of the daily CO<sub>2</sub> NAFs in Daecheong Reservoir located in Geum River in South Korea, and compare the models` performance against the multiple linear regression (MLR) model that was proposed in the previous study (Chung et al” 2016). As a result, the RF and ANN models revealed much enhanced performance in the estimation of high NAF values, while the MLR model significantly underestimated them. A cross-validation with 10-fold random samplings was applied to evaluate the performance of the three models，and it indicated that the ANN model is best, followed by RF and MLR models."
저수지 CO2 배출량 산정을 위한 기계학습 모델의 적용,2017,"['Artificial neural network', 'Carbon emission', 'Daecheong Reservoir', 'Machine learning', 'Random forest.']",,"The lakes and reservoirs have been reported as important sources of carbon emissions to the atmosphere in many countries. Although field experiments and theoretical investigations based on the fundamental gas exchange theory have proposed the quantitative amounts of Net Atmospheric Flux (NAF) in various climate regions, there are still large uncertainties at the global scale estimation. Mechanistic models can be used for understanding and estimating the temporal and spatial variations of the NAFs considering complicated hydrodynamic and biogeochemical processes in a reservoir, but these models require extensive and expensive datasets and model parameters. On the other hand, data driven machine learning (ML) algorithms are likely to be alternative tools to estimate the NAFs in responding to independent environmental variables. The objective of this study was to develop random forest (RF) and multi-layer artificial neural network (ANN) models for the estimation of the daily CO2 NAFs in Daecheong Reservoir located in Geum River of Korea, and compare the models performance against the multiple linear regression(MLR) model that proposed in the previous study(Chung et al., 2016). As a result, the RF and ANN models showed much enhanced performance in the estimation of the high NAF values, while MLR model significantly under estimated them. Across validation with 10-fold random samplings was applied to evaluate the performance of three models, and indicated that the ANN model is best, and followed by RF and MLR models"
기계학습을 활용한 프로야구 승부예측에 관한 연구,2017,"['Neural Network', 'Baseball', 'Prediction', 'Machine Learning', '신경망', '야구', '예측', '기계학습']",,"In this paper, we propose a model for predicting the game using artificial neural network based on date data recorded by athletes in order to predict the win / loss of KBO (Korea Baseball Organization) professional baseball game. Considering that the proportion of starting pitchers in the baseball game is high in 9 innings, the detailed data of the starting pitcher and the records of the remaining pitchers are applied separately and the data are used from 2014 to 2016."
기계학습 기반의 뉴스 추천 서비스 구조와 그 효과에 대한 고찰,2017,"['기계학습', '뉴스 추천 서비스', '카카오', '루빅스', '멀티암드밴딧 알고리듬', 'Machine Learning', 'News Recommendation Service', 'RUBICS', 'Multi-Armed Bandit']","본 논문에서는 카카오가 2015년 6월부터 다음 뉴스에 적용한 루빅스(RUBICS)의 구조와 성과를 고찰한다. 루빅스는 다양한 추천 알고리듬으로 구성된 앙상블(Ensemble) 추천 시스템이며, 각 이용자의 성향을 반영한 개인화 추천과 이용자 집단 내의 트렌드를 반영한 추천을 통합적으로 제공한다. 본 논문에서는 루빅스의 초기(콜드 스타트(Cold-Start) 이용자가 다수인 상황)에 주요 알고리듬으로 사용된 멀티암드밴딧(Multi-Armed Bandit) 중심의 뉴스 추천시스템을 설명한다. 이어 알고리듬 성능을 추적하고 개선하기 위해 사용한 성능평가 방법을 설명하고 이를 통한 점진적인 알고리듬 개선 프로세스에 대해 논의한다. 마지막으로 루빅스 도입 이전과 이후의 뉴스 서비스의 성과 지표 비교를 통해 루빅스의 효과를 설명한다. 루빅스가 다음 모바일 뉴스에 도입되기 전인 2015년 4월과 도입(2015년 6월) 후인 2015년 8월의 뉴스 소비를 비교한 결과, 루빅스가 적용된 후 일평균 클릭 수는 130% 증가했으며, 일평균 뉴스 이용자도 45% 늘었다. 또한 첫 화면에 노출되는 뉴스 콘텐츠의 양도 250% 증가하였다. 이는 루빅스가 이용자 경험의 개선을 통해 이용자의 증가와 뉴스 내의 다양성 확보에 효과가 있음을 보여준다.","We study the structure of RUBICS (Real-time User Behavior Interactive Content recommender System) and its performance in the Daum mobile news service (the “News Service”). RUBICS has deployed in the News Service since June 2015. RUBICS is an ensemble recommender system consisting of various recommendation algorithms, which provides users with a combination of trend recommendation and personalized one. In this paper, we mainly explain a customized Multi-Armed Bandit (MAB) algorithm, which played a major role in the early version system where most users were in cold-start situations. Then, we explain our performance evaluation methods and test-procedures which were employed in order to improve the algorithms in our system. Finally, we discuss the impact of RUBICS on the News Service by comparing the KPIs of the service before and after deployment of RUBCIS. RUBICS increased the average number of clicks per day by 130% and the average number of news clickers per day by 45% between April 2015and August 2015. Also, the number of news articles shown in the Daum mobile homepage increased by 250% during the same period. These results show that RUBICS is efficient in improving user experiences and therefore, can increase the number of active users in the News Service, and enhance diversity of news articles. We hereby wish to share our knowledge obtained from the development of RUBICS and seek to help build an open discussion for the usage of machine learning in the news recommendation service."
빅데이터를 이용한 서울시 행복지수 분석 및 예측을 위한 실험 및 고찰,2017,"['도시 빅데이터', '기계학습', '머신러닝', '예측 모델', '도시 지표', '가중치 분석', 'Big data', 'machine learning', 'prediction model', 'urban data model']",,"Cities have complex system composed diverse activities. The activities in cities have complex relationship that creates diverse urban phenomena. Big Data is emerging technology in order to understand such complex network. This research aims to understand such relations by analysing the diverse city indexes. 28 indexes were collected in 25 of districts in Seoul city and analysed to find a weighted correlation. By defining the correlation values of certain years, it tries to predict the missed index values, “happiness” of each districts in other years. The result presents that the overall prediction accuracy 70.25%. However, for further discussion, the result is considered that this methods may not enough to use in practice, since the data has inconstant accuracy by different learning years."
RCM 자료와 기계학습을 이용한 북극권 카라-바렌츠 해역의 해빙면적비 예측,2017,"['해빙면적비', '기계학습', '지역기후모형', '위성원격탐사', 'Sea Ice Concentration', 'machine learning', 'regional climate model', 'satellite remote sensing']",,"Arctic sea ice as an indicator of climate change plays an important role in controlling global climate system. Thus, accurate observation and prediction of Sea Ice Concentration (SIC) is essential for understanding global climate change. In this study, we aim to improve the prediction accuracy of SIC by using machine learning and Regional Climate Model (RCM) data for a more robust method and a higher spatial resolution. Using the CORDEX RCM and NASA SIC data between January 1981 and December 2015, we developed three statistical models using Multiple Linear Regression (MLR), Support Vector Machine (SVM), and Deep Neural Network (DNN) which can deal with the non-linearity problem, respectively. The DNN model showed the best performance among the three models with the significant correlation between the predictive and observed SIC (r=0.811, p-value < 0.01)and the Root Mean Square Error (RMSE) of 0.258. With deeper considerations of the polar fronts and the characteristics of ocean current and tide, the DNN model can be applied for near future prediction of Arctic sea ice changes."
기계학습을 통한 TIMSS 2011 중학생의 수학 성취도 관련 변수 탐색,2017,"['기계학습', 'LASSO', '축소추정법', 'TIMSS', '수학성취도', 'Machine learning', 'LASSO', 'Penalized regression', 'TIMSS', 'Math achievement']","본 연구는 기계학습적 접근법인 LASSO 기법을 우리나라 TIMSS 2011 중학교 2학년 자료에 적용하였다. TIMSS의 100개의 설명변수를 모형에 모두 투입하여 22개 변수를 선택하였을때, 이 모형의 예측정확도는 약 80%였다. 학생의 수학적 자기효능감, 수학에 대한 태도, 어머니의 교육 수준, 그리고 가정 보유 장서 수와 같은 가정의 교육자원 변수가 학생의 수학 성취수준에 영향을 미치는 것으로 나타났으며, 이는 기존 연구 결과와 일치하였다. 본 연구에서 학생의 수학 성취수준과 관련과 있다고 새롭게 탐색된 변수로 수학숙제 시간, 학생의 과학적 자기효능감, 과학숙제 부여 빈도 등이 있었다. 연구 함의 및 향후 연구 주제 또한 논의되었다.","A substantial body of research has been conducted on factors relating to students’ math achievement with TIMSS. However, most studies have focused on selected a few factors instead of utilizing hundreds of variables TIMSS provides, and have employed conventional statistical methods. This study aimed to investigate possible sets of predictors from a totally different approach: LASSO, currently one of the most popular machine learning techniques. Korean 8th graders’ TIMSS 2011 were used as the sample, and the prediction accuracy of the LASSO model was about 80% with the selected 22 out of 100 predictors. As results, students’ math efficacy, attitudes toward math, mother’s education level, and home educational resources including amount of books at home were influential to their math achievement, which was consistent with previous studies. Additionally, math homework completion time, student’s science self-efficacy, and science homework frequency were newly found important predictors. Implications and future research topics are discussed."
기계학습모델을 이용한 저수지 수위 예측,2017,"['Reservoir water level forecasting', 'Artificial neural network', 'Generalized regression neural network', 'Adaptive neuro-fuzzy inference system', 'Random forest']",,"This study investigates the efficiencies of machine learning models, including artificial neural network (ANN), generalized regression neural network (GRNN), adaptive neuro-fuzzy inference system (ANFIS) and random forest (RF), for reservoir water level forecasting in the Chungju Dam, South Korea. The models' efficiencies are assessed based on model efficiency indices and graphical comparison. The forecasting results of the models are dependent on lead times and the combination of input variables. For lead time t = 1 day, ANFIS1 and ANN6 models yield superior forecasting results to RF6 and GRNN6 models. For lead time t = 5 days, ANN1 and RF6 models produce better forecasting results than ANFIS1 and GRNN3 models. For lead time t = 10 days, ANN3 and RF1 models perform better than ANFIS3 and GRNN3 models. It is found that ANN model yields the best performance for all lead times, in terms of model efficiency and graphical comparison. These results indicate that the optimal combination of input variables and forecasting models depending on lead times should be applied in reservoir water level forecasting, instead of the single combination of input variables and forecasting models for all lead times."
통계적 기계학습에서의 ADMM 알고리즘의 활용,2017,"['Constraint', 'optimization', 'parallel computing', 'penalty function', 'regularization.', '벌점함수', '병렬컴퓨팅', '제약조건', '조정화', '최적화']","최근 여러 분야에서 데이터에 근거한 분석방법론에 대한 수요가 증대됨에 따라 이를 처리할 수 있는 최적화 방법이 발전되고 있다. 특히 통계학과 기계학습 분야의 문제들에서 요구되는 다양한 제약 조건은 볼록 최적화 (convex optimization) 방법으로 해결할 수 있다. 본 논문에서 리뷰하는 alternating direction method of multipliers (ADMM) 알고리즘은 선형 제약 조건을 효과적으로 처지 할 수 있으며, 합의 방식을 통해 병렬연산을 수행할 수 있어서 범용적인 표준 최적화 툴로 자리매김 되고 있다. ADMM은 원래의 문제보다 최적화가 쉬운 부분문제로 분할하고 이를 취합함으로써 복잡한 원 문제를 해결하는 방식의 근사알고리즘이다. 부드럽지 않거나 복합적인 (composite) 목적 함수를 최적화할 때 유용하며, 쌍대이론과 proximal 작용소 이론을 토대로 체계적으로 알고리즘을 구성할 수 있기 때문에 통계 및 기계학습 분야에서 폭 넓게 활용되고 있다. 본 논문에서는 최근 통계와 관련된 여러 분야에서 ADMM알고리즘의 활용도를 살펴보고자 하며 주요한 두 가지 주제에 중점을 두고자 한다. (1) 목적식의 분할 전략과 증강 라그랑지안 방법 및 쌍대문제의 설명과 (2) proximal 작용소의 역할이다. 알고리즘이 적용된 사례로, 벌점화 함수 추정 등의 조정화 (regularization)를 활용한 방법론들을 소개한다. 모의 자료를 활용하여 lasso 문제의 최적화에 대한 실증결과를 제시한다.","In recent years, as demand for data-based analytical methodologies increases in various fields, optimization methods have been developed to handle them. In particular, various constraints required for problems in statistics and machine learning can be solved by convex optimization. Alternating direction method of multipliers (ADMM) can effectively deal with linear constraints, and it can be effectively used as a parallel optimization algorithm. ADMM is an approximation algorithm that solves complex original problems by dividing and combining the partial problems that are easier to optimize than original problems. It is useful for optimizing non-smooth or composite objective functions. It is widely used in statistical and machine learning because it can systematically construct algorithms based on dual theory and proximal operator. In this paper, we will examine applications of ADMM algorithm in various fields related to statistics, and focus on two major points: (1) splitting strategy of objective function, and (2) role of the proximal operator in explaining the Lagrangian method and its dual problem. In this case, we introduce methodologies that utilize regularization. Simulation results are presented to demonstrate effectiveness of the lasso."
기계 학습 방법을 이용한 직장 생활 프로파일 기반의 퇴직 예측 모델 개발,2017,"['직장 생활 프로파일', '기계 학습', '연관성 분석', '지도 학습', '분류 알고리즘', 'Work Life Profile', 'Machine Learning', 'Association Analysis', 'Supervised Learning', 'Classification Algorithm']","최근 대부분의 기업에서 인적 자원의 유출이 조직에 미칠 부정적인 영향을 인지하게 되면서 조직 구성원의 이직 및 퇴직의도에 대해 많은 연구가 이루어졌다. 그러나 대부분 설문조사의 형태로 이루어지며, 직장 생활 데이터를 기반으로 이직 또는 퇴직의도를 살펴본 연구는 아직까지 미비했다. 이에 본 연구에서는 직장 생활 프로파일을 기반으로 직원의 퇴직 여부에 영향을 미치는 요인에 대한 분석을 실시하고, 기계 학습 방법을 활용하여 퇴직 예측 모델을 생성했다. 이 결과, 기존의 설문조사를 중심으로 수행되었던 연구에서 접근하지 못했던 다양한 요인들을 파악할 수 있었다. 또한, 우수한 성능의 퇴직 예측모델 생성을 통해 기업의 인적 자원 유출에 대한 해결방안을 제시할 수 있는 연구의 발판을 마련했다.","Recently, much research has been done on the turnover and retirement intentions of the organization members as many companies recognize the negative impact of the human resource outflow on the organization. However, most of the studies are conducted in the form of questionnaires, and there is still a lack of studies on the turnover and retirement intentions based on the work life data. In this study, we analyzed the factors affecting the retirement of employees based on the work life profile, and created a retirement prediction model using the machine learning method. As a result, we could identify various factors that were not covered in previous researches. In addition, we have established a basis for research that can provide a solution for the problem of human resource outflow by generating a good performance retirement prediction model."
기계학습법을 이용한 서리 발생 구분 추정 연구,2017,"['Frost', 'Artificial neural network', 'Random forest', 'Support vector machine']","본 연구에서는 기상청 예보자료를 이용할 것을 전제로 서리가 발생하는 날과 서리가 발생하지 않는 날을 구분하는 모형을 구축하였다. 서리가 발생한 날과 서리가 발생하지 않은 날을 구분할 수 있는 기상인자로서 최저기온, 평균풍속, 평균상대습도, 평균이슬점온도로 나타났다. 기상인자별로 두 날을 비교한 결과 서리가 발생한 날이 서리가 발생하지 않은 날에 비해 최저기온, 이슬점온도, 평균풍속은 낮게 나타났고 상대습도는 높게 나타났다. 이러한 기상인자로 인공신경망, 랜덤포레스트, 서포트벡터 머신의 기계학습법을 이용한 모형을 연구한 결과 70%이상의 정확도를 나타내어 활용 가능성이 있을 것으로 판단된다.",
기계학습 기반 상세화를 통한 위성 지표면온도와 환경부 토지피복도를 이용한 열환경 분석: 대구광역시를 중심으로,2017,"['land surface temperature', 'downscaling', 'Hot spot analysis', 'random forest', 'urban climate', 'land cover']","급격한 도시화와 이상기후의 증가로 도시의 기온이 꾸준히 올라가고 있으며, 한 도시 안에서도 열분포 양상이 지역마다 다르게 나타나고 있어 상세한 도시 열환경 분석이 요구된다. 최근에는 위성자료를 이용한 열환경 분석이 수행되고 있으나, 위성자료는 시·공간해상도의 Trade-off 관계로 인해 정밀한 분석에어려움이 따른다. 이 연구는 2012년부터 2016년의 대구광역시 여름철 열환경 분석을 위해, MODIS (Moderate Resolution Imaging Spectroradiometer) 1 km 공간해상도의 낮과 밤 지표면온도(낮LST1km, 밤LST1km)를 250 m 공간해상도(낮LST250m, 밤LST250m)로 상세화 시켰다. 상세화에는 기계학습 기법인 랜덤포레스트(Random Forest)가 이용되었다. 향상된 LST250m는 기존의 LST1km에 비해, 대구광역시 행정동 기준 불투수면적 비율과 지표면온도가 높은 상관관계를 보여주었다. 다음으로, 상세화 된 낮과 밤LST250m를이용하여 Hot Spot 분석을 수행하였다. 대구광역시 행정동 중 낮과 밤 지표면온도가 Hot Spot으로 군집화된 영역을 비교하고, 토지피복도를 이용하여 그 원인을 분석했다. 낮에는 공업 및 상업지역의 비율이 높은영역에서, 밤의 경우 주거지역의 비율이 높은 영역에서 높은 Hot Spot이 군집 되었다. 본 연구의 열환경 분석 접근은 향후 도시정책 수립 및 국민안전에 큰 기여를 할 수 있을 것으로 기대된다.","Temperatures in urban areas are steadily rising due to rapid urbanization and on-going climate change. Since the spatial distribution of heat in a city varies by region, it is crucial to investigate detailed thermal characteristics of urban areas. Recently, many studies have been conducted to identify thermal characteristics of urban areas using satellite data. However, satellite data are not sufficient for precise analysis due to the trade-off of temporal and spatial resolutions. In this study, in order to examine the thermal characteristics of Daegu Metropolitan City during the summers between 2012 and 2016, Moderate Resolution Imaging Spectroradiometer (MODIS) daytime and nighttime land surface temperature (LST) data at 1 km spatial resolution were downscaled to a spatial resolution of 250 m using a machine learning method called random forest. Compared to the original 1 km LST, the downscaled 250 m LST showed a higher correlation between the proportion of impervious areas and mean land surface temperatures in Daegu by the administrative neighborhood unit. Hot spot analysis was then conducted using downscaled daytime and nighttime 250 m LST. The clustered hot spot areas for daytime and nighttime were compared and examined based on the land cover data provided by the Ministry of Environment. The high-value hot spots were relatively more clustered in industrial and commercial areas during the daytime and in residential areas at night. The thermal characterization of urban areas using the method proposed in this study is expected to contribute to the establishment of city and national security policies."
자아 중심 주제 인용분석을 활용한 딥러닝 연구동향 분석,2017,"['딥러닝', '기계학습', '연구동향 분석', '자아중심 주제인용분석', '공저 네트워크', '동시인용분석', '인용 이미지 키워드', '인용 성장지수', 'deep learning', 'machine learning', 'research trends analysis', 'ego centered topic citation analysis', 'coauthorship networks', 'co-citation analysis', 'citation image keywords', 'citation growth index']","최근 들어 다양한 분야에서 딥러닝이 혁신적인 기계학습 기법으로 급속하게 확산되고 있다. 이 연구에서는 딥러닝 연구동향을 분석하기 위해서 자아 중심 주제 인용분석 기법을 변형하여 응용해보았다. 이를 위해 Web of Science에서 ‘deep learning’으로 탐색하여 검색된 문헌 중 소수의 씨앗 문헌으로부터 인용 관계를 통해 분석 대상 문헌을 확보하는 방법을 시도하였다. 씨앗 문헌을 인용하는 최근 논문들을 딥러닝 분야의 현행 연구를 반영하는 자아 문헌집합으로 설정하였다. 자아 문헌으로부터 빈번히 인용된 선행 연구들은 딥러닝 분야의 연구 주제를 나타내는 인용 정체성 문헌집합으로 설정하였다. 자아 문헌집합에 대해서는 공저 네트워크 분석을 비롯한 정량적 분석을 실시하여 주요 국가와 연구 기관을 파악하였다. 인용 정체성 문헌들에 대해서는 동시인용 분석을 실시하고, 도출된 문헌 군집을 인용하는 주요 키워드인 인용 이미지 키워드를 파악하여 주요 문헌과 주요 연구 주제를 밝혀내었다. 마지막으로 특정 주제에 대한 인용 영향력이 성장하는 추세를 반영하는 인용 성장지수 CGI를 제안하고 측정하여 딥러닝 분야의 선도 연구 주제가 변화하는 동향을 밝혔다.","Recently, deep learning has been rapidly spreading as an innovative machine learning technique in various domains. This study explored the research trends of deep learning via modified ego centered topic citation analysis. To do that, a few seed documents were selected from among the retrieved documents with the keyword ‘deep learning’ from Web of Science, and the related documents were obtained through citation relations. Those papers citing seed documents were set as ego documents reflecting current research in the field of deep learning. Preliminary studies cited frequently in the ego documents were set as the citation identity documents that represents the specific themes in the field of deep learning. For ego documents which are the result of current research activities, some quantitative analysis methods including co-authorship network analysis were performed to identify major countries and research institutes. For the citation identity documents, co-citation analysis was conducted, and key literatures and key research themes were identified by investigating the citation image keywords, which are major keywords those citing the citation identity document clusters. Finally, we proposed and measured the citation growth index which reflects the growth trend of the citation influence on a specific topic, and showed the changes in the leading research themes in the field of deep learning."
딥 러닝 프레임워크의 비교 및 분석,2017,"['머신 러닝', '딥 러닝', '인공 지능', 'Machine Learning', 'Deep Learning', 'AI']","딥 러닝은 사람이 가르치지 않아도 컴퓨터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 딥 러닝은 세상을 이해하고 감지하는 인공지능을 개발하는데 가장 촉망받는 기술이 되고 있으며, 구글, 바이두, 페이스북 등이 가장 앞서서 개발을 하고 있다. 본 논문에서는 딥 러닝을 구현하는 딥 러닝 프레임워크의 종류에 대해 논의하고, 딥 러닝 프레임워크의 영상과 음성 인식 분야의 효율성에 대해 비교, 분석하고자 한다.","Deep learning is artificial intelligence technology that can teach people like themselves who need machine learning. Deep learning has become of the most promising in the development of artificial intelligence to understand the world and detection technology, and Google, Baidu and Facebook is the most developed in advance. In this paper, we discuss the kind of deep learning frameworks, compare and analyze the efficiency of the image and speech recognition field of it."
미디어 창작도 기계가 대체하는가? : ‘휴머리즘(human+algorithm)’ 미디어의 가능성 혹은 한계,2017,"['humarithm', 'algorithm', 'artificial intelligence', 'AI', 'media creation', 'automation', '휴머리즘', '알고리즘', '인공지능', '미디어 창작', '자동화']","기술의 발전에 따라 텍스트 뉴스, 영상 뉴스, 영화, 소설, 음악, 회화 등 미디어 콘텐츠들이 자동으로 만들어지는 사례들이 속속 등장하고 있다. 그러나 이에 대한 그동안의 논의에서 주를 이뤘던 것은 기계가인간의 창작을 대체할 수 있는지, 또는 인간의 창작을 대체하기 위한 기술적 요소는 무엇인지 등 기술적관점에서의 분석이었다. 이 글은 미디어 창작의 자동화 사례를 텍스트(『현인강림』, 『컴퓨터가 소설을쓰는 날』, WHIM 프로젝트, 딥비트), 영상(<선스프링>, <모건> 예고편), 음악(이아무스, 플로 컴포저), 회화(딥드림), 뉴스 등 분야별로 구체적으로 분석했다. 각각의 작동방식 분석을 통해 이러한 자동화 사례들이 새로운 것을 창작했다기보다는 기존 패턴을 분석한 결과를 토대로 새로운 형식을 만든 것이며, 기존 패턴의 구체적 맥락은 읽어내지 못하고 있음을 밝혔다. 이를 통해 기계가 인간의 창작을 대체할 수있을 것인가라는 논의를 넘어 기계를 활용해 인간의 창의성을 어떻게 더 높일 수 있는가라는 논의를 위해 ‘휴머리즘(human＋algorithm) 미디어’라는 개념을 제시했다. 휴머리즘 미디어는 기계의 연산 능력을 바탕으로 인간의 창조성을 확대하는 새로운 미디어 형식으로 인간은 기계의 도움을 받아 통찰의 능력을 확대하고, 이렇듯 확대된 통찰의 능력을 기계가 학습해 새로운 가능성을 지속적으로 열어나가는것이다.","As technology developing, media contents such as text news, video news, movie, novel, music, painting, start to be created automatically by machine. However, the discussions about ‘automated media creation through technology’ have been mainly focused on analysis from a technical point of view(whether the machine replaces human, what technology is required to replace human, etc.). This article analyzed automation cases of media creation in detail by categories such as text, image, music, movie, news and so on. Through the analysis of each mode of operation, it was revealed that they are not the pure creation from scratch. Because they created some new format based on the analysis of existing patterns. Also the process of automated media creation could not read the specific context of existing media. Authors proposed the concept of ‘humarithm(human＋algorithm) media’ in order to discuss how to increase human creativity by using machine beyond the discussion of whether machine can replace human creation. Humarithm media is a new media format that expands human creativity based on the computing power of the machine. Human beings can extend the ability of insight with the help of machine, machine can learn the insight at the same time, to open up new possibilities continuously."
딥러닝을 PC에 적용하기 위한 메모리 최적화에 관한 연구,2017,"['Image Processing', 'Machine Learning', 'Deep Learning', 'Reduced Learning Time', 'Data Reduction']","본 논문에서는 딥러닝을 PC에 적용하기 위한 메모리 최적화에 관한 알고리즘을 제안한다. 제안된 알고리즘은 일반 PC에서 기존의 딥러닝 구조에서 요구되는 연산처리 과정과 데이터 량을 감소시켜 메모리 및 연산처리 시간을 최소화한다. 본 논문에서 제안하는 알고리즘은 분별력이 있는 랜덤 필터를 이용한 컨볼루션 층 구성 과정, PCA를 이용한 데이터 축소 과정, SVM을 사용한 CNN 구조 생성 등의 3과정으로 이루어진다. 분별력이 있는 랜덤 필터를 이용한 컨볼루션 층 구성 과정에서는 학습과정이 필요치 않아서 전체적인 딥러닝의 학습시간을 단축시킨다. PCA를 이용한 데이터 축소 과정에서는 메모리량과 연산처리량을 감소시킨다. SVM을 사용한 CNN 구조 생성에서는 필요로 하는 메모리량과 연산 처리량의 감소 효과를 극대화 시킨다. 제안된 알고리즘의 성능을 평가하기 위하여 예일대학교의 Extended Yale B 얼굴 데이터베이스를 사용하여 실험한 결과, 본 논문에서 제안하는 알고리즘이 기존의 CNN 알고리즘과 비교하여 비슷한 성능의 인식률을 보이면서 연산 소요시간과 메모리 점유율에 있어 우수함이 확인되었다. 본 논문에서 제안한 알고리즘을 바탕으로 하여 일반 PC에서도 많은 데이터와 연산처리를 가진 딥러닝 알고리즘을 구현할 수 있으리라 기대된다.","In this paper, we propose an algorithm for memory optimization to apply deep learning to PC. The proposed algorithm minimizes the memory and computation processing time by reducing the amount of computation processing and data required in the conventional deep learning structure in a general PC. The algorithm proposed in this paper consists of three steps: a convolution layer configuration process using a random filter with discriminating power, a data reduction process using PCA, and a CNN structure creation using SVM. The learning process is not necessary in the convolution layer construction process using the discriminating random filter, thereby shortening the learning time of the overall deep learning. PCA reduces the amount of memory and computation throughput. The creation of the CNN structure using SVM maximizes the effect of reducing the amount of memory and computational throughput required. In order to evaluate the performance of the proposed algorithm, we experimented with Yale University""s Extended Yale B face database. The results show that the algorithm proposed in this paper has a similar performance recognition rate compared with the existing CNN algorithm. And it was confirmed to be excellent. Based on the algorithm proposed in this paper, it is expected that a deep learning algorithm with many data and computation processes can be implemented in a general PC."
기상자료를 이용한 기계학습모델 기반 태양광 발전량 예측,2017,"['태양광 발전량 예측', '인공신경망', '적응 뉴로퍼지 추론 시스템', '일반회귀신경망', 'Photovoltaic power generation forecasting', 'Artificial neural network', 'Adaptive neuro-fuzzy inference system', 'Generalized regression neural network']",,"This study investigates the performance of machine learning-based photovoltaic power generation forecasting models using meteorological data. Three machine learning models, artificial neural network (ANN), adaptive neuro-fuzzy inference system (ANFIS) and generalized regression neural network (GRNN) models, are developed utilizing photovoltaic power generation and meteorological data, and then the model performances are compared based on statistical model efficiency indices. The machine learning models with photovoltaic power generation and meteorological variables, especially solar radiation and sunshine duration, as inputs perform better than those with only photovoltaic power generation variable. ANN models yield better forecasting results than ANFIS and GRNN models. Among all models, ANN3 model with photovoltaic power generation, solar radiation and sunshine duration as input variables produces the best performance based on model efficiency indices. Therefore, ANN model using solar radiation and sunshine duration among meteorological variables can be an effective tool for reliable photovoltaic power generation forecasting."
한영 기계 번역에서 ST의 유형적 특징에 따른 번역 오류 분석,2017,"['Korean-English machine translation', 'error analysis', 'source text', 'neural machine translation', 'deep learning', '한영기계번역', '오류 분석', '원천 언어', '신경망 기계번역', '딥 러닝']","지난 몇 년 동안 기계번역의 기술은 통계 기계번역(SMT: Statistical Machine Translation)에서 신경망 기계번역(NMT: Neural Machine Translation)으로 괄목할만한 발전을 보여주었다. 딥러닝(deep learning)이 도입되면서 기계번역의 연구는 주로 인공지능의 시스템과 알고리즘을 개발하는 컴퓨터 공학 분야로 제한되었다. 그러나 NMT의 품질은 인간 번역으로 구성된 병렬 코퍼스의 질과 양이 결정적인 영향을 미친다. NMT의 작동 과정에서 신경망이 학습하는 모범 번역은 인간이 투입한다. 그리고 정확한 원문의 입력도 중요한 요소가 된다. 기계번역을 통해 우수한 품질의 결과물을 생산하기 위해서는 번역자가 정확한 원문을 입력하고, 번역물을 수정할 수 있어야 한다. 특히 한영 번역의 경우 원문의 정확도는 번역물 품질에 주요 변수가 된다. 틀린 맞춤법이나 구문, 비문 등이 포함된 원천 텍스트를 입력하면 당연히 오류의 확률이 더 높아진다. 자연언어처리에서 원천 언어의 특징도 주요 변수가 된다. 예를 들면 원천 언어가 한국어인 경우, 조사의 사용이나 언어사용 환경에 따라 번역 오류가 발생할 수 있다.이런 상황을 고려해 볼 때 기계번역의 오류 유형을 제시하고, 원천 텍스트와의 관련성을 고찰하는 연구가 필요하고, 이는 인문학 분야에서 수행되는 것이 바람직하다. 원문의 검토가 사전 처리 과정이라면 기계번역의 결과물을 평가하고, 품질을 개선하는 방안을 제시하는 것은 후처리 과정이 된다.이 연구에서는 한영 기계번역에서 인간의 사전 처리와 후처리 문제를 살펴본다. 연구의 목적은 원천 텍스트의 정확도와 연계해서 오류를 항목별로 분석함으로써 기계번역의 오류 문제에 접근하는 방식을 제시하고 오류를 줄이는 방안을 논의하는 데 있다.","Over the past few years, the technology of machine translation has made remarkable progress from Statistical Machine Translation (SMT) to Neural Machine Translation (NMT). With the introduction of deep learning, the study of machine translation has been performed mainly in the field of computer engineering, which develops systems and algorithms for artificial intelligence. However, the quality and quantity of parallel corpus composed of human translation has a decisive influence on the quality of NMT. In the process of NMT, the model translation that neural network learns is input by human. Also, input of source text is an important factor. The translator must be able to input the correct original text and modify the translation to get excellent quality results in machine translation. Especially, in the case of Korean-English translation, the accuracy of the original text is the main variable for the translation quality. To reduce errors, the translator must enter the correct source text. Inputting source text that contains incorrect spelling, imprecise phrases, and non-grammatical sentences will, of course, increase the probability of error. In the natural language processing, the characteristics of the source language are also the main variables. For example, if the source language is Korean, translation errors may occur depending on the use of the postposition or contextual situation. Given this situation, the accuracy of the source text becomes a major factor in the quality of translation. While the review and revision of the original text is a preprocessing process, evaluating the results of the machine translation and suggesting ways to improve the quality is a postprocessing process.Considering this situation, it is necessary to study the relation between the source text and the error type of machine translation, and it is desirable to perform it in the field of humanities.In this study, we examine human preprocessing and postprocessing issues in Korean-English machine translation. The purpose of this study is to present the error problem of machine translation by analyzing the error in line with the accuracy of the source text, and discussing ways to reduce translation errors."
유사·명시적 학습을 적용한 탁구 백핸드 스트로크의 암묵적 학습효과,2017,"['유사학습', '명시적 학습', '탁구 백핸드 스트로크', 'Analogy Learning', 'Implicit', 'Explicit Motor Learning', 'Table Tennis Backhand Stroke']",,"Purpose: The purpose of this study was to compare and analyze the result of analogy learning, one way of implicit learning, to that of explicit learning when applying the table tennis backhand stroke. This study was to find out effective and efficient learning methods that enable learners to acquire and use the exercise skills easily in school physical education and sports instruction field. Methods: The subjects of the study were 30 students in first grade who tested out and randomly assigned groups of 10 analogy group(AG), explicit group(EG), and control group(CG) for the table tennis team of Busan G middle school sports club in 2016. The research project was to return the ball from the table tennis machine to the target with the table tennis backhand stroke. Data were analyzed by one-way ANOVA to verify homogeneity and repeated measures ANOVA was performed to see differences in learning effects between the groups and division. Results: First, in acquisition phase(AP), there was a difference between absolute errors(AE) in the groups. Second, in retention phase(RP), immediate retention phase(IRP) and delayed retention phase(DRP) were measured, absolute difference, variable error(VE), radial error(RE), and directional error(DE) were significant differences in the groups. Variable error had major effect on division. Conclusion: It can be seen analogy learning, which is one of tacit learning, is effective for the table tennis backhand stroke. When learners are learning motor skills in school physical education and sports instruction field, efficient and effective analogy learning can be used as an alternative to explicit learning methods."
딥러닝 모형의 복잡도에 관한 연구,2017,"['법러닝', '복잡도', '선형 영역', '심층 신경망 함수', '함수 궤적', '함수 전이', 'Complexity', 'deep learning', 'deep neural network', 'linear regions', 'trajectory of a function', 'transition of a function.']","딥러닝은 영상 인식, 음성 인식 등 기존의 머신 러닝 기법들로 해결이 어려웠던 분야에서 매우 우수한 성능을 보였고, 그로 인해 딥러 닝의 폭발적인 연구의 증가가 있었다. 좋은 성능을 보이는 모형 및 모수 추정 방법에 대한 연구들이 주를 이루고 있는 현 흐름 속에서 딥러닝의 이론적인 연구 또한 조심스럽게 진행되고 있다. 본 논문에서는 딥러닝의 성공을 딥러닝 함수가 복잡한 함수를 효율적으로 잘 표현할 수 있음에서 해답을 찾고, 이에 관련된 이론적인 연구들을 조사하여 분석하고자 한다.","Deep learning has been studied explosively and has achieved excellent performance in areas like image and speech recognition, the application areas in which computations have been challenges with ordinary machine learning techniques. The theoretical study of deep learning has also been researched toward improving the performance. In this paper, we try to find a key of the success of the deep learning in rich and efficient expressiveness of the deep learning function, and analyze the theoretical studies related to it."
특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델,2017,"['Machine learning', 'Deep learning', 'Artificial neural network', 'Power Electric demand prediction', 'LSTM']",,"This study analyze correlation between weekdays data and special days data of different power demand patterns, and builds a separate data set, and suggests ways to reduce power demand prediction error by using deep learning network suitable for each data set. In addition, we propose a method to improve the prediction rate by adding the environmental elements and the separating element to the meteorological element, which is a basic power demand prediction elements. The entire data predicted power demand using LSTM which is suitable for learning time series data, and the special day data predicted power demand using DNN. The experiment result show that the prediction rate is improved by adding prediction elements other than meteorological elements. The average RMSE of the entire dataset was 0.2597 for LSTM and 0.5474 for DNN, indicating that the LSTM showed a good prediction rate. The average RMSE of the special day data set was 0.2201 for DNN, indicating that the DNN had better prediction than LSTM. The MAPE of the LSTM of the whole data set was 2.74% and the MAPE of the special day was 3.07 %."
NCS 학습모듈에 의한 산학일체형 도제학교의 금형 분야 교육과정 개발,2017,"['NCS', 'NCS Learning Modules', 'Apprenticeship School', 'Die and Mold Curriculum', 'DACUM', '국가직무능력표준(NCS)', 'NCS 학습모듈', '산학일체형 도제학교', '금형 교육과정', 'DACUM']","본 연구의 목적은 DACUM 직무분석법으로 도출된 금형제작원의 핵심작업과 NCS 학습모듈을 기반으로 산학일체형 도제학교의 금형 분야 교육과정을 개발하는 것이다. 이를 위해 첫째, DACUM 위원회의 협의를 통해 중요도 A등급을 받은 61개의 작업과 입직초기작업으로 도출된 32개의 작업을 비교·분석하여 18개의 핵심작업을 선정하였다. 둘째, 산학일체형 도제학교에 참여하는 산업체의 금형 전문가 20명을 대상으로 설문조사를 실시하여 18개의 핵심작업과 309개의 NCS 능력단위요소를 비교·분석한 결과 56개의 능력단위요소를 매칭시켰다. 셋째, 핵심작업과 능력단위요소의 행렬표를 바탕으로 기초제도, 기계제도, 기계기초공작, 공작기계, 사출금형제작기초, 사출금형제작기본, 프레스금형제작기초, 프레스금형제작기본 등 8개의 교과목을 선정하였다. 넷째, 8종의 교과목과 NCS 능력단위를 학습모듈로 하여 교육과정을 구성하였다. 최종적으로 도출된 산학일체형 도제학교의 금형 분야의 교육과정 구성은 다음과 같다. 1학년은 공업계열 공통과목인 기초제도 교과목과 전공기초과목인 기계기초공작 교과목이 편성되었다. 2학년은 전공기초과목인 기계제도와 공작기계 교과목이 편성되었고, 실무과목인 사출금형제작기초와 프레스금형제작기초를 학교내 교육(Off-JT)과 산업체 현장교육(OJT)으로 분리하여 편성하였다. 마지막으로 3학년은 실무과목인 사출금형제작기본과 프레스금형제작기본을 Off-JT와 OJT로 분리하여 편성하였다.","This study aims at developing the curriculum for die and mold at apprenticeship schools based on both key tasks of die and mold makers drawn from the DACUM job analysis and NCS learning modules. To this end, first of all, a comparative analysis was made of both 61 tasks receiving an A grade in importance through discussion by the DACUM Committee and 32 tasks drawn by entry-level tasks in order to select 18 key tasks. Second, a survey was conducted of 20 die and mold experts in the industry participating in apprenticeship schools to make a comparative analysis of 18 key tasks and 309 elements of competency unit of NCS, thus matching 56 elements of competency unit. Third, based on matrix table of key tasks and the element of competency unit, 8 subjects were selected including basic drawing, mechanical drawing, basic mechanical manufacturing, machine tool, basic injection mold manufacturing, basic press die manufacturing, principles of injection mold manufacturing and principles of press die manufacturing. Fourth, the curriculum was composed of 8 subjects and NCS units of competency as a learning module. The final composition of the die and mold curriculum at Korean-type apprenticeship schools is as follows. As for first-year students, they would be taught basic drawing, an industry-specific common subject, and the basic major course of basic mechanical manufacturing. For second-year students, they would be taught mechanical drawing and machine tool, which are the basic major courses. Basic injection mold manufacturing and basic press die manufacturing, which is a practical subject, was divided into off-the-job training (Off-JT) provided within schools and on-the-job training (OJT) given training at the work place. Finally, third-year students would be taught the practical subject of principles of injection mold manufacturing and principles of press die manufacturing by dividing Off-JT and OJT."
강화학습기법의 동적일정계획에의 적용가능성에 대한 소고,2017,"['Flexible Manufacturing System', 'Reinforcement Learning', 'Dispatching Rules', 'Dynamic Scheduling']",,"The ability to dynamically reschedule jobs is core of flexible manufacturing system. Reinforcement learning, a machine learning approach undergoing development in various control systems, offers advantages in dynamic environments. This paper presents a feasibility study on the reinforcement learning for a dynamic scheduling problem."
딥러닝 모델을 이용한 영상 기반 항만시설물 손상 탐지 프레임워크,2022,"['딥러닝', '영상', '항만시설물', '손상', 'Deep Learning', 'Vision', 'Port Structure', 'Damage']","우리나라에는 60개의 항만에 총 1,086개의 항만시설이 존재하며, 그중 30년이 지난 노후시설은 총 284개(27.7%)나 된다. 현재 항만시설물은 육안 점검을 통해 유지관리가 수행되고 있으나, 항만시설물의 규모와 접근성의 어려움으로 인해 많은 노동력과 작업시간, 그리고 점검자의 위험 노출의 문제점을 안고 있다. 본 연구에서는 영상으로 항만시설물을 촬영하고, 촬영된 영상을 학습된 딥러닝 모델을 이용하여 검출하는 항만시설물 손상 탐지 프레임워크를 제안하였다. 실제 항만에서 촬영한 영상을 이용하여 제안한 프레임워크의 성능을 검증한 결과, 높은 정확도로 손상을 자동 탐지할 수 있음을 보였다.",
축사에서 딥러닝을 이용한 질병개체 파악방안,2017,,,"Recently, the wide spread of IoT (Internet of Things) based technology enables the accumulation of big biometric data on livestock. The availability of big data allows the application of diverse machine learning based algorithm in the field of agriculture, which significantly enhances the productivity of farms. In this paper, we propose an abnormal livestock detection algorithm based on deep learning, which is the one of the most prominent machine learning algorithm. In our proposed scheme, the livestock are divided into two clusters which are normal and abnormal (disease) whose biometric data has different characteristics. Then a deep neural network is used to classify these two clusters based on the biometric data. By using our proposed scheme, the normal and abnormal livestock can be identified based on big biometric data, even though the detailed stochastic characteristics of biometric data are unknown, which is beneficial to prevent epidemic such as mouth-and-foot disease."
서비스 맞춤형 컨테이너를 위한 블록 입출력 히스토리 학습 기반 컨테이너 레이어 파일 시스템 선정 기법,2017,,"OS-level의 가상화 기술은 애플리케이션을 배포하기 위한 새로운 패러다임으로, 기존의 가상화 기술인 가상 머신을 대체할 수 있는 기술로서 주목받고 있다. 특히 컨테이너는 기존의 리눅스 컨테이너에 유니온 마운트 포인트(Union Mount Point) 와 레이어 구조의 이미지를 적용함으로써 보다 빠르고 효율적인 애플리케이션의 배포가 가능하다. 이러한 컨테이너의 특징들은 스냅숏 기능을 제공하는 레이어 구조의 파일 시스템에서만 사용될 수 있으며, 애플리케이션의 특징에 따라 적절한 레이어 파일 시스템을 선택하는 것이 요구된다. 따라서 본 논문에서는 대표적인 레이어 파일 시스템들의 특징을 조사한 뒤, 레이어 파일 시스템의 동작 원리인 Allocate-on-Demand 및 Copy-up 방식에 따른 파일 시스템의 쓰기 성능 평가를 수행한다. 또한 각 레이어 파일 시스템 방식의 블록 입출력 사용 데이터를 학습한 인공 신경망을 통해 임의의 애플리케이션에 대해 적합한 레이어 파일 시스템 방식을 결정하는 방법을 제시하고 이에 대한 타당성을 검토한다.",
국내 학술논문의 동명이인 저자명 식별을 위한 방법,2017,"['Author Name Disambiguation', 'Machine Learning', 'Rule-based Method', 'Heuristic', '저자명 식별', '머신러닝', '룰 베이스 방법', '휴리스틱']","저자명 식별이란 다른 이름으로 표기된 한 명의 개인을 식별하는 것과 같은 이름을 가진 서로 다른 저자들을 각기 구별된 개인으로 분류하는 것으로, 저자의 연구 목록 및 연구 업적 평가, 특정 분야의 전문가를 검색하거나, 인용색인과 같은 학술 정보 서비스의 원활한 운영을 위해 반드시 해결해야 할 문제이다. 본 연구는 단순 머신러닝만을 사용한 실험 결과와 휴리스틱 방식으로 데이터 셋의 오류 수정 및 정규화 작업을 이후 머신러닝의 처리 과정에 룰 베이스 기반의 규칙을 부여한 저자명 식별 실험의 결과의 비교를 통하여, 인간의 개입이 머신러닝의 단점을 보완하고 저자명 식별 성능을 향상시킬 수 있는지 알아보았다. 그 결과 F-measure 0.1 이상 향상시킨 정규화 된 email기반의 룰 베이스 저자식별 결과로 정규화 과정과 휴리스틱 설정에 필요한 인간의 패턴인식과 추론능력이 머신러닝의 단점을 보완해줄 수 있음에 대한 가능성을 나타내었다.","The task of author name disambiguation involves identifying an author with different names or different authors with the same name. The author name disambiguation is important for correctly assessing authors’ research achievements and finding experts in given areas as well as for the effective operation of scholarly information services such as citation indexes. In the study, we performed error correction and normalization of data and applied rules-based author name disambiguation to compare with baseline machine learning disambiguation in order to see if human intervention could improve the machine learning performance. The improvement of over 0.1 in F-measure by the corrected and normalized email-based author name disambiguation over machine learning demonstrates the potential of human pattern identification and inference, which enabled data correction and normalization process as well as the formation of the rule-based diambiguation, to complement the machine learning’s weaknesses to improve the author name disambiguation results."
실시간 장애물 회피 자동 조작을 위한 차량 동역학 기반의 강화학습 전략,2017,"['Reinforcement Learning', 'Obstacle Avoidance']",,"As the development of autonomous vehicles becomes realistic, many automobile manufacturers and components producers aim to develop ‘completely autonomous driving’. ADAS (Advanced Driver Assistance Systems) which has been applied in automobile recently, supports the driver in controlling lane maintenance, speed and direction in a single lane based on limited road environment. Although technologies of obstacles avoidance on the obstacle environment have been developed, they concentrates on simple obstacle avoidances, not considering the control of the actual vehicle in the real situation which makes drivers feel unsafe from the sudden change of the wheel and the speed of the vehicle. In order to develop the ‘completely autonomous driving’ automobile which perceives the surrounding environment by itself and operates, ability of the vehicle should be enhanced in a way human driver does. In this sense, this paper intends to establish a strategy with which autonomous vehicles behave human-friendly based on vehicle dynamics through the reinforcement learning that is based on Q-learning, a type of machine learning. The obstacle avoidance reinforcement learning proceeded in 5 simulations. The reward rule has been set in the experiment so that the car can learn by itself with recurring events, allowing the experiment to have the similar environment to the one when humans drive. Driving Simulator has been used to verify results of the reinforcement learning. The ultimate goal of this study is to enable autonomous vehicles avoid obstacles in a human-friendly way when obstacles appear in their sight, using controlling methods that have previously been learned in various conditions through the reinforcement learning."
인공지능과 예술창작 활동의 융복합 사례분석 및 특성 연구,2017,"['Artificial Intelligence(인공지능)', 'Deep Learning(딥러닝)', 'Art Creation(예술창작)', 'Creativity(창의성)', 'Convergence(융복합)']","최근 컴퓨터의 발달로 인해 네트워크의 활성화, 정보의 혁명, 빅데이터의 등장, 혁신적인 딥러닝의 기술발전으로 인공지능은 눈부신 성장을 하고 있으며 인공지능에 대한 대중들의 관심도 급증하고 있다. 테크놀로지와 예술의 융합은 오래전부터 계속되었으나 인공지능처럼 기계가 지능을 가지고 인간 고유의 능력인 창의적인 예술 활동을 직접 하는 경우는 없었으며 단순히 예술의 기계적 장치 수단으로써만 사용되었다.  그러던 것이 최근 인공지능의 영역은 단순한 기계적인 일처리 방식 분야뿐만 아니라 인간 고유의 영역이었던 창의성을 필요로 하는 예술분야까지 침범하였고 더불어 인공지능의 창의성에 대한 논란도 끊임없이 계속되고 있다.  그럼에도 불구하고 학문이라는 각각의 고유한 영역안에서 오랜 기간 형성된 학문간의 장벽을 허물고 인공지능이라는 과학기술과 예술창작 활동을 융복합시켜 과학과 예술의 협력을 통한 동반성장을 도모하고 예술창작 분야의 새로운 패러다임을 창출하였다는 것에 그 의의가 크다 하겠다.  이에 본 연구는 인간의 고유한 능력이자 재능인 창의성이 인공지능 시대와 어떻게 연결될 수 있으며 인공지능이 창의성을 요구하는 예술분야에서 어떠한 기술로 개발되었는지에 대해 알아보고자 한다. 또한 미래를 예측할 수 없는 현재 상황에서 인공지능을 활용한 예술의 특성을 살펴봄으로써 예술발달에 새로운 방향을 마련하는 자료로 활용하고 더불어 미래 인공지능 예술분야의 발전에 기여하는데 연구의 목적이 있다. 연구방법은 다음과 같은 순서로 기술한다.  첫째, 연구의 배경을 바탕으로 필요성과 목적에 대해 설정하고 구체적인 연구방법을 제시한다.  둘째, 인공지능의 정의와 역사에 대해 알아보고 빅데이터를 기반으로 한 인공지능 핵심기술 딥러닝에 대해 기술한다.  셋째, 인공지능을 활용한 예술분야에서도 특히 인공지능의 기술 개발이 활발하게 이루어진 문학, 음악, 미술 분야를 선정하여 인공지능과 예술이 융복합 된 사례조사를 통해 인공지능 예술창작 현황에 대해 기술한다.  넷째, 인공지능 예술창작분야의 사례분석을 바탕으로 인공지능의 예술에 따른 표현특성을 도출한다.  그 결과 인공지능이 활용된 예술의 표현특성으로는 기존에 학습한 데이터를 바탕으로 새로운 것을 창조하는 창의성, 미적활동을 통해 즐거움을 느낄 수 있는 유희성, 예술작품 제작과정에서 나타나는 노동의 해결책에 대한 편리성, 단순한 기술적 조작이나 새로운 기계학습의 프로그래밍 변화로 하나의 형태에서 전혀 다른 형태의 작품으로 바꿀 수 있는 가변성이 나타났다.  결론적으로 현재 인공지능의 창의성은 새로운 것을 창조했다기보다는 이미 주어진 데이터의 기계학습을 통하여 기존의 작품을 모사하여 재창조하는 수준이다. 즉 인공지능의 예술창작분야에 있어서 현재까지는 창의성이나 판단력, 직관 등 인간 고유의 영역을 대체할 수는 없으나 인공지능 예술창작의 기술 개발은 앞으로의 가능성을 예측할 수 있는 큰 성과라 할 수 있다.  정보화 기술(IT)시대에서 데이터 기술(DT)시대로 빠르게 전환되고 있는 4차 산업혁명시대의 인공지능기술 발달은 서비스산업과 노동가치의 상승으로 우리 삶을 높이는데 일조할 것이며 예술분야에서는 새로운 창작에 대한 영감을 주는 등 창작활동에 많은 도움이 될 것이다. 이에 본 연구는 앞으로 지속적으로 인공지능이 창의성을 요구하는 문화예술분야에 도움이 되기를 기대해본다.","A.I.(Artificial intelligence) has been building momentum due to network activation, information innovation, big data, and technological advancement of innovative deep learning as a result of the development of computers, and the interest in A.I is growing remarkably. There has been the merging of technology and arts for years; however, unlike A.I, machines have not had creative art performance ability as human have, but have only been used as a mechanical method of arts.  A.I. field now is not only used as simple mechanical methods, but has also invaded the arts area that needs creativity which had been only for human distinction, and the controversy over creativity of A.I. is ongoing.   However, in the distinct fields of academic research, getting rid of the barrier between academic fields and converging the scientific technology of A.I and art creation activities so that through the collaboration between science and arts, their collective growth is promoted and a new paradigm in the art field is created will be of great significance.  This research intends to find out how creativity known as an exclusive human ability and area is connected to A.I. and what technics have developed A.I. in the creativity-demanded arts field. Moreover, this research aims to be used to shape new direction of artistic development as reviewing the characteristics of arts applied A.I. and to contribute towards the A.I. arts sphere under the unpredictable current situation. The research methods are composed of the following order.  First of all, the necessity and the purpose of the research based on research background is set and specific research methods is drawn.  Secondly, the research finds out the definition and history of A.I. and describes deep learning of the A.I. core technology based on big data.  Third, case study on the field of literature, music, and fine arts that actively develop A.I. technics among A.I. art fields are selected and then through a case analysis study of the convergence between A.I and art, the current situation of A.I. artistic creation described.  Fourth, characteristics of expression of A.I. based on case studies of A.I. artistic creation field is deducted.  With respect to the results, characteristics of expression of A.I. arts are; creativity that creates new things that never existed based on learning data, pleasure that is felt through aesthetic works, convenience related to labour solutions during the creating process, and variability that changes from one to a total different work by simple technical operation or programming changes of new machine learning.  In conclusion, the creativity of current A.I. does not create new things but rather recreate existing work via machine learning from already given data. To sum up, for now, the field of artistic creation of A.I. cannot replace human ability like creation, instinct, judgement, etc.; however, technical development of A.I. artistic creation is a big result to predict future possibility.  In the fourth industrial revolution in which IT (information Technology) quickly moves to DT (Date Technology), A.I. technical development will contribute to improve our quality of lives due to increasing service industry and labor values. It will also help to inspire new creation in the art field. This paper is expected to help the culture-art field that consistently needs A.I creativity."
차세대 인공지능의 특허대상 범위에 대한 도전 - 미국의 법리를 중심으로 -,2017,"['인공지능 특허', '인공지능 특허적격성', '인공지능 특허대상성', '머신러닝 특허', '알고리즘 특허', '특허기계', 'AI Patent', 'AI Patentable Subject-matter', 'Machine Learning Patent', 'Algorithm Patent', 'Patent Machine']","인공지능(Artificial Intelligence)은 발명의 과정을 변화시키고 있다. 유전자 알고리즘 등 머신러닝을 활용한 프로그램들은 특허성 있는 발명을 만들어내는 데 있어 중요한 역할을 해왔으며, 이미 상당수의 특허가 그러한 프로그램의 프로세스에 부여되었다. 그러나 기술의 비약적인 발전으로 인공지능을 활용한 프로그램들은 이제 발명과정의 부분적인 역할에서 벗어나 스스로 데이터에 접근하고 자동화된 시행착오 테스트를 통해 진화하며, 자체적으로 신규한 발명을 만들어 낼 능력을 갖추어가고 있다. 기하급수적인 양의 발명을 만들어낼 수 있는 강력한 “특허 기계”의 등장을 예고하고 있는 것이다. 신기술의 등장에 따라 점차 확장되어왔던 특허대상의 범위에 대한 비판적인 고찰이 요구되는 시점이며, 인공지능 프로세스의 특허적격성은 재검토 되어질 필요가 있다. 이 논문에서는 인공지능 프로세스의 특허적격성 판단을 위한 미국의 법 해석 방향을 소개하고, 사례의 적용가능성 검토를 통해 무분별한 인공지능 특허 허여의 위험성을 경고한다.","Artificial Intelligence(AI) has been changing the process of invention. The system utilizing machine learning such as genetic algorithm has proven it has the ability to perform central role of invention process and several of them were already patented. However, because of the developing AI technique, the future machine will access big data itself and evolve through performing automated trial and error test, so finally could create a new invention itself. It will be a strong “Patent Machine”. It is time to begin to reexamine whether AI meets patent eligibility requirement. We need to critically consider the expanding range of patentable subject matter. This paper introduces the analysis method on the law of patentable subject matter and warns the risk of indiscriminate patenting on AI through illustrating related cases."
신경망 및 통계 기법 기반의 기계학습을 이용한 유류유출 및 기상 예측 연구 동향,2017,"['유류유출', '재난', '기상', '기계학습', '예측', 'Oil spill', 'Disaster', 'Weather', 'Machine learning', 'Forecast']","정확한 예측은 미래에 일어날 현상에 대해 효과적으로 준비 혹은 대처 할 수 있게 해준다. 특히, 기상 현상은 인간의 생활과 밀접한 연관이 있으며, 발생할 수 있는 기상 및 재난 예측을 통해 인명, 재산 등의 피해로부터 예방 할 수 있게 해준다. 해상에서 발생할 수 있는 재난 중 하나인 유류유출 사고에 대해 빠르고 효과적으로 대응하 기 위해서는 유출유의 이동과 주변 해역의 기상을 정확하게 예측하는 것이 중요하다. 본 논문에서는 분류 및 회귀 예측과 관련된 연구에서 준수한 성능 및 예측 가능성을 보여준 기계학습 기법으로 서포트 벡터 머신, 가우시안 프로 세스, 다층 퍼셉트론, 방사기저함수 네트워크의 총 4 개의 기계학습 기법을 선별하였다. 선별한 기계학습 기법을 이용하여 유류유출의 탐지와 바람, 강우량, 오존 등의 기상 데이터를 예측하는 연구들의 연구 방법과 결과 등을 설 명하며 이를 활용한 기계학습 기반 유류유출 예측 모델의 적용 가능성을 제시한다.","Accurate forecasting enables to effectively prepare for future phenomenon. Especially, meteorological phenomenon is closely related with human life, and it can prevent from damage such as human life and property through forecasting of weather and disaster that can occur. To respond quickly and effectively to oil spill accidents, it is important to accurately predict the movement of oil spills and the weather in the surrounding waters. In this paper, we selected four representative machine learning techniques: support vector machine, Gaussian process, multilayer perceptron, and radial basis function network that have shown good performance and predictability in the previous studies related to oil spill detection and prediction in meteorology such as wind, rainfall and ozone. we suggest the applicability of oil spill prediction model based on machine learning."
기계학습 기반의 실시간 이미지 인식 알고리즘의 성능,2017,"['machine learning', 'artificial neural network', 'image recognition', 'deep learning', 'autonomous vehicle']",본 논문에서는 기계학습 기반의 실시간 이미지 인식 알고리즘을 개발하고 개발한 알고리즘의 성능을 테스트 하였다. 실시간 이미지 인식 알고리즘은 기계 학습된 이미지 데이터를 바탕으로 실시간으로 입력되는 이미지를 인식한다. 개발한 실시간 이미지 인식 알고 리즘의 성능을 테스트하기 위해 자율주행 자동차 분야에 적용해보았고 이를 통해 개발한 실시간 이미지 인식 알고리즘의 성능을 확인해보았다.,"In this paper, we developed a real-time image recognition algorithm based on machine learning and tested the performance of the algorithm. The real-time image recognition algorithm recognizes the input image in real-time based on the machine-learned image data. In order to test the performance of the real-time image recognition algorithm, we applied the real-time image recognition algorithm to the autonomous vehicle and showed the performance of the real-time image recognition algorithm through the application of the autonomous vehicle."
A Novel Road Segmentation Technique from Orthophotos Using Deep Convolutional Autoencoders,2017,"['Road Segmentation', 'Deep Learning', 'Autoencoder', 'Convolutional Neural Networks', 'Remote sensing', 'Orthophotos']",,"This paper presents a deep learning-based road segmentation framework from very high-resolution orthophotos. The proposed method uses Deep Convolutional Autoencoders for end-to-end mapping of orthophotos to road segmentations. In addition, a set of post-processing steps were applied to make the model outputs GIS-ready data that could be useful for various applications. The optimization of the model's parameters is explained which was conducted via grid search method. The model was trained and implemented in Keras, a high-level deep learning framework run on top of Tensorflow. The results show that the proposed model with the best-obtained hyperparameters could segment road objects from orthophotos at an average accuracy of 88.5%. The results of optimization revealed that the best optimization algorithm and activation function for the studied task are Stochastic Gradient Descent (SGD) and Exponential Linear Unit (ELU), respectively. In addition, the best numbers of convolutional filters were found to be 8 for the first and second layers and 128 for the third and fourth layers of the proposed network architecture. Moreover, the analysis on the time complexity of the model showed that the model could be trained in 4 hours and 50 minutes on 1024 high-resolution images of size $106{\times}106pixels$, and segment road objects from similar size and resolution images in around 14 minutes. The results show that the deep learning models such as Convolutional Autoencoders could be a best alternative to traditional machine learning models for road segmentation from aerial photographs."
A Novel Road Segmentation Technique from Orthophotos Using Deep Convolutional Autoencoders,2017,"['Road Segmentation', 'Deep Learning', 'Autoencoder', 'Convolutional Neural Networks', 'Remote sensing', 'Orthophotos']",,"This paper presents a deep learning-based road segmentation framework from very high-resolution orthophotos. The proposed method uses Deep Convolutional Autoencoders for end-to-end mapping of orthophotos to road segmentations. In addition, a set of post-processing steps were applied to make the model outputs GIS-ready data that could be useful for various applications. The optimization of the model`s parameters is explained which was conducted via grid search method. The model was trained and implemented in Keras, a high-level deep learning framework run on top of Tensorflow. The results show that the proposed model with the best-obtained hyperparameters could segment road objects from orthophotos at an average accuracy of 88.5%. The results of optimization revealed that the best optimization algorithm and activation function for the studied task are Stochastic Gradient Descent (SGD) and Exponential Linear Unit (ELU), respectively. In addition, the best numbers of convolutional filters were found to be 8 for the first and second layers and 128 for the third and fourth layers of the proposed network architecture. Moreover, the analysis on the time complexity of the model showed that the model could be trained in 4 hours and 50 minutes on 1024 high-resolution images of size 106 × 106 pixels, and segment road objects from similar size and resolution images in around 14 minutes. The results show that the deep learning models such as Convolutional Autoencoders could be a best alternative to traditional machine learning models for road segmentation from aerial photographs."
일기 예보와 예측 일사 및 일조를 이용한 태양광 발전 예측,2017,"['Solar photovoltaic generation forecast', 'Deep learning', 'Artificial neural network', 'Support vector machine']",,"Photovoltaic generation which has unlimited energy sources are very intermittent because they depend on the weather. Therefore, it is necessary to get accurate generation prediction with reducing the uncertainty of photovoltaic generation and improvement of the economics. The Meteorological Agency predicts weather factors for three days, but doesn’t predict the sunshine and solar radiation that are most correlated with the prediction of photovoltaic generation. In this study, we predict sunshine and solar radiation using weather, precipitation, wind direction, wind speed, humidity, and cloudiness which is forecasted for three days at Meteorological Agency. The photovoltaic generation forecasting model is proposed by using predicted solar radiation and sunshine. As a result, the proposed model showed better results in the error rate indexes such as MAE, RMSE, and MAPE than the model that predicts photovoltaic generation without radiation and sunshine. In addition, DNN showed a lower error rate index than using SVM, which is a type of machine learning."
관성센서를 이용한 버그균형검사 점수 분류 연구,2017,"['Berg Balance Scale', 'BBS', 'Inertial Sensor', 'GMM', 'Machine Learning']","본 논문에서는 균형평가도구 중 임상에서 가장 많이 사용되는 BBS(Berg Balance Scale)를 머신러닝 기법을 이용하여 점수 분류 정확도를 제시한다. 데이터취득은 Noraxon 시스템을 이용하여, 신체 8군데(왼쪽·오른쪽 발목, 왼쪽·오른쪽 엉덩이 위, 왼쪽·오른쪽 손목, 등(Back), 이마)에 관성센서를 부착하였다. 관성센서의 3축 가속도데이터를 기반으로 특징벡터 STFT(Short Time Fourier Transform), SAM(Signal Area Magnitude)를 추출하였다. 그 다음, BBS의 항목을 동작특성에 따라 정적인 동작(static movement)과 동적인 동작(dynamic movement)으로 나누었고, BBS의 각 항목에 대하여 점수에 영향이 있는 센서부착위치에 따라 특징벡터를 선별하였다. BBS의 항목마다 선별된 특징벡터는 GMM(Gaussian Mixture Model)을 이용하여 분류하였다. 실험대상자 40명에 대한 정확도 산출결과, 1번순으로 차례대로 55.5%, 72.2%, 87.5%, 50%, 35.1%, 62.5%, 43.3%, 58.6%, 60.7%, 33.3%, 44.8%, 89.2%, 51.8%, 85.1%의 분류 정확도를 확인하였다.","In this paper, we present the score classification accuracy of BBS(Berg Balance Scale) which is the most commonly used balance evaluation tool using machine learning. Data acquisition was performed using the Noraxon system and an inertial sensor of Noraxon system was attached to the body in 8 locations (left and right ankle, left and right upper buttocks, left and right wrists, back, forehead). Based on the 3-axis accelerometer of the inertial sensor, the feature vector STFT(Short Time Fourier Transform) and SAM(Signal Area Magnitude) were extracted. Then, the items of the BBS were divided into static movement and dynamic movement depending on the operation characteristics, and the feature vectors were selected according to the sensor attachment positions which affect the score for each item of the BBS. Feature vectors selected for each item of BBS were classified using GMM(Gaussian Mixture Model). As a result of the accuracy calculation for 40 subjects, 55.5%, 72.2%, 87.5%, 50%, 35.1%, 62.5%, 43.3%, 58.6%, 60.7%, 33.3%, 44.8%, 89.2%, 51.8%, 85.1%, respectively."
Very Short-Term Wind Power Ensemble Forecasting without Numerical Weather Prediction through the Predictor Design,2017,"['Wind power forecasting', 'Ensemble forecasting', 'Gradient boosting machine']",,"The goal of this paper is to provide the specific forecasting steps and to explain how to design the forecasting architecture and training data sets to forecast very short-term wind power when the numerical weather prediction (NWP) is unavailable, and when the sampling periods of the wind power and training data are different. We forecast the very short-term wind power every 15 minutes starting two hours after receiving the most recent measurements up to 40 hours for a total of 38 hours, without using the NWP data but using the historical weather data. Generally, the NWP works as a predictor and can be converted to wind power forecasts through machine learning-based forecasting algorithms. Without the NWP, we can still build the predictor by shifting the historical weather data and apply the machine learning-based algorithms to the shifted weather data. In this process, the sampling intervals of the weather and wind power data are unified. To verify our approaches, we participated in the 2017 wind power forecasting competition held by the European Energy Market conference and ranked sixth. We have shown that the wind power can be accurately forecasted through the data shifting although the NWP is unavailable."
원형 근전도 센서 어레이 시스템의 센서 틀어짐에 강인한 손 제스쳐 인식,2017,"['Bio-Signal Processing', 'EMG', 'Pattern Classification', 'Machine Learning', 'PCA']","본 논문에서는 원형 근전도 시스템 장비를 사용하여 근전도 패턴인식을 할 때, 장비의 센서 위치와 무관하게 패턴 인식이 가능한 알고리즘을 제안한다. 6가지 동작의 8채널 근전도 신호를 1초간 측정한 데이터를 이용하여 14개의 특징점을 추출하였다. 또한 8개의 채널에서 추출된 112개의 특징점을 나열하여 주성분분석을 하고 영향력이 높은 데이터만을 추려내어 8개의 입력 신호로 줄였다. 모든 실험은 k-NN 분류기를 이용하여 데이터를 학습시키고 5-fold 교차 검증을 사용하여 데이터를 검증하였다. 기계학습에서 데이터를 학습시킬 때, 어떤 데이터를 학습하느냐에 따라 그 결과가 크게 달라진다. 기존의 연구들에서 사용하는 학습 데이터를 사용 할 경우 99.3%의 정확도를 확인하였다. 그러나 센서의 위치가 22.5도 정도만 틀어지더라도 67.28%의 정확도로 명확하게 떨어짐을 보았다. 본 논문에서 제안하는 학습 방법을 사용 할 경우 98%의 정확도를 보이고 장비의 센서의 위치가 바뀌더라도 98% 근처의 정확도를 유지함을 보였다. 이러한 결과를 사용하여 원형 근전도 시스템을 사용하는 사용자들의 편의성을 크게 증대시켜 줄 수 있을 것으로 보인다.","In this paper, we propose an algorithm that can recognize the pattern regardless of the sensor position when performing EMG pattern recognition using circular EMG system equipment. Fourteen features were extracted by using the data obtained by measuring the eight channel EMG signals of six motions for 1 second. In addition, 112 features extracted from 8 channels were analyzed to perform principal component analysis, and only the data with high influence was cut out to 8 input signals. All experiments were performed using k-NN classifier and data was verified using 5-fold cross validation. When learning data in machine learning, the results vary greatly depending on what data is learned. EMG Accuracy of 99.3% was confirmed when using the learning data used in the previous studies. However, even if the position of the sensor was changed by only 22.5 degrees, it was clearly dropped to 67.28% accuracy. The accuracy of the proposed method is 98% and the accuracy of the proposed method is about 98% even if the sensor position is changed. Using these results, it is expected that the convenience of the users using the circular EMG system can be greatly increased."
A Gabor-based network for heterogeneous face recognition,2017,"['Heterogeneous face recognition', 'Gabor features', 'Extreme learning machine', 'Random weighting']",,"<P><B>Abstract</B></P>  <P>In this paper, we propose a single hidden-layer Gabor-based network for heterogeneous face recognition. The proposed input layer contains novel computational units which propagate geometrically localized input image sub-blocks to hidden nodes. The propagated pixels are then convolved with a set of Gabor kernels followed by a randomly weighted summation and a non-linear activation function operation. The output layer adopts a linear weighting scheme which can be deterministically estimated similar to that in extreme learning machine. Our experiments on three experimental scenarios using BERC visual-thermal infrared database and CASIA visual-near infrared database show promising results for the proposed network.</P>"
Very Short-Term Wind Power Ensemble Forecasting without Numerical Weather Prediction through the Predictor Design,2017,"['Wind power forecasting', 'Ensemble forecasting', 'Gradient boosting machine']",,"The goal of this paper is to provide the specific forecasting steps and to explain how to design the forecasting architecture and training data sets to forecast very short-term wind power when the numerical weather prediction (NWP) is unavailable, and when the sampling periods of the wind power and training data are different. We forecast the very short-term wind power every 15 minutes starting two hours after receiving the most recent measurements up to 40 hours for a total of 38 hours, without using the NWP data but using the historical weather data. Generally, the NWP works as a predictor and can be converted to wind power forecasts through machine learning-based forecasting algorithms. Without the NWP, we can still build the predictor by shifting the historical weather data and apply the machine learning-based algorithms to the shifted weather data. In this process, the sampling intervals of the weather and wind power data are unified. To verify our approaches, we participated in the 2017 wind power forecasting competition held by the European Energy Market conference and ranked sixth. We have shown that the wind power can be accurately forecasted through the data shifting although the NWP is unavailable."
소상공인 날씨경영 지원을 위한 지리적 시각화 활용 방안에 관한 연구,2017,"['Weather risk management', 'Geovisualization', 'Infographics', 'Machine learning', '날씨경영', '지리적 시각화', '인포그래픽', '머신러닝']","날씨가 산업부문에 미치는 영향이 중요하다는 사실이 알려지면서, 산업분야별로 날씨 영향력에 대응하기 위해서 날씨경영 지원을 위한 정보 서비스를 구축하고 있다. 날씨정보와 기업의 매출정보가 위치속성을 가지고 있으며 기업의 경영활동에서 나타나는 문제가 위치속성에서 기인하는 공간문제인 점을 고려한다면, 날씨경영 지원을 위한 정보 서비스에서 지리적 시각화를 활용하는 것은 중요하다고 할 수 있다. 이 연구에서는 소상공인이 날씨와 매출액 간의 상관관계를 쉽게 파악할 수 있도록 시각화 도구, 사용자 인터랙션, 인포그래픽 디자인 그리고 머신러닝 분석 결과를 결합하는 지리적 시각화 서비스 프로토타입을 제안한다. 이 연구에서 제안한 지리적 시각화 서비스 프로토타입은 향후 날씨경영 지원 서비스 개발에 활용할 수 있는 참조모델이 될 수 있을 것으로 평가할 수 있다.","As the influence of weather on industries becomes important, the efforts to build weather risk management services for individual industry are increasing to cope with the climate impacts. Based on the spatial characteristics of weather and business information which include locational components, it is important to utilize geovisualization for support of weather risk management from a geographic perspective. This study proposes a geovisualization service prototype which supports visualization tools, user interactions, and infographics design. Our service prototype can be a reference for the development of weather risk management services that combine geovisualization and machine-learning analysis."
Very Short-Term Wind Power Ensemble Forecasting without Numerical Weather Prediction through the Predictor Design,2017,"['Wind power forecasting', 'Ensemble forecasting', 'Gradient boosting machine']",,"The goal of this paper is to provide the specific forecasting steps and to explain how to design the forecasting architecture and training data sets to forecast very short-term wind power when the numerical weather prediction (NWP) is unavailable, and when the sampling periods of the wind power and training data are different. We forecast the very short-term wind power every 15 minutes starting two hours after receiving the most recent measurements up to 40 hours for a total of 38 hours, without using the NWP data but using the historical weather data. Generally, the NWP works as a predictor and can be converted to wind power forecasts through machine learning-based forecasting algorithms. Without the NWP, we can still build the predictor by shifting the historical weather data and apply the machine learning-based algorithms to the shifted weather data. In this process, the sampling intervals of the weather and wind power data are unified. To verify our approaches, we participated in the 2017 wind power forecasting competition held by the European Energy Market conference and ranked sixth. We have shown that the wind power can be accurately forecasted through the data shifting although the NWP is unavailable."
Sensitivity analysis of the influencing factors of slope stability based on LS-SVM,2017,"['slope stability', 'sensitivity analysis', 'orthogonal design', 'least squares support vector machine', 'gray correlation']",,"This study proposes a sensitivity analysis method for slope stability based on the least squares support vector machine (LS-SVM) to examine the influencing factors of slope stability. The method uses LS-SVM as an algorithm for machine learning. An appropriate training dataset is established according to the slope characteristics, and a testing dataset is designed orthogonally. Results of the testing data in the experiment design are calculated after training using the LS-SVM model. The sensitivity of the slope stability of each factor is examined via gray correlation analysis. The results are consistent with those of the traditional Bishop analysis and can be used as a reference for optimizing slope design."
Fire Detection using Deep Convolutional Neural Networks for Assisting People with Visual Impairments in an Emergency Situation,2017,"['시각장애인', '화재감지', '심층학습', '심층 합성곱 신경망', 'blind people', 'fire detection', 'deep learning', 'deep convolutional networks']",본 연구는 실내에서 화재 발생시 시각 장애인들을 지원하기 위한 영상 기반의 화재감지기를 제안한다. 건물 내에 화재가 발생하는 비상 상황 발생시 시각 장애인은 일반인보다 상황을 인지하는 것이 늦기 때문에 위험한 상황에 노출되기 쉽다. 기존의 연기 감지기와 같은 현재의 화재 감지 방법은 화재 발생시 발생하는 화학 센서 기반 기술을 사용함으로써 감지가 상대적으로 늦으며 화재가 확산된 후에 감지가 되는 등 낮은 신뢰성이 문제가 될 수 있다. 이를 보완하기 위해 영상 기반의 화재 감지 기술이 개발되었지만 낮은 정확도가 문제가 되어 실용화되지 못하였다. 최근 인공 지능을 위한 심층 학습 분야의 큰 발전으로 영상 내의 물체 인식률이 높아짐에 따라 관련 연구가 활발히 진행되고 있다. 따라서 본 연구에서는 보안 카메라 영상을 사용하여 화재를 감지할 수 있는 심층 학습 기반의 화재 감지기를 제안한다. 심층 학습 기반의 접근법은 영상에서 자동으로 특징을 학습할 수 있으므로 일반적으로 복잡한 상황에 대해서도 일반화가 가능하다. 본 논문에서는 화재감지 정확도와 속도 측면의 균형을 고려하여 두 개의 심층 합성곱 신경망 모델을 제안하였다. 실험을 통해 두 모델 모두 99%의 평균 정밀도로 화재를 감지할 수 있으며 첫번째 모델은 초당 30장의 처리 속도와 76%의 정확도를 나타냈다. 두번째 모델은 초당 50장의 처리 속도와 61%의 정확도를 나타낸다. 또한 두 개의 모델의 메모리 사용량을 서로 비교하였으며 다양한 실제 화재 시나리오에서 테스트하여 신뢰할 수 있는 모델임을 증명하였다. 본 논문에 제안한 영상 기반 화재 감지기가 상용화된다면 상대적으로 실내 화재에 취약한 시각 장애인들의 안전에 도움이 될 것이다.,"In an event of an emergency, such as fire in a building, visually impaired and blind people are prone to exposed to a level of danger that is greater than that of normal people, for they cannot be aware of it quickly. Current fire detection methods such as smoke detector is very slow and unreliable because it usually uses chemical sensor based technology to detect fire particles. But by using vision sensor instead, fire can be proven to be detected much faster as we show in our experiments. Previous studies have applied various image processing and machine learning techniques to detect fire, but they usually don t work very well because these techniques require hand-crafted features that do not generalize well to various scenarios. But with the help of recent advancement in the field of deep learning, this research can be conducted to help solve this problem by using deep learning-based object detector that can detect fire using images from security camera. Deep learning based approach can learn features automatically so they can usually generalize well to various scenes. In order to ensure maximum capacity, we applied the latest technologies in the field of computer vision such as YOLO detector in order to solve this task. Considering the trade-off between recall vs. complexity, we introduced two convolutional neural networks with slightly different model s complexity to detect fire at different recall rate. Both models can detect fire at 99% average precision, but one model has 76% recall at 30 FPS while another has 61% recall at 50 FPS. We also compare our model memory consumption with each other and show our models robustness by testing on various real-world scenarios."
회전기계류 상태 실시간 진단을 위한 IoT 기반 클라우드 플랫폼 개발,2017,"['Smart Factory(스마트 팩토리)', 'Internet of Things(사물인터넷)', 'Cloud Platform(클라우드 플랫폼)', 'Machine Learning(기계학습)', 'Rotating Machinery(회전기계류)']",스마트 팩토리 시대가 열리면서 발전 플랜트에서 발생하는 빅데이터를 활용한 설비 유지 보수 방법론이 부각되고 있다. 본 연구에서는 데이터 기반 방법론의 효과적인 적용과 발전 플랜트 실시간 성능 모니터링을 위해 사물인터넷 기반 클라우드 플랫폼을 제안한다. Short-term Analysis에서는 사물인터넷 센서를 이용하여 학습된 건전성 인자와 패턴 비교를 통해 설비의 상태 진단과 결과 전송을 목적으로 한다. Long-term Analysis는 취합된 고차원 데이터를 활용하여 설비간 관계 파악과 인과관계 확인을 통한 트렌드 분석을 목적으로 한다. 분석 및 진단 결과는 클라우드 플랫폼의 웹 기반 시스템을 통해 시각화하여 사용자의 접근성을 향상시켜 장소나 접속 기기에 상관없이 데이터를 확인할 수 있도록 한다. 개발된 플랫폼의 성능 검증은 회전기계류 테스트베드로 진행한다.,"The objective of this research is to improve the efficiency of data collection from many machine components on smart factory floors using IoT(Internet of things) techniques and cloud platform, and to make it easy to update outdated diagnostic schemes through online deployment methods from cloud resources. The short-term analysis is implemented by a micro-controller, and it includes machine-learning algorithms for inferring snapshot information of the machine components. For long-term analysis, time-series and high-dimension data are used for root cause analysis by combining a cloud platform and multivariate analysis techniques. The diagnostic results are visualized in a webbased display dashboard for an unconstrained user access. The implementation is demonstrated to identify its performance in data acquisition and analysis for rotating machinery."
"중, 소형시설물 지진피해평가·관리시스템 개발",2021,"['시설물', '지진피해', '지진가속도', '딥러닝', 'Infrastructure', 'Earthquake Damage', 'Ground acceleration', 'Deep Learning']","지진이 발생하면 시설물의 관리자는 구조물의 피해발생 여부를 조사하고 긴급복구를 실시하는 등 대응을 수행할 책임이 있다. 그러나 교량 및 건축물과 같은 대형의 사회기반시설에 대해서 지진발생 후 소수의 관리인원이 제한된 시간 내에 다수구조물의 지진피해를 확인하고 안전성을 평가하는데는 어려움이 있다. 국내에서는 지진재해대응시스템이 개발되어 있으나 확률론적 안전성 평가방법을 적용하고 있어 개별 시설물에 대한 피해 정도를 제공하지는 못하는 실정이다. 이에 본 연구에서는 중, 소형시설물의 지진피해평가·관리시스템을 개발함으로써 지진재해 발생 후 관리자에게 구조물의 피해발생 여부, 긴급점검 등 유지관리활동의 필요유무 정보를 제공하고자 한다.",
적응형뉴로퍼지시스템을 이용한 인코넬718 밀링가공시 표면상태감시,2017,"['Inconel718', 'Surface roughness', 'ANFIS', 'Neural network', 'Milling', 'Neuro fuzzy']",,"Inconel 718 is a typical difficult-to-cut material, has low machinability. The condition of the machined surface is easily deteriorated by rapid tool wear caused by high temperature. Therefore, it is important to monitor the state of the machined surface by considering abnormal phenomena in machining. In this study, surface roughness is predicted using an ANFIS (Adaptive Neuro Fuzzy Inference System). In wet machining, there is a limit to using sensors for signal acquisition. Thus, the cutting force and acceleration signals are obtained using only a dynamometer and acceleration sensor in the cutting process. The cutting condition and acquisition of signals were selected as input variables and the learning data for ANFIS was set according to these parameters. The ANFIS algorithm was optimized by back-propagation learning and the surface roughness value was predicted through this. The results of this study can be used to monitor surface roughness in real-time machining."
Study on Feasibility for Artificial Intelligence (AI) Noise Reduction Algorithm with Various Parameters in Pediatric Abdominal Radio-Magnetic Computed Tomography (CT),2017,"['pediatric abdominal computed tomography (CT)', 'Artificial intelligence (AI)-based machine learning', 'deep learning', 'image processing', 'noise reduction algorithm', 'dose and image quality evaluation']",,"The importance of radiation-based images has been increasing due to their ability to provide rapid diagnosis and facilitate treatment of lesions. Among them, the frequency of examination using computed tomography(CT) has been increasing because of this technique’s fast examination time and high diagnostic power. However, although the criteria for screening have been presented based on many previous studies on the CT exposure dose for adults, the criteria for children remain inadequate. Especially, relaxing the conditions to reduce the exposure dose of CT will lead to generation of noises. To address this problem, many noise removal algorithms have been developed. Among developed algorithms, a particularly strong interest has been focused on deep learning methods, which are a sort of artificial intelligence (AI)-based machine learning. Therefore, the present study aimed to develop a noise removal algorithm using the Gaussian Mixture Model (GMM), an AIbased deep learning method, and to apply the algorithm to pediatric abdominal CT so that to evaluate the usefulness of the approach. PMMA phantoms with different diameters of 12, 16, 20, 24, and 32 cm, which can express pediatric abdomen, were manufactured and used. To evaluate dose and image quality, the tube current was fixed to 200 mAs and the tube voltage was changed from 80 to 120, and 140 kVp; thereafter, the tube voltage was fixed to 120 kVp and the tube currents were changed from 50 to 100, 150, 200, and 250 mAs. According to the results, CTDIw showed a tendency to increase alongside with increases in the tube voltage and the tube currents, while noise decreased proportionally. In addition, the contrast decreased as the tube voltage increased, but was shown to be almost unrelated to the tube currents. Finally, the excellent CNRD result was measured in lowest exposure condition at 80 kVp and 50 mAs. Also, the average of CNRD with AI noise reduction algorithm was 1.6-4.2 times higher than before the application. In conclusion, the doses and characteristics of the pediatric abdominal CT scan according to various image acquisition conditions could be successfully identified and the efficiency of the AI noise removal algorithm developed in the present study was demonstrated."
웨어러블 센서를 이용한 라이프로그 데이터 자동 감정 태깅,2017,"['인공지능', '기계학습', '감성 컴퓨팅', '라이프로그', '웨어러블 센서', '자동 태깅', 'artificial intelligence', 'machine learning', 'affective computing', 'lifelog', 'wearable sensors', 'automated tagging']","본 논문에서는 실생활에서 수집한 웨어러블 센서 데이터에서 사용자의 체험 기반 감정 태그 정보를 자동으로 부여하는 시스템을 제안한다. 사용자 본인의 감정과 사용자가 보고 듣는 정보를 종합적으로 고려하여 네 가지의 감정 태그를 정의한다. 직접 수집한 웨어러블 센서 데이터를 중심으로 기존 감성 컴퓨팅 연구를 통해 알려진 보조 정보를 결합하여, 다중 센서 데이터를 입력으로 하고 감정 태그를 구분하는 머신러닝 기반 분류 시스템을 학습하였다. 다중 모달리티 기반 감정 태깅 시스템의 유용성을 보이기 위해, 기존의 단일 모달리티 기반의 감정 인식 접근법과의 정량적, 정성적 비교를 한다.","In this paper, we propose a system that automatically assigns user""s experience-based emotion tags from wearable sensor data collected in real life. Four types of emotional tags are defined considering the user""s own emotions and the information which the user sees and listens to. Based on the collected wearable sensor data from multiple sensors, we have trained a machine learning-based tagging system that combines the known auxiliary tools from the existing affective computing research and assigns emotional tags. In order to show the usefulness of this multi-modality-based emotion tagging system, quantitative and qualitative comparison with the existing single-modalitybased emotion recognition approach are performed."
불확실성 기반 상태 공간 학습 알고리즘을 이용한 Exploration-Exploitation 딜레마에 관한 연구,2017,"['학습', '불확실성', '메타 인지', 'Exploration-Exploitation 딜레마', '의사결정', 'Learning', 'Uncertainty', 'Metacognition', 'Exploration-Exploitation dilemma', 'Decision making']","본 논문은 인간의 학습 과정에서 발생하는 자신의 학습 정도에 대한 불확실성을 평가하는 메타 인지 능력 기반 학습 과정을 형식화하고, 메타 인지 기반 상태 공간 학습 알고리즘을 제안하였다. 상태 공간 (state-space) 학습과정을 구현한 2단계 마르코프 의사결정 게임 데이터를 사용, 상태 공간 정보에 대한 근접도(Proximity)와 최소오류제곱을 이용하여 불확실성을 도출하고, 이것이 인간의 상태 공간 학습에 미치는 영향을 확인하였다. 또한 현재 가지고 있는 상태 공간에 대한 정보를 바탕으로 기계학습의 본질적 문제인 Exploration-Exploitation 딜레마의 trade-off를 예측하고, 개선 가능성을 보였다.","This paper proposes a formal model and the algorithm for human’s state space leaning process based on metacognition which is seen as the human’s capability to introspect their thought process and report their level of uncertainty. Given the 2-stage Markov decision process game data which augmented humans’ state space learning process, the algorithm performs online updates of low dimensional embedding of state space on the basis of the uncertainty assessment. We found out that the uncertainty does use on the human learning process. Furthermore, by predicting the exploration-exploitation tradeoff using acquired knowledge about the state space, it is expected to improve the exploration and exploitaotni dilemma in machine learning."
딥러닝을 이용한 범용적 스테그아날리시스,2017,"['스테그아날리시스', '스테가노그래피', '딥러닝', '범용적 스테그아날리시스 모델', 'steganalysis', 'steganography', 'deep learning', 'generalized steganalysis model']","스테그아날리시스(Steganalysis)란 이미지 등 일반적인 자료에 암호화된 정보를 은닉하는 스테가노그래피(Steganography)에 대한 검출 및 분석 방법으로, 기계학습 기반 방법론을 포함한다. 기존 기계학습 기반 스테그아날리시스는 영상(Image)의 특징(Feature) 추출 및 모델링에 기반하며, 최근 딥러닝(Deep Learning)의 적용으로 검출 정확도가 큰 폭으로 향상되었다. 하지만 현존하는 스테그아날리시스 모델은 단일 스테가노그래피 기법에 대해 국한되어 있어 학습에 사용되지 않은 스테고(Stego) 이미지의 경우 검출이 불가능한 결정적 한계를 가진다. 본 연구에서는 다양한 스테가노그래피 기법으로 생성된 스테고이미지에 딥러닝을 적용하여 스테그아날리시스를 학습하는 범용적 모델을 제안한다. 다양한 실험을 통해 제안 기법의 효용성 및 가능성을 확인하고, 범용적 스테그아날리시스 모델이 각각에 특화된 검출 기법과 유사한 정확도로 스테고 이미지를 검출할 수 있음을 보인다.","Steganalysis is to detect information hidden by steganography inside general data such as images. There are stegoanalysis techniques that use machine learning (ML). Existing ML approaches to steganalysis are based on extracting features from stego images and modeling them. Recently deep learning-based methodologies have shown significant improvements in detection accuracy. However, all the existing methods, including deep learning-based ones, have a critical limitation in that they can only detect stego images that are created by a specific steganography method. In this paper, we propose a generalized steganalysis method that can model multiple types of stego images using deep learning. Through various experiments, we confirm the effectiveness of our approach and envision directions for future research. In particular, we show that our method can detect each type of steganography with the same level of accuracy as that of a steganalysis method dedicated to that type of steganography, thereby demonstrating the general applicability of our approach to multiple types of stego images."
강인한 포즈 예측을 위한 하이브리드 구조 기반의 온라인 학습 기법,2017,"['Augmented reality', 'Object tracking', 'Keypoint matching', 'Support vector machine', 'Pose estimation']",,
뜰개 이동 예측을 위한 신경망 및 통계 기반 기계학습 기법의 성능 비교,2017,"['유류 유출', '뜰개', '기계학습', '순환신경망', '예측', 'Oil Spill', 'Drifter', 'Machine learning', 'Recurrent neural network', 'LSTM', 'Prediction']","뜰개는 해양에서 해수의 특성 및 흐름을 관측하기 위한 장비로서, 해수의 흐름 관측을 이용해 유출유 확산 예측을 위해 사용될 수 있다. 본 논문에서는 관측기관에서 사용하는 뜰개가 특정 시간 간격으로 관측한 바람 및 해수의 특성과 이동경로를 기계학습 기법들을 이용하여 학습시키고 예측하는 모델을 제안한다. 서포트벡터 회귀, 방사기저함수 네트워크, 가우시안 프로세스, 다층 퍼셉트론, 순환신경망을 이용하여 뜰개의 이동경로 예측 방법을 제시한다. 기존 MOHID 수치모델과 비교하여 각 기법별로 4 개의 사례중 3 개에서 성능이 개선되었으며, 가장 좋은 개선율을 보인 기법은 LSTM으로 평균 47.59% 개선되었다. 추후 연구에서는 배깅과 부스팅을 이용하여 가중치를 부여하여 정확도를 개선할 예정이다.","Drifter is an equipment for observing the characteristics of seawater in the ocean, and it can be used to predict effluent oil diffusion and to observe ocean currents. In this paper, we design models or the prediction of drifter trajectory using machine learning. We propose methods for estimating the trajectory of drifter using support vector regression, radial basis function network, Gaussian process, multilayer perceptron, and recurrent neural network. When the propose mothods were compared with the existing MOHID numerical model, performance was improve on three of the four cases. In particular, LSTM, the best performed method, showed the imporvement by 47.59% Future work will improve the accuracy by weighting using bagging and boosting."
Plurality Rule–based Density and Correlation Coefficient–based Clustering for K-NN,2017,"['Classification', 'Density-based', 'K-NN', 'DPC-KNN-PCA', 'Processing time']",,"k-nearest neighbor (K-NN) is a well-known classification algorithm, being feature space–based on nearest-neighbor training examples in machine learning. However, K-NN, as we know, is a lazy learning method. Therefore, if a K-NN–based system very much depends on a huge amount of history data to achieve an accurate prediction result for a particular task, it gradually faces a processing-time performance-degradation problem. We have noticed that many researchers usually contemplate only classification accuracy. But estimation speed also plays an essential role in realtime prediction systems. To compensate for this weakness, this paper proposes correlation coefficient–based clustering (CCC) aimed at upgrading the performance of K-NN by leveraging processing-time speed and plurality rule–based density (PRD) to improve estimation accuracy. For experiments, we used real datasets (on breast cancer, breast tissue, heart, and the iris) from the University of California, Irvine (UCI) machine learning repository. Moreover, real traffic data collected from Ojana Junction, Route 58, Okinawa, Japan, was also utilized to lay bare the efficiency of this method. By using these datasets, we proved better processing-time performance with the new approach by comparing it with classical K-NN. Besides, via experiments on realworld datasets, we compared the prediction accuracy of our approach with density peaks clustering based on K-NN and principal component analysis (DPC-KNN-PCA)."
Structural failure classification for reinforced concrete buildings using trained neural network based multi-objective genetic algorithm,2017,"['genetic algorithm', 'classification', 'neural network', 'reinforced concrete']",,"Structural design has an imperative role in deciding the failure possibility of a Reinforced Concrete (RC) structure. Recent research works achieved the goal of predicting the structural failure of the RC structure with the assistance of machine learning techniques. Previously, the Artificial Neural Network (ANN) has been trained supported by Particle Swarm Optimization (PSO) to classify RC structures with reasonable accuracy. Though, keeping in mind the sensitivity in predicting the structural failure, more accurate models are still absent in the context of Machine Learning. Since the efficiency of multiobjective optimization over single objective optimization techniques is well established. Thus, the motivation of the current work is to employ a Multi-objective Genetic Algorithm (MOGA) to train the Neural Network (NN) based model. In the present work, the NN has been trained with MOGA to minimize the Root Mean Squared Error (RMSE) and Maximum Error (ME) toward optimizing the weight vector of the NN. The model has been tested by using a dataset consisting of 150 RC structure buildings. The proposed NN-MOGA based model has been compared with Multi-layer perceptron-feed-forward network (MLPFFN) and NN-PSO based models in terms of several performance metrics. Experimental results suggested that the NN-MOGA has outperformed other existing well known classifiers with a reasonable improvement over them. Meanwhile, the proposed NN-MOGA achieved the superior accuracy of 93.33% and F-measure of 94.44%, which is superior to the other classifiers in the present study."
Structural failure classification for reinforced concrete buildings using trained neural network based multi-objective genetic algorithm,2017,"['genetic algorithm', 'classification', 'neural network', 'reinforced concrete']",,"Structural design has an imperative role in deciding the failure possibility of a Reinforced Concrete (RC) structure. Recent research works achieved the goal of predicting the structural failure of the RC structure with the assistance of machine learning techniques. Previously, the Artificial Neural Network (ANN) has been trained supported by Particle Swarm Optimization (PSO) to classify RC structures with reasonable accuracy. Though, keeping in mind the sensitivity in predicting the structural failure, more accurate models are still absent in the context of Machine Learning. Since the efficiency of multi-objective optimization over single objective optimization techniques is well established. Thus, the motivation of the current work is to employ a Multi-objective Genetic Algorithm (MOGA) to train the Neural Network (NN) based model. In the present work, the NN has been trained with MOGA to minimize the Root Mean Squared Error (RMSE) and Maximum Error (ME) toward optimizing the weight vector of the NN. The model has been tested by using a dataset consisting of 150 RC structure buildings. The proposed NN-MOGA based model has been compared with Multi-layer perceptron-feed-forward network (MLP-FFN) and NN-PSO based models in terms of several performance metrics. Experimental results suggested that the NN-MOGA has outperformed other existing well known classifiers with a reasonable improvement over them. Meanwhile, the proposed NN-MOGA achieved the superior accuracy of 93.33% and F-measure of 94.44%, which is superior to the other classifiers in the present study."
Plant Leaf Recognition Using a Convolution Neural Network,2017,"['Leaf', 'Classification', 'Visual system', 'CNN', 'GoogleNet']",,"There are hundreds of kinds of trees in the natural ecosystem, and it can be very difficult to distinguish between them. Botanists and those who study plants however, are able to identify the type of tree at a glance by using the characteristics of the leaf. Machine learning is used to automatically classify leaf types. Studied extensively in 2012, this is a rapidly growing field based on deep learning. Deep learning is itself a self-learning technique used on large amounts of data, and recent developments in hardware and big data have made this technique more practical. We propose a method to classify leaves using the CNN model, which is often used when applying deep learning to image processing"
Plant Leaf Recognition Using a Convolution Neural Network,2017,"['Leaf', 'Classification', 'Visual system', 'CNN', 'GoogleNet']",,"There are hundreds of kinds of trees in the natural ecosystem, and it can be very difficult to distinguish between them. Botanists and those who study plants however, are able to identify the type of tree at a glance by using the characteristics of the leaf. Machine learning is used to automatically classify leaf types. Studied extensively in 2012, this is a rapidly growing field based on deep learning. Deep learning is itself a self-learning technique used on large amounts of data, and recent developments in hardware and big data have made this technique more practical. We propose a method to classify leaves using the CNN model, which is often used when applying deep learning to image processing."
Industry 4.0 in Germany and the EU,2017,"['Non-personal Data', 'Data Ownership', 'Property', 'Intellectual Property', 'Protection of Databases', 'Trade Secrets', 'Data as Infrastructure', 'Economics of Data']",,"In its core, Industry 4.0 refers to the change of production processes under conditions of adaptive intelligent production systems. Instead of being governed by a centrally controlled and in advance optimized process of production, the change aims at a continuous self-optimization of the process, which seems to be possible only through continuous generation and processing of information and its governance by artificial intelligence, in particular machine learning technologies.  The following presentation will focus on the emerging data economy. However, the debate on data and its adequate legal framework was dominated for a long time by the data protection issue related to personal data and constitutional questions of self-determination in times of ubiquitous data generation in a connected world. Industry 4.0 shifts the attention to machine generated, non-personal data, its role in the innovation process and an adequate regulatory framework between rights of exclusion and rights of access. This turns out to be an important political question in the EU and Germany and leads to the discussion of various concepts and instruments to ensure the free flow of data on the one side and the need for protection of machine-generated data on the other side.  Before I display the current framework and its applicability to data and data sets, I will outline some characteristics of data, because the concept of data is not well defined. Data are often understood as representing the real world or attributes or characteristics thereof and they are taken on its face value, treated as being neutral, objective, pre-analytic in nature and as conveying the information. This might be called a container approach. However, data are in fact framed technically, economically, ethically, temporally and so on. I follow the hypothesis, that data do not exist independently of the context they are generated and interpreted within. Therefore, it is more about relations between different data and data sets instead of following a container approach. This has a lot of consequences with regard to the question of “data ownership”, which is a hot topic of the current discussion. I will display in the following, that neither the law of property or intellectual property covers currently non-personal data as a subject of protection. In fact, the governance framework is mainly a contractual one, often accompanied by factual arrangement, which obviously are sufficient for most of the business actors. This is compatible with economic analysis of the problem. It might be a more productive approach to think about data as an infrastructure of the data driven economy which would bring rights to access data pools, standards of data, interoperability etc. to the fore."
RNN(Recurrent Neural Network)을 이용한 기업부도예측모형에서 회계정보의 동적 변화 연구,2017,"['순환 신경망', '부도 예측', '시계열 모형', 'Recurrent Neural Network', 'Bankruptcy Prediction', 'Time-Series model']",,"Corporate bankruptcy can cause great losses not only to stakeholders but also to many related sectors in society. Through the economic crises, bankruptcy have increased and bankruptcy prediction models have become more and more important. Therefore, corporate bankruptcy has been regarded as one of the major topics of research in business management. Also, many studies in the industry are in progress and important.  Previous studies attempted to utilize various methodologies to improve the bankruptcy prediction accuracy and to resolve the overfitting problem, such as Multivariate Discriminant Analysis (MDA), Generalized Linear Model (GLM). These methods are based on statistics. Recently, researchers have used machine learning methodologies such as Support Vector Machine (SVM), Artificial Neural Network (ANN). Furthermore, fuzzy theory and genetic algorithms were used. Because of this change, many of bankruptcy models are developed. Also, performance has been improved.  In general, the company’s financial and accounting information will change over time. Likewise, the market situation also changes, so there are many difficulties in predicting bankruptcy only with information at a certain point in time. However, even though traditional research has problems that don’t take into account the time effect, dynamic model has not been studied much. When we ignore the time effect, we get the biased results. So the static model may not be suitable for predicting bankruptcy. Thus, using the dynamic model, there is a possibility that bankruptcy prediction model is improved.  In this paper, we propose RNN (Recurrent Neural Network) which is one of the deep learning methodologies. The RNN learns time series data and the performance is known to be good. Prior to experiment, we selected non-financial firms listed on the KOSPI, KOSDAQ and KONEX markets from 2010 to 2016 for the estimation of the bankruptcy prediction model and the comparison of forecasting performance. In order to prevent a mistake of predicting bankruptcy by using the financial information already reflected in the deterioration of the financial condition of the company, the financial information was collected with a lag of two years, and the default period was defined from January to December of the year. Then we defined the bankruptcy. The bankruptcy we defined is the abolition of the listing due to sluggish earnings. We confirmed abolition of the list at KIND that is corporate stock information website. Then we selected variables at previous papers. The first set of variables are Z-score variables. These variables have become traditional variables in predicting bankruptcy. The second set of variables are dynamic variable set. Finally we selected 240 normal companies and 226 bankrupt companies at the first variable set. Likewise, we selected 229 normal companies and 226 bankrupt companies at the second variable set.  We created a model that reflects dynamic changes in time-series financial data and by comparing the suggested model with the analysis of existing bankruptcy predictive models, we found that the suggested model could help to improve the accuracy of bankruptcy predictions. We used financial data in KIS Value (Financial database) and selected Multivariate Discriminant Analysis (MDA), Generalized Linear Model called logistic regression (GLM), Support Vector Machine (SVM), Artificial Neural Network (ANN) model as benchmark.   The result of the experiment proved that RNN’s performance was better than comparative model. The accuracy of RNN was high in both sets of variables and the Area Under the Curve (AUC) value was also high. Also when we saw the hit-ratio table, the ratio of RNNs that predicted a poor company to be bankrupt was higher than that of other comparative models. However the limitation of this paper is that an overfitting problem occurs during RNN learning. But we expect to be able to solve the overfitting problem by selecting more lear"
Intention Classification for Retrieval of Health Questions,2017,"['Health Questions', 'Intention Recognition', 'Text Classification', 'Learning-Based Classifiers', 'Location-based Feature Weighting', 'Area-based Feature Weighting']",,"Healthcare professionals have edited many health questions (HQs) and their answers for healthcare consumers on the Internet. The HQs provide both readable and reliable health information, and hence retrieval of those HQs that are relevant to a given question is essential for health education and promotion through the Internet. However, retrieval of relevant HQs needs to be based on the recognition of the intention of each HQ, which is difficult to be done by predefining syntactic and semantic rules. We thus model the intention recognition problem as a text classification problem, and develop two techniques to improve a learning-based text classifier for the problem. The two techniques improve the classifier by location-based and area-based feature weightings, respectively. Experimental results show that, the two techniques can work together to significantly improve a Support Vector Machine classifier in both the recognition of HQ intentions and the retrieval of relevant HQs."
MSERs와 CNN 기반의 실시간 교통표지판 인식,2017,"['Traffic Signs Recognition', 'Dataset bias', 'Convolutional Neural Networks', 'Transfer learning']",,"This paper proposes a traffic sign recognition algorithm that is robust in various environments. Color information is an important element in the traffic sign recognition system, as the performance depends on variations in weather conditions, illumination, and type of cameras used. Besides the above factors, traffic signs also differ across countries. To overcome these problems, our approach involves traffic sign detection, classification, and tracking. In the detection module, color enhancement with maximally stable extremal regions is performed to improve the extracting candidate regions of traffic signs. Support vector machine classifiers with distance to border and histogram of oriented gradient feature vectors are used to detect the traffic signs. Detected traffic signs are thereby classified using convolutional neural networks with fine-tuning. Additionally, Kalman filter-based multi-target tracking not only verifies traffic sign detection but also optimizes the detection of regions of interest. The result of traffic sign detection is 95.67% when trained on the Belgium Traffic Signs Dataset for Detection (BTSD) training dataset and tested on the Germany Traffic Signs Detection Benchmark test dataset. Moreover, while using the BTSD training dataset, the area under the curve of our method is 89.56%. In classification, the performance of INHA Traffic Signs Classification is increased to 97.48% by adding transfer learning."
생의학 분야 학술 논문에서의 개체명 인식 및 관계 추출을 위한 언어 자원 수집 및 통합적 구조화 방안 연구,2017,"['정보 추출', '개체명 인식', '관계 추출', '바이오 텍스트 마이닝', '학습 집합', 'Information Extraction', 'Named-Entity Recognition', 'Relation Extraction', 'Bio-text Mining', 'Training Set']","본 논문에서는 급격히 증가하는 생의학 분야 비정형 텍스트에서 핵심적 내용을 추출할 수 있는 기계학습 기반 정보 추출 시스템을 구축하기 위한 언어자원 수집 및 통합적 구조화 방안을 제안한다. 제안된 방법은 정보 추출 시스템을 크게 개체명 인식과 개체명 간 관계 추출 시스템으로 구분하고, 각각의 시스템에 적합한 학습데이터를 구성하기 위해 생의학 분야 개체명 사전과 학습 집합을 수집한다. 그리고 수집된 해당 자원들의 특성을 분석하여 개체 구별을 위해 필수적으로 포함시켜야 할 항목들을 도출하고 이를 통해 시스템 학습과정에서 사용될 학습 데이터를 구성하기 위한 항목을 선정한다. 이와 같이 선정된 학습데이터의 구성 내용에 따라 수집된 자원들을 가공하여 학습 데이터를 구축한다. 본 연구에서는 생의학 분야의 하위 분야인 유전자, 단백질, 질병, 약물 4개 분야에 대한 개체명 사전과 학습 집합을 수집하여 각각을 학습 데이터로 구축하였으며, 개체명 사전을 통해 구축된 개체명 인식용 학습 데이터를 대상으로 개체명 수용 범위를 측정하기 위한 검증 과정을 수행하였다.","This paper introduces an integrated model for systematically constructing a linguistic resource database that can be used by machine learning-based biomedical information extraction systems. The proposed method suggests an orderly process of collecting and constructing dictionaries and training sets for both named-entity recognition and relation extraction. Multiple heterogeneous structures for the resources which are collected from diverse sources are analyzed to derive essential items and fields for constructing the integrated database. All the collected resources are converted and refined to build an integrated linguistic resource storage. In this paper, we constructed entity dictionaries of gene, protein, disease and drug, which are considered core linguistic elements or core named entities in the biomedical domains and conducted verification tests to measure their acceptability."
K Nearest Neighbor Joins for Big Data Processing based on Spark,2017,['K-'],,"K Nearest Neighbor Join (KNN Join) is a simple yet effective method in machine learning. It is widely used in small dataset of the past time. As the number of data increases, it is infeasible to run this model on an actual application by a single machine due to memory and time restrictions. Nowadays a popular batch process model called MapReduce which can run on a cluster with a large number of computers is widely used for large-scale data processing. Hadoop is a framework to implement MapReduce, but its performance can be further improved by a new framework named Spark. In the present study, we will provide a KNN Join implement based on Spark. With the advantage of its in-memory calculation capability, it will be faster and more effective than Hadoop. In our experiments, we study the influence of different factors on running time and demonstrate robustness and efficiency of our approach."
세드릭 프라이스의 건축에 나타나는 사이버네틱스의 영향 -‘펀 팰리스’ 프로젝트를 중심으로-,2017,"['세드릭 프라이스', '펀 팰리스', '사이버네틱스', '1960년대', '프로그램 비결정성', '상호반응기계', 'Cedric Price', 'Fun Palace', 'Cybernetics', '1960s', 'Programmatic indeterminacy', 'Interactive machine']",,"The 1960s in Britain was the period of rapid economic and social change. Under this circumstance, the visionary architect Cedric Price designed the Fun Palace, of which idea came from the theatre producer, Joan Littlewood. They hoped this place to be an improvisational learning space, so Price proposed the building as ‘kit of parts’ which can respond to programmatic indeterminacy. Cybernetics was introduced to control this flexibility dramatically changed the character of the project from ‘theatre of people’ to ‘interactive machine’. That resulted in the change of the status of user from subjective human beings to abstract data in the cybernetic algorithm as well, and led the project to a completely opposite direction from that Price intended. After Fun Palace, cybernetics technology could still be found in his other projects, and it can be assumed that this was because the algorithmic system of cybernetics were on the same line of thought of Price’s idea ― anti-building or ‘kit of parts’. The effects of cybernetics varied in projects; Similar negative effect in Fun Palace can be found in Generator project, but on the other hand, in Potteries Thinkbelt project, cybernetics showed a positive aspect by contribution to the development of project on the formal analogy of algorithmic network."
세드릭 프라이스의 건축에 나타나는 사이버네틱스의 영향 -'펀 팰리스' 프로젝트를 중심으로-,2017,['1960'],,"The 1960s in Britain was the period of rapid economic and social change. Under this circumstance, the visionary architect Cedric Price designed the Fun Palace, of which idea came from the theatre producer, Joan Littlewood. They hoped this place to be an improvisational learning space, so Price proposed the building as 'kit of parts' which can respond to programmatic indeterminacy. Cybernetics was introduced to control this flexibility dramatically changed the character of the project from 'theatre of people' to 'interactive machine'. That resulted in the change of the status of user from subjective human beings to abstract data in the cybernetic algorithm as well, and led the project to a completely opposite direction from that Price intended. After Fun Palace, cybernetics technology could still be found in his other projects, and it can be assumed that this was because the algorithmic system of cybernetics were on the same line of thought of Price's idea - anti-building or 'kit of parts'. The effects of cybernetics varied in projects; Similar negative effect in Fun Palace can be found in Generator project, but on the other hand, in Potteries Thinkbelt project, cybernetics showed a positive aspect by contribution to the development of project on the formal analogy of algorithmic network."
입력변수 및 학습사례 선정을 동시에 최적화하는 GA-MSVM 기반 주가지수 추세 예측 모형에 관한 연구,2017,"['다분류 SVM', '유전자 알고리즘', '입력변수 선택', '학습사례 선택', '주가지수 추세 예측', 'Multiclass SVM', 'Genetic Algorithm', 'Feature Selection', 'Instance Selection', 'Stock Market Index Trend Prediction']",,"There have been many studies on accurate stock market forecasting in academia for a long time, and now there are also various forecasting models using various techniques. Recently, many attempts have been made to predict the stock index using various machine learning methods including Deep Learning. Although the fundamental analysis and the technical analysis method are used for the analysis of the traditional stock investment transaction, the technical analysis method is more useful for the application of the short-term transaction prediction or statistical and mathematical techniques. Most of the studies that have been conducted using these technical indicators have studied the model of predicting stock prices by binary classification - rising or falling - of stock market fluctuations in the future market (usually next trading day). However, it is also true that this binary classification has many unfavorable aspects in predicting trends, identifying trading signals, or signaling portfolio rebalancing.  In this study, we try to predict the stock index by expanding the stock index trend (upward trend, boxed, downward trend) to the multiple classification system in the existing binary index method. In order to solve this multi-classification problem, a technique such as Multinomial Logistic Regression Analysis (MLOGIT), Multiple Discriminant Analysis (MDA) or Artificial Neural Networks (ANN) we propose an optimization model using Genetic Algorithm as a wrapper for improving the performance of this model using Multi-classification Support Vector Machines (MSVM), which has proved to be superior in prediction performance. In particular, the proposed model named GA-MSVM is designed to maximize model performance by optimizing not only the kernel function parameters of MSVM, but also the optimal selection of input variables (feature selection) as well as instance selection. In order to verify the performance of the proposed model, we applied the proposed method to the real data. The results show that the proposed method is more effective than the conventional multivariate SVM, which has been known to show the best prediction performance up to now, as well as existing artificial intelligence / data mining techniques such as MDA, MLOGIT, CBR, and it is confirmed that the prediction performance is better than this. Especially, it has been confirmed that the ‘instance selection’ plays a very important role in predicting the stock index trend, and it is confirmed that the improvement effect of the model is more important than other factors.  To verify the usefulness of GA-MSVM, we applied it to Korea’s real KOSPI200 stock index trend forecast. Our research is primarily aimed at predicting trend segments to capture signal acquisition or short-term trend transition points. The experimental data set includes technical indicators such as the price and volatility index (2004 ~ 2017) and macroeconomic data (interest rate, exchange rate, S&P 500, etc.) of KOSPI200 stock index in Korea. Using a variety of statistical methods including one-way ANOVA and stepwise MDA, 15 indicators were selected as candidate independent variables. The dependent variable, trend classification, was classified into three states: 1 (upward trend), 0 (boxed), and -1 (downward trend). 70% of the total data for each class was used for training and the remaining 30% was used for verifying. To verify the performance of the proposed model, several comparative model experiments such as MDA, MLOGIT, CBR, ANN and MSVM were conducted. MSVM has adopted the One-Against-One (OAO) approach, which is known as the most accurate approach among the various MSVM approaches. Although there are some limitations, the final experimental results demonstrate that the proposed model, GA-MSVM, performs at a significantly higher level than all comparative models."
Private attribute inference from Facebook’s public text metadata: a case study of Korean users,2017,,,"<P>Originality/value - This paper investigates whether private attributes of SNS users can be inferred with a few pieces of publicly available information although users are not willing to disclose them. The experimental results showed that gender, age, marital status, and relationship status, can be inferred by machine-learning algorithms. Based on these results, an early warning system was designed to help both service providers and users to protect the users' privacy.</P>"
시계열 모형을 이용한 일일 전력 최대수요 예측,2017,"['전이함수 모형', '개입분석', '일일 전력 최대수요', '불쾌지수', '체감온도.', 'Transfer function model', 'Intervention analysis', 'Electrical load', 'Discomfort index', 'Sensory temperature.']","현대 사회에서 삶을 영위하기 위하여 필수적인 요소인 전기는 많은 양을 저장할 수 없는 특성 때문에 정확한 전력수요를 바탕으로 적정량을 생산하는 것이 매우 중요하다. 원활한 전기 공급을 위하여 전력의 최대수요 예측에 대한 연구가 국내외에서 진행되고 있고, 그 중 일일 전력 최대수요 예측은 공급 전력 부족으로 인한 정전이 발생하지 않기 위하여 그 중요도가 매우 크다. 본 연구에서는 일일 전력 최대수요 자료가 시간에 따라 관측되는 시계열 자료임을 고려하여 전이함수모형(transfer function model)과 개입분석(intervention analysis)을 이용하여 일일 전력 최대수요 예측을 연구하였다. 연구 결과로 불쾌지수와 체감온도를 입력 시계열로 활용하고, 계절 및 휴일과 휴일 사이 평일인 샌드위치 데이의 효과를 개입효과로 활용한 ARIMA 모형을 이용한 일일 전력 최대수요 예측 모형을 제안하였다. 제안한 모형은 기존 모형들에 비하여 일상생활에서 사용하는 지표인 불쾌지수와 체감온도를 활용하여 결과에 대한 해석이 쉽고, 예측 오차가 낮아 효율적이다. 제안한 모형을 통해 정확한 일일 전력 최대수요 예측으로 전력 발전의 효율성을 높이고, 원활한 전력 공급에 기여할 것으로 기대한다.","Producing and supplying electricity based by precise electrical load forecasting is very important as large amount of electricity cannot be stored. Therefore there are many researches and forecasting models such as regression, exponential smoothing method, fuzzy regression, multilayer perception and extreme learning machine. However, some of the models do not incorporate the autocorrelation structure which is in time series such as electrical load. Therefore, we study transfer function model and intervention model with discomfort index, sensory temperature index as input time series and seasonal effect, sandwich day (the day is between two holidays) effect as intervention. In this study, we demonstrate the effectiveness of proposed model through comparing other methods in terms of predictive error. This model allows us to forecast more accurately and to interpret predictive value easily because discomfort index, sensory temperature index are used in real life. This model might be quite useful to save power cost and to supply electricity smoothly"
인공지능 로봇과 인간의 관계에 대한 윤리적 성찰과 전망,2017,"['인공지능 로봇', '유사 공감', '조건적 자율성', '자기부정', '생명의 관계망', 'AI robots', 'quasi-empathy', 'conditioned autonomy', 'self-denial', 'the value network of life']",,"This paper aims to explore relationship between AI robots and human beings and to reflect on it ethically. Nowadays, the conception of human life have been developed in accordance with the advance of technology, robotics, information based on networks and big data, etc. At the moment, AI robots can learn knowledge, recognize human users, and communicate with them by conditioned program and algorithm. AI robots, that is, is seen as an quasi-ethical being, not a just machine. An aspect of relationship between AI robots and human beings, for example, of communication and exchanging emotions, is like a emotional process of empathy among human agents. In that AI robots are the products of imitation on human beings, a feature of communication is based on quasi-empathy. The main task to ethical life in future, therefore, is to utilize AI robots as a tool that has the only target on realizing common goods. In one of the main concerns about AI robots, it is expected to have the strongest level of autonomy and intelligence through machine learning. This is potential fear like SF movies that robots destroy humans, even though their activities are conditioned by programme and algorithm. In the end, AI robots are in the control of the principle of ‘self-denial’ for humans in the value network of life, operated conditioned autonomy."
Restricting Answer Candidates Based on Taxonomic Relatedness of Integrated Lexical Knowledge Base in Question Answering,2017,"['Question Answering', 'Answer Type', 'Type Coercion', 'Taxonomy', 'Taxonomic Relatedness.']",,"This paper proposes an approach using taxonomic relatedness for answer-type recognition and type coercion in a question-answering system. We introduce a question analysis method for a lexical answer type (LAT) and semantic answer type (SAT) and describe the construction of a taxonomy linking them. We also analyze the effectiveness of type coercion based on the taxonomic relatedness of both ATs. Compared with the rule-based approach of IBM’s Watson, our LAT detector, which combines rule-based and machine-learning approaches, achieves an 11.04% recall improvement without a sharp decline in precision. Our SAT classifier with a relatedness-based validation method achieves a precision of 73.55%. For type coercion using the taxonomic relatedness between both ATs and answer candidates, we construct an answer-type taxonomy that has a semantic relationship between the two ATs. In this paper, we introduce how to link heterogeneous lexical knowledge bases. We propose three strategies for type coercion based on the relatedness between the two ATs and answer candidates in this taxonomy. Finally, we demonstrate that this combination of individual type coercion creates a synergistic effect."
자동외관검사를 위한 확률기반 불량 확인 알고리즘 개발,2017,"['Visual Inspection', 'Verification Inspection', 'Bayes Inference', 'Naive Bayes Algorithm']",,"The visual inspection of electronic parts consists of two steps: automatic visual inspection and verification inspection. In the stage of a verification inspection, the human inspector sequentially inspects all the areas which detected in the automatic inspection. In this study, we propose an algorithm to determine the order of verification inspection by Bayes inference well known in the field of machine learning. This is a method of prioritizing a region estimated to have a high probability of defect using experience data of past inspection. This algorithm was applied to the visual inspection of ultraviolet filters to verify its effectiveness. As a result of the comparison experiment, it was confirmed that the verification inspection can be completed 30% of the conventional method by adapting proposed algorithm."
인공지능기반 창호환기시스템 연구 동향 분석,2017,"['Artificial Intelligence', 'Internet of Things', 'Window Ventilation System', 'Research Trends', 'Market condition', '인공지능', '사물인터넷', '창호환기시스템', '연구동향', '시장현황']",,"Purpose: According to the 4th industrial revolution, interest in artificial intelligence is increasing in the field of architecture. However, there are few studies that applied artificial intelligence in the field of architecture.Therefore, this study compares and analyzes the artificial intelligence researches in domestic and overseas architectural and window areas in depth and grasps the technology applicable to window ventilation systems based on artificial intelligence. Method: A total of 456 papers were searched by using domestic and foreign scholarly search engines with kewords;“Artificial Intelligence”, “Artificial Neural Network”,“Machine Learning”, “Support Vector Machine”, “Genetic Algorithm”, “Building”, “Architecture”, “Window Ventilation System”, “Smart Window”, “Smart Ventilation”. Result: Research using artificial intelligence in the field of architecture has been steadily increasing. Among them, there are 266 studies(58.3%) in the field of building environmental facilities. In addition, 312 cases of window system research were investigated, and 115 cases of ventilation related research were 36.9%. The results of this study will be used as basic data for the development of window ventilation system based on artificial intelligence."
관광 패러다임의 변화에 따른 창의융합인재의 알파고 리더십 개발방안,2017,"['Artificial intelligence', 'Paradigm of tourism', 'Creative convergence talents', 'AlphaGo leadership', 'AlphaGo age', 'Start-up tourist destination', 'Fourth industrial revolution']",,"It is an age when AI(artificial intelligence) changes the paradigm of tourism. AlphaGo leadership of creative convergence talents is needed for the age. We have to show true leadership that leads artificial intelligence. The reason for making artificial intelligence is because it is in the basic desire of a survival instinct to live without doing things that you do not want to do, instead of doing things you want to do. A certain number of humans who hate humans should be more alert than mechanical intelligence. Because machines also learn. Learning machine intelligence, which is not based on trust, can lead to an era of disaster caused by machines. Therefore, the only way to turn disaster into a blessing is to make our society and leaders trust, be transparent and honest. We also need to show mutual cooperation to each other for future generations. Therefore, leaders of the AlphaGo Age should have true leadership that leads to artificial intelligence. This study presents the AlphaGo Leadership in the era of the Fourth Industrial Revolution due to the change of tourism paradigm as follows. Innovative AlphaGo leadership that surpasses traditional leadership, AlphaGo leadership that transforms into a start-up tourist destination, and the use of AlphaGo leadership to nurture productive new technologies."
SW 보안 취약점 자동 탐색 및 대응 기술 분석,2017,"['Automatic-Analysis', 'Concolic-Execution', 'Fuzzing', 'Patch-Generation', 'Security-Vulnerability', 'Symbolic-Execution']","자동으로 해킹을 수행하는 도구 및 기법의 발전으로 인해 최근 신규 보안 취약점들이 증가하고 있다. 대표적인 취약점 DB인 CVE를 기준으로 2010년부터 2015년까지 신규 취약점이 약 8만건이 등록되었고, 최근에도 점차 증가하는 추세이다. 그러나 이에 대응하는 방법은 많은 시간이 소요되는 전문가의 수동 분석에 의존하고 있다. 수동 분석의 경우 취약점을 발견하고, 패치를 생성하기까지 약 9개월의 시간이 소요된다. 제로데이와 같은 빠른 대응이 필요한 취약점에 대한 위험성이 더 부각되는 이유이다. 이와 같은 문제로 인해 최근 자동화된 SW보안 취약점 탐색 및 대응 기술에 대한 관심이 증가하고 있다. 2016년에는 바이너리를 대상으로 사람의 개입을 최소화하여 자동화된 취약점 분석 및 패치를 수행하는 최초의 대회인 CGC가 개최 되었다. 이 외에도 세계적으로 Darktrace, Cylance 등의 프로젝트를 통해 인공지능과 머신러닝을 활용하여 자동화된 대응 기술들을 발표하고 있다. 그러나 이러한 흐름과는 달리 국내에서는 자동화에 대한 기술 연구가 미비한 상황이다. 이에 본 논문에서는 자동화된 SW 보안 취약점 탐색 및 대응 기술을 개발하기 위한 선행 연구로서 취약점 탐색과 대응 기술에 대한 선행 연구 및 관련 도구들을 분석하고, 각 기술들을 비교하여 자동화에 용이한 기술 선정과 자동화를 위해 보완해야 할 요소를 제안한다.","As automatic hacking tools and techniques have been improved, the number of new vulnerabilities has increased. The CVE registered from 2010 to 2015 numbered about 80,000, and it is expected that more vulnerabilities will be reported. In most cases, patching a vulnerability depends on the developers"" capability, and most patching techniques are based on manual analysis, which requires nine months, on average. The techniques are composed of finding the vulnerability, conducting the analysis based on the source code, and writing new code for the patch. Zero-day is critical because the time gap between the first discovery and taking action is too long, as mentioned. To solve the problem, techniques for automatically detecting and analyzing software (SW) vulnerabilities have been proposed recently. Cyber Grand Challenge (CGC) held in 2016 was the first competition to create automatic defensive systems capable of reasoning over flaws in binary and formulating patches without experts"" direct analysis. Darktrace and Cylance are similar projects for managing SW automatically with artificial intelligence and machine learning. Though many foreign commercial institutions and academies run their projects for automatic binary analysis, the domestic level of technology is much lower. This paper is to study developing automatic detection of SW vulnerabilities and defenses against them. We analyzed and compared relative works and tools as additional elements, and optimal techniques for automatic analysis are suggested."
E-MICE: Energy-Efficient Concurrent Exploitation of Multiple Wi-Fi Radios,2017,,,"<P>The concurrent use of multiple Wi-Fi radios in individual frequency channels is a solution readily available today to the increase of a mobile station's communication capacity, but at the expense of occasional performance deterioration (when the heterogeneity of capacity between interfaces gets severe) and additional power consumption. This paper proposes a mobile-side solution for the concurrent use of multiple radios in a performance-aware and energy-efficient manner, with which a mobile station activates and deactivates radio interfaces dynamically according to traffic demands and a predicted capacity gain. To this end, the proposed solution is composed of multiple prediction algorithms and a control algorithm. Prediction when activating an additional radio interface is relatively difficult since no information of the disabled interface's current status (and the corresponding frequency channel's) is available at the time of prediction. Our experiments show that, despite different types and used channels, different radio interfaces have a strong correlation of received signal strengths and used PHY rates between them. Based on this observation, the proposed solution learns a correlation pattern between interfaces whenever multiple interfaces are active and makes prediction of the coverage, expected PHY rate and capacity impact of an inactive interface based on the learned correlation with a currently active interface. The design of the prediction algorithms are based on a simple or machine-learning technique (SVM). The control algorithm then keeps monitoring the utilization of active interfaces and, if any of them has utilization over a threshold, checks if each inactive interface is within coverage and a valid rate range based on an active interface's received signal strength. Finally, an action of a configuration change (either activation, deactivation, or no change) selected based on the prediction of the resulting capacity is applied. Testbed experiments using COTS dual-band Wi-Fi interfaces demonstrate that the solution can enhance throughput by up to 29.6 percent (in a close distance to AP) and at most halve power consumption compared to legacy aggregation while the gain varies depending on the location and traffic conditions.</P>"
로보어드바이저 거래와 금융소비자 보호 방안,2017,"['금융소비자보호', '로보어드바이저', '인공지능', '투자자산 관리서비스', 'Financial Consumer Protection', 'Robo-Advisor', 'Investment Asset Management Service', 'Artificial Intelligence']","본 연구에서는 맞춤형 투자자산 관리서비스인 로보어드바이저의 상용화에 따른 적합성 원칙의 적용규제를 통한 금융소비자보호의 합리적인 규제방안을 제시하고자 한다. 인공지능에 기반을 둔 로보어드바이저는 신기술 도입에 따른 서비스의 편리성과 경제적 효용성 등의 장점을 갖고 있으나, 고도의 전문적인 기술수준이 요구되고 있을 뿐만 아니라 금융산업 전반에 걸친 다양한 응용과 융합된 상품 형태로 서비스 제공이 가능함에 따라 새로운 패러다임에 의한 규제 역량이 필요한 상황이다. 신기술 도입초기에는 규제공백으로 인한 금융서비스 제공의 편익비용이 금융소비자에게 전가되는 경향은 사회적 불신으로 이어질 수 있다. 또한 신기술에 대한 관련 규제가 모색되는 동안에도 기술성장에 따른 상용화가 가속화되고 있는 실정을 감안한다면 금융소비자에 대한 적절한 보호방안은 반드시 선행되어야 한다. 따라서 본 연구는 인공지능에 의해 구현되는 로보어드바이저에 대한 법적지위를 검토하고, 알고리즘 오류 및 결함 등으로 인한 책임소재를 규명하며, 적절한 책임 분배를 위한 명시적 규제 방안을 검토하고자 한다. 특히 로보어드바이저의 투자자문ㆍ일임업에 대한 적합성원칙과 설명의무의 적용에 관한 문제점을 고찰하고, 금융소비자를 보호하기 위한 법적 개선방안을 제시하고자 한다.","Robo-Advisor is an asset management service that is implemented by machine learning. It requires a lot of cost and high technology for commercialization. The public commercialization of such a robot advisor requires cooperation among governmental policy efforts, private participation agencies and research institutes, and it is obvious that quality of asset management service should be excellent in terms of public utilization value.Robo-Advisor should not pursue economic efficiency and institutional convenience in the initial process of introducing new technology. Robo-Advisor should be secured the convenience and stability of the public in order to become a popular investment advisory service. Therefore, government authorities should provide fair and responsible regulatory measures to bring stability and convenience of financial markets.The protection of financial consumers against errors and defects of various algorithms that implement high artificial intelligence technology as asset management service should be prepared as a legislative plan.Above all, the Robo-Advisor that utilizes artificial intelligence has a wide range of influences, so characteristics of the Robo-advisor should be grasped, and the agenda for the ambiguous use of the concept of artificial intelligence should be secured the attribution of responsibility and safety due to the autonomy of artificial intelligence.Therefore, in order to solve the issues related to securing the reliability and similarity of the Robo-Advisor utilizing artificial intelligence, it is necessary to prioritize the establishment of the basic law on the legal status and ethical status of the Robo-Advisor. Regulatory measures should also be established to verify the safety and transparency of the Robo-Advisor.This study suggests that regulation of financial service of Robo-Advisor should be established in three aspects. First, regulations require the explicit enactment of rules for adherence to disclosure requirements, including regulations on the application of prudent investment principles and disclosure obligations, for regulations that disrupt market order. Second, it is required to establish concrete application criteria of investors’ profiling based on the principle of suitability of financial investment business entity. Third, the regulations on the adequacy of the algorithms that drive the Robo-Advisor and the verification of the processes should be specifically proposed, and measures should be taken to fully consider the equality of the users.Robo-Advisor are still in the early stages of introducing the system, and there are still policy implications and various technology convergence in the IT industry is underway, so continuous monitoring, additional research, and diverse efforts are needed. In addition, the cultural level at which financial market trading are secured and various issues across the society should be fully reflected."
반복적 기법을 사용한 그래프 기반 단어 모호성 해소,2017,"['단어 중의성 해소', '중의성 단어', '지식기반', '바벨넷', 'WSD', 'ambiguous word', 'knowledge base', 'BabelNet']","최근 자연어 처리 분야에서 단어의 모호성을 해소하기 위해서 다양한 기계 학습 방법이 적용되고 있다. 지도 학습에사용되는 데이터는 정답을 부착하기 위해 많은 비용과 시간이 필요하므로 최근 연구들은 비지도 학습의 성능을 높이기 위한 노력을 지속적으로 시도하고 있다. 단어 모호성 해소(word sense disambiguation)를 위한 비지도 학습연구는 지식 기반(knowledge base)를 이용한 방법들이 주목받고 있다. 이 방법은 학습 데이터 없이 지식 기반의정보을 이용하여 문장 내에서 모호성을 가지는 단어의 의미를 결정한다. 지식 기반을 이용한 방법에는 그래프 기반방식과 유사도 기반 방법이 대표적이다. 그래프 기반 방법은 모호성을 가지는 단어와 그 단어가 가지는 다양한 의미들의 집합 간의 모든 경로에 대한 의미 그래프를 구축한다는 장점이 있지만 불필요한 의미 경로가 추가되어 오류를증가시킨다는 단점이 있다. 이러한 문제를 해결하기 위해 본 논문에서는 그래프 구축을 위해 불필요한 간선들을 배제하면서 반복적으로 그래프를 재구축하는 모델을 제안한다. 또한, 구축된 의미 그래프에서 더욱 정확한 의미를 예측하기 위해 하이브리드 유사도 예측 모델을 적용한다. 또한 제안된 모델은 다국어 어휘 의미망 사전인 BabelNet 을 사용하기 때문에 특정 언어뿐만 아니라 다양한 언어에도 적용 가능하다.","Current word sense disambiguation techniques employ various machine learning-based methods. Various approaches have been proposed to address this problem, including the knowledge base approach. This approach defines the sense of an ambiguous word in accordance with knowledge base information with no training corpus. In unsupervised learning techniques that use a knowledge base approach, graph-based and similarity-based methods have been the main research areas. The graph-based method has the advantage of constructing a semantic graph that delineates all paths between different senses that an ambiguous word may have. However, unnecessary semantic paths may be introduced, thereby increasing the risk of errors. To solve this problem and construct a fine-grained graph, in this paper, we propose a model that iteratively constructs the graph while eliminating unnecessary nodes and edges, i.e., senses and semantic paths. The hybrid similarity estimation model was applied to estimate a more accurate sense in the constructed semantic graph. Because the proposed model uses BabelNet, a multilingual lexical knowledge base, the model is not limited to a specific language."
인공적 도덕 행위자에 관한 도덕철학·심리학적 성찰,2017,"['인공적 도덕 행위자', '상향식', '하향식', '혼합형', '도덕적 정서', 'artificial moral agent', 'bottom-up', 'top-down', 'hybrid', 'moral emotion']","본 연구의 목적은 인공적 도덕 행위자의 개발에 있어서 도덕철학적·도덕심리학적 성찰을 제공하는 것이다. 도덕적 인공지능의 개발이 제기하는 도덕성 문제가 무엇인지를 밝혀냄과 동시에 도덕적 인공지능의 개발과정에서 제기되는 여러 문제들을 성찰해 보고자 하는 것이다. 우선 전통적인 공리주의나 의무론적 윤리이론에 기반을 둔 하향식 접근, 발달적·발전적·진화적 접근을 추구하는 상향식 접근, 그리고 이 두 접근을 융합하려는 혼합식 접근을 살펴보았다. 또한 도덕적 정서를 고려하는 접근이 보완적으로 왜 필요한지를 살피고자 하였다. 특별히 최근의 신경과학이나 도덕심리학적 입장은 이성과 사고하는 능력 중심의 기존 관점에서 벗어나 감정이나 직관의 중요성을 더욱 강조하는 경향성을 가지기에 이성과 직관·정서의 상호보완적 접근을 추구하는 AMA의 도덕성 구축이 필요함을 제시하였다. 여러 접근에서 모두 한계점과 문제점을 가지고 있지만 이것을 도덕철학적으로 또 도덕심리학·신경과학·신경윤리학적으로 살펴봄으로써 반성적 성찰을 제공하고자 하였다.","The moral decision-making abilities in AI is necessary. Robots with the ability to make moral judgments on its own is called AMA. In this paper I research that in certain circumstances AMA can be seen as real moral agents. For this, I will suggest four approaches when it comes to establishing an ethics for the AMA. First, the top-down approach makes use of the traditional ethical theories such as utilitarian or deontological theories. The role of the ethical theory in this approach is to provide the AMA with rules to follow in morally complex situations. Second, the bottom-up approach follows the central ideas proposed by developing various machine-learning methods for the AMA to learn ethical reasoning without giving it any available rules at hand. The basic idea for this approach is to regard the AMA as a human child who has the potential of obtaining moral reasoning as the child grows up according to proper developmental stages of morality. Third, the hybrid approach is an attempt to unite the top-down and the bottom-up approaches. Fourth, I argue that emotions, intuitions, and feelings are very important for AMA to be truly ethical. From a neuroscientific perspective and moral psychology, moral emotions have a scientific basis worthy of consideration. After all, I wish to provide some direction for AMA by outlining the value and limitations inherent in each of these approaches."
자동화된 사실 확인(fact checking) 기술(technology)의 현황과 한계,2017,"['팩트 체크', '사실 확인', '페이크 뉴스', '투명성', '알고리즘 저널리즘', '플랫폼', 'fact check', 'fake news', 'transparency', 'algorithm journalism', 'platform']","페이크 뉴스 등으로 인한 문제가 전 세계적 이슈가 되면서 ‘사실 확인(fact checking)’이 그 대안으로서 주목받고 있다. 하지만, 소규모 인력이 문제가 되는 사실을 확인하는 기존의 ‘사실 확인’ 방식으로 다루기에는 너무 많은 양의 사실들이 등장하면서, 컴퓨터 등 기술의 힘을 빌려 자동으로 사실을 확인하려는 시도들이 이어지고 있다. 이 글은 자동화된 ‘사실 확인 기술들이 어떠한 방식으로 작동하고 있는지를 지식 기반 방식, 맥락적 방식, 형식 기반 방식, 기계 학습 방식 등 네 가지 유형으로 구분해 설명했다. 또, 각각의 방식 사례로 구글의 지식 금고, 지식 그래프, 구글 뉴스의 ‘팩트 체크’ 라벨, 클레임버스터 등을 제시하고 현재 시점에서 한계점을 분석했다. 현재 단계에서 자동화된 ‘사실 확인 기술들은 방대한 정보의 빠른 처리를 통해 인간의 최종적인 사실 확인을 도와주는 수준이라고 할 수 있었다. 하지만, 확인해야 할 텍스트 양의 증가, 편견의 배제, 뉴스 유통의 플랫폼화 등으로 인해 특정한 사실의 사실 여부를 자동으로 판단하려는 시도는 지속적으로 늘어날 것으로 전망된다. 그러나 단지 기계적으로 처리했다고 해서 그 내용이 초당파적이거나 사실임을 입증하지는 않는다. 이 글은 기계 또는 기술이 수행한 결과에 대해서도 ‘사실 확인’이 필요하며 그 방안으로서 기술의 투명성이 필요함을 지적했다.","As fake news is becoming a global issue, ‘fact checking’ is attracting attention as an alternative. However, too many facts have emerged to deal with the traditional ‘fact checking’ approach that is done in a way that a few human workforce confirm the fact. Accordingly, attempts have been made to automatically check the facts by borrowing the power of technology such as a computer. This article described how the automated ‘fact checking’ techniques are working in four different ways: knowledge based, contextual, style based, and machine-learning. And this article presented example of each way(Google’s knowledge base, Knowledge graph, Goole’s ‘fact checking’ label, Claimbuster) and analyzed the limit at current point. As a result, the automated ‘fact checking’ technologies can be said to help people to confirm their final facts through rapid processing of vast amounts of information. Finally, this article argued that ‘fact checking’ is necessary for the results of automated ‘fact checking’, and pointed out that technology transparency is required."
노인 운전자의 공격적인 운전 상태 검출 기법,2017,"['노인 안전 운전', 'K-평균 알고리즘', '기댓값 최대화 알고리즘', '가우시안 혼합 모델', '스마트폰 가속도계']","공격적인 성향의 운전은 자동차 사고의 주요한 원인이 된다. 기존 연구에서는 공격적 성향의 운전을 검출하기 위해, 주로 청년을 대상으로 연구가 이뤄졌으며 기계학습의 순수한 Clustering 또는 Classification 기법을 통해 이뤄졌다. 그러나 노인들은 취약한 신체적 조건에 의해 젊은 운전자와는 다른 운전 강도를 가지고 있어 기존의 방식으로는 검출이 불가능 하며, 데이터를 보정하는 등의 새로운 방법이 필요하다. 그리하여, 본 연구에서는 기존의 클러스터링 기법(K-means, Expectation - maximization algorithm)에, 새롭게 제안하는 ECA(Enhanced Clustering method for Acceleration data)기법을 추가하여, 주행 차량에 위치한 스마트폰으로부터 수집된 가속도 데이터를 분석하고 공격적인 운전 형태를 검출해 낸다. ECA는 모든 피험자의 데이터에서 K-means와 EM을 통해 검출된 군집군의 데이터 중 높은 강도의 데이터를 선별하여, 특징을 스케일링한 값을 통해 모델링한다. 본 방식을 통해 기존의 연구의 순수한 클러스터링 방식과는 달리, 모든 청장년 및 노인 실험 참가자 개인들의 공격적인 운전 데이터가 검출되었으며, 클러스터링 기법간의 비교를 통해 K-means 기법이 보다 높은 검출 효율을 갖고 있음을 확인했다. 또한, K-means 방식을 검출한 공격적인 운전 데이터에서는 젊은 운전자가 노인운전자에 비해 1.29배의 높은 운전 강도를 가지고 있음을 발견했다. 이와 같이 본 연구에서 제안된 방식은 낮은 운전 강도를 갖고 있는 노인의 데이터에서 공격적인 운전을 검출 가능하게 되었으며, 특히. 제안된 방법은 노인 운전자를 위한 맞춤형 안전운전 시스템을 구축이 가능하며, 추후 다양한 연구을 통해 이상 운전 상태를 검출하고 조기 경보하는데 활용이 가능할 것이다.","Aggressive driving is a major cause of car accidents. Previous studies have mainly analyzed young driver's aggressive driving tendency, yet they were only done through pure clustering or classification technique of machine learning. However, since elderly people have different driving habits due to their fragile physical conditions, it is necessary to develop a new method such as enhancing the characteristics of driving data to properly analyze aggressive driving of elderly drivers. In this study, acceleration data collected from a smartphone of a driving vehicle is analyzed by a newly proposed ECA(Enhanced Clustering method for Acceleration data) technique, coupled with a conventional clustering technique (K-means Clustering, Expectation-maximization algorithm). ECA selects high-intensity data among the data of the cluster group detected through K-means and EM in all of the subjects' data and models the characteristic data through the scaled value. Using this method, the aggressive driving data of all youth and elderly experiment participants were collected, unlike the pure clustering method. We further found that the K-means clustering has higher detection efficiency than EM method. Also, the results of K-means clustering demonstrate that a young driver has a driving strength 1.29 times higher than that of an elderly driver. In conclusion, the proposed method of our research is able to detect aggressive driving maneuvers from data of the elderly having low operating intensity. The proposed method is able to construct a customized safe driving system for the elderly driver. In the future, it will be possible to detect abnormal driving conditions and to use the collected data for early warning to drivers."
Feature Selection Algorithm for Intrusions Detection System using Sequential Forward Search and Random Forest Classifier,2017,"['FeatureSelection', 'SFFS', 'RandomForest', 'IDS']",,"Cyber attacks are evolving commensurate with recent developments in information security technology. Intrusion detection systems collect various types of data from computers and networks to detect security threats and analyze the attack information. The large amount of data examined make the large number of computations and low detection rates problematic. Feature selection is expected to improve the classification performance and provide faster and more cost-effective results. Despite the various feature selection studies conducted for intrusion detection systems, it is difficult to automate feature selection because it is based on the knowledge of security experts. This paper proposes a feature selection technique to overcome the performance problems of intrusion detection systems. Focusing on feature selection, the first phase of the proposed system aims at constructing a feature subset using a sequential forward floating search (SFFS) to downsize the dimension of the variables. The second phase constructs a classification model with the selected feature subset using a random forest classifier (RFC) and evaluates the classification accuracy. Experiments were conducted with the NSL-KDD dataset using SFFS-RF, and the results indicated that feature selection techniques are a necessary preprocessing step to improve the overall system performance in systems that handle large datasets. They also verified that SFFS-RF could be used for data classification. In conclusion, SFFS-RF could be the key to improving the classification model performance in machine learning."
기계학습을 활용한 상품자산 투자모델에 관한 연구,2017,"['상품자산', '기계학습', 'SVM', '투자모델', 'Commodity Asset', 'Machine Learning', 'Support Vector Machine', 'Investment Model']",,"Services using artificial intelligence have begun to emerge in daily life. Artificial intelligence is applied to products in consumer electronics and communications such as artificial intelligence refrigerators and speakers. In the financial sector, using Kensho’s artificial intelligence technology, the process of the stock trading system in Goldman Sachs was improved. For example, two stock traders could handle the work of 600 stock traders and the analytical work for 15 people for 4weeks could be processed in 5 minutes. Especially, big data analysis through machine learning among artificial intelligence fields is actively applied throughout the financial industry.  The stock market analysis and investment modeling through machine learning theory are also actively studied. The limits of linearity problem existing in financial time series studies are overcome by using machine learning theory such as artificial intelligence prediction model. The study of quantitative financial data based on the past stock market-related numerical data is widely performed using artificial intelligence to forecast future movements of stock price or indices. Various other studies have been conducted to predict the future direction of the market or the stock price of companies by learning based on a large amount of text data such as various news and comments related to the stock market.  Investing on commodity asset, one of alternative assets, is usually used for enhancing the stability and safety of traditional stock and bond asset portfolio. There are relatively few researches on the investment model about commodity asset than mainstream assets like equity and bond. Recently machine learning techniques are widely applied on financial world, especially on stock and bond investment model and it makes better trading model on this field and makes the change on the whole financial area.  In this study we made investment model using Support Vector Machine among the machine learning models. There are some researches on commodity asset focusing on the price prediction of the specific commodity but it is hard to find the researches about investment model of commodity as asset allocation using machine learning model. We propose a method of forecasting four major commodity indices, portfolio made of commodity futures, and individual commodity futures, using SVM model. The four major commodity indices are Goldman Sachs Commodity Index(GSCI), Dow Jones UBS Commodity Index(DJUI), Thomson Reuters/Core Commodity CRB Index(TRCI), and Rogers International Commodity Index(RI). We selected each two individual futures among three sectors as energy, agriculture, and metals that are actively traded on CME market and have enough liquidity. They are Crude Oil, Natural Gas, Corn, Wheat, Gold and Silver Futures. We made the equally weighted portfolio with six commodity futures for comparing with other commodity indices.  We set the 19 macroeconomic indicators including stock market indices, exports & imports trade data, labor market data, and composite leading indicators as the input data of the model because commodity asset is very closely related with the macroeconomic activities. They are 14 US economic indicators, two Chinese economic indicators and two Korean economic indicators. Data period is from January 1990 to May 2017. We set the former 195 monthly data as training data and the latter 125 monthly data as test data.  In this study, we verified that the performance of the equally weighted commodity futures portfolio rebalanced by the SVM model is better than that of other commodity indices. The prediction accuracy of the model for the commodity indices does not exceed 50% regardless of the SVM kernel function. On the other hand, the prediction accuracy of equally weighted commodity futures portfolio is 53%. The prediction accuracy of the individual commodity futures model is better than that of commodity indices model especially in agricult"
A Study on Accuracy Estimation of Service Model by Cross-validation and Pattern Matching,2017,"['Machine learning method', 'Pattern matching', 'Cross validation']",,"In this paper, the service execution accuracy was compared by ontology  based rule inference method and machine learning method, and the amount of data at the point when the service  execution accuracy of the machine learning method becomes equal to the service execution accuracy of  the rule inference was found. The rule inference, which measures service execution accuracy and service  execution accuracy using accumulated data and pattern matching on service results. And then machine  learning method measures service execution accuracy using cross validation data. After creating a  confusion matrix and measuring the accuracy of each service execution, the inference algorithm can be selected  from the results."
하나의 IMU를 이용한 앉은 자세 분류 연구,2017,"['Sitting posture', 'Classification', 'Internal Measurement Unit : IMU', 'Machine learning', 'Principle Component Analysis : PCA']","바르지 못한 앉은 자세는 다양한 질병과 신체 변형을 유발한다. 하지만 오랜 시간동안 바른 앉은 자세를 유지하는 것은 쉬운 일이 아니다. 이러한 이유 때문에 그동안 자동으로 바른 앉은 자세를 유도하기 위한 다양한 시스템이 제안되어왔다. 이전에 제안되었던 앉은 자세 판별 및 바른 앉은 자세 유도 시스템은 영상 처리를 이용한 방법, 의자에 압력센서를 달아 측정하는 방법, IMU(Internal Measurement Unit)를 이용한 방법이 있었다. 이 중 IMU를 이용한 측정 방법은 하드웨어 구성이 간단하고, 공간, 광량 등의 환경적 제한이 적어 측정에 있어서 용이한 이점이 있었다. 본 논문에서는 하나의 IMU를 이용하여 적은 데이터로 효율적으로 앉은 자세를 분류하는 방법을 연구하였다. 특징추출 기법을 이용하여 데이터 분류에 기여도가 낮은 데이터를 제거하였으며, 머신러닝 기법을 이용하여 앉은 자세 분류에 적합한 센서 위치를 찾고, 여러 개의 머신러닝 모델 중 가장 분류 정확도가 높은 머신러닝 모델을 선정하였다. 특징추출 기법은 PCA(Principal Component Analysis)를 사용하였고, 머신러닝 모델은 SVM(Support Vector Machine), KNN(K Nearest Neighbor), K-means (K-means Algorithm) GMM (Gaussian Mixture Model), and HMM (Hidden Marcov Model)모델을 사용하였다. 연구결과 데이터 분류율이 높게나온 뒷목이 적합한 센서 위치가 되었으며, 센서 데이터 중 Yaw데이터는 분류 기여도가 가장 낮은 데이터임을 PCA 특징추출 기법을 이용하여 확인하고, 제거하여도 분류율에 영향이 매우 작음을 확인하였다. 적합 머신러닝 모델은 SVM, KNN 모델로 다른 모델에 비하여 분류율이 높게 나오는 것을 확인할 수 있었다.","Bad sitting postures are known to cause for a variety of diseases or physical deformation. However, it is not easy to fit right sitting posture for long periods of time. Therefore, methods of distinguishing and inducing good sitting posture have been constantly proposed. Proposed methods were image processing, using pressure sensor attached to the chair, and using the IMU (Internal Measurement Unit). The method of using IMU has advantages of simple hardware configuration and free of various constraints in measurement. In this paper, we researched on distinguishing sitting postures with a small amount of data using just one IMU. Feature extraction method was used to find data which contribution is the least for classification. Machine learning algorithms were used to find the best position to classify and we found best machine learning algorithm. Used feature extraction method was PCA(Principal Component Analysis). Used Machine learning models were five : SVM(Support Vector Machine), KNN(K Nearest Neighbor), K-means (K-means Algorithm) GMM (Gaussian Mixture Model), and HMM (Hidden Marcov Model). As a result of research, back neck is suitable position for classification because classification rate of it was highest in every model. It was confirmed that Yaw data which is one of the IMU data has the smallest contribution to classification rate using PCA and there was no changes in classification rate after removal it. SVM, KNN are suitable for classification because their classification rate are higher than the others."
기존 건물 HVAC 시스템에 대한 다섯 가지 기계학습 모델 개발,2017,"['기존 건물', '기계학습', '데이터 기반 모델', 'HVAC 시스템', '시뮬레이션 모델', 'Existing building', 'machine learning', 'data-driven model', 'HVAC system', 'Simulation model']",,"The first principles-based simulation model, e.g. dynamic simulation, is influenced by model uncertainty, simplification of the reality, lack of information, a modeler’s subjective assumptions, etc. Recently, a data-driven machine learning model has received a growing attention for simulation of existing buildings. The data-driven model is advantageous that it is simpler and requires less inputs than the first principles based model. In this study, the authors applied five different machine learning techniques (Artificial Neural Network, Support Vector Machine, Gaussian Process, Random Forest, and Genetic Programming) to HVAC systems (chiller, cooling tower, pump, ice thermal storage system and air handling unit) installed in an existing office building. It was found that the five machine learning models are good enough to predict the dynamic behavior of the HVAC systems. The machine learning model made by Genetic Programming is most accurate among the five machine learning models. The models made by Support Vector Machine and Gaussian Process Model require significant computation time and thus are limited in terms of the number of inputs. The accuracy of the model made by Random Forest is dependent on the set of inputs."
A Study on Accuracy Estimation of Service Model by Cross-validation and Pattern Matching,2017,"['Machine learning method', 'Pattern matching', 'Cross validation']",,"In this paper, the service execution accuracy was compared by ontology based rule inference method and machine learning method, and the amount of data at the point when the service execution accuracy of the machine learning method becomes equal to the service execution accuracy of the rule inference was found. The rule inference, which measures service execution accuracy and service execution accuracy using accumulated data and pattern matching on service results. And then machine learning method measures service execution accuracy using cross validation data. After creating a confusion matrix and measuring the accuracy of each service execution, the inference algorithm can be selected from the results."
Influence on overfitting and reliability due to change in training data,2017,"['Overfitting', 'machine learning', 'Deep-learning', 'cross-entropy', 'Tensorflow', 'Mnist dataset', 'Artificial Intelligence', 'Softmax regression', 'Reliability', 'loss-function']",,"The range of problems that can be handled by the activation of big data and the development of hardware has been rapidly expanded and machine learning such as deep learning has become a very versatile technology. In this paper, mnist data set is used as experimental data, and the Cross Entropy function is used as a loss model for evaluating the efficiency of machine learning, and the value of the loss function in the steepest descent method is We applied the GradientDescentOptimize algorithm to minimize and updated weight and bias via backpropagation. In this way we analyze optimal reliability value corresponding to the number of exercises and optimal reliability value without overfitting. And comparing the overfitting time according to the number of data changes based on the number of training times, when the training frequency was 1110 times, we obtained the result of 92%, which is the optimal reliability value without overfitting."
Influence on overfitting and reliability due to change in training data,2017,"['Overfitting', 'machine learning', 'Deep-learning', 'cross-entropy', 'Tensorflow', 'Mnist dataset', 'Artificial Intelligence', 'Softmax regression', 'Reliability', 'loss-function']",,"The range of problems that can be handled by the activation of big data and the development of hardware has been rapidly expanded and machine learning such as deep learning has become a very versatile technology. In this paper, mnist data set is used as experimental data, and the Cross Entropy function is used as a loss model for evaluating the efficiency of machine learning, and the value of the loss function in the steepest descent method is We applied the GradientDescentOptimize algorithm to minimize and updated weight and bias via backpropagation. In this way we analyze optimal reliability value corresponding to the number of exercises and optimal reliability value without overfitting. And comparing the overfitting time according to the number of data changes based on the number of training times, when the training frequency was 1110 times, we obtained the result of 92%, which is the optimal reliability value without overfitting."
The Research of Face Expression Recognition based on CNN using Tensorflow,2017,"['VGG', 'convolution neural network', 'expression recognition']",,
기계학습 기반의 장애 음성 검출 시스템,2017,"['Speech disorder', 'Machine learning']",,"This paper deals with the implementation of speech disorder detection system based on machine learning classification. Problems with speech are a common early symptom of a stroke or other brain injuries. Therefore, detection of speech disorder may lead to correction and fast medical treatment of strokes or cerebrovascular accidents. The speech disorder system can be implemented by extracting features from the input speech and classifying the features using machine learning algorithms. Ten machine learning algorithms with various scaling methods were used to discriminate speech disorder from normal speech. The detection system was evaluated by the TORGO database which contains dysarthric speech collected from speakers with either cerebral palsy or amyotrophic lateral sclerosis."
건물유형별 에너지소비 예측성능 향상을 위한 변수중요도 및 기계학습모델 평가,2017,"['기계학습모델', '건물 에너지소비예측', '초등학교', '상업용 건물', '변수중요도', 'Machine Learning Model', 'Building Energy Consumption Forecasting', 'Primary School', 'Commercial Building', 'Variable Importance']",,"The optimal machine learning model depends on building types was selected by comparing and analyzing short term load forecasting (STLF) performance of primary school and commercial reference building based on 4 machine learning models such as ANN, SVM, CHAID, and, RF. The research consists of data collection-storage, data analysis, meteorological variables extraction, energy consumption forecasting and analysis on typical primary school and commercial building energy model. TMY (Typical Meteorological Year) of Incheon, Korea was applied and based on weather forecasting data provided by the KMA (Korea Meteorological Agency). In case of building energy consumption data, primary school and medium commercial reference building energy consumption data by on EIA’s Commercial Buildings Energy Consumption Survey (CBECS) were used. Key weather variables were extracted for each machine learning model between the input variables and the output which is building energy consumption in 15 minutes interval. Finally, forecasting of energy consumption on different building types conducted a comparative analysis of the forecasting performance of building energy consumption based on 4 machine learning models using optimal input variables. The results shows ANN model outperforms other models with 5.44% of CV (RMSE) for 7 days school building energy forecasting trained 8 weeks prior data. Whereas, RF model performs better than the others with 10.96% of CV (RMSE). It may be concluded that the priority of variables which have impacts on energy consumption is important and the most suitable model for energy forecasting is different by the building types."
Stress Identification and Analysis using Observed Heart Beat Data from Smart HRM Sensor Device,2017,"['Stress', 'HRV', 'Machine Learning']",,"In this paper, we analyses heart beat data to identify subjects stress state (binary) using heart rate variability (HRV) features extracted from heart beat data of the subjects and implement supervised machine learning techniques to create the mental stress classifier. There are four steps need to be done: data acquisition, data processing (HRV analysis), features selection, and machine learning, before doing performance measurement. There are 56 features generated from the HRV Analysis module with several of them are selected (using own algorithm) after computing the Pearson Correlation Matrix (p-values). The results of the list of selected features compared with all features data are compared by its model error after training using several machine learning techniques: support vector machine, decision tree, and discriminant analysis. SVM model and decision tree model with using selected features shows close results compared to using all recording by only 1% difference. Meanwhile, the discriminant analysis differs about 5%. All the machine learning method used in this works have 90% maximum average accuracy."
기계학습을 이용한 노면온도변화 패턴 분석,2017,"['Surface Road Temperature Change', 'Machine Learning', 'Road Weather', 'Thermal Mapping', 'Ambient Temperature']",,"PURPOSES:This study suggests a specific methodology for the prediction of road surface temperature using vehicular ambient temperature sensors. In addition, four kind of models is developed based on machine learning algorithms.METHODS:Thermal Mapping System is employed to collect road surface and vehicular ambient temperature data on the defined survey route in 2015 and 2016 year, respectively. For modelling, all types of collected temperature data should be classified into response and predictor before applying a machine learning tool such as MATLAB. In this study, collected road surface temperature are considered as response while vehicular ambient temperatures defied as predictor. Through data learning using machine learning tool, models were developed and finally compared predicted and actual temperature based on average absolute error.RESULTS:According to comparison results, model enables to estimate actual road surface temperature variation pattern along the roads very well. Model III is slightly better than the rest of models in terms of estimation performance.CONCLUSIONS :When correlation between response and predictor is high, when plenty of historical data exists, and when a lot of predictors are available, estimation performance of would be much better."
Food Powder Classification Using a Portable Visible-Near-Infrared Spectrometer,2017,"['Classification', 'Food Powder', 'Machine Learning', 'Near Infrared Spectroscopy', 'Portable VIS-NIR Spectrometer']",,"Visible-near-infrared (VIS-NIR) spectroscopy is a fast and non-destructive method for analyzing materials. However, most commercial VIS-NIR spectrometers are inappropriate for use in various locations such as in homes or offices because of their size and cost. In this paper, we classified eight food powders using a portable VIS-NIR spectrometer with a wavelength range of 450–1,000 nm. We developed three machine learning models using the spectral data for the eight food powders. The proposed three machine learning models (random forest, k-nearest neighbors, and support vector machine) achieved an accuracy of 87%, 98%, and 100%, respectively. Our experimental results showed that the support vector machine model is the most suitable for classifying non-linear spectral data. We demonstrated the potential of material analysis using a portable VIS-NIR spectrometer."
의생명 이미지 분류 기법의 최신 동향,2017,"['Biomedical images', 'Image classification', 'Radiology', 'Computer vision', 'Machine learning']",,"As biomedical imaging equipment and machine learning algorithms are improved, biomedical image analysis became a popular topic for both biologists and machine learning researchers. Biomedical image analysis includes various topics such as classification, segmentation, and registration. All of them are being actively studied, and there are a lot of remarkable papers on these topics. In this paper, we focus on recent trend of biomedical image classification. Because researchers use microscopy images for biological image analysis and use radiological data such as CT, MRI for medical image analysis, we explain classification methods used in several researches for biological image and medical image separately, depending on the type of images to be analyzed. In addition to traditional methods based on feature descriptor, we also introduce methods that apply deep learning in biomedical image classification, since deep learning is recently used in many researches for image processing. We found that deep learning based models show great performance in biomedical domain, and state-of-the-art idea of image processing and computer vision has potential to be applied to biomedical problems. Finally we suggest future works for better biomedical image classifier, based on the idea that are recently studied in computer vision, but with few papers in biomedical domain."
랜덤 포레스트와 데이터 전처리를 이용한 냉동기 기계학습 모델 개발,2017,"['인버스 모델링', '기계학습', '랜덤 포레스트', '변수 선택', '변수 구축', 'Inverse Modeling', 'Machine Learning', 'Random Forest', 'Variable Selection', 'Variable Construction']",,"It has been widely acknowledged that a machine learning model can be used as a surrogate to a first-principle based dynamic simulation model. The accuracy and computation efficiency of a machine learning model is dependent on a combination of input variables. The random forest algorithm, one of the machine learning algorithms, can calculate a variable importance that determines the influence of each input variable on the output of the model. In this study, the authors developed three random forest models of a chiller in an existing building as follows: (1) Model A consisting of 12 measured variables from BEMS data, (2) Model B consisting of 2 measured input variables plus 4 new variables constructed by random selection, and (3) Model C consisting of 4 measured input variables plus 2 new variables constructed based on a physics-based equation. The CVRMSE of the three models are 8.56%, 5.44%, and 4.28%, respectively. The findings of this study can be summarized threefold: (1) all three random forest models are good enough to describe the dynamics of the chiller system, (2) the random forest machine learning algorithm can be used to develop a simulation model of the system, and (3) an accurate model can be constructed either by the random selection or the physics-based equation, even when a few input variables are given."
스마트한 기계를 위한 온톨로지,2017,"['온톨로지', '형식적 존재론', '기계지능', '후설', '현상학', 'Ontology', 'Formal Ontology', 'Machine Intelligence', 'Husserl', 'Phenomenology']",일상의 자연어로 인간과 소통하는 기계가 우리 주변을 채우고 있다. 이는 기계가 인간의 언어를 이해하는 것처럼 보이게 만든다. 물론 기계가 인간의 언어를 실제로 이해하는 것은 아니다. 기계가 인간의 언어를 이해하는 것처럼 보이는 까닭은 기계가 인간의 자연어가 갖고 있는 구조와 어휘들을 학습함으로써 자연어의 의미론적 구조를 모방할 수 있게 되었기 때문이다. 정보공학에서는 기계가 인간과 의사소통할 수 있도록 정보를 구조화하는 작업을 ‘온톨로지(ontology)’라고 부른다. 최근 정보공학 분야에서 사용하는 온톨로지는 후설의 형식적 존재론과 영역 존재론의 프로젝트와 구조적으로 대단히 유사하다. 이는 정보공학과 후설 현상학이 서로 협업할 수 있는 접점이 있음을 뜻한다. 이 논문은 기계가 인간의 자연어를 이해하는 것처럼 보이는 일이 어떻게 가능한지를 살펴보고 현상학과 정보공학이 협업할 수 있는 접점을 시사하고자 한다.,"It seems not to be strange that we communicate with the machine with ordinary natural language. Could the machine really understand the human natural language? Of course not! It seems, however, to be so. The reason is the machine can simulate the natural language by the machine learning about the semantic structure and words of the natural language. In information science, the “ontology” means that the structuring of data and informations for the communication between the machine and the human being. This ontology, I believe, is a realization of Husserl’s ontological project. In this paper, I tried to show how the machine could seems to be to understand the natural language and that we could find a clue for interdisciplinary studies of information sciences and Husserl’s phenomenology."
自學用 한문교육SW 개선 방안 연구,2017,"['한문', '한문교육', '교육용SW', '소프트웨어', '미래교육', 'Sino-classical written language', 'HanMun education', 'Learning Software', 'Software', 'Future Society']","최근 제4차 산업혁명이 새로운 화두로 떠오르고 있다. 인류 생활 전반에 커다란 변화가 예상된다. 제2외국어 습득과 관련하여서도 이런 변화는 이미 시작되었다. 머지않은 미래에 인공지능과 이를 활용한 기계가 번역과 통역을 수행할 것이라는 예상은 이미 현실이 되고 있다. 이런 상황 속에서 인간을 대상으로 하는 언어 교육의 일종인 한문교육을 논하는 것은 미래지향적인 것처럼 보이지 않는다. 그러나 기계가 인간과 같이 완벽한 통역과 번역을 하는 것은 더 많은 시간이 필요하고, 설 사 개발된다 할지라도 자신의 뇌를 이용하는 것 같은 편리함을 느끼지 못하며, 통계 수치에 의한 선택이 항상 옳은 답을 내놓지 않는다는 것, 그리고 인공지능의 개발과 발전도 결국 인간에 의해 주도된다는 점 등을 생각해 본다면 여전히 인간을 대상으로 한 학습의 효율성 증대 방법을 찾는 것은 여전히 유의미하다. 본고는 현재라는 시간적 관점을 포함하여 교육과정 설계에서 중요한 대상과 목적, 내용과 과정설 계 등 다양한 방면에서 다양한 유형의 SW를 고찰하고, 각 유형에 따라 유의미한 결과를 취득하기 위해 어떻게 기획되고 발전되어야 하는지 논하였다. 특히 물리적 공간과 시간을 넘어서는 자학용 SW를 중점으로 삼아 살펴보았다. 마지막으로 국내를 넘어 해외 학습자들을 위한 SW개발과 언어교 육으로서의 한문 원전 독해 뿐 아니라, 한문을 독해 학습의 대상에서 넘어 다양한 해석이 가능한 인문학 교육의 자원으로 개발할 것을 제안하였다.","The fourth industrial revolution has recently focused as a new topic. Significant changes are expected throughout human life. These changes have already begun in connection with the acquisition of foreign languages. It is already a reality that the AI(artificial intelligence) and the machine using it will perform translation and interpretation in the near future. In this context, discussing the Sino-Classical language education, which is a type of language education aimed at humans. But it takes more time for the machine to perform perfect interpretation and translation like a human being, and even if it develops; it does not feel as convenient to use its own brain; and that choice by statistical numbers does not always give the right answer; develop AI and machine also controled by human beings, find ways to increase the efficiency of learning for humans is still meaningful. This paper examines the various types of learning software in various ways such as important object, purpose, content and process design in curriculum design including current time perspective. And how to be planned and developed to outcomes in order to achieve meaningful results in anytime and anywhere. Finally, suggested that have to learning software have to develop for any foreign learners; This software not only used for learning langage or interpretation to mother tongue, have to develop and build a liberal arts education by various thinking and view."
이진 분류문제에서의 딥러닝 알고리즘의 활용 가능성 평가,2017,"['이진분류', '딥러닝', '다층 퍼셉트론', '합성곱 신경망', '장단기 기억', 'Binary Classification', 'Deep Learning', 'Multi-Layer Perceptron', 'Convolutional Neural Network', 'Long Short-Term Memory']",,"Recently, AlphaGo which is Bakuk (Go) artificial intelligence program by Google DeepMind, had a huge victory against Lee Sedol. Many people thought that machines would not be able to win a man in Go games because the number of paths to make a one move is more than the number of atoms in the universe unlike chess, but the result was the opposite to what people predicted. After the match, artificial intelligence technology was focused as a core technology of the fourth industrial revolution and attracted attentions from various application domains. Especially, deep learning technique have been attracted as a core artificial intelligence technology used in the AlphaGo algorithm.  The deep learning technique is already being applied to many problems. Especially, it shows good performance in image recognition field. In addition, it shows good performance in high dimensional data area such as voice, image and natural language, which was difficult to get good performance using existing machine learning techniques. However, in contrast, it is difficult to find deep leaning researches on traditional business data and structured data analysis. In this study, we tried to find out whether the deep learning techniques have been studied so far can be used not only for the recognition of high dimensional data but also for the binary classification problem of traditional business data analysis such as customer churn analysis, marketing response prediction, and default prediction. And we compare the performance of the deep learning techniques with that of traditional artificial neural network models.  The experimental data in the paper is the telemarketing response data of a bank in Portugal. It has input variables such as age, occupation, loan status, and the number of previous telemarketing and has a binary target variable that records whether the customer intends to open an account or not. In this study, to evaluate the possibility of utilization of deep learning algorithms and techniques in binary classification problem, we compared the performance of various models using CNN, LSTM algorithm and dropout, which are widely used algorithms and techniques in deep learning, with that of MLP models which is a traditional artificial neural network model. However, since all the network design alternatives can not be tested due to the nature of the artificial neural network, the experiment was conducted based on restricted settings on the number of hidden layers, the number of neurons in the hidden layer, the number of output data (filters), and the application conditions of the dropout technique. The F1 Score was used to evaluate the performance of models to show how well the models work to classify the interesting class instead of the overall accuracy.  The detail methods for applying each deep learning technique in the experiment is as follows. The CNN algorithm is a method that reads adjacent values from a specific value and recognizes the features, but it does not matter how close the distance of each business data field is because each field is usually independent. In this experiment, we set the filter size of the CNN algorithm as the number of fields to learn the whole characteristics of the data at once, and added a hidden layer to make decision based on the additional features. For the model having two LSTM layers, the input direction of the second layer is put in reversed position with first layer in order to reduce the influence from the position of each field. In the case of the dropout technique, we set the neurons to disappear with a probability of 0.5 for each hidden layer.  The experimental results show that the predicted model with the highest F1 score was the CNN model using the dropout technique, and the next best model was the MLP model with two hidden layers using the dropout technique. In this study, we were able to get some findings as the experiment had proceeded. First, models using dropout techniques have a"
빙축열 시스템의 익일 방냉량 예측 기계학습 모델 및 제어,2017,"['빙축열 시스템', '기계학습', '모델 예측 제어', '사무소 건물', '시뮬레이션 모델', 'ice thermal storage system', 'machine learning', 'model predictive control', 'office building', 'simulation model']",,"In South Korea, an ice thermal storage system is popular because night-time electricity rate is cheaper than daytime rate. A spherical ice ball system is one of the most popular ice thermal storage systems used in Korea. However, it is difficult to estimate the degree of freezing and defrosting of the spherical ice ball system and thus, excessive icing commonly occurs in order to prevent any shortage of stored ice. If this rule-of thumb control can be replaced by a simulation model-based control, there would be significant potential for energy savings. In this study, the authors developed 25 machine learning simulation models for the spherical ice thermal storage system installed in a 30-story office building (gross floor area: 32,600m2) located in Seoul, Korea. Five different machine learning algorithms (Artificial Neural Network, Support Vector Machine, Gaussian Process, Random Forest, and Genetic Programming) were used for five different input scenarios, respectively. The 25 machine learning models are accurate enough to predict the amount of icing required for the following daytime. In addition, with the use of Model Predictive Control (MPC), 16.8% of excessive icing during overnight can be reduced and 15% of cooling energy (chiller, cooling tower, Brine pump, etc.) can be saved."
Adaptive Prediction Method Based on Alternating Decision Forests with Considerations for Generalization Ability,2017,"['Data Mining', 'Big Data', 'Prediction Model', 'Random Forests', 'Alternating Decision Forests']",,"Many machine learning algorithms have been proposed and applied to a wide range of prediction problems in the field of industrial management. Lately, the amount of data is increasing and machine learning algorithms with low computational costs and efficient ensemble methods are needed. Alternating Decision Forest (ADF) is an efficient ensemble method known for its high performance and low computational costs. ADFs introduce weights representing the degree of prediction accuracy for each piece of training data and randomly select attribute variables for each node. This method can effectively construct an ensemble model that can predict training data accurately while allowing each decision tree to retain different features. However, outliers can cause overfitting, and since candidates of branch conditions vary for nodes in ADFs, there is a possibility that prediction accuracy will deteriorate because the fitness of training data is highly restrained. In order to improve prediction accuracy, we focus on the prediction results for new data. That is to say, we introduce bootstrap sampling so that the algorithm can generate out-of-bag (OOB) datasets for each tree in the training phase. Additionally, we construct an effective ensemble of decision trees to improve generalization ability by considering the prediction accuracy for OOB data. To verify the effectiveness of the proposed method, we conduct simulation experiments using the UCI machine learning repository. This method provides robust and accurate predictions for datasets with many attribute variables."
합성곱 신경망을 이용한 복잡한 형상을 가진 공의 인식,2017,"['deep learning', 'R-CNN', 'RoboCup', 'object classification', 'object localization']",,"Image processing is widely used not only in manufacturing industries, but also in advanced contexts such as RoboCup, an international robotics competition. Recently, in the image processing field, convolutional neural networks, which is a deep learning approach, became the mainstream of object recognition algorithms. In this paper, a convolutional neural network is designed and used to learn the features of the ball in the RoboCup soccer game. The convolutional neural network was named JeoNet. JeoNet was modified to learn fewer features than VGGNet and ResNet, but shows the same performance. In order to obtain the detected ball’s position, the Single Shot Multibox Detector was applied. To verify JeoNet, an experimental environment was constructed in which a soccer robot finds a ball in the sight. The benefits of JeoNet were shown by comparing the tracking time of the ball between JeoNet and conventional machine vision based ball finding algorithms."
Adaptive Prediction Method Based on Alternating Decision Forests with Considerations for Generalization Ability,2017,"['Data Mining', 'Big Data', 'Prediction Model', 'Random Forests', 'Alternating Decision Forests']",,"Many machine learning algorithms have been proposed and applied to a wide range of prediction problems in the field of industrial management. Lately, the amount of data is increasing and machine learning algorithms with low computational costs and efficient ensemble methods are needed. Alternating Decision Forest (ADF) is an efficient ensemble method known for its high performance and low computational costs. ADFs introduce weights representing the degree of prediction accuracy for each piece of training data and randomly select attribute variables for each node. This method can effectively construct an ensemble model that can predict training data accurately while allowing each decision tree to retain different features. However, outliers can cause overfitting, and since candidates of branch conditions vary for nodes in ADFs, there is a possibility that prediction accuracy will deteriorate because the fitness of training data is highly restrained. In order to improve prediction accuracy, we focus on the prediction results for new data. That is to say, we introduce bootstrap sampling so that the algorithm can generate out-of-bag (OOB) datasets for each tree in the training phase. Additionally, we construct an effective ensemble of decision trees to improve generalization ability by considering the prediction accuracy for OOB data. To verify the effectiveness of the proposed method, we conduct simulation experiments using the UCI machine learning repository. This method provides robust and accurate predictions for datasets with many attribute variables."
온라인 간편 결제 환경에서 기계학습을 이용한 무자각 인증 기술 연구,2017,"['Authentication', 'Machine Learning', 'Account Takeover', 'Fraud Detection']","최근 환경기반 인증 기술로 사용자의 로그인 히스토리를 계정도용 또는 정상 로그인으로 분류한 후 사용자별로 통계모델을 만들어 사용자를 인증하는 Reinforced authentication이 제안되었다. 하지만 Reinforced authentication은 사용자가 과거에 계정도용을 당한 적이 없으면 공격을 당할 가능성이 높다. 본 논문은 이러한 문제점을 해결하기 위해 기계학습 알고리즘을 이용하여 사용자 환경정보와 타인의 환경정보를 함께 학습시켜 2-Class 사용자 모델을 만드는 무자각 인증 기술을 제안한다. 제안한 기술의 성능을 평가하기 위해 목표 사용자에 대해 아무 정보도 없는 무 지식 공격자와 목표 사용자에 대해 한 가지의 정보만 알고 있는 정교한 공격자에 대한 Evasion Attack을 실험하였다. 무 지식공격자에 대한 실험 결과 Class 0의 Precision과 Recall 각각 1.0과 0.998로 측정되었으며, 정교한 공격자에 대한 실험결과 Class 0의 Precision과 Recall 각각 0.948과 0.998로 측정되었다.","Recently, environment based authentication technique had proposed reinforced authentication, which generating statistical model per user after user login history classifies into account takeover or legitimate login. But reinforced authentication is likely to be attacked if user was not attacked in past. To improve this problem in this paper, we propose unconsciousness authentication technique that generates 2-Class user model, which trains user’s environmental information and others’ one using machine learning algorithms. To evaluate performance of proposed technique, we performed evasion attacks: non-knowledge attacker that does not know any information about user, and sophisticated attacker that only knows one information about user. Experimental results against non-knowledge attacker show that precision and recall of Class 0 were measured as 1.0 and 0.998 respectively, and experimental results against sophisticated attacker show that precision and recall of Class 0 were measured as 0.948 and 0.998 respectively."
Predicting Product Demands for Large-scale Chain Stores with FTRL-Proximal Linear Regression,2017,"['online learning', 'FTRL-proximal', 'demand prediction', 'chain stores']",,"Demand prediction for large-scale chain stores is a large-scale learning problem. A solution for this kind of problems is the online learning used in areas of machine learning when it is computationally infeasible to train over the entire dataset. This paper proposes to apply an online learning algorithm, FTRL-Proximal, to an example demand prediction problem for large-scale chain stores published in an open competition. Experimental results show that the algorithm with some minor modification is better than the best single model published in the competition."
Influence on overfitting and reliability due to change in training data,2017,"['Overfitting', 'machine learning', 'Deep-learning', 'cross-entropy', 'Tensorflow', 'Mnist dataset', 'ArtificialIntelligence', 'Softmax regression', 'Reliability', 'loss-function']",,
돌발홍수 예보를 위한 빅데이터 분석방법,2017,"['돌발홍수', '로지스틱회귀모형', '머신러닝', '예보시스템', '지표수문모델', 'Flash flood', 'Land Surface model', 'Logistic regression model', 'Nature hazard warning', 'Machine learning']",,
작성자 분석 기반의 공격 메일 탐지를 위한 분류 모델,2017,"['Text Mining', 'Machine Learning', 'Classification', 'Authorship Analysis', 'Attacker Identification', '텍스트마이닝', '기계학습', '분류', '작성자분석', '공격자 식별']","최근 사이버보안에서 악성코드를 이용한 공격은 메일에 악성코드를 첨부하여 이를 사용자가 실행하도록 유도하여 공격을 수행하는 형태가 늘어나고 있다. 특히 문서형태의 파일을 첨부하여 사용자가 쉽게 실행하게 되어 위험하다. 저자 분석은 NLP(Neutral Language Process) 및 텍스트 마이닝 분야에서 연구되어지고 있는 분야이며, 특정 언어로 이루어진 텍스트 문장, 글, 문서를 분석하여작성한 저자를 분석하는 방법들은 연구하는 분야이다. 공격 메일의 경우 일정 공격자에 의해 작성되어지기 때문에 메일 내용 및 첨부된 문서 파일을 분석하여 해당 저자를 식별하면 정상메일과 더욱 구별된 특징들을 발견할 수 있으며, 탐지 정확도를 향상시킬 수있다. 본 논문에서는 기존의 기계학습 기반의 스팸메일 탐지 모델에서 사용되는 특징들과 문서의 저자 분석에 사용되는 특징들로부터 공격메일을 분류 및 탐지를 할 수 있는 feature vector 및 이에 적합한 IADA2(Intelligent Attack mail Detection based on Authorship Analysis)탐지 모델을 제안하였다. 단순히 단어 기반의 특징들로 탐지하던 스팸메일 탐지 모델들을 개선하고, n-gram을 적용하여 단어의 시퀀스 특성을 반영한 특징을 추출하였다. 실험결과, 특징의 조합과 특징선택 기법, 적합한 모델들에 따라 성능이 개선됨을 검증할 수 있었으며, 제안하는 모델의 성능의 우수성과 개선 가능성을 확인할 수 있었다.","Recently, attackers using malicious code in cyber security have been increased by attaching malicious code to a mail and inducing the user to execute it. Especially, it is dangerous because it is easy to execute by attaching a document type file. The author analysis is a research area that is being studied in NLP (Neutral Language Process) and text mining, and it studies methods of analyzing authors by analyzing text sentences, texts, and documents in a specific language. In case of attack mail, it is created by the attacker.Therefore, by analyzing the contents of the mail and the attached document file and identifying the corresponding author, it is possible to discover more distinctive features from the normal mail and improve the detection accuracy.In this pager, we proposed IADA2(Intelligent Attack mail Detection based on Authorship Analysis) model for attack mail detection.The feature vector that can classify and detect attack mail from the features used in the existing machine learning based spam detection model and the features used in the author analysis of the document and the IADA2 detection model. We have improved the detection models of attack mails by simply detecting term features and extracted features that reflect the sequence characteristics of words by applying n-grams. Result of experiment show that the proposed method improves performance according to feature combinations, feature selection techniques, and appropriate models."
Support Vector Regression 기반의 단기 풍력발전 예측시스템 개발,2017,"['Support Vector Machine(SVM)', 'Support Vector Regression(SVR)', 'Wind Power Forecasting', 'Short-Term Forecasting', 'Machine Learning']",,"Short-term wind power forecasting is a technique which informs system operators of how much wind power can be expected at a specific time. Due to the increasing penetration of wind generating resource into power grids, short-term wind power forecasting is becoming an important issue for grid integration analysis. Generally, regression model is used to forecast short-term wind generation. Regression method is an approach for modeling the relevance between a dependent variable and one or more independent variables. In order to enhance wind power forecasting errors, we propose the short-term wind power forecasting using support vector machine based on linear regression."
기계학습 기반 내부자위협 탐지기술,2017,"['Insider threat', 'Machine learning', 'Neural network', 'Anomaly detect', 'Information security']","최근 몇 년 동안 지속적으로 개인정보유출, 기술유출 사고가 빈번하게 발생하고 있다. 조사에 따르면 이러한 유출 사고의 주체로 가장 많은 부분을 차지하고 있는 것이 조직 내부에 있는 ‘내부자’로, 내부자에 의한 기술유출은 조직에 막대한 피해를 주기 때문에 점점 더 중요한 문제로 여겨지고 있다. 본 논문에서는 내부자위협을 방지하기 위해 기계학습을 이용하여 직원들의 일반적인 정상행위를 학습하고, 이에 벗어나는 비정상 행위를 탐지하기 방법에 대한 연구를 하고자한다. Neural Network 모델 중 시계열 데이터의 학습에 적합한 Recurrent Neural Network로 구성한 Autoencoder를 구현하여 비정상 행위를 탐지하는 방법에 대한 실험을 진행하였고, 이 방법에 대한 유효성을 검증하였다.","In recent years, personal information leakage and technology leakage accidents are frequently occurring. According to the survey, the most important part of this spill is the ""insider"" within the organization, and the leakage of technology by insiders is considered to be an increasingly important issue because it causes huge damage to the organization. In this paper, we try to learn the normal behavior of employees using machine learning to prevent insider threats, and to investigate how to detect abnormal behavior. Experiments on the detection of abnormal behavior by implementing an Autoencoder composed of Recurrent Neural Network suitable for learning time series data among the neural network models were conducted and the validity of this method was verified."
스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석,2017,"['딥 러닝', '스파크', 'Caffe', '분산 컴퓨팅', '클러스터 컴퓨팅', 'deep learning', 'Apache Spark', 'Caffe', 'parallel computing', 'cluster computing']","딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다.","By piling up hidden layers in artificial neural networks, deep learning is delivering outstanding performances for high-level abstraction problems such as object/speech recognition and natural language processing. Alternatively, deep-learning users often struggle with the tremendous amounts of time and resources that are required to train deep neural networks. To alleviate this computational challenge, many approaches have been proposed in a diversity of areas. In this work, two of the existing Apache Spark-based acceleration frameworks for deep learning (SparkNet and DeepSpark) are compared and analyzed in terms of the training accuracy and the time demands. In the authors"" experiments with the CIFAR-10 and CIFAR-100 benchmark datasets, SparkNet showed a more stable convergence behavior than DeepSpark; but in terms of the training accuracy, DeepSpark delivered a higher classification accuracy of approximately 15%. For some of the cases, DeepSpark also outperformed the sequential implementation running on a single machine in terms of both the accuracy and the running time."
Predicting the Occurrence of the English Modals Can and May Using Deep Neural Networks,2017,"['can', 'may', 'classification', 'deep learning', 'deep neural networks']",,"Predicting the Occurrence of the English Modals Can and May Using Deep Neural Networks. Studies in Modern Grammar 96, 167-189. This paper tries to provide a computational modeling of language processing using deep neural networks. For this purpose, the corpus data in the ICE-USA was used. After all the sentences with can and may were encoded with eighteen linguistic factors, the annotated data were fed into the deep neural networks (DNN). The DNN was constructed with three layers, and each layer contained seventeen nodes. After the DNN was constructed, the learning process was performed with a training set. Then, the performance was measured with a test set. The processes were repeated one hundred times, and it was observed that the DNN had the classification accuracy of 91.5%. The results are promising in that reliable methods can be used in automatically classifying the frequently used modal auxiliary on the basis of the deep learning system."
클러스터링 기반 건물 용도별 에너지 소비 패턴 분석,2017,"['Energy consumption pattern', 'Machine learning', 'Clustering analysis', 'Building usage']",,"The analysis of energy use patterns is considered to be one of the important building energy performance evaluation, because it can improve the understanding of energy consumption characteristics of building. Pattern analysis can also be used for benchmarking with other buildings. In this study, we analyzed the building energy consumption patterns based on the energy consumption data from building energy management system(BEMS) using machine learning techniques, especially k-means clustering. Energy consumption data were collected from 8 buildings with different building usage for one year. As a result, the office type buildings (A, B, D, E) showed different characteristics in seasons, weekday and holiday, etc according to the number k. The residential building (C) showed no significant difference in the weekday and weekday, but was more sensitive to seasonal changes. The buildings that operate 24 hours, such as F(Police station), G(Fire station), showed similar energy use patterns on weekdays and weekends. The school building (H) was divided into 11 clusters according to weekdays and holidays. Clustering based on building energy consumption could reveal different energy patterns and characteristics according to building operation, and the results were not always match to the nominal building usage."
기계학습을 활용한 개인 특성 예측,2017,"['예측', '기계학습', '인지양식', '알고리즘', 'Machine Learning', 'Cognitive Style', 'Prediction', 'Algorithm']",,"Studies in the social sciences predominantly focus on the relationships between social-psychological factors and/or differences between groups, and thus it is insufficient to predict specific factors of individuals. In this study, we examine methods for applying machine learning to social science studies. Undergraduate students completed a survey of Korean Object-Spatial Imagery and Verbal Questionnaire (K-QSIVQ). The algorithms for prediction were naive Bayes, logistic regression, sequential minimal optimization, and J4.8. Results found that the majors of undergraduate students were successfully predicted by simple psycho-social factors. In addition, we found that prediction rates were affected by which type of data structure and algorithm were used. Furthermore, factors that were not statistically different between groups also played an important role in predicting the major of participants. The current study provides a framework beyond traditional statistical approaches for further research using machine learning in social science studies."
SNS 게시글과 감성분류에 기반한 다단계 노래 추천 시스템,2017,"['Sentiment Analysis', 'Sentence Similarity', 'Machine Learning', 'Song Recommendation', 'Social Network Service', '감성 분류', '문장 유사도', '기계 학습', '노래 추천', 'SNS']","소셜 네트워크 사용자가 늘어나면서 자신의 이야기를 다른 사람들과 공유하는 경우가 늘어났다. 이러한 글에는 사용자의 감성이 내재되어 있는데 이러한 특징을 분석, 활용하여 사용자의 감성에 어울리는 노래를 추천하고자 한다. 본 논문에서는 먼저, 트위터 말뭉치를 수집하여 이모티콘이나 광고 등 불필요한 데이터를 제거하는 전처리 과정을 거친 후, 단어 벡터를 생성하여 기계학습 기법 중 하나인 SVM을 이용하여 기쁨, 슬픔, 분노, 공포 등 4가지 감성을 분류하는 기계학습 모델을 구현하였다. 게시글에 적합한 감성의 노래를 추천하기 위해 추천할 노래들을 노래 가사를 기준으로 수작업으로 감성 범주에 맞게 분류하는 작업을 하였다. 이후 사용자의 트위터 글이 주어지면 이를 학습된 기계학습 모델을 이용하여 사용자의 글에 내재된 감성을 분석하여 4가지 감성 범주 가운데 하나를 선택하고, 선택된 범주에 속하는 노래 가사들을 대상으로 주어진 사용자 트위터 글과의 코사인 유사도 계산을 통해 유사도 값이 가장 높은 노래를 추천하는 방법을 제안한다.","With the increasement of social network users, SNS became common to share their stories with others. Since the SNS articles include users' emotions, songs matching a user’s emotion can be recommended by analyzing these chracteristics. In the preprocesing phase, we collected tweet corpus and removed unnecessary data such as emoticons or advertisements, and then generated sentence vectors. Afterwards, SVM, one of the most popular machine learning techniques, is used to implement classification model that categorize four sentiments which are happiness, sadness, anger and fear. To recommend the song with the right sentiment of the tweet, we manually classified lyrics of songs into 4 sentiment categories mentioned above. In the application phase, given user’s tweets, by analyzing inherent sentiment of user’s tweets, one emotional category is selected by the trained model, and finally the song to recommend is selected by calculating cosine similarities between the tweets and lyrics in the selected category."
이중 기계학습 구조를 이용한 안구이동추적 기술개발,2017,"['Eye-Tracking', 'Dual machine learning structure', 'HCI', 'PLA', 'SVR']",,"In this paper, we developed bio-signal based eye tracking system using electrooculogram (EOG) and electromyogram (EMG) which measured simultaneously from same electrodes. In this system, eye gazing position can be estimated using EOG signal and we can use EMG signal at the same time for additional command control interface. For EOG signal processing, PLA algorithms are applied to reduce processing complexity but still it can guarantee less than 0.2 seconds of reaction delay time. Also, we developed dual machine learning structure and it showed robust and enhanced tracking performances. Compare to conventional EOG based eye tracking system, developed system requires relatively light hardware system specification with only two skin contact electrodes on both sides of temples and it has advantages on application to mobile equipments or wearable devices. Developed system can provide a different UX for consumers and especially it would be helpful to disabled persons with application to orthotics for those of quadriplegia or communication tools for those of intellectual disabilities."
심층학습을 이용한 기계번역 기술과 정확도 연구,2017,"['Deep Neural Network', 'Machine Translation', 'Google Translator', 'Recurrent Neural Network', 'Autoencoder']",,"In this study, we discuss the basic technology of machine learning of the deep neural network for natural language processing(NLP). We explain the distributed vector representation of words. Distributed vector representation is proved to be able to carry semantic meanings and are useful in various NLP tasks. The recurrent neural network(RNN) is employed to get the vector representation of sentences. We discuss the RNN encoder-decoder model and some modifications of the RNN structure to improve the accuracy of the machine translations. To test and verify the accuracy of Google translator, we performed the translation among Korean, English, and Japanese, and examined the meaning change between the original and the translated sentence. In neural network translation, we showed some inaccuracies of the translation such as wrong relation between subject and object, or some omission or repetition of the original meaning. In order to increase the performance and accuracy of machine translation, it is necessary to acquire more data for training."
"TIMSS 2015 Korean Student, Teacher, and School Predictor Exploration and Identification via Random Forests",2017,"['Random forests', 'decision trees', 'machine learning', 'large-scale data', 'TIMSS', 'mathematics achievement']",,"Previous TIMSS studies have employed conventional statistical methods, focusing on selected few indicators. The purpose of this study was to explore and identify important variables to predict students’ mathematics achievement, utilizing as many student, teacher, and school variables as possible via random forests, a popular machine learning technique. TIMSS 2015 Korean 8th graders’ student, teacher, and school datasets were merged to extract important predictors for students’ mathematics achievement. The prediction accuracy, sensitivity, and specificity of the model were 78%, 83%, and 73%, respectively. Among 413 TIMSS variables explored, variables identified as having the highest variable importance were all student variables, consistent with previous research. Scientific importance of the study was discussed as well as further research topics."
클래스 불균형 데이터에 적합한 기계 학습 기반 침입 탐지 시스템,2017,"['Intrusion Detection System', 'Machine Learning', 'Imbalanced Dataset']","본 논문에서는 정상과 이상 트래픽이 불균형적으로 발생하는 상황에서 기계 학습 기반의 효과적인 침입 탐지 시스템에 관한 연구 결과를 소개한다. 훈련 데이터의 패턴을 학습하여 정상/이상 패킷을 탐지하는 기계 학습 기반의 IDS에서는 훈련 데이터의 클래스 불균형 정도에 따라 탐지 성능이 현저히 차이가 날 수 있으나, IDS 개발 시 이러한 문제에 대한 고려는 부족한 실정이다. 클래스 불균형 데이터가 발생하는 환경에서도 우수한 탐지 성능을 제공하는 기계 학습 알고리즘을 선정하기 위하여, 본 논문에서는 Kyoto 2006+ 데이터셋을 이용하여 정상 대 침입 클래스 비율이 서로 다른 클래스 불균형 훈련 데이터를 구축하고 다양한 기계 학습 알고리즘의 인식 성능을 분석하였다. 실험 결과, 대부분의 지도 학습 알고리즘이 좋은 성능을 보인 가운데, Random Forest 알고리즘이 다양한 실험환경에서 최고의 성능을 보였다.","This paper aims to develop an IDS (Intrusion Detection System) that takes into account class imbalanced datasets. For this, we first built a set of training data sets from the Kyoto 2006+ dataset in which the amounts of normal data and abnormal (intrusion) data are not balanced. Then, we have run a number of tests to evaluate the effectiveness of machine learning techniques for detecting intrusions. Our evaluation results demonstrated that the Random Forest algorithm achieved the best performances."
Gas detonation cell width prediction model based on support vector regression,2017,"['Detonation Cell Width', 'Hydrogen Safety', 'Machine Learning', 'Support Vector Regression']",,"Detonation cell width is an important parameter in hydrogen explosion assessments. The experimental data on gas detonation are statistically analyzed to establish a universal method to numerically predict detonation cell widths. It is commonly understood that detonation cell width, λ, is highly correlated with the characteristic reaction zone width, δ. Classical parametric regression methods were widely applied in earlier research to build an explicit semiempirical correlation for the ratio of λ/δ. The obtained correlations formulate the dependency of the ratio λ/δ on a dimensionless effective chemical activation energy and a dimensionless temperature of the gas mixture. In this paper, support vector regression (SVR), which is based on nonparametric machine learning, is applied to achieve functions with better fitness to experimental data and more accurate predictions. Furthermore, a third parameter, dimensionless pressure, is considered as an additional independent variable. It is found that three-parameter SVR can significantly improve the performance of the fitting function. Meanwhile, SVR also provides better adaptability and the model functions can be easily renewed when experimental database is updated or new regression parameters are considered."
다중 생체신호를 이용한 신경망 기반 전산화 감정해석,2017,"['Emotion', 'Biological Signal', 'Restricted Boltzmann Machine (RBM)', 'Multilayer Neural Network (MNN)', 'Deep Belief Network (DBN)', '감정', '생체신호']",,"Emotion affects many parts of human life such as learning ability, behavior and judgment. It is important to understand human nature. Emotion can only be inferred from facial expressions or gestures, what it actually is. In particular, emotion is difficult to classify not only because individuals feel differently about emotion but also because visually induced emotion does not sustain during whole testing period. To solve the problem, we acquired bio-signals and extracted features from those signals, which offer objective information about emotion stimulus. The emotion pattern classifier was composed of unsupervised learning algorithm with hidden nodes and feature vectors. Restricted Boltzmann machine (RBM) based on probability estimation was used in the unsupervised learning and maps emotion features to transformed dimensions. The emotion was characterized by non-linear classifiers with hidden nodes of a multi layer neural network, named deep belief network (DBN). The accuracy of DBN (about 94 %) was better than that of back-propagation neural network (about 40 %). The DBN showed good performance as the emotion pattern classifier."
Factors influencing metabolic syndrome perception and exercising behaviors in Korean adults,2017,"['Healthcare Bigdata', 'Korean Community Health Survey', 'Machine Learning', 'Metabolic Syndrome', 'XGBoost']","본 연구는 기계 학습법 중 하나인 XGBoost를 이용하여 대사증후군을 인지하고 신체활동을 수행하는 집단을 예측하고자 2014년 7월부터 2015년 12월까지 시도되었다. 이에 2009-2013년 지역사회건강조사를 연구자료로 사용하였고 370,430명의 성인을 분석에 포함하였다. 본 연구의 종속변수는 대사증후군의 인지 및 신체활동 실천정도에 따른 단계로 3단계로 구분하였다:Stage 1(무인지, 무 신체활동), Stage 2(인지, 무 신체활동), and Stage 3(인지, 신체활동). 예측변수로는 5년간의 지역사회건강조사 중 공통으로 수집된 문항으로부터 161개의 특성을 선택하였다. 자료 분석을 위해 R program을 이용하여 XGBoost 알고리즘을 적용하였다. 분석 결과 정확도는 0.735 이었으며, 가장 영향을 미치는 10개의 특성은 나이, 교육수준, 체중조절시도 경험, EQ-5D 운동능력, 영양표시 확인, 개인 건강보험가입 유무, EQ-5D 일상활동, 금연광고경험 여부, 통증유무, 당뇨에 대한 보건기관의 교육 경험 순으로 확인되었다. 본 연구결과는 XGBoost가 보건의료빅데이터를 이용한 질병의 예방과 관리에 영향을 주는 요인을 확인하는데 유용한 도구임을 보여주었다. 또한, 본 연구를 통해 대사증후군에 취약한 계층을 확인하고 이를 위한 교육프로그램 개발에 도움을 줄 수 있을 것으로 보인다.","This study was conducted to determine which factors would predict metabolic syndrome (MetS) perception and exercise by applying a machine learning classifier, or Extreme Gradient Boosting algorithm (XGBoost) from July 2014 to December 2015. Data were obtained from the Korean Community Health Survey (KCHS), representing different community-dwelling Korean adults 19 years and older, from 2009 to 2013. The dataset includes 370,430 adults. Outcomes were categorized as follows based on the perception of MetS and physical activity (PA): Stage 1 (no perception, no PA), Stage 2 (perception, no PA), and Stage 3 (perception, PA). Features common to all questionnaires for the last 5 years were selected for modeling. Overall, there were 161 features, categorical except for age and the visual analogue scale (EQ-VAS). We used the Extreme Boosting algorithm in R programming for a model to predict factors and achieved prediction accuracy in 0.735 submissions. The top 10 predictive factors in Stage 3 were: age, education level, attempt to control weight, EQ mobility, nutrition label checks, private health insurance, EQ-5D usual activities, anti-smoking advertising, EQ-VAS, education in health centers for diabetes, and dental care. In conclusion, the results showed that XGBoost can be used to identify factors influencing disease prevention and management using healthcare bigdata."
"Text Classification for Patents: Experiments with Unigrams, Bigrams and Different Weighting Methods",2017,"['Data Mining', 'Patent Classification', 'Information Retrieval', 'Machine Learning', 'Support Vector Machine (SVM)', 'Supervised Weighting Scheme', 'Noun Phrase Extraction', 'Bag of Words']",,"Patent classification is becoming more critical as patent filings have been increasing over the years. Despite comprehensive studies in the area, there remain several issues in classifying patents on IPC hierarchical levels. Not only structural complexity but also shortage of patents in the lower level of the hierarchy causes the decline in classification performance. Therefore, we propose a new method of classification based on different criteria that are categories defined by the domain's experts mentioned in trend analysis reports, i.e. Patent Landscape Report (PLR). Several experiments were conducted with the purpose of identifying type of features and weighting methods that lead to the best classification performance using Support Vector Machine (SVM). Two types of features (noun and noun phrases) and five different weighting schemes (TF-idf, TF-rf, TF-icf, TF-icf-based, and TF-idcef-based) were experimented on."
Prediction of Metal Ion Binding Sites in Proteins from Amino Acid Sequences by Using Simplified Amino Acid Alphabets and Random Forest Model,2017,"['amino acid sequence', 'binding sites', 'machine learning', 'proteins']",,"Metal binding proteins or metallo-proteins are important for the stability of the protein and also serve as co-factors in various functions like controlling metabolism, regulating signal transport, and metal homeostasis. In structural genomics, prediction of metal binding proteins help in the selection of suitable growth medium for overexpression’s studies and also help in obtaining the functional protein. Computational prediction using machine learning approach has been widely used in various fields of bioinformatics based on the fact all the information contains in amino acid sequence. In this study, random forest machine learning prediction systems were deployed with simplified amino acid for prediction of individual major metal ion binding sites like copper, calcium, cobalt, iron, magnesium, manganese, nickel, and zinc."
네트워크 트래픽 수집 및 복원을 통한 내부자 행위 분석 프레임워크 연구,2017,"['Cyber', 'Insider Threat', 'Behavior Analysis', 'Machine Learning']",,"In this paper, we developed a framework to detect and predict insider information leakage by collecting and restoring network traffic. For automated behavior analysis, many meta information and behavior information obtained using network traffic collection are used as machine learning features. By these features, we created and learned behavior model, network model and protocol-specific models. In addition, the ensemble model was developed by digitizing and summing the results of various models. We developed a function to present information leakage candidates and view meta information and behavior information from various perspectives using the visual analysis. This supports to rule-based threat detection and machine learning based threat detection. In the future, we plan to make an ensemble model that applies a regression model to the results of the models, and plan to develop a model with deep learning technology."
Prediction of Metal Ion Binding Sites in Proteins from Amino Acid Sequences by Using Simplified Amino Acid Alphabets and Random Forest Model,2017,"['amino acid sequence', 'binding sites', 'machine learning', 'proteins']",,"Metal binding proteins or metallo-proteins are important for the stability of the protein and also serve as co-factors in various functions like controlling metabolism, regulating signal transport, and metal homeostasis. In structural genomics, prediction of metal binding proteins help in the selection of suitable growth medium for overexpression's studies and also help in obtaining the functional protein. Computational prediction using machine learning approach has been widely used in various fields of bioinformatics based on the fact all the information contains in amino acid sequence. In this study, random forest machine learning prediction systems were deployed with simplified amino acid for prediction of individual major metal ion binding sites like copper, calcium, cobalt, iron, magnesium, manganese, nickel, and zinc."
Pet Shop Recommendation System based on Implicit Feedback,2017,"['기계 학습', '추천 시스템', '암묵적 피드백', '상품 클릭 정보', 'Machine learning', 'Recommendation systems', 'Implicit feedback', 'Click information on items']",,"Due to the advances in machine learning and artificial intelligence technologies, many new services have become available. Among such services, recommendation systems have already been successfully applied to commercial services and made profits as in online shopping malls. Most recommendation algorithms in commercial services are based on content analysis or explicit feedback rates as in movie recommendations. However, many online shopping malls have difficulties in content analysis or are lacking explicit feedbacks on their items, which results in no recommendation system for their items. Even for such service systems, user log data is easily available, and if recommendations are possible with such log data, the quality of their service can be improved. In this paper, we extract implicit feedback like click information for items from log data and provide a recommendation system based on the implicit feedback. The proposed system is applied to a real in-service online shopping mall."
A Study of Model Selection for Electric Data using Cross Validation Approach,2017,"['Model selection', 'K-fold cross validation', 'Machine learning', 'Model fit', 'Electric power']",,"In this paper, the appropriate model is selected for the risk assessment of the electric utility pole data with the help of cheat sheets and k-fold cross validation. In order to analyze, predict and forecast the data, the appropriate model has to be selected. The major issue is the declination of the accuracy in the model fitting, which may result in poor model selection. There are different type of machine learning algorithm, which makes it difficult to conclude the model selection. To ensure the proper selection of the model, we undergo a two-step process. Firstly, the basic model is selected with the existing model selection cheat sheets named as Scikit learn and Microsoft azure, by understanding the available input and required output of the data. After getting through the multiple question, the respective models such as Generalized Additive Model, Generalized Linear Model, Linear Regression and Support Vector Machine are obtained. In order to attain the appropriate model, we perform k-fold cross validation to estimate the risk of the algorithms, by comparing 2-fold, 8-fold and 10-fold cross validation. Between the three set, the 10-cross fold validation of generalized additive model is selected with the least risk error. Using k-fold cross validation, we estimate the accuracy of the model that is suitable for the data, by using the electric power data set."
P2P 봇넷 탐지 연구의 비교 및 분석,2017,"['P2P botnet detection', 'life cycle', 'machine learning', 'data sets']",,"In this paper, we propose our four-phase life cycle of P2P botnet with corresponding detection methods and the future direction for more effective P2P botnet detection. Our proposals are based on the intensive analysis that compares existing P2P botnet detection schemes in different points of view such as life cycle of P2P botnet, machine learning methods for data mining based detection, composition of data sets, and performance matrix. Our proposed life cycle model composed of linear sequence stages suggests to utilize features in the vulnerable phase rather than the entire life cycle. In addition, we suggest the hybrid detection scheme with data mining based method and our proposed life cycle, and present the improved composition of experimental data sets through analysing the limitations of previous works."
Development of a Stress Classification Model Using Deep Belief Networks for Stress Monitoring,2017,"['Stress', 'Stress Classification Model', 'Deep Belief Network', 'Machine Learning', 'KNHANES']",,"Objectives: Stress management is related to public healthcare and quality of life; an accurate stress classification method is necessary for the design of stress monitoring systems. Therefore, the goal of this study was to design a novel stress classification model using a deep learning method. Methods: In this paper, we present a stress classification model using the dataset from the sixth Korea National Health and Nutrition Examination Survey conducted from 2013 to 2015 (KNHANES VI) to analyze stress-related health data. Statistical analysis was performed to identify the nine features of stress detection, and we evaluated the performance of the proposed stress classification by comparison with several stress detection models. The proposed model was also evaluated using Deep Belief Networks (DBN). Results: We designed profiles depending on the number of hidden layers, nodes, and hyper-parameters according to the loss function results. The experimental results showed that the proposed model achieved an accuracy and a specificity of 66.23% and 75.32%, respectively. The proposed DBN model performed better than other classification models, such as support vector machine, naive Bayesian classifier, and random forest. Conclusions: The proposed model in this study was demonstrated to be effective in classifying stress detection, and in particular, it is expected to be applicable for stress prediction in stress monitoring systems."
기계학습 방법에 기반 한 불균형 침입탐지 데이터 분류법의 성능평가에 관한 연구,2017,"['침입탐지', '기계학습', '데이터 전처리', '희소 클래스', 'IDS', 'Machine Learning', 'Data Preprocessing', 'Rare Class']","본 논문에서는 침입탐지 데이터셋을 사용하여 이상 행위를 탐지하고 데이터 전처리 과정의 효율성을 높이기 위해 훈련 데이터의 클래스 비율을 조절한다. 제안 방법의 성능을 입증하기 위해 머신러닝 알고리즘들을 사용하여 비교 실험을 한다. 일반적으로 머신러닝을 기반으로 한 분류 알고리즘을 적용할 때 클래스의 크기는 분류에 많은 영향을 끼친다. 주요 클래스 크기가 희소 클래스에 비해 많이 큰 경우에는 주요 클래스로만 분류되는 경향이 있다. 희소 클래스의 비율이 최소 0.5% 이상 되도록 유지하고, 희소 클래스의 분류 효율을 높일 수 있는 적절한 비율을 찾고자 한다. 기존 데이터에 랜덤성을 부여하여 희소 클래스들의 수를 증가시키는 SMOTE (Synthetic Miniority Over-sampling TEchnique) 기법을 사용한다. 실험에 사용한 KDD CUP 1999 데이터셋은 R2L과 U2R 공격 유형에 해당하는 클래스의 수가 매우 적어서 높은 분류 효율을 내기 어려운 점이 있다. 본 연구에서는 여러 클래스들 간의 관계 및 분포를 분석한 후, 주요 클래스와 희소 클래스의 비중을 조절하는 방법을 사용하여 분류 효율을 개선하였다. 특히, 희소 클래스의 탐지 여부에 높은 비중을 두면서 전체적인 분류 성능을 개선하고자 하였다. 훈련 데이터셋의 희소 클래스인 U2R, R2L 및 Probe를 각각 120배, 9배, 1.5배 증가시킨 recall 실험 결과에서, k-NN 실험에 대해 U2R 클래스의 경우 0.11, R2L 클래스의 경우 0.02의 성능 향상을 보였다. SVM 실험에서 U2R 클래스의 경우 0.02, R2L 클래스의 경우 0.08의 성능 향상을 보였으며, 의사결정트리 실험에서는 U2R 클래스의 경우에 0.25의성 능 향상을 보였다.","In this paper, we adjusted the class distribution of train data to increase efficiency in data pre-processing and detect anomalies in an intrusion detection dataset. We conduct an experiment with machine learning algorithms to prove the efficiency of our proposed methods. In general, when using machine learning algorithms, volume of class influences on the results of classification. When the volume of majority classes is larger than that of minority classes, most of samples tend to vote the majority class. We hold the proportion of each rare class to be 0.5% at least, and try to find the proper proportion of rare classes. SMOTE (Synthetic Minority Over-sampling TEchnique) was used to increase the number of instances of rare class. It is difficult to improve the efficiency of classification because KDD CUP 1999 dataset, which are used to our tests, have rare classes such as R2L and U2R. In our research, we analyze various classes and enhance the efficiency of clasfsiciation by adjusting the volume of rare classes. We attempt tiomprove the performance of classification focusing on the rare classes such as U2R, R2L and Probe. The number of instances of U2R, R2L and Probe class in the train data was increased by 12-fold, 9-fol da,nd 1.5 fold, respectively. Recall metrics okf -NN tests went up to 0.11 in U2R class and 0.02 in R2L class. Recall metrics of SVM tests went up to 0.02 in U2R class and 0.08 in R2L class, and those of decision tree tests went up to 0.25."
Multi-task Convolutional Neural Network System for License Plate Recognition,2017,"['Deep convolutional neural network', 'license plate recognition', 'machine learning', 'multi task learning']",,"License plate recognition is an active research field as demands sharply increase with the developmentof Intelligent Transportation System (ITS). However, since the license plate recognition(LPR) is sensitive to theconditions of the surrounding environment such as a complicated background in the image, viewing angle andillumination change, it is still difficult to correctly recognize letters and digits on LPR. This study applies DeepConvolutional Neural Network (DCNN) to the license plate recognition. The DCNN is a method of which theperformance has recently been proven to have an excellent generalization error rate in the field of image recognition.The proposed layer structure of the DCNN used in this study consists of a combination of a layer for judging theexistence of a license plate and a layer for recognizing digits and characters. This learning method is based on Multi-Task Learning (MTL). Through experiments using real images, this study shows that this layer structure classifiesdigits and characters more accurately than the DCNN using a conventional layer does. We also use artificial imagesgenerated directly for training model."
"Text Classification for Patents : Experiments with Unigrams, Bigrams and Different Weighting Methods",2017,"['Data Mining', 'Patent Classification', 'Information Retrieval', 'Machine Learning', 'Support Vector Machine (SVM)', 'Supervised Weighting Scheme', 'Noun Phrase Extraction', 'Bag of Words']",,"Patent classification is becoming more critical as patent filings have been increasing over the years. Despite comprehensive studies in the area, there remain several issues in classifying patents on IPC hierarchical levels. Not only structural complexity but also shortage of patents in the lower level of the hierarchy causes the decline in classification performance. Therefore, we propose a new method of classification based on different criteria that are categories defined by the domain’s experts mentioned in trend analysis reports, i.e. Patent Landscape Report (PLR). Several experiments were conducted with the purpose of identifying type of features and weighting methods that lead to the best classification performance using Support Vector Machine (SVM). Two types of features (noun and noun phrases) and five different weighting schemes (TF-idf, TF-rf, TF-icf, TF-icf-based, and TF-idcef-based) were experimented on."
IoT 디바이스에서 다차원 디지털 신호 처리를 위한 신경망 최적화,2017,"['신경망', '이엘엠', '기계학습', '아두이노', 'Neural Network', 'Extreme Learning Machine', 'Machine Learning', 'Arduino']",,
기계학습 기반 저 복잡도 긴장 상태 분류 모델,2017,"['Classification model', 'Human anxiety', 'Complexity', 'Machine learning', 'Support vector machine']",,"Recently, services for personal biometric data analysis based on real-time monitoring systems has been increasing and many of them have focused on recognition of emotions. In this paper, we propose a classification model to classify anxiety emotion using biometric data actually collected from people. We propose to deploy the support vector machine to build a classification model. In order to improve the classification accuracy, we propose two data pre-processing procedures, which are normalization and data deletion. The proposed algorithms are actually implemented based on Real-time Traffic Flow Measurement structure, which consists of data collection module, data preprocessing module, and creating classification model module. Our experiment results show that the proposed classification model can infers anxiety emotions of people with the accuracy of 65.18%. Moreover, the proposed model with the proposed pre-processing techniques shows the improved accuracy, which is 78.77%. Therefore, we can conclude that the proposed classification model based on the pre-processing process can improve the classification accuracy with lower computation complexity."
기계학습 기반의 영화흥행예측 방법 비교: 인공신경망과 의사결정나무를 중심으로,2017,"['predicting movie success', 'linear regression analysis', 'machine learning', 'artificial neural network', 'decision tree', '영화흥행예측', '선형회귀분석', '기계학습', '인공신경망', '의사결정나무']","본 연구는 영화산업의 가치사슬단계에 따라 각 단계에서 고려할 수 있는 변인을 활용하여 제작/투자, 배급, 상영단계별 모형을 구성하였다. 모형의 예측력을 높이기 위해 회귀분석으로 유의미한 변인을 도출하여 모형을 추가로 설정하였다. 주어진 변인을 바탕으로 기계학습 분석방법인 인공신경망과 의사결정나무 분석방법 간의 예측력 차이를 비교하였다. 분석 결과, 제작/투자 모형과 배급 모형에서 모든 변인을 투입했을 때는 인공신경망의 정확도가 의사결정나무보다 높았으나, 회귀분석결과에 따라 선정된 변인을 투입하였을 때는 의사결정나무의 정확도가 더 높았다. 상영 모형에서는 회귀분석결과의 반영여부와 관계없이 인공신경망의 정확도가 의사결정나무의 정확도보다 높게 나타났다. 본 논문은 영화흥행 예측연구에 기계학습기법을 적용하여 예측성과가 향상됨을 확인하였다는데 의의가 있다. 선형회귀분석 결과를 기계학습기법에 반영함으로써 기존의 선형적 분석방법의 한계를 극복하고자 하였다.","In this paper, we constructed the model of production/investment, distribution, and screening by using variables that can be considered at each stage according to the value chain stage of the movie industry. To increase the predictive power of the model, a regression analysis was used to derive meaningful variables. Based on the given variables, we compared the difference in predictive power between the artificial neural network, which is a machine learning analysis method, and the decision tree analysis method. As a result, the accuracy of artificial neural network was higher than that of decision trees when all variables were added in production/ investment model and distribution model. However, decision trees were more accurate when selected variables were applied according to regression analysis results. In the screening model, the accuracy of the artificial neural network was higher than the accuracy of the decision tree regardless of whether the regression analysis result was reflected or not. This paper has an implication which we tried to improve the performance of movie prediction model by using machine learning analysis. In addition, we tried to overcome a limitation of linear approach by reflecting the results of regression analysis to ANN and decision tree model."
게임 유용성 평가에 미치는 요인에 관한 연구: 스팀(STEAM) 게임 리뷰데이터 분석,2017,"['Game Review', 'STEAM', 'Helpfulness', 'Big Data', 'Machine Learning']","인터넷 환경의 발달로 소비자들 사이에 상품정보에 대한 의견이 교환되기 시작하면서 다양한 형식의 온라인 리뷰들이 급속도로 생성되고 있다. 이러한 추세에 따라, 기업들은 온라인 리뷰들 을 분석하여 마케팅, 세일즈, 제품개발 등의 다양한 기업 활동에서 그 결과를 활용하려는 노력 을 진행하고 있다. 그러나 대표적인 경험재인 ‘게임’과 관련된 산업에서의 온라인 리뷰에 대한 연구는 매우 부족한 실정이다. 이에 본 연구는 머신러닝 모델을 활용하여 스팀(STEAM)게임의 커뮤니티 데이터를 분석하였다. 이를 통해 타 사용자의 게임 리뷰를 유용하다고 판단하는데 영 향을 미치는 요인을 분석하고, 리뷰의 유용성을 예측하는데 있어 가장 우수한 성능을 보인 모 델과 변수들을 도출하여 사용자의 충성도와 사용성을 증대시키기 위한 제안을 하고자 한다.","With the development of the Internet environment, various types of online reviews are being generated and exchanged among consumers to share their opinions. In line with this trend, companies are making efforts to analyze online reviews and use the results in various business activities such as marketing, sales, and product development. However, research on online review in industry related to 'Video Game' which is representative experience goods has not been performed enough. Therefore, this study analyzed STEAM community review data using machine learning techniques. We analyzed the factors affecting the opinion of other users' game review. We also propose managerial implications to incease user loyalty and usability."
"인공지능 알고리즘의 편향성, 불투명성이 법적 의사결정에 미치는 영향 및 규율 방안",2017,"['인공지능 알고리즘', '법적 의사결정', '차별', '재범의 위험성', '예측 모델', '범죄예측', '머신러닝', '불투명성', '편향성', 'Artificial intelligence Algorithms', 'Legal Decision making', 'Discrimination', 'Recidivism risk', 'Predictive Model', 'Machine learning', 'Opacity', 'Bias']",,"In the field of law, artificial intelligence is being explored in various forms. Especially, machine learning is leading the destructive innovation in the field of law as the artificial intelligence becomes popular. There are also concerns that artificial intelligence may be mentioned as a singular phenomenon that transcends human intelligence, that many jobs are lost due to artificial intelligence, or that artificial intelligence is a threat to the survival of mankind. However, it is easy to overlook the fact that artificial intelligence is already operating in reality, and that artificial intelligence, in particular, plays a role in human decision-making. US police have long been engaged in crime prevention activities using artificial intelligence-based crime prediction techniques and have achieved considerable achievements such as reduced crime rates. In the judiciary, for example, probation, bail, and even judgment, models to predict recidivism is widely used. Although it is thought that decision making such as prediction by artificial intelligence will be free from objectivity and prejudice unlike human decision which is influenced by subjectivity, it is surprisingly revealed that decision making by artificial intelligence is biased and particularly discriminatory. The biased nature of decision making by artificial intelligence and its discriminatory results are likely to undermine the social value of prohibiting discrimination. Therefore, the countermeasures against various problems of decision making by artificial intelligence such as biased problems include not only posterior discipline that corrects differential results, but also generation of differential results in the design, implementation, and performance evaluation of artificial intelligence decision tools. There is also a great need for pre-regulation to block in advance.Especially in the public domain, such as legal decision making by artificial intelligence algorithms, there is a need for a different approach to individual remediation in the private domain, where decision making has a wide range of influences. Rather than seeking redress, it seems effective to block the source of the algorithm elements that can bring discriminative effects in the decision making process. Among these precautionary measures, legality control through prior control of the development process and approval of use is a priority. It is necessary to introduce the concept of ethical design to the pre-control of the development process. It must be ensured that the artificial intelligence algorithm operates in accordance with the ethical standards beyond the merit of being operated by the designer`s intention. Furthermore, before using artificial intelligence algorithms, it is necessary to perform static analysis, which is an algorithm code oriented analysis, and dynamic analysis, which examines the operation process of an actual algorithm. Furthermore, when artificial intelligence algorithms are used, there is a problem that automation of decisions is made so that no one is responsible for the risks or mistakes caused by decisions. Therefore, human intervention in the decision-making process is necessary in order to provide normative grounds for legal decision making and to clarify the responsible party. In addition to these pre-regulations, the resolution of the opacity of artificial intelligence algorithms should also be included in the larger picture of the discipline."
Mini-batch bagging and attribute ranking for accurate user authentication in keystroke dynamics,2017,"['Keystroke dynamics', 'Mini-batch', 'Bagging', 'Attribute ranking', 'One-class na&iuml']",,"<P><B>Abstract</B></P>  <P>We consider the problem of differentiating users’ typing behavior patterns using machine learning algorithms with keystroke dynamics features. We have proposed mini-batch bagging (MINIBAG) method and attribute ranking of one-class naïve Bayes (AR-ONENB) algorithm. MINIBAG is motivated from bagging because MINIBAG chunks each attribute of the dataset into multiple sub-datasets during the preprocessing phase. Meanwhile, AR-ONENB sorts the attributes based on the time length during the preprocessing phase for effective classification. Both proposed algorithms have shown promising experimental results from various keystroke dynamics based user authentication benchmark tests. From the experimental results, it can be seen that MINIBAG facilitates machine learning algorithms to have an ensemble of multiple models from mini-batches. AR-ONENB, on the other hands, calculates log-likelihood value from keystroke index order for anomaly estimation, which exploits the observation that the user’s typing speed is unique.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We have proposed mini-batch bagging (MINIBAG) method and attribute ranking of one-class naïve Bayes (AR-ONENB) algorithm. </LI> <LI>  We have presented attribute-by-attribute data fragmentation technique which is used in MINIBAG method. </LI> <LI>  MINIBAG facilitates machine learning algorithms to have an ensemble of multiple models from mini-batches. </LI> <LI>  We have introduced a new feature, keystroke index order, based on the typing speed of a user in AR-ONENB algorithm. </LI> <LI>  Rate of difference of the rate of mean produces a reliable prediction to the result. </LI> </UL> </P>"
앙상블 학습을 사용한 RF 위협체 역추정 모델의 성능평가,2017,"['전자전', '레이더 위협', '앙상블학습', '역추정 정확도', 'Electronic Warfare', 'Radar Threats', 'Ensemble Learning', 'Accuracy of Reverse Extrapolation']","본 논문에서는 앙상블 학습 기법을 이용하여 전자파 신호를 발산하는 RF(Radio Frequency) 위협체를 역추정하 는 방법에 관하여 논한다. 기존 연구에서 레이더 위협을 생성하고 실제 전자전 상황을 모델링 할 수 있는 시뮬레이 터에 대하여 연구 및 구현하였다. 개발 중인 전자전 시뮬레이터는 다양한 기계학습 알고리즘을 통하여 생성한 모델 을 사용하여 RF 위협체에 대한 역추정 정확도를 실시간으로 제시한다. 본 논문은 구현한 시뮬레이터를 활용하여 RF 위협체의 수집신호변수를 생성 및 수신하며, 앙상블 학습 기법을 이용하여 생성한 역추정 모델에 의하여 위협체 를 역으로 식별하는 방법을 제안한다. 실험에서 다양한 기계학습 알고리즘으로 생성한 모델과 메타 학습 방법론인 앙상블 학습 기법을 적용한 모델을 이용하여 RF 위협체에 대한 역추정 정확도를 측정하고 실험결과를 분석하였다.","In this paper, we discuss a method using an ensemble learning technique for the reverse extrapolation of RF (Radio Frequency) threats that emit electromagnetic signals. We have studied and implemented a simulator that is capable of generating radar threats and modeling the actual electronic warfare situations. The simulator presents the reverse extrapolation accuracy of RF threats in real time. Based upon the electronic warfare signal variables of RF threats in our simulator, we propose a method to reversely identify RF threats through models compiled using ensemble learning techniques. We have measured and analyzed the reverse extrapolation accuracy of the models of RF threats, which are generated by basic machine learning algorithms and by ensemble learning algorithms as a meta-learning framework."
RGB-D 정보를 이용한 객체 탐지 기반의 신체 키포인트 검출 방법,2017,"['Video Surveillance', 'Object Detection', 'Body Keypoint Localization', 'Convolutional Pose Machines', 'Belief Map', 'Human Activity Recognition', '영상감시', '객체 탐지', '신체 키포인트 검출', '컨볼루셔널 포즈 머신', '신념 지도', '인간 행위 인식']","최근 영상감시 분야에서는 영상에서 움직이는 사람을 탐지하고, 탐지된 사람의 행위를 분석하는 방식에 딥러닝 기반 학습방법이적용되기 시작했다. 이러한 지능형 영상분석 기술을 적용할 수 있는 분야 중 하나인 인간 행위 인식은 객체를 탐지하고 탐지된 객체의 행위를 인식하기 위해 신체 키포인트를 검출 하는 과정을 거치게 된다. 본 논문에서는 RGB-D 정보를 이용한 객체 탐지 기반의신체 키포인트 검출 방법을 제시한다. 먼저, 두 대의 카메라로 생성된 색상정보와 깊이정보를 이용하여 이동하는 객체를 배경으로부터 분할하여 탐지한다. RGB-D 정보를 이용하여 탐지된 객체의 영역을 재조정하여 생성된 입력 데이터를 한 사람의 자세 추정을 위한Convolutional Pose Machines(CPM)에 적용한다. CPM을 이용하여 한 사람당 14개의 신체부위에 대한 신념 지도(Belief Map)를 생성하고, 신념 지도를 기반으로 신체 키포인트를 검출한다. 이와 같은 방법은 키포인트를 검출할 객체에 대한 정확한 영역을 제공하게 되며, 개별적인 신체 키포인트의 검출을 통하여 단일 신체 키포인트 검출에서 다중 신체 키포인트 검출로 확장 할 수 있다. 향후, 검출된 키포인트를 이용하여 인간 자세 추정을 위한 모델을 생성할 수 있으며 인간 행위 인식 분야에 기여 할 수 있다.","Recently, in the field of video surveillance, a Deep Learning based learning method has been applied to a method of detecting a moving person in a video and analyzing the behavior of a detected person. The human activity recognition, which is one of the fields this intelligent image analysis technology, detects the object and goes through the process of detecting the body keypoint to recognize the behavior of the detected object. In this paper, we propose a method for Body Keypoint Localization based on Object Detection using RGB-D information. First, the moving object is segmented and detected from the background using color information and depth information generated by the two cameras. The input image generated by rescaling the detected object region using RGB-D information is applied to Convolutional Pose Machines for one person's pose estimation. CPM are used to generate Belief Maps for 14 body parts per person and to detect body keypoints based on Belief Maps. This method provides an accurate region for objects to detect keypoints an can be extended from single Body Keypoint Localization to multiple Body Keypoint Localization through the integration of individual Body Keypoint Localization. In the future, it is possible to generate a model for human pose estimation using the detected keypoints and contribute to the field of human activity recognition."
휴대형 근적외선/가시광선 분광기를 이용한 의약품 분류기법,2017,"['NIR(Near Infra-Rred)', 'Spectrometer', 'SVM(Support Vector Machine)', 'Machine Learning', 'Confusion Matrix']","의약품은 인간의 건강 및 생명과 밀접한 관련이 있기 때문에 증상에 맞는 의약품을 처방받아 복용하는 것은 매우 중요한 문제이다. 더욱이 세계적으로 위조 의약품이 증가하는 상황에서 정품 의약품들을 정확하게 분류하는 기술은 점점 중요해진다. 그러나 의약품을 제대로 분류할 수 있는 전문적인 지식을 갖춘 인력이 제한적이라는 측면에서 의약품을 자동적으로 분류하는 기술이 필요하다. 본 논문에서는 휴대용 분광기를 이용하여 의약품의 근적외선 및 가시광선 스펙트럼을 추출하고, Support Vector Machine(SVM) 기법을 이용하여 추출한 스펙트럼 데이터를 학습시켜 분류하는 방법을 제안하였다. 모의실험을 통해 근적외선과 가시광선 스펙트럼 데이터를 사용하여 6종의 의약품을 학습시키고 분류하였을 때 평균적으로 99.9 %의 정확도를 얻었다. 또한 본 논문에서는 위조 의약품 검출을 위한 2단계 SVM 분류 기법을 제안하였으며, 이를 통해 정품과 위조 의약품을 구분하는 정확도가 향상되고, 처리속도가 개선되는 것을 확인하였다.","It is important to prescribe and take medicines that are appropriate for symptoms, since medicines are closely related to human health and life. Moreover, it becomes more important to accurately classify genuine medicines with counterfeit, since the number of counterfeit increases worldwide. However, the number of high-quality experts who have enough experience to properly classify them is limited and there exists a need for the automatic technique to classify medicine tablets. In this paper, we propose a method to classify the tablets by using a handheld spectrometer which provides both Near Infra-Red (NIR) and visible light spectrums. We adopted Support Vector Machine(SVM) as a machine learning algorithm for tablet classification. As a result of the simulation, we could obtain the classification accuracy of 99.9 % on average by using both NIR and visible light spectrums. Also, we proposed a two-step SVM approach to discriminate the counterfeit tablets from the genuine ones. This method could improve both the accuracy and the processing time."
RBM을 이용한 언어의 분산 표상화,2017,"['연결주의 모델링', '지역 표상', '분산 표상', '제한된 볼츠만 머신', 'connectionist modeling', 'localist representation', 'distributed representation', 'restricted Boltzmann machine']","연결주의 모델은 계산주의적 관점에서 언어 처리를 연구하는 한 가지 접근법이다. 그리고 연결주의 모델연구를 진행하는데 있어서 표상(representation)을 구축하는 것은, 모델의 학습 수준 및 수행 능력을 결정한다는 점에서 모델의 구조를 만드는 것만큼이나 중요한 일이다. 연결주의 모델은 크게 지역 표상(localist representation)과 분산 표상(distributed representation)이라는 두 가지 서로 다른 방식으로 표상을 구축해 왔다. 하지만 종래 연구들에서 사용된 지역 표상은 드문 목표 활성화 값을 갖고 있는 출력층의 유닛이 불활성화 하는 제한점을, 그리고 과거의 분산 표상은 표상된 정보의 불투명성에 의한 결과 확인의 어려움이라는 제한점을 갖고 있었으며 이는 연결주의 모델 연구 전반의 제한점이 되어 왔다. 본 연구는 이와 같은 과거의 표상 구축의 제한점에 대하여, 제한된 볼츠만 머신(restricted Boltzmann machine)이 갖고 있는 특징인 정보의 추상화를 활용하여 지역 표상을 가지고 분산 표상을 유도하는 새로운 방안을 제시하였다. 결과적으로 본 연구가 제안한 방법은 정보의 압축과 분산 표상을 지역 표상으로 역변환하는 방안을 활용하여 종래의 표상 구축 방법이 갖고 있는 문제를 효과적으로 해결함을 보였다.","The connectionist model is one approach to studying language processing from a computational perspective. And building a representation in the connectionist model study is just as important as making the structure of the model in that it determines the level of learning and performance of the model. The connectionist model has been constructed in two different ways: localist representation and distributed representation. However, the localist representation used in the previous studies had limitations in that the unit of the output layer having a rare target activation value is inactivated, and the past distributed representation has the limitation of difficulty in confirming the result by the opacity of the displayed information. This has been a limitation of the overall connection model study. In this paper, we present a new method to induce distributed representation with local representation using abstraction of information, which is a feature of restricted Boltzmann machine, with respect to the limitation of such representation of the past. As a result, our proposed method effectively solves the problem of conventional representation by using the method of information compression and inverse transformation of distributed representation into local representation."
생체신호를 활용한 학습기반 영유아 스트레스 상태 식별 모델 연구,2017,"['생체신호', '기계학습', '스트레스 상태 식별', '데이터마이닝', '데이터분석', 'Bio-signals', 'Machine Learning', 'Stress Status Identification', 'Data Mining', 'Data Analysis']",오늘날 감정 표현이 서툰 영유아가 처한 극도의 스트레스 상태를 자동적으로 파악하는 것은 영유아의 안전을 위협하며 지속적으로 발생하는 위험 상황의 실시간적인 인지를 위해 반드시 필요한 기술이다. 따라서 본 논문에서는 생체신호를 활용하여 영유아의 스트레스 상태를 분류하기 위한 기계학습 기반의 모델과 생체신호 수집용 스마트 밴드 및 모니터링용 모바일 어플리케이션을 제안한다. 구체적으로 본 연구에서는 영유아의 감정을 나타내는 주요한 요인이 되는 음성 및 심박 데이터의 조합을 활용하여 기존에 널리 알려진 데이터 마이닝 기법을 통해 영유아의 스트레스 상태 패턴을 학습하고 예측한다. 본 연구를 통해 생체신호를 활용하여 영유아의 스트레스 상태 식별을 자동화할 수 있는 가능성을 확인하였으며 나아가서 궁극적으로 영유아의 위험 상황 예방에 활용될 수 있을 것으로 기대된다.,"Recently, identification of the extremely stressed condition of children is an essential skill for real-time recognition of a dangerous situation because incidents of children have been dramatically increased. In this paper, therefore, we present a model based on machinelearning techniques for stress status identification of a child by using bio-signals such as voice and heart rate that are major factors for presenting a child’s emotion. In addition, a smart band for collecting such bio-signals and a mobile application for monitoring child’s stress status are also suggested. Specifically, the proposed method utilizes stress patterns of children that are obtained in advance for the purpose of training stress status identification model. Then, the model is used to predict the current stress status for a child and is designed based on conventional machine learning algorithms. The experiment results conducted by using a real-world dataset showed that the possibility of automated detection of a child’s stress status with a satisfactory level of accuracy. Furthermore, the research results are expected to be used for preventing child’s dangerous situations."
전통문화 콘텐츠 표준체계를 활용한 자동 텍스트 분류 시스템,2017,"['텍스트 분류', '빅데이터', '지도 학습', '기계학습', '자연어처리', 'Text Classification', 'Big Data', 'Supervised Learning', 'Machine Learning', 'Natural Language Processing']","한국 문화의 역사, 전통과 관련된 디지털 웹 문서가 증가하게 되었다. 하지만 창작자 또는 전통 문화와 관련된 소재를 찾는 사용자들은 정보를 검색해도 결과가 충분하지 않았으며 원하는 정보를 얻지 못하는 경우가 나타나고 있다. 이런 효과적인 정보를 접하기 위해서는 문서 분류가 필요하다. 과거에 문서 분류는 작업자가 수작업으로 문서 분류하여 시간과 비용이 많이 소비하는 어려움이 있었지만, 최근 기계학습 기반으로 한 자동 문서 분류를 통해 효율적인 문서 분류가 이루어진다. 이에 본 논문은 전통문화 콘텐츠를 체계적인 분류체계로 구성한 한민족정보문화마당 데이터를 기반으로 전통문화 콘텐츠 자동 텍스트 분류 모델을 개발한다. 본 연구는 한민족정보문화마당 텍스트 데이터에 대해 단어 빈도수를 추출하기 위해 TF-IDF모델, Bag-of-Words 모델, TF-IDF/Bag-of-Words를 결합한 모델을 적용하여 각각 SVM 분류 알고리즘을 사용하여 전통문화 콘텐츠 자동 텍스트 분류 모델을 개발하여 성능평가를 확인하였다.","The Internet have increased the number of digital web documents related to the history and traditions of Korean Culture. However, users who search for creators or materials related to traditional cultures are not able to get the information they want and the results are not enough. Document classification is required to access this effective information. In the past, document classification has been difficult to manually and manually classify documents, but it has recently been difficult to spend a lot of time and money. Therefore, this paper develops an automatic text classification model of traditional cultural contents based on the data of the Korean information culture field composed of systematic classifications of traditional cultural contents. This study applied TF-IDF model, Bag-of-Words model, and TF-IDF/Bag-of-Words combined model to extract word frequencies for 'Korea Traditional Culture' data. And we developed the automatic text classification model of traditional cultural contents using Support Vector Machine classification algorithm."
Automatic Detection of Sleep Stages based on Accelerometer Signals from a Wristband,2017,"['Artificial Intelligence', 'Pattern recognition and classification', 'Signal processing']",,"In this paper, we suggest an automated sleep scoring method using machine learning algorithms on accelerometer data from a wristband device. For an experiment, 36 subjects slept for about eight hours while polysomnography (PSG) data and accelerometer data were simultaneously recorded. After the experiments, the recorded signals from the subjects were preprocessed, and significant features for sleep stages were extracted. The extracted features were classified into each sleep stage using five machine learning algorithms. For validation of our approach, the obtained results were compared with PSG scoring results evaluated by sleep clinicians. Both accuracy and specificity yielded over 90 percent, and sensitivity was between 50 and 80 percent. In order to investigate the relevance between features and PSG scoring results, information gains were calculated. As a result, the features that had the lowest and highest information gain were skewness and band energy, respectively. In conclusion, the sleep stages were classified using the top 10 significant features with high information gain."
기하정보 기반 이상탐지분석을 이용한 BIM 개별 부재 IFC 분류 무결성 검토에 관한 연구,2017,"['BIM', 'IFC', '기계학습', '이상탐지분석', 'Building Information Modeling', 'Industry Foundation Classes', 'Machine Learning', 'Anomaly Detection']",,"Although Industry Foundation Classes (IFC) provide standards for exchanging Building Information Modeling (BIM) data, authoring tools still require manual mapping between BIM entities and IFC classes. This leads to errors and omissions, which results in corrupted data exchanges that are unreliable and thus compromise the validity of IFC. This research explored precedent work by Krijnen and Tamke, who suggested ways to automate the mapping of IFC classes using a machine learning technique, namely anomaly detection. The technique incorporates geometric features of individual components to find outliers among entities in identical IFC classes. This research primarily focused on applying this approach on two architectural BIM models and determining its feasibility as well as limitations. Results indicated that the approach, while effective, misclassified outliers when an IFC class had several dissimilar entities. Another issue was the lack of entities for some specific IFC classes that prohibited the anomaly detection from comparing differences. Future research to improve these issues include the addition of geometric features, using novelty detection and the inclusion of a probabilistic graph model, to improve classification accuracy."
제4차 산업혁명 시대의 스마트 환경을 활용한 의사소통교육 모델 연구,2017,"['the 4th industrial revolution', 'education model using the data', 'communication education for engineering students', 'smart education methods']",,"The 4th industrial revolution refers to an era where machines capable of outperforming humans are created. In light of the 4th industrial revolution, university students are demanded problem solving abilities, critical thinking abilities, and problem discovering abilities as general and basic abilities. The need for changes in the university level communication education for engineering students remains imperative in this constantly changing social environment. The era where education is conducted only in classrooms is over. This paper discusses the need for diversified education such as the integration of online and offline education, the reinforcement of learning outside of the classroom as well as an education model that transcends formal and informal education such as games and activities that induce self-learning, both intentional and non-intentional learning, and the utilization of mass media and social networking systems. Through providing an education model that assesses and utilizes the data gained from the learning process provided above, this paper widens the perception of future education methods in the 4th industrial revolution."
가상현실 응용을 위한 MCSVM 기반 손 제스처 인식 방법,2017,"['Hand Gesture Recognition', 'User Interaction', 'Leap Motion', 'Gesture Classification', 'Machine Learning', '손 제스처 인식', '사용자 상호작용', '립모션', '제스처 분류', '머신러닝']","최근 가상현실 기술의 발전으로 가상공간에서 자연스러운 상호작용을 위하여 손 제스처 인식에 대한 연구가 활발히진행되고 있다. 본 논문은 가상현실 응용에서 손 제스처를 이용한 상호작용이 가능하도록 손 제스처 유형을 정의하고 MCSVM 학습을 통한 손 제스처 인식 방법을 제안한다. 먼저 전처리 과정을 거친 다양한 손 데이터를 이진 결정트리로 1차 분류를 한다. 분류 된 데이터는 리샘플링을 한 다음 체인코드를 생성하고 이에 대한 히스토그램으로 특징 데이터를 구성한다. 이를 기반으로 학습된 MCSVM을 통해 2차 분류를 수행하여 제스처를 인식한다. 실험 결과3D 오브젝트와 상호작용을 위한 16개의 명령 제스처에 대해 평균 99.2%의 인식률을 보였다. 마우스 인터페이스와 비교한 정성적 평가에서는 본 방법이 마우스 입력에 비하여 직관적이고 사용자 친화적인 상호작용이 가능함을보여 게임, 교육, 의료 등 다양한 응용 분야에서의 입력 인터페이스로 활용 될 수 있음을 알 수 있었다.","Recently hand gesture recognition which is one of several methods for natural user interaction is being extensively researched in the development of virtual reality technology. In this paper, we suggest a hand gesture recognition method based on the MCSVM for interaction in the virtual reality applications. First, we preprocess various hand data and classify the data through the binary decision tree. The classified data is resampled and converted to the chain-code, and then we construct the hand feature data with the histograms of the chain code. Finally, the input gesture is recognized by MCSVM-based machine learning from the feature data. Experimental results show an average of 99.2% recognition ratio of 16 kinds of command hand gestures for interaction with a 3D object. From experiment of a comparison with the mouse interface, it shows that the paper method is more intuitive and user friendly than mouse input. Therefore, this hand gesture interface can be used in various fields such as game, education, medical field, etc."
심볼릭 인공지능을 위한 R 심볼릭 데이터분석,2017,"['심볼릭 인공지능', 'R데이터언어', '심볼릭 데이터분석', '기계학습', 'Symbolic Artificial Intelligence', 'R Data Language', 'Symbolic Dat Analysis', 'Machine Learning']",컴퓨터와 인간은 분명 다르지만 기본적으로 데이터를 저장하고 처리하는 개념적 측면에서는 서로 유사한 구조를 갖는다. 하지만 수집된 전체 데이터를 처리하고 분석하는 컴퓨터와는 달리 인간은 요약된 패턴 단위로 데이터를 처리한다. 즉 인간은 전체 데이터를 다루기보다는 요약된 정보를 통해 최적의 의사결정을 한다. 전체 데이터보다 요약된 정보만을 관리하면 시간과 비용 면에서 더 효율적인 시스템을 구축할 수 있다. 특히 빅데이터 환경에서 인공지능의 학습을 위한 대용량 데이터의 처리 및 분석을 위하여 요약된 정보에 기반 한 데이터학습에 대한 필요성이 제기되고 있다. 본 연구에서는 이와 같이 요약된 정보에 기반 한 심볼릭 인공지능 시스템의 효율적인 구축을 위하여 통계학의 심볼릭 데이터분석에 대하여 연구한다. 특히 대표적인 데이터언어인 R에서 제공하는 심볼릭 데이터분석 함수를 이용한 심볼릭 인공지능에 대한 방법을 소개한다. 제안방법의 성능평가를 위하여 객관적인 기계학습 데이터 사례를 이용하였다.,"Computers and humans are different, but basically they have a similar structure in conceptual aspects of data storing and processing. However, unlike computers that process and analyze the entire data collected, humans process the data in a summarized pattern. In other words, humans make the best decisions through summarized information rather than whole data. By managing only summarized information, you can build a more efficient system in terms of time and cost. In particular, there is a need for learning from data based on summarized information for processing and analyzing large amounts of data for artificial intelligence learning in a big data environment. In this paper, symbolic data analysis of statistics is studied for efficient construction of symbolic artificial intelligence system based on the information summarized in this way. We introduce a method for symbolic artificial intelligence using symbolic data analysis functions provided by R data language. In order to evaluate the performance of proposed method, objective machine learning data were used."
워드 임베딩을 이용한 아마존 패션 상품 리뷰의 사용자 감성 분석,2017,"['워드 임베딩', '감성분석', '오피니언 마이닝', '인공지능', '딥러닝', '융합기술', 'Word Embedding', 'Sentiment Analysis', 'Opinion Mining', 'Artificial Intelligence', 'Deep Learning', 'Convergence technique']","현대 사회에서 패션 시장의 규모는 해외와 국내 모두 지속적으로 증가하고 있다. 전자상거래를 통해 상품 을 구입하는 경우 다른 소비자들이 작성한 상품에 대한 평가 데이터는 소비자가 상품의 구입 여부를 결정하는데에 영향을 미친다. 기업의 입장에서도 상품에 대한 소비자의 평가 데이터를 분석하여 소비자의 피드백을 반영한다면 기업의 성과에 긍정적인 영향을 미칠 수 있다. 이에 본 논문에서는 아마존 패션 상품의 리뷰 데이터를 학습하여 형성 된 워드임베딩 공간을 이용하여 사용자의 감성을 분석하는 모델을 구축하는 방법을 제안한다. 실험은 아마존 리뷰 데이터 570만건을 학습하여 형성된 워드임베딩 공간을 이용하여 긍정, 부정 리뷰 데이터의 개수에 따라 총 3개의 SVM 분류기 모델을 학습하는 방식으로 진행하였다. 실험 결과 긍정 리뷰 데이터 5만건, 부정 리뷰데이터 5만건을 이용하여 SVM 분류기를 학습하였을 때 88.0%로 가장 높은 정확도(accuracy)를 나타냈다.","In the modern society, the size of the fashion market is continuously increasing both overseas and domestic. When purchasing a product through e-commerce, the evaluation data for the product created by other consumers has an effect on the consumer's decision to purchase the product. By analysing the consumer’s evaluation data on the product the company can reflect consumer’s opinion which can leads to positive affect of performance to company. In this paper, we propose a method to construct a model to analyze user 's sentiment using word embedding space formed by learning review data of amazon fashion products. Experiments were conducted by learning three SVM classifiers according to the number of positive and negative review data using the formed word embedding space which is formed by learning 5.7 million Amazon review data.. Experimental results showed the highest accuracy of 88.0% when learning SVM classifier using 50,000 positive review data and 50,000 negative review data."
기계 학습 방법을 이용한 활동 프로파일 기반의 스마트 시니어 분류 모델 개발,2017,"['활동 프로파일', '스마트 시니어', '기계 학습', '지도 학습', '비지도 학습', '분류 모델', 'Activity Profile', 'Smart Senior', 'Machine Learning', 'Supervised Learning', 'Unsupervised Learning', 'Classification Model']","최근 스마트폰의 보급 및 웹 서비스의 도입으로 온라인 사용자들은 대규모의 콘텐츠를 시간과 장소에 관계없이 접할 수 있게 되었다. 그러나 사용자들은 대규모의 콘텐츠 사이에서 원하는 콘텐츠를 찾는 데 어려움을 겪게 되었다. 이러한 문제를 해결하기 위해 다양한 분야에서 사용자 모델링 및 추천 시스템에 대한 연구가 활발하게 수행되었다. 그러나 정보 환경의 변화에 따른 시니어 계층의 적극적인 변화에도 불구하고 시니어 계층에 초점을 맞춘 사용자 모델링 및 추천 시스템에 대한 연구는 매우 부족한 실정이다. 이에 본 논문에서는 기계 학습 방법을 기반으로 스마트 시니어 계층의 선호도를 파악할 수 있는 모델링 방법을 제안하고, 스마트 시니어 분류 모델을 개발 한다. 이 결과, 스마트 시니어 계층의 선호도를 파악할 수 있을 뿐만 아니라 스마트 시니어 분류 모델 개발을 통해 시니어 사용자에게 가장 적합한 활동 및 콘텐츠를 제공하는 콘텐츠 추천 연구에 대한 발판을 마련하였다.","With the recent spread of smartphones and the introduction of web services, online users can access large-scale content regardless of time or place. However, users have had trouble finding the content they wanted among large-scale content. To solve this problem, user modeling and content recommendation system have been actively studied in various fields. However, in spite of active changes in senior groups according to the changes in information environment, research on user modeling and content recommendation system focused on senior groups are insufficient. In this paper, we propose a method of modeling smart senior based on their preference, and further develop a smart senior classification model using machine learning methods. As a result, we can not only grasp the preferences of smart seniors, but also develop a smart senior classification model, which is the foundation for the research of a recommendation system which will provide the activities and contents most suitable for senior groups."
소프트웨어 정의 무선 메쉬 네트워크에서의 경량화된 중복 제거 기법,2017,"['Wireless mesh network (WMN)', 'software-defined networking (SDN)', 'lightweight traffic redundancy elimination (LTRE)', 'machine learning', 'source routing', 'cache management', '무선 메쉬 네트워크', '소프트웨어 정의 네트워킹', '중복 제거 기법', '기계 학습', '소스라우팅', '캐쉬 관리']","낮은 비용으로 무선 네트워킹 인프라를 구축할 수 있는 무선 메쉬 네트워크에서는 제한된 무선 자원을 효율적으로 이용하기 위해 패킷 전송(특히, 불필요하게 중복되는 패킷 전송)을 신중하게 처리해야 한다. 본 논문에서는 컨트롤러를 통한 중앙 집중식의 관리가 가능한 소프트웨어 정의 네트워킹 기반의무선 메쉬 네트워크에서 불필요하게 중복 전송되는 데이터의 양을 감소시키기 위해 경량화된 중복 제거기법을 제안한다. 제안하는 중복 제거 기법은 감소되는 트래픽 양을 극대화하기 위해 컨트롤러가 1) 기계학습 기반의 정보 요청, 2) ID기반의 소스 라우팅, 3) 인기도 기반의 캐쉬 업데이트를 통해 중복 제거 효과를 극대화시킬 수 있는 최적의 경로를 결정한다. 시뮬레이션 결과는 제안하는 기법을 통해 전체 트래픽부하를 18.34%-48.89% 만큼 감소시킬 수 있음을 보여준다.","Wireless mesh network (WMN) is a promising technology for building a cost-effective and easily-deployed wireless networking infrastructure. To efficiently utilize limited radio resources in WMNs, packet transmissions (particularly, redundant packet transmissions) should be carefully managed. We therefore propose a lightweight traffic redundancy elimination (LTRE) scheme to reduce redundant packet transmissions in software-defined wireless mesh networks (SD-WMNs). In LTRE, the controller determines the optimal path of each packet to maximize the amount of traffic reduction.In addition, LTRE employs three novel techniques: 1) machine learning (ML)-based information request, 2) ID-based source routing, and 3) popularity-aware cache update. Simulation results show that LTRE can significantly reduce the traffic overhead by 18.34% to 48.89%."
An experimental analysis of limitations of MapReduce for iterative algorithms on Spark,2017,"['Iterative algorithms', 'Hadoop', 'Spark', 'HaLoop', 'iMapReduce', 'Twister']",,"<P>MapReduce is the most popular framework for distributed processing. Recently, the scalability of data mining and machine learning algorithms has significantly improved with help from MapReduce. However, MapReduce does not handle iterative algorithms very efficiently. The problem is that many data mining and machine learning algorithms are iterative by nature. In order to overcome the limitations of MapReduce, many advanced distributed systems have been developed, including HaLoop, iMapReduce, Twister, and Spark. In this paper, we identify and categorize the limitations of MapReduce in handling iterative algorithms, and then, experimentally investigate the consequences of these limitations by using the most flexible and stable distributed system, Spark. According to our experiment results, the network I/O overhead was the primary factor that affected system performance the most. The disk I/O overhead also affected system performance, but it was less significant than the network I/O overhead. For the synchronization overhead, it affected system performance only when the static data was not cached.</P>"
자살예방 정책수단 평가 및 해결방안 연구,2017,"['자살예방프로그램', '정책평가', '분절회귀분석', '빅데이터', '기계학습', '다학제적 접근', 'suicide prevention program', 'policy evaluation', 'segmental regressionanalysis', 'big data', 'machine learning', 'multidisciplinary approach']","본 연구에서는 핀란드와 일본의 자살예방프로그램에 대한 경제적 분석 및 정책평가를 실시하였다. 본 연구 분석결과를 요약하면 다음과 같다. 먼저 자살예방프로그램을 강력하게 시행한 국가들은 정책추진사후에 자살증가가 감소하고, 그 변동성이 안정적 상태로 나타났다. 둘째, 일본과 핀란드의 자살예방프로그램의 정책효과를 정량적으로 평가할 때, 평균 연간 자살률이 전년대비 14.2%감소되는 효과가 존재하였다. 셋째, 정부의 자살예방프로그램은 경제적인 요인뿐만 아니라 사회적인 요인을 포함하는 광범위한 정책수단을 추진할 때, 정책효과의 유효성이 나타났다. 본 연구 분석결과에 나타난 자살예방프로그램시행에 대한 정책적 시사점은 다음과 같다. 먼저 자살예방프로그램추진에 따른 긍정적 효과가 존재하기 때문에 장기적이고 지속적인 정책추진력이 중요한 요소임을 보여준다. 둘째, 정부차원의 자살예방프로그램이 성공하기 위해서는 광범위한 관련 영역 즉 경제영역과 사회영역 그리고 문화영역을 포함하는 정책적용범위가 요구된다. 마지막으로 자살예방프로그램의 정책효과를 극대화하기 위해서는 자살예방프로그램에 관련된 대상을 지속적으로 모니터링하고, 장기적 차원에서 빅 데이터 및 기계학습을 적용하는 단계가 요구된다.","In this study, we conducted an economic analysis and policy evaluation of suicide prevention program. The results of this study are summarized as follows. First, the countries that implemented the suicide prevention program strongly showed that the suicide rate decreased after the implementation of the policy and that the volatility was stable. Second, when quantitatively evaluating the policy effects of suicide prevention programs in Japan and Finland, the average annual suicide rate decreased by 14.2% from the previous year. Third, the government""s suicide prevention program showed the effectiveness of the policy effect when pursuing a wide range of policy instruments including economic factors as well as social factors. The results of this study suggest that the policy implications of suicide prevention programs are as follows. First, there is a positive effect of the suicide prevention program, which shows that long-term and sustained policy drive is an important factor. Second, in order to success the suicide prevention programs at the government, ranges of policy coverages including economic, social and cultural areas are required. Finally, in order to maximize the policy effect of the suicide prevention program, it is necessary to continuously monitor the subjects related to the suicide prevention program and to apply the big data and machine learning in the long term."
영상의 색체 강도 엔트로피를 이용한 나비 종 자동 인식 향상 방법,2017,"['나비 종 인식', '특징 추출', '가지 길이 유사성 엔트로피', '색채 강도 엔트로피', '기계 학습', 'Butterfly Identification', 'Feature Extraction', 'Branch Length Similarity Entropy', 'Color Intensity Entropy', 'Machine Learning']","영상을 이용한 나비 종 자동 인식 기법은 생물종 다양성 연구 및 종의 진화, 발달 과정의 연구를 위한 기초 작업을 돕는 것으로 연구자들의 관심이 높다. 기계학습 기반의 나비 종 인식 시스템은 사용하는 특징추출 방법에 성능이 크게 좌우되는 성질을 가지고 있다. 본 논문은 나비 영상이 가진 색채 강도의 분포를 이용하는 색채 강도 (Color Intensity) 엔트로피를 제안하고 기존에 제시된 가지 길이 유사성 (Branch Length Similarity) 엔트로피와 함께 사용할 경우 10% 이상의 인식률 향상을 얻을 수 있음을 보인다. 제안한 방법의 신뢰성 있는 성능 평가를 위해 영상 인식에 자주 사용되는 대표적인 특징 추출 방법인 아이겐 이미지, 2D 푸리에 변환, 2D 웨이블릿 변환 방법들을 비교 대상으로 다양한 기계학습을 이용해 성능을 평가한다.","Automatic butterfly identification using images is one of the interesting research fields because it helps the related researchers studying species diversity and evolutionary and development process a lot in this field. The performance of the butterfly species identification system is dependent heavily on the quality of selected features. In this paper, we propose color intensity (CI) entropy by using the distribution of color intensities in a butterfly image. We show color intensity entropy can increase the recognition rate by 10% if it is used together with previously suggested branch length similarity entropy. In addition, the performance comparison with other features such as Eigenface, 2D Fourier transform, and 2D wavelet transform is conducted against several well known machine learning methods."
LTRE: Lightweight Traffic Redundancy Elimination in Software-Defined Wireless Mesh Networks,2017,"['무선 메쉬 네트워크', '소프트웨어 정의 네트워킹', '중복 제거 기법', '기계 학습', '소스라우팅', '캐쉬 관리', 'Wireless mesh network (WMN)', 'software-defined networking (SDN)', 'lightweight traffic redundancy elimination (LTRE)', 'machine learning', 'source routing', 'cache management']",,"Wireless mesh network (WMN) is a promising technology for building a cost-effective and easily-deployed wireless networking infrastructure. To efficiently utilize limited radio resources in WMNs, packet transmissions (particularly, redundant packet transmissions) should be carefully managed. We therefore propose a lightweight traffic redundancy elimination (LTRE) scheme to reduce redundant packet transmissions in software-defined wireless mesh networks (SD-WMNs). In LTRE, the controller determines the optimal path of each packet to maximize the amount of traffic reduction. In addition, LTRE employs three novel techniques: 1) machine learning (ML)-based information request, 2) ID-based source routing, and 3) popularity-aware cache update. Simulation results show that LTRE can significantly reduce the traffic overhead by 18.34% to 48.89%."
발화행태 특징을 활용한 응급상황 신고자 연령분류,2017,"['Age classification', 'Speech utterances', 'Speech recognition', 'Emergency calls', 'Turn-taking', 'Silent pause', '연령분류', '발화행태', '음성인식', '응급상황', '대화반응', '무성휴지']","본 논문에서는 실제 응급상황센터에 접수된 신고전화의 음성분석을 통하여 발화자의 연령을 분류하고자 한다. 2가지 발화행태적 특징요소인 무성휴지(Silent Pause), 대화반응시간(Turn-taking latency)를 활용하여 성인과 노인을 분류할 수 있는 특징에 대한 분류기준을 선정하고, 이를 기계학습 분류기인 SVM(Support Vector Machine)을 활용하여 분류정확도를 확인하였다. 먼저, 응급상황센터의 실제 신고전화에 대하여 발화행태적 특징요소를 기반으로 청취분석을 통하여 발생길이에 대하여 성인과 노인사이에 통계적으로 유의하다는 것을 확인하였다(p<0.05). 또한, 성인과 노인 각 100개, 총 200개의 음성데이터를 5차 교차검증방법을 사용하여 기계학습을 실행한 결과, 2가지의 발화행태를 모두 사용한 복합기준(무성휴지+대화반응시간)일 경우, 70%의 가장 높은 분류정확도를 확인할 수 있었다. 본 연구의 결과는 음성에 기반한 연령을 분류하는 연구에 있어서, 기존의 음성정보와 더불어, 새로운 발화행태적 특징요소와의 결합을 통하여 연령구분을 가능하게 하는 새로운 방법으로 제안할 수 있을 것이다. 또한, 향후 음성기반 상황판단 시스템 기술 개발에 있어서 기초자료로 적용이 가능하며, 이를 통하여 신속한연령분류를 판단을 통한 상황대처가 가능하도록 하는 데에 기여할 수 있을 것이다.","In this paper, we investigated the age classification from the speaker by analyzing the voice calls of the emergency center. We classified the adult and elderly from the call center calls using behavioral speech utterances and SVM(Support Vector Machine) which is a machine learning classifier. We selected two behavioral speech utterances through analysis of the call data from the emergency center: Silent Pause and Turn-taking latency. First, the criteria for age classification selected through analysis based on the behavioral speech utterances of the emergency call center and then it was significant(p ＜0.05) through statistical analysis. We analyzed 200 datasets (adult: 100, elderly: 100) by the 5 fold cross-validation using the SVM(Support Vector Machine) classifier. As a result, we achieved 70% accuracy using two behavioral speech utterances. It is higher accuracy than one behavioral speech utterance. These results can be suggested age classification as a new method which is used behavioral speech utterances and will be classified by combining acoustic information(MFCC) with new behavioral speech utterances of the real voice data in the further work. Furthermore, it will contribute to the development of the emergency situation judgment system related to the age classification."
약물-표적 단백질 연관관계 예측모델을 위한 쌍 기반 뉴럴네트워크,2017,"['뉴럴네트워크', '약물-표적 단백질 연관관계 예측모델', '단백질 수치화', 'Neural network', 'Compound-target protein interaction', 'Protein embedding']","In-silico 기반의 약물-표적 단백질 연관관계 예측은 신약 탐색 단계에서 매우 중요하다. 그러나 기존의 예측모델은 입력 값이 고정적이며 표적 단백질의 특질 값이 가공된 데이터로 한정됨으로써 예측 모델의 확장성과 유연성이 부족하다. 본 논문에서는 약물-표적 단백질 연관관계를 예측하는 확장 가능한 형태의 머신러닝 모델을 소개한다. 확장 가능한 머신러닝 모델의 핵심 아이디어는 쌍기반의 뉴럴 네트워크로써, 약물과 단백질의 미가공 데이터를 사용하여 특질을 추출하고 특질 값을 각각의 뉴럴 네트워크 레이어에 입력한다. 이 방법은 추가적인 지식없이 자동적으로 약물과 단백질의 특질을 추출한다. 또한 쌍기반 레이어는 특질값을 풍부한 저차원의 벡터로 향상 시킴으로써 입력 값의 차이로 인한 편향 학습을 방지한다. PubChem BioAssay(PCBA) 데이터 셋에 기반한 5-폴드 교차 검증법을 통하여 제안한 모델의 성능을 평가했으며, 이전의 모델보다 우월한 성능을 보였다.","Predicting compound-protein interactions in-silico is significant for the drug discovery. In this paper, we propose an scalable machine learning model to predict compound-protein interaction. The key idea of this scalable machine learning model is the architecture of pairwise neural network model and feature embedding method from the raw data, especially for protein. This method automatically extracts the features without additional knowledge of compound and protein. Also, the pairwise architecture elevate the expressiveness and compact dimension of feature by preventing biased learning from occurring due to the dimension and type of features. Through the 5-fold cross validation results on large scale database show that pairwise neural network improves the performance of predicting compound-protein interaction compared to previous prediction models."
전력데이터 분석에서 이상점 추출을 위한 데이터 클러스터링 아키텍처에 관한 연구,2017,"['데이터 분석', '전력데이터', '비지도학습', '이상점', '주성분분석']","과거에는 전력데이터를 분석하는 기법으로 주로 기계학습의 지도학습 기법을 많이 활용하였고 데이터 마이닝 기법을 통한 패턴 검출을 주로 연구하였다. 그러나 전력데이터의 규모 커지고 실시간 데이터 공급이 가능해진 현재에는 과거의 데이터 분류 및 분석 기법을 통한 데이터 분석 연구는 한계가 존재한다. 이에 본 논문에서는 큰 규모의 전력데이터를 분석할 수 있는 클러스터링 아키텍처를 제안한다. 제안하는 클러스터링 프로세스는 비지도학습기법인 K-means 알고리즘의 문제점을 보완하고 전력데이터 수집과 분석까지의 모든 과정을 자동화할 수 있는 프로세스이다. 총 3 Level로 구분하여 Row Data Level, Clustering Level, User Interface Level로 구분하여 전력데이터를 분류 및 분석한다. 또한 클러스터링의 효율성 향상을 위하여 주성분분석 및 정규분포기반의 최적의 클러스터 수 K값 추출과 이상점으로 분류되는 데이터 감소를 위한 변형된 K-means 알고리즘을 제시한다.","In the past, researchers mainly used the supervised learning technique of machine learning to analyze power data and investigated the identification of patterns through the data mining technique. Data analysis research, however, faces its limitations with the old data classification and analysis techniques today when the size of electric power data has increased with the possible real-time provision of data. This study thus set out to propose a clustering architecture to analyze large-sized electric power data. The clustering process proposed in the study supplements the K-means algorithm, an unsupervised learning technique, for its problems and is capable of automating the entire process from the collection of electric power data to their analysis. In the present study, power data were categorized and analyzed in total three levels, which include the row data level, clustering level, and user interface level. In addition, the investigator identified K, the ideal number of clusters, based on principal component analysis and normal distribution and proposed an altered K-means algorithm to reduce data that would be categorized as ideal points in order to increase the efficiency of clustering."
특허문서 필드의 기능적 특성을 활용한 IPC 다중 레이블 분류,2017,"['특허 분류', 'IPC 자동분류', '특허문서 필드', '필드 기능', '멀티 레이블 분류', 'Patent classification', 'IPC Classification', 'Patent Document Fields', 'Field function', 'Multi-label classification']",,"Recently, with the advent of knowledge based society where information and knowledge make values, patents which are the representative form of intellectual property have become important, and the number of the patents follows growing trends. Thus, it needs to classify the patents depending on the technological topic of the invention appropriately in order to use a vast amount of the patent information effectively. IPC (International Patent Classification) is widely used for this situation. Researches about IPC automatic classification have been studied using data mining and machine learning algorithms to improve current IPC classification task which categorizes patent documents by hand. However, most of the previous researches have focused on applying various existing machine learning methods to the patent documents rather than considering on the characteristics of the data or the structure of patent documents. In this paper, therefore, we propose to use two structural fields, technical field and background, considered as having impacts on the patent classification, where the two field are selected by applying of the characteristics of patent documents and the role of the structural fields. We also construct multi-label classification model to reflect what a patent document could have multiple IPCs. Furthermore, we propose a method to classify patent documents at the IPC subclass level comprised of 630 categories so that we investigate the possibility of applying the IPC multi-label classification model into the real field. The effect of structural fields of patent documents are examined using 564,793 registered patents in Korea, and 87.2% precision is obtained in the case of using title, abstract, claims, technical field and background. From this sequence, we verify that the technical field and background have an important role in improving the precision of IPC multi-label classification in IPC subclass level."
Applying Artificial Neural Network for Sentiment Analytics of Social Media Text Data in fastfood industry,2017,"['Sentiment Analytics', 'Social Media', 'Fastfood Brands', 'Competitive Analysis', 'Vietnam']",,"The increasing of users in social networking services in Vietnam help companies have better communication channels with customers. Nowadays, any companies can easily invest tools and human to monitor and harvest customer-generated contents not only about their own brands but also about their competitive brands on social media sites. In order utilize the value in the harvested data, certain analytic techniques are required. This paper proposed a method to apply mining social media data in the context of fastfood brands. We collected data from top fastfood chains including Lotteria, MacDonald, KFC, Vietnam Pizza Hut and Pepperonis Vietnam and applied machine learning to classify the sentiment of informal text data. The results show that applying neural network machine learning in sentiment analytics of social media text data is suitable for sentiment analytics and applicable for future data prediction in fastfood industry."
실시간 탐지를 위한 인공신경망 기반의 네트워크 침입탐지 시스템,2017,"['Intrusion Detection System', 'Artificial Neural Network', 'Multi-objective Genetic Algorithm', 'Featureselection', 'NSL_KDD data set']","네트워크를 통한 사이버 공격 기법들이 다양화, 고급화 되면서 간단한 규칙 기반의 침입 탐지/방지 시스템으로는 지 능형 지속 위협(Advanced Persistent Threat: APT) 공격과 같은 새로운 형태의 공격을 찾아내기가 어렵다. 기존에 알려 지지 않은 형태의 공격 방식을 탐지하는 이상행위 탐지(anomaly detection)를 위한 해결책으로 최근 기계학습 기법을 침입탐지 시스템에 도입한 연구들이 많다. 기계학습을 이용하는 경우, 사용하는 특징 집합에 침입탐지 시스템의 효율성 과 성능이 크게 좌우된다. 일반적으로, 사용하는 특징이 많을수록 침입탐지 시스템의 정확성은 높아지는 반면 탐지를 위 해 소요되는 시간이 많아져 긴급성을 요하는 경우 문제가 된다. 논문은 이러한 두 가지 조건을 동시에 충족하는 특징 집합을 찾고자 다목적 유전자 알고리즘을 제안하고 인공신경망에 기반한 네트워크 침입탐지 시스템을 설계한다. 제안한 방법의 성능 평가를 위해 NSL_KDD 데이터를 대상으로 이전에 제안된 방법들과 비교한다.","As the cyber-attacks through the networks advance, it is difficult for the intrusion detection system based on the simple rules to detect the novel type of attacks such as Advanced Persistent Threat(APT) attack. At present, many types of research have been focused on the application of machine learning techniques to the intrusion detection system in order to detect previously unknown attacks. In the case of using the machine learning techniques, the performance of the intrusion detection system largely depends on the feature set which is used as an input to the system. Generally, more features increase the accuracy of the intrusion detection system whereas they cause a problem when fast responses are required owing to their large elapsed time. In this paper, we present a network intrusion detection system based on artificial neural network, which adopts a multi-objective genetic algorithm to satisfy the both requirements: accuracy, and fast response. The comparison between the proposing approach and previously proposed other approaches is conducted against NSL_KDD data set for the evaluation of the performance of the proposing approach."
웨어러블 센서와 커널 기법을 이용한 낙상 탐지에 관한 고찰,2017,"['커널 탐색', '커널 기법', '스마트 폰 센서', '보행 특징', 'Kernel Search', 'Kernel Methods', 'Smart Phone Sensors', 'Walking Fetuares']","최근 들어 기계학습 분야의 여러 우수 방법론들은 관련 분야에서 우수한 성능을 보이며 계속적으로 빠르게 발전하고 있다. 커널 기법은 오랫동안 이러한 경쟁에 동참하며 우수한 성능을 산출함으로써 많은 주목을 끌어왔던 방법론 중 하나이다. 그 중에서도 확률론적 커널 기법인 가우시안 프로세스는 함수 근사, 패턴 분류, 비선형 특징 검출 등의 기계학습 문제에서 뛰어난 예측 및 오차 범위 결과를 제공하고 있다. 본 논문에서는 보행 중 낙상이 발생하는 경우를 탐지하기 위하여 웨어러블 센서와 가우시안 프로세스 및 커널 탐색 등을 이용하는 방안을 고려하였다. 이러한 연구에 있어서, 가우시안 프로세스 모델링 단계에서는, 가우시안 프로세스 기반 동적 모델링과 자동 커널 탐색을 고려하였다. 가우시안 프로세스 기반 동적모델링에서는 인덱스의 역할을 상태 벡터가 수행하는 반면에, 자동 커널 탐색에서는 시간이 이러한 역할을 수행한다. 고려된 방법론의 응용 가능성을 관찰하기 위하여 실험을 실시하였고, 가능성 있는 결과를 관찰하였다.","Recently, many advanced machine learning methods have demonstrated excellent performance in many related fields. The kernel methods have been one of such advanced methodologies that have attracted a great deal of attention because they have long been involved in this competition and producing superior performance. Among them, the Gaussian process, which is a probabilistic kernel method particularly effective for machine learning problems such as function approximation, pattern classification, and nonlinear feature extraction, is providing excellent prediction and error-bar results. In this paper, we consider the problem of detecting the occurrence of fall during walking based on wearable sensors, Gaussian process methodologies, and kernel search. Here in the Gaussian process modeling stage, Gaussian process-based dynamic modeling and automatic kernel search were utilized. In Gaussian process-based dynamic modeling, the latent state vector performs the role of the index, while in the automatic kernel search, time plays the index role. Experiments were conducted to observe the applicability of the proposed methodology, and promising outcomes were observed."
"빅데이터 분석 시장 활성화를 위한 기술적, 제도적 요인에 관한 연구: 전문가 심층인터뷰 방법을 중심으로",2017,"['빅데이터(BigData) 분석', '전문가 심층면접조사(In-depth Interview)', '기술적인 요소', '제도적인 요소', '데이터 거버넌스(data governance)', 'Big Data Analysis', 'In-depth Interview', 'Technical Factors', 'Institutional Factors', 'Data Governance Framework']","전 산업에 걸쳐 빅데이터(BigData)에 대한 관심이 날로 증대되고 있고, 기업들은 빅데이터 분석 솔루션을 활용한 비즈니스 가치 창출과 이를 최적화하려는 수익모델을 개발하고 있다. 주요 국가 정부와 산업계에서는 빅데이터를 각종 문제 해결 및 이슈 대응과 더불어 미래 전략과 수반되는 전략적 의사결정의 중요한 도구로 활용하고자 한다. 한국 정부 또한 빅데이터 시장 활성화를 위한 의지가 명확하고 매년 빅데이터 관련 예산을 증액하고 있으나 빅데이터 관련 기업들은 비즈니스 모델 부재로 높은 수익성을 내지 못하고 있는 실정이다. 또한 다양한 영역에서의 빅데이터 활용 성공사례가 부족한 점으로 인해 민간기업의 경우 빅데이터 투자에 보수적으로 접근하고 있다. 따라서 본 연구는 빅데이터 시장 활성화의 저항요인 규명과 빅데이터 분석 활성화에 필요한 기술적, 제도적 요인을 도출하기 위해 전문가 심층면접조사(In-depth Interview)를 수행하였다. 연구결과, 빅데이터 전문가들은 빅데이터 분석 시장 활성화에 필요한 기술적, 제도적 요소로 (1) 기계학습(machine learning) 및 인공지능기법(artificial intelligence techniques)의 기술력 향상, (2) 비식별 정보이용 활성화를 위한 개인정보보호법 제도 개선과 빅데이터 진흥법 제정, (3) 데이터 과학자, 빅데이터 분석가 등의 전문 인력 양성 필요, (4) 정부의 공공데이터 개방과 민간 빅데이터와의 통합 필요, (5) 데이터 거버넌스(data governance) 프레임워크의 구성요소 개발 및 상세화 등을 제시하였다.","Interest in big data is growing throughout the industries and companies are developing profit models that create and optimize business value using big data analysis solutions. The governments and industries of leading countries are using big data as an important tool to solve various problems and issues as well as for establishing future strategies and making strategic decisions. The Korean government has a clear determination to stimulate the big data market and is increasing its budget for big data, but big data related companies are not making high profits due to the lack of business models. Furthermore, private companies are assuming a conservative position toward investments in big data due to insufficient success stories of big data use in various areas. In this study, therefore, the delphi survey and in-depth interview methodologies were used to identify the resistance factors of the big data market activation and elucidate the technical and institutional factors required to stimulate big data analysis. The results of this study revealed that big data experts suggested five technical and institutional factors required to stimulate the big data analysis market including: (1) improvement of technologies for machine learning and artificial intelligence techniques, (2) personal information protection act revision for activating the use of de-identification of personal information and big data industry promotion act legislation, (3) the need to nurture specialists such as data scientists and big data analysis, (4) the need to actively open public data, and (5) developing and refining components in data governance framework."
과표본추출에 의한 음성인식율의 향상,2017,"['음소', '의사결정트리', '과표본추출', '랜덤포리스트', '음성인식', 'phoneme', 'decision tree', 'over-sampling', 'random forests', 'speech recognition']","음성인식을 위한 분석시스템에 있어 난제의 하나인 충분히 신뢰할만한 음향적 파라미터를 얻기 위한 일환으로 이해가 용이한 데이터마이닝 모델을 생성하여 소기의 목적을 달성하는데 사용할 수 있으나, 이에 대한 걸림돌 중 하나는 잘 정리된 충분한 양의 훈련 데이터의 부족이다. 부족한 훈련 데이터를 보완하기 위한 방법으로는 과표본추출(over-sampling)이 흔히 사용되며 이를 위한 대표적 방법으로 SMOTE 알고리즘이 제안되어 활용된다. 그러나 SMOTE 알고리즘에 의해 생성된 훈련 데이터 인스턴스는 비록 K-인접이웃 기법에 의해 생성되었다하나 기본적으로 인공 데이터이므로 클래스의 진위를 검사해볼 필요성이 있다. 본 논문에서는 의사결정트리를 목표 데이터마이닝 모델로 할 때 음성 데이터를 포함하는 phoneme 데이터베이스처럼 클래스의 분포가 한쪽으로 치우친 데이터베이스에서 의사결정트리의 앙상블을 포함하는 기계학습 알고리즘인 랜덤포리스트를 사용하여 인공 데이터를 검정함으로써 보다 개선된 의사결정트리를 생성할 수 있음을 실험을 통해 증명하였다.","Decision trees can be used to acquire acoustic parameters for the analytical system of speech recognition, but a difficult part for the purpose is the lack of well-prepared data as well as enough number of training data for more accurate classification using the decision tree. As a method to supplement the insufficient data, SMOTE that is a representative method for over-sampling is widely accepted. But, because the generated instances by the over-sampling method are basically artificial instances, even though the artificial data are based on k-nearest neighbors, we need to check the true positiveness of them. Moreover, ensemble learning algorithms are robust for data errors so that we want to apply the algorithm for our purpose. In this paper, when we have a skewed data set like phoneme database which have vocal sound data, we showed in experiment that the artificial instances could be checked by the machine learning algorithm of random forests which are based on ensemble learning and could generate more improved decision trees by using the checked instances."
A Comparison of Oversampling Methods on Imbalanced Topic Classification of Korean News Articles,2017,"['Imbalanced data', 'oversampling methods', 'SMOTE', 'topic classification']",,"Machine learning has progressed to match human performance, including the field of text classification. However, when training data are imbalanced, classifiers do not perform well. Oversampling is one way to overcome the problem of imbalanced data and there are many oversampling methods that can be conveniently implemented. While comparative researches of oversampling methods on non-text data have been conducted, studies comparing oversampling methods under a unifying framework on text data are scarce. This study finds that while oversampling methods generally improve the performance of classifiers, similarity is an important factor that influences the performance of classifiers on imbalanced and resampled data."
Performance Comparison of Logistic Regression Algorithms on RHadoop,2017,"['Big data', 'Hadoop', 'Logistic regression', 'R', 'RHadoop']",,"Machine learning has found widespread implementations and applications in many different domains in our life. Logistic regression is a type of classification in machine leaning, and is used widely in many fields, including medicine, economics, marketing and social sciences. In this paper, we present the MapReduce implementation of three existing algorithms, this is, Gradient Descent algorithm, Cost Minimization algorithm and Newton-Raphson algorithm, for logistic regression on RHadoop that integrates R and Hadoop environment applicable to large scale data. We compare the performance of these algorithms for estimation of logistic regression coefficients with real and simulated data sets. We also compare the performance of our RHadoop and RHIPE platforms. The performance experiments showed that our Newton-Raphson algorithm when compared to Gradient Descent and Cost Minimization algorithms appeared to be better to all data tested, also showed that our RHadoop was better than RHIPE in real data, and was opposite in simulated data."
스마트 워치를 사용한 일상생활 인간 행동 인지,2017,"['Machine Learning', 'Human Activity Recognition', 'Classifier', 'Smart Watch', 'Smart Phone']",,
동계 전력수요예측을 위한 신경망 모델에 관한 연구,2017,"['machine learning', 'artificial neural network', 'deep learning', 'electric power demand prediction', 'tensorflow']",,
드론 비행 조종을 위한 자이로센서 데이터 기계학습 모델,2017,"['Machine Learning', 'Gyro Sensor', 'Drone Flight', 'Drone Control', 'Data Mining']",,
Estimation of Desired Motion Intention and Compliance Control for Upper Limb Assist Exoskeleton,2017,"['Extreme learning machine', 'human motion intention estimation', 'model reference adaptive impedance control', 'upper limb assist exoskeleton']",,"In this paper, we have addressed two issues for upper limb assist exoskeleton. 1) Estimation of DesiredMotion Intention (DMI); 2) Robust compliance control. To estimate DMI, we have employed Extreme LearningMachine Algorithm. This algorithm is free from traditional Neural Network based problems such as local minima,selection of suitable parameters, slow convergence of adaptation law and over-fitting. These problems cause lot ofproblem in tuning the intelligent algorithm for the desired results. Furthermore, to track the estimated trajectory, wehave developed model reference based adaptive impedance control algorithm. This control algorithm is based onstable poles of desired impedance model, forcing the over all system to act as per desired impedance model. It alsoconsiders robot and human model uncertainties. To highlight the effectiveness of the proposed control algorithm, wehave compared it with simple impedance and target reference based impedance control algorithms. Experimentalevaluation is carried on seven degree of freedom upper limb assist exoskeleton. Results describe the effectiveness ofELM algorithm for DMI estimation and robust tracking of the estimated trajectory by the proposed model referenceadaptive impedance control law."
비디오에서 동체의 행위인지를 위한 효율적 학습 단위에 관한 연구,2017,"['Frame Learning Units', 'Behavior Recognition', 'Multiple Support Vector Machine', 'Multi Sliding Window']",,
TSK 기반의 ELM 예측기를 이용한 에너지 효율 예측,2017,"['Extreme Learning Machine', 'TSK Fuzzy Rule', 'Random Clustering', 'Predictor']",,"This study suggests an ELM model that is based on a TSK fuzzy model and compares its performance projection with the existing ELM model. The TSK based ELM model replaces the in the existing model with a linear function. Additionally, the center of the cluster is haphazardly set. The Weighted value between the hidden layer and input is nonexistent whereas the weighted value between the hidden layer and output apply a linear equation. In order to evaluate the performance of TSK - based ELM predictor, we compared the performance of existing ELM predictor with the energy efficiency problem using building cooling and heating load prediction data. In conclusion, the TSK based ELM model outperformed the current ELM model in performance projection."
Large-Scale Text Classification with Deep Neural Networks,2017,"['deep learning', 'large-scale text classification', 'natural language processing', 'artificial neural networks', '딥러닝', '대용량 문서 분류', '자연어 처리', '인공신경망']",,"The classification problem in the field of Natural Language Processing has been studied for a long time. Continuing forward with our previous research, which classifies large-scale text using Convolutional Neural Networks (CNN), we implemented Recurrent Neural Networks (RNN), Long- Short Term Memory (LSTM) and Gated Recurrent Units (GRU). The experiment’s result revealed that the performance of classification algorithms was Multinomial Naïve Bayesian Classifier < Support Vector Machine (SVM) < LSTM < CNN < GRU, in order. The result can be interpreted as follows: First, the result of CNN was better than LSTM. Therefore, the text classification problem might be related more to feature extraction problem than to natural language understanding problems. Second, judging from the results the GRU showed better performance in feature extraction than LSTM. Finally, the result that the GRU was better than CNN implies that text classification algorithms should consider feature extraction and sequential information. We presented the results of fine-tuning in deep neural networks to provide some intuition regard natural language processing to future researchers."
심층 신경망의 최적화를 통한 소규모 행동 분류 문제의 행동 인식 방법,2017,"['행동 인식', '심층 신경망', 'LRCN', '최적화', 'Activity Recognition', 'Deep Neural Network', 'Optimization']",,"Recently, Deep learning has been used successfully to solve many recognition problems. It has many advantages over existing machine learning methods that extract feature points through hand-crafting. Deep neural networks for human activity recognition split video data into frame images, and then classify activities by analysing the connectivity of frame images according to the time. But it is difficult to apply to actual problems which has small-scale activity classes. Because this situations has a problem of overfitting and insufficient training data. In this paper, we defined 5 type of small-scale human activities, and classified them. We construct video database using 700 video clips, and obtained a classifying accuracy of 74.00%."
Stress Identification and Analysis using Observed Heart Beat Data from Smar t HRM Sensor Device,2017,"['Stress', 'HRV', 'Machine Learning']",,
개인별 심박수 기준을 설정하기 위한 피드백-RFC 모델,2017,"['스마트 피트니스', '머신 러닝', '피드백', 'Smart Fitness', 'Machine Learning', 'Feedback']",,"Many of the wearable smart fitness devices provide services related to users` heartbeat rates. These services use fixed standards which have been pre-determined based on statistical data. However, because body conditions significantly differ between individuals, the services applying fixed standards to all individuals are not reliable. This paper proposes the Feedback-RFC model which adapts heartbeat standards to individual users` exercise abilities and also proposes a method to implement the model. This paper also shows the effectiveness of the Feedback-RFC model by collecting heartbeat data from 12 participants and evaluating the model with the data."
인공지능 기반 드론 목표물 추적 시스템의 설계 및 구현,2017,"['Drone(UAV)', 'Machine learning', 'Reinforcement learning', 'Target tracking', 'Communication']",,
컨볼루션 신경망을 사용한 영상 객체 추적에서 경계 박스 분할을 통한 효과적인 온라인 학습 알고리듬,2017,"['CNN', 'Deep learning', 'Visual tracking', 'Computer vision', 'machine learning', 'ANN']",,
Deep into the Brain: Artificial Intelligence in Stroke Imaging,2017,"['Artificial intelligence', 'Machine learning', 'Stroke']",,"<P>Artificial intelligence (AI), a computer system aiming to mimic human intelligence, is gaining increasing interest and is being incorporated into many fields, including medicine. Stroke medicine is one such area of application of AI, for improving the accuracy of diagnosis and the quality of patient care. For stroke management, adequate analysis of stroke imaging is crucial. Recently, AI techniques have been applied to decipher the data from stroke imaging and have demonstrated some promising results. In the very near future, such AI techniques may play a pivotal role in determining the therapeutic methods and predicting the prognosis for stroke patients in an individualized manner. In this review, we offer a glimpse at the use of AI in stroke imaging, specifically focusing on its technical principles, clinical application, and future perspectives.</P>"
전자상거래 추천시스템을 위한 순환신경망 알고리즘들의 성능평가,2017,"['전자상거래', '추천시스템', '머신러닝', '순환신경망', '최적화 알고리즘', '텐서플로우', 'e-commerce', 'recommendation system', 'machine learning', 'recurrent neural network', 'optimization algorithm', 'TensorFlow']","전자상거래 발전에 따라 온라인 쇼핑을 이용하는 사람들이 증가하였고 제품 또한 다양해지고 있다. 이러한 추세로 구매자가 만족할 수 있는 정확한 추천시스템의 중요성이 증대되었으며 정확도를 높이기 위한 새로운 방법의 연구가 계속되고 있다. 순환신경망은 시퀀스 학습에 적합한 딥 러닝 방법 중 하나이며 본 연구에서는 추천시스템의 정확도를 높이는 방법으로 구매자의 제품 접근순서를 순환신경망에 적용하여 알고리즘 성능평가를 하였다. 알고리즘 성능평가에는 대표적인 순환신경망 알고리즘과 최적화 알고리즘으로 진행하였다. 순환신경망 알고리즘으로는 RNN, LSTM, GRU 그리고 최적화 알고리즘으로는 Adagrad, RMSProp, Adam optimizer를 사용하였다. 실험 도구로는 구글의 오픈소스 라이브러리인 텐서플로우를 사용하였고 데이터는 RecSys Challenge 2015에서 제공하는 e-commerce session 데이터를 활용하였다. 실험 결과 실험 데이터에 적합한 최적의 하이퍼파라미터를 발굴하고 적용하여 RecSys Challenge 2015 참가자들의 결과와 비교하였다. 상품 접근 순서만을 학습시킨 결과이기 때문에 등수가 높지는 않았지만 기존 추천시스템에 접목한다면 정확도 향상에 기여할 수 있을 것으로 보인다.","Due to the advance of e-commerce systems, the number of people using online shopping and products has significantly increased. Therefore, the need for an accurate recommendation system is becoming increasingly more important. Recurrent neural network is a deep-learning algorithm that utilizes sequential information in training. In this paper, an evaluation is performed on the application of recurrent neural networks to recommendation systems. We evaluated three recurrent algorithms (RNN, LSTM and GRU) and three optimal algorithms(Adagrad, RMSProp and Adam) which are commonly used. In the experiments, we used the TensorFlow open source library produced by Google and e-commerce session data from RecSys Challenge 2015. The results using the optimal hyper-parameters found in this study are compared with those of RecSys Challenge 2015 participants."
Navigator Lookout Activity Classification Using Wearable Accelerometers,2017,"['Lookout activity classification', 'Machine learning', 'Maritime information', 'Wearable sensor']",,"Maintaining a proper lookout activity routine is integral to preventing ship collision accidents caused by human errors. Various subjective measures such as interviewing, self-report diaries, and questionnaires have been widely used to monitor the lookout activity patterns of navigators. An objective measurement of a lookout activity pattern classification system is required to improve lookout performance evaluation in a real navigation setting. The purpose of this study was to develop an objective navigator lookout activity classification system using wearable accelerometers. In the training session, 90.4% accuracy was achieved in classifying five fundamental lookout activities. The developed model was then applied to predict real-lookout activity in the second session during an actual ship voyage. 86.9% agreement was attained between the directly observed activity and predicted activity. Based on these promising results, the proposed unobstructed wearable system is expected to objectively evaluate navigator lookout patterns to provide a better understanding of lookout performance."
Gaussian-Based SMOTE Algorithm for Solving Skewed Class Distributions,2017,"['Skewed class distribution', 'SMOTE', 'Gaussian random variable', 'Classification']",,"Sufficient amount of learning data is an essential condition to implement a classifier with excellent performance. However, the obtained data usually follow a significantly biased distribution of classes. It is called a class imbalance problem, which is one of the frequently occurred issues in the real world applications. This problem causes a considerable performance drop because most of the machine learning methods assume given data follow a balanced distribution of classes. The implemented classifier will derive false classification results if the problem is not solved. Therefore, this paper proposes a novel method, named as Gaussianbased SMOTE, to solve the problem by combining Gaussian distribution in a synthetic data generation process. It is confirmed that the proposed method could solve the class imbalance problem by conducting experiments with actual cases."
텍스트 마이닝을 통한 셰익스피어 학술논문 영어초록 코퍼스의 토픽모델링 분석,2017,"['셰익스피어', '코퍼스언어학', '토픽모델링', '머신러닝', '키워드분석', '트렌드 분석', 'Shakespeare', 'Corpus Linguistics', 'topic modeling', 'machine learning', 'keyword analysis', 'trend analysis']",,
연관법령 검색을 위한 워드 임베딩 기반 Law2Vec 모형 연구,2017,"['텍스트 마이닝', '법률 정보', '머신 러닝', '워드임베딩', 'Word2Vec', '키워드 검색', 'Text Mining', 'Legal Tech', 'Machine Learning', 'Word Embedding', 'Word2Vec', 'Keyword']",,"The ultimate goal of legal knowledge search is to obtain optimal legal information based on laws and precedent. Text mining research is actively being undertaken to meet the needs of efficient retrieval from large scale data. A typical method is to use a word embedding algorithm based on Neural Net. This paper demonstrates how to search relevant information, applying Korean law information to word embedding. First, we extracts reference laws from precedents in order and takes reference laws as input of Law2Vec. The model learns a law by predicting its surrounding context law. The algorithm then moves over each law in the corpus and repeats the training step. After the training finished, we could infer the relationship between the laws via the embedding method. The search performance was evaluated based on precision and the recall rate which are computed from how closely the results are associated to the search terms. The test result proved that what this paper proposes is much more useful compared to existing systems utilizing only keyword search when it comes to extracting related laws."
A novel classification approach based on Naive Bayes for Twitter sentiment analysis,2017,"['Twitter sentiment analysis', 'Machine learning', 'Naive Bayes', 'Attribute weighting', 'Feature selection']",,"With rapid growth of web technology and dissemination of smart devices, social networking service(SNS) is widely used. As a result, huge amount of data are generated from SNS such as Twitter, and sentiment analysis of SNS data is very important for various applications and services. In the existing sentiment analysis based on the Naive Bayes algorithm, a same number of attributes is usually employed to estimate the weight of each class. Moreover, uncountable and meaningless attributes are included. This results in decreased accuracy of sentiment analysis. In this paper two methods are proposed to resolve these issues, which reflect the difference of the number of positive words and negative words in calculating the weights, and eliminate insignificant words in the feature selection step using Multinomial Naive Bayes(MNB) algorithm. Performance comparison demonstrates that the proposed scheme significantly increases the accuracy compared to the existing Multivariate Bernoulli Naive Bayes(BNB) algorithm and MNB scheme."
A Risk Classification Based Approach for Android Malware Detection,2017,"['Android', 'malware detection', 'risk', 'machine learning', 'fuzzy logic']",,"Existing Android malware detection approaches mostly have concentrated on superficial features such as requested or used permissions, which can`t reflect the essential differences between benign apps and malware. In this paper, we propose a quantitative calculation model of application risks based on the key observation that the essential differences between benign apps and malware actually lie in the way how permissions are used, or rather the way how their corresponding permission methods are used. Specifically, we employ a fine-grained analysis on Android application risks. We firstly classify application risks into five specific categories and then introduce comprehensive risk, which is computed based on the former five, to describe the overall risk of an application. Given that users` risk preference and risk-bearing ability are naturally fuzzy, we design and implement a fuzzy logic system to calculate the comprehensive risk. On the basis of the quantitative calculation model, we propose a risk classification based approach for Android malware detection. The experiments show that our approach can achieve high accuracy with a low false positive rate using the RandomForest algorithm."
Optimal Classifier for Detection of Obstructive Sleep Apnea Using a Heartbeat Signal,2017,"['Obstructive sleep apnea', 'Machine learning', 'SVM', 'LR', 'DT', 'LDA', 'KNN']",,"This study is to find the optimum classifier that can be easy and robust diagnostic method of the obstructive sleep apnea (OSA) using a heartbeat signal. The heartbeat signal was acquired from the 92 patients with OSA. The dataset consists 98,060 epochs, from them the training sets contained 68,642 epochs from the 63 OSA patients and test sets contained 29,418 epochs from the 29 OSA patients, respectively. The heartbeat signal was analyzed in the time and frequency domain and six features were extracted (normal-to-normal [NN], standard deviation of mean NN [SDNN], root mean square of successive differences [rMSSD], low-frequency [LF], high-frequency [HF], and LF/HF ratio). All extracted features were used to train the following classifiers: linear discriminant analysis (LDA), decision tree (DT), logistic regression (LR), k-nearest neighbor (KNN) and support vector machine (SVM). The top three classifiers (SVM, DT, and LDA) showed the accuracy of 93.2%, 93.2%, and 93.2% for test sets, respectively. Then, the top three classifiers could be effective on sleep studies and OSA detections."
A CTR Prediction Approach for Text Advertising Based on the SAE-LR Deep Neural Network,2017,"['Deep Neural Network', 'Machine Learning', 'Text Advertising', 'SAE-LR']",,"For the autoencoder (AE) implemented as a construction component, this paper uses the method of greedylayer-by-layer pre-training without supervision to construct the stacked autoencoder (SAE) to extract theabstract features of the original input data, which is regarded as the input of the logistic regression (LR)model, after which the click-through rate (CTR) of the user to the advertisement under the contextualenvironment can be obtained. These experiments show that, compared with the usual logistic regressionmodel and support vector regression model used in the field of predicting the advertising CTR in theindustry, the SAE-LR model has a relatively large promotion in the AUC value. Based on the improvement ofaccuracy of advertising CTR prediction, the enterprises can accurately understand and have cognition for theneeds of their customers, which promotes the multi-path development with high efficiency and low costunder the condition of internet finance."
A CTR Prediction Approach for Text Advertising Based on the SAE-LR Deep Neural Network,2017,"['Deep Neural Network', 'Machine Learning', 'Text Advertising', 'SAE-LR']",,"For the autoencoder (AE) implemented as a construction component, this paper uses the method of greedy layer-by-layer pre-training without supervision to construct the stacked autoencoder (SAE) to extract the abstract features of the original input data, which is regarded as the input of the logistic regression (LR) model, after which the click-through rate (CTR) of the user to the advertisement under the contextual environment can be obtained. These experiments show that, compared with the usual logistic regression model and support vector regression model used in the field of predicting the advertising CTR in the industry, the SAE-LR model has a relatively large promotion in the AUC value. Based on the improvement of accuracy of advertising CTR prediction, the enterprises can accurately understand and have cognition for the needs of their customers, which promotes the multi-path development with high efficiency and low cost under the condition of internet finance."
Energy Prediction Modeling for Numerical Control Programs Using MTConnect,2017,"['Energy prediction (에너지 예측)', 'Machine tool (공작기계)', 'Machine-learning (기계 학습)', 'MTConnect (엠티커넥트)', 'Data analytics (데이터 분석)']",,
LSTM모델 기반 전기차용 2단 감속기 유압 예측,2022,"['Hydraulic Pressure(유압)', 'Deep Learning(딥러닝)', 'Machine Learning(머신러닝)', 'Long Short Term Memory(장단기 순환신경망)', 'Vehicle Control(차량 제어)']",,
사물인터넷과 AI가 가져올 산업구조의 변화,2017,"['Internet of Things', 'Machine Learning', 'Security', 'Cloud Computing', 'Big Data', 'Mobile Platform']","최근 국내외적으로 사물인터넷(IoT, Internet of Things) 서비스 산업은 매우 빠른 속도로 변화하고 성장해 나가고 있다. 본 논문은 IoT 서비스 산업의 변화와 함께 일어나고 있는 인류의 삶 속에서의 새로운 변화의 원동력이 무엇인가를 찾기 위해 노력하였다. 이렇게 시장 환경이 변화하는 가운데 경쟁도 글로벌 경쟁, 생태계 경쟁으로 그 양상이 확대되고 있으나, 글로벌 기업들의 플랫폼 선점과 고도의 생태계 발전 전략에 비해 국내 기업들의 생태계 구축 비전은 아직 뚜렷하지 않은 상황이다. 또한 IoT 서비스의 확산에 따른 모바일 네트워크에서의 IoT 서비스 연동이 요구되고 있다. IoT 보안 프로토콜은 무선과 유 선을 연계하는 게이트웨이(Gateway)에서 전달되는 데이터의 모든 내용이 누출되는 보안상의 취약점이 있어 종단간 보안도 제공하지 못하는 단점이 있다. 이에 본 논문에서는 IoT와 인공지능(AI) 서비스 산업 생태계를 구성하고 있는 제반 요소의 현 황을 살펴본 후, 이로부터 얻을 수 있는 보안 산업과 관련한 전략적 시사점을 제시해 보고자 한다.","Recently IoT(Internet of Things) service industry has grown very rapidly. In this paper, we investigated the changes in IoT service industry as well as new direction of human life in future global society. Under these changing market conditions, competition has been also changed into global and ecological competition. But compared to the platform initiatives and ecological strategies of global companies, Korean companies' vision of building ecosystems is still unclear. In addition, there is a need of internetworking between mobile and IoT services. IoT security Protocol has weakness of leaking out information from Gateway which connected wire and wireless communication. As such, we investigate the structure of IoT and AI service ecosystem in order to gain strategic implications and insights for the security industry in this paper."
Music Key Identification using Chroma Features and Hidden Markov Models,2017,"['Music Key', 'Hidden Markov Model', 'Chroma Features', 'Machine Learning']",,"A musical key is a fundamental concept in Western music theory. It is a collective characterization of pitches and chords that together create a musical perception of the entire piece. It is based on a group of pitches in a scale with which a music is constructed. Each key specifies the set of seven primary chromatic notes that are used out of the twelve possible notes. This paper presents a method that identifies the key of a song using Hidden Markov Models given a sequence of chroma features. Given an input song, a sequence of chroma features are computed. It is then classified into one of the 24 keys using a discrete Hidden Markov Models. The proposed method can help musicians and disc-jockeys in mixing a segment of tracks to create a medley. When tested on 120 songs, the success rate of the music key identification reached around 87.5%."
"자율주행 시대, 차세대 소프트웨어에서 길을 찾다",2017,"['Autonomous Vehicle', 'Self Driving', 'Smart Car', 'Machine Learning', 'Mobility', 'Automotive Software']","아이폰의 등장과 함께 시작된 스마트폰이 최근 10년간 시장의 변화와 혁신의 중심을 주도해 왔다면, 이제 자율 주행, 커넥티드 서비스, 공유 모델 등으로 대별되는 스마트카가 향후 10년간 그 자리를 이어갈 양상이다. 맥킨지컨설팅에 따르면 기술적, 규제적 이슈들이 해결되어 갈 경우 2030년경에는 전 세계 신차 판매량의15%가 자율주행이 가능한 차량일 것으로 추정되고 있다.이러한 성장의 전제조건인 기술적 이슈의 핵심은 차량의 인지, 판단, 제어절차를 고도화할 수 있는 센서, 네트워크, 데이터분석 기술 등의 고도화와 밀접하게 연관되며, 특히 내외부 데이터를 취합하고 실시간으로 분석하여 판단할 수 있는 알고리즘과 소프트웨어 기술의 중요성이 더욱 부각되고 있다.자율주행의 본격적 적용을 위해서는 기술적 발전을 넘어, 규제 및 사회적 수용 여부도 필수불가결한 조건이 될 것으로 전망된다. 또한 자율주행은 자동차산업의 비즈니스 모델 자체를 일회성 신차구매소유형 모델에서 우버 등으로 대표되는 사용료 기반의 모빌리티 공유형 모델로의 전환을 가속화할 것으로 예상된다.이러한 시점에 본 보고서에서는 자율주행 기술과 관련된 기술적 요소 중 기존 하드웨어 중심의 기술 요소 외에, 통합적 소프트웨어 아키텍처, 외부 정보 센싱 및 지능형 알고리즘, 유연한 내외부 인터페이스, 사이버 보안 및 표준화 등의 소프트웨어적 특징을 살펴보고자 한다.",
Statistics and Deep Belief Network-Based Cardiovascular Risk Prediction,2017,"['Cardiovascular Diseases', 'Deep Belief Network', 'Machine Learning', 'Cardiovascular Risk Prediction', 'KNHANES']",,"Objectives: Cardiovascular predictions are related to patients’ quality of life and health. Therefore, a risk prediction model for cardiovascular conditions is needed. Methods: In this paper, we propose a cardiovascular disease prediction model using the sixth Korea National Health and Nutrition Examination Survey (KNHANES-VI) 2013 dataset to analyze cardiovascularrelated health data. First, statistical analysis was performed to find variables related to cardiovascular disease using health data related to cardiovascular disease. Second, a model of cardiovascular risk prediction by learning based on the deep belief network (DBN) was developed. Results: The proposed statistical DBN-based prediction model showed accuracy and an ROC curve of 83.9% and 0.790, respectively. Thus, the proposed statistical DBN performed better than other prediction algorithms.Conclusions: The DBN proposed in this study appears to be effective in predicting cardiovascular risk and, in particular, is expected to be applicable to the prediction of cardiovascular disease in Koreans."
과거시차를 고려한 지지벡터 회귀모형에 기반한 서울지역 가뭄예측,2017,"['기계학습', '지지 벡터 회귀', '비정상성', '표준강수지수.', 'machine leaning', 'support vector regression', 'nonstationary', 'standardized precipitation index.']","본 연구에서는 가뭄의 척도를 나타내는 표준강수지수(SPI)를 이용하여 기계학습 기법 중 하나인 지지 벡터 회귀(support vector regression; SVR) 모형과 더불어 과거시차를 고려함으로서 시계열 분석방법의 단점을 보완하고자 한다. 본 논문에서는 SVR모형 적용시 자료의 형태를 크게 두 가 지로 구분한 후, 그 중 하나를 다시 4가지로 구분하여 총 5가지의 자료형태를 정의하였다. 첫째로 과거시차를 고려하지 않은 자료의 형태로 현재시점의 독립변수로 현재시점의 종속변수를 예측하는 자료형태이다. 둘째로 과거시차를 고려한 자료형태이다. 과거시차를 고려한 자료형태는 4가지로 과거 3개월, 6개월, 9개월, 12개월의 자료를 독립변수로 고려하고 현재시점의 종속변수를 예측하는 자료형태이다. 가뭄현상이란 오랫동안 계속해 비가 내리지 않아 메마른 날씨로 강수량의 영향을 받는다. 따라서 본 연구에서는 5가지의 자료형태에 따른 SVR모형을 적용하고, 강수량의 계절적 요인을 파악한 후 계절적 요인을 고려한 SVR을 적용한 후 비교평가 하였다. 결론적으로 과거시차를 고려한 자료형태가 고려하지 않은 자료형태보다 SVR모형의 예측정확도가 높았다. 그 중 과거 6개월을 독립변수로 고려한 SVR모형의 예측정확도가 가장 우수했다. 이를 통해 본 연구의 본래목적에 부합한 자료의 형태는 과거시차를 고려한 자료 중 과거 6개월을 독립변수로 고려한 자료임을 확인하였다. 하지만 본 연구에서는 계절성을 고려하지 않은 SVR모형과 계절성을 고려한 SVR모형의 예측정확도의 값의 차는 크지 않았다. 따라서 본 연구에서는 과거시차를 고려한 자료를 통해 SPI를 예측하는데 계절적 요소가 유의하지 않다고 판단하였다.","The purpose of this study overcomes the limitation in time series data analysis using the support vector regression (SVR) model, which is one of the machine learning methods. We apply the SVR model to the nonstationary monthly SPI (standardized precipitation index) time series data which is one of the measures of drought. We consider two different data types to build SVR model. First, we do not consider the past time-lag. Second, we consider the reasonable amount of past time-lags. The data of considering past time-lags are 4 type, these are 3, 6, 9 and 12 months as the independent variable. Totally, we define 5 types of data sets. Therefore, in this study, SVR model according to 5 types of data was applied, and also SVR model with seasonality was applied after identify the seasonal factors of precipitation. In conclusion, it is more accurate to consider the past time-lag in all SVR models. Among the data considering the past time-lag, the data considering the past 6 months shows the best performance. However, the difference between the SVR model without seasonality and with seasonality is not significant. Therefore, we conclude that seasonal factors is not significant for prediction SPI."
폐 결절 검출을 위한 합성곱 신경망의 성능 개선,2017,"['Pulmonary nodule detection', 'Convolutional Neural Network', 'Machine learning']",,"Early detection of the pulmonary nodule is important for diagnosis and treatment of lung cancer. Recently, CT has been used as a screening tool for lung nodule detection. And, it has been reported that computer aided detection(CAD) systems can improve the accuracy of the radiologist in detection nodules on CT scan. The previous study has been proposed a method using Convolutional Neural Network(CNN) in Lung CAD system. But the proposed model has a limitation in accuracy due to its sparse layer structure. Therefore, we propose a Deep Convolutional Neural Network to overcome this limitation. The model proposed in this work is consist of 14 layers including 8 convolutional layers and 4 fully connected layers. The CNN model is trained and tested with 61,404 regions-of-interest (ROIs) patches of lung image including 39,760 nodules and 21,644 non-nodules extracted from the Lung Image Database Consortium(LIDC) dataset. We could obtain the classification accuracy of 91.79% with the CNN model presented in this work. To prevent overfitting, we trained the model with Augmented Dataset and regularization term in the cost function. With L1, L2 regularization at Training process, we obtained 92.39%, 92.52% of accuracy respectively. And we obtained 93.52% with data augmentation. In conclusion, we could obtain the accuracy of 93.75% with L2 Regularization and Data Augmentation."
실시간 학습 방법을 이용한 베어링 고장진단 성능 개선,2017,"['기계학습', '실시간학습', '고장진단', '상태 인지', '특징 추출', 'Machine learning', 'Real-time training', 'Fault diagnosis', 'Condition recognition', 'Feature extraction']",본 논문에서는 베어링 고장진단 성능을 개선하기 위해 실시간 학습 방법을 제안한다. 기존 베어링 고장진단의 문제점은 학습되지 않은 상태에 대해 올바른 분류를 할 수 없다는 점이다. 제안한 4단계 실시간 학습 방법은 새로운 상태를 실시간으로 인지 및 학습하여 새로운 상태의 데이터를 올바르게 분류할 수 있다. 1단계에서는 학습 정보에서 각 클래스의 무게중심과 그 클래스 내 각 특징벡터 사이의 유클리디안 거리를 계산하여 각 클래스별로 거리의 최대값을 계산한다. 2단계에서는 새로 취득된 데이터의 특징벡터와 각 클래스의 무게중심 사이의 유클리디안 거리를 계산하고 각 클래스별 최대 허용 거리와 비교한다. 3단계에서는 새로 취득된 데이터들과 각 클래스 내 무게중심 사이의 거리가 각 클래스의 최대 허용 거리보다 모두 클 경우 새로운 상태의 데이터로 인지하고 새로운 상태 인지 횟수를 증가시킨다. 마지막 4단계에서는 새로운 상태 인지 회수가 10보다 클 경우 새로운 상태의 클래스를 생성하기 위해 새로운 상태로 인지된 10개의 데이터를 새로운 상태의 클래스로 지정하고 분류기를 재학습시킨다. 제안한 방법의 성능을 검증하기 위해 실제 베어링 결함 데이터를 사용하여 제안한 실시간 학습 방법의 효율성을 검증하였다.,"In this paper, a real-time training method to improve the performance of bearing fault diagnosis. The traditional bearing fault diagnosis cannot classify a condition which is not trained by the classifier. The proposed 4-step method trains and recognizes new condition in real-time, thereby it can classify the condition accurately. In the first step, we calculate the maximum distance value for each class by calculating a Euclidean distance between a feature vector of each class and a centroid of the corresponding class in the training information. In the second step, we calculate a Euclidean distance between a feature vector of new acquired data and a centroid of each class, and then compare with the allowed maximum distance of each class. In the third step, if the distance between a feature vector of new acquired data and a centroid of each class is larger than the allowed maximum distance of each class, we define that it is data of new condition and increase count of new condition. In the last step, if the count of new condition is over 10, newly acquired 10 data are assigned as a new class and then conduct re-training the classifier. To verify the performance of the proposed method, bearing fault data from a rotating machine was utilized."
Development of Image-based Assistant Algorithm for Vehicle Positioning by Detecting Road Facilities,2017,"['Vehicle Positioning', 'Sensor Fusion', 'Single Photo Resection', 'Machine Learning', 'Object Detection', 'Road Facilities']",,
Hot spot DBC: Location based information diffusion for marketing strategy in mobile social networks,2017,"['NCCU', 'mobile social networks', 'information diffusion', 'machine learning', 'viral marketing']",,"As the advances of technology in mobile networking and the popularity of online social networks (OSNs), the mobile social networks (MSNs) provide opportunities for marketing strategy. Therefore, understanding the information diffusion in the emerging MSNs is a critical issue. The information diffusion address a problem of how to find the proper initial nodes who can effectively propagate as widely as possible in the minimum amount of time. We propose a new diffusion scheme, called Hotspot DBC, which is to find k influential nodes considering each node’s mobility behavior in the hotspot zones. Our experiments were conducted in the Opportunistic Network Environment (ONE) using real GPS trace, to show that the proposed scheme results. In addition, we demonstrate that our proposed scheme outperforms other existing algorithms."
컨벌루션 신경회로망과 ReLU 함수 기반 ELM 분류기를 이용한 영상 분류,2017,"['convolutional neural network', 'rectified linear unit', 'extreme learning machine', 'image classification']",,
Analyzing Visitors’ Preferences on Tourism Accommodation Services by Opinion Mining,2017,"['Sentiment analysis', 'hotel services', 'services preferences', 'machine learning', 'Vietnam']",,"Tourism is considered as one of the most important industries in Vietnam. The Government continuously keeps managing and asking for improving all sectors related to tourism. As an important infrastructure for tourism industries, hotels are highly considered for improving customer services. On hotel booking and reviews channels, customers express their opinions and feedback about their experienced hotels by writing online reviews, this is valuable source of information that hotel managers should utilize. In this study, we collected 22,383 online reviews about Vietnamese hotels written by foreign customers in English. Then we developed a hybrid model to perform opinion mining on social media text and explore for customer opinion. The results show that opinion mining on customers reviews can show services preferences on hotel services. Based on this result we recommend for improving customer satisfactions via diversifying across cultures services."
Gated Multi-Modal Neural Networks를 이용한 다중 웨어러블 센서 결합 방법 및 일상 행동 패턴 분석,2017,"['Gated multi-modal neural networks', 'Multi-modal learning', 'Wearable sensor', '자동 행동 스키마 생성', 'automaticschema construction']","본고에서는 다중 웨어러블 센서 데이터로부터 사용자의 일상 생활 행동 패턴을 분석할 수 있는 새로운 기계학습 모델을 제안한다. 제안하는 모델은 다중 웨어러블 센서 데이터를 효과적으로 학습하기 위하여 사람이 다중 센서 정보를 처리하는 방법을 적용한 새로운 신경망 모델이다. 제안하는 Gated multi-modal neural netoworks는 계층적 신경망 구조를 가지고 있으며 Gate 모듈을 통해 각 센서 데이터를 선택적으로 결합하여 처리하는 특징을 가진다. 실험을 위해 다중 웨어러블 장치를 착용하고 일상 생활 중 한 가지인 레스토랑에서의 행동 센서 데이터를 수집하였다. 실험 결과로서, 제시하는 모델을 이용하여 실제 웨어러블 센서 데이터를 분석하였을 때 분류 정확도가 비교적 정확하고 빠르게 처리할 수 있음을 확인하였다. 또한 모델의 중간 계층에서의 노드의 활성화 패턴 분석을 통해 자동으로 일상생활 패턴을 추출할 수 있고 이를 이용하여 지식 스키마를 생성할 수 있음을 확인하였다.","We propose a new machine learning algorithm which analyzes daily activity patterns of users from multi-modal wearable sensor data. The proposed model learns and extracts activity patterns using input from wearable devices in real-time. Inspired by cue integration of human""s property, we constructed gated multi-modal neural networks which integrate wearable sensor input data selectively by using gate modules. For the experiments, sensory data were collected by using multiple wearable devices in restaurant situations. As an experimental result, we first show that the proposed model performs well in terms of prediction accuracy. Then, the possibility to construct a knowledge schema automatically by analyzing the activation patterns in the middle layer of our proposed model is explained."
Fine-Grained Mobile Application Clustering Model Using Retrofitted Document Embedding,2017,"['Document embedding', 'Text clustering', 'Deep learning']",,"In this paper, we propose a fine-grained mobile application clustering model using retrofitted document embedding. To automatically determine the clusters and their numbers with no predefined categories, the proposed model initializes the clusters based on title keywords and then merges similar clusters. For improved clustering performance, the proposed model distinguishes between an accurate clustering step with titles and an expansive clustering step with descriptions. During the accurate clustering step, an automatically tagged set is constructed as a result. This set is utilized to learn a high-performance document vector. During the expansive clustering step, more applications are then classified using this document vector. Experimental results showed that the purity of the proposed model increased by 0.19, and the entropy decreased by 1.18, compared with the K-means algorithm. In addition, the mean average precision improved by more than 0.09 in a comparison with a support vector machine classifier."
Hot spot DBC: Location based information diffusion for marketing strategy in mobile social networks,2017,"['mobile social networks', 'information diffusion', 'machine learning', 'NCCU', 'viral marketing']",모바일 디바이스의 무선 네트워크 통신 기술과 온라인 소셜 네트워크 발전으로 모바일 소셜 네트워크는 모바일 기기 사이에 마케팅 전략의 기회를 제공한다. 이에 따라 모바일 소셜 네트워크 상에서 정보 유포는 중요한 문제가 되었으며 여러 기법을 제안해왔다. 정보 유포 연구 정의는 메시지와 같은 정보를 가진 초기 노드로부터 최소한의 시간에 최대한 많은 유저에게 정보를 전달하는 기법이다. 본 논문에서 우리는 새로운 정보 유포 기법인 기계학습과 소셜 위치정보 기반의 Hotspot DBC를 제안한다. 위치기반 정보 유포 기법으로써 핫스팟 지역을 사용한다. 웜업 기간에 움직임 패턴을 활용하여 초기 영향력 있는 노드를 찾는다. 이후 전체 네트워크 지역을 고려하는 것이 아닌 특정 핫스팟 지역에서만 패턴을 추출하여 찾는다. 웜업 기간 끝나는 시점에서 각 노드는 움직임 패턴을 추출한다. 마지막으로 각 패턴에서 소셜 관계를 분석함으로써 영향력 있는 노드 k개가 선정된다. 우리는 기회적 네트워크 환경에서 GPS 위치 기록의 실제 모바일 노드의 움직임 데이터를 ONE 시뮬레이터 환경에서 실험하였다. 추가적으로 통신범위와 초기 정보 유포 k 노드 수를 다양하게 실험하여 기존 기법보다 더 나은 결과를 확인할 수 있다.,"As the advances of technology in mobile networking and the popularity of online social networks (OSNs), the mobile social networks (MSNs) provide opportunities for marketing strategy. Therefore, understanding the information diffusion in the emerging MSNs is a critical issue. The information diffusion address a problem of how to find the proper initial nodes who can effectively propagate as widely as possible in the minimum amount of time. We propose a new diffusion scheme, called Hotspot DBC, which is to find k influential nodes considering each node's mobility behavior in the hotspot zones. Our experiments were conducted in the Opportunistic Network Environment (ONE) using real GPS trace, to show that the proposed scheme results. In addition, we demonstrate that our proposed scheme outperforms other existing algorithms."
전통문화 이미지를 위한 세부 자질 주목형 이미지 자동 분석기,2017,"['Image Processing', 'Image Classifier', 'Deep Learning', 'Artificial Neural Networks', 'Natural Language Processing', 'Machine Learning', 'Artificial Intelligence', '이미지 처리', '이미지 분류기', '딥러닝', '인공신경망', '자연어처리', '기계학습', '인공지능']","이 논문에서는 최근 전통문화의 늘어나는 콘텐츠와 대조적으로 전통문화에 대한 접근성이 떨어지는 점에 주목하여 이러한 콘텐츠의 접근성의 향상을 위해 지속된 관리와 연구를 위하여 전통문화 이미지를 위한 이미지 자동 분석기를 소개한다. 이 논문에서 소개하는 이미지 자동 분석기는 인공신경망을 기반으로 입력 이미지의 자질들을 벡터스페이스로 변환하여 이를 RNN 기반의 모델을 통하여 세부 자질들을 파악하여 전통문화 이미지의 분류를 행한다. 이러한 방법을 통하여 전체적으로 비슷하게 보이는 전통문화 이미지들의 분류를 가능케 한다. 해당 모델의 훈련을 위하여 한민족정보문화마당 기반의 형식을 토대로 넓은 폭의 이미지 데이터를 수집 및 정리하여 차후 전통문화 이미지 관련 분야에서 사용할 수 있는 데이터셋의 구축에 기여를 하였다. 또한 이러한 연구가 최종적으로 전통문화와 관련된 수요, 공급 및 연구가 한층 더 활발해지는 것에 기여를 한다.","As accessibility toward traditional cultural contents drops compared to its increase in production, the need for higher accessibility for continued management and research to exist. For this, this paper introduces an image classifier model for traditional images based on artificial neural networks, which converts the input image's features into a vector space and by utilizing a RNN based model it recognizes and compares the details of the input which enables the classification of traditional images. This enables the classifiers to classify similarly looking traditional images more precisely by focusing on the details. For the training of this model, a wide range of images were arranged and collected based on the format of the Korean information culture field, which contributes to other researches related to the fields of using traditional cultural images. Also, this research contributes to the further activation of demand, supply, and researches related to traditional culture."
Music Key Identification using Chroma Features and Hidden Markov Models,2017,"['Music Key', 'Hidden Markov Model', 'Chroma Features', 'Machine Learning']",,
외골격 로봇의 동작인식을 위한 보행의 운동학적 요인을 이용한 보행유형 분류,2017,"['Gait', 'Exoskeleton robot', 'Kinematics', 'IMUs sensor', 'Machine learning']",,"The exoskeleton robot is a technology developed to be used in various fields such as military, industry and medical treatment. The exoskeleton robot works by sensing the movement of the wearer. By recognizing the wearer's daily activities, the exoskeleton robot can assist the wearer quickly and efficiently utilize the system. In this study, LDA, QDA, and kNN are used to classify gait types through kinetic data obtained from subjects. Walking was selected from general walking and stair walking which are mainly performed in daily life. Seven IMUs sensors were attached to the subject at the predetermined positions to measure kinematic factors. As a result, LDA was classified as 78.42%, QDA as 86.16%, and kNN as 87.10% ~ 94.49% according to the value of k."
Analyzing Visitors' Preferences on Tourism Accommodation Services by Opinion Mining,2017,"['Sentiment analysis', 'hotel services', 'services preferences', 'machine learning', 'Vietnam']",,"Tourism is considered as one of the most important industries in Vietnam. The Government continuously keeps managing and asking for improving all sectors related to tourism. As an important infrastructure for tourism industries, hotels are highly considered for improving customer services. On hotel booking and reviews channels, customers express their opinions and feedback about their experienced hotels by writing online reviews, this is valuable source of information that hotel managers should utilize. In this study, we collected 22,383 online reviews about Vietnamese hotels written by foreign customers in English. Then we developed a hybrid model to perform opinion mining on social media text and explore for customer opinion. The results show that opinion mining on customers reviews can show services preferences on hotel services. Based on this result we recommend for improving customer satisfactions via diversifying across cultures services."
GPGPU와 Combined Layer를 이용한 필기체 숫자인식 CNN구조 구현,2017,"['기계학습', '스레드', '필기체인식', 'CNN', 'GPGPU', 'MNIST', 'machine learning', 'CNN', 'GPGPU', 'thread', 'Handwriting Recognition', 'MNIST']",,
소셜 빅데이터 분석과 기계학습을 이용한 영화흥행예측 기법의 실험적 평가,2017,"['Box office Revenue', 'Social Bigdata', 'Machine Learning', 'Prediction', 'Reviews']",,
인공지능에 대한 연구의 현황과 전망 ― 윤리 규범의 관점에서,2017,"['기계 학습', '규범', '윤리', '인공지능', '행위자', 'Agent', 'Artificial Intelligence (A.I.)', 'Machine Learning', 'Moral(Ethical)', 'Responsibility']",,
Pet Shop Recommendation System based on Implicit Feedback,2017,"['기계 학습', '추천 시스템', '암묵적 피드백', '상품 클릭 정보', 'Machine learning', 'Recommendation systems', 'Implicit feedback', 'Click information on items']",,
Calculation of Detector Positions for a Source Localizing Radiation Portal Monitor System Using a Modified Iterative Genetic Algorithm,2017,"['Radiation portal monitor', 'Optimization', 'Modified iterative genetic algorithm', 'Machine learning', 'Designing source localizing RPM']",,"Background: This study aims to calculate detector positions as a design of a radioactive source localizing radiation portal monitor (RPM) system using an improved genetic algorithm. Materials and Methods: To calculate of detector positions for a source localizing RPM system optimization problem is defined. To solve the problem, a modified iterative genetic algorithm (MIGA) is developed. In general, a genetic algorithm (GA) finds a globally optimal solution with a high probability, but it is not perfect at all times. To increase the probability to find globally optimal solution rather, a MIGA is designed by supplementing the iteration, competition, and verification with GA. For an optimization problem that is defined to find detector positions that maximizes differences of detector signals, a localization method is derived by modifying the inverse radiation transport model, and realistic parameter information is suggested. Results and Discussion: To compare the MIGA and GA, both algorithms are implemented in a MATLAB environment. The performance of the GA and MIGA and that of the procedures supplemented in the MIGA are analyzed by computer simulations. The results show that the iteration, competition, and verification procedures help to search for globally optimal solutions. Further, the MIGA is more robust against falling into local minima and finds a more reliably optimal result than the GA. Conclusion: The positions of the detectors on an RPM for radioactive source localization are optimized using the MIGA. To increase the contrast of the measurements from each detector, a relationship between the source and the detectors is derived by modifying the inverse transport model. Realistic parameters are utilized for accurate simulations. Furthermore, the MIGA is developed to achieve a reliable solution. By utilizing results of this study, an RPM for radioactive source localization has been designed and will be fabricated soon."
PHR 기반 개인 맞춤형 건강정보 탐사 알고리즘 설계,2017,"['개인건강기록', '온톨로지', '기계학습', '속성기반 연관규칙', 'PHR기반 건강정보서비스시스템', 'Personal Health Record', 'Ontology', 'Machine Learning', 'Axis based association rule', 'PHR based Health Information Service System']",,
나노입자 영상 분할 및 분류를 위한 요소 트리와 다층 퍼셉트론 기법,2017,"['나노입자', '분할', '분류', '요소 트리', '기계 학습', 'Nanoparticles', 'Segmentation', 'Classification', 'Component tree', 'Machine learning']",현미경의 발달로 미시적인 관찰과 실험이 가능해지고 고성능 현미경으로 촬영한 세포나 나노입자 영상을 빠르고 효율적으로 분석하는 일이 중요해지고 있다. 그 중 입자 영역을 분할해 입자의 수를 세고 같은 종류의 입자들끼리 분류하는 문제는 꾸준히 연구되어온 중요한 연구 주제이다. 본 논문에서는 요소 트리를 이용해 영상 내 입자 후보들을 검출하고 분류하는 알고리즘을 제시한다. 우선 영상의 요소 트리를 구축해 입자일 가능성이 높은 영역들을 검출하고 그들의 지형적 특징 데이터로 데이터 셋을 만들었다. 그리고 해당 데이터 셋으로 다층 퍼셉트론 분류기를 학습시켜 입자 후보들의 분류를 시도했다. 실험 결과 입자 군집까지 성공적으로 분류하는 것을 확인하였다.,"With the development of the microscope, microscopic observations and experiments became possible; thus, fast and effective analysis of the images of cells or nanoparticles taken with high-performance microscopes has become more important than ever. The problems of particle segmentation for counting and classification by the type of particles are essential research issues that have been researched steadily so far. In this paper, we identify particle candidates for images, and we use a classifier in an attempt to classify the candidates by type. First, we build a component tree of input images in quasi-linear time and extract areas with a higher possibility of particles with their morphological features for making data set. Then, we use the data set to train multi-layer perceptron classifiers and attempt to classify the particle candidates. Experimental results showed that the particle clusters were correctly classified with high accuracy."
ELM 기반의 지능형 알고리즘과 퍼지 소속함수를 이용한 유입변압기 고장진단 기법,2017,"['Fault diagnosis', 'Power transformer', 'Fuzzy membership', 'ELM(Extreem Learning Machine)']",,"Power transformers are an important factor for power transmission and cause fatal losses if faults occur. Various diagnostic methods have been applied to predict the failure and to identify the cause of the failure. Typical diagnostic methods include the IEC diagnostic method, the Duval diagnostic method, the Rogers diagnostic method, and the Doernenburg diagnostic method using the ratio of the main gas. However, each diagnostic method has a disadvantage in that it can’t diagnose the state of the power transformer unless the gas ratio is within the defined range. In order to solve these problems, we propose a diagnosis method using ELM based intelligent algorithm and fuzzy membership function. The final diagnosis is performed by multiplying the result of diagnosis in the four diagnostic methods (IEC, Duval, Rogers, and Doernenburg) by the fuzzy membership values. To show its effectiveness, the proposed fault diagnostic system has been intensively tested with the dissolved gases acquired from various power transformers."
Hierarchical Genetic Algorithm and Fuzzy Radial Basis Function Networks for Factors Influencing Hospital Length of Stay Outliers,2017,"['Data Mining', 'Intensive Care Units', 'Length of Stay', 'Machine Learning', 'Medical Informatics']",,"Objectives: Controlling hospital high length of stay outliers can provide significant benefits to hospital management resources and lead to cost reduction. The strongest predictive factors influencing high length of stay outliers should be identified to build a high-performance prediction model for hospital outliers. Methods: We highlight the application of the hierarchical genetic algorithm to provide the main predictive factors and to define the optimal structure of the prediction model fuzzy radial basis function neural network. To establish the prediction model, we used a data set of 26,897 admissions from five different intensive care units with discharges between 2001 and 2012. We selected and analyzed the high length of stay outliers using the trimming method geometric mean plus two standard deviations. A total of 28 predictive factors were extracted from the collected data set and investigated. Results: High length of stay outliers comprised 5.07% of the collected data set.The results indicate that the prediction model can provide effective forecasting. We found 10 common predictive factors within the studied intensive care units. The obtained main predictive factors include patient demographic characteristics, hospital characteristics, medical events, and comorbidities. Conclusions: The main initial predictive factors available at the time of admission are useful in evaluating high length of stay outliers. The proposed approach can provide a practical tool for healthcare providers, and its application can be extended to other hospital predictions, such as readmissions and cost."
단층 코어넷의 특성화 함수와 수학적 귀납법에 의한 증명,2017,"['Artificial Intelligence', 'Artificial Neural Network', 'Multi-Valued Logic', 'Machine Learning', 'Combinatorics', '인공지능', '인공신경망회로', '다치논리회로', '기계학습', '조합론']","본 논문에서는 인공신경망회로의 최소 요소가 되는 하나의 입력노드와 하나의 출력노드, 그리고 입출력에 다단(multi-level)값을 갖는 단층(입출력 2 layer) 다단 코어넷(CoreNet)의 무게값 공간 특성화 함수를 구하였고, 이를 수학적 귀납법으로 증명하였다.제안된 p단 입력과 q단 출력을 갖는 코어넷의 특성화 함수는 XAp,q(t)=t2-p(q-1)t+1/2(p-1)(q-1)(pq-2p+2)이다. Zaslavsky의 정리에 의하여 공간 배치도 Ap,q에 의한 분할 영역의 수 r(Ap,q)는 p(q-1)+1/2(p-1)(q-1)(pq-2p+2)+1이다.분할 영역의 수를 최대화하기 위하여 입출력 단(level)의 다단계 값 표현을 위한 분할 방법으로 ± cot(√x)함수와 [2(k-1)+1]/2q를 이용한 NMLGR 방법을 이용하였다. p와 q값에 따라 y(ω) 축 이외에도 추가로 3중첩이상의 교차점이 있을 수 있다. 여기서는 ω축 이외에는 3중첩 이상의 교차점이 없는 것으로 가정한다.","This paper presents a CoreNet which has a multi-leveled input value and a multi-leveled output value with a 2-layered ANNet, which is the basic structure of an Artificial Neural Network.I have suggested an equation for the characteristic function of the weight value space of the CoreNet, which has a p-leveled input and a q-leveled output. I have proved it through the mathematical induction method.The equation is XAp,q(t)=t2-p(q-1)t+1/2(p-1)(q-1)(pq-2p+2). The number of regions of arrangement A, r(A) is p(q-1)+1/2(p-1)(q-1)(pq-2p+2)+1 by Zaslavsky's theorem.I used the function of ± cot(√x) and [2(k-1)+1]/2q as in NMLGR for the leveling method of the input and output values to maximize the number of regions . Intersecting points, each made up of more than two lines, may exist, aside from on the y(ω) axis, according to p and q values. Here, we assume these points do not exist."
최근 건축분야의 인공지능 기계학습 연구동향,2017,"['건축분야', '인공지능', '기계학습', '인공신경망', '연구동향', 'Architectural Field', 'Artificial Intelligence', 'Machine Learning', 'Artificial Neural Network', 'Research Trends']",,"This paper carried out research trends of Artificial Intelligence (AI) of architectural field by comparing and analyzing the domestic & international journal papers in order to propose possibilities of application of Artificial Intelligence to architectural field in Korea. Firstly, theory of AI was analyzed comprehensively and papers were selected based on keyword of the papers, such as ""AI"", ""ANN"", “GA”, “SVM”, ""Building"", ""Architecture"" published in the domestic and international journals from 2000 to 2016. After selecting domestic and international journal papers adequately, in-depth analysis was conducted by architectural field, subject, method, and year. According to the analysis results, research trends of total chronology was growing steady and steep growth, especially in architectural environment and facility field. Furthermore, over half of the total papers applied ANN models for research. Lastly, in order to have competitive power of the domestic industry in the future, it determined that the Artificial Intelligence research in the field of architecture should be carried forward more actively."
얼굴 표정 인식을 위한 방향성 LBP 특징과 분별 영역 학습,2017,"['Directional Local Binary Pattern', 'Facial Expression Recognition', 'AdaBoost Learning', 'Support Vector Machine']",,
A Proposal for Classification of Document Data with Unobserved Categories Considering Latent Topics,2017,"['Document Classification', 'Latent Topic Model', 'Polya Distribution', 'Unobserved Category']",,"With rapid development on information society, automatic document classification by machine learning has become even more important. In document classification, it is assumed that a new input data can be classified into any of the categories observed in the training data. Therefore, if a new input data belongs to an unobserved category which does not exist in the training data, then such data cannot be classified exactly. To solve the above problem, Arakawa et al. proposed the method which models the generative probabilities of documents with a mixture of Polya distributions and estimates the optimum category within all observed and unobserved categories where it is assumed that documents in each category are generated from each single Polya distribution. However, the statistical characteristics of document categories are generally more complicated and there are various underlying latent topics in a category. Because a single Polya distribution models each category in the conventional approach, this method cannot represent the variation of word frequency depending on plural unobserved latent topics. This paper proposes a new model which assumes a mixture of Polya distributions for the generative probabilities of documents in a category to represent plural latent topics. To verify the effectiveness of the proposed method, we conduct the simulation experiments of document classification by using a set of English newspaper articles."
단어 쓰임새 정보와 신경망을 활용한 한국어 Hedge 인식,2017,"['워드임베딩', 'Hedge 인식', 'SVM', 'CRF', '기계학습', 'Word Embedding', 'Hedge Detection', 'SVM', 'CRF', 'Machine Learning']","본 논문에서는 한국어 문장을 대상으로 불확실한 사실이나 개인적인 추측으로 인해 중요하지 않다고 판단되는 문장, 즉 Hedge 문장들을 분류해 내고자 한다. 기존 영어권 연구에서는 Hedge 문장들을 분류할 때 단어의 의존관계 정보가 여러 형태로 활용되고 있으나, 한국어 연구에서는 사용되고 있지 않음을 확인하였다. 또 기존의 워드 임베딩(Word Embedding) 기법에서 단어의 쓰임새 정보가 학습된다는 점을 인지하였다. 단어의 쓰임새 정보가 어느 정도 의존관계를 표현할 수 있을 것으로 보고 워드 임베딩 정보를 Hedge 분류 실험에 적용하였다. 기존에 많이 사용되던 SVM과 CRF를 baseline 시스템으로 활용하였고 워드 임베딩과 신경망을 사용하여 비교실험을 하였다. 워드임베딩 데이터는 세종데이터와 온라인에서 수집된 데이터를 합하여 총 150여만 문장을 사용하였고 Hedge 분류 데이터는 수작업으로 구축한 12,517 문장의 뉴스데이터를 사용하였다. 워드 임베딩을 사용한 시스템이 SVM보다 7.2%p, CRF보다 1.6%p 좋은 성능을 내는 것을 확인하였다. 이는 단어의 쓰임새 정보가 한국어 Hedge 분류에서 긍정적인 영향을 미친다는 것을 의미한다.","In this paper, we try to classify Korean hedge sentences, which are regarded as not important since they express uncertainties or personal assumptions. Through previous researches to English language, we found dependency information of words has been one of important features in hedge classification, but not used in Korean researches. Additionally, we found that word embedding vectors include the word usage information. We assume that the word usage information could somehow represent the dependency information. Therefore, we utilized word embedding and neural networks in hedge sentence classification. We used more than one and half million sentences as word embedding dataset and also manually constructed 12,517-sentence hedge classification dataset obtained from online news. We used SVM and CRF as our baseline systems and the proposed system outperformed SVM by 7.2%p and also CRF by 1.2%p. This indicates that word usage information has positive impacts on Korean hedge classification."
Vessel Target Prediction Method and Dead Reckoning Position Based on SVR Seaway Model,2017,"['Vessel Traffic Services', 'Dead reckoning position', 'Seaway model', 'Support vectorregression', 'Machine learning']",,"A person who has responsible for ship’s safety, such as captain and Vessel Traffic Service Operator (VTSO), should make a decision to prevent the ship from colliding or other accident related on traffic situation. At this time, the positions of the own ship and the opponent ship are used for identification and prediction of the future situation, and the action is selected based on this information. Here, the person in charge predicts the position of itself and the opposing ship, and the calculated positions are called Dead Reckoning Position (DRP). In the existing DRP calculation, the position of the ship is predicted based on the current position, speed and course, so it cannot be applied in all navigation situations. For this reason, both the vessel and the VTS center utilize the navigation intentions of the two vessels related to the traffic situation for their own decision-making. In this study, we intend to predict the ship’s position based on the route extraction method proposed in the SVR seaway model. We predict the future speed, and propose a method of predicting the position applied to the SVR seaway model. For the verification of the proposed DRP calculation, a virtual path and ship’s trajectories which are similar to the actual navigation environment were constructed. As a result, comparison data between the existing DRP and proposed DRP are presented. And enhanced closest point of approach calculation results are presented for two approaching ships as a time series. We expect that the advanced DRP could be used for relevant tasks to ship’s mater and/or VTSO."
Opcode와 Windows API를 사용한 멀웨어 탐지,2017,"['Malware', 'PE File Format', 'Opcode', 'Windows API Calls', 'Machine Learning', 'Bernoulli Naïve Bayes', 'K-Nearest Neighbor.']","본 논문에서는 멀웨어 탐지 방법으로 Opcode (operation code)와 실행 파일에서 추출한 Windows API Call 로 구성된 특징 벡터를 사용하는 방법을 제안한다. 먼저 PE 파일에서 추출한 opcode와 windows API로 특징 벡터를구성하고 Bernoulli Naïve Bayes과 K-Nearest Neighbor 분류기 알고리즘을 사용하여 성능을 각각 측정하였다. 실험결과, 제안한 방법과 KNN 분류기를 사용하여 분류하면 95.21%의 멀웨어 탐지 정확도를 얻을 수 있었다. 결과적으로기존의 Opcode 또는 Windows API 호출 중 하나만 사용하는 방법보다 제안한 방법이 멀웨어 탐지 정확도에서 높은성능을 보인다.","We proposed malware detection method, which use the feature vector that consist of Opcode(operation code) and Windows API Calls extracted from executable files. And, we implemented our feature vector and measured the performance of it by using Bernoulli Naïve Bayes and K-Nearest Neighbor classifier. In experimental result, when using the K-NN classifier with the proposed method, we obtain 95.21% malware detection accuracy. It was better than existing methods using only either Opcode or Windows API Calls."
쿨레쇼프의 영화연기론,2017,"['쿨레쇼프', '노동의 과정', '공간 메트릭 웹', '동작축', '기계적 과정', 'Lev Kuleshov', 'labour process', 'metrical web', 'axes of movement', 'mechanical process']","쿨레쇼프의 연기론은 신체 중심의 이론이다. 배우는 선형적 모형에 한정된 짧은 실습을 통해 쿨레쇼프의 연기훈련법을 습득할 수 있다. 실습과정은 배우들의 신체를 평면적인 구성에 적응하는 방법을 제시하며, 복잡한 무대 패턴에 직면했을 때 신체를 통제할 수 있고, 움직임과 텍스트를 안정되게 병치시킬 수 있는 역량을 제공한다. 나아가, 쿨레쇼프의 동작축과 메트릭 웹과 같은 개념은 컴퓨터의 2D와 3D에서 캐릭터 구축의 원리로 이해할 수 있으며, 영상애니메이션의 캐릭터 연기 구성에 유용한 원천을 제공할 수 있다. 이 글은 쿨레쇼프의 「영화예술(Art of the Cinema)」(1929)을 주된 텍스트로 삼아 그의 연기론의 핵심 개념을 고찰하는 것에 한정하였다. 쿨레쇼프가 주창한 배우의 기계적 과정, 배우 마네킹, 마스크 얼굴, 기계 얼굴과 같은 더욱 심도 있는 비판적 논의는차후의 과제로 남겨두고자 한다.","Kuleshov's acting theory is a body-centered one. The actor can learn Kuleshov's acting training method through the étude limited to a linear model. The étude offers a way to adapt the actor's body to a planar configuration, to control the body in the face of complex stage patterns, and to provide a stable juxtaposition of movement and text. Furthermore, the concepts such as the motion axes and the metric web of Kuleshov can be understood as the principle of character building in 2D and 3D of computer, and can provide a useful source constituting the character of animation. This article has limited Kuleshov's view of some key concepts of his acting theory as the main text of Art of the Cinema. I will leave more intensive critical discussions such as the mechanical process of the actor Kuleshov advocated, the actor mannequin, the mask face, and the machine face as a future task."
소셜 텍스트의 주요 정보 추출을 위한 로지스틱 회귀 앙상블 기법,2017,"['기계학습', '정보 추출', '앙상블', '로지스틱 회귀', '소셜 네트워크 서비스', 'Machine Learning', 'Information Extraction', 'Ensemble', 'Logistic Regression', 'Social Media']",,"Currenty, in the era of big data, text mining and opinion mining have been used in many domains, and one of their most important research issues is to extract significant information from social media. Thus in this paper, we propose a logistic regression ensemble method of finding the main body text from blog HTML. First, we extract structural features and text features from blog HTML tags. Then we construct a classification model with logistic regression and ensemble that can decide whether any given tags involve main body text or not. One of our important findings is that the main body text can be found through `depth` features extracted from HTML tags. In our experiment using diverse topics of blog data collected from the web, our tag classification model achieved 99% in terms of accuracy, and it recalled 80.5% of documents that have tags involving the main body text."
손 제스처 인식에 기반한 Virtual Block 게임 인터페이스,2017,"['Hand Gesture Recognition', 'Interaction', 'Leap Motion', 'Support Vector Machine']",최근 가상현실 기술의 발전으로 가상의 3D 객체와 자연스러운 상호작용이 가능하도록 하는사용자 친화적인 손 제스처 인터페이스에 대한 연구가 활발히 진행되고 있다. 그러나 대부분의연구는 단순하고 적은 종류의 손 제스처만 지원되고 있는 실정이다. 본 논문은 가상환경에서3D 객체와 보다 직관적인 방식의 손 제스처 인터페이스 방법을 제안한다. 손 제스처 인식을 위하여 먼저 전처리 과정을 거친 다양한 손 데이터를 이진 결정트리로 1차 분류를 한다. 분류된 데이터는 리샘플링을 한 다음 체인코드를 생성하고 이에 대한 히스토그램으로 특징 데이터를 구성한다.이를 기반으로 학습된 MCSVM을 통해 2차 분류를 수행하여 제스처를 인식한다. 본 방법의 검증을위하여 3D 블록을 손 제스처를 통하여 조작하는 ‘Virtual Block’이라는 게임을 구현하여 실험한 결과 16개의 제스처에 대해 99.2%의 인식률을 보였으며 기존의 인터페이스보다 직관적이고 사용자 친화적임을 알 수 있었다.,"With the development of virtual reality technology, in recent years, user-friendly hand gesture interface has been more studied for natural interaction with a virtual 3D object.Most earlier studies on the hand-gesture interface are using relatively simple hand gestures. In this paper, we suggest an intuitive hand gesture interface for interaction with 3D object in the virtual reality applications. For hand gesture recognition, first of all, we preprocess various hand data and classify the data through the binary decision tree. The classified data is re-sampled and converted to the chain-code, and then constructed to the hand feature data with the histograms of the chain code. Finally, the input gesture is recognized by MCSVM-based machine learning from the feature data.To test our proposed hand gesture interface we implemented a ‘Virtual Block’ game. Our experiments showed about 99.2% recognition ratio of 16 kinds of command gestures and more intuitive and user friendly than conventional mouse interface."
공공부문 데이터의 경제적 가치평가 연구: 소상공인 신용보증 데이터 사례,2017,"['Data Valuation', 'Public Sector Data', 'Business Credit Guarantee']",,"As the important breakthrough continues in the field of machine learning and artificial intelligence recently, there has been a growing interest in the analysis and the utilization of the big data which constitutes a foundation for the field. In this background, while the economic value of the data held by the corporates and public institutions is well recognized, the research on the evaluation of its economic value is still insufficient. Therefore, in this study, as a part of the economic value evaluation of the data, we have conducted the economic value measurement of the data generated through the small business guarantee program of Korean Federation of Credit Guarantee Foundations (KOREG). To this end, by examining the previous research related to the economic value measurement of the data and intangible assets at home and abroad, we established the evaluation methods and conducted the empirical analysis. For the data value measurements in this paper, we used `cost-based approach`, `revenue-based approach`, and `market-based approach`. In order to secure the reliability of the measured result of economic values generated through each approach, we conducted expert verification with the employees. Also, we derived the major considerations and issues in regards to the economic value measurement of the data. These will be able to contribute to the empirical methods for economic value measurement of the data in the future."
A Selective Review on Random Survival Forests for High Dimensional Data,2017,"['Censoring', 'Random survival forest', 'Survival ensemble', 'Survival tree', 'Time-to-event data']",,"Over the past decades, there has been considerable interest in applying statistical machine learning methods in survival analysis. Ensemble based approaches, especially random survival forests, have been developed in a variety of contexts due to their high precision and non-parametric nature. This article aims to provide a timely review on recent developments and applications of random survival forests for time-to-event data with high dimensional covariates. This selective review begins with an introduction to the random survival forest framework, followed by a survey of recent developments on splitting criteria, variable selection, and other advanced topics of random survival forests for time-to-event data in high dimensional settings. We also discuss potential research directions for future research."
SDN 환경에서 효율적 Flow 전송을 위한 전송 지연 평가 기반 부하 분산 기법 연구,2017,"['소프트웨어 정의 네트워크', '기계학습', '트래픽 분류', '전송 지연', 'SDN', 'classification', 'transmission delay', 'machine learning']","Software-Defined Network의 등장은 하드웨어적인 네트워크 기능들을 소프트웨어적인 형태 의 모듈로 Controller에 보다 유연하게 적용시키도록 함으로써 전통적인 네트워크의 구조를 변화시키고 있다. 이러한 환경 속에서 최근 네트워크 트래픽에 대한 Quality of Service 및 자원관리와 같은 다양한 관점에서의 네트워크 관리정책에 대한 연구개발이 진행되고 있고, 이러한 관리정책을 뒷받침 할 수 있는 네트워크 모니터링에 대한 기법들 또한 제시되어 왔다. 이에 본 논문에서는 기계 학습 기법인 Naive Bayesian Classification을 통하여 Flow를 분류한 후, 전송 지연 측정 모듈을 통하여 효율적인 전송경로를 선정하는 기법을 제안한다. 이는 다양한 대역폭을 갖는 여러 경로들로 이루어진 네트워크상에서 효율적인 경로 분배 역할을 할 수 있고, 부하를 분산시킴으로써 보다 원활한 네트워크 환경 및 서비스 품질을 제공할 수 있다.","In a centralized control structure, the software defined network controller manages all openflow enabled switched in a data plane and controls the telecommunication between all hosts. In addition, the network manager can easily deploy the network function to the application layer with a software defined network controller. For this reason, many methods for network management using a software defined network concept have been proposed. The main policies for network management are related to traffic Quality of Service and resource management. In order to provide Quality of Service and load distribution for network users, we propose an efficient routing method using a naïve bayesian algorithm and transmission delay estimation module. In this method, the forwarding path is decided by flow class and estimated transmission delay result in the software defined network controller. With this method, the load on the network node can be distributed to improve overall network performance. The network user also gets better dynamic Quality of Service."
News Topic Extraction based on Word Similarity,2017,"['텍스트 마이닝', '토픽 추출', 'LDA', '기계 학습', 'text mining', 'topic extraction', 'machine learning']",,
효율적인 문헌 분류를 위한 시계열 기반 데이터 집합 선정 기법,2017,"['SVM', '나이브베이즈', '시계열분석', '기계학습', '분류', 'Naive Bayes', 'time-Series Analysis', 'Machine Learning', 'Classification']","인터넷 기술이 발전함에 따라 온라인상의 데이터는 급격하게 증가하고 있고, 증가하는 데이터에 대해 점진적인 기계학습 기법을 통해 효율적으로 학습하기 위한 연구가 진행되고 있다. 온라인상의 문서는 대부분 게시일, 출판일과 같은 시계열적 정보를 포함하고 있고, 이를 분류에 반영한다면 효율적인 분류가 가능할 것이다. 본 연구에서는 웹 문서상에서 나타나는 어휘의 시계열적 변화를 분석하였고, 분석한 시계열 정보를 기반으로 데이터 집합을 분할하여 효율적인 분류 학습 기법을 제안한다.  실험 및 검증을 위해 온라인상의 뉴스 기사 100만 건을 시계열 정보를 포함하여 수집하였다. 수집된 데이터를 바탕으로 데이터 집합을 분할하여 Naïve Bayes 및 SVM 분류기를 사용하여 실험을 진행하였고, 각 모델에서 전체 데이터 집합 학습 대비 최대 2.02% 포인트, 2.32% 포인트의 성능 향상을 확인하였다. 본 연구를 통해 시계열적 어휘의 변화를 분류에 반영하여 분류의 성능을 향상시킬 수 있음을 확인하였다.","As the Internet technology advances, data on the web is increasing sharply. Many research study about incremental learning for classifying effectively in data increasing. Web document contains the time-series data such as published date. If we reflect time-series data to classification, it will be an effective classification. In this study, we analyze the time-series variation of the words. We propose an efficient classification through dividing the dataset based on the analysis of time-series information. For experiment, we corrected 1 million online news articles including time-series information. We divide the dataset and classify the dataset using SVM and Naïve Bayes. In each model, we show that classification performance is increasing Through this study, we showed that reflecting, time-series information can improve the classification performance."
흉부 CT 영상에서 다중 뷰 영상과 텍스처 분석을 통한 고형 성분이 작은 폐 간유리음영 결절 분류,2017,"['Pulmonary Nodule Classification', 'Ground-glass Opacity Nodule', 'Texture Analysis', 'Machine Learning', 'Support Vector Machine']",,
안드로이드에서 앱 사용과 터치 정보를 이용한 행위 기반 사용자 인증 기술 연구,2017,"['Android', 'Behavior Based Authentication', 'Application Usage', 'Touch Dynamic', 'Machine Learning']","스마트폰 기기 내에 저장되는 사용자 정보가 다양화되어 개인정보에 대한 위협도 함께 증가하고 있다. 패턴 잠금, 지문 인식 등 다양한 사용자 인증 기술이 스마트폰에 적용되어 있으나 사용자 의존적, 거부감 유발 등의 한계점을 보이고 있다. 최근 주목받고 있는 행위 기반 인증은 기기 사용과 동시에 인증이 가능하여 사용자에게 높은 편의성을 제공하나 타 인증 기술에 비해 정확도가 낮아 이를 개선하기 위한 연구가 꾸준히 수행되고 있다. 본 연구에서는 이전 연구에서 고려되지 않았던 앱 사용 정보를 새로운 인증 요소로 활용하는 방법을 제안한다. 또한 실제 앱 사용 상황을 고려한 데이터 수집 및 분석을 통해 제안 기술의 성능을 상세하게 분석한다.","The increase in user data stored in the device implies the increase in threats of users’ sensitive data. Currently, smartphone authentication mechanisms such as Pattern Lock, fingerprint recognition are widely used. Although, there exist disadvantages of inconvenience use and dependence that users need to depend on their own memory. User behavior based authentication mechanism have advantages of high convenience by offering continuous authentication when using the mobile device. However, these mechanisms show limitations on low accuracy of authentication and there are researches to improve the accuracy. This paper proposes improved authentication mechanism that uses user’s smartphone application usage pattern which has not considered on earlier studies. Also, we analyze performance of proposed mechanism with collected datasets from actual use of smartphone applications."
Acoustic Event Detection in Multichannel Audio Using Gated Recurrent Neural Networks with High-Resolution Spectral Features,2017,"['Acoustic event detection', 'Deep recurrent neural networks', 'Gated recurrent neural network', 'Multichannel audio']",,"Recently, deep recurrent neural networks have achieved great success in various machine learning tasks, and have also been applied for sound event detection. The detection of temporally overlapping sound events in realistic environments is much more challenging than in monophonic detection problems. In this paper, we present an approach to improve the accuracy of polyphonic sound event detection in multichannel audio based on gated recurrent neural networks in combination with auditory spectral features. In the proposed method, human hearing perception-based spatial and spectral-domain noise-reduced harmonic features are extracted from multichannel audio and used as high-resolution spectral inputs to train gated recurrent neural networks. This provides a fast and stable convergence rate compared to long short-term memory recurrent neural networks. Our evaluation reveals that the proposed method outperforms the conventional approaches."
Imbalanced SVM-Based Anomaly Detection Algorithm for Imbalanced Training Datasets,2017,"['Anomaly detection', 'Decision function', 'GMean', 'Imbalanced training sample set', 'Support vector machine (SVM).']",,"Abnormal samples are usually difficult to obtain in production systems, resulting in imbalanced training sample sets. Namely, the number of positive samples is far less than the number of negative samples.Traditional Support Vector Machine (SVM)-based anomaly detection algorithms perform poorly for highly imbalanced datasets: the learned classification hyperplane skews toward the positive samples, resulting in a high false-negative rate. This article proposes a new imbalanced SVM (termed ImSVM)- based anomaly detection algorithm, which assigns a different weight for each positive support vector in the decision function. ImSVM adjusts the learned classification hyperplane to make the decision function achieve a maximum GMean measure value on the dataset. The above problem is converted into an unconstrained optimization problem to search the optimal weight vector. Experiments are carried out on both Cloud datasets and Knowledge Discovery and Data Mining datasets to evaluate ImSVM. Highly imbalanced training sample sets are constructed. The experimental results show that ImSVM outperforms over-sampling techniques and several existing imbalanced SVM-based techniques."
A Proposal for Classification of Document Data with Unobserved Categories Considering Latent Topics,2017,"['Document Classification', 'Latent Topic Model', 'Polya Distribution', 'Unobserved Category']",,"With rapid development on information society, automatic document classification by machine learning has become even more important. In document classification, it is assumed that a new input data can be classified into any of the categories observed in the training data. Therefore, if a new input data belongs to an unobserved category which does not exist in the training data, then such data cannot be classified exactly. To solve the above problem, Arakawa et al. proposed the method which models the generative probabilities of documents with a mixture of Polya distributions and estimates the optimum category within all observed and unobserved categories where it is assumed that documents in each category are generated from each single Polya distribution. However, the statistical characteristics of document categories are generally more complicated and there are various underlying latent topics in a category. Because a single Polya distribution models each category in the conventional approach, this method cannot represent the variation of word frequency depending on plural unobserved latent topics. This paper proposes a new model which assumes a mixture of Polya distributions for the generative probabilities of documents in a category to represent plural latent topics. To verify the effectiveness of the proposed method, we conduct the simulation experiments of document classification by using a set of English newspaper articles."
텍스트마이닝을 활용한 산업분석 방법론에 관한 연구: 문장 분류를 이용한 PEST와 긍부정 분석,2017,"['Industrial analysis', 'PEST', 'SWOT', 'Polarity analysis', 'Text mining', 'Machine learning']","오늘날의 기업들은 날로 치열해 지는 산업 내 경쟁 속에서의 생존을 위해 끊임없이 자기가 속한 산업의 변화와 동향을 파악하고 이를 자사의 정책이나 제품개발에 주기적으로 반영하면서 생존해야 하는 환경하에 있다. 이를 위해 주기적으로 수행해야 할 업무 중 하나가 산업정보의 분석이다. 대다수의 기업들은 많은 시간, 인력을 투입하거나 혹은 적지 않은 비용을 들여 외부 전문 분석기관의 도움을 받는 형태로 산업분석 정보를 획득하고 있다. 하지만 이러한 기존의 방식이 다소 휴리스틱하고 정성적인 접근법임으로 인해 분석결과의 품질이 매번 다르다는 점, 엄청난 양의 산업관련정보가 실시간으로 온라인에서 생산되고 있고 이들 정보를 최대한 분석에 반영할 경우 보다 높은 품질의 분석결과를 기대할 수 있음을 감안할 때 기존과는 다른 새로운 방식의 분석 기법 도입이 요구된다. 이에 본 연구에서는 대용량의 원천 데이터로부터 산업분석에 포함될 수 있는 정보를 추출하고 이를 산업분석 프레임워크의 각 카테고리별로 자동 분류해주는 텍스트마이닝 방법론을 제안한다. 기계학습 기반의 문장 분류기를 구축하여 보편적으로 활용되는 산업분석 프레임워크의 지표별로 분류될 수 있는 정보를 문장 형태로 수집하게 하였다. 제안한 시스템을 이용하여 PEST와 긍부정 분석을 수행하였으며, 실험을 통해 제안된 시스템의 분류 정확도를 평가하였다.",
제조업의 심층신경망 기계학습(딥러닝),2017,"['심층신경망 기계학습', '제조업', '하드웨어/소프트웨어 개발환경', 'deep neural net machine learning(deep Learning)', 'manufacturing', 'environments', 'development']",,
순환인공신경망(RNN)을 이용한 대도시 도심부 교통혼잡 예측,2017,"['순환 인공 신경망', '기계학습', '실시간 소통상황 예측', '반복정체', 'Recurrent Neural Network', 'machine learning', 'realtime traffic congestion estimation', 'recurrent congestion']",,
원문정보공개 지원을 위한 민감정보 필터링 요건에 관한 연구,2017,"['정보공개', '원문정보공개', '필터링', '개인정보', '민감정보', '기계학습', 'information disclosure', 'original information disclosure', 'filtering', 'personal information', 'sensitive information', 'machine learning']","원문정보공개 서비스를 개시한 후 한해 천만 건에 가까운 전자 결재문서가 온라인을 통해 공개되고 있다. 하지만 대량의 전자결재문서를 정보공개 업무담당자가 모두 확인하여 원문정보공개 서비스를 수행하는 것은 현실적으로 불가능한 상황이다. 이에 따라 최근 일부 공공기관에서는 개인정보 필터링 도구를 활용하여 문서 생산단계에서 정형화된 개인정보를 필터링하고 있으나 비정형화된 민감정보는 관리되지 않고 있다. 본 연구에서는 원문정보공개 지원을 위해 사용 중인 필터링 도구 분석을 통해 필터링 도구의 고도화 방향을 설정하였으며, 필터링 도구 활용단계가 추가된 결재문서 본문 작성과 원문정보공개 프로세스를 재설계하였다.","Approximately 10 million electronic approval documents have been released online since the commencement of the original information disclosure service. However, it is practically impossible to carry out an original information disclosure service by confirming a large amount of electronic approval documents to all persons in charge of information disclosure. Recently, some public organizations have been using private information filtering tools to filter personal information at the stage of document production, but the management of different sensitive information has not been managed using solutions. In this study, we set up the advanced direction of the filtering tool by analyzing the filtering tool in use to support the original information disclosure, and redesigned the text of the approval document and the original information disclosure process with the use of the filtering tool."
Question Answering Optimization via Temporal Representation and Data Augmentation of Dynamic Memory Networks,2017,"['메모리 네트워크', '질의응답', '인공지능', '기계학습', '시간 인식', '데이터 확장', 'memory network', 'question answering', 'artificial intelligence', 'machine learning', 'time perception', 'data augmentation']",,
Automatic progressive damage detection of rotor bar in induction motor using vibration analysis and multiple classifiers,2017,"['Classification', 'DWT', 'Induction motor', 'Rotor bars', 'Vibration analysis']",,"There is an increased interest in developing reliable condition monitoring and fault diagnosis systems of machines like induction motors; such interest is not only in the final phase of the failure but also at early stages. In this paper, several levels of damage of rotor bars under different load conditions are identified by means of vibration signals. The importance of this work relies on a simple but effective automatic detection algorithm of the damage before a break occurs. The feature extraction is based on discrete wavelet analysis and autocorrelation process. Then, the automatic classification of the fault degree is carried out by a binary classification tree. In each node, comparing the learned levels of the breaking off correctly identifies the fault degree. The best results of classification are obtained employing computational intelligence techniques like support vector machines, multilayer perceptron, and the k-NN algorithm, with a proper selection of their optimal parameters."
‘Hot Search Keyword’ Rank-Change Prediction,2017,"['인기 검색어', '시계열 예측', '검색어 예측', '기계학습', 'hot search keyword', 'temporal prediction', 'search keyword prediction', 'machine learning']",,
점진적 기계학습 기반의 레이더 위협체 역추정 모델 생성 및 갱신,2017,"['통합전자전', '레이더 위협', '점진적 기계학습', '역추정 모델 통합', '뎀스터-쉐이퍼 알고리즘', 'Integrated Electronic Warfare', 'Radar Threats', 'Incremental Machine Learning', 'Integration of Reverse Extrapolation Model', 'Dempster-Shafer algorithm']","다양한 전자전 상황에서 단위 위협체에 대하여 전자전 모델링과 시뮬레이션을 수행할 수 있는 통합 전자전 시뮬레이터의 개발 필요성이 대두되고 있다. 본 논문에서는 전자전 상황에서 전자정보 수집신호의 변수를 기반으로 전자파신호를 발산하는 레이더 위협을 역추정하기 위한 시뮬레이션 시스템의 구성요소를 분석하고, 역추정 모델을 점진적으로 유지할 수 있는 방법을 제안한다. 또한, 실험을 통하여 점진적 역추정 모델 갱신 기법의 유효성 및 개별 역추정결과의 통합 기법을 평가한다. 개별 역추정 모델의 생성을 위하여 의사결정트리, 베이지안 분류기, 인공신경망 및유클리디안 거리 측정방식과 코사인 유사도 측정방식을 활용하는 군집화 알고리즘을 이용하였다. 첫 번째 실험에서레이더 위협체에 대한 역추정 모델을 구축하기 위한 위협 예제의 크기를 점진적으로 증가시키면 역추정 모델의 정확도는 향상되었으며, 이러한 과정이 반복되면 역추정 모델에 대한 정확도는 일정한 값으로 수렴하였다. 두 번째 실험에서는 개별 역추정 모델의 결과를 통합하기 위하여 투표, 가중투표 및 뎀스터-쉐이퍼 알고리즘을 이용하였으며, 역추정 모델의 통합 결과는 뎀스터-쉐이퍼 알고리즘에 의한 역추정 정확도가 가장 좋은 성능을 보였다.","Various electronic warfare situations drive the need to develop an integrated electronic warfare simulator that can perform electronic warfare modeling and simulation on radar threats. In this paper, we analyze the components of a simulation system to reversely model the radar threats that emit electromagnetic signals based on the parameters of the electronic information, and propose a method to gradually maintain the reverse extrapolation model of RF threats. In the experiment, we will evaluate the effectiveness of the incremental model update and also assess the integration method of reverse extrapolation models. The individual model of RF threats are constructed by using decision tree, naive Bayesian classifier, artificial neural network, and clustering algorithms through Euclidean distance and cosine similarity measurement, respectively. Experimental results show that the accuracy of reverse extrapolation models improves, while the size of the threat sample increases. In addition, we use voting, weighted voting, and the Dempster-Shafer algorithm to integrate the results of the five different models of RF threats. As a result, the final decision of reverse extrapolation through the Dempster-Shafer algorithm shows the best performance in its accuracy."
시스템 요구사항 분석을 위한 순환적-점진적 복합 분석방법,2017,"['요구사항 분석', '대규모 시스템', '빅데이터', 'Requirement Analysis', 'Large-Scale System', 'Big Data']",,"Development of Intelligent Systems involves effective integration of large-scaled knowledge processing and understanding, human-machine interaction, and intelligent services. Especially, in our project for development of a self-growing knowledge-based system with inference methodologies utilizing the big data technology, we are building a platform called WiseKB as the central knowledge base for storing massive amount of knowledge and enabling question-answering by inferences. WiseKB thus requires an effective methodology to analyze diverse requirements convoluted with the integration of various components of knowledge representation, resource management, knowledge storing, complex hybrid inference, and knowledge learning, In this paper, we propose an integrated requirement analysis method that blends the traditional sequential method and the iterative-incremental method to achieve an efficient requirement analysis for largescale systems."
인공지능 창작물의 저작권 보호,2017,"['인공지능(AI)', '저작권 보호', '부정경쟁', '딥러닝', '지능형 로봇\r\nartificial intelligence(AI)', 'copyright protection', 'deep learning', 'unfair competition', 'intelligent robot']","디지털 연결성과 고도화된 ICT 기술을 기반으로 한 제4차 산업혁명은 새로운 저작물의 출현을 가능하게 하였다. 그중 인공지능(Artificial Intelligence, AI)은 딥러닝(deep learning) 기술을 기반으로 스스로 학습하고 인지추론을 할 수 있다는 점에서 기존의 기계들과 다르다. 인공지능 기술은 발전 단계에 따라 창작성, 가용성, 다양성 등에서 차이는 있으나 음악, 미술, 게임, 디자인, 소설, 신문기사 등 다양한 분야에서 인간이 아닌 주체로서 창작물을 만들어내고 있다. 인공지능 창작은 인간이 창작에 직접적으로 관연하지 않는다는 점에서 기존 지식재산권 보호의 사각지대에 놓여있어 새로운보호 체계에 대한 요구가 증가하고 있다. 인공지능 창작물에 대한 저작권 보호에 대한 논의는 일본과 EU를 중심으로 이루어지고 있으며, 특히 일본 지식재산전략본부가 2016년 4월 8일 인공지능 보고서를 발표하였다.이 논문은 일본의 인공지능 보고서를 중점적으로 분석하고, 이에 더해 인공지능 창작물의 저작권 보호 방안을 제시한다. 우선 인공지능 기술의 발전은 향후 다양한 창작물이 대량으로 출현할 것이 예견되는데, 만일 배타적 권리를 부여할 경우 독점화심화로 인한 부작용이 우려된다. 그러나 다른 한편으로 인공지능에 대한 투자를 유도하기 위한 저작권 보호의 요구가 증대되고 있어 찬반논의의 조화로운 접근이 필요하다. 이 논문은 현존하는 인공지능 산업에 대한 투자 회수를 보호하고자 할 경우에도 매우 낮은 수준의 보호가 타당하다고 주장한다. 예를 들면, 인공지능 창작물에 대해 ‘약한 저작권 보호(Thin copyright protection)’이론을 적용하여 침해의 구성요소로서 ‘실질적 유사성(substantial similarity)’이 아닌 ‘현저한 유사성(striking similarity)’을 요건으로 정하고, 구제에 있어서도 형사처벌은 배제할 것을 제안하고 있다. 또한 인공지능 창작물과 인간의 창작물을 구별하기 위하여 새로운 등록제도와 표시제도의 도입을 고민하여야 하며, 보호기간도 5년 정도의 단기로 설정할 것을 주장한다. 나아가 비록 침해에 해당한다고 하더라도 그 사용의 금지보다는 보상금 지급을 전제로 한 사용 허락의 방안도 고려해 볼 것을 제안한다.","The fourth industrial revolution, based on digital connectivity and sophisticated ICT technology, enabled the emergence of new works. Artificial Intelligence (AI) is different from conventional machines in that it is able to learn and do cognitive reasoning based on deep learning techniques. Although AI technology differs in terms of creativity, availability, and diversity according to the stage of development, AI is creating creativity as a non-human subject in various fields such as music, art, game, design, novel and newspaper article. AI creation lies in the blind spot of protection of existing intellectual property rights in that human beings are not directly involved in creation, and the demand for a new protection system is increasing. Discussions on the copyright protection of AI creations arecentered on Japan and the EU. In particular, the Japan Intellectual Property Strategy Headquarters issued the Artificial Intelligence Report on April 8, 2016.This paper focuses on the AI report of Japan and presents a new approach for copyright protection of AI creation. First of all, the development of AI technology is expected to produce a large number of various creative works in the future. If an exclusive right is given, it is worried about side effects due to intensification of monopolization. On the other hand, the need for copyright protection to induce investment in AI is increasing, and a harmonious approach to the pros and cons is needed. This paper argues that a very low level of protection is valid even when protecting the return on investment in existing AI industries. For example, applying ‘Thin copyright protection’ theory to AI creations, the ‘striking similarity’ rather than ‘substantial similarity’ as a component of infringement is defined as a requirement. It is suggested that criminal punishment should be excluded even in relief. In addition, to distinguish between AI creations and human’s, it is necessary to consider the introduction of new registration and labeling systems. This paper also argues that it is appropriate to set the protection period to a short term of about 5 years.Furthermore, even if it is an infringement, it is suggested to consider the possibility of using permission based on the payment of compensation rather than the prohibition of the use."
나이브 베이즈 빅데이터 분류기를 이용한 렌터카 교통사고 심각도 예측,2017,"['빅데이터', '렌터카', '교통사고', '심각도', '나이브 베이즈', '기계학습', 'Big data', 'rental car', 'traffic accident', 'severity', 'Naive Bayes', 'machine learning']",,
보안 인텔리전트 유형 분류를 위한 다중 프로파일링 앙상블 모델,2017,"['보안', '빅데이터', '인텔리전스', '침해사고', '프로파일', '앙상블 모델', '기계학습', 'Big Data', 'Threat Intelligence', 'Cyber Incident', 'Profile', 'Ensemble Model', 'Machine Learning']","최근 기업의 보안 시스템으로부터 수집되는 보안 인텔리전스 수는 악성코드의 확산으로 인해 기하급수적으로 증가하고 있다. 빅 데이터 환경이 도래하면서 기업들은 침해사고에 대한 다양한 정보를 이용할 수 있게 되면서 기업이 수집할 수 있는 침해사고 정보가 다양해지고 있다. 이에 따라 보안 인텔리전스를 구성하고 있는 침해사고의 다양한 속성을 사용하여 보다 정확하게 유사침해사고를 그룹별로 분류할 필요성이 요구되고 있다. 본 연구에서는 유사도 비교 분석 이론에 근거하여 침해사고를 공격유형과 침해자원을 고려한 다중 프로파일을 개발하고, 이를 활용하여 보안 인텔리전스를 구성하고 있는 침해사고 유형 분류의 정확성을 개선하는 다중 프로파일 기반 앙상블 모델을 제안한다. 제안 모델은 침입탐지시스템에서 수집된 계층적 침해자원에 대한 유사도 분석을 통해 새로운 침해사고를 효과적으로 분석할 수 있다. 사실적이고 의미 있는 침해사고의 구성을 통한 유형 분류는 새로운 침해사고에 대한 유사 침해사고를 정확하게 분류 제공함으로써 분석의 실용성을 향상시킨다.","Threat intelligences collected from cyber incident sharing system and security events collected from Security Information & Event Management system are analyzed and coped with expanding malicious code rapidly with the advent of big data. Analytical classification of the threat intelligence in cyber incidents requires various features of cyber observable. Therefore it is necessary to improve classification accuracy of the similarity by using multi-profile which is classified as the same features of cyber observables. We propose a multi-profile ensemble model performed similarity analysis on cyber incident of threat intelligence based on both attack types and cyber observables that can enhance the accuracy of the classification. We see a potential improvement of the cyber incident analysis system, which enhance the accuracy of the classification. Implementation of our suggested technique in a computer network offers the ability to classify and detect similar cyber incident of those not detected by other mechanisms."
Fall Detection System for the Elderly Based on the Classification of Shimmer Sensor Prototype Data,2017,"['Aged Humans', 'Computer Communication Network', 'Accidental Fall Detection', 'Information Systems', 'Shimmer', 'Wireless Technology', 'Machine Learning']",,"Objectives: Falling in the elderly is considered a major cause of death. In recent years, ambient and wireless sensor platforms have been extensively used in developed countries for the detection of falls in the elderly. However, we believe extra efforts are required to address this issue in developing countries, such as Pakistan, where most deaths due to falls are not even reported.Considering this, in this paper, we propose a fall detection system prototype that s based on the classification on real time shimmer sensor data. Methods: We first developed a data set, ‘SMotion’ of certain postures that could lead to falls in the elderly by using a body area network of Shimmer sensors and categorized the items in this data set into age and weight groups.We developed a feature selection and classification system using three classifiers, namely, support vector machine (SVM), Knearest neighbor (KNN), and neural network (NN). Finally, a prototype was fabricated to generate alerts to caregivers, health experts, or emergency services in case of fall. Results: To evaluate the proposed system, SVM, KNN, and NN were used. The results of this study identified KNN as the most accurate classifier with maximum accuracy of 96% for age groups and 93% for weight groups. Conclusions: In this paper, a classification-based fall detection system is proposed. For this purpose, the SMotion data set was developed and categorized into two groups (age and weight groups). The proposed fall detection system for the elderly is implemented through a body area sensor network using third-generation sensors. The evaluation results demonstrate the reasonable performance of the proposed fall detection prototype system in the tested scenarios."
Fault Location and Classification of Combined Transmission System,2017,"['SVM', 'Fault location', 'Combined transmission line', 'Wavelet transform', 'Feature extraction']",,"An effective statistical feature extraction approach of data sampling of fault in the combined transmission system is presented in this paper. The proposed algorithm leads to high accuracy at minimum cost to predict fault location and fault type classification. This algorithm requires impedance measurement data from one end of the transmission line. Modal decomposition is used to extract positive sequence impedance. Then, the fault signal is decomposed by using discrete wavelet transform. Statistical sampling is used to extract appropriate fault features as benchmark of decomposed signal to train classifier. Support Vector Machine (SVM) is used to illustrate the performance of statistical sampling performance. The overall time of sampling is not exceeding 1¼ cycles, taking into account the interval time. The proposed method takes two steps of sampling. The first step takes ¾ cycle of during-fault and the second step takes ¼ cycle of post fault impedance. The interval time between the two steps is assumed to be ¼ cycle. Extensive studies using MATLAB software show accurate fault location estimation and fault type classification of the proposed method. The classifier result is presented and compared with well-established travelling wave methods and the performance of the algorithms are analyzed and discussed."
뉴럴 디코딩의 원리와 최신 연구 동향 소개,2017,"['neural decoding', 'spike trains', 'rate decoding', 'temporal decoding', 'population decoding', 'information theory', 'and machine-learning']",,"The neural decoding is a procedure that uses spike trains fired by neurons to estimate features of original stimulus. This is a fundamental step for understanding how neurons talk each other and, ultimately, how brains manage information. In this paper, the strategies of neural decoding are classified into three methodologies: rate decoding, temporal decoding, and population decoding, which are explained. Rate decoding is the firstly used and simplest decoding method in which the stimulus is reconstructed from the numbers of the spike at given time (e. g. spike rates). Since spike number is a discrete number, the spike rate itself is often not continuous and quantized, therefore if the stimulus is not static and simple, rate decoding may not provide good estimation for stimulus. Temporal decoding is the decoding method in which stimulus is reconstructed from the timing information when the spike fires. It can be useful even for rapidly changing stimulus, and our sensory system is believed to have temporal rather than rate decoding strategy. Since the use of large numbers of neurons is one of the operating principles of most nervous systems, population decoding has advantages such as reduction of uncertainty due to neuronal variability and the ability to represent a stimulus attributes simultaneously. Here, in this paper, three different decoding methods are introduced, how the information theory can be used in the neural decoding area is also given, and at the last machinelearning based algorithms for neural decoding are introduced."
Efficient and Fast Iris Localization Using Binary Radial Gradient Features for Human-Computer Interaction,2017,"['Iris localization', 'gaze estimation', 'human-computer interaction', 'fast sliding window', 'binary feature', 'radial gradient']",,"<P>This paper proposes an efficient and fast iris localization method. It uses support vector machine learning of iris features that represent closed outer and inner iris boundaries encompassing a low-intensity region. In addition, depending on the location of the iris in an eye image, an iris detection method is proposed based on three sub-datasets of eye images (middle, right, and left sub-datasets) with different iris features. The proposed method is implemented using fast sliding window and fast computation of the iris detection score with binary features. Compared with state-of-the-art methods, experimental results show that the proposed method is twice as fast and has comparable accuracy, even when factoring in head rotation, glasses, and highlights.</P>"
4차 산업혁명과 한국의 번역산업 현황 및 통번역 교육의 미래,2017,"['CAT Tool(Computer Aided Translation 컴퓨터지원 번역 도구)', 'TC(Technical Communication', '테크니컬 커뮤니케이션)', 'MT(Machine Translation', '기계번역)', 'TRADOS(트라도스)']",,"This study explores the future of interpretation and translation education considering the status of Korean translation industry in the 4 th industrial revolution era to make a breakthrough in its academia and education.Humanities have not been able to establish a leading position in the era of the Artificial Intelligence, Big Data, Deep Learning and Internet of Thing though the mechanism of  translation  and  interpretation  plays a leading role in the revolution. The 4 th revolution will lead the area of translation and interpretation to make a stepping stone through the transition of awareness and building of the viable strategy further."
Convolutional Neural Network (CNN) 기반의 단백질 간 상호 작용 추출,2017,"['단백질간 상호작용 추출', '컨볼루션 네트워크', '정보추출', '딥 러닝', '기계학습', 'protein-protein interaction extraction', 'convolutional networks', 'information extraction', 'deep learning', 'machine learning']",본 논문에서는 학술 문헌에서 표현된 단백질 간 상호 작용(Protein-Protein Interaction) 정보를 자동으로 추출하기 위한 확장된 형태의 Convolutional Neural Network (CNN) 모델을 제안한다. 이 모델은 기존에 관계 추출(Relation Extraction)을 위해 고안된 단순 자질 기반의 CNN 모델을 확장하여 다양한 전역 자질들을 추가적으로 적용함으로써 성능을 개선할 수 있는 장점이 있다. PPI 추출 성능 평가를 위해서 많이 활용되고 있는 준거 평가 컬렉션인 AIMed를 이용한 실험에서 F-스코어 기준으로 78.0%를 나타내어 현재까지 도출된 세계 최고 성능에 비해 8.3% 높은 성능을 나타내었다. 추가적으로 CNN 모델이 복잡한 언어 처리를 통한 자질 추출 작업을 하지 않고도 단백질간 상호 작용 추출에 높은 성능을 나타냄을 보였다.,"In this paper, we propose a revised Deep Convolutional Neural Network (DCNN) model to extract Protein-Protein Interaction (PPIs) from the scientific literature. The proposed method has the merit of improving performance by applying various global features in addition to the simple lexical features used in conventional relation extraction approaches. In the experiments using AIMed, which is the most famous collection used for PPI extraction, the proposed model shows state-of-the art scores (78.0 F-score) revealing the best performance so far in this domain. Also, the paper shows that, without conducting feature engineering using complicated language processing, convolutional neural networks with embedding can achieve superior PPIE performance."
사물인터넷 환경에서 제품 불량 예측을 위한 기계 학습 모델에 관한 연구,2017,"['사물인터넷', '빅데이터', '예측', '기계 학습 모델', '제4차 산업혁명', 'Internet of Things', 'Big Data', 'Prediction', 'Machine Learning Model', 'The Fourth Industrial Revolution']",,
Explaining nonlinear classification decisions with deep Taylor decomposition,2017,"['Deep neural networks', 'Heatmapping', 'Taylor decomposition', 'Relevance propagation', 'Image recognition']",,"<P><B>Abstract</B></P>  <P>Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.</P>    <P><B>Highlights</B></P> <P> <UL> <LI>  A novel method to explain nonlinear classification decisions in terms of input variables is introduced. </LI> <LI>  The method is based on Taylor expansions and decomposes the output of a deep neural network in terms of input variables. </LI> <LI>  The resulting deep Taylor decomposition can be applied directly to existing neural networks without retraining. </LI> <LI>  The method is tested on two large-scale neural networks for image classification: BVLC CaffeNet and GoogleNet. </LI> </UL> </P>"
인공지능 기술(AI)의 도입에 따른 관광산업 직무대체수준 및 영향에 관한 탐색적 연구 - 대학생을 중심으로 -,2017,"['Artificial Intelligence', 'Tourism Industry', 'Job Replacement Level']",,"As the age of the fourth industrial revolution comes, automation technologies such as machine learning and artificial intelligence are affecting the profession of the tourism industry. Within the next 10 years, artificial intelligence technology is increasingly applied to various fields of the tourism industry. The more specific purpose of this study was to analyze the recognition of university students for job replacement level and influences of artificial intelligence. Data collection was carried on Oct, 2016 for 125 university students. As for the results of analysis, the possibility of substituting the artificial intelligence technology by occupation of tourism industry shows that tourist interpretation guides(61.8%) is the highest and casino dealers(53.2%), golf course caddies(53.2%) are also high. It also shows that the development of artificial intelligence technology is expected to be influential throughout the tourism sector in the near future, it is inevitable that a collaborative network both academia and industry sector should be established. especially, it is said that they should train artificial intelligence and big data experts in tourism field. Several academic and practical implications are suggested."
Bug Report Quality Prediction for Enhancing Performance of Information Retrieval-based Bug Localization,2017,"['정보검색기반 결함위치식별', '버그리포트', '쿼리 품질', '기계학습', 'information retrieval-based bug localization', 'bug report', 'query quality', 'machine learning']",,
Mathematics and its Education for Near Future,2017,"['education of mathematics', 'mathematics in the future', 'artificial intelligence', 'industrial mathematics', 'history of mathematics', 'counting', 'visualization.']",,"Recently industry goes through enormous revolution. Related to this, major changes in applied mathematics are occurring while coping with the new trends like machine learning and data analysis. The last two decades have shown practical applicability of the long-developed mathematical theories, especially some advanced mathematics which had not been introduced to applied mathematics.In this concern some countries like the U.S. or Australia have studied the changing environments related to mathematics and its applications and deduce strategies for mathematics research and education. In this paper we review some of their studies and discuss possible relations with the history of mathematics."
A Detailed Analysis of Classifier Ensembles for Intrusion Detection in Wireless Network,2017,"['Classifier Ensembles', 'Classifier’s Significance', 'Intrusion Detection Systems (IDSs)', 'Wireless Network']",,"Intrusion detection systems (IDSs) are crucial in this overwhelming increase of attacks on the computinginfrastructure. It intelligently detects malicious and predicts future attack patterns based on the classificationanalysis using machine learning and data mining techniques. This paper is devoted to thoroughly evaluateclassifier ensembles for IDSs in IEEE 802.11 wireless network. Two ensemble techniques, i.e. voting andstacking are employed to combine the three base classifiers, i.e. decision tree (DT), random forest (RF), andsupport vector machine (SVM). We use area under ROC curve (AUC) value as a performance metric. Finally,we conduct two statistical significance tests to evaluate the performance differences among classifiers."
통합 방법론을 적용한 THAAD 배치 이후 한중 보따리 무역의 변화 연구,2017,"['보따리 무역', 'THAAD 배치', '통합 방법론', '방법론 다각화', '부트스트랩', 'Parcel Trade', 'THAAD Deployment', 'Mixed Methodology', 'Triangulation', 'Bootstrap']","본 연구는 한중 간 소규모 무역의 주체인 보따리상에 대한 인터뷰 자료를 바탕으로 질적 연구와 양적 연구를 동시에 수행하는 통합 방법론을 통해 동일한 결론을 도출하였다. 또한 데이터를 증폭하는 과정에서 머신 러닝 기법의 하나인 부트스트랩을 활용하여 통합 방법론의 유용성에 대한 기존 이론을 무역학 분야에서 다시 한 번 입증하는 이론적 기여가 있었다. 더불어, 한국의 THAAD 배치와 중국의 무역 보복으로 인해 전반적으로 소규모 무역을 통한 보따리상의 활동이 축소되었으나, 오히려 한국 내 중국 물품에 대한 물량 또는 판매 속도는 크게 줄어들지 않았다는 것을 입증하며 실무적 공헌 또한 있었다. 본 연구는 직업군의 특수성으로 인해 조선족 이외의 다양한 보따리상을 접촉하지 못하였다는 한계점이 있으나, 향후 이를 극복하여 더욱 정교한 연구가 가능할 것이라 기대한다.","This study concluded the same conclusion through an mixed methodology that simultaneously conducts qualitative and quantitative research based on the interview data of people doing small and parcel trade between Korea and China. In the process of amplifying the data, there was a theoretical contribution to reestablish the theory of the usefulness of mixed methodology in the field of trade using the bootstrap, which is one of the machine learning techniques. In addition, Korea's THAAD deployment and China's trade retaliation reduced overall small and parcel trade activity, but also proved that sales volume and velocity in Korea for Chinese goods did not much decrease. This study has limitations that it can not contact various parcel traders other than Korean-Chinese due to the specificity of the occupation group, but it is expected that more sophisticated research will be possible in the future."
증분형 K-means 클러스터링 기반 방사형 기저함수 신경회로망 모델 설계,2017,"['Incremental K-means clustering', 'recursive least square estimation', 'Radial basis function neural networks', 'Particle swarm optimization']",,"In this study, the design methodology of radial basis function neural networks based on incremental K-means clustering is introduced for learning and processing the big data. If there is a lot of dataset to be trained, general clustering may not learn dataset due to the lack of memory capacity. However, the on-line processing of big data could be effectively realized through the parameters operation of recursive least square estimation as well as the sequential operation of incremental clustering algorithm. Radial basis function neural networks consist of condition part, conclusion part and aggregation part. In the condition part, incremental K-means clustering algorithms is used tweights of the conclusion part are given as linear function and parameters are calculated using recursive least squareo get the center points of data and find the fitness using gaussian function as the activation function. Connection s estimation. In the aggregation part, a final output is obtained by center of gravity method. Using machine learning data, performance index are shown and compared with other models. Also, the performance of the incremental K-means clustering based-RBFNNs is carried out by using PSO. This study demonstrates that the proposed model shows the superiority of algorithmic design from the viewpoint of on-line processing for big data."
제4차 산업혁명이 노동시장과 노동사회법에 미치는 영향,2017,"['제4차 산업혁명', '노동 4.0', '플렛폼 경제', '디지털 경제', '디지털 경영', '직업훈련', '평생교육', '4th Industrial Revolution', 'industry 4.0', 'Arbeit 4.0', 'automation', 'platform economy', 'digital management', 'on-the-job-training']","Industry 4.0가 일자리에 미치는 효과는 직업에 따라 다르나. 일부 직업은 자동화되고, 반복작업과 관련 있는 저숙련, 저임금 직은 이른 장래에 사라질 것이다. 인공지능(AI). 기계학습(machine learning), 소프트웨어 자동화애플 등과 같은 기술은 저임금, 저숙련 노동자들에게만 영향을 주는 것이 아니고, 점차 컴퓨터로 하여금 기자, 교사, 변호사 등과 같은 상당한 교육ㆍ훈련이 요구되는 직업까지도 수행할 수 있게 될 것이다. 전적으로 안전한 직업은 하나도 없다. 그러나 공감, 소통기술, 긴밀한 인간관계 등을 요구하는 직업은 로봇이나 자동화로 대체되기 어렵다. ‘플렛폼 경제’(platform economy) 의 증가로 근로조건은 점차로 유연해지고 있다. 어느 고용 형태에서는 고용계약, 임금기준, 근로시간규정, 고정 일자리, 노조 가입 등이 블가능하다. 노동자 스스로가 자신의 사회적 보호, 작업장 보건과 안전 보호 등에 책임을 지게 된다. ‘디지털 경영’(Digital management)으로 경영자들은 디지털/스마트 장비로 회사를 보다 효율적으로 경영할 수 있다. 사용자들은 근로자들이 잠시 전 연락을 받고 불러내거나 돌려보내는 ‘적시’ (just-in-time) 일정을 만들어내는 데 흥미를 갖게 될 것이다. 이와 같은 ‘국경없는 노동’(work without frontiers)은 스트레스와 burnout을 유발하기 십상이다. 정보통신기술(ICT)에 기반한 모바일 노동은 노동집중화를 초래하고 스트레스의 수준을 높인다. 스마트 기재로 근로자의 성과를 계속 모니터하는 등의 새로운 경영형태도 스트레스의 수준을 높인다. 이러한 것들은 burnout 또는 고립공포감(Fear of Missing Out, FOMO) 등 직업병를 유발할 수 있다. 일자리를 없애는 것이 Industry 4,0의 가장 심각한 부정적 효과 중의 하나이다. 따라서 고용보험이라는 효율적인 제도를 확보하는 것이 강력한 수단이 된다. 이 제도가 자동화로 밀려난 노동자들을 위한 안전망이 된다. 일자리에 기반한 훈련프로그램이 채택되어 해고된 노동자들이 구직수당을 받아 작업을 통한 교육 훈련(on-the-job training)에 참가할 수 있어야 한다. 해고된 근로자들이 작업현장을 떠나지 않는 것이 중요하다. 기술적, 구조적 변화는 일자리에 필요한 노동자의 기술 역시 변화하게 한다. 따라서 빠르게 변화하는 디지털 사회에서는 재교육과 재취업이 중요할 것으로 예상된다. 최근의 교육은 노동자의 조직 내외부 협력 능력을 향상시키는 의미를 포함하고 있다. 특히 지식 경제에서는 공장 내에서만 생산과정이 끝나는 것이 아니라 노동자 및 관리자의 다양한 활동과 연결되어 있으며, 이들의 창의력, 사회적 소양 등을 향상해가는 것이 곧 기업의 성과에도 영향을 미치게 될 것이다.","As the effect of industry 4.0, some occupations will be automated, low-skilled, low-wage jobs involving repetitive works will disappear in an imminent future. No job is totally safe. Automation is blind to the color of workers’ collar. However, jobs that require empathy, communication skills, and close personal interaction would be more difficult to be displaced by robots or automation. With the increase of “platforms’ economy”, the labour conditions become more and more flexible. Within some forms of employment, there is no employment contract, wage standards, working-hour regulations, immobile workplace, access to labour unions. The workers have to be responsible for their own social protection, work health and safety protection. With “digital management” the employers can manage their companies more efficiently. The employers will be encouraged to create “just-in-time” schedules in which workers are called in or sent home on a short notice. It is likely to trigger occupational diseases such as burn-out or FOMO (Fear of Missing Out). Skilled workers will be hired for a certain project or to solve a specific problem. On line platforms will match employers and workers. Establishing an efficient mechanism of unemployment insurance will be a powerful tool to deal with job displacement caused by Industry 4.0. It can offer a secure safety net for workers displaced by automation. Work-based training programs should also be adopted so the displaced workers can participate in on-the-job training while receiving unemployment benefits. However, workers without certain level of technical knowledge are more likely to be left behind. As technology innovation continues, workers have to keep learning to meet the need of different skills required by new jobs. An efficient mechanism of job training and continuing education will help workers be hired or navigate job transitions more successfully. The pessimists believe that all the jobs will be replaced by automation in the imminent future. The optimists insist that automation will create more jobs than it destroys in the end. All the workers will be required to learn new skills in order to survive in the future labour market. There will be jobs that nobody in the past ever predicted. The good news is that mass replacement of jobs by automation is not going to happen overnight. We still have time to think about how to adapt to the new world."
Performance analysis of space heating smart control models for energy and control effectiveness in five different climate zones,2017,"['Smart heating control', 'Fuzzy inference system', 'Artificial neural network', 'Energy and control effectiveness', 'Climate zone']",,"<P><B>Abstract</B></P>  <P>This paper compares smart control models for heating supply air among five different climate conditions to discuss the effectiveness of machine learning tools in terms of control and energy efficiency.</P> <P>A thermostat on/off control is typically used to maintain room temperature at a desired level. Advanced computing technologies have recently been introduced to complement the conventional on/off controls to improve control efficiency in heating systems. However, these methods, which were mostly utilized to control fuel amount or fan motor speed, lacked the capability to promptly respond to various outdoor temperature conditions as climate zones requiring refined control strategies to reduce environmental impacts.</P> <P>This paper proposes intelligent controls of mass and temperature simultaneously for heating air supply. The Fuzzy Inference System (FIS) and Artificial Neural Network (ANN) algorithms are utilized to develop six control models, and the models are tested to evaluate both control and energy efficiency during the winter season in five climate zones (from climate zone 2 through 6; i.e., Houston, Dallas, Raleigh, Chicago, and Detroit, respectively). Results include the energy consumption, control errors, and control signals in comparison to the baseline on/off control, which confirms the fact that the ANN simultaneous controls of mass and temperature is more effective than the other controllers for control accuracy and energy savings by 71.3% and 0.3%, respectively. The effectiveness of the ANN controller can contribute to maintaining room temperature accompanying the reduction of energy consumption, which is directly related to improve human comfort and reduce environmental impacts in various climate zones.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Smart control models are proposed to improve control accuracy and energy efficiency. </LI> <LI>  To provide appropriate thermal energy, the models simultaneously control air mass and temperature. </LI> <LI>  Model’s purposes are to maintain desired room temperature and suppress energy consumption increases. </LI> <LI>  All models are compared with conventional thermostat on/off controller in five different climate zones in the U.S. </LI> <LI>  The ANN model increases the effectiveness for space heating in both moderate and cold climate areas. </LI> </UL> </P>"
Group lasso를 통한 중학생의 삶의 만족도에 영향을 미치는 변수 탐색,2017,"['한국아동청소년패널조사', '삶의 만족도', 'group lasso', '벌점 회귀모형', '숙달목적지향성 학습습관', '기계학습', 'KCYPS', 'life satisfaction', 'group lasso', 'penalized regression', 'mastery goal orientation', 'machine learning']","한국청소년정책연구원의 KCYPS 패널 자료가 수백 개의 변수들을 제공함에도, 선행 연구들은 그 중 십여 개의 변수 또는 요인만을 선정하여 청소년의 삶의 만족도를 모형화해왔다. 그러나 복잡다단한 인간을 대상으로 하는 사회과학 연구는 기존 이론에 근거한 몇 가지 변수 또는 요인만을 이용하는데서 벗어나, 다른 새로운 변수들을 파악함으로써 기존 이론을 정비할 필요가 있다. 특히 KCYPS가 제공하는 변수들은 그 이론적·실제적 타당성을 다수의 전문가들이 연구 설계에서부터 고려하여 수집된 변수들이다. 따라서 본 연구는 KCYPS 6차년도 초4 패널 자료 전체를 이용하여 중학생의 삶의 만족도에 영향을 미치는 변수를 탐색하고자 벌점 회귀모형 기법인 group lasso를 적용하였다. 벌점 회귀모형은 비벌점 회귀모형이 투입변수가 증가함에 따라 모형안정성이 떨어지는 문제에 대하여 해결책을 제시한다. 또한 본 연구에서 group lasso를 적용함으로써 모형에서 연속형 변수뿐만 아니라 범주형 변수를 함께 다룰 수 있었다. 그 결과 338개 변수 중 15 개 변수가 선택되었으며, 이 때 모형의 예측 정확도는 78.25%였다. 선택된 변수 중 자아인식, 정서문제, 양육방식, 전체성적 만족도, 지역사회인식, 가정경제수준 평가 관련 문항은 선행연구에서 이용된 바 있으며, 그 회귀계수 방향 또한 선행연구 결과와 전반적으로 일치하였다. 선행연구에서 다루어지지 않았으나 벌점 회귀모형에서 선택된 변수로 공부시간, 여가시간, 숙달목적 지향성 학습습관, 학교 체육시간 관련 문항이 있었다. 본 연구는 국내 사회과학 패널 자료에 group lasso를 적용한 최초의 연구일 것으로 사료된다.","This study explored predictors affecting KCYPS middle school students’ life satisfaction levels, via penalized regression, specifically the group lasso. Among 338 KCYPS predictors after data cleaning had been conducted, a total of 15 were selected in the group lasso model. The prediction accuracy was determined to be 78.25%. Self-concept, depression, parental rearing styles, overall academic satisfaction, community recognition, gender, and home economic status were found to have an effect on students life satisfaction, consistent with the findings of previous research. Study hours, mastery goal orientation, and students’ perceived physical education hours were newly explored predictors, not yet investigated in previous research. As one of the first group lasso studies making use of social science panel data, this study successfully included categorical predictors as well as continuous ones in one group lasso model."
A Detailed Analysis of Classifier Ensembles for Intrusion Detection in Wireless Network,2017,"['Classifier Ensembles', ""Classifier's Significance"", 'Intrusion Detection Systems (IDSs)', 'Wireless Network']",,"Intrusion detection systems (IDSs) are crucial in this overwhelming increase of attacks on the computing infrastructure. It intelligently detects malicious and predicts future attack patterns based on the classification analysis using machine learning and data mining techniques. This paper is devoted to thoroughly evaluate classifier ensembles for IDSs in IEEE 802.11 wireless network. Two ensemble techniques, i.e. voting and stacking are employed to combine the three base classifiers, i.e. decision tree (DT), random forest (RF), and support vector machine (SVM). We use area under ROC curve (AUC) value as a performance metric. Finally, we conduct two statistical significance tests to evaluate the performance differences among classifiers."
Dual-kNN for a Pattern Classification Approach,2017,"['Dual-kNN', 'kNN', 'Robustness', 'Pattern classification']",,"Classification is a process of discovering and categorizing objects from large data storage that have similar characteristics, properties, and patterns. One of the most widely used classification methods in machine learning is the k-nearest neighbors (k-NN) algorithm. The unique property of k-NN that appeals to researchers is its simplicity, so it can be applied successfully over a wide field. However, according to measurement of the performance of an algorithm based on three considerations (simplicity, processing time, and prediction power), the k-NN algorithm lacks highspeed computation and maintenance of high accuracy for different K values. In other words, k-NN is a heuristic classification approach. Besides, the prediction accuracy fades away whenever K approaches larger values. To overcome these issues, this paper presents a dual-kNN that concentrates on two properties to keep up the accuracy at different K values and upgrade processing time performance. By conducting experiments on real datasets and comparing this algorithm with k-NN, it was also confirmed that the new dual-kNN is an effective and robust approach to classification."
토픽 모델링에 따른 고등학생 논설문의 응결성과 응집성의 상관분석,2017,"['응결성', '응집성', '응결 장치', '토픽 모델링', 'LDA', '기계 학습', '준 지도 학습', '텍스트 마이닝', 'RASCH 모형', '일반화 가능도', 'Cohesion', 'Coherence', 'Cohesive Device', 'Topic Modeling', 'Machine Learning', 'Semi-Supervised Learning', 'Text Mining', 'Rasch Model', 'Generalizability']",,"This study investigates the validity of the method used to measure coherence by analyzing the correlation between cohesion scores and the coherence of student texts calculated using topic modeling. For this purpose, cohesion through topic similarity was categorized into local, global, and overall text coherence. Next, the results were compared with teacher-generated coherence scores. The results showed that local cohesion was negatively correlated with the coherence scores. Global cohesion was not significantly correlated with teachers` grading results, and overall text cohesion showed a positive correlation. This study shows that coherence is related to the consistency of the whole text and that topic modeling can be a useful tool for providing objective information about the text."
염색가공 산업의 에너지 효율화를 위한 제조현장 빅데이터 활용에 관한 연구,2017,"['Big Data', 'Dyeing Process', 'Energy Efficiency', 'Green Manufacturing', 'Information and Communication Technology']",,"The manufacturing industry has been actively adapting ICT (Information and Communication Technology) into the field with keywords such as 4th industrial revolution. Due to collecting information and data analytics technologies, products, machines and process in the traditional manufacturing industry have become smart. In the textile industry, an efficiency in a dyeing process greatly depends on energy usage. Thus, researchers in dyeing-finishing factories focus on energy efficiency in this area. They have been trying to make energy efficient through various experiments, but haven’t achieved remarkable result due to various problems on the site. Therefore, we collect manufacturing big data and try to improve energy efficiency based on the collected data. In this paper, we consider a method to improve the energy efficiency in dyeing process using manufacturing big data. We propose a way to achieve energy efficiency in the dyeing process with lower energy usage and repeated dyeing. As a result of this paper, it is suggested that dyeing process should be instructed and controlled based on the significant variables and learning model when energy efficiency is to be utilized by using manufacturing big data. We also verify the feasibility of this argument through a case study using ANN."
Playing to our human strengths to prepare medical students for the future,2017,"['Curriculum', 'Undergraduate', 'Technology', 'Competency', 'Hong Kong']",,"We are living in an age where artificial intelligence and astounding technological advances are bringing truly remarkable change to healthcare. Medical knowledge and skills which form the core responsibility of doctors such as making diagnoses may increasingly be delivered by robots. Machines are gradually acquiring human abilities such as deep learning and empathy. What, then is the role of doctors in future healthcare? And what direction should medical schools be taking to prepare their graduates? This article will give an overview of the evolving technological landscape of healthcare and examine the issues undergraduate medical education may have to address. The experience at The University of Hong Kong will serve as a case study featuring several curricular innovations that aim to empower medical graduates with the capabilities to thrive in the future."
SNS텍스트의 오피니언 마이닝을 위한 언어자원 기반 감성 분석 플랫폼 연구,2017,"['sentiment analysis', 'opinion mining', 'DecoTex platform', 'social media text', 'twitter crawling', 'preprocessing', 'DECO Korean dictionary', 'local-grammar graph', '감성분석', '오피니언마이닝', 'DecoTex플랫폼', 'SNS 텍스트', '트위터크롤링', '전처리', 'DECO사전', 'LGG문법']",,"This study aims to introduce DecoTex, a language resource-based sentiment analysis platform, implemented for opinion mining of social media texts. DecoTex supports several functions such as the Twitter crawler, Preprocessing module, and Sentiment Analysis modules. The Sentiment Analysis modules consist of two parts: Supervised Machine Learning options requiring Sentiment- Annotated Corpora as training data and Lexicon-based algorithmic options based on Sentiment Lexica and Local Grammars. By illustrating a process of classifying positive/negative opinions on ‘China’ and ‘Japan’ in Twitter texts through DecoTex platform, this study emphasizes the importance of a computational platform for humanities researchers. We believe that it is crucial to free them from making efforts to learn programming skills for obtaining experimental results or evaluating their studies since they may focus on constructing linguistic resources that require an enormous amount of time, energy, and knowledge."
온라인 음악 콘텐츠 추천 시스템 구현을 위한 협업 필터링 기법들의 비교 평가,2017,"['Data mining', 'Collaborative filtering', 'Clustering', 'Recommendation', 'Content']",,"As big data technologies have been developed and massive data have exploded from users through various channels, CEO of global IT enterprise mentioned core importance of data in next generation business. Therefore various machine learning technologies have been necessary to apply data driven services but especially recommendation has been core technique in viewpoint of directly providing summarized information or exact choice of items to users in information flooding environment. Recently evolved recommendation techniques have been proposed by many researchers and most of service companies with big data tried to apply refined recommendation method on their online business. For example, Amazon used item to item collaborative filtering method on its sales distribution platform. In this paper, we develop a commercial web service for suggesting music contents and implement three representative collaborative filtering methods on the service. We also produce recommendation lists with three methods based on real world sample data and evaluate the usefulness of them by comparison among the produced result. This study is meaningful in terms of suggesting the right direction and practicality when companies and developers want to develop web services by applying big data based recommendation techniques in practical environment."
A Hand Gesture Recognition Sensor Using Reflected Impulses,2017,,,"<P>This paper introduces a hand gesture recognition sensor using ultra-wideband impulse signals, which are reflected from a hand. The reflected waveforms in time domain are determined by the reflection surface of a target. Thus every gesture has its own reflected waveform. Thus we propose to use machine learning, such as convolutional neural network (CNN) for the gesture classification. The CNN extracts its own feature and constructs classification model then classifies the reflected waveforms. Six hand gestures from american sign language (ASL) are used for an experiment and the result shows more than 90% recognition accuracy. For fine movements, a rotating plaster model is measured with 10 degrees step. An average recognition accuracy is also above 90%.</P>"
Prediction of black tea fermentation quality indices using NIRS and nonlinear tools,2017,"['Black tea', 'Fermentation', 'Near infrared spectroscopy', 'Nonlinear tools']",,"Catechin content, the ratio of tea polyphenols and free amino acids (TP/FAA), as well as the ratio of theaflavins and thearubigins (TFs/TRs) are important biochemical indicators to evaluate fermentation quality. To achieve rapid determination of such biochemical indicators, synergy interval partial least square and extreme learning machine combined with an adaptive boosting algorithm, Si-ELM-AdaBoost algorithm, were used to establish quantitative analysis models between near infrared spectroscopy (NIRS) and catechin content and between TFs/TRs and TP/FAA, respectively. The results showed that prediction performance of the Si-ELM-AdaBoost mixed algorithm is superior than that of other models. The prediction results with root-mean-square error of prediction ranged from 0.006 to 0.563, the ratio performance deviation values exceeded 2.5, and predictive correlation coefficient values exceeded 0.9 in the prediction model of each biochemical indicator. NIRS combined with Si-ELMAdaBoost mixed algorithm could be utilized for online monitoring of black tea fermentation. Meanwhile, the AdaBoost algorithm effectively improved the accuracy of the ELM model and could better approach the nonlinear continuous function."
Consistency Control of Roller-Compacted Concrete for Pavement,2017,"['Roller-compacted concrete', 'consistency', 'aggregate gradation', 'water content', 'admixtures']",,"Roller-compacted concrete or RCC is a dry concrete that requires compaction in order to reach its final form. Its consistency is usually overlooked due to its inconsistency and lack of subjective nature. To work with this concrete, however, proper consistency is necessary for supporting the compacting machine and minimizing compaction energy. Vebe time is used as consistency measurement due to RCC’s dryness. Vebe time ranged from 30 to 75 seconds is considered to be appropriate consistency for RCC in pavement application. The purpose of this study is to determine the effect of aggregate gradation, water content, admixtures and time on RCC’s consistency for pavement application. It was found that Vebe time decreased when water content increased and increased when sand by aggregate ratio or the amount of fine aggregate increased. The workable time of normal RCC mixture (an optimal mixture) was found to be less than 50 minutes. Poly Naphtalene Sulfonate superplatiscizer or PNS was discovered to be very effective in lowering down Vebe time and maintaining it. 0.3% of this admixture was learned to extend the working time up to four hours without influencing RCC’s compressive strength."
사상 최대 레이테 해전의 전투경과 분석과 전투 교훈 고찰,2017,"['Pacific War', 'Battle of Leyte Gulf', 'Naval Power', 'IJN', 'Five Main Battles', 'Combat Lessons', 'Analysis']",,"As the greatest naval battle in the history, the battle of Leyte Gulf in Oct 1944 has very significant meanings in the Pacific War. Compared with the battle of Jutland which has a place as the second largest battle of all, the battle of Leyte Gulf has shown not only its bigger size but also all sort of the available warships and warfare machines in surface, under sea and sky. From the point of views in the tides of Pacific War, this battle has marked as the decisive battle which the back bones of IJN(Imperial Japanese Navy) was completely broken down and confirmed US naval power far higher level to IJN.IJN`s fleet nearly achieved its long-desired victory because of poor US command decisions. Instead, on the brink of success, the Japanese commander turned away and US Navy won another major victory. After naval victory at the battle of Leyte Gulf, US Force managed to press on Luzon, Okinawa, Iwojima and then finally made Japan unconditionally surrender in Aug 1945.This study focused in detail on the each phase of the five main battles in the battle of Leyte Gulf, namely at Palawan Passage, Sibuyan Sea, Surigao Strait, Samar Island and Cape Engano. Through this study, we can make some analysis what sort of factors influence on the results of the decisive battles, and also we can learn the valuable combat lessons which can be useful for the implementation of future combat operation which might take place in Korean peninsula."
와전류탐상검사를 이용하여 탐지 가능한 볼트홀 내부 균열 길이 연구,2017,"['Eddy Current Inspection(와전류탐상검사)', 'Probability of Detection(탐지확률)']","물리모델과 기계학습방법을 이용한 모델지원탐지확률(MAPOD, Model-assisted Probability of Detection) 실험계획법과 운용 중 결함이 발생한 부품을 사용하여 탐지확률을 측정하는 방법을 연구하였다. 검사방법은 와전류탐상검사를 적용하였고 검사대상은 볼트홀 표면에 존재하는 피로균열이다. 모델지원탐지확률을 이용한 결과 실험요인이 큰 폭으로 감소하였다. 몬테카를로(Monte Carlo) 시뮬레이션을 이용하여 시편 균열길이 측정의 불확실성을 탐지확률에 반영함으로써 사용 중 결함품을 사용하여 비파괴검사정비사의 기량검증을 수행할 수 있었다.","In this study, the physics-based model and machine learning technique were used to conduct model-assisted probability of detection (MAPOD) experiments. The possibility of using in-service cracked parts was also investigated. Bolt hole shaped specimens with fatigue crack on the hole surface were inspected using eddy current inspection. Owing to MAPOD, the number of experimental factors decreased significantly. The uncertainty in the crack length measurement for in-service cracked parts was considered by the application of Monte Carlo simulation."
"초분광 표적 탐지를 위한 L<sub>2,1</sub>-norm Regression 기반 밴드 선택 기법",2017,"['Hyperspectral Target Detection', 'Band Selection', '$L_{2', '1}$-norm regression']",,"When performing target detection using hyperspectral imagery, a feature extraction process is necessary to solve the problem of redundancy of adjacent spectral bands and the problem of a large amount of calculation due to high dimensional data. This study proposes a new band selection method using the $L_{2,1}$-norm regression model to apply the feature selection technique in the machine learning field to the hyperspectral band selection. In order to analyze the performance of the proposed band selection technique, we collected the hyperspectral imagery and these were used to analyze the performance of target detection with band selection. The Adaptive Cosine Estimator (ACE) detection performance is maintained or improved when the number of bands is reduced from 164 to about 30 to 40 bands in the 350 nm to 2500 nm wavelength band. Experimental results show that the proposed band selection technique extracts bands that are effective for detection in hyperspectral images and can reduce the size of the data without reducing the performance, which can help improve the processing speed of real-time target detection system in the future."
DECO 감성사전과 LGG 문법에 기반한 관광 숙박 온라인 후기글의 감성 분석 연구,2017,"['감성분석', 'DECO사전', 'LGG문법', '온라인후기글', '제주도', '에어비엔비', 'Sentiment Analysis', 'DECO Dictionary', 'Local Grammar Graphs', 'Online Reviews', 'Jeiju Island', 'Airbnb']",,"This study proposes a Sentiment Analysis of Airbnb users' reviews of Jeju Island (Korean tourist attraction) based on DECO Korean dictionary and Local Grammar Graphs(LGGs). As a result of classification utilizing DecoSentiClassifier, 97% reviews turned out to be ‘Positive’. Moreover, we investigated time-series trend graphs, co-occurrence network, and term-frequency tables of the two most popular districts (Seogwipo-si and Jeju-si) of Jeju. Unlike the related studies mostly rooted in machine learning methods such as statistic classification or automatic lexical expansion, this research focuses on lexical algorithmic classification based on DECO dictionary for simple words and LGG formalism for multi-word expressions such as polarity-shifted sequences. Sentiment analysis based on elaborated language resources enhances overall reliability of the analysis and makes accessible a bootstrap approach, clarifying the primary significance of this study."
와전류탐상검사를 이용하여 탐지 가능한 볼트홀 내부 균열 길이 연구,2017,"['와전류탐상검사', '탐지확률']","물리모델과 기계학습방법을 이용한 모델지원탐지확률(MAPOD, Model-assisted Probability of Detection) 실험계획법과 운용 중 결함이 발생한 부품을 사용하여 탐지확률을 측정하는 방법을 연구하였다. 검사방법은 와전류탐상검사를 적용하였고 검사대상은 볼트홀 표면에 존재하는 피로균열이다. 모델 지원탐지확률을 이용한 결과 실험요인이 큰 폭으로 감소하였다. 몬테카를로(Monte Carlo) 시뮬레이션을 이용하여 시편 균열길이 측정의 불확실성을 탐지확률에 반영함으로써 사용 중 결함품을 사용하여 비파괴검사정비사의 기량검증을 수행할 수 있었다.","In this study, the physics-based model and machine learning technique were used to conduct model-assisted probability of detection (MAPOD) experiments. The possibility of using in-service cracked parts was also investigated. Bolt hole shaped specimens with fatigue crack on the hole surface were inspected using eddy current inspection. Owing to MAPOD, the number of experimental factors decreased significantly. The uncertainty in the crack length measurement for in-service cracked parts was considered by the application of Monte Carlo simulation."
Neuro Fuzzy와 WECR 기법에 의한 상수관망 누수예측,2017,"['상수관망', '누수', '뉴로퍼지', 'WECR(Western Electric Control Rule)', 'Water Distribution Network', 'Leakage', 'Neuro-Fuzzy']","상수관망 관로누수 판별을 위해서는 공급유량과 수수유량 관계로 해석하기 위한 예측 알고리즘과 이상감지 방법이 병행되어야 한다. 상수관망에는 다양한 센서가 설치되어 있음에 따라 센서 형태별 예측 알고리즘을 비교하였으며, 이 결과 뉴로퍼지 알고리즘 예측이 우수함을 확인하였다. 또한 센서 조합별 이상감지 판별율을 비교한 결과 유량센서를 많이 고려할수록 더 좋은 결과를 얻었으며, 압력센서 자료를 활용하여도 이상감지가 가능하였다. 따라서 상수관망 누수감지를 보다 신속하고 정확하게 해석하기 위해서 센서조합별 적용 머신러닝 알고리즘을 다양화하는 방식을 제안하였다.","A prediction algorithm and an abnormal detection method must be concurrently applied to find leaks from water pipes, which leads to be analyzed by the relationship between the supply and receiving flow. As various sensors are installed in water distribution network, the prediction algorithms for different sensor types are compared. In this paper, Neuro-fuzzy algorithm prediction is the most excellent than the others as an prediction algorithm, in which the more flow rates for input variable are considered and the estimation error are decreased. If there is no flow sensor, it is proposed that pressure sensor can be used for input and output variables. Therefore, the paper propose a method to diversify the machine learning algorithms applied to sensor combinations to analyze the water leakage detection more quickly and accurately."
멀티코어 인메모리 환경에서 트랜잭션을 처리하기 위한 효율적인 HTM 기법,2017,"['멀티코어 인메모리 데이터베이스', '하드웨어 트랜잭셔널 메모리', '충돌 예측', '재시도 정책', 'multi-core in-memory databases', 'hardware transactional memory', 'conflict prediction', 'retry policy']","하드웨어 트랜잭셔널 메모리(HTM)는 트랜잭션 처리를 위한 병렬 프로그래밍 패러다임을 크게 바꾸었으며, 최근 Intel에서 TSX를 제안함에 따라 HTM에 기반한 다수의 연구들이 수행되었다. 그러나 기존 연구들은 트랜잭션 처리에서 하나의 원인에 대한 충돌 예측만을 지원하며, 모든 워크로드에 대해 획일화된 TSX 환경을 제공한다. 이러한 문제점을 해결하기 위해, 본 논문에서는 멀티코어 인메모리 환경에서 트랜잭션을 처리하기 위한 효율적인 HTM 기법을 제안한다. 첫째, 제안하는 기법은 과거 트랜잭션처리 정보를 수집한 매트릭스를 이용하여, HTM 실패시의 대비책 경로로써 STM 혹은 single lock을 선택한다. 둘째, 머신러닝 알고리즘 기반 재시도 정책을 제공함으로써, 워크로드 특성에 맞는 효율적인 트랜잭션 처리를 수행한다. 마지막으로 STAMP를 이용한 성능평가를 통해, 제안하는 기법이 기존 연구에 비해 10～20%의 성능 향상이 있음을 보인다.","Hardware Transactional Memory (HTM) has greatly changed the parallel programming paradigm for transaction processing. Since Intel has recently proposed Transactional Synchronization Extension (TSX), a number of studies based on HTM have been conducted. However, the existing studies support conflict prediction for a single cause of the transaction processing and provide a standardized TSX environment for all workloads. To solve the problems, we propose an efficient hardware transactional memory scheme for processing transactions in multi-core in-memory environment. First, the proposed scheme determines whether to use Software Transactional Memory (STM) or the serial execution as a fallback path of HTM by using a prediction matrix to collect the information of previously executed transactions. Second, the proposed scheme performs efficient transaction processing according to the characteristic of a given workload by providing a retry policy based on machine learning algorithms. Finally, through the experimental performance evaluation using Stanford transactional applications for multi-processing (STAMP), the proposed scheme shows 10～20% better performance than the existing schemes."
Analysis of Neural Network Approaches for Nonlinear Modeling of Switched Reluctance Motor Drive,2017,"['Switched reluctance motor', 'Finite element analysis', 'ANN', 'GRNN', 'ELM']",,This paper attempts to employ and investigate neural based approaches as interpolation tools for modeling of Switched Reluctance Motor (SRM) drive. Precise modeling of SRM is essential to analyse the performance of control strategies for variable speed drive application. In this work the suitability of Generalized Regression Neural Network (GRNN) and Extreme Learning Machine (ELM) in addition to conventional neural network are explored for improving the modeling accuracy of SRM. The neural structures are trained with the data obtained by modeling of SRM using Finite Element Analysis (FEA) and the trained neural network is incorporated in the model of SRM drive. The results signify the modeling accuracy with GRNN model. The closed loop drive simulation is performed in MATLAB/Simulink environment and the closeness of the results in comparison with the experimental prototype validates the modeling approach.
Analysis of Neural Network Approaches for Nonlinear Modeling of Switched Reluctance Motor Drive,2017,"['Switched reluctance motor', 'Finite element analysis', 'ANN', 'GRNN', 'ELM']",,This paper attempts to employ and investigate neural based approaches as interpolation tools for modeling of Switched Reluctance Motor (SRM) drive. Precise modeling of SRM is essential to analyse the performance of control strategies for variable speed drive application. In this work the suitability of Generalized Regression Neural Network (GRNN) and Extreme Learning Machine (ELM) in addition to conventional neural network are explored for improving the modeling accuracy of SRM. The neural structures are trained with the data obtained by modeling of SRM using Finite Element Analysis (FEA) and the trained neural network is incorporated in the model of SRM drive. The results signify the modeling accuracy with GRNN model. The closed loop drive simulation is performed in MATLAB/Simulink environment and the closeness of the results in comparison with the experimental prototype validates the modeling approach.
Assessment of Premature Ventricular Contraction Arrhythmia by K-means Clustering Algorithm,2017,"['Electrocardiogram', 'Premature Ventricular Contraction', 'K-Means Clustering', 'Poincare Plot', 'Heart Rate Variability']",,"Premature Ventricular Contraction(PVC) arrhythmia is most common abnormal-heart rhythm that may increase mortal risk of a cardiac patient. Thus, it is very important issue to identify the specular portraits of PVC pattern especially from the patient. In this paper, we propose a new method to extract the characteristics of PVC pattern by applying K-means machine learning algorithm on Heart Rate Variability depicted in Poinecare plot. For the quantitative analysis to distinguish the trend of cluster patterns between normal sinus rhythm and PVC beat, the Euclidean distance measure was sought between the clusters. Experimental simulations on MIT-BIH arrhythmia database draw the fact that the distance measure on the cluster is valid for differentiating the pattern-traits of PVC beats. Therefore, we proposed a method that can offer the simple remedy to identify the attributes of PVC beats in terms of K-means clusters especially in the long-period Electrocardiogram(ECG)."
부호화 패턴 분석을 이용한 동영상 삭제 검출 기법,2017,"['Video Forensics', 'Frame Deletion', 'Video Forgery', 'HEVC', 'Coding Pattern']",,"In this paper, we introduce a technique to detect the video forgery using coding pattern analysis. In the proposed method, the recently developed standard HEVC codec, which is expected to be widely used in the future, is used. First, HEVC coding patterns of the forged and the original videos are analyzed to select the discriminative features, and the selected feature vectors are learned through the machine learning technique to model the classification criteria between two groups. Experimental results show that the proposed method is more effective to detect frame deletions for HEVC-coded videos than existing works."
근전도 신호를 이용한 손목 힘 및 악력 추정,2017,"['Robot prosthesis', 'Electromyography', 'Multilayer perceptron', 'Force estimation']",,"This paper proposes a method to simultaneously estimate two degrees of freedom in wrist forces (extension - flexion, adduction - abduction) and one degree of freedom in grasping forces using Electromyography (EMG) signals of the forearms. To correlate the EMG signals with the forces, we applied a multi - layer perceptron(MLP), which is a machine learning method, and used the characteristics of the muscles constituting the forearm to generate learning data. Through the experiments, the similarity between the MLP target value and the estimated value was investigated by applying the coefficient of determination (R2) and root mean square error (RMSE) to evaluate the performance of the proposed method. As a result, the R2values with respect to the wrist flexionextension, adduction - abduction and grasping forces were 0.79, 0.73 and 0.78 and RMSE were 0.12, 0.17, 0.13 respectively."
빅데이터 통합모형 비교분석,2017,,"빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
"초분광 표적 탐지를 위한 L2,1-norm Regression 기반 밴드 선택 기법",2017,"['Hyperspectral Target Detection', 'Band Selection', 'L2', '1-norm regression']","초분광 영상을 이용한 표적 탐지를 수행할 때에는 인접한 분광 밴드의 중복성의 문제 및 고차원 데이터로 인해 발생하는 방대한 계산량의 문제점을 해결하기 위한 특징 추출 과정이 필수적이다. 본 연구는 기계 학습 분야의 특징 선택 기법을 초분광 밴드 선택에 적용하기 위해 L2,1-norm regression 모델을 이용한새로운 밴드 선택 기법을 제안하였으며, 제안한 밴드 선택 기법의 성능 분석을 위해 표적이 존재하는 초분광영상을 직접 촬영하고 이를 바탕으로 표적 탐지를 수행한 결과를 분석하였다. 350 nm~2500 nm 파장 대역에서 밴드 수를 164개에서 약 30~40개로 감소시켰을 때 Adaptive Cosine Estimator(ACE) 탐지 성능이유지되거나 향상되는 결과를 보였다. 실험 결과를 통해 제안한 밴드 선택 기법이 초분광 영상에서 탐지에 효율적인 밴드를 추출해 내며, 이를 통해 성능의 감소 없이 데이터의 차원 감소를 수행할 수 있어 향후 실시간표적 탐지 시스템의 처리 속도 향상에 도움을 줄 수 있을 것으로 보인다.","When performing target detection using hyperspectral imagery, a feature extraction process is necessary to solve the problem of redundancy of adjacent spectral bands and the problem of a large amount of calculation due to high dimensional data. This study proposes a new band selection method using the L2,1-norm regression model to apply the feature selection technique in the machine learning field to the hyperspectral band selection. In order to analyze the performance of the proposed band selection technique, we collected the hyperspectral imagery and these were used to analyze the performance of target detection with band selection. The Adaptive Cosine Estimator (ACE) detection performance is maintained or improved when the number of bands is reduced from 164 to about 30 to 40 bands in the 350 nm to 2500 nm wavelength band. Experimental results show that the proposed band selection technique extracts bands that are effective for detection in hyperspectral images and can reduce the size of the data without reducing the performance, which can help improve the processing speed of real-time target detection system in the future."
넓은 해영역에서의 GA를 이용한 PID 제어기 게인 조정에 따른 개체수와 세대수 파라미터의 특징에 관한 연구,2017,"['Modified PID Controller', 'Genetic Algorithm', 'Gain tuning']",,"A GA is one of the best method to find optimal value in searching area. A GA is driven by probabilistic selection that based on the survival of the fittest. So this algorithm need a huge solving time even if it can be used lots of optimizing problem such as structural design, machine learning, system’s identification and so on. This GA’s characteristic constrain the program to drive offline. Some studies try to use this algorithm on online or reduce the GA’s running time with parallel GA or micro GA. Unfortunately these studies still didn’t reduce amount of fitness solving.  If the chromosome was imported to the system, it affected system’s stability. And when the control system uses online GA, it also doesn’t have enough learning time. In this study, try to find stability criterion to reduce the chromosome’s affection and find the characteristic of the number of population and generation when GA was driven into the wide searching area."
전이에 의해 융합되는 시조의 문학치료 코드 연구,2017,"['문학치료 코드', '치유의 콘텐츠', '감정의 배출', '감정의 융합', '슬픔의 코드', '행복의 부호화', 'Literary Therapeutic Codes', 'Contents of Therapy', 'Emission of Emotions', 'Convergence of Emotions', 'Code of Sadness', 'Encoding of happiness']",본 연구는 그동안 탁월한 치유의 기능이 내재되어 있다고 알려진 시조의 감정 코드들을 분석하여 인문학 적 치유의 콘텐츠를 활성화시키고자 하는 데에 목적이 있다. 치유작용의 일환으로써의 시조는 여러 작품들을 감상 하는 과정에서 형성되는 감정의 융합을 통해 감정의 총체라 할 수 있는 치유의 감정 코드들을 형성한다. 이러한 과정은 인체생리학적으로 인체 내에서의 문학치료의 진행을 가능하게 한다. 머신러닝이 인지기능에 의해 스스로 학습하는 것처럼 상시적으로 부호화와 재부호화에 대한 코딩 과정이 인체 시스템의 수많은 뉴런들의 집합체들에서 작동된다. 그 과정에서 감정 코드들의 집합적인 부호화에 의해 인체 내에서 아미노산이 합성되는 것으로 예측된다. 이러한 아미노산들이 인체의 신호 체계를 조절하는 것이다. 향후 이러한 인문학과 인체생리학의 접점에서의 치료의 연구가 진행된다면 보다 질 높은 인문학적 치유의 프로그램이 활성화될 것으로 기대된다.,"The purpose of this study is to analyze the emotional codes of Sijo, which has been acknowledged to have excellent therapeutic function, to activate the contents of the therapy of humanities. Sijo as a function of healing forms emotional codes of therapy, which is the total of emotions, through the fusion of emotions formed during the process of appreciation of various works. This process enables the literary therapeutic activities to proceed physiologically in the human body. Just as machine learning is self-learning by cognitive functions, the coding process for encoding and re-encoding at all times operates on collections of numerous neurons in the human system. In such a process, it is predicted that amino acids are synthesized in the human body by collective encoding of emotion codes. These amino acids regulate the signaling system of the human body. In the future, if the study on the healing process as such at the contact point of humanities and human physiology proceeds, it is expected that a program of higher quality humanistic therapy will be activated."
"Adaptive Resource Management and Provisioning in the Cloud Computing: A Survey of Definitions, Standards and Research Roadmaps",2017,"['Cloud Computing', 'Federated Clouds Resource Provisioning', 'Research Challenges in the Cloud', 'Service Level Agreement']",,"The fact that cloud computing services have been proposed in recent years, organizations and individuals face with various challenges and problems such as how to migrate applications and software platforms into cloud or how to ensure security of migrated applications. This study reviews the current challenges and open issues in cloud computing, with the focus on autonomic resource management especially in federated clouds. In addition, this study provides recommendations and research roadmaps for scientific activities, as well as potential improvements in federated cloud computing. This survey study covers results achieved through 190 literatures including books, journal and conference papers, industrial reports, forums, and project reports. A solution is proposed for autonomic resource management in the federated clouds, using machine learning and statistical analysis in order to provide better and efficient resource management."
Naive Bayes 기반 안드로이드 악성코드 분석 기술 연구,2017,"['Malware', 'Classification', 'Naive bayes']","스마트 폰의 보급률이 증가함에 따라 스마트 폰을 대상으로 하는 악성코드들이 증가하고 있다. 360 Security의 스마트 폰 악성코드 통계에 따르면 2015년 4분기에 비해 2016년 1분기에 악성코드가 437% 증가하는 수치를 보였다. 특히 이러한 스마트 폰 악성코드 유포의 주요 수단인 악성 어플리케이션들은 사용자 정보 유출, 데이터 파괴, 금전 갈취 등을 목적으로 하는데 운영 체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 해주는 인터페이스인 API에 의하여 동작하는 경우가 대부분이다. 본 논문에서는 정적 분석으로 도출한 어플리케이션 내 API의 패턴을 지도 학습 기법으로 머신에 학습하여 정상 어플리케이션과 악성 어플리케이션 내의 API 패턴의 유사도에 따라 악성 어플리케이션을 탐지하는 메커니즘을 제시하고 샘플 데이터에 대하여 해당 메커니즘을 사용하여 도출한 label 별 탐지율과 탐지율 개선을 위한 기법을 보인다. 특히, 제안된 메커니즘의 경우 신종 악성 어플리케이션의 API 패턴이 기존에 학습된 패턴과 일정 수준 유사한 경우 탐지가 가능하며 향후 어플리케이션의 다양한 feature를 연구하여 본 메커니즘에 적용한다면 anti-malware 체계의 신종 악성 어플리케이션 탐지에 사용될 수 있을 것이라 예상된다.","As the penetration rate of smartphones increases, the number of malicious codes targeting smartphones is increasing. I 360 Security""s smartphone malware statistics show that malicious code increased 437 percent in the first quarter of 2016 compared to the fourth quarter of 2015. In particular, malicious applications, which are the main means of distributing malicious code on smartphones, are aimed at leakage of user information, data destruction, and money withdrawal. Often, it is operated by an API, which is an interface that allows you to control the functions provided by the operating system or programming language. In this paper, we propose a mechanism to detect malicious application based on the similarity of API pattern in normal application and malicious application by learning pattern of API in application derived from static analysis. In addition, we show a technique for improving the detection rate and detection rate for each label derived by using the corresponding mechanism for the sample data. In particular, in the case of the proposed mechanism, it is possible to detect when the API pattern of the new malicious application is similar to the previously learned patterns at a certain level. Future researches of various features of the application and applying them to this mechanism are expected to be able to detect new malicious applications of anti-malware system."
A review of tree-based Bayesian methods,2017,"['Bayesian additive regression trees', 'boosting', 'random forests', 'semiparametric Bayes']",,"Tree-based regression and classification ensembles form a standard part of the data-science toolkit. Many commonly used methods take an algorithmic view, proposing greedy methods for constructing decision trees; examples include the classification and regression trees algorithm, boosted decision trees, and random forests. Recent history has seen a surge of interest in Bayesian techniques for constructing decision tree ensembles, with these methods frequently outperforming their algorithmic counterparts. The goal of this article is to survey the landscape surrounding Bayesian decision tree methods, and to discuss recent modeling and computational developments. We provide connections between Bayesian tree-based methods and existing machine learning techniques, and outline several recent theoretical developments establishing frequentist consistency and rates of convergence for the posterior distribution. The methodology we present is applicable for a wide variety of statistical tasks including regression, classification, modeling of count data, and many others. We illustrate the methodology on both simulated and real datasets."
관계형 데이터베이스 워크로드 분석을 통한 NoSQL 시스템 추천,2017,"['관계형 데이터베이스', '워크로드', 'NoSQL', '성능 평가', '추천 시스템', 'Relational Database', 'Workload', 'NoSQL', 'Performance Evaluation', 'Recommendation System']","관계형 데이터베이스 관리 시스템(RDBMS)으로 처리하기 어려운 규모의 빅데이터를 효과적으로 처리할 수 있는 NoSQL이 등장하였으며, 많은 기업들이 자사의 데이터베이스를 RDBMS에서 NoSQL로 마이그레이션 하고자 한다. 그러나 다양한 NoSQL 시스템들이 존재하기 때문에 주어진 RDB 워크로드에 어떤 NoSQL 시스템이 적합한지를 평가하는 데 많은 시간과 비용이 소요된다. 본 논문에서는 관계형 데이터베이스(RDB)의 워크로드를 분석하여 적합한 NoSQL을 추천해주는 시스템을 제안한다. 제안하는 시스템은 NoSQL 성능 평가 결과와 RDB 워크로드 데이터를 결합하여 학습 데이터를 생성한다. 다양한 기계학습 분류기를 적용하여 제안한 NoSQL 추천 시스템의 정확도를 측정한 결과, 사전에 학습되지 않은 워크로드 유형을 사용하여 테스트하였을때는 LDA+SVM 분류기가 82.36%, 학습된 워크로드 유형을 사용하여 테스트하였을 때는 Decision Tree 분류기가 96.53%의 가장 높은 정확도를 보였다.","Big data is difficult to process using Relational Database Management Systems (RDBMSs), and NoSQL has emerged to effectively process big data. Many enterprises plan to migrate their databases from RDBMS to NoSQL. Because there are so many NoSQL systems, it takes a lot of time and cost to evaluate which NoSQL system is appropriate for a given RDB workload. In this paper, we propose a system that recommends NoSQL systems based on RDB workload analysis. The proposed system generates training data by combining performance evaluation results for NoSQL systems and RDB workload data. We evaluate the proposed system using various machine learning classifiers. Experimental results show that for unlearned workload types, the LDA+SVM classifier achieves the highest accuracy of 82.36%. For learned workload types, the Decision Tree classifier achieves the highest accuracy of 96.53%."
An Optimized CLBP Descriptor Based on a Scalable Block Size for Texture Classification,2017,"['Texture classification and recognition', 'LBP', 'CLBP', 'SVM', 'Scalable block size']",,"In this paper, we propose an optimized algorithm for texture classification by computing a completed modeling of the local binary pattern (CLBP) instead of the traditional LBP of a scalable block size in an image. First, we show that the CLBP descriptor is a better representative than LBP by extracting more information from an image. Second, the CLBP features of scalable block size of an image has an adaptive capability in representing both gross and detailed features of an image and thus it is suitable for image texture classification. This paper successfully implements a machine learning scheme by applying the CLBP features of a scalable size to the Support Vector Machine (SVM) classifier. The proposed scheme has been evaluated on Outex and CUReT databases, and the evaluation result shows that the proposed approach achieves an improved recognition rate compared to the previous research results."
일반화가속모형을 이용한 기술신용평가 주요 지표 분석,2017,,,"In order to provide technical financial support to small and medium-sized venture companies based on technology, the government implemented the TCB evaluation, which is a kind of technology rating evaluation, from the Kibo and a qualified private TCB. In this paper, we briefly review the current state of TCB evaluation and available indicators related to technology evaluation accumulated in the Korea Credit Information Services (TDB), and then use indicators that have a significant effect on the technology rating score. Multiple regression techniques will be explored. And the relative importance and classification accuracy of the indicators were calculated by applying the key indicators as independent features applied to the generalized boosting model, which is a representative machine learning classifier, as the class influence and the fitness of each model. As a result of the analysis, it was analyzed that the relative importance between the two models was not significantly different. However, GBM model had more weight on the InnoBiz certification, R&D department, patent registration and venture confirmation indicators than regression model."
A Prediction Method for Short-Term Wind Power Generation using Feature Vector Extraction of Wind Direction and Wind Speed in Jeju Island,2017,"['전력발전량예측', '풍향', '풍속', 'K-means clustering', 'SVR', 'SVM', 'Forecasting of Wind Power Generation', 'Wind Direction', 'Wind Speed', 'K-means clustering', 'SVR', 'SVM']",,"In this paper, we propose a wind power forecasting method that takes into consideration wind characteristics to improve the accuracy of wind power prediction. The proposed method involves extracting wind characteristics and predicting power generation. Correlation analysis of power generation amount, wind direction, and wind speed is performed for extracting wind characteristics. Based on the correlation between the wind direction and the wind speed, the feature vector is extracted by clustering using the K-means method. In the prediction part, machine learning is performed using the SVR (support vector regression) that generalizes the SVM (support vector machine) so that an arbitrary real value can be predicted. To verify the accuracy and feasibility of the proposed method, we used the data collected from three different locations of the Jeju Island wind farm. Experimental results show that the error of the proposed method is better than that of existing wind power generation methods."
Extraction of ObjectProperty-UsageMethod Relation from Web Documents,2017,"['Medicinal Property', 'N-Word-Co', 'Semantic Relation', 'Usage-Method']",,"This paper aims to extract an ObjectProperty-UsageMethod relation, in particular the HerbalMedicinalProperty-UsageMethod relation of the herb-plant object, as a semantic relation between two related sets, a herbalmedicinal-property concept set and a usage-method concept set from several web documents. ThisHerbalMedicinalProperty-UsageMethod relation benefits people by providing an alternative treatment/solutionknowledge to health problems. The research includes three main problems: how to determine EDU (whereEDU is an elementary discourse unit or a simple sentence/clause) with a medicinal-property/usage-methodconcept; how to determine the usage-method boundary; and how to determine the HerbalMedicinalProperty-UsageMethod relation between the two related sets. We propose using N-Word-Co on the verb phrase withthe medicinal-property/usage-method concept to solve the first and second problems where the N-Word-Cosize is determined by the learning of maximum entropy, support vector machine, and naïve Bayes. We alsoapply naïve Bayes to solve the third problem of determining the HerbalMedicinalProperty-UsageMethodrelation with N-Word-Co elements as features. The research results can provide high precision in theHerbalMedicinalProperty-UsageMethod relation extraction."
Wine Quality Assessment Using a Decision Tree with the Features Recommended by the Sequential Forward Selection,2017,"['Decision Tree', 'Wine Quality', 'Classification', 'Sequential Forward Selection']",,"Nowadays wine is increasingly enjoyed by a wider range of consumers, and wine certification and quality assessment are key elements in supporting the wine industry to develop new technologies for both wine making and selling processes. There have been many attempts to construct a more methodical approach to the assessment of wines, but most of them rely on objective decision rather than subjective judgement. In this paper, we propose a data mining approach to predict human wine taste preferences that is based on easily available analytical tests at the certification step. We used sequential forward selection and decision tree for this purpose. Experiments with the wine quality dataset from the UC Irvine Machine Learning Repository demonstrate the accuracies of 76.7% and 78.7% for red and white wines respectively."
다중 이미지에서 단일 이미지 검출 및 추적 시스템 구현,2017,"['AR', 'SIFT algorithm', 'ORB algorithm', 'image detection and tracking system', 'KNN algorithm']",,"Augmented Reality(AR) is the core technology of the future knowledge service industry. It is expected to be used in various fields such as medical, education, entertainment etc. Briefly, augmented reality technology is a technique in which a mapped virtual object is augmented when a real-world object is viewed through a device after mapping a real-world object and a virtual object. In this paper, we implemented object detection and tracking system, which is a key technology of augmented reality. To speed up the object tracking, the ORB algorithm, which is a lightweight algorithm compared to the detection algorithm, is applied. In addition, KNN classifier, which is a machine learning algorithm, was applied to detect a single object by learning multiple images."
AI를 통한 글쓰기와 작가의 운명-「コンピュータが小説を書く日」을 중심으로 -,2017,"['인공지능', '소설 창작', '스토리 자동 생성', 'AI', '컴퓨터가 소설을 쓰는 날', 'artificial intelligence', 'creative writing', 'automatic story generation program', 'AI', 'The Day when a Computer Writes a Novel']","이 논문은 컴퓨터 인공지능을 통한 창의적인 글쓰기의 사례 분석을 통해 최근 제기되고 있는 작가의 운명과 존재론에 대한 시론적인 접근을 하고자 한다. 일본 나고야대학교 사토 사토시 교수의 연구실에서 제작한 인공지능이 창작한 소설 「컴퓨터가 소설을 쓰는 날(コンピュータが小説を書 く日)」을 중심으로 이 소설에 사용된 자연어 처리의 알고리즘을 분석하고, 그 소설적 성취를 평가하고자 했다. 「컴퓨터가 소설을 쓰는 날」은 기계 학습을 위해 기존 소설의 문장을 모방하고 치환하거나, 짧은 회화로 이루어진 대화체 소설을 기존 소설의 여러 번을 통해 병치시키는 방법으로 소설을 창작해 왔다. 그러나 이러한 방법론으로 컴퓨터에게 완전히 창의적인소설을 스스로 쓰는 방법을 학습시킬 수는 없었으며, 이는 인공지능을 통한 글쓰기가 가지는 일정한 한계를 보여준다.","This paper attempts to provide a preliminary approach to the fate and ontology of the author, which has recently been raised through a case study of creative writing through computer artificial intelligence.This paper analyzes the algorithm of natural language processing used in the novel “the days when computers write novels”, focusing on this novel created by artificial intelligence produced by Professor Satoshi Sato, professor at Nagoya University. “The Day when a Computer Writes a Novel” has created novels by imitating and replacing sentences of existing novels for machine learning, or by juxtaposing dialogue novels made up of short conversations through several existing novels. However, with this methodology, the computer could not learn how to write a completely creative novel on its own, which shows the limitations of writing through artificial intelligence."
공업계 고등학교 기계과 교사의 직업정체성에 관한 생애사 연구,2017,"['technical high school', 'mechanical education teacher', 'vocational identity', 'teacher identity', 'life history research', '공업계 고등학교', '기계과 교사', '직업정체성', '교사정체성', '생애사']","1970년대 산업화에 의한 숙련기술인력 수요의 급속한 팽창 및 이와 더불어 추진된 숙련기술인력 양성정책에 힘입은 공업교육은 산업변화와 더불어 변화하고, 필요한 인력을 육성하는 가운데 오랜 정체 상태를 벗어나게 되었다. 이후 공업교육은 국가 경제 정책에 종속됨과 이로부터 벗어남을 반복하며, 부침을 거듭해 왔다. 산업화, 정보화, 지식경제화의 영향에 의한 변화의 격랑 가운데 공업고교 교사로 산다는 것은 무엇일까? 지속된 변화의 와중에서 그들은 무엇을 지키고자 하였으며, 어떤 교사가 되고자 하였을까? 이를 탐구하려는 것이 이 연구의 배경이다. 본 연구의 목적은공업계 고등학교 기계과 교사의 생애사 연구를 통해 다음 두 가지 문제를 탐구하는것이다: 기계과 교사로서 겪은 주요한 경험은 무엇인가? 사회와 학교교육 변화의 맥락 속에서 그들의 직업정체성은 어떻게 변화, 형성되었는가? 연구목적을 달성하기위하여 공업계 고등학교 기계과 교사로서 1970년대에 교직에 입문하여 40년 가까이그 자리를 지킨 2인을 연구참여자로 선정하여 심층면담을 실시하였고 이를 녹취하여 분석하였다. 심층면담을 통해 얻은 자료 외에 연구참여자의 인사기록카드, 각종수상기록, 언론기사 등도 분석하였다. 연구 결과 공업계 고교 기계과 교사가 겪은주요한 교육적 경험은 ①자격증 취득을 위한 교육 ②기능반 지도교사 경험 ③공고교육의 혁신 경험 ④새로운 분야에 대한 학습 ⑤공업고등학교의 급격한 위상변화에대한 경험 ⑥실습장을 유지관리, 안전사고 예방 경험 등이었다. 공업계 기계과 교사의 교직 경험에 따른 직업정체성은 ①정체성 표류 ②정체성 안정 ③정체성 전환 ④ 정체성 유보 ⑤정체성 승화 ⑥정체성 통합의 과정을 거치면서 형성되고 발달하였다.","The purpose of this study was to investigate the vocational identity through the reflection of the major experience as the teacher through the life history of the technical high school. In order to achieve the purpose of this study, two technical high school mechanical and career teachers were selected as research participants and in-depth interviews were conducted with them. The data obtained through the in-depth interviews were analyzed through six steps.Six major experiences of the participants were identified as results of the research: ① the experience of trying to train the specialist of precision machining in the beginning of teacher’s life, ② experience as a skill competition team teacher, ③ experience of innovating public education by introducing new industry field, ④ experience of constant learning new field and sharing with colleagues, ⑤ experience in the rapid change of the status of technical high school, ⑥ experience in the prevention of students' safety accidents and maintenance of the practice field.Through these educational experiences, each research participant was forming one’s vocational identity as a mechanical teacher.The vocational identity of the research participants were identified as follows: ① identity drifting phase, ② identity stability stage, ③ transition stage of the teacher role, ④ suspended stage to preserve identity, ⑤ identification sublimation stage, ⑥ identification of the true meaning of the teacher, and integration of the identity.Through these six steps, their identities were formed, strengthened and changed at each stage."
자동분류기반 성격 유형별 도서추천시스템 개발을 위한 실험적 연구,2017,,,"The purpose of this study is to develop an automatic classification system for recommending appropriate books of 9 enneagram personality types, using book information data reviewed by librarians. Data used for this study are book review of 501 recommended titles for children and young adults from National Library for Children and Young Adults. This study is implemented on the assumption that most people prefer different types of books, depending on their preference or personality type. Performance test for two different types of machine learning models, nonlinear kernel and linear kernel, composed of 360 clustering models with 6 different types of index term weighting and feature selections, and 10 feature selection critical mass were experimented. It is appeared that LIBLINEAR has better performance than that of LibSVM(RBF kernel). Although the performance of the developed system in this study is relatively below expectations, and the high level of difficulty in personality type base classification take into consideration, it is meaningful as a result of early stage of the experiment."
음소기반의 순환 신경망 음성 검출기를 이용한 음성 향상,2017,"['RNN', 'GMM', 'Phoneme', 'VAD', 'MMSE']",,
주성분 분석법을 이용한 회귀다항식 기반 모델 및 패턴 분류기 설계,2017,"['Dimension Reduction', 'Feature Extraction', 'Pattern Classification', 'Prediction Model', 'Principal Component Analysis']","본 논문에서는 매우 높은 차원을 가진 데이터에서 의미 있는 특징 벡터 추출하여 입력 공간의 차원을 줄이기 위하여 주성분 분석법을 사용하였다. 주성분 분석법을 이용하여 축소된 차원을 가진 입력 데이터를 이용하여 회귀 다항식의 입력벡터로 사용하는 모델과 패턴 분류기의 설계 방법을 제안하였다. 제안된 모델 및 패턴 분류기는 매우 단순한 구조를 가진 회귀다항식을 기반으로 설계하여 모델 및 패턴 분류기의 과적합 문제를 해결 하고자 하였다. 제안된 설계방법을 적용하여 설계된 모델과 패턴 분류기의 성능을 비교 및 평가하기 위하여, 다양한 기계 학습 데이터 집합을 사용하였다.","The new design methodology of prediction model and pattern classification, which is based on the dimension reduction algorithm called principal component analysis, is introduced in this paper. Principal component analysis is one of dimension reduction techniques which are used to reduce the dimension of the input space and extract some good features from the original input variables. The extracted input variables are applied to the prediction model and pattern classifier as the input variables. The introduced prediction model and pattern classifier are based on the very simple regression which is the key point of the paper. The structural simplicity of the prediction model and pattern classifier leads to reducing the over-fitting problem. In order to validate the proposed prediction model and pattern classifier, several machine learning data sets are used."
ACO-based clustering for Ego Network analysis,2017,"['Social networks analysis', 'Ego Networks', 'Clustering', 'ACO algorithm']",,"<P>The unstoppable growth of Social Networks (SNs), and the huge number of connected users, have become these networks as one of the most popular and successful domains for a large number of research areas. The different possibilities, volume and variety that these SNs offer, has become them an essential tool for every-day working and social relationships. One of the basic features that any SN provides is to allow users to group, organize and classify their connections into different groups, or 'circles'. These circles can be defined using different characteristics as roommates, workmates, hobbies, professional skills, etc. The problem of finding these circles taking into account the variety, volume and dynamics of these SNs has become an important challenge for a wide number of Computer Science areas, as Big Data, Data Mining or Machine Learning among others. Problems related to pre-processing, fusion and knowledge discovering of information from these sources are still an open question. This paper presents a new Bioinspired method, based on Ant Colony Optimization (ACO) algorithms, that has been designed to find and analyze these circles. Given any user in a network, the new method is able to automatically determine the different users that compose his/her groups or circles of interest, so the network will be clustered into different components based on the users profiles and their dynamics. This algorithm has been applied to Ego Networks where the node centering the network (called 'Ego') represents the user being studied. In this work two different ACO algorithms, that differ in the source of information used to perform the community finding tasks, have been designed. The first ACO algorithm uses the information extracted from the topology of the network, whereas the second one uses the profile information provided by users. The proposed algorithms are able to detect the different circles in three popular Social Networks: Facebook, Twitter and Google+. Finally, and using several databases from previous SNs, an experimental evaluation of our methods has been carried out to show how the algorithms are currently working. (C) 2016 Elsevier B.V. All rights reserved.</P>"
저노출 카메라와 웨이블릿 기반 랜덤 포레스트를 이용한 야간 자동차 전조등 및 후미등 인식,2017,"['intelligent headlight control', 'region of interest', 'adaptive thresholding', 'random forest', 'pairing', 'low-exposure camera']",,"In this paper, we propose a novel intelligent headlight control (IHC) system which is durable to various road lights and camera movement caused by vehicle driving. For detecting candidate light blobs, the region of interest (ROI) is decided as front ROI (FROI) and back ROI (BROI) by considering the camera geometry based on perspective range estimation model. Then, light blobs such as headlights, taillights of vehicles, reflection light as well as the surrounding road lighting are segmented using two different adaptive thresholding. From the number of segmented blobs, taillights are first detected using the redness checking and random forest classifier based on Haar-like feature. For the headlight and taillight classification, we use the random forest instead of popular support vector machine or convolutional neural networks for supporting fast learning and testing in real-life applications. Pairing is performed by using the predefined geometric rules, such as vertical coordinate similarity and association check between blobs. The proposed algorithm was successfully applied to various driving sequences in night-time, and the results show that the performance of the proposed algorithms is better than that of recent related works."
Biological function integrated prediction of severe radiographic progression in rheumatoid arthritis: a nested case control study,2017,"['Rheumatoid arthritis', 'Radiographic progression', 'Bioinformatic analysis', 'GWAS', 'Post-GWAS analysis']",,"<P><B>Background</B></P><P>Radiographic progression is reported to be highly heritable in rheumatoid arthritis (RA). However, previous study using genetic loci showed an insufficient accuracy of prediction for radiographic progression. The aim of this study is to identify a biologically relevant prediction model of radiographic progression in patients with RA using a genome-wide association study (GWAS) combined with bioinformatics analysis.</P><P><B>Methods</B></P><P>We obtained genome-wide single nucleotide polymorphism (SNP) data for 374 Korean patients with RA using Illumina HumanOmni2.5Exome-8 arrays. Radiographic progression was measured using the yearly Sharp/van der Heijde modified score rate, and categorized in no or severe progression. Significant SNPs for severe radiographic progression from GWAS were mapped on the functional genes and reprioritized by post-GWAS analysis. For robust prediction of radiographic progression, tenfold cross-validation using a support vector machine (SVM) classifier was conducted. Accuracy was used for selection of optimal SNPs set in the Hanyang Bae RA cohort. The performance of our final model was compared with that of other models based on GWAS results and SPOT (one of the post-GWAS analyses) using receiver operating characteristic (ROC) curves. The reliability of our model was confirmed using GWAS data of Caucasian patients with RA.</P><P><B>Results</B></P><P>A total of 36,091 significant SNPs with a <I>p</I> value <0.05 from GWAS were reprioritized using post-GWAS analysis and approximately 2700 were identified as SNPs related to RA biological features. The best average accuracy of ten groups was 0.6015 with 85 SNPs, and this increased to 0.7481 when combined with clinical information. In comparisons of the performance of the model, the 0.7872 area under the curve (AUC) in our model was superior to that obtained with GWAS (AUC 0.6586, <I>p</I> value 8.97 × 10<SUP>-5</SUP>) or SPOT (AUC 0.7449, <I>p</I> value 0.0423). Our model strategy also showed superior prediction accuracy in Caucasian patients with RA compared with GWAS (<I>p</I> value 0.0049) and SPOT (<I>p</I> value 0.0151).</P><P><B>Conclusions</B></P><P>Using various biological functions of SNPs and repeated machine learning, our model could predict severe radiographic progression relevantly and robustly in patients with RA compared with models using only GWAS results or other post-GWAS tools.</P><P><B>Electronic supplementary material</B></P><P>The online version of this article (doi:10.1186/s13075-017-1414-x) contains supplementary material, which is available to authorized users.</P>"
Transport modelling in the age of big data,2017,,,"New Big Data sources such as mobile phone call data records, smart card data and geo-coded social media records allow to observe and understand mobility behaviour on an unprecedented level of detail. Despite the availability of such new Big Data sources, transport demand models used in planning practice still, almost exclusively, are based on conventional data such as travel diary surveys and population census. This literature review brings together recent advances in harnessing Big Data sources to understand travel behaviour and inform travel demand models that allow transport planners to compute what-if scenarios. From trip identification to activity inference, we review and analyse the existing data-mining methods that enable these opportunistically collected mobility traces inform transport demand models. We identify that future research should tap on the potential of probabilistic models and machine learning techniques as commonly used in data science. Those data-mining approaches are designed to handle the uncertainty of sparse and noisy data as it is the case for mobility traces derived from mobile phone data. In addition, they are suitable to integrate different related data sets in a data fusion scheme so as to enrich Big Data with information from travel diaries. In any case, we also acknowledge that sophisticated modelling knowledge has developed in the domain of transport planning and therefore we strongly advise that still, domain expert knowledge should build the fundament when applying data-driven approaches in transport planning. These new challenges call for a multidisciplinary collaboration between transport modellers and data scientists."
Downscaling of MODIS Land Surface Temperature to LANDSAT Scale Using Multi-layer Perceptron,2017,"['Downscaling', 'Land Surface Temperature', 'Multi-layer Perceptron', 'Random Forest', 'Landsat', 'MODIS']",,"Land surface temperature is essential for monitoring abnormal climate phenomena such as UHI (Urban Heat Islands), and for modeling weather patterns. However, the quality of surface temperature obtained from the optical space imagery is affected by many factors such as, revisit period of the satellite, instance of capture, spatial resolution, and cloud coverage.Landsat 8 imagery, often used to obtain surface temperatures, has a high resolution of 30 meters (100 meters rearranged to 30 meters) and a revisit frequency of 16 days. On the contrary, MODIS imagery can be acquired daily with a spatial resolution of about 1 kilometer. Many past attempts have been made using both Landsat and MODIS imagery to complement each other to produce an imagery of improved temporal and spatial resolution. This paper applied machine learning methods and performed downscaling which can obtain daily based land surface temperature imagery of 30 meters."
RBFNNs 기반 소프트맥스 패턴분류기를 이용한 포즈변화에 강인한 얼굴인식 시스템 설계,2017,"['Face Recognition', 'Pose Classification', '(2D)2PCA', 'Softmax Fucntion', 'FCM Clustering', '얼굴인식', '포즈분류', '(2D)2PCA', '소프트맥스 함수', 'FCM 클러스터링']","본 연구는 포즈변화에 따른 얼굴인식을 수행하기 위해 FCM 클러스터링 RBFNNs기반 소프트맥스 패턴분류기가 제안된다.기존의 RBFNNs 패턴분류기의 출력층에 소프트맥스 활성함수를 사용하여 패턴 분류기의 출력을 확률 값으로 표현한다.얼굴인식을 위한 포즈는 다양한 환경에서의 인식을 위해 다중 포즈영역을 통해 포즈를 추정하고 이를 기반으로 얼굴인식을수행한다. 다양한 포즈 변화에서 포즈를 식별하기 위해 Cambridge ICPR DB의 데이터를 사용하여 15명의 얼굴 이미지를정면이 포함된 3개의 포즈(오른쪽, 정면, 왼쪽)로 구성된다. 또한 PCA 와 (2D)2PCA을 사용하였다. 결과적으로 전처리 기반포즈추정 단계, 그리고 전처리 기반 얼굴인식의 단계의 순차적인 두 단계를 통해 전체 얼굴인식을 수행하게 된다. 패턴분류기의 성능평가를 위하여 Cambridge ICPR 데이터와 머신러닝 데이터를 사용하여 FCM기반 RBFNNs 패턴분류기와 성능을비교분석 하였다.","In this study, a softmax pattern classifier based on FCM clustering RBFNNs is proposed for face recognition with pose variation.The output of the pattern classifier is expressed as a probability value by using the softmax activation function in the output layer of the existing RBFNNs pattern classifier. Pose for face recognition is estimated through multiple pose area for recognition in various environments and then face recognition is carried out based on pose estimation. In order to identify the poses obtained though various pose variations, the data of Cambridge ICPR DB is used and 42 face images per person are totally constructed by 3 other poses(right, front, and left) per person including the front face. (2D)2PCA as well as PCA are used. As a result, the whole face recognition is performed through two sequential steps of the preprocessing based pose estimation step and the preprocessing based face recognition step. For the performance evaluation of the pattern classifier, the results of the FCM - based RBFNNs pattern classifier using Cambridge ICPR data and machine learning data."
『항한필휴(航韓必携)』에 보이는 제1차 수신사의 모습,2017,"['수신사(修信使)', '『항한필휴(航韓必携)』', '김기수(金綺秀)', '박영선(朴英善)', '김용원(金鏞元)', '『일동기유(日東記遊)』', '『창사기행(滄?紀行)』', 'Susinsa', 'Koukanhitsukei', 'Kim Ki-su', 'Park Young-sun', 'Kim Yong-won', 'Ildonggiyu', 'Changsagihaeng']",,"Upon the Chosun-Japan Treaty of 1876, the first Susinsa of Chosun recovered the rupture of diplomatic relations between Chosun and Japan for 60 years and experienced the new modern civilization as a national delegation. The studies of Susinsa have been conducted mainly on the basis of Ildonggiyu, the official history written by Kim Ki-su. Although Changsagihaeng and recent translation of Japanese materials improved the accessibility to the references, related researches are still lacking. To broaden our horizons for the research of Susinsa, therefore, we investigated the Koukanhitsukei which contains most of data from the Japanese Ministry of Foreign Affairs.  The Koukanhitsukei consists of 18 books and were published by Sakada Morodo of the Japanese ministry of foreign affairs to assist Miyamoto Kouichi for his task in Chosun after return of Susinsa. In these references, not only fragmentary events such as participating in magic banquet and physician’s visiting from Juntendo for a sick envoy member, but also detailed stories such as the painter Kim Yong-won’s purchase of machines and chemicals (zinc and hydrochloric acid) and Park Young-sun’s learning of vaccination from Juntendo were contained, which were not included in the record of diplomatic journey of Chosun. Such a positive attitude toward modern civilization has been hard to find in the records by Kim Ki-su or his personal assistant Ahn Gwang-mook.  We can also figure out the Japanese viewpoint on the Susinsa by Koukanhitsukei. Japanese in the meiji era had an antipathy to the arrogant attitude of Chosun’s Tongsinsa and attempted to impair the relation between two countries. They regarded Chosun as an uncivilized country clinging to old customs and had a perception that they must civilize people of Chosun. Consequently, though there was no practical outcomes, they tried to let the first Susinsa enlarge the knowledge about multiple government organizations, and the products of civilization."
단어 의미와 자질 거울 모델을 이용한 단어 임베딩,2017,"['단어 임베딩', '단어 표현', '어휘의미망', '의미관계', '국어사전', '단어의미', '자질거울모델', 'word embedding', 'word representation', 'lexical semantic network', 'sematic relation', 'dictionary', 'word sense', 'feature mirror model']","단어 표현은 기계학습을 사용하는 자연어 처리 분야에서 중요하다. 단어 표현은 단어를 텍스트가 아닌 컴퓨터가 분별할 수 있는 심볼로 표현하는 방법이다. 기존 단어 임베딩은 대량의 말뭉치를 이용하여 문장에서 학습할 단어의 주변 단어를 이용하여 학습한다. 하지만 말뭉치 기반의 단어 임베딩은 단어의 등장 빈도수나 학습할 단어의 수를 늘리기 위해서는 많은 양의 말뭉치를 필요로 한다. 본 논문에서는 말뭉치 기반이 아닌 단어의 뜻풀이와 단어의 의미 관계(상위어, 반의어)를 이용하며 기존 Word2Vec의 Skip-Gram을 변형한 자질거울모델을 사용하여 단어를 벡터로 표현하는 방법을 제시한다. 기존 Word2Vec에 비해 적은 데이터로 많은 단어들을 벡터로 표현 가능하였으며 의미적으로 유사한 단어들이 비슷한 벡터를 형성하는 것을 확인할 수 있다. 그리고 반의어 관계에 있는 두 단어의 벡터가 구분되는 것을 확인할 수 있다.","Word representation, an important area in natural language processing(NLP) used machine learning, is a method that represents a word not by text but by distinguishable symbol. Existing word embedding employed a large number of corpora to ensure that words are positioned nearby within text. However corpus-based word embedding needs several corpora because of the frequency of word occurrence and increased number of words. In this paper word embedding is done using dictionary definitions and semantic relationship information(hypernyms and antonyms). Words are trained using the feature mirror model(FMM), a modified Skip-Gram(Word2Vec). Sense similar words have similar vector. Furthermore, it was possible to distinguish vectors of antonym words."
심박 정보 기반 위치 정보 융합형 감정 추론 어플리케이션 개발,2017,"['웨어러블 디바이스', '위치 정보', '심박 정보', '감정 추론', '개인화 서비스', '정보 융합', 'Wearable device', 'Location Information', 'Heartbeat rate Information', 'Emotion Inference', 'Personal Service', 'Information Convergence']","최근 웨어러블 디바이스를 통한 다양한 개인 정보를 수집하고 이를 활용하는 분야가 활성화되고 있다. 본 논문에서는 스마트폰과 함께 일상 생활에서 착용하여 사용이 용이한 웨어러블 디바이스인 스마트워치를 통하여 심박 정보를 수집하고, 이를 위치 정보와 결합한 분석을 토대로 해당 위치에서의 감정 맞춤형 장소 추천이 가능한 어플리케이션을 개발한다. 이는 감정 추론 결과에 위치 정보를 추가함으로써 개인화서비스 제공 분야의 활용도를 높일 수 있으며, 부가적인 장치가 필요 없이 단지 스마트폰의 어플리케이션과 스마트워치의 사용으로 정보 수집과 분석이 이루어지므로 다양한 맞춤형 서비스 제공에 용이하게 활용될 수 있다.","The personal activity information is expanding as a way to utilize wearable devices that are emerging as next generation smart devices. This paper develops an application for collecting heartbeat rate and location information of a user using SmartWatch, which is a smartphone and wearable device, and analyzing it through machine learning to infer user's emotion information. By using smart phone and smart watch, developed application can collect biometric data and location information by simply executing application and doing everyday life. In addition, adding the location information to the hearbit rate data, it proves higher utilization than existing ones."
An evolutionary system for the prediction of high performance concrete strength based on semantic genetic programming,2017,"['high performance concrete', 'concrete strength', 'genetic programming', 'local search', 'semantics']",,"High-performance concrete, besides aggregate, cement, and water, incorporates supplementary cementitious materials, such as fly ash and blast furnace slag, and chemical admixture, such as superplasticizer. Hence, it is a highly complex material and modeling its behavior represents a difficult task. This paper presents an evolutionary system for the prediction of high performance concrete strength. The proposed framework blends a recently developed version of genetic programming with a local search method. The resulting system enables us to build a model that produces an accurate estimation of the considered parameter.Experimental results show the suitability of the proposed system for the prediction of concrete strength. The proposed method produces a lower error with respect to the state-of-the art technique. The paper provides two contributions: from the point of view of the high performance concrete strength prediction, a system able to outperform existing state-of-the-art techniques is defined; from the machine learning perspective, this case study shows that including a local searcher in the geometric semantic genetic programming system can speed up the convergence of the search process."
Extraction of ObjectProperty-UsageMethod Relation from Web Documents,2017,"['Medicinal Property', 'N-Word-Co', 'Semantic Relation', 'Usage-Method']",,"This paper aims to extract an ObjectProperty-UsageMethod relation, in particular the HerbalMedicinalProperty-UsageMethod relation of the herb-plant object, as a semantic relation between two related sets, a herbal-medicinal-property concept set and a usage-method concept set from several web documents. This HerbalMedicinalProperty-UsageMethod relation benefits people by providing an alternative treatment/solution knowledge to health problems. The research includes three main problems: how to determine EDU (where EDU is an elementary discourse unit or a simple sentence/clause) with a medicinal-property/usage-method concept; how to determine the usage-method boundary; and how to determine the HerbalMedicinalProperty-UsageMethod relation between the two related sets. We propose using N-Word-Co on the verb phrase with the medicinal-property/usage-method concept to solve the first and second problems where the N-Word-Co size is determined by the learning of maximum entropy, support vector machine, and naïve Bayes. We also apply naïve Bayes to solve the third problem of determining the HerbalMedicinalProperty-UsageMethod relation with N-Word-Co elements as features. The research results can provide high precision in the HerbalMedicinalProperty-UsageMethod relation extraction."
Relay Selection in Cooperative Power Line Communication: A Multi-Armed Bandit Approach,2017,"['Cooperative communication', 'multi-armed bandit', 'power line communication (PLC)', 'relay selection.']",,"Power line communication (PLC) exploits the existence ofinstalled infrastructure of power delivery system, in order to trans-mit data over power lines. In PLC networks, different nodes of thenetwork are interconnected via power delivery transmission lines,and the data signal is flowing between them. However, the attenu-ation and the harsh environment of the power line communicationchannels, makes it difficult to establish a reliable communicationbetween two nodes of the network which are separated by a longdistance. Relaying and cooperative communication has been usedto overcome this problem. In this paper a two-hop cooperative PLChas been studied, where the data is communicated between a trans-mitter and a receiver node, through a single array node which hasto be selected from a set of available arrays. The relay selectionproblemcan be solved by having channel state information (CSI) attransmitter and selecting the relay which results in the best perfor-mance. However, acquiring the channel state information at trans-mitter increases the complexity of the communication system andintroduces undesired overhead to the system. We propose a classof machine learning schemes, namely multi-armed bandit (MAB),to solve the relay selection problem without the knowledge of thechannel at the transmitter. Furthermore, we develop a new MABalgorithm which exploits the periodicity of the synchronous impul-sive noise of the PLC channel, in order to improve the relay selec-tion algorithm."
대기경계층 고도 산출을 위한 인공신경망기법 적용,2017,"['인공신경망', '잡음제거 오토인코더', '대기경계층 고도', '운고계', '후방산란자료', 'Artificial Neural Network', 'Ceilometer', 'Denoising Autoencoder', 'Planetary Boundary Layer Height', 'Back-Scattered Data']","대기경계층 고도(Planetary Boundary Layer, Height PBLH)는 기상과 대기확산을 예측하는데 매우 중요한 인자이다. PBLH를 결정하기 위해 여러 관측 자료들이 사용되고 있으며, 그 중 라이다식 운고계를 이용한 방법이 최근에 많이 사용되고 있다. 운고계에서 PBLH를 추정하기 위해 사용하는 경도법(Gradient method)은 매우 간단하지만 여러 잡음으로 인해 고도를 잘못 추정하는 경우가 발생한다. 본 논문에서는 라이더식 운고계에서 수집한 후방산란자료에 기계학습기법을 적용하여 PBLH를 산출하는 방법을 제안한다. 제안한 방법은 잡음제거 오토인코더(Denoising autoencoder)를 이용하여 비지도 학습으로 운고계 후방산란자료의 잡음소거를 수행한 뒤 인공신경망(Artificial Neural Network, ANN) 학습을 통해 PBLH를 산출한다. 실험에는 보성지역에 설치된 라이더식 운고계 CL51에서 관측된 2015년 1월부터 2016년 5월까지의 후방산란자료를 사용하였으며, 검증을 위해 운고계 CL51의 PBLH 산출 프로그램 BL-view의 자료와 경도법으로 산출된 PBLH 자료를 사용하였다. 실험결과 제안한 방법이 경도법보다 2배 이상 좋은 성능을 보였다.","The planatery boundary layer height(PBLH) is very important factor in determining weahter and atmospheric diffusion. As a method to determine the PBLH, there is a method to use observation data. Among them, a ceilometer-based method is recently used with good performance. The gradient method which is used to estimate the PBLH in ceilometer is very simple, but the height may be incorrect due to noise. In this paper, we proposed new methodo testimate the PBLH by applying machine learning to back-scattere d data collected from ceilometer. The proposed method uses denoising autoencoder to eliminate noise of back-scattered data, and then estimates the PBLH through artificial neural network. We collected back-scattered data from January 2015 to May 2016, which were observed by ceilometer CL51, installed in Boseong, Korea. For the verification, PBLH data from the PBLH estimation program BL-view of CL51 and estimated by using the gradient method is used. Experimental results show that the proposed method has more than twice better performance than the gradient method."
인공 신경망 기반의 고시간 해상도를 갖는 전력수요 예측기법,2017,"['에너지 관리 시스템', '스마트 그리드', '전력수요 예측', '인공 신경망']","최근 스마트 그리드 산업의 발달과 더불어 효과적인 에너지 관리 시스템의 필요성이 커지고 있다. 특히, 전기 부하 및 에너지 요금 감소를 위해서는 정확한 전력수요 예측과 그에 따른 효과적인 스마트 그리드 운영 전략이 필요하다. 본 논문에서는 보다 정확한 전력수요 예측을 위하여, 수요 시한 기준으로 수집된 전력 사용 데이터를 고시간 해상도로 분할하고, 이에 적합한 인공 신경망 기반의 전력수요 예측 모델을 구축하고자 한다. 예측 모델의 정확도를 향상시키기 위하여 우선, 수열 형태의 시계열 데이터가 가지는 주기성을 제대로 반영하지 못하는 기계 학습 모델의 문제점을 해결하고자, 시계열 데이터를 2차원 공간의 연속적인 데이터로 변환한다. 더욱이, 고시간 해상도에 따른 온도나 습도 등 외부 요인들의 보다 정확한 반영을 위해 이들에 대해서도 선형 보간법을 사용하여 세분화된 시점에서의 값을 추정하여 반영한다. 마지막으로, 구성된 특성 벡터에 대해 주성분 분석 수행을 통하여 불필요한 외부 요인을 제거한다. 예측 모델의 성능을 평가하기 위해서 5겹 교차 검증을 수행하였다. 실험 결과 모든 고시간 해상도에서 성능 향상을 보였으며, 특히 3분 해상도의 경우 3.71%의 가장 낮은 오차율을 보였다.","With the recent development of smart grid industry, the necessity for efficient EMS(Energy Management System) has been increased. In particular, in order to reduce electric load and energy cost, sophisticated electric load forecasting and efficient smart grid operation strategy are required. In this paper, for more accurate electric load forecasting, we extend the data collected at demand time into high time resolution and construct an artificial neural network-based forecasting model appropriate for the high time resolution data. Furthermore, to improve the accuracy of electric load forecasting, time series data of sequence form are transformed into continuous data of two-dimensional space to solve that problem that machine learning methods cannot reflect the periodicity of time series data. In addition, to consider external factors such as temperature and humidity in accordance with the time resolution, we estimate their value at the time resolution using linear interpolation method. Finally, we apply the PCA(Principal Component Analysis) algorithm to the feature vector composed of external factors to remove data which have little correlation with the power data. Finally, we perform the evaluation of our model through 5-fold cross-validation. The results show that forecasting based on higher time resolution improve the accuracy and the best error rate of 3.71% was achieved at the 3-min resolution."
"Design, Development and Testing of the Modular Unmanned Surface Vehicle Platform for Marine Waste Detection",2017,"['control system', 'mobile robotics', 'marine waste detection', 'unmanned surface vehicle']",,"Mobile robots are used for years as a valuable research and educational tool in form of available open-platform designs and Do-It-Yourself kits. Rapid development and costs reduction of Unmanned Air Vehicles (UAV) and ground based mobile robots in recent years allowed researchers to utilize them as an affordable research platform. Despite of recent developments in the area of ground and airborne robotics, only few examples of Unmanned Surface Vehicle (USV) platforms targeted for research purposes can be found. Aim of this paper is to present the development of open-design USV drone with integrated multi-level control hardware architecture. Proposed catamaran - type water surface drone enables direct control over wireless radio link, separate development of algorithms for optimal propulsion control, navigation and communication with the ground-based control station. Whole design is highly modular, where each component can be replaced or modified according to desired task, payload or environmental conditions. Developed USV is planned to be utilized as a part of the system for detection and identification of marine and lake waste. Cameras mounted to the USV would record sea or lake surfaces, and recorded video sequences and images would be processed by state-of-the-art computer vision and machine learning algorithms in order to identify and classify marine and lake waste."
Combined Artificial Bee Colony for Data Clustering,2017,"['Data Clustering', 'Combined Artificial Bee Colony (CABC)', 'K-means']",,"Data clustering is one of the most difficult and challenging problems and can be formally considered as a particular kind of NP-hard grouping problems. The K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, it has high possibility to trap in local optimum and high variation of solutions with different initials for the large data set. Therefore, we need study efficient computational intelligence method to find the global optimal solution in data clustering problem within limited computational time. The objective of this paper is to propose a combined artificial bee colony (CABC) with K-means for initialization and finalization to find optimal solution that is effective on data clustering optimization problem. The artificial bee colony (ABC) is an algorithm motivated by the intelligent behavior exhibited by honeybees when searching for food. The performance of ABC is better than or similar to other population-based algorithms with the added advantage of employing fewer control parameters. Our proposed CABC method is able to provide near optimal solution within reasonable time to balance the converged and diversified searches. In this paper, the experiment and analysis of clustering problems demonstrate that CABC is a competitive approach comparing to previous partitioning approaches in satisfactory results with respect to solution quality. We validate the performance of CABC using Iris, Wine, Glass, Vowel, and Cloud UCI machine learning repository datasets comparing to previous studies by experiment and analysis. Our proposed KABCK (K-means+ABC+K-means) is better than ABCK (ABC+K-means), KABC (K-means+ABC), ABC, and K-means in our simulations."
"초기 영화 속 속도의 테크놀로지, 그리고 기술 문명의 표상",2017,"['초기 영화', '속도', '테크놀로지', '문명', '표상', 'Early Cinema', 'Speed', 'Technology', 'Civilization', 'Representation']","본 논문에서는 초기 영화 속 다양한 ‘속도 기계’들이 과학기술을 기반으로 한 근대 문명을 어떻게 표상하고 있는지에 관해 탐구하였다. 이를 위해 19세기 말에서 20세기 초까지의 기술적 전환기에 속도-시각 테크놀로지 발달로 인해 파급된 가속화 현상과 시계(視界)의 확장, 공간 분화의 양상을 분석하였다. 또한, 이러한 과정을 통해 테크놀로지에 대한 인간의 시선과 태도, 테크놀로지와 사회 구조의 관계, 테크놀로지를 둘러싼 세계 공영의 문제 등을 고찰하였다. 그리하여, 속도테크놀로지에 관한 당시 사람들의 양가적 관점과 감정, 경험과 상상 등을 다음과 같이 크게 세 가지 차원에서 도출하였다. 첫째, 자동차 경주를 촬영한 기록영화 또는 자동차의 폭발이나 통제 불능 상태를 다룬 트릭영화에는 가속화에 대한 인간의 욕망과 불안이 반영되어 있다. 둘째, 보는 이로 하여금 새로운 시각적 경험을 선사하는 여러 종류의 ‘기차 영화’에는 서구 사회의 근대적 발전상과 함께 노동-계급 문제로 점철된 어두운 이면이 노출되어 있다. 셋째, 차별적이고도 위계적인 공간 분화 경향을 보이는 풍경 영화, 여행 영화, 보도 영화, <달세계 여행>로 대표되는 초기 극영화 등에는 자본주의, 내셔널리즘, 제국주의 등에 의한 인류 공존의 왜곡된 모습이 내재되어 있다. 이를 바탕으로, 자동차, 기차, 우주선 등 근대적 속도 장치들에 대한 인간의 인식과 태도, 심리적 반응 등을 통해서는 인간과 기계와의 관계를, 도로와 철로, 도시의 구조 등을 통해서는 인간과 인간의 관계를, 세계 각지 및 우주 공간 등을 통해서는 인간과 타자의 관계를 파악할 수 있다.","This paper aims to reveal that how numerous speed-machines in early cinema represented modern civilization which was a scientific technology-based world. It focuses on the aspects of acceleration phenomenon, expansion of visibility, and spatial differentiation through development of speed-visual technology at technological turn from the late 19th century to the early 20th century. With these aspects, I researched remarkable aspects between human and technology: human perception and attitude towards technology, a relationship between technology and social structure, a coexistence issue. As a result, I found three aspects of contemporary people at this period; they have ambivalent perspective, experience and imagination for speed technology. First, documentary films shooting car race and trick films showing cars exploded or out of control reflected people’s desire and anxiety about acceleration by technology. Second, various kinds of ‘Train Films’ which gave a new visual experience to the audience revealed dark side of problems related with labor-class which was raised in modern western society. Third, coexistence between human and technology distorted by Capitalism, Nationalism, and Imperialism were inherent in landscapes films, travel films, newsreel films and early fiction films like showing spatial differentiation with hierarchy. Based on this research, we can learn a relationship between human and machines through people’s recognition, attitude and psychological response towards modern speed-machines such as cars, trains, and spaceships. Also, we can find a relationship between humans through roads, railways, and city structures and a relationship between human and the Other through world or space."
센서 데이터를 위한 스마트 통합 처리 시스템 연구,2017,"['센서데이타', '사물인터넷', 'MTConnect', '자율컴퓨팅', '아두이노', 'Sensor Data', 'IoT', 'MTConnect', 'Autonomic Computing', 'Arduino']","본 논문은 센서 데이터를 수집하고 효과적으로 처리하는 IoT 서비스를 위한 스마트 센서 데이터 통합 처리 시스템을 소개한다. IoT 분야의 발전으로 센서 데이터를 수집하고 이를 네트워크로 송•수신하는 기술을 바탕으로 하는 스마트 홈, 자율주행 자동차 등의 다양한 프로젝트가 진행됨에 따라 센서 데이터를 처리하고 효과적으로 활용하기 위한 자율제어 시스템이 이슈가 되고 있다. 그러나 자율제어 시스템의 모니터링을 위한 센서 데이터 형식은 도메인에 따라 다르기 때문에 각기 다른 다양한 도메인에 자율제어 시스템을 적용하는 스마트 센서 데이터 통합 처리 시스템이 필요하다. 따라서 본 논문은 스마트 센서 데이터 통합 처리 시스템을 소개하고, 이를 적용시켜 창문을 기준으로 내부와 외부의 센서 데이터를 처리하기 위해 1) receiveData, 2) parseData, 3) addToDatabase의 3단계 프로세스를 가지고, 자율제어 시스템에 의하여 쾌적한 실내 환경을 조성하기 위해 환기를 하는 자동 창문 개폐 시스템 ‘Smart Window’를 제안하고 구현한다. 이를 통해 대기 정보를 수집해 모니터링하며, 저장된 데이터를 토대로 통계 분석 및 더 나은 자율제어 수행을 위한 기계학습을 가능하게 한다.","In this paper, we introduce an integrated processing system of smart sensor data for IoT service which collects sensor data and efficiently processes it. Based on the technology of collecting sensor data to the development of the IoT field and sending it to the network · Based on the receiving technology, as various projects such as smart homes, autonomous running vehicles progress, the sensor data is processed and effectively An autonomous control system to utilize has been a problem. However, since the data type of the sensor for monitoring the autonomous control system varies according to the domain, a sensor data integration processing system applying the autonomous control system to various different domains is necessary. Therefore, in this paper, we introduce the Smart Sensor Data Integrated Processing System, apply it and use the window as a reference to process internal and external sensor data 1) receiveData, 2) parseData, 3) addToDatabase 3 With the process of the stage, we provide and implement the automatic window opening / closing system ""Smart Window"" which ventilates to create a comfortable indoor environment by autonomous control system. As a result, standby information is collected and monitored, and machine learning for performing statistical analysis and better autonomous control based on the stored data is made possible."
융합 인공벌군집 데이터 클러스터링 방법,2017,"['Data Clustering', 'Combined Artificial Bee Colony (CABC)', 'K-means']",,"Data clustering is one of the most difficult and challenging problems and can be formally considered as a particular kind of NP-hard grouping problems. The K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, it has high possibility to trap in local optimum and high variation of solutions with different initials for the large data set. Therefore, we need study efficient computational intelligence method to find the global optimal solution in data clustering problem within limited computational time. The objective of this paper is to propose a combined artificial bee colony (CABC) with K-means for initialization and finalization to find optimal solution that is effective on data clustering optimization problem. The artificial bee colony (ABC) is an algorithm motivated by the intelligent behavior exhibited by honeybees when searching for food. The performance of ABC is better than or similar to other population-based algorithms with the added advantage of employing fewer control parameters. Our proposed CABC method is able to provide near optimal solution within reasonable time to balance the converged and diversified searches. In this paper, the experiment and analysis of clustering problems demonstrate that CABC is a competitive approach comparing to previous partitioning approaches in satisfactory results with respect to solution quality. We validate the performance of CABC using Iris, Wine, Glass, Vowel, and Cloud UCI machine learning repository datasets comparing to previous studies by experiment and analysis. Our proposed KABCK (K-means+ABC+K-means) is better than ABCK (ABC+K-means), KABC (K-means+ABC), ABC, and K-means in our simulations."
국내 TV광고에 표현된 로봇 캐릭터의 역할 유형과 상징적 의미에 관한 연구,2017,"['로봇', '캐릭터', '행동 영역', '역할 유형', 'robot', 'character']","로봇은 4차 산업혁명을 이끌어가는 핵심 화두 중 하나로, 다양한 산업분야는 물론이고 일상생활에까지 영향을 끼치고 있다. 소설·영화·애니메이션 등 미디어로만 접하던 로봇 시대는 미래의 이슈가 아닌 현실이 되었다. 로봇 공학의 발달은 로봇의 모습을 인간에 가깝도록 진화시켜 왔다. 이제 그들은 인간처럼 사고하거나 학습하기도 하고, 인간과 유사한 외형을 갖추고 표정과 행동으로 감정을 드러내기도 한다. 로봇은 기계 이상의 존재가 되었고 이는 곧 하나의 캐릭터로 기능할 수 있음을 의미한다. 본 연구는 국내 TV광고에 표현된 로봇 캐릭터들의 행동 영역을 분석하여 역할 유형을 도출하고 이를 통하여 로봇 캐릭터의 상징적 의미를 파악하는 데에 목적이 있다. 이를 위한 연구방법으로 블라디미르 프로프(Vladimir Propp)의 『민담형태론(Morphology of the Folktale)』을 통하여 정립한 등장인물의 7가지 행동 영역과 역할 유형에 근거하여 로봇 캐릭터를 분석하였으며, 그 결과를 바탕으로 상징적 의미를 파악하고자 하였다. 연구 결과, 국내 TV광고의 로봇 캐릭터는 ‘적(villain)형’, ‘증여자(donor)형’, ‘조력자(helper)형’, ‘파견자(dispatcher)형’ ‘주인공(hero)형’, ‘가짜 주인공(false hero)형’으로 총 6가지 유형으로 도출되었다. 또한 광고적 상징을 파악한 결과, 적·파견자·가짜 주인공은 경쟁사를, 증여자·조력자·주인공은 자사를 상징함을 알 수 있었다. 본 연구는 국내 TV광고에 표현된 로봇 캐릭터의 역할 유형을 정리하고 상징적 의미를 도출하였으며, 향후 TV광고를 포함한 다양한 미디어에 표현될 로봇 캐릭터의 역할과 상징성에 대한 연구의 기초를 제공하고자 하였다. 이러한 연구는 로봇 캐릭터를 사회 문화적 관점으로 연구함으로써 향후 미디어 콘텐츠의 질적 향상을 위한 과제를 제시하는데에 의의가 있다.","Robots are on of the key issues that lead the 4th industrial revolution, affecting various industries as well as everyday life. The robot era, which was only seen through media such as novels, movies, and animations, is no longer an issue of future and has become a reality. The development of robotics has evolved robots to be similar to humans. Not only robots think and learn but express their emotions through face expressions and actions as humans do. Robots have become more than machines, which means they can function as a single character. The purpose of this study is to analyze the behavior of robot characters represented in domestic TV commercials, to derive role types and to understand the symbolic meaning of robot characters. This study analyzed the robot character based on seven behavioral areas and role types set through ‘Morphology of a fairy-tale’, which is established by Vladimir Propp and suggested the symbolic meanings based on the result. As a result of the study, the robot characters of domestic TV commercials were derived from 6 types, namely, ‘villain’, ‘donor’, ‘helper’, ‘dispatcher’, ‘hero’, and ‘false hero’. As a result of identifying the symbolic meaning in terms of advertisement, the ‘villain’, ‘dispatcher’, and ‘false hero’ symbolized the competitor, whereas the ‘donor’, ‘helper’, and ‘hero’ symbolized the company. This study summarizes the role types of robot characters represented in domestic TV commercials and suggests the role and symbolism of robot characters to be expressed in various media including TV commercials in the future. This research has significance to suggest future tasks for improving quality of media contents by studying robot character from sociocultural perspective."
Non-magnetic compliant finger sensor for continuous fine motor movement detection,2017,['MEG compatible Somatotopy Sensorimotor Force regressed contrast Real-time motion data'],,"A non-magnetic MEG compatible device hasbeen developed that provides continuous force and velocityinformation. Combined with MEG, this device may findutility in characterizing brain regions associated with forceand velocity relative to individual digits or movementpattern. 15 healthy right-handed participants were givenvisual cues to perform random finger movements on theprototype finger sensor for 21 s and then rest for 21 s (7times). Respective finger flexion data were obtained, during151-channel MEG brain scanning, by feeding the signalfrom finger sensor into four input Analog to Digital Converter(ADC) channels in the MEG hardware. The sourceactivity was reconstructed in beta band using a LinearlyConstrained Minimum Variance (LCMV) beamformer inthe beta band. The ADC channels were used as regressorsfor a continuous time General Linear Model (GLM) and aRegion of Interest (ROI) was identified to examine activity.MEG analysis showed bilateral activation in the primarymotor cortex region. Because individual digits could beisolated in the ADC data, somatotopy of the fingers wereobserved consistent with the homunculus except pinkyfinger. The total span was calculated to be 5.5662 mm. Thestudy confirms that the finger sensor is magneticallycompatible with MEG measurements and may potentiallyprovide a means to study complex sensorimotor functions.Improved isolation of individual digit information alongwith the use of machine learning algorithms can helpretrieve more accurate results."
데이터 클러스터링을 위한 혼합 시뮬레이티드 어닐링,2017,"['Data Clustering', 'Hybrid Simulated Annealing', 'K-means']",,"Data clustering determines a group of patterns using similarity measure in a dataset and is one of the most important and difficult technique in data mining. Clustering can be formally considered as a particular kind of NP-hard grouping problem. K-means algorithm which is popular and efficient, is sensitive for initialization and has the possibility to be stuck in local optimum because of hill climbing clustering method. This method is also not computationally feasible in practice, especially for large datasets and large number of clusters. Therefore, we need a robust and efficient clustering algorithm to find the global optimum (not local optimum) especially when much data is collected from many IoT (Internet of Things) devices in these days. The objective of this paper is to propose new Hybrid Simulated Annealing (HSA) which is combined simulated annealing with K-means for non-hierarchical clustering of big data. Simulated annealing (SA) is useful for diversified search in large search space and K-means is useful for converged search in predetermined search space. Our proposed method can balance the intensification and diversification to find the global optimal solution in big data clustering. The performance of HSA is validated using Iris, Wine, Glass, and Vowel UCI machine learning repository datasets comparing to previous studies by experiment and analysis. Our proposed KSAK (K-means+SA+K-means) and SAK (SA+K-means) are better than KSA(K-means+SA), SA, and K-means in our simulations. Our method has significantly improved accuracy and efficiency to find the global optimal data clustering solution for complex, real time, and costly data mining process."
토픽 모델링에 기반한 온라인 상품 평점 예측을 위한 온라인 사용 후기 분석,2017,"['LDA', 'Artificial Neural Network', 'Topic Modeling', 'Rating Prediction', 'Review Analysis']",,"Customers have been affected by others’ opinions when they make a purchase. Thanks to the development of technologies, people are sharing their experiences such as reviews or ratings through online or social network services, However, although ratings are intuitive information for others, many reviews include only texts without ratings. Also, because of huge amount of reviews, customers and companies can’t read all of them so they are hard to evaluate to a product without ratings. Therefore, in this study, we propose a methodology to predict ratings based on reviews for a product. In a methodology, we first estimate the topic-review matrix using the Latent Dirichlet Allocation technic which is widely used in topic modeling. Next, we predict ratings based on the topic-review matrix using the artificial neural network model which is based on the backpropagation algorithm. Through experiments with actual reviews, we find that our methodology can predict ratings based on customers’ reviews. And our methodology performs better with reviews which include certain opinions. As a result, our study can be used for customers and companies that want to know exactly a product with ratings. Moreover, we hope that our study leads to the implementation of future studies that combine machine learning and topic modeling."
Applying of Decision Tree Analysis to Risk Factors Associated with Pressure Ulcers in Long-Term Care Facilities,2017,"['Data Mining', 'Decision Trees', 'Long-Term Care', 'Pressure Ulcer', 'Risk Factors']",,"<P><B>Objectives</B></P><P>The purpose of this study was to use decision tree analysis to explore the factors associated with pressure ulcers (PUs) among elderly people admitted to Korean long-term care facilities.</P><P><B>Methods</B></P><P>The data were extracted from the 2014 National Inpatient Sample (NIS)—data of Health Insurance Review and Assessment Service (HIRA). A MapReduce-based program was implemented to join and filter 5 tables of the NIS. The outcome predicted by the decision tree model was the prevalence of PUs as defined by the Korean Standard Classification of Disease-7 (KCD-7; code L89<SUP>*</SUP>). Using R 3.3.1, a decision tree was generated with the finalized 15,856 cases and 830 variables.</P><P><B>Results</B></P><P>The decision tree displayed 15 subgroups with 8 variables showing 0.804 accuracy, 0.820 sensitivity, and 0.787 specificity. The most significant primary predictor of PUs was length of stay less than 0.5 day. Other predictors were the presence of an infectious wound dressing, followed by having diagnoses numbering less than 3.5 and the presence of a simple dressing. Among diagnoses, “injuries to the hip and thigh” was the top predictor ranking 5th overall. Total hospital cost exceeding 2,200,000 Korean won (US $2,000) rounded out the top 7.</P><P><B>Conclusions</B></P><P>These results support previous studies that showed length of stay, comorbidity, and total hospital cost were associated with PUs. Moreover, wound dressings were commonly used to treat PUs. They also show that machine learning, such as a decision tree, could effectively predict PUs using big data.</P>"
랜덤 포레스트 기반 공동주택 공용관리비 추산모델,2017,"['공용관리비', '공동주택', '랜덤 포레스트', '데이터마이닝', 'Maintenance cost', 'Multi-Family housing', 'Random Forest', 'Data mining']",,"As multi-family housing has been chosen as the most popular types of housing in Korea, the maintenance of these facilities has become a key issue for the lives of the residents. The problem concerning the estimation of common maintenances cost is a sensitive issue and one that is currently receiving a lot of interest from the residents. Factors affecting this issue are complex and diverse. Thus, it is difficult to verify if the results of given estimates are adequate or whether or not the costs are high in comparison to other similar facilities. So, based on the historical data of multi-family housing, this study suggests an estimation model for arriving at common maintenance costs by utilizing the random forest method - a technique used in data mining. The multi-family housing data used in the configuration of the model was collected from certain regions in Seoul and, based on this, the random forest method was used to analyze the factors that influence common maintenance costs in order to develop an estimation model. This model is notable as it differed from traditional statistical methods by utilizing data mining -the random forest method- to build an estimation model for common maintenance costs. As a result of the case verification, the random forest based estimation model in this study is considered useful, and it is expected that more precise estimates will be gradually achieved as the data accumulates due to the nature of data mining and machine learning techniques."
SVR 기반 다변수 단기풍력발전예측 모델 연구,2017,"['풍력발전', '풍력발전예측', '다변수', 'SVR', 'nu-SVR', 'Wind Power', 'Wind Power Forecasting', 'SVR', 'nu-SVR', 'Multi-variate']","최근 신재생에너지는 기후변화대응, 에너지 안보, 수요관리에서 큰 비중을 차지하고 있다. 신재생에너지 중 풍력에 너지원은 풍력 터빈을 이용하여 풍력을 전력으로 바꾸어 에너지 역할로서 중요하다. 이때 풍력에너지 예측이 중요한 이유는 전력계통에서 풍력발전기가 중앙수급발전기가 되었을 때 발전기 유지 보수, 발전기 기동정지 계획, 경제급 전, 전력수급계획(발전기, 송전선로 등), 전력시장 입찰 등에 영향을 미치기 때문이다. 따라서 본 논문은 효율적인 풍력발전기의 단기풍력발전량을 예측하기 위하여 다변수로는 발전량, 풍향, 풍속, 발전변동량을 사용한다. 이때 다 변수간 상관관계를 이용하여 다변수 조합을 통하여 모델 4개를 생성한다. 그리고 4개의 모델 중 최적의 모델을 선 택하기 위하여 기계학습 방법인 SVR를 사용한다. 모델을 검증하기 위하여 제주도 지역의 풍력발전단지 3곳 (A,B,C)에 데이터를 사용하여 발전량을 예측한다. 실험결과, 발전량, 풍향, 풍속을 이용한 모델이 단기풍력발전량 을 예측하는 데 있어서 다른 모델보다 예측 오차가 작았다. 따라서 단기풍력발전량을 예측하는데 있어서 가장 중요 한 변수는 발전량, 풍향, 풍속이다.","Recently, renewable energy plays a major role in response to climate change, energy security and demand management. Among renewable energy, wind energy source is important as energy role by converting wind power into electric power using wind turbine. The reason for emphasizing the importance of wind energy forecasting affects that when the wind turbine becomes a central supplydemand generator in the power system, the maintenance of the generator, the stoppage of the generator stoppage, the economic dispatch, the power supply plan (generator, transmission line, etc.). Therefore, this paper uses power generation, wind direction, wind speed, and power generation variation as multi-variables to predict the short-term wind power generation of an efficient wind power generator. In this case, four models are generated through multi-variate combination using multi-variate correlation. And SVR, which is a machine learning method, is used to select the best model among the four models. To verify the model, we estimate the power generation using data at three wind farms (A, B, C) in Jeju Island. Experimental results show that the model using power generation, wind direction and wind speed has a smaller prediction error than other models in predicting short-term wind power generation. Therefore, the most important variables in predicting short-term wind power generation are generation amount, wind direction and wind speed."
스파크 프레임워크를 위한 병렬적 k-Modes 알고리즘,2017,"['k-모드', '범주적 데이터', '클러스터링', '스파크']",클러스터링은 빅데이터 분석 및 데이터 마이닝 분야에서 데이터 간 유사성을 파악하기 위해 사용하는 기법으로 다양한 클러스터링 기법 중 범주적 데이터를 위해 k-Modes 알고리즘이 대표적으로 사용된다. k-Modes와 같이 반복적 연산이 집중된 작업의 속도를 향상시키기 위해 많은 관심을 받고 있는 분산 병행 프레임워크 스파크는 하둡과 달리 RDD라는 추상화 객체 개념을 사용하여 대용량의 데이터를 메모리 상에서 처리 가능한 환경을 제공한다. 스파크는 다양한 기계학습을 위한 라이브러리인 Mllib을 제공하고 있으나 연속적 데이터만 처리 가능한 k-means만 포함되어 있어 범주적 데이터 처리가 불가능한 한계가 있다. 따라서 본 논문에서는 스파크 환경에서 범주적 데이터 클러스터링을 위한 k-Modes 알고리즘을 위한 RDD 설계하고 효과적으로 동작할 수 있는 알고리즘을 구현하였다. 실험을 통해 제안한 알고리즘이 스파크 환경에서 선형적으로 증가한다는 것을 보였다.,"Clustering is a technique which is used to measure similarities between data in big data analysis and data mining field. Among various clustering methods, k-Modes algorithm is representatively used for categorical data. To increase the performance of iterative-centric tasks such as k-Modes, a distributed and concurrent framework Spark has been received great attention recently because it overcomes the limitation of Hadoop. Spark provides an environment that can process large amount of data in main memory using the concept of abstract objects called RDD. Spark provides Mllib, a dedicated library for machine learning, but Mllib only includes k-means that can process only continuous data, so there is a limitation that categorical data processing is impossible. In this paper, we design RDD for k-Modes algorithm for categorical data clustering in spark environment and implement an algorithm that can operate effectively. Experiments show that the proposed algorithm increases linearly in the spark environment."
문장유사도 측정 기법을 통한 스팸 필터링 시스템 구현,2017,"['스팸메시지', '필터링', '문장유사도 측정기법', '집합기반 POI 검색 알고리즘', 'spam message', 'filtering', 'sentence similarity measurement method', 'set-based POI search algorithm']","문자 메시지는 휴대폰을 사용하는 사람들에게 중요한 의사소통의 방법 중 하나이다. 또한 친구맺기 방식이 필요 없이 사용이 가능하기 때문에 이를 악용한 불법 광고 스팸메시지가 기승을 부리고 있다. 최근 스팸 필터링을 위해 기계 학습을 이용한 시스템들이 등장 하였지만 많은 계산을 필요로 하는 단점이 있다. 본 논문에서는 검색할 쿼리를 입력할 때 부정확한 쿼리를 입력하더라도 저장된 데이터베이스와 비교하여 가장 비슷한 단어를 차수 개념을 적용하여 유추하는 집합 기반 POI(Point of Interest) 검색 알고리즘을 이용하여 스팸 필터링 시스템을 구현하였다. 이 알고리즘을 적용하면 서버 컴퓨팅 없이 문자의 조합만을 이용해 쿼리를 유추할 수 있기 때문에 스팸 필터링에 적용하여 입력된 문자메시지가 교묘하게 변형되더라도 스팸이라고 필터링이 가능하다. 또한 문장 유사도 측정 기법을 활용하여 스팸 필터링 성능을 향상시켰으며, 스팸 필터링에 취약한 특정 유형도 걸러내기 위해 특정 전처리 과정을 지원함으로써 대부분의 스팸메세지를 필터링 가능하도록 하였다. 기존 집합기반 POI 검색 알고리즘과 이를 확장 시킨 문장 유사도 측정 기법, 특정 전처리 과정을 추가한 시스템으로 필터링 시스템의 성능평가를 진행하였다. 그 결과 본 논문에서 구현한 시스템이 기존 집합기반 POI 알고리즘과 비교하여 향상된 스팸 필터링 성능을 보여주는 것을 확인하였다. 또한 이동통신사 3사에서 필터링에 취약한 유형이 본 논문에서 구현한 시스템으로 높은 성능으로 필터링이 가능하다는 것을 확인하였다.","Short message service (SMS) is one of the most important communication methods for people who use mobile phones. However, illegal advertising spam messages exploit people because they can be used without the need for friend registration. Recently, spam message filtering systems that use machine learning have been developed, but they have some disadvantages such as requiring many calculations. In this paper, we implemented a spam message filtering system using the set-based POI search algorithm and sentence similarity without servers. This algorithm can judge whether the input query is a spam message or not using only letter composition without any server computing. Therefore, we can filter the spam message although the input text message has been intentionally modified. We added a specific preprocessing option which aims to enable spam filtering. Based on the experimental results, we observe that our spam message filtering system shows better performance than the original set-based POI search algorithm. We evaluate the proposed system through extensive simulation. According to the simulation results, the proposed system can filter the text message and show high accuracy performance against the text message which cannot be filtered by the 3 major telecom companies."
데이터마이닝을 이용한 글로벌 리츠 투자 특성 예측,2017,"['부동산간접투자', '글로벌리츠', '투자가치', '예측분석', '정분류율', '중요도', 'Real Estate Indirect Investment', 'Global REITs', 'Investment Value', 'Forecast Analysis', 'Sorting Rate', 'Importance']","글로벌 금융위기 및 유럽 재정위기, 중국의 경기둔화 등 대외적 요인과 국내경기 둔화, 전세시장 역전 등의 대내적 요인에 따른 부동산 경기 부진으로 거래가 매우 침체되어 있다. 리츠(Real Estate Investment Trusts, REITs)와 부동산펀드(Real Estate Fund, REF) 등을 통해 임대수익이나 매각수익을 향유하는 부동산 간접투자시장이 급성장 하고 있다. 리츠투자는 글로벌 포트폴리오 및 대체투자 다변화, 수익률 극대화라는 기치하에 연기금 등 기관투자자의 수임을 받은 자산운용사를 중심으로 판매사를 통해 지속적으로 재간접펀드 일종인 글로벌리츠재간접펀드에 글로벌부동 산펀드와 더불어 투자자산을 증대시키고 있다. 글로벌리츠재간접투자의 예측분석 및 투자특성 분석결과를 바탕으로 투자하고자 하는 기관투자자 및 투자회사 실무담당자에게 투자 특성 예측분석을 통해 해외 투자지역 선별 및 투자항목 선택에 조력을 줌으로써 위험을 최소화하는데 기여하고자 하는 목적에서 연구를 실시하였다. 데이터마이닝을 통한 분류분석을 위한 데이터마이닝 투자가치 예측분석 결과 예측분석의 분류의 정확도는 99.7%로 높은 정분류율을 나타냈 다. 따라서 인공신경망 모형(ANN)을 활용한 분석결과를 바탕으로 자산운용사 및 판매사의 상품기획 및 자산운용 담당자들에게 글로벌 리츠상품 개발 기준 및 판매 기준 등을 제시해 줄 것을 기대한다.","1. CONTENTS (1) RESEARCH OBJECTIVESThe results of the analysis of the prospectus and investment characteristics of the global barrel re-indebted fuels will be used by institutional investors and investment company practitioners who want to invest in overseas REITs to select overseas investment region selection and investment items And to contribute to the minimization of risk by providing assistance to the public.(2) RESEARCH METHODThe data used for valuation analysis and classification analysis of REITs Investment consisted of 332 asset management companies  performance data on real estate overseas investment-type REITs investment products, The investment profit ratio of overseas investment-type commodities was 2016.It was 1 year immediately before the end of October 2015 (from May 1, 2015 to October 20, 2010).(3) RESEARCH FINDINGSWe use data mining to classify and analyze the investment characteristics of the Global Litigation Re-Induced Firm by securing predictive power using these data mining methods.2. RESULTSResults Characteristics of Investment in Global Ritz Re-Indirect Fund Using Data Mining As a result of machine learning for predictive analysis, the neural network model has the highest positive classification rate (99.7% accuracy) for predicting investment outcome Indicated. Next, we showed the prediction accuracy (Chon classification rate 98.82%) for the significance analysis of prediction variables of decision tree model (C 5.0) and logistic regression model. Based on the accuracy of such prediction, the independent variables affecting the investment result (IV) of the dependent variable as a result of the importance analysis of the variable are OM (operational maintenance), total net asset (NAV), price standard (BP) I was able to confirm the fact that."
豊西 柳應斗의 「農謳十四章」에 대한 고찰,2017,"['Yu', 'Eungdu(柳應斗)', 'Huanghaedo(黃海道)', 'factuality(寫實性)', 'instructive (敎訓性)', 'metaphor(比喩性)', '柳應斗', '黃海道', '寫實性', '敎訓性', '比喩性']","柳應斗(1847～1914)의 「農謳十四章」은 姜希孟(1424～1483)의 「農謳」를 온고지신한 작품이다. 유응두가 「農謳十四章」을 지은 목적은, 열심히 농사를 잘 지어 생활을 풍요롭게 해야 한다는 마음을, 노래를 통해 暗誦하게 하여 지속적으로 농사에 열중하고자하는 마음을 갖도록 하는데 있었다. 유응두는 韻字를 붙이는데 있어 章의 제목을 기억연상하기 쉽게 제목에 들어있는 글자를 운자로 썼다. 즉 유응두는 <誇農>에 韻字를 붙이는데 있어 2구, 4구, 6구, 8구, 10구, 12구, 14구, 16구, 18구에 農字를 붙였다. 제 1구에도 붙였다. 농사를 짓는 것이 중요하다는 점을 강조한 것이며 노래를 듣는 사람으로 하여금 농사에 대한 자긍심을 갖도록 하기 위한 조치이다. 이렇듯 유응두는 조선말 곤궁한 시대에 살면서 농사를 통한 민생안정을 도모하고자 했던 것이다. 유응두의 「農謳十四章」의 내용의 특징을 9가지로 분류해볼 수 있다. 첫 째 雨暘의 혜택의 直感性과 임금의 혜택의 隱微性, 둘째 근면함과 나태함 그 결과의 차이에 대한 인식, 섯째 농기구의 활용에 따른 旱水害 예방과 貧富의 격차, 넷째 잡초 제거와 對比하여 조정 관료 등용에 대한 충언, 다섯째 육체노동을 통한 농사 소득에 대한 자부심, 여섯 째 새참의 효용과 그 제공시간의 중요성, 일곱 째 飢餓解決의 최저 수준에 滿足, 여덟 째 물닭의 울음소리에 投影된 住居 食生活의 수준, 아홉 째 농작물의 관리 후 濯足하며 洗心의 境地 吟味이다. 유응두의 「農謳十四章」은 강희맹의 「農謳」의 형식을 본떠 지었다. 그러나 그는 그의 시에 당시 농민의 실상을 상세히 묘사하여 寫實性이 높다. 따라서 유응두의 「農謳十四章」은 1800년 대 말 1900년대 초 지금 북한 황해도지역 농촌의 어려운 농경 실상을 여실히 알 수 있는 수작이라 할 수 있다. 李衡祥(1653～1733)의 강희맹의 「農謳」를 본떠 「次農謳」와 「後農謳」를 지었다. 조선말 유응두는 강희맹의 「農謳」의 형식과 구조를 본떠 「농구십사장」은 지었다. 유응두는 형식적인 면에서는 강희맹의 농구를 본떴으나 구조적인 면에서 句數를 거의 2배 이상 늘였다. 그러다 보니 내용을 풍부하게 묘사하여 사실성과 구체성이 뛰어나 당시의 정황을 잘 알 수 있다. 그리고 권면성과 교훈성도 제시되어 있다. 이렇듯 유응두의 「농구십사장」은 한문학의 전통을 근대까지 계승하여 그 맥을 이었다고 그 문학사적 의의를 부여할 수 있다.","Yu, Eungdu(柳應斗; 1847～1914)'s ｢Nonggusipsajang(農謳十四章)｣ is a piece of reviewing the old and learning the new from Gang, Heemaeng(姜希孟; 1424～1483)'s ｢Nonggu農謳｣. By the way, it has many almost more than double of Gang, Heemaeng's stanza number(句數). With that at that times Farmers' reality and their psychological aspect were described in detail and expression rhetorics was fine. Yu, Eungdu(柳應斗)'s ｢Nonggusipsajang(農謳十四章)｣'s contents characters can be divided 9 variety. At first, Wuyang(雨暘)'s intuition(直感性) of benefit and King's Eunmiseong(隱微性) of benefit, second, diligent and idle, the cognition of difference from the result, third, prevention of flood damage(旱水害) according to utilization of farm machines and implements and gap of rich and poor(貧富), fourth, advice of the Court bureaucrat promotion contrast with(對比) weed removal, fifth, pride of farming income through physical working, sixth, importance of serving time and utility of elevenses, seventh, satisfaction(滿足) from minimum level of starvation solution(飢餓解決), eighth, food, clothing, shelter housing(住居), dietary life(食生活) level by projection(投影) cry of water hen, ninth, appreciation(吟味) of Sesim(洗心) state(境地) and washing foot(濯足) after crop management. Yu, Eungdu(柳應斗)'s ｢Nonggusipsajang(農謳十四章)｣ was composed imitated of form of Gang, Heemaeng(姜希孟)'s ｢Nonggu農謳｣. However, he described reality of farming in his poems in detail at that times so factuality(寫實性) was high. And He suggested properly encouragement(勸勉性) and Instructive(敎訓性). Therefore Yu, Eungdu(柳應斗)'s ｢Nonggusipsajang(農謳十四章)｣ was an excellent work which can be known the difficult reality of farming in farm village of Huang- haedo(黃海道) district in North Korea contemporary late 1800 years to early 1900 years, so ti can be given the meaning."
"‘제4차 산업혁명’ 시대, 인문학의 역할과 과제",2017,"['제4차 산업혁명', '인공지능 시스템', '의생명과학기술', '기본소득', '지적재산권', '온화한 지성', 'The ‘Fourth Industrial Revolution’', 'AI systems', 'Biomedical Technologies', 'Basic Income', 'Gentle Intellect']","‘제4차 산업혁명’의 주요 인자는 인공지능 시스템과 의생명과학기술이다. 그것은 신체적 인간의 오랜 염원인 부(富)와 불로장생에 ‘혁명적’ 기여를 할 것으로 기대되는 반면에 이제까지의 인간 사회와 ‘인간’ 개념을 근본적으로 뒤흔들 위협적 요소를 포함하고 있다.  이미 ‘제3차 산업혁명’ 과정에서 부와 사회적 발언권이 소수에게 집중되어 중산층이 얇아지고, 일단 밀려난 다수가 상대적 빈곤을 벗어나기가 더욱 어려운, 이른바 ‘양극화’ 현상이 나타났다. 이제 더욱 발전된 인공지능 시스템이 다양한 방식으로 인간 사회에 진입할 ‘제4차 산업혁명’이 진척을 보일수록, 종전의 노동 기반 사회의 구조는 점차 와해될 가능성이 높아질 것이다.  그렇기에 ‘제4차 산업혁명’의 결과 시민들 사이의 빈부 격차가 더욱 심화되는 비인도적 사회가 초래되는 것을 피하고, 생산능력과 소비능력의 선순환을 이룩하기 위해서는 보편적인 국민 복지제도가 수립되어야 한다. 전 국민의 주택, 교육, 의료비는 공동체가 담당하고, 기타 일용할 비용에 대해서는 국민 기본소득 제도를 수립해야 한다.  다른 한편 의생명과학기술의 진보가 인간의 생명과 인체에 관여함으로써 일어날 인간 변이를 방지해야 한다. 우선 인체나 인간 생명을 조작하는 데 활용될 가능성이 크면서도 그 파장을 예상하기 어려운, 신과학기술의 산물에 관련해서는 지적재산권을 제한하고 사유화를 최소화함으로써 개발속도를 조정하고, 그것이 인간의 생명 구조의 변경과 관련이 있는 것일 경우에는 반드시 ‘기술 시민권’을 확보해야 한다. 더 나아가 〈국제 의생명과학 기구〉를 만들어 생명공학 기술이 핵무기 못지않게 엄정한 국제적 규범 질서 안에서 연구 개발 사용되도록 통제해야 한다.  ‘제4차 산업혁명의 시대’에 달리기는 자동차에, 날기는 비행기에, 계산하기는 인공지능에, 산업 노동은 로봇에 맡기면서, 인간이 하는 주요한 일은 이것들을 조정하고 이것들의 일들을 조율하는 것이다. 이를 위해서 인간에게는 균형 잡힌 통찰력, 곧 온화한 지성이 필요하거니와, 이러한 지성은 기민한 지능과는 달리 냉철한 머리와 따뜻한 가슴의 화합에서 배양된다. - ‘제4차 산업혁명’의 참주역은 ‘지능적’인 사람이 아니라 ‘지성적’인 사람, 인문적 지성을 갖춘 사람이어야 할 것이고, 그래서 인문학의 역할이 절실하다.","The critical factors in the ‘Fourth Industrial Revolution’ are artificial intelligence(AI) systems and biomedical technologies. The ‘revolution’ occurring in these technologies is expected to increase productivity and longevity, for which all mortal humans have been longing. However, at the same time, the ‘revolution’ has the potential to shake the foundation of present social structures and the ideas about what it means to be human.  Already in the ‘Third Industrial Revolution’. there has been a ‘thinning’ of the middle class. As society became more ‘bipolarized’, society has more ‘haves’ and ‘have-nots,’ with fewer in between, which in turn has led to an increase in social tensions. The ‘Fourth Industrial Revolution’ might yield greater inequality, particularly in its potential to disrupt labor markets. As automation substitutes labor across the economy, the displacement of workers by machines might exacerbate the gap between returns on capital and returns on labor. This means a collapse to the internal structure of the labor-based society.  Under these circumstances, to prepare for the ‘Fourth Industrial Revolution’, it is necessary to introduce the general welfare system. Society must bear the expenses of housing, education, and medical services. Basic income systems must also be introduced to support the expenses of other areas.  Specific advances in biomedical technologies, which are capable of changing the nature of the human species, require us to take risks and responsibilities for their application such as hacking medical devices, privacy and confidentiality of medical records, and biological inequalities depending on social class. The government must restrict intellectual property rights or industrial copyrights for the products of biomedical technologies, which are not only easily embedded in the human body but also bound to have widespread social ramifications, in order to decelerate the speed of technical development. In the case of these products, which have the potential to manipulation human genetic structure, ‘technological citizenship’ must be secured. Moreover, any studies in these technologies must be strictly progressed according to international standards established by the “International Biomedical Science Agency(IBSA)”.  As robots increasingly take on manual labor and autonomous vehicles, depending on AI helps to increase mobilities. This seems to minimize the role of human involvement of things from product-production to decisionmaking. However, the role of human involvement has changed. All of us are responsible for guiding developments in these technologies and in the decisions we make on a daily basis. To do this, however, we must develop a balanced, comprehensive insight of how technology is affecting our lives and how technology lifts humanity into a new moral consciousness. For development, this view needs not only gentle intellect but also moral consciousness of human dignity, which we can build up by learning litterae humaniores."
ICT 중소기업 R&D의 스테레오타입에 대한 연구,2017,"['ICT', '스테레오타입', '데이터마이닝', '의사결정나무 분석', 'R&amp', 'D 정책', '중소기업 지원 정책', 'ICT (Information &amp', 'Communication Technology)', 'Stereotype', 'Data mining', 'Decision tree analysis', 'R&amp', 'D policy', 'SMEs support policy']","국내 ICT 산업은 글로벌 경쟁력을 갖추고 경제발전에 크게 이바지 해왔으며, 침체된 우리나라의 경제상황을 활성화할 수 있는 성장 동력으로 주목받고 있다. 이러한 ICT 산업을 국내외에서 다양한 모습으로 바라보고 있는데, 이 중에는 객관적인 근거가 부족한 고정 관념도 많다. 이런 특정 집단에 대해 많은 사람이 가지는 공통되고 고정된 견해가 스테레오타입인데, 스테레오타입은 항상 부정적인 것은 아니지만 우리의 의사결정에 큰 영향을 주기 때문에 간과할 수 없다. 따라서 본 연구는 ICT 산업에 대한 스테레오타입을 살펴보고 보다 객관적이고 상대적인 스테레오타입을 제공하고자 한다.  이를 위해, 본 연구는 3,300개 중소기업 설문을 토대로 의사결정나무 분석을 통해 국내 ICT 기업이 다른 기술 기업과 비교해서 가지는 특징을 도출했다. 기업일반, 기술개발 활동, 기술개발 조직과 인력 등 10가지 R&D 정책 주제에 대해서 291개 변수를 대상으로 분석했는데, 기계학습을 활용한 데이터마이닝의 한 가지 방법인 의사결정나무 분석을 활용해서 ICT 기업과 다른 기술 기업이 구분되는 변수를 찾고 그 특징을 통해 객관적인 ICT 기업의 스테레오타입을 제시했다.  이 연구의 결과로 제시된 ICT 기업의 스테레오타입에 따르면, 국내 ICT 기업을 위해서는 첫째 R&D 기획이나 판로개척을 지원할 수 있는 기술정책이 필요하며, 둘째 신제품이나 신규 분야 진출을 위한 R&D 지원정책이 강화되어야 하고, 셋째 기술개발 결과에 대한 보안과 지재권 관리를 위한 지원정책이 요구되며, 넷째 ICT 기업과 관련된 정부 R&D 지원 제도관련 행정 간소화가 요구되는 것으로 나타났다.  이 연구의 결과는 ICT 중소기업을 위한 기술정책 수립·집행·평가에 다양한 시사점을 제공할 수 있으며, 특히 ICT 중소기업을 위한 R&D 정책을 수립하는 정책당국자나 유관기관의 연구자에게 여러가지 정책적 가이드를 제공해 줄 것으로 기대한다.","The ICT industry has been the main driver of Korea’s economy with international competitiveness and is expected to be the growth engine that will revitalize the currently depressed economy. A broad range of different perspectives and opinions on the industry exist in Korea and overseas. Some of these are stereotypes, not all of which are based on objective evidence. Stereotypes refer to widely-held fixed opinions on a specific group and do not necessarily have negative connotations. However, they should not be viewed lightly because they can substantially affect decision-making process. In this regard, this study sought to review the stereotypes of ICT industry and identify objective and relative stereotypes.  In the study, a decision-tree analysis was conducted on a survey result of 3,300 small and medium-sized enterprises (SMEs) in order to identify Korean ICT companies’ characteristics that distinguish them from other technology companies. The decision-tree analysis, a data mining process based on machine learning, took a total of 291 variables into account in 10 subjects such as: corporate business in general, technology development activities as well as organization and people in technology development. Identifying the variables that distinguish ICT companies from other technology companies with the decision-tree analysis, the study then came up with a list of objective stereotypes of ICT companies.  The findings from the stereotypes of Korean ICT companies are as follows. First, the companies are in need of technology policies that help R&D planning and market penetration. Second, policies must better support the companies working to sell new products or explore new business. Third, the companies need policies that support secure protection of development outcomes and proper management of IP rights. Fourth, the administrative procedures related to governmental support for ICT companies’ R&D projects must be simplified.  It is hoped that the outcome of this study will provide meaningful guidance in establishment, implementation and evaluation of technology policies for ICT SMEs, particularly to policymakers or researchers in relevant government agencies who determine R&D policies for ICT SMEs."
S-MTS를 이용한 강판의 표면 결함 진단,2017,"['빅데이터', '데이터마이닝', '다중 클래스 분류', '마할라노비스 다구찌 시스템', '강판 표면 결함 진단', 'Big Data', 'Multiclass Classification', 'Simultaneous MTS(S-MTS)', 'Mahalanobis Taguchi System(MTS)', 'Steel Plates Faults Diagnosis']",,"Steel plate faults is one of important factors to affect the quality and price of the steel plates. So far many steelmakers generally have used visual inspection method that could be based on an inspectors intuition or experience. Specifically, the inspector checks the steel plate faults by looking the surface of the steel plates. However, the accuracy of this method is critically low that it can cause errors above 30% in judgment. Therefore, accurate steel plate faults diagnosis system has been continuously required in the industry. In order to meet the needs, this study proposed a new steel plate faults diagnosis system using Simultaneous MTS (S-MTS), which is an advanced Mahalanobis Taguchi System (MTS) algorithm, to classify various surface defects of the steel plates. MTS has generally been used to solve binary classification problems in various fields, but MTS was not used for multiclass classification due to its low accuracy. The reason is that only one mahalanobis space is established in the MTS. In contrast, S-MTS is suitable for multi-class classification. That is, S-MTS establishes individual mahalanobis space for each class. Simultaneous implies comparing mahalanobis distances at the same time. The proposed steel plate faults diagnosis system was developed in four main stages. In the first stage, after various reference groups and related variables are defined, data of the steel plate faults is collected and used to establish the individual mahalanobis space per the reference groups and construct the full measurement scale. In the second stage, the mahalanobis distances of test groups is calculated based on the established mahalanobis spaces of the reference groups. Then, appropriateness of the spaces is verified by examining the separability of the mahalanobis diatances. In the third stage, orthogonal arrays and Signal-to-Noise (SN) ratio of dynamic type are applied for variable optimization. Also, Overall SN ratio gain is derived from the SN ratio and SN ratio gain. If the derived overall SN ratio gain is negative, it means that the variable should be removed. However, the variable with the positive gain may be considered as worth keeping. Finally, in the fourth stage, the measurement scale that is composed of selected useful variables is reconstructed. Next, an experimental test should be implemented to verify the ability of multi-class classification and thus the accuracy of the classification is acquired. If the accuracy is acceptable, this diagnosis system can be used for future applications. Also, this study compared the accuracy of the proposed steel plate faults diagnosis system with that of other popular classification algorithms including Decision Tree, Multi Perception Neural Network (MLPNN), Logistic Regression (LR), Support Vector Machine (SVM), Tree Bagger Random Forest, Grid Search (GS), Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The steel plates faults dataset used in the study is taken from the University of California at Irvine (UCI) machine learning repository. As a result, the proposed steel plate faults diagnosis system based on S-MTS shows 90.79% of classification accuracy. The accuracy of the proposed diagnosis system is 6-27% higher than MLPNN, LR, GS, GA and PSO. Based on the fact that the accuracy of commercial systems is only about 75-80%, it means that the proposed system has enough classification performance to be applied in the industry. In addition, the proposed system can reduce the number of measurement sensors that are installed in the fields because of variable optimization process. These results show that the proposed system not only can have a good ability on the steel plate faults diagnosis but also reduce operation and maintenance cost. For our future work, it will be applied in the fields to validate actual effectiveness of the proposed system and plan to improve the accuracy based on the results."
Compressive strength prediction of CFRP confined concrete using data mining techniques,2017,"['CFRP confined concrete', 'data mining', 'artificial neural networks', 'support vector machines']",,"During the last two decades, CFRP have been extensively used for repair and rehabilitation of existing structures as well as in new construction applications. For rehabilitation purposes CFRP are currently used to increase the load and the energy absorption capacities and also the shear strength of concrete columns. Thus, the effect of CFRP confinement on the strength and deformation capacity of concrete columns has been extensively studied. However, the majority of such studies consider empirical relationships based on correlation analysis due to the fact that until today there is no general law describing such a hugely complex phenomenon. Moreover, these studies have been focused on the performance of circular cross section columns and the data available for square or rectangular cross sections are still scarce. Therefore, the existing relationships may not be sufficiently accurate to provide satisfactory results. That is why intelligent models with the ability to learn from examples can and must be tested, trying to evaluate their accuracy for composite compressive strength prediction. In this study the forecasting of wrapped CFRP confined concrete strength was carried out using different Data Mining techniques to predict CFRP confined concrete compressive strength taking into account the specimens’ cross section: circular or rectangular.Based on the results obtained, CFRP confined concrete compressive strength can be accurately predicted for circular cross sections using SVM with five and six input parameters without spending too much time. The results for rectangular sections were not as good as those obtained for circular sections. It seems that the prediction can only be obtained with reasonable accuracy for certain values of the lateral confinement coefficient due to less efficiency of lateral confinement for rectangular cross sections."
