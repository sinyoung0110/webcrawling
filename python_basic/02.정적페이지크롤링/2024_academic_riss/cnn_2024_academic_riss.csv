title,date,keywords,abstract,multilingual_abstract
CNN을 활용한 M-PSK변조 기반 무선 광통신 시스템에서의 Log-Normal 모델과 Gamma-Gamma 모델의 대기 난류 채널 분류 성능 비교,2024,"['무선 광통신', '대기 난류', '채널 분류', '합성곱 신경망 (CNN)', 'PSK 변조', 'Wireless Optical Communication', 'Atmospheric Turbulence', 'Channel Classification', 'Convolutional Neural Network (CNN)', 'PSK Modulation']","본 논문은 서로 다른 위상 천이 변조(phase shift keying, PSK) 방식을 사용하는 무선 광통신 시스템에서 합성곱 신경망 (convolutional neural network, CNN)에 기반하여 대기 난류 채널의 분류 성능을 비교한다. 대기 난류는 무선 광통신 시스템의 성능 저하를 야기하는 주요 요인 중 하나로, 난류 강도에 따라 약한 난류, 중간 난류, 강한 난류로 구분된다. 본 연구는 PSK 변조 방식을 적용한 무선 광통신 시스템을 대상으로, 수신 신호의 성상도 (constellation diagram)를 입력으로 하는 CNN 모델을 이용하여 난류 채널을 분류하고, 분류 정확도를 비교한다. 약한 난류 채널을 Log-Normal (L-N) 난류 모델과 Gamma-Gamma (G-G) 난류 모델로 모델링하였으며, 중간 난류와 강한 난류는 G-G 난류모델로부터 파라미터를 조절하여 모델링한다. 각 난류 강도에 따른 데이터셋을 생성하여 CNN 모델을 학습하였다. PSK 변조 방식들에 대해 제안된 CNN 모델의 분류 정확도를 비교함으로써, 성상도 기반 CNN 채널 분류 기법이 PSK 변조 방식에 적용 가능함을 보여준다.","This paper compares the classification performance of atmospheric turbulence channels based on convolutional neural networks (CNNs) in wireless optical communication systems employing different phase shift keying (PSK) modulation schemes. Atmospheric turbulence is one of the primary factors causing performance degradation in wireless optical communication systems, and it is classified into weak, moderate, and strong turbulence based on the intensity. This study focuses on classifying turbulence channels in PSK modulated wireless optical communication systems using a CNN model that takes constellation diagrams of received signals as input and compares the classification accuracy. Weak turbulence channels are modeled using both the Log-Normal (L-N) turbulence model and the Gamma-Gamma (G-G) turbulence model, while moderate and strong turbulence are modeled by adjusting the parameters of the G-G turbulence model. The CNN model is trained using data sets generated for each turbulence intensity. By comparing the classification accuracy of the proposed CNN model across various PSK modulation schemes, the study demonstrates that the constellation diagram-based CNN channel classification technique can be applied to PSK modulation schemes."
클라우드 이상 행위 탐지를 위한 1-D STM 블록 기반 Stacking CNN 모델,2024,"['Cloud System Security', 'Anomaly Detection', 'Deep Learning', 'Stacking CNN', '클라우드 시스템 보안', '이상 탐지', '딥러닝', 'Stacking CNN']","클라우드 컴퓨팅 기술은 클라우드 서비스의 핵심 기술이며, 사용자에게 공간의 제약 없이 특정 물리 서버의 자원을 필요한 만큼 제공한다. 이러한 클라우드 컴퓨팅 기술은 데이터 수집및 분석, 의사 결정을 빠르고 효율적으로 수행하는 장점을 가지지만, 보안 위협에 취약한 단점을 가진다. 따라서, 클라우드 컴퓨팅 기술의 보안 위협에 대응하기 위해 침입 탐지 시스템이 필요하다. 최근 침입 탐지 시스템 중 합성곱 신경망(CNN) 기반 이상 행위 탐지 연구가활발히 진행되고 있다. 하지만, CNN 기반 이상 행위 탐지 모델은 이상 행위에 대한 세부 수준 및 추상 수준의 특징 추출 한계점이 존재한다. 따라서, 본 논문에서는 CNN 기반 이상 행위 탐지 모델의 한계점을 극복할 수 있는 1-D STM 블록과 이를 기반으로 설계한 StackingCNN 기반 이상 행위 탐지 방안을 제안한다. 실험을 통해 Stacking CNN 기반 이상 행위 탐지 방안은 클라우드 보안 위협에 대응할 수 있는 이상 행위 탐지 모델임을 검증하였다.","As a core technique of cloud service, cloud computing technique provides userswith the resources of a specific physical server without spatial constraints. Eventhough such cloud computing technique performs data collection, analysis, anddecision-making quickly and efficiently, it is vulnerable to security threats. Thus,an intrusion detection system is needed to defend against such security threats.Recently, convolutional neural network(CNN)-based anomaly detection methodshave been actively studied. However, the existing CNN-based anomaly detectionmethods have limitations in extracting detailed and abstract-level features forabnormal behaviors. Therefore, In this paper, we propose an 1-D STM block whichovercomes the limitations of existing CNN-based anomaly detection methods. Also,we propose a new anomaly detection method using Stacking CNN model based onthe 1-D STM blocks. From the experimental results, we validate that the proposedanomaly detection method is effective in mitigating cloud security threats."
3D CNN-LSTM 알고리즘을 이용한 손동작 비디오 영상 분류,2024,"['Artificial Intelligence', 'Deep Learning', 'CNN', 'LSTM', 'Video Classification', 'Hand Gesture Classification']","손동작 인식은 이미지나 비디오 데이터로부터 인간의 동작 및 제스처를 식별하는 행동인식기술의 한 형태이다. 디지털 기술의 발전으로 제품에 스마트 기능이 추가되는 사례가 많아지면서 동작인식의 편리성과 효율성도 강조 되고 있다. 본 연구는 손동작 인식을 시도하기 위한 과정으로, 손동작을 기반으로 클래스를 나누어 각각의 클래스를 분류해내는 비디오 분류 연구를 진행한다. 비디오 영상 자체로 딥러닝 분류를 하게 되면 정확도도 높으며, 이미지를 통한 비디오 분류보다 다양한 분야에서 활용이 가능하다는 장점이 있다. 제시된 알고리즘은 3D CNN(Convolutional neural network)과 LSTM(Long Short-Term Memory)이 결합된 형태로 이루어져 있다. 개발한 3D CNN은 이미지나 비디오의 특징 추출에 주로 사용하는 2D CNN 중 ResNet-18의 구조에서 고안하였다. LSTM은 순차 데이터를 학습, 처리, 분류하는 데 주로 사용되고 있는 RNN(Recurrent Neural Network)중의 한 종류이다. 3D CNN을 통해 비디오의 특징을 추출하고, LSTM을 통해 추출된 특징의 시퀀스를 학습 후 각 비디오 시퀀스를 손동작의 변화를 기준으로 하는 다섯 가지 클래스로 분류하였으며 비디오 분류 결과 정확도 평균 87%를 보여 주었다.","Hand gesture recognition is a subset of motion recognition technology that identifies human actions from image or video data. With the advancement of digital technology and the increasing integration of smart functions into products, the convenience and efficiency of motion recognition have become more prominent. This research aims to explore the process of hand gesture recognition by classifying video sequences based on hand gestures. The research focuses on video classification using deep learning techniques, which offer higher accuracy and broader applicability compared to image-based video classification. The proposed algorithm combines a 3D Convolutional Neural Network (3D CNN) with a Long Short-Term Memory network (LSTM). The developed 3D CNN is based on the ResNet-18 architecture, which is commonly used for feature extraction in images and videos. The LSTM, an extension of the Recurrent Neural Network (RNN), is employed to learn, process, and classify sequential data. The 3D CNN extracts features from video sequences, and the LSTM learns these feature sequences to classify each video sequence into one of five classes based on variations in hand gestures. The combined network, utilizing 3D CNN for feature extraction and LSTM for sequence learning, provides a robust approach to classify hand gestures in video sequences, demonstrating potential for diverse applications in various fields. The video classification accuracy reached approximately 87%."
CNN 기반 위성 이미지를 활용한 북한의 도시 인구추정,2024,"['북한 인구', '주간 위성 이미지', 'CNN', '이웃 효과', 'U-net', 'North Korea’s population', 'daytime satellite image', 'CNN', 'neighboring effects', 'U-net']","북한은 공식적인 절차를 통해 인구데이터를 공개하지 않지만, 통계청, 인터넷 검색을 통해 북한의 인구와 관련된 자료를 확인할 수 있다. 그러나 이 데이터들은 1993년, 2008년에 유엔인구기금(UNFPA)의 지원을 받아 실시한 인구총조사를 기반으로 추정된 자료이고 신뢰성도 떨어지는 것으로 알려져 있다. 이에 본 연구에서는 북한의 현재 인구를 가늠하기 위한 첫 시도로 2023년 북한의 주간 위성 이미지를 이용하여 평양과 개성의 인구를 격자 단위로 추정하였다. 연구 결과로 CNN 기반 격자 단위 인구추정 모델을 개발하였다. 이 모형은 우리나라를 대상으로 CNN 모델을 훈련하고, 북한에 적용하는 것을 목표로 한다. 모형은 CNN의 대표적인 알고리즘인 VGG16 모델을 기반으로 전이학습을 하였으며, 주간 위성 이미지에서 나타나는 남북한의 계절 차이를 조정하기 위해 U-net을 활용하여 조정된 이미지를 사용하였다. 또한, 이웃효과(neighboring effects)를 추가하여 모델의 성능을 개선하였다. 모델 적합 결과 우리나라의 4대 광역시의 인구는 실제 인구와 큰 차이 없이 추정되었으며, 북한의 평양과 개성의 인구는 2008년 센서스인구와 유사하게 추정되어 만족스러운 결과를 보여주었다.","North Korea does not officially disclose population data through formal procedures. However, information related to North Korea's population can be verified through KOSTAT or internet searches. Nevertheless, these data are based on population surveys conducted with the support of the United Nations Population Fund (UNFPA) in 1993 and 2008, and are known to be of questionable reliability. In this study, as an initial attempt to estimate the current population of North Korea, we utilized daytime satellite images from 2023 to estimate the populations of Pyongyang and Kaesong at the grid level. The research resulted in the development of a gridded population estimation model based on a Convolutional Neural Network (CNN). The model was trained on CNN using data from South Korea and aimed to be applied to North Korea. It employed the VGG16 model, a representative algorithm of CNN, for transfer learning. To account for seasonal differences in the images from daytime satellite data, a U-net was used for image adjustment. Furthermore, neighboring effects were incorporated to enhance the model's performance. The model fitting results indicated that the populations of the four major metropolitan cities in South Korea were estimated without significant differences from actual populations. The populations of Pyongyang and Kaesong in North Korea were also estimated to be similar to the 2008 census data, demonstrating satisfactory results."
초등학생 대상 인공지능 교육 프로그램 개발 및 적용:  CNN을 중심으로,2024,"['AI 교육', 'AI 원리', '이미지 인식', 'CNN', 'ADDIE', 'AI education', 'AI principle', 'Image Recognition', 'CNN', 'ADDIE']","본 연구에서는 초등학생을 대상으로 한 인공지능 교육 중 이미지 인식의 이해를 위한 교육 프로그램을 개발하고, 프로그램의 타당성과 효과를 검증하였다. 프로그램 개발은 ADDIE 모형에 기반하여 분석, 설계, 개발, 적용 및 평가/수정 단계를 거치면서 진행되었다. 먼저, 교육 프로그램 설계를 위해 CNN의 원리를 이해하기 위한 핵심 교육요소를 분석하고 이를 기초로 프로그램의 목표를 설정한 후, 총 9차시의 CNN 기반의 이미지 인식 인공지능 교육 프로그램을 개발하였다. 그 교육 프로그램은 일반적으로 어렵게 생각하는 CNN의 원리를 초등학교 학습자들에게 언플러그드 교수법을 적용하여 실제 체험하고 이해하며 활용하는 형태로 개발되었다. 개발된 교육 프로그램의 검증을 위해 1, 2차 델파이 조사를 진행하였다. 델파이 조사에서 제시된 검토 의견에 따라 수정된 교육 프로그램을 초등학교 5학년 학생 2개 학급 54명을 대상으로 적용하여 관찰 및 포트폴리오 평가를 통해 효과를 분석하였다.","In this study, an educational program was developed to understand the principle of image recognition among artificial intelligence education for elementary school students, and the validity and effectiveness of the program were verified. Program development was carried out through analysis, design, development, application, and evaluation/modification steps based on the ADDIE model. First, to design an educational program, we analyzed key educational elements to understand the principles of CNN and set the program's goals based on this, and then developed a CNN-based image recognition artificial intelligence education program for a total of 9 sessions. The educational program made it easier for elementary school learners to understand CNN's principles, which are generally considered difficult, by applying unplugged teaching methods, and developed them in the form of actual experience, understanding, and utilization. To verify the developed educational program, the first and second Delphi surveys were conducted and revised. The revised educational program was then applied to 54 students in two classes of fifth grade elementary school students and the effectiveness was analyzed through observation and portfolio evaluation."
CNN을 위한 사투리 음성 데이터의 Spectrogram 이미지 변환 적용의 POC 검증,2024,"['Dialect audio data', 'Spectrogram', 'Mel-spectrogram', 'CNN', 'RNN']","본질적으로 음성 데이터는 시계열(Time-series) 데이터이며, 따라서 음성 분류를 위해 ARIMA (Autoregressive integrated moving average) 또는 ES(Exponential smoothing) 알고리즘과 같은 시계열 알고리즘 또는 ML 측면에서는 RNN(Recurrent neural network)을 사용한다. 또 다른 방법으로 RNN 대신에 CNN(Convolutional neural network) 학습 과정의 입력으로 시계 열 숫자 배열이 아닌 오디오 데이터를 나타내는 이미지로 스펙트로그램(Spectrogram)을 사용하는 것이다. 본 논문에서는 시계열 데이터 분석에 RNN 대신에 CNN 기법을 활용하기 위한 음성 데이 터의 Spectrogram 분석과 Mel-spectrogram 분석 이미지를 입력 데이터의 이미지로 사용하며, 사투리 음성의 패턴을 추출하기 위한 CNN 모델을 제안한다. 또한, 제안된 모델의 파이썬 기반 프 로토타입에 의한 POC(Proof of concept)를 수행하여 가능성을 검증하였다.","In essence, audio data is time-series data. Therefore, for audio classification, time-series algorithms such as ARIMA (Autoregressive integrated moving average), ES (Exponential smoothing), or RNN (Recurrent neural network) in machine learning terms are commonly employed. Another method is to use a spectrogram as an image representing audio data rather than a time series number array as the input to the CNN(Convolutional neural network) learning process instead of RNN. In this paper, we use spectrogram analysis and mel-spectrogram analysis images of audio data as input data, using the CNN technique instead of RNN for time series data analysis, and we propose a CNN model to extract patterns of dialect audio. In addition, the feasibility was verified by performing a POC(Proof of concept) using a Python-based prototype of the proposed model."
음성 감정 인식에서의 어텐션 노이즈 감소를 위한CNN 기반의 Log-Mel 스펙트로그램 이미지 압축 기법,2024,"['Speech Emotion Recognition', 'Image Compression', 'Attention Mechanism', 'Transformer', 'Deep Learning']","본 논문은 음성 감정 인식에서 log-Mel 스펙트로그램을 기반으로 한 이미지 압축 기법을 제안하고, 이 기법이 어텐션 메커니즘을활용한 vision transformer 모델에서 성능 향상에 기여할 수 있음을 보인다. 특히, log-Mel 스펙트로그램은 음성 신호의 주파수특성을 잘 포착하여 음성 감정 인식에 유용하게 사용되는데, 본 연구에서는 이 스펙트로그램을 이미지 형태로 처리하면서 발생할수 있는 어텐션 노이즈를 효과적으로 감소시키는 방법을 제시한다. 핵심적인 아이디어는 CNN을 수평 커널로 사용하여 log-Mel 스펙트로그램 이미지의 해상도를 압축하고, 이를 통해 vision transformer 모델에서 중요한 패턴을 보다 효과적으로 학습하도록 돕는 것이다. 제안된 기법은 기존의 log-Mel 스펙트로그램을 128×1001 크기로 처리하고, 이 이미지를 128×129로 고정된 크기로압축하면서 임의의 이미지 보간이 수행되도록 설계되었다. 이러한 전처리 과정은 모델이 음성 감정 인식에서 유용한 특징을 보다잘 추출할 수 있도록 돕는다. 본 논문에서는 log-Mel 스펙트로그램의 주어진 특성에 맞게 CNN 기반의 압축 기법을 사용하여 스펙트로그램의 중요 정보를 보존하면서, vision transformer 모델의 어텐션 메커니즘에서 발생할 수 있는 노이즈를 최소화하는 방법을 제안한다. Crowd Sourced Emotional Multimodal Actors(CREMA) 데이터셋을 이용한 실험을 통해, 제안하는 기법이86.83%의 정확도를 나타내어 기존의 방법들보다 음성 감정 인식에서 더 뛰어난 성능을 보임을 확인하였다.","This paper proposes convolutional neural networks (CNN) based log-Mel spectrogram image compression methodfor attention noise reduction in speech emotion recognition (SER) and demonstrates how this method can contributeto improved performance in vision transformer models utilizing attention mechanisms. log-Mel spectrograms,which effectively capture the frequency characteristics of speech signals, are commonly used in SER tasks. In thisstudy, we present a method to reduce attention noise that may arise when processing these spectrograms asimages. The core idea is to use a CNN with horizontal kernels to compress the resolution of log-Mel spectrogramimages, thereby facilitating the vision transformer model's ability to learn important patterns more effectively. Theproposed approach processes the original log-Mel spectrograms at a size of 128×1001 and compresses them intoa fixed 128×129 resolution while performing random image interpolation. This preprocessing step aids the modelin better extracting relevant features for emotion recognition. This paper propose how the CNN-based compressionmethod preserves essential information from the log-Mel spectrograms while minimizing attention noise in thevision transformer model's attention mechanism. Through experiments using the Crowd Sourced EmotionalMultimodal Actors (CREMA) dataset, the proposed method achieved an accuracy of 86.83%, demonstrating superiorperformance in speech emotion recognition compared to existing methods."
이미지의 인지적 특징 정량화를 통한 CNN-ViT 하이브리드 미학 평가 모델,2024,"['Image aesthetic assessmet', 'Transformer', 'Convolutional neural network', 'color harmony', 'image processing']","본 논문에서는 이미지의 지역적 및 전역적 특징을 결합하여 이미지의 미학적 품질을 자동으로 평가할 수 있는 CNN-ViT 하이브리드 모델을 제안한다. 이 접근 방식에서는 CNN을 사용하여 색상 및 객체 배치와 같은 지역적 특징을 추출하고, ViT를 통해 전역적 특징을 반영하여 이미지의 미학적 가치를 분석한다. Color composition은 입력 이미지에서 주요 색상을 추출해 생성한 컬러팔레트를 CNN에 통과시켜 얻은 값이며, Rule of Third는 이미지 속 오브젝트가 삼등분할점에 얼마나 근접한지를 정량적으로 평가한 점수로 사용된다. 이러한 값들은 모델에 이미지의 주요 평가 요소인 색채와 공간 균형에 대한 정보를 제공한다. 모델은 이를 바탕으로 이미지의 점수와 색상, 공간의 균형 간에 연관성을 분석하며, 인간의 평가 분포와 유사한 점수를 추측하도록 설계되었다. 실험 결과, AADB 이미지 데이터베이스에서 스피어만순위상관계수(SRCC)에서는 0.716을 기록하여 순위 예측에서 더 일관된 결과를제공 했으며, 피어슨상관계수(LCC)에서도 0.72을 기록하여 기존 연구 모델보다 2~4% 정도 향상된 결과를 보였다.","This paper proposes a CNN-ViT hybrid model that automatically evaluates the aesthetic quality of images bycombining local and global features. In this approach, CNN is used to extract local features such as color andobject placement, while ViT is employed to analyze the aesthetic value of the image by reflecting global features.Color composition is derived by extracting the primary colors from the input image, creating a color palette, andthen passing it through the CNN. The Rule of Thirds is quantified by calculating how closely objects in the imageare positioned near the thirds intersection points. These values provide the model with critical information aboutthe color balance and spatial harmony of the image. The model then analyzes the relationship between thesefactors to predict scores that align closely with human judgment. Experimental results on the AADB image databaseshow that the proposed model achieved a Spearman's Rank Correlation Coefficient (SRCC) of 0.716, indicatingmore consistent rank predictions, and a Pearson Correlation Coefficient (LCC) of 0.72, which is 2~4% higher thanexisting models."
회전플랫폼을 이용한 AI CNN 기반의 조속기 불량 검출 시스템 개발,2024,"['convolutional neural networks (CNN)', 'defect detection', 'engine governor', 'xception', 'inception', '.']",,"In this study, an automated defect-detection system based on a convolutional neural network (CNN) for rapid governor rotation was developed and its performance was evaluated. In the proposed study, the governor was used in diesel engines to regulate the fuel injection amounts to regularly maintain the engine's rotational speed. The governor was rotated using a servomotor at speeds of 700, 1000, 2000, 2800, and 3200 rpm, and the degree of the governor’s opening was captured using a camera. CNN was employed to detect the defect states using captured images of the governor's opening degree. The experimental results compare and evaluate the performance using two CNN algorithms: Xception and Inception. This study demonstrates the application of CNN-based models to improve defect-detection systems in manufacturing processes. Accordingly, CNN algorithms extract and learn features from images, rendering them useful for the detection of various types of defects."
블라인드 통신 환경에서 CNN을 활용한 변조 및 채널 코딩 인식과 프로토콜 역공학 시뮬레이션 구현,2024,"['modulation recognition', 'channel coding recognition', 'Convolutional Neural Network (CNN)', 'protocol reverse engineering', 'blind communication', '변조 인식', '채널 코딩 인식', 'Convolutional Neural Network (CNN)', '프로토콜 역공학', '블라인드 통신']","본 논문에서는 송수신기가 통신 제원을 공유하지 않는 블라인드 통신 환경에서 CNN (Convolutional Neural Network)을 활용한 변조 및 채널 코딩 인식과 프로토콜 역공학에 대한 시뮬레이션 구현에 대하여 설명한다. 통신채널은 AWGN 채널로 가정하였으며 변조 방식으로는 BPSK, QPSK, 8PSK를 사용하고 채널 코딩은 (2, 1, 3), (2, 1, 4), (2, 1, 5) convolutional 코드를 사용한다. 딥러닝 모델 중 하나인 CNN을 사용하여 변조 및 채널 코딩방식을 인식한다. 또한 프로토콜 역공학 알고리즘인 contiguous sequence pattern 알고리즘을 사용하여 프로토콜분석을 수행한다. 본 논문의 시뮬레이션은 블라인드 통신 환경을 구현하여 변조 및 채널 코딩 인식, 프로토콜 역공학을 위한 데이터 생성 및 성능 평가 수단으로 활용 가능하다.","This paper describes the implementation of the simulation for modulation and channel coding recognition and protocol reverse engineering using CNN (Convolutional Neural Network) in the blind communication environment where transmitters and receivers do not share communication parameters. The communication channel is assumed to be AWGN channel, and BPSK, QPSK, and 8PSK are used as modulation schemes. For Channel coding, (2, 1, 3), (2, 1, 4), and (2, 1, 5) convolutional codes are used. CNN, a type of deep learning model, is utilized to recognize modulation and channel coding schemes. Additionally, the contiguous sequence pattern algorithm, a protocol revers engineering algorithm, is employed to analyze protocols. The simulation in this paper implements the blind communication environment and can be used as a means to generate data and evaluate the performance of modulation and channel coding recognition and protocol reverse engineering."
GPS 음영 지역에서 측위 성능 개선을 위한 CNN-GRU 기반 GPS/INS 융합 측위 시스템,2024,"['CNN-GRU', 'Kalman filter', 'Positioning', 'Localization', 'GPS shadow zone']","측위 기술은 자율주행과 UAV 등 실시간으로 이동하는 이동체의 안전한 운행을 위해 필수적으로 적용되는 기술이다. GPS와 INS를 결합한 기존 융합 측위 시스템은 높은 정확도를 제공하지만, GPS 음영지역에서는 INS 센서의 오차누적 문제로 인해 측위 성능이 저하되는 문제가 있다. 이를 해결하기 위해 본 논문에서는 CNN-GRU 기반 GPS/INS 융합 측위 시스템을 제안한다. 본 논문에서 제안한 시스템은 음영지역에서 CNN-GRU 모델을 통해 이동체 위치를 예측하고 예측값을 Kalman filter에 입력하여 GPS 음영지역에서도 높은 정확도로 위치를 추정한다. 제안된 모델 성능 검증을 위해 NCLT (North Campus Long-Term) 데이터셋으로 학습 및 시뮬레이션을 진행하였으며, 실험 결과 제안된측위 시스템은 기존 Kalman filter만을 이용한 측위 결과의 오차보다 음영 지역에서 최대 83.3% 감소한 측위 오차를얻었다.","Positioning technology is essential for the safe operation of moving objects in real-time, such as autonomous vehicles and UAVs. While traditional GPS/INS fusion positioning systems offer high accuracy, their performance degrades in GPS shadow zone due to the error accumulation problem of the INS. To address this issue, a GPS/INS fusion positioning system based on CNN-GRU is proposed in this paper. The proposed system predicts the position of the moving object in GPS shadow zone using a CNN-GRU model and inputs the predicted values into a Kalman filter to estimate the position with high accuracy even in GPS shadow zone. In order to validate the performance of the proposed model, training and simulations were performed on the North Campus Long-Term (NCLT) dataset. Experimental results show that the proposed positioning system reduced the positioning error in GPS shadow zones by up to 83.3% compared to the positioning results using only the traditional Kalman filter."
CNN-RNN 특징 추출을 활용한 LncRNA 서열 데이터 기반 질병 관련 LncRNA 예측 모델 개발,2024,"['long non-coding RNA', 'lncRNA', 'disease association prediction', 'CNN-RNN framework', 'sequence data', '.']","LncRNA(Long non-coding RNA)는 다양한 생물학적 과정에서 중요한 역할을 하며, 비정상적인 발현은 질병 발생의 주요 원인 중 하나이다. 따라서 lncRNA와 질병 간의 연관성을 밝히는 것은 질병 메커니즘을 이해하는 데 중요하다. 전통적인 생물학적 실험은 시간과 비용이 많이 들기 때문에, 딥러닝 기반 데이터 분석 기법이 이를 보완할 수 있다. 여러 방법들이 제안되었지만, 일반화 능력에 한계가 있다. 이러한 한계를 극복하기 위해, 본 논문에서는 CNN-RNN 구조의 특징 추출 모델을 사용하여 lncRNA 서열 데이터로부터 중요 특징 벡터를 추출하였다. 이 벡터를 통합된 LDA(LncRNA Disease Association) 데이터에 사용하여 lncRNA와 질병 간의 관계를 예측하였다. 실험 결과, CNN-RNN 구조를 통해 유용한 특징 벡터를 추출하여 lncRNA와 질병의 연관성을 효과적으로 예측할 수 있었다.","Long non-coding RNA(LncRNA) plays a crucial role in various biological processes, and its abnormal expression is a major cause of disease development. Therefore, elucidating the relationship between lncRNA and diseases is essential for understanding disease mechanisms. Traditional biological experiments are time-consuming and costly, so deep learning-based data analysis techniques can complement these methods. Although several approaches have been proposed, they all have limitations in generalization ability. To overcome these limitations, this paper employs a CNN-RNN feature extraction model to derive significant feature vectors from lncRNA sequence data. These vectors are then used to predict the relationship between lncRNA and diseases using integrated LncRNA Disease Association(LDA) data. Experimental results demonstrate that the CNN-RNN structure effectively extracts useful feature vectors, enabling accurate prediction of lncRNA-disease associations."
CNN과 GRU를 활용한 파일 유형 식별 및 분류,2024,"['Digital Forensics', 'File fragment type identification', 'File carving', 'CNN', 'GRU']","현대 사회에서의 디지털 데이터의 빠른 증가로 디지털 포렌식이 핵심적인 역할을 하고 있으며, 파일 유형 식별은 그 중에서 중요한 부분 중 하나이다. 파일 유형을 빠르고 정확하게 식별하기 위해서 인공지능을 사용한 파일 유형 식별 모델 개발 연구가 진행되고 있다. 그러나 기존 연구들은 일부 국내 점유율이 높은 파일을 식별할 수 없어, 국내에서 사용하기에 부족함이 있다. 따라서 본 논문에서는 CNN과 GRU를 활용한 더욱 정확하고 강력한 파일 유형 식별 모델을 제안한다. 기존 방법의 한계를 극복하기 위해 제안한 모델은 FFT-75 데이터셋에서 가장 우수한 성능을 보이며, 국내에서 높은 점유율을 가지는 HWP, ALZ, EGG와 같은 파일 유형도 효과적으로 식별할 수 있다. 제안한 모델과 세 개의 기존 연구 모델(CNN-CO, FiFTy, CNN-LSTM)을 서로 비교하여 모델 성능을 검증하였다. 최종적으로 CNN과 GRU 기반의 파일 유형 식별 및 분류 모델은 512바이트 파일 조각에서 68.2%의 정확도를, 4096바이트 파일 조각에서는 81.4%의 정확도를 달성하였다.",
모션블러 이미지에 대한 CNN 모델의 균열 검출 성능,2024,"['CNN (convolutional neural network)', 'Motion blur', 'Dataset', 'Crack detection', 'F1 score', 'CNN (convolutional neural network)', '모션블러', '데이터셋', '균열 검출', 'F1 score']",,"In this study, we analyzed the effect of motion blur on images used for detecting cracksin concrete tunnel linings on the performance of CNN models. Motion-blurred imageswith intensities ranging from 10 to 50 were generated on the Kaggle and KICT datasets.A semantic segmentation model with ResNet 18, ResNet 34, VGG 11, and Alex-Net as backbones for feature extraction was employed, all pre-trained on the U-Netarchitecture. The performance of these models in crack detection was then assessed.It was observed that detection accuracy decreased across all models as the intensity ofmotion blur increased for each dataset. Within the same model, the F1-score on theKICT dataset showed over 20% higher performance than on the Kaggle dataset. Thisstudy demonstrates that CNN-based crack detection performance is affected by thequality of the image data and that the crack detection accuracy of CNN models canvary depending on the quality of the dataset used in training."
다중 스펙트럼 CNN 기반 고해상도 컬러 영상 보간 기법,2024,"['컨볼루션 신경망', '초해상도', '네트워크', '딥러닝', 'CNN', 'super resolution', 'network', 'deep learning']","본 연구에서는 다중 스펙트럼 컨볼루션 신경망(CNN)을 활용하여 고해상도 컬러 이미지 보간을 수행하는 혁신적인 기법을 제안한다. 이 방법은 저해상도 이미지를 고해상도로 변환하는 과정에서 발생하는 색상 왜곡과 디테일의 손실을 최소화하고자 한다. 우리의 CNN 모델은 다양한 스펙트럼 데이터를 입력으로 사용하여 이미지 내의 복잡한 텍스처와 색상의 상관관계를 더 정확하게 파악한다. 이를 통해 더욱 선명하고 자연스러운 색상을 가진 고해상도 이미지를 생성한다. 개선된 성능을 달성하기 위해 초해상도 네트워크는 일반적으로 많은 수의 계층과 매개변수를 포함하며, 이는 모바일 기기에서의 적용을 제한한다. 이 문제를 해결하기 위해, 우리는 모바일 임베디드 시스템을 위한 경량 이미지 초고해상도를 위한 중첩 백 프로젝션 피드백 네트워크를 제안한다. 첫째, 백 프로젝션 피드백 블록과 연결 피드백을 사용하여 네트워크의 다양한 레벨에서의 상세 특징을 효율적으로 학습한다. 둘째, 경량 네트워크에 적합한 중첩 백 프로젝션을 제안하여 복원 오류를 최소화한다. 마지막으로, 융합 주목 모듈을 제안하여 정보가 풍부한 특징에 더 많은 주의를 기울인다. 테스트 결과, 제안된 기법은 기존의 단일 스펙트럼 기반 방법들과 비교하여 향상된 시각적 품질과 색상 정확도를 보여주었다.","In this study, we propose an innovative technique to perform high-resolution color image interpolation using a multispectral convolutional neural network (CNN). This method seeks to minimize color distortion and loss of detail that occur in the process of converting low-resolution images to high resolution. Our CNN model uses diverse spectral data as input to more accurately identify complex texture and color correlations within images. This creates high-resolution images with clearer, more natural colors. To achieve improved performance, super-resolution networks typically include a large number of layers and parameters, which limits their application in mobile devices. To solve this problem, we propose a nested back-projection feedback network for lightweight image super-resolution for mobile embedded systems. First, it uses back-projection feedback blocks and connection feedback to efficiently learn detailed features at various levels of the network. Second, we minimize restoration errors by proposing nested back projection suitable for lightweight networks. Finally, we propose a fusion attention module to pay more attention to information-rich features. Experimental results showed that the proposed technique showed improved visual quality and color accuracy compared to existing single spectrum-based methods."
전이학습 기반 CNN-LSTM을 통한 항공기 터보팬 잔여 유효 수명 예측,2024,"['고장 예지 및 건전성 관리', '잔여 유효 수명 예측', 'CNN-LSTM', '전이학습', 'C-MAPSS 데이터세트', 'Prognostics and Health Management', 'Remaining Useful Life Prediction', 'CNN-LSTM', 'Transfer Learning', 'C-MAPSS Dataset']",,"The objective of research in the field of prognostics and health management is to predict the Remaining Useful Life of aircraft engines,a critical component of analysis within this domain. Nevertheless, there are difficulties in acquiring dependable failure information, andthe limited availability of defect data hinders the development of predictive models. Current data augmentation techniques are utilizedto enhance the insufficient defect data; however, the heuristic approaches might oversimplify the data characteristics, ultimately decreasingpredictive accuracy. This study suggests a hybrid model that combines Transfer Learning, specifically integrating Convolutional NeuralNetworks (CNN) and Long Short-Term Memory (LSTM). The hybrid CNN-LSTM model integrates the CNN’s feature extraction capabilitieswith the LSTM’s long-term time series learning capacity, facilitating the representation of intricate dynamic characteristics and temporalfluctuations in aircraft engine sensor data. The performance of predictive techniques is enhanced by applying data learned from varioussource domains to target domain data through transfer learning. The results obtained by applying this model to the C-MAPSS aircraftengine simulator dataset developed by the National Aeronautics and Space Administration (NASA) corroborate the idea that employinga pre-trained model through transfer learning improves predictive accuracy in comparison to the standard mixed model. Furthermore,the proposed model demonstrates improved predictive abilities when compared to various leading predictive models in the PHM field."
CNN을 이용한 3상 유도전동기 ITSC 진단의 효율적인1차원 전류 신호 구성 및 Encoding방법,2024,"['Induction Motor', 'ITSC', 'CNN', 'GAF', 'SWM']","본 논문에서는 CNN을 이용한 3상 유도모터 ITSC(Inter-Turn Short Circuit) 고장진단에 있어서, 전류 데이터를 이용한 고장진단 및 효율적인 이미지 encoding 방법을 제안하도록 한다. 진동, 소음센서를 이용한 방법과 달리 전류를 이용하는 방법은 데이터의 손실이 낮을 수 있다는 장점은 있지만, 3상 신호로 인해 CNN의 채널 수 증가의 부담이있다. 이에 D-Q 동기좌표계의 D축성분만의 데이터를 활용하여 채널 부담을 줄이고, 효율적인 입력 이미지 구성 방법을 알아보고자 SWM(Slide Window Method)과 GAF(Gramian Angular Field)방식을 비교하도록 하였다. 데이터는 무부하부터 전부하까지 전체 변화를 고려하였으며, 그 결과, GAF방식은 약 74%, SWM방식은 약 65%로, GAF방식이 약 9%의 높은 정확도를 보임을 알 수 있었다. 또한, 학습된 속도에있어서 약 14.74[s]로 전체 학습 시간대비 차이가 없었으며, 100 epoch 이하에서는 빠른 속도로 학습이 가능함을 알 수 있었다","This paper proposes an efficient fault diagnosis method for ITSC(Inter-Turn Short Circuit) in three-phaseinduction motors using CNN. By utilizing only the D-axis component of the D-Q synchronous coordinatesystem, it compares SWM(Slide Window Method) and GAF(Gramian Angular Field) methods for image encoding.Results show GAF achieving ~74% accuracy, while SWM achieves ~65%, indicating GAF’s superiority by 9%.Learning time (~14.74s) remains consistent, particularly with epochs ≤ 100, showcasing faster learning."
CNN을 이용한 디스크 확산법의 억제 영역 자동 감지 모델 개발,2024,"['CNN', 'disk diffusion method', 'inhibition zone detection', 'antibiotic resistance', 'image processing', 'CNN', '디스크 확산법', '차단 영역 감지', '항생제 내성', '이미지 처리']","항생제 내성 및 효과를 확인하기 위한 디스크 확산법 실험에서 차단 영역을 정확하고 효율적으로 감지하기 위해 Convolutional Neural Network(CNN)을 활용한 모델을 개발하였다. 다양한 실험 환경을 고려하여 훈련 데이터를 자동으로 생성하였으며, 과적합을 방지하기 위해 디스크 이미지와 차단 영역에 대한 데이터 증강(augmentation)을 수행하였다. 개발된 모델은 입력으로 3채널의 RGB 이미지를 받아 1채널의 흑백 이미지를 출력하며, 최종 정확도는 98.17%를 달성하였다. 모델의 출력 결과를 바탕으로 Hough Circle Detection 알고리즘을 적용하여 배지 내 디스크의 위치를 정확히 감지할 수 있었고, 감지된 디스크 주변의 색상 변화를 분석하여 차단 영역의 크기를 파악할 수 있었다. 본 연구에서 개발한 모델을 활용하면 기존의 수작업으로 이루어지던 디스크 확산법 결과 분석을 자동화할 수 있어 항생제 내성 및 효과 실험의 효율성과 정확성을 크게 향상시킬 수 있을 것으로 기대된다. 이는 항생제 내성 연구 및 신약 개발 분야에서 유용하게 활용될 수 있을 것이다.","A Convolutional Neural Network (CNN) model was developed to accurately and efficiently detect inhibition zones in disk diffusion tests for assessing antibiotic resistance and efficacy. Training data was automatically generated considering various experimental conditions, and data augmentation was performed on disk images and inhibition zones to prevent overfitting. The developed model takes 3-channel RGB images as input and outputs 1-channel grayscale images, achieving a final accuracy of 98.17%. By applying the Hough Circle Detection algorithm to the model's output, the position of disks in the culture medium could be precisely detected, and the size of the inhibition zone could be determined by analyzing color changes around the detected disks. The model developed in this study is expected to significantly improve the efficiency and accuracy of antibiotic resistance and efficacy experiments by automating the analysis of disk diffusion test results, which was previously done manually. This can be usefully applied in the fields of antibiotic resistance research and new drug development."
CNN 기반 인코더와 Transformer 기반 인코더의 이미지 캡셔닝 성능 비교 분석,2024,"['image captioning', 'residual network 50', 'visual geometry group-16', 'vision transformers', 'shifted window transformer', '.']","이미지 캡셔닝은 이미지의 특징을 추출하여 이미지를 인식하고 자연어 처리와 결합하여 이미지에 대한 설명을 생성하는 작업이다. 이미지 캡셔닝 결과는 때때로 부자연스러운 텍스트를 생성한다. 이러한 문제의 원인을 정확하게 파악하기 위해 인코더들의 성능을 비교 실험한다. 이미지 캡션 생성 과정은 인코더, 디코더 구조를 가진다. 인코더에서 얻어지는 이미지 특징 추출 결과에 따라 디코더에서 생성되는 텍스트에 많은 영향을 미친다. 그에 따라 CNN 계열의 Resnet50, VGG-16과 트랜스포머 계열의 비전 트랜스포머, 스윈 트랜스포머 인코더의 성능을 비교하여 캡션 생성에 있어서 결정적인 영향을 주는지를 분석한다. 정성 및 정량 평가한 결과를 수치화하고 그래프 및 표로 제시하여 CNN 계열과 트랜스포머 계열의 인코딩 결과를 비교 분석하였다.","Image captioning involves extracting features from an image to recognize its content and combining them with natural language processing to generate a description of the image. However, the results of image captioning sometimes generate unnatural text. To accurately identify the cause of this issue, a comparative experiment of various encoders’ performance is conducted. The image caption generation process employs an encoder-decoder architecture. Since the text generated by the decoder is heavily influenced by the results of image feature extraction obtained from the encoder. This study compares the performance of CNN-based encoders, such as ResNet50 and VGG-16, with Transformer-based encoders, like Vision Transformer and Swin Transformer, to analyze whether they have a decisive impact on caption generation. This study quantified the results of the qualitative and quantitative evaluation and presented them in graphs and tables to compare and analyze the encoding performance between CNN-based and Transformer-based models."
휴대용 NIR 분광기와 CNN을 이용한 제품의 스테인리스강 등급 분류 방법,2024,"['Deep Learning', 'NIR Spectrometer', 'CNN', 'Stainless steel', 'STS Grade', 'CNN', '딥러닝', '근적외선 분광계', '스테인리스강', 'STS 등급']",,"This paper proposes a method for classifying the grade of stainless steel using a portable NIR(Near Infrared Ray) spectrometer and a CNN(Convolutional Neural Network) deep learning model. Traditionally, methods for classifying stainless steel grades have included chemical analysis, magnetic testing, molybdenum spot tests, and portable XRF devices. In addition, a classification method using a machine learning model with element concentration and heat treatment temperature as parameters was presented in the paper. However, these methods are limited in their application to everyday products, such as kitchenware and cookware, due to the need for reagents, specialized equipment, or reliance on professional services. To address these limitations, this paper proposes a simple method for classifying the grade of stainless steel using a NIR spectrometer and a CNN model. If the method presented in this paper is installed on a portable device as an on-device in the future, it will be possible to determine the grade of stainless steel used in the product, and to determine on-site whether a product made of low-cost material has been disguised as a high-cost product."
실시간 지하공동구 화재 온도 예측을 위한 Residual CNN-LSTM 모델 연구,2024,"['underground utility tunnel', 'fire temperature forecasting', 'residual learning', 'convolutional neuraln Network(CNN)', 'long-short term memory(LSTM)', '지하공동구', '화재 온도 예측', '잔차 학습', '합성곱 신경망', '장단기 메모리']",,"Underground utility tunnels (UUTs) play major roles in sustaining the life of citizens and industries with regard to carrying electricity, telecommunication, water supply pipes. Fire is one of the most commonly common disasters in underground facilities, which can be prevented through proper management. This paper proposes a hybrid deep learning model named Residual CNN-LSTM to predict fire temperatures. Scenarios of underground facility fire outbreaks were created and fire temperature data was collected using FDS software. In the experiment, we analyzed the appropriate depth of residual learning of the proposed model and compared the performance to other predictive models. The results showed that RMSE, MAE and MAPE of Residual CNN-LSTM are each 0.061529, 0.053851, 6.007076 respectively, making Residual CNN-LSTM far superior to other models in terms of its predictive performance."
"무용예술에서 생성형 인공지능의 역할과 가능성 - CNN, RNN 및 GAN 기술의 적용",2024,"['AI-generated dance', 'Generative AI', 'CNN', 'RNN', 'GAN', '인공지능 기반 무용', '생성형 인공지능', 'CNN', 'RNN', 'GAN']","본 연구에서는 생성형 인공지능의 기능적 특성을 분석하여 무용예술 도구로서의 역할과 가능성을 탐색하고자 한다. 데이터의 패턴 분석과 예측에 사용되는 인공신경망 모델인 CNN과 RNN, 그리고 원래 이미지 생성에 사용되었으나 현재는 움직임 생성까지 적용 범위를 확장하고 있는 GAN의 기능적 구조를 검토한다. 이를 통해 생성형 인공지능이 안무 생성, 무용 훈련, 무보 기록 체계 개선 등에 어떠한 혁신적 변화를 가져올 수 있는지 논의한다. 궁극적으로, 생성형 인공지능 기술의 급격한 발전에 따라 그 영향력이 더욱 확대될 것으로 예상되므로 무용 창작가들에게 이 기술을 실질적으로 활용할 수 있는 유용한 방향성을 제공하고자 한다.","This study explores the role and potential of generative AI as a tool in dance by analyzing key neural network models, including CNN, RNN, and GAN. Initially used for image generation, GANs now extend to movement generation. The research discusses how these models can innovate choreography, dancer training, technical movement analysis, and dance notation. As generative AI rapidly evolves, its impact is expected to grow, and this study aims to provide practical direction for dance creators to effectively utilize these technologies in their work."
CNN–RNN을 이용한 시뮬레이션 기반 항공기 자세 추정 연구,2024,"['deep learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)', 'aircraft attitude estimation', '.']",,"Recent advances in deep learning have led to the widespread use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) across various fields. For aircraft attitude estimation, CNNs can effectively extract spatial features from images, whereas RNNs model temporal continuity for more accurate predictions. This study proposes a hybrid method that combines CNN and RNN architectures to improve the accuracy and stability of real-time aircraft attitude estimation. CNN extracts spatial information from each frame, and the RNN captures the temporal dependencies to predict attitude changes. A dataset from the X-Plane 11 simulator collected under diverse environmental conditions was used to train the model. The proposed approach achieved high accuracy based on performance metrics, such as the mean absolute error, root mean square error, and R-squared, confirming its effectiveness. The simulation results demonstrated reliable attitude estimation even in complex environments, making it suitable for real-time autonomous flight systems. These findings suggest that the proposed model can significantly enhance the safety and reliability of such systems."
CNN을 이용한 방전 표면에 따른 방전 가공조건 예측,2024,"['Micro EDM', 'Micro machining', 'Deep learning', 'Convolutional neural network', 'Grad CAM', '미세 방전 가공', '미세 가공', '딥러닝', '합성곱신경망', '그래드캠']",,"CNN is one of the deep learning technologies useful for image-based pattern recognition and classification. For machining processes, this technique can be used to predict machining parameters and surface roughness. In electrical discharge machining (EDM), the machined surface is covered with many craters, the shape of which depends on the workpiece material and pulse parameters. In this study, CNN was applied to predict EDM parameters including capacitor, workpiece material, and surface roughness. After machining three metals (brass, stainless steel, and cemented carbide) with different discharge energies, images of machined surfaces were collected using a scanning electron microscope (SEM) and a digital microscope. Surface roughness of each surface was then measured. The CNN model was used to predict machining parameters and surface roughness."
생체정보 보호를 위한 CNN 기반의 홍채 지문 영역 분할,2024,"['Segmentation', 'Detection', 'Artificial Intelligence Learning', 'Biometric Information', 'CNN', '영역 분할', '감지', '인공지능 학습', '생체 정보', '합성곱 신경망 모델']","스마트 기기의 발달과 고해상도 이미징 기술의 대중화로 인해, 지문이 노출되거나, 화상 회의, 화상 통화 등 고화질 얼굴 사진에서 홍채 정보가 노출되고 있다. 스마트기기의 대중화는 일상적인 디지털 활동에서 무분별한 사진 공유로 인해, 개인의 생체정보인 지문이나 홍채가 노출되어 위조 및 악용될 가능성이 높아지고 있다. 이러한 문제를 해결하기 위해서 본 논문에서는 원본 이미지로부터 생체정보를 보호하고 보안을 강화할 목적으로 CNN의 영역 분할기법을 활용하여 이미지 내 지문과 홍채를 식별 보호하는 방안을 제안한다. 제안된 모델은 입력 이미지에서 지문 및홍채를 식별한 후 해당 영역에 블러 처리를 적용하며, 이를 원본 이미지와 결합하여 보안성을 강화한다. U-Net 및ResNet-34를 백본으로 사용한 모델 구조를 통해 학습 시간 및 성능을 비교한다.","With the development of smart devices and the popularization of high-resolution imaging technology, fingerprints arebeing exposed, and iris information is being exposed in high-definition facial photos such as video conferences and videocalls. The popularization of smart devices has increased the possibility of personal biometric information such asfingerprints and irises being exposed and forged and misused due to indiscriminate photo sharing in everyday digitalactivities. To solve this problem, this paper proposes a method to identify and protect fingerprints and irises in imagesby utilizing CNN's region segmentation technique for the purpose of protecting biometric information from the originalimage and enhancing security. The proposed model identifies fingerprints and irises in the input image, applies blurringto the corresponding regions, and combines them with the original image to enhance security. The learning time andperformance are compared through model structures using U-Net and ResNet-34 as backbones."
CNN 기반의 인간형 로봇의 낙상 판별 모델,2024,"['Humanoid robot', 'Fall detection', 'CNN', 'Image augmentation']",,"Humanoid robots, designed to interact in human environments, require stable mobility to ensure safety. When a humanoid robot falls, it causes damage, breakdown, and potential harm to the robot. Therefore, fall detection is critical to preventing the robot from falling. Prevention of falling of a humanoid robot requires an operator controlling a crane. For efficient and safe walking control experiments, a system that can replace a crane operator is needed. To replace such a crane operator, it is essential to detect the falling conditions of humanoid robots. In this study, we propose falling detection methods using Convolution Neural Network (CNN) model. The image data of a humanoid robot are collected from various angles and environments. A large amount of data is collected by dividing video data into frames per second, and data augmentation techniques are used. The effectiveness of the proposed CNN model is verified by the experiments with the humanoid robot MAX-E1."
무인항공기 비행 상태 예측을 위한 개선된 CNN-LSTM 혼합모델,2024,"['UAV(무인항공기)', 'CNN(합성곱 신경망)', 'LSTM(장단기 기억 신경망)', 'Loss of Control(조종 불능)', 'Prediction(예측)']","최근에 무인항공기의 사업화가 활발하게 추진됨에 따라 무인항공기의 안전성 확보를 위한 기술 개발에 많은 관심이 집중되고 있다. 일반적으로 무인항공기는 운용 중 급기동, 외란, 조종사 실수 등으로 인하여 조종 불능의 상태로 진입할 가능성을 지닌다. 조종 불능 상태로의 진입을 예방하기 위해서는 무인항공기의 비행 상태를 예측하는 것이 필수적으로 요구된다. 본 논문에서는 무인항공기의 비행 상태 예측 성능의 향상을 위하여 개선된 CNN-LSTM 혼합모델을 제안한다. 모의실험은 제안하는 모델을 이용한 예측 기법이 기존 예측 기법에 비하여 비행 상태 예측 성능이 우수하며 온보드 환경에서 실시간으로 운용됨을 보인다.","In recent years, as the commercialization of unmanned aerial vehicles (UAVs) has been actively promoted, much attention has been focused on developing a technology to ensure the safety of UAVs. In general, the UAV has the potential to enter an uncontrollable state caused by sudden maneuvers, disturbances, and pilot error. To prevent entering an uncontrolled situation, it is essential to predict the flight state of the UAV. In this paper, we propose a flight state prediction technique based on an improved CNN−LSTM hybrid mode to enhance the flight state prediction performance. Simulation results show that the proposed prediction technique offers better state prediction performance than the existing prediction technique, and can be operated in real-time in an on-board environment."
Batch Normalization을 결합한 CNN과 MNIST 데이터셋에서의 정확도 향상에 관한 연구,2024,"['MNIST dataset', 'Batch Normalization', 'Max Pooling', 'Fully connected layers', 'CNN', 'LeNet-5', 'MNIST 데이터셋', '배치정규화', '맥스 풀링', '완전연결계층', 'CNN', 'LeNet-5']",,"In this paper, we proposes a Convolutional Neural Networks(CNN) equipped with Batch Normalization(BN) for handwritten digit recognition training the MNIST dataset. Aiming to surpass the performance of LeNet-5 by LeCun et al., a 6-layer neural network was designed. The proposed model processes 28x28 pixel images through convolution, Max Pooling, and Fully connected layers, with the batch normalization to improve learning stability and performance. The experiment utilized 60,000 training images and 10,000 test images, applying the Momentum optimization algorithm. The model configuration used 30 filters with a 5x5 filter size, padding 0, stride 1, and ReLU as activation function. The training process was set with a mini-batch size of 100, 20 epochs in total, and a learning rate of 0.1. As a result, the proposed model achieved a test accuracy of 99.22%, surpassing LeNet-5's 99.05%, and recorded an F1-score of 0.9919, demonstrating the model's performance. Moreover, the 6-layer model proposed in this paper emphasizes model efficiency with a simpler structure compared to LeCun et al.'s LeNet-5 (7-layer model) and the model proposed by Ji, Chun and Kim (10-layer model). The results of this study show potential for application in real industrial applications such as AI vision inspection systems.It is expected to be effectively applied in smart factories, particularly in determining the defective status of parts."
CNN과 진동데이터를 활용한 산업용 로봇의 고장 진단,2024,"['Industrial Robot', 'Vibration Sensor', 'Deep Learning', 'Fault Diagnosis', 'CNN']",,"Products were typically produced using specialized equipment such as CNC machines, milling machines, and lathes in traditional manufacturing. However, modern manufacturing is increasingly attempting with technological advancements to leverage large industrial robots for machining, offering greater flexibility, efficiency, and a high degree of freedom throughout the entire production process. Additionally, the demand for industrial robots continues to rise as industries adopt smart factories. These robots are becoming larger, more precise, and faster, as they take over tasks previously requiring specialized equipment or skilled human operators. Where numerous robots are in operation in factories, ensuring a stable supply chain and maintaining operational uptime is crucial. Therefore, preparing for potential mechanical failures in each robot is necessary, and there is a growing need for technologies that enable real-time fault diagnosis and predictive maintenance. A large industrial robot used for machining was employed as a testbed for fault diagnosis in this study. The Vibration data was collected from various robot axes under both normal operating conditions and abnormal conditions, such as end-effector overloads and drive malfunctions. The collected vibration data was then preprocessed, and key features were analyzed and extracted. The extracted features were used to build a learning model, and in this study, the CNN (Convolutional Neural Network) algorithm was applied instead of k-NN (k-Nearest Neighbors) to diagnose defects occurring in the discontinuous movements of the robot, thereby improving accuracy."
파노라마방사선영상 CNN의 골다공증 판정:  전영역영상과 국한부위영상에서의 비교,2024,"['Osteoporosis', 'Panoramic radiograph', 'Neural network', 'Mandible']",,"This study aimed to investigate the difference that convolutional neural network(CNN) shows in the determining osteoporosis on panoramic radiograph by performing a paired test by inputting the original image and the limited image including the cortical bone of the posterior border of the mandible used by radiologists. On panoramic radiographs of a total of 661 subjects (mean age 66.3 years ± 11.42), the area including the cortical bone of the posterior part of the mandible was divided into the left and right sides, and the ROI was set, and the remaining area was masked in black to form the limited image. For training of VGG-16, panoramic radiographs of 243 osteoporosis subjects (mean age 72.67 years ± 7.97) and 222 normal subjects (mean age 53.21 years ± 2.46) were used, and testing 1 and testing 2 were performed on the original and limited images, respectively, using panoramic radiographs of 51 osteoporosis subjects (mean age 72.78 years ± 8.3) and 47 normal subjects (mean age 53.32 years ± 2.81). The accuracy of VGG-16 for determining osteoporosis was 97%, in the testing 1 and 100% in the testing 2. When determining osteoporosis on the original image, CNN showed sensitivity in a wide range of areas including not only the inferior cortical bone of the mandible but also the maxillary and mandibular cancellous bone, cervical spine, and zygomatic bone. When the same ROI including the lower inferior cortical border of the mandible of the osteoporosis group was applied and the sensitive region was compared between the original image and the limited image, the original image showed wider sensitive region in cancellous bone and cortical bone than on the limited image (p<.05). Since osteoporosis is a disease that affects throughout the skeletal system, this finding seems very valid."
3D CNN과 영상처리 기술을 융합한  한국어 독순술 시스템 개발,2024,"['Lip-Reading', '3D Convolutional Neural Network', 'Hearing impaired', 'Video Speech Recognition', 'Video Classifier', 'Multimodal']",,"In this paper aims to develop a lip reading system utilizing deep learning technology to enhance the quality of life for individuals with hearing impairments. Specifically, we sought to establish a speaker-independent lip reading model using a 3D convolutional neural network(3D CNN) and a video classifier. For the dataset, we utilized four lip reading videos from the AI-HUB lip reading speech recognition dataset, which included both expert and general participants in noisy environments. The data were segmented into clips for training purposes. The 3D CNN architecture effectively captured the spatiotemporal features of lip movements, while the video classifier applied a multimodal approach to fuse visual and auditory information. The training results achieved a loss of 0.002, a training loss of 0.013, and a training accuracy of 97.4%. This demonstrates the proposed deep learning-based lip reading system's potential for speaker independence and adaptability in noisy environments. In this paper presents a practical solution that can support communication and social integration for individuals with hearing impairments."
HOG 알고리즘과 CNN을 이용한 객체 검출 시스템에 관한 연구,2024,"['Image Processing', 'Objects Tracking', 'Histogram of Oriented Gradients(HOG)', 'Convolution Neural Network(CNN)']",,"For the purpose of predicting credit card customer churn accurately through data analysis Detecting and tracking objects in continuous video is essential in self-driving cars, security and surveillance systems, sports analytics, medical image processing, and more. Correlation tracking methods such as Normalized Cross Correlation(NCC) and Sum of Absolute Differences(SAD) are used as an effective way to measure the similarity between two images. NCC, a representative correlation tracking method, has been useful in real-time environments because it is relatively simple to compute and effective. However, correlation tracking methods are sensitive to rotation and size changes of objects, making them difficult to apply to real-time changing videos. To overcome these limitations, this paper proposes an object tracking method using the Histogram of Oriented Gradients(HOG) feature to effectively obtain object data and the Convolution Neural Network(CNN) algorithm. By using the two algorithms, the shape and structure of the object can be effectively represented and learned, resulting in more reliable and accurate object tracking. In this paper, the performance of the proposed method is verified through experiments and its superiority is demonstrated."
액션로더 모델 분류 및 불량 검출을 위한 CNN 기반의 검사 시스템 개발,2024,"['Action Loader', 'Deep Learning', 'Classification', 'Defect Detection', 'Xception', 'Inception']",,"In this paper, we propose an AI inspection system based on deep learning to analyze the product image of the action loader (linear actuator system) inside an automatic car door handle. The proposed system aims to classify the model of the action loader and detect its defects. In addition, the paper compares performance evaluation using CNN(Convolutionary Neural Networks)-based Xception and Inception models, respectively. Due to low defective image data, data augmentation and transfer learning techniques are applied to improve the performance. As an experimental result, Xception showed comparatively better results than Inception.These experimental results were confirmed using Accuracy, Precision, Recall, and F1-Score based on the Confusion Matrix performance indicator. The proposed CNN-based inspection system presents practical applicability in the field of automobile part classification and defect detection."
뇌-컴퓨터 인터페이스를 위한 뇌파 기반 보행 인식 분류 CNN-BiLSTM 모델 개발,2024,"['뇌-컴퓨터 인터페이스', '뇌파', '보행', '동적 환경', '합성곱 신경망', '양방향 장단기 메모리', 'Brain-computer interface (BCI)', 'Electro encephalo graphy (EEG)', 'Gait', 'Dynamic environment', 'Convolutional neural network (CNN)', 'Bidirectional long short-term memory (BiLSTM)']",,"Brain-computer interface (BCI) is a technology used in various fields to analyze electroencephalography (EEG) signals torecognize an individual's intention or state and control a computer or machine. However, most of the research on BCI is onmotor imagery, and research on active movement is concentrated on upper limb movement. In the case of lower limbmovement, most of the research is on the static state or single movements. Therefore, in this research, we developed adeep-learning model for classifying walking behavior(1: walking, 2: upstairs, 3: downstairs) based on EEG signals in adynamic environment to verify the possibility of classifying EEG signals in a dynamic state. We developed a model thatcombined a convolutional neural network (CNN) and a bidirectional long short-term memory (BiLSTM). The model obtainedan average recognition performance of 82.01%, with an average accuracy of 93.77% for walking, 76.52% for upstairs, and75.75% for downstairs. It is anticipated that various robotic devices aimed at assisting people with disabilities and theelderly could be designed in the future with multiple features, such as human-robot interaction, object manipulation, andpath-planning utilizing BCI for control."
GPNPU 아키텍처 설계 및 CNN을 이용한 성능 평가,2024,"['NPU', 'Deep Learning', 'CNN', 'Dataflow', 'FPGA']",,"The deep neural networks (DNN) models are applied to diverse fields due to its astonishing performance. The DNN processing requires a huge number of computations with a massive amount of data. To expedite the DNN processing, AI accelerators are typically used. However, most of the proposed accelerator architectures are customized and tailored for a specific type of DNNs. This paper presents a GPNPU (General-Purpose Neural Processing Unit) architecture for efficiently processing various DNNs with instructions optimized for inference. The instructions go through different pipeline stages according to the instruction types. The pipeline stall is avoided with separate register files and corresponding datapath. The GPNPU was designed using Verilog-HDL and ported to UltraScale+ FPGA on ZCU102. It operates at 200 MHz with 0.444 W power consumption. Compared to the baseline, our GPNPU reduces the LUT and Flip-Flop usages by 15.6% and by 0.9%, respectively. Our GPNPU outperforms baseline in terms of execution time and power consumption at the same operating frequency. Additionally, Tiling allows GPNPU to process the convolution operation iteratively with reduced code size and data memory, consequently lowering power consumption. The output stationary dataflow enhances the energy efficiency via data reuse."
드론 식별을 위한 CNN 기반 이미지 분류 모델 성능 비교,2024,"['Drones', 'Transfer learning', 'Image classification', 'Convolutional Neural Networks', 'Aerial targets', '드론', '전이 학습', '이미지 분류', '합성곱 신경망', '공중표적']","최근 전장에서의 드론 활용이 정찰뿐만 아니라 화력 지원까지 확장됨에 따라, 드론을 조기에 자동으로 식별하는 기술의 중요성이 더욱 증가하고 있다. 본 연구에서는 드론과 크기 및 외형이 유사한 다른 공중 표적들인 새와 풍선을 구분할 수 있는 효과적인 이미지 분류 모델을 확인하기 위해, 인터넷에서 수집한 3,600장의 이미지 데이터셋을 사용하고, 세 가지 사전 학습된 합성곱 신경망 모델(VGG16, ResNet50, InceptionV3)의 특징 추출기능과 추가 분류기를 결합한 전이 학습 접근 방식을 채택하였다. 즉, 가장 우수한 모델을 확인하기 위해 세 가지 사전 학습된 모델(VGG16, ResNet50, InceptionV3)의 성능을 비교 분석하였으며, 실험 결과 InceptionV3 모델이 99.66%의 최고 정확도를 나타냄을 확인하였다. 본 연구는 기존의 합성곱 신경망 모델과 전이 학습을 활용하여 드론을 식별하는 새로운 시도로써, 드론 식별 기술의 발전에 크게 기여 할 것으로 기대된다.","Recent developments in the use of drones on battlefields, extending beyond reconnaissance to firepower support, have greatly increased the importance of technologies for early automatic drone identification. In this study, to identify an effective image classification model that can distinguish drones from other aerial targets of similar size and appearance, such as birds and balloons, we utilized a dataset of 3,600 images collected from the internet. We adopted a transfer learning approach that combines the feature extraction capabilities of three pre-trained convolutional neural network models (VGG16, ResNet50, InceptionV3) with an additional classifier. Specifically, we conducted a comparative analysis of the performance of these three pre-trained models to determine the most effective one. The results showed that the InceptionV3 model achieved the highest accuracy at 99.66%. This research represents a new endeavor in utilizing existing convolutional neural network models and transfer learning for drone identification, which is expected to make a significant contribution to the advancement of drone identification technologies."
비대면 자동결제 시스템을 위한 CNN 기반 객체 검출기의 고처리량 및 전력 효율적인 FPGA 구현,2024,"['Artificial intelligence', 'Convolutional neural networks', 'Accelerator', 'Low-power']","2019년 말부터 시작된 코로나19로 인해 무인 소매 시장은 최근 몇 년간 큰 폭의 성장세를 보이며 향후 성장세를 이어갈 것으로 예상된다. 본 연구는 빠르게 확대되고 있는 무인 소매 시장의 저비용, 고성능 시스템 요구에 부응하기 위해 엣지 디바이스에 구현이 가능한 전력효율과 처리율이 높은 비대면 자동결제 시스템을 설계하는 것을 목표로 한다. 실제로, 본 논문은 경량 물체 감지 모델인 tiny-YOLOv3 가속기 IP를 설계하고 Xilinx Zynq Ultrascale+ MPSoC ZCU102 Evaluation Kit에 주변 장치를 구성함으로써 실제 비대면 자동결제 환경에서 소비자들의 구매 품목을 식별하여 자동결제가 가능한 비대면 자동결제 시스템을 구축했다. 제안하는 tiny-YOLOv3 가속기 IP를 포함한 비대면 자동결제 시스템은 여러 이미지 추론 과정에서 5.04W의 전력만을 소비하며 137.22GOP/s의 처리량을 달성했다. 결과적으로, 제안한 시스템은 엣지 디바이스를 기반으로 비대면 결제 시스템을 구축하고자 하는 무인 소매 시장 참가자들의 시장 접근을 활성화할 수 있을 것으로 기대한다.","Since the onset of the COVID-19 pandemic, the unmanned retail market has experienced substantial growth and is projected to continue its upward trajectory. This research aims to address the demand for low-cost, high-performance systems in this rapidly expanding market by designing a power-efficient, high-throughput, contactless automatic payment system that can be implemented on edge devices. This paper presents the design of a lightweight object detection model, the tiny-YOLOv3 accelerator IP, and integrates it with peripheral devices on the Xilinx Zynq Ultrascale+ MPSoC ZCU102 Evaluation Kit. The objective is to establish a contactless automatic payment system capable of processing consumer purchases in a real-world environment. The proposed system consumes only 5.04W of power while achieving a throughput of 137.22GOP/s across multiple image inference tasks. The results indicate that the proposed system can significantly enhance market access for participants in the unmanned retail sector aiming to deploy contactless payment solutions."
부분  신장  절제술  계획을  위한  하이브리드 CNN-트랜스포머  네트워크를  활용한  신장  종양  분할,2024,"['신장  종양  분할', 'CT  영상', '하이브리드  네트워크', '합성곱  신경망', '트랜스포머', 'Kidney Tumor  Segmentation', 'CT  Image', 'Hybrid  Network', 'Convolutional Neural Network', 'Transformer']","신장암 치료를 위한 부분 신장 절제술에서 수술 계획을 위한 신장 종양의 정확한 크기와 위치 등의 정보가 필수적이다. 따라서 신장 종양을 정확하게 분할하는 것이 중요하지만, 종양이 주변 장기와 밝기값이 유사하고 위치 및 크기가 환자마다 다양하여 분할에 어려움이 있다. 본 연구에서는 신장 종양의 분할 성능 개선을 목표로, 영상 내 지역적 및 전역적 특징을 모두 고려할 수 있는 합성곱 신경망과 트랜스포머가 결합된 하이브리드 네트워크를 제안한다. 제안 방법은 UNETR++와의 비교 실험에서 다이스 유사계수 78.54%,  정밀도 85.07%로 전반적으로 우수한 성능을 보였다. 또한, 종양 크기별 분석에서는 UNETR++에서 관찰되는 과대 분할 및 이상치가 개선된 결과를 보였다.","In partial  nephrectomy  for  kidney  cancer  treatment, accurate  segmentation of  the  kidney tumor  is  crucial  for  surgical  plannin g,  as it provides essential information on  the  precise size  and  location of  the  tumor.  However,  it is challenging  due to the tumor’s similar intensity to surrounding  organs and  the  variability in its  location and size  across  patients. In  this  study,  we propose  a hybrid network that integrates  a convolutional neural  network and  a transformer  to  capture  both local  and  global features,  aiming  to  improve  the  segmentation performance of  kidney tumors.  We validated our  method  through comparative experiments with UNETR++,  outperforming it with a Dice Similarity Coefficient  (DSC)  of 78.54% and  a precision  of  85.0 7%.  Moreover, in  the  analysis  by  tumor size, our  method  demonstrated  improvements  by  reducing  over-segmentation and ou tlier cases  observed  in  UNETR++."
추론속도 향상을 위한 확장가능 멀티칩 CNN 가속기 설계 및 뉴럴네트워크 분할 기법,2024,"['Multi-chip', 'Convolution neural networks', 'Accelerator architecture']","컨볼루션 신경망(CNN)의 발전에 따라 신경망 모델의 크기가 급격히 커지고 있어 전체 CNN 네트워크를 단일 CNN 가속기 칩에 매핑하는 것이 점점 어려워지고 있다. 이를 해결하기 위해 본 논문에서는 다중 칩 CNN 가속기의 확장 가능한 아키텍처를 제안하며, 이는 나노미터 규모의 공정 기술을 사용한 거대한 가속기 설계 및 제조의 천문학적 비용을 피할 수 있게 한다. 다중 칩 접근 방식은 현대 신경망의 급격히 증가하는 크기를 수용하는 비용 효율적인 솔루션으로 간주된다. 이는 대규모 신경망을 여러 개의 소형 가속기 칩으로 분할하면 소형 가속기의 설계 노력을 줄이고 저비용 공정 기술을 사용하여 소형 칩을 제조할 수 있다는 관찰에 기인한다. 본 논문에서는 신경망을 여러 칩으로 분할하는 다양한 기법의 비교 분석을 제시하며, 출력 채널 기반 분할이 칩 간 데이터 전송 시간 측면에서 더 효율적임을 입증한다. 제안된 다중 칩 아키텍처의 성능 향상을 보여주기 위해, 객체 탐지 CNN 모델인 YOLOv5n을 목표로 한 예제 다중 칩 가속기를 설계하고, 두 개의 Xilinx VCU118 FPGA를 기반으로 한 다중 FPGA를 사용하여 구현하였다. 실험 결과, 두 개의 FPGA 구현은 단일 칩 구현에 비해 추론 속도가 70% 향상되는 동시에 지연 시간이 71% 감소함을 보여준다.","As Convolution Neural Networks (CNNs) have advanced, the size of neural network models has been rapidly growing, making it increasingly challenging to map an entire CNN network onto a single CNN accelerator chip. To address this issue, this paper presents a scalable architecture of multi-chip CNN accelerator which allows to avoid the astraunomic cost of huge accelerator design and fabrication using nano-meter scale process technology.  Multi-chip approach is considered an cost-efficient solution to accommodate the rapid growing size of modern neural networks. This is attributed to the observation that paritioning a large neural network in multiple accelerator chips of smaller size allows to reduce the design effort of smaller accelerator and to fabricaste the smaller chip using a less expensive process technology. This paper also presents comparative analysis of different paritioning techniques of a neural network into multiple chips, and demonstrates that an output-channel based partition is more efficient with respect to the data transfer time between the chips. To show performance improvement of proposed multi-chip architecture, we design an example multi-chip accelerator aimed for an object detector CNN model called YOLOv5n and implement it using a multi-FPGA based on two Xilinx VCU118 FPGAs. The experiment demonstrates that two-FPGA implementation achieves an improvement of inference speed by 70 % at the cost of latency decrease by 71 % compared with a single chip implementation."
CNN 모델과 Transformer 조합을 통한 토지피복 분류 정확도 개선방안 검토,2024,"['원격탐사', '딥러닝', '트랜스포머', 'Unet', '토지피복', 'Remote Sensing', 'Deep Learning', 'Transformer', 'Unet', 'Land Cover']","본 연구는 Transformer 모듈을 기반으로 다양한 구조의 모델을 구성하고, 토지피복 분류를 수행하여 Transformer 모듈의 활용방안 검토를 목적으로 하였다. 토지피복 분류를 위한 딥러닝 모델은 CNN 구조를 가진 Unet 모델을 베이스 모델로 선정하였으며, 모델의 인코더 및 디코더 부분을 Transformer 모듈과 조합하여 총 4가지 딥러닝 모델을 구축하였다. 딥러닝 모델의 학습과정에서 일반화 성능 평가를 위해 같은 학습조건으로 10회 반복하여 학습을 진행하였다. 딥러닝 모델의 분류 정확도 평가결과, 모델의 인코더 및 디코더 구조 모두 Transformer 모듈을 활용한 D모델이 전체 정확도 평균 약 89.4%, Kappa 평균 약 73.2%로 가장 높은 정확도를 보였다. 학습 소요시간 측면에서는 CNN 기반의 모델이 가장 효율적이었으나 Transformer 기반의 모델을 활용할 경우, 분류 정확도가 Kappa 기준 평균 0.5% 개선되었다. 차후, CNN 모델과 Transformer의 결합과정에서 하이퍼파라미터 조절과 이미지 패치사이즈 조절 등 다양한 변수들을 고려하여 모델을 고도화 할 필요가 있다고 판단된다. 토지피복 분류과정에서 모든 모델이 공통적으로 발생한 문제점은 소규모 객체들의 탐지가 어려운 점이었다. 이러한 오분류 현상의 개선을 위해서는 고해상도 입력자료의 활용방안 검토와 함께 지형 정보 및 질감 정보를 포함한 다차원적 데이터 통합이 필요할 것으로 판단된다.","This research aimed to construct models with various structures based on the Transformer module and to perform land cover classification, thereby examining the applicability of the Transformer module. For the classification of land cover, the Unet model, which has a CNN structure, was selected as the base model, and a total of four deep learning models were constructed by combining both the encoder and decoder parts with the Transformer module. During the training process of the deep learning models, the training was repeated 10 times under the same conditions to evaluate the generalization performance. The evaluation of the classification accuracy of the deep learning models showed that the Model D, which utilized the Transformer module in both the encoder and decoder structures, achieved the highest overall accuracy with an average of approximately 89.4% and a Kappa coefficient average of about 73.2%. In terms of training time, models based on CNN were the most efficient. however, the use of Transformer-based models resulted in an average improvement of 0.5% in classification accuracy based on the Kappa coefficient. It is considered necessary to refine the model by considering various variables such as adjusting hyperparameters and image patch sizes during the integration process with CNN models. A common issue identified in all models during the land cover classification process was the difficulty in detecting small-scale objects. To improve this misclassification phenomenon, it is deemed necessary to explore the use of high-resolution input data and integrate multidimensional data that includes terrain and texture information."
자막 검출 CNN 모델을 이용한 동의 및 비동의 동영상자동 분류 포렌식,2024,"['동의 및 비동의 동영상 분류', '자막 검출', 'CNN', '멀티미디어 포렌식', 'Agreed or Non-Agreed Video Classification', 'Caption Detection', 'CNN', 'Multimedia Forensics']","동영상을 이용한 디지털 범죄가 증가하고 있지만 방대한 데이터 규모로 인해 인력 및 자원 측면에서 분석에 제약이 있어서 멀티미디어 포렌식에 인공지능을 도입하는 추세이다. 본 논문에서는 동영상에 포함된 자막 검출을 기반으로 동의 및 비동의 동영상을 분류하여 포렌식 분석 대상을 선별하는 알고리즘을 제안한다. 동의 및 비동의 동영상의 기준을 정의하고 동영상을 세그먼트 단위로 분할하여 동영상 데이터셋을 구축하였다. 자막 검출을 위해서 CNN 모델을 설계하여 최적화를 수행한 후에 동영상에 적용하여 자막 검출 비율에 대한 임계값을 기준으로 동의 및 비동의 분류를 수행하였다. 또한 성능 향상을 위한 다양한 실험과 분석을 수행하였다. 그 결과에 따르면 설계한 자막 검출 CNN 모델은 98.1% 정확도를 보였고, 제안한 동의 및 비동의 동영상 분류 알고리즘은 95.9% 정확도를 나타냈다.","Digital crimes using video are increasing and hence artificial intelligence is being introduced because of limitations in analysis in terms of manpower and resources due to the vast amount of data. In this paper, we propose an algorithm to select videos for forensic analysis by classifying an agreed or non-agreed video based on detecting captions included videos. After defining the criteria for agreed and non-agreed video, a video dataset was constructed by dividing video into segments. A CNN model was designed and optimized for caption detection and then applied to the video to classify an agreed or non-agreed video based on the caption detection rate threshold. We also conducted various experiments and analyzes to improve performance. As a result, the designed caption detection CNN model showed 98.1% accuracy, and the proposed agreed or non-agreed video classification algorithm showed 95.9% accuracy."
리뷰 일관성을 이용한 BERT-CNN 기반 리뷰 유용성 예측 모델 개발,2024,"['리뷰 유용성 예측', '리뷰 일관성', 'BERT-CNN', '딥러닝', '전자상거래', 'Review Helpfulness Prediction', 'Review Consistency', 'BERT-CNN', 'Deep Learning', 'E-Commerce']","최근 온라인 리뷰의 수가 급증함에 따라 소비자들은 자신의 구매 결정에 도움이 되는 유용한 리뷰를 찾는 데 어려움을 겪고 있다. 이로 인해 소비자에게 유의미한 리뷰를 식별하여 제공하는 것이 중요해짐에 따라 리뷰 유용성 예측에 관한 다양한 연구가 지속적으로 진행되고 있다. 그러나 대부분의 연구는 리뷰 텍스트의 의미론적 특성을 추출하는 데 중점을 두었고 이에 수반되는 평점 정보를 예측 작업에 반영하지 않았다. 따라서 본 연구는 이러한 평점 정보를 리뷰 유용성 예측에 도입하고 리뷰 텍스트와 평점 간의 일관성을 바탕으로 예측하였다. 본 연구에서 제안한 BERTexCon(BERT-CNN text and rating consistency model for review helpfulness prediction)은 Feature Encoder와 Consistency Extraction 두 가지 모듈로 되어있다. Feature Encoder 모듈은 리뷰 텍스트와 평점 정보에서 특성을 추출하는 데 사용하고 Consistency Extraction 모듈은 정보 간의 일관성을 추출하는 데 사용한다. 특히, 본 연구는 BERT-CNN 모델을 활용하여 리뷰 텍스트 중에 실제 유용성에 크게 영향을 미칠 수 있는 특성을 바탕으로 예측 작업을 수행하였다. 본 연구는 Amazom.com에서 수집된 실제 소비자 리뷰를 바탕으로 제안된 BERTexCon 모델의 예측 성능을 측정하였다. 실험 결과를 따르면 본 연구에서 제안한 BERTexCon모델은 기존 연구에서 사용된 여러 모델과 비교했을 때 성능이 가장 우수함을 나타냈다. 따라서 본 연구에서 제안한 방법론은 다양한 전자상거래 플랫폼에서 적용될 수 있고 정교한 리뷰 유용성 예측 서비스를 제공할 수 있다.","With the rapid increase in online reviews, consumers struggle to find helpful reviews to help them make purchasing decisions. Therefore, various studies in the review helpfulness prediction have been proposed, demonstrating the importance of identifying and providing meaningful reviews to consumers. However, most studies focused on extracting the semantic features from review texts, the accompanying star ratings are not introduced in the prediction task. Therefore, this study aims to introduce such star rating information and predict review helpfulness from the perspective of review consistency between review texts and star ratings. The BERTexCon (BERT-CNN Text and Rating Consistency Model for Review Helpfulness Prediction) proposed in this study consists of feature encoder and consistency extraction. The feature encoder module is used to extract features from review text and star rating information, and the consistency extraction module is used to extract consistency between the information. Specifically, this study applies the BERT-CNN model to conduct predictions based on main features that can significantly affect helpfulness. To evaluate the prediction performance of the proposed BERTexCon model, this study used real-world online reviews collected from Amazon.com. The experimental results showed that the BERTexCon model performs best compared to the various models applied in previous studies. Therefore, the proposed methodology of this study can be applied to various e-commerce platforms and provide an accurate review helpfulness prediction service."
회전된 객체 분류를 위한 CNN 기법들의 성능 비교 분석,2024,"['Deep Learning', 'Filter Design', 'Steerable Filter', 'Group Equivariant Convolution', 'Group Equivariant CNN']",,"There are two kinds of well-known CNN methods, the group equivariant CNN and the CNN using steerable filters, which have excellent classification performances for randomly rotated objects in image space. This paper describes their mathematical structures and introduces implementation methods. We implement them, including the existing CNN, which have the same number of filters, then compare and analyze their performances by simulating them with the randomly rotated . According to the experimental results, the steerable CNN, which shows a classification improvement over the others, has a relatively small number of parameters to learn, so performance degradation is relatively small even when the size of the training dataset is reduced."
3차원 적층 구조 저항변화 메모리 어레이를 활용한CNN 가속기 아키텍처,2024,"['RRAM', 'neuromorphic computing', '3D-stacked', 'artificial neural network', 'artificial intelligence']","본 논문은 낮은 구동 전류 특성과 3차원 적층 구조로 확장시킬 수 있는 장점을 가진 3차원 적층형 이중 팁 RRAM을 CNN 가속기 아키텍처에 접목하는 연구를 수행한 논문이다. 3차원 적층형 이중 팁을 적층 형태의 병렬연결로 시냅스 어레이에 사용하여 멀티-레벨을 구현하였다. 이를 Network-on-chip 형태의 가속기 내에 DAC, ADC, 버퍼 및 레지스터, shift & add 회로 등 다양한 하드웨어 블록들과 함께 구성하여 CNN 가속기에 대한 시뮬레이션을 수행하였다. 시냅스 가중치와 활성화 함수의 양자화는 16-bit으로 가정하였다. 해당 가속기 아키텍처를 위한 병렬 파이프라인을 통해 CNN 연산을 시뮬레이션한 결과, 연산효율은 약 370GOPs/W를 달성하였으며, 양자화에 의한 정확도 열화는 3 % 이내가 되는 결과를 나타냈다.","This paper presents a study on the integration of 3D-stacked dual-tip RRAM with a CNN acceleratorarchitecture, leveraging its low drive current characteristics and scalability in a 3D stacked configuration. Thedual-tip structure is utilized in a parallel connection format in a synaptic array to implement multi-levelcapabilities. It is configured within a Network-on-chip style accelerator along with various hardware blocks suchas DAC, ADC, buffers, registers, and shift & add circuits, and simulations were performed for the CNN accelerator.The quantization of synaptic weights and activation functions was assumed to be 16-bit. Simulation results of CNNoperations through a parallel pipeline for this accelerator architecture achieved an operational efficiency ofapproximately 370 GOPs/W, with accuracy degradation due to quantization kept within 3%."
홀로그램 기록결과물의 품질 평가를 위한 CNN 모델 설계,2024,"['Deep learning', 'Convolutional neural network', 'Hologram quality assessment']","다양한 딥러닝(deep learning) 기술중에서 이미지 처리에 특화되어있는 CNN(Convolutional Neural Network) 기법은 합성곱 신경망으로 본 논문에서 필요한 이미지 분류 및 품질평가 작업에 필요한 신경망 알고리즘이다. 홀로그래피는 기록 광원을 이용하여 3차원 입체정보를 2차원적인 기록매질의 평면에 기록하고 재생하는 기술이다. 홀로그램 기록결과물은 아날로그 형태이기 때문에 지금까지는 기록된 결과물을 평가하는 과정이 수학적인 계산방법에 의해 검토되어 제한적이거나, 주관적이고 시각적인 검토에만 의존해왔다. 이러한 문제점들을 해결하기 위하여 정량적이고 객관적으로 홀로그램 기록결과물의 품질을 자동으로 평가하는 시스템을 구현하였다. 학습 데이터셋에 사용할 이미지를 등급에 따라 구분하여 1,200개를 새롭게 생성하였다. 그 이미지를 홀로그램의 품질평가에서 기록광원의 과다노출 또는 노출부족으로 구분할 수 있도록 6등급으로 구분하였다. 홀로그램 기록결과물의 촬영 이미지는 일반적인 디지털 사진의 촬영 이미지와는 다르기 때문에 품질평가의 기준을 다르게하여 구분하기 위해서 그 기준에 부합하여 CNN 모델을 설계하였다.","Among various deep learning technologies, CNN (Convolutional Neural Network) technique specialized in image processing is a convolutional neural network and is a neural network algorithm required for the image classification and quality evaluation tasks required in this paper. Holography is a technology that records and reproduces three-dimensional stereoscopic information on a two-dimensional flat surface of a recording medium using a recording light source. Since the holographic recording results are in an analog form, the process of evaluating the recorded results has been limited by mathematical calculation methods so far, or has been dependent on subjective and visual reviews. To solve these problems, a system that automatically evaluates the quality of holographic recording results quantitatively and objectively was implemented. We created 1,200 new images to be used in the learning dataset by classifying them according to grade. The images were classified into 6 grades so that they could be distinguished as overexposed or underexposed by the recording light source in the quality evaluation of the hologram. Since the captured images of holographic recording results are different from those of general digital photographs, a CNN model was designed to meet the criteria in order to distinguish them by differentiating the quality evaluation criteria."
"폐렴 및 정상군 판별을 위한 딥러닝 모델 성능 비교연구: CNN,VUNO,LUNIT 모델 중심으로",2024,"['Pneumonia diagnosis system', 'Chest X-ray image', 'CNN', 'VUNO', 'LUNIT']",,"The purpose of this study is to develop a CNN based deep learning model that can effectively detectpneumonia by analyzing chest X-ray images of adults over the age of 20 and compare it with VUNO, LUNIT acommercialized AI model. The data of chest X-ray image was evaluate based on accuracy,precision,recall,F1 score,and AUC score. The CNN model recored an accuracy of 82%, precision 76%, recall 99%, F1 score 86%, and AUCscore 0.7937. The VUNO model recordded an accuracy of 84%, precision 81%, recall 94%, F1 score 87%, andAUC score 0.8233. The LUNIT model recorded an accuracy of 77%, precision 72%, recall 96%, F1 score 83%, andAUC score 0.7436. As a result of the Confusion Matrix analysis, the CNN model showe FN (3), showing the highestrecall rate (99%) in the diagnosis of pneumonia. The VUNO model showed excellent overall perfomance with highaccuracy (84%) and AUC score (0.8233), and the LUNIT model showed high recall rate (96%) but the accuracy andprecision showed relatively low results. This study will be able to provide basic data useful for the development of apneumonia diagnosis system by comprehensively considers the perfomance of the medel is necessary to effectivelydiscriminate between penumonia and normal groups."
차량용 임베디드 컴퓨팅 환경 내 졸음운전 감지를 위한 3D-CNN 모델 검증 및 예측 시간 평가,2024,"['Drowsy Driving', '3D-CNN', 'Vehicle Embedded Systems', 'Classification', 'PyTorch', '졸음운전', '3차원 컨볼루션 네트워크', '차량 임베디드 시스템', '분류', '파이토치']",,"This study evaluates the operability and prediction time of a proposed drowsy driving detection methodto assess its feasibility for actual vehicles. We utilized the Jetson Nano 2GB Developer Kit to confirmthat our proposed 3D-CNN model operates effectively in this embedded computing environment. Wefound that the average classification time for detecting drowsy driving was approximately 0.42 s. Theproposed 3D-CNN model is therefore a practical technology capable of detecting driver drowsiness,enhancing safety in real vehicle environments."
Mask R-CNN 모델과 YOLO 모델을 활용한 차량 관점의 자율주행 주차 공간 인식 모델 개발,2024,"['주차 공간 인식', '자율주행', '주차장', 'Parking Space Recognition', 'Autonomous Driving', 'Parking Lot', 'Mask R-CNN', 'YOLO']",본 논문에서는 자율주행 자동차가 주차장에서 주차할 공간을 탐색하려고 할 때 주차 가능 공간을 인식할 수 있는 능력을 갖도록 하는 딥러닝 모델의 필요성을 제안하였다. 제안된 딥러닝 모델의 기능은 자율주행 중 차량 관점에서 주행 공간과 주차 가능 공간을 분할로 구별해 내는 공간 인식에 그 목적이 있다. 본 연구에서는 컴퓨터비전 분야에서 2단계검출 모델로 대표되는 Mask R-CNN 모델과 1단계 검출 모델로 대표되는 YOLO 모델을 전이 학습하여 만든 모델로 주차 가능 공간 인식에 적용할 것을 제안한다. 실내 대형 주차장에서 주차 공간 인식 실험을 두 모델의 출력 결과물을통해 확인해 봄으로써 본 연구의 유용성을 확인하였다.,"A deep-learning model that allows autonomous cars to recognize available parking spaces when attempting to search for spaces to park in parking lots is proposed herein.The proposed deep-learning model is designed to perform spatial recognition, i.e., partitioning the driving space and available parking space into segments from the perspective of the vehicle during autonomous driving. We propose the utilization of the Mask R-CNN model represented by a two-stage detection model in a computer vision field and the YOLO model represented by a one-stage detection model for the recognition of available parking spaces.The effectiveness of the proposed model is confirmed via a parking-space-recognition experiment in large indoor parking lots using the output results of the abovementioned two models."
"통합 CNN, LSTM, 및 BERT 모델 기반의음성 및 텍스트 다중 모달 감정 인식 연구",2024,"['Speech Emotion Recognition', 'CNN', 'LSTM', 'BERT', 'Multimodal Emotion Recognition', 'Deep Learning', '음성 감정 인식', 'CNN', 'LSTM', 'BERT', '다중 모달 감정 인식', '딥 러닝']",,"Identifying emotions through speech poses a significant challenge due to the complex relationship between language and emotions. Our paper aims to take on this challenge by employing feature engineering to identify emotions in speech through a multimodal classification task involving both speech and text data. We evaluated two classifiers—Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM)—both integrated with a BERT-based pre-trained model. Our assessment covers various performance metrics (accuracy, F-score, precision, and recall) across different experimental setups). The findings highlight the impressive proficiency of two models in accurately discerning emotions from both text and speech data."
컴퓨터 생성 홀로그램 기반의 문서보안 패턴 암호화 및 복호화를 위한 Pre-training De-noise CNN 기법,2024,"['Computer-generated hologram', 'Document security', 'Pre-training de-noise CNN', 'Encryption', 'Offline decryption']","본 논문은 컴퓨터 생성 홀로그램 암호화 기술을 문서 보안에 적용하여 문서의 암호화 및 보안을 강화하는 새로운 접근 방식을 제안한다. 현대 사회에서 문서의 위조 및 변조 위험이 증가하고 있는 상황에서, 제안된 시스템은 이러한 위협에 효과적으로 대응하기 위해 개발되는것이 목적이며, 이 시스템은 컴퓨터 생성 홀로그램 기술을 사용하여 문서를 암호화한 후, 문서의 가장자리나 특정 위치에 암호화된 데이터를 인쇄함으로써 고화질로 복원할 수 있는 기능을 제공한다. 이러한 복원 과정에서는 Pre-training De-noise CNN 기법을 활용하여 컴퓨터 생성 홀로그램의 품질을 크게 향상시키고, 이를 통해 문서의 원본 상태를 정확하고 신속하게 재현할 수 있다. 또한, 이 시스템은 인터넷 연결이 없는 오프라인 환경에서도 안정적으로 작동하며, 변조된 문서를 탐지하고 복호화할 수 있는 기능을 제공함으로써, 보안이 취약한 환경에서도 문서의 무결성을 보장할 수 있다. 이 연구는 문서의 안전성과 신뢰성을 유지하기 위한 포괄적이고 다목적 솔루션의 개발에 기여하며, 다양한 분야에서 응용될 수 있는 강력한 보안 기술로서의 가능성을 제시한다. 특히, 공공 기관, 금융, 법률 등 문서의 보안이 중요한 영역에서의 활용 가능성을 높이는 데 기여할 수 있을 것이다.","This paper presents a novel approach to enhancing document security by applying Computer-Generated Hologram (CGH) encryption technology to document encryption. The proposed system encrypts documents using CGH technology and prints the encrypted data on the edges of the document, enabling high-resolution restoration. To achieve this, the system employs a Pre-training De-noise CNN method to enhance the quality of the CGH and accurately reproduce the original state of the document. Additionally, the system supports offline decryption, ensuring tamper detection even in environments without internet connectivity. This research contributes to the development of a comprehensive and versatile solution for ensuring document security and integrity across various domains"
비휘발성 메모리 기반 IMC을 활용한단일 코어/다중 레이어 CNN 가속기 최적화,2024,"['Design space exploration', 'IMC', 'CNN', 'accelerator optimization', 'Non-volatile memory']","이 논문에서는 비휘발성 메모리 기반 In-Memory Computing(IMC)를 활용한 단일 코어/다중 레이어 CNN 가속기의 설계 초기단계에서 가속기의 성능과 면적을 예측하여 최적 메모리 데이터 플로우 및 인터페이스를 탐색할 수 있는 새로운 설계 공간 탐색기를제안한다. 이를 위해 다양한 메모리 레이아웃, 인터페이스, 매핑 방법을 탐색 공간에 포함하였다. 설계 옵션들을 완전 탐색 방식으로탐색하고, 성능과 면적을 예측하여 최적 메모리 데이터 플로우 및 인터페이스를 탐색했다. ResNet-18를 목표 네트워크로 설정하고,제안하는 설계 공간 탐색기를 통해 찾아낸 최적 메모리 데이터 플로우 및 인터페이스는 baseline 대비 면적 효율 측면에서 약 132배 향상이 가능함을 확인했다.","This paper presents a novel Design Space Explorer(DSE) that can predict the performance and area of asingle-core/multi-layer CNN accelerator using non-volatile memory-based In-Memory Computing(IMC) at an earlystage of design to explore the optimal memory data flow and interface. To achieve this, we include variousmemory layouts, interfaces, and mapping methods in the exploration space. Design options were explored in anexhaustive search manner, and the optimal memory data flow and interfaces were explored by predictingperformance and area. Using ResNet-18 as the target network, we found that the optimal memory data flow andinterface found by the proposed DSE can improve the area efficiency by about 132 times compared to thebaseline."
비파괴검사 품질향상을 위한 CNN 기반 용접결함 분류 및 검증에 관한 연구,2024,"['용접결함', '합성곱 신경망', '비파괴 검사', '육안검사', '방사선 탐상검사', 'Weld defect', 'Convolutional Neural Network (CNN)', 'Nondestructive test (NDT)', 'Visual Test (VT)', 'Radioisotope Test (RT)']","용접은 제조산업에서 가장 중요한 공정 과정이다. 하지만, 산업현장에서는 용접인력 부족 및 고비용의 문제와 전문가 수준의 기술을 습득까지의 오랜 경험이 요구되기 때문에, 제조공정에서 인공지능(AI)기술의 도입이 시급하다. 본 논문에서는 합성곱 신경망(Convolutional Neural Networks, CNN)기반 VGG 모델을 활용하여 제조공정에서 나타나는 용접결함에 대한 이미지 분류를 진행하고, 그 성능을 평가하고자 한다. 본 연구에서는 2가지 유형의 육안검사(Visual Test, VT)와 방사선 탐상검사(Radioisotope Test, RT)의 용접결함 이미지를 수집하였다. 용접결함은 4개의 용접결함(VT: 기공, 용입부족, 융합불량, 언더컷/RT:기공, 용입부족, 균열, 슬래그 혼입)과 1개의 정상으로 구성되어 있다. 용접결함 이미지는 원 데이터를 직접적으로 활용하였으며, 그 결과, VT, RT 이미지에 대하여 각각 98%, 92%의 성능을 확인하였다. 본 연구는 데이터 증강 등 데이터 정제 없이 진행한 점에 의의가 있으며, 향후 본 연구 결과를 기반으로 더 많은 자료수집을 통한 데이터의 확장과 더불어, 다양한 딥러닝 모델을 활용한 성능향상을 통하여 용접결함 검사 시스템 개발에 활용할 수 있을 것이다.","Welding plays a crucial role in the manufacturing industry. Nevertheless, the manufacturing industry urgently requires integrated artificial intelligence (AI) technology to enhance productivity because of the scarcity of human resources, the high costs involved, and the long time needed to attain an expert level. This study aims to classify welding defects using the EGG model based on CNN (Constitutional Neural Network). This study collected two types of welding defect images: a visual test (VT) and a radioisotope test (RT). There are four categories of welding defects: VT defects, which include porosity, incomplete penetration, lack of fusion, and undercut, and RT defects, which consist of cracks, porosity, lack of fusion, and slag inclusion. We also collected normal data. We input the raw image, not data p reprocessing, and achieve classification performances of 98% in VT and 92% in RT, respectively. Our finding is significant because it was conducted without data purification, such as data augmentation. We are expected to expand the data and improve performance by utilizing a variety of deep-learning models. In addition, our study helps to create a welding defect inspection system that can accurately detect surface defects in welds in future works."
EEG 스펙트로그램 이미지를 기반으로 한 행동 분류 모델의 2D-CNN,2024,"['합성곱 신경망', '뇌파', '스펙트로그램', 'BCI', '딥러닝', 'ResNet', 'Convolutional Neural Network', 'EEG', 'Spectrogram', 'BCI', 'Deep Learning', 'ResNet']","본 논문은 뇌의 전기적 활동을 기록하는 뇌파 데이터를 이용한 행동 분류 모델을 개발하는 데 초점을 맞춰 진행했다. 뇌파 신호의 잡음을 해결하기 위해 Notch filter(NF)와 Band-pass filter(BF)의 전처리 기법을 사용했다. 이후 신호를 단시간 Fourier 변환(STFT)을 이용하여 스펙트로그램으로 변환하여 시간과 주파수 활성화를 시각화했다. 스펙트로그램 이미지를 10초, 15초, 30초 간격으로 나누어 저장하여 시간적 유의성을 판단했다. 이 스펙트로그램을 기반으로 2D-CNN의 일종인 사전 학습된 ResNet18을 이용하여 모델을 구성했다. 실험 결과, 30초 간격으로 전처리를 적용한 데이터에서 NF와 Band-pass filter 모두 82.89%의 정확도를 보였으며, 이는 시간적 유의성을 가지는 것으로 나타났다. 이 연구는 뇌파 데이터의 효과적인 처리와 분류 성능 향상을 위한 전처리 방법의 중요성을 강조한다.","This paper focused on developing a behavior classification model using EEG data that records the electrical activity of the brain. To solve the noise of EEG signals, preprocessing techniques such as Notch filter(NF) and Band-pass filter(BF) were used. After that, the signal was converted into a spectrogram using Short Time Fourier Transform(STFT) to visualize time and frequency activation. The temporal significance was determined by dividing the spectrogram image into 10-second, 15-second, and 30-second intervals and storing it. Based on this spectrogram, a model was constructed using pre-trained ResNet18, a type of 2D-CNN. As a result of the experiment, both the NF and the BF showed accuracy of 82.89% in the data to which the preprocessing was applied at 30-second intervals, which was found to have temporal significance. This study emphasizes the importance of preprocessing methods for improving the effective processing and classification performance of EEG data."
CNN 모델을 활용한 검색 빈도 데이터 기반 신조어 분류 알고리즘,2024,"['newly-coined word', 'deep learning', 'classification', 'search frequency', 'naver datalab', '.']","SNS상에서 신조어의 사용이 일상화되고 있으며, 특히 사회집단별로 사용하는 신조어에도 차이가 있는 것으로 파악되고 있다. 본 연구에서는 급증하는 신조어의 출현 경향과 사례를 분석하여 신조어로 인해 발생하는 의사소통 문제를 개선하고자, 네이버 데이터랩에서 제공하는 검색 빈도 데이터를 활용하여 CNN 딥러닝 모델에 기반한 신조어 분류 알고리즘을 제안한다. 제안 알고리즘의 성능 분석을 위해 네이트판, DC인사이드, 네이버뉴스에서 크롤링한 데이터 셋에 적용한 결과, 약 82%의 신조어 분류 정확도를 확인할 수 있었다. 또한 오픈 소스 라이브러리인 Streamlit을 사용하여 신조어의 출현 빈도 순위와 관련 정보를 시각화하는 웹서비스 시스템을 구현하였다.","The use of newly coined words on social media has become commonplace, and we have observed that there are differences in the use of these words among different social groups. In this study, we analyze the trends and examples of the rapidly increasing appearance of newly coined words. In order to improve communication problems caused by newly coined words, we propose a newly coined word classification algorithm using a CNN deep learning model and search word frequency data provided by Naver Data Lab. When we applied this proposed algorithm to datasets crawled from Nate Pann, DC Inside, and Naver News, we were able to confirm an accuracy rate of approximately 82% for newly coined word classification. Furthermore, we have implemented a web application that visualizes the frequency of appearance rankings and related information of newly coined words using Streamlit, an open-source library."
CNN 이미지 분류 모델의 메타모픽 테스팅을 위한 복합 변형규칙 생성,2024,"['metamorphic testing', 'convolutional neural network', 'image classification models', 'composite variant rules', '메타모픽 테스팅', 'CNN', '이미지 분류 모델', '복합 변형규칙']",,"To evaluate the performance of the software, a testing process using a dataset that matches actual conditions is required. This study focuses on the evaluation test results and proposes metamorphic testing for image classification models using composite variant rules. The proposed testing applies both single variant rule and composite variant rules to the original test set. Then, the testing compares the output with the original test set's output to check whether the outputs violate the metamorphic relationship. By using the proposed testing, the test cases applied composite variant rules of noise and zoom in and out satisfied metamorphic relation. Through this, we can see that image classification models can maintain normal performance under conditions in which various variables are complexly reflected."
의료영상에서 웨이블렛 변환 기반 CNN 모형을 이용한 잡음제거,2024,"['딥러닝', '디노이징 컨볼루션 신경망', '의료영상', '잡음제거', '웨이블렛 변환', 'Deep learning', 'Denoising Convolutional Neural Network', 'Medical Image', 'Noise Reduction', 'Wavelet Transform']",,"In medical images such as MRI(Magnetic Resonance Imaging) and CT(Computed Tomography) images, noise removal has a significant impact on the performance of medical imaging systems.Recently, the introduction of deep learning in image processing technology has improved the performance of noise removal methods. However, there is a limit to removing only noise while preserving details in the image domain. In this paper, we propose a wavelet transform-based CNN(Convolutional Neural Network) model, namely the WT-DnCNN(Wavelet Transform-Denoising Convolutional Neural Network) model, to improve noise removal performance. This model first removes noise by dividing the noisy image into frequency bands using wavelet transform, and then applies the existing DnCNN model to the corresponding frequency bands to finally remove noise. In order to evaluate the performance of the WT-DnCNN model proposed in this paper, experiments were conducted on MRI and CT images damaged by various noises, namely Gaussian noise, Poisson noise, and speckle noise. The performance experiment results show that the WT-DnCNN model is superior to the traditional filter, i.e., the BM3D(Block-Matching and 3D Filtering) filter, as well as the existing deep learning models, DnCNN and CDAE(Convolution Denoising AutoEncoder) model in qualitative comparison, and in quantitative comparison, the PSNR(Peak Signal-to-Noise Ratio) and SSIM(Structural Similarity Index Measure) values were 36~43 and 0.93~0.98 for MRI images and 38~43 and 0.95~0.98 for CT images, respectively. In addition, in the comparison of the execution speed of the models, the DnCNN model was much less than the BM3D model, but it took a long time due to the addition of the wavelet transform in the comparison with the DnCNN model."
음향 데이터를 이용한 CNN 추론 윈도우 기반 산업용 직교 좌표 로봇의 고장 진단 기법,2024,"['Cartesian robot', 'Failure detection', 'Industrial robots', 'Deep learning', 'Coordinate', 'Anomaly', 'Abnormal', 'Anomalous situation']",,"In the industrial field, robots are used to increase productivity by replacing labors with dangerous, difficult,and hard tasks. However, failures of individual industrial robots in the entire production process may cause productdefects or malfunctions, and may cause dangerous disasters in the case of manufacturing parts used in automobilesand aircrafts. Although requirements for early diagnosis of industrial robot failures are steadily increasing, there aremany limitations in early detection. This paper introduces methods for diagnosing robot failures using sound-based dataand deep learning. This paper also analyzes, compares, and evaluates the performance of failure diagnosis using variousdeep learning technologies. Furthermore, in order to improve the performance of the fault diagnosis system using deeplearning technology, we propose a method to increase the accuracy of fault diagnosis based on an inference window.When adopting the inference window of deep learning, the accuracy of the failure diagnosis was increased up to 94%."
포트홀 탐지를 위한 생성형 AI 기반 데이터셋 구축과 CNN 모델 성능 평가,2024,"['생성형 AI', '프롬프트', '포트홀', '합성곱 신경망', '딥러닝', 'Generative AI', 'Prompt', 'Pothole', 'Convolutional Neural Network', 'Deep Learning']","차량의 증가와 기후 변화로 인한 포트홀 문제는 교통안전에 중대한 영향을 미치며, 이를 해결하기 위한 자동화된 탐지 기술이 표구된다. 본 논문에서는 도로의 포트홀 탐지의 효율성을 높이기 위해 생성형 AI 이미지를 활용한 새로운 접근법을 제안하였다. 실제 포트홀 이미지 대신, 생성형 AI 도구를 사용하여 제작된 가상 이미지를 활용하여 탐지 모델을 학습시켰다. Midjourney와 Playground 등 다양한 AI 도구로 생성된 이미지를 사용해 학습한 모델과 실제 이미지를 사용한 모델 사이의 성능을 비교했다. 연구 결과를 통해 생성형 AI가 포트홀 탐지 모델의 정확성과 효율성을 높이는 데 유용할 가능성이 있음을 확인하였고, 도로 유지보수의 효율성을 향상시킬 수 있는 방안을 제시하였다. 이를 통해 생성형 AI의 활용 가능성에 관한 기초를 마련하였고, 사회적 안전과 경제적 비용 절감에 기여할 것으로 기대한다.","The issue of potholes, exacerbated by the increase in vehicles and climate change, has significant implications for traffic safety, necessitating the development of automated detection technologies. In this paper, we propose a novel approach to improve the efficiency of pothole detection on roads by utilizing generative AI images. Instead of using real pothole images, a detection model was trained using virtual images generated by AI tools. The performances of models trained with images generated by various AI tools, such as Midjourney and Playground, were compared with those of model trained with real images. The results confirm that generative AI can enhance the accuracy and efficiency of pothole detection models and thereby offers potential solutions for improving road maintenance efficiency. Hence, this study lays the groundwork for the potential application of generative AI in road maintenance to enhance social safety and reduce economic costs."
"웹 방화벽 로그 분석을 통한 공격 분류: AutoML, CNN, RNN, ALBERT",2024,"['Web Attack Detection', 'WAF Log', 'TF-IDF', 'AutoML', 'Machine Learning']","사이버 공격, 위협이 복잡해지고 빠르게 진화하면서, 4차 산업 혁명의 핵심 기술인 인공지능(AI)을 이용하여 사이버 위협 탐지 시스템 구축이 계속해서 주목받고 있다. 특히, 기업 및 정부 조직의 보안 운영 센터(Security Operations Center)에서는 보안 오케스트레이션, 자동화, 대응을 뜻하는 SOAR(Security Orchestration, Automation and Response) 솔루션 구현을 위해 AI를 활용하는 사례가 증가하고 있으며, 이는 향후 예견되는 근거를 바탕으로 한 지식인 사이버 위협 인텔리전스(Cyber Threat Intelligence, CTI) 구축 및 공유를 목적으로 한다. 본 논문에서는 네트워크 트래픽, 웹 방화벽(WAF) 로그 데이터를 대상으로 한 사이버 위협 탐지 기술 동향을 소개하고, TF-IDF(Term Frequency-Inverse Document Frequency) 기술과 자동화된 머신러닝(AutoML)을 이용하여 웹 트래픽 로그 공격 유형을 분류하는 방법을 제시한다.","Cyber Attack and Cyber Threat are getting confused and evolved. Therefore, using AI(Artificial Intelligence), which is the most important technology in Fourth Industry Revolution, to build a Cyber Threat Detection System is getting important. Especially, Government’s SOC(Security Operation Center) is highly interested in using AI to build SOAR(Security Orchestration, Automation and Response) Solution to predict and build CTI(Cyber Threat Intelligence). In this thesis, We introduce the Cyber Threat Detection System by analyzing Network Traffic and Web Application Firewall(WAF) Log data. Additionally, we apply the well-known TF-IDF(Term Frequency-Inverse Document Frequency) method and AutoML technology to classify Web traffic attack type."
스펙트로그램을 이용한 CNN 음성인식 모델,2024,"['음성 인식', '심층 학습', '스펙트로그램', '단구간 푸리에 변환', '합성곱 신경망', 'Speech Recognition', 'Deep Learning', 'Spectrogram', 'Short Time Fourier Transform', 'Convolutional Neural Network']","본 논문에서는 명령어 음성신호의 인식 성능을 개선하기 위한 새로운 합성곱 신경망(CNN: Convolutional Neural Network) 모델을 제안한다. 이 방법은 입력신호의 단구간 푸리에 변환(STFT: Short-Time Fourier Transform) 후 스펙트로그램 이미지를 구하고 CNN 모델을 이용한 지도학습을 통하여 명령어 인식 성능을 개선하였다. 입력신호를 단시간 구간별로 푸리에 변환한 다음 스펙트로그램 이미지를 구하고 CNN 딥러닝 모델을 이용하여 다중 분류 학습을 수행한다. 이는 시간영역 음성신호를 특성이 잘 표현되도록 주파수영역으로 변환하고 변환 파라미터에 대한 스펙트로그램 이미지를 이용하여 딥러닝 훈련을 수행함으로써 명령어를 효과적으로 분류한다. 본 연구에서 제안한 음성인식시스템의 성능을 검증하기 위하여 Tensorflow와 Keras 라이브러리를 사용한 시뮬레이션 프로그램을 작성하고 모의실험을 수행하였다. 실험 결과, 제안한 심층학습 알고리즘을 이용하면 92.5%의 정확도를 얻을 수 있는 것으로 확인되었다.","In this paper, we propose a new CNN model to improve the recognition performance of command voice signals. This method obtains a spectrogram image after performing a short-time Fourier transform (STFT) of the input signal and improves command recognition performance through supervised learning using a CNN model. After Fourier transforming the input signal for each short-time section, a spectrogram image is obtained and multi-classification learning is performed using a CNN deep learning model. This effectively classifies commands by converting the time domain voice signal to the frequency domain to express the characteristics well and performing deep learning training using the spectrogram image for the conversion parameters. To verify the performance of the speech recognition system proposed in this study, a simulation program using Tensorflow and Keras libraries was created and a simulation experiment was performed. As a result of the experiment, it was confirmed that an accuracy of 92.5% could be obtained using the proposed deep learning algorithm."
CNN과 Attention을 통한 깊이 화면 내 예측 방법,2024,"['영상부호화', '화면 내 예측', '깊이 영상', 'video coding', 'intra prediction', 'depth picture', 'attention mechanism']",본 논문에서는 CNN과 Attention 기법을 통한 깊이 영상의 화면 내 예측 방법을 제안한다. 제안하는 방법을 통해 예측하고자 하는 블록 내 화소마다 참조 화소를 선택할 수 있도록 한다. CNN을 통해 예측 블록의 상단과 좌단에서 각각 수직방향과 수평 방향의 공간적 특징을 검출한다. 두 공간적 특징은 예측블록과 참조 화소들에 대한 특징을 예측하기 위해 각각 특징차원과 공간적 차원으로 병합된다. Attention을 통해 예측 블록과 참조 화소간의 상관성을 입력된 공간적 특징을 통해 예측한다. Attention을 통해 예측된 상관성은 CNN 레이어를 통해 화소 도메인으로 복원되어 블록 내 화소 값이 예측된다. 제안된 방법이 VVC의 인트라 모드에 추가되었을 때 화면 예측 오차가 평균 5.8% 감소하였다.,"In this paper, we propose an intra prediction method for depth picture using CNN and Attention mechanism. The proposed method allows each pixel in a block to predict to select pixels among reference area. Spatial features in the vertical and horizontal directions for reference pixels are extracted from the top and left areas adjacent to the block, respectively, through a CNN layer. The two spatial features are merged into the feature direction and the spatial direction to predict features for the prediction block and reference pixels, respectively. the correlation between the prediction block and the reference pixel is predicted through attention mechanism. The predicted correlations are restored to the pixel domain through CNN layers to predict the pixels in the block. The average prediction error of intra prediction is reduced by 5.8% when the proposed method is added to VVC intra modes."
Method of Predicting Braking Intention Using LSTM-CNN-Attention With Hyperparameters Optimized by Genetic Algorithm,2024,"['Advanced driver assistance systems', 'attention mechanism', 'braking intention prediction', 'CNN', 'LTSM', 'parametric tuning by genetic algorithm.']",,"Prediction of a driver’s braking intention enables the advanced driver assistance system (ADAS) to intervene in the braking system as early as possible, which may shorten braking distance and improve driving safety. This paper proposes a novel deep learning model called LSTM-CNN-Attention that combines a long short-term memory (LSTM) neural network, convolutional neural network (CNN), and Attention mechanism for extracting spatiotemporal features of multi-sensor data to improve prediction accuracy. The proposed model inherits both temporal and spatial feature extraction abilities from LSTM and CNN. The LSTM-CNN-Attention model has a parallel architecture, which enhances the feature extraction ability of the model for multi-sensor time series data and improves the prediction accuracy of the driver’s braking intention before the braking action. Furthermore, a driving simulator is set up to sample driving data for training and evaluating the proposed method. According to the results of the experiment, the model obtains up to 3.16% higher accuracy than the baseline models such as LSTM, CNN, and bidirectional LTSM (Bi-LSTM). Additionally, the influence of sliding window size and prediction horizon on the performance of the method is investigated. A method of tuning hyperparameters using the genetic algorithm is presented. The results demonstrate that the prediction accuracy increases by about 2% after being optimized by GA."
A Simple Reshaping Method of sEMG Training Data for Faster Convergence in CNN-Based HAR Applications,2024,['Convolutional neural network  · sEMG training data  · Human activity recognition  · Reshaping  · Faster convergence'],,"Convolutional neural networks (CNNs) have demonstrated excellent image recognition performance. CNNs have also been successfully extended to human activity recognition (HAR) applications, which aim to recognize the intent of human actions or diagnoses for clinical purposes using sEMG collected from the human body. It has been observed in the literature that using visual image training data to train a CNN is prone to having a square matrix in terms of shape in image recognition, while using sEMG training data to train CNN may inherently have a rectangular matrix with a small number of rows and a vast number of columns in terms of shape in HAR applications. This leads to the assumption that CNN may converge much faster in its learning if sEMG training data are reshaped to have a square matrix in terms of shape without losing any information from the original training data in the shape of a rectangular matrix. This study proposes a simple but very eff ective reshaping method to reshape sEMG training data in terms of shape from a rectangular matrix to a square matrix without losing any of the original information. Empirical studies confi rm that the proposed reshaping method enhances CNN learning such that it converges much faster regardless of optimizers and CNN models considered in the study. Our fi ndings strongly recommend the use of CNN learning in sEMG-based HAR application."
CNN Combined With a Prior Knowledge-based Candidate Search and Diffusion Method for Nighttime Vehicle Detection,2024,"['Candidate diffusion', 'candidate search', 'CNN', 'nighttime vehicle detection']",,"Driver assistance systems or smart headlamp technology require accurate vehicle detection in nighttimetraffic environments. This study proposes a novel nighttime vehicle detection (NVD) algorithm that can be appliedto these technologies, and the algorithm was implemented using image processing. Images taken on roads at nightare basically dark and lack information regarding vehicle appearance. Additionally, they contain significant noisecaused by various lights and the scattering or reflection of these lights. Therefore, it is difficult to increase theperformance of existing NVD methods. In addition, recent end-to-end convolutional neural network (CNN)-basedobject detection (OD) methods exhibit low NVD performance owing to their poor learning capability caused bylack of information and noise in the images. This study presents new methods to overcome the limitations ofNVD implementation: 1) We propose a candidate search and diffusion method based on the use of experimentalheuristics and hand-crafted features to utilize the characteristics related to light emitted from vehicle headlamps ortaillamps. 2) We propose a CNN method that combines the approaches applied in latest CNN-based OD method withthe proposed candidate search and diffusion method. To demonstrate the superiority of the proposed method, weconducted experiments and compared the proposed method to recent CNN-based OD methods. The experimentalresults demonstrated the higher detection performance of the proposed method compared to other methods. Thecode is available at https://github.com/sjg918/gj-nvd-diffusion/"
MLP와 CNN에 의한 하중 검출의 신뢰성 연구,2024,"['Multi Layer Perceptron', 'Convolutional Neural Network', 'Finite Element Analysis', 'Crawler Crane. Load detection']",,"Purpose: The detection of external and internal forces is important for the safety evaluation of mechanical structures. In this study, the results of using a multi-layer perceptron (MLP) and convolution neural network (CNN) to improve the detection reliability were analyzed.Methods: Load data collected from structural analysis of a crawler crane was used for training the MLP and CNN. A brief procedure for setting the learning conditions and functions for the MLP and CNN was presented and verified with quantitative figures.Results: The appropriate conditions for the functions used by the MLP and CNN for learning and recognizing the loads on the crawler crane were identified. Under these conditions, the maximum errors of the MLP and CNN were 0.24 and 1.45 tons, respectively. Thus, the MLP was more reliable at learning and recognizing the loads.Conclusion: Based on the results, MLPs and CNNs can effectively detect loads on mechanical structures and systems. Thus, load-detection methods based on MLPs and CNNs could improve the safety evaluation of mechanical structures."
"ConTL: Improving the Performance of EEG-based Emotion Recognition via the Incorporation of CNN, Transformer and LSTM",2024,"['EEG', '감정인식', 'ConTL', 'EEG', 'emotion recognition', 'hybrid-network', 'CNN', 'Transformer', 'LSTM']",,
CNN-aided timing synchronization in OFDM systems by exploiting lightweight cascaded mode,2024,['Timing synchronizationCascaded networkLightweight CNNOFDM system'],,"In orthogonal frequency division multiplexing (OFDM) systems, the existing timing synchronization (TS) methods are challenged by high computational complexity, large processing delay, and performance degradation in wireless scenarios. To alleviate these issues, a lightweight cascaded one-dimensional convolutional neural network (1-D CNN)-based TS scheme is proposed in this paper, which is developed from the joint perspective of considering cascaded mode and network lightweight. Specifically, we meticulously design two lightweight subnetworks. The first one is implemented with only one 1-D CNN layer due to the coarse timing offset task, which aims to reduce the search range of TS for the following subnetwork. Based on the narrowed search range of TS, the second subnetwork is also light-weighted with a two-layer 1-D CNN, which refines the estimation of timing offset. By jointly considering the cascaded mode and the lightweight 1-D CNN, the proposed scheme improves the TS correctness with reduced computational complexity and processing delay compared with the existing works. Simulation results validate the effectiveness and robustness of the proposed TS scheme given variant parameters."
CSI-Net: CNN Swin Transformer Integrated Network for Infrared Small Target Detection,2024,"['Hybrid encoder', 'infrared (IR) image', 'small target detection', 'swin transformer', 'UNet.']",,"In the realm of infrared (IR) small target detection, pinpointing blurry and low-contrast targets accurately is immensely challenging due to the intricate features of IR images. To tackle this, we introduce CSI-Net, a novel network architecture merging CNN and swin transformer. CSI-Net features a hybrid encoder design, blending encoder-decoder layout of UNet with swin transformer’s parallel execution alongside CNN. This amalgamation enables the network to capture local features and long-distance dependencies, enhancing its ability to accurately identify small targets. Leveraging hierarchical features of swin transformer, CSI-Net adeptly grasps contextual information crucial for small target detection. Moreover, CSI-Net employs full-scale skip connections over encoder-decoder and decoder-decoder, integrating multiscale CNN and swin transformer features to improve gradient propagation. Experimental results validate superiority of proposed method over traditional CNN and Transformer methods. At NUAA-SIRST, metrics like mIoU (0.7483), detection probability (0.9734), and false alarm rates (0.101 × 10−5) demonstrate significant improvement. Similarly, at NUDT-SIRST, values like mIoU (0.8887), detection probability (0.9894), and false alarm rates (0.431×10−5) show notable enhancement. The performance of network scales with dataset size, and its robustness is affirmed by the area under the ROC curve (AUC). Additionally, an ablation study validates the efficacy of hybrid encoder. Varying the presence of the parallel swin transformer module (PSM) reveals that its application enhances small target detection performance. The comprehensive evaluation shows that the swin transformer-enhanced UNet architecture effectively tackles the challenges of IR small target detection."
A Dynamic Warning Method for Electric Vehicle Charging Safety Based on CNN-BiGRU Hybrid Model,2024,"['BiGRU', 'charging safety', 'CNN', 'dynamic warning', 'electric vehicle.']",,"Electric vehicles (EVs) are prone to spontaneous combustion during charging, which can lead to safetyaccidents. Therefore, it is critical to accurately obtain the charging crises of EVs for timely fault identification andearly warning. This paper proposes a hybrid convolutional neural networks (CNN) and bi-directional gated recurrentunit (BiGRU) dynamic early warning method for EV charging safety. The method combines CNN and BiGRUfeatures to rapidly extract deep characteristics of EV charging data, establish charging safety prediction models,and train it with historical normal charging data. After training, real-time EV charging data is input for predictionto identify whether EV charging processes are irregular. Sliding windows are used with the residual analysis of thehistorical data forecast outcomes to generate the safety dynamic warning threshoThe energy rules. The experimentalresults demonstrated that the CNN-BiGRU model has a superior prediction effect and accuracy. With eRMSE andeMAPE as the evaluation criteria, the charging current is 0.2393 A and 0.1888%, the charging voltage is 0.3859 Vand 0.084%, and the temperature is 0.0543◦C and 0.1658%; The charging current, voltage and temperature data canbe used for early fault warning, which can be advance by 20.7 s, 20.2 s and 17.7 5 s, respectively."
1D-CNN-LSTM Hybrid-Model-Based Pet Behavior Recognition through Wearable Sensor Data Augmentation,2024,"['Behavior Recognition', 'CNN-LSTM', 'Data Augmentation', 'Deep Learning', 'Sensor data', 'Wearable Device']",,"The number of healthcare products available for pets has increased in recent times, which has prompted active research into wearable devices for pets. However, the data collected through such devices are limited by outliers and missing values owing to the anomalous and irregular characteristics of pets. Hence, we propose pet behavior recognition based on a hybrid one-dimensional convolutional neural network (CNN) and long short- term memory (LSTM) model using pet wearable devices. An Arduino-based pet wearable device was first fabricated to collect data for behavior recognition, where gyroscope and accelerometer values were collected using the device. Then, data augmentation was performed after replacing any missing values and outliers via preprocessing. At this time, the behaviors were classified into five types. To prevent bias from specific actions in the data augmentation, the number of datasets was compared and balanced, and CNN-LSTM-based deep learning was performed. The five subdivided behaviors and overall performance were then evaluated, and the overall accuracy of behavior recognition was found to be about 88.76%."
어텐션 기반 1D CNN을 활용한 이더리움 온체인 피싱 탐지 방법,2024,"['on-chain data', 'blockchain', 'attention', '1D CNN', 'ethereum', 'cryptocurrency', 'phishing']",,"The recent popularity of cryptocurrencies has led to a surge in illegal activities such as phishing and money laundering that take advantage of their characteristics. In particular, the number of online phishing and scam crimes using Ethereum is increasing. Therefore, there is a need for an effective way to detect Ethereum-based phishing and scams. In this paper, we propose an attentions-based 1D CNN model that can detect phishing activities by utilizing Ethereum on-chain data collected in real-time. The key feature of our model is the structure of a 1D CNN combined with an attentional mechanism that recognizes temporal patterns in transaction data to predict phishing. To evaluate the model, we compare it with existing deep learning models, and the results show that the proposed model has improved accuracy and AUC."
Fire Detection Based on Image Learning by Collaborating CNN-SVM with Enhanced Recall,2024,"['Vision sensing', 'Fire detection', 'Machine learning', 'Convolutional neural network (CNN)', 'Support vector machine (SVM)', 'Recall rate']",,"Effective fire sensing is important to protect lives and property from the disaster. In this paper, we present an intelligent visual sensingmethod for detecting fires based on machine learning techniques. The proposed method involves a two-step process. In the first step,fire and non-fire images are used to train a convolutional neural network (CNN), and in the next step, feature vectors consisting of 256values obtained from the CNN are used for the learning of a support vector machine (SVM). Linear and nonlinear SVMs with differentparameters are intensively tested. We found that the proposed hybrid method using an SVM with a linear kernel effectively increasedthe recall rate of fire image detection without compromising detection accuracy when an imbalanced dataset was used for learning. Thisis a major contribution of this study because recall is important, particularly in the sensing of disaster situations such as fires. In ourexperiments, the proposed system exhibited an accuracy of 96.9% and a recall rate of 92.9% for test image data."
CNN 기반의 유해화학물질 분류 및 판독을 위한 유해화학물질 학습데이터셋 구축 방법에 관한 연구,2024,"['Hazardous chemicals', 'Disaster', 'Training data', 'Dataset construction', 'Artificial intelligence', '유해화학물질', '재난재해', '학습데이터', '데이터셋 구축', '인공지능']","최근 화학산업이 발전함에 따라 다양한 화학사고가 증가하고 있다. 증가하는 화학사고에 대응하고자 인공지능기술을 접목한 유해화학물질 사고대응 기술에 대한 다양한 연구가 수행되고 있다. 영상 및 이미지 기반의 인공지능 유해화학물질 판독시스템은 사고 유해화학물질의 정확한 판독을 위한 충분한 학습이 가능한 양의 학습데이터가필요하다. 그러나, 유해화학물질이 가지는 위험성으로 인해 데이터 구축에 어려움이 있어 현재 유해화학물질 판독을 위한 인공지능 연구용 학습데이터는 매우 부족하다. 따라서 본 논문에서는 물질의 상태, 시각적 특징의 유무등 유해화학물질 및 화학사고의 특성을 반영한 인공지능 학습데이터셋 구축 방법을 제안한다. 유해화학물질 및 화학사고의 특성에 따른 학습데이터셋 구축 방법을 따라 자체 유해화학물질 실험을 통한 원시데이터 수집 및 확보, 데이터 전처리 및 가공, 학습데이터의 어노테이션 과정을 거쳐 유해화학물질 9종에 대한 학습데이터셋 약 20만장을 구축하였다. 구축된 데이터셋은 학습과 검증을 위해 8:1:1의 비율로 나눠 학습, 검증, 테스트데이터로 활용하였다. CNN에 기반한 유해화학물질 판독의 결과로 평균 약 90%의 유해화학물질 판독 정확도가 도출되었고, 판독결과는 실제 화학사고 현장에서 사고물질을 추정해 줌으로써, 현장대원에게 사고물질에 대해 적절하고 신속한 대응을 지원할 수 있을 것으로 기대된다.","Recently, as the chemical industry develops, various chemical accidents are increasing. In order to respond to the increasing number of chemical accidents, various studies are being conducted on hazardous chemical accident response technology that incorporates artificial intelligence technology to detect chemical substances.Video and image-based artificial intelligence hazardous chemical detection systems require a sufficient amount of training data to enable accurate detecting of hazardous chemicals in accidents. However, due to the risk of hazardous chemicals, it is difficult to construct data, so currently, training data for artificial intelligence research for detecting hazardous chemicals is very insufficient. Therefore, this paper proposes a method of constructing an artificial intelligence training dataset that reflects the characteristics of hazardous chemicals and chemical accidents, such as the state of the material and the presence or absence of visual features. Following the proposed training dataset construction method, about 200,000 training datasets for 9 types of hazardous chemicals were constructed through collecting and securing raw data through self-experimentation of hazardous chemical , data processing, and annotation of the training data. The constructed dataset was divided in a ratio of 8:1:1 for training and validation and used training, validation, and test data. As a result of CNN-based hazardous chemical detecting, an average hazardous chemical detecting accuracy of about 90% was obtained.The detecting results are expected to provide an estimate of the accidental hazardous chemicals at the actual chemical accidents, thereby supporting appropriate and rapid response to the accidental substances to on-site firefighter."
Comparative Study on CNN-based Bridge Seismic Damage Identification Using Various Features,2024,"['Continuous rigid bridge', 'Seismic damage', 'Damage identification', 'Damage feature', 'Convolutional neural network']",,"Quick and accurate identification of bridge damage after an earthquake is crucial for emergency decision-making and post-disaster rehabilitation. The maturing technology of deep neural networks (DNN) and the integration of health monitoring systems provide a viable solution for seismic damage identification in bridges. However, how to construct damage features that can efficiently characterize the seismic damage of the bridge and are suitable for the use with DNN needs further investigation. This study focuses on seismic damage identification for a continuous rigid bridge using raw acceleration responses, statistical features, frequency features, and time-frequency features as inputs, with damage states as outputs, employing a deep convolutional neural network (CNN) for pattern classification. Results indicate that all four damage features can identify seismic damage, with time-frequency features achieving the highest accuracy but having a complex construction process. Frequency features also demonstratehigh accuracy with simpler construction. Raw acceleration response and statistical features perform poorly, with statistical features deemed unsuitable as damage indicators. Overall, frequency features are recommended as CNN inputs for quick and accurate bridge seismic damage identification."
파이썬을 이용한 미사일 피격 이미지 추출 및 CNN 기반 머신러닝을 이용한 명중정보 분석 연구,2024,"['미사일 피격 이미지(Missile Strike Image)', 'Canny 함수(Canny Function)', 'MNIST 데이터셋(MNIST Dataset)', 'Adam 옵티마이저(Adam Optimizer)', 'CNN(Convolutional Neural Network)']",,
Adaptive Classification of VPN and Non-VPN IoT Traffic Data Using CNN with Spatio-temporal Features,2024,"['Internet of Things', 'Adaptive Classification', 'Convolutional Neural Network', 'Virtual Private Network', 'Spatial and Temporal Features']",,"Low network throughput and high round-trip latency are two common challenges in Internet of Things (IoT) communications. This study addresses these issues by proposing an adaptive classification method that maintains network throughput above 360 Mbps and round-trip latency below 1 ms, while achieving a classification accuracy of 90% and a recall rate above 93.33%. This demonstrates the method’s ability to provide high throughput, low latency, and efficient traffic classification, addressing critical performance challenges in IoT environments and offering robust support for traffic management and security in real-world IoT deployments. The proposed method utilizes a convolutional neural network (CNN) to differentiate between virtual private network (VPN) and non-VPN traffic. First, the communication traffic data are cleaned using an amplitude-limiting filtering technique to remove noise. The cleaned data are then divided into subsets for preprocessing. Next, a deep learning model is trained using the ISCX VPN–nonVPN public dataset, which integrates both spatial and temporal features of traffic data. Finally, the model leverages the parameter-sharing capability of neurons in the CNN’s hidden layers, reducing the number of trained parameters and significantly improving classification performance. Considering the development of new technologies such as VPN intelligent deployment and IPsec policy automatic generation, the research results of this study will accelerate the automation and intelligence transformation of the IoT ecosystem from deployment to management."
CNN을 이용한 3상 유도전동기 ITSC 진단의 효율적인 1차원 전류 신호 구성 및 Encoding방법,2024,"['Induction Motor', 'ITSC', 'CNN', 'GAF', 'SWM']",,
CNN을 이용한 지능형 비접촉 호흡 모니터링 시스템,2024,"['sleep apnea', 'UWB respiration sensor', 'deep learning', 'polysomnography', 'non-contact radar', 'convolutional neural network']",,"Non-contact monitoring of vital signals has attracted much interest in the digital healthcare field due to its convenience. Much research is being conducted on the construction of a non-contact respiration measurement system to diagnose sleep apnea, which not only reduces quality of life but also causes many diseases. The problem with non-contact respiration sensors is that it is difficult to discern noise caused by movement. To solve this problem, an intelligent respiratory monitoring system was implemented using a CNN-based deep learning model. CNNs learning data measured breathing status by measuring chest movement using non-contact UWB radar distance measurement technology. Using non-contact UWB respiration sensor data, learning data was constructed by labeling it into respiration, apnea, and noise(movement). After offline learning was completed, breathing status was measured online, and the problems caused by movement were solved through deep learning."
Feasibility Study of CNN-based Super-Resolution Algorithm Applied to Low-Resolution CT Images,2024,"['AI', 'CNN', 'Super-Resolution', 'Windowing', 'CT']",,"Recently, various techniques are being applied through the development of medical AI, and research has been conducted on the application of super-resolution AI models. In this study, evaluate the results of the application of the super-resolution AI model to brain CT as the basic data for future research. Acquiring CT images of the brain, algorithm for brain and bone windowing setting, and the resolution was downscaled to 5 types resolution image based on the original resolution image, and then upscaled to resolution to create an LR image and used for network input with the original imaging. The SRCNN model was applied to each of these images and analyzed using PSNR, SSIM, Loss. As a result of quantitative index analysis, the results were the best at 256×256, the brain and bone window setting PSNR were the same at 33.72, 35.2, and SSIM at 0.98 respectively, and the loss was 0.0004 and 0.0003, respectively, showing relatively excellent performance in the bone window setting CT image. The possibility of future studies aimed image quality and exposure dose is confirmed, and additional studies that need to be verified are also presented, which can be used as basic data for the above studies."
딥러닝 기반의 기업 추천의도 예측: 한국과 미국 취업 플랫폼 데이터를 활용한 CNN-BiLSTM 분석,2024,"['기업 추천의도', '직무만족', '딥러닝', '취업 플랫폼', 'Corporate recommendation intention', 'Deep learning', 'Job satisfaction', 'CNN-BiLSTM', 'Job platforms']",,
CNN-ViT 통합 모듈을 이용한 Two-Branch 백본 기반 깊이 완성 연구,2024,"['Depth completion(깊이 완성)', 'Deep learning(딥러닝)', 'Multi-modal learning(멀티모달 러닝)', 'Vision transformer(비전 트랜스포머)', 'Residual connection(잔차 연결)']",,
Improving Deep CNN-Based Radar Target Classification Performance by Applying a Denoise Filter,2024,"['Deep Neural Network', 'Denoise Filter', 'Inception-Residual Module', 'Radar Target Classification', 'Range-Doppler Image']",,"This paper presents a novel method for removing noise from range-Doppler images by using a filter prior to conducting target classification using a deep neural network. Specifically, Kuan, Frost, and Lee filters are employed to eliminate speckle noise components from radar data images. Furthermore, a neural network that combines residual and inception blocks (RINet) is proposed. The RINet model is trained and tested on the RAD-DAR dataset—a collection of range-Doppler feature maps. The analysis results show that the application of a Lee filter with a window size of 7 in the RAD-DAR dataset demonstrates the most improvement in the model’s classification performance. On applying this noise filter to the dataset, the RINet model successfully classified radar targets, exhibiting a 4.51% increase in accuracy and a 14.07% decrease in loss compared to the classification results achieved for the original data. Furthermore, a comparison of the RINet model with the noise filtering solution with five other networks was conducted, the results of which show that the proposed model significantly outperforms the others."
CNN 모델을 이용한 원전 주 제어실 전계강도 예측,2024,"['CNN', 'EMI', 'EMC', 'Electric Field Strength', '-']","본 연구는 원자력 발전소 주 제어실과 같이 안전이 중요한 지역에서 전계 강도를 예측하기 위하여 CNN(convolutional neural networks)을 활용하는 방법을 제안한다. CNN 모델은 주어진 공간에 대하여 RT(ray tracing)시뮬레이터 측정을 통하여 획득한 전계분포를 학습한 후 새로운 조건에 대한 전계값을 효과적으로 예측할 수 있다. 제안하는 기법의 유효성을검증하기 위해 원전 주 제어실 환경에서 송신안테나의 위치를 변경하며, CNN 모델로부터 예측한 전계값과 RT 시뮬레이터의 결과를 비교하여 평균 오차율이 5 % 이하임을 확인하였다. 제안하는 CNN 기법은 원자력 발전소와 같은 환경에서효율적이고 유효한 전계 예측 방법으로 활용될 수 있을 것이다.","This study proposes a method for predicting the electric field strength in a nuclear power plant's main control room (MCR) using convolutional neural networks (CNN). The CNN model learns the electric field distribution using data from the ray tracing (RT) simulator or measurements and predicts the electric field strength for new conditions. The proposed method was validated by comparing the predicted electric-field strength with the results of the RT simulator by changing the position of the transmitting antenna in the MCR. The average errors were less than 5 %, confirming that the proposed method can effectively predict electric fields in environments such as nuclear power plants."
ConvIMage : IMU 시계열 데이터의 영상 신호 변환을 통한 CNN 기반 동작 추정 알고리즘 개발,2024,"['동작 추정', '합성곱신경망', '관성센서', '시계열데이터', '영상처리', 'Pose Estimation', 'CNN', 'IMU', 'Time-series data', 'Image processing']","자이로스코프와 카메라 센서를 통한 동작 인식 기법은 저전력 소모와 상호작용의 용의성 등의 이유로 다양한 산업 분야에 적용되고 있다. 하지만, 보정 방법에 따라 정확도가 떨어질 수 있고, 실시간 처리에 많은 연산량에 의한 지연 문제가 있다. 따라서 본 연구는 IMU 센서의 시계열 데이터를 이미지 데이터로 변환 후 CNN 알고리즘을 통해 학습하여 동작 추정을 수행하는 ConvIMage를 제안한다. ConvIMage는 IMU를 통해 수집한 시계열 데이터를 색상 채널로 변환하여 패턴 이미지를 구성하고, CNN 모델을 통해 각 동작에 대한 패턴을 학습한다. 실험을 통해 ConvIMage를 평가한 결과 동작 부위에 따라 각각 83.42%, 85.97%의 성능을 보였다. 이는 추후 동작 데이터를 활용하는 IoT 서비스 개발 등에 적용할 수 있을 것으로 기대된다.","Gyroscopes and camera sensors, widely utilized for motion recognition across industries, are celebrated for their low power consumption and user-friendly interaction. Nevertheless, challenges such as accuracy fluctuations due to calibration methods and computational delays in real-time processing persist. In this innovative study, we introduce ConvIMage, a groundbreaking approach that transforms Inertial Measurement Unit (IMU) sensor time-series data into image data through Convolutional Neural Network (CNN) algorithms, enhancing motion estimation capabilities. ConvIMage ingeniously assembles pattern images by converting IMU-derived time-series data into distinctive color channels, empowering a CNN model to discern intricate movement patterns. Experimental assessments underscore ConvIMages commendable performance, showcasing accuracies ranging from 83.42% to 85.97%, contingent upon the specific type of motion. This auspicious outcome positions ConvIMage as a robust solution for future IoT service development, leveraging motion data with enhanced accuracy and real-time processing capabilities for a multitude of applications."
CNN Inference Accelerator Optimized for AI Applications for Object Detection,2024,"['Convolutional Neural Network', 'CNN inference accelerator', 'Neural Processing Unit', 'YOLOv5-nano model']",,"The advancement of state-of-the-art technology has dramatically impacted the field of Deep Neural Networks (DNNs), especially Convolutional Neural Networks (CNNs). As the demand for AI applications on mobile devices grows, power-hungry GPUs are no longer viable for mobile AI applications. Instead, there is a growing research trend towards compact and low power Neural Processing Units (NPUs) to solve current problems. This article presents an efficient architecture of a CNN inference accelerator that is optimized for AI applications on mobile devices. We propose two architectural enhancements and two optimization methods to improve the existing CNN accelerator [17]. To evaluate our work, we implemented it on a Zynq UltraScale+ MPSoC ZCU 102 Evaluation Board and verified it with the YOLOv5-nano model used for CNN object detection. Experimental results show that we reduced resource utilization by 7.31% for LUTs, 22.29% for FFs, and 3.90% for DSPs. In our Vivado simulation, we accelerated the inference time by 33.5%. With the reduced resource usage described above, we have implemented an accelerator with no loss of accuracy and better resource usage and speed."
Image Reconstruction Method by Spatial Feature Prediction  Using CNN and Attention,2024,"['Image Reconstruction', 'Spatial Feature Prediction', 'CNN', 'Attention Mechanism.']",,"In this paper, we propose an image reconstruction method through CNN and attention layers. The proposed method reconstructs a square block from reference pixels that are located in its top and left areas. The first CNN layers of the proposed network find spatial features in vertical and horizontal directions for the reference pixels in the top and left areas, respectively. Then, the two spatial features are merged. The spatial features of the block are predicted by applying self-attention to the merged spatial features. A correlation between the block and the reference pixels is found through attention layers for the spatial features of the block and of the reference pixels. Finally, the last CNN layers reconstruct the pixels of the block by converting spatial feature domain to pixel domain. In simulation results, block reconstruction accuracies increase by an average of 14% for actual videos compared with intra prediction in VVC. The proposed method can accurately reconstruct for blocks including more nonlinear patterns such as curves."
"고추 작물의 정밀 질병 진단을 위한 딥러닝 모델 통합 연구: YOLOv8, ResNet50, Faster R-CNN의 성능 분석",2024,"['스마트 농업', '작물 질병 진단', '욜로v8', '레스넷50', '딥러닝 모델 비교', 'Smart Agriculture', 'Crop Disease Diagnosis', 'YOLOv8', 'ResNet50', 'Deep Learning Model Comparison']","본 연구의 목적은 YOLOv8, ResNet50, Faster R-CNN 모델을 활용하여 고추 작물의 질병을 진단하고, 각 모델의 성능을 비교하는 것이다. 첫 번째 모델은 YOLOv8을 사용하여 질병을 진단하였고, 두 번째 모델은 ResNet50을 단독으로 사용하였다. 세 번째 모델은 YOLOv8과 ResNet50을 결합하여 질병을 진단하였으며, 네 번째 모델은 Faster R-CNN을 사용하여 질병을 진단하였다. 각 모델의 성능은 정확도, 정밀도, 재현율, F1-Score 지표로 평가된다. 연구 결과, YOLOv8과 ResNet50을 결합한 모델이 가장 높은 성능을 보였으며, YOLOv8 단독모델도 높은 성능을 나타냈다.","The purpose of this study is to diagnose diseases in pepper crops using YOLOv8, ResNet50, and Faster R-CNN models and compare their performance. The first model utilizes YOLOv8 for disease diagnosis, the second model uses ResNet50 alone, the third model combines YOLOv8 and ResNet50, and the fourth model uses Faster R-CNN. The performance of each model was evaluated using metrics such as accuracy, precision, recall, and F1-Score. The results show that the combined YOLOv8 and ResNet50 model achieved the highest performance, while the YOLOv8 standalone model also demonstrated high performance."
Enhancing vibration-based damage assessment with 1D-CNN: parametric studies and field applications,2024,"['Vibration', 'Damage assessment', 'Deep Learning', '1D-CNN', 'Truss bridge']",,"Deep learning approaches have emerged as promising solutions for vibration-based damage assessment. Although these approaches have shown great potential, further investigations are required to apply them to real-world problems, as most studies have been limited to training with experimental and numerical simulation data. To address this, this study examines the feasibility of employing a one-dimensional convolutional neural network (1D-CNN) for damage assessment by utilizing both simulated data and field applications on an actual truss bridge. Extensive parametric studies were conducted to investigate the performance of the model under various architectural configurations, sensor quantities, sensor locations, and degrees of damage. The results of the hyperparameter optimization show that a moderate number of optimizable parameters is essential for the universal applicability of optimized hyperparameters across different situations or configurations. Comparative studies with other machine learning and deep learning algorithms have validated the superior performance of the 1D-CNN in vibration-based damage detection. Finally, the field application demonstrated the robust potential of the 1D-CNN for real-world scenarios, achieving an impressive F1-score of 90.58% even with single-channel measurements."
CNN 기반의 전이학습과 데이터 증강을 통한  화재 영상 분류 개선,2024,"['산불 감지', 'CNN', '전이학습', '데이터 증강', 'ResNet50', 'Wildfire Detection', 'Convolutional Neural Networks', 'Transfer Learning', 'Data Augmentation', 'ResNet50']","전 세계는 기상이변의 영향으로 산불 등 자연 재해가 끊이지 않고 있으며 이로 인한 사회 안전에 심각한 위협이 되고 있다. 특히 대한민국 동해안 지역은 매년 산불 피해로 인한 막대한 재산 피해가 발생하고 있다. 초기 화재 감지 모델의 필수적인 개발은 훈련을 위한 제한된 이미지 데이터와 관련된 도전을 극복해야 하며, 이는 과적합의 위험을 증가시킨다. 이를 해결하기 위해, 랜덤하게 50% 범위까지 회전, 랜덤하게 20% 범위까지 축소 및 확대, 랜덤하게 50%까지 가로 및 세로 뒤집기를 적용하였다. 성능 평가에서 6층 신경망이 7층 신경망보다 더 우수한 성능을 보였으며, 이는 제한된 데이터셋을 가지고 계층 수를 늘리는 것이 바람직하지 않음을 의미한다. 또한, 화재 이미지 분류를 위한 딥러닝 기반 CNN 모델과 ResNet50 전이 학습 모델의 평가는 전이 학습의 우수한 효과를 확인하였다. 이러한 발견은 초기 화재 감지 모델 개발에 도움이 될 것으로 기대하며, 미래 시스템을 위한 귀중한 통찰력을 제공할 것이다.","Natural disasters, such as wildfires, due to climate change are a constant and serious threat to the world and societal safety. Every year, the eastern coastal region of South Korea experiences significant property damage due to wildfires. The imperative development of early fire detection models necessitates overcoming challenges associated with limited image data for training, which elevates the risk of overfitting. To address this, data augmentation techniques, including random rotation (up to 50%), random scaling (up to 20%), and random horizontal and vertical flipping (up to 50%), were employed to augment the training dataset. Performance evaluation indicated that the 6-layer neural network outperformed its 7-layer counterpart, highlighting the impracticality of increasing layer count with a limited dataset. Furthermore, an assessment of deep learning-based CNN models and ResNet50 transfer learning models for fire image classification underscored the superior efficacy of transfer learning. These findings hold promise for advancing early fire detection model development, offering valuable insights for future systems."
R-CNN Auto-system for Detecting Text Road Signs in Baghdad,2024,"['R-CNN', 'Labeling', 'Epoch', 'Detection', 'Baghdad', 'Recognition']",,"Due to inadequate lighting, motion blur, occlusion, and the eventual disappearance of road signs, the determination of textual road signs is difficult to resolve. With the aid of a recurrent convolutional neural network (R-CNN), the current study focuses on detecting textual road signs in Baghdad at different times of day under varied situations, including vehicle speed, surrounding layers, epochs of the R-CNN, etc. Two types of different contrast on signs were used: blue and blue-green signs with white text. The differences in contrast seem to play an effective role in recall, sensitivity, and F1 score values. Results showed that the precision values for all signs and epochs were unity. For 20 and 60 epochs, the sensitivity values for the blue sign were 47.43% and 48.35%, respectively, while for the blue-green sign, the sensitivity values were equal to 95.19% for both numbers of epochs. The F1 scores were 0.6435 and 0.9753 for 20 epochs, while for 60 epochs it was 0.6518 and 0.9753 for blue and blue-green signs, respectively. The experiments validated the suggested software and provided implementation guidance to diagnose and automatically classify text road signs on streets."
Mask R-CNN 알고리즘의 의미론적 분할에 대한 마스크 기반의 성능 평가,2024,"['의미론적 분할', '마스크 기반 평가', '주행 가능한 영역', 'Mask R-CNN', 'Semantic Segmentation', 'Mask-based Performance Evaluation', 'Driveable Area']","일반적으로 빛, 장애물, 그림자, 곡선 차선 등의 환경적 영향으로 인해 차선 표시를 감지하는 데 어려움이 많고 이로 인해 차선 표시를 감지하는 오류가 높아진다. 본 논문은 환경 조건에 따른 차선 인식의 문제를 해결하기 위해 실제 운전 차량에서 수집한 데이터로부터 Mask R-CNN 알고리즘을 사용하여 의미론적 분할을 수행하고 주행 가능한 영역을 추출하는 방법을 제안한다. 그리고 학습 모델의 성능은 마스크 기반의 평가로 이미지에서 특정 객체의 정확한 위치와 픽셀 수준에서 객체의 모양과 경계에 대한 추정을 평가한다. 실험 결과 낮에 많은 비가 오고 안개가 발생한 경우 주행 가능한 영역 인식률이 높았고, 맑은 날씨이지만 조명이 아주 어두워 앞을 인식하기 어려운 조건에도 인식률이 높았다. 그러나 밤에 폭우가 내리는 경우는 차선 자체인식이 어렵고, 반대 차선의 빛으로 인한 왜곡으로 주행 가능한 영역 인식에 오류 발생률이 높았다.","In general, it is difficult to detect lane markings due to environmental influences such as light, obstacles, shadows, and curved lanes, which increases the error in detecting lane markings. In this paper, we propose a method to perform semantic segmentation and extract drivable areas using the Mask R-CNN algorithm from data collected from actual driving vehicles to solve the problem of lane recognition according to environmental conditions. And the performance of the learning model is evaluated based on the mask-based evaluation to estimate the exact location of a specific object in the image and the shape and boundary of the object at the pixel level. The experimental results showed that the recognition rate of the drivable area was high when it rained heavily during the day and was foggy, and the recognition rate was high even when it was difficult to recognize the front on a clear night in condition of very dark. However, in case of heavy rain night, it was difficult to recognize the lane itself, and the error rate in recognizing the drivable area was high due to distortion caused by the light from the opposite lane."
Simple 1D CNN Model for Accurate Classification of Gait Patterns Using GRF Data,2024,"['Attention mechanism', 'Convolutional neural networks (CNN)', 'Gait analysis', 'Ground reaction force (GRF)', 'Gaiter dataset']",,"Gait analysis plays a pivotal role in clinical diagnostics and aids in the detection and evaluation of various disorders and disabilities. Traditional methods often rely on intricate video systems or pressure mats to assess gait. Previous studies have demonstrated the potential of artificial intelligence (AI) in gait analysis using techniques, such as convolutional neural networks (CNN) and long short-term memory (LSTM) networks. However, these methods often encounter challenges related to high dimensionality, temporal dependencies, and variability in gait patterns, making accurate and efficient classification difficult. To address these challenges, this study introduces a simple one-dimensional (1D) CNN model designed to analyze ground reaction force (GRF) patterns and classify individuals as healthy or suffering from gait disorders. The model achieved a remarkable classification accuracy of 98.65% in distinguishing healthy individuals from those with gait disorders, demonstrating significant improvements over the existing models. This performance is bolstered by the attention mechanism and standardization techniques that enhance robustness and accuracy."
주조 공정에서 제어 로직과 온도 데이터를 활용한 CNN Autoencoder 기반 공정 이상 진단,2024,"['Anomaly detection', 'CNN autoencoder', 'Process analysis', 'Programmable logic controller (PLC)', 'Signal processing']",,"Checking the normal operation of facilities through process analysis and quickly identifying and handling problems when abnormalities occur are key challenges in the manufacturing industry. In this study, we propose a CNN autoencoder model to determine the status of the process based on equipment operation data and temperature data patterns of the casting process. By training the model with data that combines equipment operation Gantt charts and temperature change graphs, it recognizes change patterns within the process and determines abnormalities without relying on data parameters. The CNN autoencoder model, which self-learns the patterns of the training dataset, effectively classifies abnormal cycles by learning only the patterns of normal data, even in environments where process results are not collected. Additionally, it provides new solutions for process improvement by identifying problems that were difficult to detect with existing data analysis-based anomaly detection models. Our experimental model interprets the training dataset as images and presents a pattern analysis method that can be implemented without complex data processing, not only in the manufacturing industry but also in any field where data patterns exist."
A study of Strawberry Maturity Classification Using Improved Faster R-CNN,2024,"['Convolutional Neural Network (CNN)', 'Faster R-CNN', 'Image Classification', 'RoI Align', 'Strawberry Maturity']",,"In strawberry cultivation, maturity classification plays an important role in ensuring the efficiency and quality of harvesting. In this study, we propose an Improved Faster R-CNN model to address these challenges, using MobileNetV3-Large as the backbone network to achieve a lightweight model, and introducing RoI Align to improve the spatial accuracy of the feature map. Experiments are conducted using the KGCV_Strawberry dataset, with precision, recall, F1 score, and mean average precision (mAP) measured for performance evaluation. The experimental results show that the proposed model achieves an average precision of 71.35%, recall of 71.07%, and F1 score of 71.21% across all classes. In particular, the proposed model achieves 63% performance on mAP0.5 and 58% performance on mAP0.5:0.95, which is comparable to existing ResNet-based models while achieving faster inference speed. The proposed model achieves a processing speed of 27.6543 ms, which is about 2 ms faster than existing ResNet-based models. This indicates that the goal of creating a lightweight model with improved image processing capability was achieved with minimal performance degradation. This research is expected to contribute to the development of automated strawberry cultivation systems in greenhouse environments and has the potential to be applied to various agricultural environments in the future."
Comparison and analysis of CNN models to Address Skewed Data Issues in Alzheimer's Diagnosis,2024,"['Alzheimer’s disease', 'Non-Demented', 'Very Mild Demented', 'Mild Demented', 'Moderate Demented', 'Convolution Neural Network', 'EfficientNetV2B0', 'MRI', 'OASIS dataset']",,"Alzheimer's disease is a form of dementia that can be managed by identifying the disease in its initial phases. In recent times, numerous computer-aided diagnostic techniques utilizing magnetic resonance imaging (MRI) have demonstrated promising outcomes in the categorization of Alzheimer's disease (AD). The OASIS MRI dataset was utilized which has 80,000 brain MRI images. It is suggested to resample this dataset as it is highly imbalanced and posed a challenge in preventing bias toward majority class while employing the convolution neural network (CNN) model for classification. This paper examines and extracts patterns and features of 461 patients taken from the OASIS dataset. The research has aimed at utilizing the Base Model of EfficientNetV2B0 with custom classification layers, and simplified custom CNN model, also exploring Multi-class classification across four distinct classes: Non-Demented, Very Mild Demented, Mild Demented, Moderate Demented in addition to binary classification as Non-Demented and treating other classes as demented. Furthermore, different dataset sizes were experimented with 5,000 and 20,000 for each class to be discussed in this paper. The experiment results indicate that EfficientNetV2B0 achieved the accuracy of 98% in binary classification, 99% in multiclass. Whereas custom sequential CNN model in multiclass classification presents the accuracy of 96% for 20,000 dataset size and 98% for 80,000 dataset size."
Improving Musical Expression by Capturing Psychological Changes with CNN Support,2024,"['Vocal Performance', 'EEG', 'Psychological Changes', 'DEAP', 'CNN', 'Differential Entropy.']",,"In vocal performance, capturing psychological changes through electroencephalography (EEG) and integrating them with music can improve musical expression. We propose an EEG-based emotion recognition model using continuous convolutional neural networks (CNN).EEG signals in different frequency bands are extracted as features using differential entropy. An EEG enhancement method reassigns variable importance to channels by suppressing redundant information. The model is evaluated on the DEAP dataset for emotion recognition. Combining a rest-state baseline signal before each trial significantly improves accuracy. Following the simulation results, the suggested continuous CNN model has an average classification accuracy of 95.36% and 95.31 for arousal and valence on 22 channels, respectively. This is close to the average accuracy of 32 channels. Likewise, it can help capture the psychological changes of vocal performers and improve musical expression."
Quality Classification of Multi-Layer Copper Foil Stacks Welds for Ultrasonic Welding Using CNN and RNN,2024,"['Multilayer copper foil', 'Ultrasonic welding', 'Weldability', 'Classification model', 'Convolutional Neural Network (CNN)', 'Recurrent Neural Network (RNN)', 'Long Short-Term Memory (LSTM)']",,"This study aims to develop a model for classifying weld quality using data acquired in real-time during the ultrasonic welding process. The data utilized includes LVDT (DP-10, DAQ-Express) and power signal data. The model categorizes welds into three classes (insufficient, sufficient, and excessive) based on the total input energy of the ultrasonic welding process. To classify the quality of ultrasonic welds, Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) are employed. The focus of this research is on utilizing CNN and RNN models to classify weld quality based on signal data acquired from ultrasonic welding, aiming to enhance the reliability of secondary battery joints."
Determination of Joint Defects in Copper Tube Induction Heating Brazing Area Using Infrared Thermal Image Based on CNN Algorithm,2024,"['Copper tube', 'Induction heating', 'Brazing', 'Thermal image', 'Defect identification', 'Convolutional neural network']",,"Due to its excellent processability, thermal conductivity and high corrosion resistance, the copper tube applied to the heat exchanger is joined by the brazing process. In order to improve the performance of heat exchangers, it is essential to inspect the joint quality of copper tubes, but it is difficult to identify defects in tube-shaped joints without cutting. To solve this problem, this study proposes a new detection method based on the Convolutional Neural Network (CNN) model to detect joint defects that occur in brazing joints of copper tubes. In the experiment, a brazing joint using high-frequency induction heating was performed on a 12.71 mm diameter copper tube, which is mainly used in heat exchangers, and the joint failure was judged based on the penetration depth of the filler material measured by vertically cutting the joined copper tube. In addition, thermal image data having a data structure of 80 × 80 pixels per frame was collected to be used as data to determine whether the brazing joint is defective in real time. Finally, using the collected thermal image data, we developed a CNN model with a structure that applies different hyperparameters to determine whether or not the joint of copper tube is defective. The selected CNN model produced an f1 score of 0.991 and a recall of 99.73%, and formed the basis for developing a system that identifies defects in brazing joints of copper tubes through thermal image data obtained in real time."
IPC-CNN: A Robust Solution for Precise Brain Tumor Segmentation Using Improved Privacy-Preserving Collaborative Convolutional Neural Network,2024,"['Brain tumors', 'Improved Convolutional Neural Network', 'Segmentation', 'Privacy-Preserving', 'BRATS', 'Figshare', 'Generative Adversarial Network']",,"Brain tumors, characterized by uncontrollable cellular growths, are a significant global health challenge. Navigating the complexities of tumor identification due to their varied dimensions and positions, our research introduces enhanced methods for precise detection. Utilizing advanced learning techniques, we've improved early identification by preprocessing clinical dataset-derived images, augmenting them via a Generative Adversarial Network, and applying an Improved Privacy-Preserving Collaborative Convolutional Neural Network (IPC-CNN) for segmentation. Recognizing the critical importance of data security in today's digital era, our framework emphasizes the preservation of patient privacy. We evaluated the performance of our proposed model on the Figshare and BRATS 2018 datasets. By facilitating a collaborative model training environment across multiple healthcare institutions, we harness the power of distributed computing to securely aggregate model updates, ensuring individual data protection while leveraging collective expertise. Our IPC-CNN model achieved an accuracy of 99.40%, marking a notable advancement in brain tumor classification and offering invaluable insights for both the medical imaging and machine learning communities."
One-dimensional CNN Model of Network Traffic Classification based on Transfer Learning,2024,"['Convolution Neural Network', 'traffic classification', 'transfer learning', 'feature pre-processing']",,"There are some problems in network traffic classification (NTC), such as complicated statistical features and insufficient training samples, which may cause poor classification effect. A NTC architecture based on one-dimensional Convolutional Neural Network (CNN) and transfer learning is proposed to tackle these problems and improve the fine-grained classification performance. The key points of the proposed architecture include: (1) Model classification--by extracting normalized rate feature set from original data, plus existing statistical features to optimize the CNN NTC model. (2) To apply transfer learning in the classification to improve NTC performance. We collect two typical network flows data from Youku and YouTube, and verify the proposed method through extensive experiments. The results show that compared with existing methods, our method could improve the classification accuracy by around 3-5%for Youku, and by about 7 to 27% for YouTube."
Merged CNN 기반 유한요소모델 업데이트 방법론,2024,"['유한요소 모델 업데이팅', '딥러닝', '합성곱 신경망', '진동모드형상', '고유진동수', 'Finite Element Model Updating', 'Deep Learning', 'Convolutional Neural Network', 'Vibration Mode Shape', 'Natural Frequency']","구조물의 유지관리에 있어서 구조물의 현재 상태가 반영된 정교한 유한요소해석모델(FEA)이 요구되는 경우가 많다. 현재 구조물의 특성이 정교하게 반영된 유한요소해석 모델을 구축하기 위해 대상 구조물의 다양한 재료 및 기하학적 물성이 반영되어야 하는데, 설계 시 고려된 물성치와 시공된 시점에서의 값 그리고 현재 시점의 값 간에는 차이가 존재하기 때문에 일반적으로는 대상 구조물의 실측 데이터를 활용하여 해석모델의 업데이트를 수행한다. 이 때 실측치와 해석치의 비교를 통한 오차 최소화를 목적으로 반복적인 업데이트 작업을 수행하게 되며 이에 따라 많은 시간이 소요되는 경우가 다수이다. 본 연구에서는 인공신경망을 활용한 효과적인 모델 업데이트 방법에 대해 연구하였다. 본 연구에서는 대상 구조물의 고유진동수 및 모드형상 등의 구조의 모달 정보를 활용하여 유한요소 모델의 매개변수를 직접 추정하는 접근 방식을 제안한다. 다양한 변수 간의 복잡한 상관관계를 분석하는 데 효과적인 심층 신경망(DNN)과 진동 모드 간의 관계성을 반영할 수 있는 합성곱 신경망(CNN)을 통합한 알고리즘을 활용하였다. 휨부재에 대한 검증을 통해 제안한 방법론이 높은 정확도로 목표 모달 정보에 부합하도록 유한요소해석 모델을 업데이트할 수 있음을 확인하였다.","Finite element analysis requires the construction of a model that accurately reflects the structural characteristics of a target structure. Such models must incorporate precise material and geometric properties. However, discrepancies often arise between the properties assumed during the design phase and those observed in the actual structure. To address this, the models are iteratively updated using real measurement data, minimizing the errors between measured and analytical results. This process, however, can be time-consuming, particularly for complex structures. In this study, we propose a novel approach to directly estimate the parameters of a finite element model by utilizing the modal information from the structure, including natural frequencies and mode shapes. Our algorithm integrates a deep neural network that effectively solves complex problems using a convolutional neural network that captures the relationships between the nodal data and modes. Verification using a beam model demonstrated that the proposed methodology successfully updated the finite element analysis model to accurately match the target modal information."
해상상태를 고려한 CNN 기반의 부유형 풍력 터빈 회전 상태 구분,2024,"['floating wind turbine', 'rotation state', 'sea state', 'Monte Carlo simulation', 'CNN classifier']",,"This paper focuses on distinguishing the rotation states of wind turbine blades in floating wind system when sea states are considered. To implement our ideas, we conducted electromagnetic numerical simulation, indoor and outdoor measurements. The experiments categorize the sea states into four different levels instead of the conventional nine levels to distinguish clearly the wave height and period. The training data consists of noise-free spectrograms, while the test data is added with the Gaussian noise at the given signal-to-noise ratio(SNR) of 5 ㏈, 10㏈, 15㏈, and 20㏈. The results using the Convolutional Neural Network(CNN) classifier indicate that the performance is improved as the SNR increases. 50 Monte Carlo simulations are conducted and the classification accuracy is higher than 92% at all cases of using the numerical simulation, indoor and outdoor measurement data."
An Implementation of Effective CNN Model for AD Detection,2024,"[""Alzheimer's disease (AD)"", 'Magnetic Resonance Imaging (MRI)', 'Convolution Neural Network (CNN)']",,"This paper focuses on detecting Alzheimer’s Disease (AD). The most usual form of dementia is Alzheimer's disease, which causes permanent cause memory cell damage. Alzheimer's disease, a neurodegenerative disease, increases slowly over time. For this matter, early detection of Alzheimer's disease is important.  The purpose of this work is using Magnetic Resonance Imaging (MRI) to diagnose AD.  A Convolution Neural Network (CNN) model, Reset, and VGG the pre-trained learning models are used.  Performing analysis and validation of layers affects the effectiveness of the model. T1-weighted MRI images are taken for preprocessing from ADNI. The Dataset images are taken from the Alzheimer's Disease Neuroimaging Initiative (ADNI). 3D MRI scans into 2D image slices shows the optimization method in the training process while achieving 96% and 94% accuracy in VGG 16 and ResNet 18 respectively. This study aims to classify AD from brain 3D MRI images and obtain better results."
Network Anomaly Traffic Detection Using WGAN-CNN-BiLSTM in Big Data Cloud–Edge Collaborative Computing Environment,2024,"['Abnormal Traffic Mining', 'Big Data', 'BiLSTM', 'Cloud–Edge Collaborative Computing', 'CNN', 'Wasserstein Generative Adversarial Networks']",,"Edge computing architecture has effectively alleviated the computing pressure on cloud platforms, reducednetwork bandwidth consumption, and improved the quality of service for user experience; however, it hasalso introduced new security issues. Existing anomaly detection methods in big data scenarios with cloud–edge computing collaboration face several challenges, such as sample imbalance, difficulty in dealing withcomplex network traffic attacks, and difficulty in effectively training large-scale data or overly complex deeplearningnetwork models. A lightweight deep-learning model was proposed to address these challenges. First,normalization on the user side was used to preprocess the traffic data. On the edge side, a trained Wassersteingenerative adversarial network (WGAN) was used to supplement the data samples, which effectively alleviatesthe imbalance issue of a few types of samples while occupying a small amount of edge-computing resources.Finally, a trained lightweight deep learning network model is deployed on the edge side, and the preprocessedand expanded local data are used to fine-tune the trained model. This ensures that the data of each edge nodeare more consistent with the local characteristics, effectively improving the system's detection ability. In thedesigned lightweight deep learning network model, two sets of convolutional pooling layers of convolutionalneural networks (CNN) were used to extract spatial features. The bidirectional long short-term memorynetwork (BiLSTM) was used to collect time sequence features, and the weight of traffic features was adjustedthrough the attention mechanism, improving the model's ability to identify abnormal traffic features. Theproposed model was experimentally demonstrated using the NSL-KDD, UNSW-NB15, and CIC-ISD2018datasets. The accuracies of the proposed model on the three datasets were as high as 0.974, 0.925, and 0.953,respectively, showing superior accuracy to other comparative models. The proposed lightweight deeplearning network model has good application prospects for anomaly traffic detection in cloud–edgecollaborative computing architectures."
국가유산 보존을 위한 Computer Vision기반 CNN 알고리즘을 이용한 소유권 공유 시스템,2024,"['합성곱 신경망', '컴퓨터 비전', '이미지 인식', '크라우드 펀딩', '소유권 공유', '가치 예측', 'Convolutional Neural Network', 'Vision AI', 'Image Recognition', 'Crowd Funding', 'Shared Ownership', 'Value Prediction']","국내에서 국가유산은 보존할 만한 가치가 있는 문화유산 · 자연유산 · 무형유산을 뜻한다. 하지만 국가유산들의 값을 매기고 판매, 구매되는 거래의 문제, 소유권을 가지고 분쟁이 일어나는 소유권의 문제, 환수받지 못한 환수의 문제가 발생하고 있다. 본 논문에서는 CNN(:Convolutional Neural Network) 알고리즘을 활용하여 국가유산의 보존과 소유권 공유를 위한 시스템을 개발하고 그 성능을 분석한다. 이 시스템은 이미지 인식 기술과 크라우드 펀딩을 결합하여 문제점들을 해결할 수 있는 새로운 관리 방안을 제시한다. 이미지 인식 기술인 Vision AI를 활용하여 자동 감정 기능을 통해 국가유산의 가치를 신속하게 평가하며, 사용자가 국가유산의 지분을 공유하고 실시간으로 가치를 확인할 수 있다. 이를 통해 국가유산의 보존과 환수에 대한 혁신적인 접근 방식을 제공하고, 다수의 사용자가 국가유산 보호에 적극적으로 참여할 수 있는 시스템으로 구성하였다.","The term national heritage in Korea refers to cultural heritage, natural heritage, and intangible heritage that are deemed valuable for preservation. However, challenges arise related to the valuation, transaction, and ownership disputes of these heritage assets, as well as issues concerning their repatriation. This paper presents the development and performance analysis of a system designed for the preservation and ownership sharing of national heritage utilizing Convolutional Neural Network (CNN) algorithms. In this paper, we proposed system that integrates image recognition technology and crowdfunding to address these issues. By employing Vision AI for automated valuation, the system enables rapid assessment of national heritage values and allows users to share ownership and monitor real-time valuations. This approach offers an innovative solution for heritage preservation and repatriation, facilitating active participation form a broad user base in the protection of national heritage."
Selection of Heating Lines in the Line Heating Process for Steel Plates Using Faster R−CNN,2024,"['Line heating', 'Heating position', 'Curved surface', 'Finite element analysis', 'Faster R−CNN']",,"In the process of surface forming through line heating of a steel plate, accurately determining the position of the heating lines is crucial to achieving the desired curvature. In this study, we propose a Faster R−CNN based model to predict the positions of heating lines from images of the desired curved surface. Initially, a finite element model for line heating on a steel plate is employed to obtain deformation analysis results based on the positions of the heating lines. The shape resulting from the combination of heating lines is acquired by superimposing the deformation analysis results of each heating line. Color map images of curved surfaces and corresponding information about heating lines are utilized as training data for the proposed model. The model is subjected to training through backpropagation to minimize the total output error. Testing the trained model revealed that the model accurately predicted the positions of the heating lines to achieve the desired surface. Furthermore, validation of the model on a surface with arbitrary curvature confirmed that heating the plate based on the predicted positions of the heating lines resulted in obtaining a curved surface that was very similar to the arbitrary target surface. Consequently, it was determined that the model could be effectively utilized to predict the positions of the heating lines in the line heating process."
CNN 기반 슬관절 골관절염 중증도 판단을 위한 통합 보완된 등급 판정 시스템,2024,"['슬관절 골관절염', '협착', '골극', '인공지능', 'Knee Osteoarthritis', 'X-ray', 'Joint Space Narrow', 'Osteophyte', 'AI', 'CNN']",,
Mask R-CNN의 Target 학습을 이용한 드론의 자율비행,2024,"['Autonomous flight', 'Drone', 'GPS', 'Interial flight', 'MRCNN(Mask R-CNN)']",,
XAI를 이용한 CNN 기반 리눅스 악성코드 탐지,2024,"['XAI', 'CNN', 'Linux', 'Malware', 'AI']",,
콘크리트 구조체 균열 탐지에 대한 Mask R-CNN 알고리즘 적용성 평가,2024,"['Convolutional neural network', 'Crack detection', 'Deep learning model', 'Intersection over union', 'Mask R-CNN']",,
CNC 용접 로봇의 실시간 공정 감시 및 이상 현상 감지를 위한 CNN 기반 시스템 개발,2024,"['실시간 감지', '시스템 평가', '용접 영상 데이터', '이상 현상 감지', 'Real-time Detection', 'System Verification', 'CNN(Convolutional Neural Network)', 'Welding Video Data', 'Anomaly Detection']",,
CNN 기반 스펙트로그램을 이용한 자유발화 음성감정인식,2024,"['Spontaneous Speech', 'Speech Emotion Recognition', 'Spectrogram', 'Convolutional Neural Network', '자유발화', '음성감정인식', '스펙트로그램', '합성곱신경망']",,"Speech emotion recognition (SER) is a technique that is used to analyze the speaker's voice patterns, including vibration, intensity,and tone, to determine their emotional state. There has been an increase in interest in artificial intelligence (AI) techniques, which arenow widely used in medicine, education, industry, and the military. Nevertheless, existing researchers have attained impressive resultsby utilizing acted-out speech from skilled actors in a controlled environment for various scenarios. In particular, there is a mismatchbetween acted and spontaneous speech since acted speech includes more explicit emotional expressions than spontaneous speech. Forthis reason, spontaneous speech-emotion recognition remains a challenging task. This paper aims to conduct emotion recognition andimprove performance using spontaneous speech data. To this end, we implement deep learning-based speech emotion recognition usingthe VGG (Visual Geometry Group) after converting 1-dimensional audio signals into a 2-dimensional spectrogram image. The experimentalevaluations are performed on the Korean spontaneous emotional speech database from AI-Hub, consisting of 7 emotions, i.e., joy, love,anger, fear, sadness, surprise, and neutral. As a result, we achieved an average accuracy of 83.5% and 73.0% for adults and young peopleusing a time-frequency 2-dimension spectrogram, respectively. In conclusion, our findings demonstrated that the suggested frameworkoutperformed current state-of-the-art techniques for spontaneous speech and showed a promising performance despite the difficulty inquantifying spontaneous speech emotional expression."
단일 CNN 기반 AVM 영상에서의 주차 구획 검출 및 분할 동시 수행,2024,"['Automatic parking system(자동 주차 시스템)', 'Parking slot detection(주차 구획 검출)', 'Parking slot segmentation(주차 구획 분할)', 'Convolutional neural network(합성곱 신경망)', 'Around view monitoring(AVM)(어라운드 뷰 모니터링)']",,
3차원 적층 구조 저항변화 메모리 어레이를 활용한 CNN 가속기 아키텍처,2024,"['RRAM', 'neuromorphic computing', '3D-stacked', 'artificial neural network', 'artificial intelligence']",,
Genetic Algorithm based hyperparameter tuned CNN for identifying IoT intrusions,2024,"['Bayesian optimization', 'Extended Compact genetic algorithm(eCGA)', 'Genetic Algorithm', 'Internet of Things (IoT)', 'Intrusion Detection System (IDS)', 'Probabilistic model building genetic algorithm (PMBGA).']",,"In recent years, the number of devices being connected to the internet has grown enormously, as has the intrusive behavior in the network. Thus, it is important for intrusion detection systems to report all intrusive behavior. Using deep learning and machine learning algorithms, intrusion detection systems are able to perform well in identifying attacks. However, the concern with these deep learning algorithms is their inability to identify a suitable network based on traffic volume, which requires manual changing of hyperparameters, which consumes a lot of time and effort. So, to address this, this paper offers a solution using the extended compact genetic algorithm for the automatic tuning of the hyperparameters. The novelty in this work comes in the form of modeling the problem of identifying attacks as a multi-objective optimization problem and the usage of linkage learning for solving the optimization problem. The solution is obtained using the feature map-based Convolutional Neural Network that gets encoded into genes, and using the extended compact genetic algorithm the model is optimized for the detection accuracy and latency. The CIC-IDS-2017 and 2018 datasets are used to verify the hypothesis, and the most recent analysis yielded a substantial F1 score of 99.23%. Response time, CPU, and memory consumption evaluations are done to demonstrate the suitability of this model in a fog environment."
"머신러닝 기술의 재료·가공문제에 적용III - RNN, LSTM, CNN",2024,,,
로그 전처리를 적용한 컨볼루션 신경망 기반차량 레이더 간섭 경감,2024,"['Automotive Radar', 'Interference Mitigation', 'Convolutional Neural Network (CNN)', 'Logarithmic Preprocessing', 'Signal-to-Interference-plus-Noise Ratio (SINR)']","최근 차량용 레이더의 사용이 급증함에 따라 동일 주파수 대역에서 작동하는 다수의 레이더 간의 간섭 문제가 부각되고 있다. 본연구에서는 로그 전처리(Logarithmic Pre-Processing, LPP)를 활용하여 컨볼루션 신경망(CNN) 기반 차량용 레이더 간섭 경감성능을 향상시키고자 한다. 시뮬레이션 기반으로 간섭을 포함한 거리-도플러 맵(RD 맵)을 입력으로 하고, 간섭이 없는 RD 맵을 레이블로 하여 CNN을 학습시킴에 있어 LPP를 적용한다. LPP를 통해 신호의 동적 범위를 축소하고 신호 분포를 개선할 수 있으며,시뮬레이션 결과 7.1 dB의 신호대간섭잡음비(SINR) 향상을 확인하였다.","Due to the recent surge in the number of of automotive radars, the issue of interference among multiple radarsoperating in the same frequency band has become prominent. In this study, we aim to enhance the performanceof convolutional neural network (CNN)-based automotive radar interference mitigation by utilizing logarithmicpreprocessing (LPP). We apply LPP in training the CNN, using simulation-based range-Doppler (RD) maps thatinclude interference as inputs and interference-free RD maps as labels. Through LPP, we reduce the dynamicrange of the signals to emphasize subtle signal variations and improve the signal distribution. Simulation resultsconfirm an improvement in the signal-to-interference-plus-noise ratio (SINR) of 7.1 dB."
볼륨-플로우 그래프 기반 폐질환 분류를 위한앙상블 딥러닝 모델,2024,"['합성곱 신경망', '앙상블 딥러닝 모델', '폐질환', '볼륨-플로우 그래프', 'Convolutional Neural Network', 'Ensemble Deep Learning Model', 'Pulmonary Disease', 'Flow Volume Loops']","만성 폐쇄성 폐질환은 만성적인 기도 폐쇄를 특징으로 하는 호흡기 질환이다. 만성 폐쇄성폐질환은 초기에 자각 증상이 거의 없어, 대부분 중증 상태로 악화된다. 또한, 인종, 성별, 키,몸무게 등 다양한 요인을 포함한 폐 질환 분류 회귀식은 복잡하고, 정확한 판별을 위해서는지속적인 갱신을 필요로 한다. 따라서 폐질환의 초기 진단이 용이하도록 간편한 휴대형 페기능 검사기를 통해 산출 가능한 볼륨-플로우 그래프 이미지 기반 분류 모델이 요구된다.본 논문에서는 폐질환 조기 진단을 위해 볼륨-플로우 그래프 이미지의 전처리 및 합성곱 신경망 기반 앙상블 딥러닝 모델을 구현하였고, 이를 검증했다. 합성곱 신경망 기반 앙상블 딥러닝 모델은 VGG16, VGG19, ResNet50, 그리고 MobileNet 구조 기반 4개의 모델로 구성되며, 전부 전이학습 및 미세조정하여 사용하였다. 세부적으로는 부족한 수의 학습 데이터를볼륨-플로우 그래프 이미지의 특성을 고려하여 적합한 데이터 증강기법을 적용하였고, 4개의 모델들은 가중치 기반의 간접투표 방식을 사용했다. 최종 앙상블 모델은 단순히 폐질환유무를 판별하는 것이 아닌 정상, 제한성 폐질환, 폐쇄성 폐질환, 그리고 혼합성 폐질환과 같이 총 4개의 클래스로 분류하는 모델임에도 불구하고, 테스트 데이터를 통한 성능은 정확도90.91%, 가중치 평균 정밀도 91.11%, 가중치 평균 재현율 90.91%로 높은 수치를 보였다.","Chronic Obstructive Pulmonary Disease (COPD) is a respiratory disease characterized bychronic airway obstruction. COPD often progresses to a severe stage, since thereare few noticeable symptoms in the early stages. Also regression equations involingvarious factors such as race, gender, height, and weight to determine whether ornot there is pulmonary disease is complex and needs to be updated periodically.Therefore, there is a demand for a system that can easily analze the presence orabsence of the pulmonary disease, even for non-experts. In this paper, aCNN-based flow volume loops classification model using ensemble learning andappropriate data pre-processing algorithms was proposed and validated to diagnosepulmonary disease in the early stages. The ensemble model was organized by fourCNN models based on VGG16, VGG19, Resnet50, and MobileNet and used transferlearning and fine-tuning for each pre-trained model. Specifically, to overcome asmall amount of data, several data augmentation techniques that took into accountthe characteristics of flow volume loops were used, and soft voting was employedfor the ensemble model. The proposed ensemble model not only could diagnose thepresence or absence of pulmonary disease but could also classify into a total of fourcategories: normal, restrictive, obstructive, and combined pulmonary diseases. As aresult of the experiment, the performance of the proposed ensemble model showedan accuracy of 90.91%, precision of 91.11%, and recall of 90.91%."
잡음에 강건한 이미지 분류 모델을 위한 다양한 필터 크기를 가진 다중 합성곱 신경망 앙상블 학습 연구,2024,"['Convolution Neural Network', 'Ensemble Learning', 'Voting', 'MNIST', 'Robust model']","본 논문에서는 노이즈 이미지에 대한 강건한 분류 모델 작성을 위하여 다양한 필터크기를 가진 다중 합성곱 신경망 앙상블 모델을 연구하였다. 다중 합성곱 신경망 앙상블 모델은 2개의 다중필터 합성곱 신경망 앙상블 모델의 소프트 보팅(soft voting) 조합으로 구성되는데, 각각의 다중필터 합성곱 신경망 앙상블 모델은 다시 5개의 단일 합성곱 신경망의 소프트 보팅 조합으로 구성된다. 단일 합성곱 신경망들은 서로 다른 필터 크기가 적용되었으며, 그 필터 크기는 임의의 크기인 3, 5, 7, 11, 13이다. 단일 합성곱 신경망들은 학습 과정에서 특별한 연산이 적용되었는데, 각 단일 합성곱 신경망에서 마지막 완전 연결 계층의 출력이 서로 적절히 조합되어, 다시 각각의 단일 합성곱 신경망 모델의 소프트맥스 및 교차 엔트로피 오차(softmax-with-Loss) 계층으로 보내져 순전파 연산을 수행한다. 그 후, 오차역전파 연산을 수행하며 가중치를 갱신하도록 함으로써 단일 합성곱 신경망 모델들이 학습 과정에서 상호보완 될 수 있도록 하였다. 작성된 다중 합성곱 신경망 앙상블 학습모델의 강건성 평가는 MNIST(Modified National Institute of Standards and Technology) 손글씨 숫자 이미지 데이터로 수행되었다. 숫자 이미지 데이터는 1개의 정상 데이터 셋과, 3개의 비정상 잡음 데이터 셋으로 구성되어 있으며, 정상/비정상 데이터 상관없이 학습 및 테스트하여 모델의 성능을 평가하였다. 그 결과, 다중 합성곱 신경망 앙상블 모델의 분류 성능이 단일 합성곱 신경망 모델보다 전반적으로 향상된 것을 확인하였다.","A multiple CNN ensemble model was developed using various filter sizes to train a noise-robust image classification model. The multiple CNN ensemble model consisted of a soft voting combination of two multiple-sized filter CNN ensemble models. The multiscale filter CNN ensemble model consisted of a soft voting combination of five single CNN models. Single CNN models were made using 3, 5, 7, 11, and 13-sized filters. During the modeling, a special calculation process was applied to CNNs, outputs of last affine layer in each CNN model are combine properly. The combined outputs were sent to softmax-with-loss layer to conduct rest of forward propagation. Lastly, by progressing progress back propagation calculation, CNN models made it possible to complement each other's weight variables. Evaluation of the robustness of the multiple CNN ensemble model was performed using an MNIST handwritten number image data set, 1 normal data set, and 3 noise added data set. These image data sets were used to model and test the performance of the classification model regardless of normal or noise. The resulting multiple CNN ensemble model had better classification performance than the single CNN model."
다중 입출력 FMCW 레이다를 활용한 합성곱 신경망 기반 사람 동작 인식 시스템,2024,"['MIMO FMCW Radar', 'Human Activity Recognition', 'Point Cloud', 'PointPillars', 'CNN']","본 논문에서는 다중 입출력 주파수 변조 연속파 (MIMO FMCW; multiple input multiple output frequency modulation continuous wave) 레이다 기반 HAR (human activity recognition) 시스템의 설계 및 구현 결과를 제시하였다. 다중 입력 다중 출력 레이다 센서를 통한 포인트 클라우드 데이터를 활용하여 HAR 시스템을 구현하면 사생활 보호와 함께, 안전성 및 정확성 측면에서 장점이 있다. 본 논문에서는, MIMO FMCW 레이다 센서로부터의 포인트클라우드 데이터 기반 HAR을 위해 PointPillars와 DS-CNN (depthwise separable convolutional neural network)을 기반으로 최적 경량 네트워크를 개발하였다. 경량화된 네트워크를 통해 고해상도 포인트 클라우드 데이터를 처리하여 높은 인식 정확도와 함께 효율성을 달성하였다. 결과적으로, 98.27%의 정확도와 11.27M Macs (multiply-accumulates) 연산 복잡도로 구현 가능함을 확인하였다. 또한, 개발한 모델을 라즈베리파이(Raspberry-Pi) 시스템에 구현하여 최대 8 fps의 속도로 포인트 클라우드 데이터 처리가 가능함을 확인하였다.","In this paper, a human activity regeneration (HAR) system based on multiple input multiple output frequency modulation continuous wave (MIMO FMCW) radar was designed and implemented. Using point cloud data from MIMO radar sensors has advantages in terms of privacy, safety, and accuracy. For the implementation of the HAR system, a customized neural network based on PointPillars and depthwise separate convolutional neural network (DS-CNN) was developed. By processing high-resolution point cloud data through a lightweight network, high accuracy and efficiency were achieved. As a result, the accuracy of 98.27% and the computational complexity of 11.27M multiply-accumulates (Macs) were achieved. In addition, the developed neural network model was implemented on Raspberry-Pi embedded system and it was confirmed that point cloud data can be processed at a speed of up to 8 fps."
영상 잡음 제거 신경망 및 구조 최적화,2024,"['Convolutional neural network', 'Image denoising', 'Multi-channel feature map', 'Covariate shift', 'Gaussian noise', '합성곱 신경망', '영상 잡음제거', '다채널 특징맵', '분산 천이', '가우시안 잡음']","합성곱 기반의 신경망이 컴퓨터 비전 분야에서 우수한 성능을 보임이 알려진 후로 다양한 분야에 적용되고 있다.영상 내의 잡음을 제거하는 과제에도 신경망을 이용한 연구가 활발히 수행되고 있다. 우수한 잡음제거 성능을 보이는 구조를 찾고, 또한 그 구조에 적용되는 여러 가지 파라미터를 선정하는 작업은 매우 중요하다. 본 논문에서는 합성곱 신경망을 여러 채널 및 여러 층으로 구성하여 입력 영상 속에 포함되어 있는 잡음을 추정하는 네트워크를 제안한다. 또한 내부 신호의 공변량 천이 현상에 대응하기 위해 배치 정규화를 채택한다. 이러한 구조의 세부 파라미터인 채널 수와 층수를 성능 평가에 의하여 결정하였다. 또한 다양한 학습 데이터를 이용하여 네트워크를 학습시키고, 가우시안 잡음제거 성능을 최신의 연구결과들과 비교하여 제안된 신경망의 우수성을 보인다.","Since convolutional neural networks (CNNs) have been shown to exhibit excellent performance in the field ofcomputer vision, they are being applied to various domains. Research using neural networks for tasks such as removingnoise from images is also being actively conducted. Finding structures that demonstrate superior noise removalperformance and selecting various parameters applicable to these structures are crucial tasks. In this paper, we propose anetwork that estimates noise within input images by constructing convolutional neural networks with multiple channelsand layers. To address the issue of internal covariate shift, batch normalization is adopted. The detailed parameters of thisstructure, such as the number of channels and layers, are determined by evaluating their performance. Additionally, thenetwork is trained using various datasets, and the Gaussian noise removal performance is compared with the latestresearch results to demonstrate the superiority of the proposed neural network."
복합 임베디드 시스템 시계열 데이터를 활용한 딥러닝 이상 탐지 방법 비교 연구,2024,"['Deep Learning(딥러닝)', 'Anomaly Detection(이상 탐지)', '1D CNN(1차원 CNN)']","비행체 같은 복합 임베디드 시스템은 고장이 발생하면 심각한 위험을 초래할 수 있다. 본 논문에서는 복합 임베디드 시스템에서 출력되는 시계열 데이터 셋과 LSTM, 1차원 CNN과 같은 딥러닝 알고리즘을 활용하여 이상 탐지 모델을 생성하고 추론 결과를 비교했다. 그 결과 1차원 CNN 모델이 좋은 성능을 보였다. 이전 연구(합성곱 신경망을 활용한 항공 시스템의 이상 탐지 모델 연구)에서 생성한 2차원 CNN 모델의 추론 성능을 비교한 결과 정확도와 재현율은 2차원 CNN 모델이 높았지만, 추론 속도는 1차원 CNN 모델이 빨랐다. 실시간 이상 탐지가 필요한 복합 임베디드 시스템의 이상 탐지 모델에는 1차원 CNN 모델이 적합한 것으로 판단된다.","Complex embedded systems such as aircraft can lead to serious hazards when failures occur. This paper presents an anomaly detection model using deep learning techniques such as LSTM and 1D CNN on time-series datasets generated from complex embedded systems and compares inference results. Results showed that the 1D CNN model outperformed the LSTM model. Compared with the inference performance of a two-dimensional CNN model created in a previous study (Anomaly Detections Model of Aviation System by CNN), the two-dimensional CNN model had higher accuracy and recall. However, the 1-dimensional CNN model had faster inference speed. We can conclude that the 1D CNN model is more suitable than the LSTM model for anomaly detection in complex embedded systems that require real-time anomaly detection."
Dance Movement Recognition based on Deep Learning,2024,"['Deep learning', 'Convolutional neural network', 'Movement recognition']",,"In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s."
Atrial Fibrillation Identification Using CNNs Based on Genomic Data,2024,['Atrial fi brillation · Convolutional neural network · Genome-wide association studies · Polygenic risk score'],,"Atrial fi brillation (AF) is the most common cardiac arrhythmia and a major cardiovascular disease epidemic of the 21st century. Early diagnosis and intervention are crucial as AF often progresses without symptoms. This study aims to identify AF using genome-wide association studies and convolutional neural networks (CNN). Genomic data from 6,358 individuals were used to develop a CNN model, with L2 regularization applied to prevent overfi tting. The L2-regularized CNN signifi cantly outperformed the regular CNN across various p-value thresholds. For instance, at p< 0.0001, the L2-regularized CNN achieved an accuracy of 0.731 ± 0.071 compared to 0.703 ± 0.055 for the regular CNN. At p< 0.001, the L2-regularized CNN showed an accuracy of 0.630 ± 0.089, while the regular CNN had 0.577 ± 0.095. This demonstrates a notable improvement in model performance with L2 regularization. Although the regular CNN showed higher accuracy in some scenarios, such as achieving 0.984 ± 0.015 at p< 0.01 compared to 0.970 ± 0.020 for the L2-regularized CNN, the performance diff erence between the models decreased as the p-value threshold became more stringent. Overall, L2 regularization not only improved the model’s performance and stability but also reduced the performance gap between the models under stricter p-value conditions. These fi ndings highlight that L2-regularized CNNs can signifi cantly enhance performance in genomic studies, off ering a more eff ective alternative to traditional polygenic risk score methods for AF identifi cation study."
머신러닝 기반 음악 장르 분류에 대한 연구,2024,"['Music Genre', 'Classification of Music', 'Machine Learning', 'CNN(Convolutional Neural Network)', 'LSTM (Long Short-Term Memory)']","음악 장르는 음악을 분류하기 위한 수단으로 박자, 템포, 멜로디의 높낮이 등의 수많은 특징을 사용하여 분류한다. 본 논문에서는 전처리 과정을 통하여 음악의 특징을 추출하고 머신러닝 기법으로 학습시켜 장르를 구분하는 방법을 제안하였다. CNN(Convolutional Neural Network), LSTM (Long Short-Term Memory)의 두 가지 머신러닝 알고리즘을 사용하여 알고리즘별 성능을 비교 분석하였다. 분석 결과, 경음악(light Music), 발라드(Ballad), 록(Rock), 블루스(Blues), 알앤비(R&B), 클래식(Classic) 등 크게 6가지 장르로 분류 실험을 수행한 결과로 CNN을 이용한 머신러닝 기법의 정확도가 98.7%로 가장 높았으며, 이는 특징을 자동으로 추출해주는 CNN의 특성 때문이었다. 높은 정확도를 보여준 CNN을 통해 자동 음악 추천 시스템과 비슷한 응용 분야에서의 활용 가능성을 확인하였으며, 제한된 데이터와 비 최적화된 매개변수 설정에도 불구하고 유의미한 결과를 제시하였다.","Music genres are classified using numerous features such as beat, tempo, and melodic pitch as a means to categorise music. This paper propose a method to classify genres by extracting music features through preprocessing and training them with machine learning techniques. Two machine learning algorithms, CNN (Convolutional Neural Network) and LSTM (Long Short-Term Memory), were used to compare the performance of each algorithm. The results of the analysis showed that the machine learning method using CNN had the highest accuracy of 98.7%, which is due to the characteristics of CNN that automatically extracts features. The high accuracy of CNN confirms the possibility of using it in applications similar to automatic music recommendation systems, and shows significant results despite limited data and non-optimal parameter settings."
Bayesian neural network를 활용한 화재 오인식 개선 연구,2024,"['convolution neural network', 'bayesian neural network', 'MC dropout', 'deep learning', '.']",현재 딥러닝 모델들의 잘못된 예측으로 간혹 사고가 발생하고 있는 게 사실이다. 특히 화재 및 재난의 경우에는 피해 규모는 상상을 초월할 수 있다. 본 논문에서는 화재와 같이 Data 수집이 제한되었을 때 화재의 인식률 저하를 개선하기 위하여 BNN(Bayesian neural network)의 방식 중 하나인 MC(Monte Carlo) dropout을 활용한 화재 오인식 개선에 관해 연구하였다. BNN이 화재 인식 후 불확실성의 분포가 클 때 화재일 가능성이 작다고 판단하여 CNN의 화재 판단을 보류하는 방식으로 화재 인식률을 개선 시켰다. 총 100개의 학습되지 않은 이미지를 활용하여 CNN 방식과 BNN + CNN 방식 사용 시 추론 결과를 서로 비교하였다. 그 결과 약 13%가 불확실성이 높아 개선된 추론 결과를 얻었다. 전체 데이터 확인 결과 4% 정도 에러를 고려하면 CNN에 비해 약 9% 정도 개선된 결과를 얻었다.,"Accidents sometimes occur due to incorrect predictions of current deep learning models. Especially damage from fire or disaster is beyond our imagination. In this paper, we studied recognition rate improvement using Monte Carlo (MC) dropout, one of the Bayesian neural network(BNN) methods to improve the low recognition rate of fire when data collection is limited, such as a fire. When BNN recognized fire and the uncertainty distribution was large, it judged that the probability of a fire was low and improved the fire recognition rate by suspending CNN's fire judgment. One hundred untrained images were used to compare the inference results when using the CNN method and BNN + CNN method. As a result, approximately 13% had high uncertainty, resulting in improved inference results. As a result of checking the entire data, considering the error of about 4%, the results were improved by about 9% compared to CNN."
KoBERT와 KoGPT2 기반의 대형언어모델과 딥러닝을 통합한 리뷰 유용성 예측모형,2024,"['대형언어모델', 'KoBERT', 'KoGPT2', '리뷰 유용성', '통합모형', 'Large Language Models', 'KoBERT', 'KoGPT2', 'Review helpfulness', 'Integrated model']","AI 기술이 산업 전반에서 광범위하게 적용되면서 텍스트 데이터 기반의 대형언어모델이 높은 관심을 받고 있다. 대형 언어모델은 번역, 챗봇, 콘텐츠 생성 등과 같은 자연어 처리 분야에서 활발히 연구되고 있으며, 이커머스 분야에서도 고객 데이터 분석을 위해 사용되고 있다. 제품 및 서비스에 대한 사용 경험을 기반으로 사용자가 직접 작성하는 온라인 리뷰는 고객분석을 위한 중요한 자료이며, 대형언어모델의 활용은 텍스트로 작성되어 있는 리뷰 데이터의 의미 파악을 보다 정확 하게 할 수 있도록 한다. 본 연구는 SVM, 1D-CNN, 2D-CNN, CNN-LSTM의 딥러닝 모델과 대형 언어 모델인 KoBERT 와 KoGPT2로 리뷰 유용성 예측모형을 구축하고, 이를 통합하여 텍스트 내의 복잡한 의미가 반영된 리뷰 유용성 예측모 형을 제안한다. 구글 지도의 리뷰 데이터를 활용하였으며, 딥러닝 기법에서는 CNN-LSTM의 예측 성과가 72.74%로 가장 우수한 것으로 나타났다. KoBERT와 KoGPT2의 대형언어모델은 73.22%와 75.74%로 기존의 머신러닝 기법의 예측 모델 보다 대형언어모델을 기반으로 한 예측 모형이 우수한 성능을 보였다. 본 연구에서 제안한 딥러닝 기법과 대형 언어 모델을 통합한 통합모형에서는 76.37%의 정확도로 예측성과를 향상시켰으며, 통합모형은 텍스트의 의미를 보다 정확하게 반영하고, 예측성과를 향상시키며 예측모형의 안정성을 높일 수 있다.","As AI technology is widely applied across industries, text data-based large language models are gaining significant attention. Large language models are actively researched in natural language processing fields such as translation, chatbots, and content creation, and are also used for customer data analysis in e-commerce. Online reviews, which are written directly by customers based on their experiences with products and services, are crucial for customer analysis, and leveraging large language models can help better understand the meanings embedded in these text reviews. This study proposes a review helpfulness prediction model by integrating deep learning models such as SVM, 1D-CNN, 2D-CNN, CNN-LSTM, and large language models KoBERT and KoGPT2, thereby reflecting the complex semantics within the text. Experiment results indicate that the CNN-LSTM model showed the best prediction performance at 72.74%. The large language models KoBERT and KoGPT2 achieved 73.22% and 75.74%, respectively, showing that prediction models based on large language models performed better than traditional machine learning models. The integrated model, combining the deep learning techniques and large language models proposed in this study, improved prediction performance with an accuracy of 76.37%, indicating that the integrated model can more accurately reflect the text’s meaning, enhance prediction performance, and improve model stability."
NSL-MHA : 클라우드 이상 행위 탐지 모델의 적대적 훈련 기법 제안,2024,"['클라우드 시스템 보안', '이상 탐지', '딥러닝', '적대적 공격', 'NSL-MHA', 'Cloud System Security', 'Anomaly Detection', 'Deep Learning', 'Adversarial Attack', 'NSL-MHA']","오늘날 기업 및 산업 분야에서 클라우드 컴퓨팅 기술의 활용이 증가함에 따라 클라우드 컴퓨팅 기술의 취약점을 활용한 보안 위협 문제가 대두되고 있다. 이에 대응하기 위해, 클라우드 이상 행위 탐지 기술의 중요성이 강조되고 있다. 최근 연구에 따르면, CNN 모델 기반 이상 행위 탐지 기술은 우수한 탐지 성능을 보이는 것을 입증하였다. 그러나, CNN 모델 기반이상 행위 탐지 기술은 적대적 공격에 취약하다는 단점이 존재한다. 따라서, 본 논문에서는NSL-MHA 적대적 훈련 기법을 제안하여 CNN 모델 기반 이상 행위 탐지 기술의 적대적공격 취약점을 극복하고자 한다. 실험을 통해 NSL-MHA 적대적 훈련 기법이 CNN 모델 기반 이상 행위 탐지 기술의 적대적 공격 취약성을 극복함을 검증하였다.","""As the utilization of cloud computing techniques increases in today’s enterprises and industries, security threats exploiting the vulnerabilities of cloud computing techniques have become a significant concern. In response, the importance of anomaly detection techniques in cloud computing is being emphasized. Recent research has demonstrated that CNN model-based anomaly detection techniques achieve excellent detection performance. However, a drawback of these techniques is their vulnerability to adversarial attacks. Therefore, this paper proposes the NSL-MHA adversarial training method to overcome the vulnerabilities of CNN-based anomaly detection techniques against adversarial attacks. From the experimental results, it was verified that the NSL-MHA adversarial training method overcomes the drawbacks of CNN model-based anomaly detection techniques."""
상품 카테고리 자동분류를 위한 BERT-분류기 아키텍처 연구,2024,"['문장 분류', '문장 유사도', 'Sentence BERT', 'CNN', 'ResNet', 'Transformer', 'Classification', 'Sentence classification', 'Sentence similarity', 'Sentence BERT', 'CNN', 'ResNet', 'Transformer', 'Classification']","본 연구는 생활 속 존재하는 다양한 상품들의 명칭을 BERT를 통해 임베딩 벡터화한 다음 이를 기반으로 상품 카테고리 예측을 수행하는 아키텍처에 대한 연구이다. 아키텍처의 성능은 상품 명칭으로부터 임베딩 추출을 수행하는 BERT 모델과, 추출된 임베딩으로 카테고리 예측을 수행하는 분류기에 의해 결정된다. 따라서 본 연구는 우선 상품 명칭 분류에 적합한 BERT 모델을 선정하고, 선정된 BERT 모델에 다양한 분류기를 적용하여 가장 높은 성능을 달성하는 BERT-분류기 조합을 찾고자 하였다. 최초 적합한 BERT 모델 선정에는 단순한 CNN 분류기를 사용하였으며 이를 baseline으로 다른 분류기와 성능을 비교하였다. 아키텍처의 성능은 카테고리 정답에 대한 precision, recall, f1 score, accuracy로 정량화하여 평가하였다. 실험 결과 BERT 측면에서는, Sentence BERT 모델이 비교 대상인 일반 BERT 모델보다 적합함을 확인하였다. 그리고 분류기 측면에서는, Sentence BERT와 CNN으로 구성된 baseline 대비하여 Residual Block이 추가 적용된 분류기가 더 높은 성능을 보였다. 본 연구에 사용된 Sentence BERT 모델의 경우 한국어 데이터가 학습되지 않은 단순 모델로, 향후 추가적 연구를 통해 다양한 한국어 데이터를 학습시켜 Domain Adaptation을 수행할 경우 추가적 성능 향상이 기대된다.","This research focuses on an architecture that vectorizes the names of various products found in daily life using BERT, followed by predicting product categories based on these embeddings. The architecture's performance is determined by the BERT model, which extracts embeddings from product names, and the classifier that predicts categories from these embeddings. Consequently, this research initially aimed to identify a BERT model suitable for classifying product names and then find the most efficient combination of BERT model and classifier by applying various classifiers to the chosen BERT model. A simple CNN classifier was employed for the initial selection of a suitable BERT model, serving as a baseline for performance comparison with other classifiers. The architecture's effectiveness was quantified using precision, recall, f1 score, and accuracy for category predictions. Experimental results showed that the Sentence BERT model was more suitable for this task than a conventional BERT model. Additionally, classifiers enhanced with Residual Blocks demonstrated superior performance compared to the baseline combination of Sentence BERT and CNN. The Sentence BERT model used in this study, not trained on Korean data, suggests that further improvements could be achieved through Domain Adaptation by training with diverse Korean datasets."
향상된 흉부 엑스레이 진단을 위한 멀티 클래스 토큰 기반 하이브리드 트랜스포머 모델,2024,"['Chest X-ray', 'Vision transformer', 'Multi-label classification', 'Deep learning']","흉부 엑스레이(Chest X-ray)는 폐의 이상을 진단하고 발견하는 데 일반적으로 사용되는 의료 영상 기술 중 하나로 딥러닝, 특히 컨벌루션 신경망 (Convolutional Neural Network, CNN)을 기반으로 한 컴퓨터 보조 진단(Computer Aided Diagnosis, CAD) 시스템은 의사들의 진단을 돕는데 많이 활용되고 있다. 이 연구에서는 CNN과 트랜스포머를 효과적으로 통합하여 흉부 질환의 분류 성능을 높이는 새로운 모델, 즉 Multi-Class Token CheXFormer (MCTCheXFormer)를 제안한다. 이 모델은 convolution 연산과 self-attention 메커니즘을 사용하여 흉부 엑스레이 내 지역 및 전역적인 특징을 효과적으로 활용하도록 설계되었다. MCTCheXFormer는 트랜스포머와 흉부 엑스레이 분류에서 뛰어난 성능을 보여주는 CNN 모델인 CheXNet으로 구성되며, 트랜스포머의 class token은 single-class token에서 multi-class token으로 확장하였다. 확장된 class token은 클래스별 특징을 학습하고 구분할 수 있도록 해 다중 레이블 분류 성능을 높였다. 또한, CheXNet을 통해 생성한 신뢰도 점수를 multi-class token에 attention 가중치로 적용하는 Iterative Class Token Weighting (ICW) 기법을 제안하여 모델의 흉부 질환 분류 성능을 높이고자 하였다. 제안 모델의 트랜스포머는 Pyramid Vision Transformer (PVT)를 기반으로 하고 있으며 총 4단계로 이루어져 있다. Token refinement 모듈을 추가하여 각 단계에서 생성되는 다양한 크기의 patch token의 차원과 multi-class token의 차원이 같도록 조절하였다. 제안한 MCTCheXFormer는 14개의 흉부 질환에 클래스 레이블을 제공하는 ChestX-ray14 데이터셋에서 CNN 또는 트랜스포머를 사용하는 기존 흉부 엑스레이 분류 모델과 비교하였다. 비교 결과 MCTCheXFormer는 다른 모델 대비 뛰어난 성능을 보였고, 이를 통해 흉부 질환에서 정확하고 효율적인 진단을 위한 트랜스포머의 활용 가능성을 보여주었다.","Chest X-rays are commonly used medical imaging techniques for diagnosing and detecting lung abnormalities. Computer-aided diagnosis (CAD) systems based on deep learning, especially convolutional neural networks (CNNs), have proven valuable in assisting doctors with these diagnoses. In this study, we propose a novel model, the Multi-Class Token CheXFormer (MCTCheXFormer), which integrates CNNs and transformers to enhance chest disease classification performance. This model leverages both convolutional operations and self-attention mechanisms to effectively capture local and global features in chest X-rays. MCTCheXFormer combines a transformer with CheXNet—a CNN model known for its strong performance in chest X-ray classification. Here, the transformer's class token is extended from a single-class token to a multi-class token, enabling it to learn and differentiate class-specific features and improve multi-label classification. Additionally, we introduce an Iterative Class Token Weighting (ICW) technique, which applies the confidence scores generated by CheXNet as attention weights to the multi-class tokens, further enhancing classification performance. The model’s transformer is based on the Pyramid Vision Transformer (PVT) and consists of four stages. A token refinement module is added to ensure that the dimensions of the patch tokens generated at each stage align with those of the multi-class tokens. We evaluated the proposed MCTCheXFormer on the ChestX-ray14 dataset, which provides class labels for 14 chest diseases, comparing it with existing CNN- and transformer-based models. MCTCheXFormer outperformed the other models, highlighting the potential of transformers for accurate and efficient chest disease diagnosis."
딥러닝 기반 시계열 분석 모델의 불확실성 정량화 비교 연구,2024,"['딥러닝', '안정적인 모델', '불확실성', '시계열', 'deep learning', 'reliable model', 'uncertainty', 'time series', 'MC Dropout']","인공지능의 발전으로 머신러닝과 딥러닝 모델이 다양한 산업에서 적용되어 좋은 성능을 보이고 있으며 최근 금융시장에서도 적용되는 사례가 증가하고 있다. 그러나 딥러닝 모델은 예측 결과가 나오게 된 과정과 해석을 파악하기에 어려움이 있다. 이는 결과에 대한 해석이 특히 중요시 되는 금융에 딥러닝 모델을 적용하는데 어려움이 있어 신뢰할 수 있는 모델에 대한 필요성이 대두되고 있다. 신뢰할 수 있는 모델이란 모델에 Dropout과 같은 변화에도 일관된 예측을 보이는 안정적인 모델로 모델의 불확실성을 통해 파악할 수 있다. 본 연구는 딥러닝 모델의 불확실성을 확인하여 신뢰할 수 있는 모델의 기준을 보이고 모델의 불확실성을 통해 이상 탐지하는 모델을 파악하고자 한다. 실험에서 전통적인 통계 모델 ARIMA(Auto Regressive Integrated Moving Average)와 시계열 데이터에 주로 쓰이는 딥러닝 모델인 CNN(Convolutional Neural Network), LSTM(Long Short Term Memory), MLP(Multi-Layer Perceptron), 및 CNN-LSTM 모델을 적용하였고 MC(Monte Carlo) Dropout을 통해 베이지안 관점에서 불확실성을 측정하였다. 실험 결과 다양한 패턴의 시계열 데이터에 대해 통계 모델보다 여러 딥러닝 모델이 성능이 좋음을 확인하였고 성능이 가장 우수하지는 않아도 불확실성이 적어 안정적인 모델이 LSTM 계열임을 확인하였다. 이를 통해 불확실성이 모델의 정확도와 함께 모델 선택 시 고려되어야 할 요소임을 확인하였고 불확실성이 큰 모델이 이상 탐지하므로 CNN 계열의 모델이 적합함을 확인하였다.","With the advancement of artificial intelligence, machine learning, and deep learning, their applications in various industries, particularly finance, have increased. However, interpreting predictions from deep learning models poses challenges, especially in finance where result interpretation is important. This study aims to determine the uncertainty of stable deep learning models, despite changes in the model like dropout, to establish standards for reliable models and identify those detecting anomal data through model uncertainty. In the experiment, the traditional statistical model ARIMA and deep learning models mainly used for time series analysis, CNN, LSTM, MLP, and CNN-LSTM. Uncertainty was measured from a Bayesian perspective using MC Dropout. The experimental results confirmed that deep learning models performed better than statistical models for various patterns of time series data. It was observed that, even if the performance was not the best, LSTM based models exhibited low uncertainty, indicating stability. Consequently, this study highlights the importance of considering uncertainty along with accuracy in model selection. Moreover, it was confirmed that models with higher uncertainty are suitable for anomaly detection, making CNN based models particularly fitting for this purpose."
흉부 X-선 영상을 이용한 Vision transformer 기반 폐렴 진단 모델의 성능 평가,2024,"['딥러닝', '폐렴 진단', '흉부 X-선 영상', 'Vision transformer', 'Deep learning', 'Pneumonia detection', 'Chest X-ray image']",,"The various structures of artificial neural networks, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have been extensively studied and served as the backbone of numerous models. Among these, a transformer architecture has demonstrated its potential for natural language processing and become a subject of in-depth research. Currently, the techniques can be adapted for image processing through the modifications of its internal structure, leading to the development of Vision transformer (ViT) models. The ViTs have shown high accuracy and performance with large data-sets. This study aims to develop a ViT-based model for detecting pneumonia using chest X-ray images and quantitatively evaluate its performance. The various architectures of the ViT-based model were constructed by varying the number of encoder blocks, and different patch sizes were applied for network training. Also, the performance of the ViT-based model was compared to the CNN-based models, such as VGGNet, GoogLeNet, and ResNet. The results showed that the traninig efficiency and accuracy of the ViT-based model depended on the number of encoder blocks and the patch size, and the F1 scores of the ViT-based model ranged from 0.875 to 0.919. The training effeciency of the ViT-based model with a large patch size was superior to the CNN-based models, and the pneumonia detection accuracy of the ViT-based model was higher than that of the VGGNet. In conclusion, the ViT-based model can be potentially used for pneumonia detection using chest X-ray images, and the clinical availability of the ViT-based model would be improved by this study."
딥러닝과 사용자 감정인식 기반의 스마트디퓨저 구현,2024,"['smart diffuser', 'emotional analysis', 'CNN', 'temperature and humidity', 'facial expression detecting', '.']","본 논문에서는 사용자의 감정상태를 인식하여 적절한 향을 낼 수 있는 딥러닝 기반의 스마트 디퓨저를 제안한다. 시스템의 전면부에 위치한 카메라센서를 통해 사용자의 얼굴표정을 인식하고, 이를 CNN을 이용한 감정인식모델을 통해 분석하여 결과값을 바탕으로 향을 자동으로 택한다. 또한 감정 유사도를 분석하여 감정의 깊이에 따라 팬의 세기를 제어하며 온습도 상황에 변동에도 일정한 정도의 발향을 위해 온습도 센서를 통해 팬의 동작시간을 조절한다. 동작예시로 행복감정을 인식하여 95.42%의 감정유사도와 25.7℃와 습도 67.3%에서 42초간 동작하였다. 본 논문에서는 스마트 디퓨저의 설계와 동작과정, CNN기반 감정분석모델과 프로토타입 동작실험 및 고찰에 대해 기술한다.","In this paper, we propose a deep learning-based smart diffuser that can recognize the user's emotional state and produce an appropriate scent. The system utilizes a camera sensor located at the front to recognize the user's facial expressions. These expressions are analyzed through an emotion recognition model based on CNN, which then automatically selects the fragrance based on the results. Additionally, the system analyzes the similarity of emotions to control the fan's intensity according to the depth of the emotion. It adjusts the fan's operation time through temperature and humidity sensors to maintain a consistent level of diffusion despite changes in environmental conditions. As an example of operation, the happiness emotion was recognized and operated for 42 seconds at an emotional similarity of 95.42% and 25.7℃ and humidity of 67.3%. This paper describes the design and operation process of the smart diffuser, the CNN-based emotion analysis model, as well as the prototype's operation experiments and considerations."
기하학적 특징 추가를 통한 얼굴 감정 인식 성능 개선,2024,"['ASM', 'Facial Expression Recognition', 'Inception', 'VGG']",,"In this paper, we propose a new model by adding landmark information as a feature vector to the existing CNN-based facial emotion classification model. Facial emotion classification research using CNN-based models is being studied in various ways, but the recognition rate is very low. In order to improve the CNN-based models, we propose algorithms that improves facial expression classification accuracy by combining the CNN model with a landmark-based fully connected network obtained by ASM. By including landmarks in the CNN model, the recognition rate was improved by several percent, and experiments confirmed that further improved results could be obtained by adding FACS-based action units to the landmarks."
고객 서비스 개선을 위한 비정형 텍스트 데이터 자동 분류 모델 비교 - 고객 불만 데이터를 대상으로,2024,"['고객 불만', '자동 분류', '서비스 개선', '비정형 데이터', '나이브 베이즈', '랜덤 포레스트', '서포트 벡터 머신', '합성곱 신경망', '순환 신경망', 'Customer Complaints', 'Automatic Classification', 'Service Improvement', 'Unstructured Data', 'Naive Bayes', 'Random Forest', 'SVM', 'CNN', 'LSTM']","정보기술의 발전과 디지털 커뮤니케이션의 확산으로 인해 급증하는 고객 불만과 피드백을 효과적으로 관리하고 처리하는 방법이 필요하다. 특히, 대부분의 데이터가 비정형 데이터인 상황에서, 이를 신속히 처리하고 분류하여 고객 서비스를 개선하는 것은 중요하다. 이에 본 연구에서는 전통적 분류 모델인 Naive Bayes, SVM, Random Forest와 딥러닝 모델인 CNN, LSTM을 살펴보고, 보스턴시의 교통 불만 데이터에 적용하여 고객 불만 데이터의 자동 분류 성능을 비교 분석하였다. 연구 결과, CNN과 LSTM은 각각 81%와 97%의 높은 분류 정확도를 보여, 고객 불만처럼 복잡하고 다양한 패턴의 비정형 데이터 처리에 더욱 효과적임을 확인하였다. 이러한 결과는 딥러닝 모델이 고객 불만 데이터의 특성을 더 잘 분석하고, 문맥적 연결을 감지하는 능력이 우수하기 때문이다. 본 연구는 기업이 고객의 목소리를 신속하고 정확하게 파악하고 대응할 수 있는 고객 서비스 개선 방법론을 제공하며, 이는 기업 경쟁력을 강화하는 데 기여할 것으로 기대된다.","With the advancement of information technology and the proliferation of digital communication, there is an increasing need for effective management and processing of the growing volume of customer complaints and feedback. Particularly, when most of the data is unstructured, it is crucial to quickly process and classify this data to improve customer service. In this study, we examine traditional classification models such as Naive Bayes, SVM, and Random Forest, as well as deep learning models like CNN and LSTM. These models were applied to Boston's traffic complaint data to compare the performance of automatic classification of customer complaint data. The results showed that CNN and LSTM achieved high classification accuracies of 81% and 97%, respectively, confirming their effectiveness in handling complex and diverse patterns of unstructured data, such as customer complaints. These findings demonstrate that deep learning models are better at analyzing the characteristics of customer complaint data and detecting contextual connections. This study provides a methodology for companies to quickly and accurately understand and respond to customer voices, thereby enhancing corporate competitiveness."
Meta Pseudo Count를 활용한 준지도 학습 기반 인구 밀집도 추정,2024,"['인구밀집도', 'Meta Pseudo Labels', 'CNN', 'Transformer', 'Crowd Density Estimation', 'Meta Pseudo labels', 'CNN', 'Transformer']","대규모 인파가 모이는 장소의 안전을 보장하기 위한 인구 밀집도 분석 기술은, 딥러닝 학습방법을 활용한 지능형 영상 분석 기술을 사용한다. 인구 밀집도 분석 분야에서 레이블링 작업의 비용과 노동력 문제를 해결하기 위해 준지도 학습 방법이 주목받고 있다. 인구 밀집도 분석 기술은 교통 관리, 안전 감시 등 다양한 분야에서 중요한 연구 주제로 활용되며, CNN 계열의 모델을 사용하여 예측 모델을 구축한다. 레이블링 작업은 비용과 노동력이 많이 투입되는 과정이며, 실제 환경은 레이블링 되지 않은 데이터의 양이 레이블링 된 데이터의 양보다 많다. 본 연구에서는 인구 밀집도 분석을 위해 Meta Pseudo Count(MPC)라는 준지도 학습 방법을 제안한다. Meta Pseudo Count 방법론은, 레이블이 없는 데이터에 대해 Pseudo Count를 생성하고, 이를 이용하여 Teacher 모델이 Student 모델을 학습시킨다. 기존의 지도학습 모델에 레이블이 없는 데이터를 추가로 학습하였을 때, Meta Pseudo Count 방식은 예측의 정확도가 준지도 학습 모델의 장점을 보여주며, 레이블이 없는 데이터를 활용하여 학습 모델의 일반화 능력이 향상되었다.","The technology of Crowd density estimation, which ensures the safety of densely populated areas, utilizes intelligent video analysis techniques based on deep learning. Semi-supervised learning methods have gained attention in the field of crowd density analysis to address the challenges of labeling costs and labor. Crowd density estimation is a important research topic applied in various areas such as traffic management and safety surveillance, often using CNN-based models to build prediction models. Labeling tasks are costly and labor-intensive, and in real fields, the amount of unlabeled data outweighs the labeled data. In this paper, a semi-supervised learning method called Meta Pseudo Count (MPC) is proposed for crowd density estimation. The Meta Pseudo Count methodology generates pseudo counts for unlabeled data and uses them to train a Teacher model to educate a Student model. When unlabeled data is added to conventional supervised learning models, the Meta Pseudo Count approach demonstrates the accuracy of predictions, showing the advantages of semi-supervised learning models. It also enhances the generalization ability of the trained model by utilizing unlabeled data for learning."
근감소증 모니터링과 동작 예측을 위한 스마트 디바이스 기반의 딥러닝 모델 연구,2024,"['근감소증', '동작 인식', '상황인지', '딥러닝', '신경망', 'GRU', 'CNN-CRU', 'Sacopenia', 'Human Activity Recognition', 'Context Awareness', 'Deep-Learning', 'Deep Neural Network', 'GRU', 'CNN-CRU']","본 연구는 근감소증 판별과 근감소증으로 인한 낙상 등의 동작 감지를 위한 딥러닝 모델 연구를 수행한다. 스마트폰의 높은 보급률을 활용하여 추가 구매 물품 없이 근감소증을 관찰할 수 있는 시스템을 제안하고 가능성을 확인한다. 스마트폰에 내장된 9축 IMU 센서를 활용해 정상 걸음, 비정상 걸음, 낙상, 달리기, 스쿼트 자세에 대한 데이터 총 307,584개를 수집한 후 학습을 통해 최적의 알고리즘을 확인한다. 근감소증 판별을 위해 이진 데이터 분류 모델과 움직임 또는 동작 분류 모델인 다중 분류 모델의 최적 알고리즘을 확인한다. 이진 분류 모델에서 GRU 모델이 정확도가 100%로 정확도와 속도가 가장 높았고 다중 분류 모델의 경우 CNN-GRU를 활용한 경우93.72%로 가장 높았고 연구에서 제안하는 모델에서 학습 속도 또한 172.16초로 가장 빨랐다. 본연구를 통해 운동 예측 또는 동작 감지와 같은 딥러닝 모델의 최적 조합을 확인했으며, 디지털헬스케어 분야와 실시간 인공지능 처리 시스템 연구 등에 활용될 수 있을 것이다.","This study investigates deep learning models for predicting Sarcopenia and motion, such as falls, resulting from Sarcopenia. By leveraging the widespread use of Smartphones, We propose a system that monitors Sarcopenia without the need for additional equipment. A total of 307,584 data points were collected using the built-in 9-axis of IMU sensor of a smartphone, capturing normal walking, abnormal walking, falling, running, and squatting movements. We aims to identify the optimal algorithm through training. To classify Sarcopenia, both binary classification models and multi-class classification models for movement or motion recognition were evaluated. In the binary classification model, the GRU model achieved 100% accuracy, showing the highest performance in both accuracy and speed. For the multi-class classification model, the CNN-GRU combination reached the highest accuracy of 93.72%, and the proposed model demonstrated the fastest training time at 172.16 seconds. This research identifies the optimal combination of deep learning models for motion prediction and detection, and it has potential applications in the fields of digital healthcare and real-time artificial intelligence processing systems."
Shanghai Containerised Freight Index Forecasting Based on Deep Learning Methods: Evidence from Chinese Futures Markets,2024,"['SCFI 예측', '선물 시장', '머신 러닝', 'CNN', 'LSTM', 'SCFI Forecast', 'Futures Market', 'Machine Learning', 'Convolution Neural Network', 'Long and Short-term Memory']",,"With the escalation of global trade, the Chinese commodity futures market has ascended to a pivotal role within the international shipping landscape. The Shanghai Containerized Freight Index (SCFI), a leading indicator of the shipping industry’s health, is particularly sensitive to the vicissitudes of the Chinese commodity futures sector. Nevertheless, a significant research gap exists regarding the application of Chinese commodity futures prices as predictive tools for the SCFI. To address this gap, the present study employs a comprehensive dataset spanning daily observations from March 24, 2017, to May 27, 2022, encompassing a total of 29,308 data points. We have crafted an innovative deep learning model that synergistically combines Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) architectures. The outcomes show that the CNN-LSTM model does a great job of finding the nonlinear dynamics in the SCFI dataset and accurately capturing its long-term temporal dependencies. The model can handle changes in random sample selection, data frequency, and structural shifts within the dataset. It achieved an impressive R² of 96.6% and did better than the LSTM and CNN models that were used alone. This research underscores the predictive prowess of the Chinese futures market in influencing the Shipping Cost Index, deepening our understanding of the intricate relationship between the shipping industry and the financial sphere. Furthermore, it broadens the scope of machine learning applications in maritime transportation management, paving the way for SCFI forecasting research. The study’s findings offer potent decision-support tools and risk management solutions for logistics enterprises, shipping corporations, and governmental entities."
Radiographic Analysis of Scoliosis Using Convolutional Neural Network in Clinical Practice,2024,"['Scoliosis', 'Cobb Angle', 'Convolutional Neural Network', 'Radiography']","목적 척추측만증 평가 시 컨볼루션 신경망(convolutional neural network; 이하 CNN)을 이용한 자동콥각도 측정(automated Cobb angle measurement; 이하 ACAM)의 신뢰성과 정확성을 평가하고 측정시간을 비교하였다. 대상과 방법 척추측만증이 의심되는 환자 411명을 대상으로 하였으며, 척추 방사선사진에 대해 ACAM을 수행하였다. 관찰자 1 (두 명의 근골격 영상의학과 의사의 합의)과 관찰자 2 (영상의학과 전공의)가 콥각도를 독립적으로 측정하였다. 콥각도 측정치는 관찰자 1의 측정치를 기준치로 사용하여 분류하였다. 관찰자 간 신뢰성과 상관관계를 급내상관계수(intraclass correlation coefficient; 이하 ICC)와 스피어만 순위 상관계수를 이용하여 평가하였고 ACAM과 관찰자의 정확도와 측정시간을 평가하였다. 결과 ACAM은 관찰자 1과 높은 신뢰성을 보이며 매우 높은 상관관계를 나타냈고(ICC = 0.976, 스피어만의 순위 상관계수 = 0.948) 평균 콥각도 차이는 1.1이었다. 전체적인 정확도는 높았으며(88.2%), 특히 경도(92.2%) 및 중등도(96%) 척추측만증 그룹에서 높았다. 반면 척추 비대칭 그룹에서는 정확도가 낮았고(77.1%) 심한 척추측만증 그룹에서는 높았으며(95%) 관찰자보다 콥각도를 작게 측정하는 경향을 보였다. ACAM은 관찰자에 비해 측정시간이 절반 정도 짧았다(p < 0.001). 결론 CNN을 이용한 ACAM은 경도나 중등도 척추측만증의 콥각도 측정을 향상시키나, 척추 비대칭이나 심한 척추측만증에 사용하는 데는 제한 점이 있었다. 하지만 측정시간을 현저히 감소시켰다.","Purpose To assess the reliability and accuracy of an automated Cobb angle measurement (ACAM) using a convolutional neural network (CNN) for scoliosis evaluation and to compare measurement times. Materials and Methods ACAM was applied to spine radiographs in 411 patients suspected of scoliosis. Observer 1 (consensus of two musculoskeletal radiologists) and observer 2 (a radiology resident) measured Cobb angle (CA). CA measurements were categorized using observer 1's measurements as the reference standard. Inter-observer reliability and correlation were assessed using intraclass correlation coefficient (ICC) and Spearman's rank correlation coefficient, respectively. Accuracy and measurement time of ACAM and observers were evaluated. Results ACAM demonstrated excellent reliability and very high correlation with observer 1 (ICC = 0.976, Spearman's rank correlation = 0.948), with a mean CA difference of 1.1. Overall accuracy was high (88.2%), particularly in mild (92.2%) and moderate (96%) scoliosis. Accuracy was lower in spinal asymmetry (77.1%) and higher in severe scoliosis (95%), although the CA was lower compared to the observers. ACAM significantly reduced measurement time by nearly half compared to the observers (p < 0.001). Conclusion ACAM using CNN enhances CA measurement for assessing mild or moderate scoliosis, despite limitations in spinal asymmetry or severe scoliosis. Nonetheless, it substantially decreases measurement time."
거리영상과 딥러닝을 활용한 가로수준의 범죄불안감 측정 및 시각화,2024,"['범죄불안감', '거리영상', '딥러닝', '샴네트워크', '랭크넷', 'Global-Patch-RSS-CNN모델', '정성평가', 'Fear of Crime', 'Street View Images', 'Deep Learning', 'Siamese Network', 'RankNet', 'Global-Patch-RSS-CNN model', 'Qualitative Evaluation']","거주민의 도시 건조환경(Urban Built Environment)에 대한 인식은 도시연구, 도시계획 및 도시설계에 중요한 요소이다. 범죄불안감이란 특정 장소와 특정 범죄에 대해서 느끼는 범죄 발생 가능성에 대한 불안감의 심리량을 의미하는데, 이는 개개인의 주관적인 평가이다. 범죄불안감은 실제 범죄율보다 빠르게 증가하고 있어, 사람들이 범죄불안감을 느끼는 지역을 찾는 것은 범죄예방에 효과적이며 중요한 과정이다. 하지만 기존 연구에서 도시 건조환경에 대한 불안감 측정은 소수의 사람과 제한된 범위를 대상으로 설문조사나 현장조사에 의존하여 제한적이었다. 본 연구의 목적은 거리영상과 딥러닝 기술을 활용하여 시민들이 느끼는 범죄 불안감을 측정하고 시각화하는 것이며 연구대상지역은 서울시 영등포구이다. 거리영상을 활용하여 범죄불안감을 측정하기 위해서는 거리 영상에 대한 사람들의 범죄불안감을 측정하고, 이를 딥러닝 모델을 활용하여 평가점수를 예측하는 모델을 구축해야 한다. 이를 위해 본 연구에서는 카카오맵 API를 활용하여 거리영상을 수집하였다. 수집한 영상 중 20,886장의 거리영상을 활용하여 상대적으로 불안감을 느끼는 거리가 어느 쪽인지를 응답하도록 하는 171,942개의 훈련데이터 셋을 구축하였다. 구축된 쌍별비교 데이터 셋으로 Global-Patch-RSS-CNN모델을 훈련 후, 훈련된 모델을 연구대상 지역 전체에 적용하여 범죄불안감 예측점수를 도출하고 시각화였다. 본 연구는 거리영상과 딥러닝 기술을 활용하여 도시의 범죄불안감을 측정하는 첫 사례를 제시하였다는 점, 그리고 범죄불안감이 높게 평가되는 지역의 환경 특성을 분석하여, 효과적인 도시 계획 및 범죄 예방 전략 수립에 기여할 수 있다는 점에 의의가 있다.","Residents’ perception of the urban built environment is an important factor in urban studies, urban planning, and urban design. Perceived fear of crime is a psychological measure of fear about the likelihood of a crime occurring in a particular place and for a particular crime, which is a subjective assessment by the individual. Fear of Crime is increasing faster than the actual crime rate, so identifying areas where people feel fear of crime is an effective and important process for crime prevention. However, previous studies have been limited by relying on surveys or fieldwork with a small number of people and a limited scope. The purpose of this study is to measure and visualize the fear of crime felt by citizens using street view images and deep learning technology, and the study area is Yeongdeungpo-gu, Seoul. In order to measure fear of crime using street view images, it is necessary to measure people’s fear of crime on street images and build a model to predict the evaluation score using a deep learning model. For this study, we collected street view images using Kakao Map API. Using 20,886 street view images from the collected images, we built a training data set of 171,942 images that ask users to respond to which street they feel relatively unsafe. After training the Global-Patch-RSS-CNN model with the constructed pairwise comparison data set, the trained model was applied to the entire study area to derive and visualize the prediction score of fear of crime. This study is significant in that it presents the first case of measuring urban fear of crime using street view images and deep learning technology, and it can contribute to effective urban planning and crime prevention strategies by analyzing the environmental characteristics of areas with high fear of crime."
반지도학습 딥러닝 모델을 이용한 진동 기반 구조물 손상 탐지 기술,2024,"['반지도학습', '딥러닝', '진동 응답', '구조물 손상 탐지', 'LK-Block Encoder', '1-D CNN', 'Semi-supervised learning', 'Deep learning', 'Vibration responses', 'Damage detection', 'LK-Block Encoder', '1-D CNN']","본 연구는 LK-Block Encoder를 반지도학습하여 구조물의 진동 응답을 통한 손상 탐지 프레임워크를 제안하고 이를 검증하기 위해전단 빌딩을 이용한 실험을 진행하였다. 1-D CNN 기반 은닉층 블록을 4개 직렬로 연결한 LK-Block Encoder를 반지도학습한 후 특징 공간 상에서 정상 상태의 진동 데이터와 손상 상태의 진동 데이터를 분류하는 임계치를 설정하여 진동 데이터로부터 손상을 탐지할 수 있는 프레임워크를 제시하였다. 이를 검증하기 위해 전단 빌딩의 기둥 두께를 다르게 하여 손상 시나리오를 가정한 후 제안한 프레임워크를 통해 손상 탐지를진행하였다. 그 결과, 큰 손상 상태에 대해서 97.03%의 정확도를 보였다. 정상 상태의 데이터 셋을 4개로 증가시켜 모델을 학습한 결과 작은 손상 상태에 대해서도 99.66% 정확도로 손상을 탐지하는 것을 보였다. 또한 탐지 대상과 다른 종류의 손상으로 모델을 학습시키는 경우에도 정상 상태 데이터를 증가시키면 손상 탐지 정확도가 높아지는 것을 확인하였다. 이를 통해 고유진동수 분석으로 탐지가 어려운 작은 손상에 대해서 제안한 프레임워크가 높은 성능으로 손상을 탐지하는 것을 보였다.","This study proposes a framework for damage detection in structures through vibration responses using semi-supervised learning of an LK-Block Encoder, and validated through experiments with a shear building. The framework utilizes an LK-Encoder, which is composed of four serially connected 1-D CNN-based hidden layer blocks, and applies semi-supervised learning to set a threshold in the feature space for distinguishing between normal and damaged vibration data, thereby enabling damage detection from vibration data. To validate this approach, the study assumed damage scenarios by varying the thickness of shear building columns, and damage detection was conducted using the proposed framework. Results showed an accuracy of 97.03% for large damage condition. When the dataset of the normal condition was increased fourfold, small damage was detected with an accuracy of 99.66%. Additionally, it was confirmed that even when the model was trained with different types of damage from the target detection, increasing the amount of normal data improved damage detection accuracy. These results indicate that the proposed framework effectively detects even minor damage, which is difficult to identify through natural frequency analysis, with high accuracy."
"Development and Multicenter, Multiprotocol Validation of Neural Network for Aberrant Right Subclavian Artery Detection",2024,"['Aberrant subclavian artery', 'artificial intelligence', 'deep learning']",,"Purpose: This study aimed to develop and validate a convolutional neural network (CNN) that automatically detects an aberrant right subclavian artery (ARSA) on preoperative computed tomography (CT) for thyroid cancer evaluation.Materials and Methods: A total of 556 CT with ARSA and 312 CT with normal aortic arch from one institution were used as the training set for model development. A deep learning model for the classification of patch images for ARSA was developed using two-dimension CNN from EfficientNet. The diagnostic performance of our model was evaluated using external test sets (112 and 126 CT) from two institutions. The performance of the model was compared with that of radiologists for detecting ARSA using an independent dataset of 1683 consecutive neck CT.Results: The performance of the model was achieved using two external datasets with an area under the curve of 0.97 and 0.99, and accuracy of 97% and 99%, respectively. In the temporal validation set, which included a total of 20 patients with ARSA and 1663 patients without ARSA, radiologists overlooked 13 ARSA cases. In contrast, the CNN model successfully detected all the 20 patients with ARSA.Conclusion: We developed a CNN-based deep learning model that detects ARSA using CT. Our model showed high performance in the multicenter validation."
Potential Improvement of GK2A Clear-Sky Atmospheric Motion Vectors Using the Convolutional Neural Network Model,2024,['Atmospheric motion vector · Remote sensing · Optical flow · Geostationary satellite'],,"In this study, we propose a new approach to improve the accuracy of the horizontal atmospheric motion vector (AMV) in cloud-free skies and its forecasting. We adapted the optical flow of the convolutional neural network (CNN) framework model using two 10-min interval infrared images at water vapor channels (centered at 6.3, 7.0, and 7.3 m) from the Korean geostationary satellite GEO-KOMPSAT-2A (GK2A). Since all pixels had seamless AMVs calculated by CNN (CNN AMVs), we could also predict AMVs using the linear regression method. The tracking performance of the CNN-based algorithm was validated using AMVs retrieved from GK2A (GK2A AMVs) by estimating the difference between those values and the ECMWF (European Centre for Medium-Range Weather Forecasts) Reanalysis v5 (ERA5) wind data over Korea in 2022.CNN AMVs showed similar or better root-mean-square vector differences (RMSVDs) than GK2A AMVs (12.33–12.86 vs.15.89–19.96 m/s). The RMSVDs of the forecasted AMVs were 2.74, 2.95, 3.41, and 4.79 m/s at lead times of 10, 20, 30, and 60 min, respectively. Consequently, our method showed higher accuracy for tracking motion in the production of AMVs and succeeded in forecasting AMVs. We expect that such potential improvements in computational accuracy for operational GK2A AMVs will contribute to increased accuracy when forecasting meteorological phenomena related to wind."
Transformer 기반의 HDR 영상 복원 알고리즘을 통한 효과적인 Ghost Artifact 제거,2024,"['High dynamic range imaging', 'Ghost artifact removal', 'Multi-exposure low dynamic range images', 'Transformer', 'Attention mechanism']","High dynamic range (HDR) imaging의 주요 문제는 다중 노출의 low dynamic range (LDR) 이미지들을 병합할 때 발생하는 ghostartifact를 제거하는 것이다. 주어진 다중 노출 이미지들 간의 움직임이 심한 영역에서는 필요한 정보가 로컬 영역에 존재하지 않기 때문에 local 특징 추출에 특화된 convolutional neural network (CNN) 기반 방법으로는 ghost artifact가 불가피하다. 이 문제를 해결하기 위해 우리는 local connectivity 특성을 지닌 CNN과 global dependency 획득이 가능한 transformer를 결합시킨 새로운 HDR 이미지 복원 네트워크를 제안한다. 제안 방법은 CNN을 통해 다중 노출의 LDR 이미지들에서 고차원의 feature들을 추출하고, 추출된feature들을 중간 노출 LDR 기준으로 낮은 노출 LDR과는 Low-transformer에, 높은 노출 LDR과는 High-transformer에 입력시켜global 정보를 캡처한다. 본 논문의 실험 결과를 통해 제안 방법이 기존 방법들과 비교하여 우수한 성능을 보임을 입증한다.","The primary issue in high dynamic range (HDR) imaging is the removal of ghost artifacts that occur when mergingmulti-exposure low dynamic range (LDR) images. In areas with significant motion between the given multi-exposure images,necessary information is not present in the local region, making ghost artifacts inevitable for convolutional neural network(CNN)-based methods specialized in local feature extraction. To address this issue, we propose a novel HDR image reconstructionnetwork that combines CNNs with transformers capable of acquiring global dependency while retaining local connectivitycharacteristics. Our method extracts high-dimensional features from multi-exposure LDR images using CNNs and then feeds thesefeatures into Low-transformers for low-exposure LDR images and High-transformers for high-exposure LDR images, based on amedium exposure LDR image, to capture global information. Through experiments presented in this paper, we demonstrate thesuperior performance of the proposed method compared to the existing methods."
Novel Deep Learning Hybrid-Ensemble Method for Financial Domain Information and Stock Price Forecasting,2024,"['Time Series Forecasting', 'Stock Prediction', 'LSTM', 'Hybrid Model', 'Deep Learning', 'Prediction Model', '주가 시계열 예측', '주식 예측', 'LSTM', '하이브리드 모델', '딥러닝', '예측 모델']",,"This study aims to develop the novel technique for time series forecasting of stock prices. For the research methods, we developed method based on stacking mechanism of LSTM(Long Short Term Memory), Ridge Regression, Linear Regression and CNN(Convolutional Neural Network) for predicting “Close” prices of Amazon, Microsoft, Netflix and Apple stock prices for next day, next 7 days, next 14 days and 21 days. In the results of this research, we compared our method to another popular hybrid method CNN-LSTM and also to base models of our method such as CNN and LSTM as well as RNN(Recurrent Neural Network). We used four datasets and four periods to predict and our method outperformed other models on metrics such MSE (Mean Squared Error), RMSE (Root Mean Squared Error), RMSE (Root Mean Squared Error) and SD (Standard Deviation of Errors). In conclusion, the LSTM-ENSEMBLE-CNN (proposed method) model stands out as the best performer among the tested models. It achieves the lowest MSE, RMSE, and MAE, indicating minimal prediction error."
Unraveling trends in schistosomiasis: deep learning insights into national control programs in China,2024,"['Schistosomiasis', 'Deep learning', 'Spatio-temporal analysis', 'China']",,"OBJECTIVES: To achieve the ambitious goal of eliminating schistosome infections, the Chinese government has implemented diverse control strategies. This study explored the progress of the 2 most recent national schistosomiasis control programs in an endemic area along the Yangtze River in China.METHODS: We obtained village-level parasitological data from cross-sectional surveys combined with environmental data in Anhui Province, China from 1997 to 2015. A convolutional neural network (CNN) based on a hierarchical integro-difference equation (IDE) framework (i.e., CNN-IDE) was used to model spatio-temporal variations in schistosomiasis. Two traditional models were also constructed for comparison with 2 evaluation indicators: the mean-squared prediction error (MSPE) and continuous ranked probability score (CRPS).RESULTS: The CNN-IDE model was the optimal model, with the lowest overall average MSPE of 0.04 and the CRPS of 0.19. From 1997 to 2011, the prevalence exhibited a notable trend: it increased steadily until peaking at 1.6 per 1,000 in 2005, then gradually declined, stabilizing at a lower rate of approximately 0.6 per 1,000 in 2006, and approaching zero by 2011. During this period, noticeable geographic disparities in schistosomiasis prevalence were observed; high-risk areas were initially dispersed, followed by contraction. Predictions for the period 2012 to 2015 demonstrated a consistent and uniform decrease.CONCLUSIONS: The proposed CNN-IDE model captured the intricate and evolving dynamics of schistosomiasis prevalence, offering a promising alternative for future risk modeling of the disease. The comprehensive strategy is expected to help diminish schistosomiasis infection, emphasizing the necessity to continue implementing this strategy."
인공지능을 이용한 고밀도 폴리에틸렌의 자외선 부식도 예측,2024,"['High density polyethylene', 'Ultraviolet rays', 'Artificial intelligence', 'Convolutional neural network', 'Corroison']","선박 제작에 주로 사용되는 섬유강화플라스틱(FRP) 소재는 우수한 내구성과 내충격성을 제공하지만, 자외선에 장기간 노출될 경우 심각한 변형을 겪게 되며, 이는 폐선 처리 과정을 복잡하게 만들어 해상 환경오염의 주요 원인 중 하나로 지목되고 있다. 이에 대한 대응책으로 친환경적이고 재활용이 가능한 소재로 주목받고 있는 고밀도 폴리에틸렌(HDPE)의 사용이 증가하고 있으나, HDPE 또한 내열성과 내후성의 문제로 인해 자외선에 대한 취약성을 드러내고 있다. 본 논문에서는 부식된 HDPE를 시간 별로 분석하고 예측하기 위해 인공지능 기법인 Convolutional Neural Network(CNN)을 적용한다. CNN은 딥러닝 분야에서 이미지 분류 및 데이터 학습에 유용한 장점을 가지고 있다. 이 기법을 활용하여 UV LAMP로 특정 시간 동안 HDPE를 자외선에 노출시킨후, 부식된 이미지 데이터를 취득하고 훈련을 진행하였고 90% 이상의 정확도를 도출하였다. 연구 결과를 기반으로 선박 소재의 노후화를 예측하고, 이에 따른 폐선 처리 문제와 해상 환경오염을 사전에 방지할 수 있는 효과적인 방안을 모색할 수 있을 것으로 기대된다.","Fiber-reinforced plastic (FRP) materials, which are mainly used in ship manufacturing, provide excellent durability and impact resistance, but long-term exposure to ultraviolet rays causes serious deformation, which complicates the processing of closed wires and is pointed out as one of the main causes of marine environmental pollution. As a countermeasure against this, the use of high-density polyethylene (HDPE), which is attracting attention as an eco-friendly and recyclable material, is increasing, but HDPE is also showing vulnerability to ultraviolet rays due to the limitations of heat resistance and weather resistance. In this paper, we apply the Convolutional Neural Network (CNN), an artificial intelligence technique, to analyze and predict HDPE corroded by exposure to ultraviolet rays over time. CNN has useful advantages for image classification and data learning in the field of deep learning, and through this technique, it was confirmed that after exposing HDPE to ultraviolet rays for a specific time using UV LAMP, it can be predicted with more than 90% accuracy by acquiring it with corroded image data and conducting training. Based on the research results, it is expected that it will be possible to predict the aging of ship materials and find effective ways to prevent the disposal of abandoned ships and marine environmental pollution in advance."
인공지능 기반 심리상담에 활용되는 딥러닝 기법 고찰,2024,"['인공지능', '심리상담', '딥러닝', '머신러닝', 'Artificial Intelligence', 'Psychological Counseling', 'Deep Learning', 'Machine Learning']","목적 본 연구는 첫째, 현재까지 발전해온 딥러닝 기법들에 대해서 고찰하여 정리해 보며, 둘째, 이러한 딥러닝 기법들이 실제로 인공지능 심리상담 로봇에 어떻게 활용될 수 있는지 논의하는데 주 목적이 있다.방법 인공지능 심리상담에서 활용되고 있는 최신 딥러닝 기법을 고찰하기 위해 2022년까지 감정 분석 및 표정 생성, 텍스트 생성분야에서 딥러닝 기법을 활용한 국내외 논문과 이를 설명한 서적들을 모두 검색하였다. 국내 논문 검색은 RISS, KISS, 국외 논문검색은 ERIC(ProQuest), JSTOR, Google Scholar 등의 논문 검색 사이트를 활용하였다.결과 인공지능을 심리상담에 활용할 때 주로 주목하는 기술은 상대방의 표정에서 감정을 인식하고 비슷한 표정을 생성해 내거나혹은 상대방이 말한 문장에서 감정을 인식하고 이에 응답하는 문장을 생성해 내는 것이다. 이에, 머신러닝과 딥러닝의 개념을 소개하고, 사람의 뇌에서 이루어지는 원리를 이용하여 인공지능을 만드는 방식인 딥러닝 기법들인 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), LSTM(Long Short Term Memory), Transformer, BERT(Bidirectional Encoder Representations from Transformers), GPT(Generative Pretrained Transformer), GAN(Generative Adversarial Network) 등이 작동하는 방식을 기술하였다. 특히, 지금까지 이미지 분석을 통한 감정 인식 프로그램은 주로 CNN을활용하고, 언어는 GPT-2, LSTM 등을 활용하여 연구가 진행되어 왔음이 확인되었다.결론 현존하는 딥러닝 기법 중 인공지능을 심리상담에 활용할 때 주로 주목하는 기술인 상대방의 표정에서 감정을 인식하고 비슷한표정을 생성 혹은 상대방이 말한 문장에서 감정을 인식하고 이에 응답하는 문장을 생성하는 방식이나, 아직까지 규칙 기반 챗봇이주를 이룬다. 이러한 딥러닝 기법을 활용한 인공지능 기반 상담의 장단점을 다루었으며 향후 자연스러운 상호작용이 가능한 기술발전이 요구될 뿐 아니라 그에 대한 효과성 검증이 필요하다.","Objectives This study aims to review and summarize deep learning techniques that have been developed to date and to discuss how they can be applied in practice to artificial intelligence-based psychology counseling robots.Methods To examine the latest deep learning techniques utilized in artificial intelligence psychological counseling, an extensive literature search was conducted for research papers and relevant books from both domestic and international sources in the fields of emotion analysis, facial expression generation, and text generation.. For domestic literature, databases such as RISS and KISS were utilized, and for international literature, research paper search sites including ERIC (ProQuest), JSTOR, and Google Scholar were employed.Results When applying artificial intelligence in psychological counseling, the prominent technology of interest involves recognizing emotions from the interlocutor's facial expressions and generating similar expressions, or recognizing emotions from sentences spoken by the interlocutor and generating responsive sentences. The study introduced the concepts of machine learning and deep learning and explained the workings of deep learning techniques, such as CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), LSTM (Long Short Term Memory), Transformer, BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pretrained Transformer), and GAN (Generative Adversarial Network). These techniques are founded on the principles derived from human brain functioning. Particularly, emotion recognition programs through image analysis have predominantly relied on CNN, while research in the realm of language has advanced with the utilization of GPT-2, LSTM, and similar methods.Conclusions Among the existing deep learning techniques, the recognition of emotions from the interlocutor's facial expressions and the generation of similar expressions, or the recognition of emotions from sentences spoken by the interlocutor and the generation of responsive sentences, are the technologies predominantly under scrutiny for their application in artificial intelligence-based psychological counseling. Nevertheless, rule-based chatbots continue to dominate the landscape. This paper explored the merits and demerits of AI-based counseling employing such deep learning techniques. Looking ahead, there is a need for the advancement of technology that enables natural interactions, coupled with the essential verification of its effectiveness."
A feasibility study on distinguishing fluor concentrations in liquid scintillators from scintillation events observed by photomultiplier tubes using convolutional neural networks,2024,"['Liquid scintillator · Linear alkyl benzene · 2', '5-Diphenyloxazole · 1', '4-Bis(2-methylstyryl)benzene · Light yield · Pulse shape · Wavelength shift · Convolution neural network']",,"Linear alkyl benzene-based liquid scintillators (LSs) have been extensively used as targets for neutrino detectors in recent decades owing to their environmentally friendly properties, high light yield, and cost efciency. Neutrino events are typically reconstructed from scintillation events observed by photomultiplier tubes (PMTs) attached to the detector. A comprehensive understanding of the LS response is required for interpreting reconstructed neutrino events during detector operation. In this study, we investigate the properties of scintillation events such as light yield, waveform, and wavelength shift of the emitted scintillation light at various concentrations of fuor dissolved in the LS. The light yield, waveform, and wavelength shift exhibit a nonlinear relationship with fuor concentration, complicating the determination of fuor concentration from the observed characteristics of the scintillation events. We employ a convolutional neural network (CNN) to model this nonlinear relationship between fuor concentration and LS properties. The CNN learns the distinctive features of the scintillation events from observed waveforms and the relative ratio of the light yield below 425 nm to the total light yield detected by a PMT at diferent fuor concentrations. The trained CNN was able to distinguish the scintillation events with diferent 2,5-diphenyloxazole and 1,4-bis(2-methylstyryl)benzene concentrations according to the observed waveform and relative wavelength shift. The classifed scintillation events for each LS sample exhibited clear features for the diferent LS concentrations, emphasizing the discriminative capability of the trained CNN. This research presents the frst demonstration of LS fuor concentration discrimination using machine-learning techniques in PMT-based detectors."
온디바이스 탑승자 모니터링 시스템을 위한 딥러닝 알고리즘 제안,2024,"['LSTM', 'CNN', 'Deep learning', 'Passenger monitoring', 'Self-driving']","자율주행 차량은 운전자나 동승자의 조작 없이 스스로 운전할 수 있는 차량으로, 자율주행 기술 수준에 대해서는 국제적으로 SAE의 표준이 사용되고 있다. 현재 구글, 엔비디아, 테슬라 등 해외 IT 기업을 중심으로 레벨 4 자율주행 차량의 시스템 및 개발이 진행 중이다. 레벨 3 이상의 자율주행 차량의 경우 자율주행 시스템이 운전자의 역할을 수행해야 하므로, 높은 수준의 자율주행을 구현하기 위해서는 판단 시스템에 대한 성능개선이 필요하다. 성능 개선은 딥러닝을 활용하여 이루어질 수 있으며 딥러닝 기반의 자율주행 시스템을 구축하기 위해서는 충분한 시나리오와 데이터 세트가 필요하다. 본 연구에서는 CNN-LSTM 모델을 통해 차량 탑승자의 상황을 판단하여 시나리오를 생성하는 이미지 캡션 알고리즘을 제안하고,  알고리즘 훈련 후  Perplexity, Loss 결과를 분석한다. 훈련된 알고리즘을 기반으로 시뮬레이션을 진행하여 적절한 상황인지 캡셔닝 데이터가 생성되는지 분석한다.","An autonomous vehicle is a vehicle that can operate on its own without the manipulation of a driver or passenger, and the standard of SAE (Society of Automatic Engineers) is used internationally for the level of autonomous driving technology. Currently, the system and development of level 4 autonomous vehicles are underway, centering on foreign it companies such as Google, Nvidia, and Tesla. For self-driving cars at level-3 or higher, the autonomous driving system must play the role of the driver, so it is necessary to advance the judgment system to implement high-level autonomous driving. In order to construct a deep learning-based autonomous driving system, sufficient scenarios and datasets are required. This study proposes an image captioning algorithm that creates a scenario by judging the situation of the passenger in the vehicle through the CNN-LSTM model, and analyzes whether appropriate data are generated for learning the monitoring system through simulation."
임베디드 시스템에서의 객체 탐지 네트워크의 가속을 위한  중요도 탐색 필터 가지치기 기법 연구,2024,"['Object detection', 'Network compression', 'Pruning', 'Inference time']","최근, 컴퓨터 기술이 발달하면서 CNN 기반의 객체 탐지 네트워크와 관련된 연구가 활발히 진행되고 있다. 하지만 많은 수의 CNN은 제한된 메모리와 연산량을 가지는 임베디드 환경에서의 추론을 어렵게 하는 원인이 된다. 이 문제의 대표적인 해결 방법으로 네트워크 가지치기 기법이 있다. 네트워크 가지치기 기법은 중복된 역할을 하는 파라미터를 제거하여 추론 시 요구되는 메모리와 연산량을 감소시켜 임베디드 보드에서의 추론을 용이하게 할 수 있다. 하지만 대부분의 가지치기 기법은 두 단계의 학습을 요구하여 많은 시간과 자원이 소모되고 가지치기에 따른 채널의 관계 변화를 반영하지 못해 최적의 경량 네트워크를 보장할 수 없다. 따라서 본 논문에서는 최적의 경량 네트워크를 얻기 위한 중요도 탐색 기법을 제안하고 가지치기의 과정을 단순화하여 한 단계의 훈련만으로 가지치기가 가능한 중요도 탐색 필터 가지치기 기법을 제안한다. 본 논문에서는 VGG-16과 ResNet-50을 백본 네트워크로 가지는 SSD 네트워크에 가지치기를 적용하고 Jetson Xavier NX에서 추론 속도를 측정하였다. ResNet-50을 이용하는 네트워크에서 실험 결과 mAP(0.5)는 가지치기 비율에 따라 0.5 %, 0.7 %, 1.0 % 감소하였지만, 추론 시간은 12.75 %, 16.03 %, 21.66 % 향상되었다. 또한 학습 시간은 다른 기법보다 최대 43.85 % 빠르며 유사한 가지치기 비율의 네트워크와 비교할 때 높은 성능을 가진다.","In recent years, with the development of computer technology, research on CNN-based object detection networks has been actively conducted. However, a large number of CNNs can make inference difficult in embedded environments with limited memory and computation. A typical solution to this problem is network pruning. Network pruning can facilitate inference on embedded boards by reducing the amount of memory and computation required by removing redundant parameters. However, most pruning methods require two stages of training, which consumes a lot of time and resources, and cannot guarantee an optimal lightweight network because they cannot reflect the changes in channel relationships due to pruning. Therefore, this paper proposes an importance search method to obtain an optimal lightweight network, and simplifies the pruning process to propose an importance search filter pruning method that can be pruned with only one stage of training. In this paper, we apply pruning to the SSD network with VGG-16 and ResNet-50 as the backbone network, and measure the inference speed on Jetson Xavier NX. In the network using ResNet-50, the experimental results showed that mAP(0.5) decreased by 0.5%, 0.7%, and 1.0% depending on the pruning ratio, but inference time improved by 12.75%, 16.03%, and 21.66%. In addition, the learning time is up to 43.85% faster than other methods and has high performance when compared to networks with similar pruning ratios."
낙상 판별을 위한 웨어러블 센서 데이터의 최적 샘플링 모델,2024,"['낙상 감지', '샘플링 주기', '데이터베이스', '센서 데이터', 'CNN-LSTM(Convolutional Neural Networks-Long Short Term Memory)', 'fall detection', 'sampling frequency', 'database', 'sensor data', 'CNN-LSTM (Convolutional Neural Networks-Long Short Term Memory)']",,"Recently, the demand for fall risk prediction data of workers through smart band sensors worn by workers at industrial sites has been increasing. For the battery efficiency of the wearable device, research on an appropriate sampling period of sensor data is required, but related research has not yet been conducted. This paper proposes an optimal sampling frequency selection method that can minimize battery consumption by comparing and analyzing the fall detection performance according to the sampling interval of sensor data. Learning models for fall detection apply convolutional neural network-long short-term memory (CNN-LSTM) deep learning. It learns the model with three fall data KFALL, DLR, and FallAllD, respectively, and applies the downsampled data of each model. In this case, the model is learned by selecting only an action showing a waveform similar to a fall. As a result of the study, it was confirmed that the performance of fall discrimination can be maintained even if it increases five times from the existing sampling frequency. This suggests that the amount of batteries consumed for sensor data sampling can be significantly reduced while maintaining the performance of the current fall detection."
Utilizing Deep Learning for Early Diagnosis of Autism: Detecting Self-Stimulatory Behavior,2024,"['Autism Spectrum Disorder(ASD)', 'Computer Vision', 'Stereotyped behavior', 'Early diagnosis', 'CNN', 'GRU']",,"We investigate Autism Spectrum Disorder (ASD), which is typified by deficits in social interaction, repetitive behaviors, limited vocabulary, and cognitive delays. Traditional diagnostic methodologies, reliant on expert evaluations, frequently result in deferred detection and intervention, particularly in South Korea, where there is a dearth of qualified professionals and limited public awareness. In this study, we employ advanced deep learning algorithms to enhance early ASD screening through automated video analysis. Utilizing architectures such as Convolutional Long Short-Term Memory (ConvLSTM), Long-term Recurrent Convolutional Network (LRCN), and Convolutional Neural Networks with Gated Recurrent Units (CNN+GRU), we analyze video data from platforms like YouTube and TikTok to identify stereotypic behaviors (arm flapping, head banging, spinning). Our results indicate that the LRCN model exhibited superior performance with 79.61% accuracy on the augmented platform video dataset and 79.37% on the original SSBD dataset. The ConvLSTM and CNN+GRU models also achieved higher accuracy than the original SSBD dataset. Through this research, we underscore AI's potential in early ASD detection by automating the identification of stereotypic behaviors, thereby enabling timely intervention. We also emphasize the significance of utilizing expanded datasets from social media platform videos in augmenting model accuracy and robustness, thus paving the way for more accessible diagnostic methods."
온라인 한글 필기 인식을 위한 전처리 알고리즘 개발,2024,"['온라인 필기 인식', '한글 필기', '한글 자모', '전처리', 'CNN']","최근 인공지능 기술이 발전하면서 상당히 진화된 응용 서비스가 제공되고 있다. 이러한 인공지능 기술은 대용량 데이터, 고성능 처리 인프라, 복잡한 모델을 필요로 한다. 하지만 모든응용이 이러한 개발과정을 따라야 하는 것은 아니다. 응용의 성격에 따라 적절한 전처리 작업을 수행한다면 적당한 크기의 데이터와 비교적 간단한 모델로도 향상된 성능을 보일 수있다. 본 논문에서는 오래된 연구 주제 중 하나인 온라인 한글 필기 인식 시스템을 개발하고자 한다. 사용자가 모바일 기기에 글자를 입력하면, 입력한 획에 대하여 전처리 작업을 수행하여 자음/모음 후보를 결정한다. 이후 단순한 CNN 기반 모델을 이용하여 인식을 진행하도록 한다. 아주 간단한 모델이지만 전처리 작업을 통해 입력을 자음/모음 단위로 최소화하고,그 결과 출력의 개수도 자/모음에 해당하는 40여개로 줄일 수 있었다. 그에 따라 평균 95.6%의 인식률을 보일 수 있었다.","""With the recent development of artificial intelligence technology, highly evolved application services are being provided. These artificial intelligence technologies require large amounts of data, high-performance processing infrastructure, and complex models for learning. However, not all applications have to follow this development process. In other words, if appropriate preprocessing job is performed according to the nature of the application, improved performance can be obtained with data of appropriate size and a simple model. In this paper, we intend to develop an online Hangul handwriting recognition system, one of the old research topics. When the user writes a character on a mobile device, a preprocessing is performed on the input stroke to determine a consonant/vowel candidates. After that, a simple CNN-based model is used to proceed with recognition. Although it is a very simple model, the user handwriting was minimized in units of consonants/ vowels through preprocessing, and as a result, the number of outputs could be reduced to about 40 corresponding to consonants/vowels. Accordingly, it was possible to show an average recognition rate of 95.6%."""
Vision Transformers-Based Transfer Learning for Breast Mass Classification From Multiple Diagnostic Modalities,2024,['Vision Transformer  · Transfer Learning  · Breast Mass  · Ultrasound  · Mammography'],,"Breast mass evaluation is crucial for early breast cancer diagnosis via imaging. While Convolutional Neural Network (CNN)- based deep learning (DL) has enhanced this process, it suff ers from computational complexity and limited spatial encoding.Vision Transformer (ViT)-based DL, more adept at encoding spatial information, presents a promising alternative. This study introduces a ViT-based transfer learning (TL) method for breast mass classifi cation. Three ViT-based TL architectures pretrained on ImageNet were proposed and evaluated using ultrasound and mammogram datasets. Comparative analysis against ViT trained from scratch and CNN-based TL was conducted. Results showed the ViT-based TL method achieving the highest area under curve (AUC) of 1 ± 0 for both datasets, outperforming ViT from scratch and yielding similar or better performance compared to CNN-based TL. Despite its computational cost, ViT-based TL demonstrates superior classifi cation capabilities for breast mass images. This research provides a foundational framework for future studies exploring ViT-based TL in breast cancer diagnosis."
이미지 변환을 통한 RF 신호 기반의 드론 및 성능 평가,2024,"['Image transformation', 'RF signals', 'Convolutional neural network', 'Drone classification']","드론 기술의 급속한 발전과 다양한 산업에서의 응용이 크게 확대되어감과 함께 보안 위협 또한 증가하고 있으며, 이를 해결하기 위한 연구가 요구되고 있다. 본 연구에서는 드론 분류를 위하여 RF 신호를 사용하였고, 이를 전처리하기 위해 웨이블릿 변환, STFT 및 Mel-Spectrogram 분석을 수행하고, 이를 이미지로 변환하여 학습하는 CNN 기반 학습 모델을 개발하였다. 또한 Image 변환 과정에서 병렬 처리를 최적화하여 계산 속도를 향상시켰다. 제안된 모델은 기존 Spectrogram 변환 방식 대비 학습 속도를 크게 단축하며, 실시간 탐지에 적합한 성능을 보였다. 결론적으로, 본 연구는 Image 변환 방식을 통한 CNN 모델을 통해 RF 신호 기반 드론 탐지의 분류의 정확성과 실시간성을 향상시켰다.","The rapid advancement of drone technology has led to increasing security threats, requiring effective countermeasures. This study presents a CNN-based model for drone classification using RF signals, processed with wavelet transform, STFT, and Mel-spectrogram. By optimizing parallel image conversion, the model achieves faster computation and supports real-time detection. The proposed approach enhances both classification accuracy and real-time performance compared to conventional methods."
Transformer Network-Aided Relative Pose Estimation for Non-cooperative Spacecraft Using Vision Sensor,2024,"['Monocular vision', 'Pose Estimation', 'Perspective-n-Point', 'Gauss-Newton Method', 'Convolution Neural Network', 'Transformer']",,"The objective of the proposed work is to perform monocular vision-based relative 6-DOF pose estimation of the non-cooperative target spacecraft relative to the chaser satellite in rendezvous operations. In this work, the convolutional neural network (CNN) is replaced by the high-resolution transformer network to predict the feature points of the target satellite. The self-attention mechanism inside the transformer provides the advantage of overcoming the inadequacies of the translation equivariance, 2D neighborhood awareness, and long-range dependencies in CNN. First, the 3D model of the target satellite is reconstructed using the inverse direct linear transform (IDLT) method. Then, the pose estimation pipeline is developed with a learning-based image-processing subsystem and geometric optimization of the pose solver. The image-processing subsystem performs target localization using CNN-based architecture. Then, the key points detection network performs regression to predict 2D key points using the transformer-based network. Afterward, the predicted key points based on their confidence scores are projected onto the corresponding 3D points, and the pose value is computed using the efficient perspective-n-point method. The pose is refined using the non-linear iterative Gauss–Newton method. The proposed architecture is trained and tested on the spacecraft pose estimation dataset and it shows superior accuracy both in translation and rotation values. The architecture has shown robustness against the drastically changing clutter background and light conditions in the space images due to the self-attention mechanism. Moreover, this method consumes less computation resources by using fewer floating-point operations and trainable parameters with low input image resolution."
뇌전증 환자의 MEG 데이터에 대한 분류를 위한 인공신경망 적용 연구,2024,['(MEG)'],,"This study performed a multi-classification task to classify mesial temporal lobe epilepsy with left hippocampal sclerosis patients (left mTLE), mesial temporal lobe epilepsy with right hippocampal sclerosis (right mTLE), and healthy controls (HC) using magnetoencephalography (MEG) data. We applied various artificial neural networks and compared the results. As a result of modeling with convolutional neural networks (CNN), recurrent neural networks (RNN), and graph neural networks (GNN), the average k-fold accuracy was excellent in the order of CNN-based model, GNN-based model, and RNN-based model. The wall time was excellent in the order of RNN-based model, GNN-based model, and CNN-based model. The graph neural network, which shows good figures in accuracy, performance, and time, and has excellent scalability of network data, is the most suitable model for brain research in the future."
Building Detection: Testing a New Object-Based Approach Against Neural Networks,2024,"['High-rise Building Detection', 'Convolutional Neural Network', 'Object-based', 'Azimuth Angle']",,"Automated identification of HRBs (High-rise Buildings) on satellite images is challenging when densely populated areas are concerned. Factors that increase complexity are, among others, roads and both the azimuth and elevation angle of the sensor. In this study, two different effective HRB detection techniques are proposed. The first method is using CNNs (Convolutional Neural Networks), an extensively used tool for pattern recognition in the field of machine learning. However, domain movement considerably reduces the CNN's performance on the test data in other domains, making it difficult to generalize. Besides, obtaining the dense annotations on the remote sensing images is expensive and time-consuming. Therefore, a new object-based approach is proposed that includes multi-resolution segmentation and relief displacement by azimuth angles of the sensor. Both methods were tested using images from four regions in South Korea using VHR (Very High Resolution) satellite imagery from the KOMPSAT-3 and WorldView-3. The results show that the performance of both methods heavily depends on factors such as building size and density as well as on external factors such as the position, shape, and size of HRBs. It can be concluded that our proposed method using the relationship between the azimuth angle of the sensor and the relief displacement of the building has several distinct advantages over the CNN-based approach. E.g. the CNN performance considerably relies on the availability of a large number of training data. In addition, quantitative evaluation showed an accuracy improvement rate of at least 30% in intersection over union and F1 score compared to the object-based benchmark models. Eventually, our proposed method allows to evaluate the performance of each image individually, which helps to identify the scenarios where a certain method works best."
Deep Learning for Green Chemistry: An AI-Enabled Pathway for Biodegradability Prediction and Organic Material Discovery,2024,['Biodegradability · SMILES · Green chemistry'],,"The increasing global demand for eco-friendly products is driving innovation in sustainable chemical synthesis, particularly the development of biodegradable substances. Herein, a novel method utilizing artifi cial intelligence (AI) to predict the biodegradability of organic compounds is presented, overcoming the limitations of traditional prediction methods that rely on laborious and costly density functional theory (DFT) calculations. We propose leveraging readily available molecular formulas and structures represented by simplifi ed molecular-input line-entry system (SMILES) notation and molecular images to develop an eff ective AI-based prediction model using state-of-the-art machine learning techniques, including deep convolutional neural networks (CNN) and long-short term memory (LSTM) learning algorithms, capable of extracting meaningful molecular features and spatiotemporal relationships. The model is further enhanced with reinforcement learning (RL) to better predict and discover new biodegradable materials by rewarding the system for identifying unique and biodegradable compounds. The combined CNN-LSTM model achieved an 87.2% prediction accuracy, outperforming CNN- (75.4%) and LSTM-only (79.3%) models. The RL-assisted generator model produced approximately 60% valid SMILES structures, with over 80% being unique to the training dataset, demonstrating the model’s capability to generate novel compounds with potential for practical application in sustainable chemistry. The model was extended to develop novel electrolytes with desired molecular weight distribution."
Enhanced Indoor Localization Scheme Based on Pedestrian Dead  Reckoning and Kalman Filter Fusion with Smartphone Sensors,2024,"['IoT', 'Indoor localization', 'Pedestrian Dead Reckoning', 'Neural Network', 'motion recognition', 'and Smartphone Sensors', 'IoT', '실내 측위', '보행자 측위 항법', '신경망', '동작 인식 및 스마트폰 센서']",,"Indoor localization is a critical component for numerous applications, ranging from navigation in large buildings to emergency response. This paper presents an enhanced Pedestrian Dead Reckoning (PDR) scheme using smartphone sensors, integrating neural network-aided motion recognition, Kalman filter-based error correction, and multi-sensor data fusion. The proposed system leverages data from the accelerometer, magnetometer, gyroscope, and barometer to accurately estimate a user's position and orientation. A neural network processes sensor data to classify motion modes and provide real-time adjustments to stride length and heading calculations. The Kalman filter further refines these estimates, reducing cumulative errors and drift. Experimental results, collected using a smartphone across various floors of University, demonstrate the scheme's ability to accurately track vertical movements and changes in heading direction. Comparative analyses show that the proposed CNN-LSTM model outperforms conventional CNN and Deep CNN models in angle prediction. Additionally, the integration of barometric pressure data enables precise floor level detection, enhancing the system's robustness in multi-story environments. Proposed comprehensive approach significantly improves the accuracy and reliability of indoor localization, making it viable for real-world applications"
A Method for Generating Malware Countermeasure Samples Based on Pixel Attention Mechanism,2024,"['Malware', 'Generative Adversarial Networks', 'Deep Learning', 'Pixel Attention Mechanism', 'Adversarial Samples']",,"Studies have shown that malware has become a primary means of attacking the Internet. Therefore, adversarial samples have become a vital breakthrough point for studying malware. By studying adversarial samples, we can gain insights into the behavior and characteristics of malware, evaluate the performance of existing detectors in the face of deceptive samples, and help to discover vulnerabilities and improve detection methods for better performance. However, existing adversarial sample generation methods still need help regarding escape effectiveness and mobility. For instance, researchers have attempted to incorporate perturbation methods like Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), and others into adversarial samples to obfuscate detectors. However, these methods are only effective in specific environments and yield limited evasion effectiveness. To solve the above problems, this paper proposes a malware adversarial sample generation method (PixGAN) based on the pixel attention mechanism, which aims to improve adversarial samples' escape effect and mobility. The method transforms malware into grey-scale images and introduces the pixel attention mechanism in the Deep Convolution Generative Adversarial Networks (DCGAN) model to weigh the critical pixels in the grey-scale map, which improves the modeling ability of the generator and discriminator, thus enhancing the escape effect and mobility of the adversarial samples. The escape rate (ASR) is used as an evaluation index of the quality of the adversarial samples. The experimental results show that the adversarial samples generated by PixGAN achieve escape rates of 97%, 94%, 35%, 39%, and 43% on the Random Forest (RF), Support Vector Machine (SVM), Convolutional Neural Network (CNN), Convolutional Neural Network and Recurrent Neural Network (CNN_RNN), and Convolutional Neural Network and Long Short Term Memory (CNN_LSTM) algorithmic detectors, respectively."
TCN-BiLSTM 앙상블 모델 기반 심전도를 이용한 운전자 식별 시스템,2024,"['운전자 인식', '심전도', '운전자 식별', 'TCN', 'BiLSTM', 'Driver recognition', 'ECG', 'Driver identification', 'TCN', 'BiLSTM']","최근 스마트 모빌리티 시스템이 운전자 중심 서비스를 위해 위·변조에 강인한 신체 내부의 전기적 신호인 생체신호를 이용하여 운전자 인식 연구가 활발히 진행 중이다. 기존 딥러닝 네트워크로써 CNN은 제한적인 지역적 특징 추출과 LSTM은 반주기적 생체신호의 형태학적 특징 분석 한계로 성능을 개선하는데 한계가 있다. 본 논문은 시간변화에 따른 신호 패턴을 학습하는 TCN(Temporal Convolutional Network)과 장기 의존성을 학습하는  BiLSTM(Bidirectional Long Short Term Memory)을 이용한 운전자 식별 시스템을 제안한다. 제안한 식별 시스템은 신호의 잡음을 제거하는 전처리 과정, 기준점 및 비기준점 기반 특징 분할 과정, TCN과 BiLSTM 앙상블 모델에 의해 운전자를 식별하는 과정으로 구성된다. 실험 결과, PhysioNet 공개 DB인 drivedb와 normal sinus rhythm database를 이용하여 운전자 식별 정확도는 각각 99.76%, 99.97%로 기존 단일 네트워크보다 4.64%, 3.84% 더 우수함을 확인하였다.","Recently, driver recognition research is actively underway for smart mobility systems to provide driver-centered services using biosignals, electrical signals inside the body that are resistant to forgery and falsification. As an existing deep learning network, CNN has limited local feature extraction and LSTM has limitations in improving performance due to limitations in analyzing morphological features of semi-periodic biological signals. This paper proposes a driver identification system using a temporal convolutional network (TCN) that learns signal patterns according to time changes and a Bidirectional Long Short Term Memory(BiLSTM) that learns long-term dependencies. The proposed identification system consists of a preprocessing process to remove noise from the signal, a feature segmentation process based on fiducial points and non-fiducial points, and a process to identify the driver using the TCN and BiLSTM ensemble models. Experimental results using the PhysioNet public databases, drivedb and normal sinus rhythm database, showed that the driver identification accuracy was 99.76% and 99.97% respectively, which is 4.64% and 3.84% better than the existing single network models."
YOLO와 EfficientNetV2를 사용한 지능적 제품 탐지 및 추천을 위한 End-to-End AI 기반 서비스 모델 개발,2024,"['Marketing', 'YOLO', 'Visual Similarity', 'One-shot learning', 'EfficientNet', 'End-to-End Service', '마케팅', 'YOLO', 'Visual Similarity', 'One-shot learning', 'EfficientNet', 'End-to-End 서비스']","최근, 동영상 콘텐츠 소비와 제품구매 행동이 자연스럽게 이어지는 마케팅 연구가 활발하게 이루어지고있다. 본 논문에서는 유튜브의 영상 시청중에 자연스럽게 인터넷 쇼핑으로 이어질 수 있도록 관련 제품을 탐지하고유사 제품을 추천해주는 서비스 기술을 제안하고 구현하였다. 제안한 기술은 YOLOv8과 미리 학습된 EfficientNetV2 를 사용하였고, 제한적으로 탐지할 수 있는 제품 클래스의 개수를 해결하기 위해 CNN모델을 추가함으로써 단일객체 탐지 모델의 한계를 극복하였다. 또한 탐지할 수 있는 제품의 분류 성능을 높이기 위해 Weighted Box Fusion기법을 적용하였다. 테스트 모델에 사용된 제품 검출 성능 평가 결과에서 mAP는 최고 91.2%의 높은 검출률을 보였다. 구현결과, 제안한 기술은 시청중에 판매가 이루어질 수 있는 다양한 동영상 플랫폼의 End-to-End 서비스에 활용될 수 있을 것으로 기대한다.","Recently, there has been active research in marketing connecting video content consumption to product purchasing behaviors seamlessly. In this paper, we propose and implement a service technology that detects related products during YouTube video viewing and recommends similar products, enabling a smooth transition to online shopping. Our proposed technology utilizes YOLOv8 and a pre-trained EfficientNetV2, and overcomes the limitations of a single object detection model by adding a CNN model to address the issue of a limited number of detectable product classes. Additionally, the Weighted Box Fusion technique is applied to enhance the product classification performance of detectable products. The product detection performance of the test model showed a high mAP of up to 91.2%. Based on our results, we anticipate that the proposed technology can be applied to various video platforms where sales can be made during viewing, offering an end-to-end service."
디지털 자산 가격 예측을 위한 딥러닝 기반 시계열 예측 방법 비교 연구,2024,"['Cryptocurrency Price Prediction', 'Time Series Forecasting', 'Deep Learning', 'Bitcoin', 'Ethereum']","디지털 자산 시장의 급격한 성장과 높은 변동성은 투자자와 거래 참여자들에게 가격 예측의 중요성을 강조하고있다. 이에 따라 많은 연구자들이 딥러닝 기반의 시계열 예측 모델을 도입하여 디지털 자산 가격 예측의 정확성을 향상시키고자 노력하고 있다. 그러나 기존 연구는 주로 LSTM 및 CNN과 같은 바닐라 모델을 중점적으로 활용해왔으며, 이러한 모델들은 특정 상황에서는 효과적일 수 있지만 시계열 데이터의 복잡한 시간적 종속성을 완전히 포착하기 어려워최적의 예측을 제공하지 못할 수 있다. 본 논문은 이러한 문제에 대한 대안으로 제안된 최신의 시계열 예측 모델들과기존의 디지털 자산 가격 예측 모델들을 포함해 8개의 모델 성능을 비교 분석한다. 실험 결과, SegRNN 모델은 비트코인(BTC) 및 이더리움(ETH) 시장에서 가격 예측을 수행할 때 다른 모델보다 뛰어난 성능을 보였다. 특히, BTC 시장에서1시간 틱(Tick) 데이터를 사용하여 6개의 미래 가격 시계열을 예측한 결과, MSE, MAE가 각각 0.0007, 0.0143로 모든모델 중 가장 우수한 성능을 보였다. 본 연구 결과는 디지털 자산 시장 참여자들에게 효과적인 의사 결정을 지원하고, 투자 전략의 성공 가능성을 높이는 데 기여할 것으로 기대된다.","Rapid growth and the high volatility of the digital asset market emphasize the importance of price prediction for investors and traders. Consequently, many researchers have introduced deep learning time series prediction models to improve the accuracy of digital asset price forecasting.However, past studies mostly used basic models like LSTM and the CNN, which can be effective in some situations but can struggle to fully capture complex time dependencies in the data, thus not providing optimal predictions. This paper compares and analyzes the performance of eight models, including the latest time series prediction models and existing digital asset price prediction models. Experimental results show that the SegRNN model outperformed other models in predicting prices in Bitcoin (BTC) and Ethereum (ETH) markets. Specifically, when predicting six price time series using one-hour tick data in the BTC market, the SegRNN model achieved the best performance (MSE and MAE values of 0.0007 and 0.0143, respectively). The findings of this study are expected to support effective decision-making for participants in the digital asset market, increasing the success potential of investment strategies."
트라우마 방지를 위한 사고 영상 탐지기 개발 및 사고 영상 검출 서비스 제안,2024,"['Trauma Prevention', 'AI Recommendation Algorithm', 'Accident Video Detection', 'Artificial Intelligence', '트라우마 방지', 'AI 추천 알고리즘', '사고 영상 탐지', '인공지능']","AI 추천 알고리즘의 부작용으로 인해 영상 플랫폼 사용자가 사고 영상 시청 시 트라우마가 유발될 우려가 있다. 그러나 사고 영상에 대한 규제 기준이 미흡하다. 본 논문에서는 YouTube와 같은 영상 플랫폼에서 트라우마를 유발할 수 있는 사고 영상을 효과적으로 탐지하고 규제하기 위해 네 가지 사고 카테고리를 통합한 검출 시스템을 제안한다. 또한 제안한 시스템에 적합하게 활용할 수 있는 CNN 기반 화재 및 침수 탐지 모델, two-stream 학습을 이용한 폭행 탐지 모델, 그리고 YOLOv4를 기반으로 한 교통사고 탐지 기법을 구현하였다. 화재, 침수, 폭행 탐지 모델은 각각 95%, 96%, 97%의 정확도를, 교통사고 탐지 기법은 97.1%의 탐지율과 2.86%의 오탐률을 달성하였다. 본 연구는 기존 규제 항목이 아닌 사고 영상을 탐지하여 사용자 트라우마를 방지하고, 안전한 미디어 환경을 조성하는 데 기여할 것으로 기대한다.","Due to the side effects of AI recommendation algorithms, there is a risk of users experiencing trauma when watching accident videos on video platforms. However, regulatory standards for accident videos are inadequate. This paper proposes a detection system that integrates four accident categories to effectively detect and regulate accident videos that can cause trauma on platforms like YouTube. The proposed system includes CNN-based fire and flood detection models, a two-stream learning-based violence detection model, and a YOLOv4-based car crash detection method. The fire, flood, and violence detection models achieved accuracies of 95%, 96%, and 97%, respectively, while the car crash detection method achieved a detection rate of 97.1% and a false alarm rate of 2.86%. This study aims to contribute to preventing user trauma and creating a safer media environment by detecting accident videos, which are not covered by existing regulations."
수면 소리 데이터를 활용한 1D ResNet 딥러닝 모델 기반 수면무호흡증 탐지 연구,2024,"['Sleep apnea', 'Polysomnography', 'Sleep sound', 'Deep learning', 'MFCC']","수면무호흡증(Sleep Apnea)은 전 세계적으로 심각한 건강 문제를 일으키는 질환으로, 주로 수면 중 상부 기도의 폐쇄로 인해 발생한다. 현재 수면무호흡증의 표준 진단 방법인 수면다원검사(Polysomnography, PSG)는 높은 비용과 복잡성 등의 한계가 있다. 본 연구에서는 수면 중 발생하는 소리 데이터를 활용하여 수면무호흡증을 탐지하는 비침습적 방법을 제안하였다. 소리 데이터는 MFCC(Mel-Frequency Cepstral Coefficients)로 특징을 추출하였으며, 1D CNN 기반의 ResNet(Residual Network) 모델을 통해 분류를 수행하였다. 실험 결과, 제안된 모델은 5겹 교차 검증을 통해 평균 정확도(Accuracy) 97.8%, 재현율(Recall) 97.7%, 민간도(Precision) 97.9%, AUC 0.978의 성능을 달성하였다. 향후 연구에서는 데이터셋을 확장하고 다양한 딥러닝 모델을 실험하여 모델의 성능을 더욱 향상시킬 계획이다. 본 연구는 수면무호흡증 탐지의 정확성을 높이고, 효율적인 건강관리 시스템 구축에 기여할 수 있을 것으로 기대한다.","Sleep Apnea is a serious global health issue caused primarily by the obstruction of the upper airway during sleep. The current standard diagnostic method for sleep apnea, Polysomnography (PSG), has limitations such as high cost and complexity. In this study, we propose a non-invasive method to detect sleep apnea by utilizing sound data recorded during sleep. The sound data features were extracted using Mel-Frequency Cepstral Coefficients (MFCC), and classification was performed using a 1D CNN-based ResNet (Residual Network) model. The experimental results show that the proposed model achieved an average accuracy of 97.8%, a recall of 97.7%, a precision of 97.9%, and an AUC of 0.978 through 5-fold cross-validation. Future research will focus on expanding the dataset and experimenting with various deep learning models to further improve the model's performance. This study is expected to contribute to improving the accuracy of sleep apnea detection and the development of an efficient healthcare management system."
실시간 수위 예측을 위한 시공간 특징공학적 최적학습모델,2024,"['시계열 데이터 예측', '피처 엔지니어링', '수위 예측', 'time series data forecasting', 'feature engineering', 'water level', 'spatiotemporal series data']","남도대교가 위치한 섬진강 유역의 데이터는 한 시간별로 제공되고 수위의 변화가 크기 때문에 예측이 매우 어렵다. 비정형 시계열 자료인 수위 예측을 위해 수위 자료뿐만 아니라 상류에 있는 댐 자료와 기후 자료를 사용하였고 STL 분해, 차분, 시간 인코딩을 이용하여 파생 변수를 생성한다. 또한 목표 수위와 상관관계가 가장 큰 상류 지역의 자료만을 사용하여 입력 자료의 변수를 줄였다. XGBoost, SVR, LSTM, CNN-LSTM 아키텍처 중 XGBoost가 섬진강 유역의 하천 데이터에 가장 적합한 알고리즘으로 도출되었고, 최신 자료의 약 1년 반을 가중하여 학습하는 방법이 통상적인 방법보다 수위의 급증 패턴을 더 정확하게 예측하였다. 머신러닝 모델이 R-square 기준으로 97.781%의 정확도를 보여 본 연구의 딥러닝 모델보다 우수한 성능을 보이는 것으로 관찰되었다. 최종 모델을 이용하여 실시간 수위 예측 결과를 시각화하는 하천 범람 예측 시스템을 구현하였다.","Data from the Seom Jin River basin where the Namdo Bridge is located are provided every hour. Predicting water level is very difficult because the water level changes are large. For water level prediction using unstructured time series data, including water level data, upstream dam data, and climate data, derivative variables were generated by using STL decomposition, difference, and time encoding. In addition, the variables of the input data were reduced using only data from the upstream region having the greatest correlation with the target water level. Among the XGBoost, SVR, LSTM, and CNN-LSTM architectures, XGBoost was derived as the most suitable algorithm for river data in the Seom Jin River basin. The learning method by weighting about a year and a half of the latest data predicted the surge pattern of the water level more accurately than the conventional method. The machine learning model had an accuracy of 97.781%, showing a performance superior to the deep learning model in this study. Using the final model, a river overflow prediction system was implemented to visualize the real-time water level prediction result."
이미지 딥러닝을 이용한 건설현장 안전모 미착용 인식에 대한 연구,2024,"['안전모', '객체인식', '이미지 딥러닝', 'Safety helmet', 'Object detection', 'Image deep learning']",건설현장에 개인보호 미착용에 따른 사고가 자주 발생한다. 산업재해 통계에 따르면 건설업 근로자의 주요 사망원인 중 하나가 안전모 미착용이고 현장에서는 안전모 착용을 위해 다양한 노력을 하고 있으나 이를 잘 지키지 못하는 것이 현실이다. 보호구 착용 관리를 효율적으로 하는 방법 중에는 CCTV 기반 이미지 딥러닝 알고리즘을 활용하는 것이 있으며 건설현장 이미지 데이터를 기반으로 Convolutional Neural Network(CNN) 알고리즘을 적용하여 안전모의 착용 및 미착용 인식을 통해 작업자의 안전모 착용 준수를 확인할 수 있는 다양한 방법들이 제안되고 있다. 이는 건설현장 근로자의 안전모 착용 준수 여부를 확인하고 안전 수칙 위반 근로자를 식별하여 안전관리에 도움을 줄 수 있다. 이에 본 연구에서 우리는 YouOnly Look Once(YOLO)를 활용하여 근로자의 안전모 미착용 여부를 효과적으로 판단할 수 있는 모델 구축 방법론을 제시하였다. CIS 공개 데이터 셋을 적용하여 안전모 미착용 근로자 검출을 위한 최적의 변수와 데이터 비율을 선정하고 다양한 학습과 검증을 통해 도출된 분석결과를 통해 얻은 안전모 착용 및 미착용 데이터 분포에 따른 판별 정확도 및 오차 분석을 통해 현장 활용성을 높이고자 하였다.,"The most common accidents at construction sites are caused by not wearing personal protective equipment. According to industrial accidents statistics, one of the main death causes is not wearing safety helmets, and although various efforts have been made to have workers wear safety helmets. One of the ways to manage the wearing of safety helmet is to use CCTV-based image deep learning algorithm, so various methods have been proposed to confirm workers' compliance with wearing safety helmets by the CNN. This can help with safety management by checking whether workers are complying with wearing safety helmets and identifying workers who violate safety rules. In this study, we proposed a model construction methodology that can effectively determine whether workers are not wearing safety helmets by utilizing YOLOv9. With CIS data set, we selected the optimal variables and data ratio for detecting workers not wearing safety helmets, and we aimed to increase field usability by analyzing the discrimination accuracy and error according to the distribution of data on wearing or not wearing safety helmets derived through various learning and verification."
사전 학습 모델과 앙상블 기법을 통한 음성 감정인식,2024,"['Deep learning', 'ensemble learning', 'pre-trained models', 'speech emotion recognition', '딥러닝', '사전 학습된 모델', '앙상블 학습', '음성 감정 인식']","음성 감정 인식 연구는 인간-기계 상호작용을 향상시키는 데 중요하고, 의료, 교육, 고객 서비스 등 다양한 분야에서 효율성을 높이고 사용자 경험을 개선할 수 있다. 본 연구에서는 DACON의 `월간 데이콘 음성 감정 인식 AI 경진대회'에 참가하여 여섯 가지 감정을 분류하는 AI 모델을 개발을 목표로 하였다. 전통적인 음성 처리 기술 기반 방법과 사전 학습된 모델을 이용한 방법들의 성능을 비교하였고, 사전 학습된 모델을 통해 음성의 일반화된 특징을 효과적으로 학습한 임베딩 벡터의 추가 학습 가능성을 탐구하였다. 그 결과, WavLM에 1D CNN을 결합한 모델이 79.80\%의 성능으로 우수한 결과를 보였고, 사용한 모든 사전 학습된 모델들을 하드 보팅 앙상블하여 5등에 준하는 80.79\%까지 성능을 향상시켰다. 본 연구는 음성 감정 분류에서 높은 성능을 달성하여 음성 감정 인식 기술의 적용 가능성을 높임으로써, 다양한 실제 응용 분야에서 감정 인식 모델의 활용을 가능하게 하는 데 기여할 것이다.","Research on speech emotion recognition plays a crucial role in enhancing human-machine interaction and improving efficiency and user experience in various fields such as healthcare, education, and customer service. In this study, we aimed to develop an AI model to classify six emotions by participating in DACON's `Monthly DACON Speech Emotion Recognition AI Competition'. We compared the performance using traditional speech processing techniques and pretrained models, and investigated the potential for additional learning using embedding vectors effectively learned through pretrained models. As a result, a model combining WavLM with 1D CNN demonstrated superior performance at 79.80\%, and by ensembling all pretrained models using hard voting, we further improved performance to 80.79\%, achieving a ranking equivalent to 5th place in the competition. This research is expected to contribute to the application potential of speech emotion recognition technology, enabling the utilization of emotion recognition models in various real-world applications."
Research on Vocal Information Processing using a Main Melody Extraction Algorithm,2024,"['Accuracy', 'Conditional random field', 'Main melody extraction', 'Vocal information']",,"Precise extraction of the main melody from polyphonic music is a critical challenge in vocal information processing. This paper starts with a brief introduction to extracting vocal music information features. Two distinct feature types were selected: the Mel-frequency cepstral coefficient (MFCC) and chroma. An innovative main melody extraction algorithm was then developed using a convolutional neural network (CNN) and conditional random field (CRF). The performance of the algorithm was validated on datasets. The main melody extraction effects were improved significantly using MFCC and chroma as inputs to the CNN-CRF algorithm for feature extraction. The algorithm achieved an overall accuracy (OA) of 86.72% and a voicing false alarm (VFA) of 6.84% on the ADC2004 dataset. On the MIREX05 dataset, the algorithm attained an OA and VFA of 85.21% and 11.16%, respectively. The algorithm exhibited pronounced enhancement when being tested on the MIREX05 dataset, and chroma played a notable role in enhancing the raw chroma accuracy. This algorithm also performed better than the SegNet and FTANet algorithms."
AI-Based Prediction Module of Key Neutronic Characteristics to Optimize Loading Pattern for i-SMR with Flexible Operation,2024,['Convolution neural network · Loading pattern optimization · i-SMR (innovative small modular reactor) · Flexible operation · Screening technique · Simulated annealing'],,"This paper proposes an AI-based module for a loading pattern (L/P) optimization algorithm applied to the i-SMR, designed for fl exible operation. The AI module can be used as a surrogate model in the simulated annealing (SA) screening process, which allows for more effi cient optimization. The convolution neural network (CNN) model was trained using reactor core L/Ps and corresponding core parameter values derived from a realistic core simulation code. For load-following operations, we selected core parameters such as control rod insertion depth, radial peaking factor, axial shape index, and eff ective multiplication factor. To calculate the objective function of an L/P during the SA process using core design codes, it takes approximately 3 s, while the AI-based module can predict the objective function within about 0.1 ms. During the prediction of selected parameters, we discovered two factors aff ecting prediction accuracy. First, the model exhibited a signifi cant increase in error when trained on dataset containing negative values. Second, utilizing batch normalization (BN) layer and squeeze and excitation (SE) module, intended to improve accuracy, resulted in a decrease in performance of the model.Our study demonstrated that the CNN-based model achieves excellent prediction accuracy and has an ability to accelerate optimization algorithms by taking advantage of artifi cial intelligence’s inherent computational speed."
딥러닝과 머신러닝을 통한 당뇨병 데이터 분석,2024,"['Diabetes', 'Classification', 'Machine Learning', 'Deep Learning', 'Ensemble Model', '당뇨병', '분류', '머신러닝', '딥러닝', '앙상블  모델']","당뇨병은 널리 퍼진 만성 질환으로, 세계적으로 영향을 미치고, 경제적으로도 상당한 재정적 부담을 부가하고 있다. 당뇨병은 혈액의 포도당을 조절하는 능력을 저하하고 , 삶의 질과 수명을 감소시킬 수 있는 만성 질환이다. 또한 당뇨병은 인슐린을 생성하지 못하거나, 효과적으로 사용하지 못한다. 당뇨병 문제의 규모는 상대적으로 크지만, 쉽게 인식하지 못한다. 당뇨병을 완치할 수 있는 방법은 없지만 체중 감량, 건강식, 활동적 생활 및 치료를 받는 것과 같은 전략은 많은 환자에서 이 질병의 피해를 완화할 수 있다. 조기 진단은 생활 방식의 변화와 보다 효과적인 치료로 이어진다. 본 연구의 의의는 당뇨병이 있는지 여부에 대한 정확한 예측을 제공하고 당뇨병 위험을 가장 잘 예측하는 위험 요소는 무엇인지 찾는 것이다.  예측에 있어서 여러 가지 머신러닝 기법과 딥러닝의 CNN과 RNN을 통한 Ensemble Model 사용하고, 평가방법으로 Accuracy와 Recall을사용한다. 이 Ensemble Model은 Transformer구조를 따르고자 했고, 경량화하였다.","Diabetes is a widespread chronic disease that affects people worldwide and imposes significant financial burdens. Diabetes impairs the ability to regulate blood glucose levels, reducing quality of life and life expectancy. Additionally, diabetes is characterized by either the inability to produce insulin or to use it effectively. Despite its prevalence, diabetes is often underrecognized. While there is no cure for diabetes, strategies such as weight loss, healthy eating, an active lifestyle, and treatment can mitigate the disease's impact in many patients. Early diagnosis leads to lifestyle changes and more effective treatment. This study aims to provide accurate predictions for diabetes and identify the most significant risk factors for its development. The study employs various machine learning techniques, and  ensemble models using CNN and RNN, with accuracy and recall as evaluation metrics. This Ensemble Model attempted to follow the Transformer structure and made it lightweight."
매니폴드 데이터 증강기법 기반의 딥러닝 방법론을 적용한 축소 모델 개발,2024,"['manifold learning', 'model-order reduction', 'deep learning', 'data augmentation', '매니폴드 러닝', '모델 차수 축소', '딥러닝', '연산유체역학', '데이터 증강']","본 논문에서는 저 레이놀즈 수 영역에서 에어포일의 공기역학적 성능을 예측하기 위한 딥러닝 기반의 축소 모델을 제시하였다. 딥러닝 기반 축소 모델에서 CFD 해석 결과의 높은 차원의 데이터를 효율적으로 다루기 위해 변이형 오토인코더를 결합한 합성곱 신경망을 적용하였다. 부호화 거리 함수를 통해 에어포일의 형상과 유동 조건을 이미지 데이터화 하고, 이에 대해 합성곱 신경망을 매개변수화 하였다. 또한, 전산유체역학 해석의 계산 비용으로 인한 부족한 훈련 데이터를 극복하기 위해 투영 기반의 비선형 매니폴드 데이터 증강기법을 개발하였다. NACA 4계열 에어포일은 해석 예제로 고려하여 제안하는 프레임워크의 내삽과 외삽 정확도를 평가하였으며 매니폴드 데이터 증강기법을 적용하여 프레임워크의 정확도 향상을 확인하였다.","This study presents a deep learning-based framework to predict the aerodynamic performance of low Reynolds number airfoils. The framework employs a convolutional neural network (CNN) combined with a variational autoencoder (VAE) to efficiently handle large datasets. Moreover, the signed distance function is used as the network input to represent the airfoil configuration in the image data and parameterize the CNN. A novel generative model based on projection-based manifold learning is proposed to overcome the data mining limitation of computational fluid dynamics which may incur significant computational costs. The interpolation and extrapolation accuracy of the proposed framework is evaluated using the NACA 4-digit airfoil configuration.The results show improved accuracy via data augmentation performed by the proposed generative model."
"The potential role of synthetic computed tomography in spinal surgery: generation, applications, and implications for future clinical practice",2024,"['Computed tomography', 'Magnetic resonance imaging', 'Convoluted neural networks', 'Spine surgery']",,"Computed tomography (CT) is widely used for the diagnosis and surgical treatment of spinal pathologies, particularly for pedicle screw placement. However, CT’s limitations, notably radiation exposure, necessitate the development of alternative imaging techniques. Synthetic CT (sCT), which generates CT-like images from existing magnetic resonance imaging (MRI) scans, offers a promising alternative to reduce radiation exposure. This study examines the emerging role of sCT in spinal surgery, focusing on usability, efficiency, and potential impact on surgical outcomes. This qualitative literature review evaluated various sCT generation methods, encompassing traditional atlas-based and bulk-density models, as well as advanced convolutional neural network (CNN) architectures, including U-net, V-net, and generative adversarial network models. The review assessed sCT accuracy and clinical feasibility across different medical disciplines, particularly oncology and surgery, with potential applications in orthopedic, neurosurgical, and spinal surgery. sCT has shown significant promise across various medical disciplines. CNN-based techniques enable rapid and accurate generation of sCT from MRI scans, rendering clinical use feasible. sCT has been used to identify pathologies and monitor disease progression, suggesting that MRI alone may suffice for diagnosis and planning in the future. In spinal surgery, sCTs are particularly useful in visualizing key anatomical features like vertebral dimensions and spinal canal diameter. However, challenges persist, especially in visualizing complex structures and larger spinal regions, like the lumbar spine. Additional limitations include inaccuracies stemming from surgical implants and image variability. The application of sCT technology in spinal surgery holds great promise, improving diagnostics, planning, and treatment outcomes. Although further research is required to improve its precision, it offers a viable alternative to traditional CT in many clinical contexts, with the potential for broader application as the technology matures."
"심층신경망으로 가는 통계 여행, 두 번째 여행: RNN의 구조와 이미지 분류",2024,"['DNN', 'Classification', 'MLP', 'Regression', 'GLM', '심층신경망', '분류', '다층퍼셉트론', '회귀분석', '일반화선형모형']","RNN은 DNN의 여러 모형을 이행하는 데 있어 중추적 역할을 하는 모형이다. 또 이후 Seq2Seq 모형으로 발전하고, transformer로 발전하는 과정을 통하여, 현시점 최고의 관심이 되고 있는 대규모 언어모형의 발전을 이끌어 온 핵심적 기술이라 할 수 있다. 그럼에도 불구하고 RNN의 작동방식을 이해하는 것은 쉬운 일이 아니다. 특히 RNN의 핵심 모형이 LSRM과 GRU의 작동방식을 이해하기 위한 방안을 모색하다. 더하여 LSTM과 GRU에 대한 구체적인 사용 사례를 보이기 위하여, MNIST 데이터에서의 필기숫자 분류 문제에 적용하였다. 각각의 이미지를 여러 개의 패치로 구획하는 방법을 이용하여 양방향LSTM과 양방향 GRU를 적용하였다. 그 결과를 CNN과 비교하였다.","RNNs are models that play a pivotal role in understanding various forms of DNNs. They have evolved into Seq2Seq models and subsequently into Transformers, leading to the development of large language models (LLMs) that are currently the focus of significant interest. Nonetheless, understanding the operation of RNNs is not an easy task. In particular, the core models of RNNs, LSTM and GRU, are challenging to comprehend due to their structural complexity. This paper explores ways to understand the operation of LSTM and GRU. Additionally, to demonstrate specific use cases of LSTM and GRU, we applied them to the problem of handwritten digit classification using the MNIST dataset. We utilized a method of segmenting each image into multiple patches and applied bidirectional LSTM and bidirectional GRU. The results were then compared with those of CNN."
인공지능을 활용한 챔버형 반도체 제조 설비의 Fan Motor 이상감지 진단에 관한 연구,2024,"['CBM', 'Feature Engineering', 'LSTM', 'BiLSTM 오토인코더', 'Anomaly Score', 'CBM', 'Feature Engineering', 'LSTM', 'BiLSTM Auto-encoder', 'Anomaly Score']","반도체 장치산업은 막대한 투자비가 수반 되므로 생산 설비가 고유의 성능을 유지하기 위한 설비 예방보전 활동이 중요하다. 설비보전의 중요성으로 기업에서는 다양한 예방보전 활동이 진행되고 있으며, 아직은 수명에 의한 TBM(Time Base Maintenance) 형태의 예방보전에 의존하고 있다. 최근 기술 발전으로 AI 기법을 활용한 고장을 진단하고 사전 조치를 진행하는 CBM(Condition Based Maintenance) 예지보전 형태로 발전하고 있다. 본 논문에서는 반도체 챔버형 설비에서 Fan Motor 고장을 진단하기 위한 연구로 현장의 데이터와 가장 유사한 공공 데이터셋을 통해 진동신호를 AI 기법을 이용하여 고장진단 방법을 연구하였다. 첫 번째 선행연구에서 인공지능 딥러닝 기법으로 3가지 모델인 DNN, RNN, CNN로 고장을 예측하였고, 진동 신호 4개를 Feature Engineering을 통해 19개로 확대하여 동일하게 3가지 모델로 고장 예측을 비교 분석하여 모델 알고리즘의 성능을 개선하였다. 아울러 대부분의 AI 연구는 배치 단위의 시계열 데이터를 통한 고장진단 방법론을 연구하고 있다. 반도체 생산 현장은 24시간 가동되는 장비이므로 스트리밍 상태의 실시간 기반의 데이터를 활용하여 정상데이터를 학습하고 이상 데이터가 감지되면, 고장으로 분류가 가능한 오토인코더 기법을 활용하여 성능을 검증하고 고장진단 방법을 연구하였다. 본 연구에서 시사하는 바는 통상적인 인공지능 기법으로 알고리즘 성능을 개선하는 연구에서 한 단계 진전되어 Feature Engineering을 통한 성능개선을 진행하였다. 산업 현장에서 실제 적용이 가능한 오토인코더 알고리즘을 접목하여 고장 예측을 시각화하고, 정상상태를 학습하여 Anomaly Score을 예측하고, 이상 데이터가 발생 시 차이를 분석하여 고장 예측이 가능한 것을 검증하였다. 또한, 정상데이터의 학습데이터로 이상 데이터 예측이 가능하므로 정상학습 데이터의 Anomaly Score 최댓값으로 이상치를 등급화할 수 있다. 설비의 보전상태를 정상가동, 모니터링 상태, 보전상태 등으로 분류가 가능한 예지보전 시스템을 구현하는데 활용될 수 있다.","Since semiconductor device industry requires enormous investment costs, preventive maintenance activities are important to ensure that production equipment maintains its unique performance. Due to the importance of equipment maintenance, various preventive maintenance activities are being carried out by manufactures, and they still rely on preventive maintenance in the form of TBM (Time Base Maintenance) based on lifespan. With technological advancements, it is developing into a form of predictive maintenance that uses AI techniques to diagnose failures and take proactive measures. In this paper, a study was conducted to diagnose fan motor failure in semiconductor chamber-type equipment, and a failure diagnosis method was studied using vibration signals using AI techniques through similar data sets. First, in previous research, failure was predicted using three models (DNN, RNN, CNN) using artificial intelligence deep learning techniques, and the four vibration signals were expanded to 19 through feature engineering to compare failure predictions using the same three models. Through analysis, the performance of the model algorithm was improved. In addition, most AI research studies failure diagnosis methodologies through batch-level time series data. Since semiconductor production sites are equipment that operates 24 hours a day, normal data is learned using streaming real-time data, and when abnormal data is detected, the autoencoder technique is used to classify it as a failure, to verify performance and diagnose failures. was studied. The implication of this study is that it is a step forward from research on improving algorithm performance using typical artificial intelligence techniques, and has progressed to improve performance through feature engineering. We visualized failure prediction by incorporating an autoencoder algorithm that can be actually applied in industrial sites, predicted anomaly scores by learning normal states, and analyzed the differences when abnormal data occurs to verify that failure prediction is possible. In addition, since abnormal data can be predicted using normal learning data, outliers can be graded by grade based on the maximum Anomaly Score of normal learning data. It can be used to implement a predictive maintenance system that can classify the maintenance status of facilities into normal operation, monitoring status, and maintenance status."
Research on Transformation and Interpretability in Credit Classification,2024,"['Big Data Processing and Analysis', 'Credit Risk Prediction', 'Deep Learning', 'eXplainable AI']",,"The modern financial industry demands rapid decision-making based on diverse information from dynamicenvironments. Predicting outcomes from such data is complex due to rapid shifts influenced by numerousfactors. Despite advancements in artificial intelligence technology that offer sophisticated analytical models,accurately predicting outcomes and providing sufficient justification for these predictions remain challenging,particularly with fragmented model constructions. In this paper, we propose a novel approach for efficientprocessing of available public personal credit data, deriving new analysis elements, and comparing predictioninterpretations. Specifically, we develop 11 prediction models that can be categorized into two types: dataimage transformation and time-series transformation. The models undergo standardization, preprocessing, andcross-validation for optimization, with their predictive performances compared and validated. Modelsleveraging convolutional neural network (CNN) and convolutional neural network-long short-term memory(CNN-LSTM) architectures demonstrate strong performance across both categories. To fully interpret theclassification process, SHAP is applied to compare and explain the prediction results for each model type."
감지 데이터 딥러닝을 사용한 작업자 낙상 탐지 모델,2024,"['딥 러닝', '낙상 감지', '지도 학습', '센서 데이터', 'deep learning', 'fall detection', 'supervised learning', 'sensors data']",,"The construction industry plays a significant role in a nation's development. However, construction industry workers face high risks due to the use of heavy machinery and require constant vigilance to prevent accidents, such as falls. Sensor-based fall detection systems are considered accurate and efficient as they are easy to carry when attached to the body. In this study, the data is collected while performing some regular tasks using wearable sensors, the gyro and accelerometer.The collected data was then processed and cleaned after which the learning model was applied to it.CNN-LSTM-based model for detection of fall was introduced and applied together because of CNN feature extraction capability along with LSTM as it is popular for its time series ability. The proposed CNN-LSTM-based model, using an accelerometer and gyro sensor at a sampling frequency of 50 Hz, has an accuracy of 99.91%."
경량 시간 세그먼트 네트워크를 이용한 비디오 장면 이해: 운전자 폭행 탐지에서의 검증,2024,"['시간 세그먼트 네트워크', '비디오 장면 이해', '이상 탐지', '운전자 폭행', 'temporal segment network', 'video scene understanding', 'anomaly detection', 'driver assault']","최근 택시와 버스 등 교통수단에서 탑승자가 운전자를 폭행하는 사건이 증가하는 추세로, 특히 늦은 밤 주취자에 의한 운전자 폭행 등에 대한 신속한 대응은 더욱 어려운 상황이다. 이러한 문제에 대응하기 위해, 본 연구팀은 탑승자에 의한 운전자 폭행 상황을 실시간으로 탐지할 수 있는 경량 합성곱 신경망 기반의 시간적 세그먼트 네트워크(TSN) 모델을 제안한다. TSN은 동영상을 효율적으로 처리하기 위해 소수의 이미지 프레임을 샘플링하며, 공간 정보처리 스트림과 시간 정보처리 스트림으로 나뉘어 학습이 진행된다. 각 스트림에는 합성곱 신경망이 들어가는데, 이 연구에서는 경량 신경망 아키텍처인 MobileOne 모델을 적용하여 모델 사이즈를 크게 줄였고, 제한된 컴퓨팅 리소스에서도 정확도는 오히려 개선됨을 보인다. 본 모델은 차량 내 운전자 모니터링 시스템에 통합되어 운전자에게 발생할 수 있는 위험한 상황에 대한 신속한 대응 및 예방에 기여할 수 있을 것으로 기대된다.","The number of driver assaults in transportation such as taxis and buses has been increasing over the past few years. It can be especially difficult to respond quickly to assaults on drivers by drunks late at night. To address this issue, our research team proposed a lightweight CNN-based Temporal Segment Network (TSN) model that could detect driver assaults by passengers in real time. The TSN model efficiently processes videos by sampling a small number of image frames and divides videos into two streams for learning: one for spatial information processing and the other for temporal information processing. Convolutional neural networks are employed in each stream. In this research, we applied a lightweight CNN architecture, MobileOne, significantly reducing the model size while demonstrating improved accuracy even with limited computing resources. The model is expected to contribute to rapid response and prevention of hazardous situations for drivers when it is integrated into vehicular driver monitoring systems."
Inducing aortic aneurysm/dissection in zebrafish: evaluating the efficacy of β-Aminopropionic Nitrile as a model,2024,"['Aortic aneurysm/dissection (AAD)', 'Zebrafish', 'β- Aminopropionic Nitrile (BAPN)', 'Animal model']",,"Aortic aneurysm/dissection (AAD) poses a life-threatening cardiovascular emergency with complex mechanisms and a notably high mortality rate. Zebrafish (Danio rerio) serve as valuable models for AAD due to the conservation of their three-layered arterial structure and genome with that of humans. However, the existing studies have predominantly focused on larval zebrafish, leaving a gap in our understanding of adult zebrafish. In this study, we utilized β-Aminopropionic Nitrile (BAPN) impregnation to induce AAD in both larval and adult zebrafish. Following induction, larval zebrafish exhibited a 28% widening of the dorsal aortic diameter (p < 0.0004, n = 10) and aortic arch malformations, with a high malformation rate of 75% (6/8). Conversely, adult zebrafish showed a 41.67% (5/12) mortality rate 22 days post-induction. At this time point, the dorsal aortic area had expanded by 2.46 times (p < 0.009), and the vessel wall demonstrated significant thickening (8.22 ± 2.23 μM vs. 26.38 ± 10.74 μM, p < 0.05). Pathological analysis revealed disruptions in the smooth muscle layer, contributing to a 58.33% aneurysm rate.Moreover, the expression levels of acta2, tagln, cnn1a, and cnn1b were decreased, indicating a weakened contractile phenotype. Transcriptome sequencing showed a significant overlap between the molecular features of zebrafish tissues post-BAPN treatment and those of AAD patients. Our findings present a straightforward and practical method for generating AAD models in both larval and adult zebrafish using BAPN."
진동분석을 통한 회전익 드론의 블레이드 착빙 예지,2024,"['블레이드 착빙(Blade Icing)', '딥러닝(Deep Learning)', '드론(Drone)', '고장 예지(Fault Prognosis)', '건전성 예측및 관리(Prognostics and Health Management)']",,"Weather is one of the main causes of aircraft accidents, and among the phenomena caused by weather, icing is a phenomenon in which an ice layer is formed when an object exposed to an atmosphere below a freezing temperature collides with supercooled water droplets. If this phenomenon occurs in the rotor blades, it causes defects such as severe vibration in the airframe and eventually leads to loss of control and an accident. Therefore, it is necessary to foresee the icing situation so that it can ascend and descend at an altitude without a freezing point. In this study, vibration data in normal and faulty conditions was acquired, data features were extracted, and vibration was predicted through deep learning-based algorithms such as CNN, LSTM, CNN-LSTM, Transformer, and TCN, and performance was compared to evaluate blade icing. A method for minimizing operating loss is suggested."
Empirical analysis of Deep Learning Models in forecasting Chaotic Time series data,2024,"['혼돈 시계열 예측', '딥러닝', '리아푸노프 지수', '다단계 기법', '모델 함수 호출', 'Chaotic time series forecasting', 'deep learning', 'Lyapunov exponent', 'multi-steps technique', 'model function calls']",,"The extraction of a system’s evolutionary patterns is a central modelling problem in the area of chaos forecasting, a task almost impossible to be achieved by statistical models. Thanks to deep learning which is considered a revolutionary technique in the forecasting of chaotic time series due to its ability to detect hidden pattern from data and thus enhance prediction accuracy these systems are now handled, resulting in outstanding achievements. However, individuals who are new to the field or not well-versed with the subject might find it challenging to understand the properties of chaos and their implications, as well as the logic behind the design and implementation of complex algorithms. These topics, which are crucial for a comprehensive understanding of the field, may not always be thoroughly discussed in related literature. This paper aims to bridge this gap by providing an empirical approach to these subjects. It explains and apply major chaos properties and proposes a straightforward approach to identify them from a random system. Furthermore, the analyses of the performance of the Multilayer Perceptron (MLP), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and Convolutional Neural Networks -Long Short-Term Memory (CNN-LSTM) on chaotic time series data generated from the system, using a multistep-ahead forecasting approach to understand their individual behaviour and provide explanation about their complexity assessed by the number of function called by the algorithm along with their running time which represents potential reasons behind their performance."
Effective Anomaly Identification in Surveillance Videos Based on Adaptive Recurrent Neural Network,2024,['Surveillance system · Recurrent neural network · Maximally stable extremal regions · convolutional neural network'],,"Surveillance systems completed in true environment are of a solid nature. As the environment is uncertain and variable, care gradually becomes confusing when moving away from a stable and controlled environment. Evidence to distinguish stressful abnormalities in video surveillance is a problematic issue due to leakage, video screaming, contradictions and motives.Hence, in this paper, adaptive recurrent neural network is developed for anomaly detection from the videos. The projected technique is a combination of recurrent neural network and crystal structure algorithm. In the anomality detection, the video should be changed into frames. After that, the images should be enhanced for improving image quality. Once, the image quality is enhanced, the image background should be eliminated for achieving object detection. In the proposed technique, the region of interest is utilized to attain the object detection step in the images. The detected object images are used to tracking the object in the images by using the proposed classifer. To enhance the object tracking system, the feature extraction is a required topic in the system. Maximally stable extremal regions is used to extract the required features from the images.Finally, the proposed classifer is utilized to achieve anomaly detection based on object movement in the input images. The projected strategy is implemented and evaluated by performance metrices. It is contrasted with conventional techniques such as convolutional neural network-particle swarm optimization (CNN-PSO) and CNN respectively."
Building Detection: Testing a New Object-Based Approach Against Neural Networks,2024,"['High-rise Building Detection', 'Convolutional Neural Network', 'Object-based', 'Azimuth Angle']",,"Automated identification of HRBs (High-rise Buildings) on satellite images is challenging when densely populated areas are concerned. Factors that increase complexity are, among others, roads and both the azimuth and elevation angle of the sensor. In this study, two different effective HRB detection techniques are proposed. The first method is using CNNs (Convolutional Neural Networks), an extensively used tool for pattern recognition in the field of machine learning. However, domain movement considerably reduces the CNNs performance on the test data in other domains, making it difficult to generalize. Besides, obtaining the dense annotations on the remote sensing images is expensive and time-consuming. Therefore, a new object-based approach is proposed that includes multi-resolution segmentation and relief displacement by azimuth angles of the sensor. Both methods were tested using images from four regions in South Korea using VHR (Very High Resolution) satellite imagery from the KOMPSAT-3 and WorldView-3. The results show that the performance of both methods heavily depends on factors such as building size and density as well as on external factors such as the position, shape, and size of HRBs. It can be concluded that our proposed method using the relationship between the azimuth angle of the sensor and the relief displacement of the building has several distinct advantages over the CNN-based approach. E.g. the CNN performance considerably relies on the availability of a large number of training data. In addition, quantitative evaluation showed an accuracy improvement rate of at least 30% in intersection over union and F1 score compared to the object-based benchmark models. Eventually, our proposed method allows to evaluate the performance of each image individually, which helps to identify the scenarios where a certain method works best."
콘크리트 구조물 균열 파악을 위한 분류 모델 분석,2024,"['Concrete Crack', 'Convolution Neural Network', 'Classification']",,"Purpose: The current study was used to propose a model for identifying cracks in concrete structures by comparing and analyzing various models using Convolutional Neural Networks (CNNs).Methods: Two CNN-based classification models, VGG-16 and ResNet-50, were developed, compared, and analyzed. A confusion matrix was employed as a performance indicator to evaluate their performance in individual instances.Results: The comparative analysis indicated that ResNet-50 outperformed VGG-16 in performance metrics. Additionally, the inference speed based on test data revealed a significant difference, with ResNet-50 requiring 35 seconds compared to VGG-16's 77 seconds.Conclusion: The ResNet-50 showed excellent performance in confusion matrix-based performance indicators and inference speed. It shows strong potential for practical applications in identifying concrete crack structures in real-world scenarios."
LBP 표시자를 위한 비교 연산 절감 방법,2024,"['LBP', 'LBCNN', 'Image texture', 'Feature point', 'Code optimization']","LBP (Local binary pattern) 알고리즘은 컴퓨터 비전 분야에서 객체의 질감(Texture)을 인식 하는데 가장 많이 사용되는 방법 중 하나이다. 최근에는 신경망 분야에도 적용되어 연산복잡도가 높 은 CNN을 대체하기 위한 LBCNN (Local binary convolutional neural network)에 대한 연 구가 한창이다. 하지만, LBP 계산 시에도 이미지상의 모든 픽셀에 대하여 이웃 픽셀들과의 비교 연 산을 수행하기 때문에 연산량에 대한 부담은 여전히 존재하며 특히 임베디드 프로세서를 사용하는 로봇, 드론 등의 시스템에서는 상당한 부담이 된다. 이를 해결하기 위하여 본 논문에서는 LBP 알고 리즘 계산에 있어 비교  연산량을 절감할 수 있는 방법을 제안한다. 이전 픽셀에 대한 비교  연산 결 과로부터 힌트를 얻어 현재 픽셀에 대한 비교  연산 시 생략이 가능한 경우이면 생략하는 방법이다. 본 방법을 샘플  이미지들에 적용한 결과 텍스쳐  이미지들의 경우 비교  연산 절감률이 평균  43.9% 에 달하였고 비텍스쳐 이미지들의 경우 38.59%에 달하였다.","The LBP (Local binary pattern) algorithm has been one of the most widely used methods for recognizing texture in the field of computer vision. Recently, research on LBCNN (Local binary convolutional neural network) has been actively conducted as an alternative to CNNs with high computational complexity. However, even during LBP computation, the computational burden persists due to the need for comparison operations between neighboring pixels for all pixels in the image. This burden is especially significant in systems such as robots and drones that use embedded processors. To address this issue, this paper proposes a method to reduce the computational complexity of the LBP algorithm. It involves skipping comparison operations for the current pixel based on comparison operation results from previous pixels if it is determined that they can be skipped. When applied to sample images, the proposed method achieved an average reduction of 43.9%  for texture images and 38.59% for non-texture images in the number of comparison operations."
비전 트랜스포머 모델 기반 한국인 얼굴 감정 분류 연구,2024,"['Computer Vision', 'Vision Transformer', 'Facial Expression Recognition', 'Emotion Classification', 'Fine-tuning']","인간의 표정은 기본적인 감정을 전달하는 표현 요소로써 인간과 컴퓨터 간의 상호작용에서 중요한 역할을 한다.컴퓨터 비전 및 머신러닝 분야에서는 최근 딥러닝을 기반으로 얼굴 표정을 기본 감정으로 분류하며, 그 중 합성곱 신경망(CNN: Convolution Neural Network) 기반의 모델이 주로 쓰이고 있다. 모델을 학습하는데 주로 쓰이는 데이터셋들은 다양한 인종이 섞여 있으며, 서양인의 얼굴 중심으로 이뤄져있다. 본 연구에서는 사전 학습된 비전 트랜스포머(ViT: Vision Transformer) 모델을 한국인의 얼굴 표정에 7가지 감정으로 라벨링되어 있는 데이터셋을 기반으로 파인튜닝한다. 모델에 입력하기 위해 데이터셋에서 제공되는 메타데이터에서 제공하는 얼굴의 좌표값을 활용하여 얼굴 부분을 크롭하고 총 70,000장의 이미지를 8:1:1의 비율로 분할하여 데이터셋을 재구성하였다. 학습된 한국인 얼굴 감정 분류 비전 트랜스포머는 전체 테스트 데이터셋에 대한 정확도 85.54 %를 기록하며 동일한 데이터셋을 사용한 합성곱 신경망 기반 모델에 비해 1.17 %의 성능 향상을 보였다. 다른 클래스들에 비해 낮은 성능을 보였던 불안, 슬픔을 나타내는클래스에 대해서도 성능을 개선하였다.","Facial expressions play an important role in human-computer interaction because they convey basic human emotions. In the field of computer vision and machine learning, deep learning has recently been used to classify facial expressions into basic emotions, with models based on convolutional neural networks being the most popular. Datasets that are mainly used to train the models are a mixture of various races, but mainly consist of Western faces. In this study, we fine-tune a pretrained vision transformer model based on a dataset of Korean facial expressions labeled with seven emotions. For input into the model, the dataset was reconstructed by cropping the faces using coordinates provided by the metadata in the dataset, splitting the 70,000 images at a ratio of 8:1:1. The trained Korean facial emotion classification vision transformer achieved 85.54% accuracy on the entire test dataset, showing a 1.17% performance improvement over a convolutional neural network model using the same dataset.We improved performance for classes representing anxiety and sadness, which had performed poorly compared to other classes."
음성감정 추출을 위한 오픈소스 기반 인공지능 설계 및 개발,2024,"['인공지능', '감정인식', '트랜스포머', 'HuBERT', 'Mel-Frequency Cepstral Coefficient', 'Emotion Recognition', 'Transformer', 'HuBERT', 'Mel-Frequency Cepstral Coefficient']",,"This study aims to improve communication for people with hearing impairments by developing artificial intelligence models that recognize and classify emotions from voice data. To achieve this, we utilized three major AI models: CNN-Transformer, HuBERT-Transformer, and Wav2Vec 2.0, to analyze users' voices in real-time and classify their emotions. To effectively extract features from voice data, we applied transformation techniques such as Mel-Frequency Cepstral Coefficient (MFCC), aiming to accurately capture the complex characteristics and subtle changes in emotions within the voice. Experimental results showed that the HuBERT-Transformer model demonstrated the highest accuracy, proving the effectiveness of combining pre-trained models and complex learning structures in the field of voice-based emotion recognition. This research presents the potential for advancements in emotion recognition technology using voice data and seeks new ways to improve communication and interaction for individuals with hearing impairments, marking its significance."
딥러닝 자세 추정 모델을 사용한 각도 기반  위험 행동 분류 엣지 시스템 구현,2024,"['Pose Estimation', 'Deep Learning', 'Keypoint', 'Neural Networks', 'Behavior Classification']",,"This paper proposes a system to address safety issues in public spaces by using a deep learning model to classify dangerous behaviors based on keypoint angles. The YOLOv8-Pose model is employed to extract keypoints in real-time, detecting dangerous actions such as punching, kicking, and fall down. Experimental results show that the proposed method achieves an accuracy of 95.6% with a processing speed of 8.1ms, making it approximately 4.65 times faster than traditional CNN-based methods. This efficiency allows for real-time monitoring in various settings, including parks, factories, and schools, without the need for high-performance devices or extensive datasets. By analyzing the angles between keypoints, the system significantly reduces computational load while maintaining high accuracy. The practical implementation of this system can enhance safety monitoring by providing an effective and efficient solution for detecting potential risks in large public areas. This system holds promise for improving safety management in public spaces through a cost-effective and computationally efficient approach."
배 병해충 이미지 분류를 위한 딥러닝 최적 모델 선택에 관한 연구,2024,"['배 병해충', '딥러닝 모델', '이미지 분류', '검역', '데이터 증강', 'Pear Pests and Diseases', 'Deep Learning Models', 'Image Classification', 'Quarantine', 'Data Augmentation']",,"With the increase in agricultural exports, pest and disease quarantine measures have been strengthened globally. Upon detection of pests or diseases in agricultural products, the entire shipment must be recalled or discarded. Therefore, detecting pests during the post-harvest sorting process is critical. This study aims to identify the optimal deep-learning model for classifying healthy and pest-infested pears during sorting. To achieve this, a dataset was created by collecting images of pest-infested pears under conditions similar to publicly available healthy pear images. The study compares CNN-based models (ResNet, MobileNet, EfficientNet, ConvNext) and a transformer-based model (ViT) using the dataset. Standard learning parameters and data augmentation techniques were also evaluated. Accuracy and Grad-CAM were used to analyze model performance. The results indicate that ResNet101 achieved the best performance based on accuracy and Grad-CAM."
LLVM IR 대상 악성코드 탐지를 위한 이미지 기반 머신러닝 모델,2024,"['LLVM IR', 'Image based', 'Malware Detection', 'ResNet50V2']","최근 정적분석 기반의 시그니처 및 패턴 탐지 기술은 고도화되는 IT 기술에 따라 한계점이 드러나고 있다. 이는 여러 아키텍처에 대한 호환 문제와 시그니처 및 패턴 탐지의 본질적인 문제이다. 악성코드는 자신의 정체를 숨기기 위하여 난독화, 패킹 기법 등을 사용하고 있으며 또한, 코드 재정렬, 레지스터 변경, 분기문 추가 등 기존 정적분석 기반의 시그니처 및 패턴 탐지 기법을 회피하고 있다. 이에 본 논문에서는 이러한 문제를 해결할 수 있는 머신러닝을 통한 LLVM IR 코드 이미지 기반 악성코드 정적분석 자동화 기술을 제안한다. 바이너리가 난독화되거나 패킹된 사실에 불구하고 정적 분석 및 최적화를 위한 중간언어인 LLVM IR로 디컴파일한다. 이후 LLVM IR 코드를 이미지로 변환하여 CNN을 이용한 알고리즘 중 전이 학습 및 Keras에서 지원하는 ResNet50v2으로 학습하여 악성코드를 탐지하는 모델을 제시한다.",
Multi-scale context fusion network for melanoma segmentation,2024,"['Melanoma segmentation', 'Receptive field', 'Attention mechanism', 'multi-scale contextural information']",,"Aiming at the problems that the edge of melanoma image is fuzzy, the contrast with the background is low, and the hair occlusion makes it difficult to segment accurately, this paper proposes a model MSCNet for melanoma segmentation based on U-net frame. Firstly, a multi-scale pyramid fusion module is designed to reconstruct the skip connection and transmit global information to the decoder. Secondly, the contextural information conduction module is innovatively added to the top of the encoder. The module provides different receptive fields for the segmented target by using the hole convolution with different expansion rates, so as to better fuse multi-scale contextural information. In addition, in order to suppress redundant information in the input image and pay more attention to melanoma feature information, global channel attention mechanism is introduced into the decoder. Finally, In order to solve the problem of lesion class imbalance, this paper uses a combined loss function. The algorithm of this paper is verified on ISIC 2017 and ISIC 2018 public datasets. The experimental results indicate that the proposed algorithm has better accuracy for melanoma segmentation compared with other CNN-based image segmentation algorithms."
Novel approaches in geomechanical parameter estimation using machine learning methods and conventional well logs,2024,"['Model evaluation', 'petrophysical data log', 'geomechanical parameters', 'CLM algorithm']",,"Today, geomechanics plays a crucial role in the oil industry, particularly in enhancing production and ensuring well stability. To achieve optimal results, accurate estimation of geomechanical parameters is essential. One of the low-cost and accurate methods for estimating geomechanical parameters is the use of intelligent methods. In this research, geomechanical parameters are estimated using conven- tional data logs using intelligent methods. The aim of this study is to introduce a new machine learning algorithm to estimate geomechanical parameters using conventional data logs in one of the hydro- carbon field wells in southwest Iran. In this article, the shear wave velocity and uniaxial compressive strength (UCS) were estimated using machine learning algorithms. Subsequently, other geomechanical parameters  were  calculated  based  on  these  estimated  parameters  derived  from  machine  learning algorithms. For shear wave velocity (Vs) prediction using MLP and CLM (CNN+LSTM+MLP) algorithms, First, effective features were selected using the Auto-encoder deep learning algorithm. The selected features  for  Vs  input  into  the  algorithms  were  Vp,  RHOB,  CALIPER,  and  NPHI,  and  then  the  Vs  is estimated with MLP and CLM algorithm."
Deep learning-based automatic segmentation of the mandibular canal on panoramic radiographs: A multi-device study,2024,"['Mandibular Canal', 'Panoramic Radiography', 'Deep Learning', 'Artificial Intelligence']",,"Purpose: The objective of this study was to propose a deep-learning model for the detection of the mandibular canal on dental panoramic radiographs.Materials and Methods: A total of 2,100 panoramic radiographs (PANs) were collected from 3 different machines: RAYSCAN Alpha (n = 700, PAN A), OP-100 (n = 700, PAN B), and CS8100 (n = 700, PAN C). Initially, an oral and maxillofacial radiologist coarsely annotated the mandibular canals. For deep learning analysis, convolutional neural networks (CNNs) utilizing U-Net architecture were employed for automated canal segmentation. Seven independent networks were trained using training sets representing all possible combinations of the 3 groups. These networks were then assessed using a hold-out test dataset.Results: Among the 7 networks evaluated, the network trained with all 3 available groups achieved an average precision of 90.6%, a recall of 87.4%, and a Dice similarity coefficient (DSC) of 88.9%. The 3 networks trained using each of the 3 possible 2-group combinations also demonstrated reliable performance for mandibular canal segmentation, as follows: 1) PAN A and B exhibited a mean DSC of 87.9%, 2) PAN A and C displayed a mean DSC of 87.8%, and 3) PAN B and C demonstrated a mean DSC of 88.4%.Conclusion: This multi-device study indicated that the examined CNN-based deep learning approach can achieve excellent canal segmentation performance, with a DSC exceeding 88%. Furthermore, the study highlighted the importance of considering the characteristics of panoramic radiographs when developing a robust deep-learning network, rather than depending solely on the size of the dataset."
함수열 회귀모형과 딥러닝 알고리즘을 이용한 노지채소의 수확량 예측,2024,"['노지 작물의 수확량 예측', '식생지수', '함수열 자료 분석법', 'yield prediction of field crops', 'vegetation index', 'functional regression model', '1D-CNN+BiLSTM']","현대 농업은 비료나 에너지 자원 및 농부들의 노동력을 최소로 하면서 최대의 수확량을 획득할 수 있는 새로운 인공지능 경작 방법들의 개발이 필요하다. 따라서 본 연구에서 양파나 마늘같은 노지 채소들의 성장상태를 수시로 확인하여 사전에 수확량을 정확히 예측하는 방법들을 개발하여 생산된 농산물의 수요와 공급을 적절히 조절함과 동시에 경제성이 극대화될 수 있는 스마트 농업기술을 제안하려고 한다. 전남의 무안군에 있는 파속채소연구소에서 시험단위를 마련하고, 이들을 2개의 블록으로 나누어 각 블록별로 총 16개의 실험구로 나누고 각 실험구별로 비료 수준은 표준양을 기준으로 4개 수준을 서로 겹치지 않도록 랜덤하게 배치하였다. 각 실험구에 심어진 양파와 마늘에 대해서 재배기간 동안 일정한 간격으로 다분광 영상을 수집하여 이들로부터 10가지의 식생지수들을 추출하였다. 실험결과로 양파의 경우는 1D-CNN과 엽초장 변수가 결합한 모델이 가장 우수하며 다음으로 1D-CNN과 RECI가 결합한 모형과 1D-CNN+BiLSTM과 MNGRD가 결합한 모형들이 다음 순서로 예측력이 우수한 것으로 나타났고, 마늘의 경우에는 1D-CNN과 엽초장 변수가 결합한 모델이 가장 우수하며 다음으로 1D-CNN과 NGRD가 결합한 모형과 1D-CNN+BiLSTM과 엽초장 변수가 결합한 모형들이 다음 순서로 예측력이 우수하였다.","Modern agriculture requires the development of new AI-driven farming methods that can achieve maximum yields while minimizing the use of fertilizers, energy resources, and labor. Therefore, this study aims to propose smart agricultural technologies that can optimize economic efficiency by accurately predicting crop yields in advance through frequent monitoring of the growth status of field vegetables, such as onions and garlic, and appropriately adjusting the supply and demand of the harvested products. An experimental unit was set up at the Research Institute in Muan-gun, Jeollanam-do. The fertilizer levels were set at four different levels based on a standard amount. Multispectral images were collected at regular intervals during the cultivation period of onions and garlic in each plot, and 10 vegetation indices were extracted from these images. As a result of the experiment, for onions, the model combining 1D-CNN with the sheath length variable showed the best performance, followed by the model combining 1D-CNN with RECI and the model combining 1D-CNN+BiLSTM with MNGRD. For garlic, the model combining 1D-CNN with the sheath length variable was also the most accurate, followed by the model combining 1D-CNN with NGRD and the model combining 1D-CNN+BiLSTM with the sheath length variable."
Traditional Chinese medicine diagnostic prediction model for holistic syndrome differentiation based on deep learning,2024,"['Traditional Chinese medicine syndromes', 'Deep learning', 'Holistic syndrome differentiation', 'Expert knowledge', 'Artificial intelligence']",,"Background: With the development of traditional Chinese medicine (TCM) syndrome knowledge accumulation and artificial intelligence (AI), this study proposes a holistic TCM syndrome differentiation model for the classification prediction of multiple TCM syndromes based on deep learning and accelerates the construction of modern foundational TCM equipment.Methods: We searched publicly available TCM guidelines and textbooks for expert knowledge and validated these sources using ten-fold cross-validation. Based on the BERT and CNN models, with the classification constraints from TCM holistic syndrome differentiation, the TCM-BERT-CNN model was constructed, which completes the end-to-end TCM holistic syndrome text classification task through symptom input and syndrome output. We assessed the performance of the model using precision, recall, and F1 scores as evaluation metrics.Results: The TCM-BERT-CNN model had a higher precision (0.926), recall (0.9238), and F1 score (0.9247) than the BERT, TextCNN, LSTM RNN, and LSTM ATTENTION models and achieved superior results in model performance and predictive classification of most TCM syndromes. Symptom feature visualization demonstrated that the TCM-BERT-CNN model can effectively identify the correlation and characteristics of symptoms in different syndromes with a strong correlation, which conforms to the diagnostic characteristics of TCM syndromes.Conclusions: The TCM-BERT-CNN model proposed in this study is in accordance with the TCM diagnostic characteristics of holistic syndrome differentiation and can effectively complete diagnostic prediction tasks for various TCM syndromes. The results of this study provide new insights into the development of deep learning models for holistic syndrome differentiation in TCM."
Revolutionizing Brain Tumor Segmentation in MRI with Dynamic Fusion of Handcrafted Features and Global Pathway-based Deep Learning,2024,"['Brain tumor', 'Health Risks', 'Handcrafted features', 'Global-pathway CNN', 'Local-pathway CNN']",,"Gliomas are the most common malignant brain tumor and cause the most deaths. Manual brain tumor segmentation is expensive, time-consuming, error-prone, and dependent on the radiologist's expertise and experience. Manual brain tumor segmentation outcomes by different radiologists for the same patient may differ. Thus, more robust, and dependable methods are needed. Medical imaging researchers produced numerous semi-automatic and fully automatic brain tumor segmentation algorithms using ML pipelines and accurate (handcrafted feature-based, etc.) or data-driven strategies. Current methods use CNN or handmade features such symmetry analysis, alignment-based features analysis, or textural qualities. CNN approaches provide unsupervised features, while manual features model domain knowledge. Cascaded algorithms may outperform feature-based or data-driven like CNN methods. A revolutionary cascaded strategy is presented that intelligently supplies CNN with past information from handmade feature-based ML algorithms. Each patient receives manual ground truth and four MRI modalities (T1, T1c, T2, and FLAIR). Handcrafted characteristics and deep learning are used to segment brain tumors in a Global Convolutional Neural Network (GCNN). The proposed GCNN architecture with two parallel CNNs, CSPathways CNN (CSPCNN) and MRI Pathways CNN (MRIPCNN), segmented BraTS brain tumors with high accuracy. The proposed model achieved a Dice score of 87% higher than the state of the art. This research could improve brain tumor segmentation, helping clinicians diagnose and treat patients."
Detection of Cervical Foraminal Stenosis from Oblique Radiograph Using Convolutional Neural Network Algorithm,2024,"['Convolutional neural network', 'deep learning', 'machine learning', 'cervical foraminal stenosis', 'cervical oblique radiograph', 'magnetic resonance imaging', 'screening tool']",,"Purpose: This study was conducted to develop a convolutional neural network (CNN) algorithm that can diagnose cervical foraminal stenosis using oblique radiographs and evaluate its accuracy.Materials and Methods: A total of 997 patients who underwent cervical MRI and cervical oblique radiographs within a 3-month interval were included. Oblique radiographs were labeled as “foraminal stenosis” or “no foraminal stenosis” according to whether foraminal stenosis was present in the C2–T1 levels based on MRI evaluation as ground truth. The CNN model involved data augmentation, image preprocessing, and transfer learning using DenseNet161. Visualization of the location of the CNN model was performed using gradient-weight class activation mapping (Grad-CAM).Results: The area under the curve (AUC) of the receiver operating characteristic curve based on DenseNet161 was 0.889 (95% confidence interval, 0.851–0.927). The F1 score, accuracy, precision, and recall were 88.5%, 84.6%, 88.1%, and 88.5%, respectively. The accuracy of the proposed CNN model was significantly higher than that of two orthopedic surgeons (64.0%, p<0.001; 58.0%, p<0.001). Grad-CAM analysis demonstrated that the CNN model most frequently focused on the foramen location for the determination of foraminal stenosis, although disc space was also frequently taken into consideration.Conclusion: A CNN algorithm that can detect neural foraminal stenosis in cervical oblique radiographs was developed. The AUC, F1 score, and accuracy were 0.889, 88.5%, and 84.6%, respectively. With the current CNN model, cervical oblique radiography could be a more effective screening tool for neural foraminal stenosis."
물리정보 기반 딥러닝을 이용한 도시침수 해석: 온천천 유역 사례,2024,"['Artificial intelligence', 'Deep learning', 'Physical information', 'Urban inundation', 'Flood prediction', '인공지능', '딥러닝', '물리정보', '도시침수', '홍수 예측']","기후변화로 인한 집중호우의 증가로 도시침수의 발생 빈도가 높아짐에 따라, 침수 위험 지역에서의 신속한 대응을 위해 2차원 침수해석 정보가 필요하다. 하지만, 기존 물리과정 기반 모형은 고해상도 침수 정보 생산에 높은 계산 비용이 요구되어 실시간 활용에 한계가 있다. 본 연구에서는 물리과정 기반 모형의 도시침수 공간분포 해석 결과를 신속하고 정확하게 모사할 수 있는 CNN (Convolutional Neural Network) 기반 딥러닝 모형을 개발하고 그 적용성을 평가하였다. 부산 온천천 유역을 대상으로 물리과정 기반 모형으로 다양한 가상 강수 시나리오에 대해 10 m 공간해상도의 2차원 침수 정보를 생성하고, CNN 모형을 훈련시켰다. 모형의 검증에는 2014년과 2020년의 두 가지 과거 침수 사상에 대한 물리모형 대비 최대 침수심 해석 재현성을 HR (Hit Rate), FAR (False Alarm Ratio), CSI (Critical Success Index) 등의 정량지표로 평가하였다. 또한, 딥러닝 모형에서 강수량의 시간 변동성이 미치는 영향을 평가하기 위해 강수 입력의 시간 범위(강수 윈도우)에 따른 민감도 분석을 수행하였다. 모의 결과, 2014년 침수사상은 HR 0.98, FAR 0.12, CSI 0.85, 2020년 침수사상은 HR 0.92, FAR 0.19, CSI 0.76 로 CNN 모형이 기존 물리모형 대비 침수 공간분포를 적절하게 재현함을 확인하였다. 강수 윈도우 분석 결과, 2014년 사상에서는 6시간, 2020년 사상에서는 2시간 범위를 입력할 때 CNN 모형의 성능이 최적이었다. 또한, 딥러닝 기반 모형은 물리과정 기반 모형의 순차 계산 대비 연산 시간을 약 98%, 병렬 계산 대비 약 90% 단축할 수 있어 준실시간에 가까운 효율적 침수 예측이 가능함을 확인하였다. 제안된 딥러닝 기반 모형은 계산 효율성과 정확도 측면에서 물리과정 기반 모형의 대안으로 활용 가능하며, 도시 침수 예측 및 조기 경보 시스템의 운영을 위한 효율적인 도구가 될 수 있을 것으로 기대된다.","The increasing frequency of urban flooding, driven by extreme rainfall events due to climate change, necessitates the rapid production of flood information for prompt response. However, physically based models are limited in real-time applications due to the high computational cost of generating high-resolution flood information. This study developed and evaluated a Convolutional Neural Network (CNN)-based deep learning model that can rapidly and accurately reproduce the spatial distribution analysis results of a physically based model for urban flooding. For the Oncheon-cheon catchment, flood analysis data at a 10-meter spatial resolution were generated using a physically based model for various synthetic rainfall scenarios. This data was then used to train and construct the CNN model. The model was validated using quantitative metrics, including the Hit Rate (HR), False Alarm Ratio (FAR), and Critical Success Index (CSI), by comparing the maximum inundation depth analysis results of the 2014 and 2020 historical flood events to those of the physically based model. Furthermore, a sensitivity analysis was conducted to assess the impact of temporal variability in rainfall on the performance of the deep learning model. The maximum inundation depth simulation exhibited high reproducibility, with an HR value of 0.98, an FAR of 0.12, and a CSI of 0.85 for the 2014 event, and an HR value of 0.92, an FAR of 0.19, and a CSI of 0.76 for the 2020 event. The analysis of rainfall window size indicated that the CNN model achieved optimal performance with a 6-hour rainfall window for the 2014 event and a 2-hour window for the 2020 event. Additionally, the deep learning-based model reduced computation time by approximately 98% compared to the sequential calculation of the physically based model and by approximately 90% compared to the parallel calculation, enabling near real-time computation. The proposed deep learning-based model is a computationally efficient and accurate alternative to physically based models, making it a useful tool for real-time urban flood prediction and early warning systems."
딥러닝 기반의 레일표면손상 평가,2024,"['레일표면결함', '진단시스템', '딥러닝', 'Fast R-CNN', '애플리케이션', 'Rail surface defects', 'Diagnostic system', 'Deep learning', 'Fast R-CNN', 'Application']","철도 레일은 차륜과 레일의 접촉면인 레일 표면에서 구름 접촉 피로 균열이 상시 발생할 수 있는 조건이기 때문에 균열의 상태를 철저히 점검하고 절손을 방지하기 위한 정밀한 점검 및 진단이 필요하다. 최근 궤도 시설의 성능 평가에 대한 세부 지침에서는 궤도 성능평가를 위한 방법과 절차에 관한 필요사항을 제시하고 있다. 그러나 레일 표면 손상을 진단하고 등급을 산정하는 것은 주로 외관 조사(육안 조사)에 의존하며, 이는 점검자의 주관적인 판단에 따른 정성적인 평가에 의존할 수밖에 없는 실정이다. 따라서 본 연구에서는 Fast R-CNN을 사용하여 레일 표면 결함 검출에 대한 딥 러닝 모델 연구를 수행하였다. 레일 표면 결함 이미지의 데이터 세트를 구축한 후, 모델을 테스트하였다. 딥러닝 모델의 성능평가 결과에서 mAP가 94.9%로 나타났다. Fast R-CNN의 균열 검출 효과가 높기 때문에 이 모델을 사용하면 레일 표면 결함을 효율적으로 식별할 수 있을 것으로 판단된다.","Since rolling contact fatigue cracks can always occur on the rail surface, which is the contact surface between wheels and rails, railway rails require thorough inspection and diagnosis to thoroughly inspect the condition of the cracks and prevent breakage. Recent detailed guidelines on the performance evaluation of track facilities present the requirements for methods and procedures for track performance evaluation. However, diagnosing and grading rail surface damage mainly relies on external inspection (visual inspection), which inevitably relies on qualitative evaluation based on the subjective judgment of the inspector. Therefore, in this study, we conducted a deep learning model study for rail surface defect detection using Fast R-CNN. After building a dataset of rail surface defect images, the model was tested. The performance evaluation results of the deep learning model showed that mAP was 94.9%. Because Fast R-CNN has a high crack detection effect, it is believed that using this model can efficiently identify rail surface defects."
CCTV 동영상에서 보행자 이상행동 이벤트 검출을 위한 딥러닝 기반 이상행동 이벤트 인식 방법,2024,"['Pedestrian Abnormal Behavior Recognition', 'CCTV Video Analysis', 'Pose Estimation', 'Object Detection', '2D CNN', 'LSTM', '3D CNN', '보행자 이상행동 인식', 'CCTV 동영상 분석', '포즈 예측', '객체 검출', '2D CNN', 'LSTM', '3D CNN']","CCTV의 설치가 증가하면서 모니터링 업무량이 크게 증가했다. 하지만, 단순히 인력을 늘리는 것만으로는 해결할 수 없는 한계에 부딪혔다. 이 문제를 해결하기 위해, 지능형 CCTV 기술이 개발되었으나, 이마저도 다양한 상황에서 성능 저하의 문제를 겪고 있다. 본 논문에서는 다양한 상황에 적용 가능하고 강건한 CCTV 동영상 통합 이상행동 인식 방법을 제안한다. 동영상으로부터 프레임 이미지를 추출하여 원시 이미지, 히트맵 표현 이미지 입력을 사용하며, 이미지 단계와 특징 벡터 단계에서의 병합 방식을 통해 특징 벡터를 추출하고, 이를 바탕으로 2차원 합성곱 신경망 모델과 3차원 합성곱 신경망 모델, 그리고 LSTM과 평균 풀링을 활용한 이상행동 인식 방법을 제안한다. 성능 검증을 위해 소분류 클래스를 정의하고 총 1,957개의 이상행동 동영상 클립 데이터를 생성하여 검증한다. 제안하는 방법은 CCTV 영상을 통한 이상행동 인식의 정확도를 향상시키며, 보안 및 감시 시스템의 효율성을 증대시킬 수 있을 것으로 기대한다.","With increasing CCTV installations, the workload for monitoring has significantly increased. However, a growing workforce has reached its limits in addressing this issue. To overcome this problem, intelligent CCTV technology has been developed. However, this technology experiences performance degradation in various situations. This paper proposes a robust and versatile method for integrated abnormal behavior recognition in CCTV footage that could be applied in multiple situations. This method could extract frame images from videos to use raw images and heatmap representation images as inputs. It could remove feature vectors through merging methods at both image and feature vector levels. Based on these vectors, we proposed an abnormal behavior recognition method utilizing 2D CNN models, 3D CNN models, LSTM, and Average Pooling. We defined minor classes for performance validation and generated 1,957 abnormal behavior video clips for testing. The proposed  method is expected to improve the accuracy of abnormal behavior recognition through CCTV footage, thereby enhancing the efficiency of security and surveillance systems."
"Accuracy, Uncertainty and Explainability of Mixed Input Neural Network Models for Prediction of Missile Aerodynamic Loads",2024,['Missile  aerodynamics · Deep  learning · Regression  modeling · Multi-Layer  Perceptron · Convolutional  Neural Network · Mixed  Input  Neural  Network'],,"Prediction models for aerodynamic loads of missile conﬁguration were developed using CNN (Convolutional Neural Network)-based Mixed Input Neural Network (MINN), inputs of which are image in the ﬁrst input layer and ﬂow con- ditions in the second input layer. The signed distance function was used to convert missile geometry to image data with various resolutions. Aerodynamic dataset was generated by using Missile DATCOM. To check the uncertainty due to the randomness of trained deep neural network models, box plots of prediction errors from independently trained multiple mod- els were generated and compared. Grad-CAM was used to provide explainability to missile conﬁguration images. It was conﬁrmed that predictions of the neural network model become robust as the size of dataset increases. MINN1, which only uses image resolution of whole missile geometry was found to be unable to accurately predict effects of the nose type on axial force. Therefore, the missile nose type information was explicitly provided to the second input layer in MINN2. Then, a CNN classiﬁcation model was developed for nose type prediction using signed distance function image around the missile nose. The accuracy of the nose type classiﬁcation CNN model was 100% for 642 or higher input image resolutions. CNN + MINN2 architecture, which provides MINN2 with the predicted nose type by the CNN model, was built and compared with MINN1 and MINN2. MLP (Multi-Layer Perceptron) was also used for comparison with the MINN models as a reference.Both MINN2 and CNN + MINN2 are conﬁrmed to be very accurate having relative errors less than 5%."
아음속 수송체 알루미늄 프레임의 비선형 유도초음파 주파수 응답 – 합성곱 신경망 분석 기반 미세 감육 진단 가능성 연구,2024,"['구조 진단', '유도초음파', '심층학습', '합성곱 신경망', '객체검출', 'Structural Health Monitoring', 'Guided Wave', 'Deep Learning', 'Convolution Neural Network', 'Object Detection']",,
CCTV 영상과 딥러닝을 이용한 교량통행 차량하중 추정,2024,"['Deep Learning', 'Faster R-CNN', 'Vehicle Loading', 'Bridge', 'CCTV', '딥러닝', 'Faster R-CNN', '차량하중', '교량', 'CCTV']","차량 하중은 교량의 열화를 일으키는 주된 원인 중 하나이다. 현재 WiM(Weigh-in-Motion)을 사용하여 통행 차량의 하중을 측정하고 있으나, WiM은 접촉식 센서로 설치 및 유지관리 비용이 큰 단점이 있다. 본 연구에서는 딥러닝과 CCTV 영상을 이용하여 비접촉식으로 교량 통행 차량 하중 이력을 추정하는 방법을 제안하였다. 제안된 방법은 물체 탐지 딥러닝 모델을 이용하여 통행 차종을 인식하고, 해당 차량의하중을 국내 주요 차량 모델들의 공차중량에 근거하여 작성된 하중기반 7차종 분류표에 근거하여 추정한다. 물체 탐지 딥러닝 모델로는 Faster R-CNN 모델이 사용되었으며, Faster R-CNN 모델을 7차종 분류표에 따라 구축된 영상 학습데이터를 이용하여 학습시켰다. 학습된 딥러닝 모델의 성능은 교량 CCTV로 취득한 영상을 이용하여 검증하였다. 최종적으로 실제 교량 상부에 설치된 CCTV에서 취득한 영상을 이용하여 교량을 통행중인 차량 하중을 연속으로 추정함으로써 특정 시간동안 통행 차량의 하중 이력 그래프를 획득할 수 있음을 보였다.","Vehicle loading is one of the main causes of bridge deterioration. Although WiM (Weigh in Motion) can be used to measure vehicle loading on a bridge, it has disadvantage of high installation and maintenance cost due to its contactness. In this study, a non-contact method is proposed to estimate the vehicle loading history of bridges using deep learning and CCTV images. The proposed method recognizes the vehicle type using an object detection deep learning model and estimates the vehicle loading based on the load-based vehicle type classification table developed using the weights of empty vehicles of major domestic vehicle models. Faster R-CNN, an object detection deep learning model, was trained using vehicle images classified by the classification table. The performance of the model is verified using images of CCTVs on actual bridges. Finally, the vehicle loading history of an actual bridge was obtained for a specific time by continuously estimating the vehicle loadings on the bridge using the proposed method."
허프 변환과 convolutional neural network 모델 기반 선박 소음의 로파그램 분석 및 식별,2024,"['수동소나', '로파그램', '허프 변환', 'Convolutional Neural Network (CNN)', '표적 식별', 'Passive sonar', 'Lofargram', 'Hough transform', 'Convolutional Neural Network (CNN)', 'Target identification']",,"This paper proposes a method to improve the performance of ship identification through lofargram analysis of ship noise by applying the Hough Transform to a Convolutional Neural Network (CNN) model. When processing the signals received by a passive sonar, the time-frequency domain representation known as lofargram is generated. The machinery noise radiated by ships appears as tonal signals on the lofargram, and the class of the ship can be specified by analyzing it. However, analyzing lofargram is a specialized and time-consuming task performed by well-trained analysts. Additionally, the analysis for target identification is very challenging because the lofargram also displays various background noises due to the characteristics of the underwater environment. To address this issue, the Hough Transform is applied to the lofargram to add lines, thereby emphasizing the tonal signals. As a result of identification using CNN models on both the original lofargrams and the lofargrams with Hough transform, it is shown that the application of the Hough transform improves lofargram identification performance, as indicated by increased accuracy and macro F1 scores for three different CNN models."
데이터 효율적 이미지 분류를 통한 안질환 진단,2024,"['안질환 진단 및 분류', 'CFI', 'CNN', '딥러닝', '인공지능', 'Ocular disease diagnosis and classification', 'Deep Learning', 'Artificial Intelligence']","전 세계적인 인구 고령화 현상으로, 녹내장, 백내장, 황반변성과 같은 실명을 초래할 수 있는 주요 안질환의 발병률이 상승하고 있다. 이에 안과 분야에서는 실명률을 줄이기 위해 예방이 어려운 질환의 진단에 관심이 집중되고 있다. 본 연구는 기존보다 적은 양의 데이터를 활용하여 안저 사진 내의 안질환을 정확하게 진단하는 딥러닝 방안을 제안한다. 이를 위해 적은 데이터로도 효과적인 학습이 가능한 Convolutional Neural Network (CNN) 모델을 선정하여 다양한 안질환 환자의 Conventional Fundus Image (CFI)를 분류한다. 선정된 CNN 모델들은 Accuracy, Precision, Recall, F1-score에서 우수한 성능을 기록함으로써 CFI 내 안질환의 정확한 분류에 탁월한 성능을 보였다. 이러한 접근법은 안과 전문의들의 수작업 분석을 줄이고, 진료 시간을 단축하며, 리소스가 제한된 환경에서도 일관성 있는 진단 결과를 제공함으로써 의료 현장에 효율적이고 정확한 진단의 보조 도구로 기여할 수 있다.","The worldwide aging population trend is causing an increase in the incidence of major retinal diseases that can lead to blindness, including glaucoma, cataract, and macular degeneration. In the field of ophthalmology, there is a focused interest in diagnosing diseases that are difficult to prevent in order to reduce the rate of blindness. This study proposes a deep learning approach to accurately diagnose ocular diseases in fundus photographs using less data than traditional methods. For this, Convolutional Neural Network (CNN) models capable of effective learning with limited data were selected to classify Conventional Fundus Images (CFI) from various ocular disease patients. The chosen CNN models demonstrated exceptional performance, achieving high Accuracy, Precision, Recall, and F1-score values. This approach reduces manual analysis by ophthalmologists, shortens consultation times, and provides consistent diagnostic results, making it an efficient and accurate diagnostic tool in the medical field."
통계적 회귀모형 및 머신러닝 모형들을 이용한 젖소의 우유 생산량 예측,2024,"['젖소', '우유 생산량', '사료섭취량', '착유일수', 'dairy cow', 'milk production', 'feed intake', 'milking days', '1D-CNN+BiLSTM']","젖소의 우유 생산량의 예측은 축산농가의 생산성을 평가하는 중요한 지표로 활용될 수 있다. 본 연구는 농가에서 사육하는 젖소의 우유 생산량을 시기별로 예측하는 방법들을 제안한다. 이를 위해 다음의 세 단계로 연구를 수행하였다. 첫째, 전남 보성군의 축산농가를 선정하여 젖소 49 마리 각각에 대해서 사료섭취량, 월령(나이), 산차, 착유일수, 우유 생산량을 수집하였다. 둘째, 수집된 자료를 바탕으로 산점도와 상관분석을 통하여 4가지 특성들이 우유 생산량에 얼마나 영향을 미치는가를 알기 위해 통계적 분석을 시행하였다. 셋째, 각 젖소의 시기별 우유 생산량을 정확히 예측하기 위해 중선형회귀모형, 랜덤포레스트 회귀모형(RFRM), XGBoost, 1D-CNN+BiLSTM 등의 네 가지 예측모형을 사용하였다. 다양한 실험결과를 통하여 랜덤포레스트와 XGBoost의 예측력이 가장 우수하고, 다음으로 딥러닝 방법인 1D-CNN+BiLSTM 모델이 우수하며 중선형회귀모형이 가장 예측력이 떨어짐을 알 수 있었다. 또한 XGBoost 분석기법을 통하여 우유생산량에 가장 높은 영향을 미치는 변수들은 월령, 착유일수, 사료섭취량, 산차의 순서로 나타남을 알 수 있었다.","Prediction of milk production from dairy cows can be used as an important indicator to evaluate the productivity of livestock farms. This study proposes methods to predict milk production from dairy cows raised in livestock farms by period. To this end, the study was conducted in three steps. First, a livestock farm in Boseong-gun, Jeollanam-do was selected, and feed intake, age, parity, number of milking days, and milk production were collected for each of 49 dairy cows. Second, based on the collected data, statistical analysis was performed to find out how much the four characteristics affect milk production through scatter plots and correlation analysis. Third, in order to accurately predict the milk production of each dairy cow by period, four prediction models were used: the linear regression model, random forest regression model (RFRM), XGBoost technique and 1D-CNN+BiLSTM. Through various experimental results, it was found that the machine learning methods, random forest and XGBoost methods, had the best predictive power, followed by 1D-CNN+BiLSTM model, while the linear regression model had the worst predictive power. In addition, through the XGBoost analysis technique, it was found that the variables that had the greatest influence on milk production were age, milking days, feed intake, and parity, in that order."
Comparison of Fall Detection Systems Based on YOLOPose and Long Short-Term Memory,2024,"['Fall detection', 'The elderly', 'Long short-term memory (LSTM)', 'Principal component analysis (PCA)', 'Convolutional neural network (CNN)']",,"In this study, four types of fall detection systems – designed with YOLOPose, principal component analysis (PCA), convolutionalneural network (CNN), and long short-term memory (LSTM) architectures – were developed and compared in the detection ofeveryday falls. The experimental dataset encompassed seven types of activities: walking, lying, jumping, jumping in activities ofdaily living, falling backward, falling forward, and falling sideways. Keypoints extracted from YOLOPose were entered into thefollowing architectures: RAW-LSTM, PCA-LSTM, RAW-PCA-LSTM, and PCA-CNN-LSTM. For the PCA architectures, thereduced input size stemming from a dimensionality reduction enhanced the operational efficiency in terms of computational timeand memory at the cost of decreased accuracy. In contrast, the addition of a CNN resulted in higher complexity and loweraccuracy. The RAW-LSTM architecture, which did not include either PCA or CNN, had the least number of parameters, whichresulted in the best computational time and memory while also achieving the highest accuracy."
자율주행 자동차의 주행을 위한 딥러닝 모델 연구,2024,"['딥러닝', '컨볼류션 신경망', '전이학습', '평균절대값오차', '자율주행', 'Deep Learning', 'Convolutional Neural Networks', 'Transfer Learning', 'MAE(Mean Absolute Error)', 'Autonomous Vehicle']","본 연구의 목적은 실내용 자율주행 자동차 딥러닝 모델을 연구하는 데 있다. 이를 위해 Nvidia, Transfer 모델과본 연구의 CNN 모델을 딥러닝을 실행하여, MAE 및 R2-score 값을 비교하였다. 연구 결과 Nvidia 모델과 본 연구의 모델은 Loss 값이 안정될 뿐 아니라 R2-score 값도 우수한 특성을 나타내지만, Transfer 모델은 Loss 및 R2-socre 이 안정되지 못하였다. 이러한 수정된 모델의 결과를 바탕으로 본 연구에서 GPU 기반 Nvidia 모델과 크게 다르지않은 CNN 모델을 제안하였다.","The purpose of this study was to investigate deep learning models for indoor autonomous vehicles. Deep learning was conducted using an NVIDIA model, transfer learning models, and the CNN model developed in this study, and the MAE and R2-score values were compared. The results demonstrated that both the NVIDIA model and the proposed CNN model exhibited not only stable loss values but also superior R2-score characteristics. By contrast, the transfer learning model did not achieve stable loss or R2-score values. Based on the results of the modified model, this study proposed a CNN model that is comparable to a GPU-based NVIDIA model."
Genetic Algorithm-based Convolutional Neural Network Feature Engineering for Optimizing Coronary Heart Disease Prediction Performance,2024,"['Machine Learning', 'Artificial Intelligence', 'Heart Diseases', 'Nerve Net', 'Deep Learning']",,"Objectives: This study aimed to optimize early coronary heart disease (CHD) prediction using a genetic algorithm (GA)-based convolutional neural network (CNN) feature engineering approach. We sought to overcome the limitations of traditional hyperparameter optimization techniques by leveraging a GA for superior predictive performance in CHD detection. Methods: Utilizing a GA for hyperparameter optimization, we navigated a complex combinatorial space to identify optimal configurations for a CNN model. We also employed information gain for feature selection optimization, transforming the CHD datasets into an image-like input for the CNN architecture. The efficacy of this method was benchmarked against traditional optimization strategies. Results: The advanced GA-based CNN model outperformed traditional methods, achieving a substantial increase in accuracy. The optimized model delivered a promising accuracy range, with a peak of 85% in hyperparameter optimization and 100% accuracy when integrated with machine learning algorithms, namely naïve Bayes, support vector machine, decision tree, logistic regression, and random forest, for both binary and multiclass CHD prediction tasks. Conclusions: The integration of a GA into CNN feature engineering is a powerful technique for improving the accuracy of CHD predictions. This approach results in a high degree of predictive reliability and can significantly contribute to the field of AI-driven healthcare, with the possibility of clinical deployment for early CHD detection. Future work will focus on expanding the approach to encompass a wider set of CHD data and potential integration with wearable technology for continuous health monitoring."
Application of deep learning for semantic segmentation in robotic prostatectomy: Comparison of convolutional neural networks and visual transformers,2024,"['Artificial intelligence', 'Computer vision systems', 'Deep learning', 'Prostatectomy']",,"Purpose: Semantic segmentation is a fundamental part of the surgical application of deep learning. Traditionally, segmentation in vision tasks has been performed using convolutional neural networks (CNNs), but the transformer architecture has recently been introduced and widely investigated. We aimed to investigate the performance of deep learning models in segmentation in robot-assisted radical prostatectomy (RARP) and identify which of the architectures is superior for segmentation in robotic surgery.Materials and Methods: Intraoperative images during RARP were obtained. The dataset was randomly split into training and validation data. Segmentation of the surgical instruments, bladder, prostate, vas and seminal vesicle was performed using three CNN models (DeepLabv3, MANet, and U-Net++) and three transformers (SegFormer, BEiT, and DPT), and their performances were analyzed.Results: The overall segmentation performance during RARP varied across different model architectures. For the CNN models, DeepLabV3 achieved a mean Dice score of 0.938, MANet scored 0.944, and U-Net++ reached 0.930. For the transformer architectures, SegFormer attained a mean Dice score of 0.919, BEiT scored 0.916, and DPT achieved 0.940. The performance of CNN models was superior to that of transformer models in segmenting the prostate, vas, and seminal vesicle.Conclusions: Deep learning models provided accurate segmentation of the surgical instruments and anatomical structures observed during RARP. Both CNN and transformer models showed reliable predictions in the segmentation task; however, CNN models may be more suitable than transformer models for organ segmentation and may be more applicable in unusual cases. Further research with large datasets is needed."
Research on Methods to Increase Recognition Rate of Korean Sign Language using Deep Learning,2024,"['Deep learning', 'CNN', 'Sign language', 'Deaf', 'Hand detection', 'Image processing']",,"Deaf people who use sign language as their first language sometimes have difficulty communicating because they do not know spoken Korean. Deaf people are also members of society, so we must support to create a society where everyone can live together. In this paper, we present a method to increase the recognition rate of Korean sign language using a CNN model. When the original image was used as input to the CNN model, the accuracy was 0.96, and when the image corresponding to the skin area in the YCbCr color space was used as input, the accuracy was 0.72. It was confirmed that inserting the original image itself would lead to better results. In other studies, the accuracy of the combined Conv1d and LSTM model was 0.92, and the accuracy of the AlexNet model was 0.92. The CNN model proposed in this paper is 0.96 and is proven to be helpful in recognizing Korean sign language."
주거 및 공공장소 이상행동탐지를 위한 서비스 설계,2024,"['Anomaly Detection', 'AI Learning Data', 'ResNet50', '3D-CNN', 'GridCV', 'GRU', '이상행동 탐지', 'AI 학습 데이터', 'ResNet50', '3D-CNN', 'GridCV', 'GRU']","본 연구에서는 보안과 범죄 예방 강화의 하나로 공공 CCTV와 보안 카메라의 영상 데이터를 사용하여주거 및 공용 공간에서 이상행동을 탐지하기 위한 AI 학습 데이터 세트의 구축과 이를 활용한 모델을 시범 개발하였다. AI 학습 데이터 세트와 모델은 민간 기업의 AI 기술 발전과 AI 프로젝트 개발을 촉진하기 위해 설계되었다.데이터 세트 구축 시 비디오 프레임에서 특징을 추출하기 위하여 ResNet50을, JSON 파일에서 스켈레톤 포인트를처리하기 위하여 3D-CNN을 사용하여 모듈화 하였다. 이 데이터를 사전에 정의된 이상행동에 따라 Labeling 하였다. 또한 GridCV를 사용하여 SVM 분류기와 비디오 시퀀스 처리를 위한 GRU를 활용하였다. 모델의 학습 성능평가에서는 주요 정확도(main accuracy)가 지속해서 향상되었으며, 상세 손실(detailed loss) 또한 감소하는 추세를 보였다. 이를 바탕으로 학습된 모델은 주어진 비디오 시퀀스에서 나타나는 행동의 범주를 예측할 수 있다. 본연구에서 구축된 AI 학습 데이터 세트와 모델 시범 개발로 즉각적인 이상행동 감지를 통한 범죄예방 및 범인 검거를 위해 인공지능 학습에 필요한 데이터 확보, 구축 및 배포하여 민간기업의 AI 기술 발전 및 인공지능 사업의발전을 도모하고자 이상행동 탐지 기능 개발의 실용성에 대한 귀중한 인사이트를 제공하여 공공 안전 분야에서AI 애플리케이션의 발전에 기여할 것으로 기대된다.","This study presents the construction of an AI learning dataset and the prototypical development of a model for detecting anomalous behaviors in residential and public spaces, as part of an effort to enhance security and crime prevention. The AI learning dataset and model were designed to stimulate the advancement of AI technology and the development of AI projects in private companies. During the dataset construction, ResNet50 was modularized to extract features from video frames, and 3D-CNN was used to process skeleton points from JSON files. This data was then labeled according to predefined anomalous behaviors.Furthermore, GridCV was employed to utilize the SVM classifier and GRUs for processing video sequences. The learning performance evaluation of the model demonstrated a continuous improvement in main accuracy and a decreasing trend in detailed loss.. The trained model can predict the category of behavior appearing in a given video sequence. The AI learning dataset and model prototyped in this study provide valuable insights into the practicality of developing anomaly detection functions. It is expected to contribute to the advancement of AI applications in the field of public safety by securing, constructing, and distributing data necessary for AI learning for immediate anomaly detection, crime prevention, and offender apprehension."
방위산업보안을 위한 X-ray 영상과 딥러닝 기반 소형 저장장치 검출,2024,"['X선 영상', '딥러닝', 'Faster R-CNN', 'Xception', 'YOLO', 'X-ray image', 'deep learning', 'Faster R-CNN', 'Xception', 'YOLO']","방위산업을 포함한 주요 제조업(반도체, 디스플레이, 이차전지, 자동차 등)에서유출되는 저장장치를 보안요원이 탐지하는 데는 많은 시간과 훈련이 필요하다. 본 논문에서는 X-ray 영상과 딥러닝을 이용하여 소형 저장장치의 정확한 탐지를통해 방위 산업의 핵심 정보 유출을 방지하여 산업 안보에 기여하는 것을 목표로한다. 이를 위해 먼저, 공개된 저장장치 이미지 세트와 클라이언트의 샘플데이터를 사용하여 저장장치 탐지에 특화된 데이터셋을 구축하였다. 이어서, 저장장치 탐지에 적합한 모델을 찾기 위해 다양한 딥러닝 기반 객체 탐지 모델을조사하였으며, 그 결과 Faster R-CNN, Xception 및 YOLO를 이용하여 각각84.33%, 91.74%, 95.94%의 mAP(mean Average Precision)를 얻었다.","It takes a lot of time and training for security guards to detect storage devices exported from defense industries. In this paper, we aim to prevent the leakage of critical information with X-ray image and deep learning in defense industries and thus contribute to defense industrial security through accurate detection of storage devices. The first step is to build a data set specialized for small storage device detection using the open image set and sample data from the client. To find a suitable model for detecting storage devices, various deep learning-based object detection models were investigated. Finally, the obtained mAP of Faster R-CNN, Xception and YOLO were 84.33%, 91.84%, 95.94%, respectively."
Convoluted Neural Network for Detection of Clinically Significant Prostate Cancer on 68 Ga PSMA PET/CT Delayed Imaging by Analyzing Radiomic Features,2024,['Positron emission tomography computed tomography · 68 Ga PSMA · Neural networks · Prostate cancer'],,"Purpose To assess the utility of convoluted neural network (CNN) in differentiating clinically significant and insignificantprostate cancer in patients with 68 Ga PSMA PET/CT-targeted prostate biopsy-proven prostate cancer.Methods In this retrospective study, 142 patients with clinical suspicion of prostate cancer were evaluated who underwent68 Ga-PSMA PET/CT imaging followed by 68 Ga-PSMA PET/CT-targeted prostate biopsy from the PSMA-avid prostatelesion. Twenty patients with no PSMA-avid lesions were excluded. Local Image Features Extraction (LifeX) software wasused to extract radiomic features (RF) from delayed 68 Ga-PSMA PET/CT images of 122 patients. LifeX failed to extractradiomic features in 24 patients, and the remaining 98 were evaluated. RFs were fed to an in-built CNN of the software forcomputation and results were achieved. Patients with Gleason Score ≥ 7 on histopathology were labeled clinically significantprostate cancer (csPCa). The diagnostic values of radiomic features were evaluated.Results The csPCa was revealed in 69/98 (70.4%) patients, and insignificant PCa was noticed in 29/98 (29.6%) patients.The software extracted 124 RF from the delayed 68 Ga-PSMA PET/CT images. The accuracy of the CNN was 80.7% todifferentiate clinically significant and clinically insignificant prostate cancer, with an error percentage (E %) of 19.3%. Thesensitivity, specificity, positive predictive, and negative predictive values were 90.3%, 57.7%, 83.6%, and 71.4%, respectively,to detect csPCa.Conclusion CNN is a feasible pre-biopsy screening tool for identifying clinically significant prostate cancer and can be usedas an adjunct in the initial diagnosis and early treatment planning."
Comparative analysis of chronic progressive nephropathy (CPN) diagnosis in rat kidneys using an artificial intelligence deep learning model,2024,['Deep learning · Histopathology · Chronic progressive nephropathy · YOLOv8 · Mask R-CNN · SOLOv2'],,"With the development of artificial intelligence (AI), technologies based on machines and deep learning are being used in many academic fields. In toxicopathology, research is actively underway to analyze whole slide image (WSI)-level images using AI deep-learning models. However, few studies have been conducted on models for diagnosing complex lesions comprising multiple lesions. Therefore, this study used deep learning segmentation models (YOLOv8, Mask R-CNN, and SOLOv2) to identify three representative lesions (tubular basophilia with atrophy, mononuclear cell infiltration, and hyaline casts) of chronic progressive nephropathy of the kidney, a complex lesion observed in a non-clinical test using rats and selected an initial model appropriate for diagnosing complex lesions by analyzing the characteristics of each algorithm. Approximately 2000 images containing three lesions were extracted using 33 WSI of rat kidneys with chronic progressive nephropathy.Among them, 1701 images were divided into first and second rounds of learning. The loss and mAP50 values were measured twice to confirm the performances of the three algorithms. Loss measurements were stopped at an appropriate epoch to prevent overfitting, and the loss value decreased in the second round based on the data learned in the first round. After measuring the accuracy twice, detection using Mask R-CNN showed the highest mAP50 in all lesions among the three models and was considered sufficient as an initial model for diagnosing complex lesions. By contrast, the YOLOv8 and SOLOv2 models showed low accuracy for all three lesions and had difficulty with segmentation tasks. Therefore, this paper proposes a Mask R-CNN as the initial model for segmenting complex lesions. Precise diagnosis is possible if the model can be trained by increasing the input data, thereby providing greater accuracy in diagnosing pathological images."
Research on Pattern Elements and Colors in Apparel Design through Fractal Theory,2024,"['Apparel Design', 'Color', 'Fractal Theory', 'Pattern']",,"Excellent apparel design can increase market competitiveness. This article briefly introduced the theory offractals and its application in the field of apparel design. The convolutional neural network (CNN) algorithmwas used to assist in the evaluation of apparel designs. In the case analysis, the accuracy of the evaluation wasvalidated by comparing the CNN algorithm with two other intelligent algorithms, support vector machine(SVM) and back propagation (BP). The evaluation of the proposed design showed that compared with SVMand BP algorithms, the CNN algorithm had higher accuracy in evaluating apparel designs. The evaluation resultof the proposed apparel design not only further verifies the effectiveness of the CNN algorithm, but alsodemonstrates that the theory of fractals can be effectively applied in apparel design to provide more innovativedesigns."
A Deep Learning Based Breast Cancer Classification System Using Mammograms,2024,['Breast cancer detection  · Preprocessing  · Contrast enhancement  · Genetic algorithm  · Markov random adaptive segmentation (MRAS)  · Genetic algorithm (GA) based optimization  · Convolutional neural network (CNN) based classifi cation'],,"An automatic breast cancer detection and classifi cation system plays an essential role in medical imaging applications. But accurate disease identifi cation is one of the complicated processes due to the existence of noisy contents and irrelevant structure of the original images. In conventional works, various medical image processing techniques have been developed for accurately classifying the types of breast cancer. Still, it confronts diffi culties due to the aspects of increased complexity in computations, error values, false positives, and misclassifi cation outputs. Hence, this research work proposes to develop an optimization-based classifi cation system for the breast cancer identifi cation system. Here, the Gaussian fi ltering and Adaptive Histogram Equalization (AHE) techniques are utilized for preprocessing the original mammogram images by eliminating the noisy contents and enhancing the contrast of an image. Then, the Markov Random Adaptive Segmentation (MRAS) technique is employed for detecting the boundary region based on the random value selection. To make the classifying procedure easier, the set of features is optimally extracted from the segmented region with the help of a Genetic Algorithm (GA). In which, the global best fi tness value is estimated by using the crossover, mutation, and selection operations. Finally, the Convolutional Neural Network (CNN) classifi cation technique is utilized for categorizing the image as to whether normal or abnormal with its type. The entire performance analysis of the suggested model is validated and compared using multiple measures during the evaluation. In the proposed method GA performs feature selection and prunes unnecessary features. The major goal is to improve the classifi cation performance while reducing the number of features used. The proposed system GA-CNN provides improved performance results with a reduced error rate.The suggested GA-CNN increases accuracy (98.5), sensitivity (99.38), and specifi city values (98.4) as compared to the existing technique by eff ectively identifying the classed label."
Accuracy of posteroanterior cephalogram landmarks and measurements identification using a cascaded convolutional neural network algorithm: A multicenter study,2024,"['Artificial intelligence', 'Convolutional neural network', 'Posteroanterior cephalograms']",,"Objective: To quantify the effects of midline-related landmark identification on midline deviation measurements in posteroanterior (PA) cephalograms using a cascaded convolutional neural network (CNN). Methods: A total of 2,903 PA cephalogram images obtained from 9 university hospitals were divided into training, internal validation, and test sets (n = 2,150, 376, and 377). As the gold standard, 2 orthodontic professors marked the bilateral landmarks, including the frontozygomatic suture point and latero-orbitale (LO), and the midline landmarks, including the crista galli, anterior nasal spine (ANS), upper dental midpoint (UDM), lower dental midpoint (LDM), and menton (Me). For the test, Examiner-1 and Examiner-2 (3-year and 1-year orthodontic residents) and the Cascaded-CNN models marked the landmarks. After point-to-point errors of landmark identification, the successful detection rate (SDR) and distance and direction of the midline landmark deviation from the midsagittal line (ANS-mid, UDM-mid, LDM-mid, and Me-mid) were measured, and statistical analysis was performed. Results: The cascaded-CNN algorithm showed a clinically acceptable level of point-to-point error (1.26 mm vs. 1.57 mm in Examiner-1 and 1.75 mm in Examiner-2). The average SDR within the 2 mm range was 83.2%, with high accuracy at the LO (right, 96.9%; left, 97.1%), and UDM (96.9%). The absolute measurement errors were less than 1 mm for ANS-mid, UDM-mid, and LDM-mid compared with the gold standard. Conclusions: The cascaded-CNN model may be considered an effective tool for the auto-identification of midline landmarks and quantification of midline deviation in PA cephalograms of adult patients, regardless of variations in the image acquisition method."
Classification of Pulmonary Nodules in 2-[ 18 F]FDG PET/CT Images with a 3D Convolutional Neural Network,2024,['Convolutional neural networks · Positron emission tomography · 2-[18F]FDG PET/CT · Pulmonary nodules · Artificial intelligence'],,"Purpose 2-[18F]FDG PET/CT plays an important role in the management of pulmonary nodules. Convolutional neuralnetworks (CNNs) automatically learn features from images and have the potential to improve the discrimination betweenmalignant and benign pulmonary nodules. The purpose of this study was to develop and validate a CNN model for classificationof pulmonary nodules from 2-[18F]FDG PET images.Methods One hundred thirteen participants were retrospectively selected. One nodule per participant. The 2-[18F]FDG PETimages were preprocessed and annotated with the reference standard. The deep learning experiment entailed random datasplitting in five sets. A test set was held out for evaluation of the final model. Four-fold cross-validation was performed fromthe remaining sets for training and evaluating a set of candidate models and for selecting the final model. Models of threetypes of 3D CNNs architectures were trained from random weight initialization (Stacked 3D CNN, VGG-like and Inceptionv2-like models) both in original and augmented datasets. Transfer learning, from ImageNet with ResNet-50, was also used.Results The final model (Stacked 3D CNN model) obtained an area under the ROC curve of 0.8385 (95% CI: 0.6455–1.0000)in the test set. The model had a sensibility of 80.00%, a specificity of 69.23% and an accuracy of 73.91%, in the test set, foran optimised decision threshold that assigns a higher cost to false negatives.Conclusion A 3D CNN model was effective at distinguishing benign from malignant pulmonary nodules in 2-[18F]FDGPET images."
처리성능 최적화를 위한 생성형 인공지능 이미지 판별 방안,2024,"['생성형 인공지능', '생성된 합성 이미지 분류', '합성곱신경망', '하이퍼 파라미터 튜닝', 'Generative AI', 'Generative Image Classification', 'Convolutional Neural Network', 'Hyperparameter Optimization']","생성형 인공지능의 등장으로 실제 이미지와 합성 이미지의 조작 여부를 판별하기 어려워졌다. 이러한 문제를 해결하기 위해 본 논문에서는 실제 임베디드 환경에서 실제 이미지와 생성형 인공지능이 생성한 합성 이미지를 효율적으로 판별하는 기술을 제안한다. 제안된 방법은 기존 CNN 구조에 하이퍼 파라미터 튜닝을 통해 모델의 이미지 처리 성능 최적화를 진행하였다. 또한 모델의 경량화를 진행해 본 논문의 지향점인 최소한의 파라미터로 최고의 성능을 달성하는 것을 목표로 모델을 설계하였다. 제안된 모델은 입력 영상에서 특징을 추출하는 CNN 계층, 영상의 크기를 줄이면서 주요 특징을 유지하는 Max Pooling, 마지막으로 최종 예측 값을 수행하는 Dense 계층으로 구성되어 있으며, 여기에 하이퍼 파라미터 튜닝을 통해 모델의 처리 성능 및 최적화를 진행하였다. 제안된 모델의 정량적 평가를 위해 제한된 환경인 임베디드 보드에서 실험을 진행한 결과, 제안된 모델은 비교 평가를 위해 선정한 모델들인 EfficientNetB0, ViT(Vision Transformer)과 유사한 정확도를 보유하면서 처리 성능 측면에서 다른 모델들에 비해 Model load time 및 Inference time이 더 효율적인 것을 확인할 수 있었다.","With the advent of generative artificial intelligence, it has become difficult to determine whether real and synthetic images are manipulated. To solve this problem, this paper proposes a technology to efficiently classifying between real images and synthetic images generated by generative artificial intelligence in a real embedded environment. The proposed method optimized the image processing performance of the model through hyperparameter tuning to the existing CNN structure. In addition, the model was designed with the aim of achieving the best performance with minimal parameters, which is the goal of this paper by proceeding with the weight reduction of the model. The proposed model is a CNN layer that extracts features from the input image, reducing the size of the image while reducing the main features It consists of the maintaining Max Pooling, and finally, the Dense layer that performs the final prediction value, and the processing performance and optimization of the model were carried out through hyperparameter tuning. As a result of conducting experiments on an embedded board, which is a limited environment for the quantitative evaluation of the proposed model, it was confirmed that the proposed model load time and inference time were more efficient than other models in terms of processing performance while having similar accuracy to the models selected for comparative evaluation, EfficientNetB0 and ViT (Vision Transformer)."
다중 세그먼트 신호를 이용한 WiFi CSI 기반의 사람 행동 인식,2024,"['Human Activity Recognition(HAR)', 'WiFi CSI', 'Multiple Segment', 'Prediction-Score Fusion', '사람 행동 인식', 'WiFi CSI', '다중 세그먼트', '예측점수 융합']","센서 기반의 행동 인식 기술은 비전 기반 방식에 비하여 사생활 침해의 우려가 적은 장점이 있다. 이와 더불어 CSI 신호를 이용한 행동 인식 방식은 사용자에게 센서를 부착하거나 센서가 내장된 기기를 휴대해야 하는 불편을 해소하여 사용자 편이성을 극대화할 수 있다. 본 연구에서는 CSI 신호를 효과적으로 식별할 수 있는 두 가지 딥 러닝 모델을 제안한다. CNN 모델은 5개의 합성곱층과 2개의 밀집층으로 구성하였고, 양방향 LSTM 모델은 2개의 Bi-LSTM층과 2개의 밀집층으로 구성하였다. 또한 여러 세그먼트의 예측 결과를 융합하는 예측-점수 융합 방법을 제안한다. 융합 방법은 4개의 규칙(다수결, 곱, 합, 최대)을 사용한다. 본 연구에서는 걷기, 달리기, 앉기, 일어나기, 구부리기, 쓰러지기, 눕기의 7가지 일상 행동에 대한 CSI 신호로 구성된 데이터세트로 실험을 진행하였다. 원천 신호를 동일한 길이의 세그먼트로 분할하기 위해 본 연구에서 제시한 다운샘플링 방식은 슬라이딩 윈도우 방식에 비하여 더 짧은 신호로 더 정확하게 사람의 행동을 식별할 수 있음을 실험을 통해 확인하였다. 제안한 CNN 모델과 양방향 LSTM 모델은 단일 세그먼트 신호에 대하여 각각 89.29%, 95.24%의 정확도를 보여 제안된 모델의 유효성을 확인하였다. 또한 다중 세그먼트를 이용한 예측점수 융합 방식으로 정확도 향상이 가능함을 확인하였다.","Sensor-based activity recognition technology has the advantage of reducing the risk of privacy infringement compared to vision-based methods. In addition, the activity recognition method using CSI signals can maximize user convenience by eliminating the inconvenience of attaching a sensor to the user or carrying a device with a built-in sensor. This study proposes two deep-learning models that can effectively identify CSI signals. One is a CNN model with five convolution layers and two dense layers, and the other is a bidirectional LSTM model with two Bi-LSTM layers and two dense layers. Prediction-score fusion methods were presented that fuse the prediction results from multiple segments. The fusion method uses four rules: majority rule, product rule, sum rule, and max rule. This study uses a database with seven daily activities: walking, running, sit-down, stand-up, bending, falling, and lying down. Experimental results show that a downsampling method can more accurately identify human activity with shorter signals than the sliding window method. The proposed CNN and bidirectional LSTM models show an accuracy of 89.29% and 95.24%, respectively, for single-segment signals. It shows the effectiveness of the proposed model. Furthermore, it confirms that accuracy can be improved using the prediction-score fusion method using multiple segments."
딥러닝을 활용한 운전자 기반 보행자 감지 시스템,2024,"['Pedestrian', 'Yolo', 'Driver', 'Deep learning', 'Image segmentation']","본 연구의 목적은 운전자로부터 보행자의 신호 상태와 횡단보도, 인도 영역을 쉽게 인지하여 보행자의 안전에 도움을 줄 수 있는 운전자 기반 보행자 안전 알고리즘을 제시하였다. 연구에서는 단안 카메라와 객체 검출 알고리즘 중 하나인 image segmentation을 사용하였다. 운전자를 기반으로 보행자와 횡단보도, 자동차를 검출하기 위해서는 정확한 segmentation 경계와 객체를 검출하여 판단할 수 있는 능력이 필요하다. 실험을 하기 전 객체 검출과 segmentation을 제공하는 모델 Mask R-CNN와 YOLOv8 모델의 구조를 비교하였다. Mask R-CNN은 RolAign 이후에 segmentation mask branch 구조를 추가시켜 각 객체에 대해 픽셀 단위의 마스크를 예측하게 하였다. YOLOv8-seg YOLACT 알고리즘의 원리를 사용한다. Segmentation Branch 구조를 추가시켜 instance segmentation을 수행할 수 있도록 하였다. 논문에서는 YOLOv8-seg 모델을 사용하고 COCO-seg 데이터 셋의 여러 모델을 성능과 학습을 분석하여 실험을 진행하였다. 실험을 진행 후 자동차 안에서의 라이브 스트리밍을 통해 실시간 성능을 확인하였다.","The purpose of this study is to propose a driver-based pedestrian safety algorithm that helps drivers easily recognize pedestrian signal status, crosswalks, and sidewalk areas, thereby enhancing pedestrian safety. The study uses a monocular camera and one of the object detection algorithms, image segmentation. To detect pedestrians, crosswalks, and vehicles from the driver's perspective, it is necessary to have the ability to accurately detect objects and boundaries through segmentation. Prior to the experiments, the structures of the Mask R-CNN and YOLOv8 models, which provide object detection and segmentation, were compared. Mask R-CNN adds a Segmentation Mask Branch structure after RoIAlign, enabling pixel-level mask prediction for each object. The YOLOv8-seg model utilizes the principles of the YOLACT algorithm, adding a Segmentation Branch structure to perform instance segmentation. The paper uses the YOLOv8-seg model and analyzes the performance and training of various models on the COCO-seg dataset. After conducting experiments, the real-time performance was verified through live streaming from within the vehicle."
특성 확장을 이용한 태양광 발전량 예측을 위한 딥러닝 모델,2024,"['solar photovoltaic generation forecast', 'deep neural network', 'parallel model', '.']","무한한 에너지원을 가진 태양광 발전은 기상 환경에 의존하기 때문에 발전량이 간헐적이어서 효율적인 에너지 관리를 위해서 발전량의 불확실성을 줄이고 경제성을 향상하기 위하여 정확한 발전량 예측 기술이 필요하다. 본 논문은 특성 공학을 이용하여 입력 특성을 확장하고, 다양한 딥러닝 모델을 통해 태양광 발전량을 예측하였다. 제안한 딥러닝 모델은 기본 딥러닝 모델을 병렬로 연결한 모델로서 DNN 모델을 기본으로 1D-CNN, Multi kernel 1D-CNN을 병합한 DCNN, DMCNN 모델과 LSTM, BiLSTM을 병합한 DLSTM, DBiLSTM 모델이다. 실험 결과, 기본 모델에서는 특성공학을 적용한 모델의 오차가 적었으며, 기본 모델 보다 병렬 모델의 오차가 적었다.  특히, 병렬 모델 중에서도 DBiLSTM 모델이 본 논문에서 제시한 모델 중 가장 뛰어난 성능을 보였으며, 영암 발전소에서의 RMSE는 0.0326, 연성 발전소에서의 RMSE는 0.0231로 나타났다.","Solar power generation, which relies on an infinite energy source, is intermittent due to its dependence on weather conditions. Therefore, accurate power generation prediction technology is essential to reduce the uncertainty of power generation and enhance economic efficiency for effective energy management. This paper expands input features using feature engineering and predicts solar power generation through various deep learning models. The proposed deep learning models are parallel models that connect basic deep learning models in parallel, including the DCNN and DMCNN models, which merge 1D-CNN and Multi-kernel 1D-CNN based on the DNN model, and the DLSTM and DBiLSTM models, which merge LSTM and BiLSTM. The experimental results showed that the models applying feature engineering had lower errors in the basic models, and the parallel models had even lower errors than the basic models. In particular, among the parallel models, the DBiLSTM model demonstrated the best performance of all the models proposed in this paper, with an RMSE of 0.0326 for the Yeong-am Power Plant and an RMSE of 0.0231 for the Yeon-seong Power Plant."
Classification of Mild Cognitive Impairment Using Functional Near-Infrared Spectroscopy-Derived Biomarkers With Convolutional Neural Networks,2024,"['Functional neuroimaging', 'Mild cognitive impairment', 'Machine learning', 'Brain', 'biomarkers']",,"Objective To date, early detection of mild cognitive impairment (MCI) has mainly depended on paper-based neuropsychological assessments. Recently, biomarkers for MCI detection have gained a lot of attention because of the low sensitivity of neuropsychological assessments. This study proposed the functional near-infrared spectroscopy (fNIRS)-derived data with convolutional neural networks (CNNs) to identify MCI.Methods Eighty-two subjects with MCI and 148 healthy controls (HC) performed the 2-back task, and their oxygenated hemoglobin (HbO2) changes in the prefrontal cortex (PFC) were recorded during the task. The CNN model based on fNIRS-derived spatial features with HbO2 slope within time windows was trained to classify MCI. Thereafter, the 5-fold cross-validation approach was used to evaluate the performance of the CNN model.Results Significant differences in averaged HbO2 values between MCI and HC groups were found, and the CNN model could better discriminate MCI with over 89.57% accuracy than the Korean version of the Montreal Cognitive Assessment (MoCA) (89.57%). Specifically, the CNN model based on HbO2 slope within the time window of 20–60 seconds from the left PFC (96.09%) achieved the highest accuracy.Conclusion These findings suggest that the fNIRS-derived spatial features with CNNs could be a promising way for early detection of MCI as a surrogate for a conventional screening tool and demonstrate the superiority of the fNIRS-derived spatial features with CNNs to the MoCA."
Application of deep learning with bivariate models for genomic prediction of sow lifetime productivity-related traits,2024,"['Convolutional Neural Network', 'Deep Learning', 'Epistatic Interaction', 'Genomic Prediction', 'Pig', 'Sow Lifetime Productivity']",,"Objective: Pig breeders cannot obtain phenotypic information at the time of selection for sow lifetime productivity (SLP). They would benefit from obtaining genetic information of candidate sows. Genomic data interpreted using deep learning (DL) techniques could contribute to the genetic improvement of SLP to maximize farm profitability because DL models capture nonlinear genetic effects such as dominance and epistasis more efficiently than conventional genomic prediction methods based on linear models. This study aimed to investigate the usefulness of DL for the genomic prediction of two SLP-related traits; lifetime number of litters (LNL) and lifetime pig production (LPP).Methods: Two bivariate DL models, convolutional neural network (CNN) and local convolutional neural network (LCNN), were compared with conventional bivariate linear models (i.e., genomic best linear unbiased prediction, Bayesian ridge regression, Bayes A, and Bayes B). Phenotype and pedigree data were collected from 40,011 sows that had husbandry records. Among these, 3,652 pigs were genotyped using the PorcineSNP60K BeadChip.Results: The best predictive correlation for LNL was obtained with CNN (0.28), followed by LCNN (0.26) and conventional linear models (approximately 0.21). For LPP, the best predictive correlation was also obtained with CNN (0.29), followed by LCNN (0.27) and conventional linear models (approximately 0.25). A similar trend was observed with the mean squared error of prediction for the SLP traits.Conclusion: This study provides an example of a CNN that can outperform against the linear model-based genomic prediction approaches when the nonlinear interaction components are important because LNL and LPP exhibited strong epistatic interaction components. Additionally, our results suggest that applying bivariate DL models could also contribute to the prediction accuracy by utilizing the genetic correlation between LNL and LPP."
Short-Packet Communications in Wireless Energy Transfer Full-Duplex IoT Networks with Deep Learning Design,2024,"['Deep neural network', 'residual self-interference', 'short-packet communication', 'wireless power transfer']",,"In this paper, we study wireless energy transfer full-duplex (FD) Internet-of-Things (IoT) networks, where multiple FD IoT relays are deployed to assist short-packet communications between a source and a robot destination with multiple antennas in automation factories. Taking into account two residual interference (RSI) models for FD relays, we propose a full relay selection (FRS) scheme to maximize the end-to-end signal-to-noise ratio of packet transmissions aiming at improving the block error rate (BLER) and throughput of the considered system. Towards real-time configurations, we design a deep learning framework based on the FRS scheme to accurately predict the average BLER and system throughput via a short inference process. Simulation results reveal the significant effects of RSI models on the performance of FD IoT networks. Furthermore, the CNN design achieves the lowest root-mean-squared error among other schemes such as the conventional CNN and deep neural network. Furthermore, the DL framework can estimate similar BLER and throughput values as the FRS scheme, but with significantly reduced complexity and execution time, showing the potential of DL design in dealing with complex scenarios of heterogeneous IoT networks.In this paper, we study wireless energy transfer full-duplex (FD) Internet-of-Things (IoT) networks, where multiple FD IoT relays are deployed to assist short-packet communications between a source and a robot destination with multiple antennas in automation factories. Taking into account two residual interference (RSI) models for FD relays, we propose a full relay selection (FRS) scheme to maximize the end-to-end signal-to-noise ratio of packet transmissions aiming at improving the block error rate (BLER) and throughput of the considered system. Towards real-time configurations, we design a deep learning framework based on the FRS scheme to accurately predict the average BLER and system throughput via a short inference process. Simulation results reveal the significant effects of RSI models on the performance of FD IoT networks. Furthermore, the CNN design achieves the lowest root-mean-squared error among other schemes such as the conventional CNN and deep neural network. Furthermore, the DL framework can estimate similar BLER and throughput values as the FRS scheme, but with significantly reduced complexity and execution time, showing the potential of DL design in dealing with complex scenarios of heterogeneous IoT networks."
EOG 기반 수평 시선 추적 경량형 딥러닝 알고리즘의 최적화를 위한 가상 환경 실험,2024,"['시선추적', 'CNN', '안구전위', '가상환경', '메타버스', '안구움직임', 'eyetracking', 'CNN', 'EOG', 'virtual environment', 'Metaverse', 'eye gaze']","본 연구는 매우 적은 수의 파라미터의 딥러닝 모델로 정확도를 높이고 이에 더하여 눈 깜빡임을 실시간으로 예측할 수 있는 알고리즘을 제안하고 실험한다. 기존의 시선 추적 알고리즘은 눈동자에서나오는 EOG 신호가 각도에 따라 선형성[1,2]을 띈다는 점에서 착안한 알고리즘에 기반하여 연구가 진행이 되어 왔다. 하지만 본 논문에서 제시하고자 하는 알고리즘은 유도 편향을 보이는 데이터이기에 1D CNN, Residual Block등과 같은 Layer들을 사용하여 경량형 딥러닝 네트워크를 구성하여 실시간 예측이 가능하다. 이 연구에서는 추가적으로 눈 깜빡임에 대한 딥러닝 모델 예측을 이용하여 가상 환경 전용 HMD를 착용한 상태에서도 안구 움직임을 예측할 수 있는 장치를 사용하여 실험을 진행하였다. 이 연구에서 진행한 EOG Data를 이용한 안구 복원을 상하 움직임과 극단적인 눈동자 움직임에 대한 연구를 추가하여 아바타 안구의 실시간성을 살려 사실감 있는 복원에 대한 구현이 가능하다.",
Assessing Stream Vegetation Dynamics and Revetment Impact Using Time-Series RGB UAV Images and ResNeXt101 CNNs,2024,"['UAV', 'VDVI', 'CNN', 'ResNeXt101 model', 'Stream management', 'Revetment']",,"Small streams, despite their rich ecosystems, face challenges in vegetation assessment due tothe limitations of traditional, time-consuming methods. This study presents a groundbreaking approach,combining unmanned aerial vehicles (UAVs), convolutional neural networks (CNNs), and the vegetationdifferential vegetation index (VDVI), to revolutionize both assessment and management of streamvegetation. Focusing on Idong Stream in South Korea (2.7 km long, 2.34 km² basin area) with eight diverserevetment methods, we leveraged high-resolution RGB images captured by UAVs across five dates (July–December). These images trained a ResNeXt101 CNN model, achieving an impressive 89% accuracy inclassifying vegetation cover (soil, water, and vegetation). This enabled detailed spatial and temporal analysisof vegetation distribution. Further, VDVI calculations on classified vegetation areas allowed assessmentof vegetation vitality. Our key findings showcase the power of this approach: (a) The CNN model generatedhighly accurate cover maps, facilitating precise monitoring of vegetation changes over time and space. (b)August displayed the highest average VDVI (0.24), indicating peak vegetation growth crucial for stabilizingstreambanks and resisting flow. (c) Different revetment methods impacted vegetation vitality. Fieldstonesections exhibited initial high vitality followed by decline due to leaf browning. Block-type sections andthe control group showed a gradual decline after peak growth. Interestingly, the “H environment block”exhibited minimal change, suggesting potential benefits for specific ecological functions. (d) Despite initialdifferences, all sections converged in vegetation distribution trends after 15 years due to the influence ofsurrounding vegetation. This study demonstrates the immense potential of UAV-based remote sensingand CNNs for revolutionizing small-stream vegetation assessment and management. By providing high-resolution, temporally detailed data, this approach offers distinct advantages over traditional methods,ultimately benefiting both the environment and surrounding communities through informed decision-making for improved stream health and ecological conservation."
Black Ice Detection System Using Artificial Intelligence,2024,"['Black Ice', 'CNN model', 'YOLOv5 model', 'YOLOv8 model', 'Real-time']",,"As a result of analyzing domestic traffic accidents, the number of fatalities caused by black ice-related accidents is as much as 3.7 than that of snowy road accidents. Unlike ordinary snow, black ice is difficult to detect with the naked eye, and it is hard for drivers to distinguish it within a second while driving. Therefore, the plan is to apply computer vision to detect black ice in real-time. To accomplish this task, three Artificial Intelligence models were compared and analyzed. The Artificial IntelligenceI models used are CNN, YOLOv5, and YOLOv8. The CNN model detected 258 out of 285 images where black ice occurred, with an accuracy of 87%. YOLOv5 detected 270 out of 285 images, achieving an accuracy of 95%. Lastly, YOLOv8 showed the highest accuracy, detecting 280 out of 285 images with an accuracy of 98%. In the future, this research will be combined with real-time CCTV installed by the National Traffic Information Center to detect black ice in real-time during winter and provide solutions to reduce the likelihood of traffic accidents caused by black ice."
딥러닝을 이용한 영상의 병변 분류 모델,2024,"['Deep Learning', 'CNN', 'VGG16', 'Lesion', 'Classification']",본 논문은 피부 병변을 분류하기 위해 CNN 기반의 수정된 VGG16 모델을 제안한다. 제안한 모델의 성능 평가를 위해 2018 MICCAI 분류 챌린지의 HAM10000 데이터 셋을 사용하였다. 데이터 개수가 부족한 문제를 보완하기 위해 증강기법을 적용하였다. 실험을 통해 7가지 종류의 피부 병변에 대해 평균 96.81%의 정확도를 얻었다. 실험 결과는 피부질환을 조기에 식별하는데 도움이 되며 의료 전문가가 적절하게 검증하고 치료하는데 활용할 수 있을 것이다.,"This paper proposes a modified VGG16 model based on CNN to classify skin lesions. To evaluate the performance of the proposed model, the HAM10000 data set from the 2018 MICCAI classification challenge was used. Augmentation technique was applied to compensate for the problem of insufficient data. Through the experiment, an average accuracy of 96.81% was obtained for 7 types of skin lesions. The experimental results will help identify skin diseases early and can be used by medical professionals to appropriately verify and treat them."
State-of-Health Prediction for Li-ion Batteries for Efficient Battery Management System Using Hybrid Machine Learning Model,2024,['Machine learning · CNN · ARIMA · GRU · Energy storage devices · Li-ion batteries'],,"Since Lithium-ion (Li-ion) batteries are frequently used for real-time applications, evaluating their State of Health (SoH) is crucial to guarantee their efectiveness and safety. Model-based methods with SoH prediction are helpful. However, the issues with battery modelling have led to a greater dependence on machine learning (ML). As a signifcant step in assessing the efectiveness of ML techniques, data preprocessing has also drawn much attention. In this work, a new preprocessing method using relative State of Charge (SoC) is proposed; further, this paper describes a hybrid learning model (HLM) that combines auto-regressive integrated moving average (ARIMA), gated recurrent unit (GRU) and convolutional neural network (CNN). Data: proposed HLM uses time-series and SoC domain data; the ARIMA+GRU algorithm trains the time-series data, while CNN trains the SoC domain data. Both outputs are mean averaged to get the fnal output prediction. The proposed HLM is evaluated for root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) using the National Aeronautics and Space Administration (NASA’s) randomized battery usage data set (RBUDS).The results indicate that the recommended HLM is more accurate and has a smaller error margin than existing ML models."
신경망을 이용한 반도체 테스트 핀 불량 검출,2024,"['Deep learning', 'CNN', 'Perceptron', 'Automatic defect classification', 'Semiconductor']","사람의 머리카락보다 얇은 반도체 테스트 핀으로 반도체 단자에 접촉하여 반도체의 전기적 선능 측정을 반복한다. 테스트 핀과 반도체 사이의 완전한 접촉을 위하여 핀에는 스프링이 있어서 스프링을 중심으로 양쪽의 구조가 눌렸다 펴지기를 반복한다. 만약 불량 테스트 핀이 발생하면 완전한 접촉이 되지 않아 반도체 성능 측정에 오류가 발생한다. 본 논문은 합성곱 신경망 (CNN) 기법 및 다층 퍼셉트론 신경망 (MLP)을 이용하여 양호한 핀과 불량한 핀을 학습하여 사람의 눈을 이용하지 않고 불량 핀을 검출한다. 따라서 수작업으로 불량 핀을 검출하지 않고, 제안하는 두 모델을 이용하여 기계가 자동으로 약 97%의 정확도로 불량 핀을 검출할 수 있다.","Semiconductor test pins, which are thinner than human hair, repeatedly make contact with semiconductor terminals to measure the electrical performance of the semiconductors. To ensure complete contact between the test pins and the semiconductor, the pin is equipped with a spring, allowing the structure on both sides of the spring to be compressed and then released repeatedly. If a defective test pin occurs, it results in incomplete contact, leading to errors in measuring semiconductor performance. This paper utilizes Convolutional Neural Networks (CNN) and Multilayer Perceptron Neural Networks (MLP) techniques to train and detect good and defective pins, thereby detecting defective pins without the use of human vision. Therefore, instead of manually detecting defective pins, the proposed models enable machines to automatically detect defective pins with about 97% accuracy."
포렌식을 위한 MFCC 기반의 오디오 음질 분류 방법,2024,"['audio quality classification', 'MFCC', 'CNN', 'modified DenseNet', 'forensics', '.']","통신, 엔터테인먼트, 보안 등 다양한 분야에서 오디오의 활용이 증가함에 따라서, 그 음질을 평가하여 응용하는 것이 중요해지고 있다. 특히, 오디오 포렌식 분야에서 오디오의 고음질과 저음질을 신속하게 판별하는 기술은 불법적인 녹취 데이터를 분류하는데 기여한다. 본 논문에서는 변형된 DenseNet 기반의 음질 분류 모델을 통해 오디오의 음질을 판단하는 방법을 제안한다. 3초 단위 오디오를 입력받아, MFCC(Mel-Frequency Cepstral Coefficients)를 이용해 2차원 신호 특징을 추출하였고, 변형된 DenseNet 모델에 적용하여 음질 판단에 활용하였다. 국내외 데이터셋과 자체적으로 수집한 오디오를 사용하여 실험을 수행하였다. CNN 모델을 사용하였을 때 86.7% 정확도를 보였으나, 제안한 변형된 DenseNet 모델을 사용하였을 때 94% 정확도를 달성하였다.","As the use of audio increases in various fields such as communication, entertainment, and security, it is becoming more important to evaluate accurately its quality and apply. In particular, the technology to quickly determine the high and low quality of audio can contribute to classify illegal recording data in the field of audio forensics. In this paper, we propose a method of determining the audio quality using a modified DenseNet-based audio quality classification model. When audio in units of 3 seconds was input, the 2D feature of the audio was extracted using Mel-Frequency Cepstral Coefficients(MFCC) and applied to the modified DenseNet model to determine audio quality. Experiments were performed using domestic and foreign datasets and audio collected in-house. Although the accuracy of the CNN model was 86.7%, the proposed modified DenseNet model achieved the accuracy of 94%."
New dimension in leaf stomatal behavior analysis: a robust method with machine learning approach,2024,['Detection\xa0· Dynamics\xa0· Mask R-CNN\xa0· Segmentation\xa0· Stomatal pore'],,"Stomata are specialized pores that play a vital role in gas exchange and photosynthesis. Microscopic images are often used to assess stomatal characteristics in plants; however, this can be a challenging task. By utilizing Matterport’s Mask R-CNN implementation as the foundational model, fine-tuning was conducted on a dataset of 810 microscopic images of Hedyotis corymbosa leaves’ surfaces for automated stomatal pores detection. The outcomes were promising, with the model achieving a convergence of 98% mean average precision (mAP) for both detection and segmentation. The training loss and validation loss values converged around 0.18 and 0.37, respectively. Regression analyses demonstrated the statistical significance (p values ≤ 0.05) of predictor parameters. Notably, the tightest cluster of data points was observed in stomata pore area meas- urements, followed by width and length. This highlights the precision of the stomatal pore area in characterizing stomatal traits. Despite challenges posed by the original dataset’s low-resolution images and artifacts like dust, bubbles, and blurriness, our innovative utilization of the Mask R-CNN algorithm yielded commendable outcomes. This research introduces a robust approach for stomatal phenotyping with broad applications in plant biology and environmental studies."
Accuracy Measurement of Image Processing-Based Artificial Intelligence Models,2024,"['Machine learning', 'Deep learning', 'CNN models', 'Random forest models', 'VGG16 models', 'Image processing']",,"When a typhoon or natural disaster occurs, a significant number of orchard fruits fall. This has a great impact on the income of farmers. In this paper, we introduce an AI-based method to enhance low-quality raw images. Specifically, we focus on apple images, which are being used as AI training data. In this paper, we utilize both a basic program and an artificial intelligence model to conduct a general image process that determines the number of apples in an apple tree image. Our objective is to evaluate high and low performance based on the close proximity of the result to the actual number. The artificial intelligence models utilized in this study include the Convolutional Neural Network (CNN), VGG16, and RandomForest models, as well as a model utilizing traditional image processing techniques. The study found that 49 red apple fruits out of a total of 87 were identified in the apple tree image, resulting in a 62% hit rate after the general image process. The VGG16 model identified 61, corresponding to 88%, while the RandomForest model identified 32, corresponding to 83%. The CNN model identified 54, resulting in a 95% confirmation rate. Therefore, we aim to select an artificial intelligence model with outstanding performance and use a real-time object separation method employing artificial function and image processing techniques to identify orchard fruits. This application can notably enhance the income and convenience of orchard farmers."
배달 로봇 응용을 위한 LiDAR 센서 기반 객체 분류 시스템,2024,"['LiDAR', 'Point Cloud Data', 'PointPillars', 'DS-CNN', 'Delivery Robot']","본 논문에서는 배달 서비스 로봇 응용을 위한 LiDAR 센서 기반 경량화된 객체 분류 시스템을 제안한다. 3차원 포인트 클라우드 데이터를 Pillar Feature Network (PFN)을 사용하여 2차원 pseudo image로 인코딩한 후, Depthwise Separable Convolution NeuralNetwork (DS-CNN)에 기반하여 설계된 네트워크를 통해 객체 분류를 수행하는 경량화된 시스템을 설계하였다. 구현 결과, 설계한 분류네트워크의 파라미터 수와 Multiply-Accumulate (MAC) 연산 수는 각각 9.08K 및 3.49M이며, 94.94%의 분류 정확도를 지원 가능함을확인하였다","In this paper, we propose a lightweight object classification system using a LiDAR sensor for delivery servicerobots. The 3D point cloud data is encoded into a 2D pseudo image using a Pillar Feature Network (PFN), and thenpassed through a lightweight classification network designed based on Depthwise Separable Convolutional NeuralNetworks (DS-CNN). The implementation results show that the designed classification network has 9.08Kparameters and 3.49M Multiply-Accumulate (MAC) operations, while supporting a classification accuracy of 94.94%."
음향기반 교통사고 검지를 위한 딥러닝 모델 연구,2024,"['Traffic', 'Accident', 'Acoustic', 'Artificial Intelligent', 'DNN', 'CNN', 'RNN', '교통', '사고', '음향', '인공지능', '심층신경망', '합성곱신경망', '순환신경망']","C-ITS(Cooperative-Intelligent Transport Systems) 및 자율주행 환경에서 교통사고와 같은 돌발상황의 신속한 검지가 중요해짐에 따라, 최근에는 이를 위한 다양한 시스템 개발과 관련된 연구가 활발히 진행되고 있다. 본 연구는 기존의 영상 및 레이더 기반 검지 방식의 한계를 극복하기 위해 음향 정보를 이용한 교통사고 검지 기술을 개발하는 것을 목표로 한다. 구체적으로, 교통사고 시 발생하는 음향 데이터를 수집하고, 이를 통해 충돌 및 급제동과 같은 특징을 추출하였다. 추출된 음향 데이터를 바탕으로DNN, CNN, RNN의 딥러닝 모델을 학습시켜 각 모델을 통해 사고 패턴을 검지하는 방법을 연구하였다. 이후, 학습된 모델들의 검지 결과를 비교 분석하여 음향 패턴을 검지하는 데 가장 적합한 알고리즘 모델을 선정하였다. 최적의 알고리즘을 적용하여 음향기반 자동 사고 검지 시스템을 개발하였으며, 이 시스템은 교통사고를 신속하고 정확하게 판별할 수 있다. 본 연구는 딥러닝 알고리즘과 음향 특징 추출 기술을 통해 정확한 교통사고 검지를 가능하게 하여 교통 안전 향상에 기여할 수 있을 것으로 기대된다.","In the context of C-ITS and autonomous driving, rapid detection of traffic incidents is crucial. This research addresses the limitations of traditional methods such as imaging and radar by developing a technology that utilizes acoustic information for incident detection. Specifically, we analyzed acoustic data to extract features and trained deep learning models—DNN, CNN, and RNN—to identify patterns associated with crash and skid. Through comparative analysis of the models' detection results, we identified the optimal algorithm for acoustic pattern recognition. This study demonstrates the potential of advanced deep learning algorithms and acoustic feature extraction in enhancing automated accident detection systems."
딥러닝 기법을 이용한 선삭 작업 분류,2024,"['Lathe Machining(선반가공)', 'Sound Signal(소리신호)', 'Spectrogram(스펙트로그램)', 'Deep Neural Network(DNN)(심층신경망)', 'Convolutional Neural Network(CNN)(컨볼루션신경망)', 'Job Classification(작업분류)']",,
비격식의 소규모 다범주 민원 자동분류 알고리즘 성능 비교 연구,2024,"['Automatic Classification', 'Small-Scale Informal Text', 'CNN', 'LSTM', 'Ko-BERT', 'Civil Complaint Data', '자동 분류', '소규모 비격식 텍스트', '민원']","머신러닝 기술의 발전으로 텍스트 자동 분류에 대한 연구가 증가하고 있다. 텍스트 자동 분류는 사전에 정의된 범주의 레이블을 각 데이터에 부여함으로써 대량의 데이터를 효율적으로 할당하는 것이다. 지금까지의 분류 연구는 자질 선정이 용이한 뉴스나 학술 데이터 및 SNS 데이터 등으로 대규모 데이터를 대상으로 많이 이루어졌다. 이와 달리 민원처럼 소규모의 비격식(informal) 텍스트를 대상으로, 다양한 주제 범위의 데이터를 다시 의미, 유형, 형식 등 세부 범주별로 분류하기는 어려운 일이다. 이에 본 연구의 목적은 소규모의 비격식 텍스트로 구성된 다범주 자동 분류에서 가장 성능이 좋은 알고리즘을 찾아내는 것이다. 이를 위해 먼저 2016년부터 2020년까지 부산시 민원 데이터를 수집하여 데이터 전처리를 실시하였다. 이후 민원의 특성 범주의 레이블을 정의하였고, 마지막으로 지도학습으로 각 분류 알고리즘의 성능을 비교 분석하였다. 실험결과 분류의 정확도는 CNN < LSTM < Ko-BERT의 순서로 나타났다. 따라서 비격식어이며 소규모인 다양한 주제에 대해 유형 및 특성별로 복합적 다범주 분류에서는 문서의 자질(feature)을 추출하는 것이 아니고, 시퀀스와 컨텍스트를 고려하여야함을 밝혀냈다. 본 연구의 학문적 공헌도로는 전통적인 분류기부터 딥러닝의 최신 알고리즘을 같은 실험 환경에서 비교 분석하여 알고리즘 간의 차이를 규명하였다는 점이다. 실무적으로는 본 연구에서 비격식(informal) 문서인 민원에 대한 분류기 성능 평가 결과는 향후 소규모의 SNS 데이터 및 다른 민원 등 다양한 주제이며 복잡한 범주에 대한 낮은 품질의 텍스트 데이터의 처리 및 분류에 활용될 수 있을 것이다.","Research Purpose: The purpose of this study is to identify the most effective algorithm for automatic multi-category classification of small-scale informal textResearch Methods: To achieve this, data preprocessing was conducted on municipal complaint data from 2016 to 2020 in Busan. Subsequently, labels for the characteristic categories of complaints were defined, followed by a comparative analysis of the performance of each classification algorithm using supervised learning.Results in Research: The experimental results showed that the classification accuracy followed the order of CNN < LSTM < Ko-BERT. Thus, it was revealed that for multi-category classification of diverse topics in informal and small-scale text, it is essential to consider sequences and contexts rather than extracting document features.Research Conclusion: The academic contribution of this study lies in comparing and analyzing algorithms from traditional classifiers to the latest deep learning algorithms under the same experimental conditions, thereby elucidating the differences between algorithms. From a practical standpoint, the evaluation of classification performance for informal documents such as complaints in this study could be utilized for processing and classifying low-quality text data of various topics, including small-scale SNS data and other complaints with complex categories, in the future."
수경재배 참외 인식을 위한 열화상 및 딥러닝의 적용 가능성 검토,2024,"['Thermal Imaging', 'Crop Monitoring', 'Image recognition', 'Faster R-CNN', 'YOLO v5']",,"Currently, many studies have applied a deep learning-based image recognition technology for solving labor shortages and other issues caused by rural aging. This study aimed to determine if thermal imaging could be used in a deep learning model to recognize oriental melon grown in a hydroponic system. To recognize oriental melon using thermal imaging, time-series thermal imaging was performed under sunny and cloudy weather conditions. Temperatures of oriental melon and canopy were extracted from thermal images. Differences between extracted temperatures according to weather conditions were then determined. It was found that thermal images acquired after 14:00 were suitable for stable recognition of oriental melon regardless of weather conditions. Based on this result, additional thermal images were acquired to train YOLO v5 and Faster R-CNN models. Acquired thermal images were trained with original and augmented data. Recognition performances of training models were compared with the best mAP (mean Average Precision). As a result, it was confirmed that both YOLO v5 and Faster R-CNN models achieved the best mAP@0.5 of 92% or more regardless of data augmentation. Data augmentation did not significantly affect the accuracy of either model. This might be because thermal images used to train models were acquired under restrictive conditions in a hydroponic greenhouse, which affected model generalization. Therefore, additional experiments under various conditions are necessary to improve generalization of the model in the future."
Fault diagnosis of linear transfer robot using XAI,2024,"['Linear motion robot', 'Transfer Learning', 'Fault diagnosis', 'Linear rail misalignment', 'CNN', 'XAI']",,"Artificial intelligence is crucial to manufacturing productivity. Understanding the difficulties in producing disruptions, especially in linear feed robot systems, is essential for efficient operations. These mechanical tools, essential for linear movements within systems, are prone to damage and degradation, especially in the LM guide, due to repetitive motions. We examine how explainable artificial intelligence (XAI) may diagnose wafer linear robot linear rail clearance and ball screw clearance anomalies. XAI helps diagnose problems and explain anomalies, enriching management and operational strategies. By interpreting the reasons for anomaly detection through visualizations such as Class Activation Maps (CAMs) using technologies like Grad-CAM, FG-CAM, and FFT-CAM, and comparing 1D-CNN with 2D-CNN, we illustrates the potential of XAI in enhancing diagnostic accuracy. The use of datasets from accelerometer and torque sensors in our experiments validates the high accuracy of the proposed method in binary and ternary classifications. This study exemplifies how XAI can elucidate deep learning models trained on industrial signals, offering a practical approach to understanding and applying AI in maintaining the integrity of critical components such as LM guides in linear feed robots."
마이크로컨트롤러와 지능이론 기반 유도전동기 고장진단,2024,"['fault diagnosis', 'induction motor', 'raspberry pi 5', 'vibration sensor', 'CNN', 'SVM', 'MNN', '.']","본 논문에서는 라즈베리파이 5와 지능이론(Intelligent theory)을 이용한 유도전동기 고장진단시스템을 제안하였다. 제안한 방법에서는 유도전동기 시뮬레이터를 통해 획득한 진동 데이터를 신경회로망 모델로 학습하였고 라즈베리파이 5를 사용하여 데이터 수집 및 진단 시스템 동작을 하나의 컨트롤러로 수행하였다. 또한 진단 결과를 터치스크린과 GUI(Graphical User Interface)를 통해 사용자가 직접 확인할 수 있다. 시스템의 성능은 유도전동기의 시뮬레이터에서 획득한 데이터를 사용하여 진단 실험 결과를 통해 시스템의 성능을 확인하였으며, CNN(Convolutional Neural Network), SVM(Support Vector Machine) 및 MNN(Multi-layer Neural Network)과의 고장진단 성능을 비교하였다.","In this paper, we propose a fault diagnosis system for induction motors using Raspberry Pi 5 and intelligent theory. The proposed method involves learning a neural network model with vibration data obtained from an induction motor simulator. The Raspberry Pi 5 is utilized to acquire data and operate the diagnosis system as a single controller. Additionally, users can directly check the diagnosis results through a touchscreen and Graphical User Interface(GUI). The performance of the system is verified through fault diagnostic experiments using data obtained from the induction motor simulator and compared with the diagnosis results by Convolutional Neural Network(CNN), Support Vector Machine(SVM) and Multi-layer Neural Network(MNN)."
비트맵 데이터 학습을 통한 딥러닝 기반의 메모리 수리 예측 기술 연구,2024,"['Memory Devices', 'RA Algorithm', 'Deep Learning', 'Convolutional Neural Networks', 'Electrical Die Sorting', '반도체 메모리', 'RA 알고리즘', '딥러닝', '합성곱 신경망(CNN)', '전기적 다이 분류']","반도체 메모리 기술의 지속적인 발전은 메모리 칩의 저장 용량을 크게 증가시켰지만, 동시에 제조 및 테스트 비용 증가, 소형화 및 고집적화로 인한 결함 발생 확률 증가와 같은 여러 문제를 초래했다. 이러한 문제를 효과적으로 해결하기 위해, 전기 다이 분류(EDS) 공정에서는 불량 셀을 예비 셀로 대체하는 RA(Redundancy Analysis) 알고리즘을 사용한다. 그러나 기존의 C 언어 기반 RA 프로세스는 칩의 복잡성이 증가함에 따라 테스트 시간이 길어지고 비용이 증가하는 단점이 있다. 본 논문에서는 이러한 한계를 극복하고자, 과거 수리 데이터를 기반으로 합성곱 신경망(CNN)을 활용해 실패 비트맵을 학습하는 딥러닝 기반 수리 예측 모델을 제시하고, RA 알고리즘의 딥러닝 적용 가능성을 확인하였다.","The continuous advancement of semiconductor memory technology has significantly increased memory chip capacity but has also introduced new challenges, including higher manufacturing and testing costs and a greater likelihood of defects due to miniaturization and high integration. To address these challenges, the Electrical Die Sorting (EDS) process employs a Redundancy Analysis (RA) algorithm to replace faulty cells with spare ones. However, as chip complexity increases, the traditional RA process, based on C language, becomes less efficient, resulting in longer testing times and higher costs. This paper proposes a deep learning-based repair prediction model that utilizes convolutional neural networks (CNN) to learn from historical repair data and failure bitmaps, thereby improving the efficiency of the RA process. The study confirms the applicability of deep learning to RA algorithms, demonstrating its potential to overcome the limitations of traditional methods."
노지 채소 경작에서 최적의 재배전략과 생구무게의 예측,2024,"['Prediction of Bulb Weight', 'growth characteristics', 'vegetation index', 'non-parametric regression model', 'random forest regression model', '1D-CNN + Attention based BiLSTM', '생구무게 예측', '생육특성', '식생지수', '비모수 함수열 동시 회귀모형', '랜덤포레스트 회귀모형', '1D-CNN + Attention based BiLSTM']",,"Crops grown in open fields are greatly affected by various environmental factors such as climate, temperature changes and precipitation which can significantly influence crop yields depending on cultivation methods and environmental conditions. Therefore, this study proposes cultivation strategies to maximize the yield of onions and garlic along with methods for predicting bulb weight.An experimental site was established at the Allium Crop Research Institute in Muan, where growth characteristics were manually measured, and vegetation indices were acquired using multispectral imaging, along with corresponding bulb weights for both onions and garlic at regular intervals. To predict bulb weight, three predictive models were applied: NFCRM, RFRM, and 1D-CNN+Attention BiLSTM. Comparative analysis of predictive performance showed that NFCRM outperformed the other models, RFRM and 1DCABL, in predicting of the bulb weight of both onions and garlic."
딥러닝 신경망 모델과 SFM 기술 기반으로 구축된 3차원 디지털 트윈을 이용한 구조물의 기울기 자동 산출,2024,"['오브젝트 추출', '3차원 모델 구축', '2차원 이미지', '통신주 안전', 'Segmentation', '3D model construction', 'Digital twin', 'Mask R-CNN', 'SFM']","인공지능과 융합된 디지털 트윈 기술은 국방 분야를 비롯한 다양한 산업 전반에 시뮬레이션 도구로서 그 활용도가 증대되고 있다. 다양한 객체로 구성된 3차원 모델을 신속하고 값싸게 구축하는 기술은 이 분야에서 매우 중요하며, 여러 장의 2차원 이미지를 통하여 3차원의 모델을 자동으로 구축하는 연구가 진행되어 왔다. 본 논문에서 단순한 사진 촬영을 통하여 구조물의 기울기를 산출하기 위한 3차원 모델 자동 구축방법에 관하여 다루었다. 해당 기울기 산출의 대상 구조물의 일례로 통신주를 선택하여 적용하였다. 촬영된 2차원 이미지로부터 통신주를 분리해내기 위하여 Mask R-CNN을 통한 통신주 인지 및 오브젝트 추출 모델을 개발하였으며, 각 오브젝트들로 구성된 3차원 모델 구축하기 위하여 SFM 기술 기반 알고리즘을 제안하였다. 최종적으로 추출된 2차원 이미지와 3차원 데이터로부터 통신주와 지면과 이루는 각도를 자동으로 산출하였으며, 현장 측정 데이터와 비교하였다.","Digital twin technology combined with artificial intelligence is increasingly being used as a simulation tool across various industries, including the defense field. Technology for quick and inexpensive construction of 3D models composed of various objects is very important in this field, and corresponding research has been carried out focused on automatic 3D model construction based on multiple 2D images. In this paper, we discuss a method for automatic construction of 3D model to calculate the inclination angle of the structure using simply taken 2D photographs. As an example of inclination angle calculation, we chose a telecom pole for application. In order to extract telecom poles from captured 2D images, we propose a pole recognition and segmentation model based on Mask R-CNN, and suggest a algorithm based on SFM technology to build a corresponding 3D model. In addition, the inclination angle between the pole and the ground surface was automatically estimated from the extracted pole image and 3D data. Finally the calculated values from the models are compared with the data measured in the field."
Improved Deep Learning Approach For Underwater Salient Object Detection Using Spectral Residual and Fuzzy C-Means Clustering,2024,['Under water  · Object detection  · Spectral residual (SR)  · Fuzzy c-means clustering (FCMC)  · Convolutional neural network (CNN)'],,"The novel analysis that the underwater salient detection is the act of recognizing and emphasizing prominent and visually distinctive elements or objects within underwater images or fi lms, assisting in tasks like marine research, underwater navigation, and resource prospecting. In this paper, we present a novel fuzzy c-means clusteringintegrated convolutional neural network (FCMC-CNN) for analysing the accuracy and robustness of saliency detection in diffi cult underwater situations.To enhance the object detectionperformance below the water’s surface, this method involves the application of both highlevel CNN representations and low-level parameters. Spectral residual analysis (SR) approachand the proposed method are used for precisely locating salient objects in underwater photos. Although the diffi culties imposed through variable spectral properties and low light conditions, this method requires to increase the accuracy of underwater prominent item detection. To gauge how well the suggested algorithm works, we simulate experiments using Python software. We assess the experimental results in terms of PSNR (44.2658%), SSIM (0.7726), FSIM (0.8369), and Average time (1.0852).This method demonstrated signifi cant improvements in accurately recognizing underwater objects, enhancing the performance in detecting objects under water and possibly obtaining greater accuracy rates."
합성곱 신경망 기반 화재 인식 모델 최적화 연구: Layer Importance Evaluation 기반 접근법,2024,"['레이어 중요도 평가', '전이 학습 모델', '합성곱 신경망 최적화', '실시간 화재 감지', '기여도', 'Layer Importance Evaluation', 'Transfer Learning Model', 'CNN Optimization', 'Real-Time Fire Detection', 'Contribution']","본 연구는 Layer Importance Evaluation을 통해 도출된 화재 감지에 최적화된 딥러닝 아키텍처를 제안한다. 기존의 합성곱 신경망(Convolutional Neural Network, CNN) 기반 화재 감지 시스템의 불필요한 복잡성과 연산을 초래하는 문제점을 해결하기 위해, Layer Importance Evaluation 기법을 통해 가중치 및 활성화 값에 근거한 모델의 내부 레이어의 동작을 분석하고, 화재 감지에 기여도가 높은 레이어를 식별한 뒤, 식별한 레이어만으로 모델을 재구성하여, 기존 모델과의 성능 지표를 비교 분석하였다. Xception, VGG19, ResNet, EfficientNetB5 등 네 가지 전이 학습 모델을 사용하여 화재 데이터를 학습시킨 후, Layer Importance Evaluation기법을 적용하여 각 레이어의 가중치와 활성화 값을 분석한 뒤 기여도가 가장 높은 상위 랭크 레이어들을 선별하여 새로운 모델을 구축하였다. 연구 결과, 구현된 아키텍처는 기존 모델 대비 약 80% 가량 경량화 된 파라미터로도 동등한 성능을 유지하며, 약 3~5배가량 신속한 학습 속도를 가지면서도 기존의 복잡한 전이학습 모델에 비해 정확도, 손실, 혼동행렬 지표에서 동등한 성능을 출력함으로써, 화재 감시 장비의 효율성을 높이는 데 기여할 수 있음을 확인하였다.","This study proposes a deep learning architecture optimized for fire detection derived through Layer Importance Evaluation. In order to solve the problem of unnecessary complexity and operation of the existing Convolutional Neural Network (CNN)-based fire detection system, the operation of the inner layer of the model based on the weight and activation values was analyzed through the Layer Importance Evaluation technique, the layer with a high contribution to fire detection was identified, and the model was reconstructed only with the identified layer, and the performance indicators were compared and analyzed with the existing model. After learning the fire data using four transfer learning models: Xception, VGG19, ResNet, and EfficientNetB5, the Layer Importance Evaluation technique was applied to analyze the weight and activation value of each layer, and then a new model was constructed by selecting the top rank layers with the highest contribution. As a result of the study, it was confirmed that the implemented architecture maintains the same performance with parameters that are about 80% lighter than the existing model, and can contribute to increasing the efficiency of fire monitoring equipment by outputting the same performance in accuracy, loss, and confusion matrix indicators compared to conventional complex transfer learning models while having a learning speed of about 3 to 5 times faster."
Development of an Optimal Convolutional Neural Network Backbone Model for Personalized Rice Consumption Monitoring in Institutional Food Service using Feature Extraction,2024,"['deep learning', 'neural networks', 'computer', 'rice', 'food services']",,"This study aims to develop a deep learning model to monitor rice serving amounts in institutional foodservice, enhancing personalized nutrition management. The goal is to identify the best convolutional neural network (CNN) for detecting rice quantities on serving trays, addressing balanced dietary intake challenges. Both a vanilla CNN and 12 pre-trained CNNs were tested, using features extracted from images of varying rice quantities on white trays. Configurations included optimizers, image generation, dropout, feature extraction, and fine-tuning, with top-1 validation accuracy as the evaluation metric. The vanilla CNN achieved 60% top-1 validation accuracy, while pre-trained CNNs significantly improved performance, reaching up to 90% accuracy. MobileNetV2, suitable for mobile devices, achieved a minimum 76% accuracy. These results suggest the model can effectively monitor rice servings, with potential for improvement through ongoing data collection and training. This development represents a significant advancement in personalized nutrition management, with high validation accuracy indicating its potential utility in dietary management. Continuous improvement based on expanding datasets promises enhanced precision and reliability, contributing to better health outcomes."
딥러닝을 이용한 액티그래피 데이터에서의 수면장애 예측,2024,"['Sleep-wake disorder', 'Deep learning', 'Actigraphy.']",,"Objectives: The aim of this study was to classify polysomnography (PSG)-based sleep disorders using actigraphy data using a convolutional neural network (CNN).Methods: Actigraphy data, PSG data, and diagnoses were obtained from 214 patients from a single-center sleep clinic. Patients diagnosed with circadian sleep disorders, narcolepsy, or periodic limb movement disorders were excluded. From the actigraphy data, three types of data were selected from the first 5 days, namely, sleep-wake status, activity count, and light exposure per epoch. The data were processed into a two-dimensional array with four instances, namely, 24-hour full-day data and data for 6, 8, and 10 hours timepoints after sleep onset, and then analyzed. Using a CNN, we attempted to classify the processed data into PSG-based diagnoses.Results: Overfitting of the training data was observed. The CNN showed near-perfect accuracy on the test data, but failed to classify the validation data (area under the curve: 24-hour full-day data: 0.6031, 6 hours after sleep onset: 0.5148, 8 hours: 0.6122, and 10 hours: 0.5769).Conclusions: The lack and inaccuracy of data were responsible for the results. A higher sampling rate and additional ancillary data, such as PSG or heart rate variability data, are necessary for accurate classification. Additionally, alternative approaches to machine learning, such as transformers, should be considered in future studies."
An automated quality assurance system with deep learning for small cube-ball phantom localization in noisy megavoltage images,2024,['Radiation oncology  · Automated QA system  · Machine learning  · Image processing  · Medical physics'],,"To enhance effi ciency and minimize errors, we automated the quality assurance (QA) process in radiation oncology, specifi - cally laser localization. Additionally, we explored the use of a convolutional neural network (CNN) to enhance the detection of small cube-ball phantoms in noisy images. Laser localizations were measured manually on the acquired images. To automate the QA workfl ow, we developed a Linux server equipped with database and web servers. Digital Imaging and Communications in Medicine (DICOM) fi les were retrieved 40 times for 10 linear accelerators (LINACs). The center of the cube-ball phantoms was estimated through Gaussian fi tting. We applied CNN using 6,968 stored results to improve the estimation performance in noisy megavoltage (MV) images. Subsequently, both analysis time and accuracy were compared. Our hospital has been employing the automated QA system since 2018, notably reducing the time for laser localization from 30 min to just 1 min. The average and standard deviation (SD) of inter-observer variability in the X- and Y-axes were 0.06 ± 0.01 mm and 0.05 ± 0.01 mm, respectively. Absolute diff erences between manual assessment and Gaussian fi tting presented average and SD values of 0.40 ± 0.51 mm and 0.23 ± 0.24 mm, respectively. In contrast, absolute diff erences between manual assessment and CNN presented average and SD values of 0.12 ± 0.10 mm and 0.11 ± 0.09 mm, respectively. Overall, the automated QA system signifi cantly hastened procedures in our large hospital and improved the estimation of the cube-ball phantom’s position in noisy images through deep learning."
연속학습을 활용한 경량 온-디바이스 AI 기반 실시간 기계 결함 진단 시스템 설계 및 구현,2024,"['Continual Learning', 'Deep Learning', 'Machine Fault Diagnosis', 'On-Device AI']",,"Although on-device artificial intelligence (AI) has gained attention to diagnosing machine faults in real time, most previous studies did not consider the model retraining and redeployment processes that must be performed in real-world industrial environments. Our study addresses this challenge by proposing an on-device AI-based real-time machine fault diagnosis system that utilizes continual learning. Our proposed system includes a lightweight convolutional neural network (CNN) model, a continual learning algorithm, and a real-time monitoring service. First, we developed a lightweight 1D CNN model to reduce the cost of model deployment and enable real-time inference on the target edge device with limited computing resources. We then compared the performance of five continual learning algorithms with three public bearing fault datasets and selected the most effective algorithm for our system. Finally, we implemented a real-time monitoring service using an open-source data visualization framework. In the performance comparison results between continual learning algorithms, we found that the replay-based algorithms outperformed the regularization-based algorithms, and the experience replay (ER) algorithm had the best diagnostic accuracy. We further tuned the number and length of data samples used for a memory buffer of the ER algorithm to maximize its performance. We confirmed that the performance of the ER algorithm becomes higher when a longer data length is used. Consequently, the proposed system showed an accuracy of 98.7%, while only 16.5% of the previous data was stored in memory buffer. Our lightweight CNN model was also able to diagnose a fault type of one data sample within 3.76 ms on the Raspberry Pi 4B device."
인공지능 알고리즘을 적용한 한국프로야구 경기결과의 선행적 예측,2024,"['Artificial intelligence', 'Game result prediction', 'Korea Professional Baseball League', 'RE24', 'Sports analytics', '인공지능', '경기결과 예측', '한국프로야구', 'RE24', '스포츠 애널리틱스']","본 연구는 인공지능 알고리즘을 적용하여 한국프로야구 경기의 승패를 선행적으로 예측하기 위한 방법론을 제시하기 위해실시되었다. 이를 위해 한국프로야구의 경기기록을 비롯하여 다양한 경기력 지표들이 체계적으로 구축된 스탯티즈 홈페이지에 있는 총 11시즌(2013∼2023) 간 펼쳐진 7,744경기의 팀 분석단위 빅데이터를 수집하고 전처리하였다. 본 연구에서는 이를 기반으로 Python 3.11.5을 활용하여 5가지 인공지능 알고리즘으로 구성된 딥러닝 기반 1D-CNN과 다층퍼셉트론(Multilayer Perceptron, MLP)을 포함하여 머신러닝 알고리즘인 로지스틱 회귀(Logistic Regression), 서포트 벡터 머신(SVM), 그래디언트 부스팅(GBM)으로 변수를 선택하고 경기결과를 예측하였다. 본 연구의 실증결과, 한국프로야구 경기를 선행적으로 예측하는 데 5가지 변수(홈/원정 여부, 타격 RE24, 상대 타자 RE24, 투수 RE24, 상대 투수 RE24)로 구성될 수 있으며, 로지스틱회귀 알고리즘으로 경기결과를 예측하였을 때 53.71%로 가장 높은 예측력이 나타났다. 아울러, 무승부 경기를 제거하고 1DCNN을 적용하여 한국프로야구 경기를 선행적으로 예측할 때 56.10%로 가장 높은 경기결과의 예측력을 보였다. 본 연구는한국프로야구 경기를 선행적으로 예측한 최초의 연구로 그 학술적⋅실무적 의의를 지닌다.","This study was conducted to propose a methodology for proactively predicting the outcomes of Korean professional baseball games by applying artificial intelligence algorithms. For the assessment, we collected and preprocessed big data comprising 7,744 games structured on the STATIZ website, a systematic database of various performance indicators including game records of the Korean Professional Baseball League, consisting of 11 seasons (2013-2023). This study utilized Python 3.11.5 to select variables and predict game results using machine learning algorithms such as Logistic Regression, Support Vector Machine (SVM), Gradient Boosting (GBM), and deep learning-based 1D-CNN and Multi-layer Perceptron (MLP). The empirical results of this study determine that five variables (home/away status, batting RE24, opposing batter RE24, pitching RE24, and opposing pitcher RE24) can be used to predict the outcome of a Korean professional baseball game in advance, and the highest prediction accuracy of 53.71% was found when predicting the outcome of the game with the logistic regression algorithm. In addition, the highest prediction accuracy of 56.10% was obtained when the draw games were removed and 1D-CNN was applied to predict the outcome of Korean professional baseball games in advance. This study is the first study to predict Korean professional baseball games in advance, which has academic and practical significance."
AI 기반 산업용 커넥터 핀의 미삽 상태 검출에 관한 연구,2024,"['Convolutional Neural Networks(합성곱 신경망)', 'Connector(커넥터)', 'Defects Detection(결함 검출)', '데이터 증강Data Augmentation(데이터 증강)']",,"Connectors are crucial in electronic systems for ensuring the transmission of electrical signals and power, particularly in the automotive, aerospace, and telecommunications industries. Defective connectors can lead to significant system failure, making early detection vital. Manual inspections are inefficient and inaccurate, necessitating automated methods. In this study, we developed an automated defect detection system using deep learning. Specifically convolutional neural networks (CNN) with TensorFlow and Keras were used to improve detection efficiency and accuracy. A dataset of 1,020 connector images was created from a 30-second video. The dataset was then classified into normal and defective categories, augmented for diversity, and converted to grayscale. The CNN model, trained over 20 epochs, achieved a validation accuracy of 1.00 and training accuracy of 0.996. Performance evaluations demonstrated a real-time prediction accuracy of 99.25% at a processing speed of up to 72,000 classifications per hour. This study demonstrates the effectiveness of the CNN model in automated defect detection, significantly enhancing the productivity and quality control for manufacturers."
한국인 구음장애 환자의 발화 데이터 기반 질병 예측을 위한 모바일 애플리케이션 개발,2024,"['Dysarthria', 'Deep learning', 'Diagnosis', 'Mobile application']",,"Communication with others plays an important role in human social interaction and information exchange in modern society. However, some individuals have difficulty in communicating due to dysarthria. Therefore, it is necessary to develop effective diagnostic techniques for early treatment of the dysarthria. In the present study, we propose a mobile device-based methodology that enables to automatically classify dysarthria type. The light-weight CNN model was trained by using the open audio dataset of Korean patients with dysarthria. The trained CNN model can successfully classify dysarthria into related subtype disease with 78.8%~96.6% accuracy. In addition, the user-friendly mobile application was also developed based on the trained CNN model. Users can easily record their voices according to the selected inspection type (e.g. word, sentence, paragraph, and semi-free speech) and evaluate the recorded voice data through their mobile device and the developed mobile application. This proposed technique would be helpful for personal management of dysarthria and decision making in clinic."
무인항공기 영상과 인공지능을 활용한 농업지역 야적퇴비 탐지,2024,"['Unmanned aerial vehicle', 'Instance segmentation', 'OBIA', 'Remote sensing', 'Non-point pollution sources', '.']",,"Non-point sources of water pollution, particularly in agricultural areas, are increasingly concerning. Among these, compost piles are receiving heightened attention as a source of pollution. This study utilized unmanned aerial vehicle (UAV) imagery for the efficient detection and management of compost. The basic data consisted of multispectral UAV imagery, including Red, Green, Blue, Rededge, and NIR bands, as well as the Normalized Difference Vegetation Index (NDVI). The analysis compared object-based image analysis with a random forest classifier (OBIA-RF) and deep learning-based instance segmentation using Mask R-CNN. In the accuracy evaluation based on Intersection Over Union (IoU) 75 %, OBIA-RF was analyzed with precision of 0.4356, recall of 0.7273, and F1 score of 0.5128, while Mask R-CNN was analyzed with precision of 0.6923, recall of 0.9818, and F1 score of 0.8120. While OBIA is useful, it shows limitations in handling spatial and spectral data, leading to partial misclassifications within the compost boundaries. Mask R-CNN, in contrast, effectively maintains spatial and contextual data, ensuring more precise identification and delineation of compost piles. This research underscores the potential of UAV-based remote sensing combined with advanced image analysis techniques in environmental management. These methods offer a more efficient and comprehensive alternative to conventional field surveys for monitoring agricultural non-point source pollution."
Prediction Model of Spinal Osteoporosis Using Lumbar Spine X-Ray from Transfer Learning Deep Convolutional Neural Networks,2024,"['Deep learning', 'Lumbar vertebrae', 'Osteoporosis', 'Spine', 'X-rays']",,"Objective: Osteoporosis is highly prevalent among older adults and women. This condition leads to a deterioration in bone mineral density and microarchitecture, significantly increasing the risk of fractures. Additionally, osteoporosis commonly results in complications such as screw loosening and non-union during spinal surgery. Deep-learning algorithms have now achieved an accuracy comparable to the current human margin of error. Therefore, this study explored the potential of using transfer learning in deep learning algorithms to predict, diagnose, and screen for osteoporosis using commonly obtained sagittal spine X-rays from patients with spinal conditions.Methods: We retrospectively evaluated 2,300 consecutive patients who underwent dual energy X-ray absorptiometry (DXA) and lumbar sagittal plain X-ray exams between 2013 and 2021. The exclusion criteria included: (1) a gap of more than 1 year between the DXA and X-ray exams; (2) vertebrae that had undergone vertebroplasty; (3) lack of spine anterior-posterior DXA; and (4) images that were unassessable. Ultimately, 256 patients (images) were included in the study. Transfer learning was applied using convolutional neural network (CNN) techniques, specifically visual geometry group (VGG) 16, VGG 19, ResNet50, and Xception.Results: The most accurate CNN model in the training group was ResNet50, with an accuracy of 0.95. ResNet50 showed the best performance, with an accuracy of 0.82, precision of 0.80, recall of 0.86, and F1-score of 0.83. Additionally, its area under the curve (0.76) was higher than that other CNN models. The confusion matrix for ResNet50’s performance displayed the outcomes for images predicted as osteoporosis (n=12) among the test data osteoporosis images (n=14)Conclusion: Artificial intelligence (AI) technology employing deep learning techniques is significantly nearing human capabilities in the role of diagnostic assistance. The diagnosis of osteoporosis using bone mineral density is expected to evolve into a comprehensive diagnostic aid or decision-making tool with the integration of AI in the future."
딥러닝과 스펙트로그램을 이용한 사람과 동물 분류에 관한 연구,2024,"['CNN', 'Micro-Doppler', 'doppler radar', 'bipedal movement', 'quadrupedal movement']",,"In this paper, we utilize Doppler radar to measure quadrupedal and bipedal movements, which are methods for distinguishing between animals and humans. Through these measurements, we obtain Dynamic Radar Cross Section(DRCS) data and apply Short-Time Fourier Transform(STFT) to generate spectrogram images from the acquired data. We train a Convolutional Neural Network(CNN) classifier using these spectrogram images and evaluate its classification performance. We obtain 502 samples of bipedal movement and 515 samples of quadrupedal movement. As it is difficult to directly measure quadrupedal movements from actual animals, we employ a quadrupedal movement imitator and measure these movements using it. We divide the data into training and test sets in a 7:3 ratio to check the classification performance. As a result, the classification accuracy is 93.75%. Through this study, we confirm the feasibility of distinguishing between animal and human gait based on spectrogram images."
데이터 프리패치를 이용한 하드웨어 가속기의 병목 현상 해결,2024,"['HW Accelerator', 'CNN', 'Bottleneck', 'Data Prefetch', 'Dual Buffer', 'RTL Simulation', '하드웨어 가속기', 'CNN', '병목현상', '데이터 프리패치', '듀얼 버퍼', 'RTL 시뮬레이션']","최근 다양한 분야에서 딥러닝이 사용되면서, 더 빠르고 정확한 결과를 내는 딥러닝이 더욱 중요해졌다. 이를 위해서는 많은 양의 저장 공간이 필요하고, 대용량 연산을 진행해야 한다. 이에 따라 여러 연구는 빠르고 정확하게 연산 처리가 가능한 하드웨어 가속기를 이용한다. 하지만 하드웨어 가속기는 CPU와 하드웨어 사이를 이동하면서 병목현상이 발생하게 된다. 따라서 본 논문에서는 하드웨어 가속기의 병목현상을 효율적으로 줄일 수 있는 데이터 프리패치 전략을 제안한다. 데이터 프리패치 전략의 핵심 아이디어는 Matrix Multiplication Unit(MMU)가 연산을 진행하는 동안 다음 연산에 필요한 데이터를 예측하여 로컬 메모리로 올려 병목현상을 줄인다. 또한, 이 전략은 듀얼 버퍼를 이용하여 읽고 쓰는 두 가지 동작을 동시에 진행하여 처리율을 높인다. 이를 통해 데이터 전송의 지연시간 및 실행 시간을 감소시킨다. 시뮬레이션을 통해 듀얼 버퍼를 이용한 병렬 프로세싱과 데이터 프리패치를 이용한 메모리 간 병목현상을 최대한 감소시켜 하드웨어 가속기의 성능이 24% 향상함을 알 수 있다.","Deep learning with faster and more accurate results requires large amounts of storage space and large computations. Accordingly, many studies are using hardware accelerators for quick and accurate calculations. However, the performance bottleneck is due to data movement between the hardware accelerators and the CPU. In this paper, we propose a data prefetch strategy that can efficiently reduce such operational bottlenecks. The core idea of the data prefetch strategy is to predict the data needed for the next task and upload it to local memory while the hardware accelerator (Matrix Multiplication Unit, MMU) performs a task. This strategy can be enhanced by using a dual buffer to perform read and write operations simultaneously. This reduces latency and execution time of data transfer. Through simulations, we demonstrate a 24% improvement in the performance of hardware accelerators by maximizing parallel processing with dual buffers and bottlenecks between memories with data prefetch."
YOLO 성능 향상을 위한 데이터 증강기법,2024,"['데이터 증강기법', '딥러닝', '기계학습', '인공지능', '복사-붙여넣기(증강)', 'Data augmentation', 'deep learning', 'machine learning', 'artificial intelligence', 'Copy-paste (augmentation)']","컴퓨터 비전은 CNN, 트랜스포머 등과 같은 모델의 발전으로 여러 분야에서 좋은 성과를 이루었다. 하지만, 모델을 학습하기 위해서는 다양하고 많은 데이터가 필요하다. 이러한 학습데이터를 얻기 위해서는 많은 시간과 노력이 필요 로 한다. 이러한 높은 비용으로 인해 데이터 부족이나 데이터 불균형이 발생하게 된다. 데이터 증강기법은 이러한 문 제를 해결하기 위한 좋은 방법이다. 본 논문에서는 객체 인식 모델을 위한 데이터 증강기법 중에서(복사-붙여넣기) Copy-Paste를 활용한 데이터 증강기법을 연구한다. 이전 연구에서는 인스턴스 영상 분할 객체를 붙이거나 시각적 인 맥락을 바탕으로 객체를 붙인다. 하지만 인스턴스 영상 분할 객체를 사용하지 않고 단순한 방법인 바운딩 박스 (Bounding Box)를 그대로 기존의 객체 위치에 같은 크기로 붙이거나 무작위로 붙이는 것도 모델의 성능이 향상된 다는 것을 발견했다. 또한, 객체에서 SAM(Segment Anything Model) 모델을 활용하여 객체의 인스턴스를 추출 하여 붙이는 방법을 제안한다. 그리고 붙이는 객체에 데이터 증강기법을 적용하여 데이터를 증강하는 방법을 추가실 험으로 보여준다. 또한, 기존의 객체가 붙여지는 객체에 의해 가려지는 것을 막기 위해 객체를 붙이고 기존 이미지에 있는 객체를 덮어쓴 방법도 적용하였다. 본 논문에서 객체 인식 모델 Yolo v5를 Pascal VOC12 데이터셋으로만 학 습한 결과보다 제안한 데이터 증강기법을 활용해서 학습한 결과가 더 높은 성능을 보여주는 것을 확인하였다.","Computer vision has shown excellent performance in various fields, thanks to the advancements in models like CNN and Transformers. However, training these models requires diverse and abundant data, which demands a significant amount of time and effort. The high cost associated with acquiring such training data often leads to issues like data scarcity and data imbalance. Data augmentation techniques provide effective solutions to address these challenges. In this paper, we focus on researching data augmentation techniques for object recognition models, specifically leveraging the Copy-Paste(Augmentation) technique. The previous researches involved attaching objects based on instance segmentation or visual context. However, we have discovered that using a straightforward approach, such as attaching bounding boxes of the same size to the existing object locations or randomly attaching objects, enhances the model's performance significantly. Furthermore, we propose a method of using the SAM(Segment Anything Model) to extract object instances from images and attaching them. We demonstrate additional experiments applying data augmentation techniques to the attached objects. To prevent existing objects in the image from occluded by the attached objects, we present a method of overlaying them into the image with attached objects. In this paper, we train the object recognition model using YOLO(You Only Look Once) v5 on the Pascal VOC12 dataset, and show better performance when utilizing the proposed data augmentation techniques."
Cloud IoT-Oriented Neural Network-Based Taekwondo  Teaching Scheme,2024,"['Taekwondo', 'Poomsae', 'Cloud IoT', 'CNN', 'Mogrifier LSTM.']",,"As Taekwondo is widely accepted, there is a rapid increase in Taekwondo learners. Traditional Taekwondo teaching mode is challenging to meet the increasing educational needs. In Taekwondo teaching, in addition to teaching the basic skills of combat, Taekwondo Poomsae teaching is also required. The quality of Taekwondo Poomsae learning is critical to the overall strength of Taekwondo. For a long time, the judgment of the quality of Poomsae action has relied on the manual evaluation of teachers, which could be more conducive to forming an objective and accurate quality score. Therefore, it is necessary to introduce in-depth learning to find new solutions to these problems. First, a multi-sensor data fusion method is proposed to collect Taekwondo Poomsae action. Then, a Taekwondo Poomsae expertise integrated multiview feature extraction method is proposed. Finally, Convolutional Neural Network (CNN)-Mogrifier Long Short-Term Memory (LSTM) is proposed to train the generated Taekwondo Poomsae action scoring model, identifying whether Taekwondo Poomsae action meets the standard and improve Taekwondo teaching. The effect test of Taekwondo Poomsae action intelligent evaluation shows that the results of the proposed method follow the evaluation given by the teachers, and the discrimination of the scores is moderate, which indicates that the proposed method has good Taekwondo Poomsae action quality evaluation ability. Furthermore, the experimental results show that CNNMogrifier LSTM achieves high recognition accuracy of Taekwondo Poomsae, gives comprehensive evaluation and improvement suggestions for action completion quality, breaks away from the restrictions of teachers and venues, and realizes automatic and smart Taekwondo teaching."
Phase-Shifted DMRS-Aided Automatic Modulation Classification for PDSCH in 5G New Radio,2024,"['AMC', 'PDSCH', '5G NR', 'CNN', 'DMRS']",,"In this letter, a novel automatic modulation classification (AMC) scheme is developed for physical downlink shared channel (PDSCH) in 5G New Radio (NR). We design a convolutional neural network (CNN) to classify modulation types of the received PDSCH. To improve the classification accuracy, an enhanced demodulation reference signal (DMRS) structure is proposed where the phase of the DMRS is shifted depending on the modulation types. Simulation results verify that the proposed AMC scheme achieves 31.5% gain compared to the legacy scheme in terms of classification accuracy."
자생 매미 음성 분류를 위한 딥러닝 접근 : 주파수 변화 분석과 모델 최적화,2024,"['Artificial Intelligence', 'Deep-learning', 'CNN', 'Classification', 'Spectogram']","본 논문은 한국에서 서식하는 매미과 속인 말매미 등 12종의 국내 자생종 매미의 음성 데이터를 활용하여 딥러닝기법을 통해 매미 종을 분류하는 새로운 접근 방식을 제시하였다. 표준화된 데이터 전처리 및 시간에 따른 주파수 변화를 시각적으로 나타내는 그래픽 표현방식인 스펙트로그램(Spectrogram)의 적용을 통해 주파수 변화와 시간적 변화를동시에 시각화하여 데이터의 특성을 파악하고 활용하며 딥러닝 모델인 ResNet34, ResNet50, AlexNet 모델을 적용하였다. 드롭아웃 기법을 적용하여 과적합(Overfitting)을 방지하며, 다양한 학습률(Learning Rates)을 적용하여 모델의학습 및 검증 과정을 최적화하였다. 이러한 접근을 통해 98% 이상의 높은 정확도로 매미 종을 식별을 검증하였다. 본연구는 인공지능 기술인 CNN(Convolutional Neural Network)를 활용하여 생물 다양성 보존과 종 식별의 정확성을높이기 위해 수행하였으며, 음성 데이터 기반의 딥러닝 시스템이 생태학적 연구와 환경 모니터링에 크게 기여할 수 있음을 시사한다. 나아가 본 연구는 생태계 보존 및 관리에 중요한 도구로 활용될 수 있음을 보여주며, 인공지능 기술과 생물분류학을 결합하여 향후 생물 다양성 연구와 환경 보호를 위한 새로운 방법을 제시할 수 있다","This paper presents a novel approach to classifying cicada species by using deep learning techniques that utilize acoustic data of 12 cicada species found in Korea, including Meimuna opalifera.Standardized data preprocessing and the application of spectrograms, which visually represent frequency changes over time, were used to simultaneously visualize both frequency and temporal changes, allowing for species identification from data characteristics. Deep learning models such as ResNet34, ResNet50, and AlexNet were applied. Dropout techniques were employed to prevent overfitting, and various learning rates were applied to optimize the training and validation processes of the models. The approach successfully identified cicada species with an accuracy of over 98%. This study enhances the accuracy of species identification and conservation of biodiversity by using the artificial intelligence technology of a convolutional neural network. It suggests that deep learning systems based on acoustic data can significantly contribute to ecological research and environmental monitoring. Furthermore, this study has the potential for use as an essential tool in ecosystem conservation and management, combining AI and taxonomy to propose new methods for future biodiversity research and environmental protection."
실시간 측정데이터 기반의 디스크커터 마모상태 판별 딥러닝 알고리즘 개발,2024,"['Disc cutter wear', 'Deep learning', 'CNN', 'Utility cable tunnel', 'Shield TBM', '디스크커터 마모', '딥러닝 기법', '합성곱신경망', '전력구 터널', '쉴드TBM']","송전선로 지중화 사업의 일환인 전력구 터널은 쉴드TBM 공법에 의해 건설된다. 쉴드TBM 구성요소 중 디스크커터는 암반을 파쇄하는 중요한 역할을 수행한다. 마모한계에 도달하거나 편마모와 같은 파손이 발생함에 따라 적절한 교체가 이루어져야 효율적인 터널 공사가 가능하다. 본 연구에서는 실시간으로 측정된 디스크커터의 마모량과 회전수를 기반으로 디스크커터의 마모상태를 판별하기 위한 딥러닝 알고리즘 개발을 수행하였다. 실대형 굴진시험 결과를 통해 디스크 커터의 마모상태에 따라 측정데이터가 상이하게 획득되는 것을 확인하였다. 합성곱신경망 모델을 기반으로 실시간 측정 데이터를 활용하여 디스크커터의 마모특성을 판별할 수 있는 알고리즘을 개발하였다. 합성곱신경망의 필터를 통해 데이터의 분포 특성을 학습할 수 있고, 이러한 패턴 특징을 통해 균등마모와 편마모를 분류할 수 있는 모델의 성능을 확인하였다.","The power cable tunnels which are part of the underground transmission line project, are constructed using the shield TBM method. The disc cutter among the shield TBM components plays an important role in breaking rock mass. Efficient tunnel construction is possible only when appropriate replacement occurs as the wear limit is reached or damage such as uneven wear occurs. A study was conducted to determine the wear conditions of disc cutter using a deep learning algorithm based on real-time measurement data of wear and rotation speed. Based on the results of full-scaled tunnelling tests, it was confirmed that measurement data was obtained differently depending on the wear conditions of disc cutter. Using real-time measurement data, an algorithm was developed to determine disc cutter wear characteristics based on a convolutional neural network model. Distributional patterns of data can be learned through CNN filters, and the performance of the model that can classify uniform wear and uneven wear through these pattern features."
경량화 MobileNet을 활용한 축산 데이터 음성 분석,2024,"['Livestock Environment', 'Smart Farm', 'Audio Analysis', 'CNN(Convolution Neural Network)', '축산환경', '스마트팜', '음성 분석', 'CNN(Convolution Neural Network)']","돼지는 꿀꿀거림, 기침, 비명과 같은 다양한 소리로 환경에 대한 반응과 건강 상태를 나타낸다. 돼지 음성의 중요성으로 최근 들어 돼지의 음성은 축산업 종사자에게 매우 중요한 데이터로 활발하게 연구되고 있다. 이를 위해 돼지의 음성 패턴을 분석하여 농장 소음 속에서 돼지의 음성을 구분하고 음성과 기침 소리를 구분하는 경량화 MobileNet 모델을 제안한다. 이 MobileNet은 돈사 내에서 다양한 배경 잡음, 기침 소리 등의 다양한 소리 속에서 돼지의 음성만을 정밀하게 구분하고 분석할 수 있었다. 테스트 결과, 이 모델은  98.2%의 높은 정확도를 보여주었다. 이러한 결과를 바탕으로 향후 연구에서는 돼지의 감정 분석, 스트레스 파악 등의 문제 해결을 기대한다.","Pigs express their reactions to their environment and health status through a variety of sounds, such as grunting, coughing, and screaming. Given the significance of pig vocalizations, their study has recently become a vital source of data for livestock industry workers. To facilitate this, we propose a lightweight deep learning model based on MobileNet that analyzes pig vocal patterns to distinguish pig voices from farm noise and differentiate between vocal sounds and coughing. This model was able to accurately identify pig vocalizations amidst a variety of background noises and cough sounds within the pigsty. Test results demonstrated that this model achieved a high accuracy of 98.2%. Based on these results, future research is expected to address issues such as analyzing pig emotions and identifying stress levels."
시각화 기반의 시계열 음향 분류에서의 플롯 크기의 영향력 분석,2024,"['Deep Learning', 'Convolutional Neural Network(CNN)', 'Time-series', 'Vision AI', '딥러닝', '합성곱 신경망', '시계열', '영상 인공지능']",,"In recent years, visualizing time-series data as images for use in vision-based Artificial Intelligence (AI) models has gained significant attention. This approach transforms temporal sequences into images that can be processed by deep learning models, such as Convolutional Neural Network (CNN).Although its effectiveness has been demonstrated in various domains, the impact of plot size on model performance remains underexplored. In this study, we investigate the effect of varying plot sizes on classification accuracy by visualizing natural sounds (e.g., cats, crows) and testing five classes of 2,000 samples each using the YOLO model. While training was conducted on 320x320 plots, test sets were generated at six sizes (112x112 to 640x640). Results show that as the plot size of the test dataset diverged from that of the training dataset, both precision and recall decreased, highlighting the importance of plot size consistency in time-series visualization research."
Implementation of a Music Generation System Through Automatic Text Prompt Generation: Focusing on Emotion Analysis Through Music Analysis and Lyrics Analysis,2024,"['Music Generation', 'Text Prompt Automation', 'Emotion Analysis', 'Deep Learning', 'CNN', 'LSTM', 'Music Recommendation.']",,"Current AI-based music generation models and research primarily focus on manual text-based music generation. This paper proposes a music generation system that automates text prompts to enhance user convenience and streamline the creative process. The study involves building a dataset that includes genre, artist, and album information by analyzing and processing music data collected from audio files and extracting keywords from lyrics. The lyrics data are tokenized using the KoNLPy natural language processing library in Python, and key terms are extracted through TF-IDF vectorization. Additionally, the study suggests a method for automatically generating text prompts using MFCC, tempo, and other feature data to predict emotions through a model that combines CNN and ChatGPT. These automatically generated text prompts are then input into the MusicGen model to automatically create new music that reflects the user's emotional state and musical preferences. The findings of this study are expected to contribute to the field of music data analysis and generation."
다층 다요소 시스템의 최적화를 위한 진화연산의 탐색공간 축소 - 딥러닝 가지치기 사례 연구,2024,"['Multilayers Multi-elements System', 'Evolutionary Computation', 'Gene Expression by Rules', 'CNN', 'Filter Pruning']",,"Optimization of multi-layer, multi-element systems such as deep learning is an NP-hard problem that requires determining the number of layers, the number of elements in a layer, and the types of elements. In such a system, deleting redundant elements to reduce the size while maintaining performance is crucial to conserve resources and improve the efficiency of the system. This is a very complex and challenging problem because it consists of a large number of multi-layered and multi-element systems with a huge search space. Evolutionary computation is widely used for large-scale optimization problems due to its high efficiency, but it is difficult to apply due to the characteristics of evolutionary computation when the calculation of the fitness function is complex. To solve this problem, we propose a technique that dramatically reduces the search space by improving the representation of the gene.We verify its feasibility by applying it to a case study, CNN pruning. We use the ResNet56 model for the CIFAR10 dataset and compare it with existing pruning approaches."
Anomaly Detection System for Solar Power Distribution Panels utilizing Thermal Images,2024,"['Anomaly Detection', 'Digitalization of Power Facilities', 'Faster R-CNN', 'Object Detection', 'Thermal Image']",,"This study aimed to develop an advanced anomaly-detection system tailored for solar power distribution panels using thermalimaging cameras to ensure operational stability. It addresses the imperative shift toward digitalized safety management inelectrical facilities, transcending the limitations of conventional empirical methodologies. Our proposed system leverages afaster R-CNN-based artificial intelligence model optimized through meticulous hyperparameter tuning to efficiently detectanomalies in distribution panels. Through comprehensive experimentation, we validated the efficacy of the system in accuratelyidentifying anomalies, thereby propelling safety protocols forward during the fourth industrial revolution. This study signifies asignificant stride toward fortifying the integrity and resilience of solar power distribution systems, which is pivotal for adaptingto emerging technological paradigms and evolving safety standards in the energy sector. These findings offer valuable insightsfor enhancing the reliability and efficiency of safety management practices and fostering a safer and more sustainable energylandscape."
Defect Detection of Scroll Fixed using AI Machine Vision Inspection,2024,"['Scroll compressor fixed', 'Defect detection', 'Machine vision', 'Deep learning', 'Convolutional Neural Network(CNN)']",,"This study was conducted to improve the process quality and productivity of the scroll compressor fixed parts for high-efficiency air conditioners. We have developed a defect detection technique for scroll fixed components through vision inspection due to lack of manpower when a defect occurs in the processing process and a long time to analyze the cause of the defect. In general, conventional vision inspection has low detection capability when there are various defect items such as complex shapes, defect types, sizes, and locations. However, in this study, we developed improvement measures for process defects through the application of AI algorithms with a machine vision inspection automation system. The model was classified and designed to facilitate AI learning by classifying images by standard based on scroll fixed component images collected with vision in the field, and setting brightness and regions of interest. Defect detection of fixed scroll components was determined by applying a CNN deep learning algorithm by increasing the amount of data using data augmentation techniques."
"Deep Neural Network Entrepreneurial Project Recommendation Model for the Integration of Industry, Education, and Entrepreneurship Needs of Students",2024,"['Industry-education integration', 'Entrepreneurial project recommendation', 'DNN', 'Matrix decomposition', 'Word embedding']",,"As the size of the entrepreneurship project information platform grows, it is becoming increasingly difficult for student users to find in-demand entrepreneurship projects that integrate industry and education comprehensively and rapidly. The severe information overload leads to poor accuracy of recommendation results. This study addressed these problems based on Deep Neural Networks (DNNs) and Matrix Decomposition Algorithms (MDAs) by combining a Convolutional Neural Network (CNN), word embedding, and one-hot coding techniques. The DNN-MF model was used to extract the entrepreneurial needs and implicit features of students. The DNN-MF model designed for the study was also improved and incorporated with student user features, i.e., the DNN-DNN2 model was constructed. The experiments showed that the Root Mean Square Error (RMSE) of the DNN-MF model was lower than that of the Convolution Matrix Factorization (ConvMF) and Probabilistic Matrix Factorization (PMF) by 0.1190 and 0.1677, respectively. The RMSE of the DNN-DNN2 model was lower than that of the DNN-MF model, and the recommendation accuracy of the study model was 2.35% higher than that of the DNN-DNN1 model, which did not incorporate the student user characteristics. These results showed that the proposed recommendation model for entrepreneurial projects was significantly better than the current popular ones. Moreover, the model could complete the task of recommending entrepreneurial projects faster and more accurately, effectively solving the cold start problem of users and projects, which has certain practical significance."
Transformer의 개별 가지치기를 이용한 효율적인 이미지 캡셔닝 기법,2024,"['Super-resolution', 'Deep Learning', 'Deep Residual Block']","본 논문에서는 이미지 캡셔닝에서 개별 가지치기 기법을 통해 효율적인 트랜스포머 네트워크를 제안한다. 일반적으로 이미지 캡션모델은 사전 학습된 CNN 인코더, 트랜스포머 인코더 및 디코더의 세 가지로 구성된다. 본 연구에서는 캡션 모델의 각 구성 요소를개별적으로 최적화하도록 설계한 가지치기(Pruning) 기술을 통해, 전체 구조가 기존 캡셔닝 모델과 다르더라도 인코더 또는 디코더 네트워크와 같은 유사한 구성 요소를 공유하는 모델에 대한 적용성을 넓혔다. 또한 디코더에서 캡셔닝을 위한 손실함수를 적용함으로써성능을 향상시켰다. 본 모델을 영문 및 한글 버전에 적용한 결과 기존 대비 우수한 성능을 확인하였다.","In this letter, we propose an efficient transformer network using individual pruning techniques in image captioning. Typically, animage caption model consists of three things: a pre-trained CNN encoder, a transformer encoder, and a decoder. In this study, aproposed pruning technique was designed to optimize each component of a caption model individually and shared similarcomponents, such as encoder or decoder networks, even if the overall structure is different from conventional captioning models.Additionally, proposed method was applied a loss function for captioning in the decoder. As a result of applying this model to theEnglish and Korean versions, superior performance was confirmed compared to the existing model."
합성곱 신경망 기반 화재 인식 모델 최적화 연구: Layer Importance Evaluation 기반 접근법,2024,,"본 연구는 Layer Importance Evaluation을 통해 도출된 화재 감지에 최적화된 딥러닝 아키텍처를 제안한다. 기존의 합성곱 신경망(Convolutional Neural Network, CNN) 기반 화재 감지 시스템의 불필요한 복잡성과 연산을 초래하는 문제점을 해결하기 위해, Layer Importance Evaluation 기법을 통해 가중치 및 활성화 값에 근거한 모델의 내부 레이어의 동작을 분석하고, 화재 감지에 기여도가 높은 레이어를 식별한 뒤, 식별한 레이어만으로 모델을 재구성하여, 기존 모델과의 성능 지표를 비교 분석하였다. Xception, VGG19, ResNet, EfficientNetB5 등 네 가지 전이 학습 모델을 사용하여 화재 데이터를 학습시킨 후, Layer Importance Evaluation기법을 적용하여 각 레이어의 가중치와 활성화 값을 분석한 뒤 기여도가 가장 높은 상위 랭크 레이어들을 선별하여 새로운 모델을 구축하였다. 연구 결과, 구현된 아키텍처는 기존 모델 대비 약 80% 가량 경량화 된 파라미터로도 동등한 성능을 유지하며, 약 3~5배가량 신속한 학습 속도를 가지면서도 기존의 복잡한 전이학습 모델에 비해 정확도, 손실, 혼동행렬 지표에서 동등한 성능을 출력함으로써, 화재 감시 장비의 효율성을 높이는 데 기여할 수 있음을 확인하였다.","This study proposes a deep learning architecture optimized for fire detection derived through Layer Importance Evaluation. In order to solve the problem of unnecessary complexity and operation of the existing Convolutional Neural Network (CNN)-based fire detection system, the operation of the inner layer of the model based on the weight and activation values was analyzed through the Layer Importance Evaluation technique, the layer with a high contribution to fire detection was identified, and the model was reconstructed only with the identified layer, and the performance indicators were compared and analyzed with the existing model. After learning the fire data using four transfer learning models: Xception, VGG19, ResNet, and EfficientNetB5, the Layer Importance Evaluation technique was applied to analyze the weight and activation value of each layer, and then a new model was constructed by selecting the top rank layers with the highest contribution. As a result of the study, it was confirmed that the implemented architecture maintains the same performance with parameters that are about 80% lighter than the existing model, and can contribute to increasing the efficiency of fire monitoring equipment by outputting the same performance in accuracy, loss, and confusion matrix indicators compared to conventional complex transfer learning models while having a learning speed of about 3 to 5 times faster."
Radiographic Analysis of Scoliosis Using Convolutional Neural Network in Clinical Practice,2024,"['Scoliosis', 'Cobb Angle', 'Convolutional Neural Network', 'Radiography']",,"Purpose To assess the reliability and accuracy of an automated Cobb angle measurement (ACAM) using a convolutional neural network (CNN) for scoliosis evaluation and to compare measurement times.Materials and Methods ACAM was applied to spine radiographs in 411 patients suspected of scoliosis. Observer 1 (consensus of two musculoskeletal radiologists) and observer 2 (a radiology resident) measured Cobb angle (CA). CA measurements were categorized using observer 1’s measurements as the reference standard. Inter-observer reliability and correlation were assessed using intraclass correlation coefficient (ICC) and Spearman’s rank correlation coefficient, respectively. Accuracy and measurement time of ACAM and observers were evaluated.Results ACAM demonstrated excellent reliability and very high correlation with observer 1 (ICC = 0.976, Spearman’s rank correlation = 0.948), with a mean CA difference of 1.1. Overall accuracy was high (88.2%), particularly in mild (92.2%) and moderate (96%) scoliosis. Accuracy was lower in spinal asymmetry (77.1%) and higher in severe scoliosis (95%), although the CA was lower compared to the observers. ACAM significantly reduced measurement time by nearly half compared to the observers (p < 0.001).Conclusion ACAM using CNN enhances CA measurement for assessing mild or moderate scoliosis, despite limitations in spinal asymmetry or severe scoliosis. Nonetheless, it substantially decreases measurement time."
Design and Optimization of Basketball Hit Prediction Model Based on Convolutional Neural Network and Sensor Data,2024,"['컨볼루션 신경망', '각도 센서', '자기 센서', '자이로스코프', '물체 예측', 'Convolutional Neural Network', 'Angle Sensor', 'Magnetic Sensor', 'Gyroscope', 'Object Prediction']",,"Basketball shooting percentage is an important index used to measure a player’s technical skill. This paper presents a basketball shot prediction model based on a convolutional neural network (CNN) and sensor data, to improve the efficiency and accuracy of basketball shot training. First, three sensors were used to collect player motion data during the shooting process, and the CNN was used to analyze and learn these data. The proposed model achieved 98.5% shooting prediction accuracy, which is higher 13.5% than the existing paper method. Recently, the rapid development of artificial intelligence and sensor technology has led to the emergence of deep learning-based shooting hit prediction models, providing new scientific tools for basketball training."
AI 자습실의 참여가 자기조절학습에 미치는 효과 분석: K 고등학교를 중심으로,2024,"['AI-assisted study room', 'AI learning environment', 'self-regulated learning', 'learning strategies', 'PSM', 'AI 자습실', '인공지능 학습환경', '자기조절학습', '학습전략', 'PSM매칭']","본 연구의 목적은 K 고등학교 AI 자습실이 자기조절학습에 미치는 영향을 양적, 질적으로 검증하고자 하는 것이다. AI 자습실은 인공지능 기술 기반의 CNN 딥러닝 기법을 적용하여 머리 움직임과 시선의 움직임을 파악하고 실시간으로 뇌파를 측정하여 집중력을 측정하는 기술이 사용되었다. 연구 대상은 실험집단 45명과 SPSS 28.0프로그램의 PSM매칭을 사용하여 추출된 통제집단 45명으로 구성되었다. 실험집단은 AI 자습실을 6주 동안 70분씩 2번, 매주 4회 AI 자습실을 이용하고 사전검사, 사후검사와 추후검사에 참여하였고 통제집단은 실험집단과 동일한 시점에 3번의 검사에 참여하였다. 동질성 검정, 집단 간 차이, 반복 측정 분산분석을 실시하였고, 사후검사 결과를 바탕으로 6명 학생을 대상으로 심층 면접 인터뷰를 통해 AI 자습실 사용에 대한 경험을 분석하였다. 연구결과는 첫째, AI 자습실 효과에 대한 자기조절학습의 반복 측정 분산분석결과, 실험집단과 통제집단 간에는 유의한 차이가 나타나지 않았다. 둘째, AI 자습실 경험에 대한 면담 결과에 의하면 자기조절학습지수 상승 집단은 AI 자습실 경험에 대해 대체로 긍정적으로 인식하고 AI 자습실 사용이 학습동기 유지에 도움이 되었다고 응답한 반면에 무변화와 하락 집단은 집중력 측정 기계 착용에 대한 불편함 때문에 오히려 학습집중에 방해가 되었다고 응답하였다.교육적 함의점 : 본 연구는 인공지능 기반의 학습환경이 자기조절학습 향상 가능성을 실증적으로 점검하였다는 점에서 중요한 교육적 함의점이 있다. 학교 현장의 안착과 학습자에게 유용한 효과를 끌어내기 위해 인공지능 기반 학습환경을 설계하고 구현할 때, 학습자 친화적으로 학습환경을 설계하고 구현할 필요가 있으며, 학습자 맞춤형 교육적 지원이 동반되어야 할 것이다.","This study aims to quantitatively and qualitatively evaluate the effects of an artificial intelligence(AI)-assisted study room on self-regulated learning at K High School. The AI-assisted study room employs convoluted neural network (CNN) deep learning techniques based on AI technology to monitor head and gaze movements, and utilizes real-time electroencephalogram(EEG) measurements to assess concentration levels. The research sample comprised 45 students in the experimental group and 45 students in the control group, selected using propensity score matching with the SPSS 28.0 program. The experimental group used the AI-assisted study room for 70 minutes, twice a week over six weeks, and participated in pre-tests, post-tests, and follow-up tests. The control group took the same three tests at corresponding intervals. Homogeneity tests and repeated measures ANOVA were conducted. Based on the post-test results, in-depth interviews were held with six students to analyze their experiences with the AI-assisted study room. The findings are as follows: First, repeated measures ANOVA for self-regulated learning revealed no significant differences between the experimental and control groups affirming the effectiveness of the AI-assisted study room. Second, interview results indicated that students with increased self-regulated learning indices in the experimental group generally reported positive experiences and perceptions with the AI assisted study room, stating that it helped maintain their learning motivation. In contrast, students in the no change and decrease groups reported that the discomfort caused by wearing concentration measurement devices hindered their learning concentration.Educational Impact and Implications : This study holds important educational implications as it empirically examined the potential of AI-assited learning environments to enhance self-regulated learning. For AI-based learning environments to be established in schools and to ensure their positive impact on learners, they need to be designed and implemented in a learner-friendly manner and accompanied by learner-tailored educational support."
Dental Age Estimation in Children Using Convolution Neural Network Algorithm: A Pilot Study,2024,"['Convolutional neural networks', 'Deep learning', 'Dental age estimation']",,"Purpose: Recently, deep learning techniques have been introduced for age estimation, with automated methods based on radiographic analysis demonstrating high accuracy. In this study, we applied convolutional neural network (CNN) techniques to the lower dentition area on orthopantomograms (OPGs) of children to develop an automated age estimation model and evaluate its accuracy for use in forensic dentistry.Methods: In this study, OPGs of 2,856 subjects aged 3-14 years were analyzed. The You Only Look Once (YOLO) V8 object detection technique was applied to extract the mandibular dentition area on OPGs, designating it as the region of interest (ROI). First, 200 radiographs were randomly selected, and were used to train a model for extracting the ROI. The trained model was then applied to the entire dataset. For the CNN image classification task, 80% of OPGs were allocated to the training set, while the remaining 20% were used as the test set. A transfer learning approach was employed using the ResNet50 and VGG19 backbone models, with an ensemble technique combining these models to improve performance. The mean absolute error (MAE) on the test set was used as the validation metric, and the model with the lowest MAE was selected.Results: In this study, the age estimation model developed using mandibular dentition region from OPGs achieved MAE and root mean squared error (RMSE) values of 0.501 and 0.742, respectively, on the test set, and MAE and RMSE values of 0.273 and 0.354, respectively, on the training set.Conclusions: The automated age estimation model developed in this study demonstrated accuracy comparable to that of previous research and shows potential for applications in forensic investigations. Increasing the sample size and incorporating diverse deep learning techniques are expected to further enhance the accuracy of future age estimation models."
딥러닝 및 패치 기반 커널 PCA를 이용한 미세먼지 추정,2024,"['Patch-based Kernel PCA', 'Deep Learning', 'Particulate Matter Prediction']","본 연구는 이미지 기반 미세먼지(PM2.5 및 PM10) 농도 예측을 위해 패치 기반 커널 PCA와 딥러닝을 이용한미세먼지 추정 방법론을 제안한다. 커널 PCA는 이미지의 비선형적 특징을 효과적으로 추출하고, CNN 모델은 이를 학습하여 높은 예측 성능을 달성한다. 강화 학습 기반 마스크 최적화와 다중 커널 통합을 통해 예측 정확도와 학습 효율성을 향상했으며, 다양한 환경에서 일관된 성능을 유지했다. 실험 결과, 제안된 방법론은 기존 센서 기반 방법보다 넓은범위에서 실시간 모니터링이 가능하며, 저사양 하드웨어에서도 우수한 실시간 성능을 보여준다. 향후 연구는 다양한 환경에서의 데이터 수집과 모델 최적화를 통해 실시간 응용 가능성을 더욱 높이는 데 주력할 것이다.","In this paper, we propose a methodology that combines patch-based kernel PCA and deep learning for image-based particulate matter (PM2.5 and PM10) concentration prediction. Kernel PCA effectively extracts the nonlinear features of images, and a CNN model is trained to achieve high prediction performance. Through reinforcement learning-based mask optimization and multi-kernel integration, we improve the prediction accuracy and learning efficiency, while maintaining consistent performance in different environments. Experimental results show that the proposed methodology is capable of real-time monitoring in a wider range than existing sensor-based methods, and shows good real-time performance even on low-end hardware. Future work will focus on data collection in different environments and model optimization to further enhance its real-time applicability."
박스 구조물의 부재력 예측을 위한 딥러닝 모델 구현 및 성능 비교,2024,"['box structure', 'deep learning', 'optimization algorithm', 'neural network model', '박스 구조물', '딥러닝', '최적화 알고리즘', '신경망 모델']","본 연구에서는 박스 구조물의 부재력 예측을 위한 다양한 딥러닝 모델의 정확성을 비교하고자 하였다. 이를 위해 상용 유한요소 프로그램인 MIDAS를 이용하여 300개의 유한요소모델을 작성하고, 수치해석을 수행하여 딥러닝 모델에 적용하기 위한 학습데이터를 생성하였다. 또한, 딥러닝 모델의 정확성을 비교하기 위해 MLP, CNN, RNN 및 LSTM과 같은 다양한 신경망 모델과 Adam, SGD, RMSprop 및 Adamax 등 최적화 알고리즘을 교차 적용하여 16개의 딥러닝 모델을 생성하였다. 그 결과 Adam 최적화 알고리즘이 모든 모델에서 가장 우수한 성능을 보여주었으며, 특히 MLP 모델에서 가장 높은 R2 값을 나타내었다. 이를 통해, 박스 구조물의부재력 예측을 위한 최적의 딥러닝 모델 구성은 Adam optimizer와 MLP 구조임을 확인하였다.","In this study, we compared the accuracy of various deep learning models for estimating the member forces of box structures. Particularly, 300 finite element models were generated using the MIDAS commercial finite element program, and numerical analyses were performed to generate training data for the deep learning models. To compare model accuracy, 16 deep learning models were generated using various neural network architectures—MLP, CNN, RNN, and LST—and optimization algorithms, including Adam, SGD, RMSprop, and Adamax. The results demonstrated that the Adam optimizer consistently delivered best across all models, with the highest R2 value observed particularly in MLP. This confirms that the combination of the Adam optimizer and MLP architecture is the most effective configuration for predicting the member forces in box structures."
Implant Thread Shape Classification by Placement Site from Dental Panoramic Images Using Deep Neural Networks,2024,"['Artificial intelligence', 'Convolutional neural networks', 'Classification', 'Deep learning', 'Implant system']",,"Purpose: In this study, we aimed to classify an implant system by comparing the types of implant thread shapes shown on radiographs using various Convolutional Neural Networks (CNNs), particularly Xception, InceptionV3, ResNet50V2, and ResNet101V2. The accuracy of the CNN based on the implant site was compared.Materials and Methods: A total of 1000 radiographic images, consisting of eight types of implants, were preprocessed by resizing and CLAHE filtering, and then augmented. CNNs were trained and validated for implant thread shape prediction. Grad-CAM was used to visualize class activation maps (CAM) on the implant threads shown within the radiographic image.Results: Averaged over 10 validation folds, each model achieved an AUC of over 0.96: AUC of 0.961 (95% CI 0.952–0.970) with Xception, 0.973 (95% CI 0.966-0.980) with InceptionV3, 0.980 (95% CI 0.974-0.988) with ResNet50V2, and 0.983 (95% CI 0.975-0.992) with ResNet101V2. Accuracy was higher in the posterior region than in the anterior area in all four models. Most CAMs highlighted the implant surface where the threads were present; however, some showed responses in other areas.Conclusion: The CNN models accurately classified implants in all areas of the oral cavity according to the thread shape, using radiographic images."
자연어처리 기반 스마트 이동기기 사용성평가 감성분석 모델 개발,2024,"['Sentiment analysis', 'Deep learning', 'Transfer learning', 'Usability evaluation', 'Smart rollator']","최근 빅데이터 및 인공지능 기술의 발전에도 불구하고 사용성평가 분야에서는 텍스트 등 비정형 데이터의 부족으로 감성분석 연구에 제한이 많았다. 이에 본 연구에서는 전이학습을 기반으로 소규모 사용성평가 데이터를 활용한 감성분석 모델을 제안한다. 이를 위해 네이버 영화리뷰 20만 건의 댓글로 CNN 모델을 생성하고 사용성평가 517건의 데이터를 이용하여 전이학습을 수행하였다. 분석결과 본 연구에서 제안한 전이학습 모델은 소규모 데이터만으로 생성된 모델보다 약 20%의 정확도 향상과 1epoch당 1400ms의 학습시간 단축을 보였다. 본 연구에서는 사용성평가 분야에 한글 텍스트 감성분석 및 전이학습을 처음으로 적용하여 향후 소규모 데이터인 사용성평가에 감성분석 연구를 활용할 수 있는 이론적 기반을 제공하였다는 점이다. 또한, 실제로 데이터가 부족하여 시도하기 어려웠던 사용성평가 분야의 감성분석에 전이학습을 통해 설문지 없이 고령자와 간단한 응답을 통하여 사용성평가가 가능하다는 것을 확인하였다.","Despite the recent advances in big data and artificial intelligence technologies, the usability evaluation field needs to be expanded in sentiment analysis research due to the need for more unstructured data, such as text. This study proposes a sentiment analysis model using small-scale usability evaluation data based on transfer learning. For this purpose, we generated a CNN model with 200,000 comments from Naver movie reviews and performed transfer learning using data from 517 cases of usability evaluations. As a result of the analysis, the transfer learning model proposed in this study shows an accuracy improvement of about 20% and a learning time reduction of 1400ms per epoch compared to the model generated with only small-scale data. In this study, we applied Korean text sentiment analysis and transfer learning to the field of usability evaluation for the first time, providing a theoretical basis for using sentiment analysis research for usability evaluation with small data in the future. In addition, we confirmed that it is possible to evaluate the usability of elderly and simple responses without questionnaires through transfer learning for sentiment analysis in the field of usability evaluation, which was challenging to try due to a lack of data in practice."
IR 카메라 기반 다양한 크기 선박의 정밀 탐지를 위한 다중 스케일 어텐션 기법,2024,"['Maritime surveillance', 'Infrared cameras', 'Multi-scale attention', 'Real time detection', 'Small object detection']","해양 선박 탐지는 해양 안전, 보안, 환경 보호 등 다양한 분야에서 중요하다. 특히 야간이나 악천후와 같은 저가시성 환경에서 선박 탐지는 더욱 어려워지며, 이를 해결하기 위해 적외선(IR) 카메라가 활용된다. 그러나 IR 카메라는 저해상도와 제한된 색상 정보로 인해 작은 선박 탐지가 어렵다는 한계가 있다. 본 연구는 CNN(convolutional neural network) 특징 맵을 기반으로 한 다중 스케일 어텐션MSA(multi-scale attention) 기법을 제안하여 다양한 크기의 선박을 정밀하게 탐지한다.  MSA는 YOLOv8의 다중 스케일 특징 맵을 활용해 실시간 탐지 성능을 유지하면서도 소형 선박 탐지를 개선한다. 실험 결과, 제안된 모델은 IR 기반 탐지에서 소형 및 중형 선박의 탐지 정밀도를 높여 해양 환경에서 실시간 탐지 성능을 극대화함을 확인하였다.","Maritime vessel detection is critical in various fields such as maritime safety, security, and environmental protection. However, vessel detection becomes increasingly challenging in low-visibility conditions, such as nighttime or adverse weather. To address this issue, infrared (IR) cameras are employed. Nevertheless, IR cameras face limitations due to low resolution and limited color information, making the detection of small vessels particularly difficult. This study proposes a multi-scale attention (MSA) technique based on convolutional neural network (CNN) feature maps to accurately detect vessels of various sizes. By leveraging the multi-scale feature maps of YOLOv8, MSA improves the detection of small vessels while maintaining real-time detection performance. Experimental results demonstrate that the proposed model enhances the detection precision for small and medium-sized vessels in IR-based detection, thereby maximizing real-time detection performance in maritime environments."
딥러닝 기반 가상 피팅 기능을 갖는 중고 의류  거래 시스템 구현,2024,"['Secondhand Trading', 'Virtual Fitting', 'Deep Learning', 'PyTorch', 'CP-VTON-Plus']","본 논문은 딥러닝을 기반으로 한 가상 피팅 기능을 갖춘 중고 의류 거래 시스템의 구현을 소개한다. 제안된 시스템은 사용자가 중고 의류를 온라인으로 시각적으로 착용하고 핏을 확인할 수 있는 기능을 제공한다. 이를 위해, 합성곱 (CNN) 알고리즘을 사용하여 사용자의 신체 형상과 의류의 디자인을 고려한 가상 착용 모습을 생성한다. 이를 통해 구매자는 온라인에서 실제로 의류를 입기 전에 핏을 미리 확인할 수 있으며, 이는 구매 결정에 도움을 준다. 또한, 판매자는 시스템을 통해 정확한 의류 사이즈와 핏을 제시할 수 있어 구매자의 만족도를 높일 수 있다. 본 논문은 CNN 모델의 학습 절차, 시스템의 구현 방법, 사용자 피드백 등을 자세히 다루고, 실험 결과를 통해 제안된 시스템의 유효성을 입증한다.",
차량 도어 충돌 방지용 레이다 신호처리 시스템 설계 및 구현,2024,"['BNN Accelerator', 'FPGA', 'Embedded System', 'FMCW Radar', 'Object Detection']","본 논문에서는 차량의 개문사고를 예방하기 위한 목적으로 FMCW 레이다 센서를 활용하여 물체를 감지하고 분류 가능한 시스템설계 및 구현 결과가 제시된다. 제안된 시스템은 Raspberry-Pi 기반 임베디드시스템과 FPGA 가속기에 기반하여 구현되었으며, 해당 시스템은 레이다 센서 신호처리 과정과 물체를 자전거, 자동차, 사람으로 분류하는 딥러닝 과정을 수행한다. CNN 알고리즘은연산량과 메모리 사용량이 크기 때문에 임베디드시스템에 적합하지 않다. 이를 해결하기 위해 임베디드시스템에 적합한 경량화된딥러닝 모델인 BNN을 FPGA 상에 구현한 뒤 결과를 검증하였고, 90.33%의 분류 정확도와 20ms의 수행시간을 확인하였다.","This paper presents the design and implementation results of a Raspberry-Pi-based embedded system with anFPGA accelerator that can detect and classify objects using an FMCW radar sensor for preventing door collisionaccidents in vehicles. The proposed system performs a radar sensor signal processing and a deep learningprocessing that classifies objects into bicycles, automobiles, and pedestrians. Since the CNN algorithm requiressubstantial computation and memory, it is not suitable for embedded systems. To address this, we implemented alightweight deep learning model, BNN, optimized for embedded systems on an FPGA, and verified the resultsachieving a classification accuracy of 90.33% and an execution time of 20ms"
인공지능의 민사책임에 대한 소고,2024,"['AI', 'Generative AI', 'Civil Liability', 'Product Liability', 'Pharmaceuticals manufactured using generative AI', 'Strict Liability', '인공지능', '생성형 인공지능', '민사책임', '생성형 인공지능 기술 활용 의약품', '위험책임', '제조물책임']","최근의 인공지능 기술의 발달은 그 속도나 규모의 면에서 인류사의 어느 시기보다 가장 빠른 변화를 가져오고 있다. 기술의 발달로 데이터베이스를 통하여 생성된 자료를 통한 훈련으로 의료용 인공지능의 한계가 극복되는 등, 2012년에 합성곱 신경망 (CNN)으로 이미지처리에 대한 딥러닝이 본격화 된 이래 인공지능 기술은 눈부시게 발달해 왔다. 최근의 로봇의 자연어 처리 발전에 고급자연어처리(Natural Language Processing, 이하 ‘NLP’)를 통하여 인공지능의 활용이 가속화 되고 있다. 이러한 NLP의 활용은 언어가 아무리 복잡하더라도 기계가 데이터를 식별하고 이해할 수 있게 되어 더욱 빠르고 정확한 생성형 인공지능의 발달의 초석이 되었다. 그렇다면 발달의 속도를 멈추지 않는 인공지능, 생성형 인공지능이 활용되는 시대에 인공지능의 활용으로 발생한 손해에 대해서는 인공지능이 가진 생래적인 특성인 예측불가능성과 불투명성을 시작으로 블랙박스 효과등의 특성을 고려하여 우리 민법의 책임원리에 인공지능의 민사책임을 대입해 보았다. 그러기 위해서는 먼저, 인공지능으로 인한 불법행위책임을 논의함에 있어서 인공지능의 기술 발달 단계를 고려한 법적 책임을 판단해 보고 ‘약한 인공지능’이라 하더라도 인공지능 개발자에 의하여 창조된, “지배 가능한 위험(Gefahr)에 해당” 될 수 있으며, 모든 유형은 아니더라도 일부에는 무과실책임인 위험책임의 적용 가능성이 있음을 살펴 보았다. 아울러, 인공지능에 적용가능한 민사책임을 과실책임과 무과실책임으로 나누어 검토하면서, 비교법적으로는 EU의 흐름도 살펴보았다.그러나 무과실책임에 있어서 제조물책임법을 논의하면서 기존의 제조물책임법의 한계점을 극복하기 위한 대표적 사례로서 생성형 인공지능 기술을 활용한 의약품 제조에 위험책임을 적용할 수 없는지 그 가능성과 시사점을 살펴 보았다. 인류는 현재 가장 빠른 기술의 발달 시대와 폭발하는 빅 데이터의 시대에 살고 있으며 기술의 발달로 인하여 인류는 많은 이익을 누릴 수 있게 되었다. 기술의 발전에 따라서 사용자의 편의가 개선되고 막대한 부가 창출되는 만큼, 민사책임 영역에서의 위험책임의 의미가 더욱 의미를 가질 수 있다. 생성형 인공지능은 이미 신약개발에 소요되는 비용과 시간을 혁신적으로 줄여주어 제약회사에는 막대한 이윤을 주는 반면, 기존의 제조물책임법을 적용하더라도 설계상의 결함에 대하여 합리적인 대체가능성에 대한 면책가능성이 있어 피해자의 손해를 적절히 구제하기 어렵다. 생성형 인공지능의 시대, 의약품 제조라는 사례를 상정하여 보다 강화된 위험책임의 적용가능성을 고찰해 보았다.","The recent development of artificial intelligence (AI) technology is bringing about changes at a faster pace and on a larger scale than any other period in human history. With technological advancements overcoming the limitations of medical AI through training with databases, AI technology has made remarkable progress since the inception of deep learning for image processing with convolutional neural networks (CNN) in 2012. The recent advancements in natural language processing (NLP) have accelerated the utilization of AI through sophisticated natural language processing, enabling machines to identify and understand data regardless of the complexity of the language. This has laid the foundation for the rapid and precise development of generative AI. In the era where generative AI is being utilized without pausing in its developmental speed, we considered the civil liability of AI in our civil law principles, taking into account the inherent characteristics of AI such as unpredictability, opacity, and the black box effect.To do this, we first examined the legal liability considering the stages of AI technology development in discussing the tort liability caused by AI. Even “Weak AI,” created by AI developers, may fall under “Gefahr,” and while not all types, some may apply to strict liability in terms of risk liability. Furthermore, while reviewing civil liability applicable to AI under fault-based and no-fault liability, we also looked at the trends in the EU comparatively.In discussing no-fault liability, particularly under the Product Liability Act, we examined the possibility and implications of applying risk liability to pharmaceutical manufacturing using generative AI technology as a representative example to overcome the limitations of the existing Product Liability Act. Humanity currently lives in an era of rapid technological development and exploding big data, enjoying numerous benefits due to these advancements. As user convenience improves and massive added value is created through technological progress, the meaning of risk liability in the realm of civil liability can gain more significance. Generative AI has already drastically reduced the costs and time required for new drug development, providing substantial profits to pharmaceutical companies. However, even if the existing Product Liability Act is applied, it may be difficult to adequately remedy the harm to victims due to the reasonable alternative possibility defense regarding design defects. In the era of generative AI, we examined the possibility of applying enhanced risk liability by assuming the case of pharmaceutical manufacturing."
Spatio-Temporal Modeling via Adaptive Frequency Filtering for Video Action Recognition,2024,"['비디오 인식', '시공간 모델링', '주파수 필터링', '이산 코사인 변환', 'video recognition', 'spatio-temporal modeling', 'frequency filtering', 'DCT']",,"Modeling long-term spatio-temporal dependencies in video data is challenging, as CNNs often struggle to capture global context through their local receptive fields. To address this problem, we propose an efficient global spatio-temporal modeling method that integrates easily with existing CNN models. Our approach utilizes Discrete Cosine Transform (DCT) to shift information into the frequency domain, where two adaptive filtering paths operate complementarily: one removes redundant frequencies while preserving essential information, and the other enhances important frequencies for spatio-temporal modeling. We introduce DynamicMNIST, a lightweight dataset featuring various digit behaviors like shifting, rotating, and scaling. Our evaluations on three public benchmarks and DynamicMNIST demonstrate that the proposed module enhances activity recognition performance across different CNN models with minimal additional parameters and computational costs."
이미지에서 추정된 물체 위치를 이용한 심층 강화학습 기반 로봇 제어,2024,"['Reinforcement learning', 'Position extractor', 'Convolutional neural network', 'Truncated quantile critics', 'Hindsight experience replay']","본 논문은 이미지를 통해 목표 물체의 위치를 추정하고, 그 위치를 이용해 로봇 팔이 물체를 목표 위치로 이동시키는 강화 학습 방법을 제시한다. 목표 물체의 위치를 추정하기 위해, 사전 학습된 VGG16의 특징 추출 부분을 기반으로 변형된 Convolutional Neural Network (CNN) Position Extractor를 사용하여, 이미지와 목표 물체 위치의 데이터 쌍을 가지고 지도 학습을 실시하였다. 강화 학습 기법으로 Hindsight Experience Replay (HER)와 Truncated Quantile Critics (TQC)를 사용하여 시뮬레이션 환경에서 로봇 팔이 목표 물체를 목표 위치로 이동시키도록 반복 훈련하였다. 학습된 로봇 팔이 이미지에서 목표 물체의 현재 위치를 추정하여 그 위치로 물체를 옮길 수 있으므로, 목표 물체의 위치를 실시간으로 추적하는 추가 센서가 필요하지 않다는 장점이 있다. 본 논문에서 개발한 방법을 사용했을 때 평균 누적 보상 –48.51와 성공률 95.0%를 달성하였다. 실험 결과를 통해 목표 물체를 정밀하게 측위하지 않아도, 이미지를 통해 목표 물체의 위치를 추정하고, 그 위치를 이용해 로봇 팔이 물체를 목표 위치로 이동시키는 것이 가능함을 확인하였다.","This paper presents a method that utilizes raw images to infer the position of an object and uses reinforcement learning methods to move an object to a desired position by a robot arm. At first, for inferring the position of the object, pre-collected raw images and the exact position of the object are used to train a Convolutional Neural Network (CNN) Position Extractor, which is based on the feature extraction part of pre-trained VGG16. Then, reinforcement learning methods such as Truncated Quantile Critics (TQC) along with Hindsight Experience Replay (HER) are used to train a robot arm to move the object to a desired position in the simulation environment. A big advantage of this methodology is that an extra sensor for tracking the exact position of the object in real-time is not needed, since raw images are used to infer the position of the object and the robot arm uses that inferred position to move the object to the desired location. The mean cumulative rewards and the success rate of the methodology proposed by this paper are –48.51 and 95.0% respectively. The results obtained by this method show that it is possible to move an object from a certain position to a desired one by a trained robot arm using the object positions inferred from raw images, instead of using the actual positions of the object."
드론 검출을 위한 레이다 신호처리 시스템 설계,2024,"['AI Accelerator', 'BNN', 'Drone detection', 'Embedded system', 'FMCW radar sensor']","본 논문에서는 FMCW (frequency modulated continuous wave) 레이다 센서를 활용하여 드론 검출이 가능한 시스템 설계 및 구현 결과를 제시한다. 드론 검출 시스템의 구현을 위해, 레이다 센서로부터 입력된 신호를 FFT, CFAR, clustering, tracking으로 이어지는 총 4단계의 신호처리 과정을 통해 객체를 탐지하고, 해당 객체를 드론과 다른 사물로 분류하기 위한 딥러닝 추론 과정을 수행한다. 딥러닝의 높은 연산량과 많은 메모리 요구를 감소시키기 위해 CNN (convolution neural network) 연산을 이진화하여 수행하는 BNN (binary neural network) 구조를 적용하였다. 성능 평가 및 검증 결과 89.33%의 객체 구분 정확도를 확인할 수 있었고, 총 수행 시간은 4 ms로 실시간 동작이 가능함을 확인하였다.","In this paper, we present the design and implementation results of a system that classifies drones from other objects using an FMCW (frequency-modulated continuous wave) radar sensor. The proposed system detects various objects through a four-stage signal processing procedure, consisting of FFT, CFAR, clustering, and tracking, using signals received from the radar sensor. Subsequently, a deep learning process is conducted to classify the detected objects as either drones or other objects. To mitigate the high computational demands and extensive memory requirements of deep learning, a BNN (binary neural network) structure was applied, binarizing the CNN (convolutional neural network) operations. The performance evaluation and verification results demonstrated a drone classification accuracy of 89.33%, with a total execution time of 4 ms, confirming the feasibility of real-time operation."
수어 번역을 위한 3차원 컨볼루션 비전 트랜스포머,2024,"['Sign Language Translation', 'Transformer', 'Convolutional Transformer', '수어 번역', '트랜스포머', '컨볼루전 트랜스포머']","한국에서 청각장애인은 지체장애인에 이어 두 번째로 많은 등록 장애인 그룹이다. 하지만 수어 기계 번역은 시장 성장성이 작고, 엄밀하게주석처리가 된 데이터 세트가 부족해 발전 속도가 더디다. 한편, 최근 컴퓨터 비전과 패턴 인식 분야에서 트랜스포머를 사용한 모델이 많이 제안되고있는데, 트랜스포머를 이용한 모델은 동작 인식, 비디오 분류 등의 분야에서 높은 성능을 보여오고 있다. 이에 따라 수어 기계 번역 분야에서도트랜스포머를 도입하여 성능을 개선하려는 시도들이 제안되고 있다. 본 논문에서는 수어 번역을 위한 인식 부분을 트랜스포머와 3D-CNN을 융합한3D-CvT를 제안한다. 또, PHOENIX-Wether-2014T [1]","In the Republic of Korea, people with hearing impairments are the second-largest demographic within the registered disabilitycommunity, following those with physical disabilities. Despite this demographic significance, research on sign language translationtechnology is limited due to several reasons including the limited market size and the lack of adequately annotated datasets. Despitethe difficulties, a few researchers continue to improve the performacne of sign language translation technologies by employing the recentadvance of deep learning, for example, the transformer architecture, as the transformer-based models have demonstrated noteworthyperformance in tasks such as action recognition and video classification. This study focuses on enhancing the recognition performanceof sign language translation by combining transformers with 3D-CNN. Through experimental evaluations using the PHOENIX-Wether-2014Tdataset [1], we show that the proposed model exhibits comparable performance to existing models in terms of Floating Point OperationsPer Second (FLOPs)."
딥러닝 기술을 적용한 지능형 CCTV의 초기 화재 검출 방안에 관한 연구,2024,"['CCTV', 'Fire detection', 'Thermal imaging sensor', 'RGB sensor', 'Deep learning analysis']","화재는 예방 단계에서 사전 예측 및 조기 감지가 매우 중요하기 때문에 딥러닝 AI 분석 기술이 접목된 지능형CCTV의 영상 분석 기술이 매우 활발하게 연구되고 있다. 현재 지능형 CCTV는 가시광선 영상 분석이 가능하지만,검출 대상의 정확도가 떨어진다. 이를 해결하기 위하여 가시광선 감지기와 열화상 감지기를 결합하여 이중 구조로구성하고, 알고리즘(algorithm)을 구현하여 사전에 예측하고 감지하도록 하였다. 본 연구에서는 RGB 감지기와 열화상 감지기를 통해 3가지 클래스(fire, smoke, person)를 검출할 수 있는 알고리즘을 구축하였으며, 분류 신경망을 구축하기 위해 CNN 딥러닝 방식과 YOLOv5 방식을 활용하였다. 이중 센싱 카메라를 통해 성능을 평가한 결과 화염의크기와 온도 변화 등을 대상으로 화재 예측을 감지하는 트리거 역할을 수행할 수 있었으며, 전용 서버를 통해 지속적인 업데이트가 수행될 경우 초기 화재 검출의 성능을 지속적으로 향상시킬 수 있을 것으로 판단된다.","Pre-prediction and early detection are important for the prevention of fires. Hence, the integration of intelligent CCTVimage analysis technology, deep learning, and artificial intelligence is actively being studied. Intelligent CCTV can analyzevisible light images of fires, but the accuracies of the detection targets are low. To solve this problem, a dual sensingexperimental device was constructed by combining a visible light sensor and a thermal image sensor, and an algorithm wasimplemented to predict fire events. An algorithm was constructed to detect three classes (Fire, Smoke, and Person) throughRGB sensors and thermal imaging sensors. Additionally, a CNN deep learning method and the YOLOv5 method were usedto build a classification neural network. The dual sensing device was able to act as a trigger to predict and detect a firebased on the size of the flame and changes in temperature."
골전도 헤드폰 형태로 추출된 골전도 음성 신호의 딥러닝 활용,2024,"['Bone conduction', 'Bone-conducted speech signals', 'Automatic speech recognition', 'Deep learning']",,"In this study, we used deep learning to align bone-conducted speech signals with air-conducted speech signals, aiming to replace traditional air conduction microphones in voice-based services capturing surrounding sounds. We fabricated headphones, placing bone conduction microphones on the rami (the branches of a bone in the jaw area), in line with traditional bone conduction headphone configurations. Using LSTM, CNN, and CRNN models, we created databases that aligned bone-conducted speech signals with their air-conducted counterparts and tested them with bone-conducted speech signals captured via our custom-made headphones. The CNN model demonstrated superior performance in accurately distinguishing three English words (“apple,” “hello,” and “pass”), including their voiceless pronunciations. In conclusion, our study shows that deep learning models can effectively use bone-conducted speech signals extracted from the rami for automatic speech recognition (ASR), paving the way for future ASR technology that precisely recognizes only the speaker’s voice."
신체 움직임 분석을 위한 모션 비전 시스템 개발 연구,2024,"['운동 모션', '영상분석', '실시간 움직임 분석', '오픈포즈', '인공지능', 'ExeRcise Motion', 'Image Analysis', 'Real-Time Motion Analysis', 'Open Pose', 'Artificial Intelligence']","요약본 연구에서는 실시간 모션 분석 시스템을 개발하고 검증하기 위해 데이터 수집, 알고리즘 개발, GUI 및 소프트웨어 테스트 등을 수행하였다. 먼저, 데이터 수집 및 전처리 결과로 다양한 운동 동작을 수행하는 참여자의 영상을 촬영하여 이미지 데이터를 수집하고, 관절 위치 정보를 라벨링하여 학습 데이터를 구축하였다. 이를 통해 모델이 운동 동작을 정확하게 인식하고 분석할 ]수 있도록 체계적으로 데이터를 구성하였다. 다음으로, Convolutional Neural Network (CNN)과 Part Affinity Fields (PAFs) 알고리즘을 활용하여 관절 위치 추출과 관절 각도 계산을 수행하였으며, 이를 통해 객체의 동작 분석 및 상호작용 예측에 유용한 결과를 얻을 수 있었다. GUI 개발 결과로는 모션 데이터의 실시간 시각화 및 분석을 가능케 하는 다양한 기능을 개발하였으며, 입력된 영상 위에 오버레이로 모션 데이터를 시각적으로 표시하고, 감지된 인원 수, FPS, 프레임수 등의 정보를 제공하여 사용자에게 편리한 환경을 제공하였다. 소프트웨어 실행 결과에서는 실시간으로 참여자의 동작을 탐지하고, 관절 위치를 정확하게 출력하였으며, OpenPose 라이브러리를 활용하여 실시간 캠 촬영을 통해 프레임을 움직임을 실시간으로 인식하였으며, 관절의 각도 또한 직관적인 측정 App을 통해 측정을 오차범위 안으로 검증하였다.","AbstractIn this study, data collection, algorithm development, GUI and software tests were performed to develop and verify a real-time motion analysis system. First, image data were collected by photographing images of participants performing various exercise movements as a result of data collection and preprocessing, and training data was constructed by labeling joint location information. Through this, the data was systematically constructed so that the model could accurately recognize and analyze the exercise motion. Next, joint position extraction and joint angle calculation were performed using the Convolutional Neural Network (CNN) and Part Affinity Fields (PAFs) algorithms, and through this, useful results were obtained for analyzing the motion of objects and predicting the interaction. As a result of GUI development, various functions were developed to enable real-time visualization and analysis of motion data, and motion data was visually displayed as an overlay on the input image, and information such as the number of detected people, FPS, and frames was provided to provide a convenient environment to users. In the software execution results, participants' movements were detected in real-time, joint positions were accurately output, frame movements were recognized in real-time through real-time cam shooting using the OpenPose library, and the angle of the joint was also verified within the error range through an intuitive measurement app."
교량 모니터링 시스템의 취득데이터 오류신호 검지,2024,"['시설물 노후화', '유지관리', '모니터링 데이터', '오류신호 검지', 'Infrastructure aging', 'Maintenance and management', 'Monitoring data', 'Anomaly signal detection']",공용년수 30년을 초과하는 노후 SOC 시설물이 지속적으로 증가하고 있는 추세에서 시설물의 구조적 안전사고 발생위험성이 함께 증가하고 있어 시설물의 효과적 유지관리를 위한 모니터링 시스템 구축 및 운영이 필수적이다. 시설물의 비정상 거동 등으로 인해 발생하는 데이터는 일반적 상황에서 수집되는 데이터와 상이한 경향 또는 계측치를 나타내어 이러한 오류신호를 통해 시설물의 현재 상태및 앞으로의 상태를 예측할 수 있다. 본 연구에서는 다중선형회괴(MMLR) 학습 오류신호 검지 기법과 합성곱 신경망(CNN) 오류신호검지 기법을 활용하여 기존의 시설물 모니터링 데이터에 적용하여 기존 시설물 감시에 활용하고 있는 구조적 허용치 기반의 이상검지기법이 감지하지 못하는 비일상적 비정상적 데이터 오류신호의 검지 성능을 확인하였다.,"As aging SOC (Social Overhead Capital) facilities exceeding 30 years of service life continue to rise, the risk of structural safety incidentsin these facilities also increases. This underscores the necessity for establishing and operating an effective monitoring system for facilitymaintenance. Data generated by abnormal behavior in facilities often deviates in patterns or measurements from data collected undernormal conditions, allowing these anomalies to provide insights into the facility’s current and future state. This study applies a MultipleLinear Regression (MMLR) anomaly detection technique and a Convolutional Neural Network (CNN) anomaly detection technique toexisting facility monitoring data. By doing so, it evaluates the performance of these methods in detecting abnormal, non-routine anomaliesthat may not be identified by conventional structural threshold-based anomaly detection methods currently used in facility monitoring."
DNN을 위한 비트 단위 파라미터 조작 프레임워크 및 파라미터와 정확도 간의 상호 연관성 분석,2024,"['딥 뉴럴 네트워크', '파라미터', '비트 연산', '정확도', '강인성', 'Deep Neural Network', 'parameters', 'bit-wise operations', 'accuracy', 'robustness']","최근 DNN이 다양한 산업에 확산되면서 IoT 기기 및 엣지 컴퓨팅에 적합한 경량 모델에 관한 연구가 급증하고 있 다. 본 논문에서는 기존에 없던 딥러닝 모델의 파라미터를 1 비트 단위로 조작할 수 있는 자동화 프레임워크를 개발 하며 파라미터 비트와 모델 정확도 사이의 관계를 실험 및 연구한다. 본 연구는 제안된 프레임워크를 사용하여 ImageNet 데이터셋으로 사전 학습된 DNN 모델 중 CNN 모델들의 파라미터를 하위 n-bit를 0, 1 또는 랜덤한 값으로 치환하는 3가지 방법을 통해 각각 정보 손실 발생시키면서 파라미터와 정확도 간의 강인성을 비트 단위로 실험하였다. 주요 모델로는 InceptionV3, InceptionResnetV2, ResNet50, Xception, DenseNet121, Mobile NetV1, MobileNetV2 을 사용하였다. 실험 결과, 성능이 낮은 모델일수록 하위 비트의 정보 손실에 민감하여 성 능이 좋은 모델보다 정확도를 유지하는 비트 수가 적다는 것을 실험적으로 확인했고, 파라미터와 정확도 간의 강인 성이 높다는 것을 확인하였다. 이러한 실험을 바탕으로 모델별 유효 파라미터 비트를 설정하여 파라미터를 줄이며 정확도를 유지할 수 있다.","Recently, with the proliferation of DNNs in various industries, there has been a surge in research on lightweight models suitable for IoT devices and edge computing. In this paper, we propose an automated framework that enables manipulation of deep learning model parameters at a 1-bit level, a capability not previously available. We investigate the relationship between parameter bits and model accuracy. Using the developed framework, we systematically experimented with the parameters of CNN models pre-trained on the ImageNet dataset by setting the lower n-bit to 0, 1, or a random value while each method inducing distinct information loss. The primary models evaluated include InceptionV3, InceptionResnetV2, ResNet50, Xception, DenseNet121, MobileNetV1, and MobileNetV2. Experimental results show that models with lower performance are more sensitive to information loss in the lower bits, requiring fewer bits to maintain accuracy compared to high-performing models. This concludes a high robustness between parameters and accuracy."
ECG 데이터 비식별화 기반의 Model Extraction Attack 방어 기법,2024,"['Model Extraction Attack', 'De-identification', 'Deep Learning', 'ECG Data', 'Deep Learning']",,
YOLOv5 및 다항 회귀 모델을 활용한사과나무의 착과량 예측 방법,2024,"['Deep Learning', 'Object recognition', 'Fruit number counting', 'YOLO series', 'Regression']","본 논문은 딥러닝 기반 객체 탐지 모델과 다항 회귀모델을 이용하여 사과나무에 열린 사과의 개수를 예측할 수 있는 새로운 알고리즘을 제안한다. 사과나무에 열린 사과의 개수를 측정하면 사과 생산량을 예측할 수 있고, 농산물 재해 보험금 산정을 위한 손실을평가하는 데에도 활용할 수 있다. 사과 착과량 측정을 위해 사과나무의 앞면과 뒷면을 촬영하였다. 촬영된 사진에서 사과를 식별하여 라벨링한 데이터 세트를 구축하였고, 이 데이터 세트를 활용하여 1단계 객체 탐지 방식의 CNN 모델을 학습시켰다. 그런데 사과나무에서 사과가 나뭇잎, 가지 등으로 가려진 경우 영상에 포착되지 않아 영상 인식 기반의 딥러닝 모델이 해당 사과를 인식하거나추론하는 것이 어렵다. 이 문제를 해결하기 위해, 우리는 두 단계로 이루어진 추론 과정을 제안한다. 첫 번째 단계에서는 영상 기반딥러닝 모델을 사용하여 사과나무의 양쪽에서 촬영한 사진에서 각각의 사과 개수를 측정한다. 두 번째 단계에서는 딥러닝 모델로 측정한 사과 개수의 합을 독립변수로, 사람이 실제로 과수원을 방문하여 카운트한 사과 개수를 종속변수로 설정하여 다항 회귀 분석을수행한다. 본 논문에서 제안하는 2단계 추론 시스템의 성능 평가 결과, 각 사과나무에서 사과 개수를 측정하는 평균 정확도가90.98%로 나타났다. 따라서 제안된 방법은 수작업으로 사과의 개수를 측정하는 데 드는 시간과 비용을 크게 절감할 수 있다. 또한,이 방법은 딥러닝 기반 착과량 예측의 새로운 기반 기술로 관련 분야에서 널리 활용될 수 있을 것이다.","In this paper, we propose a novel algorithm for predicting the number of apples on an apple tree using a deeplearning-based object detection model and a polynomial regression model. Measuring the number of apples on anapple tree can be used to predict apple yield and to assess losses for determining agricultural disaster insurancepayouts. To measure apple fruit load, we photographed the front and back sides of apple trees. We manuallylabeled the apples in the captured images to construct a dataset, which was then used to train a one-stage objectdetection CNN model. However, when apples on an apple tree are obscured by leaves, branches, or other parts ofthe tree, they may not be captured in images. Consequently, it becomes difficult for image recognition-based deeplearning models to detect or infer the presence of these apples. To address this issue, we propose a two-stageinference process. In the first stage, we utilize an image-based deep learning model to count the number of applesin photos taken from both sides of the apple tree. In the second stage, we conduct a polynomial regression analysis,using the total apple count from the deep learning model as the independent variable, and the actual number ofapples manually counted during an on-site visit to the orchard as the dependent variable. The performanceevaluation of the two-stage inference system proposed in this paper showed an average accuracy of 90.98% incounting the number of apples on each apple tree. Therefore, the proposed method can significantly reduce thetime and cost associated with manually counting apples. Furthermore, this approach has the potential to be widelyadopted as a new foundational technology for fruit load estimation in related fields using deep learning."
An Ensemble Deep Transfer Learning Model for Multi-dimensional Image Classification of Histological Prostate Biopsy Patterns,2024,"['Multi-dimensional', 'Histological', 'Prostate Cancer', 'Ensemble Deep Transfer Learning', 'Image Classification']",,"Early prostate cancer diagnosis by pathologists remains challenging. Recent advances in computer-aided detection (CAD), artificial intelligence (AI), and machine learning (ML) allow prostate cancer grading. This study explored the accuracy of prostate cancer detection by deep learning techniques, particularly convolutional neural networks (CNNs). We performed three-way binary classification based on images cropped to 256 × 256 and 512 × 512 pixels using an ensemble deep CNN model. Six pre-trained CNN models (MobileNet, VGG-16, ResNet-50, DenseNet-121, Inception-V3, and EfficientNet-B0) were integrated to classify histopathological features. The overall accuracy for the combined 256 × 256 and 512×512 pixel images was 94.9%. Additionally, in separate classifications of 256×256 and 512×512 images, we achieved overall accuracies of 90.8% and 94.3%, respectively. Consequently, our method effectively distinguishes benign from malignant samples, approaching near-perfect accuracy."
강교량 도장열화에 따른 백아화 평가와 상태평가 방법,2024,"['강교량', '백아화', '색차', '도막두께', '머신러닝', 'Steel bridge', 'Paint chalking', 'Color difference', 'Paint coating thickness', 'Machine learning']","본 연구에서는 강교량 도장의 백아화와 상태평가 방법을 분석하기 위하여 공용 중 강교량 20개를 선정하여 색차, 백아화, 도장두께를 측정하였다. 색차계를 활용하여 색차를 측정하고, 테이프법과 표준사진을 활용하여 백아화 등급을 평가하였으며, 백아화 제거 전후의 도장두께를 측정하여 백아화 발생 수준에 따른 도장두께 감소량을 평가하였다. 색차 분석 결과, 도장계의 색상에 따라 상대적으로 색차가 발생하는 것을 확인할 수 있었으며, 흰색 도장계는 백아화가 발생하더라도 색차가 나타나지 않는 것을 알 수 있었다. 백아화 등급과 도장두께 평가 결과, 백아화는 외측에 위치한 강부재에 발생하였으며, 백아화가 발생함에 따라 도장두께가 감소하는 경향이나타났다. 또한, 도장두께는 백아화 수준이나 상대적인 편차에 따라 감소량이 상대적일 수 있음을 확인하였다. 추가적으로, 백아화 등급 평가 방법을 간소화하기 위한 방법으로 사진촬영 이미지만으로 백아화를 평가할 수 있는 Convolutional Neural Network (CNN)을머신러닝 기법으로 적용하여 분석하였다.","In this study, to analyze the paint chalking and condition evaluation methods of the steel bridges, 20 public steel bridges were selected and the color difference, paint chalking, and coating thickness were measured. The color difference was measured using a colorimeter, and the grades of paint chalking were evaluated using the tape method and standard photos. The paint coating thickness before and after removing the paint chalking was measured to evaluate the reduction of the paint coating thickness depending on the paint chalking level. From a result of color difference analysis, it was confirmed that a relative color difference occurred depending on the color of the paint type, and it was found that white paint showed color difference even if paint chalking occurred. In addition, it was confirmed that the reduction in paint coating thickness may be relative depending on the level of paint chalking or relative deviation. Furthermore, as a method to simplify the evaluation process of paint chalking, a machine learning model that can evaluate its grade using only photographic images was analyzed by CNN(Convolutional Neural Network)."
스미스 차트를 이용한 구리 인터커텍트의 비파괴적 부식도 평가,2024,"['Artificial intelligence', 'Cu interconnects', 'Corrosion', 'Non-destructive evaluation', 'Smith chart', '.']","전자패키지 내부의 부식이 시스템 성능 및 신뢰성에 큰 영향을 미치고 있어, 시스템 건전성 관리를 위해 부식에대한 비파괴적 진단 기법의 필요성이 커지고 있다. 본 연구에서는 복소 임피던스의 크기와 위상을 통합적으로 시각화하는도구인 스미스 차트를 활용하여, 구리 인터커넥트의 부식을 비파괴적으로 평가하는 방법을 제시하고자 한다. 실험을 위해구리 전송선을 모사한 시편을 제작하고, MIL-STD-810G 기준 온습도 사이클에 노출시켜 시편에 부식을 인가하였다. R 채널 기반 색변화로 시편의 부식도를 정량적으로 평가하고 레이블링 하였다. 부식의 성장에 따라 시편의 S-파라미터와 스미스 차트를 측정한 결과, 5 단계의 부식도에 따라 유의미한 패턴의 변화가 관찰되어, 스미스 차트가 부식도 평가에 효과적인 도구임을 확인하였다. 더 나아가 데이터 증강을 통해 다양한 부식도를 갖는 4,444개의 스미스 차트를 확보하여, 스미스차트를 입력 받아 구리 인터커넥트의 부식 단계를 출력하는 인공지능 모델을 학습시켰다. 이미지 분류에 특화된 CNN 및Transfomrer 모델을 적용한 결과, ConvNeXt 모델이 정확도 89 .4%로 가장 높은 부식 진단 성능을 보였다. 스미스 차트를이용하여 전자패키지 내부 부식을 진단할 경우, 전자신호를 이용하는 비파괴적 평가를 수행할 수 있다. 또한. 신호 크기와위상 정보를 통합적으로 시각화 하여 직관적이며 노이즈에 강건한 진단이 가능할 것으로 기대한다.","Corrosion inside electronic packages significantly impacts the system performance and reliability, necessitating non-destructive diagnostic techniques for system health management. This study aims to present a non-destructive method for assessing corrosion in copper interconnects using the Smith chart, a tool that integrates the magnitude and phase of complex impedance for visualization. For the experiment, specimens simulating copper transmission lines were subjected to temperature and humidity cycles according to the MIL-STD-810G standard to induce corrosion. The corrosion level of the specimen was quantitatively assessed and labeled based on color changes in the R channel. S-parameters and Smith charts with progressing corrosion stages showed unique patterns corresponding to five levels of corrosion, confirming the effectiveness of the Smith chart as a tool for corrosion assessment. Furthermore, by employing data augmentation, 4,444 Smith charts representing various corrosion levels were obtained, and artificial intelligence models were trained to output the corrosion stages of copper interconnects based on the input Smith charts. Among image classification-specialized CNN and Transformer models, the ConvNeXt model achieved the highest diagnostic performance with an accuracy of 89.4%.When diagnosing the corrosion using the Smith chart, it is possible to perform a non-destructive evaluation using electronic signals. Additionally, by integrating and visualizing signal magnitude and phase information, it is expected to perform an intuitive and noise-robust diagnosis."
샌드위치 복합재의 결함 탐지 및 정량화를 위한 일치 추적 분해 기반 디노이징 기법 개발,2024,"['matching pursuit decomposition', 'sandwich composite', 'deep learning', 'signal preprocessing', '일치 추적 분해', '샌드위치 복합재', '딥러닝', '신호 전처리']","본 논문에서는 일치 추적 분해를 활용한 샌드위치 복합재의 결함 탐지 및 정량화 방법을 소개한다. 샌드위치 복합재 시편을 제작하기 위해 핸드 레이-업 공법과 핫 프레스 공법을 활용하여 결함이 존재하는 시편과 없는 시편을 제작하였다. 결함의 위치와 정도를 파악하기 위해 플래시 서모그래피를 활용하여 확인하였다. 각각의 시편에서 데이터를 확보하기 위해 pitch-catch법을 활용한 초음파 전파 실험을 설정하였고, 샌드위치 복합재의 표면에 부착한 압전 센서를 통해 데이터를 확보하였다. 획득한 신호는 일치 추적 분해를 이용하여 추정 및 분해하고, 고속 푸리에 변환과 웨이블릿 변환 기반 노이즈 제거 방법과의 성능을 비교하였다. 노이즈를 제거한 신호는 각각 동일한 구조의 1-D CNN 모델에 훈련하여 성능을 비교하였다. 제안한 일치 추적 분해 기반 신호 노이즈 제거는 기존의 방법보다 높은 정확도, 안정성, 훈련 속도를 보였으며, 시간-주파수 영역에서 보다 직관적인 모드 분리를 확인하여 특성 추출을 통한 일치 추적 분해 기반 신호 전처리 및 딥러닝 모델 훈련의 가능성을 확장할 수 있음을 확인하였다.","In this paper, a damage detection and quantification method for sandwich composites using matching pursuit decomposition (MPD) is presented. Sandwich composites with and without delamination were fabricated using the hand lay-up and hot-press methods, and the location and size of delamination were confirmed using flash thermography. An ultrasonic wave propagation experiment using the pitch-catch method was set up to collect data from healthy and damaged samples. The acquired signals were estimated and decomposed using MPD and compared with signals denoised using fast Fourier and wavelet transforms. The denoised signals were trained by a 1-D CNN model with the same number of layers and filters.. The proposed method showed improved accuracy and stability than the traditional method. In addition, more reliable mode separation in the time-frequency representation could be confirmed, extending the possibility of MPD-based signal preprocessing in deep learning training."
Real-Time CCTV Based Garbage Detection for Modern Societies using Deep Convolutional Neural Network with Person-Identification,2024,"['Convolutional neural network', 'CCTV camera', 'deep learning', 'garbage detection', 'real-time detection']",,"Trash or garbage is one of the most dangerous health and environmental problems that affect pollution. Pollution affects nature,human life, and wildlife. In this paper, we propose modern solutions for cleaning the environment of trash pollution by enforcingstrict action against people who dump trash inappropriately on streets, outside the home, and in unnecessary places. ArtificialIntelligence (AI), especially Deep Learning (DL), has been used to automate and solve issues in the world. We availed this as anexcellent opportunity to develop a system that identifies trash using a deep convolutional neural network (CNN). This paperproposes a real-time garbage identification system based on a deep CNN architecture with eight distinct classes for the trainingdataset. After identifying the garbage, the CCTV camera captures a video of the individual placing the trash in the incorrectlocation and sends an alert notice to the relevant authority."
딥러닝 알고리즘 적용한 한국여자프로골프 선수들의 컷 통과 예측 및 성능 평가,2024,"['Deep Learning Algorithms', 'Multilevel Wavelet Decomposition Network', 'KLPGA', 'Cutoff Prediction', 'Sport Analytics', '딥러닝 알고리즘', '다층 웨이블릿 분해 네트워크', '한국여자프로골프', '컷 통과 예측', '스포츠 애널리틱스']","한국여자프로골프(KLPGA, 이하 KLPGA)는 세계에서 가장 파급력 있는 여자프로골프투어 중 하나로 대회 마지막까지 플레이를 할 수 있는 자격이 주어지는 컷 통과 여부는 선수 개인적으로나 산업적으로 중요하다. 최근 인공지능과 빅데이터의 발달로 스포츠 경기결과를 예측하는 연구가 활발하게 수행되며 산업적으로도 활용되고 있지만 아직 KLPGA컷 통과 여부를 예측하는 연구는 발견하기 힘든 실정이다. 본 연구는 이러한 연구 공백을 해결하기 위해 KLPGA 대회에서 선수들의 컷 통과여부를 딥러닝 알고리즘을 적용하여 선행적으로 예측하고자 수행되었다. 이를 위해 KLPGA 홈페이지에 공개된 전체 데이터를 체계적으로 수집하고, 이를 3개의 딥러닝 알고리즘(LSTM, CNN, mWDN)을 기반으로 예측 모형에 구축하여 선수들의 대회 컷 통과 여부를 실증적으로 예측하였다. 실증결과 KLPGA 선수들의 대회 컷 통과여부를 실질적으로 가장 잘 예측한 딥러닝 알고리즘은 다층 웨이블릿 분해 네트워크(mWDN)로 F1-score= 0.75로 나타났다. 2023년에 KLPGA투어에서 개최된 총상금 상위 3개 대회의 컷 통과 여부를 딥러닝 알고리즘 기반 예측된 선수 리스트와 실제 컷 통과 선수 리스트를 비교한 결과, 352명 중 276명(78.4%)의 컷 통과 여부를 정확히 예측하였다. 본 연구는 국내 최초로 딥러닝 알고리즘을 적용하여 KLPGA 선수들의 컷 통과 여부를 실질적으로 예측하고 실증적인 선수 리스트를 도출한 연구라는 점에서 이를 프로골프 산업에 적용할 수 있는 학문적 의의와 실무적 시사점을 지닌다.","The Korean Ladies Professional Golf Association (KLPGA) is one of the most influential womens professional golf tours in the world, and the qualification to play until the end of the tournament, determined by whether a player passes the cut or not, is important for both players and industry. Recently, with the development of artificial intelligence and big data, research on predicting sports game results has been actively conducted and industrially utilized. However, research on predicting cut off in KLPGA tournaments is still scarce. This study aimed to address this research gap by applying deep learning algorithms to predict players cut off in KLPGA tournaments. To achieve this, data was collected from KLPGA website and built prediction models based on three deep learning algorithms (LSTM, CNN, mWDN) to empirically predict players cut outcomes. The empirical results showed that the multi-level wavelet decomposition network (mWDN) was the most effective deep learning algorithm for predicting KLPGA players cut outcomes, with an F1-score of 0.75. When comparing the predicted player list based on deep learning algorithms with the actual list of players who passed the cut in the top three tournaments with the highest prize money held during the 2023 KLPGA tour, it accurately predicted the cut outcomes of 276 out of 352 players (78.4%). This study holds academic significance and practical implications for the golf industry as the first in South Korea to empirically predict KLPGA players cut outcomes using deep learning algorithms and derive a practical list of players."
Deep Learning-based Delinquent Taxpayer Prediction: A Scientific Administrative Approach,2024,"['Deep learning', 'financial machine learning', 'local tax delinquency', 'tax defaulter prediction', 'tax information systems']",,"This study introduces an effective method for predicting individual local tax delinquencies using prevalent machine learning and deep learning algorithms. The evaluation of credit risk holds great significance in the financial realm, impacting both companies and individuals. While credit risk prediction has been explored using statistical and machine learning techniques, their application to tax arrears prediction remains underexplored. We forecast individual local tax defaults in Republic of Korea using machine and deep learning algorithms, including convolutional neural networks (CNN), long short-term memory (LSTM), and sequence-to-sequence (seq2seq). Our model incorporates diverse credit and public information like loan history, delinquency records, credit card usage, and public taxation data, offering richer insights than prior studies. The results highlight the superior predictive accuracy of the CNN model. Anticipating local tax arrears more effectively could lead to efficient allocation of administrative resources. By leveraging advanced machine learning, this research offers a promising avenue for refining tax collection strategies and resource management."
재난 현장 인명 구조를 위한 딥러닝 기반 잡음 제거 및 음향 분류,2024,"['Noise reduction', 'Disaster site', 'Wiener filtering']","도시 재난 현장에서는 다양한 형태의 잡음이 발생하여 인명 탐지 및 구조 작업의 정확도와 효율성을 저하시킬 수 있다. 이를 해결하기 위해 본 연구는 Wave-U-Net 기반의 딥러닝 모델과 Wiener 필터를 결합한 잡음 제거 방법을 제안하였다. 깨끗한 오디오 신호와 다양한 잡음을 합성하여, 깨끗한 신호 (data1), 잡음 제거를 적용한 신호 (data2), 추가로 Wiener 필터를 적용한 신호 (data3)로 구성된 데이터셋을 생성하였다. 데이터셋은 SNR 0 dB부터 30 dB까지 5 dB 단위로 다양한 잡음 수준에서 생성되었으며, 이를 사용하여 각각의 모델을 학습하였다. 제안된 잡음 제거 방법의 효과를 평가하기 위해 Simple CNN (Convolutional Neural Network), XGBoost (eXtreme Gradient Boosting), SVM (Support Vector Machine)을 사용하여 각 데이터셋의 성능을 측정하였다. 실험 결과, SNR 0 dB에서 5 dB 구간에서는 잡음 제거가 성능 향상에 긍정적인 영향을 미쳤으나, SNR 10 dB 이상의 환경에서는 잡음 제거가 오히려 성능 저하를 초래하였다. 이는 잡음이 적은 환경에서 과도한 잡음 제거가 신호 왜곡을 일으키거나, 불필요한 신호 처리로 인해 원래 신호의 품질을 손상시킬 수 있기 때문이다. 본 연구는 복잡한 잡음 환경에서 잡음 제거의 효과를 확인하였으며, 향후 연구는 SNR 10 dB 이상의 고잡음 환경에서도 성능을 유지할 수 있는 방법을 탐색하는 데 중점을 두어야 한다.","Urban disaster sites often experience various types of noise, which can significantly hinder the accuracy and efficiency of human detection and rescue operations. To address this issue, this study proposes a noise reduction method that combines a Wave-U-Net-based deep learning model with a Wiener filter. Clean audio signals and various types of noise were synthesized to create a dataset consisting of clean signals (data1), signals with noise reduction applied (data2), and signals with an additional Wiener filter applied (data3). The dataset was generated at noise levels ranging from SNR 0 dB to 30 dB in 5 dB increments, and each model was trained using these datasets. To evaluate the effectiveness of the proposed noise reduction method, the performance of Simple CNN (Convolutional Neural Network), XGBoost (eXtreme Gradient Boosting), and SVM (Support Vector Machine) was measured on each dataset. Experimental results showed that noise reduction had a positive effect on performance in the SNR 0 dB to 5 dB range, but in environments with SNR levels above 10 dB, noise reduction led to performance degradation. This degradation is likely due to over-suppression of noise in lower-noise environments, which can distort the signal or result in unnecessary signal processing that harms the original signal quality. This study demonstrates the effectiveness of noise reduction in complex noise environments and highlights the need for further research to develop methods that maintain performance in higher SNR environments, particularly above 10 dB."
삼차원 합성곱 신경망과 X선 단층 영상에서 추출한 형태학적 특징을 이용한 PEMFC용 가스확산층의 투과도 예측,2024,"['가스확산층', '고분자 전해질막 연료전지', '삼차원 합성곱 신경망', '미세구조', 'Gas Diffusion Layer', 'Proton Exchange Membrane Fuel Cell', '3D Convolutional Neural Network', 'Microstructure']","본 연구에서는 고분자 전해질막 연료전지용 가스확산층의 투과도를 예측하기 위해 삼차원 합성곱 신경망 모델을 사용하는 방법론을 소개한다. 먼저, 기계학습 모델을 학습시키기 위해 X-선 단층 촬영을 통해 얻은 실제 가스확산층 이미지에서 형태학적 특성을 추출해 가스확산층의 대표 체적 요소로 이루어진 인공 데이터셋을 생성한다. 이러한 형태학적 특성은 다공성, 섬유 배향, 직경의 통계적 분포가 포함된다. 구축한 인공 데이터셋 대표 체적 요소들의 투과도를 평가하기 위해 격자 볼츠만 방법이 사용되었으며 각각의 대표 체적 요소들의 투과도를 도출하였다. 이러한 인공 데이터셋을 통해 삼차원 합성곱 신경망 모델을 학습시켰으며 인공 데이터셋을 학습한 삼차원 합성곱 신경망 모델이 실제 가스확산층의 대표 체적 요소 투과도 또한 잘 예측하는 것을 확인하였다.","In this research, we introduce a novel approach that employs a 3D convolutional neural network (CNN) model to predict the permeability of Gas Diffusion Layers (GDLs). For training the model, we create an artificial dataset of GDL representative volume elements (RVEs) by extracting morphological characteristics from actual GDL images obtained through X-ray tomography. These morphological attributes involve statistical distributions of porosity, fiber orientation, and diameter. Subsequently, a permeability analysis using the Lattice Boltzmann Method (LBM) is conducted on a collection of 10,800 RVEs. The 3D CNN model, trained on this artificial dataset, well predicts the permeability of actual GDLs."
인공지능 기반 열간단조 이형제 분사 및 도포관리시스템 개발,2024,"['열간단조', '이형제', '코팅관리', '적층 제조', '인공지능', 'Hot Forging', 'Release Agent', 'Coating Management', 'Additive Manufacturing', 'Artificial Intelligence']","열간단조 이형제 분사 기술은 열간단조 공정 중의 하나로, 다양한 금속 소재를 가열한 상태에서 압력을 가해 물체의 형상을 변형하는 기술로 자동차 산업, 항공우주 산업, 기계산업 등 다양한 산업 분야 활용되고 있다. 기존의 열간 단조 이형제 분사 기술은 주로 수작업을 통하여 진행하고 있기 때문에 금속 소재 낭비, 운영 비용 증가 등의 문제점들이 발생한다. 본 논문에서는 이러한 기존 열간단조 이형제 분사 방식의 문제점 및 한계점을 극복하기 위하여 인공지능을 활용한 이형제 분사량과 도포품질 측정 기술을 개발하고자 한다. 이를 위하여 이형제 분사 및 도포관리시스템에서 가장 중요한 이형제 분사 측정과 도포 품질 분석을 위하여 인공지능 기법을 적용한다. 세부적으로 이미지 증강에는 GAN(Generative Adversarial Network), 분사형상 검출에는 YOLO(You Only Look Once), 분사량 측정에는 Linear Regression을, 도포품질 분석에는 CNN(Convolutional Neural Network)과 SVM(Support Vector Machine)을 각각 적용한다.","The hot forging compound injection technique is one of the processes in hot forging where various metal materials are heated and pressure is applied to deform the shape of the object, and this technology is utilized in various industries, including the automotive, aerospace, and machinery sectors. The conventional hot forging compound injection technique has some issues as it mainly relies on manual labor, leading to several problems such as metal material waste and increased operating costs. In this paper, we aim to overcome these issues and limitations of the conventional hot forging compound injection method by developing an artificial intelligence-based technique for measuring the injection amount and coating quality. In detail, Generative Adversarial Network(GAN) is employed for image augmentation, You Only Look Once(YOLO) for injection pattern detection, Linear Regression for injection volume measurement, and Convolutional Neural Network(CNN) along with Support Vector Machine (SVM)for coating quality analysis."
시계열 데이터를 이용한 인공신경망 기반 공작기계 가공상태 모니터링,2024,"['공작기계', '시계열 데이터', '인공신경망', '합성곱 신경망', '장단기 메모리', 'Machine tool', 'Time series data', 'Artificial neural network', 'Convolution neural network', 'Long short-term memory']",,"In order to monitor the machining status of a machine tool, it is necessary to measure the signal of the machine tool and establish the relationship between the machining status and the signal. One effective approach is to utilize an AI-based analysis model. To improve the accuracy and reliability of AI models, it is crucial to identify the features of the model through signal analysis. However, when dealing with time series data, it has been challenging to identify these features. Therefore, instead of directly applying time series data, a method was used to extract the best features by processing the data using techniques such as RMS and FFT. Recently, there have been numerous reported cases of designing AI models with high accuracy and reliability by directly applying time series data to find the best features, particularly in the case of AI models combining CNN and LSTM. In this paper, time series data obtained through a gap sensor are directly applied to an AI model that combines CNN, LSTM, and MLP (Multi-Layer Perceptron) to determine tool wear. The machine tool and tool status were monitored and evaluated through an AI model trained using time series data from the machining process."
메니에르병에서 내이 자기공명영상의 활용,2024,"['Hearing loss', 'Magnetic resonance imaging', 'Meniere disease', 'Vertigo.']",,"Ménière’s disease (MD) is one of the diseases that greatly reduces the quality of life, causingrepeated dizziness, hearing loss, and tinnitus. There have been various efforts to diagnoseMD and predict its prognosis, but even today, hearing test is the only objective test included inthe diagnostic criteria. This is because we lack tools with which we can clearly identify theendolymphatic hydrops (EH), the histologic hallmark of MD. Since the mid-2000s, 3-teslaMRI using a three-dimensional fluid-attenuated inversion recovery sequence has begun to beused to detect the EH of MD. More recently, many clinical studies have been conducted usingthis sequence of MRI, and the diagnostic value of inner ear MRI has thus increased. In particular,with the remarkable development of the convolutional neural network (CNN), the technologyof medical image analysis has also grown dramatically. In this work, we explore howinner ear MRI is clinically used in MD, how CNN is actually used in the diagnosis of MD,and finally consider the diagnostic value of inner ear MRI in the future."
"RETRACTED ARTICLE: Determination of Power Transformer Fault’s Severity Based on Fuzzy Logic Model with GR, Level and DGA Interpretation",2024,['Transformer  · Duval Pentogan Method  · Harris Hawks Optimization  · Dissolved Gas analysis  · Gas Rate'],,"Transformer defects are defi ned by their severity which is the intrinsic property of the transformer. Several approaches for identifying the severity of Power Transformer (PT) problems have previously been proposed; however, most published research does not incorporate Gas Level (GL), Gas Rate (GR), and DGA interpretation into a unifi ed strategy. A novel technique in the form of fuzzy logic (FL) has been off ered as a new way to assess faults’ severity by utilizing the combination of GL, GR, and DGA interpretation from the Duval Pentagon Method (DPM) to increase the reliability of the faults’ severity evaluation of PT. Based on the local population, a four-level typical concentration and rate were created. A Deep Learning (DL) oriented Convolutional Neural Network (CNN) based DPM and Harris Hawks Optimization (HHO) method with a high agreement to that same graphical DPM has also been devised to enable the evaluation of hundreds of PT information easy. The proposed method was applied to 448 PTs, and it was then used to assess the severity of problems in PTs using historical DGA data. Due to the integration of GL, GR, and DGA interpretation results in one technique, this novel strategy yields good agreement with earlier methods, but with better sensitivity."
Anomaly detection of unbalanced rotating shaft based on deep learning and thresholds,2024,"['Bearing', 'Anomaly detection', 'Deep learning', 'Convolutional neural network', 'Threshold']",,"Motors are important machines used in various industries. They provide power to various pumps, air compressors, refrigeration plants, purifiers, and air-conditioning plants. However, the motor may not be optimally coupled with the driven machinery during the repair process, and the bearings may become damaged over time as the machine operates. These problems can cause an imbalance in the motor shaft, thus resulting in vibrations. Therefore, vibrations and abnormal indicators must be detected timely to ensure machine safety. A deep-learning model for anomaly detection based on publicly available bearing data was developed in this study. Bearing data from various experiments were plotted and their characteristics were analyzed. Additionally, the vibration amplitude graphs of certain sections were saved as images. The saved images were categorized into normal and abnormal, and then classified using a convolutional neural network (CNN) model. Evaluation of the model performance on the test set for the trained CNN model shows an accuracy of 0.95, which indicates that the model performs well in distinguishing between normal and abnormal vibration amplitudes.Furthermore, anomaly detection based on vibration-amplitude threshold values was performed."
실사용 환경에 적합한 EMG 기반 손동작 인식을 위한 전처리로서의 Wavelet Transform,2024,"['Electromyograph', 'Hand gesture recognition', 'Actual user-environment Wavelet transform', 'TQWT']","손동작이란 기본적인 잡기 동작뿐만 아니라 의사소통을 위한 제스처 등을 포함하며 사람의 일상생활에서 상당히 중요한 역할을 수행한다. 이러한 손동작을 인식하여 HCI(Human Computer Interface) 로 활용하기 위해 표면근전도(sEMG : Surface Electromyography)를 이용한 손동작 인식 분야는 꾸준히 연구되어 왔다. 근전도 신호는 기본적으로 많은 잡음 요소가 존재하기 때문에 손동작을 인식하기 위해 다양한 전처리 신호처리 기법이 개발되었고, 특히 주파수 분석을 위해 웨이블릿 변환(WT: Wavelet Transform)이 자주 사용된다. 따라서 본 논문에서는 웨이블릿 변환 기반의 3가지의 기법을 비교하여 손동작 인식 분야의 실제 사용 환경에 가장 적합한 기법을 선택한다. 손동작 인식 분야의 주된 목표인 실시간 인식을 위해 각 기법에서의 처리시간과 동작 인식 정확도를 비교하였으며, 비교된 웨이블릿 변환 기법은 각각 DWT(Discrete WT, single level), TQWT(Tunable Q-factor WT), CWT(Continuous WT)이다. 비교에 사용된 데이터세트는 서로 다른 5명의 대상에게 수집된 15가지 손동작을 포함하고 있으며, 먼저 각 3가지 기법으로 특징을 추출하고 딥러닝 분류기(가벼운 CNN)를 사용하여 손동작을 인식한다. 손동작 인식이 이루어지는 각 과정에서 처리시간이 기록되고 최종적으로 15가지 손동작에 대한 평균 정확도가 계산된다. 결과 TQWT와 CWT에서 유사한 약 75%의 평균 정확도를 얻었지만 인식 과정에 소요되는 시간이 TQWT에서 0.08초, CWT에서 0.26초였다. 따라서 정확도 측면에서 비슷한 성능을 보이면서 처리시간이 빠른 TQWT가 손동작 인식의 실제 사용 환경에 적합한 기법임을 보여주었다.","Hand gestures include not only grasping movements but also gestures for communication and using very important role in daily life. The field of hand gesture recognition using surface electromyography (sEMG) has been studied to recognize these hand movements and use them as HCI (Human Computer Interface). Since electromyography signals basically have many noise elements, various pre-processing techniques have been developed to recognize hand gestures, and Wavelet Transform (WT) is frequently used for frequency analysis. Therefore, in this paper, three pre-processing techniques based on wavelet transform are compared to select the most suitable technique for the actual user-environment in the field of hand gesture recognition. Processing time and gesture recognition accuracy in each technique were compared for real-time recognition, which is the main goal of the field of hand gesture recognition, and the compared wavelet transform techniques are DWT (Discrete WT), TQWT (Tunable Q-factor WT), and CWT (Continuous WT). The dataset used in the comparison contains 15 hand gestures collected from five different subjects, first extracting features with each of the three techniques and recognizing hand gestures using a deep learning classifier (light CNN). In each process in which hand gesture recognition is performed, processing time is recorded, and finally, the average accuracy for 15 hand gestures is calculated. The results obtained similar average accuracy of about 75% in TQWT and CWT, but the time required for the recognition process was 0.08 seconds in TQWT and 0.26 seconds in CWT. Therefore, it was shown that TQWT with fast processing time is a suitable technique for the actual user-environment of hand gesture recognition, showing similar performance in terms of accuracy."
항로표지 충돌 방지를 위한 영상 전처리 알고리즘과 딥러닝을 활용한 해상 객체 고속 검출,2024,"['Horizontal line detection', 'vessel detection', 'binarization', 'route sign', 'image segmentation', '수평선 검출', '선박 검출', '이진화', '항로표지', '이미지 분할']","해양에서 사용되는 부이와 같은 항로표지는 항해 중인 선박들에게 정확한 정보를 제공하여 선박이 자신의 위치를 명확히 파악하고, 주변의 위험 지역을 표시하여 안전한 항로를 유지하는데 필수적인 역할을 한다. 하지만, 선박과의 충돌 사고로 인해 부이의 파손 및 복구에 막대한 비용이 소요된다. 이러한 사고를 예방하기 위해 현재 고가형 장비를 사용하기도 하지만 비용 부담 문제로 도입하기 쉽지 않다. 해당 문제를 해결하기 위해 본 논문에서는 임베디드 시스템을 활용한 해상 객체 검출 알고리즘 연구를 진행한다. 기존 연구에서는 수평선 검출을 위해 허프 변환을 사용하였지만, 연산량이 많아 실시간 처리가 어렵다는 한계가 존재한다. 이를 개선하기 위해 본 논문에서는 이미지 분할을 진행한 후, Otsu 알고리즘을 최적화하여 수평선을 검출한다. 또한, 검출된 수평선을 기준으로 선박 충돌 위험성이 높은 구역을 위험 영역(Region of Interest, ROI)으로 설정한다. 위험 영역을 설정한 이후, 수평선 아래에 위치한 영역에서 해상 객체를 검출하고 해당 영역에 CNN(Convolutional Neural Network)모델을 활용하여 해당 객체의 선박 여부를 판별한다. 만약 선박으로 판별된 객체가 위험 영역에 존재하는 경우, 이를 위험 선박으로 간주한다. 제안하는 알고리즘은 항로표지 충돌 사고를 사전에 방지할 수 있다.","Aids to navigation, such as buoys used in maritime environments, play a crucial role in providing accurate information to navigating vessels, enabling them to precisely determine their position and maintain safe routes by marking surrounding hazardous areas. However, collisions between ships and these aids result in substantial costs for buoy damage and repair. While high-end equipment is currently used to prevent such accidents, its widespread adoption is hindered by cost concerns. This paper presents research on a maritime object detection algorithm utilizing embedded systems to address this issue. Previous studies employed the Hough transform for horizon detection, but its high computational demands posed challenges for real-time processing. To overcome this limitation, our approach first performs image segmentation, followed by an optimized Otsu algorithm for horizon detection. Subsequently, we establish a Region of Interest (ROI) based on the detected horizon, focusing on areas with a high risk of ship collision. Within this ROI, particularly below the horizon line, maritime objects are detected. A Convolutional Neural Network (CNN) model is then applied to determine whether the detected objects are ships. Objects classified as ships within the ROI are considered potential collision risks."
Image Compression Using Discrete Wavelet Transform and Convolution Neural Networks,2024,['Discrete wavelet transform  · Convolution neural network  · Entropy encoding'],,"The amount of information is growing very fast and multimedia fi les are the elements of information that occupy more storage. This problem calls for more effi cient image compression techniques to save the cost on storage and transmission.Compression methods are used to convert the image fi les with less memory space compared to the original image. Transform based image compression has its signifi cance in image compression but combining it with the developing technologies like deep learning produce effi cient results. A lossy compression technique is proposed in this paper which incorporates Convolutional Neural Networks (CNNs) to predict wavelet high frequency coeffi cients from low frequency coeffi cients. The main premise of the proposed framework is that information which can be recovered at the decoder via CNN prediction can be excluded from the encoding bit stream that resulting in reduced size. This method of image compression is effi cient compared with the individual methods of transform based and CNN based image compression. From the results, it is observed high PSNR of 42.688 dB, low MSE of 3.5015, high entropy and optimum SSIM of 0.986 is obtained using proposed model by considering X-ray image of chest with compression ratio of 66.351%."
유사하거나 동일한 폐수처리공정에서의 전이학습 적용 유무에 따른 심층학습 알고리즘의 성능 평가,2024,"['전이학습', '심층학습', '합성곱 신경망', '장단기 메모리', '폐수처리공정', '""Transfer learning', 'Deep learning', 'Convolutional neural network', 'Long short-term memory', 'Wastewater treatment process""']","""본 연구에서는 두 개의 인지도가 높은 심층학습 알고리즘을 사용하여 하나의 폐수처리공정에서 다른 폐수처리공정으로의 전이학습의 적용 가능성을 평가하였다. 구체적으로는, 전이학습을 위한 벤치마크 알고리즘으로4개및 3개의 은닉층으로 각각 구성된 합성곱 신경망과 장단기 메모리를 사용하였다. 심층학습과 전이학습을 위해 (진주와 청주시에 위치한) 동일한 처리공정을 가지는 2개의 폐수처리시설로부터 2018년부터 2022년까지 총 5년간의입력 데이터가 제공되었다. 모델의 성능 평가는 평균제곱오차를 기준으로 2개 심층학습과 더불어 2개의 다른 전이학습 적용 방법(사전 훈련된 모델에서 개발된 모든 은닉층을 사용하는 방법과 다수의 은닉층 중 마지막 은닉층만을 훈련에 사용하는 방법)을 채택하여 수행되었다. 평가 결과, 유량 및 생물화학적 산소요구량과 같은 종속 변수에관계없이 합성곱 신경망과 장단기 메모리의 성능은 상대적으로 유사한 것으로 조사되었으며, 다만 유량 변수의 낮은 변동성으로 인하여 생물화학적 산소요구량에 비해 유량 예측의 정확도가 다소 높은 것으로 평가되었다. 기존모델의 모든 은닉층을 사용한 전이학습 기법을 두 가지 벤치마크 알고리즘에 적용한 결과 두 알고리즘 모두 유량에 한정하여 예측 성능이 다소 향상되는 것으로 조사되었다. 또한, 다른 전이학습 기법을 사용한 경우에도 벤치마크 알고리즘의 예측 정확도에는 큰 변화가 없는 것으로 평가되었다. 전이학습의 잠재적인 활용 방안으로는 데이터부족으로 인해 심증학습 기반의 신규 예측 모델 개발이 어려운 타겟 도메인에 (소스 도메인에서 개발된) 기존 모델의 신속한 재사용이 포함될 수 있을 것으로 판단된다.""","""This study assessed the feasibility of transfer learning from one wastewater treatment process to another using two popular deep learning algorithms. Specifically, convolutional neural network (CNN) and long short-term memory (LSTM), which consisted of four and three hidden layers, respectively, were used as benchmark algorithms for transfer learning. Input data for both deep learning and transfer learning were provided from two wastewater treatment plants with identical treatment trains in series (located in Jinju and Cheongju City) over the five-year period from 2018 to 2022. Performance evaluation was also done not only against two deep learning algorithms but also against those adopting two transfer learning strategies, one for freezing all hidden layers developed from the pre-trained model and the other for training the last hidden layer only among multiple ones, with respect to Mean Squared Error (MSE). We found that the performance of both CNN and LSTM was relatively comparative regardless of dependent variables, discharge and biochemical oxygen demand (BOD), whereas the prediction accuracy of both algorithms was slightly higher for discharge than for BOD due to its low variability. When transfer learning which froze all hidden layers of the existing model was applied to two benchmark algorithms, the predictive performance of both algorithms was found to slightly improved only for discharge. Also, there was no measurable variation in the prediction accuracy of benchmark algorithms using the other transfer learning approach.Potential applications of transfer learning include the rapid reuse of the existing models (developed from source domains) for target domains which are hard to develop new prediction models due to the lack of data in deep learning."""
Performance Analysis of Cervical Cancer Detection System Using Fusion Based CFICNN Classifier,2024,"['Cancer', 'Cervical', 'Classifications', 'Dataset', 'Features']",,"This paper proposes a fully computer assisted automated cervical cancer detection method using cervical images. This proposed system consist of six modules as Edge detector, image fusion, Gabor transform, feature computation, classification algorithm and segmentation method. The edge pixels show the contrast edge variations of each pixel in cervical image with respect to its corresponding nearby pixels. Hence, these edge pixels are detected using fuzzy logic and then the edge detected cervical images are fused using arithmetic pixel fusion algorithm. This fused cervical image having the pixels in the form of spatial resolution and hence it is need to be converted into multi-format resolution for computing the features from it. The spatial pixels in fused image are converted into multi orientation pixels using Gabor transform and then features are computed from this Gabor image. In this work, Local Binary Pattern (LBP), Grey Level Co-occurrence Matrix (GLCM) and Pixel Intensity Features (PIF) are computed from the Gabor cervical image. These features have been classified by the Cervical Features Incorporated Convolutional Neural Networks (CFICNN) classification algorithm. The modified version of the Visual Geometry Group- Convolutional Neural Networks (VGG-CNN) architecture is called as Cervical Features Incorporated CNN (CFICNN) and it is proposed in this paper for both training and classification process. Finally, the cancer pixels are segmented using morphological operations based segmentation algorithm.The Guanacaste Dataset (GD) and Kaggle Dataset (KD) are used for estimating performance efficiency."
입찰 문장의 BIM 요구사항 난이도 판별에 대한 문자 임베딩 기반 딥러닝 모델 비교,2024,"['문자 임베딩', '합성곱 신경망', '양방향 장단기기억 신경망', '입찰', 'BIM 요구사항', 'Character embedding', 'Convolutional neural network', 'Bi-directional long-short term memory neural network', 'Bid', 'BIM requirement']","건설사업의 BIM 적용이 의무화됨에 따라 입찰단계에서부터 BIM 요구사항 분석이 중요해지고 있고, 방대한 입찰 텍스트 정보를 효과적으로 처리하기 위한 자연어 처리 연구가 활발히 이뤄지고 있다. 국내 입찰문서는 한글과 영문이 혼재되어 있고 동일 표현에 대한 표기가 불규칙해 전처리를 수행하더라도 텍스트 품질 개선이 제한되고 형태소 분석기 성능에 영향을 받는 등의 어려움이 있어, 분석 모델의 성능 저하의 원인으로 작용한다. 이러한 이유로 본 연구는 전처리에 기인한 성능 저하를 저감할 수 있도록 문자 임베딩을 사용해 입찰 문장에 포함된 BIM 요구사항의 난이도 분류를 수행하는 딥러닝 모델을 제시하였다. 단순 문자 임베딩, 양방향 장단기기억 신경망을 결합한 문자 임베딩, 그리고 합성곱 신경망을 결합한 문자 임베딩 모델에 대한 주요 매개변수 영향을 분석하여 최적 모델을 도출하였고, 문자 임베딩 모델 간 BIM 요구사항 난이도 판별 성능을 비교하였다. 추가로 단어 임베딩 기반의 타 모델 결과와 비교하였다. 세 가지 모델 가운데 합성곱 신경망을 활용한 문자 임베딩 모델이 가장 높은 F1 지표(0.98)를 나타내었으며, F1 변화에 합성곱 필터 수 및 크기가 가장 큰 영향을 미치는 것을 확인하였다. 또한 문자 임베딩 모델 사용을 통해 단어 임베딩 모델 대비 약 15 %의 F1 지표 향상이 가능함을 확인하였다.","With the mandatory application of Building Information Modeling (BIM) in construction projects, the analysis of BIM requirementsfrom the bidding stage has become increasingly important. To effectively handle the vast amount of bid text information, research onnatural language processing has been actively conducted. However, domestic bid documents often contain a mixture of Korean andEnglish, and the inconsistent representation of identical expressions limits text quality improvement even after pre-processing, whichin turn affects the performance of morphological analyzers. These challenges contribute to the degradation of analytical modelperformance. To mitigate performance degradation caused by pre-processing, this study proposes a deep learning model that classifiesthe difficulty level of BIM requirements in bid sentences using character embeddings. The study analyzes the impact of key parameterson three types of character embedding models: a simple character embedding, a character embedding combined with the Bi-directionallong short-term memory layer, and a character embedding combined with the convolutional neural networks (CNN) layer. Based onthis analysis, the optimal model was derived, and the performance of BIM requirement difficulty classification was compared acrossthe character embedding models. Additionally, the results were compared with those of other models based on word embeddings.Among the three models, the character embedding model utilizing CNN achieved the highest F1 score (0.98), with the number andsize of convolutional filters having the most significant impact on F1 score variation. Furthermore, it was confirmed that the use ofcharacter embedding models resulted in an approximately 15% improvement in the F1 score compared to word embedding models."
딥러닝을 활용한 알약인식 및 복용관리 시스템,2024,"['CNN', 'Deep Learning', 'Medication Management', 'Pill Recognition', 'VGGNet']",,"It is difficult to know the efficacy of pills if the pill bag or wrapper is lost after purchasing the pill. Many people do not classify the use of commercial pills when storing them after purchasing and taking them, so the inaccessibility of information on the side effects of pills leads to misuse of pills. Even with existing applications that search and provide information about pills, users have to select the details of the pills themselves. In this paper, we develope a pill recognition application by building a model that learns the formulation and colour of 22,000 photos of pills provided by a Pharmaceutical Information Institution to solve the above situation. We also develope a pill medication management function."
Design of Automatic Defect Classification System  for Wafer Edge Defect Inspection,2024,"['CNN', 'Deep Learning', 'Image Processing', 'Auto Defect Classification', 'Wafer Edge Defect']",,"This paper proposes an automatic defect classification (ADC) system to detect and classify bare wafer edge defects that occur during the extreme wafer thinning process required for advanced chip stacking technologies such as TSV and HBM. The proposed system combines a convolutional neural network (ResNet) with traditional image processing techniques (OpenCV-based frequency domain filtering) to effectively classify and visualize wafer edge defects. Experimental results demonstrate that the system achieves high accuracy in defect classification and detection, providing an efficient solution to prevent wafer damage and yield reduction."
피부병변 영상 분할의 성능향상을 위한 VmCUnet,2024,"['CNN', 'U-net', 'Medical Image Segmentation', 'Vmamba', 'VM-Unet', 'VM-UnetV2']","본 논문에서는 피부병변 영상에서 이미지 분할 성능을 향상시키기 위해 설계된 딥러닝 모델인 VmCUnet을 제안한다. VmCUnet은 Vm-UnetV2와 CIM(Cross-Scale Interaction Module)을 결합하여 인코더의 각 계층에서 추출한 특징들을 CIM으로 통합하여다양한 패턴과 경계를 정확하게 인식할 수 있다. VmCUnet은 ISIC-2017와 ISIC-2018 데이터 세트를 사용하여 피부 병변의 이미지 분할을 수행하였고 Unet, TransUnet, SwinUnet Vm-Unet, Vm-UnetV2와 비교하여 성능 지표인 IoU, Dice Score에서 더높은 성능을 보였다. 향후 작업에서는 다양한 의료 영상 데이터 세트에 대한 추가 실험을 수행하여 VmCUnet 모델의 일반화 성능을 검증할 예정이다","In this paper, we have proposed VmCUnet, a deep learning model designed to enhance image segmentationperformance in skin lesion image. VmCUnet has combined Vm-UnetV2 with the CIM(Cross-Scale InteractionModule), and the features extracted from each layer of the encoder have been integrated through CIM toaccurately recognize the boundaries of various patterns and objects. VmCUnet has performed image segmentationof skin lesions using ISIC-2017 and ISIC-2018 datasets and has outperformed Unet, TransUnet, SwinUnet,Vm-Unet, and Vm-UnetV2 on the performance metrics IoU and Dice Score. In future work, we will conductadditional experiments on different medical imaging datasets to validate the generalization performance of theVmCUnet model"
합성곱 신경망 연산을 위한 저전력 콘볼루션 레이어 하드웨어 설계,2024,"['CNN', 'Convolution Layer', 'Low-Power', 'Multiplication']",,
Contraband Identification Algorithm for Intelligent Millimeter-wave Security Screening Device based on Regional-convolution Neural Network Algorithm for Civil Aviation,2024,"['CNN', 'MFD algorithm', 'CED algorithm', 'Security equipment', 'Millimeter-wave']",,"Security is directly tied to the protection of public property and lives and is one of the key safeguards for the regular functioning of civil aviation. Millimeter-wave-based security screening technology has been developed to handle the demand for security screening during periods of high passenger traffic and to minimize the involvement of security personnel. But it cannot meet the need for quick passage at peak passenger flow because the present millimeter-wave contraband image content is insufficient, and the target-detection accuracy is low. In order to solve this problem, this study examined the denoising of millimeter-wave contraband images based on mean filtering and the wavelet transform, and the Canny algorithm was used to realize the edge detection of images. A mask region-convolutional neural network algorithm was used to identify contraband targets in the detection area to realize the real-time monitoring of millimeter-wave security equipment. The peak signal-to-noise ratio and mean square error of the mean filtered denoising-wavelet transform algorithm were 25.439 dB and 65.4781, respectively. The classification accuracy rates were greater than those of the fast area convolutional neural network model-based approach (93.65%, 89.94%, and 91.25%, respectively). In conclusion, the suggested algorithm is reliable and effective at locating and identifying targets for contraband in civil aviation security screening."
수치 데이터로 변환된 RP 이미지를 활용하여 공동 깊이에 따른 적외선 특성 분석,2024,"['CNN', 'Infrared camera', 'Recurrence plot', 'Res Net 101']",,
Edge 분석과 ROI 기법을 활용한 콘크리트 균열 분석 - Edge와 ROI를 적용한 콘크리트 균열 분석 및 검사 -,2024,"['CNN', 'Concrete Crack', 'ROI', 'Edge Segmentation', 'Manual Inspection', '합성곱 신경망', '콘크리트 균열', '관심영역', '에지 세그멘테이션', '수동 검사']","본 논문에서는 합성곱신경망과 ROI기법을 이용한 콘크리트 균열 분석에 관해 소개한다. 콘크리트 표면, 빔과 같은 구조물은 피로 응력, 주기 부하에 노출되며, 이는 일반적으로 구조물의 표면에서 미세한 수준에서 시작되는 균열을 야기한다. 구조물의 균열은 안정성을 저하시키고 구조물의 견고함을 감소시킨다. 조기 발견을 통해 손상 및 고장 가능성을 방지하기 위한 예방 조치를 취할 수 있다. 일반적으로 수동 검사 결과는 품질이 좋지 않고, 대규모 기반 시설의 경우 접근이 어려우며, 균열을 정확하게 감지하기 어렵다. 이러한 수동검사의 자동화는 기존 방식의 한계를 해결할 수 있기 때문에 컴퓨터 비전 기반의 연구들이 수행되었다. 하지만 다양한 유형의 균열이나, 열화상 카메라 등을 이용한 연구들은 부족한 상태이다. 따라서 본 연에서는 콘크리트 벽의 균열을 자동으로 감지하는 방법론을 개발하여 제시하며, 다음과 같은 연구 내용을 목표로 한다. 첫째, 균열 감지 이미지 기반 분석의 주요 장점인 이미지 처리 기술을 사용하여 기존의 수동 방법과 비교하여 정확도가 향상된 결과 및 정보를 제공한다. 둘째, 강화된 Sobel edge segmentation 기술 및 ROI 기법 기반의 알고리즘을 개발하여 비파괴 시험을 위한 자동 균열 감지 기술을 구현한다.","This paper presents the application of Convolutional Neural Networks (CNNs) and Region of Interest (ROI) techniques for concrete crack analysis. Surfaces of concrete structures, such as beams, etc., are exposed to fatigue stress and cyclic loads, typically resulting in the initiation of cracks at a microscopic level on the structure's surface. Early detection enables preventative measures to mitigate potential damage and failures. Conventional manual inspections often yield subpar results, especially for large-scale infrastructure where access is challenging and detecting cracks can be difficult. This paper presents data collection, edge segmentation and ROI techniques application, and analysis of concrete cracks using Convolutional Neural Networks. This paper aims to achieve the following objectives: Firstly, achieving improved accuracy in crack detection using image-based technology compared to traditional manual inspection methods. Secondly, developing an algorithm that utilizes enhanced Sobel edge segmentation and ROI techniques. The algorithm provides automated crack detection capabilities for non-destructive testing."
스마트 전조등을 위한 비전 기반 야간 차량 인식,2024,"['CNN', 'light-blob paring', 'smart headlamp', 'vehicle candidate generation', 'vehicle candidate classification', 'vehicle candidate tracking', '.']",,"Recently, there has been an increasing need for algorithms capable of precisely and rapidly recognizing vehicles at night via smart control of headlamps. In this study, we constructed an algorithm that could detect vehicles approaching the main vehicle and vehicles moving in the same direction as the main vehicle through images taken in front of the vehicle on a road at night. The algorithm mainly involved 1) the generation of vehicle candidates (VCs), 2) the classification of VCs, and 3) the tracking of VCs. VC generation generally begins with the extraction of light-blobs from an image and the pairing of these blobs. However, because various lights are mixed, it is difficult to identify which of these lights originate from vehicles. To solve this problem, we constructed multiple feature maps that are likely to closely relate to the light emitted from head and tail lamps and calculated the stereo disparity. The feature maps and stereo disparity were used for light-blob pairing to generate VCs. Subsequently, VC classification and tracking were performed. VC classification was performed using a convolutional neural network. The classifier indicated with probability whether the VC was a vehicle approaching the main vehicle, a vehicle going in the same direction as the main vehicle, or a non-vehicle. VC tracking performed via a KanadeLucasTomasi-based feature tracker enabled robust vehicle detection between consecutive input images. We showed that the proposed algorithm can be applied to the control of smart headlamps through real vehicle experiments."
합성곱 신경망 병렬 연산처리를 지원하는 저전력 곱셈 프로세싱 엘리먼트 설계,2024,"['CNN', 'Low-power multiplication', 'Processing element', 'Multiplier', 'FPGA']",,"CNNs tend to take a long time to learn and consume a lot of power due to lack of system resources with many data processing units when there are repetitive handles that do not have high performance in the image field. In this paper, we propose a handling method based on a low-power bus that can increase the exchange rate of multipliers and multiplicands within the convolution mixer, which is a tendency activity that occurs when a convolution mixer has multiplication, which is the core element of combination. Convolutional neural networks have proprietary low-power shared processor support and the design was implemented on an Intel DE1-SoC FPGA board using Verilog-HDL. The experiments validated the performance by comparing it with the exchange rate of the multiplier originally proposed by Shen on MNIST's numeric image database."
패션 카테고리 오버샘플링 자동화 시스템,2024,"['CNN', 'Deep learning', 'Oversampling', 'ResNet50', 'YOLOv8', 'Fashion category', '컨볼루션 신경망', '딥러닝', '오버샘플링', '레즈넷50', '욜로 버전 8', '패션 카테고리']",,
Deep Learning-Based Approaches for Nucleus Segmentation,2024,"['Deep Learning', 'CNN', 'Nuclei Segmentation', 'Image Segmentation', 'U-Net']",,"The accurate identification of cell nuclei is a critical aspect of various analyses, given that human cells, numbering around 30 trillion, contain DNA as their genetic code. In this research paper, we provide a comprehensive overview of deep learning-based techniques for nucleus segmentation. We have replicated and assessed the state-of-the-art methods using datasets like FCN, SegNet, U-net, and DoubleU-net, with a focus on the Data Science Bowl 2018 dataset comprising 670 training data folders and 65 testing data folders. Our experimental findings reveal that DoubleU-Net surpasses U-Net and other baseline models, yielding more precise segmentation masks. This promising outcome suggests that DoubleU-Net could serve as a robust model for addressing various challenges in medical image segmentation."
잔차 신경망을 활용한 펫 로봇용 화자인식 경량화,2024,"['Speaker recognition', 'CNN', 'Resnet', 'Lightweight', 'Classification']",,
PolyLaneDet: Lane Detection with Free-Form Polyline,2024,"['Lane detection', 'CNN', 'Deep learning']",,"Lane detection is a critical component of autonomous driving technologies that face challengessuch as varied road conditions and diverse lane orientations. In this study, we aim to addressthese challenges by proposing PolyLaneDet, a novel lane detection model that utilizes a freeform polyline, termed ‘polylane,’ which adapts to both vertical and horizontal lane orientationswithout the need for post-processing. Our method builds on the YOLO v4 architecture toavoid restricting the number of detectable lanes. This model can regress both vertical andhorizontal coordinates, thereby improving the adaptability and accuracy of lane detection invarious scenarios. We conducted extensive experiments using the CULane benchmark and acustom dataset to validate the effectiveness of the proposed approach. The results demonstratethat PolyLaneDet achieves a competitive performance, particularly in detecting horizontallane markings and stop lines, which are often omitted in traditional models. In conclusion,PolyLaneDet advances lane detection technology by combining flexible lane representationwith robust detection capabilities, making it suitable for real-world applications with diverseroad geometries."
멀티 블록 기반 Random Erasing in  the Frequency Domain,2024,"['Data Augmentation', 'CNN', 'Frequency domain', 'Random Erasing in the Frequency domain', 'Multi block', 'Discrete Fourier Transform']",,"Random Erasing in the Frequency domain (REF) is a data augmentation method that performs random erasing in the frequency domain. In order to evaluate the performance, it utilizes two metrics such as the corruption error, which measures the error rate for a corruption dataset, and the clean error, which measures the error rate for a clean dataset. While REF is effective in reducing the corruption error, it shows the increment in clean error. To address this increment, this paper proposes Random Erasing in the Frequency domain using multi-block. Additionally, it considers both clean error and corruption error to identify the best multi-block configuration. The training image is divided into n×n blocks, and REF is applied to each block to generate various transformations. Experimental results show that utilizing a 2×2 block configuration reduces clean error by up to 0.466%. Moreover, the best multi-blocks configuration results in a decrease of clean error by up to 0.046% and a reduction of corruption error by up to 5.246%."
잔차 신경망을 활용한 펫 로봇용 화자인식 경량화,2024,"['Speaker recognition', 'CNN', 'Resnet', 'Lightweight', 'Classification']","화자인식은 개개인마다 다른 음성 주파수를 분석하여 미리 저장된 음성과 비교해 본인 여부를 판단하는 하나의 기술을 의미한다.딥러닝 기반의 화자인식은 여러 분야에 적용되고 있으며, 펫 로봇도 그 중 하나이다. 하지만 펫 로봇의 하드웨어 성능은 딥러닝 기술의 많은 메모리 공간과 연산에 있어 매우 제한적인 상황이다. 이는 펫 로봇이 사용자와 실시간 상호작용에 있어 해결해야 할 중요한 문제점이다. 딥러닝 모델의 경량화는 위와 같은 문제를 해결하기 위한 하나의 중요한 방법으로 자리하였으며, 최근 많은 연구가진행되고 있다. 이 논문에서는 특정한 명령어 형태인 펫 로봇용 음성 데이터 세트를 구축하고 잔차(Residual)를 활용한 모델들의 결과를 비교해 펫 로봇용 화자인식의 경량화 연구의 결과를 서술하며, 결론에서는 제안한 방법에 대한 결과와 향후 연구방안에 대해서술한다.","Speaker recognition refers to a technology that analyzes voice frequencies that are different for each individualand compares them with pre-stored voices to determine the identity of the person. Deep learning-based speakerrecognition is being applied to many fields, and pet robots are one of them. However, the hardware performance ofpet robots is very limited in terms of the large memory space and calculations of deep learning technology. This isan important problem that pet robots must solve in real-time interaction with users. Lightening deep learning modelshas become an important way to solve the above problems, and a lot of research is being done recently. In thispaper, we describe the results of research on lightweight speaker recognition for pet robots by constructing a voicedata set for pet robots, which is a specific command type, and comparing the results of models using residuals. Inthe conclusion, we present the results of the proposed method and Future research plans are described."
객체 비율을 고려한 패션 이미지 분류 시스템,2024,"['Deep learning', 'CNN (Convolutional Neural Network)', 'Fashion image classification']","최근 하드웨어 기술의 발달로 딥러닝 기술은 연산량 문제와 연산 속도를 개선하며 다양한 분야에 적용되고 있다. 이러한 변화에 따라 각 분야에서 객체 인식의 정확도 성능을 높이려는 시도가 활발히 연구되고 있다. 본 논문에서는 객체의 비율이 중요하게 평가되는 패션 이미지 인식 시스템을 위해 제로 패딩과 보더 외삽법을 이용한 객체 비율 보존 방법에 기반한 패션 이미지 분류를 제안한다. 제안하는 방법은 Confusion Matrix의 위양성률과 위음성률을 감소시켜 오분류 문제를 해결하고, 제안 방법의 효과를 통해 비율이 중요한 패션 이미지 인식에서 성능 향상을 보여준다.",
딥러닝을 위한 비단조 활성화 함수,2024,"['Convolutional Neural Network(CNN)', 'Deep learning', 'Activation function']",,"The activation function significantly affects the performance of neural networks. Among the numerous functions, the Rectified Linear Unit(ReLU) is widely used in many deep learning applications owing to its simplicity and performance. This study proposes a new nonlinear activation function derived from logarithmic and hyperbolic tangent functions. It exhibits the following distinct characteristics: 1) If the input is greater than 0, then the output is the same as the input, 2) if the input is approximately 0, then the output exhibits non-linear characteristics, and 3) if the input is negative infinity, then the output has a value of approximately zero. Simulation results show that the proposed activation function surpasses the ReLU, Mish, and Power Function Linear Units in terms of classification accuracy. In particular, when applied to the CIFAR-10 classification using the VGG19 network, it increases the accuracy by approximately 1%."
Novel Algorithms for Early Cancer Diagnosis Using Transfer Learning with MobileNetV2 in Thermal Images,2024,"['Accuracy', 'Breast cancer', 'Deep CNN', 'Fine-tuning', 'MobileNet', 'Thermographic images']",,"Breast cancer ranks among the most prevalent forms of malignancy and foremost cause of death by cancer worldwide. It is not preventable. Early and precise detection is the only remedy for lowering the rate of mortality and improving the probability of survival for victims. In contrast to present procedures, thermography aids in the early diagnosis of cancer and thereby saves lives. But the accuracy experiences detrimental impact by low sensitivity for small and deep tumours and the subjectivity by physicians in interpreting the images. Employing deep learning approaches for cancer detection can enhance the efficacy. This study explored the utilization of thermography in early identification of breast cancer with the use of a publicly released dataset known as the DMR-IR dataset. For this purpose, we employed a novel approach that entails the utilization of a pre-trained MobileNetV2 model and fine tuning it through transfer learning techniques. We created three models using MobileNetV2: one was a baseline transfer learning model with weights trained from ImageNet dataset, the second was a fine-tuned model with an adaptive learning rate, and the third utilized early stopping with callbacks during fine-tuning. The results showed that the proposed methods achieved average accuracy rates of 85.15%, 95.19%, and 98.69%, respectively, with various performance indicators such as precision, sensitivity and specificity also being investigated."
AI 기반의 실시간 이동 표적 조준점 계산 방법에 대한 연구,2024,"['AI-based target estimation', 'CNN Model', 'DaSiameseRPN Algorithm', 'EO/IR camera imagery', 'Hardware Accelerator', 'Image processing', 'Leading point calculation', 'Lucas-Kanade Algorithm', 'Linear regression', 'Real-time target tracking', 'Motion Vector', 'Object tracking', 'Predictive tracking', 'Moving target analysis']",,"Although various plans for future warfare are being discussed, no research has been published on a targeting device that predicts the aiming point of a target using the DaSiameseRPN algorithm, nor has any study demonstrated its real-time operation on a hardware accelerator. To process DaSiameseRPN in real-time on a hardware accelerator, an AI model that compensates for the accuracy loss caused by model compression was applied. This paper presents a novel approach to real-time target aiming by processing Image Tracer, DaSiameseRPN, and the Lucas-Kanade Algorithm on a hardware accelerator. The primary goal of this research is to accurately determine the aiming point of a moving target by leveraging advanced AI techniques in a real-time embedded system. To achieve real-time performance, we implemented fine-tuning, transfer learning, and model compression, enabling the AI algorithms to operate efficiently on the hardware platform.The effectiveness of our approach was validated through comprehensive analyses, including motion vector extraction, linear regression analysis, and aim point error rate evaluation. The results demonstrate a substantial improvement in accuracy, with the AI system consistently predicting target positions with minimal error. Specifically, the integration of brightness clipping and linear regression led to a notable reduction in aiming errors, making the system more reliable in dynamic environments. Moreover, the system's ability to process complex AI algorithms in real-time on a hardware accelerator opens up new possibilities for deploying similar technologies in various real-world applications. The findings of this study confirm that the proposed method not only meets real-time requirements but also enhances the precision of target aiming, which is critical for applications such as defense systems, autonomous vehicles, and advanced surveillance systems. In conclusion, this research contributes to the field of AI-driven target tracking by providing a robust, real-time solution that can be implemented on hardware accelerators, thereby advancing the capabilities of current aiming technologies."
Similarity Analysis Model with 6CH ResNet Structure,2024,"['Convolutional Neural Network (CNN)', 'Image Similarity', 'Large Waste']",,"Largescale waste similarity analysis is crucial for automating waste management on a large scale. It involvesconfirming the match between waste discharged from homes and that collected by agencies, which is essentialfor a stable automated system. This paper compares feature extraction methods for similarity measurement,including the scaleinvariant feature transform (SIFT) algorithm with added HSV color features, convolutionalneural networkbased encoders, and a modified 6channel (6CH) ResNet for endtoend learning. The resultsdemonstrate that the 6CH ResNet achieves up to 4.9% higher accuracy than both the basic SIFT method andencoders, as well as the SIFT algorithm with HSV color features. Implementing the 6CH ResNet in automatedwaste management systems can enhance object similarity measurement while using fewer computing resources."
영상 속 개인 비식별화 모델의 설계 및 구현,2024,"['합성곱 신경망', '객체 검출', '객체 추적', '비식별화', 'CNN', 'Object Detection', 'Object Tracking', 'De-identification']","본 논문에서는 영상 속 개인정보를 제거하는 개인 비식별화 구조를 제안하고, 객체 검출 알고리즘과 객체 추적 알고리즘을 연결하여 제안한 구조에 기반한 동영상 속 개인정보 제거가 가능한 개인 비식별화 시스템으로 구축하였다. 기존 알고리즘의 문제였던 작은 크기의 객체 검출이 더 잘 되도록 기존 모델의 구조를 수정하였고, 웹캠 등의 기기로부터 입력된 영상에 대해서도 검출 후 추적이 가능한 구조로 구축하였다. 객체 검출 및 객체 추적의 단순 연결에 비해 처리 속도 개선이 있었고, 작은 크기의 객체 검출 개선과 객체 검출의 손실값이 개선되는 결과를 보였다. 본 논문에서 제안한 알고리즘은 웹캠의 출력 영상을 입력으로 사용할 수 있으므로 학교 또는 보육시설 등과 같이 실시간성으로 개인정보가 제거된 동영상을 공개하는 작업이 요구되는 다양한 장소에서 활용될 수 있을 것으로 사료된다.","We propose a personal de-identification architecture that removes personal information in videos, and connect the object detection algorithm and object tracking algorithm to build a personal de-identification system that can remove personal information in videos based on the proposed architecture. We modified the existing model to better detect small-sized objects, and built a system that can detect and track people in images received from devices such as webcams. Comparing to the simple connection of object detection and object tracking, the processing speed was improved, and the results showed improvement in the detection of small objects and improvement in the loss value of object detection. Since the algorithm proposed in this paper can use the output video of a webcam as an input, it is expected to be utilized in various places where it is necessary to disclose de-personalized videos in real-time, such as schools or childcare centers."
자연어 프롬프트 기반 데이터셋 생성 및 시각화 시스템,2024,"['dataset', 'NLP', 'web scraping', 'prompt', 'CNN model']",,"It is important to analyze data for deriving useful insights with the rapid growth of data. Web scraping techniques are needed to extract unstructured data from the web, but it is difficult to utilize due to the different HTML structure of each web page. In this study, we propose dataset creation and visualization system based on natural language prompt to improve the difficulty of web data utilization. The proposed system uses a deep learning model to classify the types of natural language prompt, it can perform automated web scraping based on the extracted keywords and create, edit and visualize datasets. We applied the system to websites from various domains to evaluate its performance. The system enables users to create, edit, and analyze datasets using natural language prompts instead of writing complex web scraping scripts to obtain datasets for educational research analysis."
Similar Image Retrieval Technique based on Semantics through Automatic Labeling Extraction of Personalized Images,2024,"['CBIR', 'Image Retrieval', 'Deep Learning', 'CNN', 'Feature Detect', 'etc.']",,"Despite the rapid strides in content-based image retrieval, a notable disparity persists between the visual features of images and the semantic features discerned by humans. Hence, image retrieval based on the association of semantic similarities recognized by humans with visual similarities is a difficult task for most image-retrieval systems. Our study endeavors to bridge this gap by refining image semantics, aligning them more closely with human perception. Deep learning techniques are used to semantically classify images and retrieve those that are semantically similar to personalized images. Moreover, we introduce a keyword-based image retrieval, enabling automatic labeling of images in mobile environments. The proposed approach can improve the performance of a mobile device with limited resources and bandwidth by performing retrieval based on the visual features and keywords of the image on the mobile device."
A Study on the Vulnerability of Semantic Segmentation Model to Data Transformation,2024,"['Semantic Segmentation', 'Autonomous Driving', 'Data Transformation', 'ViT', 'CNN']",,"With the advancement of autonomous driving technology, the importance of semantic segmentation has markedly increased,while the amount of datasets needed for training has been limited. Accordingly, there has been a growing effort to increasedatasets using data augmentation techniques to train semantic segmentation models. However, the distributional gap betweenaugmented and real data can lead to performance limitations when models trained on real data are applied to augmented data.Therefore, this paper constructs new datasets by applying proposed data transformations on real-world datasets. Additionally, weevaluate the impact of these transformations on semantic segmentation models trained on real datasets. Results show that semanticsegmentation models are vulnerable to distortions in color information and object characteristics in transformed datasets.Furthermore, the vision transformer based model is less sensitive to distribution changes and shows greater segmentationperformance compared to fully convolutional network based models."
불균형 블랙박스 동영상 데이터에서  충돌 상황의 다중 분류를 위한 손실 함수 비교,2024,"['deep learning', 'data imbalance', 'loss function', 'metric', 'CNN.']",,"Data imbalance is a common issue encountered in classification problems, stemming from a significant disparity in the number of samples between classes within the dataset. Such data imbalance typically leads to problems in classification models, including overfitting, underfitting, and misinterpretation of performance metrics. Methods to address this issue include resampling, augmentation, regularization techniques, and adjustment of loss functions. In this paper, we focus on loss function adjustment, particularly comparing the performance of various configurations of loss functions (Cross Entropy, Balanced Cross Entropy, two settings of Focal Loss: α = 1 and α = Balanced, Asymmetric Loss) on Multi-Class black-box video data with imbalance issues. The comparison is conducted using the I3D, and R3D_18 models."
YOLOv8을 이용한 화재 검출 시스템 개발,2024,"['YOLOv8', 'Deep Neural Networks', 'Fire Detection', 'Transformer', 'CNN']",,"It is not an exaggeration to say that a single fire causes a lot of damage, so fires are one of the disaster situations that must be alerted as soon as possible. Various technologies have been utilized so far because preventing and detecting fires can never be completely accomplished with individual human efforts. Recently, deep learning technology has been developed, and fire detection systems using object detection neural networks are being actively studied. In this paper, we propose a new fire detection system that improves the previously studied fire detection system. We train the YOLOv8 model using refined datasets through improved labeling methods, derive results, and demonstrate the superiority of the proposed system by comparing it with the results of previous studies."
초기 화재 진압을 위한 자율주행 소방 로봇 시스템 설계,2024,"['Figthing Robot', 'Ros', 'Slam', 'Autonomous-Driving', 'Yolo-Cnn', 'Manipulator']",,
다수의 IR-UWB 레이다를 이용한 인원수 및 좌표 추정 연구,2024,"['IR-UWB radar', 'People counting', 'CNN', 'Micro-Doppler', 'Location estimation']",,"In this paper, we propose an efficient method for estimating the number of people and their locations usingmultiple IR-UWB radar sensors. Using three IR-UWB radar sensors in the indoor space, the measured signal from thetarget is processed to remove the clutter using rejection methods. Then, to further remove the clutter and to determinethe presence of the human, the time-frequency image representing the micro-Doppler is obtained and classified by aconvolutional neural network. Finally, the system finds the number of human objects and estimates each position in atwo-dimensional space. In experiments using the measured data, the system successfully estimated the location andnumber of individuals with a high accuracy ≈ 88.68 %."
DNN(Deep Neural Network)과 앙상블 학습모델을 활용한 낙상사고 방지에 관한 실증연구,2024,"['HPE(Human Pose Estimation)', 'ANN', 'CNN', 'DNN', 'RNN', 'Fall Prediction', 'Person Skeleton', '사람자세예측', '인공지능', '낙상예측', '사람관절']",,"The method of analyzing human poses is to predict the coordinate value of each joint in advance by predicting the movement of the body movement and a method of extracting the movement data of the joint.In this study, a dataset of human joints is constructed using a coco model among DNN (Deep Neural Network) models using 34 joint datasets for the construction of human joints. The coco model is convenient to construct a dataset by detecting various objects and is highly utilized to efficiently recognize two-dimensional objects. For example, it can have a great effect on preventing falls from beds for patients who cannot move well in domestic nursing hospitals or nursing homes. In this study, a camera applied with NVIDIA GPU-based Jetson Nano was manufactured and empirically verified, and an ensemble learning model was used to predict safety and risk posture."
Deep Learning-based Arabic Sign Recognition System for Automated Communication with Hearing Impaired Individuals,2024,"['Arabic Sign Language', 'Deep Neural Networks', 'ResNet', 'CNN', 'Automatic Recognition', 'Hearing Impaired']",,"Arabic Sign Language (ArSL) is used by individuals who are hard of hearing or deaf in Arab countries, as well as others around the world who use it for religious purposes. for the need for automated systems to facilitate the learning and communication of ArSL is therefore significant. Such systems would allow people to learn Arabic Sign Language and use it to communicate among themselves and with the surrounding community. This paper presents the development of an automatic recognition system capable of accurately identifying Arabic signs through hand gestures. In this paper, two Residual Network (ResNet) Configurations, Version 1 (V1) and Version 2 (V2), are proposed and detailed. The proposed ResNet V1 achieved an average accuracy of 98.83%, while ResNet V2 achieved an average accuracy of 98.84%. The results described in this paper far exceed those reported in the extant literature. The high accuracy of the proposed system shows the potential for integrating the system with education tools and assistive technologies for people with special needs."
다변량 데이터 분석을 통한 효과적인 전력부하 예측 : Gas Carrier 사례 연구,2024,"['인공신경망(Artificial Neural Network)', '확장된 합성곱 신경망(Dilated CNN)', '가스 운반선(Gas Carrier)', '주성분분석(Principal Component Analysis)']",,
인공지능 오토인코더를 활용한 항공기 조종면 파손(고장) 탐지 및 분류,2024,"['anomaly detection', 'AI (Artificial Intelligence)', 'Autoencoder', 'Bi-LSTM', 'classification', 'CNN', 'deep learning', '.']",,"This paper proposes an algorithm for detection and classifying aircraft control surface damage using an AI model for cause investigation. Control surface damage on fixed-wing aircraft causes structural and aerodynamic changes that affect the flight control system, which was developed using routine flight data; therefore, knowing the type of damage is essential. The proposed algorithm employs AI models for aircraft damage detection (ADD) and damage type classification (DTC) using routine flight and damage occurrence data. The ADD model uses unsupervised learning, whereas the DTC model uses transfer learning, allowing for effective learning even when abnormal data are small. Furthermore, the ADD model generates detection results using the mean absolute error (MAE) and the Mahalanobis distance. In contrast, the DTC model generates the final classification results using the probability accumulation values. The simulation results show that this AI model algorithm can detect control surface failure quickly and correctly identify damage types."
DCGAN 화질 열화 문제 개선을 위한 초해상도 데이터 증강 방법,2024,"['생성적 적대 신경망', '유사 데이터', '화질 열화', '초해상도', 'CNN', 'Generative Adversarial Network', 'Similar Data', 'Quality Deterioration', 'Super Resolution', 'Convolution Neural Network']",,
Convolutional neural network-based transmit antenna selection for UAV-ground station communications with time-varying channels,2024,['Transmit antenna selectionUnmanned aerial vehicle (UAV) communicationConvolutional neural network (CNN)'],,"This study proposes a novel transmit antenna selection (TAS) method for improving communications between the unmanned aerial vehicle (UAV) and ground station (GS). By selecting an appropriate UAV antenna, the signal-to-noise ratio (SNR) at the GS can be significantly enhanced. However, obtaining the necessary channel state information between the UAV and GS is challenging due to the UAV’s movement and resulting channel variations. To overcome this challenge, we propose an innovative approach that leverages a convolutional neural network to predict SNRs and a missing SNR completion method. The numerical evaluation demonstrates that the proposed method can effectively enhance TAS accuracy."
이미지 특징 강화와 앙상블 학습을 활용한 디지털 조작 이미지 검출 프레임워크,2024,"['computer vision', 'image forgery detection', 'ensemble learning', 'feature enhancement', 'CNN', 'vision transformer', '.']","디지털 환경에서 조작 이미지는 무분별하게 생성되며, 이에 따라 적응성과 범용성을 갖춘 자동화된 검출 시스템이 요구된다. 기존의 연구에서는 특정 형태의 조작만을 검출하거나 상황에 국한된 모델을 제안하여 다양한 환경에 확장이 어렵다는 한계가 존재하였다. 또한 최신 조작 경향성을 반영한 데이터를 활용한 연구가 부족한 상황이다. 따라서 본 연구는 다양하고, 새로운 조작 이미지를 효과적으로 검출하고, 확장 가능성을 갖춘 강건한 딥러닝 프레임워크를 제안한다. 이를 위해 조작된 이미지의 특징을 강화하였으며 다수의 딥러닝 기반 모델에 앙상블 학습을 적용하였다. 주요 결과로는 컨볼루션 신경망(Convolutional Neural Network)과 비전 트랜스포머(Vision Transformer) 기반의 다섯 개의 모델을 앙상블 한 결과 기본 모델과 비교하여 최소 3.45%에서 최대 10.4%의 정확도가 상승하였으며, 특징을 강화한 조작 이미지가 검출 성능에 효과적임을 확인하였다.","In the digital environment, forged images are generated indiscriminately, requiring automated detection system with adaptability and versatility. The limitations of existing studies are that they detect only certain types of manipulation or propose models that are limited to a specific situation, making it difficult to extend to various environments. In addition, there is a lack of research utilizing data that reflects the latest forgery trends. Therefore, This paper proposes a scalable and robust deep learning-based framework for effectively detecting diverse and novel types of digitally forged images. To address this we applied feature enhancing on forged images and ensemble learning on multiple deep learning-based models. The main results are that the ensemble of five Convolutional Neural Network and Vision Transformer-based models showed an accuracy increase of at least 3.45% and up to 10.4% compared to the baseline model, and confirmed that feature-enhanced image was effective in improving detection performance."
Deep Learning-Based Defect Detection in Cu-Cu Bonding Processes,2024,"['Cu-Cu Bonding', 'Deep Learning', 'Defect Detection', 'Defect Map', 'ResNet', 'CNN']",,"Cu-Cu bonding, one of the key technologies in advanced packaging, enhances semiconductor chip performance, miniaturization, and energy efficiency by facilitating rapid data transfer and low power consumption. However, the quality of the interface bonding can significantly impact overall bond quality, necessitating strategies to quickly detect and classify in-process defects. This study presents a methodology for detecting defects in wafer junction areas from Scanning Acoustic Microscopy images using a ResNet-50 based deep learning model. Additionally, the use of the defect map is proposed to rapidly inspect and categorize defects occurring during the Cu-Cu bonding process, thereby improving yield and productivity in semiconductor manufacturing."
"SenseNet: Densely Connected, Fully Convolutional Network with Bottleneck Skip Connection for Image Segmentation",2024,"['Image segmentation', 'Semantic segmentation', 'Deep neural network', 'Convolutional networks', 'Artificial intelligence (AI)', '6G', 'Virtual reality', 'Surveillance cameras', 'Autonomous cars']",,"This paper presents SenseNet, a convolution neural network (CNN) model for image segmentation. SenseNet architecture includes encoders with their corresponding decoders and bottleneck skip connections. The last layer of the architecture is a classification layer that classifies each pixel of an image for image segmentation. SenseNet addresses the limitations of conventional semantic segmentation models. Moreover, the skip connection does not include sufficient information for the recovery in the decoder path. This paper proposes a novel network structure combining a modified dense block and dense skip connection for efficient information recovery at the decoder path. Furthermore, this paper also proposes a dense, long skip connection that transfers the feature maps of each layer of the encoder to a layer of the decoder. This dense skip connection helps the network recover the information efficiently in the decoder path. SenseNet achieves state-of-the-art accuracy with fewer parameters and high-level features in the decoder path. This study evaluated SenseNet on the urban scene benchmark dataset CamVid and measured the performance in terms of intersection over union (IoU) and global accuracy. SenseNet outperformed the baseline model by an 8.7% increase in IoU. SenseNet can be downloaded from https://github.com/sensenetskip/sensenet."
Speech Emotion Recognition in People at High Risk of Dementia,2024,"['People at High Risk of Dementia', 'Speech Emotion Recognition', 'CNN+LSTM Algorithm', 'Deep Learning', 'Voice and Text Analysis']",,"Background and Purpose: The emotions of people at various stages of dementia need to be effectively utilized for prevention, early intervention, and care planning. With technology available for understanding and addressing the emotional needs of people, this study aims to develop speech emotion recognition (SER) technology to classify emotions for people at high risk of dementia. Methods: Speech samples from people at high risk of dementia were categorized into distinct emotions via human auditory assessment, the outcomes of which were annotated for guided deep-learning method. The architecture incorporated convolutional neural network, long short-term memory, attention layers, and Wav2Vec2, a novel feature extractor to develop automated speech-emotion recognition. Results: Twenty-seven kinds of Emotions were found in the speech of the participants. These emotions were grouped into 6 detailed emotions: happiness, interest, sadness, frustration, anger, and neutrality, and further into 3 basic emotions: positive, negative, and neutral. To improve algorithmic performance, multiple learning approaches were applied using different data sources-voice and text-and varying the number of emotions. Ultimately, a 2-stage algorithm-initial text-based classification followed by voice-based analysis-achieved the highest accuracy, reaching 70%. Conclusions: The diverse emotions identified in this study were attributed to the characteristics of the participants and the method of data collection. The speech of people at high risk of dementia to companion robots also explains the relatively low performance of the SER algorithm. Accordingly, this study suggests the systematic and comprehensive construction of a dataset from people with dementia."
최적화 알고리즘과 학습률 적용에 따른흉부 X선 영상 딥러닝 분류 모델 성능평가,2024,"['딥러닝', '컨볼루션 인공 신경망', '최적화 알고리즘', '학습률', '흉부 X선 영상', 'Deep-Learning', 'CNN', 'Inception V3', 'Optimization algorithm', 'Learning rate', 'Chest X-ray image']","최근에는 딥러닝을 이용한 의료영상 분야의 자동진단 솔루션에 대한 연구 및 개발이 활발하게 진행되고 있다. 본 연구에서는 컨볼루션 인공 신경망 기반의 딥러닝 모델인 Inception V3를 이용하여 흉부 X선 영상의 폐렴 유무 분류에 대한 신속하면서도 정확한 분류 딥러닝 모델링을 찾고자 하였다. 이러한 이유로 딥러닝 모델링에 최적화알고리즘 AdaGrad, RMS Prop, Adam을 적용한 후 학습률을 0.01과 0.001로 선택적으로 적용하여 딥러닝 모델링을 구현한 후 흉부 X선 영상 폐렴 유무 분류에 대한 성능을 비교 평가하였다. 연구결과 분류 모델의 성능과 인공신경망의 학습상태를 평가할 수 있는 검증 모델링에서는 학습률 0.001과 최적화 알고리즘으로 Adam을 적용한 경우 흉부 X 선 영상의 폐렴 유무 분류에 대한 딥러닝 모델링의 성능이 가장 우수하다는 것을 알 수 있었다. 그리고 최근 딥러닝 모델링의 설계 시 최적화 알고리즘으로 주로 적용이 되는 Adam의 경우 학습률 0.01과 0.001의 선택적인 적용에서 우수한 성능 및 우수한 Metric 결과를 나타내었다. 테스트 모델링에 대한 Metric 평가에서는 학습률 0.1을 적용한 AdaGrad 가 가장 우수한 결과를 나타내었다. 이러한 결과를 통하여 이진법 기반의 의료영상 분류 딥러닝 모델링의 설계 시, 신속하면서도 정확한 성능을 기대하기 위해서는 최적화 알고리즘으로 Adam을 적용하는 경우에는 학습률 0.01, AdaGrad를 적용하는 경우에는 학습률은 0.01을 우선적으로 적용할 것을 권고한다. 그리고 향후 유사 연구 시, 본 연구 결과는 기초자료로 제시될 것이라 사료되며 딥러닝을 이용한 의료영상의 자동 진단 목적의 헬스 · 바이오 산업에서 유용한 자료로 활용되기를 기대한다.","Recently, research and development on automatic diagnosis solutions in the medical imaging field using deep learning are actively underway. In this study, we sought to find a fast and accurate classification deep learning modeling for classification of pneumonia in chest images using Inception V3, a deep learning model based on a convolutional artificial neural network. For this reason, after applying the optimization algorithms AdaGrad, RMS Prop, and Adam to deep learning modeling, deep learning modeling was implemented by selectively applying learning rates of 0.01 and 0.001, and then the performance of chest X-ray image pneumonia classification was compared and evaluated. As a result of the study, in verification modeling that can evaluate the performance of the classification model and the learning state of the artificial neural network, it was found that the performance of deep learning modeling for classification of the presence or absence of pneumonia in chest X-ray images was the best when applying Adam as the optimization algorithm with a learning rate of 0.001. I was able to. And in the case of Adam, which is mainly applied as an optimization algorithm when designing deep learning modeling, it showed excellent performance and excellent metric results when selectively applying learning rates of 0.01 and 0.001. In the metric evaluation of test modeling, AdaGrad, which applied a learning rate of 0.1, showed the best results. Based on these results, when designing deep learning modeling for binary-based medical image classification, in order to expect quick and accurate performance, a learning rate of 0.01 is preferentially applied when applying Adam as an optimization algorithm, and a learning rate of 0.01 is preferentially applied when applying AdaGrad. I recommend doing this. In addition, it is expected that the results of this study will be presented as basic data during similar research in the future, and it is expected to be used as useful data in the health and bio industries for the purpose of automatic diagnosis of medical images using deep learning."
Deep Learning-Based Defect Detection in Cu-Cu Bonding Processes,2024,"['Cu-Cu Bonding', 'Deep Learning', 'Defect Detection', 'Defect Map', 'ResNet', 'CNN']",,"Cu-Cu bonding, one of the key technologies in advanced packaging, enhances semiconductor chip performance, miniaturization, and energy efficiency by facilitating rapid data transfer and low power consumption. However, the quality of the interface bonding can significantly impact overall bond quality, necessitating strategies to quickly detect and classify in-process defects. This study presents a methodology for detecting defects in wafer junction areas from Scanning Acoustic Microscopy images using a ResNet-50 based deep learning model. Additionally, the use of the defect map is proposed to rapidly inspect and categorize defects occurring during the Cu-Cu bonding process, thereby improving yield and productivity in semiconductor manufacturing."
전이학습 기반 특징융합을 이용한 누출판별 기법 연구,2024,"['배관 누출 감지', '딥 러닝', '1D 합성곱 신경망', '특징융합', '전이학습', 'Pipe Leak Detection', 'Deep Learning', '1D CNN', 'Feature Fusion', 'Transfer Learning']",,"When there were disparities in performance between models trained in the time and frequency domains, even after conducting anensemble, we observed that the performance of the ensemble was compromised due to imbalances in the individual model performances.Therefore, this paper proposes a leakage detection technique to enhance the accuracy of pipeline leakage detection through a step-wiselearning approach that extracts features from both the time and frequency domains and integrates them. This method involves a two-steplearning process. In the Stage 1, independent model training is conducted in the time and frequency domains to effectively extract crucialfeatures from the provided data in each domain. In Stage 2, the pre-trained models were utilized by removing their respective classifiers.Subsequently, the features from both domains were fused, and a new classifier was added for retraining. The proposed transferlearning-based feature fusion technique in this paper performs model training by integrating features extracted from the time and frequencydomains. This integration exploits the complementary nature of features from both domains, allowing the model to leverage diverseinformation. As a result, it achieved a high accuracy of 99.88%, demonstrating outstanding performance in pipeline leakage detection."
혼합 샘플링을 이용한 하이브리드 딥러닝 결합 모델 기반의 부정맥 분류,2024,"['부정맥', 'SMOTE-Tomek', '합성곱 신경망', '양방향 장단기 기억 신경망', '어텐션 메커니즘', 'Arrhythmia', 'SMOTE-Tomek', 'CNN', 'BLSTM', 'Attention-Mechanism Received 2 July 2024', 'Revised 8 July 2024', 'Accepted 30 July 2024 * Corresponding Author Hyeog-Soong Kwon(E-mail:hskwon@pusan.ac.kr Tel:+82-55-350-5411) Professor', 'Department of IT Engineering', 'Pusan National University', 'Miryang', '50463 Korea Open Access http://doi.org/10.6109/jkiice.2024.28.10.1183\tprint ISSN: 2234-4772 online ISSN: 2288-4165 This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License(http://creativecommon', 'distribution', 'and reproduction in any medium', 'provided the original work is properly cited. Copyright Ⓒ The Korea Institute of Information and Communication Engineering.']","부정맥은 심장 박동이 불규칙하게 뛰고 있는 상태를 말하며, 심정지와 같은 위험한 상황을 유발할 수 있기 때문에 이의 조기 검출은 매우 중요하다. 본 연구에서는 혼합 샘플링 기법과 어텐션 메커니즘 기반의 하이브리드 딥러닝 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 전처리 과정을 거친 심전도 신호를 사용하였다. 이때 데이터의 불균형 문제를 해결하기 위해 SMOTE-Tomek 혼합 샘플링 기법을 적용하였다. 이후 컨볼루션 레이어를 통해 부정맥 신호의 패턴을 추출하고 이를 BLSTM 레이어에 입력한 후 어텐션 메커니즘을 통해 가중치를 학습하고 검증 데이터로 모델을 평가한 후 부정맥을 분류하였다. 제안한 방법의 타당성을 판단하기 위해 MIT-BIH 부정맥 데이터베이스를 통해 분류의 정확도, 정밀도, 재현율, F1-score를 비교하였다. 성능평가 결과 각각 99.64%, 93.27%, 95.05%, 94.08%로 분류율이 우수함을 확인할 수 있었다.","Arrhythmia is an irregular heartbeat, and its early detection is very important because it can cause dangerous situations such as sudden cardiac death. In this study, we propose a method for arrhythmia classification using a hybrid deep learning combination model based on mixed sampling technique and attention mechanism. To do this, we used preprocessed ECG signals. The SMOTE-Tomek mixed sampling technique was applied to address the imbalance in the data. The convolutional hierarchy was then configured to precisely extract the pattern of the arrhythmia signal, which was used as the input of BLSTM, and then the weights were learned through an attention mechanism, and the model was evaluated with validation data to verify the change in normal and arrhythmia classification. To demonstrate the superiority of the proposed method, we compared the accuracy, precision, recall, and F1-score of the classification using the MIT-BIH arrhythmia database. The performance evaluation results showed that the classification rates were 99.64%, 93.27%, 95.05%, and 94.08%, respectively."
전장 유전체 서열과 콘볼루션 신경망을 이용한 인유두종바이러스의 위험성 분류,2024,"['인유두종바이러스', '자궁경부암', '전장 유전체 서열', '컨볼루션 신경망', '텐서플로우', 'human papillomavirus', 'cervical cancer', 'whole genome sequence', 'Convolutional Neural Network (CNN)', 'TensorFlow']",,
A Hybrid Deep Learning Model for Generating Time-series Fire Data in Underground Utility Tunnel based on Convolutional Attention TimeGAN,2024,"['지하공동구', '화재 데이터 생성', '어텐션 매커니즘', '합성곱 신경망', '게이트 순환 유닛', '적대적 생성 신경망', 'underground utility tunnel', 'fire data generation', 'CNN', 'attention', 'GRU', 'GAN']",,
금속 3D 프린터 제품의 초음파 전파 특성 분석 및 Deep Learning 알고리즘의 초음파 결함 분류 능력 비교분석,2024,"['초음파 검사', '금속 3D 프린터', '심층 학습', '이미지 분류', '합성곱 신경망', '장단기 기억 신경망', 'Ultrasonic Testing', '3D Printer', 'Deep Learning', 'Image Classification', 'CNN', 'LSTM']",,
Classification of Gravitational Waves from Black Hole-Neutron Star Mergers with Machine Learning,2024,"['gravitational waves', 'conditional information', 'machine learning', 'classification']",,"This study developed a machine learning-based methodology to classify gravitational wave (GW) signals from black holeneutron star (BH-NS) mergers by combining convolutional neural network (CNN) with conditional information for feature extraction. The model was trained and validated on a dataset of simulated GW signals injected to Gaussian noise to mimic real world signals. We considered all three types of merger: binary black hole (BBH), binary neutron star (BNS) and neutron starblack hole (NSBH). We achieved up to 96% correct classification of GW signals sources. Incorporating our novel conditional information approach improved classification accuracy by 10% compared to standard time series training. Additionally, to show the effectiveness of our method, we tested the model with real GW data from the Gravitational Wave Transient Catalog (GWTC-3) and successfully classified ~90% of signals. These results are an important step towards low-latency real-time GW detection."
시계열 데이터를 이용한 딥러닝 기반 용접 공정 모니터링 리뷰,2024,"['Time-series data', 'Welding process monitoring', 'Deep learning', 'Time domain', 'Time-frequency domain', 'Long Short-Term Memory (LSTM)', 'Convolutional Neural Network (CNN)']",,"The quality of welds during welding processes significantly affects the performance and the reliability of the final products. Therefore, to guarantee a high quality of the products, technologies that utilize time-series data measured by various sensors for monitoring the welding processes are required. Because the time-series data measured during the welding processes exhibit nonlinear and nonstationary characteristics, deep learning techniques, which can automatically learn the features of nonlinear and nonstationary signals through deep network structures, have recently gained recognition as a new monitoring method. Therefore, in this review, recent research that applied deep learning models based on time-series data measured during welding processes to monitor welding processes are introduced.In addition, the types of time-series data and deep learning model structures that are predominantly used to monitor the welding processes, such as predicting the penetration states and identifying the welding defects are discussed.Lastly, based on the research cases discussed herein, future research directions and the prospects of deep learning- based welding process monitoring technology that uses time-series data are discussed."
Efficient robot tracking system using single-image-based object detection and position estimation,2024,['Deep learningPID controlLinear regression trackingImage processing'],,"This study proposes a mother-slave robot tracking system that identifies the target, predicts its location, and tracks it based on a single image. The proposed system utilizes a Convolutional Neural Network (CNN) for object detection, to identify the target robot. The distance and angle between the robots are then calculated through linear regression analysis, which offers a more efficient and cost-effective solution than traditional methods. The performance of the system was evaluated, resulting in an accuracy of 99.59% for object detection, and an average distance error of 2.04% for the estimated location."
광산배수 처리를 위한 기계학습 기반 소석회 투입량 예측 연구,2024,"['예측', '기계학습', '광산배수', '처리', '합성곱 신경망', 'prediction', 'machine learning', 'mine drainage', 'treatment', 'convolutional neural network']","본 연구는 광산배수 처리시설의 효율적 설계와 운영을 위해 기계학습(ML) 기법으로 광산배수 처리시설(ST와 HT)의 소석회 투입량을 예측하였다. 처리시설 원본 자료에서 이상치를 제거한 후, 소석회 투입량과 관계가 있는 유량, 그리고 소석회에 의해 공급된 OH‒와 상당히 관계가 있는 금속이온(Fe, Mn, Al) 농도와 pH를 입력자료로 선정하였다. 합성곱 신경망(CNN) 모델이 사용되었고, 원본 자료의 제한적이고 불균형적인 자료의 문제를 보완하면서 원본 자료 특성을 유지하기 위해fancy 주성분 분석(PCA)를 이용한 자료증대 기법이 사용되었다. ML 모델에 의해 예측된 테스트자료 세트의 소석회 투입량은 이론적 계산식보다 평균 절대 오차(MAE)는 낮고 결정계수(R2)는 높았다. 기계학습 기법의 사용으로 처리시설의 운영효율 증가 및 신규 시설에의 기본 설계자료 제공이 기대된다.","In this study, we predicted the lime dosage for treatment facilities (ST and HT) using machine learning (ML) to effectively design and operate mine drainage treatment facilities. After removing the bad data from the original data, the flow rate related to the lime dosage, and metal ion (Fe, Mn, Al) concentrations and the pH which are highly related to OH‒ supplied by lime, were selected as inputs.The convolutional neural network was used, and the data was augmented using fancy principal component analysis to compensate for the limited and imbalanced dataset while maintaining the characteristics of the original data. The test dataset prediction by the ML model demonstrated a lower mean absolute error and higher coefficient of determination (R2) than that of the theoretical calculation equation. The ML application is expected to enhance operational effectiveness of treatment facilities and offer fundamental design data for new facilities."
설진 영상의 혀 영역 자동 분할을 위한 U-Net 기반 딥러닝 알고리즘,2024,"['Tongue image segmentation', 'U-Net', 'Tongue diagnosis', 'Tongue region segmentation', 'Deep learning', 'Convolutional neural network']",,"Research on improving the accuracy of tongue region segmentation in the deep learning process of Korean medicine's tongue diagnosis is actively ongoing. This study aims to propose a segmentation model based on the U-Net using Convolutional Neural Networks (cNN). Binary mask images representing the tongue region were created, and the dataset was randomly divided into an 8:2 ratio for the train and test set. To prevent overfitting, the changes in validation loss were monitored at each epoch. Finally, Dice similarity coefficient (DSC) and Jaccard index (JI) were computed to measure the accuracy of the segmentation model in identifying the target regions. The modified U-Net network showed a significant level of accuracy in tongue region segmentation and minimal overfitting despite a small number of training data sets. The accuracy in the train set reached 0.997 and in the test set the accuracy was 0.993. The Dice similarity coefficient (DSC) score on the test dataset was 0.981 ± 0.017 and the Jaccard index (JI) score was 0.964 ± 0.031. The proposed model based on U-Net for tongue region extraction is anticipated to be effective for practical applications such as computerized tongue analysis systems."
경량화 기법을 통한 저사양 NPU를 탑재한 IP 카메라에서의실시간 차량번호 인식 성능 향상,2024,"['Lightweighting', 'Deep Learning', 'Vehicle Number Recognition', 'Performance Improvement', 'Real-time', '경량화', '딥러닝', '차량번호 인식', '효율성 향상', '실시간']",,"This paper proposes a lightweight method to improve the performance of real-time vehicle number recognition on low-specificationembedded devices, to solve the problem of increasing physical space and cost due to the expansion of the vehicle number recognitionmarket. The proposed method is based on a lightweight CNN model and uses techniques such as image preprocessing, hyperparameteroptimization, activation function optimization, and quantization to simultaneously improve recognition accuracy and speed. Experimentsshow that, in the case of the SSD-lite model, image preprocessing with Shi-Tomasi corner detection, the application of ReLU4 as theactivation function, and quantization resulted in an mAP@.5 of 0.94, which is an accuracy improvement of more than 10%, and a recognitiontime of 10.9 ms, which is a speed improvement of more than 10%. In addition, the proposed method meets real-time requirements (FPS≥ 30) with minimal loss of accuracy and a speed improvement of about 10% on IP cameras using the EN675 SoC of EYENIX, an edgedevice with an NPU performance of 1.2 TOPS."
스테레오 카메라를 활용한 자율 비행 UAV의 반투과성 장애물 인식 및 회피 시스템,2024,"['무인 항공기', '충돌 회피', '최적 경로', '딥 러닝', '이미지 프로세싱', '철조망 울타리', 'UAV', 'Collision Avoidance', 'Optimal path', 'Deep learning', 'Image processing', 'Wire fence']",,"This paper proposes a system for autonomous UAVs to detect and navigate around semi-permeable obstacles, such as a wire fence. The proposed method employs a stereo camera to detect semi-permeable obstacles using a Convolutional Neural Network (CNN) based object detection algorithm and utilizes image processing techniques such as Canny Edge Detection to eliminate the background of obstacles. This enables precise decision of the three-dimensional position of obstacles through the utilization of the collected depth information. Additionally, the system incorporates the Fast-Planner, which is a path-planning algorithm, to map the semi-permeable obstacles and create avoidance trajectories. The experimental results validate the proposed method improves the precision of the obstacle location compared to conventional 3D object detection. In addition, it could be effective to generate the obstacle avoidance routes by the path planning algorithm."
Advanced Machine Learning Approaches for High-Precision Yield Prediction Using Multi-temporal Spectral Data in Smart Farming,2024,"['Precision Agriculture', 'Crop Yield Prediction', 'Machine Learning', 'Multi-temporal Spectral Data', 'Integrated Modeling ApproachTime']",,"This study explores advanced machine learning techniques for improving crop yield prediction in smart farming, utilizing multi-temporal spectral data from drone-based multispectral imagery. Conducted in garlic orchards in Andong, Gyeongbuk Province, South Korea, the research examines the effectiveness of various vegetation indices and cutting-edge models, including LSTM, CNN, Random Forest, and XGBoost. By integrating these models with the Analytic Hierarchy Process (AHP), the study systematically evaluates the factors that influence prediction accuracy. The integrated approach significantly outperforms single models, offering a more comprehensive and adaptable framework for yield prediction. This research contributes to precision agriculture by providing a robust, AI-driven methodology that enhances the sustainability and efficiency of farming practices."
Multi-Agent Deep Reinforcement Learning for Fighting Game: A Comparative Study of PPO and A2C,2024,"['Multi-Agent Reinforcement Learning', 'Proximal Policy Optimization', 'Advantage Actor-Critic', 'Performance Evaluation']",,"This paper investigates the application of multi-agent deep reinforcement learning in the fighting game Samurai Shodown using Proximal Policy Optimization (PPO) and Advantage Actor-Critic (A2C) algorithms. Initially, agents are trained separately for 200,000 timesteps using Convolutional Neural Network (CNN) and Multi-Layer Perceptron (MLP) with LSTM networks. PPO demonstrates superior performance early on with stable policy updates, while A2C shows better adaptation and higher rewards over extended training periods, culminating in A2C outperforming PPO after 1,000,000 timesteps. These findings highlight PPO's effectiveness for short-term training and A2C's advantages in long-term learning scenarios, emphasizing the importance of algorithm selection based on training duration and task complexity. The code can be found in this link https://github.com/Lexer04/Samurai-Shodown-with-Reinforcement-Learning-PPO."
동형 암호를 활용한 프라이버시 보장 암호화 API 오용 탐지 프레임워크,2024,"['Privacy-Preserving Machine Learning', 'Homomorphic Encryption', 'Cryptographic API Misuse Detection', 'Convolutional Neural Network']",,"In this study, we propose a privacy-preserving cryptographic API misuse detection framework utilizing homomorphic encryption. The proposed framework is designed to effectively detect cryptographic API misuse while maintaining data confidentiality. We employ a Convolutional Neural Network (CNN)-based detection model and optimize its structure to ensure high accuracy even in an encrypted environment. Specifically, to enable efficient homomorphic operations, we leverage depth-wise convolutional layers and a cubic activation function to secure non-linearity, enabling effective misuse detection on encrypted data. Experimental results show that the proposed model achieved a high F1-score of 0.978, and the total execution time for the homomorphically encrypted model was 11.20 seconds, demonstrating near real-time processing efficiency. These findings confirm that the model offers excellent security and accuracy even when operating in a homomorphic encryption environment."
토지피복 분류를 위한 멀티 모달 모델의 활용 가능성 평가,2024,"['딥러닝', '멀티모달', '토지피복', 'Clip', 'Clipseg', 'Segformer', 'Unet', 'Deep learning', 'Multimodal', 'Land cover']",,"This study was conducted to evaluate the potential of a multimodal model for land cover classification. The performance of the Clipseg multimodal model was compared with two unimodal models including Convolutional Neural Network (CNN)-based Unet and Transformer-based Segformer for land cover classification. Using orthophotos of two areas (Area1 and Area2) in Wonju City, Gangwon Province, classification was performed for seven land cover categories (Forest, Cropland, Grassland, Wetland, Settlement, Bare Land, and Forestry-managed Land). The results showed that the Clipseg model demonstrated the highest generalization performance in new environments, achieving the highest accuracy among the three models with an Overall Accuracy of 83.9% and Kappa of 0.72 in the test area (Area2). It performed particularly well in classifying Forest (F1-Score 94.7%), Cropland (78.0%), and Settlement (78.4%). While Unet and Segformer models showed high accuracy in the training area (Area1), they exhibited limitations in generalization ability with accuracy decreases of 29% and 20% respectively in the test area. The Clipseg model required the most parameters (approximately 150 million) and the longest training time (10 hours 48 minutes) but showed stable performance in new environments. In contrast, Segformer achieved considerable accuracy with the least parameters (about 16 million) and the shortest training time (3 hours 21 minutes), demonstrating its potential for use in resource-limited environments. This study shows that image-text-based multimodal models have a high potential for land cover classification. Their superior generalization ability in new environments suggests they can be effectively applied to land cover classification in various regions. Future research could further improve classification accuracy through model structure improvements, addressing data imbalances, and additional validation in diverse environments."
한국어 코퍼스에서 딥러닝 기반 감성 분석 모델,2024,"['Sentimental Analysis', 'Machine Learning', 'Deep Learning', 'Transformer', 'GPT', '감성 분석', '머신러닝', '딥러닝', 'Transformer', 'GPT']",,"This study comprehensively analyzes the emotional analysis model using deep learning in the Korean corpus, and discusses major research achievements and technological advances. Emotional analysis is the process of extracting and classifying subjective information from text, and the development of deep learning has brought many changes in the field of emotional analysis. Starting with the traditional emotional analysis method, the development of early deep learning models using RNN and CNN is examined, and the process of greatly improving the complex context understanding and processing ability of text through Transformer-based models is analyzed. In this process, models such as BERT and GPT show high performance and potential for expansion to various languages and domains. In addition, it analyzes the research trends of multi-lingual and domain emotional analysis and discusses how to increase the generalization ability of the model through cases using zero-shot and transfer learning. In addition, it also introduces major datasets and evaluation indicators. Finally, it mentions various challenges such as ethical issues in practical applications and suggests future research directions."
A channel estimation method using denoising autoencoder for large-scale asymmetric backscatter systems,2024,['Backscatter communicationBeamformingChannel estimationDeep learningDenoising autoencoder'],,"A novel channel estimation method based on deep learning algorithm is proposed for large-scale IoT networks. We consider asymmetric backscatter communication system to maintain low-power at sensor nodes. In order to obtain channel data, we design denoising autoencoder which consists of encoder with Feedforward Neural Network (FNN) and decoder with Convolutional Neural Network (CNN). Finally, the channel estimation error is minimized, while the pilots are optimized. Especially, we adopt beamforming technique that relies only on cascaded channel data to reduce complexity in multi-sensor system. It is shown that the accuracy is slightly degraded while the complexity is greatly reduced."
컬러 이미지와 딥러닝 기술을 활용한 고구마 수분 스트레스 추정,2024,"['ANOVA', 'Color Imagery', 'Convolution Neural Network', 'Sweet Potato', 'Water Stress', '고구마', '수분 스트레스', '컬러 이미지', '분산 분석', '합성곱 신경망']","전 세계 인구는 2050년까지 20억 명 증가할 것으로 예상되며, 그 중 절반 이상이 개발도상국 출신일 것으로 전망된다. FAO에 따르면, 개발도상국에서는 영양부족과 식량 불안정이 심각한 상황에 처해 있으며, 이러한 배경 속에서 고구마는 중요한 영양 공급원으로 주목받고 있다. 그러나 기후 변화로 인한 가뭄과 홍수는 작물에 큰 피해를 주고 있으며, 고구마도 예외가 아니다. 이에 본 연구는 딥러닝과 컬러 이미지를 활용하여 고구마의 수분 스트레스 수준을 분류하였다. 실험은 수분 스트레스 수준을 건조, 적습, 과습의 세 가지로 나누어 진행되었다. 연구 결과, CNN 모델을 이용한 분류에서 0.8의 정확도를 달성하였다. 본 연구는 고구마뿐만 아니라 다른 노지 재배 작물에서도 정밀한 관개 제어를 위한 중요한 기초 자료로 활용될 수 있을 것으로 기대된다.","By 2050, the global population is projected to increase by 2 billion, with over half of this increase occurring in developing countries. According to the Food and Agriculture Organization, developing countries face severe challenges related to malnutrition and food insecurity, with sweet potatoes gaining attention as a vital source of nutrients. However, droughts and floods driven by climate change are causing significant damage to crops, including sweet potatoes. This study therefore utilized deep learning and RGB imagery to classify water stress levels in sweet potatoes. Water stress was categorized into three levels for the experiment: dry, normal, and overwatered. As a result, the convolution neural network model developed in this study achieved an accuracy of 0.8. This research is expected to serve as a valuable foundation for precise irrigation control, benefiting not only sweet potatoes but also other field crops."
IoT 환경 기반의 뇌파 및 시선 추적을 활용한 학습 패턴 분석 시스템 설계,2024,"['EEG', 'Eye-Tracking', 'Personalized Learning', 'Artificial Intelligence', 'Learner State Monitoring', '뇌파', '시선추적', '맞춤형 학습', '인공지능', '학습자 상태 모니터링']","본 논문은 학습 장애를 가진 학생들을 위한 생체신호 기반 맞춤형 학습 지원 시스템의 설계를 제안한다. 이시스템은 EEG(뇌파)와 시선 추적 데이터를 활용하여 학습자의 상태를 실시간으로 모니터링하고, 집중력 저하, 지루함또는 흥미 감소를 식별한다. 이를 통해 맞춤형 피드백과 적응형 학습 환경을 제공함으로써 학습 경험과 효과를 향상시키고자 한다. 시스템의 주요 구성 요소로는 Emotiv Epoc X와 시선 추적 장치를 사용한 데이터 수집, 수집된 데이터의전처리, 그리고 CNN(Convolutional Neural Networks) 및 LSTM(Long Short-Term Memory)과 같은 AI 모델의적용이 포함된다. 또한 Random Forest와 Gradient Boosting을 활용하여 학습자 특성을 예측하고 피드백을 최적화하며, Decision Trees를 통해 학습 성과를 분석하고 개별 맞춤형 피드백을 제공한다. 제안된 시스템은 학습 장애 학생들에게 최적의 학습 환경을 제공하여 교육적 성과와 동기를 향상시키는 것을 목표로 한다.","This paper proposes the design of a personalized learning support system for students with learning disabilities, utilizing biometric signals. The system leverages EEG (electroencephalography) and eye-tracking data to monitor the learner's state in real-time, identifying signs of decreased concentration, boredom, or diminished interest. By providing customized feedback and an adaptive learning environment, the system aims to enhance the learning experience and effectiveness. Key components of the system include data collection using Emotiv Epoc X and eye-tracking devices, data preprocessing, and the application of AI models such as Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. Additionally, Random Forest and Gradient Boosting techniques are employed to predict learner characteristics and optimize feedback, while Decision Trees are used to analyze learning outcomes and deliver individualized recommendations. The proposed system aims to provide an optimal learning environment for students with learning disabilities, with the ultimate goal of improving educational performance and motivation."
Automated Detection of COVID-19 in Chest Radiographs: Leveraging Machine Learning Approaches,2024,"['COVID-19 pandemic', 'Machine learning models', 'Chest X-ray classification', 'Automated identification', 'Medical diagnosis']",,"The World Health Organization (WHO) has designated the COVID-19 pandemic a global health emergency, prompting responses all over the world. The fatality rate is between 2% and 5%, and millions of people around the world have been infected. While the WHO recommends tests, resource-intensive testing has motivated the development of CNN technology for automated identification. Research employing machine learning models shows great accuracy in classifying X-ray and CT images for COVID-19 detection. These models include denseNet201, resnet50V2, inceptionv3, mobile net, and custom CNNs. The interpretation of chest X-rays has come a long way, yet there are still obstacles to overcome. In this paper, we present a way for using a machine learning model to categorize chest X-ray pictures into normal, COVID-19, viral pneumonia, and lung opacity, demonstrating the model's efficacy in assisting medical diagnosis, especially in time-sensitive situations like COVID-19."
Analysis of Research Trends in Deep Learning-Based Video Captioning,2024,"['Video Captioning', 'Computer Vision', 'Natural Language Processing', 'Deep Learning', '비디오 캡션', '컴퓨터 비전', '자연어 처리', '딥러닝']",,"Video captioning technology, as a significant outcome of the integration between computer vision and natural language processing,has emerged as a key research direction in the field of artificial intelligence. This technology aims to achieve automatic understandingand language expression of video content, enabling computers to transform visual information in videos into textual form. This paperprovides an initial analysis of the research trends in deep learning-based video captioning and categorizes them into four main groups:CNN-RNN-based Model, RNN-RNN-based Model, Multimodal-based Model, and Transformer-based Model, and explain the concept ofeach video captioning model. The features, pros and cons were discussed. This paper lists commonly used datasets and performanceevaluation methods in the video captioning field. The dataset encompasses diverse domains and scenarios, offering extensive resourcesfor the training and validation of video captioning models. The model performance evaluation method mentions major evaluation indicatorsand provides practical references for researchers to evaluate model performance from various angles. Finally, as future research tasksfor video captioning, there are major challenges that need to be continuously improved, such as maintaining temporal consistency andaccurate description of dynamic scenes, which increase the complexity in real-world applications, and new tasks that need to be studiedare presented such as temporal relationship modeling and multimodal data integration."
딥 뉴럴 네트워크를 활용한 강우 나우캐스팅의 최신 동향과 한계 극복을 위한 향후 과제,2024,"['Nowcasting', 'Deep neural networks', 'Convolutional neural networks', 'Recurrent neural networks', 'Generative adversarial networks', 'Extreme rainfall', '나우캐스팅', '딥 뉴럴 네트워크', '합성곱 신경망', '순환 신경망', '생성적 적대 신경망', '극한 강우']","딥러닝 모델은 방대한 데이터를 활용하여 강우 시스템의 복잡한 시공간 패턴을 효과적으로 포착함으로써, 기존 수치예보(Numerical Weather Prediction, NWP) 모델과 레이더 에코 외삽법의 계산 속도 및 비선형 강수 동역학 처리의 한계를 보완하여 단기 강우 예측에서 뛰어난 성과를 보이고 있다. 이에 따라, 본 논문에서는 딥러닝 기반 강우 나우캐스팅 모델을 체계적으로 리뷰하고, 합성곱 신경망(Convolutional Neural Networks, CNN), 순환 신경망(Recurrent Neural Networks, RNN), 생성적 적대 신경망(Generative Adversarial Networks, GAN) 기반의 세 가지 주요 그룹으로 분류하여 분석하였다. 또한, 각 모델에서 나온 공통적인 한계점과 이들 문제를 해결하기 위한 전략을 심도 있게 조사하였다. 다양한 손실함수의 적용, 전이학습, 샘플링, 그리고 앙상블 모델의 활용과 같은 혁신적인 접근법이 모델 성능 개선에 미치는 영향을 논의하며, 이를 바탕으로 강우 나우캐스팅의 향후 연구 방향을 제시한다. 본 리뷰는 강우 나우캐스팅에 대한 딥러닝 기반 기술의 현재 상태를 이해하고, 향후 연구 및 기술 발전을 위한 지침을 제공하는 데 기여하고자 한다.","Deep learning models have demonstrated remarkable performance in short-term rainfall prediction by effectively capturing the complex spatiotemporal patterns of rainfall systems using vast datasets. This has helped to address the limitations of traditional Numerical Weather Prediction (NWP) models and radar echo extrapolation methods, such as computational speed and nonlinear precipitation dynamics. In this paper, we systematically review deep learning-based rainfall nowcasting models, categorizing them into three main groups: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs). We also conduct an in-depth analysis of the common limitations identified in these models and explore strategies to overcome them. Innovative approaches, such as the application of diverse loss functions, transfer learning, sampling techniques, and ensemble models, are discussed in terms of their impact on enhancing model performance. Based on these findings, we propose future research directions for rainfall nowcasting. This review aims to provide a comprehensive understanding of the current state of deep learning-based technologies for rainfall nowcasting and serve as a guide for future research and technological advancements in the field."
Method for Recognition of Tennis Error Training Action Based on Artificial Intelligence Technology,2024,"['AI', 'Tennis training', 'Action recognition']",,"Artificial intelligence (AI) has brought great changes to the traditional sports industry. In order to solve the shortcomings of current recognition methods for tennis error training and obtain better recognition effect, we constructed a recognition method based on AI technology. A random projection algorithm was used to reduce the dimension of feature vectors, a CNN (convolutional neural network) model was used to learn training samples after dimension reduction, and a recognition model of wrong tennis training actions was constructed. The preprocessing of data included converting the original Cartesian coordinate system into a cylindrical coordinate system and normalizing the time of a skeletal motion sequence. Experiments show that the recognition accuracy of this model on the NTU-RGB+D dataset can reach 95.34%. The recognition accuracy of this model on the UTD-MHAD dataset can reach 94.12%. Compared with another model, the accuracy of this model was improved, which verified the superiority of this model. It can provide some technical support for the recognition of wrong tennis training actions and improve the tennis teaching effect and students’ learning level."
계층적 컨볼루션 신경망 기반의 최적화된 다중 IoT 서비스 관리 기법,2024,"['클라우드 서비스', '블록체인', '사물인터넷', '확률', '가중치', '사용자 정보 관리 기술', 'cloud service', 'blockchain', 'internet of things', 'probability', 'weighted value', 'user information management technology']",,"Due to the diversity of IoT contexts, it is not easy to satisfy both the security and efficiency of IoT resources these days. In particular, the integrity of IoT resources is not fully guaranteed in the distributed IoT environment (manager error handling, service error, etc.), which is difficult to directly manage IoT resources. In this study, we propose an optimized multi-IoT resource management technique based on hierarchical convolution (CNN) to efficiently manage IoT resources in a distributed IoT environment. The proposed technique aims to optimize the distribution of IoT resources by collecting the attributes of IoT resources from various paths and then using convolution and attack pattern pooling. In particular, the proposed technique connects each IoT resource with the attack pattern based on the blockchain, connecting each IoT resource with a hash chain, and through this, efficiently verifying the resource with an attack pattern. In addition, the proposed technique enables the efficient operation of IoT resources by processing IoT resource blocks in a hierarchical multi-step method so that the amount of IoT resources between servers and IoT devices is not dynamically processed. In the event of unexpected interference or attack between IoT devices in a distributed environment, the proposed technique hashes the resources of IoT devices asymmetrically to allow minimum errors in IoT resources and to secure resource connectivity. As a result of the experiment, IoT resource verification time was improved by an average of 8.1%, and IoT resource accuracy was improved by up to 13.5%. This result is because, depending on the likelihood value of IoT resources, association processing between the corresponding resources may occur. In addition, the proposed technique minimizes the cost of processing IoT resources by distinguishing IoT resources to be processed at IoT servers and IoT resources to be executed at the server stage in order to efficiently transmit information from IoT devices."
스마트 농업을 위한 YOLO 기반 작물 해충 탐지 모바일 애플리케이션,2024,"['Object Detection', 'YOLO Algorithm', 'Deep Learning', 'Progressive Web App', 'Smart Farming']","작물 해충은 작물 수확량 감소의 주된 원인 중 하나로, 식량농업기구(FAO)의 추정에 따르면 전 세계적으로 해충과 질병으로 인한 작물 손실이 20~40%에 이른다. 인구 증가와 기후 변화가 이 문제를 더욱 심화시키고 있다. 이에 본 논문에서는 쌀 생산에 심각한 위협을 주는 해충을 조기에 탐지하고, 초기 피해에 대응할 수 있는 적절한 살충제 정보를 제공함으로써 수확량 감소를 줄이고 환경 오염도 완화하는 방법을 제안한다. 현실적인 실외 환경에서 수집된 데이터를 데이터 증강 기술로 확장한 후, YOLO 기반의 컨볼루션 신경망(CNN)을 사용하여 훈련시켜 95.2%의 mAP@0.5 지표로 높은 정확도를 달성한 모델을 개발하였다. 또한, 작물 해충의 종류와 권장 살충제 정보를 제공하기 위해 서버에 데이터베이스를 구축하였다. 이렇게 개발된 YOLOv8 모델과 데이터베이스를 통합하여 플랫폼 독립적으로 작동하는 PWA(Progressive Web App)를 개발했다. 이 앱은 네트워크 연결이 불안정하거나 없는 야외 환경에서도 작동 가능하며, 특히 원거리 농촌 지역에 큰 이점을 제공하여 해충 탐지와 살충제 정보 접근성을 향상시킨다.","Crop pests are one of the primary causes of reduced agricultural yields, with the Food and Agriculture Organization (FAO) estimating that global crop losses due to pests and diseases range from 20% to 40%. The escalating issues of population growth and climate change further exacerbate this problem. This paper proposes a method to mitigate yield reductions and environmental pollution by providing timely pest detection and appropriate pesticide information for rice production, which faces significant threats from pests. By applying data augmentation techniques to real-world outdoor data, and by training a YOLO-based convolutional neural network, our model achieved high accuracy with a 95.2% mAP@0.5 metric. Additionally, a server database was constructed to provide information on types of crop pests and recommended pesticides. Using the developed YOLOv8 model and database, we developed a platform-independent progressive web app that operates even in areas with unstable or no network connections. The app is particularly beneficial in remote rural areas, enhancing access to pest detection and pesticide information."
딥페이크 검출을 위한 일반화된 메타러닝 EfficientNet 비전 변환기 모델,2024,"['Deepfake Detection', 'Vision Transformer', 'Generalization', 'Video Forensics', 'Meta-Learning', 'EfficientNet']",,"Digitally manipulated images that are realistic-looking but fake, which are known as Deepfake. With the remarkable developments in deep generative models, the accessibility and accuracy of manipulated technologies are increasing, leading to fake videos becoming increasingly difficult to identify. Different facial forgery techniques result in complicated data distributions, but Deepfake detection techniques based on CNN(convolutional neural network) architecture are utilized in the majority of Deepfake detection models as binary classification problems. In this paper, we propose a model, named MEViT, which uses a combination of EfficientNet Vision Transformer with a meta-learning-based technique to improve the generalization of the detection model. Furthermore, we propose a learning process to update the model and introduce pair-discrimination loss and domain adjustment loss to improve detection ability across various domains. We also create various experiments on several Deepfake datasets and compare our proposal with many state-of-the-art works to prove the efficiency of our approach."
Development of Attention-Enabled Multi-Scale Pyramid Network-Based Models for Body Part Segmentation of Dairy Cows,2024,['Precision livestock farming · Deep learning · Dairy cattle · Semantic segmentation · Computer vision'],,"Purpose Automated assessment of dairy cow traits, important for productivity evaluation, provides advantages by mitigating personal biases, measurement errors, and stress factors typically associated with manual assessment. To develop such a system, the initial step involves accurately segmenting cow body regions for subsequent trait measurement.Methods Thus, the present study introduces a refined DeepLabV3 + CNN model with EfficientNetB2 as the backbone and enhanced with attention mechanisms, aiming for precise segmentation of cow body regions from lateral and posterior views.In the DeepLabV3 + model, various backbone models, including MobileNet, MobileNetV2, MobileNetV3, EfficientNetB0, EfficientNetB1, and EfficientNetB2, were evaluated. Among these, EfficientNetB2 exhibited superior performance in lateral view segmentation, achieving a mean Intersection-over-union (m-IoU) of 94.19%. To further enhance segmentation accuracy, attention mechanisms such as Squeeze and Excitation (SE), Residual connection-infused Squeeze and Excitation (SER), Convolutional Block Attention Module (CBAM), and Residual connection-infused Convolutional Block Attention Module (CBAMR) were incorporated into the DeepLabV3 + model.Results The introduction of attention mechanisms in the EfficientNetB2 model led to enhanced m-IoU values: SE (94.27%), SER (94.25%), CBAM (94.59%), and CBAMR (94.66%). EfficientNetB2, integrated with CBAM and Residual connections (termed CBAMR), found to be top-performing model, achieving m-IoU values of 94.66% (lateral view), 93.77% (posterior view), and 99.61% (stature). The lateral view segmentation demonstrated high IoU for the body (98.73%) and rump (96.54%), with lowest IoU for teats (79.70%) due to their smaller spatial presence in input image. For posterior view regions, the CBAMR model achieved IoU scores above 79.0%, with the rear leg showing the highest (96.70%) and rump bones the lowest (79.52%). The segmentation accuracy for stature exceeded 90.0%, indicating less complexity in single-body region segmentation.Conclusions Therefore, these developed models demonstrate considerable accuracy in segmenting cow regions, making a significant contribution to the advancement of computer vision–based systems for measuring linear-type traits, and hold promise for deployment in such an automatic system."
RGB-D 센서 기반 실내 자율 감시 로봇,2024,"['Autonomous Patrol', 'Digital Control', 'RGB-D Sensor', 'ROS', 'Surveillance Robot', '자율정찰', '디지털제어', 'RGB-D 센서', '로봇운영체계', '감시로봇']",,"This article presents an autonomous surveillance robot with an Red-Green-Blue-Depth (RGB-D) sensor. The robot incorporates Simultaneous Localization and Mapping (SLAM), autonomous patrol, face recognition, and human tracking. Based on mathematical modeling, the control system of the robot is designed with proportional-integral- differential (PID) controllers. Autonomous patrol is achieved through the control system and Robot Operating System (ROS) Navigation Stack. A Convolutional Neural Network (CNN) model is employed for face recognition.For human tracking, a position-control system is developed based on skeleton tracking. The integration of these functions into a single system results in a low-cost surveillance robot, which is tested in real-life environments."
배관 누수 감지를 위한 트리플렛 신경망을 활용한 이상치 분포 분리,2024,"['Leakage Detection', 'Anomaly Detection', 'Triplet Network', 'Machine Learning', 'Deep Learning', '누수 감지', '이상치 탐지', '트리플렛 신경망', '기계 학습', '딥러닝']","본 논문에서는 스마트 공정의 배관 누수 감지 문제를 해결하기 위해 트리플렛 네트워크 기반의 이상 탐지 방법을 제안한다. 기존의 머신러닝과 딥러닝 기법은 부족한 데이터 수뿐만 아니라, 데이터 잡음으로 인해 정상과 누수 데이터의 분포가 섞여 있음을 문제로 삼고 이는 정확한 누출 감지에 어려움이 있음을 설명한다. 제안한 방법은 트리플렛 신경망을 통해 정상 데이터와 누수 데이터의 잠재 벡터를 분리하여 잡음 문제 및 데이터 희소성 문제를 해결한다. 그 결과 비교 모델보다 높은 F1 점수를 보였으며, 그 중에서도 트리플렛 신경망을 적용한 CNN 모델이 가장 우수한 F1 점수와 강건성을 보였다. 그러나 한 번의 실수가 크게 작용하는 배관 누수 감지 문제에서는 더 높은 F1 점수를 기록할 필요가 있음을 언급한다.","This study proposes a triplet network-based anomaly detection method to solve the problem of pipe-leak detection in smart processes. Existing machine learning and deep learning techniques suffer from not only insufficient data numbers but also data noise, which causes the distribution of normal and leaky data to be mixed, making it difficult to accurately detect leaks. The proposed method solves the noise and data sparsity problems by separating the latent vectors of normal and leaky data through a triplet neural network. The results show higher F1 scores than comparative models do, and the convolutional neural network model with the triplet neural network has the best F1 score and robustness. However, it is noted that higher F1 scores are needed to address the pipe-leak detection problem, where a single mistake plays a major role."
Machine Learning Using Template-Based-Predicted Structure of Haemagglutinin Predicts Pathogenicity of Avian Influenza,2024,"['Convolutional neural network', 'principal component analysis', 'abnormality detection', 'machine learning', 'avian influenza', 'haemagglutinin']",,"Deep learning presents a promising approach to complex biological classifications, contingent upon the availability of well-curated datasets. This study addresses the challenge of analyzing threedimensional protein structures by introducing a novel pipeline that utilizes open-source tools to convert protein structures into a format amenable to computational analysis. Applying a twodimensional convolutional neural network (CNN) to a dataset of 12,143 avian influenza virus genomes from 64 countries, encompassing 119 hemagglutinin (HA) and neuraminidase (NA) types, we achieved significant classification accuracy. The pathogenicity was determined based on the presence of H5 or H7 subtypes, and our models, ranging from zero to six mid-layers, indicated that a four-layer model most effectively identified highly pathogenic strains, with accuracies over 0.9.To enhance our approach, we incorporated Principal Component Analysis (PCA) for dimensionality reduction and one-class SVM for abnormality detection, improving model robustness through bootstrapping. Furthermore, the K-nearest neighbor (K-NN) algorithm was fine-tuned via hyperparameter optimization to corroborate the findings. The PCA identified distinct clustering for pathogenic HA, yielding an AUC of up to 0.85. The optimized K-NN model demonstrated an impressive accuracy between 0.96 and 0.97. These combined methodologies underscore our deep learning framework's capacity for rapid and precise identification of pathogenic avian influenza strains, thus providing a critical tool for managing global avian influenza threats."
"Review of medical imaging systems, medical imaging data problems, and XAI in the medical imaging field",2024,"['Artificial Intelligence (AI)', 'Deep learning (DL)', 'Medical imaging equipment', 'medical image data', 'Picture Archiving and Communication System (PACS)', 'explainable artificial intelligence (XAI)']",,"Currently, artificial intelligence (AI) is being applied in the medical field to collect and analyze data such as personal genetic information, medical information, and lifestyle information. In particular, in the medical imaging field, AI is being applied to the medical imaging field to analyze patients' medical image data and diagnose diseases. Deep learning (DL) of deep neural networks such as CNN and GAN have been introduced to medical image analysis and medical data augmentation to facilitate lesion detection, quantification, and classification. In this paper, we examine AI used in the medical imaging field and review related medical image data acquisition devices, medical information systems for transmitting medical image data, problems with medical image data, and the current status of explainable artificial intelligence (XAI) that has been actively applied recently. In the future, the continuous development of AI and information and communication technology (ICT) is expected to make it easier to analyze medical image data in the medical field, enabling disease diagnosis, prognosis prediction, and improvement of patients' quality of life. In the future, AI medicine is expected to evolve from the existing treatment-centered medical system to personalized healthcare through preemptive diagnosis and prevention."
자율주행 차량 시뮬레이션에서의 강화학습을 위한 상태표현  성능  비교,2024,"['자율주행', '강화학습', '상태  표현', '시뮬레이션', '가상환경', 'Autonomous driving', 'Reinforcement learning', 'State representation', 'Simulation', 'Virtual environment']","딥러닝과 강화학습을 활용한 비전 기반 엔드투엔드 자율주행 시스템 관련 연구가 지속적으로 증가하고 있다. 일반적으로 이러한 시스템은 위치, 속도, 방향, 센서 데이터 등 연속적이고 고차원적인 차량의 상태를 잠재 특징 벡터로 인코딩하고, 이를 차량의 주행 정책으로 디코딩하는 두 단계로 구성된다. 도심 주행과 같이 다양하고 복잡한 환경에서는Variational Autoencoder(VAE)나 Convolutional Neural Network(CNN)과 같은 네트워크를 이용한 효율적인 상태 표현방법의 필요성이 더욱 부각된다. 본 논문은 차량의 이미지 상태 표현이 강화학습 성능에 미치는 영향을 분석하였다.CARLA  시뮬레이터 환경에서 실험을 수행하였고, 차량의 전방 카메라 센서로부터 취득한 RGB  이미지 및 Semantic Segmented 이미지를 각각 VAE와 Vision Transformer(ViT) 네트워크로 특징 추출하여 상태 표현 학습에 활용하였다. 이러한 방법론이 강화학습에 미치는 영향을 실험하여, 데이터 유형과 상태 표현 기법이 자율주행의 학습 효율성과 결정능력 향상에 어떤 역할을 하는지를 실험하였다.","Research into vision-based end-to-end autonomous driving systems utilizing deep learning and reinforcement learning has been steadily increasing. These systems typically encode continuous and high-dimensional vehicle states, such as location, velocity, orientation, and sensor data, into latent features, which are then decoded into a vehicular control policy. The complexity of urban driving environments necessitates the use of state representation learning through networks like Variational Autoencoders (VAEs) or Convolutional Neural Networks (CNNs). This paper analyzes the impact of different image state encoding methods on reinforcement learning performance in autonomous driving. Experiments were conducted in the CARLA simulator using RGB images and semantically segmented images captured by the vehicle’s front camera. These images were encoded using VAE and Vision Transformer (ViT) networks. The study examines how these networks influence the agents’ learning outcomes and experimentally demonstrates the role of each state representation technique in enhancing the learning efficiency and decision- making capabilities of autonomous driving systems."
Attention layer를 활용한 이미지 기반 피부암 분류 시스템,2024,"['Skin Cancer', 'Image Classification', 'Attention', 'Imbalanced Data']","고령화가 심화되면서 암 발병률이 증가하고 있다. 피부 암은 외적으로 보이지만 사람들이 알아채지 못하거나 가볍게 간과하는 경우가 많다. 이에 초기 발견 시기를 놓쳐 말기의 경우 생존율이 7.5~11%로 사망에 이를 수 있다. 하지만 피부 암을 진단함에있어 육안으로 진단하는 것이 아닌 정밀검사, 세포 검사 등 시간과 비용이 많이 든다는 단점이 있다. 따라서 본 연구에서는 이러한 단점을 해결하기 위해 Attention CNN 모델 기반 피부암 분류 시스템을 제안한다. 이 시스템은 전문의로 하여금 피부 암을 초기에 발견하여 신속한 조치를 취할 수 있도록 하는데 큰 도움을 줄 수 있다. 피부암 종류에 따른 이미지 데이터 불균형 문제에서분포 비율이 낮은 데이터에는 Over Sampling 기법을, 분포 비율이 높은 데이터에는 Under Sampling 기법을 적용하여 완화하고Attention layer가 없는 모델과 있는 모델을 비교하여 Attention layer가 없는 사전학습 모델에 추가한 피부암 분류 모델을 제안한다. 또한, 특정 클래스에 대하여 데이터 증강 기법을 강화하여 데이터 불균형 문제를 해결할 계획이다.","As the aging population grows, the incidence of cancer is increasing. Skin cancer appears externally, but people often don’t noticeit or simply overlook it. As a result, if the early detection period is missed, the survival rate in the case of late stage cancer is only7.5-11%. However, the disadvantage of diagnosing, serious skin cancer is that it requires a lot of time and money, such as a detailedexamination and cell tests, rather than simple visual diagnosis. To overcome these challenges, we propose an Attention-based CNNmodel skin cancer classification system. If skin cancer can be detected early, it can be treated quickly, and the proposed system cangreatly help the work of a specialist. To mitigate the problem of image data imbalance according to skin cancer type, this skin can cer classification model applies the Over Sampling, technique to data with a high distribution ratio, and adds a pre-learning modelwithout an Attention layer. This model is then compared to the model without the Attention layer. We also plan to solve the dataimbalance problem by strengthening data augmentation techniques for specific classes."
딥러닝을 활용한 고대 수막새 이미지 분류 검토,2024,"['디지털 고고학', 'AI 고고학', '딥러닝', '머신 러닝', '수막새']","최근 의료, 제조, 자율주행, 보안 등 다양한 분야에서 인공지능과 컨볼루션 신경망 등 딥러닝 기술을 활용한 연구들이 활발하게 진행되고 있으며, 사회 전반에 적지 않은 영향을 미치고 있다. 본 연구 또한 이러한 흐름에 맞춰서 고고학 유물 분류에 딥러닝을 활용해 보았다. 즉, 연구는 고고학 조사를 통해 출토된 고대 수막새의 이미지 분류에 딥러닝 기술을 적용하는 초보적 시도로서, 고구려, 백제, 신라 시대의 수막새 이미지를 CNN 모델로 학습시켜 분류를 진행하였다.고구려, 백제, 신라 수막새 이미지 각각 100장씩 총 300장을 기반으로 기본 데이터셋을 형성하였고, 데이터 증강 기법을 활용하여 4배를 증가시킴으로써 총 1,200장을 데이터셋으로 구축하였다. 사전 훈련된 EfficientNetB0 모델의 전이학습을 통하여 모델을 구축한 후, 5겹 교차검증을 실시한 결과 평균 학습 정확도 98.06%, 검증 정확도 97.08%를 기록하였다.또한 학습된 모델을 240장의 테스트 데이터셋으로 성능을 평가한 결과, 최소 91% 이상의 높은 정확도로 삼국의 수막새 이미지를 시대별로 구분할 수 있음을 확인하였다. 특히 학습률 0.0001에서 정확도 92.92%, 정밀도 92.96%, 재현율 92.92%, F1 점수 92.93%로 가장 우수한 성능을 보였는데, 이는 다양한 학습률 설정을 통하여 과적합과 과소적합 문제를 방지함과 동시에 최적의 매개변수를 찾는 과정에서 이루어졌다.본 연구의 결과는 한국 고고학 자료의 분류에 딥러닝 기술 활용 가능성을 확인했다는 점에서 의의가 있다고 생각된다. 또한 기존에 축적·제작된 ImageNet 데이터셋 및 파라미터가 고고 자료 분석에도 긍정적으로 적용할 수 있음을 확인하였다. 이러한 접근은 향후 고고학 데이터베이스 축적이나 활용, 박물관의 유물 분류 및 정리 등 다양한 방식의 모델을 창출할 수 있을 것이다.","Recently, research using deep learning technologies such as artificial intelligence, convolutional neural networks, etc. has been actively conducted in various fields including healthcare, manufacturing, autonomous driving, and security, and is having a significant influence on society. In line with this trend, the present study attempted to apply deep learning to the classification of archaeological artifacts, specifically ancient Korean roof-end tiles.Using 100 images of roof-end tiles from each of the Goguryeo, Baekje, and Silla dynasties, for a total of 300 base images, a dataset was formed and expanded to 1,200 images using data augmentation techniques. After building a model using transfer learning from the pre-trained EfficientNetB0 model and conducting five-fold cross-validation, an average training accuracy of 98.06% and validation accuracy of 97.08% were achieved.Furthermore, when model performance was evaluated with a test dataset of 240 images, it could classify the roof-end tile images from the three dynasties with a minimum accuracy of 91%. In particular, with a learning rate of 0.0001, the model exhibited the highest performance, with accuracy of 92.92%, precision of 92.96%, recall of 92.92%, and F1 score of 92.93%. This optimal result was obtained by preventing overfitting and underfitting issues using various learning rate settings and finding the optimal hyperparameters.The study’s findings confirm the potential for applying deep learning technologies to the classification ofKorean archaeological materials, which is significant. Additionally, it was confirmed that the existing ImageNet dataset and parameters could be positively applied to the analysis of archaeological data. This approach could lead to the creation of various models for future archaeological database accumulation, the use of artifacts in museums, andclassification and organization of artifacts."
Data quality augmentation and parallel network modeling for residual life prediction of lithium‑ion batteries,2024,"['Li-ion battery remaining life prediction', 'Convolutional neural network', 'Long short-term memory network', 'Parallel network']",,"Research on the data-driven health state estimation of lithium-ion batteries has gained signifi cant attention in recent years. However, the practical implementation of obtaining one data point in one cycle has resulted in poor data quality, leading to low accuracy and prediction instability. To overcome this challenge, a two-step approach is proposed. First, available data are enriched using Akima spline curve interpolation, and the overall degradation trend of the battery is extracted as a Sigmoid function, enhancing the data quality. Second, a parallel network model that combines the strengths of the convolutional neural network (CNN) and the long short-term memory network (LSTM) is introduced. This model leverages the ability of one-dimensional convolutional neural network (1DCNN) to effectively capture local features and proficiency of the LSTM in capturing long-term dependencies. By employing this hybrid model, a better understanding and prediction of the remaining battery life is achieved. Finally, based on the NASA public battery dataset, expanded and decomposed data are trained and predicted by the parallel network model. Experimental results demonstrate that the proposed method exhibits high accuracy and strong generalization capability."
FS-Transformer: A new frequency Swin Transformer for multi-focus image fusion,2024,"['Multi-focus image fusion', 'Swin Transformer', 'Wavelet Transform', 'Deep learning']",,"In recent years, multi-focus image fusion has emerged as a prominent area of research, with transformers gaining recognition in the field of image processing. Current approaches encounter challenges such as boundary artifacts, loss of detailed information, and inaccurate localization of focused regions, leading to suboptimal fusion outcomes necessitating subsequent post-processing interventions. To address these issues, this paper introduces a novel multi-focus image fusion technique leveraging the Swin Transformer architecture. This method integrates a frequency layer utilizing Wavelet Transform, enhancing performance in comparison to conventional Swin Transformer configurations. Additionally, to mitigate the deficiency of local detail information within the attention mechanism, Convolutional Neural Networks (CNN) are incorporated to enhance region recognition accuracy. Comparative evaluations of various fusion methods across three datasets were conducted in the paper. The experimental findings demonstrate that the proposed model outperformed existing techniques, yielding superior quality in the resultant fused images."
수어 번역을 위한 3차원 컨볼루션 비전 트랜스포머,2024,"['수어 번역', '트랜스포머', '컨볼루전 트랜스포머', 'Sign Language Translation', 'Transformer', 'Convolutional Transformer']",,"In the Republic of Korea, people with hearing impairments are the second-largest demographic within the registered disability community, following those with physical disabilities. Despite this demographic significance, research on sign language translation technology is limited due to several reasons including the limited market size and the lack of adequately annotated datasets. Despite the difficulties, a few researchers continue to improve the performance of sign language translation technologies by employing the recent advance of deep learning, for example, the transformer architecture, as the transformer-based models have demonstrated noteworthy performance in tasks such as action recognition and video classification. This study focuses on enhancing the recognition performance of sign language translation by combining transformers with 3D-CNN. Through experimental evaluations using the PHOENIX-Wether-2014T dataset [1], we show that the proposed model exhibits comparable performance to existing models in terms of Floating Point Operations Per Second (FLOPs)."
Deep Inter Prediction for Versatile Video Coding (VVC),2024,"['Deep Learning', 'Inter Prediction', 'Frame Generation', 'Versatile Video Coding (VVC)']",,"'A sophisticated video surveillance system involves the problem of limited video storage to record video data for long time. Video compression technology is an effective solution to address this problem. Inspired by the success of neural network-based approaches in computer vision, research on neural network-based video coding has emerged. With the aim of achieving improved compression efficiency, an investigation on inter prediction plays a crucial role in neural network-based video coding. In this paper, we propose a convolutional neural network (CNN)-based generation and enhancement method for inter prediction (GEIP) in the Versatile Video Coding (VVC) standard. By leveraging fused features and self-attended features based on attention mechanism, the proposed method maximizes inter prediction performance. When compared with VTM-11.0 NNVC-1.0 anchor, it is verified that the BDrate reduction of the proposed method can be achieved up to 7.06% on Y component under random access (RA) configuration."
얼굴영상과 얼굴의 텍스처 및 연대기나이 데이터를 이용한 인지나이 예측,2024,"['Perceived age', 'Age estimation', 'Facial image', 'Regression']",,"People of the same chronological age can show different signs of aging. Biological age is an indicator of the degree of biological aging of the body excluding diseases. Perceived age is highly correlated with biological age, which reflects health assessment, and is often used as a clinical indicator of aging. However, there is a lack of objective methods to quantify perceived age. Therefore, this study aimed to propose a novel perceived age esti- mation algorithm. The proposed algorithm consists of two steps. First, the initial perceived age is predicted from a facial image using a convolutional neural network (CNN) ensemble model. In the second step, the final perceived age is estimated by applying a regression algorithm to the predicted gender, predicted BMI, texture features extracted from the facial image, and the predicted perceived age obtained in the first step. Better performance results were obtained by averaging models generated from various base regression models. The averaged model of CatBoost and LightGBM showed a mean absolute error of 2.9614. The proposed method can be used as a health care model to promote self-care."
드론 방제의 최적화를 위한 딥러닝 기반의 밀도맵 추정,2024,"['Image Processing(영상처리)', 'Agricultural drone(농업용 드론)', 'Spraying performance(살포 성능)', 'Water sensitive paper(감수지)', 'Droplet Measurement(액적 측정)', 'Density map(밀도맵)']",,
Corrosion area detection and depth prediction using machine learning,2024,"['Ship corrosion', 'Corrosion detection', 'Depth predicting', 'Machine learning']",,"Corrosion reduces the thickness of a structure, making it less safe and reducing its lifespan. In particular, ships are vulnerable to corrosion because they are always submerged in seawater. This corrosion is identified through regular inspections of the ship structure, and gradually increases in scope if no action is taken at an early stage. In this study, we developed a model to detect the corrosion areas and predict the depth of corrosion in the detected areas. The corrosion area detection model used a machine learning model based on Mask R-CNN. The 35,753 images were used to map corrosion images and measured corrosion depths. Four different color maps and regression algorithm were used to predict corrosion depths and their performance was compared. The new attempt to predict the corrosion depth from images in this study will contribute to improving existing corrosion control methods by providing information for corrosion prevention and maintenance."
딥러닝 기반 콘크리트 균열 검출 기술에 관한 연구,2024,"['균열 탐지', '인공지능', '균열', '성능지표', 'Crack detection', 'artificial intelligence', 'YOLO', 'crack', 'Performance Indicators']",,"When buildings deteriorate, they may develop defects like surface cracks and structural subsidence. If left unaddressed, these issues can significantly weaken the structure, potentially leading to collapse accidents. Detecting cracks promptly is crucial to prevent such outcomes. With the advancements in artificial intelligence, researchers are exploring deep learning techniques to identify microscopic cracks, replacing traditional manual methods. As AI technology progresses, diverse AI models have emerged, enhancing the reliability of crack detection data for field inspections. This study focuses on leveraging the Yolo model, known for its superior performance and faster data acquisition compared to other AI models. By incorporating object detection methods used by CNN, the study aims to enhance the detection performance of the model by considering various variables across different AI models and detection techniques."
딥러닝 모델을 이용한 실시간 부정맥 감지 이중화 모바일 시스템,2024,"['심전도', 'R-피크', '신호분석', '딥러닝', '부정맥', 'Electrocardiogram (ECG)', 'R-Peak', 'Signal Analysis', 'Deep Learning', 'Arrhythmia']",,"In this study, a system is introduced that integrates a wearable electrocardiogram (ECG) sensor device, a portable smartphone, and a server that performs accurate ECG analysis. The system that performs accurate analysis on ECG signals detects the most important signs of arrhythmia using a deep learning model and transmits warning notifications to the portable smartphone. The system continues detection using a small-scale lightweight detection analysis system in case of communication failure with the ECG analysis server system. In addition, we introduce an algorithm for R-peak detection of ECG signals—which is essential for the detection of arrhythmia—a CNN model specifically designed for this purpose, and a method of adjusting the threshold for the output of the deep learning model. Therefore, using the proposed system, the efficiency of arrhythmia diagnosis can be improved."
Classification of Cognitive Impairment Using Quadratic Discriminant Analysis Based Spiral Dynamic Optimization Algorithm,2024,['Mild cognitive impairment  · Quadratic discriminant analysis  · Spiral dynamic optimization algorithm'],,"This research uses machine learning techniques for the classifi cation of cognitive impairment using Quadratic Discriminant Analysis (QDA) based Spiral Dynamic Optimization Algorithm (SDOA). The proposed method employs a machine learning classifi er coupled with a series of pre-processing techniques encompassing image contrast enhancement and feature extraction and selection. Linear contrast stretch is utilized for image contrast enhancement, while stacked auto-encoder (SAE) is employed for feature extraction. The feature selection process is optimized using the Adam optimizer within the QDA framework. The classifi cation process is executed through the QDA classifi er, and the obtained results are compared with those derived from CNN and QDA classifi cation methods. The primary objective of this study is to assess the eff ectiveness of the proposed machine learning method in distinguishing between Early Mild Cognitive Impairment (EMCI) and Mild Cognitive Impairment (MCI). Addressing the defi ciencies in existing research related to the early detection of MCI, the study focuses on enhancing robustness and accuracy. The fi ndings reveal that the accuracy rate of the QDA-SDOA classifi cation approach is 96%, which is a higher accuracy rate than MLSVM-RBFK, SVM-RF-MLR, NNITFS, E3DDCCN of 0.8%, 1.1.%, 1.4% and 0.9%, respectively. The classifi cation accuracy rate for meningioma MRIs highlights the superior accuracy of MCI classifi cation using QDA-SDOA in comparison to existing classifi ers."
생성형 AI 이미지 증강을 통한 참외 병해충 데이터 불균형 개선 및 분류 성능 향상,2024,"['Deep Learning', 'Image Augmentation', 'Plant Pests', 'Data Imbalance', 'Generative AI', 'Smart Farm']",,"Due to climate change, plant pests and diseases are becoming increasingly severe, posing significant challenges to agricultural productivity and crop quality. Additionally, although smart farming technologies attempt to address these issues, the difficulty in collecting balanced and sufficient data remains a major obstacle. This study proposes the use of generative AI models to create images as a solution to the data imbalance problem in plant pest datasets. The proposed method utilizes Generative Adversarial Networks (GAN) and Generative Pre-trained Transformer 4 (GPT-4) to generate high- quality synthetic images of plant pests. The augmented dataset is then used to train and evaluate state- of-the-art classification models, including Convolutional Neural Networks (CNN) and Transformer- based architectures. Experiments were conducted using a dataset of Korean melon (Cucumis melo L.) leaves, which are particularly susceptible to various pests and diseases. The results demonstrate that the proposed augmentation techniques significantly improve the performance of the classification models, with a specific method achieving the highest F1-score and accuracy. The generated images are also shown to be visually similar to real pest images, indicating the effectiveness of the augmentation approach."
Comparative Study of Ship Image Classification using Feedforward Neural Network and Convolutional Neural Network,2024,"['Ship Image Classification', 'Feedforward Neural Network', 'Convolutional Neural Network']",,"In autonomous navigation systems, the need for fast and accurate image processing using deep learning and advanced sensor technologies is paramount. These systems rely heavily on the ability to process and interpret visual data swiftly and precisely to ensure safe and efficient navigation. Despite the critical importance of such capabilities, there has been a noticeable lack of research specifically focused on ship image classification for maritime applications. This gap highlights the necessity for more in-depth studies in this domain. In this paper, we aim to address this gap by presenting a comprehensive comparative study of ship image classification using two distinct neural network models: the Feedforward Neural Network (FNN) and the Convolutional Neural Network (CNN). Our study involves the application of both models to the task of classifying ship images, utilizing a dataset specifically prepared for this purpose. Through our analysis, we found that the Convolutional Neural Network demonstrates significantly more effective performance in accurately classifying ship images compared to the Feedforward Neural Network. The findings from this research are significant as they can contribute to the advancement of core source technologies for maritime autonomous navigation systems. By leveraging the superior image classification capabilities of convolutional neural networks, we can enhance the accuracy and reliability of these systems. This improvement is crucial for the development of more efficient and safer autonomous maritime operations, ultimately contributing to the broader field of autonomous transportation technology."
Two-Stage Cascaded High-Precision Early Warning of Wind Turbine Faults Based on Machine Learning and Data Graphization,2024,['Data graphization · Fault early warning · Gramian angular feld · Wind turbines · Time generative adversarial network · Vision transformer'],,"Due to the limited accessibility of wind turbines (WTs) and the complexity of operation and maintenance (O&M), it is increasingly important to early warn the component faults of WTs, and the difculties lie in balancing the comprehensiveness and delicacy of early warning. In this paper, a two-stage cascaded high-precision fault early warning method based on machine learning (ML) and data graphization is proposed. The frst stage copes with the early warning of the main components, in which the supervisory control and data acquisition (SCADA) data are converted into Gramian Angular Field (GAF) images to establish the potential relationship of fault features at diferent time points, and the fault characteristics are extracted by convolutional neural network (CNN) to realize fault early warning for multiple main components simultaneously. The second stage focus on the fault subcomponents inside the main components further, in which the time generative adversarial network (TimeGAN) is adopted to enhance the fault code data samples, then the enhanced data in the form of grayscale images is input into the Vision Transformer (ViT) to train the subcomponent early warning model. The proposed method is validated with real SCADA data, the results show the efectiveness of the proposed method."
중소유통기업지원을 위한 상품 카테고리 재분류 기반의 수요예측 및 상품추천 방법론 개발,2024,"['Small and Medium Distribution Industry', 'Demand Forecasting', 'Recommendation', 'Time Series Prediction', 'Deep Learning']",,"Distribution and logistics industries contribute some of the biggest GDP(gross domestic product) in South Korea and the number of related companies are quarter of the total number of industries in the country. The number of retail tech companies are quickly increased due to the acceleration of the online and untact shopping trend. Furthermore, major distribution and logistics companies try to achieve integrated data management with the fulfillment process. In contrast, small and medium distribution companies still lack of the capacity and ability to develop digital innovation and smartization. Therefore, in this paper, a deep learning-based demand forecasting & recommendation model is proposed to improve business competitiveness. The proposed model is developed based on real sales transaction data to predict future demand for each product. The proposed model consists of six deep learning models, which are MLP(multi-layers perception), CNN(convolution neural network), RNN(recurrent neural network), LSTM(long short term memory), Conv1D-BiLSTM(convolution-long short term memory) for demand forecasting and collaborative filtering for the recommendation. Each model provides the best prediction result for each product and recommendation model can recommend best sales product among companies own sales list as well as competitor’s item list. The proposed demand forecasting model is expected to improve the competitiveness of the small and medium-sized distribution and logistics industry."
인공 지능 기술을 이용한 음성 인식 기술에 대한 고찰,2024,"['Speech Recognition', 'Deep Neural Networks', 'Silent Speech Interface', 'Lip-Reading Technology', 'Self-Supervised Learning']",,"This paper explores the recent advancements in speech recognition technology, focusing on the integration of artificial intelligence to improve recognition accuracy in challenging environments, such as noisy or low-quality audio conditions. Traditional speech recognition methods often suffer from performance degradation in noisy settings. However, the application of deep neural networks (DNN) has led to significant improvements, enabling more robust and reliable recognition in various industries, including banking, automotive, healthcare, and manufacturing. A key area of advancement is the use of Silent Speech Interfaces (SSI), which allow communication through non-speech signals, such as visual cues or other auxiliary signals like ultrasound and electromyography, making them particularly useful for individuals with speech impairments. The paper further discusses the development of multi-modal speech recognition, combining both audio and visual inputs, which enhances recognition accuracy in noisy environments. Recent research into lip-reading technology and the use of deep learning architectures, such as CNN and RNN, has significantly improved speech recognition by extracting meaningful features from video signals, even in difficult lighting conditions. Additionally, the paper covers the use of self-supervised learning techniques, like AV-HuBERT, which leverage large-scale, unlabeled audiovisual datasets to improve performance. The future of speech recognition technology is likely to see further integration of AI-driven methods, making it more applicable across diverse industries and for individuals with communication challenges. The conclusion emphasizes the need for further research, especially in languages with complex morphological structures, such as Korean"
서비스 자동화 시스템을 위한 물체 자세 인식 및 동작 계획,2024,"['Pose Detection', 'Object Detection', 'Grasping', 'Motion Planning', 'Point Cloud']",,"Recently, automated solutions using collaborative robots have been emerging in various industries. Their primary functions include Pick & Place, Peg in the Hole, fastening and assembly, welding, and more, which are being utilized and researched in various fields. The application of these robots varies depending on the characteristics of the grippers attached to the end of the collaborative robots. To grasp a variety of objects, a gripper with a high degree of freedom is required. In this paper, we propose a service automation system using a multi-degree-of-freedom gripper, collaborative robots, and vision sensors. Assuming various products are placed at a checkout counter, we use three camerasto recognize the objects, estimate their pose, and create grasping points for grasping. The grasping points are grasped by the multi-degree-of-freedom gripper, and experiments are conducted to recognize barcodes, a key task in service automation. To recognize objects, we used a CNN (Convolutional Neural Network) based algorithm and point cloud to estimate the object’s 6D pose. Using the recognized object’s 6d pose information, we create grasping points for the multi-degree-of-freedom gripper and perform re-grasping in a direction that facilitates barcode scanning. The experiment was conducted with four selected objects, progressing through identification, 6D pose estimation, and grasping, recording the success and failure of barcode recognition to prove the effectiveness of the proposed system."
Material-Adaptive Anomaly Detection Using Property-Concatenated Transfer Learning in Wire Arc Additive Manufacturing,2024,"['Wire arc additive manufacturing', 'Anomaly detection', 'Transfer learning', 'Convolutional neural network', 'Quality monitoring', 'Material property']",,"Wire arc additive manufacturing is a promising additive manufacturing process because of its high deposition rate, and material diversity. However, the low quality of melted parts is a critical issue, owing to the difficulty in establishing design rules for process–structure–property–performance. Previous studies have resolved this challenge by deriving anomaly detection models for quality monitoring and have largely relied on machine learning by training melt pool image data. Acquiring sufficient data is a key to obtaining reliable models in machine learning; however, an issue arises from concerning the cost intensiveness in high-cost materials. We propose a material-adaptive anomaly detection method to detect balling defects in a target material using property-concatenated transfer learning. First, transfer learing is applied to derive convolutional neural network (CNN)-based models from a source material and transfer them to a target material, wherein data are insufficient and machine learning rarely achieves high performance. Second, material properties are concatenated on transfer learning as additional features onto image features, contrary to typical transfer learning where CNNs only extract image features. We perform experiments in a gas tungsten arc welding system with low-carbon steel (LCS), stainless steel (STS), and inconel (INC) materials. Our models achieve best classification accuracies of 82.95%, 89.47%, and 84.22% when transferring from LCS to STS, LCS to INC, and STS to INC, respectively, compared with 78.03%, 86.37%, and 73.63% obtained using typical transfer learning. The proposed method can effectively resolve the data scarcity by model transfer from sufficient datasets in low-cost materials to rare datasets in high-cost materials. Moreover, it outperforms typical transfer learning because material properties are learned as manufacturing-knowledge features, accounting for melting and hardening characteristics of materials."
Ceramic tile surface defect detection with integrated feature engineering and defect fuse classifier,2024,"['Ceramic tile', 'Defect detection', 'Hybrid optimization model', 'Defectfuse classifier']",,"Introduction: Ceramic tile surface defect detection is crucial for ensuring product quality. This study proposes an integratedapproach combining feature engineering and a Defect Fuse Classifier for accurate defect detection. Methods: The proposedmodel utilizes Python and splits the collected data into 70% for training and 30% for testing. Purpose: The purposesection explicitly states the objectives of the study. It highlights the research goals, such as evaluating the effectiveness ofthe proposed methodology in detecting ceramic tile surface defects and exploring the impact of parameter variations ondetection performance. Results: Comparative analysis with state-of-the-art methods is conducted using various metrics suchas sensitivity, specificity, accuracy, precision, FPR, FNR, NPV, F-Measure, and MCC. (a) For a Training Rate of 70%: Theproposed Defect Fuse Classifier outperforms existing models with an accuracy of 97.4%, precision of 88.5%, sensitivity of88.5%, specificity of 98.5%, F-Measure of 88.5%, MCC of 87%, NPV of 98.5%, FPR of 1.4%, and FNR of 11.4%. Conclusion:This study introduces a novel deep learning approach for ceramic tile surface defect detection, encompassing data acquisition,pre-processing, feature extraction, feature selection, and deep learning-based defect detection. The proposed Defect FuseClassifier, integrating CNN, Bi-LSTM, and RNN, demonstrates superior performance, making it a promising solution fordefect detection in ceramic tile surfaces."
Predictive modeling algorithms for liver metastasis in colorectal cancer: A systematic review of the current literature,2024,"['Colorectal cancer', 'Liver metastasis', 'Prediction', 'Systematic review']",,"This study aims to assess the quality and performance of predictive models for colorectal cancer liver metastasis (CRCLM). A systematic review was performed to identify relevant studies from various databases. Studies that described or validated predictive models for CRCLM were included. The methodological quality of the predictive models was assessed. Model performance was evaluated by the reported area under the receiver operating characteristic curve (AUC). Of the 117 articles screened, seven studies comprising 14 predictive models were included. The distribution of included predictive models was as follows: radiomics (n = 3), logistic regression (n = 3), Cox regression (n = 2), nomogram (n = 3), support vector machine (SVM, n = 2), random forest (n = 2), and convolutional neural network (CNN, n = 2). Age, sex, carcinoembryonic antigen, and tumor staging (T and N stage) were the most frequently used clinicopathological predictors for CRCLM. The mean AUCs ranged from 0.697 to 0.870, with 86% of the models demonstrating clear discriminative ability (AUC > 0.70). A hybrid approach combining clinical and radiomic features with SVM provided the best performance, achieving an AUC of 0.870. The overall risk of bias was identified as high in 71% of the included studies. This review highlights the potential of predictive modeling to accurately predict the occurrence of CRCLM. Integrating clinicopathological and radiomic features with machine learning algorithms demonstrates superior predictive capabilities."
Fetal QRS Complexes Detection Using Deep Learning Technique,2024,['QRS complex detection · Fetal ECG · Deep learning techniques · Convolutional neural network'],,"The fetal Q, R, and S peaks complex detection in Non-invasive fetal ECG is an important procedure to ensure the fetal condition during the pregnancy. However, the detection process is quite complex because of the presence of large-amplitude maternal ECG signals. While conventional approaches lag, detecting devices should deliver data with low accuracy and low sensitivity. As a result of the fndings in the current study, an architecture based on a convolutional neural network model -LeNet is proposed for reliable detection of fetal QRS complexes. The proposed deep learning model is experimented with non-invasive fetal electrocardiogram (NI-fECG). NI-FECG physio net data and compared with conventional, support vector machine (SVM), Naive Bayes, k-nearest neighbor (KNN), and convolutional neural network (CNN) algorithms. With maximum accuracy of 99.46% the proposed model attains maximum performance for all other parameters like precision, recall and F-measure compared to existing state of art of techniques."
입경 분류된 토양의 RGB 영상 분석 및 딥러닝 기법을 활용한 AI 모델 개발,2024,"['Soil  texture', 'grain  size', 'computer  vision', 'deep  learning']",,"Soil texture is determined by the proportions of sand, silt, and clay within the soil, which influence characteristics such as porosity, water retentioncapacity, electrical conductivity (EC), and pH. Traditional classification of soil texture requires significant sample preparation including oven drying toremove organic matter and moisture, a process that is both time-consuming and costly. This study aims to explore an alternative method by developingan AI model capable of predicting soil texture from images of pre-sorted soil samples using computer vision and deep learning technologies. Soilsamples collected from agricultural fields were pre-processed using sieve analysis and the images of each sample were acquired in a controlled studioenvironment using a smartphone camera. Color distribution ratios based on RGB values of the images were analyzed using the OpenCV library inPython. A convolutional neural network (CNN) model, built on PyTorch, was enhanced using Digital Image Processing (DIP) techniques and thentrained across nine distinct conditions to evaluate its robustness and accuracy. The model has achieved an accuracy of over 80% in classifying theimages of pre-sorted soil samples, as validated by the components of the confusion matrix and measurements of the F1 score, demonstrating its potentialto replace traditional experimental methods for soil texture classification. By utilizing an easily accessible tool, significant time and cost savings canbe expected compared to traditional methods."
Benchmark study on a novel online dataset for standard evaluation of deep learning-based pavement cracks classification models,2024,"['Convolutional neural networks', 'Pavement cracks', 'Deep learning', 'Benchmark study', 'Crack classification']",,"Highway agencies and practitioners expect to have the most efficient method with adequate accuracy when choosing a deep learning-based model for pavement crack classification. However, many works are implemented on their own dataset, making them hard to compare with each other, and also less persuasive and robust. Therefore, a Road Cracks Classification Dataset is proposed to serve as a standard and open-source dataset. Based on this dataset, a benchmark study of fourteen deep learning classification methods is evaluated. Two parameters, the Ratio of F1 and Training Time (RFT) and Ratio of F1 and Prediction Time (RFP), are proposed to quantify the efficiency of networks. The results show that ConvNeXt_base reaches the highest accuracy among all models but requires the longest training time. AlexNet takes the least training time among all models, but gains the lowest accuracy. Of the four crack types, the block crack has the lowest accuracy, which means it is the most difficult to detect. SqueezeNet1_0 has the highest efficiency among all models in converting the computing power to accuracy. Wide ResNet 50_2 consumes the longest prediction time among CNN models, while the ConvNeXt_base has the highest feasibility on real-time tasks. To implement a suitable deep learning-based pavement crack inspection, we recommend a good balance between computational cost and accuracy. Based on this, we provide practical recommendations according to different user groups."
영상 패치 기반 그래프 신경망을 이용한 수동소나 신호분류,2024,"['수동소나', '그래프 표현', '영상 패치', '그래프 신경망', 'Passive sonar', 'Graph representation', 'Patch image', 'Graph Neural Network (GNN)']","본 논문에서는 그래프 신경망을 이용한 수동소나 신호 분류 알고리즘을 제안한다. 제안하는 알고리즘은 스펙트로그램을 영상 패치로 분할하고, 인접 거리의 영상 패치 간 연결을 통해 그래프를 표현한다. 이후, 표현된 그래프를이용하여 그래프 합성곱 신경망을 학습하고 신호를 분류한다. 공개된 수중 음향 데이터를 이용한 실험에서 제안된 알고리즘은 스펙트로그램의 선 주파수 특징을 그래프 형태로 표현하며, 92.50 %의 우수한 분류 정확도를 갖는다. 이러한결과는 기존의 합성곱 신경망과 비교하여 8.15 %의 높은 분류 정확도를 갖는다.","We propose a passive sonar signal classification algorithm using Graph Neural Network (GNN).The proposed algorithm segments spectrograms into image patches and represents graphs through connections between adjacent image patches. Subsequently, Graph Convolutional Network (GCN) is trained using the represented graphs to classify signals. In experiments with publicly available underwater acoustic data, the proposed algorithm represents the line frequency features of spectrograms in graph form, achieving an impressive classification accuracy of 92.50 %. This result demonstrates a 8.15 % higher classification accuracy compared to conventional Convolutional Neural Network (CNN)."
SMAGNet: Scaled Mask Attention Guided Network for Vision-based Gait Analysis in Multi-person Environments,2024,"['Video recognition', 'Computer vision', 'Gait analysis', 'Mask guided attention', 'Bi-level optimization']",,"Clinical gait analysis plays a key role in diagnosing and managing neurodegenerative diseases such as Parkinson’s disease. In recent years, vision-based gait analysis methods have emerged as promising non-invasive approaches to quantify gait characteristics. However, most methods assume single-person situations, but multi-person situations are more common in realworld medical settings. In this paper, we propose a novel mask-guided attention model called a Scaled Mask Guided Attention Network (SMAGNet), which exploits a target persons detection result to address multi-person issues. SMAGNet utilizes a detection box as a mask label to predict attention maps that highlight patients’ gait features and progressively refines the maps for accurate analysis. Experimental results show that the mean absolute percentage error (MAPE) was improved by up to 20% for the target spatio-temporal gait variable compared to the baseline 3D CNN (Convolutional Neural Networks). Moreover, we achieved significantly better performance compared to other methods, including a recent state-of-the-art gait recognition model named GaitBase. These results showcase SMAGNet’s effectiveness in multi-person gait analysis and its potential for real-world clinical use."
투자심리를 이용한 암호화폐 가격예측에 관한 연구,2024,"['암호화폐(Bitcoin', 'Ethereum)', '공포탐욕 지수', 'Time-varying Granger Causality', '투자심리', 'Cryptocurrency', 'Time-varying Granger Causality', 'Bitcoin', 'Ethereum', 'Investor Sentiment']","본 연구에서는 2018년 1월부터 2024년 6월까지 암호화폐(Bitcoin과 Ethereum)와 공포탐욕 지수(CNNMoney Crypto Fear and Grid Index)를 이용해 암호화폐 시장의 투자심리가 Bitcoin 및 Ethereum 가격과 어떻게 상호작용하고, 최종적으로 공포탐욕 지수가 암호화폐의 가격을 예측하는데 중요한 정보가 될 수 있는지를 분석하였다.본 연구에서 제시하는 표본기간동안의 실증분석 결과는 다음과 같다. 첫째, 암호화폐가 공포탐욕 지수를 Granger cause하지만 반대는 성립하지 않는 것으로 나타났기 때문에 투자자들은 공포탐욕 지수를 기반으로 거래 전략을 설계할 때 주의가 필요하다. 둘째, 모수의 단기적 안정성을 조사하기 위해 Residual-based Cointegration Model로 Sup-F, Mean-F 및 Exp-F 검정을 시행하고, VAR 구조의 장기적인 안정성을 분석한 결과에서 시간 가변적 특성을 발견하였다. 셋째, Time-varying Granger Causality 기법을 활용해 암호화폐 가격과 공포탐욕 지수 사이의 Granger 인과관계가 일정하지 않지만 투자심리가 암호화폐 가격 예측에 활용될 수 있는 가능성을 발견하였다. 다만   window 설정방식에 따라 인과관계의 시기가 달라질 수 있고, Bitcoin과 Ethereum에 대한 투자심리의 작용과정에도 차이가 존재하였다.","This paper used cryptocurrency and CNN Money Crypto Fear and Grid Index from January 2018 to June 2024 to analyze how investor sentiment in the cryptocurrency market interacts with Bitcoin and Ethereum prices, and ultimately, investor sentiment can be important information for predicting the price of cryptocurrency.The results of empirical analysis during the sample period are as follows. First, investors need to be cautious when designing trading strategies based on the CNNMoney Crypto Fear and Grid Index, as investor sentiment has been shown not to Granger cause cryptocurrencies.  Second, Sup-F, Ave-F, Exp-F tests were performed using the Residual-based Cointegration Model to investigate the short-term stability of the parameters, and time-varying characteristics were found in the long-term stability of the VAR structure. Third, In the analysis using Time-Varying Granger Causality, the Granger causal relationship between cryptocurrency prices and investor sentiment is not constant, but the possibility that investor sentiment can be used to predict cryptocurrency prices was found. However, the timing of the causal relationship may vary depending on the window setting method, and there were differences in the process of action of investor sentiment for Bitcoin and Ethereum."
Forecasting realized volatility using data normalization and recurrent neural network,2024,"['asymmetry', 'realized volatility', 'normalization', 'ratio transformation', 'recurrent neural network']",,"We propose recurrent neural network (RNN) methods for forecasting realized volatility (RV). The data are RVs of ten major stock price indices, four from the US, and six from the EU. Forecasts are made for relative ratio of adjacent RVs instead of the RV itself in order to avoid the out-of-scale issue. Forecasts of RV ratios distribution are first constructed from which those of RVs are computed which are shown to be better than forecasts constructed directly from RV. The apparent asymmetry of RV ratio is addressed by the Piecewise Minmax (PM) normalization. The serial dependence of the ratio data renders us to consider two architectures, long short-term memory (LSTM) and gated recurrent unit (GRU). The hyperparameters of LSTM and GRU are tuned by the nested cross validation. The RNN forecast with the PM normalization and ratio transformation is shown to outperform other forecasts by other RNN models and by benchmarking models of the AR model, the support vector machine (SVM), the deep neural network (DNN), and the convolutional neural network (CNN)."
Research on the Design of Financial Data Analysis Platform with Joint PSO-HQCNN and RPA Robot Visualization Technology,2024,"['RPA robot', 'Visualization techniques', 'Quantum neural networks', 'Financial data', 'Intelligent platforms']",,"A novel RPA technique for financial data analysis based on quantum neural network model is innovatively developed. Compared to the conventional model, the Hybrid Quantum Convolutional Neural Network model (HQCNN) reduces the loss value by 0.0056% and improves the training and testing accuracy by 0.93% and 0.36%, respectively. In addition, the hybrid quantum convolutional neural network model of this RPA exhibits less fluctuation in loss value after 60 iterations and remains stable after 90 iterations. Meanwhile, we combine the particle swarm optimization algorithm with HQCNN to transform classical data into quantum state data for joint optimization. The results of the recognition and validation accuracy plot show that PSO-HQCNN has the best recognition effect, with a recognition accuracy of 96.85%, followed by HQCNN with a recognition accuracy of 96.20%. And CNN has the lowest recognition accuracy of 95.65%. However, PSO-HQCNN model increases the time cost while improving the accuracy. Therefore, in the process of applying RPA to financial systems, trade-offs should be made according to the actual situation, and the HQCNN model or PSO-HQCNN model should be selected. In conclusion, through the implementation process of RPA robot visualization application established by using the quantum neural network model, this study provides a new direction of exploration and a feasible implementation path for the automated process processing of enterprise financial data analysis."
재난약자 및 취약시설에 대한 APC실증에 관한 연구,2024,"['재난취약시설', '요구조자', '자동계수기', '인공지능', '영상인식', 'Disaster-vulnerable Facilities', 'Victims', 'Auto People Counter', 'AI', 'Image Recognition']",,"Purpose: The purpose of this study is to improve the recognition rate of APC (Auto People Counting), which accurately identifies the remaining claimants and provides them to response agencies such as fire departments when a disaster occurs in a disaster-vulnerable facility such as a nursing hospital. Currently, when a disaster occurs, response agencies arrive at the disaster site and ask building officials directly to determine the status of those in need within the building. This may be inaccurate information about the rescuer, which may expand the scope of work of the response agency and pose a risk to the safety of the rescuer. APC automatically counts the number of people entering and leaving the building and provides real-time information on the number of people remaining, making it possible to accurately determine the status of those in need in the event of a disaster. The purpose of this study is to select the optimal artificial intelligence algorithm so that APC can more accurately count the number of people entering.Method: In this study, baseline modeling was performed using a CNN model to improve the algorithm that recognizes images of entering personnel through cameras targeting APCs installed and operated in actual disaster-vulnerable facilities. The study was conducted by analyzing the performance of various algorithms to select the top seven candidates and using a transfer learning model to select the optimal algorithm with the best performance.Research Results: As a result of the experiment, the precision and recall of the Densenet201 and Resnet152v2 models, which had the best time and performance, were confirmed to show 100% accuracy for all labels. Among these, the Densenet201 model showed higher performance.Conclusion: Among various artificial intelligence algorithms, the optimal algorithm that can be applied to APC was selected. This will improve the recognition rate of APC and enable quick and safe rescue operations by accurately identifying the information of rescuers in the event of a disaster. This is expected to contribute to ensuring the safety of rescuers performing rescue operations as well as the safe rescue of rescuers. In the future, additional research on algorithm analysis and learning is required to accurately identify the number of people entering disaster-vulnerable facilities in various disaster situations such as haze."
LSTM - MLP 인공신경망 앙상블을 이용한 장기 강우유출모의,2024,,,"Physical models, which are often used for water resource management, are difficult to build and operate with input data and may involve the subjective views of users. In recent years, research using data-driven models such as machine learning has been actively conducted to compensate for these problems in the field of water resources, and in this study, an artificial neural network was used to simulate long-term rainfall runoff in the Osipcheon watershed in Samcheok-si, Gangwon-do. For this purpose, three input data groups (meteorological observations, daily precipitation and potential evapotranspiration, and daily precipitation - potential evapotranspiration) were constructed from meteorological data, and the results of training the LSTM (Long Short-term Memory) artificial neural network model were compared and analyzed. As a result, the performance of LSTM-Model 1 using only meteorological observations was the highest, and six LSTM-MLP ensemble models with MLP artificial neural networks were built to simulate long-term runoff in the Fifty Thousand Watershed. The comparison between the LSTM and LSTM-MLP models showed that both models had generally similar results, but the MAE, MSE, and RMSE of LSTM-MLP were reduced compared to LSTM, especially in the low-flow part. As the results of LSTM-MLP show an improvement in the low-flow part, it is judged that in the future, in addition to the LSTM-MLP model, various ensemble models such as CNN can be used to build physical models and create sulfur curves in large basins that take a long time to run and unmeasured basins that lack input data."
딥러닝 기반 스테그어낼러시스와 적대적 스테가노그래피 기술의 최신 연구 동향,2024,"['스테가노그래피', '은닉통신', '스테그어낼러시스', '딥러닝', '적대적 공격', 'Steganography', 'Covert Communications', 'Steganalysis', 'Deep Learning', 'Adversarial Attack']","최근 인공지능의 발전은 급속히 진행되고 있으며 컴퓨터 통신분야 뿐만 아니라사회 전반에 걸쳐 큰 영향을 주고 있다. 인공지능을 통해 많은 사람들은 생활에편리함을 느끼고 있으나 이를 악용하는 사례 또한 증가하고 있다. 특히, 스테가노그래피(Steganography)는 정보를 은닉하는 기술로, 해커와 간첩뿐만아니라 악성 SW 간의 은밀한 통신에 지속적으로 악용되고 있으며 기법 역시고도화되고 있다. 한편, 스테그어낼러시스(Steganalysis)는 스테가노그래피 기술로은닉된 비밀 메시지를 탐지하고 추출하는 것을 목표로 하는 기술이다. 점점 더정교해지는 은닉 기법에 대응하기 위해, 최근에는 딥러닝(Deep Learning)을 활용한스테그어낼러시스가 효과적인 대응기술로 주목받고 있다. 본 논문에서는 국방영역에서의 스테가노그래피 은닉 통신을 탐지하여 대응하기 위한 대표적인 딥러닝기반의 스테그어낼러시스 기법을 소개한 후 이를 회피하기 위한 적대적스테가노그래피 기술 동향 분석을 통해 위험성 알리고 대응 방안을 제시하고자한다.","Recently, the development of artificial intelligence is progressing rapidly and is having a significant impact not only on the computer communication field but also on society as a whole. Many people feel convenience in their lives through artificial intelligence, but cases of abuse of it are also increasing. In particular, technologies such as steganography are continuously being abused due to their ability to hide information, and the technology and attack techniques are improving day by day. Steganalysis aims to detect and extract secret messages hidden in these messages. In particular, stagnation using deep learning has recently been attracting attention in order to respond to increasingly sophisticated hiding techniques. In this paper, we study various deep learning models such as CNN and GAN and explore methods applied to steganalysis. In addition, we will confirm the possibility of practical deep learning-based steganalysis to respond to steganography threats in defense security, and seek ways in which the technology can contribute to the defense information protection system."
딥러닝 기반 실내 디자인 인식,2024,"['Classification', 'Data Imbalance', 'Deep Learning', 'Interior design', 'Interior Image Segmentation', 'Interior Recommendation Service']",,"We spend a lot of time in indoor space, and the space has a huge impact on our lives. Interior designplays a significant role to make an indoor space attractive and functional. However, it should consider a lot of complexelements such as color, pattern, and material etc. With the increasing demand for interior design, there is a growingneed for technologies that analyze these design elements accurately and efficiently. To address this need, this studysuggests a deep learning-based design analysis system. The proposed system consists of a semantic segmentationmodel that classifies spatial components and an image classification model that classifies attributes such as color,pattern, and material from the segmented components. Semantic segmentation model was trained using a dataset of30000 personal indoor interior images collected for research, and during inference, the model separate the input imagepixel into 34 categories. And experiments were conducted with various backbones in order to obtain the optimalperformance of the deep learning model for the collected interior dataset. Finally, the model achieved good performanceof 89.05% and 0.5768 in terms of accuracy and mean intersection over union (mIoU). In classification partconvolutional neural network (CNN) model which has recorded high performance in other image recognition tasks wasused. To improve the performance of the classification model we suggests an approach that how to handle data thathas data imbalance and vulnerable to light intensity. Using our methods, we achieve satisfactory results in classifyinginterior design component attributes. In this paper, we propose indoor space design analysis system that automaticallyanalyzes and classifies the attributes of indoor images using a deep learning-based model. This analysis system, usedas a core module in the A.I interior recommendation service, can help users pursuing self-interior design to completetheir designs more easily and efficiently."
Signal Augmentation Method based on Mixing and Adversarial Training for Better Robustness and Generalization,2024,"['Adversarial training', 'automatic modulation recognition', 'data augmentation', 'mixing signals', 'robustnes']",,"More and more deep learning methods have been applied to wireless communication systems. However, the collection of authentic signal data poses challenges. Moreover, due to the vulnerability of neural networks, adversarial attacks seriously threaten the security of communication systems based on deep learning models. Traditional signal augmentation methods expand the dataset through transformations such as rotation and flip, but these methods improve the adversarial robustness of the model little. However, common methods to improve adversarial robustness such as adversarial training not only have a high computational overhead but also potentially lead to a decrease in accuracy on clean samples. In this work, we propose a signal augmentation method called Adversarial and Mixed-based Signal Augmentation (AMSA). The method can improve the adversarial robustness of the model while expanding the dataset and does not compromise the generalization ability. It combines adversarial training with data mixing and then interpolates selected pairs of samples to form new samples in an expanded dataset consisting of original and adversarial samples thus generating more diverse data. We conduct experiments on the RML2016.10a and RML2018.01a datasets using automatic modulation recognition (AMR) models based on CNN, LSTM, CLDNN, and Transformer. And compare the performance in scenarios with different numbers of samples. The results show that AMSA allows the model to achieve comparable or even better adversarial robustness than using adversarial training, and reduces the degradation of the model's generalization performance on clean data."
HRNet과 Transformer를 활용한 고해상도 위성영상의 구름탐지,2024,"['AIHub', 'Cloud Detection', 'HRNet', 'Satellite Imagery', 'Transformer', 'AIHub', '구름탐지', 'HRNet', '위성영상', '트랜스포머']","위성센서의 발달과 더불어 원격탐사 위성에 다양한 목적의 고해상도 센서가 탑재되어 발사되고 있으며, 높은 품질의 고해상도 위성영상에 대한 수요 또한 증대되고 있다. 사용자가 빠르게 고해상도 위성영상을 활용하기 위해서 는 방사보정, 정사보정 등의 전처리 과정이 적용된 ARD 형태의 자료가 필요하다. ARD 형태로 위성영상을 처리하기 위해서는 위성영상 내에 존재하는 구름 영역의 정보가 필요하며, 이를 위해 위성영상의 구름탐지 기법에 대한 다양한 연구들이 진행되고 있다. 본 연구에서는 고해상도 위성영상의 구름탐지를 위한 딥러닝 모델을 구성하고 이에 대한 성능 평가를 수행하였다. 특히, 대표적인 합성곱 신경망(Convolutional Neural Network)인 HRNet의 채널융합과정 내에 트랜스포머(Transformer)를 결합하여 딥러닝 모델의 성능을 향상시키고자 하였다. 또한, 훈련을 위해서 AIHub의 다목적실용위성을 이용한 구름탐지 훈련자료에 전처리 과정을 적용하여 학습의 성능을 향상시켰다. 실험결과, 전처리 과정이 적용된 훈련자료가 학습의 성능을 향상시키는 것을 확인하였다. 또한, 기존의 딥러닝 모델들과의 성능 평가를 통하여 제안한 딥러닝 모델이 효과적으로 구름지역을 추출할 수 있음을 확인하였다.","The demand for satellite imagery with high spatial resolution has increased since various remotely sensed satellite sensors such as KOMPSAT (Korean Multi-Purpose Satellite) and CAS (Compact Advanced Satellite) have launched. To quickly utilize high-resolution satellite imagery, ARD (Analysis Ready Data) with preprocessing steps such as radiometric and geometric corrections should be required. Various algorithms on cloud detection techniques for satellite imagery have been developed to process satellite imagery in ARD format. In this manuscript, a deep learning model for cloud detection in satellite imagery with high spatial resolution was developed. The Transformer layer was integrated within the channel fusion process of HRNet (High Resolution Network), which is one of the representative CNN (Convolutional Neural Network), to enhance the performance of the deep learning model. Additionally, the training performance by applying preprocessing steps was improved using AIHub's KOMPSAT training dataset for cloud detection. Experimental results represented that preprocessing of the training data improved the learning performance. Furthermore, through performance evaluation with existing deep learning models, it was confirmed that the proposed deep learning model could effectively extract cloud regions."
악성 췌장 병변 진단에서 인공지능기술을 이용한 초음파내시경의 응용,2024,"['Key Words: Artificial intelligence (AI)', 'Endoscopic ultrasound (EUS)', 'Pancreatic neoplasms Copyright ⓒ Korean Society of Gastrointestinal Cancer Research. This is']","췌장암(pancreatic cancer, PC)은 가장 치명적인 암으로 5년 전체 생존율(5-year overall survival rate)은 모든 병기에서 9%로 4기 질환의 경우 3%에 불과하다[1]. 현재 악성 췌장 병변의 진단에는 CT 스캔, 자기공명영상(magnetic resonance imaging), 초음파내시경(endoscopic ultrasound, EUS) 등 다양한 기법이 사용되고 있는데, 이중에서도 초음파내시경(EUS)은 췌관 암종(pancreaticductal adenocarcinoma) 및 췌관 선상세포 암종(pancreatic acinar cell carcinoma)과 같은 외분비계 세포에서 발생하는 악성 종양뿐 아니라 신경내분비 종양(pancreatic neuroendocrine tumors, PNETs), 췌장 낭포성 병변(pancreatic cystic lesions)과 같은 내분비 세포에서 발생하는 악성 췌장 병변의 진단에도 매우 유용하다[2]. 하지만, 만성 췌장염(chronic pancreatitis,CP)이 동반된 경우 EUS는 특이도가 낮아 감별 진단이 어렵고[3], 또한 시술자의 의존도가 높아 진단이 주관적일수 있어 아직까지는 초음파내시경 유도하 세침 흡인 생검술(endoscopic ultrasound guided fine needle aspiration)을 이용한 세포학적 진단이 췌장암 진단의 goldstandard이다.인공지능(artificial intelligence, AI)은 생물학적 두뇌를 학습하고 모방하기 위해 개발된 모든 컴퓨터 시스템에 적용되는 기술로 특히, 머신 러닝(machine learning, ML)은 대량의 데이터를 이용해 다양한 패턴을 찾아내는 AI의 한 형태다(Fig. 1) [4]. 이러한 ML에는 지도 학습(supervised learning), 비지도 학습(unsupervised learning), 강화 학습(reinforced learning)의 세 가지 유형이 있는데, 이중 지도 학습은 의학, 특히 진단 분야에서 연구되고 응용이 되고 있다. 특히, EUS에서는 신경망(neural networks, NN)이라고도 불리는 인공 신경망(artificial neural networks, ANN)과 서포트 벡터 머신(support vector machine, SVM)이라는 두 가지 유형의 지도 학습 방법이 연구되었다[5]. 딥 러닝(deep learning, DL)은 ANN에서 유래한 고급 개념으로, 인간 두뇌의 뉴런에서 영감을 받아 ANN의 여러 복잡한 층을 사용한다. 최근 널리 쓰이는 DL 알고리즘의 중 하나인 합성 곱신경망(convolutional neural network, CNN)은 데이터에서 지식을 추출해 학습이 이루어졌지만, 데이터의 특징을 추출하여 특징들의 패턴을 파악하는 알고리즘이다.반면, support vector machine (SVM)은 이미 입력 및 출력으로 훈련된 매우 많은 양의 데이터가 공급되는 지도ML 유형으로 훈련을 위해 더 많은 데이터 입력 없이는 더 많은 범주 지식을 자체 학습할 수 없다[6].지난 몇 년 동안 인공지능(AI) 활용이 의료 전반에 걸쳐 급격히 확대되었으며, Xu 등[7]은 EUS 영상을 이용하여 췌장암에서 예후 평가에 대한 연구를 시행하여 발표하였다. 실제로 2015년부터 2023년까지 PubMed 검색에서 인공지능, 췌장암을 핵심 용어로 조사해보면 발표된 연구 수가 기하급수적으로 증가했음을 알 수 있다(Fig. 2). 본고에서는 문헌 고찰을 통한 췌장 악성종양 진단에 대한 EUS 기반 AI 연구에 대한 효능에 대해서 논의하고자 한다.","Pancreatic cancer is a highly fatal malignancy with a 5-year survival rate of < 10%. Endoscopic ultrasound (EUS) is a useful noninvasive tool for differential diagnosis of pancreatic malignancy and treatment decision-making. However, the performance of EUS is suboptimal, and its accuracy for differentiating pancreatic malignancy has increased interest in the application of artificial intelligence (AI). Recent studies have reported that EUS-based AI models can facilitate early and more accurate diagnosis than other preexisting methods. This article provides a review of the literature on EUS-based AI studies of pancreatic malignancies."
딥러닝과 해양환경 연속관측자료를 활용한 저층 용존산소 시간 변동 예측,2024,"['빈산소', '양식장', '저층 용존산소', '딥러닝', '예측', 'Hypoxia', 'Aquaculture', 'Bottom dissolved oxygen', 'Deep learning', 'Prediction']","최근 빈산소수괴의 규모와 빈도가 지속적으로증가하고 있어 양식생물 집단폐사 등 수산업에 심각한 경제적 피해를 발생시키고 있다. 양식 현장에서 빈산소수괴로 인한 피해를 최소화하기 위해서는 빈산소수괴발생 시기를 사전에예측하여 조기 대응할 수 있는 예측모델 구축이 필요하다. 본 연구에서는 딥러닝기반 시계열 예측에특화된 순환신경망 모델 중 Long Short-Term Memory(LSTM), Gate Recurrent Unit(GRU)과합성곱 신경망인 1-Dimension Convolution Neural Network(1D-CNN)을 활용하여 저층용존산소의 변동을 예측한 후 모델별로 성능을 평가하였다. 딥러닝모델의 입력자료는 당동만 해역에서 2019년부터 2022년 사이에 연속 관측된 층별 해양환경자료를 사용하였다. 2019년과2021년 자료는 모델의학습 및 검증자료로사용하였고 2022년 자료를 예측하여 관측자료와비교·검증하였다. 모델의예측 정확도에 영향을 미치는 최적의 입력자료와 매개변수를 선정하기위해 Pearson 상관관계와 Mutual Information(MI) 분석, 시행착오법을 수행하였다. 그 결과 GRU 모델과 1D-CNN 모델의 성능이 LSTM 모델보다 성능이 우수한 것으로 나타났다. 예측선행시간이 증가할수록LSTM 모델의 단주기 변동 패턴의 재현성이 감소하였는데, 이는 각모델 간 구조에 기인한 결과로 나타났다. 본 연구를 통해시계열 예측에 딥러닝 모델을 적용할 경우 데이터 특성을 반영한 모델을 활용해야 함을 알 수 있었다. 향후 신뢰성 있는 양질의 입력자료 확보와 매개변수 조정을 통해 모델의 예측 오차를 줄일 경우 향상된 예측 정확도와 48시간 이상의 예측시간을 확보할 수 있을것으로 판단된다.","In recent years, the scale and frequency of hypoxia events have continued to increase, causing serious economic damage to the fishery industry, including mass mortality of aquaculture organisms. In order to minimize the damage caused by hypoxia in aquaculture, it is necessary to build a prediction model that can predict the timing of hypoxia in advance and respond to it early. In this study, recurrent neural network models specialized in time series prediction, Long Short-Term Memory(LSTM), Gate Recurrent Unit(GRU), and 1-Dimensional Convolution Neural Network(1D-CNN), a convolutional neural network, were used to predict the variation of bottom dissolved oxygen, and the performance of each model was evaluated. The input data for the deep learning models were layer by layer marine environmental data continuously observed in the Dangdong bay from 2019 to 2022. The 2019 to 2021 data were used as training and validation data for the model, and the 2022 data were predicted and compared and validated with the observed data. Pearson correlation and mutual information(MI) analyses, trial and error methods were performed to select the optimal inputs and parameters that affect the prediction accuracy of the model. The results showed that the GRU model and 1D-CNN model outperformed the LSTM model. The reproducibility of the short-term variation pattern of the LSTM model decreased as the forecast lead time increased, which was attributed to the structure of each model. This study shows that when applying deep learning models to time series forecasting, it is necessary to use models that reflect data characteristics. In the future, if the prediction error of the model is reduced by securing reliable and high-quality inputs and adjusting the parameters, it is expected that improved prediction accuracy and a prediction time of more than 48 hours can be secured."
웨이퍼 이송 로봇의 심층학습과 진동신호 기반 정렬 유격 이상 진단 시스템,2024,"['Wafer transfer robot', 'Deep learning', 'Fault diagnosis', 'Ball screw misalignment', 'Convolutional neural network', 'Explainable artificial intelligence', '웨이퍼 이송 로봇', '심층학습', '이상 진단', 'B(볼 스크류 유격 이상', '합성곱 신경망', '설명 가능한 인공지능']",,"In the semiconductor manufacturing industry, efficient operation of wafer transfer robots has a direct impact on productivity andproduct quality. Ball screw misalignment anomalies are a critical factor affecting precision transport of robots. Early diagnosis ofthese anomalies is essential to maintaining system efficiency. This study proposed a method to effectively diagnose ball screwmisalignment anomalies using 1D-CNN and 2D-CNN models. This method mainly uses binary classification to distinguishbetween normal and abnormal states. Additionally, explainable artificial intelligence (XAI) technology was applied to interpretdiagnostic decisions of the two deep learning models, allowing users to convince prediction results of the AI model. This studywas based on data collected through acceleration sensors and torque sensors. It compared accuracies of 1D-CNN and 2DCNNmodels. It presents a method to explain the model's predictions through XAI. Experimental results showed that theproposed method could diagnose ball screw misalignment anomalies with high accuracy. This is expected to contribute to theestablishment of reliable abnormality diagnosis and preventive maintenance strategies in industrial sites."
물체 파지점 검출 향상을 위한 분할 기반 깊이 지도 조정,2024,"['Segmentation', 'Deep Learning', 'Robotic Grasping']",,"Robotic grasping in unstructured environments poses a significant challenge, demanding precise estimation of gripping positions for diverse and unknown objects. Generative Grasping Convolution Neural Network (GG-CNN) can estimate the position and direction that can be gripped by a robot gripper for an unknown object based on a three-dimensional depth map. Since GG-CNN uses only a depth map as an input, the precision of the depth map is the most critical factor affecting the result. To address the challenge of depth map precision, we integrate the Segment Anything Model renowned for its robust zero-shot performance across various segmentation tasks. We adjust the components corresponding to the segmented areas in the depth map aligned through external calibration. The proposed method was validated on the Cornell dataset and SurgicalKit dataset. Quantitative analysis compared to existing methods showed a 49.8% improvement with the dataset including surgical instruments. The results highlight the practical importance of our approach, especially in scenarios involving thin and metallic objects."
실외 UWB NLOS 판별을 위한 멀티 헤드 어텐션 신경망 설계,2024,"['UWB', 'Multi-head attention', 'CIR', 'LOS/NLOS']",,"In this paper, we introduce a method of classifying UWB CIR data into LOS and NLOS environments by applying the multi-head attention algorithm. The 1016 UWB CIR values sampled at 100 ms intervals are divided into 100 segments. By comparing the classification time and accuracy of the LSTM-CNN algorithm and the multi-head attention algorithm, it is shown that the latter achieved a classification accuracy of 94.41% for LOS/NLOS environments, outperforming the LSTM-CNN model."
이미지 분석기법을 이용한 레일표면손상 진단애플리케이션 개발,2024,"['Rail surface damage', 'Diagnostic system', 'Deep learning', 'Application', '레일표면손상', '진단시스템', '딥러닝', '애플리케이션']","최근 제정된 궤도시설의 성능평가에 관한 세부지침에서 궤도성능평가의 평가절차 및 실시방법 등에 관한 필요사항을 제시하였다. 그러나 외관조사(육안조사)에 의해 레일표면손상의 등급이 결정되며, 점검자의 주관적인 판단으로 정성적인 평가에만 의존할  수밖에 없는 실정이다. 따라서 본 연구에서는 레일표면손상을 이용하여 레일내부결함까지 진단할 수 있는 진단애플리케이션을 개발하고자 하였다. 현장조사에서는 레일표면손상을 조사하고 패턴을 분석하였다. 또한 실내시험에서는 레일내부손상 이미지 데이터를 구축하기 위하여 SEM 시험을 이용하였으며, 균열 길이, 깊이 및 각도를 정량화하였다. 본 연구에서는 현장조사와 실내시험에서 구축한 이미지 데이터를 적용한 딥러닝 모델(Fast R-CNN)을 애플리케이션에 적용하였다, 스마트기기에서 사용이 가능한 딥러닝 모델을 이용한 레일표면손상 진단 애플리케이션(App)을 개발하여 향후 궤도진단 및 성능평가 업무에 활용 가능한 레일표면손상 스마트 진단시스템을 개발하였다.","The recently enacted detailed guidelines on the performance evaluation of track facilities presented the necessary requirements regarding the evaluation procedures and implementation methods of track performance evaluation. However, the grade of rail surface damage is determined by external inspection (visual inspection), and there is no choice but to rely only on qualitative evaluation based on the subjective judgment of the inspector. Therefore, in this study, we attempted to develop a diagnostic application that can diagnose rail internal defects using rail surface damage. In the field investigation, rail surface damage was investigated and patterns were analyzed. Additionally, in the indoor test, SEM testing was used to construct image data of rail internal damage, and crack length, depth, and angle were quantified. In this study, a deep learning model (Fast R-CNN) using image data constructed from field surveys and indoor tests was applied to the application. A rail surface damage diagnosis application (App) using a deep learning model that can be used on smart devices was developed. We developed a smart diagnosis system for rail surface damage that can be used in future track diagnosis and performance evaluation work."
Dual-scale BERT using multi-trait representations for holistic and trait-specific essay grading,2024,"['automated essay scoring', 'deep learning methods', 'multi-task learning', 'multi-trait scoring', 'transformer-based models']",,"As automated essay scoring (AES) has progressed from handcrafted techniques to deep learning, holistic scoring capabilities have merged. However, specific trait assessment remains a challenge because of the limited depth of earlier methods in modeling dual assessments for holistic and multi-trait tasks. To overcome this challenge, we explore providing comprehensive feedback while modeling the interconnections between holistic and trait representations. We introduce the DualBERT-Trans-CNN model, which combines transformerbased representations with a novel dual-scale bidirectional encoder representations from transformers (BERT) encoding approach at the document-level. By explicitly leveraging multi-trait representations in a multi-task learning (MTL) framework, our DualBERT-Trans-CNN emphasizes the interrelation between holistic and trait-based score predictions, aiming for improved accuracy. For validation, we conducted extensive tests on the ASAP++ and TOEFL11 datasets. Against models of the same MTL setting, ours showed a 2.0% increase in its holistic score. Additionally, compared with single-task learning (STL) models, ours demonstrated a 3.6% enhancement in average multi-trait performance on the ASAP++ dataset."
AI 챗봇 기반의 효과적인 SNS 메신저 피싱 공격 대응체계 연구,2024,"['사회공학 공격', '메신저 피싱 범죄', '딥러닝', '데이터 불균형', '지능형 챗봇', ': Social engineering attack', 'SNS phishing attack', 'Deep Learning', 'Data imbalance', 'Chatbot security assistant']","SNS 메신저 피싱 공격은 메신저에서 개인정보 탈취 또는 협박 등을 위한사회공학적 공격으로, 사이버 범죄 주요 유형 중 하나이다. 보안이 중요한 국방영역에서도 메신저 피싱으로 인해 심각한 위협이 될 수 있다. 한편 기존의메신저 피싱 탐지는 키워드를 기반으로 한 탐지 방식이 주를 이루나, 공격자들의단순 우회에도 탐지에 한계가 발생한다. 본 연구에서는 고도화된 SNS 메신저피싱 공격 대응을 위한 고려요소를 분석하고 AI 챗봇 기반 대응체계의연구방향과 실험결과를 제시한다. 첫째, Text-CNN, LSTM 등의 자연어 처리모델을 활용한 탐지 모델을 제안한다. 둘째, 데이터 불균형 문제 해결을 위해, SMOTE, GAN 기반 등의 데이터 증강을 활용한 방안을 제시한다. 셋째, 다양한매체에서의 탐지를 위해 OCR 및 STT 기술 적용으로 이미지 및 음성 데이터를기반으로 한 탐지 기법을 제시한다. 제안된 AI 기반 메신저 피싱 탐지 모델은단순 탐지 방식보다 높은 정확도를 기대할 수 있고 지능형 챗봇은 사용자가상황에 맞는 적절한 대응 방안을 선택할 수 있도록 하여 피해를 최소화에하는 데기여할 수 있을 것이다.","SNS phishing attacks exploit digital communication platforms to illegally obtain individuals' financial information and assets. Traditional detection methods often rely on simplistic keyword-based techniques, which are ineffective against attackers using word variations and evasion tactics. We addresses these challenges by employing data augmentation techniques, such as Synthetic Minority Over-sampling Technique (SMOTE) and Generative Adversarial Networks (GAN), to balance the dataset. We also propose advanced natural language processing models, including Text-CNN and Long Short-Term Memory (LSTM) networks, to learn the patterns of phishing texts effectively.To enhance detection across various media, we integrate Optical Character Recognition (OCR) and Speech-to-Text (STT) technologies, creating a comprehensive detection framework utilizing both image and audio data.Additionally, we develop an intelligent chatbot to provide real-time support and step-by-step response strategies to phishing victims. Our AI-based detection model is expected to offer improved accuracy over conventional methods, while the chatbot helps users select appropriate responses, minimizing potential damages."
PIDNet 기반 실시간 콘크리트 균열 탐지 모델 구현,2024,"['.', 'concrete crack detection', 'real-time crack detection', 'concrete surface analysis', 'PIDNet']","본 연구에서는 콘크리트 표면의 균열을 실시간으로 정확하게 탐지하기 위해 PIDNet 기반의 딥러닝 모델을 제안한다. PIDNet은 PID(Proportional-Integral-Derivative) 제어기의 개념을 네트워크 아키텍처에 도입하여, 세 가지 분기(branch)를 통해 상세한 특징, 문맥 정보, 경계 정보를 효과적으로 학습하였다. 모델의 학습과 평가는 AI-Hub에서 제공하는 콘크리트 균열 데이터셋을 활용하였으며, 동일한 워크스테이션 환경에서 U-Net, Attention U-Net, U-Net++, Mask R-CNN 등 기존의 대표적인 세그멘테이션 모델들과 비교 실험을 수행하였다. 평가 결과, 제안된 PIDNet 기반 모델은 IoU 92.3%를 기록하며, 기존 모델 대비 우수한 균열 탐지 성능을 보였다. 또한, 처리 속도 25 FPS와 모델 크기 45MB로 실시간 처리와 경량화 측면에서도 뛰어난 효율성을 확인하였다. 따라서, 본 연구의 PIDNet 기반 모델은 콘크리트 구조물의 균열 모니터링 시스템에 효과적으로 적용될 수 있을 것으로 기대된다.","In this study, we propose a PIDNet-based deep learning model for accurate real-time detection of cracks on concrete surfaces. By incorporating the concept of Proportional-Integral-Derivative(PID) controllers into the network architecture, PIDNet effectively learns detailed features, contextual information, and boundary data through its three branches. We trained and evaluated the model using a concrete crack dataset provided by AI-Hub and conducted comparative experiments with existing segmentation models such as U-Net, Attention U-Net, U-Net++, and Mask R-CNN under identical workstation conditions. The evaluation results demonstrate that the proposed PIDNet-based model achieved an IoU of 92.3%, outperforming existing models in crack detection performance. Additionally, with a processing speed of 25 FPS and a model size of 45MB, it exhibits excellent efficiency in terms of real-time processing and lightweight design. Therefore, the PIDNet-based model presented in this study is expected to be effectively applicable to crack monitoring systems for concrete structures."
딥러닝 기반 응용 트래픽 분석을 위한 프로세스 로그활용 다중 호스트 데이터셋 수집 시스템,2024,"['Machine Learning', 'Dataset', 'Network Traffic Classification', 'Multi-host', 'Generalization']","네트워크 트래픽 분류는 네트워크 관리 분야의 핵심 기술로 최근 딥러닝 기법을 적용하여 다양한 공개 데이터셋을 활용하여 발전하고 있다. 그러나 현존 공개 데이터셋의 대부분은 단일 호스트 데이터셋으로 특정 사용자 행동 패턴에 과적합될 가능성이 있다. 본 논문에서는 프로세스 로그 활용 다중 호스트 데이터셋 수집 시스템을 제안하며, 이를 활용하여 수집한 데이터셋을 활용하여 다양한 사용자 행동 패턴을 학습하여 모델의 일반화 능력을 향상시키고, 2D-CNN 분류기 모델의 정확도를 약 27~29% 향상시켰다. 이러한 시스템을 통해 다중 호스트 데이터셋의 구축을 지원하고, 분류기 모델의 일반화 능력을 향상시키고자 한다.","Network traffic classification is a core technology in network management, and recent advancements have applied deep learning techniques using various public datasets. However, most existing public datasets are single-host datasets, which may lead to overfitting to specific user behavior patterns. In this paper, we propose a multi-host dataset collection system utilizing process logs. Using the collected dataset, we aim to enhance the model’s generalization capability by learning various user behavior patterns and improve the 2D-CNN Classifier model's accuracy by approximately 27-29%. This system supports the construction of multi-host datasets and aims to improve the generalization capability of classifier models."
농장별 돼지 탐지 딥러닝 모델 성능 비교 분석,2024,"['Pig', 'Image', 'Deep Learning', 'Detection', 'Smart Farm']","가축의 상태를 관찰하고 관리하는 것은 농장의 생산성을 높이는데 중요한 역할을 한다. 그러나 사람이 직접 모든가축의 상태를 모니터링하는 것은 노동력과 시간의 제약으로 한계 존재한다. 이로 인해 이미지 기반 가축 모니터링 시스템에 대한 관심이 증가하는 추세이다. 국내외적으로 영상을 이용한 객체 탐지에 대해 다양한 연구가 진행되고 있으나수집된 환경에서만 최적화된 성능을 보이는 경향이 있다. 이에 따라, 사육 환경에 의존하지 않고 일반화된 성능을 유지할수 있은 객체 탐지 모델에 대한 기술 개발이 필요하다. 따라서 본 연구에서는 다양한 양돈장 환경에서 수집된 영상 데이터를 이용하여 각 환경에 따른 딥러닝 기반 객체 탐지 모델의 돼지 탐지 성능을 비교하고자 하였다. 연구는 세 곳의양돈 농가(완주, 김제, 익산)에서 수집된 영상을 이용하여 Faster R-CNN, YOLOv4, YOLOv8, DETR 네 가지 모델의성능을 비교 분석하였다. 주요 평가 지표는 mean Average Precision와 초당 프레임 수로 설정하였으며, 각 농장에서수집된 데이터를 학습 및 평가하여 모델의 일반화 성능을 분석하였다. 실험 결과, YOLOv8 모델이 98.4%로 가장 높은정확도와 일관된 성능을 보였으며, 평균 16.2 ms의 처리속도를 유지하고 있어 다양한 환경에서 실시간으로 돼지를 모니터링 할 수 있음을 확인하였다. 본 연구는 딥러닝 기술을 활용한 돼지 탐지의 실용적 적용 가능성을 제시하며, 향후 가축모니터링 시스템 개발에 기여할 것으로 기대된다.","Monitoring and managing the condition of livestock is vital for enhancing farm productivity.However, in manually monitoring the condition of livestock there are limitations due to constraints on labor and time. Although various studies have been conducted on object detection using images, performance tends to be optimized only for the specific environment in which the data were collected.Therefore, there is a need for development of object detection models that can maintain generalized performance across diverse breeding environments. This study compares pig detection by deep learning object-detection models that use image data collected from various pig farms. The data were collected from three farms in Wanju, Gimje, and Iksan, and the performance of four models (the Faster R-CNN, YOLOv4, YOLOv8, and DETR) was compared and analyzed. The evaluation metrics were mean average precision and frames per second. The models were trained and evaluated on data collected from each farm to analyze their generalizability. Experimental results indicate that the YOLOv8 model demonstrated the highest accuracy and consistent performance, maintaining an average processing speed of 16.2 ms, effectively detecting pigs in various environments. This study highlights the practical applicability of pig detection using deep learning technology, and is expected to contribute to the development of future livestock monitoring systems."
OOD 객체 검출 기반 지게차 원격 적재 제어 보조 기술,2024,"['Out of Distribution Detection', 'Freight Recognition', 'Loading Assistance System', 'Smart Logistics', '분포 이탈 탐지', '화물 인식', '적재 보조 시스템', '스마트 물류']","최근 물류 자동화 시스템에 대한 관심이 높아지면서 무인 지게차 연구도 활발히 이루어지고 있다. 기존 무인 지게차 관련 연구는 주로 한정된 실내 공간에서 적용할 수 있는 기술에 집중되어 있다. 하지만, 야외 환경에서는 다양한 외부 요인으로 인해 센서 정보의 신뢰도가 떨어지며 객체 검출의 정확도를 보장하기 어렵다. 본 연구는 야외 환경에 특화된 무인 지게차 기술을 위해 다중 카메라 센서를 활용한 두 가지 기술을 제안한다. 첫째, 상차 작업 중 충돌 방지를 위해 트럭 측면과 포크 높이를 인식해 안전한 적재 높이를 추정하는 기술이다. 둘째, 학습되지 않은 화물의 검출 정확도를 높이기 위해 out-of-distribution 기술의 적용 방안을 제안한다. 제안된 방법론의 현장 적용 가능성을 검증하기 위해 실제 중장비의 1/20 크기 프로토타입을 제작해 실험을 수행하였다. 적합한 객체 검출 모델을 선정하기 위해 Faster R-CNN, YOLOX, DAMO-YOLO, YOLOv8을 비교 실험하였고, 평균 정밀도(average precision) 기준으로 트럭 옆면 인식률은 각 100, 77.3, 99, 99.5을 획득하였다. 또한, 적재공간 및 화물 인지 성능은 YOLOX 모델을 기준으로 각 95.3와 87.83 성능을 보였다. 본 연구는 야외 무인 지게차의 원격 제어 시 화물 낙하 방지와 작업 효율성 향상에 이바지할 것으로 기대된다.","With increasing interest in automated material handling systems, a research on unmanned forklifts has been actively progressing. Existing research has primarily focused on methods applicable to controlled indoor environments. However, sensor data reliability decreases due to external factors, making object detection accuracy difficult to ensure in outdoor environments. We here propose two approaches specialized for unmanned forklifts using multiple camera sensors. First, an approach for estimating a safe loading height by recognizing the truck's side wall and the fork height. Second, an approach for applying out-of-distribution(OOD) to accurately detect previously unseen cargo shapes. We built a 1/20 scale prototype system of the actual heavy equipment to test the feasibility of the proposed approaches in real-world applications. To select a suitable object detection model, we conducted comparative experiments on Faster R-CNN, YOLOX, DAMO-YOLO, and YOLOv8. Based on average precision, the recognition rates for the truck sidewall were 100, 77.3, 99, and 99.5, respectively. Furthermore, the performance for detecting loading space and cargo was 95.3 and 87.83, respectively. We expect that our approach enhances freight drop prevention and operational efficiency in remote-controlled forklifts."
영상에서 효율적인 잡음제거를 위한 dRED-TL-GAN 모델,2024,"['딥러닝', '잡음제거', 'deformable 컨볼루션', 'GAN', 'Deep learning', 'deformable convolution', 'dRED-TL-GAN', 'image denoising']","영상에서 잡음은 시각적인 왜곡이나 불편을 주는 것 외에도 영상 시스템에서 성능 저하를 가져옴으로써 영상에서 잡음제거는 영상처리에서 중요한 전처리 과정이다. 본 논문에서는 영상에서 잡음제거를 위해 GAN 모델에서 파생된 DCGAN 기반의 deformable RED and transfer learning based generative adversarial networks (dRED-TL-GAN)모델을 제안하고자 한다. 제안된 dRED-TL-GAN 모델에서 생성자는 인코더-디코더 구조로 이루어진 deformable RED 구조이고, 판별자는 전이학습 기반 구조이다. 여기서 deformable RED 구조는 인코더의 컨볼루션 층에서 표준 컨볼루션 대신 deformable 컨볼루션을 사용하여 영상의 특징을 고려하였고, 판별자는 ResNet-18 모델을 사용하여 학습 속도가 분류 정확도를 높혔다. 본 논문에서 제안된 dRED-TL-GAN 모델의 성능 평가를 위해 전통적인 Mean 필터, Median 필터와 BM3D 필터, 그리고 기존 딥러닝의 DnCNN 모델, RED-CNN 모델 그리고 DCGAN 모델을 고려하였으며, 다양한 잡음, 즉, 가우시안 잡음 (Caussian noise), 포아송 잡음 (Poisson noise) 그리고 스팩클 잡음 (Speckle noise)으로 훼손된 얼굴 영상을 대상으로 실험하였다. 성능 실험은 정성적인 평가와 정량적인 평가로 구성되며, 정성적인 평가 결과, Mean 필터, Median 필터, 그리고 BM3D 필터를 포함한 공간 필터들은 대체로 잡음이 남아있고, 또한 호릿한 영상을 얻었고, 제안된 dRED-TL-GAN 모델은 다른 딥러닝 모델보다 에지있는 선명한 영상을 얻었다. 또한, 정량적인 평가 척도인 Peak signal-to-noise ratio (PSNR), Mean squared error (MSE) 그리고 Structural similarity index measure (SSIM) 면에서 dRED-TL-GAN 모델은 모든 잡음과 모든 평가 척도에서 가장 좋은 성능 수치를 얻었다.","Noise in images not only causes visual distortion or inconvenience, but also reduces performance in the imaging system, so image denoising is an important preprocessing process in image processing. In this paper, we propose a dRED-TL-GAN model based on DCGAN, derived from GAN, to remove noise from images. The generator of the dRED-TL-GAN model is a deformable RED structure consisting of an encoder-decoder structure, and the discriminator is a transfer learning-based structure. Here, the deformable RED structure used deformable convolutin in the encoder’s convolution layer to remove noise by considering the characteristics of the image, and used the ResNet-18 model in the discriminator to increase learning speed and classification accuracy. To evaluate the performance of the proposed dRED-TL-GAN model, traditional filters including Mean filter, Median filter, and BM3D filter, and existing deep learning models including DnCNN model, RED-CNN model, and DCGAN model were considered. An performance experiment was conducted on face images damaged by various noises, namely Gaussian noise, Poisson noise, and Speckle noise. The performance experiment consists of qualitative and quantitative evaluations. First, in the qualitative evaluation, spatial filters including the Mean filter, Median filter, and BM3D filter generally remained noisy and resulted in blurry results, and the propose dRED-TL-GAN model obtained clearer images with edges than other deep learning models. Additionally, in a quantitative evaluation using PSNR, MSE, and SSIM metrics, the dRED-TL-GAN model performs well under all noises considered and on all evaluation metrics."
어디가 더 걷기 좋다고 생각하십니까? 거리영상과 샴 네트워크 기반의 딥러닝 모델을 활용한 정성적 보행환경 평가,2024,"['Street view images', 'deep learning', 'walking environment', 'qualitative evaluation.', '거리영상', '딥러닝', '보행환경', '정성평가.']","본 연구는 거리영상과 딥러닝 기술을 활용하여 보행환경에 대한 사람들의 정성적 평가를 시각화하고 그 결과를 분석하고자 하였다. 보행의 중요성이 강조되면서 보행환경에 대한 인지 평가의 중요성도 강조되고 있다. 도시 건조환경에 대한 인식의 평가는 설문이나 인터뷰 등을 통해 일부의 사람을 대상으로 제한된 지역에 대해 수행되는 한계가있었다. 하지만 보행자의 시야에서 관찰하는 것과 유사하게 도시를 프로파일링할 수 있는 거리영상의 대두와 딥러닝기술의 발전은 광범위한 지역에 상세한 수준에서 도시 건조환경에 대한 정성적 평가를 가능하게 하고 있다. 본 연구에서는 안양시와 영등포구를 연구 대상 지역으로 거리영상을 수집하고, Global-Patch-RSS-CNN 모델을 활용하여 보행환경을 정성적으로 평가한 후, 그 결과를 시각화하여 걷기 좋다고 인식되는 지역과 나쁘다고 인식되는 지역을 분석하였다. 본 연구는 세 가지 측면에서 의의가 있다. 첫째, 보행환경에 대한 정성평가를 하고자 할 때 별도의 쌍별 비교 데이터 셋을 구축하지 않고도 연구 지역의 거리영상을 활용하여 보행환경에 대한 상세한 수준의 정성평가를 할 수 있다는 점, 둘째, 보행환경 정성평가를 위한 딥러닝 모델에 있어서도 국내 실정에 맞게 구축한 보행환경 쌍별 비교 데이터셋으로 사전 훈련된 딥러닝 모델을 활용할 수 있다는 점, 셋째, 국내 타지역에서 보행환경 정성평가를 하고자 할 때 전문가가 아니라도 쉽게 보행환경 정성평가를 수행할 수 있도록 프로세스를 체계적으로 제시한다는 점이다.","This study aims to visualize evaluation of the perceived walking environment and analyze the results using street view images and deep learning technology. As the importance of walking is emphasized, the importance of evaluation of the perceived walking environment is also emphasized. The evaluation of people’s perceptions about the urban built environment had limitation in that it was conducted through surverys or interviews with some people in a limited area. However, the emergence of street view images that can profile cities similarly to observations from a pedestrian’s perspective and the advancement of deep learning technologies enable qualitative evaluation of urban built environment at a detailed level over a wide range of areas. In this study, street view images were collected fromAnyang-si and Yeongdeungpo-gu, and the walking environment was qualitatively evaluated using the Global-Patch- RSS-CNN model, and the results were visualized on a map to analyze areas that are perceived as good or bad for walking. This study is significant in three ways. First, when conducting a qualitative evaluation of the walking environment, it is possible to conduct a detailed level of qualitative evaluation of the walking environment by utilizing street view images of the study area without building a training data-set; second, the deep learning model for evaluation of the perceived walking environment which is pre-trained with paired comparison data-set built for domestic conditions can be utilized; third, when conducting a evaluation of perceived walking environment in other areas of Korea, it is possible to systematically present a process so that non-professionals can easily evaluate the perceived walking environment."
MediaPipe로 추출한 신체 Landmark 및 IMU를 이용한 멀티모달 인간행동인식 딥러닝 모델 연구,2024,"['인간행동인식', '멀티모달', '관성측정센서', '영상', '미디어파이프', '분류', 'Human Action Recognition(HAR)', 'multimodal', 'IMU', 'Video', 'Mediapipe', 'classification']","딥러닝을 활용한 인간 행동 인식(Human Activity Recognition)에 관한 연구는 활발하게 진행되고 있다. 다양한 인공지능 기법을 활용하여 영상 속 신체의 랜드마크를 검출하여, 사람의 자세를 추정하여 인간 행동 인식을 예측한 다. 하지만 카메라 위치나 밝기 등 다양한 외란에 의해 영상 정보만을 활용한 인간 행동 인식 예측은 정확도가 낮아 지는 문제점이 있다. 따라서, 본 연구에서는 인간 행동 인식률을 높이기 위해 RGB-D 카메라 기반의 Landmark 추출과 IMU를 통합한 멀티모달 시스템을 제안한다. IMU 센서와 RGB-D 카메라를 활용하여, 각기 다른 10종류의 동작을 수집하였다. IMU 센서에서 3축 가속도 데이터를 추출하고, Mediapipe 인공지능 프레임워크를 이용하여 영상 데이터에서 프레임 단위로 신체에서 랜드마크 33개의 3축 위치 좌표 데이터를 추출하여 동작 데이터를 시계열 데이터로 통일하였다. 영상 데이터와 IMU 센서의 가속도 데이터를 하나의 시계열 데이터로 통합하고, 이 과정에서 슬라이딩 윈도우 및 선형 증강 등의 기법을 활용하여 데이터의 양을 증강하였다. 이를 본 연구에서 새롭게 제안한 1D-CNN 및 LSTM 신경망을 통해 학습을 진행하였다. 또한 동작의 특성에 따라 신경망의 학습에 사용한 랜드마 크의 개수를 제한하거나, IMU 데이터 및 랜드마크 데이터와 통합 데이터를 학습할 때 각각 분류기의 성능을 확인 하였다. 그 결과, 랜드마크와 IMU 센서 데이터를 통합한 동작 데이터를 학습시켰을 때, 분류 인공신경망에서 향상 된 분류 성능을 내는 것을 확인하였다.","The rapid development of AI-based computer vision and deep learning technologies have been proven invaluable for Human Activity Recognition (HAR). However, under the various environmental conditions such as light-interference, image occlusion, the prediction performance of Human Activity Recognition can be decreased dramatically. This paper propose an RGB-D based Landmark detection with IMU sensor systems for multi-modal deep learning analysis to increase the performance of HAR. 10 different types of human motions are collected using the proposed RGB-D with IMU sensor system. The 3-axis accelerometer data are extracted from IMU sensor. And by applying AI framework, called MediaPipe, the 3-axis location data of 33 landmarks of the body extracted as the input datasets for the HAR classification. The extracted data and the motion data are unified into time series sequential data. In order to increase the training dataset for the HAR classification, the estimated pose data from MediaPipe and the acceleration data from the IMU sensor are not only integrated into the same size of the sequential data, but also sliding window and linear interpolation are used. Furthermore, 1D-CNN and LSTM neural network are implemented for the HAR classification. As a result, the proposed RGB-D with IMU sensor system has increased the classification performance for Human Activity Recognition than applying the features obtained from the camera only."
객체 탐지 기술을 통한 휠 너트 제품의 단조 공정에서 불량 검출,2024,"['Image processing', 'Object detection', 'Forging', 'Wheel Nut', 'Defect detection', 'Image augmentation', '영상 처리', '객체 탐지', '단조', '휠 너트', '불량 검출', '이미지 증대']",,"This study developed a defect-detecting system for automotive wheel nuts. We proposed an image processing method using OpenCV for efficient defect-detection of automotive wheel nuts. Image processing method focused on noise removal, ratio adjustment, binarization, polar coordinate system formation, and orthogonal coordinate system conversion. Through data collection, preprocessing, object detection model training, and testing, we established a system capable of accurately classifying defects and tracking their positions. There are four defect types. Type 1 and type 2 defects are defects of products where the product is completely broken circumferentially. Type 3 and type 4 defects are defects are small circumferential dents and scratches in the product. We utilized Faster R-CNN and YOLOv8 models to detect defect types. By employing effective preprocessing and post-processing steps, we enhanced the accuracy. In the case of Fast RCNN, AP values were 0.92, 0.93, 0.76, and 0.49 for types 1, 2, 3, and 4 defects, respectively. The mAP was 0.77. In the case of YOLOv8, AP values were 0.78, 0.96, 0.8, and 0.51 for types for types 1, 2, 3, and 4 defects, respectively. The mAP was 0.76. These results could contribute to defect detection and quality improvement in the automotive manufacturing sector."
Vision-based Multi-task Hybrid Model for Teacher-Student Behavior Recognition in Classroom Environment,2024,"['Classroom behavior', 'Dual-stream framework', 'Multi-task hybrid model', 'Multi-mode learning', 'Spatio-temporal graph convolutional network']",,"Teacher-student concentration in the teaching process is an essential indicator for evaluating teaching quality. Many researches assess students' learning interests by identifying their classroom behaviors but ignore the influence of teachers' behavior on students' behavior. Therefore, we collect classroom video data of teacher and student perspectives to analyse the interplay between their behaviors. Considering the particularity of data collection in classroom environments, we design a vision-based multi-task hybrid model for multi-mode data (RGB, optical flow and skeleton data). This model structure is divided into two parts. The RGB and optical flow are input into a spatio-temporal dual-stream framework for real-time action localization of the teacher. This dual-stream framework includes a 2D-CNN branch to extract spatial information and a Vision Transformer (ViT) branch to extract temporal information. In another part, skeleton data is obtained through the pose estimation method, and we propose a multi-level stacked spatio-temporal graph convolutional network (MSSTGCN) for skeleton-based student behavior recognition. This network can process the multi-order semantic information of the skeleton data and fuse the features at different scales through the Non-local block."
