title,date,keywords,abstract,multilingual_abstract
잡음에 강건한 이미지 분류 모델을 위한 다양한 필터 크기를 가진 다중 합성곱 신경망 앙상블 학습 연구,2024,"['Convolution Neural Network', 'Ensemble Learning', 'Voting', 'MNIST', 'Robust model']","본 논문에서는 노이즈 이미지에 대한 강건한 분류 모델 작성을 위하여 다양한 필터크기를 가진 다중 합성곱 신경망 앙상블 모델을 연구하였다. 다중 합성곱 신경망 앙상블 모델은 2개의 다중필터 합성곱 신경망 앙상블 모델의 소프트 보팅(soft voting) 조합으로 구성되는데, 각각의 다중필터 합성곱 신경망 앙상블 모델은 다시 5개의 단일 합성곱 신경망의 소프트 보팅 조합으로 구성된다. 단일 합성곱 신경망들은 서로 다른 필터 크기가 적용되었으며, 그 필터 크기는 임의의 크기인 3, 5, 7, 11, 13이다. 단일 합성곱 신경망들은 학습 과정에서 특별한 연산이 적용되었는데, 각 단일 합성곱 신경망에서 마지막 완전 연결 계층의 출력이 서로 적절히 조합되어, 다시 각각의 단일 합성곱 신경망 모델의 소프트맥스 및 교차 엔트로피 오차(softmax-with-Loss) 계층으로 보내져 순전파 연산을 수행한다. 그 후, 오차역전파 연산을 수행하며 가중치를 갱신하도록 함으로써 단일 합성곱 신경망 모델들이 학습 과정에서 상호보완 될 수 있도록 하였다. 작성된 다중 합성곱 신경망 앙상블 학습모델의 강건성 평가는 MNIST(Modified National Institute of Standards and Technology) 손글씨 숫자 이미지 데이터로 수행되었다. 숫자 이미지 데이터는 1개의 정상 데이터 셋과, 3개의 비정상 잡음 데이터 셋으로 구성되어 있으며, 정상/비정상 데이터 상관없이 학습 및 테스트하여 모델의 성능을 평가하였다. 그 결과, 다중 합성곱 신경망 앙상블 모델의 분류 성능이 단일 합성곱 신경망 모델보다 전반적으로 향상된 것을 확인하였다.","A multiple CNN ensemble model was developed using various filter sizes to train a noise-robust image classification model. The multiple CNN ensemble model consisted of a soft voting combination of two multiple-sized filter CNN ensemble models. The multiscale filter CNN ensemble model consisted of a soft voting combination of five single CNN models. Single CNN models were made using 3, 5, 7, 11, and 13-sized filters. During the modeling, a special calculation process was applied to CNNs, outputs of last affine layer in each CNN model are combine properly. The combined outputs were sent to softmax-with-loss layer to conduct rest of forward propagation. Lastly, by progressing progress back propagation calculation, CNN models made it possible to complement each other's weight variables. Evaluation of the robustness of the multiple CNN ensemble model was performed using an MNIST handwritten number image data set, 1 normal data set, and 3 noise added data set. These image data sets were used to model and test the performance of the classification model regardless of normal or noise. The resulting multiple CNN ensemble model had better classification performance than the single CNN model."
합성곱 신경망을 이용한 종 수준의 동물플랑크톤 분류기 및 시각화,2024,"['합성곱 신경망', '동물 플랑크톤', '종 동정', '시각화', 'Convolutional Neural Network', 'Zooplankton', 'Species Identification', 'Visualization']","동물플랑크톤의 종 동종은 해양 생태계의 이해 및 지구온난화를 연구하는데 가장 기본이다. 본 연구에서는 3종의 동물플랑크톤을 종 수준에서 암컷과 수컷을 분류할 수 있는 합성곱 신경망 모델을 제안한다. 첫째 연구자들이 획득하는 현미경 이미지를 기반으로 형태적 특징을 포함하는 학습데이터를 구축한다. 학습데이터의 구축에 있어 대상 종의 형태적 특징 정보를 보존하는 데이터 확대 방법을 적용한다. 둘째 구축된 학습데이터로부터 종 특징들이 학습될 수 있는 합성곱 신경망 모델을 제안한다. 제안한 모델은 높은 해상도를 고려하여 학습 이미지 정보 손실을 최소화하였고 완전 연결 층 대신에 전역 평균 폴링 층을 사용하여 학습 매개 변수 개수를 최소화하였다. 제안한 모델의 일반성을 제시하기 위해 새로이 획득한 데이터를 기반으로 성능을 제시하였다. 마지막으로 개발된 모델에서 추출된 특징들의 시각화를 통해, 분류 모델의 중요 특징을 제시하였다.","Species identification of zooplankton is the most basic process in understanding the marine ecosystem and studying global warming. In this study, we propose an convolutional neural network model that can classify females and males of three zooplankton at the species level. First, training data including morphological features is constructed based on microscopic images acquired by researchers. In constructing training data, a data argumentation method that preserves morphological feature information of the target species is applied. Next, we propose a convolutional neural network model in which features can be learned from the constructed learning data. The proposed model minimized the information loss of training image in consideration of high resolution and minimized the number of learning parameters by using the global average polling layer instead of the fully connected layer. In addition, in order to present the generality of the proposed model, the performance was presented based on newly acquired data. Finally, through the visualization of the features extracted from the model, the key features of the classification model were presented."
합성곱 순환 신경망 모델을 이용한 의사 레이블링 기법 기반  능동소나 표적 식별 약지도 딥러닝 알고리즘 연구,2024,"['능동소나', '표적 식별', '약지도 학습', '합성곱 순환 신경망', '의사 레이블링', 'Active sonar', 'Target recognition', 'Weakly-supervised learning', 'Conventional Recurrent Neural Network (CRNN)', 'Pseudo labeling']","본 논문은 음향 신호처리에 널리 사용되는 합성곱 순환 신경망(Convolutional Recurrent Neural Network, CRNN) 모델을 기반으로 의사 레이블링 기법을 적용하여 소량 및 불균형 능동소나 데이터를 효과적으로 활용할 수 있 는 능동소나 표적 식별을 위한 약지도 딥러닝 알고리즘을 제안한다. 두 가지의 서로 다른 신호대잡음비와 클러터 환경을 가정하여 생성한 능동소나 시뮬레이션 데이터를 학습 및 테스트 과정에 사용하였으며, 시뮬레이션 데이터에 단시간 푸 리에 변환(Short Time Fourier Transform, STFT)을 적용하여 얻은 스펙트로그램을 알고리즘 학습을 위한 특징 인자 로 사용하였다. 본 논문에서 제안하는 알고리즘은 학습 데이터와 무관한 테스트 데이터를 사용하여 표적과 비표적 F1 점수를 지표로 성능을 평가하였으며, 그 결과 합성곱 순환 신경망 모델이 일반적인 음향 신호 처리뿐만 아니라 능동소나 표적 식별에서도 유의미한 성능을 보이는 것을 확인하였다. 또한 의사 레이블링 기법이 합성곱 순환 신경망 모델을 이용 한 능동소나 표적 식별 알고리즘의 성능 개선에 도움을 주는 것을 확인할 수 있었다.","In this paper, we proposed the weakly-supervised deep learning algorithm for active sonar target recognition based on pseudo labeling using Conventional Recurrent Neural Network (CRNN) model widely used for acoustic signal processing because it can effectively utilize small and unbalanced active sonar data. Active sonar simulation data assuming two different SNRs and clutter environments were used in the training and testing process, and spectrogram obtained by applying Short Time Fourier Transform (STFT) to the simulation data was used as a feature factor for algorithm training. The algorithm proposed in this paper was evaluated based on the target and nontarget F1-score using test data independent of training data. As a result, it was confirmed that the CRNN model showed significant performance not only in typical acoustic signal processing but also active sonar target recognition. Also, pseudo-labeling helps to improve the performance of the active sonar target recognition algorithm used the CRNN model."
삼차원 합성곱 신경망과 X선 단층 영상에서 추출한 형태학적 특징을 이용한 PEMFC용 가스확산층의 투과도 예측,2024,"['가스확산층', '고분자 전해질막 연료전지', '삼차원 합성곱 신경망', '미세구조', 'Gas Diffusion Layer', 'Proton Exchange Membrane Fuel Cell', '3D Convolutional Neural Network', 'Microstructure']","본 연구에서는 고분자 전해질막 연료전지용 가스확산층의 투과도를 예측하기 위해 삼차원 합성곱 신경망 모델을 사용하는 방법론을 소개한다. 먼저, 기계학습 모델을 학습시키기 위해 X-선 단층 촬영을 통해 얻은 실제 가스확산층 이미지에서 형태학적 특성을 추출해 가스확산층의 대표 체적 요소로 이루어진 인공 데이터셋을 생성한다. 이러한 형태학적 특성은 다공성, 섬유 배향, 직경의 통계적 분포가 포함된다. 구축한 인공 데이터셋 대표 체적 요소들의 투과도를 평가하기 위해 격자 볼츠만 방법이 사용되었으며 각각의 대표 체적 요소들의 투과도를 도출하였다. 이러한 인공 데이터셋을 통해 삼차원 합성곱 신경망 모델을 학습시켰으며 인공 데이터셋을 학습한 삼차원 합성곱 신경망 모델이 실제 가스확산층의 대표 체적 요소 투과도 또한 잘 예측하는 것을 확인하였다.","In this research, we introduce a novel approach that employs a 3D convolutional neural network (CNN) model to predict the permeability of Gas Diffusion Layers (GDLs). For training the model, we create an artificial dataset of GDL representative volume elements (RVEs) by extracting morphological characteristics from actual GDL images obtained through X-ray tomography. These morphological attributes involve statistical distributions of porosity, fiber orientation, and diameter. Subsequently, a permeability analysis using the Lattice Boltzmann Method (LBM) is conducted on a collection of 10,800 RVEs. The 3D CNN model, trained on this artificial dataset, well predicts the permeability of actual GDLs."
합성곱 신경망 기반 화재 인식 모델 최적화 연구: Layer Importance Evaluation 기반 접근법,2024,[],"본 연구는 Layer Importance Evaluation을 통해 도출된 화재 감지에 최적화된 딥러닝 아키텍처를 제안한다. 기존의 합성곱 신경망(Convolutional Neural Network, CNN) 기반 화재 감지 시스템의 불필요한 복잡성과 연산을 초래하는 문제점을 해결하기 위해, Layer Importance Evaluation 기법을 통해 가중치 및 활성화 값에 근거한 모델의 내부 레이어의 동작을 분석하고, 화재 감지에 기여도가 높은 레이어를 식별한 뒤, 식별한 레이어만으로 모델을 재구성하여, 기존 모델과의 성능 지표를 비교 분석하였다. Xception, VGG19, ResNet, EfficientNetB5 등 네 가지 전이 학습 모델을 사용하여 화재 데이터를 학습시킨 후, Layer Importance Evaluation기법을 적용하여 각 레이어의 가중치와 활성화 값을 분석한 뒤 기여도가 가장 높은 상위 랭크 레이어들을 선별하여 새로운 모델을 구축하였다. 연구 결과, 구현된 아키텍처는 기존 모델 대비 약 80% 가량 경량화 된 파라미터로도 동등한 성능을 유지하며, 약 3~5배가량 신속한 학습 속도를 가지면서도 기존의 복잡한 전이학습 모델에 비해 정확도, 손실, 혼동행렬 지표에서 동등한 성능을 출력함으로써, 화재 감시 장비의 효율성을 높이는 데 기여할 수 있음을 확인하였다.","This study proposes a deep learning architecture optimized for fire detection derived through Layer Importance Evaluation. In order to solve the problem of unnecessary complexity and operation of the existing Convolutional Neural Network (CNN)-based fire detection system, the operation of the inner layer of the model based on the weight and activation values was analyzed through the Layer Importance Evaluation technique, the layer with a high contribution to fire detection was identified, and the model was reconstructed only with the identified layer, and the performance indicators were compared and analyzed with the existing model. After learning the fire data using four transfer learning models: Xception, VGG19, ResNet, and EfficientNetB5, the Layer Importance Evaluation technique was applied to analyze the weight and activation value of each layer, and then a new model was constructed by selecting the top rank layers with the highest contribution. As a result of the study, it was confirmed that the implemented architecture maintains the same performance with parameters that are about 80% lighter than the existing model, and can contribute to increasing the efficiency of fire monitoring equipment by outputting the same performance in accuracy, loss, and confusion matrix indicators compared to conventional complex transfer learning models while having a learning speed of about 3 to 5 times faster."
합성곱 신경망 기반 화재 인식 모델 최적화 연구: Layer Importance Evaluation 기반 접근법,2024,"['레이어 중요도 평가', '전이 학습 모델', '합성곱 신경망 최적화', '실시간 화재 감지', '기여도', 'Layer Importance Evaluation', 'Transfer Learning Model', 'CNN Optimization', 'Real-Time Fire Detection', 'Contribution']","본 연구는 Layer Importance Evaluation을 통해 도출된 화재 감지에 최적화된 딥러닝 아키텍처를 제안한다. 기존의 합성곱 신경망(Convolutional Neural Network, CNN) 기반 화재 감지 시스템의 불필요한 복잡성과 연산을 초래하는 문제점을 해결하기 위해, Layer Importance Evaluation 기법을 통해 가중치 및 활성화 값에 근거한 모델의 내부 레이어의 동작을 분석하고, 화재 감지에 기여도가 높은 레이어를 식별한 뒤, 식별한 레이어만으로 모델을 재구성하여, 기존 모델과의 성능 지표를 비교 분석하였다. Xception, VGG19, ResNet, EfficientNetB5 등 네 가지 전이 학습 모델을 사용하여 화재 데이터를 학습시킨 후, Layer Importance Evaluation기법을 적용하여 각 레이어의 가중치와 활성화 값을 분석한 뒤 기여도가 가장 높은 상위 랭크 레이어들을 선별하여 새로운 모델을 구축하였다. 연구 결과, 구현된 아키텍처는 기존 모델 대비 약 80% 가량 경량화 된 파라미터로도 동등한 성능을 유지하며, 약 3~5배가량 신속한 학습 속도를 가지면서도 기존의 복잡한 전이학습 모델에 비해 정확도, 손실, 혼동행렬 지표에서 동등한 성능을 출력함으로써, 화재 감시 장비의 효율성을 높이는 데 기여할 수 있음을 확인하였다.","This study proposes a deep learning architecture optimized for fire detection derived through Layer Importance Evaluation. In order to solve the problem of unnecessary complexity and operation of the existing Convolutional Neural Network (CNN)-based fire detection system, the operation of the inner layer of the model based on the weight and activation values was analyzed through the Layer Importance Evaluation technique, the layer with a high contribution to fire detection was identified, and the model was reconstructed only with the identified layer, and the performance indicators were compared and analyzed with the existing model. After learning the fire data using four transfer learning models: Xception, VGG19, ResNet, and EfficientNetB5, the Layer Importance Evaluation technique was applied to analyze the weight and activation value of each layer, and then a new model was constructed by selecting the top rank layers with the highest contribution. As a result of the study, it was confirmed that the implemented architecture maintains the same performance with parameters that are about 80% lighter than the existing model, and can contribute to increasing the efficiency of fire monitoring equipment by outputting the same performance in accuracy, loss, and confusion matrix indicators compared to conventional complex transfer learning models while having a learning speed of about 3 to 5 times faster."
합성곱 신경망을 이용한 상지 엑스선 영상 분류 모델 유용성 평가,2024,"['합성곱 신경망', '딥러닝', '의료 영상', '영상 분류', '검사 오류', 'Convolutional Neural Network', 'Deep Learning', 'Medical Image', 'Image Classification', 'Examination Error']","본 연구는 엑스선 검사 과정에서 환자와 코드를 정확히 확인하지 않아 발생할 수 있는 실수나 오류를 예방하는 것을 목표로 하고 있다. 이를 통해 방사선사의 작업 효율성을 높이고 의료 사고를 방지하며, 합성곱 신경망 기반 이미지 분류 기술을 활용한 실질적인 임상 적용 방안을 제안하고자 한다. 연구는 19,381개의 상지 근골격계 엑스선 이미지를 7개의 영역, 19개의 class로 분류하였으며, 학습, 검증, 평가 세트 비율을 8:1:1로 분할하였다. 딥러닝 모델은 VGG-16, DenseNet-121, ResNet-152v2와 같은 심층 학습 모델을 사용하여 정확도, 정밀도, 재현율, F1 스코어 및 혼동 행렬을 기반으로 모델 성능을 평가하였다. 학습결과 DenseNet-121의 전체 정확도에서 87.77%, 평균 class 정확도에서 98.71%, 정밀도에서 91.78%, 재현율에서 86.93%, F1스코어에서 86.71%를 보였다. 모든지표에서 DenseNet-121이 가장 높은 성능을 보였다. 본 연구는 상지 X선 이미지를 활용한 다양한 심층 학습 모델의 성능을 평가하였으며, 충분한 성능을 보여주었다. 이를 통해 작업 효율성을 높이고 의료 사고 방지가능성을 확인하였다.","This study aims to prevent errors that may occur during the radiography examination process, such as misinterpretation of images, by utilizing artificial intelligence, a core technology of the Fourth Industrial Revolution. Through this, we sought to enhance the work efficiency of radiologic technologists, prevent medical accidents. We labeled 19,381 upper ex- tremity musculo-skeletal X-ray images into 7 regions and 19 classes, and divided them into training, validation, and test sets at a ratio of 8:1:1. We used deep learning models such as VGG-16, DenseNet-121, and ResNet-152v2 to evaluate model performance based on accuracy, precision, recall, F1-score, and confusion matrix. The results showed that DenseNet-121 achieved an overall accuracy of 87.77%, an average class accuracy of 98.71%, a precision of 91.78%, a recall of 86.93%, and an F1 score of 86.71%. DenseNet-121 demonstrated the highest performance across all metrics. This study evaluated the performance of various deep learning models using upper extremity radiographic image and demonstrated sufficient performance. Through this, the potential to improve work efficiency and prevent medical accidents was confirmed."
합성곱 신경망에 의한 과도 하중 감지에 대한 연구,2024,"['Convolutional Neural Network(합성곱 신경망)', 'Crawler Crane(크롤러 크레인)', 'Finite Element Analysis(유한요소해석)', 'Stacked Auto Encoder(스택형 자동인코더)', 'Load Detection(하중인식)']",,"Accurate load detection is important for the safe operation of mechanical structures. This study attempts toincorporate convolutional neural network technology to improve the accuracy of load detection. To increase thedetection accuracy of the excessive external load applied to the mechanical structure, it is necessary to check theamount of learning data along with the application of the Convolutional Neural Network technique of the artificialneural network. In this study, the amount of analysis data of the mechanical structure was insufficient forConvolutional Neural Network learning; therefore, the application of the stacked auto code technique was examinedas a method of securing the amount of data required for Convolutional Neural Network learning. In addition,appropriate conditions were suggested by researching the procedure of the Convolutional Neural Network for loaddetection and conditions appropriate for each function and variable. The accuracy was verified by detecting thehoisting load of the crawler crane from the load of the roller, which was the lower structure. The results of thisstudy can be applied to the analysis and design of various mechanical structures, and the possibility of using aConvolutional Neural Network to ensure machine safety and prevent accidents was verified."
에지 검출을 위한 경량 확장 합성곱 신경망,2024,"['에지 검출', '합성곱 신경망', '확장 합성곱', '균형 교차 엔트로피', 'F-지표', 'Edge Detection', 'Convolutional Neural Network', 'Dilated Convolution', 'Balanced Cross-Entropy', 'F-Measure']",,"Deep learning-based edge detection methods exhibit superior performance when compared to traditional methods; however, they typically require highly complex architectures, excessive computational power, and high memory capacity. In this paper, we propose a lightweight dilated convolutional network (LDCN) with flexible structure and size using four types of convolutional neural network blocks with a significantly small number of parameters. We trained the proposed three-stage neural network-based edge detector on the Berkeley Segmentation Data Set 500 and evaluated its performance in terms of the F-measure. Thus, we were able to achieve the same level of performance with optimal dataset scale (ODS) and optimal image scale (OIS) values of 0.771 and 0.795, respectively, using a neural network with approximately one-tenth the size of existing lightweight neural network-based edge detectors. Furthermore, with a parallel backbone structure, the ODS and OIS values were improved to 0.802 and 0.822, respectively, achieving superior performance equivalent to that of existing edge detectors that are based on significantly complex neural networks with tens of times more weights."
사운드와 활동 정보를 이용한 셀프 어텐션 잔차  시간적 합성곱 신경망 기반 실내 비상상황 인식,2024,"['상황인식', '잔차 시간적 합성곱 신경망', '인간 활동 인식', '사운드 이벤트 검출', 'Temporal convolution network', 'Indoor emergency awareness', 'Sound event detection', 'Activity recognition']","본 논문은 모바일 기기를 통해 수집된 소리와 활동 정보를 통해 사용자의 비상상황을 인식하여 알려주는 실내비상인식 알람 시스템을 제안한다. 제안하는 시스템에서는 모바일 기기의 마이크로 입력되는 실내 공간 사운드, 그리고모바일 기기 내에 장착된 가속도계와 자이로스코프의 신호를 셀프 어텐션 잔차 시간적 합성곱 신경망(Self-Attentive Residual Temporal Convolutional Networks, SARTCN)에 적용함으로써 비상상황을 인식하고 모바일 전송 시스템을 사용하여 모니터링되는 사람의 상태를 보호자나 가족에게 신속하게 전달한다. 학습을 위해 실제 모바일 기기를 통해녹음된 사운드 데이터 및 가속도계, 자이로스코프의 신호를 활용하여 비상상황을 인식하는 실험을 수행하였으며, SARTCN은 사운드 이벤트 인식과 활동인식의 통합한 실내 비상 상황 인식에서 93.7 %의 높은 정확도를 보여주었다.제안하는 시스템은 노인과 어린아이와 같이 도움이 필요한 사람들의 비상상황을 자동으로 감지하고 대처하는 모니터링 시스템에 효과적으로 적용될 수 있다.","In this paper, we propose an indoor emergency awareness alert system that recognizes and delivers a user's emergency situation through sound and activity information collected through a mobile device. In the proposed system, the indoor spatial sound inputted through the microphone of the mobile device and the signals from the accelerometer and gyroscope installed in the mobile device are applied to the Self-Attentive Residual Temporal Convolutional Networks (SARTCN) to recognize emergency situations and quickly transmit the status of the monitored person to the guardian or family using the mobile transmission system. For training, we conducted experiments to recognize emergency situations using sound data recorded through actual mobile devices, as well as accelerometer and gyroscope signals, and our proposed SARTCN model achieved a high accuracy of 93.7 % in recognizing indoor emergency events by integrating sound event detection and activity recognition. The experimental results show that the proposed system can be effectively applied to a real-time monitoring system that automatically detects and responds to emergency situations of people who need assistance, such as the elderly and children."
‘언어적 전회’에서 ‘인공적 전회’로: 합성곱 신경망과 오토인코더를 중심으로,2024,"['artificial intelligence', 'convolutional neural network', 'autoencoder', 'symbolism', 'connectionism', 'symbol grounding', 'linguistic turn', 'artificial turn', '인공지능', '합성곱 신경망', '오토인코더', '기호주의', '연결주의', '심볼 그라운딩', '언어적 전회', '인공적 전회']","본 연구는 2012년의 두 실험, 즉 약칭 ‘알렉스넷’과 ‘구글의 고양이’에 대한 기술공학적인 분석을 통해 이것이 과연 어떤 이유에서 인공지능 개발사에 종별적인 차이와 함께 거대한 변혁을 가져왔는지를 검토한다. 특히 두 실험의 핵심 기술인 ‘합성곱 신경망(Convolutional Neural Network)’과 ‘오토인코더(Autoencoder)’를 살펴보면서 그 각각의 원리와 작동, 메커니즘을 가능한 한 정교하게 언어화해 나간다. 기술에 대한 번역 작업이라 할 수 있다. 다음으로 이 글은 이러한 기술적 논의를 연결 고리 삼아 인문사회적인 질문을 던지는 데까지 논의를 확장해 나간다. 무엇보다 이 글은 인공지능이 기존의 ‘언어적 전회(Linguistic Turn)’, 즉 언어가 우리의 사유와 경험을 구성한다는 문제설정을 어떻게 기술적 차원에서(기술적 언어를 통해) 반복하는지를 파고들면서, 기계에 의한 또 다른 전회의 가능성, 이른바 ‘인공적 전회(Artificial Turn)’의 성립 여부를 원리적 차원에서 점검한다. 인공지능이 자체의 고유한 방식을 통해 기표와 기의를 결합시키고 또 그럼으로써 이 세계를 인식하고 (재)구성한다면, 마치 언어가 그러했듯이 이 또한 어떤 전회의 한 계기가 될 수 있지 않을까? 이 글은 이를 인공지능이라는 기술적 대상을 중심으로 한 인공적 전회로 규정한다. 마지막으로 이 글은 인공적 전회를 언어적 전회와 나란히 읽어내는 데 그치기보다는, 도리어 그것이 어떻게 언어적 전회를 그 내부에서부터 침식하고 변형하는지, 또 그럼으로써 어떻게 이전과는 다른 새로운 사유를 요청하는지를 규명한다. 인공지능과 언어(기호), 세계, 그리고 (기술적)존재로 이어지는 새로운 계열을 묻는 것, 이것이 이 글의 핵심 질문이다.","This study attempts a technical engineering analysis of two experiments in 2012, namely ‘Alexnet’ and ‘Google's Cat’. Through this, we examine why these two experiments have transformed the history of AI development along with their differences. In particular, this study analyzes the principles, operation, and mechanism of each of the two experiments' core technologies, ‘Convolutional Neural Network’ and ‘Autoencoder’. It can be said to be a translation of technology. Next, the article builds on this discussion and extends it to ask humanistic and social questions. Among other things, this article explores how AI technologically repeats the Linguistic Turn, the idea that language organizes our thoughts and experiences. As a result, the possibility of another turn by the machine, the so-called ‘Artificial Turn’, is examined at a principle level. If AI can combine the signifier and the signified in its own way, and as a result, recognize and (re)construct this world, wouldn't this also be an opportunity for some turn, just like language did? We define this as an Artificial Turn centered on a technological object(AI). Lastly, we examine how an Artificial Turn transforms a Linguistic Turn from within and how it calls for a new way of thinking that is different from before. This is the central question of this article, asking for a new series of connections between AI and language, worlds, and existence."
아음속 수송체 알루미늄 프레임의 비선형 유도초음파 주파수 응답 – 합성곱 신경망 분석 기반 미세 감육 진단 가능성 연구,2024,"['구조 진단', '유도초음파', '심층학습', '합성곱 신경망', '객체검출', 'Structural Health Monitoring', 'Guided Wave', 'Deep Learning', 'Convolution Neural Network', 'Object Detection']",,
베어링 결함 모드 분류하는 과적합에 강건한 합성곱 신경망 네트워크,2024,"['Fault Detection', 'Auto-Encoder', 'Slewing Bearing', 'Convolutional Neural Network', 'Short-Time Fourier Transformation', '이상 탐지', '오토엔코더', '선회 베어링', '합성곱 신경망', '단시간 푸리에 변환']","베어링은 축을 중심으로 하는 회전 운동에서 발생하는 마찰을 방지하고 부하를 지지하는 기계 시스템에서 사용되는 정밀한 부품이다. 베어링은 내륜 결함, 외륜 결함 및 회전 요소 결함과 같은 결함들에 의해 주로 고장난다. 전통적인 진동 신호 분석과 달리, 단시간 푸리에 변환과 결합된 컨볼루션 신경망을 사용한 딥러닝 기술은 미세한 결함까지도 효과적으로 분류할 수 있다. 그러나 대부분의 선행 연구들은 과적합을 강하게 유발하는 조건에서 수행되지 않았다. 본 논문은 베어링 결함 모드를 분류하는 신경망의 과적합을 방지하는 방법을 주로 논한다. 검증을 위해 베어링 운용 중 동시에 측정한 축방향 및 지름방향 가속도 신호을 실험으로 구축했다. 간단한 신호 분석으로도 이종의 축 신호는 물리적으로 매우 유사하였고 따라서 측정 방향이 달라져도 훈련과 검증의 성능 차이가 나는 것은 과적합을 의미함을 확인했다. 본 논문에서는 오토인코더 기반의 컨볼루션 신경망을 사용하여 과적합을 방지하며 성능을 안정적으로 향상시켰다.","Bearings are precise components used in mechanical systems to prevent friction and support loads arising from rotational movements along an axis. Bearings primarily fail due to defects such as inner ring faults, outer ring faults, and rolling element faults. Unlike traditional vibration signal analysis, deep learning techniques combining convolutional neural networks with short-time Fourier transforms have been known to classify even minor defects. However, previous studies have not been conducted under conditions that strongly cause overfitting. This paper mainly discusses about how to prevent overfitting in convolutional neural networks for bearing fault mode classification. We constructed a dataset with simultaneously measured axial and radial acceleration signals during bearing operation. Simple signal analysis showed that two different signals are physically very similar, confirming that differences in training and validation performance due to changing measurement directions indicate overfitting. In this paper, we prevented overfitting and improved performance using a convolutional neural network based on auto-encoders."
DNA 길이와 혼합 종 개수 예측을 위한 합성곱 신경망,2024,"['Convolutional neural network', 'DNA length', 'Number of DNA species', 'Spatiotemporal map']","기계학습법의 신경망 기술을 이용한 자료분석은 질병 유전자 탐색 및 진단, 신약 개발, 약인성 간 손상 예측 등과 같은 다양한 분야에서 활용되고 있다. 질병 특징 발견을 위한 자료분석은 DNA 정보를 기반으로 이루어질 수 있다. 본연구에서는 DNA의 분자 정보 중 DNA의 길이와 용액 내 DNA의 길이별 종 개수를 예측하는 신경망을 개발하였다.겔 전기영동을 통한 기존 방법론의 시간 소요 한계점을 해결하고자, 미세유체역학적 농축 장치의 동역학 자료를 분석대상으로 하여 실험 분석 과정 중의 시간 소요 문제점을 해결하였다. 동역학 자료를 공간시간 지도로 재구성하여 학습및 예측에 필요한 계산용량을 낮추었으며, 공간시간 지도에 대한 분석 정확도를 높이기 위해 합성곱 신경망을 활용하였다. 그 결과, 단일 변수 회귀로써의 단일 DNA 길이 예측과 복합 변수 회귀로써의 다종 DNA 길이의 동시 예측 및이진 분류로써의 DNA 혼합 종 개수 예측을 성공적으로 수행하였다. 추가적으로, 예측 과정 중 발생할 수 있는 예측편향을 학습 자료 구성 방식을 통한 해결책을 제시하였다. 본 연구를 활용한다면, 광학 측정 자료를 이용하는 액체생검 기반의 세포유리 DNA 분석 및 암 진단 등의 의학 자료 분석을 효과적으로 수행할 수 있을 것이다.","Machine learning techniques utilizing neural networks have been employed in various fields such as disease gene discovery and diagnosis, drug development, and prediction of drug-induced liver injury. Disease features can be investigated by molecular information of DNA. In this study, we developed a neural network to predict the length of DNA and the number of DNA species in mixture solution which are representative molecular information of DNA. In order to address the time-consuming limitations of gel electrophoresis as conventional analysis, we analyzed the dynamic data of a microfluidic concentrating device. The dynamic data were reconstructed into a spatiotemporal map, which reduced the computational cost required for training and prediction. We employed a convolutional neural network to enhance the accuracy to analyze the spatiotemporal map. As a result, we successfully performed single DNA length prediction as single-variable regression, simultaneous prediction of multiple DNA lengths as multivariable regression, and prediction of the number of DNA species in mixture as binary classification. Additionally, based on the composition of training data, we proposed a solution to resolve the problem of prediction bias. By utilizing this study, it would be effectively performed that medical diagnosis using optical measurement such as liquid biopsy of cell-free DNA, cancer diagnosis, etc."
대장암 분화도 예측을 위한 순서학습과 투표기법 기반 합성곱 신경망 인공지능 모델,2024,"['Computational pathology', 'Cancer grading', 'Order learning', 'Voting', '계산병리학', '암 등급 분류', '순서학습', '투표체계']","암은 전 세계적으로 주요 사망원인 중 하나이며, 환자의 건강 관리를 위해 신속 정확한 암 진단이 필수적이다. 본 연구에서는 대장암 환자로부터 얻어진 디지털화된 전체 슬라이드 이미지와 딥러닝 기술을 활용하여 대장암 암 등급 분류를 수행할 수 있는 방법론을 제시한다. 기존의 암 등급 분류 연구는 범주형 분류 방법이 주로 활용되었다. 범주형 분류 방법에서는 서로 다른 암 등급을 독립적인 것으로 가정한다. 하지만, 암 세포조직은 정상 세포조직과의 유사한 정도에 따라 저분화도 암세포부터 고분화도 암세포까지 나눌 수 있어 상대적인 관계성이 성립함을 알 수 있다. 따라서, 본 연구에서는 암 등급 간 순서관계를 정의하고 이를 활용하여 암 등급 분류를 수행하고자 한다. 이를 위해 합성곱 신경망에 기초하여 모델을 구성한다. 해당 모델은 범주형 분류와 순서분류를 동시에 수행하며, 순서분류를 위해 입력 이미지와 이와 비교할 수 있는 참고 이미지 쌍을 활용한다. 또한, 잘못 예측될 가능성이 높은 입력 이미지를 선별하고, 보다 정확한 암 등급 분류를 수행하기 위해 투표 체계를 활용한 후보정 기법을 제시한다. 실험 결과, 본 연구에서 제안하는 순서학습 기반 합성곱 신경망 모델은 대장암 분화도 예측에서 기존의 모델 대비 우수한 성능을 보였다. 또한, 본 연구에서 제안하는 모델의 각 구성요소들은 암 등급 분류 성능 향상에 골고루 기여하는 것을 확인할 수 있었다. 이번 연구를 통해 디지털화된 세포조직 이미지를 활용한 자동화된 암 등급 분류를 수행할 수 있는 가능성을 확인하였으며, 제안하는 기술은 대장암 이외의 다른 암 또는 질병 연구에 활용될 수 있을 것으로 기대된다.","Cancer is one of the leading causes of death worldwide. Accurate and reliable cancer diagnosis is a prerequisite for timely management and treatment. In this study, we propose a deep learning method that can conduct colorectal cancer diagnosis on whole slide images obtained from colorectal cancer patients. Previous research on cancer grading primarily focused on categorical classification, which assumes the independence among cancer grades. However, cancer grades indicate how different or close the cancer cells are to normal cells. That is, cancer grades are related to each other. Herein, we propose to define the ordinal relationship among cancer grades and use them to conduct cancer diagnosis. To achieve this, we construct a convolutional neural network that can simultaneously perform both categorical and ordinal classification. The ordinal classification utilizes a pair of an input image and a reference image. Moreover, we introduce a voting mechanism to improve the classification performance. The voting mechanism identifies the input image that is likely to be mis-classified and corrects the classification. The experimental results demonstrate that the proposed method not only accurately conducts cancer grading but also outperforms other competing models. We anticipate that the proposed method can be applied to other types of cancers and disease to improve the quality of diagnosis and patient management."
합성곱 신경망 연산을 위한 저전력 콘볼루션 레이어 하드웨어 설계,2024,"['CNN', 'Convolution Layer', 'Low-Power', 'Multiplication']",,
합성곱 신경망 병렬 연산처리를 지원하는 저전력 곱셈 프로세싱 엘리먼트 설계,2024,"['CNN', 'Low-power multiplication', 'Processing element', 'Multiplier', 'FPGA']",,"CNNs tend to take a long time to learn and consume a lot of power due to lack of system resources with many data processing units when there are repetitive handles that do not have high performance in the image field. In this paper, we propose a handling method based on a low-power bus that can increase the exchange rate of multipliers and multiplicands within the convolution mixer, which is a tendency activity that occurs when a convolution mixer has multiplication, which is the core element of combination. Convolutional neural networks have proprietary low-power shared processor support and the design was implemented on an Intel DE1-SoC FPGA board using Verilog-HDL. The experiments validated the performance by comparing it with the exchange rate of the multiplier originally proposed by Shen on MNIST's numeric image database."
확장 합성곱 신경망 기반의 도로 노면 파손 검지 연구,2024,"['Dilated Convolutional Neural Network', 'AI detection', 'Road surface', 'Pothole', 'YOLOv5']",,"Potholes, one of the main causes of road-surface damage, pose a physical hazard to drivers, cause vehicle damage, and increase road maintenance costs. Hence, a model that enhances the accuracy of pothole detection and improves the real-time detection speed is required.A new model based on dilated convolutional neural networks was developed using a dataset that considers various lighting conditions, road conditions, and pothole sizes and shapes.Although the existing YOLOv5 model demonstrated high speed, it exhibited some false-positive pothole detections. In contrast, the proposed dilated convolutional neural network achieved both high accuracy and an appropriate inference speed, making it suitable for real-time detection.Compared with traditional models, the proposed model demonstrated efficiency in terms of model size and inference speed, indicating its potential suitability for systems performing real-time pothole detection when installed directly in vehicles."
입사각 정보를 이용한 합성곱 신경망 기반의 우주표적 분류기 성능 향상,2024,"['Angle of Incidence', 'Convolutional Neural Network', 'Space-Target', 'Micro-Doppler Signature', 'Micro-Motion']",,
유방암 분류를 위한 합성곱 신경망 및 랜덤 포레스트 분류기의 비교 연구,2024,"['Automated Diagnostic System', 'Breast Cancer Diagnosis', 'Classification Performance Metrics', 'Convolutional Neural Network', 'Computer-Aided Diagnosis', 'Early Detection', 'Random Forest']",,
다중 입출력 FMCW 레이다를 활용한 합성곱 신경망 기반 사람 동작 인식 시스템,2024,"['MIMO FMCW Radar', 'Human Activity Recognition', 'Point Cloud', 'PointPillars', 'CNN']","본 논문에서는 다중 입출력 주파수 변조 연속파 (MIMO FMCW; multiple input multiple output frequency modulation continuous wave) 레이다 기반 HAR (human activity recognition) 시스템의 설계 및 구현 결과를 제시하였다. 다중 입력 다중 출력 레이다 센서를 통한 포인트 클라우드 데이터를 활용하여 HAR 시스템을 구현하면 사생활 보호와 함께, 안전성 및 정확성 측면에서 장점이 있다. 본 논문에서는, MIMO FMCW 레이다 센서로부터의 포인트클라우드 데이터 기반 HAR을 위해 PointPillars와 DS-CNN (depthwise separable convolutional neural network)을 기반으로 최적 경량 네트워크를 개발하였다. 경량화된 네트워크를 통해 고해상도 포인트 클라우드 데이터를 처리하여 높은 인식 정확도와 함께 효율성을 달성하였다. 결과적으로, 98.27%의 정확도와 11.27M Macs (multiply-accumulates) 연산 복잡도로 구현 가능함을 확인하였다. 또한, 개발한 모델을 라즈베리파이(Raspberry-Pi) 시스템에 구현하여 최대 8 fps의 속도로 포인트 클라우드 데이터 처리가 가능함을 확인하였다.","In this paper, a human activity regeneration (HAR) system based on multiple input multiple output frequency modulation continuous wave (MIMO FMCW) radar was designed and implemented. Using point cloud data from MIMO radar sensors has advantages in terms of privacy, safety, and accuracy. For the implementation of the HAR system, a customized neural network based on PointPillars and depthwise separate convolutional neural network (DS-CNN) was developed. By processing high-resolution point cloud data through a lightweight network, high accuracy and efficiency were achieved. As a result, the accuracy of 98.27% and the computational complexity of 11.27M multiply-accumulates (Macs) were achieved. In addition, the developed neural network model was implemented on Raspberry-Pi embedded system and it was confirmed that point cloud data can be processed at a speed of up to 8 fps."
네트워크 침입 탐지 분야에서 공격 유형 분류를 위한 합성곱 신경망 모델에 대한 연구,2024,"['network intrusion detection', 'transfer learning', 'attack type classification', 'UNSW-NB15']",,
멀티 모달리티 데이터 활용을 통한 골다공증 단계 다중 분류 시스템 개발: 합성곱 신경망 기반의 딥러닝 적용,2024,"['인공지능', '골밀도', '골다공증', '임상 의사결정 지원 시스템', '딥러닝', 'Artificial intelligence', 'Bone marrow density', 'Osteoporosis', 'Clinical Decision Support Systems', 'Deep learning']","골다공증은 전 세계적으로 주요한 건강 문제임에도 불구하고, 골절 발생 전까지 쉽게 발견되지 않는 단점을 가지고 있습니다. 본 연구에서는 골다공증 조기 발견 능력 향상을 위해, 복부 컴퓨터 단층 촬영(Computed Tomography, CT) 영상을 활용하여 정상-골감소증-골다공증으로 구분되는 골다공증 단계를 체계적으로 분류할 수 있는 딥러닝(Deep learning, DL) 시스템을 개발하였습니다. 총 3,012개의 조영제 향상 복부 CT 영상과 개별 환자의 이중 에너지 X선 흡수 계측법(Dual-Energy X-ray Absorptiometry, DXA)으로 얻은 T-점수를 활용하여 딥러닝 모델 개발을 수행하였습니다. 모든 딥러닝 모델은 비정형 이미지 데이터, 정형 인구 통계 정보 및 비정형 영상 데이터와 정형 데이터를 동시에 활용하는 다중 모달 방법에 각각 모델 구현을 실현하였으며, 모든 환자들은 T-점수를 통해 정상, 골감소증 및 골다공증 그룹으로 분류되었습니다.가장 높은 정확도를 갖는 모델 우수성은 비정형-정형 결합 데이터 모델이 가장 우수하였으며, 수신자 조작 특성 곡선 아래 면적이 0.94와 정확도가 0.80를 제시하였습니다. 구현된 딥러닝 모델은 그라디언트 가중치 클래스 활성화 매핑(Gradient-weighted Class Activation Mapping, Grad-CAM)을 통해 해석되어 이미지 내에서 임상적으로 관련된 특징을 강조했고, 대퇴 경부가 골다공증을 통해 골절 발생이 높은 위험 부위임을 밝혔습니다. 이 연구는 DL이 임상 데이터에서 골다공증 단계를 정확하게 식별할 수 있음을 보여주며, 조기에 골다공증을 탐지하고 적절한 치료로 골절 위험을 줄일 수 있는 복부 컴퓨터 단층 촬영 영상의 잠재력을 제시할 수 있습니다.","Osteoporosis is a major health issue globally, often remaining undetected until a fracture occurs. To facilitate early detection, deep learning (DL) models were developed to classify osteoporosis using abdominal computed tomography (CT) scans. This study was conducted using retrospectively collected data from 3,012 contrast-enhanced abdominal CT scans. The DL models developed in this study were constructed for using image data, demographic/clinical information, and multi-modality data, respectively.Patients were categorized into the normal, osteopenia, and osteoporosis groups based on their T-scores, obtained from dual-energy X-ray absorptiometry, into normal, osteopenia, and osteoporosis groups. The models showed high accuracy and effectiveness, with the combined data model performing the best, achieving an area under the receiver operating characteristic curve of 0.94 and an accuracy of 0.80. The image-based model also performed well, while the demographic data model had lower accuracy and effectiveness. In addition, the DL model was interpreted by gradient-weighted class activation mapping (Grad-CAM) to highlight clinically relevant features in the images, revealing the femoral neck as a common site for fractures. The study shows that DL can accurately identify osteoporosis stages from clinical data, indicating the potential of abdominal CT scans in early osteoporosis detection and reducing fracture risks with prompt treatment."
한반도 집중호우 모의를 위한 심층 합성곱 생성적 적대 신경망의 강우 임계 설정에 관한 연구,2024,"['정량적 강우 추정', '생성적 적대 신경망', '극한 강우 이미지', '최대 임계값 설정 기준', 'quantitative precipitation estimates', 'generative adversarial network', 'extreme precipitation image', 'maximum threshold setting criteria']","기상 이변으로 인해 증가하는 극한 호우 피해에 효과적으로 대응하기 위해서는 호우 주의보 및 경보 발령 기준이 되는 강우량을 정확히 추정하는 것이 매우 중요하다. 본 연구는 한반도 전역의 5km 공간 해상도를 가진 일누적 강우량 자료를 활용하여 한반도 집중호우인 장마와 태풍에 따른 극한 강우 패턴을 모의하는 것을 목표로 한다. 먼저, 극한 강우 자료의 특성을 정확히 반영할 수 있는 최대 임계값을 도출하였고, 이를 기반으로 극한 강우 사건을 모의하기 위해 심층 합성곱 생성적 적대 신경망(DCGAN)을 제안하였다. 생성된 강우 이미지의 품질 평가는 FID(Frechet Inception Distance), 재구성 손실(reconstruction loss), MAPE(Mean Absolute Percentage Error) 등의 평가 지표를 사용하였다. 분석 결과, 강우 발생 사건 수의 상위 0.01%를 임계값으로 설정하는 것이 손실된 정보를 효과적으로 절충(trade-off)하는 데 가장 적절한 것으로 나타났다. DCGAN 모델은 장마와 태풍 상황에서 정량적 강우 추정에 유용한 것으로 분석되었으며, 특히 200mm/day 이하의 강우 사건 모의에서 기존 모델에 비해 모든 지표에서 우수한 성능을 보였다. 생성된 이미지는 국지적 강우 패턴을 충실히 반영하여 특정 지역에서 발생할 수 있는 자연재해의 가능성을 예측하고 대비하는 데 유용한 정보를 제공할 수 있을 것으로 기대된다.","To effectively respond to the increasing damage caused by extreme rainfall due to climate change, it is crucial to accurately estimate the rainfall threshold that triggers heavy rain advisories and warnings. This study aims to simulate extreme rainfall patterns associated with monsoons and typhoons over the Korean Peninsula by using daily cumulative rainfall data with a 5km spatial resolution. First, a maximum threshold was determined to represent the characteristics of extreme rainfall data best and a Deep Convolutional Generative Adversarial Network (DCGAN) model was proposed to simulate such extreme rainfall events. The quality of the generated rainfall images was evaluated using metrics such as Frechet Inception Distance (FID), reconstruction loss, and Mean Absolute Percentage Error (MAPE). Analysis results indicated that setting the threshold at the top 0.01% of rainfall events achieved the most effective trade-off in preserving information. The DCGAN model proved useful for quantitative rainfall estimation in monsoon and typhoon scenarios, showing superior performance across all metrics, especially for events with rainfall amounts below 200mm/day, compared to conventional models. The generated images effectively captured localized rainfall patterns and are expected to provide valuable information for predicting and preparing for potential natural disasters in specific areas."
심층 합성곱 생성적 적대 신경망을 활용한 하악 제1대구치 가상 치아 생성 및 정확도 분석,2024,"['Deep Convolutional Generative Adversarial Network', 'Deep learning', 'Tooth classification', 'Virtual tooth generation']",,"Purpose: This study aimed to generate virtual mandibular left first molar teeth using deep convolutional generative adversarial networks (DCGANs) and analyze their matching accuracy with actual tooth morphology to propose a new paradigm for using medical data.Methods: Occlusal surface images of the mandibular left first molar scanned using a dental model scanner were analyzed using DCGANs. Overall, 100 training sets comprising 50 original and 50 background-removed images were created, thus generating 1,000 virtual teeth. These virtual teeth were classified based on the number of cusps and occlusal surface ratio, and subsequently, were analyzed for consistency by expert dental technicians over three rounds of examination. Statistical analysis was conducted using IBM SPSS Statistics ver. 23.0 (IBM), including intraclass correlation coefficient for intrarater reliability, one-way ANOVA, and Tukey’s post-hoc analysis.Results: Virtual mandibular left first molars exhibited high consistency in the occlusal surface ratio but varied in other criteria. Moreover, consistency was the highest in the occlusal buccal lingual criteria at 91.9%, whereas discrepancies were observed most in the occusal buccal cusp criteria at 85.5%. Significant differences were observed among all groups (p<0.05).Conclusion: Based on the classification of the virtually generated left mandibular first molar according to several criteria, DCGANs can generate virtual data highly similar to real data. Thus, subsequent research in the dental field, including the development of improved neural network structures, is necessary."
의료영상 분류를 위한 심층신경망 훈련에서 StyleGAN 합성 영상의 데이터 증강 효과    분석,2024,"['심층신경망', '의료영상', '영상 분류', '데이터 증강', '생성적 적대 신경망', 'Deep learning', 'Medical imaging', 'Image classification', 'Data augmentation', 'Generative adversarial network']","본 논문에서는 의료 영상 분류를 위한 심층 신경망 훈련에서 StyleGAN 합성 영상의 데이터 증강 효과를 분석한다. 이를 위해흉부 X선 영상에서의 폐렴 진단과 복부 CT 영상에서의 간전이암 분류 문제에서 StyleGAN 합성 영상을이용하여 VGG-16 심층 합성곱 신경망 훈련을 수행한다. 실험에서 분류 결과에 대한 정량적, 정성적 분석을 통해 StyleGAN 데이터 증강이 특징공간에서 클래스 외곽을 확장하는 특성을 보이며, 이와 같은 특성으로 인해 실제 영상과의 적절한 비율을 통해 혼합했을 때분류 성능이 개선될 수 있음을 확인하였다.","In this paper, we examine the effectiveness of StyleGAN-generated images for data augmentation in training deep neural networks for medical image classification. We apply StyleGAN data augmentation to train VGG-16 networks for pneumonia diagnosis from chest X-ray images and focal liver lesion classification from abdominal CT images. Through quantitative and qualitative analyses, our experiments reveal that StyleGAN data augmentation expands the outer class boundaries in the feature space. Thanks to this expansion characteristics, the StyleGAN data augmentation can enhance classification performance when properly combined with real training images."
영상 잡음 제거 신경망 및 구조 최적화,2024,"['Convolutional neural network', 'Image denoising', 'Multi-channel feature map', 'Covariate shift', 'Gaussian noise', '합성곱 신경망', '영상 잡음제거', '다채널 특징맵', '분산 천이', '가우시안 잡음']","합성곱 기반의 신경망이 컴퓨터 비전 분야에서 우수한 성능을 보임이 알려진 후로 다양한 분야에 적용되고 있다.영상 내의 잡음을 제거하는 과제에도 신경망을 이용한 연구가 활발히 수행되고 있다. 우수한 잡음제거 성능을 보이는 구조를 찾고, 또한 그 구조에 적용되는 여러 가지 파라미터를 선정하는 작업은 매우 중요하다. 본 논문에서는 합성곱 신경망을 여러 채널 및 여러 층으로 구성하여 입력 영상 속에 포함되어 있는 잡음을 추정하는 네트워크를 제안한다. 또한 내부 신호의 공변량 천이 현상에 대응하기 위해 배치 정규화를 채택한다. 이러한 구조의 세부 파라미터인 채널 수와 층수를 성능 평가에 의하여 결정하였다. 또한 다양한 학습 데이터를 이용하여 네트워크를 학습시키고, 가우시안 잡음제거 성능을 최신의 연구결과들과 비교하여 제안된 신경망의 우수성을 보인다.","Since convolutional neural networks (CNNs) have been shown to exhibit excellent performance in the field ofcomputer vision, they are being applied to various domains. Research using neural networks for tasks such as removingnoise from images is also being actively conducted. Finding structures that demonstrate superior noise removalperformance and selecting various parameters applicable to these structures are crucial tasks. In this paper, we propose anetwork that estimates noise within input images by constructing convolutional neural networks with multiple channelsand layers. To address the issue of internal covariate shift, batch normalization is adopted. The detailed parameters of thisstructure, such as the number of channels and layers, are determined by evaluating their performance. Additionally, thenetwork is trained using various datasets, and the Gaussian noise removal performance is compared with the latestresearch results to demonstrate the superiority of the proposed neural network."
캡슐 신경망의 시계열 데이터에 대한 노이즈 저감 기능,2024,"['관점 불변성', '아핀 행렬', '센서 고장', '벡터 표현', '적대적 공격', '노이즈 함수', 'Viewpoint Equivariance', 'Affine Matrix', 'Defective Sensor', 'Vector Representation', 'Adversarial Attack', 'Noise Formula']","캡슐은 여러 뉴런을 묶은 벡터 표현으로, 객체의 각도, 위치, 크기와 같은 중요한 정보를 담고 있다. 캡슐 신경망은 이러한 관점 불변성을 학습하여 기존의 합성곱 신경망보다 노이즈가 많은 데이터에 강건하게 작동한다. 특히, 동적 라우팅 캡슐 신경망은 아핀 행렬과 동적 라우팅을 통해 캡슐을 학습한다. 본 연구에서는 아핀 행렬이 데이터의 변형을 나타내는 동안, 동적 라우팅 캡슐 신경망이 노이즈가 많고 민감한 시계열 데이터에 대한 노이즈 안정화 기능을 수행할 수 있다고 가정한다.  우리는 이 노이즈 안정화 기능을 입증하기 위해 심전도(ECG) 데이터에 대해 수동 및 적대적 공격을 수행한다. 본 연구는 캡슐 신경망이 노이즈를 효과적으로 제거하여 노이즈 안정화 기능을 수행함을 실험을 통해 입증한다. 또한, 시계열 분석에서 발생한 노이즈 데이터로 인한 전처리 과정을 데이터 기반으로 해결할 수 있는 잠재력을 강조한다.","A Capsule is a vector-wise representation formed by multiple neurons that encodes conceptual information about an object, such as angle, position, and size. Capsule Neural Network (CapsNet) learns to be viewpoint invariant using these capsules. This property makes CapsNet more resilient to noisy data compared to traditional Convolutional Neural Networks (CNNs). The Dynamic-Routing Capsule Neural Network (DR-CapsNet) uses an affine matrix and dynamic routing mechanism to train the capsules. In this paper, we propose that DR-CapsNet has the potential to act as a noise stabilizer in time series sensor data that have high sensitivity and significant noise in real world. To demonstrate the robustness of DR-CapsNet as a stabilizer, we conduct manual and adversarial attacks on an electrocardiogram (ECG) dataset. Our study provides empirical evidence that CapsNet effectively functions as a noise stabilizer and highlights its potential in addressing the challenges of preprocessing noisy measurements in time series analysis."
영상 패치 기반 그래프 신경망을 이용한 수동소나 신호분류,2024,"['수동소나', '그래프 표현', '영상 패치', '그래프 신경망', 'Passive sonar', 'Graph representation', 'Patch image', 'Graph Neural Network (GNN)']","본 논문에서는 그래프 신경망을 이용한 수동소나 신호 분류 알고리즘을 제안한다. 제안하는 알고리즘은 스펙트로그램을 영상 패치로 분할하고, 인접 거리의 영상 패치 간 연결을 통해 그래프를 표현한다. 이후, 표현된 그래프를이용하여 그래프 합성곱 신경망을 학습하고 신호를 분류한다. 공개된 수중 음향 데이터를 이용한 실험에서 제안된 알고리즘은 스펙트로그램의 선 주파수 특징을 그래프 형태로 표현하며, 92.50 %의 우수한 분류 정확도를 갖는다. 이러한결과는 기존의 합성곱 신경망과 비교하여 8.15 %의 높은 분류 정확도를 갖는다.","We propose a passive sonar signal classification algorithm using Graph Neural Network (GNN).The proposed algorithm segments spectrograms into image patches and represents graphs through connections between adjacent image patches. Subsequently, Graph Convolutional Network (GCN) is trained using the represented graphs to classify signals. In experiments with publicly available underwater acoustic data, the proposed algorithm represents the line frequency features of spectrograms in graph form, achieving an impressive classification accuracy of 92.50 %. This result demonstrates a 8.15 % higher classification accuracy compared to conventional Convolutional Neural Network (CNN)."
신경망을 이용한 반도체 테스트 핀 불량 검출,2024,"['Deep learning', 'CNN', 'Perceptron', 'Automatic defect classification', 'Semiconductor']","사람의 머리카락보다 얇은 반도체 테스트 핀으로 반도체 단자에 접촉하여 반도체의 전기적 선능 측정을 반복한다. 테스트 핀과 반도체 사이의 완전한 접촉을 위하여 핀에는 스프링이 있어서 스프링을 중심으로 양쪽의 구조가 눌렸다 펴지기를 반복한다. 만약 불량 테스트 핀이 발생하면 완전한 접촉이 되지 않아 반도체 성능 측정에 오류가 발생한다. 본 논문은 합성곱 신경망 (CNN) 기법 및 다층 퍼셉트론 신경망 (MLP)을 이용하여 양호한 핀과 불량한 핀을 학습하여 사람의 눈을 이용하지 않고 불량 핀을 검출한다. 따라서 수작업으로 불량 핀을 검출하지 않고, 제안하는 두 모델을 이용하여 기계가 자동으로 약 97%의 정확도로 불량 핀을 검출할 수 있다.","Semiconductor test pins, which are thinner than human hair, repeatedly make contact with semiconductor terminals to measure the electrical performance of the semiconductors. To ensure complete contact between the test pins and the semiconductor, the pin is equipped with a spring, allowing the structure on both sides of the spring to be compressed and then released repeatedly. If a defective test pin occurs, it results in incomplete contact, leading to errors in measuring semiconductor performance. This paper utilizes Convolutional Neural Networks (CNN) and Multilayer Perceptron Neural Networks (MLP) techniques to train and detect good and defective pins, thereby detecting defective pins without the use of human vision. Therefore, instead of manually detecting defective pins, the proposed models enable machines to automatically detect defective pins with about 97% accuracy."
시계열 데이터를 이용한 인공신경망 기반 공작기계 가공상태 모니터링,2024,"['공작기계', '시계열 데이터', '인공신경망', '합성곱 신경망', '장단기 메모리', 'Machine tool', 'Time series data', 'Artificial neural network', 'Convolution neural network', 'Long short-term memory']",,"In order to monitor the machining status of a machine tool, it is necessary to measure the signal of the machine tool and establish the relationship between the machining status and the signal. One effective approach is to utilize an AI-based analysis model. To improve the accuracy and reliability of AI models, it is crucial to identify the features of the model through signal analysis. However, when dealing with time series data, it has been challenging to identify these features. Therefore, instead of directly applying time series data, a method was used to extract the best features by processing the data using techniques such as RMS and FFT. Recently, there have been numerous reported cases of designing AI models with high accuracy and reliability by directly applying time series data to find the best features, particularly in the case of AI models combining CNN and LSTM. In this paper, time series data obtained through a gap sensor are directly applied to an AI model that combines CNN, LSTM, and MLP (Multi-Layer Perceptron) to determine tool wear. The machine tool and tool status were monitored and evaluated through an AI model trained using time series data from the machining process."
적외선 열화상 비파괴검사(IRT) 결과분석에 경량화딥러닝 신경망 활용,2024,"['MobileNet(모바일넷)', 'Lightweight Deep Learning(경량화딥러닝)', 'Convolutional Neural Network(합성곱신경망)', 'Infrared Thermography Testing(적외선 열화상 비파괴검사)', 'Statistical Analysis(통계분석)']",,
입찰 문장의 BIM 요구사항 난이도 판별에 대한 문자 임베딩 기반 딥러닝 모델 비교,2024,"['문자 임베딩', '합성곱 신경망', '양방향 장단기기억 신경망', '입찰', 'BIM 요구사항', 'Character embedding', 'Convolutional neural network', 'Bi-directional long-short term memory neural network', 'Bid', 'BIM requirement']","건설사업의 BIM 적용이 의무화됨에 따라 입찰단계에서부터 BIM 요구사항 분석이 중요해지고 있고, 방대한 입찰 텍스트 정보를 효과적으로 처리하기 위한 자연어 처리 연구가 활발히 이뤄지고 있다. 국내 입찰문서는 한글과 영문이 혼재되어 있고 동일 표현에 대한 표기가 불규칙해 전처리를 수행하더라도 텍스트 품질 개선이 제한되고 형태소 분석기 성능에 영향을 받는 등의 어려움이 있어, 분석 모델의 성능 저하의 원인으로 작용한다. 이러한 이유로 본 연구는 전처리에 기인한 성능 저하를 저감할 수 있도록 문자 임베딩을 사용해 입찰 문장에 포함된 BIM 요구사항의 난이도 분류를 수행하는 딥러닝 모델을 제시하였다. 단순 문자 임베딩, 양방향 장단기기억 신경망을 결합한 문자 임베딩, 그리고 합성곱 신경망을 결합한 문자 임베딩 모델에 대한 주요 매개변수 영향을 분석하여 최적 모델을 도출하였고, 문자 임베딩 모델 간 BIM 요구사항 난이도 판별 성능을 비교하였다. 추가로 단어 임베딩 기반의 타 모델 결과와 비교하였다. 세 가지 모델 가운데 합성곱 신경망을 활용한 문자 임베딩 모델이 가장 높은 F1 지표(0.98)를 나타내었으며, F1 변화에 합성곱 필터 수 및 크기가 가장 큰 영향을 미치는 것을 확인하였다. 또한 문자 임베딩 모델 사용을 통해 단어 임베딩 모델 대비 약 15 %의 F1 지표 향상이 가능함을 확인하였다.","With the mandatory application of Building Information Modeling (BIM) in construction projects, the analysis of BIM requirementsfrom the bidding stage has become increasingly important. To effectively handle the vast amount of bid text information, research onnatural language processing has been actively conducted. However, domestic bid documents often contain a mixture of Korean andEnglish, and the inconsistent representation of identical expressions limits text quality improvement even after pre-processing, whichin turn affects the performance of morphological analyzers. These challenges contribute to the degradation of analytical modelperformance. To mitigate performance degradation caused by pre-processing, this study proposes a deep learning model that classifiesthe difficulty level of BIM requirements in bid sentences using character embeddings. The study analyzes the impact of key parameterson three types of character embedding models: a simple character embedding, a character embedding combined with the Bi-directionallong short-term memory layer, and a character embedding combined with the convolutional neural networks (CNN) layer. Based onthis analysis, the optimal model was derived, and the performance of BIM requirement difficulty classification was compared acrossthe character embedding models. Additionally, the results were compared with those of other models based on word embeddings.Among the three models, the character embedding model utilizing CNN achieved the highest F1 score (0.98), with the number andsize of convolutional filters having the most significant impact on F1 score variation. Furthermore, it was confirmed that the use ofcharacter embedding models resulted in an approximately 15% improvement in the F1 score compared to word embedding models."
볼륨-플로우 그래프 기반 폐질환 분류를 위한앙상블 딥러닝 모델,2024,"['합성곱 신경망', '앙상블 딥러닝 모델', '폐질환', '볼륨-플로우 그래프', 'Convolutional Neural Network', 'Ensemble Deep Learning Model', 'Pulmonary Disease', 'Flow Volume Loops']","만성 폐쇄성 폐질환은 만성적인 기도 폐쇄를 특징으로 하는 호흡기 질환이다. 만성 폐쇄성폐질환은 초기에 자각 증상이 거의 없어, 대부분 중증 상태로 악화된다. 또한, 인종, 성별, 키,몸무게 등 다양한 요인을 포함한 폐 질환 분류 회귀식은 복잡하고, 정확한 판별을 위해서는지속적인 갱신을 필요로 한다. 따라서 폐질환의 초기 진단이 용이하도록 간편한 휴대형 페기능 검사기를 통해 산출 가능한 볼륨-플로우 그래프 이미지 기반 분류 모델이 요구된다.본 논문에서는 폐질환 조기 진단을 위해 볼륨-플로우 그래프 이미지의 전처리 및 합성곱 신경망 기반 앙상블 딥러닝 모델을 구현하였고, 이를 검증했다. 합성곱 신경망 기반 앙상블 딥러닝 모델은 VGG16, VGG19, ResNet50, 그리고 MobileNet 구조 기반 4개의 모델로 구성되며, 전부 전이학습 및 미세조정하여 사용하였다. 세부적으로는 부족한 수의 학습 데이터를볼륨-플로우 그래프 이미지의 특성을 고려하여 적합한 데이터 증강기법을 적용하였고, 4개의 모델들은 가중치 기반의 간접투표 방식을 사용했다. 최종 앙상블 모델은 단순히 폐질환유무를 판별하는 것이 아닌 정상, 제한성 폐질환, 폐쇄성 폐질환, 그리고 혼합성 폐질환과 같이 총 4개의 클래스로 분류하는 모델임에도 불구하고, 테스트 데이터를 통한 성능은 정확도90.91%, 가중치 평균 정밀도 91.11%, 가중치 평균 재현율 90.91%로 높은 수치를 보였다.","Chronic Obstructive Pulmonary Disease (COPD) is a respiratory disease characterized bychronic airway obstruction. COPD often progresses to a severe stage, since thereare few noticeable symptoms in the early stages. Also regression equations involingvarious factors such as race, gender, height, and weight to determine whether ornot there is pulmonary disease is complex and needs to be updated periodically.Therefore, there is a demand for a system that can easily analze the presence orabsence of the pulmonary disease, even for non-experts. In this paper, aCNN-based flow volume loops classification model using ensemble learning andappropriate data pre-processing algorithms was proposed and validated to diagnosepulmonary disease in the early stages. The ensemble model was organized by fourCNN models based on VGG16, VGG19, Resnet50, and MobileNet and used transferlearning and fine-tuning for each pre-trained model. Specifically, to overcome asmall amount of data, several data augmentation techniques that took into accountthe characteristics of flow volume loops were used, and soft voting was employedfor the ensemble model. The proposed ensemble model not only could diagnose thepresence or absence of pulmonary disease but could also classify into a total of fourcategories: normal, restrictive, obstructive, and combined pulmonary diseases. As aresult of the experiment, the performance of the proposed ensemble model showedan accuracy of 90.91%, precision of 91.11%, and recall of 90.91%."
비파괴검사 품질향상을 위한 CNN 기반 용접결함 분류 및 검증에 관한 연구,2024,"['용접결함', '합성곱 신경망', '비파괴 검사', '육안검사', '방사선 탐상검사', 'Weld defect', 'Convolutional Neural Network (CNN)', 'Nondestructive test (NDT)', 'Visual Test (VT)', 'Radioisotope Test (RT)']","용접은 제조산업에서 가장 중요한 공정 과정이다. 하지만, 산업현장에서는 용접인력 부족 및 고비용의 문제와 전문가 수준의 기술을 습득까지의 오랜 경험이 요구되기 때문에, 제조공정에서 인공지능(AI)기술의 도입이 시급하다. 본 논문에서는 합성곱 신경망(Convolutional Neural Networks, CNN)기반 VGG 모델을 활용하여 제조공정에서 나타나는 용접결함에 대한 이미지 분류를 진행하고, 그 성능을 평가하고자 한다. 본 연구에서는 2가지 유형의 육안검사(Visual Test, VT)와 방사선 탐상검사(Radioisotope Test, RT)의 용접결함 이미지를 수집하였다. 용접결함은 4개의 용접결함(VT: 기공, 용입부족, 융합불량, 언더컷/RT:기공, 용입부족, 균열, 슬래그 혼입)과 1개의 정상으로 구성되어 있다. 용접결함 이미지는 원 데이터를 직접적으로 활용하였으며, 그 결과, VT, RT 이미지에 대하여 각각 98%, 92%의 성능을 확인하였다. 본 연구는 데이터 증강 등 데이터 정제 없이 진행한 점에 의의가 있으며, 향후 본 연구 결과를 기반으로 더 많은 자료수집을 통한 데이터의 확장과 더불어, 다양한 딥러닝 모델을 활용한 성능향상을 통하여 용접결함 검사 시스템 개발에 활용할 수 있을 것이다.","Welding plays a crucial role in the manufacturing industry. Nevertheless, the manufacturing industry urgently requires integrated artificial intelligence (AI) technology to enhance productivity because of the scarcity of human resources, the high costs involved, and the long time needed to attain an expert level. This study aims to classify welding defects using the EGG model based on CNN (Constitutional Neural Network). This study collected two types of welding defect images: a visual test (VT) and a radioisotope test (RT). There are four categories of welding defects: VT defects, which include porosity, incomplete penetration, lack of fusion, and undercut, and RT defects, which consist of cracks, porosity, lack of fusion, and slag inclusion. We also collected normal data. We input the raw image, not data p reprocessing, and achieve classification performances of 98% in VT and 92% in RT, respectively. Our finding is significant because it was conducted without data purification, such as data augmentation. We are expected to expand the data and improve performance by utilizing a variety of deep-learning models. In addition, our study helps to create a welding defect inspection system that can accurately detect surface defects in welds in future works."
유사하거나 동일한 폐수처리공정에서의 전이학습 적용 유무에 따른 심층학습 알고리즘의 성능 평가,2024,"['전이학습', '심층학습', '합성곱 신경망', '장단기 메모리', '폐수처리공정', '""Transfer learning', 'Deep learning', 'Convolutional neural network', 'Long short-term memory', 'Wastewater treatment process""']","""본 연구에서는 두 개의 인지도가 높은 심층학습 알고리즘을 사용하여 하나의 폐수처리공정에서 다른 폐수처리공정으로의 전이학습의 적용 가능성을 평가하였다. 구체적으로는, 전이학습을 위한 벤치마크 알고리즘으로4개및 3개의 은닉층으로 각각 구성된 합성곱 신경망과 장단기 메모리를 사용하였다. 심층학습과 전이학습을 위해 (진주와 청주시에 위치한) 동일한 처리공정을 가지는 2개의 폐수처리시설로부터 2018년부터 2022년까지 총 5년간의입력 데이터가 제공되었다. 모델의 성능 평가는 평균제곱오차를 기준으로 2개 심층학습과 더불어 2개의 다른 전이학습 적용 방법(사전 훈련된 모델에서 개발된 모든 은닉층을 사용하는 방법과 다수의 은닉층 중 마지막 은닉층만을 훈련에 사용하는 방법)을 채택하여 수행되었다. 평가 결과, 유량 및 생물화학적 산소요구량과 같은 종속 변수에관계없이 합성곱 신경망과 장단기 메모리의 성능은 상대적으로 유사한 것으로 조사되었으며, 다만 유량 변수의 낮은 변동성으로 인하여 생물화학적 산소요구량에 비해 유량 예측의 정확도가 다소 높은 것으로 평가되었다. 기존모델의 모든 은닉층을 사용한 전이학습 기법을 두 가지 벤치마크 알고리즘에 적용한 결과 두 알고리즘 모두 유량에 한정하여 예측 성능이 다소 향상되는 것으로 조사되었다. 또한, 다른 전이학습 기법을 사용한 경우에도 벤치마크 알고리즘의 예측 정확도에는 큰 변화가 없는 것으로 평가되었다. 전이학습의 잠재적인 활용 방안으로는 데이터부족으로 인해 심증학습 기반의 신규 예측 모델 개발이 어려운 타겟 도메인에 (소스 도메인에서 개발된) 기존 모델의 신속한 재사용이 포함될 수 있을 것으로 판단된다.""","""This study assessed the feasibility of transfer learning from one wastewater treatment process to another using two popular deep learning algorithms. Specifically, convolutional neural network (CNN) and long short-term memory (LSTM), which consisted of four and three hidden layers, respectively, were used as benchmark algorithms for transfer learning. Input data for both deep learning and transfer learning were provided from two wastewater treatment plants with identical treatment trains in series (located in Jinju and Cheongju City) over the five-year period from 2018 to 2022. Performance evaluation was also done not only against two deep learning algorithms but also against those adopting two transfer learning strategies, one for freezing all hidden layers developed from the pre-trained model and the other for training the last hidden layer only among multiple ones, with respect to Mean Squared Error (MSE). We found that the performance of both CNN and LSTM was relatively comparative regardless of dependent variables, discharge and biochemical oxygen demand (BOD), whereas the prediction accuracy of both algorithms was slightly higher for discharge than for BOD due to its low variability. When transfer learning which froze all hidden layers of the existing model was applied to two benchmark algorithms, the predictive performance of both algorithms was found to slightly improved only for discharge. Also, there was no measurable variation in the prediction accuracy of benchmark algorithms using the other transfer learning approach.Potential applications of transfer learning include the rapid reuse of the existing models (developed from source domains) for target domains which are hard to develop new prediction models due to the lack of data in deep learning."""
EfficientNetV2S를 활용한 한국어 손글씨 성별 분류: 글자 수와 연령대별 성능 분석,2024,"['손글씨', '성별', '합성곱 신경망', 'EfficientNetV2S', '정확도', '연령', '글자 수', 'Handwriting', 'Gender', 'Convolutional Neural Network', 'EfficientNetV2S', 'Accuracy', 'Age', 'Character Count']","기존의 글씨체 성별 분류 연구는 전통적인 합성곱 신경망 모델, 앙상블 학습 기법, 그리고 DenseNet201과 같은 심층 합성곱 신경망을 활용했다. 기존의 방법에서 연산 효율성과 성능의 최적화 문제가 있었고, 이를 극복하기 위해 EfficientNetV2S 모델을 활용한 새로운 접근 방식을 제안한다. 제안된 방법은 손글씨 데이터를 전처리한 후, EfficientNetV2S 모델과 SAM 옵티마이저, 학습 스케줄러를 적용하여 글씨체로 성별을 분류하는 것이다. 전처리 과정에서는 이미지를 회색조로 변환하고 Otsu's 방법을 통해 이진화하여 단어 객체만을 추출한 후, 글자 수마다 지정된 크기로 이미지를 정규화하였다. 본 논문에서는 20대 데이터 셋에서의 글자 수에 따른 성별 분류 정확도를 비교하였고, 3글자 데이터 셋에서의 연령대에 따른 성별 분류 정확도를 비교하였다. 20대 데이터를 기반으로 글자 수별 성능을 평가한 결과, 3글자 단어에서 79.88%로 가장 높은 정확도를 기록했다. 이어서 10대부터 50대까지의 연령대별 성별 분류 실험에서 30대까지 분류 성능이 향상하여 97.29%의 정확도를 보였으나, 40대와 50대에서는 다소 감소하는 경향이 나타났다. 본 논문에서 제안한 방법은 기존 연구보다 더 높은 정확도로 성별을 분류할 수 있음을 증명하였으며, 문서 작성자 추정에서 보조 자료로 활용될 수 있다.","Existing studies on handwriting-based gender classification have utilized traditional convolutional neural network models, ensemble learning techniques, and deep convolutional networks like DenseNet201. However, these methods have encountered computational efficiency and performance optimization challenges. This paper proposes a new approach using the EfficientNetV2S model to address these issues. The proposed method involves preprocessing handwritten data and applying the EfficientNetV2S model, SAM optimizer, and a learning scheduler to classify gender based on handwriting. In the preprocessing steps, images are converted to grayscale, binarized using Otsu's method to extract word objects, and then normalized to a specified size according to the number of characters. In this study, gender classification accuracy was compared based on character count using a dataset of individuals in their 20s and based on age groups using a dataset of three-character words. The results show that, for the 20s dataset, the highest accuracy of 79.88% was achieved with three-character words. Additionally, in gender classification experiments across age groups from teenagers to 50s, accuracy improved up to the 30s group, reaching 97.29%, but then showed a slight decline in the 40s and 50s groups. The method proposed in this paper shows that gender can be classified with better accuracy than in previous studies and can be used as supplementary data in author attribution analysis."
Edge 분석과 ROI 기법을 활용한 콘크리트 균열 분석 - Edge와 ROI를 적용한 콘크리트 균열 분석 및 검사 -,2024,"['CNN', 'Concrete Crack', 'ROI', 'Edge Segmentation', 'Manual Inspection', '합성곱 신경망', '콘크리트 균열', '관심영역', '에지 세그멘테이션', '수동 검사']","본 논문에서는 합성곱신경망과 ROI기법을 이용한 콘크리트 균열 분석에 관해 소개한다. 콘크리트 표면, 빔과 같은 구조물은 피로 응력, 주기 부하에 노출되며, 이는 일반적으로 구조물의 표면에서 미세한 수준에서 시작되는 균열을 야기한다. 구조물의 균열은 안정성을 저하시키고 구조물의 견고함을 감소시킨다. 조기 발견을 통해 손상 및 고장 가능성을 방지하기 위한 예방 조치를 취할 수 있다. 일반적으로 수동 검사 결과는 품질이 좋지 않고, 대규모 기반 시설의 경우 접근이 어려우며, 균열을 정확하게 감지하기 어렵다. 이러한 수동검사의 자동화는 기존 방식의 한계를 해결할 수 있기 때문에 컴퓨터 비전 기반의 연구들이 수행되었다. 하지만 다양한 유형의 균열이나, 열화상 카메라 등을 이용한 연구들은 부족한 상태이다. 따라서 본 연에서는 콘크리트 벽의 균열을 자동으로 감지하는 방법론을 개발하여 제시하며, 다음과 같은 연구 내용을 목표로 한다. 첫째, 균열 감지 이미지 기반 분석의 주요 장점인 이미지 처리 기술을 사용하여 기존의 수동 방법과 비교하여 정확도가 향상된 결과 및 정보를 제공한다. 둘째, 강화된 Sobel edge segmentation 기술 및 ROI 기법 기반의 알고리즘을 개발하여 비파괴 시험을 위한 자동 균열 감지 기술을 구현한다.","This paper presents the application of Convolutional Neural Networks (CNNs) and Region of Interest (ROI) techniques for concrete crack analysis. Surfaces of concrete structures, such as beams, etc., are exposed to fatigue stress and cyclic loads, typically resulting in the initiation of cracks at a microscopic level on the structure's surface. Early detection enables preventative measures to mitigate potential damage and failures. Conventional manual inspections often yield subpar results, especially for large-scale infrastructure where access is challenging and detecting cracks can be difficult. This paper presents data collection, edge segmentation and ROI techniques application, and analysis of concrete cracks using Convolutional Neural Networks. This paper aims to achieve the following objectives: Firstly, achieving improved accuracy in crack detection using image-based technology compared to traditional manual inspection methods. Secondly, developing an algorithm that utilizes enhanced Sobel edge segmentation and ROI techniques. The algorithm provides automated crack detection capabilities for non-destructive testing."
경량화 U-Net을 사용한 엣지 디바이스용 미세플라스틱 이미지 분할,2024,"['미세플라스틱', '이미지 분할', '경량화', '인공신경망', 'U-Net', 'depthwise separable 합성곱', 'microplastic', 'image segmentation', 'lightweighting', 'U-Net', 'depthwise separable convolution']","해양 생태계에 부적절한 영향을 끼치는 미세플라스틱을 검출하여 배출되는 양을 줄이는 작업이 필요하다. 미세플라스틱은 현미경 이미지 분할 딥러닝 모델을 적용해 검출할 수 있는데, 정확도를 높이기 위해서는 데이터의 다운샘플링을 지양하는 것이 중요하다. 하지만, 이를 위해서는 일반적으로 모델의 파라미터 및 연산량이 증가하는 문제가 있어 휴대형 장치에 실시간으로 동작하기 어렵다. 따라서 딥러닝 모델을 휴대형 장치를 사용해 현장에서 채취한 시료로부터 즉각 미세플라스틱을 검출하는 과정에는 적용하기 위해서는 데이터의 해상도를 유지하되 경량화 된 모델이 필요하다. 모델 경량화 실험을 위해서 이미지 분할 분야의 대표적인 모델인 U-Net의 합성곱 계층에 기존의 다양한 경량화 방법을 적용하여 U-Net과의 성능을 비교하였다. Depthwise Separable 합성곱 계층을 사용한 경우 U-Net에 비하여 유사한 mIoU 성능을 보이며, 82.6% 감소된 연산량을 보였다. 또 행렬 분해 및 Group 합성곱을 적용한 경우는 U-Net에 비해 7.41%의 mIoU 성능 하락이 있었지만, 99.55% 감소된 연산량을 보인다. 이는 현장에서 즉각적으로 데이터를 취득해야 하는 휴대형 장치에 적용해 이점을 얻을 수 있을 것으로 생각된다.","There is a need to detect microplastics that adversely affect marine ecosystems and reduce their emissions. Microplastics can be detected by applying deep learning models to segment microscopic images. While it is important to avoid downsampling the data to improve accuracy, this usually requires an increase in model parameters and computation, making it difficult to operate in real-time on mobile devices. Therefore, to apply deep learning models to the process of instant microplastic detection from samplescollected in the field using mobile devices, a lightweight model is required while maintaining the resolution of the data. For the model lightweight experiment, we applied various existing lightweight methods to the convolution layer of U-Net, a representative model in the image segmentation field, and compared its performance with U-Net. The Depthwise Separable convolution layer shows mIoU performance that is comparable to that of U-Net, with 82.6% less computation. In addition, the Matrix Factorization and Group convolution layers show 99.55% less computation, although there is a 7.41% mIoU performance drop compared to U-Net. This is thought to be beneficial for mobile devices that require immediate data acquisition in the field."
처리성능 최적화를 위한 생성형 인공지능 이미지 판별 방안,2024,"['생성형 인공지능', '생성된 합성 이미지 분류', '합성곱신경망', '하이퍼 파라미터 튜닝', 'Generative AI', 'Generative Image Classification', 'Convolutional Neural Network', 'Hyperparameter Optimization']","생성형 인공지능의 등장으로 실제 이미지와 합성 이미지의 조작 여부를 판별하기 어려워졌다. 이러한 문제를 해결하기 위해 본 논문에서는 실제 임베디드 환경에서 실제 이미지와 생성형 인공지능이 생성한 합성 이미지를 효율적으로 판별하는 기술을 제안한다. 제안된 방법은 기존 CNN 구조에 하이퍼 파라미터 튜닝을 통해 모델의 이미지 처리 성능 최적화를 진행하였다. 또한 모델의 경량화를 진행해 본 논문의 지향점인 최소한의 파라미터로 최고의 성능을 달성하는 것을 목표로 모델을 설계하였다. 제안된 모델은 입력 영상에서 특징을 추출하는 CNN 계층, 영상의 크기를 줄이면서 주요 특징을 유지하는 Max Pooling, 마지막으로 최종 예측 값을 수행하는 Dense 계층으로 구성되어 있으며, 여기에 하이퍼 파라미터 튜닝을 통해 모델의 처리 성능 및 최적화를 진행하였다. 제안된 모델의 정량적 평가를 위해 제한된 환경인 임베디드 보드에서 실험을 진행한 결과, 제안된 모델은 비교 평가를 위해 선정한 모델들인 EfficientNetB0, ViT(Vision Transformer)과 유사한 정확도를 보유하면서 처리 성능 측면에서 다른 모델들에 비해 Model load time 및 Inference time이 더 효율적인 것을 확인할 수 있었다.","With the advent of generative artificial intelligence, it has become difficult to determine whether real and synthetic images are manipulated. To solve this problem, this paper proposes a technology to efficiently classifying between real images and synthetic images generated by generative artificial intelligence in a real embedded environment. The proposed method optimized the image processing performance of the model through hyperparameter tuning to the existing CNN structure. In addition, the model was designed with the aim of achieving the best performance with minimal parameters, which is the goal of this paper by proceeding with the weight reduction of the model. The proposed model is a CNN layer that extracts features from the input image, reducing the size of the image while reducing the main features It consists of the maintaining Max Pooling, and finally, the Dense layer that performs the final prediction value, and the processing performance and optimization of the model were carried out through hyperparameter tuning. As a result of conducting experiments on an embedded board, which is a limited environment for the quantitative evaluation of the proposed model, it was confirmed that the proposed model load time and inference time were more efficient than other models in terms of processing performance while having similar accuracy to the models selected for comparative evaluation, EfficientNetB0 and ViT (Vision Transformer)."
광산배수 처리를 위한 기계학습 기반 소석회 투입량 예측 연구,2024,"['예측', '기계학습', '광산배수', '처리', '합성곱 신경망', 'prediction', 'machine learning', 'mine drainage', 'treatment', 'convolutional neural network']","본 연구는 광산배수 처리시설의 효율적 설계와 운영을 위해 기계학습(ML) 기법으로 광산배수 처리시설(ST와 HT)의 소석회 투입량을 예측하였다. 처리시설 원본 자료에서 이상치를 제거한 후, 소석회 투입량과 관계가 있는 유량, 그리고 소석회에 의해 공급된 OH‒와 상당히 관계가 있는 금속이온(Fe, Mn, Al) 농도와 pH를 입력자료로 선정하였다. 합성곱 신경망(CNN) 모델이 사용되었고, 원본 자료의 제한적이고 불균형적인 자료의 문제를 보완하면서 원본 자료 특성을 유지하기 위해fancy 주성분 분석(PCA)를 이용한 자료증대 기법이 사용되었다. ML 모델에 의해 예측된 테스트자료 세트의 소석회 투입량은 이론적 계산식보다 평균 절대 오차(MAE)는 낮고 결정계수(R2)는 높았다. 기계학습 기법의 사용으로 처리시설의 운영효율 증가 및 신규 시설에의 기본 설계자료 제공이 기대된다.","In this study, we predicted the lime dosage for treatment facilities (ST and HT) using machine learning (ML) to effectively design and operate mine drainage treatment facilities. After removing the bad data from the original data, the flow rate related to the lime dosage, and metal ion (Fe, Mn, Al) concentrations and the pH which are highly related to OH‒ supplied by lime, were selected as inputs.The convolutional neural network was used, and the data was augmented using fancy principal component analysis to compensate for the limited and imbalanced dataset while maintaining the characteristics of the original data. The test dataset prediction by the ML model demonstrated a lower mean absolute error and higher coefficient of determination (R2) than that of the theoretical calculation equation. The ML application is expected to enhance operational effectiveness of treatment facilities and offer fundamental design data for new facilities."
Merged CNN 기반 유한요소모델 업데이트 방법론,2024,"['유한요소 모델 업데이팅', '딥러닝', '합성곱 신경망', '진동모드형상', '고유진동수', 'Finite Element Model Updating', 'Deep Learning', 'Convolutional Neural Network', 'Vibration Mode Shape', 'Natural Frequency']","구조물의 유지관리에 있어서 구조물의 현재 상태가 반영된 정교한 유한요소해석모델(FEA)이 요구되는 경우가 많다. 현재 구조물의 특성이 정교하게 반영된 유한요소해석 모델을 구축하기 위해 대상 구조물의 다양한 재료 및 기하학적 물성이 반영되어야 하는데, 설계 시 고려된 물성치와 시공된 시점에서의 값 그리고 현재 시점의 값 간에는 차이가 존재하기 때문에 일반적으로는 대상 구조물의 실측 데이터를 활용하여 해석모델의 업데이트를 수행한다. 이 때 실측치와 해석치의 비교를 통한 오차 최소화를 목적으로 반복적인 업데이트 작업을 수행하게 되며 이에 따라 많은 시간이 소요되는 경우가 다수이다. 본 연구에서는 인공신경망을 활용한 효과적인 모델 업데이트 방법에 대해 연구하였다. 본 연구에서는 대상 구조물의 고유진동수 및 모드형상 등의 구조의 모달 정보를 활용하여 유한요소 모델의 매개변수를 직접 추정하는 접근 방식을 제안한다. 다양한 변수 간의 복잡한 상관관계를 분석하는 데 효과적인 심층 신경망(DNN)과 진동 모드 간의 관계성을 반영할 수 있는 합성곱 신경망(CNN)을 통합한 알고리즘을 활용하였다. 휨부재에 대한 검증을 통해 제안한 방법론이 높은 정확도로 목표 모달 정보에 부합하도록 유한요소해석 모델을 업데이트할 수 있음을 확인하였다.","Finite element analysis requires the construction of a model that accurately reflects the structural characteristics of a target structure. Such models must incorporate precise material and geometric properties. However, discrepancies often arise between the properties assumed during the design phase and those observed in the actual structure. To address this, the models are iteratively updated using real measurement data, minimizing the errors between measured and analytical results. This process, however, can be time-consuming, particularly for complex structures. In this study, we propose a novel approach to directly estimate the parameters of a finite element model by utilizing the modal information from the structure, including natural frequencies and mode shapes. Our algorithm integrates a deep neural network that effectively solves complex problems using a convolutional neural network that captures the relationships between the nodal data and modes. Verification using a beam model demonstrated that the proposed methodology successfully updated the finite element analysis model to accurately match the target modal information."
부분  신장  절제술  계획을  위한  하이브리드 CNN-트랜스포머  네트워크를  활용한  신장  종양  분할,2024,"['신장  종양  분할', 'CT  영상', '하이브리드  네트워크', '합성곱  신경망', '트랜스포머', 'Kidney Tumor  Segmentation', 'CT  Image', 'Hybrid  Network', 'Convolutional Neural Network', 'Transformer']","신장암 치료를 위한 부분 신장 절제술에서 수술 계획을 위한 신장 종양의 정확한 크기와 위치 등의 정보가 필수적이다. 따라서 신장 종양을 정확하게 분할하는 것이 중요하지만, 종양이 주변 장기와 밝기값이 유사하고 위치 및 크기가 환자마다 다양하여 분할에 어려움이 있다. 본 연구에서는 신장 종양의 분할 성능 개선을 목표로, 영상 내 지역적 및 전역적 특징을 모두 고려할 수 있는 합성곱 신경망과 트랜스포머가 결합된 하이브리드 네트워크를 제안한다. 제안 방법은 UNETR++와의 비교 실험에서 다이스 유사계수 78.54%,  정밀도 85.07%로 전반적으로 우수한 성능을 보였다. 또한, 종양 크기별 분석에서는 UNETR++에서 관찰되는 과대 분할 및 이상치가 개선된 결과를 보였다.","In partial  nephrectomy  for  kidney  cancer  treatment, accurate  segmentation of  the  kidney tumor  is  crucial  for  surgical  plannin g,  as it provides essential information on  the  precise size  and  location of  the  tumor.  However,  it is challenging  due to the tumor’s similar intensity to surrounding  organs and  the  variability in its  location and size  across  patients. In  this  study,  we propose  a hybrid network that integrates  a convolutional neural  network and  a transformer  to  capture  both local  and  global features,  aiming  to  improve  the  segmentation performance of  kidney tumors.  We validated our  method  through comparative experiments with UNETR++,  outperforming it with a Dice Similarity Coefficient  (DSC)  of 78.54% and  a precision  of  85.0 7%.  Moreover, in  the  analysis  by  tumor size, our  method  demonstrated  improvements  by  reducing  over-segmentation and ou tlier cases  observed  in  UNETR++."
캐스케이드 융합 기반 다중 스케일 열화상 향상 기법,2024,"['열화상 이미지', '적외선 이미지', '이미지 향상', '합성곱 신경망', '특징 융합', 'Thermal Image', 'Infrared Image', 'Image Enhancement', 'Convolutional Neural Networks', 'Feature Fusion']","본 연구는 다양한 스케일 조건에서 열화상 이미지를 향상시키기 위한 새로운 캐스케이드 융합 구조를 제안한다. 특정 스케일에 맞춰 설계된 방법들은 다중 스케일에서 열화상 이미지 처리에 한계가 있었다. 이를 극복하기 위해 본 논문에서는 다중 스케일 표현을 활용하는 캐스케이드 특징 융합 기법에 기반한 통합 프레임워크를 제시한다. 서로 다른 스케일의 신뢰도 맵을 순차적으로 융합함으로써 스케일에 제약받지 않는 학습이 가능해진다. 제안된 구조는 상호 스케일 의존성을 강화하기 위해 엔드 투 엔드 방식으로 훈련된 합성곱 신경망으로 구성되어 있다. 실험 결과, 제안된 방법은 기존의 다중 스케일 열화상 이미지 향상 방법들보다 우수한 성능을 보인다는 것을 확인할 수 있었다. 또한, 실험 데이터셋에 대한 성능 분석 결과 이미지 품질 지표가 일관되게 개선되었으며, 이는 캐스케이드 융합 설계가 스케일 간 견고한 일반화를 가능하게 하고 교차 스케일 표현 학습을 더 효율적으로 수행하는 데 기여하는 것을 보여준다.","This study introduces a novel cascade fusion architecture aimed at enhancing thermal images across various scale conditions. The processing of thermal images at multiple scales has been challenging due to the limitations of existing methods that are designed for specific scales. To overcome these limitations, this paper proposes a unified framework that utilizes cascade feature fusion to effectively learn multi-scale representations. Confidence maps from different image scales are fused in a cascaded manner, enabling scale-invariant learning. The architecture comprises end-to-end trained convolutional neural networks to enhance image quality by reinforcing mutual scale dependencies. Experimental results indicate that the proposed technique outperforms existing methods in multi-scale thermal image enhancement. Performance evaluation results are provided, demonstrating consistent improvements in image quality metrics. The cascade fusion design facilitates robust generalization across scales and efficient learning of cross-scale representations."
CNN을 활용한 M-PSK변조 기반 무선 광통신 시스템에서의 Log-Normal 모델과 Gamma-Gamma 모델의 대기 난류 채널 분류 성능 비교,2024,"['무선 광통신', '대기 난류', '채널 분류', '합성곱 신경망 (CNN)', 'PSK 변조', 'Wireless Optical Communication', 'Atmospheric Turbulence', 'Channel Classification', 'Convolutional Neural Network (CNN)', 'PSK Modulation']","본 논문은 서로 다른 위상 천이 변조(phase shift keying, PSK) 방식을 사용하는 무선 광통신 시스템에서 합성곱 신경망 (convolutional neural network, CNN)에 기반하여 대기 난류 채널의 분류 성능을 비교한다. 대기 난류는 무선 광통신 시스템의 성능 저하를 야기하는 주요 요인 중 하나로, 난류 강도에 따라 약한 난류, 중간 난류, 강한 난류로 구분된다. 본 연구는 PSK 변조 방식을 적용한 무선 광통신 시스템을 대상으로, 수신 신호의 성상도 (constellation diagram)를 입력으로 하는 CNN 모델을 이용하여 난류 채널을 분류하고, 분류 정확도를 비교한다. 약한 난류 채널을 Log-Normal (L-N) 난류 모델과 Gamma-Gamma (G-G) 난류 모델로 모델링하였으며, 중간 난류와 강한 난류는 G-G 난류모델로부터 파라미터를 조절하여 모델링한다. 각 난류 강도에 따른 데이터셋을 생성하여 CNN 모델을 학습하였다. PSK 변조 방식들에 대해 제안된 CNN 모델의 분류 정확도를 비교함으로써, 성상도 기반 CNN 채널 분류 기법이 PSK 변조 방식에 적용 가능함을 보여준다.","This paper compares the classification performance of atmospheric turbulence channels based on convolutional neural networks (CNNs) in wireless optical communication systems employing different phase shift keying (PSK) modulation schemes. Atmospheric turbulence is one of the primary factors causing performance degradation in wireless optical communication systems, and it is classified into weak, moderate, and strong turbulence based on the intensity. This study focuses on classifying turbulence channels in PSK modulated wireless optical communication systems using a CNN model that takes constellation diagrams of received signals as input and compares the classification accuracy. Weak turbulence channels are modeled using both the Log-Normal (L-N) turbulence model and the Gamma-Gamma (G-G) turbulence model, while moderate and strong turbulence are modeled by adjusting the parameters of the G-G turbulence model. The CNN model is trained using data sets generated for each turbulence intensity. By comparing the classification accuracy of the proposed CNN model across various PSK modulation schemes, the study demonstrates that the constellation diagram-based CNN channel classification technique can be applied to PSK modulation schemes."
스펙트로그램을 이용한 CNN 음성인식 모델,2024,"['음성 인식', '심층 학습', '스펙트로그램', '단구간 푸리에 변환', '합성곱 신경망', 'Speech Recognition', 'Deep Learning', 'Spectrogram', 'Short Time Fourier Transform', 'Convolutional Neural Network']","본 논문에서는 명령어 음성신호의 인식 성능을 개선하기 위한 새로운 합성곱 신경망(CNN: Convolutional Neural Network) 모델을 제안한다. 이 방법은 입력신호의 단구간 푸리에 변환(STFT: Short-Time Fourier Transform) 후 스펙트로그램 이미지를 구하고 CNN 모델을 이용한 지도학습을 통하여 명령어 인식 성능을 개선하였다. 입력신호를 단시간 구간별로 푸리에 변환한 다음 스펙트로그램 이미지를 구하고 CNN 딥러닝 모델을 이용하여 다중 분류 학습을 수행한다. 이는 시간영역 음성신호를 특성이 잘 표현되도록 주파수영역으로 변환하고 변환 파라미터에 대한 스펙트로그램 이미지를 이용하여 딥러닝 훈련을 수행함으로써 명령어를 효과적으로 분류한다. 본 연구에서 제안한 음성인식시스템의 성능을 검증하기 위하여 Tensorflow와 Keras 라이브러리를 사용한 시뮬레이션 프로그램을 작성하고 모의실험을 수행하였다. 실험 결과, 제안한 심층학습 알고리즘을 이용하면 92.5%의 정확도를 얻을 수 있는 것으로 확인되었다.","In this paper, we propose a new CNN model to improve the recognition performance of command voice signals. This method obtains a spectrogram image after performing a short-time Fourier transform (STFT) of the input signal and improves command recognition performance through supervised learning using a CNN model. After Fourier transforming the input signal for each short-time section, a spectrogram image is obtained and multi-classification learning is performed using a CNN deep learning model. This effectively classifies commands by converting the time domain voice signal to the frequency domain to express the characteristics well and performing deep learning training using the spectrogram image for the conversion parameters. To verify the performance of the speech recognition system proposed in this study, a simulation program using Tensorflow and Keras libraries was created and a simulation experiment was performed. As a result of the experiment, it was confirmed that an accuracy of 92.5% could be obtained using the proposed deep learning algorithm."
단일 리드 심전도 데이터를 이용한 심혈관 질환 예측,2024,"['cardiovascular disease', 'electrocardiogram', 'convolutional neural network', 'wearable healthcare device', '심혈관 질환', '심전도', '합성곱 신경망', '웨어러블 헬스케어 기기']","혈관 질환을 진단하는 가장 대표적인 방법은 심전도 데이터를 분석하는 것이며, 병원에서 측정하는 심전도 데이터는 대부분 12개의 리드로 구성되어 있다. 하지만, 웨어러블 헬스케어 기기에서는 일반적으로 1개의 리드만 측정되며, 심혈관 질환을 진단하는 데에도 한계가 있다. 따라서 본 논문에서는 웨어러블 헬스케어 기기로 측정 가능한 단일 리드를 사용하여 흔히 발생하는 심혈관 질환인 심방세동, 좌각차단, 우각차단을 예측하는 연구를 진행하였다. 합성곱 신경망 모델을 기반으로 질환을 예측하였으며 AUC, F1-score를 통해 성능을 측정 및 비교한 결과, 심방세동, 좌각차단, 우각차단의 예측 평균 AUC가 각각 0.966, 0.971, 0.965, F1-score가 각각 0.867, 0.816, 0.848로 우수한 성능을 보이는 것을 확인하였다. 이를 통해 웨어러블 헬스케어 기기에서 획득 가능한 단일 리드만을 활용한 심혈관 질환의 진단 가능성을 확인할 수 있었다.","The most representative approach to diagnosing cardiovascular disease is to analyze electrocardiogram (ECG), and most ECG data measured in hospitals consist of 12 leads. However, wearable healthcare devices usually measure only single-lead ECG, which has limitations in diagnosing cardiovascular disease. Therefore, in this paper, we conducted a study to predict common cardiovascular diseases such as atrial fibrillation (AF), left bundle branch block (LBBB), and right bundle branch block (RBBB) using a single lead that could be measured with a wearable healthcare device. For experiments, we used a convolutional neural network model and measured its performance using various leads in terms of AUC and F1-score. For AF, LBBB, and RBBB, average AUC values were 0.966, 0.971, and 0.965, respectively, and average F1-scores were 0.867, 0.816, and 0.848, respectively. These experimental results confirm the possibility of diagnosing cardiovascular disease using only a single lead ECG that can be obtained with wearable healthcare devices."
그래프 동형 모델을 이용한 탈수소화 엔탈피 예측,2024,"['dehydrogenation enthalpy', 'graph isomorphism network', 'molecular embedding', '탈수소화 엔탈피', '그래프 동형 모델', '분자 임베딩']","본 논문은 분자의 구조 정보를 이용하는 기존의 물성 예측 접근에 그래프 합성곱 신경망 모델을 병합하여 분자 임베딩을 생성, 이상적인 액상유기수소운반체 선정에 중요한 역할을 하는 탈수소화 엔탈피를 예측하는 연구를 소개한다. 제안하는 방법은 그래프 합성곱 모델 중 가장 좋은 표현력을 가진 것으로 알려진 그래프 동형 모델(Graph Isomorphism Network)을 사용했으며, 해당 모델을 통해 개별 분자를 구성하는 원자 정보를 바탕으로 분자 임베딩을 생성했을 때, 기존의 물리화학(chemical physics) 이론에 기반한 알고리즘에 비해 탈수소화 엔탈피를 예측하는데 더 적합한 임베딩을 생성할 수 있음을 관찰하였다. 또한 생략 연결 (skip connection)을 사용하여 깊은 그래프 합성곱 층을 구성할 수 있으며, 작은 배치 사이즈로 모델을 학습할 때 모델의 성능이 증가하는 경향성을 관찰한 내용을 보고한다.","This paper conducts dehydrogenation enthalpy prediction that could play an important role in selecting optimal liquid organic hydrogen carriers. We employed graph convolutional networks, which produced molecular embeddings for the prediction. Specifically, we adopted Graph Isomorphism Network (GIN) known to be the most expressive graph-based representation learning model. Our proposed approach could build molecular embeddings. Our proposed approach outperformed conventional machine learning solutions and traditional representations based on chemical physics algorithms. In addition, the performance of the proposed model could be improved with small batch sizes and deeper GCN layers using skip connections."
실시간 측정데이터 기반의 디스크커터 마모상태 판별 딥러닝 알고리즘 개발,2024,"['Disc cutter wear', 'Deep learning', 'CNN', 'Utility cable tunnel', 'Shield TBM', '디스크커터 마모', '딥러닝 기법', '합성곱신경망', '전력구 터널', '쉴드TBM']","송전선로 지중화 사업의 일환인 전력구 터널은 쉴드TBM 공법에 의해 건설된다. 쉴드TBM 구성요소 중 디스크커터는 암반을 파쇄하는 중요한 역할을 수행한다. 마모한계에 도달하거나 편마모와 같은 파손이 발생함에 따라 적절한 교체가 이루어져야 효율적인 터널 공사가 가능하다. 본 연구에서는 실시간으로 측정된 디스크커터의 마모량과 회전수를 기반으로 디스크커터의 마모상태를 판별하기 위한 딥러닝 알고리즘 개발을 수행하였다. 실대형 굴진시험 결과를 통해 디스크 커터의 마모상태에 따라 측정데이터가 상이하게 획득되는 것을 확인하였다. 합성곱신경망 모델을 기반으로 실시간 측정 데이터를 활용하여 디스크커터의 마모특성을 판별할 수 있는 알고리즘을 개발하였다. 합성곱신경망의 필터를 통해 데이터의 분포 특성을 학습할 수 있고, 이러한 패턴 특징을 통해 균등마모와 편마모를 분류할 수 있는 모델의 성능을 확인하였다.","The power cable tunnels which are part of the underground transmission line project, are constructed using the shield TBM method. The disc cutter among the shield TBM components plays an important role in breaking rock mass. Efficient tunnel construction is possible only when appropriate replacement occurs as the wear limit is reached or damage such as uneven wear occurs. A study was conducted to determine the wear conditions of disc cutter using a deep learning algorithm based on real-time measurement data of wear and rotation speed. Based on the results of full-scaled tunnelling tests, it was confirmed that measurement data was obtained differently depending on the wear conditions of disc cutter. Using real-time measurement data, an algorithm was developed to determine disc cutter wear characteristics based on a convolutional neural network model. Distributional patterns of data can be learned through CNN filters, and the performance of the model that can classify uniform wear and uneven wear through these pattern features."
비트맵 데이터 학습을 통한 딥러닝 기반의 메모리 수리 예측 기술 연구,2024,"['Memory Devices', 'RA Algorithm', 'Deep Learning', 'Convolutional Neural Networks', 'Electrical Die Sorting', '반도체 메모리', 'RA 알고리즘', '딥러닝', '합성곱 신경망(CNN)', '전기적 다이 분류']","반도체 메모리 기술의 지속적인 발전은 메모리 칩의 저장 용량을 크게 증가시켰지만, 동시에 제조 및 테스트 비용 증가, 소형화 및 고집적화로 인한 결함 발생 확률 증가와 같은 여러 문제를 초래했다. 이러한 문제를 효과적으로 해결하기 위해, 전기 다이 분류(EDS) 공정에서는 불량 셀을 예비 셀로 대체하는 RA(Redundancy Analysis) 알고리즘을 사용한다. 그러나 기존의 C 언어 기반 RA 프로세스는 칩의 복잡성이 증가함에 따라 테스트 시간이 길어지고 비용이 증가하는 단점이 있다. 본 논문에서는 이러한 한계를 극복하고자, 과거 수리 데이터를 기반으로 합성곱 신경망(CNN)을 활용해 실패 비트맵을 학습하는 딥러닝 기반 수리 예측 모델을 제시하고, RA 알고리즘의 딥러닝 적용 가능성을 확인하였다.","The continuous advancement of semiconductor memory technology has significantly increased memory chip capacity but has also introduced new challenges, including higher manufacturing and testing costs and a greater likelihood of defects due to miniaturization and high integration. To address these challenges, the Electrical Die Sorting (EDS) process employs a Redundancy Analysis (RA) algorithm to replace faulty cells with spare ones. However, as chip complexity increases, the traditional RA process, based on C language, becomes less efficient, resulting in longer testing times and higher costs. This paper proposes a deep learning-based repair prediction model that utilizes convolutional neural networks (CNN) to learn from historical repair data and failure bitmaps, thereby improving the efficiency of the RA process. The study confirms the applicability of deep learning to RA algorithms, demonstrating its potential to overcome the limitations of traditional methods."
딥 뉴럴 네트워크를 활용한 강우 나우캐스팅의 최신 동향과 한계 극복을 위한 향후 과제,2024,"['Nowcasting', 'Deep neural networks', 'Convolutional neural networks', 'Recurrent neural networks', 'Generative adversarial networks', 'Extreme rainfall', '나우캐스팅', '딥 뉴럴 네트워크', '합성곱 신경망', '순환 신경망', '생성적 적대 신경망', '극한 강우']","딥러닝 모델은 방대한 데이터를 활용하여 강우 시스템의 복잡한 시공간 패턴을 효과적으로 포착함으로써, 기존 수치예보(Numerical Weather Prediction, NWP) 모델과 레이더 에코 외삽법의 계산 속도 및 비선형 강수 동역학 처리의 한계를 보완하여 단기 강우 예측에서 뛰어난 성과를 보이고 있다. 이에 따라, 본 논문에서는 딥러닝 기반 강우 나우캐스팅 모델을 체계적으로 리뷰하고, 합성곱 신경망(Convolutional Neural Networks, CNN), 순환 신경망(Recurrent Neural Networks, RNN), 생성적 적대 신경망(Generative Adversarial Networks, GAN) 기반의 세 가지 주요 그룹으로 분류하여 분석하였다. 또한, 각 모델에서 나온 공통적인 한계점과 이들 문제를 해결하기 위한 전략을 심도 있게 조사하였다. 다양한 손실함수의 적용, 전이학습, 샘플링, 그리고 앙상블 모델의 활용과 같은 혁신적인 접근법이 모델 성능 개선에 미치는 영향을 논의하며, 이를 바탕으로 강우 나우캐스팅의 향후 연구 방향을 제시한다. 본 리뷰는 강우 나우캐스팅에 대한 딥러닝 기반 기술의 현재 상태를 이해하고, 향후 연구 및 기술 발전을 위한 지침을 제공하는 데 기여하고자 한다.","Deep learning models have demonstrated remarkable performance in short-term rainfall prediction by effectively capturing the complex spatiotemporal patterns of rainfall systems using vast datasets. This has helped to address the limitations of traditional Numerical Weather Prediction (NWP) models and radar echo extrapolation methods, such as computational speed and nonlinear precipitation dynamics. In this paper, we systematically review deep learning-based rainfall nowcasting models, categorizing them into three main groups: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs). We also conduct an in-depth analysis of the common limitations identified in these models and explore strategies to overcome them. Innovative approaches, such as the application of diverse loss functions, transfer learning, sampling techniques, and ensemble models, are discussed in terms of their impact on enhancing model performance. Based on these findings, we propose future research directions for rainfall nowcasting. This review aims to provide a comprehensive understanding of the current state of deep learning-based technologies for rainfall nowcasting and serve as a guide for future research and technological advancements in the field."
드론 식별을 위한 CNN 기반 이미지 분류 모델 성능 비교,2024,"['Drones', 'Transfer learning', 'Image classification', 'Convolutional Neural Networks', 'Aerial targets', '드론', '전이 학습', '이미지 분류', '합성곱 신경망', '공중표적']","최근 전장에서의 드론 활용이 정찰뿐만 아니라 화력 지원까지 확장됨에 따라, 드론을 조기에 자동으로 식별하는 기술의 중요성이 더욱 증가하고 있다. 본 연구에서는 드론과 크기 및 외형이 유사한 다른 공중 표적들인 새와 풍선을 구분할 수 있는 효과적인 이미지 분류 모델을 확인하기 위해, 인터넷에서 수집한 3,600장의 이미지 데이터셋을 사용하고, 세 가지 사전 학습된 합성곱 신경망 모델(VGG16, ResNet50, InceptionV3)의 특징 추출기능과 추가 분류기를 결합한 전이 학습 접근 방식을 채택하였다. 즉, 가장 우수한 모델을 확인하기 위해 세 가지 사전 학습된 모델(VGG16, ResNet50, InceptionV3)의 성능을 비교 분석하였으며, 실험 결과 InceptionV3 모델이 99.66%의 최고 정확도를 나타냄을 확인하였다. 본 연구는 기존의 합성곱 신경망 모델과 전이 학습을 활용하여 드론을 식별하는 새로운 시도로써, 드론 식별 기술의 발전에 크게 기여 할 것으로 기대된다.","Recent developments in the use of drones on battlefields, extending beyond reconnaissance to firepower support, have greatly increased the importance of technologies for early automatic drone identification. In this study, to identify an effective image classification model that can distinguish drones from other aerial targets of similar size and appearance, such as birds and balloons, we utilized a dataset of 3,600 images collected from the internet. We adopted a transfer learning approach that combines the feature extraction capabilities of three pre-trained convolutional neural network models (VGG16, ResNet50, InceptionV3) with an additional classifier. Specifically, we conducted a comparative analysis of the performance of these three pre-trained models to determine the most effective one. The results showed that the InceptionV3 model achieved the highest accuracy at 99.66%. This research represents a new endeavor in utilizing existing convolutional neural network models and transfer learning for drone identification, which is expected to make a significant contribution to the advancement of drone identification technologies."
인공지능(AI) 모델을 사용한 차나무 잎의 병해 분류,2024,"['artificial intelligence', 'Camellia sinensis', 'convolutional neural network', 'detection', 'leaf image', '인공 지능', 'Camellia sinensis', '합성곱 신경망', '탐색', '잎 이미지']","이 연구에서는 Inception V3, SqueezeNet(local), VGG-16, Painters 및 DeepLoc의 다섯 가지 인공지능(AI) 모델을 사용하여 차나무 잎의 병해를 분류하였다. 여덟 가지 이미지 카테고리를 사용하였는데, healthy, algal leaf spot, anthracnose, bird’s eye spot, brown blight, gray blight, red leaf spot, and white spot였다. 이 연구에서 사용한 소프트웨어는 데이터 시각적 프로그래밍을 위한 파이썬 라이브러리로 작동하는 Orange3였다. 이는 데이터를 시각적으로조작하여 분석하기 위한 워크플로를 생성하는 인터페이스를 통해 작동되었다. 각 AI 모델의 정확도로 최적의 AI 모델을 선택하였다. 모든 모델은 Adam 최적화, ReLU 활성화 함수, 은닉 레이어에 100개의 뉴런, 신경망의 최대 반복횟수가 200회, 그리고 0.0001 정규화를 사용하여 훈련되었다. Orange3 기능을 확장하기 위해 새로운 이미지 분석Add-on을 설치하였다. 훈련 모델에서는 이미지 가져오기(import image), 이미지 임베딩(image embedding), 신경망(neural network), 테스트 및 점수(test and score), 혼동 행렬(confusion matrix) 위젯이 사용되었으며, 예측에는 이미지 가져오기(import image), 이미지 임베딩(image embedding), 예측(prediction) 및 이미지 뷰어(image viewer) 위젯이 사용되었다. 다섯 AI 모델[Inception V3, SqueezeNet(로컬), VGG-16, Painters 및 DeepLoc]의 신경망 정밀도는 각각 0.807, 0.901, 0.780, 0.800 및 0.771이었다. 결론적으로 SqueezeNet(local) 모델이 차나무 잎 이미지를 사용하여 차병해 탐색을 위한 최적 AI 모델로 선택되었으며, 정확도와 혼동 행렬을 통해 뛰어난 성능을 보였다.","In this study, five artificial intelligence (AI) models: Inception v3, SqueezeNet (local), VGG-16, Painters, and DeepLoc were used to classify tea leaf diseases. Eight image categories were used: healthy, algal leaf spot, anthracnose, bird’s eye spot, brown blight, gray blight, red leaf spot, and white spot. Software used in this study was Orange 3 which functions as a Python library for visual programming, that operates through an interface that generates workflows to visually manipulate and analyze the data. The precision of each AI model was recorded to select the ideal AI model. All models were trained using the Adam solver, rectified linear unit activation function, 100 neurons in the hidden layers, 200 maximum number of iterations in the neural network, and 0.0001 regularizations. To extend the functionality of Orange 3, new add-ons can be installed and, this study image analytics add-on was newly added which is required for image analysis. For the training model, the import image, image embedding, neural network, test and score, and confusion matrix widgets were used, whereas the import images, image embedding, predictions, and image viewer widgets were used for the prediction. Precisions of the neural networks of the five AI models (Inception v3, SqueezeNet (local), VGG-16, Painters, and DeepLoc) were 0.807, 0.901, 0.780, 0.800, and 0.771, respectively. Finally, the SqueezeNet (local) model was selected as the optimal AI model for the detection of tea diseases using tea leaf images owing to its high precision and good performance throughout the confusion matrix."
비전 트랜스포머 모델 기반 한국인 얼굴 감정 분류 연구,2024,"['Computer Vision', 'Vision Transformer', 'Facial Expression Recognition', 'Emotion Classification', 'Fine-tuning']","인간의 표정은 기본적인 감정을 전달하는 표현 요소로써 인간과 컴퓨터 간의 상호작용에서 중요한 역할을 한다.컴퓨터 비전 및 머신러닝 분야에서는 최근 딥러닝을 기반으로 얼굴 표정을 기본 감정으로 분류하며, 그 중 합성곱 신경망(CNN: Convolution Neural Network) 기반의 모델이 주로 쓰이고 있다. 모델을 학습하는데 주로 쓰이는 데이터셋들은 다양한 인종이 섞여 있으며, 서양인의 얼굴 중심으로 이뤄져있다. 본 연구에서는 사전 학습된 비전 트랜스포머(ViT: Vision Transformer) 모델을 한국인의 얼굴 표정에 7가지 감정으로 라벨링되어 있는 데이터셋을 기반으로 파인튜닝한다. 모델에 입력하기 위해 데이터셋에서 제공되는 메타데이터에서 제공하는 얼굴의 좌표값을 활용하여 얼굴 부분을 크롭하고 총 70,000장의 이미지를 8:1:1의 비율로 분할하여 데이터셋을 재구성하였다. 학습된 한국인 얼굴 감정 분류 비전 트랜스포머는 전체 테스트 데이터셋에 대한 정확도 85.54 %를 기록하며 동일한 데이터셋을 사용한 합성곱 신경망 기반 모델에 비해 1.17 %의 성능 향상을 보였다. 다른 클래스들에 비해 낮은 성능을 보였던 불안, 슬픔을 나타내는클래스에 대해서도 성능을 개선하였다.","Facial expressions play an important role in human-computer interaction because they convey basic human emotions. In the field of computer vision and machine learning, deep learning has recently been used to classify facial expressions into basic emotions, with models based on convolutional neural networks being the most popular. Datasets that are mainly used to train the models are a mixture of various races, but mainly consist of Western faces. In this study, we fine-tune a pretrained vision transformer model based on a dataset of Korean facial expressions labeled with seven emotions. For input into the model, the dataset was reconstructed by cropping the faces using coordinates provided by the metadata in the dataset, splitting the 70,000 images at a ratio of 8:1:1. The trained Korean facial emotion classification vision transformer achieved 85.54% accuracy on the entire test dataset, showing a 1.17% performance improvement over a convolutional neural network model using the same dataset.We improved performance for classes representing anxiety and sadness, which had performed poorly compared to other classes."
경량 시간 세그먼트 네트워크를 이용한 비디오 장면 이해: 운전자 폭행 탐지에서의 검증,2024,"['시간 세그먼트 네트워크', '비디오 장면 이해', '이상 탐지', '운전자 폭행', 'temporal segment network', 'video scene understanding', 'anomaly detection', 'driver assault']","최근 택시와 버스 등 교통수단에서 탑승자가 운전자를 폭행하는 사건이 증가하는 추세로, 특히 늦은 밤 주취자에 의한 운전자 폭행 등에 대한 신속한 대응은 더욱 어려운 상황이다. 이러한 문제에 대응하기 위해, 본 연구팀은 탑승자에 의한 운전자 폭행 상황을 실시간으로 탐지할 수 있는 경량 합성곱 신경망 기반의 시간적 세그먼트 네트워크(TSN) 모델을 제안한다. TSN은 동영상을 효율적으로 처리하기 위해 소수의 이미지 프레임을 샘플링하며, 공간 정보처리 스트림과 시간 정보처리 스트림으로 나뉘어 학습이 진행된다. 각 스트림에는 합성곱 신경망이 들어가는데, 이 연구에서는 경량 신경망 아키텍처인 MobileOne 모델을 적용하여 모델 사이즈를 크게 줄였고, 제한된 컴퓨팅 리소스에서도 정확도는 오히려 개선됨을 보인다. 본 모델은 차량 내 운전자 모니터링 시스템에 통합되어 운전자에게 발생할 수 있는 위험한 상황에 대한 신속한 대응 및 예방에 기여할 수 있을 것으로 기대된다.","The number of driver assaults in transportation such as taxis and buses has been increasing over the past few years. It can be especially difficult to respond quickly to assaults on drivers by drunks late at night. To address this issue, our research team proposed a lightweight CNN-based Temporal Segment Network (TSN) model that could detect driver assaults by passengers in real time. The TSN model efficiently processes videos by sampling a small number of image frames and divides videos into two streams for learning: one for spatial information processing and the other for temporal information processing. Convolutional neural networks are employed in each stream. In this research, we applied a lightweight CNN architecture, MobileOne, significantly reducing the model size while demonstrating improved accuracy even with limited computing resources. The model is expected to contribute to rapid response and prevention of hazardous situations for drivers when it is integrated into vehicular driver monitoring systems."
매니폴드 데이터 증강기법 기반의 딥러닝 방법론을 적용한 축소 모델 개발,2024,"['manifold learning', 'model-order reduction', 'deep learning', 'data augmentation', '매니폴드 러닝', '모델 차수 축소', '딥러닝', '연산유체역학', '데이터 증강']","본 논문에서는 저 레이놀즈 수 영역에서 에어포일의 공기역학적 성능을 예측하기 위한 딥러닝 기반의 축소 모델을 제시하였다. 딥러닝 기반 축소 모델에서 CFD 해석 결과의 높은 차원의 데이터를 효율적으로 다루기 위해 변이형 오토인코더를 결합한 합성곱 신경망을 적용하였다. 부호화 거리 함수를 통해 에어포일의 형상과 유동 조건을 이미지 데이터화 하고, 이에 대해 합성곱 신경망을 매개변수화 하였다. 또한, 전산유체역학 해석의 계산 비용으로 인한 부족한 훈련 데이터를 극복하기 위해 투영 기반의 비선형 매니폴드 데이터 증강기법을 개발하였다. NACA 4계열 에어포일은 해석 예제로 고려하여 제안하는 프레임워크의 내삽과 외삽 정확도를 평가하였으며 매니폴드 데이터 증강기법을 적용하여 프레임워크의 정확도 향상을 확인하였다.","This study presents a deep learning-based framework to predict the aerodynamic performance of low Reynolds number airfoils. The framework employs a convolutional neural network (CNN) combined with a variational autoencoder (VAE) to efficiently handle large datasets. Moreover, the signed distance function is used as the network input to represent the airfoil configuration in the image data and parameterize the CNN. A novel generative model based on projection-based manifold learning is proposed to overcome the data mining limitation of computational fluid dynamics which may incur significant computational costs. The interpolation and extrapolation accuracy of the proposed framework is evaluated using the NACA 4-digit airfoil configuration.The results show improved accuracy via data augmentation performed by the proposed generative model."
CCTV 동영상에서 보행자 이상행동 이벤트 검출을 위한 딥러닝 기반 이상행동 이벤트 인식 방법,2024,"['Pedestrian Abnormal Behavior Recognition', 'CCTV Video Analysis', 'Pose Estimation', 'Object Detection', '2D CNN', 'LSTM', '3D CNN', '보행자 이상행동 인식', 'CCTV 동영상 분석', '포즈 예측', '객체 검출', '2D CNN', 'LSTM', '3D CNN']","CCTV의 설치가 증가하면서 모니터링 업무량이 크게 증가했다. 하지만, 단순히 인력을 늘리는 것만으로는 해결할 수 없는 한계에 부딪혔다. 이 문제를 해결하기 위해, 지능형 CCTV 기술이 개발되었으나, 이마저도 다양한 상황에서 성능 저하의 문제를 겪고 있다. 본 논문에서는 다양한 상황에 적용 가능하고 강건한 CCTV 동영상 통합 이상행동 인식 방법을 제안한다. 동영상으로부터 프레임 이미지를 추출하여 원시 이미지, 히트맵 표현 이미지 입력을 사용하며, 이미지 단계와 특징 벡터 단계에서의 병합 방식을 통해 특징 벡터를 추출하고, 이를 바탕으로 2차원 합성곱 신경망 모델과 3차원 합성곱 신경망 모델, 그리고 LSTM과 평균 풀링을 활용한 이상행동 인식 방법을 제안한다. 성능 검증을 위해 소분류 클래스를 정의하고 총 1,957개의 이상행동 동영상 클립 데이터를 생성하여 검증한다. 제안하는 방법은 CCTV 영상을 통한 이상행동 인식의 정확도를 향상시키며, 보안 및 감시 시스템의 효율성을 증대시킬 수 있을 것으로 기대한다.","With increasing CCTV installations, the workload for monitoring has significantly increased. However, a growing workforce has reached its limits in addressing this issue. To overcome this problem, intelligent CCTV technology has been developed. However, this technology experiences performance degradation in various situations. This paper proposes a robust and versatile method for integrated abnormal behavior recognition in CCTV footage that could be applied in multiple situations. This method could extract frame images from videos to use raw images and heatmap representation images as inputs. It could remove feature vectors through merging methods at both image and feature vector levels. Based on these vectors, we proposed an abnormal behavior recognition method utilizing 2D CNN models, 3D CNN models, LSTM, and Average Pooling. We defined minor classes for performance validation and generated 1,957 abnormal behavior video clips for testing. The proposed  method is expected to improve the accuracy of abnormal behavior recognition through CCTV footage, thereby enhancing the efficiency of security and surveillance systems."
Convolutional Neural Network을 이용한 액화 수소 밸브 설계 변수의 영향 예측,2024,"['합성곱 신경망', '전산유체해석', '유량계수', '액화수소', '니들밸브', 'Convolutional neural network', 'Computational fluid dynamics analysis', 'Flow coefficient', 'Liquified hydrogen', 'Needle valve']",,"Liquefied hydrogen is attracting attention as an energy source of the future due to its hydrogen storage rate and low risk. However, the disadvantage is that the unit price is high due to technical difficulties in production, transportation, and storage. This study was conducted to improve the design accuracy and development period of needle valves, which are important parts with a wide technical application range among liquefied hydrogen equipment. Since the needle valve must discharge an appropriate flow rate of the liquefied fluid, it is important to determine the needle valve design parameters suitable for the target flow rate. Computational Fluid Dynamics and Artificial Neural Network technology used to determine the design variables of fluid flow were applied to improve the setting and analysis time of the parameter. In addition, procedures and methods for applying the design parameter of needle valves to Convolutional Neural Networks were presented. The procedure and appropriate conditions for selecting parameters and functional conditions of the Convolutional Neural Network were presented, and the accuracy of predicting the flow coefficient according to the design parameter was secured 95%. It is judged that this method can be applied to other structures and machines."
영상 속 개인 비식별화 모델의 설계 및 구현,2024,"['합성곱 신경망', '객체 검출', '객체 추적', '비식별화', 'CNN', 'Object Detection', 'Object Tracking', 'De-identification']","본 논문에서는 영상 속 개인정보를 제거하는 개인 비식별화 구조를 제안하고, 객체 검출 알고리즘과 객체 추적 알고리즘을 연결하여 제안한 구조에 기반한 동영상 속 개인정보 제거가 가능한 개인 비식별화 시스템으로 구축하였다. 기존 알고리즘의 문제였던 작은 크기의 객체 검출이 더 잘 되도록 기존 모델의 구조를 수정하였고, 웹캠 등의 기기로부터 입력된 영상에 대해서도 검출 후 추적이 가능한 구조로 구축하였다. 객체 검출 및 객체 추적의 단순 연결에 비해 처리 속도 개선이 있었고, 작은 크기의 객체 검출 개선과 객체 검출의 손실값이 개선되는 결과를 보였다. 본 논문에서 제안한 알고리즘은 웹캠의 출력 영상을 입력으로 사용할 수 있으므로 학교 또는 보육시설 등과 같이 실시간성으로 개인정보가 제거된 동영상을 공개하는 작업이 요구되는 다양한 장소에서 활용될 수 있을 것으로 사료된다.","We propose a personal de-identification architecture that removes personal information in videos, and connect the object detection algorithm and object tracking algorithm to build a personal de-identification system that can remove personal information in videos based on the proposed architecture. We modified the existing model to better detect small-sized objects, and built a system that can detect and track people in images received from devices such as webcams. Comparing to the simple connection of object detection and object tracking, the processing speed was improved, and the results showed improvement in the detection of small objects and improvement in the loss value of object detection. Since the algorithm proposed in this paper can use the output video of a webcam as an input, it is expected to be utilized in various places where it is necessary to disclose de-personalized videos in real-time, such as schools or childcare centers."
문화유산 이미지의 질감과 색상 스타일 전이를 위한 알고리즘 개발 연구,2024,"['합성곱 신경망', '머신러닝', '스타일 변환', '표현학습']","스타일 전이 알고리즘은 현재 활발히 연구되는 분야로 일반 이미지를 고전 회화 스타일로 전이시키는 알고리즘도 개발되었다. 그러나 우리나라의 문화유산 이미지에 적용하였을 때 적절한 성과를 보이지 않으며, 적용 사례도 부족한 실정이다. 이에 본 연구에서는 우리나라 문화유산 스타일로 응용할 수 있는 스타일 전이 알고리즘을 개발하고자 한다. 이는 표현 학습을 통해 유의미한 특성을 학습하여 데이터에 대한 이해도를 높였으며, 대상 이미지 내에서 배경과 문화유산을 분리하고, 스타일 이미지에서 원하는 색상과 질감의 스타일 영역을 추출할 수 있게 제작하였다. 이를 통해 대상 이미지의 형태를 유지하면서 스타일 이미지의 특징을 효과적으로 전이하여 새로운 이미지를 생성할 수 있으며, 다양한 문화유산 스타일을 전이시킬 수 있음을 확인하였다.","Style transfer algorithms are currently undergoing active research and are used, for example, to convert ordinary images into classical painting styles. However, such algorithms have yet to produce appropriate results when applied to Korean cultural heritage images, while the number of cases for such applications also remains insufficient. Accordingly, this study attempts to develop a style transfer algorithm that can be applied to styles found among Korean cultural heritage. The algorithm was produced by improving data comprehension by enabling it to learn meaningful characteristics of the styles through representation learning and to separate the cultural heritage from the background in the target images, allowing it to extract the style-relevant areas with the desired color and texture from the style images. This study confirmed that, by doing so, a new image can be created by effectively transferring the characteristics of the style image while maintaining the form of the target image, which thereby enables the transfer of a variety of cultural heritage styles."
국가유산 보존을 위한 Computer Vision기반 CNN 알고리즘을 이용한 소유권 공유 시스템,2024,"['합성곱 신경망', '컴퓨터 비전', '이미지 인식', '크라우드 펀딩', '소유권 공유', '가치 예측', 'Convolutional Neural Network', 'Vision AI', 'Image Recognition', 'Crowd Funding', 'Shared Ownership', 'Value Prediction']","국내에서 국가유산은 보존할 만한 가치가 있는 문화유산 · 자연유산 · 무형유산을 뜻한다. 하지만 국가유산들의 값을 매기고 판매, 구매되는 거래의 문제, 소유권을 가지고 분쟁이 일어나는 소유권의 문제, 환수받지 못한 환수의 문제가 발생하고 있다. 본 논문에서는 CNN(:Convolutional Neural Network) 알고리즘을 활용하여 국가유산의 보존과 소유권 공유를 위한 시스템을 개발하고 그 성능을 분석한다. 이 시스템은 이미지 인식 기술과 크라우드 펀딩을 결합하여 문제점들을 해결할 수 있는 새로운 관리 방안을 제시한다. 이미지 인식 기술인 Vision AI를 활용하여 자동 감정 기능을 통해 국가유산의 가치를 신속하게 평가하며, 사용자가 국가유산의 지분을 공유하고 실시간으로 가치를 확인할 수 있다. 이를 통해 국가유산의 보존과 환수에 대한 혁신적인 접근 방식을 제공하고, 다수의 사용자가 국가유산 보호에 적극적으로 참여할 수 있는 시스템으로 구성하였다.","The term national heritage in Korea refers to cultural heritage, natural heritage, and intangible heritage that are deemed valuable for preservation. However, challenges arise related to the valuation, transaction, and ownership disputes of these heritage assets, as well as issues concerning their repatriation. This paper presents the development and performance analysis of a system designed for the preservation and ownership sharing of national heritage utilizing Convolutional Neural Network (CNN) algorithms. In this paper, we proposed system that integrates image recognition technology and crowdfunding to address these issues. By employing Vision AI for automated valuation, the system enables rapid assessment of national heritage values and allows users to share ownership and monitor real-time valuations. This approach offers an innovative solution for heritage preservation and repatriation, facilitating active participation form a broad user base in the protection of national heritage."
다변량 데이터 분석을 통한 효과적인 전력부하 예측 : Gas Carrier 사례 연구,2024,"['인공신경망(Artificial Neural Network)', '확장된 합성곱 신경망(Dilated CNN)', '가스 운반선(Gas Carrier)', '주성분분석(Principal Component Analysis)']",,
중환자실 도어 제어를 위한 MobileNetV2 기반의 실시간 마스크 감지 인공지능 알고리즘,2024,"['딥러닝', '합성곱 신경망', '마스크 인식', 'Deep learning', 'Convolutional neural network', 'Face mask recognition']",,"In this study, we proposed an AI-algorithm for face mask recognition based on the MobileNetV2 network to implement automatic door control in intensive care units. The proposed network was constructed using four bottleneck blocks, incorporating depth-wise separable convolution with channel expansion/projection to minimize computational costs. The performance of the proposed network was compared with other networks trained with an identical dataset. Our network demonstrated higher accuracy than other networks. It also had less trainable total parameters. Additionally, we employed the CVzone-based machine learning model to automatically detect face location. The neural network for mask recognition and the face detection model were integrated into a system for real-time door control using Arduino. Consequently, the proposed algorithm could automatically verify the wearing of masks upon entry to intensive care units, thereby preventing respiratory disease infections among patients and medical staff. The low computational cost and high accuracy of the proposed algorithm also provide excellent performance for real-time mask recognition in actual environments."
ConvIMage : IMU 시계열 데이터의 영상 신호 변환을 통한 CNN 기반 동작 추정 알고리즘 개발,2024,"['동작 추정', '합성곱신경망', '관성센서', '시계열데이터', '영상처리', 'Pose Estimation', 'CNN', 'IMU', 'Time-series data', 'Image processing']","자이로스코프와 카메라 센서를 통한 동작 인식 기법은 저전력 소모와 상호작용의 용의성 등의 이유로 다양한 산업 분야에 적용되고 있다. 하지만, 보정 방법에 따라 정확도가 떨어질 수 있고, 실시간 처리에 많은 연산량에 의한 지연 문제가 있다. 따라서 본 연구는 IMU 센서의 시계열 데이터를 이미지 데이터로 변환 후 CNN 알고리즘을 통해 학습하여 동작 추정을 수행하는 ConvIMage를 제안한다. ConvIMage는 IMU를 통해 수집한 시계열 데이터를 색상 채널로 변환하여 패턴 이미지를 구성하고, CNN 모델을 통해 각 동작에 대한 패턴을 학습한다. 실험을 통해 ConvIMage를 평가한 결과 동작 부위에 따라 각각 83.42%, 85.97%의 성능을 보였다. 이는 추후 동작 데이터를 활용하는 IoT 서비스 개발 등에 적용할 수 있을 것으로 기대된다.","Gyroscopes and camera sensors, widely utilized for motion recognition across industries, are celebrated for their low power consumption and user-friendly interaction. Nevertheless, challenges such as accuracy fluctuations due to calibration methods and computational delays in real-time processing persist. In this innovative study, we introduce ConvIMage, a groundbreaking approach that transforms Inertial Measurement Unit (IMU) sensor time-series data into image data through Convolutional Neural Network (CNN) algorithms, enhancing motion estimation capabilities. ConvIMage ingeniously assembles pattern images by converting IMU-derived time-series data into distinctive color channels, empowering a CNN model to discern intricate movement patterns. Experimental assessments underscore ConvIMages commendable performance, showcasing accuracies ranging from 83.42% to 85.97%, contingent upon the specific type of motion. This auspicious outcome positions ConvIMage as a robust solution for future IoT service development, leveraging motion data with enhanced accuracy and real-time processing capabilities for a multitude of applications."
Lenet5의 FPGA 구현을 위한 High-Level Synthesis 방법,2024,"['Lenet5', 'FPGA', '메모리복제', '병렬처리', 'HLS', 'Lenet5', 'FPGA', 'Memory Duplication', 'Parallel Processing', 'HLS']","본 논문에서는 합성곱 신경망중에서 가장 잘 알려진 Lenet5를 HLS (high-level synthesis) 툴을 사용하여 FPGA (field programmable gate arrays)로 구현하는 방법을 소개한다. Lenet5의 FPGA 구현에는 HDL (hardware description language) 툴과 HLS 툴이 주로 사용된다. HLS는 C 코드에서 바로 FPGA로 구현되므로 개발기간이 짧지만 HDL에 비해 사용자가 할 수 있는 최적화에 한계가 있다. 본 논문에서는 Lenet5의 동작속도 향상을 위해 반복문 내의 실행문을 반복 실행하지 않고 병렬로 동시에 실행하기 위해 메모리를 복제하고 for loop문을 unrolling 하였다. For loop문을 loop unrolling하기 위해, 1차원 배열변수는 레지스터로 구현하고, 2차원 이상의 배열변수는 loop 문 반복횟수와 동일한 개수로 메모리를 여러 개로 분리하는 방법을 소개한다. 또한 일부 배열변수의 access 속도 향상을 위해 1 클록내에서 2회 access 할 수 있는 2 ports 메모리로 지정을 하는 방법을 소개한다. 본 논문에서 제안한 방법을 FPGA에 실제로 구현하고 기존의 HDL 구현 및 HLS 방법들과 성능 및 장단점을 비교한다.","This paper introduces a method of implementing Lenet5, the best-known convolutional neural network, on FPGA (field programmable gate arrays) using HLS (high-level synthesis) tools. HDL (hardware description language) and HLS tools are mainly used in the FPGA implementation of Lenet5. HLS is implemented directly from C code to FPGA, so the development period is short, but compared to HDL, there are limits to the optimization that users can do. In this paper, to improve the operation speed of Lenet5, the memory was duplicated, and the for loop statement was unrolled to execute the execution statements within the loop simultaneously and in parallel without repeating them. To loop unroll the for loop statement, we introduce a method of implementing one-dimensional array variables as registers and dividing two-dimensional or more array variables into multiple memories with the same number of loop statement repetitions. In addition, to improve the access speed of some array variables, we introduce a method of designating a 2-port memory that can be accessed twice within one clock period. The method proposed in this paper is actually implemented on an FPGA, and its performance and pros and cons are compared with existing HDL implementations and HLS methods."
무인항공기 비행 상태 예측을 위한 개선된 CNN-LSTM 혼합모델,2024,"['UAV(무인항공기)', 'CNN(합성곱 신경망)', 'LSTM(장단기 기억 신경망)', 'Loss of Control(조종 불능)', 'Prediction(예측)']","최근에 무인항공기의 사업화가 활발하게 추진됨에 따라 무인항공기의 안전성 확보를 위한 기술 개발에 많은 관심이 집중되고 있다. 일반적으로 무인항공기는 운용 중 급기동, 외란, 조종사 실수 등으로 인하여 조종 불능의 상태로 진입할 가능성을 지닌다. 조종 불능 상태로의 진입을 예방하기 위해서는 무인항공기의 비행 상태를 예측하는 것이 필수적으로 요구된다. 본 논문에서는 무인항공기의 비행 상태 예측 성능의 향상을 위하여 개선된 CNN-LSTM 혼합모델을 제안한다. 모의실험은 제안하는 모델을 이용한 예측 기법이 기존 예측 기법에 비하여 비행 상태 예측 성능이 우수하며 온보드 환경에서 실시간으로 운용됨을 보인다.","In recent years, as the commercialization of unmanned aerial vehicles (UAVs) has been actively promoted, much attention has been focused on developing a technology to ensure the safety of UAVs. In general, the UAV has the potential to enter an uncontrollable state caused by sudden maneuvers, disturbances, and pilot error. To prevent entering an uncontrolled situation, it is essential to predict the flight state of the UAV. In this paper, we propose a flight state prediction technique based on an improved CNN−LSTM hybrid mode to enhance the flight state prediction performance. Simulation results show that the proposed prediction technique offers better state prediction performance than the existing prediction technique, and can be operated in real-time in an on-board environment."
엣지 기반 적대적 예제 탐지 모델의 효과에 대한 연구: 다양한 적대적 알고리즘을 대상으로,2024,"['딥러닝 모델', '컴퓨터 비전', '합성곱 신경망', '적대적 예제', '에지 기반 분류', '적대적 방어', 'Deep Learning Model', 'Computer Vision', 'Convolutional Neural Network', 'Adversarial Example', 'Edge-based Classification', 'Adversarial defense']",,"Deep learning models show excellent performance in tasks such as image classification and object detection in the field of computer vision, and are used in various ways in actual industrial sites.Recently, research on improving robustness has been actively conducted, along with pointing out that this deep learning model is vulnerable to hostile examples. A hostile example is an image in which small noise is added to induce misclassification, and can pose a significant threat when applying a deep learning model to a real environment. In this paper, we tried to confirm the robustness of the edge-learning classification model and the performance of the adversarial example detection model using it for adversarial examples of various algorithms. As a result of robustness experiments, the basic classification model showed about 17% accuracy for the FGSM algorithm, while the edge-learning models maintained accuracy in the 60-70% range, and the basic classification model showed accuracy in the 0-1% range for the PGD/DeepFool/CW algorithm, while the edge-learning models maintained accuracy in 80-90%. As a result of the adversarial example detection experiment, a high detection rate of 91-95% was confirmed for all algorithms of FGSM/PGD/DeepFool/CW. By presenting the possibility of defending against various hostile algorithms through this study, it is expected to improve the safety and reliability of deep learning models in various industries using computer vision."
AI 기반 산업용 커넥터 핀의 미삽 상태 검출에 관한 연구,2024,"['Convolutional Neural Networks(합성곱 신경망)', 'Connector(커넥터)', 'Defects Detection(결함 검출)', '데이터 증강Data Augmentation(데이터 증강)']",,"Connectors are crucial in electronic systems for ensuring the transmission of electrical signals and power, particularly in the automotive, aerospace, and telecommunications industries. Defective connectors can lead to significant system failure, making early detection vital. Manual inspections are inefficient and inaccurate, necessitating automated methods. In this study, we developed an automated defect detection system using deep learning. Specifically convolutional neural networks (CNN) with TensorFlow and Keras were used to improve detection efficiency and accuracy. A dataset of 1,020 connector images was created from a 30-second video. The dataset was then classified into normal and defective categories, augmented for diversity, and converted to grayscale. The CNN model, trained over 20 epochs, achieved a validation accuracy of 1.00 and training accuracy of 0.996. Performance evaluations demonstrated a real-time prediction accuracy of 99.25% at a processing speed of up to 72,000 classifications per hour. This study demonstrates the effectiveness of the CNN model in automated defect detection, significantly enhancing the productivity and quality control for manufacturers."
포트홀 탐지를 위한 생성형 AI 기반 데이터셋 구축과 CNN 모델 성능 평가,2024,"['생성형 AI', '프롬프트', '포트홀', '합성곱 신경망', '딥러닝', 'Generative AI', 'Prompt', 'Pothole', 'Convolutional Neural Network', 'Deep Learning']","차량의 증가와 기후 변화로 인한 포트홀 문제는 교통안전에 중대한 영향을 미치며, 이를 해결하기 위한 자동화된 탐지 기술이 표구된다. 본 논문에서는 도로의 포트홀 탐지의 효율성을 높이기 위해 생성형 AI 이미지를 활용한 새로운 접근법을 제안하였다. 실제 포트홀 이미지 대신, 생성형 AI 도구를 사용하여 제작된 가상 이미지를 활용하여 탐지 모델을 학습시켰다. Midjourney와 Playground 등 다양한 AI 도구로 생성된 이미지를 사용해 학습한 모델과 실제 이미지를 사용한 모델 사이의 성능을 비교했다. 연구 결과를 통해 생성형 AI가 포트홀 탐지 모델의 정확성과 효율성을 높이는 데 유용할 가능성이 있음을 확인하였고, 도로 유지보수의 효율성을 향상시킬 수 있는 방안을 제시하였다. 이를 통해 생성형 AI의 활용 가능성에 관한 기초를 마련하였고, 사회적 안전과 경제적 비용 절감에 기여할 것으로 기대한다.","The issue of potholes, exacerbated by the increase in vehicles and climate change, has significant implications for traffic safety, necessitating the development of automated detection technologies. In this paper, we propose a novel approach to improve the efficiency of pothole detection on roads by utilizing generative AI images. Instead of using real pothole images, a detection model was trained using virtual images generated by AI tools. The performances of models trained with images generated by various AI tools, such as Midjourney and Playground, were compared with those of model trained with real images. The results confirm that generative AI can enhance the accuracy and efficiency of pothole detection models and thereby offers potential solutions for improving road maintenance efficiency. Hence, this study lays the groundwork for the potential application of generative AI in road maintenance to enhance social safety and reduce economic costs."
혼합 샘플링을 이용한 하이브리드 딥러닝 결합 모델 기반의 부정맥 분류,2024,"['부정맥', 'SMOTE-Tomek', '합성곱 신경망', '양방향 장단기 기억 신경망', '어텐션 메커니즘', 'Arrhythmia', 'SMOTE-Tomek', 'CNN', 'BLSTM', 'Attention-Mechanism Received 2 July 2024', 'Revised 8 July 2024', 'Accepted 30 July 2024 * Corresponding Author Hyeog-Soong Kwon(E-mail:hskwon@pusan.ac.kr Tel:+82-55-350-5411) Professor', 'Department of IT Engineering', 'Pusan National University', 'Miryang', '50463 Korea Open Access http://doi.org/10.6109/jkiice.2024.28.10.1183\tprint ISSN: 2234-4772 online ISSN: 2288-4165 This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License(http://creativecommon', 'distribution', 'and reproduction in any medium', 'provided the original work is properly cited. Copyright Ⓒ The Korea Institute of Information and Communication Engineering.']","부정맥은 심장 박동이 불규칙하게 뛰고 있는 상태를 말하며, 심정지와 같은 위험한 상황을 유발할 수 있기 때문에 이의 조기 검출은 매우 중요하다. 본 연구에서는 혼합 샘플링 기법과 어텐션 메커니즘 기반의 하이브리드 딥러닝 결합 모델을 이용한 부정맥 분류 방법을 제안한다. 이를 위해 먼저 전처리 과정을 거친 심전도 신호를 사용하였다. 이때 데이터의 불균형 문제를 해결하기 위해 SMOTE-Tomek 혼합 샘플링 기법을 적용하였다. 이후 컨볼루션 레이어를 통해 부정맥 신호의 패턴을 추출하고 이를 BLSTM 레이어에 입력한 후 어텐션 메커니즘을 통해 가중치를 학습하고 검증 데이터로 모델을 평가한 후 부정맥을 분류하였다. 제안한 방법의 타당성을 판단하기 위해 MIT-BIH 부정맥 데이터베이스를 통해 분류의 정확도, 정밀도, 재현율, F1-score를 비교하였다. 성능평가 결과 각각 99.64%, 93.27%, 95.05%, 94.08%로 분류율이 우수함을 확인할 수 있었다.","Arrhythmia is an irregular heartbeat, and its early detection is very important because it can cause dangerous situations such as sudden cardiac death. In this study, we propose a method for arrhythmia classification using a hybrid deep learning combination model based on mixed sampling technique and attention mechanism. To do this, we used preprocessed ECG signals. The SMOTE-Tomek mixed sampling technique was applied to address the imbalance in the data. The convolutional hierarchy was then configured to precisely extract the pattern of the arrhythmia signal, which was used as the input of BLSTM, and then the weights were learned through an attention mechanism, and the model was evaluated with validation data to verify the change in normal and arrhythmia classification. To demonstrate the superiority of the proposed method, we compared the accuracy, precision, recall, and F1-score of the classification using the MIT-BIH arrhythmia database. The performance evaluation results showed that the classification rates were 99.64%, 93.27%, 95.05%, and 94.08%, respectively."
Computer Vision-based Basketball Player Training System,2024,"['농구 선수 훈련', '객체 감지', '합성곱 신경망', '싱글숏 멀티박스 감지기', '전송 학습', 'Basketball Player Training', 'Object Detection', 'Convolutional Neural Network', 'Single Shot MultiBox Detector', 'Transfer Learning']",,"Computer vision-based basketball player training system is a state-of-the-art field that relies on computer vision technologies and deep learning to help the basketball player train. Computer Vision-Based basketball player training systems rely on extensive training data to detect the players movements and poses; the current training datasets are relatively small and vary in quality, affecting the basketball training effect. This paper proposes the human skeleton detection model, basketball and basketball hoop detection model, basketball shot detection model, basketball hit detection model, and basketball hit prediction model. In the proposed model, the basketball hit detection is improved by up to 9.66% over the existing method. The basketball hit prediction model is improved by up to 10.72% over the existing method using mathematical methods."
노인 모니터링 시스템을 위한 열화상 이미지 기반 자세 인식 딥러닝 알고리즘 개발,2024,"['독거노인', '노인 모니터링', '적외선 열화상', '열적자세 알고리즘', '합성곱 신경망', 'Elderly living alone', 'Elderly monitoring', 'Infrared thermal image', 'Thermal pose algorithm', 'Convolutional neural network']",,"Elderly monitoring systems are gaining significant attention in our increasingly aging society. Existing monitoring systems, which utilize RGB and infrared cameras, often encounter errors when recognizing human-like objects, photos, and videos as actual humans. Additionally, privacy concerns arise due to this issue. However, these challenges can potentially be overcome by employing thermal images. Thus, our study aimed to investigate the feasibility of identifying and categorizing human postures depicted in thermal images using deep learning models and algorithms. To conduct our experiment, we developed a system that utilizes a thermal pose algorithm and a convolutional neural network. As a result, we achieved an average accuracy of 88.3%, with the highest accuracy reaching 91.2%."
뇌-컴퓨터 인터페이스를 위한 뇌파 기반 보행 인식 분류 CNN-BiLSTM 모델 개발,2024,"['뇌-컴퓨터 인터페이스', '뇌파', '보행', '동적 환경', '합성곱 신경망', '양방향 장단기 메모리', 'Brain-computer interface (BCI)', 'Electro encephalo graphy (EEG)', 'Gait', 'Dynamic environment', 'Convolutional neural network (CNN)', 'Bidirectional long short-term memory (BiLSTM)']",,"Brain-computer interface (BCI) is a technology used in various fields to analyze electroencephalography (EEG) signals torecognize an individual's intention or state and control a computer or machine. However, most of the research on BCI is onmotor imagery, and research on active movement is concentrated on upper limb movement. In the case of lower limbmovement, most of the research is on the static state or single movements. Therefore, in this research, we developed adeep-learning model for classifying walking behavior(1: walking, 2: upstairs, 3: downstairs) based on EEG signals in adynamic environment to verify the possibility of classifying EEG signals in a dynamic state. We developed a model thatcombined a convolutional neural network (CNN) and a bidirectional long short-term memory (BiLSTM). The model obtainedan average recognition performance of 82.01%, with an average accuracy of 93.77% for walking, 76.52% for upstairs, and75.75% for downstairs. It is anticipated that various robotic devices aimed at assisting people with disabilities and theelderly could be designed in the future with multiple features, such as human-robot interaction, object manipulation, andpath-planning utilizing BCI for control."
A Hybrid Deep Learning Model for Generating Time-series Fire Data in Underground Utility Tunnel based on Convolutional Attention TimeGAN,2024,"['지하공동구', '화재 데이터 생성', '어텐션 매커니즘', '합성곱 신경망', '게이트 순환 유닛', '적대적 생성 신경망', 'underground utility tunnel', 'fire data generation', 'CNN', 'attention', 'GRU', 'GAN']",,
전이학습 기반 특징융합을 이용한 누출판별 기법 연구,2024,"['배관 누출 감지', '딥 러닝', '1D 합성곱 신경망', '특징융합', '전이학습', 'Pipe Leak Detection', 'Deep Learning', '1D CNN', 'Feature Fusion', 'Transfer Learning']",,"When there were disparities in performance between models trained in the time and frequency domains, even after conducting anensemble, we observed that the performance of the ensemble was compromised due to imbalances in the individual model performances.Therefore, this paper proposes a leakage detection technique to enhance the accuracy of pipeline leakage detection through a step-wiselearning approach that extracts features from both the time and frequency domains and integrates them. This method involves a two-steplearning process. In the Stage 1, independent model training is conducted in the time and frequency domains to effectively extract crucialfeatures from the provided data in each domain. In Stage 2, the pre-trained models were utilized by removing their respective classifiers.Subsequently, the features from both domains were fused, and a new classifier was added for retraining. The proposed transferlearning-based feature fusion technique in this paper performs model training by integrating features extracted from the time and frequencydomains. This integration exploits the complementary nature of features from both domains, allowing the model to leverage diverseinformation. As a result, it achieved a high accuracy of 99.88%, demonstrating outstanding performance in pipeline leakage detection."
딥 러닝을 통해 스마트 그리드 이상 탐지 기능 강화,2024,"['스마트 그리드 안정성', '이상 탐지', '합성곱 신경망', '예측 모델링', '순환 신경망', '고장 탐지', 'Smart Grid Stability', 'Anomaly Detection', 'CNNs', 'Predictive Modeling', 'RNNs', 'Fault Detection']","스마트 그리드로의 전력망 현대화는 효율성, 신뢰성, 지속 가능성 측면에서 많은 이점을 제공합니다. 그러나 복잡하고 상호 연결된 스마트 그리드 시스템은 이상 탐지와 그리드 회복력 유지에 있어 새로운 과제를 제시한다. 기존의 이상 탐지 방법은 스마트 그리드 데이터의 동적이고 이질적인 특성에 적응하기 어려워, 이상 탐지 및 완화에 있어 비효율성을 초래한다. 이러한 문제를 해결하기 위해 본 연구는 TensorFlow 프레임워크를 활용한 딥러닝 기술을 통해 스마트 그리드 이상 탐지와 회복력을 향상하는 새로운 접근 방안을 제안한다. 연구의 목표는 두 가지로 나뉜다. 첫째, 스마트 그리드 데이터 내에서 이상을 정확하게 감지할 수 있는 고급 딥러닝 모델을 개발하고, 둘째, 감지된 이상에 대해 선제적으로 대응하고 이를 완화하여 그리드 회복성을 강화하는 것이다.","Modernizing the power grid to a smart grid offers many benefits in terms of efficiency, reliability, and sustainability. However, complex and interconnected smart grid systems present new challenges in detecting anomalies and maintaining grid resilience. Existing anomaly detection methods have difficulty adapting to the dynamic and heterogeneous characteristics of smart grid data, resulting in inefficiency in anomaly detection and mitigation. To solve these problems, this study proposes a new approach to improve smart grid anomaly detection and resilience through deep learning technology using the TensorFlow framework. The goals of the research are divided into two. First, to develop an advanced deep learning model that can accurately detect anomalies within smart grid data, and second, to strengthen grid resilience by proactively responding to and mitigating detected anomalies."
CNN 기반 스펙트로그램을 이용한 자유발화 음성감정인식,2024,"['Spontaneous Speech', 'Speech Emotion Recognition', 'Spectrogram', 'Convolutional Neural Network', '자유발화', '음성감정인식', '스펙트로그램', '합성곱신경망']",,"Speech emotion recognition (SER) is a technique that is used to analyze the speaker's voice patterns, including vibration, intensity,and tone, to determine their emotional state. There has been an increase in interest in artificial intelligence (AI) techniques, which arenow widely used in medicine, education, industry, and the military. Nevertheless, existing researchers have attained impressive resultsby utilizing acted-out speech from skilled actors in a controlled environment for various scenarios. In particular, there is a mismatchbetween acted and spontaneous speech since acted speech includes more explicit emotional expressions than spontaneous speech. Forthis reason, spontaneous speech-emotion recognition remains a challenging task. This paper aims to conduct emotion recognition andimprove performance using spontaneous speech data. To this end, we implement deep learning-based speech emotion recognition usingthe VGG (Visual Geometry Group) after converting 1-dimensional audio signals into a 2-dimensional spectrogram image. The experimentalevaluations are performed on the Korean spontaneous emotional speech database from AI-Hub, consisting of 7 emotions, i.e., joy, love,anger, fear, sadness, surprise, and neutral. As a result, we achieved an average accuracy of 83.5% and 73.0% for adults and young peopleusing a time-frequency 2-dimension spectrogram, respectively. In conclusion, our findings demonstrated that the suggested frameworkoutperformed current state-of-the-art techniques for spontaneous speech and showed a promising performance despite the difficulty inquantifying spontaneous speech emotional expression."
시각화 기반의 시계열 음향 분류에서의 플롯 크기의 영향력 분석,2024,"['Deep Learning', 'Convolutional Neural Network(CNN)', 'Time-series', 'Vision AI', '딥러닝', '합성곱 신경망', '시계열', '영상 인공지능']",,"In recent years, visualizing time-series data as images for use in vision-based Artificial Intelligence (AI) models has gained significant attention. This approach transforms temporal sequences into images that can be processed by deep learning models, such as Convolutional Neural Network (CNN).Although its effectiveness has been demonstrated in various domains, the impact of plot size on model performance remains underexplored. In this study, we investigate the effect of varying plot sizes on classification accuracy by visualizing natural sounds (e.g., cats, crows) and testing five classes of 2,000 samples each using the YOLO model. While training was conducted on 320x320 plots, test sets were generated at six sizes (112x112 to 640x640). Results show that as the plot size of the test dataset diverged from that of the training dataset, both precision and recall decreased, highlighting the importance of plot size consistency in time-series visualization research."
음향기반 교통사고 검지를 위한 딥러닝 모델 연구,2024,"['Traffic', 'Accident', 'Acoustic', 'Artificial Intelligent', 'DNN', 'CNN', 'RNN', '교통', '사고', '음향', '인공지능', '심층신경망', '합성곱신경망', '순환신경망']","C-ITS(Cooperative-Intelligent Transport Systems) 및 자율주행 환경에서 교통사고와 같은 돌발상황의 신속한 검지가 중요해짐에 따라, 최근에는 이를 위한 다양한 시스템 개발과 관련된 연구가 활발히 진행되고 있다. 본 연구는 기존의 영상 및 레이더 기반 검지 방식의 한계를 극복하기 위해 음향 정보를 이용한 교통사고 검지 기술을 개발하는 것을 목표로 한다. 구체적으로, 교통사고 시 발생하는 음향 데이터를 수집하고, 이를 통해 충돌 및 급제동과 같은 특징을 추출하였다. 추출된 음향 데이터를 바탕으로DNN, CNN, RNN의 딥러닝 모델을 학습시켜 각 모델을 통해 사고 패턴을 검지하는 방법을 연구하였다. 이후, 학습된 모델들의 검지 결과를 비교 분석하여 음향 패턴을 검지하는 데 가장 적합한 알고리즘 모델을 선정하였다. 최적의 알고리즘을 적용하여 음향기반 자동 사고 검지 시스템을 개발하였으며, 이 시스템은 교통사고를 신속하고 정확하게 판별할 수 있다. 본 연구는 딥러닝 알고리즘과 음향 특징 추출 기술을 통해 정확한 교통사고 검지를 가능하게 하여 교통 안전 향상에 기여할 수 있을 것으로 기대된다.","In the context of C-ITS and autonomous driving, rapid detection of traffic incidents is crucial. This research addresses the limitations of traditional methods such as imaging and radar by developing a technology that utilizes acoustic information for incident detection. Specifically, we analyzed acoustic data to extract features and trained deep learning models—DNN, CNN, and RNN—to identify patterns associated with crash and skid. Through comparative analysis of the models' detection results, we identified the optimal algorithm for acoustic pattern recognition. This study demonstrates the potential of advanced deep learning algorithms and acoustic feature extraction in enhancing automated accident detection systems."
금속 3D 프린터 제품의 초음파 전파 특성 분석 및 Deep Learning 알고리즘의 초음파 결함 분류 능력 비교분석,2024,"['초음파 검사', '금속 3D 프린터', '심층 학습', '이미지 분류', '합성곱 신경망', '장단기 기억 신경망', 'Ultrasonic Testing', '3D Printer', 'Deep Learning', 'Image Classification', 'CNN', 'LSTM']",,
CNN을 이용한 방전 표면에 따른 방전 가공조건 예측,2024,"['Micro EDM', 'Micro machining', 'Deep learning', 'Convolutional neural network', 'Grad CAM', '미세 방전 가공', '미세 가공', '딥러닝', '합성곱신경망', '그래드캠']",,"CNN is one of the deep learning technologies useful for image-based pattern recognition and classification. For machining processes, this technique can be used to predict machining parameters and surface roughness. In electrical discharge machining (EDM), the machined surface is covered with many craters, the shape of which depends on the workpiece material and pulse parameters. In this study, CNN was applied to predict EDM parameters including capacitor, workpiece material, and surface roughness. After machining three metals (brass, stainless steel, and cemented carbide) with different discharge energies, images of machined surfaces were collected using a scanning electron microscope (SEM) and a digital microscope. Surface roughness of each surface was then measured. The CNN model was used to predict machining parameters and surface roughness."
AI를 이용한 레이더 SNR 향상 기법,2024,"['레이더(RADAR)', '펄스 적분(Pulse Integration)', '오탐(False Alarm)', '딥 러닝(Deep Learning)', '합성곱 신경망(Convolutional Neural Network)']",,
로봇 비전의 영상 인식 AI를 위한 전이학습 정량 평가,2024,"['Robot Vision', 'Image Recognition', 'Transfer Learning', 'Convolution Neural Network', 'MNIST', '로봇 비전', '영상 인식', '전이 학습', '합성곱신경망', 'MNIST']","본 연구에서는 로봇 비전용 영상 인식을 비롯한 다양한 AI 분야에서 널리 활용되는 전이학습에 대한 정량적 평가를 제시하였다. 전이학습을 적용한 연구 결과에 대한 정량적, 정성적 분석은 제시되나, 전이학습 자체에 대해서는 논의되지 않는다. 따라서 본 연구에서는 전이학습 자체에 대한 정량적 평가를 숫자 손글씨 데이터베이스인 MNIST를 기반으로 제안한다. 기준 네트워크를 대상으로 전이학습 동결층의 깊이 및 전이학습 데이터와 사전 학습 데이터의 비율에 따른 정확도 변화를 추적하였다. 이를 통해 첫번째 레이어까지 동결할 때 전이학습 데이터의 비율이 3% 이상일 경우, 90% 이상의 정확도를 안정적으로 유지할 수 있음이 확인되었다. 본 연구의 전이학습 정량 평가 방법은 향후 네트워크 구조와 데이터의 종류에 따라 최적화된 전이학습을 구현하는데 활용 가능하며, 다양한 환경에서 로봇 비전 및 이미지 분석 AI의 활용 범위를 확대할 것이다.",
홀로그램 기록결과물의 품질 평가를 위한 CNN 모델 설계,2024,"['Deep learning', 'Convolutional neural network', 'Hologram quality assessment']","다양한 딥러닝(deep learning) 기술중에서 이미지 처리에 특화되어있는 CNN(Convolutional Neural Network) 기법은 합성곱 신경망으로 본 논문에서 필요한 이미지 분류 및 품질평가 작업에 필요한 신경망 알고리즘이다. 홀로그래피는 기록 광원을 이용하여 3차원 입체정보를 2차원적인 기록매질의 평면에 기록하고 재생하는 기술이다. 홀로그램 기록결과물은 아날로그 형태이기 때문에 지금까지는 기록된 결과물을 평가하는 과정이 수학적인 계산방법에 의해 검토되어 제한적이거나, 주관적이고 시각적인 검토에만 의존해왔다. 이러한 문제점들을 해결하기 위하여 정량적이고 객관적으로 홀로그램 기록결과물의 품질을 자동으로 평가하는 시스템을 구현하였다. 학습 데이터셋에 사용할 이미지를 등급에 따라 구분하여 1,200개를 새롭게 생성하였다. 그 이미지를 홀로그램의 품질평가에서 기록광원의 과다노출 또는 노출부족으로 구분할 수 있도록 6등급으로 구분하였다. 홀로그램 기록결과물의 촬영 이미지는 일반적인 디지털 사진의 촬영 이미지와는 다르기 때문에 품질평가의 기준을 다르게하여 구분하기 위해서 그 기준에 부합하여 CNN 모델을 설계하였다.","Among various deep learning technologies, CNN (Convolutional Neural Network) technique specialized in image processing is a convolutional neural network and is a neural network algorithm required for the image classification and quality evaluation tasks required in this paper. Holography is a technology that records and reproduces three-dimensional stereoscopic information on a two-dimensional flat surface of a recording medium using a recording light source. Since the holographic recording results are in an analog form, the process of evaluating the recorded results has been limited by mathematical calculation methods so far, or has been dependent on subjective and visual reviews. To solve these problems, a system that automatically evaluates the quality of holographic recording results quantitatively and objectively was implemented. We created 1,200 new images to be used in the learning dataset by classifying them according to grade. The images were classified into 6 grades so that they could be distinguished as overexposed or underexposed by the recording light source in the quality evaluation of the hologram. Since the captured images of holographic recording results are different from those of general digital photographs, a CNN model was designed to meet the criteria in order to distinguish them by differentiating the quality evaluation criteria."
시민과학에서의 AI 활용 가능성과 한계,2024,"['AI', '시민과학', '머신러닝', '협업 파트너로서 AI', '시민과학자', 'AI', 'citizen science', 'machine learning', 'AI as collaborative partner', 'citizen scientist']","이 논문은 시민과학에서 AI가 활용된 사례 조사를 통해 AI가 시민과학에 어떤 영향을 미쳤는지를 분석한다. 컴퓨터 비전, 합성곱 신경망 등 머신러닝, 딥러닝 알고리즘의 AI 기술이 시민과학에 적용되면서 시민과학 프로젝트의 데이터 처리 속도가 향상되고 데이터 품질이 향상되었다. 머신러닝 알고리즘으로 데이터 처리가 자동화됨에 따라 생물 다양성에 대한 전 지구적 변화 추적이 가능해졌고 증거 데이터 기반의 사전예방적 보존 정책 수립에 시민과학이 기여할 수 있게 되었다. 시민과학자들에 대한 개인별 피드백과 교육이 가능해짐에 따라 시민과학에의 참여 증진을 낳을 수 있었다. 한편, AI 기술은 시민과학자들이 실행해야 하는 과학 활동을 자동화하여 시민과학이 시민과학자들의 참여 없이 수행이 가능한 상황을 초래할 수도 있다. 현재의 AI 기술이 보여주는 블랙박스 문제와 편향성 문제는 시민과학이 갖고 있는 다른 과학 구성의 가능성에 제약을 줄 수도 있다. AI 기술이 가져다줄 수 있는 긍정적 효과를 지속하기 위해서는 부정적 결과를 가져다 주는 문제에 대한 해결책을 마련하고 시민과학자들과 AI의 협업 활동이 가능하게 하는 AI 활용 전략 수립이 필요하다. 다양한 시민과학자들의 참여를 보장하는 협업 파트너로서의 AI 기술 개발을 추진할 필요가 있다.","This paper analyzes how AI has impacted citizen science through case studies of its use in citizen science. The application of machine learning, deep learning algorithms, such as computer vision and convolutional neural networks, to citizen science has increased the speed of data processing and improved data quality produced by citizen science projects. The automation of data processing with machine learning algorithms has made it possible to track global changes in biodiversity and contribute to evidence-based, proactive conservation policy. The ability to provide personalized feedback and training to citizen scientists has led to increased participation in citizen science projects. On the other hand, AI technologies can also automate the scientific activities that citizen scientists need to perform, leading to situations where citizen science can be done without the participation of citizen scientists. The black box and bias issues of current AI technologies can also limit the possibilities of citizen science that can be contributed to constitution of another science. In order to sustain the positive effects that AI technologies can bring, it is necessary to develop AI use strategies that prevent the negative consequences and enable collaborative activities between citizen scientists and AI. We need to develop AI technologies as collaborative partners that ensure the participation of diverse citizen scientists."
빅데이터 플랫폼 기반 동명이인 판별 기법 설계,2024,"['Name Disambiguation', 'Distributed Processing', 'GCN', 'HAC', 'Big Data', '이름 모호성', '분산 처리', '그래프 합성곱 신경망', '계층적 군집 분석', '빅데이터']",,"Currently, papers and patents search sites simply provide the function of browsing published papers and patents, or collecting research results registered by name. However, if the names of the same name are not distinguished, it becomes somewhat cumbersome to judge the research results. So, various studies are being conducted to resolve the ambiguity of the name called a name disambiguation. In this paper, we design and propose a name disambiguation scheme based on research results such as the papers and patents. The proposed scheme utilizes Spark that is a big data processing platform to process large amounts of data. Unlike existing schemes, it has the advantage of reflecting newly added research results in that new data are collected and stored by real-time collecting system. And we utilize GCN and HAC, which are populary used in existing name disambiguation studies. The proposed scheme shows that when a total of 7,104,000 papers and patents data are learned by the GCN algorithm, it performs about 1.21 times faster in a distributed environment than in a single server environment. As the number of data increased, the effectiveness of distributed processing through Spark clusters becomes more prominent."
시공간 그래프 랜덤워크를 활용한 비디오 의미구조 이해,2024,"['video understanding', 'compositional learning', 'spatiotemporal graph', 'random walk', 'semantic unit', '비디오 이해', '구성적 학습', '시공간 그래프', '랜덤워크', '의미단위']","긴 비디오 이해는 비디오 내 다양한 의미단위들을 찾고, 이들 간 복잡한 관계 해석에 초점을 맞춘다. 기존 방식은 합성곱 신경망이나 transformer 기반 모델을 활용하여 짧은 클립들에 대한 문맥정보를 인코딩하고, 이들 간의 시간적 관계를 고려한다. 그러나 해당 방식으로는 비디오 내부에 존재하는 의미 단위들간 복잡한 관계 포착이 어렵다. 본 논문에서는 이러한 의미단위들 간 관계를 명시적으로 표현하기 위해 객체를 정점, 객체들 간 시공간 관계를 간선으로 하는 시공간 그래프로 비디오 입력을 재표현한다. 또한, 해당 그래프에서 시공간 랜덤워크를 통해 얻은 고차원적 의미관계(high-order relationship) 정보를 활용하여, 주요 의미단위를 더 작은 단위들의 구성으로 표현하는 새로운 방법을 제안한다. 다양한 물체들의 복잡한 행동에 관련된 비디오 데이터셋 CATER를 활용한 실험으로, 제안하는 방식이 효과적인 의미단위 포착능력을 가짐을 입증하였다.","Understanding a long video focuses on finding various semantic units present in the video and interpreting complex relationships among them. Conventional approaches utilize models based on CNNs or transformers to encode contextual information for short clips and then consider temporal relationships among them. However, such approaches struggle to capture complex relationships among smaller semantic units within video clips. In this paper, we present video inputs using a spatiotemporal graph with objects as vertices and relative space-time information between objects as edges, to explicitly express relationships among these semantic units. Additionally, we proposed a novel method to represent major semantic units as compositions of smaller units using high-order relationship information obtained by spatiotemporal random walks on the graph. Through experiments on CATER dataset, which involved complex actions of multiple objects, we demonstrated that our approach exhibited effective semantic unit capturing capabilities."
반려동물 안구 질환을 위한 딥러닝 모델 기반 진단 시스템,2024,"['artificial intelligence', 'deep learning', 'ocular diseases', 'system', 'convolutional neural network', '인공지능', '딥러닝', '안구 질환', '시스템', '합성곱 신경망']","반려동물의 안구 질환은 늦은 진단과 치료로 인해 실명 등의 중대한 결과를 초래할 수 있다. 이는 반려동물 양육 가정의 증가에 따라 점점 더 중요한 문제로 부상하고 있다. 본 논문은 이 문제에 대응하기 위해 인공지능 기반의 조기 진단과 치료 방향을 제시하는 시스템을 설계하고 구현한다. 제안하는 시스템은 AIHUB의 라벨링된 데이터셋을 활용하여 ResNet과 EfficientNet 모델을 최적화한다. 또한 고정밀 질병 분류가 가능하도록 하여 전문가의 진단을 보조하고, 진료가 어려운 지역의 사용성을 높인다. 결과적으로 제안하는 시스템은 반려동물의 안구 건강을 효과적으로 관리하고 보호자의 부담을 경감할 수 있다. 성능평가를 통해, 제안하는 모델은 반려동물의 안구 질환 분류에서 90% 이상의 높은 정확도를 나타냄을 보인다.","Pet eye diseases can have serious consequences, including blindness, if not diagnosed and treated promptly. This issue is becoming increasingly important as more households own pets. In this paper, we present a system that uses artificial intelligence to provide early diagnosis and treatment recommendations for pet eye diseases. We use labeled data sets from AIHUB to optimize ResNet and EfficientNet models for diagnosing these diseases. The proposed system helps experts classify diseases with high precision and makes it more accessible in areas with limited medical services. As a result, the system effectively manages and protects the ocular health of cats and dogs, reducing the burden on their caregivers. Performance evaluations demonstrate that the proposed model achieves over 90% accuracy in classifying eye diseases."
Deep Learning-Based Plant Health State Classification Using Image  Data,2024,"['Deep Learning', 'Convolutional Neural Networks', 'Channel-wise Attention', 'Depthwise Separable Convolution', 'Attention-Enhanced ResNet', 'Plant Health State Classification', '딥러닝', '합성곱 신경망', '채널 어텐션', '깊이 분리 합성곱', 'Attention-Enhanced ResNet', '작물 건강 상태 분류']",,"Tomatoes are rich in nutrients like lycopene, β-carotene, and vitamin C. However, they often suffer from biological and environmental stressors, resulting in significant yield losses. Traditional manual plant health assessments are error-prone and inefficient for large-scale production. To address this need, we collected a comprehensive dataset covering the entire life span of tomato plants, annotated across 5 health states from 1 to 5. Our study introduces an Attention-Enhanced DS-ResNet architecture with Channel-wise attention and Grouped convolution, refined with new training techniques. Our model achieved an overall accuracy of 80.2% using 5-fold cross-validation, showcasing its robustness in precisely classifying the health states of tomato plants"
생체정보 보호를 위한 CNN 기반의 홍채 지문 영역 분할,2024,"['Segmentation', 'Detection', 'Artificial Intelligence Learning', 'Biometric Information', 'CNN', '영역 분할', '감지', '인공지능 학습', '생체 정보', '합성곱 신경망 모델']","스마트 기기의 발달과 고해상도 이미징 기술의 대중화로 인해, 지문이 노출되거나, 화상 회의, 화상 통화 등 고화질 얼굴 사진에서 홍채 정보가 노출되고 있다. 스마트기기의 대중화는 일상적인 디지털 활동에서 무분별한 사진 공유로 인해, 개인의 생체정보인 지문이나 홍채가 노출되어 위조 및 악용될 가능성이 높아지고 있다. 이러한 문제를 해결하기 위해서 본 논문에서는 원본 이미지로부터 생체정보를 보호하고 보안을 강화할 목적으로 CNN의 영역 분할기법을 활용하여 이미지 내 지문과 홍채를 식별 보호하는 방안을 제안한다. 제안된 모델은 입력 이미지에서 지문 및홍채를 식별한 후 해당 영역에 블러 처리를 적용하며, 이를 원본 이미지와 결합하여 보안성을 강화한다. U-Net 및ResNet-34를 백본으로 사용한 모델 구조를 통해 학습 시간 및 성능을 비교한다.","With the development of smart devices and the popularization of high-resolution imaging technology, fingerprints arebeing exposed, and iris information is being exposed in high-definition facial photos such as video conferences and videocalls. The popularization of smart devices has increased the possibility of personal biometric information such asfingerprints and irises being exposed and forged and misused due to indiscriminate photo sharing in everyday digitalactivities. To solve this problem, this paper proposes a method to identify and protect fingerprints and irises in imagesby utilizing CNN's region segmentation technique for the purpose of protecting biometric information from the originalimage and enhancing security. The proposed model identifies fingerprints and irises in the input image, applies blurringto the corresponding regions, and combines them with the original image to enhance security. The learning time andperformance are compared through model structures using U-Net and ResNet-34 as backbones."
고객 서비스 개선을 위한 비정형 텍스트 데이터 자동 분류 모델 비교 - 고객 불만 데이터를 대상으로,2024,"['고객 불만', '자동 분류', '서비스 개선', '비정형 데이터', '나이브 베이즈', '랜덤 포레스트', '서포트 벡터 머신', '합성곱 신경망', '순환 신경망', 'Customer Complaints', 'Automatic Classification', 'Service Improvement', 'Unstructured Data', 'Naive Bayes', 'Random Forest', 'SVM', 'CNN', 'LSTM']","정보기술의 발전과 디지털 커뮤니케이션의 확산으로 인해 급증하는 고객 불만과 피드백을 효과적으로 관리하고 처리하는 방법이 필요하다. 특히, 대부분의 데이터가 비정형 데이터인 상황에서, 이를 신속히 처리하고 분류하여 고객 서비스를 개선하는 것은 중요하다. 이에 본 연구에서는 전통적 분류 모델인 Naive Bayes, SVM, Random Forest와 딥러닝 모델인 CNN, LSTM을 살펴보고, 보스턴시의 교통 불만 데이터에 적용하여 고객 불만 데이터의 자동 분류 성능을 비교 분석하였다. 연구 결과, CNN과 LSTM은 각각 81%와 97%의 높은 분류 정확도를 보여, 고객 불만처럼 복잡하고 다양한 패턴의 비정형 데이터 처리에 더욱 효과적임을 확인하였다. 이러한 결과는 딥러닝 모델이 고객 불만 데이터의 특성을 더 잘 분석하고, 문맥적 연결을 감지하는 능력이 우수하기 때문이다. 본 연구는 기업이 고객의 목소리를 신속하고 정확하게 파악하고 대응할 수 있는 고객 서비스 개선 방법론을 제공하며, 이는 기업 경쟁력을 강화하는 데 기여할 것으로 기대된다.","With the advancement of information technology and the proliferation of digital communication, there is an increasing need for effective management and processing of the growing volume of customer complaints and feedback. Particularly, when most of the data is unstructured, it is crucial to quickly process and classify this data to improve customer service. In this study, we examine traditional classification models such as Naive Bayes, SVM, and Random Forest, as well as deep learning models like CNN and LSTM. These models were applied to Boston's traffic complaint data to compare the performance of automatic classification of customer complaint data. The results showed that CNN and LSTM achieved high classification accuracies of 81% and 97%, respectively, confirming their effectiveness in handling complex and diverse patterns of unstructured data, such as customer complaints. These findings demonstrate that deep learning models are better at analyzing the characteristics of customer complaint data and detecting contextual connections. This study provides a methodology for companies to quickly and accurately understand and respond to customer voices, thereby enhancing corporate competitiveness."
컬러 이미지와 딥러닝 기술을 활용한 고구마 수분 스트레스 추정,2024,"['ANOVA', 'Color Imagery', 'Convolution Neural Network', 'Sweet Potato', 'Water Stress', '고구마', '수분 스트레스', '컬러 이미지', '분산 분석', '합성곱 신경망']","전 세계 인구는 2050년까지 20억 명 증가할 것으로 예상되며, 그 중 절반 이상이 개발도상국 출신일 것으로 전망된다. FAO에 따르면, 개발도상국에서는 영양부족과 식량 불안정이 심각한 상황에 처해 있으며, 이러한 배경 속에서 고구마는 중요한 영양 공급원으로 주목받고 있다. 그러나 기후 변화로 인한 가뭄과 홍수는 작물에 큰 피해를 주고 있으며, 고구마도 예외가 아니다. 이에 본 연구는 딥러닝과 컬러 이미지를 활용하여 고구마의 수분 스트레스 수준을 분류하였다. 실험은 수분 스트레스 수준을 건조, 적습, 과습의 세 가지로 나누어 진행되었다. 연구 결과, CNN 모델을 이용한 분류에서 0.8의 정확도를 달성하였다. 본 연구는 고구마뿐만 아니라 다른 노지 재배 작물에서도 정밀한 관개 제어를 위한 중요한 기초 자료로 활용될 수 있을 것으로 기대된다.","By 2050, the global population is projected to increase by 2 billion, with over half of this increase occurring in developing countries. According to the Food and Agriculture Organization, developing countries face severe challenges related to malnutrition and food insecurity, with sweet potatoes gaining attention as a vital source of nutrients. However, droughts and floods driven by climate change are causing significant damage to crops, including sweet potatoes. This study therefore utilized deep learning and RGB imagery to classify water stress levels in sweet potatoes. Water stress was categorized into three levels for the experiment: dry, normal, and overwatered. As a result, the convolution neural network model developed in this study achieved an accuracy of 0.8. This research is expected to serve as a valuable foundation for precise irrigation control, benefiting not only sweet potatoes but also other field crops."
인공위성 원격탐사 기반 메탄 배출 모니터링 기술 현황,2024,"['methane detection', 'convolutional neural network', 'satellite remote sensing', 'shortwave infrared (SWIR) band', 'greenhouse gases', '메탄 탐지', '합성곱 신경망', '위성 원격탐사', '단파장적외선 밴드', '온실가스']","메탄은 이산화탄소에 이어 두 번째로 지구온난화에 미치는 영향이 큰 온실가스로, 기후변화에 상당한 영향을 미친다. 본 논문에서는 메탄 배출을 효율적으로 탐지하고 정량화하기 위해 사용되는 인공위성 원격탐사 기반 메탄 탐지 기술을 종합적으로 검토하고자 한다. 메탄 배출원은 크게 자연적 배출원(영구동토, 습지)과 인위적 배출원(농축산업, 석탄광, 석유 및 가스전, 폐기물 처리)으로 구분된다. 이 중 인위적 배출원에 대해 단파장적외선을 포함한 다양한 파장영역의 정보를 활용한 메탄 탐지의 원리와 이를 지원하는 주요 위성자료의 활용성에 대해 고찰하였다. 최근에는 위성자료를 활용한 메탄 탐지에서 딥러닝 기법을 적용한 연구들이 진행되고 있으며 이는 메탄 배출을 보다 정확하게 분석하는 데 기여하고 있다. 또한, 딥러닝 기법 적용 사례를 포함하여 전 지구, 지역 및 대형 사고 규모에서의 메탄 배출 탐지 사례를 종합적으로 검토하고 위성 기반 메탄 모니터링의 실용성을 평가하였다. 전 지구 규모에서는 Sentinel-5P TROPOspheric Monitoring Instrument (TROPOMI)와 같은 위성 센서를 사용한 연구들이 검토되었고 지역 규모에서는 주로 TROPOMI 자료와 상대적으로 고해상도의 위성자료(Sentinel-2 MultiSpectral Instrument (MSI), GHGSat Wide-Angle Fabry-Perot (WAF-P) Imaging Spectrometer 등)를 결합하여 메탄 배출 및 배출량을 탐지한 연구 사례를 소개하였다. 이러한 종합적 검토를 통해 위성 기반 메탄 탐지 기술의 현황과 활용성을 평가하였다.","Methane is the second most significant greenhouse gas contributing to global warming after carbon dioxide, exerting a substantial impact on climate change. This paper provides a comprehensive review of satellite remote sensing-based methane detection technologies used to efficiently detect and quantify methane emissions. Methane emission sources are broadly categorized into natural sources (such as permafrost and wetlands) and anthropogenic sources (such as agriculture, coal mines, oil and gas fields, and landfills). This study focuses on anthropogenic sources and examines the principles of methane detection using information from various spectral bands, including the shortwave infrared (SWIR) band, and the utilization of key satellite data supporting these technologies. Recently, deep learning techniques have been applied in methane detection research using satellite data, contributing to more accurate analyses of methane emissions. Furthermore, this paper assesses the practicality of satellite-based methane monitoring by synthesizing case studies of methane emission detection at global, regional, and major incident scales, including examples of applying deep learning techniques. At the global scale, research utilizing satellite sensors like the Sentinel-5P TROPOspheric Monitoring Instrument (TROPOMI) was reviewed. At the regional scale, studies were highlighted where TROPOMI data was combined with relatively high-resolution satellite data, such as the Sentinel-2 MultiSpectral Instrument (MSI) and GHGSat Wide-Angle Fabry-Perot (WAF-P) Imaging Spectrometer, to detect methane emissions and sources. Through this comprehensive review, the current state and applicability of satellite-based methane detection technologies are evaluated."
저해상도 적외선 이미지 기반 실시간 노인 낙상 검출,2024,"['Fall', 'Low resolution image', 'Infrared sensor', 'Privacy protection', 'Fall detection system']","현대 사회에서 노인 인구의 비율은 점차 증가하여 헬스 케어에 대한 수요가 점차 증가하고 있다. 낙상은 노인 인구의 주요 상해원인으로, 본 논문은 저해상도 적외선 이미지를 사용하여 노인의 낙상을 실시간으로 감지하는 심층신경망 기반 낙상 탐지 시스템을제안한다. 저가형 적외선 장비를 사용하여 영상을 취득함으로써 비용 절감 및 사생활 문제를 해결하였으며, 그럼에도 높은 수준의인식 성능을 유지하기 위해 낙상의 흐름을 효과적으로 인식하는 다중 프레임 입력 기반 합성곱-LSTM 모델을 설계하였다. 이는eHomeSeniors 낙상 탐지 데이터 셋에 96.1%의 정확도를 달성하여 제안하는 저비용의 사생활 보장 낙상탐지 시스템의 성능을 증명한다.","In modern society, the proportion of elderly population is gradually increasing, leading to a rising demand forhealthcare. Falls are a major cause of injury among the elderly, and this paper proposes a deep neural networkasedfall detection system that uses low-resolution infrared images to detect falls in real-time. By acquiring imagesthrough cost-effective infrared equipment, we address both cost reduction and privacy issues, yet maintain highrecognition performance by designing a convolutional-LSTM model that effectively recognizes the flow of fallsthrough multi-frame input. This approach achieved 96.1% accuracy on the eHomeSeniors fall detection dataset,demonstrating the performance of the proposed cost-effective, privacy-preserving fall detection system."
실시간 지하공동구 화재 온도 예측을 위한 Residual CNN-LSTM 모델 연구,2024,"['underground utility tunnel', 'fire temperature forecasting', 'residual learning', 'convolutional neuraln Network(CNN)', 'long-short term memory(LSTM)', '지하공동구', '화재 온도 예측', '잔차 학습', '합성곱 신경망', '장단기 메모리']",,"Underground utility tunnels (UUTs) play major roles in sustaining the life of citizens and industries with regard to carrying electricity, telecommunication, water supply pipes. Fire is one of the most commonly common disasters in underground facilities, which can be prevented through proper management. This paper proposes a hybrid deep learning model named Residual CNN-LSTM to predict fire temperatures. Scenarios of underground facility fire outbreaks were created and fire temperature data was collected using FDS software. In the experiment, we analyzed the appropriate depth of residual learning of the proposed model and compared the performance to other predictive models. The results showed that RMSE, MAE and MAPE of Residual CNN-LSTM are each 0.061529, 0.053851, 6.007076 respectively, making Residual CNN-LSTM far superior to other models in terms of its predictive performance."
자기 교사 학습 모델의 특장점 분석과 사진 분류 및 객체 탐지 성능 분석 연구,2024,"['self-supervised learning', 'contrastive learning', 'knowledge distillation', 'computer vision', 'object detection', 'semantic segmentation', 'convolutional neural network', 'transformer', '자기 교사 학습', '대조학습', '지식 증류', '컴퓨터 비전', '객체 탐지', '객체 분할', '합성곱 신경망', '트랜스포머']","최근, 교사 학습 기반의 인공지능 분야가 급속도로 발전하고 있다. 그러나 교사 학습은 정답 값이 지정된 데이터집합에 의존하기 때문에, 정답 값을 확보하기 위한 비용이 커진다. 이러한 문제점을 해결하기 위해 정답 값없이 사진의 일반적인 특징을 학습할 수 있는 자기 교사 학습(Self-supervised learning)이 연구되고 있다. 본 논문에서는 다양한 자기 교사 학습 모델을 학습 방식과 백본 네트워크 기준으로 분류하고, 각 모델의 장단점, 성능을 비교 분석하였다. 성능 비교를 위해 사진 분류 작업을 사용하였다. 또한 전이 학습의 성능을 비교하기 위해 세밀한 예측 과업의 성능 또한 비교 분석하였다. 그 결과, 긍정적 쌍만 사용하는 모델이 노이즈를 최소화하여 부정적인 쌍을 같이 사용하는 모델들보다 높은 성능을 달성하였다. 또한 세밀한 예측의 경우 이미지를 마스킹하여 학습하거나 멀티스테이지 모델 등을 활용하여 지역적인 정보를 추가로 학습하는 방식이 더욱 높은 성능을 달성한 것을 확인하였다.","Recently, the field of teacher-based artificial intelligence (AI) has been rapidly advancing. However, teacher-based learning relies on datasets with specified correct answers, which can increase the cost of obtaining these correct answers. To address this issue, self-supervised learning, which can learn general features of photos without needing correct answers, is being researched. In this paper, various self-supervised learning models were classified based on their learning methods and backbone networks. Their strengths, weaknesses, and performances were then compared and analyzed. Photo classification tasks were used for performance comparison. For comparing the performance of transfer learning, detailed prediction tasks were also compared and analyzed. As a result, models that only used positive pairs achieved higher performance by minimizing noise than models that used both positive and negative pairs. Furthermore, for fine-grained predictions, methods such as masking images for learning or utilizing multi-stage models achieved higher performance by additionally learning regional information."
인공지능의 민사책임에 대한 소고,2024,"['AI', 'Generative AI', 'Civil Liability', 'Product Liability', 'Pharmaceuticals manufactured using generative AI', 'Strict Liability', '인공지능', '생성형 인공지능', '민사책임', '생성형 인공지능 기술 활용 의약품', '위험책임', '제조물책임']","최근의 인공지능 기술의 발달은 그 속도나 규모의 면에서 인류사의 어느 시기보다 가장 빠른 변화를 가져오고 있다. 기술의 발달로 데이터베이스를 통하여 생성된 자료를 통한 훈련으로 의료용 인공지능의 한계가 극복되는 등, 2012년에 합성곱 신경망 (CNN)으로 이미지처리에 대한 딥러닝이 본격화 된 이래 인공지능 기술은 눈부시게 발달해 왔다. 최근의 로봇의 자연어 처리 발전에 고급자연어처리(Natural Language Processing, 이하 ‘NLP’)를 통하여 인공지능의 활용이 가속화 되고 있다. 이러한 NLP의 활용은 언어가 아무리 복잡하더라도 기계가 데이터를 식별하고 이해할 수 있게 되어 더욱 빠르고 정확한 생성형 인공지능의 발달의 초석이 되었다. 그렇다면 발달의 속도를 멈추지 않는 인공지능, 생성형 인공지능이 활용되는 시대에 인공지능의 활용으로 발생한 손해에 대해서는 인공지능이 가진 생래적인 특성인 예측불가능성과 불투명성을 시작으로 블랙박스 효과등의 특성을 고려하여 우리 민법의 책임원리에 인공지능의 민사책임을 대입해 보았다. 그러기 위해서는 먼저, 인공지능으로 인한 불법행위책임을 논의함에 있어서 인공지능의 기술 발달 단계를 고려한 법적 책임을 판단해 보고 ‘약한 인공지능’이라 하더라도 인공지능 개발자에 의하여 창조된, “지배 가능한 위험(Gefahr)에 해당” 될 수 있으며, 모든 유형은 아니더라도 일부에는 무과실책임인 위험책임의 적용 가능성이 있음을 살펴 보았다. 아울러, 인공지능에 적용가능한 민사책임을 과실책임과 무과실책임으로 나누어 검토하면서, 비교법적으로는 EU의 흐름도 살펴보았다.그러나 무과실책임에 있어서 제조물책임법을 논의하면서 기존의 제조물책임법의 한계점을 극복하기 위한 대표적 사례로서 생성형 인공지능 기술을 활용한 의약품 제조에 위험책임을 적용할 수 없는지 그 가능성과 시사점을 살펴 보았다. 인류는 현재 가장 빠른 기술의 발달 시대와 폭발하는 빅 데이터의 시대에 살고 있으며 기술의 발달로 인하여 인류는 많은 이익을 누릴 수 있게 되었다. 기술의 발전에 따라서 사용자의 편의가 개선되고 막대한 부가 창출되는 만큼, 민사책임 영역에서의 위험책임의 의미가 더욱 의미를 가질 수 있다. 생성형 인공지능은 이미 신약개발에 소요되는 비용과 시간을 혁신적으로 줄여주어 제약회사에는 막대한 이윤을 주는 반면, 기존의 제조물책임법을 적용하더라도 설계상의 결함에 대하여 합리적인 대체가능성에 대한 면책가능성이 있어 피해자의 손해를 적절히 구제하기 어렵다. 생성형 인공지능의 시대, 의약품 제조라는 사례를 상정하여 보다 강화된 위험책임의 적용가능성을 고찰해 보았다.","The recent development of artificial intelligence (AI) technology is bringing about changes at a faster pace and on a larger scale than any other period in human history. With technological advancements overcoming the limitations of medical AI through training with databases, AI technology has made remarkable progress since the inception of deep learning for image processing with convolutional neural networks (CNN) in 2012. The recent advancements in natural language processing (NLP) have accelerated the utilization of AI through sophisticated natural language processing, enabling machines to identify and understand data regardless of the complexity of the language. This has laid the foundation for the rapid and precise development of generative AI. In the era where generative AI is being utilized without pausing in its developmental speed, we considered the civil liability of AI in our civil law principles, taking into account the inherent characteristics of AI such as unpredictability, opacity, and the black box effect.To do this, we first examined the legal liability considering the stages of AI technology development in discussing the tort liability caused by AI. Even “Weak AI,” created by AI developers, may fall under “Gefahr,” and while not all types, some may apply to strict liability in terms of risk liability. Furthermore, while reviewing civil liability applicable to AI under fault-based and no-fault liability, we also looked at the trends in the EU comparatively.In discussing no-fault liability, particularly under the Product Liability Act, we examined the possibility and implications of applying risk liability to pharmaceutical manufacturing using generative AI technology as a representative example to overcome the limitations of the existing Product Liability Act. Humanity currently lives in an era of rapid technological development and exploding big data, enjoying numerous benefits due to these advancements. As user convenience improves and massive added value is created through technological progress, the meaning of risk liability in the realm of civil liability can gain more significance. Generative AI has already drastically reduced the costs and time required for new drug development, providing substantial profits to pharmaceutical companies. However, even if the existing Product Liability Act is applied, it may be difficult to adequately remedy the harm to victims due to the reasonable alternative possibility defense regarding design defects. In the era of generative AI, we examined the possibility of applying enhanced risk liability by assuming the case of pharmaceutical manufacturing."
단일 CNN 기반 AVM 영상에서의 주차 구획 검출 및 분할 동시 수행,2024,"['Automatic parking system(자동 주차 시스템)', 'Parking slot detection(주차 구획 검출)', 'Parking slot segmentation(주차 구획 분할)', 'Convolutional neural network(합성곱 신경망)', 'Around view monitoring(AVM)(어라운드 뷰 모니터링)']",,
Enhancing Speech Emotion Recognition with Hybrid Graph Neural Networks: A GCN-GAT Framework,2024,"['Speech signal modeling', 'Graph Convolutional Networks (GCN)', 'Graph Attention Networks (GAT)', 'Emotion Recognition', 'Node Feature Extraction', 'Relationship Analysis', '음성 신호 모델링', '그래프 합성곱 신경망', '그래프 어텐션 신경망', '감정 인식', '노드 특성 추출', '관계 분석']",,"This paper proposes a speech emotion recognition method based on modeling speech signals as circular or linear graphs, enabling the extraction of node characteristics and practical analysis of relationships between nodes. The proposed method combines Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) layers to leverage the strengths of each in processing graph data. Precisely, GCN captures local relationships between nodes by aggregating information from neighboring nodes. The GAT mechanism better captures complex global relationships between nodes by assigning weights to neighboring nodes. Experiments validate our approach using the IEMOCAP dataset, demonstrating performance comparable to state-of-the-art models in emotion recognition tasks. The results of this study provide new insights and methodologies for further exploration in the field of speech signal processing."
웨이퍼 이송 로봇의 심층학습과 진동신호 기반 정렬 유격 이상 진단 시스템,2024,"['Wafer transfer robot', 'Deep learning', 'Fault diagnosis', 'Ball screw misalignment', 'Convolutional neural network', 'Explainable artificial intelligence', '웨이퍼 이송 로봇', '심층학습', '이상 진단', 'B(볼 스크류 유격 이상', '합성곱 신경망', '설명 가능한 인공지능']",,"In the semiconductor manufacturing industry, efficient operation of wafer transfer robots has a direct impact on productivity andproduct quality. Ball screw misalignment anomalies are a critical factor affecting precision transport of robots. Early diagnosis ofthese anomalies is essential to maintaining system efficiency. This study proposed a method to effectively diagnose ball screwmisalignment anomalies using 1D-CNN and 2D-CNN models. This method mainly uses binary classification to distinguishbetween normal and abnormal states. Additionally, explainable artificial intelligence (XAI) technology was applied to interpretdiagnostic decisions of the two deep learning models, allowing users to convince prediction results of the AI model. This studywas based on data collected through acceleration sensors and torque sensors. It compared accuracies of 1D-CNN and 2DCNNmodels. It presents a method to explain the model's predictions through XAI. Experimental results showed that theproposed method could diagnose ball screw misalignment anomalies with high accuracy. This is expected to contribute to theestablishment of reliable abnormality diagnosis and preventive maintenance strategies in industrial sites."
복합 임베디드 시스템 시계열 데이터를 활용한 딥러닝 이상 탐지 방법 비교 연구,2024,"['Deep Learning(딥러닝)', 'Anomaly Detection(이상 탐지)', '1D CNN(1차원 CNN)']","비행체 같은 복합 임베디드 시스템은 고장이 발생하면 심각한 위험을 초래할 수 있다. 본 논문에서는 복합 임베디드 시스템에서 출력되는 시계열 데이터 셋과 LSTM, 1차원 CNN과 같은 딥러닝 알고리즘을 활용하여 이상 탐지 모델을 생성하고 추론 결과를 비교했다. 그 결과 1차원 CNN 모델이 좋은 성능을 보였다. 이전 연구(합성곱 신경망을 활용한 항공 시스템의 이상 탐지 모델 연구)에서 생성한 2차원 CNN 모델의 추론 성능을 비교한 결과 정확도와 재현율은 2차원 CNN 모델이 높았지만, 추론 속도는 1차원 CNN 모델이 빨랐다. 실시간 이상 탐지가 필요한 복합 임베디드 시스템의 이상 탐지 모델에는 1차원 CNN 모델이 적합한 것으로 판단된다.","Complex embedded systems such as aircraft can lead to serious hazards when failures occur. This paper presents an anomaly detection model using deep learning techniques such as LSTM and 1D CNN on time-series datasets generated from complex embedded systems and compares inference results. Results showed that the 1D CNN model outperformed the LSTM model. Compared with the inference performance of a two-dimensional CNN model created in a previous study (Anomaly Detections Model of Aviation System by CNN), the two-dimensional CNN model had higher accuracy and recall. However, the 1-dimensional CNN model had faster inference speed. We can conclude that the 1D CNN model is more suitable than the LSTM model for anomaly detection in complex embedded systems that require real-time anomaly detection."
딥러닝과 해양환경 연속관측자료를 활용한 저층 용존산소 시간 변동 예측,2024,"['빈산소', '양식장', '저층 용존산소', '딥러닝', '예측', 'Hypoxia', 'Aquaculture', 'Bottom dissolved oxygen', 'Deep learning', 'Prediction']","최근 빈산소수괴의 규모와 빈도가 지속적으로증가하고 있어 양식생물 집단폐사 등 수산업에 심각한 경제적 피해를 발생시키고 있다. 양식 현장에서 빈산소수괴로 인한 피해를 최소화하기 위해서는 빈산소수괴발생 시기를 사전에예측하여 조기 대응할 수 있는 예측모델 구축이 필요하다. 본 연구에서는 딥러닝기반 시계열 예측에특화된 순환신경망 모델 중 Long Short-Term Memory(LSTM), Gate Recurrent Unit(GRU)과합성곱 신경망인 1-Dimension Convolution Neural Network(1D-CNN)을 활용하여 저층용존산소의 변동을 예측한 후 모델별로 성능을 평가하였다. 딥러닝모델의 입력자료는 당동만 해역에서 2019년부터 2022년 사이에 연속 관측된 층별 해양환경자료를 사용하였다. 2019년과2021년 자료는 모델의학습 및 검증자료로사용하였고 2022년 자료를 예측하여 관측자료와비교·검증하였다. 모델의예측 정확도에 영향을 미치는 최적의 입력자료와 매개변수를 선정하기위해 Pearson 상관관계와 Mutual Information(MI) 분석, 시행착오법을 수행하였다. 그 결과 GRU 모델과 1D-CNN 모델의 성능이 LSTM 모델보다 성능이 우수한 것으로 나타났다. 예측선행시간이 증가할수록LSTM 모델의 단주기 변동 패턴의 재현성이 감소하였는데, 이는 각모델 간 구조에 기인한 결과로 나타났다. 본 연구를 통해시계열 예측에 딥러닝 모델을 적용할 경우 데이터 특성을 반영한 모델을 활용해야 함을 알 수 있었다. 향후 신뢰성 있는 양질의 입력자료 확보와 매개변수 조정을 통해 모델의 예측 오차를 줄일 경우 향상된 예측 정확도와 48시간 이상의 예측시간을 확보할 수 있을것으로 판단된다.","In recent years, the scale and frequency of hypoxia events have continued to increase, causing serious economic damage to the fishery industry, including mass mortality of aquaculture organisms. In order to minimize the damage caused by hypoxia in aquaculture, it is necessary to build a prediction model that can predict the timing of hypoxia in advance and respond to it early. In this study, recurrent neural network models specialized in time series prediction, Long Short-Term Memory(LSTM), Gate Recurrent Unit(GRU), and 1-Dimensional Convolution Neural Network(1D-CNN), a convolutional neural network, were used to predict the variation of bottom dissolved oxygen, and the performance of each model was evaluated. The input data for the deep learning models were layer by layer marine environmental data continuously observed in the Dangdong bay from 2019 to 2022. The 2019 to 2021 data were used as training and validation data for the model, and the 2022 data were predicted and compared and validated with the observed data. Pearson correlation and mutual information(MI) analyses, trial and error methods were performed to select the optimal inputs and parameters that affect the prediction accuracy of the model. The results showed that the GRU model and 1D-CNN model outperformed the LSTM model. The reproducibility of the short-term variation pattern of the LSTM model decreased as the forecast lead time increased, which was attributed to the structure of each model. This study shows that when applying deep learning models to time series forecasting, it is necessary to use models that reflect data characteristics. In the future, if the prediction error of the model is reduced by securing reliable and high-quality inputs and adjusting the parameters, it is expected that improved prediction accuracy and a prediction time of more than 48 hours can be secured."
HRNet과 Transformer를 활용한 고해상도 위성영상의 구름탐지,2024,"['AIHub', 'Cloud Detection', 'HRNet', 'Satellite Imagery', 'Transformer', 'AIHub', '구름탐지', 'HRNet', '위성영상', '트랜스포머']","위성센서의 발달과 더불어 원격탐사 위성에 다양한 목적의 고해상도 센서가 탑재되어 발사되고 있으며, 높은 품질의 고해상도 위성영상에 대한 수요 또한 증대되고 있다. 사용자가 빠르게 고해상도 위성영상을 활용하기 위해서 는 방사보정, 정사보정 등의 전처리 과정이 적용된 ARD 형태의 자료가 필요하다. ARD 형태로 위성영상을 처리하기 위해서는 위성영상 내에 존재하는 구름 영역의 정보가 필요하며, 이를 위해 위성영상의 구름탐지 기법에 대한 다양한 연구들이 진행되고 있다. 본 연구에서는 고해상도 위성영상의 구름탐지를 위한 딥러닝 모델을 구성하고 이에 대한 성능 평가를 수행하였다. 특히, 대표적인 합성곱 신경망(Convolutional Neural Network)인 HRNet의 채널융합과정 내에 트랜스포머(Transformer)를 결합하여 딥러닝 모델의 성능을 향상시키고자 하였다. 또한, 훈련을 위해서 AIHub의 다목적실용위성을 이용한 구름탐지 훈련자료에 전처리 과정을 적용하여 학습의 성능을 향상시켰다. 실험결과, 전처리 과정이 적용된 훈련자료가 학습의 성능을 향상시키는 것을 확인하였다. 또한, 기존의 딥러닝 모델들과의 성능 평가를 통하여 제안한 딥러닝 모델이 효과적으로 구름지역을 추출할 수 있음을 확인하였다.","The demand for satellite imagery with high spatial resolution has increased since various remotely sensed satellite sensors such as KOMPSAT (Korean Multi-Purpose Satellite) and CAS (Compact Advanced Satellite) have launched. To quickly utilize high-resolution satellite imagery, ARD (Analysis Ready Data) with preprocessing steps such as radiometric and geometric corrections should be required. Various algorithms on cloud detection techniques for satellite imagery have been developed to process satellite imagery in ARD format. In this manuscript, a deep learning model for cloud detection in satellite imagery with high spatial resolution was developed. The Transformer layer was integrated within the channel fusion process of HRNet (High Resolution Network), which is one of the representative CNN (Convolutional Neural Network), to enhance the performance of the deep learning model. Additionally, the training performance by applying preprocessing steps was improved using AIHub's KOMPSAT training dataset for cloud detection. Experimental results represented that preprocessing of the training data improved the learning performance. Furthermore, through performance evaluation with existing deep learning models, it was confirmed that the proposed deep learning model could effectively extract cloud regions."
교량 모니터링 시스템의 취득데이터 오류신호 검지,2024,"['시설물 노후화', '유지관리', '모니터링 데이터', '오류신호 검지', 'Infrastructure aging', 'Maintenance and management', 'Monitoring data', 'Anomaly signal detection']",공용년수 30년을 초과하는 노후 SOC 시설물이 지속적으로 증가하고 있는 추세에서 시설물의 구조적 안전사고 발생위험성이 함께 증가하고 있어 시설물의 효과적 유지관리를 위한 모니터링 시스템 구축 및 운영이 필수적이다. 시설물의 비정상 거동 등으로 인해 발생하는 데이터는 일반적 상황에서 수집되는 데이터와 상이한 경향 또는 계측치를 나타내어 이러한 오류신호를 통해 시설물의 현재 상태및 앞으로의 상태를 예측할 수 있다. 본 연구에서는 다중선형회괴(MMLR) 학습 오류신호 검지 기법과 합성곱 신경망(CNN) 오류신호검지 기법을 활용하여 기존의 시설물 모니터링 데이터에 적용하여 기존 시설물 감시에 활용하고 있는 구조적 허용치 기반의 이상검지기법이 감지하지 못하는 비일상적 비정상적 데이터 오류신호의 검지 성능을 확인하였다.,"As aging SOC (Social Overhead Capital) facilities exceeding 30 years of service life continue to rise, the risk of structural safety incidentsin these facilities also increases. This underscores the necessity for establishing and operating an effective monitoring system for facilitymaintenance. Data generated by abnormal behavior in facilities often deviates in patterns or measurements from data collected undernormal conditions, allowing these anomalies to provide insights into the facility’s current and future state. This study applies a MultipleLinear Regression (MMLR) anomaly detection technique and a Convolutional Neural Network (CNN) anomaly detection technique toexisting facility monitoring data. By doing so, it evaluates the performance of these methods in detecting abnormal, non-routine anomaliesthat may not be identified by conventional structural threshold-based anomaly detection methods currently used in facility monitoring."
고갈 가스전에서의 CO2 저장관련인자 분석을 통한 기계학습 기반 저장효율지수 예측,2024,"['CO2  지중저장', '고갈 가스전', '저장관련인자', '기계학습', '저장효율지수', 'CO2 geological storage', 'depleted gas fields', 'storage factor', 'machine learning', 'storage efficiency index']","최근 CO2 지중저장이 탄소중립 달성을 위한 기술 중 하나로 부상하고 있다. 대상 저장소 중 고갈 가스전은 무결성과 안정성이 높아 저장에 용이하나 고갈 가스전에서 잔류 및 용해 포획을 통한 저장안정성 및 효율 분석 연구는 전무하다. 이 연구에서는 고갈 가스전에 대한 주입 시뮬레이션을 통해CO2 저장안정성 및 효율에 영향을 미치는 저장관련인자를 입력자료로 한 기계학습 기반의 저장효율지수 예측모델을 구축하여 신뢰성을 평가하였다. 그 결과 주입률, 최대 저류층압력, 공극률, 유체투과도, 온도의 영향을 확인하였으며, 저장효율지수 예측 시 랜덤 포레스트, 서포트 벡터머신, 익스트림 그래디언트 부스팅, 합성곱 신경망의 적용성을 검토하였다. 이는 향후 현장 고갈 가스전 정보를 기반으로 신뢰성 있는 저장효율지수 예측을 위한 사전연구로서 유의미하다고 판단된다.","Recently, CO2 geological storage has been increasingly utilized as a technical solution for achieving carbon neutrality. Depleted gas fields are particularly beneficial because of their integrity and stability. However, no analyses have been conducted regarding storage stability and efficiency through residual and solubility trapping. In this study, injection simulations on a depleted gas reservoir model were performed to identify the factors affecting CO2 storage. Machine learning models were developed and evaluated using these data to reliably predict the storage efficiency index. The results confirmed the impact of the injection rate, maximum reservoir pressure, porosity, permeability, and temperature on storage efficiency. The applicability of random forests, support vector machines, extreme gradient boosting, and convolutional neural networks for predicting the storage efficiency index was reviewed. This study provides foundational data for the reliable prediction of storage efficiency using information from depleted gas fields."
클라우드 이상 행위 탐지를 위한 1-D STM 블록 기반 Stacking CNN 모델,2024,"['Cloud System Security', 'Anomaly Detection', 'Deep Learning', 'Stacking CNN', '클라우드 시스템 보안', '이상 탐지', '딥러닝', 'Stacking CNN']","클라우드 컴퓨팅 기술은 클라우드 서비스의 핵심 기술이며, 사용자에게 공간의 제약 없이 특정 물리 서버의 자원을 필요한 만큼 제공한다. 이러한 클라우드 컴퓨팅 기술은 데이터 수집및 분석, 의사 결정을 빠르고 효율적으로 수행하는 장점을 가지지만, 보안 위협에 취약한 단점을 가진다. 따라서, 클라우드 컴퓨팅 기술의 보안 위협에 대응하기 위해 침입 탐지 시스템이 필요하다. 최근 침입 탐지 시스템 중 합성곱 신경망(CNN) 기반 이상 행위 탐지 연구가활발히 진행되고 있다. 하지만, CNN 기반 이상 행위 탐지 모델은 이상 행위에 대한 세부 수준 및 추상 수준의 특징 추출 한계점이 존재한다. 따라서, 본 논문에서는 CNN 기반 이상 행위 탐지 모델의 한계점을 극복할 수 있는 1-D STM 블록과 이를 기반으로 설계한 StackingCNN 기반 이상 행위 탐지 방안을 제안한다. 실험을 통해 Stacking CNN 기반 이상 행위 탐지 방안은 클라우드 보안 위협에 대응할 수 있는 이상 행위 탐지 모델임을 검증하였다.","As a core technique of cloud service, cloud computing technique provides userswith the resources of a specific physical server without spatial constraints. Eventhough such cloud computing technique performs data collection, analysis, anddecision-making quickly and efficiently, it is vulnerable to security threats. Thus,an intrusion detection system is needed to defend against such security threats.Recently, convolutional neural network(CNN)-based anomaly detection methodshave been actively studied. However, the existing CNN-based anomaly detectionmethods have limitations in extracting detailed and abstract-level features forabnormal behaviors. Therefore, In this paper, we propose an 1-D STM block whichovercomes the limitations of existing CNN-based anomaly detection methods. Also,we propose a new anomaly detection method using Stacking CNN model based onthe 1-D STM blocks. From the experimental results, we validate that the proposedanomaly detection method is effective in mitigating cloud security threats."
악성 췌장 병변 진단에서 인공지능기술을 이용한 초음파내시경의 응용,2024,"['Key Words: Artificial intelligence (AI)', 'Endoscopic ultrasound (EUS)', 'Pancreatic neoplasms Copyright ⓒ Korean Society of Gastrointestinal Cancer Research. This is']","췌장암(pancreatic cancer, PC)은 가장 치명적인 암으로 5년 전체 생존율(5-year overall survival rate)은 모든 병기에서 9%로 4기 질환의 경우 3%에 불과하다[1]. 현재 악성 췌장 병변의 진단에는 CT 스캔, 자기공명영상(magnetic resonance imaging), 초음파내시경(endoscopic ultrasound, EUS) 등 다양한 기법이 사용되고 있는데, 이중에서도 초음파내시경(EUS)은 췌관 암종(pancreaticductal adenocarcinoma) 및 췌관 선상세포 암종(pancreatic acinar cell carcinoma)과 같은 외분비계 세포에서 발생하는 악성 종양뿐 아니라 신경내분비 종양(pancreatic neuroendocrine tumors, PNETs), 췌장 낭포성 병변(pancreatic cystic lesions)과 같은 내분비 세포에서 발생하는 악성 췌장 병변의 진단에도 매우 유용하다[2]. 하지만, 만성 췌장염(chronic pancreatitis,CP)이 동반된 경우 EUS는 특이도가 낮아 감별 진단이 어렵고[3], 또한 시술자의 의존도가 높아 진단이 주관적일수 있어 아직까지는 초음파내시경 유도하 세침 흡인 생검술(endoscopic ultrasound guided fine needle aspiration)을 이용한 세포학적 진단이 췌장암 진단의 goldstandard이다.인공지능(artificial intelligence, AI)은 생물학적 두뇌를 학습하고 모방하기 위해 개발된 모든 컴퓨터 시스템에 적용되는 기술로 특히, 머신 러닝(machine learning, ML)은 대량의 데이터를 이용해 다양한 패턴을 찾아내는 AI의 한 형태다(Fig. 1) [4]. 이러한 ML에는 지도 학습(supervised learning), 비지도 학습(unsupervised learning), 강화 학습(reinforced learning)의 세 가지 유형이 있는데, 이중 지도 학습은 의학, 특히 진단 분야에서 연구되고 응용이 되고 있다. 특히, EUS에서는 신경망(neural networks, NN)이라고도 불리는 인공 신경망(artificial neural networks, ANN)과 서포트 벡터 머신(support vector machine, SVM)이라는 두 가지 유형의 지도 학습 방법이 연구되었다[5]. 딥 러닝(deep learning, DL)은 ANN에서 유래한 고급 개념으로, 인간 두뇌의 뉴런에서 영감을 받아 ANN의 여러 복잡한 층을 사용한다. 최근 널리 쓰이는 DL 알고리즘의 중 하나인 합성 곱신경망(convolutional neural network, CNN)은 데이터에서 지식을 추출해 학습이 이루어졌지만, 데이터의 특징을 추출하여 특징들의 패턴을 파악하는 알고리즘이다.반면, support vector machine (SVM)은 이미 입력 및 출력으로 훈련된 매우 많은 양의 데이터가 공급되는 지도ML 유형으로 훈련을 위해 더 많은 데이터 입력 없이는 더 많은 범주 지식을 자체 학습할 수 없다[6].지난 몇 년 동안 인공지능(AI) 활용이 의료 전반에 걸쳐 급격히 확대되었으며, Xu 등[7]은 EUS 영상을 이용하여 췌장암에서 예후 평가에 대한 연구를 시행하여 발표하였다. 실제로 2015년부터 2023년까지 PubMed 검색에서 인공지능, 췌장암을 핵심 용어로 조사해보면 발표된 연구 수가 기하급수적으로 증가했음을 알 수 있다(Fig. 2). 본고에서는 문헌 고찰을 통한 췌장 악성종양 진단에 대한 EUS 기반 AI 연구에 대한 효능에 대해서 논의하고자 한다.","Pancreatic cancer is a highly fatal malignancy with a 5-year survival rate of < 10%. Endoscopic ultrasound (EUS) is a useful noninvasive tool for differential diagnosis of pancreatic malignancy and treatment decision-making. However, the performance of EUS is suboptimal, and its accuracy for differentiating pancreatic malignancy has increased interest in the application of artificial intelligence (AI). Recent studies have reported that EUS-based AI models can facilitate early and more accurate diagnosis than other preexisting methods. This article provides a review of the literature on EUS-based AI studies of pancreatic malignancies."
시계열 데이터를 위한 스파이크 인코딩 최신 연구 동향,2024,"['Spiking neural network', 'Neuromorphic chip', 'Time series', 'Spike encoding']","스파이킹 신경망(Spiking Neural Network, SNN)은 실제 생물학적 뇌의 동작을 모사하여 스파이크로 알려진 이산 데이터를 통해 정보를 처리한다. 스파이크는 막전위가 임계치를 초과할 때 생성되며, 이렇게 생성된 스파이크는 SNN 내의 노드 간 정보 통신에 사용된다. 스파이크를 통한 정보 전송 방법은 스파이크 데이터의 희소성 특징 덕분에 에너지 절약에 있어서 효율적이다. SNN 모델은 스파이크의 발화 타이밍을 활용하여 시간 데이터를 처리하는 데에 적합하며, 심층 신경망(Deep Neural Network, DNN)에 비해 비교적 낮은 계산 비용으로 유사한 성능을 달성할 수 있는 이점을 제공한다. 본 연구에서는 시간 관련 정보를 효율적으로 처리하는 스파이크 인코딩 방법을 조사하고, 최근 스파이크 인코딩 기술을 아날로그 시계열 데이터에 적용하는 데 중점을 둔다. 본 논문에서는 HSA, BSA, Burst 및 TTFS 네 가지 인코딩 방법을 역합성곱 기반 인코딩 및 발화 시간 코딩 방법으로 분류한다. 더불어, 간단한 분류 모델을 사용하여 각 인코딩 방법에 따른 정확도를 측정하고 분석을 수행하고, 시계열 데이터 분류 작업에 가장 적합한 인코딩 방법을 제시한다.","A Spiking Neural Network (SNN) processes information through discrete electrical events, emulating the behavior of neurons observed in the brain, known as spikes. Spikes are generated when the membrane potential exceeds a specific threshold, and these generated spikes are used to communicate information between nodes within SNNs. This event-driven method of information transmission is energy-efficient because of the sparsity of spike data. SNN models can provide the advantage of accomplishing tasks with reduced computational resources, while enabling comparable performance to Deep Neural Networks (DNNs) in processing temporal data by leveraging spike timing. This research investigates methods for efficiently handling time-related information, with a focus on applying recent trends in spike encoding techniques to analog time-series data. We categorize four encoding methods - HSA, BSA, Burst, and TTFS - into deconvolution-based encoding and temporal coding methods. We measure their accuracy by utilizing a simple classification model and conduct analysis to identify the most suitable encoding method for time-series data classification task."
