title,date,keywords,abstract,multilingual_abstract
문자 인코딩 방식의 변화에 따른 트랜스포머 기반 침입탐지 모델의 탐지성능 비교,2024,[],"트랜스포머 모델의 핵심 요소인 토크나이저는 숫자 형태의 데이터를 제대로 이해하지 못한다. 따라서 패킷 페이로드를 문장처럼 학습하여 실제 네트워크에서 동작 가능한 트랜스포머 기반의 침입탐지 모델을 구축하기 위해서는 16진수 형태의 패킷 페이로드를 문자 형태로 변환하는 것이 필요하다. 이러한 문제 인식 하에 본 연구에서는 3종의 문자 인코딩 방식을 적용하여 패킷 페이로드를 숫자 및 문자 형태로 변환한 후 트랜스포머 모델에 학습시키면서 모델의 탐지성능이 어떻게 달라지는지를 분석하였다. 성능 분석 실험을 위한 데이터세트는 UNSW-NB15 데이터세트에 포함된 PCAP 파일에서 패킷 페이로드를 추출하여 구성하였으며, 학습 모델은 RoBERTa를 사용하였다. 실험 결과, ISO-8859-1 인코딩이 이진분류 및 다중분류에서 가장 우수한 성능을 달성하는 것으로 확인되었으며, 토큰의 수를 512개로 설정하고 최대 에포크를 15회로 증가한 경우에 다중분류 정확도가 88.77%까지 향상되었다.","A tokenizer, which is a key component of the Transformer model, lacks the ability to effectively comprehend numerical data. Therefore, to develop a Transformer-based intrusion detection model that can operate within a real-world network environment by training packet payloads as sentences, it is necessary to convert the hexadecimal packet payloads into a character-based format. In this study, we applied three character encoding methods to convert packet payloads into numeric or character format and analyzed how detection performance changes when training them on transformer architecture. The experimental dataset was generated by extracting packet payloads from PCAP files included in the UNSW-NB15 dataset, and the RoBERTa was used as the training model. The experimental results demonstrate that the ISO-8859-1 encoding scheme achieves the highest performance in both binary and multi-class classification. In addition, when the number of tokens is set to 512 and the maximum number of epochs is set to 15, the multi-class classification accuracy is improved to 88.77%."
비전 트랜스포머 모델 기반 한국인 얼굴 감정 분류 연구,2024,"['Computer Vision', 'Vision Transformer', 'Facial Expression Recognition', 'Emotion Classification', 'Fine-tuning']","인간의 표정은 기본적인 감정을 전달하는 표현 요소로써 인간과 컴퓨터 간의 상호작용에서 중요한 역할을 한다.컴퓨터 비전 및 머신러닝 분야에서는 최근 딥러닝을 기반으로 얼굴 표정을 기본 감정으로 분류하며, 그 중 합성곱 신경망(CNN: Convolution Neural Network) 기반의 모델이 주로 쓰이고 있다. 모델을 학습하는데 주로 쓰이는 데이터셋들은 다양한 인종이 섞여 있으며, 서양인의 얼굴 중심으로 이뤄져있다. 본 연구에서는 사전 학습된 비전 트랜스포머(ViT: Vision Transformer) 모델을 한국인의 얼굴 표정에 7가지 감정으로 라벨링되어 있는 데이터셋을 기반으로 파인튜닝한다. 모델에 입력하기 위해 데이터셋에서 제공되는 메타데이터에서 제공하는 얼굴의 좌표값을 활용하여 얼굴 부분을 크롭하고 총 70,000장의 이미지를 8:1:1의 비율로 분할하여 데이터셋을 재구성하였다. 학습된 한국인 얼굴 감정 분류 비전 트랜스포머는 전체 테스트 데이터셋에 대한 정확도 85.54 %를 기록하며 동일한 데이터셋을 사용한 합성곱 신경망 기반 모델에 비해 1.17 %의 성능 향상을 보였다. 다른 클래스들에 비해 낮은 성능을 보였던 불안, 슬픔을 나타내는클래스에 대해서도 성능을 개선하였다.","Facial expressions play an important role in human-computer interaction because they convey basic human emotions. In the field of computer vision and machine learning, deep learning has recently been used to classify facial expressions into basic emotions, with models based on convolutional neural networks being the most popular. Datasets that are mainly used to train the models are a mixture of various races, but mainly consist of Western faces. In this study, we fine-tune a pretrained vision transformer model based on a dataset of Korean facial expressions labeled with seven emotions. For input into the model, the dataset was reconstructed by cropping the faces using coordinates provided by the metadata in the dataset, splitting the 70,000 images at a ratio of 8:1:1. The trained Korean facial emotion classification vision transformer achieved 85.54% accuracy on the entire test dataset, showing a 1.17% performance improvement over a convolutional neural network model using the same dataset.We improved performance for classes representing anxiety and sadness, which had performed poorly compared to other classes."
트랜스포머 기반 군사용 자동음성인식 모델 제안 및 평가,2024,"['Automatic-Speech-Recognition', 'Transformer', 'Future-Warfare', 'End-to-end', 'Whisper']","현대 군사 환경에서는 정확하고 신속한 통신과 정보전달의 중요성이 강조되고 있다. 특히 전투 현장에서 양손에무기를 들고 전투를 실시하는 군인에게 있어 음성인식 기반의 정보전달 및 무인 무기체계 조종은 필수적이다. 본 연구에서는 트랜스포머 기반 음성인식 모델을 한국어 군사용어 음성 데이터를 군사 교범, 군사용어사전, 군사 간행물로 분류하여 각각 파인튜닝하여 성능을 평가하고 비교분석 하였다. 파인튜닝한 3개의 모델 모두 기존 음성인식 모델보다 나은성능을 보였으며, 특히 군사 교범을 학습한 모델이 가장 성능이 뛰어났다. 이는 같은 군사 데이터라도 군 내에서 사용되는 전술적 개념이나 특징 등이 포함된 데이터를 학습하는 것이 음성인식 모델의 성능을 더 많이 향상시킨다는 것을 알수 있었으며 이를 통해 트랜스포머 기반 음성인식 모델의 군사적 적용 가능성을 확인할 수 있었다.",다국어 초록 정보 없음
패킷 페이로드 분석과 오버샘플링을 적용한 트랜스포머 기반 침입탐지 모델,2024,"['.', 'intrusion detection', 'packet payload', 'oversampling', 'transformer', 'natural language processing']","인공지능을 기반으로 하는 침입탐지 모델들은 합성 데이터인 메타데이터를 학습하기 때문에 실제 네트워크에서 발생하는 패킷을 이용해 침입을 탐지하는 것이 제한된다. 그리고 학습 과정에서 데이터의 불균형 문제를 해결하지 못할 경우 다중분류에서 특정 클래스에 대한 탐지성능이 저하될 수 있다. 이러한 문제를 해결하기 위해 본 논문에서는 패킷 페이로드를 트랜스포머 기반의 언어모델을 통해 전처리 없이 분석하고, 오버샘플링을 적용하여 희소 클래스에 대한 탐지성능을 향상시킨 침입탐지 모델을 제안하였다. UNSW-NB15 데이터세트를 사용해 성능평가를 수행하였으며, 학습 모델은 RoBERTa 모델을 사용하였다. 실험 결과 ADASYN으로 오버샘플링을 수행했을 때 다중분류에서 가장 높은 정확도인 87.15%를 달성하였다.","Most intrusion detection models based on artificial intelligence use meta-data, which is synthetic data generated through packet analysis. Therefore, it is limited to detect intrusion using packets occurring in real networks. In addition, failure to solve the data imbalance problem in the learning process can significantly degrade detection performance for specific classes with a small number of data in multi-class classifications. To address these problems, we propose an intrusion detection model that analyzes packet payloads without preprocessing through a transformer-based natural language processing model and improves detection performance for rare classes through oversampling. We used UNSW-NB15 dataset for performance evaluation, and the RoBERTa model was used as the training model. As a result of the experiment, 87.15% of accuracy was achieved in multi-class classifications when oversampled with ADASYN."
특허상담 자동분류의 성능 향상 방안 연구: 트랜스포머 기반 인공지능 모델 버트(BERT)를 활용,2024,"['특허상담', '자동분류', '인공지능모델', '버트모델', '모델학습', 'Intellectual property consultation', 'automatic classification', 'artificial intelligence model', 'BERT model', 'model learning']",국문 초록 정보 없음,"Intellectual property customer counseling is an important public service that supports the creation of intellectual property rights and protection of the rights and interests of applicants and rights holders. To effectively support customers and secure the use of counseling content as a policy, counseling contents are classified according to certain criteria. Until 2020, it was professional counselors who directly classified these contents, but 2021 saw a shift toward automatic classification based on text analysis (TA) of the consultation texts. However, an investigation as to the distribution of counseling case classification over the past five years showed some differences between the 2018-2020 distribution, classified by professional counselors, and the 2021-2022 distribution, automatically classified by TA. Therefore, this study investigated how to improve the performance of the automatic classification system using BERT, a transformer-based AI model. After fine-tuning the BERT model, which was pre-trained using patent counseling text data and professional counselor classification values data, it was observed that the BERT’s automatic classification distribution was more similar to that of professional counselors than the classification distribution of the existing TA. These results show that the future application of the “Patent Consultation Classification BERT,” a tentative name for the model, to automatic patent consultation classification may yield a better performance than the current TA method. Furthermore, if the automatic classification results become more reliable through the use of this AI model, the purpose behind the policy for the automation of this procedure―namely easing the burden and improving the efficiency of professional counselors―may be achieved with improved continuity and stability. This may then enable a more accurate identification of the current status of patent customer counseling services and customer needs."
트랜스포머 모델을 활용한 전기차 배터리 SOH 예측 연구,2024,"['Finite element analysis', 'Proton exchange membrane', 'Fatigue failure', 'PEMFC', 'Hygrothermal load', 'User subroutine', '유한요소해석', '양성자교환막', '피로파손', '고분자 전해질 연료 전지', '수분/열하중', '사용자서브루틴']",국문 초록 정보 없음,"This paper presents a Transformer-based State of Health(SoH) estimation algorithm that is applied to publicly available NASA data. Data preprocessing involves the application of a moving average to reduce noise and utilize wavelet transformers to extract features. The preprocessed data serves as input to the Transformer model in estimating SoH. Next, a comparative analysis with an LSTM-based model is conducted by using the Root Mean Square Error(RMSE) metric. The proposed model demonstrates a superior SoH estimation accuracy, surpassing the LSTM-based model by up to 39.58 %."
트랜스포머 모델을 활용한 직무 추천 모델 개발에 관한 연구,2024,"['이력서 기반 직무 추천', '딥러닝', '트렌스포머 모델', 'Resume-based job recommendations', 'deep learning', 'Transformers models']",국문 초록 정보 없음,다국어 초록 정보 없음
전력 사용량 예측을 위한 새로운 트랜스포머 기반 모델,2024,"['Transformer', 'Time-Series Forecasting', 'Power Consumption', 'MLP', 'Depthwise Separable Convolution']",국문 초록 정보 없음,"Recently, Transformer has demonstrated excellent performance by effectively addressing the long-term dependency issues of traditional time series prediction models. However, Transformer also has limitations, such as a lack of ability to learn the sequential characteristics of time series data and the need for significant computational resources due to their complex structure. This paper proposes an EMformer model based on the Transformer architecture to overcome these limitations and improve prediction accuracy.EMformer reduces computational costs by replacing the decoder with an MLP and enhances sequential feature extraction by replacing the feed-forward neural network in the encoder with depthwise separable convolution. The model's performance is evaluated using power consumption dataset and compared with other time series prediction models. The results show that EMformer improve performance by up to 57.3% in MAPE and 30.75% in RMSE compared to other models."
순열 동변적인 데이터의 특성을 고려한 트랜스포머 구조 기반 다중 객체 이동 궤적 보간 모델,2024,"['시공간 데이터', '다중 객체 궤적 보간', '축구 이벤트 분류', '스포츠 데이터 분석', 'spatio-temporal data', 'multi-agent trajectory imputation', 'soccer event classification', 'sport data analysis']",국문 초록 정보 없음,"Following recent advancements in GPS and camera & computer vision technologies, it has become possible to acquire accurate trajectories of multiple agents in real-time. As a result, several applications and data analysis services utilizing multi-agent trajectories have been discussed.However, the acquired trajectories contain errors or missing values due to various technical and physical limitations, which lead to the degradation of the quality of both the application systems and data analysis results. In this paper, we propose deep learning-based multi-agent trajectory imputation model that accurately imputes missing values from incomplete soccer player trajectories information that are partially obtained through GPS devices or computer vision-based object tracking systems. In particular, considering that the data is provided in the form of a set of 2D coordinates which is permutation invariant, we design a deep neural network based on the Set Transformer model to take into account the permutation invariant nature of the data. To evaluate how the proposed model can accurately impute missing trajectories, we utilize multi-agent trajectory data collected from real-world soccer matches. In addition, we propose a soccer event prediction model to verify that accurately imputed trajectories can alleviate the deterioration of the performance in the event classification task when imputed trajectories are used as input data."
향상된 흉부 엑스레이 진단을 위한 멀티 클래스 토큰 기반 하이브리드 트랜스포머 모델,2024,"['Chest X-ray', 'Vision transformer', 'Multi-label classification', 'Deep learning']","흉부 엑스레이(Chest X-ray)는 폐의 이상을 진단하고 발견하는 데 일반적으로 사용되는 의료 영상 기술 중 하나로 딥러닝, 특히 컨벌루션 신경망 (Convolutional Neural Network, CNN)을 기반으로 한 컴퓨터 보조 진단(Computer Aided Diagnosis, CAD) 시스템은 의사들의 진단을 돕는데 많이 활용되고 있다. 이 연구에서는 CNN과 트랜스포머를 효과적으로 통합하여 흉부 질환의 분류 성능을 높이는 새로운 모델, 즉 Multi-Class Token CheXFormer (MCTCheXFormer)를 제안한다. 이 모델은 convolution 연산과 self-attention 메커니즘을 사용하여 흉부 엑스레이 내 지역 및 전역적인 특징을 효과적으로 활용하도록 설계되었다. MCTCheXFormer는 트랜스포머와 흉부 엑스레이 분류에서 뛰어난 성능을 보여주는 CNN 모델인 CheXNet으로 구성되며, 트랜스포머의 class token은 single-class token에서 multi-class token으로 확장하였다. 확장된 class token은 클래스별 특징을 학습하고 구분할 수 있도록 해 다중 레이블 분류 성능을 높였다. 또한, CheXNet을 통해 생성한 신뢰도 점수를 multi-class token에 attention 가중치로 적용하는 Iterative Class Token Weighting (ICW) 기법을 제안하여 모델의 흉부 질환 분류 성능을 높이고자 하였다. 제안 모델의 트랜스포머는 Pyramid Vision Transformer (PVT)를 기반으로 하고 있으며 총 4단계로 이루어져 있다. Token refinement 모듈을 추가하여 각 단계에서 생성되는 다양한 크기의 patch token의 차원과 multi-class token의 차원이 같도록 조절하였다. 제안한 MCTCheXFormer는 14개의 흉부 질환에 클래스 레이블을 제공하는 ChestX-ray14 데이터셋에서 CNN 또는 트랜스포머를 사용하는 기존 흉부 엑스레이 분류 모델과 비교하였다. 비교 결과 MCTCheXFormer는 다른 모델 대비 뛰어난 성능을 보였고, 이를 통해 흉부 질환에서 정확하고 효율적인 진단을 위한 트랜스포머의 활용 가능성을 보여주었다.","Chest X-rays are commonly used medical imaging techniques for diagnosing and detecting lung abnormalities. Computer-aided diagnosis (CAD) systems based on deep learning, especially convolutional neural networks (CNNs), have proven valuable in assisting doctors with these diagnoses. In this study, we propose a novel model, the Multi-Class Token CheXFormer (MCTCheXFormer), which integrates CNNs and transformers to enhance chest disease classification performance. This model leverages both convolutional operations and self-attention mechanisms to effectively capture local and global features in chest X-rays. MCTCheXFormer combines a transformer with CheXNet—a CNN model known for its strong performance in chest X-ray classification. Here, the transformer's class token is extended from a single-class token to a multi-class token, enabling it to learn and differentiate class-specific features and improve multi-label classification. Additionally, we introduce an Iterative Class Token Weighting (ICW) technique, which applies the confidence scores generated by CheXNet as attention weights to the multi-class tokens, further enhancing classification performance. The model’s transformer is based on the Pyramid Vision Transformer (PVT) and consists of four stages. A token refinement module is added to ensure that the dimensions of the patch tokens generated at each stage align with those of the multi-class tokens. We evaluated the proposed MCTCheXFormer on the ChestX-ray14 dataset, which provides class labels for 14 chest diseases, comparing it with existing CNN- and transformer-based models. MCTCheXFormer outperformed the other models, highlighting the potential of transformers for accurate and efficient chest disease diagnosis."
트랜스포머 기반 모델의 한국어 음성인식 성능 비교 연구,2024,"['딥러닝', '머신러닝', '음성인식', '음성공학', 'deep learning', 'machine learning', 'speech recognition']","트랜스포머 모델은 텍스트, 영상 등 순차적 입력 데이터에서 의미 있는 정보를 추출하는 데 뛰어난 성과를 보여주었으며, 음성인식 분야에서도 종단형 모델로서 주목받고 있다. 본 연구에서는 트랜스포머 음성인식 모델과 이를개선한 컨포머, E-브랜치포머 모델을 한국어 음성인식에 적용하여 성능을 비교하였다. AIHub에 공개된 한국어 음성 데이터를 활용하여 약 7,500시간의 훈련셋을 마련하고, ESPnet 툴킷을 활용하여 트랜스포머, 컨포머, E-브랜치포머 모델을 훈련하고 성능을 평가하였다. 또한, 인식 단위로 음절과 서브워드를 사용하는 경우를 비교하고, Byte Pair Encoding의 토큰 수 변화에 따른 성능 차이를 분석하였다. 실험 결과, E-브랜치포머가 한국어 음성인식에서 가장 우수한 성능을 보였으며, 컨포머는 트랜스포머보다 우수하였으나 긴 발화에 대해서는 성능 저하가 확인되었다.이러한 성능 저하의 원인으로 인코더-디코더의 크로스 어텐션 정렬 과정에 오차가 발생함을 확인하였다. 또한, 서브워드 인식 단위를 사용하면서 토큰 수를 조정할 때의 성능 변화에 대한 분석을 통해 최적의 설정을 찾고자 하였다. 본 연구는 모델의 정확도와 처리 속도를 종합적으로 평가하였으며, 이를 통해 한국어 음성인식의 효율성을 극대화할 수 있는 방법을 모색하였다. 대규모 한국어 음성인식 모델의 학습과 컨포머의 인식 오류 개선 연구에 기여할 수 있을 것으로 기대된다. 또한, 향후 연구 방향으로는 다양한 한국어 음성 데이터셋을 활용한 추가 실험과 더불어, 컨포머의 구조적 개선을 통한 인식 성능 향상을 목표로 한다.","Transformer models have shown remarkable performance in extracting meaningful information from sequential input data such as text and images, and are gaining attention as end-to-end models for speech recognition. This study compared the performances of the Transformer speech recognition model and its enhanced versions, the Conformer and E-Branchformer, when applied to Korean speech recognition. Using Korean speech data from AIHub, we prepared a training set of approximately 7,500 hours and evaluated the models using the ESPnet toolkit. Additionally, we compared syllables and subwords as recognition units and analyzed the performance differences with changes in the number of tokens using Byte Pair Encoding. The results showed that the E-Branchformer achieved the best performance in Korean speech recognition and Conformer outperformed Transformer but degraded in performance for long utterances owing to cross-attention alignment errors. We aimed to determine the optimal settings by analyzing the performance changes with subword token adjustments.This study comprehensively evaluated model accuracy and processing speed to maximize the efficiency of Korean speech recognition. This is expected to contribute to the training of large-scale Korean speech recognition models and improve Conformer recognition errors. Future research should include additional experiments with diverse Korean speech datasets and enhance the recognition performance through structural improvements in the Conformer."
실시간 비행 제어 데이터 예측을 위한 트랜스포머 모델의 경량화 연구,2024,"['Transformer(트랜스포머)', 'Deep learning(딥러닝)', 'Lightweight(경량화)', 'Efficiency(효율화)', 'Real-time data prediction(실시간 데이터 예측)']",국문 초록 정보 없음,다국어 초록 정보 없음
RMS 볼륨 특징을 이용한 배관계 누출 감지 비전 트랜스포머 모델에 대한 연구,2024,"['Vision transformer', 'Leak detection', 'Deep learning', 'RMS pattern feature', 'Patch embedding']","본 논문에서는 플랜트 배관 시스템의 미세 누출을 탐지하기 위해 특징 융합 기반의 비전 트랜스포머 모델을 제안한다. 누출 신호를 측정하기 위하여 여러 센서로부터 데이터 수집 환경을 구성하고, 시계열 데이터를 수집하였다. 수집된 데이터는 Root mean square (RMS) 패턴 특징으로 변환되며, 이러한 패턴은 센서 간 특징융합을 통해 볼륨 특징으로 재구성된다. 이러한 재구성된 데이터는 미세 누출 감지를 위해 비전 트랜스포머 모델로 학습된다. 실험 결과, 비전 트랜스포머 모델은 기존 신경망 기반 딥러닝 모델들의 성능을 능가하는 97.44%의 높은 정확도를 달성하였음을 확인할 수 있었다.","This paper proposes a vision transformer model based on feature fusion to detect micro-leaks in plant piping systems. To measure leak signals, a data collection environment with multiple sensors was configured, and time-series data were collected. The collected data are converted into root mean square (RMS) pattern features, which are then reconstructed into volume features through feature fusion among sensors. This reconstructed data are trained with the vision transformer model for detecting micro-leaks. Experimental results demonstrate that the vision transformer model achieves a high accuracy of 97.44%, surpassing the performance of existing neural network-based deep learning models."
비전 트랜스포머 기반 전이학습을 활용한 봉제 불량 검출 모델 연구,2024,[],"최근 딥러닝 모델, 비전 센서와 사물 인터넷 등의 정보통신기술이 급속히 발전하면서 다양한 분야 속 이미지 인식 및 분류 모델의 활용 사례도 늘어나고 있다. 이러한 최신 동향과 달리 의류 제조업은 여전히 작업자의 노동력에 의존적이며, 봉제선 불량과 같은 미세한 불량은 원단 불량 검출과 달리 적합한 검출 시스템이 제시되어 있지 않다. 본 연구에서는 봉제 불량 이미지를 자동으로 검출할 수 있는 ViT(Vision Transformer) 기반 전이학습 모델을 연구하였다. ViT 는 최근 컴퓨터 언어 분야에서 뛰어난 성능을 보이는 트랜스포머 기반 모델을 이미지 분석에 적용한 모델로 , 이미지를 여러 개의 패치로 나누어 각 패치를 단어 토큰으로 취급하여 시퀀스 데이터 처리에 최적화된 트랜스포머 아키텍처를 활용한다. 우선 Tensorflow 기반 ViT사전학습 모델을 구성하고, 전이학습을 통해 ViT 를 봉제선 불량 이미지 데이터셋을 분류할 수 있도록 학습하였다. 이를 통해, 구축된 ViT 기반 전이학습 모델로 10 종의 봉제선 불량 유형을 식별할 수 있음을 확인하였으며, 정확도는 96%를 달성하였다.",다국어 초록 정보 없음
비전 트랜스포머 기반 전이학습을 활용한 봉제 불량 검출 모델 연구,2024,[],"최근 딥러닝 모델, 비전 센서와 사물 인터넷 등의 정보통신기술이 급속히 발전하면서 다양한 분야 속 이미지 인식 및 분류 모델의 활용 사례도 늘어나고 있다. 이러한 최신 동향과 달리 의류 제조업은 여전히 작업자의 노동력에 의존적이며, 봉제선 불량과 같은 미세한 불량은 원단 불량 검출과 달리 적합한 검출 시스템이 제시되어 있지 않다. 본 연구에서는 봉제 불량 이미지를 자동으로 검출할 수 있는 ViT(Vision Transformer) 기반 전이학습 모델을 연구하였다. ViT 는 최근 컴퓨터 언어 분야에서 뛰어난 성능을 보이는 트랜스포머 기반 모델을 이미지 분석에 적용한 모델로 , 이미지를 여러 개의 패치로 나누어 각 패치를 단어 토큰으로 취급하여 시퀀스 데이터 처리에 최적화된 트랜스포머 아키텍처를 활용한다. 우선 Tensorflow 기반 ViT사전학습 모델을 구성하고, 전이학습을 통해 ViT 를 봉제선 불량 이미지 데이터셋을 분류할 수 있도록 학습하였다. 이를 통해, 구축된 ViT 기반 전이학습 모델로 10 종의 봉제선 불량 유형을 식별할 수 있음을 확인하였으며, 정확도는 96%를 달성하였다.",다국어 초록 정보 없음
SASRec vs. BERT4Rec: 트랜스포머 기반 순차적 추천 모델의 성능 분석,2024,"['순차적 추천 시스템', '딥러닝', '인공지능', '재현성', '트랜스포머', 'sequential recommender system', 'deep learning', 'artificial intelligence', 'reproducibility', 'transformer']","순차적 추천 시스템은 사용자 로그로부터 관심사를 추출하고 이를 바탕으로 사용자가 다음에 선호할만한 항목을 추천한다. SASRec과 BERT4Rec은 대표적인 순차적 추천 모델로 널리 활용되고 있다. 기존 연구들은 두 모델을 베이스라인으로 다양한 연구에 활용하고 있지만, 두 모델은 실험 환경 차이로 인해 일관된 성능을 보이지 않는다. 본 논문에서는 여덟 가지 대표적 순차적 추천 데이터셋에서 SASRec과 BERT4Rec의 성능을 비교 및 분석하여 검증한다. 이를 통해, 사용자-항목 상호작용 수가 BERT4Rec 학습에 가장 큰 영향을 미치며, 결국 이는 두 모델의 성능 차이로 이어진다는 사실을 관찰하였다. 더 나아가, 본 연구는 순차적 추천 환경에서 널리 활용되는 두 학습 방법 역시 인기도 편향과 시퀀스 길이에 따라 다른 효과를 보일 수 있음을 보인다. 이를 통해, 데이터셋 특성을 고려하는 것이 추천 성능 개선을 위해 필수적임을 강조한다.","Sequential recommender systems extract interests from user logs and use them to recommend items the user might like next. SASRec and BERT4Rec are widely used as representative sequential recommendation models. Existing studies have utilized these two models as baselines in various studies, but their performance is not consistent due to differences in experimental environments. This research compares and analyzes the performance of SASRec and BERT4Rec on six representative sequential recommendation datasets. The experimental result shows that the number of user-item interactions has the largest impact on BERT4Rec training, which in turn leads to the performance difference between the two models. Furthermore, this research finds that the two learning methods, which are widely utilized in sequential recommendation settings, can also have different effects depending on the popularity bias and sequence length. This shows that considering dataset characteristics is essential for improving recommendation performance."
트랜스포머 모델을 이용한 미래 혈당 예측 모델 개발,2024,"['트랜스포머(transformer)', '혈당(blood glucose)', '제2형 당뇨병(type 2 diabetes)']",국문 초록 정보 없음,다국어 초록 정보 없음
Pix2pix-Swin: Swin 계층적 영상 트랜스포머를 이용한 RGB-to-NIR 이미지 변환 모델 프레임워크,2024,"['RGB-to-NIR', 'Image translation', 'Autonomous driving', 'Near-infrared', 'perception in adverse weather']","RGB 이미지를 근적외선(Near-Infrared, NIR) 이미지로 변환하는 새로운 딥러닝프레임워크인 pix2pix-Swin을 제안한다. 근적외선(NIR) 이미지는 가시광선 스펙트럼을벗어난 파장을 감지하여 저조도 환경이나 악천후 상황에서도 사물 인식 능력을 제공할 수있다. 이러한 특성 덕분에 NIR 이미지는 안전이 중요한 자동차 등의 응용 분야에서 RGB 기반영상 기술에 비해 상대적인 이점을 제공할 수 있다. 제안된 프레임워크는 pix2pixHD 아키텍처를 기반으로 하며, Swin Transformer를 도입하여 성능을 향상시켰다. 프레임워크의평가를 위해 9개 카테고리로 구성된 공개 데이터셋인 NIRScene을 사용하였다. 실험 결과, pix2pix-Swin 모델은 PSNR, SSIM, FID 등의 정량적 평가 지표에서 기존 방식들을 능가하는성능을 보였다.","We propose a novel deep learning framework called pix2pix-Swin, which converts RGB images to Near-Infrared (NIR) images. NIR images capture wavelengths beyond the visible light spectrum, providing object recognition capabilities even in low-light environments or adverse weather conditions.This makes NIR imaging technology advantageous compared to RGB-based imaging technology, especially in safety-sensitive applications such as automotive sectors. The proposed framework is based on the pix2pixHD architecture, with the incorporation of the Swin Transformer to enhance performance. To evaluate the proposed framework, we used the publicly available dataset NIRScene, which consists of 9 categories. Experimental results demonstrate that the pix2pix-Swin model outperforms existing models across quantitative metrics, including Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Fréchet Inception Distance (FID)."
트랜스포머 기반 딥러닝 모델을 이용한 건물 변화탐지,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
트랜스포머 모델의 순방향 네트워크를 위한 관심사 기반 가지치기 기법,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
비전 트랜스포머 모델의 적대적 공격 취약성 연구: 완전 미세 조정과 프롬프트 튜닝 비교 고찰,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
레벤슈타인 트랜스포머 기반 빠른 추론이 가능한 음성 인식 모델에 관한 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
순환신경망과 트랜스포머 모델을 활용한 POMDP 환경에서의 강화학습 성능 개선에 관한 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
메모리 접근 효율을 고려한 트랜스포머 기반 모델들의 데이터 압축률 분석,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
시공간 종속성을 활용한 트랜스포머 모델 설계 및 교통 데이터 임퓨테이션,2024,"['Spatial Temporal Transformer Networks', '교통 데이터', '데이터 임퓨테이션']",국문 초록 정보 없음,다국어 초록 정보 없음
트랜스포머 기반 2-Phase 학습법을 통한 EEG 데이터 분류 모델 성능 개선,2024,[],국문 초록 정보 없음,"Electroencephalogram (EEG) brain signals provide a wealth of information, and Brain-Computer Interface (BCI) technology leveraging these signals offers hope for individuals with disabilities. Recent research has explored various fields with EEG signal like Motor Imagery, Emotion recognition etc. Among them, there are several studies on object imagery to synthesize object class from brain signals. However, previous work has demonstrated poor performance in EEG classification. This is because EEG signals have different characteristics from person to person, making them difficult to generalize, and it led to itself in differences between train and test performance. In our study, we address this limitation by employing a Transformer-based approach and a two-phase training strategy, leading to improved classifier performance. Consequently, our enhanced classifier show better performance and less gap between train and test performance. Also when we visualize the features for each class, we can see that they are organized into a better refined distribution by label. And we can expect that this can contribute to various applications including assistive technologies for individuals with disabilities."
강건한 양방향 트랜스포머 사전학습 언어모델 기반 암호화 트래픽 분류,2024,[],국문 초록 정보 없음,"The proliferation of internet service platforms has led to an increase in the volume and diversity of traffic data. Consequently, the need for traffic classification has become more pressing, necessitating new approaches to encrypted traffic classification. In this paper, we propose the Robust BERT for Encrypted Traffic Classification (RB-ET), a transformer-based model designed to overcome the limitations of traditional DPI methods. The RB-ET model enhances efficiency by removing NSP during pre-training and utilizing Half-Chance Label Prediction (HCLP) to enable learning from unlabeled data as well. Experimental results show that RB-ET has successfully improved the accuracy of encrypted traffic classification and reduced training time compared to existing models."
Segment representation을 이용한 트랜스포머 기반의 특허 문서 분류 모델,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
분자 도킹 시뮬레이션 데이터를 이용한 트랜스포머 기반 결합 친화도 예측 모델,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
구조적 주의집중 헤드 가지치기 기반 트랜스포머 모델 경량화,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 모델과 Transformer 조합을 통한 토지피복 분류 정확도 개선방안 검토,2024,"['원격탐사', '딥러닝', '트랜스포머', 'Unet', '토지피복', 'Remote Sensing', 'Deep Learning', 'Transformer', 'Unet', 'Land Cover']","본 연구는 Transformer 모듈을 기반으로 다양한 구조의 모델을 구성하고, 토지피복 분류를 수행하여 Transformer 모듈의 활용방안 검토를 목적으로 하였다. 토지피복 분류를 위한 딥러닝 모델은 CNN 구조를 가진 Unet 모델을 베이스 모델로 선정하였으며, 모델의 인코더 및 디코더 부분을 Transformer 모듈과 조합하여 총 4가지 딥러닝 모델을 구축하였다. 딥러닝 모델의 학습과정에서 일반화 성능 평가를 위해 같은 학습조건으로 10회 반복하여 학습을 진행하였다. 딥러닝 모델의 분류 정확도 평가결과, 모델의 인코더 및 디코더 구조 모두 Transformer 모듈을 활용한 D모델이 전체 정확도 평균 약 89.4%, Kappa 평균 약 73.2%로 가장 높은 정확도를 보였다. 학습 소요시간 측면에서는 CNN 기반의 모델이 가장 효율적이었으나 Transformer 기반의 모델을 활용할 경우, 분류 정확도가 Kappa 기준 평균 0.5% 개선되었다. 차후, CNN 모델과 Transformer의 결합과정에서 하이퍼파라미터 조절과 이미지 패치사이즈 조절 등 다양한 변수들을 고려하여 모델을 고도화 할 필요가 있다고 판단된다. 토지피복 분류과정에서 모든 모델이 공통적으로 발생한 문제점은 소규모 객체들의 탐지가 어려운 점이었다. 이러한 오분류 현상의 개선을 위해서는 고해상도 입력자료의 활용방안 검토와 함께 지형 정보 및 질감 정보를 포함한 다차원적 데이터 통합이 필요할 것으로 판단된다.","This research aimed to construct models with various structures based on the Transformer module and to perform land cover classification, thereby examining the applicability of the Transformer module. For the classification of land cover, the Unet model, which has a CNN structure, was selected as the base model, and a total of four deep learning models were constructed by combining both the encoder and decoder parts with the Transformer module. During the training process of the deep learning models, the training was repeated 10 times under the same conditions to evaluate the generalization performance. The evaluation of the classification accuracy of the deep learning models showed that the Model D, which utilized the Transformer module in both the encoder and decoder structures, achieved the highest overall accuracy with an average of approximately 89.4% and a Kappa coefficient average of about 73.2%. In terms of training time, models based on CNN were the most efficient. however, the use of Transformer-based models resulted in an average improvement of 0.5% in classification accuracy based on the Kappa coefficient. It is considered necessary to refine the model by considering various variables such as adjusting hyperparameters and image patch sizes during the integration process with CNN models. A common issue identified in all models during the land cover classification process was the difficulty in detecting small-scale objects. To improve this misclassification phenomenon, it is deemed necessary to explore the use of high-resolution input data and integrate multidimensional data that includes terrain and texture information."
Transformer 기반 LLM의 학습을 이용한 112 허위오인신고분류·예측모델 개발,2024,"['Transformer', 'NLP', '112', 'False Alarm', 'Binary Classification', '트랜스포머', '자연어처리', '112', '허위신고', '이진분류']","112 긴급신고 시스템은 국민 안전을 위한 경찰의 최전선으로, 신속한 출동 및 사건처리가 무엇보다도 중요하다.허위오인신고는 경찰력이 낭비될뿐 아니라 진정으로 도움을 필요로 하는 상황에 대응하기가 어려워진다는 점에서그 문제가 크다. 최근들어 증가하고 있는 허위오인신고에 대응하기 위하여 본 연구자는 딥러닝을 기반으로한 112 허위오인신고 분류·예측모델을 제안한다. 본 모델은 112상황실 접수요원이 요약한 신고내용 텍스트를 입력받아 해당 신고의 허위오인여부를 결정하게 된다. 악의적 허위신고와 오인신고중 후자는 신고접수자 입장에서 표면적으로알아채기가 불가능에 가깝다. 이로 인해 연구자는 허위오인신고 전체 데이터와 악의적인 허위신고만을 담은 데이터를 나누어 실험하였다. 트랜스포머 구조를 가진 BERT, KoBERT,ELECTRA, KoELECTRA, RoBERTa 5가지모델에 대하여 동일한 하이퍼파라미터로 모델 훈련을 진행했다. 본 연구는 자연어처리와 LLM을 이용하여 경찰의실제 치안업무에 대해 문제해결적 접근을 수행했다는 점에 의의가 있다. 본 연구의 결과가 악의적인 허위신고를빠르게 식별하고 경찰이 의사결정을 지원하는데에 도움이 될 것으로 기대한다.","The 112 emergency reporting system is the police's front line for public safety, and rapid dispatch and incident handling are of the utmost importance. False reports are problematic in that they not only waste police power, but also make it difficult to respond to situations that need help. In order to respond to the increase in false reports, this researcher proposes a 112 false report classification and prediction model based on deep learning. This model receives the report text summarized by the 112 situation room receptionist and determines whether the report is false or misidentified. Mistaken reports are almost impossible to detect on the surface from the point of view of the person who filed the report. Because of this, the researcher conducted an experiment dividing data containing all false reports and data containing only malicious false reports. Model training was performed with the same hyperparameters for five models with transformer structures: BERT,KoBERT, ELECTRA, and RoBERTa. This study is significant in that it took a problem-solving approach to the police's actual security work using natural language processing and LLM. It is expected that the results of this study will help identify malicious false reports and support police decision-making."
웹사이트 게시글 및 상품 리뷰 검색 기능 향상: ResNet-Transformer 모델을 이용한 BM25 랭킹 알고리즘 성능 개선,2024,"['레즈넷', '트랜스포머', '레즈넷-트랜스포머', '웹사이트 검색', '랭킹 알고리즘', 'BM25', 'ResNet', 'Transformer', 'ResNet-Transformer', 'Website search', 'BM25', 'Rangking algorithm']",국문 초록 정보 없음,"This paper proposes a method to improve the search functionality for website posts and product reviews by using a ResNet-Transformer model in conjunction with the BM25 ranking algorithm. BM25 is a widely used algorithm in text-based search that ranks documents by evaluating their relevance to user queries. However, it has limitations in capturing local features of words and understanding the context of a sentences. To address these issues, this study applies a classification approach that combines the ResNet model, which excels at extracting local features, with the Transformer model, known for its strong contextual understanding, as weights for BM25. Experimental results demonstrate that the proposed method improves the nDCG metric by 9.38% and the aP@5 metric by 11.82% compared to BM25 alone. This suggests that implementing this method in search engines across various websites can provide more accurate results for post and review searches."
드론 영상 인식과 Transformer를 활용한 도심 주행 차량의 차로 변경 예측 모델 연구,2024,"['드론 비전', '차로 변경 예측', 'traffic context', 'transformer', 'yolov8', 'drone-vision', 'lane change prediction', 'traffic context', 'transformer', 'yolov8']","차로 변경은 차량 간의 차선 간섭으로 인해 사고의 위험이 존재하며, 이에 따라 교통 흐름에 영향을 미친다. 따라서, 사고의 위험성을 줄이고 교통 시스템을 원활하게 하기 위해 차로 변경 예측에 관한 연구는 필요하다. 본 연구에서는 드론으로 수집된 차량의 탑 뷰(top-view) 영상 정보를 활용하여 차량에 대한 정보를 추출하고, 차로 변경을 예측하는 방법에 대하여 제시한다. 먼저, 영상 내 차량 객체 탐지를 위해 딥러닝 기반 객체 탐지 모델인 YOLOv8을 사용하였으며, 객체 정보를 바탕으로 Traffic Context를 추출한다. 추출된 정보를 바탕으로 Transformer 모델을 활용하여 차로 변경 예측을 수행한다. 본 연구 실험에서는 드론으로 촬영한 대전 유성구 구성동의 도로 상황 영상을 활용하였다. 실험 결과 YOLOv8의 객체 탐지 성능으로는 mAP50에서 0.99, mAP50-95에서는 0.75로 검출 객체와 실체 객체 간의 높은 일치도를 확인하였다. 차로 변경 예측 모델에서는 Transformer가 다른 모델들에 비해 0.02 높은 0.977의 Accuracy를 보였으며, 혼동 행렬에서 가장 낮은 오분류를 확인하였다. 본 연구가 향후 효율적인 교통 흐름 관리를 위한 자료로 활용되어 교통 시스템 개선에 기여할 수 있을 것으로 기대된다.","Lane changes pose a risk of accidents due to lane interference between vehicles, affecting traffic flow. Therefore, research on predicting lane changes is necessary to reduce accident risks and improve the traffic system. This study proposes a method for extracting vehicle information from top-view drone footage and predicting lane changes. We used the deep learning-based object detection model YOLOv8 for vehicle detection in the footage and extracted Traffic Context from the detected objects. Using this extracted information, we performed lane change prediction utilizing a Transformer model. For our experiments, we utilized drone footage of road conditions in Guseong-dong, Yuseong-gu, Daejeon. The experimental results demonstrated that YOLOv8 achieved a high object detection performance with an mAP50 of 0.99 and an mAP50-95 of 0.75, indicating a high degree of agreement between detected and actual objects. In terms of lane change prediction, the Transformer model outperformed other models, achieving an accuracy of 0.977, which is 0.02 higher, and the lowest misclassification rate in the confusion matrix. This study is expected to contribute to improving traffic systems by serving as a valuable resource for efficient traffic flow management in the future."
자연어 처리(Transformer) 모델을 활용한 Smali 코드 학습 기반 안드로이드 악성코드 탐지 기법,2024,"['Android', 'APK', 'Smali', 'Transformer', 'BERT', 'roBERTa', 'BART']",국문 초록 정보 없음,"Studies on Android malware detection by using machine learning have been varied, utilizing network traffic, memory dumps, and other data necessary for model training. In this paper, we propose a model to determine malware presence by training three Transformer models-BERT, RoBERTa, and BART-using Smali code obtained from APK files. We decompiled 1,318 malware-infected files and 1,236 benign files provided by CIC-AndMal-2020. The decompiled files were very large and contained unnecessary code for training, requiring a preprocessing step to remove it. Training and evaluation results showed that RoBERTa achieved the highest evaluation accuracy. However, BERT exhibited higher training performance, and in prediction results for 451 benign and 597 malware files, BERT slightly outperformed RoBERTa. BART generally showed lower performance compared to BERT and RoBERTa. The differences in training, evaluation, and prediction results between BERT and RoBERTa seem to be due to the lack of diversity in the dataset and the absence of sophisticated preprocessing. Nevertheless, this experiment confirms that BERT and RoBERTa can both achieve significant performance in the field of malware detection. In future work, the proposed model is expected to achieve even better performance by improving the preprocessing steps."
Transformer 기반 딥러닝 모델들을 이용한 정수 처리 시설 문제 조류 시뮬레이션,2024,"['Drinking water treatment plants', 'LSTM', 'Problematic algae', 'SHAP', 'Transformer']",국문 초록 정보 없음,다국어 초록 정보 없음
Transformer 기반 딥러닝 모델들을 이용한 정수 처리 시설 문제 조류 시뮬레이션,2024,"['Drinking water treatment plants', 'LSTM', 'Problematic algae', 'SHAP', 'Transformer']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 Vision Transformer 모델을 적용한 산불 화재 조기 감지 기술에 관한 연구,2024,"['Forest fire', 'Fire detection', 'Vision transformers', 'Convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
흉부 X-선 영상을 이용한 Vision transformer 기반 폐렴 진단 모델의 성능 평가,2024,"['딥러닝', '폐렴 진단', '흉부 X-선 영상', 'Vision transformer', 'Deep learning', 'Pneumonia detection', 'Chest X-ray image']",국문 초록 정보 없음,"The various structures of artificial neural networks, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have been extensively studied and served as the backbone of numerous models. Among these, a transformer architecture has demonstrated its potential for natural language processing and become a subject of in-depth research. Currently, the techniques can be adapted for image processing through the modifications of its internal structure, leading to the development of Vision transformer (ViT) models. The ViTs have shown high accuracy and performance with large data-sets. This study aims to develop a ViT-based model for detecting pneumonia using chest X-ray images and quantitatively evaluate its performance. The various architectures of the ViT-based model were constructed by varying the number of encoder blocks, and different patch sizes were applied for network training. Also, the performance of the ViT-based model was compared to the CNN-based models, such as VGGNet, GoogLeNet, and ResNet. The results showed that the traninig efficiency and accuracy of the ViT-based model depended on the number of encoder blocks and the patch size, and the F1 scores of the ViT-based model ranged from 0.875 to 0.919. The training effeciency of the ViT-based model with a large patch size was superior to the CNN-based models, and the pneumonia detection accuracy of the ViT-based model was higher than that of the VGGNet. In conclusion, the ViT-based model can be potentially used for pneumonia detection using chest X-ray images, and the clinical availability of the ViT-based model would be improved by this study."
Knowledge-Augmented Transformer 모델을 활용한 게임 승부 예측 시스템,2024,"['게임 승부 예측', '지식 증강', '지식 추론', '트랜스포머', '딥러닝', 'Winner Prediction', 'Knowledge Augmentation', 'Reasoning', 'Transformer', 'Deep Learning']","인공지능(AI) 기술이 발전함에 따라 이를 여러 분야에 적용하는 연구들이 활발하게 진행되고 있다. 그중 게임 분야에서는 게임 상황을 분석하여 전략 추천 및 승부 예측 연구가 진행되고 있다. 기존의 연구에서는 주로 수집된 게임 로그 데이터를 AI 분류 모델을 기반으로 학습하고, 이를 바탕으로 승부를 예측하거나 전략을 추천하 는 방식을 사용하고 있다. 그러나 대용량의 시계열 게임 데이터를 분류 모델을 기반으로 학습하는 기존 방식의 경 우 게임 초기 예측에서 낮은 성능을 보이고 있다. 이에 본 연구에서는 이러한 단점을 개선하기 위해 자연어 등의 시퀀스 데이터 분석에 사용되는 Transformer 모델을 개선한 LLM 모델 기반의 게임 승부 예측 시스템을 제안한 다. 또한 성능 향상을 위하여 입력된 데이터를 기반으로 전략 등의 추가 정보를 추론하여 프롬프트에 같이 활용하 는 knowledge augmentation 기법을 적용한다. 제안하는 시스템을 실시간 전략게임인 Starcraft2에 적용한 실험 을 통해 게임의 승부 예측 성능이 향상됨을 확인하였고 게임의 특징을 잘 반영되는 것을 확인하였다.","As artificial intelligence(AI) technology develops, studies that apply it to various fields are actively being conducted. Among them, in the field of games, research is being conducted to analyze game situations in order to recommend play strategies or predict game outcomes. The existing studies mainly use a method of learning from collected game log data based on AI classification models, and use this to predict match outcomes or recommend strategies. However, the existing method of learning large-scale time-series game data based on classification models shows low performance in early-game predictions. In this study, we propose a game outcome prediction system based on an improved LLM model, which enhances the Transformer model commonly used for analyzing sequence data such as natural language, to address these limitations. Additionally, to enhance performance, a knowledge augmentation technique is applied, which infers additional information such as strategies based on the input data and incorporates it into the prompt. Through experiments applying the proposed system to the real-time strategy game StarCraft2, we confirmed that the system improves the accuracy of game outcome prediction and effectively captures the key characteristics of the game."
다중 시계열을 이용한 장기 예측 Transformer 모델,2024,"['artificial intelligence', 'deep learning', 'transformer', 'time series forecasting', '인공지능', '딥러닝', '트랜스포머', '시계열 예측']","많은 현대 연구에서는 시계열 예측 모델을 위해 recurrent nueral networks (RNN) 혹은 long short-term memory (LSTM)과 같은 인공지능 기술의 적용을 탐구한다. 이러한 인공지능 모델 중에서도 자연어 처리를 위해 처음 개발된 모델인 transformer는 큰 주목을 받고 있다. 그럼에도 불구하고, 많은 시계열 예측 모델은 장기 예측을 적절히 다루지 못하고 있다. 따라서 본 연구에서는 “목표 시계열”과 예측에 영향을 미칠 수 있는 다수의 “참고 시계열”을 포함하는 트랜스포머 아키텍처 기반의 장기 예측 모델을 제안한다.","Numerous contemporary studies are exploring the application of artificial intelligence techniques such as recurrent neural networks (RNN) and long short-term memory (LSTM) for time series forecasting models. Among these AI models, the Transformer, which is a high-performance model initially developed for natural language processing, has gained significant attention. Despite this, many time series forecasting models do not adequately address long-term prediction. Therefore, this study seeks to develop a long-term forecasting model based on the Transformer architecture, incorporating a “target time series” and a multiple “reference time series” that may influence the forecast."
Depth Prediction Transformer 모델을 활용한 다시점 실사 데이터의 고품질 깊이 정보 생성 기법,2024,[],"다시점 실사 영상을 3차원으로 재구성하기 위해서는 다중 시점 간의 일관성을 유지하면서도 고품질의 깊이 맵을 추정하는 것이 필수적이지만, 이는 많은 기술적 도전 과제를 동반한다. 실사 기반 다시점 시퀀스를 취득하고 MPEG immersive video (MIV) 를 사용하여 6자유도를 지원하는 비디오를 재구성하는 전체 시스템에서 각 시점에서 취득한 카메라 정보와 함께 추정된 깊이 정보를 요구한다. 기존에는 multi-view stereo (MVS) 기법이나 immersive video depth estimation (IVDE) 등의 방법을 통해 깊이 추정을 수행했다. 그러나 이러한 방식들은 장면 특성이나 캡처 환경에 따라 깊이 맵 추정의 정확도가 저하될 수 있으며, 특히 낮은 텍스처 데이터에서는 성능이 떨어지는 한계가 있다. 이러한 부정확한 깊이 정보를 그대로 사용할 경우 3차원 재구성 품질이 저하되어 중간 뷰 합성 시 다량의 아티팩트가 발생하는 문제가 발생한다. 따라서 본 연구는 깊이 예측 트랜스포머 (depth prediction transformer, DPT) 모델을 통해 단일 이미지 깊이 정보를 추출하고, 이를 다중 시점 스테레오 (MVS)로 생성된 깊이 정보와 결합하여 구조적 일관성을 유지한 다시점 깊이 정보를 생성하는 새로운 접근법을 제안한다.",다국어 초록 정보 없음
Transformer 모델을 적용한 전기차량 리튬 이온 배터리의 노화도 예측 및 시각화를 위한 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
Transformer 모델을 활용한 얌체 운전자의 나들목 끼어들기 사전 예측,2024,"['Transformer', 'Lane Change', 'Drone Vision', 'Selfish Cutting-in Vehicle']",국문 초록 정보 없음,다국어 초록 정보 없음
KorBERT 및 Transformer 모델을 동시 활용한 한국어 문장 요약 시스템,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
수치예보모델 예측장을 활용한 Transformer 기반 강수 보정 연구,2024,"['표현 학습', '강수 보정', '수치예보모델', 'Transformer']",국문 초록 정보 없음,다국어 초록 정보 없음
Transformer와 통계적 특징 활용한 제조 센서데이터에서의 예측 모델 성능 향상 기법 개발,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
Transformer와 통계적 특징 활용한 제조 센서데이터에서의 예측 모델 성능 향상 기법 개발,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
"Mamba, Transformer, LSTM을 이용한 주식 예측 모델 분석",2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
드론 비전을 활용한 Transformer 기반 차량 차선 변경 예측 모델,2024,"['Deep Learning model', 'Drone Vision', 'Traffic Prediction']",국문 초록 정보 없음,다국어 초록 정보 없음
Explainable AI와 Transformer를 이용한 수술 중 저혈압 실시간 예측 모델 개발,2024,"['설명 가능한 인공지능(Explainable AI)', '트랜스포머(Transformer)', '딥러닝(Deep Learning)', '시계열 예측(Timeseries Prediction)']",국문 초록 정보 없음,다국어 초록 정보 없음
Reparameterization을 활용한 하드웨어 친화적인 Hybrid Vision Transformer 모델 구현,2024,[],국문 초록 정보 없음,"A lightweight hybrid vision transformer (ViT), MobileViT, has been proposed to perform real-time vision tasks on resource-constrained mobile devices. However, due to its architecture that adds convolutional neural network (CNN) architecture to a standard transformer network, MobileViT has higher latency than light-weight CNN models that have relatively more parameters and floating-point operations (FLOPs). To address this, we remove the residual add of MobileNetV2 blocks with using reparameterization and replace layer normalization with batch normalization. The proposed network reduced the parameter count by 16.5% and FLOPs by 9.0% with only a 0.4% accuracy drop and reduced CPU and GPU latency by 12.7% and 12.3%, respectively compared to MobileViT-XXS."
한국어-영어 기계 번역에 대한 Transformer 모델 경량화의 영향 분석,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
이미지 생성을 통한 트랜스포머 기반 헤드 모션 예측 알고리즘,2024,"['사이버 멀미', '가상현실', '렌더링', '인공지능', 'cyber sickness', 'virtual reality', 'rendering', 'AI']","모션 투 포톤 지연은 헤드 마운트 디스플레이 기반 가상현실에서 사용자의 움직임과 영상 출력의 시차로 인한 사이버 멀미 같은 불편감을 줄 수 있고, 이러한 불편함이 지속되면 사용자의 몰입감을 방해할 수 있다. 기존의 모션 투 포톤 지연을 줄이는 방식은 직접 헤드 모션 데이터의 경향성을 파악하거나, 순환신경망 모델을 통해 헤드 모션을 예측하지만, 기존의 순환신경망 모델은 시퀀스 정보를 오랜 시간 동안 기억하지 못하는 장기 의존성 문제와 병렬 처리의 제약이 존재한다. 본 논문은 트랜스포머 기반 헤드 모션 예측 모델을 이용하여 이전의 영상 프레임의 데이터를 통해 이후의 프레임을 예측하는 기법을 제안한다. 본 논문에서는 이미지 생성모델을 통해 디코딩 과정에서도 이미지를 사용한다는 점과 자연어처리에서 사용되던 딥러닝 모델을 예측 모델로 사용함에 있어서 높은 확장성을 가진다. 또한 본 연구에서 제안한 모델은 데이터를 추가로 사용하여 기존 모델보다 사용자의 헤드 모션을 잘 예측함을 알 수 있다.","Motion-to-photon latency in virtual reality based on head-mounted display can cause discomfort such as cyber sickness due to a lag between a user's physical movement and the image output, potentially disrupting users’ immersion. Traditional methods to reduce this latency involve manually analyzing head motion trends or predicting head motion with recurrent neural networks. However, these models faced long-term dependency issues in remembering information over sequences and limitations in parallel processing. In this paper, images are also used in the decoding process through an image generation model. A deep learning model used in natural language processing is highly scalable when using it as a prediction model. Accordingly, the model proposed in this study could use additional data to predict the user’s head motion and thereby, outperforms the existing models."
트랜스포머 기반 산림지와 도심지 의미론적 분할 및 탄소 저장량 예측 기법,2024,"['컴퓨터 비전', '딥러닝', '항공 영상', '탄소 저장량', '의미론적 분할', 'Computer Vision', 'Deep Learning', 'Aerial Image', 'Carbon Storage', 'Semantic Segmentation']","산림의 탄소 저장량 측정은 주로 현장 조사와 원격 탐사의 방법을 통해 이뤄지나, 이런 접근법은 측정의 정확도가 떨어지는 문제를 안고 있다. 따라서 본 연구에서는 항공 관측 이미지를 활용하여 산림을 구분하고 이에 상응하는 탄소 저장량을 측정하는딥러닝 모델을 제안한다. 기존의 이미지 기반 객체 탐지 모델들은 매개 변수의 수가 많고 계산 비용이 높아 실시간 서비스나 자원 제약이 많은 경우 활용이 어렵다는 단점이 있다. 이에 본 연구가 제안하는 모델은 트랜스포머 구조를 기반한 SegFormer를 활용해 경량화와 분류 정확도의 두 가지 목표를 동시에 달성하고자 하였다. 실험 결과 1픽셀당 25cm 해상도의 항공 이미지를 활용했을 때 기존 알고리즘 대비 우수한 성능을 확인하였다. 본 연구의 결과를 활용하여 추후 탄소 저장량 예측 및 모니터링에 효과적으로 적용될 수 있을 것으로 기대한다.","Carbon storage in forests is mainly measured by field surveys and remote sensing methods; however, these approaches afford reduced measurement accuracy. Therefore, this study proposes a deep learning model that utilizes aerial imagery to classify forests and measure the corresponding carbon storage. Existing image-based object detection models have a large number of parameters and high computational costs; therefore, it is difficult to apply them in real-time services or in resource-constrained situations. To address this, the proposed model leverages the SegFormer architecture based on transformers to simultaneously achieve both lightweight design and classification accuracy. The proposed model experimentally demonstrated superior performance compared to existing algorithms on aerial images with a resolution of 25 cm per pixel. The findings of this study are expected to be effectively applied in future carbon storage prediction and monitoring efforts."
딥페이크 검출을 위한 일반화된 메타러닝 EfficientNet 비전 변환기 모델,2024,"['Deepfake Detection', 'Vision Transformer', 'Generalization', 'Video Forensics', 'Meta-Learning', 'EfficientNet']",국문 초록 정보 없음,"Digitally manipulated images that are realistic-looking but fake, which are known as Deepfake. With the remarkable developments in deep generative models, the accessibility and accuracy of manipulated technologies are increasing, leading to fake videos becoming increasingly difficult to identify. Different facial forgery techniques result in complicated data distributions, but Deepfake detection techniques based on CNN(convolutional neural network) architecture are utilized in the majority of Deepfake detection models as binary classification problems. In this paper, we propose a model, named MEViT, which uses a combination of EfficientNet Vision Transformer with a meta-learning-based technique to improve the generalization of the detection model. Furthermore, we propose a learning process to update the model and introduce pair-discrimination loss and domain adjustment loss to improve detection ability across various domains. We also create various experiments on several Deepfake datasets and compare our proposal with many state-of-the-art works to prove the efficiency of our approach."
인공지능기반 사전학습언어모델 적용방안에 관한 연구,2024,"['사전학습언어모델', '도메인 특화', '전이학습', '금융 특화 언어모델', 'BERT', 'Pre-trained Language Model', 'Domain-Specific Fields', 'BERT Model', 'Legal Corpus']","사전학습언어모델(Pre-trained Language Model)은 대량의 텍스트 데이터를 활용하여 사전에 학습(pre-training)된 자연어 처리 모델을 의미한다. 사전학습언어모델이 다양한 영역에서 활용되고 있으나 전문용어 학습데이터가 부족한 영역에서 도메인에 특화된 용어를 이해하지 못하는 한계점을 가진다. 따라서 최근 BERT(Bidirectional Encoder Representations from Transformers)와 GPT(Generative Pretrained Transformer)를 기반으로 추가 사전학습을 통해 변형된 도메인 특화 언어모델의 필요성이 강조되고 있다. 본 연구에서는 BERT의 사전훈련방법과 BERT 기반의 변형기법(ALBERT, RoBERTa, ELECTRA)을 분석하고, 대표적인 도메인 특화 분야인 바이오의학, 금융, 법률 도메인에서 활용 가능한 사전학습언어모델을 제안하고자 한다. 바이오의학 특화 사전학습모델은 바이오의학 분야의 전문 용어, 의학적 문장 구조, 의학적 개체명 인식 등의 도메인 특정 언어 특성을 학습하도록 설계된다. 이것은 주로 BERT의 사전훈련방법과 아키텍처를 기반으로 전이학습을 통해 바이오의학 작업에 적용될 수 있도록 조정된다. 바이오의학 특화 사전학습모델은 의료 문서 분류, 의료 개체명 인식, 의료 질문 응답, 바이오의학 관련 정보 검색 등의 다양한 자연어 처리 작업에 사용될 수 있다. 금융 특화 사전학습모델은 금융 전문 용어, 금융 시장 동향, 금융 상품 및 서비스에 관련된 문장 구조 등을 이해하고 처리할 수 있는 모델이다. 금융 시장 동향에 관한 자동화된 뉴스 기사를 생성하고, 금융 보고서, 보도 자료 등과 같은 긴 텍스트를 간결하게 요약하여 핵심 정보를 추출하는 작업에 활용될 수 있다. 또한 금융 특화 사전학습모델은 금융 분석가들이 기업의 재무 상태, 성과 및 전망에 대한 투자 제안을 생성하는 데 도움을 준다. 마지막으로 법률 특화 사전학습모델은 법률 문서에 적합한 언어 모델로 법률 문서 분류 및 요약, 법률 문서 유사성 평가 등에 활용된다. 법률 특화 사전학습모델은 BERT 모델을 법률 분야의 특수한 텍스트에 대해 사전학습하고, 이를 통해 법률 문서에 특화된 특성을 학습한다. 이러한 특성은 법률 분야의 특수한 용어, 문맥, 문법 등을 포함한다. 법률 특화 사전학습모델은 법률 말뭉치를 사용한 스크래치 사전학습과 추가 사전학습을 통해 법률 관련 태스크를 해결하도록 성능을 고도화할 수 있다.","Pre-trained Language Model(PLM) refers to a natural language processing(NLP) model that has been pre-trained using large amounts of text data. The PLM has the limitation of not being able to understand domain-specific terminology due to a lack of training data for terminology. Therefore, the need for a domain-specific language model modified through BERT- or GPT-based pre-trained learning has recently been emphasized. In this study, we analyze BERT's pre-training method and BERT-based transformation techniques (ALBERT, RoBERTa, ELECTRA) and propose a PLM that can be used in biomedical, financial, and legal domains. The biomedical-specific pre-trained learning model is designed to learn domain-specific language characteristics such as technical terminology, medical sentence structure, and medical entity name recognition in the biomedical field. It is mainly adjusted to be applied to biomedical tasks through transfer learning based on BERT's pre-training method and architecture. For this purpose, it is pre-trained with pre-trained biomedical text data, and this pre-training transfers domain-specific knowledge to the model through learning representations for biomedical-related texts. The finance-specific pre-trained learning model is a model that can understand and process financial terminology, financial market trends, and sentence structures and vocabulary related to financial products and services. It can be used to generate news articles about financial market trends and to extract key information by concisely summarizing long texts such as financial reports and corporate press releases. Additionally, finance-specific pre-trained models help financial analysts generate investment recommendations based on a company's financial condition, performance, and prospects. The legal-specific pre-trained model is a language model suitable for legal documents and is used for legal document classification, legal document summarization, and legal document similarity evaluation. The legal-specific pre-learning model was created by pre-training the BERT model on special texts in the legal field, and through this, it learns characteristics specialized for legal documents. The performance of the legal-specific pre-training model can be improved to solve legal-related tasks through scratch pre-training and additional pre-training using legal corpora."
한국어 대규모 언어 모델의 양자화 성능에 대한 비교 연구,2024,"['Large Language Models', 'Open Source', 'Quantization', 'BitsAndBytes', 'Ko LM Eval Harness']","트랜스포머(Transformer) 아키텍처 기반의 대규모 언어 모델(LLM: Large Language Models)은 자연어 처리작업에서 매우 높은 수준의 성능을 보인다. 크기와 성능 효율성을 고려한 여러 모델이 개발되었으나, 여전히 모델 운용에는 많은 메모리 자원이 필요하기에 메모리 효율성을 고려한 모델의 경량화가 중요한 과제로 대두되고 있다. 기존 모델의구조를 유지하면서 파라미터를 저정밀도 데이터 타입으로 변환하는 양자화는 메모리 사용량을 크게 줄일 수 있으며, 추가적인 훈련 없이도 적용할 수 있어 응용 프로그램 통합시 접근성과 효율성을 높여준다. 본 연구에서는 비트 앤 바이트(BitsAndBytes) 양자화 모듈을 활용하여 오픈소스 한국어 언어 모델을 경량화하고, 메모리 사용량과 성능을 비교하여LLM의 효율적 운용 방안을 제시한다. 8비트 및 4비트 양자화를 통해 각각 평균 약 38%, 67%의 메모리 감소를 확인했으며, 언어 모델 평가 벤치마크에서 평균 성능 변화율이 5% 미만으로 나타나 양자화에 의한 성능 손실이 크지 않음을확인했다. 또한, 메모리 사용량이 유사한 양자화된 대형 모델과 소형 모델의 성능을 비교한 결과, 13개 벤치마크 중 양자화된 대형 모델이 0-shot 9개, 5-shot 8개 항목에서 성능 우위를 보여, 대형 모델을 양자화하여 사용하는 것이 일반화성능과 자원 효율성 측면에서 더 효과적임을 입증했다.","Transformer architecture large language models (LLMs) demonstrate exceptionally high performance in natural language processing tasks. While various models have been developed that consider size and performance efficiency, they still require significant memory resources to deploy, making model compression for memory efficiency an important challenge. Quantization, which converts parameters to low-precision data types while maintaining the existing model structure, can significantly reduce memory usage and can be applied without additional training, enhancing accessibility and efficiency in application integration. In this study, we propose an efficient deployment strategy for LLMs by compressing open-source Korean language models using the bitsandbytes quantization module and comparing memory usage and performance. Through eight-bit and four-bit quantization, we observed average memory reductions of approximately 38% and 67%, respectively. In language model evaluation benchmarks, the average performance change was less than 5%, confirming that performance loss due to quantization is not significant. Additionally, comparing the performance of quantized large models with small models of similar memory usage across 13 benchmarks, the quantized large models showed superior performance in nine zero-shot and eight five-shot tasks. This demonstrates that using quantized large models is more effective in terms of generalization performance and resource efficiency."
전장소음에 강건한 음성인식 모델 연구,2024,"['Automatic Speech Recognition', 'Whisper', 'Fine-tuning', 'Denoising', 'Battlefield sound', '음성인식', '위스퍼', '파인튜닝', '디노이징', '전장소음']","최근 Transformer 기반 음성인식 모델들의 발전으로, 다양한 환경에서의 음성인식 성능이 크게 향상되었다. 이러한 모델들은 소음이 포함된 데이터를 일부 학습하여, 소음이 포함된 음성데이터에 대해서도 우수한 성능을 발휘한다. 그러나 사람의 말소리보다 훨씬 큰 전장소음(총기, 포탄 소리)과 같은 극단적인 환경에서는 이들 모델의 성능이 상대적으로 저하된다. 본 연구에서는 전장소음이 음성인식 모델의 성능에 끼치는 영향을 확인하였으며, OpenAI의 Whisper 모델을 디노이징 기법과 파인튜닝을 적용하여, 전장소음에 강건한 모델로 개선하였다. 디노이징 기법과 파인튜닝을 통하여 전장소음의 강도 및 모델의 종류에 따른 에러율(CER, Character Error Rate)을 Medium모델 기준 평균 35%, Small모델 기준 평균 40% 감소시킴으로써, 강도 높은 소음이 존재하는 실제 전장 환경에서도 개선된 Whisper 모델이 효과적으로 활용될 수 있음을 시사한다.","Transformer-based speech recognition models have significantly improved speech recognition performance in various environments. These models generally train some data with background noise, enabling them to exhibit superior performance even in a noisy environment. However, their performance noticeably degrades under extreme conditions, such as in battlefield noise environments, where the overwhelming sound of gunfire and explosions vastly overshadows human speech. In this study, we examined the impact of battlefield noise on the performance of OpenAI's Whisper models and enhanced them the robustness of against battlefield noise with a denoising model and fine-tuning. By fine-tuning the models, we successfully achieved significant reductions in the Character Error Rate (CER): 35% for Medium model and 40% for Small model. This substantial improvement demonstrates that the enhanced Whisper models are robust enough to be effectively utilized in real-world battlefield environments, where noise levels are exceptionally high."
해충 및 과수화상병 분류를 위한 클래스 활성화 맵 기반의비전 트랜스포머,2024,"['image classification', 'vision transformer', 'class activation map', 'saliency', '。']","최근 비전 트랜스포머 모델이 이미지 분류기의 대표적인 모델로 자리매김하고 있다. 하지만, 배경과 객체의 색상이 유사하거나 배경의 텍스처가 복잡할 경우 모델의 정확도가 저하되는 문제가 발생한다. 이를 해결하기 위해, 관심 영역 기반의 딥러닝 모델이 개발되었지만, 배경이 복잡한 경우 이미지 분할 라벨링 작업은 사실상 어렵다고 볼 수 있다. 또한 이미지 분할 맵은 이진화된 값으로 표현되기 때문에 정보량이 부족한 단점이 있다. 따라서 본 연구에서는 이미지 분할 맵 대신에 클래스 활성화 맵을 사용한 비전 트랜스포머를 제시하고자 한다. 실험 결과를 통해, 제안한 모델이 배경이 복잡한 이미지에 대해서도 관심 영역을 잘 포착할 수 있었고 해충 및 과수화상병 데이터셋에 대해서 기존 분류 모델보다 더 우수한 정확도를 달성할 수 있었다.","Recently, the vision transformer model has become a representative model for image classifiers. However, if the background and object colors are similar or the background texture is complex, the model's accuracy deteriorates. To solve this problem, a deep learning model based on the region of interest has been developed, but when the background is complex, the image segmentation labeling task can be considered difficult in practice. Additionally, image segmentation maps have the disadvantage of insufficient information because they are expressed as binary values. Therefore, in this study, we would like to present a vision transformer that uses a class activation map instead of an image segmentation map. Through experimental results, the proposed model was able to capture regions of interest well even in images with complex backgrounds and achieved better accuracy than existing classification models for pest and fire blight datasets."
BERT 기반의 모델을 이용한 무기체계 소프트웨어 정적시험 거짓경보 분류 모델 개발 방법 연구,2024,"['weapon system software', 'SW reliability testing', 'static testing', 'false alarm classification', 'BERT-based model', '무기체계 소프트웨어', '소프트웨어 신뢰성 시험', '정적시험', '거짓경보 분류', 'BERT기반 모델']","최근 무기체계에서 소프트웨어의 규모와 복잡도가 커짐에 따라 소프트웨어의 신뢰성 및 안정성 확보가 요구되고 있다. 이를 위해 개발자는 정적 및 동적 신뢰성 시험을 수행해야한다. 하지만 정적시험 과정에서 많은 거짓경보들이 발생하여 이를 분석하고 처리하는데 많은 시간과 자원을 할애하고 있다. 기존 연구에서는 이러한 문제를 해결하기 위해 SVM, LSTM 등의 모델을 활용하여 거짓 경보를 분류한다. 하지만 연구들에서 사용된 모델의 입력값은 코드 관련 정보이거나, Word2Vec기반 코드 임베딩이므로 결함 발생 부분과 연관된 코드 간의 관계를 표현하지 못한다는 한계점이 존재한다. BERT기반의 모델은 양방향 트랜스포머의 적용을 통해 문장 간 앞뒤 관계를 학습하므로 코드 간 관계를 분석하는데 용이하다. 따라서 이를 거짓 경보 분류 문제에 활용하면 위 한계점을 극복할 수 있다. 본 논문에서는 정적시험 결과를 효율적으로 분석하기 위해 BERT기반의 모델을 활용한 거짓경보 분류 모델 개발 방법을 제안한다. 개발 환경에서 데이터셋을 구축하는 방법을 설명하고, 실험을 통해 분류 모델의 성능이 우수함을 보인다.","Recently, as the size and complexity of software in weapon systems have increased, securing the reliability and stability is required. To achieve this, developers perform static and dynamic reliability testing during development. However, a lot of false alarms occur in static testing progress that cause wasting resources such as time and cost for reconsider them. Recent studies have tried to solve this problem by using models such as SVM and LSTM. However, they have a critical limitation in that these  models do not reflect correlation between defect code line and other lines since they use Word2Vec-based code embedding or only code information. The BERT-based model learns the front-to-back relationship between sentences through the application of a bidirectional transformer. Therefore, it can be used to classify false alarms by analyzing the relationship between code. In this paper, we proposed a method for developing a false alarm classification model using a BERT-based model to efficiently analyze static test results. We demonstrated the ability of the proposed method to generate a dataset in a development environment and showed the superiority of our model."
"""트랜스포머 알고리즘의 멀티 헤드 어텐션과 피드포워드 네트워크에서 활용 가능한 효율적인 행렬 곱셈기""",2024,"['Transformer', 'MHA', 'FFN', 'Systolic Array', 'MAC', 'Quantization']","""자연어 처리 모델이 발전함에 따라 챗 GPT와 같은 대화형 언어 생성 AI 모델이 널리 사용되고 있다. 따라서 자연어 처리 최신모델의 기반이 되는 트랜스포머 알고리즘을 하드웨어로 구현하여 연산 속도와 전력 소비량을 개선하는 것은 중요하다고 할 수 있다.특히, 행렬 곱셈을 통해 문장에서 서로 다른 단어 간의 관계를 분석하는 멀티 헤드 어텐션과 피드 포워드 네트워크는 트랜스포머에서 연산량이 가장 큰 핵심적인 알고리즘이다. 본 논문에서는 기존의 시스톨릭 어레이를 변형하여 행렬 곱 연산 속도를 개선하고, 입력 단어 개수 변동에 따라 지연시간도 변동되는 유동적인 구조를 제안한다. 또한, 트랜스포머 알고리즘의 정확도를 유지하는 형태로양자화를 하여 메모리 효율성과 연산 속도를 높였다. 본 논문은 평가를 위해 멀티헤드어텐션과 피드포워드 네트워크에서 소요되는클럭사이클을 검증하고 다른 곱셈기와 성능을 비교하였다.""","""With the advancement of NLP(Natural Language Processing) models, conversational AI such as ChatGPT is becoming increasingly popular. To enhance processing speed and reduce power consumption, it is important to implement the Transformer algorithm, which forms the basis of the latest natural language processing models, in hardware. In particular, the multi-head attention and feed-forward network, which analyze the relationships between different words in a sentence through matrix multiplication, are the most computationally intensive core algorithms in the Transformer. In this paper, we propose a new variable systolic array based on the number of input words to enhance matrix multiplication speed. Quantization maintains Transformer accuracy, boosting memory efficiency and speed. For evaluation purposes, this paper verifies the clock cycles required in multi-head attention and feed-forward network and compares the performance with other multipliers."""
트랜스포머 기반 적외선 및 가시 이미지 융합 기술 연구,2024,"['Infrared Image', 'Visible Light Image', 'Image Fusion', 'Contrastive Language Image Pre-training Model', 'Transformer', 'Deep Learning', '적외선 영상', '가시광선 영상', '이미지 퓨전', '대비 언어 이미지 사전 학습 모델', '트랜스포머', '딥러닝']","적외선과 가시광선 이미지 융합의 목표는 대상을 강조하고 세부 질감 정보를 포함하는 융합 이미지를 생성하는 것이다. 하지만 기존 알고리즘은 종종 이미지의 시각적 품질에만 집중하고, 의미적 내용을 간과하는 경향이 있다. 이를 해결하기 위해, 본 연구에서는 트랜스포머 모델의 전역 특징 추출 기능과 대비 언어 이미지 사전 학습(CLIP: Contrastive Language Image Pre-training)을 통한 손실 함수를 활용하여 이미지 융합 과정을 최적화하는 방법을 제안한다. 먼저, 이미지에서 로컬 및 글로벌 정보를 추출하고 상호작용하기 위해 특징 안내 트랜스포머(FGT: Feature-Guided Transformer) 모듈을 개발한다. 이후, 두 가지 서로 다른 이미지를 적응적으로 융합하기 위해 특징 동적 융합(FDF: Feature Dynamic Fusion) 모듈을 설계한다. 또한, 수학적 손실 함수와 언어 기반 손실 함수를 결합하여 융합된 이미지의 시각적 품질과 의미적 정보를 동시에 향상시켰다. 공개 데이터 세트에 대한 종합적인 실험 결과, 제안된 방법이 기존의 융합 방법들에 비해 주관적 평가에서 우수한 성능을 보였음을 입증하였다.","The goal of infrared and visible image fusion is to generate a fused image that emphasizes targets while retaining detailed texture information. However, conventional algorithms often focus solely on visual quality, neglecting the semantic content of the images. To address this issue, this study proposes a method to optimize the image fusion process by leveraging the global feature extraction capabilities of the transformer model and utilizing a loss function derived from Contrastive Language-Image Pre-training (CLIP). First, a FeatureGuided Transformer (FGT) module is developed to extract and interact with both local and global information from the images. Then, a Feature Dynamic Fusion (FDF) module is designed to adaptively fuse the two different types of images. Additionally, the method incorporates a combination of mathematical loss functions and language-based loss functions to simultaneously enhance the visual quality and semantic content of the fused images. Comprehensive experiments on public datasets demonstrate that the proposed method outperforms existing fusion methods in terms of subjective evaluations."
멀티스케일 특성을 활용한 비전 트랜스포머 기반 딥페이크 탐지에 관한 연구,2024,"['딥페이크 탐지', '멀티스케일 특성 분석', '비전 트랜스포머', 'Deepfake Detection', 'Multiscale Feature Analysis', 'Vision Transformer']","딥페이크는 이미지나 영상에서 특정 사람의 얼굴을 다른 사람으로 대체하는 딥 러닝 기술, 또는 이 기술을 이용해 생성한 가짜 이미지나 영상을 지칭한다. 딥 러닝 기술이 널리 보급되면서 딥페이크 기술에 대한 접근성이 높아졌고, 결과적으로 이를 악용한 범죄도 증가하고 있다. 이에 따라 효과적인 딥페이크 탐지 기술의 필요성이 점점 더 커지고 있다. 딥페이크 생성은 주로 신원 교체와 표정 재연이라는 두 가지 방식으로 이루어지는데, 기존의 탐지 기술은 딥페이크가 어떤 방식 으로 생성되었는지에 따라 탐지 성능의 편차를 보인다. 본 연구에서는 딥페이크 탐지 모델의 성능 편차를 줄임으로써 기존 방법론들의 한계를 보완할 수 있는 연구를 제안하고자 하였다. 제안하는 모델은 먼저 영상을 프레임 단위의 이미지들로 자른 다음, 딥페이크의 주된 대상 영역인 얼굴 부분과, 일종의 지역 정보라고 할 수 있는 입 부분을 각각 추출하여 멀티스케일 특성으로 활용한다. 각 특성을 서로 다른 비전 트랜스포머 구조에 입력한 다음, 출력되는 예측 결과들을 종합하여 동영상이 딥페이크인지 아닌지를 효과적으로 판단하게 된다. 특히, 얼굴 부분은 신원 교체 방식으로 생성된 딥페이크를 대응하는 데 도움이 되고, 입 부분은 표정 재연 방식의 딥페이크를 대응하는 데 도움이 되기 때문에 모델은 서로 다른 딥페이크 생성 방식에 대한 강건성을 갖게 된다. 제안하는 방법론을 두 개의 데이터셋에 대해 실험한 결과, 상대적으로 높은 탐지 성능과 함께 다양한 딥페이크 생성 방식에 대해 보다 범용적으로 대응할 수 있는 가능성을 확인하였다.","Deepfake refers to deep learning technology that replaces a specific person’s face in an image or video with another person’s face, or to the fake images or videos generated using this technology. As deep learning technology has become widely disseminated, access to deepfake technology has increased, resulting in a rise in crimes exploiting it. Consequently, there is a growing need for effective deepfake detection technologies. Deepfake generation primarily occurs through two methods: identity swap and facial reenactment. Existing detection technologies exhibit performance variations depending on the method of deepfake generation. This study aims to propose a research approach that addresses the limitations of existing methodologies by reducing the performance disparity of deepfake detection models. The proposed model first cuts a video into frame-by-frame images, then extracts the face area, which is the main target of deepfakes, and the mouth area, which can be considered a type of local information, and utilizes them as multi-scale features. By inputting each feature into different vision transformer structures and integrating the resulting predictions, the model effectively determines whether a video is a deepfake. Specifically, the face area helps address identity swap deepfakes, while the mouth area assists in handling facial reenactment deepfakes, thereby endowing the model with robustness against different deepfake generation methods. Experimental results on two datasets demonstrate the proposed method’s relatively high detection performance and its potential for more generalizable response to various deepfake generation methods."
빅데이터 모델 분석을 통한 주식시장에 대한 연구,2024,"['Big Data', 'Analyze', 'Stock Market', 'Performance Analysis', 'AI']","본 연구는 빅데이터 분석을 통한 주식시장 분석에 대한 연구로 다양한 빅데이터 모델들을 비교하고, 각 모델의 성과를 측정하는 방법론을 제시함으로써 투자자들이 보다 합리적인 의사 결정을 내릴 수 있도록 돕고자 하였다. 이를 위하여 본 연구는 다양한 AI 알고리즘 모델을 분석하여 각각의 장단점과 정확도를 비교하였다. 연구 결과 LSTM 인공지능 모델의 주식 예측률은 84.9%로 다른 AI 인공지능 모델 중 가장 높은 주식 예측률을 보여주고 있다. LSTM은 딥러닝 모델의 일종으로, 특히 시퀀스 데이터(예: 자연어, 음성, 시계열 데이터) 처리에 매우 효과적인 알고리즘으로 시계열 데이터의 장기 의존 관계를 효과적으로 학습할 수 있는 능력을 가지고 있는 것으로 나타났다. 본 연구로 인하여 투자자들은 LSTM 순환 신경망을 통해 보다 합리적인 투자가 이루어질 것으로 예측한다. 앞으로 다양한 AI 알고리즘을 활용하여 보다 정교하고 신뢰할 수 있는 투자를 할 수 있도록 돕는 데 기여할 것으로 예상된다. 특히, 트랜스포머와 그래프 신경망의 활용은 주식 예측의 정확성을 크게 높일 가능성을 보여주었다.","This study aimed to help investors make more rational decisions by comparing various big data models and suggesting a methodology for measuring the performance of each model through big data analysis. Various AI algorithm models were analyzed, and their strengths, weaknesses, and accuracy were compared. The stock prediction rate of the LSTM artificial intelligence model was 84.9%, showing the highest stock prediction rate among other AI artificial intelligence models. LSTM is a type of deep learning model that is very effective for processing sequence data (e.g., natural language, voice, time series data) and can effectively learn the long-term dependency of time series data. The model predicts investors will make more rational investments through LSTM recurrent neural networks. In the future, this study is expected to help people make more sophisticated and reliable investments by utilizing various AI algorithms. In particular, the use of transformers and graph neural networks has potential to increase the accuracy of stock forecasts."
GPT 모델을 활용한 보안취약점 탐색,2024,"['보안취약점', '보안취약점 탐색', 'GPT 모델', 'GPT 3.5', 'security vulnerability', 'vulnerability detection', 'GPT model', 'GPT 3.5']","본 논문은 최근 큰 관심을 받는 대규모 언어처리 모델인 GPT의 소프트웨어 보안취약점 탐색에 있어서 활용 가능성과 한계를 탐색했다. 이를 위해, 다양한 오픈소스 프로젝트에서 독립적인 커밋 기록과 Java 파일을 수집하고, 이를 바탕으로 gpt-3.5-turbo-16k 모델의 보안취약점 탐지 능력을 효과적으로 검증했다. 질의응답 과정을 통해 도출된 답변을 5개의 항목으로 나누고 검증하는 과정을 거쳤다. 이 검증 과정에서 GPT 모델 답변의 신뢰성을 검증하기 위해 상용화된 정적분석기 3종과 비교하는 방식을 채택했다. 본 연구는 GPT의 보안취약점 탐지 도구로서의 가능성과 한계를 관찰했다. 이를 바탕으로 후속 연구에 도움이 될 수 있는 중요한 데이터와 결과를 제공하고, 보안취약점 탐색에 관한 연구 분야에 기여하고자 한다. 선행 연구의 한계를 극복하기 위해 보안취약점 탐색에 다양한 상황을 고려할 수 있는 넓은 범위의 데이터를 활용했고, GPT 모델의 답변 신뢰성을 검증했다.","This paper explores the potential and limitations of leveraging the Generative Pre-trained Transformer (GPT) model, a widely recognized large-scale language processing model, for the detection of software security vulnerabilities. The study collected independent commit records and Java files from diverse open-source projects and effectively validated the security vulnerability detection capabilities of the gpt-3.5-turbo-16k model using this dataset. The process included categorizing and validating responses obtained through prompting and dividing them into five categories. In the validation phase, a comparison was made with three commercial static analyzers to gauge the reliability of GPT model responses. This research contributes insights into the possibilities and constraints of GPT as a security vulnerability detection tool, providing valuable data and results for future research in the field. To overcome the limitations of prior studies, a comprehensive dataset encompassing various scenarios for security vulnerability exploration was employed, and the reliability of GPT model responses was thoroughly verified."
에지 검출과 ViT 기반의 세분화 모델 Annotation 자동 생성 프로세스,2024,"['비전 트랜스포머', '소벨 에지 검출', '스플라인 보간', '세분화', 'ViT', 'Sobel edge detection', 'Spline interpolation', 'Segmentation']","세분화는 이미지 내에서 객체를 탐지하고 객체의 에지 검출 후 마스킹하여 객체를 세분화하는 컴퓨터 비전 딥러닝 작업이다. 세분화 모델에 필요한 annotation을 생성하는 방법은 수작업으로 직접 annotation 점들을 이미지에서 생성하거나 에지 검출 모델 및 딥러닝 모델을 사용해서 annotation을 생성한다. 하지만 수작업으로 annotation을 만드는것은 매우 번거롭고, 기존의 에지 검출 알고리즘이나 딥러닝 모델을 이용하는 경우, 데이터 크기와 잡음에 민감하고사전 annotation 학습이 필요한 문제가 있다. 이러한 문제를 해결하기 위해 본 논문에서는 스플라인 보간법, 소벨 에지 검출 알고리즘, 그리고 비전 트랜스포머(ViT)를 활용하여 사전 학습 없이 자동으로 annotation을 생성하는 새로운프로세스를 제안한다. 제안된 프로세스는 데이터 크기와 잡음에 덜 민감하며, 사전학습 없이 annotation 생성이 가능하다. 실험 결과, 제안된 방법은 기존 SAM 기반 세분화 모델과 유사하거나 더 나은 성능을 보이며, 세분화 작업에 효율적인 대안을 제공한다.","Segmentation is a computer vision deep learning task that detects objects within an image, identifies their edges, andsegments them by applying masks. To generate the annotations required for segmentation models, one can either manuallycreate annotations by placing points on images or use edge detection models and deep learning models to generate them.However, manually creating annotations is cumbersome, and using existing edge detection algorithms or deep learningmodels has issues such as sensitivity to data size and noise, and the need for prior annotation training. To address theseproblems, this paper proposes a new process that utilizes spline interpolation, Sobel edge detection, and VisionTransformer (ViT) to automatically generate annotations without prior training. The proposed process is less sensitive todata size and noise, and allows annotation generation without prior training. Experimental results show that the proposedmethod achieves performance similar to or better than the existing SAM-based segmentation models, offering an efficientalternative for segmentation tasks."
감정분석 모델성능 향상을 위한 GPT기반 데이터 증강 방법,2024,"['GPT', 'data augmentation', 'large-scale language model', 'prompt engineering', '.']","머신러닝에 중요한 데이터 셋의 구성과 품질을 올리는 기술인 데이터 증강은 적은 양의 데이터를 바탕으로 다양한 알고리즘을 통해 데이터의 양을 늘리는 기술이다. 본 연구에서는 대규모 언어 모델인 GPT(Generative Pre-trained Transformer)를 활용한 데이터 증강으로 감정 분석 모델의 성능을 향상시키는 방법을 제안하고 평가한다. 데이터 셋의 클래스 불균형 문제를 해결하기 위해 가중치를 적용한 로직을 사용하였고, 생성된 데이터의 품질 및 다양성에 대한 한계를 극복하기 위해 프롬프트 엔지니어링을 적용했다. 실험결과, 제안한 방법은 데이터의 품질을 유지하면서 다양성을 높이고, 클래스 불균형 문제를 효과적으로 해결할 수 있어 KoBERT 모델을 이용해 GPT를 활용한 데이터 증강이 모델의 성능을 향상시킬 수 있음을 보였다.","Data augmentation, a technology that increases the composition and quality of datasets important for machine learning, is a technology that increases the amount of data through various algorithms based on a small amount of data. In this study, we propose and evaluate ways to improve the performance of emotion analysis models by augmenting data using a large language model, Generative Pre-trained Transformer(GPT). We used weighted logic to solve the class imbalance problem of datasets and applied prompt engineering to overcome limitations on the quality and diversity of generated data. As a result of the experiment, it was shown that the proposed method can increase diversity while maintaining the quality of the data and effectively solve the class imbalance problem, so that data augmentation using GPT can improve the performance of the model using the KoBERT model."
해충 및 과수화상병 분류를 위한 클래스 활성화 맵 기반 크로스 어텐션 멀티스케일 비전 트랜스포머,2024,"['Vision Transformer', 'Cross Attention', 'Class Activation Map']","최근 비전 트랜스포머 모델이 이미지 분류기의 대표적인 모델로 자리매김 하고 있지만 객체의 크기가 작거나 배경이 복잡할 때 정확도가 저하되는 경향이 있다. 이를 해결하기 위해, 관심 영역 비전 트랜스포머가 개발되었지만 거대한 이미지 데이터셋에 대한 영상 분할 라벨링 작업이 요구된다. 그리고 영상 분할 맵은 이진화된 값으로 표현되기 때문에 정보량이 부족한 단점이 있다. 따라서 본 연구에서는 영상 분할 맵 대신에 클래스 활성화 맵을 사용하여 관심 영역 비전 트랜스포머를 개선하는 방법을 제시하고자 한다. 실험 결과를 통해, 제안한 클래스 활성화 맵 기반의 관심 영역 비전 트랜스포머가 해충 및 과수화상병 분류에서 기존의 최첨단 분류모델보다 더 우수한 정확도를 획득할 수 있었다.","Recently, the vision transformer model has become a representative model for image classifiers, but accuracy tends to deteriorate when the object size is small or the background is complex. To solve this problem, a region-of-interest (ROI) vision transformer (ViT) has been developed, but it requires image segmentation labeling for huge image datasets. Since the image segmentation map is expressed as binarized values, it has the disadvantage of insufficient information. Therefore, in this study, we propose a method to improve the ROI-ViT by using a class activation map (CAM) instead of an image segmentation map. Through experimental results, the proposed CAM-based ROI-ViT was able to achieve better accuracy than the existing state-of-the-art classification models for pest and fire blight classification."
특징 매칭을 이용한 페어와이즈 어텐션 강화 모델에대한 연구,2024,"['Vision Transformer', 'Clock Drawing Test', 'Attention Mechanism', 'Dementia Classification', 'Image Processing']","Vision Transformer(ViT)는 패치 간의 관계를 학습하지만, 색상, 질감, 경계와 같은 중요한 특징을 간과할 경우 의료 분야나 얼굴 인식 등에서 성능 한계가 발생할 수 있다. 이를 해결하기 위해 본 연구에서는 Pairwise Attention Reinforcement(PAR) 모델을 제안한다. PAR 모델은 학습 이미지와 참조 이미지를 인코더에 입력하여 두 이미지 간의 유사성을 계산한 후, 높은 유사성을 보이는 이미지 어텐션 스코어 맵을 매칭하여 학습 이미지의 매칭 영역을 강화한다. 이를 통해 이미지 간의 중요한 특징이 강조되며,미세한 차이도 구별할 수 있다. 시계 그리기 검사 데이터를 사용한 실험에서 PAR 모델은 Precision 0.9516, Recall 0.8883,F1-Score 0.9166, Accuracy 92.93%를 기록하였다. 본 모델은 Pairwise Attention 방식을 이용한 API-Net 대비 12% 성능이향상되었으며, ViT 모델 대비 2%의 성능 향상을 보였다.","Vision Transformer (ViT) learns relationships between patches, but it may overlook important features such ascolor, texture, and boundaries, which can result in performance limitations in fields like medical imaging or facialrecognition. To address this issue, this study proposes the Pairwise Attention Reinforcement (PAR) model. The PARmodel takes both the training image and a reference image as input into the encoder, calculates the similaritybetween the two images, and matches the attention score maps of images with high similarity, reinforcing thematching areas of the training image. This process emphasizes important features between images and allows evensubtle differences to be distinguished. In experiments using clock-drawing test data, the PAR model achieved aPrecision of 0.9516, Recall of 0.8883, F1-Score of 0.9166, and an Accuracy of 92.93%. The proposed modelshowed a 12% performance improvement compared to API-Net, which uses the pairwise attention approach, anddemonstrated a 2% performance improvement over the ViT model."
서로 다른 문장 구조의 병렬 말뭉치 통합을 통한 기계번역 모델 품질의 향상,2024,"['Machine Translation', 'Transformer', 'OpenNMT', 'Parallel Corpus', 'Artificial Neural Network Machine Translation', '기계번역', '트랜스포머', 'OpenNMT', '병렬 말뭉치', '인공신경망 기계번역']","최근 AI 기술이 빠르게 발전하면서 이전에는 개발하기 어려웠던 번역기를 민간에서도 비교적 쉽게 만들 수 있게 되었고, 일반적으로 학습 데이터의 양을 늘릴 경우 번역 품질은 향상되는 경향을 보였다. 하지만 뉴스 데이터로 학습된 기계번역 모델은 동일한 뉴스 데이터를 추가 학습해도 정형화되어 있지 않은 뉴스 데이터의 특성으로 인해 번역 모델의 품질 향상 폭이 크지 않다. 이에 본 연구에서는 이러한 뉴스 데이터가 가진 구조적 한계점을 보완하기 위해 정형화된 문장 구조를 가진 특허 데이터를 기계학습 시 학습 데이터에 추가하여 번역 품질을 향상시키고자 하였다. 현재 다양한 문장 구조를 가진 학습 데이터를 조합하여 기계번역 품질을 향상시키는 연구는 많이 이루어지지 않았으며, 대부분의 연구는 학습 데이터 자체의 품질이나 오류율을 최소화하는 데 중점을 두고 있다. 이를 위해 본 연구는 다양한 문장 구조를 가진 뉴스 학습 데이터와 정형화된 문장 구조를 가진 특허 학습 데이터의 비율을 조정하여 다양한 번역 모델을 생성하였고, 생성된 번역 모델의 품질 변화에 대한 분석을 수행하였다. 실험 결과, 뉴스 데이터와 특허 데이터의 비율을 2:8로 조정한 학습 데이터로 생성한 모델의 품질이 가장 좋게 나타났으며, 뉴스 데이터로만 학습한 모델 대비 66.7% 높은 품질을 보이는 것으로 나타났다.","Recent advances in AI technology have rapidly made it relatively easy for the public to develop translation systems that were previously difficult to create. Generally, increasing the amount of training data has tended to improve translation quality. However, machine translation models trained on news data do not show significant improvements in translation model quality even when additional news data is used for training, due to the unstructured nature of news data. In this study, we aimed to enhance translation quality by supplementing training data with patent data that has structured sentence patterns to address these structural limitations of news data. Research on improving machine translation quality by combining training data with various sentence structures is not extensively conducted, with most focusing on minimizing the quality or error rate of the training data itself. To address this, we generated various translation models by adjusting the ratio of news training data with structured patent training data and analyzed the quality changes of the generated translation models. Experimental results showed that the model trained with a 2:8 ratio of news data to patent data exhibited the highest quality, demonstrating a 66.7% improvement compared to models trained only on news data."
생성형 AI 모델의 대규모 비밀번호 생성 및 추측공격 성능 검증,2024,"['Password Guessing', 'Password Security', 'Generative AI', 'LLMs']","비밀번호 추측 공격이 진보하면서 기존 비밀번호 보안 방책의 효율성을 재고할 필요가 있다. 본 논문은 생성형 AI의 대규모 비밀번호 생성에 기반한 추측 공격에 대해 연구하였다. 본 논문에서는 트랜스포머 기반 아키텍처의 장점과 언어 모델이 갖는 실제적인 비밀번호 생성의 장점을 결합한 하이브리드 모델인 PassGPT+Llama3.2를 제안한다. 비밀번호 유출 공개 데이터셋 수집 및 전처리 과정을 거쳐 비밀번호의 다양하고 복잡한 구조를 반영한 데이터셋을 구축하였으며, 이를 활용하여 학습 및 검증을 수행하였다. 본 논문에서 제안한 모델은 학습 시 1시간 45분 소요되었으며, 비밀번호 생성에 22분이 소요되었다. 또한 본 논문에서 제안하는 모델은 기존 모델에 비해 높은 Hit Rate를 보였으며, 이는 실제적인 비밀번호를 생성하는 모델의 우수한 능력을 보여준다. 본 연구는 비밀번호 보안에 있어서의 생성형 AI의 역할을 확인하고 AI 기반 추측 공격에 대한 진보된 방어책이 필요함을 시사한다.","In cybersecurity, sophisticated guessing attacks continually challenge the effectiveness of password security measures. This paper investigates the potential of generative artificial intelligence models for large-scale password generation and their implications for guessing attacks. We introduce PassGPT+LLaMa3.2, a hybrid model that combines the strengths of transformer-based architectures with advanced linguistic modeling capabilities to generate highly realistic passwords. Our experiments were conducted on a private dataset, comprising a diverse array of password structures to evaluate the performance of our model in terms of training and testing efficiency. Our findings demonstrate that PassGPT+Llama3.2 significantly enhances the diversity and realism of generated passwords, achieving a training time of 1h 45min and a testing time of 22min. Moreover, our model exhibits higher Hit Rate compare to existing models, indicating its effectiveness in mimicking real-world password patterns. This research underscores the impact of generative AI on password security, highlighting the need for advanced defenses against AI-driven guessing attacks."
KoGPT-2 언어 모델을 이용한 유아의 감정에 따른 동화 생성 시스템 설계,2024,"['동화 생성', 'KoGPT-2 언어 모델', 'KoBERT 언어 모델', '감정 분석', 'TTS(Text-To-Text)', 'STT(Speech-To-Text)', 'CNN+STN(Convolution Neural Network + Spatial Transformer Network)']",동화는 시공간적 제약을 많이 받는 유아들에게 간접적 삶의 경험을 제공한다. 간접적 삶의 경험은 유아들의 정서 발달에 영향을 끼친다. 본 논문은 유아들을 위한 동화 생성 시스템을 제안한다. 본 논문은 KoGPT-2 언어 모델을 적용하여 동화를 생성하고 영상 인식과 자연어 인식 모델을 적용하여 유아들의 감정을 분석한다. 제안된 시스템은 이미지 기반 영상처리와 언어기반 자연어처리를 통해 감정을 분석한다. 이미지 기반 감정 분석 모듈은 카메라를 통해 유아들의 표정 이미지를 수집하고 CNN+STN(Convolution Neural Network + Spatial Transformer Network) 구축하여 유아 표정 이미지에 대한 감정을 분석한다. 언어기반 감정 분석 모듈은 마이크를 통해 입력된 음성 데이터를 STT(Speech-To-Text)를 통해 변환하여 수집하고 KoBERT 언어 모델을 적용한 후 언어에서 획득 가능한 감정을 분석한다. 제안된 시스템은 이미지와 언어기반 감정 분석 모델을 융합하여 도출된 감정 결과를 기반으로 Fine-Tuning 한 KoGPT-2 언어 모델을 사용하여 동화를 생성한다. 생성된 동화는 TTS(Text-To-Speech)로 유아들에게 음성으로 들려주도록 제공된다.,다국어 초록 정보 없음
적응적 채널 분할 방법을 통한 저복잡도 비전 트랜스포머,2024,"['Deep learning', 'Vision transformer', 'Low complexity', 'Adaptive channel partitioning', 'Edge device']","최근 컴퓨터 비전 연구에서는 비전 트랜스포머가 백본 네트워크로써 높은 성능을 입증했지만, 높은 네트워크 복잡도로 인해 에지장치로의 배포는 여전히 제한적이다. 본 논문에서는 에지 장치로의 적용을 용이하게 하기 위해, 적응적 채널 분할 방법을 통한 저복잡도 비전 트랜스포머 모델을 제안한다. 본 논문에서는 분할할 채널의 비율과 레이어의 민감도에 따라 제안 방법을 적응적으로 적용하여, 모델의 연산량 및 메모리 부담을 개선하면서도 정확도 손실율을 최소화한다. 본 논문의 5-겹 교차 검증의 실험 결과, 제안하는 저복잡도 비전 트랜스포머는 기존 비전 트랜스포머 모델 대비 FLOPs 약 24.9%, 파라미터 수 약 40.4%, 추론 속도 약 16.7%의 개선을보였으며, 분류 정확도는 Top 1 Accuracy 기준 최대 1.18%p 향상되었다.","Recent research in computer vision has demonstrated the high performance of Vision Transformers as backbone networks;however, their deployment to edge devices remains limited due to their high network complexity. In this paper, we propose alow-complexity Vision Transformer model facilitated for edge device deployment through an adaptive channel partitioning method.The proposed method adaptively applies according to the sensitivity of the layers and the ratio of channels partitioned, therebyimproving the model's computational and memory burden while minimizing accuracy loss. Our experimental results, using 5-foldcross-validation, showed a reduction of about 24.9% in FLOPs, 40.4% in the number of parameters, and a 16.7% improvement ininference speed compared to existing Vision Transformer models, with an increase in classification accuracy of up to 1.18percentage points in terms of Top 1 Accuracy."
수어 번역을 위한 3차원 컨볼루션 비전 트랜스포머,2024,"['Sign Language Translation', 'Transformer', 'Convolutional Transformer', '수어 번역', '트랜스포머', '컨볼루전 트랜스포머']","한국에서 청각장애인은 지체장애인에 이어 두 번째로 많은 등록 장애인 그룹이다. 하지만 수어 기계 번역은 시장 성장성이 작고, 엄밀하게주석처리가 된 데이터 세트가 부족해 발전 속도가 더디다. 한편, 최근 컴퓨터 비전과 패턴 인식 분야에서 트랜스포머를 사용한 모델이 많이 제안되고있는데, 트랜스포머를 이용한 모델은 동작 인식, 비디오 분류 등의 분야에서 높은 성능을 보여오고 있다. 이에 따라 수어 기계 번역 분야에서도트랜스포머를 도입하여 성능을 개선하려는 시도들이 제안되고 있다. 본 논문에서는 수어 번역을 위한 인식 부분을 트랜스포머와 3D-CNN을 융합한3D-CvT를 제안한다. 또, PHOENIX-Wether-2014T [1]","In the Republic of Korea, people with hearing impairments are the second-largest demographic within the registered disabilitycommunity, following those with physical disabilities. Despite this demographic significance, research on sign language translationtechnology is limited due to several reasons including the limited market size and the lack of adequately annotated datasets. Despitethe difficulties, a few researchers continue to improve the performacne of sign language translation technologies by employing the recentadvance of deep learning, for example, the transformer architecture, as the transformer-based models have demonstrated noteworthyperformance in tasks such as action recognition and video classification. This study focuses on enhancing the recognition performanceof sign language translation by combining transformers with 3D-CNN. Through experimental evaluations using the PHOENIX-Wether-2014Tdataset [1], we show that the proposed model exhibits comparable performance to existing models in terms of Floating Point OperationsPer Second (FLOPs)."
다중 시멘틱 세그멘테이션 AI 기반의 가전용 크림프 하네스 검사 모델 개발,2024,"['Wire harness', 'Crimp harness inspection', 'Multi class semantic segmentation', 'U-Net']","와이어 하네스는 가전제품, 전기자동차, 자율주행 자동차에서 혈류의 역할을 하는 임의의 전기적회로의 상호 연결을 제공하는 와이어의 그룹으로 정의되며 품질이 가장 중요한 척도이다. 와이어 하네스 품질 불량은 제품 고장, 화재, 인명사고와 직결되기 때문이다. 본 논문은 와이어 하네스 압착공정 결과물인 크림프 하네스의 불량을 판정하기 위해, 다중 시멘틱 세그멘테이션 기법을 활용하는 방법을 제안하였다. 크림프 하네스의 불량 판정 문제는 전처리된 하네스 데이터로부터 연속된 5개 세그먼트들의 높이 및 폭의 길이를 정확히 측정하면 가능한 것으로 판단되었다. 이에 착안하여 대표적인 시멘틱 세그멘테이션 모델인 U-Net을 기반으로 다중 세그먼트 식별에 적합한 AI 모델의 개발을 목표로 하였다. 다중 세그먼트 식별을 위해 U-Net의 인코더 부분을 ResNet 34, EfficientNet B1 및 Mix Transformer B0로 변형한 모델을 제안하였다. 인공지능 모델 개발을 위해, 데이터셋 구축에는 와이어 하네스 제조공장에서 수집된 크림프 하네스 이미지들을 사용하였다. 개발된 다중 시멘틱 세그멘테이션 AI 모델은 테스트 데이터셋에 대해 95.14%의 판별 정확도를 나타내었다. 제안된 방법은 종래의 방법(수작업, 압착센서 측정값 및 규칙 기반의 영상처리)의 단점을 개선한, 균일한 고품질 유지와 인건비 절감이 가능하다.","Wire harness is defined as groups of wires providing interconnections for arbitrary electrical circuits that serve as the bloodstream in consumer electronics, electric vehicles, and autonomous cars. Poor wire harness quality is directly related to produce product failures, fires, and human casualties. This paper proposes a method that utilizes multi-class semantic segmentation techniques to determine the defects of the crimp harness, which is the result of a product of the wire harness crimp process. The problem of defect detection of crimp harness can be solved by accurately measuring the height and width of five consecutive segments from the preprocessed harness data. With this insight, we aimed to develop an AI model suitable for multi-segment identification based on U-Net, a representative semantic segmentation model. To identify multiple segments, we proposed a model that modifies the encoder part of U-Net using Resnet 34, EfficientNet B1, and Mix Transformer B0. For AI model development, images of crimp harnesses collected from a wire harness manufacturing plant were used to build the dataset. The developed multi-class semantic segmentation AI model showed a discernment accuracy of 95.14% on the test dataset. Through the method proposed in this paper, it is possible to maintain uniform high quality and reduce labor costs, which improves the shortcomings of the existing crimp harness quality inspection(manual, crimp sensor measurements, and rule-based image processing)."
트랜스포머 오리지널 시리즈에 나타난 변신의 원리와 새로운 영화 양식,2024,"['트랜스포머 오리지널 시리즈', '변신', '탈-연속성', '혼돈의 영화', '탈상관적 이미지', 'Transformers original series', 'Transformation', 'Post-continuity', 'Chaos cinema', 'Discorrelated images']","이 연구는 트랜스포머 오리지널 시리즈에서 나타나는 로봇의 변신에 대한 분석을 통해서 동시대 대중영화의 새로운 양식을 고찰해보기 위한 시도이다. 2000년대 전후로 빠른 편집, 자유로운 카메라의 움직임, 화려한 효과를 앞세운 영화들이 하나의 경향을 이루었다. 이 새로운 경향을 설명하기 위해 강화된 연속성, 혼돈의 영화, 탈-연속성, 탈상관적 이미지와 같은 개념이 쓰였다. 이런 논의는 동시대 영화가 서사 중심적인 영화 모델을 넘어서 이미지 중심적인 영화 모델, 즉 관객에게 시각적 스펙터클에 대한 경험을 제공하기 위한 새로운 양식을 구축했다는 것을 의미한다. 트랜스포머 오리지널 시리즈는 로봇의 변신을 하나의 스펙터클로 활용한다. 이 시리즈에서 로봇의 변신은 크게 조립에 기반한 변신, 합체에 기반한 변신, 입자에 기반한 방식을 따른다. 디지털 시각효과를 통해 구현된 각각의 변신은 인간의 시각적 역량을 벗어나는 비가시적, 인간의 지각과 인지에 과부하를 일으키는 초과적, 인간과 로봇을 포함한 모든 대상의 존재 방식을 넘어서는 초월적 특징을 갖는다. 이처럼 오늘날 디지털 영화 이미지는 고전적인 연속성의 체계를 무너뜨리거나 대체하면서 관객에게 비가시적, 초과적, 초월적인 양식에 기초한 새로운 영화 경험을 제공하고 있다.","This study is an attempt to examine a new style of contemporary popular film through an analysis of robot transformations in the Transformers original series. The robot transformation largely follows the method of assembly-based transformation, combination-based transformation, and particle-based transformation. Each transformation, implemented through digital visual effects, has invisible characteristics beyond human visual capacity, excessive to the point of overloadings human perception and cognition, and a transcendental beyond exisence of all objects, including humans and robots. As such, today’s digital film images disrupt or replace the classical system of continuity, providing audiences with a new cinematic experience based on invisible, excessive, and transcendental styles."
트랜스포머 기반 협력 추론 기술 연구 동향,2024,[],"최근 엣지 디바이스에서 인공지능(AI)을 활용하는 수요가 급격히 증가하면서, 협력 추론이 중요한 연구 분야로 부상하고 있다. 엣지 디바이스는 발전을 거듭하고 있지만, 여전히 제한된 연산 자원으로 인해 고성능 인공지능 모델을 직접 사용하기 어렵고, 모든 데이터를 서버로 전송할 경우 과도한 통신 비용이 발생할 수 있다. 이러한 문제를 해결하기 위해 제안된 협력 추론 기법은 엣지 디바이스와 서버 간에 인공지능 모델의 연산을 분담하여, 높은 추론 정확도를 유지하면서도 통신 비용을 효율적으로 절감할 수 있는 방안을 제시한다. 하지만 최근 주목받고 있는 트랜스포머(transformer) 모델은 구조적 특성상 기존의 협력 추론 방식의 모델 분할로는 통신량을 줄일 수 없다. 본 논문에서는 이러한 한계를 극복하여 트랜스포머를 효과적으로 활용할 수 있는 협력 추론 기술의 최신 연구 동향에 대해서 소개한다.",다국어 초록 정보 없음
트랜스포머 기반 네트워크를 활용한 SAR 유류 유출 탐지 전이 학습 기법,2024,[],"빠른 유류 유출 사고 대응을 위해 워성 영상을 활용한 유류 유출 탐지의 중요성이 커지고 있다. 이에 본 논문에서는 자연 영상에서 사전 학습된 트랜스포머 모델 기반의 SegFormer 모델을 활용해 SAR 영상을 이용한 유류 유출 탐지 모델을 제안하고자 한다. 본 모델은 입력 위성 영상을 다양한 크기의 특성맵으로 추출하는 인코더와 이를 조합하여 segmentation 결과를 도출하는 다중 퍼셉트론을 활용한 디코더로 구성되어 있으며, 이를 크로스 엔트로피 손실함수와 주사위 손실함수를 이용해 학습하였다. 실험 결과, 제안된 네트워크는 다른 모델 대비 mIoU 와 F1-score 에서 향상된 성능을 보였다.",다국어 초록 정보 없음
트랜스포머를 이용한 거리함수 기반 포인트 클라우드 개선,2024,"['Point cloud', 'Implicit neural representation', 'Vision transformer']","3D 센서의 놀라운 발전에도 불구하고, 취득된 3차원 포인트 클라우드는 잡음, 낮은 밀집도, 그리고 비균일성과 같은 문제점을 나타내는 경향이 있다. 이러한 데이터를 이용해 3D 콘텐츠의 다양한 산업군에 적용했을 때, 성능이 저하되기 때문에 포인트 클라우드의품질을 향상시키는 것은 중요하다. 그러나 기존 네트워크 기반의 포인트 클라우드 품질 향상 기법은 신경망의 한계로 인하여 몇 가지의 문제가 있었다. 본 논문에서는 거리함수 기반의 트랜스포머 모델을 제안한다. 제안하는 모델은 실제 포인트 클라우드와 입력 포인트 클라우드 간 거리를 예측한다. 제안하는 방법은 기존 방법들보다 뛰어난 성능을 보였다. Chamfer distance (CD), Hausdorffdistance (HD), 그리고 ground truth mesh 데이터와 예측한 포인트 클라우드 간 거리를 나타내는 point-to-surface distance (P2F) 3가지 측정에서 모두 기존 Grad-PU보다 우수한 값을 보였다.","Despite of the superior advancement of 3D sensors, raw 3D point clouds are poor quality including noisy, sparse, and irregularity.Because these point clouds cause performance degradation in various 3D applications, enhancing raw point clouds is important.However, existing learning-based point cloud super-resolution methods have some limitations in the architecture of neural networks.In this paper, we propose transformer-based model applying distance fields. Our network predicts the distance between input pointcloud and ground truth point cloud. Experiments demonstrate our method outperforms existing methods.It exhibited superior valuesin all three measurements: Chamfer Distance (CD), Hausdorff Distance (HD), and point-to-surface distance (P2F) when compared tothe existing Grad-PU, indicating a closer distance between the predicted point cloud and the ground truth mesh data."
"심층신경망으로 가는 통계 여행, 세 번째 여행: 언어모형과 트랜스포머",2024,"['language model', 'transformer', 'multi-head attention', 'encoder-decoder', 'positional encoding', '언어모형', '트랜스포머', '다중어텐션', '인코더-디코더', '위치인코딩']","지난 10년의 기간 심층신경망의 비약적 발전은 언어모형의 개발과 그 발전을 함께 해 왔다. 언어모형은 초기 RNN을 이용한 encoder-decoder 모형의 형태로 개발되었으나, 2015년 attention이 등장하고, 2017년 transformer가 등장하여 혁명적 기술로 성장하였다. 본연구에서는 언어모형의 발전과정을 간략하게 살펴보고, 트랜스포머의 작동원리와 기술적 요소에 대하여 구체적으로 살펴본다. 동시에 언어모형, 트랜스포머와 관련되는 통계모형과, 방법론에 대하여 함께 검토한다.","Over the past decade, the remarkable advancements in deep neural networks have paralleled the development and evolution of language models. Initially, language models were developed in the form of Encoder-Decoder models using early RNNs. However, with the introduction of Attention in 2015 and the emergence of the Transformer in 2017, the field saw revolutionary growth. This study briefly reviews the development process of language models and examines in detail the working mechanism and technical elements of the Transformer. Additionally, it explores statistical models and methodologies related to language models and the Transformer."
계층구조의 트랜스포머 기반 상세 뷰 자율주행차 궤적 예측 기법,2024,"['Autonomous driving', 'Trajectory prediction', 'Deep learning', 'Transformers', 'Spatial context encoding']",자율 주행 차량의 궤적을 정확하게 예측하는 것은 안전한 주행을 보장하는 데 필수적이지만 멀티모달 미래 궤적을 예측하는 것은 어려울 수 있다. 어텐션과 트랜스포머와 같은 최근의 접근 방식은 에이전트 상호 작용과 지도 문맥를 고려하여 최첨단 성능을 달성하였다. 본 연구에서는 트랜스포머를 사용한 에이전트 중심 접근 방식을 사용하여 환경에 대한 포괄적인 이해를 제공하는 궤적 예측에 초점을 맞추었다. 제안한 접근 방식은 주변 에이전트나 차선을 레벨로 배치하고 각 레벨의 정보를 인코딩하는 상세 뷰 공간 컨텍스트 인코딩을 도입하여 복잡한 공간 관계를 효율적으로 인코딩할 수 있다. 제안 궤적 예측 기법에 트랜스포머 모델을 적용하였다. 제안 기법은 아르고버스 벤치마크에서 평가되었으며 정확도 측면에서 최첨단 기법 대비 우수함을 보였다.,"Accurately predicting the trajectory of an autonomous vehicle is essential for ensuring safe navigation, but it can be challenging to predict multimodal future trajectory. Recent approaches, such as attention and transformers, have achieved state-of-the-art performance by considering agent interactions and map contexts. In this study, the focus was on trajectory prediction using an agent-centric approach with transformers, which provides a comprehensive understanding of the environment. Our proposed approach introduces a detailed-view spatial context encoding that arranges nearby agents or lanes into levels and encoding the information of each level, which enables the efficient encoding of complex spatial relationships. We adopt the transformer model to our proposed trajectory prediction scheme. Our approach was evaluated on the Argoverse benchmark and outperformed the state-of-the-art baseline in terms of accuracy."
GPT 모델을 이용한 게임 NPC 및 퀘스트 생성 모듈 구현,2024,[],국문 초록 정보 없음,"GPT (Generative Pre-trained Transformer) model is Transformer model-based Language Model. In this study, an attempt was made to develop a module that automatically generates Role Playing Game’s Non-Player Character and Quests according to input parameters using GPT model. The offered module is expected to reduce development time and increase reusability in roleplaying games."
대형 언어 모델: 영상의학 전문가를 위한 종합 안내서,2024,"['Natural Language Processing', 'Large Language Model', 'Transformer', 'Radiology', 'Chatbot', 'ChatGPT']","대형 언어 모델은 자연어 처리 분야에 국한되지 않고 기술 산업의 거의 모든 분야에서부터일상생활에 이르기까지, 전 지구적인 혁신을 가져왔다. 방대한 데이터셋에 대한 광범위한 사전 훈련 덕분에 현대의 대형 언어 모델들은 일반적인 작업뿐 아니라 의료 영상과 같은 전문적인 분야의 작업까지 수행 가능하게 되었다. 업체들은 매우 빠른 속도로 버전 업데이트 및신규 모델 출시를 발표하고 있고, 그로 인해 초기에 지적되었던 여러 문제점과 한계점들이하나씩 해결되어 가고 있다. 또한 초기의 스케일링 업 방식의 발전 방향성에서 탈피하여 최근에는 작아진, 온프레미스 오픈 소스 대형 언어 모델의 개념이 주목받고 있고, 이로 인해 전문 의료지식에 대한 미세조정, 훈련 효율성 제고, 개인정보 문제 해결, 성능 변동 관리 등의이슈들이 해결되어 가고 있다. 본 종설은 대형 언어 모델을 활용하려는 영상의학 전문가에게, 관련 기술에 대한 개념적 지식과 실용적인 지침, 그리고 현재의 기술 지형과 미래 방향성등을 통합적으로 제공하고자 작성되었다.","Large language models (LLMs) have revolutionized the global landscape of technology beyond the field of natural language processing. Owing to their extensive pre-training using vast datasets, contemporary LLMs can handle tasks ranging from general functionalities to domain-specific areas, such as radiology, without the need for additional fine-tuning. Importantly, LLMs are on a trajectory of rapid evolution, addressing challenges such as hallucination, bias in training data, high training costs, performance drift, and privacy issues, along with the inclusion of multimodal inputs. The concept of small, on-premise open source LLMs has garnered growing interest, as fine-tuning to medical domain knowledge, addressing efficiency and privacy issues, and managing performance drift can be effectively and simultaneously achieved. This review provides conceptual knowledge, actionable guidance, and an overview of the current technological landscape and future directions in LLMs for radiologists."
자기 교사 학습 모델의 특장점 분석과 사진 분류 및 객체 탐지 성능 분석 연구,2024,"['self-supervised learning', 'contrastive learning', 'knowledge distillation', 'computer vision', 'object detection', 'semantic segmentation', 'convolutional neural network', 'transformer', '자기 교사 학습', '대조학습', '지식 증류', '컴퓨터 비전', '객체 탐지', '객체 분할', '합성곱 신경망', '트랜스포머']","최근, 교사 학습 기반의 인공지능 분야가 급속도로 발전하고 있다. 그러나 교사 학습은 정답 값이 지정된 데이터집합에 의존하기 때문에, 정답 값을 확보하기 위한 비용이 커진다. 이러한 문제점을 해결하기 위해 정답 값없이 사진의 일반적인 특징을 학습할 수 있는 자기 교사 학습(Self-supervised learning)이 연구되고 있다. 본 논문에서는 다양한 자기 교사 학습 모델을 학습 방식과 백본 네트워크 기준으로 분류하고, 각 모델의 장단점, 성능을 비교 분석하였다. 성능 비교를 위해 사진 분류 작업을 사용하였다. 또한 전이 학습의 성능을 비교하기 위해 세밀한 예측 과업의 성능 또한 비교 분석하였다. 그 결과, 긍정적 쌍만 사용하는 모델이 노이즈를 최소화하여 부정적인 쌍을 같이 사용하는 모델들보다 높은 성능을 달성하였다. 또한 세밀한 예측의 경우 이미지를 마스킹하여 학습하거나 멀티스테이지 모델 등을 활용하여 지역적인 정보를 추가로 학습하는 방식이 더욱 높은 성능을 달성한 것을 확인하였다.","Recently, the field of teacher-based artificial intelligence (AI) has been rapidly advancing. However, teacher-based learning relies on datasets with specified correct answers, which can increase the cost of obtaining these correct answers. To address this issue, self-supervised learning, which can learn general features of photos without needing correct answers, is being researched. In this paper, various self-supervised learning models were classified based on their learning methods and backbone networks. Their strengths, weaknesses, and performances were then compared and analyzed. Photo classification tasks were used for performance comparison. For comparing the performance of transfer learning, detailed prediction tasks were also compared and analyzed. As a result, models that only used positive pairs achieved higher performance by minimizing noise than models that used both positive and negative pairs. Furthermore, for fine-grained predictions, methods such as masking images for learning or utilizing multi-stage models achieved higher performance by additionally learning regional information."
이미지의 인지적 특징 정량화를 통한 CNN-ViT 하이브리드 미학 평가 모델,2024,"['Image aesthetic assessmet', 'Transformer', 'Convolutional neural network', 'color harmony', 'image processing']","본 논문에서는 이미지의 지역적 및 전역적 특징을 결합하여 이미지의 미학적 품질을 자동으로 평가할 수 있는 CNN-ViT 하이브리드 모델을 제안한다. 이 접근 방식에서는 CNN을 사용하여 색상 및 객체 배치와 같은 지역적 특징을 추출하고, ViT를 통해 전역적 특징을 반영하여 이미지의 미학적 가치를 분석한다. Color composition은 입력 이미지에서 주요 색상을 추출해 생성한 컬러팔레트를 CNN에 통과시켜 얻은 값이며, Rule of Third는 이미지 속 오브젝트가 삼등분할점에 얼마나 근접한지를 정량적으로 평가한 점수로 사용된다. 이러한 값들은 모델에 이미지의 주요 평가 요소인 색채와 공간 균형에 대한 정보를 제공한다. 모델은 이를 바탕으로 이미지의 점수와 색상, 공간의 균형 간에 연관성을 분석하며, 인간의 평가 분포와 유사한 점수를 추측하도록 설계되었다. 실험 결과, AADB 이미지 데이터베이스에서 스피어만순위상관계수(SRCC)에서는 0.716을 기록하여 순위 예측에서 더 일관된 결과를제공 했으며, 피어슨상관계수(LCC)에서도 0.72을 기록하여 기존 연구 모델보다 2~4% 정도 향상된 결과를 보였다.","This paper proposes a CNN-ViT hybrid model that automatically evaluates the aesthetic quality of images bycombining local and global features. In this approach, CNN is used to extract local features such as color andobject placement, while ViT is employed to analyze the aesthetic value of the image by reflecting global features.Color composition is derived by extracting the primary colors from the input image, creating a color palette, andthen passing it through the CNN. The Rule of Thirds is quantified by calculating how closely objects in the imageare positioned near the thirds intersection points. These values provide the model with critical information aboutthe color balance and spatial harmony of the image. The model then analyzes the relationship between thesefactors to predict scores that align closely with human judgment. Experimental results on the AADB image databaseshow that the proposed model achieved a Spearman's Rank Correlation Coefficient (SRCC) of 0.716, indicatingmore consistent rank predictions, and a Pearson Correlation Coefficient (LCC) of 0.72, which is 2~4% higher thanexisting models."
전이학습을 이용한 신발 이미지 스타일 분류모델 연구,2024,"['전이학습', '신발 스타일 분류', '신발 아웃솔', '신발 갑피', 'Transfer Learning', 'Shoes Style Classification', 'Shoes Outsole', 'Shoes Upper', 'ConvNeXt']","전자상거래의 성장과 4차산업혁명 기술 발전에 따라 패션 산업에서 인공지능을 접목한 서비스가 활발히 도입되고 있으나 신발 산업은 아직 관련 연구가 깊게 되어 있지 않아 활용 사례 및 데이터셋이 부족하다. 본 논문에서는 웹크롤링으로 운동화, 스니커즈 이미지를 수집하고 디자인 및 제조 관점을 반영하여 신발 스타일과 아웃솔, 갑피에 대해서 라벨링하였다. 구축한 약 2만건의 데이터셋을 대상으로 ResNet, ConvNeXt, ViT, Swin Transfomer를 전이학습하고 각 모델의 결과를 비교하였다. 그 결과 ConvNeXt 모델에서 가장 우수한 결과를 얻었고 과적합을 방지하기 위해 추가로 파인튜닝하여 테스트 데이터셋 대상으로 정확도 87%의 결과를 얻었다. 본 연구를 바탕으로 신발 산업에서 디자인 및 제조 기술에 딥러닝 모델을 활용하여 생산성을 향상시킬 수 있을 것이라 기대한다.","With the growth of e-commerce and the development of the 4th Industrial Revolution technologies, services using AI are being actively introduced in the fashion industry. However, the shoes industry has not yet been studied in-depth on AI and there is a lack of datasets and use cases. In this paper, we collected images of sneakers and running shoes by web crawling and labeled shoe styles, outsoles, and uppers from design and manufacturing perspectives. We trained ResNet, ConvNeXt, ViT and Swin Transformer on our dataset and compared the results of each model. As a result, the ConvNeXt model obtained the best results and was further fine-tuned to prevent overfitting, resulting in 87% accuracy on the test dataset. Based on this study, We expect that deep learning will be used in design and manufacturing process to improve productivity in the shoe industry."
SWT-SVD 전처리 알고리즘을 적용한 예측적 베어링 이상탐지 모델,2024,"['베어링 이상탐지', '설비예지보전', '딥러닝', '주파수변환', 'Bearing anomaly detection', 'PHM', 'Deep learning', 'Frequency transform']","섬유, 자동차와 같은 여러 제조 공정에서 설비가 고장이 나 멈추게 되면 기계가 작동하지 않게 되고 이는 기업의 시간적, 금전적 손실로 이어진다. 따라서 설비의 고장이 발생하기 전, 고장을 예측하여 정비할 수 있도록 설비의 이상을 사전에 탐지하는 것이 중요하다. 대부분의 설비 고장 원인은 설비의 필수 부품인 베어링의 고장으로, 베어링의 고장을 진단하는 것은 설비예지보전 연구의 핵심이기도 하다. 본 논문에서는 베어링의 진동 신호를 분석하여 SWT-SVD 전처리 알고리즘을 제안하고 이를 시계열 이상탐지 모델 네트워크 중 하나인 어노멀리 트랜스포머에 적용하여 베어링 이상탐지 모델을 구현한다. 제조공정의 베어링 진동신호는 실시간으로 센서값들의 이력이 작성되어 노이즈가 존재하므로, 이를 줄이기 위해 본 연구에서는 정상 웨이블릿 변환(Stationary Wavelet Transform)을 사용하여 주파수 성분을 추출하고, 특이값 분해(Singular Value Decomposition) 알고리즘을 통해 유의미한 특징들을 추출하는 전처리를 진행한다. 제안하는 SWT-SVD 전처리 방법을 적용한 베어링 이상탐지 모델 실험을 위해 IEEE PHM학회에서 제공하는 PHM-2012-Challenge 데이터 세트를 활용하였으며, 실험 결과는 0.98의 정확도와 0.97의 F1-Score로 우수한 성능을 보였다. 추가로, 성능 향상을 입증하기 위해 선행 연구들과 성능 비교를 진행한다. 비교 실험을 통해 제안한 전처리 방법이 기존의 전처리보다 높은 성능을 보임을 확인하였다.","In various manufacturing processes such as textiles and automobiles, when equipment breaks down or stops, the machines do not work, which leads to time and financial losses for the company. Therefore, it is important to detect equipment abnormalities in advance so that equipment failures can be predicted and repaired before they occur. Most equipment failures are caused by bearing failures, which are essential parts of equipment, and detection bearing anomaly is the essence of PHM(Prognostics and Health Management) research. In this paper, we propose a preprocessing algorithm called SWT-SVD, which analyzes vibration signals from bearings and apply it to an anomaly transformer, one of the time series anomaly detection model networks, to implement bearing anomaly detection model. Vibration signals from the bearing manufacturing process contain noise due to the real-time generation of sensor values. To reduce noise in vibration signals, we use the Stationary Wavelet Transform to extract frequency components and perform preprocessing to extract meaningful features through the Singular Value Decomposition algorithm. For experimental validation of the proposed SWT-SVD preprocessing method in the bearing anomaly detection model, we utilize the PHM-2012-Challenge dataset provided by the IEEE PHM Conference. The experimental results demonstrate significant performance with an accuracy of 0.98 and an F1-Score of 0.97. Additionally, to substantiate performance improvement, we conduct a comparative analysis with previous studies, confirming that the proposed preprocessing method outperforms previous preprocessing methods in terms of performance."
자연 데이터로 학습한 의미론적 분할 모델의 생성 데이터 적용 사례 연구,2024,[],"본 논문은 자연 데이터로 학습된 트랜스포머 기반의 의미론적 분할 네트워크의 생성 데이터 적용에 대한 사례 연구를 진행한다. 최근 정확한 분할 작업이 중요한 자율 주행 분야가 높은 성과를 보이면서 도로 데이터 셋에 대한 관심도 높아지고 있다. 동시에 최신 생성 모델들은 사람이 보기에는 완성도 높은 결과를 도출하지만, 의미론적 분할 모델들의 기준에서 이러한 생성 이미지를 어떻게 인식하고 처리 되는지 명확하지 않다. 기존의 분할 모델들은 자연 이미지를 다루고 있어 이러한 모델들에 생성 이미지가 잘 적용되는지 검증이 필요하다. 따라서 본 연구에서는 자연 데이터 셋에 이미지 데이터 증대 기법을 적용하여 생성 데이터 셋을 구축하고, 이를 자연 데이터 셋으로 사전 학습된 의미론적 분할 모델에 적용하는 연구를 한다. 실험 결과, 원본의 자연 데이터와 비교해서 변화가 작은 데이터는 분할 작업에 잘 적용되는 것을 볼 수 있었고, 변화가 큰 데이터는 좋지 않은 결과를 보여 분할 작업에 적용이 되지 않은 것을 보여 주었다.",다국어 초록 정보 없음
SCA: Cross-Attention 지도 학습에 기반한 문서기반 응답 생성 모델의 성능 향상,2024,"['proxy signature', 'ID-based partially blind signature scheme', 'proxy partially blind signature scheme', 'gap Diffie-Hellman problem', 'bilinear-pairing', '사전학습 언어모델', 'Attention supervision', '트랜스포머', '문서 기반 응답 생성', 'QA']","문서 기반 응답 생성은 소비자 상담이나 보험 설계와 같이 정확한 사실에 기반한 근거가 되는 문서를 검색한 후, 해당 문서를 통해 대화 응답을 생성하는 작업을 의미한다. 이번 연구에서는 응답 생성 모델이 입력된 문서로부터 답변 생성에 필요한 부분을 찾아내어 반영하는 능력을 향상시키기 위해 Supervised Cross-attention을 제시했다. 이는 디코더의 Cross-attention에 대해 Attention Supervision을 적용하는 것으로, 입력 문서 중 실제 답변 생성에 포함되어야 하는 정보인 레퍼런스에 해당하는 부분에 Cross-attention 가중치가 집중되도록 지도학습 과정을 추가하는 것이다. 이 방법과 추가적인 성능 향상 방법을 도입한 결과 기존 SOTA 대비 F1 지표에서 1.13의 성능 향상을 확인하였고, Supervised Cross-attention을 통해 0.25의 성능 향상이 있었음을 확인했다.","Document-grounded response generation is the task of aiming at generating conversational responses by “grounding” the factual evidence on task-specific domain, such as consumer consultation or insurance planning, where the evidence is obtained from the retrieved relevant documents in response to a user’s question under the current dialogue context. In this study, we propose supervised cross-attention (SCA) to enhance the ability of the response generation model to find and incorporate “response-salient snippets” (i.e., spans or contents), which are parts of the retrieved document that should be included and maintained in the actual answer generation. SCA utilizes the additional supervised loss that focuses cross-attention weights on the response-salient snippets, and this attention supervision likely enables a decoder to effectively generate a response in a “saliency-grounding” manner, by strongly attending to the important parts in the retrieved document. Experiment results on MultiDoc2Dial show that the use of SCA and additional performance improvement methods leads to the increase of 1.13 in F1 metric over the existing SOTA, and reveals that SCA leads to the increase of 0.25 in F1."
공구 교체 시점 기반 라벨링을 활용한 공구 수명 예측 모델,2024,"['공구 마모', '공구 수명 예측', '딥러닝', 'CNC 선반 설비', '공구 교체', 'Tool Wear', 'Tool Life Prediction', 'Deep Learning', 'CNC Equipment', 'Tool Replacement']","제조업 분야에서 공구 마모는 생산성과 제품 품질 저하에 영향을 미치는 주요 요소로 인식되고 있다. 이를 해결하기 위해 공구 사용 횟수와 마모 기록을 라벨 데이터로 활용하여 공구 수명 예측 모델을 개발하고 있지만, 산업 현장에서는 다양한 가공 조건과 제품 생산 중단 등으로 공구 마모 데이터를 수집하기 어렵다. 또한 공구 사용 횟수는 공구품질 변동, 작업 환경 온습도 등의 요인으로 인해 사용 횟수가 동일하더라도 공구 마모도가 다르게 나타날 수 있다. 본 논문에서는 공구의 실제 교체 시기를 그 수명 종료로 간주하고 이를 기반으로 공구 교체 시점 기반 라벨링 방식을 제안하였다. 그리고 트랜스포머 기반 딥러닝 모델을 이용한 공구수명 예측 모델을 개발하고 성능 분석을 수행하였다.","In the manufacturing industry, tool wear is recognized as a major factor affecting productivity and product quality degradation. To solve this problem, tool life prediction models are being developed using the number of tool uses and wear records as labeling data, but it is difficult to collect tool wear data in industrial sites due to various machining conditions and product production interruptions. In addition, the number of tool uses can cause different tool wear degrees even if the number of uses is the same due to factors such as tool quality fluctuations and working environment temperature and humidity. In this paper, the actual replacement time of a tool is considered as the end of its life, and based on this, a tool replacement time-based labeling method is proposed, and a tool life prediction model using a transformer-based deep learning model is developed and performance analysis is performed."
비전 트랜스포머를 이용한 단일 리드 심전도 기반 사용자 인증 시스템,2024,"['Authentication', 'Vision Transformer', 'Electrocardiogram', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 모델을 적용한 재생 주물사의 품질 예측 연구,2024,"['Loss on ignition', 'Deep learning', 'Prediction', 'CNN-LSTM', 'Transformer']",국문 초록 정보 없음,다국어 초록 정보 없음
한국어 BERT 모델을 활용한 청각 정보 기반 광고 영상 분류 방법론,2024,"['광고 분류', '웹 크롤링', '자연어 처리', '청각적 정보 추출', 'Advertisement Classification', 'Auditory Information Extraction', 'BERT', 'Natural Language Process', 'Web Crawling']",국문 초록 정보 없음,"In this paper, we propose an effective classification methodology for video advertisements, focusing on the Korean languagebased natural language processing model Bidirectional Encoder Representations from Transformers (BERT). During the research process, advertisement video data are collected through internet crawling and processed through answer labeling and preprocessing to make them analyzable. Specifically, in the preprocessing stage, auditory information, that is, voice data, is extracted from the videos and converted into text. The Korean BERT (KoBERT) model is used for the experiment as the research method, and the methodology is verified to enhance the efficiency and accuracy of advertisement classification. This study is expected to enable more precise classification of advertising content, significantly enhancing the efficiency of the advertising industry."
TabTransformer와 조건부 GAN 알고리즘을 활용한 우리나라 대졸자 취업 만족도 예측 모델의 개선을 위한 데이터 증강 기법 연구,2024,"['직무 만족도', '탭트랜스포머', '조건부 생성적 적대 신경망', '데이터 증강', '멀티헤드 어텐션', 'Job Satisfaction', 'TabTransformer', 'Conditional GAN', 'Data Augmentation', 'Multi-Head Attention']",국문 초록 정보 없음,"This study integrates TabTransformer and CTGAN for predicting job satisfaction among South Korean college graduates. TabTransformer handles complex tabular data relationships with self-attention, while CTGAN generates high-quality synthetic samples. The combined approach achieves an accuracy of 0.85, precision of 0.83, recall of 0.82, F1-score of 0.82, and an AUC of 0.88. Cross-validation confirms the model's robustness and generalizability with a mean accuracy of 0.85 and a standard deviation of 0.008. The integration of TabTransformer and CTGAN enhances predictive accuracy and model generalizability, providing valuable insights for employment policy and research."
트윗 클러스터링을 통한 마약 조직 및 규모 식별 모델 개발,2024,"['Cyber Investigation', 'Drug', 'Social Media', 'Tweet', 'Clustering', '사이버 수사', '마약', '소셜미디어', '트윗', '클러스터링']","본 논문은 10대와 청년층에서 빈번하게 발생하는 마약 범죄를 수사하기 위해 소셜미디어 플랫폼 ‘X’에서마약 홍보 트윗을 수집하고, 이를 바탕으로 마약 유통 조직 및 규모를 식별하는 클러스터링 모델을 개발하는것을 목표로 한다. 최근 소셜미디어의 익명성을 악용한 마약, 불법 도박, 성범죄 등 다양한 사이버 범죄가증가하고 있으며, 특히 마약 유통 조직은 각 구성원이 자신의 역할에 대해서만 익명으로 지시를 받고, 다른 구성원들과 직접 연결되지 않은 점조직 형태로 운영되고 있다. 이러한 유형의 범죄를 추적하기위해 BERT(Bidirectional Encoder Representations from Transformers), GloVe(Global Vectors for Word Representation)와 같은 텍스트 임베딩 모델 및 K-means Clustering과 Spectral Clustering 등 다양한 클러스터링알고리즘을 활용하여 실험 시나리오를 설계하였다. 또한, 각 시나리오에서 도출된 클러스터링 결과를자카드 유사도(Jaccard Similarity) 및 전수조사 기반으로 검증하고, 모든 시나리오에서 동일한 마약 조직으로식별된 트윗 클러스터를 분석하여 사이버 수사 시, 추적 우선순위가 높은 계정을 식별한다.",다국어 초록 정보 없음
토지피복 분류를 위한 멀티 모달 모델의 활용 가능성 평가,2024,"['딥러닝', '멀티모달', '토지피복', 'Clip', 'Clipseg', 'Segformer', 'Unet', 'Deep learning', 'Multimodal', 'Land cover']",국문 초록 정보 없음,"This study was conducted to evaluate the potential of a multimodal model for land cover classification. The performance of the Clipseg multimodal model was compared with two unimodal models including Convolutional Neural Network (CNN)-based Unet and Transformer-based Segformer for land cover classification. Using orthophotos of two areas (Area1 and Area2) in Wonju City, Gangwon Province, classification was performed for seven land cover categories (Forest, Cropland, Grassland, Wetland, Settlement, Bare Land, and Forestry-managed Land). The results showed that the Clipseg model demonstrated the highest generalization performance in new environments, achieving the highest accuracy among the three models with an Overall Accuracy of 83.9% and Kappa of 0.72 in the test area (Area2). It performed particularly well in classifying Forest (F1-Score 94.7%), Cropland (78.0%), and Settlement (78.4%). While Unet and Segformer models showed high accuracy in the training area (Area1), they exhibited limitations in generalization ability with accuracy decreases of 29% and 20% respectively in the test area. The Clipseg model required the most parameters (approximately 150 million) and the longest training time (10 hours 48 minutes) but showed stable performance in new environments. In contrast, Segformer achieved considerable accuracy with the least parameters (about 16 million) and the shortest training time (3 hours 21 minutes), demonstrating its potential for use in resource-limited environments. This study shows that image-text-based multimodal models have a high potential for land cover classification. Their superior generalization ability in new environments suggests they can be effectively applied to land cover classification in various regions. Future research could further improve classification accuracy through model structure improvements, addressing data imbalances, and additional validation in diverse environments."
신경망 언어 모델 구축을 통한 중국어 문두 다중논항 어순 수용성 예측 연구,2024,"['문두 다중논항', '어순', '수용성 데이터', '신경망 언어 모델', '맥버트', 'AI 모델', '사전 훈련', '미세 조정', '어순 오류 식별', 'Sentence-Initial Multiple Arguments', 'Word Order', 'Acceptability Data', 'Neural Network Language Model', 'MacBERT', 'AI Model', 'Pre-trained', 'Fine-tuning', 'Word Order Error Detection']",국문 초록 정보 없음,"In this paper, we applied a transformer-based neural network language model to solve the word order problem in Chinese Sentence-Initial Multiple Arguments (SIMA) and verified its effectiveness. The study focused on the different constituents that occur at the beginning of Chinese sentences, their interactions, and how word order constraints contribute to grammaticality. The goal was to validate the effectiveness of natural language processing methods in determining the grammaticality of word order in Chinese SIMA.To investigate this, we constructed a specialized dataset and developed a predictive model. The SIMA dataset consists of 15,298 Chinese sentences. These sentences were labeled as grammatically correct or incorrect using a binary classification method. We developed a model to predict the acceptability of word order in SIMA and evaluated its accuracy. The model demonstrated a high level of accuracy in predicting word order, achieving 90% correctness compared to established grammatical norms.In addition, the study analyzed cases where the model’s predictions differed from native speakers’ judgments, showing that acceptability prediction is not just a simple binary distinction process. This led to a more nuanced understanding of the relationship between language model predictions and native speaker judgments. In the secondary analysis focusing on sentences where the AI model’s predictions diverged from native speaker judgments, we found that after reevaluation, a significant proportion of these sentences (94.8%) aligned closely with native judgments, highlighting the nuanced capabilities of our model. These findings not only demonstrate the effectiveness of our model in analyzing Chinese SIMA but also contribute to a deeper understanding of AI’s role in linguistic analysis."
인공지능의 법적 규율 Ⅰ: 범용모델과 생성모델,2024,"['인공지능', '범용모델', '생성모델', '저작권', '개인정보', 'general-purpose model', 'generative model', 'artificial intelligence', 'misuse', 'copyright', 'personal data']",국문 초록 정보 없음,"Transformer-based decoders offer generative capabilities without requiring fine-tuning, blurring the distinction between general-purpose and generative models. Given their disparate risk profiles, however, tailored legal oversight should be devised for each category. First, safety and security control over high-impact general-purpose models must be crafted to ensure alignment with international standards and national security objectives. Second, to broaden the scope of lawful data access, nebulous dataset protection legislation should be refined, with developers and providers tasked with mitigation measures based on infringement risk assessment. Particularly, developers of models intended for use in generative tasks should be mandated, (i) for retrieval-based models: to anonymize publicly unavailable personal data and compensate rightsholders through collective rights management (CRM) or private copying levies (PCV); and (ii) for generation-based models: to adopt reasonable mitigation measures to qualify for a safe harbor. Third, the misuse of synthetic media should be addressed by not only reinforced enforcement against misusers but also clear allocation of responsibilities across the value chain. Fourth, machine-assisted creation should be granted weaker legal protections. Finally, accuracy, fairness, and transparency concerns in general-purpose/generative models should be addressed by developing and standardizing measurement and mitigation technologies instead of immediate legal interventions."
Transformer fault acoustic identification model based on acoustic denoising and DBO-SVM,2024,['Transformer  · Core loosening  · Kurtosis value  · Dung Beetle optimization algorithm  · Support vector machine'],국문 초록 정보 없음,"In order to address the impact of ambient noise on the acquisition of the transformer body acoustic pattern and completely extract the information contained in the transformer acoustic pattern, This study suggests a transformer core loosening identifi cation technique based on the integration of wavelet threshold denoising and VMD with Identifi cation of transformer core loosening using DBO (Dung Beetle Optimization Algorithm)-optimized SVMs (Support Vector Machine) and the diff erence between the kurtosis value and the mixed acoustic signal is used to get the de-noised signal with a high signal-to-noise ratio.After that, the signal is fed into an optimized support vector machine for training in order to produce the core loosening identifi cation model. By means of the no-load tests conducted on a 500 V transformer and the examination of the acoustic signals gathered with varying levels of core looseness, the fi ndings demonstrate that the transformer core looseness identifi - cation model with the denoised MFCC feature parameters and the dung-beetle algorithm optimized support vector machine in this work achieves an accuracy of 96.25%, hence improving the core looseness fault identifi cation rate."
RF 신호 기반 다중 인물 자세 추정 성능 향상을 위한 모델 구조 분석 및 확장,2024,"['RF 신호', '트랜스포머 모델', '시각적 단서', '세그멘테이션 마스크', '다중 프레임 입력', 'RF-based pose estimation', 'multi-person pose estimation', 'cross-modal knowledge distillation', 'segmentation mask']",국문 초록 정보 없음,"An RF-based multi-person pose estimation system can estimate each human posture even when it is challenging to obtain clear visibility due to obstacles or lighting conditions. Traditionally, a cross-modal teacher-student learning approach has been employed. The approach utilizes pseudo-label data acquired by using images captured concurrently with RF signal collection as input for a pretrained image-based pose estimation model. In a previous research study, the research team applied cross-modal knowledge distillation to mimic the feature maps of image-based learning models and referred to it as ""visual cues."" This enhanced the performance of RF signal-based pose estimation. In this paper, performance is compared based on the ratio at which the learned visual cues are concatenated, and an analysis of the impact of segmentation mask learning and the use of multiframe inputs on multi-person pose estimation performance is presented. It is demonstrated that the best performance is achieved when visual cues and multiframe inputs are used in combination."
트랜스포머 기반 산림 및 도심지 의미론적 분할 및 탄소 저장량 예측,2024,"['Computer Vision', 'Deep Learning', 'Aerial Image', 'Corbon Storage', 'Sementic Segmantation']","대기 중 온실가스 농도가 높아짐에 따라 지구온난화가 가속화되며 핵심지표에서 정상범위를 벗어난 이상지표들이 관측되고 있다. 이에 우리나라는 기후변화를 완화시키기 위한 방법 중 하나로 탄소 중립을 실행하고 있으며 현재 탄소 저장량 측정은 현장조사와 원격 탐사 등의 방식을 활용하고 있다. 본 논문에서는 기존 방식의 낮은 공간 해상도와 정확도 문제를 해결하고자 상세한 측정이 가능한 현장조사와 비용과 시간, 공간 해상도가 높은 새로운 모델 제작을 시도했다. 해당 분야에서는 사용 전례가 없는 트랜스포머 구조를 기반으로 한 Segformer를 활용하였으며 항공영상에서 산림지 분할 정확도 0.8552, 저장량 예측 정확도 0.6342를 달성하였다. 추후 위성영상 기반 탄소 저장량 예측 모델 제작 시 기초 연구로 활용 가능할 것으로 예상된다.","As the concentration of greenhouse gases in the atmosphere increases, global warming is accelerating, and anomalies outside the normal range are being observed in key indicators. In response, Korea is implementing carbon neutrality as one of the ways to mitigate climate change. Currently, carbon storage measurement is using methods such as field survey and remote sensing. In this paper, we sought to address the limitations of existing methods, which are characterised by low spatial resolution and accuracy. To this end, we conducted field surveys with detailed measurements and developed a new model that exhibits high cost, time, and spatial resolution. Segformer, a transformer-based approach that represents a novel contribution to this field, was employed, resulting in an accuracy of 0.8552 for forest area segmentation and 0.6342 for storage volume prediction from aerial images. It is anticipated that this research will serve as a foundation for future satellite image-based carbon storage prediction models."
"RETRACTED ARTICLE: Determination of Power Transformer Fault’s Severity Based on Fuzzy Logic Model with GR, Level and DGA Interpretation",2024,['Transformer  · Duval Pentogan Method  · Harris Hawks Optimization  · Dissolved Gas analysis  · Gas Rate'],국문 초록 정보 없음,"Transformer defects are defi ned by their severity which is the intrinsic property of the transformer. Several approaches for identifying the severity of Power Transformer (PT) problems have previously been proposed; however, most published research does not incorporate Gas Level (GL), Gas Rate (GR), and DGA interpretation into a unifi ed strategy. A novel technique in the form of fuzzy logic (FL) has been off ered as a new way to assess faults’ severity by utilizing the combination of GL, GR, and DGA interpretation from the Duval Pentagon Method (DPM) to increase the reliability of the faults’ severity evaluation of PT. Based on the local population, a four-level typical concentration and rate were created. A Deep Learning (DL) oriented Convolutional Neural Network (CNN) based DPM and Harris Hawks Optimization (HHO) method with a high agreement to that same graphical DPM has also been devised to enable the evaluation of hundreds of PT information easy. The proposed method was applied to 448 PTs, and it was then used to assess the severity of problems in PTs using historical DGA data. Due to the integration of GL, GR, and DGA interpretation results in one technique, this novel strategy yields good agreement with earlier methods, but with better sensitivity."
트랜스포머 인코더를 활용한 음절 단위 경량화 형태소 분석기,2024,"['트랜스포머 인코더', '형태소 분석기', '형태소 품사 태깅', '순차적 레이블링', 'Transformer Encoder', 'Morphological Analysis', 'Part of Speech Tagging', 'Sequential-Labeling']",국문 초록 정보 없음,"Morphological analysis involves segmenting morphemes, the smallest units of meaning or grammatical function in a language, andassigning part-of-speech tags to each morpheme. It plays a critical role in various natural language processing tasks, such as namedentity recognition and dependency parsing. Much of modern natural language processing relies on deep learning-based language models,and Korean morphological analysis can be broadly categorized into sequence-to-sequence methods and sequential labeling methods. Thisstudy proposes a morphological analysis approach using the transformer encoder for sequential labeling to perform syllable-levelpart-of-speech tagging, followed by morpheme restoration and tagging through a pre-analyzed dictionary. Additionally, the CBOW methodwas used to extract syllable-level embeddings in lower dimensions, designing a lightweight morphological analyzer model with reducedparameters. The proposed model achieves fast inference speed and low parameter usage, making it efficient for use in resource-constrainedenvironments."
Life Estimation Correction Model for Offshore Wind Power Transformer Based on Fault Tree Theory,2024,['Ofshore transformers · Fault tree theory · Life prediction'],국문 초록 정보 없음,"The occurrence of fault would greatly afect the remaining life of ofshore wind power transformer. In this paper, the fault events during the operation of the ofshore power transformer were analyzed based on the fault tree theory and the structure function of the transformer fault event was established with considering the operation environment to propose the risk model of transformer fault events. The Monte Carlo method was used to sample the risk model, and the fault risk coefcient of the operation for the ofshore transformer was obtained. Taking the infuence of fault events into the remaining life of the transformer, a Life estimation correction model for ofshore wind power transformer was established, which provides guidance for the optimal design and early fault warning of ofshore transformers."
데이터 전처리를 간소화한 자연어처리 기반의 악성코드 탐지모델,2024,"['preprocessing', 'transformer', 'BERT', 'DistillBERT', 'BART', 'natural language processing', 'CIC-MalMem-2022']",국문 초록 정보 없음,"In order to train a machine learning or deep learning model to detect malware, it is essential to preprocess the data before training the model. And when new malware appears, the preprocessing process must be updated and applied to the model again. To solve these inefficiencies, this paper proposes a malware detection model based on natural language processing. After merging 55 attributes of the CIC-MalMem-2022 dataset into a single sentence separated by spaces, we trained the Transformer model, BERT, DistilBERT, and BART, and analyzed the classification performance. As a result, the detection performance of binary classification was similar to that of previous studies, and the accuracy of multi classification was 84.69%, 85.10%, and 84.44%, confirming that it can achieve excellent performance with a simple preprocessing process."
DNN 모델 추론을 위한 Lookup Table 기반 PIM의 가능성,2024,"['Processing-in-memory', 'Lookup Table', 'Transformer-based Generative Model', 'Recommendation System', '프로세싱 인 메모리', '룩업 테이블', '트랜스포머 기반 생성형 모델', '추천시스템']",국문 초록 정보 없음,"Processing-in-memory (PIM) is an accelerator that enables data to be processed closer to the stored memory. Due to the nature ofPIM specialized in data movement, PIM can be used as an efficient accelerator in transformer-based generative model and recommendationsystem, which have recently garnered attention. In this paper, we examine the latest research trends of PIM that enhance therecommendtation system and generative language model, which are suitable applications for PIM usage. Additionally, we discuss theresearch direction of PIM based on previous studies. Lastly, we verify the effectiveness of LUT in PIM systems through experiments."
비디오 스윈 트랜스포머 기반의 향상된  Visual Saliency 예측,2024,"['Video Saliency Prediction', 'Video Swin Transformer', 'Feature Pyramid Network', 'Multi Stage']",국문 초록 정보 없음,"In this paper, we propose a Video Swin Transformer Saliency Network (VST-SalNet). The proposed model utilizes the Video Swin Transformer as its backbone to effectively learn the spatiotemporal features of video data and is designed to handle long-range spatiotemporal dependencies. Additionally, it integrates high-level semantic information and low-level details through the application of a feature pyramid structure. This structure enables multi-scale feature fusion and refines spatial details across resolutions. In turn, the model enhances spatial resolution by effectively handling objects of various sizes, preserving semantic information, and minimizing information loss. Experimental results on DHF1K, Hollywood-2, and UCF Sports datasets, evaluated using metrics such as SIM and CC, confirm that VST-SalNet outperforms the state-of-the-art models."
GPT-3.5 기반 초거대 언어모델을 활용한 보이스피싱 탐지 기법,2024,"['large language model', 'GPT', 'voice phishing detection', 'prompt design', '초거대 언어모델', 'GPT', '보이스피싱 탐지', '프롬프트 설계']",국문 초록 정보 없음,"In this paper, we introduce a novel approach for voice phishing call detection, using text-davinci-003, which is a recently updated model from the generative pre-trained transformer (GPT) -3.5 language model series. To achieve this, we devised a prompt to let the language model respond with an integer ranging from 0 to 10, which indicates the likelihood that a given conversation is a voice phishing attempt. For prompt tuning, hyperparameter adjustment, and performance validation,we use a total of 105 actual Korean voice phishing transcripts and 704 transcripts from various topics of general conversations as our dataset. The proposed scheme includes a function to send voice phishing alarm during a call and a function to finally determine whether the call was a voice phishing after the call ends. Performance is evaluated in five different scenarios using different types of training and test data, demonstrating an accuracy range of 0.95 to 0.97 for the proposed technique. In particular, when tested with data from sources different from those used in training, the proposed scheme performs better than the existing bidirectional encoder representations from transformer (BERT) model-based schemes."
심전도 기반 사용자 인증 시스템의 인증 속도 및 효율성 개선을 위한 시퀀스 투 시퀀스 구조의 비전 트랜스포머,2024,"['Token Masking', 'Vision Transformer', 'Sequence-to-Sequence', 'Electrocardiogram', 'Authentication', 'Deep Learning']",국문 초록 정보 없음,"This study aims to improve the authentication speed and efficiency of user authentication based on Electrocardiogram (ECG) signals. ECG signals are unique to each individual and are difficult to replicate and manipulate, making them a promising candidate for new authentication methods. However, compared to fingerprints, iris, and facial recognition, ECG-based authentication has the inconvenience of requiring longer measurement times for acquiring the necessary ECG signals. To address these challenges, we developed a novel approach that integrates a sequence-to-sequence Transformer architecture with the Vision Transformer (ViT) model to achieve enhanced authentication speed and efficiency. The Sequence-to-Sequence structure allows input ECG signals to be processed in short patches by the transformer model, enabling real-time analysis of electrocardiogram signals. In addition, we employed masking techniques to tokenized input patches, enabling the model to authenticate early even when only partial ECG signals are available. The model’s performance at a sequence length of 3 is as follows: accuracy 98.8%, precision 100%, recall 97.62%, and F1-score 98.8%. We expect that by inputting three bits of the measured electrocardiogram signals into the proposed model, it will be able to authenticate users quickly and accurately."
수어 번역을 위한 3차원 컨볼루션 비전 트랜스포머,2024,"['수어 번역', '트랜스포머', '컨볼루전 트랜스포머', 'Sign Language Translation', 'Transformer', 'Convolutional Transformer']",국문 초록 정보 없음,"In the Republic of Korea, people with hearing impairments are the second-largest demographic within the registered disability community, following those with physical disabilities. Despite this demographic significance, research on sign language translation technology is limited due to several reasons including the limited market size and the lack of adequately annotated datasets. Despite the difficulties, a few researchers continue to improve the performance of sign language translation technologies by employing the recent advance of deep learning, for example, the transformer architecture, as the transformer-based models have demonstrated noteworthy performance in tasks such as action recognition and video classification. This study focuses on enhancing the recognition performance of sign language translation by combining transformers with 3D-CNN. Through experimental evaluations using the PHOENIX-Wether-2014T dataset [1], we show that the proposed model exhibits comparable performance to existing models in terms of Floating Point Operations Per Second (FLOPs)."
태양광 설비 및 기후 데이터를 활용한 태양광 발전량 예측 모델 개발,2024,"['Artificial intelligence', 'Photovoltaic power generation', 'Power generation prediction', 'Transformer model']",국문 초록 정보 없음,"Faced with ongoing resource depletion and climate catastrophes due to global warming, there is an  increasing  interest  in  reducing  carbon  emissions  and  the  need  for  sustainable  renewable energy. To address these issues, the expansion of renewable energy usage is imperative. Among various  sources,  solar  power  generation  is  the  most  widely  used  source  in  renewable  energy production and occupies the largest proportion. This study aims to propose a methodology for predicting solar power generation using environmental and power generation data. Considering the characteristics of solar power generation, which are influenced by the continuity of time, a Transformer model specialized in time series data was developed. This model demonstrates per- formance superiority compared to other existing AI models. The proposed model shows promis- ing  results  and  is  expected  to  be  utilized  for  advanced  operation  and  management  of  power plants."
Arabic Stock News Sentiments Using the Bidirectional Encoder Representations from Transformers Model,2024,"['Machine Learning', 'Deep Learning', 'Classification', 'Prediction', 'Stock Market']",국문 초록 정보 없음,"Stock market news sentiment analysis (SA) aims to identify the attitudes of the news of the stock on the official platforms toward companies' stocks. It supports making the right decision in investing or analysts' evaluation. However, the research on Arabic SA is limited compared to that on English SA due to the complexity and limited corpora of the Arabic language. This paper develops a model of sentiment classification to predict the polarity of Arabic stock news in microblogs. Also, it aims to extract the reasons which lead to polarity categorization as the main economic causes or aspects based on semantic unity. Therefore, this paper presents an Arabic SA approach based on the logistic regression model and the Bidirectional Encoder Representations from Transformers (BERT) model. The proposed model is used to classify articles as positive, negative, or neutral. It was trained on the basis of data collected from an official Saudi stock market article platform that was later preprocessed and labeled. Moreover, the economic reasons for the articles based on semantic unit, divided into seven economic aspects to highlight the polarity of the articles, were investigated. The supervised BERT model obtained 88% article classification accuracy based on SA, and the unsupervised mean Word2Vec encoder obtained 80% economic-aspect clustering accuracy. Predicting polarity classification on the Arabic stock market news and their economic reasons would provide valuable benefits to the stock SA field."
트랜스포머 인코더를 활용한 음절 단위 경량화 형태소 분석기,2024,[],국문 초록 정보 없음,"Morphological analysis involves segmenting morphemes, the smallest units of meaning or grammatical function in a language, and assigning part-of-speech tags to each morpheme. It plays a critical role in various natural language processing tasks, such as named entity recognition and dependency parsing. Much of modern natural language processing relies on deep learning-based language models, and Korean morphological analysis can be broadly categorized into sequence-to-sequence methods and sequential labeling methods. This study proposes a morphological analysis approach using the transformer encoder for sequential labeling to perform syllable-level part-of-speech tagging, followed by morpheme restoration and tagging through a pre-analyzed dictionary. Additionally, the CBOW method was used to extract syllable-level embeddings in lower dimensions, designing a lightweight morphological analyzer model with reduced parameters. The proposed model achieves fast inference speed and low parameter usage, making it efficient for use in resource-constrained environments."
Ubiq-Trans : Protein Ubiquitination Site Identification Tool using Transformer Language Model,2024,"['Transformer language model', 'Lysine ubiquitination', 'Post translational modification', 'Protein sequence']",국문 초록 정보 없음,다국어 초록 정보 없음
Loss Function 변화에 따른 VT-ADL 모델 성능 비교 분석,2024,"['Vision Transformer', '이상 탐지(Anomaly Detection)', '지역화(Localization)', '손실함수(Loss Function)', 'MVTec']",국문 초록 정보 없음,다국어 초록 정보 없음
메모리 트랜스포머 Q-학습을 활용한 카트 - 폴 시스템 제어,2024,"['Deep reinforcement learning', 'DQN', 'DDQN', 'Dueling DDQN', 'Transformer']",국문 초록 정보 없음,"This paper proposes a memory transformer Q-learning network(MTQN) algorithm to improve existing deep reinforcement learning algorithms. MTQN is configured by combining transformers with existing deep reinforcement learning models to model sequence systems more efficiently, and the gating mechanism of LSTM is additionally used for using the transformer. The proposed algorithm is compared and analyzed with DQN, a representative deep reinforcement learning algorithm, and its modified algorithms, targeting cart-pole system, a representative reinforcement learning benchmark environment. The simulation extracts and compares the evaluation score, cart position, and pole angle of cart-pole system, and shows that the proposed algorithm learns the fastest and most stably."
머신러닝 언어모델을 활용한 문법적 연어 추출 방법론 연구 - 명사를 중심어로 하는 문법적 연어를 중심으로 -,2024,"['머신러닝', '문법적 연어', '자질', '엔트로피', '오버 샘플링', '언더 샘플링', 'N-그램', 'machine learning', 'grammatical collocation', 'feature', 'entropy', 'over sampling', 'under sampling', 'n-gram']",국문 초록 정보 없음,"This study aimed to select features for identifying Korean grammatical collocations and explored the feasibility of classifying grammatical collocations using a machine-learning model. Candidate grammatical collocations whose nodes are nouns were extracted from the Sejong Corpus. Six features were identified: the frequency of lexical chains, the entropy of adjacent words in lexical chains, the average distance and variance between components of lexical chains, and the entropy of preceding and following elements of lexical chains whose nodes are nouns. To address the class imbalance in the training data, eight sampling techniques were applied. Both the original and sampled datasets were trained using XGBoost to develop a classification model and evaluate its performance.The results indicated that the model trained on data sampled using a combination of SMOTE and ENN exhibited the highest accuracy and better classified the minority class of grammatical collocations. The most influential features were 'frequency', 'minimum entropy', and 'variance of average distance'. However, limitations were identified, as the frequency and information of adjacent words alone were insufficient to fully capture the contextual meaning and grammatical characteristics of collocations. Future research should utilize transformer-based pre-trained models and embedding techniques to extract features that reflect the contextual meaning and functions of grammatical collocations. This approach is expected to facilitate an objective review of grammatical collocation lists for Korean language education and establish unified criteria for identifying grammatical collocations."
온디바이스 소형언어모델 기술개발 동향,2024,['AI'],국문 초록 정보 없음,"This paper introduces the technological development trends in on-device SLMs (Small Language Models). Large Language Models (LLMs) based on the transformer model have gained global attention with the emergence of ChatGPT, providing detailed and sophisticated responses across various knowledge domains, thereby increasing their impact across society. While major global tech companies are continuously announcing new LLMs or enhancing their capabilities, the development of SLMs, which are lightweight versions of LLMs, is intensely progressing. SLMs have the advantage of being able to run as on-device AI on smartphones or edge devices with limited memory and computing resources, enabling their application in various fields from a commercialization perspective. This paper examines the technical features for developing SLMs, lightweight technologies, semiconductor technology development trends for on-device AI, and potential applications across various industries."
한국어 언어모델의 개인 식별 번호 처리 능력 연구,2024,"['Korean Language Model', 'Personal Identifiable Information', 'Named-Entity Recognition', 'Resident Registration Number', 'Alien Registration Number', 'Prompting Test', '한국어 언어모델', '개인 식별 정보', '개체명식별', '주민등록번호', '외국인등록번호', '프롬프트 테스트']",국문 초록 정보 없음,"This research aimed to enhance Korean language models' handling of Personal Identification Numbers(PINs) by creating a Korean Personal Identifiable Information(PII) annotation system and a related training dataset. The study mainly focused on distinguishing complex numeric PINs like Resident Registration Numbers(RRNs) and Alien Registration Numbers(ARNs). It found that transformer-based Korean Language Models(LMs) struggled to differentiate these PINs, while multilingual Large Language Models(LLMs) were more effective, particularly in inferring RRNs, nationality, and age. The findings underscore the importance of regularly updating the Korean PINs dataset and developing specialized language models for more accurate PIN detection and inference."
Optimization of automatic classification for women’s pants based on the swin transformer model,2024,"['Swin transformer', 'Global attention mechanism', 'Women’s pants classification', 'Deep learning', 'Fashion E-commerce']",국문 초록 정보 없음,"In the post-pandemic era, integrating e-commerce and deep learning technologies is critical for the fashion industry. Automatic classification of women’s pants presents challenges due to diverse styles and complex backgrounds. This study introduces an optimized Swin Transformer model enhanced by the Global Attention Mechanism (GAM) to improve classification accuracy and robustness. A novel dataset, FEMPANTS, was constructed, containing images of five main trouser styles. Data preprocessing and augmentation were applied to enhance the model's generalization. Experimental results demonstrate that the improved model achieves a classification accuracy of 99.12% and reduces classification loss by 34.6%. GAM enhances the model's ability to capture global and local features, ensuring superior performance in complex scenarios. The research results not only promote the automation process in the fashion industry but also provide references for other complex image classification problems. This study highlights advancements in fashion e-commerce, offering practical applications for inventory management, trend analysis, and personalized recommendations, while paving the way for future innovations in deep learning-based image recognition."
적대적 학습이 모델 손실함수 기하에 미치는 영향에 대한 Hessian 고윳값 기반 정량적인 분석,2024,[],국문 초록 정보 없음,"Deep learning has shown remarkable performance in many fields, but its vulnerability to adversarial attacks has been exposed by several recent studies. Adversarial training is one of commonly used defense mechanism. In this paper, we analyze the effects of adversarial training on model geometry across different architectures such as convolutional neural networks (CNN) and vision transformers (ViT) quantitatively by using Hessian matrix. Results show the needs to develop more effective adversarial training methods for ViT. Additionally, we hope that this paper provides a new perspective on the impact of adversarial training techniques on different models’ geometry."
Self-Attention 딥러닝 모델 기반 산업 제품의 이상 영역 분할 성능 분석,2024,"['자기주의(Self-Attention)', '밀집 예측 트랜스포머(Dense Prediction Transformer)', '이상 분할(Anomaly Segmentation)', '딥러닝(Deep Learning)', '성능 분석(Performance Analysis)']",국문 초록 정보 없음,다국어 초록 정보 없음
시계열 데이터 예측을 위한 트랜스포머 경량화 설계,2024,"['Deep learning model reduction(딥러닝 모델 경량화)', 'Lightweight transformer(경량화 트랜스포머)', 'Time-series data prediction(시계열 데이터 예측)']",국문 초록 정보 없음,다국어 초록 정보 없음
차세대 배전지능화시스템의 체계적인 공통정보모델 프로파일 관리방안,2024,"['Advanced distribution management system', 'Common information model', 'CIM profile', 'IEC 61970-301', 'Interoperability']",국문 초록 정보 없음,"Common Information Model (CIM) is an essential technique for ensuring interoperability in Energy Management Systems (EMS) by defining data profiles for information exchange. Given the changing system environment, CIM undergoes periodic revisions, necessitating updates to the profiles used in EMS. However, comparing and interpreting CIM as defined in the Unified Modeling Language (UML) can be time-consuming and may lead to human errors. In this context, this study proposes systematic approaches for managing data profiles using an automatic tracking function for CIM and a structured process for profile management. The effectiveness of this approach is demonstrated by applying it to profiles defining the key functions of Korea's advanced distribution management system (ADMS), such as operational limits, renewable energy sources, and power transformers. This research can serve as a guideline for addressing practical issues in securing interoperability in ADMS."
DeepECtransformer: A Transformer-based Deep Learning Model for Enzyme Function Prediction,2024,"['enzyme commission number prediction', 'function annotation', 'transformer']",국문 초록 정보 없음,다국어 초록 정보 없음
Incorporating BERT-based NLP and Transformer for An Ensemble Model and its Application to Personal Credit Prediction,2024,"['Credit Prediction', 'Transformer', 'BERT', 'Ensemble Modeling', 'Tabular Data']",국문 초록 정보 없음,다국어 초록 정보 없음
Study on the Arc-Fault Detection Transformer Model Based on Dual Multi-Head Attention,2024,"['Arc-fault detection', 'Transformer', 'Ensemble', 'Deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
위험 시나리오에 대해 트랜스포머 네트워크 기반 자율주행차량의 충돌 및 궤적 예측 알고리즘 개발,2024,"['Collision prediction', 'Trajectory prediction', 'Transformer', 'Deep learning', 'Risk assessment', 'Scenario-based assessment', '충돌 예측', '궤적 예측', '트랜스포머', '딥러닝', '위험도 평가', '시나리오 기반 평가']",국문 초록 정보 없음,"This research proposed a method for predicting collisions and trajectories using a transformer network with parallel computing capabilities for multiple vehicles. The accurate prediction of the driving trajectories of surrounding vehicles is essential for the decision-making processes of autonomous vehicles(AVs). Furthermore, the ability to predict imminent collisions can significantly enhance the safety of AVs. However, although several studies have addressed these issues individually, it is rare to find research that tackles both problems simultaneously. Hence, to facilitate the multitasks of collision prediction and trajectory prediction, we modified the prediction head associated with the final layer of the network to enable multitasking capabilities. This study explored two model architectures: one with an encoder-decoder structure and another with only a decoder. The performance of the proposed algorithm is compared with existing algorithms in the literature. The results demonstrate that our suggested algorithm outperforms previous methods in terms of parallelization."
배 병해충 이미지 분류를 위한 딥러닝 최적 모델 선택에 관한 연구,2024,"['배 병해충', '딥러닝 모델', '이미지 분류', '검역', '데이터 증강', 'Pear Pests and Diseases', 'Deep Learning Models', 'Image Classification', 'Quarantine', 'Data Augmentation']",국문 초록 정보 없음,"With the increase in agricultural exports, pest and disease quarantine measures have been strengthened globally. Upon detection of pests or diseases in agricultural products, the entire shipment must be recalled or discarded. Therefore, detecting pests during the post-harvest sorting process is critical. This study aims to identify the optimal deep-learning model for classifying healthy and pest-infested pears during sorting. To achieve this, a dataset was created by collecting images of pest-infested pears under conditions similar to publicly available healthy pear images. The study compares CNN-based models (ResNet, MobileNet, EfficientNet, ConvNext) and a transformer-based model (ViT) using the dataset. Standard learning parameters and data augmentation techniques were also evaluated. Accuracy and Grad-CAM were used to analyze model performance. The results indicate that ResNet101 achieved the best performance based on accuracy and Grad-CAM."
한국어 코퍼스에서 딥러닝 기반 감성 분석 모델,2024,"['Sentimental Analysis', 'Machine Learning', 'Deep Learning', 'Transformer', 'GPT', '감성 분석', '머신러닝', '딥러닝', 'Transformer', 'GPT']",국문 초록 정보 없음,"This study comprehensively analyzes the emotional analysis model using deep learning in the Korean corpus, and discusses major research achievements and technological advances. Emotional analysis is the process of extracting and classifying subjective information from text, and the development of deep learning has brought many changes in the field of emotional analysis. Starting with the traditional emotional analysis method, the development of early deep learning models using RNN and CNN is examined, and the process of greatly improving the complex context understanding and processing ability of text through Transformer-based models is analyzed. In this process, models such as BERT and GPT show high performance and potential for expansion to various languages and domains. In addition, it analyzes the research trends of multi-lingual and domain emotional analysis and discusses how to increase the generalization ability of the model through cases using zero-shot and transfer learning. In addition, it also introduces major datasets and evaluation indicators. Finally, it mentions various challenges such as ethical issues in practical applications and suggests future research directions."
시장 테일 리스크 예측을 위한 딥러닝  모델 비교 분석,2024,"['Volatility', 'Tail risk', 'SKEW Index', 'VIX Index', 'Deep Learning', 'Time Series']",국문 초록 정보 없음,"Financial data as volatility data is difficult to capture patterns and trends. Considering the unstructured pattern and volatility inherent in financial data, it is necessary to perform multi-faceted analysis by complementing data with unique characteristics to achieve a reliable level of prediction. Accordingly, we apply the SKEW index and VIX index, which measure market tail risk and volatility, to a deep learning model to analyze asymmetric volatility more comprehensively. Deep learning, which can process large-scale data, is effective in learning the complex patterns and nonlinearity characteristics of financial time series data. LSTM suitable for time series data analysis and Transformer, which enables efficient parallel processing, are applied, and TCN and N-HiTS, which have been proposed relatively recently, are applied together to compensate for the problem of gradient loss and inefficiency in long-term sequences. Some models have been confirmed to have excellent actual overall predictive ability because they can learn the dependence of very long sequences and have strengths in capturing various temporal patterns of time series data."
플라잉 커패시터 멀티레벨 컨버터의 계산 부담 저감을 위한 일반화된 계층구조 단목적 모델 예측 제어기법,2024,"['FCS-MPC(Finite-Control-Set Model Predictive Control)', 'Multilevel converter', 'FCC(Flying Capacitor Converter)', 'SST(Solid-State Transformer)']",국문 초록 정보 없음,"This paper proposes a generalized control method to reduce computational burden based on finite control set-model predictive control(FCS-MPC) in a single-phase flying capacitor multilevel converter(FCMC). The proposed method consists of FCS-MPC with a hierarchical structure, which controls the grid current and flying capacitor voltage step-by-step using their respective cost functions. The proposed method reduces the number of calculations by segmenting power devices into groups and sequentially finding the optimal state using a round-robin priority. In addition, the optimal state is found simply through calculation without comparison due to the single-objective cost function. Therefore, the amount of calculation is significantly reduced compared with the conventional method and leads to a shortened execution time. By reducing execution time, the sampling period can be shortened, thereby increasing the switching frequency. Furthermore, by using a smaller inductor, the total harmonic distortion(THD) of the grid current can be reduced. The effectiveness of the proposed method is verified through simulation and experiment using a single-phase 6-level FCMC at the laboratory scale."
Ubiq-Trans : Protein Ubiquitination Site Identification Tool using Transformer Language Model,2024,"['Protein sequence', 'Post translational modification', 'Lysine ubiquitination', 'Transformer language model']",국문 초록 정보 없음,다국어 초록 정보 없음
위성 사진의 의미적 분할을 위한 딥러닝 기반 모델 백본 구조 분석,2024,[],국문 초록 정보 없음,"This paper analyzes the performance of various deep learning backbone architectures (ResNet-50, Swin-B, MAE, BEiT, ConvNExT, ViT) pre-trained on ImageNet dataset, to evaluate which backbone is suitable for semantic segmentation on satellite images. The study encompasses fine-tuning each model using Potsdam remote sensing dataset and comparing their performances with mean intersection over union (mIoU) metric. The results demonstrate that transformer-based models show relatively higher performances. This research shows the importance of backbone selection for remote sensing tasks, which has many possible applications including urban planning and natural disaster prevention, highlighting potential improvements in efficiency and performance for satellite image processing."
시위 뉴스 영상에서 폭력 프레이밍의 작동 기제 분석 : 비전 트랜스포머(Vision Transformer)를 활용한 폭력 이미지 분류를 통해,2024,"['Protest Paradigm', 'Violence', 'Framing', 'Image Classification', 'Vision Transformer', '시위 패러다임', '폭력', '프레임', '이미지 분류']",국문 초록 정보 없음,"Protests are acts in which citizens exercise their basic rights. However, citizen rallies opposing government policies or labor strikes demanding wage increases are often suppressed as illegal and portrayed negatively by the media. Journalism research challenges the media’s reporting techniques, known as the ’protest paradigm’, by pointing out that protests are frequently described as disturbances and confrontations. Most studies about pretest news have focused on textual analysis, with little in-depth analysis on news videos. In this regard, this study examined the video editing strategies used to frame violence in broadcast news coverage of protests. Specifically, editing strategies that emphasize violence in videos can be discussed from two perspectives: the location and duration of violence-related shots. From the first standpoint, it is expected that violence-related scenes will be put early in the news story to attract viewers’ attention. From the second perspective, it is predicted that violence scenes are expected to be edited in such a way that the number of brief shots is maximized in order to enhance tension and capture viewers’ attention. As a result, it is reasonable to expect that shots involving violence will be brief. To verify these hypotheses, this study developed a classifier to determine the presence of violence in images based on the Vision Transformer (ViT). The researchers fine-tuned the publicly available vit-large-patch16-224 model on Hugging Face by replacing the output class into violent/non-violent categories. The classifier achieved high levels of accuracy (97.12%) and F1 score. Subsequently, the researchers collected 335 news videos (from 9 broadcasters) on “Labor Day protests” from Naver News between 2003 and 2023. From these, 13,156 keyframes were identified as violent or non-violent using the developed violence classifier. The results showed that more violent scenes were observed in keyframes located in the early parts of the news story, and more violent scenes were observed in keyframes with shorter durations. Moreover, there was a significant interaction effect between the location and duration of keyframes. This indicates that media emphasizing violent scenes tend to place such scenes at the beginning of the video and employ various similar shots for rapid editing. This editing strategy may be designed to capture the audience’s attention by highlighting the deviance news value. The protest paradigm in media coverage of protests includes not only riot and confrontation frames but also discussion frame. Korean media, mindful of viewer ratings, tends to use violent frames including riots and confrontations. Moving forward, it is essential for the media to focus on the themes of protests as socially significant issues and to facilitate the exchange of opinions among societal members through discussion frames."
Explainable Deep Learning for Enzyme Engineering with Leveraging Attention Analysis of Transformer-based Model for NAD/NADP Cofactor Specificity,2024,"['Protein engineering', 'Deep learning', 'Cofactor switching', 'Transformer', 'Mutation design']",국문 초록 정보 없음,다국어 초록 정보 없음
얼굴 영역 추출 시 여유값의 설정에 따른  개성 인식 모델 정확도 성능 분석,2024,"['Artificial Intelligence', 'Face Extraction', 'OCEAN', 'MTCNN', 'Personality Recognition']",국문 초록 정보 없음,"Recently, there has been growing interest in personalized services tailored to an individual's preferences. This has led to ongoing research aimed at recognizing and leveraging an individual's personality traits. Among various methods for personality assessment, the OCEAN model stands out as a prominent approach. In utilizing OCEAN for personality recognition, a multi modal artificial intelligence model that incorporates linguistic, paralinguistic, and non-linguistic information is often employed. This paper examines the impact of the margin value set for extracting facial areas from video data on the accuracy of a personality recognition model that uses facial expressions to determine OCEAN traits. The study employed personality recognition models based on 2D Patch Partition, R2plus1D, 3D Patch Partition, and Video Swin Transformer technologies. It was observed that setting the facial area extraction margin to 60 resulted in the highest 1-MAE performance, scoring at 0.9118. These findings indicate the importance of selecting an optimal margin value to maximize the efficiency of personality recognition models."
Direct orientation estimation through inertial odometry based on a deep transformer model,2024,"['Inertial odometry', 'Six degrees of freedom', 'Drift', 'Neural network', 'Transformer']",국문 초록 정보 없음,"Studies on the inertial measurement unit (IMU), a fundamental localization solution for mobile devices in inertial odometry have been conducted. Most inertial odometry approaches focus on the two-dimensional space; however, technological advancements demand the accurate measurement of movements in the three-dimensional (3D) space, making 3D inertial odometry algorithms essen-tial. Three-dimensional inertial odometry calculates the relative pose based on IMU-measured data, and the estimated pose denotes the displacement encountered by the sensor within a unit of time. Subsequently, the trajectory is generated through integration. However, many existing approaches are characterized by drift errors owing to the integration processes utilized to estimate position and orienta-tion. We propose an extended direct orientation inertial odometry network (DO IONet) that directly estimates the orientation to over-come drift errors, improving the estimation performance of the 3D translation vector. The proposed approach calculates the orientation by inputting linear acceleration, gyroscope, gravity acceleration, and geomagnetic values, overcoming drift errors associated with ori-entation estimation. The extended DO IONet comprises an encoder for local feature extraction and a decoder for sequential feature extraction. The proposed model doesn't require structural initialization and doesn't cause drift error because an integration process is not required to estimate the orientation."
뇌졸중 환자의 뇌 병변 분할 영상 예측을 위한 딥러닝 모델 및 학습 방법,2024,[],국문 초록 정보 없음,"In this study, we investigate deep learning models for an effective and efficient lesion segmentation in 3D brain diffusion weighted images (DWI). For image segmentation, convolution neural networks (CNN) and Transformer-based models are widely used. CNNs excel at extracting local features, while Transformer-based models excel at extracting global features. Herein, we employ 2 CNN models (3D-Unet and 3D-UNet++) and 2 Transformerbased models (3D-MobileViT and 3D-SwinUNetR) for brain lesion segmentation. To evaluate the four models, DWI and ADC (apparent diffusion coefficient) of 651 brain stroke patients are used as train, validation, and test set in this study. The experimental results demonstrate that deep learning models are able to successfully segment stroke lesion but their performance varies depending on the size and frequency of the lesion among patients."
Generative AI 활용 공동디자인 워크숍에서 창의성 향상을 위한 퍼실리테이션과 프로세스 모델 제안 - ChatGPT의 활용을 중심으로,2024,"['Design Thinking Process', 'Co-design', 'Creativity Facilitation', 'Generative AI', 'AI-Creativity', '디자인 사고 프로세스', '공동디자인', '창의성 퍼실리테이션', '생성형 AI']",국문 초록 정보 없음,"Background: In today’s complex and multidimensional societal issues, interdisciplinary collaboration is essential, and cooperative and collective ‘creativity’ is increasingly highlighted as a crucial factor in addressing such challenges. While endeavors to enhance creativity through artificial intelligence (AI) collaboration persist across diverse sectors of society, literature addressing creativity within the framework of co-design and studies aimed at maximizing creativity are scarce. Therefore, this study aims to propose an effective facilitation role utilizing generative AI in the co-design process that enhances participants’ creativity and to suggest a workshop process model for co-design utilizing generative AI.Methods: Through theoretical considerations, principles for executing co-design were defined and creativity elements and facilitation roles were derived based on these principles. Building upon these concepts, a workshop process and toolkit for fostering creativity through collaboration between humans and generative AI were designed. Workshop experiments were conducted, employing different treatments regarding the provision of ChatGPT (Chat Generative Pre-trained Transformer), to compare and verify the effectiveness of two workshop sessions with the same group. Observational analyses of the workshop process, reflective interviews with participants, and expert evaluations of the outputs were conducted to derive insights. Reflecting on these findings, a blueprint for a workshop process model leveraging generative AI for enhancing creativity was proposed.Results: 10 principles of co-design execution were derived, and 5 creativity elements were identified along with 15 sub-elements in accordance with these principles. Corresponding to the sub-elements of creativity, 14 elements of creativity facilitation were identified. The utilization of ChatGPT positively influenced various aspects of creativity in co-design, such as facilitating collaborative knowledge [CC₁], fostering collaborative design thinking [CC₃], aiding idea expression [CC₄], and supporting the collaborative environment [CC<SUB>5</SUB>]. As a supplementary facilitator, ChatGPT played a useful role in providing knowledge support, aiding idea expression, and facilitating collaboration. Comparing the evaluation results of creative output, while usefulness remained consistent, fluency was higher in ChatGPT workshops. Conversely, originality was rated higher in conventional workshops. This suggests that while the utilization of ChatGPT contributed to increasing productivity in workshops, ChatGPT may have limitations in enhancing the quality of ideas.Conclusions: The collaborative role of AI as a facilitator for enhancing creativity generally had a positive impact on participants’ creativity. However, depending on participants’ intrinsic motivations, AI could potentially act as a hindering factor to creativity. Thus, continuous intervention by human facilitators is deemed crucial to support the evolution of high-quality ideas. This study validates the utility of utilizing generative AI as a collaborative creativity facilitation tool through empirical research in codesign workshops and suggests the direction for effective collaboration between human and generative AI based on the co-design process. From a practical standpoint, proposing a concrete blueprint for a codesign workshop process model utilizing generative AI is vital for addressing practical problem-solving in complex and interdisciplinary co-design activities. This model can be applied across various problem-solving domains in the future."
Generalized Average Modeling 기법을 이용한 단상 하이브리드 변압기의 AC/DC 컨버터 소신호 모델,2024,"['AC/DC converter', 'GAM(Generalized Average Modeling)', 'Small-signal modeling', 'Hybrid transformer']",국문 초록 정보 없음,"This paper proposes a small-signal modeling approach for an AC/DC converter in single-phase hybrid transformer with an AC input. In contrast to a topology such as a boost PFC which uses a rectification stage, the AC/DC converter cannot be accurately modeled using classical small-signal techniques. In addition, single-phase topologies require alternative modeling methods because of the zero average current of the input inductor and input voltage, which is different from a three-phase case using a dq transformation. In this paper, a Generalized Average Modeling(GAM) technique is employed to obtain an accurate small-signal model for the totem-pole PFC circuit. This technique allows for the separation of real and imaginary components of voltage and current, even when the average input values are zero, enabling an effective small-signal modeling. The accurate model facilitates a more precise analysis of the dynamic characteristics of the AC/DC converter circuit than conventional approaches. Furthermore, it lays a groundwork for designing suitable current and voltage controllers. The accuracy of the proposed modeling technique is validated by circuit simulations and experiments with a 300 W prototype converter."
의료 영상 병변 영상 분할을 위한 효율적 딥러닝 모델 연구,2024,[],국문 초록 정보 없음,"In this study, we explored deep learning models for automated lesion segmentation in medical imaging. Encoder-decoder frameworks are commonly employed for image segmentation. Herin, we utilized two CNN-based models (3D UNet and UNet++) and one transformer-based model (3D MobileViTv3). These encoder-decoder neural networks were applied to two types of medical image segmentation: brain tumor segmentation observed in MRI scans and liver tumor segmentation observed in CT scans. Our experimental findings demonstrate that while deep learning models can successfully segment tumor regions, their performance varies based on model structures."
Vision Transformer를 활용한 운전자 이상행동 분류 딥러닝 시스템,2024,"['도로 교통', '운전자 이상행동', '딥러닝', 'Vision Transformer', 'Road traffic', 'Driver abnormal behavior', 'Deep learning', 'Vision Transformer']","도로 교통 사고와 교통 위반 행동은 현대 사회에서 급증하는 문제로, 이에 대한 효과적인 대응이 필요하다. 이러한 사고와 위반 행동은 세계적으로 증가하는 추세를 보이며, 그로 인한 사회 및 경제적 영향은 상당히 심각하다. 주로 운전자의 부주의로 발생하는 도로 교통 사고를 예방하기 위해, 딥러닝과 머신러닝을 활용한 시스템이 구축되고 있다. 이전의 연구 들은 주로 운전자의 이미지를 기반으로 한 모델을 사용하여 운전자의 이상행동을 감지하는 데 초점을 맞추었다. 그러나 이러한 기존 연구들은 대부분 컨볼루션 기반의 모델을 사용하여 운전자의 이상행동을 감지하고 분류하는 데 중점을 두고 있다. 컨볼루션 기반 모델은 초기 학습 단계에서 이미지에서 특정 패턴 및 특징을 학습하고, 이를 고정된 크기의 필터로 추출하는 특징이 있다. 이는 다양한 운전 상황에 대한 적응성이 제한된다는 한계가 있다. 따라서 본 논문은 컨볼루션 기반 모델의 한계를 극복하고자, Vision Transformer 모델을 활용한 운전자 이상행동 분류 모델을 구축하였다. 해당 모델의 우수성을 확인하기 위해 기존 연구에서 사용된 ResNet-101, VGG19, Xception, ConvNeXt 등의 모델과 분류 성능 평가 지표를 기반으로 비교 분석을 실시하였다. 비교 분석 결과, Vision Transformer 모델이 기존의 컨볼루션 기반 모델들보다 탁월한 성능을 보여주었다. 이러한 결과는 Vision Transformer의 학습 방식이 다양한 특징 및 패턴을 효과적으로 학습하고 이를 활용할 수 있음을 시사한다. 본 연구는 도로 교통 안전성 향상을 위한 혁신적인 모델의 가능성을 제시하며, 더 나아가 안전 운전 문화의 정착과 사회적 이익을 증진시킬 수 있다.","The surge in road traffic accidents and traffic violations is a pressing issue in modern society, demanding effective responses. These incidents display a global upward trend, with significant societal and economic repercussions. To mitigate road accidents, primarily caused by driver negligence, systems leveraging deep learning and machine learning are being developed. Previous research has predominantly focused on models based on driver images for detecting abnormal driving behavior, with a predominant emphasis on convolutional models. Convolutional models learn specific patterns and features from images during the initial stages of training, extracting them using fixed-size filters, thereby limiting adaptability to diverse driving scenarios. This paper addresses the limitations of convolutional models by introducing a driver abnormal behavior classification model using the Vision Transformer. To validate the superiority of this model, a comparative analysis was conducted with well-established models such as ResNet-101, VGG19, Xception, and ConvNeXt, employing classification performance metrics from previous studies. The results of the comparative analysis demonstrate that the Vision Transformer model outperforms traditional convolutional models. This outcome indicates the effectiveness of Vision Transformer’s learning approach in efficiently capturing and utilizing various features and patterns. This research not only presents the potential for an innovative model to enhance road traffic safety but also pledges to contribute to the establishment of a safety-oriented driving culture and the enhancement of societal benefits."
Transformer와 LSTM을 순차적으로 적용하여 분석한 주택 가격 지수 예측 연구 - 문제점 분석 및 해결 전략을 중심으로 -,2024,"['LSTM', 'Transformer', 'Housing Price Prediction', 'Problem Analysis', 'Solution Strategies', 'Machine Learning', 'Predictive Modeling', 'Error Analysis', 'LSTM', 'Transformer', '주택 가격 예측', '문제점 분석', '해결 전략', '머신러닝', '예측 모델링', '오차 분석']","본 연구는 주택 가격 지수 변동요인에 대한 선행연구들을 고찰하고, LSTM(Long Short-Term Memory)와 Transformer 모델을 활용하여 주택 가격 지수 예측 모델을 구축한다. 특히 시계열 데이터 처리에 특화된 LSTM과 텍스트 데이터 처리에 특화된 DistilBERT를 결합하여, 과거 주택 가격 지수 데이터와 관련 뉴스기사 데이터를 함께 활용한다. 실험 결과로 제안된 모델은 각 지역(J,S,G)에서 생성된 예측값과 실제값 비교 그래프들이 상당 정확도로 일치함을 확인시켜주었다.그러나 일부 클러스터에서 상대적으로 높은 오차를 보인 것으로 파악되어 추가적인 분석 및 개선이 필요함을 제언한다. 별개로, 클러스터링 결과 해석에 있어서 주관적 요소가 크게 작용할 수 있는 점 역시 확인되었다. 이에 따라 추가적인 분석이 요구됨을 제언한다. 결과 시각화 및 통계적 분석 역시 수행되어 각 지역의 주택 가격 변동 추세를 잘 반영하는 것으로 확인되었다. 본 연구는 LSTM과 DistilBERT 기반의 심 학습 모델로 주택 가격 지수 예측에 대한 새로운 접근 방식을 제시함으로써 부동산 시장 동향 예측에 중요한 인사이트를 제공한다. 이 연구의 접근법과 발견은 다른 연구자들에게 창조적인 해결방안 탐색 및 문제 해결 전략 개발의 출발점으로서 유익할 것으로 기대한다.","This study aims to review previous research on factors affecting the housing price index and construct a prediction model for the index usingLong Short-Term Memory (LSTM) and Transformer models. Specifically, it combines LSTM, specialized in processing time-series data, andDistilBERT, specialized in handling text data, to utilize both historical housing price index data and relevant news articles. The experimentalresults of the proposed model confirmed significant accuracy when comparing predicted values in each region (J, S, G) with the actualvalues. However, some clusters displayed relatively high errors, indicating a need for additional analysis and improvement. Additionally, itwas observed that subjective elements could significantly impact the interpretation of clustering results, highlighting the necessity for furtheranalysis. Result visualization and statistical analysis were conducted, confirming their accurate reflection of housing price fluctuation trends ineach region. This study introduces a novel approach to predicting the housing price index using deep learning models like LSTM andDistilBERT, providing valuable insights into real estate market trend predictions. The approaches and findings from this research areanticipated to provide valuable starting points for further exploration of creative solutions and the development of effective problem-solvingstrategies."
표형식 데이터 기반 Transformer 방법론을 활용한 개인 신용대출 부도예측 모형,2024,"['Transformer', 'Tab-Transformer', 'FT-Transformer', 'Standardized tabular data', 'Personal credit loan default prediction', 'Transformer', 'Tab-Transformer', 'FT-Transformer', '표형식 데이터', '개인신용대출 부도예측']","코로나19 이후 물가 상승과 이를 억제하기 위한 주요 국가들의 기준금리 인상이 글로벌 금융시장에 영향을 미치며, 한국에서도 개인 신용대출 연체율이 상승하고 있다. 이러한 상황에서 개인 신용대출 부도 가능성을 정확하게 예측하는 능력이 중요해지고 있으며, 본 연구는 정형화된 신용정보 데이터를 활용해 부도 여부를 예측하고자 한다. 개인 신용대출 부도예측 연구에서는 통계적 방법론부터 기계학습까지 다양한 접근이 시도되었으며, 최근에는 다층퍼셉트론과 같은 심화학습 방법론도 적용되고 있다. 그러나 다층퍼셉트론은 입력변수 간의 맥락 정보를 반영하지 못해, 기존 기계학습 방법론보다 예측 성능에서 개선을 보이지 못하고 있다.본 연구에서는 기존 다층퍼셉트론 방법론의 단점을 극복하기 위해, 자연어처리 영역에서 주로 활용되고 있는 Transformer 방법론을 개인 신용대출 부도예측 문제에 적용해 보았고, 그 결과 기존 심화학습 대비 예측 성능의 개선과 함께 이전의 방법론 중 예측성능이 가장 뛰어난 앙상블 기반 의사결정나무인 XGBoost 방법론과 동등한 수준의 예측성능을 보이고 있음을 확인하였다. 본 연구의 시사점은 자연어처리에 주로 사용되던 Transformer 방법론이, 다양한 변수로 구성된 표형식 데이터를 활용한 개인 신용대출 부도예측 문제에서도 효과적일 수 있음을 확인했다는 점이다. 이는 기존의 전통적인 모델링 기법들과 비교하여 Transformer가 고차원 데이터 간의 복잡한 상호작용을 더 잘 포착하고, 예측 성능을 향상시킬 수 있음을 시사한다. 이로써 Transformer 모델은 금융 분야의 다양한 예측 문제에서 그 활용 범위를 확장할 수 있는 가능성을 보여주고 있다.","Since COVID-19, the rise in prices and the increase in the base interest rate in major countries to suppress it have affected the global financial market, and the delinquency rate of personal credit loans is also increasing in Korea. In this situation, the ability to accurately predict the possibility of personal credit loan default is becoming important, and this study aims to predict default using standardized credit information data. Various approaches have been attempted in personal credit loan default prediction research, from statistical methods to machine learning, and recently, deep learning methods such as multilayer perceptron have been applied. However, multilayer perceptron does not reflect contextual information between input variables, so it does not show improvement in prediction performance compared to existing machine learning methods. In this study, in order to overcome the shortcomings of the existing multilayer perceptron methodology, the Transformer methodology, which is mainly used in the natural language processing field, was applied to the problem of personal credit loan default prediction, and as a result, it was confirmed that it showed an improvement in prediction performance compared to the existing deep learning and showed the same level of prediction performance as the XGBoost methodology, an ensemble-based decision tree with the best prediction performance among previous methods. The implication of this study is that the Transformer methodology, which is mainly used in natural language processing, can be effective in the problem of predicting personal credit loan defaults using tabular data consisting of various variables. This suggests that, compared to existing traditional modeling techniques, Transformer can better capture complex interactions between high-dimensional data and improve prediction performance. This shows that the Transformer model has the potential to expand its application range in various prediction problems in the financial field."
Transformer의 개별 가지치기를 이용한 효율적인 이미지 캡셔닝 기법,2024,"['Super-resolution', 'Deep Learning', 'Deep Residual Block']","본 논문에서는 이미지 캡셔닝에서 개별 가지치기 기법을 통해 효율적인 트랜스포머 네트워크를 제안한다. 일반적으로 이미지 캡션모델은 사전 학습된 CNN 인코더, 트랜스포머 인코더 및 디코더의 세 가지로 구성된다. 본 연구에서는 캡션 모델의 각 구성 요소를개별적으로 최적화하도록 설계한 가지치기(Pruning) 기술을 통해, 전체 구조가 기존 캡셔닝 모델과 다르더라도 인코더 또는 디코더 네트워크와 같은 유사한 구성 요소를 공유하는 모델에 대한 적용성을 넓혔다. 또한 디코더에서 캡셔닝을 위한 손실함수를 적용함으로써성능을 향상시켰다. 본 모델을 영문 및 한글 버전에 적용한 결과 기존 대비 우수한 성능을 확인하였다.","In this letter, we propose an efficient transformer network using individual pruning techniques in image captioning. Typically, animage caption model consists of three things: a pre-trained CNN encoder, a transformer encoder, and a decoder. In this study, aproposed pruning technique was designed to optimize each component of a caption model individually and shared similarcomponents, such as encoder or decoder networks, even if the overall structure is different from conventional captioning models.Additionally, proposed method was applied a loss function for captioning in the decoder. As a result of applying this model to theEnglish and Korean versions, superior performance was confirmed compared to the existing model."
HRNet과 Transformer를 활용한 고해상도 위성영상의 구름탐지,2024,"['AIHub', 'Cloud Detection', 'HRNet', 'Satellite Imagery', 'Transformer', 'AIHub', '구름탐지', 'HRNet', '위성영상', '트랜스포머']","위성센서의 발달과 더불어 원격탐사 위성에 다양한 목적의 고해상도 센서가 탑재되어 발사되고 있으며, 높은 품질의 고해상도 위성영상에 대한 수요 또한 증대되고 있다. 사용자가 빠르게 고해상도 위성영상을 활용하기 위해서 는 방사보정, 정사보정 등의 전처리 과정이 적용된 ARD 형태의 자료가 필요하다. ARD 형태로 위성영상을 처리하기 위해서는 위성영상 내에 존재하는 구름 영역의 정보가 필요하며, 이를 위해 위성영상의 구름탐지 기법에 대한 다양한 연구들이 진행되고 있다. 본 연구에서는 고해상도 위성영상의 구름탐지를 위한 딥러닝 모델을 구성하고 이에 대한 성능 평가를 수행하였다. 특히, 대표적인 합성곱 신경망(Convolutional Neural Network)인 HRNet의 채널융합과정 내에 트랜스포머(Transformer)를 결합하여 딥러닝 모델의 성능을 향상시키고자 하였다. 또한, 훈련을 위해서 AIHub의 다목적실용위성을 이용한 구름탐지 훈련자료에 전처리 과정을 적용하여 학습의 성능을 향상시켰다. 실험결과, 전처리 과정이 적용된 훈련자료가 학습의 성능을 향상시키는 것을 확인하였다. 또한, 기존의 딥러닝 모델들과의 성능 평가를 통하여 제안한 딥러닝 모델이 효과적으로 구름지역을 추출할 수 있음을 확인하였다.","The demand for satellite imagery with high spatial resolution has increased since various remotely sensed satellite sensors such as KOMPSAT (Korean Multi-Purpose Satellite) and CAS (Compact Advanced Satellite) have launched. To quickly utilize high-resolution satellite imagery, ARD (Analysis Ready Data) with preprocessing steps such as radiometric and geometric corrections should be required. Various algorithms on cloud detection techniques for satellite imagery have been developed to process satellite imagery in ARD format. In this manuscript, a deep learning model for cloud detection in satellite imagery with high spatial resolution was developed. The Transformer layer was integrated within the channel fusion process of HRNet (High Resolution Network), which is one of the representative CNN (Convolutional Neural Network), to enhance the performance of the deep learning model. Additionally, the training performance by applying preprocessing steps was improved using AIHub's KOMPSAT training dataset for cloud detection. Experimental results represented that preprocessing of the training data improved the learning performance. Furthermore, through performance evaluation with existing deep learning models, it was confirmed that the proposed deep learning model could effectively extract cloud regions."
무인 점포 실시간 이상 행동 감지를 위한 Transformer 기반지능형 CCTV 시스템,2024,"['범죄 예방', '지능형 CCTV', '딥러닝', '트랜스포머', '무인점포', 'Crime Prevention', 'Intelligent CCTV', 'Deep Learning', 'Transformer', 'Unmanned store']","최근 무인점포가 가파르게 증가함에 따라 이를 지키기 위한 보안 문제가 대두되고 있다. 특히 실시간 모니터링 부재로 인한 절도, 기물 파손 등의 위험이 심각한데, 이를 방지하기 위해 CCTV를 설치하여 기록을 통해 범죄를 추적하고 있으나 역부족인 상황이다. 본 연구에서는 무인점포에서 발생할 수 있는 이상행동을 실시간으로 감지하는 Transformer 기반 지능형 CCTV 시스템을 제안한다. 본 연구에서 사용하는 Transformer 기반 지능형 이상행동 감지 시스템은 기존의 단순한 기계학습 모델을 활용한 시스템들과 달리 CCTV 영상에서 추출한 사람의 관절 위치 정보를 입력으로 사용하여 절도, 전도, 파손 등의 이상행동을 분류할 수 있다. 또한, 무인점포 환경에 최적화된 모델을 설계하기 위해 다양한 하이퍼파라미터를 통해 성능을 검증하였다. 이를 바탕으로 무인점포 내에서 이상행동이 감지되는 경우, 해당 위치와 시간, 그리고 관련 영상 프레임 시퀀스를 실시간으로 확인할 수 있다.","The rapid expansion of unmanned retail stores has raised critical security concerns, thereby necessitating the development and implementation of robust protective measures. The absence of real-time monitoring systems in these environments has heightened the vulnerability to risks such as theft and property damage. Although closed-circuit television (CCTV) systems have been deployed to retrospectively investigate criminal activities, these systems are often insufficient in preventing incidents. This study introduces a Transformer-based intelligent CCTV system designed for the real-time detection of anomalous behaviors within unmanned retail environments. Unlike conventional systems that rely on basic machine learning models, our proposed system leverages human joint position data extracted from CCTV footage to classify a range of anomalous behaviors, including theft, falls, and property damage. Additionally, extensive hyperparameter optimization was performed to maximize the model's effectiveness in these specific environments. Our System enhances the system's usability by enabling real-time identification of anomalous behavior, complete with location data, timestamps, and corresponding video frame sequences."
재귀적 대화 요약을 통한 장기 기억 트렌스포머,2024,"['Long-term memory', 'Natural language processing', 'Text summarization']","최근 ChatGPT[1]와 같은 Transformer[2] 기반의 언어 모델을 사용한 AI 챗봇(Chatbot)이 주목 받고 있다. 이러한 언어 모델들은 초기 대화의 정보를 잃어버려 일관된 맥락의 대화를 유지하기 어렵다. 본 논문에서는 이러한 문제를 해결하기 위해 대화의 내용을 재귀적으로 요약하는 알고리즘(Recursive Dialog Summarization, RDS)을 제안한다. 대화가 길어지면 대화 내역을 요약하고, 요약된 내용으로 기존의 대화 내역을 대체하여 언어 모델의 입력으로 사용한다. 실험은 이러한 재귀적 대화 요약이 기존의 언어 모델의 답변 정확도를 향상하고 입력 토큰 수를 줄여 응답 시간을 단축하는 것을 보였다. 또한, 제안 방법을 실제 챗봇에 적용하여 사용자의 개인 정보를 긴 대화에서 기억할 수 있음을 확인하였다.","Recently, AI chatbots using Transformer[2]-based language models such as ChatGPT[1] have been attracting attention. A significant challenge faced by these models is their inability to maintain coherent context throughout a conversation, often losing initial dialogue information. To address this problem, we introduce a novel algorithm called Recursive Dialog Summarization (RDS). RDS dynamically condenses the length of the conversation history, replacing it with a summarized version for the language model. Experiments demonstrate that RDS not only enhances the response accuracy of the language models but also effectively reduces the number of input tokens, leading to faster latency. Through a real-world chatbot, we show that dialog summarization can maintain users' personal information in long conversations."
유역정보 기반 Transformer및 LSTM을 활용한 다목적댐 일 단위 유입량 예측,2024,"['다목적댐', '유입량', '딥러닝', '트랜스포머', '파인튜닝', 'Multi-purepose dam', 'Inflow', 'Deep learning', 'Transformer', 'Fine-tuning']","딥러닝을 활용하여 유역 특성을 반영한 유량 예측 및 비교 연구가 주목받고 있다. 본 연구는 셀프 어텐션 메커니즘을 통해 대용량 데이터 훈련에 적합한 Transformer와 인코더-디코더(Encoder-Decoder) 구조를 가지는 LSTM-based multi-state-vector sequence-to-sequence (LSTM- MSV-S2S) 모형을 선정하여 유역정보(catchment attributes)를 고려할 수 있는 모형을 구축하였고 이를 토대로 국내 10개 다목적댐 유역의 유입량을 예측하였다. 본 연구에서 설계한 실험 구성은 단일유역-단일훈련(Single-basin Training, ST), 다수유역-단일훈련(Pretraining, PT), 사전학습-파인튜닝(Pretraining-Finetuning, PT-FT)의 세 가지 훈련 방법을 사용하였다. 모형의 입력 자료는 선정된 10가지 유역정보와 함께 기상 자료를 사용하였으며, 훈련 방법에 따른 유입량 예측 성능을 비교하였다. 그 결과, Transformer 모형은 PT와 PT-FT 방법에서 LSTM-MSV-S2S보다 우수한 성능을 보였으며, 특히 PT-FT 기법 적용 시 가장 높은 성능을 나타냈다. LSTM-MSV-S2S는 ST 방법에서는 Transformer보다 높은 성능을 보였으나, PT 및 PT-FT 방법에서는 낮은 성능을 보였다. 또한, 임베딩 레이어 활성화 값과 원본 유역정보를 군집화하여 모형의 유역 간 유사성 학습 여부를 분석하였다. Transformer는 활성화 벡터가 유사한 유역들에서 성능이 향상되었으며, 이는 사전에 학습된 다른 유역의 정보를 활용해 성능이 개선됨을 입증하였다. 본 연구는 다목적댐별 적합한 모형 및 훈련 방법을 비교하고, 국내 유역에 PT 및 PT-FT 방법을 적용한 딥러닝 모형 구축의 필요성을 제시하였다. 또한, PT 및 PT-FT 방법 적용 시 Transformer가 LSTM-MSV-S2S보다 성능이 더 우수하였다.","Rainfall-runoff prediction studies using deep learning while considering catchment attributes have been gaining attention. In this study, we selected two models: the Transformer model, which is suitable for large-scale data training through the self-attention mechanism, and the LSTM-based multi-state-vector sequence-to-sequence (LSTM-MSV-S2S) model with an encoder-decoder structure. These models were constructed to incorporate catchment attributes and predict the inflow of 10 multi-purpose dam watersheds in South Korea. The experimental design consisted of three training methods: Single-basin Training (ST), Pretraining (PT), and Pretraining-Finetuning (PT-FT). The input data for the models included 10 selected watershed attributes along with meteorological data. The inflow prediction performance was compared based on the training methods. The results showed that the Transformer model outperformed the LSTM-MSV-S2S model when using the PT and PT-FT methods, with the PT-FT method yielding the highest performance. The LSTM-MSV-S2S model showed better performance than the Transformer when using the ST method; however, it showed lower performance when using the PT and PT-FT methods. Additionally, the embedding layer activation vectors and raw catchment attributes were used to cluster watersheds and analyze whether the models learned the similarities between them. The Transformer model demonstrated improved performance among watersheds with similar activation vectors, proving that utilizing information from other pre-trained watersheds enhances the prediction performance. This study compared the suitable models and training methods for each multi-purpose dam and highlighted the necessity of constructing deep learning models using PT and PT-FT methods for domestic watersheds. Furthermore, the results confirmed that the Transformer model outperforms the LSTM-MSV-S2S model when applying PT and PT-FT methods."
교통안전 빅데이터와 Transformer-LSTM을 활용한 시계열 교통류 예측 분석 및 Xgboost 기반 실시간 고속도로 화물운송경로 위험도 평가 방법론 개발,2024,"['Freight vehicle', 'Freight routes', 'Real-time risk assessment', 'Deep learning', 'Traffic data', '화물차', '화물운송경로', '실시간사고위험평가', '딥러닝', '교통데이터']","물리적 피해와 인명 피해가 큰 화물차 사고는 공급망 차원에서 리드 타임에 크게 영향을 미쳐 신뢰도 저하와 재주문율 하락으로 이어져 화물차 교통사고를 잠재적 위험 요소로 판단해야 한다. 본 연구는 교통‧기상‧모바일 데이터를 통해 교통안전과 복합적으로 연관된 요소를 기반으로 단기 교통류를 예측하고 사전에 사고를 포착할 수 있는 실시간 화물 운송 경로 위험도 평가 방법론을 개발하는 것을 목적으로 한다. 우선, 실시간 교통 데이터를 기반으로 Transformer-LSTM을 활용하여 시계열 교통류를 예측하였다. 다음으로 Xgboost 기반의 화물차 사고 예측모형을 개발하였다. 분석 결과 위양성률이 5.23%로 도출되어 실시간 화물운송경로 위험도 평가에 효과적일 것으로 판단된다. 연구의 결과물은 향후 화물차 운전자를 위한 안전경로안내 서비스를 제공할 수 있으며 민간 내비게이션 업체와 협력을 통해 화물차 사고 예방을 위한 실시간 사고위험 경고 서비스 제공에 활용할 수 있다.","Freight vehicle crashes with physical damage and human casualties can significantly affect lead times at the supply chain level, leading to decreased reliability and lower reorder rates, making it necessary to consider freight vehicle traffic accidents as a potential risk factor. This study aims to develop a real-time freight transportation route risk assessment methodology that can predict short-term traffic flows and detect crashes in advance based on factors that are complexly related to traffic safety through traffic, weather, and mobile data. First, based on real-time traffic data, Transformer-LSTM was used to predict time series traffic flow. Next, Xgboost based real-time crash prediction model for freight vehicles was developed. As a result of the analysis, a false positive rate of 5.23% was obtained, and it is judged to be effective for real-time risk assessment of cargo transportation routes. The results of the study can be used to provide a safe route guidance service for freight vehicle drivers in the future. Moreover, real-time crash risk warning services can be applicable to prevent freight vehicle crashes through cooperation with private navigation companies."
Chat Generated Pre-Trained Transformer를 통해 얻은 돌발성 감각신경성 난청 정보의 정확성,2024,"['Artificial intelligence', 'Data accuracy', 'Hearing loss', 'sudden.']",국문 초록 정보 없음,"Background and Objectives Chat generated pre-trained transformer (ChatGPT) is a con-versational artificial intelligence model, which has recently attracted worldwide attention byenabling natural conversations based on huge information from deep learing in various fields.Several studies have reported usefullness and reliability of medical information obtained byChatGPT, but there are no studies explaining reliability and accuracy in the field of otorhino-larynoglogy. On this regard, we investigated the accuracy of information on sudden sensori-neural hearing loss obtained by ChatGPT.Materials and Method Twenty-five questions and answeres related to sudden sensorineuralhearing loss were recorded from ChatGPT based on textbook from Korean Society of Otorhi-nolaryngology-Head and Neck Surgery and Clinical Guidelines of American Academy ofOtolaryngology-Head and Neck Surgery. Answers were shown to one specialist in otorhino-laryngoly in a blind test and asked to assess their accuracy. Each question was rated as ‘accu-rate’ or ‘inaccurate.’ If the contents were not found in the textbook or the guidelines, it wasrated as ‘unreliable.’Results Of the 25 questions, 19 (76%) were identified as ‘accurate,’ 6 (24%) were ‘inaccu-rate,’ and 0 (0%) were ‘unreliable.’ Questions about definition, prevalence, hearing rehabilita-tion, diagnosis and treatment were found to be more accurate than the average, while causesand prognosis were less accurate than the average.Conclusion The information on sudden sensorineurla hearing loss obatined from ChatGPTwas quite accurate. It is expected to provide substantial help to patients and doctors. As medi-cine and medical artificial intelligence develop together, further research is needed on reliabil-ity and accuracy in vaious diseases and fields of otorhinolaryngology-head and neck surgery."
정제된 특징 공간에서의 윈도우 어텐션이 적용된 Vision Transformer기반 이미지 분류 성능 개선 연구,2024,"['Image Classification', 'Deep learning', 'Vision Transformer']",국문 초록 정보 없음,"The window-based self-attention vision transformer (ViT) reduces computational complexity by computing attention within a specific window. However, it is difficult to capture the interactions between pixels from different windows. To address this issue, Swin transformer, a representative window-based self-attention ViT, introduces shifted window multi-head self-attention (SW-MSA) to capture the cross-window information. However, tokens that are distant from each other still cannot be grouped into one window.This paper proposes a method to cluster tokens based on similarity in the feature-space and compute attention within the cluster.The proposed method is an alternative to the SW-MSA of the existing Swin transformer. Additionally, this paper adopts a method to refine the feature space using convolutional block attention module (CBAM) to enhance the representational power of the model.In experimental results, the proposed network outperforms existing convolutional neural networks and transformer-based backbones in the classification task for ImageNet-1K."
Chat Generated Pre-Trained Transformer를 통해 얻은 알레르기 비염 정보를 믿을 수 있을까?,2024,"['Allergy and immunology', 'Artificial intelligence', 'ChatGPT', 'Data accuracy', 'Rhinitis', 'allergic.']",국문 초록 정보 없음,"Background and Objectives Chat Generated Pre-Trained Transformer (ChatGPT) is alarge language model, which allows consumers to get information with one simple questionfor free. There are few studies that reported the reliability and usefullness of ChatGPT in thefield of otorhinolarynoglogy, so we would like to investigate the reliability of informationabout allergic rhinitis generated by ChatGPT.Materials and Method We asked ChatGPT 35 questions related to allergic rhinitis based onthe textbook from Korean Society of Otorhinolaryngology-Head and Neck Surgery, the clini-cal guidelines of American Academy of Otolaryngology-Head and Neck Surgery, and theguidelines of Allergic Rhinitis and Its impact on Asthma, and recorded the generated answers.Five specialists from our department were shown the answers in a blind test to assess their re-liability. Each question was rated either ‘accurate’ or ‘inaccurate,’ and if the contents were notfound in the textbook or the guideline, it was rated as ‘unreliable.’Results Of the 35 questions, 26 (74%) were identified as ‘accurate,’ 9 (26%) were ‘inaccu-rate,’ and 0 (0%) were ‘unreliable.’ Questions about epidemiology, causes, diagnosis, andprognosis were found to be more accurate than the average, whereas definitions and treat-ments were less accurate than the average.Conclusion The information about allergic rhinitis generated by ChatGPT was quite reli-able, showing that ChatGPT can be helpful in understanding and treating the disease. It isnecessary to use the developing medical artificial intelligence wisely."
Sharpness-Aware Minimization을 적용한 Separable Vision Transformer 기반 악성코드 유형 분류 기법,2024,"['Malware', 'Classification Method', 'Separable Vision Transformer', 'SharpnessAware Minimization', '악성코드', '유형 분류 기법', 'Separable Vision Transformer', 'Sharpness-Aware Minimization']",국문 초록 정보 없음,"""The methods of classifying malware family through malware visualization generate malware images and then classify malware family using artificial intelligence models such as Convolutional Neural Networks(CNNs). However, such methods are vulnerable to malware obfuscation techniques. In this paper, we propose a malware classification method based on the Separable Vision Transformer(SepViT) that is robust against obfuscation techniques. The proposed method performs malware family classification using a SepViT model enhanced with Sharpness-Aware Minimization(SAM) after visualizing malware as grayscale images. From the experimental results using the Microsoft Malware Classification Challenge dataset, we show that SAM Optimizer-based SepViT used in the proposed method can classify malware family more accurately than four methods(ResNet18, ViT, CrossViT, SepViT). We also analyze the basis for classification of the proposed method using Grad-Cam. In addition, from the experiments using AndroDex dataset, we show that the proposed method shows good detection performance even in the presence of obfuscation in malware."""
데이터셋 품질 개선을 위한 Self-Supervised Vision Transformer 기반의 객체 Pseudo-label 생성 기법,2024,"['self-supervised learning', 'semi-supervised learning', 'pseudo label', 'object detection', 'object segmentation', 'dataset', '자가지도학습', '준지도학습', '수도라벨', '객체탐지', '객체분할', '데이터셋']",국문 초록 정보 없음,"Image segmentation is one of the most important tasks. It localizes objects into bounding boxes and classifies pixels in an image. The performance of an Instance segmentation model requires datasets with labels for objects of various sizes. However, the recently released 'Image for Small Object Detection' dataset has large and common objects that lack labels, causing potential performance degradation. In this paper, we improve the quality of datasets by generating pseudo-labels for general objects using an unsupervised learning-based pseudo-labeling methodology to solve the aforementioned problems. Specifically, small object detection performance was improved by (+2.54 AP) compared to the original dataset. Moreover, we were able to prove an increase in performance using only a small amount of data. As a result, it was confirmed that the quality of the dataset was improved through the proposed method."
Vision Transformer를 이용한 자동변조인식 기술,2024,"['자동변조인식', 'Vision transformer(ViT)', 'Transformer encoder', '무선통신시스템', '성상도', 'Automatic modulation recognition', 'Vision transformer(ViT)', 'Transformer encoder', 'Wireless communication systems', 'Constellation']","자동변조인식 (AMR, Automatic Modulation Recognition)은 무선 통신 시스템에서 핵심적인 역할을 하는 기술로, 데이터 통신의 효율성 향상 및 무선 통신 시스템의 신뢰성과 보안 강화에 기여한다. 최근 딥러닝 기술 발전으로 AMR 분야도 딥러닝을 활용하여 변조 인식 성능을 향상하는 연구가 매우 활발히 수행되고 있다. 이에 본 논문은 시계열 이미지 데이터 처리 능력이 뛰어난 ViT (Vision Transformer) 모델 기반 AMR 기술을 제안한다. ViT 모델은 입력 이미지를 작은 이미지 단위인 패치로 나눈 후, 각 패치에 순서를 할당하여 Transformer Encoder의 입력으로 사용한다. ViT 기반 AMR 모델은 각 변조 방식의 성상도를 학습하여 변조 방식을 인식한다. 제안한 변조 인식 기법은 낮은 SNR에서도 변조 인식 정확도가 평균 약 2% 향상되었다.","Automatic Modulation Recognition (AMR) is a technology that plays a key role in wireless communication systems, contributing to improving the efficiency of data communication and enhancing the reliability and security of wireless communication systems. Recently, due to the development of deep learning technology, research using deep learning has been actively conducted in the field of AMR. In this paper, we propose an AMR technique based on the ViT (Vision Transformer) model, which has excellent time series data processing capabilities. The ViT model divides the input image into patches, which are small image units, and assigns an order to each patch, which is used as an input to the transformer encoder. By doing so, the ViT-based AMR model learns the characteristics of each modulation scheme and automatically recognizes the modulation scheme. By using the ViT-based AMR model, we were able to achieve an average classification accuracy improvement of about 2% even at low SNR."
토픽모델링과 네트워크 분석에 기반한 AI 음성기술 연구 동향 분석,2024,"['음성처리 지적구조', '토픽모델링', '네트워크분석', '음성인식', '음성합성', 'Speech processing intellectual structure', 'Topic modeling', 'Network analysis', 'Speech recognition', 'Speech synthesis']","본 연구에서는 토픽모델링과 네트워크 분석을 활용하여 AI 음성기술의 연구 동향을 WoS에 등재된 한국저자 논문 1,530편을 대상으로 3차 시기로 나누어 AI 음성기술 연구의 지적 네트워크과 주요 연구 토픽을 분석했다. 초기 연구(2011-2015)는 HMM과 같은 머신러닝 모델 및 초기 딥 러닝 기술을 사용하여 음성인식, 소음 감소및 신호 처리 개선에 중점을 둔 강력한 음성인식, 청각 처리 및 화자 적응이었다. 중기(2016～2020)는 딥 러닝과머신러닝 기술을 적용하여 음성 및 언어 처리 분야에서 상당한 발전을 가져왔고 감정 인식, 시끄러운 환경에서의향상된 음성인식 및 의료 분야와 같은 응용 분야에 중점을 두고 있었다. 최근 연구(2021～2024)는 자연어 처리를위한 Transformers 및 BERT를 포함한 정교한 AI 모델을 사용하여 음성 및 감정 인식이 지속적으로 발전하고있고, 맞춤형 음성합성, 달팽이관 이식과 같은 보조 기술의 적용에도 중점은 두고 있다. 본 연구에서 한국은 2011 년부터 2024년까지 AI 음성처리 기술 분야의 연구 동향을 분석한 결과는 상당한 기술 발전과 적용 확대를 경험했다는 결론이 나왔다. 이러한 발전은 지속적인 혁신과 새로운 과제에 대한 적응을 통해 다양한 부문에서 AI 음성처리 기술의 영향력과 중요성이 커지고 있음을 반영할 수 있다.","In this study, using topic modeling and network analysis, research trends in AI voice technology were divided into three periods targeting 1,530 papers by Korean authors registered in WoS to identify the intellectual network and major research topics of AI voice technology research. was analyzed. Early research (2011-2015) was in robust speech recognition, auditory processing and speaker adaptation, focusing on improving speech recognition, noise reduction and signal processing using machine learning models such as the HMM and early deep learning techniques. The mid-term (2016-2020) brought significant advances in the field of speech and language processing by applying deep learning and machine learning technologies, focusing on application areas such as emotion recognition, improved speech recognition in noisy environments, and the medical field. Recent research (2021-2024) continues to advance speech and emotion recognition using sophisticated AI models, including Transformers and BERT for natural language processing, and also focuses on the application of assistive technologies such as personalized speech synthesis and cochlear implants. there is. In this study, the results of analyzing research trends in the field of AI voice processing technology from 2011 to 2024 concluded that Korea has experienced significant technological development and expansion of application. These developments may reflect the growing influence and importance of AI voice processing technology in various sectors through continuous innovation and adaptation to new challenges."
Swin Transformer와 샴 네트워크를 활용한 도시 가로경관의 범죄불안감 예측,2024,[],"본 연구는 Swin Transformer와 샴 네트워크를 활용하여 도시 가로경관의 범죄불안감 점수를 예측하는 딥러닝 모델을 개발하는 것을 목표로 한다. 연구에 사용된 훈련 데이터는 안양시와 영등포구에서 수집된 거리영상으로, 한국의 다양한 도시 건조환경을 반영할 수 있는 특징을 지닌다. 제안된 모델은 82.03%의 정확도를 기록하며, 기존 모델들과 비교하여 더 높은 예측 정확도를 달성하였다. 이를 통해 도시 가로경관과 범죄불안감 간의 관계를 더 효과적으로 예측할 수 있음을 확인하였다.",다국어 초록 정보 없음
"ConTL: Improving the Performance of EEG-based Emotion Recognition via the Incorporation of CNN, Transformer and LSTM",2024,"['EEG', '감정인식', 'ConTL', 'EEG', 'emotion recognition', 'hybrid-network', 'CNN', 'Transformer', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
Transformer-Based Mechanical Property Prediction for Polymer Matrix Composites,2024,['Artifi cial intelligence · Mechanical property prediction · Polymer matrix composites · Language model'],국문 초록 정보 없음,"Combinatorial nature of polymer matrix composites design requires a robust predictive model to accurately predict the mechanical properties of polymer composites, thereby reducing the need for extensive and costly trial-and-error approaches in their manufacturing. However, traditional prediction models have been either lacking in accuracy or too resource-intensive for practical use. This study proposes an advanced Transformer-based predictive model simultaneously considering various variables that can infl uence mechanical properties, while utilizing only a minimal amount of training data. In developing this model, we utilize an extensive dataset across 294 types of polymer composites, using a diverse range of polymers and reinforcements, providing a comprehensive basis for the model’s predictions. The model employs a Transformer-based transfer learning technique, known for its effi ciency with small datasets, to predict essential mechanical properties such as tensile strength, tensile modulus, fl exural strength, fl exural modulus and density. It shows high predictive accuracy ( R 2 = 92%) and makes reliable predictions for combinations of polymer composites that have not been trained on ( R 2 = 82%). Additionally, the model’s eff ectiveness and learning process are validated through Explainable Artifi cial Intelligence analysis and latent space visualization."
Enhancing Transformer-based Cooking Recipe Generation Models from Text Ingredients,2024,"['Attention mechanism', 'BART', 'Recipe-generation model', 'Transformer']",국문 초록 정보 없음,"Recipe generation is an important task in both research and real life. In this study, we explore several pretrained language models that generate recipes from a list of text-based ingredients. Our recipe-generation models use a standard self-attention mechanism in Transformer and integrate a re-attention mechanism in Vision Transformer. The models were trained using a common paradigm based on cross-entropy loss and the BRIO paradigm combining contrastive and cross-entropy losses to achieve the best performance faster and eliminate exposure bias. Specifically, we utilize a generation model to produce N recipe candidates from ingredients. These initial candidates are used to train a BRIO-based recipe-generation model to produce N new candidates, which are used for iteratively fine-tuning the model to enhance the recipe quality. We experimentally evaluated our models using the RecipeNLG and CookingVN-recipe datasets in English and Vietnamese, respectively. Our best model, which leverages BART with re-attention and is trained using BRIO, outperforms the existing models."
Optimization and Analysis of Leakage Reactance for a Converter Transformer of the Electric Transport System,2024,['Converter transformer · Electric transport system · Finite element method · Leakage reactance · Transient analysis'],국문 초록 정보 없음,"Converter transformers are widely used in the electric transport system and it is crucial equipment for the rectifer unit of the transport’s tracking substations. Leakage reactance is a crucial criterion during the development of a converter transformer.Almost all of the analytical methods consider only the axial leakage fux density during the evaluation of the leakage reactance. Radial leakage fux density is neglected in the analytical methods. Neglecting the radial leakage fux density during the computation of the leakage reactance in the two-winding transformers and other power transformers does not signifcantly afect the results. However, in the case of the converter transformers, radial leakage fux density also needs to be fully considered. In some of the converter transformers; windings, core, insulation material, and other parts of the transformer are so complex that analytical methods are impossible or difcult to implement. Hence, any other method is needed to evaluate the diferent parameters of the transformer. The optimal selection of leakage reactance is an important parameter during the design of the converter transformer. Numerical computational methods are one of the most commonly used techniques to solve and analyse the complex models of transformers. To accurately compute the leakage reactance of the electric transport system transformer (traction transformer), a transient method is used, which considers the efect of the radial leakage fux density. A prototype converter transformer of the electric transport system has been developed to obtain the experimental results. A transient method results and prototype transformer results show excellent agreement and verify the correctness of the fnite element model. The results of the traditional analytical and magnetostatics fnite element analysis are also compared with the short-circuit experimental test."
Vulnerability Threat Classification Based on XLNET AND ST5-XXL model,2024,"['Machine Learning', 'Deep Learning', 'Feature', 'Model Training']",국문 초록 정보 없음,"We provide a detailed analysis of the data processing and model training process for vulnerability classification using Transformer-based language models, especially sentence text-to-text transformers (ST5)-XXL and XLNet. The main purpose of this study is to compare the performance of the two models, identify the strengths and weaknesses of each, and determine the optimal learning rate to increase the efficiency and stability of model training. We performed data preprocessing, constructed and trained models, and evaluated performance based on data sets with various characteristics. We confirmed that the XLNet model showed excellent performance at learning rates of 1e-05 and 1e-04 and had a significantly lower loss value than the ST5-XXL model. This indicates that XLNet is more efficient for learning. Additionally, we confirmed in our study that learning rate has a significant impact on model performance. The results of the study highlight the usefulness of ST5-XXL and XLNet models in the task of classifying security vulnerabilities and highlight the importance of setting an appropriate learning rate. Future research should include more comprehensive analyzes using diverse data sets and additional models."
Transformer Network-Aided Relative Pose Estimation for Non-cooperative Spacecraft Using Vision Sensor,2024,"['Monocular vision', 'Pose Estimation', 'Perspective-n-Point', 'Gauss-Newton Method', 'Convolution Neural Network', 'Transformer']",국문 초록 정보 없음,"The objective of the proposed work is to perform monocular vision-based relative 6-DOF pose estimation of the non-cooperative target spacecraft relative to the chaser satellite in rendezvous operations. In this work, the convolutional neural network (CNN) is replaced by the high-resolution transformer network to predict the feature points of the target satellite. The self-attention mechanism inside the transformer provides the advantage of overcoming the inadequacies of the translation equivariance, 2D neighborhood awareness, and long-range dependencies in CNN. First, the 3D model of the target satellite is reconstructed using the inverse direct linear transform (IDLT) method. Then, the pose estimation pipeline is developed with a learning-based image-processing subsystem and geometric optimization of the pose solver. The image-processing subsystem performs target localization using CNN-based architecture. Then, the key points detection network performs regression to predict 2D key points using the transformer-based network. Afterward, the predicted key points based on their confidence scores are projected onto the corresponding 3D points, and the pose value is computed using the efficient perspective-n-point method. The pose is refined using the non-linear iterative Gauss–Newton method. The proposed architecture is trained and tested on the spacecraft pose estimation dataset and it shows superior accuracy both in translation and rotation values. The architecture has shown robustness against the drastically changing clutter background and light conditions in the space images due to the self-attention mechanism. Moreover, this method consumes less computation resources by using fewer floating-point operations and trainable parameters with low input image resolution."
Transformer balancing winding technology with effective shielding for suppressing common mode noise in flyback converters,2024,"['Common mode noise', 'Flyback converter', 'Shielding layer', 'Balancing winding', 'Shielding-balancing winding']",국문 초록 정보 없음,"The main methods for suppressing the common mode (CM) noise in flyback converters include adding a shielding layer and adding a balancing winding. To combine the advantages of both methods, a balancing winding with a shielding effect is proposed to suppress CM noise. First, the CM noise transmission path of a flyback converter is analyzed, and an equivalent model of CM noise is established. Then, combined with the CM noise characteristics of the flyback converter, the design criteria for the shielding-balancing winding are given. Finally, experiments are conducted on a flyback converter prototype. The CM noise spectra of four transformer structures (without a shielding layer, with a traditional copper foil shielding layer added, with a balancing winding and with the proposed shielding-balancing winding) are compared. The results show that the CM noise of the flyback converter can be effectively suppressed by adding the shielding-balancing winding proposed in this paper. In addition, the effectiveness of the proposed method is verified."
FS-Transformer: A new frequency Swin Transformer for multi-focus image fusion,2024,"['Multi-focus image fusion', 'Swin Transformer', 'Wavelet Transform', 'Deep learning']",국문 초록 정보 없음,"In recent years, multi-focus image fusion has emerged as a prominent area of research, with transformers gaining recognition in the field of image processing. Current approaches encounter challenges such as boundary artifacts, loss of detailed information, and inaccurate localization of focused regions, leading to suboptimal fusion outcomes necessitating subsequent post-processing interventions. To address these issues, this paper introduces a novel multi-focus image fusion technique leveraging the Swin Transformer architecture. This method integrates a frequency layer utilizing Wavelet Transform, enhancing performance in comparison to conventional Swin Transformer configurations. Additionally, to mitigate the deficiency of local detail information within the attention mechanism, Convolutional Neural Networks (CNN) are incorporated to enhance region recognition accuracy. Comparative evaluations of various fusion methods across three datasets were conducted in the paper. The experimental findings demonstrate that the proposed model outperformed existing techniques, yielding superior quality in the resultant fused images."
Robust transformer-based anomaly detection for nuclear power data using maximum correntropy criterion,2024,"['Nuclear power', 'Anomaly detection', 'Transformer', 'MCC']",국문 초록 정보 없음,"Due to increasing operational security demands, digital and intelligent condition monitoring of nuclear power plants is becoming more significant. However, establishing an accurate and effective anomaly detection model is still challenging. This is mainly because of data characteristics of nuclear power data, including the lack of clear class labels combined with frequent interference from outliers and anomalies. In this paper, we introduce a Transformer-based unsupervised model for anomaly detection of nuclear power data, a modified loss function based on the maximum correntropy criterion (MCC) is applied in the model training to improve the robustness. Experimental results on simulation datasets demonstrate that the proposed Trans-MCC model achieves equivalent or superior detection performance to the baseline models, and the use of the MCC loss function is proven can obviously alleviate the negative effect of outliers and anomalies in the training procedure, the F1 score is improved by up to 0.31 compared to Trans-MSE on a specific dataset. Further studies on genuine nuclear power data have verified the model's capability to detect anomalies at an earlier stage, which is significant to condition monitoring."
A Token Selection Method for Effective Token Pruning in Vision Transformers,2024,"['비전 트랜스포머', '멀티 헤드 셀프 어텐션', '모델 가속화', '토큰 프루닝', 'vision transformers', 'multi-head self-attention', 'model acceleration', 'token pruning']",국문 초록 정보 없음,다국어 초록 정보 없음
Hybrid Transformer for Anomaly Detection on Railway HVAC Systems Through Feature Ensemble of Spatial–Temporal with Multi-channel GADF Images,2024,['Anomaly detection  · GADF  · Transformer  · HVAC system  · Hybrid modeling'],국문 초록 정보 없음,"The Heating, Ventilating, and Air Conditioning (HVAC) system, responsible for maintaining a comfortable indoor environment in buildings and vehicles, is designed to regulate factors such as temperature, humidity, and airfl ow. In transportation facilities, where HVAC systems are installed, they control and adjust the temperature, humidity, and intake of air within interior spaces, ensuring a pleasant environment, enhancing service quality, and safeguarding user health. However, these systems, which are both large-scale and highly complex, pose challenges when it comes to timely and eff ective problemsolving using a run-to-fail policy-based reactive maintenance approach. Therefore, there is a growing demand for deep learning models capable of HVAC fault detection to design preventive management using AI. These deep learning models typically receive input in the form of time-series data generated by various sensors in HVAC systems or images generated through transformation algorithms that intuitively represent time-series data. However, conventional deep learning models for analyzing these data types tend to focus on either temporal or spatial features. Hence, to utilize both temporal and spatial features simultaneously, we propose a transformer-based hybrid model. The proposed model leverages the Gramian Angular Diff erence Field algorithm, one of the image transformation algorithms, to convert multivariate time-series data from HVAC into multi-channel images. It then performs each second anomaly detection by combining feature information extracted through encoders from both transformer and vision transformer. In experimental datasets, the anomaly detection performance achieved an F1 score of 0.9965. As a result, this demonstrates that the proposed deep learning model can enhance the overall reliability and safety of HVAC systems, and showing that deep learning models can serve as crucial toolsin enhancing the maintenance and safety of HVAC systems."
Vision Transformer와 LoRA를 활용한 Breast Mass Segmentation,2024,[],국문 초록 정보 없음,"Breast cancer remains a leading cause of morbidity and mortality among women worldwide, making early and accurate diagnosis crucial for effective treatment. Traditional deep learning methods for medical image segmentation have relied heavily on convolutional neural networks (CNNs), but they sometimes struggle with generalization due to the complex nature of medical images. This paper introduces a novel approach to breast mass segmentation by employing a Vision Transformer (ViT) enhanced with Low-Rank Adaptation (LoRA), combining the global receptive field of transformers with the adaptability of parameter-efficient training techniques. We trained our model on a comprehensive dataset consisting of mammographic images annotated with expert radiological assessments to delineate breast masses. The ViT-LoRA model was compared against standard CNNs. The proposed method not only improves the accuracy of breast mass segmentation but also reduces the requirement for extensive computational resources typically associated with transformers, making it feasible for real-world medical applications. Our findings suggest that ViT-LoRA could serve as a powerful tool in the early detection of breast cancer, potentially leading to better patient outcomes."
Laminated nanocrystalline‑ferrite high saturation magnetic flux density composite core for use in high‑frequency transformers,2024,"['High-frequency transformer', 'Composite laminated core', 'Nanocrystalline-ferrite', 'High saturation flux density', 'Low core loss']",국문 초록 정보 없음,"The low power density and high frequency loss of the core limits the miniaturization of high-frequency transformers (HFT) with an increase of the switching frequency. In this paper, a composite core with laminated nanocrystalline films and ferrite sheets is proposed based on the high saturation magnetic flux density of nanocrystalline and the low loss of ferrite. The two materials are laminated at a certain thickness ratio to form a composite unit. Then multiple layers of units are stacked to form the composite core. A homogenization model is established to calculate the equivalent permeability. Then the magnetic field strength of the composite core can be obtained, which can be used to calculate the magnetic flux density in different materials. An optimization model is built with the objective of optimizing the core loss and power density by adjusting the thickness ratio. Based on the non-dominated sorting genetic algorithm II (NSGA-II), it obtains the optimal thickness ratio. Simulation results show that the composite core increases the magnetic flux density from 0.3 T to 0.55 T over a ferrite core. A 100 V/200 V, 1 kW, 20 kHz composite core HFT prototype is developed. The power density is increased by 23.5% when compared to a ferrite HFT. The core loss is reduced by 37% when compared to nanocrystalline HFT, and the efficiency is increased from 94% to 96.5%."
Bifurcation Characterization of Ferroresonance Modes in Power Transformer: Simulation and Experimental Analysis,2024,"['ferroresonance', 'nonlinear transformer', 'hysteresis model', 'bifurcation']",국문 초록 정보 없음,"The occurrence of ferroresonance phenomenon in the electrical network depends on several parameters and situations. To understand this phenomenon, it is necessary to test the occurrence of different ferroresonant modes in transformers. This paper presents a study on the ferroresonance phenomenon, focusing on the characterization of the oscillation modes using bifurcation diagram. Accurate transient models for the transformer using the Tellinen hysteresis model and polynomial approximation are implemented. Bifurcation studies are conducted using numerical simulation and analytical techniques (i.e., Galerkin method). Experimental tests on the transformer are performed using the capacitance values obtained in the bifurcation analysis. Various ferroresonant modes (fundamental, subharmonic, quasi-periodic, and chaotic) are measured. A comparison between the experimental and simulation results validates the elaborated models."
Joint streaming model for backchannel prediction and automatic speech recognition,2024,"['automatic speech recognition', 'backchannel prediction', 'block processing', 'multitask learning', 'streaming fashion', 'streaming transformer']",국문 초록 정보 없음,"In human conversations, listeners often utilize brief backchannels such as ''uh-huh'' or ''yeah.'' Timely backchannels are crucial to understanding and increasing trust among conversational partners. In human-machine conversation systems, users can engage in natural conversations when a conversational agent generates backchannels like a human listener. We propose a method that simultaneously predicts backchannels and recognizes speech in real time. We use a streaming transformer and adopt multitask learning for concurrent backchannel prediction and speech recognition. The experimental results demonstrate the superior performance of our method compared with previous works while maintaining a similar single-task speech recognition performance. Owing to the extremely imbalanced training data distribution, the single-task backchannel prediction model fails to predict any of the backchannel categories, and the proposed multitask approach substantially enhances the backchannel prediction performance. Notably, in the streaming prediction scenario, the performance of backchannel prediction improves by up to 18.7% compared with existing methods."
Tokenization Stability Index: A Catalyst for Optimizing Transformer Models for Low Resource Languages,2024,"['Large Language Model', 'Low-resource language', 'Morphological structure', 'Optimization', 'Tamil', 'Tokenizer', 'Tokenization Stability Index']",국문 초록 정보 없음,"Texts from low-resource languages, including those from the Dravidian language family, are characterized by complex morphological structures that can substantially challenge large language models. While transformer models have proven effective in numerous applications, morphological features make low-resource languages less represented. To address this problem, we present the Tokenization Stability Index (TSI), a new metric that objectively captures the differences and similarities between tokenization techniques. TSI assesses token stability, the degree of vocabulary integration, multi-token matching, and the overall rate of all tokens versus unique tokens. We offer a robust mathematical overview, theoretical implications, and case studies to show that TSI creates a reliable framework for improving low-resource language transformer models. Custom tokenization techniques were developed and tested on Tamil-based text inputs. The modified BERT model significantly surpassed the baseline and IndicBERT models, illustrating further potential for refining tokenization frameworks to enhance text processing accuracy on Dravidian-based languages and low-resource languages."
A cux on Transformer-based U-NET models for Medical Image Segmentation,2024,"['Convolution Neural Network', 'U-NET', 'Transformer', 'Medical image segmentation']",국문 초록 정보 없음,"In recent years, U-NET has made significant advancements in medical image segmentation. U-NET is a widely used architecture in medical image segmentation, which minimizes information loss due to downsampling in Convolutional Layer Network (CNN)-based architectures through skip connections. However, it has limitations in training long-range dependencies due to the local receptive field of convolutional operations. To overcome these limitations in long-range dependencies, a integrates model of Transformer for global feature extraction and the advantages of U-NET for local feature representation was integrated. This resulted in improved accuracy and computational speed for medical image segmentation. This thesis investigates the combined model of U-NET and Transformer for accurate medical image segmentation."
Network Intrusion Detection Using Transformer and BiGRU-DNN in Edge Computing,2024,"['Bi-directional Gated Recurrent Unit', 'Class Imbalance', 'Deep Neural Network', 'Edge Computing', 'Network Intrusion Detection', 'Transformer-Encoder']",국문 초록 정보 없음,"To address the issue of class imbalance in network traffic data, which affects the network intrusion detectionperformance, a combined framework using transformers is proposed. First, Tomek Links, SMOTE, and WGANare used to preprocess the data to solve the class-imbalance problem. Second, the transformer is used to encodetraffic data to extract the correlation between network traffic. Finally, a hybrid deep learning network modelcombining a bidirectional gated current unit and deep neural network is proposed, which is used to extract longdependencefeatures. A DNN is used to extract deep level features, and softmax is used to complete classification.Experiments were conducted on the NSLKDD, UNSWNB15, and CICIDS2017 datasets, and the detectionaccuracy rates of the proposed model were 99.72%, 84.86%, and 99.89% on three datasets, respectively.Compared with other relatively new deep-learning network models, it effectively improved the intrusiondetection performance, thereby improving the communication security of network data."
Vision-based Multi-task Hybrid Model for Teacher-Student Behavior Recognition in Classroom Environment,2024,"['Classroom behavior', 'Dual-stream framework', 'Multi-task hybrid model', 'Multi-mode learning', 'Spatio-temporal graph convolutional network']",국문 초록 정보 없음,"Teacher-student concentration in the teaching process is an essential indicator for evaluating teaching quality. Many researches assess students' learning interests by identifying their classroom behaviors but ignore the influence of teachers' behavior on students' behavior. Therefore, we collect classroom video data of teacher and student perspectives to analyse the interplay between their behaviors. Considering the particularity of data collection in classroom environments, we design a vision-based multi-task hybrid model for multi-mode data (RGB, optical flow and skeleton data). This model structure is divided into two parts. The RGB and optical flow are input into a spatio-temporal dual-stream framework for real-time action localization of the teacher. This dual-stream framework includes a 2D-CNN branch to extract spatial information and a Vision Transformer (ViT) branch to extract temporal information. In another part, skeleton data is obtained through the pose estimation method, and we propose a multi-level stacked spatio-temporal graph convolutional network (MSSTGCN) for skeleton-based student behavior recognition. This network can process the multi-order semantic information of the skeleton data and fuse the features at different scales through the Non-local block."
F_MixBERT: Sentiment Analysis Model using Focal Loss for Imbalanced E-commerce Reviews,2024,"['E-commerce reviews', 'Sentiment analysis', 'BERT', 'MixMatch', 'Focal loss']",국문 초록 정보 없음,"Users' comments after online shopping are critical to product reputation and business improvement. These comments, sometimes known as e-commerce reviews, influence other customers' purchasing decisions. To confront large amounts of e-commerce reviews, automatic analysis based on machine learning and deep learning draws more and more attention. A core task therein is sentiment analysis. However, the e-commerce reviews exhibit the following characteristics: (1) inconsistency between comment content and the star rating; (2) a large number of unlabeled data, i.e., comments without a star rating, and (3) the data imbalance caused by the sparse negative comments. This paper employs Bidirectional Encoder Representation from Transformers (BERT), one of the best natural language processing models, as the base model. According to the above data characteristics, we propose the F_MixBERT framework, to more effectively use inconsistently low-quality and unlabeled data and resolve the problem of data imbalance. In the framework, the proposed MixBERT incorporates the MixMatch approach into BERT’s high-dimensional vectors to train the unlabeled and low-quality data with generated pseudo labels. Meanwhile, data imbalance is resolved by Focal loss, which penalizes the contribution of large-scale data and easily-identifiable data to total loss. Comparative experiments demonstrate that the proposed framework outperforms BERT and MixBERT for sentiment analysis of e-commerce comments."
GPT Prompt Engineering for a Large Language Model-Based Process Improvement Generation System,2024,['Process design · GPT · Generative AI · Flowsheet input language · Multi-agent system · Prompt engineering'],국문 초록 정보 없음,"Process design improvements require extensive knowledge, considerable time, and huge human resources due to the complexity of chemical processes and their diverse objective functions. However, machine learning-based approaches using vast accumulated data are limited in low versatility, applicable only to specifi c processes, and unable to understand the basis of model decisions. This study proposes the GPT-based Improved Process Hybrid Transformer (GIPHT), a process design improvement generation system utilizing Large Language Model (LLM). LLMs, being natural language-based, allow for understanding the basis of model decisions without need of explainable AI analysis. GIPHT is composed of multi-agent to enhance versatility and performance for diverse chemical processes. We also propose the Detailed Simplifi ed Flowsheet Input Line Entry System format to express process diagrams in natural language, including enhanced information about process conditions. A structured prompt system is employed and validated in the LLM domain through prompt engineering. GIPHT searches and extracts data based on its proposed improvement methodology, providing explanations for the decision-making process and the basis, overcoming limitations of the traditional black-box AI models. It off ers directional ideas to design engineers in the early stages of process design and would be used for training of process engineers, supporting improvement of outdated processes and transformation into more environmentally friendly processes."
Classical and Bayesian inferences of stress-strength reliability model based on record data,2024,"['inverse Lomax distribution', 'lower record values', 'Bayesian estimation', 'bootstrap confidence intervals', 'Markov Chain Monte Carlo']",국문 초록 정보 없음,"In reliability analysis, the probability P(Y <X) is significant because it denotes availability and dependability in a stress-strength model where Y and X are the stress and strength variables, respectively. In reliability theory, the inverse Lomax distribution is a well-established lifetime model, and the literature is developing inference techniques for its reliability attributes. In this article, we are interested in estimating the stress-strength reliability R = P(Y < X), where X and Y have an unknown common scale parameter and follow the inverse Lomax distribution. Using Bayesian and non-Bayesian approaches, we discuss this issue when both stress and strength are expressed in terms of lower record values. The parametric bootstrapping techniques of R are taken into consideration. The stress-strength reliability estimator is investigated using uniform and gamma priors with several loss functions. Based on the proposed loss functions, the reliability R is estimated using Bayesian analyses with Gibbs and Metropolis-Hasting samplers. Monte Carlo simulation studies and real-data-based examples are also performed to analyze the behavior of the proposed estimators. We analyze electrical insulating fluids, particularly those used in transformers, for data sets using the stress-strength model. In conclusion, as expected, the study’s results showed that the mean squared error values decreased as the record number increased. In most cases, Bayesian estimates under the precautionary loss function are more suitable in terms of simulation conclusions than other specified loss functions."
Evaluating Chest Abnormalities Detection: YOLOv7 and Detection Transformer with CycleGAN Data Augmentation,2024,"['Object detection', 'Computer Vision', 'YOLOv7', 'Detection Transformer', 'Medical Imaging', 'Data Augmentation', 'CycleGAN', 'Generative Adversarial Networks', 'Performance Evaluation']",국문 초록 정보 없음,"In this paper, we investigate the comparative performance of two leading object detection architectures, YOLOv7 and Detection Transformer (DETR), across varying levels of data augmentation using CycleGAN. Our experiments focus on chest scan images within the context of biomedical informatics, specifically targeting the detection of abnormalities. The study reveals that YOLOv7 consistently outperforms DETR across all levels of augmented data, maintaining better performance even with 75% augmented data. Additionally, YOLOv7 demonstrates significantly faster convergence, requiring approximately 30 epochs compared to DETR's 300 epochs. These findings underscore the superiority of YOLOv7 for object detection tasks, especially in scenarios with limited data and when rapid convergence is essential. Our results provide valuable insights for researchers and practitioners in the field of computer vision, highlighting the effectiveness of YOLOv7 and the importance of data augmentation in improving model performance and efficiency."
Research on Pressure Buffer Structure of Swash Plate Plunger Hydraulic Transformer,2024,"['Bufer structure', 'Flow feld simulation', 'Hydraulic transformer', 'Pressure shock']",국문 초록 정보 없음,"The phenomenon of pressure shock is experienced in the operation of hydraulic transformers. A valve plate featuring a triangular groove buffer structure is designed in this paper to mitigate this phenomenon. The differential equation of oil pressure in the plunger cavity with buffer structure is established and transformed into the pressure increment equation of the plunger cavity, thereby obtaining the relation curves between the size of the buffer structure and the pressure change of the plunger cavity, as well as the influence law of the buffer structure on the pressure change of the plunger cavity. The optimal size of the triangular groove buffer structure for each distribution window is determined. The fluid model with the above buffer structure is subjected to a transient simulation using ANSYS, and the pressure distribution cloud diagram of the plunger is obtained. The simulation results show that the cushioning structure can effectively realize the pressure buffering effect."
Performance of a Large Language  Model in the Generation of Clinical  Guidelines for Antibiotic Prophylaxis  in Spine Surgery,2024,"['Artificial intelligence', 'Antibiotic prophylaxis', 'Orthopedic surgery']",국문 초록 정보 없음,"Objective: Large language models, such as chat generative pre-trained transformer (ChatGPT), have great potential for streamlining medical processes and assisting physicians in clinical decision-making. This study aimed to assess the potential of ChatGPT’s 2 models (GPT-3.5 and GPT-4.0) to support clinical decision-making by comparing its responses for antibiotic prophylaxis in spine surgery to accepted clinical guidelines.Methods: ChatGPT models were prompted with questions from the North American Spine Society (NASS) Evidence-based Clinical Guidelines for Multidisciplinary Spine Care for Antibiotic Prophylaxis in Spine Surgery (2013). Its responses were then compared and assessed for accuracy.Results: Of the 16 NASS guideline questions concerning antibiotic prophylaxis, 10 responses (62.5%) were accurate in ChatGPT’s GPT-3.5 model and 13 (81%) were accurate in GPT4.0. Twenty-five percent of GPT-3.5 answers were deemed as overly confident while 62.5% of GPT-4.0 answers directly used the NASS guideline as evidence for its response.Conclusion: ChatGPT demonstrated an impressive ability to accurately answer clinical questions. GPT-3.5 model’s performance was limited by its tendency to give overly confident responses and its inability to identify the most significant elements in its responses. GPT-4.0 model’s responses had higher accuracy and cited the NASS guideline as direct evidence many times. While GPT-4.0 is still far from perfect, it has shown an exceptional ability to extract the most relevant research available compared to GPT-3.5. Thus, while ChatGPT has shown far-reaching potential, scrutiny should still be exercised regarding its clinical use at this time."
CSI-based human activity recognition via lightweight compact convolutional transformers,2024,"['activity recognition', 'channel state information', 'compact convolutional transformer', 'WiFi sensing']",국문 초록 정보 없음,"WiFi sensing integration enables non-intrusive and is utilized in applications like Human Activity Recognition (HAR) to leverage Multiple Input Multiple Output (MIMO) systems and Channel State Information (CSI) data for accurate signal monitoring in different fields, such as smart environments. The complexity of extracting relevant features from CSI data poses computational bottlenecks, hindering real-time recognition and limiting deployment on resource-constrained devices. The existing methods sacrifice accuracy for computational efficiency or vice versa, compromising the reliability of activity recognition within pervasive environments. The lightweight Compact Convolutional Transformer (CCT) algorithm proposed in this work offers a solution by streamlining the process of leveraging CSI data for activity recognition in such complex data. By leveraging the strengths of both CNNs and transformer models, the CCT algorithm achieves state-of-the-art accuracy on various benchmarks, emphasizing its excellence over traditional algorithms. The model matches convolutional networks' computational efficiency with transformers' modeling capabilities. The evaluation process of the proposed model utilizes self-collected dataset for CSI WiFi signals with few daily activities. The results demonstrate the improvement achieved by using CCT in real-time activity recognition, as well as the ability to operate on devices and networks with limited computational resources."
Enhanced Control of Human Motion Generation using Action-conditioned Transformer VAE with Low-rank Factorization,2024,"['Disentangled control', '3D human mesh generation', 'Latent space']",국문 초록 정보 없음,"This paper presents an action-conditioned transformer variational autoencoder (VAE) designed to generate realistic and diverse human motion sequences. The model enables control of specific body parts of the generated human motions, thereby achieving more degrees of freedom and diversity in human actions. In order to achieve control of the body parts, this paper acquires attribute vectors through low-rank factorization and null space projection. We employ scheduling schemes for the KL-term ( ) and data augmentation to address posterior collapse to promote motion diversity. Evaluations on the UESTC and HumanAct12 datasets demonstrate the effectiveness of the proposed model and methods, showing plausible and humanlike actions. In addition, we show the application of control to actions generated in unconditional settings, thus revealing the potential for future research. To the best of our knowledge, this is a pioneering work on directly controlling motions in the latent space without using other modalities."
Fault detection in blade pitch systems of floating wind turbines utilizing transformer architecture,2024,"['blade pitch system', 'fault detection', 'floating wind turbine', 'prognostics and health management', 'sequential data', 'transformer']",국문 초록 정보 없음,"This paper proposes a fault detection method for blade pitch systems of floating wind turbines using transformerbased deep-learning models. Transformers leverage self-attention mechanisms, efficiently process time-series data, and capture long-term dependencies more effectively than traditional recurrent neural networks (RNNs). The model was trained using normal operational data to detect anomalies through high reconstruction losses when encountering abnormal data. In this study, various fault conditions in a blade pitch system, including environmental load cases, were simulated using a detailed model of a spar-type floating wind turbine, the data collected from these simulations were used to train and test the transformer models. The model demonstrated superior fault-detection capabilities with high accuracy, precision, recall, and F1 scores. The results show that the proposed method successfully identifies faults and achieves high-performance metrics, outperforming existing traditional multi-layer perceptron (MLP) models and long short-term memory-autoencoder (LSTM-AE) models. This study highlights the potential of transformer models for real-time fault detection in wind turbines, contributing to more advanced condition-monitoring systems with minimal human intervention."
A Study on the Vulnerability of Semantic Segmentation Model to Data Transformation,2024,"['Semantic Segmentation', 'Autonomous Driving', 'Data Transformation', 'ViT', 'CNN']",국문 초록 정보 없음,"With the advancement of autonomous driving technology, the importance of semantic segmentation has markedly increased,while the amount of datasets needed for training has been limited. Accordingly, there has been a growing effort to increasedatasets using data augmentation techniques to train semantic segmentation models. However, the distributional gap betweenaugmented and real data can lead to performance limitations when models trained on real data are applied to augmented data.Therefore, this paper constructs new datasets by applying proposed data transformations on real-world datasets. Additionally, weevaluate the impact of these transformations on semantic segmentation models trained on real datasets. Results show that semanticsegmentation models are vulnerable to distortions in color information and object characteristics in transformed datasets.Furthermore, the vision transformer based model is less sensitive to distribution changes and shows greater segmentationperformance compared to fully convolutional network based models."
Application of deep learning for semantic segmentation in robotic prostatectomy: Comparison of convolutional neural networks and visual transformers,2024,"['Artificial intelligence', 'Computer vision systems', 'Deep learning', 'Prostatectomy']",국문 초록 정보 없음,"Purpose: Semantic segmentation is a fundamental part of the surgical application of deep learning. Traditionally, segmentation in vision tasks has been performed using convolutional neural networks (CNNs), but the transformer architecture has recently been introduced and widely investigated. We aimed to investigate the performance of deep learning models in segmentation in robot-assisted radical prostatectomy (RARP) and identify which of the architectures is superior for segmentation in robotic surgery.Materials and Methods: Intraoperative images during RARP were obtained. The dataset was randomly split into training and validation data. Segmentation of the surgical instruments, bladder, prostate, vas and seminal vesicle was performed using three CNN models (DeepLabv3, MANet, and U-Net++) and three transformers (SegFormer, BEiT, and DPT), and their performances were analyzed.Results: The overall segmentation performance during RARP varied across different model architectures. For the CNN models, DeepLabV3 achieved a mean Dice score of 0.938, MANet scored 0.944, and U-Net++ reached 0.930. For the transformer architectures, SegFormer attained a mean Dice score of 0.919, BEiT scored 0.916, and DPT achieved 0.940. The performance of CNN models was superior to that of transformer models in segmenting the prostate, vas, and seminal vesicle.Conclusions: Deep learning models provided accurate segmentation of the surgical instruments and anatomical structures observed during RARP. Both CNN and transformer models showed reliable predictions in the segmentation task; however, CNN models may be more suitable than transformer models for organ segmentation and may be more applicable in unusual cases. Further research with large datasets is needed."
A high-density gamma white spots-Gaussian mixture noise removal method for neutron images denoising based on Swin Transformer UNet and Monte Carlo calculation,2024,"['Neutron images', 'Image denoising', 'SUNet', 'Monte Carlo calculation', 'Gamma white spots', 'Gaussian noise']",국문 초록 정보 없음,"During fast neutron imaging, besides the dark current noise and readout noise of the CCD camera, the main noise in fast neutron imaging comes from high-energy gamma rays generated by neutron nuclear reactions in and around the experimental setup. These high-energy gamma rays result in the presence of high-density gamma white spots (GWS) in the fast neutron image. Due to the microscopic quantum characteristics of the neutron beam itself and environmental scattering effects, fast neutron images typically exhibit a mixture of Gaussian noise. Existing denoising methods in neutron images are difficult to handle when dealing with a mixture of GWS and Gaussian noise. Herein we put forward a deep learning approach based on the Swin Transformer UNet (SUNet) model to remove high-density GWS-Gaussian mixture noise from fast neutron images. The improved denoising model utilizes a customized loss function for training, which combines perceptual loss and mean squared error loss to avoid grid-like artifacts caused by using a single perceptual loss. To address the high cost of acquiring real fast neutron images, this study introduces Monte Carlo method to simulate noise data with GWS characteristics by computing the interaction between gamma rays and sensors based on the principle of GWS generation. Ultimately, the experimental scenarios involving simulated neutron noise images and real fast neutron images demonstrate that the proposed method not only improves the quality and signal-to-noise ratio of fast neutron images but also preserves the details of the original images during denoising."
Optimizing FT-Transformer: Sparse Attention for Improved Performance and Interpretability,2024,"['Transformer', 'Attention Mechanism', 'Tabular Data', 'Explainable AI', 'Deep Neural Network']",국문 초록 정보 없음,다국어 초록 정보 없음
Language model performance on English control  constructions and its implications,2024,"['control constructions', 'language models', 'parameters', 'language acquisition']",국문 초록 정보 없음,"This paper examines the learnability of subject and object control constructions with transitive verbs (e.g., promise and persuade). It explores how children and Transformer-based language models (LMs), such as GPT-2, distinguish these constructions using semantic, contextual, and syntactic cues. While children rely on syntactic cues such as double object constructions (DOCs) to disambiguate subject and object control verbs (Becker, 2014), GPT-2 derives a different conclusion with respect to this distinction. The study highlights the importance of accessing the underlying syntactic structures of control predicates in helping children distinguish between these constructions (Larson, 1991). It also discusses implications for improving LM performance, suggesting that allowing LMs the access to underlying structures during training could enhance their accuracy in handling surface-ambiguous structures."
Enhancing Trajectory Recovery for Long Interval Time : A Hierarchical Transformer Approach,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
UAV 통신을 위한 멀티모달 센싱 기반 빔 예측,2024,"['빔 예측', '심층 신경망', '트랜스포머', '멀티모달 학습', '무선 통신', 'Beam prediction', 'Deep learning', 'Transformer', 'Multi-modal learning', 'Wireless communications']","본 논문에서는 무선 통신 시스템에서 효율적인 빔포밍이 가능하도록 카메라 이미지 데이터와 GPS 데이터를 모두 사용해 최적의 빔을 예측하는 딥러닝 기법을 제안한다. 기존 연구에서는 카메라 이미지 데이터와 GPS 데이터를 개별적으로 사용하는 싱글모달 빔 예측 모델이 제안되었다. 하지만 이러한 방법은 측정 환경과 이상치에 민감하다는 한계를 갖는다. 본 논문에서는 이를 극복하기 위해 트랜스포머의 파생 모델인 비전 트랜스포머에 기반한두 가지 데이터를 결합하여 활용하는 새로운 기법을 제안한다. 실험 결과, 제안 모델이 기존 모델 대비 32개 빔과64개 빔에 대한 Top-1, 2, 3 정확도 모두에서 더 높은 성능을 보이는 것을 확인하였다. 특히 제안 모델의 Top-3 정확도는 두 가지 실험 모두에서 거의 100%에 가까운 정확도를 보였다.","In this paper, we propose a deep learning model to predict the optimal beam for wireless communication systems by utilizing both camera image data and GPS data, enabling efficient beamforming. Existing work has proposed single-modal beam prediction models that utilize camera image data and GPS data individually.However, these models have limitations in that they are sensitive to measurement environments and outliers.To overcome the limitations, we propose a new model that combines and utilizes the two types of data based on a derivative model of Transformer called Vision Transformer. Experimental results show that the proposed model exhibits higher performance in terms of Top-1, 2, 3 accuracy for both 32-beam and 64-beam scenarios compared to the existing model. Particularly, the Top-3 accuracy of the proposed model showed nearly 100% accuracy in both scenarios."
딥러닝 기술을 활용한 복숭아 ‘미황’의 성숙도 자동 분류,2024,"['EfficientNet', 'fruit firmness', 'robot harvester', 'Vision Transformer', 'YOLOv5', 'EfficientNet', '과실경도', '로봇수확', 'Vision Transformer', 'YOLOv5']","소비자에게 전달되는 복숭아는 숙도에 따라서 품질이 달라지기 때문에 섭취하기에 적합한 숙도를 고려하여 유통하는 과정이 필요하다. 또한, 숙도는 복숭아의 상품성 및 저장성에 영향을 미칠 수 있어 적합한 수확 시기를 선정하는 작업이 요구되지만, 현재 노지 과수 작목의 숙도 판별에 대한 국내 연구는 미미한 실정이다. 그렇기 때문에 본 연구에서는 딥러닝 객체 탐지 분류모델을 활용하여 복숭아 ‘미황’에 대한 숙도 분류 모델을 개발하였다. 실험실 내부 및 야외에서 촬영된 각 2,800장의 이미지를활용하여 데이터 셋을 구축하였고, 수확 날짜 및 복숭아 과정부(apex)의 색도 a* 값을 기준으로 하는 두 개의 데이터 셋으로구성하여 각 셋의 구분 기준에 따라 미숙, 적숙 그리고 과숙 3개의 class로 분류하였다. Train : Validation : Test 데이터 셋은7 : 2 : 1의 비율로 분류하였고 데이터의 다양성 향상 및 unbalance를 해결하기 위해 augmentation을 실시하였다. 딥러닝 모델은 EfficientNet, YOLOv5 그리고 Vision Transformer를 활용하였으며 EfficientNet에서 가장 우수한 분류 모델 성능을 기록하였다. 날짜 기준 분류 모델은 분류 모델 성능 평가 지표 기준 최저 및 최대 100%의 정확도를 달성하였고, 색도 a* 값 기준 분류모델은 최저 94.7%, 최대 98.2%의 높은 정확도를 보였다. 본 연구에서 개발된 객체 탐지 기반 복숭아 숙도 분류 모델은 향후노지 과수 작목의 숙도 분류를 통한 기계수확 적기 판정 작업에 활용될 수 있을 것으로 판단된다.","Peach must be delivered to market when at their proper ripeness, as its fruit quality declines quickly after harvest. Therefore, it is necessary to consider suitable ripeness for consumption and distribution. However, research on ripeness judgments for peaches in the orchard is scarce. This study used deep learning technology to develop a ripeness classification model for ‘Mihwang’ peaches. A dataset was prepared using 2,800 images, each taken from a peach orchard (outside dataset) and a laboratory (inside dataset) with the same fruit. The dataset was constructed based on the harvest date of the peaches and the peach apex’s skin color (a* value). It uses three classes, immature, ripe, and overripe, according to the classification criteria of the two datasets. The model was trained with a ratio of 7:2:1 of training data, validation data, and test data, and image data augmentation was carried out to improve the diversity of the data and to solve any imbalances.Among EfficientNet, YOLOv5, and Vision Transformer, the deep learning model recorded the best classification model performance on EfficientNet. Based on the classification model and performance evaluation index, the harvest-date-based classification model achieved the highest accuracy of 100%. The classification model based on the apex color a* value of peaches showed high accuracy with a minimum rate of 94.7% and a maximum rate of 98.2%. The peach ripeness classification model developed in this study can be used for determining the proper time for the mechanical harvesting of fruit from an orchard."
상품 카테고리 자동분류를 위한 BERT-분류기 아키텍처 연구,2024,"['문장 분류', '문장 유사도', 'Sentence BERT', 'CNN', 'ResNet', 'Transformer', 'Classification', 'Sentence classification', 'Sentence similarity', 'Sentence BERT', 'CNN', 'ResNet', 'Transformer', 'Classification']","본 연구는 생활 속 존재하는 다양한 상품들의 명칭을 BERT를 통해 임베딩 벡터화한 다음 이를 기반으로 상품 카테고리 예측을 수행하는 아키텍처에 대한 연구이다. 아키텍처의 성능은 상품 명칭으로부터 임베딩 추출을 수행하는 BERT 모델과, 추출된 임베딩으로 카테고리 예측을 수행하는 분류기에 의해 결정된다. 따라서 본 연구는 우선 상품 명칭 분류에 적합한 BERT 모델을 선정하고, 선정된 BERT 모델에 다양한 분류기를 적용하여 가장 높은 성능을 달성하는 BERT-분류기 조합을 찾고자 하였다. 최초 적합한 BERT 모델 선정에는 단순한 CNN 분류기를 사용하였으며 이를 baseline으로 다른 분류기와 성능을 비교하였다. 아키텍처의 성능은 카테고리 정답에 대한 precision, recall, f1 score, accuracy로 정량화하여 평가하였다. 실험 결과 BERT 측면에서는, Sentence BERT 모델이 비교 대상인 일반 BERT 모델보다 적합함을 확인하였다. 그리고 분류기 측면에서는, Sentence BERT와 CNN으로 구성된 baseline 대비하여 Residual Block이 추가 적용된 분류기가 더 높은 성능을 보였다. 본 연구에 사용된 Sentence BERT 모델의 경우 한국어 데이터가 학습되지 않은 단순 모델로, 향후 추가적 연구를 통해 다양한 한국어 데이터를 학습시켜 Domain Adaptation을 수행할 경우 추가적 성능 향상이 기대된다.","This research focuses on an architecture that vectorizes the names of various products found in daily life using BERT, followed by predicting product categories based on these embeddings. The architecture's performance is determined by the BERT model, which extracts embeddings from product names, and the classifier that predicts categories from these embeddings. Consequently, this research initially aimed to identify a BERT model suitable for classifying product names and then find the most efficient combination of BERT model and classifier by applying various classifiers to the chosen BERT model. A simple CNN classifier was employed for the initial selection of a suitable BERT model, serving as a baseline for performance comparison with other classifiers. The architecture's effectiveness was quantified using precision, recall, f1 score, and accuracy for category predictions. Experimental results showed that the Sentence BERT model was more suitable for this task than a conventional BERT model. Additionally, classifiers enhanced with Residual Blocks demonstrated superior performance compared to the baseline combination of Sentence BERT and CNN. The Sentence BERT model used in this study, not trained on Korean data, suggests that further improvements could be achieved through Domain Adaptation by training with diverse Korean datasets."
효율적인 개방형 어휘 3차원 개체 분할을 위한 클래스-독립적인 3차원 마스크 제안과 2차원-3차원 시각적 특징 앙상블,2024,"['- 3', '3', '2-3']","개방형 어휘 3차원 포인트 클라우드 개체 분할은 3차원 장면 포인트 클라우드를 훈련단계에서 등장하였던 기본 클래스의 개체들뿐만 아니라 새로운 신규 클래스의 개체들로도 분할해야 하는 어려운 시각적 작업이다. 본 논문에서는 중요한 모델 설계 이슈별 기존 모델들의 한계점들을 극복하기 위해, 새로운 개방형 어휘 3차원 개체 분할 모델인 Open3DME를 제안한다. 첫째, 제안 모델은 클래스-독립적인 3차원 마스크의 품질을 향상시키기 위해, 새로운 트랜스포머 기반 3차원 포인트 클라우드 개체 분할 모델인 T3DIS[6]를 마스크 제안 모듈로 채용한다. 둘째, 제안 모델은 각 포인트 세그먼트별로 텍스트와 의미적으로 정렬된 시각적 특징을 얻기 위해, 사전 학습된 OpenScene 인코더와 CLIP 인코더를 적용하여 포인트 클라우드와 멀티-뷰 RGB 영상들로부터 각각 3차원 및 2차원 특징들을 추출한다. 마지막으로, 제안 모델은 개방형 어휘 레이블 할당 과정동안 각 포인트 클라우드 세그먼트별로 추출한 2차원 시각적 특징과 3차원 시각적 특징을 상호 보완적으로 함께 이용하기 위해, 특징 앙상블 기법을 적용한다. 본 논문에서는 ScanNet-V2 벤치마크 데이터 집합을 이용한 다양한 정량적, 정성적 실험들을 통해, 제안 모델의 성능 우수성을 입증한다.","Open-vocabulary 3D point cloud instance segmentation (OV-3DIS) is a challenging visual task to segment a 3D scene point cloud into object instances of both base and novel classes. In this paper, we propose a novel model Open3DME for OV-3DIS to address important design issues and overcome limitations of the existing approaches. First, in order to improve the quality of class-agnostic 3D masks, our model makes use of T3DIS, an advanced Transformer-based 3D point cloud instance segmentation model, as mask proposal module. Second, in order to obtain semantically text-aligned visual features of each point cloud segment, our model extracts both 2D and 3D features from the point cloud and the corresponding multi-view RGB images by using pretrained CLIP and OpenSeg encoders respectively. Last, to effectively make use of both 2D and 3D visual features of each point cloud segment during label assignment, our model adopts a unique feature ensemble method. To validate our model, we conducted both quantitative and qualitative experiments on ScanNet-V2 benchmark dataset, demonstrating significant performance gains."
처리성능 최적화를 위한 생성형 인공지능 이미지 판별 방안,2024,"['생성형 인공지능', '생성된 합성 이미지 분류', '합성곱신경망', '하이퍼 파라미터 튜닝', 'Generative AI', 'Generative Image Classification', 'Convolutional Neural Network', 'Hyperparameter Optimization']","생성형 인공지능의 등장으로 실제 이미지와 합성 이미지의 조작 여부를 판별하기 어려워졌다. 이러한 문제를 해결하기 위해 본 논문에서는 실제 임베디드 환경에서 실제 이미지와 생성형 인공지능이 생성한 합성 이미지를 효율적으로 판별하는 기술을 제안한다. 제안된 방법은 기존 CNN 구조에 하이퍼 파라미터 튜닝을 통해 모델의 이미지 처리 성능 최적화를 진행하였다. 또한 모델의 경량화를 진행해 본 논문의 지향점인 최소한의 파라미터로 최고의 성능을 달성하는 것을 목표로 모델을 설계하였다. 제안된 모델은 입력 영상에서 특징을 추출하는 CNN 계층, 영상의 크기를 줄이면서 주요 특징을 유지하는 Max Pooling, 마지막으로 최종 예측 값을 수행하는 Dense 계층으로 구성되어 있으며, 여기에 하이퍼 파라미터 튜닝을 통해 모델의 처리 성능 및 최적화를 진행하였다. 제안된 모델의 정량적 평가를 위해 제한된 환경인 임베디드 보드에서 실험을 진행한 결과, 제안된 모델은 비교 평가를 위해 선정한 모델들인 EfficientNetB0, ViT(Vision Transformer)과 유사한 정확도를 보유하면서 처리 성능 측면에서 다른 모델들에 비해 Model load time 및 Inference time이 더 효율적인 것을 확인할 수 있었다.","With the advent of generative artificial intelligence, it has become difficult to determine whether real and synthetic images are manipulated. To solve this problem, this paper proposes a technology to efficiently classifying between real images and synthetic images generated by generative artificial intelligence in a real embedded environment. The proposed method optimized the image processing performance of the model through hyperparameter tuning to the existing CNN structure. In addition, the model was designed with the aim of achieving the best performance with minimal parameters, which is the goal of this paper by proceeding with the weight reduction of the model. The proposed model is a CNN layer that extracts features from the input image, reducing the size of the image while reducing the main features It consists of the maintaining Max Pooling, and finally, the Dense layer that performs the final prediction value, and the processing performance and optimization of the model were carried out through hyperparameter tuning. As a result of conducting experiments on an embedded board, which is a limited environment for the quantitative evaluation of the proposed model, it was confirmed that the proposed model load time and inference time were more efficient than other models in terms of processing performance while having similar accuracy to the models selected for comparative evaluation, EfficientNetB0 and ViT (Vision Transformer)."
YOLO 성능 향상을 위한 데이터 증강기법,2024,"['데이터 증강기법', '딥러닝', '기계학습', '인공지능', '복사-붙여넣기(증강)', 'Data augmentation', 'deep learning', 'machine learning', 'artificial intelligence', 'Copy-paste (augmentation)']","컴퓨터 비전은 CNN, 트랜스포머 등과 같은 모델의 발전으로 여러 분야에서 좋은 성과를 이루었다. 하지만, 모델을 학습하기 위해서는 다양하고 많은 데이터가 필요하다. 이러한 학습데이터를 얻기 위해서는 많은 시간과 노력이 필요 로 한다. 이러한 높은 비용으로 인해 데이터 부족이나 데이터 불균형이 발생하게 된다. 데이터 증강기법은 이러한 문 제를 해결하기 위한 좋은 방법이다. 본 논문에서는 객체 인식 모델을 위한 데이터 증강기법 중에서(복사-붙여넣기) Copy-Paste를 활용한 데이터 증강기법을 연구한다. 이전 연구에서는 인스턴스 영상 분할 객체를 붙이거나 시각적 인 맥락을 바탕으로 객체를 붙인다. 하지만 인스턴스 영상 분할 객체를 사용하지 않고 단순한 방법인 바운딩 박스 (Bounding Box)를 그대로 기존의 객체 위치에 같은 크기로 붙이거나 무작위로 붙이는 것도 모델의 성능이 향상된 다는 것을 발견했다. 또한, 객체에서 SAM(Segment Anything Model) 모델을 활용하여 객체의 인스턴스를 추출 하여 붙이는 방법을 제안한다. 그리고 붙이는 객체에 데이터 증강기법을 적용하여 데이터를 증강하는 방법을 추가실 험으로 보여준다. 또한, 기존의 객체가 붙여지는 객체에 의해 가려지는 것을 막기 위해 객체를 붙이고 기존 이미지에 있는 객체를 덮어쓴 방법도 적용하였다. 본 논문에서 객체 인식 모델 Yolo v5를 Pascal VOC12 데이터셋으로만 학 습한 결과보다 제안한 데이터 증강기법을 활용해서 학습한 결과가 더 높은 성능을 보여주는 것을 확인하였다.","Computer vision has shown excellent performance in various fields, thanks to the advancements in models like CNN and Transformers. However, training these models requires diverse and abundant data, which demands a significant amount of time and effort. The high cost associated with acquiring such training data often leads to issues like data scarcity and data imbalance. Data augmentation techniques provide effective solutions to address these challenges. In this paper, we focus on researching data augmentation techniques for object recognition models, specifically leveraging the Copy-Paste(Augmentation) technique. The previous researches involved attaching objects based on instance segmentation or visual context. However, we have discovered that using a straightforward approach, such as attaching bounding boxes of the same size to the existing object locations or randomly attaching objects, enhances the model's performance significantly. Furthermore, we propose a method of using the SAM(Segment Anything Model) to extract object instances from images and attaching them. We demonstrate additional experiments applying data augmentation techniques to the attached objects. To prevent existing objects in the image from occluded by the attached objects, we present a method of overlaying them into the image with attached objects. In this paper, we train the object recognition model using YOLO(You Only Look Once) v5 on the Pascal VOC12 dataset, and show better performance when utilizing the proposed data augmentation techniques."
LLaMA 3 온디바이스 가속기의 구현을 위한 고정소수점 연산 분석,2024,"['LLaMA 3', 'LLM', 'Accelerator', 'Fixed-Point', 'ASIC']","LLM(대규모 언어 모델)은 RNN과 LSTM의 발전된 모델로, 트랜스포머 구조를 갖는다. 트랜스포머는 2017년 ‘Attention Is AllYou Need’ 논문 이후 발전해 OpenAI GPT-4, Google Gemini Pro 1.5 등 성공적인 LLM이 출시되었다. LLM은 방대한 데이터를 학습하기 위해 고성능 GPU가 필요해 일반적으로 로컬에서 개인 사용자에게 공개되지 않는다. Meta AI의 LLaMA 3는 연구적/상업적목적으로 사용 가능한 오픈소스로, 8B와 70B 모델로 제공된다. LLaMA 3는 로컬에서 실행 가능하지만, 다중 GPU 환경이 필요하다.온디바이스 LLM을 구동하려면 양자화와 고정 소수점 연산이 필요하며, 엣지 디바이스에서 부동 소수점 연산은 자원 부담이 크다. 고정 소수점 연산은 빠르지만 표현 범위가 좁아 LLM의 답변 정확도에 영향을 미칠 수 있다. 본 논문은 LLaMA 3 8B 모델의 구조와연산을 분석하고, 고정 소수점 실험 결과와 하드웨어 자원 사용량을 제시한다.","LLM (Large Language Model) is an advanced model for processing sequential data, evolving from RNN and LSTM models,and is based on the transformer architecture. Since the publication of the 'Attention Is All You Need' paper in 2017, transformershave continuously developed, leading to successful LLMs such as OpenAI's GPT-4 and Google's Gemini Pro 1.5. LLMs requireextensive data training, necessitating high-performance GPUs and prolonged training times, which is why they are typically notavailable for local use by individual users. Meta AI's LLaMA 3, an open-source model for research and commercial use, isavailable in 8B and 70B parameter models. While LLaMA 3 can be run locally, it requires a multi-GPU environment. To runLLMs on-device, quantization and fixed-point arithmetic are needed due to the resource constraints of edge devices. Floating-pointoperations are resource-intensive and challenging for edge devices, though fixed-point operations, while faster, have a narrowerrange and may affect LLM accuracy. This paper analyzes the structure and operations of the LLaMA 3 8B model, presentsfixed-point experiment results, and discusses hardware resource usage."
환경데이터 학습을 통한 AI 기반 노지 스마트팜 설계,2024,"['인공지능', '다변량 분석', 'TFT모델', '스마트팜', 'AI', 'Multi-horizon forecasting', 'Radio Temporal Fusion Transformers', 'Smart Farm']","본 논문은 인공지능(AI)과 사물인터넷(IoT)을 기반으로 한 노지 스마트팜 시스템을 설계하는 것을 목표로 한다. Temporal Fusion Transformer(: TFT)와 같은 트랜스포머 기반 시계열 예측 모델을 활용하여 작물의 생육 환경을 실시간으로 모니터링하고 이를 바탕으로 관수 및 관비를 자동으로 조정하는 시스템을 제안한다. 실시간으로 수집된 환경 데이터와 기상 데이터를 통합하여 AI 모델을 학습시키고, 이를 통해 작물의 생육에 최적화된 관수 및 관비 전략을 도출하는 것을 목표로 한다. 이 시스템은 자원 사용을 최소화하면서도 농업 생산성을 극대화할 수 있는 솔루션을 제공하며, 다양한 기상 조건에서의 성능 검증을 진행할 예정이다. 향후 연구는 다양한 작물과 지역에 적용 가능한 표준화된 노지 스마트팜 모델을 개발하고, 장기적인 데이터 수집을 통해 시스템 성능을 지속적으로 개선할 계획이다.","This paper aims to design an open field smart farm system based on artificial intelligence (AI) and the Internet of Things (IoT). We propose a system that monitors the crop growth environment in real time and automatically adjusts irrigation and fertilization based on the results by utilizing a transformer-based time series prediction model such as Temporal Fusion Transformer (TFT). The goal is to integrate environmental data and weather data collected in real time to train an AI model, and derive an irrigation and fertilization strategy optimized for crop growth. This system provides a solution that can maximize agricultural productivity while minimizing resource use, and its performance will be verified under various weather conditions. Future research plans to develop a standardized open field smart farm model applicable to various crops and regions, and to continuously improve system performance through long-term data collection."
단안 깊이 추정을 위한 소실점 위치 정보를 사용하는 향상된 SW-MSA,2024,"['Deep learning', 'Depth estimation', 'Monocular depth estimation', 'Swin transformer', 'Vanishing point']","본 논문은 단안 렌즈를 통한 깊이 추정에서 소실점 탐지와 향상된 SW-MSA를 사용한 Swin Transformer 기반의 깊이 추정 모델을 제안한다. 이 모델은 이미지가 입력되면 소실점을 탐색한 후 소실점의 위치에 따른 유형을 파악하여 깊이 추정 모델에 도움이 될 정보를 모델에 전달한다. 소실점 위치 유추는 먼저 이미지에서 캐니 선분 검출기로 외곽선을 추출하여 허프 변환을 통하여 직선 성분만 남기고, 그 직선들을 연장해서 가장 많은 선분의 교점 영역을 소실점으로 설정한다. 소실점의 위치 유형은 3가지로 분류되는데, 유형에 따라 SW-MSA의 셀프 어텐션 방식이 나뉜다. 제안한 모델 성능은 실험 결과를 통하여 기존 단안 깊이 추정 모델과 더 나은 결과를 나타낸다. 본 논문은 소실점이라는 기하학적 특성을 통하여 단안 깊이 추정을 함으로써 훈련 데이터에 의존하지 않고 이미지의 근원적인 특성을 찾아내는 기술을 사용하는 것을 강조한다. 본 논문은 깊이 추정 분야에 중요한 기여를 하고 있으며, 소실점이라는 원근법에서 사용하는 개념을 깊이 추정 분야에서 이용하기 때문에 기술의 잠재력이 크다는 것을 강조한다.","This paper proposes a Swin Transformer-based depth estimation model using vanishing point detection and improved SW-MSA in depth estimation through a monocular lens. This model, upon receiving a image, searches for the vanishing point, then identifies the type based on the location of the vanishing point, and conveys information helpful to the depth estimation model. Inference of the vanishing point position first involves extracting the outlines from a image using the Canny edge detector, then retaining only the line components through Hough transformation. These lines are then extended to determine the vanishing point as the area where the most line intersections occur. The types of vanishing point positions are classified into three categories, and the self-attention mechanism of SW-MSA varies according to the type. The performance of the proposed model demonstrates better results than the existing monocular depth estimation models, as shown by experimental result. This paper emphasizes the use of  technology that identifies the intrinsic characteristics of an image by estimatioing monocular depth through the geometric feature of vanishing points, thereby not relying on training data. This paper makes a significant contribution to the field of depth estimation, emphasizing the potential of the technology by utilizing the concept of vanishing points from perspective in depth estimation."
음성 감정 인식에서의 어텐션 노이즈 감소를 위한CNN 기반의 Log-Mel 스펙트로그램 이미지 압축 기법,2024,"['Speech Emotion Recognition', 'Image Compression', 'Attention Mechanism', 'Transformer', 'Deep Learning']","본 논문은 음성 감정 인식에서 log-Mel 스펙트로그램을 기반으로 한 이미지 압축 기법을 제안하고, 이 기법이 어텐션 메커니즘을활용한 vision transformer 모델에서 성능 향상에 기여할 수 있음을 보인다. 특히, log-Mel 스펙트로그램은 음성 신호의 주파수특성을 잘 포착하여 음성 감정 인식에 유용하게 사용되는데, 본 연구에서는 이 스펙트로그램을 이미지 형태로 처리하면서 발생할수 있는 어텐션 노이즈를 효과적으로 감소시키는 방법을 제시한다. 핵심적인 아이디어는 CNN을 수평 커널로 사용하여 log-Mel 스펙트로그램 이미지의 해상도를 압축하고, 이를 통해 vision transformer 모델에서 중요한 패턴을 보다 효과적으로 학습하도록 돕는 것이다. 제안된 기법은 기존의 log-Mel 스펙트로그램을 128×1001 크기로 처리하고, 이 이미지를 128×129로 고정된 크기로압축하면서 임의의 이미지 보간이 수행되도록 설계되었다. 이러한 전처리 과정은 모델이 음성 감정 인식에서 유용한 특징을 보다잘 추출할 수 있도록 돕는다. 본 논문에서는 log-Mel 스펙트로그램의 주어진 특성에 맞게 CNN 기반의 압축 기법을 사용하여 스펙트로그램의 중요 정보를 보존하면서, vision transformer 모델의 어텐션 메커니즘에서 발생할 수 있는 노이즈를 최소화하는 방법을 제안한다. Crowd Sourced Emotional Multimodal Actors(CREMA) 데이터셋을 이용한 실험을 통해, 제안하는 기법이86.83%의 정확도를 나타내어 기존의 방법들보다 음성 감정 인식에서 더 뛰어난 성능을 보임을 확인하였다.","This paper proposes convolutional neural networks (CNN) based log-Mel spectrogram image compression methodfor attention noise reduction in speech emotion recognition (SER) and demonstrates how this method can contributeto improved performance in vision transformer models utilizing attention mechanisms. log-Mel spectrograms,which effectively capture the frequency characteristics of speech signals, are commonly used in SER tasks. In thisstudy, we present a method to reduce attention noise that may arise when processing these spectrograms asimages. The core idea is to use a CNN with horizontal kernels to compress the resolution of log-Mel spectrogramimages, thereby facilitating the vision transformer model's ability to learn important patterns more effectively. Theproposed approach processes the original log-Mel spectrograms at a size of 128×1001 and compresses them intoa fixed 128×129 resolution while performing random image interpolation. This preprocessing step aids the modelin better extracting relevant features for emotion recognition. This paper propose how the CNN-based compressionmethod preserves essential information from the log-Mel spectrograms while minimizing attention noise in thevision transformer model's attention mechanism. Through experiments using the Crowd Sourced EmotionalMultimodal Actors (CREMA) dataset, the proposed method achieved an accuracy of 86.83%, demonstrating superiorperformance in speech emotion recognition compared to existing methods."
순차적 레이블링을 통한 한국어 의존 구문분석,2024,"['의존 구문분석', '어절 임베딩', '사전학습 모델', '스페셜 토큰', 'dependency parsing', 'word-level embedding', 'pre-trained model', 'special token']","의존 구문분석은 언어 분석에서 중요한 단계로, 문장 내 어절 간의 관계를 파악하는 과정이다. 최근 자연어 처리 분야에서는 트랜스포머 계열의 사전 학습 모델들이 다양한 자연어처리 연구에서 뛰어난 성능을 보이며, 의존 구문분석에도 적용되었다. 기존의 사전 학습 모델을 적용한 의존 구문분석은 크게 두 단계로 처리되었다. 첫째, 사전 학습 모델을 통해 생성된 토큰 단위 임베딩을 어절 단위 임베딩으로 병합한다. 둘째, 구성된 임베딩을 비교하거나 분류하는 단계를 통해 의존 관계를 분석한다. 그러나 사전 학습 모델의 특성상 파라미터가 많고, 추가적인 계층을 통해 임베딩을 구성·비교·분류하는 과정이 포함되어 시간 및 메모리의 효율성이 떨어지는 문제가 있었다. 본 논문에서는 의존 구문분석 세트 단위를 정의하고, 계층 축소를 통해 학습 및 추론의 효율성을 높인 순차적 레이블링 기반의 의존 구문분석 기법을 제안한다. 구문분석 세트를 정의하기 위해 스페셜 토큰을 추가하여 어절 단위 임베딩 병합 단계를 생략하였으며, 계층 축소로 파라미터 수를 효율적으로 줄여 학습 및 추론에 필요한 시간을 크게 단축하였다. 제안된 모델은 의존 구문분석에서 유의미한 성능을 보인다.","Dependency parsing is a crucial step in language analysis. It identifies relationships between words within a sentence. Recently, many models based on a pre-trained transformer have shown impressive performances in various natural language processing research. hey have been also applied to dependency parsing. Generally, traditional approaches to dependency parsing using pre-trained models consist of two main stages: 1) merging token-level embeddings generated by the pre-trained model into word-level embeddings; and 2) analyzing dependency relations by comparing or classifying the merged embeddings. However, due to a large number of parameters and additional layers required for embedding construction, comparison, and classification, these models can be inefficient in terms of time and memory usage. This paper proposes a dependency parsing technique based on sequential labeling to improve the efficiency of training and inference by defining dependency parsing units and simplifying model layers. The proposed model eliminates the necessity of the word-level embedding merging step by utilizing special tokens to define parsing units. It also effectively reduces the number of parameters by simplifying model layers. As a result, the training and inference time is significantly shortened. With these optimizations, the proposed model maintains meaningful performance in dependency parsing."
Meta Pseudo Count를 활용한 준지도 학습 기반 인구 밀집도 추정,2024,"['인구밀집도', 'Meta Pseudo Labels', 'CNN', 'Transformer', 'Crowd Density Estimation', 'Meta Pseudo labels', 'CNN', 'Transformer']","대규모 인파가 모이는 장소의 안전을 보장하기 위한 인구 밀집도 분석 기술은, 딥러닝 학습방법을 활용한 지능형 영상 분석 기술을 사용한다. 인구 밀집도 분석 분야에서 레이블링 작업의 비용과 노동력 문제를 해결하기 위해 준지도 학습 방법이 주목받고 있다. 인구 밀집도 분석 기술은 교통 관리, 안전 감시 등 다양한 분야에서 중요한 연구 주제로 활용되며, CNN 계열의 모델을 사용하여 예측 모델을 구축한다. 레이블링 작업은 비용과 노동력이 많이 투입되는 과정이며, 실제 환경은 레이블링 되지 않은 데이터의 양이 레이블링 된 데이터의 양보다 많다. 본 연구에서는 인구 밀집도 분석을 위해 Meta Pseudo Count(MPC)라는 준지도 학습 방법을 제안한다. Meta Pseudo Count 방법론은, 레이블이 없는 데이터에 대해 Pseudo Count를 생성하고, 이를 이용하여 Teacher 모델이 Student 모델을 학습시킨다. 기존의 지도학습 모델에 레이블이 없는 데이터를 추가로 학습하였을 때, Meta Pseudo Count 방식은 예측의 정확도가 준지도 학습 모델의 장점을 보여주며, 레이블이 없는 데이터를 활용하여 학습 모델의 일반화 능력이 향상되었다.","The technology of Crowd density estimation, which ensures the safety of densely populated areas, utilizes intelligent video analysis techniques based on deep learning. Semi-supervised learning methods have gained attention in the field of crowd density analysis to address the challenges of labeling costs and labor. Crowd density estimation is a important research topic applied in various areas such as traffic management and safety surveillance, often using CNN-based models to build prediction models. Labeling tasks are costly and labor-intensive, and in real fields, the amount of unlabeled data outweighs the labeled data. In this paper, a semi-supervised learning method called Meta Pseudo Count (MPC) is proposed for crowd density estimation. The Meta Pseudo Count methodology generates pseudo counts for unlabeled data and uses them to train a Teacher model to educate a Student model. When unlabeled data is added to conventional supervised learning models, the Meta Pseudo Count approach demonstrates the accuracy of predictions, showing the advantages of semi-supervised learning models. It also enhances the generalization ability of the trained model by utilizing unlabeled data for learning."
격자 간섭계의 위상 영상에서의 민감도 및 해상도 최적화를 위한 기계학습법 적용 연구,2024,"['Grating interferometer', 'Phase contrast image', 'Deep learning', 'Swin transformer', 'Simulation', '격자간섭계', '위상차영상', '딥러닝', '스윈트랜스포머', '시뮬레이션']","X-선과 중성자와 같은 방사선은 물체를 파괴하지 않고 내부를 볼 수 있는 의료 및 비파괴 검사 분야에서 널리 사용된다. 엑스선과 중성자를 이용한 흡수 영상 외에도, 격자 간섭계를 사용한 위상차 영상과 다크필드 영상이 있다. 위상차 영상은 방사선이 투과 시 발생하는 파동의 위상차를 이용해 대조비를 나타내고, 기본 흡수 영상보다 더 뛰어난 식별 능력을 가진다. 격자 간섭계 시스템에서 위상격자(G1)가 중앙에 위치한 대칭 구조에서 가장 높은 민감도를 얻을 수 있으며, 위상격자(G1)와 해석격자(G2) 사이에서 샘플의 위치에 따라 결과 영상의 민감도와 영상 품질이 달라진다. 이 반비례하는 특성을 조정하기 위해 스윈 트랜스포머 기반 딥러닝 모델을 사용하여 각각의 좋은 특성을 합성하였으며 이 모델의 성능과 논문 [S. H. Lee et al., Sci. Rep. 10, 9891 (2020)]의 deep residual GAN 모델 결과와 비교 분석하였다. 이후 결과 분석에서 합성 문제를 일으킨 데이터의 유형과 GAN 및 스윈 트랜스포머의 네트워크 구조와 특성을 분석하여, 후속 연구를 위한 보완점을 제안한다.","The X-ray and neutron grating interferometers enable phase-contrast and dark field imaging. Phase-contrast imaging leverages the phase difference of waves as radiation passes through an object, yielding superior contrast compared to conventional absorption imaging. In a grating interferometer system, the maximum sensitivity is achieved in a symmetrical configuration, with the phase grating (G1) positioned at the center. Sensitivity and resolution depend on the distance between the phase (G1) and the analyzer (G2) grating. To harmonize these inversely proportional characteristics, a Swin Transformer-based deep learning model was employed, synthesizing favorable attributes. The performance of this model was subsequently compared and analyzed against the results of a deep residual GAN model, as detailed in our previously published paper [S. H. Lee et al., Sci. Rep. 10, 9891 (2020)]. In the subsequent analysis of the outcomes, we scrutinized and identified the data types contributing to synthesis challenges. Additionally, we explored the network structure and characteristics of both GAN and Swin Transformer, proposing supplementary points for further research. Grating Interferometer,"
이종 그래프 간의 융합 모듈을 활용한 목적 지향 대화 응답 시스템,2024,"['Task-Oriented Dialogue', 'Response Generation', 'Dialogue State Tracking', 'Graph', 'Attention Mechanism', '목적 지향 대화 모델', '응답 생성', '대화 상태 추적', '그래프', '어텐션 메커니즘']","목적 지향 대화 시스템(Task-Oriented Dialogue System)은 특정 업무를 달성하기 위해 시스템이 대화를 통해 사용자에게 도움을 주는 것을 목적으로 하는 자연어 처리의 분야이다. 최근에는 목적 지향 대화 시스템의 성능 향상을 위해 트랜스포머(Transformer) 기반의 사전 학습 언어 모델이 널리 활용되고 있다. 본 논문에서는 보다 전문적인 응답을 생성하기 위해서 사전 학습 언어 모델에 외부지식을 통합하여, 트랜스포머 기반의 언어 모델에 그래프 어텐션 네트워크를 사용하여 지식 그래프 형태의 데이터를 추가적으로 융합하는 시스템을 제안한다. 또한 두 개 이상의 그래프에 대해 연구를 확장하여 이종 그래프의 정보를 사용한 대화 응답 생성을 실험했다. 본 논문에서는 제안 시스템을 검증하기 위해  2,076개 대화와 226,823개의 음악 도메인 그래프 트리플로 이루어진 음악 도메인 기반의 대화 데이터를 구축하고 공개했다. 실험으로 살펴본 최종 제안 모델의 성능은 KoBART 모델을 미세조정(Fine-tuning)한 응답 생성 방식에 비해 ROUGE-1 13.83%p,  ROUGE-2 8.26%p, ROUGE-L 13.5%p의 성능 향상을 보였다.","The field of Task-Oriented Dialogue Systems focuses on using natural language processing to assist users in achieving specific tasks through conversation. Recently, transformer-based pre-trained language models have been employed to enhance performances of task-oriented dialogue systems. This paper proposes a response generation model based on Graph Attention Networks (GAT) to integrate external knowledge data into transformer-based language models for more specialized responses in dialogue systems. Additionally, we extend this research to incorporate information from multiple graphs, leveraging information from more than two graphs. We also collected and refined dialogue data based on music domain knowledge base to evaluate the proposed model. The collected dialogue dataset consisted of 2,076 dialogues and 226,823 triples. In experiments, the proposed model showed a performance improvement of 13.83%p in ROUGE-1, 8.26%p in ROUGE-2, and 13.5%p in ROUGE-L compared to the baseline KoBART model on the proposed dialogue dataset."
인공지능 한문 자동번역을 위한 코퍼스 구축 현황과 과제,2024,"['Key Words: Institute for the Translation of Korean Classics', 'Korean Studies Institute', 'Corpus', 'Neural Machine Translation', 'Transformer', '핵심어: 한국고전번역원', '한국국학진흥원', '코퍼스', '신경망기계번역모델', '트렌스포머번역모델']","【국문초록】 인공지능 한문 자동번역을 위한 코퍼스 구축 현황과 과제육 수 화연구 목적: 본 연구는 한국고전번역원과 한국국학진흥원에서 구축한 코퍼스의 현황을 살펴보고, 앞으로의 과제를 제시하고자 하는 데 목적을 두었다.연구 방법: 신경망기계번역(NMT) 모델을 개발한 한국고전번역원과 transformer 번역모델을 개발한 한국국학진흥원의 코퍼스 구축 현황과 휴먼 평가 과정을 분석하였다.연구 내용: 한국고전번역원과 한국국학진흥원의 코퍼스 구축과 휴먼 평가 과정을 비교하였다.결론 및 제언: 인공지능 한문 자동번역의 질적 제고를 위해서는 “정확성”이 담보된 양질의 코퍼스를 구축하여야 한다. 이를 위해서 문집류 코퍼스, 일기류 코퍼스, 사서류 코퍼스 등 문체별로 별도의 지침을 마련하여 코퍼스를 구축하고, 사업의 속도보다는 “방향성”에 중점을 두어 추진해야 한다.핵심어: 한국고전번역원, 한국국학진흥원, 코퍼스, 신경망기계번역모델, 트렌스포머번역모델","Present Status and Tasks of Establishing a Corpus for AI-based Chinese Character Machine Translation Suhwa Yuk* Abstract: The purpose of this study was to find a way to link sports tourism marketing in the process of determining the direction of cultural marketing for regional development. The survey was conducted from Oct. 13 to Oct. 19, 2023, and a total of 220 people participated. The research results are as follows. First, the impact of cultural marketing on regional development is the expansion of cultural facilities and cultural revitalization. Second, the impact of sports tourism on regional development is price and product. Third, the location, product, and promotion of sports tourism were confirmed to have a partial mediating effect in the relationship between cultural revitalization and regional development. Fourth, the price of sports tourism was confirmed to have a partial mediating effect in the relationship between cultural revitalization, expansion of cultural facilities, and regional development. We hope that this research will serve as an opportunity for the growth of the tourism industry and contribute to revitalizing the local economy of Jeollanam-do.Key Words: Institute for the Translation of Korean Classics, Korean Studies Institute, Corpus, Neural Machine Translation, Transformer □ 접수일: 2024년 12월 1일, 수정일: 2024년 12월 13일, 게재확정일: 2024년 12월 20일＊ 한국국학진흥원 전임연구원(Researcher, Korean Studies Institute, Email: 007water@hanmail.net)"
다자간 대화 시스템을 위한 예상 수신자 및 타겟발화 예측 태스크,2024,"['다자간 대화', '대화 분석', '수신자 예측', '타겟발화 정보 예측', 'multi-party dialogue', 'discourse parsing', 'addressee prediction', 'reply-to prediction']","최근 사람들간의 소통창구가 많아지면서 일대일 대화 뿐만 아닌 다자간의 대화가 많아지고 있으며, 이와 함께 다자간 대화를 분석하기 위한 연구가 활발히 이루어지고 있다. 기존에 제안된 다자대화 분석 모델들은 일반적으로 응답이 주어진 상태에서 최종 응답의 수신자, 즉 발화의 대상을 예측해 왔다. 그러나 이는 실제 다자간 대화 응답 생성에 필요한 작업과는 다르며, 실제 다자간 대화를 위해서는 발화자가 자신이 응답할 수신자를 선정하는 과정이 필요하다. 이를 위해, 본 논문에서는 응답 정보에 의존하지 않는 새로운 다자간 대화 수신자 예측 태스크를 제안한다. 제안한 태스크를 통해 실제 다자간 대화상에서 어떤 발화에 대답할지에 대한 예상 타겟발화와, 발화의 대상인 예상 수신자를 예측하여 맞추는 것을 목표로 한다. 또한 예상 타겟발화 및 수신자 예측을 위해 트랜스포머 인코더 기반의 마스크드 토큰 예측 학습 방식을 활용한 모델을 제안한다. 본 논문에서 제안하는 모델은 최종 응답이 없이 이전까지의 대화 맥락을 통해 현재 발화자의 예상 타겟발화와 예상 수신자를 예측한다. 제안한 모델은 Ubuntu IRC 데이터셋에서 예상 수신자 정확도 82%와 예상 타겟발화 정확도 68%의 성능을 획득하였으며, 이는 제안한 모델이 발화해야 하는 대상을 예측하여 다자간 대화 시스템에 활용할 수 있음을 보여준다. 이후 다자대화 데이터셋을 추가 제작하고 실제 다자간 대화 응답 생성 시스템에 적용하여 연구를 확장할 계획이다.","As the number of communication channels between people has increased in recent years, there has been a rise in both multi-party conversations and one-to-one conversations. Research on analyzing multi-party conversations has also been active. In the past, models for analyzing such dialogues typically predicted the addressee of the final response based on the previous responses. However, this differs from the task of generating multi-party dialogue responses, which requires the speaker to select the addressee to whom they will respond. In this paper, we propose a new task for predicting the addressee of a multi-party dialogue that does not rely on response information. Our task aims to predict and match the expected target utterance with the expected addressee in a real multi-party dialogue. To accomplish this, we introduce a model that uses a transform encoder-based masked token prediction learning method. This model predicts the expected target utterance and the expected addressee of the current speaker based on the previous dialogue context, without considering the final response. The proposed model achieves an accuracy of 82% in predicting the expected recipient and 68% in predicting the expected target utterance accuracy on the Ubuntu IRC dataset. These results demonstrate the potential of our model for use in a multi-party dialogue system, as it can accurately predict the target utterance that should be used. Moving forward, we plan to expand our research by creating additional datasets for multi-party dialogues and applying them to real-world multilateral dialogue response generation systems."
"Chat GPT의 원리, 활용, 한계와 업무효율화",2024,"['트랜스포머', '대규모언어모델', '챗 GPT', '활용방안', '한계', '업무 효율화', 'Transformer', 'LLM', 'Chat GPT', 'Applications', 'Limitations', 'Business Efficiency']","본 논문에서는 대규모 언어모델인 GPT를 활용한 Chat GPT의 원리와 활용방법, 그리고 사용상의 한계 및 업무 효율화 방안을 소개하였다. 이를 위하여 자연어 처리의 작업 영역을 자세히 알아보고, 컴퓨터에서 자연어 처리의 가장 첫 단계로 임베딩이 이루어짐을 설명하였다. 문장 수준의 임베딩을 위하여 제시된 트랜스포머와 GPT의 관계도 설명하였다. 마침내, RLHF를 통하여 GPT-3의 성능을 개선한 GTP-3.5를 기반으로 Chat GPT가 개발되어, OpenAI에 의해 발표되었음도 알아보았다. Chat GPT는 질의응답, 번역, 교정, 요약, 표 데이터 처리, 코딩 등의 영역에 활용할 수 있으며, 역할설정 및 자료 전달을 통하여 원하는 답변을 얻기 위한 유도도 할 수 있다. 한편으로, Chat GPT의 활용 방안이 광대한 만큼 사회에 가져온 충격도 막대함을 알아보았다. 기업체 혹은 국가 차원의 보안이슈가 제기되어 사용금지 조치가 이루어졌으며, 과학계의 저자 인정 여부와 문화예술계는 예술적 가치에 대한 논쟁과 더불어 일자리 이슈가 제기되면서 파업도 일어났다. 생성 AI에 의한 가짜 문제가 제기되었고, 사이버 범죄의 수단으로 악용됨도 알아보았다. Chat GPT가 지닌 환각현상 등의 한계도 알아보았다. 마지막으로 Chat GPT를 업무에 활용하기 위한 방안으로 환각현상을 염두에 둔 내용확인 필요성, 검색기가 아님을 주의하여 RAG 기능이 있는 생성형 AI의 활용하는 것과 전문적인 영역을 위하여 개발된 sLLM 사용 등을 제시하였다.","This paper introduces the principles and applications of Chat GPT, which utilizes the large-scale language model GPT. It first discusses the detailed workings of natural language processing, where embedding serves as the initial step in computer-based language processing. The relationship between transformers and GPT is explained for sentence-level embedding. Then this paper explores the development of Chat GPT based on GPT-3.5, which has been improved via reinforcement learning from human feedback or RLHF, and released by OpenAI. Chat GPT can be utilized in various domains such as question answering, translation, correction, summarization, tabular data processing, and coding. It can guide users to obtain desired responses through role-setting and data delivery. However, its broad application is having significant societal impacts. Issues related to corporate or national security have led to usage restrictions, while debates over authorship recognition in the scientific community and discussions about artistic value in the cultural and arts sector have sparked strikes due to job concerns. The emergence of fake problems produced by generative AI, along with its misuse for cybercrime, is also highlighted. Such limitations of Chat GPT, including hallucination phenomena, are discussed in this work. Lastly, suggestions are made for utilizing Chat GPT in business that include emphasizing the need for content verification with hallucination in mind, cautioning against relying solely on search engines, utilizing generative AI with retrieval-augmented generation(RAG) functionality, and employing small large language models (sLLMs) developed for professional domains."
검색증강생성(RAG) 기반 레시피 추천 시스템의 요구사항 일치도 평가 및 개선 방안,2024,[],"2022년 트랜스포머 구조의 인공지능 대형언어모델(LLM)에 기반한 상용서비스인 OpenAI의 ChatGPT가 등장하면서 이를 이용한 서비스 개발이 큰 관심을 받고 있다. 특히 생성 모델의 환영 현상을 RAG(Retrieval Augmented Generation)을 통해 줄이는 기술이 표준적인 기법으로 자리 잡고 있다.  본 연구는 GPT-4와 LangChain을 사용하여 LLM에 RAG를 레시피 추천 시스템에 접목했을 때 성능을 평가해 보았다. 또한 RAG 시스템의 검색과 추천 성능을 향상할 수 있는 추가적인 기법을 제시하였다. 6가지 사용자 요구 사항을 충족하는 추천 레시피의 성능을 요구사항과 추천된 레시피의 특성 일치도를 비교하여 평가하였다. 그 결과, 기존의 RAG 기법은 언어 모델의 생각을 제공된 문제로 제약하기 때문에 한계를 보였다. 언어 모델의 지식과 제공된 지식을 적절히 결합할 방안의 연구가 필요하다.",다국어 초록 정보 없음
저편향·고분산된 보편적 데이터를 이용한 효율적인 오프라인 강화학습 방법,2024,"['모방학습', '강화학습', '오프라인 강화학습', '전문가 데이터', '범용 인공지능', 'Imitation Learning', 'Reinforcement Learning (RL)', 'Offline RL', 'Expert Demo', 'Artificial General Intelligence']","대규모 언어 모델(Large Language Model) 기반 Robotic Transformer 활용으로 로봇은 복잡한 시퀀스 문제도 스스로 해결할 수 있게 되었으나, 여전히 단위 행동은 사전에 획득된 고품질 전문가 데이터를 이용해 학습되고 있다. 전문가 데이터는 특정 행동을 완벽하게 수행하는 예시로 수집하는 데 드는 시간과 비용이 많이 발생하며, 모든 상황을 고려할 수 없어 편향된 특성이 있다. 따라서, 본 논문에서는 저편향·고분산된 보편적인 데이터를 이용하여 복잡한 문제 환경에서 강화학습이 효율적으로 학습하는 방법을 제안한다. 또한, RLIF(Reinforcement Learning via Intervention Feedback) 알고리즘을 사용한 학습 평가와 환경의 노이즈 차이에 따른 도메인 랜덤화 실험을 진행한다. 본 논문에서는 저편향·고분산된 보편적 데이터를 사용하여 기존의 전문가 데이터만으로 학습했을 때보다 보상이 증가하고 새로운 환경에서도 높은 점수를 유지하는 모델을 만들 수 있다는 결과를 제시한다. 본 연구는 복잡한 환경변화에도 효율적인 강화학습을 실현하는 데 기여할 것으로 기대된다.","The Robotic Transformer, based on the Large Language Model (LLM), allows robots to independently solve complex sequence problems. However, the primitive actions are still derived from high-quality expert data obtained in advance. Expert data consists of flawless execution of specific actions, but it is time-consuming and expensive to collect, and it is biased because it does not account for all situations. In this paper, we propose a method based on reinforcement learning to efficiently learn in complex problem environments using low-bias and high-variance practical data. Additionally, we evaluate the learning using the Reinforcement Learning via Intervention Feedback (RLIF) algorithm and conduct a domain randomization experiment to assess the impact of environmental noise. We demonstrate that using low-bias, high-variance practical data can help create a model that boosts rewards and maintains high scores in new environments compared to training with only expert data. This study contributes to efficient reinforcement learning in complex and changing environments."
한국어 생의학 개체명 인식 성능 비교와 오류 분석,2024,"['개체명 인식', 'BIO-태깅', '트랜스포머', '전이 학습', '생의학 말뭉치', 'Named Entity Recognition', 'BIO-Tagging', 'Transformers', 'Transfer Learning', 'Bio-Medical Corpus']","딥러닝 분야에서 트랜스포머 아키텍쳐의 출현은 자연어 처리 연구가 획기적인 발전을 가져왔다. 개체명 인식은 자연어 처리의 한 분야로 정보 검색과 같은 태스크에 중요한 연구 분야이다. 생의학 분야에서도 그 중요성이 강조되나 학습용 한국어 생의학 말뭉치의 부족으로 AI를 활용한 한국어 임상 연구 발전에 제약이 되고 있다.본 연구에서는 한국어 생의학 개체명 인식을 위해 새로운 생의학 말뭉치를 구축하고 대용량 한국어 말뭉치로 사전 학습된 언어 모델들을 선정하여 전이 학습시켰다. F1-score로 선정된 언어 모델의 개체명 인식 성능과 태그별 인식률을 비교하고 오류 분석을 하였다. 인식 성능에서는 KlueRoBERTa가 상대적인 좋은 성능을 보였다. 태깅 과정의 오류 분석 결과 Disease의 인식 성능은 우수하나 상대적으로 Body와 Treatment는 낮았다. 이는 문맥에 기반하여 제대로 개체명을 분류하지 못하는 과분할과 미분할로 인한 것으로, 잘못된 태깅들을 보완하기 위해서는 보다 정밀한 형태소 분석기와 풍부한 어휘사전 구축이 선행되어야 할 것이다.","The advent of transformer architectures in deep learning has been a major breakthrough in natural language processing research. Object name recognition is a branch of natural language processing and is an important research area for tasks such as information retrieval. It is also important in the biomedical field, but the lack of Korean biomedical corpora for training has limited the development of Korean clinical research using AI.In this study, we built a new biomedical corpus for Korean biomedical entity name recognition and selected language models pre-trained on a large Korean corpus for transfer learning. We compared the name recognition performance of the selected language models by F1-score and the recognition rate by tag, and analyzed the errors. In terms of recognition performance, KlueRoBERTa showed relatively good performance. The error analysis of the tagging process shows that the recognition performance of Disease is excellent, but Body and Treatment are relatively low. This is due to over-segmentation and under-segmentation that fails to properly categorize entity names based on context, and it will be necessary to build a more precise morphological analyzer and a rich lexicon to compensate for the incorrect tagging."
외부 지식 그래프 결합을 위한 그래프 변환기 알고리즘,2024,"['외부 지식 체계', '지식 그래프', '그래프 변환기', '일반 상식 추론', '다중 양상 학습', 'external knowledge base', 'knowledge graph', 'graph transformer', 'commonsense reasoning', 'multi-modal learning']","시각적 상식 추론은 추론 시 단순한 영상 내 객체 간의 특성이나, 관계 등 시각적 정보만을 요구하는 시각적 질문응답과 비교하여 질문 이외에 장면에 대한 맥락적 이해와 관련하여 일반 상식을 요구하는 도전적인 문제다. 본 연구에서는 일반 상식과 관련한 지식을 외부 지식 체계로부터 결합하기 위한 지식 그래프 생성 및 그래프 변환기 학습 알고리즘을 제안한다. 제안 모델에서는 외부 지식 체계인 ConceptNet으로부터 주어진 양상 정보와 관련된 지식을 검색하여 지식 그래프를 생성한다. 시각 객체와 문장 객체와 함께 지식 그래프를 정점과 간선 구분 없이 하나의 입력 단위로 그래프 변환기의 입력으로 학습한다. 본 논문에서 제안한 모델의 우수성을 입증하기 위해 시각적 상식 추론 데이터 집합을 통한 실험으로 기존 모델과 개선된 성능을 비교한다.","Visual Commonsense Reasoning(VCR) presents a more challenging problem compared to Visual Question Answering(VQA), which primarily requires understanding visual characteristics and relationships among objects within an image. In addition to the question itself, VCR necessitates a contextual comprehension of the scene and general commonsense knowledge. This paper proposes a knowledge graph construction and graph transformer learning algorithm to integrate knowledge related to general commonsense from external knowledge systems. In our proposed model, knowledge is retrieved from ConceptNet, an external knowledge system, based on the given modality information to construct a knowledge graph. This knowledge graph, along with images and text, is used as input for the graph transformer as a unified token without distinguishing between nodes and edges during training. To demonstrate the superiority of our proposed model, we conduct experiments using the VCR dataset and compare the improved performance with baseline models."
LLM 기반의 생성형 AI 응답 데이터 품질이 업무 활용 만족도에  미치는 영향에 관한 연구,2024,[],"2017년 새로운 형태의 아키텍처인 트랜스포머(Transformer)가 발표되면서 언어모델에도 많은 변화가 있었다. 특히 대형 언어 모델인 LLM(Large language model)의 발전으로 검색이나 챗봇(Chatbot)과 같은 생성형 AI 서비스가 다양한 업무 영역에 활용되고 있다. 하지만 개인정보 유출과 같은 보안 이슈나 거짓 정보를 생성하는 할루시네이션(Hallucination)과 같은 신뢰성 문제가 발생하면서 이러한 서비스의 실효성에 대한 우려의 목소리도 커지고 있다. 이에 본 연구에서는 이러한 우려에도 불구하고 생성형 AI를 업무 영역에 활용하고 있는 빈도가 점점 증가하고 있는 요인에 대해서 분석하고자 하였다. 이를 위해 LLM 기반의 생성형 AI 응답 데이터 품질에 영향을 미치는 8가지 요인을 도출하고 유효 표본 195개를 대상으로 이러한 요인들이 업무 활용 만족도에 미치는 영향을 실증 분석하였다. 분석결과 전문성, 접근성, 다양성, 편리성이 지속적 사용의도에 유의한 영향을, 보안성, 안정성, 신뢰성 등이 부분적으로 유의한 영향을, 완전성이 부정적 영향을 미치는 요인으로 나타났다. 본 연구에서는 응답 데이터 품질에 대한 수요자의 인식이 업무 활용 만족도에 어떠한 영향을 미치는지 학문적으로 규명하고, 이러한 서비스에 대한 수요자 중심의 의미 있는 실무적 시사점을 제시하는데 그 목적이 있다.","With the announcement of Transformer, a new type of architecture, in 2017, there have been many changes in language models. In particular, the development of LLM (Large language model) has enabled generative AI services such as search and chatbot to be utilized in various business areas. However, security issues such as personal information leakage and reliability issues such as hallucination, which generates false information, have raised concerns about the effectiveness of these services. In this study, we aimed to analyze the factors that are increasing the frequency of using generative AI in the workplace despite these concerns. To this end, we derived eight factors that affect the quality of LLM-based generative AI response data and empirically analyzed the impact of these factors on job satisfaction using a valid sample of 195 respondents. The results showed that expertise, accessibility, diversity, and convenience had a significant impact on intention to continue using, security, stability, and reliability had a partially significant impact, and completeness had a negative impact. The purpose of this study is to academically investigate how customer perception of response data quality affects business utilization satisfaction and to provide meaningful practical implications for customer-centered services."
딥러닝 기반 도로 네트워크 추출 방법론 비교,2024,"['원격탐사', '정사영상', '도로추출', '딥러닝', '트랜스포머']","도로 정보는 자율주행, 도로 계획 등 다양한 분야에서 가치가 높고 이에 따라 원격탐사 영상으로부터 도로 정보를 자동으로 추출하기 위한 딥러닝 기반의 연구가 수행되어왔다. 본 연구는 딥러닝을 활용하여 정사 영상으로부터 도로 네트워크를 추출하는 여러 segment ation 모델들을 통해 도로를 추출하고 그 결과를 비교하고자 하였다. 이를 위해 Semantic Segmentation 작업을 수행하는 모델인 PSPNet, SegNet, Unet, SegFormer를 활용하였고 입력 자료로는 정사영상과 수치지형도를 사용하였다. 성능 분석을 위해 다양한 평가 지표(accuracy, precision, recall, f1-score, mIOU)를 사용하였고 SegFormer의 결과가 모든 평가 지표에서 가장 우수하였다. 본 연구결과는 딥러닝 방법론을 활용한 도로 정보 갱신시스템을 구현할 때 모델 선정에 도움을 줄 수 있을 것으로 기대할 수 있다.",다국어 초록 정보 없음
정밀한 다중언어 OCR을 위한 파이프라인,2024,"['deep learning', 'computer vision', 'optical character recognition', 'transformer', '.']","본 논문에서는 효과적인 다중언어 OCR(Optical Character Recognition)을 수행하기 위한 최적의 파이프라인을 제안한다. 기존 연구들은 단일 언어 데이터를 대상으로 OCR을 수행해 왔다. 이 과정에서 이미지는 먼저 탐지 모델에 입력되어 영역을 식별 후, 이 영역을 인식 모델로 전달하여 텍스트 문장을 추출한다. 하지만 이 방식은 단일 언어 OCR 네트워크에 국한되어 있어, 다양한 언어에 대한 데이터는 처리하지 못한다는 한계가 있었다. 이에 본 논문에서는 각 언어에 대한 특성을 고려한 언어 분류 모델을 기존 모델에 통합하고, 이를 기반으로 언어별 독립적 인식 모델을 구성한 다중언어 OCR이 가능한 방법론을 개발하였다. 제안하는 파이프라인은 실험을 통해 다중언어 데이터에 대해 정량적 및 정성적으로 우수한 성능을 확인하였다.","This paper proposes an optimal pipeline for effective multilingual Optical Character Recognition(OCR). Previous research has focused on performing OCR on single-language data. In this process, images are first input into a detection model to identify regions, which are then passed to a recognition model to extract text sentences. However, this approach is limited to single-language OCR networks and cannot process data in various languages. To address this limitation, we integrated a language classification model, which considers the characteristics of each language, into the existing model and developed a methodology for multilingual OCR by constructing independent recognition models for each language. The proposed pipeline was experimentally validated, demonstrating superior quantitative and qualitative performance on multilingual data."
강건한 자기주도 학습 기반 다중 프레임 깊이 추정: 코스트 볼륨 대체제를 찾아서,2024,"['Deep learning', 'Self-supervised learning', 'Transformer', 'Cost volume', 'Depth estimation']","다중 프레임 깊이 추정(multi-frame depth estimation)은 여러 입력 프레임의 기하학적 정보를 활용하기 때문에 단일 프레임 깊이 추정 (monocular depth estimation)보다 더 좋은 깊이 예측을 할 수 있다. 기존 다중 프레임 기반 모델은 에피폴라 기하학을 기반으로한 코스트 볼륨을 쌓아서 깊이 추정을 하였는데, 이 코스트 볼륨은 두 가지 주요 단점을 가진다. (1) 정적인 환경에서만 동작하고 (2) 모델 추론 단계에서 추가적인 카메라 포즈 정보를 요구한다. 결과적으로, 이러한 에피폴러 기반 코스트 볼륨은 동적 객체가 존재하는 실제 환경에서 깊이 추정 성능이 부정확하다. 따라서 본 논문에서는 에피폴러 기반 코스트 볼륨의 한계를 극복하기 위해 종합적인 코스트 볼륨을 사용하는 것을 제안하고, 트랜스포머의 cross-attention map 이 그 역할을 할 수 있음을 보인다. 이미지 재구성의 자가지도 학습으로 깊이 추정 모델을 학습할 경우, 트랜스포머의 cross-attention layer은 에피폴라 기하학에 기반하지 않는 코스트 볼륨을 배울 수 있으며, 동적 객체가 존재하는 환경에서 강건한 깊이 추정을 할 수 있을 것이다. 우리는 동적인 객체가 많은 Cityscapes 데이터셋에 평가를 진행하여 본 논문의 방법론이 기존 방법론보다 우수하고 동적인 객체가 존재하는 실제 환경에서 강건한 깊이 추정을 할 수 있음을 실험적으로 보인다.","Self-supervised multi-frame depth estimation predicts depth by utilizing geometric cues from multiple input frames. Traditional methods rely on epipolar geometry to construct cost volumes, but they have two major drawbacks: (1) they assume a static environment and (2) they require pose information during inference. Consequently, these methods struggle in real-world scenarios with dynamic objects. In this paper, we propose using the cross-attention map as a comprehensive cost volume to address these limitations. We show that training the cross-attention layers for image reconstruction enables implicit learning of a warping function, similar to the explicit epipolar warping in conventional methods. We introduce CRoss-Attention map and Feature aggregaTor (CRAFT), designed to effectively aggregate and refine the full cost volume. We also implement CRAFT hierarchically, enhancing depth predictions through a coarse-to-fine approach. Evaluations on the Cityscapes datasets demonstrate that our method outperforms traditional techniques, showing robustness in challenging conditions with dynamic objects."
딥러닝 기법을 활용한 임상 및 수종 분류 정확도 평가,2024,"['Tree Species', 'Forest Type', 'Deep Learning', 'DeeplabV3+', 'Swin-Transformer']","본 연구는 위성영상을 기반으로 딥러닝 모델을 활용하여 임상 및 수종 분류를 수행하였다. 딥러닝 모델은 CNN(Convolutional Neural Network) 구조의 DeeplabV3+ 모델과 Transformer 기반의 Swin-Unet을 활용하였으며, 데이터세트는 분광정보와 식생지수의 조합에 따라 Dataset A(4채널, 분광정보), Dataset B(7채널, 분광정보+식생지수)를 활용하여 식생지수가 임상 및 수종 분류 정확도에 미치는 영향력을 평가하였다. 데이터세트 구성에 따른 분류 정확도 평가 결과, 임상분류 과정에서는 표면반사율 정보에 식생지수를 추가로 활용함에 따라 분류정확도가 향상되었으나, 반대로 수종분류 과정에서는 분류 정확도가 소폭 감소하였다. 딥러닝 모델 별 분류정확도 비교결과, 학습시간의 경우, DeeplabV3+ 모델이 적게 소요되었지만 분류 정확도는 Swin-Unet을 이용했을 경우 더 우수하였다. 임상 분류 과정에서는 Dataset B를 활용한 Swin-Unet이 전체정확도(OA; Overall Accuracy)기준 평균 약 75.1%로 가장 높은 정확도를 보였으며, 수종 분류에서는 Dataset A를 활용한 Swin-Unet이 전체정확도 기준 평균 약 45.3%로 가장 높은 정확도를 보였다.","This study utilized deep learning models based on satellite imagery to classify forest types and species. The deep learning models used were the CNN-based DeeplabV3+ and the Transformer-based Swin-Unet. The datasets were prepared to Dataset A (4 channels, spectral information) and Dataset B (7 channels, spectral information + vegetation indices) by a combination of spectral information and vegetation indices, and then the impact of vegetation indices on the classification accuracy of forest type and species segmentation were assessed. The result of classification accuracy based on dataset composition showed that the addition of vegetation indices to surface reflectance information could improve the accuracy in forest type classification while the accuracy for tree species segmentation reduced. When comparing the each classification accuracy by used deep learning models, DeeplabV3+ required approximately 10 minutes less for training time, and Swin-Unet showed higher performance in terms of classification accuracy. In forest type classification, Swin-Unet using Dataset B was estimated at the highest overall accuracy 75.1% whereas Swin-Unet using Dataset A was assessed at the highest overall accuracy 45.3% in species segmentation.1)"
셀프-어텐션(Self-Attention)을 활용한 집단 감정 서사 연구의 가능성,2024,"['인공지능', '감정 분석', '셀프-어텐션', '트랜스포머', '과제 기반 연결*', 'artificial intelligence', 'emotion analysis', 'self-attention', 'transformers', 'task-based connection']","인공 지능 기반 감정 분석은 집합적 감정 분석에 유용하다. 하지만 이제까지의 분석은 주로 데이터를잘 알려진 몇 가지 감정으로 분류하는 것에 머물렀다. 감정을 둘러싼 이론적 논쟁을 참고하면 이는 감정 분석의 가능성을 제한하는 일이다. 이 글에서는 이런 한계를 넘어서 감정 서사를 포착하는 인공 지능 기반 감정 분석의 가능성을 검토한다. 그 가능성의 핵심에는 셀프-어텐션(self-attention)이 있다.셀프-어텐션은 트랜스포머 아키텍쳐의 핵심 기술인데, 데이터에서 토큰들 사이의 연결과 의존을 보다다양하게 포착한다. 그것이 구조 동일성 기반 연결이 아니라 과제 기반 연결에 주목하기 때문이다. 셀프-어텐션에 기반한 다양한 모델을 통해 우리는 감정 서사를 좀 더 정교하게 탐색하는 다양한 전략을고안할 수 있다. 이 글에서는 자동 문서 생성 인공 지능과 가려진 단어 예측 인공 지능을 활용한 두가지 전략을 제안한다. 나아가 코로나19 관련 데이터를 활용하여, 자동 문서 생성을 통해 특정 데이터에 존재하는 주된 감정 서사를 재현하는 접근의 예시를 제시한다.","Artificial intelligence-based emotion analysis helps analyze collective emotion. However, analytics have mainly been limited to categorizing data into a few well-known emotions.Considering the theoretical debates surrounding emotions, we can say this limits the possibilities of emotion analysis. In this article, I examine the potential for AI-based emotion analysis to go beyond these limitations and capture emotional narratives. At the core of this possibility is self-attention. Self-attention is a crucial technology in Transformer architecture. It captures more delicate and diverse connections and dependencies between tokens in the data because it focuses on task-based connections rather than structural identity-based connections. Various models based on self-attention allow us to devise diverse strategies to explore emotional narratives more sophisticatedly. This article proposes two strategies that utilize automatic document generation AI and masked word prediction AI. Furthermore, using COVID-19-related data, I present a real-world example of the first strategy that uses automatic document generation to recreate the dominant emotion narrative in a given data set."
BERT를 이용한 협업 필터링 강화 추천 시스템,2024,"['BERT', 'collaborative filtering', 'deep learning', 'embed', 'recommendation system']","최근 인공지능과 딥러닝 기술은 크게 발전하였으며, 그 중에서도 BERT 모델은 트랜스포머 아키텍처를 기반으로한 자연어 처리 분야에서 문맥 이해 능력이 뛰어나다는 평가를 받고 있다. 이러한 성능은 전통적인 추천 시스템을 한단계 더 발전시킬 수 있는 잠재력을 지니고 있다. 본 연구에서는 추천 시스템의 성능 향상을 위해 협업 필터링 방식에딥러닝 모델을 결합하는 접근 방식을 채택하였다. 구체적으로, BERT를 활용해 사용자 리뷰의 감정 분석을 수행하고, 이러한 리뷰 감정을 기반으로 사용자를 임베딩함으로써 유사한 취향을 가진 사용자를 찾아내어 추천하는 시스템을 구현하였다. 또한 이 과정에서 오픈소스 검색 엔진인 Elasticsearch를 활용하여 빠른 검색, 추천 결과를 검색할 수 있다.사용자의 텍스트 데이터를 분석하여 추천의 정확도와 개인화 수준을 높이는 접근 방식은 향후 다양한 온라인 서비스에서의 사용자 경험 개선에 중요한 역할을 할 것이다.","In recent years, artificial intelligence and deep learning technologies have made significant advances, and the BERT model has been recognized for its excellent contextual understanding in natural language processing based on the transformer architecture. This performance has the potential to take traditional recommendation systems to the next level. In this study, we adopt an approach that combines a collaborative filtering approach with a deep learning model to improve the performance of recommendation systems. Specifically, we implemented a system that uses BERT to analyze the sentiment of user reviews and embed users based on these review sentiments to find and recommend users with similar tastes. In the process, we also utilized Elasticsearch, an open-source search engine, for quick search and retrieval of recommended results. The approach of analyzing users' textual data to increase the accuracy and personalization of recommendations will play an important role in improving the user experience on various online services in the future."
3차원 라이다 스캐너 기반 포인트 클라우드의 의미론적 분할 기술,2024,[],"3차원 라이다를 통해 획득한 포인트 클라우드의 의미론적 분할은 최근 컴퓨터 비전, 자율주행, 로봇 공학 등 다양한 분야에서의 활용 가능성으로 인하여 주목받고 있다. 그러나 3D 포인트 클라우드 의미론적 분할은 데이터의 비정형성, 대용량 처리, 센서 노이즈 등으로 인한 여러 가지 도전 과제를 안고 있으며, 해결하기 위해 다양한 접근 방식과 알고리즘이 제안되고 있다. 특히 최근 몇 년간 딥러닝 기술의 발전으로 종단간 학습이 가능한 신경망 모델들로 기술 개발 영역이 확대되고 있다. 본 기고문에서는 포인트, 이미지 투영, 복셀, 트랜스포머 모델 등 다양한 접근 방식의 주요 알고리즘들을 체계적으로 분류하고, 각 방법론의 핵심 아이디어, 학습 모델의 구조 등 장단점을 비교 분석하였다. 이를 통해 3D 포인트 클라우드 의미론적 분할 분야의 현재 기술 수준을 종합적으로 파악하고, 관련 연구자에게 향후 연구 방향을 제시하고자 한다.",다국어 초록 정보 없음
이미지 특징 강화와 앙상블 학습을 활용한 디지털 조작 이미지 검출 프레임워크,2024,"['computer vision', 'image forgery detection', 'ensemble learning', 'feature enhancement', 'CNN', 'vision transformer', '.']","디지털 환경에서 조작 이미지는 무분별하게 생성되며, 이에 따라 적응성과 범용성을 갖춘 자동화된 검출 시스템이 요구된다. 기존의 연구에서는 특정 형태의 조작만을 검출하거나 상황에 국한된 모델을 제안하여 다양한 환경에 확장이 어렵다는 한계가 존재하였다. 또한 최신 조작 경향성을 반영한 데이터를 활용한 연구가 부족한 상황이다. 따라서 본 연구는 다양하고, 새로운 조작 이미지를 효과적으로 검출하고, 확장 가능성을 갖춘 강건한 딥러닝 프레임워크를 제안한다. 이를 위해 조작된 이미지의 특징을 강화하였으며 다수의 딥러닝 기반 모델에 앙상블 학습을 적용하였다. 주요 결과로는 컨볼루션 신경망(Convolutional Neural Network)과 비전 트랜스포머(Vision Transformer) 기반의 다섯 개의 모델을 앙상블 한 결과 기본 모델과 비교하여 최소 3.45%에서 최대 10.4%의 정확도가 상승하였으며, 특징을 강화한 조작 이미지가 검출 성능에 효과적임을 확인하였다.","In the digital environment, forged images are generated indiscriminately, requiring automated detection system with adaptability and versatility. The limitations of existing studies are that they detect only certain types of manipulation or propose models that are limited to a specific situation, making it difficult to extend to various environments. In addition, there is a lack of research utilizing data that reflects the latest forgery trends. Therefore, This paper proposes a scalable and robust deep learning-based framework for effectively detecting diverse and novel types of digitally forged images. To address this we applied feature enhancing on forged images and ensemble learning on multiple deep learning-based models. The main results are that the ensemble of five Convolutional Neural Network and Vision Transformer-based models showed an accuracy increase of at least 3.45% and up to 10.4% compared to the baseline model, and confirmed that feature-enhanced image was effective in improving detection performance."
배기가스 온도 데이터를 활용한 선박 메인엔진 결함 진단 및 예지,2024,"['Fault diagnosis', 'Time-series prediction', 'Marine systems', 'Exhaust gas temperature', 'Machine Learning', 'Transformer']","선박 메인 엔진의 결함을 조기에 발견하고 대처하는 것은 효율적이고 안전한 운항을 위해 매우 중요하다. 결함이 발생할 경우 경제적 손실과 안전의 위험이 증가할 수 있다. 그러나 현재 시점에서의 결함 진단은 이미 발생한 결함에 대해서만 대처할 수 있다는 한계가 있다. 따라서 본 논문에서는 실제 운항 환경에서 수집된 배기가스 온도 데이터를 활용하여 현재<BR/>시점에서의 결함 진단에서 더 나아가 미래 시점에서의 결함 진단으로 확장하여 선박 메인 엔진의 결함 진단을 위한 모의실험을 수행한다. 연구는 세 단계로 진행된다. 첫째, 현재 시점에서의 결함 진단에 여러 머신러닝 모델을 적용하여 가장 적합한 모델을 선정한다. 둘째, 미래의 시계열 데이터를 예측하는 Transformer 기반 모델을 설계하여 성능을 평가한다.  마지막으로 예측된 시계열 데이터를 기반으로 미래 시점에서의 결함 진단을 진행한다. 실험 결과, 예측된 시계열 데이터를 활용하여 결함 진단을 진행하여 78.160%의 정확도를 달성하였다.",다국어 초록 정보 없음
생성형 AI를 활용한 기업의 업무혁신과 임직원 역량 향상에 관한 연구 : POSCO P-GPT를 중심으로,2024,"['생성형 AI', 'Chat-GPT', 'P-GPT', '업무혁신', '역량향상']","최근 인공지능의 활용성이 확산되면서 이미지, 영상인식, 음성인식 및 합성 등의 분야에서 데이터 학습을 통한 생성모델, 초거대 언어모델이 본격적으로 등장하였으며, `16년 알파고 출현 이후 딥러닝의 확산과 하드웨어의 급격한 발전으로 인공지능 학습능력과 정확도가 급속하게 향상되었다. 인공지능 기술은 다른 기술분야에 비해 기술의 변화속도가 매우 빠르며, 서비스 구현을 위한 핵심 모델의 성능이 최근 몇 년사이에 큰 폭으로 향상되었고, COVID-19 펜데믹 이후 사회 및 산업 전분야에 급격한 디지털 대전환으로 인공지능 산업의 팽창과 민간투자, 스타트업의 활성화도 꾸준히 진행중이다. 이러한 배경에서 대형언어모델을 중심으로 하는 생성형 AI(Chat-GPT : Chat-Generative Pre-trained Transformer 등)가 본격 출현하면서 인공지능 시장을 선도하고 있으며, 국내 뿐만 아니라, 주요 선진국에서도 생성형 AI기술에 대한 선점과 사회적 파급효과를 위한 대응 정책을 수립하여 적극적으로 주도하고있다. 본 연구는 POSCO에서 활용중인 P-GPT를 중심으로 생성형 AI를 활용한 기업의 업무혁신과 역량 향상을 위한 시사점을 도출하기 위해 다음과 같은 연구를 수행하였다. 첫째, 생성형 AI산업에 관한 사례조사를 통해 기업들이 적용하고 있는 생성형 AI의 특징을 비교분석 함으로써, 기업들의 생성형 AI적용 방안에 대한 시사점을 도출하고자 한다. 둘째, 생성형AI를 활용한 업무프로세스 혁신방안을 위해 POSCO의 P-GPT 데이터를 기반으로 기업의 현재 활용 수준과 효과성을 평가하고자 한다. 셋째, 사내 직원을 대상으로 실태조사를 통해 직원들의 GPT사용경험, 피드백 데이터를 수집하고, 이를 분석하여 개선방안을 도출하고자 한다. 이에 본 연구의 목적은 생성형 AI를 적용하고자 하는 기업들에게 업무혁신을 위한 방안과 직원들의 역량향상 및 교육에 관한 시사점을 제시하는 것이다.",다국어 초록 정보 없음
BERT 기반 사전학습을 이용한 탄성파 자료처리: 송신원 모음 배열 비교,2024,"['BERT', 'pretraining', 'seismic processing', 'BERT', '사전학습', '탄성파 자료처리']","탄성파 자료처리는 탄성파 자료를 분석하여 지구 내부 구조와 특성을 파악하는 기술로, 높은 컴퓨터 연산력이 요구된다. 이러한 도전 과제를 해결하기위해 머신러닝 기술이 도입되었으며, 잡음 제거, 속도 모델 구축 등 다양한 작업에서 활용되고 있다. 그러나, 대부분의 연구는 특정 탄성파 처리 작업에집중되어 있어 자료에 내재된 유사한 특징과 구조를 충분히 활용하지 못하는 한계가 있다. 본 연구에서는 BERT (Bidirectional Encoder Representations from Transformers) 기반의 사전학습을 위해 단일 송신원 모음에서 수신기별 시계열 자료(‘수신기 배열’)와 동일 시간에 기록된 수신기 신호(‘시간 배열’)를 입력 자료로 활용하는 방법을 비교하였다. 이를 위해 단층을 포함한 속도 모델에서 생성한 합성 송신원 모음 자료를 이용하여 잡음 제거, 속도 추정, 그리고 단층 확인 작업을 수행하였다. 임의 잡음 제거 작업에서는 수신기 및 시간 배열에서 모두 좋은 성능을 보였으나, 공간적인 분포 파악이 요구되는 속도 추정 및 단층 확인 작업에서는 시간 배열의 결과가 상대적으로 더 우수함을 확인하였다.","The processing of seismic data involves analyzing earthquake wave data to understand the internal structure and characteristics of the Earth, which requires high computational power. Recently, machine learning (ML) techniques have been introduced to address these challenges and have been utilized in various tasks such as noise reduction and velocity model construction. However, most studies have focused on specific seismic data processing tasks, limiting the full utilization of similar features and structures inherent in the datasets. In this study, we compared the efficacy of using receiver-wise time-series data (“receiver array”) and synchronized receiver signals (“time array”) from shotgathers for pretraining a Bidirectional Encoder Representations from Transformers (BERT) model. To this end, shotgather data generated from a synthetic model containing faults was used to perform noise reduction, velocity prediction, and fault detection tasks. In the task of random noise reduction, both the receiver and time arrays showed good performance. However, for tasks requiring the identification of spatial distributions, such as velocity estimation and fault detection, the results from the time array were superior."
BART 기반 문서 요약을 통한 토픽 모델링 성능 향상,2024,"['문서 요약', 'BART', '토픽 모델링', 'LDA', 'Perplexity', 'Rouge', 'Document Summarization', 'Topic Modeling']","정보의 증가 속에서 학문 연구의 환경은 지속적으로 변화하고 있으며, 이에 따라 대량의 문서를 효과적으로 분석하는 방법의 필요성이 대두된다. 본 연구에서는 BART(Bidirectional and Auto-Regressive Transformers) 기반의 문서 요약 모델을 사용하여 텍스트를 정제하여 핵심 내용을 추출하고, 이를 LDA(Latent Dirichlet Allocation) 알고리즘을 통한 토픽 모델링의 성능 향상 방법을 제시한다. 이는 문서 요약을 통해 LDA 토픽 모델링의 성능과 효율성을 향상시키는 접근법을 제안하고 실험을 통해 검증한다. 실험 결과, 논문 데이터를 요약하는 BART 기반 모델은 Rouge-1, Rouge-2, Rouge-L 성능 평가에서 각각 0.5819, 0.4384, 0.5038의 F1-Score를 나타내어 원문의 중요 정보를 포착하고 있음을 보인다. 또한, 요약된 문서를 사용한 토픽 모델링은 Perplexity 지표를 통한 성능 비교에서 원문을 사용한 토픽 모델링의 경우보다 약 8.08% 더 높은 성능을 보인다. 이는 토픽 모델링 과정에서 데이터 처리량의 감소와 효율성 향상에 기여한다.","The environment of academic research is continuously changing due to the increase of information, which raises the need for an effective way to analyze and organize large amounts of documents. In this paper, we propose Performance Improvement of Topic Modeling using BART(Bidirectional and Auto-Regressive Transformers) based Document Summarization. The proposed method uses BART-based document summary model to extract the core content and improve topic modeling performance using LDA(Latent Dirichlet Allocation) algorithm. We suggest an approach to improve the performance and efficiency of LDA topic modeling through document summarization and validate it through experiments. The experimental results show that the BART-based model for summarizing article data captures the important information of the original articles with F1-Scores of 0.5819, 0.4384, and 0.5038 in Rouge-1, Rouge-2, and Rouge-L performance evaluations, respectively. In addition, topic modeling using summarized documents performs about 8.08% better than topic modeling using full text in the performance comparison using the Perplexity metric. This contributes to the reduction of data throughput and improvement of efficiency in the topic modeling process."
비관리 해변의 해안 쓰레기 모니터링을 위한 RT-DETR 적용 방안 연구,2024,"['무인항공기', '해안 쓰레기', '비관리 해변', '모니터링', '현장 조사', 'UAV', 'Coastal Debris', 'Unmanaged Coast', 'RT-DETR', 'Monitoring', 'Field Investigation']","한정된 정점과 인력 기반의 조사로 실제 국내 표착되는 해안 쓰레기의 총용량 추정이 어려운 우리나라의 해안 쓰레기 모니터링 방식 개선을 위해 비관리 해변에서 UAV(: Unmanned Aerial Vehicle) 이미지와 RT-DETR 모델을 기반으로 해안 쓰레기 탐지하고 현장 조사와의 비교 연구로 해안 쓰레기의 정량적 탐지 및 자연 해안선 기준 우리나라에 표착되는 전체 쓰레기 총용량 추정 가능성을 제시하였다. RT-DETR(: Realtime DEtection TRansformer) 모델 학습 결과 mAP@0.5는 0.894, mAP@0.5:0.95는 0.693의 정확도를 보였다. 모델을 비관리 해변에 적용한 전체 해안 쓰레기 개수에 대한 정확도는 72.9%로 나타났다. 본 연구와 비관리 해변에 대한 모니터링을 정의하는 관리지침 마련 연구가 동반된다면 우리나라에 표착되는 전체 해안 쓰레기의 총 용량 추정이 가능할 것으로 기대된다.",다국어 초록 정보 없음
상대적 위치 임베딩을 적용한 DeBERTa 기반 물류 안전사고 인과관계 분류,2024,"['인과관계 분류', '상대적 위치 임베딩', '물류 안전 관리', '자연어처리', 'Logistics Safety Management', 'Natural Language Processing', 'Causal Relationship Classification', 'Relative Position Embedding', 'DeBERTa']","최근 물류 산업의 급속한 성장에 따라 안전사고 발생 빈도가 증가하고 있으며, 이를 예방하기 위한 AI 기반 인과관계 분석의 중요성이 대두되고 있다. 하지만 물류 안전사고 사례의 상당수는 단일이 아닌 복수의 인과관계를 포함하고 있어, 기존의 BERT(bidirectional encoder representations from transformers) 계열 모델이 사용하는 절대적 위치 임베딩만으로는 이러한 복잡한 문맥을 정확히 이해하는 데 한계가 있다. 이러한 문제를 해결하고자 본 연구에서는 상대적 위치 임베딩과 절대적 위치 임베딩을 모두 고려하는 DeBERTa(decoding-enhanced BERT with disentangled attention) 모델 기반의 인과관계 분류 방법을 제안하며, 이 방법은 물류 안전사고 문장 내 복수의 인과관계를 더 정확하게 분류할 수 있다. 제안된 방법의 유효성을 검증하기 위해 BERT, ELECTRA(efficiently learning an encoder that classifies token replacements accurately) 모델과 DeBERTa의 인과관계 분류 정확도와 F1-score를 비교 분석하였다. 그 결과, 상대적 위치 임베딩이 복수의 인과를 포함하는 문장 내 인과관계 분류정확도 향상에 기여함을 확인하였다.","The rapid growth of the logistics industry has led to an increase in the frequency of safety incidents, highlighting the importance of AI-based causal relationship analysis for prevention. Many logistics safety incident cases involve multiple causal relationships rather than a single one, which poses challenges for existing BERT(bidirectional encoder representations from transformers)-based models that rely solely on absolute position embeddings to accurately understand such complex contexts. To address this issue, this study proposes a causal relationship classification method based on the DeBERTa(decoding-enhanced BERT with disentangled attention) model, which considers both relative and absolute position embeddings. This approach enables more accurate classification of multiple causal relationships within logistics safety incident sentences. To validate the effectiveness of the proposed method, we compared the classification accuracy and F1-score of BERT, ELECTRAefficiently learning an encoder that classifies token replacements accurately), and DeBERTa models. The results confirm that relative position embeddings contribute to improving the accuracy of causal relationship classification in sentences containing multiple causal links."
해충 카운팅의 정확성 향상을 위한 Dual Block 기반의새로운 Mada-CenterNet,2024,"['Pest Counting', 'Deep Learning', 'Object Detection', 'Crowd Counting']","농업 분야에서 해충에 대한 효과적인 방제는 작물 생산성 향상에 필수적인 요소이다. 해충의 방제를 위해서는 해충의 종류, 발생시기는 물론이며, 해충의 발생량에 대한 정보가 필요하다. 해충의 발생량을 파악하는 방법인 해충 카운팅 관련 선행 연구인,Mada-CenterNet은 변형 가능한 컨볼루션과 멀티스케일 어텐션 퓨전을 활용하여 해충 카운팅의 정확도를 향상시켰으며 해당 분야에서 가장 우수하다고 보고되고 있다. 본 연구에서는 Mada-CenterNet의 트랜스포머 구조인 멀티스케일 어텐션 대체하는 새로운트랜스포머 구조인 듀얼 블록을 적용하였으며, 픽셀 경로와 시맨틱 경로의 교차 어텐션을 통해 더욱 정교한 특징 맵을 추출하였다.실험 결과, 제안된 모델은 기존 Mada-CenterNet보다 해충 카운팅 정확도가 우수함과 동시에 폐색 문제와 해충의 몸체 손상, 다양한 모습으로 인한 탐지의 어려움을 효과적으로 완화하였다. 기존 해충 카운팅의 방법과 달리, 인력 및 시간 비용을 절감할 수 있다는 장점을 확보할 수 있으며 물체의 계수가 필요한 다른 농업 분야에도 활용이 가능할 것으로 기대된다.","Effective pest control in the agricultural field is essential for improving crop productivity. To do so, information onthe type and timing of pests, as well as the amount of pests generated, is required. Mada-CenterNet, a prior studyon pest counting, which is a method of identifying the amount of pest occurrence, has improved the accuracy ofpest counting by utilizing transformable convolution and multiscale attention fusion and is reported to be the best inthe field. In this study, a new transformer structure with a dual block was applied instead of multiscale attention,which is the transformer structure of Mada-CenterNet. More sophisticated feature maps were extracted throughcross-attention of pixel path and semantic path. As a result of the experiment, the proposed model has improved theaccuracy of pest counting. It is better than the existing Mada-CenterNet and effectively alleviates obstructionproblems, damage to pests' bodies, and detection difficulties caused by various appearances. Unlike conventionalpest counting methods, it can secure the advantage of reducing manpower and time costs, and it is expected that itcan be used in other agricultural fields that require counting of objects."
연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교,2024,"['Consolidation settlement', 'Deep learning', 'Neural networks', 'Settlement prediction', 'Time-series forecasting']","대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교·분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교·분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다.","The accurate prediction of consolidation settlement is essential for construction sites on soft clay to optimize preload removal and reduce residual settlement. In Korea, measurement-based methods are commonly employed; however, these methods can be inaccurate with limited data and vary depending on the analysis period. Weighted nonlinear regression analysis and various deep learning models have been proposed to overcome these limitations; however, comparative analysis of these techniques remains insufficient. Thus, this study compares four deep learning  lgorithms(i.e., the ANN, LSTM, GRU, and Transformer models) and three measurement-based settlement prediction techniques (i.e., the hyperbolic method, Asaoka method, and weighted nonlinear regression analysis) across 392 conditions based on training and regression days (60-150 days). The results demonstrated that the weighted nonlinear regression analysis and GRU model generally obtained the highest prediction accuracy under all conditions, and the prediction accuracy of all techniques improved as the duration of the measurement data increased. When using 150 days of data, all the techniques achieved errors of less than 3 cm, providing accurate prediction results."
GPT를 활용한 MQTT 기반 IDS 우회 방법,2024,"['AI', 'GPT', 'MQTT', 'IDS', 'evasion', '.']","사물인터넷(IoT)은 경량 프로토콜인 MQTT(Message Queuing Telemetry Transport)를 통해 기기 간의 원활한 통신을 지원하며, 효율성과 확장성 등의 장점으로 인해 다양한 분야에서 활용되고 있다. 그러나 IoT가 확산되며 네트워크 보안 문제도 야기되고 있으며, 특히 MQTT 트래픽의 경량성과 비표준화된 특성, 그리고 공격 기법의 지속적인 진화로 인해 기존 침입 탐지 시스템(IDS)은 이러한 트래픽을 효과적으로 탐지하는 데 한계를 드러내고 있다. 본 연구에서는 IDS의 탐지 성능을 향상시키는데 활용할 수 있도록 GPT(Generative Pre-trained Transformers) 같은 생성 인공지능(AI)를 활용하여 IDS 탐지를 회피할 수 있는 MQTT 데이터를 생성하는 방법을 제안한다. 전처리된 정상 MQTT 데이터를 기반으로 GPT 모델을 학습시켜 데이터를 생성하고, 악성 MQTT 데이터를 merge 함으로써 IDS 탐지를 우회할 수 있는 데이터를 생성하였다. 생성된 데이터는 IDS의 취약점을 분석하고, 탐지 성능 개선을 위한 학습 데이터 강화 및 모델 설계에 활용될 것을 기대한다.","The Internet of Things(IoT) supports seamless communication between devices through the lightweight protocol  Message Queuing Telemetry Transport(MQTT), which is widely applied across various fields due to its advantages in efficiency and scalability. However, the rapid expansion of IoT has raised significant network security concerns. In particular, the lightweight and non-standardized characteristics of MQTT traffic, coupled with the continuous evolution of attack techniques, have exposed the limitations of existing Intrusion Detection Systems(IDS) in effectively detecting such traffic. This study proposes a method for generating MQTT data capable of evading IDS detection by leveraging Generative AI, specifically Generative Pre-trained Transformers(GPT), to enhance IDS detection performance. By training a GPT model on preprocessed normal MQTT data, malicious MQTT data were merged and synthesized to create datasets capable of bypassing IDS detection. The generated data are expected to facilitate the analysis of IDS vulnerabilities and contribute to improving detection performance through the enhancement of training data and model design."
생성형 AI 기반의 화재 통계 비정형 데이터 분석에 관한 연구,2024,"['Generative AI', 'Big data analytics', 'Unstructured data', 'Natural language understanding']","화재 발생 시 해당 사건에 대해 현장의 전반적인 개요가 작성되며, 작성자에 따라 용어나 문장 구성 등이다양한 형식의 비정형 형태로 기록된다. 이러한 비정형 텍스트를 분석하기 위해 생성형 AI를 활용하였으며,발화요인을 자동으로 분류하기 위한 연구를 수행하였다.연구에 활용한 데이터는 한 해 동안 발생한 화재의 데이터를 활용하였고, 개인정보는 비식별화된 데이터를활용하였다. 화재가 발생한 월과 화재 유형, 화재 개요 데이터를 활용하여 발화요인을 11가지로 분류하였다.본 연구의 목적은 화재 개요와 여러 통계 데이터를 활용하여 발화요인을 예측하는 것이지만, 궁극적으로는생성형 AI를 활용하여 각자의 스타일로 작성된 화재 개요 문장을 정형화 및 획일화하여 효율적으로 AI를활용하는 것에 있다.생성형 AI는 발화요인이 11가지인 다중분류 방식으로 접근하였고, 분류 모델은 페이스북의 RoBERTa를활용하였다. 트랜스포머의 인코딩을 활용한 BERT 계열의 모델은 주어진 문장의 내용을 이해하기에 적합한모델로, 입력 텍스트 데이터를 활용하여 결과를 추론할 수 있는 모델이다. 발화요인을 분류하기 위한 기본형태로, 화재 개요 텍스트와 발화요인으로 학습데이터를 구성하였고, 분류 성능을 향상시키기 위해 화재 개요에 화재 발생 월과 화재 유형을 추가한 학습데이터를 사용하였다. 학습 데이터는 학습:검증:테스트를 8:1:1로구성하였으며, 노이즈 데이터를 제외한 총 40,000여 건의 데이터를 학습하였다. 모델의 최대 길이(max_seq)는512이며, 학습 횟수(epochs)는 모두 16회를 수행하였다.실험 결과로, 화재 개요만 활용하여 발화요인을 예측하였을 때, 테스트 정밀도(Accuracy)는 47.66%였다.화재 발생 월과 화재 유형을 추가하였을 경우, 테스트 정밀도는 75.83%로 발화요인 예측 정확도가 향상되었다.화재 개요에 직접적으로 발화요인이 언급되지 않았음에도 발화요인에 영향을 주는 요소들을 학습하여 분류한것으로 예측된다. 또한 월별, 유형별에 따라 자주 발생하는 발화요인이 있기 때문에, 해당 데이터를 추가로학습했을 때 정밀도가 향상된 것으로 추정된다.본 연구로 발화요인 분류에 도움이 되는 데이터를 추가할 경우, 생성형 AI의 분류 성능이 향상되는 것을확인하였다. 본 연구를 기반으로, 향후 화재감식반에 대한 추가적인 교육이나 시스템이 없어도, 생성형 AI를통해 화재 개요를 정형화된 형태로 자동 교정하기 위한 연구를 수행하고자 한다.",다국어 초록 정보 없음
수체 추출을 위한 Geo-SAM 기법의 응용: 국토위성영상 적용 실험,2024,[],"Meta에서 신속한 영상 분할 기능을 제공하는 대규모 컴퓨터 비전 생성 모델을 발표한 이후, 여러 활용 분야에서 이를 적용하려는 연구가 이루어지고 있다. 이 연구에서는 위성 영상 자료에 Segment Anything Model (SAM)을 사용할 수 있는 QGIS 플러그인 Geo-SAM을 사용하여 수체 객체 탐지와 추출에 대한 SAM의 적용성을 조사해 보고자 하였다. 실험 대상 자료는 국토위성(Compact Advanced Satellite 500, CAS500-1) 영상을 사용하였다. 이 자료를 가지고 SAM을 적용하여 얻은 결과는 같은 입력 영상으로부터 수작업으로 제작한 수체 객체 자료, Open Street Map (OSM)의 수체 자료, 국토지리정보원의 수계 수치지도와 비교하였다. SAM 처리 결과와 비교 대상 자료를 이용하여 추출된 모든 객체를 대상으로 계산한 경계사각형의 교집합/합집합의 평균값을 나타내는 mean Intersection over Union (mIoU)은 각각 0.7490, 0.5905, 0.4921로 나타났고, 각 자료에서 공통으로 나타나거나 추출된 객체에 대해 계산한 결과는 차례대로 0.9189, 0.8779, 0.7715로 나타났다. SAM을 적용한 결과와 다른 비교 자료와의 공간적 일치도를 분석한 결과, SAM에서는 한 개의 수체 객체를 여러 개의 분할 요소로 나타내므로 수체 객체 분류를 지원하는 의미 있는 결과를 보이고 있음을 알 수 있다.","Since the release of Meta's Segment Anything Model (SAM), a large-scale vision transformer generation model with rapid image segmentation capabilities, several studies have been conducted to apply this technology in various fields. In this study, we aimed to investigate the applicability of SAM for water bodies detection and extraction using the QGIS Geo-SAM plugin, which enables the use of SAM with satellite imagery. The experimental data consisted of Compact Advanced Satellite 500 (CAS500)-1 images. The results obtained by applying SAM to these data were compared with manually digitized water objects, Open Street Map (OSM), and water body data from the National Geographic Information Institute (NGII)-based hydrological digital map. The mean Intersection over Union (mIoU) calculated for all features extracted using SAM and these three-comparison data were 0.7490, 0.5905, and 0.4921, respectively. For features commonly appeared or extracted in all datasets, the results were 0.9189, 0.8779, and 0.7715, respectively. Based on analysis of the spatial consistency between SAM results and other comparison data, SAM showed limitations in detecting small-scale or poorly defined streams but provided meaningful segmentation results for water body classification."
심층 신경망을 사용한 누운 얼굴 감지 기법,2024,"['딥러닝', '얼굴 인식', '영상 분류', '컴퓨터 비전.', 'Computer vision', 'deep learning', 'face recognition', 'image classification.']","본 연구에서는 사람의 얼굴 영상을 활용하여 누워있는지 여부를 판별하는 딥러닝 모델을 개발하였다. 우리는 YouTube 동영상을 통해 새로운 데이터셋을 구축하였으며, 서로 다른 42개의 동영상으로부터 819장의 레이블된 얼굴 영상을 확보하였다. 이 데이터셋을 이용해 사전 학습된 Swin Transformer를 이진 분류 문제에 맞게 미세 조정하였다. 이 모델은 테스트 데이터셋에 대해 96.3%의 정확도를 보였고 공개 데이터셋의 다국적 얼굴을 눕지 않은 얼굴로 가정한 실험에서 72.7% 재현율을 보였다. 또한, 우리는 제안된 방법을 기반으로 한 실시간 애플리케이션을 개발하여 실제 환경에서의 정확성을 확인하였다. 본 연구의 결과는 얼굴 영상만을 이용해 스마트폰 알람 앱에서 사용자의 일어난 상태를 감지하거나 VR 기기 사용자의 상태 감지 기능 등에 활용될 것으로 기대된다.","We introduced a neural network to detect a lying-down person from facial images. We constructed a new dataset through YouTube videos, obtaining 819 labeled facial images from 42 different video clips. We fine-tuned a pre-trained Swin Transformer using this dataset for binary classification. Our model achieves 96.3\% accuracy on the proposed test set and 72.7% recall rate on an existing large-scale face dataset. In addition, we developed a real-time application based on the proposed approach to evaluate its accuracy in real-world scenarios. The results of this paper have the potential to find applications across various domains, such as detecting a user's wakefulness in smartphone alarm applications or monitoring the user's state while wearing a virtual reality device, solely using facial images."
Blurry 클래스 증분 학습 환경에서의 효율적인 프롬프트 학습 방법,2024,"['연속 학습', 'Blurry 클래스 증분 학습', '프롬프트 기반 증분 학습', '비전 트랜스포머', 'continual learning', 'blurry-class incremental learning', 'prompt-based incremental learning', 'Vision Transformer']","연속 학습은 일련의 태스크로 구성된 데이터를 연속적으로 학습하면서 성능을 유지하는 것을 목표로 한다. 보편적 시나리오인 태스크 간 클래스가 겹치지 않는 disjoint 연속 학습과는 달리, blurry 연속 학습은 태스크 간 클래스가 겹치는 보다 현실적인 시나리오를 다룬다. 기존 대부분의 연속 학습 연구는 disjoint 시나리오에 초점을 맞추어 진행되어 왔고, 최근에는 ViT(Vision Transformer) 모델에 프롬프트 메커니즘을 적용하는 프롬프트 기반 연속 학습이 많은 관심을 받고 있다. 본 논문에서는 프롬프트 기반 연속 학습 방법을 기반으로 blurry 클래스 증분 학습에 적합한 유사도 함수를 적용시킴으로써 실험을 통해 그 성능을 분석한다. 이를 통해 우리의 방법이 더 효율적으로 blurry 데이터를 학습하는 것을 입증하면서 우수성을 확인한다.","Continual learning is the process of continuously integrating new knowledge to maintain performance across a sequence of tasks. While disjoint continual learning, which assumes no overlap between classes across tasks, blurry continual learning addresses more realistic scenarios where overlaps do exist. Traditionally, most related works have predominantly focused on disjoint scenarios and recent attention has shifted towards prompt-based continual learning. This approach uses prompt mechanism within a Vision Transformer (ViT) model to improve adaptability. In this study, we analyze the effectiveness of a similarity function designed for blurry class incremental learning, applied within a prompt-based continual learning framework. Our experiments demonstrate the success of this method, particularly in its superior ability to learn from and interpret blurry data."
시공간 그래프 랜덤워크를 활용한 비디오 의미구조 이해,2024,"['video understanding', 'compositional learning', 'spatiotemporal graph', 'random walk', 'semantic unit', '비디오 이해', '구성적 학습', '시공간 그래프', '랜덤워크', '의미단위']","긴 비디오 이해는 비디오 내 다양한 의미단위들을 찾고, 이들 간 복잡한 관계 해석에 초점을 맞춘다. 기존 방식은 합성곱 신경망이나 transformer 기반 모델을 활용하여 짧은 클립들에 대한 문맥정보를 인코딩하고, 이들 간의 시간적 관계를 고려한다. 그러나 해당 방식으로는 비디오 내부에 존재하는 의미 단위들간 복잡한 관계 포착이 어렵다. 본 논문에서는 이러한 의미단위들 간 관계를 명시적으로 표현하기 위해 객체를 정점, 객체들 간 시공간 관계를 간선으로 하는 시공간 그래프로 비디오 입력을 재표현한다. 또한, 해당 그래프에서 시공간 랜덤워크를 통해 얻은 고차원적 의미관계(high-order relationship) 정보를 활용하여, 주요 의미단위를 더 작은 단위들의 구성으로 표현하는 새로운 방법을 제안한다. 다양한 물체들의 복잡한 행동에 관련된 비디오 데이터셋 CATER를 활용한 실험으로, 제안하는 방식이 효과적인 의미단위 포착능력을 가짐을 입증하였다.","Understanding a long video focuses on finding various semantic units present in the video and interpreting complex relationships among them. Conventional approaches utilize models based on CNNs or transformers to encode contextual information for short clips and then consider temporal relationships among them. However, such approaches struggle to capture complex relationships among smaller semantic units within video clips. In this paper, we present video inputs using a spatiotemporal graph with objects as vertices and relative space-time information between objects as edges, to explicitly express relationships among these semantic units. Additionally, we proposed a novel method to represent major semantic units as compositions of smaller units using high-order relationship information obtained by spatiotemporal random walks on the graph. Through experiments on CATER dataset, which involved complex actions of multiple objects, we demonstrated that our approach exhibited effective semantic unit capturing capabilities."
CCTV 관제 업무의 효율성 강화를 위한 LLVM 기반 영상 정보의 텍스트 변환과 지능형 검색 시스템,2024,[],"본 연구는 관제 상황에서 취득한 영상 정보를 LLVM 기술을 사용하여 텍스트로 변환 및 데이터베이스에 저장함으로써, 관제 업무의 효율성을 향상하는 것을 목표로 한다. Human Falling Detection and Tracking 모델을 이용해 새로 등장하는 객체 감지 및 이상 행동을 식별하고, LLVM 기반의 Scene Recognition 모델로 상황을 텍스트로 설명하였다. 텍스트로 설명된 영상 정보를 Transformer의 Summarization 모델로 가독성을 높이기 위해 요약해 주었다. 또한 Elasticsearch 기술을 사용하여 텍스트화된 정보를 신속하게 검색할 수 있도록 함으로써, 소수 인력으로도 효과적인 관제 운용을 가능하게 할 것으로 기대한다.",다국어 초록 정보 없음
생성형 AI 연대기적 고찰,2024,"['생성형 AI', 'NLP', 'LSTM', '딥러닝', 'GAN', 'BERT', 'ChatGPT', 'Generative AI', 'NLP', 'LSTM', 'Deep learning', 'GAN', 'BERT', 'ChatGPT']","이 논문에서는 생성형 인공지능(AI)의 시작부터 현재까지의 발전 과정을 포괄적이고 연대기적으로 설명한다. 주된 요소와 핵심 기술을 자세히 살펴봄으로써 신경망 설계, 언어 모델 개발, 이미지 생성 기술에서 중요한 이정표를 발견하는 등 생성형 AI 기술의 진화를 추적한다. 1950년대의 기초 이론부터 2010년대 생성적 적대 신경망(GAN)과 트랜스포머 모델과 같은 획기적인 혁신에 이르기까지, 단순한 패턴 인식부터 복잡한 자연어 처리 등 AI 기능의 기하급수적인 성장과 그 응용 범위의 확장에 대해 살펴보았다. 방법론적으로는 선행연구와 생성형 AI의 근간을 형성한 주요 기술 혁신을 연대기적으로 분석하는 방식을 사용했다. 다양한 산업에 대한 AI의 영향, 윤리적 고려 사항 및 미래의 기술적 잠재력에 초점을 두고 분석되었다. 그 결과, 생성형 AI는 계산 효율성과 창의성을 크게 향상시켰지만 윤리적 딜레마와 막대한 계산 자원의 필요성과 같은 과제도 제기하고 있음을 보여주었다. 결론에서는 생성형 AI의 미래에 대해 논의하고 강력한 윤리적 기준과 균형을 이루는 지속적인 혁신이 필요하다는 점을 시사한다. 이 연구는 역사적 궤적뿐만 아니라 정책 입안자, 개발자, 학계가 생성형 AI의 잠재적 발전가능성을 극대화하면서 위험을 완화할 수 있는 방법을 모색하도록 촉구한다는 점에서 중요한 의미를 갖는다.","This paper provides a comprehensive and chronological account of the development of generative Artificial Intelligence (AI) from its inception to the present day. Through a detailed examination of key advances and key technologies, it traces the evolution of generative AI technology, uncovering important milestones in neural network design, language model development, and image generation techniques. Beginning with foundational theories in the 1950s and ending with breakthrough innovations such as Generative Adversarial Neural Networks (GANs) and transformer models in the 2010s, it examines the exponential growth of AI capabilities and the expansion of its range of applications, from simple pattern recognition to complex natural language processing and beyond. Methodologically, it uses a chronological analysis with a matching of seminal papers and major technological innovations that have shaped the landscape of generative AI. The implications of these developments are critically analyzed, focusing on the impact of AI on different industries, ethical considerations, and future technological potential. The results show that generative AI has greatly improved computational efficiency and creativity but also poses challenges, such as ethical dilemmas and the need for enormous computational resources. The conclusion discusses the future of generative AI and suggests that it will require continued innovation balanced with strong ethical standards. This study is significant not only for its historical trajectory but also for its call to action for policymakers, developers, and academics to find ways to mitigate the risks while converging on the benefits of generative AI."
‘AI-춘향 캐릭터’ 프로토타입 구축을 위한 시론,2024,"['AI 춘향 캐릭터', '춘향이 챗봇', '생성형 AI', '챗GPT', '춘향전', '문화콘텐츠', '프로토타입', 'AI Chunhyang character', 'Chunhyang Chatbot', 'Generative AI', 'ChatGPT', 'Chunhyangjeon (春香傳)', 'cultural content', 'prototype']","본고에서는 고소설 가운데 이본(異本)이 가장 많은 󰡔춘향전󰡕을 대상으로 생성형 AI 챗GPT를 활용한 ‘AI 춘향 캐릭터’의 프로토타입 구축을 시도하였다. 이를 위해 생성형 인공지능으로 대화형 AI에 속하는 OPENAI의 ChatGPT(Generative Pre-trained Transformer)에 주목하여 챗GPT에 󰡔춘향전󰡕의 스토리를 입힌 ‘AI 춘향 캐릭터’를 만들었다. 그리하여 사용자와 ‘AI 춘향 캐릭터’와의 실시간 대화 모델을 구현할 수 있었다.먼저, 문자와 음성을 이용한 ‘AI 춘향 챗봇’ 프로토타입은 <춘향이 챗봇>과 <춘향이 챗봇2>로 모두 GPT4.0을 이용하였다. 󰡔춘향전󰡕 속 춘향 캐릭터를 잃지 않으면서도, 현대 사용자와의 대화를 원활하게 이어나갈 수 있게 하였다. 특히, <춘향이 챗봇2>는 OpenAI Assistants를 이용하여 차별화를 두었다.다음으로 3D 캐릭터를 이용한 ‘AI 춘향 챗봇’ 프로토타입으로 <결혼 후 춘향 챗봇>과 ‘<춘향이 챗봇>의 3D 캐릭터 버전’을 구현하였다. 챗GPT3.5의 환각현상으로 인한 거짓 정보 생산 가능성을 차단하고 환각 현상을 오히려 긍정적으로 활성화시켰고, 춘향전 스토리를 기반으로 대화를 이어나갈 수 있도록 2개의 챗봇을 복합 적용하였다.본 연구에서 시도한 ‘AI 춘향 캐릭터’ 프로토타입 개발은 고소설의 문화콘텐츠화에 이바지할 수 있는 가치 있는 연구가 될 것이다.","This study attempts to develop a prototype of an ‘AI Chunhyang Character’ using Generative AI, specifically ChatGPT, focusing on “Chunhyangjeon (春香傳)”, the Korean classic novel with the most variants. By utilizing OpenAI’s ChatGPT (Generative Pre-trained Transformer), which belongs to the category of conversational AI, we created an ‘AI Chunhyang Character’ that incorporates the story of “Chunhyangjeon”. This enabled the implementation of a real-time conversation model between users and the ‘AI Chunhyang Character.’ Initially, the text- and voice-based ‘AI Chunhyang Chatbot’ prototypes, named “Chunhyang Chatbot” and “Chunhyang Chatbot 2”, were developed using GPT-4.0. These prototypes maintain the integrity of the Chunhyang character from “Chunhyangjeon” while facilitating smooth communication with modern users. Notably, “Chunhyang Chatbot 2” was differentiated by leveraging OpenAI Assistants.Subsequently, a 3D character-based ‘AI Chunhyang Chatbot’ prototype was developed, including “Post-Marriage Chunhyang Chatbot” and the 3D character version of “Chunhyang Chatbot”. By addressing and positively harnessing the hallucination phenomenon of ChatGPT-3.5, which could otherwise lead to the generation of false information, these chatbots were designed to continue conversations based on the “Chunhyangjeon” story.The development of the ‘AI Chunhyang Character’ prototype in this study represents valuable research that can contribute to the cultural contentization of classic novels."
와전류 기법을 이용한 EV용 헤어핀 코일 기계적 물성 예측 시스템 개발,2024,"['헤어핀 코일', '와전류', '소성변형률', '항복강도', 'Hairpin Coil', 'Eddy Current', 'Plastic Strain', 'Yield Strength']","본 연구에서는 와전류 기반 측정 시스템을 개발하여 헤어핀 코일의 기계적 물성인 소성변형률과 항복강도를 예측하였다. 헤어핀 코일 내부에 와전류가 안정적으로 생성되도록 드라이브와 픽업 코일을 설계하였고, 기계적 물성을 예측하기 위해 와전류로부터 변화된 코일의 임피던스를 키르히호프 전압 법칙과 간략화된 변압기 모델을 바탕으로 수식화하였다. 소성변형률이 다른 헤어핀 코일을 이용하여 임피던스 위상과 소성변형률 간 관계를 실험적으로 확인하고 예측식을 수립하였다. 항복강도는 인장시험으로부터 확보된 modified Hockett-Sherby 재료모델에 예측된 소성변형률을 대입하여 계산하였다. 평탄화 공정을 통과한 샘플을 대상으로 와전류 실험을 한 결과 10% 오차 이내로 인장시험값과 일치하는 것으로 나타났다. 이를 통해 본 연구의 와전류 기반 기법이 헤어핀 코일의 기계적 물성 예측에 효과적으로 활용될 수 있음을 검증하였다.","In this study, we developed an eddy current measurement system to predict the mechanical properties of hairpin coils. To ensure stable current generation within the hairpin coil, drive and pickup coils were designed. To predict mechanical properties, impedance changes in the coil owing to eddy current was formulated using Kirchhoff's voltage law and a simplified transformer model. Using hairpin coils with varying plastic strains, the relationship between impedance phase and ductility was experimentally verified. Yield strength was calculated by substituting the predicted plastic strain, obtained from impedance phase change, into a modified Hockett–Sherby material model derived from tensile tests. The results of eddy current-based yield strength prediction on leveled samples demonstrated a match within a 10% margin of error with tensile test values. This validated the effectiveness of the eddy current-based technique in predicting the mechanical properties of hairpin coils."
오픈 데이터를 이용한 음성 데이터 파이프라인 설계,2024,[],"본 논문에서는 공개된 영상 데이터를 이용하여 음성 합성 기술 학습에 사용할 수 있는 데이터셋을 구성하는 파이프라인을 제안한다. 음성 데이터셋 구성을 위하여 음성 콘텐츠의 특징 및 전사 정보를 획득하기 위해 AST (Audio Spectrogram Transformer), Whisper 등의 딥러닝 모델을 활용하고, 문장 단위의 데이터셋 구성을 위해 구두점과 종결 어미를 이용한 양 방향 탐색 알고리즘을 제안한다. 제안된 오디오 데이터 파이프라인을 통해 획득된 데이터의 유효성을 확인하기 위해 데이터 분할 정확도를 측정하고 구성된 데이터셋을 이용해 딥러닝 기반의 음성 합성 엔진을 학습하여 품질을 확인한다.",다국어 초록 정보 없음
학습 기반 방법을 활용한 건축 평면도의 구성 요소 추출,2024,[],"본 논문에서는 임의의 평면도에 대해 방, 벽, 문 등의 구성요소를 의미론적 정보로 추출하는 방법을 제안한다. 일반적으로 평면도는 방의 모양과 종류, 벽의 형태, 문의 위치 등 다양한 의미론적 정보가 포함되어 있다. 그러나 평면도가 일반화 되어 있지 않고 구성요소의 의미론적 정보가 부족하여 학습 기반의 방법을 적용함에 어려움이 있다. 이를 해결하기 위해 CNN 기반의 방법을 이용할 수 있으나 평면도의 구조적 특성상 어렵다. 제안하는 방법은 이러한 문제를 해결하기 위해 트랜스포머 기반의 모델을 기반으로 의미론적 추론을 진행하고, 추론된 정보를 기반으로 규칙 기반 알고리즘을 통해 입력 평면도에 대한 구성요소의 의미론적 정보를 상세히 추출한다. 해당 방법은 다양한 형태의 평면도 데이터에 잘 동작하였다. 또한 평면도의 구성요소의 의미론적 정보를 데이터화 하는 것으로 추후 학습 기반의 방법론에 활용될 수 있다.",다국어 초록 정보 없음
수능 킬러문항 배제에 대한 감성분석: 교육 소비자로서의 학부모 댓글을 통한 정책 반응 평가,2024,"['comments', 'internet public opinion', 'education policy', 'sentiment ananlysis', 'deep learning', '댓글', '인터넷 여론', '대입정책', '감성분석', '딥러닝']","본고는 교육부의 수능 출제 방향 변경, 즉 “킬러문항 배제” 정책에 대한 학부모들의 여론이 인터넷 댓글에서 어떻게 형성되었는지를 분석하였다. 학부모들은 사교육의 소비자로서 네이버와 같은 온라인 커뮤니티에 가입하여 교육 콘텐츠를 소비함과 동시에 교육정책에 대한 의견도 활발하게 공유할 수 있다. 특히, 대입수능정책과 관련된 게시글에 대해 학부모들은 댓글을 통해 즉각 반응할 수 있으며 이러한 여과없는 텍스트자료는 정책에 대한 소비자의 반응을 살펴볼 수 있는 중요한 자료이다. 본고에서는 네이버에서 “킬러문항 배제”로 검색하였을 때 결과물로 나타나는 교육 관련 카페에서 해당 게시글에 달린 댓글을 수집하여 트랜스포머 모델을 학습하고, 학부모들의 감정을 “불안”과 “안도”로 분류하는 감성분류기를 구축하였다. 이를 통해 킬러문항에 대한 입시정책 변화에 대한 학부모들의 반응을 분석한 결과 전체 댓글 4,098건의 37.5%가 “불안”한 의견을 나타냈으며, 수능 정책과 무관한 댓글을 제외할 경우, 1,576건의 댓글 중 “불안”한 의견의 비율은 97.5%에 달했다. 이 결과는 킬러문항 배제라는 정책적 변화가 학부모들을 안심시킬 것이라는 정책적 기대와 달리 정책 변경이 오히려 불안을 증대시키고 있음을 시사한다. 이는 교육정책뿐만 아니라, 정부의 정책 수립과 변경에서 예측가능성과 신뢰가 바탕되어야 한다는 중요한 시사점을 제공한다. 따라서, 교육정책이 학부모와 학생들의 심리적 반응에 미치는 영향을 더 심도 있게 고려할 필요가 있음을 제언한다.","This study analyzes how parental opinions on the Ministry of Education's policy change regarding the College Scholastic Ability Test (CSAT) - specifically, the exclusion of “killer questions” - are formed through internet comments. Online content related to CSAT policies is easily accessible to the public, and opinions on such matters are freely expressed through comments. Therefore, comments on relevant news articles and posts can be considered an important source of parental opinions. In this study, comments from a Naver education-related forum were collected and used to train a transformer-based model, which classified parents' emotions into “anxiety” and ‘relief.“ The analysis of reactions to the killer question exclusion policy revealed that 37.5% of all comments expressed ”anxiety,“ and when excluding comments unrelated to the CSAT policy, the proportion of anxious comments increased to 97.5%. These results suggest that, contrary to the policy's aim of reassuring parents, frequent policy changes have instead heightened their anxiety. This study highlights the need for government policies, including educational reforms, to be formulated and adjusted in a manner that is predictable and based on public trust."
의사 참조 이미지를 활용한 무참조 이미지 화질 평가,2024,"['Image quality assessment', 'Perceptual quality', 'Pseudo-reference image', 'Scale-invariant distortion', 'Quality score regressor']","무참조 이미지 화질 평가(no-reference image quality assessment; NR-IQA)는 참조 영상에 대한 정보가 주어지지 않은 상태에서 인간 시각 체계를 반영하여 이미지 화질 저하 수준을 객관적으로 정량화 하는 것을 목표로 한다. 기존 NR-IQA 기술은 특정 왜곡 특성에 대해 높은 민감성을 갖고 있으며, 의미론적 화질 인지 및 화질 저하 수준을 판단하기에는 한계를 지니고 있다. 본 논문에서는 기존 NR-IQA 접근 방식의 한계를 극복하고 예측 정확도를 향상시키기 위해 지역적 왜곡 패턴 추출과 고수준 의미 정보 추출에 보다 능숙한 완전 참조 (full-reference IQA; FR-IQA) 방식의 프레임워크를 따르는 NR-IQA 모델인 multi-scale pseudo image quality assessor(MPIQ)를 제안한다. 제안하는 MPIQ는 하이브리드 구조에 기반해 합성곱 네트워크를 통한 지역적 왜곡 패턴 추출과 트랜스포머 기반의 전역적 화질 수준 이해를 도모하며, 의사 참조 이미지 reconstructor와 quasi FR-IQA regressor라는 두 가지 모듈로 구성된다. 의사 참조 이미지 reconstructor는 FR-IQA 방식과 유사하게 화질 추론 모델이 동작할 수 있도록 인코더-디코더 구조를 차용하여 의사 참조 이미지를 재구성하고 이미지 왜곡 정보를 학습한다. 이 과정에서 크기 불변 왜곡 패턴의 추출을 위해 다중 스케일 구조를 반영하였다. Quasi FR-IQA regressor는 왜곡 이미지에서 추출된 특징과 의사 참조 이미지 특징의 차이를 통해 전역적 왜곡 수준을 도출함으로써 이미지 화질 수준을 최종적으로 예측한다. MPIQ는 주관적 평가를 통해 획득된 mean opinion score에 end-to-end로 학습되었으며, 실험 결과 기존 NR-IQA 기술 대비 20%의 성능 향상을 달성하였다.","No-reference image quality assessment (NR-IQA) aims to objectively quantify the level of image quality degradation by reflecting the human visual system in the absence of information about the pristine image. Existing NR-IQA techniques have high sensitivity to specific distortion types, but have limitations in determining semantic quality information or global image quality degradation. In this paper, to resolve the limitations of existing NR-IQA approaches and improve predictive power, we propose a multi-scale pseudo image quality assessor (MPIQ). MPIQ is an NR-IQA model that follows the framework of full-reference IQA (FR-IQA), which is more proficient in extracting local distortion patterns and aggregating higher-level perceptual quality information. The proposed MPIQ employs a hybrid scheme that seeks to understand local distortion patterns through the convolutional neural networks and global level of image quality based on transformers, and consists of two modules: a pseudo-reference image reconstructor and a quasi FR-IQA regressor. Similar to the FR-IQA approach, the pseudo-reference image reconstructor utilizes an encoder-decoder structure to reconstruct the pseudo-reference image and learn image degradation information compared to a distorted one. Here, a multi-scale structure is reflected to extract scale-invariant distortion patterns. Quasi FR-IQA regressor predicts the image quality score by deriving the global distortion level through the difference between the features extracted from the distorted and the pseudo-reference images. MPIQ was supervised onto the mean opinion score obtained through subjective evaluation in an end-to-end manner, and experimental results showed a 20% performance improvement compared to the existing NR-IQA."
스미스 차트를 이용한 구리 인터커텍트의 비파괴적 부식도 평가,2024,"['Artificial intelligence', 'Cu interconnects', 'Corrosion', 'Non-destructive evaluation', 'Smith chart', '.']","전자패키지 내부의 부식이 시스템 성능 및 신뢰성에 큰 영향을 미치고 있어, 시스템 건전성 관리를 위해 부식에대한 비파괴적 진단 기법의 필요성이 커지고 있다. 본 연구에서는 복소 임피던스의 크기와 위상을 통합적으로 시각화하는도구인 스미스 차트를 활용하여, 구리 인터커넥트의 부식을 비파괴적으로 평가하는 방법을 제시하고자 한다. 실험을 위해구리 전송선을 모사한 시편을 제작하고, MIL-STD-810G 기준 온습도 사이클에 노출시켜 시편에 부식을 인가하였다. R 채널 기반 색변화로 시편의 부식도를 정량적으로 평가하고 레이블링 하였다. 부식의 성장에 따라 시편의 S-파라미터와 스미스 차트를 측정한 결과, 5 단계의 부식도에 따라 유의미한 패턴의 변화가 관찰되어, 스미스 차트가 부식도 평가에 효과적인 도구임을 확인하였다. 더 나아가 데이터 증강을 통해 다양한 부식도를 갖는 4,444개의 스미스 차트를 확보하여, 스미스차트를 입력 받아 구리 인터커넥트의 부식 단계를 출력하는 인공지능 모델을 학습시켰다. 이미지 분류에 특화된 CNN 및Transfomrer 모델을 적용한 결과, ConvNeXt 모델이 정확도 89 .4%로 가장 높은 부식 진단 성능을 보였다. 스미스 차트를이용하여 전자패키지 내부 부식을 진단할 경우, 전자신호를 이용하는 비파괴적 평가를 수행할 수 있다. 또한. 신호 크기와위상 정보를 통합적으로 시각화 하여 직관적이며 노이즈에 강건한 진단이 가능할 것으로 기대한다.","Corrosion inside electronic packages significantly impacts the system performance and reliability, necessitating non-destructive diagnostic techniques for system health management. This study aims to present a non-destructive method for assessing corrosion in copper interconnects using the Smith chart, a tool that integrates the magnitude and phase of complex impedance for visualization. For the experiment, specimens simulating copper transmission lines were subjected to temperature and humidity cycles according to the MIL-STD-810G standard to induce corrosion. The corrosion level of the specimen was quantitatively assessed and labeled based on color changes in the R channel. S-parameters and Smith charts with progressing corrosion stages showed unique patterns corresponding to five levels of corrosion, confirming the effectiveness of the Smith chart as a tool for corrosion assessment. Furthermore, by employing data augmentation, 4,444 Smith charts representing various corrosion levels were obtained, and artificial intelligence models were trained to output the corrosion stages of copper interconnects based on the input Smith charts. Among image classification-specialized CNN and Transformer models, the ConvNeXt model achieved the highest diagnostic performance with an accuracy of 89.4%.When diagnosing the corrosion using the Smith chart, it is possible to perform a non-destructive evaluation using electronic signals. Additionally, by integrating and visualizing signal magnitude and phase information, it is expected to perform an intuitive and noise-robust diagnosis."
T5-GPT 간 상징적 증류 지식 활용 프롬프트 엔지니어링,2024,"['생성형 언어모델', '상징적 지식 증류', '프롬프트 엔지니어링', '데이터 생성', '사전학습', '트랜스포머', 'generative language model', '. symbolic knowledge distillation', 'prompt engineering', 'data generation', 'pre-training', 'Transformer']",국문 초록 정보 없음,"This study proposes a prompt engineering method for 'Cross-model Symbolic Knowledge Distillation' of generative natural language models (LM)s. Our approach defines the text outputs generated from the generative LMs’ reasoning for a specific downstream task as the 'Symbolic Distilled Knowledge (SDK)'. We aim to improve the reasoning abilities of each generative LM for downstream tasks by training each model in such a way that leverages the SDK from the counterpart model, with the goal of minimizing human labor. We implemented our approach using GPT-J and T5, which differ in model structure and parameter scale. The models that were semi-pretrained by prompting for cross-model symbolic knowledge distillation showed better downstream task performance compared to the baseline. For example, on the SLURP benchmark, which is used for the Intent Classification task, GPT-J-distillated T5 showed an accuracy of 81.95%, which was approximately 10% higher than those achieved by the standard T5 models. T5-distillated GPT-J also showed an accuracy of 29.76% on the SLURP benchmark, representing an improvement of approximately 7.38% over the standard GPT-J."
기업 맞춤형 sLLM 설계,2024,"['sLLM', 'generative AI', 'Transformer', 'Llame', 'Langchain']","급변하고 있는 인공지능의 발전은 사회의 기업 문화형태를 바꾸고 있다. 그 중 LLM(Large Language Model)은 그룹이나 개인에 맞는 지식 접근을 용이하게 하며, 고객에 대한 의사 결정 지원이나 데이터 처리 문서 작성 등 반복적이고 복잡했던 일을 처리해 줌으로 업무의 자동화를 이끌고 있다. 특히, 기업 맞춤형 sLLM(small Large Language Model)은 각 기업에 맞는 LLM을 이용하여 기업에 최적화된 업무처리를 효율적으로 처리하여 정확하고 빠른 의사 결정을 통해 기업의 업무처리에 생산성을 높일 수 있다. 기업 맞춤형 sLLM의 설계는 기업 데이터의 수집과 전처리 과정을 거쳐 토큰화, 단어의 의미를 수치화하는 임베딩 단계를 거쳐 학습모델을 구현하고 훈련과 추론 과정을 거쳐 처리될 수 있도록 한다. 본 논문에서는 기업 맞춤형 sLLM의 설계를 연구하고자 한다. 기업 맞춤형 sLLM은 업무의 효율을 높여 기업의 창의적인 기술 발전을 가져올 뿐 아니라 AI와 상호보완적인 역할을 하며 기업의 가치를 창출할 수 있을 것이다.","The rapid advancement of artificial intelligence is reshaping the corporate cultural landscape, Among these advancements, Large Language Model(LLM) are facilitating easier access to knowledge tailored to groups and individuals, automating tasks that were once repetitive and complex, such as customer support, data processing, and document creation. Particularly, custom enterprise sLLM(small Large Language Model) leverage LLMs optimized for specific businesses to efficiently handle operations tailored to their needs. This enables accurate and swift decision-making, thereby increasing productivity in business processes. The design of custom enterprise sLLM(small Large Language Model) involves several stages: collecting and preprocessing enterprise data, tokenization, embedding to numerically represent word semantics, implementing a learning model, and processing through training and inference stages. This paper aims to explore the design of custom enterprise sLLM. These models not only improve operational efficiency but also foster creative technological advancements within businesses Furthermore, they play a complementary role with AI, contributing to the creation of greater corporate value."
고전력밀도 OBC를 위한 6.6kW Planar 변압기의 머신러닝 기반 최적 설계,2024,"['Multi-objective optimization', 'Planar transformer', 'Machine learning', 'On-board charger']",국문 초록 정보 없음,"This paper proposes an optimal design process for a planar transformer for on-board charger(OBC). As it is difficult to mathematically model the high-frequency copper loss of the transformer, conventional design processes tend to have large errors in designing the transformers. In this paper, geometric parameters of a shell-type planar transformer are identified, and FEA simulations are completed to obtain the copper loss of various shapes of the shell-type planar transformers. Regression models for the copper loss are determined using the simulation results and the machine learning technique. From the regression model, optimal high-frequency transformer designs and Pareto front(in terms of transformer 2-dimensional area and loss) are obtained using NSGA-II. In the Pareto front, a design was selected as a desired optimal, and the selected design was verified by FEA simulation. The simulated copper loss of the selected design matched very well, thus demonstrating the validity of the proposed design process."
중·소규모 건설현장을 위한 GPT와 RAG기반 위험성평가 자동화 방안,2024,"['중소규모 건설현장', '위험성평가', '대규모 언어모델', 'GPT', '검색증강생성', 'small and medium-sized construction sites', 'risk assessment', 'large-scale language model', 'Generative Pre-trained Transformer(GPT)', 'retrieval augmented generation (RAG)']","건설산업의 복잡한 생산구조와 가변적인 현장조건으로 인해 안전사고가 빈번히 발생하며, 특히 중·소규모 건설현장에서 안전관리가 어려운 실정이다. 이를 해결하기 위해 위험성평가는 유해·위험요인을 사전에 파악하고 대책을 수립하는 중요한 과정이지만, 현재의 위험성 평가는 주로 안전관리자의 경험에 의존하고 있어 한계가 있다. 본 연구는 생성형 대규모 언어모델의 한계를 극복하고, 보다 효율적인 위험성평가방법을 제안하는 것을 목표로 한다. 이를 위해 관련 문서를 기반으로 사용자 질문에 맞는 정보를 찾아내는 ‘검색증강생성(RAG; retrieval augmented generation)’ 방식을 도입하여, GPT모델의 성능을 향상 시키고, 보다 구체적이고 전문적인 안전대책을 도출할 수 있음을 확인하였다. 실험결과, 기존 GPT모델만을 사용할 때 보다 작업 특성에 맞는 유해·위험요인을 효과적으로 도출할 수 있었으며, 구체적인 안전대책도 자동 생성할 수 있었다. 이러한 결과를 바탕으로 중·소규모 건설현장에서의 위험성평가자동화시스템을 개발한다면, 전문 안전관리자에 대한 의존도를 줄이고 보다 효율적이고 체계적인 안전관리가 가능할 것으로 기대된다.","The construction industry faces frequent safety accidents due to its complex production structure and variable site conditions, with small and medium-sized construction sites being particularly vulnerable. To address these challenges, risk assessment plays a critical role in identifying hazardous factors in advance and establishing countermeasures. However, current risk assessments rely heavily on the subjective judgment and experience of safety managers, which poses limitations, especially in sites lacking specialized personnel. This study aims to propose a more efficient risk assessment method by overcoming the limitations of large-scale generative language models. By applying Retrieval Augmented Generation (RAG; retrieval augmented generation), which provides relevant documents to the model to generate more accurate answers, we enhanced the performance of the GPT model in deriving specific and expert-level safety measures. The experimental results showed that the RAG approach allowed for the effective identification of hazardous factors tailored to the task characteristics and generated more concrete safety countermeasures compared to using GPT alone. Based on these findings, the development of an automated risk assessment system for small and medium-sized construction sites could reduce reliance on professional safety managers and enable more efficient and systematic safety management."
중·소규모 건설현장을 위한 GPT와 RAG기반 위험성평가 자동화 방안,2024,"['중소규모 건설현장', '위험성평가', '대규모 언어모델', 'GPT', '검색증강생성', 'small and medium-sized construction sites', 'risk assessment', 'large-scale language model', 'Generative Pre-trained Transformer(GPT)', 'retrieval augmented generation (RAG)']","건설산업의 복잡한 생산구조와 가변적인 현장조건으로 인해 안전사고가 빈번히 발생하며, 특히 중·소규모 건설현장에서 안전관리가 어려운 실정이다. 이를 해결하기 위해 위험성평가는 유해·위험요인을 사전에 파악하고 대책을 수립하는 중요한 과정이지만, 현재의 위험성 평가는 주로 안전관리자의 경험에 의존하고 있어 한계가 있다. 본 연구는 생성형 대규모 언어모델의 한계를 극복하고, 보다 효율적인 위험성평가방법을 제안하는 것을 목표로 한다. 이를 위해 관련 문서를 기반으로 사용자 질문에 맞는 정보를 찾아내는 ‘검색증강생성(RAG; retrieval augmented generation)’ 방식을 도입하여, GPT모델의 성능을 향상 시키고, 보다 구체적이고 전문적인 안전대책을 도출할 수 있음을 확인하였다. 실험결과, 기존 GPT모델만을 사용할 때 보다 작업 특성에 맞는 유해·위험요인을 효과적으로 도출할 수 있었으며, 구체적인 안전대책도 자동 생성할 수 있었다. 이러한 결과를 바탕으로 중·소규모 건설현장에서의 위험성평가자동화시스템을 개발한다면, 전문 안전관리자에 대한 의존도를 줄이고 보다 효율적이고 체계적인 안전관리가 가능할 것으로 기대된다.","The construction industry faces frequent safety accidents due to its complex production structure and variable site conditions, with small and medium-sized construction sites being particularly vulnerable. To address these challenges, risk assessment plays a critical role in identifying hazardous factors in advance and establishing countermeasures. However, current risk assessments rely heavily on the subjective judgment and experience of safety managers, which poses limitations, especially in sites lacking specialized personnel. This study aims to propose a more efficient risk assessment method by overcoming the limitations of large-scale generative language models. By applying Retrieval Augmented Generation (RAG; retrieval augmented generation), which provides relevant documents to the model to generate more accurate answers, we enhanced the performance of the GPT model in deriving specific and expert-level safety measures. The experimental results showed that the RAG approach allowed for the effective identification of hazardous factors tailored to the task characteristics and generated more concrete safety countermeasures compared to using GPT alone. Based on these findings, the development of an automated risk assessment system for small and medium-sized construction sites could reduce reliance on professional safety managers and enable more efficient and systematic safety management."
딥러닝과 머신러닝을 통한 당뇨병 데이터 분석,2024,"['Diabetes', 'Classification', 'Machine Learning', 'Deep Learning', 'Ensemble Model', '당뇨병', '분류', '머신러닝', '딥러닝', '앙상블  모델']","당뇨병은 널리 퍼진 만성 질환으로, 세계적으로 영향을 미치고, 경제적으로도 상당한 재정적 부담을 부가하고 있다. 당뇨병은 혈액의 포도당을 조절하는 능력을 저하하고 , 삶의 질과 수명을 감소시킬 수 있는 만성 질환이다. 또한 당뇨병은 인슐린을 생성하지 못하거나, 효과적으로 사용하지 못한다. 당뇨병 문제의 규모는 상대적으로 크지만, 쉽게 인식하지 못한다. 당뇨병을 완치할 수 있는 방법은 없지만 체중 감량, 건강식, 활동적 생활 및 치료를 받는 것과 같은 전략은 많은 환자에서 이 질병의 피해를 완화할 수 있다. 조기 진단은 생활 방식의 변화와 보다 효과적인 치료로 이어진다. 본 연구의 의의는 당뇨병이 있는지 여부에 대한 정확한 예측을 제공하고 당뇨병 위험을 가장 잘 예측하는 위험 요소는 무엇인지 찾는 것이다.  예측에 있어서 여러 가지 머신러닝 기법과 딥러닝의 CNN과 RNN을 통한 Ensemble Model 사용하고, 평가방법으로 Accuracy와 Recall을사용한다. 이 Ensemble Model은 Transformer구조를 따르고자 했고, 경량화하였다.","Diabetes is a widespread chronic disease that affects people worldwide and imposes significant financial burdens. Diabetes impairs the ability to regulate blood glucose levels, reducing quality of life and life expectancy. Additionally, diabetes is characterized by either the inability to produce insulin or to use it effectively. Despite its prevalence, diabetes is often underrecognized. While there is no cure for diabetes, strategies such as weight loss, healthy eating, an active lifestyle, and treatment can mitigate the disease's impact in many patients. Early diagnosis leads to lifestyle changes and more effective treatment. This study aims to provide accurate predictions for diabetes and identify the most significant risk factors for its development. The study employs various machine learning techniques, and  ensemble models using CNN and RNN, with accuracy and recall as evaluation metrics. This Ensemble Model attempted to follow the Transformer structure and made it lightweight."
한국어 생성 요약 성능 평가 지표 분석 연구,2024,"['Natural Language Processing', 'Abstractive Summarization', 'Automatic Metric', 'Transformer', 'Large Language Model', '자연어 처리', '생성 요약', '자동 평가 지표', '트랜스포머', '대규모 언어모델']","본 연구는 한국어 생성 요약의 자동 평가 지표를 분석하고 검증하는 것을 목표로 한다. 언어마다 고유한 특성이 다르므로 각 언어에 적합한 평가지표의 필요성에 따라 한국어에 특화된 연구가 요구된다. 현재 한국어를 대상으로 한 생성 요약 및 메타 평가 연구는 다른 언어에 비해 훨씬 부족한상황이다. 따라서 한국어 생성 요약 데이터를 활용하여 평가 기준 및 문서 유형에 따른 신뢰성 있는 자동 평가 지표를 검증함으로써 향후 생성 요약및 자연어 생성 분야의 한국어 모델 연구에 이바지하고자 한다. 요약 모델 평가 시 공신력 있는 지표로 여겨지는 인간 평가(Human Evaluation)는시간과 비용이 많이 소요되므로 자동 평가 지표 연구는 효율성 측면에서도 중요한 의의가 있다. 10가지 한국어 문서와 참조 요약문, 세 가지 모델(T5,KoBART, GPT-3.5 Turbo) 생성 요약문을 대상으로 유창성, 일관성, 관련성 기준으로 인간 평가와 자동 평가 지표의 상관계수를 산출하였다. 평가기준별 상관 분석 결과, T5 요약문에서는 일관성, 관련성에서 각각 0.33, 0.26, KoBART 요약문에서는 유창성, 관련성에서 0.33, 0.40의 상관계수와함께 BERTScore가 제일 높은 상관관계를 보여 한국어 요약문 평가에 효과적인 지표임을 확인하였다. 한편, 대규모 언어모델인 GPT-3.5 Turbo 요약문은환각 가능성 감지를 위해 개발된 평가 지표 HaRiM+가 일관성, 관련성 측면에서 0.23, 0.17의 유의미한 상관관계를 보였다. 또한, 문서 유형별 상관분석 결과, T5 요약문은 보도자료와 회의록에서 BLEU 지표와 높은 상관관계를 나타냈고, KoBART 요약문은 나레이션 문서에서, GPT-3.5 Turbo요약문은 사설 문서에서 BERTScore와 높은 상관관계를 보였다. 이러한 결과는 특정 문서 유형에 적합한 평가 지표를 선택하는 것이 중요하다는점을 강조한다. 이와 같이, 본 연구는 향후 한국어 요약 연구에서 목표 과제의 목적에 따라 적합한 평가 지표를 선택하는 근거로서 활용할 수 있다.","This study aims to analyze and validate automatic evaluation metrics for Korean abstractive summarization. The unique linguistic characteristicsof each language require evaluation metrics designed for them, underscoring the importance of research focused on Korean. Research onsummarization and its meta-evaluation is extremely limited, especially for Korean. Therefore, by validating reliable automatic evaluationmetrics using Korean summarization data, this study contributes to future research on Korean models in the fields of natural language generation.Human evaluation, widely regarded as the most reliable metric, is time-consuming and costly. Thus, research into automatic evaluation metricsholds significant importance for efficiency. In this study, summaries from three models—T5, KoBART,and GPT-3.5 Turbo—were evaluatedbased on their fluency, consistency, and relevance using 10 Korean documents and their corresponding reference summaries. Correlationcoefficients were calculated between human evaluations and automatic metrics for fluency, consistency, and relevance. The results showedthat for T5 summaries, the correlation coefficients for consistency and relevance were 0.33 and 0.26, respectively, while for KoBART summaries,the coefficients for fluency and relevance were 0.33 and 0.40, respectively. BERTScore demonstrated the highest correlation, indicating itseffectiveness for Korean summaries. Meanwhile, GPT-3.5 Turbo summaries showed significant correlations of 0.23 and 0.17 in consistencyand relevance using HaRiM+, a metric developed to detect hallucinations in recent work. Additionally, the correlation analysis by documenttype revealed that T5 summaries showed high correlations with the BLEU metric for briefing and meeting minutes, KoBART summaries andGPT-3.5 Turbo summaries both demonstrated high correlations with BERTScore for narrative and editorial documents, respectively. Thesefindings emphasize the importance of selecting evaluation metrics tailored to specific document types. Therefore, this study provides a basisfor selecting appropriate evaluation metrics tailored to the objectives of specific tasks in future Korean summarization research."
조화응답해석을 이용한 변압기의 소음저감 방법에 관한 연구,2024,"['조화응답해석', '구조기인소음', '소음저감 방법', '소음 예측', 'Harmonic response analysis', 'Structure borne noise', 'Noise reduction method', 'Noise prediction']","본 연구에서는 변압기 설계에 활용하기 위해 조화응답해석을 이용하여 소음저감 대책에 따른 소음 저감 예측방법을 제안한다. 변압기 부품들의 재질을 간단한 형상의 시편으로 제작하고, 실험과 해석의 모드 비교분석을 통해 실제 변압기를 구성하는 부품들의 동적 탄성계수를 규명하였다. 변압기의 유한요소모델을 구현하고 변압기의 가진력을도출하여 조화응답해석을 수행하였다. 그리고 조화응답해석 결과에서 변압기의 음향파워레벨(Sound power level) 을 이론적으로 도출하였다. 마지막으로 소음저감 대책을 수립하고, 적용 전·후에 따른 실험과 해석의 소음 저감량을비교하였다. 대책별 소음저감 비교분석을 통해 실험과 해석의 경향이 일치하는 것을 확인하였다","This study proposes a method to predict noise reduction based on noise-reduction measures, using harmonic response analysis, for transformer design. The dynamic elastic coefficients of the components comprising the actual transformer were determined by manufacturing the materials of the transformer components into simple-shaped specimens, followed by a comparison of the modes between the experiments and the analyses.A finite element model of the transformer was implemented, and harmonic response analysis was performed by deriving the exciting force of the transformer. Subsequently, the theoretical sound power level of the transformer was derived from the results of the harmonic response analysis. Finally, noise reduction measures were established, and the noise reduction amounts were compared between the experiments and the analyses, before and after applying the measures. Through the comparison and analyses of the noise reduction measures, it was confirmed that the trends in the experiments and analyses matched."
Time-Series Forecasting Based on Multi-Layer Attention Architecture,2024,"['Time-Series Forecasting', 'Attention', 'Cross-attention', 'Deep neural network']",국문 초록 정보 없음,"Time-series forecasting is extensively used in the actual world. Recent research has shown that Transformers with a self-attention mechanism at their core exhibit better performance when dealing with such problems. However, most of the existing Transformer models used for time series prediction use the traditional encoder-decoder architecture, which is complex and leads to low model processing efficiency, thus limiting the ability to mine deep time dependencies by increasing model depth. Secondly, the secondary computational complexity of the self-attention mechanism also increases computational overhead and reduces processing efficiency. To address these issues, the paper designs an efficient multi-layer attention-based time-series forecasting model. This model has the following characteristics: (i) It abandons the traditional encoder-decoder based Transformer architecture and constructs a time series prediction model based on multi-layer attention mechanism, improving the model's ability to mine deep time dependencies. (ii) A cross attention module based on cross attention mechanism was designed to enhance information exchange between historical and predictive sequences. (iii) Applying a recently proposed sparse attention mechanism to our model reduces computational overhead and improves processing efficiency. Experiments on multiple datasets have shown that our model can significantly increase the performance of current advanced Transformer methods in time series forecasting, including LogTrans, Reformer, and Informer."
금융에서의 생성형 인공지능 활용 현황과 법적 쟁점에 대한 연구,2024,"['Finance', 'Generative Artificial Intelligence', 'Deepfakes', 'Automated Decision Making', 'Bias', 'Explainable AI', 'Data Leakage', 'Chatbots', 'Robo-advisors', 'Generative Adversarial Network(GAN)', 'Transformer Model', 'Multi-modal AI.', '금융 / 생성형 인공지능 / 딥페이크 / 자동화된 의사결정 / 편향 / 설명가능한 인공지능 / 데이터 유출 / 챗봇 / 로보어드바이저 / 생성적 적대 신경망 / 변형 자동 인코더 / 트랜스포머 모델 / 다중모드 인공지능']","GPT-3 출시 이래로 생성형 인공지능(이하 ‘AI’)은 전 세계에서 여러 산업 분야에 걸쳐 중요한 기능을 하고 있고 미래의 시장 규모도 빠르게 성장할 것으로 예측된다. 생성형 AI는 금융 분야에서 고객 상담, 고객 투자 관리, 대출 등 위험 관리, 금융회사의 업무 개선에 많은 기여를 하고 있다.생성형 AI에는 생성적 적대 신경망(GAN), 트랜스포머 모델, 다중모드 AI 등이 있다. 위 AI들은 각각의 장․단점을 가지고 있으면서 합성 데이터의 생성, 사기성 거래 등의 구별, 비대면뱅킹, 금융흐름의 예측, 감정 분석, 재무 분석 등에 있어서 탁월한 성능을 발휘한다.그럼에도 금융 분야에서 생성형 AI를 활용함에 있어 몇 가지 법적 문제들이 있을 것으로 예상된다. 여기에는 조작 위험(딥페이크), 금융 안정성의 위험(플래시크래쉬, 금융시스템 리스크), 투자자보호 관련 위험, 데이터 유출 위험, 불공정의 위험(데이터 및 알고리즘 편향, 설명가능한 인공지능, 자동화된 의사결정) 등이 있어 이에 초점을 두고 그 쟁점 및 법적․기술적 해결 방안에 대하여 살펴보았다. 나아가 고객 상담시 투명성 위험, 반경쟁 위험에 관하여도 짚어보았다.","Since the release of GPT-3, generative artificial intelligence (hereinafter referred to as ‘AI’) has played a significant role across various industries worldwide, and the market size is predicted to grow substantially in the future. In the financial sector, generative AI is also bringing about positive changes, contributing significantly to tasks such as customer consultation, customer investment management, risk management including loans, and overall business improvement for financial companies.Generative AI includes Generative Adversarial Networks (GAN), Transformer models, and Multi-modal AI, each having its own strengths and weaknesses. These AIs excel in tasks such as generating synthetic data, distinguishing fraudulent transactions, non-face-to-face banking, predicting financial flows, sentiment analysis, financial analysis, and more.However, despite the positive impacts, there are anticipated legal issues in utilizing generative AI in the financial sector. These include manipulation risks (deepfakes), risks to financial stability (flash crashes, financial system risks), investor protection-related risks, data leakage risks, unfairness risks (data and algorithm bias, explainable AI, automated decision-making), among others. This discussion focuses on these points, examining the key issues and legal and technical solutions. Additionally, transparency risks during customer consultations and risks related to anti-competition are also touched upon."
Software Defect Prediction Based on SAINT,2024,"['Transformer', 'SAINT', 'Software Defect Prediction', '트랜스포머', '소프트웨어 결함 예측']",국문 초록 정보 없음,"Software Defect Prediction (SDP) enhances the efficiency of software development by proactively identifying modules likely to contain errors. A major challenge in SDP is improving prediction performance. Recent research has applied deep learning techniques to the field of SDP, with the SAINT model particularly gaining attention for its outstanding performance in analyzing structured data. This study compares the SAINT model with other leading models (XGBoost, Random Forest, CatBoost) and investigates the latest deep learning techniques applicable to SDP. SAINT consistently demonstrated superior performance, proving effective in improving defect prediction accuracy. These findings highlight the potential of the SAINT model to advance defect prediction methodologies in practical software development scenarios, and were achieved through a rigorous methodology including cross-validation, feature scaling, and comparative analysis."
긴 문서 요약을 위한 문장 분할 기반의 단계적 요약,2024,[],국문 초록 정보 없음,"Transformer based pre-trained language models have shown high performance across various NLP tasks, especially for summarization. However, the limit of input sequence length causes difficulties that only capture the beginning part of documents when such texts exceed the maximum sequence length of the model. This paper proposes a stepwise summarization approach by splitting lengthy documents into pieces, which makes it possible for the model to efficiently summarize long articles by capturing entire context. We fine-tune a BART model on a specific dataset to enhance the quality of summary. The experiment demonstrates that proposed approach has advantages in readability and provides the potential for future abstractive summarization research."
주제 인식 교차 주의를 활용한 대화 요약,2024,"['대화 요약', '트랜스포머', '교차 주의 기법', '주제 분포', 'dialogue summarization', 'transformer', 'cross-attention', 'topic distribution']","대화 요약은 일반적인 문서 요약과는 다르게 비형식적, 구어체의 사용이 많고, 대화의 맥락과 흐름 파악, 대화의 주제들에 대한 고려가 필요하다. 본 연구에서는 이러한 대화의 특성을 반영하기 위해 교차 주의 기법에 주제 분포를 인식할 수 있도록 요소를 추가한 주제 인식 교차 주의 기법을 제안한다. 이 주제 인식 교차 주의 기법은 대화와 요약문의 주제 분포를 추출하여 이 주제 분포의 유사도를 BART 모델 디코더 내부의 교차 주의 기법에 적용하여 대화 요약을 진행한다. 본 연구에서 제안하는 주제 인식 교차 주의 기법은 주제 비율을 조정함으로써 주제 분포의 유사도를 기존 교차 주의 기법에 적용되는 정도를 조절할 수 있으며, DialogSum, SAMSum 데이터셋에서의 실험을 통해 대화 요약에 적절함을 확인할 수 있다.","Unlike general document summarization, dialogue summarization frequently involves informal and colloquial language. It requires an understanding of the context and flow of the dialogue. It also requires consideration of topics. This study proposes a Topic-Aware Cross-Attention mechanism that can incorporate elements to recognize topic distributions into a cross-attention mechanism to reflect characteristics of dialogue. This Topic-Aware Cross-Attention mechanism can extract topic distributions of dialogue and summary and apply the similarity of these distributions to the cross-attention mechanism within BART model’s decoder to perform dialogue summarization. The proposed Topic-Aware Cross-Attention mechanism can adjust application degree of topic distribution similarity to the cross-attention mechanism by modifying topic-ratio. Experimental results on DialogSum and SAMSum datasets demonstrated the suitability of the method for dialogue summarization."
Sequence-to-text 기법을 활용한 언어 모형의 소개 및 분류 성능 비교,2024,"['Attention', 'language model', 'sequence classification', 'transformer.', '시퀀스 분류', '어텐션', '언어 모형', '트랜스포머.']","최근에 활발한 언어 모형의 개발과 함께 많은 분야의 연구자들이 이에 관심을 갖게 되었다. 언어 모형의 사용처는 매우 다양하여 많은 분야에 사용될 수 있다. 전통적인 통계학이나 머신 러닝의 분야에서는 이진 분류에 대한 연구가 활발하게 진행되어 왔고, 언어 모형들 역시 동일한 과제를 수행할 수 있다. 언어 모형의 특징으로 인해 입력 데이터는 테이블 형식의 숫자로 이루어진 데이터가 아니라 문자 형식의 변수를 입력해야 한다. 이 논문에서는 열 가지의 최신 언어 모형들의 목적과 특징들을 소개한다. 한편, 언어 모형의 데이터 입력을 위해 시퀀스 데이터를 텍스트로 변환하는 sequence-to-text 방법의 여러가지 예시를 구체적으로 제시하고, 예제 코드가 담긴 링크도 제공한다.  이를 통해 언어 모형 구현에 경험이 없는 독자들에게는 도움이 될 것으로 기대한다. 마지막으로, 제시한 여러가지 sequence-to-text 방법을 실제 데이터를 이용한 모의 실험을 통하여 이 논문에서 소개하는 최신 언어 모형들의 성능을 비교하고 머신 러닝 모형들의 결과도 함께 제공하여 언어 모형들의 우수한 분류 성능을 확인한다.","Recently, the active development of language models has garnered significant interest from researchers across various fields. The applications of language models are exceedingly diverse, making them suitable for a multitude of domains. In traditional statistics and machine learning, extensive research has been conducted on binary classification, a task that language models can also perform effectively. Due to the inherent characteristics of language models, the input data required is not merely numerical in tabular form, but rather comprises textual variables. This paper presents an overview of the objectives and features of ten state-of-the-art language models. Additionally, various examples of sequence-to-text methods for transforming sequence data into textual formats are detailed to assist readers who may lack experience in implementing language models. Finally, through a series of simulations utilizing actual data, this study compares the performance of the aforementioned modern language models across several sequence-to-text methods, while also providing results from machine learning models to demonstrate the superior classification performance of language models."
Using Large Language Models to Extract Core Injury Information From Emergency Department Notes,2024,"['Large Language Model', 'Injuries', 'Information Extraction', 'Clinical Note', 'Emergency Department']",국문 초록 정보 없음,"Background: Injuries pose a significant global health challenge due to their high incidence and mortality rates. Although injury surveillance is essential for prevention, it is resource-intensive.This study aimed to develop and validate locally deployable large language models (LLMs) to extract core injury-related information from Emergency Department (ED) clinical notes.Methods: We conducted a diagnostic study using retrospectively collected data from January 2014 to December 2020 from two urban academic tertiary hospitals. One served as the derivation cohort and the other as the external test cohort. Adult patients presenting to the ED with injury-related complaints were included. Primary outcomes included classification accuracies for information extraction tasks related to injury mechanism, place of occurrence, activity, intent, and severity. We fine-tuned a single generalizable Llama-2 model and five distinct Bidirectional Encoder Representations from Transformers (BERT) models for each task to extract information from initial ED physician notes. The Llama-2 model was able to perform different tasks by modifying the instruction prompt. Data recorded in injury registries provided the gold standard labels. Model performance was assessed using accuracy and macro-average F1 scores.Results: The derivation and external test cohorts comprised 36,346 and 32,232 patients, respectively. In the derivation cohort’s test set, the Llama-2 model achieved accuracies (95% confidence intervals) of 0.899 (0.889–0.909) for injury mechanism, 0.774 (0.760–0.789) for place of occurrence, 0.679 (0.665–0.694) for activity, 0.972 (0.967–0.977) for intent, and 0.935 (0.926–0.943) for severity. The Llama-2 model outperformed the BERT models in accuracy and macro-average F1 scores across all tasks in both cohorts. Imposing constraints on the Llama-2 model to avoid uncertain predictions further improved its accuracy.Conclusion: Locally deployable LLMs, trained to extract core injury-related information from free-text ED clinical notes, demonstrated good performance. Generative LLMs can serve as versatile solutions for various injury-related information extraction tasks."
음성감정 추출을 위한 오픈소스 기반 인공지능 설계 및 개발,2024,"['인공지능', '감정인식', '트랜스포머', 'HuBERT', 'Mel-Frequency Cepstral Coefficient', 'Emotion Recognition', 'Transformer', 'HuBERT', 'Mel-Frequency Cepstral Coefficient']",국문 초록 정보 없음,"This study aims to improve communication for people with hearing impairments by developing artificial intelligence models that recognize and classify emotions from voice data. To achieve this, we utilized three major AI models: CNN-Transformer, HuBERT-Transformer, and Wav2Vec 2.0, to analyze users' voices in real-time and classify their emotions. To effectively extract features from voice data, we applied transformation techniques such as Mel-Frequency Cepstral Coefficient (MFCC), aiming to accurately capture the complex characteristics and subtle changes in emotions within the voice. Experimental results showed that the HuBERT-Transformer model demonstrated the highest accuracy, proving the effectiveness of combining pre-trained models and complex learning structures in the field of voice-based emotion recognition. This research presents the potential for advancements in emotion recognition technology using voice data and seeks new ways to improve communication and interaction for individuals with hearing impairments, marking its significance."
Accurate segmented equivalent circuit‑based calculation approach for non‑ideal stranded Litz wire leakage energy,2024,"['High-frequency transformer', 'Litz wire', 'Non-ideal stranded structure', 'Leakage energy', 'Finite element method', 'Equivalent circuit']",국문 초록 정보 없음,"Existing calculations of leakage energy in the Litz wire winding region of high-frequency transformers usually ignore the influence of Litz wire stranded structures. Therefore, a new approach is established in this paper to accurately calculate Litz wire leakage energy through the segmented equivalent circuit approach and the two-dimensional finite element method. That is, a single Litz wire in a complete stranded pitch is segmented and equated to the linear structure of multiple inductance cells. First, the two-dimensional finite element method calculates the impedance of each strand of Litz wire. Then the strand current vector is solved according to the system equation. Finally, the current vector is substituted back into the 2D Litz wire transverse-sectional model to calculate the leakage magnetic field energy under the skin effect and internal proximity effect, which is combined with the analytical expression of the external leakage magnetic field to calculate the total magnetic leakage energy of the Litz wire winding. Calculation results indicate that the new approach has an average relative deviation of less than 2.154% and a maximum relative deviation of no more than 4.953%."
Investigating Syntactic Interference Effects in Neural Language Models for Second Language Acquisition,2024,"['neural language model', 'syntactic transfer effect', 'second language acquisition']",국문 초록 정보 없음,"This paper explores the intricate dynamics of cross-linguistic transfer in second language acquisition (SLA) research, investigating how the linguistic structure of a native language influences the acquisition of a second language. The study employs transfer learning as a methodology, using the Transformer-based language model, BabyRoberta. The model undergoes pre-training on Korean as the first language (L1) and subsequent fine-tuning with English as the second language (L2). Evaluation involves the BLiMP test suite, a benchmark for assessing syntactic abilities in neural language models. The primary focus is on unraveling transfer effects originating from the native language’s linguistic structure. By examining the model’s performance on syntactic tasks, particularly in the context of English, the research aims to provide insights into how neural language models encode abstract syntactic structures, incorporating inductive biases acquired during pre-training on Korean. This approach not only contributes to the understanding of cross-linguistic influences in SLA but also tries figure interplay between native and second languages within neural language models."
생성언어는 어떤 문학적 체험을 요구하는가? -인공지능으로 창출 가능한 문학과 독자 연구-,2024,"['GPT(Generative Pre-trained Transformer)', 'generative language', 'generative literature', 'time of literary experience', 'language of process', 'Vauhini Vara.', 'GPT(Generative Pre-trained Transformer)', '생성언어', '생성문학', '문학적 체험의 시간', '과정의 언어', '바우히니 바라.']","본고는 인공지능의 생성언어에서 문학적 체험의 시간이 왜 필요하고 어떻게 활용될 수 있는지를 검토하고, 생성형 인공지능을 통해 어떤 문학이 성립 가능하고 어떤 독자가 창출 가능한지에 대한 사유를 넓히는 것을 목적으로 한다.근래 들어 챗GPT 같은 생성형 인공지능이자 거대언어모델의 등장으로 인간의 문학 창작물에 근접한 결과물이 제출되고 있지만, 심미적인 감상과 생산적인 비평을 동반하지 못하고 있는 점이 한계로 지적된다. 이러한 한계는 기존의 언어를 유일한 질료로 삼아 작동하는 인공지능의 속성상 정서적인 감응을 주는 텍스트 생성이 어렵고 기존의 언어예술을 뛰어넘는 언어예술을 창출하기 힘든 점과 맞물린다. 인간의 문학이 되기 위한 전제 조건이기도 한 문학적 체험의 시간을 건너뛸 수밖에 없는 특성 또한 인공지능의 생성 텍스트에 대해 적극적인 감상과 비평을 수행하는 데 방해 요소로 남는다.인공지능의 생성언어가 지니는 이러한 태생적인 한계를 극복하는 차원에서, 본고는 창작의 결과물이 아니라 창작의 과정을 담아내는 언어로서 ‘과정의 언어’를 소개하고 관련 사례를 살폈다. 인공지능의 도움을 받아 자전적 글쓰기를 수행하는 과정을 담아낸 바우히니 바라(Vauhini Vara)의 사례는, 과정의 언어로 제출되는 창작물이 독자들과 문학적 체험의 시간을 공유하며 적극적인 감상과 비평을 불러낼 수 있는 가능성을 보여준다. 연구의 말미에는 인공지능에 의해 문학적 체험의 의미를 다르게 받아들이는 독자의 탄생과 그로 인한 새로운 생성문학의 탄생을 기대할 수 있는 근거를 짚어보았다.","This study aims to examine why the time of literary experience is necessary and how it can be utilized in the generative language of AI, and to expand the thinking on what kind of literature can be established and what kind of readers can be created through generative AI.In recent years, with the emergence of generative AI and Large Language Model such as ChatGPT, results that are close to human literary creations have been submitted, but it is pointed out as a limitation that they are not accompanied by aesthetic appreciation and productive criticism. This limitation is coupled with the difficulty of generating texts with emotional impact due to the nature of AI that works with existing language as the only material, and the difficulty of creating language art that goes beyond existing language art. The inevitable characteristic of skipping the time of literary experience, which is a prerequisite for becoming human literature, also remains an obstacle to actively appreciating and criticizing AI-generated texts.In order to overcome these inherent limitations of AI-generated languages, this study introduces the ‘language of process’ as a language that captures the process of creation rather than the product of creation and examines related cases. The case of Vauhini Vara, which captures the process of performing autobiographical writing with the help of AI, shows the possibility that creative works submitted in the language of process can share the time of literary experience with readers and invite active appreciation and criticism. At the end of the study, we look at the basis for expecting the birth of readers who differently accept the meaning of literary experience through AI and the birth of new generative literature as a result."
How does ChatGPT evaluate the value of spatial information in the 4th industrial revolution?,2024,['ChatGPT · Spatial information · Perception · 4th Industrial Revolution'],국문 초록 정보 없음,"Chat Generative Pre-trained Transformer (ChatGPT), developed by OpenAI, is a prominent AI model capable of understanding and generating human-like text based on input. Since terms and concepts of spatial information are contextual, the applications of ChatGPT on spatial information disciplines can be biased by the perceptions and perspectives of ChatGPT towards spatial information. Therefore, a thorough understanding of the real magnitude and level of comprehension of spatial information by ChatGPT is essential before exploring its potential applications in spatial information disciplines.This article aims to investigate how ChatGPT evaluates spatial information and its potential contributions to 4th Industrial Revolution (Industry 4.0). ChatGPT has summarized a notable perspective on evaluating and utilizing spatial information in the context of the Industry 4.0. The result of this study shows that ChatGPT has a good understanding on contextual concepts related to spatial information. However, it exhibits potential biases and challenges, as its responses lean towards the technological and analytical aspects. The results provide a crucial understanding on how to leverage ChatGPT’s benefits to the fullest while recognizing its constraints, with the aim to enhance the efficacy from the perspective of applications linked to spatial information."
의미적 이미지 분할에 대한 인공신경망 모형 비교 연구,2024,"['Cityscapes images', 'neural network model', 'semantic image segmentation', 'streetview images', 'transformer.', '거리 뷰 이미지', '도시 경관', '의미적 이미지 분할', '인공신경망 모형', '트랜스포머.']","의미적 이미지 분할은 이미지를 구성하는 각 픽셀을 사전에 정의된 클래스로 분류하는 컴퓨터 비전의 분야 중 하나이다. 본 연구에서는 최근에 발표된 서로 다른 인코더 구조를 지닌 4개의 인공신경망 모형에 대하여 Cityscapes 데이터의 일부를 활용하여 학습하고 나머지 데이터를 통하여 정량 평가를 통해 모형을 비교하였다. 또한 네이버 거리 뷰에서 제공하는 이미지를 수집하여 학습된 모형을 적용하고 분할 결과 이미지를 기반으로 정성적인 비교를 수행하였다. 실험 결과 Cityscapes 데이터에 대해서는 InternImage 모형의 성능이 가장 우수하게 나타났으며, 네이버 거리 뷰 이미지 데이터에 대해서는 InternImage 모형과 ConvNeXt 모형이 유사한 성능을 나타냈으며, 다른 모형 대비 우수한 성능을 나타내었다.","Semantic image segmentation is one of the active research topics in computer vision, which classifies image pixels into predetermined semantic classes such as roads, buildings, cars, and trees. In this paper, we aim to compare four recently developed semantic image segmentation models based on different encoder structures, including the Swin Transformer, BEiT, ConvNeXt, and InternImage models. We train and test these models using the Cityscapes image dataset. Additionally, we apply the trained models, based on the Cityscapes data, to the Naver Streetview images. The results show that the InternImage model performs the best on the Cityscapes dataset, and both the InternImage and ConvNeXt models achieve similar performance, outperforming the others on the Naver Streetview images."
PF-GEMV: Utilization maximizing architecture in fast matrix–vector multiplication for GPT-2 inference,2024,"['low-precision', 'matrix–vector multiplication', 'multiformat', 'utilization']",국문 초록 정보 없음,"Owing to the widespread advancement of transformer-based artificial neural networks, artificial intelligence (AI) processors are now required to perform matrix–vector multiplication in addition to the conventional matrix–matrix multiplication. However, current AI processor architectures are optimized for general matrix–matrix multiplications (GEMMs), which causes significant throughput degradation when processing general matrix–vector multiplica-tions (GEMVs). In this study, we proposed a port-folding GEMV (PF-GEMV) scheme employing multiformat and low-precision techniques while reusing an outer product-based processor optimized for conventional GEMM operations. This approach achieves 93.7% utilization in GEMV operations with an 8-bit format on an 8 X 8 processor, thus resulting in a 7.5 X increase in throughput compared with that of the original scheme. Furthermore, when applied to the matrix operation of the GPT-2 large model, an increase in speed by 7 X is achieved in single-batch inferences."
Research category classification of scientific articles on human health risks of electromagnetic fields using pre-trained BERT,2024,['Deep learning modelHuman health risks of EMFResearch category classificationPre-trained BERT'],국문 초록 정보 없음,"This paper presents bidirectional encoder representations from transformers (BERT)-based deep learning model for the classification of scientific articles. This model aims to increase the efficiency and reliability of human health risk assessments related to electromagnetic fields (EMF). The proposed model takes the title and abstract of EMF-related articles and classifies them into four categories: animal exposure experiment, cell exposure experiment, human exposure experiment, and epidemiological study. We conducted a performance evaluation to verify the superiority of the proposed model. The results demonstrated that the proposed model outperforms other deep learning models that use pre-trained embeddings, with an average accuracy of 98.33%."
Lip and Voice Synchronization Using Visual Attention,2024,"['Lip-Voice Synchronization', 'Visual Attention', 'Multi-Modal Transformer', '입술-음성 동기화', '시각적 어텐션', '트랜스포머']",국문 초록 정보 없음,"This study explores lip-sync detection, focusing on the synchronization between lip movements and voices in videos. Typically, lip-sync detection techniques involve cropping the facial area of a given video, utilizing the lower half of the cropped box as input for the visual encoder to extract visual features. To enhance the emphasis on the articulatory region of lips for more accurate lip-sync detection, we propose utilizing a pre-trained visual attention-based encoder. The Visual Transformer Pooling (VTP) module is employed as the visual encoder, originally designed for the lip-reading task, predicting the script based solely on visual information without audio. Our experimental results demonstrate that, despite having fewer learning parameters, our proposed method outperforms the latest model, VocaList, on the LRS2 dataset, achieving a lip-sync detection accuracy of 94.5% based on five context frames. Moreover, our approach exhibits an approximately 8% superiority over VocaList in lip-sync detection accuracy, even on an untrained dataset, Acappella."
패칭을 이용한 GRU 기반의 시계열 예측 방법,2024,"['time series forecasting', 'GRU', 'patching', 'transformer', '시계열 예측', 'GRU', '패칭', '트랜스포머']","시계열 예측은 기업, 현장에서 의사결정의 보조자 역할로 활용되어 매우 중요하다. 최근 트랜스포머 구조의 patch time series Transformer(PatchTST)와 MLP 구조의 Long-term time series forecasting Linear(LTSF-Linear)가 시계열 예측에서 좋은 성능을 보여주었다. 하지만 PatchTST는 학습 및 추론시간이 오래 걸리고, LTSF-Linear는 구조의 단순함 때문에 훈련 데이터가 가지고 있는 정보를 제한적으로 학습한다는 문제점이 있다. 이를 보완하기 위해 패칭된 데이터에 Gated Recurrent Unit(GRU)를 사용하여 학습시간 감소와 시계열 데이터에서 학습할 수 있는 정보를 담아낼 수 있는 patch time series GRU(PatchTSG)를 제안한다. PatchTSG는 PatchTST 대비 학습시간을 최대 82%, 추론시간을 최대 46%까지 감소시킨다.","Time series forecasting plays a crucial role in decision-making within various fields. Two recent approaches, namely, the patch time series Transformer (PatchTST) and the long-term time series foraging linear (LTSF-Linear) of the MLP structure have shown promising performance in this area. However, PatchTST requires significant time for both model training and inference, while LTSF-Linear has limited capacity due to its simplistic structure. To address these limitations, we propose a new approach called patch time series GRU (PatchTSG). By leveraging  a Gated Recurrent Unit (GRU) on the patched data, PatchTSG reduces the training time and captures valuable information from the time series data. Compared to PatchTST, PatchTSG achieves an impressive reduction in learning time (up to 82%) and inference time (up to 46%)."
이미지와 점군을 이용한 CenterFormer 개선,2024,"['object detection', 'driving environment', 'deep learning', 'Transformer', '.']",국문 초록 정보 없음,"In autonomous driving, the robust detection of objects in the driving environment is essential. Existing driving environment object recognition algorithms are based on analyzing the class and location of objects through various data formats. In this study, we use Nuscenes, a driving environment dataset, to check and verify performance in the driving environment. We propose a method that uses only point cloud data and one that complements the weaknesses of using only image data and the weaknesses of using only point cloud data by adding image data to a model called CenterFormer, which combines CenterPoint and Transformer. The results revealed that the proposed method performed better than the method using only point cloud data."
리뷰 데이터를 활용한 POI 추천 시스템,2024,"['POI 추천', '협업 필터링', '대형 언어 모델', '리뷰 데이터', '설명 가능한 AI', 'POI Recommendation', 'Collaborative Filtering', 'Large Language Model', 'Review Data', 'Explainable AI']",국문 초록 정보 없음,"With recent advances in natural language processing (NLP) and the development of large language models (LLMs), leveraging textualdata such as user reviews has significantly improved the performance of recommender systems. In this paper, we propose a Point ofInterest (POI) recommender system that enhances recommendation accuracy by integrating user review data. We employ a fine-tunedBERT (Bidirectional Encoder Representations from Transformers) model to extract embeddings from user reviews and integrate them withcollaborative filtering models (BPR-MF, LightGCN) to improve performance. Experimental results on the Yelp dataset show that modelsincorporating textual data outperform baseline models in key metrics such as HitRatio@K, Recall@K, and Precision@K. Additionally, byproviding users with relevant reviews alongside recommendations, the system enhances the transparency and trustworthiness of the results.This research demonstrates the potential of utilizing textual data in improving POI recommendation systems and offers new opportunitiesto enhance recommendation accuracy and user experience."
Large Language Models: A Guide for Radiologists,2024,"['Natural language processing', 'Large language model', 'Transformer', 'Radiology', 'Chatbot', 'ChatGPT']",국문 초록 정보 없음,"Large language models (LLMs) have revolutionized the global landscape of technology beyond natural language processing. Owing to their extensive pre-training on vast datasets, contemporary LLMs can handle tasks ranging from general functionalities to domain-specific areas, such as radiology, without additional fine-tuning. General-purpose chatbots based on LLMs can optimize the efficiency of radiologists in terms of their professional work and research endeavors. Importantly, these LLMs are on a trajectory of rapid evolution, wherein challenges such as “hallucination,” high training cost, and efficiency issues are addressed, along with the inclusion of multimodal inputs. In this review, we aim to offer conceptual knowledge and actionable guidance to radiologists interested in utilizing LLMs through a succinct overview of the topic and a summary of radiology-specific aspects, from the beginning to potential future directions."
선로 신설에 따른 전압안정도 개선 효과의 간략 검토 방법,2024,"['Voltage stability calculation', 'Thevenin equivalent model', 'Margin', 'Transmission line effect']",국문 초록 정보 없음,"This paper proposes a new method for calculating the power system voltage stability point, when seeking to improve voltage instability limit by adding new lines to a power grid. Instead of the conventional iterative power flow calculation-based P-V simulation method, we suggest a method to analytically determine the voltage stability limit power using the Thevenin equivalent model in the demand bus. The Thevenin equivalent circuit in the demand bus can be obtained through fault calculations and no-load bus voltage calculations. By reflecting a high X/R ratio inherent in the AC power grid to simplify the model, we could determine the voltage stability limit power throufh an analytical method that does not reply on simulations.Suggested method was tested compared on the IEEE-14 system and PSS/E P-V linerized simuation. Buses related to control devices-generator and transformer primary buses were relatively large, however, in buses without control devices, average errors were below 3.8%, standard divation was 4.9% showing lower errors with higher X/R ratios. Therefore, this method can ve utilized for rapid decision-making in the planning and ooperation of transmission lines in the power grid by quickly comparing and evaluatig voltage stability margins due to additional power or on/off control of lines, especially in remote demand points where control devices such as generators are not nearby."
Construction of Text Summarization Corpus in Economics Domain and Baseline Models,2024,"['Abstractive Text Summarization', 'Natural Language Processing', 'Transformer Model', 'Public Dataset', 'Economics Domain']",국문 초록 정보 없음,"Automated text summarization (ATS) systems rely on language resources as datasets. However, creating these datasets is a complex and labor-intensive task requiring linguists to extensively annotate the data. Consequently, certain public datasets for ATS, particularly in languages such as Thai, are not as readily available as those for the more popular languages. The primary objective of the ATS approach is to condense large volumes of text into shorter summaries, thereby reducing the time required to extract information from extensive textual data. Owing to the challenges involved in preparing language resources, publicly accessible datasets for Thai ATS are relatively scarce compared to those for widely used languages. The goal is to produce concise summaries and accelerate the information extraction process using vast amounts of textual input. This study introduced ThEconSum, an ATS architecture specifically designed for Thai language, using economy-related data. An evaluation of this research revealed the significant remaining tasks and limitations of the Thai language."
변압기와 케이블 임피던스를 고려한 BESS의 누설전류 분석,2024,"['Battery energy storage system', 'Cable Impedance', 'Common mode', 'Leakage current', 'Parasitic capacitance']",국문 초록 정보 없음,"This paper analyzes the magnitude of leakage current due to parasitic capacitance and cable impedance generated by structural characteristics in Battery energy storage systems(BESS). The cable was measured using an LCR meter and employed in simulations and experiments. A leakage current equivalent model was constructed and validated through comparison with experimental data. In the case with no cable impedance, the leakage current path in the IT grounding method includes paths through the LCL filter of the PCS, transformer impedance, and parasitic capacitance. However, when cable impedance is added, it was confirmed that the leakage current magnitude increases because an additional leakage current path through the cable is introduced. Therefore, the magnitude of the leakage current was 43.3 mArms before the cable was added, but after adding the cable impedance, it increased to 159.8 mArms, demonstrating a 3.7-fold increase."
효율적인 3차원 개체 분할을 위한 개체 위치 인코딩과 이중 노이즈 제거 작업들,2024,"['Point Cloud', '3D Instance Segmentation', 'Transformer-based Instance Decoder', 'Instance Attention Mask', 'Denoising Auxiliary Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
유연접속 운영을 위한 다층 퍼셉트론 기반의 ESS 연계 태양광 발전량 예측,2024,"['Neural Network', 'Multi-Layer Perceptron', 'Prediction', 'Photovoltaic Power Generation', 'Energy Storage System']",국문 초록 정보 없음,"To overcome the limitations of transformer acceptance capacity due to the rapid increase in renewable energy sources, the calculation method for the renewable energy connection acceptance capacity is changing from the previous method based on the installation capacity to the method based on the operating capacity. This paper studies a technology to predict the power generation of photovoltaic power plants connected to energy storage systems (ESS), which is necessary for predicting the operating capacity of transformer, using a multi-layer perceptron (MLP) based artificial neural network model."
한국어 립리딩: 데이터 구축 및 문장수준 립리딩,2024,"['Lip-reading(립리딩)', 'Korean(한국어)', 'Sentence-level(문장 수준)', 'and Transformer(트랜스포머)']",국문 초록 정보 없음,"Lip-reading is the task of inferring the speaker’s utterance from silent video based on learning of lipmovements. It is very challenging due to the inherent ambiguities present in the lip movement such as differentcharacters that produce the same lip appearances. Recent advances in deep learning models such as Transformerand Temporal Convolutional Network have led to improve the performance of lip-reading. However, most previousworks deal with English lip-reading which has limitations in directly applying to Korean lip-reading, and moreover,there is no a large scale Korean lip-reading dataset. In this paper, we introduce the first large-scale Koreanlip-reading dataset with more than 120 k utterances collected from TV broadcasts containing news, documentary anddrama. We also present a preprocessing method which uniformly extracts a facial region of interest and propose atransformer-based model based on grapheme unit for sentence-level Korean lip-reading. We demonstrate that ourdataset and model are appropriate for Korean lip-reading through statistics of the dataset and experimental results."
CR-M-SpanBERT: Multiple embedding-based DNN coreference resolution using self-attention SpanBERT,2024,"['coreference resolution', 'dependency parsing', 'multiple embedding']",국문 초록 정보 없음,"This study introduces CR-M-SpanBERT, a coreference resolution (CR) model that utilizes multiple embedding-based span bidirectional encoder representations from transformers, for antecedent recognition in natural language (NL) text. Information extraction studies aimed to extract knowledge from NL text autonomously and cost-effectively. However, the extracted information may not represent knowledge accurately owing to the presence of ambiguous entities. Therefore, we propose a CR model that identifies mentions referring to the same entity in NL text. In the case of CR, it is necessary to understand both the syntax and semantics of the NL text simultaneously. Therefore, multiple embeddings are generated for CR, which can include syntactic and semantic information for each word. We evaluate the effectiveness of CRM-SpanBERT by comparing it to a model that uses SpanBERT as the language model in CR studies. The results demonstrate that our proposed deep neural network model achieves high-recognition accuracy for extracting antecedents from NL text. Additionally, it requires fewer epochs to achieve an average F1 accuracy greater than 75% compared with the conventional SpanBERT approach."
A label-free high precision automated crack detection method based on unsupervised generative attentional networks and swin-crackformer,2024,"['crack detection', 'deep learning', 'unsupervised generative attentional networks', 'vision Transformer']",국문 초록 정보 없음,"Automated crack detection is crucial for structural health monitoring and post-earthquake rapid damage detection. However, realizing high precision automatic crack detection in the absence of corresponding manual labeling presents a formidable challenge. This paper presents a novel crack segmentation transfer learning method and a novel crack segmentation model called Swin-CrackFormer. The proposed method facilitates efficient crack image style transfer through a meticulously designed data preprocessing technique, followed by the utilization of a GAN model for image style transfer. Moreover, the proposed Swin-CrackFormer combines the advantages of Transformer and convolution operations to achieve effective local and global feature extraction. To verify the effectiveness of the proposed method, this study validates the proposed method on three unlabeled crack datasets and evaluates the Swin-CrackFormer model on the METU dataset. Experimental results demonstrate that the crack transfer learning method significantly improves the crack segmentation performance on unlabeled crack datasets. Moreover, the Swin-CrackFormer model achieved the best detection result on the METU dataset, surpassing existing crack segmentation models."
Alzheimer’s disease recognition from spontaneous speech using large language models,2024,"['Alzheimer’s disease', 'dementia', 'dementia detection', 'large language model', 'pretrained model']",국문 초록 정보 없음,"We propose a method to automatically predict Alzheimer’s disease from speech data using the ChatGPT large language model. Alzheimer’s disease patients often exhibit distinctive characteristics when describing images, such as difficulties in recalling words, grammar errors, repetitive language, and incoherent narratives. For prediction, we initially employ a speech recognition system to transcribe participants’ speech into text. We then gather opinions by inputting the transcribed text into ChatGPT as well as a prompt designed to solicit fluency evaluations. Subsequently, we extract embeddings from the speech, text, and opinions by the pretrained models. Finally, we use a classifier consisting of transformer blocks and linear layers to identify participants with this type of dementia. Experiments are conducted using the extensively used ADReSSo dataset. The results yield a maximum accuracy of 87.3% when speech, text, and opinions are used in conjunction. This finding suggests the potential of leveraging evaluation feedback from language models to address challenges in Alzheimer’s disease recognition."
Machine learning-based evaluation technology of 3D spatial distribution of residual radioactivity in large-scale radioactive structures,2024,"['Radioactivity distribution evaluation', 'Large-scale radioactive waste', 'Machine learning', 'Convolutional neural network', 'Transformer learning model', 'FLUKA']",국문 초록 정보 없음,"During the decommissioning of nuclear and particle accelerator facilities, a considerable amount of large-scale radioactive waste may be generated. Accurately defining the activation level of the waste is crucial for proper disposal. However, directly measuring the internal radioactivity distribution poses challenges. This study introduced a novel technology employing machine learning to assess the internal radioactivity distribution based on external measurements. Random radioactivity distribution within a structure were established, and the photon spectrum measured by detectors from outside the structure was simulated using the FLUKA Monte-Carlo code. Through training with spectrum data corresponding to various radioactivity distributions, an evaluation model for radioactivity using simulated data was developed by above Monte-Carlo simulation. Convolutional Neural Network and Transformer methods were utilized to establish the evaluation model. The machine learning construction involves 5425 simulation datasets, and 603 datasets, which were used to obtain the evaluated results. Preprocessing was applied to the datasets, but the evaluation model using raw spectrum data showed the best evaluation results. The estimation of the intensity and shape of the radioactivity distribution inside the structure was achieved with a relative error of 10%. Additionally, the evaluation based on the constructed model takes only a few seconds to complete the process."
객체 검출을 위한 텍스트 묘사 기반의 도메인 일반화 방법,2024,[],국문 초록 정보 없음,"Domain generalization is a field that focus on making a model trained with only source domain data to perform well also on other unseen domains. Recently domain generalized methods that leverage image-text multimodal models are proposed. In this paper, we propose a novel method for incorporating image and text feature in a joint space and apply it to transformer-based object detection, achieving domain generalized object detection model. Experiments on diverse weather conditions show our proposed algorithm outperforms state-of-the-art method by 12.5%."
Dual-scale BERT using multi-trait representations for holistic and trait-specific essay grading,2024,"['automated essay scoring', 'deep learning methods', 'multi-task learning', 'multi-trait scoring', 'transformer-based models']",국문 초록 정보 없음,"As automated essay scoring (AES) has progressed from handcrafted techniques to deep learning, holistic scoring capabilities have merged. However, specific trait assessment remains a challenge because of the limited depth of earlier methods in modeling dual assessments for holistic and multi-trait tasks. To overcome this challenge, we explore providing comprehensive feedback while modeling the interconnections between holistic and trait representations. We introduce the DualBERT-Trans-CNN model, which combines transformerbased representations with a novel dual-scale bidirectional encoder representations from transformers (BERT) encoding approach at the document-level. By explicitly leveraging multi-trait representations in a multi-task learning (MTL) framework, our DualBERT-Trans-CNN emphasizes the interrelation between holistic and trait-based score predictions, aiming for improved accuracy. For validation, we conducted extensive tests on the ASAP++ and TOEFL11 datasets. Against models of the same MTL setting, ours showed a 2.0% increase in its holistic score. Additionally, compared with single-task learning (STL) models, ours demonstrated a 3.6% enhancement in average multi-trait performance on the ASAP++ dataset."
Machine learning‐based evaluation technology of 3D spatial distribution of residual radioactivity in large‐scale radioactive structures,2024,"['Radioactivity distribution evaluation', 'Large-scale radioactive waste', 'Machine learning', 'Convolutional neural network', 'Transformer learning model', 'FLUKA']",국문 초록 정보 없음,"During the decommissioning of nuclear and particle accelerator facilities, a considerable amount of large-scale radioactive waste may be generated. Accurately defining the activation level of the waste is crucial for proper disposal. However, directly measuring the internal radioactivity distribution poses challenges. This study introduced a novel technology employing machine learning to assess the internal radioactivity distribution based on external measurements. Random radioactivity distribution within a structure were established, and the photon spectrum measured by detectors from outside the structure was simulated using the FLUKA Monte-Carlo code. Through training with spectrum data corresponding to various radioactivity distributions, an evaluation model for radioactivity using simulated data was developed by above Monte-Carlo simulation. Convolutional Neural Network and Transformer methods were utilized to establish the evaluation model. The machine learning construction involves 5425 simulation datasets, and 603 datasets, which were used to obtain the evaluated results.Preprocessing was applied to the datasets, but the evaluation model using raw spectrum data showed the best evaluation results. The estimation of the intensity and shape of the radioactivity distribution inside the structure was achieved with a relative error of 10%. Additionally, the evaluation based on the constructed model takes only a few seconds to complete the process"
Enhancing aircraft engine remaining useful life prediction via multiscale deep transfer learning with limited data,2024,"['remaining useful life prediction', 'multiscale convolutional neural network', 'transformer', 'transfer learning', 'domain adaptation']",국문 초록 정보 없음,"Predicting the remaining useful life (RUL) of the aircraft engine based on historical data plays a pivotal role in formulating maintenance strategies and mitigating the risk of critical failures. None the less, attaining precise RUL predictions often encounters challenges due to the scarcity of historical condition monitoring data. This paper introduces a multiscale deep transfer learning framework via integrating domain adaptation principles. The framework encompasses three integral components: a feature extraction module, an encoding module, and an RUL prediction module. During pre-training phase, the framework leverages a multiscale convolutional neural network to extract distinctive features from data across varying scales. The ensuing parameter transfer adopts a domain adaptation strategy centered around maximum mean discrepancy. This method efficiently facilitates the acquisition of domain-invariant features from the source and target domains. The refined domain adaptation Transformer-based multiscale convolutional neural network model exhibits enhanced suitability for predicting RUL in the target domain under the condition of limited samples. Experiments on the C-MAPSS dataset have shown that the proposed method significantly outperforms state-of-the-art methods."
A Study on Improving Face Recognition Accuracy Through Self-Supervised Learning,2024,"['Face Recognition', 'Self-Supervised Learning', 'Out-of-Distribution', 'Transformer', 'Contrastive Learning']",국문 초록 정보 없음,"In the context of face recognition, traditional methods have limitations when dealing with out-of-distribution data. To address these challenges, our study leverages the potential of unsupervised training within the transformer architecture. We developed an automatic video processing approach and a two-stage training model. This method utilizes both abundant unlabeled data in the wild and high-quality labeled data to enhance the training process, employing self-supervised contrastive loss and supervised classification loss, respectively. Experimental results demonstrate the superiority of our approach in terms of generalization across diverse data distributions and improved accuracy. This study validates the effectiveness of unsupervised training for face recognition and is expected to contribute to advancements in handling out-of-distribution data."
ChatGPT Vision for Radiological Interpretation: An Investigation Using Medical School Radiology Examinations,2024,"['ChatGPT', 'GPT-4 vision', 'Artificial intelligence', 'Large language model', 'Vision language model', 'Foundation model', 'Transformer', 'Generative model', 'Chatbot']",국문 초록 정보 없음,다국어 초록 정보 없음
Does BERT Learn Syntactic and Semantic Preferences in Picture Noun Phrase Interpretation?,2024,"['BERT', 'reference resolution', 'picture noun phrase', 'surprisal']",국문 초록 정보 없음,"This research investigates the Bidirectional Encoder Representations from Transformers (BERT) model’s ability to understand semantic and syntactic preferences of low-frequency expressions through reference resolution in picture noun phrases (PNPs). To this end, we report on three experiments that evaluate BERT’s understanding of reference resolution differences between personal pronouns and reflexives in possessor-less and possessed PNPs. Our experiments show that BERT exhibits human-like referential preferences with reflexives but not with personal pronouns. The findings for reflexive resolution suggest that BERT’s deep learning training does not solely rely on frequency information but serves as a mechanism for acquiring more systematic linguistic soft constraints Moreover, the different resolution patterns from the pronouns could be attributed to the reflexives’ more explicit referential dependency and their relatively low frequency."
Extensive Multilabel Classification of Brain MRI Scans for Infarcts Using the Swin UNETR Architecture in Deep Learning Applications,2024,"['Deep learning', 'Infarction', 'Classification', 'Rehabilitation']",국문 초록 정보 없음,"Objective: To distinguish infarct location and type with the utmost precision using the advantages of the Swin UNEt TRansformers (Swin UNETR) architecture.Methods: The research employed a two-phase training approach. In the first phase, the Swin UNETR model was trained using the Ischemic Stroke Lesion Segmentation Challenge (ISLES) 2022 dataset, which included cases of acute and subacute infarcts. The second phase involved training with data from 309 patients. The 110 categories result from classifying infarcts based on 22 specific brain regions. Each region is divided into right and left sides, and each side includes four types of infarcts (acute, acute lacunar, subacute, subacute lacunar). The unique architecture of Swin UNETR, integrating elements of both the transformer and u-net designs with a hierarchical transformer computed with shifted windows, played a crucial role in the study.Results: During Swin UNETR training with the ISLES 2022 dataset, batch loss decreased to 0.8885±0.1897, with training and validation dice scores reaching 0.4224±0.0710 and 0.4827±0.0607, respectively. The optimal model weight had a validation dice score of 0.5747. In the patient data model, batch loss decreased to 0.0565±0.0427, with final training and validation accuracies of 0.9842±0.0005 and 0.9837±0.0010.Conclusion: The results of this study surpass the accuracy of similar studies, but they involve the issue of overfitting, highlighting the need for future efforts to improve generalizability. Such detailed classifications could significantly aid physicians in diagnosing infarcts in clinical settings."
얕은 레이어와 깊은 레이어의 합성곱 연결을 이용한 향상된 무참조 이미지 품질평가 방법,2024,[],국문 초록 정보 없음,"This paper proposes an improved no-reference image quality assessment (NR-IQA) method. It introduces a new model that combines convolutional neural networks (CNN) and the self-attention mechanism of Transformers to extract both local and global features from input images. The proposed model employs CNN to capture local structural information and uses the CNN-extracted features as sequential inputs to the Transformer to model the global representation of the images. This paper proposes an advanced version of TReS, which uses convolution operations to improve NR-IQA performance. Experimental results show that the proposed method provides performance improvement for various datasets compared to the original TReS model."
얕은 레이어와 깊은 레이어의 합성곱 연결을 이용한 향상된 무참조 이미지 품질평가 방법,2024,[],국문 초록 정보 없음,"This paper proposes an improved no-reference image quality assessment (NR-IQA) method. It introduces a new model that combines convolutional neural networks (CNN) and the self-attention mechanism of Transformers to extract both local and global features from input images. The proposed model employs CNN to capture local structural information and uses the CNN-extracted features as sequential inputs to the Transformer to model the global representation of the images. This paper proposes an advanced version of TReS, which uses convolution operations to improve NR-IQA performance. Experimental results show that the proposed method provides performance improvement for various datasets compared to the original TReS model."
Brep2Seq: a dataset and hierarchical deep learning network for reconstruction and generation of computer-aided design models,2024,"['computer-aided design', 'boundary representation', '3D deep learning', 'geometry synthesis', '3D reconstruction', 'generative model']",국문 초록 정보 없음,"Three-dimensional (3D) reconstruction is a significant research topic in the field of computer-aided design (CAD), which is used to recover editable CAD models from original shapes, including point clouds, voxels, meshes, and boundary representations (B-rep). Recently, there has been considerable research interest in deep model generation due to the increasing potential of deep learning methods. To address the challenges of 3D reconstruction and generation, we propose Brep2Seq, a novel deep neural network designed to transform the B-rep model into a sequence of editable parametrized feature-based modeling operations comprising principal primitives and detailed features. Brep2Seq employs an encoder-decoder architecture based on the transformer, leveraging geometry and topological information within B-rep models to extract the feature representation of the original 3D shape. Due to its hierarchical network architecture and training strategy, Brep2Seq achieved improved model reconstruction and controllable model generation by distinguishing between the primary shape and detailed features of CAD models. To train Brep2Seq, a large-scale dataset comprising 1 million CAD designs is established through an automatic geometry synthesis method. Extensive experiments on both DeepCAD and Fusion 360 datasets demonstrate the effectiveness of Brep2Seq, and show its applicability to simple mechanical components in real-world scenarios. We further apply Brep2Seq to various downstream applications, including point cloud reconstruction, model interpolation, shape constraint generation, and CAD feature recognition."
Two-Stage Cascaded High-Precision Early Warning of Wind Turbine Faults Based on Machine Learning and Data Graphization,2024,['Data graphization · Fault early warning · Gramian angular feld · Wind turbines · Time generative adversarial network · Vision transformer'],국문 초록 정보 없음,"Due to the limited accessibility of wind turbines (WTs) and the complexity of operation and maintenance (O&M), it is increasingly important to early warn the component faults of WTs, and the difculties lie in balancing the comprehensiveness and delicacy of early warning. In this paper, a two-stage cascaded high-precision fault early warning method based on machine learning (ML) and data graphization is proposed. The frst stage copes with the early warning of the main components, in which the supervisory control and data acquisition (SCADA) data are converted into Gramian Angular Field (GAF) images to establish the potential relationship of fault features at diferent time points, and the fault characteristics are extracted by convolutional neural network (CNN) to realize fault early warning for multiple main components simultaneously. The second stage focus on the fault subcomponents inside the main components further, in which the time generative adversarial network (TimeGAN) is adopted to enhance the fault code data samples, then the enhanced data in the form of grayscale images is input into the Vision Transformer (ViT) to train the subcomponent early warning model. The proposed method is validated with real SCADA data, the results show the efectiveness of the proposed method."
마스크 이미지 모델링 가이드를 이용하여 개선된 스테레오 깊이 추정 기술 개발,2024,[],국문 초록 정보 없음,"In stereo matching tasks, CNN-based models have traditionally served as the predominant architectures, however, Transformer-based stereo models have also been adopted recently by leveraging effective pretraining methods to partially alleviate the inherent data-hungry issue in transformers. This paper focuses on addressing the labeled training data scarcity caused by the lack of locality inductive bias in the Transformer-based stereo models which is crucial for training with limited data when finetuning them in the downstream tasks such as stereo depth estimation. To mitigate this issue, we propose StereoIM, a novel stereo depth estimation framework that provides sufficient locality inductive biases during finetuning via Masked Image Modeling (MIM), which has been a prevalent approach for model pretraining. Reconstructing a masked image and subsequently predicting a disparity map from it, however, poses additional challenges in terms of stable model training. To overcome these challenges, we propose to employ an auxiliary network (teacher) that is updated via Exponential Moving Average (EMA) in addition to an original stereo model (student), and to use its predictions as supervisions for distilling the knowledge to the student. Our method achieves state-of-the-art on the KITTI 2015."
Users’ Attachment Styles and ChatGPT Interaction: Revealing Insights into User Experiences,2024,"['Human-AI Interaction', 'Attachment Style', 'Conversational AI Agents', 'Chatbots', 'User Experience', '인간-인공지능 상호 작용', '애착 유형', '대화형 인공지능 에이전트', '챗봇', '사용자 경험']",국문 초록 정보 없음,"This study explores the relationship between users attachment styles and their interactions with ChatGPT (Chat Generative Pre-trained Transformer), an advanced language model developed by OpenAI. As artificial intelligence (AI) becomes increasingly integrated into everyday life, it is essential to understand how individuals with different attachment styles engage with AI chatbots in order to build a better user experience that meets specific user needs and interacts with users in the most ideal way. Grounded in attachment theory from psychology, we are exploring the influence of attachment style on users interaction with ChatGPT, bridging a significant gap in understanding human-AI interaction. Contrary to expectations, attachment styles did not have a significant impact on ChatGPT usage or reasons for engagement. Regardless of their attachment styles, hesitated to fully trust ChatGPT with critical information, emphasizing the need to address trust issues in AI systems. Additionally, this study uncovers complex patterns of attachment styles, demonstrating their influence on interaction patterns between users and ChatGPT. By focusing on the distinctive dynamics between users and ChatGPT, our aim is to uncover how attachment styles influence these interactions, guiding the development of AI chatbots for personalized user experiences. The introduction of the Perceived Partner Responsiveness Scale serves as a valuable tool to evaluate users perceptions of ChatGPTs role, shedding light on the anthropomorphism of AI. This study contributes to the wider discussion on human-AI relationships, emphasizing the significance of incorporating emotional intelligence into AI systems for a user-centered future."
Modeling Short Answer Grading Performance Improvement by GPT Augmentation Data,2024,"['Data Augmentation', 'Automated Short Answer Grading System', 'GPT', 'fine-tuning']",국문 초록 정보 없음,"The automatic grading of short answer question is important in the field of Natural Language Processing. ASAG (Automated Short Answer Grading) task have undergone numerous advancements.Recent studies have adopted transformer models such as the T5 embedding or BERT-base models.Nonetheless, ASAG tasks encounter significant challenges stemming from limited data availability. The urgent need for more training data emerges as a central issue. Several researchers have proposed augmentation approaches to address this gap. In this study, we introduce other data augmentation technique utilizing prompt engineering by the GPT model. We deploy ASAG system using the Sentence Transformers model, fine-tuning specific hyper-parameters alongside the augmented dataset. The primary factors influencing performance enhancement include the augmentation process, particularly the quantity of augmented data, and the dataset split size for training and testing purposes. Furthermore, alternative GPT models or fine-tuning GPT could be explored within the augmentation process."
기술기회 발굴 지원을 위한 텍스트 분석 기반의 기술-디자인 트리 구축,2024,"['Technology Opportunities Discovery', 'Patent-Design Right Linkage Data', 'Technology-Design Tree', 'Keyword Extraction', 'Similar Groups']",국문 초록 정보 없음,"This paper introduces a novel methodology for constructing technology-design trees based on text analysis to support the discovery of technology opportunities. The methodology employs KeyBERT(Keyword extraction with Bidirectional Encoder Representations from Transformers) model to extract meaningful keywords from patents and design rights documents, thus facilitating the analysis of semantic similarities and categorization into similar technological and design groups. Further, it utilizes Cooperative Patent Classification (CPC) and Locarno Classification (LOC) to build technology trees and design trees, respectively, through the analysis of technical and product similarities. Additionally, the methodology employs structural similarity index mapping (SSIM) on patent and design right drawings to validate the constructed trees. The approach is distinguished by its minimal reliance on expert intervention, enhancing the efficiency and scalability of technology opportunity discovery processes."
효율적인 개방형 어휘 3차원 개체 분할을 위한 클래스-독립적인3차원 마스크 제안과 2차원-3차원 시각적 특징 앙상블,2024,"['포인트 클라우드', '개방형-어휘 3차원 개체 분할', '3차원 마스크 제안', '2차원-3차원 시각적 특징 앙상블', 'Point Cloud', 'Open-Vocabulary 3D Instance Segmentation', 'Class-Agnostic 3D Mask Proposal', '2D-3D Visual Feature Ensemble']",국문 초록 정보 없음,"Open-vocabulary 3D point cloud instance segmentation (OV-3DIS) is a challenging visual task to segment a 3D scene point cloudinto object instances of both base and novel classes. In this paper, we propose a novel model Open3DME for OV-3DIS to address importantdesign issues and overcome limitations of the existing approaches. First, in order to improve the quality of class-agnostic 3D masks,our model makes use of T3DIS, an advanced Transformer-based 3D point cloud instance segmentation model, as mask proposal module.Second, in order to obtain semantically text-aligned visual features of each point cloud segment, our model extracts both 2D and 3Dfeatures from the point cloud and the corresponding multi-view RGB images by using pretrained CLIP and OpenSeg encoders respectively.Last, to effectively make use of both 2D and 3D visual features of each point cloud segment during label assignment, our model adoptsa unique feature ensemble method. To validate our model, we conducted both quantitative and qualitative experiments on ScanNet-V2benchmark dataset, demonstrating significant performance gains."
"Accurate, automated classification of radiographic knee osteoarthritis severity using a novel method of deep learning: Plug-in modules",2024,"['Knee osteoarthritis', 'Deep learning', 'Classification']",국문 초록 정보 없음,"Background Fine-grained classification deals with data with a large degree of similarity, such as cat or bird species, and similarly, knee osteoarthritis severity classification [Kellgren-Lawrence (KL) grading] is one such fine-grained classification task. Recently, a plug-in module (PIM) that can be integrated into convolutional neural-network-based or transformer-based networks has been shown to provide strong discriminative regions for fine-grained classification, with results that outperformed the previous deep learning models. PIM utilizes each pixel of an image as an independent feature and can subsequently better classify images with minor differences. It was hypothesized that, as a fine-grained classification task, knee osteoarthritis severity may be classified well using PIMs. The aim of the study was to develop this automated knee osteoarthritis classification model.Methods A deep learning model that classifies knee osteoarthritis severity of a radiograph was developed utilizing PIMs. A retrospective analysis on prospectively collected data was performed. The model was trained and developed using the Osteoarthritis Initiative dataset and was subsequently tested on an independent dataset, the Multicenter Osteoarthritis Study (test set size: 17,040). The final deep learning model was designed through an ensemble of four different PIMs.Results The accuracy of the model was 84%, 43%, 70%, 81%, and 96% for KL grade 0, 1, 2, 3, and 4, respectively, with an overall accuracy of 75.7%.Conclusions The ensemble of PIMs could classify knee osteoarthritis severity using simple radiographs with a fine accuracy. Although improvements will be needed in the future, the model has been proven to have the potential to be clinically useful."
참조 비디오 개체 분할을 위한 교차 모달 개체 디코딩과 참조 표현 분리 인코딩,2024,"['Referring Expression', 'Video Object Segmentation', 'Cross-modal Object Decoding', 'Text Decoupling', 'Alignment Loss']",국문 초록 정보 없음,"Referring Video Object Segmentation(RVOS) is a complex computer vision task that requires detecting, segmenting, and tracking a specific object in a video that is referred to by a given natural language expression. In this paper, we propose CDTD-RVOS(Cross-modal Decoding and Text Decoupling for RVOS), a novel Transformer-based deep neural network model for RVOS. The proposed model effectively extracts object-specific visual features at all levels of pixels, frames, and the entire video with Transformers. In order to capture correctly the meaning of the natural language referring expression, the model uses a text decoupling technique that divides the words of the referring expression into their functional components and encodes them into rich linguistic features. Moreover, the proposed model performs cross-modal fusion between the visual feature of video objects and the linguistic feature of the referring expression at all levels of pixels, frames, and the entire video to enhance alignment with two heterogeneous features. Extensive experiments conducted on three benchmark datasets, A2D-Sentences, Ref-Youtube-VOS, and Ref-DAVIS 17, show high performance of our proposed CDTD-RVOS model."
Heat Distribution Analysis of Resonant Power Converter in Non-starting Air Conditioner of Commercial Vehicles,2024,['ANSYS/thermal analysis  · Heat distribution analysis  · Heat sink  · Resonant power converter  · Non-starting air conditioner  · Commercial vehicles'],국문 초록 정보 없음,"This study deals with ANSYS/Thermal analysis of the heat dissipation system of a resonant power converter for a nonstarting air conditioner compressor for commercial vehicles, predicts the heat sink saving eff ect, and proves feasibility through experiments. The thermal analysis model was set with the heat sink and peripheral components of the resonant power converter, and the ambient temperature was 25 °C under natural convection conditions, and ANSYS/Thermal simulation was performed using the heat fl ux value of the heating part including the MOSFET. As a result of performing ANSYS thermal analysis according to the above conditions, the heat sink of the resonant power converter showed a maximum heat distribution of 28.4 °C, and the maximum temperature of the resonant power converter with the heat sink was about 59.2 °C. According to this result, the horizontal size (L) of the heat sink selected at the beginning of development was reduced to 210 mm as a result of ANSYS analysis. A DSP-based experiment was conducted at maximum output power condition (2.5 kW) using a reduced 210 mm heat sink and the original 250 mm heat sink. As a result of the experiment, the same temperature distribution was measured in the low voltage side bus bar (LVPL) of each heat sink system, the switching element part, and the power driver, except for the high-frequency (HF) transformer. When the heat sink is reduced, the temperature of the HF transformer is about 8 °C higher than that of the original heat sink, so a transformer with a slightly higher capacity should be selected.This study is signifi cant in that it is possible to provide information on heat sink reduction by predicting the temperature of about 30ᕑ for heat sink and about 55 °C for MOSFET using only ANSYS analysis without experimentation. Using the above results, the resonant current of the transformer and the output voltage and output current of the resonant power converter were fi nally measured for 2.5 kW, and it was confi rmed that the output voltage of 250 V was stably generated at the battery voltage of 24 V."
딥러닝 기반 전기 자동차 급속 충전기용 DAB의 최적 MOSFET 소자 선정 방안,2024,"['DAB(Dual Active Bridge)', 'Deep Learning', 'DNN(Deep Neural Network)', 'EV(Electric Vehicle)', 'Fast Charger']",국문 초록 정보 없음,"This paper proposes a novel method based on deep learning to select the optimal MOSFET in dual active bridge converters used in electric vehicle fast chargers. Although various studies have applied artificial intelligence to dual active bridge converters, most of them focus on designing transformers or deriving optimal operating points. However, an optimal switch that minimizes power loss across the entire operating area must be selected to design a high power dual active bridge converter and achieve high efficiency. The proposed method uses the power loss results of simulation as training data for deep learning, allowing the model to generate a power loss profile data and select the optimal MOSFET. The validity of the proposed method is verified by comparing the power loss estimates from the deep learning model with the actual power loss from the simulations."
Comparison of long cable impedances using multiphysics and equivalent circuit models,2024,"['Long cable', 'Modeling', 'Multiphysics analysis', 'Equivalent circuit']",국문 초록 정보 없음,"When a long cable is included in power conversion systems, it causes adverse effects, such as voltage spikes and ringing at load terminals. These nonideal voltages can break the insulation of electric machines, such as transformers and motors, and reduce their lifespan. To estimate such voltage characteristics, cable impedance should be modeled on the basis of the cable length. In this paper, two cable impedance models, a multiphysics model and an equivalent circuit model, are introduced. The multiphysics model using Ansys Q3D Extractor is suggested in consideration of the structure, material, and length of a practical cable. Meanwhile, the equivalent circuit model can be quickly utilized to examine voltage spikes and frequency. The accuracy of the proposed models is verified through simulation and the experimental results based on a motor drive system equipped with 30 and 100-m cables."
Research on Two-stage Isolated Dual Output Port On-board Charging System,2024,['CLLC resonant converter  · Dual output ports  · Hybrid control method  · On-board charging system  · Three-port converter'],국문 초록 정보 없음,"This paper proposes a two-stage isolated dual output port on-board charging system, which consists of a front-stage power factor correction (PFC) converter and a rear-stage DC/DC converter. The front-stage circuit adopts a double diode bridgeless PFC and the rear-stage circuit adopts a CLLC resonant converter. A three-winding transformer is used to magnetically couple the power grid input terminal, high-voltage battery, and low-voltage battery. The fundamental wave analysis method is then used to determine the voltage gain characteristics, and the parameters of the converter power components are chosen based on the system indicators. The front-stage PFC converter uses the average current control method with a double closed loop structure, which is composed of a voltage outer loop and a current inner loop. The rear-stage DC/DC converter combines the pulse frequency modulation (PFM) and phase shift (PS) control, which enables two working modes: parking charging and driving charging. The simulation model is then developed and the experimental prototype is designed to test the on-board charging system and analyze the experimental results. The obtained results show that the power factor correction function of the input current can be achieved by the front-stage double-diode bridge-less PFC converter. In addition, the rear-stage DC/DC converter can provide high-voltage and low-voltage outputs. It can also fl exibly switch the parking charging and driving charging modes through the control strategy combining the PFM and PS. Finally, the simulations and experiments verify the correctness of the theoretical analysis."
Resonance Analysis of Medium Voltage Multi-Microgrids Considering the Interaction of Controllable Series Compensator and Grid-Connected Inverters,2024,['Multi-microgrids · Series compensator · Resonance stability · Modal analysis method · Medium voltage'],국문 초록 정보 없음,"The interaction of a controlled series compensator (CSC) with other power electronics and basic power components in a multi-microgrid (MMG) maybe lead to complex resonance problems. In this paper, the frequency domain analysis method and the mode analysis method are combined to analyze the resonance characteristics of the medium-voltage microgrid cluster system under the action of two controllable series compensators, transformer-coupled series compensator (TCSC) and capacitive-coupled series compensator (CCSC). Firstly, based on the equivalent output impedance models of TCSC and CCSC, the equivalent output impedance characteristics of TCSC and CCSC are explored by frequency domain analysis. Secondly, combined with the impedance network model of cluster system, the resonance characteristics of the MMG after separate and together access to these two controllable series compensators at diferent locations are explored by modal analysis method. The results show that the equivalent output impedance of the two couple-type compensators in a certain frequency band is capacitive, and CCSC has a wider capacitive frequency band. Changes in controller parameter selection can afect band range and capacitance degree. The CSC control parameters afect the system resonance frequency and resonance center, and when the grid-connected inverter circuit parameters are diferent, the mode of system resonance will also change. The combination of frequency domain analysis and modal analysis is an efective means to study the resonance stability of microgrid cluster systems."
Analysis of Research Trends in Deep Learning-Based Video Captioning,2024,"['Video Captioning', 'Computer Vision', 'Natural Language Processing', 'Deep Learning', '비디오 캡션', '컴퓨터 비전', '자연어 처리', '딥러닝']",국문 초록 정보 없음,"Video captioning technology, as a significant outcome of the integration between computer vision and natural language processing,has emerged as a key research direction in the field of artificial intelligence. This technology aims to achieve automatic understandingand language expression of video content, enabling computers to transform visual information in videos into textual form. This paperprovides an initial analysis of the research trends in deep learning-based video captioning and categorizes them into four main groups:CNN-RNN-based Model, RNN-RNN-based Model, Multimodal-based Model, and Transformer-based Model, and explain the concept ofeach video captioning model. The features, pros and cons were discussed. This paper lists commonly used datasets and performanceevaluation methods in the video captioning field. The dataset encompasses diverse domains and scenarios, offering extensive resourcesfor the training and validation of video captioning models. The model performance evaluation method mentions major evaluation indicatorsand provides practical references for researchers to evaluate model performance from various angles. Finally, as future research tasksfor video captioning, there are major challenges that need to be continuously improved, such as maintaining temporal consistency andaccurate description of dynamic scenes, which increase the complexity in real-world applications, and new tasks that need to be studiedare presented such as temporal relationship modeling and multimodal data integration."
다중 센서 복합체 기반 가우시안 프로세스와 딥러닝을 활용한 해양 데이터 매핑 및선박 위치 추정 기법,2024,"['Multi-sensor', 'Gaussian process', 'Underwater data process', 'Deep learning', 'Localization']",국문 초록 정보 없음,"This research proposes a novel method for determining the location of vessels using a multi-sensor complex consisting of sound, magnetic, and depth sensors. The goal is to create a reliable and precise system that can overcome the limitations of individual sensors by integrating their data. Gaussian Process Regression (GPR) is employed to interpolate sparse data collected by the multi-sensor system, while a deep learning model based on the Transformer architecture is used to estimate the vessel's position. The system is designed to enhance accuracy and robustness, particularly in noisy marine environments. Our method shows potential for real-time applications in underwater localization, particularly in areas with high noise and interference."
Improved Deep Learning-based Approach for Spatial-Temporal Trajectory Planning via Predictive Modeling of Future Location,2024,"['Intelligent Transportation System', 'trajectory planning', 'future location', 'Location-Based Social Networks']",국문 초록 정보 없음,"Trajectory planning is vital for autonomous systems like robotics and UAVs, as it determines optimal, safe paths considering physical limitations, environmental factors, and agent interactions. Recent advancements in trajectory planning and future location prediction stem from rapid progress in machine learning and optimization algorithms. In this paper, we proposed a novel framework for Spatial-temporal transformer-based feed-forward neural networks (STTFFNs). From the traffic flow local area point of view, skip-gram model is trained on trajectory data to generate embeddings that capture the high-level features of different trajectories. These embeddings can then be used as input to a transformer-based trajectory planning model, which can generate trajectories for new objects based on the embeddings of similar trajectories in the training data. In the next step, distant regions, we embedded feedforward network is responsible for generating the distant trajectories by taking as input a set of features that represent the object's current state and historical data. One advantage of using feedforward networks for distant trajectory planning is their ability to capture long-term dependencies in the data. In the final step of forecasting for future locations, the encoder and decoder are crucial parts of the proposed technique. Spatial destinations are encoded utilizing location-based social networks(LBSN) based on visiting semantic locations. The model has been specially trained to forecast future locations using precise longitude and latitude values. Following rigorous testing on two real-world datasets, Porto and Manhattan, it was discovered that the model outperformed a prediction accuracy of 8.7% previous state-of-the-art methods."
Signal Augmentation Method based on Mixing and Adversarial Training for Better Robustness and Generalization,2024,"['Adversarial training', 'automatic modulation recognition', 'data augmentation', 'mixing signals', 'robustnes']",국문 초록 정보 없음,"More and more deep learning methods have been applied to wireless communication systems. However, the collection of authentic signal data poses challenges. Moreover, due to the vulnerability of neural networks, adversarial attacks seriously threaten the security of communication systems based on deep learning models. Traditional signal augmentation methods expand the dataset through transformations such as rotation and flip, but these methods improve the adversarial robustness of the model little. However, common methods to improve adversarial robustness such as adversarial training not only have a high computational overhead but also potentially lead to a decrease in accuracy on clean samples. In this work, we propose a signal augmentation method called Adversarial and Mixed-based Signal Augmentation (AMSA). The method can improve the adversarial robustness of the model while expanding the dataset and does not compromise the generalization ability. It combines adversarial training with data mixing and then interpolates selected pairs of samples to form new samples in an expanded dataset consisting of original and adversarial samples thus generating more diverse data. We conduct experiments on the RML2016.10a and RML2018.01a datasets using automatic modulation recognition (AMR) models based on CNN, LSTM, CLDNN, and Transformer. And compare the performance in scenarios with different numbers of samples. The results show that AMSA allows the model to achieve comparable or even better adversarial robustness than using adversarial training, and reduces the degradation of the model's generalization performance on clean data."
Improved Accuracy of Vehicle Part Detection and Damage Classification using YOLO Algorithm,2024,"['Computer Vision', 'Deep Learning', 'You Only Look Once', 'Vehicle Part Detection', 'Damage Classification']",국문 초록 정보 없음,"Continuous advancements in deep learning and computer vision has led to the utilization of such advanced technologies in the field of vehicle maintenance. This study developed vehicle part detection and damage classification models to help drivers develop effective repair plans for improved vehicle safety and performance. The You Only Look Once (YOLO) algorithm and transfer learning were used to train the vehicle part detection model, and the transformer method was to train the damage classification model. The proposed model achieved up to 95% vehicle parts detection accuracy, an improvement of 3% over that of the existing model, and a damage classification accuracy of 89%, an improvement of 6% over that of the existing model. With the recent rapid development of computer vision and deep learning technology, vehicle parts detection and damage classification are expected to provide new scientific method for vehicle repair."
ST-TrackFormer: 시공간 어텐션을 활용한  다중 객체 추적 성능 개선,2024,"['Multiple Object Tracking', 'TrackFormer', 'Spatial Attention', 'Temporal Attention']",국문 초록 정보 없음,"MOT(Multiple Object Tracking) plays a crucial role in various applications such as autonomous driving, pedestrian tracking, and video surveillance, with ongoing research aimed at improving tracking performance. However, MOT faces challenges in accurate tracking due to complex scenarios involving object interactions, occlusions, and overlaps across consecutive frames. This paper proposes a novel approach integrating Spatial and Temporal Attention into the Transformer-based TrackFormer model to address these issues. This integration effectively captures spatial relationships among objects within frames and temporal changes of objects across consecutive frames. Experiments conducted on MOT16, MOT17, and MOT20 datasets demonstrate that the proposed method outperforms the original TrackFormer model in key performance metrics. Notably, on the MOT20 dataset, which deals with dense crowd environments, our method achieved 78.2% MOTA, 71.8% IDF1, and 80.2% Recall. These results suggest that the proposed method can adapt to diverse environments and complexities, offering reliable object tracking performance in real-world scenarios."
Paper Recommendation Using SPECTER with Low-Rank and Sparse Matrix Factorization,2024,"['paper recommendation', 'SPECTER', 'low-rank and sparse matrix factorization', 'heterogeneous information network.']",국문 초록 정보 없음,"With the sharp increase in the volume of literature data, researchers must spend considerable time and energy locating desired papers. A paper recommendation is the means necessary to solve this problem. Unfortunately, the large amount of data combined with sparsity makes personalizing papers challenging. Traditional matrix decomposition models have cold-start issues. Most overlook the importance of information and fail to consider the introduction of noise when using side information, resulting in unsatisfactory recommendations. This study proposes a paper recommendation method (PR-SLSMF) using document-level representation learning with citation-informed transformers (SPECTER) and low-rank and sparse matrix factorization; it uses SPECTER to learn paper content representation. The model calculates the similarity between papers and constructs a weighted heterogeneous information network (HIN), including citation and content similarity information. This method combines the LSMF method with HIN, effectively alleviating data sparsity and cold-start issues and avoiding topic drift. We validated the effectiveness of this method on two real datasets and the necessity of adding side information."
Predicting Treatment Response to Antidepressants in Patients with Major Depressive Disorder Based on Longitudinal Clinical Data Using Artificial Intelligence: A Pilot Study,2024,"['Major depressive disorder', 'Treatment response', 'Prediction', 'Artificial intelligence']",국문 초록 정보 없음,"Background: The diagnosis of major depressive disorder (MDD) relies primarily on clinical interviews, which can be subjective and time consuming. Thus, there is a need for more objective diagnostic tools. The aim of this study was to develop an artificial intelligence (AI) application that predicts the antidepressant drug response of individual patients with MDD based on longitudinal data.Methods: Longitudinal data from patient records, including sex, age, outpatient or inpatient status, medication type and dosage, and the Hamilton Depression Rating Scale (HAMD) scores, were used to train the Transformer model and the 1-dimensional convolutional neural network model. Individual patient records were allocated to training (80%), validation (10%), and testing (10%) datasets.Results: The AI model demonstrated 88% sensitivity and 92% specificity for predicting the treatment response. Significant factors independently associated with the antidepressant response included age, sex, history of depression, and baseline HAMD scores.Conclusion: This AI-driven software application provides a clinically valuable tool for predicting treatment response. While promising, further research is needed to incorporate voice data into the AI model using the voice recording feature to further improve diagnostic accuracy."
Deep Learning Approaches for Robust QR Code Extraction and Verification in Music Applications,2024,"['QR code extraction', 'Deep learning', 'music industry', 'concerts', 'music events', 'Verification']",국문 초록 정보 없음,"Quick Response (QR) codes are essential in the music industry, especially with advancements in deeplearning. They are widely used for ticketing, music event promotions, and digital content distribution.However, challenges persist in pattern extraction and authentic QR code verification, particularly indynamic environments. Traditional methods struggle with issues such as poor lighting, complexbackgrounds, and advanced counterfeits, leading to compromised accuracy. This study introduces anenhanced method for QR code extraction, named Adaptive Morphological Contour-Based QR CodeExtraction (AMCQE), which employs a five-step process including grayscale conversion, Gaussian blur,thresholding, contour detection, and morphological closing. These steps improve QR code detectionfrom images with complex backgrounds and noise. Additionally, we propose a robust QR verificationprocess using a lightweight transformer-based architecture, Mobile-ViT, which enhances the model’sability to accurately distinguish between legitimate and counterfeit QR codes through globalrepresentation learning. Experimental results demonstrate excellent performance, achieving 99.28%accuracy with a processing time of 0.08 seconds, showcasing the method’s applicability in real-worldscenarios."
UAV Imagery-based Automatic Classification of Ground Surface Types for Earthworks,2024,"['Automated construction equipment', 'Ground surface', 'Unmanned aerial vehicle', 'Multi-label classification', 'Computer vision']",국문 초록 정보 없음,"The construction industry is introducing autonomous heavy equipment to overcome labor shortages and improve productivity. For autonomous heavy equipment to work on earthmoving at sites, the equipment needs to recognize and understand ground surface types. However, the ground surface types are manually inspected in practice, and related studies are lacking. To address this issue, the authors developed and tested models that automatically classify ground surface types from images acquired by an unmanned aerial vehicle using a deep learning-based multi-label classification method that applies Binary Relevance (BR) and Label Powerset (LP) methods with Residual Neural Network (ResNet) and Vision Transformer classification network (VIT). The model performances were comparatively evaluated through experiments conducted on actual construction sites. The results showed that the BR model with ResNet is the best model in terms of automated ground surface type identification during earthmoving. The results are expected to broaden the understanding of complex and expansive construction sites for autonomous vehicles and thus facilitate deployment of autonomous heavy equipment by helping them to understand working areas and any obstacles on construction sites quickly and effectively, which will reduce the cost and time needed for on-site ground surface management."
Aircraft Motion Identification Using Sub-Aperture SAR Image Analysis and Deep Learning,2024,"['Synthetic aperture radar', 'Moving target recognition', 'Deep learning', 'Sub-aperture']",국문 초록 정보 없음,"With advancements in satellite technology, interest in target detection and identification is increasing quantitatively and qualitatively. Synthetic Aperture Radar(SAR) images, which can be acquired regardless of weather conditions, have been applied to various areas combined with machine learning based detection algorithms. However, conventional studies primarily focused on the detection of stationary targets. In this study, we proposed a method to identify moving targets using an algorithm that integrates sub-aperture SAR images and cosine similarity calculations. Utilizing a transformer-based deep learning target detection model, we extracted the bounding box of each target, designated the area as a region of interest (ROI), estimated the similarity between sub-aperture SAR images, and determined movement based on a predefined similarity threshold. Through the proposed algorithm, the quantitative evaluation of target identification capability enhanced its accuracy compared to when training with the targets with two different classes. It signified the effectiveness of our approach in maintaining accuracy while reliably discerning whether a target is in motion."
자연어 처리의 개체명 인식을 통한 기록집합체의 메타데이터 추출 방안,2024,[],"본 연구는 인공지능의 하위분야인 자연어 처리(NLP)의 개체명 인식(NER)을 통하여기록에 내재된 메타데이터 값과 기술 정보를 추출하는 방안에 대한 시험적 연구이다.연구 대상은 1960~1970년대에 생산된 구로공단 수기 기록물(약 1,200 쪽, 8만여 단어)을대상으로 하였다.디지털화를 포함하는 전처리 과정과 함께 기록 텍스트에 대해서 구글의 BERT 언어모델에 기반하여 구현되어 공개된 언어 API를 사용하여 개체명을 인식하였다. 그 결과로구로공단의 과거 기록에 포함된 173개의 인명과 314개의 조직 및 기관 개체명을 추출할수 있었고, 이는 기록의 내용에 대한 직접적인 검색어로 사용될 수 있다고 기대된다.그리고 자연어 처리의 이론적 방법론을 반·비정형의 텍스트로 이루어진 실제 기록물에적용할 때 발생하는 문제점을 파악하여 해결 방안과 고려해야 할 시사점을 제시했다.","This pilot study explores a method of extracting metadata values and descriptions fromrecords using named entity recognition (NER), a technique in natural language processing(NLP), a subfield of artificial intelligence. The study focuses on handwritten recordsfrom the Guro Industrial Complex, produced during the 1960s and 1970s, comprisingapproximately 1,200 pages and 80,000 words.After the preprocessing process of the records, which included digitization, the studyemployed a publicly available language API based on Google’s Bidirectional EncoderRepresentations from Transformers (BERT) language model to recognize entity nameswithin the text. As a result, 173 names of people and 314 of organizations and institutionswere extracted from the Guro Industrial Complex’s past records. These extracted entitiesare expected to serve as direct search terms for accessing the contents of the records.Furthermore, the study identified challenges that arose when applying the theoreticalmethodology of NLP to real-world records consisting of semistructured text. It alsopresents potential solutions and implications to consider when addressing these issues."
Efficient Recognition of Easily-confused Chinese Herbal Slices Images Using Enhanced ResNeSt,2024,"['ResNeSt', 'multilevel perception fusion (MPF)', 'perceptive sparse fusion (PSF)', 'easily-confused CHS']",국문 초록 정보 없음,"Chinese herbal slices (CHS) automated recognition based on computer vision plays a critical role in the practical application of intelligent Chinese medicine. Due to the complexity and similarity of herbal images, identifying Chinese herbal slices is still a challenging task.Especially, easily-confused CHS have higher inter-class and intra-class complexity and similarity issues, the existing deep learning models are less adaptable to identify them efficiently. To comprehensively address these problems, a novel tiny easily-confused CHS dataset has been built firstly, which includes six pairs of twelve categories with about 2395 samples. Furthermore, we propose a ResNeSt-CHS model that combines multilevel perception fusion (MPF) and perceptive sparse fusion (PSF) blocks for efficiently recognizing easilyconfused CHS images. To verify the superiority of the ResNeSt-CHS and the effectiveness of our dataset, experiments have been employed, validating that the ResNeSt-CHS is optimal for easily-confused CHS recognition, with 2.1% improvement of the original ResNeSt model.Additionally, the results indicate that ResNeSt-CHS is applied on a relatively small-scale dataset yet high accuracy. This model has obtained state-of-the-art easily-confused CHS classification performance, with accuracy of 90.8%, far beyond other models (EfficientNet, Transformer, and ResNeSt, etc) in terms of evaluation criteria."
감성분석을 이용한 재난문자의 긴급성 평가,2024,"['Emergency Alerts', 'Natural Language Processing', 'Sentiment Analysis', 'Urgency Level evaluation', '감성분석', '긴급성 평가', '자연어 처리', '재난문자']",국문 초록 정보 없음,"Emergency alerts are crucial means for promptly and accurately conveying disaster information in urgent situations. However, as the type and frequency of emergency alerts delivered to the public increase, there has been a rise in public fatigue and a decline in trust. To evaluate the appropriateness of the emergency alert service, this study proposes models that evaluate urgency levels for emergency alerts based on sentiment analysis. The models are developed using four representative natural language processing algorithms.Furthermore, criteria and methodology for evaluating urgency levels are presented. In the experimental results, among the four algorithms, the urgency level evaluation model based on the Bidirectional Encoder Representations from Transformers algorithm showed the best learning performance with an accuracy of 98%.And through the four learned algorithm-based urgency level evaluation models, the urgency of the emergency alerts issued in 2022 was classified and evaluated."
Investigating Syntactic Transfer from English to Korean in Neural L2 Language Models,2024,"['neural language model', 'second language learning', 'linguistic transfer', 'L1 interference', 'syntactic/semantic information']",국문 초록 정보 없음,"This paper investigates how the grammatical knowledge obtained in the initial language (English) of neural language models (LMs) influences the learning of grammatical structures in their second language (Korean). To achieve this objective, we conduct the now well- established experimental procedure, including (i) pre-training transformer-based GPT-2 LMs with Korean and English datasets, (ii) further fine-tuning them with a specific set of Korean data as L1 or L2, and (iii) evaluating them with the test data of KBLiMP while analyzing their linguistic generalization in L1 or L2. We have found negative transfer effects in the comparison between English as L1 and Korean as L2. Furthermore, in the trajectory analysis, the second language-learning LM has captured linguistic features of Korean including syntax, syntax-semantics interface, and morphology during the progressive training step. Our study of second language learning in LMs contributes to predicting potential syntactic challenges arising from the interference by the L1 language during the learning of Korean as a foreign language."
Grammatical Transfer in L2 Neural Language Models,2024,"['neural language model', 'L2 learning', 'grammatical transfer', 'L1 interference', 'grammatical features']",국문 초록 정보 없음,"This study examines the impacts of initial grammatical knowledge from the first language (English) on the acquisition of grammatical structures in the second language (Korean) by neural language models (NLMs). To this end, we employ the standard experimental procedure in the rapidly-evolving field of natural language processing (NLP) that encompasses (i) pre-training Transformer-based GPT-2 NLMs on either Korean or English datasets, (ii) further fine-tuning them using a targeted set of Korean data as either the first or the second language, and (iii) assessing their performances using the K-BLiMP test data while analyzing their grammatical generalization capabilities. The findings in this study indicate that negative transfer effects arise in L2 NLMs when comparing models that learn Korean as the second language with those that learn Korean as the first language. Additionally, during the progression of training, the NLMs learning the second language attained the acquisition of its grammatical features, but to different degrees depending on the construction types tested. This study enhances our understanding of potential grammatical difficulties that may occur due to the interference from the first language when NLMs learn Korean as the second language."
"How to Harness the Power of GPT for Scientific Research: A Comprehensive Review of Methodologies, Applications, and Ethical Considerations",2024,['Generative Pre-trained Transformer (GPT) · Natural Language Processing · Research Efficiency · Prompt Engineering · Interdisciplinary Collaboration'],국문 초록 정보 없음,"The rapid advancements in natural language processing, particularly with the development of Generative Pre-trainedTransformer (GPT) models, have opened up new avenues for researchers across various domains. This review articleexplores the potential of GPT as a research tool, focusing on the core functionalities, key features, and real-world applicationsof the GPT-4 model. We delve into the concept of prompt engineering, a crucial technique for effectively utilizingGPT, and provide guidelines for designing optimal prompts. Through case studies, we demonstrate how GPT can beapplied at various stages of the research process, including literature review, data analysis, and manuscript preparation.The utilization of GPT is expected to enhance research efficiency, stimulate creative thinking, facilitate interdisciplinarycollaboration, and increase the impact of research findings. However, it is essential to view GPT as a complementary toolrather than a substitute for human expertise, keeping in mind its limitations and ethical considerations. As GPT continuesto evolve, researchers must develop a deep understanding of this technology and leverage its potential to advance theirresearch endeavors while being mindful of its implications."
Evaluating the accuracy and relevance of ChatGPT responses to frequently asked questions regarding total knee replacement,2024,"['ChatGPT', 'Artificial intelligence', 'Chatbot', 'Large language model', 'Total knee replacement', 'Total knee arthroplasty']",국문 초록 정보 없음,"Background Chat Generative Pretrained Transformer (ChatGPT), a generative artificial intelligence chatbot, may have broad applications in healthcare delivery and patient education due to its ability to provide human-like responses to a wide range of patient queries. However, there is limited evidence regarding its ability to provide reliable and useful information on orthopaedic procedures. This study seeks to evaluate the accuracy and relevance of responses provided by ChatGPT to frequently asked questions (FAQs) regarding total knee replacement (TKR).Methods A list of 50 clinically-relevant FAQs regarding TKR was collated. Each question was individually entered as a prompt to ChatGPT (version 3.5), and the first response generated was recorded. Responses were then reviewed by two independent orthopaedic surgeons and graded on a Likert scale for their factual accuracy and relevance. These responses were then classified into accurate versus inaccurate and relevant versus irrelevant responses using preset thresholds on the Likert scale.Results Most responses were accurate, while all responses were relevant. Of the 50 FAQs, 44/50 (88%) of ChatGPT responses were classified as accurate, achieving a mean Likert grade of 4.6/5 for factual accuracy. On the other hand, 50/50 (100%) of responses were classified as relevant, achieving a mean Likert grade of 4.9/5 for relevance.Conclusion ChatGPT performed well in providing accurate and relevant responses to FAQs regarding TKR, demonstrating great potential as a tool for patient education. However, it is not infallible and can occasionally provide inaccurate medical information. Patients and clinicians intending to utilize this technology should be mindful of its limitations and ensure adequate supervision and verification of information provided."
Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals,2024,"['Artificial intelligence', 'Generative artificial intelligence', 'Large language model', 'Synthetic data', 'Medical imaging']",국문 초록 정보 없음,"The emergence of Chat Generative Pre-trained Transformer (ChatGPT), a chatbot developed by OpenAI, has garnered interest in the application of generative artificial intelligence (AI) models in the medical field. This review summarizes different generative AI models and their potential applications in the field of medicine and explores the evolving landscape of Generative Adversarial Networks and diffusion models since the introduction of generative AI models. These models have made valuable contributions to the field of radiology. Furthermore, this review also explores the significance of synthetic data in addressing privacy concerns and augmenting data diversity and quality within the medical domain, in addition to emphasizing the role of inversion in the investigation of generative models and outlining an approach to replicate this process. We provide an overview of Large Language Models, such as GPTs and bidirectional encoder representations (BERTs), that focus on prominent representatives and discuss recent initiatives involving language-vision models in radiology, including innovative large language and vision assistant for biomedicine (LLaVa-Med), to illustrate their practical application. This comprehensive review offers insights into the wide-ranging applications of generative AI models in clinical research and emphasizes their transformative potential."
YOLOv8을 이용한 화재 검출 시스템 개발,2024,"['YOLOv8', 'Deep Neural Networks', 'Fire Detection', 'Transformer', 'CNN']",국문 초록 정보 없음,"It is not an exaggeration to say that a single fire causes a lot of damage, so fires are one of the disaster situations that must be alerted as soon as possible. Various technologies have been utilized so far because preventing and detecting fires can never be completely accomplished with individual human efforts. Recently, deep learning technology has been developed, and fire detection systems using object detection neural networks are being actively studied. In this paper, we propose a new fire detection system that improves the previously studied fire detection system. We train the YOLOv8 model using refined datasets through improved labeling methods, derive results, and demonstrate the superiority of the proposed system by comparing it with the results of previous studies."
저압 배전망에 접속된 분산전원이 고객 전압 관리에 미치는 영향 분석,2024,"['Intelligence electric distribution grid', 'Big data', 'Machine learning', 'Distribution asset condition prediction model']",국문 초록 정보 없음,"Voltage control has become more complex as distributed energy resources or electrical vehicles increase, but voltage control is essential to continuously increase the amount of power distribution lines connected to distributed energy resources. In this paper, we perform voltage measurement data analysis through AMI(Advanced Metering Infrastructure) to prevent voltage quality degradation due to connections of distributed energy resources through appropriate voltage control and to find ways to maintain a certain level of voltage quality. Through the analysis, it is possible to identify the correlation and voltage level of voltage changes due to the connection of distributed energy resources. Because OLTC(On Load Tap Changer) enables voltage regulation and phase shifting by varying the transformer ratio under load without interruption, OLTC is a representative voltage control method.Therefore, we attempt to understand the effect of applying OLTC which are representative voltage control method and the voltage quality management effect of distributed energy resource connection lines through the analysis of voltage volatility correlation for distributed energy resources. In addition, we attempt to find an appropriate control method to maintain the voltage quality of distribution lines connected to distributed energy resources."
딥러닝 기반 지반운동을 위한 하이패스 필터 주파수 결정 기법,2024,"['Convolutional neural network', 'Deep learning', 'Earthquake', 'FAS', 'Ground motion', 'High-pass filter', 'Transformer']",국문 초록 정보 없음,다국어 초록 정보 없음
