title,date,keywords,abstract,multilingual_abstract
U-Net 및 U-Net++ 구조 기반의 초단기 레이더 강우예측 모델 성능 비교,2024,"['U-Net++', '딥러닝', '레이더', '강우 예측', 'U-Net++', 'Deep learning', 'Radar', 'Rainfall forecast']","본 연구에서는 딥러닝 기반의 U-Net++ 모형을 활용하여 강우 레이더 예측 모델을 개발하고, 기존의 U-Net 모형과의 성능을 정량적으로 비교하였다. 강우 예측의 성능 평가는 CSI(Critical Success Index)와 RMSE(Root Mean Square Error)를 이용하여 강우 임계치에 따라 선행시간별로 수행되었다. 연구 결과, U-Net++ 모형은 U-Net 모형에 비해 RMSE가 전반적으로 낮아, 양적 예측 성능이 향상되었음을 확인하였다. 반면, CSI의 경우 기존 U-Net 모형이 더 높은 값을 보여 강우 발생 여부 예측에 있어 우수한 성능을 나타냈다. 그러나 임계치가 커지고 선행시간이 증가함에 따라 두 모델 모두 CSI가 감소하고 RMSE가 증가하는 경향을 보였다. 또한, 소양강 유역의 유역 면적 강수량을 지상 강우, 강우 레이더, U-Net++ 모형, 그리고 U-Net 모형을 활용하여 비교하였다. 총 8개의 강우사상을 대상으로 10분 간격으로 누적 유역 면적 강수량을 산정한 결과, U-Net++ 모형은 선행시간이 길어질수록 다소 과대 추정되는 경향이 있었지만, 60분까지의 누적 유역 면적 강수량 예측 성능에서는 U-Net 모형보다 우수함을 보였다. 특히, 강우량이 상대적으로 많은 사상에서 U-Net++ 모형은 지상 강우 및 강우 레이더와의 높은 유사도를 나타내었으며, RMSE 분석에서도 더 낮은 중앙값과 적은 변동성을 보여 예측 성능이 우수함을 확인하였다.","This study developed a rainfall radar nowcasting model using the deep learning based U-Net++ model and quantitatively compared its performance with the U-Net model. Performance evaluation of rainfall prediction was performed by the lead time according to the rainfall threshold using CSI(Critical success index), RMSE(Root Mean Square Error). As a result of the study, it was confirmed that the overall RMSE of the U-Net++ model was lower than that of the U-Net model, and thed quantitative prediction performance of rainfall was improved. On the other hand, in the case of CSI, the existing U-Net model showed a higher value, showing excellent performance in predicting the occurrence of rainfall. However, both models showed a tendency to decrease CSI and increase RMSE as the threshold increased and the lead time increased. In addition, the areal rainfall in the Soyang river basin was compared using ground rainfall, radar data, U-Net model, and U-Net++ model. As a result of calculating cumulative areal rainfall every 10 minutes for a total of 8 rainfall events, the U-Net++ model tended to be slightly overestimated as the lead time increased, but it was shown to be superior to the U-Net model in the cumulative areal rainfall prediction performance up to 60 minutes. In particular, the U-Net++ model showed high similarity to ground rainfall and rainfall and radar data in events with relatively high rainfall, and the RMSE analysis also showed lower median and less variability, confirming excellent prediction performance."
Sentinel-2 위성영상과 U-Net을 이용한 산불 피해지 추출 방법 연구,2024,"['산불', 'U-Net', 'Sentinel-2', '의미론적 분할모델', '산불 피해 지역', 'Wildfire', 'U-Net', 'Sentinel-2', 'Semantic Segmentation', 'Wildfire-affected areas']","최근 기후 온난화 경향이 심해짐에 따라 산불의 피해가 더욱 심해질 것으로 예상된다. 산불 피해 지역의 영향과 복구 등 효과적인 대응을 위해 산불 피해 지역의 공간 정보를 신속하고 정확하게 추출할 필요가 있다. 본 연구는 Sentinel-2 위성영상과 참조자료를 이용하여 딥러닝 기반 의미론적 분할모델인 U-Net을 훈련하고, 이를 바탕으로 산불 피해 지역을 추출하는 방법을 제시하고자 하였다. 이를 위해 2016년부터 2022년까지 국내 발생 산불 중 303건의 산불과 353장의 산불 영상에 대해 육안 판독에 기반하여 참조자료를 생성하고, 의미론적 분할모델인 U-Net을 훈련하였다. U-Net을 이용하여 추출한 결과는 전통적 위성영상 분류법 중 하나인 ISODATA 기법을 이용한 결과와 함께 정확도를 비교 및 평가하였다. 비교 결과 U-Net을 이용하는 것이 ISODATA보다 더 정확하게 산불 피해 지역을 추출하는 것으로 나타났다. U-Net 모델의 성능을 더 높일 수 있도록 학습자료를 보충하고, 일련의 과정을 자동화하면 시계열 국내 산불 피해 지역의 공간자료를 쉽게 생산할 수 있어 재난 관리 및 관련 연구에서 활용할 수 있을 것이다.","With the recent trend of climate warming, wildfires are expected to become more severe. It is essential to promptly and accurately extract spatial information on wildfire-affected areas for effective response, including impact assessment and facilitating recovery efforts. This study aims to train U-Net, a deep learning-based semantic segmentation model, using Sentinel-2 satellite imagery and reference data, and propose a method for extracting wildfire-affected areas based on it. To achieve this, we generated reference data through visual inspection for 303 wildfires and 353 wildfire images in Korea from 2016 to 2022, subsequently training the U-Net model. The extracted results from U-Net were then compared and evaluated for accuracy against those obtained using ISODATA, a traditional satellite image classification method. Our findings indicate that U-Net demonstrates superior accuracy in extracting wildfire-affected areas compared to ISODATA. By augmenting the training data to further enhance the U-Net model’s performance and automating the process, we can readily generate time-series spatial data of wildfireaffected areas in Korea. Such data can prove invaluable for disaster management and related research endeavors."
전기 정전용량을 기반으로 U-net 모델을 이용한 반도체후단 공정의 잔류물 모니터링,2024,"['Electrical capacitance', 'Two-phase flow', 'U-net', 'Image reconstruction', 'Inverse problem']","본 논문에서는, 시뮬레이션 상에서 반도체 후단 공정의 프로세스를 구현하고 파이프 내부 상황을 모니터링하기 위해 전기 정전용량을 기반으로 한 U-net 모델을 적용하였다. 배관에 부착된 전극에서 측정한 정전용량 값은 U-net 네트워크 모델의 입력 데이터로사용되며, 모델을 통해 추정한 유전율 분포를 가지고 파이프 단면을 이미지화하였다. 성능 평가를 위해 수치 시뮬레이션 얀에서U-net 모델, FCNN(Fully-connected neural network) 모델, Newton-Raphson 방법으로 재구성한 이미지를 비교한 결과,U-net이 다른 이미지 복원 방식보다 좋은 복원 성능을 보였다.","In this study, U-net model based on electrical capacitance is applied to monitor the condition inside thepipeline of semiconductor rear end process implemented in the numerical simulation. Capacitance values measuredfrom electrodes attached to the pipeline is used as input data for the U-net network model and estimated permittivitydistribution by the U-net model is used to reconstructed cross-sectional image at the pipeline. In the numericalsimulation, images reconstructed by U-net model, Fully-connected neural network (FCNN) model and Newton-Raphson method are compared for evaluation. U-net model shows good results as compared to other models."
이중 분기 디코더를 사용하는 복소 중첩 U-Net 기반  음성 향상 모델,2024,"['Speech enhancement', 'Complex nested U-Net', 'Dual-branch decoder', 'Spectral mapping', 'Time-frequency masking', '음성 향상', '복소 중첩 U-Net', '이중 분기 디코더', '스펙트럼 사상', '시간 주파수 마스킹']","본 논문에서는 이중 분기 디코더를 갖는 복소 중첩 U-Net 기반의 새로운 음성 향상 모델을 제안하였다. 제안된모델은 음성 신호의 크기와 위상 성분을 동시에 추정할 수 있도록 복소 중첩 U-Net으로 구성되며, 디코더는 스펙트럼사상과 시간 주파수 마스킹을 각각의 분기에서 수행하는 이중 분기 디코더 구조를 갖는다. 이때, 이중 분기 디코더 구조는 단일 디코더 구조에 비하여, 음성 정보의 손실을 최소화하면서 잡음을 효과적으로 제거할 수 있도록 한다. 실험은음성 향상 모델 학습을 위해 보편적으로 사용되는 VoiceBank + DEMAND 데이터베이스 상에서 이루어졌으며, 다양한 객관적 평가 지표를 통해 평가되었다. 실험 결과, 이중 분기 디코더를 사용하는 복소 중첩 U-Net 기반 음성 향상 모델은 기존의 베이스라인과 비교하여 Perceptual Evaluation of Speech Quality(PESQ) 점수가 0.13가량 증가하였으며, 최근 제안된 음성 향상 모델들보다도 높은 객관적 평가 점수를 보였다.","This paper proposes a new speech enhancement model based on a complex nested U-Net with a dual-branch decoder. The proposed model consists of a complex nested U-Net to simultaneously estimate the magnitude and phase components of the speech signal, and the decoder has a dual-branch decoder structure that performs spectral mapping and time-frequency masking in each branch. At this time, compared to the single-branch decoder structure, the dual-branch decoder structure allows noise to be effectively removed while minimizing the loss of speech information. The experiment was conducted on the VoiceBank + DEMAND database, commonly used for speech enhancement model training, and was evaluated through various objective evaluation metrics. As a result of the experiment, the complex nested U-Net-based speech enhancement model using a dual-branch decoder increased the Perceptual Evaluation of Speech Quality (PESQ) score by about 0.13 compared to the baseline, and showed a higher objective evaluation score than recently proposed speech enhancement models."
갑상선 초음파 영상의 평활화 알고리즘에 따른 U-Net 기반 학습 모델 평가,2024,"['히스토그램 평활화', '대비 제한 적응 히스토그램 평활화', '초음파', '의료영상', 'U-Net', 'HE', 'CLAHE', 'Ultrasound', 'Medical Image']",,"This study aims to evaluate the performance of the U-Net based learning model that may vary depending on the histogram equalization algorithm. The subject of the experiment were 17 radiology students of this college, and 1,727 data sets in which the region of interest was set in the thyroid after acquiring ultrasound image data were used. The training set consisted of 1,383 images, the validation set consisted of 172 and the test data set consisted of 172. The equalization algorithm was divided into Histogram Equalization(HE) and Contrast Limited Adaptive Histogram Equalization(CLAHE), and according to the clip limit, it was divided into CLAHE8-1, CLAHE8-2. CLAHE8-3. Deep Learning was learned through size control, histogram equalization, Z-score normalization, and data augmentation. As a result of the experiment, the Attention U-Net showed the highest performance from CLAHE8-2 to 0.8355, and the U-Net and BSU-Net showed the highest performance from CLAHE8-3 to 0.8303 and 0.8277. In the case of mIoU, the Attention U-Net was 0.7175 in CLAHE8-2, the U-Net was 0.7098 and the BSU-Net was 0.7060 in CLAHE8-3. This study attempted to confirm the effects of U-Net, Attention U-Net, and BSU-Net models when histogram equalization is performed on ultrasound images. The increase in Clip Limit can be expected to increase the ROI match with the prediction mask by clarifying the boundaries, which affects the improvement of the contrast of the thyroid area in deep learning model learning, and consequently affects the performance improvement."
YOLO v5를 이용한 U-Net3+모델 기반 Semantic-Segmentation 성능 개선,2024,"['semantic-segmentation', 'YOLO', 'U-Net3+', 'object detection', 'mIoU', '.']","최근 영상처리 딥러닝 기술의 발달로 객체인식, 이미지 분할은 다양한 분야에 사용되고 있다. 하지만 객체인식, 이미지 분할을 학습하기 위한 데이터 생성은 쉬운 일이 아니다. 따라서 본 논문에서는 추가적인 데이터 생성 없이 YOLO(You Only Look Once), U-Net3+기반의 모델에서 효율적인 학습이 가능하도록 하는 시스템을 제안 및 구현한다. 제안된 시스템은 YOLO v5의 v5s 모델을 사용하여 1차적으로 객체인식을 수행한다. 이후 YOLO를 거쳐 출력된 객체인식 데이터는 U-Net3+기반의 모델에 입력데이터로써 사용된다. 제안된 방법을 평가하기 위해 기존의 U-Net3+기반으로만 작성된 시스템과 비교하였다. 실험 결과 제안된 방법이 평균 0.1 이상의 향상된 mIoU 결과를 보였다. 이는 제안된 방법이 데이터 생성 없이 효과적으로 이미지 분할의 성능을 개선시킬 수 있음을 확인할 수 있었다.","Recent advancements in deep learing technology for image processing have enabled the use of object detection and segmentation in various fields. However, data labeling and generation for learning object detection and segmentation are not easy tasks. Therefore, this paper proposes and implements a system that enables efficient training in a You Only Look Once(YOLO) and U-Net3+ based model without the need for additional data generation. The proposed system performs initial object detection using YOLO v5s. The object detection data output by YOLO v5s is then used as input for a U-Net3+ based model. To evaluate the proposed method, we compared it with a system based solely on the existing U-Net3+ model. Experimental results showed that the proposed method achieved an improvement of over 0.1 in mean Intersection over Union(mIoU) on average. This demonstrates that the proposed method can effectively improve segmentation performance without generating additional data."
음성인식 개선을 위한 Variational U-Net 기반 왜곡된 오디오 재구축,2024,"['웨이브 유-넷 신경망', '오토인코더', '딥 러닝', '음성인식 개선', '오디오 왜곡 복구', 'wave U-Net', 'autoencoder', 'deep learning', 'speech enhancement', 'distortion restoration']","부적절한 녹음 조건과 장비로 인한 오디오 신호의 왜곡은 정확한 음성 인식 및 양질의 오디오 분석에 어려움을 야기한다. 오디오 왜곡을 복구할 때는 그 다양성과 복잡성, 그리고 예측 불가능한 특성을 효과적으로 관리할 수 있는 정교한 방법이 요구된다. 본 논문에서는 변분 추론의 확률적 모델링 능력과 Wave U-Net 신경망의 공간 및 시간적 정보 보존된 재구축 강점을 결합한 Variational U-Net 신경망을 제안한다. 모델은 변분 추론을 통해 깨끗한 오디오 신호의 분포를 효율적으로 포착하여 다양한 왜곡에 영향받는 오디오의 확률적인 생성을 용이하게 한다. 동시에, Wave U-Net 구조를 본 모델에 적용하여 유효한 오디오 세부 특징의 보존을 보장하여 복원된 신호의 품질을 향상시킨다. 제안하는 방법은 실제 세계의 오디오 왜곡 시나리오를 통제된 설정에서 반영할 수 있는 Audio MNIST 데이터셋에서 엄격하게 평가되었다. 성능은 네 가지 최신 딥러닝 알고리즘과의 비교를 포함하여 공정하게 비교되었으며, 제안하는 방법은 다른 방법에 대비하여 SI-SDR 기준으로 +4.0dB의 유의미한 개선을 보였다.","Inadequate recording conditions and equipment leads to distortion in recorded audio signals, which makes it difficult to achieve accurate speech recognition and quality audio analysis. Recovering audio distortion requires the use of sophisticated methods that are capable of effectively managing its diversity, complexity, and unpredictable nature. This paper proposes the Variational U-Net neural network, which combines the probabilistic modeling capabilities of variational inference with the strengths of the Wave U-Net neural network in terms of preserving spatial and temporal information during reconstruction. Through variational inference, the model efficiently captures the distribution of clean audio signals, thus facilitating the probabilistic generation of audio affected by various distortions. Simultaneously, the adaptation of the Wave U-Net structure to our model ensures that valid audio details are preserved, thus enhancing the quality of the restored signal. The proposed method was rigorously evaluated using the Audio MNIST dataset, which simulates real-world audio distortion scenarios in a controlled environment. The proposed method’s performance was compared against four state-of-the-art deep learning algorithms, and the proposed method ultimately demonstrated a significant improvement of +4.0dB in SI-SDR compared to other methods."
U-Net 기반 의미분할 알고리즘의 개선 기술,2024,"['U-Net', 'Semantic Segmentation', 'Super resolution', 'Fourier Transform', 'Convolutional Block Attention Module']","본 논문에서는 U-Net 기반의 의미분할 알고리즘을 개선하여 성능을 향상시키기 위한 새로운 접근 방안을 제시하였다. 제안된 방법은 초해상도(SR) 기술을 도입하여 입력 이미지의 해상도를 개선하고, 컨볼루션 블록 어텐션 모듈(CBAM)을 활용하여 중요한 특징을강조하며, 푸리에 변환을 통해 전역적 정보를 보존하였다. 이러한 개선 요소들은 의미분할의 정확도를 높이기 위해 효과적으로 작용하였다. 특히, 초해상도 기술은 입력 이미지의 디테일을 살려 의미분할의 정밀도를 높이는 데 기여하였다. 또한, CBAM을 통해 각 특징맵의 중요한 부분을 강조하여 네트워크의 성능을 극대화하였다. 마지막으로, 푸리에 변환을 사용하여 전역적인 주파수 정보를 보존함으로써 보다 일관된 분할 결과를 얻을 수 있었다. 실험 결과, 제안된 방법은 BCEWithLogitsLoss, IoU, Dice 계수 등 다양한 평가 지표에서 기존의 U-Net 및 다른 변형 모델보다 우수한 성능을 보였다. 특히, 제안된 방법은 IoU와 Dice 계수에서 현저한 성능 향상을보여주었으며, 이는 실제 의미분할 작업에서의 실용성을 높이는 데 중요한 역할을 하였다. 이러한 결과는 제안된 방법이 의료 영상 분석, 자율 주행, 위성 이미지 분석 등 다양한 응용 분야에서의 의미분할 작업에 기여할 수 있음을 시사한다. 본 논문은 향후 연구에 있어 의미분할 알고리즘의 성능을 더욱 향상시키기 위한 기초 자료로 활용될 수 있을 것이다.","This paper presents a novel approach to improving the performance of U-Net-based semantic segmentation algorithms. Theproposed method enhances input image resolution using super-resolution (SR) technology, emphasizes key features through theConvolutional Block Attention Module (CBAM), and preserves global information using Fourier Transform. These improvementseffectively enhance the accuracy of semantic segmentation. Specifically, the super-resolution technology contributes to increasing theprecision of segmentation by preserving details in the input images. Additionally, CBAM maximizes network performance byhighlighting important regions in each feature map. Lastly, the use of Fourier Transform allows for more consistent segmentationresults by maintaining global frequency information. Experimental results demonstrate that the proposed method outperformstraditional U-Net and other modified models across various evaluation metrics, including BCEWithLogitsLoss, IoU, and Dicecoefficient. Notably, the proposed method shows significant improvement in IoU and Dice coefficients, playing a crucial role inenhancing the practical applicability of semantic segmentation tasks. These results suggest that the proposed method can contributeto various applications of semantic segmentation, such as medical image analysis, autonomous driving, and satellite image analysis.This paper can serve as a foundational resource for future research aimed at further enhancing the performance of semanticsegmentation algorithms."
설진 영상의 혀 영역 자동 분할을 위한 U-Net 기반 딥러닝 알고리즘,2024,"['Tongue image segmentation', 'U-Net', 'Tongue diagnosis', 'Tongue region segmentation', 'Deep learning', 'Convolutional neural network']",,"Research on improving the accuracy of tongue region segmentation in the deep learning process of Korean medicine's tongue diagnosis is actively ongoing. This study aims to propose a segmentation model based on the U-Net using Convolutional Neural Networks (cNN). Binary mask images representing the tongue region were created, and the dataset was randomly divided into an 8:2 ratio for the train and test set. To prevent overfitting, the changes in validation loss were monitored at each epoch. Finally, Dice similarity coefficient (DSC) and Jaccard index (JI) were computed to measure the accuracy of the segmentation model in identifying the target regions. The modified U-Net network showed a significant level of accuracy in tongue region segmentation and minimal overfitting despite a small number of training data sets. The accuracy in the train set reached 0.997 and in the test set the accuracy was 0.993. The Dice similarity coefficient (DSC) score on the test dataset was 0.981 ± 0.017 and the Jaccard index (JI) score was 0.964 ± 0.031. The proposed model based on U-Net for tongue region extraction is anticipated to be effective for practical applications such as computerized tongue analysis systems."
짝지어진 데이터셋을 이용한 분할-정복 U-net 기반 고화질 초음파 영상 복원,2024,"['Ultrasound imaging', 'Image quality enhancement', 'Paired dataset', 'U-net', 'Divide and conquer']",,"Commonly deep learning methods for enhancing the quality of medical images use unpaired dataset due to the impracticality of acquiring paired dataset through commercial imaging system. In this paper, we propose a super- vised learning method to enhance the quality of ultrasound images. The U-net model is designed by incorporating a di- vide-and-conquer approach that divides and processes an image into four parts to overcome data shortage and shorten the learning time. The proposed model is trained using paired dataset consisting of 828 pairs of low-quality and high-quality images with a resolution of 512x512 pixels obtained by varying the number of channels for the same subject. Out of a total of 828 pairs of images, 684 pairs are used as the training dataset, while the remaining 144 pairs served as the test data- set. In the test results, the average Mean Squared Error (MSE) was reduced from 87.6884 in the low-quality images to 45.5108 in the restored images. Additionally, the average Peak Signal-to-Noise Ratio (PSNR) was improved from 28.7550 to 31.8063, and the average Structural Similarity Index (SSIM) was increased from 0.4755 to 0.8511, demonstrating sig- nificant enhancements in image quality."
Performance Comparison of Water Body Detection from Sentinel-1 SAR and Sentinel-2 Optical Imagery Using Attention U-Net Model,2024,"['Sentinel-1', 'Sentinel-2', 'Attention U-Net', 'Water body detection', 'Deep learning']",,"As global warming accelerates greenhouse gas emissions, the frequency and severity of abnormal weather events such as floods and droughts are increasing, complicating disaster management and amplifying socio-economic damage. In response, effective strategies for mitigating water-related disasters and proactively addressing climate change are essential, which can be achieved through the use of satellite imagery. This study aims to compare the water body detection performance of Sentinel-1 Synthetic Aperture Radar (SAR) and Sentinel-2 optical imagery using the Attention U-Net model. Through this comparison, the study seeks to identify the strengths and limitations of each satellite imagery type for water body detection. A 256 × 256-pixel patch dataset was developed using multi-temporal imagery from the Han River and Nakdong River basins to reflect seasonal variations in water bodies, including conditions during wet, dry, and flood seasons. Additionally, the study evaluates the impact of data augmentation techniques on model performance, emphasizing the need to select augmentation methods that align with the specific characteristics of SAR and optical data. The results demonstrate that Sentinel-1 SAR imagery exhibited stable performance in detecting large water bodies, achieving high precision in defining water boundaries (Intersection over Union [IoU]: 0.964, F1-score: 0.982). In contrast, Sentinel-2 optical imagery achieved slightly lower accuracy (IoU: 0.880, F1-score: 0.936) but performed well in detecting complex water boundaries, such as those found in wetlands and riverbanks. While data augmentation techniques improved the performance of the Sentinel-1 SAR dataset, they had only a marginal effect on Sentinel-2 optical imagery, aside from slight improvements in boundary detection under new environmental conditions. Overall, this study underscores the importance of threshold and satellite imagery integration for water body monitoring. It further emphasizes the value of selecting appropriate data augmentation techniques tailored to the characteristics of each dataset. The insights from this study offer guidance for developing enhanced water resource management strategies to mitigate the impacts of climate change."
익사 사례에서 Postmortem CT 영상을 활용한 U-Net 기반 나비굴 내 액체 자동 분할: 타당성 연구,2024,"['Postmortem computed tomography', 'Drowning', 'Sphenoid sinus fluid', 'Deep learning', 'Segmentation']",,"Detecting sphenoid sinus fluid (SSF) is an additional finding in autopsies for diagnosing drowning. SSF can provide additional forensic evidence through laboratory tests such as diatom and electrolyte analyses. If drowning is suspected, accurately assessing the presence and volume of SSF during an autopsy is crucial. Utilizing postmortem computed tomography (PMCT) images could aid in accurately sampling SSF. Accurately segmenting the region of interest is essential for volume analysis using computed tomography images. However, manual segmentation techniques are labor-intensive and time-consuming, and their success depends on the experience of the observer. Therefore, this study aimed to develop a U-Net–based deep learning model for the automatic segmentation of SSF in drowning cases using PMCT images and to evaluate the performance of the model. We retrospectively reviewed 34 drowning cases in which both PMCT scans and forensic autopsies were performed at our institution. The U-Net architecture of deep learning was used for automatic segmentation. The proposed model achieved the Dice similarity coefficient (DSC) and Intersection over Union (IoU) of a maximum of 95.85% and 92.03%, a minimum of 0% and 0%, and an average of 77.15% and 67.18%, respectively. Although the average DSC and IoU did not show high similarity, this study showed that PMCT images can be used for automatic segmentation of SSF in drowning cases, which could improve the performance with sufficient dataset acquisition and further model training."
U-Net을 이용한 무인항공기 비정상 비행 탐지 기법 연구,2024,"['UAV(무인항공기)', 'Abnormal Flight(비정상 비행)', 'UAM(도심형 항공 교통 체계)', 'Deep Learning Model(딥러닝 모델)', 'Mahalanobis Distance(마할라노비스 거리)']",최근에 무인항공기의 실용화 및 사업화가 추진됨에 따라 무인항공기의 안전성 확보에 관한 관심이 증가하고 있다. 무인항공기의 사고는 재산 및 인명 피해를 발생시키기 때문에 사고를 예방할 수 있는 기술의 개발은 중요하다. 이러한 이유로 AutoEncoder 모델을 이용한 비정상 비행 상태 탐지 기법이 개발되었다. 그러나 기존 탐지 기법은 성능과 실시간 처리 측면에서 한계를 지닌다. 본 논문에서는 U-Net 기반 비정상 비행 탐지 기법을 제안한다. 제안하는 기법에서는 U-Net 모델에서 얻어지는 재구성 오차에 대한 마할라노비스 거리 증가량에 기반하여 비정상 비행이 탐지된다. 모의실험을 통해 제안 탐지 기법이 기존 탐지 기법에 비해 탐지 성능이 우수하며 온보드 환경에서 실시간으로 구동될 수 있음을 알 수  있다.,"Recently, as the practical application and commercialization of unmanned aerial vehicles (UAVs) is pursued, interest in ensuring the safety of the UAV is increasing. Because UAV accidents can result in property damage and loss of life, it is important to develop technology to prevent accidents. For this reason, a technique to detect the abnormal flight state of UAVs has been developed based on the AutoEncoder model. However, the existing detection technique is limited in terms of performance and real-time processing. In this paper, we propose a U−Net based abnormal flight detection technique. In the proposed technique, abnormal flight is detected based on the increasing rate of Mahalanobis distance for the reconstruction error obtained from the U−Net model. Through simulation experiments, it can be shown that the proposed detection technique has superior detection performance compared to the existing detection technique, and can operate in real-time in an on-board environment."
T2 TSE MR 영상에서의 U-net 딥러닝 네트워크 기반의 초고해상도 영상 복구 성능 평가,2024,"['T2 고속스핀에코 자기공명영상', '선형 보간법', '딥러닝 네트워크', '초고해상도 영상', '의료영상 복원', 'T2 turbo spin echo MRI', 'interpolation methods', 'deep learning network', 'super-resolution image', 'medical image restoration']","자기공명영상(MRI) 기술은 연부조직의 신호를 수집해 디지털 영상으로 변환하는 방법이며, T2 고속 스핀 에코 기법은 짧은 획득 시간과 높은 영상 품질로 병변 검출에 널리 사용된다. 저해상도 영상을 고해상도로 복원할 때 일반적으로 선형 보간법이 사용되었지만, 최근에는 딥러닝 기반 알고리즘을 활용한 초고해상도 복원 연구가 주목받고 있다. 본 연구는 U-Net 딥러닝 네트워크와 선형 보간법을 사용해 저해상도 T2 영상을 고해상도로 복원하고, 원본 MRI 영상과의 유사도를 비교하였다. 512 × 512 해상도의 M RI 데이터를 기반으로 128 × 128 및 256 × 256 저해상도 영상을 생성 후 복원하였으며, PSNR과 SSIM 평가 결과, U-Net 모델을 활용한 초고해상도 영상이 기존 선형 보간법보다 원본 영상에 더 유사함을 확인하였다.","Magnetic Resonance Imaging (MRI) uses magnetic fields to acquire signals from soft tissues and convert them into digital images.The T2 turbo spin echo (TSE) pulse sequence is widely applied for lesion detection due to its efficiency and image quality. While linear interpolation is commonly used to upscale low-resolution images, recent advances in deep learning, particularly with U-Net networks, have shown potential for super-resolution image restoration. This study aimed to generate super-resolution T2 TSE images using both linear interpolation and deep learning method, comparing similarity to the original MRI images. Using 300 MRI images, low-resolution images were generated and restored using nearest-neighbor linear interpolation and U-Net deep learning network.Evaluations based on peak signal to noise ratio (PSNR) and structural similarity index measure (SSIM) demonstrated that U-Net generated super-resolution images had better similarity to the original images compared to those restored through linear interpolation."
U2-Net을 활용한 생굴 부피 추정 시스템의 개발,2024,"['volume estimation', 'classification', 'automation', 'image processing', '.']",,"This study proposes an advanced image processing algorithm and a volume estimation system for automating the oyster process. Using top and side cameras, our algorithm effectively captures object features under varying moisture and lighting conditions, mitigating light reflection issues. The image processing algorithm consists of object extraction, capturing, feature extraction, and width calculation algorithms. These components accurately extract objects from multiple camera inputs, store the images, and calculate object width using the side camera, providing essential data for volume estimation based on the disc method. Experiments conducted on model and raw oysters demonstrated the system’s robust performance, achieving classification accuracies of 98.5% and 100%, respectively. The system’s high accuracy and reliability across various environmental conditions make it suitable for size classification tasks."
MEDU-Net+: a novel improved U-Net based on multi-scale encoder-decoder for medical image segmentation,2024,"['Medical image segmentation', 'Deep learning', 'U-Net', 'Multi-scale feature fusion', 'Skip connection']",,"The unique U-shaped structure of U-Net network makes it achieve good performance in image segmentation. This network is a lightweight network with a small number of parameters for small image segmentation datasets. However, when the medical image to be segmented contains a lot of detailed information, the segmentation results cannot fully meet the actual requirements. In order to achieve higher accuracy of medical image segmentation, a novel improved U-Net network architecture called multi-scale encoder-decoder U-Net+ (MEDU-Net+) is proposed in this paper. We design the GoogLeNet for achieving more information at the encoder of the proposed MEDU-Net+, and present the multi-scale feature extraction for fusing semantic information of different scales in the encoder and decoder. Meanwhile, we also introduce the layer-by-layer skip connection to connect the information of each layer, so that there is no need to encode the last layer and return the information. The proposed MEDU-Net+ divides the unknown depth network into each part of deconvolution layer to replace the direct connection of the encoder and decoder in U-Net. In addition, a new combined loss function is proposed to extract more edge information by combining the advantages of the generalized dice and the focal loss functions. Finally, we validate our proposed MEDU-Net+ MEDU-Net+ and other classic medical image segmentation networks on three medical image datasets. The experimental results show that our proposed MEDU-Net+ has prominent superior performance compared with other medical image segmentation networks."
경량화 U-Net을 사용한 엣지 디바이스용 미세플라스틱 이미지 분할,2024,"['미세플라스틱', '이미지 분할', '경량화', '인공신경망', 'U-Net', 'depthwise separable 합성곱', 'microplastic', 'image segmentation', 'lightweighting', 'U-Net', 'depthwise separable convolution']","해양 생태계에 부적절한 영향을 끼치는 미세플라스틱을 검출하여 배출되는 양을 줄이는 작업이 필요하다. 미세플라스틱은 현미경 이미지 분할 딥러닝 모델을 적용해 검출할 수 있는데, 정확도를 높이기 위해서는 데이터의 다운샘플링을 지양하는 것이 중요하다. 하지만, 이를 위해서는 일반적으로 모델의 파라미터 및 연산량이 증가하는 문제가 있어 휴대형 장치에 실시간으로 동작하기 어렵다. 따라서 딥러닝 모델을 휴대형 장치를 사용해 현장에서 채취한 시료로부터 즉각 미세플라스틱을 검출하는 과정에는 적용하기 위해서는 데이터의 해상도를 유지하되 경량화 된 모델이 필요하다. 모델 경량화 실험을 위해서 이미지 분할 분야의 대표적인 모델인 U-Net의 합성곱 계층에 기존의 다양한 경량화 방법을 적용하여 U-Net과의 성능을 비교하였다. Depthwise Separable 합성곱 계층을 사용한 경우 U-Net에 비하여 유사한 mIoU 성능을 보이며, 82.6% 감소된 연산량을 보였다. 또 행렬 분해 및 Group 합성곱을 적용한 경우는 U-Net에 비해 7.41%의 mIoU 성능 하락이 있었지만, 99.55% 감소된 연산량을 보인다. 이는 현장에서 즉각적으로 데이터를 취득해야 하는 휴대형 장치에 적용해 이점을 얻을 수 있을 것으로 생각된다.","There is a need to detect microplastics that adversely affect marine ecosystems and reduce their emissions. Microplastics can be detected by applying deep learning models to segment microscopic images. While it is important to avoid downsampling the data to improve accuracy, this usually requires an increase in model parameters and computation, making it difficult to operate in real-time on mobile devices. Therefore, to apply deep learning models to the process of instant microplastic detection from samplescollected in the field using mobile devices, a lightweight model is required while maintaining the resolution of the data. For the model lightweight experiment, we applied various existing lightweight methods to the convolution layer of U-Net, a representative model in the image segmentation field, and compared its performance with U-Net. The Depthwise Separable convolution layer shows mIoU performance that is comparable to that of U-Net, with 82.6% less computation. In addition, the Matrix Factorization and Group convolution layers show 99.55% less computation, although there is a 7.41% mIoU performance drop compared to U-Net. This is thought to be beneficial for mobile devices that require immediate data acquisition in the field."
U-Net 기반 이미지 분할 및 병변 영역 식별을 활용한 반려견 피부질환 검출 모바일 앱,2024,"['반려견 피부질환', 'U-Net 모델', '이미지 세그멘테이션', '모바일 애플리케이션', 'Canine Skin Diseases', 'U-Net Model', 'Image Segmentation', 'Mobile Application']",,
Quantitative Evaluation of a Deep Learning-based U-Net Model for Denoising Lung CT Images,2024,"['denoising', 'U-net', 'lung CT image', 'radiation electromagnetic field.']",,"This study explores the efficacy of the U-Net architecture for denoising lung CT images that have undergone the introduction of artificially added Gaussian noise. Noise in medical imaging can significantly compromise diagnostic accuracy, prompting the utilization of U-Net to mitigate this challenge. We set the noise standard deviations of 0.03, 0.05, and 0.07, employing metrics such as Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), and skewness and kurtosis of patch-based statistics difference across a dataset of 100 CT DICOM files. The results exhibited substantial enhancements in evaluating metrics following denoising, underscoring the model's capability to effectively alleviate noise and enhance diagnostic reliability. Despite positive evaluation metric results, blurring effects led to the loss of anatomical information, demonstrating the necessity for further advancements in denoising techniques. This research provides a foundational framework for the development of robust methodologies aimed at improving the quality of medical imaging."
Precise segmentation of fetal head in ultrasound images using improved U-Net model,2024,"['ellipse fitting', 'head circumference', 'ultrasound images', 'U-Net']",,"Monitoring fetal growth in utero is crucial to anomaly diagnosis. However, current computer-vision models struggle to accurately assess the key metrics (i.e., head circumference and occipitofrontal and biparietal diameters) from ultrasound images, largely owing to a lack of training data. Mitigation usually entails image augmentation (e.g., flipping, rotating, scaling, and translating). Nevertheless, the accuracy of our task remains insufficient. Hence, we offer a U-Net fetal head measurement tool that leverages a hybrid Dice and binary cross-entropy loss to compute the similarity between actual and predicted segmented regions. Ellipse-fitted two-dimensional ultrasound images acquired from the HC18 dataset are input, and their lower feature layers are reused for efficiency. During regression, a novel region of interest pooling layer extracts elliptical feature maps, and during segmentation, feature pyramids fuse field-layer data with a new scale attention method to reduce noise. Performance is measured by Dice similarity, mean pixel accuracy, and mean intersection-over-union, giving 97.90%, 99.18%, and 97.81% scores, respectively, which match or outperform the best U-Net models."
Deep U-NET Based Heating Film Defect Inspection System,2024,"['Machine vision', 'U-Net', 'Deep learning', 'Automated production', 'Real-time defect detection', 'Heating film']",,"This study introduces a real-time, high-resolution image inspection system that utilizes multiple cameras and deep learning algorithms for the real-time detection of pinholes and scratches on large-area heating films. To accommodate the repetitive inspection processes inherent in products with consistent patterns, the system operates at the region level rather than the frame level. By modifying the U-Net architecture, the system achieved precise segmentation of the inspection area, enabling real-time detection of microscale pinholes and scratches. Additionally, a sticker marker was developed to label the defective regions detected on the film. The proposed system was experimentally validated in an actual production environment, where it demonstrated an impressive 96.6% accuracy in area inspection and a 97.5% defect detection rate at a transportation speed of 12 m/min. These results serve as clear evidence of the effectiveness and practicality of the automatic detection capability facilitated by deep learning in production processes."
전기 정전용량을 기반으로 U-net 모델을 이용한 반도체 후단 공정의 잔류물 모니터링,2024,"['Electrical capacitance', 'Two-phase flow', 'U-net', 'Image reconstruction', 'Inverse problem']",,
혼합 열화 영상 복원을 위한 2단계 U-Net 트랜스포머,2024,"['Image Restoration', 'Mixed Degradation', 'Transformer', 'Computer Vision', 'Deep Learning']",,
U-Net-based Recommender Systems for Political Election System using Collaborative Filtering Algorithms,2024,"['Demographics', 'Collaborative Filtering algorithms', 'e-Government services', 'e-democracy']",,"User preferences and ratings may be anticipated by recommendation systems, which are widely used in social networking, online shopping, healthcare, and even energy efficiency. Constructing trustworthy recommender systems for various applications, requires the analysis and mining of vast quantities of user data, including demographics. This study focuses on holding elections with vague voter and candidate preferences. Collaborative user ratings are used by filtering algorithms to provide suggestions. To avoid information overload, consumers are directed towards items that they are more likely to prefer based on the profile data used by recommender systems. Better interactions between governments, residents, and businesses may result from studies on recommender systems that facilitate the use of e-government services. To broaden people’s access to the democratic process, the concept of “e-democracy” applies new media technologies. This study provides a framework for an electronic voting advisory system that uses machine learning."
U-Net 기반 아키텍처를 활용한 울혈성 심부전 환자 폐부종 진단 방법론 연구,2024,"['시맨틱 분할', '흉부 방사선 검사', '울혈성 심부전', '폐부종', 'Sementic Segmentation', 'Chest X-Ray', 'Congestive Heart Failure', 'Pulmonary Edema']",,
Automated Detection and Segmentation of Bone Metastases on Spine MRI Using U-Net: A Multicenter Study,2024,"['Bone neoplasms', 'Deep learning', 'Magnetic resonance imaging', 'Metastasis', 'Spine']",,"Objective: To develop and evaluate a deep learning model for automated segmentation and detection of bone metastasis on spinal MRI.Materials and Methods: We included whole spine MRI scans of adult patients with bone metastasis: 662 MRI series from 302 patients (63.5 ± 11.5 years; male:female, 151:151) from three study centers obtained between January 2015 and August 2021 for training and internal testing (random split into 536 and 126 series, respectively) and 49 MRI series from 20 patients (65.9 ± 11.5 years; male:female, 11:9) from another center obtained between January 2018 and August 2020 for external testing. Three sagittal MRI sequences, including non-contrast T1-weighted image (T1), contrast-enhanced T1- weighted Dixon fat-only image (FO), and contrast-enhanced fat-suppressed T1-weighted image (CE), were used. Seven models trained using the 2D and 3D U-Nets were developed with different combinations (T1, FO, CE, T1 + FO, T1 + CE, FO + CE, and T1 + FO + CE). The segmentation performance was evaluated using Dice coefficient, pixel-wise recall, and pixel-wise precision. The detection performance was analyzed using per-lesion sensitivity and a free-response receiver operating characteristic curve. The performance of the model was compared with that of five radiologists using the external test set.Results: The 2D U-Net T1 + CE model exhibited superior segmentation performance in the external test compared to the other models, with a Dice coefficient of 0.699 and pixel-wise recall of 0.653. The T1 + CE model achieved per-lesion sensitivities of 0.828 (497/600) and 0.857 (150/175) for metastases in the internal and external tests, respectively. The radiologists demonstrated a mean per-lesion sensitivity of 0.746 and a mean per-lesion positive predictive value of 0.701 in the external test.Conclusion: The deep learning models proposed for automated segmentation and detection of bone metastases on spinal MRI demonstrated high diagnostic performance."
Open-loop Wavefront Correction Based on SH-U-net for Retinal Imaging System,2024,"['Adaptive optics', 'Retinal imaging', 'Wavefront correction']",,
3DentAI: U-Nets for 3D Oral Structure Reconstruction from Panoramic X-rays,2024,"['Attention U-Net', 'CBCT', 'Panoramic X-ray', 'Focal Trough', '3D Reconstruction', 'Attention U-Net', 'CBCT', '파노라마 엑스레이', '초점 영역', '3D-복원']",,"Extra-oral imaging techniques such as Panoramic X-rays (PXs) and Cone Beam Computed Tomography (CBCT) are the most preferredimaging modalities in dental clinics owing to its patient convenience during imaging as well as their ability to visualize entire teethinformation. PXs are preferred for routine clinical treatments and CBCTs for complex surgeries and implant treatments. However, PXsare limited by the lack of third dimensional spatial information whereas CBCTs inflict high radiation exposure to patient. When a PXis already available, it is beneficial to reconstruct the 3D oral structure from the PX to avoid further expenses and radiation dose. Inthis paper, we propose 3DentAI – an U-Net based deep learning framework for 3D reconstruction of oral structure from a PX image.Our framework consists of three module – a reconstruction module based on attention U-Net for estimating depth from a PX image,a realignment module for aligning the predicted flattened volume to the shape of jaw using a predefined focal trough and ray data,and lastly a refinement module based on 3D U-Net for interpolating the missing information to obtain a smooth representation of oralcavity. Synthetic PXs obtained from CBCT by ray tracing and rendering were used to train the networks without the need of paired PXand CBCT datasets. Our method, trained and tested on a diverse datasets of 600 patients, achieved superior performance to GAN-basedmodels even with low computational complexity."
"Livelihood sustainability of small-scale fishing households: an empirical analysis of U Minh wetland, Ca Mau province, Vietnam",2024,"['Livelihood status', 'Sustainable livelihood capital index (SLCI)', 'Small-scale', 'Inland fishing', 'U Minh']",,"This paper used the UK Agency for International Development sustainable livelihood framework to measure small-scale in-land fishing household's livelihood by sustainable livelihood capital index in the vulnerable context of aquatic natural resource depletion in the wetland forest of Ca Mau province, Vietnam. Findings indicated that fishing households' livelihood capital is unsustainable and inadequate. The result took note of the beneficial physical capital while underlining the human, natural, financial, and social capital's limitations in achieving livelihood sustainability. The limitations were found to be a low score of composite index of sustainable livelihood capital (less than an average score of 0.5) whereas the outstanding score of physical capital was found. Providing training in the adoption of new livelihood models, learning livelihood diversification, access to formal credit, and appropriate coverage of social safety-net programs might help mitigate the unsustainable livelihood of inland fishing households."
『탄소제로 보험동맹(NZIA)』가입 사업자의 미국 반독점법 위반 문제,2024,"['탄소제로 보험동맹', '유엔환경계획의 글래스고 탄소제로 금융동맹', '환경·사회적 책임·지배구조 반대입법', '공화당 주도 지역', '미국 반독점법', '셔먼법', '맥커렌-퍼거슨법', '집단적 거래거절', '당연위법', '역외적용', '유럽연합기능조약 제101조 제3항', 'NZIA', 'UNEP-convened GFANZ', 'ESG and Anti-ESG legislation', 'Red Belt', 'U.S. Antitrust Act', 'Sherman Act', 'McCarren-Ferguson Act', 'collective refusal to deal', 'per se illegality', 'extra territorial application', 'Article 101(3) of the Treaty on the Functioning of the European Union.']","ESG 경영은 모든 산업 분야에서 기업경영의 뚜렷한 흐름이 되고 있다. 그 가운데 환경 부문에서는 탄소배출을 줄여 기후 위기에 대비하여야 한다는 공감대가 세계적으로 형성되고 그 대응 방안이 매우 다양하게 제시·실행되고 있다. 유엔환경계획(UNEP)의 「글라스고 탄소제로 금융동맹(GFANZ)」도 그중의 하나로서 금융산업의 전 분야에서 업권별로 대응하는 조직을 구성하고 개별기업이 공동목표를 달성하기 위하여 취할 행동지침을 제시하여 왔다. 보험 부문에서는 「탄소제로 보험동맹(NZIA)」이 창립되었다. NZIA는 2021. 7.에 8개 대형 보험회사를 회원으로 출발하였다. ESG 경영이 지속가능한 기업의 기본요건임을 의심치 않은 보험회사들이 속속 가입하면서 한때 회원 수가 30개 사에 이르렀다. 그러나 2023년 5월 미국 23개 주가 회원 보험회사가 NZIA 지침에 따라 보험사업을 영위할 경우 미국 반독점법에 위반하게 될 가능성이 높다고 경고하였다. 이에 회사들이 속속 동맹을 떠나 2024. 2. 10. 현재 11개 기업만 남게 되었다. 한국 보험회사는 삼성화재, 신한생명이 이미 탈퇴하였고, KB보험은 아직 남아 있다. 이 상황은 NZIA의 회원 회사 숫자가 늘고 주는 단순한 문제가 아니다. 예컨대 피보험자가 화재보험에 가입하고자 할 때 회원 보험회사들은 피보험자가 탄소배출회사라는 이유로 위험인수를 거부할 수 있는가? 보험회사는 미국 반독점법의 집단적 거래거절이나 부당한 공동행위자로 제재를 받을 것인가? 반독점법 시비는 보험 외에 은행업이나 자산운용업으로도 확산 될 것인가? 이 상황은 대선을 앞둔 미국 공화당의 정치적 공세인가 아니면 분명한 법적 판단에 따른 법집행의 예고인가? 파리기후변화협약에 탈퇴와 가입을 반복하고, 주에 따라 ESG에 반대하는 입법이 적지 않게 행하여지는 미국 상황의 일부인가? 매우 복잡한 요인들이 작동하고 있다. 그러나 세계적 보험회사들이 반독점법 위반 가능성을 매우 심각한 법적 위험으로 느끼고 있는 점은 분명하다. 본고는 NZIA의 등장과 좌절, ESG 추세와 반발, 금융산업 중에도 유일하게 연방 반독점법의 적용에서 제외되고 있는 보험사업의 반독점법 위반 가능성을 짚어 본다. 반독점법의 역외적용 문제이지만 이번 미국 23개 주의 태도에 비판적인 EU경쟁법과 기능조약(TFEU)의 입장을 소개한다. 우리 보험업법의 상호협정이나, 공정거래법상 역외적용·국제효력·법령에 따른 정당행위 등의 조항을 갖고 지금의 사태를 해결하기는 어렵다.NZIA 회원 기업이 미국 반독점법 위반에 대한 다툼에 실제로 휘말리게 될지는 지금 누구도 단정할 수 없다. 미국의 대선 결과, 공화당측의 정책 방향, ESG를 중시하는 세계적 동향 등 큰 변수와 함께 개별 주에 의한 돌발적인 소송 가능성도 유의해 보아야 한다. 법리에 따른 소송의 승패와 관계없이 미국에서 반독점법 시비에 휩싸이는 것은 사업자에게 매우 힘든 일이다. 보험회사들의 탈퇴를 비난하기는 어렵다. 그러나 보험산업 영역에서도 탄소제로는 매우 실현하기 어려운 과제임을 경험하게 되었다.","ESG management is becoming a mainstream trend in corporate management in all industries. In the environmental sector of ESG, there is a global consensus on the need to reduce carbon emissions to fight the climate crisis, and a wide variety of initiatives have been proposed. The Glasgow Financial Alliance for Net Zero (GFANZ) of the United Nations Environment Programme (UNEP) is one such initiative that has formed sector-specific organizations across the financial industry and set out guidelines for action to achieve collective goals. In the insurance sector, the Net-Zero Insurance Alliance (NZIA) was launched. The NZIA started in July 2021 with eight large insurance companies as members. At one point, the number of members reached 30 as more and more insurers realized that ESG management was an essential requirement for corporate sustainability. However, in May 2023, 23 U.S. states warned NZIA member insurers that they would likely violate U.S. antitrust laws if they conducted business under NZIA guidelines. As of February 10, 2024, only 11 companies remained in the alliance. Korean insurers Samsung Fire and Maritime and Shinhan Life have already withdrawn, leaving K.B. Insurance as the only remaining member of the NZIA. This situation involves several complex issues and is more than just a matter of the number of NZIA member companies rising and falling. For example, if an insured seeks fire insurance, can member insurers refuse to underwrite the risk because the insured is a carbon-emitting company? Would an insurance company be sanctioned as a boycott or business entity of illegal cartel conduct under U.S. antitrust law? Will antitrust enforcement extend beyond insurance to banking and asset managers? Is this a political move by the U.S. Republican Party in the run-up to the presidential election or a solid legal judgment? Is it part of a U.S. context that has seen repeated withdrawals from and accessions to the Paris Agreement on Climate Change and anti-ESG legislation on a state-by-state basis? There are so many complex factors in these questions that it’s difficult to determine a definitive answer. However, leading global insurance companies see the potential for antitrust violations as a severe legal risk. This article examines the rise and fall of the NZIA, ESG trends and backlash, and the potential for antitrust violations in the insurance business, which is the only financial industry exempt from federal antitrust laws. This is an issue of extraterritorial application of antitrust law, but it also introduces the position of E.U. Competition Law and the TFEU, which are critical of the attitude of the 23 U.S. states. Art.125 Mutual Agreement in the Korean Insurance Business Act and Art.3 Application to Acts Conducted Overseas, Art.56 International Cooperation of the Fair Trade Commission, Art.116 Legitimate Acts under Statutes or Regulations in Korean Monopoly Regulation and Fair Trade Act do not solve the problem.The question of whether NZIA members would violate U.S. antitrust laws is currently unanswered. And significant variables such as the outcome of the U.S. presidential election, the policies of the Republican Party, the global trend of pro-ESG, and the possibility of sudden litigation risk should be noted. Whether you win or lose on the merits, antitrust litigation in the U.S. is an arduous process that no business entities wants to go through."
수수 재배지 분할을 위한 무인기 취득 RGB 영상 분석,2024,"['무인기 영상', '수수 재배지', '영상 분할', 'Seg-Net', 'U-Net', 'Image Segmentation', 'Sorghum Cultivation Area', 'Seg-Net', 'UAV Imagery', 'U-Net']","본 연구는 수수를 대상으로 수수 주산지에서 취득한 무인기 기반 RGB영상에 Seg-Net과 U-Net모델을 작성 후, 일반화 가능성을 검토하여 실시간 재배지 파악에 더 효율적인 기법을 제안하기 위해 수행되었다. 경상북도 안동시의 수수 재배지 영상 264장을 이용해 모델학습을 진행하고, 충청북도 제천시 수수 재배지 영상 14장을 이용하여 테스트를 진행하였다. U-Net의 학습은 14epoch, AccuracyC = 0.9426, LossC = 0.1593, Dice_coefC = 0.9223, AccuracyV = 0.6403, LossV = 1.9624, Dice_coefV = 0.6402에 4시간 37분이 소요되었으며, Seg-Net의 학습은 101epoch, AccuracyC = 0.6363, LossC = 0.6573, Dice_coefC = 0.5586, AccuracyV = 0.5711, LossV = 0.6785, Dice_coefV = 0.5586이며 1시간 55분이 소요되었다. Test결과 U-Net은 AccuracyT = 0.6806, LossT = 0.7180, Dice_coefT = 0.5558, Seg-Net은 AccuracyT = 0.7472, LossT = 0.5225, Dice_coefC = 0.6159로 나타났다. Seg-Net의 Calibration성능은 낮지만 일반화 성능이 뛰어나며, 모델의 빠른 학습 시간, 더 낮은 메모리 요구량으로 수수 재배지 분할에서 U-Net보다 효율적인 모델이라고 사료된다.","This study was conducted to propose a more efficient method for real-time cultivation area detection by examining the generalization capability of Seg-Net and U-Net models using UAV-based RGB imagery obtained from major sorghum cultivation areas. A total of 264 sorghum cultivation area images from Andong City, Gyeongsangbuk-do, were used for model training, and 14 images from Jecheon City, Chungcheongbuk-do, were used for testing. U-Net training was performed for 14 epochs, achieving AccuracyC = 0.9426, LossC = 0.1593, Dice_coefC = 0.9223, AccuracyV = 0.6403, LossV = 1.9624, Dice_coefV = 0.6402, with a training time of 4 hours and 37 minutes. Seg-Net training was performed for 101 epochs, achieving AccuracyC = 0.6363, LossC = 0.6573, Dice_coefC = 0.5586, AccuracyV = 0.5711, LossV = 0.6785, Dice_coefV = 0.5586, with a training time of 1 hour and 55 minutes. Test results showed that U-Net achieved AccuracyT = 0.6806, LossT = 0.7180, Dice_coefT = 0.5558, while Seg-Net achieved AccuracyT = 0.7472, LossT = 0.5225, Dice_coefC = 0.6159. Although Seg-Net showed lower calibration performance, it demonstrated superior generalization performance, faster training time, and lower memory requirements, making it a more efficient model for sorghum cultivation area segmentation than U-Net."
딥러닝 기반 강수 예측 모델 개선 연구: 가중 평균 앙상블 기법을 통한 성능 향상,2024,"['Precipitation Nowcasting', 'HSR', 'Deep-learning', 'U-Net', 'Ensemble', '단기 강수 예측', '딥러닝', '앙상블']","본 연구는 다중 고도각 기반 합성 강우량(HSR) 데이터를 활용해 강원도 지역을 대상으로 딥러닝 기반 단기 강수 예측 모델을 개발하고, 가중 평균 앙상블 기법을 적용해 강수 예측 성능을 개선하고자 하였다. 최근 기후 변화로 극한 강수 사건의 빈도와 강도가 증가함에 따라, 정확하고 신뢰성 높은 단기 강수 예측의 필요성이 커지고 있다. 이를 위해 U-Net과 Attention 메커니즘을 적용한 다양한 모델(SE U-Net, Attention U-Net, Dual Attention U-Net)을 학습하고, 각 모델의 예측 결과를 가중 평균 앙상블로 결합하였다. Attention 메커니즘은 중요한 정보를 포착하고 불필요한 신호를 억제하여 강수의 위치와 강도를 보다 정밀하게 예측하는 데 기여하지만, 낮은 강수 강도에서는 과적합으로 인해 오탐률(FAR)이 증가하는 현상이 나타났다. 이를 보완하기 위해 앙상블 기법을 적용하여 과적합을 줄이고 예측의 신뢰성을 높이고자 하였다. 실험 결과, 30mm/h 이상의 극한 강수를 제외한 다양한 강수 조건에서 단일 모델에 비해 모든 성능 지표에서 일관된 성능 향상이 나타났으며, 앙상블 기법이 Attention 기반 모델의 장점을 유지하면서도 과적합 문제를 줄여 예측의 신뢰성과 정확도를 높이는 데 효과적임을 확인하였다. 본 연구는 Attention 메커니즘과 앙상블 기법의 결합이 강수 예측 성능을 효과적으로 향상시킬 수 있음을 보여주며, 향후 다양한 기상 데이터와 앙상블 기법의 확장을 통해 더 일반화된 예측 모델 개발의 필요성을 제안한다.","This study develops a deep learning-based short-term precipitation nowcasting model using HSR (Hybrid Surface Rainfall) data for Gangwon Province and applies a weighted average ensemble method to improve prediction accuracy. With climate change increasing the frequency and intensity of extreme precipitation events, accurate short-term precipitation forecasts are crucial. Various models, including U-Net and Attention-based models (SE U-Net, Attention U-Net, Dual Attention U-Net), were trained and combined using a weighted average ensemble. The Attention mechanism enhances the accuracy of precipitation location and intensity predictions by focusing on key information and suppressing noise. However, it increased FAR (False Alarm Ratio) at low precipitation intensities due to overfitting, which the ensemble method mitigated to improve reliability. Results showed consistent performance improvements across various precipitation conditions, except for extremes above 30mm/h. The weighted average ensemble reduced overfitting while preserving the strengths of Attention-based models, enhancing prediction reliability and accuracy. This study highlights that combining Attention mechanisms with ensemble methods can effectively improve precipitation nowcasting, suggesting future work on expanding ensemble techniques and integrating diverse meteorological data for more generalized models."
발열 구조체 시편을 활용한 딥러닝 기반 내부 박리 정량 평가,2024,"['Thermal image', 'U-Net', 'Vector label image', 'Internal delamination', 'Damage detection', '열화상 이미지', '딥러닝 모델', '벡터 레이블 이미지', '내부 박리', '손상 탐지']","이 연구는 열화상 이미지를 활용하여 딥러닝 모델을 기반으로 발열 구조체 내부 박리의 손상 탐지를 목표로 한다. 딥러닝 모델 중 하나인 U-Net은 세분성 작업 성능이 뛰어나 작은 데이터셋으로도 효과적인 데이터 처리가 가능하다는 장점이 있다. 이 연구에서는 이를 활용해 발열 구조체 시편의 열화상 이미지를 학습하고, 손상에 따른 내부 박리를 탐지하는 방법을 제시하고자 한다. 입력 변수로 발열 시간과 임의로 가한 시편의 박리 정도를 활용하였다. U-Net 모델은 총 24개의 레이어로 구성하였으며, 인코더와 디코더 구조를 통해 영상 이미지로부터 추출한 열화상 이미지를 학습하였다. 개발한 인공지능 모델의 성능평가를 위해, 호모그래피에 기반한 열화상 이미지를 생성하였으며, 이를 활용해 손상 정량 평가를 수행하고 성능을 검증하였다.","This study aims to detect damage from internal delamination of heating composite materials based on a deep learning model using thermal images. U-Net, a deep learning model specialized in image segmentation, excels in granular task performance and enables effective data processing even with small datasets. In this study, a U-net architecture is used to train thermal images of heating composite materials and to propose a method to detect internal damage, known as delamination. The duration of heating and the artificially created delamination level of specimens are used for the input variables. The U-Net model consists of a total of 24 layers and is structured with an encoder and decoder. It was trained on thermal images extracted from video images. To evaluate the performance of the developed artificial intelligence model, images for tests were created using homography and used to verify the suggested method and to quantify its performance."
폐 CT 영상에서 다양한 노이즈 타입에 따른 딥러닝 네트워크를 이용한 영상의 질 향상에 관한 연구,2024,"['딥러닝 모델', 'U-net 네트워크', '전산화 단층촬영', '노이즈 감소', 'Deep Learning', 'U-Net Architecture', 'Computed Tomography', 'Noise Reduction']","디지털 영상, 특히, 전산화 단층촬영 영상은 X선 신호를 디지털 영상 신호로 변환하는 과정에서 노이즈가 필수적으로 포함되기 때문에 노이즈 저감화에 대한 고려가 필수적이다. 최근, 딥러닝 모델 기반의 노이즈 감소가 가능한 연구가 수행되고 있다. 그러므로, 본 연구의 목적은 폐 CT 영상에서의 다양한 종류의 노이즈를 U-net 딥러닝 모델을 이용하여 노이즈 감소 효과를 평가하였다. 총 800장의 폐 CT 영상을 사용하였고, Adam 최적화 함수와 100회의 반복 학습 횟수, 0.0001의 학습률을 적용한 U-net 모델을 이용하였다. 노이즈를 포함한 입력 영상 생성을 위하여 Gaussian 노이즈, Poisson 노이즈, salt & pepper 노이즈, speckle 노이즈를 적용하였다. 정량적 분석 인자로 평균 제곱 오차, 최대 신호 대 잡음비, 영상의 변동계수를 사용하여 분석하였다. 결과적으로, U-net 네트워크는 다양한 노이즈 조건에서 우수한 성능을 나타냈으며 그 효용성을 입증하였다.","The digital medical imaging, especially, computed tomography (CT), should necessarily be considered in terms of noise distribution caused by converting to X-ray photon to digital imaging signal. Recently, the denoising technique based on deep learning architecture is increasingly used in the medical imaging field. Here, we evaluated noise reduction effect according to various noise types based on the U-net deep learning model in the lung CT images. The input data for deep learning was generated by applying Gaussian noise, Poisson noise, salt and pepper noise and speckle noise from the ground truth (GT) image. In particular, two types of Gaussian noise input data were applied with standard deviation values of 30 and 50. There are applied hyper-parameters, which were Adam as optimizer function, 100 as epochs, and 0.0001 as learning rate, respectively. To analyze the quantitative values, the mean square error (MSE), the peak signal to noise ratio (PSNR) and coefficient of variation (COV) were calculated. According to the results, it was confirmed that the U-net model was effective for noise reduction all of the set conditions in this study. Especially, it showed the best performance in Gaussian noise."
크림프 하네스 검사 장치 구현을 위한 다중 클래스 의미 분할 앙상블 기법,2024,"['Wire harnesses', 'Crimp harnesses', 'U-net encoder', 'Ensemble technique', 'Deep learning']","와이어 하네스는 전기⦁전자 장비에서 전선 및 케이블을 체계적으로 정리하고 보호하는 핵심 구성 요소이다. 와이어 하네스 품질 불량은 제품 고장, 화재, 인명사고와 직결되므로 이를 방지하기 위해 품질 관리가 핵심적이다. 본 논문에서는 압착공정 품질검사를 위해 U-net 인코더 기반 앙상블 기법을 제안한다. 앙상블 기법은 여러 개의 서로 다른 U-net 구조를 결합함으로써 보다 정확한 최종 예측을 생성한다. 앙상블 가중치 계산 알고리즘으로 첫째 U-Net 모델의 IoU, F1 점수, 재현율, 정밀도의 평균값을 통해 둘째는 IoU 평균값이 낮은 모델에 대해 페널티를 부여하여 이를 통해 앙상블 가중치를 각각 결정한다. 와이어 하네스 제조공장에서 얻은 크림프 하네스 이미지를 활용하여 실시한 앙상블 기법 분석 결과, 판별 정확도가 95.41%에 달했다. 제안된 방법은 기존 방법의 단점을 극복하고, 일관된 높은 품질을 유지하면서 동시에 생산비용을 절감할 수 있는 가능성을 제공한다.","Wire harnesses are a key component for organizing and protecting wires and cables in electrical and electronic equipment. Poor wire harness quality is directly linked to product failure, fire, and personal injury, so quality control is key to preventing this. In the wire harness manufacturing process, quality inspection is especially important for crimp harnesses, which are the product of the crimping process that crimp terminals onto stripped wire cables. In this paper, we propose a U-net encoder-based ensemble method for crimping process quality inspection. The ensemble method combines several different U-net structures to produce a more accurate final prediction. The ensemble weight calculation algorithm determines the ensemble weights, firstly, through the average values of IoU, F1 score, recall, and precision of the U-Net models, and secondly, by penalizing the models with lower average values of IoU. The analysis of the ensemble method using crimped harness images obtained from a wire harness manufacturing plant showed that the discrimination accuracy reached 95.41%. The proposed method overcomes the shortcomings of existing methods and offers the possibility of reducing costs while maintaining consistently high quality."
이미지의 균열 픽셀 탐지를 위한 딥러닝 모델의 적용과 의미론적 분할 활용,2024,"['Crack', 'Deep learning', 'Image', 'Semantic segmentation', 'U-Net', '균열', '딥러닝', '이미지', '의미론적 분할', 'U-Net']","본 연구에서는 수자원시설에서 활용될 수 있는 검출 기술로 균열 이미지의 딥러닝 학습을 통한 손상탐지 기법의 적용을위하여 균열 손상 이미지 데이터를 수집, 활용, 학습하여 이를 탐지할 수 있는 이미지처리 알고리즘의 적용을 수행하였다. 딥러닝기법 중 합성곱을 기반으로 한 U-Net 구조를 활용하여 구조물 균열손상 이미지들의 학습과 특징 추출을 통하여 각 픽셀 별분류를 통해 이미지 내에서 균열손상 부위를 분류해 낼 수 있었다. 이 과정 중 활성화 맵을 시각화하여 균열 특징에 대한 모델의반응을 확인하여 모델이 이미지의 어느 부분에 주목하고 있는지를 확인하였다. 균열 검출 결과 이미지 마스크 처리를 통한참 값과 비교하여 높은 정확도와 정밀도가 나타나 본 기법이 균열 탐지에 적용성이 있음을 확인하였다. 본 연구에서 학습된모델은 취득한 이미지에서의 균열 검출을 비롯하여 수자원 시설물 이미지에 대한 적용에도 검출 능력이 드러났으며, 향후수자원 구조물의 안전 진단 및 평가를 위한 모니터링에서 활용될 것으로 기대된다.","To apply damage detection methods through deep learning of crack images that could be used in water resources facilities, an image processing algorithm that could detect crack damage image data was collected, utilized, and trained in this study. Using the U-Net structure based on convolution among deep learning techniques, we were able to classify crack damage areas within the image through classification for each pixel through learning and feature extraction of structural crack damage images. During this process, the activation map was visualized to check the model's response to crack features to determine which part of the image the model was focusing on. Crack detection results showed high accuracy and precision compared to the true value through image mask processing, confirming that this technique could be used for crack detection. The model learned in this study demonstrated detection capabilities of crack detection in acquired images as well as application to images of water resources facilities. It is expected to be used for monitoring safety diagnosis and evaluating water resources structures in the future."
CCTV 영상과 의미론적 분할 모델을 이용한 재해성 하천기인 부유쓰레기 탐지,2024,"['River Floating debris', 'CCTV images', 'Semantic Segmentation', 'U-net Model', 'Detection', '하천기인 부유쓰레기', 'CCTV 영상', '의미론적 분할', 'U-Net 모델', '탐지']","기후 변화로 인한 극단적인 이상 기후 현상이 빈번해지면서 수재해의 발생 빈도가 증가하고 있다. 특히, 집중강우 기간 동안 육상에서 다량으로 유입되는 재해성 하천기인 부유쓰레기는 수질 오염, 수생태계 교란, 경관 훼손과 같은 심각한 문제를 일으키고 있다. 그러나 하천과 하구를 통해 해양으로 유출되는 부유쓰레기의 양과 분포에 대한 연구와 이해는 여전히 부족한 상황이다. 따라서 본 연구에서는 CCTV 영상자료와 의미론적 분할 모델에서 우수한 성능을 보이는 U-Net 모델을 이용하여 부유쓰레기 탐지 모델을 개발하였다. 정량적인 모델의 정확도를 평가한 결과, mIoU 0.69, Precision 0.87, Recall 0.77, F1-score 0.80의 정확도를 보였으며, 부유쓰레기의 크기와 관계없이 정성적인 결과에서도 부유쓰레기를 잘 탐지하는 것으로 나타났다. 본 연구를 통해 CCTV 영상과 딥러닝 모델을 활용하여 부유쓰레기를 지속적으로 탐지할 수 있음을 확인하였다. 향후 이미지 증강 기법과 추가적인 자료 축적을 통해 학습 자료의 다양성이 확보될 경우, 그 활용도와 정확도가 더욱 향상될 것으로 기대된다.","With the increasing frequency of extreme weather events due to climate change, water-related disasters are becoming more frequent. In particular, large amounts of hazardous river floating debris from land during periods of heavy rainfall cause serious problems such as water pollution, disruption of aquatic ecosystems and landscape degradation. However, there is still a lack of research and understanding of the amount and distribution of floating debris entering the ocean through rivers and estuaries. Therefore, we developed a floating debris detection model using CCTV images and the U-Net model, which has excellent performance in semantic segmentation model. As a result of evaluating the accuracy of the quantitative model, it showed an accuracy of mIoU 0.69, precision 0.87, Recall 0.77 and F1-score 0.80, and the qualitative results showed that it detected floating garbage well regardless of the size of the floating garbage. This study shows that it is possible to continuously detect floating garbage using CCTV images and deep learning models. In the future, if the diversity of training materials is ensured through image augmentation techniques and additional data accumulation, it is expected that the usage and accuracy will be further improved."
Deep Learning-Based Approaches for Nucleus Segmentation,2024,"['Deep Learning', 'CNN', 'Nuclei Segmentation', 'Image Segmentation', 'U-Net']",,"The accurate identification of cell nuclei is a critical aspect of various analyses, given that human cells, numbering around 30 trillion, contain DNA as their genetic code. In this research paper, we provide a comprehensive overview of deep learning-based techniques for nucleus segmentation. We have replicated and assessed the state-of-the-art methods using datasets like FCN, SegNet, U-net, and DoubleU-net, with a focus on the Data Science Bowl 2018 dataset comprising 670 training data folders and 65 testing data folders. Our experimental findings reveal that DoubleU-Net surpasses U-Net and other baseline models, yielding more precise segmentation masks. This promising outcome suggests that DoubleU-Net could serve as a robust model for addressing various challenges in medical image segmentation."
The Quantitative Evaluation of  Automatic Segmentation in Lumbar  Magnetic Resonance Images,2024,"['Automatic segmentation', 'Lumbar spine', 'Magnetic resonance imaging', 'Residual U-Net', 'Spinal stenosis']",,"Objective: This study aims to overcome challenges in lumbar spine imaging, particularly lumbar spinal stenosis, by developing an automated segmentation model using advanced techniques. Traditional manual measurement and lesion detection methods are limited by subjectivity and inefficiency. The objective is to create an accurate and automated segmentation model that identifies anatomical structures in lumbar spine magnetic resonance imaging scans.Methods: Leveraging a dataset of 539 lumbar spinal stenosis patients, the study utilizes the residual U-Net for semantic segmentation in sagittal and axial lumbar spine magnetic resonance images. The model, trained to recognize specific tissue categories, employs a geometry algorithm for anatomical structure quantification. Validation metrics, like Intersection over Union (IOU) and Dice coefficients, validate the residual U-Net’s segmentation accuracy. A novel rotation matrix approach is introduced for detecting bulging discs, assessing dural sac compression, and measuring yellow ligament thickness.Results: The residual U-Net achieves high precision in segmenting lumbar spine structures, with mean IOU values ranging from 0.82 to 0.93 across various tissue categories and views.The automated quantification system provides measurements for intervertebral disc dimensions, dural sac diameter, yellow ligament thickness, and disc hydration. Consistency between training and testing datasets assures the robustness of automated measurements.Conclusion: Automated lumbar spine segmentation with residual U-Net and deep learning exhibits high precision in identifying anatomical structures, facilitating efficient quantification in lumbar spinal stenosis cases. The introduction of a rotation matrix enhances lesion detection, promising improved diagnostic accuracy, and supporting treatment decisions for lumbar spinal stenosis patients."
CNN 기반 위성 이미지를 활용한 북한의 도시 인구추정,2024,"['북한 인구', '주간 위성 이미지', 'CNN', '이웃 효과', 'U-net', 'North Korea’s population', 'daytime satellite image', 'CNN', 'neighboring effects', 'U-net']","북한은 공식적인 절차를 통해 인구데이터를 공개하지 않지만, 통계청, 인터넷 검색을 통해 북한의 인구와 관련된 자료를 확인할 수 있다. 그러나 이 데이터들은 1993년, 2008년에 유엔인구기금(UNFPA)의 지원을 받아 실시한 인구총조사를 기반으로 추정된 자료이고 신뢰성도 떨어지는 것으로 알려져 있다. 이에 본 연구에서는 북한의 현재 인구를 가늠하기 위한 첫 시도로 2023년 북한의 주간 위성 이미지를 이용하여 평양과 개성의 인구를 격자 단위로 추정하였다. 연구 결과로 CNN 기반 격자 단위 인구추정 모델을 개발하였다. 이 모형은 우리나라를 대상으로 CNN 모델을 훈련하고, 북한에 적용하는 것을 목표로 한다. 모형은 CNN의 대표적인 알고리즘인 VGG16 모델을 기반으로 전이학습을 하였으며, 주간 위성 이미지에서 나타나는 남북한의 계절 차이를 조정하기 위해 U-net을 활용하여 조정된 이미지를 사용하였다. 또한, 이웃효과(neighboring effects)를 추가하여 모델의 성능을 개선하였다. 모델 적합 결과 우리나라의 4대 광역시의 인구는 실제 인구와 큰 차이 없이 추정되었으며, 북한의 평양과 개성의 인구는 2008년 센서스인구와 유사하게 추정되어 만족스러운 결과를 보여주었다.","North Korea does not officially disclose population data through formal procedures. However, information related to North Korea's population can be verified through KOSTAT or internet searches. Nevertheless, these data are based on population surveys conducted with the support of the United Nations Population Fund (UNFPA) in 1993 and 2008, and are known to be of questionable reliability. In this study, as an initial attempt to estimate the current population of North Korea, we utilized daytime satellite images from 2023 to estimate the populations of Pyongyang and Kaesong at the grid level. The research resulted in the development of a gridded population estimation model based on a Convolutional Neural Network (CNN). The model was trained on CNN using data from South Korea and aimed to be applied to North Korea. It employed the VGG16 model, a representative algorithm of CNN, for transfer learning. To account for seasonal differences in the images from daytime satellite data, a U-net was used for image adjustment. Furthermore, neighboring effects were incorporated to enhance the model's performance. The model fitting results indicated that the populations of the four major metropolitan cities in South Korea were estimated without significant differences from actual populations. The populations of Pyongyang and Kaesong in North Korea were also estimated to be similar to the 2008 census data, demonstrating satisfactory results."
다중 시멘틱 세그멘테이션 AI 기반의 가전용 크림프 하네스 검사 모델 개발,2024,"['Wire harness', 'Crimp harness inspection', 'Multi class semantic segmentation', 'U-Net']","와이어 하네스는 가전제품, 전기자동차, 자율주행 자동차에서 혈류의 역할을 하는 임의의 전기적회로의 상호 연결을 제공하는 와이어의 그룹으로 정의되며 품질이 가장 중요한 척도이다. 와이어 하네스 품질 불량은 제품 고장, 화재, 인명사고와 직결되기 때문이다. 본 논문은 와이어 하네스 압착공정 결과물인 크림프 하네스의 불량을 판정하기 위해, 다중 시멘틱 세그멘테이션 기법을 활용하는 방법을 제안하였다. 크림프 하네스의 불량 판정 문제는 전처리된 하네스 데이터로부터 연속된 5개 세그먼트들의 높이 및 폭의 길이를 정확히 측정하면 가능한 것으로 판단되었다. 이에 착안하여 대표적인 시멘틱 세그멘테이션 모델인 U-Net을 기반으로 다중 세그먼트 식별에 적합한 AI 모델의 개발을 목표로 하였다. 다중 세그먼트 식별을 위해 U-Net의 인코더 부분을 ResNet 34, EfficientNet B1 및 Mix Transformer B0로 변형한 모델을 제안하였다. 인공지능 모델 개발을 위해, 데이터셋 구축에는 와이어 하네스 제조공장에서 수집된 크림프 하네스 이미지들을 사용하였다. 개발된 다중 시멘틱 세그멘테이션 AI 모델은 테스트 데이터셋에 대해 95.14%의 판별 정확도를 나타내었다. 제안된 방법은 종래의 방법(수작업, 압착센서 측정값 및 규칙 기반의 영상처리)의 단점을 개선한, 균일한 고품질 유지와 인건비 절감이 가능하다.","Wire harness is defined as groups of wires providing interconnections for arbitrary electrical circuits that serve as the bloodstream in consumer electronics, electric vehicles, and autonomous cars. Poor wire harness quality is directly related to produce product failures, fires, and human casualties. This paper proposes a method that utilizes multi-class semantic segmentation techniques to determine the defects of the crimp harness, which is the result of a product of the wire harness crimp process. The problem of defect detection of crimp harness can be solved by accurately measuring the height and width of five consecutive segments from the preprocessed harness data. With this insight, we aimed to develop an AI model suitable for multi-segment identification based on U-Net, a representative semantic segmentation model. To identify multiple segments, we proposed a model that modifies the encoder part of U-Net using Resnet 34, EfficientNet B1, and Mix Transformer B0. For AI model development, images of crimp harnesses collected from a wire harness manufacturing plant were used to build the dataset. The developed multi-class semantic segmentation AI model showed a discernment accuracy of 95.14% on the test dataset. Through the method proposed in this paper, it is possible to maintain uniform high quality and reduce labor costs, which improves the shortcomings of the existing crimp harness quality inspection(manual, crimp sensor measurements, and rule-based image processing)."
Teaching English in University Visually based On 3D Immersion Technology,2024,"['Visualization techniques', 'U-Net algorithm', '3D layout', 'Autonomous learning', 'Support rate']",,"The application of visualization technology in education helps to promote information technology in education and enhances learners’ ability to perceive information. Therefore, this study builds an online, self-directed learning visualization teaching system that includes a data input layer, a visualization coding layer, a logical recommendation layer, and a view presentation layer. In addition, to enhance visualization of web data, the teaching system optimizes the visual experience by using the U-Net algorithm and an immersive network with a 3D layout. The results show that for the LIME dataset test, this study’s proposed algorithm obtained the highest mean image entropy at 7.67, which is an improvement of 0.05 and 0.32 over the MBLLEN and RetinexNet algorithms, respectively. Therefore, this algorithm is more advantageous in enhancing the richness of image information. In addition, in the validation of the rationality of the online self-directed learning model, the visualization technique was fully supported by students, helping them to adapt to the learning system quickly. This indicates that the visualization system proposed in this study is effective in improving students’ self-directed learning skills."
"Geospatial technologies for estimating post-wildfire severity through satellite imagery and vegetation types: a case study of the Gangneung Wildfire, South Korea",2024,"['wildfire', 'remote sensing', 'U-Net', 'vegetation indices', 'carbon monoxide']",,"Wildfires have caused natural environmental damage that has contributed to deforestation, consequently demonstrating a significant influence on atmospheric emissions. Wildfires occur frequently in South Korea, especially during the spring season. This study assessed post-wildfires areas in Gangneung, South Korea, on April 11, 2023, which were generated by implementing remote sensing technology and statistical analysis. Remote sensing and classification techniques, including PlanetScope, have been developed for identifying wildfire-damaged areas. The method for classifying post-wildfire mapping estimation includes the utilization of deep learning approaches, especially using the U-Net architecture. Therefore, the assessment of wildfire severity can be conducted using Sentinel-2 and Sentinel-5P imagery in addition to an analysis of the vegetation type and air pollutant within the affected region. In the present study, Sentinel-2 imagery was to generate spectral indices, including the differenced normalized burn ratio (dNBR), differenced normalized difference moisture index (dNDMI), differenced soil adjusted vegetation index (dSAVI), and differenced normalized vegetation index (dNDVI). Sentinel-5P imagery was utilized to produce carbon monoxide (CO) column number densities. The estimation of wildfire areas was conducted using a PlanetScope classified image with the U-Net classifier, which was evaluated based on the overall accuracy value of 95% and kappa accuracy of 0.901. The wildfire severity level was shown by dNBR, which was correlated with the parameters, including RBR, dNDMI, dSAVI, dNDVI, and CO. The statistical analysis demonstrated a significant and positive correlation between the wildfire severity and the parameters. Moreover, the average of vegetation indices (NDMI, SAVI, and NDVI) before and after a wildfire were found to decrease by vegetation type, including 17.55% in mixed barren land areas, 17.49% in other grasses, 24.71% in mixed forest land, 22.48% in coniferous land, 13.48% in fields, and 4.29% in paddy fields. On the  basis of the results, these estimates can be employed to identify the level of damage caused by wildfires to vegetation and air quality."
미국 금리 정책 변화와 아시아-태평양 주요국 환율 수익률 전이효과: 2001년 이후 분석,2024,"['Asia-Pacific', 'Currency Interconnectedness', 'Exchange Rate', 'U.S. Monetary Policy', 'Volatility Spillover Index']",,"Purpose – This study analyzes the impact of U.S. monetary policy changes on exchange rate returns in key Asia-Pacific countries.Design/Methodology/Approach – To achieve this, the study utilizes the volatility spillover index developed by Diebold and Yilmaz, which is widely recognized for its ability to measure interconnectedness in financial markets. The analysis covers twelve currencies from January 3, 2001, to September 18, 2024, divided into seven sub-periods aligned with changes in the U.S. federal funds rate. The study evaluates net spillover effects and pairwise spillovers to understand the relationships among the currencies.Findings – The total spillover effect of 22.17% underscores significant interdependence among Asia-Pacific currencies, with spillover effects becoming more pronounced during U.S. interest rate hikes. The South Korean Won was a net recipient of information, while the Singapore Dollar and Chinese Yuan emerged as key transmitters. The 52-week rolling average analysis shows that changes in U.S. rates had a swift and dynamic impact on currency linkages.Research Implications – The findings highlight the importance for policymakers and investors to closely monitor U.S. interest rate changes, as they have substantial implications for exchange rate volatility in the Asia-Pacific region."
특성맵 차분을 활용한 커널 기반 비디오 프레임 보간 기법,2024,"['딥러닝', '프레임 차분', '비디오 프레임 보간', 'U-Net', 'Deep Learning', 'Frame Differencing', 'Video Frame Interpolation', 'U-Net']",,"Video frame interpolation is an important technique used in the field of video and media, as it increases the continuity of motionand enables smooth playback of videos. In the study of video frame interpolation using deep learning, Kernel Based Method captureslocal changes well, but has limitations in handling global changes. In this paper, we propose a new U-Net structure that applies featuremap differentiation and two directions to focus on capturing major changes to generate intermediate frames more accurately while reducingthe number of parameters. Experimental results show that the proposed structure outperforms the existing model by up to 0.3 in PSNRwith about 61% fewer parameters on common datasets such as Vimeo, Middle-burry, and a new YouTube dataset. Code is available athttps://github.com/Go-MinSeong/SF-AdaCoF."
Supervised deep learning-based synthetic computed tomography from kilovoltage cone-beam computed tomography images for adaptive radiation therapy in head and neck cancer,2024,"['Cone-beam computed tomography', 'Synthetic CT', 'Deep learning', 'Supervised U-Net', 'Adaptive radiation therapy', 'Head and neck cancer']",,"Purpose: To generate and investigate a supervised deep learning algorithm for creating synthetic computed tomography (sCT) images from kilovoltage cone-beam CT (kV-CBCT) images for adaptive radiation therapy (ART) in head and neck cancer (HNC).Materials and Methods: This study generated the supervised U-Net deep learning model using 3,491 image pairs from planning CT (pCT) and kV-CBCT datasets obtained from 40 HNC patients. The dataset was split into 80% for training and 20% for testing. The evaluation of the sCT images compared to pCT images focused on three aspects: Hounsfield units accuracy, assessed using mean absolute error (MAE) and root mean square error (RMSE); image quality, evaluated using the peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) between sCT and pCT images; and dosimetric accuracy, encompassing 3D gamma passing rates for dose distribution and percentage dose difference.Results: MAE, RMSE, PSNR, and SSIM showed improvements from their initial values of 53.15 ± 40.09, 153.99 ± 79.78, 47.91 ± 4.98 dB, and 0.97 ± 0.02 to 41.47 ± 30.59, 130.39 ± 78.06, 49.93 ± 6.00 dB, and 0.98 ± 0.02, respectively. Regarding dose evaluation, 3D gamma passing rates for dose distribution within sCT images under 2%/2 mm, 3%/2 mm, and 3%/3 mm criteria, yielded passing rates of 92.1% ± 3.8%, 93.8% ± 3.0%, and 96.9% ± 2.0%, respectively. The sCT images exhibited minor variations in the percentage dose distribution of the investigated target and structure volumes. However, it is worth noting that the sCT images exhibited anatomical variations when compared to the pCT images.Conclusion: These findings highlight the potential of the supervised U-Net deep learningmodel in generating kV-CBCT-based sCT images for ART in patients with HNC."
Temporomandibular Joint Segmentation Using Deep Learning for Automated Three-Dimensional Reconstruction,2024,"['Cone beam computed tomography', 'Deep learning', 'Segmentation', 'Temporomandibular joint', 'U-Net']",,"Purpose: Cone beam computed tomography (CBCT) is widely used to evaluate the temporomandibular joint (TMJ). For the three-dimensional (3D) assessment of the TMJ, segmentation of the mandibular condyle and articular fossa is essential. This study aimed to perform deep learning-based 3D segmentation of the mandibular condyle on CBCT images and evaluate the performance of the segmentation.Methods: CBCT scan data from 99 patients (mean age: 53.3±19.2 years) diagnosed with TMJ disorders were analyzed. From the CBCT images, sagittal, coronal, and axial planes showing the mandibular condyle were selected and combined to form two-dimensional (2D) images. The U-Net deep learning model was used to exclusively segment the mandibular condyle area from the 2D images. From these results, 3D images of the mandibular condyle were reconstructed. Accuracy, precision, recall, and the Dice coefficient were calculated to appraise segmentation performance in each plane.Results: The average Dice coefficient was 0.92 for the coronal and axial planes and 0.82 for the sagittal plane. The CBCT image-based segmentation performance of the mandibular condyle in the coronal and axial planes exceeded that in the sagittal plane. The sharpness and uniformity of the 2D images affected segmentation performance, with segmentation errors more likely occurring in non-uniform images. Certain segmentation errors were corrected through software processing. Finally, the segmented mandibular condyle images were applied to the CBCT data to reconstruct a 3D TMJ model.Conclusions: Mandibular condyle 3D segmentation on CBCT images using U-Net may help evaluate and diagnose TMJ disorders. The proposed segmentation method may assist clinicians in efficiently analyzing CBCT images, particularly in cases involving anatomical abnormalities."
PIDNet 기반 실시간 콘크리트 균열 탐지 모델 구현,2024,"['.', 'concrete crack detection', 'real-time crack detection', 'concrete surface analysis', 'PIDNet']","본 연구에서는 콘크리트 표면의 균열을 실시간으로 정확하게 탐지하기 위해 PIDNet 기반의 딥러닝 모델을 제안한다. PIDNet은 PID(Proportional-Integral-Derivative) 제어기의 개념을 네트워크 아키텍처에 도입하여, 세 가지 분기(branch)를 통해 상세한 특징, 문맥 정보, 경계 정보를 효과적으로 학습하였다. 모델의 학습과 평가는 AI-Hub에서 제공하는 콘크리트 균열 데이터셋을 활용하였으며, 동일한 워크스테이션 환경에서 U-Net, Attention U-Net, U-Net++, Mask R-CNN 등 기존의 대표적인 세그멘테이션 모델들과 비교 실험을 수행하였다. 평가 결과, 제안된 PIDNet 기반 모델은 IoU 92.3%를 기록하며, 기존 모델 대비 우수한 균열 탐지 성능을 보였다. 또한, 처리 속도 25 FPS와 모델 크기 45MB로 실시간 처리와 경량화 측면에서도 뛰어난 효율성을 확인하였다. 따라서, 본 연구의 PIDNet 기반 모델은 콘크리트 구조물의 균열 모니터링 시스템에 효과적으로 적용될 수 있을 것으로 기대된다.","In this study, we propose a PIDNet-based deep learning model for accurate real-time detection of cracks on concrete surfaces. By incorporating the concept of Proportional-Integral-Derivative(PID) controllers into the network architecture, PIDNet effectively learns detailed features, contextual information, and boundary data through its three branches. We trained and evaluated the model using a concrete crack dataset provided by AI-Hub and conducted comparative experiments with existing segmentation models such as U-Net, Attention U-Net, U-Net++, and Mask R-CNN under identical workstation conditions. The evaluation results demonstrate that the proposed PIDNet-based model achieved an IoU of 92.3%, outperforming existing models in crack detection performance. Additionally, with a processing speed of 25 FPS and a model size of 45MB, it exhibits excellent efficiency in terms of real-time processing and lightweight design. Therefore, the PIDNet-based model presented in this study is expected to be effectively applicable to crack monitoring systems for concrete structures."
딥러닝 기반 레이더-통신 중첩 신호 분리 기술,2024,"['Deep learning', 'Time-Frequency Analysis', 'Communication Signal', 'Signal Restoration', '딥러닝', '시간-주파수 분석', '무선 통신 신호', '신호 복원']","무선 통신 기술의 발전으로 인해 신호 간의 간섭이 일어나고 있으며, 이는 통신의 품질과 신뢰성에 부정적인영향을 미친다. 이와 같은 문제를 해결하기 위해 주파수 필터링, 공간적 분리와 같은 신호처리 알고리즘이 개발되었지만, 주파수가 완전히 중첩된 환경에서는 성능이 크게 저하된다. 본 논문에서는 이와 같은 문제를 해결하기 위해 딥러닝 모델인 U-Net을 활용하여 중첩된 신호를 분리하고 원본 신호를 복원시키는 방법을 제안한다. 1차원의I/Q 데이터를 STFT 알고리즘을 적용하여 2차원의 시간-주파수 이미지로 변환시켰고, U-Net 모델을 적용하여 중첩된 신호를 분리하였다. 통신 신호를 복원하는 것을 목표로 하였으며, -29dB ~ 0dB의 SIR에서 BPSK 신호의BER이   이하로 보장되었다.","The advancement of wireless communication technology has led to increased signal interference between signals, negatively affecting the quality and reliability of communication. To address such issues, signal processing algorithms like frequency filtering and spatial separation have been developed, yet their performance significantly degrades in environments with completely overlapping frequencies. This paper proposes a method using the deep learning model U-Net to separate overlapping signals and restore the original signals. 1D I/Q data was transformed into 2D time-frequency images through the application of the STFT algorithm, and the U-Net model was employed to segregate the overlapping signals. The goal was to restore the communication signal, and a BER of   or less was guaranteed for the BPSK signal at a SIR of -29 dB to 0 dB."
CT 영상에서 WT-GAN 모델을 이용한 효율적인 잡음제거,2024,"['WT-GAN', 'deep learning', 'CT image', 'noise reduction', '딥러닝', 'CT 영상', '잡음제거']","CT 촬영 시 방사선량을 줄이면 피폭 위험성을 낮출 수 있으나, 영상 해상도가 크게 저하 될 뿐 아니라 잡음(noise) 발생으로 인해 진단의 효용성이 떨어진다. 따라서, CT 영상에서의 잡음제거는 영상복원 분야에 있어 매우 중요하고 필수적인 처리 과정이다. 영상 영역에서 잡음과 원래 신호를 분리하여 잡음만을 제거하는 것은 한계가 있다. 본 논문에서는 웨이블릿 변환 기반 GAN 모델 즉, WT-GAN(wavelet transform-based GAN) 모델을 이용하여 CT 영상에서 효과적으로 잡음 제거하고자 한다. 여기서 사용된 GAN 모델은 U-Net 구조의 생성자와 PatchGAN 구조의 판별자를 통해 잡음제거 영상을 생성한다. 본 논문에서 제안된 WT-GAN 모델의 성능 평가를 위해 다양한 잡음, 즉, 가우시안 잡음(Gaussian noise), 포아송 잡음 (Poisson noise) 그리고 스펙클 잡음 (speckle noise)에 의해 훼손된 CT 영상을 대상으로 실험하였다. 성능 실험 결과, WT-GAN 모델은 전통적인 필터 즉, BM3D 필터뿐만 아니라 기존의 딥러닝 모델인 DnCNN, CDAE 모형 그리고 U-Net GAN 모형보다 정성적이고, 정량적인 척도 즉, PSNR (Peak Signal-to-Noise Ratio) 그리고 SSIM (Structural Similarity Index Measure) 면에서 우수한 결과를 보였다.","Reducing the radiation dose during CT scanning can lower the risk of radiation exposure, but not only does the image resolution significantly deteriorate, but the effectiveness of diagnosis is reduced due to the generation of noise. Therefore, noise removal from CT images is a very important and essential processing process in the image restoration. Until now, there are limitations in removing only the noise by separating the noise and the original signal in the image area. In this paper, we aim to effectively remove noise from CT images using the wavelet transform-based GAN model, that is, the WT-GAN model in the frequency domain. The GAN model used here generates images with noise removed through a U-Net structured generator and a PatchGAN structured discriminator. To evaluate the performance of the WT-GAN model proposed in this paper, experiments were conducted on CT images damaged by various noises, namely Gaussian noise, Poisson noise, and speckle noise. As a result of the performance experiment, the WT-GAN model is better than the traditional filter, that is, the BM3D filter, as well as the existing deep learning models, such as DnCNN, CDAE model, and U-Net GAN model, in qualitative and quantitative measures, that is, PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index Measure) showed excellent results."
객체 검출 알고리즘을 활용한 딥러닝 기반 상완 신경총 초음파 영상의 분할에 관한 연구,2024,"['상완신경총', '초음파영상', '객체탐지', '이미지분할', 'Brachial Plexus', 'Ultrasound Image', 'Object Detection', 'Image Segmentation']","초음파 유도 국소마취는 통증 관리와 회복 시간을 개선하여 말초신경 차단에 널리 사용되는 기법이다. 하지만 능숙한 임상의들에게도 초음파 영상에서 나타나는 speckle 및 Doppler와 같은 영상에 내재되어 있는 artifacts로 인하여 상완 신경총(BP; Brachial Plexus)의 정확한 검출 및 식별이 여전히 난제로 남아있다. 이 문제를 해결하기 위해, 우리는 다중 스케일의 접근법을 기반으로 하는 BP의 객체 검출과 그 결과로부터 U-Net 기반의 의미론적 영상 분할을 수행하는 small target 기반의 BP segmentation 알고리즘을 제안한다. 이를 위해 현재 BP 검출 및 식별은 다음과 같이 진행되었다: 1) 다중 스케일 기반의 RetinaNet 모델을 활용하여 BP 신경 영역을 대략적으로 특정하는 단계와 2) 객체 검출로부터 제한된 영상의 범위를 입력으로 U-Net을 활용함으로서 BP 신경의 영역을 검출하는 단계. 실험 결과는 제안된 모델이 분할 전용 모델 등의 경쟁 방법에 비해 BP 신경 영역을 대략적으로 특정하여 식별 범위를 제한함으로서 BP 신경 범위 분할의 정확도를 높이고 고품질 BP 분할을 생성할 수 있음을 보여준다.","Ultrasound-guided regional anesthesia is one of the most common techniques used in peripheral nerve blockade by enhancing pain control and recovery time. However, accurate Brachial Plexus (BP) nerve detection and identification remains a challenging task due to the difficulty in data acquisition such as speckle and Doppler artifacts even for experienced anesthesiologists. To mitigate the issue, we introduce a BP nerve small target segmentation network by incorporating BP object detection and U-Net based semantic segmentation into a single deep learning framework based on the multi-scale approach. To this end, the current BP detection and identification was estimated: 1) A RetinaNet model was used to roughly locate the BP nerve region using multi-scale based feature representations, and 2) U-Net was then used by feeding plural BP nerve features for each scale. The experimental results demonstrate that our proposed model produces high quality BP segmentation by increasing the accuracies of the BP nerve identification with the assistance of roughly locating the BP nerve area compared to competing methods such as segmentation-only models."
아시아 상장지수펀드(ETF)의 가격효율성과 유동성에 관한 연구,2024,"['아시아 상장지수펀드(ETF)', '가격괴리율', '유동성', '분위수 회귀분석', 'Asia Exchange Traded Fund(ETF)', 'Differentials', 'Liquidity', 'Quantile regression']","본 연구에서는 가격효율성이 유동성과 연관되어 있다는 점을 고려해 가격괴리율에 대한 유동성의 영향을 실증분석하였다. ETF 가격괴리율과 유동성 간의 관계를 파악하기 위해 본 연구에서는 미국 뉴욕증권거래소(NYSE)에 상장된 6개의 아시아 국가 ETF(한국, 중국, 인도, 인도네시아, 말레이시아, 필리핀)를 선정하였으며, 표본기간은 2015년 1월 2일부터 2023년 2월 28일까지이다. 분석 결과 아시아 국가 ETF의 가격괴리율 정도가 전반적으로 작은 상황에서 유동성은 가격괴리율과 음(-)의 관계를 가지는 것으로 나타났으며, 펀드 프리미엄 및 디스카운트 각각에 대해서는 각각 양(+)과 음(-)으로 추정되었다. 그리고 ETF의 가격괴리율에 대해 모멘텀(momentum)은 양(+)의 관계, 회전율은 음(-)의 관계를 가졌으며, 변동성(VOL)을 의미하는 모수는 4개 국가 ETF(인도, 인도네시아, 말레이시아, 필리핀)에서 음(-)으로 추정되었다. 이처럼 미국 시장에서 거래되는 아시아 ETF의 경우 가격괴리율 현상은 유동성, 변동성, 회전율과 관련이 있으며, 방향은 프리미엄 또는 디스카운트에 따라 다를 수 있다는 사실을 발견하였다.","Considering that price efficiency is related to liquidity, this study empirically analyzed the effect of liquidity on the differentials  defined by the relationship between ETF prices and the net asset value (NPV) of underlying assets. In order to understand the relationship between differentials and liquidity in ETF, this study selected six Asian countries ETFs (Korea, China, India, Indonesia, Malaysia, and the Philippines) listed on the New York Stock Exchange (NYSE), and the sample period is from January 2, 2015 to February 28, 2023. As a result of the analysis, liquidity was estimated to have a negative (-) relationship with differentials  in Asian countries, and positive (+) and negative (-), respectively, for fund premiums and discounts. In addition, the momentum was positive (+) and the rotation rate was negative (-) for the ETF's price distortion rate, and the parameter, which means volatility (VOL), was estimated to be negative (-) in the four countries ETFs (India, Indonesia, Malaysia, and the Philippines). In the case of Asian ETFs traded in the U.S. market, it was found that differentials phenomenon is related to liquidity, volatility, and turnover, and the direction may vary depending on premium or discount. In addition, although the ETF's in-kind creation and redemption functions contribute to efficient pricing, it can be seen that in the country ETF market, prices are formed inefficiently due to continuous price errors due to arbitrage restrictions. Therefore, if arbitrage trading is possible indefinitely, it can be suggested as a practical implication that the deviation from the net asset value may be reduced."
문화예술부문에 대한 재정지출이 온실가스배출에 미치는 영향분석,2024,"['Culture and Art', 'Greenhouse Gas Emissions', 'Environmental Kuznets Curve Model', 'Dynamic Panel Model', 'Generalized Method of Moments', '문화예술', '온실가스배출', '환경쿠츠네츠 모형', '동태적 패널모형', '일반화적률추정법']","기후변화로 인해 환경적 고려의 중요성이 더욱 강조되고 있다. 이에 본 연구는 동태패널모형을 활용한 2단계 추정법을 적용하여, 문화․예술부문 재정지출이 온실가스 배출에미치는 영향을 직접효과와 간접효과로 구분하여 분석하였다. 1단계 분석 결과, 문화․예술부문 재정지출의 증가는 지역 경제성장에 긍정적인 영향을 미치는 것으로 나타났다. 2 단계 분석 결과, 1인당 GRDP와 온실가스 배출량 사이에 역 U자형 곡선이 존재하며, 이는 환경 쿠즈네츠 곡선 가설을 지지함을 확인하였다. 한편, 문화․예술부문 재정지출은온실가스 배출량을 직접적으로 증가시키지만, 지역 경제성장을 통해 간접적으로는 감소시키는 것으로 나타났다. 그러나 직접효과가 간접효과보다 더 크게 나타나, 총 효과로는온실가스 배출량 증가를 초래하는 것으로 분석되었다. 본 연구결과는 지방정부 차원의효율적인 온실가스 저감 정책을 위해 문화․예술 활동에서의 에너지 효율성을 높이고 친환경 에너지원 사용을 촉진하는 방안이 필요하며, 문화․예술 종사자의 환경에 대한 인식과 에너지 소비패턴의 변화를 유도할 수 있는 지원이 필요함을 의미한다.","As the culture and arts sector develops alongside economic growth, the increase in greenhouse gas emissions highlights the importance of environmental considerations in the context of climate change. This study employs a two-step estimation method using a dynamic panel model to analyze the impact of fiscal expenditure for the culture and arts sector on greenhouse gas emissions, distinguishing between direct and indirect effects. The first-stage analysis reveals that increased fiscal expenditure in the culture and arts sector positively impacts regional economic growth. The second-stage analysis indicates the presence of an inverted U-shaped curve between per-capita GRDP and greenhouse gas emissions, supporting the Environmental Kuznets Curve hypothesis. While fiscal expenditure for the culture and arts sector directly increases greenhouse gas emissions, it indirectly reduces them through regional economic growth. However, the direct effect is greater and more significant than the indirect effect, resulting in a net increase in greenhouse gas emissions. These findings suggest that for effective greenhouse gas reduction policies at the local government level, it is necessary to improve energy efficiency in cultural and artistic activities and promote the use of eco-friendly energy sources. Additionally, there is a need for support that can raise environmental awareness among cultural and artistic professionals and induce changes in their energy consumption patterns."
문제해결에 기초한 그림책 토의 활동이 유아의 정서지능 및 또래유능성에 미치는 영향,2024,"['핵심어: 문제해결', '그림책 토의활동', '유아', '정서지능', '또래 유능성', 'Key Words: Problem-solving', 'Picture Book Discussion Activities', 'Young Children’s', 'Emotional Intelligence', 'Emotional Intelligence']","문제해결에 기초한 그림책 토의 활동이 유아의 정서지능 및 또래유능성에 미치는 영향양 소 령ㆍ김 현 정연구 목적: 본 연구 목적은 문제해결에 기초한 그림책 토의 활동이 유아의 정서지능 및 또래유능성에 미치는 영향을 분석하는데 목적이 있다.연구 방법: 연구대상은 G시에 위치한 U유치원 만 5세 유아 38명(실험집단 19명, 통제집단 19명)이다. 연구도구는 정서지능과 또래유능성 검사도구를 사용하였다. 실험처치는 8주간 총 8회에 걸쳐 실시하였다. 수집된 자료는 SPSS 통계 프로그램으로 독립 t검정을 실시하였다.연구 내용: 첫째, 문제해결에 기초한 그림책 토의활동이 유아의 정서지능에 긍정적인 영향을 주는 것으로 나타났다. 둘째, 문제해결에 기초한 그림책 토의활동이 유아의 또래유능성에 긍정적인 영향을 주는 것으로 나타났다.결론 및 제언: 유아들이 일상생활 및 활동 환경 내에서 또래와의 긍정적인 상호작용을 통해 사회적 기술을 발달시키고, 갈등 상황을 건설적으로 해결하는 능력을 키울 수 있음을 시사한다.핵심어: 문제해결, 그림책 토의활동, 유아, 정서지능, 또래 유능성","Effects of a Problem-solving-based Picture Book Discussion Activity on Toddlers’ Emotional Intelligence andPeer Competence Soryeong Yang** & Hyunjeong Kim*** Abstract: The objective of this study was to assess the impact of problem-solving oriented picture book discussion activities on the emotional intelligence and peer competence of children. This study involved 38 children aged five from kindergarten U in the city of G, divided into an experimental group of 19 and a comparison group of 19. Instruments measuring emotional intelligence and peer competence were utilized as research tools. The intervention consisted of eight sessions conducted over a period of eight weeks. Data were analyzed using an independent t-test with the statistical software SPSS. The findings indicated that problem-solving oriented picture book discussions significantly enhanced the emotional intelligence and peer competence of toddlers. These results suggest that toddlers can develop social skills and improve their capacity to resolve conflicts constructively through positive interactions with peers in their daily lives and activities.Key Words: Problem-solving, Picture Book Discussion Activities, Young Children’s, Emotional Intelligence, Emotional Intelligence □ 접수일: 2024년 4월 3일, 수정일: 2024년 4월 18일, 게재확정일: 2024년 4월 20일＊ 이 논문은 2023학년도 남부대학교 학술연구비의 지원을 받아 연구되었음.이 논문은 주저자의 2023년도 남부대학교 석사학위논문을 수정･보완한 것임.** 주저자, 우암유치원 교사(First Author, Teacher, Uam Kindergarden, Email: thfud9639@daum.net)*** 교신저자, 남부대학교 유아교육과 부교수(Corresponding Author, Professor, Nambu Univ., Email: jhmom@nambu.ac,kr)"
딥러닝을 이용한 스마트팜 로봇용 작물 부위 정밀 인식기술,2024,"['딥러닝', '시맨틱 세그멘테이션 신경망', '스마트팜', '로봇', '작물 부위 인식', 'Deep learning', 'Semantic segmentation neural network', 'smart farm robot', 'crop part recognition']","스마트팜에서 로봇으로 작물의 생육을 관리하기 위해 줄기, 가지, 잎, 과일 같은 작물 부위를정밀하게 인식하는 것이 선행되어야 한다. 이 본문에서는 시맨틱 세그멘테이션 딥러닝을 이용하여 작물 부위를 인식하는 기술을 제안한다. 딥러닝 학습용 데이터셋 구축을 위해 토마토 작물의 RGB 이미지를 확보하고 라벨링하여 시맨틱 세그멘테이션 신경망 학습용 데이터셋을 구축한다. 시맨틱 세그멘테이션 신경망 U-Net을 개선하여 제안한 작물 부위 인식 기술에 적용하여 실험하고 신경망 종류에 따른 성능을 평가한다. 개선된 U-Net은 효율적 구성으로 실시간 처리가 필요한 로봇 작업에 적합하다. 제안한 작물 부위 인식 기술은 스마트팜 로봇에 접목하여 작물의 생육 관리에 활용될 것으로 기대된다.","For crop growth management robots in smart farms, precisely recognizing cropparts is needed. This paper proposes a technology to recognize crop parts usingsemantic segmentation deep learning. To build a deep learning learning dataset, theRGB images of tomato crops are secured and labeled to construct a semanticsegmentation neural network learning dataset. We improve the semanticsegmentation neural network U-Net, apply it to the proposed crop part recognitiontechnology, and evaluate the neural network's performance. The modified U-Netwith efficient structure is proper for a robot operation with real-time process. Theproposed crop part recognition technology is expected to be applied to smart farmrobots and used for crop growth management."
Multi-scale context fusion network for melanoma segmentation,2024,"['Melanoma segmentation', 'Receptive field', 'Attention mechanism', 'multi-scale contextural information']",,"Aiming at the problems that the edge of melanoma image is fuzzy, the contrast with the background is low, and the hair occlusion makes it difficult to segment accurately, this paper proposes a model MSCNet for melanoma segmentation based on U-net frame. Firstly, a multi-scale pyramid fusion module is designed to reconstruct the skip connection and transmit global information to the decoder. Secondly, the contextural information conduction module is innovatively added to the top of the encoder. The module provides different receptive fields for the segmented target by using the hole convolution with different expansion rates, so as to better fuse multi-scale contextural information. In addition, in order to suppress redundant information in the input image and pay more attention to melanoma feature information, global channel attention mechanism is introduced into the decoder. Finally, In order to solve the problem of lesion class imbalance, this paper uses a combined loss function. The algorithm of this paper is verified on ISIC 2017 and ISIC 2018 public datasets. The experimental results indicate that the proposed algorithm has better accuracy for melanoma segmentation compared with other CNN-based image segmentation algorithms."
Denoising Laplace-domain Seismic Wavefields using Deep Learning,2024,"['seismic data processing', 'deep learning', 'random noise attenuation', 'Laplace domain', 'full waveform inversion']",,"Random noise in seismic data can significantly impair hydrocarbon exploration by degrading the quality of subsurface imaging. We propose a deep learning approach to attenuate random noise in Laplace-domain seismic wavefields. Our method employs a modified U-Net architecture, trained on diverse synthetic P-wave velocity models simulating the Gulf of Mexico subsurface. We rigorously evaluated the network’s denoising performance using both the synthetic Pluto velocity model and real Gulf of Mexico field data. We assessed the effectiveness of our approach through Laplace-domain full waveform inversion. The results consistently show that our UNet approach outperforms traditional singular value decomposition methods in noise attenuation across various scenarios. Numerical examples demonstrate that our method effectively attenuates random noise and significantly enhances the accuracy of subsequent seismic imaging processes."
AI 기반 항공기 광학 탐지 장치 성능 개선을 위한 합성 이미지 활용 연구,2024,"['Multi-ISO', 'Deep learning', 'Infrared detection', 'Noise reduction', 'Synthetic data']","본 연구는 야간 환경에서 발생하는 조명과 노이즈에 의한 이미지 왜곡을 저감하고, 적외선 탐지 장치의 성능을 향상시키기 위해 AI 기반 이미지 복원 기술을 제안한다. 이를 위해 가시광선 이미지를 기반으로 다양한 조명 조건과 ISO 값을 반영한 합성 이미지 데이터셋을 구축하고, 딥러닝 모델(AutoEncoder 및 U-Net)을 활용하여 원본 이미지 복원 성능을 확인하였다. 실험 결과, Multi-ISO 모델(9채널)이 Single-ISO 모델(3채널)보다 전반적으로 우수한 성능을 보였으며, 특히 다양한 ISO 값을 활용한 입력 데이터가 이미지 복원 성능을 향상시킴을 입증하였다. 본 연구는 실제 데이터 수집이 어려운 상황에서도 합성 데이터를 통해 AI 모델을 효과적으로 학습시키고, 이미지 복원에 적용할 수 있음을 확인하였다. 이러한 연구 결과는 AI를 활용한 광학 탐지 장치의 성능을 향상시키는 데 기여할 수 있을 것으로 기대된다.","This study proposes an AI-based image restoration technique to reduce image distortion caused by lighting and noise in nighttime environments and improve the performance of infrared detection systems. A synthetic image dataset was constructed using visible light images under various lighting conditions and ISO settings, and deep learning models (AutoEncoder and U-Net) were trained to assess image restoration performance. Experimental results show that the Multi-ISO model (9-channel) outperforms the Single-ISO model (3-channel), especially when utilizing input data with multiple ISO values. This study demonstrates that AI models can be effectively trained using synthetic data, even when real data collection is challenging, and can be applied to image restoration tasks. These findings are expected to contribute to enhancing the performance of optical detection systems through AI-based technology."
모션블러 이미지에 대한 CNN 모델의 균열 검출 성능,2024,"['CNN (convolutional neural network)', 'Motion blur', 'Dataset', 'Crack detection', 'F1 score', 'CNN (convolutional neural network)', '모션블러', '데이터셋', '균열 검출', 'F1 score']",,"In this study, we analyzed the effect of motion blur on images used for detecting cracksin concrete tunnel linings on the performance of CNN models. Motion-blurred imageswith intensities ranging from 10 to 50 were generated on the Kaggle and KICT datasets.A semantic segmentation model with ResNet 18, ResNet 34, VGG 11, and Alex-Net as backbones for feature extraction was employed, all pre-trained on the U-Netarchitecture. The performance of these models in crack detection was then assessed.It was observed that detection accuracy decreased across all models as the intensity ofmotion blur increased for each dataset. Within the same model, the F1-score on theKICT dataset showed over 20% higher performance than on the Kaggle dataset. Thisstudy demonstrates that CNN-based crack detection performance is affected by thequality of the image data and that the crack detection accuracy of CNN models canvary depending on the quality of the dataset used in training."
드론 항공영상을 이용한 딥러닝 기반 앙상블 토지 피복 분할알고리즘 개발,2024,"['앙상블학습', '투표알고리즘', '토지피복분할', 'Ensemble learning method', 'Voting system', 'Cadastral segmentation']",,"In this study, a proposed ensemble learning technique aims to enhance the semantic segmentationperformance of images captured by Unmanned Aerial Vehicles (UAVs). With the increasing use of UAVsin fields such as urban planning, there has been active development of techniques utilizing deep learningsegmentation methods for land cover segmentation. The study suggests a method that utilizes prominentsegmentation models, namely U-Net, DeepLabV3, and Fully Convolutional Network (FCN), to improvesegmentation prediction performance. The proposed approach integrates training loss, validation accuracy,and class score of the three segmentation models to enhance overall prediction performance. The methodwas applied and evaluated on a land cover segmentation problem involving seven classes: buildings, roads,parking lots, fields, trees, empty spaces, and areas with unspecified labels, using images captured by UAVs.The performance of the ensemble model was evaluated by mean Intersection over Union (mIoU), and theresults of comparing the proposed ensemble model with the three existing segmentation methods showedthat mIoU performance was improved. Consequently, the study confirms that the proposed technique canenhance the performance of semantic segmentation models."
Intelligent detection of fastener defects and mixed assortments,2024,['Artificial intelligenceFastenerDefectMixed assortmentsDetection'],,This paper investigates the use of artificial intelligence (AI) image detection and discrimination technology to address issues related to mixed assortments and defects encountered in the fastener manufacturing and packaging processes. The defect detection system primarily utilizes the YOLOv4-tiny model with parameter setting and data augmentation techniques. The mixed assortments detection system is constructed using U-Net-Light and Siamese network. The research results demonstrate that the developed systems can indeed replace or assist on-site personnel in conducting efficient and accurate inspections and screenings.
딥러닝 기법을 이용한 연안 양식 시설 탐지의 정확도 평가,2024,"['Sentinel-2', '딥러닝', '양식시설물 탐지', 'Deep learning', 'Aquaculture facility detection']",,"Due to declining fish catches caused by rapid climate change and advancements in aquaculture technology, the global demand for aquaculture products is continuously increasing. However, since the reckless expansion of facilities adversely affects the coastal ecosystem and fish stock prices, managing aquaculture facilities through periodic coastal environment monitoring is essential. This study analyzed the detection accuracy of shellfish aquaculture facilities in Gyeongsangnam-do using Sentinel-2 optical imageries and deep learning-based detection methodology. The DeepLabv3+, ResUNet++, and Attention U-Net networks were applied, and as a result, Attention U-Net showed the best detection performance with F1 score of 0.8708 and Intersection over Union 0.7708. The detection methodology presented in this study allows periodic observation of aquaculture facilities affected by sea currents and suspending matters. Also, it may apply to detecting various aquaculture species, showing high potential for expansion to wider areas. Therefore, the aquaculture facility information derived through this study is expected to be useful for future policy decisions regarding marine spatial utilization."
Reduced Scan Time in Multi-Echo Gradient Echo Imaging Using Two-Stage Neural Network,2024,"['Artificial neural network', 'Multi-echo gradient echo', 'Myelin water fraction', 'Pseudo-T1 map']",,"Purpose: Multi-echo gradient echo (mGRE) images are used to acquire and analyze multiple echo signals. As the number of acquired echoes increases, more information on the voxel decay changes can be obtained, facilitating myelin water fraction (MWF) mapping.However, an increase in the acquired echoes leads to an increase in scan time. In this study, we developed a workflow to reduce the scan time using a two-stage neural network approach, which extrapolates additional echo images using mGRE data.Materials and Methods: In Stage 1, a pseudo-T1 map was estimated using a U-net network combined with a simple signal model to correct the bias between two mGRE acquired with different scan parameters. The pseudo-T1 map was used to generate an initial echo time (TE) image from the mGRE images. In Stage 2, subsequent TE images were predicted from the initial echo image generated using a trained prediction network. The results were quantitatively compared with those obtained using a fitting algorithm. The MWF mapping results were then compared.Results: The proposed model exhibited better root mean square error, structural similarity index measure, and peak signal-to-noise ratio, as well as a higher correlation with the MWF analysis compared to the fitting algorithm.Conclusion: These results demonstrate that the proposed network can effectively reduce the scan time for mGRE image acquisition."
Automated Brain Segmentation on Computed Tomographic Images Using Perceptual Loss Based Convolutional Neural Networks,2024,"['Magnetic resonance imaging', 'Computed tomography', 'Brain segmentation', 'Deep learning', 'Perceptual loss']",,"Purpose: This study aimed to develop a new convolutional neural network-based deep learning (DL) technique for automated brain tissue segmentation from computed tomographic (CT) scans and to evaluate its performance in comparison to magnetic resonance imaging (MRI)-derived segmentations.Materials and Methods: This multicenter retrospective study collected paired CT and MRI data from 199 healthy individuals across two institutions. The data were divided into a training set (n = 100) and an internal test set (n = 50) from one institution, with additional datasets (n = 49) from the second institution for external validation. Ground truth masks for gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF) were generated from T1-weighted MR images. A U-Net-based DL model was trained for each of the three brain regions, with a perceptual loss computed from VGG19. Model performance was evaluated by calculating continuous Dice coefficient (cDice), intersection-over-union (IOU), and 95th percentile Hausdorff distance (HD95). Volumetric estimates from CT-based segmentations were compared with MRI-derived volumes using the coefficient of determination (R2), intraclass correlation coefficients (ICC), and Bland-Altman analysis.Results: The DL network trained with the perceptual loss showed superior performance, compared with that trained without the perceptual loss. In internal tests, evaluation scores (without perceptual loss vs. with perceptual loss) were: cDice = 0.717 vs. 0.765 and HD95 = 6.641 mm vs. 6.314 mm in GM; cDice = 0.730 vs. 0.767 and HD95 = 5.841 mm vs. 5.644 mm in WM; and cDice = 0.600 vs. 0.630 and HD95 = 5.641 mm vs. 5.362 mm in CSF, respectively.Volumetric analyses revealed strong agreement between MRI-derived ground truth and CT-based segmentations with R2 = 0.83/0.90 and 0.85/0.87, and ICC = 0.91/0.94 and 0.92/0.93 for GM and WM, respectively, in internal/external tests.Conclusion: The proposed DL method, enhanced with perceptual loss, improves brain tissue segmentation from CT images. This approach shows promise as an alternative to MRIbased segmentation."
Development of a PCA-Based Post-Processing Algorithm for Individual Teeth Segmentation in Dental X-ray Images,2024,"['dimensionality reduction', 'advanced medical imaging', 'image segmentation', 'medical aid diagnosis', 'convolution neural network']",,"With advancements in artificial intelligence, various fields, including magnetic medical science, are achieving results by utilizing it. In particular, the use of AI based medical image processing in dentistry is predicting oral conditions through image processing such as panoramic images and Computed Tomography (CT) contributing to the improvement of dental services. This study proposes an algorithm to improve the accuracy of individual tooth segmentation based on dental panoramic images to promote precise diagnosis and treatment planning, and to contribute to medical imaging technology with magnetic medical imaging. U-Net is improved to segment images and a post-processing step based on principal component analysis (PCA) was applied. The results show that the proposed post-processing algorithm outperforms the existing method, and the accuracy of tooth segmentation was improved. It is expected to remarkably improve clinical efficiency in dentistry and provide a foundation for the magnetic medical imaging techniques in the diagnosis and treatment of oral diseases."
Application of deep learning for semantic segmentation in robotic prostatectomy: Comparison of convolutional neural networks and visual transformers,2024,"['Artificial intelligence', 'Computer vision systems', 'Deep learning', 'Prostatectomy']",,"Purpose: Semantic segmentation is a fundamental part of the surgical application of deep learning. Traditionally, segmentation in vision tasks has been performed using convolutional neural networks (CNNs), but the transformer architecture has recently been introduced and widely investigated. We aimed to investigate the performance of deep learning models in segmentation in robot-assisted radical prostatectomy (RARP) and identify which of the architectures is superior for segmentation in robotic surgery.Materials and Methods: Intraoperative images during RARP were obtained. The dataset was randomly split into training and validation data. Segmentation of the surgical instruments, bladder, prostate, vas and seminal vesicle was performed using three CNN models (DeepLabv3, MANet, and U-Net++) and three transformers (SegFormer, BEiT, and DPT), and their performances were analyzed.Results: The overall segmentation performance during RARP varied across different model architectures. For the CNN models, DeepLabV3 achieved a mean Dice score of 0.938, MANet scored 0.944, and U-Net++ reached 0.930. For the transformer architectures, SegFormer attained a mean Dice score of 0.919, BEiT scored 0.916, and DPT achieved 0.940. The performance of CNN models was superior to that of transformer models in segmenting the prostate, vas, and seminal vesicle.Conclusions: Deep learning models provided accurate segmentation of the surgical instruments and anatomical structures observed during RARP. Both CNN and transformer models showed reliable predictions in the segmentation task; however, CNN models may be more suitable than transformer models for organ segmentation and may be more applicable in unusual cases. Further research with large datasets is needed."
딥러닝을 이용한 DEMON 그램 주파수선 추출 기법 연구,2024,"['Deep learning', 'Semantic segmentation', 'Detection of Envelope Modulation on Noise (DEMON)', 'DEMONgram', 'Frequency line extraction', '딥러닝', '의미론적 분할', 'Detection of Envelope Modulation on Noise (DEMON)', 'DEMON 그램', '주파수선 추출']","수중 소음 측정이 가능한 수동 소나에 수신된 선박 방사소음은 Detection of Envelope Modulation on Noise(DEMON) 분석으로 얻은 선박 정보를 사용하여 선박 식별과 분류가 가능하다. 하지만 낮은 신호대잡음비(Signal-to-Noise Ratio, SNR) 환경에서는 DEMON 그램 내 선박 정보가 담겨있는 표적 주파수선을 분석 및 파악하는데 어려움이 발생한다. 본 논문에서는 낮은 SNR 환경에서 보다 정확한 표적 식별을 위해 딥러닝 기법 중 의미론적 분할을 사용하여 표적 주파수선들을 추출하는 연구를 수행하였다. SNR과 기본 주파수를 변경시키며 생성한 모의 DEMON 그램 데이터를 사용하여 의미론적 분할 모델인 U-Net, UNet++, DeepLabv3+를 학습 후 평가하였고, 학습된 모델들을 이용하여 캐나다 조지아 해협에서 측정한 선박 방사소음 데이터셋인 DeepShip으로 제작한 DEMON 그램 예측 성능을 비교하였다. 모의 DEMON 그램으로 학습된 모델을 평가한 결과 U-Net이 성능이 가장 높았으며, DeepShip으로 만든 DEMON 그램의 표적 주파수선을 어느 정도 추출할 수 있는 것을 확인하였다.",
생체정보 보호를 위한 CNN 기반의 홍채 지문 영역 분할,2024,"['Segmentation', 'Detection', 'Artificial Intelligence Learning', 'Biometric Information', 'CNN', '영역 분할', '감지', '인공지능 학습', '생체 정보', '합성곱 신경망 모델']","스마트 기기의 발달과 고해상도 이미징 기술의 대중화로 인해, 지문이 노출되거나, 화상 회의, 화상 통화 등 고화질 얼굴 사진에서 홍채 정보가 노출되고 있다. 스마트기기의 대중화는 일상적인 디지털 활동에서 무분별한 사진 공유로 인해, 개인의 생체정보인 지문이나 홍채가 노출되어 위조 및 악용될 가능성이 높아지고 있다. 이러한 문제를 해결하기 위해서 본 논문에서는 원본 이미지로부터 생체정보를 보호하고 보안을 강화할 목적으로 CNN의 영역 분할기법을 활용하여 이미지 내 지문과 홍채를 식별 보호하는 방안을 제안한다. 제안된 모델은 입력 이미지에서 지문 및홍채를 식별한 후 해당 영역에 블러 처리를 적용하며, 이를 원본 이미지와 결합하여 보안성을 강화한다. U-Net 및ResNet-34를 백본으로 사용한 모델 구조를 통해 학습 시간 및 성능을 비교한다.","With the development of smart devices and the popularization of high-resolution imaging technology, fingerprints arebeing exposed, and iris information is being exposed in high-definition facial photos such as video conferences and videocalls. The popularization of smart devices has increased the possibility of personal biometric information such asfingerprints and irises being exposed and forged and misused due to indiscriminate photo sharing in everyday digitalactivities. To solve this problem, this paper proposes a method to identify and protect fingerprints and irises in imagesby utilizing CNN's region segmentation technique for the purpose of protecting biometric information from the originalimage and enhancing security. The proposed model identifies fingerprints and irises in the input image, applies blurringto the corresponding regions, and combines them with the original image to enhance security. The learning time andperformance are compared through model structures using U-Net and ResNet-34 as backbones."
딥러닝을 이용한 창상 분할 알고리즘,2024,"['Deep learning', 'Wound segmentation', 'Machine learning labeling', 'Medical image analysis']",,"Diagnosing wounds presents a significant challenge in clinical settings due to its complexity and the subjective assessments by clinicians. Wound deep learning algorithms quantitatively assess wounds, overcoming these challenges.However, a limitation in existing research is reliance on specific datasets. To address this limitation, we created a compre- hensive dataset by combining open dataset with self-produced dataset to enhance clinical applicability. In the annotation process, machine learning based on Gradient Vector Flow (GVF) was utilized to improve objectivity and efficiency over time. Furthermore, the deep learning model was equipped U-net with residual blocks. Significant improvements were observed using the input dataset with images cropped to contain only the wound region of interest (ROI), as opposed to original sized dataset. As a result, the Dice score remarkably increased from 0.80 using the original dataset to 0.89 using the wound ROI crop dataset. This study highlights the need for diverse research using comprehensive datasets. In future study, we aim to further enhance and diversify our dataset to encompass different  environments and ethnicities."
Deep learning-based automatic segmentation of the mandibular canal on panoramic radiographs: A multi-device study,2024,"['Mandibular Canal', 'Panoramic Radiography', 'Deep Learning', 'Artificial Intelligence']",,"Purpose: The objective of this study was to propose a deep-learning model for the detection of the mandibular canal on dental panoramic radiographs.Materials and Methods: A total of 2,100 panoramic radiographs (PANs) were collected from 3 different machines: RAYSCAN Alpha (n = 700, PAN A), OP-100 (n = 700, PAN B), and CS8100 (n = 700, PAN C). Initially, an oral and maxillofacial radiologist coarsely annotated the mandibular canals. For deep learning analysis, convolutional neural networks (CNNs) utilizing U-Net architecture were employed for automated canal segmentation. Seven independent networks were trained using training sets representing all possible combinations of the 3 groups. These networks were then assessed using a hold-out test dataset.Results: Among the 7 networks evaluated, the network trained with all 3 available groups achieved an average precision of 90.6%, a recall of 87.4%, and a Dice similarity coefficient (DSC) of 88.9%. The 3 networks trained using each of the 3 possible 2-group combinations also demonstrated reliable performance for mandibular canal segmentation, as follows: 1) PAN A and B exhibited a mean DSC of 87.9%, 2) PAN A and C displayed a mean DSC of 87.8%, and 3) PAN B and C demonstrated a mean DSC of 88.4%.Conclusion: This multi-device study indicated that the examined CNN-based deep learning approach can achieve excellent canal segmentation performance, with a DSC exceeding 88%. Furthermore, the study highlighted the importance of considering the characteristics of panoramic radiographs when developing a robust deep-learning network, rather than depending solely on the size of the dataset."
IRAE-UNet: InceptionResNetV2 -Attention Encoder based UNet Semantic Segmentation of Aerial Imagery,2024,"['remote sensing', 'attention', 'image segmentation', 'inception', '원격 감지', '어텐션', '영상 분할', 'Inception']",,"Remote sensing applications play a vital role in various areas such as urban planning, agriculture, and environmental monitoring. Remote sensing image segmentation, in particular, is a prominent domain that aims to address the challenges in these applications. Deep learning has significantly improved the efficiency and accuracy of remote sensing image segmentation by automating the identification of regions of interest. However, most existing methods struggle with capturing both global and local information in the images, which is crucial for accurate pixel classification. To overcome this limitation, this paper presents an enhanced version of the U-Net architecture that incorporates the InceptionResNetV2-Attention based encoder. This proposed method effectively combines the strengths of the Inception and ResNet architectures, along with the attention mechanism. The efficacy of the proposed network is verified using two publicly available datasets. The Semantic Drone Dataset consists of satellite images, while the NITRDrone dataset comprises images captured from Unmanned Aerial Vehicles (UAVs). The results demonstrate that the proposed architecture performs well on imagery obtained from different platforms, achieving  a dice-coefficient of 85.04% and 88.70% for each dataset respectively, outperforming other networks."
Extensive Multilabel Classification of Brain MRI Scans for Infarcts Using the Swin UNETR Architecture in Deep Learning Applications,2024,"['Deep learning', 'Infarction', 'Classification', 'Rehabilitation']",,"Objective: To distinguish infarct location and type with the utmost precision using the advantages of the Swin UNEt TRansformers (Swin UNETR) architecture.Methods: The research employed a two-phase training approach. In the first phase, the Swin UNETR model was trained using the Ischemic Stroke Lesion Segmentation Challenge (ISLES) 2022 dataset, which included cases of acute and subacute infarcts. The second phase involved training with data from 309 patients. The 110 categories result from classifying infarcts based on 22 specific brain regions. Each region is divided into right and left sides, and each side includes four types of infarcts (acute, acute lacunar, subacute, subacute lacunar). The unique architecture of Swin UNETR, integrating elements of both the transformer and u-net designs with a hierarchical transformer computed with shifted windows, played a crucial role in the study.Results: During Swin UNETR training with the ISLES 2022 dataset, batch loss decreased to 0.8885±0.1897, with training and validation dice scores reaching 0.4224±0.0710 and 0.4827±0.0607, respectively. The optimal model weight had a validation dice score of 0.5747. In the patient data model, batch loss decreased to 0.0565±0.0427, with final training and validation accuracies of 0.9842±0.0005 and 0.9837±0.0010.Conclusion: The results of this study surpass the accuracy of similar studies, but they involve the issue of overfitting, highlighting the need for future efforts to improve generalizability. Such detailed classifications could significantly aid physicians in diagnosing infarcts in clinical settings."
Deep learning framework for bovine iris segmentation,2024,"['Cow', 'Deep learning', 'Identification', 'Iris', 'Segmentation']",,"Iris segmentation is an initial step for identifying the biometrics of animals when establishing a traceability system for livestock. In this study, we propose a deep learning framework for pixel-wise segmentation of bovine iris with a minimized use of annotation labels utilizing the BovineAAEyes80 public dataset. The proposed image segmentation framework encompasses data collection, data preparation, data augmentation selection, training of 15 deep neural network (DNN) models with varying encoder backbones and segmentation decoder DNNs, and evaluation of the models using multiple metrics and graphical segmentation results. This framework aims to provide comprehensive and in-depth information on each model’s training and testing outcomes to optimize bovine iris segmentation performance. In the experiment, U-Net with a VGG16 backbone was identified as the optimal combination of encoder and decoder models for the dataset, achieving an accuracy and dice coefficient score of 99.50% and 98.35%, respectively. Notably, the selected model accurately segmented even corrupted images without proper annotation data. This study contributes to the advancement of iris segmentation and the establishment of a reliable DNN training framework."
무인항공기 광학 영상 기반 주진천 염생식물 분포 데이터셋,2024,"['Classification', 'Jujin estuary', 'Unmanned aerial vehicle', 'Vegetation']",,"The importance of blue carbon is significant in terms of climate change mitigationand marine ecosystem conservation, and halophyte acts as a crucial reservoir for thisblue carbon. Accordingly, this study utilized unmanned aerial vehicle (UAV) opticalsensors to create a distribution map of vegetation in the natural salt marsh of theJujin estuary. The optical images captured from a UAV at an altitude of 50 m provideultra-high-resolution optical information with a ground sampling distance of 0.6 cm.Based on these images, a U-Net model was trained to classify Phragmites communisand Suaeda maritima, generating a classification map of the mixed habitats of saltmarsh plants. The areas of Phragmites communis and Suaeda maritima in the Jujin-Cheon region were found to be 6,653.23 m² and 1,409.08 m², respectively. Theclassification results were validated using field control point data, confirming anapproximate classification accuracy of 92%."
GeoAI Dataset for Urbanized Area Segmentation from Landsat 8/9 Satellite Imagery and GEMS,2024,"['Deep learning', 'Urbanized area', 'AI dataset', 'Landsat', 'Air pollution']",,"In South Korea, air pollution has emerged as a pressing social issue, necessitatingdata-driven approaches to monitor sources of air pollutants. This study constructeda GEO AI dataset for detecting air pollution sources in urbanized areas, utilizingLandsat 8/9 satellite imagery, Geostationary Environment Monitoring Spectrometergeostationary satellite data, and air quality monitoring network data. The datasetis optimized for semantic segmentation tasks, including labeled data for urbanarea segmentation, and is designed to enable precise detection of pollution sourceswithin urban regions by integrating satellite imagery and air quality information.Using this dataset, we applied a modified U-Net model to classify pollutant sourcesin urbanized areas, achieving high performance with an mIoU of 0.8592 and pixelaccuracy of 0.9433. These results demonstrate the effectiveness of the GEO AIdataset as a tool for identifying and managing major pollution sources, providingfoundational data for air quality monitoring and policy development across SouthKorea and East Asia. With further integration of additional air pollution data, thisdataset is expected to contribute to long-term air quality management and themitigation of health impacts associated with pollution."
"The potential role of synthetic computed tomography in spinal surgery: generation, applications, and implications for future clinical practice",2024,"['Computed tomography', 'Magnetic resonance imaging', 'Convoluted neural networks', 'Spine surgery']",,"Computed tomography (CT) is widely used for the diagnosis and surgical treatment of spinal pathologies, particularly for pedicle screw placement. However, CT’s limitations, notably radiation exposure, necessitate the development of alternative imaging techniques. Synthetic CT (sCT), which generates CT-like images from existing magnetic resonance imaging (MRI) scans, offers a promising alternative to reduce radiation exposure. This study examines the emerging role of sCT in spinal surgery, focusing on usability, efficiency, and potential impact on surgical outcomes. This qualitative literature review evaluated various sCT generation methods, encompassing traditional atlas-based and bulk-density models, as well as advanced convolutional neural network (CNN) architectures, including U-net, V-net, and generative adversarial network models. The review assessed sCT accuracy and clinical feasibility across different medical disciplines, particularly oncology and surgery, with potential applications in orthopedic, neurosurgical, and spinal surgery. sCT has shown significant promise across various medical disciplines. CNN-based techniques enable rapid and accurate generation of sCT from MRI scans, rendering clinical use feasible. sCT has been used to identify pathologies and monitor disease progression, suggesting that MRI alone may suffice for diagnosis and planning in the future. In spinal surgery, sCTs are particularly useful in visualizing key anatomical features like vertebral dimensions and spinal canal diameter. However, challenges persist, especially in visualizing complex structures and larger spinal regions, like the lumbar spine. Additional limitations include inaccuracies stemming from surgical implants and image variability. The application of sCT technology in spinal surgery holds great promise, improving diagnostics, planning, and treatment outcomes. Although further research is required to improve its precision, it offers a viable alternative to traditional CT in many clinical contexts, with the potential for broader application as the technology matures."
자가 학습데이터를 활용한 딥러닝 모델 기반 세분류 토지피복 분류,2024,"['Aerial orthoimages', 'Subdivision land use map', 'Self-learning data', 'Segmentation model']",,"Land cover provides crucial information related to biological geography, ecologicalclimatology, and human activities. In the past, land cover mapping was performedbased on visual interpretation, but it had limitations in terms of time and cost.Recently, it has become possible to create land cover maps with higher temporalresolution over wider areas using artificial intelligence-based models. The accuracyand reliability of AI model-based land cover maps increase with the amount oftraining data, but it is difficult to acquire large amounts of data due to the timerequired for label data annotation. In South Korea, the Environmental GeographicInformation Service provides self-learning data consisting of aerial orthoimages andsubdivision land cover classification level label data, making it possible to collecthigh-quality data. Therefore, this study examined the feasibility of self-learningdata by building and evaluating a U-Net-based land cover classification model forwaterfront areas using self-learning data. The trained model showed relativelylow performance with an F-1 score of 0.61 for training data and 0.31 for test data.The model’s low performance is thought to be due to insufficient training causedby the large number of classification categories (34) and data imbalance betweencategories. Although the model performance using self-learning data was low, itis believed that model performance can be improved by grouping classificationcategories according to research purposes or resolving data imbalance through dataaugmentation techniques. Therefore, self-learning data is expected to be utilized invarious studies using land cover."
Automatic Segmentation and Radiologic Measurement of Distal Radius Fractures Using Deep Learning,2024,"['Distal radius fractures', 'Computer-assisted radiographic image interpretation', 'Deep learning']",,"Background: Recently, deep learning techniques have been used in medical imaging studies. We present an algorithm that measures radiologic parameters of distal radius fractures using a deep learning technique and compares the predicted parameters with those measured by an orthopedic hand surgeon.Methods: We collected anteroposterior (AP) and lateral X-ray images of 634 wrists in 624 patients with distal radius fractures treated conservatively with a follow-up of at least 2 months. We allocated 507 AP and 507 lateral images to the training set (80% of the images were used to train the model, and 20% were utilized for validation) and 127 AP and 127 lateral images to the test set. The margins of the radius and ulna were annotated for ground truth, and the scaphoid in the lateral views was annotated in the box configuration to determine the volar side of the images. Radius segmentation was performed using attention U-Net, and the volar/dorsal side was identified using a detection and classification model based on RetinaNet. The proposed algorithm measures the radial inclination, dorsal or volar tilt, and radial height by index axes and points from the segmented radius and ulna.Results: The segmentation model for the radius exhibited an accuracy of 99.98% and a Dice similarity coefficient (DSC) of 98.07% for AP images, and an accuracy of 99.75% and a DSC of 94.84% for lateral images. The segmentation model for the ulna showed an accuracy of 99.84% and a DSC of 96.48%. Based on the comparison of the radial inclinations measured by the algorithm and the manual method, the Pearson correlation coefficient was 0.952, and the intraclass correlation coefficient was 0.975. For dorsal/ volar tilt, the correlation coefficient was 0.940, and the intraclass correlation coefficient was 0.968. For radial height, it was 0.768 and 0.868, respectively.Conclusions: The deep learning-based algorithm demonstrated excellent segmentation of the distal radius and ulna in AP and lateral radiographs of the wrist with distal radius fractures and afforded automatic measurements of radiologic parameters."
초소형 위성과 연계한 딥러닝 수계 및 침수 지역 탐지 활용성 평가: PlanetScope 위성 영상과 HRNet 모형,2024,"['수체 탐지', '침수 탐지', '광학 위성 영상', 'PlanetScope', 'HRNet', 'Water body detection', 'Flood detection', 'Optical satellite imagery']",,"The continuous monitoring of water body is essential for efficient water resource management and the prevention of water-related disasters. Microsatellite and nanosatellite imageries provide a tool for continuous and accurate monitoring of water bodies at high spatial and temporal resolution. In this study, PlanetScope imagery with a resolution of 3.7 m and High-Resolution Network (HRNet) model were used to detect water bodies at dams and rivers in Korea, with the objective of evaluating the utility of water surface area monitoring. The HRNet model and the optimal band combinations of PlanetScope imagery which were R+G+B, R+G+B+NIR, Normalized Difference Water Index (NDWI), and Green+NIR+ NDWI, were initially evaluated. The Green+NIR+NDWI combination performed the best, with an accuracy of 0.91 and loss function of 0.05 for the validation set. Water body detection was performed using the HRNet model with the optimal band combination and models from previous studies (Otsu, K-means, U-net) The performance was evaluated through quantitative validation using labeled images. The HRNet model showed the best performance with an Intersection over Union (IoU) of 0.96, compared to models in previous studies (Otsu: 0.90, K-means: 0.92, U-net: 0.95). Additionally, the HRNet model’s flood detection performance showed an IoU of 0.93, indicating a high accuracy. However, there were limitations, as muddy and wet soil at the boundaries of flooded areas were false detected as water bodies. In the future, when a constellation of microsatellites is developed in Korea, the results of this study are expected to contribute to better management of water resources and water-related disasters through continuous monitoring of water bodies."
2단계 네트워크 DEA모형을 이용한 저비용항공사 점유율이 공항효율성에 미치는 영향,2024,"['Low Cost Carrier', 'Airport Efficiency', 'Two-Stage Network DEA', '저비용항공사', '공항효율성', '2단계 네트워크 DEA']","저비용항공사와 공항 효율성의 관계를 분석한 대부분의 선행연구는 DEA 분석을 통해 개별적으로 평가하는 방식으로 수행되었다. 이에 따라 공항의 프로세스가 하나의 블랙박스로 간주되어 비효율성이 공항 내 어느 단계에서 발생하는지에 대한 분석에 한계가 있었다. 본 연구는 2단계 네트워크 분석을 사용하여 공항의 효율성을 세분화하여 저비용항공사가 미치는 영향을 분석하였다. 네트워크 DEA는 기존 DEA 모델의 단점을 보완하는 방법으로 중간과정에서 발견하지 못한 부분을 세분화해서 설명할 수 있다.공항의 효율성 분석은 공항의 프로세스를 인프라, 인력 투입 등을 통해 여객, 화물 등을 산출하는 운영단계와 운영단계에서의 산출물을 활용하여 재무적 수익으로 전환하는 수익단계 2단계로 구조화하여 측정하였다.실증분석을 위해서 아태, 북미, 유럽의 세계주요공항 128개 공항을 분석 대상으로 하였고, 분석 기간은 2015년부터 2019년까지이다. 네트워크 DEA 모형의 1단계 투입변수는 활주로수, 터미널면적, 종업원수, 운영비용이고, 산출변수는 여객, 화물, 운항횟수이다. 2단계 투입요소는 1단계 산출요소를 투입요소로 하고 산출요소는 순영업이익을 사용하였다. 분석 결과 LCC 취항에 따른 운영효율성은 U자형으로 항공사 점유율이 특정 비율(40%) 이상이 되면 (+) 값을 갖는 것으로 나타났다. 수익효율성은 (-)값으로 나타났다. 전체효율성도 (-) 값으로 나타났는데, 이는 수익효율성의 (-)값이 운영효율성의 (+) 값을 상쇄시켰기 때문으로 판단된다. 네트워크 DEA를 활용하여 그동안 밝혀지지 않았던 중간과정의 효율성 분석이 가능하고, 결과를 기반으로 어떤 부분에서 공항의 효율성을 개선해야 하는지에 대한 실무적인 시사점을 얻을 수 있다.","Most previous studies have focused on examining the relationship between low-cost airlines and airport efficiency by individually evaluating airport efficiency through DEA ​​analysis. Accordingly, the airport’s process has been viewed as a black box, and there have been limitations in analyzing at what stage within the airport inefficiency occurs. This study used two-stage network analysis to segment airport efficiency and analyze the correlation with low-cost airlines. Network DEA is a method that avoids the shortcomings of the traditional DEA model and can illustrate efficiency in detail by decomposing hidden processes in the intermediate process.The airport’s efficiency evaluation was measured by structuring the airport’s process into two stages: the operation stage, which handles passengers and cargo through infrastructure and manpower input, and theprofit stage, which converts the output from the operation stage into financial profits.For the empirical analysis, 128 global major airports in Asia Pacific, North America, and Europe were selected, and the analysis period was from 2015 to 2019. The first stage input variables of the network DEA model are the number of runways, terminal area, number of employees, and operating costs, and the output variables are passengers, cargo, and number of flights. The second-stage input factors used the first-stage output factors as input factors, and net operating income was used as the output factor. As a result of the analysis, it was found that the operational efficiency achieved by LCC service is U-shaped and has a positive value when the airline’s market share exceeds a certain ratio (40%). Profit efficiency was shown as a (-) value. The overall efficiency also appeared as a (-) value, which is believed to be because the (-) value of revenue efficiency offset the (+) value of operating efficiency. By using network DEA, it has become possible to analyze intermediate processes that were previously hidden as black boxes, allowing airports to see in which areas they need to improve efficiency."
머신러닝을 이용한 한국 주식시장 변동성 예측: Multi-Input LSTM 모형의 적용,2024,"['VKOSPI', 'Volatility', 'Machine Learning', 'Forecasting', 'Multi-Input LSTM', 'VKOSPI', '변동성', '머신러닝', '예측', 'Multi-Input LSTM 모형']","본고는 다양한 머신러닝 방법과 폭넓은 설명변수를 활용하여 한국 주식시장의 중요 변동성 지표인 VKOSPI 지수를 예측/분석하였다. 일반적인 금융시장 지표뿐만 아니라 주식시장 자금흐름 및 수급동향과 관련된 변수들도 설명변수로 이용하였으며, 특히 변동성 예측을 위해 새로운 Multi-Input LSTM(Long Short-Term Memory) 모형을 제안하고 예측력을 평가하였다. 표준적인 변동성 모형인 HAR(Heterogeneous Autoregressive) 모형에 비해 머신러닝 모형들의 예측력이 전반적으로 우수한 것으로 나타났는데, 예측 대상기간이 짧은 경우 선형 모형이 그리고 예측 대상기간이 긴 경우 비선형 모형이 우수한 예측력을 보였다. 또한 Multi-Input LSTM 모형이 기존 LSTM 모형보다 예측력이 우수하다는 점과 주식시장 자금흐름 및 수급동향 관련 변수들이 Multi-Input LSTM 모형에서 중요한 역할을 한다는 것을 확인하였다.","This study explores the forecasting of the VKOSPI index, a vital volatility indicator for the Korean stock market, using advanced machine learning models. VKOSPI, similar to the VIX index in the U.S., reflects market expectations of future volatility and is crucial for risk management and financial derivatives pricing. Traditional forecasting models, such as the Heterogeneous Autoregressive (HAR) model, have been widely used in this domain. However, this research introduces a novel Multi-Input Long Short-Term Memory (LSTM) model, which incorporates a wide range of explanatory variables, including general financial variables, stock market fund flows and stock market transaction trend, to improve predictive accuracy.The Multi-Input LSTM model is designed to sequentially process categorized variables through multiple input layers, allowing it to capture complex patterns that are missed by simpler models. The study, based on data from January 2016 to March 2023, compares the forecasting performance of the Multi-Input LSTM with various other machine learning models, such as Random Forest, XGBoost, and linear models like LASSO and Elastic Net. With a total of 216 explanatory variables, including lagged values, the models are tested across different forecast horizons, including 1 day, 5 days, 10 days, and 22days.The results show that machine learning models, particularly non-linear ones such as LSTM, Random Forest, and XGBoost, outperform the HAR model, especially for longer forecast periods. The Multi-Input LSTM demonstrates superior accuracy, particularly when the variables about stock market transaction and stock market fund flow are included, highlighting their importance in predicting volatility. Furthermore, the study uses rigorous statistical tests to validate the enhanced performance of the Multi-Input LSTM model over traditional approaches.The study contributes to the growing field of machine learning in finance, demonstrating that advanced models like the Multi-Input LSTM can effectively handle the complexities of financial time series data."
5·18민주화운동 당시 적용된 계엄군 교범의 변화에 관한 연구,2024,"['Key Words: The May 18 Democratic Movement', 'Riot Suppression', 'Riot Suppression Operation', 'Civil Disturbance Suppression Operation', 'Field Manual', '핵심어: 5·18민주화운동', '폭동진압', '폭동진압작전', '소요진압작전', '야전교범']","【국문초록】 5·18민주화운동 당시 적용된 계엄군 교범의 변화에 관한 연구김 남 진ㆍ황보 근연구 목적: 본 연구의 목적은 5·18민주화운동 당시 계엄군에게 적용된 육군의 교범이 어떻게 변화되었는지 검토하여 문제점과 개선방안을 도출하고자 하였다.연구 방법: 육군의 교범을 연혁적으로 분석하였고, 이에 상응하는 미군의 교범을 비교 분석하였다.연구 내용: 1980년 당시 군이 폭동 진압 작전을 함에 있어서 광주시민을 어떻게 규정하고 작전을 수행하였는지를 교범 분석을 통해 연구하였다. 군 작전 계획에서 광주시민은 시민이 아닌 무장한 비정규군 즉 ‘적 또는 게릴라’로 규정하였다는 것을 확인할 수 있었다. 1981년과 1985년 두차례에 걸쳐 개정된 교범은 ‘적 또는 게릴라’를 대상으로 하는 보병의 작전 계열 교범으로 변경된 것을 확인했다.결론 및 제언: 국가폭력으로부터 국민의 인권을 지키기 위해서는 군의 행동 기준이 되는 기저 법령뿐만 아니라 작전의 기준이 되는 교범 중 잘못 제·개정된 교범을 고쳐야 한다. 본 연구결과를 통해 구체적으로 현행 소요 진압에 관한 보병의 작전 계열 교범을 헌병 작전 계열로 교범을 변경해야 한다고 제언한다.핵심어: 5·18민주화운동, 폭동진압, 폭동진압작전, 소요진압작전, 야전교범","A Study on the Changes of Manuals Applied to the Soldiers During the May 18 Democratic Movement* Namjin Kim** & Keun Hwangbo*** Abstract: This study examined the army’s Field manuals applied during the May 18 Democratization Movement and what is the problems and substitutes of the current manuals. The Army’s Field manuals are analyzed and the corresponding U.S. military Field manuals are compared.  Considering that the target of suppression was defined as ‘enemy or guerrilla’, not citizens, in the Field manual of U.S. army, the operation plan in Gwangju also. It was confirmed that the two revised in 1981 and 1985 were changed to infantry operational affiliates targeting ‘enemies or guerrillas’. This article pointed out that in order to protect the human rights of the people from national violence, it is necessary to correct the  revised Field manual of army. Specifically, it is necessary to change the current infantry’s operation-affiliated manual to the military police operation-affiliated manual.Key Words: The May 18 Democratic Movement, Riot Suppression, Riot Suppression Operation, Civil Disturbance Suppression Operation, Field Manual □ 접수일: 2024년 11월 29일, 수정일: 2024년 12월 17일, 게재확정일: 2024년 12월 30일＊ 이 논문은 2024년 광주광역시 보조금 지원사업에 의해 연구되었음.** 주저자, 전남대학교 5·18연구소 전임연구원(First Author, Researcher, Chonnam National Univ., Email: enjoik85@hanmail.net) *** 공동저자, 서강대학교 국제한국학선도연구소 책임연구원(Co-author, Researcher, Sogang Univ., Email: Kayhb39@gmail.com)"
Identification of Preeclamptic Placenta in Whole Slide Images Using Artificial Intelligence Placenta Analysis,2024,"['Placenta', 'Preeclampsia', 'Artificial Intelligence', 'Unsupervised Learning']",,"Background: Preeclampsia (PE) is a hypertensive pregnancy disorder linked to placental dysfunction, often involving pathological lesions like acute atherosis, decidual vasculopathy, accelerated villous maturation, and fibrinoid deposition. However, there is no gold standard for the pathological diagnosis of PE and this limits the ability of clinicians to distinguish between PE and non-PE pregnancies. Recent advances in computational pathology have provided the opportunity to automate pathological analysis for diagnosis, classification, prediction, and prediction of disease progression. In this study, we assessed whether computational pathology could be used to identify PE placentas.Methods: A total of 168 placental whole-slide images (WSIs) of patients from Seoul National University Hospital (comprising 84 PE cases and 84 normal controls) were used for model development and internal validation. For external validation of the model, 76 placental slides (including 38 PE cases and 38 normal controls) were obtained from the Boramae Medical Center (BMC). To establish standard criteria for diagnosing PE and distinguishing it from controls using placental WSIs, patch characteristics and quantification of terminal and intermediate villi were employed. In unsupervised learning, K-means clustering was conducted as a feature obtained through an Auto Encoder to extract the ratio of each cluster for each WSI. For supervised learning, quantitative assessments of the villi were obtained using a U-Net-based segmentation algorithm. The prediction model was developed using an ensemble method and was compared with a clinical feature model developed by using placental size features.Results: Using ensemble modeling, we developed a model to identify PE placentas.The model showed good performance (area under the precision-recall curve [AUPRC], 0.771; 95% confidence interval [CI], 0.752–0.790), with 77.3% of sensitivity and 71.1% of specificity, whereas the clinical feature model showed an AUPRC 0.713 (95% CI, 0.694–0.732) with 55.6% sensitivity and 86.8% specificity. External validation of the predictive model employing the BMC-derived set of placental slides also showed good discrimination (AUPRC, 0.725; 95% CI, 0.720–0.730).Conclusion: The proposed computational pathology model demonstrated a strong ability to identify preeclamptic placentas. Computational pathology has the potential to improve the identification of PE placentas."
딥러닝 모델 기반의 자동차 배출가스 관련 대기환경 이상 데이터 탐지 연구,2024,"['이상치 탐지', '시계열 데이터 분류', '대기질', '환경', 'Anomaly Detection', 'Timeseries Classification', 'Air Quality', 'Environment']","자동차는 주요 대기 오염원 중 하나로 작용하고 있으며 자동차가 주 오염원인 대기오염물질 데이터의 분석을 통해 전기자동차, 교통량 등과 실제 대기오염의 상관관계를 분석할 수 있으며, 이러한 분석을 위해선 대기오염물질 데이터의 신뢰성 확보가 중요하다. 본 논문은 딥러닝 모델과 동적 시간 와핑, 변화점 탐지 등의 알고리즘을 복합적으로 이용하여 전국 각지의대기오염물질 측정소에서 측정되는 데이터 중 ‘베이스라인 이상’ 증상이 나타나는 구간을 탐지하는 방법을 제시한다. 기존 연구들은 이전에 없던 패턴이 나타나는 데이터를 탐지하여 이상으로 정의하지만 이는 베이스라인 이상 탐지에는 적합하지 않았다. 본 논문에서는 주로 이미지 분할(Segmentation)에 사용되는 Unet모델을 시계열 데이터에 적합하도록 변형하여 사용하고 있으며 또한 동적 시간 와핑과 변화점 탐지 알고리즘을 적용하여 주변 측정소와 적절한 비교를 진행하고 이를 통해 오탐지를 최소화하였다.","Automobiles are one of the major sources of air pollution, and analyzing data on air pollutants, where vehicles are the primary pollutants, can help elucidate the correlation between factors like electric vehicles, traffic volume, and actual air pollution. Ensuring the reliability of air pollutant data is crucial for such analyses. This paper proposes a method for detecting sections of data exhibiting ‘baseline anomalies’ measured at air pollutant monitoring stations across the country by combining deep learning models with algorithms such as dynamic time warping and change point detection. While previous studies have focused on detecting data with unprecedented patterns and defined them as anomalies, this approach was not suitable for detecting baseline anomalies. In this study, we modify the U-Net model, typically used for image segmentation, to be more suitable for time-series data and apply dynamic time warping and change point detection algorithms to compare with nearby monitoring stations, thereby minimizing false detections."
개항기 전보송달지(1885~1905년) 연구,2024,"['telegraphy', 'telegrams', 'Open Port Period', 'American Legation in Korea', '전보', '전보지', '전보송달지', '개항기', '주한미국공사관']","본 연구는 한국 근대사에서 전신(電信)과 전보(電報)가 도입된 개항기를 배경으로 1885년부터 1905년까지 서울에서 수신되어 현재 미국 국립문서기록관리청(United States National Archives and Records Administration)의 ‘미국 국무부 해외공관 문서(Records of the Foreign Service Posts of the Department of State, 1788-1964, Record Group 84)’에 보존된 전보송달지(電報送達紙) 329개를 소개하고 그 특징과 의미를 밝히는 데 목적이 있다. 전신은 조선과 대한제국이 나라의 근대화를 위하여 집중한 산업이었으며, 본 연구는 기존의 연구에서 소외되었던 전보 기록물과 전보의 내용을 조명하여 후속 연구의 기초 자료를 제시하고자 한 데 의의가 있다.이에 본 연구에서는 첫째, 329개 전보송달지 기록물을 형태적으로 살펴보아 한ㆍ중ㆍ일 각 전신 회사의 양식지(樣式紙)와 레터헤드(letterhead) 등을 종류별로 살펴보았다. 둘째, 연도별 전보량 변화, 전보 발신인과 수신인의 특징, 전보 내용의 주제별 분류의 세 가지 측면에서 전보송달지를 분석하였다. 셋째, 향후 연구자들이 접근하기 용이하도록 전보송달지 전체에 대한 목록을 만들어 기초 자료를 제시하였다. 본 연구는 아직 발견되지 않은 다른 전보가 존재할 가능성을 열어둔다. 과거에는 존재 자체를 알 수 없었던 자료들이 디지털 기술의 발달에 따라 접근성이 높아지는 시대적 상황 속에서 본 연구는 해외에 보존된 한국의 역사적 사료를 소개하는 최근 연구들과 같은 맥락에 있다고 볼 수 있다. 본 논문에서 다루는 329개 전보송달지는 2024년 5월부터 디지털아카이브(jeonbo.omeka.net)로 열람할 수 있으며, 새로이 발굴되는 자료들은 해당 홈페이지에서 추가 제공할 예정이다.","The purpose of this study is to introduce 329 archival telegram delivery forms that were used to transmit telegraphic messages to the American Legation in Seoul, Korea from 1885 to 1905 and are currently preserved in the Records of the Foreign Service Posts of the Department of State, 1788-1964, Record Group 84, at the U.S. National Archives and Records Administration. The study first examines and divides the telegraph records according to their physical features and characteristics. Secondly, the themes of the telegrams are divided into several categories, confirming their value as a basic source for understanding the historical context of Korea during the Open Port Period. Lastly, a complete list of 329 telegrams with their basic metadata is offered. The telegrams of this study will be available as a digital archive (www.jeonbo.omeka.net) from May 2024."
기후변화 관련 보험섹터 대응에 관한 국제 규제 서설,2024,"['「기후변화에 관한 파리협정」', '기후관련 재무정보 개시 태스크포스', '국제 지속가능기준심의회', '보험감독자국제기구', '유엔환경회의 금융 이니셔티브 넷제로 전환을 위한 보험포럼', '기후변화: 위기와 기회', '「The Paris Agreement on Climate Change)」', 'TCFD', 'ISSB', 'IAIS', 'UNEP FI FIT', 'climate change- risk and chance']","2015년의 「기후변화에 관한 파리협정」은 2050년까지의 탄소배출 감축목표를 제시하였다. 이에 따라 국제기구와 단체, 각국 정부, 개별기업 등의 계획이 구체화되고 가속화되고 있다. 금융위원회도 최근 금융권이 해결할 당면과제로 기후변화 대응을 강조하고 있다. 보험섹터 역시 많은 국가가 관련 입법을 하였거나 추진 중이며 관련 정책을 실행 중이다. 기후위기는 ‘하나뿐인 지구’라는 명제가 보여주듯 국제 사회의 공통 목표와 실행 노력이 매우 중요하다. 이에 따라 많은 국제기구나 이니셔티브가 나서서 다양한 목표, 목적, 이행기준, 이행방법을 제시하고 있다. 이는 대부분 각 국가나 개별 보험회사의 동의를 얻어 실행되는 임의적 권고 내지 규정에 불과하지만 장차 국내 입법이나 규범으로 자리 잡을 가능성이 높다. 각국에서 입법화되기 전이라도 개별회사의 참여 여부, 참여 수준, 규제의 이행정도는 국제기구나 주요기업이 조사·보고·공시 대상으로 삼거나 이행정도를 분석·평가하여 해당기업의 가치를 평가하거나 등급을 매기거나 평판을 내리고 때로는 거래대상으로 삼을지를 판단하는 데 활용하기도 한다. 그 결과 국제기구나 이니셔티브의 규제나 권고는 기업 활동에 실질적인 규범으로 작용한다. 특히 ESG, 책임투자, SDGs의 강한 세계적 동향 속에서 우리나라나 개별보험사들이 불참하거나 소극적 대응을 하는 경우, 저평가의 불이익을 피하기 어렵다. 따라서 개별기업은 기후변화대응 추세에 적절한 시기에 적절한 참여를 하여야 한다. 그러나 기후변화 대책이 매우 다양한 차원에서 다양한 방법으로 이루어지고 있어 참여수단·시기·참여정도를 판단하기가 쉽지 않은 실정이다. 더구나 국제규제 활동의 변화가 빨라서 활동이 갑자기 종료되거나 내용이 수시로 바뀌기도 한다. 필자는 「보험법학회지」 제18권 제1호(2024.3.)에 2021년 야심차게 출발한 「탄소제로 보험동맹」(NZIA)이 미국 일부 주 정부의 경고 속에 위기에 처해있음을 소개하고, 2024.11. 미국 대통령 선거 결과에 영향을 받을 것으로 전망하였다. 그러나 NZIA는 공화당계 주 정부의 압력에 버티지 못하고 역사의 뒤안길로 사라졌다. 유엔환경계획(UN Environment Program: UNEP)은 2024.4.25. 「넷제로전환을 위한 보험포럼」(FIT)의 창설과 동시에 NZIA의 소멸을 공식선언하였다. 한국 보험회사도 3개사가 참여하였던 NZIA의 단명은 급속히 변모하는 국제사회에서 국제활동 참여를 신중하게 선택할 필요가 있음을 알려준 사례이다. 본고는 복잡·다양한 국제사회의 기후변화 대응 활동을 보험섹터와 관련이 깊고 영향력이 큰 부분을 중심으로 간략히 소개하였다. 그 내용이 워낙 방대하여 모두 다루지 못한 부분이 많다. 특히 각국 정부의 입법적·행정적 대응이나 각 개별 보험회사의 대응에 대해서는 따로 소개하고자 한다.본 연구를 통하여 국내 보험회사들이 국제사회의 기후변화 대응 방향과 ESG, SDGs, 지속가능성에 대하여 파악하고, 국제기구나 이니셔티브에 참여할지 여부, 참여시기, 참여 수준을 결정할 때와 정부가 입법적·행정적으로 대응하는 데 참고 자료가 되길 바란다.","The 2015 「Paris Agreement on Climate Change」 set forth carbon emission reduction targets by 2050. This landmark accord has catalyzed the formation and acceleration of concrete plans by international organizations, governmental bodies, and individual corporations. The insurance sector, in particular, has witnessed numerous countries enacting or planning legislation to align with these targets, implementing pertinent policies in response. As the proposition “Only One Earth” suggests, addressing the climate crisis necessitates the international community's unified objectives and coordinated efforts. In this context, various international organizations and initiatives have articulated numerous goals, standards, and implementation strategies. While most of these are predominantly voluntary, receiving endorsement from individual countries and insurance companies, there is a substantial possibility they will eventually be incorporated into domestic legislation or regulatory frameworks. Even before being legislated in each country, international organizations and major companies investigate, report, or disclose the participation status, level of participation, and compliance of individual companies. These international organizations and major companies analyze and evaluate the level of compliance to assess the value and reputation of the respective companies and determine whether they are suitable for transactions. Consequently, the recommendations and regulations of international organizations and initiatives often function as de facto norms. In the face of robust global trends such as ESG(Environmental, Social, and Governance), responsible investment, and the Sustainable Development Goals(SDGs), any country or insurance company exhibiting reluctance or passive engagement risks devaluation. Strategic, timely, and appropriate participation in these initiatives is imperative; however, the multifaceted nature and diverse approaches to addressing the climate crisis complicate decision-making processes. Additionally, existing initiatives may conclude, and new ones may emerge, further complicating the landscape. In the Korea Ins. L. J.(Vol.18, Issue 1, 2024.), I examined the “Net-Zero Insurance Alliance(NZIA)”, which was ambitiously launched in 2021 but encountered significant challenges due to warnings from several U.S. state governments. It was anticipated that the outcome of the U.S. presidential election in November 2024 would impact its trajectory. However, NZIA was unable to withstand the pressure exerted by Republican-led state governments and ultimately disbanded. On April 25, 2024, the United Nations Environment Programme Financial Initative formally announced the dissolution of NZIA and the establishment of the “Forum for Insurance Transition to Net Zero(FIT)”. The short-lived misfortune of NZIA, which included the participation of three Korean insurance companies, illustrates the necessity for prudent selection of international engagements. Simultaneously, regardless of the imperative nature of tasks essential for the survival of humanity, the stark reality of the international community is characterized by persistent obstruction and interference from vested interest groups. Consequently, addressing international regulations necessitates meticulous and strategic policy consideration.This paper provides a concise overview of the most pertinent and influential aspects of the insurance sector's engagement in the complex and diverse international activities aimed at addressing the climate crisis. Given the vast scope of this topic, certain areas remain unaddressed in this paper and will be supplemented in future research. Furthermore, subsequent publications will explore legislative and administrative responses by various governments, as well as the responses of individual insurance companies."
피부병변 영상 분할의 성능향상을 위한 VmCUnet,2024,"['CNN', 'U-net', 'Medical Image Segmentation', 'Vmamba', 'VM-Unet', 'VM-UnetV2']","본 논문에서는 피부병변 영상에서 이미지 분할 성능을 향상시키기 위해 설계된 딥러닝 모델인 VmCUnet을 제안한다. VmCUnet은 Vm-UnetV2와 CIM(Cross-Scale Interaction Module)을 결합하여 인코더의 각 계층에서 추출한 특징들을 CIM으로 통합하여다양한 패턴과 경계를 정확하게 인식할 수 있다. VmCUnet은 ISIC-2017와 ISIC-2018 데이터 세트를 사용하여 피부 병변의 이미지 분할을 수행하였고 Unet, TransUnet, SwinUnet Vm-Unet, Vm-UnetV2와 비교하여 성능 지표인 IoU, Dice Score에서 더높은 성능을 보였다. 향후 작업에서는 다양한 의료 영상 데이터 세트에 대한 추가 실험을 수행하여 VmCUnet 모델의 일반화 성능을 검증할 예정이다","In this paper, we have proposed VmCUnet, a deep learning model designed to enhance image segmentationperformance in skin lesion image. VmCUnet has combined Vm-UnetV2 with the CIM(Cross-Scale InteractionModule), and the features extracted from each layer of the encoder have been integrated through CIM toaccurately recognize the boundaries of various patterns and objects. VmCUnet has performed image segmentationof skin lesions using ISIC-2017 and ISIC-2018 datasets and has outperformed Unet, TransUnet, SwinUnet,Vm-Unet, and Vm-UnetV2 on the performance metrics IoU and Dice Score. In future work, we will conductadditional experiments on different medical imaging datasets to validate the generalization performance of theVmCUnet model"
한국과 미국의 금리 격차가 단기채 수익률 및 수익률 변동성에 미치는 영향,2024,"['단기채권', '변동성', '수익률', '오차수정모형', '일반 자기회귀 조건부 이분산', '한미 금리격차', 'Error correction model', 'GARCH', 'Korea-U.S. Interest rate gap', 'Short-term bonds', 'Volatility', 'Yield']","본 연구는 한미 금리차와 한미금리역전 현상이 단기 채권 시장에 미치는 영향을 분석하는 것을 목적으로 하며 이를 위해 CD 수익률과 변동성에 미치는 영향을 분석했다. 외부 변수들이 CD 수익률에 미치는 영향을 통제하기 위해 통제변수로 환율, 외국인 채권 순매수, 전산업생산지수, M2통화량을 사용하였고 연구 방법론으로는 오차수정모형과 GARCH 모형을 사용하여 분석을 진행하였다. 주요한 실증분석 결과는 다음과 같다. 첫째, 한미 금리 격차와 한미금리역전은 CD 수익률에 유의미한 영향을 미치지 못하고 있으며 원인에 대해서는 추후 분석이 필요하다. 둘째, 한미 금리차와 한미금리역전은 CD 수익률 변동성에는 유의한 영향을 미치고 있는 것으로 나타났다. 이는 한국과 미국의 금리차가 역전되어 차이 날수록 CD 수익률 변동성은 증가하게 된다는 해석이 가능하며 이는 이론적 배경에도 부합한다. 본 연구는 이러한 결과를 통해 한미 금리차와 금리역전이 한국 금융시장에서 CD 수익률의 변동성에 미치는 영향을 조명하며, 향후 한국의 금리 정책 및 금융시장 안정성에 대한 중요한 시사점을 제공할 수 있을 것으로 기대된다.","The purpose of this study is to analyze the impact of the Korea-US interest rate difference and the reversal of Korea-US interest rates on the short-term bond market, and for this purpose, the impact on CD(Certificate of Deposit) returns and volatility was analyzed. To control for external variables affecting CD yields, the exchange rate, net foreign bond purchases, the industrial production index, and M2 money supply were used as control variables. The analysis was conducted using an Error Correction Model (ECM) and a GARCH model. The main empirical findings are as follows: First, the interest rate differential and the inversion of interest rates between Korea and the United States do not significantly affect CD yields, and further analysis is needed to understand the underlying causes. Second, it was found that the interest rate differential and the inversion of interest rates between Korea and the United States have a significant impact on the volatility of CD yields. This suggests that as the interest rate differential between Korea and the United States widens and becomes inverted, the volatility of CD yields increases, which is consistent with theoretical expectations. Through these findings, this study sheds light on the impact of the interest rate differential and inversion between Korea and the United States on the volatility of CD yields in the Korean financial market and is expected to provide important implications for Korea's interest rate policy and financial market stability in the future."
도로 안정성 강화를 위한 로드마크 및 도로 손상 인식 모델,2024,"['Roadmark', 'road damage', 'road safety', 'U-net', 'YOLOv8', '로드마크', '도로 손상', '도로 안정성', 'U-net', 'YOLOv8']","본 연구는 도로 표지와 도로 표면의 물리적 손상으로 인한 도로 안전 및 인프라 유지 관리의 문제점을 다룬다.해당 부분을 지원하는 기존의 도로 모니터링 방법들은 대부분 수작업에 의존되며 비효율적이고 주관적이며, 결과의 일관성이 떨어진다. 본 논문에서는 이를 위해 주행 중인 차량의 관점에서 도로 표지 및 손상된 영역을 동적으로 감지하는 새로운 프로세스를 제안한다. 이 모델은 도로 표지 인식을 위한 객체 인식(Object detection)기술과손상된 영역을 식별하기 위한 영역 분할(Segmentation)기술을 통합하여, 두 단계의 병렬 관계로 구성한다. 이 접근방식은 도로 손상을 식별함으로써 운전을 보조할 뿐만 아니라 유지 보수를 지원하는 방향으로 확장되어, 전통적인시스템에 비해 근본적인 해결책을 제공하고 실시간 운영 및 손상된 영역에 대한 유지 관리 지원에 중점을 맞춘다.영역 분할과 객체 인식 기술을 결합한 제안된 모델은 실시간 대응에만 초점을 맞추거나 도로의 다양한 정보를 간과하는 기존 방법의 한계를 극복하고, 도로 안전 및 유지 보수에 대한 포괄적 해결책을 제공하고자 한다.","This paper addresses the challenges in road safety and infrastructure maintenance management posed by physical damages to road signs and road surfaces. Existing road monitoring methods that support these aspects often rely heavily on manual labor, proving to be inefficient, subjective, and yielding inconsistent results. In this paper, we propose a new model that dynamically detects road signs and damaged areas from the perspective of moving vehicles. This model integrates object detection technology for road sign recognition and segmentation technology for identifying damaged areas, forming a parallel relationship between these two stages. This approach not only assists in driving by identifying road damages but also extends to supporting maintenance, providing a fundamental solution compared to traditional systems. The proposed model focuses on real-time operation and maintenance support for damaged areas, offering a comprehensive solution for road safety and maintenance. By combining segmentation and object detection technologies, the proposed model aims to overcome the limitations of existing methods that either focus solely on real-time response or overlook various information about the road, aiming to provide a comprehensive solution for road safety and maintenance."
Shoreline Change Analysis with Deep Learning Semantic Segmentation Using Remote Sensing and GIS Data,2024,"['Shoreline', 'Change analysis', 'Remote sensing', 'GIS', 'Attention U-net', 'Water index']",,"Shoreline management is essential for navigation, coastal resource management, and coastal planning and development. Shoreline change detection is vital for shoreline monitoring; however, traditional methods used for such detection are laborious and have limited accuracy. An approach that integrates remote sensing imagery and geographic information systems (GISs) is proposed herein to simultaneously identify shoreline changes and perform grid-level visualization for updating shoreline data. The integrated approach uses deep learning–based segmentation networks and water indexes to accurately classify land and sea in remote sensing images. Transfer learning was used to address the issue of insufficient data, wherein weights trained on a large open dataset were applied to the target area. The segmentation results were compared with existing shoreline GIS data to identify the areas experiencing shoreline changes. Grid-level visualization enhanced the identification of regions requiring flexible data updates and investigation efficiency by focusing on specific areas. The proposed approach accurately detected shoreline changes, albeit with some errors of commission, predominantly in regions featuring intricate shorelines and small clusters of islands. The proposed approach offers efficient solutions for shoreline change detection, with potential applications in coastal management, environmental science, urban planning, and coastal hazard assessment."
An improved fuzzy c-means method based on multivariate skew-normal distribution for brain MR image segmentation,2024,"['Multivariate skew-normal distribution', 'Fuzzy C-Means(FCM)', 'KL divergence', 'U-Net', 'Brain MR images.']",,"Accurate segmentation of magnetic resonance (MR) images is crucial for providing doctors with effective quantitative information for diagnosis. However, the presence of weak boundaries, intensity inhomogeneity, and noise in the images poses challenges for segmentation models to achieve optimal results. While deep learning models can offer relatively accurate results, the scarcity of labeled medical imaging data increases the risk of overfitting. To tackle this issue, this paper proposes a novel fuzzy c-means (FCM) model that integrates a deep learning approach. To address the limited accuracy of traditional FCM models, which employ Euclidean distance as a distance measure, we introduce a measurement function based on the skewed normal distribution. This function enables us to capture more precise information about the distribution of the image. Additionally, we construct a regularization term based on the Kullback-Leibler (KL) divergence of high-confidence deep learning results. This regularization term helps enhance the final segmentation accuracy of the model. Moreover, we incorporate orthogonal basis functions to estimate the bias field and integrate it into the improved FCM method. This integration allows our method to simultaneously segment the image and estimate the bias field. The experimental results on both simulated and real brain MR images demonstrate the robustness of our method, highlighting its superiority over other advanced segmentation algorithms."
fMRI 데이터를 이용한 알츠하이머 진행상태 분류,2024,"['알츠하이머', '딥러닝', '기능적 자기 공명 영상', 'Alzheimer', '3D U-Net', 'Deep learning', 'fMRI']",,
재난 현장 인명 구조를 위한 딥러닝 기반 잡음 제거 및 음향 분류,2024,"['Noise reduction', 'Disaster site', 'Wiener filtering']","도시 재난 현장에서는 다양한 형태의 잡음이 발생하여 인명 탐지 및 구조 작업의 정확도와 효율성을 저하시킬 수 있다. 이를 해결하기 위해 본 연구는 Wave-U-Net 기반의 딥러닝 모델과 Wiener 필터를 결합한 잡음 제거 방법을 제안하였다. 깨끗한 오디오 신호와 다양한 잡음을 합성하여, 깨끗한 신호 (data1), 잡음 제거를 적용한 신호 (data2), 추가로 Wiener 필터를 적용한 신호 (data3)로 구성된 데이터셋을 생성하였다. 데이터셋은 SNR 0 dB부터 30 dB까지 5 dB 단위로 다양한 잡음 수준에서 생성되었으며, 이를 사용하여 각각의 모델을 학습하였다. 제안된 잡음 제거 방법의 효과를 평가하기 위해 Simple CNN (Convolutional Neural Network), XGBoost (eXtreme Gradient Boosting), SVM (Support Vector Machine)을 사용하여 각 데이터셋의 성능을 측정하였다. 실험 결과, SNR 0 dB에서 5 dB 구간에서는 잡음 제거가 성능 향상에 긍정적인 영향을 미쳤으나, SNR 10 dB 이상의 환경에서는 잡음 제거가 오히려 성능 저하를 초래하였다. 이는 잡음이 적은 환경에서 과도한 잡음 제거가 신호 왜곡을 일으키거나, 불필요한 신호 처리로 인해 원래 신호의 품질을 손상시킬 수 있기 때문이다. 본 연구는 복잡한 잡음 환경에서 잡음 제거의 효과를 확인하였으며, 향후 연구는 SNR 10 dB 이상의 고잡음 환경에서도 성능을 유지할 수 있는 방법을 탐색하는 데 중점을 두어야 한다.","Urban disaster sites often experience various types of noise, which can significantly hinder the accuracy and efficiency of human detection and rescue operations. To address this issue, this study proposes a noise reduction method that combines a Wave-U-Net-based deep learning model with a Wiener filter. Clean audio signals and various types of noise were synthesized to create a dataset consisting of clean signals (data1), signals with noise reduction applied (data2), and signals with an additional Wiener filter applied (data3). The dataset was generated at noise levels ranging from SNR 0 dB to 30 dB in 5 dB increments, and each model was trained using these datasets. To evaluate the effectiveness of the proposed noise reduction method, the performance of Simple CNN (Convolutional Neural Network), XGBoost (eXtreme Gradient Boosting), and SVM (Support Vector Machine) was measured on each dataset. Experimental results showed that noise reduction had a positive effect on performance in the SNR 0 dB to 5 dB range, but in environments with SNR levels above 10 dB, noise reduction led to performance degradation. This degradation is likely due to over-suppression of noise in lower-noise environments, which can distort the signal or result in unnecessary signal processing that harms the original signal quality. This study demonstrates the effectiveness of noise reduction in complex noise environments and highlights the need for further research to develop methods that maintain performance in higher SNR environments, particularly above 10 dB."
Whole Spine Segmentation Using  Object Detection and Semantic  Segmentation,2024,"['Machine learning', 'Deep learning', 'Spine', 'Artificial intelligence', 'Algorithms']",,"Objective: Virtual and augmented reality have enjoyed increased attention in spine surgery.Preoperative planning, pedicle screw placement, and surgical training are among the most studied use cases. Identifying osseous structures is a key aspect of navigating a 3-dimensional virtual reconstruction. To automate the otherwise time-consuming process of labeling vertebrae on each slice individually, we propose a fully automated pipeline that automates segmentation on computed tomography (CT) and which can form the basis for further virtual or augmented reality application and radiomic analysis.Methods: Based on a large public dataset of annotated vertebral CT scans, we first trained a YOLOv8m (You-Only-Look-Once algorithm, Version 8 and size medium) to detect each vertebra individually. On the then cropped images, a 2D-U-Net was developed and externally validated on 2 different public datasets.Results: Two hundred fourteen CT scans (cervical, thoracic, or lumbar spine) were used for model training, and 40 scans were used for external validation. Vertebra recognition achieved a mAP50 (mean average precision with Jaccard threshold of 0.5) of over 0.84, and the segmentation algorithm attained a mean Dice score of 0.75 ± 0.14 at internal, 0.77 ± 0.12 and 0.82 ± 0.14 at external validation, respectively.Conclusion: We propose a 2-stage approach consisting of single vertebra labeling by an object detection algorithm followed by semantic segmentation. In our externally validated pilot study, we demonstrate robust performance for our object detection network in identifying individual vertebrae, as well as for our segmentation model in precisely delineating the bony structures."
신재 최산두 한시를 통한 인문학적 문화콘텐츠 구축 방안,2024,"['Choi San-du classical Chinese poetry', 'value of life', 'building cultural content', 'cultural community', 'healing of mind and body', '신재 최산두의 삶과 문학', '인문융합예술', '커뮤니케이션 구축 및 활성화', '문화공동체제 기반 확보', '교육자료', '문화관광 자원']","이 연구는 신재 최산두 한시 작품을 통하여 인문학적 문화콘텐츠 구축 방안을 찾기 위한 논의이다. 작품에 드러난 인간 삶의 가치 지향을 인문학적 문화콘텐츠와 연계하여 논의했다. 먼저 최산두가 살았던 시대상황과 정신적 지향에 대하여 살폈다. 『新齋集 』에 수록되어 있는 한시를 통하여 22세 때 진사시에 합격한 이후부터 31세 별시문과 급제 때까지의 행적을 살폈다. 최산두의 나이 21세 때인 1504년(연산군 10년)에 갑자사화(甲子士禍)가 일어나자 스승인 김굉필이 순천에서 극형을 당한다. 김굉필의 제자인 최산두에게 화가 미칠 것은 너무나 당연한 일이었다. 그의 한시 <天子菴霖雨呤>을 통하여 잃어버린 아홉 해를 승주군 이읍면에 있는 천자암에서 보냈다는 것을 가늠해 볼 수 있었다.최산두 한시의 자연애와 인간애의 의미망을 탐색하고 인문학적 문화콘텐츠를 구축했다. 광양시는 급속한 산업화로 인하여 도시, 농업, 공업이 어우러진 복합도시이다. 지역민들의 사회적 계층 갈등이 심화되어가고 있다. 이러한 점에서 그들의 자긍심과 애향심을 고취시킬 방안을 찾아보고자 했다.이 연구를 통하여 지역민의 문화적 소외감을 극복하고 자긍심 고취와 인문학적 문화 소통 이해도 증진에 영향을 미치게 될 것이다. 또한 지역민들의 심신 치유와 인문학적 지식 공유를 통한 농어촌과 도심의 문화공동체적 협력 체제 구축에 활로가 될 것이다.","This study is a discussion to find strategies to build humanistic cultural content through Shinjae Choi San-du's classical Chinese poetry works. The value orientation of human life revealed in his works was discussed in connection with humanistic cultural content. First, we examined the circumstances of the times in which Choi San-du lived and his spiritual orientation. Through the classical Chinese poems included in his “Shinjae-jip (新齋集)”, we examined his career from the time he passed the exam for the civil service rank of Jinsa at the age of 22 to the time he passed the Irregular Civil Service Exam at the age of 31. When the Gajasahwa (甲子士禍; Gapja year literati's political disaster) occurred in 1504 (10th Year of King Yonsangun), when Choi San-du was 21 years old, his teacher Kim Gweng-pil was executed at Suncheon. It was only natural that the disaster would reach Choi San-du, a disciple of Kim Gweng-pil. Through his classical Chinese poetry “Cheon-ja-am-rim-u-ryeong (天子菴霖雨?)”, it was possible to estimate that he stayed at Cheonja-am temple in Yieup-myeon, Seungju-gun for his lost nine years.We explored the semantic net of love for nature and humanity appearing in Choi San-du's classical Chinese poetry works and established a strategy to build humanistic cultural content. Gwangyang-city is a complex city where urban, agriculture, and industry are combined due to rapid industrialization. Social class conflicts among local residents are intensifying. In this regard, the intention was to find a way to encourage their pride and love for their hometown. It was discussed that this lies in revitalizing humanistic cultural content with the goal of orienting the value of human life by exploring humanistic qualities.Through this study, it will have an impact on restoring local residents' sense of cultural alienation, enhancing their self-esteem, and improving their understanding of cultural communication in the humanities. In addition, it will be an avenue for establishing a cultural community cooperation system between rural and urban areas through healing the mind and body of local residents and sharing humanistic knowledge."
국외 해외진출기업 위기관리시스템 발전방안 연구 : 美 OSAC(Overseas Seccurity Advisory Council) 비교분석,2024,"['국가위기관리', '재외국민보호', '해외진출기업', 'OSAC', '민관정보공유체계', '해외테러', 'National risk management', 'Protection of Overseas Citizens', 'Companies expanding overseas', 'OSAC', 'Sharing information system between private and government', 'Overseas terrorism']","이 연구의 목적은 초 연결시대 급변하고 있는 국외 테러·재난·범죄 등 다양한 위협 발생 시 골든타임내 우리나라 해외진출기업의 위기관리 역량을 강화하기 위한 것이다. 러시아 우크라이나전, 이스라엘-하마스 국지전, 재난위기 등 국제적 긴장감은 계속 고조되고 있다. 이에, 해외진출기업들이 안전하게 해외사업을 하도록 보장하는 것은 더 이상 기업만의 사 안이 아니다. 범부처 중심의 국가가 위기관리 차원에서 예방·대비·대응·사후조치 등 주요 단계별로 지원해야 한다. 이러한 인식하에 해외 위기관리시스템 발전방안을 도출하고자, 미 국무부 OSAC과 미국 해외진출기업들의 사례를 연구하고 국내 사례를 비교분석 하였다. 우리나라 해외진출기업 위기관리시스템을 분석한 결과, 첫째, 테러 등 해외 위기상황에 대한 정보공유 부족, 둘째, 해외진출기업 위기관리시스템 운영에 대한 구체적 입법화 미비, 셋째, 해외진출기업 보호를 위한 전담조직 부재라는 결론을 도출하였다. 우리나라 해외진출기업 위기관리시스템에 대한 분석을 통해, 정책적인 발전방안을 제시 하였다. 첫째, 예방단계에서 정부기관의 테러 등 해외 위협상황 정보 공유체계와 현지 네트 워크 강화, 둘째, 대비단계로서 정부기관의 해외진출기업 위기관리시스템 법ㆍ제도적 장치 마련, 셋째, 민-관 위기관리 거버넌스 역량 강화, 마지막으로 우리나라 해외진출기업의 위기관리 역량 강화이다. 해외진출기업 위기관리시스템 역량을 강화하기 위해 정부기관과 해외진출기업 양측 모두의 노력이 중요하다.","The purpose of this study is to strengthen the risk management capabilities of Korean companies expanding overseas within the golden time when various threats such as overseas terrorism, disasters, and crimes occur in the rapidly changing era of hyper-connectivity. International tensions such as the Russia-Ukraine war, the Israel-Hamas local war, and disaster continue to heighten. Accordingly, ensuring that companies can safely conduct overseas business is no longer a matter for companies alone. The government, centered on inter-ministerial affairs, must support major stages such as prevention, preparation, response, and follow-up measures in terms of risk management. Based this awareness, we studied the cases of the US State Department OSAC and US companies expanding overseas and compared and analyzed domestic cases in order to derive a plan for developing an overseas risk management system. As a result of analyzing the risk management system of Korean companies advancing overseas, first, information sharing on overseas threat situations such as terrorism is not often, second, specific legislation on the operation of the risk management system for companies expanding overseas is necessary, and third, absence of a dedicated organization to protect companies expanding overseas. Through the analysis of the risk management system of Korean companies expanding overseas, policy development plans were suggested. First, in the prevention stage, the government agency‘s overseas threat situation information sharing system such as terrorism and the strengthening of local networks, second, in the preparation stage, establishing legal and institutional devices for the government agency’s overseas risk management system for companies expanding overseas, third, the strengthening of the public-private risk management governance capacity, and lastly, the strengthening of the risk management capacity of Korean companies expanding overseas. In order to strengthen the risk management system capacity of companies expanding overseas, the efforts of both government agencies and companies advancing overseas are important."
