title,date,keywords,abstract,multilingual_abstract
YOLO 시리즈(V1에서 V11까지)와 응용 애플리케이션 분석 비교,2024,"['Object Detection', 'Deep Learning', 'Computer Vision', 'You Only Look Once(YOLO)', 'YOLO Comparison']",국문 초록 정보 없음,"Deep Learning has emerged as multi-domain innovation aimed the popularity of various Machine Learning techniques, and YOLO makes it possible for widely using in deep learning for object detection tasks. In this paper, we present a analysis of YOLO series (original scheme to version 11), undertaking a comprehensive analysis of YOLO’s performance and synthesizes existing researches. We start by describing the architecture and contribution of YOLO families, discussing the major changes in network architecture, and training tricks for each model. Then, se summarize the necessary lessons form YOLO’s development and provide a perspective on its highlighting research directions to enhance object detection."
YOLO v5를 이용한 U-Net3+모델 기반 Semantic-Segmentation 성능 개선,2024,"['semantic-segmentation', 'YOLO', 'U-Net3+', 'object detection', 'mIoU', '.']","최근 영상처리 딥러닝 기술의 발달로 객체인식, 이미지 분할은 다양한 분야에 사용되고 있다. 하지만 객체인식, 이미지 분할을 학습하기 위한 데이터 생성은 쉬운 일이 아니다. 따라서 본 논문에서는 추가적인 데이터 생성 없이 YOLO(You Only Look Once), U-Net3+기반의 모델에서 효율적인 학습이 가능하도록 하는 시스템을 제안 및 구현한다. 제안된 시스템은 YOLO v5의 v5s 모델을 사용하여 1차적으로 객체인식을 수행한다. 이후 YOLO를 거쳐 출력된 객체인식 데이터는 U-Net3+기반의 모델에 입력데이터로써 사용된다. 제안된 방법을 평가하기 위해 기존의 U-Net3+기반으로만 작성된 시스템과 비교하였다. 실험 결과 제안된 방법이 평균 0.1 이상의 향상된 mIoU 결과를 보였다. 이는 제안된 방법이 데이터 생성 없이 효과적으로 이미지 분할의 성능을 개선시킬 수 있음을 확인할 수 있었다.","Recent advancements in deep learing technology for image processing have enabled the use of object detection and segmentation in various fields. However, data labeling and generation for learning object detection and segmentation are not easy tasks. Therefore, this paper proposes and implements a system that enables efficient training in a You Only Look Once(YOLO) and U-Net3+ based model without the need for additional data generation. The proposed system performs initial object detection using YOLO v5s. The object detection data output by YOLO v5s is then used as input for a U-Net3+ based model. To evaluate the proposed method, we compared it with a system based solely on the existing U-Net3+ model. Experimental results showed that the proposed method achieved an improvement of over 0.1 in mean Intersection over Union(mIoU) on average. This demonstrates that the proposed method can effectively improve segmentation performance without generating additional data."
YOLO와 EasyOCR을 혼합한 차량 번호 기반 겸용 차량 분류 연구,2024,"['YOLO', 'You Only Look Once', '광학 문자 인식', '영상 인식', '화물차량', '차량 번호판', '차종 분류', '겸용 차량', '딥러닝', 'YOLO', 'You Only Look Once', 'OCR', 'Image Recognition', 'Cargo Vehicle', 'License Plate', 'Classification of Vehicle Types', 'Combined Vehicle', 'Deep learning']",국문 초록 정보 없음,"The lane designation and the bus-only lane system for traffic speed and road safety are difficult to crack down on, and for this purpose, crackdown methods using image recognition technologies are being studied. Existing studies require continuous learning or additional equipment, and it is difficult to classify combined vehicles such as vans and pickup trucks. Therefore, in this study, YOLO and EasyOCR were mixed to classify combined vehicles through vehicle type symbols. For combined vehicles, higher accuracy was shown than classification using YOLO. Due to the nature of Hangul, the accuracy was slightly lowered because the OCR was not accurately recognized, but if it is used with the existing YOLO classification, high accuracy of crackdown will be possible."
거대 AI 학습용 데이터셋을 활용한 YOLO  기반 유해조수 인식 및 퇴치 시스템,2024,"['Large Dataset', 'Wildlife Repellent', 'YOLO Detection', 'Deep Learning']",국문 초록 정보 없음,"AI-based harmful wildlife repellent devices and systems introduced in several studies are unable to smoothly detect and repel many and various types of harmful wildlifes due to a lack of learning data. To solve this problem, this study proposes an AI object recognition-based harmful wildlife repellent system that learns a YOLO-Based AI model using a 250,000-page wildlife activity dataset and applies it to a harmful wildlife repellent system. By training a new YOLO AI model using large AI training data, mAP (IoU=0.50～0.95) performance is improved by about 4% and prediction speed by about 18% compared to the existing YOLO model, and by applying this to a commercial MCU board, it is possible to construct a low-cost, high-performance harmful wildlife repellent system."
YOLO와 대분류 객체 탐지 모델을 결합한 패션 아이템 자동 레이블링 시스템,2024,"['Labeling', 'Fashion', 'YOLO(You Only Look Once)', 'Bounding Box', 'Object Detection', '레이블링', '패션', 'YOLO', '경계 상자', '객체 탐지']",국문 초록 정보 없음,"This paper propose an automatic labeling system for fashion items in images by combining one of the object detection models, YOLO(You Only Look Once), with a high-level classification object detection model. After detecting the primary fashion items, TOP and BOTTOM, in an image, the system analysis the bounding boxes of the detected objects and removes redundant or unnecessary bounding boxes through preprocessing to extract bounding boxes with accurate location information. The extracted bounding boxes are compared to the classes defined by the high-level object detection model with coordinate normalization to perform automatic labeling by matcing the input fashion item types. The system's performance was evaluated on 10,000 fashion images and corresponding test data, and 8,192 images were found to be correctly labeled. This demonstrates a significant improvement in efficiency over manual labeling methods, showing the system's practical contribution to large-scale fashion image data processing."
자율주행 환경에서 노이즈가 YOLO 기반의 객체 탐지에 미치는 영향에 관한 연구,2024,"['YOLO', 'Deep Learning', 'Object Detection', 'Data Quality', 'Computer Vision', 'Noise', 'YOLO', '딥러닝', '객체 탐지', '데이터 품질', '컴퓨터 비전', '노이즈']",국문 초록 정보 없음,"Noise caused by adverse weather conditions in data collected during autonomous driving can lead to object recognition errors, potentially resulting in critical accidents. While this risk is widely acknowledged, there is a lack of research that quantitatively and systematically analyzes it. Therefore, this study aims to examine and quantify the extent to which noise affects object detection in autonomous driving environments. To this end, we utilized the YOLO v5 model trained on unprocessed datasets. The test data were divided into noise ratios of 0% (Original), 20%, 40%, 60%, and 80%, and the detection results were evaluated by constructing a Confusion Matrix. Experimental results show that as the noise ratio increases, the True Positive (TP) rate decreases, and the F1-score also significantly drops across all noise levels, specifically from 0.69 to 0.47, 0.29, 0.18, and 0.14. These findings are expected to contribute to enhancing the stability of autonomous driving technology. Future research will focus on collecting real datasets that include naturally occurring noise and developing more effective noise removal techniques."
스마트 농업을 위한 YOLO 기반 작물 해충 탐지 모바일 애플리케이션,2024,"['Object Detection', 'YOLO Algorithm', 'Deep Learning', 'Progressive Web App', 'Smart Farming']","작물 해충은 작물 수확량 감소의 주된 원인 중 하나로, 식량농업기구(FAO)의 추정에 따르면 전 세계적으로 해충과 질병으로 인한 작물 손실이 20~40%에 이른다. 인구 증가와 기후 변화가 이 문제를 더욱 심화시키고 있다. 이에 본 논문에서는 쌀 생산에 심각한 위협을 주는 해충을 조기에 탐지하고, 초기 피해에 대응할 수 있는 적절한 살충제 정보를 제공함으로써 수확량 감소를 줄이고 환경 오염도 완화하는 방법을 제안한다. 현실적인 실외 환경에서 수집된 데이터를 데이터 증강 기술로 확장한 후, YOLO 기반의 컨볼루션 신경망(CNN)을 사용하여 훈련시켜 95.2%의 mAP@0.5 지표로 높은 정확도를 달성한 모델을 개발하였다. 또한, 작물 해충의 종류와 권장 살충제 정보를 제공하기 위해 서버에 데이터베이스를 구축하였다. 이렇게 개발된 YOLOv8 모델과 데이터베이스를 통합하여 플랫폼 독립적으로 작동하는 PWA(Progressive Web App)를 개발했다. 이 앱은 네트워크 연결이 불안정하거나 없는 야외 환경에서도 작동 가능하며, 특히 원거리 농촌 지역에 큰 이점을 제공하여 해충 탐지와 살충제 정보 접근성을 향상시킨다.","Crop pests are one of the primary causes of reduced agricultural yields, with the Food and Agriculture Organization (FAO) estimating that global crop losses due to pests and diseases range from 20% to 40%. The escalating issues of population growth and climate change further exacerbate this problem. This paper proposes a method to mitigate yield reductions and environmental pollution by providing timely pest detection and appropriate pesticide information for rice production, which faces significant threats from pests. By applying data augmentation techniques to real-world outdoor data, and by training a YOLO-based convolutional neural network, our model achieved high accuracy with a 95.2% mAP@0.5 metric. Additionally, a server database was constructed to provide information on types of crop pests and recommended pesticides. Using the developed YOLOv8 model and database, we developed a platform-independent progressive web app that operates even in areas with unstable or no network connections. The app is particularly beneficial in remote rural areas, enhancing access to pest detection and pesticide information."
YOLO와 EfficientNetV2를 사용한 지능적 제품 탐지 및 추천을 위한 End-to-End AI 기반 서비스 모델 개발,2024,"['Marketing', 'YOLO', 'Visual Similarity', 'One-shot learning', 'EfficientNet', 'End-to-End Service', '마케팅', 'YOLO', 'Visual Similarity', 'One-shot learning', 'EfficientNet', 'End-to-End 서비스']","최근, 동영상 콘텐츠 소비와 제품구매 행동이 자연스럽게 이어지는 마케팅 연구가 활발하게 이루어지고있다. 본 논문에서는 유튜브의 영상 시청중에 자연스럽게 인터넷 쇼핑으로 이어질 수 있도록 관련 제품을 탐지하고유사 제품을 추천해주는 서비스 기술을 제안하고 구현하였다. 제안한 기술은 YOLOv8과 미리 학습된 EfficientNetV2 를 사용하였고, 제한적으로 탐지할 수 있는 제품 클래스의 개수를 해결하기 위해 CNN모델을 추가함으로써 단일객체 탐지 모델의 한계를 극복하였다. 또한 탐지할 수 있는 제품의 분류 성능을 높이기 위해 Weighted Box Fusion기법을 적용하였다. 테스트 모델에 사용된 제품 검출 성능 평가 결과에서 mAP는 최고 91.2%의 높은 검출률을 보였다. 구현결과, 제안한 기술은 시청중에 판매가 이루어질 수 있는 다양한 동영상 플랫폼의 End-to-End 서비스에 활용될 수 있을 것으로 기대한다.","Recently, there has been active research in marketing connecting video content consumption to product purchasing behaviors seamlessly. In this paper, we propose and implement a service technology that detects related products during YouTube video viewing and recommends similar products, enabling a smooth transition to online shopping. Our proposed technology utilizes YOLOv8 and a pre-trained EfficientNetV2, and overcomes the limitations of a single object detection model by adding a CNN model to address the issue of a limited number of detectable product classes. Additionally, the Weighted Box Fusion technique is applied to enhance the product classification performance of detectable products. The product detection performance of the test model showed a high mAP of up to 91.2%. Based on our results, we anticipate that the proposed technology can be applied to various video platforms where sales can be made during viewing, offering an end-to-end service."
YOLO 기반 GPR 신호 심층학습을 통한 터널 콘크리트 라이닝 배면공동 자동 검출,2024,"['Ground Penetrating Radar', 'Tunnel Assesment', 'Deep learning', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 활용한 실시간 하수관로 결함 탐지 알고리즘 개발,2024,"['Big data', 'Object detection', 'Sewer pipe defect detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 활용한 실시간 하수관로 결함 탐지 알고리즘 개발,2024,"['Big data', 'Object detection', 'Sewer pipe defect detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
ONNX 기반 런타임 성능 분석: YOLO와 ResNet,2024,"['ONNX', '딥 모델', 'Inference Runtime', '객체 감지', '이미지 분류', 'Deep Model', 'Object Detection', 'Image Classification']",국문 초록 정보 없음,"In the field of computer vision, models such as You Look Only Once (YOLO) and ResNet are widely used due to their real-time performance and high accuracy. However, to apply these models in real-world environments, factors such as runtime compatibility, memory usage, computing resources, and real-time conditions must be considered. This study compares the characteristics of three deep model runtimes: ONNX Runtime, TensorRT, and OpenCV DNN, and analyzes their performance on two models. The aim of this paper is to provide criteria for runtime selection for practical applications. The experiments compare runtimes based on the evaluation metrics of time, memory usage, and accuracy for vehicle license plate recognition and classification tasks. The experimental results show that ONNX Runtime excels in complex object detection performance, OpenCV DNN is suitable for environments with limited memory, and TensorRT offers superior execution speed for complex models."
다양한 재료에서 발생되는 연기 및 불꽃에 대한 YOLO 기반 객체 탐지 모델 성능 개선에 관한 연구,2024,"['Materials', 'Object detection', 'Fire detection', 'Real_time', 'YOLOv5']",국문 초록 정보 없음,"This paper is an experimental study on the improvement of smoke and flame detection from different materials with YOLO. For the study, images of fires occurring in various materials were collected through an open dataset, and experiments were conducted by changing the main factors affecting the performance of the fire object detection model, such as the bounding box, polygon, and data augmentation of the collected image open dataset during data preprocessing. To evaluate the model performance, we calculated the values of precision, recall, F1Score, mAP, and FPS for each condition, and compared the performance of each model based on these values. We also analyzed the changes in model performance due to the data preprocessing method to derive the conditions that have the greatest impact on improving the performance of the fire object detection model. The experimental results showed that for the fire object detection model using the YOLOv5s6.0 model, data augmentation that can change the color of the flame, such as saturation, brightness, and exposure, is most effective in improving the performance of the fire object detection model. The real-time fire object detection model developed in this study can be applied to equipment such as existing CCTV, and it is believed that it can contribute to minimizing fire damage by enabling early detection of fires occurring in various materials."
YOLO-YCbCr 기반 화염 검출 기법 적용성 향상 연구,2024,"['Fire detection', 'Flame segmentation', 'Artificial intelligence', 'Image processing', 'Color space']",국문 초록 정보 없음,다국어 초록 정보 없음
농경지 이용현황 파악을 위한 고해상도 영상정보 기반의 YOLO-SAM 융합 모델 개발,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
모델 크기별 데이터 증강 비율 탐구를 통한 YOLO 기반 의류 이미지 다중 카테고리 분류 연구,2024,"['clothing classification', 'object detection', 'color extraction', 'hyper-parameter fine-tuning', 'image augmentation', '의류 분류', '객체 탐지', '색상 추출', '하이퍼파라미터 튜닝', '이미지 증강']","최근 여러 의류 쇼핑 플랫폼 및 의류 관련 산업에서 AI를 도입하여 소비자의 니즈를 충족시키고 구매력을 높이는 체계를 도입함에 따라, 의류의 카테고리와 색상을 정확히 분류하는 필요성이 급증하고 있다. 본 연구는 구매자 리뷰 이미지를 사용하여 한 이미지 내 여러 카테고리의 다양한 의류와 해당 색상을 분류하는 딥러닝 모델을 개발함으로써 이와 같은 문제를 해결하고자 한다. 구매자 리뷰 이미지 데이터를 직접 크롤링하여 데이터 증강 등 다양한 전처리 과정을 거친 후, YOLOv10 모델을 이용하여 의류의 객체를 탐지하고 이를 카테고리별로 분류한다. 이후, 이미지의 색상을 더 잘 추출하기 위해 고려한 크롭 방법을 통해 의류 영역을 자르고, 색상 차트와의 유사도를 계산하여 가장 유사한 색상명을 추출하는 방법을 구현한다. 실험 결과, 본 연구의 접근 방식이 효과적임을 보여주며, 모델 크기 및 증강 배율이 높을수록 성능이 향상함을 확인하였다. 사용한 모델은 의류 카테고리 및 색상 추출에서 모두 안정적인 성능을 기록하였으며, 그 신뢰성을 입증하였다. 제안된 시스템은 사용자 리뷰 이미지를 기반으로 한 정확한 의류 카테고리와 색상 분류를 통해 고객 만족도 및 구매력을 향상할 뿐만 아니라, 자동화된 패션 분석에 대한 추가 연구의 기초를 마련한다. 또한, 패션 트렌드 분석, 재고 관리, 마케팅 전략 수립 등 관련 산업의 여러 분야에도 활용될 수 있는 확장성을 지닌다.","With the recent adoption of AI by various clothing shopping platforms and related industries to meet consumer needs and enhance purchasing power, the necessity for accurate classification of clothing categories and colors has surged. This paper aims to address this issue by developing a deep learning model that classifies various clothing items and their colors within a single image using buyer review images. After directly crawling buyer review image data and performing various preprocessing steps such as data augmentation, we utilized the YOLOv10 model to detect clothing objects and classify them into categories. Subsequently, to improve color extraction, we implemented a cropping method to isolate clothing regions in the images and calculated the similarity with a color chart to extract the most similar color names. Our experimental results show that our approach is effective, with performance increasing with model size and augmentation scale. The employed model showed stable performance in both clothing category and color extraction, proving its reliability. The proposed system not only enhances customer satisfaction and purchasing power by accurately classifying clothing categories and colors based on user review images but also lays the foundation for further research in automated fashion analysis. Moreover, it possesses the scalability to be utilized in various fields of the related industry, such as fashion trend analysis, inventory management, and marketing strategy development."
"GAN 알고리즘을 활용한 딥러닝 기반 Yolo v7, Yolo v8 모델 화재 탐지 성능 분석",2024,"['Generative adversarial network', 'YOLO   V7', 'YOLO   V8', 'Object detection', 'Image processing']","본 연구는 산업 재해 중에서도 특히 심각한 피해를 유발하는 화재 사고에 초점을 맞추고 있으며, 화재의 신속한 탐지와 대응은 재산 손실과 인명 피해를 최소화하는 데 있어서 필수적이다. 본 연구 에서는 Generative Adversarial Networks(GAN) 알고리즘을 활용하여 실제 화재 및 연기 이미 지로부터 높은 품질의 합성 화재 및 연기 이미지를 생성할 수 있도록 설계하였다. 생성된 이미지는 화재 탐지 모델의 학습 데이터로 사용되어, 실제 환경에서의 탐지 성능을 개선하는 데 이바지한다. 본 연구는 YOLO v7과 YOLO v8을 활용하여 화재 탐지 성능을 분석한다. 학습 결과로써 ‘all’ 클 래스의 mAP50 값은 YOLO v7에서 0.937, YOLO v8에서 0.966이고, ‘fire’ 클래스의 mAP 값 은 YOLO v7에서 0.958, YOLO v8에서 0.972이고, ‘smoke’ 클래스의 mAP 값은 YOLO v7에 서 0.916, YOLO v8에서 0.961로 측정되었다. 이를 통해 모델이 다양한 화재 및 연기 상황을 더 잘 이해하고, 실제 화재 발생 시 더 높은 정확도와 신속한 대응이 가능하게 된다. 본 연구는 화재 탐지 기술의 발전뿐만 아니라, GAN을 활용한 데이터 증강이 다양한 영상 처리 기반 탐지 시스템의 성능 개선에 기여할 수 있음을 보여준다.","This study focuses on fire accidents, which cause severe damage among industrial accidents, and rapid detection and response to fire is essential to minimize property loss and human casualties. In this study, the Generative Adversarial Networks (GAN) algorithm was designed to generate high-quality synthetic fire and smoke images from actual fire and smoke images. The generated images are used as training data for the fire detection model, contributing to improving detection performance in real environments. This study analyzes fire detection performance using YOLO v7 and YOLO v8. As a training result, the mAP50 value of the 'all' class is 0.937 in YOLO v7 and 0.966 in YOLO v8, the mAP value of the 'fire' class is 0.958 in YOLO v7 and 0.972 in YOLO v8, and the mAP value of the 'smoke' class is 0.972 in YOLO v8. It was measured as 0.916 in v7 and 0.961 in YOLO v8, which allows the model to better understand various fire and smoke situations and enables higher accuracy and faster response in the event of an actual fire. This study shows that, in addition to developing fire detection technology, data augmentation using GAN can improve the performance of various image processing-based detection systems."
YOLO 모델별 독성 해양 생물 탐지 성능 비교 및 스마트 수산 기술 적용 가능성 탐색,2024,"['딥러닝', 'YOLO 알고리즘', '해양 생물', '파란고리문어', 'Deep Learning', 'YOLO Algorism', 'Marine Organism', 'Blue-Ringed Octopus']",국문 초록 정보 없음,"The rise in sea temperatures due to global warming has accelerated the migration of marine species, leading to the frequent discovery of toxic marine organisms in domestic waters. The blue-ringed octopus in particular is very dangerous because it contains a deadly poison called tetrodotoxin. Therefore, early detection of these toxic species and minimizing the risk to human life is crucial. This study evaluates the effectiveness of using the latest object detection technology, the YOLO model, to detect toxic marine species, aiming to provide valuable information for the development of a smart fisheries system. The analysis results showed that YOLOv8 achieved the highest precision at 0.989, followed by YOLOv7 at 0.775 and YOLOv5m at 0.318. In terms of recall, YOLOv8 scored 0.969, YOLOv5l scored 0.845, and YOLOv7 scored 0.783. For mAP50 and mAP50-95 metrics, YOLOv8 also performed the best with scores of 0.978 and 0.834, respectively. Overall, YOLOv8 demonstrated the highest performance, indicating its strong suitability for real-time detection of toxic marine organisms. On the other hand, the YOLOv5 series showed lower performance, revealing limitations in detection under complex conditions. These findings suggest that the use of the latest YOLO model is essential for establishing an early warning system for toxic marine species."
YOLO 객체 탐지 기법을 활용한 혼합 외국 동전 식별의 웹 기반 구현 및 성능 평가,2024,"['YOLO Object Detection', 'Mixed Foreign Coins', 'Web-based Application', 'Currency Exchange Information', 'Coin Identification', 'YOLO 객체 탐지', '혼합 외국 동전', '웹 기반 응용', '환율 변환 정보', '동전 식별']","여행 경험이 부족하거나 다수의 국가를 단기간에 여행하는 여행자들은 혼합된 외국 동전을 구분하고 그 가치를 이해하는 데 어려움을 겪을 것이다. 본 논문은 다수 국가의 외국 동전이 한 프레임 안에 존재하는 경우 이를 YOLO 객체 탐지를 사용해 식별하는 모델을 구현하고 그 성능을 평가한 결과를 담고 있다. 제안 모델은 Google Colab에서 훈련된 8,100개 이미지 데이터셋에서 미국 달러, 유럽 유로, 중국 위안 등 18가지 다른 동전 클래스를 성공적으로 식별할 수 있다. 제안 모델은 모바일 친화적인 웹 애플리케이션으로 구현되었으며, 사용자가 동전 이미지를 업로드하면 인식 결과와 함께 사용자의 선택에 따라 최신 환율 변환 정보를 제공 받을 수 있다. 모델의 성능 지표 점수는 정밀도(Precision), 재현율(Recall) 및 정확도(Accuracy)에 대해 각각 0.892, 0.932 및 0.925로서 만족스러운 결과를 보여주었다.","Travelers who lack extensive experience or those visiting multiple countries in a short timeframe often need help to differentiate and identify the values of mixed foreign coins. This paper introduces a model that employs You Only Look Once (YOLO) object detection to identify various foreign coins within a single image frame and thoroughly evaluate its performance. The model, developed on Google Colab, has been trained using a dataset of 8,100 images and successfully identifies 18 different classes of coins, including the US dollar, European euro, and Chinese yuan. Implementing the model as a mobile-friendly web application allows users to upload images of their coins, and the application will provide identification results along with the option to receive the latest currency exchange information. The performance metrics scores of the model were 0.892, 0.932, and 0.925 for Precision, Recall, and Accuracy, respectively, showing satisfactory results."
엣지 검출 과정을 통한 YOLO 기반 구조물의 균열 탐지,2024,"['Edge Nomalization', 'Canny', 'Object Detection', 'YOLOv8', 'Crack', 'Deep Learning']",국문 초록 정보 없음,"In this paper, we propose an algorithm that combines the YOLO model with edge detection techniques to effectively detect cracks occurring in structures. Existing manual inspection methods are time-consuming, costly, and suffer from poor accuracy. To solve this problem, this study proposes an automated deep learning-based detection method, specifically using a YOLO model and a canny edge detection algorithm to perform more precise crack boundary extraction. The proposed algorithm consists of two steps. The first step is image preprocessing, which uses several preprocessing techniques such as gray-scale conversion, median blur, normalization, and brightness inversion to highlight the edges of cracks. In the second step, the canny edge detection algorithm is used to detect the boundaries of the cracks in the preprocessed image, and the YOLOv8 model is used to learn and detect the location of the corresponding cracks. The results show that the best performance is achieved when the YOLO model is trained using 6 steps of preprocessing and canny edge detection."
시각장애인 보행 안전을 위한 Few-shot Learning과 Grounding DINO 기반 준지도학습 YOLO 프레임워크,2024,"['computer vision', 'few-shot learning', 'YOLO', 'grounding DINO', 'object detection', '.']","시각장애인의 보행 안전을 위한 객체 탐지 시스템은 실시간 처리와 높은 정확도가 요구되나, 현재 공개된 보행자 시점의 데이터셋이 매우 제한적이라는 문제에 직면해 있다. 본 연구에서는 이러한 한계를 극복하기 위해 Few-shot Learning과 Grounding DINO를 통합한 새로운 YOLO 최적화 프레임워크를 제안한다. 제안된 프레임워크는 클래스당 레이블링된 이미지 수를 기존 3,000장에서 150장으로 95% 감소시키면서도 mAP 0.80의 성능을 유지하였다. 또한 동적 배치 정규화와 신뢰도 기반 가중치 손실 함수를 도입하여 야간 우천과 같은 열악한 환경에서도 mAP 0.78의 안정적인 성능을 보였으며, 42 FPS의 처리 속도와 3.5GB의 메모리 사용량으로 모바일 환경에서의 실시간 처리가 가능함을 입증하였다. 본 연구에서 제안한 통합적 접근은 의료 영상 분석, 산업 검사 등 레이블링된 데이터가 제한적인 다양한 분야에서의 활용 가능성을 보여준다.","Object detection systems for safe walking of visually impaired people require real-time processing and high accuracy, but face limitations due to the scarcity of publicly available pedestrian perspective datasets. This study proposes a novel YOLO optimization framework that integrates Few-shot Learning and Grounding DINO to overcome these limitations. The proposed framework maintains an mAP of 0.80 while reducing the number of labeled images per class by 95%, from 3,000 to 150. By introducing dynamic batch normalization and confidence-based weight loss functions, the system achieves stable performance with an mAP of 0.78 even in adverse conditions such as nighttime rain. The framework demonstrates real-time processing capability in mobile environments with 42 FPS and 3.5GB memory usage. Our integrated approach shows potential applications in various fields with limited labeled data, such as medical image analysis and industrial inspection."
딥러닝 기반 YOLO 활용 실시간 AI 산불 감시 시스템,2024,"['모니터링 시스템', '산불', '실시간 시스템', 'YOLO', '딥러닝', 'Monitering System', 'Wildfire', 'Real-time System', 'YOLO', 'Deep-Learning']","최근 건조한 날씨에 생기는 불씨가 초기진압에 실패하며 대형 산불로 확산되는 사고가 많이 발생하고 있다. 산에서 생기는 불씨를 초반에 발견하는 것으로 문제 해결이 가능해진다.  넓은 지역을 사람이 직접으로 관찰하는 것은 어렵기 때문에 자동 검출 시스템이 필요하다. 영상 분석을 통한 자동 산불 감지 시스템을 제안하고자 한다. 이를 통해 인력 낭비를 줄일 것으로 예상하며 기존 방식의 한계점을 개선한 학습법이 효과가 있음을 검증한다. 감지 성능 평가 지표로 객체 탐지 예측의 정확률, 재현율과 mAP에서 높은 성과를 달성하였다. 그리고 발화 연기와 아닌 것을 구별하는 학습하는 방식을 제안한다. 분할기법을 이용한 본 논문의 예측방법은 면적을 계산하여 산불 규모를 유추할 수 있을 것으로 기대된다.","Recently, a lot of accidents have occurred in which small embers generated in dry weather fail to suppress the initial fire and spread to large wildfires. To solve this problem, finding embers in the mountains at the beginning is important. An automatic detection system is needed because it is difficult for humans to observe large areas directly. This study was conducted to find a highly practical method by proposing an AI-automatic forest wildfire detection system using image analysis. Through this, it is expected to reduce manpower waste drastically, and it is verified that the learning method that improves the limitations of the existing method has a real effect. High performance was achieved in the accuracy rate, recall rate, and mean average precision of object detection prediction, which can be seen as a wildfire detection performance evaluation index. This paper proposes an AI model(YOLO, You Only Looks Once model) method of deep learning to distinguish between ignition smoke and non-ignition smoke. In the future, it is expected that the scale of forest fire can be inferred by calculating the distance between the forest fire occurrence point and the shooting point and the area using the segmentation technique installed in the AI model."
Mask R-CNN 모델과 YOLO 모델을 활용한 차량 관점의 자율주행 주차 공간 인식 모델 개발,2024,"['주차 공간 인식', '자율주행', '주차장', 'Parking Space Recognition', 'Autonomous Driving', 'Parking Lot', 'Mask R-CNN', 'YOLO']",본 논문에서는 자율주행 자동차가 주차장에서 주차할 공간을 탐색하려고 할 때 주차 가능 공간을 인식할 수 있는 능력을 갖도록 하는 딥러닝 모델의 필요성을 제안하였다. 제안된 딥러닝 모델의 기능은 자율주행 중 차량 관점에서 주행 공간과 주차 가능 공간을 분할로 구별해 내는 공간 인식에 그 목적이 있다. 본 연구에서는 컴퓨터비전 분야에서 2단계검출 모델로 대표되는 Mask R-CNN 모델과 1단계 검출 모델로 대표되는 YOLO 모델을 전이 학습하여 만든 모델로 주차 가능 공간 인식에 적용할 것을 제안한다. 실내 대형 주차장에서 주차 공간 인식 실험을 두 모델의 출력 결과물을통해 확인해 봄으로써 본 연구의 유용성을 확인하였다.,"A deep-learning model that allows autonomous cars to recognize available parking spaces when attempting to search for spaces to park in parking lots is proposed herein.The proposed deep-learning model is designed to perform spatial recognition, i.e., partitioning the driving space and available parking space into segments from the perspective of the vehicle during autonomous driving. We propose the utilization of the Mask R-CNN model represented by a two-stage detection model in a computer vision field and the YOLO model represented by a one-stage detection model for the recognition of available parking spaces.The effectiveness of the proposed model is confirmed via a parking-space-recognition experiment in large indoor parking lots using the output results of the abovementioned two models."
Octave-YOLO: 실시간 객체 탐지를 위한 직접적 다중 스케일 특징 융합,2024,"['object detection', 'YOLO', 'octave convolution', 'multi-scale feature fusion', '객체 탐지', 'YOLO', 'octave convolution', '다중 스케일 특징 융합']","최근 객체 탐지 분야에서는 다양한 크기의 객체를 감지하기 위하여 여러 스케일의 특징 맵들을 융합하는 다중 스케일 특징 융합을 위한 많은 연구가 진행되고 있다. 이러한 다중 스케일의 특징맵을 융합하기 위해, FPN(Feature Pyramid Network)이나 PANet(Path Aggregation Network) 등의 다양한 네트워크 구조가 제시되었다. FPN을 개선한 PANet은 하향식 경로뿐만 아니라 상향식 경로를 추가하여 객체 탐지 분야에서 큰 성능 향상을 이루었다. 그러나 기존 PANet에서의 다중 스케일 특징 융합을 위한 업스케일링 또는 다운스케일링 과정은 원래 특징 맵에서 보존된 저수준 또는 고수준 정보의 손실을 야기했다. 본 논문에서는 옥타브 합성곱(Octave Convolution)을 통한 별도의 처리 없이 다양한 크기의 특징 맵을 원활하게 융합할 수 있는 Octave C2f 모듈을 제안하여 정확성을 향상시키고 계산 복잡도를 줄였다. PASCAL VOC 및 MS COCO 데이터 세트를 사용한 실험 결과, YOLOv8 기본 모델과 비교하여 개선된 정확성과 감소된 계산 작업량 및 매개변수 개수를 확인할 수 있었다.","In object detection research, multiscale feature fusion—combining feature maps of different scales to detect objects of varying sizes—has become a critical focus. Network structures like Feature Pyramid Networks (FPNs) and Path Aggregation Networks (PANets) have been developed to address this challenge. PANet, an enhancement of FPN, integrates both top-down and bottom-up pathways, leading to significant improvements in object detection performance. However, during multiscale feature fusion, PANet’s upscaling and downscaling processes can result in the loss of crucial low- or high-level information from the original feature maps. In this paper, we introduce the Octave C2f module, which employs octave convolution to seamlessly fuse feature maps of different sizes without the need for additional processing. This innovative approach enhances accuracy while reducing computational complexity. Experimental results on the PASCAL VOC and MS COCO datasets demonstrate improved accuracy, reduced computational effort, and a decrease in parameter count compared to the default YOLOv8 model."
YOLO 기반 개인형 이동장치 주행 도로 인식 시스템,2024,"['Personal mobility devices', 'Traffic accidents', 'Road image recognition', 'Object detection', 'YOLOv5']","본 논문은 특히 개인형 이동장치의 이용이 금지된 인도와 횡단보도에서 관련 교통사고가 증가하는 사회적 배경을 다룬다. 인도, 횡단보도와 같이 개인형 이동장치의 운행이 제한된 도로에서 상당수의 개인형 이동장치 교통사고가 발생하고 있으며, 이를 해결하기 위해 금지된 도로에서 개인형 이동장치의 불법 운전을 모니터링하고 규제해야 할 필요성이 존재하지만, 실시간으로 모니터링하기에는 현실적인 한계가 존재한다. 이러한 한계를 극복하기 위해 주행 도로 이미지 데이터를 활용하여 도로 종류를 인식하고 이를 통해 금지된 도로를 주행하는 개인형 이동장치의 불법 운전을 식별하는 모니터링 시스템을 제안하며, 그 성능을 검사하기 위해 애플리케이션으로 시스템을 개발하였다. 이 애플리케이션은 YOLO 객체 감지 모델을 사용하여 주행 도로의 종류를 구분하고, 이를 통해 개인형 이동장치 운전자가 금지된 도로에서 이용할 때를 감지하고 그에 따른 경고 및 안내 메시지를 발행하여 적절한 경로를 준수하도록 유도한다. 이 시스템은 개인형 이동장치 운전자들이 금지된 도로를 주행하는 경우 시스템은 이러한 행동을 방지하기 위해 경고 및 안내 메시지를 출력한다. 이 논문의 마지막 섹션에서는 시스템의 한계에 대해 논의하고 잠재적인 개선 사항을 제안하여 향후 연구 방향을 제시한다. 본 연구를 통해 주행이 금지된 도로에서 발생하는 교통사고를 줄이기 위한 기반을 마련하여 개인형 이동장치와 관련된 전반적인 교통사고를 줄여 공공의 안전성을 높이는 것을 목표로 한다.","This paper addresses the increasing incidence of traffic accidents involving personal mobility devices, particularly on sidewalks and crosswalks where personal mobility device usage is prohibited. Despite the necessity of monitoring and regulating the illegal operation of personal mobility devices on restricted roads, real-time identification and enforcement pose significant challenges. To overcome these limitations, we propose a monitoring system that utilizes road image data to recognize the type of road and identify unauthorized personal mobility device usage. An application was developed to test the system's performance, leveraging the YOLO object detection model to distinguish road types. This application aims to guide personal mobility device users to adhere to appropriate routes by detecting when they are operating on prohibited roads and issuing warnings and guidance messages accordingly. The system's implementation includes real-time alerts to deter personal mobility device users from entering restricted areas, thus enhancing road safety. In the final section of this paper, we discuss the limitations of the system and suggest potential improvements, outlining directions for future research. Through this study, we hope to lay the groundwork for reducing traffic accidents involving personal mobility devices on restricted roads, ultimately contributing to a significant decrease in overall personal mobility device-related traffic incidents and improving public safety."
다중 YOLO 모델을 활용한 방울토마토 성숙도 판별 성능 비교 연구,2024,"['deep learning', 'harvesting robot', 'object detection', 'cherry tomato', 'YOLO (You Only Look Once)', '.']",국문 초록 정보 없음,"Millions of tons of cherry tomatoes are produced annually, with the harvesting process being crucial. This paper presents a deep learning-based approach to distinguish the ripeness of cherry tomatoes during the harvesting process. It specifically analyzes the performance of the YOLO (You Only Look Once)v5 and YOLOv8 models, which are designed to rapidly detect the ripeness of cherry tomatoes in real time. The proposed system is expected to resolve rural issues caused by population decline and enhance productivity in cherry tomato harvesting environments. Future research will aim to apply this technology to harvesting robots for the automatic recognition and harvesting of cherry tomatoes."
Hue Saturation Value (HSV) 필터를 활용한 YOLO 화재 탐지 성능향상 및 360 카메라 기반 화재 위치 인식,2024,"['욜로', '360 카메라', '딥러닝', 'HSV', '객체 인식', 'yolo', '360 camera', 'deep learning', 'hsv', 'object detection']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 화재탐지 적용을 위한 YOLO 알고리즘 비교에 관한 연구,2024,"['Fire detection', 'YOLO', 'Object detection', 'Real-time']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO v10 기반 위성 영상 기반 태양광 발전소 탐지 및 정량화 모델 개발,2024,"['YOLOv10', 'Solar power plant', 'Aerial Image', 'KAKAO map']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO기법을 사용한 차량가속도 및 차두거리 산출방법,2024,"['가속도', '차두거리', '객체인식', 'YOLO', 'Acceleration', 'Spacing', 'Object recognition', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO-Pose와 Repetition Network을 이용한 AI기반 심폐소생술 훈련 시스템 개발,2024,"['영상처리', '심폐소생술', '인체 자세 추정', 'YOLO-Pose', 'RepNet', 'Image Processing', 'CPR', 'Human Pose Estimation', 'YOLO-Pose', 'RepNet']",국문 초록 정보 없음,다국어 초록 정보 없음
PreScan의 보행자 객체 탐지 성능 비교를 통한 최적 YOLO 알고리즘 선정에 대한 연구,2024,"['Object Detection', 'YOLO(You Only Look Once)', 'PreScan', 'Optimization']",국문 초록 정보 없음,"This study aims to determine the optimal YOLO algorithm for object detection performance in PreScan simulation. YOLOv4, the current model used, is compared with five versions of YOLOv8 (v8n, v8s, v8m, v8l, v8x). The analysis focuses on simulation time, initial detection distance, and continuous detection distance to assess the suitability of each version for practical applications. YOLOv8n, designed for speed and efficiency, demonstrated significant improvements in reducing simulation time, while YOLOv8x showed exceptional performance in terms of detection accuracy and consistency. The various versions of YOLOv8 each present unique strengths, with YOLOv8n excelling in speed and YOLOv8x in accuracy. YOLOv8m offered a well-balanced approach, making it particularly suitable for scenarios where both speed and detection reliability are crucial. The study highlights the potential benefits of adopting YOLOv8 models in PreScan simulations, emphasizing their ability to enhance object detection performance in the tested scenario. While further testing is needed to confirm applicability across various conditions, the results suggest that each version has unique strengths that could be leveraged depending on specific requirements. Overall, YOLOv8m is identified as the optimal choice for balanced performance in the current test scenario, ensuring both effective simulation and reliable object detection capabilities."
YOLO를 활용한 안티-드론 객체 탐지 시스템의 학습 이미지 수에 따른 성능 분석,2024,"['Drone', 'Object Detection', 'Machine Learning', 'YOLO', 'Number of Images']",국문 초록 정보 없음,"Recently, machine learning based real-time anti-drone object detection systems have attracted great attention to protect multi-use facilities or national important facilities from drones. This paper studies the performance and relationship analysis on the anti-drone object detection system by the number of learning images with YOLO network based on transfer learning, in order to provide guidelines that can be applied in real environments where learning data is difficult to obtain, such as terrorist and wartime situations, and sudden drone/UAV infiltration situations, and so on."
YOLO 객체 탐지 기술을 활용한 가정용 화재 감지 및 알림 시스템,2024,"['YOLOv8', 'RTSP', 'Fire Detection']","화재는 다른 재난보다 확산 속도가 빠르기 때문에 신속하고 정확한 감지와 지속적인 감시가 요구된다. 이를 위해서는 인적, 물적 자원이 요구되는데 최근 다양한 분야에서 활용되고 있는 객체 탐지 모델 YOLO를 활용하여 이 문제를 해결하고자 한다. 따라서 본 논문은 가정에서 화재가 발생할 시 YOLOv8을 기반으로 생성된 화재 감지 모델을 실시간으로 모니터링할 수 있는 시스템과 화재를 감지할 시 사용자에게 알림을 전송하는 시스템을 개발하였다.","Since fires spread faster than other disasters, rapid and accurate detection and continuous monitoring are required. This requires human and material resources, and this problem is solved by using the object detection model YOLO, which has been recently used in various fields. Therefore, this paper developed a system that can monitor the fire detection model generated based on YOLOv8 in real time when a fire occurs at home and a system that transmits notifications to users when detecting a fire."
용접 공정에서 객체 탐지 알고리즘 YOLO의 다각적 응용 방안,2024,"['YOLO', 'Welding Automation', 'Weld Monitoring', 'Computer Vision', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 창고 내 잠재적 위협이 되는 객체 검출,2024,"['Deep learning', 'Object detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 객체인식 전자동 모니터암,2024,"['automated monitor arm system', 'computer-centric tasks', 'SORT algorithm', 'YOLO’s object recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO와 OpenCV 알고리즘을 이용한 안전 규제 위반 공용 전동킥보드 이용자 단속,2024,"['YOLO', 'OpenCV', 'electric kick scooter', 'identification']",국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 시스템에서의 안전모 탐지를 위한 YOLO-NAS 모델 설계,2024,"['임베디드', '온디바이스AI', '객체탐지', '딥러닝', 'Embedded System', 'On-device AI', 'Object Detection', 'Deep Learning', 'YOLO-NAS']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO와 전이 학습을 이용한 실시간 우회전 교통사고 예방 모델 연구,2024,"['객체탐지', '컴퓨터 비전', '교통 모니터링', '딥러닝', '우회전 안전', 'Object Detection', 'Computer Vision', 'Traffic Monitoring', 'Deep Learning', 'Right-turn Safety']","본 연구는 YOLOv7 모델을 활용하여 우회전 교차로에서 보행자와 차량을 탐지하고, 제한된 리소스 환경에서도 실시간 탐지가 가능한 시스템을 구현하고자 하였다. 이를 위해 AIHub 교통 데이터 세트와 커스텀 데이터 세트를 결합하고, 데이터 전처리 및 증강 기법을 적용하여 학습 데이터의 품질을 강화하였다. 특히 커스텀 데이터 세트는 교차로 환경을 실제와 유사하게 설계하여 탐지 성능을 높이는 데 기여하였다. 모델 학습 과정에서 YOLOv7 모델은 학습률 0.1, 배치 크기 8, 에포크 200회로 설정하였으며, 입력 이미지 크기는 640×640으로 통일하였다. 학습 결과, YOLOv7 모델은 mAP@0.5에서 93.2%, mAP@0.5:0.95에서 76.5%의 성능을 기록하였으며, 평균 응답 시간은 118ms로 Jetson Nano 환경에서도 실시간 탐지가 가능함을 확인하였다. 이는 기존 YOLOv7 모델 대비 성능이 개선되었으며, 제한된 환경에서도 높은 정확도와 신뢰성을 제공함을 입증하였다. 본 연구는 YOLOv7 기반 객체 탐지 시스템이 실시간 안전 모니터링 및 경고 시스템으로 활용 가능함을 제시하였다. 향후 연구에서는 하이퍼파라미터 최적화, 관심 영역(ROI) 조정, 경고 알고리즘 개선 등을 통해 시스템의 실시간성과 신뢰성을 더욱 강화할 계획이다.","This study utilized the YOLOv7 model to detect pedestrians and vehicles at right-turn intersections and aimed to implement a system capable of real-time detection even in resource-constrained environments. To achieve this, the AIHub traffic dataset was combined with a custom dataset, and data preprocessing and augmentation techniques were applied to enhance the quality of the training data. Notably, the custom dataset was designed to closely resemble actual intersection environments, contributing to improved detection performance. During the training process, the YOLOv7 model was configured with a learning rate of 0.1, a batch size of 8, and 200 epochs, with input image sizes standardized to 640×640. As a result, the YOLOv7 model achieved an mAP@0.5 of 93.2% and an mAP@0.5:0.95 of 76.5%, with an average response time of 118ms, demonstrating its capability for real-time detection in Jetson Nano environments. These results indicate that the proposed YOLOv7 model improved performance compared to the original YOLOv7 and provides high accuracy and reliability even in constrained settings. This study suggests that the YOLOv7-based object detection system can be utilized as a real-time safety monitoring and alert system. Future research will focus on optimizing hyperparameters, adjusting the region of interest (ROI), and improving alert algorithms to further enhance the system's real-time capabilities and reliability."
YOLO와 OCR을 결합한 고속 택배 라벨 인식 시스템 개발을 위한 접근방법,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO를 이용한 제주 천연자원 항노화 실시간 분석,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO-Pose 기반 운동 보조 헬스케어 프로그램,2024,"['deep-learning', 'pose estimation', 'healthcare', 'computer vision', 'personal training']","현대 사회에서 건강에 대한 인식이 높아지면서 운동의 중요성이 강조되고 있지만, 많은 현대인들이 시간적, 경제적 제약으로 인해 충분히 운동을 하지 못하고 있다. 더욱이 잘못된 운동 자세는 부상을 초래할 수 있어 정확한 자세 유지가 필수적이다. 본 연구에서는 YOLOv8-pose를 활용한 운동 영상의 포즈 추정을 통해 사용자의 운동 자세를 정확히 파악하고 이를 통해 개인화된 운동 방법을 제안하는 프로그램을 개발하고자 한다.","In modern society, as awareness of health increases, the importance of exercise is emphasized. However, many people are unable to exercise adequately due to time and economic constraints. Furthermore, incorrect exercise postures can lead to injuries, making it essential to maintain accurate poses. This study aims to develop a program that precisely identifies users exercise postures through pose estimation of exercise videos using YOLOv8-pose, and suggests personalized exercise methods based on this information."
YOLO-WORLD 멀티모달기반 모니터링 지원 플랫폼,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO-EfficientNet 기반의 실시간 안전모 탐지 모델 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
유해조류 검출을 위한 인공지능 알고리즘 분석: Faster R-CNN과 YOLO의 성능 비교,2024,"['yolov5', 'faster R-CNN', 'Harmful birds eradication', 'mAP', 'hours']",국문 초록 정보 없음,다국어 초록 정보 없음
Object detection for various types of vessels using the YOLO algorithm,2024,"['Object detection', 'Ship type', 'YOLO v3', 'YOLO v5s']",국문 초록 정보 없음,"Owing to the development of computer vision technology, much effort is being conducted to apply it in the maritime field. In this study, we developed a model that can detect various types of ships using object detection. Nine types of ship images were downloaded, and bounding box processing of the ships in the images was performed. Among the You Only Look Once (YOLO) model versions for object detection, YOLO v3 and YOLO v5s were used to train the training set, and predictions were made on the validation and testing sets. For the validation and testing sets, both models made good predictions. However, as some mispredictions occurred in the testing set, recommendations for these are given in the last section."
Yolo 와 Slowfast 알고리즘 기반 유아의 자연스러운 행동 인식 기법,2024,"['유아 행동 인식', '딥 러닝', 'YOLO', 'SlowFast Model']","최근 딥러닝 기술의 발달과 컴퓨팅 파워의 증가로 영상을 통한 사용자 행동 인식과 관련한 연구가 많이 진행되고 있다. 본 논문에서는 Yolo 와 Slowfast 알고리즘 기반으로 유아의 행동을 분석하는 알고리즘을 제안하였다. 유아의 경우, 성인과 골격 구조가 다르기 때문에, 일반적인 모델로 인식할 경우 차이가 발생할 수 있다. 이에 따라, YOLO 모델을 파인 튜닝해서 유아 인식의 정확도를 올리고, SlowFast 모델을 통해서 유아들이 많이 하는 앉기나 서기, 걷기 등과 같은 13 개의 행동을 예측한다. 유아들이 자연스럽게 활동하는 상황에서 데이터를 수집하였고, 실험 결과 사람 인식률의 경우 96% 의 정확도를 보여주었고, 행동 인식의 경우 50% 정도의 정확도를 보여주었다. 향후 제안한 방법을 유아 교육기관에 활용하는 모니터링 시스템 등에 적용이 가능하다.",다국어 초록 정보 없음
IS-YOLO: A YOLOv7-based Detection Method for Small Ship Detection in Infrared Images With Heterogeneous Backgrounds,2024,"['Deep learning', 'infrared image', 'maritime', 'small ship detection.']",국문 초록 정보 없음,"Ship detection from infrared images occupies an important role in maritime search and tracking applications. When compared with methods to process daytime RGB photos, processing infrared images has challenges due to the reduced signal-to-clutter ratio (SCR), indistinct outlines, and inadequate spatial resolutions. In addition, the detection of small targets remains challenging owing to their size variations and unclear edges, leading to missed detections and low accuracy. This work suggests the use of infrared-ship YOLO (IS-YOLO), a model to recognize small ships in infrared images. The proposed technique, based on YOLOv7, enhances the ability to detect infrared objects in heterogeneous scenarios. First, we improve the ability of the YOLOv7 backbone to extract features by introducing a new structure for the efficient layer aggregation network (ELAN) with a two convolutions and GhostConv module. Secondly, the max pooling pyramid-ELAN is introduced to integrate multi-scale information. Furthermore, we capture an infrared small ship dataset using the FLIR T620 camera. The experimental results demonstrate that the IS-YOLO model had the best performance in small ship detection from infrared images compared to several state-of-the-art models, as shown by optimal metrics that include average precision (AP@.5, AP@.5:.95, the number of parameters, and the model size): AP@.5, 88.9%; AP@.5:.95, 38.2%; 32.8 M; and 63.1 Mb, respectively. The proposed approach can serve as a valuable reference for the development of small-ship detection methods with infrared images."
Evaluation of the YOLO models for discrimination of the alfalfa pollinating bee species,2024,['Alfalfa pollinating bee Bee recognition Computer vision Deep learning YOLO series'],국문 초록 정보 없음,"Identifying insect pollinators and their roles in mediating pollen flow is critical to understand the potential gene flow risks of insect pollination-dependent crop species, such as alfalfa. This study was conducted to evaluate and compare the feasibility of You Only Look Once (YOLO) version 3 (YOLOv3), YOLOv5, YOLOv7, and YOLO Representation (YOLOR) to discriminate the three most common alfalfa pollinating bee species, including honeybee, bumblebee, and leafcutting bee. The metrics comparison results showed YOLOv3 and YOLOv5 out performed YOLOv7 and YOLOR regarding model precision, recall, F 1 score, and mAP50 values. YOLOv3 and YOLOv5 could successfully discriminate the three different bee species with an accuracy of almost 100% (99.9%, 99.8%, and 100% accuracy for honeybee, bumblebee, and leafcutting bee for the two models, respectively).Comparatively, YOLOv7 could discriminate honeybee with an accuracy of 95% but was more likely to mistakenly discriminate bumblebee and leafcutting bee due to the relatively lower discriminating accuracy (87.3% and 66.2%, respectively). While the values of determined parameters for YOLOR were lower than YOLOv3 and YOLOv5, the higher precision (0.99680) along with recall (0.98721), F 1 (0.99198), mAP50 (0.99323), and mAP50-100 (0.89076) values indicate that this model could be able to obtain a favorable performance in discriminating the three bee species. In summary, the proposed method in this study has the potential for identifying the alfalfa pollinating bee species, studying the bees’ flower-visiting behaviors, evaluating the risks of insect-mediated pollen flow, and thus contributing to the management of genetically engineered (GE) alfalfa transgene flow."
YOLO Series를 사용한 DeepSORT 성능 비교,2024,"['Object Detection', 'MOT', 'DeepSORT', 'YOLO', 'Object Detection', 'MOT', 'DeepSORT', 'YOLO']","본 연구는 스마트시티 발전에 따라 교통 관리와 인구 모니터링의 중요성이 커지면서 CCTV 데이터를 활용한 실시간 분석이 필수적이다. 기존의 수동 데이터 수집 방식은 신뢰성과 정확성에 한계가 있어, 객체 추적 알고리즘을 사용하는 지능 형 CCTV가 도입되었지만, 여전히 ID 변경과 재식별 문제를 겪고 있다. 이를 해결 하기 위해 DeepSORT 알고리즘과 YOLOv5, YOLOv7, YOLOv8 등의 객체 탐지 모델을 결합한 방안을 사용하여 MOT16 및 MOT20 데이터셋을 통해 각 모델의 성 능을 MOTA, MOTP 지표로 평가하였다. 연구 결과, YOLOv8과 DeepSORT의 조합이 복잡한 도시 환경에서 가장 높은 MOTA와 MOTP 점수를 기록하며 우수한 성능을 보였다. 특히, YOLOv8은 MOT16-03 시퀀스에서 70.3 MOTA를 기록하며 YOLOv5와 YOLOv7을 능가하였 고, MOT20 데이터셋에서도 높은 정확도와 추적 일관성을 유지하였다. 이러한 결과 는 YOLOv8과 DeepSORT의 조합이 도시 CCTV 환경에서 객체 탐지 및 추적에 가장 효과적임을 나타내며, 스마트시티의 지능형 CCTV 시스템에 대한 최적의 선 택 기준을 제공할 수 있다.","This paper highlights the growing importance of traffic management and population monitoring as smart cities evolve, underscoring the necessity of real-time analysis using CCTV data. Traditional manual data collection methods face limitations in reliability and accuracy, prompting the adoption of intelligent CCTVs with object tracking algorithms. However, challenges such as ID switching and re-identification persist. To address these issues, this study evaluates the performance of DeepSORT combined with object detection models like YOLOv5, YOLOv7, and YOLOv8, using the MOT16 and MOT20 datasets and performance metrics such as MOTA and MOTP. The findings indicate that the combination of YOLOv8 and DeepSORT achieved the highest MOTA and MOTP scores, demonstrating excellent performance in complex urban environments. Specifically, YOLOv8 recorded a MOTA of 70.3 in the MOT16-03 sequence, outperforming YOLOv5 and YOLOv7, and maintained high accuracy and tracking consistency in the MOT20 dataset. These results suggest that the combination of YOLOv8 and DeepSORT is the most effective solution for object detection and tracking in urban CCTV settings, providing an optimal selection criterion for intelligent CCTV systems in smart cities."
YOLO 및 SAM 모델 기반 용접 X-ray 결함 영상 증강 기법,2024,[],국문 초록 정보 없음,"Welding is an essential process in manufacturing engineering and requires high reliablity to ensure structural integrity and safety. In this paper, we present a defect data augmentation approach for synthesizing X-ray welding defect images to ameliorate the issue of limited data. This is a achieved by employing a YOLO[1] (You Only Look Once) model to detect welding defects from training images and use bounding boxes and center points extracted from YOLO[1] as prompts for SAM[2] (Segment Anything). We apply a bilateral filter to the defect mask extracted from SAM[2] and blend it with a normal image for augmentation. Experimental results on a public welding defect dataset show the augmented images from our approach enhances welding defect detection."
YOLO 성능 향상을 위한 데이터 증강기법,2024,"['데이터 증강기법', '딥러닝', '기계학습', '인공지능', '복사-붙여넣기(증강)', 'Data augmentation', 'deep learning', 'machine learning', 'artificial intelligence', 'Copy-paste (augmentation)']","컴퓨터 비전은 CNN, 트랜스포머 등과 같은 모델의 발전으로 여러 분야에서 좋은 성과를 이루었다. 하지만, 모델을 학습하기 위해서는 다양하고 많은 데이터가 필요하다. 이러한 학습데이터를 얻기 위해서는 많은 시간과 노력이 필요 로 한다. 이러한 높은 비용으로 인해 데이터 부족이나 데이터 불균형이 발생하게 된다. 데이터 증강기법은 이러한 문 제를 해결하기 위한 좋은 방법이다. 본 논문에서는 객체 인식 모델을 위한 데이터 증강기법 중에서(복사-붙여넣기) Copy-Paste를 활용한 데이터 증강기법을 연구한다. 이전 연구에서는 인스턴스 영상 분할 객체를 붙이거나 시각적 인 맥락을 바탕으로 객체를 붙인다. 하지만 인스턴스 영상 분할 객체를 사용하지 않고 단순한 방법인 바운딩 박스 (Bounding Box)를 그대로 기존의 객체 위치에 같은 크기로 붙이거나 무작위로 붙이는 것도 모델의 성능이 향상된 다는 것을 발견했다. 또한, 객체에서 SAM(Segment Anything Model) 모델을 활용하여 객체의 인스턴스를 추출 하여 붙이는 방법을 제안한다. 그리고 붙이는 객체에 데이터 증강기법을 적용하여 데이터를 증강하는 방법을 추가실 험으로 보여준다. 또한, 기존의 객체가 붙여지는 객체에 의해 가려지는 것을 막기 위해 객체를 붙이고 기존 이미지에 있는 객체를 덮어쓴 방법도 적용하였다. 본 논문에서 객체 인식 모델 Yolo v5를 Pascal VOC12 데이터셋으로만 학 습한 결과보다 제안한 데이터 증강기법을 활용해서 학습한 결과가 더 높은 성능을 보여주는 것을 확인하였다.","Computer vision has shown excellent performance in various fields, thanks to the advancements in models like CNN and Transformers. However, training these models requires diverse and abundant data, which demands a significant amount of time and effort. The high cost associated with acquiring such training data often leads to issues like data scarcity and data imbalance. Data augmentation techniques provide effective solutions to address these challenges. In this paper, we focus on researching data augmentation techniques for object recognition models, specifically leveraging the Copy-Paste(Augmentation) technique. The previous researches involved attaching objects based on instance segmentation or visual context. However, we have discovered that using a straightforward approach, such as attaching bounding boxes of the same size to the existing object locations or randomly attaching objects, enhances the model's performance significantly. Furthermore, we propose a method of using the SAM(Segment Anything Model) to extract object instances from images and attaching them. We demonstrate additional experiments applying data augmentation techniques to the attached objects. To prevent existing objects in the image from occluded by the attached objects, we present a method of overlaying them into the image with attached objects. In this paper, we train the object recognition model using YOLO(You Only Look Once) v5 on the Pascal VOC12 dataset, and show better performance when utilizing the proposed data augmentation techniques."
Development of an Electric Scooter Photo Recognition System Using YOLO,2024,"['Electric Scooter Sharing Service', 'Object Detection', 'Photo Recognition', 'YOLO']",국문 초록 정보 없음,"The use of electric scooter (e-scooter) sharing services has increased significantly in recent years due to theirconvenience and economy. In order to rent an e-scooter, a user first finds nearby e-scooters using a smartphoneapplication, which shows the global positioning system (GPS) locations of e-scooters around the user. However,since the error of GPS can be more than 10 m, the user may have difficulty finding the exact location of the escooterthe user wants to use. To alleviate this problem, an e-scooter sharing service “Kickgoing,” operated byOlulo in South Korea, provides users with e-scooter photos taken by users upon return, along with their GPSlocations, on its smartphone application. Those photos help subsequent users to find e-scooters more accurately.However, since some users upload photos that do not include e-scooters or are unrecognizable, it is essential toprovide users with only those photos that clearly include an e-scooter. Therefore, in this paper, we develop ane-scooter photo recognition system that can accurately recognize only those photos that include e-scooters. Thedeveloped system, which is based on YOLO, uses three techniques: if a whole e-scooter is not recognized, itrecognizes an e-scooter by recognizing its parts individually; it recognizes e-scooters with significantlydifferent photography angles as different classes; and it provides users with only those photos in which theproportion of the e-scooter is within a certain range. Experimental results on a real dataset show that thedeveloped system recognizes e-scooter photos more accurately compared to a system that uses the YOLOmodel as is."
고속 YOLO 기반 차량 검출 성능 최적화 및 개선에 관한 연구,2024,"['Autonomous vehicle(자율주행 자동차)', 'Vehicle detection(차량 검출)', 'Real-time(실시간)', 'Youn Only Look Once(YOLO 알고리즘)', 'Less detect layer(적은 레이어 모델)']",국문 초록 정보 없음,"Autonomous driving systems are leading the innovation of transportation systems in modern society. One of the key elements of this technology is the accuracy and real-time capabilities of vehicle detection. Precise and rapid vehicle detection is a crucial factor that enables autonomous vehicles to operate safely in complex road environments. For this reason, object detection must be equipped with fast inference speed and maintain high accuracy. This study focuses on reducing the processing time and improving the accuracy of vehicle detection, which are essential for autonomous driving. In this study, considering that vehicle objects typically have a relatively large size, we aim to simplify the model structure and reduce its depth by removing small detect layers that are unnecessarily used in the existing YOLOv5s model. This is intended to achieve reductions in detection time and improvements in accuracy."
Additive Learning for Object Detection: A Dual-Model Approach with YOLO,2024,[],국문 초록 정보 없음,"This paper introduces enhancing object detection capabilities through an additive learning framework integrating two detection models such as YOLO (You Only Look Once). Additive learning involves AI modules collaboratively enhancing their performance by sharing and utilizing knowledge from each other. This framework significantly improves both dual models performance through continuous analysis of new incoming image data, enabling dynamic decisions on whether an image should be saved for further detection capability refinement. The implementation of this framework not only achieves higher accuracy in object detection systems but also ensures that the models adapt and improve when encountering new, unseen data points."
Improved Accuracy of Vehicle Part Detection and Damage Classification using YOLO Algorithm,2024,"['Computer Vision', 'Deep Learning', 'You Only Look Once', 'Vehicle Part Detection', 'Damage Classification']",국문 초록 정보 없음,"Continuous advancements in deep learning and computer vision has led to the utilization of such advanced technologies in the field of vehicle maintenance. This study developed vehicle part detection and damage classification models to help drivers develop effective repair plans for improved vehicle safety and performance. The You Only Look Once (YOLO) algorithm and transfer learning were used to train the vehicle part detection model, and the transformer method was to train the damage classification model. The proposed model achieved up to 95% vehicle parts detection accuracy, an improvement of 3% over that of the existing model, and a damage classification accuracy of 89%, an improvement of 6% over that of the existing model. With the recent rapid development of computer vision and deep learning technology, vehicle parts detection and damage classification are expected to provide new scientific method for vehicle repair."
YOLO v8을 활용한 컴퓨터 비전 기반 교통사고 탐지,2024,"['Car accidents detection', 'Computer vision', 'YOLOv8', 'CCTV', '자동차 사고 탐지', '컴퓨터 비전', 'YOLOv8', 'CCTV']",국문 초록 정보 없음,"Car accidents occur as a result of collisions between vehicles, leading to both vehicle damage and personal and material losses. This study developed a vehicle accident detection model based on 2,550 image frames extracted from car accident videos uploaded to YouTube, captured by CCTV. To preprocess the data, bounding boxes were annotated using roboflow.com, and the dataset was augmented by flipping images at various angles. The You Only Look Once version 8 (YOLOv8) model was employed for training, achieving an average accuracy of 0.954 in accident detection. The proposed model holds practical significance by facilitating prompt alarm transmission in emergency situations. Furthermore, it contributes to the research on developing an effective and efficient mechanism for vehicle accident detection, which can be utilized on devices like smartphones. Future research aims to refine the detection capabilities by integrating additional data including sound."
YOLO 계열 객체 탐지 신경망 모델 기술 동향,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
STN-YOLO: 공간 변환 네트워크를 이용한 견고한 뇌종양 탐지,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 모델을 활용한 조임 상태가 불량한 볼트 검출,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO v8을 이용한 분리수거 보조 장치,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반 뇌 종양 탐지와 MGMT 프로모터 메틸화 예측에 관한 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO v7 깊이 측정 알고리즘을 이용한 실시간 미세먼지 관제 시스템,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반의 자동차 부품 이기종 혼입 방지 예측 모델,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
YOLO V8를 활용한 노인 행동 인식 및 응급 알림 시스템,2024,"['pose estimation', 'object estimation', 'convolutional neural network', 'population aging', 'twilio']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLO 기반 PM 불법 운전 과태료 자동 징수 시스템,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
개선된 YOLO 기반의 다양한 도로 사용자 검출 및 위치 추정 방법,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
전이학습 활용 YOLO 기반 안티-드론 객체 탐지 시스템을 위한 Precision 및 Recall 효율 성능 분석,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
OFDM 레이다 시스템을 위한 YOLO 기반 물체의 속도 및 거리 추정,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
생활폐기물 분리배출을 위한 YOLO 모델 기반 객체 탐지 및 챗봇 알고리즘 개발,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
두피 상태 관리를 위한 YOLO 모델 기반 실시간 모근 검출 기법,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
지능형 홈케어를 위한 분할된 YOLO 모델과 잠재 코드 전송을 통한 효율적 데이터 통신,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
학습기반 과학화경계시스템 고도화에 적합한 YOLO v5 기술,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
에지 디바이스를 이용한 유해조류 검출 시스템의 YOLO 알고리즘 모델 성능 연구,2024,"['edge device', 'harmful birds', 'artificial intelligent', 'yolov7', 'orchards']","까마귀와 같은 유해조류에 대한 농가의 경제적 손실 피해가 매년 발생하고 있다. 이러한 피해를 방지하기위한 다양한 도구들이 개발되었지만 유해조류들이 가지는 퇴치 위협 적응 이라는 생물학적 특성으로 여러 방법들이 유명무실해 지고있다. 그래서 본 연구에서는 과수원 내에 발생하는 유해조류를 퇴치하기 위한 시스템에서 사용하기 위해 yolov7을 임베디드 보드 위에 탑재하여 새를 인식하는 유해조류 방조용 AI 모델을 개발하고 임베디드 보드 별로 이에 대한 성능을 비교하였다. 이는 물리적으로 소형 임베디드 보드가 활용되어야 하는 과수원의 배경에 적합한 연구 방식이며, 추후 다양한 방조법 연구에 활용될 수 있을 것으로 기대된다.","Harmful birds, such as crows, cause economic losses to farmers every year. Various tools have been developed to prevent these damages, but many methods are becoming ineffective due to the biological characteristics of harmful birds called threat adaptation. Therefore, in this study, we developed an AI model for harmful bird control that recognizes birds by mounting yolov7 on embedded boards for use in a system to combat harmful birds in orchards, and compared the performance of each embedded board. This is a research method that is suitable for the background of an orchard where physically small embedded boards must be utilized, and it is expected to be utilized in future research on various control methods."
GMAW의 표면 기공 검출을 위한 YOLO 알고리즘 성능 비교에 관한 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
유해조류 방지 시스템을 위한 에지 디바이스 기반의 YOLO 알고리즘 모델 속도 개선 연구,2024,"['edge device', 'harmful birds', 'TensorRT yolov', 'orchards']",국문 초록 정보 없음,다국어 초록 정보 없음
로봇의 옷 펼치기 작업을 위한 YOLO 기반 3 차원 파지점 추정,2024,"['Robot Vision', 'Grasping detection', 'Deep Learning', 'RGB-D']",국문 초록 정보 없음,다국어 초록 정보 없음
결함 감지를 위한 맞춤형 레이블링 기능을 갖춘 YOLO 기반 플라스틱 표면 검사기,2024,"['Plastic Defect', 'Object Detection', 'You Only Look Once', 'Labeling', 'Deep learning', '플라스틱 결함', '객체 감지', '욜로', '레이블링', '딥러닝']",국문 초록 정보 없음,"The rapid advancement of society due to industrialization, particularly through mass production enabled by automation, has led to the production of numerous products. However, it is difficult to ensure that all products are manufactured perfectly without defects. Therefore, identifying defects in products during the production process has become crucial. In modern society, detecting defects in various materials is highly valued. This paper focuses on detecting defects in plastic materials, which are among the most widely used and practical materials. In this study, we manually labeled the dataset, creating a dataset consisting of two classes. We utilized the YOLOv8 (You Only Look Once) model, which is capable of object detection, for training. To ensure fair evaluation, k-Fold Cross Validation was performed, resulting in an average F1 Score of 0.95, mAP50 of 0.97, and mAP50-95 of 0.68."
OpenCV Canny Edge 검출을 활용한 YOLO v8 위해물품 엑스레이 이미지 분류 성능 개선 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
Object detection 기반 산불 감지 모델의 비화재 이벤트 감지 성능 개선을 위한 연구,2024,"['Wildfire', 'Object detection', 'Deep learning', 'YOLO', 'Faster-RCNN']","산불화재는 생태계에 큰 피해를 초래할 뿐만 아니라, 인명 및 재산피해를 유발하게 된다. 이러한 산불화재를예방하기 위해 최근 실시간 영상 인식 분야에서 이슈가 되고있는 딥러닝 기반의 Object detection기술을 적용한산불화재 감지 성능 개선 연구가 수행되고 있다. 이러한 산불 화재 감지 선행연구는 화염 및 연기 이미지를실시간으로 정확하고 빠르게 감지하였고, 높은 성능의 화재감지 모델을 개발하였다. 하지만, 비화재 이벤트에대한 고려는 수행되지 않았으며, 이는 구름, 안개/연무, 굴뚝연기 등과 같은 화재 연기와 유사한 이미지에대한 분석은 미흡한 상황이다. 본 연구에서는 다양한 산불 이벤트(구름, 안개/연무, 굴뚝연기, 화재연기, 화염)에서의 산불 화재 감지 성능을 분석하기위해 Object detection 모델의 YOLO, Faster-RCNN 등의 모델 성능 비교분석 연구를 수행하였다. 모델 실험 결과, 2-Stage 모델에 해당하는 Faster-RCNN 모델은 정확성 측면에서 높은성능을 나타내었고, 1-Stage 모델에 해당하는 YOLO 계열 모델이 속도 측면에서는 높은 성능을 나타내었다.화재 이벤트별 모델 추론 결과, 모든 모델에서 객체형태가 상대적으로 크게 나타나는 구름, 안개/연무 객체는높은 정확도를 나타내었고, 굴뚝연기와 화재연기 이미지에서 오탐지가 발생하는 문제가 발생하였다. 하지만,추론속도에서 YOLO 계열 모델의 성능이 높게 나타났으며, 정확성 측면에서는 Faster-RCNN과 YOLO 성능차이가 미미하였다. 따라서, YOLO와 같이 빠른 추론속도를 나타내는 1-Stage 모델의 네트워크 구조, 하이퍼 파라미터 최적화 등의 연구를 통해 감지 정확도 개선하는 방향으로 나아가야 한다고 판단된다.",다국어 초록 정보 없음
YOLOv5를 이용한 치과용 3D프린터 출력물 불량 검출,2024,"['디지털 덴티스트리', '3D프린터', '치아모델', '불량검출', 'YOLOv5', 'Digital Dentistry', '3D Printer', 'Teeth Model', 'Defect Detection', 'YOLOv5']","본 연구는 현재 치과 산업의 기술 방식이 아날로그에서 디지털 방식으로 변함에 따라 디지털 덴티스트리 기술을 적용한 대표적 장비인 3D프린터의 잘못된 출력에 의한 불량품으로 인해 재료 및 시간 낭비와 폐기물 발생이 초래되는 실정을 개선할 수 있는 방안으로써 출력물 불량 검출에 대해 고찰하였다. 불량 검출 진행을 위해 객체 인식 알고리즘 중 메모리 사용량이 적고 학습 속도가 빠른 YOLO(You Only Look Once)을 선택하였고 준비된 데이터 셋에 대해 적합한 파라미터를 찾기 위해 학습모델 및 설정에 따른 성능 비교 테스트를 진행하였다. 테스트를 통해 구축한 최종 학습데이터를 통해 치아 모델 3종(구강 모델, 수술용 가이드 모델, 임시치아 모델)의 불량 검출 테스트를 진행하였고 그 결과 최대 80%의 수준으로 불량 검출이 되는 것을 확인하였다. 치아 모델의 불량 검출이 정상적으로 진행됨을 확인하였기 때문에 이는 YOLO를 통한 치과용 3D프린터의 불량 검출에 대한 유의미한 도구임을 확인하였으며, 향후 연구의 진행 방향으로는 성능의 편차를 줄이기 위한 연구 및 YOLO 버전별 성능 비교를 진행하고 도출된 데이터를 활용하여 최종적으로 3D프린터 내 카메라 설치를 통해 실시간으로 추적할 수 있는 고도화된 연구가 이루어져야 할 것이다.","As the current technology of the dental industry changes from analog to digital, this study considered the detection of dental 3D printer output defects as a way to improve the situation in which defects caused by the incorrect output of 3D printers, representative equipment applied with digital dentistry technology, cause waste of materials and time. For the progress of defect detection, You Only Look Once (YOLO) was selected among object recognition algorithms with low memory usage and high learning speed, and a performance comparison test was conducted according to the learning model and setting to find appropriate parameters for the prepared data set. The final learning data established through the test was used to conduct a defect detection test of three types of teeth models (oral, surgical guide, and temporary teeth models). As a result, it was confirmed that defect detection was performed at up to 80%. Since it was confirmed that the detection of defects in the dental model proceeds normally, it was confirmed that this is a significant tool for the detection of defects in dental 3D printers through YOLO. In the future research, research to reduce performance deviations and performance comparison by YOLO version should be conducted, and advanced research that can be tracked in real-time through camera installation in the 3D printer should be conducted using the derived data."
인공지능을 활용한 유해 객체 탐지 시스템,2024,"['Detection system', 'YOLO', 'Obejct detection', 'SlowFast', 'Artificial Intelligence']","본 논문에서는 2000년대 초반부터 증가하는 묻지마 범죄에 대응하기 위해 인공지능 기술을 활용한 실시간 영상 분석 시스템을 설계 및 구현하였다. 이 시스템은 특히 공공장소에서 발생할 수 있는 흉기 소지 및 폭력적 행위를 실시간으로 탐지하고, 이를 사용자에게 즉각적으로 알리는 기능을 통해 효과적인 대응을 가능하게 한다. 본 연구의 핵심 기술로는 두 가지 인공지능 모델인 SlowFast와 YOLO를 사용하였다. SlowFast 모델은 비디오 내의 미세한 움직임을 정밀하게 포착하여 폭력적인 행위를 감지하는데 특화되어 있으며, YOLO 모델은 빠른 속도로 영상 내의 흉기와 같은 위험 물체를 실시간으로 탐지하는데 사용된다. 이러한 기술의 결합을 통하여 본 시스템은 학교, 쇼핑몰, 공공장소 등 다중 이용 시설에서의 실제 적용 가능성을 실험하며 공공 안전을 강화하고 범죄 예방에 크게 기여할 수 있을 것으로 기대된다. 본 연구는 인공지능 기술의 발전이 어떻게 사회적 문제 해결에 기여할 수 있는지를 보여주며, 특히 실시간 범죄 대응 및 예방 분야에서의 활용 가능성을 높일 것으로 판단된다.","This paper presents the design and implementation of an Artificial Intelligence (AI)-based real-time video analysis system to address the increasing indiscriminate crimes that have been prevalent since the early 2000s. The system is specifically designed to detect the possession of weapons and violent behavior in public spaces in real time, and to immediately alert users, enabling effective responses. The core technologies used in this research are two AI models: SlowFast and YOLO. The SlowFast model is specialized in precisely capturing subtle movements within videos to detect violent actions, while the YOLO model is used to detect dangerous objects like weapons in videos rapidly. By combining these technologies, the system explores practical applications in public facilities such as schools, shopping malls, and other public spaces, enhancing public safety and significantly contributing to crime prevention. This research demonstrates how advancements in AI technology can contribute to solving social problems, particularly in the field of real-time crime response and prevention, and will be highly regarded for its potential applications."
방위산업보안을 위한 X-ray 영상과 딥러닝 기반 소형 저장장치 검출,2024,"['X선 영상', '딥러닝', 'Faster R-CNN', 'Xception', 'YOLO', 'X-ray image', 'deep learning', 'Faster R-CNN', 'Xception', 'YOLO']","방위산업을 포함한 주요 제조업(반도체, 디스플레이, 이차전지, 자동차 등)에서유출되는 저장장치를 보안요원이 탐지하는 데는 많은 시간과 훈련이 필요하다. 본 논문에서는 X-ray 영상과 딥러닝을 이용하여 소형 저장장치의 정확한 탐지를통해 방위 산업의 핵심 정보 유출을 방지하여 산업 안보에 기여하는 것을 목표로한다. 이를 위해 먼저, 공개된 저장장치 이미지 세트와 클라이언트의 샘플데이터를 사용하여 저장장치 탐지에 특화된 데이터셋을 구축하였다. 이어서, 저장장치 탐지에 적합한 모델을 찾기 위해 다양한 딥러닝 기반 객체 탐지 모델을조사하였으며, 그 결과 Faster R-CNN, Xception 및 YOLO를 이용하여 각각84.33%, 91.74%, 95.94%의 mAP(mean Average Precision)를 얻었다.","It takes a lot of time and training for security guards to detect storage devices exported from defense industries. In this paper, we aim to prevent the leakage of critical information with X-ray image and deep learning in defense industries and thus contribute to defense industrial security through accurate detection of storage devices. The first step is to build a data set specialized for small storage device detection using the open image set and sample data from the client. To find a suitable model for detecting storage devices, various deep learning-based object detection models were investigated. Finally, the obtained mAP of Faster R-CNN, Xception and YOLO were 84.33%, 91.84%, 95.94%, respectively."
실시간 대중교통 모니터링 시스템 구현,2024,"['Arduino', 'Public Transport', 'Real-time Monitoring System', 'Object detection', 'YOLO (You Only Look Once)', '아두이노', '대중교통', '실시간 모니터링 시스템', '객체 검출', 'YOLO(You Only Look Once']","본 논문에서는 실시간 대중교통 모니터링 시스템을 제안하였다. 제안한 연구는 대중교통 앱(App)을 제작하고, 광센서, 압력 센서, 객체검출 알고리즘을 활용하여 구현하였다. 또한, 버스 모형을 제작하여 동작을 검증하였다. 제안한실시간 대중교통 모니터링 시스템은 다음과 같이 3가지 특징을 가진다. 첫째, 광센서와 압력 센서의 값의 변화에 따라좌석의 착석 여부와 총 승객 인원을 파악하여 앱에서 대중교통 내부의 혼잡도를 확인할 수 있도록 구현하였다. 둘째, 다수의 승객이 동시에 승하차할 때 발생할 수 있는 광센서의 오차를 방지하기 위해, 객체검출 알고리즘인 YOLO를 활용하여 CCTV 승객 수 확인 가능성을 확인하였다. 셋째, 별도의 화면에서 탑승할 버스 내의 좌석이 착석된 경우를 색깔로 표시함으로써 편의를 제공한다. 승객의 현재 위치 확인, 현 위치에서 탑승 가능한 대중교통 및 도착 잔여 시간도확인 가능하다. 따라서 제안한 시스템은 대중교통 이용객들에게 보다 높은 편의성을 제공할 수 있을 것으로 기대한다","In this paper, a real-time public transportation monitoring system is proposed. The proposed system was implemented by developing a public transportation app and utilizing optical sensors, pressure sensors, and an object detection algorithm. Additionally, a bus model was created to verify the system's functionality. The proposed real-time public transportation monitoring system has three key features. First, the app can monitor congestion levels within public transportation by detecting seat occupancy and the total number of passengers based on changes in optical and pressure sensor readings. Second, to prevent errors in the optical sensor that can occur when multiple passengers board or disembark simultaneously, we explored the possibility of using the YOLO object detection algorithm to verify the number of passengers through CCTV footage. Third, convenience is enhanced by displaying occupied seats in different colors on a separate screen. The system also allows users to check their current location, available public transportation options, and remaining time until arrival.Therefore, the proposed system is expected to offer greater convenience to public transportation users."
스마트 축사내 상황인지 자율이동형 환경센서 개발 및 가축행동 분석에 관한 연구,2024,"['스마트 축사', '고유ID유지', '딥-소트', '행동패턴분석', 'Smart Barn', 'Unique ID Retention', 'Deep SORT', 'Behavior Pattern Analysis']","본 연구는 스마트 축사 내에서 자율주행 시스템을 활용하여 가축의 행동 패턴과 환경 데이터를 기반으로 소의 질병 유무를 예측하는 시스템을 개발하는 것을 목표로 한다. 외부 기기(RFID 태그 등) 없이 순수 카메라 영상만을 이용해 각 소의 고유 ID를 유지하는 것이 필수적이며, 이를 통해 소별로 시간대에 따른 서기, 앉기, 누워있기 등의 행동 패턴을 추적할 수 있다. 또한, 온도, 습도와 같은 환경 데이터를 통합하여 소의 건강 상태를 종합적으로 평가한다. 이를 위해 YOLO를 이용한 객체 탐지, Deep SORT를 이용한 추적, 그리고 ReID를 이용한 재식별 알고리즘을 결합한 고유 ID 유지 알고리즘을 제안하였다. 실험 결과, YOLO + Deep SORT + ReID 알고리즘이 고유 ID 유지 성능에서 가장 우수한 결과를 보였으며, LSTM 기반 행동 분석 모델이 행동 패턴 예측에서 높은 정확도를 나타내었다. 본 연구의 시스템은 축사 내부의 환경 데이터와 행동 패턴을 종합적으로 분석하여 가축의 질병이나 스트레스 상태를 실시간으로 예측할 수 있는 효과적인 도구로 활용될 수 있을 것이다.","This study aims to develop a system that predicts the health status of cattle based on behavior patterns and environmental data within a smart barn using an autonomous driving system. Maintaining a unique ID for each cow using only a camera, without external devices (such as RFID tags), is essential. This enables the tracking of behavior patterns such as standing, sitting, and lying for each cow over time. Additionally, environmental data such as temperature and humidity are integrated to comprehensively assess the cows' health conditions. To achieve this, we propose a unique ID retention algorithm that combines object detection using YOLO, tracking with Deep SORT, and re-identification (ReID). Experimental results show that the YOLO + Deep SORT + ReID algorithm delivers the best performance in maintaining unique IDs, and the LSTM-based behavior analysis model demonstrates high accuracy in predicting behavior patterns. This system can serve as an effective tool for real-time prediction of livestock health conditions, such as disease or stress, through comprehensive analysis of environmental data and behavior patterns inside the barn."
엣지 디바이스용 실시간 열화상 객체 검출을 위한 YOLOv5기반 경량화 방법론,2024,"['Deep Learning', 'Object Detection', 'Infrared Radiation', 'Attention', 'Edge Device', 'Lightweight']","딥러닝을 이용한 객체검출은 대부분 RGB 영상을 기반으로 이루어지고 있다. 하지만 RGB 영상은 야간이나 안개, 비, 눈 등 여러환경적인 조건에서는 객체를 검출하는데 정확도가 떨어지는 문제점이 있다. 반면에 IR (Infra Red) 영상은 열 정보만으로 처리하므로RGB 영상보다 해상도가 떨어지지만 환경적인 조건에 덜 민감하다. 딥러닝을 이용한 객체검출 모델은 다양하지만, 최근에는 정확도가높고 처리 속도가 빠른 YOLO가 많이 사용되고 있다. 그러나 YOLO는 RGB 영상에 맞춰 설계되어 있어 IR 영상에서 객체검출을 하기 위해서는 IR 영상에 맞춰 설계할 필요가 있다. 또한 많은 계산량이 요구되는 딥러닝 알고리즘을 엣지 디바이스에서 사용하기 위해서는 실시간 처리를 위한 경량화가 필요하다. 본 논문은 기존 YOLOv5 모델을 IR 영상에 맞게 수정하고 경량화하기 위해 기존의 3개레이어로 이루어진 헤드를 2개 레이어로 줄이고, 정확도 향상을 위해 CBAM (Convolution Block Attention Module)을 추가하였다.모의실험 결과, 본 논문에서 제안한 모델의 정확도는 95.5%, mAP50은 96.4%, 파라미터는 160만 개로 기존 모델 YOLOv5s와 비교해보면 정확도는 1.1% 떨어지지만, 파라미터는 4.375배 줄어들었다. 또한, 제안된 모델에 TensorRT 모델로 변환한 결과 mAP50은 1.6%감소하였지만 속도 측면에서 제안된 모델보다 25fps 높은 결과를 확인했다.","Most object detection models based on deep learning are primarily designed for RGB images. However, they suffer from pooraccuracy in various environmental conditions such as nighttime, fog, rain, and snow. On the other hand, IR (Infrared) images areprocessed with only thermal information, so the resolution is lower than RGB images, but they are less sensitive to environmentalconditions. While there are various object detection models using deep learning recently, YOLO, known for its high accuracy andfast processing speed, has been widely adopted. However, since YOLO is designed based on RGB images, it needs to be adaptedfor IR images to perform object detection effectively. In addition, in order to use deep learning algorithms that require a largeamount of computation in edge devices, it is necessary to reduce weight for real-time processing. In this paper, in order to modifyand reduce the weight of the existing YOLOv5 model to fit the IR image, the existing three-layer head was reduced to two layers,and CBAM was added to improve accuracy. In experimental results,, the precision of the model proposed in this paper was95.5%, mAP50 was 96.4%, and the parameters were 1.6M. Compared to the existing model YOLOv5s, the precision decreased by2.4%, but the parameters decreased by 4.375 times. In addition, as a result of converting the proposed model to the TensorRTmodel, mAP50 decreased by 1.6%, but in terms of speed, the result was 25fps higher than the proposed model."
저조도 환경에서 물체 인식 성능 향상을 위한 조명 위치 설계,2024,"['Light position', 'YOLO', 'Low illumination', 'Object detection']","본 논문에서는 저조도 환경에서 물체 인식 성능 향상을 위해 조명 위치의 실험적 분석 연구를 수행하였다. 저조도 환경에서 인식 성능을 높이기 위해 흔히 잡음을 추가하거나 저조도 환경을 포함하여 학습을 수행한다. 하지만, 인식 성능의 개선을 위해 조명이 필요하며 동시에 적절한 위치가 설계되어야 한다. 본 논문에서는 카메라와 조명의 다양한 위치 관계에 따른 YOLO의 인식 성능을 분석하였다. 이를 토대로 평균적인 신뢰도가 가장 높은 조명 위치를 제시하였다. 향후, 저조도 환경에서 로봇 기반 자동차 번호판 인식을 위해 제시한 실험분석 결과를 활용할 예정이다.","In this study, we conducted an experimental analysis on the proper positioning of the light to enhance object detection performance in low-light environments. Typically, to improve object detection performance in such conditions, noise is considered or the system is trained by including low-light environments. However, the light is essential for improving detection accuracy, and its proper positioning must be carefully designed. This study analyzed the performance of YOLO object detection according to various relative positions of the camera and lighting. Based on this analysis, we identified the light position that consistently provided the highest average confidence. Future work will utilize these experimental results to implement robot-based automatic license plate recognition in low-light conditions."
시각장애인 친화적 충돌 회피 시스템 개발,2024,"['object dection', 'visually impairment', 'YOLO', 'deep learning']","시각장애인들이 일상생활에서 어플리케이션을 통해 이동의 불편함을 줄이고 일상생활을 도와주고자 충돌회피 시스템을 개발하게 되었다. 우리는 Roboflow의 데이터셋 생성 툴을 이용하여 경기대학교의 강의실 내부를 탐지하기 적합한 데이터셋을 구성하였으며, 이 데이터셋을 Yolo에 학습시켜 책상, 의자 그리고 사람 총 세개의 클래스를 탐지하는 mAP 0.91의 객체 탐지 모델 ClassVision AI를 만들었다. 우리는 핸드폰 카메라와 연동하여 사용자 앞의 객체를 탐지하고, TTS 음성를 이용하여 사용자에게 소리를 통해 객체의 유무를 알려줄 수 있도록 어플리케이션을 구현하였다. 이를 통해 사용자는 교내에서 안전하게 생활할 수 있으며, 시각장애인 학생이 선택할 수 있는 하나의 도구를 만듦으로서 삶의 향상을 도울 수 있게 되었다.","We developed a collision avoidance system to reduce the inconvenience of mobility and assist daily life for visually impaired individuals through an application. Using Roboflows dataset creation tool, we constructed a suitable dataset for detecting the interior of Kyunggi Universitys classrooms. We trained this dataset with YOLO to create ClassVision AI, an object detection model with an mAP of 0.91, capable of detecting three classes: desks, chairs, and people. We implemented an application that integrates with a smartphone camera to detect objects in front of the user and uses TTS (Text-to-Speech) to audibly notify the user of the presence of objects. This allows users to safely navigate campus and provides a tool for visually impaired students to enhance their daily lives."
딥러닝 기반 콘크리트 균열 검출 기술에 관한 연구,2024,"['균열 탐지', '인공지능', '균열', '성능지표', 'Crack detection', 'artificial intelligence', 'YOLO', 'crack', 'Performance Indicators']",국문 초록 정보 없음,"When buildings deteriorate, they may develop defects like surface cracks and structural subsidence. If left unaddressed, these issues can significantly weaken the structure, potentially leading to collapse accidents. Detecting cracks promptly is crucial to prevent such outcomes. With the advancements in artificial intelligence, researchers are exploring deep learning techniques to identify microscopic cracks, replacing traditional manual methods. As AI technology progresses, diverse AI models have emerged, enhancing the reliability of crack detection data for field inspections. This study focuses on leveraging the Yolo model, known for its superior performance and faster data acquisition compared to other AI models. By incorporating object detection methods used by CNN, the study aims to enhance the detection performance of the model by considering various variables across different AI models and detection techniques."
YOLOv8 마커 학습을 이용한 우주 환경에서의 강인한 검출,2024,"['On-Orbit Servicing(OOS', '궤도상서비싱)', 'You Look Only Once(YOLO)', 'ArUco Marker', 'Marker Occlusion']","본 논문에서는 위성 간 근접 운용을 위한 환경을 ROS-Gazebo 시뮬레이션 환경에 구현하고, ArUco 마커를 국제우주정거장(International Space Station, ISS)에 부착하여 단안 카메라를 이용한 마커 검출 시뮬레이션을 수행한다. ArUco 마커의 경우 조도와 형태 변형에 민감하므로, 우주쓰레기로 인해 마커가 가려지면서 외곽선 소실 또는 마커 정보 소실이 일어나는 경우 검출이 불가능하다는 단점이 존재한다. 이를 보완하기 위해서 ISS 모델 정보와 마커 정보가 주어지는 협력적인 상황에서 YOLOv8을 이용해 국제우주정거장과 ArUco 마커를 학습하고, 거리가 가까워짐에 따라 ISS, 마커로 이어지는 연속적인 검출 구조를 구성하였다. 그다음, 거리에 따라 YOLO와 전통적인 마커 검출 방법을 이용했을 때의 인식 여부를 조사하였다. 그 결과, ISS와 마커의 검출이 연속적으로 일어남을 확인했고, 온전한 마커의 경우 전통적인 마커 검출 방법을 이용했을 때 YOLOv8을 이용한 검출 방법보다 비교적 먼 거리에서 검출됨을 확인하였다. 하지만, 우주쓰레기로 마커가 가려지거나 광원이 제한적인 조건에서는 YOLOv8이 온전한 마커의 경우와 유사한 검출률을 보여주었고, 전통적인 마커 검출 방법을 이용하는 경우 마커 검출이 어려움을 확인하였다.","In this paper, an environment for satellite proximity operations is implemented in the ROS-Gazebo simulation environment, and ArUco markers are attached to the International Space Station(ISS) to perform marker detection simulations using monocular cameras. ArUco markers are sensitive to lighting conditions and shape deformations, so if the markers are occluded by space debris, the detection may become impossible due to the loss of outline or marker information. To address this limitation, we employed YOLOv8 in a collaborative setup where ISS model information and marker data are available. YOLOv8 is used to train on the International Space Station and ArUco markers, creating a continuous detection structure that transitions from ISS to markers as proximity decreases. and the detection performance is investigated based on distance when using YOLO and traditional marker detection methods. As a result, continuous detection of both the ISS and markers was confirmed. and it was observed that intact markers were detected at relatively longer distances when using traditional marker detection methods compared to the detection method using YOLOv8. However, when markers are occluded by space debris or under limited lighting conditions, YOLOv8 demonstrates similar detection rates to intact markers, while traditional marker detection methods struggle to detect markers."
차량행태 기반 안전시설 안전성 평가 : 무인 교통단속용 장비와 과속방지턱을 중심으로,2024,"['도로안전시설', '교통안전시설', '단속장비', '대리안전지표(SSM)', '드론 영상 분석', 'Road Safety Facilities', 'Traffic Safety Facilities', 'Enforcement Equipment', 'Surrogate Safety Measure (SSM)', 'Drone Video Analysis']","본 연구는 도로 및 교통안전시설, 무인 교통단속용 장비와 과속방지턱이 차량 주행 행태와 도로 안전성에 미치는 영향을 정량적으로 평가하기 위해 수행되었다. 드론 영상과 YOLO v8 알고리즘을 활용하여 차량의 주행 데이터를 수집하고, SSM(Surrogate Safety Measure) 지표를 적용하여 안전시설 설치 유무에 따른 주행 안정성을 분석하였다. 분석 결과, 단속장비 설치 구 간에서 차량 속도가 낮아지고 일정한 주행 패턴과 안정적인 차간거리가 유지되며 주행 안정성 에 긍정적인 영향을 미치는 것으로 나타났다. 반면, 단속장비가 없는 구간에서는 과속 차량 비 율이 높고 주행 속도의 변동성이 커 교통 안전성이 상대적으로 낮아질 가능성을 보였다. 또한 다양한 대리안전지표를 활용하여 단속장비가 설치된 구간의 주행 안전성을 다각도로 평가하 였다. 실제 주행 환경에서 수집된 데이터를 기반으로 객관적인 안전성 분석을 수행한 결과, 단 속장비가 도로 안전성 향상에 기여할 수 있음을 확인하였다. 향후 도로 및 교통안전시설의 설 치 효과를 입증하는 기초 자료로 활용될 수 있으며, 도로 및 교통안전시설의 안전성 평가와 개선 방안을 수립하는 데 중요한 근거가 될 것이다.","This study evaluates the impact of road and traffic safety facilities, specifically unmanned enforcement equipment and speed bumps, on vehicle behavior and road safety. Using drone footage and the YOLO v8 algorithm, driving data were collected and SSM (Surrogate Safety Measure) indicators were applied to assess stability with and without safety facilities. Results show that sections with enforcement equipment exhibit lower speeds, consistent driving patterns, and stable headway distances, positively impacting stability. In contrast, sections without enforcement equipment showed higher speeding rates and speed variability, suggesting lower safety levels. This analysis confirms that enforcement equipment can improve road safety and provides foundational data for future safety evaluations and improvement strategies."
고품질 및 객체 인식 향상을 위한 GAN 기반 이미지 처리 기법,2024,"['GAN', 'Medical Image Processing', 'Super-Resolution', 'Object Recognition', 'YOLO', 'Training Stability']",국문 초록 정보 없음,"This paper presents a study on utilizing Generative Adversarial Networks (GANs) to enhance medi cal image processing and object recognition. The proposed methods focus on generating high-quality medical images through super-resolution and improving object detection and classification by integrat ing GAN with YOLO. Additionally, to address challenges in GAN training, such as mode collapse and overfitting, optimization techniques like Spectral Normalization and Gradient Penalty are applied to en sure training stability. By integrating these techniques into the “openEMR” system, the paper demon strates the practical applicability of GANs in medical image analysis, contributing to the development of more efficient and accurate solutions within EMR systems."
생성형 AI 기반 이미지 데이터 증강을 활용한 멜론 과실 탐지 및 품질 평가,2024,"['Data augmentation', 'Deep learning', 'Fruit detection', 'Fruit quality', 'Generative AI', 'Image-to-image generation', 'Prompt engineering', 'Text-to-image generation', '과실 품질', '과실 탐지', '데이터 증강', '딥러닝', '생성형 인공지능', '이미지 기반 이미지 생성', '프롬프트 엔지니어링', '텍스트 기반 이미지 생성']","현대 농업은 생산성 및 품질 향상과 환경 영향 최소화라는복합적인 도전에 직면해 있으며, 과실의 성장 및 품질을 모니터링하고 관리하는 것은 매우 중요한 과제이다. YOLO와 같은 실시간 과실 탐지를 위한 딥러닝 모델을 효과적으로 훈련시키기 위해서는 고품질 이미지 데이터셋이 필수적이나, 농업 분야에서는 이러한 데이터셋이 부족한 실정이다. 생성형AI 모델은 고품질 이미지를 생성하여 이러한 문제를 해결할수 있다. 본 연구에서는 미드저니와 파이어플라이 도구를 사용하여 텍스트-이미지, 이미지(수확 전)-이미지, 및 이미지(수확 후)-이미지 생성 방법으로 멜론 재배 온실과 수확 후 과실 이미지를 생성하였다. 생성된 이미지는 PSNR 및 SSIM 등의 지표로 평가되었으며, YOLOv9 모델의 탐지 성능(IoU = 0.95)도 평가되었다. 또한 네트 품질 평가 방법을 이용하여 실제 과실과 생성된 과실의 네트 품질을 평가하였다. 생성형 AI 는 원본 이미지와 유사한 이미지를 생성하였으며, 수확 후 이미지를 통한 과실 이미지 생성의 경우 매우 뛰어난 사실성을표현하였다. 생성 이미지는 실제 이미지와 동일하게 YOLOv9 모델에 의해 탐지되었으며, 네트 품질도 평가될 수 있었다. 이는 생성형 AI가 실제적이고 효과적인 과실 탐지 및 품질 평가를 위해 현실적인 이미지를 생성할 수 있음을 보여주며, 농업분야에서의 큰 잠재력을 나타낸다. 본 연구는 멜론 과실 탐지및 품질 평가를 위한 데이터 증강에 있어서 AI 생성 이미지의잠재력을 모색하며, 생성형 AI의 농업에 대한 적용을 긍정적으로 전망한다.","Monitoring and managing the growth and quality of fruits are very important tasks. To train deep learning models like YOLO for real-time fruit detection effectively, high-quality image datasets are essential. However, such datasets are often lacking in agriculture. Generative AI models can help by creating high-quality images. In this study, we used MidJourney and Firefly tools to generate images of melon greenhouses and post-harvest fruits through text-to-image, pre-harvest image-to-image, and post-harvest image-to-image methods. We evaluated these AI-generated images using PSNR and SSIM metrics and tested the YOLOv9 model’s detection performance. We also assessed the net quality of real and generated fruits. Our results showed that generative AI could produce images very similar to real ones, especially for post-harvest fruits. The YOLOv9 model detected the generated images well, and the net quality was also measurable. This shows that generative AI can create realistic images useful for fruit detection and quality assessment, indicating its great potential in agriculture. This study highlights the potential of AI-generated images for data augmentation in melon fruit detection and quality assessment and envisions a positive future for generative AI applications in agriculture."
완전 무인 매장의 AI 보안 취약점: 객체 검출 모델에 대한 Adversarial Patch 공격 및 Data Augmentation의 방어 효과성 분석,2024,"['Fully Unmanned Stores', 'Security Vulnerabilities', 'Adversarial Patch', 'Data Augmentation']","코로나19 팬데믹으로 인해 비대면 거래가 보편화되면서, 완전 무인 매장의 증가 추세가 두드러지고 있다. 이러한 매장에서는 모든 운영 과정이 자동화되어 있으며, 주로 인공지능 기술이 적용된다. 그러나 이러한 인공지능 기술에는 여러 보안 취약점이 존재하고, 이러한 취약점들은 완전 무인 매장 환경에서 치명적으로 작용할 수 있다. 본 논문은 인공지능 기반의 완전 무인 매장이 직면할 수 있는 보안 취약점을 분석하고, 특히 객체 검출 모델인 YOLO에 초점을 맞추어, 적대적 패치를 활용한 Hiding Attack과 Altering Attack이 가능함을 보인다. 이러한 공격으로 인해, 적대적 패치를 부착한 객체는 검출 모델에 의해 인식되지 않거나 다른 객체로 잘못 인식될 수 있다는 것을 확인한다. 또한, 보안 위협을 완화하기 위해 Data Augmentation 기법이 적대적 패치 공격에 어떠한 방어 효과를 주는지 분석한다. 우리는 이러한 결과를 토대로 완전 무인 매장에서 사용되는 인공지능 기술에 내재된 보안 위협에 대응하기 위한 적극적인 방어 연구의 필요성을 강조한다.","The COVID-19 pandemic has led to the widespread adoption of contactless transactions, resulting in a noticeable increase in the trend towards fully unmanned stores. In such stores, all operational processes are automated, primarily using artificial intelligence (AI) technology. However, this AI technology has several security vulnerabilities, which can be critical in the environment of fully unmanned stores. This paper analyzes the security vulnerabilities that AI-based fully unmanned stores may face, focusing particularly on the object detection model YOLO, demonstrating that Hiding Attacks and Altering Attacks using adversarial patches are possible. It is confirmed that objects with adversarial patches attached may not be recognized by the detection model or may be incorrectly recognized as other objects. Furthermore, the paper analyzes how Data Augmentation techniques can mitigate security threats by providing a defensive effect against adversarial patch attacks. Based on these results, we emphasize the need for proactive research into defensive measures to address the inherent security threats in AI technology used in fully unmanned stores."
이미지와 텍스트 정보를 활용한 인공지능 기반 산불 탐지 방법,2024,"['Artificial Intelligence', 'Classifiation', 'Contrastive Language–Image Pre-training', 'Forest', 'Wildfire Detection', 'You Only Look Once']","전 지구적인 기후변화는 장기간에 걸친 온도 상승, 강우량의 변화 등으로 전 세계적으로 자연재해가 증가하고있다. 그 중 산불의 발생은 점차 대형화되고 있는 추세이다. 대한민국은 10년(2013~2022년)동안 평균 537건의 산불이발생하여 3,560ha의 산림이 소실되었으며, 이것은 매년 1,180개의 축구장 면적(약 3ha)의 산림이 타고 있는 것이다.본 논문은 이미지와 텍스트 정보를 활용한 인공지능 기반 산불 탐지 방법을 제안한다. 제안 방법은 YOLOv9-C, RT-DETR-Res50, RT-DETR-L, YOLO-World-S 방법과 mAP50, mAP75, FPS에 대해 성능을 비교하였으며, 타 방법보다 높은 성능을 가진 것을 확인하였다. 제안 방법은 강원특별자치도에 산불조기감지 시스템의 산불탐지 모델로 실증하였으며, 추후 산림지역 뿐만 아니라 도시지역도 포함할 수 있는 화재탐지 방향으로 고도화할 계획이다.","Global climate change is causing an increase in natural disasters around the world due to long-term temperature increases and changes in rainfall. Among them, forest fires are becoming increasingly large. South Korea experienced an average of 537 forest fires over a 10-year period (2013-2022), burning 3,560 hectares of forest. That's 1,180 soccer fields(approximately 3 hectares) of forest burning every year. This paper proposed an artificial intelligence based wildfire detection method using image and text information. The performance of the proposed method was compared with YOLOv9-C, RT-DETR-Res50, RT-DETR-L, and YOLO-World-S methods for mAP50, mAP75, and FPS, and it was confirmed that the proposed method has higher performance than other methods. The proposed method was demonstrated as a forest fire detection model of the early forest fire detection system in the Gangwon State, and it is planned to be advanced in the direction of fire detection that can include not only forest areas but also urban areas in the future."
영상분석 기법을 활용한 공유형 PM(Personal Mobility) 주차상태 검지 시스템 개발,2024,"['Shared PM', 'PM Illegal Parking', 'PM Detection', 'PM Pose Detection', 'Smart City']","최근 PM 사용의 급증으로 인해 불법 주정차가 차량 통행을 방해하고 보행자 안전을 위협하는 문제가 부각되고 있으며, 이를 효과적으로 관리하기 위한 기술적 해결책이 필요한 상황이다. 본 연구는 공유형 개인 이동 수단(Personal Mobility, PM)의 방치와 불법 주정차 문제를 해결하기 위해 딥러닝 기반의 검지 시스템을 개발하였다. CCTV 영상을 활용하여 실시간으로 불법 주정차된 PM을 자동으로 검지할 수 있는 시스템을 구축하였으며, 이를 위해 다양한 PM 데이터를 수집하고 YOLO-v5 모델을 활용하여 PM의 주차 상태(세워짐, 넘어짐 등)를 분류하였다. 실험 결과, 개발 시스템은 높은 정밀도와 재현율을 통해 모든 주차 상태에서 안정적인 검지 성능을 입증하였다. 또한, 기존 수작업 중심의 단속 방식에 비해 단속 효율성을 크게 향상시켜, 관리 인력의 부담을 줄이고 보다 신속한 대응이 가능하도록 설계되었다. 본 기술은 CCTV를 기반으로 불법 주정차를 사전에 감지함으로써 교통 흐름을 개선하고 보행자 안전을 강화하여, 도시 관리 효율성 증진뿐만 아니라 공공 안전 향상에 기여할 수 있을 것으로 기대한다.","The recent surge in the use of personal mobility (PM) devices has highlighted issues related to illegal parking, which disrupts vehicle traffic and poses risks to pedestrian safety. Effective technological solutions are required to address these challenges. This study aimed to resolve the issues of abandoned and illegally parked shared PM devices by developing a deep learning-based detection system. The proposed system used closed-circuit television (CCTV) footage to automatically detect illegally parked PMs in real time. This was achieved by collecting a diverse dataset of PMs and using the YOLO-v5 model to classify the parking status of PMs (e.g., upright, fallen). The experimental results showed that the proposed system achieved stable detection performance with high precision and recall across various parking conditions. Furthermore, compared to traditional manual enforcement methods, the system significantly improved enforcement efficiency, reducing the burden on management personnel and enabling faster responses. The technology is expected to help improve public safety and enhance urban management efficiency by detecting illegal parking in advance based on CCTV, improving traffic flow, and strengthening pedestrian safety."
주행 안전성 평가를 위한 블랙박스 영상 인식 적용 기법 연구,2024,"['블랙박스', '영상인식 알고리즘', '후미추돌사고', 'TTC', '교통안전', 'black box', 'image recognition algorithm', 'rear-end crash', 'time to collision', 'traffic safety']","교통 안전성 평가는 교통사고 자료, 내비게이션 및 운행기록장치, 시뮬레이션 등을 주로 사용하고 있으나, 사고 발생 직전의 상황을 규명하는 데에는 한계가 있다. 블랙박스 영상의 경우 사고 발생 직전의 상황을 가장 잘 설명할 수 있는 데이터를 얻을 수 있으며, 차량 소유주의 동의를 얻으면 사고 영상을 쉽게 취득할 수 있고, 보급률이 100%에 달해 샘플 데이터 구득이 용이하다는 장점이 있다(Han and Yang, 2007). 본 연구는 블랙박스 영상에서 관련된 데이터를 추출하고, 후미추돌 교통사고 상황에서의 차량 행태를 분석하여 교통안전성을 평가하는 방법론을 제시하고자 한다. 이를 위해 후미추돌 교통사고의 블랙박스 영상 분석을 위하여 OpenCV의 YOLO5에 기반한 영상인식 알고리즘을 개발하여 블랙박스 영상에서의 객체 인식을 수행한다. 그리고 선행 및 후행 차량 속도를 예측하고 차간 거리를 추정하는 알고리즘을 개발한다. 실도로 주행실험을 통해 개발된 알고리즘의 학습 및 보정을 진행하였으며 고속도로 본선에서 발생한 12건의 후미추돌사고에 대해 각각의 속도 및 TTC를 추출하였다. 12건의 사고를 속도를 기준으로 3가지 그룹으로 나누어 각 그룹별 특성을 분석하였다. 본 연구는 블랙박스 영상을 통한 후미추돌사고 발생 직전의 차량 행태 분석을 위한 알고리즘을 개발하였으며, 추후 카메라를 이용한 영상분석에 기반한 안전성 분석 및 자율주행차량의 사고 회피 및 대응을 위한 기초자료를 구축할 때 활용될 수 있다. 또한, 알고리즘 및 평가지표의 고도화를 통하여 실 도로 상황에서의 교통안전성 증진을 위한 전략 수립에 기여할 수 있을 것으로 기대된다.","To evaluate traffic safety, traffic accident data, navigation systems, driving recorders, and simulations are commonly used. However, these methods have limitations in identifying situations immediately before accidents occur. In contrast, black box camera footage can be obtained with the vehicle owner's consent and, with a 100% penetration rate, allows for comprehensive analysis of all vehicles. This study aims to analyze vehicle behavior in rear-end collision situations based on black box camera footage and to establish foundational data for future collision avoidance and response strategies for autonomous vehicles. To analyze rear-end collision black box camera footage, an image recognition algorithm based on OpenCV's YOLO5 is developed to perform object recognition in the footage. Additionally, algorithms are developed to predict the speed of preceding and following vehicles and to estimate the inter-vehicle distance. Real road driving experiments were conducted to train and calibrate the developed algorithms. Speeds and Time-to-Collision were extracted from 12 rear-end collision cases that occurred on highways. These 12 accidents were categorized into three groups based on speed, and the characteristics of each group were analyzed. Through this study, an algorithm was developed to analyze vehicle behavior immediately before rear-end collisions using black box camera footage. The further refinement of this algorithm and evaluation metrics is expected to advance video-based traffic accident analysis and contribute to the development of strategies for improving traffic safety in real road conditions."
광학 이미지 전처리를 통한 국방 저조도 환경에서의 객체탐지 연구,2024,"['Low-light Defense Environment', 'Histogram Equalization', 'Image Improvement', 'Object Detection', 'Computer Vision.']","우리 군은 과학기술 강군 육성의 기조 아래 병력 감축을 보완하고 감시 태세를 유지하기 위해 최전방 일반전초에 과학화 경계시스템을 운용하고 있다. 하지만, 기존 도입된 시스템은 영상감시 병력이 다수의 감시카메라를 동시에 관리하므로 피로도가 높으며 오탐지 및 탐지 누락의 문제가 발생할 수 있기 때문에 인공지능을 확대 적용한 지능화 된 감시시스템은 기술적·인적 제한요소를 극복하기 위해 필수적이다. 또한 인공지능 객체탐지는 저조도 환경에서 성능이 저하되며, 특히 전방 경계작전 환경과 같은 미약한 광원 조건에서 객체 왜곡과 노이즈가 발생할 경우 문제는 더욱 가중된다. 이에 따라 인공지능 감시시스템에서 저조도 이미지를 전처리하여 탐지 확률을 향상시키는 것은 중요하다. 본 논문에서는 군 경계작전 환경에서의 저조도 광학 이미지에 대한 전처리로 객체 탐지 성능의 유의미한 향상 여부를 연구하고자 한다. 군 경계작전 환경과 유사한 조건으로 철책선 및 숲 배경의 인물과 동물 이미지를 수집하였고 전처리를 위해 명암대비 조정 기법인 히스토그램 평활화를 적용하여 데이터셋을 구성하였다. 데이터셋은 원본 이미지와 전처리 이미지로 나누어 YOLO 모델에 학습을 진행하였으며 각 그룹별 학습된 모델의 객체 탐지 성능을 평가하였다. 결과적으로 전처리 이미지의 mAP50는 0.890으로 원본 이미지의 mAP50인 0.884보다 향상되었음을 확인하였다. 본 연구의 결과는 향후 저조도 환경에서 광학 이미지 전처리를 통해 객체 탐지를 향상시키고, 일반전초와 같은 군 경계작전 환경에서 감시시스템의 분석 및 개발에 활용될 것으로 기대된다.","Armies operate automated surveillance systems at frontline outposts to maintain readiness and to compensate for troop reductions, aligned with a policy to enhance military capabilities through technology. Managing multiple surveillance cameras can lead to operator fatigue and errors, necessitating the integration of AI to overcome both technological and human limitations, particularly in low-light conditions where AI object detection performance is often impaired. This paper explores the advantages of preprocessing low-light optical images to improve AI object detection in military settings. Images of humans and animals set against military backgrounds are collected and preprocessed using histogram equalization. These images are categorized into original and preprocessed groups and analyzed using YOLO. Analysis indicates that preprocessed images achieved a mean average precision (mAP) of 0.890, exceeding the original mAP of 0.884. This suggests that image preprocessing significantly enhances object detection capabilities in low-light conditions, which could benefit development and refinement of military surveillance systems."
드론 기반 딥러닝을 활용한 교차로 교통 데이터 분석,2024,"['드론', '딥러닝', '교통 데이터', '경로 인식률', '차종 인식률', 'Drone', 'Deep Learning', 'Traffic Data', 'Path Recognition Rate', 'Vehicle Type Recognition Rate']",국문 초록 정보 없음,다국어 초록 정보 없음
AI 가속기를 적용한 맨홀 균열 탐지 임베디드 시스템 개발,2024,[],"맨홀의 사고가 급증함에 따라 예방책이 필요하지만, 국내에는 아직 체계적인 맨홀 시스템이 존재하지 않는다. 본 논문에서는 이러한 문제를 해결하기 위해 FPGA와 Yolov5를 통해 맨홀 관리 시스템을 구축하는 방법을 제안한다. 제안된 시스템을 구현하기 위해서는 Kria KV260보드에 양자화된 yolo모델을 배포하여 캠을 통해 맨홀의 균열을 탐지한다. 모델을 양자화하고 FPGA에 배포하여 라즈베리 파이에서의 성능보다 약 44배 향상된 성능을 보였고, 정확도는 85%의 정확도를 보임을 확인하였다. 제안된 방법은 효율적인 맨홀 관리 시스템을 구축하고 각종 사고를 예방하는데 활용될 수 있을 것으로 기대된다.",다국어 초록 정보 없음
변형 및 표면 얼룩에 강인한 RGB 이미지 기반 6차원 위치추정 모델 학습을 위한 가상 이미지 합성 모델,2024,"['data synthesis', 'keypoint detection', '6D pose estimation', 'object detection', 'RGB images']",국문 초록 정보 없음,"The problem of 6D pose estimation from RGB images is actively researched in various industries. However, the application of the techniques is challenging in real industrial environments due to various non-uniform factors. In this study, a method for generating virtual data based on image synthesis is purposed to build a keypoint dataset for training robust 6D pose estimation model in real industrial field. Additionally, the performance of the keypoint extraction model trained using the generated virtual data is validated by using yolo-v8 pose model."
객체 탐지 딥러닝 기법을 활용한 필지별 조사 방안 연구,2024,"['YOLO', '법정지목', '토지이용현황', '시설물', '농경지', 'YOLO', 'land category', 'Land use', 'Facility', 'Agricultural land']","본 연구에서는 드론영상을 기반으로 YOLO 알고리즘을 통해 시설물과 농경지를 대상으로 객체탐지를 실시하고, 이를 법정지목과 비교를 수행하여 영상기반의 조사 가능성을 검토하였다. YOLO 알고리즘을 통해 객체를 탐지한 결과 건축물의 경우에는 기존 수치지형도에서 제공하고 있는 건축물 중 96.3%에 해당하는 객체를 탐지하는 것으로 분석되었다. 또한 수치지형도에서는 건축물이 위치하지 않지만, 영상에서 건축물이 존재하는 136개의 건축물을 추가로 탐지하는 것으로 나타나 정확도가 높은 것으로 나타났다. 비닐하우스의 경우에는 총 297개를 탐지했으나, 일부 과수형 비닐하우스의 경우에 탐지율이 낮은 것으로 분석되었다. 마지막으로 농경지는 가장 낮은 탐지율을 보였다. 농경지는 시설물 대비 넓은 면적과 불규칙한 형상으로 학습데이터의 일관성이 낮아 정확도가 시설물에 비해 작은 것으로 판단된다. 따라서 농경지의 경우에는 박스형태의 탐지가 아닌 Segmentation 탐지가 더욱 효과적으로 활용될 것으로 보인다. 마지막으로 탐지된 객체를 법정지목과 비교를 수행하였다. 그 결과 건축물이 입지가 어려운 농경지 및 임야에서 건축물이 존재하는 것으로 분석되었다. 그러나 이 건축물이 불법으로 활용됨을 파악하기 위해선 행정정보와 연계가 필요할 것으로 보여진다. 따라서 현재 수준에서는 건축물이 입지하기 어려운 필지에 건축물의 존재유무를 객관적으로 판단할 수 있는 수준까지 조사가 가능한 것으로 볼 수 있다.","This study examined the feasibility of image-based surveys by detecting objects in facilities and agricultural land using the YOLO algorithm based on drone images and comparing them with the land category by law. As a result of detecting objects through the YOLO algorithm, buildings showed a performance of detecting objects corresponding to 96.3% of the buildings provided in the existing digital map. In addition, the YOLO algorithm developed in this study detected 136 additional buildings that were not located in the digital map. Plastic greenhouses detected a total of 297 objects, but the detection rate was low for some plastic greenhouses for fruit trees. Also, agricultural land had the lowest detection rate. This result is because agricultural land has a larger area and irregular shape than buildings, so the accuracy is lower than buildings due to the inconsistency of training data. Therefore, segmentation detection, rather than box-shaped detection, is likely to be more effective for agricultural fields. Comparing the detected objects with the land category by law, it was analyzed that some buildings exist in agricultural and forest areas where it is difficult to locate buildings. It seems that it is necessary to link with administrative information to understand that these buildings are used illegally. Therefore, at the current level, it is possible to objectively determine the existence of buildings in fields where it is difficult to locate buildings."
A Comparative Study of Deep Learning Techniques for Alzheimer's disease Detection in Medical Radiography,2024,"['Convolutional neural network (CNN)', ""Alzheimer's disease"", 'MRI dataset', 'YOLO', 'VGG16']",국문 초록 정보 없음,"Alzheimer's disease is a brain disorder that worsens over time and affects millions of people around the world. It leads to a gradual deterioration in memory, thinking ability, and behavioral and social skills until the person loses his ability to adapt to society. Technological progress in medical imaging and the use of artificial intelligence, has provided the possibility of detecting Alzheimer's disease through medical images such as magnetic resonance imaging (MRI). However, Deep learning algorithms, especially convolutional neural networks (CNNs), have shown great success in analyzing medical images for disease diagnosis and classification. Where CNNs can recognize patterns and objects from images, which makes them ideally suited for this study. In this paper, we proposed to compare the performances of Alzheimer's disease detection by using two deep learning methods: You Only Look Once (YOLO), a CNN-enabled object recognition algorithm, and Visual Geometry Group (VGG16) which is a type of deep convolutional neural network primarily used for image classification. We will compare our results using these modern models Instead of using CNN only like the previous research. In addition, the results showed different levels of accuracy for the various versions of YOLO and the VGG16 model. YOLO v5 reached 56.4% accuracy at 50 epochs and 61.5% accuracy at 100 epochs. YOLO v8, which is for classification, reached 84% accuracy overall at 100 epochs. YOLO v9, which is for object detection overall accuracy of 84.6%. The VGG16 model reached 99% accuracy for training after 25 epochs but only 78% accuracy for testing. Hence, the best model overall is YOLO v9, with the highest overall accuracy of 86.1%."
일반 CCTV 시스템에 적합한 지능형 이상행동 탐지 관리 솔루션 설계 및 구현,2024,"['YOLO', 'SlowFast', '지능형 CCTV', '보안', 'You Look Only Once(YOLO)', 'SlowFast', 'Intelligent CCTV', 'Security']","기존의 일반 CCTV 시스템은 단순한 영상 녹화 기능만 제공하는 데에 비해, 지능형 CCTV는 실시간 탐지 및 분석, 자동 경고 등의 강화된 기능을 포함한다. 최근 국내에서는 기존 CCTV 시스템이 현대의 보안 요구를 충족시키지 못하는 한계로 인해 대대적인 지능형 이상행동 탐지 시스템 도입의 중요성이 대두되고 있다. 본 논문은 일반 CCTV에 지능형 이상행동 탐지 AI 시스템을 구축 및 탑재함으로써, 추가적인 설치 또는 교체 없이 비용적인 측면에서 보다 효율적으로 보안 관제를 수행할 수 있는 방안을 제안한다. 이를 위해 YOLO (You Look Only Once)와 SlowFast를 결합한 AI 모델을 활용하여 통합 관제 솔루션을 설계하고 구현하였다. 제안된 시스템은 일반 CCTV를 통해 실시간으로 수집한 데이터를 기반으로 이상행동을 감지하고, 관련 정보를 웹 기반 소프트웨어에 전송하여 신속한 대응을 가능하게 한다. 본 연구는 기존 CCTV 시스템을 개선함과 동시에 지능형 CCTV의 장점을 도입하여 보안 관제의 효율성을 향상시킬 수 있을 것으로 기대한다.","While the existing general CCTV system only provides a simple video recording function, intelligent CCTV includes reinforced functions such as real-time detection, object analysis, and automatic warning. Recently, the importance of introducing a large-scale intelligent abnormal behavior detection system has emerged due to the limitation that the existing CCTV system needs to satisfy the modern security needs in Korea. This paper proposes a more efficient way to perform security control in terms of cost without additional installation or replacement by establishing and installing an intelligent abnormal behavior detection AI system on general CCTV. In the proposed system, an integrated control solution is designed and implemented using an AI model that combines YOLO (You Look Only Once) and SlowFast. The proposed YOLO and SlowFast models can effectively perform real-time object detection and time-series data analysis in the experimental results. In particular, the YOLO model demonstrates exceptional performance in real-time object detection, while the SlowFast network proves suitable for detailed analysis of time-series data. In addition, the proposed system can detect abnormal behaviors based on data analysis collected through general CCTV in the real environment and transmit related information to a web-based application that provides a rapid response. As a result, this study is expected to improve the existing CCTV system and fulfill the efficiency of security control by introducing the advantages of intelligent CCTV simultaneously."
딥러닝 알고리즘 기반 보행자 감지 시스템,2024,"['Pedestrian', 'Yolo', 'Deep learning', 'Jetson nano', 'Object detecting']","스마트 횡단보도는 IoT 센서와 실시간 신호 제어 기술을 활용하여 보행자 사고 위험을 줄이는 대표적인 기술이다. 최근 딥러닝 알고리즘의 발전에 따라 실시간 보행자 탐지시스템을 구축할 수 있는 환경이 개선되었다. Yolo 알고리즘은 많은 성능 개선을 통해 실시간 객체 탐지에 있어 높은 인식률과 인식속도를 나타낸다. 그 중 Yolov8 알고리즘은 C2f 모듈, PAN 모듈과 앵커 프리 방식을 채택하면서 기존 모델에 비해 성능이 향상되었다. 따라서 본 논문에서는 실제 보행자 데이터 세트를 구성하여 Yolo 알고리즘 버전 별 성능을 분석하고 훈련을 통해 보행자 감지 시스템에 적합한 알고리즘 버전을 선별한다. 훈련된 알고리즘을 젯슨 나노에 이식하여 온-디바이스 기반 보행자 감지 시스템을 구축한 후 실제 시뮬레이션을 통해 보행자가 정상적으로 감지되는 지를 확인한다.","Smart crosswalks are representative technologies that reduce the risk of pedestrian accidents by utilizing IoT sensors and real-time signal control technology. With the recent development of deep learning object detecting algorithms, the environment to build a real-time pedestrian detection system has improved. Yolo algorithm shows high recognition rate and high recognition speed in real-time object detection through many performance improvements. Among them, Yolov8 algorithm has been upgraded a lot in performance compared to the existing model by adopting C2f module, PAN module and anchor-free method. Therefore, in this paper, a real pedestrian data set is constructed to analyze the performance of each version of Yolo algorithm and select the algorithm version suitable for the pedestrian detection system through actual training. After constructing an on-device based pedestrian detection system by transplanting the trained algorithm into Jetson Nano board, it checks whether pedestrians are detected normally through actual simulation."
YOLOv4를 이용한 CCTV 영상 내 군중 밀집도 분석 서비스 개발,2024,"['CCTV', 'Crowd Density', 'Deep Leaning', 'Object Detection', 'YOLOv4']","본 논문에서는 2022년 10월 29일 한국에서 발생한 이태원 압사 사고를 기반으로 미래에 발생할 수 있는 인파 사고에 대하여 군중 밀집으로 인한 위험을 미리 예측하고, 예방하기 위한 목적으로 작성되었다. 단일 CCTV 같은 경우 관리자가 실시간으로 현재 상황을 판별할 수 있지만, 하루 종일 해당 화면만 들여다볼 수 없기 때문에 CCTV 화각으로 촬영된 영상들을 학습한 YOLO v4를 이용하여 객체를 탐지하고, 정해진 군집의 수가 초과하는 순간에 알림을 통해 군중 밀집으로 인한 안전사고를 예방하게 된다. YOLO v4 모델을 사용하게 된 이유는 이전 YOLO 모델보다 더욱 높은 정확성과 빠른 속도로 개선되어, 객체 탐지 기법이 더 용이해졌기 때문이다. 본 서비스를 AI-Hub 사이트에 등재된 CCTV 영상 데이터로 테스트하는 과정을 거치게 된다. 현재 한국에 CCTV는 기하급수적으로 증가하였고, 이를 실제 CCTV에 적용한다면 앞으로 일어나게 될 군중 밀집으로 인한 사고를 비롯한 다양한 사고를 예방할 수 있을 것으로 기대한다.","In this paper, the purpose of this paper is to predict and prevent the risk of crowd concentration in advance for possible future crowd accidents based on the Itaewon crush accident in Korea on October 29, 2022. In the case of a single CCTV, the administrator can determine the current situation in real time, but since the screen cannot be seen throughout the day, objects are detected using YOLOv4, which learns images taken with CCTV angle, and safety accidents due to crowd concentration are prevented by notification when the number of clusters exceeds. The reason for using the YOLO v4 model is that it improves with higher accuracy and faster speed than the previous YOLO model, making object detection techniques easier. This service will go through the process of testing with CCTV image data registered on the AI-Hub site. Currently, CCTVs have increased exponentially in Korea, and if they are applied to actual CCTVs, it is expected that various accidents, including accidents caused by crowd concentration in the future, can be prevented."
딥러닝을 이용한 마이크로 드릴비트 이물질 검사 시스템 구현,2024,"['YOLO V3', '드릴비트 검사', '이물질 검출', '자동화 시스템', 'PCB 제조 공정', 'YOLO v3', 'Drill Bit', 'Foreign Material Detection', 'Automated System', 'PCB Manufacturing Process']",국문 초록 정보 없음,"This paper implemented a drill bit foreign matter inspection system based on the YOLO V3 algorithm and evaluated its performance. The study trained the YOLO V3 model using 600 training data to distinguish between the normal and foreign matter states of the drill bit. The implemented inspection system accurately analyzed the state of the drill bit and effectively detected defects through automatic inspection. The performance evaluation was performed on drill bits used more than 2,000 times, and achieved a recognition rate of 98% for determining whether resharpening was possible. The goal of foreign matter removal in the cleaning process was evaluated as 99.6%, and the automatic inspection system could inspect more than 500 drill bits per hour, which was about 4.3 times faster than the existing manual inspection method and recorded a high accuracy of 99%. These results show that the automated inspection system can dramatically improve inspection speed and accuracy, and can contribute to quality improvement and cost reduction in manufacturing sites. In future studies, it is necessary to develop more efficient and reliable inspection technology through system optimization and performance improvement."
소아 사시 진단을 위한 스마트폰 기반 각막 빛 반사 검사 시스템 구현,2024,"['Pediatric strabismus', 'Corneal light reflection test', 'YOLO', 'object detection', 'smartphone', '소아 사시', '각막 빛 반사 검사', 'YOLO', '객체 검출', '스마트폰']","사시는 원인을 정확히 알 수 없는 시력 장애이다. 약 3.5% 내외에서 발생하는 것으로 알려진 소아 사시는 지속적인 관찰이 없으면 발견이 어려우며, 시력이 완성되는 만 7세 이전에발견해서 치료하는 것이 매우 중요하다. 치료가 늦어지면 약시, 복시와 같은 시력 장애의 위험이 커진다. 소아 사시의 조기 진단을 위해 본 논문에서는 스마트폰에 기반한 각막 빛 반사검사 시스템을 제안하였다. 제안된 시스템은 스마트폰의 전면 화면을 광원으로 사용하여 스마트폰 사용자의 각막에 비춘 빛 반사점을 학습된 YOLO 모델을 사용하여 자동으로 검출하고, 검출된 양안의 반사점 사이의 간격에 따라 사시를 진단한다. 소아가 집중해서 스마트폰을 보는 동안 눈의 움직임을 모니터링 하면서 자동으로 사시를 진단할 수 있기 때문에 부모가 자녀 눈의 변화를 제대로 확인하지 못하는 경우에도 사시를 조기에 발견하여 치료할 수있도록 도울 수 있다.","Strabismus is a visual impairment whose cause is unknown. Pediatric strabismus,known to occur in about 3.5%, is difficult to detect without continuous observation,and it is very important to detect and treat it before the age of 7 when vision iscompleted. If treatment is delayed, the risk of vision disorders such as amblyopiaand double vision increases. For the early diagnosis of childhood strabismus, thispaper proposed a corneal light reflection test system based on smartphone. Theproposed system uses the front screen of the smartphone as a light source toautomatically detect light reflection points on smartphone user's cornea using thetrained YOLO model, and diagnoses strabismus based on the gap between thedetected reflection points of both eyes. Since strabismus can be automaticallydiagnosed while a child is looking at the smartphone, strabismus can be detectedand treated properly even if parents are unable to properly check the position oftheir child's eyes."
Stable Diffusion의 하이퍼파라미터값에 따른 이미지 생성 정확도 분석,2024,"['Stable diffusion', '생성형 AI', '하이퍼파라미터', 'AI 생성 이미지 정확도', 'YOLO 객체 인식', 'Stable diffusion', 'Generative AI', 'Hyperparameter', 'AI-Generated image accuracy', 'YOLO object detection']","본 논문은 하이퍼파라미터 조정이 이미지 품질에 미치는 영향을 분석하여 Stable Diffusion의 성능을 객관적으로평가한다. Stable Diffusion은 텍스트 프롬프트를 기반으로 이미지를 생성하고 이미지 편집 등 다양한 작업을 수행할수 있는 AI 모델이다. 생성된 이미지의 정확도를 평가하기 위해 본 연구는 YOLO 객체 인식 모델을 사용하여, 다양한하이퍼파라미터 설정이 전체 이미지 정확도에 미치는 영향을 분석한다. 실험 결과는 모델 최적화에 유용한 통찰을제공하며, 성능 개선을 위한 필수 데이터를 제시한다. 본 논문은 복잡한 프롬프트 처리 및 자동 하이퍼파라미터 조정의 필요성을 강조하며, AI 기반 이미지 생성의 지속적 개선을 위한 기초 자료가 될 것이다.","This paper presents an objective evaluation of Stable Diffusion’s performance by analyzing the impact ofhyperparameter adjustments on image quality. Stable Diffusion is an advanced AI model designed to generate imagesfrom text prompts and capable of performing various tasks, including image editing and transformation. To assess theaccuracy of the generated images, this study utilizes the YOLO object recognition model as a measurement tool,examining how different hyperparameter settings influence overall image accuracy. Experimental findings offer valuableinsights into model optimization, providing essential data for refining Stable Diffusion’s performance. The study highlightsthe need for future research in developing complex prompt processing techniques and establishing automatedhyperparameter tuning systems, which are critical for enhancing model adaptability and image generation quality. Byproviding a foundational understanding, this research serves as a basis for ongoing improvement efforts in AI-based imagegeneration."
철책의 이상 상태를 감시하기 위한 임베디드 시스템에서의 실시간 객체 탐지 모델 성능 비교 분석,2024,"['딥러닝', '컴퓨터 비전', '객체 인식', '기계학습', 'Deep Learning', 'Computer Vision', 'Object Detection', 'Machine Learning']","최전방 철책을 넘어 탈북하는 사건이 가끔 일어난다. 국방의 관점에서 일어나선 안될 이런 사고를 예방하기 위해 감시 시스템을 보완하는 기술로 실시간 객체 탐지 기술이 효과적일 수 있다. 감시 시스템에 실시간 객체 탐지 기술을 적용하고자 SSD, DSSD 및 YOLO V5~V8까지의 모델의 성능을 비교했다. 감시 시스템에 실시간 객체 탐지 모델을 적용하기 위해서는 드론 등의 임베디드 시스템에 탑재하는 것이 효과적이기 때문에 임베디드 시스템에서 활용할 수 있는 모델을 찾고자 했다. 모델의 성능을 끌어올리기 위해 별도의 시스템을 구성하고 전방 철책과 같은 모델의 이미지로 구성한 소규모 적은 수의 클래스 데이터 세트를 학습시켰다. 학습한 모델을 mAP, 재현률 그리고 FPS를 지표로 평가했다. 실험 결과 mAP 지표에서 V5-X 모델이 우수했다. mAP와 재현률을 종합적으로 고려할 때 가장 우수한 모델은 YOLO V8-L이다. 구성한 임베디드 시스템에서 FPS를 측정했을 때 V8-N 모델만이 실시간의 기준인 30 FPS를 초과하는 성능을 보였다. V8-N 모델은 예측 정확도는 V8-L 모델과 큰 차이가 없으며 45 FPS를 달성해 실시간의 기준을 충족한다. 실험 결과 V8-N 모델이 임베디드 시스템에서 실시간 객체 탐지 모델로 효과적임을 확인했다.","Occasionally, incidents of violations of the Northern Limit Line (NLL) fence occur. From a national defense perspective, Real-time Object Detection can be effective as a complementary technology to surveillance systems to prevent such accidents that should not occur. In order to apply Real-time Object Detection for use in embedded systems to surveillance systems, we compared the performance of models from SSD, DSSD, and YOLO V5 to V8. We trained the model with the same images as the NLL fence. We used the model in the system configured to improve performance of trained model. Then, measured mAP, Recall and FPS. The best model considering mAP and Recall is YOLO V8-L. When measuring FPS, only the V8-N exceeded the real-time standard of 30 FPS and achieved 45 FPS. The V8-N has a prediction accuracy close to the V8-L and meets the standards for real-time FPS, enabling real-time object detection in embedded systems."
생성적 적대 신경망을 활용한 지능형 송전철탑 애자 탐지 기법,2024,"['객체 탐지', '데이터 구축', '생성적 적대 신경망', '가상 이미지 데이터', '애자', 'Object Detection', 'Data Construction', 'Generative Adversarial Network', 'Virtual Image Data', 'Insulator']","최근 증가하는 전력 수요에 따라 발전소로부터 전력을 전달하는 송전철탑의 건설이 증가 되고 있다. 이에 따라 송전철탑 안정성의 핵심 요소인 애자의 유지 보수 작업이 중요해지고 있다. 기존의 수동적인 애자보수 작업은 작업자가 직접 송전철탑에 올라가 애자를 확인하는 방식인데 이는 작업자의 안전성과 효율성의 문제를 가진다. 따라서 본 연구에서는 드론과 고해상도 카메라, 생성적 적대 신경망 StyleGAN2-ADA, 객체탐지 모델인 YOLO v7을 이용하여 자동화 및 향상된 애자 탐지 기법을 제시한다. 드론과 고해상도 카메라로 실제적인 애자 이미지 데이터를 취득하고 StyleGAN2-ADA를 통해 가상 애자 이미지 데이터를 생성한다. 이후 실제 이미지 데이터와 가상 이미지 데이터를 결합해 YOLO v7을 학습하여 애자 탐지에 적용한다. 실험을 통해 이 기법의 우수성을 검증하였으며 애자뿐만 아니라 탐지 작업이 필요한 다양한 산업현장에서도 적용가능할 것이다.","Due to the continuous increase in power demand, the construction of transmission towers to deliver electricity from power plants is increasing. Consequently, the importance of maintaining insulators, a key element in the stability of transmission towers, has become increasingly significant. Traditional maintenance involves manual inspections in which workers climb transmission towers to check the insulators. However, this method poses safety and efficiency issues for workers. Therefore, this study proposes an automated and enhanced detection method for insulators using drones, high-resolution cameras, StyleGAN2-ADA, and the object detection model YOLO v7. High-resolution images of the real insulators are captured using drones and cameras, and virtual insulator images are generated using StyleGAN2-ADA. YOLO v7 is trained on a combined dataset of real and virtual images to detect insulators. Experiments verified the superiority of this method, suggesting its applicability to insulators, and various industrial sites that involve detection tasks."
악천후 환경에서의 객체 검출 모델 성능 비교,2024,"['object detection', 'heavy rain', 'intelligent surveillance cameras', 'heavy rain generation']","최근 인공지능과 네트워크 기술을 접목한 지능형 감시카메라가 범죄 예방, 긴급 구조, 도로 교통 관리와 같은 다양한 분야에서 활용되고 있다. 이러한 지능형 감시카메라는 대부분 실외에 설치되므로 다양한 환경에 영향을 받는다. 특히 폭우 환경에서는 빗줄기, 블러링, 잡음의 영향을 받게 되어 객체 인식이 어렵게 된다. 따라서, 본 연구는 폭우 영상과 같은 열화된 영상이 객체 검출 성능에 미치는 영향을 알아보고자 한다. 이를 위해, 원본 영상과 폭우 생성 과정을 통해 생성된 영상을 객체 검출 모델의 대표적인 알고리즘인 YOLO v3와 YOLO v5를 통해 평가를 진행하였다. 실험 결과를 통해, 폭우 환경에서 객체 검출 성능이 청명한 환경에 비해 평균 0.124만큼 감소된다는 사실을 확인하였다.","Recently, intelligent surveillance cameras incorporating artificial intelligence and network technology has been used in various fields such as crime prevention, emergency rescue, and road traffic management. Most of these intelligent surveillance cameras are installed outdoors, so they are affected by various environments. Especially in a heavy rain environment, it is affected by rain, blurring, and noise, making object recognition difficult. Therefore, this study aims to find out the effect of deteriorated images such as heavy rain images on object detection performance. To this end, the original image and the image generated through the heavy rain generation process were evaluated through YOLO v3 and YOLO v5, which are representative algorithms of the object recognition model. Through the experimental results, it was confirmed that object detection performance in a heavy rain environment is weakened compared to a clear environment."
실시간 객체인식 모듈을 활용한 영상 내 군중밀도 산출 및 자동 추출 프로그램의 구현,2024,"['YOLO model', 'crowd counting', 'head detection', 'density calculation']","수많은 군중이 모이는 여러 가지 유형의 행사에서, 군중의 밀집도를 빨리 파악하고 인명피해를 예측하는 체계적인 대응이 공공안전의 지속적인 유지에 필수적인 요소이다. 본 논문에서는 효율적으로 객체를 탐지하고 그 결과를 실시간으로 처리할 수 있는 1-stage detection 모델인 YOLO 모델을 응용하여, CCTV 등에서 확인되는 군중 밀도를 효과적으로 검출하고 활용할 수 있도록 하였다. 다양한 공개 데이터셋을 기반으로 한 결과, 제안하는 방법은 기설치된 CCTV 등에 나타난 사람들을 빠르게 인식하고 그에 따른 군중밀도를 손쉽게 산출할 수 있었다. 구축된 모델은 약 95%의 정밀도, 93%의 재현율 및 0.89의 F1- score를 나타냈으며, 구현된 프로그램은 인구밀도를 효과적으로 산출함과 동시에 위급상황 알림, 그래프표출, 로그 저장 등의 기능들을 갖추었다. 본 연구는 인구 밀집도 분석을 위한 효율적인 도구를 제공함으로써, 대규모 행사나 공공장소에서의 군중 관리 및 안전 확보에 중요한 역할을 할 것이다","Maintaining continuous public safety in various events where large crowds gather requires quickly assessing crowd density and predicting potential casualties. The YOLO model, a 1-stage detection model capable of efficiently detecting objects and processing results in real-time is applied in this study to effectively detect and utilize crowd density observed through CCTV cameras. Utilizing various public datasets, the proposed model quickly recognizes individuals appearing on pre-installed CCTV footage and easily calculates the corresponding crowd density, with the demonstration of approximately 95% precision, 93% recall, and an F1-score of 0.89. The implemented program effectively calculates population density while also providing functionalities such as emergency alerts, graphical displays, and log storage. This study provides an efficient tool for crowd density analysis, playing a crucial role in crowd management and ensuring safety at large-scale events and public places."
이미지 기반 웹 구조적 유사도 평가 향상에 관한 연구: SSIM과 ORB 알고리즘 결합 제안,2024,"['YOLO', '이미지유사도', 'Jaccard', 'SSIM', 'ORB', '구조적판별', 'YOLO', 'Image Similarity', 'Jaccard', 'SSIM', 'ORB', 'Structural Discrimination']",국문 초록 정보 없음,"This study aims to establish a standard to accurately determine the similarity of the results when web pages are generated automatically using AI technology due to the explosive increase in demand for digital business. The YOLO, SSIM, Jaccard, and ORB techniques presented in previous studies related to the existing image similarity evaluation index generally focused on the partial and morphological similarity between the reference and the derived image. However, with the development of more complex and in-depth digital services based on generative AI, the need for comprehensive similarity analysis and determination methods that reflect the context and structure has emerged. Accordingly, this study proposed and verified a method to obtain ‘Web Structural Similarity (WSS)’ by combining the advantages of SSIM and ORB prior techniques. The research will serve various meaningful implications."
이미지 메타 정보 기반 한국인 표정 감정 인식,2024,"['메타 정보', '표정 감정 인식', 'Yolo FaceV2', 'VGG', 'EfficientNet', 'Meta-Information', 'Facial Expression Emotion', 'Yolo FaceV2', 'VGG', 'EfficientNet']","최근 팬데믹의 영향과 ICT 기술의 발전으로 인해 비대면·무인 시스템의 활용이 확대되고 있으며, 비대면 상황에서 의사소통은 감정을 이해하는 것이 매우 중요하다. 감정을 이해하기 위해서는 다양한 표정에 대한 감정 인식 방법이 필요함에 따라 이미지 데이터에서 표정 감정 인식 개선을 위한 인공지능 기반 연구가 진행되고 있다. 하지만 기존의 표정 감정 인식 연구는 정확도 향상을 위해 대량의 데이터를 활용하기 때문에 높은 컴퓨팅 파워와 많은 학습 시간이 필요하다. 본 논문에서는 이러한 한계점을 개선하기 위해 소량 데이터로도 표정 감정 인식이 가능한 방법으로 이미지 메타 정보인 연령과 성별을 활용한 표정 감정 인식 방법을 제안한다. 표정 감정 인식을 위해 원본 이미지 데이터에서 Yolo Face 모델을 활용하여 얼굴을 검출하였으며, 이미지 메타 정보를 기반으로 VGG 모델을 통해 연령과 성별을 분류한 다음 EfficientNet 모델을 활용하여 7가지 감정을 인식하였다. 메타 정보 기반 데이터 분류 모델과 전체 데이터로 학습한 모델을 비교한 결과 제안하는 데이터 분류 학습 모델의 정확도가 더 높았음을 확인하였다.",다국어 초록 정보 없음
"Estimation of Overtopping Discharge Using Real-time Monitoring, Numerical, Empirical, and Neural Network Methods",2024,"['Wave overtopping', 'Real-time monitoring', 'YOLO', 'Coastal hazards', 'Coastal flooding', '월파', '실시간 모니터링', 'YOLO', '해안 위험', '해안 침수']",국문 초록 정보 없음,"Wave overtopping due to storm surges and high waves, such as swells, is a major coastal flooding hazard, which necessitates accurate predictions for the safety of coastal facilities and people. This study investigates the wave overtopping characteristics, including wave heights and discharge, along the South Korean coastline using numerical, empirical, neural network, gradient boosting, and computer-vision-based models. Wave heights were calculated using coupled ADvanced CIRCulation (ADCIRC) and Simulating Waves Nearshore (SWAN) models using meteorological data obtained from the Korea Meteorological Administration (KMA), Japan Meteorological Agency (JMA), National Centers for Environmental Prediction (NCEP), and European Centre for Medium-Range Weather Forecasts (ECMWF) for the entire east coast of South Korea. The Samcheok Port, located on the east coast of South Korea, was selected as the pilot area for installing a closed-circuit television (CCTV) system to detect wave overtopping. The stills captured from the CCTV videos were analyzed using You Only Look Once (YOLO) to detect and quantify run-up events in the pictures. The performance of the numerical model was qualitatively and quantitatively assessed by comparing the predicted wave characteristics with observed values. The performance of the numerical model was deemed excellent in terms of wave height prediction, with minimum root mean square errors (RMSEs) of 0.60 m and 0.44 m for typhoon and wind conditions, respectively. In the prediction of wave period, the RMSE values for typhoon and strong wind conditions were 1.68 m and 1.84 m, respectively. The study findings confirm that the real-time video monitoring of waves can facilitate reliable prediction of wave overtopping characteristics, which can enable real-time and rapid hazard assessments and provide warnings for the protection of coastal communities."
딥러닝 비전기반 비파괴  차량 엔진밸브 용접합부 표면결함 검사 방법,2024,"['Engine', 'valve', 'inspection', 'deep learning', 'YOLO']",국문 초록 정보 없음,"Engine valves are key parts of automobile engines. In particular, defects in the welds of engine valves can be very fatal to the performance of the engine and the safe operation of the car. The task of having workers visually inspect and read all welded parts of engine valves to determine defects results in poor consistency and large errors, resulting in low productivity and economic efficiency, which does not guarantee the safety and reliability of automobiles. In this paper, we propose and implement a vision-based, non-contact inspection method for surface weld defects of automobile engine valves using deep learning model YOLO, and analyze its performance. The experimental results showed an excellent defect recognition, classification success rate, with high reliability of position and size alignment. In particular, real-time processing is possible by using the YOLO model with high object classification performance."
컨포멀 코팅의 미세 기포 검출을 위한 최적 UV 조도 선정 알고리즘,2024,"['Conformal coating', 'Bubble detection', 'UV light intensity', 'Feature space', 'YOLO v8']","컨포멀 코팅(Conformal Coating)은 PCB(Printed Circuit Board)를 보호하는 기술이다. 코팅 과정에서 PCB 기판과 코팅 사이에 기포가 발생할 수 있는데, 이는 회로 오작동의 원인이 되기 때문에 기포 검사는 제품의 신뢰성을 위해 반드시 거쳐야 하는 작업이다. 기포 검사를 위해 PCB를 UV(Ultra Violet) 광원 아래에 두고 촬영한 영상에서 기포의 시인성은 PCB 배경 색상과 코팅의 두께를 비롯하여 UV 조도 등 다양한 요소의 영향을 받는다. 본 논문에서는 코팅 두께에 대한 정보가 없는 상황에서 기포 검출을 위한 최적의 UV 조도를 선정하는 기법을 제시하였다. 이를 위해 입력 영상으로부터 유효 영역을 추출하고 평균 밝기와 최대 색상 위치라는 두가지 특징을 계산한다. 그리고 특징 공간에서 데이터의 통계적 특성을 고려한 마할라노비스 거리를 기반으로 UV 조도의 적정성을 판단하였다. 또한 기포 검출 단계에서는 YOLO v8 모델을 기반으로 적용하되 기포의 발생 위치에 따라 분류된 다중 클래스를 도입함으로써 기포 형태의 비정형성에 대응하였으며 타일링 과정을 적용함으로써 미세 기포에 대한 검출 성능을 향상시켰다. 임의의 PCB에 대해 UV 조도 변화에 따른 기포 검출률과 조도 적정성 척도와의 상관성에 대한 실험을 수행하였으며 이를 통해 제안 알고리즘의 타당성을 입증하였다. 기존의 기포검사 장비에 제안 알고리즘을 통합함으로써 보다 신뢰성 높은 기포 검사 솔루션을 제공할 수 있을 것으로 기대된다.","Conformal coating is a key technology used to protect Printed Circuit Boards (PCBs). And the bubble inspection is an essential task for the reliability of the PCB since the bubbles which generated during the coating process can be causes of circuit malfunctions. The visibility of bubbles in images captured under UV (Ultra Violet) light for bubble inspection is influenced by various factors, including the background color of the PCB, the thickness of the coating as well as UV light intensity. This paper proposes a technique for selecting the optimal UV intensity level for bubble detection when the information about the coating thickness is not available. In the proposed method, the effective region is extracted from the input image, and then two features, that is average brightness of B component and maximum position of H component, are calculated. And the optimal UV light intensity is determined based on the Mahalanobis distance considering the statistical characteristics of the data in the feature space. Meanwhile the YOLO v8 model is adopted in the bubble detection stage. The bubbles are classified into multi according to location to consider the irregularity of bubble shapes and the image tiling is applied to enhance the detection performance for tiny bubbles. The validity of the proposed algorithm is demonstrated through experiments which investigate the correlation between the bubble detection rate and Mahalanobis distance according to UV intensity level. It is expected to provide a more reliable bubble inspection solution by integrating the proposed algorithm into the existing conformal coating equipment."
수경재배 참외 인식을 위한 열화상 및 딥러닝의 적용 가능성 검토,2024,"['Thermal Imaging', 'Crop Monitoring', 'Image recognition', 'Faster R-CNN', 'YOLO v5']",국문 초록 정보 없음,"Currently, many studies have applied a deep learning-based image recognition technology for solving labor shortages and other issues caused by rural aging. This study aimed to determine if thermal imaging could be used in a deep learning model to recognize oriental melon grown in a hydroponic system. To recognize oriental melon using thermal imaging, time-series thermal imaging was performed under sunny and cloudy weather conditions. Temperatures of oriental melon and canopy were extracted from thermal images. Differences between extracted temperatures according to weather conditions were then determined. It was found that thermal images acquired after 14:00 were suitable for stable recognition of oriental melon regardless of weather conditions. Based on this result, additional thermal images were acquired to train YOLO v5 and Faster R-CNN models. Acquired thermal images were trained with original and augmented data. Recognition performances of training models were compared with the best mAP (mean Average Precision). As a result, it was confirmed that both YOLO v5 and Faster R-CNN models achieved the best mAP@0.5 of 92% or more regardless of data augmentation. Data augmentation did not significantly affect the accuracy of either model. This might be because thermal images used to train models were acquired under restrictive conditions in a hydroponic greenhouse, which affected model generalization. Therefore, additional experiments under various conditions are necessary to improve generalization of the model in the future."
Development of Deep Learning Color Recognition Model for Color Measurement Processes,2024,['Deep learning  · Object detection  · Color recognition  · Open source computer vision  · You only look once algorithm (YOLO)'],국문 초록 정보 없음,"We present a deep learning color recognition model for the color measurement process in the paint industry. Currently, spectrophotometers are primarily used for color measurements owing to their accuracy. The measurement method involves manually injecting the sample into a spectrophotometer. Our proposed method uses a webcam with a deep learning model on the stand of a spectrophotometer. Deep learning models are widely used for image and color detection. In this study, the “you only look once (YOLO)” algorithm is applied for real-time detection of color samples. Upon training various sample images using YOLO, the model could detect the sample area in real time using a webcam. An open source computer vision (OpenCV) library was used for the color recognition model, and the detected RGB color value was converted to the international commission on illumination color space (CIELAB) value, which is primarily used in the color measuring process.However, because of the mirror-like refl ection of light from a surface with specular refl ection, it is diffi cult to implement the color value using a camera. To address this problem, we compare several specular removal methods and propose the most suitable model for the color recognition model of color samples. The accuracy of the proposed model was verifi ed by comparing the colors of various samples. Our proposed approach can easily detect samples and color values, which can contribute signifi cantly to automatically calculating the exact amount of coloring required for the target color."
RNN 모델을 이용한 반려견 관절 데이터의 결측치 예측 및 보간,2024,"['딥러닝', '결측치 보간', '시계열 분석', 'LSTM', 'GRU', 'Deep learning', 'Missing data interpolation', 'Time series analysis', 'LSTM', 'GRU']","본 연구는 반려견 자세 추정 과정의 결측치 문제를 딥러닝 기반 보간 방식으로 해결하고자 하였다. YOLO v8을 이용해 반려견 자세를 추정하고, LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit) 모델로 결측치를 보간하였다. 실험 결과, 두 모델 모두 전반적인 패턴을 잘 포착하고 결측치를 자연스럽게 보간했으나, 급격한 변화에 대응하는 정확도와 평가 데이터에서의 성능 저하가 관찰되었다. 이를 통해 모델 구조 개선, 데이터 다양성 확보, YOLOv8 성능 향상 등의 필요성을 확인하였다. 본 연구는 반려견 자세 추정의 결측치 문제 해결 가능성을 제시하며, 향후다양한 시계열 결측치 문제에 적용될 수 있을 것으로 기대된다.","This study addresses the critical issue of handling missing data in the process of estimating dog postures byimplementing an advanced deep learning-based interpolation approach. Initially, YOLO v8 was utilized to conduct primaryestimations of dog postures. Following this, Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) modelswere employed to effectively interpolate the missing values. Experimental results indicated that both models succeeded incapturing the overall posture patterns and produced smooth interpolations for missing data. However, limitations wereobserved in responding accurately to abrupt posture changes, which led to a noticeable performance decline in theevaluation phase. These findings emphasize the need for further model architecture improvements, expanded data diversity,and enhanced YOLO v8 performance to achieve greater accuracy. This research proposes a practical solution foraddressing missing data in dog posture estimation, with promising implications for broader applications in diversetime-series interpolation scenarios."
Application of Deep Learning-Based   Object Detection Models to Classify Images of   Cacatua Parrot Species,2024,"['Cacatua parrots', 'CITES', 'conservation', 'deep learning', 'image classification', 'object detection']",국문 초록 정보 없음,"Parrots, especially the Cacatua species, are a particular focus for trade because of their mimicry, plumage, and intelligence. Indeed, Cacatua species are imported most into Korea. To manage trade in wildlife, it is essential to identify the traded species. This is conventionally achieved by morphological identification by experts, but the increasing volume of trade is overwhelming them. Identification of parrots, particularly Cacatua species, is difficult due to their similar features, leading to frequent misidentification. There is thus a need for tools to assist experts in accurately identifying Cacatua species in situ. Deep learning-based object detection models, such as the You Only Look Once (YOLO) series, have been successfully employed to classify wildlife and can help experts by reducing their workloads. Among these models, YOLO versions 5 and 8 have been widely applied for wildlife classification.The later model normally performs better, but selecting and designing a suitable model remains crucial for custom datasets, such as wildlife. Here, YOLO versions 5 and 8 were employed to classify 13 Cacatua species in the image data. Images of these species were collected from eBird, iNaturalist, and Google. The dataset was divided, with 80% used for training and validation and 20% for evaluating model performance. Model performance was measured by mean average precision, with YOLOv5 achieving 0.889 and YOLOv8 achieving 0.919. YOLOv8 was thus better than YOLOv5 at detecting and classifying Cacatua species in the examined images. The model developed here could significantly support the management of the global trade in Cacatua species."
온디바이스 AI 기반 근로자 안전 관리 및행동 추정 시스템 개발,2024,"['YOLO', 'Raspberry Pi', 'Object Detection', 'Action Recognition', 'On-Device AI']",국문 초록 정보 없음,"Since the Serious Accidents Punishment Act, employers have made efforts to protect the safety and lives of workers, leading to the installation of CCTV in many workplaces. However, accidents continue to occur, and in some workplaces, CCTV is used to monitor the attendance of workers, escalating conflicts between employers and employees. This study aims to protect the safety and privacy of workers by processing video data on a Raspberry Pi without external data transfer. The system checks whether workers are wearing safety equipment and promptly alerts colleagues in case a worker falls, enabling swift responses. Object detection is based on YOLO, with safety equipment data being trained. Various models were implemented for action recognition. The object detection and action estimation models were quantized and applied on the Raspberry Pi, achieving 73% accuracy for detecting people and safety equipment and 93% accuracy for action estimation. It is expected that the system presented in this study will simultaneously safeguard the lives and privacy of workers while contributing to the resolution of conflicts between employers and employees."
영상분석 기반 임산부 인증 수유실 자동 출입 관리,2024,"['수유실 자동 출입 시스템', 'YOLO', 'MediaPipe', '객체 인식', '자세 검출', 'Nursing room automatic door system', 'YOLO', 'MediaPipe', 'Object recognition', 'Posture detection']","본 논문은 임산부 인증을 활용한 딥러닝 기반 수유실 자동 출입 관리 시스템을 제안한다. 이 시스템은 임산부와 아기 동반 보호자의 편의성과 안전성을 증진하는 것을 목표로 한다. 스마트폰 애플리케이션을 통해 임산부를 인증하며, 객체 인식과 자세 검출 기술을 통해 아기 동반 여부를 확인한 후 자동으로 수유실 출입문이 열리도록 설계되었다.딥러닝 기반 객체 인식과 자세 검출 알고리즘은 실제 테스트에서 높은 정확도를 보였으며, 임산부와 아기 동반 보호자의 안전한 출입을 보장한다. 이러한 시스템은 기존 수유실 출입 관리 방식에 비해 편리성과 보안성이 크게 향상되었다는 평가를 받았다. 또한, 사용자의 긍정적인 피드백을 통해 시스템의 실효성과 필요성이 입증되었다. 이 시스템은 대중교통 및 공공시설에 적용할 수 있으며, 임산부와 아기 동반 보호자의 접근성을 높이는 한편, 사회적 배려 문화를 확산시키는 데 이바지할 수 있을 것으로 기대된다.","This paper proposes a deep learning-based automatic access management system for nursing rooms using maternityauthentication. The system aims to enhance the convenience and safety of pregnant women and caregivers accompaniedby infants. It verifies pregnant women through a smartphone application and is designed to automatically open the nursingroom door after detecting whether they are accompanied by an infant using object recognition and posture detectiontechnologies. The deep learning-based object recognition and posture detection algorithms demonstrated high accuracy inreal-world tests, ensuring safe access for both pregnant women and caregivers with infants. This system has beenevaluated to significantly improve convenience and security compared to existing nursing room access managementmethods. Moreover, positive user feedback has confirmed the system's effectiveness and necessity. This system can beapplied to public transportation and public facilities, enhancing accessibility for pregnant women and caregivers, whilecontributing to the spread of a culture of social consideration."
Design on Object Recognition Framework Based on Deep Learning Network Model,2024,"['VGG16', 'PyTorch', 'GPU', 'YOLO', 'Lightweight Model']",국문 초록 정보 없음,"Object-based image retrieval has a wide range of practical value that can be applied to institutional asset management, laboratory instrumentality administration on campus, and other object recognition fields. The common methods for using the deep learning framework VGG16 for image retrieval were elaborated. The Keras framework, PyTorch framework, and the framework integrating both PyTorch features and SIFT features were used to identify the object data set, respectively. According to the research findings, the PyTorch framework based on the GPU-accelerating settings showed the best performance in feature extraction and a strong robustness in recognizing objects under cluttered contexts. A comparison of VGG16 with YOLOV5, a popular target detection framework, showed that VGG16 is better at extracting the overall image features when using the GPU acceleration-based setup of the PyTorch framework, whereas YOLO is better at extracting the features of specific objects in the image. In terms of the VGG16 model applied to an embedded intelligent terminal, the VGG16 network structure was deleted, and attention mechanism and data enhancement were added, achieving a good retrieval speed and acquiring a valuable method for constructing a lightweight VGG16 network model."
인공지능 드론 배송 시스템의 구현 및 검증,2024,"['Artificial intelligence', 'Drone', 'Delivery', 'YOLO']",국문 초록 정보 없음,"In this paper, we propose the implementation of a drone delivery system using artificial intelligence in asituation where the use of drones is rapidly increasing and human errors are occurring. This system requires theimplementation of an accurate control algorithm, assuming that last-mile delivery is delivered to the apartmentveranda. To recognize the delivery location, a recognition system using the YOLO algorithm was implemented, and adelivery system was installed on the drone to measure the distance to the object and increase the delivery distance toensure stable delivery even at long distances. As a result of the experiment, it was confirmed that the recognitionsystem recognized the marker with a match rate of more than 60% at a distance of less than 10m while the dronehovered stably. In addition, the drone carrying a 500g package was able to withstand the torque applied as the raillengthened, extending to 1.5m and then stably placing the package down on the veranda at the end of the rail."
YOLOv8-Seg 모델을 이용한 어류 탐지 및 분류 성능 비교연구,2024,"['Deep learning', 'Artificial intelligence', 'YOLO', '어류 탐지 및 분류', '객체 분할', '수산자원', 'Deep learning', 'Artificial intelligence', 'YOLO', 'Fish detection and classification', 'Instance segmentation', 'Fisheries resource']",국문 초록 정보 없음,다국어 초록 정보 없음
날씬한 여성 신체와 주체성에 관한 소고 - 중국 영화 〈러라군탕(热辣滚烫)〉을 예로,2024,"['자링(?玲)', '〈러라군탕(?辣??', 'YOLO)〉', '〈인생은 한 번뿐(我只活一次)〉', '여성 신체', '여성 주체성', '몸 담론', 'Jia Ling(?玲)', '〈?辣??', 'YOLO〉', '〈Life is only once (我只活一次)〉', 'female body', 'female subjectivity', 'body discourse']",국문 초록 정보 없음,다국어 초록 정보 없음
화재 위치 산정기술 향상을 위한 CCTV 지도 작성 방안에 관한 연구,2024,"['화재 위치', '화재 검출', '딥러닝(YOLO)', '알고리즘', 'CCTV', 'Fire Location', 'Fire Detection', 'Deep Learning (YOLO)', 'Algorithm']",국문 초록 정보 없음,다국어 초록 정보 없음
전통시장을 위한 열화상 기반 실시간  화재 감지 시스템 개발,2024,"['Fire Detection', 'Fire Risk', 'Fire Detection System', 'YOLO Model', 'Traditional Markets', 'Thermal Imaging Camera']",국문 초록 정보 없음,"Traditional markets are highly susceptible to fire due to the dense concentration of stores, the frequent use of open flames, and inadequate electrical wiring management. Existing fire detection systems relying on CCTV are limited in accuracy, as they are easily affected by environmental factors such as external lighting and smoke. Similarly, sensor-based fire detection systems tend to lose reliability over time due to equipment degradation and maintenance challenges. To address these issues, this study developed a real-time fire detection system using thermal imaging cameras to mitigate the impact of external environmental factors, along with the YOLO (You Only Look Once) model, known for its efficacy in object detection. The study found that YOLOv8 and YOLOv10 exhibited the best performance, although detection accuracy was constrained by insufficient flame object data. It is anticipated that the futre incorporation of data augmentation techniques will further enhance the system’s applicability, not only in traditional markets but also in other environments with a high risk of fire."
노면 탐지 영상처리 및 센서를 활용한 개인형 이동장치용 경고 장치 설계,2024,"['개인형 이동장치', '불량 노면 감지 모델', 'Flask', 'GPS 센서', '라즈베리파이', 'YOLO', 'Personal mobility device', 'Bad road surface detection model', 'Flask', 'GPS sensor', 'Raspberry Pi', 'YOLO']","개인형 이동장치(Personal Mobility)는 노면 상태에 따라 사용자의 안전에 큰 위협이 된다. 최근 사용이 급증하면서 사고 건수도 함께 증가하고 있어, 이를 예방하기 위한 시스템이 필요하다. 본 연구는 노면 장애물을 감지하여 운전자의 안전을 향상시키기 위한 경고 시스템을 설계하고 개발한다. 이를 위해 노면 장애물의 이미지를 기반으로 데이터셋을 구성하고 YOLOv5 모델을 학습시킨다. 이후 라즈베리파이 4B를 기반으로 하여 카메라로 촬영된 영상을 실시간 프레임 단위로 처리하고 노면 장애물이 감지되면 LED 경고를 발생시킨다. Flask 프레임워크를 활용하여 실시간으로 장애물 감지 상태를 모니터링한다. 또한, GPS 센서를 활용하여 사용자의 위치 및 속도 정보를 수집하고, 설정 속도를 초과할 경우 버저를 통해 청각 경고를 발생시키는 시스템을 개발한다. 향후 사용자의 운행 과정에서 발견된 노면 장애물과 GPS 정보를 서버에 전송하여 실시간으로 노면 안전 상태를 제공하는 시스템으로 확장할 수 있으며, 본 연구 결과는 이러한 시스템 개발의 요소기술로 활용될 가능성이 높다.","Personal Mobility devices pose a significant safety risk to users depending on road conditions. With the recent surge in usage, the number of accidents has also increased, highlighting the need for a preventative system. This study aims to design and develop a warning system to enhance the safety of drivers by detecting road obstacles. To achieve this, a dataset is constructed using images of road obstacles, and the YOLOv5 model is trained. The system is based on the Raspberry Pi 4B, which processes video frames captured by a camera in real-time and triggers an LED warning when an obstacle is detected. The Flask framework is used to monitor the obstacle detection status in real time.Additionally, a GPS sensor is utilized to collect the user's location and speed data, and an auditory warning is triggered via a buzzer if the set speed is exceeded. In the future, this system could be expanded to transmit detected road obstacles and GPS information to a server, providing users with real-time road safety information. The results of this study can serve as essential technology for developing such a system."
드론 영상에서 지상기준점 타겟의 자동탐지 및 위치결정,2024,"['Ground Control Point', 'Target', 'Photogrammetry', 'Straight Line', 'Object detection', 'YOLO V8', 'Least Square Method', '지상기준점', '타겟', '사진측량', '직선', '객체 탐지', 'YOLO V8', '최소제곱법']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 무인 팔레트 트럭의 경로 제어 연구,2024,"['Unmanned pallet truck(무인 파레트 트럭)', 'Deep learning(딥러닝)', 'YOLO(욜로)', 'Path control(경로제어)', 'Pallet hole recognition(파레트 홀 인식)']",국문 초록 정보 없음,"As e-commerce and pallet cargo business continue to grow and the skilled driver population decreases, the need for unmanned pallet trucks is increasing in the growing logistics unloading and loading works. Development of unmanned pallet trucks can be considered in two ways, including the development of unmanned fully automatic equipment and the method of unmanning existing manual pallet trucks using add-on technology. In this study, as a base technology for unmanned pallet trucks, research was conducted to develop key technology that can recognize standard pallets through cameras and deep learning recognition. Research was conducted to control the movement of the pallet truck in front of the pallet so that forks can be inserted more accurately and quickly into the pallet holes. As a result of this study, the accuracy of hole center recognition with standard pallet by YOLO deep learning from around 3 meters in front of the pallet was within ±10 mm and the performance was 10 Hz."
요양시설 노인을 위한 이동형 스마트캠,2024,"['Elderly care facility', 'Autonomous driving', 'SLAM', 'Real-time detection']","이 연구는 고령화 사회에서의 요양 시설 안전 문제에 대응하기 위해 이동형 스마트카메라 시스템을 제안한다. 시스템은 YOLO 알고리즘을 사용하여 실시간으로 위험물체를 감지하고, 돌발행동을 인식하여 노인 환자들의 안전을 증진한다. 또한, SLAM 기술을 활용하여 자율주행을 구현하여 환자를 모니터링하고 목표 지점으로 이동한다. 이를 통해 요양 시설에서의 안전사고를 예방하고 환자들의 삶의 질을 향상시킬 수 있다. 노인 환자들의 안전을 보장함으로써 가족들에게 안심과 신뢰를 제공하며, 요양 시설의 인력 부족 문제에도 대응할 수 있는 효과적인 솔루션을 제시한다.","This study proposes a mobile smart camera system to address safety concerns in elderly care facilities within an aging society. Utilizing the YOLO algorithm, the system detects hazardous objects in real-time and identifies sudden behavioral changes to enhance the safety of elderly residents. Furthermore, by implementing SLAM technology, the system achieves autonomous navigation to monitor patients and facilitate movement to designated areas. This approach aims to prevent accidents in care facilities, improve the quality of life for residents, and provide peace of mind for families. Additionally, it offers an effective solution to address staffing shortages in care facilities."
Jetson TX1 기반 사회복지시설을 위한 위험 상황 실시간 감지 시스템,2024,"['human pose estimation', 'object detection', 'nvidia jetson tx1', 'cctv', 'real-time', 'social welfare facilities']","본 논문에서는 사회복지시설 내 안전사고 예방을 위해 딥러닝 기반의 실시간 행동 탐지 및 알림 시스템을 제안한다. 이 시스템은 Jetson TX1을 기반으로 YOLO 모델과 OpenPose를 활용하여 낙상, 기절, 싸움, 위험 물건 소지 등 다양한 위험 상황을 실시간으로 탐지하고, 근무자에게 알림을 전송한다. 제안한 시스템은 신속한 대응을 가능하게 하며, 위험 상황의 상세 정보를 제공하여 근무자의 상황 판단을 돕는다. 또한, 근무자가 위험상황을 확인하고 환자 상태를 입력할 수 있도록 하여 사후 관리를 돕는다.","This paper proposes a real-time action detection and notification system based on deep learning to prevent safety accidents in social welfare facilities. The system utilizes YOLO and OpenPose models on a Jetson TX1 platform to detect various dangerous situations in real-time, including falls, fainting, fights, and possession of dangerous objects. It then sends notifications to staff members. The proposed system enables prompt responses, provides detailed information about dangerous situations to assist staff members in making informed decisions, and facilitates aftercare by allowing staff to acknowledge the situation and input patient status."
선형회귀를 통한 제조 폐색 환경에서의 다중 객체 재식별 성능 향상,2024,"['Manufacturing Process', 'Occlusion', 'Multi-Object Tracking', 'linear Regression', 'Re-identification', '제조 공정', '폐색', '다중 객체 추적', '선형회귀', '재식별']","본 연구는 폐색 영역이 존재하는 제조 환경에서 컴퓨터 비전을 이용한 개별 자재의 식별 및 위치 추적 문제를 다룬다. 동일한 외형의 다중 객체들이 폐색 영역을 통과할 때 발생하는 ID switch(IDS) 문제를 해결하고자 YOLO(You Only Look Once)와 BoT-SORT(Bag of Tricks for SORT)에 선형회귀를 적용해 폐색 영역 통과 시점을 예측하였다. 실제 제조 환경과 유사한 제조 모형 실험 환경을 구축하여 실험한 결과, 폐색을 통과하는 순서가 엇갈리는 상황에서도 재식별이 원활히 이루어졌으며, 95.2%의 높은 재식별 정확도를 달성하였다.","This study addresses the problem of identification and location tracking of individual materials using computer vision in a manufacturing environment with occluded areas. To solve the ID switch (IDS) problem when multiple objects with the same appearance pass through an occluded area, YOLO (You Only Look Once), BoT-SORT (Bag of Tricks for SORT) and linear regression is used to predict timing while passing occluded area. As a result of testing by constructing a manufacturing model experiment environment similar to the actual, it was confirmed that re-identification was performed well even in situations where the order of passing through occlusion was different, and a high re-identification accuracy of 95.2% was obtained."
YOLOv8을 이용한 한글 지문자 인식,2024,"['한글 지문자', 'YOLOv8', 'MediaPipe', 'SVM', 'Korean Fingerspelling', 'YOLOv8', 'MediaPipe', 'SVM']","청각 장애인은 음성을 사용할 수 없으므로 주로 수어를 통하여 의사소통을 한다. 수어의 한 종류인 한글 지문자는 손과 손가락의 모양으로 한글의 자음과 모음을 나타낸다. 청각 장애인들이 지문자를 익히면 의사소통을 쉽게 할 수 있지만 배우기가 쉽지 않다. 본 논문에서는 인공지능 기술을 이용하여 수어 교육에 활용할 수 있는 지문자를 인식하는 알고리즘을 제안하고자 한다. 이를 위해 본 논문에서는 이미지 인식에 많이 활용되는 YOLOv8을 활용한 한글 지문자 인식 알고리즘을 제안한다. 또한 YOLO 학습에 사용되는 다량의 학습 데이터를 자동으로 구축하기 위하여 미디어파이프(MediaPipe)의 Landmark 기능을 활용한 자동 어노테이션 방법을 제안한다. 제안하는 방법의 성능을 기존 연구의 SVM(support vector machine) 알고리즘과 비교하여 우수성을 검증하였다. 특히, 오인식률이 높은 한글 지문자‘ㅓ’,‘ㅕ’,‘ㅔ’,‘ㅖ’에 대해서도 높은 인식률을 보임을 확인하였다.","Deaf people communicate with sign language using their hands. Korean fingerspelling, a type of sign language, represents Korean consonants and vowels through hand and finger shapes. Although fingerspelling is an effective communication method, it can be challenging to learn. This paper proposes an algorithm for recognizing fingerspelling to support sign language education using artificial intelligence technology. Specifically, we present a Korean fingerspelling recognition algorithm based on YOLOv8, which is widely used in image recognition. Additionally, we introduce an automatic annotation method using MediaPipe’s Landmark feature to efficiently create the large amount of training data required for YOLO training. The performance of the proposed method was validated by comparing it with the Support Vector Machine (SVM) algorithm from previous research, demonstrating its superiority. Notably, our method achieved high recognition accuracy for Korean fingerspelling characters ‘ㅓ,’ ‘ㅕ,’ ‘ㅔ,’ and ‘ㅖ,’ which typically have high misrecognition rates."
소형 저궤도 정찰위성을 이용한 전장 정보력 및 방어 우세권 확보 방안 연구,2024,"['소형위성', '통신', '감시정찰', '사물인식', '영상분석', 'small satellites', 'communication', 'surveillance and reconnaissance', 'object recognition', 'image analysis']","현대 전장 환경에서 기술의 발전으로 공격 방식이 더욱 정교해지고 소형화됨 에 따라, 실시간 정보의 중요성이 점차 증가하고 있다. 이러한 변화는 군사적 정보 수집 및 분석에 새로운 기술적 혁신을 요구한다. 소형 저궤도 정찰위성은 감시·정 찰이 필요한 지역에 대해 신속한 정보 수집과 정밀한 분석을 제공하여 기존 탐지 능력의 한계를 극복한다. 또한, 실시간 전장 상황에서 정밀한 감시와 분석을 통해 적군의 공격을 효과적으로 방어할 수 있다. 본 연구는 소형 저궤도 정찰위성과 YOLO 알고리즘을 이용해 군사적 정보 우세를 확보하기 위한 방안을 제시한다.","In the modern battlefield environment, advancements in technology have led to more sophisticated and miniaturized attack methods, increasing the importance of real-time information. These changes demand new technological innovations in military intelligence collection and analysis. Small low-Earth orbit reconnaissance satellites provide rapid information collection and precise analysis for regions requiring surveillance and reconnaissance, overcoming the limitations of traditional detection capabilities. Furthermore, they enable precise monitoring and analysis of real-time battlefield situations, effectively defending against enemy attacks. This study presents strategies for securing military information superiority using small low-Earth orbit reconnaissance satellites and the YOLO algorithm."
Real time instruction classification system,2024,"['Computer Vision', 'Speech Recognition', 'Machine Learning', 'Detection']",국문 초록 정보 없음,"A recently the advancement of society, AI technology has made significant strides, especially in the fields of computer vision and voice recognition. This study introduces a system that leverages these technologies to recognize users through a camera and relay commands within a vehicle based on voice commands. The system uses the YOLO (You Only Look Once) machine learning algorithm, widely used for object and entity recognition, to identify specific users. For voice command recognition, a machine learning model based on spectrogram voice analysis is employed to identify specific commands. This design aims to enhance security and convenience by preventing unauthorized access to vehicles and IoT devices by anyone other than registered users. We converts camera input data into YOLO system inputs to determine if it is a person, Additionally, it collects voice data through a microphone embedded in the device or computer, converting it into time-domain spectrogram data to be used as input for the voice recognition machine learning system. The input camera image data and voice data undergo inference tasks through pre-trained models, enabling the recognition of simple commands within a limited space based on the inference results. This study demonstrates the feasibility of constructing a device management system within a confined space that enhances security and user convenience through a simple real-time system model. Finally our work aims to provide practical solutions in various application fields, such as smart homes and autonomous vehicles."
장애인을 위한 인공지능 도구 개발에 관한 체계적 고찰: 국내 연구를 중심으로,2024,"['장애인', '인공지능', '체계적 고찰', 'Disability', 'Artificial Intelligence', 'Systematic Review']","본 연구는 국내 연구를 중심으로 장애인을 위한 인공지능 도구 개발에 관한 체계적 고찰하였다. 문헌검색은 RISS, KISS, DBpia의 검색엔진을 사용하여, 2020년부터 2024년 10월까지 출판된 국내 논문을 키워드를 이용해 26편의 논문을 선정하였다. 연구 결과, 연구대상자는 청각장애와 시각장애로 각각 9편(34.60%), 그 외의 장애는 각각 1편(3.85%)이었다. 인공지능 도구 개발의 연구목적을 ICF의 기준을 근거로 하여 분석하였다. 기능과 장애는 26편(100%), 배경요인은 0편(0%)로 나타났다. 인공지능 도구를 기능에 따라 5개로 분류하였다. 인식의 기능이 28번(96.55%)이고, 예측의 기능은 1번(3.45%)이고, 자동화, 소통과 생성의 기능은 없었다. 본 논문의 인공지능 도구는 총 33개이다. 인공지능 도구의 기능 수준에 따라 3단계 머신러닝은 9개(27.27%), 사용횟수는 19번(32.78%)이고, 4단계 딥러닝은 24개(72.73%), 사용횟수는 39번(67.24%)이다. MediaPipe, Tensorflow, YOLO, OpenCV가 5번으로 가장 많이 사용되었다. 본 연구를 통해 장애인을 대상으로 한 인공지능 도구 개발의 동향과 활용방안을 모색하는데 기초 자료로 제공한다.","This study systematically reviewed domestic research on the development of artificial intelligence tools for the disabled. The literature search was conducted using the search engines of RISS, KISS, and DBpia—a total of 26 domestic papers published from 2020 to October 2024 were selected using keywords. As a result, the subjects of the study were nine papers (34.60%) each for hearing and visual impairment, and one paper (3.85%) each for other disabilities. The research purpose of the development of artificial intelligence tools was analyzed based on the International Classification of Functioning Disability and Health (ICF) criteria. Functions and disabilities were 26 papers (100%), and background factors were 0 papers (0%). The artificial intelligence tools were classified into five types according to their functions. The recognition function was 28 times (96.55%), the prediction function was one time (3.45%)—there were no functions of automation, communication, and creation. The artificial intelligence tools in this paper consist of a total of 33. According to the functional level of the AI ​​tool, 3-stage machine learning was used nine times (27.27%) and 19 times (32.78%), and 4-stage deep learning was used 24 times (72.73%) and 39 times (67.24%). MediaPipe, Tensorflow, YOLO, and OpenCV were used the most at a total of five times. This study provides basic data for exploring exploring trends in the development of AI tools for the disabled and ways on how to utilize them."
MLOps 기반 Kubeflow 환경에 최적화된 객체 탐지 모델 개발,2024,"['AI Workflow', 'MLOps', 'Docker', 'Container', 'Kubernetes']","기존 인공지능 시스템은 서비스 규모가 증가함에 따라 환경 설정, 특징 추출, 리소스 관리, 모델 학습 등 모든 단계를 수작업으로 진행하는 경향이 있다. 이는 전문성이 요구되는 작업으로 자동화보다는 전문 인력에 의존하는 측면이 높은데, 그 결과 분석 결과의 신뢰성과 일관성이 저하되는 원인이 될 수 있다. 최근에는 이러한 문제를 해결하기 위해 MLOps의 필요성이 중요해지고 있으며, Kubeflow와 같은 MLOps 플랫폼을 활용한 환경에서 인공지능 모델의 자동화, 배포, 관리 등 연구가 활발하게 진행되고 있다. 이에 본 연구에서는 Kubeflow Dashboard에서 AI 모델 구현에 필요한 전처리, 알고리즘 선택 등의 진행을 웹 UI에서 진행할 수 있는 KFP(Kubeflow Pipeline) 컴포넌트 코드를 개발하여 YOLO 객체 탐지 모델의 자동화된 모니터링 및 배포, 운영 과정을 심도 있게 기술하였다. 이를 통해 시간과 노력이 많이 소모되는 반복적인 작업들을 자동화하여 효율성을 높일 수 있었으며, 특히 비동기 방식으로 애플리케이션이 배포되고 실행되는 과정을 강조함으로써 실시간으로 변화하는 환경에 더욱 적응 가능한 시스템을 확인하였다. 또한, 매개변수 설정을 좀 더 효율적으로 관리하여 다양한 변수들이 분석 결과에 미치는 영향을 최소화하고, 인력과 시간을 단축하여 일관되고 우수한 성능을 확보하여 모델 각 단계에서 실행 결과가 동시에 어떻게 처리되고 어떤 영향을 미치는지 상태를 확인하고 추적할 수 있었다.","AI(Artificial Intelligence) models tend to perform all steps manually, include set to up environment, extract feature, management resources, and learning models, as the service scale increases. This is a task that requires expertise and relies on professional manpower rather than automated , which can cause the reliability and consistency of the analysis results to deteriorate. Recently, the need for MLOps has become important to solve these problems, and research such as automated , deployment, and management of AI models is with actively conducted in environments using MLOps platform such as Kubeflow. Therefore, in this study, KFP(Kubeflow Pipeline) component code that can proceed with preprocessing and algorithm select required to implement AI models on the Kuberflow dashboard and described in depth the automated monitoring, distribute, and operation process of the YOLO object detection model. This provide in it was possible to increase efficiency by automated  tasks that require a lot of time consume and iterative process of models, emphasize be placed on asynchronous deployment and execute of applications, enable adaptability to dynamically changed environment. In addition to, by efficiently manage parameter set be able to minimize the impact of various variables on the analysis result, reduce manpower and time to ensure consistent and superior performance, and check and track the status of how execute result are handled and how they affect them at each stage of the models."
인공지능 기반 열간단조 이형제 분사 및 도포관리시스템 개발,2024,"['열간단조', '이형제', '코팅관리', '적층 제조', '인공지능', 'Hot Forging', 'Release Agent', 'Coating Management', 'Additive Manufacturing', 'Artificial Intelligence']","열간단조 이형제 분사 기술은 열간단조 공정 중의 하나로, 다양한 금속 소재를 가열한 상태에서 압력을 가해 물체의 형상을 변형하는 기술로 자동차 산업, 항공우주 산업, 기계산업 등 다양한 산업 분야 활용되고 있다. 기존의 열간 단조 이형제 분사 기술은 주로 수작업을 통하여 진행하고 있기 때문에 금속 소재 낭비, 운영 비용 증가 등의 문제점들이 발생한다. 본 논문에서는 이러한 기존 열간단조 이형제 분사 방식의 문제점 및 한계점을 극복하기 위하여 인공지능을 활용한 이형제 분사량과 도포품질 측정 기술을 개발하고자 한다. 이를 위하여 이형제 분사 및 도포관리시스템에서 가장 중요한 이형제 분사 측정과 도포 품질 분석을 위하여 인공지능 기법을 적용한다. 세부적으로 이미지 증강에는 GAN(Generative Adversarial Network), 분사형상 검출에는 YOLO(You Only Look Once), 분사량 측정에는 Linear Regression을, 도포품질 분석에는 CNN(Convolutional Neural Network)과 SVM(Support Vector Machine)을 각각 적용한다.","The hot forging compound injection technique is one of the processes in hot forging where various metal materials are heated and pressure is applied to deform the shape of the object, and this technology is utilized in various industries, including the automotive, aerospace, and machinery sectors. The conventional hot forging compound injection technique has some issues as it mainly relies on manual labor, leading to several problems such as metal material waste and increased operating costs. In this paper, we aim to overcome these issues and limitations of the conventional hot forging compound injection method by developing an artificial intelligence-based technique for measuring the injection amount and coating quality. In detail, Generative Adversarial Network(GAN) is employed for image augmentation, You Only Look Once(YOLO) for injection pattern detection, Linear Regression for injection volume measurement, and Convolutional Neural Network(CNN) along with Support Vector Machine (SVM)for coating quality analysis."
UAV 영상 데이터 기반의 객체인식 연구동향 분석,2024,"['무인항공기', '객체인식', '초해상화', '바운딩박스 일치율', '신뢰도 점수', 'UAV', 'Object Detection', 'Super Resolution', 'IoU', 'Confidence Score']","건설분야에서 드론을 활용한 객체인식은 도전적인 주제이다. 드론을 활용하여 취득된 데이터는 상대적으로 높은 고도에서 촬영됨으로 인해 촬영각도의 제한된 범주에서 객체의 정보를 획득한다는 점에서 일반적으로 객체인식에 활용되는 이미지와 다른 특성을 갖추고 있다. 이러한 드론 데이터의 특성은 일반 이미지를 통해 학습된 객체인식 모델에 적용 및 활용될 경우에 제약요소로 작용된다. 따라서 객체인식에 드론데이터가 활용될 수 있도록 하기 위해 드론의 데이터 특성에 적합하게 객체인식 성능을 높일 수 있는 방법이 필요하다.본 연구는 드론을 활용한 객체인식의 활용성을 높이기 위한 방법을 탐구하기 위해 딥러닝 기반의 연구사업과 문헌을 분석한다. 주요 목적은 드론 데이터셋을 활용하여 건설 분야에서 객체인식률을 향상시키기 위함이다. 통상적인 데이터 전처리와 YOLO, FRCNN 등의 모델의 활용방법이 드론데이터셋과 함께 활용될 경우 객체인식 성능을 향상시키기 위한 조건과 요구조건들을 탐구한다. 다수의 연구사례를 통해 초해상화 방법을 통해 상대적으로 해상도가 낮고 객체의 특징추출이 어려운 드론 데이터셋을 보완할 수 있음을 확인함으로써 객체인식률을 개선할 수 있는 방법을 제안한다.","Utilizing drones for object detection presents a challenge in the construction field. Drones capture data from relatively high altitudes, resulting in images with a limited range of viewing angles for object formation, unlike the typical images used for object detection. These drone data characteristics impose constraints on the application and utilization of object detection models trained on general images. Therefore, methods tailored for drone data characteristics are required to enhance object detection performance. This study analyzed deep learning-based research projects and reviewed the literature to explore methods for enhancing the utility of drone-based object detection. The primary objective was to improve object detection rates in the construction industry by leveraging drone datasets. We investigated the conditions and requirements for enhancing object detection performance, applying typical data preprocessing to drone datasets and models such as you only look once (YOLO) and faster region-convolutional neural network (FRCNN). Additionally, we supplemented the datasets with low resolution images, to address challenging object feature extraction."
영상 객체 인식 기술을 활용한 알약 빅데이터 분석 시스템,2024,"['Medicine', 'Pills', 'Misuse', 'Combination', 'Object Detection']","오늘날 의학 기술이 발달로 인하여 다양한 종류의 약물이 존재한다. 이렇게 다양한 약물은 적절히 복용하면 간단하게는 영양 보충부터, 특정 증상/질병에 대한 예방/극복까지 할 수 있다. 이러한 약물은 적은 용량으로도 인간의 몸에 큰 영향을 미치기 때문에 대부분 전문 지식을 갖추고 있는 전문의의 철저한 관리하에 조제/제공되어야 한다. 하지만 실제 복용자는 실수로 잘못된 약물 조합을 복용할 수도 있으며, 이는 약물 오남용의 큰 부분을 차지한다. 본 논문은 이러한 문제를 극복하고자 객체 인식 모델을 활용하여 약물 이미지로 해당 약물 정보를 제공할 수 있는지 확인하고자 한다. 본 논문에서 제안하는 약물 구분 모델은 YOLO V8을 사용하였으며, 실험 결과 F1-Score 0.83, PR Curve 0.928, mAP50 92.5%의 결과를 달성하였다. 다양한 각도의 알약 이미지를 학습하기 위해 이미지 증강 기술로 학습한 모델임을 고려하면 높은 수준의 정확도와 재현율이 보인다고 판단한다. 향후 좀 더 다양한 약물의 종류와 이미지를 학습한다면 실제 서비스화가 가능할 것으로 보이며, ICD-10 코드 및 이용자 맞춤 서비스를 통해 약물 오남용 등의 문제도 해결할 수 있을 것이다.","Today, as medical technology advances, a variety of drugs are available. With this wide range ofmedications, they can be used for various purposes, from simple nutritional supplementation toprevention and management of specific symptoms or diseases, when taken appropriately. Thesemedications can have a significant impact on the human body even in small doses, which is why theyshould mostly be compounded and provided under the careful supervision of a healthcare professionalwith specialized knowledge. However, in reality, users may inadvertently consume the wrongcombination of drugs, contributing significantly to drug misuse. This paper aims to address these issuesby utilizing object detection models to provide drug information from drug images. The experimentalresults of the proposed drug classification model using YOLO V8 in this paper achieved a F1-Score of0.83, PR Curve of 0.928, and a mAP50 of 92.5%. Considering that the model was trained using imageaugmentation techniques to handle a variety of pill images from different angles, it is judged to exhibita high level of accuracy and recall. It appears that future deployment in real services is possible withthe inclusion of a more extensive range of drug types and images for training. Additionally, theincorporation of ICD-10 codes and personalized user services could help address issues related todrug misuse and other challenges."
체중 측정 정확도 향상을 위한 돼지 이미지 학습,2024,"['Learned images', 'video data', 'livestock pig farming', 'weight data', 'regression model', '이미지 학습', '영상 데이터', '축산 양돈', '체중 데이터', '회귀 모델']","가축의 생체중은 건강 및 사육 환경 관리에 중요한 정보이고 이를 통해 최적 사료량이나 출하시기 등을 결정하게 된다. 일반적으로 가축의 무게를 측정할 때 체중계를 이용하지만, 체중계를 이용한 가축 무게를 측정하는데 상당한 인력과 시간이 필요하고 성장 단계별 측정이 어려워 사료급이량 조절 등의 효과적인 사육 방법이 적용되지 못하는 단점이 있다. 본 연구는 축산 양돈 분야에 영상 및 이미지 데이터를 수집, 분석, 학습, 예측 등을 통해 포유자돈, 이유자돈, 육성돈, 비육돈 구간별 체중 측정에 관한 연구와 함께 정확도를 높이고자 하였다. 이를 위해 파이토치(pytorch), YOLO(you only look once) 5 모델, 사이킷런(scikit learn) 라이브러리를 사용하여 학습시킨 결과, 실제치(actual)와 예측치(prediction) 그래프에서 RMSE(root mean square error) 0.4%와 MAPE(mean absolute percentage error) 0.2%로 유사한 흐름을 확인할 수 있다. 이는 양돈 분야의 포유자돈, 이유자돈, 육성돈, 비육돈 구간에서 활용할 수 있으며 다각도로 학습된 이미지 및 영상데이터와 실제 측정된 체중 데이터를 바탕으로 지속적인 정확도 향상이 가능하고 향후 영상판독을 통해 돼지의 부유별 생산량에 대한 예측으로 효율적인 사육관리가 가능할 것으로 기대된다.","The live weight of livestock is important information for managing their health and housing conditions, and it can be used to determine the optimal amount of feed and the timing of shipment. In general, it takes a lot of human resources and time to weigh livestock using a scale, and it is not easy to measure each stage of growth, which prevents effective breeding methods such as feeding amount control from being applied. In this paper, we aims to improve the accuracy of weight measurement of piglets, weaned pigs, nursery pigs, and fattening pigs by collecting, analyzing, learning, and predicting video and image data in animal husbandry and pig farming. For this purpose, we trained using Pytorch, YOLO(you only look once) 5 model, and Scikit Learn library and found that the actual and prediction graphs showed a similar flow with a of RMSE(root mean square error) 0.4%. and MAPE(mean absolute percentage error) 0.2%. It can be utilized in the mammalian pig, weaning pig, nursery pig, and fattening pig sections. The accuracy is expected to be continuously improved based on variously trained image and video data and actual measured weight data. It is expected that efficient breeding management will be possible by predicting the production of pigs by part through video reading in the future."
Exploring the Feasibility of Neural Networks for Criminal Propensity Detection through Facial Features Analysis,2024,"['Neural networks', 'Criminal propensity detection', 'Facial feature extraction']",국문 초록 정보 없음,"While artificial neural networks are adept at identifying patterns, they can struggle to distinguish between actual correlations and false associations between extracted facial features and criminal behavior within the training data. These associations may not indicate causal connections. Socioeconomic factors, ethnicity, or even chance occurrences in the data can influence both facial features and criminal activity. Consequently, the artificial neural network might identify linked features without understanding the underlying cause. This raises concerns about incorrect linkages and potential misclassification of individuals based on features unrelated to criminal tendencies. To address this challenge, we propose a novel region-based training approach for artificial neural networks focused on criminal propensity detection. Instead of solely relying on overall facial recognition, the network would systematically analyze each facial feature in isolation. This fine-grained approach would enable the network to identify which specific features hold the strongest correlations with criminal activity within the training data. By focusing on these key features, the network can be optimized for more accurate and reliable criminal propensity prediction. This study examines the effectiveness of various algorithms for criminal propensity classification. We evaluate YOLO versions YOLOv5 and YOLOv8 alongside VGG-16. Our findings indicate that YOLO achieved the highest accuracy 0.93 in classifying criminal and non-criminal facial features. While these results are promising, we acknowledge the need for further research on bias and misclassification in criminal justice applications"
관측 조건 및 학습 구성에 따른 차량 검출 성능 분석,2024,"['YOLO (You Only Look Once)', 'deep learning', 'object detection', 'distance', 'angle', 'image resolution', 'dataset']",국문 초록 정보 없음,다국어 초록 정보 없음
타일링 이동 기법을 활용한 드론 영상 기반 농경정보 구축 방안 연구,2024,"['YOLO', 'Segmentation', 'Tiling Move', 'Image Overlab']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 객체 감지를 통한 금연 구역에서의 흡연 방지에 관한 연구,2024,"['YOLO', 'Object Detection', 'Quantization', 'Directional Speaker', 'Smoking']",국문 초록 정보 없음,다국어 초록 정보 없음
앙상블 YOLOv5 모델을 활용한 교통 약자 탐지 방법 연구,2024,"['Object Detection', 'YOLO', 'Ensemble', 'Traffic Vulnerable Detection', 'NMS', 'WBF', '객체 탐지', '앙상블', '교통약자 탐지']",국문 초록 정보 없음,다국어 초록 정보 없음
Development of an AI-based Real-time Monitoring System for Quality Assessment of 3D Printed Parts,2024,"['3D printing', 'YOLO', 'Monitoring', 'Vision']",국문 초록 정보 없음,다국어 초록 정보 없음
F-SORT 기반 고속도로 추월차로 지속 주행 무인 단속 시스템 설계,2024,"['F-SORT', 'YOLO', 'Object Tracking', 'Realtime', 'unmanned crackdown system']","한국 도로교통법에 따르면 고속도로 추월차선(1차선)에서 지속 주행 시, 지정차로위반으로 판단한다. 현재 고속도로에서 앞선 상황을 단속하기 위해서는 시민의 신고나, 도로 경찰이 직접 위반 여부를 판단하여 단속하고 있다. 이는, 고속도로에서 차량의 속도가 아닌 추월 여부에 따라 위반이 판단되고, CCTV에서는 차량이 지속해서 주행하고 있는지기준이 모호하여 판단이 힘들기 때문이다. 따라서, 사람의 개입 없이 시스템이 1차선 지속 주행 여부를 스스로 판단하고단속하는 시스템이 필요하다. 본 논문에서는 객체 추적 중에서 다중 객체 추적(Multiple Object Tracking)이 가능하고시스템의 실시간성을 보장하기 위해 SORT(Simple Online and Realtime Tracking) 모델을 기반한 F-SORT(Focus Simple Online and Realtime Tracking)를 기반하여 차량을 실시간으로 추적하고 차량의 이동 거리를 판단하여 1차선 지속 주행 여부를 시스템이 판단하여 단속하는 무인 단속 시스템을 설계하였다.","According to the Korean Road Traffic Act, continuous driving in the overtaking lane (1 lane) of the highway is judged as a violation of the designated lane. Currently, in order to crack down on the advanced situation on the highway, a citizen's report or the road police directly determine whether it is a violation and crack down. This is because a violation is judged by overtaking or not the speed of the vehicle on the highway, and it is difficult to judge whether the vehicle is continuously driving because the standard is ambiguous in CCTV. Therefore, a system that self-determines and regulates whether the first lane is continuously driving without human intervention is needed. In this paper, in order to enable multiple object tracking during object tracking and to ensure the system's real-time feasibility, an unmanned crackdown system was designed based on F-SORT (Focused-Simple Online and Realtime Tracking) based on the Simple Online and Realtime Tracking (SORT) model, and the system determines whether or not the vehicle is continuously driving in one lane by determining the moving distance of the vehicle"
딥러닝을 이용한 시각장애인용 횡단보도 탐지 모델 연구,2024,"['Deep Learning', 'YOLO', 'Object Detection', 'crosswalk', 'Visually impaired']",국문 초록 정보 없음,"Crosswalks play an important role for the safe movement of pedestrians in a complex urban environment. However, for the visually impaired, crosswalks can be a big risk factor. Although assistive tools such as braille blocks and acoustic traffic lights exist for safe walking, poor management can sometimes act as a hindrance to safety. This paper proposes a method to improve accuracy in a deep learning-based real-time crosswalk detection model that can be used in applications for pedestrian assistance for the disabled at the beginning. The image was binarized by utilizing the characteristic that the white line of the crosswalk image contrasts with the road surface, and through this, the crosswalk could be better recognized and the location of the crosswalk could be more accurately identified by using two models that learned the whole and the middle part of the crosswalk, respectively. In addition, it was intended to increase accuracy by creating a boundary box that recognizes crosswalks in two stages: whole and part. Through this method, additional frames that the detection model did not detect in RGB image learning from the crosswalk image could be detected."
카메라 기반 회랑 내 실시간 객체 탐지 시스템,2024,"['Edge computing', 'Yolo', 'Deep learning', 'Corridor monitoring', 'Object detecting']","도심 항공 모빌리티(UAM; urban air mobility)는 급증하는 도시권의 인구집중과 교통혼잡으로 인한 새로운 해결책으로서 차세대 교통수단으로 주목받고 있다. 하지만 이러한 UAM의 도입에 있어 기존의 교통 관리 체계(ATM; air traffic management)와는 다른 새로운 교통 관리 체계가 필요하며, 다양한 감시 시스템의 종류 중 하나로 해당 논문에서는 본 감시 시스템의 기능을 보조하는 측면으로서 UAM 감시 및 탐지 사용 기술로 카메라 센서를 사용한 단안 카메라 기반의 UAM 회랑 내 비행체의 2차 감시 시스템을 제안한다. 이에 실시간 객체 탐지 방법으로 이전 모델 대비 높은 FPS 성능과 첨단 백본 네트워크, 향상된 피라미드 구조를 사용하여 실시간 탐지에 우수한 YOLOv8 인공지능 연산 기술을 사용한다. 실제 외부 환경에서 학습된 알고리즘 기반으로 실험을 수행한 결과 객체를 정상적으로 탐지하는 것을 확인하였다.","Urban air mobility (UAM) is attracting attention as a next-generation transportation method as a new solution due to the rapidly increasing population concentration and traffic congestion in urban areas. However, the introduction of such UAM requires a new traffic management system different from the existing traffic management system (ATM), and as one of the types of surveillance systems, this paper proposes a secondary surveillance system of a flying object in a monocular camera-based UAM corridor using a camera sensor as a technology to assist the function of this surveillance system. Therefore, the real-time object detection method uses YOLOv8 artificial intelligence computational technology, which is superior for real-time detection using higher FPS performance, advanced backbone network, and improved pyramid structure compared to previous models. As a result of conducting experiments based on algorithms learned in the actual external environment, it was confirmed that objects were detected normally."
로봇 작업 공간 확장을 위한 인공지능 기반 pick-and-throw 로봇,2024,"['Robot grasping', 'Yolo object segmentation', 'Robot workspace']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 객체인식과 자율주행 기반 국방 무인 경계 및 정찰 시스템,2024,"['Object Detection', 'YOLO', 'SLAM', 'Navigation', 'Computer Vision']",국문 초록 정보 없음,다국어 초록 정보 없음
인간 자세 추정 기반 골프 스윙 자세 판별 자동화 알고리즘 개발,2024,"['Pose Estimation', 'YOLO V8', 'Webcam', 'Multi-Layer Perceptron', 'Golf Swing']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 객체인식이 가능한 스마트 카트,2024,"['Cart', 'Object Recognition', 'YOLO', 'Realtime']",국문 초록 정보 없음,다국어 초록 정보 없음
인공지능 로봇 관리 감독 프로그램 개발을 위한 기준선 인식 알고리즘 연구,2024,"['Line Detection', 'Piano Wire', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
시각지능 기술을 활용한 작업자 안전관제시스템 개발,2024,"['Visual Intelligence', 'Video Inference', 'Yolo Algorithm', 'Worker Safety', 'CCTV Monitoring System']",국문 초록 정보 없음,"Since the implementation of the Serious Accident Punishment Act, various attempts have been made in the field to prevent safety accidents and respond quickly when accidents occur. In particular, building a safety management operation system that monitors the site in real time using IoT technology is an issue. In this paper, we develop video inference technology using CCTV as a way to prevent worker safety accidents in high-risk industrial sites such as power plants. Based on this, we develop functions to detect worker falls, entry into hazardous areas, and fires in real time. We would like to introduce an intelligent worker safety control system implemented to control field events"
AI 객체인식기술 기반의 육안점검 모바일 정비지원체계 구현,2024,"['AI', '인공지능', '객체인식', 'YOLO', '모바일', '육안점검', '정비지원']",국문 초록 정보 없음,다국어 초록 정보 없음
SBC 컴퓨팅 환경에서 딥러닝을 이용한 자돈 압사 인식 성능 분석,2024,"['Smart pig farm', 'AIoT', 'YOLO', 'Deep learning', 'SBC.']",국문 초록 정보 없음,다국어 초록 정보 없음
영상처리 알고리즘을 이용한 테니스공 수거 로봇 개발,2024,"['Image Processing', 'Object Detection', 'YOLO', 'Tennis Ball Collection Robot']",국문 초록 정보 없음,다국어 초록 정보 없음
참외 인공 수분 자동화를 위한 실시간 암꽃 위치 인식 기술 개발,2024,"['automated pollination', 'object detection', 'yolo', 'stereo vision', '.']",국문 초록 정보 없음,"Automation in agriculture is increasingly viewed as a solution to current challenges, such as labor shortages, shifting consumer preferences, and ecological responsibility. Within agricultural automation, object detection and location estimation play crucial roles in developing automated task systems for the cultivation process. In this study, we aim to develop a female flower detection model and estimate the three-dimensional location for an automated pollination system for oriental melons. First, we employ real-time object detection models, YOLOv5 and YOLOv8, to identify female flowers and compare their performance in terms of detection accuracy and processing speed. Both YOLOv5 and YOLOv8 achieved high accuracy, with mAP50 scores exceeding 0.85. However, YOLOv8 demonstrated superior real-time processing capability. Second, we utilize depth information obtained from a stereo vision camera to estimate the three-dimensional locations of the flowers detected by the object detection model. To this end, we built a ROS (Robot operating system) based female flower localization system and analyzed the localization data for female flowers of oriental melons."
인물 객체의 3차원 인스턴스 분할 기술 연구,2024,"['Segmentation', 'Instance', 'SAM', 'YOLO', 'NeRF']",국문 초록 정보 없음,다국어 초록 정보 없음
신속하고 정확한 포트홀 탐지를 위한 영상 처리 및 라벨링 방법 비교 분석,2024,"['엣지검출', 'Object Detection', 'OpenCV', 'YOLO', 'labeling', 'Canny Edge Detection']",국문 초록 정보 없음,"This paper focuses on exploring methods for rapidly and accurately detecting potholes on roads, aiming to contribute to preventing vehicle damage and maintaining smooth traffic flow. The paper labels images with and without the application of Canny Edge Detection and grayscale, and compares the speed and accuracy of detection using YOLOv7. It is possible to swiftly and accurately detect potholes on the road, thereby ensuring vehicle damage prevention and passenger safety. Additionally, it is expected to provide important information for determining the priority of road maintenance tasks, improving traffic safety, and ultimately reducing long-term road maintenance costs."
CARLA를 활용한 전이학습 기반 객체 검출 데이터 셋 구축에 관한 연구,2024,"['object detection', 'autonomous driving', 'transfer learning', 'YOLO', 'CARLA', 'data construction', 'Bbox', '.']",국문 초록 정보 없음,.
히스토그램 평활화를 활용한 딥러닝 기반 야간 객체탐지 성능평가,2024,"['Nighttime', 'Object Detection', 'Histogram Equalization', 'YOLO', 'Deep Learning']",국문 초록 정보 없음,"The scientific guard system is operated for security operations on the front line. Recently, an artificial intelligence-based scientific guard system has been pilot-tested for performance enhancement.The defection incidents on the front lines in 2020 and 2022 showed that the nighttime object detection performance of a scientific border system is critical to ensuring successful security operations. The purpose of this study was to implement an artificial intelligence model that can improve the nighttime object detection performance and be applied to scientific guard systems. This paper proposed a deep learning-based model that can improve the object detection performance at night so that it can be applied to scientific guard systems. The nighttime object detection performance was improved by constructing test data and applying histogram equalization to the original and modified daytime and nighttime soldier images. Six datasets were then applied to YOLOv8 to produce the training models. The performance between models was compared, analyzed, and validated. As a result, the model performance trained with images using histogram equalization was improved compared to the model trained with the original images. The concepts presented in this study can be applied to actual scientific guard systems in the future."
재고 관리 및 도난 방지를 위한 영상분석 기반 무인 매장 관리 시스템,2024,"['무인 매장 솔루션', '실시간 영상인식', '경량화 YOLO 모델', '재고 관리', '도난 방지', 'Unmanned store solution', 'Real-time video analysis', 'Light-weight deep learning model', 'Stock management', 'and Theft prevention']",국문 초록 정보 없음,"This paper presents an unmanned store management system that can provide stock management and theft prevention for displayed products using a small camera that can monitor the shelves of sold products in small and medium-sized stores. This system is a service solution that integrates object recognition, real-time communication, security management, access management, and mobile authentication. The proposed system uses a custom YOLOv5-x model to recognize objects on the display, measure quantities in real time, and support real-time data communication with servers through Raspberry Pie. In addition, the number of objects in the database and the object recognition results are compared to detect suspected theft situations and provide burial images at the time of theft. The proposed unmanned store solution is expected to improve the efficiency of small and medium-sized unmanned store operations and contribute to responding to theft."
YOLOv5 및 다항 회귀 모델을 활용한사과나무의 착과량 예측 방법,2024,"['Deep Learning', 'Object recognition', 'Fruit number counting', 'YOLO series', 'Regression']","본 논문은 딥러닝 기반 객체 탐지 모델과 다항 회귀모델을 이용하여 사과나무에 열린 사과의 개수를 예측할 수 있는 새로운 알고리즘을 제안한다. 사과나무에 열린 사과의 개수를 측정하면 사과 생산량을 예측할 수 있고, 농산물 재해 보험금 산정을 위한 손실을평가하는 데에도 활용할 수 있다. 사과 착과량 측정을 위해 사과나무의 앞면과 뒷면을 촬영하였다. 촬영된 사진에서 사과를 식별하여 라벨링한 데이터 세트를 구축하였고, 이 데이터 세트를 활용하여 1단계 객체 탐지 방식의 CNN 모델을 학습시켰다. 그런데 사과나무에서 사과가 나뭇잎, 가지 등으로 가려진 경우 영상에 포착되지 않아 영상 인식 기반의 딥러닝 모델이 해당 사과를 인식하거나추론하는 것이 어렵다. 이 문제를 해결하기 위해, 우리는 두 단계로 이루어진 추론 과정을 제안한다. 첫 번째 단계에서는 영상 기반딥러닝 모델을 사용하여 사과나무의 양쪽에서 촬영한 사진에서 각각의 사과 개수를 측정한다. 두 번째 단계에서는 딥러닝 모델로 측정한 사과 개수의 합을 독립변수로, 사람이 실제로 과수원을 방문하여 카운트한 사과 개수를 종속변수로 설정하여 다항 회귀 분석을수행한다. 본 논문에서 제안하는 2단계 추론 시스템의 성능 평가 결과, 각 사과나무에서 사과 개수를 측정하는 평균 정확도가90.98%로 나타났다. 따라서 제안된 방법은 수작업으로 사과의 개수를 측정하는 데 드는 시간과 비용을 크게 절감할 수 있다. 또한,이 방법은 딥러닝 기반 착과량 예측의 새로운 기반 기술로 관련 분야에서 널리 활용될 수 있을 것이다.","In this paper, we propose a novel algorithm for predicting the number of apples on an apple tree using a deeplearning-based object detection model and a polynomial regression model. Measuring the number of apples on anapple tree can be used to predict apple yield and to assess losses for determining agricultural disaster insurancepayouts. To measure apple fruit load, we photographed the front and back sides of apple trees. We manuallylabeled the apples in the captured images to construct a dataset, which was then used to train a one-stage objectdetection CNN model. However, when apples on an apple tree are obscured by leaves, branches, or other parts ofthe tree, they may not be captured in images. Consequently, it becomes difficult for image recognition-based deeplearning models to detect or infer the presence of these apples. To address this issue, we propose a two-stageinference process. In the first stage, we utilize an image-based deep learning model to count the number of applesin photos taken from both sides of the apple tree. In the second stage, we conduct a polynomial regression analysis,using the total apple count from the deep learning model as the independent variable, and the actual number ofapples manually counted during an on-site visit to the orchard as the dependent variable. The performanceevaluation of the two-stage inference system proposed in this paper showed an average accuracy of 90.98% incounting the number of apples on each apple tree. Therefore, the proposed method can significantly reduce thetime and cost associated with manually counting apples. Furthermore, this approach has the potential to be widelyadopted as a new foundational technology for fruit load estimation in related fields using deep learning."
과수원 유해조류 추적을 위한 인공지능 알고리즘에 관한 연구,2024,"['harmful birds', 'tracking', 'artificial intelligent', 'deepsort', 'yolo', 'faster r-cnn']",국문 초록 정보 없음,다국어 초록 정보 없음
시각장애인을 위한 화폐 인식 시스템,2024,"['딥러닝(Deep Learning)', '영상인식((Image Recognition)', 'YOLO(You Only Look Once)', 'TTS(Text to Speech)']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLOv8 딥러닝 모델을 통한 새싹 채소의 부위별 길이 측정,2024,"['sprout vegetable', 'deep learning', 'phenotyping', 'YOLO']",국문 초록 정보 없음,"Deep learning has gained considerable interest in agricultural breeding research. While advances in sequencing technologies have made genotypic data collection easier in genomic breeding, phenotypic data collection remains labor intensive and time consuming. Furthermore, as traditional phenotypic data collection relies heavily on manual processes, the results may vary based on the researcher’s skill and criteria. Thus, automated phenotypic data collection is essential for addressing these challenges. In this study, we aimed to develop a deep learning model using the YOLOv8 framework to measure the lengths of hypocotyls and roots in sprout vegetables such as mung bean, cowpea, and soybean. Our model automates the measurement process, accurately identifies the hypocotyl and root using Roboflow, and subsequently measures their lengths with high precision in various legume species. This approach addresses the challenges of extensive phenotypic data collection, which is essential for genetic breeding and agricultural improvement. Our deep learning model facilitates consistent and accurate data collection in large-scale studies by controlling variables influenced by the researcher’s skills and criteria. This reduces errors and enhances data reliability and accuracy, which are crucial for successful breeding practices and agricultural research."
협동로봇과 AI 기술을 활용한 바리스타 로봇 연구,2024,"['Collaborative Robot(협동로봇)', 'You Only Look Once(YOLO', '실시간 객체 탐지 알고리즘)', 'Robot Operating System(ROS', '로봇 운영체제)']",국문 초록 정보 없음,"Collaborative robots, designed for direct interaction with humans have limited adaptability to environmental changes. This study addresses this limitation by implementing a barista robot system using AI technology. To overcome limitations of traditional collaborative robots, a model that applies a real-time object detection algorithm to a 6-degree-of-freedom robot arm to recognize and control the position of random cups is proposed. A coffee ordering application is developed, allowing users to place orders through the app, which the robot arm then automatically prepares. The system is connected to ROS via TCP/IP socket communication, performing various tasks through state transitions and gripper control. Experimental results confirmed that the barista robot could autonomously handle processes of ordering, preparing, and serving coffee."
고립된 국가유산을 위한 국가유산 관리 플랫폼 구현,2024,"['national heritage management', 'image processing', 'YOLO', 'time series senor data', 'MQTT']",국문 초록 정보 없음,"This paper implements a national heritage management platform considering the characteristics and types of alone cultural heritage. The platform utilizes devices such as multi-sensor devices, location tracking devices, and CCTV to provide services including CCTV-based intrusion monitoring for alone cultural heritage, video-based monitoring for theft/damage of cultural heritage, illegal intrusion monitoring, and GPS-based location tracking services. By utilizing this platform, it is possible to prevent theft of alone cultural heritage that is difficult to manage due to budget constraints and to preserve the value of cultural heritage. Based on this research background, this paper proposes optimized techniques to enhance the performance of the cultural heritage management platform, aiming to secure leading technologies in the field of theft prevention and tracking of cultural heritage."
LIDAR 및 360 카메라 센서 융합을 통한 전 방향 거리 및 객체 인식 기술 개발,2024,"['라이다', '욜로', '360 카메라', '객체 인식', 'yolo', 'lidar', '360 camera', 'object detection']",국문 초록 정보 없음,다국어 초록 정보 없음
건설자재 객체인식률 향상을 위한 Unity 기반 합성데이터 생성 방안,2024,"['합성데이터', 'Unity', '컴퓨터 비전', '객체인식', 'YOLO', 'synthetic data', 'unity', 'computer vision', 'object detection', 'you only look once']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 김부각 건조 반제품 표면 검출 모델 개발,2024,"['Deep learning', 'Object detection', 'Vison system', 'YOLO-v5', 'Kimbukak']",국문 초록 정보 없음,다국어 초록 정보 없음
YOLOX 모델의 미세조정을 통한 LWIR 영상 탐지 성능평가,2024,"['object detection', 'long wave infrared (LWIR)', 'YOLO', 'deep learning', '.']",국문 초록 정보 없음,"Owing to the rapid development of artificial intelligence technology, a range of data is being used for training neural networks. For example, studies using images with traditional RGB channels are predominant in the field of deep learning. Furthermore, the number of studies that employ RGB channel data is constantly increasing and they are achieving considerable performance enhancements. However, research on infrared images, including long wave infrared (LWIR), is neglected compared to RGB channel images. In this paper, we focus on LWIR data to evaluate the performance of YOLOX through a fine-tuning technique and confirm the possibility of applying pre-trained weights trained with RGB images to LWIR images. In addition to training the YOLOX model, we construct an LWIR image dataset to evaluate the performance of YOLOX. An experiment was conducted using pre-trained weights trained by RGB channel images and weights trained by our LWIR images. The results indicated clear differences in performance, achieving 3.2% and 54.2% of mean average precision (mAP), respectively. Our study confirmed that it is necessary to perform training through fine-tuning to ensure reliable performance depending on the lens performance, cooling characteristics of the infrared cameras, and wavelength band of the camera."
YOLOv5 및 다항 회귀 모델을 활용한 사과나무의 착과량 예측 방법,2024,"['Deep Learning', 'Object recognition', 'Fruit number counting', 'YOLO series', 'Regression']",국문 초록 정보 없음,다국어 초록 정보 없음
자율주행차량 실증을 통한 나이트비전 카메라의 성능검증,2024,"['Night Vision Camera', 'Autonomous Vehicle', 'Object Detection', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
2D 영상 특징점과 3D Point Cloud를 이용한 시든 잎의 절단점 검출 방법 개발,2024,"['robot vision', 'pose estimation', 'keypoint detection', 'YOLO', 'RANSAC', '.']",국문 초록 정보 없음,"In agriculture, removing withered leaves is crucial for maintaining crop quality and preventing pests and diseases. This paper proposes a method for estimating the pose of wilted leaves and removing wilted leaves. While estimating precisely 3D location and pose information is essential for this task, most of previous methods for pose estimation have difficulty in processing time due to the complexity of feature extraction from 3D point cloud. The proposed method utilizes the YOLOv8 keypoint detection model to obtain image information, and YOLOv7 instance segmentation to isolate the region of interest. We calculate the 3D coordinates of the cutting point and the 3D rotation of the wilted leaf by applying RANSAC plane fitting and projection on 3D point cloud, simplifying the information required for the task. The method was validated using five types of model plant pots, achieving an average processing time of 98.584 ms and an accuracy of 3.83 mm. Additionally, the method recorded a 78% success rate in the removal of withered leaves."
딥러닝과 지향성 스피커를 통한 유해조류 식별 및 퇴치에 따른 농작물 피해방지 효과에 대한 연구,2024,"['deep learning', 'object detection', 'directional speaker', 'YOLO V8']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 화재탐지 딥러닝 모델의 생성형 AI 적용에 관한 연구,2024,"['Real-time fire detection', 'Object detection', 'YOLO', 'Generative AI', 'Data augmentation']","최근 전기차 화재, 공장 화재와 같은 다양한 원인으로 실내 화재의 피해가 증가하고 있으며, 이를 실시간으로신속하고 정확하게 감지하기 위해 인공지능을 적용한 실시간 화재탐지 모델에 관한 연구가 활발히 수행되고있다.인공지능의 발전 속도가 빨라짐에 따라 현재 매우 높은 수준의 인공지능 모델이 상용화되고 있으며, 알고리즘을 수정하여 모델 성능을 유의미하게 개선하는 데는 한계가 존재한다. 이에 따라 데이터의 중요성이 부각되고있으며, 알고리즘을 개선하는 것보다 양질의 데이터를 확보하는 것이 인공지능 모델의 성능을 향상시키는데 더 중요한 요소로 여겨지고 있다. 그러나 화재의 경우 양질의 데이터를 확보하는 데 어려움이 있으며,산불 화재의 경우, 미국, 호주 및 EU에서는 국가 차원에서 데이터를 관리하고 빅데이터를 수집하고 있지만,실내 화재의 경우 데이터 수집이 매우 어려운 실정이다. 현재는 데이터를 확보하기 위해 데이터 증강 기법을사용하여 데이터 부족 문제를 해결하고 있지만, 적절하지 않은 데이터 증강 기법이나 과도한 데이터 증강은인공지능 모델의 성능 저하로 이어질 수 있다. 최근 생성형 AI의 발달이 고도화됨에 따라 우리 사회에 큰영향력을 행사하고 있으며, 이미지 생성 AI는 컴퓨터 비전 기술을 활용하여 실제와 유사한 이미지를 생성하고,다양한 이미지 데이터를 학습하여 새로운 이미지를 생성한다.본 연구에서는 실시간 실내 화재탐지 모델의 데이터 부족 문제를 해결하기 위해 기존의 데이터 증강 방식과생성형 AI를 통한 데이터 수집 방식을 각각 적용하여 실시간 실내 화재탐지 모델의 성능을 개선하고 데이터부족 문제를 해결하고자 하였다.",다국어 초록 정보 없음
Deep Learning for Multivariate Anomaly Detection in Advanced Manufacturing Execution Systems,2024,"['Anomaly Detection', 'Deep learning', 'Manufacturing Execution Systems', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
초기 화재 진압을 위한 자율주행 소방 로봇 시스템 설계,2024,"['Figthing Robot', 'Ros', 'Slam', 'Autonomous-Driving', 'Yolo-Cnn', 'Manipulator']",국문 초록 정보 없음,다국어 초록 정보 없음
UAV와 딥러닝을 활용한 야적퇴비 탐지 및 관리등급 산정,2024,"['무인항공기', '딥러닝', '인스턴스세그멘테이션', 'YOLOv8', '야적퇴비', 'Unmanned aerial vehicles', 'Deep learning', 'Instance segmentation', 'YOLOv8', 'Compost heap']",국문 초록 정보 없음,"This research assessed the applicability of the You Only Look Once (YOLO)v8 and DeepLabv3+models for the effective detection of compost heaps, identified as a significant source of non-pointsource pollution. Utilizing high-resolution imagery acquired through Unmanned Aerial Vehicles (UAVs),the study conducted a comprehensive comparison and analysis of the quantitative and qualitativeperformances. In the quantitative evaluation, the YOLOv8 model demonstrated superior performanceacross various metrics, particularly in its ability to accurately distinguish the presence or absence of coverson compost heaps. These outcomes imply that the YOLOv8 model is highly effective in the precisedetection and classification of compost heaps, thereby providing a novel approach for assessing themanagement grades of compost heaps and contributing to non-point source pollution management. Thisstudy suggests that utilizing UAVs and deep learning technologies for detecting and managing compostheaps can address the constraints linked to traditional field survey methods, thereby facilitating theestablishment of accurate and effective non-point source pollution management strategies, and contributingto the safeguarding of aquatic environments."
적외선 영상 전처리에 따른 딥러닝 기반의 객체 탐지 모델 성능 평가,2024,"['딥러닝', '영상 전처리', '객체 탐지', 'Deep Learning', 'Image Preprocessing', 'Object Detection', 'YOLO']","딥러닝 네트워크의 발전에 따라 적외선 영상을 딥러닝에 적용하려는 연구가 활발하게 이루어지고 있다. 다양한 탐지 모델에 적외선 영상을 적용하여 탐지 성능을 향상시키는 연구들이 있다. 하지만 대부분의 연구가딥러닝 네트워크의 구조를 변화시키는데 집중하였고 입력 영상의 특성에 따른 딥러닝 네트워크의 탐지 성능의차이에 대한 연구는 진행되지 않았다. 본 논문에서는 적외선 원 영상(RAW)을 획득하여 딥러닝 기반의 탐지모델에서 적외선 영상의 Min-max, Plateau, CLAHE 세 가지 전처리 기법에 따른 성능의 차이가 있는지 성능 평가 지표인 mAP(mean Average Precision)를 통해 확인하였다. Min-max 기법이 81%의 mAP를 보여주며 가장 좋은 성능을 나타내었고, CLAHE 기법이 차량 객체에 대해서 다른 전처리 기법 대비 약 2%의AP가 앞서는 성능을 보여주는 것을 확인하였다.","With advancements in deep learning networks, there is active research aiming to apply infrared images in deep learning field. Various studies enhance detection performance by integrating infrared imagery into diverse detection models. However, most research have focused on changing the structure of deep learning networks, and research investigating differences in detection performance of deep learning networks based on the characteristics of input images has been scarce. In this paper, we acquired raw data of low wave infrared images (LWIR) and evaluated the performance differences in deep learning-based detection models using three equalization preprocessing techniques: Min-max, Plateau, and Contrast Limited Adaptive Histogram Equalization (CLAHE).Our research shows that Min-max method achieves an mAP of 81% showing the best performane, and CLAHE outperforms other preprocessing methods by approximately 2% in average precision, specifically for vehicle detection tasks."
킥보드 수거 로봇 시스템,2024,"['Mobile Robot System', 'Swerve Drive', '6D Pose Estimation', 'PnP', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 1종 가축 전염병 모니터링 및 추적 시스템,2024,"['disease tracking', 'object detection', 'smart farm', 'jetson nano', 'YOLO', '.']","본 연구는 농가의 안전을 강화하고 가축 전염병 확산을 방지하기 위해 Jetson Nano 기반의 실시간 위험 요소 모니터링 및 추적 시스템을 제안한다. 이 시스템은 YOLOv7 모델을 활용하여 사람과 차량을 탐지하고, 탐지된 객체를 객체 관리 알고리즘으로 전달한다. 객체 관리 알고리즘은 사람과 차량의 객체를 추적·관리하며, 차량에 번호판 정보가 없을 경우 YOLOv8 모델을 사용한 번호판 인식 알고리즘을 통해 정보를 업데이트한다. 성능 평가 결과, Jetson Nano에서 사물 탐지 모델과 번호판 인식 모델은 각각 FPS 18.7, mAP@50 94.3%와 FPS 14.3, mAP@50 98.6%를 기록하였다. 본 시스템은 농장 출입 상황을 효과적으로 모니터링하며, 가축 전염병 확산 방지에 기여할 수 있는 실시간 대응 도구로 활용될 수 있다.","This study proposes a real-time risk factor monitoring and tracking system based on Jetson Nano to strengthen the safety of farmers and prevent the spread of livestock infectious diseases. This system uses the YOLOv7 model to detect people and vehicles and delivers the detected objects to an object management algorithm. The object management algorithm tracks and manages objects of people and vehicles and updates the information through the license plate recognition algorithm using the YOLOv8 model if there is no license plate information in the vehicle. As a result of the performance evaluation, in the Jetson Nano, the object detection model and the license plate recognition model recorded FPS 18.7, mAP@50 94.3%, and FPS 14.3, mAP@50 98.6% respectively. This system effectively monitors the farm access situation and can be used as a real-time response tool that can contribute to the prevention of the spread of livestock infectious diseases."
농업경영체 등록정보와 태양광 발전소 분포도를 활용한 농경지의 공간적 파편화 특성분석,2024,"['Solar panel facility', 'Cropland', 'FRAGSTATS', 'Spatial distribution', 'AI', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
깊이 추정 기반 안개 제거 알고리즘을 통한 실제 안개 환경에서의 검출 성능 향상,2024,"['foggy environment(안개환경)', 'haze removal(안개제거)', 'object detection(객체검출)', 'YOLO(욜로)', 'deep learning(딥러닝)']",국문 초록 정보 없음,다국어 초록 정보 없음
가두리 양식장에서 ROV를 이용한 어류 모니터링을 위한 고밀도로 사육되는 양식 어류 탐지에 관한 연구,2024,"['Fish Cage Farm(양식장)', 'ROV Underwater Camera(수중로봇 수중 카메라)', 'Fish Detection(어류탐지)', 'Fish Dorsal(어류 등)']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study of Novel Initial Fire Detection Algorithm Based on Deep Learning Method,2024,['Initial fi re detection · Smoke detector · Thermal camera · Deep learning · Yolo'],국문 초록 정보 없음,"A small ember, created by a chemical reaction between a substance and oxygen, can grow into a large fi re as temperature, wind, and weather conditions change. A growing fi re incident can have devastating consequences, including property loss, environmental damage, and loss of life, which is why early fi re detection is so important. There are various detection devices such as smoke detectors, heat detectors, fi re detectors, and gas detectors that can be used in the early stages of a fi re. While early fi re detection system developments incorporating IoT technology are emerging in various industries, Smoke alarms, the most common type of smoke detector in homes and offi ces, accounted for 96.6% of all malfunctions from 2021 to July of the previous year, totaling 249,445 incidents. The analysis of detector malfunctions showed that non-fi re alarm factors such as food, cooking, and dust accounted for the largest share of 40.6%. This paper proposes an algorithm for early fi re detection by incorporating a deep learning-based model to compensate for the problem of non-fi re warning malfunctions, which is a shortcoming of existing detectors. Finally, for fi re detection, a bounding box for the fi re is specifi ed using a smoke detector, a thermal imaging camera, and a webcam camera trained with the Yolov7 model.Then, we propose an algorithm to remove the bounding box of non-fi re reports and malfunctions from the heating map using smoke detectors and thermal imaging cameras. After applying the algorithm proposed in this paper, only fi res with heat sources are recognized, and all bounding boxes for non-fi re reports are removed."
Online to Offline 상점의 자동화 : 초소형 깊이의 Yolov8과 특징점 기반의 상품 인식,2024,"['Online to Offline(O2O)', 'Automation', 'Object Detection', 'Feature Matching', 'YOLO']",국문 초록 정보 없음,다국어 초록 정보 없음
SoC 기반의 엣지 디바이스를 위한 Yolov5M 경량화 및 최적화에 관한 연구,2024,"['AI', 'Deep Learning', 'Lightweight', 'Optimization', 'Edge Device', 'SoC', 'NPU', 'CCTV', 'Yolo']",국문 초록 정보 없음,"Recently, intelligent systems with artificial intelligence have been basically adopted in the field of CCTV, and the method of analyzing images input from CCTV using deep learning algorithms is mainly used in the server. However, image quality deterioration may occur in the process of transmitting and storing images, reliability is difficult to be guaranteed in terms of security, and continuous investment in server construction and management is required. When building a CCTV network using an SoC-based edge device equipped with NPU functions, these shortcomings can be overcome and better quality services can be provided. However, since lower performance NPU must be utilized compared to the server, various studies should be accompanied to reduce the weight of the deep learning model and improve accuracy. In this paper, we implemented a deep learning model that can guarantee high speed and accuracy by optimizing and lightweighting the Yolov5M model specialized for the NPU environment using the NAS (Neural Architecture Search) technique."
딥러닝 기반 방울토마토 수확 로봇의 숙도 판별을 위한 YOLOv5와 YOLOv8의 성능 비교에 관한 연구,2024,"['Deep learning', 'Harvesting robot', 'Object detection', 'Cherry tomato', 'YOLO(You Only Look Once)']",국문 초록 정보 없음,다국어 초록 정보 없음
실시간 객체 검출 기술 YOLOv5를 이용한 스마트 엘리베이터 시스템에 관한 연구,2024,[],국문 초록 정보 없음,"In this paper, a smart elevator system was studied using real-time object detection technology based on YOLO(You only look once)v5. When an external elevator button is pressed, the YOLOv5 model analyzes the camera video to determine whether there are people waiting, and if it determines that there are no people waiting, the button is automatically canceled. The study introduces an effective method of implementing object detection and communication technology through YOLOv5 and MQTT (Message Queuing Telemetry Transport) used in the Internet of Things. And using this, we implemented a smart elevator system that determines in real time whether there are people waiting. The proposed system can play the role of CCTV (closed-circuit television) while reducing unnecessary power consumption. Therefore, the proposed smart elevator system is expected to contribute to safety and security issues."
실시간 항공영상 기반 UAV-USV 간 협응 유도·제어 알고리즘 개발,2024,"['UAV(Unmanned Aerial Vehicle', '무인항공기)', 'USV(Unmanned Surface Vessel', '무인수상선)', 'ROS(Robot Operating System', '로봇운영체제)', 'YOLO(You Only Look Once', '딥러닝 모델)', 'Path planning(경로 계획)']",국문 초록 정보 없음,다국어 초록 정보 없음
Real-Time Comprehensive Assistance for Visually Impaired Navigation,2024,"['Visual impairment', 'Object detection', 'Machine learning', 'Computer vision', 'Voice command functionality', 'You-Only-Look-Once (YOLO)']",국문 초록 정보 없음,"Individuals with visual impairments face numerous challenges in their daily lives, with navigating streets and public spaces being particularly daunting. The inability to identify safe crossing locations and assess the feasibility of crossing significantly restricts their mobility and independence. Globally, an estimated 285 million people suffer from visual impairment, with 39 million categorized as blind and 246 million as visually impaired, according to the World Health Organization. In Saudi Arabia alone, there are approximately 159 thousand blind individuals, as per unofficial statistics. The profound impact of visual impairments on daily activities underscores the urgent need for solutions to improve mobility and enhance safety. This study aims to address this pressing issue by leveraging computer vision and deep learning techniques to enhance object detection capabilities. Two models were trained to detect objects: one focused on street crossing obstacles, and the other aimed to search for objects. The first model was trained on a dataset comprising 5283 images of road obstacles and traffic signals, annotated to create a labeled dataset. Subsequently, it was trained using the YOLOv8 and YOLOv5 models, with YOLOv5 achieving a satisfactory accuracy of 84%. The second model was trained on the COCO dataset using YOLOv5, yielding an impressive accuracy of 94%. By improving object detection capabilities through advanced technology, this research seeks to empower individuals with visual impairments, enhancing their mobility, independence, and overall quality of life."
UWB를 활용한 시각장애인용 스마트고글,2024,"['초광대역 센서', '삼변 측위', '칼만 필터', '라즈베리 파이', '머신 러닝', 'UWB(DWM1000)', 'Triangulation', 'Kalman Filter', 'Raspberry Pi', 'YOLO', 'Machine Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
자율주행 반사광 적응형 다각도 편광영상 기반 객체 인식 기술,2024,"['Multi-angle polarized camera(다각도 편광카메라)', 'Semantic segmentation(의미적 분할)', 'Autonomous driving(자율주행)', 'YOLO(욜로)', 'Image processing(이미지 처리)']",국문 초록 정보 없음,"We propose the introduction of the multi-angle polarized camera in the autonomous driving system. Robust sensor perception capabilities in adverse conditions are essential for achieving Level 4 autonomous driving. As seen in the Tesla accident case, performance degradation due to reflections can be catastrophic. The multi-angle polarized camera can analyze polarization components at four different angles[0°/45°/90°/135°]. It can enable the application of reflection removal algorithms. We compared the recognition performance of image processing methods with Glare Reduction and Merge algorithms using the YOLOv8 segmentation model. Glare reduction, which removes reflections, showed higher map performance compared to merged images, indicating the effectiveness of multi-angle polarization cameras in autonomous driving environments."
꼬리물기 무인교통단속장비의 설치 효과 분석,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
출입자 안전장구 검출 시스템 연구,2024,"['엣지 디바이스', '지능형 영상 분석', '개인 안전 장구', '욜로-타이니 모델', 'Edge device', 'intelligent video analysis', 'PPE(Personal Protective Equipment)', 'YOLO-tiny model']",국문 초록 정보 없음,"The safety of workers at industrial sites is a critical issue, and various facilities and regulations are in place to ensure safety. Among these, the most important factor is raising field workers' awareness of wearing safety equipment. However, many workers neglect to wear such equipment due to inconvenience or the demands of their tasks. Furthermore, with the expansion of the *Serious Accident Punishment Act* to include workplaces with fewer than 50 employees starting in 2024, the establishment and implementation of a safety and health management system led by management have become essential.In response to this, this paper proposes a system that can detect whether workers are wearing safety gear upon entering the worksite. It also explores the development of an operational environment to encourage compliance and validate its effectiveness through field testing. Building a video analysis system powered by a high-end GPU, however, can impose a significant financial burden. To address this, the study introduces a solution leveraging an edge device-based system for intelligent video analysis, aiming to create a product that can be easily deployed in the field."
YOLOv8과 무인항공기를 활용한 고해상도 해안쓰레기 매핑,2024,[],국문 초록 정보 없음,"Coastal debris presents a significant environmental threat globally. This research sought to improve the monitoring methods for coastal debris by employing deep learning and remote sensing technologies. To achieve this, an object detection approach utilizing the You Only Look Once (YOLO)v8 model was implemented to develop a comprehensive image dataset for 11 primary types of coastal debris in our country, proposing a protocol for the real-time detection and analysis of debris. Drone imagery was collected over Sinja Island, situated at the estuary of the Nakdong River, and analyzed using our custom YOLOv8-based analysis program to identify type-specific hotspots of coastal debris. The deployment of these mapping and analysis methodologies is anticipated to be effectively utilized in managing coastal debris."
가상환경에서 해상 풍력 발전기용 UAV를 위한 광 카메라 (OCC) 기술 연구,2024,"['Optical camera communication', 'Offshore wind generator', 'UAV', 'Virtual environment']","본 논문은 광 카메라 통신(Optical Camera Communication; OCC)를 이용하여 문제가 발생한 풍력발전기의 위치정보 및 상태정보를 무인항공기(Unmanned Aerial Vehicle; UAV)를 통해 얻는 활용 방안을 가상환경 시뮬레이션으로 구현하였다. 시뮬레이션은 Unreal Engine 4로 진행하였으며, 시뮬레이션으로 구현된 해상 풍력 단지를 UAV의 카메라로 촬영한 후 YOLO v5를 이용하여 실시간으로 LED의 위치를 검출하였다. 그리고 검출된 영역을 통해 LED의 색 패턴을 판별하고 판별된 색 패턴을 통해 문제가 발생한 발전기의 위치 및 상태를 판단할 수 있음을 확인하였다.","In this paper, we propose a method utilizing Optical Camera Communication (OCC) to obtain the location and status information of problematic wind generator through Unmanned Aerial Vehicle (UAV). The simulation is conducted using Unreal Engine 4. The offshore wind farm implemented using the Unreal Engine 4 simulation is captured by the UAV's camera, and real-time detection of LED positions is carried out using YOLOv5. Subsequently, the color patterns of the detected areas are analyzed. Through this analysis, it is confirmed that the precise location and status of the problematic wind generators can be accurately determined."
실시간 임베디드 에지 컴퓨팅을 위한 Camera-LiDAR 후기 융합 기반 교통 참여자 검출,2024,"['Object detection (물체 검출)', 'Edge computing (에지 컴퓨팅)', 'Embedded system (임베디드 시스템)', 'LiDAR (라이다)', 'RGB camera (컬러 카메라)', 'Sensor fusion (센서 융합)']",국문 초록 정보 없음,"Recently, the fusion of camera and LiDAR has been widely studied for accurately perceiving the surrounding environment. This paper proposes a late fusion method that combines the outputs of these two sensors. YOLOv7 was used for camera-based detection, while Complex YOLO was employed for LiDAR-based detection. Both networks were embedded into QCS610 after being simplified through channel pruning and post-training quantization. The outputs of the two methods are fused via Hungarian algorithm-based matching. In experiments, the proposed method showed a reliable detection result on the public dataset A9."
Grid and Layout Generator,2024,"['Book Design', 'Workload', 'Timesaving', 'Automatic', 'Template']",국문 초록 정보 없음,"With increasing demands in today’s fast-paced society, designers face significant workload pressures, often leading to overlooked details and burnout. This paper introduces the Grid and Layout Generator, an AI-driven tool utilizing Bert and Yolo word-to-vector technology and similarity scores, which is one of the recommendation systems, designed to streamline book design by recommending optimized layouts and grids based on book dimensions and text volume, enhancing readability and efficiency. In a study involving book designers and avid readers, eye-tracking and reading speed analysis showed improved readability with the generated layouts. Results suggest that the tool can reduce book design time by 20%, highlighting its potential to alleviate design workload while improving reader engagement and comprehension."
딥러닝 기반 실시간 객체 인식을 지원하는  대형차량용 360도 3D 어라운드뷰 시스템에 관한 연구,2024,"['Surround View Monitoring', 'SVM', 'Automatic Calibration', 'Vehicle Safety Systems']",국문 초록 정보 없음,"This study proposes the design and implementation of a deep learning-based real-time object recognition supported 360-degree 3D around-view system to address the blind spot issues in large vehicles. Unlike passenger cars, large vehicles have more extensive blind spots due to their size and structure, making it difficult for drivers to fully perceive the surrounding environment. The proposed system utilizes the YOLO algorithm for object detection and a multi-camera setup to generate an optimized 360-degree view of the surroundings. The system also incorporates automatic calibration technology, using 3D mesh correction data to stitch the camera inputs seamlessly. Experimental results show that the system achieves high frame rates and object recognition accuracy, effectively enhancing the driver's situational awareness and safety. The system has the potential for wider applications in various large transportation vehicles, such as trucks and buses, contributing to road safety and accident prevention."
Dental Age Estimation in Children Using Convolution Neural Network Algorithm: A Pilot Study,2024,"['Convolutional neural networks', 'Deep learning', 'Dental age estimation']",국문 초록 정보 없음,"Purpose: Recently, deep learning techniques have been introduced for age estimation, with automated methods based on radiographic analysis demonstrating high accuracy. In this study, we applied convolutional neural network (CNN) techniques to the lower dentition area on orthopantomograms (OPGs) of children to develop an automated age estimation model and evaluate its accuracy for use in forensic dentistry.Methods: In this study, OPGs of 2,856 subjects aged 3-14 years were analyzed. The You Only Look Once (YOLO) V8 object detection technique was applied to extract the mandibular dentition area on OPGs, designating it as the region of interest (ROI). First, 200 radiographs were randomly selected, and were used to train a model for extracting the ROI. The trained model was then applied to the entire dataset. For the CNN image classification task, 80% of OPGs were allocated to the training set, while the remaining 20% were used as the test set. A transfer learning approach was employed using the ResNet50 and VGG19 backbone models, with an ensemble technique combining these models to improve performance. The mean absolute error (MAE) on the test set was used as the validation metric, and the model with the lowest MAE was selected.Results: In this study, the age estimation model developed using mandibular dentition region from OPGs achieved MAE and root mean squared error (RMSE) values of 0.501 and 0.742, respectively, on the test set, and MAE and RMSE values of 0.273 and 0.354, respectively, on the training set.Conclusions: The automated age estimation model developed in this study demonstrated accuracy comparable to that of previous research and shows potential for applications in forensic investigations. Increasing the sample size and incorporating diverse deep learning techniques are expected to further enhance the accuracy of future age estimation models."
화염 이미지 기반 열방출율 예측에 관한 기초 연구,2024,"['Heat release rate prediction', 'Flame image', 'Deep learning', 'Flame segmentation', 'Performance evaluation']","화재 열방출율은 화재의 크기, 성장 등 화재 특성을 결정짓는 중요한 인자로서 가연물의 열방출율을 측정및 예측하는 것은 화재 발생 특성 파악 및 화재 대응을 위해 필수적이다. 현재 가연물의 열방출 특성을 규명하기위해서 산소소모법을 이용한 콘칼로리미터 등 다양한 방법론을 통해 열방출률을 측정하고 있으나 고도의기술력과 비용이 요구되고 있다. 따라서 본 연구에서는 화재 발생 영상의 화염 영역 검출 기반 실시간 화재열방출율 예측 방법을 제시하고 이에 대한 예측 성능을 평가하였다. 다양한 화재 발생 이미지 기반 학습을통하여 화염 영역 검출에 최적화된 딥러닝 모델(YOLO segmentation)을 도출하였다. 이를 통해 실시간 화재발생 영상의 화염 영역 검출 및 픽셀 위치 정보 추출을 통하여 화염의 직경 및 화염 높이를 정량화하고 Heskestad상관식과 Zukoski 상관식을 이용하여 실시간 화재 열방출율을 예측하였다. 화염 이미지와 열방출율 데이터를포함한 실험을 대상으로 화염 영역 검출 및 열방출율 예측을 수행하고 실험 결과와 비교 분석하였다. Intersectionover Union (IoU) 평가지표를 활용하여 딥러닝 모델의 화염 영역 검출 성능을 평가하고 Mean Average Error(MAE) 평가지표를 이용하여 실시간 화재 열방출율 예측 성능을 정략적으로 평가하였다. 평가 결과, 이미지기반 실시간 화재 열방출율 예측 가능성을 확인하였으며 예측 정확도 향상을 위한 개선 사항을 제시하였다.",다국어 초록 정보 없음
PolyLaneDet: Lane Detection with Free-Form Polyline,2024,"['Lane detection', 'CNN', 'Deep learning']",국문 초록 정보 없음,"Lane detection is a critical component of autonomous driving technologies that face challengessuch as varied road conditions and diverse lane orientations. In this study, we aim to addressthese challenges by proposing PolyLaneDet, a novel lane detection model that utilizes a freeform polyline, termed ‘polylane,’ which adapts to both vertical and horizontal lane orientationswithout the need for post-processing. Our method builds on the YOLO v4 architecture toavoid restricting the number of detectable lanes. This model can regress both vertical andhorizontal coordinates, thereby improving the adaptability and accuracy of lane detection invarious scenarios. We conducted extensive experiments using the CULane benchmark and acustom dataset to validate the effectiveness of the proposed approach. The results demonstratethat PolyLaneDet achieves a competitive performance, particularly in detecting horizontallane markings and stop lines, which are often omitted in traditional models. In conclusion,PolyLaneDet advances lane detection technology by combining flexible lane representationwith robust detection capabilities, making it suitable for real-world applications with diverseroad geometries."
수중 환경에서 3D 카메라와 YOLOv8를 활용한 물고기 크기 측정 시스템 개발에 관한 연구,2024,[],"본 연구는 수중 환경에서 3D 카메라(RealSense D435i)를 활용하여 딥러닝 및 컴퓨터 비전 기술을 통합한 어류 크기 측정 시스템을 개발한다. 이 시스템은 굴절 현상으로 인해 발생하는 좌표 왜곡을 기준 객체를 이용해 보정하는 방법을 도입한다. 또한, YOLOv8 모델을 활용하여 어류의 머리와 꼬리를 정밀하게 탐지하고, 이 데이터를 기반으로 어류의 전체 길이를 측정하는 알고리즘을 개발하였다. 기존의 사각형 바운딩 박스를 사용하는 YOLO 모델 대신 원형 바운딩 박스를 사용함으로써 어류 크기 측정의 정확성과 간편성을 향상시키는 새로운 방법을 제안한다.",다국어 초록 정보 없음
도로 이상 탐지 기술 동향과 딥러닝 기반 포트홀 탐지 알고리즘,2024,[],국문 초록 정보 없음,"Recent advancements in computer vision, machine learning, and deep learning technologies have led to a shift from manual inspection methods to automated detection systems utilizing ICT technologies such as sensors, drones, and computer vision. In this study, we examine the current state of road anomaly detection technologies based on patents and propose a deep learning-based pothole detection technique for road anomaly detection systems. The proposed model is built upon YOLO v8 and is capable of identifying the location and presence of potholes, achieving a performance index mAP50 of 0.754. This suggests its potential effectiveness for efficient application in road anomaly detection."
이미지 내 다중 음원 객체 분석을 통한 스테레오 오디오 생성,2024,"['이미지-오디오 생성', '스테레오 오디오', '다중 객체 음원 탐지', '멀티 모달 AI', '생성형 AI', 'Image-to-Audio Generation', 'Stereo Audio', 'Multiobject Sound-Source Detection', 'Multimodal', 'Generative AI']",국문 초록 정보 없음,"Image-to-audio (I2A) technology has recently gained significant attention in the field of artificial intelligence. However, existing methods primarily focus on single-channel audio generation based on input images consisting of a single object, leading to issues such as blending of sound sources and missing audio elements in images consisting of multiple objecs. To address these limitations, we propose a novel approach for generating multi-source stereo audio from images containing multiple sound-producing objects. We employ YOLO (You Only Look Once) to detect multiple sound-producing objects and AudioLDM to generate distinct audio for each detected object. Subsequently, these individually generated audio sources are converted into stereo audio based on the sizes and positions of the corresponding objects. We evaluated the proposed model on a custom-built dataset comprising multiobject images paired with multisource audio, and it outperformed all baseline models across all metrics. This research overcomes the limitations of current I2A technologies by effectively handling complex, multisource scenarios, thereby advancing the field of audio generation."
2축식 드론 추적 로봇의 제어기 설계 및 선정 방안 연구,2024,"['2DOF robot(2자유도 로봇)', 'Trracking(추적)', 'PID(비례제어기)', 'SMC(슬라이딩모드제어)', 'MPC(모델 예측제어)']",국문 초록 정보 없음,"This study compared performances of PID (Proportional Integral Derivative), SMC (Sliding Mode Control), and MPC (Model Predictive Control) strategies applied to a 2DOF (Degree Of Freedom) drone tracking robot. The developed 2DOF robot utilized a depth camera with an IMU (Inertial Measurement Unit), laser pointers, and servo motors to rapidly detect and track objects. Image processing was conducted using the YOLO deep learning model. Through this setup, controllers were attached to the robot to track random drone movements, comparing performances in terms of accuracy and energy consumption. This study revealed that while SMC demonstrated precise tracking without deviating from the path, both PID and MPC controllers showed deviations. Performance-wise, SMC is superior. However, considering economic aspects, PID is more advantageous due to its lower power consumption and relatively minor tracking errors."
Prioritization of Search/Restoring Operations in Disaster Sites Using Computer Vision,2024,[],국문 초록 정보 없음,"In the aftermath of earthquakes, both living and non-living structures often suffer extensive damage, making rescue operations challenging and critical. The deployment of drones in earthquake disaster <BR/>management has emerged as a valuable innovation, offering real-time aerial imagery that can significantly enhance rescue efforts. This research focuses on the application of drone-captured images to identify and prioritize affected individuals using advanced machine-learning (ML) techniques. Specifically, we are developing a model utilizing You Only Look Once (YOLO) and Convolutional Neural Networks (CNN) to analyze drone images for detecting injured or distressed individuals. The primary objective of this model is to ensure the safety and well-being of individuals impacted by the earthquake. In addition to<BR/>prioritizing human safety, the research aims to facilitate the restoration of essential services such as electricity, which is critical for effective rescue operations and the overall comfort of affected individuals. The study will also explore the creation of a strategic plan that outlines a clear and actionable pathway for search and rescue teams (SAR). This plan will guide the teams in efficiently navigating the disaster area and executing their rescue operations systematically. By integrating these technological advancements with strategic planning, the research aims to enhance the efficiency and effectiveness of earthquake<BR/>disaster response, ultimately improving outcomes for those affected by such catastrophic events."
AI기술을 활용한 재난 예방 및 대응 시스템 개발에 관한 연구,2024,"['Deep learning applications', 'Earthquake detection', 'Fire detection', 'Industrial disaster prevention', 'Real-time data analysis']","현대 사회에서 문명의 발전과 산업 활동 증가로 자연재해 및 인공재해 발생 빈도가 증가하고 있다. 본연구에서는 다양한 재난 유형에 딥러닝 기술을 적용 및 재난 예방 및 대응 시스템의 효율성을 향상시키는방안을 제안하였다. 지진 감지 분야에서는 Convolutional Neural Network (CNN) 기반 U-Net 모델을 활용하여지진의 P파 첫 도착 시점을 정확하고 신속하게 감지하였다. 이 모델은 기존의 센서 기반 시스템보다 빠르게지진 신호를 분석하여, 초기 경보 시스템의 반응 시간을 단축시키는 데 기여하였다.화재 감지 분야에서는 고해상도 화재 연기 이미지와 다양한 패턴의 화염 이미지를 활용하여 초기 화재징후를 정확히 식별할 수 있는 딥러닝 모델을 구현하였다. 이 모델은 연기와 불꽃의 시각적 특성을 학습하여복잡한 환경에서도 화재 발생 초기에 빠르게 반응할 수 있도록 개발하였다. 특히, Faster R-CNN, YOLO, SwinTransformer, Separable Convolution layer 등 다양한 CNN 기반 알고리즘을 활용하여 화재 감지 속도와 정확도를개선하였다. 또한, Si 기반 Color 센서를 활용한 화재 감지 방식은 주변 밝기 측정을 통해 빛의 변화를 감지함으로써, 화재를 신속하고 정확하게 탐지할 수 있는 장점이 있다. 이 기술을 활용하면 기존 열, 연기, 불꽃 감지기의온도 변화나 다른 열원의 영향으로 인한 오작동 문제를 상당 부분 해결할 수 있다.산업 재해 예방을 위해 회전체 기계에서 발생하는 소리 신호를 스펙트로그램으로 변환하여 2차원 소리패턴을 분석, 고장을 조기에 감지하는 딥러닝 시스템을 개발하였다. 이 시스템은 장비의 예기치 않은 중단없이 지속적인 생산성을 유지하는 데 중요한 역할을 수행한다. 본 연구에서 개발된 딥러닝 기반 기술들은실시간 데이터 분석과 정밀한 패턴 인식을 통해 재난 상황에서 신속하고 정확한 의사 결정을 가능하게 하며,재난 대응 시스템의 전반적인 성능을 향상시킬 것으로 기대된다.",다국어 초록 정보 없음
이미지 딥러닝을 이용한 건설현장 안전모 미착용 인식에 대한 연구,2024,"['안전모', '객체인식', '이미지 딥러닝', 'Safety helmet', 'Object detection', 'Image deep learning']",건설현장에 개인보호 미착용에 따른 사고가 자주 발생한다. 산업재해 통계에 따르면 건설업 근로자의 주요 사망원인 중 하나가 안전모 미착용이고 현장에서는 안전모 착용을 위해 다양한 노력을 하고 있으나 이를 잘 지키지 못하는 것이 현실이다. 보호구 착용 관리를 효율적으로 하는 방법 중에는 CCTV 기반 이미지 딥러닝 알고리즘을 활용하는 것이 있으며 건설현장 이미지 데이터를 기반으로 Convolutional Neural Network(CNN) 알고리즘을 적용하여 안전모의 착용 및 미착용 인식을 통해 작업자의 안전모 착용 준수를 확인할 수 있는 다양한 방법들이 제안되고 있다. 이는 건설현장 근로자의 안전모 착용 준수 여부를 확인하고 안전 수칙 위반 근로자를 식별하여 안전관리에 도움을 줄 수 있다. 이에 본 연구에서 우리는 YouOnly Look Once(YOLO)를 활용하여 근로자의 안전모 미착용 여부를 효과적으로 판단할 수 있는 모델 구축 방법론을 제시하였다. CIS 공개 데이터 셋을 적용하여 안전모 미착용 근로자 검출을 위한 최적의 변수와 데이터 비율을 선정하고 다양한 학습과 검증을 통해 도출된 분석결과를 통해 얻은 안전모 착용 및 미착용 데이터 분포에 따른 판별 정확도 및 오차 분석을 통해 현장 활용성을 높이고자 하였다.,"The most common accidents at construction sites are caused by not wearing personal protective equipment. According to industrial accidents statistics, one of the main death causes is not wearing safety helmets, and although various efforts have been made to have workers wear safety helmets. One of the ways to manage the wearing of safety helmet is to use CCTV-based image deep learning algorithm, so various methods have been proposed to confirm workers' compliance with wearing safety helmets by the CNN. This can help with safety management by checking whether workers are complying with wearing safety helmets and identifying workers who violate safety rules. In this study, we proposed a model construction methodology that can effectively determine whether workers are not wearing safety helmets by utilizing YOLOv9. With CIS data set, we selected the optimal variables and data ratio for detecting workers not wearing safety helmets, and we aimed to increase field usability by analyzing the discrimination accuracy and error according to the distribution of data on wearing or not wearing safety helmets derived through various learning and verification."
시각화 기반의 시계열 음향 분류에서의 플롯 크기의 영향력 분석,2024,"['Deep Learning', 'Convolutional Neural Network(CNN)', 'Time-series', 'Vision AI', '딥러닝', '합성곱 신경망', '시계열', '영상 인공지능']",국문 초록 정보 없음,"In recent years, visualizing time-series data as images for use in vision-based Artificial Intelligence (AI) models has gained significant attention. This approach transforms temporal sequences into images that can be processed by deep learning models, such as Convolutional Neural Network (CNN).Although its effectiveness has been demonstrated in various domains, the impact of plot size on model performance remains underexplored. In this study, we investigate the effect of varying plot sizes on classification accuracy by visualizing natural sounds (e.g., cats, crows) and testing five classes of 2,000 samples each using the YOLO model. While training was conducted on 320x320 plots, test sets were generated at six sizes (112x112 to 640x640). Results show that as the plot size of the test dataset diverged from that of the training dataset, both precision and recall decreased, highlighting the importance of plot size consistency in time-series visualization research."
PBL 문제 개발에 대한 교수자의 평가 분석 연구 - 외국인 유학생 대상 글쓰기 수업을 중심으로,2024,"['PBL 문제 개발', '문제중심학습', '쓰기 교육', '외국인 유학생', '글쓰기 수업', 'PBL(Problem-Based Learning)', 'PBL Problem Development', 'Problem-Based Learning', 'Writing Education', 'Foreign Students', 'Writing Classes']",국문 초록 정보 없음,"The purpose of this study is to evaluate the “PBL problem” used in writing classes for foreign students by experienced instructors and suggest directions necessary for developing PBL problems in the future through analysis results.Other experienced instructors evaluated the problems used in PBL classes in writing classes in universities. There were a total of 5 PBL questions to be evaluated: (A) study abroad life, (B) the amount of reading by college students, (C) people studying in coffee shops, (D) the Yolo people, (E) ChatGPT. Each evaluation question was 14 questions in total, including non-structure, practicality, relevance, and complexity.The following suggestions can be made in future writing classes for foreign students, depending on the evaluation results of the instructor. It is important to construct an environment in which learners can actively participate in the class with interest in the PBL problem in consideration of their major fields and interests."
드론을 활용한 실시간 원격 흘수 정밀 계측 프레임워크,2024,"['Draft reading', 'Drone pose estimation', 'Computer vision', '흘수 계측', '드론 위치 조정', '컴퓨터 비전']",국문 초록 정보 없음,"Measuring a ship's draft is a critical task that enhances the efficiency of bulk cargo transportation and prevents accidents such as vessel damage due to exceeding maximum draft depth. Traditional draft measurement methods require workers to approach the exterior of the ship for measurement, posing risks of accidents caused by marine environmental factors like waves and wind. To address these issues, this paper proposes an automatic draft measurement framework utilizing drones. The proposed framework estimates the drone's position to transform the images into undistorted frontal views of the draft marks and accurately detects the waterline without the need for training by employing a segmentation foundation model. Subsequently, a YOLO model is used to detect the draft marks, and the final draft depth is measured based on the detected waterline and draft marks. Experimental results demonstrate that the proposed framework achieves a rapid execution time of 0.853 seconds, including both drone pose estimation and draft measurement stages. This is significantly shorter than the time required for manual measurement by workers, indicating its potential for real-time application. Moreover, an average draft measurement error of less than 20mm showcases a high level of accuracy suitable for practical field implementation."
자율주행 트랙터를 위한 비전 센서 융합 기반의 장애물 인식 및 충돌 방지 기술 개발,2024,"['Machine Vision', 'Perception System', 'Sensor Fusion', 'Camera-LiDAR Calibration', 'Object Detection']",국문 초록 정보 없음,"For the practical implementation of autonomous agricultural machinery, reliable obstacle recognition and collision prevention systems are essential in agricultural environments. This study aimed to develop a collision prevention system for autonomous tractors capable of real-time obstacle recognition and responsive collision avoidance using video sensor fusion technology. Emphasizing human safety as the top priority, the system targeted obstacle recognition specifically for humans and operated within designed risk and warning zone ranges aligned with the tractors direction. The developed sensor fusion system integrated the robust object classification capabilities of an RGB camera with a lidar sensor for precise distance measurement, achieving synchronization through camera-lidar calibration. The recognition algorithm, based on the YOLO model applied to RGB images, identified humans, while the lidar data projected onto the image measured the relative distance from the tractor. The collision prevention system, relying on the relative distance of recognized obstacles, halted the tractor in hazardous areas, resuming operation once the obstacle cleared. Validation in static and dynamic situations on flat farmland demonstrated a recognition rate exceeding 99% in collision risk zones, a 24 cm RMSE for distance measurement, and a success rate of over 98% in collision prevention and response."
Improving Accuracy in Detecting Unknown Objects and Enhancing Low Visibility Conditions Caused by Sea Fog in Coastal Areas,2024,[],국문 초록 정보 없음,"South Korea’s geographical position, flanked by the sea on three sides, coupled with the ongoing standoff between the North and the South, makes coastal security a critical component of national defense. However, challenges in coastal operations arise due to aging military equipment and a decrease in military personnel due to low birth rates. In this context, this paper presents automated technology based on deep learning as an alternative to manpower. In coastal areas, low visibility conditions frequently occur due to sea fog, a climatic characteristic of these regions. To address this issue, the Dehazy algorithm, a technique for fog removal, has been implemented. Additionally, an algorithm that separates the background by distinguishing between the sea and sky at the horizon has been combined to selectively identify objects over the sea. For object detection, the YOLO algorithm was employed, and this paper highlights the differences in object recognition rates and real-time processing speeds between identifying unknown objects in original images versus those detected using the proposed technology."
Multi-Class Multi-Object Tracking in Aerial Images Using Uncertainty Estimation,2024,"['Detection', 'Tracking', 'Uncertainty', 'Deep learning']",국문 초록 정보 없음,"Multi-object tracking (MOT) is a vital component in understanding the surrounding environ -ments. Previous research has demonstrated that MOT can successfully detect and track surroundingobjects. Nonetheless, inaccurate classification of the tracking objects remains a challenge that needs to besolved. When an object approaching from a distance is recognized, not only detection and tracking butalso classification to determine the level of risk must be performed. However, considering the erroneousclassification results obtained from the detection as the track class can lead to performance degradationproblems. In this paper, we discuss the limitations of classification in tracking under the classificationuncertainty of the detector. To address this problem, a class update module is proposed, which leveragesthe class uncertainty estimation of the detector to mitigate the classification error of the tracker. Weevaluated our approach on the VisDrone-MOT2021 dataset, which includes multi-class and uncertain far-distance object tracking. We show that our method has low certainty at a distant object, and quicklyclassifies the class as the object approaches and the level of certainty increases. In this manner, our methodoutperforms previous approaches across different detectors. In particular, the You Only Look Once(YOLO)v8 detector shows a notable enhancement of 4.33 multi-object tracking accuracy (MOTA) incomparison to the previous state-of-the-art method. This intuitive insight improves MOT to trackapproaching objects from a distance and quickly classify them."
제조소기업 특화 보급형 산업안전관리 · AI기반 재해예방 통합시스템 개발을 위한 방향성 수립 및 설계에 관한 연구,2024,"['Serious Accidents Punishment Act', 'Industrial Safety Management', 'Accident Prevention', 'Industrial Safety Management', 'Artificial Intelligence', 'Small and Medium-sized Manufacturing Enterprises']","정부에서는 중대재해처벌법 시행을 통해 중대재해 발생저감 및 사망률감소를 목표로 하고 있다. 현재 건설업종 및 대기업을 기반으로 하는 산업안전예방을 위한 솔루션의 경우 상용화되어 활용되고 있으나, 중소기업 및 제조업종에 적합한 시스템은 부재하는 것으로 분석되었다. 이에 ‘소기업·제조업종’에서의 산업현장 안전을 위하여 ‘소기업 특화 스마트 산업안전관리 시스템’을 개발하고자 하였다. 해당 시스템은 중대재해처벌법 대처가 가능한 ‘보급형 산업안전관리 솔루션’과 빠른 재해감지를 통한 ‘AI기반 재해예방 시스템’으로 구성하였다. 본 연구에서는 ‘보급형 산업안전관리 솔루션’의 개발을 위하여 현행 지침 기반의 ‘안전보건관리체계 구축을 위한 7가지 핵심요소’를 도출하고, 이를 통해서 중기업 및 소기업에 맞는 솔루션 항목을 선정하였으며, 이를 바탕으로 솔루션을 설계 및 도출하였다. 또한 ‘AI기반 재해예방 시스템’을 구성하는 학습모델 개발을 위하여 제조업 기반의 재해발생형태 및 기인물 종류를 분석하고 이를 총 26종의 클래스(Class)로 구분하였다. 학습모델은 데이터 종류를 구분하여 설계하였고, 영상은 YOLO 및 simple-HRNet model 기반으로 음성은 Capsulenet model 기반으로 설계하였다. 본 연구결과를 통해 개발된 시스템을 산업현장에 적용함으로써, 향후 산업재해 발생률의 감소를 기대할 수 있을 것으로 사료된다.",다국어 초록 정보 없음
시각장애인 보행 안전을 위한 다중 객체  탐지 및 자연어 알람 시스템,2024,"['Multi-Object Detection', 'YOLOv5', 'KoAlpaca', 'Visually Impaired', 'LLM']",국문 초록 정보 없음,"According to the World Health Organization (WHO), 285 million people suffer from severe vision loss. Assisting the daily lives of visually impaired individuals has been a long-standing research topic. There is a high demand for support tools that allow visually impaired individuals to safely navigate to their destinations by providing information after exploring the surroundings. The walking safety assistance system developed in this paper aims to detect situations and obstacles that may occur in the walking scenarios of visually impaired individuals and generate appropriate natural language sentences to be delivered via voice. The multimodal approach processes and understands visual and language data simultaneously to provide accurate and efficient information. The multimodal AI walking assistance system for the visually impaired is designed to respond quickly and accurately to situations and obstacles encountered during walking. It constructs a pipeline using the object recognition model YOLO and the large-scale natural language model Koalpaca, providing convenience through a voice delivery system."
Development of an Autonomous UAS for on Air Surveillance and Object Detection: A Real Execution,2024,['UAS · Surveillance · Electronic speed controller · Lithium polymer battery'],국문 초록 정보 없음,"Uninhabited Aerial System (UAS), or drones, are aircraft that could be remotely controlled and managed by a person or have varying techniques, like autopilot support, and even fully autonomous modes that do not require human intervention.In this paper, the drone can be remotely controlled and used for spying, among other things. The Pixhawk fight controller, combined with a transmitter and a receiver to transmit and receive radio signals for the drone’s remote control, makes up the brains of the drone. The main components of this system are accompanied by four propellers for fight. The use of an electronic speed controller (ESC) has been implemented to control and regulate the drone’s speed. Moreover, a lithium polymer battery has been used to power up the drone. As previously indicated, the installation of the ESP Camera module to this drone has been implemented, which will be utilized for live footage taken throughout its fight and to be able to relay that footage to the user. The footage is analyzed for image processing and identifying objects in the video using the latest You Only Look Once (YOLO) algorithm as surveillance is the primary function of this system."
드론 정사영상을 이용한 개인형 이동장치 탐지 결과의 위치 정확도 평가,2024,"['Drone Image', 'Personal Mobility', 'Object Detection', 'Positional Accuracy', 'YOLOv3', '드론 영상', '개인형 이동장치', '객체 탐지', '위치정확도']","최근 현대 도시 교통은 공유 형태의 개인형 이동장치(Personal Mobility)의 등장으로 크 영향을 받고 있다. 개인형 이동장치는 공유형 개인 이동 수단이라는 특징으로 접근성과 비용 효율성으로 주목받고 있다. 하지만 이용자의 수가 증가함에 따라 통합적인 관리가 어려운 실정이며, 보행안전, 교통사고, 도시 미관 등과 같은 문제를 야기하고 있다. 이에 본 연구에서는 드론 정사영상과 YOLOv3 알고리즘을 활용하여 개인형 이동장치를 탐하고자 하였다. 나아가 드론 정사영상에서 탐지된 개인형 이동장치의 중심좌표를 GNSS 측량을 통해 얻은 실제 좌표와 비교하여 위치정확도를 평가하고자 하였다. 연구결과, 중심좌표 간의 RMSE 값은 0.1395m로 나타났으며 이를 통해 각종 문제를 야기하는 개인형 이동장치의 관리를 위해 드론 항공사진측량과 정사영상 제작을 수행하여 넓은 지역에 산재한 개인형 이동장치를 탐지하고 관리할 수 있음을 확인하였다.","Recent advancements in urban transportation have been significantly influenced by the emergence of PM (Personal Mobility), characterized by shared personal transportation options. PM has garnered attention as a novel mode of transport due to its accessibility and cost-effectiveness, leading to a surge in its users. However, the increasing number of users poses challenges in integrated management, complicating issues such as pedestrian safety, traffic accidents, and urban aesthetics. To address these challenges, this study explores the application of the YOLO (You Only Look Once) algorithm for detecting PM using drone orthophotos. The primary objective was to evaluate positional accuracy by comparing the center coordinates of identified PM units on drone orthophotos with those obtained through GNSS (Global Navigation Satellite System) surveying. The study showed a RMSE (Root Mean Square Error) value of 0.1395 meters, indicating that drone aerial photogrammetry and orthophoto production can detect and manage dispersed PM devices across wide areas, addressing various issues associated with their management."
"Guest Editorial: The 23rd International Conference on Control, Automation, and Systems (ICCAS 2023)",2024,['None'],국문 초록 정보 없음,"This special issue is dedicated to the papers that extended the work presented at the 23rd International Conference on Control, Automation, and Systems (ICCAS 2023), held Yeosu Venezia Hotel & Utop Marina Hotel, Korea, from October 17∼20, 2023. Because ICCAS aims to bring together researchers and engineers in the fields of control, automation, robotics, and systems engineering, the scope of the conference is well aligned with the scope of the International Journal of Control, Automation, and Systems (IJCAS). Thus, this special issue is pursued as part of the effort to solicit publications of the latest results in the relevant fields to IJCAS.The submitted papers underwent a rigorous review process for the quality and significance of the work. In addition, all selected papers are based on the ICCAS 2023 presentation and include substantial extension from the original presentation. Out of 18 submissions, a total of 13 papers were for publication:1. Model Predictive Current Control for Grid-connected Inverter Considering the PLL Dynamics by Sivadharshini A, Ngoc-Duc Nguyen, and Young Il Lee2. Overcoming Delayed Feedback in Reinforcement Learning Using Actor Ensembles by Jongsoo Lee, Jonghyeok Park, and Soohee Han3. Quadrotor Dynamics in a Wind Field: Equilibria Analysis and Energy Dissipation by Minhyeok Kwon and Yongsoon Eun4. Robust PCA-based Walking Direction Estimation via Stable Principal Component Pursuit for Pedestrian Dead Reckoning by Jae Wook Park, Jae Hong Lee, and Chan Gook Park5. IS-YOLO: A YOLOv7-based Detection Method for Small Ship Detection in Infrared Images With Heterogeneous Backgrounds by Indah Monisa Firdiantika and Sungho Kim6. Image Quality Assessment in Visual Reinforcement Learning for Fast-moving Targets by Sanghyun Ryoo, Jiseok Jeong, and Soohee Han7. Data-driven Fault Diagnosis of Nonlinear Systems With Parameter Uncertainty Using Deep Koopman Operator and Weighted Window Extended Dynamic Mode Decomposition by Jayden Dongwoo Lee, Lamsu Kim, Seongheon Lee, andHyochoong Bang8. A Cable-driven Parallel Robot for High-rack Logistics Automation by Seong-Hun Ha, Seong-Woo Woo, Min-Cheol Kim, Jinlong Piao, Gyoung-Hahn Kim, Md Sahin Sarker, Bae-Jeong Park, Sejeong Kim, Myungjin Jung, Keum-ShikHong, and Chang-Sei Kim9. Development of a Hybrid Gripper With Jamming Module Using Small-scale Pneumatic Pump by Myeongjin Kim, Jingon Yoon, Donghyun Kim, and Dongwon Yun10. Path-tracking Robust Model Predictive Control of an Autonomous Steering System Using LMI Optimization With Independent Constraints Enforcement by Nguyen Ngoc Nam and Kyoungseok Han11. Sparse Instantiation of Bias Nodes for Factor Graph-based Terrain-referenced Navigation by Junwoo Park and Hyochoong Bang12. Buffer Parameter Optimization for Advanced Automated Material Handling Systems in Serial Production Lines by Seunghyeon Kim, Kyung-Joon Park, and Yongsoon Eun13. Fault Detection for Re-initialization of Online Gaussian Process Regression Using Kernel Linear Independence Test by Lamsu Kim, Jayden Dongwoo Lee, Seongheon Lee, and Hyochoong BangMoving forward, the editorial board of IJCAS plans to continue its efforts in identifying exceptional papers from future editions of the International Conference on Control, Automation, and Systems (ICCAS) for potential publication at IJCAS."
OOD 객체 검출 기반 지게차 원격 적재 제어 보조 기술,2024,"['Out of Distribution Detection', 'Freight Recognition', 'Loading Assistance System', 'Smart Logistics', '분포 이탈 탐지', '화물 인식', '적재 보조 시스템', '스마트 물류']","최근 물류 자동화 시스템에 대한 관심이 높아지면서 무인 지게차 연구도 활발히 이루어지고 있다. 기존 무인 지게차 관련 연구는 주로 한정된 실내 공간에서 적용할 수 있는 기술에 집중되어 있다. 하지만, 야외 환경에서는 다양한 외부 요인으로 인해 센서 정보의 신뢰도가 떨어지며 객체 검출의 정확도를 보장하기 어렵다. 본 연구는 야외 환경에 특화된 무인 지게차 기술을 위해 다중 카메라 센서를 활용한 두 가지 기술을 제안한다. 첫째, 상차 작업 중 충돌 방지를 위해 트럭 측면과 포크 높이를 인식해 안전한 적재 높이를 추정하는 기술이다. 둘째, 학습되지 않은 화물의 검출 정확도를 높이기 위해 out-of-distribution 기술의 적용 방안을 제안한다. 제안된 방법론의 현장 적용 가능성을 검증하기 위해 실제 중장비의 1/20 크기 프로토타입을 제작해 실험을 수행하였다. 적합한 객체 검출 모델을 선정하기 위해 Faster R-CNN, YOLOX, DAMO-YOLO, YOLOv8을 비교 실험하였고, 평균 정밀도(average precision) 기준으로 트럭 옆면 인식률은 각 100, 77.3, 99, 99.5을 획득하였다. 또한, 적재공간 및 화물 인지 성능은 YOLOX 모델을 기준으로 각 95.3와 87.83 성능을 보였다. 본 연구는 야외 무인 지게차의 원격 제어 시 화물 낙하 방지와 작업 효율성 향상에 이바지할 것으로 기대된다.","With increasing interest in automated material handling systems, a research on unmanned forklifts has been actively progressing. Existing research has primarily focused on methods applicable to controlled indoor environments. However, sensor data reliability decreases due to external factors, making object detection accuracy difficult to ensure in outdoor environments. We here propose two approaches specialized for unmanned forklifts using multiple camera sensors. First, an approach for estimating a safe loading height by recognizing the truck's side wall and the fork height. Second, an approach for applying out-of-distribution(OOD) to accurately detect previously unseen cargo shapes. We built a 1/20 scale prototype system of the actual heavy equipment to test the feasibility of the proposed approaches in real-world applications. To select a suitable object detection model, we conducted comparative experiments on Faster R-CNN, YOLOX, DAMO-YOLO, and YOLOv8. Based on average precision, the recognition rates for the truck sidewall were 100, 77.3, 99, and 99.5, respectively. Furthermore, the performance for detecting loading space and cargo was 95.3 and 87.83, respectively. We expect that our approach enhances freight drop prevention and operational efficiency in remote-controlled forklifts."
