title,date,keywords,abstract,multilingual_abstract
RNN-LSTM 기반의 순차적 문장 분류 모델,2024,"['RNN-LSTM', '텍스트마이닝', '딥러닝', '자연어처리', 'text mining', 'deep learning', 'natural language processing']","문장 분류(Text Classification)는 단어, 문장, 지문 등 텍스트가 특정 카테고리에 속하는지를 자동으로 분석하는 작업을 의미하며, 비정형 데이터 분석이다. 많은 연구자들이 딥러닝을 활용하여 텍스트 분류 문제를 해결하려고 시도하고 있으며 특히, 과거의 사건이 미래에 영향을 미치도록 설계한 LSTM은 텍스트 분류 문제에 효과적이다. 하지만 LSTM은 Time Steps 수, 즉 텍스트에 활용한 단어가 늘어날수록 성능이 떨어지는 한계가 있다. 이는 장기의존성 문제와는 별개로, 일반적으로 문장을 작성할 때 글의 핵심뿐만 아니라 의미 없는 문장도 함께 작성하기 때문이다. 본 연구에서는 이러한 문제를 해결하기 위해 ‘문장 단위의 학습 결과를 반영한 RNN-LSTM 기반의 순차적 문장 분류 모델’을 제안하였다. 해당 모델은 RNN을 통해 문장을 학습한 후, 다시 LSTM 알고리즘으로 재학습함으로써 긴 문서에서도 분류 정확도를 높였다.","Text classification refers to the task of automatically analyzing whether text, such as words, sentences, or fingerprints, belongs to a specific category, and is an unstructured data analysis. Many researchers are attempting to solve text classification problems using deep learning, and in particular, LSTM, which is designed to allow past events to influence the future, is effective in text classification problems. However, LSTM has a limitation in that its performance deteriorates as the number of Time Steps, that is, the number of words used in the text increases. This is because, apart from the long-term dependency problem, when writing a sentence, not only the core of the text but also meaningless sentences are also written. In this study, to solve this problem, we proposed a 'RNN-LSTM-based sequential sentence classification model that reflects sentence-level learning results.' The model improved classification accuracy even in long documents by learning sentences through RNN and then relearning them using the LSTM algorithm."
Mozi Botnet의 분산 구조와 트래픽 특징에 기반한 YARA와 RNN의 통합적인 탐지 및 대응 시스템,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-RNN 특징 추출을 활용한 LncRNA 서열 데이터 기반 질병 관련 LncRNA 예측 모델 개발,2024,"['long non-coding RNA', 'lncRNA', 'disease association prediction', 'CNN-RNN framework', 'sequence data', '.']","LncRNA(Long non-coding RNA)는 다양한 생물학적 과정에서 중요한 역할을 하며, 비정상적인 발현은 질병 발생의 주요 원인 중 하나이다. 따라서 lncRNA와 질병 간의 연관성을 밝히는 것은 질병 메커니즘을 이해하는 데 중요하다. 전통적인 생물학적 실험은 시간과 비용이 많이 들기 때문에, 딥러닝 기반 데이터 분석 기법이 이를 보완할 수 있다. 여러 방법들이 제안되었지만, 일반화 능력에 한계가 있다. 이러한 한계를 극복하기 위해, 본 논문에서는 CNN-RNN 구조의 특징 추출 모델을 사용하여 lncRNA 서열 데이터로부터 중요 특징 벡터를 추출하였다. 이 벡터를 통합된 LDA(LncRNA Disease Association) 데이터에 사용하여 lncRNA와 질병 간의 관계를 예측하였다. 실험 결과, CNN-RNN 구조를 통해 유용한 특징 벡터를 추출하여 lncRNA와 질병의 연관성을 효과적으로 예측할 수 있었다.","Long non-coding RNA(LncRNA) plays a crucial role in various biological processes, and its abnormal expression is a major cause of disease development. Therefore, elucidating the relationship between lncRNA and diseases is essential for understanding disease mechanisms. Traditional biological experiments are time-consuming and costly, so deep learning-based data analysis techniques can complement these methods. Although several approaches have been proposed, they all have limitations in generalization ability. To overcome these limitations, this paper employs a CNN-RNN feature extraction model to derive significant feature vectors from lncRNA sequence data. These vectors are then used to predict the relationship between lncRNA and diseases using integrated LncRNA Disease Association(LDA) data. Experimental results demonstrate that the CNN-RNN structure effectively extracts useful feature vectors, enabling accurate prediction of lncRNA-disease associations."
"무용예술에서 생성형 인공지능의 역할과 가능성 - CNN, RNN 및 GAN 기술의 적용",2024,"['AI-generated dance', 'Generative AI', 'CNN', 'RNN', 'GAN', '인공지능 기반 무용', '생성형 인공지능', 'CNN', 'RNN', 'GAN']","본 연구에서는 생성형 인공지능의 기능적 특성을 분석하여 무용예술 도구로서의 역할과 가능성을 탐색하고자 한다. 데이터의 패턴 분석과 예측에 사용되는 인공신경망 모델인 CNN과 RNN, 그리고 원래 이미지 생성에 사용되었으나 현재는 움직임 생성까지 적용 범위를 확장하고 있는 GAN의 기능적 구조를 검토한다. 이를 통해 생성형 인공지능이 안무 생성, 무용 훈련, 무보 기록 체계 개선 등에 어떠한 혁신적 변화를 가져올 수 있는지 논의한다. 궁극적으로, 생성형 인공지능 기술의 급격한 발전에 따라 그 영향력이 더욱 확대될 것으로 예상되므로 무용 창작가들에게 이 기술을 실질적으로 활용할 수 있는 유용한 방향성을 제공하고자 한다.","This study explores the role and potential of generative AI as a tool in dance by analyzing key neural network models, including CNN, RNN, and GAN. Initially used for image generation, GANs now extend to movement generation. The research discusses how these models can innovate choreography, dancer training, technical movement analysis, and dance notation. As generative AI rapidly evolves, its impact is expected to grow, and this study aims to provide practical direction for dance creators to effectively utilize these technologies in their work."
CNN–RNN을 이용한 시뮬레이션 기반 항공기 자세 추정 연구,2024,"['deep learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)', 'aircraft attitude estimation', '.']",국문 초록 정보 없음,"Recent advances in deep learning have led to the widespread use of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) across various fields. For aircraft attitude estimation, CNNs can effectively extract spatial features from images, whereas RNNs model temporal continuity for more accurate predictions. This study proposes a hybrid method that combines CNN and RNN architectures to improve the accuracy and stability of real-time aircraft attitude estimation. CNN extracts spatial information from each frame, and the RNN captures the temporal dependencies to predict attitude changes. A dataset from the X-Plane 11 simulator collected under diverse environmental conditions was used to train the model. The proposed approach achieved high accuracy based on performance metrics, such as the mean absolute error, root mean square error, and R-squared, confirming its effectiveness. The simulation results demonstrated reliable attitude estimation even in complex environments, making it suitable for real-time autonomous flight systems. These findings suggest that the proposed model can significantly enhance the safety and reliability of such systems."
RNN 알고리즘을 이용한 다매체 다중경로 최적화 네트워크 기술 개발,2024,[],"미래 전장의 전쟁수행 역량은 AICBMS(AI, Cloud, Bigdata, Mobile, Security)라 일컫는 4차 산업혁명의 차세대 기술을 적용하여 혁신적인 국방력을 확보할 수 있는가에 달려 있다 해도 과언이 아니다. 또한, 미래의 군 작전환경은 네트워크를 기반으로 모든 무기체계가 하나의 통합된 정보통신망 내에서 실시간으로 전장정보를 상호공유하며 작전을 수행하게 되는 네트워크 중심전(NCW)으로 급변하고, 유·무인 복합전투체계 운용범위로 확대되고 있다. 특히, 초고속, 초연결성을 책임지는 통신 네트워크는 여러 전투 요소를 연결하고 정보의 원활한 유통을 위해 높은 생존성과 다계층(국방 모바일, 위성, M/W, 유선) 네트워크 기반의 전력 운용의 효율성을 요구한다. 이러한 관점에서 본 연구는 제원이 고정된 기존의 단일매체, 단일경로 전송과는 달리, 가용한 통신 유무선 인프라 다매체를 동시 사용하여 통신량 폭주시 부하분산과 RNN(Recurrent Neural Networks) 알고리즘을 이용한 인공지능 기반의 전송기술로 다매체다중경로(MMMP-Multi-Media Multi-Path) 적응적 네트워크 기술 개발하는 것이다.","The performance capability of the future battlefield depends on whether the next-generation technology of the Fourth Industrial Revolution, called ABCMS (AI, Bigdata, Cloud, Mobile, Security), can be applied to secure innovative defense capabilities It is no exaggeration to say. In addition, the future military operation environment is rapidly changing into a network-oriented war (NCW) in which all weapon systems mutually share battlefield information and operate in real-time within a single integrated information and communication network based on the network and is expanding to the scope of operation of the manned and unmanned complex combat system. In particular,  communication networks responsible for high-speed and hyperconnectivity require high viability and efficiency in power operation based on multi-tier (defense mobile, satellite, M/W, wired) networks for the connection of multiple combat elements and smooth distribution of information. From this point of view, this study is different from conventional single-media, single-path transmission with fixed specifications, It is an artificial intelligence-based transmission technology using RNN (Recurrent Neural Networks) algorithm and load distribution during traffic congestion using available communication wired and wireless infrastructure multimedia simultaneously and It is the development of MMMP-Multi-Media Multi-Path adaptive network technology."
화성 기상 예측을 위한 어텐션 메커니즘과 활성화 함수를 고려한 RNN 아키텍처의 비교 분석,2024,"['Mars Weather Prediction', 'Time-Series Analysis', 'Attention Mechanism', 'Activation Functions', 'Deep Learning', 'Predictive Modeling', '화성 기상 예측', '시계열 데이터 분석', '어텐션 메커니즘', '활성화 함수', '딥러닝', '예측 모델링']",국문 초록 정보 없음,"In this paper, we propose a comparative analysis to evaluate the impact of activation functions and attention mechanisms on the performance of time-series models for Mars meteorological data. Mars meteorological data are nonlinear and irregular due to low atmospheric density, rapid temperature variations, and complex terrain. We use long short-term memory (LSTM), bidirectional LSTM (BiLSTM), gated recurrent unit (GRU), and bidirectional GRU (BiGRU) architectures to evaluate the effectiveness of different activation functions and attention mechanisms. The activation functions tested include rectified linear unit (ReLU), leaky ReLU, exponential linear unit (ELU), Gaussian error linear unit (GELU), Swish, and scaled ELU (SELU), and model performance was measured using mean absolute error (MAE) and root mean square error (RMSE) metrics. Our results show that the integration of attentional mechanisms improves both MAE and RMSE, with Swish and ReLU achieving the best performance for minimum temperature prediction. Conversely, GELU and ELU were less effective for pressure prediction. These results highlight the critical role of selecting appropriate activation functions and attention mechanisms in improving model accuracy for complex time-series forecasting."
"웹 방화벽 로그 분석을 통한 공격 분류: AutoML, CNN, RNN, ALBERT",2024,"['Web Attack Detection', 'WAF Log', 'TF-IDF', 'AutoML', 'Machine Learning']","사이버 공격, 위협이 복잡해지고 빠르게 진화하면서, 4차 산업 혁명의 핵심 기술인 인공지능(AI)을 이용하여 사이버 위협 탐지 시스템 구축이 계속해서 주목받고 있다. 특히, 기업 및 정부 조직의 보안 운영 센터(Security Operations Center)에서는 보안 오케스트레이션, 자동화, 대응을 뜻하는 SOAR(Security Orchestration, Automation and Response) 솔루션 구현을 위해 AI를 활용하는 사례가 증가하고 있으며, 이는 향후 예견되는 근거를 바탕으로 한 지식인 사이버 위협 인텔리전스(Cyber Threat Intelligence, CTI) 구축 및 공유를 목적으로 한다. 본 논문에서는 네트워크 트래픽, 웹 방화벽(WAF) 로그 데이터를 대상으로 한 사이버 위협 탐지 기술 동향을 소개하고, TF-IDF(Term Frequency-Inverse Document Frequency) 기술과 자동화된 머신러닝(AutoML)을 이용하여 웹 트래픽 로그 공격 유형을 분류하는 방법을 제시한다.","Cyber Attack and Cyber Threat are getting confused and evolved. Therefore, using AI(Artificial Intelligence), which is the most important technology in Fourth Industry Revolution, to build a Cyber Threat Detection System is getting important. Especially, Government’s SOC(Security Operation Center) is highly interested in using AI to build SOAR(Security Orchestration, Automation and Response) Solution to predict and build CTI(Cyber Threat Intelligence). In this thesis, We introduce the Cyber Threat Detection System by analyzing Network Traffic and Web Application Firewall(WAF) Log data. Additionally, we apply the well-known TF-IDF(Term Frequency-Inverse Document Frequency) method and AutoML technology to classify Web traffic attack type."
"심층신경망으로 가는 통계 여행, 두 번째 여행: RNN의 구조와 이미지 분류",2024,"['DNN', 'Classification', 'MLP', 'Regression', 'GLM', '심층신경망', '분류', '다층퍼셉트론', '회귀분석', '일반화선형모형']","RNN은 DNN의 여러 모형을 이행하는 데 있어 중추적 역할을 하는 모형이다. 또 이후 Seq2Seq 모형으로 발전하고, transformer로 발전하는 과정을 통하여, 현시점 최고의 관심이 되고 있는 대규모 언어모형의 발전을 이끌어 온 핵심적 기술이라 할 수 있다. 그럼에도 불구하고 RNN의 작동방식을 이해하는 것은 쉬운 일이 아니다. 특히 RNN의 핵심 모형이 LSRM과 GRU의 작동방식을 이해하기 위한 방안을 모색하다. 더하여 LSTM과 GRU에 대한 구체적인 사용 사례를 보이기 위하여, MNIST 데이터에서의 필기숫자 분류 문제에 적용하였다. 각각의 이미지를 여러 개의 패치로 구획하는 방법을 이용하여 양방향LSTM과 양방향 GRU를 적용하였다. 그 결과를 CNN과 비교하였다.","RNNs are models that play a pivotal role in understanding various forms of DNNs. They have evolved into Seq2Seq models and subsequently into Transformers, leading to the development of large language models (LLMs) that are currently the focus of significant interest. Nonetheless, understanding the operation of RNNs is not an easy task. In particular, the core models of RNNs, LSTM and GRU, are challenging to comprehend due to their structural complexity. This paper explores ways to understand the operation of LSTM and GRU. Additionally, to demonstrate specific use cases of LSTM and GRU, we applied them to the problem of handwritten digit classification using the MNIST dataset. We utilized a method of segmenting each image into multiple patches and applied bidirectional LSTM and bidirectional GRU. The results were then compared with those of CNN."
Comparison of regression model and LSTM-RNN model in predicting deterioration of prestressed concrete box girder bridges,2024,"['bridge condition index', 'bridge engineering', 'deterioration model', 'LSTM', 'regression analysis']",국문 초록 정보 없음,"Bridge deterioration shows the change of bridge condition during its operation, and predicting bridge deterioration is important for implementing predictive protection and planning future maintenance. However, in practical application, the raw inspection data of bridges are not continuous, which has a greater impact on the accuracy of the prediction results. Therefore, two kinds of bridge deterioration models are established in this paper: one is based on the traditional regression theory, combined with the distribution fitting theory to preprocess the data, which solves the problem of irregular distribution and incomplete quantity of raw data. Secondly, based on the theory of Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN), the network is trained using the raw inspection data, which can realize the prediction of the future deterioration of bridges through the historical data. And the inspection data of 60 prestressed concrete box girder bridges in Xiamen, China are used as an example for validation and comparative analysis, and the results show that both deterioration models can predict the deterioration of prestressed concrete box girder bridges. The regression model shows that the bridge deteriorates gradually, while the LSTM-RNN model shows that the bridge keeps great condition during the first 5 years and degrades rapidly from 5 years to 15 years. Based on the current inspection database, the LSTM-RNN model performs better than the regression model because it has smaller prediction error. With the continuous improvement of the database, the results of this study can be extended to other bridge types or other degradation factors can be introduced to improve the accuracy and usefulness of the deterioration model."
Quality Classification of Multi-Layer Copper Foil Stacks Welds for Ultrasonic Welding Using CNN and RNN,2024,"['Multilayer copper foil', 'Ultrasonic welding', 'Weldability', 'Classification model', 'Convolutional Neural Network (CNN)', 'Recurrent Neural Network (RNN)', 'Long Short-Term Memory (LSTM)']",국문 초록 정보 없음,"This study aims to develop a model for classifying weld quality using data acquired in real-time during the ultrasonic welding process. The data utilized includes LVDT (DP-10, DAQ-Express) and power signal data. The model categorizes welds into three classes (insufficient, sufficient, and excessive) based on the total input energy of the ultrasonic welding process. To classify the quality of ultrasonic welds, Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) are employed. The focus of this research is on utilizing CNN and RNN models to classify weld quality based on signal data acquired from ultrasonic welding, aiming to enhance the reliability of secondary battery joints."
ANN/RNN 기반 태양광 발전량 예측에 관한 연구,2024,"['Photovoltaic generation forecasting', 'ANN', 'RNN', 'Solar radiation', 'Forecast model']",국문 초록 정보 없음,"This study proposed a forecasting model that combines ANNs and RNNs to address the intermittency and fluidity of solar power generation. Four prediction models were trained separately based on sky conditions provided by the Korea Meteorological Administration, and insolation was estimated using the ASHRAE Clear-Sky model. The proposed model showed an error rate of 6.5-7.7% based on NMAE, which meets the requirements of power generation prediction. As a result, this study can improve the accuracy of solar power generation forecasting, which can contribute to the stability of power operation and the profitability of power operators."
"머신러닝 기술의 재료·가공문제에 적용III - RNN, LSTM, CNN",2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
Comparative Analysis of GRU-RNN and LSTM Models for Battery Management System Visualization in Unreal Engine,2024,"['Digital Twin', '3D Model', 'Battery Management System', 'GRU-RNN', 'LSTM.']",국문 초록 정보 없음,다국어 초록 정보 없음
RNN 모델을 이용한 반려견 관절 데이터의 결측치 예측 및 보간,2024,"['딥러닝', '결측치 보간', '시계열 분석', 'LSTM', 'GRU', 'Deep learning', 'Missing data interpolation', 'Time series analysis', 'LSTM', 'GRU']","본 연구는 반려견 자세 추정 과정의 결측치 문제를 딥러닝 기반 보간 방식으로 해결하고자 하였다. YOLO v8을 이용해 반려견 자세를 추정하고, LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit) 모델로 결측치를 보간하였다. 실험 결과, 두 모델 모두 전반적인 패턴을 잘 포착하고 결측치를 자연스럽게 보간했으나, 급격한 변화에 대응하는 정확도와 평가 데이터에서의 성능 저하가 관찰되었다. 이를 통해 모델 구조 개선, 데이터 다양성 확보, YOLOv8 성능 향상 등의 필요성을 확인하였다. 본 연구는 반려견 자세 추정의 결측치 문제 해결 가능성을 제시하며, 향후다양한 시계열 결측치 문제에 적용될 수 있을 것으로 기대된다.","This study addresses the critical issue of handling missing data in the process of estimating dog postures byimplementing an advanced deep learning-based interpolation approach. Initially, YOLO v8 was utilized to conduct primaryestimations of dog postures. Following this, Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) modelswere employed to effectively interpolate the missing values. Experimental results indicated that both models succeeded incapturing the overall posture patterns and produced smooth interpolations for missing data. However, limitations wereobserved in responding accurately to abrupt posture changes, which led to a noticeable performance decline in theevaluation phase. These findings emphasize the need for further model architecture improvements, expanded data diversity,and enhanced YOLO v8 performance to achieve greater accuracy. This research proposes a practical solution foraddressing missing data in dog posture estimation, with promising implications for broader applications in diversetime-series interpolation scenarios."
RNN for Non-Invasive Blood Pressure Prediction Based on PPG Signals,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
다중 RNN 모델을 활용한 통합 트레이딩 시스템 조합 성과 비교 및 분석,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
MCU 기반 플랫폼에서 인공지능 학습을 위한 RNN 모델 구현,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
순환신경망 기반 저가형 뇌파 분류기 연구,2024,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 위한 사투리 음성 데이터의 Spectrogram 이미지 변환 적용의 POC 검증,2024,"['Dialect audio data', 'Spectrogram', 'Mel-spectrogram', 'CNN', 'RNN']","본질적으로 음성 데이터는 시계열(Time-series) 데이터이며, 따라서 음성 분류를 위해 ARIMA (Autoregressive integrated moving average) 또는 ES(Exponential smoothing) 알고리즘과 같은 시계열 알고리즘 또는 ML 측면에서는 RNN(Recurrent neural network)을 사용한다. 또 다른 방법으로 RNN 대신에 CNN(Convolutional neural network) 학습 과정의 입력으로 시계 열 숫자 배열이 아닌 오디오 데이터를 나타내는 이미지로 스펙트로그램(Spectrogram)을 사용하는 것이다. 본 논문에서는 시계열 데이터 분석에 RNN 대신에 CNN 기법을 활용하기 위한 음성 데이 터의 Spectrogram 분석과 Mel-spectrogram 분석 이미지를 입력 데이터의 이미지로 사용하며, 사투리 음성의 패턴을 추출하기 위한 CNN 모델을 제안한다. 또한, 제안된 모델의 파이썬 기반 프 로토타입에 의한 POC(Proof of concept)를 수행하여 가능성을 검증하였다.","In essence, audio data is time-series data. Therefore, for audio classification, time-series algorithms such as ARIMA (Autoregressive integrated moving average), ES (Exponential smoothing), or RNN (Recurrent neural network) in machine learning terms are commonly employed. Another method is to use a spectrogram as an image representing audio data rather than a time series number array as the input to the CNN(Convolutional neural network) learning process instead of RNN. In this paper, we use spectrogram analysis and mel-spectrogram analysis images of audio data as input data, using the CNN technique instead of RNN for time series data analysis, and we propose a CNN model to extract patterns of dialect audio. In addition, the feasibility was verified by performing a POC(Proof of concept) using a Python-based prototype of the proposed model."
공간적 상관성을 고려한 딥러닝 기반 부동산 가격 예측 방법 제안,2024,"['real estate valuation', 'spatial regression analysis', 'time series analysis', 'deep learning', '.']","부동산은 공간적인 특성을 가지고 있다는 점에서 다른 자산과 차별되는 특성을 갖는다. 공간적인 측면으로 접근하여, 본 연구에서의 데이터는 2013년 1분기부터 2023년 2분기까지의 서울시 3,000세대 이상의 아파트 단지이며, 방법론은 딥러닝 기반의 시계열 분석 기법인 RNN, LSTM, GRU이다. 이를 통해 3,000세대 이상의 아파트 단지들이 특정 지역구의 아파트 단지 가격에 어느 정도 영향을 미치는 지 확인할 수 있다. 모델별 평균 정확도를 MAPE를 통해 산출한 결과, RNN이 10.91, LSTM이 11.44, GRU가 11.12로서 RNN이 가장 우수했고, LSTM과 GRU가 비슷하였다. 추후 본 연구에서 제안하는 모형을 활용하여 높은 정확도의 부동산 가격 예측을 하는데 도움이 될 것으로 기대한다.","Real estate has a characteristic that is differentiated from other assets in that it has spatial characteristics. Approaching from a spatial aspect, the data in this study are apartment complexes with more than 3,000 households in Seoul from the first quarter of 2013 to the second quarter of 2023, and the methodologies are RNN, LSTM, and GRU which are deep learning-based time series analysis techniques. As a result of calculating the average accuracy of each model through MAPE, RNN was 10.91, LSTM was 11.44, and GRU was 11.12. RNN was the best, and LSTM and GRU were similar. With the proposed model, it is expected to be helpful in predicting real estate valuation with higher accuracy in the future."
이상 전력 탐지를 위한 TCN-USAD,2024,"['Self-supervised Learning', 'Anomaly detection', 'Time-Series Data', '자기 지도 학습', '이상 탐지', '시계열 데이터']","에너지 사용량의 증가와 친환경 정책으로 인해 건물 에너지를 효율적으로 소비할 필요가 있으며, 이를 위해 딥러닝 기반 이상 전력 탐지가 수행되고 있다. 수집이 어려운 이상치 데이터의 특징으로 인해 Recurrent Neural Network(RNN) 기반 오토인코더를 활용한 복원 에러 기반으로 이상 탐지가 수행되고 있으나, 시계열 특징을 온전히 학습하는데 시간이 오래 걸리고 학습 데이터의 노이즈에 민감하다는 단점이 있다. 본 논문에서는 이러한 한계를 극복하기 위해 Temporal Convolutional Network(TCN)과 UnSupervised Anomaly Detection for multivariate time series(USAD)를 결합한 TCN-USAD를 제안한다. 제안된 모델은 TCN 기반 오토인코더와 두 개의 디코더와 적대적 학습을 사용하는 USAD 구조를 활용하여 빠르게 시계열 특징을 온전히 학습할 수 있고 강건한 이상 탐지가 가능하다. TCN-USAD의 성능을 입증하기 위해 2개의 건물 전력 사용량 데이터 세트를 사용하여 비교 실험을 수행한 결과, TCN 기반 오토인코더는 RNN 기반 오토인코더 대비 빠르고 복원 성능이 우수하였으며, 이를 활용한 TCN-USAD는 다른 이상 탐지 모델 대비 약 20% 개선된 F1-Score를 달성하여 뛰어난 이상 탐지 성능을 보였다.","Due to the increase in energy consumption, and eco-friendly policies, there is a need for efficient energy consumption in buildings. Anomaly power detection based on deep learning are being used. Because of the difficulty in collecting anomaly data, anomaly detection is performed using reconstruction error with a Recurrent Neural Network(RNN) based autoencoder. However, there are some limitations such as the long time required to fully learn temporal features and its sensitivity to noise in the train data. To overcome these limitations, this paper proposes the TCN-USAD, combined with Temporal Convolution Network(TCN) and UnSupervised Anomaly Detection for multivariate data(USAD). The proposed model using TCN-based autoencoder and the USAD structure, which uses two decoders and adversarial training, to quickly learn temporal features and enable robust anomaly detection. To validate the performance of TCN-USAD, comparative experiments were performed using two building energy datasets. The results showed that the TCN-based autoencoder can perform faster and better reconstruction than RNN-based autoencoder. Furthermore, TCN-USAD achieved 20% improved F1-Score over other anomaly detection models, demonstrating excellent anomaly detection performance."
클라우드 컴퓨팅과 기계학습 기법을 이용한 주식의 기술적 분석 지표 최적화 및 주가 추세 변동 예측,2024,"['Stock Trend Prediction', 'Echo State Networks', 'Machine Learning', 'Technical Analysis', 'Cloud Computing', '주가 추세 예측', '에코 스테이트 네트워크', '기계학습', '기술적 분석', '클라우드 컴퓨팅']","국내 주식 시장에서 트렌드 예측을 위한 기계학습 모델의 활용 사례가 점점 증가하고 있다. 특히, 주가 데이터와같은 복잡한 시계열 데이터를 분석하고 예측하기 위해서는 기계학습을 활용하는 것이 필수적이다. 본 연구에서는 클라우드 컴퓨팅 서비스를 활용한 금융 데이터 수집 및 금융 시계열 추세 예측을 위한 기계학습 시스템을 제안한다. 먼저, 데이터 수집을 위해 Amazon Web Services(AWS)의 서버리스 서비스를 활용하였으며, 기술적 분석 지표(Relative Strength Index(RSI), Simple Moving Average(SMA), 볼린저 밴드, Rate Of Change(ROC), Golden Cross and Dead Cross(GDC), Stochastic Oscillator(STOCH), Moving Average Convergence Divergence(MACD), Detrended Price Oscillator(DPO))의 임계치를 유전 알고리즘을 통해 최적화 하였다. 이후 최적화된 지표들을 Echo State Network(ESN), Recurrent Neural Network(RNN), 그리고 다양한 기계학습 분류 모델의 학습 데이터로 사용하여 각 종목의 추세를 예측하였다. 예측된 추세를 바탕으로 백테스트를 진행한 결과, 평균 수익률은 ESN이 334%, RNN이 175%, 그리고 분류 모델이 199%를 기록하였다. 따라서 본 연구는 국내 주식 투자에서도 기계학습이 높은 예측력을 보이며 다양한 활용 가능성을 지니고 있음을 시사 하였다.","The application of machine learning models for trend prediction in the domestic stock market is increasing. In particular, utilizing machine learning is essential for analyzing and predicting complex time-series data, such as stock price data. This study proposes a machine learning system for financial time-series trend prediction, utilizing cloud computing services. First, for data collection, the serverless service of Amazon Web Services was employed, and the thresholds of technical analysis indicators were optimized through a genetic algorithm. The optimized indicators were then used as training data for Echo State Network, Recurrent Neural Network (RNN), and various machine learning classification models to predict the trend of each stock. Based on the predicted trends, backtesting was conducted, and the results showed that the average returns were 334% for ESN, 175% for RNN, and 199% for classification models. Therefore, this study suggests that machine learning exhibits high predictive power in domestic stock investment and holds various potential applications."
동백전 빅데이터를 활용한 딥러닝 기반 신흥 상권 성장 예측 모델 연구,2024,"['동백전 지급결제 시스템', '신흥 상권의 성장성 예측', 'Moving Average', '딥러닝', 'Dongbaekjeon Payments system', 'growth prediction of emerging commercial areas', 'Moving Average', 'Deep Learning']","본 연구는 부산광역시 지역화폐인 동백전 지급결제 시스템의 빅데이터를 활용하여 신흥 상권의 성장성을 예측하는 딥 러닝 기반 모델을 개발하고, 이동평균법을 이용한 데이터 전처리 기법이 모델 성능에 미치는 영향을 검증하는 것을 목표 로 한다. 상권은 업체와 서비스 제공자가 위치를 선택하고 마케팅 전략을 수립하는 데 중요한 요소로 작용한다. 기존 연구 에서 사용된 원형 상권 분석 방법의 한계를 극복하기 위해, 국가 공공 데이터와 연계가 가능하고 회원 가입 시 등록하는 우편번호 기반의 상권 범위 설정 방법을 제안한다. 동백전 지급결제 시스템의 충전형 선불카드 승인 데이터를 우편번호 구역을 기준으로 집계하여 선정된 신흥 상권의, 시계열 데이터를 통해 성장성을 예측하는 데 가장 효율적인 이동평균법 기반 데이터 전처리 방법과 최적의 딥러닝 모델을 제안 한다. 특히, RNN 모델과 RNN 계열 모델인 LSTM과 GRU 모델을 활용하여 전처리된 시계열 데이터를 학습하고 예측한다. 연구 결과, 단순이동평균법으로 전처리한 데이터를 GRU 모델을 사용하여 Random Seed 1에서 127 사이 구간에서 학습한 결과, 예측 성능 지표인 R²의 평균값이 0.89 이고, 평균 성능은 표준편차 0.05에서 0.89로 가장 안정적이고 우수한 결과를 보였다. 본 연구는 SMA(단순 이동평균), TMA(삼각 이동평균), WMA(가중 이동평균), EMA(지수 이동평균) 이동평균법을 기 반으로 한 데이터 전처리가 딥러닝 모델의 예측 성능에 큰 영향을 미친다는 점을 시사한다. 데이터 특성에 맞는 이동평균 법 기반 전처리 기법은 금융시장 및 다양한 산업 분야에서 시계열 데이터 학습 및 예측의 정확성과 효율성을 높이는 데 활용할 수 있다.","This study aims to develop a deep learning-based model to predict the growth potential of emerging commercial areas using big data from the Dongbaekjeon Payments system, a local currency of Busan Metropolitan City. It also seeks to verify the impact of data preprocessing techniques based on moving average methods on model performance. Commercial areas play a key role in helping businesses and service providers select locations and formulate marketing strategies. To overcome the limitations of traditional circular commercial area analysis methods used in previous studies, this research proposes a method for defining commercial area boundaries based on postal codes provided during the registration process, which can be linked to national public data. The study aggregates rechargeable prepaid card approval data from the Dongbaekjeon Payments system by postal code area and presents the most efficient moving average-based data preprocessing method along with the optimal deep learning model for predicting the growth of selected emerging commercial areas using time-series data. In particular, the study employs RNN models, including RNN-based models such as LSTM and GRU, to train and predict on preprocessed time-series data. The results indicate that using the GRU model with data preprocessed by the Simple Moving Average method, trained within the Random Seed range of 1 to 127, yielded an average R² value of 0.89, with a standard deviation of 0.05, demonstrating highly stable and superior performance. This study suggests that data preprocessing based on moving average methods, including Simple Moving Average (SMA), Triangular Moving Average (TMA), Weighted Moving Average (WMA), and Exponential Moving Average (EMA), significantly impacts the predictive performance of deep learning models. Tailored moving average-based preprocessing techniques can enhance the accuracy and efficiency of time-series data learning and prediction in financial markets and various industries."
음향기반 교통사고 검지를 위한 딥러닝 모델 연구,2024,"['Traffic', 'Accident', 'Acoustic', 'Artificial Intelligent', 'DNN', 'CNN', 'RNN', '교통', '사고', '음향', '인공지능', '심층신경망', '합성곱신경망', '순환신경망']","C-ITS(Cooperative-Intelligent Transport Systems) 및 자율주행 환경에서 교통사고와 같은 돌발상황의 신속한 검지가 중요해짐에 따라, 최근에는 이를 위한 다양한 시스템 개발과 관련된 연구가 활발히 진행되고 있다. 본 연구는 기존의 영상 및 레이더 기반 검지 방식의 한계를 극복하기 위해 음향 정보를 이용한 교통사고 검지 기술을 개발하는 것을 목표로 한다. 구체적으로, 교통사고 시 발생하는 음향 데이터를 수집하고, 이를 통해 충돌 및 급제동과 같은 특징을 추출하였다. 추출된 음향 데이터를 바탕으로DNN, CNN, RNN의 딥러닝 모델을 학습시켜 각 모델을 통해 사고 패턴을 검지하는 방법을 연구하였다. 이후, 학습된 모델들의 검지 결과를 비교 분석하여 음향 패턴을 검지하는 데 가장 적합한 알고리즘 모델을 선정하였다. 최적의 알고리즘을 적용하여 음향기반 자동 사고 검지 시스템을 개발하였으며, 이 시스템은 교통사고를 신속하고 정확하게 판별할 수 있다. 본 연구는 딥러닝 알고리즘과 음향 특징 추출 기술을 통해 정확한 교통사고 검지를 가능하게 하여 교통 안전 향상에 기여할 수 있을 것으로 기대된다.","In the context of C-ITS and autonomous driving, rapid detection of traffic incidents is crucial. This research addresses the limitations of traditional methods such as imaging and radar by developing a technology that utilizes acoustic information for incident detection. Specifically, we analyzed acoustic data to extract features and trained deep learning models—DNN, CNN, and RNN—to identify patterns associated with crash and skid. Through comparative analysis of the models' detection results, we identified the optimal algorithm for acoustic pattern recognition. This study demonstrates the potential of advanced deep learning algorithms and acoustic feature extraction in enhancing automated accident detection systems."
Analysis of Research Trends in Deep Learning-Based Video Captioning,2024,"['Video Captioning', 'Computer Vision', 'Natural Language Processing', 'Deep Learning', '비디오 캡션', '컴퓨터 비전', '자연어 처리', '딥러닝']",국문 초록 정보 없음,"Video captioning technology, as a significant outcome of the integration between computer vision and natural language processing,has emerged as a key research direction in the field of artificial intelligence. This technology aims to achieve automatic understandingand language expression of video content, enabling computers to transform visual information in videos into textual form. This paperprovides an initial analysis of the research trends in deep learning-based video captioning and categorizes them into four main groups:CNN-RNN-based Model, RNN-RNN-based Model, Multimodal-based Model, and Transformer-based Model, and explain the concept ofeach video captioning model. The features, pros and cons were discussed. This paper lists commonly used datasets and performanceevaluation methods in the video captioning field. The dataset encompasses diverse domains and scenarios, offering extensive resourcesfor the training and validation of video captioning models. The model performance evaluation method mentions major evaluation indicatorsand provides practical references for researchers to evaluate model performance from various angles. Finally, as future research tasksfor video captioning, there are major challenges that need to be continuously improved, such as maintaining temporal consistency andaccurate description of dynamic scenes, which increase the complexity in real-world applications, and new tasks that need to be studiedare presented such as temporal relationship modeling and multimodal data integration."
뇌전증 환자의 MEG 데이터에 대한 분류를 위한 인공신경망 적용 연구,2024,['(MEG)'],국문 초록 정보 없음,"This study performed a multi-classification task to classify mesial temporal lobe epilepsy with left hippocampal sclerosis patients (left mTLE), mesial temporal lobe epilepsy with right hippocampal sclerosis (right mTLE), and healthy controls (HC) using magnetoencephalography (MEG) data. We applied various artificial neural networks and compared the results. As a result of modeling with convolutional neural networks (CNN), recurrent neural networks (RNN), and graph neural networks (GNN), the average k-fold accuracy was excellent in the order of CNN-based model, GNN-based model, and RNN-based model. The wall time was excellent in the order of RNN-based model, GNN-based model, and CNN-based model. The graph neural network, which shows good figures in accuracy, performance, and time, and has excellent scalability of network data, is the most suitable model for brain research in the future."
LLaMA 3 온디바이스 가속기의 구현을 위한 고정소수점 연산 분석,2024,"['LLaMA 3', 'LLM', 'Accelerator', 'Fixed-Point', 'ASIC']","LLM(대규모 언어 모델)은 RNN과 LSTM의 발전된 모델로, 트랜스포머 구조를 갖는다. 트랜스포머는 2017년 ‘Attention Is AllYou Need’ 논문 이후 발전해 OpenAI GPT-4, Google Gemini Pro 1.5 등 성공적인 LLM이 출시되었다. LLM은 방대한 데이터를 학습하기 위해 고성능 GPU가 필요해 일반적으로 로컬에서 개인 사용자에게 공개되지 않는다. Meta AI의 LLaMA 3는 연구적/상업적목적으로 사용 가능한 오픈소스로, 8B와 70B 모델로 제공된다. LLaMA 3는 로컬에서 실행 가능하지만, 다중 GPU 환경이 필요하다.온디바이스 LLM을 구동하려면 양자화와 고정 소수점 연산이 필요하며, 엣지 디바이스에서 부동 소수점 연산은 자원 부담이 크다. 고정 소수점 연산은 빠르지만 표현 범위가 좁아 LLM의 답변 정확도에 영향을 미칠 수 있다. 본 논문은 LLaMA 3 8B 모델의 구조와연산을 분석하고, 고정 소수점 실험 결과와 하드웨어 자원 사용량을 제시한다.","LLM (Large Language Model) is an advanced model for processing sequential data, evolving from RNN and LSTM models,and is based on the transformer architecture. Since the publication of the 'Attention Is All You Need' paper in 2017, transformershave continuously developed, leading to successful LLMs such as OpenAI's GPT-4 and Google's Gemini Pro 1.5. LLMs requireextensive data training, necessitating high-performance GPUs and prolonged training times, which is why they are typically notavailable for local use by individual users. Meta AI's LLaMA 3, an open-source model for research and commercial use, isavailable in 8B and 70B parameter models. While LLaMA 3 can be run locally, it requires a multi-GPU environment. To runLLMs on-device, quantization and fixed-point arithmetic are needed due to the resource constraints of edge devices. Floating-pointoperations are resource-intensive and challenging for edge devices, though fixed-point operations, while faster, have a narrowerrange and may affect LLM accuracy. This paper analyzes the structure and operations of the LLaMA 3 8B model, presentsfixed-point experiment results, and discusses hardware resource usage."
딥러닝과 머신러닝을 통한 당뇨병 데이터 분석,2024,"['Diabetes', 'Classification', 'Machine Learning', 'Deep Learning', 'Ensemble Model', '당뇨병', '분류', '머신러닝', '딥러닝', '앙상블  모델']","당뇨병은 널리 퍼진 만성 질환으로, 세계적으로 영향을 미치고, 경제적으로도 상당한 재정적 부담을 부가하고 있다. 당뇨병은 혈액의 포도당을 조절하는 능력을 저하하고 , 삶의 질과 수명을 감소시킬 수 있는 만성 질환이다. 또한 당뇨병은 인슐린을 생성하지 못하거나, 효과적으로 사용하지 못한다. 당뇨병 문제의 규모는 상대적으로 크지만, 쉽게 인식하지 못한다. 당뇨병을 완치할 수 있는 방법은 없지만 체중 감량, 건강식, 활동적 생활 및 치료를 받는 것과 같은 전략은 많은 환자에서 이 질병의 피해를 완화할 수 있다. 조기 진단은 생활 방식의 변화와 보다 효과적인 치료로 이어진다. 본 연구의 의의는 당뇨병이 있는지 여부에 대한 정확한 예측을 제공하고 당뇨병 위험을 가장 잘 예측하는 위험 요소는 무엇인지 찾는 것이다.  예측에 있어서 여러 가지 머신러닝 기법과 딥러닝의 CNN과 RNN을 통한 Ensemble Model 사용하고, 평가방법으로 Accuracy와 Recall을사용한다. 이 Ensemble Model은 Transformer구조를 따르고자 했고, 경량화하였다.","Diabetes is a widespread chronic disease that affects people worldwide and imposes significant financial burdens. Diabetes impairs the ability to regulate blood glucose levels, reducing quality of life and life expectancy. Additionally, diabetes is characterized by either the inability to produce insulin or to use it effectively. Despite its prevalence, diabetes is often underrecognized. While there is no cure for diabetes, strategies such as weight loss, healthy eating, an active lifestyle, and treatment can mitigate the disease's impact in many patients. Early diagnosis leads to lifestyle changes and more effective treatment. This study aims to provide accurate predictions for diabetes and identify the most significant risk factors for its development. The study employs various machine learning techniques, and  ensemble models using CNN and RNN, with accuracy and recall as evaluation metrics. This Ensemble Model attempted to follow the Transformer structure and made it lightweight."
Innovative Hybrid Approach for Enhanced Renewable Energy Generation Forecasting Using Recurrent Neural Networks and Generative Adversarial Networks,2024,['Power prediction  · Renewable energy forecasting  · Machine learning  · Deep learning  · Recurrent neural network (RNNs)  · Generative adversarial networks (GANs)  · Energy grid integration  · Sustainability'],국문 초록 정보 없음,"Renewable energy sources hold the key to a sustainable and green future, yet their inherent variability poses signifi cant challenges for reliable power generation forecasting. In response to this critical issue, this study presents an innovative approach that harnesses the power of both Recurrent Neural Networks (RNNs) and Generative Adversarial Networks (GANs) to revolutionize power generation forecasting in renewable energy systems. The hybrid model combines the strengths of RNNs, known for capturing temporal dynamics and sequential dependencies, and GANs, renowned for generating realistic data distributions. The results demonstrate a remarkable improvement in forecasting accuracy compared to traditional methods, reducing errors and uncertainties. The hybrid RNN-GAN model enhances the reliability of renewable energy systems, facilitating greater integration of sustainable energy sources into the grid. Furthermore, the research underscores the importance of incorporating a Grid-Connected Hybrid System Design and implementing a closed-loop control framework.These additions ensure that the forecasts are not just theoretical but are actively used to optimize energy utilization and maintain grid stability in real-world scenarios. This innovative approach holds great promise for a greener and more effi cient energy landscape, making a substantial contribution to the transition towards a fresher and more sustainable future. The proposed Hybrid RNN-GAN model consistently outperforms existing methods, yielding signifi cantly lower RMSE and MAE values for both solar and wind data, showcasing its superior accuracy in renewable energy generation forecasting.The achieved R-squared (R 2 ) values of 0.82 for solar data and 0.7 for wind data at 100 iterations further validate the model's eff ectiveness in capturing underlying patterns, while skewness and kurtosis analyses affi rm its ability to generate predictions aligned with normal distributions."
"심층신경망으로 가는 통계 여행, 세 번째 여행: 언어모형과 트랜스포머",2024,"['language model', 'transformer', 'multi-head attention', 'encoder-decoder', 'positional encoding', '언어모형', '트랜스포머', '다중어텐션', '인코더-디코더', '위치인코딩']","지난 10년의 기간 심층신경망의 비약적 발전은 언어모형의 개발과 그 발전을 함께 해 왔다. 언어모형은 초기 RNN을 이용한 encoder-decoder 모형의 형태로 개발되었으나, 2015년 attention이 등장하고, 2017년 transformer가 등장하여 혁명적 기술로 성장하였다. 본연구에서는 언어모형의 발전과정을 간략하게 살펴보고, 트랜스포머의 작동원리와 기술적 요소에 대하여 구체적으로 살펴본다. 동시에 언어모형, 트랜스포머와 관련되는 통계모형과, 방법론에 대하여 함께 검토한다.","Over the past decade, the remarkable advancements in deep neural networks have paralleled the development and evolution of language models. Initially, language models were developed in the form of Encoder-Decoder models using early RNNs. However, with the introduction of Attention in 2015 and the emergence of the Transformer in 2017, the field saw revolutionary growth. This study briefly reviews the development process of language models and examines in detail the working mechanism and technical elements of the Transformer. Additionally, it explores statistical models and methodologies related to language models and the Transformer."
시계열 데이터 활용에 관한 동향 연구,2024,"['데이터', '시계열 데이터', '머신러닝', '순환신경망', 'LSTM', 'Data', 'Time Series Data', 'Machine Learning', 'Recurrent Neural Network', 'LSTM']",국문 초록 정보 없음,다국어 초록 정보 없음
유사 홀로그램과 LSTM을 이용한 3D 수화 교육 시스템 개발 및 평가,2024,"['.', 'sign language', 'education systems', 'leap motion', 'RNN', '3D hologram', 'user survey']","청각장애인의 의사소통 제약을 개선하기 위해 비청각장애인들도 쉽게 익힐 수 있는 수화 교육 시스템을 제안한다. 이 시스템은 기존 연구들의 3차원 시각적 특성 반영 한계를 극복하고자 유사 홀로그램을 이용하고, 립모션 장치와 순환 신경망(RNN)을 결합하여 구성하였다. 학습자가 손동작을 수행하는 홀로그램 화면을 보며 실습으로 수화를 배우고, 평가를 통해 능력 향상을 확인할 수 있도록 한다. 정답 판별을 위한 수화 인식 모델은 RNN, LSTM, BiLSTM을 각각 학습한 후 성능을 비교하여 F1 스코어 0.9451로 가장 우수한 성능을 보인 LSTM을 선정하였다. 수화 교육 시스템의 모델 성능을 평가하고, 사용자의 테스트 및 설문 조사를 수행하여 흥미 유발과 만족도를 평가한다. 궁극적으로 이 수화 교육 시스템을 통해 비청각장애인의 수화에 대한 인식 향상에 기여하고자 한다.","To improve communication constraints for the hearing-impaired, we propose a sign language education system that can be easily learned by non-hearing-impaired individuals. To overcome the limitations of the three-dimensional visual characteristics reflected in existing studies, the system utilizes a pseudo-hologram and combines a Leap Motion device with a Recurrent Neural Network(RNN). The sign language education system allows learners to easily learn and improve their sign language skills through practice by viewing the hologram screen and verifying their progress. The model for sign language recognition to determine correct answers was trained using RNN, LSTM, and BiLSTM. Among these, the LSTM model was selected as it showed the best performance with an F1 score of 0.9451. To evaluate the engagement and satisfaction of the sign language education system, user tests and surveys were conducted. This sign language education system aims to contribute to the improvement of sign language awareness among non-hearing-impaired individuals."
Modeling CO2 Loading Capacity of Diethanolamine (DEA) Aqueous Solutions Using Advanced Deep Learning and Machine Learning Algorithms: Application to Carbon Capture,2024,['Carbon capture · Diethanolamine (DEA) · CO 2 loading capacity · Recurrent Neural Networks · Intelligent model'],국문 초록 정보 없음,"Several carbon capture techniques have been developed in response to the notable rise of atmospheric carbon dioxide ( CO2 ) levels. The utilization of diethanolamine (DEA) as an absorption method is prevalent in various industries due to its high reactivity and cost-effi ciency. Hence, comprehending the equilibrium solubility of CO2 in DEA solutions is an essential step in developing and optimizing absorption procedures. In order to predict the CO2 loading capacity in the DEA solutions, four advanced deep learning and machine learning models were developed: recurrent neural networks (RNN), deep neural networks (DNN), random forest (RF), and adaBoost-support vector regression (AdaBoost-SVR). The models predict the capacity of CO2 loading as a function of temperature, CO2 partial pressure, and the concentration of DEA in the solution.Intelligent models were developed employing an extensive database which includes new experimental data points published within recent years, which were not considered in the previous studies. The RNN model was found to outperform other models based on graphical and statistical assessments, as evidenced by its lower root mean square error ( RMSE = 0.285 ) and standard deviation ( SD = 0.032 ), and higher determination coeffi cient ( R2 = 0.992 ). While the RNN model resulted in the highest accuracy in predicting CO2 absorption, the DNN, RF, and AdaBoost-SVR models also demonstrated satisfactory accuracy in predicting CO2 solubility, placed in the following ranking. A sensitivity analysis was performed on the four developed models, revealing that the CO2 partial pressure has the strongest eff ect on the CO2 loading capacity. Furthermore, a trend analysis was performed on the RNN model, demonstrating that the developed model has a high degree of accuracy in following physical trends. The binary interaction analysis was conducted with two varying parameters and one constant parameter in the RNN model through 3-D image plots, which illustrated the simultaneous eff ect of two independent parameters on CO2 loading. Finally, outlier detection was conducted by employing the Leverage method to fi nd outlier data points in the data bank, demonstrating the applicability domain of intelligent models."
Forecasting realized volatility using data normalization and recurrent neural network,2024,"['asymmetry', 'realized volatility', 'normalization', 'ratio transformation', 'recurrent neural network']",국문 초록 정보 없음,"We propose recurrent neural network (RNN) methods for forecasting realized volatility (RV). The data are RVs of ten major stock price indices, four from the US, and six from the EU. Forecasts are made for relative ratio of adjacent RVs instead of the RV itself in order to avoid the out-of-scale issue. Forecasts of RV ratios distribution are first constructed from which those of RVs are computed which are shown to be better than forecasts constructed directly from RV. The apparent asymmetry of RV ratio is addressed by the Piecewise Minmax (PM) normalization. The serial dependence of the ratio data renders us to consider two architectures, long short-term memory (LSTM) and gated recurrent unit (GRU). The hyperparameters of LSTM and GRU are tuned by the nested cross validation. The RNN forecast with the PM normalization and ratio transformation is shown to outperform other forecasts by other RNN models and by benchmarking models of the AR model, the support vector machine (SVM), the deep neural network (DNN), and the convolutional neural network (CNN)."
장단기 기억 신경망을 이용한 ABS 판재의 점탄성 모델링,2024,"['Deep learning', 'Recurrent neural networks', 'History-dependent material', 'Viscoelasticity', 'Generalized Maxwell model']",국문 초록 정보 없음,"In this paper, the capabilities of recurrent neural networks (RNNs) to describe the viscoelastic properties of acrylonitrile-butadiene styrene (ABS) are investigated. The RNN model was trained using one-dimensional strains and corresponding stress data generated by the finite element method. The optimal model was then employed to predict the viscoelastic behavior of unseen test data. Furthermore, the viscoelastic-based RNN model was tested for extrapolation using other types of strain and corresponding stress data beyond the training set. The agreement between the predicted and actual stresses demonstrates the robust performance of the trained RNN model in predicting different types of strain inputs for larger strain tests, despite being trained only with step strain inputs. Therefore, the use of RNNs can be considered a viable alternative to conventional models for predicting viscoelastic behavior."
스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교,2024,"['skeleton data', 'machine learning models', 'deep learning models', 'cross-subject cross-validation', '스켈레톤 데이터', '머신러닝 모델', '딥러닝 모델', '교차검증']","본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터를 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) ¨모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다.","This study investigates the effectiveness of 3D skeleton data for human action recognition by comparing the classification performance of machine learning and deep learning models.We use the subset of the NTU RGB+D dataset, containing only frontal-view recordings of 40 individuals performing 60 different actions. Our study uses linear discriminant analysis (LDA), support vector machine (SVM), and random forest (RF) as machine learning models, while the deep learning models are hierarchical bidirectional RNN (HBRNN) and semantics-guided neural network (SGN). To evaluate model performance, cross-subject cross-validation is conducted. Our analysis demonstrates that action type significantly impacts model performance. Cluster analysis by action category shows no significant difference in classification performance between machine learning and deep learning models for easily recognizable actions. However, for actions requiring precise differentiation based on frontal-view joint coordinates such as ‘clapping’ or ‘rubbing hands’, deep learning models show a higher performance in capturing subtle joint movements compared to machine learning models."
다중 시계열을 이용한 장기 예측 Transformer 모델,2024,"['artificial intelligence', 'deep learning', 'transformer', 'time series forecasting', '인공지능', '딥러닝', '트랜스포머', '시계열 예측']","많은 현대 연구에서는 시계열 예측 모델을 위해 recurrent nueral networks (RNN) 혹은 long short-term memory (LSTM)과 같은 인공지능 기술의 적용을 탐구한다. 이러한 인공지능 모델 중에서도 자연어 처리를 위해 처음 개발된 모델인 transformer는 큰 주목을 받고 있다. 그럼에도 불구하고, 많은 시계열 예측 모델은 장기 예측을 적절히 다루지 못하고 있다. 따라서 본 연구에서는 “목표 시계열”과 예측에 영향을 미칠 수 있는 다수의 “참고 시계열”을 포함하는 트랜스포머 아키텍처 기반의 장기 예측 모델을 제안한다.","Numerous contemporary studies are exploring the application of artificial intelligence techniques such as recurrent neural networks (RNN) and long short-term memory (LSTM) for time series forecasting models. Among these AI models, the Transformer, which is a high-performance model initially developed for natural language processing, has gained significant attention. Despite this, many time series forecasting models do not adequately address long-term prediction. Therefore, this study seeks to develop a long-term forecasting model based on the Transformer architecture, incorporating a “target time series” and a multiple “reference time series” that may influence the forecast."
DR-LSTM: Dimension reduction based deep learning approach to predict stock price,2024,"['dimension reduction', 'sufficient dimension reduction', 'long short term memory', 'recurrent neural network', 'time series data analysis']",국문 초록 정보 없음,"In recent decades, increasing research attention has been directed toward predicting the price of stocks in financial markets using deep learning methods. For instance, recurrent neural network (RNN) is known to be competitive for datasets with time-series data.Long short term memory (LSTM) further improves RNN by providing an alternative approach to the gradient loss problem. LSTM has its own advantage in predictive accuracy by retaining memory for a longer time. In this paper, we combine both supervised and unsupervised dimension reduction methods with LSTM to enhance the forecasting performance and refer to this as a dimension reduction based LSTM (DR-LSTM) approach.For a supervised dimension reduction method, we use methods such as sliced inverse regression (SIR), sparse  SIR, and kernel SIR. Furthermore, principal component analysis (PCA), sparse PCA, and kernel PCA are used as unsupervised dimension reduction methods.Using datasets of real stock market index (S&P 500, STOXX Europe 600, and KOSPI), we present a comparative study on predictive accuracy between six DR-LSTM methods and time series modeling."
박스 구조물의 부재력 예측을 위한 딥러닝 모델 구현 및 성능 비교,2024,"['box structure', 'deep learning', 'optimization algorithm', 'neural network model', '박스 구조물', '딥러닝', '최적화 알고리즘', '신경망 모델']","본 연구에서는 박스 구조물의 부재력 예측을 위한 다양한 딥러닝 모델의 정확성을 비교하고자 하였다. 이를 위해 상용 유한요소 프로그램인 MIDAS를 이용하여 300개의 유한요소모델을 작성하고, 수치해석을 수행하여 딥러닝 모델에 적용하기 위한 학습데이터를 생성하였다. 또한, 딥러닝 모델의 정확성을 비교하기 위해 MLP, CNN, RNN 및 LSTM과 같은 다양한 신경망 모델과 Adam, SGD, RMSprop 및 Adamax 등 최적화 알고리즘을 교차 적용하여 16개의 딥러닝 모델을 생성하였다. 그 결과 Adam 최적화 알고리즘이 모든 모델에서 가장 우수한 성능을 보여주었으며, 특히 MLP 모델에서 가장 높은 R2 값을 나타내었다. 이를 통해, 박스 구조물의부재력 예측을 위한 최적의 딥러닝 모델 구성은 Adam optimizer와 MLP 구조임을 확인하였다.","In this study, we compared the accuracy of various deep learning models for estimating the member forces of box structures. Particularly, 300 finite element models were generated using the MIDAS commercial finite element program, and numerical analyses were performed to generate training data for the deep learning models. To compare model accuracy, 16 deep learning models were generated using various neural network architectures—MLP, CNN, RNN, and LST—and optimization algorithms, including Adam, SGD, RMSprop, and Adamax. The results demonstrated that the Adam optimizer consistently delivered best across all models, with the highest R2 value observed particularly in MLP. This confirms that the combination of the Adam optimizer and MLP architecture is the most effective configuration for predicting the member forces in box structures."
Identification of Atrial Fibrillation With Single-Lead Mobile ECG During Normal Sinus Rhythm Using Deep Learning,2024,"['Artificial Intelligence', 'Atrial Fibrillation', 'Electrocardiography', 'Mobile Applications', 'Probability Learning']",국문 초록 정보 없음,"Background: The acquisition of single-lead electrocardiogram (ECG) from mobile devices offers a more practical approach to arrhythmia detection. Using artificial intelligence for atrial fibrillation (AF) identification enhances screening efficiency. However, the potential of singlelead ECG for AF identification during normal sinus rhythm (NSR) remains under-explored.This study introduces a method to identify AF using single-lead mobile ECG during NSR.Methods: We employed three deep learning models: recurrent neural network (RNN), long short-term memory (LSTM), and residual neural networks (ResNet50). From a dataset comprising 13,509 ECGs from 6,719 patients, 10,287 NSR ECGs from 5,170 patients were selected. Single-lead mobile ECGs underwent noise filtering and segmentation into 10-second intervals. A random under-sampling was applied to reduce bias from data imbalance. The final analysis involved 31,767 ECG segments, including 15,157 labeled as masked AF and 16,610 as Healthy.Results: ResNet50 outperformed the other models, achieving a recall of 79.3%, precision of 65.8%, F1-score of 71.9%, accuracy of 70.5%, and an area under the receiver operating characteristic curve (AUC) of 0.79 in identifying AF from NSR ECGs. Comparative performance scores for RNN and LSTM were 0.75 and 0.74, respectively. In an external validation set, ResNet50 attained an F1-score of 64.1%, recall of 68.9%, precision of 60.0%, accuracy of 63.4%, and AUC of 0.68.Conclusion: The deep learning model using single-lead mobile ECG during NSR effectively identified AF at risk in future. However, further research is needed to enhance the performance of deep learning models for clinical application."
AI 기반 검사장비 교체주기 예측 플랫폼,2024,"['AI', 'PdM', 'Monitoring Program', 'Inspection Equipment', 'Shift-by-wire Control Unit']","최근 스마트 공장의 증가에 따라, 공정 장비의 노후화와 유지관리 비용이 증가하고 있다. 이로 인해서 생산 장비의 수명을 예측하는 기술의 필요성이 커지고 있다. 자동화 생산 라인의 동작이 잠시 중단되면 큰 비용 손실을초래할 수 있다. 따라서, 장비 상태 모니터링과 실시간 고장 예측 기술이 필수 불가결하다. 장비 고장에 관계없이수리하는 PM(Preventive Maintenance) 방식을 사용하지 않고 오작동 주기를 예측하는 PdM(Predictive Maintenance)으로 생산성을 높일 수 있다. 본 논문에서는 SCU(Shift-by-wire Control Unit) 검사 장비에 적용할AI(Artificial Intelligence) 기반 PdM 기술을 개발하였다. 개발된 플랫폼은 실시간 장비 상태 예측을 수행한다. 장비의 결함을 예측하기 위해 시뮬레이션을 통해 SCU 검사 장비의 전압과 주파수 데이터 셋을 생성했다. 그리고이 데이터를 RNN(Recurrent Neural Network), LSTM(Long Short-Term Memory) 및 GRU(Gated Recurrent Unit)의 세 가지 모델에 적용하고 성능을 비교하였다. 시뮬레이션 결과를 통해 R2-score 0.992의 정확도로 GRU가최적의 예측 속도와 정확도를 달성했다. 이러한 결과를 기반으로, GRU를 이용한 PdM 플랫폼을 개발하였다. 개발된 플랫폼은 실시간으로 입력되는 데이터를 기반으로 하루 주기의 데이터를 예측하는 기능을 갖도록 했다.","Recently, with the rise of smart factories, the aging of process equipment and maintenance costs are increasing. As a result, there is an increasing need for technology to predict the lifespan of production equipment. A brief shutdown of an automated production line can result in significant financial losses.Therefore, equipment condition monitoring and real-time failure prediction technology are indispensable.Productivity can be increased with PdM (Predictive Maintenance), which predicts malfunction cycles, rather than PM (Preventive Maintenance), which repairs equipment regardless of failure. In this paper, we developed AI (Artificial Intelligence)-based PdM technology to be applied to SCU (Shift-by-wire Control Unit) inspection equipment. The platform developed performs real-time equipment condition prediction. In order to predict equipment failure, a data set of voltage and frequency for SCU inspection equipment was created through simulation. Then, this data was applied to three models: RNN (Recurrent Neural Network), LSTM (Long Short-Term Memory), and GRU (Gated Recurrent Unit), and their performance was compared. Through the simulation results, the GRU model achieved optimal prediction speed and accuracy, with an R2-score of 0.992.Based on these results, a PdM platform using GRU was developed. The developed platform has a function that predicts daily cycle data based on real-time data input."
심전도 이상 탐지를 위한 Variational Autoencoder 비교 연구,2024,"['생성모형', 'variational autoencoder', '이상 탐지', '딥러닝', 'generative model', 'variational autoencoder', 'anomaly detection', 'deep learning']","심전도는 심장질환을 감지하고 진단하기 위한 도구로 널리 이용되고 있다. 이상 심전도를 탐지하기 위해 지도학습에 기반한 다양한 딥러닝 모형들이 제안되었으나, 정상 및 이상 데이터의 불균형 등으로 인해 제한적인 성능을 보였다. 이러한 문제를 해결하기 위해 생성모형인 variational autoencoder(VAE)를 이용한 이상 탐지 모형이 제안되었다. 이 방법은 정상 데이터로 VAE 모형을 학습하고, 검증 데이터를 이용하여 정상 및 이상을 구분하는 임계값을 설정한 후, 이를 통해 테스트 데이터의 정상 및 이상을 구분한다. VAE 모형은 인코더, 잠재변수 층, 디코더로 구분되며, 인코더 및 디코더에 딥러닝 모형을 내포할 수 있다. 본 논문에서는 다양한 설정 하에서 MLP, RNN, LSTM 모형이 내포된 VAE 모형을 비교하도록 한다. 우선 원자료 뿐만 아니라 심전도 자료의 시계열적 특성을 고려하여 1차 차분한 자료를 이용하였다. 또한 기존 연구에서 디코더의 분산을 1로 고정한데 반해, 본 연구에서는 디코더의 분산에 딥러닝 모형을 설정한 경우 역시 고려하였다. 분석 결과 원자료를 이용하고 디코더의 분산에 딥러닝 모형을 설정한 LSTM 기반의 VAE 모형의 성능이 가장 우수하였다. 또한 차분한 자료를 이용하는 것보다 원자료를 이용하는 경우 모든 모형의 성능이 더 우수하였다.","Electrocardiogram is widely used as a tool for detecting and diagnosing heart disease. Previous research revealed that deep learning models based on supervised learning have limited performance due to imbalance between normal and anomaly. To overcome this problem, anomaly detection models using variational autoencoder (VAE) have been proposed. After training VAE model using normal data, a threshold to distinguish normal and anomaly is set by using validation data, then test data is applied. VAE model has encoder, a latent variable layer, and decoder. and deep learning models are embedded in encoder and decoder. In this paper, VAE models embedding MLP, RNN, and LSTM are compared under various settings which are the type of data (original data or the first-order differential data) and the assumption for the variance of decoder. As results of analysis, VAE model based on LSTM is performed best when original data is used and a deep learning model for the variance of decoder is embedded. Additionally, the performance of VAE models using original data were better than models using first-order differential data."
기계 창작 시대 한시를 어떻게 향유할 것인가-한시 창작 AI에 대한 비판적 고찰-,2024,"['Sino-poetry database', 'Generative AI', 'AI Creating Sino-poetry', 'digital humanities', '九歌', 'SikuGPT2', '詩三百', '한시 데이터', '생성형 인공지능', '한시창작 AI', '디지털 인문학', '九歌', 'SikuGPT2', '詩三百']","본 글은 한시 창작 AI의 현황을 검토하고 향후의 가능성과 그 의미에 대해 논의한 것이다. 딥러닝 기술의 대두 이후 문화예술 분야에 대한 각종 창작 AI의 도전이 가시화되고 있으며, 한시에 대해서도 비슷한 시도가 포착되고 있다. 한시는 한자 문화권의 대표적 문예 양식으로서 함축과 풍격, 율격과 의상 등을 중시하는 그 특성으로 인해 창작 AI의 성능을 테스트하는 효과적 매개가 될 수 있다. 또한 창작 AI를 기동하기 위해서는 표준적 형식으로 구축된 대규모 한시 데이터셋(dataset)이 요구되는데, 중화권에서는 그러한 성격의 한시 데이터가 개방적으로 공유되고 있어, AI의 학습 데이터를 확보하기가 상대적으로 용이하다.현존하는 한시 창작 AI는 수십여 종에 이르며 <九歌>, <SikuGPT2>, <詩三百> 등이 그 대표적 사례에 해당한다. <九歌>는 청화대학교에서 제작한 창작 AI 및 구현 웹사이트로, 순환 신경망(RNN)의 방식을 사용하였다. 해당 창작 AI는 한시 약 80만여 수가 수록된 공개 데이터베이스를 활용하고 자체적으로 가공한 약 10만여 수의 한시 데이터베이스를 학습하여 이를 토대로 한시를 창작한다. <SikuGPT2>는 남경농업대학교에서 제작한 창작 AI로, GPT2의 인과 언어 모델(CLM) 방식을 사용하였다. 이 창작 AI는 한시 약 30만여 수가 수록된 공개 데이터베이스와 󰡔四庫全書󰡕 데이터베이스를 학습하여 창작에 활용하고 있다. <詩三百>은 언어 모델을 분명하게 제시하지는 않았으나, 위에서 언급한 공개 데이터베이스 외에도 대련 약 70만 연이 포함된 데이터베이스를 사용하고 있음을 밝히고 있다.한시 창작 AI는 AI 생성 모델(generative model)의 확장적 구현이라는 측면에서 일정한 의의를 지닌다고 해야겠으나, 점점 사멸해가는 한시 문학의 특성상 한시 창작 AI에 의해 창작된 작품은 의례적 칭찬 이상의 온당한 평가를 받기가 쉽지 않다. 다만 이로부터 몇 가지 시사점을 정리해보자면, 생성형 AI 기술을 테스트하는 과정에서 한시(근체시)라는 전통적 문예 장르가 유효하게 활용될 수 있다는 점, 한시 창작 AI를 구현하려면 본격적 학습 데이터로써 웹 표준 형식의 대규모 한시 데이터셋(dataset)이 구축되어야 한다는 점, 한시 창작 AI를 활용하는 과정에서 소위 ‘기계(machine)’를 매개로 한시에 관한 새로운 시각 및 통찰 등을 전달받을 가능성이 있다는 점 등을 예시해볼 수 있겠다. 그리고 현시점에서 상용화된 대표적 한시 창작 AI 플랫폼들로부터 ‘대동소이한 창작 경향’, ‘용사의 부재’, ‘율격에의 지나친 의존’ 등을 관찰할 수 있는데, 이러한 부정적 징후를 개선하기 위한 유효한 변수로 “고전비평” 데이터와 “사전류” 데이터를 추가 학습 자원으로 활용하는 것 등을 대안으로 생각해볼 수 있겠다.","This study examines the current status of Creative AI in Sino-poetry and discusses its future possibilities and implications. Since the rise of deep learning technology, various Creative AI challenges in the field of culture and arts have become visible, and similar attempts are being made in the field of Sino-poetry. Sino-poetry, a representative literary form of the East Asian culture, can be an effective medium to represent the performance of Creative AI due to its characteristics that emphasize connotation, style, rules, and images. In addition, genre big data based on web standard formats is required to trigger Creative AI, and Sino-poetry is fully equipped with this, making it very convenient to implement.There are dozens of Sino-poetry Creative AIs in existence, including <九歌>, <SikuGPT2>, <詩三百>. 九歌 is a Creative AI and implementation website created by Tsinghua University that uses a recurrent neural network (RNN) method. This Creative AI utilizes a public database of about 800,000 Sino-poetry and learns from its own database of about 100,000 Sino-poetry to create poems based on them. SikuGPT2 is a Creative AI created by Nanjing Agricultural University that uses GPT2's Causal Language Model (CLM) method. This Creative AI draws inspiration from extensive public databases, including around 300,000 Sino-poetry entries and the 󰡔四庫全書(Sikuquanshu)󰡕 database to fuel its creative processes. <詩三百> does not explicitly state its language model, but it reveals that in addition to the public databases mentioned above, it uses a 對聯(couplet) database containing about 700,000 couplet entries.While AI Creation for Sino-poetry has certain significance as a scalable implementation of AI Creative technology, the decline of Sino-poetry makes it difficult for the poems Created by AI to receive much more than cursory praise. Some takeaways, however, include the unexpected benefits of Sino-poetry in advancing Creative AI, the web-standardized format-based databases in China that have enabled rapid adoption of Creative AI, and the new context and insights that are generated in the process of guiding the training of Creative AI. In addition to the shortcomings commonly found in Creative AI, the work of Sino-poetry Creative AIs shows a tendency toward homogeneous creation, a lack of allusion, and an over-reliance on rules in Sino-poetry. Alternatives to these developmental weaknesses include using ""classical Sino-poetry criticism"" and accepting data from ""thesaurus"" as another valid variable in the function."
LSTM Autoencoder를 이용한 자기상관 공정의 모니터링 절차,2024,[],국문 초록 정보 없음,"Many studies have been conducted to quickly detect out-of-control situations in autocorrelated processes. The most traditionally used method is a residual control chart, which uses residuals calculated from a fitted time series model. However, many procedures for monitoring autocorrelated processes using statistical learning methods have recently been proposed. In this paper, we propose a monitoring procedure using the latent vector of LSTM Autoencoder, a deep learning-based unsupervised learning method. We compare the performance of this procedure with the LSTM Autoencoder procedure based on the reconstruction error, the RNN classification procedure, and the residual charting procedure through simulation studies. Simulation results show that the performance of the proposed procedure and the RNN classification procedure are similar, but the proposed procedure has the advantage of being useful in processes where sufficient out-of-control data cannot be obtained, because it does not require out-of-control data for training."
인공지능 기반 심리상담에 활용되는 딥러닝 기법 고찰,2024,"['인공지능', '심리상담', '딥러닝', '머신러닝', 'Artificial Intelligence', 'Psychological Counseling', 'Deep Learning', 'Machine Learning']","목적 본 연구는 첫째, 현재까지 발전해온 딥러닝 기법들에 대해서 고찰하여 정리해 보며, 둘째, 이러한 딥러닝 기법들이 실제로 인공지능 심리상담 로봇에 어떻게 활용될 수 있는지 논의하는데 주 목적이 있다.방법 인공지능 심리상담에서 활용되고 있는 최신 딥러닝 기법을 고찰하기 위해 2022년까지 감정 분석 및 표정 생성, 텍스트 생성분야에서 딥러닝 기법을 활용한 국내외 논문과 이를 설명한 서적들을 모두 검색하였다. 국내 논문 검색은 RISS, KISS, 국외 논문검색은 ERIC(ProQuest), JSTOR, Google Scholar 등의 논문 검색 사이트를 활용하였다.결과 인공지능을 심리상담에 활용할 때 주로 주목하는 기술은 상대방의 표정에서 감정을 인식하고 비슷한 표정을 생성해 내거나혹은 상대방이 말한 문장에서 감정을 인식하고 이에 응답하는 문장을 생성해 내는 것이다. 이에, 머신러닝과 딥러닝의 개념을 소개하고, 사람의 뇌에서 이루어지는 원리를 이용하여 인공지능을 만드는 방식인 딥러닝 기법들인 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), LSTM(Long Short Term Memory), Transformer, BERT(Bidirectional Encoder Representations from Transformers), GPT(Generative Pretrained Transformer), GAN(Generative Adversarial Network) 등이 작동하는 방식을 기술하였다. 특히, 지금까지 이미지 분석을 통한 감정 인식 프로그램은 주로 CNN을활용하고, 언어는 GPT-2, LSTM 등을 활용하여 연구가 진행되어 왔음이 확인되었다.결론 현존하는 딥러닝 기법 중 인공지능을 심리상담에 활용할 때 주로 주목하는 기술인 상대방의 표정에서 감정을 인식하고 비슷한표정을 생성 혹은 상대방이 말한 문장에서 감정을 인식하고 이에 응답하는 문장을 생성하는 방식이나, 아직까지 규칙 기반 챗봇이주를 이룬다. 이러한 딥러닝 기법을 활용한 인공지능 기반 상담의 장단점을 다루었으며 향후 자연스러운 상호작용이 가능한 기술발전이 요구될 뿐 아니라 그에 대한 효과성 검증이 필요하다.","Objectives This study aims to review and summarize deep learning techniques that have been developed to date and to discuss how they can be applied in practice to artificial intelligence-based psychology counseling robots.Methods To examine the latest deep learning techniques utilized in artificial intelligence psychological counseling, an extensive literature search was conducted for research papers and relevant books from both domestic and international sources in the fields of emotion analysis, facial expression generation, and text generation.. For domestic literature, databases such as RISS and KISS were utilized, and for international literature, research paper search sites including ERIC (ProQuest), JSTOR, and Google Scholar were employed.Results When applying artificial intelligence in psychological counseling, the prominent technology of interest involves recognizing emotions from the interlocutor's facial expressions and generating similar expressions, or recognizing emotions from sentences spoken by the interlocutor and generating responsive sentences. The study introduced the concepts of machine learning and deep learning and explained the workings of deep learning techniques, such as CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), LSTM (Long Short Term Memory), Transformer, BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pretrained Transformer), and GAN (Generative Adversarial Network). These techniques are founded on the principles derived from human brain functioning. Particularly, emotion recognition programs through image analysis have predominantly relied on CNN, while research in the realm of language has advanced with the utilization of GPT-2, LSTM, and similar methods.Conclusions Among the existing deep learning techniques, the recognition of emotions from the interlocutor's facial expressions and the generation of similar expressions, or the recognition of emotions from sentences spoken by the interlocutor and the generation of responsive sentences, are the technologies predominantly under scrutiny for their application in artificial intelligence-based psychological counseling. Nevertheless, rule-based chatbots continue to dominate the landscape. This paper explored the merits and demerits of AI-based counseling employing such deep learning techniques. Looking ahead, there is a need for the advancement of technology that enables natural interactions, coupled with the essential verification of its effectiveness."
3D CNN-LSTM 알고리즘을 이용한 손동작 비디오 영상 분류,2024,"['Artificial Intelligence', 'Deep Learning', 'CNN', 'LSTM', 'Video Classification', 'Hand Gesture Classification']","손동작 인식은 이미지나 비디오 데이터로부터 인간의 동작 및 제스처를 식별하는 행동인식기술의 한 형태이다. 디지털 기술의 발전으로 제품에 스마트 기능이 추가되는 사례가 많아지면서 동작인식의 편리성과 효율성도 강조 되고 있다. 본 연구는 손동작 인식을 시도하기 위한 과정으로, 손동작을 기반으로 클래스를 나누어 각각의 클래스를 분류해내는 비디오 분류 연구를 진행한다. 비디오 영상 자체로 딥러닝 분류를 하게 되면 정확도도 높으며, 이미지를 통한 비디오 분류보다 다양한 분야에서 활용이 가능하다는 장점이 있다. 제시된 알고리즘은 3D CNN(Convolutional neural network)과 LSTM(Long Short-Term Memory)이 결합된 형태로 이루어져 있다. 개발한 3D CNN은 이미지나 비디오의 특징 추출에 주로 사용하는 2D CNN 중 ResNet-18의 구조에서 고안하였다. LSTM은 순차 데이터를 학습, 처리, 분류하는 데 주로 사용되고 있는 RNN(Recurrent Neural Network)중의 한 종류이다. 3D CNN을 통해 비디오의 특징을 추출하고, LSTM을 통해 추출된 특징의 시퀀스를 학습 후 각 비디오 시퀀스를 손동작의 변화를 기준으로 하는 다섯 가지 클래스로 분류하였으며 비디오 분류 결과 정확도 평균 87%를 보여 주었다.","Hand gesture recognition is a subset of motion recognition technology that identifies human actions from image or video data. With the advancement of digital technology and the increasing integration of smart functions into products, the convenience and efficiency of motion recognition have become more prominent. This research aims to explore the process of hand gesture recognition by classifying video sequences based on hand gestures. The research focuses on video classification using deep learning techniques, which offer higher accuracy and broader applicability compared to image-based video classification. The proposed algorithm combines a 3D Convolutional Neural Network (3D CNN) with a Long Short-Term Memory network (LSTM). The developed 3D CNN is based on the ResNet-18 architecture, which is commonly used for feature extraction in images and videos. The LSTM, an extension of the Recurrent Neural Network (RNN), is employed to learn, process, and classify sequential data. The 3D CNN extracts features from video sequences, and the LSTM learns these feature sequences to classify each video sequence into one of five classes based on variations in hand gestures. The combined network, utilizing 3D CNN for feature extraction and LSTM for sequence learning, provides a robust approach to classify hand gestures in video sequences, demonstrating potential for diverse applications in various fields. The video classification accuracy reached approximately 87%."
가상자산 시계열 데이터의 분석과 예측 - 시계열 모델 및 인공지능 모델의 비교 및 개선점 제시,2024,"['가상자산', '비트코인', '인공지능', '시계열', '암호화폐', 'Virtual assets', 'Bitcoin', 'artificial intelligence', 'time series', 'cryptocurrency']","비트코인, 이더리움 등의 가상자산은 주식, 채권, 옵션 등 기존의 투자 자산과 달리 가격 산정의 근거가 되는 기초자산이 존재하지 않는다. 따라서 자본자산가격 결정 모델(CAPM)이나 배당할인(DCF) 모형 등의 가격 결정 매커니즘 분석을 사용하기 어렵다. 따라서 본 연구에서는펜데믹 기간을 포함해서 2019년부터 현재까지 가상자산 시계열 데이터를 이용해 과거 정보의의존경향을 반영하는 LSTM, 페이스북(메타)에서 개발한 구조적 상태 변화를 포착하는데 사용되는 Prophet, 시계열 데이터의 구조적인 변화를 모델링하는데 사용되는 HMM(Hidden Markov Model)을 선정했다. 또한 각 분석 기간을 구분하기 위해서 팬데믹 선언 시점, 미국연준(FRB)의 기준금리 결정 등의 요인을 고려했다. 이를 통해 각 모델의 성능을 평가하고, 기존 시계열 모델인 ARIMA와 비교를 통해 개선점과 한계점을 도출했다. 분석 결과, 신경망 모형을 사용한 인공지능 모델인 RNN, LSTM이 ARIMA 모형에 비해 높은 정확도를 보였다. 이러한 결과는 시계열 데이터의 시간적 의존성, 장기 의존성, 비선형 등의 특징을 잘 반영하기때문에 예측 정확도가 높은 것으로 보인다. 다만. 분석 기간 동안 코로나19로 인한 팬데믹 선언, 미국의 급격한 기준금리 인상 및 비트코인을 비롯한 가상화폐의 저변 확대 등 환경적 요인이 존재한다. 따라서 보다 정확한 모델의 성과 평가를 위하서는 이러한 환경적인 요인이 시계열 및 인공지능 모델에 어떻게 작용하지 분석이 필요하다.","This study examines various artificial intelligence models’ effectiveness in predicting virtual asset prices such as Bitcoin and Ethereum, which, unlike traditional assets, lack a tangible basis for valuation. Given the absence of a reliable pricing mechanism like CAPM or DCF models for virtual assets, the research leverages time series data since 2019, incorporating the pandemic period. It employs models such as LSTM, which accounts for past information dependencies; Prophet, developed by Facebook (Meta) for detecting structural changes; and HMM for modeling data structural shifts. These models were tested against ARIMA, con?sidering factors including pandemic timelines and U.S. Federal Reserve rate decisions. Results showed that the neural network-based models, RNN and LSTM, outperformed ARIMA, attributed to their superior handling of time series data characteristics. However, further investigations into the impact of external factors like pandemic declarations and interest rate changes on model accuracy and virtual asset price prediction are needed."
인공지능을 활용한 챔버형 반도체 제조 설비의 Fan Motor 이상감지 진단에 관한 연구,2024,"['CBM', 'Feature Engineering', 'LSTM', 'BiLSTM 오토인코더', 'Anomaly Score', 'CBM', 'Feature Engineering', 'LSTM', 'BiLSTM Auto-encoder', 'Anomaly Score']","반도체 장치산업은 막대한 투자비가 수반 되므로 생산 설비가 고유의 성능을 유지하기 위한 설비 예방보전 활동이 중요하다. 설비보전의 중요성으로 기업에서는 다양한 예방보전 활동이 진행되고 있으며, 아직은 수명에 의한 TBM(Time Base Maintenance) 형태의 예방보전에 의존하고 있다. 최근 기술 발전으로 AI 기법을 활용한 고장을 진단하고 사전 조치를 진행하는 CBM(Condition Based Maintenance) 예지보전 형태로 발전하고 있다. 본 논문에서는 반도체 챔버형 설비에서 Fan Motor 고장을 진단하기 위한 연구로 현장의 데이터와 가장 유사한 공공 데이터셋을 통해 진동신호를 AI 기법을 이용하여 고장진단 방법을 연구하였다. 첫 번째 선행연구에서 인공지능 딥러닝 기법으로 3가지 모델인 DNN, RNN, CNN로 고장을 예측하였고, 진동 신호 4개를 Feature Engineering을 통해 19개로 확대하여 동일하게 3가지 모델로 고장 예측을 비교 분석하여 모델 알고리즘의 성능을 개선하였다. 아울러 대부분의 AI 연구는 배치 단위의 시계열 데이터를 통한 고장진단 방법론을 연구하고 있다. 반도체 생산 현장은 24시간 가동되는 장비이므로 스트리밍 상태의 실시간 기반의 데이터를 활용하여 정상데이터를 학습하고 이상 데이터가 감지되면, 고장으로 분류가 가능한 오토인코더 기법을 활용하여 성능을 검증하고 고장진단 방법을 연구하였다. 본 연구에서 시사하는 바는 통상적인 인공지능 기법으로 알고리즘 성능을 개선하는 연구에서 한 단계 진전되어 Feature Engineering을 통한 성능개선을 진행하였다. 산업 현장에서 실제 적용이 가능한 오토인코더 알고리즘을 접목하여 고장 예측을 시각화하고, 정상상태를 학습하여 Anomaly Score을 예측하고, 이상 데이터가 발생 시 차이를 분석하여 고장 예측이 가능한 것을 검증하였다. 또한, 정상데이터의 학습데이터로 이상 데이터 예측이 가능하므로 정상학습 데이터의 Anomaly Score 최댓값으로 이상치를 등급화할 수 있다. 설비의 보전상태를 정상가동, 모니터링 상태, 보전상태 등으로 분류가 가능한 예지보전 시스템을 구현하는데 활용될 수 있다.","Since semiconductor device industry requires enormous investment costs, preventive maintenance activities are important to ensure that production equipment maintains its unique performance. Due to the importance of equipment maintenance, various preventive maintenance activities are being carried out by manufactures, and they still rely on preventive maintenance in the form of TBM (Time Base Maintenance) based on lifespan. With technological advancements, it is developing into a form of predictive maintenance that uses AI techniques to diagnose failures and take proactive measures. In this paper, a study was conducted to diagnose fan motor failure in semiconductor chamber-type equipment, and a failure diagnosis method was studied using vibration signals using AI techniques through similar data sets. First, in previous research, failure was predicted using three models (DNN, RNN, CNN) using artificial intelligence deep learning techniques, and the four vibration signals were expanded to 19 through feature engineering to compare failure predictions using the same three models. Through analysis, the performance of the model algorithm was improved. In addition, most AI research studies failure diagnosis methodologies through batch-level time series data. Since semiconductor production sites are equipment that operates 24 hours a day, normal data is learned using streaming real-time data, and when abnormal data is detected, the autoencoder technique is used to classify it as a failure, to verify performance and diagnose failures. was studied. The implication of this study is that it is a step forward from research on improving algorithm performance using typical artificial intelligence techniques, and has progressed to improve performance through feature engineering. We visualized failure prediction by incorporating an autoencoder algorithm that can be actually applied in industrial sites, predicted anomaly scores by learning normal states, and analyzed the differences when abnormal data occurs to verify that failure prediction is possible. In addition, since abnormal data can be predicted using normal learning data, outliers can be graded by grade based on the maximum Anomaly Score of normal learning data. It can be used to implement a predictive maintenance system that can classify the maintenance status of facilities into normal operation, monitoring status, and maintenance status."
전처리 방법과 인공지능 모델 차이에 따른 대전과 부산의 태양광 발전량 예측성능 비교: 기상관측자료와 예보자료를 이용하여,2024,"['Solar power generation', 'Residual analysis', 'Forecast data', 'Machine learning']",국문 초록 정보 없음,"As increasing global interest in renewable energy due to the ongoing climate crisis, there is a growing need for efficient technologies to manage such resources. This study focuses on the predictive skill of daily solar power generation using weather observation and forecast data. Meteorological data from the Korea Meteorological Administration and solar power generation data from the Korea Power Exchange were utilized for the period from January 2017 to May 2023, considering both inland (Daejeon) and coastal (Busan) regions. Temperature, wind speed, relative humidity, and precipitation were selected as relevant meteorological variables for solar power prediction. All data was preprocessed by removing their systematic components to use only their residuals and the residual of solar data were further processed with weighted adjustments for homoscedasticity. Four models, MLR (Multiple Linear Regression), RF (Random Forest), DNN (Deep Neural Network), and RNN (Recurrent Neural Network), were employed for solar power prediction and their performances were evaluated based on predicted values utilizing observed meteorological data (used as a reference), 1-day-ahead forecast data (referred to as fore1), and 2-day-ahead forecast data (fore2). DNN-based prediction model exhibits superior performance in both regions, with RNN performing the least effectively. However, MLR and RF demonstrate competitive performance comparable to DNN. The disparities in the performance of the four different models are less pronounced than anticipated, underscoring the pivotal role of fitting models using residuals. This emphasizes that the utilized preprocessing approach, specifically leveraging residuals, is poised to play a crucial role in the future of solar power generation forecasting."
Traditional Chinese medicine diagnostic prediction model for holistic syndrome differentiation based on deep learning,2024,"['Traditional Chinese medicine syndromes', 'Deep learning', 'Holistic syndrome differentiation', 'Expert knowledge', 'Artificial intelligence']",국문 초록 정보 없음,"Background: With the development of traditional Chinese medicine (TCM) syndrome knowledge accumulation and artificial intelligence (AI), this study proposes a holistic TCM syndrome differentiation model for the classification prediction of multiple TCM syndromes based on deep learning and accelerates the construction of modern foundational TCM equipment.Methods: We searched publicly available TCM guidelines and textbooks for expert knowledge and validated these sources using ten-fold cross-validation. Based on the BERT and CNN models, with the classification constraints from TCM holistic syndrome differentiation, the TCM-BERT-CNN model was constructed, which completes the end-to-end TCM holistic syndrome text classification task through symptom input and syndrome output. We assessed the performance of the model using precision, recall, and F1 scores as evaluation metrics.Results: The TCM-BERT-CNN model had a higher precision (0.926), recall (0.9238), and F1 score (0.9247) than the BERT, TextCNN, LSTM RNN, and LSTM ATTENTION models and achieved superior results in model performance and predictive classification of most TCM syndromes. Symptom feature visualization demonstrated that the TCM-BERT-CNN model can effectively identify the correlation and characteristics of symptoms in different syndromes with a strong correlation, which conforms to the diagnostic characteristics of TCM syndromes.Conclusions: The TCM-BERT-CNN model proposed in this study is in accordance with the TCM diagnostic characteristics of holistic syndrome differentiation and can effectively complete diagnostic prediction tasks for various TCM syndromes. The results of this study provide new insights into the development of deep learning models for holistic syndrome differentiation in TCM."
표면 근전도활용 순환 신경망을 이용한 보행 단계 인식,2024,"['Gait Phase Recognition', 'Surface Electromyography', 'Exoskeleton', 'Wearable Sensor', '보행 단계 인식', '표면 근전도', '외골격 로봇', '착용형 센서']","표면근전도는 외골격로봇에서 인간의 움직임 의도를 감지하는데 사용될 수 있으며, 인간이 보행할 때의 보행 단계는 하지 외골격을 제어하기 위한 요소이다. 보행 단계는 지면반력을 측정해 구분할 수 있지만, 이 센서를 외골격에 직접 사용하면 부자연스러운 움직임이 발생할 수 있고, 부피도 커진다. 근전도는 움직임 이전에 근육 활성화를 감지할 수 있다는 장점이 있지만 잡음과 시간 변동성으로 인해 직접 사용하기가 어렵다. 본 연구에서는 지면반력 정보를 사용하지 않고 근전도의 시계열 특성과 순환 신경망을 사용하여 걷기의 보행 단계를 감지하였다. 보행 주기는 실제 보행 동작이 발생하기 10 ms 전에 근전도를 통해 90% 정확도로 추정하였다. 이 연구를 통해 지면반력 센서 없이도 보행 단계를 추정할 수 있음을 보여주었으며, 이는 하지 외골격 로봇 연구에서 시스템 구조를 단순화하고, 제어를 안정화하는데 도움이 될 것으로 기대한다.","This study focused on the recognition of gait phases using surface electromyography (sEMG) and a recurrent neural network (RNN). The goal was to enhance the performance of lower-limb exoskeletons, which assist in walking, by detecting human movement intent. Traditionally, ground reaction force (GRF) sensors have been used for gait phase detection; however, these sensors can cause issues with bulky designs and unnatural movement. Surface electromyography offers an advantage by detecting muscle activation before movement occurs, though it faces challenges such as noise and time variability. In this study, an RNN was applied to time-series sEMG data to predict gait phases without using GRF sensors. The model achieved a 90% accuracy in predicting gait phases 10 ms before the actual movement. This approach demonstrates that sEMG can serve as an alternative to GRF sensors, simplifying exoskeleton system designs and improving control stability. The findings suggest that using sEMG and RNNs can significantly enhance the functionality of wearable robotic systems aimed at assisting walking."
Predicting the Progression of Mild Cognitive Impairment to Alzheimer’s Dementia Using Recurrent Neural Networks With a Series of Neuropsychological Tests,2024,"['Alzheimer’s disease', 'mild cognitive impairment', 'dementia', 'neuropsychological tests', 'neural network models']",국문 초록 정보 없음,"Background and Purpose The prevalence of Alzheimer’s dementia (AD) is increasing as populations age, causing immense suffering for patients, families, and communities. Unfortunately, no treatments for this neurodegenerative disease have been established. Predicting AD is therefore becoming more important, because early diagnosis is the best way to prevent its onset and delay its progression.Methods Mild cognitive impairment (MCI) is the stage between normal cognition and AD, with large variations in its progression. The disease can be effectively managed by accurately predicting the probability of MCI progressing to AD over several years. In this study we used the Alzheimer’s Disease Neuroimaging Initiative dataset to predict the progression of MCI to AD over a 3-year period from baseline. We developed and compared various recurrent neural network (RNN) models to determine the predictive effectiveness of four neuropsychological (NP) tests and magnetic resonance imaging (MRI) data at baseline.Results The experimental results confirmed that the Preclinical Alzheimer’s Cognitive Composite score was the most effective of the four NP tests, and that the prediction performance of the NP tests improved over time. Moreover, the gated recurrent unit model exhibited the best performance among the prediction models, with an average area under the receiver operating characteristic curve of 0.916 Conclusions Timely prediction of progression from MCI to AD can be achieved using a series of NP test results and an RNN, both with and without using the baseline MRI data."
수처리 공정 최적화를 위한 XAI (eXplainable AI) 기법 비교 분석,2024,"['XAI(eXplainable AI)', 'RNN', 'Local Interpretable Model-agnostic Explanations', 'Adversarial Example Analysis', 'Feature Importance Analysis', 'Wastewater Treatment System']",국문 초록 정보 없음,"In this paper, in order to optimize the biological water treatment process, we review three representative methods among XAI's post-hoc explainability techniques. Among them, LIME and AEA methods are applied to the water treatment biological process to find an optimization method. presented. XAI's post-hoc explainability technique is applied to solve the black box problem of not knowing what is attributable to the water treatment artificial intelligence model, which is commonly used in water treatment process optimization, even if it produces good results. We analyzed which control variables were responsible for the improvement in the quality of treated water. As a result of the analysis, it was confirmed that the LIME method had a greater influence on the quality of treated water than the AEA method. In addition, it was found that this method contributes to solving the black box problem and improving the quality of treated water. In the case of the LIME method applied to the water treatment biological process in this paper, although it is not common, it was possible to analyze the characteristics of output variables even for input variables other than control variables by observing the results graphically. In the future, it is believed that by systematizing such graph analysis into an algorithm, it will be possible to propose a more effective LIME method."
LSTM을 이용한 탄천에서의 시간별 하천수위 모의,2024,"['LSTM', 'machine  learning', 'RNN', 'hourly  water  level', 'Tancheon  river']",국문 초록 정보 없음,"This study was conducted on how to simulate runoff, which was done using existing physical models, using an LSTM (Long Short-Term Memory)model based on deep learning. Tancheon, the first tributary of the Han River, was selected as the target area for the model application. To apply themodel, one water level observatory and four rainfall observatories were selected, and hourly data from 2020 to 2023 were collected to apply the model.River water level of the outlet of the Tancheon basin was simulated by inputting precipitation data from four rainfall observation stations in the basinand average preceding 72-hour precipitation data for each hour. As a result of water level simulation using 2021 to 2023 data for learning and testingwith 2020 data, it was confirmed that reliable simulation results were produced through appropriate learning steps, reaching a certain mean absoluteerror in a short period time. Despite the short data period, it was found that the mean absolute percentage error was 0.5544∼0.6226%, showing anaccuracy of over 99.4%. As a result of comparing the simulated and observed values of the rapidly changing river water level during a specific heavyrain period, the coefficient of determination was found to be 0.9754 and 0.9884. It was determined that the performance of LSTM, which aims tosimulate river water levels, could be improved by including preceding precipitation in the input data and using precipitation data from various rainfallobservation stations within the basin."
DNN(Deep Neural Network)과 앙상블 학습모델을 활용한 낙상사고 방지에 관한 실증연구,2024,"['HPE(Human Pose Estimation)', 'ANN', 'CNN', 'DNN', 'RNN', 'Fall Prediction', 'Person Skeleton', '사람자세예측', '인공지능', '낙상예측', '사람관절']",국문 초록 정보 없음,"The method of analyzing human poses is to predict the coordinate value of each joint in advance by predicting the movement of the body movement and a method of extracting the movement data of the joint.In this study, a dataset of human joints is constructed using a coco model among DNN (Deep Neural Network) models using 34 joint datasets for the construction of human joints. The coco model is convenient to construct a dataset by detecting various objects and is highly utilized to efficiently recognize two-dimensional objects. For example, it can have a great effect on preventing falls from beds for patients who cannot move well in domestic nursing hospitals or nursing homes. In this study, a camera applied with NVIDIA GPU-based Jetson Nano was manufactured and empirically verified, and an ensemble learning model was used to predict safety and risk posture."
흉부 X-선 영상을 이용한 Vision transformer 기반 폐렴 진단 모델의 성능 평가,2024,"['딥러닝', '폐렴 진단', '흉부 X-선 영상', 'Vision transformer', 'Deep learning', 'Pneumonia detection', 'Chest X-ray image']",국문 초록 정보 없음,"The various structures of artificial neural networks, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have been extensively studied and served as the backbone of numerous models. Among these, a transformer architecture has demonstrated its potential for natural language processing and become a subject of in-depth research. Currently, the techniques can be adapted for image processing through the modifications of its internal structure, leading to the development of Vision transformer (ViT) models. The ViTs have shown high accuracy and performance with large data-sets. This study aims to develop a ViT-based model for detecting pneumonia using chest X-ray images and quantitatively evaluate its performance. The various architectures of the ViT-based model were constructed by varying the number of encoder blocks, and different patch sizes were applied for network training. Also, the performance of the ViT-based model was compared to the CNN-based models, such as VGGNet, GoogLeNet, and ResNet. The results showed that the traninig efficiency and accuracy of the ViT-based model depended on the number of encoder blocks and the patch size, and the F1 scores of the ViT-based model ranged from 0.875 to 0.919. The training effeciency of the ViT-based model with a large patch size was superior to the CNN-based models, and the pneumonia detection accuracy of the ViT-based model was higher than that of the VGGNet. In conclusion, the ViT-based model can be potentially used for pneumonia detection using chest X-ray images, and the clinical availability of the ViT-based model would be improved by this study."
증분 용량 분석법과 딥러닝을 이용한 리튬 이온 배터리의 SOH 추정 방안 연구,2024,"['Lithium-ion Battery', 'Incremental Capacity Analysis', 'Correlation analysis', 'Deep learning', 'RNN(Recurrent Neural Network)', 'LSTM(Long Short Term Memory)', 'GRU(Gate Recurrent Unit)', 'SOH Estimation.']",국문 초록 정보 없음,"Lithium-ion batteries are being utilized as energy sources for electric vehicles due to their advantages such as high energy density, long life, and high efficiency. In order to ensure the safe condition of lithium-ion batteries under various driving conditions of electric vehicles, it is necessary to analyze the degradation status and causes of lithium-ion batteries and accurately estimate their state of health (SOH). Therefore, this paper proposes a method for estimating the SOH of lithium-ion batteries using incremental capacity analysis and deep learning. Incremental capacity analysis is a technique that analyzes the electrochemical state inside a lithium-ion battery and can identify the degradation state of the battery. Through this method, parameters related to degradation were extracted, and their usefulness as characteristic parameters for SOH estimation was verified by correlation analysis. The characteristic parameters validated through correlation analysis were used as inputs to deep learning algorithms for SOH estimation to compare the accuracy of SOH estimation by different estimation algorithms."
An Examination of the Impulse Response Function Under Configuration of the Multiple Autoregressive,2024,"['Causality', 'Exchange rate', 'Population growth Multivariate', 'Time Series', 'Vector Autoregressive', 'RNN']",국문 초록 정보 없음,"In this research, we study the Iraqi economy, considering the exceptional circumstances it went through during the period of the study, represented by wars, economic sanctions, and finally the Coronavirus, which affected all the economies of the world, and the wrong policies generated many problems such as high prices, low exchange rate of the Iraqi dinar, and the deficit Budget, unemployment and others. Therefore, this research focuses on the primary issue facing the Iraqi economy: inflation and its correlation with the exchange rate. This is because the Central Bank, as the monetary authority, uses the exchange rate as a key tool to guide its monetary policies towards stability. We used the autoregressive vector model to analyze data spanning from 1990 to 2021. Where the direction of the causal relationship between the variables under study was determined and measured using the Cranger test for causality, as the exchange rate relationship with inflation and its time repercussions were described. We also used the co-integration test to ascertain the existence of a long-term relationship between the variables under study."
AI-based Pairs Trading Strategies: A Novel Approach to Stock Selection,2024,"['Pairs Trading', 'Similarity Analysis', 'Autoencoder', 'Vector Embeddings', 'LSTM']",국문 초록 정보 없음,"Purpose: This study aims to explore the optimization of Stock Pairs Trading Strategies' performance using AI techniques, with a focus on accurately evaluating stock similarities and selecting the most suitable pairs.Design/methodology/approach: A variety of AI models, including Autoencoders (AE), Vector Embeddings (VE), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRU), are utilized to assess the similarity between stocks, which is crucial in the stock pairs selection process for implementing the Pairs Trading strategy.Findings: The implementation of the Pairs Trading strategy with stock pairs selected through AI models showed higher profitability than conventional methods. Strategies utilizing LSTM models demonstrated the highest performance, achieving an approximate cumulative return of 51.25353%. This indicates that AI models are capable of accurately assessing similarities and establishing effective trading strategies.Research limitations/implications: The study highlights the potential of AI-based stock pair selection methods to enhance Pairs Trading Strategies' performance. This approach surpasses traditional statistical methods by better reflecting the stock market's complexity and dynamism, potentially offering investors more stable and higher returns.Originality/value: The research contributes to the field by demonstrating the effectiveness of AI models in the stock pair selection process, suggesting a novel approach to enhancing Pairs Trading Strategies that could provide valuable insights for investors seeking more sophisticated investment strategies in the financial markets."
대기오염물질 농도 데이터의 결측 보완을 위한 순환 신경망 활용도 비교 연구,2024,"['순환 신경망', '시계열', '결측', '미세먼지']","대기 중의 미세먼지(PM)는 시공간 의존성을 모두 갖는 환경 현상으로, 기준 시간 단위마다 대기오염물질측정소에서 수집되는 미세먼지 농도 자료를 활용한 연구는 이러한 현상 특성을 고려해야 한다. 본 연구는 데이터의 시간 의존성을 고려하는 여러 순환 신경망 모형(RNN, LSTM, Bi-LSTM, 1DCNN-LSTM)을 통해 1시간 단위 미세먼지 농도 자료에 포함된 결측치를 보완하여 그 결과를 반영하는 농도 지도를 제작함으로써, 각 모형의 데이터 보완 결과를 비교하고자 하였다. 연구 결과 가장 높은 결측 보완 정확도를 보유하는 모형은 1차원 CNN-LSTM 모형으로, 해당 모형은 결측 형태에 따라 구분된 장기 결측 및 단기 결측 지점에 대해서도 높은 정확도를 보이고 있었다. 본 연구는 자료의 결측 보완을 위한 방법론을 구상할 때 순환 신경망 모형의 활용을 고려하는 경우 모형 선정에 참고할 수 있는 유용한 지침으로 활용될 수 있다.",다국어 초록 정보 없음
Real-time prediction of wave-induced hull girder loads for a large container ship based on the recurrent neural network model and error correction strategy,2024,"['Recurrent neural network', 'Hull girder loads', 'Ship motions', 'Error correction strategy']",국문 초록 정보 없음,"Real-time acquisition of wave-induced hull girder loads of a sailing ship will help the captain make reasonable decisions, which is of great significance for improving the safety of the ship’s navigation. This paper investigates the real-time prediction method of hull girder loads based on the Recurrent Neural Network (RNN) model and error correction strategy. Firstly, taking the vertical bending moment, horizontal bending moment, and torsional moment at the mid-ship position of a large container ship as examples, corresponding neural network prediction models are established through parameter influence analysis. Secondly, various sea state conditions are used to verify the feasibility of established network prediction models to predict the hull girder loads in real-time. The VBM prediction model performs better than the TM prediction model and HBM prediction model, and the errors of the TM prediction model and HBM prediction model are slightly larger in some cases. Lastly, an improved prediction model based on an error correction strategy is proposed to improve the prediction accuracy of the neural network prediction model, and the adequate performance of the error correction strategy is discussed."
딥 뉴럴 네트워크를 활용한 강우 나우캐스팅의 최신 동향과 한계 극복을 위한 향후 과제,2024,"['Nowcasting', 'Deep neural networks', 'Convolutional neural networks', 'Recurrent neural networks', 'Generative adversarial networks', 'Extreme rainfall', '나우캐스팅', '딥 뉴럴 네트워크', '합성곱 신경망', '순환 신경망', '생성적 적대 신경망', '극한 강우']","딥러닝 모델은 방대한 데이터를 활용하여 강우 시스템의 복잡한 시공간 패턴을 효과적으로 포착함으로써, 기존 수치예보(Numerical Weather Prediction, NWP) 모델과 레이더 에코 외삽법의 계산 속도 및 비선형 강수 동역학 처리의 한계를 보완하여 단기 강우 예측에서 뛰어난 성과를 보이고 있다. 이에 따라, 본 논문에서는 딥러닝 기반 강우 나우캐스팅 모델을 체계적으로 리뷰하고, 합성곱 신경망(Convolutional Neural Networks, CNN), 순환 신경망(Recurrent Neural Networks, RNN), 생성적 적대 신경망(Generative Adversarial Networks, GAN) 기반의 세 가지 주요 그룹으로 분류하여 분석하였다. 또한, 각 모델에서 나온 공통적인 한계점과 이들 문제를 해결하기 위한 전략을 심도 있게 조사하였다. 다양한 손실함수의 적용, 전이학습, 샘플링, 그리고 앙상블 모델의 활용과 같은 혁신적인 접근법이 모델 성능 개선에 미치는 영향을 논의하며, 이를 바탕으로 강우 나우캐스팅의 향후 연구 방향을 제시한다. 본 리뷰는 강우 나우캐스팅에 대한 딥러닝 기반 기술의 현재 상태를 이해하고, 향후 연구 및 기술 발전을 위한 지침을 제공하는 데 기여하고자 한다.","Deep learning models have demonstrated remarkable performance in short-term rainfall prediction by effectively capturing the complex spatiotemporal patterns of rainfall systems using vast datasets. This has helped to address the limitations of traditional Numerical Weather Prediction (NWP) models and radar echo extrapolation methods, such as computational speed and nonlinear precipitation dynamics. In this paper, we systematically review deep learning-based rainfall nowcasting models, categorizing them into three main groups: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs). We also conduct an in-depth analysis of the common limitations identified in these models and explore strategies to overcome them. Innovative approaches, such as the application of diverse loss functions, transfer learning, sampling techniques, and ensemble models, are discussed in terms of their impact on enhancing model performance. Based on these findings, we propose future research directions for rainfall nowcasting. This review aims to provide a comprehensive understanding of the current state of deep learning-based technologies for rainfall nowcasting and serve as a guide for future research and technological advancements in the field."
한국어 코퍼스에서 딥러닝 기반 감성 분석 모델,2024,"['Sentimental Analysis', 'Machine Learning', 'Deep Learning', 'Transformer', 'GPT', '감성 분석', '머신러닝', '딥러닝', 'Transformer', 'GPT']",국문 초록 정보 없음,"This study comprehensively analyzes the emotional analysis model using deep learning in the Korean corpus, and discusses major research achievements and technological advances. Emotional analysis is the process of extracting and classifying subjective information from text, and the development of deep learning has brought many changes in the field of emotional analysis. Starting with the traditional emotional analysis method, the development of early deep learning models using RNN and CNN is examined, and the process of greatly improving the complex context understanding and processing ability of text through Transformer-based models is analyzed. In this process, models such as BERT and GPT show high performance and potential for expansion to various languages and domains. In addition, it analyzes the research trends of multi-lingual and domain emotional analysis and discusses how to increase the generalization ability of the model through cases using zero-shot and transfer learning. In addition, it also introduces major datasets and evaluation indicators. Finally, it mentions various challenges such as ethical issues in practical applications and suggests future research directions."
시공간 데이터 학습을 이용한 딥러닝 모델 기반 교통사고 위험 예측,2024,"['traffic accident forecasting', 'deep learning', 'spatiotemporal data', 'attention block', 'time-series data estimation']",국문 초록 정보 없음,"Traffic accidents forecasting is highly useful because it enables prevention activities, but the high irregularity and sparsity of data make training very difficult. This study proposes an efficient deep learning model to improve the accuracy of traffic accident risk forecasting and a method to effectively utilize spatiotemporal data. The proposed model has a 2D convolutional layer block to extract features in grid space, an RNN layer block to learn time series characteristics, and an attentional block to effectively learn the association between the feature data used for training and the learned feature map In the comparative evaluation with other models, the proposed model showed better performance with fewer learning parameters. We have also shown that various data, including secondary processing data, can be utilized as training data to improve prediction performance."
해양 선박 발전기 데이터를 이용한 순환 신경망 적용 방안 연구,2024,"['해양', '선박', '발전기', '최적화', '순환신경망', 'Marine', 'Ship', 'Generator', 'Optimization', 'Recurrent Neural Network']",국문 초록 정보 없음,"The need for condition monitoring, diagnostics, and predictive technologies has become increasingly prominent to ensure the stable operational performance of ships, detect anomalies based on core equipment data of engine systems, and improve efficiency in fault prevention and operational management. However, traditional ship fault monitoring systems use alarm monitoring systems (AMS) that alert when the set points are exceeded or not met, but such fault diagnosis systems cannot predict anomalies in advance. Therefore, this study analyzes public data of ship generators based on recurrent neural networks (RNN) and evaluates the appropriateness and performance of the models according to different optimizers. By assessing the predictive capabilities in a maritime environment and analyzing each model, the study aims to verify the reliability of the appropriate models. This is expected to significantly reduce the cost and time compared to the previous methods of periodic preventive maintenance or repairs after a fault occurs, thereby increasing the efficiency of ship operations."
Egocentric 3D Skeleton Learning in a Deep Neural Network Encodes Obese-like Motion Representations,2024,"['Obesity', 'Egocentric', '3D skeleton', 'Identity', 'LSTM', 'Behavior']",국문 초록 정보 없음,"Obesity is a growing health concern, mainly caused by poor dietary habits. Yet, accurately tracking the diet and food intake of individuals with obesity is challenging. Although 3D motion capture technology is becoming increasingly important in healthcare, its potential for detecting early signs of obesity has not been fully explored. In this research, we used a deep LSTM network trained with individual identity (identity-trained deep LSTM network) to analyze 3D time-series skeleton data from mouse models with diet-induced obesity. First, we analyzed the data from two different viewpoints: allocentric and egocentric. Second, we trained various deep recurrent networks (e.g., RNN, GRU, LSTM) to predict the identity. Lastly, we tested whether these models effectively encode obese-like motion representations by training a support vector classifier with the latent features from the last layer. Our experimental results indicate that the optimal performance is achieved when utilizing an identity-trained deep LSTM network in conjunction with an egocentric viewpoint. This approach suggests a new way to use deep learning to spot health risks in mouse models of obesity and should be useful for detecting early signs of obesity in humans."
SEMD 분해 및 LSTM 모델을 활용한 제조업 업황실적 예측 모델 구축 및 영향 요인 분석,2024,"['제조업', '업황실적', '순환신경망', 'SEMD 분해', 'NMIFS-HHO', 'Manufacturing', 'Condition BSI', 'Recurrent Neural Networks', 'SEMD', 'NMIFS-HHO algorithm']",국문 초록 정보 없음,"With the recent COVID-19 pandemic, uncertainty has been substantially increased regarding the conditions on manufacturing industry. This research focused on directly or indirectly contributing to the establishments of policies which can be linked to reducing the underlying uncertainties among manufacturing industries by constructing a deep-learning based manufacturing BSI prediction model, while extracting information and marginal contributions of factors related to manufacturing condition BSI under certain time lag. This research used factor selection methods based on SEMD decomposition and NMIFS-HHO algorithms to extract a set of highly relevant covariates, while supervising a LSTM layer based RNN model, which led to the construction of a deep learning model capable of predicting manufacturing condition BSIs with high accuracy. Results show that the considered model can return accurate predictions with extremely low errors, with covariates such as long-term signal(IMF) with a 3 to 4 year period, composite index, and government rate being found important in terms of marginal contributions for prediction using SHAP analysis."
중소유통기업지원을 위한 상품 카테고리 재분류 기반의 수요예측 및 상품추천 방법론 개발,2024,"['Small and Medium Distribution Industry', 'Demand Forecasting', 'Recommendation', 'Time Series Prediction', 'Deep Learning']",국문 초록 정보 없음,"Distribution and logistics industries contribute some of the biggest GDP(gross domestic product) in South Korea and the number of related companies are quarter of the total number of industries in the country. The number of retail tech companies are quickly increased due to the acceleration of the online and untact shopping trend. Furthermore, major distribution and logistics companies try to achieve integrated data management with the fulfillment process. In contrast, small and medium distribution companies still lack of the capacity and ability to develop digital innovation and smartization. Therefore, in this paper, a deep learning-based demand forecasting & recommendation model is proposed to improve business competitiveness. The proposed model is developed based on real sales transaction data to predict future demand for each product. The proposed model consists of six deep learning models, which are MLP(multi-layers perception), CNN(convolution neural network), RNN(recurrent neural network), LSTM(long short term memory), Conv1D-BiLSTM(convolution-long short term memory) for demand forecasting and collaborative filtering for the recommendation. Each model provides the best prediction result for each product and recommendation model can recommend best sales product among companies own sales list as well as competitor’s item list. The proposed demand forecasting model is expected to improve the competitiveness of the small and medium-sized distribution and logistics industry."
MAGRU: Multi-layer Attention with GRU for Logistics Warehousing Demand Prediction,2024,"['Gated Recurrent Unit', 'Attention mechanism', 'Commodities demand forecast', 'Time series', 'Neural Network']",국문 초록 정보 없음,"Warehousing demand prediction is an essential part of the supply chain, providing a fundamental basis for product manufacturing, replenishment, warehouse planning, etc. Existing forecasting methods cannot produce accurate forecasts since warehouse demand is affected by external factors such as holidays and seasons. Some aspects, such as consumer psychology and producer reputation, are challenging to quantify. The data can fluctuate widely or do not show obvious trend cycles. We introduce a new model for warehouse demand prediction called MAGRU, which stands for Multi-layer Attention with GRU. In the model, firstly, we perform the embedding operation on the input sequence to quantify the external influences; after that, we implement an encoder using GRU and the attention mechanism. The hidden state of GRU captures essential time series. In the decoder, we use attention again to select the key hidden states among all-time slices as the data to be fed into the GRU network. Experimental results show that this model has higher accuracy than RNN, LSTM, GRU, Prophet, XGboost, and DARNN. Using mean absolute error (MAE) and symmetric mean absolute percentage error(SMAPE) to evaluate the experimental results, MAGRU’s MAE, RMSE, and SMAPE decreased by 7.65%, 10.03%, and 8.87% over GRU-LSTM, the current best model for solving this type of problem."
인공 지능 기술을 이용한 음성 인식 기술에 대한 고찰,2024,"['Speech Recognition', 'Deep Neural Networks', 'Silent Speech Interface', 'Lip-Reading Technology', 'Self-Supervised Learning']",국문 초록 정보 없음,"This paper explores the recent advancements in speech recognition technology, focusing on the integration of artificial intelligence to improve recognition accuracy in challenging environments, such as noisy or low-quality audio conditions. Traditional speech recognition methods often suffer from performance degradation in noisy settings. However, the application of deep neural networks (DNN) has led to significant improvements, enabling more robust and reliable recognition in various industries, including banking, automotive, healthcare, and manufacturing. A key area of advancement is the use of Silent Speech Interfaces (SSI), which allow communication through non-speech signals, such as visual cues or other auxiliary signals like ultrasound and electromyography, making them particularly useful for individuals with speech impairments. The paper further discusses the development of multi-modal speech recognition, combining both audio and visual inputs, which enhances recognition accuracy in noisy environments. Recent research into lip-reading technology and the use of deep learning architectures, such as CNN and RNN, has significantly improved speech recognition by extracting meaningful features from video signals, even in difficult lighting conditions. Additionally, the paper covers the use of self-supervised learning techniques, like AV-HuBERT, which leverage large-scale, unlabeled audiovisual datasets to improve performance. The future of speech recognition technology is likely to see further integration of AI-driven methods, making it more applicable across diverse industries and for individuals with communication challenges. The conclusion emphasizes the need for further research, especially in languages with complex morphological structures, such as Korean"
사영 변환 특징 추출 기법을 이용한 우선 순위 특징 추출,2024,"['Time Series Data Processing', 'Feature extraction', 'Presence or Absence of Precipitation', '시계열 데이터 처리', '특징 추출', '강수 유무 예측']","데이터의 시계열적 상관관계를 이용하여 데이터의 예측 및 분석을 하는 시계열 데이터 처리는 다양한 분야에서 연구가 진행되고 있다. 이전에는 칼만필터 혹은 파티클필터 같은 신호처리기법이 사용되었으나 최근에는 딥러닝을 활용한 시계열 데이터 처리 기법에 대한 연구가 진행되고 있다. 또한 가용한 데이터가 많아져 딥러닝 연구에 이점이 있으나 불필요한 데이터의 사용은 성능에 역효과를 줄 수 있다. 본 논문에서는 시계열 데이터 처리를 위한 ‘사영 변환 특징 추출 기법’을 제안한다. 제안하는 기법은 사영 변환을 통해 특징을 도출하고,데이터에서 해당 특징에 대한 성분을 제거한 뒤 다시 특징을 도출하는 반복적인 기법을 통해 특징을 도출한다. 이렇게 도출한 특징은 중복된 성분이 없을 뿐만 아니라 먼저 도출한 특징에 많은 정보가 있는 우선 순위가 있는 특징이 되어 특징 선택을 할 때 효과적이다. 강수유무를 예측하는 시뮬레이션을 통해 제안하는 기법의 특징 추출 기법을 비교 검증하고 결과적으로 성능을 유지하면서도 입력 데이터의 차원을 줄일 수 있다는 것을 보인다.","Time series data processing, which predicts or analyzes given data using timeseries correlations, is being researched in various fields. Previously, signalprocessing techniques such as Kalman filter or particle filter were used, butrecently, research is being conducted on time series data processing techniquesusing deep learning such as LSTM, RNN and Transformer network. Further, thereare advantages to deep learning research if more available data are provided, butthe use of unnecessary data can have an adverse effect on their performance. Inthis paper, we propose ‘projective transform feature extraction technique’ fortime series data processing. The proposed technique extracts features throughprojective transformation using simple neural network, removes components for thefeatures from the data, and then derives the features again through an iterativemethod. The features extracted in this way not only do not have duplicatingcomponents, but are also priority features with a lot of information in the featuresderived earlier, making them effective when selecting features. Through asimulation of predicting the presence or absence of precipitation, we compare andverify the feature extraction method of the proposed technique and show that thedimensionality of the input data can be reduced while maintaining predictionperformance."
Ceramic tile surface defect detection with integrated feature engineering and defect fuse classifier,2024,"['Ceramic tile', 'Defect detection', 'Hybrid optimization model', 'Defectfuse classifier']",국문 초록 정보 없음,"Introduction: Ceramic tile surface defect detection is crucial for ensuring product quality. This study proposes an integratedapproach combining feature engineering and a Defect Fuse Classifier for accurate defect detection. Methods: The proposedmodel utilizes Python and splits the collected data into 70% for training and 30% for testing. Purpose: The purposesection explicitly states the objectives of the study. It highlights the research goals, such as evaluating the effectiveness ofthe proposed methodology in detecting ceramic tile surface defects and exploring the impact of parameter variations ondetection performance. Results: Comparative analysis with state-of-the-art methods is conducted using various metrics suchas sensitivity, specificity, accuracy, precision, FPR, FNR, NPV, F-Measure, and MCC. (a) For a Training Rate of 70%: Theproposed Defect Fuse Classifier outperforms existing models with an accuracy of 97.4%, precision of 88.5%, sensitivity of88.5%, specificity of 98.5%, F-Measure of 88.5%, MCC of 87%, NPV of 98.5%, FPR of 1.4%, and FNR of 11.4%. Conclusion:This study introduces a novel deep learning approach for ceramic tile surface defect detection, encompassing data acquisition,pre-processing, feature extraction, feature selection, and deep learning-based defect detection. The proposed Defect FuseClassifier, integrating CNN, Bi-LSTM, and RNN, demonstrates superior performance, making it a promising solution fordefect detection in ceramic tile surfaces."
Deep Spectral Time-Variant Feature Analytic Model for Cardiac Disease Prediction Using Soft Max Recurrent Neural Network in WSN-IoT,2024,['Predict cardiac disease  · Extensive data analysis  · CIIR  · Feature selection and classifi cation  · Neural network  · SMAF  · IOT-WSN'],국문 초록 정보 없음,"Cardiac disease analysis in big data is an emerging factor for human health protection against heart attacks. Most cardiovascular diseases lead to heart failure due to an imbalance of immunity and attention in health conditions. Hence, immunity-based feature analysis of patients’ records is essential to predict accurate results. The machine learning methods make predictions depending on the extended-lasting features to analyze the health data. But the marginal features expose non-relational feature observation to reduce the classifi cation prediction accuracy. We propose a Deep Spectral Time-Variant Feature Analytic Model (DSTV-FAM) using SoftMax Recurrent Neural Network (SMRNN) in a wireless sensor network to improve cardiac disease prediction accuracy. Initially, the IoT sensor devices collect the data from patient observation to validate the data transmission in route propagation. The collected data is organized as features in the collective dataset. The parts are initially preprocessed into the redundant dataset and estimate the Cardiac Immunity Infl uence Rate (CIIR) depending on the time-variant feature selection model. The estimated weights are marginalized as spectral features trained into the classifi ers.Further, Soft-Max Activation Function (SMAF) creates a logical function depending on the Cardiac Aff ection Rate (CAR).Then the trained, rational neurons are constructed into a Recurrent Neural Network (RNN) Feed-forward feature values using a classifi er and Rate of Disease Aff ection (RDA) by Class Type. The proposed structure yields high prescient exactness concerning order, accuracy, and review to help early treatment for early cardiovascular gamble expectation."
A Method for Generating Malware Countermeasure Samples Based on Pixel Attention Mechanism,2024,"['Malware', 'Generative Adversarial Networks', 'Deep Learning', 'Pixel Attention Mechanism', 'Adversarial Samples']",국문 초록 정보 없음,"Studies have shown that malware has become a primary means of attacking the Internet. Therefore, adversarial samples have become a vital breakthrough point for studying malware. By studying adversarial samples, we can gain insights into the behavior and characteristics of malware, evaluate the performance of existing detectors in the face of deceptive samples, and help to discover vulnerabilities and improve detection methods for better performance. However, existing adversarial sample generation methods still need help regarding escape effectiveness and mobility. For instance, researchers have attempted to incorporate perturbation methods like Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), and others into adversarial samples to obfuscate detectors. However, these methods are only effective in specific environments and yield limited evasion effectiveness. To solve the above problems, this paper proposes a malware adversarial sample generation method (PixGAN) based on the pixel attention mechanism, which aims to improve adversarial samples' escape effect and mobility. The method transforms malware into grey-scale images and introduces the pixel attention mechanism in the Deep Convolution Generative Adversarial Networks (DCGAN) model to weigh the critical pixels in the grey-scale map, which improves the modeling ability of the generator and discriminator, thus enhancing the escape effect and mobility of the adversarial samples. The escape rate (ASR) is used as an evaluation index of the quality of the adversarial samples. The experimental results show that the adversarial samples generated by PixGAN achieve escape rates of 97%, 94%, 35%, 39%, and 43% on the Random Forest (RF), Support Vector Machine (SVM), Convolutional Neural Network (CNN), Convolutional Neural Network and Recurrent Neural Network (CNN_RNN), and Convolutional Neural Network and Long Short Term Memory (CNN_LSTM) algorithmic detectors, respectively."
