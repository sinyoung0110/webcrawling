title,date,keywords,abstract,multilingual_abstract
상품 카테고리 자동분류를 위한 BERT-분류기 아키텍처 연구,2024,"['문장 분류', '문장 유사도', 'Sentence BERT', 'CNN', 'ResNet', 'Transformer', 'Classification', 'Sentence classification', 'Sentence similarity', 'Sentence BERT', 'CNN', 'ResNet', 'Transformer', 'Classification']","본 연구는 생활 속 존재하는 다양한 상품들의 명칭을 BERT를 통해 임베딩 벡터화한 다음 이를 기반으로 상품 카테고리 예측을 수행하는 아키텍처에 대한 연구이다. 아키텍처의 성능은 상품 명칭으로부터 임베딩 추출을 수행하는 BERT 모델과, 추출된 임베딩으로 카테고리 예측을 수행하는 분류기에 의해 결정된다. 따라서 본 연구는 우선 상품 명칭 분류에 적합한 BERT 모델을 선정하고, 선정된 BERT 모델에 다양한 분류기를 적용하여 가장 높은 성능을 달성하는 BERT-분류기 조합을 찾고자 하였다. 최초 적합한 BERT 모델 선정에는 단순한 CNN 분류기를 사용하였으며 이를 baseline으로 다른 분류기와 성능을 비교하였다. 아키텍처의 성능은 카테고리 정답에 대한 precision, recall, f1 score, accuracy로 정량화하여 평가하였다. 실험 결과 BERT 측면에서는, Sentence BERT 모델이 비교 대상인 일반 BERT 모델보다 적합함을 확인하였다. 그리고 분류기 측면에서는, Sentence BERT와 CNN으로 구성된 baseline 대비하여 Residual Block이 추가 적용된 분류기가 더 높은 성능을 보였다. 본 연구에 사용된 Sentence BERT 모델의 경우 한국어 데이터가 학습되지 않은 단순 모델로, 향후 추가적 연구를 통해 다양한 한국어 데이터를 학습시켜 Domain Adaptation을 수행할 경우 추가적 성능 향상이 기대된다.","This research focuses on an architecture that vectorizes the names of various products found in daily life using BERT, followed by predicting product categories based on these embeddings. The architecture's performance is determined by the BERT model, which extracts embeddings from product names, and the classifier that predicts categories from these embeddings. Consequently, this research initially aimed to identify a BERT model suitable for classifying product names and then find the most efficient combination of BERT model and classifier by applying various classifiers to the chosen BERT model. A simple CNN classifier was employed for the initial selection of a suitable BERT model, serving as a baseline for performance comparison with other classifiers. The architecture's effectiveness was quantified using precision, recall, f1 score, and accuracy for category predictions. Experimental results showed that the Sentence BERT model was more suitable for this task than a conventional BERT model. Additionally, classifiers enhanced with Residual Blocks demonstrated superior performance compared to the baseline combination of Sentence BERT and CNN. The Sentence BERT model used in this study, not trained on Korean data, suggests that further improvements could be achieved through Domain Adaptation by training with diverse Korean datasets."
BERT어조에 기반한 애널리스트 보고서 텍스트 정보의 유용성,2024,"['애널리스트 보고서', '사전어조', 'BERT어조', '텍스트 마이닝', '텍스트 정보력', 'Analyst Reports', 'Ex-ante Sentiment', 'BERT Sentiment', 'Text Mining', 'Text Informativeness']","본 연구는 애널리스트 보고서 텍스트가 투자의견, 목표가, 이익예측치와 같은 정형 정보에 추가적인 정보를 가지고 있는지 분석한다. 양철원(2021)은 애널리스트 보고서 제목의 사전어조가 발표 전후 5일간 누적비정상수익률에 대해 투자의견, 목표가, 이익예측치를 통제하고도 추가적인 정보가 있음을 보고하고 있다. 본 연구는 애널리스트 보고서 제목 외에 요약을 추가하고, 사전어조가 아닌 KR-FinBERT-SC(Pre-trained Language Model)로 어조를 판단하는 경우 추가적인 정보가 있는지를 확인한다.2001～2023년 기간 중 코스피시장 및 코스닥 시장에 상장된 애널리스트 보고서 473,455개의 발표일 전후의 누적비정상수익률로 판단한다면, BERT어조의 정보 유용성은 사전어조보다 현저히 크다. 회귀분석 결과에 의하면, BERT어조는 사전어조의 정보를 대부분 흡수한다. BERT어조의 정보 유용성은 투자의견 변경, 목표가 변화율 보다는 약하지만, 이익예측치 변화율 보다 강하며, 정형 정보 변수에 더하여 추가적인 정보를 제공하고 있다. BERT어조는 정형 정보 변수가 제공되지 않은 보고서에서도 측정할 수 있으며, 애널리스트가 매도추천을 하는데 부담을 가지고 있어 매도추천이 희소한 상황에서 더욱 유용하다. 애널리스트 보고서의 제목과 요약은 정보 유용성의 우열을 가리기 힘들며, 두 정보는 서로 보완적이어서 텍스트 정보를 최대한 활용하기 위해서는 두 정보를 같이 사용해야 한다.","Yang(2021) reports that the prior tone of the analyst report titles provides additional information on the cumulative abnormal returns in the five days before and after the announcement, even after controlling for investment opinions, target prices, and earnings forecasts. This study adds a summary in addition to the title of the analyst report and checks if there is any additional information when judging the tone by the KR-FinBERT-SC (Pre-trained language model) rather than the prior tone.If we judge the information power of 473,455 analyst reports listed on the KOSPI and KOSDAQ markets during the period 2001～2023 by the cumulative abnormal returns before and after the publication date, the perpetuality of the information in the BERT tone is significantly greater than that of the prior word. Regression analysis shows that the BERT tone absorbs most of the information from the dictionary tone. The permanence of the information in the BERT tone is weaker than the rate of change in investment opinion and target, but stronger than the rate of change in earnings forecasts, and provides additional information on the variables of structured information. The BERT tone can also be measured in reports where structured information variables are not provided, and it is more useful in situations where sell recommendations are scarce because analysts have a burden to make sell recommendations. The title and summary of an analyst’s report are hard to argue with the information flow, and the two pieces of information are complementary to each other, so they should be used together to get the most out of the textual information."
"온라인 뉴스의 선정성이 게재 시간과 이용자 평가에 미치는 영향 : Sentence-BERT와 BERT 모델을 활용한 텍스트 유사성, 비윤리성, 감정 측정",2024,"['온라인 뉴스', '선정성', '게재 시간', '텍스트 유사도', 'BERT', 'Online News', 'Sensationalism', 'Publishing Time', 'Text Similarity', 'BERT']","본 연구는 뉴스 선정성을 세 가지 구성 요소(제목 대표성, 비윤리적 내용, 감정 유발)로 재구성하고, 이 요소들이 기사의 게재 시간과 이용자 평가(흥미성과 정보성)에 미치는 영향을 검증했다. 이를 위해 연구진은 네이버의 언론사 편집판 ‘주요 뉴스’를 실시간 스크래핑한(매시각 실행. 하루 24회) 뒤, 선거 관련 기사 20,054건에 대해 분석을 실시했다. 제목 대표성은 제목이 본문 내용을 얼마나 잘 반영하고 있는지를 나타내며, 문장 유사도 계산에 사용되는 Sentence-BERT 모델이 측정에 사용됐다. 비윤리적 내용과 감정 유발의 측정은 사전학습된 BERT 모델의 미세조정을 통해 개발된 분류기를 활용해 이뤄졌다. 분석 결과, 기사의 게재 시간에 대해 제목 대표성, 비윤리적 내용, 감정 유발이 예상한 방향으로 유의미한 영향을 미치는 것으로 나타났다. 제목 대표성이 낮은 기사일수록 언론사는 오래 게재하는 경향을 보였다. 비난을 담은 기사 제목일수록 오래 게재됐고, 감정 유발성 제목은 모든 감정 종류에서 게재 시간을 늘리는 효과를 보였다. 이용자 평가 가운데 흥미성을 예측하는 분석에서는 제목 대표성과 비윤리적 내용이 유의미한 영향을 미치지 않았다. 이는 선정적 보도가 이용자의 관심 끌기에 효과적이라는 예측에 어긋나는 결과였다. 반면, 감정적 기사는 이용자들로 하여금 흥미롭다고 평가하게 만드는 요소였다. 한편, 정보성 평가에서는 제목 대표성이 유의미하게 긍정적 영향을 미쳤다. 제목이 본문 내용을 정확하게 반영할 때 이용자가 정보가 잘 정리된 기사라고 평가한다는 것이다. 비윤리적 내용에서는 비난을 담은 기사만 정보성 평가를 높이는 것으로 나타났다. 감정에서는 공포와 놀람이 담긴 기사가 정보성이 낮다고 평가된 반면, 슬픔, 행복, 혐오가 담긴 기사는 정보성이 높다고 평가됐다. 결론적으로, 언론사는 선정적 기사(제목)를 오래 게재하는 방식으로 뉴스 이용자의 흥미를 끌고 클릭을 유도하는 것으로 나타났다. 그러나 뉴스 이용자들은 제목 대표성이 낮고 비윤리적 내용을 포함한 선정적 기사에 대해 흥미성이 높다고 평가하지 않을 뿐 아니라, 선정적 기사의 부족한 정보성을 충분히 인식하고 있는 것으로 나타났다. 본 연구의 차별성은 뉴스 선정성의 구성 요소를 새롭게 제안하고, 온라인 기사의 ‘게재 시간’이라는 새로운 개념을 도입하고, 실시간 스크래핑과 BERT 모델 활용 등 컴퓨테이셔널방법론을 본격적으로 활용한 점에 있다. 본 연구가 온라인 뉴스의 선정성에 대해 새로운 이해를 제공하고, 미디어 연구에서 컴퓨테이셔널방법론 적용을 넓히는 데에 기여하길 기대한다.","This study examined the effects of three components of news sensationalism - headline representativeness, unethical content, and emotional provocation - on the publishing time of articles and user evaluations (interest and informativeness). The study analyzed 20,054 election-related articles scraped in real-time from major news articles curated by media companies on Naver. Headline representativeness refers to how well the headline reflects the content of the article. Sentence-BERT, a model used for measuring sentence similarity, was employed for this purpose. Unethical content and emotional provocation were measured using classification models through BERT-based transfer-learning. The analysis revealed that headline representativeness, unethical content, and emotional provocation had significant impacts on the publishing time of articles as anticipated. Articles with less representative headlines tended to be published for longer durations. Articles with headlines containing censure were published for longer, whereas those with headlines expressing hate did not show a significant difference in publishing time. Emotionally provocative headlines tended to increase the publishing time for all emotional categories. In the analysis predicting user evaluations of interest, headline representativeness and unethical content did not have significant effects. This result contrasts with a general prediction that sensational reporting effectively attracts user interest. Emotionally charged articles were found to be a significant factor in users evaluating them as interesting. For the other user evaluation metric, informativeness, headline representativeness had a significantly positive effect. When headlines accurately reflected the content, users rated the article as well-organized and informative. In the case of unethical content, only articles with censure showed an increase in informativeness evaluation. Emotional expression had different impacts on informativeness depending on the category. Articles containing fear and surprise were rated lower in informativeness, while those containing sadness, happiness, and disgust were rated higher. In conclusion, it was found that media companies attract user interest and induce clicks by publishing sensational headlines for extended periods. However, news users not only do not rate sensational articles as highly interesting but also fully recognize the lack of informativeness in sensational articles. The distinctiveness of this study lies in the newly proposed components of news sensationalism, the introduction of the new concept of 'publishing time' for online articles, and the full utilization of computational methodologies, including real-time scraping and the use of BERT models. This study offers fresh insights into the sensationalism of internet news and enhances the application of computational approaches in media studies."
BERT와 Llama2를 활용한 국내 학술논문의 자동분류 모델 구축과 성능분석,2024,"['인공지능', '자동분류', 'BERT', 'Llama', 'LLM', 'Artificial Intelligence', 'Automatic Classification', 'BERT', 'Llama', 'LLM']","기초거대언어모델이 경쟁적으로 발표되고 있다. 그 중에서도 2023년 2월 발표한 메타의 Llama2 모델은 연구 커뮤니티에 개방되면서 접근성 뿐 아니라 제한된 자원 제약 하에서도 쓸 수 있으며 검증된 우수한 성능을 보여주었다. Llama2는 ChatGPT 3.5와 유사한 성능을 구현 하면서도 중소기업들이 상업적으로도 활용할 수 있는 모델이다.본 연구는 학술논문 자동분류 모델 구축 맥락에서 접근성이 좋은 BERT모델과 Llama2모델의 성능을 비교한다. 학습데이터는 AI-HUB의 1995년부터 2020년까지 16만건의 ‘논문자료 요약’ 데이터 셋을 사용하였다. 대상 분류는 한국연구재단의 연구 분야 분류기준으로 8개 분류로 정의되어 있다. 실험 결과 텍스트 입력 길이에 따라 짧은 경우는 BERT모델을, 중간이상 길이의 텍스트에 대해서는 Llama2모델이 유용하다. 대상 분류별 분석한 결과 BERT의 경우 사회과학, 공학, 농수해양에서 높았으며 Llama2는 인문학, 자연과학, 의약학, 예술체육, 복합학에서 성능이 높게 나왔다. 기업이나 조직에서 문서 자동 분류나 자연어 처리 모델을 선택할 때, 입력 데이터의 특성, 분류작업의 민감도와 목표에 따라 적절한 모델을 선택해야 한다.","Large-scale language models are being competitively released, among which Meta’s Llama2 model, introduced in February 2023, has gained attention for its accessibility and proven performance. Llama2 not only provides accessibility to the research community but also performs efficiently under limited resource constraints, offering capabilities similar to ChatGPT 3.5, while being commercially viable for small and medium-sized enterprises. This study compares the performance of the widely accessible BERT model and the Llama2 model within the context of building an automatic classification model for academic papers. The training data consists of 160,000 “paper summary” datasets from AI-HUB, spanning from 1995 to 2020. The target classification is based on the eight categories defined by the National Research Foundation of Korea’s research area classification criteria. Experimental results indicate that the BERT model is more effective for short text inputs, while the Llama2 model excels with medium to long text inputs. In terms of category-specific analysis, BERT performs better in social sciences, engineering, and agriculture/fisheries/marine sciences, while Llama2 shows superior performance in humanities, natural sciences, medicine, arts/sports, and interdisciplinary studies. When selecting a document classification or natural language processing model for companies or organizations, it is essential to consider the characteristics of the input data, the sensitivity of the classification task, and the goals to choose the most suitable model."
BERT 기반의 모델을 이용한 무기체계 소프트웨어 정적시험 거짓경보 분류 모델 개발 방법 연구,2024,"['weapon system software', 'SW reliability testing', 'static testing', 'false alarm classification', 'BERT-based model', '무기체계 소프트웨어', '소프트웨어 신뢰성 시험', '정적시험', '거짓경보 분류', 'BERT기반 모델']","최근 무기체계에서 소프트웨어의 규모와 복잡도가 커짐에 따라 소프트웨어의 신뢰성 및 안정성 확보가 요구되고 있다. 이를 위해 개발자는 정적 및 동적 신뢰성 시험을 수행해야한다. 하지만 정적시험 과정에서 많은 거짓경보들이 발생하여 이를 분석하고 처리하는데 많은 시간과 자원을 할애하고 있다. 기존 연구에서는 이러한 문제를 해결하기 위해 SVM, LSTM 등의 모델을 활용하여 거짓 경보를 분류한다. 하지만 연구들에서 사용된 모델의 입력값은 코드 관련 정보이거나, Word2Vec기반 코드 임베딩이므로 결함 발생 부분과 연관된 코드 간의 관계를 표현하지 못한다는 한계점이 존재한다. BERT기반의 모델은 양방향 트랜스포머의 적용을 통해 문장 간 앞뒤 관계를 학습하므로 코드 간 관계를 분석하는데 용이하다. 따라서 이를 거짓 경보 분류 문제에 활용하면 위 한계점을 극복할 수 있다. 본 논문에서는 정적시험 결과를 효율적으로 분석하기 위해 BERT기반의 모델을 활용한 거짓경보 분류 모델 개발 방법을 제안한다. 개발 환경에서 데이터셋을 구축하는 방법을 설명하고, 실험을 통해 분류 모델의 성능이 우수함을 보인다.","Recently, as the size and complexity of software in weapon systems have increased, securing the reliability and stability is required. To achieve this, developers perform static and dynamic reliability testing during development. However, a lot of false alarms occur in static testing progress that cause wasting resources such as time and cost for reconsider them. Recent studies have tried to solve this problem by using models such as SVM and LSTM. However, they have a critical limitation in that these  models do not reflect correlation between defect code line and other lines since they use Word2Vec-based code embedding or only code information. The BERT-based model learns the front-to-back relationship between sentences through the application of a bidirectional transformer. Therefore, it can be used to classify false alarms by analyzing the relationship between code. In this paper, we proposed a method for developing a false alarm classification model using a BERT-based model to efficiently analyze static test results. We demonstrated the ability of the proposed method to generate a dataset in a development environment and showed the superiority of our model."
SASRec vs. BERT4Rec: 트랜스포머 기반 순차적 추천 모델의 성능 분석,2024,"['순차적 추천 시스템', '딥러닝', '인공지능', '재현성', '트랜스포머', 'sequential recommender system', 'deep learning', 'artificial intelligence', 'reproducibility', 'transformer']","순차적 추천 시스템은 사용자 로그로부터 관심사를 추출하고 이를 바탕으로 사용자가 다음에 선호할만한 항목을 추천한다. SASRec과 BERT4Rec은 대표적인 순차적 추천 모델로 널리 활용되고 있다. 기존 연구들은 두 모델을 베이스라인으로 다양한 연구에 활용하고 있지만, 두 모델은 실험 환경 차이로 인해 일관된 성능을 보이지 않는다. 본 논문에서는 여덟 가지 대표적 순차적 추천 데이터셋에서 SASRec과 BERT4Rec의 성능을 비교 및 분석하여 검증한다. 이를 통해, 사용자-항목 상호작용 수가 BERT4Rec 학습에 가장 큰 영향을 미치며, 결국 이는 두 모델의 성능 차이로 이어진다는 사실을 관찰하였다. 더 나아가, 본 연구는 순차적 추천 환경에서 널리 활용되는 두 학습 방법 역시 인기도 편향과 시퀀스 길이에 따라 다른 효과를 보일 수 있음을 보인다. 이를 통해, 데이터셋 특성을 고려하는 것이 추천 성능 개선을 위해 필수적임을 강조한다.","Sequential recommender systems extract interests from user logs and use them to recommend items the user might like next. SASRec and BERT4Rec are widely used as representative sequential recommendation models. Existing studies have utilized these two models as baselines in various studies, but their performance is not consistent due to differences in experimental environments. This research compares and analyzes the performance of SASRec and BERT4Rec on six representative sequential recommendation datasets. The experimental result shows that the number of user-item interactions has the largest impact on BERT4Rec training, which in turn leads to the performance difference between the two models. Furthermore, this research finds that the two learning methods, which are widely utilized in sequential recommendation settings, can also have different effects depending on the popularity bias and sequence length. This shows that considering dataset characteristics is essential for improving recommendation performance."
리뷰 일관성을 이용한 BERT-CNN 기반 리뷰 유용성 예측 모델 개발,2024,"['리뷰 유용성 예측', '리뷰 일관성', 'BERT-CNN', '딥러닝', '전자상거래', 'Review Helpfulness Prediction', 'Review Consistency', 'BERT-CNN', 'Deep Learning', 'E-Commerce']","최근 온라인 리뷰의 수가 급증함에 따라 소비자들은 자신의 구매 결정에 도움이 되는 유용한 리뷰를 찾는 데 어려움을 겪고 있다. 이로 인해 소비자에게 유의미한 리뷰를 식별하여 제공하는 것이 중요해짐에 따라 리뷰 유용성 예측에 관한 다양한 연구가 지속적으로 진행되고 있다. 그러나 대부분의 연구는 리뷰 텍스트의 의미론적 특성을 추출하는 데 중점을 두었고 이에 수반되는 평점 정보를 예측 작업에 반영하지 않았다. 따라서 본 연구는 이러한 평점 정보를 리뷰 유용성 예측에 도입하고 리뷰 텍스트와 평점 간의 일관성을 바탕으로 예측하였다. 본 연구에서 제안한 BERTexCon(BERT-CNN text and rating consistency model for review helpfulness prediction)은 Feature Encoder와 Consistency Extraction 두 가지 모듈로 되어있다. Feature Encoder 모듈은 리뷰 텍스트와 평점 정보에서 특성을 추출하는 데 사용하고 Consistency Extraction 모듈은 정보 간의 일관성을 추출하는 데 사용한다. 특히, 본 연구는 BERT-CNN 모델을 활용하여 리뷰 텍스트 중에 실제 유용성에 크게 영향을 미칠 수 있는 특성을 바탕으로 예측 작업을 수행하였다. 본 연구는 Amazom.com에서 수집된 실제 소비자 리뷰를 바탕으로 제안된 BERTexCon 모델의 예측 성능을 측정하였다. 실험 결과를 따르면 본 연구에서 제안한 BERTexCon모델은 기존 연구에서 사용된 여러 모델과 비교했을 때 성능이 가장 우수함을 나타냈다. 따라서 본 연구에서 제안한 방법론은 다양한 전자상거래 플랫폼에서 적용될 수 있고 정교한 리뷰 유용성 예측 서비스를 제공할 수 있다.","With the rapid increase in online reviews, consumers struggle to find helpful reviews to help them make purchasing decisions. Therefore, various studies in the review helpfulness prediction have been proposed, demonstrating the importance of identifying and providing meaningful reviews to consumers. However, most studies focused on extracting the semantic features from review texts, the accompanying star ratings are not introduced in the prediction task. Therefore, this study aims to introduce such star rating information and predict review helpfulness from the perspective of review consistency between review texts and star ratings. The BERTexCon (BERT-CNN Text and Rating Consistency Model for Review Helpfulness Prediction) proposed in this study consists of feature encoder and consistency extraction. The feature encoder module is used to extract features from review text and star rating information, and the consistency extraction module is used to extract consistency between the information. Specifically, this study applies the BERT-CNN model to conduct predictions based on main features that can significantly affect helpfulness. To evaluate the prediction performance of the proposed BERTexCon model, this study used real-world online reviews collected from Amazon.com. The experimental results showed that the BERTexCon model performs best compared to the various models applied in previous studies. Therefore, the proposed methodology of this study can be applied to various e-commerce platforms and provide an accurate review helpfulness prediction service."
BERT 기반 자연어처리 모델의 미세 조정을 통한 한국어 리뷰 감성 분석: 입력 시퀀스 길이 최적화,2024,"['BERT', '하이퍼 파라미터 미세 조정', '입력 시퀀스 길이', '토픽 모델링', '감성 분석', '한국어 리뷰 분석', 'hyperparameter fine-tuning', 'input sequence length', 'topic modeling', 'sentiment analysis', 'Korean review analysis']","본 연구는 BERT 기반 자연어처리 모델들을 미세 조정하여 한국어 리뷰 데이터를 대상으로 감성 분석을 수행하는 방법을 제안한다. 이 과정에서 입력 시퀀스 길이에 변화를 주어 그 성능을 비교 분석함으로써 입력 시퀀스 길이에 따른 최적의 성능을 탐구하고자 한다. 이를 위해 의류 쇼핑 플랫폼 M사에서 수집한 텍스트 리뷰 데이터를 활용한다. 웹 스크래핑을 통해 리뷰 데이터를 수집하고, 데이터 전처리 단계에서는 긍정 및 부정 만족도 점수 라벨을 재조정하여 분석의 정확성을 높였다. 구체적으로, GPT-4 API를 활용하여 리뷰 텍스트의 실제 감성을 반영한 라벨을 재설정하고, 데이터 불균형 문제를 해결하기 위해 6:4 비율로 데이터를 조정하였다. 의류 쇼핑 플랫폼에 존재하는 리뷰들을 평균적으로 약 12 토큰의 길이를 띄었으며, 이에 적합한 최적의 모델을 제공하기 위해 모델링 단계에서는 BERT기반 사전학습 모델 5가지를 활용하여 입력 시퀀스 길이와 메모리 사용량에 집중하여 성능을 비교하였다. 실험 결과, 입력 시퀀스 길이가 64일 때 대체적으로 가장 적절한 성능 및 메모리 사용량을 나타내는 경향을 띄었다. 특히, KcELECTRA 모델이 입력 시퀀스 길이 64에서 가장 최적의 성능 및 메모리 사용량을 보였으며, 이를 통해 한국어 리뷰 데이터의 감성 분석에서 92%이상의 정확도와 신뢰성을 달성할 수 있었다. 더 나아가, BERTopic을 활용하여 새로 입력되는 리뷰 데이터를 카테고리별로 분류하고, 최종 구축한 모델로 각 카테고리에 대한 감성 점수를 추출하는 한국어 리뷰 감성 분석 프로세스를 제공한다.","This paper proposes a method for fine-tuning BERT-based natural language processing models to perform sentiment analysis on Korean review data. By varying the input sequence length during this process and comparing the performance, we aim to explore the optimal performance according to the input sequence length. For this purpose, text review data collected from the clothing shopping platform M was utilized. Through web scraping, review data was collected. During the data preprocessing stage, positive and negative satisfaction scores were recalibrated to improve the accuracy of the analysis. Specifically, the GPT-4 API was used to reset the labels to reflect the actual sentiment of the review texts, and data imbalance issues were addressed by adjusting the data to 6:4 ratio. The reviews on the clothing shopping platform averaged about 12 tokens in length, and to provide the optimal model suitable for this, five BERT-based pre-trained models were used in the modeling stage, focusing on input sequence length and memory usage for performance comparison. The experimental results indicated that an input sequence length of 64 generally exhibited the most appropriate performance and memory usage. In particular, the KcELECTRA model showed optimal performance and memory usage at an input sequence length of 64, achieving higher than 92% accuracy and reliability in sentiment analysis of Korean review data. Furthermore, by utilizing BERTopic, we provide a Korean review sentiment analysis process that classifies new incoming review data by category and extracts sentiment scores for each category using the final constructed model."
BERT를 이용한 협업 필터링 강화 추천 시스템,2024,"['BERT', 'collaborative filtering', 'deep learning', 'embed', 'recommendation system']","최근 인공지능과 딥러닝 기술은 크게 발전하였으며, 그 중에서도 BERT 모델은 트랜스포머 아키텍처를 기반으로한 자연어 처리 분야에서 문맥 이해 능력이 뛰어나다는 평가를 받고 있다. 이러한 성능은 전통적인 추천 시스템을 한단계 더 발전시킬 수 있는 잠재력을 지니고 있다. 본 연구에서는 추천 시스템의 성능 향상을 위해 협업 필터링 방식에딥러닝 모델을 결합하는 접근 방식을 채택하였다. 구체적으로, BERT를 활용해 사용자 리뷰의 감정 분석을 수행하고, 이러한 리뷰 감정을 기반으로 사용자를 임베딩함으로써 유사한 취향을 가진 사용자를 찾아내어 추천하는 시스템을 구현하였다. 또한 이 과정에서 오픈소스 검색 엔진인 Elasticsearch를 활용하여 빠른 검색, 추천 결과를 검색할 수 있다.사용자의 텍스트 데이터를 분석하여 추천의 정확도와 개인화 수준을 높이는 접근 방식은 향후 다양한 온라인 서비스에서의 사용자 경험 개선에 중요한 역할을 할 것이다.","In recent years, artificial intelligence and deep learning technologies have made significant advances, and the BERT model has been recognized for its excellent contextual understanding in natural language processing based on the transformer architecture. This performance has the potential to take traditional recommendation systems to the next level. In this study, we adopt an approach that combines a collaborative filtering approach with a deep learning model to improve the performance of recommendation systems. Specifically, we implemented a system that uses BERT to analyze the sentiment of user reviews and embed users based on these review sentiments to find and recommend users with similar tastes. In the process, we also utilized Elasticsearch, an open-source search engine, for quick search and retrieval of recommended results. The approach of analyzing users' textual data to increase the accuracy and personalization of recommendations will play an important role in improving the user experience on various online services in the future."
암호화된 트래픽 분류를 위한 향상된 BERT: 경량화되고 강건한 접근법,2024,"['BERT', 'Deep learning', 'Encrypted traffic classification', 'Lightweight', 'Security']","본 논문은 자원이 제한된 네트워크 시스템에서 암호화된 트래픽 분류를 위해 설계된 경량화 되고 강건한 BERT 모델인 SRB-ET(Slim and Robust BERT for Encrypted Traffic)를 제안한다. SRB-ET는 모델 크기를 줄이면서도 높은 분류 성능을 유지하기 위해 이웃 가중치 가중합 공유와 절반 확률 라벨 예측 기법을 사용한다. 이웃 가중치 가중합 공유는 가지치기 된 레이어의 가중치를 인접 레이어에 가중합하여 성능 손실을 최소화하고 학습 속도를 향상시킨다. 절반 확률 라벨 예측은 사전학습 중 라벨을 50%의 확률로 예측하여 효율적으로 카테고리 특징을 학습하고 더 빠르게 수렴할 수 있도록 한다. ISCX VPN-nonVPN 데이터 세트를 사용한 실험 결과, SRB-ET는 기존 기법 대비 트래픽 분류 정확도는 유지하면서 파라미터 수를 15.12% 줄이고 추론 시간을 45.1% 단축하며, 학습 속도를 54.9% 향상 시켰다.","This paper proposes SRB-ET (Slim and Robust BERT for Encrypted Traffic), a lightweight and robust BERT model designed for encrypted traffic classification in resource-constrained network systems. SRB-ET employs neighboring weight averaging and half-probability label prediction techniques to reduce model size while maintaining high classification performance. The neighboring weight averaging technique minimizes loss and enhances performance by averaging the weights of pruned layers with adjacent layers. The half-probability label prediction technique efficiently learns category features by predicting labels with a 50% probability during pre-training, enabling faster convergence. Experimental results using the ISCX VPN-nonVPN dataset demonstrate that SRB-ET maintains traffic classification accuracy while reducing the number of parameters by 15.12%, decreasing inference time by 45.1%, and improving training speed by 54.9% compared to existing methods."
특허상담 자동분류의 성능 향상 방안 연구: 트랜스포머 기반 인공지능 모델 버트(BERT)를 활용,2024,"['특허상담', '자동분류', '인공지능모델', '버트모델', '모델학습', 'Intellectual property consultation', 'automatic classification', 'artificial intelligence model', 'BERT model', 'model learning']",,"Intellectual property customer counseling is an important public service that supports the creation of intellectual property rights and protection of the rights and interests of applicants and rights holders. To effectively support customers and secure the use of counseling content as a policy, counseling contents are classified according to certain criteria. Until 2020, it was professional counselors who directly classified these contents, but 2021 saw a shift toward automatic classification based on text analysis (TA) of the consultation texts. However, an investigation as to the distribution of counseling case classification over the past five years showed some differences between the 2018-2020 distribution, classified by professional counselors, and the 2021-2022 distribution, automatically classified by TA. Therefore, this study investigated how to improve the performance of the automatic classification system using BERT, a transformer-based AI model. After fine-tuning the BERT model, which was pre-trained using patent counseling text data and professional counselor classification values data, it was observed that the BERT’s automatic classification distribution was more similar to that of professional counselors than the classification distribution of the existing TA. These results show that the future application of the “Patent Consultation Classification BERT,” a tentative name for the model, to automatic patent consultation classification may yield a better performance than the current TA method. Furthermore, if the automatic classification results become more reliable through the use of this AI model, the purpose behind the policy for the automation of this procedure―namely easing the burden and improving the efficiency of professional counselors―may be achieved with improved continuity and stability. This may then enable a more accurate identification of the current status of patent customer counseling services and customer needs."
BERT 기반 사전학습을 이용한 탄성파 자료처리: 송신원 모음 배열 비교,2024,"['BERT', 'pretraining', 'seismic processing', 'BERT', '사전학습', '탄성파 자료처리']","탄성파 자료처리는 탄성파 자료를 분석하여 지구 내부 구조와 특성을 파악하는 기술로, 높은 컴퓨터 연산력이 요구된다. 이러한 도전 과제를 해결하기위해 머신러닝 기술이 도입되었으며, 잡음 제거, 속도 모델 구축 등 다양한 작업에서 활용되고 있다. 그러나, 대부분의 연구는 특정 탄성파 처리 작업에집중되어 있어 자료에 내재된 유사한 특징과 구조를 충분히 활용하지 못하는 한계가 있다. 본 연구에서는 BERT (Bidirectional Encoder Representations from Transformers) 기반의 사전학습을 위해 단일 송신원 모음에서 수신기별 시계열 자료(‘수신기 배열’)와 동일 시간에 기록된 수신기 신호(‘시간 배열’)를 입력 자료로 활용하는 방법을 비교하였다. 이를 위해 단층을 포함한 속도 모델에서 생성한 합성 송신원 모음 자료를 이용하여 잡음 제거, 속도 추정, 그리고 단층 확인 작업을 수행하였다. 임의 잡음 제거 작업에서는 수신기 및 시간 배열에서 모두 좋은 성능을 보였으나, 공간적인 분포 파악이 요구되는 속도 추정 및 단층 확인 작업에서는 시간 배열의 결과가 상대적으로 더 우수함을 확인하였다.","The processing of seismic data involves analyzing earthquake wave data to understand the internal structure and characteristics of the Earth, which requires high computational power. Recently, machine learning (ML) techniques have been introduced to address these challenges and have been utilized in various tasks such as noise reduction and velocity model construction. However, most studies have focused on specific seismic data processing tasks, limiting the full utilization of similar features and structures inherent in the datasets. In this study, we compared the efficacy of using receiver-wise time-series data (“receiver array”) and synchronized receiver signals (“time array”) from shotgathers for pretraining a Bidirectional Encoder Representations from Transformers (BERT) model. To this end, shotgather data generated from a synthetic model containing faults was used to perform noise reduction, velocity prediction, and fault detection tasks. In the task of random noise reduction, both the receiver and time arrays showed good performance. However, for tasks requiring the identification of spatial distributions, such as velocity estimation and fault detection, the results from the time array were superior."
사용자의 세부적인 특성을 반영한 BERT 기반 호텔 추천 시스템 개발,2024,"['호텔 추천 시스템', '온라인 리뷰', '개인화 추천', 'BERT', 'Attention Mechanism', 'Hotel Recommender System', 'Online Review', 'Personalized Recommendation', 'BERT', 'Attention Mechanism']","소셜 웹사이트 및 온라인 플랫폼의 발전으로 인해 추천 시스템에 대한 관심이 증가하고 있으며, 특히 온라인 호텔 플랫 폼에서는 추천 시스템에 대한 중요성이 더욱 강조되고 있다. 대부분의 호텔 추천 시스템은 사용자가 남긴 리뷰 텍스트에서 추출한 Aspect를 기반으로 추천을 제공하는 방식으로 이루어져 있다. 하지만 이러한 방법은 리뷰 텍스트에 내제된 사용자의 세부 특성을 파악하기 어렵고, 포괄적인 Aspect에 기반하여 추천을 제공한다는 한계점이 존재한다. 본 연구에서는 기존 호텔 추천 시스템의 한계를 개선하기 위해 리뷰 텍스트를 기반으로 개인화된 추천을 제공하는 방법론을 제안했다. 구체적으로 본 연구에서는 BERT 모델을 Fine-tuning하고 Attention Mechanism을 도입하여 사용자의 세부적인 특성을 더욱 정확하게 파악하여 추천에 반영했다. 본 연구에서 제안한 모델의 성능을 평가하기 위해 TripAdvisor.com에서 수집한 온라인 리뷰를 사용하여 실험을 진행했고, 제안 모델의 우수함을 검증할 수 있었다. 따라서 본 연구는 리뷰 텍스트에 내제된 사용자 선호도를 효과적으로 파악하여 개인화 추천을 제공할 수 있는 방법론을 제안하여 호텔 추천 시스템 연구의 이론적 및 방법론 측면에 기여했다.","The need for recommender systems has grown with the development of social websites and online platforms, which emphasize the significance of online hotel platforms. Most studies on hotel recommender systems have been conducted based on the specific aspects extracted from user-generated review texts. However, such studies face challenges in capturing user-specific preference features contained in review texts and are limited to recommending hotels based on comprehensive aspects. To address such problems, this study proposed a novel methodology to effectively utilize review texts for performing personalized recommendations. Specifically, this study fine-tuned the BERT model and applied an Attention Mechanism to accurately capture user-specific preferences in the recommendations. Moreover, this study used the online reviews dataset collected from TripAdvisor.com to evaluate the recommendation performance of the proposed methodology. The experimental results showed the proposed model outperforms the benchmark models. Therefore, this study can contribute to the theoretical and methodological implications of the hotel recommender systems that effectively capture user-specific preference features contained in review texts to ensure accurately personalized recommendations."
앙상블 알고리즘과 BERT를 이용한 연구논문 주제영역 분류,2024,"['Research Paper', 'Classification', 'Machine Learning', 'Ensemble Algorithms', 'BERT']",,"Purpose  Developing and comparing a model to classify the topic of research paper using abstract text.Methods Abstract data from 120,000 papers on arXiv was collected, and classification models were developed using ensemble algorithms and BERT. For feature extraction in the ensemble algorithm, TF-IDF, LDA, and Doc2Vec methods were used to create seven feature sets. A total of 22 models were developed using various feature sets and algorithms, and their performance was compared.Results  The BERT model exhibited the highest performance with an accuracy of 0.848 and an f1-score of 0.808. Among the ensemble algorithms, LightGBM performed exceptionally well, and the direct reflection of word importance through the TF-IDF vectorization method proved to be effective.Conclusion Developing a model that automatically classifies paper topics by analyzing text offers researchers the opportunity to swiftly access the latest information and identify their research interests. This enhances accessibility to information in research fields and presents the possibility for researchers across diverse domains to gain new insights."
"통합 CNN, LSTM, 및 BERT 모델 기반의음성 및 텍스트 다중 모달 감정 인식 연구",2024,"['Speech Emotion Recognition', 'CNN', 'LSTM', 'BERT', 'Multimodal Emotion Recognition', 'Deep Learning', '음성 감정 인식', 'CNN', 'LSTM', 'BERT', '다중 모달 감정 인식', '딥 러닝']",,"Identifying emotions through speech poses a significant challenge due to the complex relationship between language and emotions. Our paper aims to take on this challenge by employing feature engineering to identify emotions in speech through a multimodal classification task involving both speech and text data. We evaluated two classifiers—Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM)—both integrated with a BERT-based pre-trained model. Our assessment covers various performance metrics (accuracy, F-score, precision, and recall) across different experimental setups). The findings highlight the impressive proficiency of two models in accurately discerning emotions from both text and speech data."
인공지능 문장 분류 모델 Sentence-BERT 기반 학교 맞춤형 고등학교 통합과학 질문-답변 챗봇 -개발 및 1년간 사용 분석-,2024,"['High school', 'School-tailored', 'Integrated science Q&A chatbot', 'Sentence-BERT', 'Topic modeling', '고등학교', '학교 맞춤형', '통합과학 질문-답변 챗봇', 'Sentence-BERT', '토픽 모델링']","본 연구에서는 오픈소스 소프트웨어와 인공지능 문서 분류 모델인한국어 Sentence-BERT로 고등학교 1학년 통합과학 질문-답변 챗봇을 제작하고 2023학년도 1년 동안 독립형 서버에서 운영했다. 챗봇은Sentence-BERT 모델로 학생의 질문과 가장 유사한 질문-답변 쌍 6개를 찾아 캐러셀 형태로 출력한다. 질문-답변 데이터셋은 인터넷에 공개된 자료를 수집하여 초기 버전을 구축하였고, 챗봇을 1년 동안 운영하면서 학생의 의견과 사용성을 고려하여 자료를 정제하고 새로운질문-답변 쌍을 추가했다. 2023학년도 말에는 총 30,819개의 데이터셋을 챗봇에 통합하였다. 학생은 챗봇을 1년 동안 총 3,457건 이용했다. 챗봇 사용 기록을 빈도분석 및 시계열 분석한 결과 학생은 수업중 교사가 챗봇 사용을 유도할 때 챗봇을 이용했고 평소에는 방과후에 자습하면서 챗봇을 활용했다. 학생은 챗봇에 한 번 접속하여평균적으로 2.1∼2.2회 정도 질문했고, 주로 사용한 기기는 휴대폰이었다. 학생이 챗봇에 입력한 용어를 추출하고자 한국어 형태소 분석기로 명사와 용언을 추출하여 텍스트 마이닝을 진행한 결과 학생은과학 질문 외에도 시험 범위 등의 학교생활과 관련된 용어를 자주입력했다. 학생이 챗봇에 자주 물어본 주제를 추출하고자 Sentence- BERT 기반의 BERTopic으로 학생의 질문을 두 차례 범주화하여 토픽 모델링을 진행했다. 전체 질문 중 88%가 35가지 주제로 수렴되었고, 학생이 챗봇에 주로 물어보는 주제를 추출할 수 있었다. 학년말에학생을 대상으로 한 설문에서 챗봇이 캐러셀 형태로 결과를 출력하는형태가 학습에 효과적이었고, 통합과학 학습과 학습 목적 이외의 궁금증이나 학교생활과 관련된 물음에 답해주는 역할을 수행했음을 확인할 수 있었다. 본 연구는 공교육 현장에서 학생이 실제로 활용하기에 적합한 챗봇을 개발하여 학생이 장기간에 걸쳐 챗봇을 사용하는과정에서 얻은 데이터를 분석함으로써 학생의 요구를 충족할 수 있는 챗봇의 교육적 활용 가능성을 확인했다는 점에 의의가 있다.","This study developed a chatbot for first-year high school students, employing open-source software and the Korean Sentence-BERT model for AI-powered document classification. The chatbot utilizes the Sentence-BERT model to find the six most similar Q&A pairs to a student’s query and presents them in a carousel format. The initial dataset, built from online resources, was refined and expanded based on student feedback and usability throughout over the operational period. By the end of the 2023 academic year, the chatbot integrated a total of 30,819 datasets and recorded 3,457 student interactions. Analysis revealed students’ inclination to use the chatbot when prompted by teachers during classes and primarily during self-study sessions after school, with an average of 2.1 to 2.2 inquiries per session, mostly via mobile phones. Text mining identified student input terms encompassing not only science-related queries but also aspects of school life such as assessment scope. Topic modeling using BERTopic, based on Sentence-BERT, categorized 88% of student questions into 35 topics, shedding light on common student interests. A year-end survey confirmed the efficacy of the carousel format and the chatbot’s role in addressing curiosities beyond integrated science learning objectives. This study underscores the importance of developing chatbots tailored for student use in public education and highlights their educational potential through long-term usage analysis."
BERT 모델 기반 기술융합기회 탐색 연구:  웨어러블 기술사례를 중심으로,2024,"['Technology Convergence', 'BERT', 'Patent Analysis', 'CPC', 'Wearables']",,"Identification  of  potential  technology  convergence  opportunities  is  crucial  to  drive innovation and growth in modern enterprises. In this study, we proposed a framework to  explore  technological  convergence  opportunities  based  on  CPC  code  sequences from patents by utilizing the BERT model. We relied on the BERT architecture to train a  new  model  using  about  1.3  million  patents  registered  at  the  Korean  Intellectual Property Office, and achieved an accuracy of approximately 73% based on HitRate@10 metric.  A  case  study  using  patents  related  to  wearable  technologies  was  conducted  to demonstrate   practicability   and   effectiveness   of   the   proposed   framework.   The   key contributions  of  this  research  include:  (1)  enabling  in-depth  analysis  that  takes  into account  the  complex  interactions  between  CPC  codes  and  contextual  variability;  (2) enabling  the  exploration  of  diverse  technology  convergence  scenarios  beyond  simple sequential  patterns.  This  study  is  one  of  the  first  studies  to  apply the  BERT  model  for exploring  technology  convergence  opportunities,  and  is  expected  to  contribute  to  the establishment   of   technology   innovation   and   R&D   strategies   by   providing   a   more accurate  and  practical  tool  for  enhancing  the  speed  and  efficiency  of  technology opportunity-related decision-making processes."
초등 인공지능 프로그래밍 교육 환경을 위한 Sentence-BERT 기반 단문 분류,2024,"['초등 인공지능 교육', '프로그래밍 환경', 'Sentence-BERT', '가상-학습', '가상-추론', 'Elementary AI Education', 'Programming Environment', 'Sentence-BERT', 'Pseudo-Training', 'Pseudo-Inference']","본 논문에서는 Sentence-BERT 바이-인코더에 기반한 단문 분류 방법을 제안하고, 이를 초등 인공지능 프로그래 밍 교육 환경에서 텍스트 학습 및 추론 시 효과적으로 적용할 수 있음을 실험적으로 보인다. 본 단문 분류 방법은 신경망을 실제로 처음부터 학습시키거나 미세 조정을 하지 않기 때문에, ‘가상-학습’ 및 ‘가상-추론’ 방법이라고 명 명하였다. 가상-학습 단계에서는 학습할 단문들을 경량 바이-인코더를 이용하여 임베딩하고, 이를 효과적으로 검색 할 수 있도록 인덱스를 생성한다. 가상-추론 단계에서는 추론할 단문들을 동일한 바이-인코더를 이용하여 임베딩하 고, FAISS, HNSW 등과 같은 근사 인접 이웃 알고리즘을 활용하여 빠르게 유사한 임베딩 벡터를 찾아 레이블 예 측을 수행한다. 이 방식을 초등 인공지능 교육에서 많이 활용되는 LSTM과 비교한 결과, 클래스 별 학습 샘플의 수 가 많지 않은 상황에서 본 방식은 LSTM보다 정확도가 크게 앞서는 것으로 나타났다. 그리고 학생들이 저성능의 컴퓨터를 활용하는 환경에서 충분히 활용할 수 있는 수준으로 학습 시간과 추론 시간이 소요됨을 확인하였다.","In this paper, we present a short sentence classification approach based on a Sentence-BERT bi-encoder and experimentally demonstrate its effectiveness for training text data in elementary AI programming educational environments. Because this approach does not train from scratch or fine-tune a neural network, we have termed it the ""pseudo-training"" and ""pseudo-inference"" method. In the pseudo-training phase, the short sentences to be trained are embedded using a lightweight bi-encoder, and an index is generated for efficient retrieval. In the pseudo-inference phase, the short sentences to be inferred are embedded using the same bi-encoder, and approximate nearest neighbor algorithms such as FAISS and HNSW are utilized to quickly find similar embedding vectors, followed by label prediction. Compared to LSTM, which is widely used in elementary AI education, the proposed method showed higher accuracy in situations where the number of training samples per class is limited. Additionally, we confirmed that the training and inference time for our approach is sufficient for practical use in programming environments where students use low-performance computers."
사건 변화와 주체 감성 추이 분석을 위한 KPF-BERT 기반 뉴스 동향 시각화 시스템 개발,2024,"['news trend visualization', 'clustering', 'named entity recognition', 'targeted sentiment analysis', 'KPF-BERT', '.']","최근 한국에서는 뉴스 복잡성으로 인해 뉴스에 대한 무관심과 이해도의 부족이 46개국 평균보다 더 높게 나타나고 있다. 현대 뉴스는 다양한 관점과 복잡한 사회적 문맥을 포함하고 있어서 독자들은 이러한 복잡성 내에서 사건과 주체 간의 흐름을 이해하는 데 어려움을 겪고 있다. 본 연구에서는 이러한 문제점을 해결하기 위해 뉴스 동향을 마인드맵 형태로 시각화하고 주체 간의 관계를 나타내는 시각화 시스템을 제안하였다. 제안한 시스템은 다양한 기사를 KPF-BERT 기반 개체명 인식 기법으로 주체를 추출하고, 클러스터별 주요 주체의 감성 분석을 통해 사건의 흐름을 시각화로 나타나도록 하였다. 시뮬레이션 결과, 제안한 시스템을 통한 뉴스의 접근성 향상과 미디어 리터러시의 증진을 기대할 수 있다.","In recent years, South Korea has witnessed a heightened disinterest and lack of understanding towards news due to the proliferation of various news media, with its rates surpassing the average of 46 countries. Contemporary news encompasses diverse perspectives and intricate societal contexts, making it challenging for readers to comprehend the flow and relationships between events and their main actors. This study proposes a visualization system that represents news trends in a mind-map format, highlighting relationships between these actors. The system extracts entities from multiple articles by named entity recognition based on KPF-BERT and visualizes the progression of events through sentiment analysis of principal entities in each cluster. Simulation results suggest that the proposed system can enhance accessibility to news and promote media literacy."
Does BERT Learn Syntactic and Semantic Preferences in Picture Noun Phrase Interpretation?,2024,"['BERT', 'reference resolution', 'picture noun phrase', 'surprisal']",,"This research investigates the Bidirectional Encoder Representations from Transformers (BERT) model’s ability to understand semantic and syntactic preferences of low-frequency expressions through reference resolution in picture noun phrases (PNPs). To this end, we report on three experiments that evaluate BERT’s understanding of reference resolution differences between personal pronouns and reflexives in possessor-less and possessed PNPs. Our experiments show that BERT exhibits human-like referential preferences with reflexives but not with personal pronouns. The findings for reflexive resolution suggest that BERT’s deep learning training does not solely rely on frequency information but serves as a mechanism for acquiring more systematic linguistic soft constraints Moreover, the different resolution patterns from the pronouns could be attributed to the reflexives’ more explicit referential dependency and their relatively low frequency."
A study on the quantificational interpretation of donkey phrase in English: utilizing Next Sentence Prediction with BERT,2024,"['donkey sentence', 'quantificational interpretation', 'ChatGPT', 'BERT', 'Next Sentence Prediction']",,"The goal of the current paper is to explore the interpretation pattern of four different types of quantificational meaning (universal/existential/deictic/generic) of the donkey phrase in English. Specifically, we utilize two deep learning language models: ChatGPT and BERT. A dataset comprising a total of 240 sentences, with 60 sentences generated by ChatGPT, underwent Next Sentence Prediction (NSP) analysis with BERT. The statistical examination, based on surprisal values, revealed a hierarchy of low surprisal values signifying high acceptability in quantificational interpretations: existential > universal > deictic > generic. Regarding the configurations of definite NP and pronouns in the donkey phrase, stand-alone sentences favored pronoun usage, while in NSP, definite NP demonstrated a more innate acceptability. This implies that, even in theoretical analysis, the E-type theory employing quantifier expressions may present a more fitting framework for donkey phrases compared to the discourse representation theory utilizing bound variable pronouns."
Development of a Ranking System for Tourist Destination Using BERT-based Semantic Search,2024,"['BERT 기반 시맨틱 검색', '카운트 기반 랭킹 알고리즘', '관광지', 'BERT-based semantic search', 'count-based ranking algorithm', 'tourist destination']",,
Evaluation of BERT-Based Models’ Ability to Linguistically Distinguish Between Human-Authored and Machine-Generated Texts,2024,"['machine-generated text detection', 'BERT', 'Natural Language Processing', 'linguistic phenomena analysis', 'Transformers', 'Large Language Model']",,"This research evaluates the effectiveness ofbidirectional language models, particularly those based on the BERTarchitecture, in distinguishing between human-authored text andmachine-generated text in the Korean language. Through an extensive empiricalanalysis using a newly established benchmark, KoMGTDetect-Bench, we explorethe linguistic attributes and complexities that differentiate machine-generatedtext from human-authored text, such as vocabulary usage, sentence structure,and syntax. Our findings reveal that BERT-based models excel in detectingsubtle nuances and irregularities in text, attributing their success to the model'sdeep semantic and syntactic understanding enabled by bidirectionalcontext-aware training strategy. This study also examines the performance ofthese models across various linguistic phenomena specific to the Koreanlanguage, highlighting their strengths and limitations."
Incorporating BERT-based NLP and Transformer for An Ensemble Model and its Application to Personal Credit Prediction,2024,"['Credit Prediction', 'Transformer', 'BERT', 'Ensemble Modeling', 'Tabular Data']",,
한국어 BERT 모델을 활용한 청각 정보 기반 광고 영상 분류 방법론,2024,"['광고 분류', '웹 크롤링', '자연어 처리', '청각적 정보 추출', 'Advertisement Classification', 'Auditory Information Extraction', 'BERT', 'Natural Language Process', 'Web Crawling']",,"In this paper, we propose an effective classification methodology for video advertisements, focusing on the Korean languagebased natural language processing model Bidirectional Encoder Representations from Transformers (BERT). During the research process, advertisement video data are collected through internet crawling and processed through answer labeling and preprocessing to make them analyzable. Specifically, in the preprocessing stage, auditory information, that is, voice data, is extracted from the videos and converted into text. The Korean BERT (KoBERT) model is used for the experiment as the research method, and the methodology is verified to enhance the efficiency and accuracy of advertisement classification. This study is expected to enable more precise classification of advertising content, significantly enhancing the efficiency of the advertising industry."
지식베이스와 카테고리를 활용한 Bert 발화 의도 분류 성능 향상 기법,2024,"['발화 의도', '지식베이스', '카테고리', 'BERT', 'CLS', 'Speech Intent', 'Knowledge Base', 'Categories']",,
Research category classification of scientific articles on human health risks of electromagnetic fields using pre-trained BERT,2024,['Deep learning modelHuman health risks of EMFResearch category classificationPre-trained BERT'],,"This paper presents bidirectional encoder representations from transformers (BERT)-based deep learning model for the classification of scientific articles. This model aims to increase the efficiency and reliability of human health risk assessments related to electromagnetic fields (EMF). The proposed model takes the title and abstract of EMF-related articles and classifies them into four categories: animal exposure experiment, cell exposure experiment, human exposure experiment, and epidemiological study. We conducted a performance evaluation to verify the superiority of the proposed model. The results demonstrated that the proposed model outperforms other deep learning models that use pre-trained embeddings, with an average accuracy of 98.33%."
An Estimation Model of Intrinsic Evaluation Ratings by Customer Reviews Based on BERT Feature Extraction,2024,"['BERT', 'Customer Review Analysis', 'Sentiment Analysis', 'Modified Evaluation Value']",,
Dual-scale BERT using multi-trait representations for holistic and trait-specific essay grading,2024,"['automated essay scoring', 'deep learning methods', 'multi-task learning', 'multi-trait scoring', 'transformer-based models']",,"As automated essay scoring (AES) has progressed from handcrafted techniques to deep learning, holistic scoring capabilities have merged. However, specific trait assessment remains a challenge because of the limited depth of earlier methods in modeling dual assessments for holistic and multi-trait tasks. To overcome this challenge, we explore providing comprehensive feedback while modeling the interconnections between holistic and trait representations. We introduce the DualBERT-Trans-CNN model, which combines transformerbased representations with a novel dual-scale bidirectional encoder representations from transformers (BERT) encoding approach at the document-level. By explicitly leveraging multi-trait representations in a multi-task learning (MTL) framework, our DualBERT-Trans-CNN emphasizes the interrelation between holistic and trait-based score predictions, aiming for improved accuracy. For validation, we conducted extensive tests on the ASAP++ and TOEFL11 datasets. Against models of the same MTL setting, ours showed a 2.0% increase in its holistic score. Additionally, compared with single-task learning (STL) models, ours demonstrated a 3.6% enhancement in average multi-trait performance on the ASAP++ dataset."
인공지능기반 사전학습언어모델 적용방안에 관한 연구,2024,"['사전학습언어모델', '도메인 특화', '전이학습', '금융 특화 언어모델', 'BERT', 'Pre-trained Language Model', 'Domain-Specific Fields', 'BERT Model', 'Legal Corpus']","사전학습언어모델(Pre-trained Language Model)은 대량의 텍스트 데이터를 활용하여 사전에 학습(pre-training)된 자연어 처리 모델을 의미한다. 사전학습언어모델이 다양한 영역에서 활용되고 있으나 전문용어 학습데이터가 부족한 영역에서 도메인에 특화된 용어를 이해하지 못하는 한계점을 가진다. 따라서 최근 BERT(Bidirectional Encoder Representations from Transformers)와 GPT(Generative Pretrained Transformer)를 기반으로 추가 사전학습을 통해 변형된 도메인 특화 언어모델의 필요성이 강조되고 있다. 본 연구에서는 BERT의 사전훈련방법과 BERT 기반의 변형기법(ALBERT, RoBERTa, ELECTRA)을 분석하고, 대표적인 도메인 특화 분야인 바이오의학, 금융, 법률 도메인에서 활용 가능한 사전학습언어모델을 제안하고자 한다. 바이오의학 특화 사전학습모델은 바이오의학 분야의 전문 용어, 의학적 문장 구조, 의학적 개체명 인식 등의 도메인 특정 언어 특성을 학습하도록 설계된다. 이것은 주로 BERT의 사전훈련방법과 아키텍처를 기반으로 전이학습을 통해 바이오의학 작업에 적용될 수 있도록 조정된다. 바이오의학 특화 사전학습모델은 의료 문서 분류, 의료 개체명 인식, 의료 질문 응답, 바이오의학 관련 정보 검색 등의 다양한 자연어 처리 작업에 사용될 수 있다. 금융 특화 사전학습모델은 금융 전문 용어, 금융 시장 동향, 금융 상품 및 서비스에 관련된 문장 구조 등을 이해하고 처리할 수 있는 모델이다. 금융 시장 동향에 관한 자동화된 뉴스 기사를 생성하고, 금융 보고서, 보도 자료 등과 같은 긴 텍스트를 간결하게 요약하여 핵심 정보를 추출하는 작업에 활용될 수 있다. 또한 금융 특화 사전학습모델은 금융 분석가들이 기업의 재무 상태, 성과 및 전망에 대한 투자 제안을 생성하는 데 도움을 준다. 마지막으로 법률 특화 사전학습모델은 법률 문서에 적합한 언어 모델로 법률 문서 분류 및 요약, 법률 문서 유사성 평가 등에 활용된다. 법률 특화 사전학습모델은 BERT 모델을 법률 분야의 특수한 텍스트에 대해 사전학습하고, 이를 통해 법률 문서에 특화된 특성을 학습한다. 이러한 특성은 법률 분야의 특수한 용어, 문맥, 문법 등을 포함한다. 법률 특화 사전학습모델은 법률 말뭉치를 사용한 스크래치 사전학습과 추가 사전학습을 통해 법률 관련 태스크를 해결하도록 성능을 고도화할 수 있다.","Pre-trained Language Model(PLM) refers to a natural language processing(NLP) model that has been pre-trained using large amounts of text data. The PLM has the limitation of not being able to understand domain-specific terminology due to a lack of training data for terminology. Therefore, the need for a domain-specific language model modified through BERT- or GPT-based pre-trained learning has recently been emphasized. In this study, we analyze BERT's pre-training method and BERT-based transformation techniques (ALBERT, RoBERTa, ELECTRA) and propose a PLM that can be used in biomedical, financial, and legal domains. The biomedical-specific pre-trained learning model is designed to learn domain-specific language characteristics such as technical terminology, medical sentence structure, and medical entity name recognition in the biomedical field. It is mainly adjusted to be applied to biomedical tasks through transfer learning based on BERT's pre-training method and architecture. For this purpose, it is pre-trained with pre-trained biomedical text data, and this pre-training transfers domain-specific knowledge to the model through learning representations for biomedical-related texts. The finance-specific pre-trained learning model is a model that can understand and process financial terminology, financial market trends, and sentence structures and vocabulary related to financial products and services. It can be used to generate news articles about financial market trends and to extract key information by concisely summarizing long texts such as financial reports and corporate press releases. Additionally, finance-specific pre-trained models help financial analysts generate investment recommendations based on a company's financial condition, performance, and prospects. The legal-specific pre-trained model is a language model suitable for legal documents and is used for legal document classification, legal document summarization, and legal document similarity evaluation. The legal-specific pre-learning model was created by pre-training the BERT model on special texts in the legal field, and through this, it learns characteristics specialized for legal documents. The performance of the legal-specific pre-training model can be improved to solve legal-related tasks through scratch pre-training and additional pre-training using legal corpora."
Keybert와 Bertopic을 활용한 텍스트마이닝 연구동향 분석,2024,"['Text Mining', 'Topic Modeling', 'NLP', 'Bertopic', 'Keybert', '텍스트마이닝', '토픽모델링', '자연어처리', 'Bertopic', 'Keybert']","대량의 텍스트 데이터를 분석하고 활용하는 텍스트 마이닝 기법은 공학 분야뿐만 아니라 사회과학과 교육 등 거의 모든 학문 분야에서 널리 사용되고 있다. 특히 최근 대규모 언어 모델의 급속한발전은 기존 텍스트 마이닝 기법의 한계를 보완하는 혁신적인 방법들을 도입하는 데 기여하고 있다. 본 연구의 목적은 국내 학술 및 학위 논문을 수집하여 최신 텍스트 마이닝 기법을 활용해 분석하는 것이다. 이를 위해 학술연구정보서비스(RISS) 데이터베이스에서 ‘텍스트 마이닝’을 키워드로 논문을 수집하였고, 수집된 논문들에 대해 키워드 분석과 토픽 모델링을 수행하였다. 키워드 분석에서는 TF- IDF를 활용한 빈도 기반 분석과 BERT 기반의 KeyBERT를 활용한 분석을 비교하였다. 또한, 토픽모델링 분석에서는 기존 통계 기반의 LDA 기법과 최신 언어 모델인 BERT 기반의 토픽 모델링 기법인 BERTopic을 비교하였다. 그 결과, BERT 기반의 토픽 분석이 응집도(Coherence Score) 점수에서 보다 우수한 성능을 나타냈다. 특히, Bertopic에서 한국어 임베딩 모델과 Keybert 기반의 토픽추출이 다국어 모델과 문장 기반의 추출보다 더 높은 응집도 점수를 기록하였다. 본 연구는 이러한 결과를 통해 한국어 텍스트 마이닝에서 최신 기법들의 적용과 활용 가능성을 제시하고자 한다.","Text mining techniques for analyzing and utilizing large-scale text data are widely used not only in engineering but also in social sciences, education, and almost all academic fields. This study aims to collect and analyze domestic academic and thesis papers on text mining using the latest text mining techniques. For this purpose, papers were collected from the Research Information Sharing Service (RISS) database using the keyword ‘text mining’, and keyword analysis and topic modeling were conducted on the collected papers. In keyword analysis, frequency-based analysis using TF-IDF and analysis using BERT-based KeyBERT were compared. Additionally, in topic modeling analysis, traditional statistical-based LDA techniques were compared with BERTopic, a topic modeling technique based on the latest BERT language model. The results showed that BERT-based topic analysis demonstrated superior performance in terms of coherence score. Particularly, the topic extraction based on Korean embedding models and Keybert recorded higher coherence scores compared to those based on multilingual models and sentence-based extraction. Through these findings, this study aims to present the applicability and potential of the latest techniques in Korean text mining."
한국어 가짜 구매후기 생성과 탐지 성능 평가,2024,"['가짜 구매후기', '거대언어모델 기반 텍스트 생성', '생성된 텍스트 탐지', 'Fake Reviews', 'LLM-generated Texts', 'Detection of Generated texts']","최근 챗지피티(ChatGPT)가 선풍적인 인기를 끌면서 일반 대중들도 일상생활에서 인공지능을 통해 텍스트를 생성할 수있게 되었다. 이에 따라 아마존과 같은 전자상거래 플랫폼에서 챗지피티를 통해 생성된 글이 올라오기 시작하였다. 그러나 전자상거래 플랫폼에서 구매 후기가 다른 고객의 구매 의사결정에 영향을 미칠 수 있다는 점에서 인공지능에 의해 생성된 가짜 구매후기를 탐지하는 것은 중요하다. 하지만 현재 한국에 생성된 텍스트에 대한 공개된 데이터셋이 없는 상황 이다. 이에 따라 본 연구는 두 단계 1) 가짜 구매후기 생성, 2) 가짜 구매후기 탐지로 진행되었다. 우선, 수집된 후기로 지시어 기반의 언어모델인 KULLM을 미세 조정하여 텍스트를 생성하였다. 생성된 텍스트의 품질은 자동 평가지표(혼란도, Rouge-L)와 사람의 지각평가를 통해 측정되었다. 그 후 분류 데이터셋을 구축하여 네 가지 BERT 기반의 언어모델과 DetectGPT 방법론을 탐지성능평가에 활용하였다. BERT 기반 언어모델의 평균 F1 점수는 0.98 이상으로 높은 탐지 성능을 보였다. DetectGPT의 F1 점수는 생성에 활용한 모델을 탐지에 그대로 활용한 경우에는 0.85, 모르는 경우에는 0.66의성능을 보여 언어모델 대비 낮은 탐지 성능을 보였다. 그러나 텍스트 생성에 활용되지 않은 다른 모델을 탐지에 활용한 경우에는 전처리가 성능을 향상시키는 것을 확인하였다. 본 연구의 기여점은 다음과 같다. 우선, 언어모델을 통한 가짜 구매 후기 데이터셋을 구축하였다. 또한 언어모델의 이진분류를 통한 성능 비교 외에도 새로운 방법론인 DetectGPT를 한국어에 적용하고, 생성된 모델을 아는 경우와 모르는 경우의 탐지 성능을 모두 측정하였다. 실무적으로는, 사람들이 거대언어모델이 생성한 텍스트를 식별하기 어렵다는 점을 확인함으로써 플랫폼은 생성된 구매후기를 관리해야한다는 점을 시사하였다.","As ChatGPT has recently gained tremendous popularity, the public is able to generate text through generative AI in their daily lives. Consequently, reviews generated by ChatGPT have begun to appear on e-commerce platforms like Amazon. Since reviews on these platforms can influence other customers’ purchasing decisions, it is important to detect fake reviews generated by AI. However, there is no available dataset of generated texts in Korea. Therefore, this study was conducted in two stages: 1) fake reviews generation and 2) fake reviews detection. First, KULLM was fine-tuned to generate fake reviews. The quality of the texts were measured using automatic evaluation metrics (perplexity, Rouge-L) and human perception survey. Subsequently, four BERT-based language models and the DetectGPT were used for detection. The BERT-based language models showed high detection performance with average F1 scores above 0.98. In contrast, the DetectGPT had a relatively lower F1 score. The performance was 0.85 when the same model used for generation was also used for detection, and it was 0.66 when a different model was used for detection. However, preprocessing of texts improved performance when a different model, not used for text generation, was utilized for detection. The contributions of this study are as follows. First, we constructed LLM-generated text dataset for Korean. Also, we compared the detection performance of different models including BERT-based models and DetectGPT. Practically, this study indicates that people are hard to distinguish texts generated by large language models, suggesting that platforms need to manage these fake reviews to enhance the reliability of online reviews."
Integrated bioelectroremediation: Simultaneous treatment of industrial effluents and bioenergy generation,2024,"['Bioelectroremediation', 'Biocatalyst', 'Microbial fuel cells', 'Polycyclic aromatic hydrocarbons (PAHs)', 'Perchlorate', 'Tetrachloroethylene']",,"Bioelectroremediation technology (BERT) is a new age greener technology which is currently been heavily studied for treatment of persistent industrial effluents such as polycyclic aromatic hydrocarbons (PAHs), perchloroethylene (PCE), perchlorate, nitrate and petroleum hydrocarbon (PHs) along with simultaneous generation of bioenergy. The focus of this review paper is on these industrial effluents because many of these effluents are toxic in nature and through contaminated water, soil or sediment enter the food chain and start to bioaccumulate thereby entering living organisms and causing severe fatal diseases. While PAHs and nitrates are major contaminant of both water and soil but their removal efficiency through BERT is much more in water sample than from soil samples, studies have shown that perchlorate and nitrate are usually co-contaminants and perchlorate, PCE and PHs are much more prevalent groundwater contaminant with good removal efficiency of these contaminants and simultaneous bioelectricity generation through BERT. Therefore, this review paper focus on role of microbial community structure as a biocatalyst in BERT along with a in-depth review of bioelectroremediation process for industrial effluent treatment involved in removing diverse pollutants integrated with energy generation from fundamentals, challenges, and future prospective dimensions."
딥러닝을 활용한 중국어 방향보어의 의미 추론 연구,2024,"['중국어 방향보어', '딥러닝', 'BERT', '의미 추론', '상', '上', '起来', '下来', '下去', '방향이동', '결과', '완성', '시작', '지속', '담화표지', 'Chinese Directional Complement', 'Deep Learning', 'BERT', 'Semantic Inference', 'Aspect', 'shang', 'qilai', 'xialai', 'xiaqu', 'Directional Movement', 'Resultative', 'Completive', 'Beginning', 'Continuative', 'Discourse Marker']","본 연구는 중국어 방향보어의 의미를 분석하고 예측하는 데 있어 딥러닝 기술을 도입하여 그 효용성을 탐색하였다. BERT 기반의 전이학습 모델을 활용하여 방향보어의 다양한 의미 기능을 자동으로 추론하고, 이 과정에서 관찰되는 언어학적 특성을 분석하였다.실험 결과, 본 연구에서 제안한 딥러닝 모델은 방향보어의 의미를 매우 높은 정확도로 예측할 수 있음을 확인하였다. 특히 동사, 부사, 전치사구, 목적어 등 다양한 문장 성분이 방향보어 의미 결정에 기여하는 양상을 포착함으로써, 기존의 언어학적 통찰을 뒷받침하는 경험적 근거를 제시하였다. 이는 자연언어처리 기술이 언어 현상의 분석과 이해에 기여할 수 있는 가능성을 시사한다.본 연구는 방향보어의 의미가 문장 내 성분들의 복합적 상호작용을 통해 역동적으로 구성됨을 보였다는 점에서 의의가 있다. 또한 대규모 말뭉치와 정교한 의미 주석 데이터를 활용한 전이학습 방법론의 유효성을 입증함으로써, 딥러닝 기술을 언어학 연구에 적용하는 새로운 지평을 열었다고 평가할 수 있다.","This study explores the effectiveness of deep learning techniques in analyzing and predicting the semantics of Chinese directional complements using a BERT-based transfer learning model. The results confirm that the proposed model can predict the meanings of directional complements with high accuracy by capturing the contributions of various sentence components. The study demonstrates that the meanings of directional complements are dynamically constructed through complex interactions among sentence components and validates the effectiveness of the transfer learning methodology utilizing large-scale corpora and semantic annotation data. However, the analysis is limited to four directional complements, and future research should expand the scope and explore ways to apply the findings in Chinese language education. The outcomes are expected to broaden the understanding of the semantic functions of modern Chinese directional complements and contribute to the improvement of relevant educational methods."
F_MixBERT: Sentiment Analysis Model using Focal Loss for Imbalanced E-commerce Reviews,2024,"['E-commerce reviews', 'Sentiment analysis', 'BERT', 'MixMatch', 'Focal loss']",,"Users' comments after online shopping are critical to product reputation and business improvement. These comments, sometimes known as e-commerce reviews, influence other customers' purchasing decisions. To confront large amounts of e-commerce reviews, automatic analysis based on machine learning and deep learning draws more and more attention. A core task therein is sentiment analysis. However, the e-commerce reviews exhibit the following characteristics: (1) inconsistency between comment content and the star rating; (2) a large number of unlabeled data, i.e., comments without a star rating, and (3) the data imbalance caused by the sparse negative comments. This paper employs Bidirectional Encoder Representation from Transformers (BERT), one of the best natural language processing models, as the base model. According to the above data characteristics, we propose the F_MixBERT framework, to more effectively use inconsistently low-quality and unlabeled data and resolve the problem of data imbalance. In the framework, the proposed MixBERT incorporates the MixMatch approach into BERT’s high-dimensional vectors to train the unlabeled and low-quality data with generated pseudo labels. Meanwhile, data imbalance is resolved by Focal loss, which penalizes the contribution of large-scale data and easily-identifiable data to total loss. Comparative experiments demonstrate that the proposed framework outperforms BERT and MixBERT for sentiment analysis of e-commerce comments."
데이터 세트별 Post-Training을 통한 언어 모델 최적화 연구 : 금융 감성 분석을 중심으로,2024,"['BERT', 'FinBERT', '금융 감성 분석', 'post-training', '사전 학습 데이터 세트', 'Financial Sentiment Analysis', 'Post-training', 'Pre-training Dataset']","본 연구는 금융 분야에서 중요한 증감 정보를 효과적으로 이해하고 감성을 정확하게 분류하기 위한 언어 모델의 학습 방법론을 탐구한다. 연구의 핵심 목표는 언어 모델이 금융과 관련된 증감 표현을 잘 이해할 수 있게 하기 위한 적절한 데이터 세트를 찾는 것이다. 이를 위해, Wall Street Journal에서 수집한 금융 뉴스 문장 중 증감 관련 단어를 포함하는 문장을 선별했고, 이와 함께 적절한 프롬프트를 사용해 GPT-3.5-turbo-1106으로 생성한 문장을 각각 post-training에 사용했다. Post-training에 사용한 데이터 세트가 언어 모델의 학습에 어떠한 영향을 미치는지 금융 감성 분석 벤치마크 데이터 세트인 Financial PhraseBank를 통해 성능을 비교하며 분석했으며, 그 결과 금융 분야에 특화된 언어 모델인 FinBERT를 추가 학습한 결과가 일반적인 도메인에서 사전 학습된 모델인 BERT를 추가학습한 것보다 더 높은 성능을 보였다. 또 금융 뉴스로 post-training을 진행한 것이 생성한 문장을 post-training을 진행한 것에 비해 전반적으로 성능이 높음을 보였으나, 일반화가 더욱 요구되는 환경에서는 생성된 문장으로 추가 학습한 모델이 더 높은 성능을 보였다. 이러한 결과는 개선하고자 하는 부분의 도메인이 사용하고자 하는 언어 모델과의 도메인과 일치해야 한다는 것과 적절한 데이터 세트의 선택이 언어 모델의 이해도 및 예측 성능 향상에 중요함을 시사한다. 연구 결과는 특히 금융 분야에서 감성 분석과 관련된 과제를 수행할 때 언어 모델의 성능을 최적화하기 위한 방법론을 제시하며, 향후 금융 분야에서의 더욱 정교한 언어 이해 및 감성 분석을 위한 연구 방향을 제시한다. 이러한 연구는 금융 분야 뿐만 아니라 다른 도메인에서의 언어 모델 학습에도 의미 있는 통찰을 제공할 수 있다.","This research investigates training methods for large language models to accurately identify sentiments and comprehend information about increasing and decreasing fluctuations in the financial domain. The main goal is to identify suitable datasets that enable these models to effectively understand expressions related to financial increases and decreases. For this purpose, we selected sentences from Wall Street Journal that included relevant financial terms and sentences generated by GPT-3.5-turbo-1106 for post-training. We assessed the impact of these datasets on language model performance using Financial PhraseBank, a benchmark dataset for financial sentiment analysis. Our findings demonstrate that post-training FinBERT, a model specialized in finance, outperformed the similarly post-trained BERT, a general domain model. Moreover, post-training with actual financial news proved to be more effective than using generated sentences, though in scenarios requiring higher generalization, models trained on generated sentences performed better. This suggests that aligning the model’s domain with the domain of the area intended for improvement and choosing the right dataset are crucial for enhancing a language model's understanding and sentiment prediction accuracy. These results offer a methodology for optimizing language model performance in financial sentiment analysis tasks and suggest future research directions for more nuanced language understanding and sentiment analysis in finance. This research provides valuable insights not only for the financial sector but also for language model training across various domains."
언어 모델 기반 음성 특징 추출을 활용한 생성 음성 탐지,2024,"['BERT', 'Audio codec', 'Voice Features Extraction', 'Speech Synthesis', 'Generated voice detection']","최근 음성 생성 기술의 급격한 발전으로, 텍스트만으로도 자연스러운 음성 합성이 가능해졌다. 이러한 발전은 타인의 음성을 생성하여 범죄에 이용하는 보이스피싱과 같은 악용 사례를 증가시키는 결과를 낳고 있다. 음성 생성 여부를 탐지하는 모델은 많이 개발되고 있으며, 일반적으로 음성의 특징을 추출하고 이러한 특징을 기반으로 음성 생성 여부를 탐지한다. 본 논문은 생성 음성으로 인한 악용 사례에 대응하기 위해 새로운 음성 특징 추출 모델을 제안한다. 오디오를 입력으로 받는 딥러닝 기반 오디오 코덱 모델과 사전 학습된 자연어 처리 모델인 BERT를 사용하여 새로운 음성 특징 추출 모델을 제안하였다. 본 논문이 제안한 음성 특징 추출 모델이 음성 탐지에 적합한지 확인하기 위해 추출된 특징을 활용하여 4가지 생성 음성 탐지 모델을 만들어 성능평가를 진행하였다. 성능 비교를 위해 기존 논문에서 제안한 Deepfeature 기반의 음성 탐지 모델 3개와 그 외 모델과 정확도 및 EER을 비교하였다. 제안한 모델은 88.08%로 기존 모델보다 높은 정확도와 11.79%의 낮은 EER을 보였다. 이를 통해 본 논문에서 제안한 음성 특징 추출 방법이 생성 음성과 실제 음성을 판별하는 효과적인 도구로 사용될 수 있음을 확인하였다.","Recent rapid advancements in voice generation technology have enabled the natural synthesis of voices using text alone. However, this progress has led to an increase in malicious activities, such as voice phishing (voishing), where generated voices are exploited for criminal purposes. Numerous models have been developed to detect the presence of synthesized voices, typically by extracting features from the voice and using these features to determine the likelihood of voice generation.This paper proposes a new model for extracting voice features to address misuse cases arising from generated voices. It utilizes a deep learning-based audio codec model and the pre-trained natural language processing model BERT to extract novel voice features. To assess the suitability of the proposed voice feature extraction model for voice detection, four generated voice detection models were created using the extracted features, and performance evaluations were conducted. For performance comparison, three voice detection models based on Deepfeature proposed in previous studies were evaluated against other models in terms of accuracy and EER. The model proposed in this paper achieved an accuracy of 88.08%and a low EER of 11.79%, outperforming the existing models. These results confirm that the voice feature extraction method introduced in this paper can be an effective tool for distinguishing between generated and real voices."
화장품 소비자의 차별화된 기호가치 소비 브랜드군에 대한 담론의 비교분석: 텍스트 마이닝을 중심으로,2024,"['Semiotic value consumption', 'Trigram analysis', 'Topic modeling analysis', 'Similarities analysis', 'BERT Sentiment analysis', '记号价值消耗，三元组分析，主题建模分析，相似度分析，BERT情感分析', '기호가치 소비', '트라이그램 분석', '토픽 모델링 분석', '유사도 분석', 'BERT 감성분석']","목적: 본 연구는 저가색조화장품과 고가색조화장품 그리고 수입색조화장품으로 세분화된 이들 세분시장은 과연 차별화된 정체성으로 포지셔닝되어 있으며, 색조화장품 브랜드군 세분시장 간에는 어떠한 유사도와 차이점을 가지고 있을까?에 대한 의문으로 시작하였다. 방법: 본 연구를 수행하기 위해 Python version 3.10.6 프로그램을 이용하여 네이버 쇼핑몰의 색조화장품 카테고리에서 기호가치 소비한 소비자의 담론을 크롤링하였으며, 전처리 과정을 거쳐서 워드클라우드 분석, N-gram 분석, 토픽 모델링 분석, 유사도 분석, 그리고 감성분석을 시행하였다. 결과: 텍스트 마이닝 분석과정에서 많은 흥미로운 것을 발견하였는데, 그 중 하나는 혁신적 소비자들이 참여하는 짧은 시간내에 이루어지는 라이브 방송을 통해 구매하는 새로운 유통경로에 대한 발견과 저가색조화장품과 수입색조화장품 세분시장에서 휴리스틱스적인 결과는 다르나 유사한 담론의 패턴을 사용하고 있었으며, 세분화된 각 세분시장은 차별화된 포지셔닝을 가지고 있는 것으로 나타났다. 결론: 비교 연구 대상인 기호가치 소비한 저가 화장품, 고가 화장품, 수입 화장품의 색조 화장품 이용 소비자 그룹은 각기 다른 정체성을 가지고 있어 브랜드 세분시장과 포지셔닝이 다르며 소비자들의 선택 속성 또한 다르기 때문에 국내 색조 화장품 산업의 방향성을 제시하는 동시에 마케팅 전략에 활용할 이론적 기초자료를 제공할 수 있으며, 각 비교 연구 군에서 얻게 되는 연구 결과에 따라 색조 화장품 브랜드 세분시장 별 시장경쟁력 강화를 위한 경영전략 및 마케팅 전략에 폭넓은 실무적 시사점을 제시할 수 있을 것이다.","Purpose: This study began by investigating the similarities and differences among segmented markets within the color cosmetics industry, which are subdivided into low-cost color, high-priced, and imported color cosmetics, positioned as differentiated identities, and what are the similarities and differences between the segmented markets of the color cosmetics brand group. Methods: To perform this study, we used Python version 3.10.6 to crawl discourse from attracting value-driven consumers in the color cosmetics category on Naver Shopping Mall. After that, we completed the pre-processing steps and then conducted Word Cloud analysis, N-gram analysis, Topic Modeling analysis, Similarity analysis, and Sentiment analysis. Results: The text mining analysis showed several interesting findings. Notably, we found a new distribution channel where innovative consumers make purchases through live broadcasts performed within a short period. Furthermore, the analysis indicated that while low-priced and imported color cosmetics submarkets showed different logical results, they utilized similar discourse patterns. Furthermore, each segmented submarket was observed to possess a distinct positioning strategy. Conclusion: The consumer groups that utilized the taste value, the subject of comparative analysis, and used the low-cost, high-value, and imported color cosmetics have different identities. Consequently, the market segmentation and positioning of these brands differ, and consumer preferences vary. This allows us to outline the direction of the domestic color cosmetics industry and provide basic theoretical materials for marketing strategies. According to the research results obtained from each comparative research group, it will be possible to present a wide range of practical implications for management and marketing strategies to strengthen the market competitiveness of color cosmetics brand segments."
Transformer-based reranking for improving Korean morphological analysis systems,2024,"['deep learning', 'Korean morphological analysis', 'natural language understanding', 'pretrained transformer encoder', 'reranking']",,"This study introduces a new approach in Korean morphological analysis combining dictionary-based techniques with Transformer-based deep learning models. The key innovation is the use of a BERT-based reranking system, significantly enhancing the accuracy of traditional morphological analysis. The method generates multiple suboptimal paths, then employs BERT models for reranking, leveraging their advanced language comprehension. Results show remarkable performance improvements, with the first-stage reranking achieving over 20% improvement in error reduction rate compared with existing models. The second stage, using another BERT variant, further increases this improvement to over 30%. This indicates a significant leap in accuracy, validating the effectiveness of merging dictionary-based analysis with contemporary deep learning. The study suggests future exploration in refined integrations of dictionary and deep learning methods as well as using probabilistic models for enhanced morphological analysis. This hybrid approach sets a new benchmark in the field and offers insights for similar challenges in language processing applications."
Automatic Classification of Scientific and Technical Papers Using Large Language Models and Retrieval-Augmented Generation,2024,"['BERT', 'Document classification', 'Large language model (LLM)', 'Retrieval-augmented generation (RAG)', 'Vector database (DB)']",,"This study proposes artificial intelligence (AI) technology for the automatic classification of Korean scientific and technical papers, aiming to achieve high accuracy even with a small amount of labeled data. Unlike existing BERT-based Korean document classification models that perform supervised learning based on a large amount of accurately labeled data, this study proposes a structure that utilize large language models (LLMs) and retrieval-augmented generation (RAG) technology. The proposed method experimentally demonstrates that it can achieve higher accuracy than existing technologies across all cases using various amounts of labeled data. Furthermore, a qualitative comparison between manually-generated labels, and recognized as correct answers and those produced by LLM responses confirmed that the LLM responses were more accurate. The findings of this study, while limited to Korean scientific documents, provide evidence that a system utilizing LLM and RAG for document classification can easily be extended to other domains with diverse document datasets, owing to its effectiveness even with limited labels."
Inter-sentential Processing of Language Models: The  Case of Felicity Conditions,2024,"['Allosentences', 'felicity', 'BERT', 'ChatGPT', 'inter-sentential processing', 'subject-object asymmetry']",,"This study used allosentences to investigate the extent to which language models comprehend the nonliteral and pragmatic elements of natural language. Allosentences are sentences that share the same truth conditions but differ in felicity conditions and are thus pragmatically differentiated. We constructed a dataset of allosentences to assess whether current language models could capture pragmatic distinctions rooted in felicity conditions, which are crucial for human-like communication. Using the BERT-base/large and GPT-3.5/ GPT-4 models, we conducted the following two experiments: Experiment 1 (next sentence prediction (NSP) task) and Experiment 2 (text generation task). Both aim to determine whether language models can select felicitous answers to questions in a human-like manner. The findings reveal that, although not flawless, language models exhibit the capacity to generate more felicitous responses in specific contexts, shedding light on their ability for human-like communication. We suggest that inter-sentential processing is required in addition to intra-sentential processing to engage in a genuinely human-like conversation. At the same time, we report that language models share with humans a bias related to subject-object asymmetry, showing better performance on object questions."
한의 처방 명칭의 개체명 정규화,2024,"['네트워크 약리학', '한의학', '중의학', '데이터 통합', '생물정보학', 'Named entity recognition', 'Named entity normalization', 'GPT', 'BERT', 'Traditional herbal formula']",,"In this paper, we propose methods for the named entity normalization of traditional herbal formula found in medical texts. Specifically, we developed methodologies to determine whether mentions, such as full names of herbal formula and their abbreviations, refer to the same concept. Two different approaches were attempted. First, we built a supervised classification model that uses BERT-based contextual vectors and character similarity features of herbal formula mentions in medical texts to determine whether two mentions are identical. Second, we applied a prompt-based querying method using GPT-4o mini and GPT-4o to perform the same task. Both methods achieved over 0.9 in Precision, Recall, and F1-score, with the GPT-4o-based approach demonstrating the highest Precision and F1-Score. The results of this study demonstrate the effectiveness of machine learning-based approaches for named entity normalization in traditional medicine texts, with the GPT-4o-based method showing superior performance. This suggests its potential as a valuable foundation for the development of intelligent information extraction systems in the traditional medicine domain."
한국어 반어 표현 탐지기,2024,"['반어 탐지', 'KoBERT', 'ChatGPT', '전이 학습', '멀티태스크 학습', 'Irony Detection', 'KoBERT', 'ChatGPT', 'Transfer Learning', 'MultiTask Learning']","자연어 처리 분야에서 반어 및 비꼼 탐지의 중요성이 커지고 있음에도 불구하고, 한국어에 관한 연구는 다른 언어들에 비해 상대적으로 많이부족한 편이다. 본 연구는 한국어 텍스트에서의 반어 탐지를 위해 다양한 모델을 실험하는 것을 목적으로 한다. 본 연구는 BERT기반 모델인 KoBERT와 ChatGPT를 사용하여 반어 탐지 실험을 수행하였다. KoBERT의 경우, 감성 데이터를 추가 학습하는 두 가지 방법(전이 학습, 멀티태스크 학습)을적용하였다. 또한 ChatGPT의 경우, Few-Shot Learning기법을 적용하여 프롬프트에 입력되는 예시 문장의 개수를 증가시켜 실험하였다. 실험을수행한 결과, 감성 데이터를 추가학습한 전이 학습 모델과 멀티태스크 학습 모델이 감성 데이터를 추가 학습하지 않은 기본 모델보다 우수한 성능을보였다. 한편, ChatGPT는 KoBERT에 비해 현저히 낮은 성능을 나타내었으며, 입력 예시 문장의 개수를 증가시켜도 뚜렷한 성능 향상이 이루어지지않았다. 종합적으로, 본 연구는 KoBERT를 기반으로 한 모델이 ChatGPT보다 반어 탐지에 더 적합하다는 결론을 도출했으며, 감성 데이터의 추가학습이 반어 탐지 성능 향상에 기여할 수 있는 가능성을 제시하였다.","Despite the increasing importance of irony and sarcasm detection in the field of natural language processing, research on the Koreanlanguage is relatively scarce compared to other languages. This study aims to experiment with various models for irony detection inKorean text. The study conducted irony detection experiments using KoBERT, a BERT-based model, and ChatGPT. For KoBERT, twomethods of additional training on sentiment data were applied (Transfer Learning and MultiTask Learning). Additionally, for ChatGPT,the Few-Shot Learning technique was applied by increasing the number of example sentences entered as prompts. The results of theexperiments showed that the Transfer Learning and MultiTask Learning models, which were trained with additional sentiment data,outperformed the baseline model without additional sentiment data. On the other hand, ChatGPT exhibited significantly lower performancecompared to KoBERT, and increasing the number of example sentences did not lead to a noticeable improvement in performance. Inconclusion, this study suggests that a model based on KoBERT is more suitable for irony detection than ChatG"
LLM 기반 임베딩 벡터를 활용한 질병과 관련된 전통 한약 처방 문서의 자동 분류,2024,"['text classification', 'herbal formula', 'large language models']",,"Objectives: This study focuses on the development of an automatic classification system for herbal formula documents related to diseases.Methods: We used 740 abstracts of herbal formula documents associated with diseases as positive samples, and sampled negative documents from the entire PubMed database. For feature extraction, we utilized text-embedding-ada-002 and OpenAI's bert-base-uncased embedding vectors based on BERT, and employed XGBoost and SVM as classification models. The performance of the classification models was evaluated using Precision, Recall, F1-Score, AUC-ROC, and AUC-PR metrics.Results: SVM consistently outperformed XGBoost, and the classification performance differed depending on whether the negative documents were sampled from the entire PubMed database or from traditional medicine literature. Furthermore, as the proportion of negative documents in the training data increased, the model's classification performance decreased. A comparison between PubMed's default ranking and the ranking generated by our automatic classification system showed that our method ranked disease-related prescription documents higher.Conclusions: Our model demonstrates that our approach can improve the efficiency of searching and collecting disease-related herbal formula literature."
추천 시스템에서의 선형 모델과 비선형 모델의 성능 비교 연구,2024,"['추천 시스템', '협업 필터링', '선형 모델', '비선형 모델', '성능 평가', 'Recommendation System', 'Collaborative Filltering', 'Linear Model', 'Non-linear Model', 'Performance Evaluation']","추천 시스템은 기업의 매출 증가로 이어질 만큼 핵심적인 역할을 하기에 추천 시스템에 대한 연구는 과거부터 다양한 접근법과 모델들이 연구되어왔다. 그러나 이러한 다양성으로 인해 추천 시스템의 종류 또한 복잡하게 구성되고 있어 추천 모델을 선택하는 데 어려움이 따른다. 따라서 본 연구는 추천 시스템에서 적절한 추천 모델 선택의 어려움을 해결하고자, 다양한 추천 모델을 구분하는 통합적인 기준을 제공하고, 통일된 환경에서 이들의 성능을 비교 평가하였다. 실험은 MovieLens와 Coursera 데이터셋을 활용하였으며, 선형 모델(ADMM-SLIM, EASER, LightGCN)과 비선형 모델(Caser, BERT4Rec)을 HR@10과 NDCG@10 지표를 통해 성능을 평가하였다. 본 연구는 연구진과 실무자들에게 데이터셋 특성과 추천 상황에 맞는 최적의 모델을 선택하는 데 유용한 정보를 제공할 것이다.","Since recommendation systems play a key role in increasing the revenue of companies, various approaches and models have been studied in the past. However, this diversity also leads to a complexity in the types of recommendation systems, which makes it difficult to select a recommendation model. Therefore, this study aims to solve the difficulty of selecting an appropriate recommendation model for recommendation systems by providing a unified criterion for categorizing various recommendation models and comparing their performance in a unified environment. The experiments utilized MovieLens and Coursera datasets, and the performance of linear models(ADMM-SLIM, EASER, LightGCN) and non-linear models(Caser, BERT4Rec) were evaluated using HR@10 and NDCG@10 metrics. This study will provide researchers and practitioners with useful information for selecting the best model based on dataset characteristics and recommendation context."
Bayesian Optimization-HyperBand 를 적용한 효과적인  가짜 뉴스 탐지모델의 성능 평가와 분석,2024,"['Rumor Detection', 'Fake News Detection', 'Text Classification', 'Hyperparameter Optimization', 'Bayesian Optimization-Hyperband (BOHB)']","소셜 미디어 상에 최근 들어 급증한 가짜 뉴스는 우리의 삶을 위협하고 있다. 즉, 더 교묘한가짜 정보가 소셜미디어에 유통될수록 더 정확한 탐지방법이 필요하다. 이를 위해 본 논문은Hyperband가 Global Optimum에 수렴하지 못하는 문제를 해결하는 동시에 강한 성능을 보이는최신 최적화 방법론인 Bayesian Optimization-Hyperband(BOHB)를 도입한 가짜 뉴스 탐지 모델을제안한다. 먼저 전처리된 LIAR 데이터셋과 FakeNewsNet 데이터셋의 텍스트를 TF-IDF, Word2Vec, BERT로 임베딩한다. 이후 텍스트 임베딩을 입력으로 하는 SVM과 Bi-LSTM으로 훈련시키는 동시에BOHB로 hyperparameter를 최적화한다. 최적화된 모델은 최적화되지 않은 모델보다 Accuracy가LIAR 데이터셋에 대해 21.1%, FAKENEWSNET에 대해 10.14%가 상승했다. 결과적으로, BOHB를적용한 모델이 그렇지 않은 모델보다 효율적임을 입증한다.","The increasing of fake news on social media threatens our life these days. The more deceptive information is flowed on the social media, the more accurate rumor detection is required. So, we propose the rumor detection model with the state-of-the-art optimizing methodology, Bayesian Optimization- Hyperband (BOHB), showing strong performance while solving the limitation of Hyperband not to converge to global optimum. First, the preprocessed rumor texts in LIAR and FakeNewsNet datasets are embedded by TF-IDF, Word2Vec and BERT. And then, we train SVM and Bi-LSTM with text embeddings as input, while optimizing hyperparameters with BOHB. The accuracy of optimized models is increased 21.1% on LIAR dataset and 10.14% on FAKENEWSNET dataset rather than not optimized models. As a result, our proposed model optimized by BOHB shows the better performance rather than not optimized models."
토픽모델링과 네트워크 분석에 기반한 AI 음성기술 연구 동향 분석,2024,"['음성처리 지적구조', '토픽모델링', '네트워크분석', '음성인식', '음성합성', 'Speech processing intellectual structure', 'Topic modeling', 'Network analysis', 'Speech recognition', 'Speech synthesis']","본 연구에서는 토픽모델링과 네트워크 분석을 활용하여 AI 음성기술의 연구 동향을 WoS에 등재된 한국저자 논문 1,530편을 대상으로 3차 시기로 나누어 AI 음성기술 연구의 지적 네트워크과 주요 연구 토픽을 분석했다. 초기 연구(2011-2015)는 HMM과 같은 머신러닝 모델 및 초기 딥 러닝 기술을 사용하여 음성인식, 소음 감소및 신호 처리 개선에 중점을 둔 강력한 음성인식, 청각 처리 및 화자 적응이었다. 중기(2016～2020)는 딥 러닝과머신러닝 기술을 적용하여 음성 및 언어 처리 분야에서 상당한 발전을 가져왔고 감정 인식, 시끄러운 환경에서의향상된 음성인식 및 의료 분야와 같은 응용 분야에 중점을 두고 있었다. 최근 연구(2021～2024)는 자연어 처리를위한 Transformers 및 BERT를 포함한 정교한 AI 모델을 사용하여 음성 및 감정 인식이 지속적으로 발전하고있고, 맞춤형 음성합성, 달팽이관 이식과 같은 보조 기술의 적용에도 중점은 두고 있다. 본 연구에서 한국은 2011 년부터 2024년까지 AI 음성처리 기술 분야의 연구 동향을 분석한 결과는 상당한 기술 발전과 적용 확대를 경험했다는 결론이 나왔다. 이러한 발전은 지속적인 혁신과 새로운 과제에 대한 적응을 통해 다양한 부문에서 AI 음성처리 기술의 영향력과 중요성이 커지고 있음을 반영할 수 있다.","In this study, using topic modeling and network analysis, research trends in AI voice technology were divided into three periods targeting 1,530 papers by Korean authors registered in WoS to identify the intellectual network and major research topics of AI voice technology research. was analyzed. Early research (2011-2015) was in robust speech recognition, auditory processing and speaker adaptation, focusing on improving speech recognition, noise reduction and signal processing using machine learning models such as the HMM and early deep learning techniques. The mid-term (2016-2020) brought significant advances in the field of speech and language processing by applying deep learning and machine learning technologies, focusing on application areas such as emotion recognition, improved speech recognition in noisy environments, and the medical field. Recent research (2021-2024) continues to advance speech and emotion recognition using sophisticated AI models, including Transformers and BERT for natural language processing, and also focuses on the application of assistive technologies such as personalized speech synthesis and cochlear implants. there is. In this study, the results of analyzing research trends in the field of AI voice processing technology from 2011 to 2024 concluded that Korea has experienced significant technological development and expansion of application. These developments may reflect the growing influence and importance of AI voice processing technology in various sectors through continuous innovation and adaptation to new challenges."
인공지능 법령 질의응답시스템을 위한 규범 기반 사례 데이터 생성과 활용에 관한 연구,2024,"['법령질의응답시스템', '이해충돌방지법', 'AI Compliance', 'KoBERT', 'Legal QA System', 'Conflict of Interest Prevention Act', 'AI Compliance', 'KoBERT']","법령정보는 국민의 일상과 밀접하게 연관되어 있지만, 이해하기 어려운 용어와 판단의 전문성이 요구된다. 특히, 위법 행위에 대한 규제를 다루는 법령의 경우 규제 대상자의 법 이해도에 따라 판단의 기준이 상이하게 나타날 수 있다. 이에 법령 접근 편의성을 높이기 위해 챗봇을 비롯한 질의응답 형식의 다양한 서비스가 개발되고 있다. 본 연구에서는 2022년 5월부터 시행된 공직자의 이해충돌방지법을 대상으로 규제위반 여부를 질의를 통해 사전에 판단할 수 있는 법령 질의응 답시스템 개발을 위한 사례 데이터 생성과 활용에 대한 방법론을 제시하고자 한다. 이를 위해 이해충돌방지법의 법조문 분석을 통해 규범 패턴을 도출하여 가상의 사례 약 31만 건을 생성하였으며, 해당 데이터를 학습 데이터로 활용하여 법위반 여부를 판단하는 BERT 기반 분류 모델을 구축하여 이해충돌방지법 위반 여부에 대한 분류 정확도를 검증하였다.","Although legal information is closely related to people’s daily lives, it can be difficult to understand and requires expertise in judgement. In the case of laws and regulations that regulate illegal acts, the standard of judgement may vary depending on the level of legal understanding of the regulated person. Therefore, various services in the form of question and answer, including chatbots, are being developed to improve access to laws and regulations. In this study, we propose a methodology for generating and utilizing case data for the development of a legal QA system that can preliminarily determine whether a regulatory violation has occurred by asking questions about the Prevention of Conflicts of Interest of Public Officials Act, which has been in effect since May 2022. This study generated about 310,000 hypothetical cases by extracting normative patterns through analyzing the legal provisions of the Conflict-of-Interest Prevention Act and built a BERT-based classification model to determine whether the law is violated by using the data as learning data to verify the classification accuracy of whether the Conflict-of-Interest Prevention Act is violated."
인공지능 기반 개체명 인식 기술을 활용한 보안 위협 정보 식별 방안 연구,2024,"['Log data analysis', 'Named entity recognition', 'Security essential information', 'Security equipment']","새로운 기술이 개발 됨에 따라, 랜섬웨어를 만들어 주는 AI 기술 등장과 같은 새로운 보안 위협도 증가되고 있다. 이러한 보안 위협에 대응하기 위해 XDR와 같은 신규 보안장비가 개발되었지만, 단일 보안장비 환경이 아닌 다양한 보안장비를 함께 사용하는 경우 필수 데이터 식별 및 분류를 위해 수많은 정규표현식을 만들어야 하는 어려움이 존재한다. 이를 해결하기 위해 본 논문에서는 다양한 보안장비 사용 환경에서 인공지능 기반 개체명 인식 기술을 도입하여 위협 정보 식별을 위한 필수 정보 식별 방안을 제안한다. 보안장비 로그 데이터를 분석하여 필수 정보를 선정한 뒤, 정보의 저장 포맷과 인공지능을 활용하기 위한 태그 리스트를 정의하였고, 인공지능을 이용한 개체명 인식 기술을 통해 필수 데이터 식별 및 추출 방안을 제안한다. 다양한 보안장비 로그 데이터와 23개의 태그 기반 개체명 인식 시험 결과 태그별 f1-score의 가중치 평균이 Bi-LSTM-CRF는 0.44, BERT-CRF는 0.99의 성능을 보인다. 향후 정규표현식 기반의 위협 정보 식별·추출 방안과 인공지능 기반의 위협 정보 식별·추출 방안을 통합하는 프로세스를 연구하고 신규 데이터 기반으로 프로세스를 적용해 볼 예정이다.","As new technologies are developed, new security threats such as the emergence of AI technologies that create ransomware are also increasing. New security equipment such as XDR has been developed to cope with these security threats, but when using various security equipment together rather than a single security equipment environment, there is a difficulty in creating numerous regular expressions for identifying and classifying essential data. To solve this problem, this paper proposes a method of identifying essential information for identifying threat information by introducing artificial intelligence-based entity name recognition technology in various security equipment usage environments. After analyzing the security equipment log data to select essential information, the storage format of information and the tag list for utilizing artificial intelligence were defined, and the method of identifying and extracting essential data is proposed through entity name recognition technology using artificial intelligence. As a result of various security equipment log data and 23 tag-based entity name recognition tests, the weight average of f1-score for each tag is 0.44 for Bi-LSTM-CRF and 0.99 for BERT-CRF. In the future, we plan to study the process of integrating the regular expression-based threat information identification and extraction method and artificial intelligence-based threat information and apply the process based on new data."
온라인 기사형 광고에 대한 소비자의 긍정적 반응 : 광고 유형(선 vs 악)과 게재 시점의 상호작용을 중심으로,2024,"['기사형 광고', '텍스트 마이닝', '선한 광고', '악한 광고', '게재 시점', '긍정적 반응', 'Online advertorials', 'Text mining', 'Vice advertorials', 'Virtue advertorials', 'Timing  of posting', 'Positive response']","기사형 광고는 기업이 자사의 신제품 또는 기술적 진보를 시장에 알리기 위해 사용하는 프로모션 수 단 중 하나이다. 광고가 기사의 형태로 제시되면 소비자의 설득지식이 활성화되기 어렵기 때문에 소비 자가 광고의 내용을 신뢰할 가능성이 높아진다. 이런 이유로 기사형 광고는 마케팅 도구로 자주 사용되 고 있으며, 이 광고의 특성과 효과에 대한 연구 역시 활발히 진행되었다. 본 연구는 기사형 광고가 다루 는 제품의 특성에 따라 이를 선(virtue)과 악(vice)으로 분류하여 소비자의 긍정적 반응을 살펴봄과 동 시에 이러한 광고 유형이 게재 시점과 어떻게 상호작용하는지 조사했다. 네이버 포털에 2019년에 게재 된 기사형 광고를 텍스트 마이닝 기법을 사용해 분류한 후, 오전과 오후 시간에 같은 제목으로 게재된 기사형 광고 406개를 선정했다. 소비자가 사용한 긍정적인 이모티콘의 수를 광고가 노출된 시간으로 나눈 값을 긍정적 반응의 지표로 사용했다. 긍정적 반응은 기사형 광고가 게재된 시점이 하루 중 오후 시간일 때 오전 시간일 때에 비해 유의하게 높았다. 광고 유형과 게재 시점의 상호작용은 유의하지 않 았으나, 게재 시점에 따른 효과가 악한 광고의 경우 한계적으로 유의한 반면 선한 광고의 경우 유의하 지 않은 방향성이 나타났다. 이는 악한 광고에서는 게재 시점을 더욱 중요하게 고려해야 함을 의미한다. 일상생활 속의 다양한 방면에 적용할 수 있는 선-악의 구분을 온라인 매체에 적용한 연구는 매우 드문 데, 본 연구는 이를 기사형 광고라는 매체에 적용하여, 기존의 기사형 광고 및 온라인 매체를 다룬 연구 와 구분된다. 또한, 기사형 광고를 추출하고 분류할 때 자주 사용되던 영어 기반의 BERT가 아닌 한글 텍스트 분류에 적합한 KoBERT 모형에 기반한 딥러닝 기법을 사용함으로써 분류에서의 좀 더 높은 정 확도를 획득할 수 있었다. 이와 같은 이론적 시사점과 함께 기사형 광고라는 촉진 도구에 대한 반응이 오후 시간일수록 긍정적이라는 결과는 실무적 시사점을 갖는다. 즉, 자사 제품 홍보를 위해 기사형 광 고를 사용할 때 소비자의 긍정적인 반응을 얻기 위해서는 기사를 오후 시간에 게재하는 것을 제안한다.","The companies often employ advertorial as a promotional tool for promoting their new products or technological advancements to the market. When advertisements are delivered in the form of the news article, it becomes difficult to activate consumers’ persuasion knowledge, thus increasing the likelihood of consumers trusting the content of the advertisement. For this reason, advertorial is frequently used as a promotion tool, and research on its characteristics and effects has been actively conducted. This study classified products featured in advertorial as virtues or vices to examine the positive responses of consumers and investigated how the type of advertisement interacts with the timing of its placement. Advertorials posted on the Naver portal in 2019 were analyzed and classified using text mining techniques, and 406 advertorials published both in the morning and evening were selected considering the impact of the timing of placement on responses. The number of positive emoticons used by consumers was measured as an indicator of positive response, which was significantly higher when the advertorials were posted in the evening compared to the morning. The interaction between advertorials and the timing of placement was not significant, but the effect of timing was marginally significant for vice advertorials, while it was not significant for virtue advertorials. This implies that the timing of placement should be more carefully considered for vice advertorials. Applying the distinction between virtue and vice in various aspects of everyday life to online media is very rare, and this study is distinguished from previous research in that it applies this distinction to advertorials, and online medium. Furthermore, the use of a deep learning technique based on KoBERT, rather than the commonly used English-based BERT, for extracting and classifying advertorials, allowed for higher accuracy in classification. Along with these theoretical implications, the result that responses to advertorials as a promotional tool are more positive later in the day has practical implications. We suggest the firms to implement advertorials for products that are designed for immediate gratification and post them at the evening. Such strategy is expected to enhance the effectiveness of the advertorials."
Modeling Short Answer Grading Performance Improvement by GPT Augmentation Data,2024,"['Data Augmentation', 'Automated Short Answer Grading System', 'GPT', 'fine-tuning']",,"The automatic grading of short answer question is important in the field of Natural Language Processing. ASAG (Automated Short Answer Grading) task have undergone numerous advancements.Recent studies have adopted transformer models such as the T5 embedding or BERT-base models.Nonetheless, ASAG tasks encounter significant challenges stemming from limited data availability. The urgent need for more training data emerges as a central issue. Several researchers have proposed augmentation approaches to address this gap. In this study, we introduce other data augmentation technique utilizing prompt engineering by the GPT model. We deploy ASAG system using the Sentence Transformers model, fine-tuning specific hyper-parameters alongside the augmented dataset. The primary factors influencing performance enhancement include the augmentation process, particularly the quantity of augmented data, and the dataset split size for training and testing purposes. Furthermore, alternative GPT models or fine-tuning GPT could be explored within the augmentation process."
한국어 반어 표현 탐지기,2024,"['반어 탐지', 'KoBERT', 'ChatGPT', '전이 학습', '멀티태스크 학습', 'Irony Detection', 'Transfer Learning', 'MultiTask Learning']",,"Despite the increasing importance of irony and sarcasm detection in the field of natural language processing, research on the Korean language is relatively scarce compared to other languages. This study aims to experiment with various models for irony detection in Korean text. The study conducted irony detection experiments using KoBERT, a BERT-based model, and ChatGPT. For KoBERT, two methods of additional training on sentiment data were applied (Transfer Learning and MultiTask Learning). Additionally, for ChatGPT, the Few-Shot Learning technique was applied by increasing the number of example sentences entered as prompts. The results of the experiments showed that the Transfer Learning and MultiTask Learning models, which were trained with additional sentiment data, outperformed the baseline model without additional sentiment data. On the other hand, ChatGPT exhibited significantly lower performance compared to KoBERT, and increasing the number of example sentences did not lead to a noticeable improvement in performance. In conclusion, this study suggests that a model based on KoBERT is more suitable for irony detection than ChatGPT, and it highlights the potential contribution of additional training on sentiment data to improve irony detection performance."
Application of Sentiment Analysis in Translanguaging and Translation,2024,"['Translanguaing(트랜스랭귀징)', 'Sentiment Analysis(감성 분석)', 'Coherence(응집성)', 'Implicature(함축)', 'TCSE', 'Translation Education(번역 교육)']",,"The purpose of this article is to emphasize the importance of sentiment analysis in translanguaging and translation. In sentiment analysis, “sentiment” refers not only to emotional feelings of love or hate, but also to opinions or attitudes. For this purpose, this study collected and examined three sets of original English transcripts and their Korean translations using the TED Corpus Search Engine (TCSE), developed by Yoichiro Hasebe at Doshisha University in Japan. With the data sets, this study performed BERT-based multilingual sentiment analysis on Google CoLab. The results revealed that sentence length and conjunction usage did not influence sentiment scores, whereas emotional or attitudinal words and phrases did affect the scores. These findings can lead to the development of new pedagogies and practical applications in the field of translation education. In addition, highlighting the significance of coherence and implicature, this study seeks to find the pragmatic or sentimental equivalence in the digital learning landscape."
한약 처방 논문의 증거 수준 예측을 위한 딥러닝 모델 개발,2024,"['herbal medicine formula', 'levels of evidence', 'deep learning', 'latural language processing', 'prediction algorithm']",,"Herbal medicine formula (HMF), a crucial treatment method in Korean medicine (KM), is increasingly being addressed in high-quality scientific journals, showing rapid growth both qualitatively and quantitatively. However, much valuable knowledge remains unstructured within a vast number of published papers. Recently, various studies have been conducted to extract knowledge from these unstructured papers by applying deep learning-based natural language processing (NLP) technologies. The levels of evidence, which indicate how reliable a particular study's findings are for making clinical decisions, play a crucial role in practicing evidence-based medicine. However, manually assessing the quality of research and determining its clinical applicability in the rapidly increasing number of papers related to HMF requires significant time and effort. Therefore, in this study, we aim to develop an algorithm to automatically determine the level of evidence of papers related to HMF by applying NLP methods. We constructed a corpus for AI training and testing. First, we selected 740 papers related to HMF and diseases randomly from PubMed using an HMF dictionary and a disease terminology dictionary. Experts in KM annotated the evidence levels to build the corpus. The distribution of evidence levels in the corpus was identified as follows: In-vivo Studies (61.22%), Randomized Control Trials (8.65%), and In-vitro Studies (7.84%). We fine-tuned BERT-based models with the built corpus to create a model that determines the evidence levels of a given paper. By evaluating the performance of four fine-tuned models, we found that SciBERT demonstrated the best performance with 94.59% (micro-F1), 89.11% (macro-F1), and 94.38% (weighted-F1)."
Traditional Chinese medicine diagnostic prediction model for holistic syndrome differentiation based on deep learning,2024,"['Traditional Chinese medicine syndromes', 'Deep learning', 'Holistic syndrome differentiation', 'Expert knowledge', 'Artificial intelligence']",,"Background: With the development of traditional Chinese medicine (TCM) syndrome knowledge accumulation and artificial intelligence (AI), this study proposes a holistic TCM syndrome differentiation model for the classification prediction of multiple TCM syndromes based on deep learning and accelerates the construction of modern foundational TCM equipment.Methods: We searched publicly available TCM guidelines and textbooks for expert knowledge and validated these sources using ten-fold cross-validation. Based on the BERT and CNN models, with the classification constraints from TCM holistic syndrome differentiation, the TCM-BERT-CNN model was constructed, which completes the end-to-end TCM holistic syndrome text classification task through symptom input and syndrome output. We assessed the performance of the model using precision, recall, and F1 scores as evaluation metrics.Results: The TCM-BERT-CNN model had a higher precision (0.926), recall (0.9238), and F1 score (0.9247) than the BERT, TextCNN, LSTM RNN, and LSTM ATTENTION models and achieved superior results in model performance and predictive classification of most TCM syndromes. Symptom feature visualization demonstrated that the TCM-BERT-CNN model can effectively identify the correlation and characteristics of symptoms in different syndromes with a strong correlation, which conforms to the diagnostic characteristics of TCM syndromes.Conclusions: The TCM-BERT-CNN model proposed in this study is in accordance with the TCM diagnostic characteristics of holistic syndrome differentiation and can effectively complete diagnostic prediction tasks for various TCM syndromes. The results of this study provide new insights into the development of deep learning models for holistic syndrome differentiation in TCM."
한시 텍스트마이닝 기법의 적용과 한계,2024,"['한시', '텍스트마이닝', '분류', '군집(clustering)', '엔그램', '(n-gram) 버트(BERT)', 'Classical Chinese Poetry', 'Text Mining', 'Classification', 'Clustering', 'n-gram', 'BERT']","이 논문은 漢詩를 대상으로 텍스트 마이닝 기법의 적용 방법을 고찰하고 그 한계를 검토한 연구이다. 특히, 본 연구에서는 n-gram과 BERT 모델을 중심으로 한 텍스트 마이닝 기법을 비교 분석하였다. n-gram 기법은 단어 간의 연관성을 바탕으로 문서의 특징을 파악할 수 있다. 그러나 이 기법은 단어 내면의 문맥을 충분히 반영하지 못한다는 단점이 있어, 텍스트의 심층적 해석에 있어 제한적일 수 있다.반면, BERT 모델은 텍스트의 모든 단어를 양방향으로 분석하여 문맥을 고려한 의미 해석을 가능하게 하는 자연어 처리 모델이다. 단순히 단어의 빈도를 기반으로 하는 것이 아니라, 단어의 위치와 주변 단어들과의 관계를 통해 더 정교한 의미 분석을 수행할 수 있다.본 연구는 이러한 두 가지 텍스트 마이닝 기법을 한시 텍스트 분석에 적용하여 그 효용성과 한계를 검토하였다. 연구 결과, n-gram과 BERT 모델은 각기 다른 특성과 성능을 보이며, 한시와 같은 전통 문학 텍스트의 분석에 있어 상호 보완적인 접근이 필요함을 확인하였다. n-gram 분석은 간단한 패턴 인식과 텍스트의 전반적인 구조 파악에 유용하며, BERT 모델은 더 깊이 있는 문맥 분석과 의미 해석에 강점이 있다.본 연구는 n-gram 분석의 사례를 통하여 한시 텍스트에서 자주 나타나는 공통적인 단어와 어구를 분석하고, 이를 바탕으로 한 온톨로지 구축만이 그 시인의 문학적 경향성과 작품의 주제 의식을 더욱 명확히 파악하여 한시의 문학적 가치를 심층적으로 조명할 수 있음을 밝혔다.또한 BERT 모델을 활용한 김창협 한시의 코사인 유사도 분석은 기계적 분석이 유용하며 가능성이 있음을 보여주었다. 다만 현재 기술의 한계상 연구자 누구나 접근한 도구가 개발된 것도 아니고 원하는 수준이라고 보기 어려운 부분도 존재한다. 한문학 연구자의 눈에 누구나 찾을 수 있는 결과라고 볼 수 있다. 하지만 순전히 기계학습의 결과이며 수십만 수의 漢詩에 적용하면, 유용한 결과를 얻을 것이다. 하지만 대량의 자원과 기술적인 완성도가 필요한 문제가 남아있다.본 논문은 텍스트 마이닝 기법을 활용하여 한시의 문학적 의미와 구조에 쉽게 접근할 수 있는 새로운 연구 방법론의 가능성을 제시하고자 하였다. 본 연구 결과의 기초 위에 다양한 텍스트 분석 모델의 적용과 그 결과에 대한 비교가 이루어진다면, 이를 통해 더욱 정교한 문학적 해석이 가능해질 것이다.","This study explores the application of text mining techniques to classical Chinese poetry (漢詩) and assesses their limitations. The research specifically compares and analyzes the strengths and weaknesses of text mining methods based on n-gram and BERT models.This study applies both text mining techniques to the analysis of classical Chinese poetry to evaluate their utility and limitations. The results highlight distinct characteristics and performances of the n-gram and BERT models, emphasizing the need for a complementary approach when analyzing traditional literary texts. While n-gram analysis is effective for identifying simple patterns and understanding the overall structure of the text, the BERT model excels in deeper contextual analysis and semantic interpretation.Through n-gram analysis, this research demonstrates the potential to gain a clearer understanding of a poet’s literary tendencies and thematic intentions by analyzing frequently occurring words and phrases in classical Chinese poetry. Additionally, the construction of ontologies based on these analyses can offer deeper insights into the literary value of the texts.Furthermore, cosine similarity analysis of Kim Chang-hyeop's classical Chinese poetry using the BERT model shows that machine-driven analysis holds promise. However, due to current technological limitations, the tools accessible to researchers are still in their developmental stages and not yet fully optimized. While the results may be readily interpretable by scholars of classical literature, large-scale machine learning applications in classical Chinese poetry require significant computational resources and further technical refinement.This paper proposes a new research methodology for accessing the literary meaning and structure of classical Chinese poetry through text mining techniques. The study suggests that further application and comparison of various text analysis models could lead to more refined and sophisticated literary interpretations."
Let’s Make an Artificial Learner to Analyze Learners’ Language!,2024,"['Bidirectional Encoder Representations from Transformers (BERT)', 'fine-tuning', 'the International Corpus Network of Asian Learners of English (ICNALE)', 'English prepositions', 'collocation analysis', 'principal component analysis']",,"This study aims to employ Artificial Intelligence (AI) to make an artificial learner for the efficient analysis of English learners’ use of prepositions. For this purpose, BERT (Bidirectional Encoder Representations from Transformers) was fine-tuned on the ICNALE (International Corpus Network of Asian Learners of English) and the way the fine-tuned BERT uses four English prepositions (at, for, in, on) was analyzed. Specifically, this study investigated whether there is a difference between the fine-tuned BERT and native English speakers in the use of the four prepositions. The results showed no significant difference. To validate these results, collocation analysis (CA) and principal component analysis (PCA) were conducted. Both the validation methods demonstrated similar findings. The similarity in results among the fine-tuned BERT, CA, and PCA suggests that the results from the fine-tuned BERT are reliable and confirms that the fine-tuned BERT can function as an artificial English learner. This study discusses the pedagogical implications of AI on learners’ language research. The new analysis method using BERT is expected to find wide-ranging applications in exploring various aspects of learners’ language."
자연어 처리(Transformer) 모델을 활용한 Smali 코드 학습 기반 안드로이드 악성코드 탐지 기법,2024,"['Android', 'APK', 'Smali', 'Transformer', 'BERT', 'roBERTa', 'BART']",,"Studies on Android malware detection by using machine learning have been varied, utilizing network traffic, memory dumps, and other data necessary for model training. In this paper, we propose a model to determine malware presence by training three Transformer models-BERT, RoBERTa, and BART-using Smali code obtained from APK files. We decompiled 1,318 malware-infected files and 1,236 benign files provided by CIC-AndMal-2020. The decompiled files were very large and contained unnecessary code for training, requiring a preprocessing step to remove it. Training and evaluation results showed that RoBERTa achieved the highest evaluation accuracy. However, BERT exhibited higher training performance, and in prediction results for 451 benign and 597 malware files, BERT slightly outperformed RoBERTa. BART generally showed lower performance compared to BERT and RoBERTa. The differences in training, evaluation, and prediction results between BERT and RoBERTa seem to be due to the lack of diversity in the dataset and the absence of sophisticated preprocessing. Nevertheless, this experiment confirms that BERT and RoBERTa can both achieve significant performance in the field of malware detection. In future work, the proposed model is expected to achieve even better performance by improving the preprocessing steps."
상대적 위치 임베딩을 적용한 DeBERTa 기반 물류 안전사고 인과관계 분류,2024,"['인과관계 분류', '상대적 위치 임베딩', '물류 안전 관리', '자연어처리', 'Logistics Safety Management', 'Natural Language Processing', 'Causal Relationship Classification', 'Relative Position Embedding', 'DeBERTa']","최근 물류 산업의 급속한 성장에 따라 안전사고 발생 빈도가 증가하고 있으며, 이를 예방하기 위한 AI 기반 인과관계 분석의 중요성이 대두되고 있다. 하지만 물류 안전사고 사례의 상당수는 단일이 아닌 복수의 인과관계를 포함하고 있어, 기존의 BERT(bidirectional encoder representations from transformers) 계열 모델이 사용하는 절대적 위치 임베딩만으로는 이러한 복잡한 문맥을 정확히 이해하는 데 한계가 있다. 이러한 문제를 해결하고자 본 연구에서는 상대적 위치 임베딩과 절대적 위치 임베딩을 모두 고려하는 DeBERTa(decoding-enhanced BERT with disentangled attention) 모델 기반의 인과관계 분류 방법을 제안하며, 이 방법은 물류 안전사고 문장 내 복수의 인과관계를 더 정확하게 분류할 수 있다. 제안된 방법의 유효성을 검증하기 위해 BERT, ELECTRA(efficiently learning an encoder that classifies token replacements accurately) 모델과 DeBERTa의 인과관계 분류 정확도와 F1-score를 비교 분석하였다. 그 결과, 상대적 위치 임베딩이 복수의 인과를 포함하는 문장 내 인과관계 분류정확도 향상에 기여함을 확인하였다.","The rapid growth of the logistics industry has led to an increase in the frequency of safety incidents, highlighting the importance of AI-based causal relationship analysis for prevention. Many logistics safety incident cases involve multiple causal relationships rather than a single one, which poses challenges for existing BERT(bidirectional encoder representations from transformers)-based models that rely solely on absolute position embeddings to accurately understand such complex contexts. To address this issue, this study proposes a causal relationship classification method based on the DeBERTa(decoding-enhanced BERT with disentangled attention) model, which considers both relative and absolute position embeddings. This approach enables more accurate classification of multiple causal relationships within logistics safety incident sentences. To validate the effectiveness of the proposed method, we compared the classification accuracy and F1-score of BERT, ELECTRAefficiently learning an encoder that classifies token replacements accurately), and DeBERTa models. The results confirm that relative position embeddings contribute to improving the accuracy of causal relationship classification in sentences containing multiple causal links."
사전학습모델 기반 소비자심리보조지수(S-CCSI) 개발,2024,"['KB-BERT', 'deep learning', 'CCSI', 'GDP economic growth rate', 'DNN', '.']","경기판단을 위해 실물지표와 더불어 소비자심리지수를 비롯한 심리지표가 도구로 활용되고 있다. 경기판단을 위해 실물지표와 소비자심리지수와 같은 심리지표가 주로 활용된다. 그러나 심리지표는 설문조사 방식을 통해 작성되어 커버리지, 이용 가능 시점, 시간적·경제적 비용에 대한 한계점이 존재한다. 이러한 한계점을 보완하기 위해 본 논문은 KB-BERT 임베딩과 DNN을 활용하여 소비자심리지수를 보조할 수 있는 소비자심리보조지수를 개발한다. 소비자심리보조지수는 현행 심리지표와의 비교 분석과 GDP 경제성장률 예측력 비교를 통해 보조지수로서의 유용성을 검증하였다. 검증 결과 소비자심리보조지수는 기업경기실사지수, 경제심리지수에 약 1~2개월 선행하며, 두 지수와 높은 상관관계가 나타났다. 또한, 소비자심리보조지수를 활용하였을 때 GDP 경제성장률 예측 성능이 전반적으로 높게 나타나는 것 확인했다. 이는 소비자심리보조지수 신뢰할 수 있는 지수이며, 경제 예측에 활용될 수 있음을 시사한다.","In economic assessment, sentiment indices such as the Composite Consumer Sentiment Index(CCSI), along with real economic indicators, are utilized as tools. However, sentiment indices, being based on survey methods, have limitations in terms of coverage, availability timing, and temporal and economic costs. To complement these limitations, this paper develops the Supplementary Composite Consumer Sentiment Index(S-CCSI) using KB-BERT embeddings and DNN. The utility of the S-CCSI as a supplementary index is verified through comparative analysis with sentiment indices and comparison of GDP economic growth rate forecasting capabilities. The results show that the S-CCSI leads the BSI and ESI by approximately 1-2 months, and exhibits a high correlation with these indices. Furthermore, when utilizing the S-CCSI, it was confirmed that the performance of GDP economic growth rate forecasting is generally higher. This suggests that the S-CCSI is a reliable index and can be utilized for economic forecasting."
자산가격변화와 비정보기반투자자의 심리에 대한 선도-지연 관계 분석,2024,"['Uninformed Investor', 'BERT', 'Sentiment', 'Lead-Lag', 'VAR', '비정보기반투자자', '감성지수', '선도-지연', 'BERT', 'VAR', 'Jensen’s Alpha']","본 연구의 목적은 비정보기반투자자의 심리를 BERT 모형을 통해 계량화함으로써 투자자의 “심리”가 자산가격변화에 대해 예측력을 갖는지 선도-지연 관계에 대한 실증분석을 통해 살펴보는 것이다. 2018년 1월 1일부터 2020년 12월 31일까지의 시가총액 기준 상위 20개 개별종목의 일간 수익률, 국고채 3년물 금리, 그리고 각 개별종목에 대한 게시판 댓글들로 산출한 감성지수를 사용하여 감성지수와 위험조정수익률 간의 상관성을 확인하고자 우선 단순선형회귀분석을 진행하였다. 단순선형회귀분석 결과 감성지수와 위험조정수익률 사이에 통계적으로 유의한 관계가 있음을 확인하였다. 이 결과를 토대로 위험조정수익률과 감성지수의 선도-지연 관계를 분석하기 위해 VAR 분석, 그랜저 인과 분석, 충격반응분석 그리고 예측오차분산분해를 진행하였다. 분석 결과, 감성지수는 위험조정수익률에 선도하는 관계를 갖지 않고, 오히려 위험조정수익률의 감성지수에 대한 예측력이 통계적으로 유의미함을 확인하였다. 해당 분석 결과의 강건성을 확인하고자 Fama-French 3 Factor 모형과 자본자산가격결정 모형에서 도출한 회귀계수를 바탕으로 젠센의 알파를 유도하여 젠센의 알파와 감성지수 간의 선도-지연 관계를 살펴보기 위해 감성지수에 각각 -1, 0, +1 시차를 두고 회귀분석을 진행함으로써 감성지수가 초과수익률에 지연된 관계가 존재한다는 것을 확인하였다. 결론적으로, 비정보기반투자자투자자 심리의 과거 정보가 현재의 자산가격변화를 설명하지 못하고, 오히려 비정보기반투자자들의 현재 심리가 자산가격변화의 과거 정보에 의해 설명되고 있음을 발견하였다.","The purpose of this study is to examine whether the investor’s sentiment has an predictive and explanatory power for asset price changes through an empirical analysis of the lead-lag relationship between uninformed investor’s sentiment and risk-adjusted returns. VAR model, Granger causality analysis, Impulse response analysis, and forecast error variance decomposition were conducted to analyze the lead-lag relationship between risk-adjusted returns and sentiment index. As a result of the analysis, it was confirmed that the sentiment index did not have a leading relationship with the risk-adjusted return rate, but that there was a statistically significant relationship in the delayed lag. In conclusion, it was found that the past information on investor sentiment of uninformed investors does not predict current change of asset price, but rather, the current sentiment of uninformed investors is predicted by lagged information on the change of asset price."
Chinese Long-Text Classification Strategy Based on Fusion Features,2024,"['Attention Mechanism', 'BERT Model', 'Fused Features', 'Neural Network']",,"In the process of Chinese long-text classification, due to the large amount of text data and complex features,methods suitable for ordinary text classification often lack sufficient accuracy, which directly leads to frequentclassification failures in long-text environments. To solve this problem, the research designed a bi-directionallong short-term memory (Bi-LSTM) model that combines forward and backward operations and utilizedattention mechanisms to improve fusion. At the same time, the bi-directional encoder representations fromtransformers (BERT) model was introduced into the text processing to form a long-text classification model.Finally, different datasets were tested to verify the actual classification effect of the model. The research resultsshowed that under different dataset environments, the classification accuracy rates of the designed models were92.93% and 93.77%, respectively, which are the models with the highest classification accuracy rates amongthe same type of models. The calculation time was 85.42 seconds and 117.51 seconds, respectively, which arethe models with the shortest calculation time among the same type of models. It can be seen that the researchdesigned long-text classification model innovatively combined the BERT model, convolutional neural networkmodel, Bi-LSTM model, and attention mechanism structure based on the data characteristics of long-textclassification, enabling the model to achieve higher classification accuracy in a shorter computational time.Moreover, it has better classification results in actual long-text classification, overcomes the classificationfailure problem caused by complex text features in the long-text classification environment, and provides apossibility for long-text specific classification paths."
KoBERT 기반 비속어 검출 모델 및 FAST API 서버 구현,2024,"['비속어 분류', 'koBERT', 'LMM', '분류 시스템', 'CoT', 'Chain of Thought', 'Classification System', 'Korean BERT', 'Large Multimodal Model', 'Profanity Classification']","본 논문에서는 한국어 BERT(KoBERT)를 전이 학습하여 비속어가 포함된 문장과 그렇지 않은 문장을 구별하는 모델을 구축하고, 이를 Python의 FAST API를 이용하여 웹 서비스 형태로 구현한 연구 결과를 제시한다. 데이터 셋은 다양한 온라인 커뮤니티와 소셜 미디어에서 수집한 문장을 활용하였으며, 전처리 과정을 거쳐 비속어 여부로 라벨링 하였다. KoBERT를 기반으로 한 분류 모델을 구축하고, 전이 학습 기법을 통해 높은 정확도의 비속어 검출 성능을 달성하였다. 또한, FAST API를 이용하여 클라이언트로부터 POST 요청을 받아 텍스트 데이터를 처리하고, 비속어 여부를 반환하는 웹 서비스를 구현하였다. 본 연구는 KoBERT를 활용한 비속어 검출의 가능성을 확인하고, 실용적인 웹 서비스 구현을 통해 실제 적용 가능성을 제시하였다. 향후 연구로는 더 다양한 데이터 셋을 활용한 모델 성능 개선과 실시간 비속어 필터링 시스템 구현을 목표로 한다.","This paper presents a study in which a model is built to distinguish between sentences containing profanity and those that do not, by applying transfer learning to KoBERT (Korean BERT). The model is implemented as a web service using Python’s FAST API. The dataset consists of sentences collected from various online communities and social media platforms, and after a preprocessing stage, the sentences were labeled based on the presence of profanity. A classification model was built using KoBERT, and by utilizing transfer learning techniques, high accuracy in profanity detection was achieved. Additionally, a web service was implemented using FAST API, which processes text data received through POST requests from clients and returns whether profanity is present or not. This study confirms the potential of using KoBERT for profanity detection and demonstrates the feasibility of practical application through the implementation of a web service. Future research will aim to improve model performance by utilizing more diverse datasets and to implement a real-time profanity filtering system."
트랜스포머 기반 모델을 이용한 연구논문 멀티레이블 주제영역 분류,2024,"['Research Paper', 'Classification', 'Multilabel', 'Transformer', 'BERT']",,"Purpose  To develop MLP and transformer-based models for the multi-label topic classification of research papers using abstract text.Methods  Abstracts from 119,600 papers in the Computer Science category of arXiv were collected to create a multi-label dataset with up to three categories out of a total of 15 possible categories. Performance was evaluated by developing a baseline MLP model along with transformer-based models: BERT, RoBERTa, and DistillBERT.Results  The transformer models outperformed the traditional MLP model. The DistillBERT model achieved the highest micro F1-score of 0.749, while the BERT model recorded macro and weighted F1-scores of 0.655 and 0.733, respectively. The RoBERTa model excelled in the samples method with a score of 0.772.Conclusion  This study enables researchers to quickly explore recent findings and effectively identify their research topics. Additionally, it is expected to significantly contribute to the efficient sharing of academic knowledge and the revitalization of the research community."
비격식의 소규모 다범주 민원 자동분류 알고리즘 성능 비교 연구,2024,"['Automatic Classification', 'Small-Scale Informal Text', 'CNN', 'LSTM', 'Ko-BERT', 'Civil Complaint Data', '자동 분류', '소규모 비격식 텍스트', '민원']","머신러닝 기술의 발전으로 텍스트 자동 분류에 대한 연구가 증가하고 있다. 텍스트 자동 분류는 사전에 정의된 범주의 레이블을 각 데이터에 부여함으로써 대량의 데이터를 효율적으로 할당하는 것이다. 지금까지의 분류 연구는 자질 선정이 용이한 뉴스나 학술 데이터 및 SNS 데이터 등으로 대규모 데이터를 대상으로 많이 이루어졌다. 이와 달리 민원처럼 소규모의 비격식(informal) 텍스트를 대상으로, 다양한 주제 범위의 데이터를 다시 의미, 유형, 형식 등 세부 범주별로 분류하기는 어려운 일이다. 이에 본 연구의 목적은 소규모의 비격식 텍스트로 구성된 다범주 자동 분류에서 가장 성능이 좋은 알고리즘을 찾아내는 것이다. 이를 위해 먼저 2016년부터 2020년까지 부산시 민원 데이터를 수집하여 데이터 전처리를 실시하였다. 이후 민원의 특성 범주의 레이블을 정의하였고, 마지막으로 지도학습으로 각 분류 알고리즘의 성능을 비교 분석하였다. 실험결과 분류의 정확도는 CNN < LSTM < Ko-BERT의 순서로 나타났다. 따라서 비격식어이며 소규모인 다양한 주제에 대해 유형 및 특성별로 복합적 다범주 분류에서는 문서의 자질(feature)을 추출하는 것이 아니고, 시퀀스와 컨텍스트를 고려하여야함을 밝혀냈다. 본 연구의 학문적 공헌도로는 전통적인 분류기부터 딥러닝의 최신 알고리즘을 같은 실험 환경에서 비교 분석하여 알고리즘 간의 차이를 규명하였다는 점이다. 실무적으로는 본 연구에서 비격식(informal) 문서인 민원에 대한 분류기 성능 평가 결과는 향후 소규모의 SNS 데이터 및 다른 민원 등 다양한 주제이며 복잡한 범주에 대한 낮은 품질의 텍스트 데이터의 처리 및 분류에 활용될 수 있을 것이다.","Research Purpose: The purpose of this study is to identify the most effective algorithm for automatic multi-category classification of small-scale informal textResearch Methods: To achieve this, data preprocessing was conducted on municipal complaint data from 2016 to 2020 in Busan. Subsequently, labels for the characteristic categories of complaints were defined, followed by a comparative analysis of the performance of each classification algorithm using supervised learning.Results in Research: The experimental results showed that the classification accuracy followed the order of CNN < LSTM < Ko-BERT. Thus, it was revealed that for multi-category classification of diverse topics in informal and small-scale text, it is essential to consider sequences and contexts rather than extracting document features.Research Conclusion: The academic contribution of this study lies in comparing and analyzing algorithms from traditional classifiers to the latest deep learning algorithms under the same experimental conditions, thereby elucidating the differences between algorithms. From a practical standpoint, the evaluation of classification performance for informal documents such as complaints in this study could be utilized for processing and classifying low-quality text data of various topics, including small-scale SNS data and other complaints with complex categories, in the future."
"심층 주제, 지역, 장르를 모두 분류할 수 있는 다면적 뉴스 기사 자동 분류 모델 연구",2024,"['BERT Model', 'News Article Classification', 'Hierarchical Classification Model', 'Multi-Class Classification Model', 'Multidimensional classification', 'BERT 모델', '뉴스 기사 분류', '계층적 분류 모델', '다중 클래스 분류 모델', '다차원 분류']","본 연구는 한국어 사전학습 모델을 활용하여 뉴스 기사를 주제, 장르, 지역별로 각각 분류하는 모델을 구축하였다. 이를 위해 국내 언론사의 분류체계를 참고하여 새로운 뉴스 기사 분류체계를 설계하였다. 주제 및 장르 분류 모델은 대분류와 중분류 모델을 연결한 계층적 구조의 분류 모델로 구현하여 카테고리 통합 모델의 성능과 비교하였다. 평가 결과, 계층적 구조의 분류 모델은 모호하거나 중복된 카테고리에서 카테고리 통합 모델보다 더 명확한 분류를 수행할 수 있다는 이점이 있었다. 뉴스 기사의 지역적 분류를 위해서는 18개의 카테고리에 대하여 분류를 수행하는 모델을 구축하였으며 지역 관련 뉴스 기사의 경우, 지역적 특성이 본문에 명확히 드러나 높은 성능을 기록할 수 있었다. 본 연구는 주제, 장르, 지역의 다각적인 측면에서 뉴스 기사를 효과적으로 분류할 수 있음을 보여주었으며, 이를 통해 사용자 요구에 부합하는 다차원적 뉴스 기사 분류 서비스의 가능성을 제시한 점에서 의의가 있다.","This study developed a model to classify news articles into categories of topic, genre, and region using a Korean Pre-trained Language model. To achieve this, a new news article classification system was designed by referring to the classification systems of domestic media outlets. The topic and genre classification models were implemented as hierarchical classification models that link the main categories and subcategories, and their performance was compared with that of an integrated category model. The evaluation results showed that the hierarchical structure classification model had the advantage of providing more precise categorization in ambiguous or overlapping categories compared to the integrated category model. For regional classification of news articles, a model was built to classify into 18 categories, and for regional news articles, the regional characteristics were clearly reflected in the text, resulting in high performance. This study demonstrated the effectiveness of classifying news articles from multiple perspectives—topic, genre, and region—and emphasized the significance of suggesting the potential for a multi-dimensional news article classification service that meets user needs."
CORRECT? CORECT!: Classification of ESG Ratings with Earnings Call Transcript,2024,"['BERT', 'Earnings Call Transcript', 'ESG', 'Machine learning', 'Natural language processing (NLP)']",,"While the incorporating ESG indicator is recognized as crucial for sustainability and increased firm value, inconsistent disclosure of ESG data and vague assessment standards have been key challenges. To address these issues, this study proposes an ambiguous text-based automated ESG rating strategy. Earnings Call Transcript data were classified as E, S, or G using the Refinitiv-Sustainable Leadership Monitor's over 450 metrics. The study employed advanced natural language processing techniques such as BERT, RoBERTa, ALBERT, FinBERT, and ELECTRA models to precisely classify ESG documents. In addition, the authors computed the average predicted probabilities for each label, providing a means to identify the relative significance of different ESG factors. The results of experiments demonstrated the capability of the proposed methodology in enhancing ESG assessment criteria established by various rating agencies and highlighted that companies primarily focus on governance factors. In other words, companies were making efforts to strengthen their governance framework. In conclusion, this framework enables sustainable and responsible business by providing insight into the ESG information contained in Earnings Call Transcript data."
데이터 전처리를 간소화한 자연어처리 기반의 악성코드 탐지모델,2024,"['preprocessing', 'transformer', 'BERT', 'DistillBERT', 'BART', 'natural language processing', 'CIC-MalMem-2022']",,"In order to train a machine learning or deep learning model to detect malware, it is essential to preprocess the data before training the model. And when new malware appears, the preprocessing process must be updated and applied to the model again. To solve these inefficiencies, this paper proposes a malware detection model based on natural language processing. After merging 55 attributes of the CIC-MalMem-2022 dataset into a single sentence separated by spaces, we trained the Transformer model, BERT, DistilBERT, and BART, and analyzed the classification performance. As a result, the detection performance of binary classification was similar to that of previous studies, and the accuracy of multi classification was 84.69%, 85.10%, and 84.44%, confirming that it can achieve excellent performance with a simple preprocessing process."
생성형 AI 연대기적 고찰,2024,"['생성형 AI', 'NLP', 'LSTM', '딥러닝', 'GAN', 'BERT', 'ChatGPT', 'Generative AI', 'NLP', 'LSTM', 'Deep learning', 'GAN', 'BERT', 'ChatGPT']","이 논문에서는 생성형 인공지능(AI)의 시작부터 현재까지의 발전 과정을 포괄적이고 연대기적으로 설명한다. 주된 요소와 핵심 기술을 자세히 살펴봄으로써 신경망 설계, 언어 모델 개발, 이미지 생성 기술에서 중요한 이정표를 발견하는 등 생성형 AI 기술의 진화를 추적한다. 1950년대의 기초 이론부터 2010년대 생성적 적대 신경망(GAN)과 트랜스포머 모델과 같은 획기적인 혁신에 이르기까지, 단순한 패턴 인식부터 복잡한 자연어 처리 등 AI 기능의 기하급수적인 성장과 그 응용 범위의 확장에 대해 살펴보았다. 방법론적으로는 선행연구와 생성형 AI의 근간을 형성한 주요 기술 혁신을 연대기적으로 분석하는 방식을 사용했다. 다양한 산업에 대한 AI의 영향, 윤리적 고려 사항 및 미래의 기술적 잠재력에 초점을 두고 분석되었다. 그 결과, 생성형 AI는 계산 효율성과 창의성을 크게 향상시켰지만 윤리적 딜레마와 막대한 계산 자원의 필요성과 같은 과제도 제기하고 있음을 보여주었다. 결론에서는 생성형 AI의 미래에 대해 논의하고 강력한 윤리적 기준과 균형을 이루는 지속적인 혁신이 필요하다는 점을 시사한다. 이 연구는 역사적 궤적뿐만 아니라 정책 입안자, 개발자, 학계가 생성형 AI의 잠재적 발전가능성을 극대화하면서 위험을 완화할 수 있는 방법을 모색하도록 촉구한다는 점에서 중요한 의미를 갖는다.","This paper provides a comprehensive and chronological account of the development of generative Artificial Intelligence (AI) from its inception to the present day. Through a detailed examination of key advances and key technologies, it traces the evolution of generative AI technology, uncovering important milestones in neural network design, language model development, and image generation techniques. Beginning with foundational theories in the 1950s and ending with breakthrough innovations such as Generative Adversarial Neural Networks (GANs) and transformer models in the 2010s, it examines the exponential growth of AI capabilities and the expansion of its range of applications, from simple pattern recognition to complex natural language processing and beyond. Methodologically, it uses a chronological analysis with a matching of seminal papers and major technological innovations that have shaped the landscape of generative AI. The implications of these developments are critically analyzed, focusing on the impact of AI on different industries, ethical considerations, and future technological potential. The results show that generative AI has greatly improved computational efficiency and creativity but also poses challenges, such as ethical dilemmas and the need for enormous computational resources. The conclusion discusses the future of generative AI and suggests that it will require continued innovation balanced with strong ethical standards. This study is significant not only for its historical trajectory but also for its call to action for policymakers, developers, and academics to find ways to mitigate the risks while converging on the benefits of generative AI."
KcBERT를 활용한 한국어 음성인식 텍스트 정확도 향상 연구,2024,"['자동 음성 인식', '한국어 음성 처리', 'Speech-to-Text', 'BERT', 'automatic speech recognition', 'korean speech processing', 'Speech-to-Text', 'BERT']","음성 인식 분야에서는 Whisper, Wav2Vec2.0, Google STT와 같은 모델이 널리 사용되고 있다. 그러나 한국어 음성 인식은 복잡한 음운 규칙과 다양한 발음 변이로 인해 성능 향상에 어려움을 겪는다. 이러한 문제를 해결하기 위해 Whisper 모델과 KcBERT 후처리 방식을 결합한 방법을 제안한다. Whisper 모델이 생성한 텍스트에 대해 KcBERT의 양방향 문맥 학습을 적용하여 문맥적 일관성을 높이고, 보다 자연스러운 텍스트로 교정하기 위해 결합하였다. 실험 결과, 후처리를 통해 Clean 환경에서 CER이 5.12%에서 1.88%로, Noise 환경에서 22.65%에서 10.17%로 감소하였다. 또한, WER은 Clean 환경에서 13.29%에서 2.71%, Noise 환경에서 38.98%에서 11.15%로 크게 개선되었다. BERTScore 역시 향상되었으며, 한국어 음성 인식에서의 복잡한 음운 규칙 교정과 텍스트 일관성 유지에 효과적임을 입증하였다.","In the field of speech recognition, models such as Whisper, Wav2Vec2.0, and Google STT are widely utilized. However, Korean speech recognition faces challenges because complex phonological rules and diverse pronunciation variations hinder performance improvements. To address these issues, this study proposed a method that combined the Whisper model with a post-processing approach using KcBERT. By applying KcBERT’s bidirectional contextual learning to text generated by the Whisper model, the proposed method could enhance contextual coherence and refine the text for greater naturalness. Experimental results showed that post-processing reduced the Character Error Rate (CER) from 5.12% to 1.88% in clean environments and from 22.65% to 10.17% in noisy environments. Furthermore, the Word Error Rate (WER) was significantly improved, decreasing from 13.29% to 2.71% in clean settings and from 38.98% to 11.15% in noisy settings. BERTScore also exhibited overall improvement. These results demonstrate that the proposed approach is effective in addressing complex phonological rules and maintaining text coherence within Korean speech recognition."
ESG 보고서의 텍스트 분석을 이용한 ESG 활동 탐색 -중국 상장 제조 기업을 대상으로-,2024,"['ESG Report', 'ESG Keywords-Library', 'Dynamic Capabilities', 'TensorFlow-BERT', 'TF-IDF', 'Cosine Similarity. Social Network Analysis', 'ESG 보고서', 'ESG 키워드 사전', '동적역량', '텐서플로우-버트', 'TF-IDF', '코사인 유사도', '소셜네트워크분석']","본 연구는 글로벌 경제시장에서 중국의 제조기업들이 동적역량을 기반으로 어떠한 ESG활동을 수행하고 있으며 그활동에는 어떠한 차이가 있는가를 분석하였다. 상하이와 선전 증권 거래소 (Shanghai & Shenzhen Stock Exchange)에서 151개 중국상장 제조 기업들의 ESG 연례 보고서와 상하이 화정 지표 정보 회사(CSI, China Securities Index Company)의 ESG 지표를 데이터로 사용하였다. 연구 분석에는 TensorFlow-BERT 모델과 코사인 유사도를 사용하여 환경, 사회, 지배구조로 구분된 ESG 키워드를 분류하였고이를 기반으로 다음 세 가지의 연구질문을 구성하였다. 첫 번째는ESG 점수가 높은기업(TOP-25)과 낮은기업(BOT-25)을 구분하여 이기업들 사이의 ESG활동에는 어떠한 차이가 있는지를 확인하였으며, 두 번째는 ESG 점수가 높은 기업만을 중심으로 10년간(2010~2019년)의 ESG 활동에는 어떠한 변화가 있는지도 확인하였다. 그 결과ESG 점수가 높은기업과 낮은기업 간의 ESG 활동에는 유의한 차이를 보였으며, TOP-25기업의 연도 별 활동 변화 추적에서는 ESG 활동의 모든부분에서 차이를 보이지 않은 것으로 나타났다. 세 번째연구에서는 연도 별로 작성된 각 항목별 E, S, G 키워드에 대하여 소셜네트워크분석을 진행하였다.  동시발생행렬(Co-occurance matrix) 기법을 통해 기업들의 ESG활동을4사분면그래프로 시각화하였으며 이를 바탕으로 ESG활동에 대한 향후 방향을 제시하였다.","As interest in ESG has been increased, it is easy to find papers that empirically study that a company's ESG activities have a positive impact on the company's performance. However, research on what ESG activities companies should actually engage in is relatively lacking. Accordingly, this study systematically classifies ESG activities of companies and seeks to provide insight to companies seeking to plan new ESG activities.This study analyzes how Chinese manufacturing companies perform ESG activities based on their dynamic capabilities in the global economy and how they differ in their activities. This study used the ESG annual reports of 151 Chinese manufacturing listed companies on the Shanghai & Shenzhen Stock Exchange and ESG indicators of China Securities Index Company (CSI) as data. This study focused on the following three research questions.The first is to determine whether there are any differences in ESG activities between companies with high ESG scores (TOP-25) and companies with low ESG scores (BOT-25), and the second is to determine whether there are any changes in ESG activities over a 10-year period (2010-2019), focusing only on companies with high ESG scores. The results showed that there was a significant difference in ESG activities between high and low ESG scorers, while tracking the year-to-year change in activities of the top-25 companies did not show any difference in ESG activities. In the third study, social network analysis was conducted on the keywords of E/S/G. Through the co-concurrence matrix technique, we visualized the ESG activities of companies in a four-quadrant graph and set the direction for ESG activities based on this."
인공지능이 미래 고용에 미칠 영향 분석,2024,"['인공지능', '일자리', '연관규칙분석', '동적토픽분석', '자동화', '업무', '스킬', 'Artificial intelligence', 'jobs', 'association rules analysis', 'dynamic topic analysis', 'automation', 'tasks', 'skills']","본 연구의 목적은 인공지능(AI)이 일자리 시장에 미치는 영향을 분석하고자 하였다. 이를 위해 구글에서 2017년 1월 1일부터 2024년 8월 31일까지 수집된 22,259건의 고용 관련 뉴스 데이터를 활용하여 AI와 고용의 관계를 탐구하였다. 연구 방법으로는 텍스트 마이닝을 기반으로 한 빈도 분석, 동적 주제 분석, 연관규칙 분석을 결합하여 AI가 일자리에 미치는 영향 의 복잡한 경로를 식별하였다. 토픽 분석과 TF-IDF 분석을 통해 AI의 부정적 영향 ‘우려’, ‘직업 이동’, ‘도전’과 ‘긍정적 기 회’, ‘새로운 기회’, ‘잠재력’에 대한 논의를 확인하였다. 또한 동적 토픽 모델링을 활용하여 시간에 따른 주제의 변화를 추적 한 결과, 2019년까지는 주로 기업 내 기술 개발, 혁신, 기술 도구가 산업에 미치는 영향을 다루었고, 이후에는 자동화가 노동 시장에 미치는 영향과 근로자의 역할, 특히 기술 수요와 고용 기회의 변화를 조명하였다. 연관규칙 분석을 통해 AI가 일자리 경로에 미치는 영향을 신뢰도 지표를 기반으로 확인하였으며, 시장과 고용에 대한 복합적인 영향을 구체적으로 분석하였다.","This study aimed to analyze the impact of artificial intelligence (AI) on the job market comprehensively. Utilizing 22,259 employment-related news articles collected from January 1, 2017, to August 31, 2024, we investigate the relationship between AI and employment. Our research methodology integrated text mining techniques, including frequency and dynamic topic analysis, along with association rule analysis, to identify the complex pathways through which AI influences job markets. Topic analysis and TF-IDF analysis highlighted discussions surrounding the negative impacts of AI, such as “concerns,” “job displacement,” and “challenges,” as well as the positive opportunities it presents, including “new opportunities” and “potential.” Dynamic topic modeling enabled us to trace the evolution of these themes over time, initially focusing on the influence of technological development and innovation within companies until 2019. Subsequently, the study illuminated the effects of automation on the labor market and examined the evolving roles of workers, particularly in response to changing demands for technology and shifts in employment opportunities. Through association rule analysis, we confirmed the significant impact of AI on job pathways based on reliability indicators and meticulously analyzed AI’s multifaceted effects on the market and employment."
챗봇 대화내용에 맞는 이미지 매칭을 위한 LLM기반 다중 감정 분류 기법 연구,2024,"['Chatbot', 'Deeplearning', 'Multi-emotion classification', 'LLM', 'Generative AI']",본 논문은 LLM 기반 챗봇 대화 중 사용자의 감정에 맞춰 적절한 이미지를 제시하기 위해 기존의 7가지 기본 감정 정보를 28개로 세분화하여 사용자 친화적인 챗봇  구현을 목표로 하였다. 구현을 위해 BERT 인공지능 알고리즘의 지식 증류(knowledge distillation) 모델    중에 하나인 DistilBERT 모델을 감정 분석 데이터에 맞춰   미세조정(fine-tunning)하였다. 스테이블디퓨전 (Stable Diffusion)으로 생성된 이미지를 이용하여 표현이 자연스러운 챗봇 개발이 가능함을 알 수 있었다.,"This paper aims to implement a user-friendly chatbot by subdividing the seven basic emotion information into 28  emotions to present appropriate images according to the user’s emotions during LLM-based chatbot conversations. For the implementation, the DistilBERT model, one of the knowledge distillation models of the BERT artificial intelligence algorithm, was fine-tuned to the sentiment analysis data. We found that developing a chatbot with natural expressions was possible using images generated by Stable Diffusion."
Challenges in Syntax-semantic Integration for Language Models: A Case Study of Korean Control Dependencies,2024,"['subject control', 'object control', 'language model', 'honorific mismatches', 'dependency formation']",,"This study evaluates the ability of language models (LMs) to process subject-verb dependencies in Korean control constructions, involving a covert subject (PRO), using three models: KLUE-RoBERTa, KR-BERT, and KoELECTRA. We focused on LMs’ capacity to detect honorific mismatches and manage complex grammatical structures. Unlike previous findings in Indo-European languages, KLUE-RoBERTa and KR- BERT showed greater sensitivity to subject NPs, whereas KoELECTRA was more responsive to object NPs and better at detecting honorific mismatches. Additionally, increasing the distance between subject and object NPs generally improved model performance."
머신러닝 기반 색채적 특성 분석 및 감성 분류에 관한 연구,2024,"['머신러닝', '색채분석', '감성분류', 'Machine Learning', 'Color Analysis', 'Sentiment Classification']","본 연구는 머신러닝 알고리즘을 활용하여 관광지 이미지를 색채적 특성과 감성적 범주로 분류하는 방법론에 중점을 두었다. 디지털 미디어와 스마트폰을 통해 수집된 사용자 생성 콘텐츠, 특히 인스타그램에서 수집된 관광지 이미지 데이터를 분석하여 관광지의 첫인상과 이미지가 관광자의 감성에 미치는 영향을 연구하였다. 색채 및 텍스트 데이터를 각각 머신러닝 알고리즘과 BERT 언어 모델을 사용하여 분석하였으며, 이를 통해 관광지 이미지의 색채적 특성과 감성적 메시지를 해석하였다. 관광지 이미지의 색채 분석과 감성 분류를 통해 관광자의 선택과 감성에 미치는 영향을 파악하고, 두 요인을 단편적이 아닌 상호 연관하여 고려할 때 활용도가 크다는 것을 보여주었다. 특히, 색채적 특성은 관광지 이미지 개선을 통해 관광지를 보다 매력적으로 만들 수 있는 중요한 요소이다. 이를 통해 관광지 이미지가 관광자의 감성과 경험에 큰 영향을 미칠 수 있음을 밝히고, 관광산업에 대한 새로운 시각과 관광 경험 최적화를 위한 효과적인 방안을 제공한다. 또한, 데이터를 분석하고 이를 체계적으로 활용한다면 관광자가 선호하는 관광지이미지의 특성과 사용자의 성향을 반영한 맞춤형 제안을 할 수 있다. 본 연구는 관광지 이미지 분석을 통해 향후 관광지의 이미지 관리 및 마케팅 전략에 중요한 시사점을 제공할 수 있을 것으로 기대된다. 궁극적으로, 관광지 이미지의 색채적 특성 및 감성 분류를 통해 관광산업에 대한 이해를 심화시키고, 관광지의 이미지 관리 및 마케팅 전략을 강화하는 데 중요한 기여를 할 것이다.","This study focuses on developing a methodology for classifying tourist destination images based on their color characteristics and emotional categories using machine learning algorithms. By analyzing user-generated content collected through digital media and smartphones, particularly tourist destination images from Instagram, the research examines how the initial impressions and imagery of tourist destinations impact tourists' emotions. Color and text data were analyzed using machine learning algorithms and the BERT language model to interpret the color characteristics and emotional messages conveyed by these images. The research demonstrates that analyzing and classifying the color characteristics and emotions of tourist destination images significantly influence tourists' choices and emotions. It shows that considering these two factors in an interconnected manner, rather than in isolation, enhances their utility. Specifically, color characteristics are crucial elements that can improve the attractiveness of tourist destination images. This study reveals that these images can significantly affect tourists' emotions and experiences, offering new insights and effective strategies for optimizing the tourism experience. Moreover, by systematically analyzing and utilizing the data, it is possible to provide customized suggestions that reflect the preferred images of tourist destinations and user tendencies. This research provides critical insights into image management and marketing strategies for tourist destinations, helping to attract tourists' interest and create positive tourism experiences. Ultimately, the study aims to deepen the understanding of the tourism industry through the color characteristics and emotional classification of tourist destination images, making significant contributions to the enhancement of image management and marketing strategies for tourist destinations."
BERTopic과 색채분석 기반 감성 추출을 이용한 관광지 추천 시스템 개발,2024,"['머신러닝', '색채분석', '관광 추천시스템', 'Machine Learning', 'Color Analysis', 'Tourism Recommendation System']","본 연구는 관광지 이미지의 색채적 및 정서적 요인을 분석하여 맞춤형 관광지 추천 시스템을 개발을 목표로 하고 있다. 자연휴양지와 도시관광지의 이미지를 대상으로 각 이미지가 전달하는 정서적 반응과 색채 특성을 평가 및 분석하였다. 설문조사를 통해 사용자들의 관광지 이미지에 대한 감정적 반응을 수집하고, BERT 기반의 BERTopic 모델을 사용해 SNS의 텍스트 데이터를 분석하였다. 설문조사 결과는 사용자들이 특정 색채와 정서적 요인에 대해 어떻게 반응하는지를 명확히 파악하였다. 자연휴양지는 초록(G)계열이 가장 연상되는 색채이며, 그 다음으로 연두(GY)ㆍ파랑(B) 계열 순으로 확인되었다. 도시관광지의 경우 주황(YR)ㆍ노랑(Y)계열이 가장 먼저, 그 뒤로 청록(BG)ㆍ파랑(B) 계열 순으로 연상 결과가 나왔다. 또한 시스템 실행 시, Bhattacharyya 거리를 활용해 이미지 간의 색채 유사도를 측정하여 사용자의 정서에 맞는 관광지 이미지를 사용자에게 보여주었다. 그리하여 본 연구는 사용자의 정서적 요구를 반영할 수 있는 새로운 접근 방식을 제안하기 위해 관광지 이미지가 사용자의 감정에 미치는 영향을 고려한 추천 시스템을 개발하였다.","This study aims to develop a personalized tourist destination recommendation system by analyzing the color and emotional factors of destination images. It evaluated and analyzed the emotional responses and color characteristics conveyed by images of natural resorts and urban tourist sites. A survey was conducted to collect users' emotional responses to these images, and a BERTopic model based on BERT was used to analyze text data from social media. The survey results provided a clear understanding of how users react to specific colors and emotional factors. For natural resorts, Green(G) was the most associated color, followed by Green-Yellow(GY) and Blue(B). In the case of urban tourist sites, Yellow-Red(YR) and Yellow(Y) were most commonly associated, followed by Blue-Green(BG) and Blue(B). Additionally, during the system's execution, the Bhattacharyya distance was used to measure color similarity between images, displaying images that match the user's emotions. Therefore, this study developed a recommendation system that considers the impact of destination images on users' emotions, proposing a new approach to better reflect users' emotional needs."
A Study on a Deep Learning-Based Approach for Automated Scoring Solutions of Korean L1 Essays,2024,"['Automated essay scoring', 'Korean essay scoring', 'L1 learner writing', 'deep learning', 'artificial intelligence automatic grading', 'AI automatic grading']",,"The study utilized 401 data points categorized into upper, middle, and lower levels. Themodel development process included five stages: 1) data purification and preprocessing, 2)embedding, 3) data segmentation and shape conversion, 4) model training, and 5) modelperformance evaluation. The research employed BERT, a pre-trained model, to develop thegrading model. Performance evaluation of the trained model yielded an accuracy of 0.7377,precision of 0.6514, recall of 0.7377, and an F1 score of 0.6717. These results demonstrate arelatively high level of performance compared to previous studies on scoring Korean writtenand essay answers by L1 learners. As a result, the feasibility of developing an automaticscoring model using the BERT language model with small-scale data from a specific domain.Also, the model’s performance shows some generalizability, but further exploration isneeded for improvement. Limitations of the study include the use of writing samples gradedwithout considering grade levels, limited test data, difficulties in processing unregisteredtokens, and the inherent unexplainability of deep learning techniques. Further discussionsand considerations on how to more effectively utilize artificial intelligence in Koreanlanguage education should continue. Ongoing research on automatic grading is necessaryto provide accurate and detailed educational feedback to students. As automatic gradingresearch in the field of Korean language education advances, it is expected that high-qualityeducational interventions for students will become possible in the future."
세계 선샤워(Sunshower)의 언어 양상과 원형 고찰 ﻿-양가성과 공포를 중심으로-,2024,"['선샤워', '태양비', '여우비', '여우가 시집간다', '여우 시집가는 날', '호랑이비', '호랑이 장가간다', '호랑이 장가가는 날', '뉴뉴미디어', '관용어', '여우불', '공포', '기능', '양가성', '홀림', '홀리다', '리미럴스페이스', '기쓰네노 요메이리', 'sunshower', 'sunrain', 'foxrain', 'the fox is getting married', 'foxs wedding day', 'tigerrain', 'the tiger is getting married', 'tigers wedding day', 'new new media', 'idiom', 'foxfire', 'fear', 'function', 'ambivalence', 'holim', 'Liminal space', 'kitsune no yomiire']","여우비는 세계에서 공통적으로 발생하는 기상현상이다. 대부분의 문화권에서는 맑은 날에 내리는 비에 대한 용어를 가지고 있으며. 이 용어는 대부분 역설적 결합의 성향을 보이거나 동물의 결흔과 출산 등이 관련되어 있다. 우리나라에서 또한 ‘여우가 시집가는 날’, ‘호랑이가 장가가는 날’, ‘여우비’, ‘호랑이비’ 등이 있다. 세계의 용어에서도 이와 유사한 단어가 있다. 바로 선샤워(Sunshower)”이다. 선샤워(Sunshower)는 아르네 -톰슨의 색인에서도 발견된다. 이외에도 선샤워(Sunshower)에 대한 포괄적인 표현 목록을 작성하려는 시도가 있었다. Kussi와 Bert Vaux, Robert Blust는 세계적으로 동일한 기상현상을 상용하는 언 어가 있음을 밝히고, 세계적 분포 양상을 설명하는 동시에 문화의 발생과 전파의 양상을 설명하고자 했다.  또한 선샤워의 다양한 표현들의 관계성을 구명하려는 노력이 있었다. 특히 Blust는 여우의 결혼식과 여우비와의 관계성에 대해 집중하였고. 전세계적으로 발견되는 이중적 기후와 결혼과의 양상을 제시하고 지역적 분포를 통해 주로 문화의 발생과 전파를 논의했다. 세계 각국에서 발견되는 선샤워의 존재는 각국의 보편성과 특수성을 파악할 수 있는 귀중한 보고인 셈이다.  우리나라도 ‘호랑이비’와 ‘여우비’와 관련된 유래담을 가지고 있다. 특이할 만한 점은 현대에 이르러 유래담과 함께 관용어구의 변형이 이루어지고 있다는 것이다. 이러한 현상은 뉴뉴미디어 발달과 함께 변모한 전승의 양상을 파악할 수 있는 자료가 된다. 본고에서는 날씨를 형용하는 관용어구와 유래담을 함께 살펴 의미를 고찰하고, 뉴뉴미디어에서 수집되고 있는 2차 자료들을 추가 조사하여 현재의 전승 현황과 의미도 함께 다루고자 하였다. ‘선샤워’ 는 단순한 날씨 관용구이기 전에 인간에게 내재된 원형에 대한 증거가 될 수 있을 것이라 생각한다. 이를 구명하기 위해서는 관용어구의 기능(function)적 분석과 더불어 유래담을 통한 접근과 해석이 필요하다. 이러한 작업을 통해 우리는 선샤워의 원시적이면서 민속적 상징성을 응축한 ’원형‘을 탐색할 수 있을 것으로 본다.","﻿  Foxrain is a common weather phenomenon throughout the world. Most cultures have a term for rain on a sunny day, usually associated with paradoxical union tendencies or animal marriage and birth stories. In Korea, there arc also idioms such as The day the fox got marricd, The day the tiger got married, ‘foxrain,’ and ‘tigerrain.’  Many languages have similar expressions to describe the weather phenomenon ‘sunshower’. The word ‘sunshower’ can also be found in Ame Thompsons index. In addition, an attempt has been made to compile a comprehensive list of similar expressions for 4sunshower5. Kussi, Bert Vaux, Robert Blust showed that there are languages all over the world that express the same weather phenomena, and hoped to explain their distribution around the world, as well as the origin and spread of culture.﻿  In addition, efforts have been made to identify the relationships between different expressions of sunshower’, fox’s wedding’, and ‘foxrain’. Blusts research focuses on fox weddings and their relationship to foxes. He examines the dual factors of climate and marriage that are observed globally, and ﻿analyses how culture spreads primarily through regional distribution. These efforts provide insights into the similarities and differences of foxrain in different countries worldwide.  In Korea, there is an origin story associated with ‘tigerrain’ and foxrain’. What is unusual about this is that the idioms and the origin story have been evolving up to the present day, which helps us to understand how the transmission through new media has changed.  In this paper, we will examine the meanings and origin stories of some idioms, conduct additional research on secondary data collected from new new media, and explore the status and meaning of traditional folklore.  In order to clarify this, it is necessary to approach and interpret the idiom through its origin story as well as through functional analysis of the idiom. Through this kind of work, we can explore the ‘archetype’ of the sunshower, which is primitive yet condensed with folk symbolism."
머신러닝을 이용한 과학기술 문헌에서의 지역명 식별과 분류방법에 대한 성능 평가,2024,"['AI 데이터셋', '다중 클래스 분류', '학술논문 데이터베이스', '지역명 분류', '과학기술 R&D 모니터링', 'AI Dataset', 'Multi-class Classification', 'Publication Database', 'Regional Name Classification', 'S&T R&D Monitoring']","생성형 AI는 최근 모든 분야에서 활용되고 있으며, 심층 데이터 분석 분야에서도 전문가를 대체할 수준으로 발전하고 있다. 그러나 과학기술 문헌에서의 지역명 식별은 학습 데이터의 부족과 이에 따른 인공지능 모델을 적용한 사례가 전무한 실정이다. 본 연구는 Web of Science에서 한국 기관 소속 저자들의 주소 데이터를 활용해 지역명을 분류하기 위한 데이터셋을 구축하고, 머신러닝 및 딥러닝 모델의 적용을 실험 및 평가했다. 실험 결과 BERT 모델이 가장 우수한 성능을 보였으며, 광역 분류에서는 정밀도 98.41%, 재현율 98.2%, F1 점수 98.31%를 기록하였다. 시군구 분류에서는 정밀도 91.79%, 재현율 88.32%, F1 점수 89.54%를 달성하였다. 이 결과는 향후 지역 R&D 현황, 지역 간 연구자 이동성, 지역 공동 연구 등 다양한 연구의 기반 데이터로 활용이 가능하다.",
"평가적 태도 부사 중 [본질(ESSENCE)]류 구문의 의미적 확장과 담화적 기능 - '본질적으로', '기본적으로', '핵심적으로'를 중심으로 -",2024,"['[본질]류 부사 구문', '의미 확장', '담화 기능', '말뭉치 방법론', '척도 값 역전 현상', 'ESSENCE-type adverbial constructions', 'semantic expansion', 'discourse function', 'corpus methodology', 'scalar reversal phenomenon']","본 연구는 [본질ESSENCE] 의미 자질을 지닌 부사 구문(‘본질적으로’, ‘기본적으로’, ‘핵심적으로’)의 의미적 확장과 그 언어적 기제를 탐구하는 것을 목적으로 하였다. 이를 위하여 말뭉치 방법론을 활용하여 이들 구문의 사용 패턴을 귀납적으로 분석함으로써, 의미적 확장과 담화적 기능을 규명하고 구문 간 차이를 고찰하였다. 연구 결과, [본질]류 부사의 의미는 척도성을 보이며, ‘기본적으로’와 ‘본질적으로’는 서실적/서상적 맥락에 따라 강조 혹은 공손성이라는 상반된 담화적 기능을 수행하는 것으로 드러났다. 반면 ‘핵심적으로’는 이러한 의미적 확장이 제한적인 것으로 나타났다. 본 연구는 BERT 임베딩과 PCA 기반 클러스터링을 통해 [본질]류 부사 구문들의 의미적 유사도를 시각화하였고, 척도 값 역전 현상을 적용하여 이들의 의미·기능 확장에 관여하는 기제를 규명하였다. 이를 통해 [본질]류 부사 구문의 의미 확장 과정을 체계적으로 분석하고 맥락별 담화 기능을 밝혔다는 점에서 연구의 의의가 있다.","This study aimed to explore the semantic expansion and linguistic mechanisms of adverbial constructions with the ESSENCE semantic feature (‘essentially’, ‘basically’, ‘crucially’). Using corpus methodology, we inductively analyzed the usage patterns of these constructions to identify their semantic expansion, discourse functions, and differences between constructions.The results showed that ESSENCE-type adverbial constructions form scales and receive irrealis or realis interpretations depending on the context. ‘Basically’ and ‘essentially’ were found to perform contrasting functions of emphasis and politeness through this context-dependent interpretation. In contrast, ‘crucially’ did not actively engage in such semantic expansion.This study visualized the semantic similarities and differences between constructions through cluster analysis using BERT embeddings and PCA. We also attempted to explain the linguistic mechanisms involved in the semantic and functional expansion of these constructions by applying the scalar reversal phenomenon. The significance of this study lies in systematically tracing the semantic expansion process of ESSENCE-type adverbial constructions and revealing their diverse discourse functions according to context."
빅데이터 기반 국방과학기술 미래유망기술 예측 연구,2024,"['Tehchnology-Push Planning', 'Defense Science Technology Prediction', 'Defense Big-Data Analysis', 'Defense Core Technology Forecasting', 'Future Emerging Technology Analysis']","최근 기술의 4차 산업혁명 시대의 기술 수명 주기가 단축되고 있고, 첨단 기술의 융·복합화가 가속화 되면서 민간 뿐만 아니라 국방분야에서도 지속적으로 변화하는 미래 전장환경에 민첩하게 대응하고, 기술적 우위를 확보하기 위한 노력을 하고 있다. 이러한 요구에 부응하기 위해 미래 첨단과학기술의 변화를 전망하여 향후 군 활용이 유망한 미래 신기술을 도출하고, 무기체계와 효과적으로 연계할 수 있는 방법론 개발 및 적용이 필요하나 신기술 개발 추세에 적합한 국방기술 예측 연구는 미진한 실정이다. 본 연구에서는 기술주도형(Technology-Push) 기술기획을 위하여 BERT 기법과 같은 빅데이터 분석 방법론을 활용한 미래기술 조사 방법론을 수립하여 군 활용이 유망한 미래 신기술 분야와 향후 첨단무기체계 개발을 위한 기술개발 방향을 제시한다.","Recently, the technology life cycle in the fourth industrial revolution has been shortened, and the convergence/combination of advanced technologies has accelerated in the private and defense sectors. Efforts are being made to respond agilely to the ever-changing future battlefield environment and secure a technical advantage. The authors anticipate changes in advanced science and technology to derive future new technology areas promising for military use and develop a methodology that can effectively link with weapons systems. On the other hand, research on defense technology prediction suitable for the trend of new technology development is insufficient and must be addressed. This paper presents a methodology, such as the BERT technique, for future technology research based on big data analysis for technology-push planning. Future new technology fields with promising military use are presented."
Thesaurus와 TTA를 이용한 Stable Diffusion 사용자 프롬프트의 의미론적 확장 및 생성 방법,2024,"['생성모델', '멀티모달', '스테이블 디퓨전', '테스트 시간 증강', '프롬프트 엔지니어링', '딥러닝', 'generative model', 'multi modal', 'Stable Diffusion', 'test time augmentation', 'prompt engineering', 'deep learning']","Text-to-image 생성 모델에서 사용자 프롬프트는 결과물인 이미지의 품질을 결정하는 핵심 요소이다. 하지만 이미지 생성 모델의 현행 연구들은 대부분 이미지를 생성하는 것에만 중점을 두고 있어, 사용자들은 원하는 결과를 얻기 위해 적절한 어휘로 프롬프트를 작성하는 데 어려움을 느끼는 문제가 있다. 본 연구에서는 생성 모델의 최종 출력과 사용자의 의도 사이의 간극을 줄여 모델의 사용성을 높이는 새로운 방법론을 제안한다. Thesaurus 기반 TTA(Test Time Augmentation) 기법을 도입하여 사용자의 프롬프트를 의미론적으로 연관된 다양한 augmented prompt로 확장한 뒤, 사용자의 피드백을 반영한다. 본 연구의 방법을 통해 사용자의 프롬프트로 생성한 이미지와는 다른 다양한 이미지를 생성하는 것을 정성 평가를 통해 확인하였으며, 증강된 프롬프트가 사용자의 프롬프트와 의미론적으로 연관되어 있다는 것을 BERT Score를 이용한 정량 평가를 통해 확인하였다.","In text-to-image generation models, the user prompt plays a crucial role in determining the quality of the resulting image. However, current research on image generation models primarily focuses on the actual creation of images, leaving users struggling to come up with prompts that use appropriate vocabulary to achieve their desired outcomes. This paper presents a new methodology that aims to enhance the usability of generative models by bridging the gap between the model's final output and the user's intention. To accomplish this, we introduce a Thesaurus-based Test Time Augmentation(TTA) technique, which allows us to semantically expand user prompts into a variety of related augmented prompts. We then incorporate user feedback into the process. We validated the effectiveness of our approach through qualitative evaluations, observing the generation of diverse images from a single user prompt. Furthermore, we confirmed the semantic relevance of our augmented prompts to the user's original prompt using a quantitative evaluation with BERT Scores."
Transformer 기반 LLM의 학습을 이용한 112 허위오인신고분류·예측모델 개발,2024,"['Transformer', 'NLP', '112', 'False Alarm', 'Binary Classification', '트랜스포머', '자연어처리', '112', '허위신고', '이진분류']","112 긴급신고 시스템은 국민 안전을 위한 경찰의 최전선으로, 신속한 출동 및 사건처리가 무엇보다도 중요하다.허위오인신고는 경찰력이 낭비될뿐 아니라 진정으로 도움을 필요로 하는 상황에 대응하기가 어려워진다는 점에서그 문제가 크다. 최근들어 증가하고 있는 허위오인신고에 대응하기 위하여 본 연구자는 딥러닝을 기반으로한 112 허위오인신고 분류·예측모델을 제안한다. 본 모델은 112상황실 접수요원이 요약한 신고내용 텍스트를 입력받아 해당 신고의 허위오인여부를 결정하게 된다. 악의적 허위신고와 오인신고중 후자는 신고접수자 입장에서 표면적으로알아채기가 불가능에 가깝다. 이로 인해 연구자는 허위오인신고 전체 데이터와 악의적인 허위신고만을 담은 데이터를 나누어 실험하였다. 트랜스포머 구조를 가진 BERT, KoBERT,ELECTRA, KoELECTRA, RoBERTa 5가지모델에 대하여 동일한 하이퍼파라미터로 모델 훈련을 진행했다. 본 연구는 자연어처리와 LLM을 이용하여 경찰의실제 치안업무에 대해 문제해결적 접근을 수행했다는 점에 의의가 있다. 본 연구의 결과가 악의적인 허위신고를빠르게 식별하고 경찰이 의사결정을 지원하는데에 도움이 될 것으로 기대한다.","The 112 emergency reporting system is the police's front line for public safety, and rapid dispatch and incident handling are of the utmost importance. False reports are problematic in that they not only waste police power, but also make it difficult to respond to situations that need help. In order to respond to the increase in false reports, this researcher proposes a 112 false report classification and prediction model based on deep learning. This model receives the report text summarized by the 112 situation room receptionist and determines whether the report is false or misidentified. Mistaken reports are almost impossible to detect on the surface from the point of view of the person who filed the report. Because of this, the researcher conducted an experiment dividing data containing all false reports and data containing only malicious false reports. Model training was performed with the same hyperparameters for five models with transformer structures: BERT,KoBERT, ELECTRA, and RoBERTa. This study is significant in that it took a problem-solving approach to the police's actual security work using natural language processing and LLM. It is expected that the results of this study will help identify malicious false reports and support police decision-making."
자연어 처리의 개체명 인식을 통한 기록집합체의 메타데이터 추출 방안,2024,,"본 연구는 인공지능의 하위분야인 자연어 처리(NLP)의 개체명 인식(NER)을 통하여기록에 내재된 메타데이터 값과 기술 정보를 추출하는 방안에 대한 시험적 연구이다.연구 대상은 1960~1970년대에 생산된 구로공단 수기 기록물(약 1,200 쪽, 8만여 단어)을대상으로 하였다.디지털화를 포함하는 전처리 과정과 함께 기록 텍스트에 대해서 구글의 BERT 언어모델에 기반하여 구현되어 공개된 언어 API를 사용하여 개체명을 인식하였다. 그 결과로구로공단의 과거 기록에 포함된 173개의 인명과 314개의 조직 및 기관 개체명을 추출할수 있었고, 이는 기록의 내용에 대한 직접적인 검색어로 사용될 수 있다고 기대된다.그리고 자연어 처리의 이론적 방법론을 반·비정형의 텍스트로 이루어진 실제 기록물에적용할 때 발생하는 문제점을 파악하여 해결 방안과 고려해야 할 시사점을 제시했다.","This pilot study explores a method of extracting metadata values and descriptions fromrecords using named entity recognition (NER), a technique in natural language processing(NLP), a subfield of artificial intelligence. The study focuses on handwritten recordsfrom the Guro Industrial Complex, produced during the 1960s and 1970s, comprisingapproximately 1,200 pages and 80,000 words.After the preprocessing process of the records, which included digitization, the studyemployed a publicly available language API based on Google’s Bidirectional EncoderRepresentations from Transformers (BERT) language model to recognize entity nameswithin the text. As a result, 173 names of people and 314 of organizations and institutionswere extracted from the Guro Industrial Complex’s past records. These extracted entitiesare expected to serve as direct search terms for accessing the contents of the records.Furthermore, the study identified challenges that arose when applying the theoreticalmethodology of NLP to real-world records consisting of semistructured text. It alsopresents potential solutions and implications to consider when addressing these issues."
인공지능 기반 심리상담에 활용되는 딥러닝 기법 고찰,2024,"['인공지능', '심리상담', '딥러닝', '머신러닝', 'Artificial Intelligence', 'Psychological Counseling', 'Deep Learning', 'Machine Learning']","목적 본 연구는 첫째, 현재까지 발전해온 딥러닝 기법들에 대해서 고찰하여 정리해 보며, 둘째, 이러한 딥러닝 기법들이 실제로 인공지능 심리상담 로봇에 어떻게 활용될 수 있는지 논의하는데 주 목적이 있다.방법 인공지능 심리상담에서 활용되고 있는 최신 딥러닝 기법을 고찰하기 위해 2022년까지 감정 분석 및 표정 생성, 텍스트 생성분야에서 딥러닝 기법을 활용한 국내외 논문과 이를 설명한 서적들을 모두 검색하였다. 국내 논문 검색은 RISS, KISS, 국외 논문검색은 ERIC(ProQuest), JSTOR, Google Scholar 등의 논문 검색 사이트를 활용하였다.결과 인공지능을 심리상담에 활용할 때 주로 주목하는 기술은 상대방의 표정에서 감정을 인식하고 비슷한 표정을 생성해 내거나혹은 상대방이 말한 문장에서 감정을 인식하고 이에 응답하는 문장을 생성해 내는 것이다. 이에, 머신러닝과 딥러닝의 개념을 소개하고, 사람의 뇌에서 이루어지는 원리를 이용하여 인공지능을 만드는 방식인 딥러닝 기법들인 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), LSTM(Long Short Term Memory), Transformer, BERT(Bidirectional Encoder Representations from Transformers), GPT(Generative Pretrained Transformer), GAN(Generative Adversarial Network) 등이 작동하는 방식을 기술하였다. 특히, 지금까지 이미지 분석을 통한 감정 인식 프로그램은 주로 CNN을활용하고, 언어는 GPT-2, LSTM 등을 활용하여 연구가 진행되어 왔음이 확인되었다.결론 현존하는 딥러닝 기법 중 인공지능을 심리상담에 활용할 때 주로 주목하는 기술인 상대방의 표정에서 감정을 인식하고 비슷한표정을 생성 혹은 상대방이 말한 문장에서 감정을 인식하고 이에 응답하는 문장을 생성하는 방식이나, 아직까지 규칙 기반 챗봇이주를 이룬다. 이러한 딥러닝 기법을 활용한 인공지능 기반 상담의 장단점을 다루었으며 향후 자연스러운 상호작용이 가능한 기술발전이 요구될 뿐 아니라 그에 대한 효과성 검증이 필요하다.","Objectives This study aims to review and summarize deep learning techniques that have been developed to date and to discuss how they can be applied in practice to artificial intelligence-based psychology counseling robots.Methods To examine the latest deep learning techniques utilized in artificial intelligence psychological counseling, an extensive literature search was conducted for research papers and relevant books from both domestic and international sources in the fields of emotion analysis, facial expression generation, and text generation.. For domestic literature, databases such as RISS and KISS were utilized, and for international literature, research paper search sites including ERIC (ProQuest), JSTOR, and Google Scholar were employed.Results When applying artificial intelligence in psychological counseling, the prominent technology of interest involves recognizing emotions from the interlocutor's facial expressions and generating similar expressions, or recognizing emotions from sentences spoken by the interlocutor and generating responsive sentences. The study introduced the concepts of machine learning and deep learning and explained the workings of deep learning techniques, such as CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), LSTM (Long Short Term Memory), Transformer, BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pretrained Transformer), and GAN (Generative Adversarial Network). These techniques are founded on the principles derived from human brain functioning. Particularly, emotion recognition programs through image analysis have predominantly relied on CNN, while research in the realm of language has advanced with the utilization of GPT-2, LSTM, and similar methods.Conclusions Among the existing deep learning techniques, the recognition of emotions from the interlocutor's facial expressions and the generation of similar expressions, or the recognition of emotions from sentences spoken by the interlocutor and the generation of responsive sentences, are the technologies predominantly under scrutiny for their application in artificial intelligence-based psychological counseling. Nevertheless, rule-based chatbots continue to dominate the landscape. This paper explored the merits and demerits of AI-based counseling employing such deep learning techniques. Looking ahead, there is a need for the advancement of technology that enables natural interactions, coupled with the essential verification of its effectiveness."
Using Large Language Models to Extract Core Injury Information From Emergency Department Notes,2024,"['Large Language Model', 'Injuries', 'Information Extraction', 'Clinical Note', 'Emergency Department']",,"Background: Injuries pose a significant global health challenge due to their high incidence and mortality rates. Although injury surveillance is essential for prevention, it is resource-intensive.This study aimed to develop and validate locally deployable large language models (LLMs) to extract core injury-related information from Emergency Department (ED) clinical notes.Methods: We conducted a diagnostic study using retrospectively collected data from January 2014 to December 2020 from two urban academic tertiary hospitals. One served as the derivation cohort and the other as the external test cohort. Adult patients presenting to the ED with injury-related complaints were included. Primary outcomes included classification accuracies for information extraction tasks related to injury mechanism, place of occurrence, activity, intent, and severity. We fine-tuned a single generalizable Llama-2 model and five distinct Bidirectional Encoder Representations from Transformers (BERT) models for each task to extract information from initial ED physician notes. The Llama-2 model was able to perform different tasks by modifying the instruction prompt. Data recorded in injury registries provided the gold standard labels. Model performance was assessed using accuracy and macro-average F1 scores.Results: The derivation and external test cohorts comprised 36,346 and 32,232 patients, respectively. In the derivation cohort’s test set, the Llama-2 model achieved accuracies (95% confidence intervals) of 0.899 (0.889–0.909) for injury mechanism, 0.774 (0.760–0.789) for place of occurrence, 0.679 (0.665–0.694) for activity, 0.972 (0.967–0.977) for intent, and 0.935 (0.926–0.943) for severity. The Llama-2 model outperformed the BERT models in accuracy and macro-average F1 scores across all tasks in both cohorts. Imposing constraints on the Llama-2 model to avoid uncertain predictions further improved its accuracy.Conclusion: Locally deployable LLMs, trained to extract core injury-related information from free-text ED clinical notes, demonstrated good performance. Generative LLMs can serve as versatile solutions for various injury-related information extraction tasks."
대형 언어 모델을 활용한 한국어 식품 리뷰 분석: 감성분석과 다중 라벨링을 통한 식품안전 위해 탐지 연구,2024,"['감성분석', 'BERT', 'Fine Tuning', '대형언어모델', '다중라벨링', '식품안전', 'Sentiment Analysis', 'Large Language Model', 'Multi-labeling', 'Food Safety']",,"Recently, there have been cases reported in the news of individuals experiencing symptoms of food poisoning after consuming raw beef purchased from online platforms, or reviews claiming that cherry tomatoes tasted bitter. This suggests the potential for analyzing food reviews on online platforms to detect food hazards, enabling government agencies, food manufacturers, and distributors to manage consumer food safety risks. This study proposes a classification model that uses sentiment analysis and large language models to analyze food reviews and detect negative ones, multi-labeling key food safety hazards (food poisoning, spoilage, chemical odors, foreign objects). The sentiment analysis model effectively minimized the misclassification of negative reviews with a low False Positive rate using a ‘funnel’ model. The multi-labeling model for food safety hazards showed high performance with both recall and accuracy over 96% when using GPT-4 Turbo compared to GPT-3.5. Government agencies, food manufacturers, and distributors can use the proposed model to monitor consumer reviews in real-time, detect potential food safety issues early, and manage risks. Such a system can protect corporate brand reputation, enhance consumer protection, and ultimately improve consumer health and safety."
특허 데이터 기반 생성형 AI 기술 동향 분석,2024,"['Artificial Intelligence', 'Bert', 'Generative AI', 'GPT', 'Patent Analysis', 'Technology Trend']",,"This paper analyzes the trends in generative AI technology based on patent application documents. To achieve this, we selected 5,433 generative AI-related patents filed in South Korea, the United States, and Europe from 2003 to 2023, and analyzed the data by country, technology category, year, and applicant, presenting it visually to find insights and understand the flow of technology. The analysis shows that patents in the image category account for 36.9%, the largest share, with a continuous increase in filings, while filings in the text/document and music/speech categories have either decreased or remained stable since 2019. Although the company with the highest number of filings is a South Korean company, four out of the top five filers are U.S. companies, and all companies have filed the majority of their patents in the U.S., indicating that generative AI is growing and competing centered around the U.S. market. The findings of this paper are expected to be useful for future research and development in generative AI, as well as for formulating strategies for acquiring intellectual property."
Emotion Identification in Twitter Using Deep Learning Based Methodology,2024,['Emotion identifcation · BERT · Sentence embedding · Word embedding · Deep neural networks · Deep learning · Multi-class classifcation · Text classifcation · Natural language processing · Tweets'],,"Twitter is one of the micro-blogging platforms in social media that is being used by many users to voice their opinions and expressions. Thus, it acts as a rich source for analyzing efective texts. This work proposes to predict multi-class emotions from tweets. Tweets are short text with a restricted number of words, include emoticons and emojis to express the content in a picturized way, involve contractions and slang, and contain various components such as URLs, mentions, hashtags, and so on. Hence, a methodology that involves tweet-specifc pre-processing strategies is necessitated. Further, it is realized that the exploitation of sentence embedding features about emotion identifcation in tweets is minimal. In this regard, the proposed methodology involves tweet collection, tweet pre-processing through natural language processing techniques to derive pre-processed tweet sentences and pre-processed tweet words, feature vector formulation through polarity of preprocessed tweet sentences and sentence embedding of pre-processed tweet sentences and word embedding of pre-processed tweet words derived through bidirectional encoder representation transformers, classifcation through deep neural networks, evaluation through train-test methodology and evolving of optimized weights for emotion identifcation from tweets with improved accuracy. The methodology is evaluated on a public dataset, Twitter Reviews for Emotion Analysis, available in the Kaggle repository using metrics namely accuracy, recall, precision, and f-measure. Various combinations of features have been provided as input to assess the best combination of features that yields the highest possible performance. Further, the parameters of the deep neural network namely dropout percentage are tuned to accomplish the best performance. As the dataset is imbalanced, the impact of class weights is analyzed to achieve better outcomes."
도농복합지역 중노년층의 스트레스에 관한 텍스트 마이닝 분석: 농업 종사 여부를 중심으로,2024,"['중노년기', '스트레스', '텍스트 마이닝', 'BERT', '도농 비교', 'Older Adults', 'Stress', 'Text Mining', 'Rural', 'Urban']","중노년기는 신체적 노화, 은퇴, 사별 등 많은 스트레스에 노출될 수 있는 시기이다. 본 연구는 텍스트 마이닝 방법을 사용하여 우리나라 도농복합지역에 거주하는 55세 이상 성인남녀 230명으로부터 약 2년간 스마트폰 애플리케이션을 통해 수집된 개방형 문자 데이터 1,703건을 분석하였다. 특히 농업 종사 여부에 따라 연구참여자의 거주환경 및 생활패턴 등 주요 특성이 다르게 나타남에 주목하여, 농업 종사군과 비농업 종사군별 워드 클라우드, 텍스트 네트워크, 중심도 분석 및 토픽 모델링 분석을 실시하고 토픽 간 거리 지도를 그려보았다. 분석 결과, 농업 종사 여부에 따라 중노년층의 일상생활에 지장을 미치는 스트레스원의 종류 및 세부 양상은 여러 차이를 보이고 있었다. 예를 들면, 농업 종사군 중노년층의 경우 농사로 인한 스트레스 및 날씨로 인한 스트레스가 높게 나타났으나, 비농업 종사군 중노년층의 경우 가족이나 직장 관계에서 비롯된 스트레스 및 지나간 자신의 삶에 대한 회한으로 인한 스트레스가 두드러지게 나타났다. 최근 들어 많은 관심을 받고 있는 관계적 복지에 관한 논의를 비롯, 도농별 특성을 고려한 후속 심층 연구를 통해 우리나라 중노년층에게 실질적으로 도움을 줄 수 있는 지역사회 기반 보건복지 정책들이 더 많이 마련되기를 기대한다.","Following weakened health conditions, decreased income after retirement, and the loss of family members, older adults are likely to experience high levels of stress. To better understand stress among older adults, this study analyzed text data collected over two years through open-ended questions in weekly surveys on our smartphone application. In total, 230 participants reported 1,703 times about their stressors. Since stressful life experiences may differ between older adults with agricultural jobs and those with non-agricultural jobs, we divided the data into two groups based on whether the participant worked in agriculture. The results demonstrate several differences between these groups: Older adults with agricultural jobs living in rural areas were more likely to experience stress related to farming or weather, whereas older adults with non-agricultural jobs living in urban areas were more likely to report psychological distress regarding relationships or in self-reflection on their lives. Considering the distinct characteristics of older adults’ lives in rural versus urban areas, we need to develop more sophisticated social policies to reduce stress and prevent mental health problems among community-dwelling older adults."
한국어 텍스트 분류 분석을 위한 데이터 증강 방법,2024,"['data augmentation', 'Korean text classification', 'masked language modeling', 'BERT', '데이터 증강', '자연어처리', '한국어 분류']","데이터 증강은 학습데이터의 변형을 통해 데이터의 크기 및 다양성을 늘리는 방법으로 과적합 규제화 수단으로 사용되고 있다. 활발한 연구가 이루어지고 있는 컴퓨터비전 영역과 달리 자연어처리 영영에서의 데이터 증강 관련 연구는 다소 제한적인 상황이다. 특히 한국어 데이터 관련 연구는 극히 적다. 본 논문에서는 소규모의 한국어 텍스트 데이터 분류 분석 성능 향상을 위한 증강 방법론을 제안한다. 1) 맞춤법 교정을 통한 데이터 증강(DA-SC), 2) 형태소 분석 기반의 쉬운 데이터 증강(EDA-POS), 3) 조건부 마스킹 언어모형 기반의 데이터 증강(DA-cMLM)의 총 세 가지 방안을 제안한다. 실제 데이터 분석을 통해 본 논문에서 제안하는 증강 방법의 적용을 통해 분류 성능을 향상시킬 수 있음을 보인다.","Data augmentation is widely adopted in computer vision. In contrast, research on data augmentation in the field of natural language processing has been limited. We propose several data augmentation methods to support the classification of Korean texts. We increase the size and diversity of text data which are specifically tailored to Korean. These methods adopt and adjust the existing data augmentation for English texts. We could improve the classification accuracy and sometimes regularize the natural language models to reduce the overfits. Our contribution to the data augmentation regarding Korean texts compose of three parts. 1) data augmentation with Spelling Correction, 2) Easy data augmentation based on part-of-speech tagging, and 3) Data augmentation with conditional Masked Language Modeling. Our experiments show that classification accuracy can be improved with the aids of our proposed methods. Due to the limit of computing facilities, we consider rather small-scale Korean texts only."
비정형 데이터를 활용한 지능형 문서 처리 관리에 관한 연구,2024,"['Document management service', 'Intelligent document platform', 'Parsing technology', 'Compilation skills', 'New document Bert function']",,"This research focuses on processing unstructured data efficiently, containing various formulas in document processing and management regarding the terms and rules of domestic insurance documents using text mining techniques. Through parsing and compilation technology, document context, content, constants, and variables are automatically separated, and errors are verified in order of the document and logic to improve document accuracy accordingly. Through document debugging technology, errors in the document are identified in real time. Furthermore, it is necessary to predict the changes that intelligent document processing will bring to document management work, in particular, the impact on documents and utilization tasks that are double managed due to various formulas and prepare necessary capabilities in the future."
온톨로지 이질성 문제를 해결하기 위한 온톨로지 매칭 방법,2024,"['온톨로지 매칭 방법', '이질성 문제', '지식 베이스', 'Ontology Matching Method', 'Heterogeneity Problem', 'SCBOW', 'BERT', 'SimRank', 'Knowledge Base']",,
버트 토픽 (BERTopic)방법으로 분석한 코로나19 백신 (COVID19 vaccination) 언론보도의 특성과 백신 접종자수에 미치는 영향 연구 : 기계학습과 모델링기법의 결합,2024,"['BERTopic', '토픽 모델링', '코로나19', '백신', '코로나19백신', '시계열분석', '뉴스', '뉴스 기사', 'BERTopic', 'Topic Modeling', 'COVID19', 'Vaccination', 'COVID19 Vaccination', 'Times Series Analysis', 'News', 'News Media']","본 연구는 최신 전환학습(Transfer learning) 텍스트 모델링 기법인 BERTopic을 통해 총 38,312개의 코로나19 백신 관련 기사를 분석함으로써 22개의 주요 토픽을 생성하였고, 그중에 가장 많이 언급된 토픽들은 코로나 확진자 추세, 백신 접종, 치료제 개발, 변이와 집단감 염, 등등의 순이었다. 시계열 요소를 도입한 BERTopic dynamic topic model을 통해 살펴본 토픽 의 변화는 상대적으로 예방접종이 잘 진행되고 있던 시기에는 백신 접종에 대한 보도가 줄어들고 델타 변이가 출연한 시점부터 오히려 백신 보도의 비율이 늘어나는 양상을 보였다. 시계열 특성 을 회귀분석에 포함한 방법으로 모델을 추정하였을 때, 단순히 코로나 확진자 수를 보도하거나 백신 개발을 강조하는 보도는 오히려 백신 접종자 수를 감소시켰고, 반면에 해외여행 등 백신을 접종함으로써 받을 수 있는 이익을 강조하는 보도가 백신 접종자 수의 증가와 관련이 있었다. 본 연구는 언론보도와 공중의 의견 간의 관계를 밝히는 기존 연구들의 의의를 넘어 특정 언론보도의 주제가 공중의 행동(백신 접종)에 영향을 미친다는 것을 밝혀 향후 연구자, 광고/홍보 전문가 그 리고 정책 결정자가 보건 위기 상황에 대응할 방안을 마련했다는 데 그 의의가 있다.","Utilizing cutting-edge text modeling techniques such as BERTopic employing a transfer learning approach, the current study investigates a total of 38,312 news articles regarding COVID-19 vaccination. We found that COVID-19 confirmed cases, vaccination efforts, the development of COVID-19 treatments, variations, and mass infections are the prominent topics among the 22 topics that we extracted. Considering the time series dynamics, we observed a decrease in topics related to vaccination as the actual vaccination rate steadily increased, whereas it increased after the appearance of the Delta variant. Regarding the relationship between topics and actual vaccination cases, we identified a negative association when newspapers reported the number of confirmed cases. However, emphasizing the benefits of vaccination, such as the availability of overseas travel, led to an increase in vaccination rates. These findings offer novel insights for theory developers, advertising/public relations experts, and policymakers dealing with public health crises."
트윗 클러스터링을 통한 마약 조직 및 규모 식별 모델 개발,2024,"['Cyber Investigation', 'Drug', 'Social Media', 'Tweet', 'Clustering', '사이버 수사', '마약', '소셜미디어', '트윗', '클러스터링']","본 논문은 10대와 청년층에서 빈번하게 발생하는 마약 범죄를 수사하기 위해 소셜미디어 플랫폼 ‘X’에서마약 홍보 트윗을 수집하고, 이를 바탕으로 마약 유통 조직 및 규모를 식별하는 클러스터링 모델을 개발하는것을 목표로 한다. 최근 소셜미디어의 익명성을 악용한 마약, 불법 도박, 성범죄 등 다양한 사이버 범죄가증가하고 있으며, 특히 마약 유통 조직은 각 구성원이 자신의 역할에 대해서만 익명으로 지시를 받고, 다른 구성원들과 직접 연결되지 않은 점조직 형태로 운영되고 있다. 이러한 유형의 범죄를 추적하기위해 BERT(Bidirectional Encoder Representations from Transformers), GloVe(Global Vectors for Word Representation)와 같은 텍스트 임베딩 모델 및 K-means Clustering과 Spectral Clustering 등 다양한 클러스터링알고리즘을 활용하여 실험 시나리오를 설계하였다. 또한, 각 시나리오에서 도출된 클러스터링 결과를자카드 유사도(Jaccard Similarity) 및 전수조사 기반으로 검증하고, 모든 시나리오에서 동일한 마약 조직으로식별된 트윗 클러스터를 분석하여 사이버 수사 시, 추적 우선순위가 높은 계정을 식별한다.",
크루얼티 프리 패션 브랜드의 커뮤니케이션 성과 분석 - 브랜드 주도적 이미지와 소비자 지각 이미지에 대한 비교 -,2024,"['감성분석', '크루얼티 프리 패션', '브랜드 이미지', '브랜드 커뮤니케이션', '윤리적 패션', 'sentiment analysis', 'cruelty-free fashion', 'brand image', 'brand communication', 'ethical fashion']",,"This study assessed the effectiveness of brand image communication on consumer perceptions of cruelty-free fashion brands. Brand messaging data were gathered from postings on the official Instagram accounts of three cruelty-free fashion brands and consumer perception data were gathered from Tweets containing keywords related to each brand. Web crawling and natural language processing were performed using Python and sentiment analysis was conducted using the BERT model. By analyzing Instagram content from Stella McCartney, Patagonia, and Freitag from their inception until 2021, this study found these brands all emphasize environmental aspects but with differing focuses: Stella McCartney on ecological conservation, Patagonia on an active outdoor image, and Freitag on upcycled products. Keyword analysis further indicated consumers perceive these brands in line with their brand messaging: Stella McCartney as high-end and eco-friendly, Patagonia as active and environmentally conscious, and Freitag as centered on recycling. Results based on the assessment of the alignment between brand-driven images and consumer-perceived images and the sentiment evaluation of the brand confirmed the outcomes of brand communication performance. The study revealed a correlation between brand image and positive consumer evaluations, indicating that higher alignment of ethical values leads to more positive consumer assessments. Given that consumers tend to prioritize search keywords over brand concepts, it’s important for brands to focus on using visual imagery and promotions to effectively convey brand communication information. These findings highlight the importance of brand communication by emphasizing the connection between ethical brand images and consumer perceptions."
적은 양의 음성 및 텍스트 데이터를 활용한 멀티 모달 기반의 효율적인 감정 분류 기법,2024,"['Artificial Intelligence', 'Natural Language Processing', 'Speech Recognition', 'Multimodal', 'Emotion Classification', '인공지능', '자연어 처리', '음성 인식', '멀티모달', '감정 분류']",,"In this paper, we explore an emotion classification method through multimodal learning utilizing wav2vec 2.0 and KcELECTRA models. It is known that multimodal learning, which leverages both speech and text data, can significantly enhance emotion classification performance compared to methods that solely rely on speech data. Our study conducts a comparative analysis of BERT and its derivative models, known for their superior performance in the field of natural language processing, to select the optimal model for effective feature extraction from text data for use as the text processing model. The results confirm that the KcELECTRA model exhibits outstanding performance in emotion classification tasks. Furthermore, experiments using datasets made available by AI-Hub demonstrate that the inclusion of text data enables achieving superior performance with less data than when using speech data alone. The experiments show that the use of the KcELECTRA model achieved the highest accuracy of 96.57%. This indicates that multimodal learning can offer meaningful performance improvements in complex natural language processing tasks such as emotion classification."
How Language Models Process Subject and Object Control: On Promise as a Subject Control Verb,2024,"['subject control', 'object control', 'PRO', 'language model', 'surprisal']",,"This squib examines how neural language models process subject and object control. Processing these two types of control requires an understanding of the structural dependency between an overt determiner phrase (DP) and a non-overt argument (PRO). By using surprisal as a complexity metric, the study tests whether two representative encoder models – BERT and RoBERTa – can distinguish subject control from object control. The results showed that, while the models succeeded in processing object control, they failed to process subject control. The surprisal estimates, which are expected to be higher for unlikely or unacceptable sentences, were elevated for subject inputs even in subject control sentences. This contrast between subject and object control is attributed to the statistical rarity of subject control in the corpus data, particularly regarding the subject control verb promise. Thus, model parsing relies more on statistical patterns than genuine syntactic analysis."
Ethics in Artificial Translation: A Biblical Perspective,2024,"['신경망 기계번역(NMT)', '인공지능 윤리', '데이터 프라이버시 및 소유권', '인공지능에서의 인간 감독', '윤리에 대한 성경적 관점', 'Neural Machine Translation (NMT)', 'AI Ethics', 'Data Privacy and Ownership', 'Human Oversight in AI', 'Biblical Perspectives on Ethics']",,"This paper addresses the ethical challenges of Artificial Intelligence in Neural Machine Translation (NMT) systems, emphasizing the imperative for developers to ensure fairness and cultural sensitivity. The authors investigate the ethical competence of AI models in NMT, examining the ethical considerations at each stage of NMT development, including data handling, focusing on privacy, data ownership, and consent. Employing a rigorous methodological framework, the authors identify and address ethical issues through empirical studies. These include employing transformer models for Luganda-English translations and enhancing efficiency with sentence mini-batching. Complementary studies refine labeling techniques and fine-tune models like BERT for analyzing Luganda and English social media content. Our second approach is a literature review from databases such as Google Scholar and platforms like GitHub. Additionally, the paper probes the distribution of responsibility between AI systems and humans, underscoring the essential role of human oversight in upholding NMT ethical standards. Incorporating a biblical perspective, the authors discuss the societal impact of NMT and the broader ethical responsibilities of developers, positing them as stewards accountable for the societal repercussions of their creations. The paper concludes with recommendations for NMT developers, advocating an approach that integrates technical proficiency with ethical integrity to advance NMT in a manner that is just and beneficial for all global communities, adhering to professional ethics and biblical values."
한국어 코퍼스에서 딥러닝 기반 감성 분석 모델,2024,"['Sentimental Analysis', 'Machine Learning', 'Deep Learning', 'Transformer', 'GPT', '감성 분석', '머신러닝', '딥러닝', 'Transformer', 'GPT']",,"This study comprehensively analyzes the emotional analysis model using deep learning in the Korean corpus, and discusses major research achievements and technological advances. Emotional analysis is the process of extracting and classifying subjective information from text, and the development of deep learning has brought many changes in the field of emotional analysis. Starting with the traditional emotional analysis method, the development of early deep learning models using RNN and CNN is examined, and the process of greatly improving the complex context understanding and processing ability of text through Transformer-based models is analyzed. In this process, models such as BERT and GPT show high performance and potential for expansion to various languages and domains. In addition, it analyzes the research trends of multi-lingual and domain emotional analysis and discusses how to increase the generalization ability of the model through cases using zero-shot and transfer learning. In addition, it also introduces major datasets and evaluation indicators. Finally, it mentions various challenges such as ethical issues in practical applications and suggests future research directions."
Tokenization Stability Index: A Catalyst for Optimizing Transformer Models for Low Resource Languages,2024,"['Large Language Model', 'Low-resource language', 'Morphological structure', 'Optimization', 'Tamil', 'Tokenizer', 'Tokenization Stability Index']",,"Texts from low-resource languages, including those from the Dravidian language family, are characterized by complex morphological structures that can substantially challenge large language models. While transformer models have proven effective in numerous applications, morphological features make low-resource languages less represented. To address this problem, we present the Tokenization Stability Index (TSI), a new metric that objectively captures the differences and similarities between tokenization techniques. TSI assesses token stability, the degree of vocabulary integration, multi-token matching, and the overall rate of all tokens versus unique tokens. We offer a robust mathematical overview, theoretical implications, and case studies to show that TSI creates a reliable framework for improving low-resource language transformer models. Custom tokenization techniques were developed and tested on Tamil-based text inputs. The modified BERT model significantly surpassed the baseline and IndicBERT models, illustrating further potential for refining tokenization frameworks to enhance text processing accuracy on Dravidian-based languages and low-resource languages."
Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals,2024,"['Artificial intelligence', 'Generative artificial intelligence', 'Large language model', 'Synthetic data', 'Medical imaging']",,"The emergence of Chat Generative Pre-trained Transformer (ChatGPT), a chatbot developed by OpenAI, has garnered interest in the application of generative artificial intelligence (AI) models in the medical field. This review summarizes different generative AI models and their potential applications in the field of medicine and explores the evolving landscape of Generative Adversarial Networks and diffusion models since the introduction of generative AI models. These models have made valuable contributions to the field of radiology. Furthermore, this review also explores the significance of synthetic data in addressing privacy concerns and augmenting data diversity and quality within the medical domain, in addition to emphasizing the role of inversion in the investigation of generative models and outlining an approach to replicate this process. We provide an overview of Large Language Models, such as GPTs and bidirectional encoder representations (BERTs), that focus on prominent representatives and discuss recent initiatives involving language-vision models in radiology, including innovative large language and vision assistant for biomedicine (LLaVa-Med), to illustrate their practical application. This comprehensive review offers insights into the wide-ranging applications of generative AI models in clinical research and emphasizes their transformative potential."
GPT-3.5 기반 초거대 언어모델을 활용한 보이스피싱 탐지 기법,2024,"['large language model', 'GPT', 'voice phishing detection', 'prompt design', '초거대 언어모델', 'GPT', '보이스피싱 탐지', '프롬프트 설계']",,"In this paper, we introduce a novel approach for voice phishing call detection, using text-davinci-003, which is a recently updated model from the generative pre-trained transformer (GPT) -3.5 language model series. To achieve this, we devised a prompt to let the language model respond with an integer ranging from 0 to 10, which indicates the likelihood that a given conversation is a voice phishing attempt. For prompt tuning, hyperparameter adjustment, and performance validation,we use a total of 105 actual Korean voice phishing transcripts and 704 transcripts from various topics of general conversations as our dataset. The proposed scheme includes a function to send voice phishing alarm during a call and a function to finally determine whether the call was a voice phishing after the call ends. Performance is evaluated in five different scenarios using different types of training and test data, demonstrating an accuracy range of 0.95 to 0.97 for the proposed technique. In particular, when tested with data from sources different from those used in training, the proposed scheme performs better than the existing bidirectional encoder representations from transformer (BERT) model-based schemes."
언어모델은 언어표현을 유연하게 처리하는가? - 재난문자를 활용한 평가 -,2024,"['language model', 'flexibility', 'evaluation', 'disaster messages', 'well-formed expression', '언어모델', '유연성', '평가', '재난문자', '적형 표현']","이 연구는 사람이 비적형 문장(non-fully well-formed sentence)을 처리할 때 보이는 유연성(flexibility)을 언어모델에서도 관찰할 수 있는지를 분석하였다. 언어모델이 사람과 같은 수준의 언어 능력을 갖추었는지 평가하기 위해서는 비적형 문장과 같이 유연성을 요구하는 벤치마크의 도입이 필요하다. 이를 위해, 재난문자를 기반으로 적형문과 비적형문 쌍으로 구성된 542개의 데이터세트를 구축하였다. 언어모델의 평가 방식은 이해와 생성의 두 가지 방식으로 진행되었으며, 각각의 과업에 특화된 언어모델을 선정하였다. 이해 실험은 5종의 인코더 기반 언어모델(KLUE-RoBERTa, KoBERT, KR-BERT, mBERT, KoELECTRA)에 자연어 추론(Natural Language Inference) 과업을 적용하였다. 생성 실험은 디코더 기반 언어모델(ChatGPT-4)이 생성한 전보문에 대해 설문조사를 진행하였다. 실험 결과, 인코더 기반 언어모델은 비적형 문장을 처리하는 과정에서 일관되지 않은 결과를 나타냈고 디코더 기반 언어모델이 작성한 전보문은 사람이 작성한 전보문과 큰 차이를 보이지 않았다.","This study investigates whether Korean language models can flexibly process non-fully well-formed sentences as they do fully well-formed sentences. For this purpose, we constructed a dataset of well-formed and telegraphic sentence pairs using disaster messages. We conducted two experiments utilizing this data: one with an understanding task on five encoder-based models (KLUE-RoBERTa, KoBERT, KR-BERT, mBERT, KoELECTRA) and the other with a generation task on a decoder-based model (ChatGPT-4). The results of the experiments revealed that language models show inconsistent performance in understanding and exhibit illogical patterns in generation, highlighting a gap between human language competence and language model's performance. Based on these findings, we propose the importance of robustness in language model evaluation methods and emphasize incorporating qualitative assessments to better reflect the complexity of human language. This study suggests that there remain significant challenges for language models to more accurately mimic human understanding and generation."
Comparison of Tactile and Optical Measurement Methods Using Precise Geometrical Shape,2024,"['Measurement', 'Optical measurement', 'Touch measurement', 'Accuracy', 'Cutting tools']",,"The presented article deals with the comparison of accuracy different measuring methods, in order to determine the achievable level of measurement accuracy as well as to evaluate deviations that may occur when measuring the identical component on different machine. The measured component was cemented carbide rod of 10 mm diameter manufactured by the company Ceratizit. Two measurement systems with various degrees of reported accuracy were utilized—coordinate measurement machine Zeiss Prismo Ultra and optical microscope Zoller Genius 3 s. Data obtained by the measurement were evaluated and compared. The experiment was carried out so that appropriate measuring system can be chosen when measuring cutting tools based on the various specific requirements depending on the currently conducted experiments, reducing the time it takes to have the tools measured as well as the load on measuring machines operators. Another reason for the experiment was to determine whether used measurement systems are capable of measuring micro-geometry of the cutting tools, which turned out to be not possible due to the technical limitations of both methods. Comparing the values of deviations between the measuring devices used in the experiment it can be concluded that the accuracy of optical measurement method is sufficient for use in other ongoing experiments when measuring basic tool geometry."
사회언어학 연구를 위한 한국어 미세조정 언어모델,2024,"['age', 'dialect', 'gender', 'Korean language model', 'social register']",,"This paper aims to test deep-learning-based Korean language models’ capacity to learn and detect social registers embedded in speech data, specifically age, gender, and regional dialects. A comprehensive understanding of linguistic phenomena requires contextualizing speech based on speakers’ age, gender, and geographic background, along with the processing of syntactic structures. To bridge the gap between human language understanding and model processing, we fine-tuned three representative Korean language models—KR-BERT, KoELECTRA-base, and KLUE-RoBERTa-base—using transcribed data from 4,000 hours of speech by middle-aged and elderly Korean speakers. The findings reveal that KoELECTRA-base outperformed the other two models across all social registers, which is likely attributed to its larger vocabulary and parameters size. Among the dialects, the Jeju dialect showed the highest accuracy in inference, which is attributed to its distinctiveness, making it easier for the models to detect. In addition to the fine-tuning process, we have made our fine-tuned models publicly available to support researchers interested in Korean computational sociolinguistics."
