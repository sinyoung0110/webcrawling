title,date,keywords,abstract,multilingual_abstract
A Sparse Target Matrix Generation Based Unsupervised Feature Learning Algorithm for Image Classification,2018,"['Neural network', 'unsupervised learning', 'sparse feature', 'classification']",,"Unsupervised learning has shown good performance on image, video and audio classification tasks, and much progress has been made so far. It studies how systems can learn to represent particular input patterns in a way that reflects the statistical structure of the overall collection of input patterns. Many promising deep learning systems are commonly trained by the greedy layerwise unsupervised learning manner. The performance of these deep learning architectures benefits from the unsupervised learning ability to disentangling the abstractions and picking out the useful features. However, the existing unsupervised learning algorithms are often difficult to train partly because of the requirement of extensive hyperparameters. The tuning of these hyperparameters is a laborious task that requires expert knowledge, rules of thumb or extensive search. In this paper, we propose a simple and effective unsupervised feature learning algorithm for image classification, which exploits an explicit optimizing way for population and lifetime sparsity. Firstly, a sparse target matrix is built by the competitive rules. Then, the sparse features are optimized by means of minimizing the Euclidean norm (L<sub>2</sub>) error between the sparse target and the competitive layer outputs. Finally, a classifier is trained using the obtained sparse features. Experimental results show that the proposed method achieves good performance for image classification, and provides discriminative features that generalize well."
Scalable and Unsupervised Feature Engineering Using Vibration-Imaging and Deep Learning for Rotor System Diagnosis,2018,,,"<P>This paper proposes a scalable and unsupervised feature engineering method that uses vibration imaging and deep learning. For scalability, a vibration imaging approach is devised that incorporates data from systems with various scales, such as small testbeds and real field-deployed systems. Moreover, a deep learning approach is proposed for unsupervised feature engineering. The overall procedure includes three key steps: 1) vibration image generation; 2) unsupervised feature extraction; and 3) fault classifier design. To demonstrate the validity of the proposed approach, three case studies are conducted using an RK4 rotor kit and a power plant journal bearing system. By incorporating smaller-system data as well as real-system data, the proposed approach can substantially increase the applicability of the fault diagnosis method while maintaining good accuracy. Moreover, the time and effort needed to develop a diagnostic approach for other rotor systems can be reduced considerably.</P>"
A New Application of Unsupervised Learning to Nighttime Sea Fog Detection,2018,"['Sea fog detection', 'COMS', 'CALIPSO', 'Unsupervised learning', 'EMalgorithm']",,"This paper presents a nighttime sea fog detection algorithm incorporating unsupervised learning technique. The algorithm is based on data sets that combine brightness temperatures from the 3.7 μm and 10.8 μm channels of the meteorological imager (MI) onboard the Communication, Ocean and Meteorological Satellite (COMS), with sea surface temperature from the Operational Sea Surface Temperature and Sea Ice Analysis (OSTIA). Previous algorithms generally employed threshold values including the brightness temperature difference between the near infrared and infrared. The threshold values were previously determined from climatological analysis or model simulation. Although this method using predetermined thresholds is very simple and effective in detecting low cloud, it has difficulty in distinguishing fog from stratus because they share similar characteristics of particle size and altitude. In order to improve this, the unsupervised learning approach, which allows a more effective interpretation from the insufficient information, has been utilized. The unsupervised learning method employed in this paper is the expectation–maximization (EM) algorithm that is widely used in incomplete data problems. It identifies distinguishing features of the data by organizing and optimizing the data. This allows for the application of optimal threshold values for fog detection by considering the characteristics of a specific domain. The algorithm has been evaluated using the Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP) vertical profile products, which showed promising results within a local domain with probability of detection (POD) of 0.753 and critical success index (CSI) of 0.477, respectively."
Design of Digital CMOS Neuromorphic IC with Current-starved SRAM Synapse for Unsupervised Stochastic Learning,2018,"['Spiking neural network (SNN)', 'spike-timing', 'dependent plasticity (STDP)', 'unsupervised learning', 'neural networks']",,"This paper proposes a current-starved SRAM circuit for use as a synapse to support a biological learning of spike-timing dependent plasticity. If the driving strength of SRAM is limited both when writing a new state and restoring the previous state, then programming the opposite synaptic weight requires several densely-repeated write operations. The synapse takes only stochastically-meaningful stimuli for training, and rejects random and noisy inputs; as a result it achieves successful learning even with binary SRAM. The proposed synapse is applied to a three-layer neuromorphic network of spiking neurons that includes a receptive synaptic array and a projective synaptic array. The network is designed with a 28-nm digital CMOS process. Applying an unsupervised learning to only the projective synapses with the receptive synapses fixed at randomly given, the network successfully memorizes multiple overlapped image patterns and recalls the trained patterns if the images are distorted."
An Unsupervised Real-time Anomaly Detection of Furnace System based on HTM,2018,"['Anomaly detection', 'Real-time', 'Unsupervised', 'Furnace systems', 'HTM', 'Machine learning']",,"The immediate recognition of abnormal temperatures in the furnace system is very important for timely disaster control. Conventional abnormal temperature detection techniques typically use pre-programmed thresholds to identify abnormal patterns from a stream of temperature data in a statistical manner. Therefore, it is not suitable for use in a heating furnace system in which abnormal patterns must be detected in real time. Hierarchical Temporal Memory (HTM) is one of the machine learning models with excellent ability to analyze patterns of stream data. This model is a new machine intelligence technique that uses unsupervised continuous learning using Cortical Learning Algorithm (CLA), which is a time-based learning algorithm, and Spare Distributed Representation (SDR), which stores temporal and spatial patterns. This HTM, which is distinguished from existing deep learning or artificial neural network model, is capable of real-time continuous prediction from input of stream data and can be used to recognize abnormal states in various fields. HTM can be used as a robust model to detect abnormalities in successive temperature data in a heating furnace system because the furnace system continues to generate temperature stream data with a certain pattern over time. Here we developed an HTM-based, unsupervised, real-time anomaly detection system for heating furnaces. Performance evaluation shows that the suggested system can perform excellent abnormal real-time detection."
Principal component pyramids for manifold learning in hand shape recognition,2018,"['Principal component analysis', 'Data pyramids', 'Multidimensional grids', 'Multilayer neural networks']",,"This paper presents two algorithms using data pyramids for hand shape recognition in Irish Sign Language. Principal Component Analysis (PCA) is used as a feature extraction and dimensionality reduction method. Originally, the problem is nonlinear and it is hard for PCA to extract the underlying structure of the data. The proposed PCA pyramids provide an alternative to nonlinear PCA as they depend on dividing the space into subspaces which are approximately linear using the appropriate eigenspace in each level. They are used to accelerate the search process to approximate the nearest neighbour search problem. The first algorithm uses unsupervised multidimensional grids to cluster the space into cells of similar objects. The second algorithm is based on training a set of simple architecture multilayer neural networks. Experimental results are given to measure the accuracy and performance of the proposed algorithms in comparison with the exhaustive search scenario. The proposed algorithms are applicable for real time applications with high accuracy measures."
비감독형 학습 기법을 사용한 심각도 기반 결함 예측,2018,"['Fault prediction', 'Defect severity', 'Unsupervised learning']",,"Most previous studies of software fault prediction have focused on supervised learning models for binary classification that determines whether an input module has faults or not. However, binary classification model determines only the presence or absence of faults in the module without considering the complex characteristics of the fault, and supervised model has the limitation that it requires a training data set that most development groups do not have. To solve these two problems, this paper proposes severity-based ternary classification model using unsupervised learning algorithms, and experimental results show that the proposed model has comparable performance to the supervised models."
제한된 라벨 데이터 상에서 다중-태스크 반 지도학습을 사용한 동작 인지 모델의 성능 향상,2018,"['transfer learning', 'multitask learning', 'activity recognition', '전이 학습', '다중 태스크 학습', '동작 인지']","기계 학습을 통한 인간 동작 인지 (human activity recognition) 시스템에서 중요한 요소는 충분한 양의 라벨 데이터 (labeled data)를 확보하는 것이다. 그러나 라벨 데이터를 확보하는 일은 많은 비용과 시간을 필요로 한다. 매우 적은 수의 라벨 데이터를 가지고 있는 새로운 환경 (타겟 도메인)에서 동작 인지 시스템을 구축하는 경우, 기존의 환경 (소스 도메인)의 데이터나 이 환경에서 학습된 분류기(classifier)를 사용하는 것은 도메인이 서로 다르기 때문에 바람직하지 않다. 기존의 기계 학습 방법들이 이러한 문제를 해결할 수 없으므로 전이 학습 (transfer learning) 방법이 제시되었으며, 이 방법에서는 소스 도메인에서 확보한 지식을 활용하여 타겟 도메인에서의 분류기 성능을 높이도록 하고 있다. 본 논문에서는 다중 태스크 신경망 (multitask neural network)을 사용하여 매우 제한된 수의 데이터만으로 정확도가 높은 동작 인지 분류기를 생성하는 전이 학습 방법을 제안한다. 이 방법에서는 소스 및 타겟 도메인 분류기의 손실 함수 최소화가 별개의 태스크로 간주된다. 즉, 하나의 신경망을 사용하여 두 태스크의 손실 함수를 동시에 최소화하는 방식으로 지식 전이(knowledge transfer)가 일어나게 된다. 또한, 제안한 방법에서는 모델 학습을 위하여 비지도 방식(unsupervised manner)으로 라벨이 부여되지 않은 데이터를 활용한다. 실험 결과, 제안한 방법은 기존의 방법에 비하여 일관적으로 우수한 성능을 보여주고 있다.","A key to a well-performing human activity recognition (HAR) system through machine learning technique is the availability of a substantial amount of labeled data. Collecting sufficient labeled data is an expensive and time-consuming task. To build a HAR system in a new environment (i.e., the target domain) with very limited labeled data, it is unfavorable to naively exploit the data or trained classifier model from the existing environment (i.e., the source domain) as it is due to the domain difference. While traditional machine learning approaches are unable to address such distribution mismatch, transfer learning approach leverages the utilization of knowledge from existing well-established source domains that help to build an accurate classifier in the target domain. In this work, we propose a transfer learning approach to create an accurate HAR classifier with very limited data through the multitask neural network. The classifier loss function minimization for source and target domain are treated as two different tasks. The knowledge transfer is performed by simultaneously minimizing the loss function of both tasks using a single neural network model. Furthermore, we utilize the unlabeled data in an unsupervised manner to help the model training. The experiment result shows that the proposed work consistently outperforms existing approaches."
딥러닝 기반의 순방향 전파형 가중치 양자화 기법,2018,"['Deep learning', 'Neural network', 'Quantization method', 'K-means method', '딥러닝', '뉴럴네트워크', '양자화기법', 'K-means기법']","여러 분야에서 뛰어난 성능을 보이는 딥러닝은 뉴럴 네트워크의 은닉 계층을 늘려 깊은 네트워크 구조를 형성할 수 있다. 이에 따라 복잡한 데이터를 쉽게 분류할 수 있으나, 가중치 수 증가로 인해 학습 연산량 및 메모리가 증가한다. 이처럼 많은 연산과 메모리가 필요한 딥러닝은 일반적으로 클라우드 상으로 학습하나, 클라우드는 사용자와의 통신상태가 원활해야 하며 서비스 비용에 대한 부담감 및 개인정보 유출에 대한 위험성을 가진다. 이러한 문제를 해결하기 위해서 딥러닝을 임베디드 디바이스에 탑재해야 하며 온디바이스 탑재를 위한 네트워크 경량화가 필요하다. 경량화 기법으로는 프루닝 기법과 양자화 기법이 널리 사용되고 있으며 기존 양자화 기법은 비지도 학습 중 하나인 K-means를 사용하여 각 계층의 가중치들을 군집화하여 대푯값을 결정한다. K-means 기법에서 군집의 개수를 의미하는 K는 시행착오 방법을 통해 설정해야 하며 이에 따른 오버헤드가 발생한다. 또한, 기존 양자화 기법은 네트워크 각 계층의 연결 관계를 무시한 채 독립적으로 양자화한다. 우리는 연산 오버헤드 문제를 해결하기 위해 가중치들의 통계적 정보를 이용한 즉각적 가중치 양자화 기법을 제안하고 네트워크 각 계층의 의존관계를 고려하여 순차 적으로 양자화함으로써 향상된 학습 성능을 보여준다.","Deep learning, which has excellent performance in various fields, can form deep network structure by increasing hidden layer of neural network. Thus, complex data can be easily classified, but the amount of learning computation and memory increases due to increase of the number of weights. Deep learning, which requires a lot of computation and memory, usually is trained on cloud environments. However, the cloud environment must be maintained in good communication state with user and have burden on service cost and risk of leakage of personal information. To solve this problem, deep learning needs to be learnt on the embedded device, and be light-weighting. Pruning and quantization methods are widely used for the light-weighting. Existing quantization methods usually use K-means, one of the unsupervised learning methods, in order to determine representative values of clustering weights. In the K-means method, the number of groups is set through trial-and-error method, which results in the computation overhead. To alleviate the overhead, we propose an instant weight quantization method using statistical information of weights Also, it can improve learning performance by quantizing sequentially with considering the dependency between layers in the network."
기계학습 클러스터링을 이용한 승하차 패턴에 따른 서울시 지하철역 분류,2018,"['Machine Learning', 'Public Data', 'Seoul Metro Station', 'GMM', 'K-means Clustering']",,"In this study, we classify Seoul metro stations according to boarding and alighting patterns using machine earning technique. The target data is the number of boarding and alighting passengers per hour every day at 233 subway stations from 2008 to 2017 provided by the public data portal. Gaussian mixture model (GMM) and K-means clustering are used as machine learning techniques in order to classify subway stations. The distribution of the boarding time and the alighting time of the passengers can be modeled by the Gaussian mixture model. K-means clustering algorithm is used for unsupervised learning based on the data obtained by GMM modeling. As a result of the research, Seoul metro stations are classified into four groups according to boarding and alighting patterns. The results of this study can be utilized as a basic knowledge for analyzing the characteristics of Seoul subway stations and analyzing it economically, socially and culturally. The method of this research can be applied to public data and big data in areas requiring clustering."
단일 클래스 분류기를 사용한 차량 해킹 탐지,2018,"['차량', '해킹', '침입탐지', '단일 클래스 분류', '비지도 학습', '기계학습', 'vehicle', 'hacking', 'intrusion detection', 'one class classification', 'unsupervised learning', 'machine learning']","본 논문에서는 단일 클래스만을 학습하여 차량에 대한 새로운 공격을 탐지한다. 분류 성능 평가를 위해 Car-Hacking 데이터셋을 사용한다. Car-Hacking 데이터셋은 실제 차량의 OBD-II 포트를 통해 CAN (Controller Area Network) 트래픽을 로깅하여 생성된다. 이 데이터셋에는 네 가지 공격 유형이 포함된다. 실험에 사용한 단일 클래스 분류 기법은 정상 클래스만을 학습하여 비정상인 공격 클래스를 분류해내는 비지도 학습이다. 비지도 학습 방법을 사용하는 경우 에 훈련 과정에서 네거티브 인스턴스를 사용하지 않기 때문에 고효율의 분류 성능을 내는 것은 어렵다. 하지만, 비지도 학습 은 라벨이 없는 새로운 공격 데이터를 분류하는데 적합한 장점이 있다. 본 연구에서는 네트워크 침입탐지 시스템에서 서명 기반의 규칙으로 탐지하기 어려운 새로운 공격 유형을 탐지하기 위해 단일 클래스 분류기를 사용한다. 제안 방법은 새로운 공격을 모두 탐지하고 정상데이터에 대해서도 효율적인 분류 성능을 보이는 파라미터 조합을 제시한다.","In this study, we try to detect new attacks for vehicle by learning only one class. We use Car-Hacking dataset, an intrusion detection dataset, which is used to evaluate classification performance. The dataset are created by logging CAN (Controller Area Network) traffic through OBD-II port from a real vehicle. The dataset have four attack types. One class classification is one of unsupervised learning methods that classifies attack class by learning only normal class. When using unsupervised learning, it difficult to achieve high efficiency because it does not use negative instances for learning. However, unsupervised learning has the advantage for classifying unlabeled data, which are new attacks. In this study, we use one class classifier to detect new attacks that are difficult to detect using signature-based rules on network intrusion detection system. The proposed method suggests a combination of parameters that detect all new attacks and show efficient classification performance for normal dataset."
NIDS의 비정상 행위 탐지를 위한 단일 클래스 분류성능 평가,2018,"['침입탐지', '단일 클래스 분류', '비지도 학습', '기계학습', '인공지능', 'Intrusion detection', 'one class classification', 'unsupervised learning', 'machine learning', 'artificial intelligence']","본 논문에서는 단일 클래스만을 학습하여 네트워크 침입탐지 시스템 상에서 새로운 비정상 행위를 탐지하는 것을 목표로 한다. 분류 성능 평가를 위해 KDD CUP 1999 데이터셋을 사용한다. 단일 클래스 분류는 정상 클래스만을 학습하여 공격 클래스를 분류해내는 비지도 학습 방법 중 하나이다. 비지도 학습의 경우에는 학습에 네거티브 인스턴스를 사용하지 않기 때문에 상대적으로 높은 분류 효율을 내는 것이 어렵다. 하지만, 비지도 학습은 라벨이 없는 데이터를 분류하는데 적합 한 장점이 있다. 본 연구에서는 서포트벡터머신 기반의 단일 클래스 분류기와 밀도 추정 기반의 단일 클래스 분류기를 사용 한 실험을 통해 기존에 없던 새로운 공격에 대한 탐지를 한다. 밀도 추정 기반의 분류기를 사용한 실험이 상대적으로 더 좋은 성능을 보였고, 신규 공격에 대해 낮은 FPR을 유지하면서도 약 96%의 탐지율을 보인다.","In this study, we try to detect anomalies on the network intrusion detection system by learning only one class. We use KDD CUP 1999 dataset, an intrusion detection dataset, which is used to evaluate classification performance. One class classification is one of unsupervised learning methods that classifies attack class by learning only normal class. When using unsupervised learning, it difficult to achieve relatively high classification efficiency because it does not use negative instances for learning. However, unsupervised learning has the advantage for classifying unlabeled data. In this study, we use one class classifiers based on support vector machines and density estimation to detect new unknown attacks. The test using the classifier based on density estimation has shown relatively better performance and has a detection rate of about 96% while maintaining a low FPR for the new attacks."
비지도학습 기반 표적 형상 식별 기법,2018,"['unsupervised learning', 'expectation-maximization', 'target shape identification']",,"We introduce an unsupervised-learning-based technique to analyze the Radio-Frequency (RF) scattering signals from a target and identify the shape of the target. A collection of scattering points on the target was obtained from the interceptor’s RF seeker; then, the Expectation-Maximization (EM) algorithm was applied to classify them and find the statistical characteristics of each cluster. The computation results provide good estimates on the general shape of the target, which includes the length and the location of specific spots, even without sufficient prior knowledge. The proposed technique was verified via Monte-Carlo simulations using the target Radar Cross-Section (RCS) models and the probabilistic models of the seekers. The algorithms were also implemented on the embedded flight computer, and the real-time location performance under realistic environmental conditions were validated via a series of experimental tests."
인공지능의 존재 지위에 대한 두 물음,2018,"['인공지능', '개념 능력', '행위 능력', '감수자 체계와 행위자 체계의 협응', 'artificial intelligence(AI)', 'conceptual competence', 'capacity to act', 'coordination of patient system and agent system']","이 논문은 인공지능의 존재론적 지위를 평가하기 위한 두 개의 물음을 던진다. 하나는 인공지능이 개념을 가질 수 있는가 하는 물음이고, 다른 하나는 인공지능이 행위의 능력을 가졌는가 하는 물음이다. 개념 능력은 인공지능이 통상적인 언어의 형태로 주어지는 명령이나 정보를 능동적으로 이해하고 그것의 작동에 반영할 수 있기 위한 필요조건이다. 최근 인공지능 기술은 영상자료에서 비지도 학습의 방식으로 특정 범주의 사물을 식별해내는 성과를 거뒀지만, 이런 식별의 능력은 개념 능력의 필요조건도 충분조건도 아니다. 인공지능이 우리와 같은 개념을 가지도록 하는 것은 인간 사회의 언어 관행을 고스란히 학습시키는 방식으로 가능할 것인데, 이것은 불가능하지는 않지만 사실상 완결되기 어려운 목표다. 한편, 행위 능력에 대한 평가는 인공지능 프로그램이나 지능형 로봇 같은 인공물을 모종의 책임과 권리를 지닌 행위 주체로 간주할 수 있는가 하는 물음을 다루기 위한 열쇠다. 행위는 행위 주체와 환경 간의 상호작용으로, 행위의 실현에는 환경 속 대상에 대한 지각과 그것에 관한 동작의 협응, 달리 말하자면 감수자 체계와 행위자 체계의 통합이 필수적이다. 그리고 이러한 협응이나 통합의 배후에는 행위를 낳는 의도를 가지고 협응을 조율하는 존재, 즉 자아가 있다. 행위는 감수자 체계와 행위자 체계의 협응을 통해 자아의 의도를 실현하는 과정이다. 인공물의 작동이 이런 조건을 충족한다고 볼 이유는 아직 없다. 결국, 두 물음에 대한 이 논문의 대답은 부정적이거나 기껏해야 유보적이다.","This paper examines two questions in order to assess the ontological status of artificial intelligence(AI). One is the question of whether AI has conceptual competence, and the other is whether AI has capacity to act. Conceptual competence is a necessary condition for AI to be able to properly understand commands and information given in ordinary human language and reflect them in its operation. A recent paper reports the success of AI in discerning objects of a specific category via unsupervised learning. But such ability implies neither a necessary nor a sufficient condition of conceptual competence. We could try to make AI share the conceptual understanding as we have, by way of feeding it the whole body of linguistic practice of human society, which is not impossible but hard to complete in reality. The assessment of capacity to act is, on the other hand, the key to the question of whether AI can be regarded as agent with certain amount of responsibilities and rights. Action is interaction between the agent and its environment. Realization of an action requires successful coordination of patient system and agent system. There is a self behind this coordination, whose intention initiates and drives the whole process. Action is thus the process of realizing the intention of the self through coordination of patient system and agent system. As there is no reason to say that the operation of artifacts meets these conditions, the answers to both questions of this paper are negative."
Anomaly Detection in Sensor Data,2018,"['Sensor Data', 'Exploratory Data Analysis', 'Control Chart', 'ARIMA Model', 'Unsupervised Learning Algorithm']",,"Purpose: The purpose of this study is to set up an anomaly detection criteria for sensor data coming from a motorcycle. Methods: Five sensor values for accelerator pedal, engine rpm, transmission rpm, gear and speed are obtained every 0.02 second from a motorcycle. Exploratory data analysis is used to find any pattern in the data. Traditional process control methods such as X control chart and time series models are fitted to find any anomaly behavior in the data. Finally unsupervised learning algorithm such as k-means clustering is used to find any anomaly spot in the sensor data. Results: According to exploratory data analysis, the distribution of accelerator pedal sensor values is very much skewed to the left. The motorcycle seemed to have been driven in a city at speed less than 45 kilometers per hour. Traditional process control charts such as X control chart fail due to severe autocorrelation in each sensor data. However, ARIMA model found three abnormal points where they are beyond 2 sigma limits in the control chart. We applied a copula based Markov chain to perform statistical process control for correlated observations. Copula based Markov model found anomaly behavior in the similar places as ARIMA model. In an unsupervised learning algorithm, large sensor values get subdivided into two, three, and four disjoint regions. So extreme sensor values are the ones that need to be tracked down for any sign of anomaly behavior in the sensor values. Conclusion: Exploratory data analysis is useful to find any pattern in the sensor data. Process control chart using ARIMA and Joe's copula based Markov model also give warnings near similar places in the data. Unsupervised learning algorithm shows us that the extreme sensor values are the ones that need to be tracked down for any sign of anomaly behavior."
Anomaly Detection in Sensor Data,2018,"['Sensor Data', 'Exploratory Data Analysis', 'Control Chart', 'ARIMA Model', 'Unsupervised Learning Algorithm']",,"Purpose: The purpose of this study is to set up an anomaly detection criteria for sensor data coming from a motorcycle.Methods: Five sensor values for accelerator pedal, engine rpm, transmission rpm, gear and speed are obtained every 0.02 second from a motorcycle. Exploratory data analysis is used to find any pattern in the data. Traditional process control methods such as X control chart and time series models are fitted to find any anomaly behavior in the data. Finally unsupervised learning algorithm such as k-means clustering is used to find any anomaly spot in the sensor data.Results: According to exploratory data analysis, the distribution of accelerator pedal sensor values is very much skewed to the left. The motorcycle seemed to have been driven in a city at speed less than 45 kilometers per hour. Traditional process control charts such as X control chart fail due to severe autocorrelation in each sensor data. However, ARIMA model found three abnormal points where they are beyond 2 sigma limits in the control chart. We applied a copula based Markov chain to perform statistical process control for correlated observations. Copula based Markov model found anomaly behavior in the similar places as ARIMA model. In an unsupervised learning algorithm, large sensor values get subdivided into two, three, and four disjoint regions. So extreme sensor values are the ones that need to be tracked down for any sign of anomaly behavior in the sensor values.Conclusion: Exploratory data analysis is useful to find any pattern in the sensor data. Process control chart using ARIMA and Joe’s copula based Markov model also give warnings near similar places in the data. Unsupervised learning algorithm shows us that the extreme sensor values are the ones that need to be tracked down for any sign of anomaly behavior."
Anomaly Detection in Sensor Data,2018,"['Sensor Data', 'Exploratory Data Analysis', 'Control Chart', 'ARIMA Model', 'Unsupervised Learning Algorithm']",,"Purpose: The purpose of this study is to set up an anomaly detection criteria for sensor data coming from a motorcycle.  Methods: Five sensor values for accelerator pedal, engine rpm, transmission rpm, gear and speed are obtained every 0.02 second from a motorcycle. Exploratory data analysis is used to find any pattern in the data. Traditional process control methods such as X control chart and time series models are fitted to find any anomaly behavior in the data. Finally unsupervised learning algorithm such as k-means clustering is used to find any anomaly spot in the sensor data.  Results: According to exploratory data analysis, the distribution of accelerator pedal sensor values is very much skewed to the left. The motorcycle seemed to have been driven in a city at speed less than 45 kilometers per hour. Traditional process control charts such as X control chart fail due to severe autocorrelation in each sensor data. However, ARIMA model found three abnormal points where they are beyond 2 sigma limits in the control chart. We applied a copula based Markov chain to perform statistical process control for correlated observations. Copula based Markov model found anomaly behavior in the similar places as ARIMA model. In an unsupervised learning algorithm, large sensor values get subdivided into two, three, and four disjoint regions. So extreme sensor values are the ones that need to be tracked down for any sign of anomaly behavior in the sensor values.  Conclusion: Exploratory data analysis is useful to find any pattern in the sensor data. Process control chart using ARIMA and Joe’s copula based Markov model also give warnings near similar places in the data. Unsupervised learning algorithm shows us that the extreme sensor values are the ones that need to be tracked down for any sign of anomaly behavior."
Generative Adversarial Network를 이용한 손실된 깊이 영상 복원,2018,"['Deep learning', 'generative adversarial network', 'depth image', 'depth camera', 'restoration']",,This paper proposes a method of restoring corrupted depth image captured by depth camera through unsupervised learning using generative adversarial network (GAN). The proposed method generates restored face depth images using 3D morphable model convolutional neural network (3DMM CNN) with large-scale CelebFaces Attribute (CelebA) and FaceWarehouse dataset for training deep convolutional generative adversarial network (DCGAN). The generator and discriminator equip with Wasserstein distance for loss function by utilizing minimax game. Then the DCGAN restore the loss of captured facial depth images by performing another learning procedure using trained generator and new loss function.
Performance Evaluation of Pilotless Channel Estimation with Limited Number of Data Symbols in Frequency Selective Channel,2018,"['Channel Estimation', 'Unsupervised Learning']",,"In a wireless mobile communication system, a pilot signal has been considered to be a necessary signal for estimating a changing channel between a base station and a terminal. All mobile communication systems developed so far have a specification for transmitting pilot signals. However, although the pilot signal transmission is easy to estimate the channel,(Ed: unclear wording: it is easy to use the pilot signal transmission to estimate the channel?) it should be minimized because it uses radio resources for data transmission. In this paper, we propose a pilotless channel estimation scheme (PCE) by introducing the clustering method of unsupervised learning used in our deep learning into channel estimation.(Ed: highlight- unclear) The PCE estimates the channel using only the data symbols without using the pilot signal at all. Also, to apply PCE to a real system, we evaluated the performance of PCE based on the resource block (RB), which is a resource allocation unit used in LTE. According to the results of this study, the PCE always provides a better mean square error (MSE) performance than the least square estimator using pilots, although it does not use the pilot signal at all. The MSE performance of the PCE is affected by the number of data symbols used and the frequency selectivity of the channel. In this paper, we provide simulation results considering various effects(Ed: unclear, clarify)."
Performance Evaluation of Pilotless Channel Estimation with Limited Number of Data Symbols in Frequency Selective Channel,2018,"['Channel Estimation', 'Unsupervised Learning.']",,"In a wireless mobile communication system, a pilot signal has been considered to be a necessary signal for estimating a changing channel between a base station and a terminal. All mobile communication systems developed so far have a specification for transmitting pilot signals. However, although the pilot signal transmission is easy to estimate the channel,(Ed: unclear wording: it is easy to use the pilot signal transmission to estimate the channel?) it should be minimized because it uses radio resources for data transmission. In this paper, we propose a pilotless channel estimation scheme (PCE) by introducing the clustering method of unsupervised learning used in our deep learning into channel estimation.(Ed: highlight- unclear) The PCE estimates the channel using only the data symbols without using the pilot signal at all. Also, to apply PCE to a real system, we evaluated the performance of PCE based on the resource block (RB), which is a resource allocation unit used in LTE. According to the results of this study, the PCE always provides a better mean square error (MSE) performance than the least square estimator using pilots, although it does not use the pilot signal at all. The MSE performance of the PCE is affected by the number of data symbols used and the frequency selectivity of the channel. In this paper, we provide simulation results considering various effects(Ed: unclear, clarify)."
Performance Evaluation of Pilotless Channel Estimation with Limited Number of Data Symbols in Frequency Selective Channel,2018,"['Channel Estimation', 'Unsupervised Learning']",,"In a wireless mobile communication system, a pilot signal has been considered to be a necessary signal for estimating a changing channel between a base station and a terminal. All mobile communication systems developed so far have a specification for transmitting pilot signals. However, although the pilot signal transmission is easy to estimate the channel,(Ed: unclear wording: it is easy to use the pilot signal transmission to estimate the channel?) it should be minimized because it uses radio resources for data transmission. In this paper, we propose a pilotless channel estimation scheme (PCE) by introducing the clustering method of unsupervised learning used in our deep learning into channel estimation.(Ed: highlight- unclear) The PCE estimates the channel using only the data symbols without using the pilot signal at all. Also, to apply PCE to a real system, we evaluated the performance of PCE based on the resource block (RB), which is a resource allocation unit used in LTE. According to the results of this study, the PCE always provides a better mean square error (MSE) performance than the least square estimator using pilots, although it does not use the pilot signal at all. The MSE performance of the PCE is affected by the number of data symbols used and the frequency selectivity of the channel. In this paper, we provide simulation results considering various effects(Ed: unclear, clarify)."
Uncertain fuzzy self-organization based clustering: interval type-2 fuzzy approach to adaptive resonance theory,2018,"['Adaptive resonance theory', 'Fuzzy ART', 'Unsupervised learning', 'Interval type-2 fuzzy clustering', 'Vigilance parameter', 'Type reduction']",,"<P><B>Abstract</B></P>  <P>Conventional unsupervised learning algorithms require knowledge of the desired number of clusters beforehand. Even if such knowledge is not required in advance, empirical selection of the parameter values may limit the adaptive capability of the algorithm, thereby restricting the clustering performance. An inherent uncertainty in the number and size of clusters requires integration of fuzzy sets into a clustering algorithm. In this paper, we propose a type-1 (T1) fuzzy ART method that adaptively selects the vigilance parameter value, which is critical in determining the network dynamics. This results in improved clustering performance due to the added flexibility in dynamic selection of the number of clusters with the use of fuzzy sets. To further manage the uncertainty associated with memberships, we extend the proposed T1 fuzzy ART with adaptive vigilance to an interval type-2 (IT2) fuzzy ART method. Type reduction and defuzzification are then performed using the KM algorithm to obtain a defuzzified vigilance parameter value. We evaluate our proposed methods on several data sets to validate their effectiveness.</P>"
An intelligent health monitoring method for processing data collected from the sensor network of structure,2018,"['damage detection', 'unsupervised feature learning', 'moving kernel principal component analysis', 'Nystrom method']",,"Rapid detection of damages in civil engineering structures, in order to assess their possible disorders and as a result produce competent decision making, are crucial to ensure their health and ultimately enhance the level of public safety. In traditional intelligent health monitoring methods, the features are manually extracted depending on prior knowledge and diagnostic expertise. Inspired by the idea of unsupervised feature learning that uses artificial intelligence techniques to learn features from raw data, a two-stage learning method is proposed here for intelligent health monitoring of civil engineering structures. In the first stage, Nystrőm method is used for automatic feature extraction from structural vibration signals. In the second stage, Moving Kernel Principal Component Analysis (MKPCA) is employed to classify the health conditions based on the extracted features. In this paper, KPCA has been implemented in a new form as Moving KPCA for effectively segmenting large data and for determining the changes, as data are continuously collected. Numerical results revealed that the proposed health monitoring system has a satisfactory performance for detecting the damage scenarios of a three-story frame aluminum structure. Furthermore, the enhanced version of KPCA methods exhibited a significant improvement in sensitivity, accuracy, and effectiveness over conventional methods."
인공지능 기반의 융복합 예술창작물 사례 분석 및 고찰,2018,"['Artificial Intelligence(인공지능)', 'Art Creation(예술창작물)', 'Supervised Learning(지도 학습)', 'Unsupervised Learning(비지도 학습)', 'Interdisciplinary convergence research (학제간 융합 연구)']","4차 산업혁명의 도래와 함께, 인공지능 기술은 창의성이 요구되는 예술창작으로 그 적용 영역이 확장되고 있다. 본 연구는 문헌연구를 통해 다학제적 융합연구의 관점에서 ‘예술창작의 수단’으로서의 인간의 창의성과 인공지능이 융합된 예술창작물의 사례를 학습 모델과 관람객의 참여형태를 기반으로 분석하고, 융합적 관점에서 인공지능 기반의 예술창작물의 의미를 조명하는데 그 목적을 두고 있다.  본 연구에서 다룬 인공지능 기반의 상호작용형 예술창작물은 관람객을 참여자나 공동 창작자로 전환시키면서 예술창작에 대한 관람객의 역할에 새로운 의미를 부여했으며, 궁극적으로 인간과 인공지능간의 관계성에 대한 성찰을 강화시켰다. 한편 인공지능 기반의 비상호작용형 예술창작물의 경우, 기계학습을 통해 이미지의 특징을 독창적인 방식으로 해석하고 새로운 이미지를 생성했다. 특히 일부 창작물의 경우에는 인공지능의 사유 가능성과 인공지능에 의해 생성된 예술창작물의 가치에 대한 관심을 증대시켰다.  결론적으로, 인간과 인공지능의 융합을 통해 탄생한 예술창작물은 인간과는 상이한 방식으로 데이터를 해석 및 표현할 수 있기 때문에, 창작자에게는 새로운 창작 소재나 창작 방식의 혁신을 통해 예술과 테크놀로지의 융합에 대한 새로운 지평을 열어 주었고, 관람객에게는 시각적 이미지에 대한 새로운 경험의 기회를 제공해 주었다.","With the advent of the 4th industrial revolution, artificial intelligence technology extends its applying to art creation area, which requires creativity. From the perspective of interdisciplinary research, this study aims to analyze new forms of art creation from the convergence of human creativity and artificial intelligence (hereafter A.I.), based on A.I. learning models and participation forms of viewer through the case studies and literature review. In addition, it contributes to shed light on the meanings of art creations using A.I. in terms of convergence research.  The interactive artworks based on A.I. discussed in this study have given new meaning to the role of spectators in art creation by turning viewers into participant as well as co-creator. Also, it ultimately let people reflect upon the relationship between human and A.I. On the other hand, in the case of non-interactive creative artworks based on A.I., machine learning was used to interpret image’s features to its own unique way and create into new images. Especially in the case of some creations, the creations augmented the interest in the value of artistic creations made by A.I..  In conclusion, because artistic creations created through the convergence of human beings and A.I. can interpret and express data in a way that differ from human beings, it opens up new horizons of the convergence of art and technology for creators to innovate through new creative materials and creative methods and gives visitors a new opportunity to experience visual images."
농산물 생산성 향상을 위한 딥러닝 기반 농업 의사결정시스템,2018,"['ADS(Agriculture Decision-making System)', 'DRCM(Deep learning based Risk Calculation Module)', 'Deep Learning', 'ICM(Information Collection Module)', 'soil and weather information']","본 논문에서 제안하는 “농산물 생산성 향상을 위한 딥러닝 기반 농업 의사결정 시스템”에서는 정밀농업을 지원하는 농장의 위치 정보를 기반으로 기상 정보를 수집하고, 수집한 기상 정보와 농작물의 실시간 데이터를 이용하여, 작물의 현재 상태를 예측하고 그 결과를 농장 관리인에게 알려준다. 제안하는 시스템은 첫째, 정밀농업을 지원하는 농장의 위치 정보를 기반으로 기상 정보를 수집하는 ICM(Information Collection System)을 설계하고, 둘째, 딥러닝 알고리즘을 기반으로 현재 날씨에 따라 농장 토지의 탄소, 수소, 산소, 질소, 수분 함유량이 재배하고 있는 작물에 적합 특정 작물을 재배하기 좋은 상태인지 판단하는 DRCM(Deep learning based Risk Calculation Module)을 설계하고, 셋째, DRCM의 결과를 기반으로 사용자에게 작물의 상태를 점검할 것을 알려주는 메시지를 전송하는 RNM(Risk Notification Module)을 설계한다. 제안하는 시스템은 기존의 시스템과 비교하였을 때, 데이터양의 증가로 인해 발생하는 정확도 감소 비율이 낮고, 분석 단계에 비지도학습을 적용하기 때문에 안정성을 향상 시킬 수 있다. 결과적으로 농장 데이터 분석 성공률이 약 5.15%가량 향상되었고, 환경 변화에 따른 작물 성장의 위험한 상태정보 다양하게 적용하였을 때, 위험한 상태정보에 대하여 상세하게 추론할 수 있었다. 이는 다양한 내·외부 환경으로부터 발생할 수 있는 작물의 질병을 미연에 예방할 수 있고, 작물이 성장하는데 최적화된 환경을 제공할 수 있는 효과를 나타낸다.","This paper proposes “The Agriculture Decision-making System(ADS) based on Deep Learning for improving crop productivity” that collects weather information based on location supporting precision agriculture, predicts current crop condition by using the collected information and real time crop data, and notifies a farmer of the result. The system works as follows. The ICM(Information Collection Module) collects weather information based on location supporting precision agriculture. The DRCM(Deep learning based Risk Calculation Module) predicts whether the C, H, N and moisture content of soil are appropriate to grow specific crops according to current weather. The RNM(Risk Notification Module) notifies a farmer of the prediction result based on the DRCM. The proposed system improves the stability because it reduces the accuracy reduction rate as the amount of data increases and is apply the unsupervised learning to the analysis stage compared to the existing system. As a result, the simulation result shows that the ADS improved the success rate of data analysis by about 6%. And the ADS predicts the current crop growth condition accurately, prevents in advance the crop diseases in various environments, and provides the optimized condition for growing crops."
다양한 크기의 식별자를 적용한 Cycle GAN을 이용한 다목적실용위성 5호 SAR 영상 색상 구현 방법,2018,"['SAR', 'KOMPSAT-5', 'Colorization', 'Deep Learning', 'Satellite Image Processing']","다목적실용위성 5호는 국내 최초로 영상레이더(SAR)가 탑재된 지구관측위성이다. SAR 영상은 위성에 부착된 안테나로부터 방사된 마이크로파가 물체로부터 반사된 신호를 수신하여 생성된다. SAR는 대기 중의입자의 크기에 비해 파장이 긴 마이크로파를 사용하기 때문에 구름이나 안개 등을 투과할 수 있으며, 주야간 구분 없이 고해상도의 영상을 얻을 수 있다. 하지만, SAR 영상에는 색상 정보가 부재하는 제한점이 존재한다. 이러한 SAR 영상의 제한점을 극복하기 위해, 도메인 변환을 위해 개발된 딥러닝 모델인 Cycle GAN을 활용하여 SAR 영상에 색상을 대입하는 연구를 수행하였다. Cycle GAN은 unpaired 데이터셋 기반의 무감독 학습으로 인해 학습이 불안정하다. 따라서 Cycle GAN의 학습 불안정성을 해소하고, 색상 구현의 성능을 향상하기 위해 다중 크기 식별자를 적용한 MS Cycle GAN을 제안하였다. MS Cycle GAN과 Cycle GAN의 색상 구현 성능을 비교하기 위하여 두 모델이 Florida 데이터셋을 학습하여 생성한 영상을 정성적 및 정량적으로 비교하였다. 다양한 크기의 식별자가 도입된 MS Cycle GAN은 기존의 Cycle GAN과 비교하여 학습 결과에서 생성자 및 식별자 손실이 대폭 감소되었고, 나뭇잎, 강, 토지 등의 영역 특성에 부합하는 색상이 구현되는 것을 확인하였다.","Kompsat-5 is the first Earth Observation Satellite which is equipped with an SAR in Korea. SAR images are generated by receiving signals reflected from an object by microwaves emitted from a SAR antenna. Because the wavelengths of microwaves are longer than the size of particles in the atmosphere, it can penetrate clouds and fog, and high-resolution images can be obtained without distinction between day and night. However, there is no color information in SAR images. To overcome these limitations of SAR images, colorization of SAR images using Cycle GAN, a deep learning model developed for domain translation, was conducted. Training of Cycle GAN is unstable due to the unsupervised learning based on unpaired dataset. Therefore, we proposed MS Cycle GAN applying multi-scale discriminator to solve the training instability of Cycle GAN and to improve the performance of colorization in this paper. To compare colorization performance of MS Cycle GAN and Cycle GAN, generated images by both models were compared qualitatively and quantitatively. Training Cycle GAN with multi-scale discriminator shows the losses of generators and discriminators are significantly reduced compared to the conventional Cycle GAN, and we identified that generated images by MS Cycle GAN are well-matched with the characteristics of regions such as leaves, rivers, and land."
악성코드 패킹유형 자동분류 기술 연구,2018,"['Packing', 'Malware classification', 'Section name', 'Clustering', 'Deep Learning']","대부분의 침해공격은 악성코드를 통해 발생하고 있으며, 침해공격으로 인한 피해는 사물인터넷/사이버 물리 시스템과 연결되면서 사이버공간에만 국한되지 않고 실생활에 큰 위협이 되고 있다. 이에 따라, 다양한 악성코드 동적분석, 정적분석기술들이 연구되었는데, 악성코드 동적분석들은 결과적인 악성행위를 쉽게 확인할 수 있어 널리 사용되었으나 VM 환경탐지 시 동작하지 않는 anti-VM 악성코드가 증가하면서 어려움을 겪고 있고, 악성코드 정적분석 기술들은 코드자체를 해석할 수 있어 많은 정보를 얻을 수 있으나 난독화, 패킹 기술들이 적용되어 분석가를 어렵게 하고 있다. 본 논문에서는 정적분석기술의 주요 장애물인 난독화 유형을 자동식별, 분류하는 기술을 제안한다. 특히, 제안하는 모델을 통해 알려진 패커나 알려지지 않은 패커와 상관없이 일정한 기준에 의해 모든 악성코드를 분류할 수 있는 것이 가능하다. 악성코드 분류는 다양한 활용이 가능하지만, 예를 들면 악성코드 정적 feature에 기반하여 머신러닝 기반 분석을 할 때, 전체 파일에 대해 학습 및 분석하는 방식보다 악성코드 유형별 학습 및 분석이 더욱 효과적일 것이다. 이를 위해, PE구조에서 활용 가능한 feature에 대해 지도 학습 및 비지도 학습 방식의 모델을 설계했고, 98,000여개 샘플을 통해 결과 검증을 진행하였다.","Most of the cyber attacks are caused by malicious codes. The damage caused by cyber attacks are gradually expanded to IoT and CPS, which is not limited to cyberspace but a serious threat to real life. Accordingly, various malicious code analysis techniques have been appeared. Dynamic analysis have been widely used to easily identify the resulting malicious behavior, but are struggling with an increase in Anti-VM malware that is not working in VM environment detection. On the other hand, static analysis has difficulties in analysis due to various packing techniques. In this paper, we proposed malware classification techniques regardless of known packers or unknown packers through the proposed model. To do this, we designed a model of supervised learning and unsupervised learning for the features that can be used in the PE structure, and conducted the results verification through 98,000 samples. It is expected that accurate analysis will be possible through customized analysis technology for each class."
Enhanced Network Intrusion Detection using Deep Convolutional Neural Networks,2018,"['Network Intrusion Detection', 'Deep Convolutional Neural Networks', 'Deep learning', 'CNN', 'IDS', 'Information Security']",,"Network Intrusion detection is a rapidly growing field of information security due to its importance for modern IT infrastructure. Many supervised and unsupervised learning techniques have been devised by researchers from discipline of machine learning and data mining to achieve reliable detection of anomalies. In this paper, a deep convolutional neural network (DCNN) based intrusion detection system (IDS) is proposed, implemented and analyzed. Deep CNN core of proposed IDS is fine-tuned using Randomized search over configuration space. Proposed system is trained and tested on NSLKDD training and testing datasets using GPU. Performance comparisons of proposed DCNN model are provided with other classifiers using well-known metrics including Receiver operating characteristics (RoC) curve, Area under RoC curve (AuC), accuracy, precision-recall curve and mean average precision (mAP). The experimental results of proposed DCNN based IDS shows promising results for real world application in anomaly detection systems."
특징영향평가 기반 패턴분류시스템,2018,"['feature selection', 'cluster validity measurement', 'feature impact evaluation', 'unsupervised learning', 'pattern classification']",,"Pattern classification system is often an important component of intelligent systems. In this paper, we present a pattern classification system consisted of the feature selection module, knowledge base construction module and decision module. We introduce a feature impact evaluation selection method based on fuzzy cluster analysis considering computational approach and generalization capability of given data characteristics. A fuzzy neural network, OFUN-NET based on unsupervised learning data mining technique produces knowledge base for representative clusters. 240 blemish pattern images are prepared and applied to the proposed system. Experimental results show the feasibility of the proposed classification system as an automating defect inspection tool."
A Distance Approach for Open Information Extraction Based on Word Vector,2018,"['open information extraction', 'word vector', 'Maximum Likelihood Estimation', 'Bayes Inference', 'natural language processing']",,"Web-scale open information extraction (Open IE) plays an important role in NLP tasks like acquiring common-sense knowledge, learning selectional preferences and automatic text understanding. A large number of Open IE approaches have been proposed in the last decade, and the majority of these approaches are based on supervised learning or dependency parsing. In this paper, we present a novel method for web scale open information extraction, which employs cosine distance based on Google word vector as the confidence score of the extraction. The proposed method is a purely unsupervised learning algorithm without requiring any hand-labeled training data or dependency parse features. We also present the mathematically rigorous proof for the new method with Bayes Inference and Artificial Neural Network theory. It turns out that the proposed algorithm is equivalent to Maximum Likelihood Estimation of the joint probability distribution over the elements of the candidate extraction. The proof itself also theoretically suggests a typical usage of word vector for other NLP tasks. Experiments show that the distance-based method leads to further improvements over the newly presented Open IE systems on three benchmark datasets, in terms of effectiveness and efficiency."
데이터 과학시대 텍스트 데이터 분석기법에 대한 간략한 소개와 제도화를 위한 제언 : 텍스트 데이터에 대한 차원축소 기법을 중심으로,2018,"['텍스트 데이터', '오픈소스 컴퓨터 언어', '토픽모형', '감정분석', '어휘기반 텍스트 분석', '기계학습', 'text data', 'open-source computer language', 'topic model', 'sentiment analysis', 'lexicon-based text analysis', 'machine learning']",,"Due to the advent of digitalization, the amount and scope of textual data explodes and provides social scientists many opportunities to exploit the advantages of the increased volume of text data. However, the plausibility of traditional manual content analysis is hardly comprehensive and/or useful because of expensive cost hiring human coders and limited amount of time for the voluminous textual data. In this sense, algorithmic understanding of textual data (i.e., identifying textual data as matrix where documents are on the row and tokens, usually words, are on the column), provides theoretical and practical solutions for the analyses of textual data, in terms of topic detection and sentiment analysis. This study overviews a variety of algorithmic approach to textual data, and provides three groups: (1) lexicon-based approach, (2) unsupervised machine learning approach, and (3) supervised machine learning approach. Those three approaches were introduced with plain words to social scientists and how they can be exploited to understand large-scale textual data and how the predicted meanings of textual data for associational or causal analysis for social scientific theory building and testing. In the discussion section, some practical suggestions regarding how those methods can be used, and what should be done for the algorithmic approach settles in social scientific fields."
역인덱스 기반 상향식 군집화 기법을 이용한 대규모 학술 핵심어 분석,2018,"['Keyword clustering', 'Inverted-index', 'keyword analysis', 'bottom-up clustering', 'information retrieval']","특허(patent), 학술 논문(scholarly paper)과 연구 보고서(research report)와 같은 디지털 문서(digital document)에는 주제(topic)를 요약하는 저자 키워드(author keyword)가 있다. 서로 다른 문서가 동일한 키워드를 공유하고 있다면 두 문서가 동일한 주제의 내용을 기술하고 있을 가능성이 매우 높다. 문서 군집화(document clustering)는 비슷한 주제를 가지는 문서들을 비지도 학습 방법(unsupervised learning)을 이용하여 같은 군집으로 그룹(group)화 하는 것이다. 문서 군집화는 다양한 분석에 이용되지만 대용량의 문서 데이터에 적용하기 위해서는 많은 계산량이 필요함으로 쉽지 않다. 이러한 경우, 문서의 내용을 이용하는 것보다 문서의 키워드를 이용하여 군집화하면 더욱 효율적으로 대용량의 데이터를 연결할 수 있다. 기존의 상향식 군집화 방법(bottom-up hierarchical clustering)은 대용량의 키워드 군집화(keyword clustering)를 수행하는데 있어서 많은 시간이 필요하다는 문제점이 있다. 본 논문에서는 정보검색(information retrieval)에서 널리 사용되는 역인덱스(inverted-index) 구조를 상향식 군집화에 적용한 효율적인 군집화 방법을 제안하고, 제안 방법을 대용량의 키워드 데이터에 적용하였으며, 그 결과를 분석하였다.","Digital documents such as patents, scholarly papers and research reports have author keywords which summarize the topics of documents. Different documents are likely to describe the same topic if they share the same keywords. Document clustering aims at clustering documents to similar topics with an unsupervised learning method. However, it is difficult to apply to a large amount of documents event though the document clustering is utilized to in various data analysis due to computational complexity. In this case, we can cluster and connect massive documents using keywords efficiently. Existing bottom-up hierarchical clustering requires huge computation and time complexity for clustering a large number of keywords. This paper proposes an inverted index based bottom-up clustering for keywords and analyzes the results of clustering with massive keywords extracted from scholarly papers and research reports."
사물인터넷 환경에서의 저전력 무선 신호 간섭 탐지 시스템,2018,"['무선 신호', '간섭', '사물인터넷', 'Wi-Fi', '802.15.4', 'Wireless Signal', 'Interference', 'Internet of Things', 'Wi-Fi', '802.15.4']","2.4GHz의 ISM 밴드에서 동작하는 802.15.4 표준 기반 IoT 기기들은 같은 공간에 존재하는 Wi-Fi와 Bluetooth 장치로부터 발생하는 신호 간섭으로 인해 심각한 성능 저하를 겪는다. Wi-Fi, Bluetooth로부터 발생하는 신호 간섭을 효율적으로 완화시키기 위해서는 간섭을 일으키는 무선 기술을 특정하고 간섭의 패턴 탐지가 중요하다. 하지만, 현재 기존에 제안되었던 다양한 간섭 탐지 기술들은 여러 개의 간섭 요소들이 동시에 발생했을 때 간섭 탐지율이 낮아지는 문제가 있다. 본 논문에서는 다수의 Wi-Fi, Bluetooth 기기들이 동작하는 환경에서 802.15.4 표준 기반 IoT 기기들이 주변 환경의 무선 신호를 수집/분석하여 간섭 탐지율을 높이는 방법을 제안한다. 우리가 제안한 IoT 간섭 탐지기는 다양한 종류의 무선 간섭이 있을 때 Unsupervised learning 기법을 활용하여 간섭의 종류를 분류해낸다. 또한, Wi-Fi Access Point에서 주기적으로 전송하는 비콘 신호와 일반적인 데이터 트래픽을 분류하여 탐지할 수 있기 때문에 802.15.4 표준 기반 IoT 기기의 성능 향상을 위한 다양한 알고리즘 개발에 활용될 수 있다. 또한, 간섭에 의한 채널 점유율이 높은 채널들의 리스트를 관리하여 동적으로 IoT 기기의 이용 채널 변경과 연계하여 IoT 기기의 전송 효율성을 높일 수 있다. 본 논문에서는 다양한 실험 결과들을 바탕으로 일반적인 환경에서의 무선 신호 간섭 상태를 보여주고 제안한 간섭 탐지 기법을 활용했을 때 동시에 다수의 신호 간섭을 탐지할 수 있음을 증명하였다.","802.15.4 compatible IoT devices suffer significant performance degradation due to signal interference from Wi-Fi and Bluetooth devices in the 2.4GHz ISM band. In order to efficiently mitigate signal interference from Wi-Fi and Bluetooth, it is important to identify the interfering sources and detect the pattern of interference. However, existing interference detection techniques have a problem in that the interference detection rate is low when a plurality of interference elements occur at the same time. In this paper, we propose a novel method to increase interference detection rate by collecting and analyzing wireless signals of surrounding environment by low power IoT devices in the environment where many Wi-Fi and Bluetooth devices operate. The proposed IoT interference detector classifies the types of interference by using the unsupervised learning technique in the presence of various kinds of radio interference. Based on various experimental results, we show the state of wireless signal interference in a general environment and proved that it can detect multiple signal interference at the same time when using the proposed interference detection technique."
국내 학술논문 주제 분류 알고리즘 비교 및 분석,2018,"['과학기술정보', '논문 데이터', '학술논문', '주제 분류', '정보 서비스', 'Science Technology Information', 'Research Data', 'Academic Paper', 'Subject Classification', 'Information Service']","학술정보 성과물을 서비스하기 위하여 논문 단위의 주제 분류는 필수가 된다. 하지만 현재까지 저널 단위의 주제 분류가 되어 있으며 기사 단위의 주제 분류가 서비스되는 곳은 많지 않다. 국내 성과물 중에서 학술 논문의 경우 주제 분류가 있으면 좀 더 큰 영역의 서비스를 담당할 수 있고 범위를 정해서 서비스 할 수 있기 때문에 무엇보다 중요한 정보가 된다. 하지만, 분야 별 주제를 분류하는 문제는 다양한 분야의 전문가의 손이 필요하고 정확도를 높이기 위해서 다양한 방법의 검증이 필요하다. 본 논문에서는 정답이 알려져 있지 않은 상태에서의 정답을 찾는 비지도 학습 알고리즘을 활용해서 주제 분류를 시도해 보고 연관도와 복잡도를 활용해서 주제 분류 알고리즘의 결과를 비교해 보고자 한다. 비지도 학습 알고리즘은 주제 분류 방법으로 잘 알려진 Hierarchical Dirichlet Precess(HDP). Latent Dirichlet Allocation(LDA), Latent Semantic Indexing(LSI) 알고리즘을 활용하여 성능을 분석해 보았다.","Subject classification of thesis units is essential to serve scholarly information deliverables. However, to date, there is a journal-based topic classification, and there are not many article-level subject classification services. In the case of academic papers among domestic works, subject classification can be a more important information because it can cover a larger area of service and can provide service by setting a range. However, the problem of classifying themes by field requires the hands of experts in various fields, and various methods of verification are needed to increase accuracy. In this paper, we try to classify topics using the unsupervised learning algorithm to find the correct answer in the unknown state and compare the results of the subject classification algorithms using the coherence and perplexity. The unsupervised learning algorithms are a well-known Hierarchical Dirichlet Process (HDP), Latent Dirichlet Allocation (LDA) and Latent Semantic Indexing (LSI) algorithm."
A novel method for natural motion mapping as a strategy of game immediacy,2018,"['Traffic classification', 'unsupervised learning', 'k-nearest neighbor', 'clustering']",,"The method of operating a game could determine the psychological distance between the player and the game character, and thus, in the Virtual Reality, players’ control methodologies are important to enhance their immersion. This study has the objective of examining the difference in games according to the method of operation based on the player’s movements. This study researched the effect of the method of operating movement conforming to the movement of the character and the physical operation of the body on forming game experiences for the player. The result of performing an experiment increased reality for the game player through a controller in the shape of the actual control, to increase focus in the game. As so, game play through movements, including actual movements by the player displayed to enhance game satisfaction. In the part of media remediation field, Game can be defined as media which has their own unique hypermediacy. Especially, in the motion based game, players’ movement mediates players and the game, therefore, players’ movement could make players’ experience augmented or immediate in accordance with the characteristics of movements. Even though sports and dances genres of motion-based games are common, RPG or adventure genres are rare. It can be explained that the characteristics of the action have been explained in the immediacy. In a game of fantasy, which is difficult to experience in real-life situations, the nature of the player's motion can increase the immersion of the game, which can contribute to utilization of players’ motion and experience design in the various genres and suggestion of grounds theory. In addition, through this study, it is able to design motion-based games of various genres."
군집화 알고리즘을 이용한 채널 추정 기법 및 성능 평가,2018,"['clustering-based unsupervised learning', 'channel estimation', 'deep learning']",,
Determining the Optimal Number of Signal Clusters Using Iterative HMM Classification,2018,"['HMM', 'Iterative Clustering', 'Optimal', 'Unsupervised', 'Signal.']",,"In this study, we propose an iterative clustering algorithm that automatically clusters a set of voice signal data without a label into an optimal number of clusters and generates hmm model for each cluster. In the clustering process, the likelihood calculations of the clusters are performed using iterative hmm learning and testing while varying the number of clusters for given data, and the maximum likelihood estimation method is used to determine the optimal number of clusters. We tested the effectiveness of this clustering algorithm on a small-vocabulary digit clustering task by mapping the unsupervised decoded output of the optimal cluster to the ground-truth transcription, we found out that they were highly correlated."
Minimally Supervised Relation Identification from Wikipedia Articles,2018,"['relation identification', 'Wikipedia mining', 'unsupervised clustering']",,"Wikipedia is composed of millions of articles, each of which explains a particular entity with various languages in the real world. Since the articles are contributed and edited by a large population of diverse experts with no specific authority, Wikipedia can be seen as a naturally occurring body of human knowledge. In this paper, we propose a method to automatically identify key entities and relations in Wikipedia articles, which can be used for automatic ontology construction. Compared to previous approaches to entity and relation extraction and/or identification from text, our goal is to capture naturally occurring entities and relations from Wikipedia while minimizing artificiality often introduced at the stages of constructing training and testing data. The titles of the articles and anchored phrases in their text are regarded as entities, and their types are automatically classified with minimal training. We attempt to automatically detect and identify possible relations among the entities based on clustering without training data, as opposed to the relation extraction approach that focuses on improvement of accuracy in selecting one of the several target relations for a given pair of entities. While the relation extraction approach with supervised learning requires a significant amount of annotation efforts for a predefined set of relations, our approach attempts to discover relations as they occur naturally. Unlike other unsupervised relation identification work where evaluation of automatically identified relations is done with the correct relations determined a priori by human judges, we attempted to evaluate appropriateness of the naturally occurring clusters of relations involving person-artifact and person-organization entities and their relation names."
Determining the Optimal Number of Signal Clusters Using Iterative HMM Classification,2018,"['HMM', 'Iterative Clustering', 'Optimal', 'Unsupervised', 'Signal']",,"In this study, we propose an iterative clustering algorithm that automatically clusters a set of voice signal data without a label into an optimal number of clusters and generates hmm model for each cluster. In the clustering process, the likelihood calculations of the clusters are performed using iterative hmm learning and testing while varying the number of clusters for given data, and the maximum likelihood estimation method is used to determine the optimal number of clusters. We tested the effectiveness of this clustering algorithm on a small-vocabulary digit clustering task by mapping the unsupervised decoded output of the optimal cluster to the ground-truth transcription, we found out that they were highly correlated."
A Unified Framework for Joint Mobility Prediction and Object Profiling of Drones in UAV Networks,2018,"['Kalman filtering', 'mobility prediction', 'online learning', 'target tracking', 'unmanned aerial vehicles']",,"In recent years, using a network of autonomous and cooperativeunmanned aerial vehicles (UAVs) without command andcommunication from the ground station has become more imperative,particularly in search-and-rescue operations, disaster management,and other applications where human intervention is limited.In such scenarios, UAVs can make more efficient decisions ifthey acquire more information about the mobility, sensing and actuationcapabilities of their neighbor nodes. In this study, we developan unsupervised online learning algorithm for joint mobilityprediction and object profiling of UAVs, to facilitate control andcommunication protocols. The proposed method not only predictsthe future locations of the surrounding flying objects, but also classifiesthem into different groups with similar levels of maneuverability(e.g., rotatory and fixed-wing UAVs) without prior knowledgeregarding these classes. This method is flexible in admittingnew object types with unknown mobility profiles, and is therebyapplicable to emerging flying ad-hoc networks (FANETs) with heterogeneous nodes."
비지도학습 데이터의 정확성 측정을 위한 클러스터별 분류 평가 예측 모델에 대한 연구,2018,"['Cluster Verification', 'RNN', 'LSTM', 'Classification', 'Unsupervised Learning', 'Clustering k-LSTM RNN']",,
AIS 데이터 분석을 통한 이상 거동 선박의 식별에 관한 연구,2018,"['기계학습', 'AIS', '해상교통 분석', '이상 거동 선박', '선박교통관제', 'Machine Learning', 'AIS', 'Maritime Traffic Analysis', 'Ship Movement Anomaly', 'Vessel Traffic Service']","최근 해상교통량이 증가하고 선박교통 관제구역이 확대됨에 따라 관제사의 업무 부하가 증가하고 있으며, 이로 인해 교통량이 급증하는 경우 관제사가 위험을 인지하지 못하는 상황도 발생하게 된다. 이러한 배경에서 본 논문에서는 관제 업무의 지원을 위해 이상 거동 선박을 자동으로 식별하는 방법을 제안한다. 본 방법은 누적된 AIS 데이터를 이용하여 관제구역 내의 통항 패턴을 학습하고, 학습된 모델과 의 비교를 통해 이상치를 계산하여 이상 거동 선박을 식별한다. 특히, 선박의 거동 상태에 대한 분류 정보가 없더라도 비지도 학습법을 기반으로 항적 데이터를 자동으로 분류하여 통항 패턴을 학습할 수 있으며, 항적의 군집화와 분류 과정을 통해 이상 거동 선박을 실시간으로 식별할 수 있는 특징을 가진다. 또한, 본 논문에서는 선박운항 시뮬레이터 및 실제 AIS 항적 데이터를 이용한 식별 실험을 수행하였으며, 이를 통해 선박교통관제 시스템에의 활용 가능성을 고찰하였다.","Recently, the Vessel Traffic Service (VTS) coverage has expanded to include coastal areas following the increased attention on vessel traffic safety. However, it has increased the workload on the VTS operators. In some cases, when the traffic volume increases sharply during the rush hour, the VTS operator may not be aware of the risks. Therefore, in this paper, we proposed a new method to recognize ship movement anomalies automatically to support the VTS operator’s decision-making. The proposed method generated traffic pattern model without any category information using the unsupervised learning algorithm.. The anomaly score can be calculated by classification and comparison of the trained model. Finally, we reviewed the experimental results using a ship-handling simulator and the actual trajectory data to verify the feasibility of the proposed method."
SNS 데이터와 Word2Vec을 이용한 게임 콘텐츠 평가,2018,"['자연어처리', 'Word2Vec', 'CBOW', '비지도 학습', 'SNS', 'NLP', 'Word2Vec', 'CBOW', 'Unsupervised Learning', 'SNS']",SNS는 각종 콘텐츠들에 대한 사용자들의 평가가 생성되는 곳으로 평가를 추론하는 데이터로 유용한 곳이다. 그러나 SNS 데이터는 비속어를 비롯해 채팅 용 문장들이 많으며 문법이 정형적이지 않아 기계적으로 의미를 해석하기가 어려움이 있다. 본 논문에서는 특정 게임 사용자들을 대상으로 SNS 데이터를 6개월간 취합하여 Word2Vec을 이용하여 게임 콘텐츠가 사용자들에 가진 의미를 분석하였다. SNS 데이터는 CBOW과 Skip-gram을 비롯하여 문장 간 거리를 비교하였으며 SNS 데이터에 대한 합리적인 기계 학습 모델을 제안한다.,"SNS is useful place for infer evaluation based on user generated feedback regarding various contents.However, SNS data contains many profanity and internet slangs, and wrong grammar. So it makes difficult to understanding and analyze meaning by the computer. In this paper, we collected SNS data for specific game users for 6 months. Then, Word2Vec was used to analyze the meaning of game contents to users. SNS data compares the distance between sentences including CBOW and Skip-gram, and suggests a reasonable machine learning model for SNS data."
SVDD를 활용한 상업용 건물에너지 소비패턴의 이상현상 감지,2018,"['건물에너지', '이상현상감지', '서포트 벡터 머신', '비감시 기계학습', 'Building energy consumption', 'Anomaly detection', 'Support vector data description (SVDD)', 'Unsupervised machine learning']",,"Anomaly detection on building energy consumption has been regarded as an effective tool to reduce energy saving on building operation and maintenance. However, it requires energy model and FDD expert for quantitative model approach or large amount of training data for qualitative/history data approach. Both method needs additional time and labors. This study propose a machine learning and data science approach to define faulty conditions on hourly building energy consumption with reducing data amount and input requirement. It suggests an application of Support Vector Data Description (SVDD) method on training normal condition of hourly building energy consumption incorporated with hourly outdoor air temperature and time integer in a week, 168 data points and identifying hourly abnormal condition in the next day. The result shows the developed model has a better performance when the  (probability of error in the training set) is 0.05 and  (radius of hyper plane) 0.2. The model accuracy to identify anomaly operation ranges from 70% (10% increase anomaly) to 95% (20% decrease anomaly) for daily total (24 hours) and from 80% (10% decrease anomaly) to 10%(15% increase anomaly) for occupied hours, respectively."
Generative Adversarial Networks를 이용한 Face Morphing 기법 연구,2018,"['대립쌍 기계학습', '얼굴합성', '합성곱 신경망', '비지도 학습', 'Generative adversarial network', 'face morphing', 'DCGAN', 'dCNN', 'unsupervised learning']",,
Binarization of degraded document images based on hierarchical deep supervised network,2018,"['Document image binarization', 'Convolutional neural network', 'Document analysis']",,"<P><B>Abstract</B></P>  <P>The binarization of degraded document images is a challenging problem in terms of document analysis. Binarization is a classification process in which intra-image pixels are assigned to either of the two following classes: foreground text and background. Most of the algorithms are constructed on low-level features in an unsupervised manner, and the consequent disenabling of full utilization of input-domain knowledge considerably limits distinguishing of background noises from the foreground. In this paper, a novel supervised-binarization method is proposed, in which a hierarchical deep supervised network (DSN) architecture is learned for the prediction of the text pixels at different feature levels. With higher-level features, the network can differentiate text pixels from background noises, whereby severe degradations that occur in document images can be managed. Alternatively, foreground maps that are predicted at lower-level features present a higher visual quality at the boundary area. Compared with those of traditional algorithms, binary images generated by our architecture have cleaner background and better-preserved strokes. The proposed approach achieves state-of-the-art results over widely used DIBCO datasets, revealing the robustness of the presented method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a supervised binarization method based on the deep supervised networks. </LI> <LI>  The multi-scale deep supervised network for binarization has not been reported yet. </LI> <LI>  A hierarchical architecture is designed to distinguish text from background noises. </LI> <LI>  Different feature levels are dealt by the multi-scale architecture. </LI> <LI>  The performance results are considerably better than state-of-the-art methods. </LI> </UL> </P>"
Efficient Data Clustering using Fast Choice for Number of Clusters,2018,"['Data Clustering', 'Heuristic Algorithm', 'Number of Clusters', 'Silhouette']",,"K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, this method has the limitation to be used with fixed number of clusters because of only considering the intra-cluster distance to evaluate the data clustering solutions. Silhouette is useful and stable valid index to decide the data clustering solution with number of clusters to consider the intra and inter cluster distance for unsupervised data. However, this valid index has high computational burden because of considering quality measure for each data object. The objective of this paper is to propose the fast and simple speed-up method to overcome this limitation to use silhouette for the effective large-scale data clustering.In the first step, the proposed method calculates and saves the distance for each data once. In the second step, this distance matrix is used to calculate the relative distance rate (Vj) of each data j and this rate is used to choose the suitable number of clusters without much computation time. In the third step, the proposed efficient heuristic algorithm (Group search optimization, GSO, in this paper) can search the global optimum with saving computational capacity with good initial solutions using  probabilisticallyfor the data clustering. The performance of our proposed method is validated to save significantly computation timeagainst the original silhouette only using Ruspini, Iris, Wine and Breast cancer in UCI machine learning repository datasets by experiment and analysis. Especially, the performance of our proposed method is much better than previous method for the larger size of data."
빠른 클러스터 개수 선정을 통한 효율적인 데이터 클러스터링 방법,2018,"['Data Clustering', 'Heuristic Algorithm', 'Number of Clusters', 'Silhouette']",,"K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, this method has the limitation to be used with fixed number of clusters because of only considering the intra-cluster distance to evaluate the data clustering solutions. Silhouette is useful and stable valid index to decide the data clustering solution with number of clusters to consider the intra and inter cluster distance for unsupervised data. However, this valid index has high computational burden because of considering quality measure for each data object. The objective of this paper is to propose the fast and simple speed-up method to overcome this limitation to use silhouette for the effective large-scale data clustering.In the first step, the proposed method calculates and saves the distance for each data once. In the second step, this distance matrix is used to calculate the relative distance rate (Vj) of each data j and this rate is used to choose the suitable number of clusters without much computation time. In the third step, the proposed efficient heuristic algorithm (Group search optimization, GSO, in this paper) can search the global optimum with saving computational capacity with good initial solutions using Vj probabilistically for the data clustering. The performance of our proposed method is validated to save significantly computation time against the original silhouette only using Ruspini, Iris, Wine and Breast cancer in UCI machine learning repository datasets by experiment and analysis. Especially, the performance of our proposed method is much better than previous method for the larger size of data."
빠른 클러스터 개수 선정을 통한 효율적인 데이터 클러스터링 방법,2018,"['Data Clustering', 'Heuristic Algorithm', 'Number of Clusters', 'Silhouette']",,"K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, this method has the limitation to be used with fixed number of clusters because of only considering the intra-cluster distance to evaluate the data clustering solutions. Silhouette is useful and stable valid index to decide the data clustering solution with number of clusters to consider the intra and inter cluster distance for unsupervised data. However, this valid index has high computational burden because of considering quality measure for each data object. The objective of this paper is to propose the fast and simple speed-up method to overcome this limitation to use silhouette for the effective large-scale data clustering. In the first step, the proposed method calculates and saves the distance for each data once. In the second step, this distance matrix is used to calculate the relative distance rate (Vｊ) of each data j and this rate is used to choose the suitable number of clusters without much computation time. In the third step, the proposed efficient heuristic algorithm (Group search optimization, GSO, in this paper) can search the global optimum with saving computational capacity with good initial solutions using Vｊ probabilistically for the data clustering. The performance of our proposed method is validated to save significantly computation time against the original silhouette only using Ruspini, Iris, Wine and Breast cancer in UCI machine learning repository datasets by experiment and analysis. Especially, the performance of our proposed method is much better than previous method for the larger size of data."
Multi-Radial Basis Function SVM Classifier: Design and Analysis,2018,"['Multi-RBF SVM', 'Composite kernel', 'Dual RBF structure', 'Clustering method', 'Particle Swam optimization']",,"In this study, Multi-Radial Basis Function Support Vector Machine (Multi-RBF SVM) classifier is introduced based on a composite kernel function. In the proposed multi-RBF support vector machine classifier, the input space is divided into several local subsets considered for extremely nonlinear classification tasks. Each local subset is expressed as nonlinear classification subspace and mapped into feature space by using kernel function. The composite kernel function employs the dual RBF structure. By capturing the nonlinear distribution knowledge of local subsets, the training data is mapped into higher feature space, then Multi-SVM classifier is realized by using the composite kernel function through optimization procedure similar to conventional SVM classifier. The original training data set is partitioned by using some unsupervised learning methods such as clustering methods. In this study, three types of clustering method are considered such as Affinity propagation (AP), Hard C-Mean (HCM) and Iterative Self-Organizing Data Analysis Technique Algorithm (ISODATA). Experimental results on benchmark machine learning datasets show that the proposed method improves the classification performance efficiently."
Unethical Network Attack Detection and Prevention using Fuzzy based Decision System in Mobile Ad-hoc Networks,2018,"['MANET', 'Intrusion detection and prevention system', 'Intelligent client agent', 'Smart server', 'Fuzzy inference', 'IBH_IDPS']",,"Security plays a vital role and is the key challenge in Mobile Ad-hoc Networks (MANET). Infrastructure-less nature of MANET makes it arduous to envisage the genre of topology. Due to its inexhaustible access, information disseminated by roaming nodes to other nodes is susceptible to many hazardous attacks. Intrusion Detection and Prevention System (IDPS) is undoubtedly a defense structure to address threats in MANET. Many IDPS methods have been developed to ascertain the exceptional behavior in these networks. Key issue in such IDPS is lack of fast self-organized learning engine that facilitates comprehensive situation awareness for optimum decision making. Proposed ""Intelligent Behavioral Hybridized Intrusion Detection and Prevention System (IBH_IDPS)"" is built with computational intelligence to detect complex multistage attacks making the system robust and reliable. The System comprises of an Intelligent Client Agent and a Smart Server empowered with fuzzy inference rule-based service engine to ensure confidentiality and integrity of network. Distributed Intelligent Client Agents incorporated with centralized Smart Server makes it capable of analyzing and categorizing unethical incidents appropriately through unsupervised learning mechanism. Experimental analysis proves the proposed model is highly attack resistant, reliable and secure on devices and shows promising gains with assured delivery ratio, low end-to-end delay compared to existing approach."
Unethical Network Attack Detection and Prevention using Fuzzy based Decision System in Mobile Ad-hoc Networks,2018,"['MANET', 'Intrusion detection and prevention system', 'Intelligent client agent', 'Smart server', 'Fuzzy inference', 'IBH_IDPS']",,"Security plays a vital role and is the key challenge in Mobile Ad-hoc Networks (MANET). Infrastructure-less nature of MANET makes it arduous to envisage the genre of topology. Due to its inexhaustible access, information disseminated by roaming nodes to other nodes is susceptible to many hazardous attacks. Intrusion Detection and Prevention System (IDPS) is undoubtedly a defense structure to address threats in MANET. Many IDPS methods have been developed to ascertain the exceptional behavior in these networks. Key issue in such IDPS is lack of fast self-organized learning engine that facilitates comprehensive situation awareness for optimum decision making. Proposed “Intelligent Behavioral Hybridized Intrusion Detection and Prevention System (IBH_IDPS)” is built with computational intelligence to detect complex multistage attacks making the system robust and reliable. The System comprises of an Intelligent Client Agent and a Smart Server empowered with fuzzy inference rule-based service engine to ensure confidentiality and integrity of network. Distributed Intelligent Client Agents incorporated with centralized Smart Server makes it capable of analyzing and categorizing unethical incidents appropriately through unsupervised learning mechanism. Experimental analysis proves the proposed model is highly attack resistant, reliable and secure on devices and shows promising gains with assured delivery ratio, low end-to-end delay compared to existing approach."
Multi-Radial Basis Function SVM Classifier,2018,"['Multi-RBF SVM', 'Composite kernel', 'Dual RBF structure', 'Clustering method', 'Particle Swam optimization']",,"In this study, Multi-Radial Basis Function Support Vector Machine (Multi-RBF SVM) classifier is introduced based on a composite kernel function. In the proposed multi- RBF support vector machine classifier, the input space is divided into several local subsets considered for extremely nonlinear classification tasks. Each local subset is expressed as nonlinear classification subspace and mapped into feature space by using kernel function. The composite kernel function employs the dual RBF structure. By capturing the nonlinear distribution knowledge of local subsets, the training data is mapped into higher feature space, then Multi-SVM classifier is realized by using the composite kernel function through optimization procedure similar to conventional SVM classifier. The original training data set is partitioned by using some unsupervised learning methods such as clustering methods. In this study, three types of clustering method are considered such as Affinity propagation (AP), Hard CMean (HCM) and Iterative Self-Organizing Data Analysis Technique Algorithm (ISODATA). Experimental results on benchmark machine learning datasets show that the proposed method improves the classification performance efficiently."
합성곱 신경망을 이용한 농산물 기사 감성 분석,2018,"['감성분석', '오피니언 마이닝', '텍스트 마이닝', '농산물가격', '합성곱 신경망', 'emotional analysis', 'opinion mining', 'text mining', 'agricultural price', 'convolutional neural networks']","본 논문에서는 농산물 가격의 등락을 기준으로 감성사전을 구축하여 농산물 관련 온라인 뉴스의 긍정/부정을 분류하는 방법을 제안한다. 이를 위해 비정형 텍스트문서를 문장 단위로 분할한 뒤 분석내용과 연관 없거나 가격 등락에 상관없이 빈번하게 언급된 단어들을 불용어로 처리한다. 형태소 분석을 진행한 후 비지도 학습 기반으로 키워드를 추출하여 합성곱 신경망(Convolutional Neural Networks, CNN)을 이용해 긍정/부정 분류를 수행하였다. 그 결과 빈도기반 키워드를 이용한 긍정/부정 분류보다 비지도 학습기반 키워드 추출과 인공신경망의 일종인 합성곱 신경망을 이용했을 때 약 20% 이상 분류 정확도가 향상되었다.","In this paper, we propose a method for sentiment analysis of online news by constructing emotional dictionary base on the fluctuation in prices of various agriculture products. The collected unstructured text data were segmented into sentences and the frequently mentioned words which were not related to price fluctuation were removed as stop words. After the morphological analysis, the keyword was extracted based on the unsupervised learning and the experiments were conducted based on the proposed model using the convolutional neural network (CNN). Consequently, about 20% improvement in accuracy was observed when CNN was used than the word frequency based method."
강우량-지속시간-침수량 관계곡선과 자기조직화 지도의 연계를 통한 범람범위 추정,2018,"['Urban inundation', 'Self-organizing feature map', 'SWMM', 'Flood forecast and warning', '도시 침수', '자기조직화 특징 지도', 'SWMM', '홍수 예․경보']","집중호우에 의한 도시 유역의 침수 피해가 도시화에 따라 증가하는 추세이며, 이에 따라 정확하면서도 신속한 홍수예보 및 침수 예상도 표출이 필요하다. 특정 강우량에 따른 미지의 침수 범위를 예상하는 것은 도시 유역의 홍수에 대한 사전 대비에 매우 중요한 사안이며, 이를 위해 현재 홍수 예보와 관련된 정부기관에서 침수 피해 예상도를 주민들에게 제공하고자 하고 있다. 하지만, 특정 강우에 따른 정확한 침수 범위를 정량화하여 표출하는데 부족함이 있으며, 강우량과 지속시간에 따른 홍수의 크기에 대한 분석을 실시하고 수리학적 연계를 통한 준 실시간 침수범위 표출 방안을 고찰해야할 시기이다. 제시된 물리적 해석기반 자료를 이용하여 강우량-지속시간-침수량 관계곡선(Rainfall-Duration-Floodingquantity relationship curve, RDF)을 제시하고, 자율학습을 수행하는 자기조직화 특징 지도와 연계하여 미지의 침수 지도를 예측하였다. 예측한 침수 지도와 2차원 침수모형을 통한 결과를 비교하여, 제시된 방법론의 타당성을 검토하였다. 연구 결과를 통하여 중규모의 강우량 또는 빈도의 사상에 따른 미지의 침수범위를 제시하는데 용이할 것으로 판단된다. 더욱이 다양한 강우-월류량-홍수 양상을 내포하는 RDF 관계 곡선과 최적 침수예상도 데이터베이스를 구축함으로서 추후에 홍수예보의 기초자료로서 사용될 것이다.","The flood damage in urban areas due to torrential rain is increasing with urbanization. For this reason, accurate and rapid floodingforecasting and expected inundation maps are needed. Predicting the extent of flooding for certain rainfalls is a very important issuein preparing flood in advance. Recently, government agencies are trying to provide expected inundation maps to the public. However, there is a lack of quantifying the extent of inundation caused by a particular rainfall scenario and the real-time prediction method for flood extent within a short time. Therefore the real-time prediction of flood extent is needed based on rainfall-runoff-inundation analysis. One/two dimensional model are continued to analyize drainage network, manhole overflow and inundation propagation by rainfall condition. By applying the various rainfall scenarios considering rainfall duration/distribution and return periods, the inundation volume and depth can be estimated and stored on a database. The Rainfall-Duration-Flooding Quantity (RDF) relationship curve based on the hydraulic analysis results and the Self-Organizing Map (SOM) that conducts unsupervised learning are applied to predict flooded area with particular rainfall condition. The validity of the proposed methodology was examined by comparing the results of the expected flood map with the 2-dimensional hydraulic model. Based on the result of the study, it is judged that this methodology will be useful to provide an unknown flood map according to medium-sized rainfall or frequency scenario. Furthermore, it will be used asa fundamental data for flood forecast by establishing the RDF curve which the relationship of rainfall-outflow-flood is considered andthe database of expected inundation maps."
차분진화를 이용한 독립성분 분석법과 선형판별 분석법 기반 부분방전 패턴 분류기 설계,2018,"['독립성분 분석법', '선형판별 분석법', '차분진화', 'PRPD 분석법', '퍼지 클러스터링', '웨카', '신경회로망', 'Independent Component Analysis(ICA)', 'Linear Discriminant Analysis(LDA)', 'Differential Evolution(DE)', 'Phase Resolved Partial Discharge Analysis', 'Fuzzy C-Means Clustering', 'Weka', 'Neural Networks']","본 연구는 독립성분 분석법과 선형판별 분석법을 사용하여 실현된 퍼지클러스터링 기반의 신경회로망 분류기의 설계방법과 관련된다. 여기서 독립성분 분석법은 조건부 단계 전의 전처리방법으로 사용되고, 선형판별 분석법은 분류기의 결론부에서 파라미터 추정으로 이용된다. 그리고 차분진화를 통해 패턴 분류기의 최적화된 입력변수, 퍼지화계수, 및 규칙 수가 조정된다. 비감독 학습 방법인 퍼지 C-Means 클러스터링은 전체 입력공간을 부분 데이터 공간 즉 퍼지규칙의 수(혹은 클러스터 수)로 나눈다. 부분방전데이터는 PRPD 분석법을 이용하여 방전 크기와 방전 수의 정보를 받는다. MIMS 프로그램으로 3개의 특징 데이터를 추출하며, 각 데이터의 특징과 패턴을 비교 및 분석한다. 제안된 분류기의 성능평가를 위하여, 제안된 분류기와 Weka를 통해 구한 패턴 분류율의 비교결과를 나타낸다.","This study is concerned with the design methodology of FCM-based neural network classifier realized with the aid of Independent Component Analysis(ICA) and Linear Discriminant Analysis(LDA). Here ICA is used as the preprocessing method before the condition phase, LDA is exploited for parameter estimation in the conclusion phase of the classifier. And the pattern classifier for the optimized input variable, fuzzification parameter and the number of rules are adjusted through the Differential Evolution(DE). Fuzzy C-Means clustering of unsupervised learning method divides the entire input space into local spaces as the number of fuzzy rules (or clusters). The partial discharge data receives information on the discharge size and discharge number using Phase Resolved Partial Discharge(PRPD) analysis. Three feature data are extracted by the Motor Insulation Monitoring System(MIMS) program, and the features and patterns of each data are compared and analyzed. In order to evaluate the performance of the proposed classifier, we show the comparison result of the pattern classification ratio obtained by the proposed classifier and Weka."
텍스트 마이닝 기법을 적용한 뉴스 데이터에서의사건 네트워크 구축,2018,"['event detection', 'latent Dirichlet allocation (LDA)', 'natural language processing (NLP)', 'text mining', 'topic modeling', '사건 네트워크', '사건탐지', '자연어처리(NLP)', '텍스트 마이닝', '토픽모델링']","전통적으로 신문 매체는 국내외에서 발생하는 사건들을 살피는 데에 가장 적합한 매체이다. 최근에는 정보통신 기술의 발달로 온라인 뉴스 매체가 다양하게 등장하면서 주변에서 일어나는 사건들에 대한 보도가 크게증가하였고, 이것은 독자들에게 많은 양의 정보를 보다 빠르고 편리하게 접할 기회를 제공함과 동시에 감당할수 없는 많은 양의 정보소비라는 문제점도 제공하고 있다. 본 연구에서는 방대한 양의 뉴스기사로부터 데이터를 추출하여 주요 사건을 감지하고, 사건들 간의 관련성을 판단하여 사건 네트워크를 구축함으로써 독자들에게현시적이고 요약적인 사건정보를 제공하는 기법을 제안하는 것을 목적으로 한다. 이를 위해 2016년 3월에서2017년 3월까지의 한국 정치 및 사회 기사를 수집하였고, 전처리과정에서 NPMI와 Word2Vec 기법을 활용하여고유명사 및 합성명사와 이형동의어 추출의 정확성을 높였다. 그리고 LDA 토픽 모델링을 실시하여 날짜별로주제 분포를 계산하고 주제 분포의 최고점을 찾아 사건을 탐지하는 데 사용하였다. 또한 사건 네트워크를 구축하기 위해 탐지된 사건들 간의 관련성을 측정을 위하여 두 사건이 같은 뉴스 기사에 동시에 등장할수록 서로더 연관이 있을 것이라는 가정을 바탕으로 코사인 유사도를 확장하여 관련성 점수를 계산하는데 사용하였다.최종적으로 각 사건은 각각의 정점으로, 그리고 사건 간의 관련성 점수는 정점들을 잇는 간선으로 설정하여 사건 네트워크를 구축하였다. 본 연구에서 제시한 사건 네트워크는 1년간 한국에서 발생했던 정치 및 사회 분야의 주요 사건들이 시간 순으로 정렬되었고, 이와 동시에 특정 사건이 어떤 사건과 관련이 있는지 파악하는데도움을 주었다. 또한 일련의 사건들의 시발점이 되는 사건이 무엇이었는가도 확인이 가능하였다. 본 연구는 텍스트 전처리 과정에서 다양한 텍스트 마이닝 기법과 새로이 주목받고 있는 Word2vec 기법을 적용하여 봄으로써 기존의 한글 텍스트 분석에서 어려움을 겪고 있었던 고유명사 및 합성명사 추출과 이형동의어의 정확도를높였다는 것에서 학문적 의의를 찾을 수 있다. 그리고, LDA 토픽 모델링을 활용하기에 방대한 양의 데이터를쉽게 분석 가능하다는 것과 기존의 사건 탐지에서는 파악하기 어려웠던 사건 간 관련성을 주제 동시출현을 통해 파악할 수 있다는 점에서 기존의 사건 탐지 방법과 차별화된다.","News articles are the most suitable medium for examining the events occurring at home and abroad. Especially, as the development of information and communication technology has brought various kinds of online news media, the news about the events occurring in society has increased greatly. So automatically summarizing key events from massive amounts of news data will help users to look at many of the events at a glance. In addition, if we build and provide an event network based on the relevance of events, it will be able to greatly help the reader in understanding the current events.In this study, we propose a method for extracting event networks from large news text data. To this end, we first collected Korean political and social articles from March 2016 to March 2017, and integrated the synonyms by leaving only meaningful words through preprocessing using NPMI and Word2Vec. Latent Dirichlet allocation (LDA) topic modeling was used to calculate the subject distribution by date and to find the peak of the subject distribution and to detect the event. A total of 32 topics were extracted from the topic modeling, and the point of occurrence of the event was deduced by looking at the point at which each subject distribution surged. As a result, a total of 85 events were detected, but the final 16 events were filtered and presented using the Gaussian smoothing technique. We also calculated the relevance score between events detected to construct the event network. Using the cosine coefficient between the co-occurred events, we calculated the relevance between the events and connected the events to construct the event network. Finally, we set up the event network by setting each event to each vertex and the relevance score between events to the vertices connecting the vertices. The event network constructed in our methods helped us to sort out major events in the political and social fields in Korea that occurred in the last one year in chronological order and at the same time identify which events are related to certain events.Our approach differs from existing event detection methods in that LDA topic modeling makes it possible to easily analyze large amounts of data and to identify the relevance of events that were difficult to detect in existing event detection. We applied various text mining techniques and Word2vec technique in the text preprocessing to improve the accuracy of the extraction of proper nouns and synthetic nouns, which have been difficult in analyzing existing Korean texts, can be found.In this study, the detection and network configuration techniques of the event have the following advantages in practical application. First, LDA topic modeling, which is unsupervised learning, can easily analyze subject and topic words and distribution from huge amount of data. Also, by using the date information of the collected news articles, it is possible to express the distribution by topic in a time series.Second, we can find out the connection of events in the form of present and summarized form by calculating relevance score and constructing event network by using simultaneous occurrence of topics that are difficult to grasp in existing event detection. It can be seen from the fact that the inter-event relevance-based event network proposed in this study was actually constructed in order of occurrence time. It is also possible to identify what happened as a starting point for a series of events through the event network.The limitation of this study is that the characteristics of LDA topic modeling have different results according to the initial parameters and the number of subjects, and the subject and event name of the analysis result should be given by the subjective judgment of the researcher. Also, since each topic is assumed to be exclusive and independent, it does not take into account the relevance between themes. Subsequent studies need to calculate the relevance between events that are not covered..."
