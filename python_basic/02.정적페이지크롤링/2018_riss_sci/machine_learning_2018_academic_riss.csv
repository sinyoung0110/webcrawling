title,date,keywords,abstract,multilingual_abstract
Machine Learning based Prediction of The Value of Buildings,2018,"['Machine Learning', 'Random Forest', 'Fully Connected Network', 'Deep Learning']",,"Due to the lack of visualization services and organic combinations between public and private buildings data, the usability of the basic map has remained low. To address this issue, this paper reports on a solution that organically combines public and private data while providing visualization services to general users. For this purpose, factors that can affect building prices first were examined in order to define the related data attributes. To extract the relevant data attributes, this paper presents a method of acquiring public information data and real estate-related information, as provided by private real estate portal sites. The paper also proposes a pretreatment process required for intelligent machine learning. This report goes on to suggest an intelligent machine learning algorithm that predicts buildings’ value pricing and future value by using big data regarding buildings’ spatial information, as acquired from a database containing building value attributes. The algorithm’s availability was tested by establishing a prototype targeting pilot areas, including Suwon, Anyang, and Gunpo in South Korea. Finally, a prototype visualization solution was developed in order to allow general users to effectively use buildings’ value ranking and value pricing, as predicted by intelligent machine learning."
Selecting the Optimal Hidden Layer of Extreme Learning Machine Using Multiple Kernel Learning,2018,"['Extreme learning machine', 'multiple kernel learning', 'hidden layer kernel', 'optimization']",,"Extreme learning machine (ELM) is emerging as a powerful machine learning method in a variety of application scenarios due to its promising advantages of high accuracy, fast learning speed and easy of implementation. However, how to select the optimal hidden layer of ELM is still an open question in the ELM community. Basically, the number of hidden layer nodes is a sensitive hyperparameter that significantly affects the performance of ELM. To address this challenging problem, we propose to adopt multiple kernel learning (MKL) to design a multi-hidden-layer-kernel ELM (MHLK-ELM). Specifically, we first integrate kernel functions with random feature mapping of ELM to design a hidden-layer-kernel ELM (HLK-ELM), which serves as the base of MHLK-ELM. Then, we utilize the MKL method to propose two versions of MHLK-ELMs, called sparse and non-sparse MHLK-ELMs. Both two types of MHLK-ELMs can effectively find out the optimal linear combination of multiple HLK-ELMs for different classification and regression problems. Experimental results on seven data sets, among which three data sets are relevant to classification and four ones are relevant to regression, demonstrate that the proposed MHLK-ELM achieves superior performance compared with conventional ELM and basic HLK-ELM."
An Intelligent MAC Protocol Selection Method based on Machine Learning in Wireless Sensor Networks,2018,"['MAC protocol', 'machine learning', 'classification', 'competitive protocol', 'non-competitive protocol']",,"Wireless sensor network has been widely used in Internet of Things (IoT) applications to support large and dense networks. As sensor nodes are usually tiny and provided with limited hardware resources, the existing multiple access methods, which involve high computational complexity to preserve the protocol performance, is not available under such a scenario. In this paper, we propose an intelligent Medium Access Control (MAC) protocol selection scheme based on machine learning in wireless sensor networks. We jointly consider the impact of inherent behavior and external environments to deal with the application limitation problem of the single type MAC protocol. This scheme can benefit from the combination of the competitive protocols and non-competitive protocols, and help the network nodes to select the MAC protocol that best suits the current network condition. Extensive simulation results validate our work, and it also proven that the accuracy of the proposed MAC protocol selection strategy is higher than the existing work."
기계학습(Machine Learning)과 전자증거- 기술기반 검토(Technology Assisted Review)에 대한 미국의 논의를 중심으로 -,2018,"['electronic evidence', 'machine learning', 'recall rate', 'precision rate', 'discovery', 'electronic stored information(ESI)', '전자증거', '기계학습', '재현율', '정밀도', '증거개시절차', '전자적으로 저장된 자료']",,"With the advent of e-mail, databases, and the capacity to store even more electronic information, there’s no doubt that the number of electronic records will continue to grow. This has and will continue to significantly increase the costs of litigation, especially during the discovery phase. In many cases, manually reviewing documents is not acceptable due to the large amount of documents that need to be reviewed. This is a major reason why U.S. courts are now starting to accept technology assisted review(TAR). This article provides a current analysis of TAR and implications toward our civil procedure system."
Analysis on Trends of Machine Learning-as-a-Service,2018,"['AI', 'Machine Learning', 'Machine Learning-as-a-Service', 'MLaaS']",,
Predicting Game Results using Machine Learning -MMORPG TERA : Focusing on the Rikanor Arena,2018,"['Game', 'Machine learning', 'Tensorflow', 'Neural Network', 'Predict']",,"Recently, much attention has been paid to machine learning - especially deep learning. As big companies like Google, Facebook are interested in AI and machine learning, these research is being developed day by day. Machine learning is expected to be used in various industries such as medical, translation, and IT. The game sector is also considered one of the areas where the effects of applying machine learning technology are expected. In this paper, we designed a Neural Network that predicts the win / loss of monsters in MMORPG-Tera’s Game contents. We designed the model through Tensorflow. This model has 1 input layer, 2 hidden layer and 1 output layer. There are 8 nodes in input layer, 16 nodes in each hidden layer and 1 nodes in output layer. For the better results we use Adam for gradient descent, Sigmoid function and Relu function for Activate function. The last part of the prepared dataset was used for the test data and the rest was used for the learning model. This model is able to predict the odds within 5 ~ 10 % error. The lack of datasets is left as an unsatisfactory point, it will be possible to reduce the error further if sufficient data is acquired and more improved model is prepared. And this proposed model will be applied to other games or sports games in the future."
Analysis on Trends of Machine Learning-as-a-Service,2018,"['AI', 'Machine Learning', 'Machine Learning-as-a-Service', 'MLaaS']",,"Demand is increasing rapidly in recent years than supply to machine learning professionals. To alleviate this gap, user-friendly machine learning software that can be used by non-specialists has emerged, which is Machine Learning-as-a-Service(MLaaS). MLaaS provides services that enable businesses to easily leverage ML capabilities without expertise.In this paper, we will compare and analyze features, interfaces, supporting programming language, ML framework, and Machine Learning services of MLaaS, to help companies easily use ML service."
Analysis on Trends of Machine Learning-as-a-Service,2018,"['AI', 'Machine Learning', 'Machine Learning-as-a-Service', 'MLaaS']",,"Demand is increasing rapidly in recent years than supply to machine learning professionals. To alleviate this gap, user-friendly machine learning software that can be used by non-specialists has emerged, which is Machine Learning-as-a-Service(MLaaS). MLaaS provides services that enable businesses to easily leverage ML capabilities without expertise. In this paper, we will compare and analyze features, interfaces, supporting programming language, ML framework, and Machine Learning services of MLaaS, to help companies easily use ML service."
Smart Machining Process Using Machine Learning: A Review and Perspective on Machining Industry,2018,"['4th industrial revolution', 'Artificial intelligence', 'Machine learning', 'Machining process', 'Machining industry']",,"The Fourth Industrial Revolution incorporates the digital revolution into the physical world, creating a new direction in a number of fields, including artificial intelligence, quantum computing, nanotechnology, biotechnology, robotics, 3D printing, autonomous vehicles, and the Internet of Things. The artificial intelligence field has encountered a turning point mainly due to advancements in machine learning, which allows machines to learn, improve, and perform a specific task through data without being explicitly programmed. Machine learning can be utilized with machining processes to improve product quality levels and productivity rates, to monitor the health of systems, and to optimize design and process parameters. This is known as smart machining, referring to a new machining paradigm in which machine tools are fully connected through a cyber-physical system. This paper reviews and summarizes machining processes using machine learning algorithms and suggests a perspective on the machining industry."
Short-term Wind Power Prediction Based on Empirical Mode Decomposition and Improved Extreme Learning Machine,2018,"['Short-term wind power', 'Prediction', 'Empirical mode decomposition', 'Improved extreme learning machine']",,"For the safe and stable operation of the power system, accurate wind power prediction is of great significance. A wind power prediction method based on empirical mode decomposition and improved extreme learning machine is proposed in this paper. Firstly, wind power time series is decomposed into several components with different frequency by empirical mode decomposition, which can reduce the non-stationary of time series. The components after decomposing remove the long correlation and promote the different local characteristics of original wind power time series. Secondly, an improved extreme learning machine prediction model is introduced to overcome the sample data updating disadvantages of standard extreme learning machine. Different improved extreme learning machine prediction model of each component is established. Finally, the prediction value of each component is superimposed to obtain the final result. Compared with other prediction models, the simulation results demonstrate that the proposed prediction method has better prediction accuracy for wind power."
Short-term Wind Power Prediction Based on Empirical Mode Decomposition and Improved Extreme Learning Machine,2018,"['Short-term wind power', 'Prediction', 'Empirical mode decomposition', 'Improved extreme learning machine']",,"For the safe and stable operation of the power system, accurate wind power prediction is of great significance. A wind power prediction method based on empirical mode decomposition and improved extreme learning machine is proposed in this paper. Firstly, wind power time series is decomposed into several components with different frequency by empirical mode decomposition, which can reduce the non-stationary of time series. The components after decomposing remove the long correlation and promote the different local characteristics of original wind power time series. Secondly, an improved extreme learning machine prediction model is introduced to overcome the sample data updating disadvantages of standard extreme learning machine. Different improved extreme learning machine prediction model of each component is established. Finally, the prediction value of each component is superimposed to obtain the final result. Compared with other prediction models, the simulation results demonstrate that the proposed prediction method has better prediction accuracy for wind power."
Machine Learning을 이용한 무기 체계(or 구성품) 고장 유형 식별,2018,"['Machine learning', 'doc2vec', 'Clustering', 'Visualization', 'Failure mode', 'Weapon System']","무기 체계(or 구성품) 개발은 한정된 개발기간과비용 등의 제한으로 시험 횟수가 많지 않아, 고장관련 축적된 데이터의 규모도 적다. 그러나 운용 중 발생한 고장 및 정비내역은 많은 부분 전산 데이터로 관리하고 있기 때문에 이를 활용한 무기 체계(or 구성품)의 고장원인 분석은 가능하다. 다만 다양한 무기체계의 고장 및 정비내역 작성 규격이 각 군 별, 업체별 상이하고, 고장 원인의 구체적 내역은 비정형 텍스트 데이터로 기술되어 있기때문에 이를 분석하는데 어려움이 있었다. 그러나 오늘날 빅데이터 처리 기술과 기계학습(Machine Learning) 알고리즘의 발전, HW연산 능력의 개선과 맞물려, 상기와 같은 비정형 데이터를 처리 할 수 있는 여러 가지 방법들이 시도 되고 있으며, 주요한 연구 분야로 활발히 연구되고 있다. 본 논문에서는 국방 무기 체계(or 구성품)의 고장/정비 관련 비정형 데이터를 기계학습 기법 중 하나인 doc2vec을 적용하여 고장사례 분석 방안에 대하여 제시한다.","The development of weapon systems (or components) is hindered by the number of tests due to the limited development period and cost, which reduces the scale of accumulated data related to failures. Nevertheless, because a large amount of failure data and maintenance details during the operational period are managed by computerized data, the cause of failure of weapon systems (or components) can be analyzed using the data. On the other hand, analyzing the failure and maintenance details of various weapon systems is difficult because of the variation among groups and companies, and details of the cause of failure are described as unstructured text data. Fortunately, the recent developments of big data processing technology, machine learning algorithm, and improved HW computation ability have supported major research into various methods for processing the above unstructured data. In this paper, unstructured data related to the failure / maintenance of defense weapon systems (or components) is presented by applying doc2vec, a machine learning technique, to analyze the failure cases."
IoT Livestock Estrus Monitoring System based on Machine Learning,2018,"['Internet of Things', 'Estrus Detection', 'Machine Learning', 'Livestock Monitoring', 'Smart Farm']",,"Machine learning is an artificial intelligence technology that analyzes data and builds data-based models, and its role in Internet-of-Things (IoT) applications is growing. In current ranches, artificial insemination is performed to make cows pregnant. Accurate estrus detection of cows is essential for the success in artificial insemination. The traditional method to detect estrus of cows is visual observation, whose success rate largely depends on the observers' experience and the frequency of observation. The integration of IoT and machine learning enables livestock diseases and estrus to be predicted. Livestock activity was measured by acceleration sensors attached to animals. Then, a system was created that can identify atypical symptoms such as those of disease and estrus. To predict calving dates in breeding cows, behavioral patterns were analyzed using machine-learning algorithms. Finally, only simple judgments by owners are required to decide whether artificial insemination will be performed."
Authorship Attribution in Huayan Texts by Machine Learning using N-gram and SVM,2018,"['Authorship Attribution', 'Machine Learning', 'N-Gram', 'SVM', 'Fazang']",,"This paper aims to evaluate the authorship of Buddhist texts in the classical Chinese language, specifically focusing on Fazang’s Huayan texts, using computational statistical methods. I also briefly introduce the basic ideas and processes related to this estimation. Regarding statistical techniques, this paper utilizes n-gram and one-class SVM (Support Vector Machine), a technique of machine learning.The authorship attribution (AA) process in stylometry using machine learning can be divided into the following three stages: (1) Building a Corpus → (2) Extracting a Feature Set → (3) Learning and Predicting Authorship.From the results of the tests, the following can be estimated.(1) This one-class SVM model is somewhat reliable given that training observations and regular tests are distributed in similar regions and abnormal tests are in different regions.(2) As the target is located in a different area from the training observations and the regular test area, the target is not likely to be Fazang’s work.(3) However, considering the fact that it is closer to training observations and regular tests than an abnormal test by Zhiyan’s writing, it can be inferred that the Huayanjing wenda is closer to Fazang’s writing than Zhiyan’s.One thing to keep in mind is that this is only a preliminary test. However, I think that there is enough meaning to show the possibility and direction about AA in Chinese Buddhist literature."
Improving Performance of Machine Learning-based Haze Removal Algorithms with Enhanced Training Database,2018,"['uniform distribution', 'equidistribution', 'enhanced equidistribution', 'haze removal', 'machine learning', 'training database']",,"Haze removal is an object of scientific desire due to its various practical applications. Existing algorithms are founded upon histogram equalization, contrast maximization, or the growing trend of applying machine learning in image processing. Since machine learning-based algorithms solve problems based on the data, they usually perform better than those based on traditional image processing/computer vision techniques. However, to achieve such a high performance, one of the requisites is a large and reliable training database, which seems to be unattainable owing to the complexity of real hazy and haze-free images acquisition. As a result, researchers are currently using the synthetic database, obtained by introducing the synthetic haze drawn from the standard uniform distribution into the clear images. In this paper, we propose the enhanced equidistribution, improving upon our previous study on equidistribution, and use it to make a new database for training machine learning-based haze removal algorithms. A large number of experiments verify the effectiveness of our proposed methodology."
"Design of a machine learning based mobile application with GPS, mobile sensors, public GIS : real time prediction on personal daily routes",2018,"['global position system(GPS)', 'public geographic information system(GIS) data', 'mobile sensors', 'machine learning', 'inference rules', 'daily route prediction.']",,"Since the global positioning system (GPS) has been included in mobile devices (e.g., for car navigation, in smartphones, and in smart watches), the impact of personal GPS log data on daily life has been unprecedented. For example, such log data have been used to solve public problems, such as mass transit traffic patterns, finding optimum travelers’ routes, and determining prospective business zones. However, a real-time analysis technique for GPS log data has been unattainable due to theoretical limitations. We introduced a machine learning model in order to resolve the limitation. In this paper presents a new, three-stage real-time prediction model for a person's daily route activity. In the first stage, a machine learning–based clustering algorithm is adopted for place detection. The training data set was a personal GPS tracking history. In the second stage, prediction of a new person's transient mode is studied. In the third stage, to represent the person's activity on those daily routes, inference rules are applied."
"Design of a machine learning based mobile application with GPS, mobile sensors, public GIS: real time prediction on personal daily routes",2018,"['global position system(GPS)', 'public geographic information system(GIS) data', 'mobile sensors', 'machine learning', 'inference rules', 'daily route prediction']",,"Since the global positioning system (GPS) has been included in mobile devices (e.g., for car navigation, in smartphones, and in smart watches), the impact of personal GPS log data on daily life has been unprecedented. For example, such log data have been used to solve public problems, such as mass transit traffic patterns, finding optimum travelers' routes, and determining prospective business zones. However, a real-time analysis technique for GPS log data has been unattainable due to theoretical limitations. We introduced a machine learning model in order to resolve the limitation. In this paper presents a new, three-stage real-time prediction model for a person's daily route activity. In the first stage, a machine learning-based clustering algorithm is adopted for place detection. The training data set was a personal GPS tracking history. In the second stage, prediction of a new person's transient mode is studied. In the third stage, to represent the person's activity on those daily routes, inference rules are applied."
"Design of a machine learning based mobile application with GPS, mobile sensors, public GIS: real time prediction on personal daily routes",2018,"['global position system(GPS)', 'public geographic information system(GIS) data', 'mobile sensors', 'machine learning', 'inference rules', 'daily route prediction.']",,"Since the global positioning system (GPS) has been included in mobile devices (e.g., for car navigation, in smartphones, and in smart watches), the impact of personal GPS log data on daily life has been unprecedented. For example, such log data have been used to solve public problems, such as mass transit traffic patterns, finding optimum travelers’ routes, and determining prospective business zones. However, a real-time analysis technique for GPS log data has been unattainable due to theoretical limitations. We introduced a machine learning model in order to resolve the limitation. In this paper presents a new, three-stage real-time prediction model for a person's daily route activity. In the first stage, a machine learning–based clustering algorithm is adopted for place detection. The training data set was a personal GPS tracking history. In the second stage, prediction of a new person's transient mode is studied. In the third stage, to represent the person's activity on those daily routes, inference rules are applied."
"Design of a machine learning based mobile application with GPS, mobile sensors, public GIS : real time prediction on personal daily routes",2018,"['global position system(GPS)', 'public geographic information system(GIS) data', 'mobile sensors', 'machine learning', 'inference rules', 'daily route prediction.']",,"Since the global positioning system (GPS) has been included in mobile devices (e.g., for car navigation, in smartphones, and in smart watches), the impact of personal GPS log data on daily life has been unprecedented. For example, such log data have been used to solve public problems, such as mass transit traffic patterns, finding optimum travelers’ routes, and determining prospective business zones. However, a real-time analysis technique for GPS log data has been unattainable due to theoretical limitations. We introduced a machine learning model in order to resolve the limitation. In this paper presents a new, three-stage real-time prediction model for a person's daily route activity. In the first stage, a machine learning–based clustering algorithm is adopted for place detection. The training data set was a personal GPS tracking history. In the second stage, prediction of a new person's transient mode is studied. In the third stage, to represent the person's activity on those daily routes, inference rules are applied."
Improving Performance of Machine Learning-based Haze Removal Algorithms with Enhanced Training Database,2018,"['uniform distribution', 'equidistribution', 'enhanced equidistribution', 'haze removal', 'machine learning', 'training database']",,"Haze removal is an object of scientific desire due to its various practical applications. Existing algorithms arefounded upon histogram equalization, contrast maximization, or the growing trend of applying machine learning inimage processing. Since machine learning-based algorithms solve problems based on the data, they usuallyperform better than those based on traditional image processing/computer vision techniques. However, to achievesuch a high performance, one of the requisites is a large and reliable training database, which seems to beunattainable owing to the complexity of real hazy and haze-free images acquisition. As a result, researchers arecurrently using the synthetic database, obtained by introducing the synthetic haze drawn from the standarduniform distribution into the clear images. In this paper, we propose the enhanced equidistribution, improving uponour previous study on equidistribution, and use it to make a new database for training machine learning-basedhaze removal algorithms. A large number of experiments verify the effectiveness of our proposed methodology"
A Novel Fundus Image Reading Tool for Efficient Generation of a Multi-dimensional Categorical Image Database for Machine Learning Algorithm Training,2018,"['Retina Fundus Image', 'Reading Tool', 'Grader', 'Machine Learning', 'Deep Learning']",,"Background: We described a novel multi-step retinal fundus image reading system for providing high-quality large data for machine learning algorithms, and assessed the grader variability in the large-scale dataset generated with this system.Methods: A 5-step retinal fundus image reading tool was developed that rates image quality, presence of abnormality, findings with location information, diagnoses, and clinical significance. Each image was evaluated by 3 different graders. Agreements among graders for each decision were evaluated.Results: The 234,242 readings of 79,458 images were collected from 55 licensed ophthalmologists during 6 months. The 34,364 images were graded as abnormal by at-least one rater. Of these, all three raters agreed in 46.6% in abnormality, while 69.9% of the images were rated as abnormal by two or more raters. Agreement rate of at-least two raters on a certain finding was 26.7%–65.2%, and complete agreement rate of all-three raters was 5.7%–43.3%. As for diagnoses, agreement of at-least two raters was 35.6%–65.6%, and complete agreement rate was 11.0%–40.0%. Agreement of findings and diagnoses were higher when restricted to images with prior complete agreement on abnormality.Retinal/glaucoma specialists showed higher agreements on findings and diagnoses of their corresponding subspecialties.Conclusion: This novel reading tool for retinal fundus images generated a large-scale dataset with high level of information, which can be utilized in future development of machine learning-based algorithms for automated identification of abnormal conditions and clinical decision supporting system. These results emphasize the importance of addressing grader variability in algorithm developments."
A Novel Fundus Image Reading Tool for Efficient Generation of a Multi-dimensional Categorical Image Database for Machine Learning Algorithm Training,2018,"['Retina Fundus Image', 'Reading Tool', 'Grader', 'Machine Learning', 'Deep Learning']",,"<P><B>Background</B></P><P>We described a novel multi-step retinal fundus image reading system for providing high-quality large data for machine learning algorithms, and assessed the grader variability in the large-scale dataset generated with this system.</P><P><B>Methods</B></P><P>A 5-step retinal fundus image reading tool was developed that rates image quality, presence of abnormality, findings with location information, diagnoses, and clinical significance. Each image was evaluated by 3 different graders. Agreements among graders for each decision were evaluated.</P><P><B>Results</B></P><P>The 234,242 readings of 79,458 images were collected from 55 licensed ophthalmologists during 6 months. The 34,364 images were graded as abnormal by at-least one rater. Of these, all three raters agreed in 46.6% in abnormality, while 69.9% of the images were rated as abnormal by two or more raters. Agreement rate of at-least two raters on a certain finding was 26.7%–65.2%, and complete agreement rate of all-three raters was 5.7%–43.3%. As for diagnoses, agreement of at-least two raters was 35.6%–65.6%, and complete agreement rate was 11.0%–40.0%. Agreement of findings and diagnoses were higher when restricted to images with prior complete agreement on abnormality. Retinal/glaucoma specialists showed higher agreements on findings and diagnoses of their corresponding subspecialties.</P><P><B>Conclusion</B></P><P>This novel reading tool for retinal fundus images generated a large-scale dataset with high level of information, which can be utilized in future development of machine learning-based algorithms for automated identification of abnormal conditions and clinical decision supporting system. These results emphasize the importance of addressing grader variability in algorithm developments.</P>"
Machine Learning Identifies Stemness Features Associated with Oncogenic Dedifferentiation,2018,"['The Cancer Genome Atlas', 'stemness', 'cancer stem cells', 'genomic', 'epigenomic', 'machine learning', 'pan-cancer', 'dedifferentiation']",,"<P><B>Summary</B></P>  <P>Cancer progression involves the gradual loss of a differentiated phenotype and acquisition of progenitor and stem-cell-like features. Here, we provide novel stemness indices for assessing the degree of oncogenic dedifferentiation. We used an innovative one-class logistic regression (OCLR) machine-learning algorithm to extract transcriptomic and epigenetic feature sets derived from non-transformed pluripotent stem cells and their differentiated progeny. Using OCLR, we were able to identify previously undiscovered biological mechanisms associated with the dedifferentiated oncogenic state. Analyses of the tumor microenvironment revealed unanticipated correlation of cancer stemness with immune checkpoint expression and infiltrating immune cells. We found that the dedifferentiated oncogenic phenotype was generally most prominent in metastatic tumors. Application of our stemness indices to single-cell data revealed patterns of intra-tumor molecular heterogeneity. Finally, the indices allowed for the identification of novel targets and possible targeted therapies aimed at tumor differentiation.</P>   <P><B>Video Abstract</B></P>  <P>Display Omitted</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Epigenetic and expression-based stemness indices measure oncogenic dedifferentiation </LI> <LI>  Immune microenvironment content and PD-L1 levels associate with stemness indices </LI> <LI>  Stemness index is increased in metastatic tumors and reveals intratumor heterogeneity </LI> <LI>  Applying stemness indices reveals potential drug targets for anti-cancer therapies </LI> </UL> </P>   <P><B>Graphical Abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
Machine learning for molecular and materials science,2018,,,"<P>Here we summarize recent progress in machine learning for the chemical sciences. We outline machine-learning techniques that are suitable for addressing research questions in this domain, as well as future directions for the field. We envisage a future in which the design, synthesis, characterization and application of molecules and materials is accelerated by artificial intelligence.</P>"
Machine-learning-based automatic identification of fetal abdominal circumference from ultrasound images,2018,,,"<P> <I>Objective</I>: Obstetricians mainly use ultrasound imaging for fetal biometric measurements. However, such measurements are cumbersome. Hence, there is urgent need for automatic biometric estimation. Automated analysis of ultrasound images is complicated owing to the patient-specific, operator-dependent, and machine-specific characteristics of such images. <I>Approach</I>: This paper proposes a method for the automatic fetal biometry estimation from 2D ultrasound data through several processes consisting of a specially designed convolutional neural network (CNN) and U-Net for each process. These machine learning techniques take clinicians’ decisions, anatomical structures, and the characteristics of ultrasound images into account. The proposed method is divided into three steps: initial abdominal circumference (AC) estimation, AC measurement, and plane acceptance checking. <I>Main results</I>: A CNN is used to classify ultrasound images (stomach bubble, amniotic fluid, and umbilical vein), and a Hough transform is used to obtain an initial estimate of the AC. These data are applied to other CNNs to estimate the spine position and bone regions. Then, the obtained information is used to determine the final AC. After determining the AC, a U-Net and a classification CNN are used to check whether the image is suitable for AC measurement. Finally, the efficacy of the proposed method is validated by clinical data. <I>Significance</I>: Our method achieved a Dice similarity metric of <img ALIGN='MIDDLE' ALT='' SRC='http://ej.iop.org/images/0967-3334/39/10/105007/pmeaaae255ieqn001.gif'/> for AC measurement and an accuracy of 87.10% for our acceptance check of the fetal abdominal standard plane.</P>"
"An Ensemble Machine Learning from Spatio-temporal Kriging for Imputation of PM10 in Seoul, Korea",2018,"['결측대치', 'Imputation', 'Spatio-temporal kriging', 'Resampling', 'Particulate matter', '시공간 크리깅', '재표집', '미세먼지']","시공간 데이터의 결측치는 그 자체로 데이터의 결함으로서 시공간 분석 결과를 왜곡시킬 수 있다. 그러나 시공간 데이터에 내재된 시공간 의존성을 이용한 결측대치 방법은 덜 주목받아 왔다. 이에 본 연구에서는 서울특별시 및 근방의 54개 측정소로부터 2010년부터 2014년까지 5년간 측정된 시간별 미세먼지(PM10) 데이터의 결측치를 대치하기 위하여 앙상블 시공간 크리깅 모형에 기초한 결측대치 모형을 제안하였다. 기존 연구들을 검토한 결과, 본 연구에서 이용된 접근법의 필요성이 발견되었다. 본 연구가 제안하는 앙상블 결측대치 모형은 단기간의 시공간 데이터에서 재표집(resampling)된 하위 데이터셋으로 복수의 시공간 크리깅 모형들을 적합하고, 이들을 앙상블하여 결측대치 정확도를 높이고자 한다. 향상 여부를 실증하기 위하여 측정 데이터에 대해 결측대치 실험을 실시하였다. 실험에서는 재표집 횟수, 시공간 크리깅 적합 시 이웃 비율, 결측 생성 비율 등 3요소에 대해 서로 다른 조건들을 적용하였다. 실험 결과, 제안된 앙상블 모형은 단일 시행 시공간 크리깅 모형(1.32~11.36%)과, 선형 앙상블 모형(평균 52%)보다 높은 정확도로 결측치를 대치하였다. 본 결과는 제한된 환경에서 시공간 크리깅 모형 앙상블이 결측 대치 정확도를 높이는 데 효과가 있음을 입증한다. 다만 제안된 알고리즘의 정확성은 머신러닝 기반의 결측대치 알고리즘에 비해서 덜 우수했는데, 이 결과는 머신러닝 알고리즘에서 시공간 의존성 효과가 어떻게 나타나는지에 대한 추가 연구 필요성을 제기한다.","Missing values in spatio-temporal data presumably cause defects, such that contaminate the results of spatio-temporal analyses. However, imputation methods for spatio-temporal data considering the inherent nature of spatio-temporal dependence have been neglected. We suggest an imputation algorithm based on ensemble spatio-temporal kriging for particulate matter measurement data for the period 2010-2014 at 54 monitoring stations near the metropolitan city of Seoul, Korea. We review previous studies on imputation methods for spatio-temporal data, then shed light on the necessity of our approach. Our approach implements resampling techniques on limited spatio-temporal data for a short-term period, then aims to enhance the imputation accuracy by taking the ensemble of the imputation results of resampled sub datasets. To examine such enhancement, we apply different conditions in experiments, including the number of resampling, neighborhood ratios, and ratios of artificially generated missing values. Results show that our approach outperforms both spatio-temporal kriging with the whole dataset (1.32~11.36%) and the linear regression-based imputation algorithm (52% in average). Our results show that the learning approach by resampling is still effective in spatiotemporal kriging in a limited environment as well as the spatio-temporal algorithm considering the inherent dependence among the data. But the considerable underperformance compared to the accuracy of the machine learning-based algorithm indicates the necessity of further examination of the effect of spatio-temporal dependence in such an algorithm."
Using Big-Data-Driven Machine-Learning Experimentation to Modeling Mobility and Safety Disruption of Critical Highway Renewal Projects,2018,,,
Detecting patterns in North Korean military provocations: What machine-learning tells us,2018,,,
Machine Learning Perspective Gene Optimization for Efficient Induction Machine Design,2018,"['Induction motor', 'annealed selection', 'Adaptive Levy Mutation', 'two point crossovers', 'fitness function', 'optimized genetic algorithm']",,"In this paper, induction machine operation efficiency and torque is improved using Machine Learning based Gene Optimization (ML-GO) Technique is introduced. Optimized Genetic Algorithm (OGA) is used to select the optimal induction machine data. In OGA, selection, crossover and mutation process is carried out to find the optimal electrical machine data for induction machine design. Initially, many number of induction machine data are given as input for OGA. Then, fitness value is calculated for all induction machine data to find whether the criterion is satisfied or not through fitness function (i.e., objective function such as starting to full load torque ratio, rotor current, power factor and maximum flux density of stator and rotor teeth). When the criterion is not satisfied, annealed selection approach in OGA is used to move the selection criteria from exploration to exploitation to attain the optimal solution (i.e., efficient machine data). After the selection process, two point crossovers is carried out to select two crossover points within a chromosomes (i.e., design variables) and then swaps two parent’s chromosomes for producing two new offspring. Finally, Adaptive Levy Mutation is used in OGA to select any value in random manner and gets mutated to obtain the optimal value. This process gets iterated till finding the optimal value for induction machine design. Experimental evaluation of ML-GO technique is carried out with performance metrics such as torque, rotor current, induction machine operation efficiency and rotor power factor compared to the state-of-the-art works."
Machine Learning Perspective Gene Optimization for Efficient Induction Machine Design,2018,"['Induction motor', 'annealed selection', 'Adaptive Levy Mutation', 'two point crossovers', 'fitness function', 'optimized genetic algorithm']",,"In this paper, induction machine operation efficiency and torque is improved using Machine Learning based Gene Optimization (ML-GO) Technique is introduced. Optimized Genetic Algorithm (OGA) is used to select the optimal induction machine data. In OGA, selection, crossover and mutation process is carried out to find the optimal electrical machine data for induction machine design. Initially, many number of induction machine data are given as input for OGA. Then, fitness value is calculated for all induction machine data to find whether the criterion is satisfied or not through fitness function (i.e., objective function such as starting to full load torque ratio, rotor current, power factor and maximum flux density of stator and rotor teeth). When the criterion is not satisfied, annealed selection approach in OGA is used to move the selection criteria from exploration to exploitation to attain the optimal solution (i.e., efficient machine data). After the selection process, two point crossovers is carried out to select two crossover points within a chromosomes (i.e., design variables) and then swaps two parent's chromosomes for producing two new offspring. Finally, Adaptive Levy Mutation is used in OGA to select any value in random manner and gets mutated to obtain the optimal value. This process gets iterated till finding the optimal value for induction machine design. Experimental evaluation of ML-GO technique is carried out with performance metrics such as torque, rotor current, induction machine operation efficiency and rotor power factor compared to the state-of-the-art works."
A pilot study using machine learning methods about factors influencing prognosis of dental implants,2018,"['Machine learning', 'Decision tree', 'Support vector machine', 'Dental implant', 'Implant prognosis']",,"PURPOSE. This study tried to find the most significant factors predicting implant prognosis using machine learning methods. MATERIALS AND METHODS. The data used in this study was based on a systematic search of chart files at Seoul National University Bundang Hospital for one year. In this period, oral and maxillofacial surgeons inserted 667 implants in 198 patients after consultation with a prosthodontist. The traditional statistical methods were inappropriate in this study, which analyzed the data of a small sample size to find a factor affecting the prognosis. The machine learning methods were used in this study, since these methods have analyzing power for a small sample size and are able to find a new factor that has been unknown to have an effect on the result. A decision tree model and a support vector machine were used for the analysis. RESULTS. The results identified mesio-distal position of the inserted implant as the most significant factor determining its prognosis. Both of the machine learning methods, the decision tree model and support vector machine, yielded the similar results. CONCLUSION. Dental clinicians should be careful in locating implants in the patient's mouths, especially mesio-distally, to minimize the negative complications against implant survival."
Predicting Surgical Complications in Adult Patients Undergoing Anterior Cervical Discectomy and Fusion Using Machine Learning,2018,"['Anterior cervical discectomy and fusion', 'Predicting', 'Complications', 'Machine Learning', 'Spine']",,"Objective: Machine learning algorithms excel at leveraging big data to identify complex patterns that can be used to aid in clinical decision-making. The objective of this study is to demonstrate the performance of machine learning models in predicting postoperative complications following anterior cervical discectomy and fusion (ACDF).Methods: Artificial neural network (ANN), logistic regression (LR), support vector machine (SVM), and random forest decision tree (RF) models were trained on a multicenter data set of patients undergoing ACDF to predict surgical complications based on readily available patient data. Following training, these models were compared to the predictive capability of American Society of Anesthesiologists (ASA) physical status classification.Results: A total of 20,879 patients were identified as having undergone ACDF. Following exclusion criteria, patients were divided into 14,615 patients for training and 6,264 for testing data sets. ANN and LR consistently outperformed ASA physical status classification in predicting every complication (p<0.05). The ANN outperformed LR in predicting venous thromboembolism, wound complication, and mortality (p<0.05). The SVM and RF models were no better than random chance at predicting any of the postoperative complications (p<0.05).Conclusion: ANN and LR algorithms outperform ASA physical status classification for predicting individual postoperative complications. Additionally, neural networks have greater sensitivity than LR when predicting mortality and wound complications. With the growing size of medical data, the training of machine learning on these large datasets promises to improve risk prognostication, with the ability of continuously learning making them excellent tools in complex clinical scenarios."
ACCELERATION OF MACHINE LEARNING ALGORITHMS BY TCHEBYCHEV ITERATION TECHNIQUE,2018,,,"Recently Machine Learning algorithms are widely used to process Big Data in various applications and a lot of these applications are executed in run time. Therefore the speed of Machine Learning algorithms is a critical issue in these applications. However the most of modern iteration Machine Learning algorithms use a successive iteration technique well-known in Numerical Linear Algebra. But this technique has a very low convergence, needs a lot of iterations to get solution of considering problems and therefore a lot of time for processing even on modern multi-core computers and clusters. Tchebychev iteration technique is well-known in Numerical Linear Algebra as an attractive candidate to decrease the number of iterations in Machine Learning iteration algorithms and also to decrease the running time of these algorithms those is very important especially in run time applications. In this paper we consider the usage of Tchebychev iterations for acceleration of well-known K-Means and SVM (Support Vector Machine) clustering algorithms in Machine Leaning. Some examples of usage of our approach on modern multi-core computers under Apache Spark framework will be considered and discussed."
Response prediction of laced steel-concrete composite beams using machine learning algorithms,2018,"['composite structures', 'machine learning algorithms', 'ultimate strength', 'displacement']",,"This paper demonstrates the potential application of machine learning algorithms for approximate prediction of the load and deflection capacities of the novel type of Laced Steel Concrete-Composite1 (LSCC) beams proposed by Anandavalli et al. (Engineering Structures 2012). Initially, global and local responses measured on LSCC beam specimen in an experiment are used to validate nonlinear FE model of the LSCC beams. The data for the machine learning algorithms is then generated using validated FE model for a range of values of the identified sensitive parameters. The performance of four well-known machine learning algorithms, viz., Support Vector Regression (SVR), Minimax Probability Machine Regression (MPMR), Relevance Vector Machine (RVM) and Multigene Genetic Programing (MGGP) for the approximate estimation of the load and deflection capacities are compared in terms of well-defined error indices. Through relative comparison of the estimated values, it is demonstrated that the algorithms explored in the present study provide a good alternative to expensive experimental testing and sophisticated numerical simulation of the response of LSCC beams. The load carrying and displacement capacity of the LSCC was predicted well by MGGP and MPMR, respectively."
Performance of machine learning methods in diagnosing Parkinson’s disease based on dysphonia measures,2018,"['Parkinson’s disease', 'Dysphonia measurements', 'Machine learning', 'Classification']",,"Parkinson’s disease (PD) is a widespreaddegenerative syndrome that affects the nervous system. Itsearly appearing symptoms include tremor, rigidity, andvocal impairment (dysphonia). Consequently, speechindicators are important in the identification of PD basedon dysphonic signs. In this regard, computer-aided-diagnosissystems based on machine learning can be useful inassisting clinicians in identifying PD patients. In this work,we evaluate the performance of machine learning basedtechniques for PD diagnosis based on dysphonia symptoms.Several machine learning techniques were consideredand trained with a set of twenty-two voice disordermeasurements to classify healthy and PD patients. Thesemachine learning methods included linear discriminantanalysis (LDA), k nearest-neighbors (k-NN), naı¨ve Bayes(NB), regression trees (RT), radial basis function neuralnetworks (RBFNN), support vector machine (SVM), andMahalanobis distance classifier. We evaluated the performanceof these methods by means of a tenfold cross validationprotocol. Experimental results show that the SVMclassifier achieved higher average performance than allother classifiers in terms of overall accuracy, G-mean, andarea under the curve of the receiver operating characteristicplot. The SVM classifier achieved higher performancemeasures than the majority of the other classifiers also interms of sensitivity, specificity, and F-measure statistics.The LDA, k-NN and RT achieved the highest averageprecision. The RBFNN method yielded the highestF-measure.; however, it performed poorly in terms of otherperformance metrics. Finally, t tests were performed toevaluate statistical significance of the results, confirmingthat the SVM outperformed most of the other classifiers onthe majority of performance measures. SVM is a promisingmethod for identifying PD patients based on classificationof dysphonia measurements."
Classification of failure mode and prediction of shear strength for reinforced concrete beam-column joints using machine learning techniques,2018,"['Beam-column joints', 'Joint shear failure', 'Failure mode', 'Machine learning', 'Probabilistic models']",,"<P><B>Abstract</B></P>  <P>Beam-column joints are one of critical components that control the oveerall performance of reinforced concrete building frames under seismic loadings. To identify the response mechanism, including the classification of failure mode and the prediction of associated shear strength, of beam-column joints, this paper introduces the application of machine learning techniques. The efficiency of various machine learning techniques is evaluated using extensive experimental data from 536 experimental tests, all of which exhibited either non-ductile joint shear failure prior to beam yielding or ductile joint shear failure after beam yielding. It has been seen from the comparison that lasso regression has a better efficiency and reasonable accuracy in the classification and prediction. The suggested formulations as a function of influential input variables can be easily used by structural engineers to provide an optimal rehabilitation strategy for existing buildings and to design new structures.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Identification of mode of failure of beam-column joints through machine learning techniques. </LI> <LI>  Probabilistic models to capture the type of failure and shear strength of beam-column joints. </LI> <LI>  Sensitivity of input variables to joint shear strength. </LI> <LI>  Comparison of various machine learning techniques to estimate the shear strength of beam-column joints. </LI> </UL> </P>"
Call Center Call Count Prediction Model by Machine Learning,2018,"['machine learning', 'prediction model', 'classification', 'random forest']",,"This paper is to introduce efficient human resource management in call center industry by coming up with a model that predicts how much the staffing is most appropriate at such a call center for a given hour period. The project aims to understand the characteristics of call center data through exploratory data analysis, and to test the effectiveness of call center staffing by formulating the rule based on a machine learning model. We initially conducted exploratory data analysis to find insights and implemented a machine learning model to predict the value of the target variable which consequently translated into the number of human receptionists preferred. From our intensive experiments, we found that Random Forest gave the best performance for call center data analysis."
Sparse pseudoinverse incremental extreme learning machine,2018,"['Extreme learning machine', 'Hidden neuron', 'Least squares estimation', 'Matrix decomposition', 'Sparsity']",,"<P>An extreme learning machine (ELM) is a popular analytic single hidden layer feedforward neural network because of its rapid learning capacity. However, vanilla dense ELMs are affected by the overfitting problem when the number of hidden neurons is high. Further direct consequences of the density are decreases in both the training and prediction speeds. In this study, we propose an incremental method for sparsifying the ELM using a newly devised indicator driven by the condition number in the ELM design matrix, in which we call sparse pseudoinverse incremental-ELM (SPI-ELM). SPI-ELM exhibits better generalization performance and lower run-time complexity compared with ELM. However, the sparsification process may negatively affect the learning speed of SPI-ELM; thus, we introduce an iterative matrix decomposition algorithm to address this issue. We also demonstrate that there is a useful relationship between the condition number in the ELM design matrix and the number of hidden neurons. This relationship helps to understand the random weights and nonlinear activation functions in ELMs. We evaluated the SPI-ELM method based on 20 benchmark data sets from the University of California Irvine repository and three real-world databases from the computer vision domain. (C) 2018 Elsevier B.V. All rights reserved.</P>"
Analyzing Machine Learning Techniques for Fault Prediction Using Web Applications,2018,"['Empirical Validation', 'Fault prediction', 'Machine Learning', 'Object-Oriented Metrics', 'Web Application Quality']",,"Web applications are indispensable in the software industry and continuously evolve either meeting a newercriteria and/or including new functionalities. However, despite assuring quality via testing, what hinders astraightforward development is the presence of defects. Several factors contribute to defects and are oftenminimized at high expense in terms of man-hours. Thus, detection of fault proneness in early phases ofsoftware development is important. Therefore, a fault prediction model for identifying fault-prone classes in aweb application is highly desired. In this work, we compare 14 machine learning techniques to analyse therelationship between object oriented metrics and fault prediction in web applications. The study is carried outusing various releases of Apache Click and Apache Rave datasets. En-route to the predictive analysis, theinput basis set for each release is first optimized using filter based correlation feature selection (CFS) method.It is found that the LCOM3, WMC, NPM and DAM metrics are the most significant predictors. The statisticalanalysis of these metrics also finds good conformity with the CFS evaluation and affirms the role of thesemetrics in the defect prediction of web applications. The overall predictive ability of different fault predictionmodels is first ranked using Friedman technique and then statistically compared using Nemenyi post-hocanalysis. The results not only upholds the predictive capability of machine learning models for faulty classesusing web applications, but also finds that ensemble algorithms are most appropriate for defect prediction inApache datasets. Further, we also derive a consensus between the metrics selected by the CFS technique andthe statistical analysis of the datasets."
Analyzing Machine Learning Techniques for Fault Prediction Using Web Applications,2018,"['Empirical Validation', 'Fault prediction', 'Machine Learning', 'Object-Oriented Metrics', 'Web Application Quality']",,"Web applications are indispensable in the software industry and continuously evolve either meeting a newer criteria and/or including new functionalities. However, despite assuring quality via testing, what hinders a straightforward development is the presence of defects. Several factors contribute to defects and are often minimized at high expense in terms of man-hours. Thus, detection of fault proneness in early phases of software development is important. Therefore, a fault prediction model for identifying fault-prone classes in a web application is highly desired. In this work, we compare 14 machine learning techniques to analyse the relationship between object oriented metrics and fault prediction in web applications. The study is carried out using various releases of Apache Click and Apache Rave datasets. En-route to the predictive analysis, the input basis set for each release is first optimized using filter based correlation feature selection (CFS) method. It is found that the LCOM3, WMC, NPM and DAM metrics are the most significant predictors. The statistical analysis of these metrics also finds good conformity with the CFS evaluation and affirms the role of these metrics in the defect prediction of web applications. The overall predictive ability of different fault prediction models is first ranked using Friedman technique and then statistically compared using Nemenyi post-hoc analysis. The results not only upholds the predictive capability of machine learning models for faulty classes using web applications, but also finds that ensemble algorithms are most appropriate for defect prediction in Apache datasets. Further, we also derive a consensus between the metrics selected by the CFS technique and the statistical analysis of the datasets."
Vibration-based Damage Detection in Bridges via Machine Learning,2018,"['damage detection', 'machine learning', 'dynamic fingerprint', 'bayesian fusion', 'rough set theory', 'naive-bayes classifier']",,"Environmental corrosion and external loads degrade the performance of a bridge over the course of its service life. Although dynamic fingerprints are damage-sensitive, they are rarely applied to bridges in-situ due to environmental noise. Machine learning techniques can facilitate effective structural damage detection. This paper proposes a detection method based on dynamic fingerprints and machine learning techniques for multi-damage problems in bridges. Vibration analysis is conducted to acquire the dynamic fingerprints, then the Bayesian fusion is used to integrate these features and preliminarily locate the damage. The RSNB method, which combines Rough Set theory and the Naive-Bayes classifier, is introduced as a robust classification tool for damage qualification. A continuous bridge is numerically simulated to validate the effectiveness of the proposed method. The RSNB method is compared with back propagation neural network, support vector machine, and decision tree techniques, it is found that the RSNB outperforms other three methods in terms of transparency, accuracy, efficiency, noise robustness, and stability."
Metabolic Syndrome Prediction Using Machine Learning Models with Genetic and Clinical Information from a Nonobese Healthy Population,2018,"['genetic polymorphism', 'machine learning', 'metabolic syndrome']",,"The prevalence of metabolic syndrome (MS) in the nonobese population is not low. However, the identification and risk mitigation of MS are not easy in this population. We aimed to develop an MS prediction model using genetic and clinical factors of nonobese Koreans through machine learning methods. A prediction model for MS was designed for a nonobese population using clinical and genetic polymorphism information with five machine learning algorithms, including naïve Bayes classification (NB). The analysis was performed in two stages (training and test sets). Model A was designed with only clinical information (age, sex, body mass index, smoking status, alcohol consumption status, and exercise status), and for model B, genetic information (for 10 polymorphisms) was added to model A. Of the 7,502 nonobese participants, 647 (8.6%) had MS. In the test set analysis, for the maximum sensitivity criterion, NB showed the highest sensitivity: 0.38 for model A and 0.42 for model B. The specificity of NB was 0.79 for model A and 0.80 for model B. In a comparison of the performances of models A and B by NB, model B (area under the receiver operating characteristic curve [AUC] = 0.69, clinical and genetic information input) showed better performance than model A (AUC = 0.65, clinical information only input). We designed a prediction model for MS in a nonobese population using clinical and genetic information. With this model, we might convince nonobese MS individuals to undergo health checks and adopt behaviors associated with a preventive lifestyle."
Metabolic Syndrome Prediction Using Machine Learning Models with Genetic and Clinical Information from a Nonobese Healthy Population,2018,"['genetic polymorphism', 'machine learning', 'metabolic syndrome']",,"The prevalence of metabolic syndrome (MS) in the nonobese population is not low. However, the identification and risk mitigation of MS are not easy in this population. We aimed to develop an MS prediction model using genetic and clinical factors of nonobese Koreans through machine learning methods. A prediction model for MS was designed for a nonobese population using clinical and genetic polymorphism information with five machine learning algorithms, including naïve Bayes classification (NB). The analysis was performed in two stages (training and test sets). Model A was designed with only clinical information (age, sex, body mass index, smoking status, alcohol consumption status, and exercise status), and for model B, genetic information (for 10 polymorphisms) was added to model A. Of the 7,502 nonobese participants, 647 (8.6%) had MS. In the test set analysis, for the maximum sensitivity criterion, NB showed the highest sensitivity: 0.38 for model A and 0.42 for model B. The specificity of NB was 0.79 for model A and 0.80 for model B. In a comparison of the performances of models A and B by NB, model B (area under the receiver operating characteristic curve [AUC] = 0.69, clinical and genetic information input) showed better performance than model A (AUC = 0.65, clinical information only input). We designed a prediction model for MS in a nonobese population using clinical and genetic information. With this model, we might convince nonobese MS individuals to undergo health checks and adopt behaviors associated with a preventive lifestyle."
Use of a Machine Learning Algorithm to Predict Individuals with Suicide Ideation in the General Population,2018,"['Suicide ideation', 'Prediction', 'Machine learning algorithm', 'Public health data']",,"Objective In this study, we aimed to develop a model predicting individuals with suicide ideation within a general population using a machine learning algorithm. Methods Among 35,116 individuals aged over 19 years from the Korea National Health & Nutrition Examination Survey, we selected 11,628 individuals via random down-sampling. This included 5,814 suicide ideators and the same number of non-suicide ideators. We randomly assigned the subjects to a training set (n=10,466) and a test set (n=1,162). In the training set, a random forest model was trained with 15 features selected with recursive feature elimination via 10-fold cross validation. Subsequently, the fitted model was used to predict suicide ideators in the test set and among the total of 35,116 subjects. All analyses were conducted in R. Results The prediction model achieved a good performance [area under receiver operating characteristic curve (AUC)=0.85] in the test set and predicted suicide ideators among the total samples with an accuracy of 0.821, sensitivity of 0.836, and specificity of 0.807. Conclusion This study shows the possibility that a machine learning approach can enable screening for suicide risk in the general population. Further work is warranted to increase the accuracy of prediction."
Early identification of emerging technologies: A machine learning approach using multiple patent indicators,2018,"['Technology forecasting', 'Emerging technologies', 'Early identification', 'Machine learning models', 'Multiple patent indicators']",,"<P><B>Abstract</B></P>  <P>Patent citation analysis is considered a useful tool for identifying emerging technologies. However, the outcomes of previous methods are likely to reveal no more than current key technologies, since they can only be performed at later stages of technology development due to the time required for patents to be cited (or fail to be cited). This study proposes a machine learning approach to identifying emerging technologies at early stages using multiple patent indicators that can be defined immediately after the relevant patents are issued. For this, first, a total of 18 input and 3 output indicators are extracted from the United States Patent and Trademark Office database. Second, a feed-forward multilayer neural network is employed to capture the complex nonlinear relationships between input and output indicators in a time period of interest. Finally, two quantitative indicators are developed to identify trends of a technology's <I>emergingness</I> over time. Based on this, we also provide the practical guidelines for implementation of the proposed approach. The case of pharmaceutical technology shows that our approach can facilitate responsive technology forecasting and planning.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Proposing a machine learning approach to identifying emerging technologies at early stages </LI> <LI>  Defining 18 input and 3 output variables from the United States Patent and Trademark Office database </LI> <LI>  Employing feed-forward multilayer neural networks to capture nonlinear relationships between input and output variables </LI> <LI>  Developing two quantitative indicators to identify trends of a technology's <I>emergingness</I>  </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
Control of Single Propeller Pendulum with Supervised Machine Learning Algorithm,2018,"['cost', 'gradient', 'control', 'data', 'propeller', 'regression']",,"Nowadays multiple control methods are used in robot control systems. A model, predictor or error estimator is often used as feedback controller to control a robot. While robots have become more and more intensive with algorithms capable to acquiring independent knowledge from raw data. This paper represents experimental results of real time machine learning control that does not require explicit knowledge about the plant. The controller can be applied on a broad range of tasks with different dynamic characteristics. We tested our controller on the balancing problem of a single propeller pendulum. Experimental results show that the use of a supervised machine learning algorithm in a single propeller pendulum allows the stable swing of a given angle."
Prediction of Return-to-original-work after an Industrial Accident Using Machine Learning and Comparison of Techniques,2018,"['Return to Work', 'Accidents', 'Occupational', 'Machine Learning']",,"Background: Many studies have tried to develop predictors for return-to-work (RTW).However, since complex factors have been demonstrated to predict RTW, it is difficult to use them practically. This study investigated whether factors used in previous studies could predict whether an individual had returned to his/her original work by four years after termination of the worker's recovery period.Methods: An initial logistic regression analysis of 1,567 participants of the fourth Panel Study of Worker's Compensation Insurance yielded odds ratios. The participants were divided into two subsets, a training dataset and a test dataset. Using the training dataset, logistic regression, decision tree, random forest, and support vector machine models were established, and important variables of each model were identified. The predictive abilities of the different models were compared.Results: The analysis showed that only earned income and company-related factors significantly affected return-to-original-work (RTOW). The random forest model showed the best accuracy among the tested machine learning models; however, the difference was not prominent.Conclusion: It is possible to predict a worker's probability of RTOW using machine learning techniques with moderate accuracy."
"Cerebral Small Vessel Disease: A Review Focusing on Pathophysiology, Biomarkers, and Machine Learning Strategies",2018,"['Small vessel disease', 'Neuroimaging', 'Biomarkers', 'Blood-brain barrier', 'Machine learning']",,"Cerebral small vessel disease (cSVD) has a crucial role in lacunar stroke and brain hemorrhages and is a leading cause of cognitive decline and functional loss in elderly patients. Based on underlying pathophysiology, cSVD can be subdivided into amyloidal and non-amyloidal subtypes.Genetic factors of cSVD play a pivotal role in terms of unraveling molecular mechanism. An important pathophysiological mechanism of cSVD is blood-brain barrier leakage and endothelium dysfunction which gives a clue in identification of the disease through circulating biological markers. Detection of cSVD is routinely carried out by key neuroimaging markers including white matter hyperintensities, lacunes, small subcortical infarcts, perivascular spaces, cerebral microbleeds, and brain atrophy. Application of neural networking, machine learning and deep learning in image processing have increased significantly for correct severity of cSVD. A linkage between cSVD and other neurological disorder, such as Alzheimer’s and Parkinson’s disease and non-cerebral disease, has also been investigated recently. This review draws a broad picture of cSVD, aiming to inculcate new insights into its pathogenesis and biomarkers. It also focuses on the role of deep machine strategies and other dimensions of cSVD by linking it with several cerebral and non-cerebral diseases as well as recent advances in the field to achieve sensitive detection, effective prevention and disease management."
머신 러닝(Machine Learning)기법을 활용한 실시간 악성파일 탐지 기법,2018,"['malware detection', 'data mining', 'machine learning', 'decision tree', 'ransomware detection']",,
Reliable Machine Learning Based Spectrum Sensing in Cognitive Radio Networks,2018,,,"<P>Spectrum sensing is of crucial importance in cognitive radio (CR) networks. In this paper, a reliable spectrum sensing scheme is proposed, which uses K-nearest neighbor, a machine learning algorithm. In the training phase, each CR user produces a sensing report under varying conditions and, based on a global decision, either transmits or stays silent. In the training phase the local decisions of CR users are combined through a majority voting at the fusion center and a global decision is returned to each CR user. A CR user transmits or stays silent according to the global decision and at each CR user the global decision is compared to the actual primary user activity, which is ascertained through an acknowledgment signal. In the training phase enough information about the surrounding environment, i.e., the activity of PU and the behavior of each CR to that activity, is gathered and sensing classes formed. In the classification phase, each CR user compares its current sensing report to existing sensing classes and distance vectors are calculated. Based on quantitative variables, the posterior probability of each sensing class is calculated and the sensing report is classified into either representing presence or absence of PU. The quantitative variables used for calculating the posterior probability are calculated through K-nearest neighbor algorithm. These local decisions are then combined at the fusion center using a novel decision combination scheme, which takes into account the reliability of each CR user. The CR users then transmit or stay silent according to the global decision. Simulation results show that our proposed scheme outperforms conventional spectrum sensing schemes, both in fading and in nonfading environments, where performance is evaluated using metrics such as the probability of detection, total probability of error, and the ability to exploit data transmission opportunities.</P>"
Predicting Game Results using Machine Learning - MMORPG TERA : Focusing on the Rikanor Arena,2018,"['Game', 'Machine learning', 'Tensorflow', 'Neural Network', 'Predict']",,
Korean Machine Reading Comprehension using Reinforcement Learning and Dual Co-Attention Mechanism,2018,"['기계독해', '이중 상호 집중', '강화학습', 'machine reading comprehension', 'dual co-attention', 'reinforcement learning']",,
Comparison of Models for the Prediction of Medical Costs of Spinal Fusion in Taiwan Diagnosis-Related Groups by Machine Learning Algorithms,2018,"['Spinal Fusion', 'Machine Learning', 'Diagnosis-Related Groups', 'Taiwan', 'Costs and Cost Analysis']",,"Objectives: The aims of this study were to compare the performance of machine learning methods for the prediction of themedical costs associated with spinal fusion in terms of profit or loss in Taiwan Diagnosis-Related Groups (Tw-DRGs) andto apply these methods to explore the important factors associated with the medical costs of spinal fusion. Methods: A dataset was obtained from a regional hospital in Taoyuan city in Taiwan, which contained data from 2010 to 2013 on patients ofTw-DRG49702 (posterior and other spinal fusion without complications or comorbidities). Naïve-Bayesian, support vectormachines, logistic regression, C4.5 decision tree, and random forest methods were employed for prediction using WEKA3.8.1. Results: Five hundred thirty-two cases were categorized as belonging to the Tw-DRG49702 group. The mean medicalcost was US $4,549.7, and the mean age of the patients was 62.4 years. The mean length of stay was 9.3 days. The lengthof stay was an important variable in terms of determining medical costs for patients undergoing spinal fusion. The randomforest method had the best predictive performance in comparison to the other methods, achieving an accuracy of 84.30%,a sensitivity of 71.4%, a specificity of 92.2%, and an AUC of 0.904. Conclusions: Our study demonstrated that the randomforest model can be employed to predict the medical costs of Tw-DRG49702, and could inform hospital strategy in terms ofincreasing the financial management efficiency of this operation."
Extracting Specific Information in Web Pages Using Machine Learning,2018,"['Data Extraction', 'Machine Learning', 'SVM', 'Decision Tree', 'Neural Network']",,"With the advent of the digital age, production and distribution of web pages has been exploding. Internet users frequently need to extract specific information they want from these vast web pages. However, it takes lots of time and effort for users to find a specific information in many web pages. While search engines that are commonly used provide users with web pages containing the information they are looking for on the Internet, additional time and efforts are required to find the specific information among extensive search results. Therefore, it is necessary to develop algorithms that can automatically extract specific information in web pages. Every year, thousands of international conference are held all over the world. Each international conference has a website and provides general information for the conference such as the date of the event, the venue, greeting, the abstract submission deadline for a paper, the date of the registration, etc. It is not easy for researchers to catch the abstract submission deadline quickly because it is displayed in various formats from conference to conference and frequently updated. This study focuses on the issue of extracting abstract submission deadlines from International conference websites. In this study, we use three machine learning models such as SVM, decision trees, and artificial neural network to develop algorithms to extract an abstract submission deadline in an international conference website. Performances of the suggested algorithms are evaluated using 2,200 conference websites."
Comparison of machine learning techniques to predict compressive strength of concrete,2018,"['concrete', 'compressive strength', 'Gaussian Process for Regression (GPR)', 'Multi Adaptive Regression Spline (MARS)', 'Minimax Probability Machine Regression (MPMR)']",,"In the present study, soft computing i.e., machine learning techniques and regression models algorithms have earned much importance for the prediction of the various parameters in different fields of science and engineering. This paper depicts that how regression models can be implemented for the prediction of compressive strength of concrete. Three models are taken into consideration for this; they are Gaussian Process for Regression (GPR), Multi Adaptive Regression Spline (MARS) and Minimax Probability Machine Regression (MPMR). Contents of cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, fine aggregate and age in days have been taken as inputs and compressive strength as output for GPR, MARS and MPMR models. A comparatively large set of data including 1030 normalized previously published results which were obtained from experiments were utilized. Here, a comparison is made between the results obtained from all the above mentioned models and the model which provides the best fit is established. The experimental results manifest that proposed models are robust for determination of compressive strength of concrete."
Image Reconstruction is a New Frontier of Machine Learning,2018,,,"<P>Over past several years, machine learning, or more generally artificial intelligence, has generated overwhelming research interest and attracted unprecedented public attention. As tomographic imaging researchers, we share the excitement from our imaging perspective [item 1) in the Appendix], and organized this special issue dedicated to the theme of “Machine learning for image reconstruction.” This special issue is a sister issue of the special issue published in May 2016 of this journal with the theme “Deep learning in medical imaging” [item 2) in the Appendix]. While the previous special issue targeted medical image processing/analysis, this special issue focuses on data-driven tomographic reconstruction. These two special issues are highly complementary, since image reconstruction and image analysis are two of the main pillars for medical imaging. Together we cover the whole workflow of medical imaging: from tomographic raw data/features to reconstructed images and then extracted diagnostic features/readings.</P>"
Short-term Prediction of Localized Heavy Rain from Radar Imaging and Machine Learning,2018,"['Dual-kNN', 'kNN', 'Machine learning', 'Robustness', 'Weather forecasting']",,"Heavy rainfall has frequently caused serious flooding and landslides, increasing traffic delays in most parts of the world. Consequently, the people in areas battered by heavy rainfall face many hardships. Thus, the negative effects of torrential rainfall always remind researchers to keep seeking the ways to prevent such damage. Therefore, we designed a system for short-term prediction of localized heavy downpours by using radar images coupled with a machine learning method. Here, we introduce a new approach, named dual k-nearest neighbor (dual-kNN), for shortterm rainfall prediction by upgrading the ordinary classification routines of classical k-nearest neighbors (k-NN). dual-kNN is able to maintain highly robust classification of various K values with an advanced simple dual consideration, where observation of a targeted object can be found not only in the specified region but also in other related regions. We conducted experimentations using 2011, 2013, and 2014 data sets collected from the WITH small-dish aviation radar installed on the rooftop of Information Engineering, University of the Ryukyus. Then, we compared the prediction accuracy of our new approach with classical k-NN. It was experimentally confirmed with test cases and simulations that the performance of dual-kNN is more effective than classical k-NN."
Using Statistical and Machine Learning Methods to Evaluate the Prognostic Accuracy of SIRS and qSOFA,2018,"['Sepsis', 'Systemic Inflammatory Response Syndrome', 'Severity of Illness Index', 'Medical Informatics', 'Artificial Intelligence']",,"Objectives: The objective of this study was to compare the performance of two popularly used early sepsis diagnostic criteria, systemic inflammatory response syndrome (SIRS) and quick Sepsis-related Organ Failure Assessment (qSOFA), using statistical and machine learning approaches. Methods: This retrospective study examined patient visits in Emergency Department (ED) with sepsis related diagnosis. The outcome was 28-day in-hospital mortality. Using odds ratio (OR) and modeling methods (decision tree [DT], multivariate logistic regression [LR], and naïve Bayes [NB]), the relationships between diagnostic criteria and mortality were examined. Results: Of 132,704 eligible patient visits, 14% died within 28 days of ED admission.The association of qSOFA ≥2 with mortality (OR = 3.06; 95% confidence interval [CI], 2.96–3.17) greater than the association of SIRS ≥2 with mortality (OR = 1.22; 95% CI, 1.18–1.26). The area under the ROC curve for qSOFA (AUROC = 0.70) was significantly greater than for SIRS (AUROC = 0.63). For qSOFA, the sensitivity and specificity were DT = 0.39, LR = 0.64, NB = 0.62 and DT = 0.89, LR = 0.63, NB = 0.66, respectively. For SIRS, the sensitivity and specificity were DT = 0.46, LR = 0.62, NB = 0.62 and DT = 0.70, LR = 0.59, NB = 0.58, respectively. Conclusions: The evidences suggest that qSOFA is a better diagnostic criteria than SIRS. The low sensitivity of qSOFA can be improved by carefully selecting the threshold to translate the predicted probabilities into labels. These findings can guide healthcare providers in selecting risk-stratification measures for patients presenting to an ED with sepsis."
Automatic Malware Detection with Machine Learning Algorithms in a Smart Office Environment,2018,"['Malware classification', 'Artificial Intelligence', 'Pattern recognition and classification', 'Mirai malware']",,"The threat of malware in the Internet of Things (IoT) environment is increasing due to a lack of detectors. This paper proposes a method to predict the intrusion of malware using state-of-the- art machine learning algorithms that can detect malware faster and more accurately, compared with the existing methods (that is, payload, port-based, and statistical methods). A smart office environment was implemented to capture the flow of packet datasets, where malware and normal packets were captured, and 11 features were extracted from them. Four machine learning algorithms (random forest, a support vector machine, AdaBoost, and a Gaussian mixture model-based naïve Bayes classifier) were investigated to implement the automatic malware monitoring system. Random forest and AdaBoost could separate the malware and normal flows perfectly, due to their ensemble structures, which could classify unbalanced and noisy datasets."
A Comparative Study of Machine Learning Classification for Color-based Safety Vest Detection on Construction-Site Images,2018,"['color space transformation', 'data mining techniques', 'image processing', 'machine learning', 'pixel-level classification', 'safety vest detection', 'worker detection']",,"Detecting the safety vests is an important foundation for various applications in safety management and productivity measurement.The fluorescent yellow-green color and fluorescent orange-red color of safety vests are generally considered as the most distinctive colors which represent workers in construction-site images. The objective of this study is to provide an evaluation of the safety vest detection using color information in construction-site images. The data sets of two colors of safety vests and the background were generated and used in this study. A comparative analysis of combinations of five color spaces (RGB, nRGB, HSV, Lab, and YCbCr) and six classifiers (ANN, C4.5, KNN, LR, NB, and SVM) was conducted. The performance of each combination was assessed in terms of the precision, recall, and F-measure. Moreover, an evaluation of the effects of color space conversion and the absence of luminance components on the detection performance was conducted. The comparison results showed that C4.5 classifier combined with YCbCr and SVM classifier combined with Lab, respectively, outperformed other combinations on each data set of safety vest colors. Furthermore, RGB color space transformation into non-RGB color spaces enhanced the classification performance. The evaluation also showed that the removal of luminance components did not help to improve the performance."
A Study on Prediction of Business Status Based on Machine Learning,2018,"['Food Hygiene Business', 'Business Analysis', 'Machine Learning', 'Prediction of Business Status', 'Neural Network']",,"Korea has a high proportion of self-employment. Many of them start the food business since it does not require high-techs and it is possible to start the business relatively easily compared to many others in business categories. However, the closure rate of the business is also high due to excessive competition and market saturation. Cafés and restaurants are examples of food business where the business analysis is highly important. However, for most of the people who want to start their own business, it is difficult to conduct systematic business analysis such as trade area analysis or to find information for business analysis. Therefore, in this paper, we predicted business status with simple information using Microsoft Azure Machine Learning Studio program. Experimental results showed higher performance than the number of attributes, and it is expected that this artificial intelligence model will be helpful to those who are self-employed because it can easily predict the business status. The results showed that the overall accuracy was over 60 % and the performance was high compared to the number of attributes. If this model is used, those who prepare for self-employment who are not experts in the business analysis will be able to predict the business status of stores in Seoul with simple attributes."
Multimodal Drowsiness Detection Methods using Machine Learning Algorithms,2018,"['Artificial Intelligence', 'Pattern recognition', 'Biomedical and biological image processing']",,"Drowsiness is a main threat to drivers, and induces inefficiency in various fields, such as industry and education. In this paper, monitoring drowsiness is investigated in which five healthy volunteers participated in an experiment to elicit drowsiness. The subjects were asked to limit their sleep duration to only two to three hours and restrict caffeine intake during the 24 hours prior to the experiment. In the experiment, a one-channel electrocardiogram (ECG) and a single-channel electroencephalogram (EEG) were simultaneously recorded. The ECG and EEG features were extracted and fed into machine learning, random forest, multilayer perceptron, and support vector machine algorithms. Various feature combinations were utilized to train the algorithms, and random forest yielded the best performance at about 90% accuracy, precision, and recall, with 10-second epochs in the ECG and EEG."
Collecting Network Field Information using Machine Learning,2018,"['기계학습', '운영체제 탐지', '네트워크', '네트워크 관제', '네트워크 명령어', 'operating system detection', 'machine learning', 'network', 'network control', 'network commands']",,
Control of Single Propeller Pendulum with Supervised Machine Learning Algorithm,2018,"['cost', 'gradient', 'control', 'data', 'propeller', 'regression']",,"Nowadays multiple control methods are used in robot control systems. A model, predictor or error estimator is often used as feedback controller to control a robot. While robots have become more and more intensive with algorithms capable to acquiring independent knowledge from raw data. This paper represents experimental results of real time machine learning control that does not require explicit knowledge about the plant. The controller can be applied on a broad range of tasks with different dynamic characteristics. We tested our controller on the balancing problem of a single propeller pendulum. Experimental results show that the use of a supervised machine learning algorithm in a single propeller pendulum allows the stable swing of a given angle."
Enhancement of modifier adaptation scheme via feedforward decision maker using historical disturbance data and deep machine learning,2018,"['Modifier adaptation', 'Model-plant mismatch', 'Deep neural network', 'KKT conditions']",,"<P><B>Abstract</B></P>  <P>Most advanced processes struggle to reduce the production cost under constraints. For this, an iterative optimization method called modifier adaptation has been utilized due to its ability to ensure the necessary conditions of optimality even under model-plant mismatch. However, the optimization performance may be degraded by the disturbance which may significantly change the true optimum. In this study, a feedforward decision maker is designed to deal with disturbances in advance and compensate the limitation of feedback scheme of the conventional modifier adaptation. It is constructed by historical data and deep machine learning, and combined with the modifier adaptation. When disturbances occur, the decision maker provides an initial point close to the true optimum by exploiting the historical data. As the information is accumulated, a better initial point for modifier adaptation is obtained. Constrained optimization of numerical example and run-to-run bioprocess are illustrated to validate the utility of the proposed method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Feedback only modifier adaptation cannot handle large disturbances properly. </LI> <LI>  Historical data and machine learning enable to design a feedforward decision maker. </LI> <LI>  Deep neural network finds better starting point for modifier adaptation. </LI> <LI>  Its applicability is confirmed with numerical and bioprocess examples. </LI> </UL> </P>"
Machine learning in biomedical engineering,2018,,,
Application of Machine Learning Methods to Interpolation of Aircraft Aerodynamic Data,2018,,,
Scoliosis Screening through a Machine Learning Based Gait Analysis Test,2018,,,
Postoperative seizure outcome-guided machine learning for interictal electrocorticography in neocortical epilepsy,2018,,,
Correction: Using Statistical and Machine Learning Methods to Evaluate the Prognostic Accuracy of SIRS and qSOFA,2018,,,
Tensor manifold-based extreme learning machine for 2.5-D face recognition,2018,,,
DLL/API 통계적 분석을 통한 Feature 추출 및 Machine Learning 기반 악성코드 탐지 기법,2018,"['Malware Detection', 'Static Analysis', 'DLL', 'API', 'Deep Neural Network']",,
Application of Image Classification using Machine Learning Technique on Smart Device,2018,"['Internet of things', 'Artificial intelligence', 'Image classification', 'Smartwatch application', '사물인터넷', '인공지능', '이미지 분류', '스마트워치 어플리케이션']",,"This paper combines two of the most recent research topics for consumer electronic devices: Internet of Things (IoT) and Artificial Intelligence (AI), applied to solve an image classification problem for an electrical appliance’s recipe database. The first part of this article presents the development of an Android mobile application containing all the options from its recipe book manual. The problem addresses the inconvenience to manually search over the catalog categories to find the recipe that matches the actual ingredient available for the users in their home. The proposed solution establishes to recognize the ingredient with the mobile device camera using transfer learning over a pre-trained Convolutional Neural Network (CNN) to distinguish between the recipes that uses the ingredient, and exclude the recipe sets that are unrelated to the ingredient acquired with the camera. In the second part of the article, the availability of sensors on most of the wrist smartwatches and fitness bands is exploited to categorize the users according to the level of physical activity, in pursuance of making a healthy recommendation according to the number of calories in each of the recipes."
Personal search system based on android using lifelog and machine learning,2018,,,"<P>Lifelog is the foundation on which lifelong services and healthcare services are implemented in a smart home system. It also plays a major role in the sub-processes of the system because it acquires information about the home's residents for home automation and entertainment. Providing personalized services to individuals by acquiring and managing this personal lifelog information has great advantages in terms of service satisfaction and effectiveness. In this paper, we implemented a personal search system based on android that collected and stored an individual's lifelog based on nine smart phone sensors and used it to derive new meaningful information about the user. The activity recognition module for classifying the user's behavior, the naive Bayesian method, showed an accuracy of 88.23% and the area under the ROC curve value of 0.941. We designed and implemented density-based spatial clustering method in the module for extracting the point of interest and the participants filled out a satisfaction questionnaire to evaluate the search system. The proposed system efficiently uses a large amount of lifelog data and automates the process of extracting meaningful information, associating it according to the user's intention.</P>"
Feature-Based Analysis for Fault Diagnosis of Gas Turbine using Machine Learning and Genetic Algorithms,2018,"['Rotating machinery (회전 기계)', 'Fault diagnosis (결함 진단)', 'Feature analysis (특징 분석)', 'Genetic algorithms (유전 알고리즘)', 'Support vector machine (서포터 벡터 머신)']",,
A local environment descriptor for machine-learned density functional theory at the generalized gradient approximation level,2018,,,
AI기법의 Q-Learning을 이용한 최적 퇴선 경로 산출 연구,2018,"['Abandon Ship', 'Evacuation', 'Machine Learning', 'Reinforcement Learning', 'Q-Learning', 'Artificial Intelligence', '퇴선', '피난', '기계학습', '강화학습', 'Q-Learning', '인공지능']","선박은 해양사고 발생 시 최악의 경우 퇴선을 해야 하나 특성상 협소하고 복잡하며 해상에서 운항하므로 퇴선이 쉽지 않다. 특히, 여객선의 경우 해상에서의 안전훈련을 이수하지 않은 불특정 다수의 승객들로 인해 더욱 퇴선이 어려운 상황이 된다. 이런 경우 승무원들의 피난 유도가 상당히 중요한 역할을 하게 된다. 그리고 구조자가 사고 선박에 진입하여 구조 활동을 하는 경우 어느 구역으로 진입해야 가장 효과적인지에 대한 검토가 필요하다. 일반적으로 승무원 및 구조자는 최단경로를 택하여 이동하는 것이 일반적이나 최단 경로에 사고 상황 등이 발생했을 경우 제2의 최적 경로 선택이 필요하다. 이러한 상황을 해결하기 위해 이 연구에서는 머신러닝(Machine learning)의 기법 중에 하나인 강화학습(Reinforcement Learning)의 Q-Learning 이용하여 퇴선 경로를 산출하고자 한다. 강화학습은 인공지능(Artificial Intelligence)의 가장 핵심적인 기능으로 현재 여러 분야에 사용되고 있다. 현재까지 개발된 대부분의 피난분석 프로그램은 최단 경로를 탐색하는 기법을 사용하고 있다. 이 연구에서는 최단경로가 아닌 최적경로를 분석하기 위해 머신러닝의 강화학습 기법을 이용하였다. 향후 AI기법인 머신러닝은 자율운항선박의 최적항로 선정 및 위험요소 회피 등 다양한 해양관련 산업에 적용 가능할 것이다.","In the worst maritime accidents, people should abandon ship, but ship structures are narrow and complex and operation takes place on rough seas, so escape is not easy. In particular, passengers on cruise ships are untrained and varied, making evacuation prospects worse. In such a case, the evacuation management of the crew plays a very important role. If a rescuer enters a ship at distress and conducts rescue activities, which zones represent the most effective entry should be examined. Generally, crew and rescuers take the shortest route, but if an accident occurs along the shortest route, it is necessary to select the second-best alternative. To solve this situation, this study aims to calculate evacuation routes using Q-Learning of Reinforcement Learning, which is a machine learning technique. Reinforcement learning is one of the most important functions of artificial intelligence and is currently used in many fields. Most evacuation analysis programs developed so far use the shortest path search method. For this reason, this study explored optimal paths using reinforcement learning. In the future, machine learning techniques will be applicable to various marine-related industries for such purposes as the selection of optimal routes for autonomous vessels and risk avoidance."
Support Vector Machine을 이용한 생체 신호 분류기 개발,2018,"['머신 러닝', '서포트 벡터 머신', '데이터 분류', '속성 추출', 'Machine Learning', 'Support Vector Machine', 'Data Classification', 'Feature Selection', 'Libsvm']","피부 저항을 이용한 생체 신호는 스트레스성 질환에 따라 각각 다른 특성을 보이고 있으며 이 특성을 이용하여 스트레스성 질환을 진단하는 생체진단 장비들이 개발 되었으며, 장비들은 피부 저항 측정기에서 측정한 신호를 해석하기 쉽게 출력해주며, 그 분야의 전문가는 출력 신호를 직접 보고 어떤 스트레스성 질환의 가능성이 높은지를 판단하게 된다. 하지만 각 측정 대상자에게서 측정된 생체 신호를 분석하여 측정 대상자가 어떤 스트레스성 질환을 가지고 있는지를 사람이 정확히 판단하기는 매우 어려울 뿐만 아니라 판단의 결과가 잘못될 가능성도 매우 높다. 이런 문제점을 해결하기 위하여 본 연구에서는 머신러닝 기법을 이용하여 측정된 신호가 어떤 스트레스성 질환의 신호에 해당하는지를 판단하는 기능을 구현하였다. 측정 장비의 낮은 컴퓨팅 능력을 고려하여 분류 기법은 SVM을 사용하였으며, 훈련 데이터와 테스트 데이터는 13개의 질환을 중심으로 오차범위 5를 사용하여 각 질환 당 1,000개를 랜덤하게 생성하여 사용하였다. 모의실험 결과에서 90% 이상의 판단 정확도를 보였으며 앞으로 측정 장비가 실제로 환자들에게 적용되면 다시 생성된 데이터로 분류기를 재훈련 할 수 있게 구성하였다.","Biomedical signals using skin resistance have different characteristics according to stress diseases. Biological diagnostic devices for diagnosing stress diseases have been developed by using these characteristics, and devices have been developed so that the signals measured by the skin storage meter can be easily analyzed. Experts in the field will look directly at the output signal to determine the likelihood of any stress disorder. However, it is very difficult for a person to accurately determine whether a person to be measured has a stress disorder by analyzing a bio-signal measured by each person to be measured, and the result of the judgment is very likely to be wrong.In order to solve these problems, we implemented the function of determining the signal of a stress disorder by using the machine learning technique. SVM was used as a classification method in consideration of low computing ability of measurement equipment. Training data and test data were randomly generated for each disease using error range 5 based on 13 diseases. Simulation results showed more than 90% decision accuracy. In the future, if the measurement equipment is actually applied to the patients, we can retrain the classifier with the newly generated data."
Semi-supervised Multi-view Manifold Discriminant Intact Space Learning,2018,"['Semi-supervised learning', 'Manifold discriminant intact space', 'Generated multi-view data points', 'Intact feature representations', 'Image classification']",,"Semi-supervised multi-view latent space learning is gaining considerable popularity recently in many machine learning applications due to the high cost and difficulty to obtain the large amount of label information of data. Although some semi-supervised multi-view latent space learning methods have been presented, there is still much space for improvement: 1) How to learn latent discriminant intact feature representations by employing data of multiple views; 2) How to exploit the manifold structure of both labeled and unlabeled point in the learned latent intact space effectively. To address the above issues, we propose an approach called semi-supervised multi-view manifold discriminant intact space learning (SM2DIS) for image classification in this paper. SM2DIS aims to seek a manifold discriminant intact space for data of different views by making use of both the discriminant information of labeled data and the manifold structure of both labeled and unlabeled data. Experimental results on MNIST, COIL-20, Multi-PIE, and Caltech-101 databases demonstrate the effectiveness and robustness of our proposed approach."
Using weighted Support Vector Machine to address the imbalanced classes problem of Intrusion Detection System,2018,"['Intrusion detection system', 'Weighted Support Vector Machine', 'Stratified sampling', 'Cost function', 'NSL-KDD']",,"Improving the intrusion detection system (IDS) is a pressing need for cyber security world. With the growth of computer networks, there are constantly daily new attacks. Machine Learning (ML) is one of the most important fields which have great contribution to address the intrusion detection issues. One of these issues relates to the imbalance of the diverse classes of network traffic. Accuracy paradox is a result of training ML algorithm with imbalanced classes. Most of the previous efforts concern improving the overall accuracy of these models which is truly important. However, even they improved the total accuracy of the system; it fell in the accuracy paradox. The seriousness of the threat caused by the minor classes and the pitfalls of the previous efforts to address this issue is the motive for this work. In this paper, we consolidated stratified sampling, cost function and weighted Support Vector Machine (WSVM) method to address the accuracy paradox of ID problem. This model achieved good results of total accuracy and superior results in the small classes like the User-To-Remote and Remote-To-Local attacks using the improved version of the benchmark dataset KDDCup99 which is called NSL-KDD."
Deep Structured Learning: Architectures and Applications,2018,"['Artificial Intelligence', 'machine learning', 'deep learning', 'deep belief network', 'deep neural network', 'deep structured learning', 'hierarchical learning.', 'Artificial Intelligence', 'machine learning', 'deep learning', 'deep belief network', 'deep neural network', 'deep structured learning', 'hierarchical learning']",,"Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies."
Deep BBN Learning for Health Assessment toward Decision-Making on Structures under Uncertainties,2018,"['deep learning', 'probabilistic learning', 'deep Bayesian belief network learning', 'structural condition assessment']",,"Structural systems are often exposed to harsh environment, while these environmental factors in turn could degrade the system over time. Their health state and structural conditions are key for structural safety control and decision-making management. Although great efforts have been paid on this field, the high level of variability due to noise and other interferences, and the uncertainties associated with data collection, structural performance and in-service operational environments post great challenges in finding information to assist decision making. The machine learning techniques in recent years have been gaining increasing attentions due to their merits capturing information from statistical representation of events and thus enabling making decision. In this study, the deep Bayesian Belief Network Learning (DBBN) was used to extract structural information and probabilistically determine structural conditions. Different to conventional shallow learning that highly relies on the quality of the hand-crafted features, the deep learning is an end-to-end method to encode the information and interpret vast amount of data with minimizing or no features. A case study was conducted to address the methods for structure under viabilities and uncertainties due to operation, damage and noise interferences. Numerical results revealed that the deep learning exhibits considerably enhanced accuracy for structural diagnostics, as compared to the supervised shallow learning. With predetermined training set, the DBBN could accurately determine the structural health state in terms of damage level, which could dramatically help decision making for further structural retrofit or not. Note that the noise interference could contaminate the data representation and in turn increase the difficulty of the data mining, though the deep learning could reduce the impacts, as compared to conventional shallow learning techniques."
Deep Structured Learning: Architectures and Applications,2018,"['Artificial Intelligence', 'machine learning', 'deep learning', 'deep belief network', 'deep neural network', 'deep structured learning', 'hierarchical learning']",,"Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies."
Controller Learning Method of Self-driving Bicycle Using State-of-the-art Deep Reinforcement Learning Algorithms,2018,"['Reinforcement Learning', 'DDPG', 'Machine Learning', 'Bicycle Self Balancing', 'Deep Learning']",,"Recently, there have been many studies on machine learning. Among them, studies on reinforcement learning are actively worked. In this study, we propose a controller to control bicycle using DDPG (Deep Deterministic Policy Gradient) algorithm which is the latest deep reinforcement learning method. In this paper, we redefine the compensation function of bicycle dynamics and neural network to learn agents. When using the proposed method for data learning and control, it is possible to perform the function of not allowing the bicycle to fall over and reach the further given destination unlike the existing method. For the performance evaluation, we have experimented that the proposed algorithm works in various environments such as fixed speed, random, target point, and not determined. Finally, as a result, it is confirmed that the proposed algorithm shows better performance than the conventional neural network algorithms NAF and PPO."
Effects of the Use of Bilingual Dictionary and Machine Translation on EFL Students  English Proficiency,2018,"['이중언어사전', '번역기', 'EFL 학습자', '영어능숙도', 'bilingual dictionary', 'machine translation', 'EFL students', 'English proficiency']",,"and machine translation on Korean EFL students  English speaking and writing proficiency. Participants in the present study were 44 Korean college students. The participants were third- or fourth-year students who enrolled in an English speaking and writing class. Divided into two experimental groups, bilingual dictionary group (n=24) and machine translation group (n=20), all participants engaged in the 16-week experiment. To examine the effectiveness of two different tools, pre- and post-tests were performed based on ACTFL tests. A perception survey was also conducted to explore the participants  attitudes toward English learning. For data analysis, paired samples t-tests were administered to compare the pre- and post-test scores. Independent t-tests were run to compare the group difference. Findings indicate that participants in both the bilingual dictionary and machine translation groups significantly improved their speaking and writing proficiency. No group difference was observed, indicating that the two tools are equally effective for EFL learning. The survey results revealed that the bilingual dictionary group had more positive attitudes toward English learning than the machine translation group. Implications and suggestions are made at the end."
Deep Structured Learning: Architectures and Applications,2018,"['Artificial Intelligence', 'machine learning', 'deep learning', 'deep belief network', 'deep neural network', 'deep structured learning', 'hierarchical learning.']",,
Personal Credit Evaluation System through Telephone Voice Analysis: By Support Vector Machine,2018,"['음성분석', '목소리 신용척도', '음성특성', '기계학습', '서포트 벡터 머신', 'Voice analysis', 'Voice credit rating', 'Voice characteristics', 'Machine learning', 'Support vector machine']",,"The human voice is one of the easiest methods for the information transmission between human beings. The characteristics of voice can vary from person to person and include the speed of speech, the form and function of the vocal organ, the pitch tone, speech habits, and gender. The human voice is a key element of human communication. In the days of the Fourth Industrial Revolution, voices are also a major means of communication between humans and humans, between humans and machines, machines and machines. And for that reason, people are trying to communicate their intentions to others clearly. And in the process, it contains various additional information along with the linguistic information. The Information such as emotional status, health status, part of trust, presence of a lie, change due to drinking, etc. These linguistic and non-linguistic information can be used as a device for evaluating the individual's credit worthiness by appearing in various parameters through voice analysis. Especially, it can be obtained by analyzing the relationship between the characteristics of the fundamental frequency(basic tonality) of the vocal cords, and the characteristics of the resonance frequency of the vocal track.In the previous research, the necessity of various methods of credit evaluation and the characteristic change of the voice according to the change of credit status were studied. In this study, we propose a personal credit discriminator by machine learning through parameters extracted through voice."
Effects of the Use of Bilingual Dictionary and Machine Translation on EFL Students' English Proficiency,2018,"['이중언어사전', '번역기', 'EFL 학습자', '영어능숙도', 'bilingual dictionary', 'machine translation', 'EFL students', 'English proficiency']",,"The present study investigates the effects of the use of bilingual dictionaries and machine translation on Korean EFL students' English speaking and writing proficiency. Participants in the present study were 44 Korean college students. The participants were third- or fourth-year students who enrolled in an English speaking and writing class. Divided into two experimental groups, bilingual dictionary group (n=24) and machine translation group (n=20), all participants engaged in the 16-week experiment. To examine the effectiveness of two different tools, pre- and post-tests were performed based on ACTFL tests. A perception survey was also conducted to explore the participants' attitudes toward English learning. For data analysis, paired samples t-tests were administered to compare the pre- and post-test scores. Independent t-tests were run to compare the group difference. Findings indicate that participants in both the bilingual dictionary and machine translation groups significantly improved their speaking and writing proficiency. No group difference was observed, indicating that the two tools are equally effective for EFL learning. The survey results revealed that the bilingual dictionary group had more positive attitudes toward English learning than the machine translation group. Implications and suggestions are made at the end."
A Comparative Study of Transfer Learning–based Methods for Inspection of Mobile Camera Modules,2018,"['Transfer learning', 'Machine vision', 'Camera module', 'Defect inspection']",,"We apply three transfer learning methods using the pretrained AlexNet convolutional neural network (CNN) model to detect defects in camera modules. In experiments, the performance of fine-tuning methods using random initial parameters in less than the two last fully connected layers while using predetermined weights as initial parameters for the remaining layers, showed better performance than other methods. We expect that the transfer learning–based CNN can be effectively applied to camera module inspection systems."
Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Machine learning', 'Periodontal diseases', 'Supervised machine learning']",,"Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%–91.2%) for premolars and 73.4% (95% CI, 59.9%–84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT."
Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Machine learning', 'Periodontal diseases', 'Supervised machine learning']",,"Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%-91.2%) for premolars and 73.4% (95% CI, 59.9%-84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT."
Building a HOG Descriptor Model of Pedestrian Images Using GA and GP Learning,2018,"['HOG model', 'Genetic algorithm', 'Genetic programming', 'Learning', 'Pedestrian detection']",,"For detecting a pedestrian by using features of images, it is generally needed to establish a reference model that is used to match with input images. The support vector machine (SVM) or AdaBoost Cascade method have been generally used to train the reference pedestrian model in the approaches using the histogram of oriented gradients (HOG) as features of the pedestrian model. In this paper, we propose a new approach to match HOG features of input images with reference model and to learn the structure and parameters of the reference model. The Gaussian scoring method proposed in this paper evaluates the degree of feature coincidence with HOG maps divided with angle of the HOG vector. We also propose two approaches for leaning of the reference model: genetic algorithm (GA) based learning and genetic programming (GP) based learning. The GA and GP are used to search the best parameters of the gene and nonlinear function representing feature map of pedestrian model, respectively. We performed experiments to verify the performance of proposed method in terms of accuracy and processing time with INRIA person dataset."
Building a HOG Descriptor Model of Pedestrian Images Using GA and GP Learning,2018,"['HOG model', 'Genetic algorithm', 'Genetic programming', 'Learning', 'Pedestrian detection']",,"For detecting a pedestrian by using features of images, it is generally needed to establish a reference model that is used to match with input images. The support vector machine (SVM) or AdaBoost Cascade method have been generally used to train the reference pedestrian model in the approaches using the histogram of oriented gradients (HOG) as features of the pedestrian model. In this paper, we propose a new approach to match HOG features of input images with reference model and to learn the structure and parameters of the reference model. The Gaussian scoring method proposed in this paper evaluates the degree of feature coincidence with HOG maps divided with angle of the HOG vector. We also propose two approaches for leaning of the reference model: genetic algorithm (GA) based learning and genetic programming (GP) based learning. The GA and GP are used to search the best parameters of the gene and nonlinear function representing feature map of pedestrian model, respectively. We performed experiments to verify the performance of proposed method in terms of accuracy and processing time with INRIA person dataset."
An analysis of smartphone overuse recognition in terms of emotions using brainwaves and deep learning,2018,"['Deep belief network', 'Electroencephalography (EEG)', 'Emotion recognition', 'Smartphone overuse']",,"<P><B>Abstract</B></P>  <P>The overuse of smartphones is increasingly becoming a social problem. In this paper, we analyze smartphone overuse levels, according to emotion, by examining brainwaves and deep learning. We assessed the asymmetry power with respect to theta, alpha, beta, gamma, and total brainwave activity in 11 lobes. The deep belief network (DBN) was used as the deep learning method, along with k-nearest neighbor (kNN) and a support vector machine (SVM), to determine the smartphone addiction level. The risk group (13 subjects) and non-risk group (12 subjects) watched videos portraying the following concepts: relaxed, fear, joy, and sadness. We found that the risk group was more emotionally unstable than the non-risk group. In recognizing Fear, a clear difference appeared between the risk and non-risk group. The results showed that the gamma band was the most obviously different between the risk and non-risk groups. Moreover, we demonstrated that the measurements of activity in the frontal, parietal, and temporal lobes were indicators of emotion recognition. Through the DBN, we confirmed that these measurements were more accurate in the non-risk group than they were in the risk group. The risk group had higher accuracy in low valence and arousal; on the other hand, the non-risk group had higher accuracy in high valence and arousal.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The smartphone addiction risk group (13 subjects) and non-risk group (12 subjects) watched videos portraying the concepts of relaxed, fear, joy, and sadness. </LI> <LI>  The risk group was more emotionally unstable than the non-risk group in EEG. Especially, in recognizing fear, a clear difference appeared between the risk and non-risk group. </LI> <LI>  We assessed the asymmetry power with respect to theta, alpha, beta, gamma, and total activity in 11 lobes, and the gamma band was the most obviously different between the risk and non-risk groups. </LI> <LI>  We found that the measurements of activity in the frontal, parietal, and temporal lobes were indicators of emotion recognition. </LI> <LI>  Through the deep belief network, we confirmed that the risk group had higher accuracy in low valence and arousal; on the other hand, the non-risk group had higher accuracy in high valence and arousal. </LI> </UL> </P>"
The Gods of the Fourth Industrial Revolution -Philosophies and Religions in the Age of Deep Learning-,2018,"['산업혁명', '4차 산업혁명', '전통적 종교', '딥 러닝', '인공지능', 'Industrial Revolution', 'the Fourth Industrial Revolution', 'Traditional Religions', 'Deep Learning', 'Artificial Intelligence']",,"Reading the signs of the times has been regarded as a central task for all religions, perhaps especially for those religions which are directed towards an end of history. Klaus Schwab characterized emerging technologies that bridge the gap between animals and machines as the “the fourth industrial revolution”. The industrial revolutions are accompanied by philosophies and had a significant effect on the traditional religions. The “market” and “the individual” are the God of third industrial revolution, and the task of the traditional religions is to offer a theological critique of these quasi-religions as forms of idolatry. Artificial Intelligence with deep learning might indeed be seen as being able to replace natural intelligence, but these problems will be worked on more easily in a dialogue between the sciences and the humanities which use the wisdom of the religions as resources for dealing with the problems. Therefore the most important thing is that human creatures are to be perfected by God in communion with God."
Deep Learning in Nuclear Medicine and Molecular Imaging: Current Perspectives and Future Directions,2018,"['Deep learning', 'Molecular imaging', 'Machine learning', 'Convolutional neural network', 'Precision medicine']",,"Recent advances in deep learning have impacted various scientific and industrial fields. Due to the rapid application of deep learning in biomedical data, molecular imaging has also started to adopt this technique. In this regard, it is expected that deep learning will potentially affect the roles of molecular imaging experts as well as clinical decision making. This review firstly offers a basic overview of deep learning particularly for image data analysis to give knowledge to nuclear medicine physicians and researchers. Because of the unique characteristics and distinctive aims of various types of molecular imaging, deep learning applications can be different from other fields. In this context, the review deals with current perspectives of deep learning in molecular imaging particularly in terms of development of biomarkers. Finally, future challenges of deep learning application for molecular imaging and future roles of experts in molecular imaging will be discussed."
Multi-Scale Distributed Representation for Deep Learning and its Application to b-Jet Tagging,2018,"['Machine Learning', 'Jet Tagging']",,Recently machine learning algorithms based on deep layered artificial neural networks (DNNs) have been applied to a wide variety of high energy physics problems such as jet tagging or event classification. We explore a simple but effective preprocessing step which transforms each realvalued observational quantity or input feature into a binary number with a fixed number of digits. Each binary digit represents the quantity or magnitude in different scales. We have shown that this approach improves the performance of DNNs significantly for some specific tasks without any further complication in feature engineering. We apply this multi-scale distributed binary representation to deep learning on b-jet tagging using daughter particles’ momenta and vertex information.
Diabetes detection using deep learning algorithms,2018,"['Deep learning', 'Diabetes', 'Heart rate variability', 'ECG', 'CNN', 'LSTM']",,"Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%."
Infrared and Visible Image Fusion Based on NSCT and Deep Learning,2018,"['Boltzmann Machine', 'Depth Model', 'Image Fusion', 'Split Bregman Iterative Algorithm']",,"An image fusion method is proposed on the basis of depth model segmentation to overcome theshortcomings of noise interference and artifacts caused by infrared and visible image fusion. Firstly, the deepBoltzmann machine is used to perform the priori learning of infrared and visible target and backgroundcontour, and the depth segmentation model of the contour is constructed. The Split Bregman iterativealgorithm is employed to gain the optimal energy segmentation of infrared and visible image contours. Then,the nonsubsampled contourlet transform (NSCT) transform is taken to decompose the source image, and thecorresponding rules are used to integrate the coefficients in the light of the segmented background contour.Finally, the NSCT inverse transform is used to reconstruct the fused image. The simulation results ofMATLAB indicates that the proposed algorithm can obtain the fusion result of both target and backgroundcontours effectively, with a high contrast and noise suppression in subjective evaluation as well as great meritsin objective quantitative indicators."
Infrared and Visible Image Fusion Based on NSCT and Deep Learning,2018,"['Boltzmann Machine', 'Depth Model', 'Image Fusion', 'Split Bregman Iterative Algorithm']",,"An image fusion method is proposed on the basis of depth model segmentation to overcome the shortcomings of noise interference and artifacts caused by infrared and visible image fusion. Firstly, the deep Boltzmann machine is used to perform the priori learning of infrared and visible target and background contour, and the depth segmentation model of the contour is constructed. The Split Bregman iterative algorithm is employed to gain the optimal energy segmentation of infrared and visible image contours. Then, the nonsubsampled contourlet transform (NSCT) transform is taken to decompose the source image, and the corresponding rules are used to integrate the coefficients in the light of the segmented background contour. Finally, the NSCT inverse transform is used to reconstruct the fused image. The simulation results of MATLAB indicates that the proposed algorithm can obtain the fusion result of both target and background contours effectively, with a high contrast and noise suppression in subjective evaluation as well as great merits in objective quantitative indicators."
Semi-Supervised Learning for Detecting of Abusive Sentence on Twitter using Deep Neural Network with Fuzzy Category Representation,2018,"['혐오 발언', '퍼지 범주 표현', '준지도 학습', '자연어 처리', '기계 학습', 'hate-speech', 'fuzzy category representation', 'semi-supervised learning', 'natural language processing', 'machine learning']",,
Application of support vector machine with firefly algorithm for investigation of the factors affecting the shear strength of angle shear connectors,2018,"['C-shaped shear connector', 'channel', 'estimation', 'prediction', 'support vector machine', 'firefly algorithm']",,"The factors affecting the shear strength of the angle shear connectors in the steel-concrete composite beams can play an important role to estimate the efficacy of a composite beam. Therefore, the current study has aimed to verify the output of shear capacity of angle shear connector according to the input provided by Support Vector Machine (SVM) coupled with Firefly Algorithm (FFA). SVM parameters have been optimized through the use of FFA, while genetic programming (GP) and artificial neural networks (ANN) have been applied to estimate and predict the SVM-FFA models' results. Following these results, GP and ANN have been applied to develop the prediction accuracy and generalization capability of SVM-FFA. Therefore, SVM-FFA could be performed as a novel model with predictive strategy in the shear capacity estimation of angle shear connectors. According to the results, the Firefly algorithm has produced a generalized performance and be learnt faster than the conventional learning algorithms."
Comparisons of Deep Learning Algorithms for MNIST in Real-Time Environment,2018,"['Capsule networks', 'Dynamic routing', 'Residual learning', 'CNN', 'Logistic regression']",,"Recognizing handwritten digits was challenging task in a couple of years ago. Thanks to machine learning algorithms, today, the issue has solved but those algorithms require much time to train and to recognize digits. Thus, using one of those algorithms to an application that works in real-time, is complex. Notwithstanding use of a trained model, if the model uses deep neural networks it requires much more time to make a prediction and becomes more complicated as well as memory usage also increases. It leads real-time application to delay and to work slowly even using trained model. A memory usage is also essential as using smaller memory of trained models works considerable faster comparing to models with huge pre-processed memory. For this work, we implemented four models on the basis of unlike algorithms which are capsule network, deep residual learning model, convolutional neural network and multinomial logistic regression to recognize handwritten digits. These models have unlike structure and they have showed a great results on MNIST before so we aim to compare them in real-time environment. The dataset MNIST seems most suitable for this work since it is popular in the field and basically used in many state-of-the-art algorithms beyond those models mentioned above. We purpose revealing most suitable algorithm to recognize handwritten digits in real-time environment. Also, we give comparisons of train and evaluation time, memory usage and other essential indexes of all four models."
Comparisons of Deep Learning Algorithms for MNIST in Real-Time Environment,2018,"['Capsule networks', 'Dynamic routing', 'Residual learning', 'CNN', 'Logistic regression']",,"Recognizing handwritten digits was challenging task in a couple of years ago. Thanks to machine learning algorithms, today, the issue has solved but those algorithms require much time to train and to recognize digits. Thus, using one of those algorithms to an application that works in real-time, is complex. Notwithstanding use of a trained model, if the model uses deep neural networks it requires much more time to make a prediction and becomes more complicated as well as memory usage also increases. It leads real-time application to delay and to work slowly even using trained model. A memory usage is also essential as using smaller memory of trained models works considerable faster comparing to models with huge pre-processed memory. For this work, we implemented four models on the basis of unlike algorithms which are capsule network, deep residual learning model, convolutional neural network and multinomial logistic regression to recognize handwritten digits. These models have unlike structure and they have showed a great results on MNIST before so we aim to compare them in real-time environment. The dataset MNIST seems most suitable for this work since it is popular in the field and basically used in many state-of-the-art algorithms beyond those models mentioned above. We purpose revealing most suitable algorithm to recognize handwritten digits in real-time environment. Also, we give comparisons of train and evaluation time, memory usage and other essential indexes of all four models."
Application of support vector machine with firefly algorithm for investigation of the factors affecting the shear strength of angle shear connectors,2018,"['C-shaped shear connector', 'channel', 'estimation', 'prediction', 'support vector machine', 'firefly algorithm']",,"The factors affecting the shear strength of the angle shear connectors in the steel-concrete composite beams can play an important role to estimate the efficacy of a composite beam. Therefore, the current study has aimed to verify the output of shear capacity of angle shear connector according to the input provided by Support Vector Machine (SVM) coupled with Firefly Algorithm (FFA). SVM parameters have been optimized through the use of FFA, while genetic programming (GP) and artificial neural networks (ANN) have been applied to estimate and predict the SVM-FFA models' results. Following these results, GP and ANN have been applied to develop the prediction accuracy and generalization capability of SVM-FFA. Therefore, SVM-FFA could be performed as a novel model with predictive strategy in the shear capacity estimation of angle shear connectors. According to the results, the Firefly algorithm has produced a generalized performance and be learnt faster than the conventional learning algorithms."
Projection spectral analysis: A unified approach to PCA and ICA with incremental learning,2018,"['independent component analysis', 'machine learning', 'neural network', 'principal component analysis', 'projection spectral analysis', 'singular value decomposition', 'spectral theorem']",,"Projection spectral analysis is investigated and refined in this paper, in order to unify principal component analysis and independent component analysis. Singular value decomposition and spectral theorems are applied to nonsymmetric correlation or covariance matrices with multiplicities or singularities, where projections and nilpotents are obtained. Therefore, the suggested approach not only utilizes a sum‐product of orthogonal projection operators and real distinct eigenvalues for squared singular values, but also reduces the dimension of correlation or covariance if there are multiple zero eigenvalues. Moreover, incremental learning strategies of projection spectral analysis are also suggested to improve the performance."
Korean and English Sentiment Analysis Using the Deep Learning,2018,"['English Text', 'Korean Text', 'Sentiment', 'Deep Learning', 'Neural Network', 'Deep Neural Network']",,"Social media has immense popularity among all services today. Data from social network services (SNSs) can be used for various objectives, such as text prediction or sentiment analysis. There is a great deal of Korean and English data on social media that can be used for sentiment analysis, but handling such huge amounts of unstructured data presents a difficult task. Machine learning is needed to handle such huge amounts of data. This research focuses on predicting Korean and English sentiment using deep forward neural network with a deep learning architecture and compares it with other methods, such as LDA MLP and GENSIM, using logistic regression. The research findings indicate an approximately 75% accuracy rate when predicting sentiments using DNN, with a latent Dirichelet allocation (LDA) prediction accuracy rate of approximately 81%, with the corpus being approximately 64% accurate between English and Korean."
Application of compressive sensing and variance considered machine to condition monitoring,2018,"['compressive sensing', 'condition monitoring', 'receiver operating characteristic', 'variance considered machine']",,"A significant data problem is encountered with condition monitoring because the sensors need to measure vibration data at a continuous and sometimes high sampling rate. In this study, compressive sensing approaches for condition monitoring are proposed to demonstrate their efficiency in handling a large amount of data and to improve the damage detection capability of the current condition monitoring process. Compressive sensing is a novel sensing/sampling paradigm that takes much fewer data than traditional data sampling methods. This sensing paradigm is applied to condition monitoring with an improved machine learning algorithm in this study. For the experiments, a built-in rotating system was used, and all data were compressively sampled to obtain compressed data. The optimal signal features were then selected without the signal reconstruction process. For damage classification, we used the Variance Considered Machine, utilizing only the compressed data. The experimental results show that the proposed compressive sensing method could effectively improve the data processing speed and the accuracy of condition monitoring of rotating systems."
Application of compressive sensing and variance considered machine to condition monitoring,2018,"['compressive sensing', 'condition monitoring', 'receiver operating characteristic', 'variance considered machine']",,"A significant data problem is encountered with condition monitoring because the sensors need to measure vibration data at a continuous and sometimes high sampling rate. In this study, compressive sensing approaches for condition monitoring are proposed to demonstrate their efficiency in handling a large amount of data and to improve the damage detection capability of the current condition monitoring process. Compressive sensing is a novel sensing/sampling paradigm that takes much fewer data than traditional data sampling methods. This sensing paradigm is applied to condition monitoring with an improved machine learning algorithm in this study. For the experiments, a built-in rotating system was used, and all data were compressively sampled to obtain compressed data. The optimal signal features were then selected without the signal reconstruction process. For damage classification, we used the Variance Considered Machine, utilizing only the compressed data. The experimental results show that the proposed compressive sensing method could effectively improve the data processing speed and the accuracy of condition monitoring of rotating systems."
Korean and English Sentiment Analysis Using the Deep Learning,2018,"['English Text', 'Korean Text', 'Sentiment', 'Deep Learning', 'Neural Network', 'Deep Neural Network']",,"Social media has immense popularity among all services today. Data from social network services (SNSs) can be used for various objectives, such as text prediction or sentiment analysis. There is a great deal of Korean and English data on social media that can be used for sentiment analysis, but handling such huge amounts of unstructured data presents a difficult task. Machine learning is needed to handle such huge amounts of data. This research focuses on predicting Korean and English sentiment using deep forward neural network with a deep learning architecture and compares it with other methods, such as LDA MLP and GENSIM, using logistic regression. The research findings indicate an approximately 75% accuracy rate when predicting sentiments using DNN, with a latent Dirichelet allocation (LDA) prediction accuracy rate of approximately 81%, with the corpus being approximately 64% accurate between English and Korean."
Political Opinion Mining from Article Comments using Deep Learning,2018,"['recurrent neural network', 'opinion mining', 'semantic analysis']",,"Policy polls, which investigate the degree of support that the policy　has for policy implementation, play an important role in making decisions. As the number of Internet users increases, the public is actively commenting on their policy news stories.　Current policy polls tend to rely heavily on phone and offline surveys. Collecting and analyzing policy articles is useful in policy surveys.　In this study, we propose a method of analyzing comments using deep learning technology showing outstanding performance in various fields. In particular, we designed various models based on the recurrent neural network (RNN) which is suitable for sequential data and compared the performance with the support vector machine (SVM), which is a traditional machine learning model. For all test sets, the SVM model show an accuracy of 0.73 and the RNN model have an accuracy of 0.83."
Structuring of Unstructured SNS Messages on Rail Services using Deep Learning Techniques,2018,"['Data Structuring', 'Deep neural network', 'Information of Rail services', 'Social network service', 'Text mining']",,"This paper presents a structuring process of unstructured social network service (SNS) messages on rail services. We crawl messages about rail services posted on SNS and extract keywords indicating date and time, rail operating company, station name, direction, and rail service types from each message. Among them, the rail service types are classified by machine learning according to predefined rail service types, and the rest are extracted by regular expressions. Words are converted into vector representations using Word2Vec and a conventional Convolutional Neural Network (CNN) is used for training and classification. For performance measurement, our experimental results show a comparison with a TF-IDF and Support Vector Machine (SVM) approach. This structured information in the database and can be easily used for services for railway users."
Deep-learning-based automatic computer-aided diagnosis system for diabetic retinopathy,2018,"['Computer-aided diagnosis', 'Diabetic retinopathy', 'Deep neural network', 'AlexNet DNN', 'Convolutional neural network', 'Gaussian mixture model', 'Linear discriminant analysis', 'SVM']",,"The high-pace rise in advanced computing andimaging systems has given rise to a new research dimensioncalled computer-aided diagnosis (CAD) system forvarious biomedical purposes. CAD-based diabeticretinopathy (DR) can be of paramount significance toenable early disease detection and diagnosis decision.Considering the robustness of deep neural networks(DNNs) to solve highly intricate classification problems, inthis paper, AlexNet DNN, which functions on the basis ofconvolutional neural network (CNN), has been applied toenable an optimal DR CAD solution. The DR modelapplies a multilevel optimization measure that incorporatespre-processing, adaptive-learning-based Gaussian mixturemodel (GMM)-based concept region segmentation, connectedcomponent-analysis-based region of interest (ROI)localization, AlexNet DNN-based highly dimensional featureextraction, principle component analysis (PCA)- andlinear discriminant analysis (LDA)-based feature selection,and support-vector-machine-based classification to ensureoptimal five-class DR classification. The simulation resultswith standard KAGGLE fundus datasets reveal that theproposed AlexNet DNN-based DR exhibits a better performancewith LDA feature selection, where it exhibits aDR classification accuracy of 97.93% with FC7 features,whereas with PCA, it shows 95.26% accuracy. Comparativeanalysis with spatial invariant feature transform (SIFT)technique (accuracy—94.40%) based DR feature extractionalso confirms that AlexNet DNN-based DR outperformsSIFT-based DR."
Altered task-dependent functional connectivity patterns during subjective recollection experiences of episodic retrieval in postpartum women,2018,"['Episodic memory', 'fcMVPA', 'Postpartum women', 'Remember/Know procedure', 'Subjective recollection effect']",,"<P><B>Abstract</B></P>  <P>Numerous studies have suggested that postpartum women show a decline in cognitive abilities. However, to date, no study has investigated the presence of qualitative alterations in recognition memory processes in postpartum women that may lead to a decline in cognitive ability. To address this issue, we employed the Remember/Know procedure and functional magnetic resonance imaging (fMRI). Behavioral results demonstrated that compared with the matched control (CTRL) group, the postpartum (PP) group endorsed “Remember” less and “Know” more to old items. A univariate analysis of fMRI data indicated lower neural activity of the subjective recollection network in the PP group than in the CTRL group. We also performed a large-scale functional connectivity multivariate pattern analysis (fcMVPA) using task-dependent time-series to detect differences in functional connectivity patterns and neural interactivity between the PP and CTRL groups. The fcMVPA results revealed that the PP group exhibited altered functional connectivity patterns from which machine learning algorithms could discriminate group membership with 94% accuracy. Collectively, these findings demonstrated that altered subjective recollection processes in the PP group during episodic memory decisions are associated with diminished neural activity and abnormal interactivity across the subjective recollection network. We believe that this is one of the first studies demonstrating qualitative alterations in recognition memory processes in postpartum women.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We investigated recognition memory processes in postpartum women (PP). </LI> <LI>  PP endorsed old items with “Remember” responses less often than control women. </LI> <LI>  PP showed decreased neural activity across the subjective recollection network. </LI> <LI>  We applied iterative functional connectivity multivariate pattern analysis. </LI> <LI>  Large-scale functional connectivity patterns across the network were altered in PP. </LI> </UL> </P>"
Study on Using Deep Learning Method to Realize The Emotion Linkage between The Gamer and His Avatar in Poker Game,2018,"['Psychological game', 'Emotion recognition', 'CNN', 'SVM', 'Emotion linkage technology']","다른 장르의 게임에 비해 포커는 게이머의 심리적 요소가 많은 영향을 끼친다. 본 논문에서는 CNN과 SVM을 기반으로 온라인 포커 게임에 게이머와 아바타 간의 감성연결을 실현하기 위한 새로운 감성 인식방법을 제안한다. CNN모델을 이용하여 원래 얼굴 이미지의 특징을 추출하고, 다중 클래스 SVM분류기를 사용하여 목표 이미지를 인식하고 분류한다.FER-2013데이터베이스에서 이 방법은 감성인식률 68.79 %를 달성하였다. 기존의 다른 감성 인식 모델과 비교하면, 이 모델은 뚜렷한 장점을 보일 수 있다. 본 게임은 Socket 통신방식을 통해 감성인식결과를 Seven Poker로 전송하여 아바타가 게이머와 같은 감성을 표현하도록 설계하였다. 온라인 포커 게임에 감성연결 기술을 이용하면 게임과 인간의 상호작용이 향상될 뿐 아니라 게이머가 상대방의 심리적인 활동을 효과적으로 분석할 수 있다. 감성연결 기술은 게임에서 게이머들에게 새로운 게임 경험을 제공할 수 있는 기술이라고 생각된다.","Compared to other types of games, poker game is a psychological game based on gamer s psychological activity. This paper proposes a method based on convolutional neural network (CNN) and support vector machine (SVM) to realize the emotion recognition to link the gamer and his avatar in online poker game. The CNN model is used to extract feature of the original face images, and the multi-class SVM classifier is used to classify the emotions. On the FER-2013 database, the proposed method achieves 68.79% emotion recognition rate, and has obvious advantages compared with most other emotion recognition methods. Next, through the socket communication, the result of the emotion recognition is transferred to the designed seven poker game to realize the emotion linkage between the gamer and his avatar. More importantly, the emotion linkage technology not only helps the gamer to analyze the opponent’s psychological state, but also enhances the interaction of the game. It is undoubtedly a new breakthrough in game play that will give gamers a whole new gaming experience."
Reliable Fault Diagnosis of Rotary Machine Bearings Using a Stacked Sparse Autoencoder-Based Deep Neural Network,2018,,,"<P>Due to enhanced safety, cost-effectiveness, and reliability requirements, fault diagnosis of bearings using vibration acceleration signals has been a key area of research over the past several decades. Many fault diagnosis algorithms have been developed that can efficiently classify faults under constant speed conditions. However, the performances of these traditional algorithms deteriorate with fluctuations of the shaft speed. In the past couple of years, deep learning algorithms have not only improved the classification performance in various disciplines (e.g., in image processing and natural language processing), but also reduced the complexity of feature extraction and selection processes. In this study, using complex envelope spectra and stacked sparse autoencoder- (SSAE-) based deep neural networks (DNNs), a fault diagnosis scheme is developed that can overcome fluctuations of the shaft speed. The complex envelope spectrum made the frequency components associated with each fault type vibrant, hence helping the autoencoders to learn the characteristic features from the given input signals more readily. Moreover, the implementation of SSAE-DNN for bearing fault diagnosis has avoided the need of handcrafted features that are used in traditional fault diagnosis schemes. The experimental results demonstrate that the proposed scheme outperforms conventional fault diagnosis algorithms in terms of fault classification accuracy when tested with variable shaft speed data.</P>"
Assessment of delaminated smart composite laminates via system identification and supervised learning,2018,"['System identification', 'Artificial intelligence', 'Smart composite laminates', 'Delamination damage', 'Optimal classifier']",,"<P><B>Abstract</B></P>  <P>This paper proposes the synergetic integration of system identification and artificial intelligence for the detection and assessment of delamination damages in smart composite laminates. An electromechanically coupled mathematical model is developed for the healthy and delaminated smart composite laminates on the basis of improved layerwise theory, higher order electric potential field and finite element method. A discriminative feature space is constructed for the healthy and delaminated structures via system identification from their structural vibration responses. The discriminative features are used for the training and cross-validation of various supervised machine learning classifiers and an optimal classifier is identified. The optimal classifier is employed to make predictions on unseen test delamination cases, and its predictions are validated via a dimensionality reduction tool. The obtained results show that the proposed technique could be employed as a reliable tool for nondestructive evaluation of smart composite laminates.</P>"
머신 러닝을 활용한 이러닝 학습 환경에서의 학습자 성취 예측 모형 탐색,2018,"['머신 러닝', '이러닝', '예측 모형', 'K-MOOC', '대학생', 'machine learning', 'e-learning', 'predictive model', 'K-MOOC', 'undergraduate student']","본 연구는 머신 러닝을 활용해 이러닝 강의의 학습자의 데이터를 토대로 학습 성취 수준을 예측함으로써, 이러닝을 활용한 과학교육에 대한 시사점을 제공하고자 하였다. 이에 본 연구는 2018년 8월부터 한 달간 2016~2017년 4학기 동안 수도권의 한대학에서 개설된 이러닝 강의에 참여한 998명의 학습자 정보를 토대로 k-근접 이웃 알고리즘, 서포트 벡터 머신, 의사결정 나무, 랜덤 포레스트, 그래디언트 부스팅, 인공 신경망 등 6가지의 분석을 통해 학습 성취 수준을 예측하였다. 그 결과, 그래디언트 부스팅을 제외한 나머지 모형에서 모두 90% 수준의 높은 정확도를 보였다. 학습 성취에 미치는 요인을 살펴보면 트리 분석에서는 기말고사, 중간고사, 과제, 출결 순으로 나타나지만 서포트 벡터 머신의 피처 선택에서는 과제, 기말고사, 중간고사, 출결 순으로 나타난다. 이는 출결 정보만으로는 유의미한 학습이 이뤄지고 있는지 판단할 수 없음을 뜻한다. 이에 본 연구는 최적화된 머신 러닝 활용 결과를 토대로 이러닝을 활용한 과학교육 및 학습자 성취 향상을 위한 여러 시사점과 후속 연구를 제안하였다.","This study aimed at predicting the learning outcomes of students participating in the e-learning course based on machine learning and giving some implications for science education in the tertiary level. Thus, this study selected metadata of a total of 998 students who enrolled the introductory science course for the last for semesters, from 2016 to 2017, and developed a predictive model relying on k-Nearest Neighbors, Support Vector Machine, Decision Tree, Random Forest, Gradient Boosting, and Artificial Neural Network. As a result, all the models except Gradient Boosting showed reliable performance over 90 percents of accuracy. Regarding the importance value of each parameter for students’ learning, models depending on tree analysis put the priority on final term, middle term, homework and attendance in order whereas SVM supported homework, final term, middle term and attendance. This result indicates that attendance information does not guarantee if students participate in the meaning learning. Thus, this study gave some implications for improving students’ learning outcome in the e-learning environment and future studies working with machine learning."
머신러닝기반 범죄발생 위험지역 예측,2018,"['Crime Prediction', 'Machine Learning', 'Decision Tree', 'Random Forest', 'SVM', '범죄예측', '머신러닝', '의사결정나무', '랜덤포레스트', '서포트벡터머신']","우리나라의 시민들은 범죄에 대한 일반적인 사항만을 알 수 있을 뿐, 자신이 범죄위험에 얼마나 노출되어 있는지를 파악하기 어렵다. 경찰의 입장에서도 범죄발생 지역을 예측할 수 있다면 경찰력이 부족한 상황에서 효율성 있게 범죄에 대처 가능할 것이지만 아직 우리나라에서는 예측시스템이 없고, 관련 연구도 매우 부족한 실정이다. 이에 본 연구에서는 범죄발생 위험지역 예측 자동화 시스템 개발의 첫 번째 단계로 빅데이터로 구축 가능한 범죄정보와 도시지역 자료를 바탕으로 머신러닝 방식을 통해 한국형 범죄발생 위험지역 예측 모형을 개발하고자 한다. 또한 시나리오를 가정하여 범죄발생 확률을 지도로 시각화함으로써 사용자의 이해도를 높이도록 하였다. 선행 연구 및 사례에서 범죄발생에 영향을 미치는 요인 중 빅데이터로 구축 가능한 범죄정보, 날씨정보(기온, 강수량, 풍속, 습도, 일조, 일사, 적설, 전운량), 지역정보(평균 건폐율, 평균 용적율, 평균 높이, 총 건축물수, 평균 공시지가, 평균 주거용도면적, 평균 지상층수)를 머신러닝에 활용할 수 있도록 데이터를 사전 처리하였다. 머신러닝 알고리즘으로서 지도학습 모형 중 다양한 분야에서 활용되며정확도가 높다고 알려진 의사결정나무모형, 랜덤포레스트모형, Support Vector Machine(SVM)모형을 활용하여 범죄 예측 모형을 구축하고 비교·분석하였다. 그 결과 평균 제곱근 오차(Root Mean Square Error, RMSE)가 낮아 예측력이 높은 의사결정나무모형을 최적모형으로 선정하였다. 이를 바탕으로 가장 빈번하게 발생하는 절도와 폭력범죄를 대상으로 시나리오를 작성하여 범죄 발생 위험지역을 예측한 결과, 사례도시 J시는 위험지역이 3가지 패턴으로 발생하는 것으로 나타났으며, 각각 발생확률을 3 등급으로 구분하여 250 x 250m 단위의 지도형태로 시각화할 수 있었다. 본 연구는 향후 자동화 시스템으로 개발하여 시시각각으로 변하는 도시 상황에 따라 실시간으로 예측 결과를 시각화하여 제공함으로써 보다 범죄로부터 안전한 도시환경 조성에 기여하고자 한다.","In Korea, citizens can only know general information about crime. Thus it is difficult to know how much they are exposed to crime. If the police can predict the crime risky area, it will be possible to cope with the crime efficiently even though insufficient police and enforcement resources. However, there is no prediction system in Korea and the related researches are very much poor. From these backgrounds, the final goal of this study is to develop an automated crime prediction system. However, for the first step, we build a big data set which consists of local real crime information and urban physicalor non-physical data. Then, we developed a crime prediction model through machine learning method. Finally, we assumed several possible scenarios and calculated the probability of crime and visualized the results in a map so as to increase the people's understanding. Among the factors affecting the crime occurrence revealed in previous and case studies, data was processed in the form of a big data for machine learning: real crime information, weather information (temperature, rainfall, wind speed, humidity, sunshine, insolation, snowfall, cloud cover) and local information (average building coverage, average floor area ratio, average building height, number of buildings, average appraised land value, average area of residential building, average number of ground floor). Among the supervised machine learning algorithms, the decision tree model, the random forest model, and the SVM model, which are known to be powerful and accurate in various fields were utilized to construct crime prevention model. As a result, decision tree model with the lowest RMSE was selected as an optimal prediction model. Based on this model, several scenarios were set for theft and violence cases which are the most frequent in the case city J, and the probability of crime was estimated by 250x250m grid. As a result, we could find that the high crime risky area is occurring in three patterns in case city J. The probability of crime was divided into three classes and visualized in map by 250 x 250m grid. Finally, we could develop a crime prediction model using machine learning algorithm and visualized the crime risky areas in a map which can recalculate the model and visualize the result simultaneously as time and urban conditions change."
머신러닝을 이용한 3차원 도로객체의 분류,2018,"['Autonomous Driving', 'Terrestrial Mobile Mapping System', 'Machine Learning', 'Support Vector Machine', 'Classification', '자율주행', '지상 모바일 매핑시스템', '머신러닝', '서포트 벡터 머신', '분류']","급변하는 주변상황이나 대형차량과 같은 큰 지형지물에 센서가 가려질 경우에는 센서만을 이용한 완전 자율주 행에는 한계가 따른다. 이에 자율주행을 위해서 센서를 이용한 한계점을 극복할 수 있도록 정한 도로지도를 부 가적으로 이용하는 방법이 사용되고 있다. 본 연구는 국토지리정보원에서 제공하는 지상 MMS(Mobile Mapping System)로 취득된 3차원 점군자료를 이용하여 도로 객체를 분류하는 연구를 수행하다. 본 연구를 위해서 원본 3 차원 점군자료를 전처리 하고, 지면과 비지면점을 분리하기 위한 필터링 기법을 선정하다. 또한 차선, 가로등, 안 전펜스 등에 해당하는 도로객체를 초기 분할한 후 분할된 객체를 머신러닝의 종류인 서포트 벡터 머신을 이용하 여 학습시킨 후 분류하다. 학습데이터는 분할된 도로객체에서 추출한 고유값을 이용한 기하학적 요소와 높이정 보만을 사용하으며 분류결과 전체정확도는 87%, 카파계수는 0.795로 나타났다. 향후 도로객체의 분","Autonomous driving can be limited by only using sensors if the sensor is blocked by sudden changes in surrounding environments or large features such as heavy vehicles. In order to overcome the limitations, the precise road-map has been used additionally. This study was conducted to segment and classify road objects using 3D point cloud data acquired by terrestrial mobile mapping system provided by National Geographic Information Institute. For this study, the original 3D point cloud data were pre-processed and a filtering technique was selected to separate the ground and non-ground points. In addition, the road objects corresponding to the lanes, the street lights, the safety fences were initially segmented, and then the objects were classified using the support vector machine which is a kind of machine learning. For the training data for supervised classification, only the geometric elements and the height information using the eigenvalues extracted from the road objects were used. The overall accuracy of the classification results was 87% and the kappa coefficient was 0.795. It is expected that classification accuracy will be increased if various classification items are added not only geometric elements for classifying road objects in the future."
표본 주택 가격 기반 부동산 가격지수 산정: 머신 러닝 방법의 활용을 중심으로,2018,"['머신 러닝', '부동산 가격지수', '랜덤 포레스트', '심층신경망', 'Machine Learning', 'Real Estate Price Index', 'Random Forest', 'Deep Neural Networks']",,"The Purpose of this study is to estimate the real estate price index based on the ‘estimated price by machine learning’. The price of a sample house was estimated using the machine learning method ‘Random forest’ and ‘Deep neural networks’, and the real estate price index was calculated using the Jevons index calculation method. First, the result of the study showed that the RF index and DNN index are similar, and the variability was changed according to the learning period. Second, the RF index and DNN index showed similar long-term trends compared to the KAB index, but it was found that there was a considerable difference in short-term trends. Third, the RF index and DNN index were found to be more variable than the KAB index, KB index, and real transaction price index, and the relationship with real transaction price index could not be confirmed. If the researcher’s qualitative analysis on the RF index and DNN index is added, it is expected that there is a high possibility of utilization as a new price index that can improve existing price index."
머신 러닝을 활용한 과학 논변 구성 요소 코딩 자동화 가능성 탐색 연구,2018,"['과학 논변', '머신 러닝', '인공지능', '자동화', '자연어 처리', 'Scientific Argumentation', 'Machine Learning', 'Artificial Intelligence', 'Automation', 'Natural Language Processing']",,"In this study, we explored the possibility of automating the process of analyzing elements of scientific argument in the context of a Korean classroom. To gather training data, we collected 990 sentences from science education journals that illustrate the results of coding elements of argumentation according to Toulmin’s argumentation structure framework. We extracted 483 sentences as a test data set from the transcription of students’ discourse in scientific argumentation activities. The words and morphemes of each argument were analyzed using the Python ‘KoNLPy’ package and the ‘Kkma’ module for Korean Natural Language Processing. After constructing the ‘argument―morpheme:class’ matrix for 1,473 sentences, five machine learning techniques were applied to generate predictive models relating each sentences to the element of argument with which it corresponded. The accuracy of the predictive models was investigated by comparing them with the results of pre-coding by researchers and confirming the degree of agreement. The predictive model generated by the k-nearest neighbor algorithm (KNN) demonstrated the highest degree of agreement [54.04% (κ = 0.22)] when machine learning was performed with the consideration of morpheme of each sentence. The predictive model generated by the KNN exhibited higher agreement [55.07% (κ = 0.24)] when the coding results of the previous sentence were added to the prediction process. In addition, the results indicated importance of considering context of discourse by reflecting the codes of previous sentences to the analysis. The results have significance in that, it showed the possibility of automating the analysis of students’ argumentation activities in Korean language by applying machine learning."
AI 머신러닝을 이용한 자동차 고장진단 시스템 설계 및 개발,2018,"['기계학습', '인공지능', '딥러닝', '고장진단시스템', 'Machine learning', 'Artificial intelligence', 'Deep running', 'Fault diagnosis system']","본 논문에서는 기계학습을 이용한 자동차 고장진단 시스템 설계에 관한 것으로, 설치위치에서 주행중인 자동차의 소음을 검출하는 다수의 음향센서를 포함하여 부품 이상에 따라 발생되는 소음데이터를 검출하여 전송하는 소음검출부와, 상기 소음검출부에서 검출된 소음데이터를 외부로 전송하며, 수신된 정보를 표시하는 사용자 단말과, 상기 소음데이터를 분석하여 고장 부품의 종류와 위치를 특정하고, 고장 부품의 종류에 따라 위험도를 결정하고, 소음데이터의 크기와 발생빈도를 이용하여 고장 정도를 판단하여 수리 지급도를 결정하여, 상기 고장 부품의 종류, 위치, 위험도, 수리 지급도 정보를 상기 사용자단말로 전송하는 진단 서버를 포함 한다. 이를 통해서 기계학습 관련 분야 산업 발전에 도움이 되었으면 한다.","The present invention relates to a design of an automotive fault diagnosis system using machine learning, and more particularly, to a vehicle fault diagnosis system using a machine learning system including a noise detector for detecting and transmitting noise data generated by a component abnormality including a plurality of acoustic sensors, A user terminal for transmitting the noise data detected by the noise detecting unit to the outside and displaying the received information; a noise analyzing unit for analyzing the noise data to identify the type and position of the faulty component, determine the risk according to the type of the faulty component, And a diagnosis server for determining the degree of repair by determining the degree of repair using the size and frequency of noise data, and transmitting the type, position, risk, and repair degree information of the failed component to the user terminal. I hope this helps to develop industry related to machine learning."
딥 러닝 및 서포트 벡터 머신기반 센서 고장 검출 기법,2018,"['Sensor fault diagnosis', 'Support vector machine', 'Genetic algorithm', 'Multi-layer support vector machine', 'Convolution neural network', 'Ensemble']","최근 산업현장에서 기계의 자동화가 크게 가속화됨에 따라 자동화 기계의 관리 및 유지보수에 대한 중요성이갈수록 커지고 있다. 자동화 기계에 부착된 센서의 고장이 발생할 경우 기계가 오동작함으로써 공정라인 운용에 막대한 피해가 발생할 수 있다. 이를 막기 위해 센서의 상태를 모니터링하고 고장의 진단 및 분류를 하는 것이 필요하다.본 논문에서는 센서에서 발생하는 대표적인 고장 유형인 erratic fault, drift fault, hard-over fault, spike fault, stuck fault를 기계학습 알고리즘인 SVM과 CNN을 적용하여 검출하고 분류하였다. SVM의 학습 및 테스트를 위해 데이터샘플들로부터 시간영역 통계 특징들을 추출하고 최적의 특징을 찾기 위해 유전 알고리즘(genetic algorithm)을 적용하였다. Multi-class를 분류하기 위해 multi-layer SVM을 구성하여 센서 고장을 분류하였다. CNN에 대해서는 데이터샘플들을 사용하여 학습시키고 성능을 높이기 위해 앙상블 기법을 적용하였다. 시뮬레이션 결과를 통해 유전 알고리즘에 의해 선별된 특징들을 사용한 SVM의 분류 결과는 모든 특징이 사용된 SVM 분류기 보다는 성능이 향상되었으나전반적으로 CNN의 성능이 SVM보다 우수한 것을 확인할 수 있었다.","As machines have been automated in the field of industries in recent years, it is a paramount importance to manage and maintain the automation machines. When a fault occurs in sensors attached to the machine, the machine may malfunction and further, a huge damage will be caused in the process line. To prevent the situation, the fault of sensors should be monitored, diagnosed and classified in a proper way. In the paper, we propose a sensor fault detection scheme based on SVM and CNN to detect and classify typical sensor errors such as erratic, drift, hard-over, spike, and stuck faults. Time-domain statistical features are utilized for the learning and testing in the proposed scheme, and the genetic algorithm is utilized to select the subset of optimal features. To classify multiple sensor faults, a multi-layer SVM is utilized, and ensemble technique is used for CNN. As a result, the SVM that utilizes a subset of features selected by the genetic algorithm provides better performance than the SVM that utilizes all the features. However, the performance of CNN is superior to that of the SVM."
머신러닝 기반의 C2 시스템 추상화를 통한 C3 복합체계에서의 시뮬레이션 기반 통신 시스템 분석,2018,,,"In the defense modeling and simulation, for the detailed analysis of the communication system, many studies have carried out the analysis under the C3 SoS(system of systems) which consists of C2(command and control) and C(communication). However, it requires time and space constraints of the C2 system. To solve this problem, this paper proposes a communication analysis method in the standalone system environment which is combined with the C system after abstracting the C2 system. In the abstraction process, we hypothesize the traffic model and mobility model for C system analysis and learn the parameters in the model based on machine learning. Through the proposed method, it is possible to construct traffic and mobility model with different output according to the battlefield. This case study shows how the process can be applied to the C3 SoS and the enhanced accuracy than the existing method. We expect that it is possible to carry out the efficient communication analysis against many experimental scenarios with various communication parameters."
머신러닝 기법을 이용한 수도권 지역의 호우피해 예측함수 개발,2018,"['재난관리', '호우피해', '머신러닝', '랜덤포레스트', '서포트 벡터 머신', 'Disaster Management', 'Heavy Rain Damage', 'Machine Learning', 'Random Forest', 'Support Vector Machine']","본 연구에서는 3가지의 머신러닝 기법(서포트 벡터 머신, 의사결정나무, 랜덤포레스트)을 이용하여 수도권 지역의 호우피해 예측함수를 개발하였다. 호우피해 예측함수의 종속변수로 호우피해액 자료를 사용하였고, 독립변수로 기상관측자료를 사용하였다. 분석결과 과거 2일전의 기상관측자료를 기반으로 서포트 벡터 머신을 이용하여 개발한 함수가 가장 높은 예측력을 보였다.기존의 연구들에서 주로 사용하였던 선형회귀모형과 비교한 결과 머신러닝 기법을 이용한 함수가 대부분 예측력이 높은 것으로 나타나 재난관리 분야에 머신러닝 기법의 적용이 가능한 것으로 판단되었다. 또한, 본 연구에서 개발된 호우피해 예측함수를 활용하여 피해 발생 전에 호우피해를 예측한다면, 적절한 재난관리를 통해 피해를 저감하는데 도움이 될 수 있을 것으로 판단된다.","In this study, we developed heavy rain damage prediction functions using three machine learning techniques (support vector machine, decision tree, and random forest) for the Seoul Capital Area, South Korea. Data on damage caused by heavy rain were used as the dependent variable for the development of the heavy rain damage prediction function, and weather observation data were used as the independent variables. When we compared the results, the best function was the support vector machines based on weather observation data of the past two days. Compared to the linear regression model used primarily in previous studies, the results showed that the functions using machine learning techniques were mostly predictable. Therefore, it was judged that the machine learning techniques could be applied to disaster management areas. Also, it is believed that using the heavy rain damage prediction function developed in this study can help reduce damage through proper disaster management before the damage occurs."
머신러닝 알고리즘을 이용한 기상 조건에 따른 노면 상태 예측 모델 연구,2018,"['Road Weather', 'Big Data', 'Road Surface State', 'Machine Learning', 'Model Evaluation', '도로기상', '빅데이터', '도로 노면상태', '머신러닝', '모델 평가']","기상 변화는 도로상의 차량 안전에 큰 영향을 미친다. 기상상태가 변화함에 따라, 노면은 미끄 러워질 수 있고, 미끄러운 노면은 차량의 제동거리를 증가시켜 운전자가 운전에 심혈을 기울여야 되 기 때문이다. 이러한 기상 변수와 노면 상태 및 차량 안전성 간 관계의 복잡성에 따라 기상 변화에 따 른 차량 안전성을 예측하기 위해서는 머신 러닝 모델 도입 필요성이 제기되고 있다. 본 연구에서는 기 존 기상 관측 장비가 없는 지역(미계측 지역)에서의 상세한 기상 데이터 및 노면 상태를 관측해 차량 안전성을 예측하는 최적의 기계학습 모델을 개발하였다. 이를 위해, 도로의 기하 정보와 ASOS의 기 상정보를 활용하여 설명변수를 가공하였다. 또한, 모델 평가 기준에 합당한 검증 방식을 적용하여, 가 장 합리적인 머신러닝 모델을 선정하였다. 그 결과, 특정 지역에 대해서 1400개의 데이터로 80% 이 상의 정확도로 노면 상태를 예측할 수 있음을 확인했다. 본 연구를 통해, 미계측 지역에 대한 노면 상 태를 예측하고, 그에 대한 마찰력을 유추한다면, 해당 도로의 위험성을 운전자에게 알리고, 사고 위험 도를 낮춰 사회적 비용을 감소시킬 수 있다.","The meteorological change affects vehicle safety. Slippery road caused by the weather increases the braking distance of vehicle. In result, drivers should drive more carefully. Because of the complexity of the relationship among vehicle safety, road surface state, and meteorological factors, machine learning model is considered to predict weather related vehicle safety. In this paper, we develop a machine learning model predicting vehicle safety by collecting detail weather data and road surface state of an area through ASOS where no weather stations are installed(so-called unmeasured area). To select the most reasonable machine learning model, we define model evalation criteria and apply them to various machine learning models. As a result, the selected model predicts road surface state of the target area with more than 80% of accuracy by using only 1,400 samples. If road surface state and friction of the road of the unmeasured area is predicted with high accuracy, social costs can be saved by decreasing accident risk through driver alert."
머신러닝 기법과 계측 모니터링 데이터를 이용한광안대교 신축거동 모델링,2018,"['bridge expansion joint', 'expansion behavior modeling', 'structural monitoring data', 'machine learning']",,"In this study, we have developed a prediction model for expansion and contraction behaviors of expansion joint in Gwangan Bridge using machine learning techniques and bridge monitoring data. In the development of the prediction model, two famous machine learning techniques, multiple regression analysis (MRA) and artificial neural network (ANN), were employed. Structural monitoring data obtained from bridge monitoring system of Gwangan Bridge were used to train and validate the developed models. From the results, it was found that the expansion and contraction behaviors predicted by the developed models are matched well with actual expansion and contraction behaviors of Gwangan Bridge. Therefore, it can be concluded that both MRA and ANN models can be used to predict the expansion and contraction behaviors of Gwangan Bridge without actual measurements of those behaviors."
머신러닝 기법을 활용한 피부 유형 판단 도구 모델에 관한 연구,2018,"['피부 유형', '뷰티 산업', '4차산업혁명', '특징점 추출', '머신러닝', 'Skin Type', 'Beauty Industry', 'Forth Industrial Revolution', 'Feature Extraction', 'Machine Learning']","최근 국내의 경제·문화적인 생활수준이 향상됨에 따라 건강하고 아름다운 피부의 상태를 유지하기 위하여 뷰티 분야에서 피부 관리에 대한 관심이 매우 높아지고 있다. 일반적으로 피부는 건성, 지성, 중성, 민감성, 복합성과 같이 크게 5가지의 특성으로 구분할 수 있다. 그러나 대부분의 소비자들은 어떤 유형의 피부를 가지고 있는지 제대로 파악하지 못하는 경우가 많으며, 피부 의 유형을 측정하기 위하여 전문 병원이나 전문적인 뷰티 테크 기기를 사용하여 피부를 진단하고 있다. 뷰티와 관련된 디바이스 시장은 주로 병원용 의료기기가 대부분이었으나, 영상 기술의 발전으로 가정에서도 편리하고 간편하게 사용할 수 있는 제품이 등장하기 시작했으며, 이를 통하여 피부 고민에 대한 경제적, 시간적인 부담이 줄어들었고, 소비자들의 관심도는 급속하게 높아 지고 있다. 특히 뷰티 테크와 관련된 시장은 4차 산업혁명의 핵심 기술과 융합되어 급속하게 발전되고 있는 상황으로, 점진적인 변화에 빠르게 대응하기 위하여 뷰티 시장에서도 단순하게 시장을 세분화하는 관점에서 벗어나 새로운 성장 동력이 필요한 실 정이다. 최근 화장품 업계에서는 피부 측정 도구를 이용하여, 피부 상태에 대한 컨설팅 및 마케팅 전략으로 필요 제품을 추천해 주는 서비스로 경쟁력을 강화하고 있다. 이에 본 논문에서는 소비자들이 피부 관리를 위하여 스스로 피부의 유형 판단이 가능하 도록, 머신러닝 기반으로 특징점을 추출하여 피부의 유형을 판단할 수 있는 모델을 제안한다. 제안 모델을 통하여 소비자 스스 로 피부의 유형 판단이 가능함에 따라 본인에게 적합한 뷰티 케어 서비스를 선택할 수 있고, 정확한 뷰티 케어 정보를 획득하여 아름답고 건강한 피부를 관리할 수 있을 것으로 기대되며, 향후 연구에서는 피부 유형의 정확도를 향상시키기 위하여 다양한 피 부 이미지의 수집에 대한 연구와 새로운 기계학습 알고리즘에 대한 연구가 계속되어야 할 것이다.","Recently, there has been a growing interest in science in the field of beauty in order to maintain healthy and beautiful skin conditions, as the domestic economy and cultural standards of living have improved. In general, the skin can be classified into five characteristics such as dryness, oilyness, neutrality, sensitivity, and complexity. However, most consumers do not know exactly what type of skin they have. To determine the type of skin, specialist hospitals and specialist beauty equipment are used to diagnose the skin. The device market related to beauty was mainly medical equipment for hospitals, but with the development of imaging technology, products that are convenient and easy to use at home have begun to appear. As a result, the economic and time burden of skin troubles has decreased, and the interest of consumers has been rapidly increasing. Especially, the market related to beauty tech is rapidly developing with the core technology of the forth industrial revolution. In order to respond quickly to gradual changes, a new growth engine is needed in the beauty market. Recently, the cosmetics industry is strengthening its competitiveness by using skin measurement tools, consulting about skin condition, and recommending necessary products as a marketing strategy. In this paper, we propose a model that can determine skin type by extracting feature points based on machine learning which enables consumers to judge skin type for skin care. Through the proposed model, it is possible for consumers to judge the type of skin on their own, so it is possible to select a beauty care service suitable for the user. It is also expected to acquire accurate beauty care information and manage beautiful and healthy skin. Future studies should continue to study the collection of various skin images and new machine learning algorithms to improve the accuracy of skin type."
텍스트 마이닝을 통한 키워드 추출과 머신러닝 기반의 오픈소스 소프트웨어 주제 분류,2018,"['open source', 'category classification', 'machine learning', 'performance comparison', '오픈소스', '주제 분류', '머신러닝', '성능 비교']",,"The proportion of users and companies using open source continues to grow. The size of open source software market is growing rapidly not only in foreign countries but also in Korea. However, compared to the continuous development of open source software, there is little research on open source software subject classification, and the classification system of software is not specified either. At present, the user uses a method of directly inputting or tagging the subject, and there is a misclassification and hassle as a result. Research on open source software classification can also be used as a basis for open source software evaluation, recommendation, and filtering. Therefore, in this study, we propose a method to classify open source software by using machine learning model and propose performance comparison by machine learning model."
안드로이드 플랫폼에서 악성 행위 분석을 통한 특징 추출과 머신러닝 기반 악성 어플리케이션 분류,2018,"['안드로이드', '행위 분석', '특징 추출', '상관 분석', '악성 어플리케이션 분류', 'Android', 'Behivavr Analysis', 'Feature Extraction', 'Correlation Analysis', 'Malware Application Classification']",,"This paper is a study to classify malicious applications in Android environment. And studying the threat and behavioral analysis of malicious Android applications. In addition, malicious apps classified by machine learning were performed as experiments. Android behavior analysis can use dynamic analysis tools. Through this tool, API Calls, Runtime Log, System Resource, and Network information for the application can be extracted. We redefined the properties extracted for machine learning and evaluated the results of machine learning classification by verifying between the overall features and the main features. The results show that key features have been improved by 1~4% over the full feature set. Especially, SVM classifier improved by 10%. From these results, we found that the application of the key features as a key feature was more effective in the performance of the classification algorithm than in the use of the overall features. It was also identified as important to select meaningful features from the data sets."
영화 흥행에 영향을 미치는 새로운 변수 개발과이를 이용한 머신러닝 기반의 주간 박스오피스 예측,2018,"['Movie', 'Box Office', 'Box Office Revenue', 'Box Office Factors', 'Prediction of Box Office', 'Predicting Number of Audience', 'Machine Learning', '영화 흥행 예측', '영화 관람객 수 예측', '박스오피스 예측', '기계학습']","2013년 누적인원 2억명을 돌파한 한국의 영화 산업은 매년 괄목할만한 성장을 거듭하여 왔다. 하지만 2015 년을 기점으로 한국의 영화 산업은 저성장 시대로 접어들어, 2016년에는 마이너스 성장을 기록하였다. 영화산업을 이루고 있는 각 이해당사자(제작사, 배급사, 극장주 등)들은 개봉 영화에 대한 시장의 반응을 예측하고 탄력적으로 대응하는 전략을 수립해 시장의 이익을 극대화하려고 한다. 이에 본 연구는 개봉 후 역동적으로 변화하는 관람객 수요 변화에 대한 탄력적인 대응을 할 수 있도록 주차 별 관람객 수를 예측하는데 목적을 두고 있다. 분석을 위해 선행연구에서 사용되었던 요인 뿐 아니라 개봉 후 역동적으로 변화하는 영화의 흥행순위, 매출점유율, 흥행순위 변동 폭 등 선행연구에서 사용되지 않았던 데이터들을 새로운 요인으로 사용하고 Naive Bays, Random Forest, Support Vector Machine, Multi Layer Perception등의 기계학습 기법을 이용하여 개봉 일 후, 개봉1주 후, 개봉 2주 후 시점에는 차주 누적 관람객 수를 예측하고 개봉 3주 후 시점에는 총 관람객 수를 예측하였다. 새롭게 제시한 변수들을 포함한 모델과 포함하지 않은 모델을 구성하여 실험하였고 비교를 위해 매 예측시점마다 동일한 예측 요인을 사용하여 총 관람객 수도 예측해보았다. 분석결과 동일한 시점에 총 관람객 수를예측했을 경우 보다 차주 누적 관람객 수를 예측하는 것이 더 높은 정확도를 보였으며. 새롭게 제시한 변수들을포함한 모델의 정확도가 대부분 높았으며 통계적으로 그 차이가 유의함으로써 정확도에 기여했음을 확인할 수있었다. 기계학습 기법 중에는 Random Forest가 가장 높은 정확도를 보였다.","The Korean film industry with significant increase every year exceeded the number of cumulative audiences of 200 million people in 2013 finally. However, starting from 2015 the Korean film industry entered a period of low growth and experienced a negative growth after all in 2016. To overcome such difficulty, stakeholders like production company, distribution company, multiplex have attempted to maximize the market returns using strategies of predicting change of market and of responding to such market change immediately. Since a film is classified as one of experiential products, it is not easy to predict a box office record and the initial number of audiences before the film is released. And also, the number of audiences fluctuates with a variety of factors after the film is released. So, the production company and distribution company try to be guaranteed the number of screens at the opining time of a newly released by multiplex chains. However, the multiplex chains tend to open the screening schedule during only a week and then determine the number of screening of the forthcoming week based on the box office record and the evaluation of audiences. Many previous researches have conducted to deal with the prediction of box office records of films. In the early stage, the researches attempted to identify factors affecting the box office record. And nowadays, many studies have tried to apply various analytic techniques to the factors identified previously in order to improve the accuracy of prediction and to explain the effect of each factor instead of identifying new factors affecting the box office record. However, most of previous researches have limitations in that they used the total number of audiences from the opening to the end as a target variable, and this makes it difficult to predict and respond to the demand of market which changes dynamically. Therefore, the purpose of this study is to predict the weekly number of audiences of a newly released film so that the stakeholder can flexibly and elastically respond to the change of the number of audiences in the film. To that end, we considered the factors used in the previous studies affecting box office and developed new factors not used in previous studies such as the order of opening of movies, dynamics of sales. Along with the comprehensive factors, we used the machine learning method such as Random Forest, Multi Layer Perception, Support Vector Machine, and Naive Bays, to predict the number of cumulative visitors from the first week after a film release to the third week. At the point of the first and the second week, we predicted the cumulative number of visitors of the forthcoming week for a released film. And at the point of the third week, we predict the total number of visitors of the film.In addition, we predicted the total number of cumulative visitors also at the point of the both first week and second week using the same factors. As a result, we found the accuracy of predicting the number of visitors at the forthcoming week was higher than that of predicting the total number of them in all of three weeks, and also the accuracy of the Random Forest was the highest among the machine learning methods we used. This study has implications in that this study 1) considered various factors comprehensively which affect the box office record and merely addressed by other previous researches such as the weekly rating of audiences after release, the weekly rank of the film after release, and the weekly sales share after release, and 2) tried to predict and respond to the demand of market which changes dynamically by suggesting models which predicts the weekly number of audiences of newly released films so that the stakeholders can flexibly and elastically respond to the change of the number of audiences in the film."
머신러닝을 이용한 빅데이터 도메인 자동 판별에 관한 연구,2018,"['빅데이터', '데이터 품질 진단', '도메인', '머신러닝', '랜덤 포레스트', 'Big Data', 'Data Quality Diagnosis', 'Domain', 'Machine Learning', 'Random Forest']","본 연구는 빅데이터 품질 진단의 핵심 요소인 도메인 기반 품질 진단을 위한 도메인 자동 판별에 관한 연구다. 빅데이터의 가치와 활용도의 증가와 4차 산업혁명의 대두로, 법률, 의료, 금융 등 IT와 융합된 다양한 분야에서 빅데이터를 활용하여 새로운 가치를 창출하려는 노력을 진행중이다. 하지만, 신뢰도가 낮은 데이터에 기반한 분석은 과정과 결과 모두에서 치명적인 문제를 발생하며, 분석 결과에 따른 판단 또한 신뢰하기 어려워 진다. 이처럼 신뢰도가 높은 데이터의 필요성 또한 증가하였지만, 데이터의 품질 확보에 대한 연구와 그에 대한 결과는 미비하다. 본 연구는 데이터 품질 향상을 위한 진단 평가의 핵심적 요소인 도메인 기반 품질 진단에서, 수작업으로 진행되었던 도메인 판별 작업을 머신러닝을 이용하여 자동화 함으로써, 작업시간을 단축하는 것을 목표로 한다. 데이터 베이스에 저장된, 도메인이 판별되어 있는 데이터의 특성에 관한 정보들을 추출하여 변수화하고, 이를 머신러닝을 이용하여 도메인 판별을 자동화 한다. 이를 빅데이터 품질 진단에 활용하고, 품질 향상에 기여하도록 한다.",
머신러닝을 이용한 항공기 수리부속 예측 모델의 실증적 연구,2018,"['Aircraft repair parts', 'Demand forecasting', 'Time-Series analysis', 'Machine learning', 'Input variable', '항공기 수리부속', '수요예측', '시계열 분석', '머신러닝', '입력변수']",,"In order to predict the future needs of the aircraft repair parts, each military group develops and applies various techniques to their characteristics. However, the aircraft and the equipped weapon systems are becoming increasingly advanced, and there is a problem in improving the hit rate by applying the existing demand prediction technique due to the change of the aircraft condition according to the long term operation of the aircraft. In this study, we propose a new prediction model based on the conventional time-series analysis technique to improve the prediction accuracy of aircraft repair parts by using machine learning model. And we show the most effective predictive method by demonstrating the change of hit rate based on actual data."
머신러닝을 이용한 웹페이지 내의 특정 정보 추출,2018,"['Data Extraction', 'Machine Learning', 'SVM', 'Decision Tree', 'Neural Network']",,"With the advent of the digital age, production and distribution of web pages has been exploding. Internet users frequently need to extract specific information they want from these vast web pages. However, it takes lots of time and effort for users to find a specific information in many web pages. While search engines that are commonly used provide users with web pages containing the information they are looking for on the Internet, additional time and efforts are required to find the specific information among extensive search results. Therefore, it is necessary to develop algorithms that can automatically extract specific information in web pages. Every year, thousands of international conference are held all over the world. Each international conference has a website and provides general information for the conference such as the date of the event, the venue, greeting, the abstract submission deadline for a paper, the date of the registration, etc. It is not easy for researchers to catch the abstract submission deadline quickly because it is displayed in various formats from conference to conference and frequently updated. This study focuses on the issue of extracting abstract submission deadlines from International conference websites. In this study, we use three machine learning models such as SVM, decision trees, and artificial neural network to develop algorithms to extract an abstract submission deadline in an international conference website. Performances of the suggested algorithms are evaluated using 2,200 conference websites."
머신러닝 기반의 오픈소스 SW 카테고리 분류 모델 연구,2018,"['Open Source Software', 'TF-IDF', 'Software Classification', 'Machine Learning', '오픈소스 SW', 'TF-IDF', '소프트웨어 분류', '머신러닝']",,"In many respects, the use and importance of open source software in companies and individuals are increasing as the days pass. However, software evaluation for users, software classification of filtering fundamentals research can not deal flexibly according to the characteristics of open source software. They are using a fixed classification system. In this research, we provide a classification model of open source software that can flexibly deal with the classification of open source software and the software category of new open source software."
머신러닝 기반 건강컨설팅 성공여부 예측모형 개발,2018,"['Machine Learning', 'Wellness Care', 'Case-Based Reasoning', 'Prediction Model', 'Life Log Data']",,"This study developed a prediction model using machine learning technology and predicted the success of health consulting by using life log data generated through u-Health service. The model index of the Random Forest model was the highest using. As a result of analyzing the Random Forest model, blood pressure was the most influential factor in the success or failure of metabolic syndrome in the subjects of u-Health service, followed by triglycerides, body weight, blood sugar, high cholesterol, and medication appear. muscular, basal metabolic rate and high-density lipoprotein cholesterol were increased; waist circumference, Blood sugar and triglyceride were decreased. Further, biometrics and health behavior improved. After nine months of u-health services, the number of subjects with four or more factors for metabolic syndrome decreased by 28.6%; 3.7% of regular drinkers stopped drinking; 23.2% of subjects who rarely exercised began to exercise twice a week or more; and 20.0% of smokers stopped smoking. If the predictive model developed in this study is linked with CBR, it can be used as case study data of CBR with high probability of success in the prediction model to improve the compliance of the subject and to improve the qualitative effect of counseling for the improvement of the metabolic syndrome."
머신러닝을 이용한 사용자 행동 인식 기반의 PIN 입력 기법 연구,2018,,"이 논문에서는 스마트폰에서 사용자 인증 프로토콜에 머신러닝을 사용하는 기법을 제안한다. 우리가 제안하는 기법은 사용자가 PIN을 입력할 때, PIN 뿐만 아니라 추가적으로 스크린을 터치하는 시간 간격 및 위치를 인증 정보로 수집하여 식별자로 사용하는 기법이다. 먼저 사용자 등록 단계에서 다수의 사용자 터치 시간 및 위치 데이터를 수집 한 다음, 그 데이터로 머신러닝을 이용하여 모델을 제작한다. 그리고 사용자 인증 단계에서 사용자가 입력한 PIN을 비교하고, PIN이 일치하면 사용자의 터치 시간 및 위치 데이터를 모델에 입력하여 기존에 수집한 데이터와 거리를 비교하여, 그에 따라 인증 성공 여부가 결정된다. 우리는 사용성 실험과 보안성 실험을 통하여 이 기법을 사용하는데 큰 불편이 없다는 것(FRR : 0%)과, 이전의 사용되고 있던 PIN 입력 기법보다 안전하다는 것(FAR : 0%)을 보였고, 그에 따라 충분히 사용될 수 있는 기법이라는 것을 확인하였다. 또한 숄더 서핑 공격 실험을 통하여 PIN이 유출되어도 보안 사고가 발생하기 힘들다는 것(FAR : 5%)을 확인하였다.",
머신러닝과 샘플링을 이용한 강원도 지역 산불발생예측모형 개발,2018,"['Forest fire Weather Index(FWI)', 'Machine learning model', 'sampling', 'imbalanced data', '캐나다 산불 기상 지수(FWI)', '머신러닝 모델', '샘플링', '불균형 데이터']","본 연구는 산불 발생 예측 모형의 정확도를 높이기 위해 머신러닝 기법을 적용한 연구이다. 산불 피해 면적이 가장 큰 강원도를 중심으로 2003년부터 2016년까지 총 14년의 산불 자료를 이용하였다. 기상자료의 오차를 줄이기 위해 강원도를 9개의 구역으로 나누어 각 구역 관측소의 기상자료를 이용하였다. 9개의 구역으로 나누어 각 구역의 산불 예측 모형을 만들게 되면 산불이 발생한 날(majority)과 산불이 발생하지 않은 날(minority)의 비율 차이가 큰 불균형 문제가 발생한다. 불균형 문제에서는 모델의 성능이 떨어지는 현상이 발생할 수 있다. 이를 해결하기 위해 여러 샘플링 방법을 적용하였다. 또한 모델의 정확도를 높이기 위해 캐나다 산불 기상 지수(FWI)의 5가지 지수를 파생변수로 사용하였다. 모델링 방법은 통계적 방법인 로지스틱 회귀분석 방법과 머신러닝 방법인 random forest와 xgboost 방법을 사용하였다. 각 구역의 최종모델의 선택기준을 정확도, 민감도, 특이도를 고려하여 정했으며, 9개 구역의 예측 결과는 산불이 발생한 104건 중 80건의 발생 예측에 성공하였으며 산불이 발생하지 않은 9758건 중 7426건의 발생하지 않음을 예측했다. 전체의 정확도는 76.1%였다.",
베이지안 머신 러닝을 이용한 은행권 주택담보대출 예측,2018,"['model choice', 'variable selection', 'posterior predictive likelihood', 'conditional Bayesian model averaging', '모형선택', '변수선택', '사후예측우도', '조건부 베이지안 모형평균']","본 연구는 우리나라 주택담보대출의 베이지안 머신 러닝 분포예측 기법을 제시하고 실제 예측결과를 분석한다. 주택담보대출 예측은 크게 세 단계로 이루어진다. 첫 번째 단계는 변수선택이다. 다수의 잠재적인 예측변수 중에서 주택담보대출 자료만을 이용한 일변수 모형보다 정확한 표본외 주택담보대출 예측력을 나타내는 ADL 모형의 예측변수만을 선택한다. 두 번째 단계에서는 선택된 예측변수를 대상으로 다수의 시계열 예측모형을 추정하고, 표본외 예측력을 기준으로 모형별 가중치를 산출한다. 마지막으로 예측 조합인데, 모형별 사후예측분포에 가중치를 부여한 예측분포를 샘플링한다. 2007년 12월부터 2016년 10월까지의 월별자료를 분석한 결과, 예측변수 및 모형 불확실성이 존재할 뿐만 아니라 시변하였다. 최근 주택담보대출 급등세는 수도권 아파트 매매가격지수가 주도적인 역할을 했으며, 올해 초 14%까지 달했던 주택담보대출 증가율은 2016년 11월 이후 차츰 둔화되어 10% 내외의 증가율을 보일 것으로 전망되었다.","This paper provides a mortgage loan prediction method and density forecasts. To this end, we develop a Bayesian machine learning algorithm based on conditional Bayesian model averaging. In this approach, the uncertainties of the parameters, models, and prediction variables are incorporated in the predictive density simulation. The first learning stage is the variable selection. Among a number of potential prediction variables we choose the prediction variables which improve the one-month-ahead predictive density accuracy compared to an uni-variate model. The second learning stage is the model choice. We evaluate both direct and indirect prediction models using the selected prediction variables. The model weights are obtained by the relative out-of-sample density prediction performance, In the last stage, the predictive density forecasts are constructed using the model-specific density forecasts and model weights. According to our empirical results based on the monthly data ranging from December 2007 to October 2016, the variable and model uncertainties are substantial, and the relative importance of the variables and models are dramatically time-varying. It is also found that recent rises of the mortgage loan are attributed to the changes in the apartment price index. Finally, the mortgage loan growth forecasts are decreasing in the forecast horizon."
의사결정트리 기반 머신러닝 기법을 적용한멜트다운 취약점 동적 탐지 메커니즘,2018,"['Meltdown Attack', 'Operating System', 'OS Vulnerabilities', 'Decision Tree', 'Dynamic Detection.', '멜트다운 공격', '운영체제', 'OS 취약점', '의사결정트리', '동적 탐지']","본 논문은 동적 샌드박스 도구를 이용하여 최근 급증하고 있는 멜트다운(Meltdown) 악성코드를 사전에 검출 및 차단하는 방법을 제시하였다. 멜트다운 공격 취약점에 대한 패치가 일부 제공되고 있으나 여전히 해당 시스템의 성능 저하 등의 이유로 의도적으로 패치를 적용하지 않는 경우가 많다. 이와 같이 적극적인 패치가 적용되지 않은 인프라를 위해 머신러닝 기법을 이용하여 기존의 시그니처 탐지 방식의 한계를 극복하는 방법을 제시하였다. 우선 멜트다운의 원리를 이해하기 위해 가상 메모리, 메모리 권한 체크, 파이프 라이닝과 추측 실행, CPU 캐시 등 4가지의 운영체제 구동 방식을 분석하고 이를 토대로 멜트다운 악성코드에 리눅스 strace 도구를 활용하여 데이터를 추출하는 메커니즘을 제공하였으며 이를 기반으로 의사 결정 트리 기법을 적용하여 멜트다운 악성코드를 판별하는 메커니즘을 구현하였다.","In this paper, we propose a method to detect and block Meltdown malicious code which is increasing rapidly using dynamic sandbox tool. Although some patches are available for the vulnerability of Meltdown attack, patches are not applied intentionally due to the performance degradation of the system. Therefore, we propose a method to overcome the limitation of existing signature detection method by using machine learning method for infrastructures without active patches. First, to understand the principle of meltdown, we analyze operating system driving methods such as virtual memory, memory privilege check, pipelining and guessing execution, and CPU cache. And then, we extracted data by using Linux strace tool for detecting Meltdown malware. Finally, we implemented a decision tree based dynamic detection mechanism to identify the meltdown malicious code efficiently."
목걸이형 센서를 이용한 머신러닝 기반 가축상태 모니터링,2018,"['젖소', '헬스 모니터링', '기계학습', '웨어러블 센서', 'Dairy cattle', 'Health monitoring', 'Machine learning', 'Wearable sensor']",사물 인터넷 기술의 급속한 발전으로 다양한 종류의 스마트 센서들이 개발 보급되고 있다. 이러한 스마트 센서들은 주로 관리자의 경험에 의해서 관리되던 축산업에도 최근 적용되어 가축 개체에 웨어러블 센서를 달거나 사물인터넷 센서를 갖춘 스마트팜 사용을 통해서 가축관리의 효율성을 향상시키고 있다. 본 논문에서는 목걸이형 스마트 센서를 이용하여 젖소의 체온과 운동량을 측정하고 이를 기반으로 개체의 상태를 파악하는 방안을 개발하였다. 특히젖소 관리에서 제일 중요한 요소인 젖소의 발정여부를 파악하는 방안을 다양한 머신러닝 방법을 이용하여 분석하였고 이를 통해서 높은 정확도로 발정여부를 예측할 수 있음을 보였다. 제안한 방안의 사용을 통해서 젖소의 발정여부를 빠르게 확인하고 이를 통해서 젖소 관리의 효율성을 향상시킬 수 있다.,"Due to the rapid development of Internet-of-Things technology, different types of smart sensors are now devised anddeployed widely. These smart sensors are now used in animal husbandry which was traditionally managed by theexperience of farmers, such that wearable sensors for livestock, and the smart farm which is equipped with multiplesensors are utilized to increase the efficiency of livestock management. Herein, we consider a scheme in which the bodytemperature and the level of activity are measured by smart sensor which is attached to the neck of dairy cattle and thehealth condition is monitored based on collected data. Especially, we find that the estrous of dairy cattle which is one ofmost important metric in milk production, can be predicted with high precision using various machine learning techniques.By utilizing the proposed prediction scheme, estrous of cattle can be detected immediately and this can improve theefficiency of cattle management."
시간 단위의 M&V 베이스라인 구축을 위한 머신러닝 알고리즘 기반 건물에너지 예측 모델의 성능 비교,2018,"['Building energy performance', 'Baseline', 'M&amp', 'V', 'Prediction model', 'KNN', 'RF', 'ANN']",,"As an alternative to existing simple regression monthly baseline method, we developed an hourly baseline model for M&V based on prediction models with machine learning techniques. This paper evaluated three data-driven energy models used to predict building electricity energy consumption: K-nearest neighbor (KNN) model, Random Forest (RF) model, and Artificial Neural Network (ANN) Model. As a result, CVRMSE is about 10% in all three models. In addition, it was confirmed that the ANN is superior to the KNN or RF in terms of the prediction accuracy of the energy consumption pattern in which the energy consumption is rapidly fluctuated with time."
머신러닝을 활용한 심근경색증/협심증 예측 및 주요 위험요인 선별,2018,"['Bagging', 'LASSO', 'SVM', 'Random Forest', '국민건강영양조사.', 'Bagging', 'LASSO', 'SVM', 'Random Forest', 'KNHANES.']","본 연구에서는 국민건강영양조사 제6기(2013-2015) 원시자료에 포함되어 있는 인구사회학적특성, 개인과거병력, 가족병력, 건강설문 그리고 건강검진 자료들을 활용하여, 심근경색증/협심증 발생을 예측하고 동시에 심근경색증/협심증 발생에 영향을 미치는 여러 가지 요인들 중 가장 주요한 위험요인들을 찾기 위해서 B-LASSO모형을 제안하였다. 훈련자료(training data)를 이용하여 모형을 구축하고 검증자료(test data)에서 모형들의 예측성능을 AUC를 이용하여 평가한 결과, B-LASSO모형의 예측성능이 LASSO, Random Forest, CART, SVM 모형들에 비하여 우수하였다. B-LASSO모형으로부터 추정된 심근경색증/협심증 발생에 영향을 미치는 주요 위험요인들의 중요도 순위는 연령, 고혈압 의사진단받음, 이상지질혈증 의사진단받음, 허혈성심장질환 가족력 순이었으며 남자가 여자보다 심근경색증/협심증 발생 위험이 더 높은 것으로 나타났다. 남자의 경우 당뇨병 의사진단을 받았거나 일상 활동에 지장이 있거나 빈혈이 있는 사람이 그렇지 않은 사람에 비해 심근경색증/협심증 발생 위험도가 높았으며, 여자의 경우 뇌졸중 의사진단을 받았거나 스트레스를 많이 받는 사람이 그렇지 않은 사람보다 심근경색증/협심증 발생 위험도가 높았다.","In this study, the B-LASSO model was proposed to predict the incidence of myocardial infarction/angina using the Korea national health and nutrition examination survey (KNHANES 2013-2015) data and to select the most important risk factors among the factors affecting myocardial infarction/angina. The prediction performance of the B-LASSO model was superior to that of the LASSO, Random Forest, CART, and SVM models in test data. The major risk factors affecting myocardial infarction/angina incidence estimated from the B-LASSO model were age, doctor-diagnosed hypertension, doctor-diagnosed dyslipidemia, family history of ischemic heart disease, and gender. Men had a higher risk of myocardial infarction/angina than women. The risk of myocardial infarction/angina was higher in men who had doctor-diagnosed diabetes or anemia than in those who did not. The risk of myocardial infarction/angina was higher in women with a doctor-diagnosed stroke or a lot of stress than in those without."
광역시 지역주민의 원전계속운전 수용성 결정요인 분석 - 머신러닝과 CVM 기법의 적용 -,2018,"['Machine Learning', 'Continued Nuclear Power', 'ID3', 'CVM', 'WTP']",,"There are growing interests in decision-making on continued operation of aged nuclear power plants. This paper attempts at identifying factors which may influence on acceptability of public for the continued nuclear power plants. The affecting factors on the decision-making are mainly explored by ID3 algorithm which results are verified through CART and CHAID algorithms. The data were based on a survey of local residents in metropolitan cities. The analysis shows that the vicinity factor have the greatest impact factor on the continued operation of aged nuclear power plants with other factors including respodents’ perception on nuclear, job and income. The resulting factors are then employed for CVM analysis to estimate willingness to pay (WTP) for the continued operation of aged nuclear power plants. The CVM finding is that individual WTP is 570KRW per month in order to secure the continuation of nuclear power."
인지 무선 시스템에서 웨이블릿 패킷 분해를 이용한서포트 벡터 머신 기반 스펙트럼 센싱,2018,"['Cognitive radio networks', 'Spectrum sensing', 'Artificial intelligence', 'Machine learning', 'Support vector machine', 'Feature extraction', 'Wavelet packet decomposition']","부사용자가 주사용자의 주파수 사용 상태를 판별하기 위해 인지 무선 시스템의 핵심 기술인 스펙트럼 센싱을사용한다. 스펙트럼 센싱 기법 중 에너지 검출법은 할당 된 채널 신호의 강도에 따라서 주사용자의 주파수 사용 유무를 판별한다. 이 기법은 단순히 신호의 크기를 이용해 스펙트럼 센싱하기 때문에 SNR 대역이 낮아질수록 주사용자의신호를 검출하기 어렵다는 단점이 있다. 본 논문은 낮은 SNR 대역에서의 성능 열화를 극복하기 위해 웨이블릿 패킷분해를 사용한 서포트 벡터 머신을 스펙트럼 센싱과 융합하는 방식을 제안하였다. 이 방식은 센싱 신호를 웨이블릿 패킷 분해를 기반으로 특징 추출하여 Support Vector Machine의 훈련과 실험용 데이터로 사용한다. 제안한 방식의 실험 결과를 SNR대역에 대해 정확도와 ROC 커브 그래프의 AUC를 이용하여 에너지 검출법과 비교하였다. 실험 결과, 제안한 시스템은 낮은 SNR대역에서 에너지 검출법 보다 더 향상된 판별 성능을 보였다.","Spectrum sensing, the key technology of the cognitive radio networks, is used by a secondary user to determine the frequency state of a primary user. The energy detection in the spectrum sensing determines the presence or absence of a primary user according to the intensity of the allocated channel signal. Since this technique simply uses the strength of the signal for spectrum sensing, it is difficult to detect the signal of a primary user in the low SNR band. In this paper, we propose a way to combine spectrum sensing and support vector machine using wavelet packet decomposition to overcome performance degradation in low SNR band. In our proposed scheme, the sensing signals were extracted by wavelet packet decomposition and then used as training data and test data for support vector machine. The simulation results of the proposed scheme are compared with the energy detection using the AUC of the ROC curve and the accuracy according to the SNR band. With simulation results, we demonstrate that the proposed scheme show better determining performance than one of energy detection in the low SNR band."
네일 드릴 머신 교육 만족도 및 요구도 조사,2018,"['네일', '네일드릴', '일렉트릭 파일', '네일 머신', '요구도', 'Nail', 'Nail Drill', 'E-File', 'Nail Machine', 'Requirement']",,"This study is basic research performed to develop nail drill training programs. The aim is to investigate satisfaction and needs among students and experienced workers who received prior nail drill training.A test was conducted among 200 nail care workers who had received nail drill training. For statistical analysis, SPSS 22.0 was adopted. The results found the following: First, among the students who completed nail drill training, most of them took the course through online learning or at a private institute. In terms of satisfaction with nail drill training, satisfaction with the number of students and training method was relatively high. However, training duration and practicality were somewhat low. Regarding needs from nail drill training, the repair of artificial nails, length adjustment and leveling were the highest. The nail care professionals with at least 3 years of work experience wanted ‘loose skin removal’, a technique commonly used at a nail salon. In contrast, those with less than 3 years of work experience showed a high demand for theory. This study is meaningful in that it is the first paper on educational needs performed among training candidates for the development of nail drill training programs. In addition, it is significant because it has provided information on consumer needs from a marketing perspective as well as basic data for nail drill curriculum."
머신러닝을 이용한 급성 뇌졸중 퇴원 환자의 중증도 보정 사망 예측 모형 개발에 관한 연구,2018,"['Stroke', 'Medical service quality outcome', 'Mortality rate', 'Machine learning', 'Prediction model', 'Severity-Adjustment', 'Comorbidity']","본 연구는 머신러닝을 활용하여 급성 뇌졸중 퇴원 환자의 중증도 보정 사망 예측 모형 개발을 목적으로 시행하였다. 전국 단위의 퇴원손상심층조사 2006~2015년 자료 중 한국표준질병사인분류(Korean standard classification of disease-KCD 7)에 따라 뇌졸중 코드 I60-I63에 해당하는 대상자를 추출하여 분석하였다. 동반질환 중증도 보정 도구로는 Charlson comorbidity index(CCI), Elixhauser comorbidity index(ECI), Clinical classification software(CCS)의 3가지 도구를 사용하였고 중증도 보정 모형 예측 개발은 로지스틱회귀분석, 의사결정나무, 신경망, 서포트 벡터 머신 기법을 활용하여 비교해 보았다. 뇌졸중 환자의 동반질환으로는 ECI에서는 합병증을 동반하지 않은 고혈압(hypertension, uncomplicated)이 43.8%로, CCS에서는 본태성고혈압(essential hypertension)이 43.9%로 다른 질환에 비해 가장 월등하게 높은 것으로 나타났다. 동반질환 중중도 보정 도구를 비교해 본 결과 CCI, ECI, CCS 중 CCS가 가장 높은 AUC값으로 분석되어 가장 우수한 중증도 보정 도구인 것으로 확인되었다. 또한 CCS, 주진단, 성, 연령, 입원경로, 수술유무 변수를 포함한 중증도 보정모형 개발 AUC값은 로지스틱 회귀분석의 경우 0.808, 의사결정나무 0.785, 신경망 0.809, 서포트 벡터 머신 0.830로 분석되어 가장 우수한 예측력을 보인 것은 서포트 벡터머신 기법인 것으로 최종 확인되었고 이러한 결과는 추후 보건의료정책 수립에 활용될 수 있을 것이다.","The purpose of this study was to develop a severity-adjustment model for predicting mortality in acute stroke patients using machine learning. Using the Korean National Hospital Discharge In-depth Injury Survey from 2006 to 2015, the study population with disease code I60-I63 (KCD 7) were extracted for further analysis. Three tools were used for the severity-adjustment of comorbidity: the Charlson Comorbidity Index (CCI), the Elixhauser comorbidity index (ECI), and the Clinical Classification Software (CCS). The severity-adjustment models for mortality prediction in patients with acute stroke were developed using logistic regression, decision tree, neural network, and support vector machine methods. The most common comorbid disease in stroke patients were hypertension, uncomplicated (43.8%) in the ECI, and essential hypertension (43.9%) in the CCS. Among the CCI, ECI, and CCS, CCS had the highest AUC value. CCS was confirmed as the best severity correction tool. In addition, the AUC values for variables of CCS including main diagnosis, gender, age, hospitalization route, and existence of surgery were 0.808 for the logistic regression analysis, 0.785 for the decision tree, 0.809 for the neural network and 0.830 for the support vector machine. Therefore, the best predictive power was achieved by the support vector machine technique. The results of this study can be used in the establishment of health policy in the future."
머신러닝을 이용한 고객세분화에 관한 연구,2018,"['CRM', 'Machine Leatning', 'Customer Segmentation', 'Clustering', 'TargetMarketing']","고객들은 갈수록 다양한 수단과 채널을 통해 자신이 갖고 있는 니즈들을 표현하고 있다. 이에 맞춰 기업들은 고객데이터를 확보하고 분석하여 개인화 마케팅으로 변화시켜 나가고 있으며 최근에는 다양한 머신러닝 방법을 활용하여 고객 세분화에 관한 많은 연구가 이루어지고 있다. 고객세분화를 통하여 전략적인 의사결정을 얻을 수 있을 뿐만 아니라 해당하는 고객 군집에 해당하는 상품과 서비스를 제안을 할 수 있다. 이에 따라 본 논문에서는 고객의 구매 이력 데이터를 사용하여 고객의 니즈를 반영한 구매수량과 구매금액을 이용하여 분포에 따라 새로운 점수를 생성한 모델을 제안하고 Python 머신 러닝 오픈소스 라이브러리 scikit-leam의 K-means 클러스터링을 활용하여 고객세분화를 하였다. 연구결과 2개의 군집이 형성되었으며, 군집1은 전체적으로 구매량이 낮아 뚜렷한 고객의 특성을 파악하지 못하였고, 군집 2는 가공식품, 과일, 채소, 축산, 해산물등 식료품을 선호하는 군집이였으며 주 고객은 30대, 40대, 50대 여성으로 나타났다. 본 연구 결과를 바탕으로 고객세 분화를 통해 고객의 상품구매 니즈를 보다 정교하게 반영한 새로운 지표를 설계하고 생성한다면 더욱 더 다양한 관점에서 고객이 원하고자 하는 바를 찾아낼 수 있을 것이다.","Customers increasingly express their needs through diverse means and channels. Companies are acquiring, analyzing, and transforming customer data into personalized marketing, and recently there is a lot of research being done on customer segmentation using a variety of machine-learning methods. Not only can customer segmentation achieve strategic decision making, but it also enables proposals for products and services corresponding to the corresponding cluster of customers. Therefore, this thesis uses the customer""s purchase history data to determine the purchase quantity and amount. Therefore, this thesis proposes a model that uses the customer""s purchase history data to generate new scores based on distribution using the quantity of purchases and amounts that reflect the customer""s needs. We used K-means clustering from Python Machine Learning open source library scikit-learn to refine our customers. The study found that two clusters were formed, and Cluster1 showed no clear customer characteristics due to low purchase volume, and Cluster2 was responsible for food products such as processed foods, fruits, vegetables, cattle, and seafood. Based on the results of this study, designing and creating new indicators that reflect the customer`s needs for purchasing through customer segmentation can result in customers` desire to do so in more ways."
무선 환경에서 대역폭 추정 기반의 머신러닝을 통한 TCP 혼잡제어 알고리즘 설계 및 성능 평가,2018,"['Wireless TCP', 'Congestion Control', 'Machine Learning', 'Bandwidth Estimation']",,
머신 러닝 방법과 시계열 분석 모형을 이용한 부동산 가격지수 예측,2018,"['머신 러닝', '부동산가격지수', '예측', '시계열분석', 'Machine Learning', 'Real Estate Price Index', 'Predicting', 'Time Series Analysis']",,"This study aims to explore the feasibility of using machine learning methods to forecast the real estate price index. To do so, machine learning methods, such as support vector machine, random forest, gradient boosting regression tree, deep neural networks, and long short term memory networks (LSTM), and the time series analysis methods such as the autoregressive integrated moving average model (ARIMA), the vector autoregression model (VAR), and the Bayesian vector autoregressive model (Bayesian VAR), were used to predict the real estate price index for apartments. The following were the main findings of the comparison of their predictive abilities. First, the predictive power of machine learning methods is superior to that of the time series analysis methods. Second, in a stable market situation, both machine learning and time series analysis methods can predict market trends moderately well. Third, when the market undergoes a dramatic change due to structural changes or external shocks, the machine learning method can accurately predict market trends for the most part, whereas the time series analysis method fails to do so. Thus, the accuracy of real estate market forecasts can be expected to improve with the use of machinelearning methods."
머신러닝 모델링을 위한 웹 기반 위성영상 데이터 전처리 자동화 시스템 설계 및 구현,2018,"['전처리 자동화', '머신러닝', '웹 시스템', '마이크로서비스', 'Automatic Preprocessing', 'Machine Learning', 'Web System', 'Microservice']","최근 공간정보 분야에서 위성영상과 머신러닝을 이용한 연구가 활발하지만 위성영상과 머신러닝이 가진 특수성으로 인하여 발생하는 데이터 확보와 전처리에 대한 요구사항을 반영한 연구는 미비하다. 이 연구에서는 위성영상기반의 머신러닝 모델링 과정에서 발생하는 요구사항을 분석하여 최신 IT 트렌드인 마이크로 서비스 아키텍처 기반의 가볍고 확장성 있는 시스템을 제시하였다. 제시하는 시스템은 데이터 확보의 요구사항을 반영하여 데이터베이스를 구축하고 시공간 필터링 및 운량 필터링 기능을 통한 효과적 데이터 확보 기능을 제공하고, 위성영상 데이터의 머신러닝 모델링 적용에 필요한 전처리에 대하여 GUI 기반의 자동화 기능을 제공하도록 설계하였다. 또한, 다수의 사용자들이 접근할 수 있도록 웹 기반으로 설계하였으며 서비스 단위의 독립적인 개발과 확장이 가능한 마이크로서비스 아키텍처 스타일로 설계 및 구현하였다.","Applying machine learning to satellite images has been actively studied in the field of geospatial information. However, there are few studies that consider data acquisition and preprocessing requirements arising from satellite image and machine learning specificity. In this study, we propose a lightweight and scalable system based on microservice architecture, which is the latest IT trend, by analyzing data acquisition and preprocessing requirements in the machine learning modeling process using satellite imagery. The proposed system facilitate effective data acquisition through spatio-temporal filtering and cloud cover filtering by constructing database, and facilitate automatic preprocessing with GUI for applying machine learning to satellite images. Moreover, we has designed a web-based system to be accessible by a number of users, has designed and implemented in a microservice architecture style that are independently developable and scalable as each service unit."
머신러닝(GRNN)을 이용한 교통사고모형의 예측정확도 개선에 관한 연구,2018,"['traffic accident models', 'machine learning', 'generalized regression neural network', 'negative binomial regression model', 'prediction accuracy']",,"PURPOSES : The purpose of this study is to compare applicability, explanation power, and flexibility of traffic accident models between estimating model using the statistical method and the machine learning method. METHODS: In order to compare and analyze traffic accident models between model estimated using the statistical method and machine learning method, data acquisition was conducted, and traffic accident models were estimated using statistical methods such as negative binomial regression model, and machine learning methods such as a generalized regression neural network (GRNN). Then, the fitness of model as R2, root mean square error (RMSE), mean absolute percentage error (MAPE), accuracy, etc., were determined to compare the traffic accident models. RESULTS: The results showed that the annual average daily traffic (AADT), speed limits, number of lanes, land usage, exclusive right turn lanes, and front signals were significant for both traffic accident models. The GRNN model of total traffic accidents had been better statistical significant with R2: 0.829, RMSE: 2.495, MAPE: 32.158, and Accuracy: 66.761 compared with the negative binomial regression model with R2: 0.363, RMSE: 9.033, MAPE: 68.987, and Accuracy: 8.807. The GRNN model of injury traffic accidents also showed similar results of model’s statistical significance. CONCLUSIONS: Traffic accident models estimated with GRNN had better statistical significance compared with models estimated with statistical methods such as negative binomial regression model."
과학의 미적 가치 인식에 대한 학습자의 응답에 대한 네트워크 및 감성 분석과 머신 러닝을 활용한 탐색적 예측 평가,2018,"['과학의 미적 가치', '형태소 분석', '감성 분석', '머신 러닝', '대학생', 'aesthetics of science', 'corpus analysis', 'network analysis', 'machine learning', 'undergraduate student']",,"The purpose of this study was to investigate students ’ perceptions about the aesthetic features of science through network and sentiment analysis, and to evaluate models to predict their perceptions by machine learning in an exploratory way. In this study, a total of 88 students were asked to answer the questionnaires on the nature of science, the nature of technology, and the aesthetic features of science. Semantic network analysis revealed that the students were more inclined to external features of aesthetics whereas internal features such as simplicity and harmony were considered as negative. Sentiment analysis also showed the similar results. The predictive models for students ’ perceptions were developed using k-nearest neighbor, support vector machine, decision tree, random forest, gradient boosting, and artificial neural network. However, all the models did not acquire successful outcomes. Based on the results, this study gave some implications for the exploration of influential factors on the aesthetic perception and the possibilities for applying machine learning to science education."
무선 환경에서 TCP 성능 개선을 위한 머신러닝 기반 LDA 혼잡제어 설계,2018,"['TCP congestion control', 'LDA', 'Wireless network', 'Machine learning', 'MLP']",,
머신러닝 기법을 이용한 납축전지 열화 예측 모델 개발,2018,"['배터리 열화', '납축전지', '열화 예측', '머신러닝', '데이터 마이닝', 'Battery Deterioration', 'Lead Acid Battery', 'Battery Deterioration Prediction', 'Machine Learning', 'Data Minin']",,"Although the worldwide battery market is recently spurring the development of lithium secondary battery, lead acid batteries (rechargeable batteries) which have good-performance and can be reused are consumed in a wide range of industry fields. However, lead-acid batteries have a serious problem in that deterioration of a battery makes progress quickly in the presence of that degradation of only one cell among several cells which is packed in a battery begins. To overcome this problem, previous researches have attempted to identify the mechanism of deterioration of a battery in many ways. However, most of previous researches have used data obtained in a laboratory to analyze the mechanism of deterioration of a battery but not used data obtained in a real world. The usage of real data can increase the feasibility and the applicability of the findings of a research. Therefore, this study aims to develop a model which predicts the battery deterioration using data obtained in real world. To this end, we collected data which presents change of battery state by attaching sensors enabling to monitor the battery condition in real time to dozens of golf carts operated in the real golf field. As a result, total 16,883 samples were obtained. And then, we developed a model which predicts a precursor phenomenon representing deterioration of a battery by analyzing the data collected from the sensors using machine learning techniques. As initial independent variables, we used 1) inbound time of a cart, 2) outbound time of a cart, 3) duration(from outbound time to charge time), 4) charge amount, 5) used amount, 6) charge efficiency, 7) lowest temperature of battery cell 1 to 6, 8) lowest voltage of battery cell 1 to 6, 9) highest voltage of battery cell 1 to 6, 10) voltage of battery cell 1 to 6 at the beginning of operation, 11) voltage of battery cell 1 to 6 at the end of charge, 12) used amount of battery cell 1 to 6 during operation, 13) used amount of battery during operation(Max-Min), 14) duration of battery use, and 15) highest current during operation. Since the values of the independent variables, lowest temperature of battery cell 1 to 6, lowest voltage of battery cell 1 to 6, highest voltage of battery cell 1 to 6, voltage of battery cell 1 to 6 at the beginning of operation, voltage of battery cell 1 to 6 at the end of charge, and used amount of battery cell 1 to 6 during operation are similar to that of each battery cell, we conducted principal component analysis using verimax orthogonal rotation in order to mitigate the multiple collinearity problem. According to the results, we made new variables by averaging the values of independent variables clustered together, and used them as final independent variables instead of origin variables, thereby reducing the dimension. We used decision tree, logistic regression, Bayesian network as algorithms for building prediction models. And also, we built prediction models using the bagging of each of them, the boosting of each of them, and RandomForest. Experimental results show that the prediction model using the bagging of decision tree yields the best accuracy of 89.3923%. This study has some limitations in that the additional variables which affect the deterioration of battery such as weather (temperature, humidity) and driving habits, did not considered, therefore, we would like to consider the them in the future research. However, the battery deterioration prediction model proposed in the present study is expected to enable effective and efficient management of battery used in the real filed by dramatically and to reduce the cost caused by not detecting battery deterioration accordingly."
머신러닝을 활용한 서울시 아파트 물리적 특성 변수들의 비선형 영향 분석: 다변량 적응 회귀 스플라인 모형의 적용,2018,"['Hedonic Price Model', 'Nonlinearity', 'Machine Learning', 'Multivariate Adaptive Regression Spline', 'Sub-Housing Market', '헤도닉 가격모형', '비선형성', '머신러닝', 'MARS', '주택하위시장']","헤도닉 가격모형은 주택가격을 추정하거나 다양한 주택가격 결정요인을 밝혀내는 연구에 널리 활용되어 왔다. 그러나 많은 연구자들이 선형회귀모형을 기반으로 헤 도닉 가격모형을 구축하면서 주택가격과 해당 주택특성들 간의 비선형적 관계를 포 착하기 어려웠다. 연구자들은 주택특성 변수와 주택가격 간의 비선형적 관계를 반 영하기 위하여 더미변수나 다항변수(제곱 또는 세제곱 등)를 주로 활용하고 있다. 하지만 개별 변수들의 조작적 정의는 주택시장에서의 경험적 지식에 기초하여 연구 자들마다 각기 다르게 설정되고 있다. 따라서 본 연구에서는 주택의 물리적 특성 변 수들과 주택가격 간의 비선형적 관계를 효과적으로 반영할 수 있는 방법론으로서 머신러닝 기법 중 하나인 Multivariate Adaptive Regression Spline(MARS)를 활용한 헤도닉 가격모형을 구축하고 향후 아파트 헤도닉 가격모형에서 변수의 조작적 정의 에 대한 시사점을 제시하고자 한다. MARS 기반의 헤도닉 가격모형은 2014년에서 2017년 사이에 거래된 서울시 아파트를 대상으로 전용면적, 세대수, 층수 및 경과 년도 등 아파트 물리적 특성 변수를 중심으로 구축하였다. 분석 결과, 전용면적 61.6㎡, 세대수 152세대 및 522세대, 3층이 개별 변수들의 영향력이 달라지는 변 곡점으로 판명되었다. 경과년수의 경우에는 시간이 지남에 따라 시설 노후화로 인 해 가격이 감소하지만 21년을 기점으로 39년까지 재건축 기대로 인해 가격이 상승 하고 그 이후 다시 가격이 하락하는 3차 함수 형태의 가격 변화를 보였다. 한편, 서 울시 주택하위시장별 분석 결과, 주택하위시장별로 아파트 물리적 특성 변수들의 비선형적 영향 패턴이 다르게 나타나므로 향후 이를 고려한 주택가격 연구가 필요 하다.","The hedonic price model has been widely used in numerous housing studies to estimate the housing price. Among them, many researchers used the linear regression method for fitting the hedonic price model, and tried to capture, or at least, control the nonlinear effects of housing characteristics by operational definition of the explanatory variables, such as dummy variables and polynomial variables. Those approaches have a limitation that they are based on empirical knowledge rather than data-driven knowledge. This study suggests an advanced hedonic price model using one of the machine learning methods, named MARS (Multivariate Adaptive Regression Spline), which can capture the inflection points where the explanatory variables have a nonlinear effect on the dependent variable. The analysis targets the apartments traded in Seoul between 2014 and 2017. Four main physical characteristics of the apartment have been selected for estimating the housing price. The analysis result shows that the determinants of the housing price have nonlinearity, indeed. The number of years from the apartment construction is representative; the housing price tends to decline over time but it dramatically rises between 21 to 39 years due to the reconstruction demand, then the price drops again after that. Additionally, the analysis result for each sub-housing market in Seoul shows that the nonlinearity of the housing price determinants considerably differs by regions."
머신러닝을 이용한 의료 및 광고 블로그 분류,2018,"['Medical blog', 'Big data', 'Machine learning', 'Blog reading system', 'Medical information blogs']","행복한 삶의 질을 목적으로 하는 의료소비자가 증가하면서 웹에 분산되어 있는 블로그의 의료 정보를 바탕으로 신뢰성 있는 의료 시설을 선택하고 고품질의 의료 서비스를 받음으로서, 시간과 비용을 절약할 수 있는 O2O 의료 마케팅 시장이 활성화 되고 있다. 인터넷, 모바일, SNS 등에서 증가하는 비정형 텍스트 데이터는 전문 의료 지식 이외에 작성자의 관심, 선호, 예상 등을 직간접적으로 반영하고 있기 때문에 의료정보의 신뢰성을 담보하기 어렵다. 본 연구에서는 빅데이터 및 MLP를 사용하여 의료정보 블로그를 분류 (의료블로그, 광고블로그)함으로서 사용자에게 보다 고품질의 의료정보 서비스를 제공하는 블로그 판단 시스템을 제안한다. 제안된 빅데이터 및 머신러닝 기술을 통해 인터넷상에 존재하는 국내의 다수 의료정보 블로그를 종합, 분석한 후 질환별 개인 맞춤형 건강정보 추천 시스템을 개발한다. 이를 통하여 사용자는 자신의 건강문제를 지속적으로 점검하고 가장 적절한 조치를 취함으로서 자신의 건강 상태를 유지하는 것이 가능할 것으로 기대된다.","With the increasing number of health consumers aiming for a happy quality of life, the O2O medical marketing market is activated by choosing reliable health care facilities and receiving high quality medical services based on the medical information distributed on web""s blog. Because unstructured text data used on the Internet, mobile, and social networks directly or indirectly reflects authors"" interests, preferences, and expectations in addition to their expertise, it is difficult to guarantee credibility of medical information. In this study, we propose a blog reading system that provides users with a higher quality medical information service by classifying medical information blogs (medical blog, ad blog) using bigdata and MLP processing. We collect and analyze many domestic medical information blogs on the Internet based on the proposed big data and machine learning technology, and develop a personalized health information recommendation system for each disease. It is expected that the user will be able to maintain his / her health condition by continuously checking his / her health problems and taking the most appropriate measures."
의사결정나무와 서포트 벡터 머신 모델을 활용한 토지이용 변화 시뮬레이션: 통일 후 북한 도시를 대상으로,2018,"['머신러닝', '토지이용/피복 변화', '북한 연구', '도시 시뮬레이션 분석', '접근불능지역 분석', 'Machine Learning', 'Land-use/Cover Change', 'North Korean Study', 'Urban Simulation Analysis', 'Inaccessible Area Analysis']","본 논문의 목적은 시뮬레이션 분석을 통한 통일 이후 북한 특정 도시를 대상으로 하여 토지이용 변화를 추정하는 것이다. 시뮬레이션 분석은 도시화 패턴 탐색을 위한 모델 적합도 연구와 시뮬레이션 결과에 따른 유효성 검증, 북한 도시 토지이용 변화 시뮬레이션 분석으로 구분된다. 도시화 패턴 탐색을 위한 모델링에 있어 적합한 방법론을 선정하기 위해서 통계 분석의 일종인 다항로지스틱 회귀분석과 머신러닝의 일종인 의사결정나무, 서포트 벡터 머신 알고리즘을 활용한 분석을 통해 토지이용 변화 추정 정확도를 비교 분석하였다. 이를 통해 시뮬레이션 단계 및 기준 토지이용별 추정 정확도가 가장 높은 모델을 결합한 시뮬레이션 통합 모델을 구축하였다. 해당 모델을 활용하여 북한 도시(남포특별시)의 시나리오별 토지이용 변화를 추정하였다. 남포특별시의 토지이용 변화 시뮬레이션 분석은 단계별 비포장도로 일부의 포장화, 철도역 신설, 신규 도심지역 개발을 가정한 시나리오로 진행하였다. 분석결과, 지역의 교통 접근성 변화와 신규 도심지역의 개발 영향은 해당 지역의 도시화는 물론이며 타 지역까지 연계되어 도시화 현상이 나타나게 되는 것을 확인할 수 있었다. 본 논문은 통일 한국 시대의 북한 도시화 현상을 미시적으로 추정하여, 향후 북한 도시의 개발정책 수립 시 전략적인 대응을 할 수 있는 측면에서 연구의 의의를 지닌다.","This study aims to estimate land-use changes in North Korea’s city after the unification through simulation. The simulation analysis consists of exploration of urban patterns, validation of simulated results, and analysis of the land-use changes in the future. The estimation accuracy of land use change was measured by polynomial regression analysis, decision tree analysis and support vector machine analysis. On this basis, suitable methodologies were selected for the modeling of the urban pattern search. The hybrid model uses the ‘C5.0’, a kind of decision tree algorithm and the ‘RBF kernel’, a kind of support vector machine algorithm. The land use change of North Korea’s city (Nampo City) was estimated based on this model. The scenario of newly constructing roads and railroad stations, and developing new urban areas was used in the simulation. The simulated results showed that the urban sprawl impact through improvement of traffic accessibility and the development of new urban areas could be linked to the region and other regions. This study could provide a strategic guidance for policy when the unification of Korea will be on the process."
머신러닝을 이용한 권한 기반 안드로이드 악성코드 탐지,2018,"['android', 'malware', 'static analysis', 'machine leaning']","본 연구는 안드로이드 정적분석을 기반으로 추출된 AndroidManifest 권한 특징을 통해 악성코드를 탐지하고자 한다. 특징들은 AndroidManifest의 권한을 기반으로 분석에 대한 자원과 시간을 줄였다. 악성코드 탐지 모델은 1500개의 정상어플리케이션과 500개의 악성코드들을 학습한 SVM(support vector machine), NB(Naive Bayes), GBC(Gradient Boosting Classifier), Logistic Regression 모델로 구성하여 98%의 탐지율을 기록했다. 또한, 악성앱 패밀리 식별은 알고리즘 SVM과 GPC (Gaussian Process Classifier), GBC를 이용하여 multi-classifiers모델을 구현하였다. 학습된 패밀리 식별 머신러닝 모델은 악성코드패밀리를 92% 분류했다.","This study focuses on detection of malicious code through AndroidManifest permissoion feature extracted based on Android static analysis. Features are built on the permissions of AndroidManifest, which can save resources and time for analysis. Malicious app detection model consisted of SVM (support vector machine), NB (Naive Bayes), Gradient Boosting Classifier (GBC) and Logistic Regression model which learned 1,500 normal apps and 500 malicious apps and 98% detection rate. In addition, malicious app family identification is implemented by multi-classifiers model using algorithm SVM, GPC (Gaussian Process Classifier) and GBC (Gradient Boosting Classifier). The learned family identification machine learning model identified 92% of malicious app families."
차륜 및 차축베어링 고장진단을 위한 빅데이터 기반 머신러닝 기법 연구,2018,"['Big data', 'Bearing/Wheel', 'Fault Diagnosis', 'Machine Learning', 'Rolling Stock']","본 철도 유지보수 산업의 효율화를 위해서는 핵심부품의 적시 관리를 통한 부품 가동률 향상 및 철도 운행의 안정성 향상이 필요하다. 또한 유지보수 시스템 고속화에 따른 신뢰성 향상과 핵심부품의 유지보수 비용 절감의 두 가지 측면을 모두 만족시키기 위해, 부품 이력관리와 대규모 빅데이터의 자동화된 분석 기술을 활용한 부품 상태 진단 기술 수요가 증가하고 있다. 이 논문에서는 철도차량의 차상 및 지상 장치로부터 발생되는 실시간 빅데이터 수집, 처리, 분석을 위해서 빅데이터 플랫폼 기반의 철도차량 부품의 상태 데이터 관리시스템을 개발하였으며, 이 시스템의 활용으로 철도차량의 부품 상태정보 및 시스템 리소스에 대한 실시간 모니터링이 가능하다. 또한 빅데이터 플랫폼으로부터 수집된 상태 데이터를 기반으로 분산/병렬처리 및 자동화된 부품 고장진단이 가능한 머신러닝 기법을 제안하였다. 실험결과, 분산/병렬처리 기술이 적용된 알고리즘의 실행시간 단축을 아마존 웹서비스의 가상 인스턴스 생성 시스템을 통해 증명하였으며, random forest 머신러닝기법을 활용한 고장 진단 모델의 베어링 및 차륜 부품에 대한 상태 예측 정확도가 83%임을 확인하였다.","Increasing the operation rate of components and stabilizing the operation through timely management of the core parts are crucial for improving the efficiency of the railroad maintenance industry. The demand for diagnosis technology to assess the condition of rolling stock components, which employs history management and automated big data analysis, has increased to satisfy both aspects of increasing reliability and reducing the maintenance cost of the core components to cope with the trend of rapid maintenance. This study developed a big data platform-based system to manage the rolling stock component condition to acquire, process, and analyze the big data generated at onboard and wayside devices of railroad cars in real time. The system can monitor the conditions of the railroad car component and system resources in real time. The study also proposed a machine learning technique that enabled the distributed and parallel processing of the acquired big data and automatic component fault diagnosis. The test, which used the virtual instance generation system of the Amazon Web Service, proved that the algorithm applying the distributed and parallel technology decreased the runtime and confirmed the fault diagnosis model utilizing the random forest machine learning for predicting the condition of the bearing and wheel parts with 83% accuracy."
Patch load resistance of longitudinally stiffened webs: Modeling via support vector machines,2018,"['steel girders', 'patch loading', 'longitudinal stiffener', 'support vector machines', 'machine learning']",,"Steel girders are the structural members often used for passing long spans. Mostly being subjected to patch loading, or concentrated loading, steel girders are likely to face sudden deformation or damage e.g., web breathing. Horizontal or vertical stiffeners are employed to overcome this phenomenon. This study aims at assessing the feasibility of a machine learning method, namely the support vector machines (SVM) in predicting the patch loading resistance of longitudinally stiffened webs. A database consisting of 162 test data is utilized to develop SVM models and the model with best performance is selected for further inspection. Existing formulations proposed by other researchers are also investigated for comparison. BS5400 and other existing models (model I, model II and model III) appear to yield underestimated predictions with a large scatter; i.e., mean experimental-to-predicted ratios of 1.517, 1.092, 1.155 and 1.256, respectively; whereas the selected SVM model has high prediction accuracy with significantly less scatter. Robust nature and accurate predictions of SVM confirms its feasibility of potential use in solving complex engineering problems."
머신러닝 기반의 온실 제어를 위한 예측모델 개발,2018,"['온실제어', '예측모델', '기계학습', '인공신경망', '순환신경망', 'Greenhouse control', 'Prediction model', 'Machine learning', 'Artificial neural network', 'Recurrent neural network']",,
머신 러닝을 이용한 외란 관측기 구현,2018,"['machine learning', 'disturbance observer', 'robust control', 'Inverse model']",,"This paper presents a method of constructing an inverse model-based disturbance observer using two neural network methods: Multi-Layer Perceptron (MLP) and Recurrent Neural Network (RNN). Learning data is prepared for MLP and RNN by selecting input data such that it contains various signal shapes such as constant, step, sinusoidal and random number, and frequency components. This input data is injected into the nominal model of the system and the resulting state values are used as the measurement. The weights of MLP and RNN are optimized using these data, and how unknown disturbances are estimated is explained using the learned MLP and RNN. The simulation results show that the proposed method works well; in other words, the MLP- and RNN-based disturbance observer can reject both external disturbances and model uncertainties."
스마트제조를 위한 머신러닝 기반의 설비 오류 발생 패턴 도출 프레임워크,2018,"['스마트제조', '설비 오류 패턴 도출', '머신러닝', '비정형 데이터', '텍스트 데이터 분석', '연관 규칙 마이닝', 'Smart Manufacturing', 'Facility Error Pattern Extraction', 'Machine Learning', 'Unstructured Data', 'Text Data Analysis', 'Association Rule Mining']","4차 산업혁명 시대를 맞아, 제조 기업들은 생산성 향상을 위해 축적된 설비 데이터를 활용하여 스마트제조를 실현하는 것에 높은 관심을 두고 있다. 하지만 기존의 설비 데이터 분석연구들은 주로 센서 데이터 등 정형 데이터를 대상으로 하여, 실제 큰 비중을 차지하고 있는 텍스트와 같은 비정형 데이터에 대한 분석 연구는 부족한 실정이다. 특히, 작업자가 수기로 작성한 텍스트 데이터를 활용한 사례는 매우 적었다. 따라서 본 논문에서는 작업자가 수기로 작성한 설비 오류 데이터를 분석하여 연관 규칙 마이닝을 통해 설비 오류 발생 패턴을 도출하는 프레임워크를 제안하고자 한다. 이때, 일반적인 텍스트 분석 기법과 같이 단어를 분석 기준으로 사용하는 경우 전문 용어에 해당하는 설비 오류의 의미를 표현하는 데에 한계가 있다는 점에 착안하여 구절을 추출하여 텍스트 분석 기준으로 사용하였다. 제안하는 프레임워크의 성능을 실제 사례를 통해 검증하였으며, 본 연구 결과를 활용하면 설비 오류를 예방하여 가동률을 높이고 나아가 제조 기업의 생산성 향상에 기여할 수 있을 것으로 기대한다.","With the advent of the 4-th industrial revolution, manufacturing companies have increasing interests in the realization of smart manufacturing by utilizing their accumulated facilities data. However, most previous research dealt with the structured data such as sensor signals, and only a little focused on the unstructured data such as text, which actually comprises a large portion of the accumulated data. Therefore, we propose an association rule mining based facility error pattern extraction framework, where text data written by operators are analyzed. Specifically, phrases were extracted and utilized as a unit for text data analysis since a word, which normally used as a unit for text data analysis, is unable to deliver the technical meanings of facility errors. Performances of the proposed framework were evaluated by addressing a real-world case, and it is expected that the productivity of manufacturing companies will be enhanced by adopting the proposed framework."
기계학습 기법을 활용한 회계이익 예측 모형 개선 방향,2018,"['Machine Learning', 'Deep Learning', 'Earnings', 'Forecasting Models', '기계학습', '딥러닝', '회계이익', '예측 모형']","본 연구에서는 회계이익의 중요성에도 불구하고, 이의 예측 모형 개발과 관련한 연구가 상대적으로 부족함을 지적하고, 최근 경영 환경의 변화에 따라 새로운 예측 모형 개발이 필요하며, 이를 위해 딥러닝을 포함한 기계학습 기법을 제안하고 있다. 또한 기계학습 기법에 친숙하지 않은 회계학 연구자들의 이해를 돕기 위해, 간략하지만 핵심적으로 가장 일반적인 기계학습 접근법과 이를 적용함에 있어 고려해야할 논점을 정리하였다.본 연구는 문헌 연구 방법에 기초하여 기존의 회계이익 예측 관련 선행 연구를 검토한 후 기계 학습 및 딥러닝의 개념적 이해와 도입 시 고려할 점을 제시하였다.회계이익 예측 문제에 있어 기존의 연구에서는 많은 개선이 이루어지지 못한 것이 사실이다. 최근 새롭게 주목 받고 있는 기계학습(또는 딥러닝)을 활용할 경우 지금까지의 연구의 한계를 극복할 수 있으며 변화된 환경에서도 유연하게 대처하여 회계정보의 유용성을 유지 및 강화하는데 도움이 될 수 있다. 본 연구에서는 이와 같은 기계학습(딥러닝)의 최신 적용 사례와 그 개념적 이해를 소개하여 이를 통해 회계학 연구자들에게 새로운 방법론의 적용 가능성에 대한 논의와 시도가 이루어질 수 있을 것으로 기대한다.","In this study, it is pointed out that the research related to the development of earnings forecasting models is relatively insufficient, despite the importance of accounting earnings, and propose the machine learning and deep learning methods according to the change of management environment. Also, I have summarized the most basic and general machine learning approaches and the issues to consider when applying them to help researchers who are not familiar with machine learning techniques.This study reviews previous researches related to accounting earnings forecasts based on literature research methods and then suggests conceptual understanding and introduction of machine learning and deep learning.It is true that many of the existing researches on accounting earnings forecast have not been much improved. The use of machine learning(or deep learning), which recently has been attracting attention, can overcome the limitations of previous studies and can help maintain and enhance the usefulness of accounting information by flexibly corresponding with the changed circumstances. In this study, I have introduced the conceptual understanding of the machine(deep) learning and its applicable examples, I hope that the applicability of the new methodology will be discussed and attempted by accounting researchers."
운고계 자료를 이용하여 기상 현상을 탐지하기 위한 기계학습 기법 적용,2018,"['운고계 후방산란자료', '기상현상 탐지', '랜덤포레스트', '서포트 벡터 머신', '인공신경망', 'Ceilometer back-scattered data', 'Meteorological phenomena detection', 'Random Forest', 'Support Vector Machine', 'Artificial Neural Network']","구름은 기후와 날씨 변화에서 가장 중요한 요인 중 하나로, 운고계는 구름의 고도와 운량을 자동으로 관측하는데 사용된다. 본 논문에서는 운고계에서 수집한 후방산란자료에 기계학습기법을 적용하여 기상현상을 탐지하는 방법을 제안한다. 먼저, 수집한 후방산란자료에 잡음을 제거하기 위한 방법으로 선형보간법과 잠음제거 오토인코더를 이용하여 잡음소거를 수행한다. 또한, 관측되는 기상현상이 현저히 적기 때문에 언더샘플링을 적용하여 기계학습기법을 적용했다. 적용한 기법으로는 랜덤포레스트, 서포트 벡터 머신, 인공신경망이며, 학습 시간의 문제로 서포트 벡터 머신과 인공신경망의 경우 특징선택으로 학습인자를 줄여 실험을 진행했다. 탐지한 기상현상으로는 강수, 안개, 기압을 다루었으며 지역별상세관측자료(AWS)와 시정자료를 사용했다. 기계학습의 성능평가를 위한 정확도 측도로 F1-점수를 사용했으며 실험에서 강수의 경우 0.3377, 안개의 경우 0.0949, 기압의 경우 0.3494를 보인다.","Clouds are one of the most important factors in climate and weather changes, and A ceilometer is used to automatically observe information about cloud altitude and cloudiness. In this paper, we propose a method to detect the presence-or-not of meteorological phenomena by applying machine learning to the back-scattered data collected from the ceilometer. First, to eliminate the noise in the observation data, linear interpolation and denoising autoencoder is used to perform noise elimination on the back-scattered data. Since the meteorological phenomena is remarkably small, the machine learning method was applied after undersampling. The machine learning used are Random Forests, Support Vector Machine, and Artificial Neural Network. In case of support vector machine and artificial neural network due to learning time problems, experiments were performed by reducing learning factors by feature selection. We deal with precipitation, fog, and atmospheric pressure as meteorological phenomena using AWS and visibility data. The F1-score was used as an accuracy measure for the performance evaluation of machine learning. In the experiment, it is 0.3377 for the precipitation, 0.0949 for the fog, and 0.3494 for the atmospheric pressure."
온라인 무료 샘플 판촉의 효과적 활용을 위한 기계학습 기반 고객분류예측 모형,2018,"['Online Free Sample Promotion', 'Machine Learning', 'Customer Relationship', 'Management', 'Customer Expansion']",,"PurposeThe purpose of this study is to build a machine learning-based customer classification model to promote customer expansion effect of the free sample promotion. Specifically, the proposed model classifies potential target customers who are expected to purchase the products included in the free sample promotion after receiving the free samples.Design/methodology/approachThis study proposes to build a customer classification model for determining customers suitable for providing free samples by using various machine learning techniques such as logistic regression, multiple discriminant analysis, case-based reasoning, decision tree, artificial neural network, and support vector machine. To validate the usefulness of the proposed model, we apply it to a real-world free sample-based target marketing case of a Korean major cosmetic retail company.FindingsExperimental results show that a machine learning-based customer classification model presents satisfactory accuracy ranging from 70% to 75%. In particular, support vector machine is found to be the most effective machine learning technique for free sample-based target marketing model. Our study sheds a light on customer relationship management strategies using free sample promotions."
기계학습 기반의 가상 네트워크 기능 자원 수요 예측 방법,2018,"['Virtual Network', 'Machine-Learning', 'Service Function Chaining']","네트워크 가상화 (Network virtualization)는 물리 네트워크상에서 각 사용자 별로 독립된 가상의 네트워크 환경을 생성하는 기술을 지칭한다. 네트워크 가상화 기술은 물리 네트워크 자원을 공유하여 사용자 별로 네트워크를 구축하는 데 필요한 비용을 절감할 수 있으며, 네트워크 관리자가 요구사항에 따라 동적으로 네트워크를 관리할 수 있도록 돕는다. 하지만 동적으로 네트워크 관리를 수행할 수 있다는 장점에도 불구하고, 관리자가 여전히 직접 판단을 내리고 관리 기능을 실행하는 과정은 동일하다. 네트워크 관리 기능 실행 전까지 관리자에 의해 네트워크 상황을 파악하고 결정을 내리는 과정에는 많은 시간이 소요될 수 있기 때문에 네트워크 가상화로 얻을 수 있는 동적 네트워크 관리라는 장점을 최대화 하지 못하고 있다. 본 논문에서는 기계학습 (Machine Learning) 기술을 도입하여 사람의 도움 없이 네트워크가 스스로 학습하여 동적으로 네트워크 관리를 수행하는 방법을 제안한다. 제안하는 방법은 가상 네트워크 관리에서 핵심적이고 필수적인 문제인 자원관리 최적화 문제를 서비스 펑션 체인 (Service Function Chaining) 문제로 정의하고, VNF의 자원 수요를 예측하여 적절한 자원을 동적으로 할당해 서비스 중단이 일어나는 것을 방지하면서 네트워크 운용비용을 절감하는 것을 목표로 한다.","Network virtualization refers to a technology creating independent virtual network environment on a physical network. Network virtualization technology can share the physical network resources to reduce the cost of establishing the network for each user and enables the network administrator to dynamically change the network configuration according to the purpose. Although the network management can be handled dynamically, the management is manual, and it does not maximize the profit of network virtualization. In this paper, we propose Machine-Learning technology to allow the network to learn by itself and manage its management dynamically. The proposed approach is to dynamically allocate appropriate resources by predicting resource demand of VNF in service function chaining, which is a core and essential problem in virtual network management. Our goal is to predict the resource demand of the VNF and dynamically allocate the appropriate resources to reduce the cost of network operation while preventing service interruption."
기계 학습 모델에 기반한 형량 예측 시스템 연구,2018,"['기계 학습', '판결 예측', '형량 예측', '양형', '법원 결정', 'Machine Learning', 'Sentence Estimation', 'Penalty Estimation', 'Sentencing', 'Court Decision']",,"National administrative justices should be operated impartially, accurately, and predictably. Depending on the individual’s social capitals and judge’s subjective discretion, sometimes the court decisions can be inconsistent, and the trust in jurisdiction can be threatened. For these reason, the need for legal assistant software utilizing recent machine learning-based training algorithm arises naturally. This paper researches the algorithms for court decision prediction based on diverse machine learning and pattern recognition-based approaches. Gathering domestic sentencing data, we analyzed the various features such as legal, social, and geometrical features of court and court participants including their interrelations, which can meaningfully affect the sentencing results. We thereafter applied and analyzed various machine learning-based sentencing prediction models that trains pattern relations in the existing sentencing data. Among the proposed sentence prediction systems, sparse nonnegative-matrix factorization (SNMF) and exemplar-based nonnegative matrix factorization (ENMF)-based methods showed the best performance achieving 42 month in RMSE and 28.7% in MAPE results. These methods especially showed remarkable performances for low valued sentences whose samples are abundant, achieving 18 month in RMSE and 29.775% MAPE for the cases under 120 months. The developed methods are expected to be even improved if we have more and balanced data set and use better-designed learning structures."
앙상블을 이용한 기계학습 기법의 설계: 뜰개 이동경로 예측을 통한 실험적 검증,2018,"['앙상블', '기계학습', '부스팅', '배깅', '뜰개']","앙상블 기법은 기계학습에서 다수의 알고리즘을 사용하여 더 좋은 성능을 내기 위해 사용하는 방법이다. 본 논문에서는 앙상블 기법에서 많이 사용되는 부스팅과 배깅에 대해 소개를 하고, 서포트벡터 회귀, 방사기저함수 네트워크, 가우시안 프로세스, 다층 퍼셉트론을 이용하여 설계한다. 추가적으로 순환신경망과 MOHID 수치모델을 추가하여 실험을 진행한다. 실험적 검증를 위해 사용하는 뜰개데이터는 7 개의 지역에서 관측된 683 개의 관측 자료다. 뜰개 관측 자료를 이용하여 6 개의 알고리즘과의 비교를 통해 앙상블 기법의 성능을 검증한다. 검증 방법으로는 평균절대오차를 사용한다. 실험 방법은 배깅, 부스팅, 기계학습을 이용한 앙상블 모델을 이용하여 진행한다. 각 앙상블 모델마다동일한 가중치를 부여한 방법, 차등한 가중치를 부여한 방법을 이용하여 오류율을 계산한다. 가장 좋은 오류율을 나타낸 방법은 기계학습을 이용한 앙상블 모델로서 6 개의 기계학습의 평균에 비해61.7%가 개선된 결과를 보였다.","The ensemble is a unified approach used for getting better performance by using multiple algorithms inmachine learning. In this paper, we introduce boosting and bagging, which have been widely used inensemble techniques, and design a method using support vector regression, radial basis function network,Gaussian process, and multilayer perceptron. In addition, our experiment was performed by adding arecurrent neural network and MOHID numerical model. The drifter data used for our experimentalverification consist of 683 observations in seven regions. The performance of our ensemble technique isverified by comparison with four algorithms each. As verification, mean absolute error was adapted. The presented methods are based on ensemble models using bagging, boosting, and machine learning. The errorrate was calculated by assigning the equal weight value and different weight value to each unit model inensemble. The ensemble model using machine learning showed 61.7% improvement compared to theaverage of four machine learning technique."
바이너리 시각화와 기계학습을 이용한 악성코드 분류,2018,"['컴퓨터 보안', '악성코드 분류', '특징정보 추출', '기계학습', 'computer security', 'malware classification', 'feature extraction', 'machine learning']","악성코드 제작 시, 기존 코드의 재사용, 악성코드 제작 도구의 발전 등의 이유로 인해, 악성코드 변종의 수가 빠르게 증가하고 있다. 따라서 악성코드의 변종을 정확하고 신속하게 분류하는 것이 중요해지고 있다. 기존의 악성코드 분류는 바이너리 파일 내 특정 바이트 순열 포함 여부를 이용하였으나 이러한 시그니처 기반 악성코드 분류는 변종 악성코드를 분류하는 데 어려움이 있다. 본 논문은 악성코드변종을 보다 높은 정확도로 분류하기 위한 이미지 기반 악성코드 분류 방법을 제안한다. 악성코드 분류를 위해, 악성코드 바이너리로부터 고정된 크기의 이미지를 생성한다. 바이너리의 각 바이트의 값을 좌표로 이용하며, 2 바이트 데이터를 <x, y> 좌표로 대응시켜, 이미지에서 각 좌표에 해당되는 픽셀의 값을 증가시킨다. 이러한 방식으로 생성된 이미지 특징정보를 기계학습에 활용한다. 악성코드 분류에 사용된 기계학습 알고리즘은 random forest와 convolutional neural network이며, 각각의 분류 기법을 10868개의 악성코드 샘플에 실험한 결과, 각각 98.9%, 97.1%의 높은 정확도로 악성코드를 분류하였다.","The number of variants of malware is rapidly increasing. This can be attributed to reasons such as reuse of existing code and evolution of malware generation tools. Therefore, it is important to classify variants of malware accurately and quickly. The current malware classification system used whether binary file includes certain byte sequence in itself but these signature based malware classifications has difficulties in classifying variants of malware. This paper proposes a new method for classifying variants of malware. To classify variants of malware, it creates a fixed size image from malware binary file. The value of each byte of the binary is used as a coordinate and the two byte data is associated with the <x, y> coordinates, and the value of the pixel corresponding to each coordinate in the image is increased. The image feature information generated in this way is utilized for machine learning. The machine learning methods used in malware classification are random forest, convolutional neural network and the experiments of each classification method on 10868 malware samples resulted with high accuracy of 98.9% and 97.1% respectively."
기계학습을 통한 여름철 노면상태 추정 알고리즘 개발,2018,"['Traffic safety', 'Weather', 'Road surface condition', 'Machine learning', '교통안전', '기상', '노면상태', '기계학습']","기상은 교통흐름, 운전자의 주행패턴, 교통사고 등 여러 방면에서 도로교통에 영향을 미치는 중요한 요인이다. 본 연구는 기상상황과 노면상태 사이의 관계에 초점을 맞추어 기계학습을 통해 도로의 노면상태를 추정하는 모델을 개발하였다. 노면 상태의 수집을 위해 실험 차량에 노면센서를 부착하여 ‘건조’, ‘습윤’, ‘젖음’, 3가지 범주로 구분된 노면상태 정보를 수집하였고, 이를 추정하기 위한 변수로 도로의 기하구조 정보(곡률, 구배), 교통정보(교통량), 기상정보(강우량, 습도, 온도, 풍속)를 활용하였다. 노면 상태를 예측하기 위한 알고리즘으로는 다양한기계학습 알고리즘이 검토되었으며, 그 중 가장 높은 정확도를 보인 ‘Random forest’를 기반으로 한 2단계 분류모형을 구축하였다. 총 16일의 실측 데이터 중 14일의 데이터를 모델을 학습하는 데 활용하였고, 2일의 데이터를 모형의 정확도를 검증하기 위해 사용하였다. 그 결과81.74%의 검증 정확도를 가지는 노면상태 예측 모델을 구축하였다. 본 연구의 결과는 기상청에서 관측하는 기상정보로 도로의 노면상태를 추정할 수 있다는 가능성을 보여주며, 새로운장비나 센서를 설치하지 않고도 기존의 기상 관측 정보와 교통정보 등을 활용하여 노면의 상태를 추정할 수 있음을 시사한다.","Weather is an important factor affecting roadway transportation in many aspects such as traffic flow, driver 's driving patterns, and crashes. This study focuses on the relationship between weather and road surface condition and develops a model to estimate the road surface condition using machine learning. A road surface sensor was attached to the probe vehicle to collect road surface condition classified into three categories as 'dry', 'moist' and 'wet'. Road geometry information (curvature, gradient), traffic information (link speed), weather information (rainfall, humidity, temperature, wind speed) are utilized as variables to estimate the road surface condition. A variety of machine learning algorithms examined for predicting the road surface condition, and a two - stage classification model based on 'Random forest' which has the highest accuracy was constructed. 14 days of data were used to train the model and 2 days of data were used to test the accuracy of the model. As a result, a road surface state prediction model with 81.74% accuracy was constructed. The result of this study shows the possibility of estimating the road surface condition using the existing weather and traffic information without installing new equipment or sensors."
기계학습 기반의 IABP 부이 자료와 AMSR2 위성영상을 이용한 여름철 북극 대기 온도 추정,2018,"['Arctic surface air temperature', 'Buoy', 'AMSR2', 'the International Arctic Bouy Programme', 'Random Forest', 'Support Vector Machine']","북극 지역의 대기 온도는 바다 및 해빙, 대기 사이의 에너지 교환에 큰 역할을 하므로 북극 대기 온도를 정확하게 파악하는 것은 중요하다. 하지만 현장 관측 자료들은 북극 대기 온도의 공간적인 분포를 나타내는 데에 한계가 있다. 따라서 본 연구에서는 부이(buoy) 자료와 Advanced Microwave Scanning Radiometer 2(AMSR2) 위성자료를 이용하여 기계학습 기반 여름철 대기 온도 추정 모델을 구축하였다. 기계학습으로는 random forest(RF) 및 support vector machine(SVM)을 사용하였으며, AMSR2 관측 시간에 따라 하루 두 번의 대기 온도를 추정하였다. 또한 추정된 대기 온도를 유럽 중기예보센터(European Centre for Medium-Range Weather Forecasts, ECMWF)의 ERA-Interim 재분석자료의 대기 온도와 공간 분포를 비교하였다. 교차 검증 결과 두 가지 기계학습 기법 모두 0.84-0.88의 R2 및 1.31-1.53°C의 RMSE를 보였다. 공간적인 분포에서 IABP 부이 관측 자료가 존재하지 않는 바렌츠해(Barents Sea), 카라해(Kara Sea) 및 배핀만(Baffin bay) 지역에서는 기계학습 모델이 ERA-Interim 대기 온도에 비하여 과소 추정하는 경향을 보였다. 본 연구는 경험적인 북극 대기 온도 추정의 가능성과 한계점을 서술하였다.","It is important to measure the Arctic surface air temperature because it plays a key-role in the exchange of energy between the ocean, sea ice, and the atmosphere. Although in-situ observations provide accurate measurements of air temperature, they are spatially limited to show the distribution of Arctic surface air temperature. In this study, we proposed machine learning-based models to estimate the Arctic surface air temperature in summer based on buoy data and Advanced Microwave Scanning Radiometer 2 (AMSR2) satellite data. Two machine learning approaches-random forest (RF) and support vector machine (SVM)-were used to estimate the air temperature twice a day according to AMSR2 observation time. Both RF and SVM showed R2 of 0.84-0.88 and RMSE of 1.31-1.53°C. The results were compared to the surface air temperature and spatial distribution of the ERA-Interim reanalysis data from the European Center for Medium-Range Weather Forecasts (ECMWF). They tended to underestimate the Barents Sea, the Kara Sea, and the Baffin Bay region where no IABP buoy observations exist. This study showed both possibility and limitations of the empirical estimation of Arctic surface temperature using AMSR2 data."
기계학습을 이용한 역사 텍스트의 저자판별: 1920년대 개벽 잡지의 논설 텍스트,2018,"['authorship attribution', 'stylometry', 'machine learning', 'support vector machine', 'GaeByeok', 'n-gram', 'text classification']",,"This study aims to demonstrate how the authorship attribution techniques can be appliedto historical texts, exploring the potential of authorship attribution as a solution to the realworld authorship disputes and the possibility of multidisciplinary research that combineshumanities and quantitative text analytics. History and literary studies have used traditionalmethods of judging the similarity of topics and subject matters or relying on extra-textualinformation to solve the authorship problems. This subjective and anecdotal approach toauthorship needs to be complemented by incorporating objective and quantitativemethodology that examines intra-textual clues. As the first case study, we performed machinelearning-based authorship attribution analysis on the 164 opinion texts with unknownauthorship from GaeByeok magazine of the 1920s. To enhance accuracy and reliability ofthe analysis, an improved machine learning algorithm was devised based on SVM byincorporating three parameters α, β, θ into the prediction model. This study is also acase study showing how to perform the authorship attribution analysis in an open setting,not in a closed setting. We hope that the prediction results of the analysis will encourageand facilitate more productive discussion among related disciplines on authorshipidentification and verification of real historical texts."
기계학습기반의 근사모델을 이용한 선박 횡동요 운동 예측,2018,"['Seakeeping Performance', 'Roll Motion Prediction', 'Machine Learning', 'Surrogate Model', 'Korean e-Navigation', '내항성능 평가', '횡동요 운동 예측', '기계학습', '근사모델', '한국형 e-Navigation']","한국형 e-Navigation의 내항성 안전 모듈은 운항 중인 선박을 실시간으로 모니터링하고 내항성의 이상 상태를 사전에 경고함으로써 선박의 안정성을 확보하는 선내 원격 모니터링 서비스 중 하나이다. 일반적으로 선박설계를 위한 내항성능은 주어진 조건에서 선체 운동 시뮬레이션을 수행하여 평가하여 왔다. 하지만 운항 중 선박의 내항성능을 실시간으로 평가하기 위해 이러한 시뮬레이션을 실제 운항조건에 맞추어 수행하는 것은 계산시간의 한계로 인해 현실적이지 않다. 본 연구에서는 기계학습 기반의 근사모델을 활용하여 선박의 내항성능 평가 요소들 중 하나인 횡동요 운동특성을 합리적으로 보다 빠르게 예측하는 방법을 소개하고자 한다. 다양한 학습 기법과 데이터의 샘플링 조건을 적용하여, 얻어진 근사모델의 결과와 운동해석 결과의 오차가 거의 1% 내로 일치함을 보였다. 따라서 이러한 방법을 활용하면 선박의 실시간 내항성능을 평가하는데 효율적으로 사용할 수 있을 것으로 판단된다.","Seakeeping safety module in Korean e-Navigation system is one of the ship remote monitoring services that is employed to ensure the safety of ships by monitoring the ship's real time performance and providing a warning in advance when the abnormal conditions are encountered in seakeeping performance. In general, seakeeping performance has been evaluated by simulating ship motion analysis under specific conditions for its design. However, due to restriction of computation time, it is not realistic to perform simulations to evaluate seakeeping performance under real-time operation conditions. This study aims to introduce a reasonable and faster method to predict a ship’s roll motion which is one of the factors used to evaluate a ship’s seakeeping performance by using a machine learning-based surrogate model. Through the application of various learning techniques and sampling conditions on training data, it was observed that the difference of roll motion between a given surrogate model and motion analysis was within 1%. Therefore, it can be concluded that this method can be useful to evaluate the seakeeping performance of a ship in real-time operation."
비만 폐쇄수면무호흡 환자에서 기계학습을 통한 적정양압 예측모형,2018,"['Sleep apnea', 'Obstructive', 'Continuous positive airway pressure', 'Machine learning', 'Obesity.']",,"The aim of this study was to develop a predicting model for the optimal continuous positive airway pressure (CPAP) for obstructive sleep apnea (OSA) patient with obesity by using a machine learning. Methods: We retrospectively investigated the medical records of 162 OSA patients who had obesity [body mass index (BMI) ≥ 25] and undertaken successful CPAP titration study. We divided the data to a training set (90%) and a test set (10%), randomly. We made a random forest model and a least absolute shrinkage and selection operator (lasso) regression model to predict the optimal pressure by using the training set, and then applied our models and previous reported equations to the test set. To compare the fitness of each models, we used a correlation coefficient (CC) and a mean absolute error (MAE). Results: The random forest model showed the best performance {CC 0.78 [95% confidence interval (CI) 0.43–0.93], MAE 1.20}. The lasso regression model also showed the improved result [CC 0.78 (95% CI 0.42–0.93), MAE 1.26] compared to the Hoffstein equation [CC 0.68 (95% CI 0.23–0.89), MAE 1.34] and the Choi’s equation [CC 0.72 (95% CI 0.30–0.90), MAE 1.40]. Conclusions: Our random forest model and lasso model (26.213+0.084×BMI+0.004×apnea-hypopnea index+0.004×oxygen desaturation index–0.215×mean oxygen saturation) showed the improved performance compared to the previous reported equations. The further study for other subgroup or phenotype of OSA is required."
목부착형 센서를 이용한 기계학습 기반 소 심부체온 예측방안,2018,,,"The body temperature of livestock is directly related to the health of livestock such that it changes immediately when there exists health problem. Accordingly, the monitoring of livestock's temperature is one of most important tasks in farm management. However, the temperature of livestock is usually measured using skin-attached sensor which is significantly affected by the outside temperature and the condition of attachment which results in the inaccurate measurement of temperature. Herein we have proposed new scheme which estimates the body core temperature of cow based on measured data from neck-attached smart sensor. Especially, we have considered both schemes which estimate the exact temperature and which detect the unusually high temperature based on machine learning. We have found that the occurrence of high temperature can be detected accurately. The proposed scheme can be used in monitoring of health condition of cow and improving the efficiency of farm management."
기계학습을 활용한 이더리움 미확인 스마트 컨트랙트 자동 분류 방안,2018,"['Blockchain', 'Ethereum', 'Smart contract', 'De-anonymity', 'Forensics']","암호화폐를 위해 개발된 블록체인 시스템은 탈중앙화, 분산원장 및 부분적 실명은닉성의 특징을 가지고 있어 최근다양한 분야에서 적용이 시도되고 있다. 그 중 부분적 실명은닉성은 사용자 프라이버시를 강력히 보장하지만 범죄악용 등 부작용 또한 나타나고 있어 이를 공격하기 위한 방안들이 지속 연구되어 왔다. 본 연구에서는 2세대 암호화폐의 대표인 이더리움 블록체인 시스템에서의 사용자 행위 식별을 위해 기계학습을 활용한 미확인 스마트 컨트랙트 기능 및 디자인 패턴의 자동 분류 방안에 대하여 제안한다.","A blockchain system developed for crypto-currency has attractive characteristics, such as de-centralization, distributedledger, and partial anonymity, making itself adopted in various fields. Among those characteristics, partial anonymity stronglyassures privacy of users, but side effects such as abuse of crime are also appearing, and so countermeasures forcircumventing such abuse have been studied continuously. In this paper, we propose a machine-learning based method forclassifying smart contracts in Ethereum regarding their functions and design patterns and for identifying user behaviorsaccording to them."
기계 학습을 이용한 공동주택 가격 추정: 서울 강남구를 사례로,2018,"['Machine Learning', 'Apartment Price', 'Support Vector Machine', 'Ensemble Model', 'Deep Neural Networks', '기계 학습', '공동주택 가격', '서포트 벡터 머신', '앙상블 모형', '심층 신경망']",,"This study examines the applicability of the machine learning methods to the real estatevaluation. Gangnam-gu, Seoul is chosen as the study area, and the housing prices are estimatedusing the sales cases collected in 2016. The predictive power of the machine learning methods suchas SVM (support vector machine), Ensemble Model and DNN (Deep Neural Networks) is superior tothat of the multiple regression analysis (MRA) methods. Among the machine learning methods, thepredictability of the GBRT (Gradient Boosting Regression Tree) model is slightly superior to that ofthe others. In addition, we estimate the assessment prices by applying an assessment ratio toestimated housing prices. The assessment values estimated by the machine learning methodsreflect the actual transaction prices better than the actual assessment values do, and satisfy thetaxation equity requirements. Drawing on the machine learning methods, this study is expected tohelp improve the efficiency of mass appraisal such as the housing assessment."
작물분류에서 기계학습 및 딥러닝 알고리즘의 분류 성능 평가: 하이퍼파라미터와 훈련자료 크기의 영향 분석,2018,"['Crop classification', 'Machine learning', 'Deep learning', 'Support vector machine', 'Convolutional neural network']",,"The purpose of this study is to compare machine learning algorithm and deep learning algorithm in crop classification using multi-temporal remote sensing data. For this, impacts of machine learning and deep learning algorithms on (a) hyper-parameter and (2) training sample size were compared and analyzed for Haenam-gun, Korea and Illinois State, USA. In the comparison experiment, support vector machine (SVM) was applied as machine learning algorithm and convolutional neural network (CNN) was applied as deep learning algorithm. In particular, 2D-CNN considering 2-dimensional spatial information and 3D-CNN with extended time dimension from 2D-CNN were applied as CNN. As a result of the experiment, it was found that the hyper-parameter values of CNN, considering various hyper-parameter, defined in the two study areas were similar compared with SVM. Based on this result, although it takes much time to optimize the model in CNN, it is considered that it is possible to apply transfer learning that can extend optimized CNN model to other regions. Then, in the experiment results with various training sample size, the impact of that on CNN was larger than SVM. In particular, this impact was exaggerated in Illinois State with heterogeneous spatial patterns. In addition, the lowest classification performance of 3D-CNN was presented in Illinois State, which is considered to be due to over-fitting as complexity of the model. That is, the classification performance was relatively degraded due to heterogeneous patterns and noise effect of input data, although the training accuracy of 3D-CNN model was high. This results imply that a proper classification algorithms should be selected considering spatial characteristics of study areas. Also, a large amount of training samples is necessary to guarantee higher classification performance in CNN, particularly in 3D-CNN."
기계학습모델을 통한 응급실 폐렴환자의 사망예측 모델과 기존 예측 모델의 비교,2018,"['Pneumonia', 'Mortality', 'Machine learning', 'Emergency department']",,"Objective: Machine learning is not yet widely used in the medical field. Therefore, this study was conducted to compare the performance of preexisting severity prediction models and machine learning based models (random forest [RF], gradient boosting [GB]) for mortality prediction in pneumonia patients.Methods: We retrospectively collected data from patients who visited the emergency department of a tertiary training hospital in Seoul, Korea from January to March of 2015. The Pneumonia Severity Index (PSI) and Sequential Organ Failure Assessment (SOFA) scores were calculated for both groups and the area under the curve (AUC) for mortality prediction was computed. For the RF and GB models, data were divided into a test set and a validation set by the random split method. The training set was learned in RF and GB models and the AUC was obtained from the validation set.The mean AUC was compared with the other two AUCs.Results: Of the 536 investigated patients, 395 were enrolled and 41 of them died. The AUC values of PSI and SOFA scores were 0.799 (0.737-0.862) and 0.865 (0.811-0.918), respectively. The mean AUC values obtained by the RF and GB models were 0.928 (0.899-0.957) and 0.919 (0.886-0.952), respectively. There were significant differences between preexisting severity prediction models and machine learning based models (P<0.001).Conclusion: Classification through machine learning may help predict the mortality of pneumonia patients visiting the emergency department."
기계학습 클러스터링을 이용한 승하차 패턴에 따른 서울시 지하철역 분류,2018,"['Machine Learning', 'Public Data', 'Seoul Metro Station', 'GMM', 'K-means Clustering']",,"In this study, we classify Seoul metro stations according to boarding and alighting patterns using machine earning technique. The target data is the number of boarding and alighting passengers per hour every day at 233 subway stations from 2008 to 2017 provided by the public data portal. Gaussian mixture model (GMM) and K-means clustering are used as machine learning techniques in order to classify subway stations. The distribution of the boarding time and the alighting time of the passengers can be modeled by the Gaussian mixture model. K-means clustering algorithm is used for unsupervised learning based on the data obtained by GMM modeling. As a result of the research, Seoul metro stations are classified into four groups according to boarding and alighting patterns. The results of this study can be utilized as a basic knowledge for analyzing the characteristics of Seoul subway stations and analyzing it economically, socially and culturally. The method of this research can be applied to public data and big data in areas requiring clustering."
기계학습 알고리즘을 이용한 반도체 테스트공정의 불량 예측,2018,"['Machine learning', 'Semiconductor test process', 'Prediction model', 'Classification', 'Package test']",,"Because of the rapidly changing environment and high uncertainties, the semiconductor industry is in need of appropriate forecasting technology. In particular, both the cost and time in the test process are increasing because the process becomes complicated and there are more factors to consider. In this paper, we propose a prediction model that predicts a final ""good"" or ""bad"" on the basis of preconditioning test data generated in the semiconductor test process. The proposed prediction model solves the classification and regression problems that are often dealt with in the semiconductor process and constructs a reliable prediction model. We also implemented a prediction model through various machine learning algorithms. We compared the performance of the prediction models constructed through each algorithm. Actual data of the semiconductor test process was used for accurate prediction model construction and effective test verification."
공공서비스 인공지능 ML 적용과 공공가치,2018,"['인공지능기반 공공서비스', '기계 학습', '신공공성', '공공 가치', 'public service', 'artificial intelligence', 'machine learning', 'public value']","최근 정보통신 기술의 발전으로 공공부문에 인공지능기법을 이용해 서비스를 제공하는 사례는 늘고 있다. 그럼에도 불구하고, 인공지능기반 공공서비스의 개념과 특징을 이해하고, 그것이 신공공성 논의에 어떠한 영향을 미치고 있는지에 대한 논의는 미흡한 실정이다. 이에 본 연구는 인공지능 기계학습(Machine Learning, ML)을 도입·적용하고 있는 공공서비스 사례를 분석하여, 행정 환경의 변화로 최근 논의가 되고 있는 신공공성에 근거한 공유된 책임성, 종합적 다양성과 적극적 중립성 등의 공공가치의 보완이 필요함을 주장하고자 한다.","Recently, artificial intelligence techniques are increasing used in public services due to ICT development. However, limited information is available to understand the concept and characteristics of public services based on artificial intelligence. How it affects new publicness is unclear. In this study, we analyzed cases of public services introducing and applying machine learning and argued that it might be necessary to complement public values such as shared accountability, comprehensive diversity, and positive neutrality based on new publicness. This has been discussed recently due to changes in public administration environments."
기계학습을 이용한 재실자 상태 인지를 위한 환경 데이터 기반 Classification 알고리즘 비교 연구,2018,"['Occupant status detection', 'Machine learning', 'Classification algorithm']",,"The purpose of this study is to develope an occupant status detection model by using indoor environmental data such as temperature, humidity, CO₂, noise, lighting power energy usage, etc. This study tested various classification algorithms (i.e., Support Vector Machine(SVM), K-Nearest Neighbor(KNN), Decision Trees(DT)) which are one of machine learning methods. We defined the occupant’s state as ‘Away’, ‘Active’, and ‘Inactive’, and tried to classify the status of the occupant by learning environmental data as prediction variables. The major environmental factors affecting the model were identified and the accuracies of prediction according to the classification algorithms were analyzed. As a result, it was confirmed that the main variables influencing the occupant status detection were the lighting electricity energy consumption and CO₂ concentration. In addition, we confirmed that by combining these two variables, we can implement an occupant status detection model with a prediction accuracy of 92%."
기계학습을 활용한 기상예측자료 기반 태양광 발전량 예측 향상기법,2018,"['Photovoltaic power output forecasting', 'Machine learning model selection', 'Solar radiation', 'Weather data']",,"This study investigated a selection of machine learning model to forecast electric power output from photovoltaic arrays based on forecasted weather data and historic solar radiation data. It tested two approaches to improve forecasting accuracy of power output with three typical machine learning algorithms such as Random Forest(RF), Artificial Neural Network(ANN), and Support Vector Machine(SVM). A forecasting power output was conducted with conventional weather forecasting data from national weather service which does not include solar radiation. The other approach has two steps, forecasting solar radiation with weather forecasting data and historic solar radiation data then it forecasts the electric power output of photovoltaic arrays. It has been studied the importance variables incorporated with the power output forecasting. The results show that the forecasting accuracy of the power output improves by using forecasted solar radiation data and Random Forest outperforms on this power output forecasting problem among other machine learning algorithms."
텍스트 마이닝과 기계 학습을 이용한 국내 가짜뉴스 예측,2018,"['Fake News Detection', 'Korean News', 'Machine Learning', 'Text Mining']",,"Fake news is defined as the news articles that are intentionally and verifiably false, and could mislead readers. Spread of fake news may provoke anxiety, chaos, fear, or irrational decisions of the public. Thus, detecting fake news and preventing its spread has become very important issue in our society. However, due to the huge amount of fake news produced every day, it is almost impossible to identify it by a human. Under this context, researchers have tried to develop automated fake news detection method using Artificial Intelligence techniques over the past years. But, unfortunately, there have been no prior studies proposed an automated fake news detection method for Korean news.In this study, we aim to detect Korean fake news using text mining and machine learning techniques. Our proposed method consists of two steps. In the first step, the news contents to be analyzed is convert to quantified values using various text mining techniques (Topic Modeling, TF-IDF, and so on). After that, in step 2, classifiers are trained using the values produced in step 1. As the classifiers, machine learning techniques such as multiple discriminant analysis, case based reasoning, artificial neural networks, and support vector machine can be applied.To validate the effectiveness of the proposed method, we collected 200  Korean news from Seoul National University’s FactCheck (http://factcheck.snu.ac.kr). which provides with detailed analysis reports from about 20 media outlets and links to source documents for each case. Using this dataset, we will identify which text features are important as well as which classifiers are effective in detecting Korean fake news."
도시 빅데이터를 활용한 스마트시티의 교통 예측 모델,2018,"['Big Data', 'Bus Headway Prediction', 'Machine Learning', 'Public Transportation', 'Smart City', 'Information Architecture', '빅데이터', '머신러닝', '버스 배차간격 예측', '대중교통', '스마트 시티', '정보 건축']",,"The research aims to find implications of machine learning and urban big data as a way to construct the flexibletransportation network system of smart city by responding the urban context changes. This research deals with a problem that existing a bus headway model is difficult to respond urban situations in real-time. Therefore, utilizing the urban big data and machine learning prototyping tool in weathers, traffics, and bus statues, this research presents a flexible headway model to predict bus delay and analyze the result. The prototyping model is composed by real-time data of buses. The data is gathered through public data portals and real time Application Program Interface (API) by the government. These data are fundamental resources to organize interval pattern models of busoperations as traffic environment factors (road speeds, station conditions, weathers, and bus information of operating in real-time). The prototyping model is implemented by the machine learning tool (RapidMiner Studio) and conducted several tests for bus delays prediction according to specific circumstances. As a result, possibilities of transportation system are discussed for promoting the urban efficiency and the citizens’ convenience by responding to urban conditions."
기계학습 방법을 이용한 레이더 신호 분류,2018,"['radar signal classification', 'jamming technique', 'machine learning', 'hidden Markov model', 'K-means']",이 논문에서는 수신된 레이더 신호로부터 추출한 파라미터 데이터에 기계학습을 적용하여 그 레이더에 대응하기 위한 재밍기법에 따라 레이더 신호를 분류하는 방법을 제안한다. 현재 군에서는 대부분 사전 조사에 의해 구축된 레이더 신호 파라미터에 대한 라이브러리를 기반으로 위협 형태에 따라 레이더 신호를 분류한다. 그러나 레이더 기술은 계속적으로 발전되고 다양해지고 있기 때문에 새로운 위협이나 기존의 라이브러리에 존재하지 않는 위협형태에 대해서 이 방법을 적용하는 경우 적절하게 신호를 분류할 수 없고 따라서 적합한 재밍기법을 선택하는데 제한이 따른다. 따라서 기존의 위협 라이브러리를 이용한 방식과 다르게 추정한 레이더 신호의 파라미터 데이터만을 이용하여 최적의 재밍기법을 선택할 수 있도록 신호를 분류하는 기술이 필요하다. 이 연구에서는 새로운 위협 신호의 형태에 대응하기 위한 방법으로 기계학습을 기반으로 한 방법을 제시한다. 제안한 방법은 기존에 축적된 라이브러리 데이터를 이용하여 은닉 마르코프(Markov) 모델과 신경망으로 구성된 분류기를 학습시킴으로써 새로운 위협 신호에 대해 적절한 재밍기법을 대응시킬 수 있도록 신호를 분류한다.,"In this paper, we propose a method to classify radar signals according to the jamming technique by applying the machine learning to parameter data extracted from received radar signals. In the present army, the radar signal is classified according to the type of threat based on the library of the radar signal parameters mostly built by the preliminary investigation. However, since radar technology is continuously evolving and diversifying, it can not properly classify signals when applying this method to new threats or threat types that do not exist in existing libraries, thus limiting the choice of appropriate jamming techniques. Therefore, it is necessary to classify the signals so that the optimal jamming technique can be selected using only the parameter data of the radar signal that is different from the method using the existing threat library. In this study, we propose a method based on machine learning to cope with new threat signal form. The method classifies the signal corresponding the new jamming method for the new threat signal by learning the classifier composed of the hidden Markov model and the neural network using the existing library data."
기계학습에 기초한 국내 학술지 논문의 자동분류에 관한 연구,2018,"['자동분류', '텍스트 범주화', '성능 요소', '학술지 논문', '로치오', '지지벡터기계', '나이브 베이즈', '단일-범주 분류', '복수-범주 분류', '기계학습', 'automatic classification', 'text categorization', 'performance factors', 'Journal articles', 'Rocchio', 'SVM (Support Vector Machine)', 'NB (Naïve Bayes)', 'single-label classification', 'multi-label classification', 'machine learning']","문헌정보학 분야의 국내 학술지 논문으로 구성된 문헌집합을 대상으로 기계학습에 기초한 자동분류의 성능에 영향을 미치는 요소들을 검토하였다. 특히, 「정보관리학회지」에 수록된 논문에 주제 범주를 자동 할당하는 분류 성능 측면에서 용어 가중치부여 기법, 학습집합 크기, 분류 알고리즘, 범주 할당 방법 등 주요 요소들의 특성을 다각적인 실험을 통해 살펴보았다. 결과적으로 분류 환경 및 문헌집합의 특성에 따라 각 요소를 적절하게 적용하는 것이 효과적이며, 보다 단순한 모델의 사용으로 상당히 좋은 수준의 성능을 도출할 수 있었다. 또한, 국내 학술지 논문의 분류는 특정 논문에 하나 이상의 범주를 할당하는 복수-범주 분류(multi-label classification)가 실제 환경에 부합한다고 할 수 있다. 따라서 이러한 환경을 고려하여 단순하고 빠른 분류 알고리즘과 소규모의 학습집합을 사용하는 최적의 분류 모델을 제안하였다.","This study examined the factors affecting the performance of automatic classification based on machine learning for domestic journal articles in the field of LIS. In particular, In view of the classification performance that assigning automatically the class labels to the articles in 「Journal of the Korean Society for Information Management」, I investigated the characteristics of the key factors(weighting schemes, training set size, classification algorithms, label assigning methods) through the diversified experiments. Consequently, It is effective to apply each element appropriately according to the classification environment and the characteristics of the document set, and a fairly good performance can be obtained by using a simpler model. In addition, the classification of domestic journals can be considered as a multi-label classification that assigns more than one category to a specific article. Therefore, I proposed an optimal classification model using simple and fast classification algorithm and small learning set considering this environment."
기계학습 기반의 신호등 검출과 형태적 정보를 이용한 인식 알고리즘,2018,"['Haar-like feature', 'SVM', 'Machine Learning', 'Traffic Light', 'Autonomous Vehicle', 'Black-box']","최근 자율 주행에 관한 다양한 연구가 진행되는 가운데 신호등 검출 및 신호 인식 알고리즘은 가장 중요한 요소 중의 하나이다. 기존에 알고리즘의 대부분은 색상을 기반으로 검출하고 인식한다. 이러한 방법은 영상의 각도, 거리, 주변 조도 환경 등에 의해 영향을 받아 신호등의 색상이 변화하여 인식률이 낮아진다는 단점이 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 Haar-like feature 및 SVM(Support Vector Machine) 기반의 신호등 검출과 제원 정보를 이용한 인식 알고리즘을 제안한다. 신호등 검출의 정확성을 향상시키기 위해서 Haar-like feature 이후에 SVM으로 검증한다. Haar-like feature와 SVM는 사전에 지도학습을 시행한다. 검출 과정 후에는 영역 분할을 통해서 신호만을 추출하여 점등 여부를 파악하고 최종적으로 인식하는 과정을 거친다. 제안한 알고리즘은 기존의 알고리즘과 달리 신호등의 형태학적 특성을 기반으로 검출하고 인식하므로 주변 환경으로부터의 영향에 강인하다는 장점이 있다. 블랙박스 영상으로 실험한 결과 기존의 색상 기반 알고리즘보다 신호의 인식률이 높았다.","The problem of traffic light detection and recognition has recently become one of the most important topics in various researches on autonomous driving. Most algorithms are based on colors to detect and recognize traffic light signals. These methods have disadvantage in that the recognition rate is lowered due to the change of the color of the traffic light, the influence of the angle, distance, and surrounding illumination environment of the image. In this paper, we propose machine learning based detection and recognition algorithm using shape information to solve these problems. Unlike the existing algorithms, the proposed algorithm detects and recognizes the traffic signals based on the morphological characteristics of the traffic lights, which is advantageous in that it is robust against the influence from the surrounding environments. Experimental results show that the recognition rate of the signal is higher than those of other color-based algorithms."
학습효과를 고려한 인간 기계 직렬체계 신뢰도와 모수추정,2018,"['human-machine system', 'serial system', 'non-homogeneous Poisson Process', 'parameter estimation.']",,"Human-machine serial systems must be normal in both systems. Though the failure of machine is irreducible by itself, the human errors are of recurring type. When the human performance is described quantitatively, non-homogeneous Poisson Process model of human errors can be developed. And the model parameters can be estimated by maximum likelihood estimation and numerical analysis method. System reliability is obtained by multiplying machine reliability by human reliability."
기계학습을 통한 예측 DGPS 항법 알고리즘,2018,"['GPS', 'DGPS', 'Machine learning', 'Navigation', 'Nonlinear regression.']","DGPS (differential GPS) 방식의 위치해 계산 방식은 기준국 수신기와 동적 수신기와의 의사거리 보정정보 (PRC; pseudo-range correction) 실시간 통신을 통해서 위치해를 계산하는 방식을 말한다. 실제 동적으로 움직이는 수신기에서는 기준국 수신기와의 통신이 단절되어 PRC 실시간 통신이 단절되는 상황이 발생한다. 논문에서는 DGPS 방식의 위치해 계산 방식에서 PRC 를 받는 실시간 상황 중간에서 수신기에 의사거리 보정 정보전송이 끊긴 상황을 가정하여, 수신기에서 기존에 수신했던 PRC 정보를 사용하여 가상의 PRC 모델을 기계학습 알고리즘을 통해 실시간 생성하는 predict DGPS를 제안한다. predict DGPS 방식을 검증하기 위해 고정되어있는 기준국의 수신기에서 실제 PRC와 본 논문에서 제안한 가상의 PRC를 적용하여 위치해를 비교, 분석하였다. 또한 실제 도로에서 PRC 통신이 단절된 시나리오를 가정하여, predict DGPS 방식을 적용한 위치해 계산 방식이 기존 방식의 위치해 계산과 비교하여 향상된 위치해를 보여 줄수 있음을 보였다.","Differential GPS (DGPS) is known as a positioning method using pseudo range correction (PRC) which is communicating between a refence receiver and moving receivers. In real world, a moving receiver loses communication with the reference receiver, resulting in loss of PRC real-time communication. In this paper, we assume that the transmission of the pseudo range correction is interrupted in the middle of real-time positioning situations, in which calibration information is received in the DGPS method. Under the disconnected communication, we propose ‘predict DGPS’ that real-time virtual PRC model which is modeled by a machine learning algorithm with previously acquired PRC data from a reference receiver. To verify predict DGPS method, we compared and analyzed positioning solutions acquired from real PRC and the virtual PRC. In addition, we show that positioning using the DGPS prediction method on a real road can provide an improved positioning solution assuming a scenario in which PRC communication was cut off."
모아레 현상을 이용한 평면부재 변형탐지와 기계학습을 활용한 인식방법,2018,"['Moire fringe', 'Deformation detection', 'Machine Learning', 'Image classification', 'Image recognition', '모아레현상', '변형탐지', '기계학습', '이미지분류', '이미지인식']","본 연구는 모아레 현상을 이용하여 구조물의 평면부재의 변형을 탐지하는 방식을 개발하였다. 평행선형상인 기존연구와 비교하여 본 연구의 원형형상은 변형 시 고유한 무늬가 나타나 변형의 방향도 시각적으로 인지할 수 있었다. 또한 변형을 확실하고 자동으로 구분할 수 있도록 기계학습의 이미지분류를 사용하여 탐지한 결과 이미지 표면이 오염되더라도 KNN, SVM방식으로는 95%의 인식률, AlexNet과 Gogglenet Inception으로는 99%의 인식률을 보여 실 현장활용이 가능할 것으로 판단된다.","This study presents a method for detecting deformation of a structure using moire fringe. Compared with the previous study result obtained by using a parallel line shape, the circular shape showed a unique pattern at the time of deformation and the direction of deformation could be visually recognized. In addition, image classification using machine learning was applied so that deformations were clearly and automatically distinguished. Even if the image surface was contaminated, the recognition rate was 95% in KNN and SVM, and was 99% in AlexNet and GoggleNet inception, which implies that field application is possible."
기계학습을 통한 전기화재 예측모델 연구,2018,"['Data Mining', 'Electrical Fire', 'Machine Learning', 'Prediction Model', 'Spatial Data']","매년 전기화재사고에 대한 사고유형 분석, 점검 등 전기적 화재사고를 줄이기 위해 다양한 노력이 있었으나, 효율적인 의사결정지원 체계 및 기존 누적 데이터 활용방안의 미비로 효과적인 대처방안이 부재한 현황이다. 본 연구는 전기안전점검데이터, 전기화재사고정보, 건축물정보, 기상청정보 등 데이터 기반의 전기화재를 예측하는 알고리즘을 개발하고 이를 활용하여 전기화재사고를 줄이는데 목적이 있다. 본 연구에서는 한국전기안전공사, 기상청, 국토교통부, 소방본부 등 기관별로 수집된 데이터를 전처리, 융합, 분석, 모델링, 검증 과정을 거쳐 전기화재에 영향을 끼치는 요인과 예측모델을 도출하였다. 주요요인으로 절연저항 값, 습도, 풍속, 건축물 노후년수, 용적율, 건폐율, 건축물용도로 나타났고, Random forest 알고리즘을 활용한 예측모델은 74.7%의 정확도를 얻었다.","Although various efforts have been made every year to reduce electric fire accidents such as accident analysis and inspection for electric fire accidents, there is no effective countermeasure due to lack of effective decision support system and existing cumulative data utilization method. The purpose of this study is to develop an algorithm for predicting electric fire based on data such as electric safety inspection data, electric fire accident information, building information, and weather information. Through the pre-processing of collected data for each institution such as Korea Electrical Safety Corporation, Meteorological Administration, Ministry of Land, Infrastructure, and Transport, Fire Defense Headquarters, convergence, analysis, modeling, and verification process, we derive the factors influencing electric fire and develop prediction models. The results showed insulation resistance value, humidity, wind speed, building deterioration(aging), floor space ratio, building coverage ratio and building use. The accuracy of prediction model using random forest algorithm was 74.7%."
기계학습을 이용한 워게임 모델의 근접전투 전장상황 평가를 위한 전문가시스템 연구,2018,"['Close Combat', 'Cross Validation', 'Machine Learning', 'Multi-Resolution Modeling', 'War-game Simulated Logic', '근접전투', '교차타당도', '기계학습', '다중해상도모델링', '워게임 모의논리']","본 연구에서는 군사 워게임 모델의 근접전투 전장상황을 평가하는 새로운 근접전투 전문가시스템을 제안한다. 근접전투 전장상황 평가 관련 기존연구인 한국형 근접전투 전문가시스템은 좋은 모형이지만, 다양한 모형들을 통한 검증 과정이 생략되었기에 최적의 모형이라고 할 수 없다. 본 연구에서는 다양한 기계학습 모형에 대해서 교차타당도 검증을 통해서 새로운 근접전투 전문가시스템을 제안하였다. 제안하는 시스템은 기존연구 결과보다 은폐엄폐는 3.15% 높은 99.07%, 전술적기동성은 1.45% 높은 90.42%, 사격가담율은 2.63% 높은 96.87%의 정확도를 보이고 있다. 또한, 근접전투 전장상황 평가를 위해서 입력변수를 공통적으로 사용할 수 있도록 정리하여, 다양한 워게임 모델에 적용할 수 있는 여건을 마련하였다. 본 연구 결과는 해상도가 상이한 워게임 모델들의 다중해상도모델의 피해평가 일치 부분에도 활용될 것으로 기대된다.","In this study, we propose a new close combat expert system that evaluates the combat battlefield situation of war-game models. The Korean close combat expert system, which is an existing research related to the evaluation of close combat battlefield situation, is a good model, but it is not an optimal model because the verification process through various models was omitted. In this study, we propose a new close combat expert system by verifying cross validity of various machine learning models. The proposed system shows that the accuracy of concealment cover is 3.15% higher than the previous study, the accuracy of tactical mobility is 1.45% higher, and the accuracy of fire participation rate is 2.63% higher. The accuracy of each is 99.07%, 90.42%, and 96.87%. In addition, for the evaluation of close combat battlefield situation, the input variables are organized so that they can be used commonly, and the conditions applicable to various war-game models are provided. The results of this study will be expected to be applied to the close combat part of multi–resolution modeling of war-game models with different resolutions."
대규모 신경회로망 분산 GPU 기계 학습을 위한 Caffe 확장,2018,"['Parallel Programming', 'GPU Computing', 'Machine Learning', '병렬 처리', 'GPU 컴퓨팅', '기계 학습']",,"Caffe is a neural net learning software which is widely used in academic researches. The GPU memory capacity is one of the most important aspects of designing neural net architectures. For example, many object detection systems require to use less than 12GB to fit a single GPU. In this paper, we extended Caffe to allow to use more than 12GB GPU memory. To verify the effectiveness of the extended software, we executed some training experiments to determine the learning efficiency of the object detection neural net software using a PC with three GPUs."
기계학습을 활용한 데이터 기반 경찰신고건수 예측,2018,"['경찰신고', '112신고', '신고예측', '기계학습', '신경망분석', '음이항 회귀분석', 'Police Calls', 'Prediction', 'Machine Learning', 'Neural Network', 'Negative Binomial Regression']","본 연구는 기계학습의 하나인 신경망 분석과 음이항 회귀분석을 활용하여 경찰신고건수를 예측하고자 2016년 6월부터 2017년 5월까지 충남지방경찰청에 접수된 112신고 데이터를 이용하여 예측모델을 개발하였다. 모델을 개발하기 위해 경찰신고건수에 영향을 줄 수 있는 시간, 휴일, 휴일 전날, 계절, 기온, 강수량, 풍속, 관할면적, 인구, 외국인 수, 단독주택비율, 기타주택비율 변수 등을 활용하였다. 변수의 종류에 따라 몇몇은 경찰신고건수와 양의 상관관계 또는 음의 상관관계가 확인되었다. 사용된 두 개의 방법론을 비교한바, 신경망분석의 예측 결과는 예측 값과 실제 값의 상관계수 0.7702, RMSE 2.557이고, 음이항 회귀분석은 상관계수 0.7158, RMSE 2.831으로 나타났다. 신경망분석은 해석가능성은 낮지만, 음이항 회귀분석에 비해 예측력이 뛰어나다는 것이 확인되었다. 향후 경찰관서에서 본 연구의 예측모델을 기초로 하여 최적의 경찰력 배치를 할 수 있을 것으로 기대된다.",
기계학습기법을 활용한 소비자의 소매유형 선택 연구: 대형마트와 전통시장을 중심으로,2018,"['Retail Format Choice', 'Cross Shopping', 'Machine Learning', '소매유형선택', '교차쇼핑', '기계학습']",,"As competition is getting fiercer between retail formats, the strategy to prevent shoppers from churning is very important in terms of shopper relationship management. Therefore, it is necessary to develop a predictive model to consider not only retail format choice (i.e., national chains or traditional market) but also the possibility of cross-shopping derived from the partial churn. In order to predict retail format choice and degree of cross shopping, the current study used logistic regression analysis, decision tree, random forest, GBM, neural network models, which can be simultaneously used for classification model and regression model. In order for the degree of cross-shopping, the visits to the favorite retail format for each shopper and the visits to the alternative store format were used as dependent variables. The ensemble method such as random forest and boosting were the most superior model in predicting the retail format choice. Through the appropriate use of machine learning method, superior prediction is possible from the retail format choice for each shopper to the degree of the cross shopping, affecting more effective customer relationship management (CRM)."
뇌파를 이용한 목격자 기억의 평가: 기계학습의 적용,2018,"['Memory', 'Recognition', 'Electroencephalography', 'Event-related potentials', 'Machine learning', 'Cognitive neuroscience']",,"This study was conducted to investigate whether memory accuracy can be assessed by analyzing electrophysiological responses (i.e., electroencephalography [EEG]) for retrieval cues related to the witnessed scene. Specifically, we examined the different patterns of EEG signals recorded during witnessed (target) and unwitnessed (lure) stimuli using event-related potential (ERP) analysis. Moreover, using multivariate pattern analysis, we also assessed how accurately single-trial EEG signals can classify target and lure stimuli. Participants watched a staged-crime video (theft crime), and the EEG signals evoked by the objects shown in the video were analyzed (n=56). Compared to the target stimulus, the lure stimulus elicited larger negative ERPs in frontal brain regions 300 to 500 milliseconds after the retrieval cue was presented. Furthermore, the EEG signals observed 450 to 500 milliseconds after the retrieval cue was presented showed the best classification performance related to eyewitness memory, with the mean classification accuracy being 56%. These results suggest that the knowledge and techniques of cognitive neuroscience can be used to estimate eyewitness memory accuracy."
BCI에서 기계 학습을 위한 간질 뇌파 특징 선택을 통한 차원 감소 방법 분석,2018,"['뇌-컴퓨터 인터페이스. 뇌파', '기계학습', '뇌전증', 'BCI', 'EEG', 'Machine Learning', 'Epilepsy']","지금까지 뇌파(Electroencephalography - EEG)는 뇌전증 진단 및 치료를 위한 가장 중요하고 편리한 방법이었다. 그러나 뇌전증 뇌파 신호의 파형 특성은 매우 약하고 비 정지 상태이며 배경 노이즈가 강하기 때문에 식별하기가 어렵다. 이 논문에서는 간질 뇌파의 특징 선택을 통한 차원 감소를 통한 분류 방법의 효과를 분석한다. 우리는 차원 감소를 위해 주 요소 분석, 커널 요소 분석, 선형 판별 분석 방법을 사용하였다. 차원 감소 방법의 성능 분석을 위해 Support Vector Machine （SVM）, Logistic Regression (LR), K-Nearestneighbor (K-NN), Decision Tree (DR), Random Forest (RF) 분류 방법들을 사용해 평가하였다. 실험 결과에 따르면, PCA는 SVM, LR 및 K-NN에서 75% 정확도를 나타냈다. KPCA는 SVM과 K-KNN에서 85%의 성능을 보였으며 LDA는 K-NN를 이용했을 때 100 %의 정확도 보여주었다. 따라서 LDA를 이용한 차원 감소가 뇌전증 EEG 신호에 대한 최고의 분류 결과 보여주었다.","Until now, Electroencephalography (EEG) has been the most important and convenient method for the diagnosis and treatment of epilepsy. However, it is difficult to identify the wave characteristics of an epileptic EEG signals as it is very weak, non-stationary and has strong background noise. In this paper, we analyse the effect of dimensionality reduction methods on Epileptic EEG feature selection and classification. Three dimensionality reduction methods: Pincipal Component Analysis（PCA）, Kernel Principal Component Analysis (KPCA) and Linear Discriminant Analysis （LDA）were investigated. The performance of each method was evaluated using Support Vector Machine （SVM）, Logistic Regression (LR), K-Nearestneighbor (K-NN), Decision Tree (DR) and Random Forest (RF). From the experimental result, PCA recorded 75% highest accuracy in SVM, LR and K-NN. KPCA recorded 85% best performance in SVM and K-KNN while LDA achieved 100% accuracy in K-NN. Thus, LDA dimensionality reduction is found to provide the best classification result for epileptic EEG signal."
기계학습을 이용한 복숭아 경락가격 및 거래량 예측모형 비교,2018,"['복숭아', '기상', '경락가격', '기계학습', 'XGboost.', 'peach', 'weather', 'auction price', 'machine learning', 'XGboost.']","과일의 경우 다른 작물보다 날씨의 영향을 많이 받으므로, 농업인의 고부가가치 창출을 위해서는 날씨를 고려한 작물모형개발이 필요하다. 본 연구에서는 과실류 중에서 비교적 제한된 조건에서 생산되는 복숭아를 연구대상으로 선정하였으며, 옥답 4.0에서 제공하는 2015년부터 2017년까지 대구에서 거래된 복숭아자료를 사용하였다. 분석에 사용되는 기상자료는 재배면적에 대한 가중치를 부여하여 생성하였으며, 1일 전부터 7일 전까지 날씨자료 중 상관성이 높은 변수를 사용하였다. 분석 방법으로는 기계학습법에 해당하는 랜덤포레스트와 그래디언트부스팅(gradient boosting machine), XGboost을 사용하였다. 분석결과, XGboost의 성능이 가장 우수하게 나타났으며, 경락가격 예측은 비교적 잘 예측할 수 있었지만, 거래량 예측의 정확성은 그리 높지 않았다. 복숭아 거래량 예측에 영향을 미치는 상위 3개의 기상변수로는 최저온도, 평균최대온도, 강수량으로 나타났다.","It is known that fruit is more affected by the weather than other crops. Therefore, in order to create high value for farmers, it is necessary to develop a wholesale price model considering the weather. Peaches produced under relatively limited conditions were chosen as subjects of study. The data were collected from 2015 to 2017 provided by okdab 4.0. The meteorological data used for the analysis were generated by weighting the cultivation area and the variables with high correlation among the weather data were selected from the day before to 7 days before. Randomforest, gradient boosting machine, and XGboost were used for the analysis. As a result of analysis, XGboost showed the best performance in the sense of RMSE and correlation, and price prediction was comparatively well predicted, but the accuracy of the trading volume prediction was not so good enough. The top three weather variables affecting to the peach were minimum temperature, average maximum temperature, and precipitation."
<수학기초>와 <기계학습> 교과 사례를 통해 살펴 본 K-MOOC의 전략적인 운영 방법 탐색,2018,"['K-MOOC', 'Subject Development', 'Long-life Education', 'Knowledge map', 'Learner', 'Learning Motivate', 'Curriculum', 'Teaching Method', 'Team Teaching', 'K-MOOC', '교과 개발', '평생교육', '지식 지도', '학습자', '학습동기', '교육과정', '교수법', '팀티칭']","본 연구의 목적은 K-MOOC의 교과 운영 사례를 통해, K-MOOC 교육의 개선 방안을 모색하는 것이다. 교육환경이 전통적인 양식에서 온라인 기반으로 바뀌었지만, 여전히 교육과 관련 해서 중요한 주체는 학습자이며, 학습자 개인의 학습동기에 있다. 과학기술의 측면에서 보면, K-MOOC의 학습환경은 디지털 환경에서 학습자가 원하면 언제·어디서나 접속해서 학습을 할 수 있다.고려대학교 공과대학 K-MOOC 운영팀이 수학기초와 기계학습 교과를 통해 얻은 K-MOOC 운영의 새로운 전략은 다음과 같다. 첫째, 형식적인 지형도로, 강좌에 대한 지속적인 품질 보증이 필요하다. 둘째, 내용적인 지형도로, 학습자들과 교수자들 및 운영자들 사이에 바람직한 소통이 필요하다. 비록 온라인 환경에 학습자들과 대면하기는 어렵지만, 온라인에서 학습자들과 소통할 수 있는 커뮤니티의 활성화가 필요하다. 셋째, 통합적인 지형도로 K-MOOC이 운영하는 교과목의 내용이 학습자들의 현실적인 삶과 연계성을 제고시킬 수 있도록 해야 한다. 이를 위해서는 K-MOOC에 적합한 교육과정 구축과 적극적인 교수법에 대한 모색이 필요하다.","The purpose of this study is to find ways to improve the K-MOOC education through two case studies of K-MOOC. Although the educational environment has changed from the traditional form to the online one, the critical subjects are still the learners and are motivated by their own learning, not only by advanced technologies. In terms of current technology, K-MOOC’s learning environment can be accessed by students whenever and wherever they want, provided that they are in a digital environment.The MOOC production & operation team of Korea University’s College of Engineering produced and operated two courses—the “Mathematical Foundation for Data Science” and “Machine Learning for Data Science”—over the course of seven months, from July 2017 to January 2018. The new strategies of K-MOOC operation are as follows. First, it is a formal topographical map, requiring continuous quality assurance for the course. Second, with a topographic map, good communication is needed between learners, teachers, and operators. Although it is difficult to meet with others in online environments, it is necessary to activate communities that can communicate with learners online. Third, the contents of the curriculum operated by K-MOOC should be linked with the real life of the learners through the integrated topographic map. In order to do this, it is necessary to find a suitable curriculum for K-MOOC and to look for active pedagogy."
2D 이미지에서 기계학습 기법을 활용한 특징점 찾기 및 신체 치수 추출,2018,"['clothing automation', '2D image', 'body measurement', 'softmax regression']","사진이미지에서 신체 치수 추출은 의류 제작의 자동화를 위한 기초 기술이다. 본 연구는 전면과 측면 사진을 입력받아 신체의 12가지 특징점을 찾고, 실험적으로 의류 제작에 필요한 6가지 기본 치수를 계산하는 방법을 제시하였다. 기존의 방법들이 이미지의 윤곽선을 만들고 윤곽선을 이용하여 특징점을 찾아내는 방법과는 달리, 이미지의 부분을 잘라내어 소프트맥스 회귀 기계학습으로 특징점을 찾은 다음, 실험을 통하여 특징점의 직선 및 곡선 거리를 계산하는 방법을 찾아내었다. 길이 계산 결과 소매길이, 가슴둘레의 오차는 2% 이내로 계산되었으며 진동, 앞장, 어깨길이는 오차 비율이 높았으나 길이 값으로는 2cm 이내로 계산되었다. 제안된 방법은 기계학습을 이용하여 특징점 위치 정확도가 높고, 기존 방법에 비하여 사진 획득시 제약 사항을 줄인 장점이 있다.","Body measurements from 2D images is the basic technique for clothing automation. We compute 12 feature points of human body from the front and side images, and experimentally calculate 6 basic sizes for clothings. Existing methods make contour from 2D images and detects feature points, but in our method we find feature points using softmax regression machine learning algorithm from the sub images, and experimentally estimates sizes by calculating length of lines and circumferences of curves using the feature points. As for the sleeve and chest length, the error is within 2%, for armhole, front and shoulder length, it have high error rate but within 2cm error bounds. The proposed method helps find more correct feature points and has the advantage of reducing the constraint on image acquisition compared to the existing methods."
Building an Analytical Platform of Big Data for Quality Inspection in the Dairy Industry,2018,"['Big Data', 'Quality Inspection', 'Dairy Industry', 'Platform Building', 'Process Control', '빅데이터', '품질검사', '유제품 산업', '플랫폼 개발', '공정관리']",,"As one of the processes in the manufacturing industry, quality inspection inspects the intermediate products or final products to separate the good-quality goods that meet the quality management standard and the defective goods that do not. The manual inspection of quality in a mass production system may result in low consistency and efficiency. Therefore, the quality inspection of mass-produced products involves automatic checking and classifying by the machines in many processes. Although there are many preceding studies on improving or optimizing the process using the data generated in the production process, there have been many constraints with regard to actual implementation due to the technical limitations of processing a large volume of data in real time. The recent research studies on big data have improved the data processing technology and enabled collecting, processing, and analyzing process data in real time. This paper aims to propose the process and details of applying big data for quality inspection and examine the applicability of the proposed method to the dairy industry. We review the previous studies and propose a big data analysis procedure that is applicable to the manufacturing sector. To assess the feasibility of the proposed method, we applied two methods to one of the quality inspection processes in the dairy industry: convolutional neural network and random forest. We collected, processed, and analyzed the images of caps and straws in real time, and then determined whether the products were defective or not. The result confirmed that there was a drastic increase in classification accuracy compared to the quality inspection performed in the past."
허혈성 심장질환 진단을 위한 기계 학습 알고리즘 비교 연구,2018,"['인공지능', '의료공학', '데이터 마이닝', '허혈성 심장질환', '전문가 시스템', 'artificial intelligence', 'medical engineering', 'data mining', 'ischemic heart disease', 'expert system']","최근, 인공지능에 대한 연구가 활발히 진행되고 있고, 인공지능 기술을 통한 정확하고 효율적인 의사결정이 가능해지고 있다. 또한, 점차 의료 지식 및 관련 데이터의 축적이 가속화되고 있으며, 인공지능 기술을 통한 질환 진단 및 처방에 대한 연구도 활발히 진행되고 있다. 본 연구에서는 대표적인 심혈관 질환인 허혈성 심장질환을 연구 도메인으로 설정하고, 해당 질환의 진단을 위한 의료 전문가 시스템 내에서 활용이 가능한 알고리즘과 효율적인 접근 방식을 비교 및 분석하여 제안한다. 본 연구의 궁극적 목표는 기존 환자의 초진기록 데이터를 바탕으로 의료 전문가 및 의사를 보조하는 것으로, 허혈성 심장질환에 대한 인과 관계 설명에 도움을 주고, 불필요한 관련 검사를 최소화한다는 데에 그 의미가 있다. 또한, 실험 데이터를 구성하여 의료 전문가 및 의사는 학습용 모델로 활용하면서, 이를 통해 경험과 지식을 효율적으로 극대화할 수 있다.","In recent years, studies on artificial intelligence have been actively conducted, and artificial intelligence technology supports accurate and efficient decision-making for mankind. Also, the accumulation of medical knowledge and related data is accelerating, and studies on diagnosis of diseases through artificial intelligence technology are being carried out briskly. In this study, I chose a representative cardiovascular disease, specifically ischemic heart disease, as a research domain, and analyzed the available algorithms comparing effective approaches in the medical expert system for diagnosis of the disease. Concretely, the purpose of the study is to assist medical experts and physicians based on the initial patient record data, help them to explain the cause of ischemic heart disease, and minimize unnecessary related tests. In addition, the experimental data can be configured so that medical professionals can use them as learning models, thereby maximizing their experience and knowledge efficiently."
착용형 양안 시선추적기와 기계학습을 이용한 시선 초점 거리 추정방법 평가,2018,"['시선 깊이', '3D 시선', '눈 추적', '가상현실', '증강현실', 'Gaze Depth', '3D gaze', 'Eye tracking', 'Virtual reality', 'Augmented reality']","본 논문은 가상현실 및 증강현실을 위해 양안식 눈추적기 기반의 시선 깊이 추정 기법을 제안한다. 제안한 방법은 먼저 양안식 눈추적기로부터 안구 및 시선과 관련된 다양한 정보를 획득한다. 이후 획득된 정보를 바탕으로 다층퍼셉트론 알고리즘 기반의 시선 추적과 인식 모델을 통해 눈 시선 깊이를 추정한다. 제안한 방법을 검증하기 위해 13명의 참여자를 모집하고 개인별 시선 추적과 범용 시선 추적에 대한 성능을 분석하였다. 실험결과 개인별 모델에서는 90.1%, 그리고 전체 사용자를 대상으로 한 범용 모델에서는 89.7%의 정확도를 보였다.","In this paper, we propose a gaze depth estimation method based on a binocular eye tracker for virtual reality and augmented reality applications. The proposed gaze depth estimation method collects a wide range information of each eye from the eye tracker such as the pupil center, gaze direction, inter pupil distance. It then builds gaze estimation models using Multilayer perceptron which infers gaze depth with respect to the eye tracking information. Finally, we evaluated the gaze depth estimation method with 13 participants in two ways: the performance based on their individual models and the performance based on the generalized model. Through the evaluation, we found that the proposed estimation method recognized gaze depth with 90.1% accuracy for 13 individual participants and with 89.7% accuracy for including all participants."
딥러닝 기반의 다층 퍼셉트론을 이용한 심장병 예측 연구,2018,"['Deep learning', 'Heart disease prediction', 'Multilayer perceptron', 'Back propagation', 'TensorFlow']",,"Deep Learning, an advanced technology for machine learning, is currently being applied to various industrial fields and is being actively applied and developed in the fields of finance, e-commerce, and Internet of Thing, which require prediction. In particular, this study will be applied to the prediction of heart disease in the medical field, and it will provide the advantage of early detection of heart disease or saving medical treatment cost such as angiography for non-heart disease patient. To apply the Multilayer Perceptron machine learning technique for Deep Learning, 2 Hidden Layers and 10 Perceptons can be constructed to improve learning accuracy. By using Back Propagation during learning, it is reversed from the Output Layer to the Hidden Layer so as to reduce the error. The error is reduced by using ReLU or Sigmoid function, and the generated prediction model optimizes the model through the Adam optimization function. In a case study, heart disease data is learned using heart disease diagnosis and presence or absence of heart disease provided by the Machine Learning & Artificial Intelligence System Center at the University of California, Irvine. The Deep Learning module is developed using a Python-based TensorFlow and validated using randomly extracted data samples from heart disease data after learning."
얼굴 인식률 향상을 위한 멀티 블록 방식의딥러닝 구조에 관한 연구,2018,"['multi-block method', 'image processing', 'machine learning', 'deep learning', 'improved face recognition', 'reduced learning time']","본 논문에서는 얼굴 인식률 향상을 위한 멀티 블록 방식의 딥러닝 구조를 제안한다. 제안하는 딥러닝의 인식 구조는 입력된 이미지의 멀티 블록화, 특징 수치 분석을 통한 멀티 블록 선정, 선정된 멀티 블록의 딥러닝 수행 등의 3가지 과정으로 구성된다. 첫 번째로 입력된 이미지의 멀티 블록화는 입력된 이미지를 4등분하여 멀티 블록화 시킨다. 두 번째로 특징 수치분석을 통한 멀티 블록 선정에서는 4등분된 멀티 블록들의 특징 수치를 확인하고 특징이 많이 부각되는 블록만을 선정하여 얼굴 인식에 방해가 되는 요소를 사전에 제거한 블록들을 선정한다. 세 번째로 선정된 멀티 블록으로 딥러닝 수행은 선정된멀티 블록 부위가 학습되어진 딥러닝 모델에 인식을 수행하여 특징 수치가 높은 효율적인 블록으로 얼굴 인식의 결과를 도출한다. 제안된 딥러닝 구조의 성능을 평가하기 위하여 CAS-PEAL 얼굴 데이터베이스를 사용하여 실험 하였다. 실험 결과,제안하는 멀티 블록 방식의 딥러닝 구조가 기존의 딥러닝 구조보다 평균 약 2.3% 향상된 얼굴 인식률을 나타내어 그 효용성이 입증됨을 확인하였다.","In this paper, we propose a multi-block deep learning structure for improving face recognition rate. The recognitionstructure of the proposed deep learning consists of three steps: multi-blocking of the input image, multi-block selectionby facial feature numerical analysis, and perform deep learning of the selected multi-block. First, the input image isdivided into 4 blocks by multi-block. Secondly, in the multi-block selection by feature analysis, the feature values of thequadruple multi-blocks are checked, and only the blocks with many features are selected. The third step is to performdeep learning with the selected multi-block, and the result is obtained as an efficient block with high feature value byperforming recognition on the deep learning model in which the selected multi-block part is learned. To evaluate theperformance of the proposed deep learning structure, we used CAS-PEAL face database. Experimental results show thatthe proposed multi-block deep learning structure shows 2.3% higher face recognition rate than the existing deep learningstructure."
인간과 기계의 협업 -기계미학의 쟁점들-,2018,"['Artificial Intelligence', 'Program', 'Author', 'Creativity', 'Creative Machine', 'Imitation Machine', '인공지능', '프로그램', '저자', '창의성', '창작기계', '모방기계']",,"This study explores artificial intelligence and creation, in terms of machine aesthetics. Artificial intelligence is evolving through machine learning, and producing artworks on its own. In fact, current artificial intelligence is widelyconsidered an “imitation machine” that learns and imitates past works, rather than being truly “creative machines.” Can such “imitation machine” works be considered artistic acts? According to the current art paradigm, only those who produce “creative” works are regarded as “authors.” An artwork is a product of creativity, not imitation. Whether customary or legal, imitations inherently oppose creation; they are not authentic works.Artificial intelligence produces artworks by algorithms and programs, and programs can be designed to produce something unpredictable. In other words, artificial intelligence can produce “creative” output. Furthermore, it is impossible to create something fundamentally new, given that all creative human activities involve the process of writing their own rules based on acquired knowledge. That is, “creativity” is not only a contradiction in itself but also a mythical concept.According to the current art paradigm, only humans can be considered “creative” authors. However, the concept of authorship is gradually expanding. The notion that artificial intelligence or programmers cannot be creators is challenged. The significance of the problem is less about the “subject” of creation than its “result.” A real program can be “post-gramme” rather than “pro-gramme.” We should consider the collaboration of humans and machines in the machine age. Humans have imitated machines, and machines have imitated humans. In the process, humans have extended beyond their corporealboundaries . Technology has always been the human’s extension. In that sense, it is an opportune time to revisit Foucault's question about authorship, and ask: “Qu’importe qui cree?”"
딥러닝 기반 앙상블을 이용한 유방암 분류,2018,"['Breast cancer', 'Classification', 'Deep learning', 'Ensemble', 'Performance evaluation']",,"Objectives: We propose a deep learning-based ensemble for improving breast cancer classification and compare it with existing six models including deep neural network on two UCI data. Methods: We propose a deep learning-based stacking ensemble method. We first applied five classifications methods individually, which were k-nearest neighbor, decision trees, support vector machines, discriminant analysis, and logistic regression analysis and then adopt a deep learning to the predictions derived from these methods after using 5-fold cross validation technique. We compared the proposed deep learning-based ensemble method with these methods for two UCI data through classification accuracy, ROC curves and c-statistics. Results: Experimental results for two UCI data showed that the proposed deep learning-based ensemble outperformed single k-nearest neighbor, decision trees, support vector machines discriminant analysis, and logistic regression analysis as well as deep neural network in terms of various performance measures. Conclusions: We proposed deep learning-based ensemble for improving breast cancer classification. The deep learning-based ensemble outperformed existing single models for all applications in terms of various performance measures."
개인적 지식기반의 계층적 학습-추론 시스템의 설계,2018,"['학습추론 시스템', '지식스레드 추출', '계층지식구조', '개인적신뢰반영계층', '지식네트워크']","최근들어 기계중심의 기술에서 점차 인간 중심의 기술로 변화되어가려는 시도가 많이 이루어지고 있다. 지능 시스템 연구에 있어서도 과거의 단순 학습과 추론 방식에서 지금은 보다 인간과 흡사한 처리, 즉 인간다움을 묘사하는 기능을 구현하려는 방향으로 나아가고 있다. 본 논문에서는 인간 두뇌의 계층성을 모방한 개인적 지식 기반의 학습과 추론 지식처리 시스템 HLRS(Hierarchical Learning Reasoning System)을 제안하고자 한다. HRLS는 학습기능을 가지는 학습계층과 심볼릭 추론 기능을 가지는 추론계층, 개인적인 신뢰네트워크인 개인적 신뢰 반영 계층이 유기적으로 결합되어 학습과 추론 및 의사결정 기능을 수행하도록 설계되었다. 특히 개인적인 신뢰정도가 추론과 의사 결정에 주는 영항, 즉 지식스레드 추출 결과의 변화를 시뮬레이션 하였다.","In recent years there have been many efforts for changing from machine oriented technology to human oriented technology gradually. In the research of Intelligent system, the previous simple learning and reasoning methods are also changing to human like processing, namely the direction of implementing humanity. In this paper, adopting the hierarchy of Human brain Personal Knowledge based Learning and Reasoning Knowledge processing system(HLRS: Hierarchical Learning Reasoning System) is proposed. HLRS is designed for processing the function of Learning, Reasoning and Decision Making with combined hierachical structure which has Learning Layer, symbolic inference based Knowledge Network Layer and Personal Belief Mirror Layer."
1970년대 대중소설의 ‘저지전략’과 자본주의적 젠더 시뮬라크르 - 박범신의 『죽음보다 깊은 잠 (1979)을 중심으로,2018,"['1970년대 대중소설', '박범신', '죽음보다 깊은 잠', '저지전략', '이미지', '시뮬라크르', '자가증식', '멜랑콜리', 'Popular novel in the 1970s', 'Park bum shin', 'A deeper sleep than death', 'Deterrence Machine', 'Image', 'Simulacres', 'Self-replicating', 'Melancholy']","본 연구는 보드리야르의 핵심 명제를 중심으로 1970년대가 끝나갈 무렵베스트셀러 오른 박범신의 『죽음보다 깊은 잠』을 분석하였다. 1970년대대중소설은 매력적인 몸과 천사 같은 영혼을 소유하였고 남자들에게 헌신적인 사랑과 성적 쾌감을 제공하면서도 어떠한 도덕적 책임도 요구하지 않는, 동화적 이미지, 성처녀 시뮬라크르가 리얼리티로 행사하였다.『죽음보다 깊은 잠』의 여주인공 ‘정다희’는 ‘경아’나 ‘이화’를 모델 이미지로 갖는 시뮬라크르이며, 1970년대 대중소설이 유사한 젠더 시뮬라크르를 재현하는 것은 시뮬라크르의 자가 증식 과정이자 ‘이미지-유행’의 과정으로 비유될 수 있다. 결국 다희의 삶은 기존의 경아와 이화의 시뮬라크르에 욕망과 환상의 비도덕성과 이기심을 강화하여 새로운 모델을 자가증식한 양상을 보인다.이 작품의 실질적인 남성 주인공인 ‘영훈’은 처음엔 거부했지만 새로이눈뜨게 된 사랑으로 통과의례를 치르게 되는데, 연애 서사와 함께 ‘이니시에이션’에 집중한다면 이 소설은 산업화 시기의 남성 성장 서사로 파악할수 있다. 이는 자동기억처럼 『별들의 고향』의 ‘문오’의 시뮬라크르이다.1970년대 대중연애소설의 낭만성, 동화성, 순수성은 순수하지 못한 현실의 ‘블라인드’ 역할을 하였다. 뒷걸음질 치는 정치와 앞으로 뛰어가는경제 사이에서 대중문화의 급팽창은 어둠과 얼음의 이미지를 반성과 순수로 은폐하는 ‘저지기계’였던 것이다. 순수하지 못한 사회는 순수한 연애를 서사화함으로써 야만의 현실로부터 동떨어지게 하고 아무리 폭력적현실도 매일 정화되는 육체처럼 깨끗해질 수 있다는 손쉬운 환상을 심어준다. 이럴 때 순수한 연애는 과대평가 되고 순수하지 못한 사회는 과소평가된다. 이러한 사회는 자유로운 사회인 동시에 폭력적 사회인 것이다.","This study analyzes Park Bum-shin's A Deeper Sleep than Death, which became a bestseller at the end of the 1970s, focusing on the core subject of Jean Baudrillard. In the 1970s, popular novels owned an attractive body and angelic soul and served men with devoted love and sexual pleasure, but did not require any moral responsibility, a fairy tale image, and a Virgin simulacra played as reality. Jung Da-hee, the heroine of A Deeper Sleep than Death, is a simulacra with Gyeonga or Ehwa as model images. The 1970s popular novels show similar gender simulacra.This can be likened to the process of self-propagation and ‘image-fashion’ of the simulacra. In the end, Dahee’s life shows the self-replication of a new model by strengthening immorality and the selfishness of desire and fantasy in the simulacra of Gyeonga and Ewha. The main character of this work, Young-hoon, is initially rejected, but the newly learned love rites his passage.Concentrating on ‘initiation’ in the romance narrative, this novel can be understood as a male growth narrative of the industrialization period. This is a simulacra of Muno in The Hometown of Stars like automatic memory. In the 1970s, the romanticity, assimilation and purity of popular romantic novels played the role of the blind to a reality that was not pure. The rapid expansion of popular culture was the deterrence machine, covering up images of darkness and ice with reflection and purity. A bad society distorts the reality of barbarism by pre-writing pure love. No matter how violent the reality is, it creates an easy fantasy that one can become as clean as the body that is purified every day. In this case, pure love is overestimated and a society that is not pure is underestimated. These societies are both free and violent."
실시간 데이터 분석의 성능개선을 위한 적응형 학습 모델연구,2018,"['Adaptive Learning', 'Machine Learning', 'Nearest Neighbor Algorithm', 'Stream Analytics', 'Artificial Intelligence', '적응형 학습', '기계 학습', '최근접 이웃 알고리즘', '실시간 분석', '인공지능']","최근 인공지능을 구현하기 위한 기술들이 보편화되면서 특히, 기계 학습이 폭넓게 사용되고 있다. 기계 학습은 대량의 데이터를 수집하고 일괄적으로 처리하며 최종 조치를 취할 수 있는 통찰력을 제공하나, 작업의 효과가 즉시 학습 과정에통합되지는 않는다. 본 연구에서는 비즈니스의 큰 이슈로서 실시간 데이터 분석의 성능을 개선하기 위한 적응형 학습 모델을 제안하였다. 적응형 학습은 데이터세트의 복잡성에 적응하여 앙상블을 생성하고 알고리즘은 샘플링 할 최적의 데이터포인트를 결정하는데 필요한 데이터를 사용한다. 6개의 표준 데이터세트를 대상으로 한 실험에서 적응형 학습 모델은 학습시간과 정확도에서 분류를 위한 단순 기계 학습 모델보다 성능이 우수하였다. 특히 서포트 벡터 머신은 모든 앙상블의 후단에서 우수한 성능을 보였다. 적응형 학습 모델은 시간이 지남에 따라 다양한 매개변수들의 변화에 대한 추론을 적응적으로업데이트가 필요한 문제에 폭넓게 적용될 수 있을 것으로 기대한다.","Recently, as technologies for realizing artificial intelligence have become more common, machine learning is widely used. Machine learning provides insight into collecting large amounts of data, batch processing, and taking final action, but the effects of the work are not immediately integrated into the learning process. In this paper proposed an adaptive learning model to improve the performance of real-time stream analysis as a big business issue.Adaptive learning generates the ensemble by adapting to the complexity of the data set, and the algorithm uses the data needed to determine the optimal data point to sample. In an experiment for six standard data sets, the adaptive learning model outperformed the simple machine learning model for classification at the learning time and accuracy. In particular, the support vector machine showed excellent performance at the end of all ensembles. Adaptive learning is expected to be applicable to a wide range of problems that need to be adaptively updated in the inference of changes in various parameters over time."
기지국 상태 조정을 위한 강화 학습 기법 분석,2018,"['기계 학습', '강화 학습', '전이 학습', 'Actor-Critic 기법', '기지국 상태 조정', 'machine learning', 'reinforcement learning', 'transfer learning', 'actor-critic method', 'knowledge transfer']","강화 학습은 변화하는 환경에서의 최적의 보상을 얻을 수 있는 행동을 결정하기 위한 정책을 얻는 기계 학습 기법이다. 하지만 기존에 연구되어 온 강화 학습은 불확실하고 연속적인 실제 환경에서 최적의 행동을 얻기 위해 발생되는 높은 계산 복잡도 문제와 학습된 결과를 얻기 위해서는 많은 시간이 소요 된다는 문제점을 가지고 있다. 앞에서 언급한 문제를 해결하기 위해, 높은 계산 복잡도 문제를 해결을 위해서는 강화 학습을 구성하는 가치 함수와 정책을 독립적으로 구성하는 AC(actor-critic) 기법이 제안되었다. 그리고 빠른 학습 결과를 얻기 위해 기 학습된 지식을 새로운 환경에서 이용하여 기존 학습보다 빠르게 학습 결과를 얻을 수 있는 전이 학습(transfer learning) 기법이 제안되었다. 본 논문에서는 기존에 연구되어 왔던 기계 학습 기법의 향상 기법인 AC 기법과 전이 학습 기법에 대해 소개하고, 이를 무선 액세스 네트워크 환경에서 기지국 상태 조정을 위해 적용되고 있는 사례를 소개한다.","Reinforcement learning is a machine learning method which aims to determine a policy to get optimal actions in dynamic and stochastic environments. But reinforcement learning has high computational complexity and needs a lot of time to get solution, so it is not easily applicable to uncertain and continuous environments. To tackle the complexity problem, AC (actor-critic) method is used and it separates an action-value function into a value function and an action decision policy. Also, in transfer learning method, the knowledge constructed in one environment is adapted to another environment, so it reduces the time to learn in a reinforcement learning method. In this paper, we present AC method and transfer learning method to solve the problem of a reinforcement learning method. Finally, we analyze the case study which a transfer learning method is used to solve  BS(base station) switching problem in wireless access networks."
효과적인 입력변수 패턴 학습을 위한 시계열 그래프 기반합성곱 신경망 모형: 주식시장 예측에의 응용,2018,"['기술적 분석가', '딥러닝', '분류기', '주가지수 등락 예측', '합성곱 신경망', 'Classifier', 'Convolutional Neural Network', 'Deep Learning', 'Stock Price Fluctuation Prediction', 'Technical Analyst']","지난 10여 년간 딥러닝(Deep Learning)은 다양한 기계학습 알고리즘 중에서 많은 주목을 받아 왔다. 특히 이미지를 인식하고 분류하는데 효과적인 알고리즘으로 알려져 있는 합성곱 신경망(Convolutional Neural Network, CNN)은 여러 분야의 분류 및 예측 문제에 널리 응용되고 있다. 본 연구에서는 기계학습 연구에서 가장 어려운예측 문제 중 하나인 주식시장 예측에 합성곱 신경망을 적용하고자 한다. 구체적으로 본 연구에서는 그래프를입력값으로 사용하여 주식시장의 방향(상승 또는 하락)을 예측하는 이진분류기로써 합성곱 신경망을 적용하였다. 이는 그래프를 보고 주가지수가 오를 것인지 내릴 것인지에 대해 경향을 예측하는 이른바 기술적 분석가를모방하는 기계학습 알고리즘을 개발하는 과제라 할 수 있다. 본 연구는 크게 다음의 네 단계로 수행된다. 첫 번째 단계에서는 데이터 세트를 5일 단위로 나눈다. 두 번째 단계에서는 5일 단위로 나눈 데이터에 대하여 그래프를 만든다. 세 번째 단계에서는 이전 단계에서 생성된 그래프를 사용하여 학습용과 검증용 데이터 세트를 나누고 합성곱 신경망 분류기를 학습시킨다. 네 번째 단계에서는 검증용 데이터 세트를 사용하여 다른 분류 모형들과 성과를 비교한다. 제안한 모델의 유효성을 검증하기 위해 2009년 1월부터 2017년 2월까지의 약 8년간의KOSPI200 데이터 2,026건의 실험 데이터를 사용하였다. 실험 데이터 세트는 CCI, 모멘텀, ROC 등 한국 주식시장에서 사용하는 대표적인 기술지표 12개로 구성되었다. 결과적으로 실험 데이터 세트에 합성곱 신경망 알고리즘을 적용하였을 때 로지스틱회귀모형, 단일계층신경망, SVM과 비교하여 제안모형인 CNN이 통계적으로 유의한 수준의 예측 정확도를 나타냈다.","Over the past decade, deep learning has been in spotlight among various machine learning algorithms. In particular, CNN(Convolutional Neural Network), which is known as the effective solution for recognizing and classifying images or voices, has been popularly applied to classification and prediction problems. In this study, we investigate the way to apply CNN in business problem solving. Specifically, this study propose to apply CNN to stock market prediction, one of the most challenging tasks in the machine learning research. As mentioned, CNN has strength in interpreting images. Thus, the model proposed in this study adopts CNN as the binary classifier that predicts stock market direction (upward or downward) by using time series graphs as its inputs. That is, our proposal is to build a machine learning algorithm that mimics an experts called 'technical analysts' who examine the graph of past price movement, and predict future financial price movements.Our proposed model named 'CNN-FG(Convolutional Neural Network using Fluctuation Graph)' consists of five steps. In the first step, it divides the dataset into the intervals of 5 days. And then, it creates time series graphs for the divided dataset in step 2. The size of the image in which the graph is drawn is 40 (pixels) × 40 (pixels), and the graph of each independent variable was drawn using different colors.In step 3, the model converts the images into the matrices. Each image is converted into the combination of three matrices in order to express the value of the color using R(red), G(green), and B(blue) scale. In the next step, it splits the dataset of the graph images into training and validation datasets. We used 80% of the total dataset as the training dataset, and the remaining 20% as the validation dataset. And then, CNN classifiers are trained using the images of training dataset in the final step. Regarding the parameters of CNN-FG, we adopted two convolution filters (5 × 5 × 6 and 5 × 5 × 9) in the convolution layer. In the pooling layer, 2 × 2 max pooling filter was used. The numbers of the nodes in two hidden layers were set to, respectively, 900 and 32, and the number of the nodes in the output layer was set to 2(one is for the prediction of upward trend, and the other one is for downward trend). Activation functions for the convolution layer and the hidden layer were set to ReLU(Rectified Linear Unit), and one for the output layer set to Softmax function.To validate our model - CNN-FG, we applied it to the prediction of KOSPI200 for 2,026 days in eight years (from 2009 to 2016). To match the proportions of the two groups in the independent variable (i.e. tomorrow's stock market movement), we selected 1,950 samples by applying random sampling. Finally, we built the training dataset using 80% of the total dataset (1,560 samples), and the validation dataset using 20% (390 samples). The dependent variables of the experimental dataset included twelve technical indicators popularly been used in the previous studies. They include Stochastic %K, Stochastic %D, Momentum, ROC(rate of change), LW %R(Larry William's %R), A/D oscillator(accumulation/distribution oscillator), OSCP(price oscillator), CCI(commodity channel index), and so on. To confirm the superiority of CNN-FG, we compared its prediction accuracy with the ones of other classification models. Experimental results showed that CNN-FG outperforms LOGIT(logistic regression), ANN(artificial neural network), and SVM(support vector machine) with the statistical significance. These empirical results imply that converting time series business data into graphs and building CNN-based classification models using these graphs can be effective from the perspective of prediction accuracy. Thus, this paper sheds a light on how to apply deep learning techniques to the domain of business problem solving."
준 지도학습 알고리즘을 이용한 뇌파 감정 분석을 위한 학습데이터 선택 방법에 관한 연구,2018,"['DEAP', 'EEG', 'Emotion Analysis', 'FFT', 'Machine Learning']",,"Recently, machine learning algorithms based on artificial neural networks started to be used widely as classifiers in the field of EEG research for emotion analysis and disease diagnosis. When a machine learning model is used to classify EEG data, if training data is composed of only data having similar characteristics, classification performance may be deteriorated when applied to data of another group. In this paper, we propose a method to construct training data set by selecting several groups of data using semi-supervised learning algorithm to improve these problems. We then compared the performance of the two models by training the model with a training data set consisting of data with similar characteristics to the training data set constructed using the proposed method."
딥러닝 기반 과일 선별 시스템,2018,"['Deep learning', 'Machine learning', 'Tensorflow', 'Inception model', 'Fruit Classification Systems']",,"Deep learning technology among artificial intelligence technologies has shown good results in image recognition field. In this paper, we use a learning model that is based on a Tensorflow based model that utilizes this deep learning technique and that has been repaired by Inception-v3 model. Based on the characteristics of the fruit, we construct a fruit classification system that classifies into four categories : Healthy apple, Damaged apple, Diseased apple and Discolored apple. To do this, we designed a learning model in which the number of learning iterations was 500 times based on 1,280 apple image data of four kinds and conducted a model evaluation experiment based on the fruit image data taken by the user. Experiments were based on images taken in three directions for accurate model evaluation. Experimental results show that the accuracy of the learning model is more than 90%. However, since fruit showed different classification results according to direction, it suggested the necessity of classification algorithm according to image direction in the future. If such a deep learning based fruit classification system is applied to farmers, fruit quality classifiers due to farm labor shortage are essential, and it will be possible to construct a fruit quality screening system with high accuracy and low cost."
온라인 쇼핑몰에서 상품 설명 이미지 내의 키워드인식을 위한 딥러닝 훈련 데이터 자동 생성 방안,2018,"['Deep learning', 'train data generation', 'OCR', 'attribute-based search', 'Single Shot MultiBox Detector', '딥러닝', '훈련데이터 생성', 'OCR', '속성 기반 검색', 'Single Shot MultiBox Detector']","E-commerce 환경의 발전으로 소비자들은 다양한 상품들을 한 자리에서 폭 넓게 비교할 수 있게 되었다. 하지만 온라인 쇼핑몰에 올라와있는 상당량의 주요 상품 정보들이 이미지 형태이기 때문에 컴퓨터가 인지할 수있는 텍스트 기반 검색 시스템에 반영될 수 없다는 한계가 존재한다. 이러한 한계점은 일반적으로 기존 기계학습 기술 및 OCR(Optical Character Recognition) 기술을 활용해, 이미지 형태로 된 키워드를 인식함으로써 개선할수 있다. 그러나 기존 OCR 기술은 이미지 안에 글자가 아닌 그림이 많고 글자 크기가 작으면 낮은 인식률을보인다는 문제가 있다. 이에 본 연구에서는 기존 기술들의 한계점을 해결하기 위하여, 딥러닝 기반 사물인식 모형 중 하나인 SSD(Single Shot MultiBox Detector)를 개조하여 이미지 형태의 상품 카탈로그 내의 텍스트 인식모형을 설계하였다. 하지만 이를 학습시키기 위한 데이터를 구축하는 데 상당한 시간과 비용이 필요했는데, 이는지도학습의 방법론을 따르는 SSD 모형은 훈련 데이터마다 직접 정답 라벨링을 해줘야 하기 때문이다. 본 연구는 이러한 문제점을 해결하기 위해 ‘훈련 데이터 자동 생성 프로그램’을 함께 개발하였다. 훈련 데이터 자동 생성 프로그램을 통해 수작업으로 데이터를 만드는 것에 비하여 시간과 비용을 대폭 절감할 수 있었으며, 생성된훈련용 데이터를 통해 모형의 인식 성능을 높일 수 있었다. 더 나아가 실험연구를 통해 자동으로 생성된 훈련데이터의 특징별로 인식기 모형의 성능에 얼마나 큰 영향을 끼치는지 알아보고, 성능 향상에 효과적인 데이터의 특징을 분석하였다. 본 연구를 통해서 개발된 상품 카탈로그 내 텍스트 인식모형과 훈련 데이터 자동 생성프로그램은 온라인 쇼핑몰 판매자들의 상품 정보 등록 수고를 줄여줄 수 있으며, 구매자들의 상품 검색 시 결과의 정확성을 향상시키는 데 기여할 수 있을 것으로 기대한다.","From the 21st century, various high-quality services have come up with the growth of the internet or ‘Information and Communication Technologies’. Especially, the scale of E-commerce industry in which Amazon and E-bay are standing out is exploding in a large way. As E-commerce grows, Customers could get what they want to buy easily while comparing various products because more products have been registered at online shopping malls.However, a problem has arisen with the growth of E-commerce. As too many products have been registered, it has become difficult for customers to search what they really need in the flood of products.When customers search for desired products with a generalized keyword, too many products have come out as a result. On the contrary, few products have been searched if customers type in details of products because concrete product-attributes have been registered rarely.In this situation, recognizing texts in images automatically with a machine can be a solution. Because bulk of product details are written in catalogs as image format, most of product information are not searched with text inputs in the current text-based searching system. It means if information in images can be converted to text format, customers can search products with product-details, which make them shop more conveniently.There are various existing OCR(Optical Character Recognition) programs which can recognize texts in images. But existing OCR programs are hard to be applied to catalog because they have problems in recognizing texts in certain circumstances, like texts are not big enough or fonts are not consistent.Therefore, this research suggests the way to recognize keywords in catalog with the Deep Learning algorithm which is state of the art in image-recognition area from 2010s. Single Shot Multibox Detector(SSD), which is a credited model for object-detection performance, can be used with structures re-designed to take into account the difference of text from object. But there is an issue that SSD model needs a lot of labeled-train data to be trained, because of the characteristic of deep learning algorithms, that it should be trained by supervised-learning. To collect data, we can try labelling location and classification information to texts in catalog manually. But if data are collected manually, many problems would come up. Some keywords would be missed because human can make mistakes while labelling train data. And it becomes too time-consuming to collect train data considering the scale of data needed or costly if a lot of workers are hired to shorten the time. Furthermore, if some specific keywords are needed to be trained, searching images that have the words would be difficult, as well.To solve the data issue, this research developed a program which create train data automatically. This program can make images which have various keywords and pictures like catalog and save location-information of keywords at the same time. With this program, not only data can be collected efficiently, but also the performance of SSD model becomes better. The SSD model recorded 81.99% of recognition rate with 20,000 data created by the program.Moreover, this research had an efficiency test of SSD model according to data differences to analyze what feature of data exert influence upon the performance of recognizing texts in images. As a result, it is figured out that the number of labeled keywords, the addition of overlapped keyword label, the existence of keywords that is not labeled, the spaces among keywords and the differences of background images are related to the performance of SSD model. This test can lead performance improvement of SSD model or other text-recognizing machine based on deep learning algorithm with high-quality data.SSD model which is re-designed to recognize texts in images and the program developed for creating train data are expected to contribute to improvement of searching system in E-co..."
숫자 기호화를 통한 신경기계번역 성능 향상,2018,"['Neural Machine Translation', 'Number Translation', 'Mistranslation', 'Symbolization', 'Model Optimizatio', '신경 기계 번역', '숫자 번역', '오번역', '기호화', '모델 최적화']",,"The development of machine learning has enabled machines to perform delicate tasks that only humans could do, and thus many companies have introduced machine learning based translators. Existing translators have good performances but they have problems in number translation. The translators often mistranslate numbers when the input sentence includes a large number. Furthermore, the output sentence structure completely changes even if only one number in the input sentence changes. In this paper, first, we optimized a neural machine translation model architecture that uses bidirectional RNN, LSTM, and the attention mechanism through data cleansing and changing the dictionary size. Then, we implemented a number-processing algorithm specialized in number translation and applied it to the neural machine translation model to solve the problems above. The paper includes the data cleansing method, an optimal dictionary size and the number-processing algorithm, as well as experiment results for translation performance based on the BLEU score."
제한된 라벨 데이터 상에서 다중-태스크 반 지도학습을 사용한 동작 인지 모델의 성능 향상,2018,"['transfer learning', 'multitask learning', 'activity recognition', '전이 학습', '다중 태스크 학습', '동작 인지']","기계 학습을 통한 인간 동작 인지 (human activity recognition) 시스템에서 중요한 요소는 충분한 양의 라벨 데이터 (labeled data)를 확보하는 것이다. 그러나 라벨 데이터를 확보하는 일은 많은 비용과 시간을 필요로 한다. 매우 적은 수의 라벨 데이터를 가지고 있는 새로운 환경 (타겟 도메인)에서 동작 인지 시스템을 구축하는 경우, 기존의 환경 (소스 도메인)의 데이터나 이 환경에서 학습된 분류기(classifier)를 사용하는 것은 도메인이 서로 다르기 때문에 바람직하지 않다. 기존의 기계 학습 방법들이 이러한 문제를 해결할 수 없으므로 전이 학습 (transfer learning) 방법이 제시되었으며, 이 방법에서는 소스 도메인에서 확보한 지식을 활용하여 타겟 도메인에서의 분류기 성능을 높이도록 하고 있다. 본 논문에서는 다중 태스크 신경망 (multitask neural network)을 사용하여 매우 제한된 수의 데이터만으로 정확도가 높은 동작 인지 분류기를 생성하는 전이 학습 방법을 제안한다. 이 방법에서는 소스 및 타겟 도메인 분류기의 손실 함수 최소화가 별개의 태스크로 간주된다. 즉, 하나의 신경망을 사용하여 두 태스크의 손실 함수를 동시에 최소화하는 방식으로 지식 전이(knowledge transfer)가 일어나게 된다. 또한, 제안한 방법에서는 모델 학습을 위하여 비지도 방식(unsupervised manner)으로 라벨이 부여되지 않은 데이터를 활용한다. 실험 결과, 제안한 방법은 기존의 방법에 비하여 일관적으로 우수한 성능을 보여주고 있다.","A key to a well-performing human activity recognition (HAR) system through machine learning technique is the availability of a substantial amount of labeled data. Collecting sufficient labeled data is an expensive and time-consuming task. To build a HAR system in a new environment (i.e., the target domain) with very limited labeled data, it is unfavorable to naively exploit the data or trained classifier model from the existing environment (i.e., the source domain) as it is due to the domain difference. While traditional machine learning approaches are unable to address such distribution mismatch, transfer learning approach leverages the utilization of knowledge from existing well-established source domains that help to build an accurate classifier in the target domain. In this work, we propose a transfer learning approach to create an accurate HAR classifier with very limited data through the multitask neural network. The classifier loss function minimization for source and target domain are treated as two different tasks. The knowledge transfer is performed by simultaneously minimizing the loss function of both tasks using a single neural network model. Furthermore, we utilize the unlabeled data in an unsupervised manner to help the model training. The experiment result shows that the proposed work consistently outperforms existing approaches."
빅데이터와 딥러닝을 활용한동물 감염병 확산 차단,2018,"['Big Data', 'Deep Learning', 'Machine Learning', 'Animal Infectious Diseases', 'Evidence-based Policy-making', '빅데이터', '딥러닝', '기계학습', '동물전염병', '증거기반 의사결정']","조류인플루엔자와 구제역 같은 동물감염병은 거의 매년 발생하며 국가에 막대한 경제적 사회적 손실을 일으키고 있다. 이를 예방하기 위해서 그간 방역당국은 다양한 인적, 물적 노력을 기울였지만 감염병은 지속적으로발생해 왔다. 최근 빅데이터와 딥러닝 기술을 활용하여 감염병의 예측모델을 개발하고자 하는 시도가 시작되고있지만, 실제로 활용가능한 모델구축 연구와 사례보고는 활발히 진행되고 있지 않은 실정이다. KT와 과학기술정보통신부는 2014년부터 국가 R&D사업의 일환으로 축산관련 차량의 이동경로를 분석하여 예측하는 빅데이터사업을 수행하고 있다. 동물감염병 예방을 위하여 연구진은 최초에는 차량이동 데이터를 활용한 회귀분석모델을 기반으로 한 예측모델을 개발하였다. 이후에는 기계학습을 활용하여 좀 더 정확한 예측 모델을 구성하였다.특히, 2017년 예측모델에서는 시설물에 대한 확산 위험도를 추가하였고 모델링의 하이퍼 파라미터를 다양하게고려하여 모델의 성능을 높였다. 정오분류표와 ROC 커브를 확인한 결과, 기계 학습 모델보다 2017년 구성된 모형이 우수함을 확인 할 수 있었다. 또한 2017에는 결과에 대한 설명을 추가하여 방역당국의 의사결정을 돕고이해관계자를 설득할 수 있는 근거를 확보하였다. 본 연구는 빅데이터를 활용하여 동물감염병예방시스템을 구축한 사례연구로 모델주요변수값, 이에따른 실제예측성능결과, 그리고 상세하게 기술된 시스템구축 프로세스는향후 감염병예방 영역의 지속적인 빅데이터활용 및 분석 모델 개발에 기여할 수 있을 것이다. 또한 본 연구에서구축한 시스템을 통해 보다 사전적이고 효과적인 방역을 할 수 있을 것으로 기대한다.","Animal infectious diseases, such as avian influenza and foot and mouth disease, occur almost every year and cause huge economic and social damage to the country. In order to prevent this, the anti-quarantine authorities have tried various human and material endeavors, but the infectious diseases have continued to occur. Avian influenza is known to be developed in 1878 and it rose as a national issue due to its high lethality. Food and mouth disease is considered as most critical animal infectious disease internationally. In a nation where this disease has not been spread, food and mouth disease is recognized as economic disease or political disease because it restricts international trade by making it complex to import processed and non-processed live stock, and also quarantine is costly. In a society where whole nation is connected by zone of life, there is no way to prevent the spread of infectious disease fully. Hence, there is a need to be aware of occurrence of the disease and to take action before it is distributed.Epidemiological investigation on definite diagnosis target is implemented and measures are taken to prevent the spread of disease according to the investigation results, simultaneously with the confirmation of both human infectious disease and animal infectious disease. The foundation of epidemiological investigation is figuring out to where one has been, and whom he or she has met. In a data perspective, this can be defined as an action taken to predict the cause of disease outbreak, outbreak location, and future infection, by collecting and analyzing geographic data and relation data. Recently, an attempt has been made to develop a prediction model of infectious disease by using Big Data and deep learning technology, but there is no active research on model building studies and case reports. KT and the Ministry of Science and ICT have been carrying out big data projects since 2014 as part of national R &D projects to analyze and predict the route of livestock related vehicles. To prevent animal infectious diseases, the researchers first developed a prediction model based on a regression analysis using vehicle movement data. After that, more accurate prediction model was constructed using machine learning algorithms such as Logistic Regression, Lasso, Support Vector Machine and Random Forest. In particular, the prediction model for 2017 added the risk of diffusion to the facilities, and the performance of the model was improved by considering the hyper-parameters of the modeling in various ways. Confusion Matrix and ROC Curve show that the model constructed in 2017 is superior to the machine learning model. The difference between the2016 model and the 2017 model is that visiting information on facilities such as feed factory and slaughter house, and information on bird livestock, which was limited to chicken and duck but now expanded to goose and quail, has been used for analysis in the later model. In addition, an explanation of the results was added to help the authorities in making decisions and to establish a basis for persuading stakeholders in 2017. This study reports an animal infectious disease prevention system which is constructed on the basis of hazardous vehicle movement, farm and environment Big Data. The significance of this study is that it describes the evolution process of the prediction model using Big Data which is used in the field and the model is expected to be more complete if the form of viruses is put into consideration. This will contribute to data utilization and analysis model development in related field. In addition, we expect that the system constructed in this study will provide more preventive and effective prevention."
가로공간 보행만족도 예측을 위한 딥러닝 모형의적용과 검증,2018,"['도시설계', '보행가로', '보행친화도', '딥러닝', 'Google Street View', 'Urban Design', 'Walking Street', 'Walkability', 'Deep Learning', 'Google Street View']","본 연구는 Google Street View 360° 파노라마 이미지와 딥러닝 기법을 적용하여 가로공간의 보행만족도를 예측하고 검증하였다. 주요 연구결과는 다음과 같다. 첫째, 모형 예측값과 참값 사이의 상관 계수는 학습 모형에 따라 0.16~0.84로 나타나 결과의 정확도 범위가 비교적 큰 것으로 나타났다. 모형 간 성능차이는 딥러닝 모형 구조에 따른 차이로 판단된다. 이러한 결과는 특정 연구 주제에 대하여 가장 적합한 모형을 적용하기 위해서 딥러닝 모형의 테스트 및 검증이 중요하다는 것을 의미한다. 둘째, 네 가지 모형 중 VGG16이 가로공간에서 보행만족도 예측모형으로 적합한 것으로 나타났다. 셋째, Google Street View Image를 활용하여 보행만족도를 예측하는 경우 사전학습 모형을 전이학습하는 것이 적합하다는 것을 보여준다. 마지막으로, 본 연구는 오픈소스 데이터를 활용한 딥러닝 모형이 도시의 물리적환경 분석에 있어 중요한 역할을 할 수 있음을 시사한다.","This study examines the prediction model of walking satisfaction level of streetscape by deep learning technique. The model focuses on the streetscape imagery and walking satisfaction level of pedestrians. We trained and tested the prediction model using the Google Street View 360° Panorama images of the survey locations for walking satisfaction level. First, the correlation coefficient between machine rating and human rating regarding walking satisfaction level ranged from 0.16 to 0.84 by the transfer learning method. This finding indicates that deep learning models should be tested and validated for the purpose of specific research topic. Second, among four test models, VGG16 is relatively suitable for the prediction model of walking satisfaction level on streetscape comparing to the Inception structure in this study. Third, the result shows that transfer learning with pre-trained model could be the best one to predict average walking satisfaction level using Google Street View images. Lastly, This study shows that deep learning skills could play an important role in analyzing and predicting urban physical environments with open source imagery data."
일한기계번역의 오류유형에 관한 고찰-일본소설을 중심으로-,2018,"['기계번역', '번역오류', '오류유형', '신경망번역', '소설번역', 'Machine translation', 'Error in translation', 'Error type', 'Neural network translation', 'Novel translation']",,近年、人工知能(AI)の発達により、機械翻訳が社会的な話題になるのに合わせて、将来なくなる職業の１位に翻訳家があげられている。しかし、グーグル翻訳と、韓国ネイバーパパゴ(PAPAGO)翻訳もまだ誤謬が多く、特に文学作品の場合、内容が通じないくらいである。ただ今後、機械翻訳のクオリティーが飛躍的に向上すると、翻訳の質も高くなると思うが、マイク・シュスター(Mike Schuster)は、AIが言語学習や通翻訳の専門家に取って代わることは不可能であるとし、どんなに機械翻訳が進んだとしても、人類はまだ外国語学習をしなければならないと述べている。本研究では、日本の小説を中心に、グーグル翻訳とネイバーパパゴの機械翻訳を利用した日韓翻訳の結果を通じて、機械翻訳による誤謬の類型を考察した。その結果、慣用句などの語彙、助詞、受身表現、指示詞などの文法、敬語、文末などの文体、分かち書き、符号などにおける誤謬がみられた。従って、翻訳家という職業がなくなるという一般論に対する反論ができたと考える。
딥러닝 시계열 알고리즘 적용한 기업부도예측모형 유용성 검증,2018,"['Optimal Feature Selection', 'Lasso Regression', 'Deep Learning Time Series Algorithm', 'Corporate Bankruptcy', 'RNN', 'LSTM', '최적 변수 선별', 'Lasso 회귀분석', '딥러닝 시계열 알고리즘', '기업부도', 'RNN', 'LSTM']","본 연구는 경제적으로 국내에 큰 영향을 주었던 글로벌 금융위기를 기반으로 총 10년의 연간 기업데이터를이용한다. 먼저 시대 변화 흐름에 일관성있는 부도 모형을 구축하는 것을 목표로 금융위기 이전(2000~2006년) 의 데이터를 학습한다. 이후 매개 변수 튜닝을 통해 금융위기 기간이 포함(2007~2008년)된 유효성 검증 데이터가 학습데이터의 결과와 비슷한 양상을 보이고, 우수한 예측력을 가지도록 조정한다. 이후 학습 및 유효성 검증데이터를 통합(2000~2008년)하여 유효성 검증 때와 같은 매개변수를 적용하여 모형을 재구축하고, 결과적으로최종 학습된 모형을 기반으로 시험 데이터(2009년) 결과를 바탕으로 딥러닝 시계열 알고리즘 기반의 기업부도예측 모형이 유용함을 검증한다.부도에 대한 정의는 Lee(2015) 연구와 동일하게 기업의 상장폐지 사유들 중 실적이 부진했던 경우를 부도로선정한다. 독립변수의 경우, 기존 선행연구에서 이용되었던 재무비율 변수를 비롯한 기타 재무정보를 포함한다.이후 최적의 변수군을 선별하는 방식으로 다변량 판별분석, 로짓 모형, 그리고 Lasso 회귀분석 모형을 이용한다. 기업부도예측 모형 방법론으로는 Altman(1968)이 제시했던 다중판별분석 모형, Ohlson(1980)이 제시한 로짓모형, 그리고 비시계열 기계학습 기반 부도예측모형과 딥러닝 시계열 알고리즘을 이용한다.기업 데이터의 경우, ‘비선형적인 변수들’, 변수들의 ‘다중 공선성 문제’, 그리고 ‘데이터 수 부족’이란 한계점이 존재한다. 이에 로짓 모형은 ‘비선형성’을, Lasso 회귀분석 모형은 ‘다중 공선성 문제’를 해결하고, 가변적인데이터 생성 방식을 이용하는 딥러닝 시계열 알고리즘을 접목함으로서 데이터 수가 부족한 점을 보완하여 연구를 진행한다.현 정부를 비롯한 해외 정부에서는 4차 산업혁명을 통해 국가 및 사회의 시스템, 일상생활 전반을 아우르기위해 힘쓰고 있다. 즉, 현재는 다양한 산업에 이르러 빅데이터를 이용한 딥러닝 연구가 활발히 진행되고 있지만, 금융 산업을 위한 연구분야는 아직도 미비하다. 따라서 이 연구는 기업 부도에 관하여 딥러닝 시계열 알고리즘 분석을 진행한 초기 논문으로서, 금융 데이터와 딥러닝 시계열 알고리즘을 접목한 연구를 시작하는 비 전공자에게 비교분석 자료로 쓰이기를 바란다.","In addition to stakeholders including managers, employees, creditors, and investors of bankrupt companies, corporate defaults have a ripple effect on the local and national economy. Before the Asian financial crisis, the Korean government only analyzed SMEs and tried to improve the forecasting power of a default prediction model, rather than developing various corporate default models. As a result, even large corporations called 'chaebol enterprises' become bankrupt. Even after that, the analysis of past corporate defaults has been focused on specific variables, and when the government restructured immediately after the global financial crisis, they only focused on certain main variables such as 'debt ratio'.A multifaceted study of corporate default prediction models is essential to ensure diverse interests, to avoid situations like the 'Lehman Brothers Case' of the global financial crisis, to avoid total collapse in a single moment.The key variables used in corporate defaults vary over time. This is confirmed by Beaver (1967, 1968) and Altman’s (1968) analysis that Deakins'(1972) study shows that the major factors affecting corporate failure have changed. In Grice's (2001) study, the importance of predictive variables was also found through Zmijewski’s (1984) and Ohlson’s (1980) models. However, the studies that have been carried out in the past use static models. Most of them do not consider the changes that occur in the course of time. Therefore, in order to construct consistent prediction models, it is necessary to compensate the time-dependent bias by means of a time series analysis algorithm reflecting dynamic change.Based on the global financial crisis, which has had a significant impact on Korea, this study is conducted using 10 years of annual corporate data from 2000 to 2009. Data are divided into training data, validation data, and test data respectively, and are divided into 7, 2, and 1 years respectively. In order to construct a consistent bankruptcy model in the flow of time change, we first train a time series deep learning algorithm model using the data before the financial crisis (2000~2006). The parameter tuning of the existing model and the deep learning time series algorithm is conducted with validation data including the financial crisis period (2007~2008). As a result, we construct a model that shows similar pattern to the results of the learning data and shows excellent prediction power. After that, each bankruptcy prediction model is restructured by integrating the learning data and validation data again (2000 ~ 2008), applying the optimal parameters as in the previous validation. Finally, each corporate default prediction model is evaluated and compared using test data (2009) based on the trained models over nine years. Then, the usefulness of the corporate default prediction model based on the deep learning time series algorithm is proved. In addition, by adding the Lasso regression analysis to the existing methods (multiple discriminant analysis, logit model) which select the variables, it is proved that the deep learning time series algorithm model based on the three bundles of variables is useful for robust corporate default prediction.The definition of bankruptcy used is the same as that of Lee (2015). Independent variables include financial information such as financial ratios used in previous studies. Multivariate discriminant analysis, logit model, and Lasso regression model are used to select the optimal variable group. The influence of the Multivariate discriminant analysis model proposed by Altman (1968), the Logit model proposed by Ohlson (1980), the non-time series machine learning algorithms, and the deep learning time series algorithms are compared.In the case of corporate data, there are limitations of 'nonlinear variables', 'multi-collinearity' of variables, and 'lack of data'. While the logit model is nonlinear, the Lasso regression model solves the multi-collinear..."
인공지능을 활용한 영어 학습용 챗봇 시스템 개발 방안 연구,2018,"['영어학습', '인공지능', '인공지능을 활용한 교육', '챗봇', '챗봇을 활용한 영어 교육', '메신저 인터페이스', 'Artificial Intelligence', 'Education through A.I.', 'English education through chatbot']",,"Artificial Intelligence has become a big part of our daily lives. The key technology of Artificial Intelligence, machine learning and deep learning, has developed chatbot. Chatbot is a conversational agent system which has recently been programmed to perform a variety of tasks such as shopping, making reservations, giving consultation, and other noteworthy tasks which require interaction with human users. Global ICT companies have increased efforts to develop advanced chatbot systems which provide a variety of chatbot services to mobile users through their Messenger platform. Although the incorporation of chatbot systems into our daily lives has seen rapid progression, the development of English learning chatbot systems has not seen the same amount of advancement. The purpose of this study is to provide theoretical background for the development of an English learning chatbot system based on Artificial Intelligence. First of all, in this study, an analysis of the core technology of Artificial Intelligence such as machine learning, deep learning and natural language processes was provided. Then, the recent developmental status of chatbot based on the messenger interface was examined. Finally, a developmental plan for the design of a chatbot for English learning was provided. As a developmental plan for designing an English learning chatbot, object and non-object oriented chatbot systems were suggested.For the object oriented chatbot, application plans of a limited theme and database were introduced. For the design of the non-object oriented chatbot, application plans for a database, a diamond tree diagram, function keys, and emoticons were proposed."
딥 러닝 기반의 악성흑색종 분류를 위한 컴퓨터 보조진단 알고리즘,2018,"['Deep Learning', 'Machine Learning', 'Malignant Melanoma', 'Convolutional Neural Network', 'Computer Aided Diagnosis']",,"The malignant melanoma accounts for about 1 to 3% of the total malignant tumor in the West, especially in the US, it is a disease that causes more than 9,000 deaths each year. Generally, skin lesions are difficult to detect the features through photography. In this paper, we propose a computer-aided diagnosis algorithm based on deep learning for classification of malignant melanoma and benign skin tumor in RGB channel skin images. The proposed deep learning model configures the tumor lesion segmentation model and a classification model of malignant melanoma. First, U-Net was used to segment a skin lesion area in the dermoscopic image. We could implement algorithms to classify malignant melanoma and benign tumor using skin lesion image and results of expert’s labeling in ResNet. The U-Net model obtained a dice similarity coefficient of 83.45% compared with results of expert’s labeling. The classification accuracy of malignant melanoma obtained the 83.06%. As the result, it is expected that the proposed artificial intelligence algorithm will utilize as a computer-aided diagnosis algorithm and help to detect malignant melanoma at an early stage."
딥러닝을 이용한 트러스 구조물의 정적 및 동적 거동 예측,2018,"['Deep learning', 'Neural networks', 'Input layers', 'Hidden layers', 'Output layers']",,"In this study, an algorithm applying deep learning to the truss structures was proposed. Deep learning is a method of raising the accuracy of machine learning by creating a neural networks in a computer. Neural networks consist of input layers, hidden layers and output layers. Numerous studies have focused on the introduction of neural networks and performed under limited examples and conditions, but this study focused on two- and three-dimensional truss structures to prove the effectiveness of algorithms. and the training phase was divided into training model based on the dataset size and epochs. At these case, a specific data value was selected and the error rate was shown by comparing the actual data value with the predicted value, and the error rate decreases as the data set and the number of hidden layers increases. In consequence, it showed that it is possible to predict the result quickly and accurately without using a numerical analysis program when applying the deep learning technique to the field of structural analysis"
지도학습에서 다양한 입력 모델에 의한 초단기 태양광 발전 예측,2018,"['Support vectors machine', 'Deep learning', 'Artificial neural network', 'Sunshine', 'Solar radiation.']",,"This study predicts solar radiation, solar radiation, and solar power generation using hourly weather data such as temperature, precipitation, wind direction, wind speed, humidity, cloudiness, sunshine and solar radiation. I/O pattern in supervised learning is the most important factor in prediction, but it must be determined by repeated experiments because humans have to decide. This study proposed four input and output patterns for solar and sunrise prediction. In addition, we predicted solar power generation using the predicted solar and solar radiation data and power generation data of Youngam solar power plant in Jeollanamdo . As a experiment result, the model 4 showed the best prediction results in the sunshine and solar radiation prediction, and the RMSE of sunshine was 1.5 times and the sunshine RMSE was 3 times less than that of model 1. As a experiment result of solar power generation prediction, the best prediction result was obtained for model 4 as well as sunshine and solar radiation, and the RMSE was reduced by 2.7 times less than that of model 1."
순환신경망 기반의 사용자 의도 예측 모델,2018,"['big data', 'deep learning', 'human intention prediction', 'RNN', '빅데이터', '딥러닝', '사용자 의도 예측', '순환 신경망']","기계 학습 모델 구축을 통한 인간의 의도 예측은 기존에도 제공되어 왔으나, 특정 행위가 발생하는 시점으로부터 먼 과거의 정보를 반영한 의도 예측이 어렵다는 단점이 존재했다. 이 문제점의 극복을 위해, 본 논문에서는 순환 신경망(RNN – Recurrent Neural Network) 기반의 행위 의도 예측 모델 학습 기법을 제안한다. 순환 신경망 모델은 시계열(Time-Series) 데이터의 패턴을 분석하여 과거의 시점이 반영된 예측 결과를 생성한다. 본 논문이 제안하는 순환 신경망 기반의 의도 예측 모델은 시간, 공간, 행위, 물체, 의도로 구성된 생활 데이터 시퀀스를 바탕으로 사용자의 의도를 예측할 수 있도록 학습된다. 순환 신경망의 각 노드는 의도 예측 모델이 먼 과거의 데이터 시퀀스를 고려하여 의도를 예측 할 수 있도록 LSTM(Long-Short Term Memory) Cell로 구성하였다. 순환 신경망 기반의 의도 예측 모델의 성능 평가를 위해, 본 논문에서는 행위 의도에 대한 가중치 그래프 기반 데이터 생성기를 구축하여 실제 실내에서 발생하는 인간 활동에 가까운 데이터를 자동으로 생성하여 실험에 사용했다. 총 23,000개의 데이터가 의도 모델 학습과 검증에 사용되었으며, 학습된 모델의 의도 예측 정확도 측정 실험을 한 결과로 평균 90.52%의 예측 정확도를 보였다.","Several studies have been conducted on human intention prediction with the help of machine learning models. However, these studies have indicated a fundamental shortcoming of machine learning models since they are unable to reflect a long span of past information. To overcome this limitation, this paper proposes a human intention prediction model based on a recurrent neural network(RNN). For performing predictions, the RNN model classifies the patterns of time-series data by reflecting previous sequence patterns of the time-series data. For performing intention prediction using the proposed model, an RNN model was trained to classify predefined intentions by using attributes such as time, location, activity and detected objects in a house. Each RNN node is composed of a long short-term memory cell to solve the long term dependency problem. To evaluate the proposed intention prediction model, a data generator based on the weighted-graph structure has been developed for generating data on a daily basis. By incorporating 23,000 data instances for training and testing the proposed intention prediction model, a prediction accuracy value of 90.52% was achieved."
선호도 학습을 통한 이미지 개선 알고리즘 구현,2018,"['Image Enhancement', 'User Preference', 'Training Image', 'Machine Learning']",,"Image enhancement is a necessary end essential step after taking a picture with a digital camera. Many different photo software packages attempt to automate this process with various auto enhancement techniques. This paper provides and implements a system that can learn a user's preferences and apply the preferences into the process of image enhancement. Five major components are applied to the implemented system, which are computing a distance metric, finding a training set, finding an optimal parameter set, training and finally enhancing the input image. To estimate the validity of the method, we carried out user studies, and the fact that the implemented system was preferred over the method without learning user preferences."
심층 다중 커널 최소제곱 서포트 벡터 회귀 기계,2018,"['Backprogation algorithm', 'deep neural network', 'least squares support vector machine', 'multilayer neural network', 'penalized objective function', 'regression', '다층 신경망', '벌칙화 목적함수', '심층 신경망', '역전파 알고리즘', '최소제곱 서포트 벡터 기계', '회귀']","본 논문에서는 회귀모형을 위한 심층 다중 커널 최소제곱 서포트 벡터 회귀 기계 (least squares support vector regression machine; LS-SVRM)을 제안한다. 제안된 모형은 입력층, 2개의 은닉층 및 출력층으로 구성된다. 각 은닉층에서 다른 형태의 커널을 가지는 LS-SVRM이 입력과 종속변 수를 이용하여 학습된다. 최종 출력을 위해 출력층은 두번째 은닉층의 출력을 입력으로 사용하여 학습된다. 다층 신경망과 달리 심층 다중 커널 LS-SVRM에서 각 LS-SVRM은 벌칙화 목적함수를 최소화하도록 훈련된다. 따라서 심층 다중 커널 LS-SVRM의 학습은 최종 비용 함수만 최소화하기 위해 가중치 및 편의항을 학습하는 다층 신경망과 완전히 다르다. 심층 다중 커널 LS-SVRM은 모든 LS-SVRM을 훈련하고 조합 가중치와 편의항를 사용한다. 이때 조합 가중치와 편의항은 역전파 알고리즘를 이용하여 갱신된다. 수치적 연구는 심층 다중 커널 LS-SVRM이 회귀 문제에 대한 최첨단 기계 학습 모형보다 우위에 있음을 보여준다.","We propose a deep multiple kernel least squares support vector regression machine (LS-SVRM) for regression, which consists of the input layer, two hidden layers and the output layer. In the hidden layer, LS-SVRMs with different kernels are trained with the inputs and the responses. For the final output, the neural network is trained with the outputs of the second hidden layer as inputs. Differently from the multilayer neural network (MNN), LS-SVRMs in the deep multiple kernel LS-SVRM are trained to minimize the penalized objective function. Thus, the learning dynamics of the deep multiple kernel LS-SVRM are totally different from MNN in which weights and biases are trained to minimize only the final cost function. The deep multiple kernel LSSVRM trains all LS-SVRMs in the architecture and makes use of combination weights and biases. The combination weights and biases are updated by backpropogation. Numerical studies illustrate that the deep multiple kernel LS-SVRM outperforms standard LS-SVRM and MNN on regression problems."
딥러닝 기반의 R-CNN을 이용한 악성코드 탐지 기법,2018,"['Malware', 'Deep learning', 'Regions with CNN', 'Image processing', '악성코드 분석', '딥러닝', 'R-CNN', '특징 추출', '이미지 프로세싱']","최근 기계학습의 발달로 인공지능을 구현하는 머신러닝과 딥러닝 같은 기술이 많은 관심을 받고 있다. 본 논문에서는 딥러닝 기반의 R-CNN을 이용한 바이너리 악성코드를 이미지화 하고 이미지에서 특징을 추출해 패밀리를 분류한다. 본 논문에서는 딥러닝에서 두 단계를 이용해 악성코드를 CNN을 이용해 이미지화하고 ,악성코드의 패밀리가 갖는 특징을 R-CNN을 이용해 분류함으로 악성코드를 이미지화하여 특징을 분류하고 패밀리를 분류한 후 악성코드의 진화를 자동 분류한다. 제안 기법은 검출율이 93.4%로 우수한 탐지 성능을 보였고 정확도는 98.6%로 매우 높은 성능을 보였다. 또한 악성코드를 이미지화 하는 CNN 처리속도가 23.3ms, 하나의 샘플을 분류하기 위해서 R-CNN처리 속도는 4ms로 비교적 빠르게 악성코드를 판별하고 분류가 가능함을 실험을 통해 증명하였다.",
온오프라인 연계 한국어 교수학습 시스템의 가능성,2018,"['한국어교육', '온라인 시스템', '어플리케이션', '게임', '온라인 클리닉', 'Korean education', 'Online system', 'Application', 'Game', 'Online Clinic']",,"The purpose of this paper is to present the possibility of a Korean education system linked to online and offline. The demand for Korean language education is continuously increasing, and the content of Korean language education has been improved. However, current Korean education media is composed of paper books and MP3. This reality needs to be improved by utilizing applications through smart phones or by interactive communication between instructors and learners. The online education system is to utilize elements of the game and to introduce the writing feedback system into the Korean education system.Hangul is an important asset in Korean language education. Hangul is a character that can express all the languages ​​of the world beyond the representation of Korean. Hangul has only one sound in one character. This feature of Hangul is an advantage when processed in machine language. Creative endeavor in Korean language education strengthens the competitiveness of Korean language education and is a strategy of survival. This builds the education system and solidifies the foundation. Through the accumulation of educational materials, it is possible to improve Korean language education by securing big data and continuously supplementing the system."
개인정보가 보호되는 동형암호기반 금융데이터분석,2018,"['동형기계학습', '동형암호', '기계학습', '함수암호', '개인정보보호', '신용점수', 'Homomorphic Encryption', 'Machine Learning', 'Functional Encryption', 'preserving private Information', 'Credit Score']",최근 기계학습(machine learning) 기술의 발전으로 빅데이터 분석이 각광을 받고 있다. 네트워크 연결성의증대로 방대한 양의 데이터의 수집이 가능해지면서 기계학습 기술에 기반이 되는 양질의 빅데이터 수집이용이해진 까닭이다. 기계학습이 효과적이려면 이종기관에서 수집된 데이터들을 민감한 개인정보를 포함하여병합하고 활용하여야 하는데 이 과정에서 개인정보유출의 문제가 심각하게 대두되고 있다.본고에서는 개인정보보호와 빅데이터 활용이라는 상충된 목표를 달성할 수 있는 정보기술적 해법으로 암호화된데이터상에서 복호화 없이 기계학습을 수행하는 동형기계학습(homomorphic machine learning) 기술을 소개한다. 동형암호(homomorphic encryption)는 평문을 암호화한 상태에서도 복호화 없이 컴퓨터가 수행하는 모든계산이 가능한 암호기술로서 특히 양자컴퓨터 시대에도 안전한 최신암호기술이다. 동형암호기술을 적용하면민감한 개인정보를 포함한 데이터분석에서도 개인정보 유출이나 데이터손실 없이 기계학습을 수행할 수 있다.구체적으로는 동형기계학습의 포괄적 이해를 위해 동형암호와 기계학습 기술을 최소한의 수학적 묘사로 개념적으로 소개하도록 한다. 또한 최근 연구결과들을 토대로 실용화에 가장 큰 걸림돌로 여겨지고 있는 동형기계학습의효율성을 분석하여 실용화 가능성을 타진해본다. 또한 민감한 개인정보를 기반으로 한 데이터분석이 필요한대표적 사례로 신용정보계산에 이를 적용하여 암호화된 개인정보를 기반으로 개인정보 유출의 위험 없이신용점수를 계산하는 과정을 제시한다.,"Recently, as machine learning research has been developed, big data analysis gets the limelight. This is because of the increased network connectivity which makes it possible to collect vast amounts of high-quality data as the ingredients of machine learning. Data including sensitive privacy from multiple institutes should be merged and utilized for effective machine learning, but the process can cause a critical problem of private data leakage.This work proposes ‘Homomorphic Machine Learning’ as an information technology solution for a contradiction problem between preserving privacy and making full use of data, which performs machine learning with encrypted data without decryption. Homomorphic encryption is cutting-edge cryptographic technology which enables any operations on computers with encrypted data. It is secure against quantum computer attack. In the situation of data analysis with sensitive private data using homomorphic encryption, machine learning can be performed with no worry of privacy leakage or data loss.Specifically, this work introduces concepts of homomorphic encryption and machine learning with minimal mathematical description for understanding homomorphic machine learning. Also, based on recent works, we investigate possibility of commercialization by analyzing effectiveness of homomorphic encryption which is major obstacle for commercialization.Credit rating requires analysis of private data. As major application, this work shows process of calculating credit rating from encrypted private data without danger of private data leakage."
싸이킷런과 사이버위협 데이터셋을 이용한 사이버 공격 그룹의 분류,2018,"['Machine Learning', 'Sci-kit Learn', 'Cyber Treat', 'Cyber Attack Group', 'Cyber Attack Datasets', '머신러닝', '싸이킷런', '사이버위협', '사이버공격그룹', '사이버공격데이터셋']","최근 IT보안의 화두가 되고 있는 가장 위협적인 공격은 APT공격이다. APT공격에 대한 대응은 인공지능기법을 활용한 대응이외에는 방법이 없다는 것이 현재까지의 결론이다. 여기서는 머신러닝 기법을 활용한 사이버위협 데이터를 분석하는 방법, 그 중에서도 빅데이터 머신러닝 프레임웍인 Scikit Learn를 활용하여 사이버공격 사례를 수집한 데이터셋을 이용하여 사이버공격을 분석하는 머신러닝 알고리즘을 구현하였다. 이 결과 70%에 육박하는 공격 분류 정확도를 보였다. 이 결과는 향후 보안관제 시스템의 알고리즘으로 발전가능하다.","The most threatening attack that has become a hot topic of recent IT security is APT Attack.. So far, there is no way to respond to APT attacks except by using artificial intelligence techniques. Here, we have implemented a machine learning algorithm for analyzing cyber threat data using machine learning method, using a data set that collects cyber attack cases using Scikit Learn, a big data machine learning framework . The result showed an attack classification accuracy close to 70%. This result can be developed into the algorithm of the security control system in the future."
인공신경망(artificial neural network)을 활용한 일반계 고등학생의 비문학 독해 평가에서의 인지진단모형 적용 방안,2018,"['인지진단모형', '머신러닝', '인공신경망', 'Q-행렬', '인지요소별 숙달 프로파일', 'Cognitive diagnosis model', 'Machine learning', 'Artificial neural network', 'Q-Matrix', 'Proficiency profile by cognitive factor']","본 연구는 인지진단모형(Cognitive Diagnosis Model)을 활용한 일반계 고등학생의 독해 평가 분석 결과를 인공신경망을 통하여 그 타당성을 검토하고, 나아가 인공신경망 모형의 머신러닝(Machine Learning)을 구현해보고자 하였다. 이를 위해 먼저, 독해 기능이나 지식과 관련한 인지요소(attribute)를 추출하여 Q-행렬(Q-Matrix)을 개발하고 이를 타당화 하였다. 이렇게 개발된 Q-행렬에 기반하여 독해 평가 도구를 제작하여 시행한 독해 평가 결과를 인지진단모형을 활용하여 비문학 독해 인지요소별 숙달(mastery) 프로파일을 추정하였다.다음으로 실제 평가 결과(Score)와 비문학 독해 인지요소별 숙달 프로파일을 인공신경망 모형의 각각 입력값과 출력값으로 투입하여 머신러닝 과정을 실행함으로써, 인공신경망 모형이 독해 평가결과에 따라 인지요소별 숙달 프로파일을 스스로 추정하는 알고리즘을 개발하고자 하였다.  본 연구의 인공신경망 모형은 훈련데이터 평가결과에 비해 테스트 데이터 평가 결과가 약간이지만 낮은 값을 보여 완전한 머신러닝이 일어나지는 않은 것으로 나타났지만, 예측 정확도가 95%를 넘었고, 카파계수가 0.9(훌륭한 일치도)를 넘었기 때문에 훈련 데이터에 대한 과적합의 결과로 볼 수 없으므로, 머신러닝의 가능성을 제시하였다고 할 수 있다.","This study would examine the validity of the result of an analysis of the evaluation of general high school students’ reading comprehension, utilizing a cognitive diagnosis model through an artificial neural network and implement machine learning of an artificial neural network model. For this purpose, this study first extracted cognitive factors Attributes related to capability or knowledge in reading comprehension, developed Q-Matrix and validated this. This study estimated the mastery profile of each cognitive factor of the reading comprehension of non-literary texts with the result of the evaluation of reading comprehension made by producing a tool for the evaluation of reading comprehension based on the developed Q-Matrix, utilizing a cognitive diagnosis model.Next, by running a machine learning process, putting the result of the actual evaluation Score and the proficiency profile of each cognitive factor of the reading comprehension of non-literary texts into the artificial neural network model, respectively, as the input value and output value, this study would develop an algorithm in which the artificial neural network model itself estimates a proficiency profile by cognitive factor according to the result of the test of reading comprehension. In the artificial neural network model in this study, the result of the evaluation of test data was lower, though slightly than the result of the evaluation of training data, so it turned out that complete machine learning did not take place; however, since prediction accuracy exceeded 95%, and kappa coefficient exceeded 0.9 (Excellent conformity degree), it cannot be considered to be an overfitting result of training data, so it is judged that this study presented the possibility of machine learning."
신경망 기계번역의 작동 원리와 번역의 정확률,2018,"['neural network model', 'NMT', 'machine translation', 'deep learning', 'RNN model', 'translation quality', 'Chinese-Korean NMT', 'accuracy of translation', 'GNMT', 'N2MT', 'Baidu NMT', '신경망 모델', '기계 번역', '심층 학습', 'RNN 모델', '번역 품질', '중국어 한국어 NMT', '번역의 정확성']",,"In this paper, we examined the mechanism of operation of the neural network model(NMT), which is attracting attention in the field of machine translation research.  The NMT model consists of a process in which the computer reads the original text in sentence units and then generates the optimal translation corresponding to the sentence using the parameters obtained by deep learning. In the process of finding the optimal translation there is no need to construct separate translation dictionaries or translation patterns because the computer will learn on its own with parallel corpus. The NMT model is simpler and more general than the existing models.  For the quality of neural network machine translation, research has been conducted mainly on English. However, the research on the translation quality of non-English languages has received relatively little attention. Especially, it is not an exaggeration to say that the study on Chinese - Korean NMT quality has not yet been successful. In this paper, we analyzed how accurately the NMT translates Chinese - Korean sentences. The programs used to evaluate the accuracy of translation are GNMT, N2MT, Baidu NMT. For the translation evaluation, we selected 370 sentences from Chinese textbooks, academic papers, newspapers, TV scripts. And the machine translation results were evaluated in terms of word translation, phrase translation, and sentence translation. According to the result of the evaluation, the accuracy of N2MT and Baidu NMT is higer than that of GNMT for the basic colloquial expressions. However, in translating practical sentences such as newspaper reports, product manuals, web documents, business expressions, and TV conversations, the accuracy of GNMT and N2MT was higher than that of Baidu NMT.  In this paper, we also discussed how to use the NMT effectively. It is true that the NMT model has improved the translation quality. However, it still does not produce very high quality translations for the source texts. It will not be easy for machine translation to completely replace human translation in the future. But machine translation programs can be an excellent aid to human translation. The NMT model learns the translation data on its own and can predict the optimal translation. Therefore, if the NMT model is specialized for the purpose of the translator, it can be used as a convenient translation tool. Developing a translation model based on the neural network theory will contribute to enhancing the accuracy and efficiency of the translation."
그래디언트 부스팅을 활용한 암호화폐 가격동향 예측,2018,"['Price Prediction', 'Cryptocurrency', 'Machine Learning', 'Supervised Learning', 'Gradient Boosting', '가격 예측', '암호화폐', '기계학습', '지도학습', '그래디언트 부스팅']",,"Stock price prediction has been a difficult problem to solve. There have been many studies to predict stock price scientifically, but it is still impossible to predict the exact price. Recently, a variety of types of cryptocurrency has been developed, beginning with Bitcoin, which is technically implemented as the concept of distributed ledger. Various approaches have been attempted to predict the price of cryptocurrency. Especially, it is various from attempts to stock prediction techniques in traditional stock market, to attempts to apply deep learning and reinforcement learning. Since the market for cryptocurrency has many new features that are not present in the existing traditional stock market, there is a growing demand for new analytical techniques suitable for the cryptocurrency market. In this study, we first collect and process seven cryptocurrency price data through Bithumb's API. Then, we use the gradient boosting model, which is a data-driven learning based machine learning model, and let the model learn the price data change of cryptocurrency. We also find the most optimal model parameters in the verification step, and finally evaluate the prediction performance of the cryptocurrency price trends."
4차 산업혁명이 한국인 영어 학습자의 기본적 의사소통능력 발달에 미치는 영향에 관한 비판적 검토,2018,"['fourth industrial revolution', 'artificial intelligence (AI)', 'machine learning (ML)', 'deep learning (DL)', 'construction grammar', 'basic communicative competence']",,"The purpose of this study is to theoretically evaluate the impact of the Fourth Industrial Revolution (e.g., machine learning (ML) and deep learning (DL)) on English education in South Korea. Few studies have investigated to what extent ML/DL technologies have instructional potential for Korean English learners’ development of English proficiency. To this end, this study deals with the four research issues by extensively reviewing previous literature on computer science and SLA theories. First, this study introduces several well-known concepts and architectures of ML/DL for the following discussions. Second, the study critically examines the opinions of those who claim that recent progress in machine translation can dramatically reduce the need for foreign language learning. Third, this study highlights the significance of basic communicative competence in English learning contexts in South Korea, which―as specified by the components and principles of construction grammar―enables Korean English learners to generate sentence-level utterances without resorting to memorized formulaic expressions. Finally, this study presents three types of English learning applications built upon ML/DL techniques whose validities are evaluated from a perspective of basic communicative competence. As a final remark, this study suggests that ML/DL techniques guided by the principles and components of construction grammar should be applied to Korean English learning contexts as a way to develop their basic communicative competence in English."
초연결성의 박물관(Hyper-connected Museum): 테크놀로지 기반의 해외 박물관 서비스 혁신 사례 고찰,2018,"['박물관 3.0', '가상현실기술', '빅 데이터', '인공지능', '머신러닝', '로봇기술', 'Museum 3.0', 'Virtual Reality', 'Big Data', 'Artificial Intelligence', 'Machine Learning', 'Robot Technology']","박물관 3.0 시대(Museum 3.0)’의 도래에 따른 주요 변화를 전망하기 위해, 본 연구는 4차산업혁명의 핵심 기술이 박물관 서비스 혁신에 미치는 영향력을 조명하는데 목적을 두고 있다. 이를 위해 구글 아트 프로젝트, 가상현실기반의 VR 애플리케이션, 버츄얼 휴먼 가이드, VR 인터랙티브 미디어, 빅데이터 기반의 관람객 분석 및 소장품간의 관계성 분석, 머신러닝 기반의 관람객 예측, 인공지능과 머신러닝 기반의 예술작품 분석 및 재생산, 로봇 투어 가이드 등 주요 사례를 문헌 연구를 통해 고찰했다. 한 가지 주지해야 할 사항은 본 연구에서 다룬 테크놀로지 기반의 혁신 서비스 사례는 대부분 외부 연구 기관의 주도 하에 박물관에 적용되었으며, 상용화로 확장되지 못했다는 것이다. 박물관이 테크놀로지 기반의 혁신 서비스를 제공하기 위해서는 테크놀로지에 대한 통찰력과 운영 역량을 갖춘 전문인력 등의 내부 자원을 필수적으로 확보해야 하며, 동시에 박물관의 사명과 관람 경험의 의미에 대한 재성찰이 요구된다.","This study aims to shed light on the impact of technologies such as virtual reality, big data, artificial intelligence, machine learning and robot technology, which are the core technologies of the Fourth Industrial Revolution, on the innovative museum services, and to prospect the forthcoming changes due to the advent of Museum 3.0. To achieve these aims, I review the case studies of Google Art Project, VR applications, the Virtual Human Guide, VR interactive media, big data analyses on visitor and collection, machine learning-based visitor number predicting, artificial intelligence and machine learning-based artwork analysis and reproduction, and robot tour guide through literature research. It is noteworthy that most technology-based innovation services covered in this study are more dependent on external agencies than museum capabilities, and the majority of cases remain in pilot or one-time based operation. Along with the arrival of the era of the Fourth Industrial Revolution, museums need to reinterpret the meaning of the museum 's mission and viewing experience from a variety of perspective before considering the acceptance of technology and its application. In this context, the Fourth Industrial Revolution technologies will present a dynamic paradigm and possibility to museums to create value in viewing experience through technology as well as the philosophical thought of the cultural heritage achieved by mankind."
기계학습 기반 IDS 보안이벤트 분류 모델의 정확도 및 신속도 향상을 위한 실용적 feature 추출 연구,2018,"['IDS', 'Network security', 'false alarm', 'machine learning', 'SVM']","인터넷의 성장과 함께 각종 취약점을 악용한 사이버 공격들이 지속적으로 증가하고 있다. 이러한 행위를 탐지하기 위한 방안으로 침입탐지시스템(IDS; Intrusion Detection System)이 널리 사용되고 있지만, IDS에서 발생하는 많은 양의 오탐(정상통신을 공격행위로 잘못 탐지한 보안이벤트)은 여전히 해결되지 않은 문제로 남아있다. IDS 오탐 문제를 해결하기 위한 방법으로 기계학습 알고리즘을 통한 자동분류 연구가 진행되고 있지만 실제 현장 적용을 위해서는 정확도와 데이터 처리속도 향상을 위한 연구가 더 필요하다. 기계학습 기반 분류 모델은 다양한 요인에 의해서 그 성능이 결정된다. 최적의 feature를 선택하는 것은 모델의 분류 성능 및 정확성 향상에 크게 영향을 미치기 때문에 기계학습에서 매우 중요한 부분을 차지한다. 본 논문에서는 보안이벤트 분류 모델의 성능 향상을 위해 기존 연구에서 제안한 기본 feature에 추가로 10종의 신규 feature를 제안한다. 본 논문에서 제안하는 10종의 신규 feature는 실제 보안관제센터 전문 인력의 노하우를 기반으로 고안된 것으로, 모델의 분류 성능을 향상시킬 뿐만 아니라 단일 보안이벤트에서 직접 추출 가능하기 때문에 실시간 모델 구축도 가능하다. 본 논문에서는 실제 네트워크 환경에서 수집된 데이터를 기반으로 제안한 신규 feature들이 분류 모델 성능 향상에 미치는 영향을 검증하였으며, 그 결과, 신규 feature가 모델의 분류 정확도를 향상시키고 오탐지율을 낮춰주는 것을 확인할 수 있었다.","With the development of Internet, cyber attack has become a major threat. To detect cyber attacks, intrusion detection system(IDS) has been widely deployed. But IDS has a critical weakness which is that it generates a large number of false alarms. One of the promising techniques that reduce the false alarms in real time is machine learning. However, there are problems that must be solved to use machine learning. So, many machine learning approaches have been applied to this field. But so far, researchers have not focused on features. Despite the features of IDS alerts are important for performance of model, the approach to feature is ignored. In this paper, we propose new feature set which can improve the performance of model and can be extracted from a single alarm. New features are motivated from security analyst’s know-how. We trained and tested the proposed model applied new feature set with real IDS alerts. Experimental results indicate the proposed model can achieve better accuracy and false positive rate than SVM model with ordinary features."
단일 클래스 분류기를 사용한 차량 해킹 탐지,2018,"['차량', '해킹', '침입탐지', '단일 클래스 분류', '비지도 학습', '기계학습', 'vehicle', 'hacking', 'intrusion detection', 'one class classification', 'unsupervised learning', 'machine learning']","본 논문에서는 단일 클래스만을 학습하여 차량에 대한 새로운 공격을 탐지한다. 분류 성능 평가를 위해 Car-Hacking 데이터셋을 사용한다. Car-Hacking 데이터셋은 실제 차량의 OBD-II 포트를 통해 CAN (Controller Area Network) 트래픽을 로깅하여 생성된다. 이 데이터셋에는 네 가지 공격 유형이 포함된다. 실험에 사용한 단일 클래스 분류 기법은 정상 클래스만을 학습하여 비정상인 공격 클래스를 분류해내는 비지도 학습이다. 비지도 학습 방법을 사용하는 경우 에 훈련 과정에서 네거티브 인스턴스를 사용하지 않기 때문에 고효율의 분류 성능을 내는 것은 어렵다. 하지만, 비지도 학습 은 라벨이 없는 새로운 공격 데이터를 분류하는데 적합한 장점이 있다. 본 연구에서는 네트워크 침입탐지 시스템에서 서명 기반의 규칙으로 탐지하기 어려운 새로운 공격 유형을 탐지하기 위해 단일 클래스 분류기를 사용한다. 제안 방법은 새로운 공격을 모두 탐지하고 정상데이터에 대해서도 효율적인 분류 성능을 보이는 파라미터 조합을 제시한다.","In this study, we try to detect new attacks for vehicle by learning only one class. We use Car-Hacking dataset, an intrusion detection dataset, which is used to evaluate classification performance. The dataset are created by logging CAN (Controller Area Network) traffic through OBD-II port from a real vehicle. The dataset have four attack types. One class classification is one of unsupervised learning methods that classifies attack class by learning only normal class. When using unsupervised learning, it difficult to achieve high efficiency because it does not use negative instances for learning. However, unsupervised learning has the advantage for classifying unlabeled data, which are new attacks. In this study, we use one class classifier to detect new attacks that are difficult to detect using signature-based rules on network intrusion detection system. The proposed method suggests a combination of parameters that detect all new attacks and show efficient classification performance for normal dataset."
NIDS의 비정상 행위 탐지를 위한 단일 클래스 분류성능 평가,2018,"['침입탐지', '단일 클래스 분류', '비지도 학습', '기계학습', '인공지능', 'Intrusion detection', 'one class classification', 'unsupervised learning', 'machine learning', 'artificial intelligence']","본 논문에서는 단일 클래스만을 학습하여 네트워크 침입탐지 시스템 상에서 새로운 비정상 행위를 탐지하는 것을 목표로 한다. 분류 성능 평가를 위해 KDD CUP 1999 데이터셋을 사용한다. 단일 클래스 분류는 정상 클래스만을 학습하여 공격 클래스를 분류해내는 비지도 학습 방법 중 하나이다. 비지도 학습의 경우에는 학습에 네거티브 인스턴스를 사용하지 않기 때문에 상대적으로 높은 분류 효율을 내는 것이 어렵다. 하지만, 비지도 학습은 라벨이 없는 데이터를 분류하는데 적합 한 장점이 있다. 본 연구에서는 서포트벡터머신 기반의 단일 클래스 분류기와 밀도 추정 기반의 단일 클래스 분류기를 사용 한 실험을 통해 기존에 없던 새로운 공격에 대한 탐지를 한다. 밀도 추정 기반의 분류기를 사용한 실험이 상대적으로 더 좋은 성능을 보였고, 신규 공격에 대해 낮은 FPR을 유지하면서도 약 96%의 탐지율을 보인다.","In this study, we try to detect anomalies on the network intrusion detection system by learning only one class. We use KDD CUP 1999 dataset, an intrusion detection dataset, which is used to evaluate classification performance. One class classification is one of unsupervised learning methods that classifies attack class by learning only normal class. When using unsupervised learning, it difficult to achieve relatively high classification efficiency because it does not use negative instances for learning. However, unsupervised learning has the advantage for classifying unlabeled data. In this study, we use one class classifiers based on support vector machines and density estimation to detect new unknown attacks. The test using the classifier based on density estimation has shown relatively better performance and has a detection rate of about 96% while maintaining a low FPR for the new attacks."
산업군 내 동질성을 고려한 온라인 뉴스 기반 주가예측,2018,"['주가 예측', '텍스트 마이닝', '기계 학습', '다중 커널 학습', '군집 분석', 'Stock prediction', 'Text Mining', 'Machine Learning', 'Multiple Kernel Learning', 'Clustering']",,"Since stock movements forecasting is an important issue both academically and practically, studies related to stock price prediction have been actively conducted. The stock price forecasting research is classified into structured data and unstructured data, and it is divided into technical analysis, fundamental analysis and media effect analysis in detail.  In the big data era, research on stock price prediction combining big data is actively underway. Based on a large number of data, stock prediction research mainly focuses on machine learning techniques. Especially, research methods that combine the effects of media are attracting attention recently, among which researches that analyze online news and utilize online news to forecast stock prices are becoming main.  Previous studies predicting stock prices through online news are mostly sentiment analysis of news, making different corpus for each company, and making a dictionary that predicts stock prices by recording responses according to the past stock price. Therefore, existing studies have examined the impact of online news on individual companies. For example, stock movements of Samsung Electronics are predicted with only online news of Samsung Electronics. In addition, a method of considering influences among highly relevant companies has also been studied recently. For example, stock movements of Samsung Electronics are predicted with news of Samsung Electronics and a highly related company like LG Electronics.These previous studies examine the effects of news of industrial sector with homogeneity on the individual company. In the previous studies, homogeneous industries are classified according to the Global Industrial Classification Standard. In other words, the existing studies were analyzed under the assumption that industries divided into Global Industrial Classification Standard have homogeneity.  However, existing studies have limitations in that they do not take into account influential companies with high relevance or reflect the existence of heterogeneity within the same Global Industrial Classification Standard sectors. As a result of our examining the various sectors, it can be seen that there are sectors that show the industrial sectors are not a homogeneous group. To overcome these limitations of existing studies that do not reflect heterogeneity, our study suggests a methodology that reflects the heterogeneous effects of the industrial sector that affect the stock price by applying k-means clustering. Multiple Kernel Learning is mainly used to integrate data with various characteristics. Multiple Kernel Learning has several kernels, each of which receives and predicts different data. To incorporate effects of target firm and its relevant firms simultaneously, we used Multiple Kernel Learning. Each kernel was assigned to predict stock prices with variables of financial news of the industrial group divided by the target firm, K-means cluster analysis.  In order to prove that the suggested methodology is appropriate, experiments were conducted through three years of online news and stock prices.  The results of this study are as follows. (1) We confirmed that the information of the industrial sectors related to target company also contains meaningful information to predict stock movements of target company and confirmed that machine learning algorithm has better predictive power when considering the news of the relevant companies and target company’s news together. (2) It is important to predict stock movements with varying number of clusters according to the level of homogeneity in the industrial sector. In other words, when stock prices are homogeneous in industrial sectors, it is important to use relational effect at the level of industry group without analyzing clusters or to use it in small number of clusters. When the stock price is heterogeneous in industry group, it is important to cluster them into groups.  This study has a"
화재 예측을 위한 퍼셉트론 기반 가중 유클리디안 거리함수의 최적화,2018,"['machine learning', 'distance function', 'weight learning', 'neural network.', '기계 학습', '거리함수', '가중치 학습', '인공신경망.']","본 논문은 건축물의 건축 관련 정보를 가진 건축물 대장, 건축물이 속한 지역의 행정데이터, 건축물의 에너지 사용량 데이터를 바탕으로 화재건축물과 유사한 건축물을 찾는 거리함수의 가중치(Weight)를 퍼셉트론(Perceptron)을 이용해 학습하는 방법을 제안한다. 화재 데이터의 경우, 속성의 종류가 다양하고 속성 값들의스케일(Scale)의 차이가 커 속성의 중요도를 반영하지 않은 유클리디안 거리함수(Euclidean Distance Function)를 사용하는 것은 적절하지 않다. 따라서 가중 유클리디안 거리함수(Weighted Euclidean Distance Function)를 사용해 거리를 측정한다. 가중 유클리디안 거리함수의 가중치는 각 속성의 속성중요도(Feature Importance)에 따라 부여하거나, 사용자가 임의로 부여한다. 본 논문은 사용자의 가중치 설정 과정 없이 퍼셉트론 학습으로 얻어진 가중치를 거리함수의 가중치로 사용함으로써 화재 건물의 탐지가 가능함을 보인다.","In this work, we propose a method of learning the weights of weighted Euclidean distance function using perceptron learning for fire prediction. In our work, the data used to fire prediction include building data, regional administration data and energy consumption data. When locating fire buildings with distance functions, it is not appropriate to adopt Euclidean distance function with no weights; this is because fire data has various types of features and large difference in scales of feature values. Thus our fire prediction method measures distances between two buildings using weighted Euclidean distance function. The weights of weighted Euclidean distance function can be given according to the feature importance, not depending upon user input. Our experimental result shows that it is possible to locate fire-risk building by using weights obtained by the perceptron learning."
기계학습 기반의 공막 색을 통한 황달 컴퓨터 보조진단 알고리즘,2018,"['Machine Learning', 'Jaundice', 'Computer-aided Diagnosis', 'Non-invasive']",,"This paper proposes a computer-aided diagnostic algorithm in a non-invasive way. Currently, clinical diagnosis of jaundice is performed through blood sampling. Unlike the old methods, the non-invasive method will enable parents to measure newborns’ jaundice by only using their mobile phones. The proposed algorithm enables high accuracy and quick diagnosis through machine learning. In here, we used the SVM model of machine learning that learned the feature extracted through image preprocessing and we used the international jaundice research data as the test data set. As a result of applying our developed algorithm, it took about 5 seconds to diagnose jaundice and it showed a 93.4% prediction accuracy. The software is real-time diagnosed and it minimizes the infant’s pain by non-invasive method and parents can easily and temporarily diagnose newborns’ jaundice. In the future, we aim to use the jaundice photograph of the newborn babies’ data as our test data set for more accurate results."
Resource Prediction for Big Data Processing in a Cloud Data Center,2018,"['Machine learning techniques', 'Data centers', 'Workload forecasting', 'Energy-aware systems', 'Time series data']",,"The high demand for big data applications, such as the Internet of Things (IoT), healthcare, business, and academia, as well as government, fosters the creation of large-scale cloud data centers. Cloud data centers contain thousands of physical machines (PMs), so resource management is necessary for allocating the tremendous amount of data to them. Knowing the workload demand in advance enables control of those resources, saving energy, reducing CPU and memory usage, and improving service. Workload prediction can be used to determine how many resources need to be allocated in the future. In this paper, we propose machine learning–based techniques to predict the daily operational workload. The proposed approach can predict the amount of power consumption (PC) and the number of PMs required to fulfill the demands of the cloud data center. Workload prediction accuracy varies based on the prediction methods used and the type of workload. In this work, we investigate three different methods: polynomial regression, support vector regression, and random forest regression (RFR). Considering both accuracy and computation time, results show that RFR provides the best performance, in our case, with a minimum root-mean-square error of 11.68 for PMs and 4869.08 for PC prediction. The computation time solidifies our selection with 2 seconds training time in all instances."
Adaptive SVM 기법 및 신뢰성 개념을 적용한 강관다단공법의 설계기법 연구,2018,"['강관다단공법', '조절형 써포트벡터머신', '기계학습', '신뢰성기반설계', '터널보강', 'Umbrella arch method', 'Adaptive support vector machine', 'Machine learning', 'Reliability based design', 'Tunnel reinforcement']","본 연구에서는 터널주변 원지반의 불확실성을 고려한 신뢰성기반 강관다단공법의 설계기법에 대하여 논의하였다. 이를 위하여 기계학습기법의 한 부류인 adaptive support vector machine과 시공 중인 터널의 한계평형해석기법을 도입한 후, 강관다단공법을적용한 터널의 안전성 여부에 대한 훈련과정을 최소화할 수 있는 방안을 제안하였다. 제안한 기법은 전형적인 Monte Carlo 기법과의 비교를 통해 그 효과를 분석하였다. 이 결과,제안한 신뢰성기반 ASVM 기법은 원지반의 불확실성을 감안하는 경우, 보조공법 적용에 따른 터널의 시공 중 파괴확률을 효율적으로 계산할 수 있음을 입증하였다. 이 결과를 바탕으로 향후에는 한계평형해석을 적용할 수 없는 경우 등을 감안하여 최소의 수치해석 결과를 바탕으로 파괴확률을 추론해 낼 수 있는 신속 ASVM 기법을 개발할 예정이다.","A reliability based design approach of the tunnel reinforcement with umbrella arch method was considered to better represent the uncertainties of the weak rock properties around the tunnel. For this, a machine learning approach called an Adaptive Support Vector Machine (ASVM) together with the limit equilibrium method were introduced to minimize the iteration numbers during the classification training of the tunnel stability. The proposed method was compared with the results of typical Monte Carlo simulations. It was concluded that the ASVM was very efficient and accurate to calculate the probability of failure having auxiliary umbrella arches and uncertain material properties of the tunnel. Future work will be concentrated on the refinement of the fast adaptation of the SVM classification so that the minimum number of numerical analyses can be used where the limit solution is not available."
특허법상 인공지능 창작물의 발명 해당 여부,2018,"['Artificial Intelligence', 'Machine Learning', 'Creative works made by AI', 'Patent Inventions', 'Article 2 (1) of the Patent Law', '인공지능', '머신러닝', '인공지능 창작물', '발명 성립성', '특허법 제2조 제1항']","우리는 인공지능이 무언가를 만들어내는 시대에 살고 있다. 불과 몇 년 전만 해도 대부분의 사람들은 인공지능이 작곡을 하고 그림을 그린다는 것을 생각하지 못했을 것이다. 똑똑해진 인공지능은 이제 인간의 창조적 영역이라 일컬어지던 음악이나 미술과 같은 예술 분야에서 인간과 유사한 작품을 만들어 낸다. 그 뿐만 아니라 인공지능은 신약 개발이나 컴퓨터 프로그램을 만드는데 있어 일정한 역할을 하고 있다. 본 논문은 이러한 인공지능의 산출물에 대해 인공지능을 인간의 도구로 보아야 할 것인가, 아니면 인공지능이 만들어낸 새로운 작품에 대해 창조성을 인정하여 특허법상 보호되는 발명으로 취급하여야 할 것인가에 대한 의문점에서 시작하였다. 기존에 학계에서 논의되던 내용은 인공지능과 같은 소프트웨어 특허에 초점을 맞추었다면, 본 논문은 인공지능이 만들어내는 산출물에 초점을 맞추어 이를 보호하여야 할 것인지, 보호한다면 어떠한 근거에서 보호를 해야 할 것인지에 대한 논의를 시작해 보고자 하였다. 인공지능이 저작권법에서 다룰만한 예술 분야에서 구체적으로 두각을 나타내는 것과는 달리 인공지능의 산출물을 특허법상 발명으로 보호한다는 주장에 대해서는 상당히 반론이 많을 수 있다. 그럼에도 불구하고 저자가 어찌 보면 뜬구름 잡는 듯 무모할 수 있는 이러한 논의를 하고자 하는 이유는 인공지능에 의해 새롭게 재편될 세계, 특히 인공지능 산출물이 특허법상 발명으로 취급될법한 유의미한 법적 의미를 지닐 가능성이 농후하다는 생각을 가지고 있기 때문이다. 아울러 과거에 비해 기술의 진보 속도는 훨씬 빠르게 이루어짐에도 불구하고 제도를 관장하는 법이 어떠한 현상이 발생한 후에나 사후적으로 대처하는 것에 대한 미진함을 조금이나마 개선하고자 하는 부족한 젊은 법학자의 객기 때문이기도 하다. 인공지능이 발명을 한다는 것은 어찌 보면 허무맹랑한 소설 같은 이야기이나 4차 산업이라는 거대 담론을 이야기하기 전에 멍석을 깔아보려는, 그래서 과학기술의 진흥을 통한 달콤한 과실을 동시대인과 공유하고 싶은 마음이 크다. 본 논문에서는 최근 회자되고 있는 인공지능의 기술적인 특징을 개괄적으로 살펴보았다. 특히 강화학습 방식을 통해 인간의 개입이 없더라도 스스로 새로운 방식을 만들어내는 알파고 제로의 운용원리를 검토하였다. 인공지능과 관련하여 알파고 제로와 같이 인간의 개입 없이 창작물을 만들어 낼 경우, 특허법 제2조 제1호의 개념상 발명에 해당할 가능성이 있다고 생각한다. 현재 제약 산업 분야와 컴퓨터 프로그램 분야에서의 인공지능 활용에서 볼 수 있듯이 인공지능이 스스로의 학습을 통해 새로운 결과물을 창출할 수 있다. 왜냐하면 인공지능이 만들어낸 결과물은 인간의 학습이라는 제약을 뛰어넘어 새로운 수를 도출할 수 있기 때문이다. 머신러닝 과정을 통해 인공지능이 이전에 비해 뛰어나다고 여겨지는 것은 크게 두 가지이다. 첫째는 방대한 데이터 처리과정을 거쳐 스스로 학습하는데 있어 시간과 절대량을 처리할 수 있는 능력이 월등하다는 것, 둘째는 이러한 학습 과정을 거쳐 스스로 특이한 수를 찾아내는데 이것이 인간이었다면 알기 어려운 수라는 것이다. 첫 번째 특징에 대해서 인공지능의 산출물을 특허법상 유의미한 발명이라고 보기는 어려울 수 있다. 이는 기존에 인간이 데이터를 처리하는 컴 ...","We live in an age of artificial intelligence. Nowadays it creates something new. Just a few years ago, artificial intelligence would not have thought of composing and drawing pictures by itself. Smart artificial intelligence produces works similar to human beings in the fields of  music and art, which were estimated as human’s creative area. Artificial intelligence even plays a role in the development of new drugs and computer programs. The paper starts from the question whether artificial intelligence should be regarded as a human tool or artifacts of artificial intelligence should be treated as protected inventions under the patent law.  Thus the paper focuses on the artifacts produced by artificial intelligence and how to protect them. Unlike the protection by copyright law, there would be considerable controversy about the claim that artifacts of artificial intelligence should be protected by patent law. Nevertheless the author intends to insist the necessity of protection because artificial intelligence may have meaningful legal impact. The pace of technological progress is much quicker than that had been in the past. However laws have a tendency of coping with the phenomenon slowly. The author wish to share results through the promotion of science and technology with my contemporaries.  The paper briefly reviewed technical features of artificial intelligence. In particular the author reviewed the operating principles of AlphaGo Zero, which can create a new way without human intervention through reinforcement learning. In the case of artificial intelligence, the creation of artworks without any human intervention is likely to correspond to the conceptual invention of Article 2 (1) of the patent law. Artificial intelligence can create new outcomes through self-learning, as seen in the use of artificial intelligence in the pharmaceutical industry and computer programs. There are two results that could be considered meaningful in the process of artificial intelligence. First, the ability of processing data in aspects of time and amount of data. It is superior than general computers due to self-learning. Second, some unpredicted unique results through its self-learning process. The first result may be difficult to be a meaningful invention under the patent law. However,  the second result may not be handled just as a tool. It is difficult to say that it is a natural phenomenon. If so, the result of artificial intelligence could be protected as inventions under the patent law. Considering the possibility of artificial intelligence technology being used in industries, the paper tried to think about how to look at artificial intelligence output. The author examined whether the patent law could be applied to artifacts of artificial intelligence. Therefore the author reviewed  artificial intelligence related technologies in detail and reviewed the concept of the invention focused on the United States. After that, the author examined whether the concept of invention could be applied to the case of artificial intelligence products that are thought to be meaningful as inventions."
Performance Improvement of Classifier by Combining Disjunctive Normal Form features,2018,"['Object detection', 'ensemble learning', 'adaboost', '2D DNF cell classifier']",,"This paper describes a visual object detection approach utilizing ensemble based machine learning.Object detection methods employing 1D features have the benefit of fast calculation speed. However, for real image with complex background, detection accuracy and performance are degraded. In this paper, we propose an ensemble learning algorithm that combines a 1D feature classifier and 2D DNF (Disjunctive Normal Form) classifier to improve the object detection performance in a single input image. Also, to improve the computing efficiency and accuracy, we propose a feature selecting method to reduce the computing time and ensemble algorithm by combining the 1D features and 2D DNF features. In the verification experiments, we selected the Haar-like feature as the 1D image descriptor, and demonstrated the performance of the algorithm on a few datasets such as face and vehicle."
Performance Improvement of Classifier by Combining Disjunctive Normal Form features,2018,"['Object detection', 'ensemble learning', 'adaboost', '2D DNF cell classifier']",,"This paper describes a visual object detection approach utilizing ensemble based machine learning. Object detection methods employing 1D features have the benefit of fast calculation speed. However, for real image with complex background, detection accuracy and performance are degraded. In this paper, we propose an ensemble learning algorithm that combines a 1D feature classifier and 2D DNF (Disjunctive Normal Form) classifier to improve the object detection performance in a single input image. Also, to improve the computing efficiency and accuracy, we propose a feature selecting method to reduce the computing time and ensemble algorithm by combining the 1D features and 2D DNF features. In the verification experiments, we selected the Haar-like feature as the 1D image descriptor, and demonstrated the performance of the algorithm on a few datasets such as face and vehicle."
행위 시간 간격 기반 게임 봇 탐지 기법,2018,"['Online Game', 'Bot Detection', 'Machine Learning']","온라인 게임 이용자가 증가하고 시장 규모가 커지면서 여러 가지 부정행위가 발생하고 있다. 게임 봇은 플레이 시간을 확보하고, 계정 레벨업과 각종 재화 획득을 용이하게 해주는 대표적인 불법 프로그램이다. 본 연구에서는 이용자의 행위 시간 간격(ATI)을 기반으로 게임 봇을 탐지하는 기법을 제안한다. 이 기법은 게임에서 봇의 행위를 관찰하여 빈도수가 많은 행위를 선별한다. 선별된 행위별로 빈도수, ATI 평균, ATI 표준편차를 feature로 Machine Learning을 적용하여 정상 사용자와 게임 봇을 구분한다. 제안한 기법의 유효성을 검증하기 위해 ‘아이온’ 게임의 실제 로그를 이용하여 성능을 측정하였고, 97%의 정확도를 보였다. 이 방법은 캐릭터의 움직임, 소셜 행위 뿐 아니라 이용자의 모든 행위를 이용할 수 있으므로 다양한 게임에 적용할 수 있다.","As the number of online game users increases and the market size grows, various kinds of cheating are occurring. Game bots are a typical illegal program that ensures playtime and facilitates account leveling and acquisition of various goods. In this study, we propose a method to detect game bots based on user action time interval (ATI). This technique observes the behavior of the bot in the game and selects the most frequent actions. We distinguish between normal users and game bots by applying Machine Learning to feature frequency, ATI average, and ATI standard deviation for each selected action. In order to verify the effectiveness of the proposed technique, we measured the performance using the actual log of the `Aion` game and showed an accuracy of 97%. This method can be applied to various games because it can utilize all actions of users as well as character movements and social actions."
Diagnosis of bearing defects using tunable Q-wavelet transform,2018,"['Bearing defects', 'Features extraction', 'Machine learning techniques', 'Tunable Q-wavelet transform']",,"Defects in rolling element bearings are foremost cause of failure in rotating machines. The accurate and fast diagnosis of bearing defects like spall, dents, pits, cracks etc. on the various component of bearing can be accomplished by analysis of vibration signals using various advanced signal processing techniques. In this work, a new technique for the diagnosis of bearing defects using tunable Qwavelet transform and fractal based features has been presented. The vibration signals have been recorded experimentally. These signals are decomposed into a number of sub-bands using tunable Q-wavelet transform for effective feature extraction. Classical statistical features and fractal dimension based features such as Higuchi fractal dimensions and Katz fractal dimensions are computed for each decomposed sub-band. These features obtained using tunable Q-wavelet transform of vibration signal are having better capability to classify defects through various machine learning algorithms."
CBIR 기반 데이터 확장을 이용한 딥 러닝 기술,2018,"['Content-based image retrieval', 'Data augmentation', 'Deep learning', 'Machine learning']",,"Generally, a large data set is required for learning of deep learning. However, since it is not easy to create large data sets, there are a lot of techniques that make small data sets larger through data expansion such as rotation, flipping, and filtering. However, these simple techniques have limitation on extendibility because they are difficult to escape from the features already possessed. In order to solve this problem, we propose a method to acquire new image data by using existing data. This is done by retrieving and acquiring similar images using existing image data as a query of the content-based image retrieval (CBIR). Finally, we compare the performance of the base model with the model using CBIR."
Determinants of Bank and Non-bank Household Loans and Short- and Long- Horizon Forecast,2018,"['Bank Loan', 'Non-bank Loan', 'Variable Selection', 'Model Selection', '은행권 대출', '비은행권 대출', '변수 선택', '모형 선택']",,"The instability of the ﬁnancial system is likely to occur when par-ticular types of loans surge rather than all types of loans surge at the same time. A preemptive policy response requires a monitoring system based on forecasts by different loan types. The purpose of this study is to forecast household loans by categorizing into four types : bank mortgage loan, bank credit loan, non-bank mortgage loan, and non-bank credit loan. Given the fact that there are numerous determinants and forecasting models for household loans, and that the determi-nants differ depending on the type of household loans, this study sets out the density forecasting algorithm based on Bayesian Machine Learning. which con-sists of a variable learning process, a model learning process, and a forecasting combination process. We ﬁnd bank mortgage loans are largely predicted by the loan rates, the volume of apartments to be moved in, and the number of apart-ment units to be sold. while the key determinants of bank credit loans are the employment rate and Jeon-se price index. On the other hand, the non-bank mort-gage loans are largely determined by the loan rates and the ratio of apartment sales prices relative to Jeon-se prices. The non-bank credit loans are also inﬂu-enced by not only the employment rate and the Jeon-se price index but also stock returns."
Evaluating Pedicle-Screw Instrumentation Using Decision-Tree Analysis Based on Pullout Strength,2018,"['Pedicle screws', 'Pullout strength', 'Osteoporosis', 'Machine learning', 'Decision-support']",,"Study Design: A biomechanical study of pedicle-screw pullout strength.Purpose: To develop a decision tree based on pullout strength for evaluating pedicle-screw instrumentation.Overview of Literature: Clinically, a surgeon’s understanding of the holding power of a pedicle screw is based on perioperative intuition (which is like insertion torque) while inserting the screw. This is a subjective feeling that depends on the skill and experience of the surgeon. With the advent of robotic surgery, there is an urgent need for the creation of a patient-specific surgical planning system.A learning-based predictive model is needed to understand the sensitivity of pedicle-screw holding power to various factors.Methods: Pullout studies were carried out on rigid polyurethane foam, representing extremely osteoporotic to normal bone for different insertion depths and angles of a pedicle screw. The results of these experimental studies were used to build a pullout-strength predictor and a decision tree using a machine-learning approach.Results: Based on analysis of variance, it was found that all the factors under study had a significant effect (p <0.05) on the holding power of a pedicle screw. Of the various machine-learning techniques, the random forest regression model performed well in predicting the pullout strength and in creating a decision tree. Performance was evaluated, and a correlation coefficient of 0.99 was obtained between the observed and predicted values. The mean and standard deviation of the normalized predicted pullout strength for the confirmation experiment using the current model was 1.01±0.04.Conclusions: The random forest regression model was used to build a pullout-strength predictor and decision tree. The model was able to predict the holding power of a pedicle screw for any combination of density, insertion depth, and insertion angle for the chosen range. The decision-tree model can be applied in patient-specific surgical planning and a decision-support system for spine-fusion surgery."
Crack identification in Timoshenko beam under moving mass using RELM,2018,"['crack detection', 'moving mass', 'frequencies', 'regularized extreme learning machine']",,"In this paper, a new method has been proposed to detect crack in beam structures under moving mass using regularized extreme learning machine. For this purpose, frequencies of beam under moving mass used as input to train machine. This data is acquired by the analysis of cracked structure applying the finite element method (FEM). Also, a validation study used for verification of the FEM. To evaluate performance of the presented method, a fixed simply supported beam and two span continuous beam are considered containing single or multi cracks. The obtained results indicated that this method can provide a reliable tool to accurately identify cracks in beam structures under moving mass."
컴퓨터 게임에서 사용자의 감성에 따른 게임 변화 기술,2018,"['Emotion retrieval', 'Game reaction', 'Emotion interaction', 'Machine learning', 'Action units']",,"Recent Information Communication Technology has been rapidly developed compare to the previous years. With the development of computer technology, many researches of intelligent systems are studied that the recognition of human’s emotion is applied to the intelligent computer response. In the 4th industrial revolution, new service type will be implemented by the new way that supports the convenience to the human focused to the user’s emotion. Emotional information and communication technology will develop the interactive communication through the recognition of user’s emotion. The information communication technology recognizes the human’s face into the mobile phone or computer camera and, from the emotion of the human, the system responses intelligent action. This research, first acquires the user’s image and recognizes the emotion through the trained data with the machine learning. The proposed this study classifies seven emotions of game players with competitive action using mobile phone. The classified emotions of players are applied to the game’s rule and interactive game pattern. This intelligent method applied to the real game and the result shows the players response and the future studies."
Acoustic data condensation to enhance pipeline leak detection,2018,"['Leak detection', 'Acoustic signal', 'Data condensation', 'Autocovariance', 'Machine learning']",,"<P><B>Abstract</B></P>  <P>Acoustic monitoring techniques are widely adopted for identifying various leaks from plant facilities to prevent loss of resources and any further structural damages. As the conventional sensing devices have measured acoustic signals at predesignated positions inside or very close to the object being observed, the need for more sophisticated and automated monitoring of more complex infrastructure has increased both the number of sensors to be installed and the amount of data to be analyzed. Thus, in order to diagnose the high-pressure steam leakage efficiently, this research proposes a novel method to find and condense the distinguishable features from the acoustic signals, which are captured by remotely dispersed microphone sensor nodes around a laboratory scale nuclear power plant coolant system. The performance of the proposed method is evaluated by several quantitative metrics resulting from the five state-of-the-art machine learning algorithms, together with the condensed data ratio. Experimental results show that the proposed method can transform the original acoustic signals into a smaller number of featured predictors, even less than ten-thousandths of the original data amount, while improving classification accuracy despite loud machine-driven noises nearby.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  For pipeline leak detection air-borne acoustic signals are remotely captured. </LI> <LI>  A method to find the key predictors that affect leak distinction is presented. </LI> <LI>  Data conversion of the acoustic signals facilitates distinguishing pipeline leaks. </LI> <LI>  Performance metrics are derived by several learning algorithms for classification. </LI> <LI>  Experiments show leaks can be better distinguished using less amount of predictors. </LI> </UL> </P>"
CNN을 이용한 딥러닝 기반 하수관 손상 탐지 분류 시스템,2018,"['딥러닝', 'CNN', 'CCTVs', '인공지능', '손상 탐지', '하수관', 'Artificial Intelligence', 'Deep Learning', 'Demage Detection', 'Sewer Inspection']","연구는 인공지능 분야의 딥러닝 기술을 기반으로 한 하수관 손상의 자동 탐지 분류 시스템을 제안한다. 성능의 최적화를 위하여 DB 획득 시 발생된 조도 및 그림자 변화와 같은 다양한 환경변화에 강인한 시스템을 구현하였다. 제안된 시스템에서는 Convolutional Neural Network(CNN) 기반의 균열 탐지 및 손상 분류 기법을 구현하였다. 최적의 결과를 위하여 256 x 256 픽셀 해상도의 CCTV 영상 9,941개를 이용하여 CNN모델을 적용하여 손상부위에 대한 딥러닝을 수행하였고 그 결과 98.76 %의 인식률을 획득하였다. 기계학습을 통한 딥러닝 모델을 기반으로 다양한 환경의 하수도 DB에서 720 x 480 픽셀 해상도의 646개의 이미지를 추출하여 성능 평가를 수행 하였다. 본 시스템은 다양한 환경에서 구축된 하수관 데이터베이스 에서 손상 유형의 자동 탐지 및 분류에 최적화된 인식률을 제시한다.","We propose an automatic detection and classification system of sewer damage database based on artificial intelligence and deep learning. In order to optimize the performance, we implemented a robust system against various environmental variations such as illumination and shadow changes. In our proposed system, a crack detection and damage classification method using a deep learning based Convolutional Neural Network (CNN) is implemented. For optimal results, 9,941 CCTV images with 256 x 256 pixel resolution were used for machine learning on the damaged area based on the CNN model. As a result, the recognition rate of 98.76% was obtained. Total of 646 images of 720 x 480 pixel resolution were extracted from various sewage DB for performance evaluation. Proposed system presents the optimal recognition rate for the automatic detection and classification of damage in the sewer DB constructed in various environments."
들뢰즈의 기호와 배움을 통해 바라본 유아교사들의 얽힌 되기 : 프로젝트 기반 STEM 교육 중심으로,2018,"['들뢰즈', '얽힌 되기', '기호', '배움', '프로젝트 기반 STEM 교육', 'Deleuze', 'becoming', 'sings', 'learning', 'project-based STEM education']","본 연구는 한 교사공동체에게 프로젝트 기반 STEM교육을 제공하고, 이들이 어떻게 교실 현장에서 이를 실행하는지 그 과정에서 나타난 배움의 과정을 살펴보았다. 특히 들뢰즈의 프로스트와 기호들 에서 기술된 기호의 유형과 연결하여 배움에서 나타난 사유모습을 살펴보았다. 자료 분석은 후기 질적 연구방법에 의해 하였으며, 이를 통해 나타난 결과는 다음과 같다. 첫째, 마주친 기호에 민감한 경우 교사들은 새로운 여정으로 출발할 수 있으며, 그 마주침의 힘과 강도는 개인의 특이성에 따라 다르게 나타났다. 둘째, 배움의 과정에서 교사들은 주로 논리적인 사유를 하며, 들뢰즈가 말한 사교적 기호나 사랑의 기호처 럼 새로운 프로젝트 기반 STEM교육의 기호를 해석하고 있었다. 셋째, 마주침으로 인해 공동체 교사들은 때때로 유목적 사유를 하도록 도전을 받았다. 접속을 통해, 내부 작용을 통해, 혹은 움직임과 실험을 통해 교사들은 연구자, 유아들, 동료 교사들과 함께 얽힌 되기를 경험하였다. 본 연구는 Deleuze의 이론을 통해 유아교사들의 배움의 과정을 새로운 시각으로 살펴본 것에 그 의의가 있다고 하겠다.","This study examined how one teacher community, which consisted of four 4 early childhood teachers, learned the ideas of project-based STEM education and implemented it in their classroom by the ideas in Deleuze’s book“Proust and Signs (French: Marcel Proust et les signes)”. For analyzing the data, it used Barad’s diffractive method. The results are as follows. First, encounter was important for learning. When early childhood teachers encountered a project-based STEM education as a new sign, the power and intensity of encounter influenced to early childhood teachers’participation of teacher learning community. Secondly, a new sign, called“project-based STEM education”, functioned as a machine. Some of these signs, such as worldly signs and signs of love functioned as a tool to search for lost time. Some of these signs, such as sensuous signs and signs of arts functioned as a tool to regain time. The signs of art can reveal the truth of difference. The interpretation of signs proceeds via an unfolding of differences. A sign is a difference that unfolds itself, and its unfolding is an ongoing repetition of its difference. Learning happened to experiment and movement in-between by encounterness. In this process, the members of teacher community become entangled teachers together."
A Fall Detection Technique using Features from Multiple Sliding Windows,2018,"['fall detection', 'wearable sensor', 'multiple sliding windows', 'supervised learning']",,"In recent years, falls among elderly people have gained serious attention as a major cause of injuries. Falls often lead to fatal consequences due to lack of prompt response and rescue. Therefore, a more accurate fall detection system and an effective feature extraction technique are required to prevent and reduce the risk of such incidents. In this paper, we proposed an efficient feature extraction technique based on multiple sliding windows and validated it through a series of experiments using supervised learning algorithms. The experiments were conducted using the public datasets obtained from tri-axial accelerometers. The results depicted that extraction of the feature from adjacent sliding windows led to high accuracy in supervised machine learning-based fall detection. Also, the experiments conducted in this study suggested that the best accuracy can be achieved by keeping the window size as small as 2 seconds. With the kNN classifier and dataset from wearable sensors, the experiments achieved accuracy rates of 94%."
A Feasibility Study on Adopting Individual Information Cognitive Processing as Criteria of Categorization on Apple iTunes Store,2018,"['App Categorization', 'Individual Information Cognitive Processing', 'Latent Semantic Analysis', 'Inter-Rater Reliability', 'TF-IDF', 'SVD', 'Machine Learning']",,"Purpose More than 7.6 million mobile apps could be approved on both Apple iTunes Store and Google Play. For managing those existed Apps, Apple Inc. established twenty-four primary categories, as well as Google Play had thirty-three primary categories. However, all of their categorizations have appeared more and more problems in managing and classifying numerous apps, such as app miscategorized, cross-attribution problems, lack of categorization keywords index, etc. The purpose of this study focused on introducing individual information cognitive processing as the classification criteria to update the current categorization on Apple iTunes Store. Meanwhile, we tried to observe the effectiveness of the new criteria from a classification process on Apple iTunes Store.Design/Methodology/Approach A research approach with four research stages were performed and a series of mixed methods was developed to identify the feasibility of adopting individual information cognitive processing as categorization criteria. By using machine-learning techniques with Term Frequency-Inverse Document Frequency and Singular Value Decomposition, keyword lists were extracted. By using the prior research results related to car app’s categorization, we developed individual information cognitive processing. Further keywords extracting process from the extracted keyword lists was performed.Findings By TF-IDF and SVD, keyword lists from more than five thousand apps were extracted. Furthermore, we developed individual information cognitive processing that included a categorization teaching process and learning process. Three top three keywords for each category were extracted. By comparing the extracted results with prior studies, the inter-rater reliability for two different methods shows significant reliable, which proved the individual information cognitive processing to be reliable as criteria of categorization on Apple iTunes Store. The updating suggestions for Apple iTunes Store were discussed in this paper and the results of this paper may be useful for app store hosts to improve the current categorizations on app stores as well as increasing the efficiency of app discovering and locating process for both app developers and users."
누가 온라인 뉴스에 댓글을 작성하거나 뉴스를 공유하는가?,2018,"['온라인 뉴스', '댓글 작성', '뉴스 공유', '통계 학습', '분류', 'Online news', 'news comments', 'news sharing', 'statistical learning', 'classification']","이 연구는 이용자들의 참여로 만들어지는 온라인 뉴스 문화에 주목하여 뉴스에 댓글을 쓰거나 뉴스를 공유하는 이들이 어떤 사람들인지를 밝히고자 하였다. 댓글이나 공유된 뉴스는 온라인 뉴스 소비에 영향을 주지만 댓글을 쓰고 뉴스를 공유하는 이들이 누구인지는 공개되어 있지 않다. 이에 ‘어떤 사람들이 온라인 뉴스 이용 문화를 만들고 있는지’를 밝혀 온라인 뉴스 문화에 대한 이해를 넓히고자 한다. 이 연구는 가설에서 출발하지 않고 데이터를 출발 지점으로 삼아 현실과 가장 가까운 대답을 얻으려 했다는 점에서 기존 연구들과 차별화된다. 이를 위해 2016년 언론수용자의식조사 데이터를 근거로 로지스틱 회귀분석, 선형/비선형 판별 분석, 의사결정 나무 모형, 랜덤 포레스트, 서포트벡터 머신을 활용한 통계 학습(statistical learning) 방법을 적용하여 댓글 작성자와 뉴스 공유자를 예측하는 최적의 모델을 찾았다. 연구 결과, 랜덤포레스트를 활용하면 댓글 작성자와 공유자를 약 99%, 94%의 정확도로 예측할 수 있었다. 예측 과정을 살펴보면, 댓글 작성자와 뉴스 공유자는 거의 일치하였기 때문에 이들을 ‘온라인 뉴스 문화 주도자’와 같은 하나의 집단으로 보는 것이 타당하다고 여겨진다. 이들은 서명운동이나 기부와 같은 사회 참여가 활발하며 정치적으로 중도 또는 진보에 가까울 경우가 많았으며 학력이 높았다. 또한 전국종합신문 뉴스에 대한 신뢰도가 낮을수록 댓글을 작성하거나 뉴스를 공유할 확률이 높았고, 그 중에서도 언론인의 사회적 영향력이나 전문성이 크다고 인식할수록 뉴스를 공유하는 사람일 확률이 높은 것으로 나타났다. 또한 이들은 SNS나 메시징 서비스 이용에 많은 시간을 소비했으며, 그 중에서도 1인 미디어나 팟캐스트 같은 이용자 참여형 뉴미디어 소비가 많다면 댓글 작성자, SNS와 메시징 서비스, 시사잡지 등 다양한 매체에서 적극적으로 뉴스를 소비한다면 뉴스 공유자일 경우가 많았다.","This study focuses on the online news culture created by users’ participation. It tries to answer the question “Who leaves comments on online news articles or shares news stories with others?” Commenting on news articles and sharing news stories influence news consumption and society at large, but it is not clear who is leaving the comments and sharing the news. This study differs from previous studies because it applies statistical learning in order to obtain the closest answer to reality, not by making assumptions but by using real data. This paper proposes an optimal model for predicting comment writers and news sharers by applying logistic regression analyses, linear/nonlinear discriminant analyses, decision tree models, random forests, and support vector machines. As a result, we could predict the commenters and the sharers with 99% and 94% accuracy, respectively, using random forests. Furthermore, it is reasonable to consider commenters and news sharers the “leaders of the online news culture” because the groups were identified to be almost identical. They were highly educated, politically liberal or moderate, and active in social activities such as signing campaigns and making donations. In addition, people with a lower amount of trust in national news media tended to write comments and share news, and the more socially influential they regard journalists as being, the more likely they are to share news stories. Finally, the leaders of the online news culture spend a significant amount of time on social networking sites and messaging services. Particularly, news commenters consume or participate in new independent media such as podcasts or YouTube videos, and news sharers actively read news from various media, including social networking sites, messaging services, and political magazines."
인공지능에 의한 판사의 대체 가능성 고찰,2018,"['인공지능 판사', '법률 직업 상실', '판결기계', '알고리즘', '대체 가능성', 'Artificial intelligence judge', 'Legal job loss', 'Judgement Machine', 'Algorithm', 'Replaceability']","인공지능 알고리즘에 의한 변화가 각계각층에서 일어나고 있다. 법조 직역도 이런 변화의 예외는 아니다. 특히 인공지능 알고리즘에 의한 법률 서비스의 혁신은 법률서비스 시장의 면모를 일신하고 있고, 그로 인한 긍정적 효과에 대한 기대도 크다. 반면 최근 슈퍼 지능이나 특이점 현상 등을 거론하며 인공지능 알고리즘은 기존의 인간 세계 질서를 파괴하고, 인간을 지배할 위험성이 높으며, 그러한 조짐은 인공지능 알고리즘이 인간이 담당하던 직업을 대체하는 데서 극명하게 드러날 것이라고 믿는 사람이 늘고 있다. 법조 직역에서도조만간 인공지능 알고리즘이 변호사를 대체하여 변호사가 대량 실직할 것이라든가, 심지어인공지능 알고리즘이 판사를 대체할 것이라는 전망까지 나오고 있는 상황이다. 문제는 인공지능 알고리즘을 개발하는 공학자가 아닌 사람들이 이와 같은 전망을 쏟아내고, 확대재생산 된다는 점이다. 현재 수준의 인공지능 알고리즘의 한계를 잘 알고, 개발 과정의 여러가지 난점을 잘 아는 인공지능 개발자 대부분은 인공지능 알고리즘이 인간을 지배하는 상황 같은 것은 꿈도 꾸지 못할 것이라 단언하고 있다.인공지능은 알고리즘에 불과하고, 만능이 아니다. 컴퓨터 프로그램으로 일일이 구현되어야 한다. 구체적으로 코딩을 해주지 않으면 아니 되는 컴퓨터 프로그램에 불과하고, 기계학습이나 강화학습 등을 통해 인간의 예측 범위를 넘는 성능까지 보여주는 일이 없지는않으나, 구체적인 구현 대상은 퀴즈쇼, 바둑이나 아케이드 게임과 같이 명쾌한 규칙을 가진 폐쇄적 환경의 문제 해결에 국한되고, 현실 세계의 복잡한 영역의 문제 해결에서 같은 성과를 거둘 가능성은 희박하며, 앞으로 그런 상황이 쉽게 오지 않을 것이다. 강화학습으로 세상을 깜짝 놀라게 한 DeepMind의 알파고는 여전히 바둑에서만 강세를 보이고 있어 의료용 등으로 활동영역을 넓혀가는 IBM Watson과는 차이가 있다. 그러나 IBM Watson조차특정 영역에 국한하여 성능을 발휘하는 한계가 있어 범용 기계로서의 가능성은 적다.본고에서는 인공지능 알고리즘에 의하여 대체될 것이라는 법조 직역 중 판사 직역의 대체 가능성을 검토하여 보았다. 인공지능에 의한 직업 상실 등을 거론하면서도 어떻게 바뀔것인지에 대한 추측만 난무할 뿐 정작 인공지능 알고리즘으로 어떻게 바꿀 것인지에 대한논의가 없다시피 한 상황에서 인공지능 알고리즘이 판사를 대체할 수 있을 것인가를 판결기계의 구현 가능성으로 타진해보았다. 인공지능 알고리즘이 적용된 판결 기계에 의한 인간 판사의 대체는 기술적 영역의 문제만으로는 충분치 않으며, 사회적 수용 가능성이나 개발 투자라는 난관도 극복하여야 하는데, 현재의 상황에서 이러한 가능성은 거의 없다고 보아야 할 것이다.","Changes by artificial intelligence algorithms are taking place in various layers. The legal domain is also not free from these changes. In particular, the innovation of legal services by artificial intelligence algorithms has renewed the aspect of the legal services market, and the expectation for the positive effects is great. On the other hand, the number of peoples who think artificial intelligence algorithm will dominate the human world has increased, and such an indication will emerge from replacing the profession that human beings were responsible for. It is also expected that artificial algorithms will replace attorneys in law and even artificial intelligence algorithms will replace judges.The problem is that people who are not engineers of artificial intelligence algorithms are pouring out this view. Artificial intelligence developers who knows the limitations of artificial intelligence algorithms and understands the difficulties of the development process do not expect artificial intelligence algorithms to dominate human world.Artificial intelligence is not omnipotent. It is only an algorithm, and it is implemented as a computer program. It is merely a computer program that needs to be specifically coded. Sometimes it also shows performance exceeding human prediction range through machine learning. However, the specific implementation target is a problem of a closed environment with clear rules such as a quiz show, go or a arcade game, and it is difficult to say that the complexity of the real world is the same.In this paper, I look at whether artificial intelligence algorithm could replace the judge.In addition, there is much debate about how the world would change by the artificial intelligence algorithm. However, there is no discussion on how to change the world by artificial intelligence algorithm. I tried to explore the possibility of implementing judgement machine. The substitution of human judges by a judgement machine is not limited to the problem of technical domain, and it should overcome obstacles such as social acceptance problem or development investment problem."
영상 콘텐츠에 나타난 포스트 휴먼 시대 인간과 인공적 타자의 관계성에 관한 연구,2018,"['post-human', '4th industrial revolution', 'AI', 'technology determinism', 'social theory', 'video contents', 'rhyzome', '포스트휴먼', '4차 산업혁명', '인공지능', '기술결정론', '사회구조론', '영상 콘텐츠', '리좀']",,"‘Post human’ means a future human being of existence fusing humankind, technology and machine. Many experts anticipate that the border line dividing human being and machine could be disappeared due to the developments of ICT(Information and Communications Technology), AI(Artificial Intelligence) and bio technology. A lot researches argue that intelligence of computers will outperform that of human being from 2030s and knowledge up-loading technology onto a human brain would be realized from 2040s. In this paper in order to grasp transition trends from present to ‘post human times’, previous studies were searched and analyzed focusing on transition from industrial society to information society. These works have been categorized into ‘technology determinism’ and ‘social theory’. Linking this previous research works, social science approach predicting the changes of social structure of ‘post human times’ was derived as ‘technology utopia,’ ‘human existence (labor) obsolescence’ and ‘extension of capitalism structural contradiction’ as well. Deleuze argued that “arts is another mean of philosophy, gives vitality onto philosophy and has role figuring out a abstract concept onto definite images.” In this paper issues from social science prediction approaches about relationship between human being and artificial intelligence (das andere) were compared with those from video contents. For this purpose four video contents developed made after 2000s were selected. From this analysis artificial intelligence, a self image of human being, from time series of view, functionality of learning, recognition, sentiment, and body have been highlighted with parallel and ‘rhyzome’ in these contents. In addition self-consciousness and mind of artificial intelligence of AI have been realized in video contents, incrementally. Finally self-learning, not by human but by other AI’s were possible in this culture texts. From these results, debates for ‘having a life’ and ‘not having a life’ will be aggravated in the near future."
작성자 분석과 CNN을 적용한 소스 코드 작성자 식별 프레임워크,2018,"['작성자 식별', '작석자 분석', '합성곱 신경망', '기계학습', '코드 분석', 'Author Identification', 'Authorship Analysis', 'Convolutional Neural Network', 'Machine Learning', 'Code Analysis']",,"Recently, Internet technology has developed, various programs are being created and therefore various codes are being made through many authors. On this aspect, some author deceive a program or code written by other particular author as they make it themselves and use other writers' code indiscriminately, or not indicating the exact code which has been used. Due to this makes it more and more difficult to protect the code. In this paper, we propose author identification framework using Authorship Analysis theory and Natural Language Processing(NLP) based on Convolutional Neural Network(CNN). We apply Authorship Analysis theory to extract features for author identification in the source code, and combine them with the features being used text mining to perform author identification using machine learning. In addition, applying CNN based natural language processing method to source code for code author classification. Therefore, we propose a framework for the identification of authors using the Authorship Analysis theory and the CNN. In order to identify the author, we need special features for identifying the authors only, and the NLP method based on the CNN is able to apply language with a special system such as source code and identify the author. identification accuracy based on Authorship Analysis theory is 95.1% and identification accuracy applied to CNN is 98%."
4차 산업혁명 시대 문학의 현재와 미래,2018,"['4차 산업혁명', '인공지능(AI)', '인간성', '창의성', '감성', '윤리성', '딥러닝', '인공지능의 문학 창작', '탈인간주의(Post-Humanism)', 'the 4th Industrial Revolution', 'AI(Artificial intelligence)', 'humanity', 'creativity', 'sensibility', 'affectivity', 'morality', 'Deep-Learning', 'Literature of AI', 'Post-Humanism']","이 글은 이른바 4차 산업혁명 시대를 맞이하여 현 단계 인공지능(AI)이 쓴 문학작품의 문제를 인간성(humanity) 구현의 측면에서 파악하고, 나아가 인공지능의 문학창작의 미래를 전망해 보기 위한 것이다. 이를 위한 논의는 인공지능의 인간성 구현에 초점을 두되, 인간성의세 가지 속성인 3ty, 즉 창의성(creativity), 감성(affectivity/sensibility), 윤리성(morality)의측면에서 인공지능이 쓴 문학작품들을 검토하고자 했다. 인공지능이 쓴 소설과 시나리오는 아직은 인간이 창작한 소설에 비해 상당한 한계를 가지고 있다. 인공지능이 빅데이터에 의한 자료 입력, 딥러닝 기반 언어처리와 논리적 추론을 통해소설과 시나리오 쓰기는 가능한 단계에 이르렀지만, 인간의 개입 없이 100% 독자적인 소설창작은 불가능하다. 기존 소설과 시나리오의 서사 패턴을 분석하여 논리적 추론을 함으로써일정한 분량의 글을 쓸 수 있지만, 그 분량은 매우 짧고 아직 ‘창의적 모방’ 수준을 넘어서지못했다. 따라서 문학 창작을 하는 인공지능을 창작의 주체로 인정할 수 있는 단계에 있지 않다. 인공지능의 시 창작도 소설과 시나리오 창작의 경우와 크게 다르지 않았다. 인공지능의시 창작은 이외로 소설과 시나리오 창작의 경우보다 앞서 이루어졌다. 특정 시인의 시 작품을딥러닝으로 학습한 인공지능이 제시된 사진을 보고 일정한 분량의 시를 창작하거나 인간이제시한 문장에 반응하는 형식으로 시를 창작하는 단계에 있다. 그렇지만 역시 인간의 도움 없이 주체적인 시 창작이 이루어지는 단계는 아니다. 미래 인공지능에 의한 문학 창작은 인간과 같은 창의성을 구현하는 것은 물론 인간적인감성과 윤리성을 토대로 신속하고 다양한 문학 창작이 가능한 수준으로 발전할 수 있다. 그런데 인공지능의 창의성 구현은 비인간적이고 반윤리적인 방향으로 나아갈 위험도 있다. 이에대한 경계심과 적절한 규제가 필요하겠지만, 이제부터 인간과 기계의 협력과 상호 소통을 통한 공생을 추구하는 탈인간주의(Post-Humanism)의 철학을 가져야 할 때이다.","This article aims to understand problems of literary works written by AI at the present stage of the 4th Industrial Revolution in terms of the implementation of humanity and to examine the future of AI's creation. This discussion focuses on the humanity of AI. For this I examined literary works written by AI in terms of three attributes of humanity: creativity, affectivity/sensibility, and morality. Short stories and scenarios written by AI still have considerable limitations compared with man-made works. Although AI has been able to write short stories and scenarios through data input, Deep-Learning based language processing and logical reasoning, it is impossible to create 100% original work without human intervention. It is possible to write a certain amount of articles by analyzing the narrative patterns of existing works and making logical reasoning, but the amount is very short and has not yet exceeded the level of ‘creative imitation’. Therefore, it is not at a stage to recognize AI as the subject of creation. The poetry has a strong subjective nature and emotional action among artistic branches of literature. The poetry creation of AI was done in two ways. One way is that AI creates a poem by seeing photographs presented by human after learned poems of a poet by Deep-Learning. Another way is that AI completes a piece of poem in a way which responds to a line of poem which a person presents. However, it is not a stage in which subjective creation of poetry is done without human help. The AI-based literary creation will develop rapidly in the near future. It is possible to develop creativity that is human-like as well as rapid and diverse literary creation based on human sensitivity and morality. A professional AI artist will appear in the near future. However, the creativity of AI is also in danger of being inhuman and anti-ethical. Appropriate regulations and discipline are naturally necessary. From now on, it is necessary for us to overcome the humanism of rejecting the machine or perceiving the machine as a means and a tool in the human-centered viewpoint. We need to have the post-humanism in pursuit of symbiosis through cooperation and mutual communication between man and machine."
An Intelligent Residual Resource Monitoring Scheme in Cloud Computing Environments,2018,"['Cloud Computing', 'Clustering', 'Computational Intelligence', 'Resource Monitoring']",,"Recently, computational intelligence has received a lot of attention from researchers due to its potential applications to artificial intelligence. In computer science, computational intelligence refers to a machine's ability to learn how to compete various tasks, such as making observations or carrying out experiments. We adopted a computational intelligence solution to monitoring residual resources in cloud computing environments. The proposed residual resource monitoring scheme periodically monitors the cloud-based host machines, so that the post migration performance of a virtual machine is as consistent with the pre-migration performance as possible. To this end, we use a novel similarity measure to find the best target host to migrate a virtual machine to. The design of the proposed residual resource monitoring scheme helps maintain the quality of service and service level agreement during the migration. We carried out a number of experimental evaluations to demonstrate the effectiveness of the proposed residual resource monitoring scheme. Our results show that the proposed scheme intelligently measures the similarities between virtual machines in cloud computing environments without causing performance degradation, whilst preserving the quality of service and service level agreement."
Predicting Corporate Bankruptcy using Simulated Annealing-based Random Forests,2018,"['Simulated Annealing', 'Random Forests', 'Bankruptcy Prediction', 'Feature Selection', 'Business Analytics', '시뮬레이티드 어니일링', '랜덤 포레스트', '부도예측', '특징선택', '비즈니스 애널리틱스']",,"Predicting a company's financial bankruptcy is traditionally one of the most crucial forecasting problems in business analytics. In previous studies, prediction models have been proposed by applying or combining statistical and machine learning-based techniques. In this paper, we propose a novel intelligent prediction model based on the simulated annealing which is one of the well-known optimization techniques. The simulated annealing is known to have comparable optimization performance to the genetic algorithms. Nevertheless, since there has been little research on the prediction and classification of business decision-making problems using the simulated annealing, it is meaningful to confirm the usefulness of the proposed model in business analytics. In this study, we use the combined model of simulated annealing and machine learning to select the input features of the bankruptcy prediction model. Typical types of combining optimization and machine learning techniques are feature selection, feature weighting, and instance selection. This study proposes a combining model for feature selection, which has been studied the most. In order to confirm the superiority of the proposed model in this study, we apply the real-world financial data of the Korean companies and analyze the results. The results show that the predictive accuracy of the proposed model is better than that of the naïve model. Notably, the performance is significantly improved as compared with the traditional decision tree, random forests, artificial neural network, SVM, and logistic regression analysis."
직관적 사고의 교육적 의의와 교수설계에의 시사점,2018,"['intuition', 'intuitive thinking', 'the 4th industrial revolution', 'artificial intelligence', 'instructional design knowledge-base', '직관', '직관적 사고', '4차 산업혁명', '인공지능', '교수설계 지식기반']",,"While technologies of artificial intelligence have been rapidly developed, people have been more interested in human intuition or intuitive thinking of which machine may not be able to have. It would be important, because artificial Intelligence's logical and analytical thinking, relied on big-data and humane intuitive thinking are going to help human beings and machine co-work in near future. This author has studied characteristics of intuitive thinking and examined how the intuitive thinking would provide a new perspective on instructional design. In order to do this study, this author has examined intuition as strong points of human intelligence, and taken sensible, unreasonable, overall, emotional, challenging, self-convicting, and momentary characteristics of intuitive thinking. And this author has explained that intuitive thinking would be accepted for human unreasonableness in future education and it would be an alternative for human personality and dignity not just to be mechanical human. In addition, this author has found that intuitive thinking has provided following implications in instructional design knowledge-base. At first, an instructional designer is a designer with creative, emotional, intuitive design capacity. Secondly, a learner is an intact person who is capable of learning with her or his inner strength. Thus, the instructional design should be based on finding her or his capabilities. Thirdly, educational contents should satisfy a leaner’s desire and would urge her or him for another learning. Fourthly, educational course and practice should foster a broad understanding to look at a big picture, so that there should be generous environment for learners’ minor errors. Fifthly, embodied cognitional strategies should actively be taken to use body sense and emotions. Sixthly, enough media should not be given for learners to think free and to examine small data. Accepting intuitive thinking in instructional design should not exclude reasonable discussion, while it would embrace alternatively unreasonable understanding and experience, such as emotions, imagination, and intuition. It would help to understand totally reasonable and unreasonable characteristics for education, and then provide opportunities to extend to design everyday education without form."
AI에 기반한 중국 철광석가격 조기경보시스템 구축 - AI 기법의 탐색적 적용 -,2018,"['Iron Ore Price', 'Early Warning System', 'AI', 'SVM', 'Random Forest']",,"AI(Artificial Intelligence) has been attracting much attention since the coming out of Alpha Go in 2016. Recently, Economic studies have been actively conducted using AI-based machine-learning and deep-learning models instead of classical time series or regression models. In this paper, I applied the AI technique to the EWS(Early Warning System) for Chinese iron ore import price, which has an important influence on the sound development of Chinese steel industry. The work presented in this paper aims to examine the comparison analysis of the prediction accuracy between the classical signal approach which are mainly used in the contemporary economics and the AI-based SVM(Support Vector Machine) and Random Forest models. And I described the pros and cons of each technique. The results show that the AI models have achieved higher accuracy than signal approaches. So, it is reasonable to think that AI models are more suitable than the traditional models for studies which focus on model’s accuracy, such as EWS. And these models can help steel companies prevent volatility in financial performance by increasing iron ore inventory or using of financial derivatives."
An Intelligent Residual Resource Monitoring Scheme in Cloud Computing Environments,2018,"['Cloud Computing', 'Clustering', 'Computational Intelligence', 'Resource Monitoring']",,"Recently, computational intelligence has received a lot of attention from researchers due to its potential applications to artificial intelligence. In computer science, computational intelligence refers to a machine’s ability to learn how to compete various tasks, such as making observations or carrying out experiments. We adopted a computational intelligence solution to monitoring residual resources in cloud computing environments. The proposed residual resource monitoring scheme periodically monitors the cloud-based host machines, so that the post migration performance of a virtual machine is as consistent with the pre-migration performance as possible. To this end, we use a novel similarity measure to find the best target host to migrate a virtual machine to. The design of the proposed residual resource monitoring scheme helps maintain the quality of service and service level agreement during the migration. We carried out a number of experimental evaluations to demonstrate the effectiveness of the proposed residual resource monitoring scheme. Our results show that the proposed scheme intelligently measures the similarities between virtual machines in cloud computing environments without causing performance degradation, whilst preserving the quality of service and service level agreement."
메모리 추가 신경망을 이용한 희소 악성코드 분류,2018,"['Malware Classification', 'Visualization', 'Memory Augmented Neural Network']","악성코드의 수가 가파르게 증가하면서 기업 및 공공기관, 금융기관, 병·의원 등을 타깃으로 한 사이버 공격 피해사례가 늘어나고 있다. 이러한 흐름에 따라 학계와 보안 업계에서는 악성코드 탐지를 위한 다양한 연구를 진행하고 있다. 최근 들어서는 딥러닝을 비롯해 머신러닝 기법을 적용하는 형태의 연구가 많이 진행되는 추세다. 이 중 합성곱 신경망(CNN: Convolutional Neural Network), ResNet 등을 이용한 악성코드 분류 연구의 경우에는 기존의 분류 방법에 비해 정확도가 크게 향상된 것을 확인할 수 있다. 그러나 타깃 공격의 특징 중 하나는 사용된 악성코드가 불특정 다수를 상대로 광범위하게 퍼뜨리는 형태가 아닌, 특정 대상을 타깃으로 한 맞춤형 악성코드라는 점이다. 이러한 유형의 악성코드는 그 수가 많지 않기 때문에 기존에 연구되어온 머신러닝이나 딥러닝 기법을 적용하기에 한계가 있다. 본 논문은 타깃형 악성코드와 같이 샘플의 양이 부족한 상황에서 악성코드를 분류하는 방법에 대해 다루고 있다. 메모리가 추가된 신경망(MANN: Memory Augmented Neural Networks) 모델을 이용하였고 각 그룹별 20개의 소량 데이터로 구성되어 있는 악성코드 데이터셋에 대해 최대 97%까지 정확도로 분류할 수있음을 확인하였다.","As the number of malicious code increases steeply, cyber attack victims targeting corporations, public institutions, financial institutions, hospitals are also increasing. Accordingly, academia and security industry are conducting various researches on malicious code detection. In recent years, there have been a lot of researches using machine learning techniques including deep learning. In the case of research using Convolutional Neural Network, ResNet, etc. for classification of malicious code, it can be confirmed that the performance improvement is higher than the existing classification method. However, one of the characteristics of the target attack is that it is custom malicious code that makes it operate only for a specific company, so it is not a form spreading widely to a large number of users. Since there are not many malicious codes of this kind, it is difficult to apply the previously studied machine learning or deep learning techniques. In this paper, we propose a method to classify malicious codes when the amount of samples is insufficient such as targeting type malicious code. As a result of the study, we confirmed that the accuracy of 97% can be achieved even with a small amount of data by applying the Memory Augmented Neural Networks model."
은행권 및 비은행권 가계대출 결정요인 분석과 장단기 예측,2018,,"거시건전성 불안은 모든 형태의 대출이 동시에 급증하기 보다는 일부 형태의 대출이 급증할 경우에 야기될 가능성이 높다. 선제적인 정책적 대 응을 위해 대출 형태별 예측을 통한 모니터링 시스템 구축이 요구된다. 본 연 구의 목적은 전체 가계대출을 은행권 주택담보대출(주담보), 은행권 마이너스 통장대출(마통), 비은행권 주담보, 비은행권 마통 등 네 개 유형으로 구분하여 예측하는 것이다. 잠재적인 가계대출 결정요인과 모형이 다수이고 가계대출 의 형태에 따라 결정요인이 상이하다는 점을 감안하여 본 연구는 베이지안 머신 러닝 기반 가계대출 유형 별 분포예측 알고리즘을 제시한다. 본 연구의 베이지안 머신 러닝 알고리즘은 변수 학습과정, 모형 학습과정, 예측 조합과 정으로 이루어진다. 예측 결과, 은행권 주택담보대출은 주로 대출금리, 아파트 입주물량, 분양물량 등에 의해 예측가능하며, 은행권 마통은 취업률과 전세가 격지수가 주요 예측변수로 작용하였다. 반면, 비은행권 주담보는 대출금리와 아파트 매매전세가비율 등에 의해 주로 결정되며, 비은행권 마통도 취업률, 주가 수익률과 더불어 전세가격지수의 영향을 많이 받는 것으로 추정되었다. 각 형태별 가계대출은 높은 지속성으로 인해 향후에도 현재와 유사한 수준의 증가율을 보일 것으로 예측된다. 다만 예측치에 내재된 불확실성이 상당하기 때문에 정책당국은 이러한 점을 반드시 고려하여야 한다.","The instability of the ﬁnancial system is likely to occur when particular types of loans surge rather than all types of loans surge at the same time. A preemptive policy response requires a monitoring system based on forecasts by different loan types. The purpose of this study is to forecast household loans by categorizing into four types:bank mortgage loan, bank credit loan, non-bank mortgage loan, and non-bank credit loan. Given the fact that there are numerous determinants and forecasting models for household loans, and that the determinants differ depending on the type of household loans, this study sets out the density forecasting algorithm based on Bayesian Machine Learning. which consists of a variable learning process, a model learning process, and a forecasting combination process. We ﬁnd bank mortgage loans are largely predicted by the loan rates, the volume of apartments to be moved in, and the number of apartment units to be sold. while the key determinants of bank credit loans are the employmentrateandJeon-sepriceindex.Ontheotherhand,thenon-bankmortgage loans are largely determined by the loan rates and the ratio of apartment sales prices relative to Jeon-se prices. The non-bank credit loans are also inﬂuenced by not only the employment rate and the Jeon-se price index but also stock returns."
인공지능을 이용한 신규간호사 이직률 예측,2018,"['인공지능', '텐서플로우', '신규간호사', '전략적 인적자원관리', '이직률', 'Artificial intelligence', 'Tensorflow', 'New nurses', 'Strategic human resources management', 'Turnover rates']","본 연구에서는 인공지능 기술 중 구글에서 개발하여 오픈소스로 제공하고 있는 텐서플로우(Tensorflow) 활용하여 신규간호사 이직률을 예측해 보았고, 이를 통해 전략적 인적자원관리 방안을 제시하였다. 부산지역 한 대학병원의 2010년에 서 2017년 사이 퇴직한 간호사 데이터 1,018건을 수집하였다. 학습에 사용된 자료는 순서를 임의로 재배열 한 뒤 전체 데이터 의 80%를 학습에, 나머지 20%를 테스트에 이용하였다. 활용된 알고리즘은 다중신경망회로(multiple neural network)로서 입력층과 출력층, 3개 층의 은닉층을 가지도록 설계 되었다. 본 연구의 결과 텐서플로우 플랫폼을 활용하여 1년 이내 이직률 을 88.7%, 3년 이내 조기 이직률은 79.8%의 정확도로 예측하였고, 대상자들의 퇴직 시 연령은 20대 후반부터 30대에 집중되 어 있었다. 가장 높은 빈도를 차지한 이직 사유로는 ‘결혼, 출산, 육아, 가정 및 개인사정’이었으나, 근무기간 1년 이하 대상자 들의 가장 높은 이직사유는 ‘업무 부적응 및 대인관계 문제’로 나타났다.","In this study, authors predicted probability of resignation of newly employed nurses using TensorFlow, an open source software library for numerical computation and machine learning developed by Google, and suggested strategic human resources management plan. Data of 1,018 nurses who resigned between 2010 and 2017 in single university hospital were collected. After the order of data were randomly shuffled, 80% of total data were used for machine leaning and the remaining data were used for testing purpose. We utilized multiple neural network with one input layer, one output layer and 3 hidden layers. The machine-learning algorithm correctly predicted for 88.7% of resignation of nursing staff with in one year of employment and 79.8% of that within 3 years of employment. Most of resigned nurses were in their late 20s and 30s. Leading causes of resignation were marriage, childbirth, childcare and personal affairs. However, the most common cause of resignation of nursing staff with in one year of employment were maladaptation to the work and problems in interpersonal relationship."
제4차 산업혁명과 문학의 테크놀로지,2018,"['제4차 산업혁명', '인공지능', '사물인터넷', '문학', '문학의 테크놀로지', '김애란', '<어디로 가고 싶으신가요>', 'The Fourth Industrial Revolution', 'artificial intelligence', 'internet of things', 'literature', 'literary technology', 'Kim Ae-Ran', '``Where Would You Like To Go?``']","이 글은 제4차 산업혁명으로 통칭되는 인공지능을 중심으로 한 기술 혁신이 문장 및 문학의 데이터화와 패턴화를 용이하게 할 것이라는 전제 하에 문학이 이러한 변화에 어떻게 대응할 수 있는지에 대한 문제에 대해 숙고하고자 했다.제4차 산업혁명은 언어와 문장 일반을 데이터로서 수월하게 취급할 수 있도록 하는 전례 없는 기술 혁신의 가능성을 제시했다. 따라서 제4차 산업혁명에 대해 양산되고 있는 문장들 또한 인공지능에 의해 자동적으로 기계학습, 취합 분석되어 빅데이터로 환원될 것이다. 그것이 제4차 산업혁명이 명확한 실체를 갖는 것처럼 사람들의 뇌리 속에 자리 잡도록 하는 과정을 부추기게 된다. 이러한 과정은 제4차 산업혁명을 지지하는 담론이 언제나 내기에 승리하도록 설정되어 있는 기계장치의 일부 같은 것으로 작용하고 있다. 그리고 그것은 해당 슬로건을 통해 정부의 행정력을 실질적으로 움직이고 기업의 자본을 집중시키는 실정적인 힘으로 작용하게 될 것이다.오늘날의 기술 혁신은 또한 문학(예술) 등의 분야를 인공지능에 의해 패턴화될 수 있도록 하는 전례 없는 가능성을 제시하고 있다. 이에 대해 문학(예술)을 창의성이라는 인간 고유의 감성적 역량에 입각한 영역에 귀속시키는 식으로 그것을 둘러싼 인간의 다양한 욕망, 실천, 담론 등이 획일화되고 단순화될수록, 문학(예술) 일반은 인공지능에 의해 분석 가능한 대상으로 환원될 것이다. 그러한 기술적 여건은 충분히 조성되어 있으며 데이터 또한 축적되어 있다. 단지 자본이 본격적으로 투자되지 않고 있을 뿐이다.우리는 이미 포스트휴먼-사이보그(기계+인간)로서 살아가지 않을 수 없게 된지 이미 오래다. 인공지능이 인간을 능가할지도 모른다는, 그것이 초래할 전례 없는 자동화에 기초한 생산성 향상에 의해 인간이 노동의 저주로부터 해방된다거나 완전히 소외되어버릴 지도 모른다는 식의 낙관과 불안을 아울러 부추기는 제4차 산업혁명에 관한 통념은, 예술과 창의, 노동을 중심으로 한 인간 본유의 영역이 존재하며 또한 그것에 계속해서 의존하지 않으면 안 된다는 환상 속에 그러한 사실을 은폐하고 있다. 그러한 휴머니즘적 환상 속에 자족하는 동안, 사전 조사나 데이터 분석, 커뮤니케이션 및 생산-유통의 전 과정 속에서 인력의 노동을 제거하여 노동 없는 자본의 영구 작동과 무한 증식을 향락하고자 하는 자본가들의 오랜 욕망은, 국가의 과학기술 정책을 비롯한 모든 비인격적 장치와 연동된, 은밀한 개입을 멈추지 않을 것이다.그러므로 우리는 제4차 산업혁명이라는 슬로건에 계속해서 고착되어 있기보다 오늘날 인간+기계로서의 조건을 부지불식간 수긍하도록 하는 비인격적 장치의 개입과 작동이 이루어지는 양상에 보다 주의를 기울여야 한다. 우리는 그것이 미지의 영역과 간극의 형태로 본격적으로 주어졌다는 사실을 냉철하게 성찰할 필요가 있다. 그리고 인간과 기계의 상호 보완적·규정적 관계 속에서 그 미지의 영역과 간극이 어떻게 작용하는지를 확인할 필요도 있다. 김애란의 단편 <어디로 가고 싶으신가요>는 이러한 문제에 대해 우리가 어떻게 대응할 수 있는가와 같은 문제를 성찰하는 데 있어서 문학이 여전히 유효한 형식이라는 사실을 단적으로 보여주는 사례다.","This article examines the problem of how literature can cope with such changes, assuming that artificial intelligence - based innovation, collectively known as the Fourth Industrial Revolution, will facilitate the dataization and patterning of sentences and literatures.The Fourth Industrial Revolution presented the possibility of unprecedented technological innovation that makes it easy to treat language and sentence general as data. Therefore, sentences that are mass-produced for the Fourth Industrial Revolution will also be automatically converted to Big Data by machine learning, synthesis analysis by artificial intelligence. It will stimulate the process by which the Fourth Industrial Revolution is positioned in the minds of people as if they have a clear reality. This process is acting as part of a mechanism in which discourses supporting the Fourth Industrial Revolution are always set to win games. And that slogan will act as a practical force to substantially move the government’s administrative power and to focus corporate capital.Today’s technological innovation also offers unprecedented possibilities to enable artificial intelligence to pattern fields such as literature(art). In this regard, as literature(art) is attributed to the domain based on the human’s own emotional capacity of creativity, and as the various desires, practices, and discourses around it become uniform and simplified, it will be reduced to an analytical target. Such technical conditions are well developed and data is also accumulated. Only capital is not invested in earnest.We have long since lived as post-human-cyborgs(machines +humans). The common sense of the Fourth Industrial Revolution, that artificial intelligence might outweigh humans, and the productivity increase based on the unprecedented automation that it will bring will liberate man from the curse of labor or vice versa, conceals such facts in the fantasy that the realm of human beings, centering on art, creativity and labor, exists as reality and continues to depend on it. While we feel self-satisfaction to such humanistic fantasies, the capitalist who wishes to endure the permanent operation and infinite proliferation of labor-free capital by eliminating all the labor of labor in the whole process of preliminary investigation, data analysis, communication and production-distribution. The long desire of the capitalist will not stop the covert intervention, which is linked to all non-person devices, including the state’s science and technology policy.Therefore, rather than sticking to the slogan of the Fourth Industrial Revolution, we pay more attention to the way in which all non-person devices intervene and operate in a way that allows us to accept the conditions of human+machine today without any sense of discomfort. We need to calmly reflect on the fact that it was given in earnest in the form of an unknown territory and gap. It is also necessary to confirm how the unknown area and gap work in the complementary and regulatory relationship between man and machine. Kim Ae-Ran’s short story, “Where Would You Like To Go?” is an example of the fact that literature is still a valid form of reflection on issues such as how we can respond to these problems."
"인공지능 시대의 예술과 창의성: - 규칙과 변형, 그리고 맥락화",2018,"['인공지능 예술 프로젝트', '알고리즘', '디지털 아트', '인터랙티브 아트', '창의성', 'projet des arts et des intelligences artificielles', 'algorithme', 'art num&eacute', 'rique', 'art interactif', 'creativite']",,"Big data, Deep Learning et une technologie d’intelligence artificielle ont été développés et des expériences sont menées aux années 2010 dans le domaine des arts pour voir si la production automatique d’œuvres d’art est possible avec un programme informatique. Un programme créé en analysant le style de l’artiste grâce à la technologie de l’I.A. prend la place importante. Des résultats sont produits automatiquement sans intervention humaine. Il est maintenant possible de produire des œuvres post-artistes que l’on a une difficulté de les distinguer des œuvres originales. Des recherches et des expériences ont été menées dans divers domaines et les résultats évoluent à un rythme étonnamment rapide. La transition vers le paradigme numérique et le développement de la technologie de l’I.A. exigent de nouveaux concepts de créativité dans le domaine des arts. Dans ce contexte, cet article se concentre sur le principe de la création artistique de l’intelligence artificielle avec un exemple du projet Flow Machines de Sony CSL Paris. Nous examinons le concept d’algorithmes après la réflexion sur le projet Flow Machines. Les algorithmes ne sont pas appliqués uniquement dans l’ère du numérique et de l’I.A., mais cela est déjà apparu dans l’histoire de l’art, comme un « travail d’algorithmes pré-informatique ». Nous aimerions réfléchir à la créativité à l’ère de l’intelligence artificielle en prenant un exemple d’art algorithmique interactif, Life Writer de Laurent Mignonneau et Christa Sommerer en tant que nouveau type de l’œuvre dans lequel des algorithmes sont introduits. Le but de cette étude est de découvrir que la créativité de l’art ne résulte pas d’un « consensus » mais plutôt d’un « dissensus » et qu’il est nécessaire de prêter plus d’attention au « principe » de la création qu’au « résultat » de la création à l ère de l’intelligence artificielle."
An Intelligent System Approach for Probabilistic Volume Rendering Using Hierarchical 3D Convolutional Sparse Coding,2018,,,"<P>In this paper, we propose a novel machine learning-based voxel classification method for highly-accurate volume rendering. Unlike conventional voxel classification methods that incorporate intensity-based features, the proposed method employs dictionary based features learned directly from the input data using hierarchical multi-scale 3D convolutional sparse coding, a novel extension of the state-of-the-art learning-based sparse feature representation method. The proposed approach automatically generates high-dimensional feature vectors in up to 75 dimensions, which are then fed into an intelligent system built on a random forest classifier for accurately classifying voxels from only a handful of selection scribbles made directly on the input data by the user. We apply the probabilistic transfer function to further customize and refine the rendered result. The proposed method is more intuitive to use and more robust to noise in comparison with conventional intensity-based classification methods. We evaluate the proposed method using several synthetic and real-world volume datasets, and demonstrate the methods usability through a user study.</P>"
텍스트 및 영상의 멀티모달분석을 이용한 트위터 사용자의 감성 흐름 모니터링 기술,2018,"['융합', '트위터 사용자 분석', '멀티모달 분석', '감성흐름 모니터링', '서포트벡터머신', '문맥인식', 'Convergence', 'Twitter user recognition', 'multi-modal analysis', 'mood trend monitoring', 'support vector machine', 'context recognition']","본 논문은 개인 사용자의 트윗을 분석하여 사용자의 감정 흐름을 모니터링할 수 있는 새로운 방법을 제안한다. 본 논문에서는 사용자의 감성 흐름을 정확하게 예측하기 위해서 기존의 텍스트 위주의 시스템과 달리 본 연구에서는 사용자가 쓴 텍스트와 영상 등으로부터 감성을 인식하는 멀티 모달 분석 기법이 개발된다. 제안된 방법에서는 먼저 어휘분석 및 문맥을 이용한 텍스트분석기와 학습기반의 영상감성인식기를 이용하여 텍스트 및 영상 트윗에 숨겨진 개별 감성을 추출한다. 이후 이들은 규칙기반 통합 방법에 의해 날짜별로 통합되고, 마지막으로 개인의 감성흐름을 보다 직관적으로 관측할 수 있도록 감성흐름그래프로 시각화한다. 제안된 방법의 효용성을 평가하기 위해 두 단계의 실험이 수행되었다. 먼저 4만여 개의 트윗으로부터 제안된 방법의 정확도 평가 실험이 수행되고, 최신 트윗 분석 기술과 비교 분석되었다. 두 번째 실험에서는 40명의 우울증을 가진 사용자와 일반사용자를 구분할 수 있는지에 대한 실험이 수행된 결과, 제안된 기술이 실제 사용자의 감성흐름을 모니터하는데 효율적임을 증명하였다.","In this paper, we propose a novel method for monitoring mood trend of Twitter users by analyzing their daily tweets for a long period. Then, to more accurately understand their tweets, we analyze all types of content in tweets, i.e., texts and emoticons, and images, thus develop a multimodal sentiment analysis method. In the proposed method, two single-modal analyses first are performed to extract the users’ moods hidden in texts and images: a lexicon-based and learning-based text classifier and a learning-based image classifier. Thereafter, the extracted moods from the respective analyses are combined into a tweet mood and aggregated a daily mood. As a result, the proposed method generates a user daily mood flow graph, which allows us for monitoring the mood trend of users more intuitively. For evaluation, we perform two sets of experiment. First, we collect the data sets of 40,447 data. We evaluate our method via comparing the state-of-the-art techniques. In our experiments, we demonstrate that the proposed multimodal analysis method outperforms other baselines and our own methods using text-based tweets or images only. Furthermore, to evaluate the potential of the proposed method in monitoring users’ mood trend, we tested the proposed method with 40 depressive users and 40 normal users. It proves that the proposed method can be effectively used in finding depressed users."
회전 포레스트 분류기법을 이용한 HEVC 스크린 콘텐츠 화면 내 부호화 조기분할 결정 방법,2018,"['HEVC', 'Screen Content Coding', 'Rotation Forest', 'Decision Tree Learning']",,"This paper presents a fast partition decision framework for High Efficiency Video Coding (HEVC) Screen Content Coding (SCC) based on machine learning. Currently, the HEVC performs quad-tree block partitioning process to achieve optimal coding efficiency. Since this process requires a high computational complexity of the encoding device, the fast encoding process has been studied as determining the block structure early. However, in the case of the screen content video coding, it is difficult to apply the conventional early partition decision method because it shows different partition characteristics from natural content. The proposed method solves the problem by classifying the screen content blocks after partition decision, and it shows an increase of 3.11% BD-BR and 42% time reduction compared to the SCC common test condition."
수공예를 통한 여성의 직업의식과 정체성 표출,2018,"['여성 수공예', '여성 정체성', '전문기술', '편물', '양장점', '주단', 'Female handicraft', 'female identity', 'a knitting machine', 'fashion house', 'hanbok']","침선, 매듭, 자수와 같은 수공예는 우리나라 전통 유교 사회였던 과거부터 일반 여성이 갖추어야 할 필수 덕목이자 기예로 여겨져 왔다. 생활용품을 자급자족하기 위해 여성이라면 익혀야 했던 ‘일상’인 수공예는 일제강점기기와 경제개발 · 산업화시기를 거치며 ‘기술’로 거듭나게 된다. 우리나라의 경제개발 시기는 해방, 6 · 25전쟁, 군사정변 등 굴곡의 역사를 거치고 빠른 시간 내에 이루어졌다. 교육에서 소외되었던 여성들은 생업전선에 내몰리게 되었고, 가계를 위해 가정 내 남성의 성공을 위해 자신을 포기하고 뒷바라지했다. 이러한 배경속에서 수공예 기술은 여성들에게 사회로 나가 일자리를 잡고 소득을 창출할 수 있는 수단을 제공하였다.  여성들은 경제개발 · 산업화시기에도 끊임없이 활동하고 소득을 취하여 가정을 책임졌다. 하지만 이런 여성들의 활동은 주목받지 못했다. 재봉틀의 등장으로 직접 손으로 하는 손바느질은 줄어들었지만, 여성 수공예는 여전히 사라지지 않고 이어지고 있다. 기성복과 공산품의 등장에도 여전히 수공예가 유지되고 있다. 그것은 여성들이 변화하는 사회적 상황에 맞춰 능동적이고 적극적으로 대처하고자 했기 때문이다. 또한 어머니에게서 딸로 전해지는 여성 전승의 문화인 수공예가 함축하고 있는 사회 · 문화적 의미가 여전히 이어지고 있기 때문이다. 지금까지 가정 내 여성들의 일상으로 치부되었던 수공예에 대한 재인식과 관심이 필요하다.  본고에서는 경제개발 · 산업화시기 여성들을 연구대상자로 선정하여 기술로서의 수공예가 그들에게 어떤 의미이고 어떻게 삶에 활용되었는지 조사하였다. 그리고 수공예를 통해 추구했던 여성상과 여성 정체성에 대해 살펴보았다.","A tradition in Korean Confucian society, handicrafts such as needlework, knotting methods, and embroidery have been considered essential virtues and skillsets that women should possess. Handicraft, which women needed to learn to be ‘self-sufficient’ during daily life, was technologically reborn during a period of economic development, industrialization, and through the Japanese occupation of Korea. The majority of the economic development happened in a short period of time during which events such as the 1) liberation of Korea from Japan occupation, 2) Korean War of 1950, and 3) post-war military dictatorship/rule by military officers brought women whom had all made personal sacrifices (to support the success of their male counterparts) and were marginalized in education to the forefront of the businesses. Women introduced to business world, they obtained a means of gaining effective employment and earning income through their handicraft skills. Regular use their handicraft skills resulted in the progressive evolution of handicraft techniques throughout Korea.  Korean women remained very active during these times of economic development and industrialization by earning income and assuming responsibility for the family’s finances. However, the majority of responsibilities held by women went largely unnoticed by the rest of the country. Hand sewing was largely replaced the emergence of the sewing machine. However, hand sewing remained as a critical talent within the skillset of many women. Even in today’s world of machined (i.e., sewing machine) clothing products previously pulled together by hand (manually), handicrafts continue to maintain a presence in Korea’s “ready-to-go” wear and industrial products mainly as a result of generations adjusting to the handicraft needs of their social environments/cultures and by continuing to abide by the tradition of passing the skills from generation to generation (i.e., mother to daughter). Due to the negligence of handicrafts in previous generations, it is crucial in today’s culture to re-recognize and re-incorporate these skills (i.e., hand sewing, needlework, and embroidery) into the daily lives of Korean women.  This thesis follows selected women in the period of economic development (discussed above) as subjects of study on how the advancement of technology in the field of handicrafts has impacted their lives."
차량 후측방 경보시스템을 위한 24 ㎓ 레이더 기반 차량 및 보행자 분류기법 개발,2018,"['24㎓ radar', 'RCTA', 'pedestrian', 'classification', 'doppler spectrum', 'linear discriminant analysis']",,"This paper proposes a method for distinguishing between pedestrians and vehicles using 24 ㎓ radar measurements and a machine-learning algorithm. In order to effectively detect moving objects, a radar signal processing algorithm based on frequency-shift keying is implemented on the embedded system equipped with filtering and amplification circuits. A Kalman Filter-based tracking algorithm is used to reject radar clutter noise and improve the identification of moving objects. Various features are obtained from a sample radar data set and linear discriminant analysis is applied to obtain a linear transformation matrix which can effectively discriminate between vehicles and pedestrians based on these features in real time. The proposed method is validated through the use of experimental data sets, exhibiting a level of performance suitable for vehicle rear cross-traffic alert systems."
An Intelligent Residual Resource Monitoring Scheme in Cloud Computing Environments,2018,"['Cloud Computing', 'Clustering', 'Computational Intelligence', 'Resource Monitoring']",,"Recently, computational intelligence has received a lot of attention from researchers due to its potentialapplications to artificial intelligence. In computer science, computational intelligence refers to a machine’sability to learn how to compete various tasks, such as making observations or carrying out experiments. Weadopted a computational intelligence solution to monitoring residual resources in cloud computing environments. The proposed residual resource monitoring scheme periodically monitors the cloud-based host machines, sothat the post migration performance of a virtual machine is as consistent with the pre-migration performanceas possible. To this end, we use a novel similarity measure to find the best target host to migrate a virtualmachine to. The design of the proposed residual resource monitoring scheme helps maintain the quality ofservice and service level agreement during the migration. We carried out a number of experimental evaluationsto demonstrate the effectiveness of the proposed residual resource monitoring scheme. Our results show thatthe proposed scheme intelligently measures the similarities between virtual machines in cloud computingenvironments without causing performance degradation, whilst preserving the quality of service and servicelevel agreement."
한국어 의미역 인식을 위한 서술성 명사의 자동처리 연구,2018,"['Semantic recognition(의미역 인식)', 'Predicative noun(서술성 명사)', 'Q&amp', 'A system(질의응답시스템)', 'Word distribution(어휘 분포)', 'Corpus(코퍼스)', 'Language Processing(언어처리)']",,"This paper proposed a method of semantic recognition to improve the extraction of correct answers of the Q&A system through machine learning. For this purpose, the semantic recognition method is described based on the distribution of predicative nouns. Predicative noun vocabularies and sentences were collected from Wikipedia documents. The predicative nouns are typed by analyzing the environment in which the predicative nouns appear in sentences. This paper proposes a semantic recognition method of predicative nouns to which rules can be applied. In Chapter 2, previous studies on predicative nouns were reviewed. Chapter 3 explains how predicative nouns are distributed. In this paper, every predicative nouns that can not be processed by rules are excluded, therefore, the predicative nouns noun forms combined with the case marker ‘의’ were excluded. In Chapter 4, we extracted 728 sentences composed of 10,575 words from Wikipedia. A semantic analysis engine tool of ETRI was used and presented a predicative nouns noun that can be handled semantic recognition language."
비지니스 이메일 영작문에 나타난 오류분석: 사례연구,2018,"['오류분석', '영작문', '이메일 영작문', '영작문지도', '동료피드백', 'error analysis', 'English writing', 'email writing', 'writing instruction. peer feedback']","본 연구는 번역기를 활용한 영작문 수업에서 대학생들이 작성한 비즈니스 이메일 영작문에 나타난 오류를 분석하고 설명하려는 연구이다. 연구는 취업실무영어 수업을 수강한 대학생들이 3가지 과제에 대해 작성한 21개 이메일을 분석하여 이에 나타난 문법오류를 분석 정리하였다. 이메일에 나타난 문법오류를 살펴보면, 동사의 용법을 제대로 알지 못해서 발생한 언어 내 오류가 가장 빈번했으며, 완료 시제를 사용해야 하는 문장에서 과거동사를 사용하는 시제에 관한 오류와 명사 앞에 정관사를 사용하지 않은 정관사 오류와 전치사 잘못 사용한 오류와 같은 언어 간 오류도 있었다. 문맥과 관련된 오류를 보면 지칭하는 명사에 맞게 단 복수대명사를 제대로 사용하지 못한 오류라던가, 문장을 연결하다가 생략할 수 없는 주어를 생략한 오류는 의미전달에 문제가 될 수 있는 심각한 오류이다. 이러한 오류분석을 통하여 영어를 학습하고 있는 학습자가 특정한 문법사항을 학습하는 데에 어려움을 겪고 있다는 것과 학생들의 영어능력 발달단계를 가늠해 주는 정보를 제공함으로 연구의 의미가 있다고 볼 수 있다.","This study aimed at providing a comprehensive account of the sources and causes of errors in business emails that Korean college students wrote using a translation machine. Data were collected from 21 emails written by the students who took a business English course. Findings indicated that the students tended to make frequent errors in verb use and verb tense as well as a definite article, countable/noncountable nouns, time adverbs and prepositions. Therefore, the study suggested that the students’ common errors imply that they experience some difficulties learning these linguistic features. Given that learners’ errors can give us valuable insights into teaching and learning how to write in English, pedagogical suggestions are put forward based on the study results."
안드로이드는 양의 꿈을 꾸는가 -인공지능 창작물의 저작자에 대한 저작권법적 검토-,2018,"['Artificial Intelligence', 'AI', 'AI Copyright', 'AI Creation', 'AI Generated Work', 'Authorship', 'Computer Generated Work', '로봇 창작물', '인공지능(AI)', '인공지능 저작물', '인공지능 저작자', '인공지능 창작물', '컴퓨터 창작물']","1950년대부터 등장한 인공지능의 개념은 21세기에 이르러 머신 러닝 기술 및 빅 데이터 활용 기술 등의 발달 덕분에 비약적인 기술적 발전을 이루었고, 현재 인간의 고유 영역이라고 치부되던 창작 영역에서도 각종 활동을하고 있다.문제는 창작물에 대한 권리 부여에 있다. 창작물 이용을 위해 이용허락을구해야 할 수도 있으며, 무단 이용에 따른 권리 침해 문제 또는 창작 과정에서 타인의 권리 침해 문제 등이 발생할 수 있다.인공지능 창작물을 퍼블릭 도메인으로 접근하는 견해, 인공지능 사용자또는 인공지능 개발자를 저작자로 보는 견해가 있다. 또한 업무상 저작물로바라보거나 인공지능에게 저작자의 지위를 부여하자는 의견 등 다양한 견해가 존재한다.현시점에서, 즉 어떠한 방식으로든 인간의 개입(창작에 대한 지시, 목적에 대한 지시 등)이 이루어지는 이상 인간에게 저작자의 지위를 부여해야 함이 타당하다.인공지능 창작물을 업무상 저작물로 보는 것은 애초에 인공지능에게 인격을 인정하는 것을 전제로 하므로 타당하지 않다. 개발자를 저작자로 보는것 역시 개발자에게 인공지능을 제작/판매하는 것으로 얻는 유인 외에 창작에 대한 이중적 보상을 부여하므로 타당하지 않다. 따라서 해당 인공지능을사용하여 자신의 원하는 목적 또는 결과를 얻고자 하는 사용자에게 저작자의 지위를 부여하는 것이 타당하다. 이러한 접근은 창작 과정에서 타인의 저작물 등을 침해하는 경우에 책임을 묻기 위해서도 가장 효과적인 접근이기도 하다.","Ever since John McCarthy defined the definition of artificial intelligence in 1956, the technology has developed. With the support of machine learning technology, artificial intelligence even creates artistic works where only human could accomplish, or thought to be.The problem rises on whether to protect the work made from artificial intelligence, or even acknowledge the authorship to the machine. There are many opinions on the issue; considering computer generated works as the public domain, giving authorship to the user/developer, or even to the artificial intelligence itself, and considering the work as made-for-hire.But yet, it is too soon to give personhood to the computer. Work made-for-hire theory does not have a ground to stand with the same problem.Acknowledging the developer as an author gives too much incentive to the developer. However, it is the user who has intent, decides and gives order to the artificial intelligence to create such work. Then it is also possible to blame the user when copyright infringement occurs during computer's work. The user is very much alike as a ‘traditional author’, with the intent to create."
Supramax Bulk Carrier Market Forecasting with Technical Indicators and Neural Networks,2018,"['Supramax Bulk Carrier', 'Technical Analysis', 'Artificial Neural Networks', 'Efficient Market Hypothesis']",,"Supramax bulk carriers cover a wide range of ocean transportation requirements, from major to minor bulk cargoes. Market forecasting for this segment has posed a challenge to researchers, due to complexity involved, on the demand side of the forecasting model. This paper addresses this issue by using technical indicators as input features, instead of complicated supply-demand variables.Artificial neural networks (ANN), one of the most popular machine-learning tools, were used to replace classical time-series models.Results revealed that ANN outperformed the benchmark binomial logistic regression model, and predicted direction of the spot market with more than 70% accuracy. Results obtained in this paper, can enable chartering desks to make better short-term chartering decisions."
Application of couple sparse coding ensemble on structural damage detection,2018,"['couple sparse coding', 'damage detection', 'frequency response function', 'principal component analysis', 'ensemble']",,"A method is proposed to detect structural damages in the presence of damping using noisy data. This method uses Frequency Response Function (FRF) and Mode-Shapes as the input parameters for a system of Couple Sparse Coding (CSC) to study the healthy state of the structure. To obtain appropriate patterns of FRF for CSC training, Principal Component Analysis (PCA) technique is adopted to reduce the full-size FRF to overcome over-fitting and convergence problems in machine-learning training. To verify the proposed method, a numerical two-story frame structure is employed. A system of individual CSCs is trained with FRFs and mode-shapes, and then termed ensemble to detect the health condition of the structure. The results demonstrate that the proposed method is accurate in damage identification even in presence of up to 20% noisy data and 5% unconsidered damping ratio. Furthermore, it can be concluded that CSC ensemble is highly efficient to detect the location and the severity of damages in comparison to the individual CSC trained only with FRF data."
Application of couple sparse coding ensemble on structural damage detection,2018,"['couple sparse coding', 'damage detection', 'frequency response function', 'principal component analysis', 'ensemble']",,"A method is proposed to detect structural damages in the presence of damping using noisy data. This method uses Frequency Response Function (FRF) and Mode-Shapes as the input parameters for a system of Couple Sparse Coding (CSC) to study the healthy state of the structure. To obtain appropriate patterns of FRF for CSC training, Principal Component Analysis (PCA) technique is adopted to reduce the full-size FRF to overcome over-fitting and convergence problems in machine-learning training. To verify the proposed method, a numerical two-story frame structure is employed. A system of individual CSCs is trained with FRFs and mode-shapes, and then termed ensemble to detect the health condition of the structure. The results demonstrate that the proposed method is accurate in damage identification even in presence of up to 20% noisy data and 5% unconsidered damping ratio. Furthermore, it can be concluded that CSC ensemble is highly efficient to detect the location and the severity of damages in comparison to the individual CSC trained only with FRF data."
"인간과 AI 로봇의 공존을 위한 교양교육-아이작 아시모프, 로버트 실버버그의 소설 『양자 인간』을 중심으로-",2018,"['the positronic man', 'Asimov and Silverberg', 'AI robot', 'robot ethics', 'right of robot', '양자 인간', '아시모프와 실버버그', '인공지능 로봇', '로봇 윤리', '로봇의 권리']","아시모프와 실버버그의 소설 양자 인간은 인간과 인공지능 로봇의 관계에서생겨날 수 있는 다양한 갈등적 상황을 보여준다. 작품의 중심인물 앤드류는40-50년 후에 등장할 것으로 예측되는 ‘강한 인공지능’ 로봇의 형상으로 나타난다. 그는 인간과 동일하게 지적 능력과 감정을 지닌 존재로 스스로 학습하고 진화하는 특성을 보여준다. 뿐만 아니라 그는 시간의 흐름과 함께 진화하면서 인간에 의해 기계로 규정되는 자아를 인식하고 인간과 동등한 사회 구성원의 법적 권리를 요청한다. 소설에서 자신의 사회적, 법적 권리를 주장하는 인공지능 앤드류의 모습은 미래 사회에서 충분히 발생 가능할 것으로 보인다.실제로 앤드류와 같은 인공지능 로봇이 인간과 같이 살아가게 될 경우, 양자의공존을 위해 로봇의 존재론적 의미와 사회적 지위에 대한 새로운 규정이 필요하다. 이러한 관점에서 오늘날 주요하게 논의되는 것이 로봇 윤리와 권리이다. 인간과 로봇의 상호 윤리와 로봇에게 필요한 법적 권리가 지켜지지 않는다면, 양자의 공존하는 삶은 실현되기 어려울 것이다. 미래 사회의 변화와 현실적 문제에대한 논의는 전문적 지식학습 위주의 전공영역보다 전인적 인격의 형성 및 사회구성원의 공존을 추구하는 사고능력과 실천역량 교육을 중심목표로 하는 교양교육 영역에서 실행하는 것이 더 적절하다. 학생들이 직접 인공지능 로봇의 윤리지침 및 법적 주체가능성과 권리에 대해 생각해 봄으로써 미래 사회를 능동적으로대비할 수 있는 것이다.","The Positronic Man suggests various conflict situations that can arise from the relationship between human and AI robot. Andrew, the protagonist in the novel, is a figuration of artificial intelligence robot which is expected to emerge in forty to fifty years. He presents similar characteristics to a human being that has intelligence and emotion, capable of self-learning and evolving. Furthermore, developing with the passage of time, he requests the legal rights as a member of a society that is equal to a human being, after he recognizes his machine-identity defined by human beings. Therefore, the emergence of an AI robot that demands own social and legal rights seems probable in future society.Actually, if an AI robot like Andrew is to live among human beings, its ontological meaning and social status should be regulatedanew for the coexistence of the two. From this perspective, it is robot ethics and rights that foregrounds recent discussion. Carrying out the discussion regarding the practical problems and changes in the future society is more pertinent to liberal education which focuses on enhancing the thinking ability and the practical competency for coexistence between members of a society than to vocational education which concentrates on professional knowledge."
Feature-Based Hand Gesture Recognition Using an FMCW Radar and its Temporal Feature Analysis,2018,,,"<P>In this paper, feature-based gesture recognition in a frequency modulated continuous wave (FMCW) radar system is introduced. We obtain a range-Doppler map (RDM) from raw signals of FMCW radar and generate a variety of features from the RDM. The features are broadly defined to reflect radar-specific characteristics as well as statistical values commonly used in machine learning. Among these radar features, those that are highly correlated with gesture recognition are selected by the proposed feature selection algorithm, which is a wrapper-based feature selection algorithm incorporated with a quantum-inspired evolutionary algorithm (QEA). Furthermore, the information factor based on the minimum redundancy maximum relevance criterion is applied to QEA in order to find feature subsets effectively. The proposed algorithm is able to extract from all feature sets feature subsets related to gesture recognition, and improves the gesture recognition accuracy of the FMCW radar system. In addition, we analyze which features of the radar are helpful for gesture recognition and perform effective gesture recognition using the features determined through feature analysis.</P>"
Supramax Bulk Carrier Market Forecasting with Technical Indicators and Neural Networks,2018,"['Supramax Bulk Carrier', 'Technical Analysis', 'Artificial Neural Networks', 'Efficient Market Hypothesis']",,"Supramax bulk carriers cover a wide range of ocean transportation requirements, from major to minor bulk cargoes. Market forecasting for this segment has posed a challenge to researchers, due to complexity involved, on the demand side of the forecasting model. This paper addresses this issue by using technical indicators as input features, instead of complicated supply-demand variables. Artificial neural networks (ANN), one of the most popular machine-learning tools, were used to replace classical time-series models. Results revealed that ANN outperformed the benchmark binomial logistic regression model, and predicted direction of the spot market with more than 70% accuracy. Results obtained in this paper, can enable chartering desks to make better short-term chartering decisions."
유정(有情)과 무정(無情)의 간극에 대해‒ 감각의 확장에 대한 소고(小考) ‒,2018,"['有情', '無情', '根', '감각기관', '4차 산업혁명', 'Sentient beings', 'Insentient beings', 'Indriya', 'Sense organs', '4th industrial revolution']","인간의 감각기관이 과학의 영역에서 자연계를 이해하고 분석하기 위한 도구이자 매개로서 핵심적 역할을 수행하는 것과 마찬가지로, 불교에서 근(根, indriya)은 유정(有情)이 지닌 생래적인 감각기관으로서, 인식의 매개일 뿐만아니라 총체적인 욕망기관, 나아가 수행도의 원동력이 되는 기체로서 그 역할이 확장되어 있는 중요한 개념이다.불교 경전 속에서 근이 설해지는 배경은 유정의 존재적 특징에 기인하는데, 다시 말하면 유정이 유정일 수 있는 바탕을 이루는 것으로 이해할 수 있을 것이다. 그러나 기술의 발달은 이른바 사물 또는 기계에게 감각기관을 부여하여 일종의 지각작용이 가능하게 되었고, 인공지능을 통해 수집된 감각을 분석하거나 판단하게 함으로써 유정의 근이 지니는 기능이 무정(無情)의 존재를 통해서도 상당 부분 구현될 수 있는 가능성을 열어 주었다.본고는 이러한 점에 착안하여 4차 산업혁명의 근간을 이루는 기술 속에서 감각의 의미에 대해 살펴보고, 이를 불교의 근과 관련지어 분석을 시도한다.이에 따라 제2장에서는 불교 전통에서 근의 의미와 변천과정을 간략히 살펴보고, 이를 자세히 다루는 『아비달마구사론』(阿毘達磨俱舍論, Abhidharmakośabhāṣya, 이하『구사론』) 제2품 「분별근품(分別根品)」을 바탕으로 정리하여 근의 의미를 알아본다. 제3장에서는 4차 산업혁명의 핵심 기술에서 감각기관이 지니는 의미를 센서 기술의 발달 및 수집된 데이터를 분류⋅분석하는 AI의 사고과정을 통해 알아볼 것이다. 마지막으로 제4장에서는 이러한 논의를 바탕으로 근의입장에서 유정과 무정, 다시 말해 인간과 기계 사이의 줄어들 수 없는 간극이 무엇인지 감각의 비교와 비유를 통해 고민해 보고자 한다.","As, in the realm of science, sense organs have performed a role of instrument or intermediation for understanding or analyzing the natural world, in Buddhism, indriyas, as inherent organs or faculty of senses, also have assumed significant roles as means of recognition, as bases of desire and furthermore as motive powers toward realization. In Buddhist texts, indriyas have been described usually as the ontological background of the sentient beings. It means that they are the reason why the sentient beings are ‘sentient.’ However, the technical development in the age of 4th Industrial Revolution, such as AI (Artificial Intelligence) or IoT (Internet of Things), has enabled investing machines with a kind of sensing power as faculty of senses. Moreover, the AI nowadays can analyze, patternize or even judge through the algorithm of deep learning, and this direction of technological development makes ambiguous the boundaries between human and machine.In this paper, I would like to discuss shortly about indriyas of the sentient (human) and the insentient beings (machine) through some arguments represented in the Abhidharmakośabhāṣya, especially in its second chapter, the Indriyanirdeśa. Therefore, first, in the second chapter, I investigate the meanings and some arguments on indriyas in the Abhidharmakośabhāṣya. In the third chapter, the recent technologies of the 4th industrial revolution in which sense organs are applied are dealt briefly. Finally, in the fourth chapter, I try to comparatively understandhow sense organs function in those two fields, namely technological and Buddhist point of view."
Hierarchical Cloud Computing Architecture for Context-Aware IoT Services,2018,,,"<P>This paper presents a new cloud computing model for context-aware Internet of Things services. The proposed computing model is hierarchically composed of two layers: a cloud control layer (CCL) and a user control layer (UCL). The CCL manages cloud resource allocation, service scheduling, service profile, and service adaptation policy from a system performance point of view. Meanwhile, the UCL manages end-to-end service connection and service context from a user performance point of view. The proposed model can support nonuniform service binding and its real-time adaptation using meta-objects. Furthermore, it supports intelligent service-context management using a supervised and reinforcement learning-based machine learning framework. We implemented a lightweight prototype of the proposed computing model. Evaluations confirm that the proposed computing model offers enhanced performance compared with legacy uniform computing models.</P>"
카본 필라멘트 바디 전자 해금의 음향 품질 분석,2018,"['전통 현악기', '해금', '개량 해금', '전자 해금', '음향분석']","전 세계의 민속악기중 현악기가 차지하는 비중이 50%를 넘는다. 그리고 이 민속 현악기는 재료를구하고, 손질해 제작하기 쉬운 목재를 이용해 만들어진다. 목재는 다른 부재에 비해 무르고 가공이쉬워 널리 활용되고 있지만, 대량생산에 적합하지 않다. 또한, 대량생산을 하더라도 악기에서 발생되는 음향의 품질이 일정하게 유지되도록 관리하는데 어려움이 있다. 그러한 이유에서 동일한 품질의저가의 보급형 제품을 만들지 못하고 있다. 우리나라에서도 서양의 전통악기인 바이올린, 첼로 등이인기를 끌고 있으며, 개량된 제작 방식의 저가형 악기가 주로 제작되어, 보급되고 연주되고 있다. 우리나라의 전통악기 해금은 그동안 전통 방식과 전통적인 재료인 천연 목제를 사용하여 악기 제작 명인들에 의해서 생산 되고 있으나, 공급되는 양이 적어 해금을 배우고 연주하려는 수요를 충족시키지못하고 있다. 그리고, 전통방식의 해금을 구하더라도, 배우려는 사람의 노력에 비해 연주가 힘들고 관리가 어렵다. 본 연구에서는 전문연주용 전통 해금과 카본 필라멘트 바디 전자 해금의 음원을 비교분석하여 악기를 제작하는 방식 개선이 음향에 미치는 영향에 대하여 연구를 수행하였다.","String instruments account for more than 50% of the world s folk instruments. Furthermore, this folkstringed instrument is made of timber that is easy to manufacture and to get from nature. Wood is widelyused because it is easy to machine and process compared with other material, but it is not suitable formass production. And also, it is difficult to produce low-cost entry-level products of the same quality athigh quality. Further, even if mass production is performed, it is difficult to manage the quality of thesound generated from the musical instrument to be constant. In Korea, western traditional instruments suchas violin and cello are becoming popular, and low-priced instruments with improved production methods aremainly produced, spread and played. Traditional Korean musical instruments Haegum has been produced bymusical instrument makers using traditional method and wood, but the quantity supplied does not meet thedemand to learn and play Haegum. And even if you try to get a traditional Haegeum, it is hard to playand hard to manage compared to the effort of the person to learn. In this paper, we investigate the effectsof the improvement of the musical instrument manufacturing on the side of acoustics by comparing andanalyzing the sound sources of the traditional haegeum and the electric carbon filament body Haegeum."
Data Mining-Aided Automatic Landslide Detection Using Airborne Laser Scanning Data in Densely Forested Tropical Areas,2018,"['Data Mining', 'Landslide Detection', 'LiDAR', 'Orthophotos', 'GIS', 'Remote Sensing']",,"Landslide is a natural hazard that threats lives and properties in many areas around the world. Landslides are difficult to recognize, particularly in rainforest regions. Thus, an accurate, detailed, and updated inventory map is required for landslide susceptibility, hazard, and risk analyses. The inconsistency in the results obtained using different features selection techniques in the literature has highlighted the importance of evaluating these techniques. Thus, in this study, six techniques of features selection were evaluated. Very-high-resolution LiDAR point clouds and orthophotos were acquired simultaneously in a rainforest area of Cameron Highlands, Malaysia by airborne laser scanning (LiDAR). A fuzzy-based segmentation parameter (FbSP optimizer) was used to optimize the segmentation parameters. Training samples were evaluated using a stratified random sampling method and set to 70% training samples. Two machine-learning algorithms, namely, Support Vector Machine (SVM) and Random Forest (RF), were used to evaluate the performance of each features selection algorithm. The overall accuracies of the SVM and RF models revealed that three of the six algorithms exhibited higher ranks in landslide detection. Results indicated that the classification accuracies of the RF classifier were higher than the SVM classifier using either all features or only the optimal features. The proposed techniques performed well in detecting the landslides in a rainforest area of Malaysia, and these techniques can be easily extended to similar regions."
Organizational microblogging for event marketing: a new approach to creative placemaking,2018,,,"Creative placemaking emphasizes the role of artists and cultural organizations in disseminating cultural products and services, and ultimately in promoting the city’s image. Over the past decade, we have witnessed a surge of cultural events in urban communities, where art and cultural spaces in the form of museums, art galleries, and exhibition halls have proliferated. Yet how to attract different audiences for event organizers to these events remains a challenge. In search of effective event marketing strategies, artists and cultural organizations increasingly rely on social media tools, such as Facebook, Twitter and Weibo (a Chinese microblog). Through an analysis of microblogging data collected through the Application Programming Interface (API) and web scraping, this paper evaluates the effectiveness of museums’ Weibo usage for attracting visitors in the city of Beijing. Applying a machine-learning algorithm and conducting a Kendall’s Tau test, we build a correlation between the degree of an account’s online activity and the frequency of onsite visits by the public. Our findings shed light on how organizations can use social media tools to more fully engage the public in social and cultural events."
Systems-level mechanisms of action of Panax ginseng: a network pharmacological approach,2018,"['network pharmacology', 'Panax ginseng', 'polypharmacology', 'traditional Asian medicine']",,"Panax ginseng has been used since ancient times based on the traditional Asian medicine theory and clinical experiences, and currently, is one of the most popular herbs in the world. To date, most of the studies concerning P. ginseng have focused on specific mechanisms of action of individual constituents. However, in spite of many studies on the molecular mechanisms of P. ginseng, it still remains unclear how multiple active ingredients of P. ginseng interact with multiple targets simultaneously, giving the multidimensional effects on various conditions and diseases. In order to decipher the systems-level mechanism of multiple ingredients of P. ginseng, a novel approach is needed beyond conventional reductive analysis. We aim to review the systems-level mechanism of P. ginseng by adopting novel analytical framework-network pharmacology. Here, we constructed a compound-target network of P. ginseng using experimentally validated and machine learning-based prediction results. The targets of the network were analyzed in terms of related biological process, pathways, and diseases. The majority of targets were found to be related with primary metabolic process, signal transduction, nitrogen compound metabolic process, blood circulation, immune system process, cell-cell signaling, biosynthetic process, and neurological system process. In pathway enrichment analysis of targets, mainly the terms related with neural activity showed significant enrichment and formed a cluster. Finally, relative degrees analysis for the target-disease association of P. ginseng revealed several categories of related diseases, including respiratory, psychiatric, and cardiovascular diseases."
Data Mining-Aided Automatic Landslide Detection Using Airborne Laser Scanning Data in Densely Forested Tropical Areas,2018,"['Data Mining', 'Landslide Detection', 'LiDAR', 'Orthophotos', 'GIS', 'Remote Sensing']",,"Landslide is a natural hazard that threats lives and properties in many areas around the world. Landslides are difficult to recognize, particularly in rainforest regions. Thus, an accurate, detailed, and updated inventory map is required for landslide susceptibility, hazard, and risk analyses. The inconsistency in the results obtained using different features selection techniques in the literature has highlighted the importance of evaluating these techniques. Thus, in this study, six techniques of features selection were evaluated. Veryhigh- resolution LiDAR point clouds and orthophotos were acquired simultaneously in a rainforest area of Cameron Highlands, Malaysia by airborne laser scanning (LiDAR). A fuzzy-based segmentation parameter (FbSP optimizer) was used to optimize the segmentation parameters. Training samples were evaluated using a stratified random sampling method and set to 70% training samples. Two machine-learning algorithms, namely, Support Vector Machine (SVM) and Random Forest (RF), were used to evaluate the performance of each features selection algorithm. The overall accuracies of the SVM and RF models revealed that three of the six algorithms exhibited higher ranks in landslide detection. Results indicated that the classification accuracies of the RF classifier were higher than the SVM classifier using either all features or only the optimal features. The proposed techniques performed well in detecting the landslides in a rainforest area of Malaysia, and these techniques can be easily extended to similar regions."
대화형 데이터 시각화 기반 실시간 관찰 및 오류 감지 시스템,2018,"['Realtime rendering', 'Data visualization', 'Temporal analysis', 'Spatial analysis', 'Data fusion']",,"Effective representation of various types of data from various types of equipment is not a trivial task. The more data items collected for sophisticated data analysis, the more trouble the system operator has to identify important items. In order to solve these problems, it is necessary to develop a real-time interactive data visualization system that can be efficiently observing large-volume data at a glance and confirming fault detection in advance. In this paper, we propose a real - time observation and fault detection system using interactive data visualization method to efficiently manage consecutively generated raw data. The proposed system consists of data collection, data visualization, data fault detection and alarm steps. In the data collection step, the real-time generated device data using the data collection device is stored, and the collected data is massaged and generalized through data preprocessing process. The normalized data is subjected to data analysis, visualization mapping, and rendering in the data visualization step. To visualize and render the defined data primitives, we use heat map, radar chart, and stream graph. In addition, statistical process control (SPC) rule-based fault detection and alarm methods are used to detect data errors. The proposed method can be widely used in various fields such as image generation, data fusion, fault detection and machine learning."
한국 사회복지학의 최근 연구경향: 연관규칙 분석의 활용,2018,"['Social Welfare', 'Research Trend', 'Association Rules', 'Apriori Algorithm', '사회복지학', '연구경향', '연관규칙', 'Apriori 알고리즘']","본 연구에서는 사회복지학의 최근 연구경향을 분석하기 위해 머신러닝 기법 중 하나인 연관규칙 분석(association rules)을 실행한다. 특히 1~2개의 소수의 학술지에 근거하지 않고 사회복지 전반적 주제를 다루는 5개 저명 학술지의 수록된 최근 논문 2,377편에 대한 연구주제, 분석방법론, 데이터를 포괄하여 다루었다는 점에서 학문적 기여가 있다. 사회복지 연구영역에 기초하여 탐색적 자료분석을 통해 귀납적으로 선택한 243개 단어에 대한 빈도분석을 하였으며, 단어들의 연관규칙을 분석하였다. 분석 결과, 첫째, 노인, 고용경제, 빈곤, 소득 관련 연구들이 최근 연구주제로 많이 다루어지고 있다. 특히 노인관련 연구는 2010년 이후 그 비율이 크게 증가하고 있다. 둘째, 분석방법론은 회귀분석, 로짓분석이 가장 많이 활용되고 있고 전통적인 분석방법인 구조방정식 모형을 통해 매개효과와 조절효과를 추정하는 논문의 출현빈도가 높다. 셋째, 향상도를 기준으로 판단하였을 때 복지패널 데이터를 이용하여 다항로짓모형을 추정하는 연구가 연관규칙 정도가 매우 높다. 또한 면접조사와 사례조사 데이터를 이용하여 질적분석을 실행하는 연관규칙도 자주 나타난다. 넷째, 노인관련 연구로 한정하였을 때, 노인의 우울관련 연구에서 매개회귀분석이 사용되는 연관성이 매우 높다. 분석결과를 토대로 사회복지학의 발전방안을 제시하면 연구 주제의 다양화, 질적 방법론과 양적 방법론의 조화, 양적방법론에서도 고전적인 분석방법론에서 벗어나 머신러닝 등 새로운 연구방법론을 적용할 필요성을 시사한다.","In this study, we conduct the association rules approach to analyze recent research trends in social welfare studies. Unlike previous literature based on 1-2 academic journals, there exists an academic contribution in that we deal with the latest 2377 articles from five major journals. Research trends are defined not only by topics but also by econometric methodology and empirical data. From association rules, we found that first, a number of recent subjects of research on the elderly, employment economy, poverty and income has increased significantly. Second, regression and logit analyses are most commonly used as an analytical tool. Mediation and moderation analyses through structural equation model are also frequently associated. Third, in terms of lift measure, multinomial logit analysis using Korea Welfare Panel Survey (KOWEPS) data shows a high degree of association. Fourth, restricting to the elderly-related papers, depression topics and mediation analysis are highly associated. It is expected that this study can identify the flow of change of research methodologies and fields of interest in the social welfare academic world. Through this, it is possible to supplement the research competitiveness of the related-scholars. This study suggests diversification of research topics, harmonization of qualitative and quantitative methodologies, and application of the new research methodology such as machine learning."
Inference of Korean Public Sentiment from Online News,2018,"['감정분석', '크라우드소싱', '온라인뉴스', '감정사전', '사회적 감정 탐지', '자연어처리', 'Sentiment Analysis', 'Crowdsourcing', 'Online News', 'Emotion Dictionary', 'Social Emotion Detection', 'Natural Language Processing']","온라인 뉴스는 기존의 신문을 대체하였고, 우리가 정보에 접근하고 공유하는 방법에 큰 변화를 가져왔다. 뉴스 웹사이트들은 사용자가 댓글을 남길 수 있는 기능을 오랜 시간동안 제공하였고, 그 중 몇몇 뉴스 웹사이트에서는 뉴스 기사들에 대한 사용자의 반응들을 크라우드소싱(crowdsource)하기 시작했다. 감정분석 분야에서는 텍스트에 반영된 감정과 반응들을 컴퓨팅적으로 모델링하기 위한 시도를 하고 있다. 본 연구에서는 뉴스 기사에 대한 반응들이 뉴스 본문과 수학적인 상관관계를 갖는지 밝히기 위해, 사용자로부터 생성된 다섯 가지의 감정 라벨(label)을 사용하여 10가지 카테고리(category)에 해당하는 100,000개 이상의 뉴스 기사들을 분석한다. 본 연구에서는 전처리과정이 최소한으로 필요하고 기계학습이 적용하지 않아도 되는 간단한 감정 분석 알고리즘(algorithm)을 제안한다. 우리는 이 모델이 한국어와 같은 형태론적으로 복잡한 언어에도 효과적이라는 것을 증명한다.","Online news has replaced the traditional newspaper and has brought about a profound transformation in the way we access and share information. News websites have had the ability for users to post comments for quite some time, and some have also begun to crowdsource reactions to news articles. The field of sentiment analysis seeks to computationally model the emotions and reactions experienced when presented with text. In this work, we analyze more than 100,000 news articles over ten categories with five user-generated emotional annotations to determine whether or not these reactions have a mathematical correlation to the news body text and propose a simple sentiment analysis algorithm that requires minimal preprocessing and no machine learning. We show that it is effective even for a morphologically complex language like Korean."
케이프선 시장 운임의 결정요인 및 운임예측 모형 분석,2018,"['케이프선 운임', '운임 결정요인', '단계적 회귀분석', '랜덤포레스트', 'Capesize Market', 'Freight Determinants', 'Stepwise Regression', 'Random Forest']","운임시장의 심한 변동성과 시계열 데이터의 불안정성으로 해운시황 예측에 대한 연구가 큰 성과를 내지 못하고 있지만 최근 대표적인 비선형 모델인 기계학습모델을 적용한 연구들이 활발히 진행되고 있다. 대부분의 기존 연구가 계량모델의 설계단계에서 입력변수에 해당하는 요인들을 기존 문헌연구와 연구자의 직관에 의존하여 선정했기 때문에 요인선정에 대한 체계적인 연구가 필요하다. 본 연구에서는 케이프선 운임을 대상으로 단계적 회귀모형과 랜덤포레스트모델을 이용하여 중요 영향요인을 분석하였다. 해운시장에서 비교적 단순한 수급구조를 가져 요인파악이 용이한 케이프선 운임을 대상으로 하였으며 총 16개의 수급요인들을 사전 추출하였다. 요인간의 상호관련성을 파악하여 단계적 회귀는 8개 요인, 랜덤포레스트는 10개 요인을 분석대상으로 선정하였으며 선정된 변수를 입력변수로 하여 예측한 결과를 비교하였다. 랜덤포레스트의 예측성능이 아주 우수하였는데 수요요인이 주로 선정된 단계적 회귀분석과는 달리 공급요인이 비중 있게 선정되었기 때문인 것으로 판단된다. 본 연구는 운임예측 연구에 있어 운임결정요인에 대한 과학적인 근거를 마련하였으며 이를 위해 기계학습 기반의 모델을 활용하였다는데 연구적 의의가 있다. 또한 시장정보의 분석에 있어 실무자들이 어떤 변수에 중점을 두어야 하는지에 대해 합리적 근거를 제시한 측면에서 해운기업의 의사결정에 실질적 도움이 될 것으로 기대된다.","In recent years, research on shipping market forecasting with the employment of non-linear AI models has attracted significant interest. In previous studies, input variables were selected with reference to past papers or by relying on the intuitions of the researchers. This paper attempts to address this issue by applying the stepwise regression model and the random forest model to the Cape-size bulk carrier market. The Cape market was selected due to the simplicity of its supply and demand structure. The preliminary selection of the determinants resulted in 16 variables. In the next stage, 8 features from the stepwise regression model and 10 features from the random forest model were screened as important determinants. The chosen variables were used to test both models. Based on the analysis of the models, it was observed that the random forest model outperforms the stepwise regression model. This research is significant because it provides a scientific basis which can be used to find the determinants in shipping market forecasting, and utilize a machine-learning model in the process. The results of this research can be used to enhance the decisions of chartering desks by offering a guideline for market analysis."
냉동고 작동오류 진단방법 개발,2018,"['Machine learning(기계학습)', 'Freezer(냉동고)', 'Operation fault(운영 오류)', 'Diagnosis(진단)', 'Prediction(예측)']",,"This study aims to diagnose operation faults of freezer such as door left open by mistakes and refrigerant leaks by using machine learning approach. Machine learning algorithms can take training raw data and then output trained model that contains prediction rules. Active power of freezer, laboratory ambient temperature, and freezer inside surface temperature are selected as monitoring variables. Heat capacity, refrigerant mass, and door opening also varied upon actual operation scenarios. About 190,000 raw data were collected. We selected five machine learning algorithms: SVM, DT, KNN, ANN, and Naive Bayesian Classification. Kernel-based classification algorithms such as KNN and SVM were found to have better performance in diagnosing operation faults of freezer than other machine learning algorithms."
이미지 데이터에 대한 분류 방법의 비교 연구,2018,"['심층 신경망', '지지벡터기계', '지지행렬기계', 'Deep neural network', 'support matrix machine', 'support vector machine']","이미지는 행렬형태로 자연스럽게 표현되므로 기존의 기계 학습 (machine learning) 방법들을 이미지 데이터에 적용하기 위해서는 행렬을 벡터로 변환해야 한다. 최근 지지행렬기계 (support matrix machine)는 데이터 행렬을 벡터로 변환하지 않고 직접 분류하도록 고안되었다. 그러나 문헌상의 연구에서는 지지행렬기계와 지지벡터기계 (support vector machine)의 분류 정확도만을 비교하였다. 본 논문에서는 지지벡터기계의 예측 성능을 k-근방 분류, 지지벡터기계, 그리고 심층 신경망 (deep neural network)과 같은 이미지 데이터에 대한 주요 분류방법들과 비교하고 이러한 방법들의 특징에 대하여 알아보고자 한다.","Since images are naturally represented as matrices, we have to reshape matrices into vectors in order to apply traditional methods in machine learning to image data. Recently, support matrix machine (SMM) has been proposed to directly classify data matrices without reshaping those matrices into vectors. However, the classification accuracies of SMM and support vector machine were compared in the literature. In this paper, we compare the predictive performance of SMM with those of major classification methods for image data such as k-nearest neighborhood classifier, support vector machine, and deep neural network and understand the characteristics of those learning methods."
이질성 학습을 통한 문서 분류의 정확성 향상 기법,2018,"['텍스트 마이닝', '문서 분류', '이질성 학습', '준지도 학습', '앙상블 학습', 'Text Mining', 'Text Classification', 'Heterogeneity Learning', 'Semi-Supervised Learning', 'Ensemble Learning']",,"In recent years, the rapid development of internet technology and the popularization of smart devices have resulted in massive amounts of text data. Those text data were produced and distributed through various media platforms such as World Wide Web, Internet news feeds, microblog, and social media. However, this enormous amount of easily obtained information is lack of organization. Therefore, this problem has raised the interest of many researchers in order to manage this huge amount of information. Further, this problem also required professionals that are capable of classifying relevant information and hence text classification is introduced. Text classification is a challenging task in modern data analysis, which it needs to assign a text document into one or more predefined categories or classes. In text classification field, there are different kinds of techniques available such as K-Nearest Neighbor, Naïve Bayes Algorithm, Support Vector Machine, Decision Tree, and Artificial Neural Network.  However, while dealing with huge amount of text data, model performance and accuracy becomes a challenge. According to the type of words used in the corpus and type of features created for classification, the performance of a text classification model can be varied. Most of the attempts are been made based on proposing a new algorithm or modifying an existing algorithm. This kind of research can be said already reached their certain limitations for further improvements. In this study, aside from proposing a new algorithm or modifying the algorithm, we focus on searching a way to modify the use of data. It is widely known that classifier performance is influenced by the quality of training data upon which this classifier is built. The real world datasets in most of the time contain noise, or in other words noisy data, these can actually affect the decision made by the classifiers built from these data. In this study, we consider that the data from different domains, which is heterogeneous data might have the characteristics of noise which can be utilized in the classification process.  In order to build the classifier, machine learning algorithm is performed based on the assumption that the characteristics of training data and target data are the same or very similar to each other. However, in the case of unstructured data such as text, the features are determined according to the vocabularies included in the document. If the viewpoints of the learning data and target data are different, the features may be appearing different between these two data. In this study, we attempt to improve the classification accuracy by strengthening the robustness of the document classifier through artificially injecting the noise into the process of constructing the document classifier.  With data coming from various kind of sources, these data are likely formatted differently. These cause difficulties for traditional machine learning algorithms because they are not developed to recognize different type of data representation at one time and to put them together in same generalization. Therefore, in order to utilize heterogeneous data in the learning process of document classifier, we apply semi-supervised learning in our study. However, unlabeled data might have the possibility to degrade the performance of the document classifier. Therefore, we further proposed a method called Rule Selection-Based Ensemble Semi-Supervised Learning Algorithm (RSESLA) to select only the documents that contributing to the accuracy improvement of the classifier. RSESLA creates multiple views by manipulating the features using different types of classification models and different types of heterogeneous data. The most confident classification rules will be selected and applied for the final decision making. In this paper, three different types of real-world data sources were used, which are news, twitter and blogs."
Artificial Neural Network: Understanding the Basic Concepts without Mathematics,2018,"['Machine Learning', 'Artificial Intelligence', 'Neural Networks', 'Deep Learning']",,"Machine learning is where a machine (i.e., computer) determines for itself how input data is processed and predicts outcomes when provided with new data. An artificial neural network is a machine learning algorithm based on the concept of a human neuron. The purpose of this review is to explain the fundamental concepts of artificial neural networks."
광학영상에서의 해빙종류 분류 연구,2018,"['Active learning', 'Convolutional neural network', 'Deep learning', 'Sea ice', 'Semantic segmentation', 'Semi-supervised learning']","광학 위성영상은 레이더 영상에 비해 시각적으로 친숙한 영상을 제공한다. 하지만해빙종류에 대한 구분은 분광학적으로 쉽지 않아 기존 기계학습에서 주로 사용하는 분광정보를 이용한 분류기법을 이용했을 경우 광학영상에서 해빙종류의 구분은 매우 어렵다. 본 연구에서는 분광정보 기반의 분류모델이 아닌 딥러닝 기반 분류기법인 semantic segmentation을 이용하여 계층적, 공간적 패턴을 학습하여 해빙종류 분류를 수행하였다. 또한 주기적으로 획득되는 광학위성자료에 비해 감독분류에서 매우 중요한 양질의 레이블 자료는 수집하는데 있어 높은 시간 및 노동 비용이 소모된다. 본 연구에서는 부족한 레이블 자료로 인해 어려운 다중영상에 대한 감독분류 문제를 준지도학습과 능동학습의 결합을 통해 해결을 시도 하였다. 이를 통해 레이블 되지 않은 새로운 영상자료로부터 추가적인 레이블을 스스로 학습하여 분류모델을 강화할 수 있었으며, 이는 향후 광학영상 기반의 운영 가능한 해빙종류 산출물 개발에도 적용될 수 있을 것으로 기대된다.","Optical remote sensing sensors provide visually more familiar images than radar images. However, it is difficult to discriminate sea ice types in optical images using spectral information based machine learning algorithms. This study addresses two topics. First, we propose a semantic segmentation which is a part of the state-of-the-art deep learning algorithms to identify ice types by learning hierarchical and spatial features of sea ice. Second, we propose a new approach by combining of semi-supervised and active learning to obtain accurate and meaningful labels from unlabeled or unseen images to improve the performance of supervised classification for multiple images. Therefore, we successfully added new labels from unlabeled data to automatically update the semantic segmentation model. This should be noted that an operational system to generate ice type products from optical remote sensing data may be possible in the near future."
점진적 샘플링과 정규 상호정보량을 이용한 온라인 기계학습 공조기 급기온도 예측 모델 개발,2018,"['정규 상호정보량', '온라인 기계학습 모델', '점진적 샘플링', 'BEMS', '정보 엔트로피', 'normalized mutual information', 'online machine learning model', 'progressive sampling', 'Building Energy Management System', 'information entropy']",,"The machine learning model can capture the dynamics of building systems with less inputs than the first principle based simulation model. The training data for developing a machine learning model are usually selected in a heuristic manner. In this study, the authors developed a machine learning model which can describe supply air temperature from an AHU in a real office building. For rational reduction of the training data, the progressive sampling method was used. It is found that even though the progressive sampling requires far less training data (n=60) than the offline regular sampling (n=1,799), the MBEs of both models are similar (2.6% vs. 5.4%). In addition, for the update of the machine learning model, the normalized mutual information (NMI) was applied. If the NMI between the simulation output and the measured data is less than 0.2, the model has to be updated. By the use of the NMI, the model can perform better prediction (5.4% → 1.3%)."
Intelligent system for drowsiness recognition based on ear canal electroencephalography with photoplethysmography and electrocardiography,2018,"['Intelligent system', 'Machine learning', 'Drowsiness', 'Ear canal EEG', 'PPG', 'ECG']",,<P><B>Abstract</B></P>  <P>We propose an intelligent system that can recognize drowsiness during daily life with the use of EEG measurements in the ear canal in combination with conventional photoplethysmography (PPG) and electrocardiography (ECG). The physiological signals for classification by machine learning were measured during the sustained attention task of simulated driving. The features were sorted by their degree of importance using three types of ranking filters and the combined information. The effect of the feature size of the biological signals on machine learning was evaluated by determining the mean squared error. The classifications were conducted with various datasets and dataset lengths that were obtained from the same biological signals considering the transitional traits of drowsiness. The statistical measures of the performance of the classifications using machine learning indicated that the system based on the ear canal EEG data and the physiological attribute data was excellent. The feature selection process with the composite ranking algorithm using multiple ranking methods improved the classification performance. The nonlinear features were highly selective among the physiological attributes for the intelligent recognition of drowsiness.</P>
인구 데이터 기반 시군구 지역별 의원 매출 예측 모델 개발,2018,"['Clinic revenue', 'Population data', 'Machine learning', 'Elastic net', 'Random forest']",,"Objectives: The study was conducted to develop the model that predicts the total sales of clinics in city based on population data.Methods: The clinic revenue, population and population movements data was consolidated into city area unit. The machine learning methods of elastic net and random forest were applied to estimate the clinic revenue and the clinic revenue difference after the five years which was transformed by log and normalization.Results: Current clinic revenue was most significant factor for the clinic revenue and the clinic revenue difference after the five years prediction. However, clinic revenue difference, the direction between current clinic revenue and future clinic revenue was reversed. The features such as population movement between city and population movement between province also were the important factors for the revenue prediction. Comparing prediction model, the elastic net based machine learning model had more prediction power than random forest based machine learning model.Conclusion: Based on the results of the study, clinic revenue, population movement between city and population movement between province could be the information factor for the revenue prediction and revenue difference prediction. When considering opening a clinic, demographic-based regional clinic revenue estimation model could be the factors of reference."
가우시안 프로세스 기반의 원거리 통신지연 보상기법을 이용한 무인기 경로계획,2018,"['object detection', 'semantic segmentation', 'deep learning', 'convolutional neural network']",,"This paper studies a path planning for a UAV (Unmanned Aerial Vehicle) that is experiencing network communication delay between the UAV and a control station. When random time-delay occurs in the communication link, a machine learning technique can deal with nonlinearities and uncertainties of the delay by estimation of UAV’s state. As a machine learning technique, this paper applies GP (Gaussian Process), which has advantage of the flexibility in modelling complex expressions using a small number of learning parameters. Despite GP’s popularity to the robotic applications, it has not been reported in learning random delay properties for real UAV flight. We apply GP learning in the path planning framework based on MPC (Model Predictive Control) method. The proposed method is evaluated on a trajectory tracking of a UAV, where we set the delay on the communication link. The experimental results show the improved tracking performance."
Neural Network based Real-time UAV Detection and Analysis by Sound,2018,"['artificial intelligence', 'artificial neural network', 'machine learning', 'ensemble learning', 'audio categorization', 'drone classification', 'K-NN', 'UAV categorization', 'UAV analysis']",,"In this paper, we present a real-time artificial intelligence system for drone detection on multiple locations. With ensemble machine learning on multiple regional clients and a central neural network server, the users can easily monitor the drone's appearance based on its motor sound data. The clients perform FFT on the sampled real-time data and detect drones using Plotted Image Machine Learning (PIL) with sending the detected audio sample to the server. The PIL uses image data from the visualized FFT graph to detect robust points, and compares the average image similarity with a reference FFT template associated with a target of interest. The server visualizes each client's detection status including machine learning result, and trains Artificial Neural Network (ANN) with extensive regional samples from clients. Afterwards, the server tests its ANN model whenever the client reports drone detection. The accuracy rate of client's PIL test is 83% and server's ANN test accuracy rate is 86%. The major deliverables of this work are a software package framework one may use to train its ANN model with various sound samples from different places to make a generalized drone detection model."
HMM과 MCSVM 기반 손 제스처 인터페이스 연구,2018,"['Hand Gesture Recognition', 'User Interface', 'Leap Motion', 'Machine Learning', 'MCSVM', 'HMM', '손 제스처 인식', '사용자 인터페이스', '립모션', '머신러닝', '다중 클래스 서포트 벡터 머신', '은닉 마르코프모델']","최근 가상현실 기술의 발전으로 가상의 3D 객체와 자연스러운 상호작용이 가능하도록 하는 사용자 친화적인 손 제스처 인터페이스에 대한 연구가 활발히 진행되고 있다. 그러나 대부분의 연구는 단순하고 적은 종류의 손 제스처만지원되고 있는 실정이다. 본 논문은 직관적이고 보편적인 손 제스처를 유형별로 분류하고 각 제스처의 인식률을 높이기 위한 머신러닝 기반 손 제스처 인식 방법을 제안한다. 먼저 립모션을 이용해 입력된 손 정보를 전처리 과정으로 인식오류를 수정한다. 그리고 난 후 이진 결정트리를 기반으로 1차 분류를 수행한 다음 손 특징 정보를 구성한다. 입력된 제스처가 정적 제스처인 경우는 MCSVM 학습을 수행하고 동적 제스처인 경우는 HMM 학습을 수행하여 최종적으로 손 제스처를 인식한다. 본 방법의 검증을 위하여 ‘Virtual Block’ 게임을 구현하여 실험한 결과 17개의 제스처 인터페이스에 대해 평균 98.6%의 인식률을 보였다. 본 연구의 결과는 마우스나 키보드 필요 없이 게임, 교육, 의료 등 다양한 가상현실 응용 분야에서 입력 인터페이스로 활용될 수 있다.","With the development of virtual reality technology, in recent years, user-friendly hand gesture interface has been more studied for natural interaction with a virtual 3D object. But most earlier studies on the hand gesture interface are using relatively simple hand gestures. In this paper, we classify intuitive and common hand gestures into certain types and present a hand gesture recognition algorithm based on the machine learning to improve the recognition ratio of each hand gesture. First of all, we use Leap Motion to get hand information and then preprocess the hand data to correct the input errors. Next, we classify the data through the binary decision tree and construct the hand feature data. Finally, the input gesture is recognized based on the MCSVM-based machine learning for static gesture and the HMM-based machine learning for dynamic gesture. Experimental results showed an average of 98.6% recognition ratio of 17 kinds of command hand gestures for interaction with a 3D object in a 'Virtual Block' game application. This hand gesture interface can be used as an input interface in various virtual reality application fields such as game, education, medical field, etc. without using mouse or keyboard device."
DNN을 이용한 오디오 이벤트 검출 성능 비교,2018,"['피드포워드 뉴럴 네트워크', '가우시안 믹스쳐 모델', '기계 학습', '서포트 벡터 머신', 'Feedforward Neural Network', 'Gaussian Mixture Model', 'Machine Learning', 'Support Vector Machine']","최근 딥러닝 기법이 다양한 종류의 패턴 인식에 있어서 우수한 성능을 보이고 있다. 하지만 소규모의 훈련데이터를 이용한 분류 실험에 있어서 전통적으로 사용되던 머신러닝 기법에 비해서 DNN의 성능이 우수한지에 대해서는 다소 간의 논란이 있어 왔다. 본 연구에서는 오디오 검출에 있어서 전통적으로 사용되어 왔던 GMM, SVM의 성능과 DNN의 성능을 비교하였다. 동일한 데이터에 대해서 인식실험을 수행한 결과, 전반적인 성능은 DNN이 우수하였으나 세그먼트 기반의 F-score에서 SVM이 DNN에 비해 우수한 성능을 보임을 알 수 있었다.","Recently, deep learning techniques have shown superior performance in various kinds of pattern recognition. However, there have been some arguments whether the DNN performs better than the conventional machine learning techniques when classification experiments are done using a small amount of training data. In this study, we compared the performance of the conventional GMM and SVM with DNN, a kind of deep learning techniques, in audio event detection. When tested on the same data, DNN has shown superior overall performance but SVM was better than DNN in segment-based F-score."
Complex Neural Classifiers for Power Quality Data Mining,2018,"['Power quality', 'Fully complex valued radial basis function network', 'Complex extreme learning machine', 'Support vector machine', 'S-Transform']",,This work investigates the performance of fully complex- valued radial basis function network(FC-RBF) and complex extreme learning machine (CELM) based neural approaches for classification of power quality disturbances. This work engages the use of S-Transform to extract the features relating to single and combined power quality disturbances. The performance of the classifiers are compared with their real valued counterparts namely extreme learning machine(ELM) and support vector machine(SVM) in terms of convergence and classification ability. The results signify the suitability of complex valued classifiers for power quality disturbance classification.
An Unsupervised Real-time Anomaly Detection of Furnace System based on HTM,2018,"['Anomaly detection', 'Real-time', 'Unsupervised', 'Furnace systems', 'HTM', 'Machine learning']",,"The immediate recognition of abnormal temperatures in the furnace system is very important for timely disaster control. Conventional abnormal temperature detection techniques typically use pre-programmed thresholds to identify abnormal patterns from a stream of temperature data in a statistical manner. Therefore, it is not suitable for use in a heating furnace system in which abnormal patterns must be detected in real time. Hierarchical Temporal Memory (HTM) is one of the machine learning models with excellent ability to analyze patterns of stream data. This model is a new machine intelligence technique that uses unsupervised continuous learning using Cortical Learning Algorithm (CLA), which is a time-based learning algorithm, and Spare Distributed Representation (SDR), which stores temporal and spatial patterns. This HTM, which is distinguished from existing deep learning or artificial neural network model, is capable of real-time continuous prediction from input of stream data and can be used to recognize abnormal states in various fields. HTM can be used as a robust model to detect abnormalities in successive temperature data in a heating furnace system because the furnace system continues to generate temperature stream data with a certain pattern over time. Here we developed an HTM-based, unsupervised, real-time anomaly detection system for heating furnaces. Performance evaluation shows that the suggested system can perform excellent abnormal real-time detection."
Complex Neural Classifiers for Power Quality Data Mining,2018,"['Power quality', 'Fully complex valued radial basis function network', 'Complex extreme learning machine', 'Support vector machine', 'S-Transform']",,This work investigates the performance of fully complex- valued radial basis function network(FC-RBF) and complex extreme learning machine (CELM) based neural approaches for classification of power quality disturbances. This work engages the use of S-Transform to extract the features relating to single and combined power quality disturbances. The performance of the classifiers are compared with their real valued counterparts namely extreme learning machine(ELM) and support vector machine(SVM) in terms of convergence and classification ability. The results signify the suitability of complex valued classifiers for power quality disturbance classification.
Analysis of Market Trajectory Data using k-NN,2018,"['Data Analytics', 'Statistical Analytics', 'K-Nearest Neighbors Algorithm', 'Point of Sales Data', 'Trajectory Data']",,"Recently, as the sensor and big data analysis technology have been developed, there have been a lot of researches that analyze the purchase-related data such as the trajectory information and the stay time. Such purchase-related data is usefully used for the purchase pattern prediction and the purchase time prediction. Because it is difficult to find periodic patterns in large-scale human data, it is necessary to look at actual data sets, find various feature patterns, and then apply a machine learning algorithm appropriate to the pattern and purpose. Although existing papers have been used to analyze data using various machine learning methods, there is a lack of statistical analysis such as finding feature patterns before applying the machine learning algorithm. Therefore, we analyze the purchasing data of Songjeong Maeil Market, which is a data gathering place, and finds some characteristic patterns through statistical data analysis. Based on the results of 1, we derive meaningful conclusions by applying the machine learning algorithm and present future research directions. Through the data analysis, it was confirmed that the number of visits was different according to the regional characteristics around Songjeong Maeil Market, and the distribution of time spent by consumers could be grasped."
딥 러닝 기반의 이미지와 비디오 압축 기술 분석,2018,"['Machine learning', 'Deep learning', 'Image', 'Video', 'Compression']",,"In this paper, we investigate image and video compression techniques based on deep learning which are actively studied recently. The deep learning based image compression technique inputs an image to be compressed in the deep neural network and extracts the latent vector recurrently or all at once and encodes it. In order to increase the image compression efficiency, the neural network is learned so that the encoded latent vector can be expressed with fewer bits while the quality of the reconstructed image is enhanced. These techniques can produce images of superior quality, especially at low bit rates compared to conventional image compression techniques. On the other hand, deep learning based video compression technology takes an approach to improve performance of the coding tools employed for existing video codecs rather than directly input and process the video to be compressed. The deep neural network technologies introduced in this paper replace the in-loop filter of the latest video codec or are used as an additional post-processing filter to improve the compression efficiency by improving the quality of the reconstructed image. Likewise, deep neural network techniques applied to intra prediction and encoding are used together with the existing intra prediction tool to improve the compression efficiency by increasing the prediction accuracy or adding a new intra coding process."
Elastic net을 통한 학생의 창의성 예측 모형 연구,2018,"['machine learning', 'elastic net', 'creativity', 'SELS', '기계학습', 'elastic net', '창의성', 'SELS']","본 연구는 학생, 학부모, 교사, 학교를 망라하는 모든 교육 주체를 분석 모형에 포함함으로써 창의성 관련 교육 정책 및 프로그램 수립·이행 시 실효성 제고에 기여하고자 하였다. SELS 8차년도 초4 패널 자료가 제공하는 2,138개 학생, 학부모, 교사, 교장, 학교 변수를 기계학습 기법인 elastic net으로 분석하여 일반계 고등학생의 창의성 예측 변수를 탐색하였다. 벌점회귀모형 기법 중 하나인 elastic net은 변수 선택이 가능하며 다중공선성까지 고려하므로 대용량 사회과학 자료 분석에 적절하다. SELS의 1,422개 설명변수를 elastic net 모형에 투입한 결과, 성취목표, 탄력성, 자아개념, 자기주도학습능력과 같은 학습 및 심리 특성 변수 21개, 진로성숙도, 진로탐색활동과 같은 진학 및 진로 변수 10개, 학부모와 자녀의 관계, 독서, 문화예술활동과 같은 가정 생활 변수 6개, 컴퓨터 및 스마트폰 활용 능력과 같은 ICT 활용 변수 3개, 교우관계, 학교폭력, 교사 및 수업 평가 등 학교 정규 수업 및 학교생활에 관한 변수 6개의 총 46개의 변수가 선택되었다. 본 연구모형이 선택한 변수 중 자기주도적 학습 능력, 자아개념, 성취목표 등의 학습 및 심리 특성 변수, 진로체험활동과 같은 진로 관련 변수, 문화체험활동, 컴퓨터활용능력 등은 선행연구에서 다뤄졌던 변수들이다. 본 연구가 새롭게 발굴한 변수는 학교폭력, 건강 상태, 교우 관계, 영어 수업 관련 변수 등이다. 연구 결과를 토대로 자유학기제(또는 자유학년제), 2015개정 교육과정의 소프트웨어교육, 위(Wee) 클래스 등과 관련한 학교 및 교육청 차원에서의 노력에 대하여 논하였다. 마지막으로, SELS 자료 수집 시 개선 사항에 대하여 제언하였다.","Previous creativity research has focused on student predictors, but teacher and school predictors also need to be identified to increase school accountability and teacher awarenss for creativity education at schools. Initially, all 2,138 variables from SELS (Seoul Educational Longitudinal Study) student, parent, teacher, principal, and school datasets were considered for predictive model building. Elastic net, best-known for selecting variables and handling multicollinearity issues, was employed as a machine learning technique. Consequently, a total of 46 predictors were selected out of 1,422 predictor candidates. Selected predictors such as students’ self-concept, self-directed learning, career-based activities, cultural experience activities, and computer efficiency were also frequently investigated in previous research. Newly found predictors include school violence experiences (spreading evil rumor), students’ peer relation, and English instruction-related variables. Implications were discussed based on the results. Specifically, school and district’s efforts should be exerted on the operations of free-semester, 2015 revised curriculum’s software education, and Wee classes. Lastly, suggestions on panel data collection were made such as switching to online surveys and delivering actual creativity tests to subsampled students."
Video Quality Representation Classification of Encrypted HTTP Adaptive Video Streaming,2018,"['Machine Learning', 'Quality Representation Classification', 'HTTPS Video Streaming', 'Encrypted Traffic', 'YouTube']",,"The increasing popularity of HTTP adaptive video streaming services has dramatically increased bandwidth requirements on operator networks, which attempt to shape their traffic through Deep Packet inspection (DPI). However, Google and certain content providers have started to encrypt their video services. As a result, operators often encounter difficulties in shaping their encrypted video traffic via DPI. This highlights the need for new traffic classification methods for encrypted HTTP adaptive video streaming to enable smart traffic shaping. These new methods will have to effectively estimate the quality representation layer and playout buffer. We present a new machine learning method and show for the first time that video quality representation classification for (YouTube) encrypted HTTP adaptive streaming is possible. The crawler codes and the datasets are provided in [43,44,51]. An extensive empirical evaluation shows that our method is able to independently classify every video segment into one of the quality representation layers with 97% accuracy if the browser is Safari with a Flash Player and 77% accuracy if the browser is Chrome, Explorer, Firefox or Safari with an HTML5 player."
Early fire detection using convolutional neural networks during surveillance for effective disaster management,2018,"['Machine learning', 'Image classification', 'Learning vision', 'Deep learning', 'Surveillance networks', 'Fire detection', 'Disaster management']",,"<P>Fire disasters are man-made disasters, which cause ecological, social, and economic damage. To minimize these losses, early detection of fire and an autonomous response are important and helpful to disaster management systems. Therefore, in this article, we propose an early fire detection framework using fine-tuned convolutional neural networks for CCTV surveillance cameras, which can detect fire in varying indoor and outdoor environments. To ensure the autonomous response, we propose an adaptive prioritization mechanism for cameras in the surveillance system. Finally, we propose a dynamic channel selection algorithm for cameras based on cognitive radio networks, ensuring reliable data dissemination. Experimental results verify the higher accuracy of our fire detection scheme compared to state-of-the-art methods and validate the applicability of our framework for effective fire disaster management. (C) 2017 Elsevier B.V. All rights reserved.</P>"
Microblog Sentiment Analysis Method Based on Spectral Clustering,2018,"['Machine Learning', 'RDM', 'Sentiment Analysis', 'Spectral Cluster']",,"This study evaluates the viewpoints of user focus incidents using microblog sentiment analysis, which has been actively researched in academia. Most existing works have adopted traditional supervised machine learning methods to analyze emotions in microblogs; however, these approaches may not be suitable in Chinese due to linguistic differences. This paper proposes a new microblog sentiment analysis method that mines associated microblog emotions based on a popular microblog through user-building combined with spectral clustering to analyze microblog content. Experimental results for a public microblog benchmark corpus show that the proposed method can improve identification accuracy and save manually labeled time compared to existing methods."
인공신경망 기반 가스 분류기의 설계,2018,"['machine learning', 'artificial neural network', 'RCE-NN', 'gas classification', 'FPGA']",,"In this paper, we propose the gas classifier based on restricted column energy neural network (RCE-NN) and present its hardware implementation results for real-time learning and classification. Since RCE-NN has a flexible network architecture with real-time learning process, it is suitable for gas classification applications. The proposed gas classifier showed 99.2% classification accuracy for the UCI gas dataset and was implemented with 26,702 logic elements with Intel-Altera cyclone IV FPGA. In addition, it was verified with FPGA test system at an operating frequency of 63MHz."
도로 및 기상조건을 고려한 노면온도변화 패턴 추정 모형 개발,2018,"['machine learning', 'vehicular ambient temperature', 'road surface temperature', 'average absolute error', 'road type']",,"PURPOSES: This study develops various models that can estimate the pattern of road surface temperature changes using machine learning methods. METHODS : Both a thermal mapping system and weather forecast information were employed in order to collect data for developing the models. In previous studies, the authors defined road surface temperature data as a response, while vehicular ambient temperature, air temperature, and humidity were considered as predictors. In this research, two additional factors-road type and weather forecasts-were considered for the estimation of the road surface temperature change pattern. Finally, a total of six models for estimating the pattern of road surface temperature changes were developed using the MATLAB program, which provides the classification learner as a machine learning tool. RESULTS: Model 5 was considered the most superior owing to its high accuracy. It was seen that the accuracy of the model could increase when weather forecasts (e.g., Sky Status) were applied. A comparison between Models 4 and 5 showed that the influence of humidity on road surface temperature changes is negligible. CONCLUSIONS: Even though Models 4, 5, and 6 demonstrated the same performance in terms of average absolute error (AAE), Model 5 can be considered the optimal one from the point of view of accuracy."
Fast Convolutional Method for Automatic Sleep Stage Classification,2018,"['Machine Learning', 'Neural Networks', 'Classification', 'Sleep Stages', 'Polysomnography']",,"Objectives: Polysomnography is essential to diagnose sleep disorders. It is used to identify a patient’s sleep pattern during sleep. This pattern is obtained by a doctor or health practitioner by using a scoring process, which is time consuming. To overcome this problem, we developed a system that can automatically classify sleep stages. Methods: This paper proposes a new method for sleep stage classification, called the fast convolutional method. The proposed method was evaluated against two sleep datasets. The first dataset was obtained from physionet.org, a physiologic signals data centers. Twenty-five patients who had a sleep disorder participated in this data collection. The second dataset was collected in Mitra Keluarga Kemayoran Hospital, Indonesia. Data was recorded from ten healthy respondents. Results: The proposed method reached 73.50% and 56.32% of the F-measures for the PhysioNet and Mitra Keluarga Kemayoran Hospital data, respectively. Both values were the highest among all the machine learning methods considered in this study. The proposed method also had an efficient running time. The fast convolutional models of the PhysioNet and Mitra Keluarga Kemayoran Hospital data needed 42.60 and 0.06 seconds, respectively. Conclusions: The fast convolutional method worked well on the tested datasets. It achieved a high F-measure result and an efficient running time. Thus, it can be considered a promising tool for sleep stage classification."
기계학습 알고리즘을 이용한 소프트웨어 취약 여부 예측 시스템,2018,"['Machine Learning', 'Fuzzing', 'Prediction', 'Vulnerability', 'Confusion Matrix']","4차 산업혁명 시대에 우리는 소프트웨어 홍수 속에 살고 있다. 그러나, 소프트웨어의 증가는 필연적으로 소프트웨어 취약점 증가로 이어지고 있어 소프트웨어 취약점을 탐지 및 제거하는 작업이 중요하게 되었다. 현재까지 소프트웨어 취약 여부를 예측하는 연구가 진행되었지만, 탐지 시간이 오래 걸리거나, 예측 정확도가 높지 않았다. 따라서 본 논문에서는 기계학습 알고리즘을 이용하여 소프트웨어의 취약 여부를 효율적으로 예측하는 방법을 설명하며, 다양한 기계학습 알고리즘을 이용한 실험 결과를 비교한다. 실험 결과 k-Nearest Neighbors 예측 모델이 가장 높은 예측률을 보였다.","In the Era of the Fourth Industrial Revolution, we live in huge amounts of software. However, as software increases, software vulnerabilities are also increasing. Therefore, it is important to detect and remove software vulnerabilities. Currently, many researches have been studied to predict and detect software security problems, but it takes a long time to detect and does not have high prediction accuracy. Therefore, in this paper, we describe a method for efficiently predicting software vulnerabilities using machine learning algorithms. In addition, various machine learning algorithms are compared through experiments. Experimental results show that the k-nearest neighbors prediction model has the highest prediction rate."
Filter Method와 Classification 알고리즘을 이용한 전자상거래 블랙컨슈머 탐지에 대한 연구,2018,"['Machine Learning', 'Supervised Learning', 'Fraud Detection', 'User Classification', 'Feature Selection']","빠른 속도로 성장하고 있는 전자상거래 시장이 기업들에게 고객층을 넓혀나갈 좋은 기회를 제공하고 있는 반면에블랙컨슈머로 인한 기업들의 피해 사례 또한 늘어나고 있다. 본 연구는 전자상거래 고객 데이터를 통해 전자상거래상의 블랙컨슈머를 탐지해내는 머신 러닝 모델을 구축하고 최적화하는 것을 목표로 한다. Feature selection의filter method와 4개의 classification 알고리즘을 이용한 실험을 통해 F-measure 0.667의 정확도로 블랙컨슈머를 탐지하는 모델을 구축하였으며 F-measure에서 11.44%, AURC에서 10.51%, TPR에서 22.87%의 성능향상을 확인 할 수 있었다.","Although fast-growing e-commerce markets gave a lot of companies opportunities to expand their customer bases, it isalso the case that there are growing number of cases in which the so-called ‘black consumers’ cause much damage onmany companies. In this study, we will implement and optimize a machine learning model that detects black consumersusing customer data from e-commerce store. Using filter method for feature selection and 4 different algorithms forclassification, we could get the best-performing machine learning model that detects black consumer with F-measure 0.667and could also yield improvements in performance which are 11.44% in F-measure, 10.51% in AURC, and 22.87% in TPR."
Design of Cognitive Fog Computing for Intrusion Detection in Internet of Things,2018,"['Extreme learning machine', 'fog computing', 'Internet of things (IoT)', 'intrusion detection system']",,"Internet of things (IoT) is penetrating into every aspect of our lives including our body, our home and our living environment along with numerous security challenges. With rapidly growing number of connected devices in IoT, the scope for cyber-attack also increases exponentially. Therefore an effective intrusion detection system (IDS) is needed to efficiently detect the attack at faster rate in highly scalable and dynamic IoT environment. In this paper, a novel intrusion detection technique is proposed based on fog computing using Online Sequential Extreme Learning Machine (OS-ELM) which can intelligently interpret the attacks from the IoT traffic. In the proposed system, the existing centralized cloud intelligence in detecting the attack is distributed to local fog nodes to detect the attack at faster rate for IoT application. The distributed architecture of fog computing enables distributed intrusion detection mechanism with scalability, flexibility and interoperability. The analysis of the proposed system proves to be efficient in terms of response time and detection accuracy."
비정형 정보와 CNN 기법을 활용한 이진 분류 모델의 고객 행태 예측,2018,"['고객 행태 예측', '합성곱 신경망', '딥러닝', '고객의 소리', 'Customer Behavior Prediction', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Voice of Customer(VOC)']",,"Deep learning is getting attention recently. The deep learning technique which had been applied in competitions of the International Conference on Image Recognition Technology(ILSVR) and AlphaGo is Convolution Neural Network(CNN). CNN is characterized in that the input image is divided into small sections to recognize the partial features and combine them to recognize as a whole. Deep learning technologies are expected to bring a lot of changes in our lives, but until now, its applications have been limited to image recognition and natural language processing.  The use of deep learning techniques for business problems is still an early research stage. If their performance is proved, they can be applied to traditional business problems such as future marketing response prediction, fraud transaction detection, bankruptcy prediction, and so on. So, it is a very meaningful experiment to diagnose the possibility of solving business problems using deep learning technologies based on the case of online shopping companies which have big data, are relatively easy to identify customer behavior and has high utilization values. Especially, in online shopping companies, the competition environment is rapidly changing and becoming more intense. Therefore, analysis of customer behavior for maximizing profit is becoming more and more important for online shopping companies.  In this study, we propose CNN model of Heterogeneous Information Integration using CNN as a way to improve the predictive power of customer behavior in online shopping enterprises. In order to propose a model that optimizes the performance, which is a model that learns from the convolution neural network of the multi-layer perceptron structure by combining structured and unstructured information, this model uses heterogeneous information integration, unstructured information vector conversion, ‘multi-layer perceptron design, and evaluate the performance of each architecture, and confirm the proposed model based on the results. In addition, the target variables for predicting customer behavior are defined as six binary classification problems: re-purchaser, churn, frequent shopper, frequent refund shopper, high amount shopper, high discount shopper.  In order to verify the usefulness of the proposed model, we conducted experiments using actual data of domestic specific online shopping company. This experiment uses actual transactions, customers, and VOC data of specific online shopping company in Korea. Data extraction criteria are defined for 47,947 customers who registered at least one VOC in January 2011 (1 month). The customer profiles of these customers, as well as a total of 19 months of trading data from September 2010 to March 2012, and VOCs posted for a month are used. The experiment of this study is divided into two stages. In the first step, we evaluate three architectures that affect the performance of the proposed model and select optimal parameters. We evaluate the performance with the proposed model.  Experimental results show that the proposed model, which combines both structured and unstructured information, is superior compared to NBC(Naïve Bayes classification), SVM(Support vector machine), and ANN(Artificial neural network). Therefore, it is significant that the use of unstructured information contributes to predict customer behavior, and that CNN can be applied to solve business problems as well as image recognition and natural language processing problems. It can be confirmed through experiments that CNN is more effective in understanding and interpreting the meaning of context in text VOC data. And it is significant that the empirical research based on the actual data of the e-commerce company can extract very meaningful information from the VOC data written in the text format directly by the customer in the prediction of the customer behavior. Finally, through various experiments, it is possible to say that the proposed model"
전이학습에 방법에 따른 컨벌루션 신경망의영상 분류 성능 비교,2018,"['Deep Learning', 'Computer Vision', 'Convolutional Neural Network', 'Transfer Learnin']",,"Core algorithm of deep learning Convolutional Neural Network(CNN) shows better performance than other machine learning algorithms. However, if there is not sufficient data, CNN can not achieve satisfactory performance even if the classifier is excellent. In this situation, it has been proven that the use of transfer learning can have a great effect. In this paper, we apply two transition learning methods(freezing, retraining) to three CNN models(ResNet-50, Inception-V3, DenseNet-121) and compare and analyze how the classification performance of CNN changes according to the methods. As a result of statistical significance test using various evaluation indicators, ResNet-50, Inception-V3, and DenseNet-121 differed by 1.18 times, 1.09 times, and 1.17 times, respectively. Based on this, we concluded that the retraining method may be more effective than the freezing method in case of transition learning in image classification problem."
라이다의 밀집도 영상을 이용한 고속 3차원 차량 검출 방법,2018,"['3D lidar', 'density image', 'height image', 'support vector machine', '3D detection', 'autonomous vehicle']",,"The deep-learning-based method is a costly method that requires the addition of a lot of learning data and hardware. This paper proposes a 3D vehicle detection method using only 3D lidar in autonomous vehicles. The proposed method generates density image and height image using point clouds. Candidates of the vehicle are detected from the complex image, and images for extracting features are generated from each candidate. In addition, we use the SVM (Support Vector Machine) instead of deep-learning, a low-cost learning method, to classify HOG (Histogram of Oriented Gradient) feature vectors. The proposed method can reduce the amount of computation as well as the execution time. The vehicle can be detected and the distance to the vehicle can be measured. Experimental results show the performance of the proposed method."
Design of Cognitive Fog Computing for Intrusion Detection in Internet of Things,2018,"['Extreme learning machine', 'fog computing', 'Internet of things (IoT)', 'intrusion detection system']",,"Internet of things (IoT) is penetrating into every aspectof our lives including our body, our home and our living environmentalong with numerous security challenges.With rapidly growingnumber of connected devices in IoT, the scope for cyber-attackalso increases exponentially. Therefore an effective intrusion detectionsystem (IDS) is needed to efficiently detect the attack at fasterrate in highly scalable and dynamic IoT environment. In this paper,a novel intrusion detection technique is proposed based on fog computingusing Online Sequential Extreme Learning Machine (OSELM)which can intelligently interpret the attacks from the IoTtraffic. In the proposed system, the existing centralized cloud intelligencein detecting the attack is distributed to local fog nodesto detect the attack at faster rate for IoT application. The distributedarchitecture of fog computing enables distributed intrusiondetection mechanism with scalability, flexibility and interoperability.The analysis of the proposed system proves to be efficientin terms of response time and detection accuracy."
하이브리드 특징 및 기계학습을 활용한 효율적인 악성코드 분류 시스템 개발 연구,2018,"['Malware', 'Classification', 'Machine Learning', 'ssdeep']","기하급수적으로 증가하고 있는 변종 악성코드에 대응하기 위해 악성코드 분류 연구가 다양화되고 있다. 최근 연구에서는 기존 악성코드 분석 기술 (정적/동적)의 개별 사용 한계를 파악하고, 각 방식을 혼합한 하이브리드 분석으로 전환하는 추세이다. 나아가, 분류가 어려운 변종 악성코드를 더욱 정확하게 식별하기 위해 기계학습을 적용하기에 이르렀다. 하지만, 각 방식을 모두 활용했을 때 발생하는 정확성, 확장성 트레이드오프 문제는 여전히 해결되지 못했으며, 학계에서 중요한 연구 주제이다. 이에 따라, 본 연구에서는 기존 악성코드 분류 연구들의 문제점을 보완하기 위해 새로운 악성코드 분류 시스템을 연구 및 개발한다.","In order to cope with dramatically increasing malware variant, malware classification research is getting diversified. Recent research tend to grasp individual limits of existing malware analysis technology (static/dynamic), and to change each method into “hybrid analysis”, which is to mix different methods into one. Futhermore, it is applying machine learning to identify malware variant more accurately, which are difficult to classify. However, accuracy and scalability of trade-off problems that occur when using all kinds of methods are not yet to be solved, and it is still an important issue in the field of malware research. Therefore, to supplement and to solve the problems of the original malware classification research, we are focusing on developing a new malware classification system in this research."
Prediction of compressive strength of GGBS based concrete using RVM,2018,"['relevance vector machine', 'GGBS', 'concrete', 'compressive strength', 'variance']",,"Ground granulated blast furnace slag (GGBS) is a by product obtained from iron and steel industries, useful in the design and development of high quality cement paste/mortar and concrete. This paper investigates the applicability of relevance vector machine (RVM) based regression model to predict the compressive strength of various GGBS based concrete mixes. Compressive strength data for various GGBS based concrete mixes has been obtained by considering the effect of water binder ratio and steel fibres. RVM is a machine learning technique which employs Bayesian inference to obtain parsimonious solutions for regression and classification. The RVM is an extension of support vector machine which couples probabilistic classification and regression. RVM is established based on a Bayesian formulation of a linear model with an appropriate prior that results in a sparse representation. Compressive strength model has been developed by using MATLAB software for training and prediction. About 70% of the data has been used for development of RVM model and 30% of the data is used for validation. The predicted compressive strength for GGBS based concrete mixes is found to be in very good agreement with those of the corresponding experimental observations."
A methodology to derive global maps of leaf traits using remote sensing and climate data,2018,"['Plant traits', 'Machine learning', 'Random forests', 'Remote sensing', 'Plant ecology', 'Climate', 'MODIS', 'Landsat']",,"<P><B>Abstract</B></P>  <P>This paper introduces a modular processing chain to derive global high-resolution maps of leaf traits. In particular, we present global maps at 500 m resolution of specific leaf area, leaf dry matter content, leaf nitrogen and phosphorus content per dry mass, and leaf nitrogen/phosphorus ratio. The processing chain exploits machine learning techniques along with optical remote sensing data (MODIS/Landsat) and climate data for gap filling and up-scaling of in-situ measured leaf traits. The chain first uses random forests regression with surrogates to fill gaps in the database (> 45<I>%</I> of missing entries) and maximizes the global representativeness of the trait dataset. Plant species are then aggregated to Plant Functional Types (PFTs). Next, the spatial abundance of PFTs at MODIS resolution (500 m) is calculated using Landsat data (30 m). Based on these PFT abundances, representative trait values are calculated for MODIS pixels with nearby trait data. Finally, different regression algorithms are applied to globally predict trait estimates from these MODIS pixels using remote sensing and climate data. The methods were compared in terms of precision, robustness and efficiency. The best model (random forests regression) shows good precision (normalized RMSE≤ 20<I>%</I>) and goodness of fit (averaged Pearson's correlation R = 0.78) in any considered trait. Along with the estimated global maps of leaf traits, we provide associated uncertainty estimates derived from the regression models. The process chain is modular, and can easily accommodate new traits, data streams (traits databases and remote sensing data), and methods. The machine learning techniques applied allow attribution of information gain to data input and thus provide the opportunity to understand trait-environment relationships at the plant and ecosystem scales. The new data products – the gap-filled trait matrix, a global map of PFT abundance per MODIS gridcells and the high-resolution global leaf trait maps – are complementary to existing large-scale observations of the land surface and we therefore anticipate substantial contributions to advances in quantifying, understanding and prediction of the Earth system.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Presented a modular process chain for plant trait mapping including local effects </LI> <LI>  High-resolution global maps of leaf traits by fusing measured trait data, LANDSAT and MODIS </LI> <LI>  Scope for testing and parameterizing trait-enabled Earth System models </LI> <LI>  Implications for land management and Earth system science applications </LI> </UL> </P>"
On the Performance of Cuckoo Search and Bat Algorithms Based Instance Selection Techniques for SVM Speed Optimization with Application to e-Fraud Detection,2018,"['Support Vector Machines', 'classification', 'machine learning', 'phishing email', 'spam email']",,"Support Vector Machine (SVM) is a well-known machine learning classification algorithm, which has been widely applied to many data mining problems, with good accuracy. However, SVM classification speed decreases with increase in dataset size. Some applications, like video surveillance and intrusion detection, requires a classifier to be trained very quickly, and on large datasets. Hence, this paper introduces two filter-based instance selection techniques for optimizing SVM training speed. Fast classification is often achieved at the expense of classification accuracy, and some applications, such as phishing and spam email classifiers, are very sensitive to slight drop in classification accuracy. Hence, this paper also introduces two wrapper-based instance selection techniques for improving SVM predictive accuracy and training speed. The wrapper and filter based techniques are inspired by Cuckoo Search Algorithm and Bat Algorithm. The proposed techniques are validated on three popular e-fraud types: credit card fraud, spam email and phishing email. In addition, the proposed techniques are validated on 20 other datasets provided by UCI data repository. Moreover, statistical analysis is performed and experimental results reveals that the filter-based and wrapper-based techniques significantly improved SVM classification speed. Also, results reveal that the wrapper-based techniques improved SVM predictive accuracy in most cases."
문서 구조 및 스트림 오브젝트 분석을 통한 문서형 악성코드 탐지,2018,"['malware', 'PDF', 'machine learning', 'java script', 'detection']",,"In recent years, there has been an increasing number of ways to distribute document-based malicious code using vulnerabilities in document files. Because document type malware is not an executable file itself, it is easy to bypass existing security programs, so research on a model to detect it is necessary. In this study, we extract main features from the document structure and the JavaScript contained in the stream object In addition, when JavaScript is inserted, keywords with high occurrence frequency in malicious code such as function name, reserved word and the readable string in the script are extracted. Then, we generate a machine learning model that can distinguish between normal and malicious. In order to make it difficult to bypass, we try to achieve good performance in a black box type algorithm. For an experiment, a large amount of documents compared to previous studies is analyzed. Experimental results show 98.9% detection rate from three different type algorithms. SVM, which is a black box type algorithm and makes obfuscation difficult, shows much higher performance than in previous studies."
AI시대 인간번역과 기계(NMT)번역의 공존 - 경영학 ‘확장(Augmentation)전략’ 중심,2018,"['NMT', 'human-machine coexistence', 'imployability', 'post-editing', 'translation and technology']",,"Human translators are deeply worried that they might be replaced by machines capable of translating and interpreting through deep learning and big data analysis. This paper takes a complementary mindset rather than either-or mindset to shift translation’s relationships with machines from automation to augmentation. The objective of this study is to set out specific areas of works where humans can coexist with intelligent machines, turning this challenge into an opportunity to expand the scope of translation rather than diminishing it. This paper adopts a model from the business administration field as a framework. It is “five-paths toward employability” (Davenport & Kirby, 2015) based on “augmentation strategy” and “complementarity” (Autor, 2014). Based on the characteristics of translation in this changing world, I could derive employable areas for human translators in the age of AI: human translators can ‘step up’ as managers establishing a platform, overseeing the whole translation process, building corpus database and coordinating collaboration among participants; ‘step aside’ as communicators catering to the linguistic and cultural needs of each party; ‘step in’ as revisers conducting pre-editing or post-editing for translations done by machines; ‘step narrowly’ as translators doing works only humans can do like literary translation; ‘step forward’ as innovators or entrepreneurs creating new areas of business such as combining language service with voice recognition, applying augmented reality technology into translation."
구글 ‘Tensor Flow’를 이용한 웹사이트 악성 코드 유포지 위험도 분석 시스템 연구,2018,"['Malicious Code', 'Machine learning', 'Tensor Flow', 'Malware', 'Artificial intelligence', '악성 코드', '머신 러닝', '텐서플로', '멀웨어', '인공지능']",,"Recently, with the development of the Internet, the spread of malicious codes using the Internet is one of the serious cyber threats, and the malicious code distribution technology applied by the detection bypass technique is rapidly developing, and researches for detecting and analyzing this are being actively carried out. However, existing malicious code distribution webpage detection system is based on signature, so obfuscated malicious JavaScript is almost impossible to detect, and there is a limitation that analysts have to constantly update detection pattern after detection. To overcome these limitations, we propose an intelligent malicious code distributed web page detection system using machine learning that can effectively analyze and detect intelligent malicious code distributed web pages."
Deep Neural Network 기반 프로야구 일일 관중 수 예측 : 광주-기아 챔피언스 필드를 중심으로,2018,"['한국프로야구', 'DNN', '머신러닝', '수요예측', 'Korean Baseball League', 'Deep Neural Network', 'Machine Learning', 'Demand Forecasting']",,"In this paper, we used the Deep Neural Network (DNN) to predict the number of daily spectators of Gwangju -KIA Champions Field in order to provide marketing data for the team and related businesses and for managing the inventories of the facilities in the stadium. In this study, the DNN model, which is based on an artificial neural network (ANN), was used, and four kinds of DNN model were designed along with dropout and batch normalization model to prevent overfitting. Each of four models consists of 10 DNNs, and we added extra models with ensemble model. Each model was evaluated by Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE). The learning data from the model randomly selected 80% of the collected data from 2008 to 2017, and the other 20% were used as test data. With the result of 100 data selection, model configuration, and learning and prediction, we concluded that the predictive power of the DNN model with ensemble model is the best, and RMSE and MAPE are 15.17% and 14.34% higher, correspondingly, than the prediction value of the multiple linear regression model."
전처리와 특징 추출이 CNN기반 화재 탐지 성능에 미치는 효과,2018,"['화재 탐지', '딥러닝', 'CNN', '전처리', '특징 추출', 'Fire Detection', 'Deep Learning', 'Preprocessing', 'Feature Extraction']","최근 들어 머신 러닝 기술의 발달로 기존 영상 기반의 응용시스템에 딥러닝 기술을 적용하는 사례들이 늘고 있다. 이러한 맥락에서 화재 감지 분야에서도 CNN (Convolutional Neural Network)을 적용하는 시도들이 이루어지고 있다. 본 논문에서는 기존 전처리 방법과 특징 추출 방법이 CNN과 결합되었을 때 화재 탐지에 어떤 효과를 유발하는지를 검증하기 위해 인식 성능과 학습 시간을 평가해 보았다. VGG19 CNN 구조를 변경, 즉 컨볼루션층을 조금씩 늘리면서 실험을 진행한 결과, 일반적으로 전처리하지 않는 이미지를 사용한 경우가 성능이 훨씬 좋음을 확인할 수 있었다. 또한 성능적인 측면에서는 전처리 방법과 특징 추출 방법이 부정적인 영향을 미치지만 학습속도 측면에서는 많은 이득이 있음을 확인할 수 있었다.","Recently, the development of machine learning technology has led to the application of deep learning technology to existing image based application systems. In this context, some researches have been made to apply CNN (Convolutional Neural Network) to the field of fire detection. To verify the effects of existing preprocessing and feature extraction methods on fire detection when combined with CNN, in this paper, the recognition performance and learning time are evaluated by changing the VGG19 CNN structure while gradually increasing the convolution layer. In general, the accuracy is better when the image is not preprocessed. Also it’s shown that the preprocessing method and the feature extraction method have many benefits in terms of learning speed."
BEGINNER'S GUIDE TO NEURAL NETWORKS FOR THE MNIST DATASET USING MATLAB,2018,"['Neural network', 'Machine learning', 'Pattern recognition', 'MNIST dataset', 'MATLAB']",,"MNIST dataset is a database containing images of handwritten digits, with each image labeled by an integer from 0 to 9. It is used to benchmark the performance of machine learning algorithms. Neural networks for MNIST are regarded as the starting point of the studying machine learning algorithms. However it is not easy to start the actual programming. In this expository article, we will give a step-by-step instruction to build neural networks for MNIST dataset using MATLAB."
Fault Diagnosis System based on Sound using Feature Extraction Method of Frequency Domain,2018,"['Pattern Recognition', 'Machine Learning', 'Machine Fault Diagnosis', 'Magnitude Spectrum', 'Principal Component Analysis', 'Artificial Neural Network']",,"Sound based machine fault diagnosis is the process consisting of detecting automatically the damages that affect the machines by analyzing the sounds they produce during their operating time. The collected sounds being inevitably corrupted by random disturbance, the most important part of the diagnosis consists of discovering the hidden elements inside the data that can reveal the faulty patterns. This paper presents a novel feature extraction methodology that combines various digital signal processing and pattern recognition methods for the analysis of the sounds produced by the drills. Using the Fourier analysis, the magnitude spectrum of the sounds are extracted, converted into two-dimensional vectors and uniformly normalized in such a way that they can be represented as 8-bit grayscale images. Histogram equalization is then performed over the obtained images in order to adjust their very poor contrast. The obtained contrast enhanced images will be used as the features of our diagnosis system. Finally, principal component analysis is performed over the image features for reducing their dimensions and a nonlinear classifier is adopted to produce the final response. Unlike the conventional features, the results demonstrate that the proposed feature extraction method manages to capture the hidden health patterns of the sound."
Assessing the readability of fiction: A corpus analysis and readability ranking of 200 English fiction texts,2018,"['readability', 'text complexity', 'fiction', 'machine learning', 'computational linguistics', 'corpus linguistics']",,"Standard readability measures are based on the readability of non-fiction texts. This means that the validity of the measures when applied to fiction texts is questionable. Thus, the scores given to fiction texts using such indicesmay be invalid when used by English teachers to identify fiction texts of appropriate difficulty for students with various reading ability levels. This paper attempts to address this problem by 1) developing a readability measure specifically designed for fiction texts and 2) applying it to 200 English fiction texts. A corpus, consisting of 100 adults  and 100 children s texts, is used for the analysis. In the initial modeling, several standard readability measures are used as variables, and machine learning is used to create a classifier which is able to classify the corpus with an accuracy of 84%. A second classifier is then created using linguistic variables rather than standard readability measures. The latter classifier is able to classify the corpus with an accuracy of 89%, indicating that the standard readability measures are less accurate in classifying fiction texts than linguistic variables. Due to its higher accuracy, the latter classifier is then used to provide a linear complexity or  readability  rank for each text. The ranking using the linguistic-based classifier provides an more accurate method of determining which texts to choose for students according to their reading levels than the standard readability measures. Importantly, the ranking instantiates a fine-grained increase in complexity. This means that the ranking can be used by an English teacher to selecta sequence of texts that represent an increasing challenge to a student without there being a frustratingly discrete rise in difficulty."
DSMS 환경에서 이상 탐지를 위한 SVM과 리샘플링 기법의 분석,2018,"['이상 탐지', '서포트 벡터 머신', '리샘플링', 'DSMS', 'CQL', 'anomaly detection', 'support vector machine']","실시간 스트림 데이터가 연속적으로 들어오는 DSMS(Data Stream Management System) 환경에서 그 데이터들의 이상여부를 판단하는 아키텍쳐를 고안한다. DSMS는 전통적인 데이터베이스관리시스템보다 스트림 데이터를 처리하는데 최적화된 시스템이며, 일부 제품에서는 SQL 대신 CQL(Continuous Query Language)을 사용한다. 따라서 DSMS에서 이상탐지를 수행하기 위해서는 이상탐지 모델을 CQL로 DSMS에 등록해야 한다. 본 논문도 이러한 DSMS 환경에서의 이상탐지 상황을 상정하고, 이상탐지모델을 CQL로 구현하려한다. CQL로의 구현을 고려하여 이상탐지를 위한 클래스 예측 알고리즘은 SVM(Support Vector Machine)을 사용한다. 그리고 본 실험에서는 SVM의 검증 성능을 높이기 위한 실험을 진행한다. 데이터집합의 클래스가 불균형할 때 발생할 수 있는 학습모델의 검증 성능 저하 문제를 리샘플링기법을 적용시켜 해결한다. 또한, 학습한 SVM모델의 임계값(threshold)을 조정하여 검증 성능을 최적화한다. 최종적으로 리샘플링된 데이터로 학습하고 임계값 조정된 SVM모델을 CQL로 변환하는 작업을 수행한다. 이 과정은 두 개의 자동화된 변환 블록을 거쳐서 수행하도록 구현한다.","In the DSMS (Data Stream Management System) environment, which receives real-time stream data continuously, we devised an architecture to judge whether the data is abnormal or not. DSMS is optimized for processing stream data rather than traditional DBMS, and some products use CQL (Continuous Query Language) instead of SQL. Therefore, an anomaly-detection model must be registered as a CQL in order to perform anomaly detection in the DSMS. This paper assumes an anomaly-detection situation in such a DSMS environment and implements the anomaly-detection model in CQL. Considering the implementation in CQL, we used an SVM (Support Vector Machine) as a class-prediction algorithm for anomaly detection. We performed experiments to improve the validation performance of the SVM. We solved the problem that validation performance of a learned model declines when the dataset is imbalanced, by applying resampling techniques. In addition, we adjusted the threshold of the learned SVM model to optimize the validation performance. Finally, we converted the threshold-tuned SVM model learned by resampled dataset to CQL. This process was implemented by means of two automated transformation blocks."
Investigation into Tolerance of Mislabeling when Classifying Patterns with Dual-kNN,2018,"['Dual-kNN', 'Density-based kNN', 'k-NN', 'Mislabeled noise']",,"As we know, machine learning algorithms are powerful tools for a variety of application domains, giving widely divergent dimensions, such as reliability, precision, robustness, high-speed solutions, etc. Likewise, the other critical dimension that a well-designed learning algorithm should occupy is strength against unpredictable and phenomenal noise. For this critical dimension, we introduce a new approach, dual k-nearest neighbors (dual-kNN), to investigate the tolerance level for mislabeling based on different injected-noise levels. Literally, dual-kNN is a reborn algorithm of k-nearest neighbors (k-NN) aiming to reduce the influence of a steady decrease in prediction accuracy over increasing k values. What is more, dual-kNN is proven to have higher classification accuracy in many application domains. For the primary goal of this paper, we mainly emphasize investigating dual-kNN’s resistance level to mislabeled classes. Provably, our empirical experimentations describe how dual-kNN has a higher resistance level to mislabeling than normal k-NN, density-based kNN, and logistic regression, for noise levels of up to 50%. The practical datasets applied within this paper are medical data files from the University of California, Irvine (UCI) Machine Learning Repository."
Prediction of concrete compressive strength using non-destructive test results,2018,"['concrete', 'compressive strength', 'machine learning regression', 'non-destructive testing']",,"Concrete which is a composite material is one of the most important construction materials. Compressive strength is a commonly used parameter for the assessment of concrete quality. Accurate prediction of concrete compressive strength is an important issue. In this study, we utilized an experimental procedure for the assessment of concrete quality. Firstly, the concrete mix was prepared according to C 20 type concrete, and slump of fresh concrete was about 20 cm. After the placement of fresh concrete to formworks, compaction was achieved using a vibrating screed. After 28 day period, a total of 100 core samples having 75 mm diameter were extracted. On the core samples pulse velocity determination tests and compressive strength tests were performed. Besides, Windsor probe penetration tests and Schmidt hammer tests were also performed. After setting up the data set, twelve artificial intelligence (AI) models compared for predicting the concrete compressive strength. These models can be divided into three categories (i) Functions (i.e., Linear Regression, Simple Linear Regression, Multilayer Perceptron, Support Vector Regression), (ii) Lazy-Learning Algorithms (i.e., IBk Linear NN Search, KStar, Locally Weighted Learning) (iii) Tree- Based Learning Algorithms (i.e., Decision Stump, Model Trees Regression, Random Forest, Random Tree, Reduced Error Pruning Tree). Four evaluation processes, four validation implements (i.e., 10-fold cross validation, 5-fold cross validation, 10% split sample validation & 20% split sample validation) are used to examine the performance of predictive models. This study shows that machine learning regression techniques are promising tools for predicting compressive strength of concrete."
A Study of Image Classification using HMC Method Applying CNN Ensemble in the Infrared Image,2018,"['Infrared image', 'Convolutional neural network', 'Machine learning']",,"In the marine environment, many clutters have similar features with the marine targets due to the diverse changes of the air temperature, water temperature, various weather and seasons. Also, the clutters in the ground environment have similar features due to the same reason. In this paper, we proposed a robust Hybrid Machine Character (HMC) method to classify the targets from the clutters in the infrared images for the various environments. The proposed HMC method adopts human’s multiple personality utilization and the CNN ensemble method to classify the targets in the ground and marine environments. This method uses an advantage of the each environmental training model. Experimental results demonstrate that the proposed method has better success rate to classify the targets and clutters than previously proposed CNN classification method."
인공지능 시대의 마취통증의학 연구,2018,"['Artificial intelligence', 'Big data', 'Machine learning', 'Medical research.']",,"A noteworthy change in recent medical research is the rapid increase of research using big data obtained from electrical medical records (EMR), order communication systems (OCS), and picture archiving and communication systems (PACS). It is often difficult to apply traditional statistical techniques to research using big data because of the vastness of the data and complexity of the relationships. Therefore, the application of artificial intelligence (AI) techniques which can handle such problems is becoming popular.Classical machine learning techniques, such as k-means clustering, support vector machine, and decision tree are still efficient and useful for some research problems. The deep learning techniques, such as multi-layer perceptron, convolutional neural network, and recurrent neural network have been spotlighted by the success of deep belief networks and convolutional neural networks in solving various problems that are difficult to solve by conventional methods. The results of recent research using artificial intelligence techniques are comparable to human experts. This article introduces technologies that help researchers conduct medical research and understand previous literature in the era of AI."
MaxEnt 모형 분석을 통한 남북한 접경지역의 금강초롱꽃 자생가능지 예측,2018,"['HABITAT SUITABILITY MODEL', 'MACHINE LEARNING', 'PROTECTED AREA', 'DEMILIITARIZED ZONE', 'VEGETATION INDEX', '생물종 분포 모형', '기계학습', '보호지역', '비무장지대', '식생지수']","금강초롱꽃(Hanabusaya asiatica)은 한반도 중동부에서만 제한적으로 분포하는 고유종으로, 분포범위가 좁고 개체수가적어 서식지를 세계자연보전연맹(IUCN, International Union for Conservation of Nature) 중요 생물다양성 보호지역(key biodiversity areas: KBAs)으로 지정하여 보호할 필요가 있다. 본 연구에서는 maximum entropy(MaxEnt) 모형을 통해남북한 접경지역 내 금강초롱꽃 자생가능지를 추정하고 이를 바탕으로 KBAs 후보지를 설정하였다. 기계학습(machine learning) 알고리즘의 하나인 MaxEnt 모형은 생물종의 출현지점만 기록한 데이터(presence-only data)로도 생물종 분포를편향되지 않게 예측할 수 있는 생물종 분포 모형으로, 본 연구의 연구대상지처럼 현장 조사가 어려운 경우 유용한 방법이다.","Hanabusaya asiatica is an endemic species whose distribution is limited in the mid-eastern part of the Korean peninsula. Due to its narrow range and small population, it is necessary to protect its habitats by identifying it as Key Biodiversity Areas (KBAs) adopted by the International Union for Conservation of Nature (IUCN). In this paper, we estimated potential natural habitats for H. asiatica using maximum entropy model (MaxEnt) and identified candidate sites for KBA based on the model results. MaxEnt is a machine learning algorithm that can predict habitats for species of interest unbiasedly with presence-only data. This property is particularly useful for the study area where data collection via a field survey is unavailable. We trained MaxEnt using 38 locations of H. asiatica and 11 environmental variables that measured climate, topography, and vegetation status of the study area which encompassed all locations of the border region between South and North Korea. Results showed that the potential habitats where the occurrence probabilities of H. asiatica exceeded 0.5 were 778 km², and the KBA candidate area identified by taking into account existing protected areas was 1,321 km². Of 11 environmental variables, elevation, annual average precipitation, average precipitation in growing seasons, and the average temperature in the coldest month had impacts on habitat selection, indicating that H. asiatica prefers cool regions at a relatively high elevation. These results can be used not only for identifying KBAs but also for the reference to a protection plan for H. asiatica in preparation of Korean reunification and climate change."
Disease risk prediction system using correlated health indexes,2018,"['Database', 'Chronic disease', 'Machine learning', 'Self-symptom checker', 'Bioinformatics']",,"With developments in science and technology and improvement in living standards, human life expectancy is steadily increasing worldwide. For effective healthcare, it is necessary to check health conditions according to individuals’ behavior and acquire prior knowledge on possible diseases. In this study, we classified the diseases that are major causes of death in Korea by referring to data provided by the Korea National Health and Nutrition Examination Survey. We selected indexes that could be used as indicators of major diseases and created the LCBB-SC. In the LCBB-SC, the data are systematically subdivided into related fields to provide integrated data related to each disease and to provide an infrastructure that can be used by researchers. In addition, by developing a web interface allowing for self-symptom assessments, this resource will be beneficial to people who want to check their own health condition using a list of diseases that might be caused by their behaviors."
나이브 베이즈 분류기를 이용한 돌발상황 검지 알고리즘 개발,2018,"['돌발 검지 알고리즘', '머신러닝', 'McMaster 알고리즘', '나이브 베이즈 분류기', 'Incident detection algorithm', 'Machine learning', 'McMaster algorithm', 'Naive Bayes classification']","본 연구에서는 최근 활발하게 활용되고 있는 머신러닝 기법을 교통분야에 적용하여 효율적인 돌발상황 검지 알고리즘을 개발하는 것을 목적으로 하였다. 미시교통시뮬레이션 모형을 통하여 대상지의 네트워크를 구축하였고 돌발상황에 영향을 줄 것으로 예상되는 변수의 여러 조합을 통해 시나리오를 설정하여 가상의 돌발상황 데이터를 수집하였다. 다음으로 대표적인 돌발상황 검지 알고리즘인 McMaster 알고리즘과 본 연구에서 개발한 나이브 베이즈 분류기 를구현하여 비교·평가하였다. 비교 결과, 나이브 베이즈 분류기가 McMaster 알고리즘에 비해 돌발상황 검지 간격에 따른 부정적인 영향이 적었고 더 우수한 검지율을 보였다. 하지만 검지율이 증가하는 만큼 오검지율 또한 증가하는 것을 확인할 수 있었다. McMaster 알고리즘은 4주기를 통해 검지가 가능하지만 나이브 베이즈 분류기는 1주기(30초)만으로 돌발상황을 판단할 수있다. 본 연구를 통해 개발한 나이브 베이즈 분류기가 효율적으로 돌발을 파악할 수 있다는것을 확인할 수 있었다.","The purpose of this study is to develop an efficient incident detection algorithm by applying machine learning, which is being widely used in the transport sector. As a first step, network of the target site was constructed with micro-simulation model. Secondly, data has been collected under various incident scenarios produced with combination of variables that are expected to affect the incident situation. And, detection results from both McMaster algorithm, a well known incident detection algorithm, and the Naive Bayes algorithm, developed in this study, were compared. As a result of comparison, Naive Bayes algorithm showed less negative effect and better detect rate (DR) than the McMaster algorithm. However, as DR increases, so did false alarm rate (FAR). Also, while McMaster algorithm detected in four cycles, Naive Bayes algorithm determine the situation with just one cycle, which increases DR but also seems to have increased FAR. Consequently it has been identified that the Naive Bayes algorithm has a great potential in traffic incident detection."
하위 훈련 성과 융합을 위한 순환적 계층 재귀 모델,2018,"['TNT Model', 'Hierarchical Convergence Model', 'Progress Convergence', 'Recursive Hierarchical Nested model', 'TNT 모델', '계층 융합 모델', '훈련 성과 융합', '순환적 계층 재귀 모델']",,"In recent years, Computer-based learning, such as machine learning and deep learning in the computer field, is attracting attention. They start learning from the lowest level and propagate the result to the highest level to calculate the final result. Research literature has shown that systematic learning and growth can yield good results. However, systematic models based on systematic models are hard to find, compared to various and extensive research attempts. To this end, this paper proposes the first TNT(Transitive Nested Triangle)model , which is a growth and fusion model that can be used in various aspects. This model can be said to be a recursive model in which each function formed through geometric forms an organic hierarchical relationship, and the result is used again as they grow and converge to the top. That is, it is an analytical method called 'Horizontal Sibling Merges and Upward Convergence'. This model is applicable to various aspects. In this study, we focus on explaining the TNT model."
Wavelet-like convolutional neural network structure for time-series data classification,2018,"['convolutional neural networks', 'machine learning', 'deep learning', 'time-series analysis']",,"Time-series data often contain one of the most valuable pieces of information in many fields including manufacturing. Because time-series data are relatively cheap to acquire, they (e.g., vibration signals) have become a crucial part of big data even in manufacturing shop floors. Recently, deep-learning models have shown state-of-art performance for analyzing big data because of their sophisticated structures and considerable computational power. Traditional models for a machinery-monitoring system have highly relied on features selected by human experts. In addition, the representational power of such models fails as the data distribution becomes complicated. On the other hand, deep-learning models automatically select highly abstracted features during the optimization process, and their representational power is better than that of traditional neural network models. However, the applicability of deep-learning models to the field of prognostics and health management (PHM) has not been well investigated yet. This study integrates the ""residual fitting"" mechanism inherently embedded in the wavelet transform into the convolutional neural network deep-learning structure. As a result, the architecture combines a signal smoother and classification procedures into a single model. Validation results from rotor vibration data demonstrate that our model outperforms all other off-the-shelf feature-based models."
SVDD를 활용한 상업용 건물에너지 소비패턴의 이상현상 감지,2018,"['건물에너지', '이상현상감지', '서포트 벡터 머신', '비감시 기계학습', 'Building energy consumption', 'Anomaly detection', 'Support vector data description (SVDD)', 'Unsupervised machine learning']",,"Anomaly detection on building energy consumption has been regarded as an effective tool to reduce energy saving on building operation and maintenance. However, it requires energy model and FDD expert for quantitative model approach or large amount of training data for qualitative/history data approach. Both method needs additional time and labors. This study propose a machine learning and data science approach to define faulty conditions on hourly building energy consumption with reducing data amount and input requirement. It suggests an application of Support Vector Data Description (SVDD) method on training normal condition of hourly building energy consumption incorporated with hourly outdoor air temperature and time integer in a week, 168 data points and identifying hourly abnormal condition in the next day. The result shows the developed model has a better performance when the  (probability of error in the training set) is 0.05 and  (radius of hyper plane) 0.2. The model accuracy to identify anomaly operation ranges from 70% (10% increase anomaly) to 95% (20% decrease anomaly) for daily total (24 hours) and from 80% (10% decrease anomaly) to 10%(15% increase anomaly) for occupied hours, respectively."
Wavelet-like convolutional neural network structure for time-series data classification,2018,"['convolutional neural networks', 'machine learning', 'deep learning', 'time-series analysis']",,"Time-series data often contain one of the most valuable pieces of information in many fields including manufacturing. Because time-series data are relatively cheap to acquire, they (e.g., vibration signals) have become a crucial part of big data even in manufacturing shop floors. Recently, deep-learning models have shown state-of-art performance for analyzing big data because of their sophisticated structures and considerable computational power. Traditional models for a machinery-monitoring system have highly relied on features selected by human experts. In addition, the representational power of such models fails as the data distribution becomes complicated. On the other hand, deep-learning models automatically select highly abstracted features during the optimization process, and their representational power is better than that of traditional neural network models. However, the applicability of deep-learning models to the field of prognostics and health management (PHM) has not been well investigated yet. This study integrates the “residual fitting” mechanism inherently embedded in the wavelet transform into the convolutional neural network deep-learning structure. As a result, the architecture combines a signal smoother and classification procedures into a single model. Validation results from rotor vibration data demonstrate that our model outperforms all other off-the-shelf feature-based models."
Big Data and Doing Research in the Management Discipline,2018,"['Big Data Science', 'Causal Inference', 'Machine Learning', 'Theory']",,"We argue that big data should be understood as an indispensable element in a wider context of big data science that also includes machine learning and results interpretations. By addressing this wider context, we examine the differences between big data science and modern sciences in general and management discipline in particular. While the former adopts data-driven approach to enhance predictive accuracy, the latter adopts theory-driven approach to produce causal explanation. Data-driven approach in conjunction with machine learning strives to enhance the predictive accuracy by allowing big data to choose a set of parameters on its own under rather loose assumptions and learning processes. In contrast, management discipline emphasizes the role of theories in deriving testable hypotheses and encourages scholars to present compelling arguments without explicitly referring to data to be used for estimation at a later stage. This implies that management discipline may not benefit much from big data science in doing academic research. But we believe that big data may prove helpful for the management discipline if we carefully identify small but meaningful patterns that are not easily detected in small data. We also argue that sampling is still an important issue in using big data for academic research."
인공지능 기반의 융복합 예술창작물 사례 분석 및 고찰,2018,"['Artificial Intelligence(인공지능)', 'Art Creation(예술창작물)', 'Supervised Learning(지도 학습)', 'Unsupervised Learning(비지도 학습)', 'Interdisciplinary convergence research (학제간 융합 연구)']","4차 산업혁명의 도래와 함께, 인공지능 기술은 창의성이 요구되는 예술창작으로 그 적용 영역이 확장되고 있다. 본 연구는 문헌연구를 통해 다학제적 융합연구의 관점에서 ‘예술창작의 수단’으로서의 인간의 창의성과 인공지능이 융합된 예술창작물의 사례를 학습 모델과 관람객의 참여형태를 기반으로 분석하고, 융합적 관점에서 인공지능 기반의 예술창작물의 의미를 조명하는데 그 목적을 두고 있다.  본 연구에서 다룬 인공지능 기반의 상호작용형 예술창작물은 관람객을 참여자나 공동 창작자로 전환시키면서 예술창작에 대한 관람객의 역할에 새로운 의미를 부여했으며, 궁극적으로 인간과 인공지능간의 관계성에 대한 성찰을 강화시켰다. 한편 인공지능 기반의 비상호작용형 예술창작물의 경우, 기계학습을 통해 이미지의 특징을 독창적인 방식으로 해석하고 새로운 이미지를 생성했다. 특히 일부 창작물의 경우에는 인공지능의 사유 가능성과 인공지능에 의해 생성된 예술창작물의 가치에 대한 관심을 증대시켰다.  결론적으로, 인간과 인공지능의 융합을 통해 탄생한 예술창작물은 인간과는 상이한 방식으로 데이터를 해석 및 표현할 수 있기 때문에, 창작자에게는 새로운 창작 소재나 창작 방식의 혁신을 통해 예술과 테크놀로지의 융합에 대한 새로운 지평을 열어 주었고, 관람객에게는 시각적 이미지에 대한 새로운 경험의 기회를 제공해 주었다.","With the advent of the 4th industrial revolution, artificial intelligence technology extends its applying to art creation area, which requires creativity. From the perspective of interdisciplinary research, this study aims to analyze new forms of art creation from the convergence of human creativity and artificial intelligence (hereafter A.I.), based on A.I. learning models and participation forms of viewer through the case studies and literature review. In addition, it contributes to shed light on the meanings of art creations using A.I. in terms of convergence research.  The interactive artworks based on A.I. discussed in this study have given new meaning to the role of spectators in art creation by turning viewers into participant as well as co-creator. Also, it ultimately let people reflect upon the relationship between human and A.I. On the other hand, in the case of non-interactive creative artworks based on A.I., machine learning was used to interpret image’s features to its own unique way and create into new images. Especially in the case of some creations, the creations augmented the interest in the value of artistic creations made by A.I..  In conclusion, because artistic creations created through the convergence of human beings and A.I. can interpret and express data in a way that differ from human beings, it opens up new horizons of the convergence of art and technology for creators to innovate through new creative materials and creative methods and gives visitors a new opportunity to experience visual images."
Combining Locality Preserving Projection with Global Information for Efficient Recognition,2018,"['PCA', 'LDA', 'LPP', 'GA', 'Feature space', 'UCI machine learning repository']",,"This paper proposes a new feature extraction scheme, combining global and local features. The proposed method uses principal component analysis (PCA) and linear discriminant analysis (LDA) for global property and locality preserving projections (LPP) for local property of the pattern. PCA and LDA are known for extracting the most descriptive ones after projection while LPP is known for preserving the neighborhood structure of the data set. The proposed combing method integrates global and local descriptive information and finds an efficient set of alternatives beyond PCA, LDA and LPP in the parametric space. Further, In order to find optimal parameters, the genetic algorithm (GA) is employed. Experiments are performed with four data sets selected in UCI machine learning repository to show the performance of the proposed algorithm."
Combining Locality Preserving Projection with Global Information for Efficient Recognition,2018,"['PCA', 'LDA', 'LPP', 'GA', 'Feature space', 'UCI machine learning repository']",,"This paper proposes a new feature extraction scheme, combining global and local features. The proposed method uses principal component analysis (PCA) and linear discriminant analysis (LDA) for global property and locality preserving projections (LPP) for local property of the pattern. PCA and LDA are known for extracting the most descriptive ones after projection while LPP is known for preserving the neighborhood structure of the data set. The proposed combing method integrates global and local descriptive information and finds an efficient set of alternatives beyond PCA, LDA and LPP in the parametric space. Further, In order to find optimal parameters, the genetic algorithm (GA) is employed. Experiments are performed with four data sets selected in UCI machine learning repository to show the performance of the proposed algorithm."
교통정보 추론을 위한 비정형데이터 분석과 다중패턴저장 기법,2018,"['Unstructured Data', 'LSA', 'ITS', 'Multi-Pattern Storage', 'Machine Learning', 'Tensorflow']",,"To understand the meaning of data is a common goal of research on unstructured data. Among these unstructured data, there are difficulties in analyzing the meaning of unstructured data related to corpus and sentences. In the existing researches, the researchers used LSA to select sentences with the most similar meaning to specific words of the sentences. However, it is problematic to examine many sentences continuously. In order to solve unstructured data classification problem, several search sites are available to classify the frequency of words and to serve to users. In this paper, we propose a method of classifying documents by using the frequency of similar words, and the frequency of non-relevant words to be applied as weights, and storing them in terms of a multi-pattern storage. We use Tensorflow's Softmax to the nearby sentences for machine learning, and utilize it for unstructured data analysis and the inference of traffic information."
다층신경망의 다양한 연결구조 제안 및 분석,2018,"['multilayer neural network', 'vanishing gradient', 'connection structure', 'machine learning']","신경망은 생물학적 뇌 구조와 동작을 모사한 계산모델이다. 가장 흔하게 사용하는 신경망은 여러 개의 레이어 즉, 층으로 구성된 다층 전진전파 신경망이고 학습은 오류역전파 알고리즘을 사용한다. 기존 다층신경망의 경우 레이어가 깊어질수록 가중치 수정량의 변화에 의해 학습성능이 나빠진다. 본 논문에서는 입력신호가 신경망 전체에 고르게 전달될 수 있도록 학습이 가능하고, 인접하지 않은 레이어의 뉴런들끼리 연결이 허용되는 신경망 연결구조를 제안하고 분석한다. 분석결과, 다층신경망에 추가된 연결구조는 레이어 깊이에 따른 다층신경망의 학습속도와 무관하였다. 또한 레이어가 깊어질수록 다층신경망에 입력레이어로부터 추가 연결한 연결구조가 우수한 학습성능이 보임을 확인하였다.","Neural networks are computational models that simulate biological brain structures and behaviors. The most commonly used neural network is a multilayer forward propagation neural network composed of several layers, ie layers, and learning uses error propagation algorithms. In the case of existing multilayer neural networks, the learning performance deteriorates due to the change in the weight modification amount as the layer becomes deeper. In this paper, we propose and analyze a neural network connection structure in which input signals can be transmitted uniformly throughout the neural network, and Neurons of non-adjacent layers are allowed to connect to each other. As a result of the analysis, the connection structure added to the multilayer neural network was not related to the learning speed of the multilayer neural network according to the layer depth. In addition, it is confirmed that the connection structure from the input layer to the multilayer neural network shows better learning performance as the layer becomes deeper."
빅데이터 분석방법을 활용한 제조업 혁신성과예측 방법에 대한 연구,2018,"['혁신예측', '빅 데이터', '한국기업혁신조사', '딥 러닝', '머신러닝', 'Innovation Performance', 'Big Data', 'Korea Innovatino Survey', 'Deep Learning', 'Machine Learning']","기술혁신에는 본질적인 어려움이 따르는데, 이는 상당부분 기술이 지닌 불확실성에 기인한다. 따라서 혁신과정에서 불확실성에 따른 위험을 감소시키기 위한 예측 방법론은 정량적 분야와 정성적 분야 모두에서 제시되어 왔다. 한편 최근 빅 데이터와 인공지능에 큰 관심이 이어지며 특히 알파고의 알고리즘 중 하나인 딥 러닝이 뛰어난 성능을 보이고 있다. 이에 본 연구는 혁신성과 예측에 있어 딥 러닝을 이용한 방법론을 접목하여 연구를 진행하였다. 모델 구축 및 학습에 있어 KIS 2016 데이터를 이용하였으며, 투입 요인으로는 정보 원천의 사용도와 혁신 목적을 사용하였고 산출 요인으로는 혁신 성과 지표를 구성하여 사용하였다. 분석 결과 선행 연구들에 비해 예측의 정확도가 향상되었음을 확인할 수 있었다. 또한 학습이 진행됨에 따라 예측의 자유도 역시 향상됨을 확인하였다.","Technological innovation has inherent difficulties, largely due to the uncertainties of technology. Thus, the forecasting methodology to reduce the risk of uncertainty in the innovation process has been presented both in quantitative and qualitative fields. On the other hand, big data and artificial intelligence have attracted great interest recently, and deep learning, which is one of the algorithms of AlphaGo, is showing excellent performance. In this study, deep learning methodology was applied to the prediction of innovation performance. To make the prediction model, we used KIS 2016 data. The input factors were importance of information source and innovation objectives and the output factor was innovation performance index, which was calculated for this study. As a result of the analysis, it can be confirmed that the accuracy of prediction is improved compared with the previous studies. As learning progressed, the degree of freedom of prediction also improved."
Arousal and Valence Classification Model Based on Long Short-Term Memory and DEAP Data for Mental Healthcare Management,2018,"['Arousal and Valence Analysis', 'Supervised Machine Learning', 'Classification', 'Machine Learning', 'DEAP Dataset']",,"Objectives: Both the valence and arousal components of affect are important considerations when managing mental healthcare because they are associated with affective and physiological responses. Research on arousal and valence analysis, which uses images, texts, and physiological signals that employ deep learning, is actively underway; research investigating how to improve the recognition rate is needed. The goal of this research was to design a deep learning framework and model to classify arousal and valence, indicating positive and negative degrees of emotion as high or low. Methods: The proposed arousal and valence classification model to analyze the affective state was tested using data from 40 channels provided by a dataset for emotion analysis using electrocardiography (EEG), physiological, and video signals (the DEAP dataset). Experiments were based on 10 selected featured central and peripheral nervous system data points, using long short-term memory (LSTM) as a deep learning method. Results: The arousal and valence were classified and visualized on a two-dimensional coordinate plane. Profiles were designed depending on the number of hidden layers, nodes, and hyperparameters according to the error rate. The experimental results show an arousal and valence classification model accuracy of 74.65 and 78%, respectively.The proposed model performed better than previous other models. Conclusions: The proposed model appears to be effective in analyzing arousal and valence; specifically, it is expected that affective analysis using physiological signals based on LSTM will be possible without manual feature extraction. In a future study, the classification model will be adopted in mental healthcare management systems."
Evaluation and Functionality Stems Extraction for App Categorization on Apple iTunes Store by Using Mixed Methods : Data Mining for Categorization Improvement,2018,"['Mobile Application', 'App Categorization', 'Inter-Rater Reliability', 'Functionality Stem', 'Tf-Idf', 'Machine Learning', 'Lemmatization', 'Natural Language Processing']",,"About 3.9 million apps and 24 primary categories can be approved on Apple iTunes Store. Making accurate categorization can potentially receive many benefits for developers, app stores, and users, such as improving discoverability and receiving long-term revenue. However, current categorization problems may cause usage inefficiency and confusion, especially for cross-attribution, etc. This study focused on evaluating the reliability of app categorization on Apple iTunes Store by using several rounds of inter-rater reliability statistics, locating categorization problems based on Machine Learning, and making more accurate suggestions about representative functionality stems for each primary category. A mixed methods research was performed and total 4905 popular apps were observed. The original categorization was proved to be substantial reliable but need further improvement. The representative functionality stems for each category were identified. This paper may provide some fusion research experience and methodological suggestions in categorization research field and improve app store’s categorization in discoverability."
Optimal EEG Locations for EEG Feature Extraction with Application to User's Intension using a Robust Neuro-Fuzzy System in BCI,2018,"['BCI (Brain Computer Interface)', 'EEG (Electroencephalogram)', 'Classification', 'Neuro-Fuzzy System', 'Robust Electrode Location']",,"Electroencephalogram (EEG) recording provides a new way to support human-machine communication. It gives us an opportunity to analyze the neuro-dynamics of human cognition. Machine learning is a powerful for the EEG classification. In addition, machine learning can compensate for high variability of EEG when analyzing data in real time. However, the optimal EEG electrode location must be prioritized in order to extract the most relevant features from brain wave data. In this paper, we propose an intelligent system model for the extraction of EEG data by training the optimal electrode location of EEG in a specific problem. The proposed system is basically a fuzzy system and uses a neural network structurally. The fuzzy clustering method is used to determine the optimal number of fuzzy rules using the features extracted from the EEG data. The parameters and weight values found in the process of determining the number of rules determined here must be tuned for optimization in the learning process. Genetic algorithms are used to obtain optimized parameters. We present useful results by using optimal rule numbers and non - symmetric membership function using EEG data for four movements with the right arm through various experiments."
Multi-Radial Basis Function SVM Classifier: Design and Analysis,2018,"['Multi-RBF SVM', 'Composite kernel', 'Dual RBF structure', 'Clustering method', 'Particle Swam optimization']",,"In this study, Multi-Radial Basis Function Support Vector Machine (Multi-RBF SVM) classifier is introduced based on a composite kernel function. In the proposed multi-RBF support vector machine classifier, the input space is divided into several local subsets considered for extremely nonlinear classification tasks. Each local subset is expressed as nonlinear classification subspace and mapped into feature space by using kernel function. The composite kernel function employs the dual RBF structure. By capturing the nonlinear distribution knowledge of local subsets, the training data is mapped into higher feature space, then Multi-SVM classifier is realized by using the composite kernel function through optimization procedure similar to conventional SVM classifier. The original training data set is partitioned by using some unsupervised learning methods such as clustering methods. In this study, three types of clustering method are considered such as Affinity propagation (AP), Hard C-Mean (HCM) and Iterative Self-Organizing Data Analysis Technique Algorithm (ISODATA). Experimental results on benchmark machine learning datasets show that the proposed method improves the classification performance efficiently."
합성곱 신경망을 사용한 화물차의 차종분류,2018,"['Vehicle Classification', 'Truck Cargo Box', 'Image Classification', 'Convolutional Neural Network', 'Machine Learning', '차종분류', '화물차 적재함', '영상분류', '합성곱 신경망', '기계학습']","본 논문에서는 화물차 차종을 분류하기 위해서 특징추출단계 없이 입력영상으로부터 차종분류결과를 얻을 수 있는 합성곱 신경망을 사용한 분류방법을 제안한다. 차량의 위에서 촬영된 영상을 입력으로 사용하고 입력영상에 적합한 합성곱 신경망의 구조를 설계한다. 차종과 화물칸의 형태에 따라 차종을 자동 분류하기 위한 학습데이터를 생성하고 지도학습의 형태로 학습시키기 위해 분류된 영상과 올바른 출력결과를 제시하여 신경망의 가중치를 학습시킨다. 실제 영상을 입력하여 합성곱 신경망의 출력을 계산하였고 실제 차종과의 비교를 통해 분류 성능을 평가 하였다. 실험결과 화물의 차종과 적재함의 형태에 따라 90%이상의 정확도로 영상을 분류할 수 있었고, 적재불량 검사의 사전 분류에 활용될 수 있다.","This paper proposes a classification method using the Convolutional Neural Network(CNN) which can obtain the type of trucks from the input image without the feature extraction step. To automatically classify vehicle images according to the type of truck cargo box, the top view images of the vehicle are used as input image and we design the structure of the CNN suitable for the input images. Learning images and correct output results is generated and the weights of neural network are obtained through the learning process. The actual image is input to the CNN and the output of the CNN is calculated. The classification performance is evaluated through comparison CNN output with actual vehicle types. Experimental results show that vehicle images could be classified with more than 90 percent accuracy according to the type of cargo box and this method can be used for pre-classification for inspecting loading defect."
Development of an Efficient Cascade Pathological-Brain Detection System using a Median Filter and Quadratic Discriminant Analysis,2018,"['Wavelet transform', 'Principal component analysis', 'Stratified cross-validation', 'Quadratic discriminant analysis']",,"This research article proposes smart utilization of a machine learning technique to discriminate between normal and pathological brain images. The method is based on the following computational technique: a median filter is utilized for pre-processing input images; discrete wavelet transform (DWT) is utilized for feature extraction; principal component analysis (PCA) minimizes the dimensionality of the wavelet coefficients; and quadratic discriminate analysis (QDA) classifies the reduced features as normal or pathological. Experiments were carried out on 90 images (five normal and 85 pathological) from a Harvard Medical School dataset. The proposed system yielded excellent classification accuracy of 98.90% with 10× 5-fold stratified crossvalidation (SCV). Moreover, the proposed technique outperforms seven state-of-the-art algorithms in terms of accuracy. Furthermore, our method signifies its effectiveness when compared with other machine learning approaches."
Enhanced Network Intrusion Detection using Deep Convolutional Neural Networks,2018,"['Network Intrusion Detection', 'Deep Convolutional Neural Networks', 'Deep learning', 'CNN', 'IDS', 'Information Security']",,"Network Intrusion detection is a rapidly growing field of information security due to its importance for modern IT infrastructure. Many supervised and unsupervised learning techniques have been devised by researchers from discipline of machine learning and data mining to achieve reliable detection of anomalies. In this paper, a deep convolutional neural network (DCNN) based intrusion detection system (IDS) is proposed, implemented and analyzed. Deep CNN core of proposed IDS is fine-tuned using Randomized search over configuration space. Proposed system is trained and tested on NSLKDD training and testing datasets using GPU. Performance comparisons of proposed DCNN model are provided with other classifiers using well-known metrics including Receiver operating characteristics (RoC) curve, Area under RoC curve (AuC), accuracy, precision-recall curve and mean average precision (mAP). The experimental results of proposed DCNN based IDS shows promising results for real world application in anomaly detection systems."
A Study on Performance of ML Algorithms and Feature Extraction to detect Malware,2018,"['Malware', 'PE File Format', 'Opcode', 'Windows API Calls', 'Machine Learning', 'Bernoulli Naive Bayes', 'Decision Tree', 'Support Vector Machine', 'K-nearest neighbor']",,"In this paper, we studied the way that classify whether unknown PE file is malware or not. In the classification problem of malware detection domain, feature extraction and classifier are important. For that purpose, we studied what the feature is good for classifier and the which classifier is good for the selected feature. So, we try to find the good combination of feature and classifier for detecting malware. For it, we did experiments at two step. In step one, we compared the accuracy of features using Opcode only, Win. API only, the one with both. We founded that the feature, Opcode and Win. API, is better than others. In step two, we compared AUC value of classifiers, Bernoulli Naïve Bayes, K-nearest neighbor, Support Vector Machine and Decision Tree. We founded that Decision Tree is better than others."
지능형 IoT 미러 시스템을 활용한 인터랙티브 콘텐츠 서비스 구현,2018,"['Electroencephalography', 'Facial expression', 'Interactive content', 'Internet-of-Things', 'Machine learning.']",,"In this paper, we develop interactive content services for preventing depression of users through an intelligent Internet of Things (IoT) mirror system. For interactive content services, an IoT mirror device measures attention and meditation data from an EEG headset device and also measures facial expression data such as sad, angery, disgust, neutral,  happy, and surprise classified by a multi-layer perceptron algorithm through an webcam. Then, it sends the measured data to an oneM2M-compliant IoT server. Based on the collected data in the IoT server, a machine learning model is built to classify three levels of depression (RED, YELLOW, and GREEN) given by a proposed merge labeling method. It was verified that the k-nearest neighbor (k-NN) model could achieve about 93% of accuracy by experimental results. In addition, according to the classified level, a social network service agent sent a corresponding alert message to the family, friends and social workers. Thus, we were able to provide an interactive content service between users and caregivers."
유전 알고리즘 기반의 비정상 행위 탐지를 위한 특징선택,2018,"['침입탐지', '기계학습', '유전알고리즘', '특징선택', '주성분 분석', 'Intrusion detection', 'Machine Learning', 'Genetic Algorithm', 'Feature Selection', 'PCA']","데이터 전처리 기법 중 하나인 특징 선택은 대규모 데이터셋을 다루는 다양한 응용분야에서 주요 연구 분야 중 하나로 각광받고 있다. 특징 선택은 패턴 인식, 기계학습 및 데이터 마이닝에서 사용됐고, 최근에는 텍스트 분류, 이미지 검색, 침입 탐지 및 게놈 분석과 같은 다양한 분야에 널리 적용되고 있다. 제안 방법은 메타 휴리스틱 알고리즘 중의 하나인 유전 알고리즘을 기반으로 한다. 특징 부분 집합을 찾는 방법은 크게 필터(filter) 방법과 래퍼(wrapper) 방법이 있는데, 본 연구에서는 최적의 특징 부분 집합을 찾기 위해 실제 분류기를 사용한 평가를 하는 래퍼 방법을 사용한다. 실험에 사용한 훈련 데이터셋은 클래스 불균형이 심하여 희소클래스에 대한 분류 성능을 높이기 어렵다. SMOTE 기법을 적용한 훈련 데이터셋을 사용하여 특징 선택을 하고 다양한 기계학습 알고리즘을 사용하여 선택한 특징들의 성능을 평가한다.","Feature selection, one of data preprocessing techniques, is one of major research areas in many applications dealing with large dataset. It has been used in pattern recognition, machine learning and data mining, and is now widely applied in a variety of fields such as text classification, image retrieval, intrusion detection and genome analysis. The proposed method is based on a genetic algorithm which is one of meta-heuristic algorithms. There are two methods of finding feature subsets: a filter method and a wrapper method. In this study, we use a wrapper method, which evaluates feature subsets using a real classifier, to find an optimal feature subset. The training dataset used in the experiment has a severe class imbalance and it is difficult to improve classification performance for rare classes. After preprocessing the training dataset with SMOTE, we select features and evaluate them with various machine learning algorithms."
인공신경망 기반 손동작 인식기의 설계 및 구현,2018,"['Artificial neural network', 'Hand gesture recognition', 'IMU sensor', 'Machine learning', 'Restricted coulomb energy.']","본 논문에서는 RCE (restricted coulomb energy) 신경망을 이용한 손동작 인식기를 제안하고, 이의 실시간 학습 및 인식을 위한 하드웨어 구현 결과를 제시한다. RCE 신경망은 네트워크 구조가 학습에 따라 유동적이며, 학습 알고리즘이 여타 신경망에 비해 비교적 간단하기 때문에 실시간 학습 및 인식이 가능하므로 손동작 인식기에 적합한 장점을 갖는다. FPGA 기반 검증 플랫폼을 사용하여 3D 숫자 데이터 셋을 생성하였으며, 설계된 손동작 인식기는 3D 숫자 데이터 셋에 대해 98.8%의 인식 정확도를 나타냈다. 제안된 손동작 인식기는 Intel-Altera cyclone Ⅳ FPGA 기반 구현 결과, 26,702개의 logic elements로 구현 가능함을 확인하였으며, 70MHz의 동작 주파수로 실시간 학습 및 인식 결과에 대한 검증을 수행하였다.","In this paper, we propose a hand gesture recognizer using restricted coulomb energy (RCE) neural network, and present hardware implementation results for real-time learning and recognition. Since RCE-NN has a flexible network architecture and real-time learning process with low complexity, it is suitable for hand recognition applications. The 3D number dataset was created using an FPGA-based test platform and the designed hand gesture recognizer showed 98.8% recognition accuracy for the 3D number dataset. The proposed hand gesture recognizer is implemented in Intel-Altera cyclone IV FPGA and confirmed that it can be implemented with 26,702 logic elements and 258Kbit memory. In addition, real-time learning and recognition verification were performed at an operating frequency of 70MHz."
Developing an Intrusion Detection Framework for High-Speed Big Data Networks: A Comprehensive Approach,2018,"['Network intrusion detection systems', 'anomaly detection', 'bulk synchronous parallel', 'BSP', 'big data', 'machine learning', 'Darpa', 'KDD Cup 99', 'ISCX-UNB dataset']",,"In network intrusion detection research, two characteristics are generally considered vital to building efficient intrusion detection systems (IDSs): an optimal feature selection technique and robust classification schemes. However, the emergence of sophisticated network attacks and the advent of big data concepts in intrusion detection domains require two more significant aspects to be addressed: employing an appropriate big data computing framework and utilizing a contemporary dataset to deal with ongoing advancements. As such, we present a comprehensive approach to building an efficient IDS with the aim of strengthening academic anomaly detection research in real-world operational environments. The proposed system has the following four characteristics: (i) it performs optimal feature selection using information gain and branch-and-bound algorithms; (ii) it employs machine learning techniques for classification, namely, Logistic Regression, Naïve Bayes, and Random Forest; (iii) it introduces bulk synchronous parallel processing to handle the computational requirements of large-scale networks; and (iv) it utilizes a real-time contemporary dataset generated by the Information Security Centre of Excellence at the University of Brunswick (ISCX-UNB) to validate its efficacy. Experimental analysis shows the effectiveness of the proposed framework, which is able to achieve high accuracy, low computational cost, and reduced false alarms."
Enhancing the Impact of Color through Artificial Intelligence for Visual Narration,2018,"['Artificial Intelligence', 'Psychology of Color', 'Goethe', 'Barthesian Code Network', 'Classification', 'Machine Learning']",,"In the seventeenth century, Isaac Newton claimed that white light is heterogeneous and consists of multiple component colors. Newton also stated that color is a mechanical and measurable attribute. A century later, Johann Goethe conducted a series of experiments for analyzing the nature of color. In contrast to Newton’s theory, Goethe postulated that the color theory should address the subjective and psychological impacts of color on human beings. Goethe’s principle has significantly influenced the contemporary philosophical and artistic approaches to the color theory. In this study, based on Goethe’s color theory, the authors developed separate color categories for the film “La La Land” and incorporated machine learning algorithms. To achieve the said objective, structural analysis was conducted by employing the “five code network or topos” described in Roland Barthes’s book titled S/Z that was published in the year 1970 . The Barthesian code network was thereby applied to create input training data for machine learning algorithms. The proposed study thus comprises foundational and novel research that can aid in developing an artificial intelligence framework for classifying the psychological responses of viewers to colors."
Friend-safe evasion attack: An adversarial example that is correctly recognized by a friendly classifier,2018,"['Deep Neural Network', 'Evasion Attack', 'Adversarial Example', 'Covert Channel', 'Machine Learning']",,"<P><B>Abstract</B></P>  <P>Deep neural networks (DNNs) have been applied in several useful services, such as image recognition, intrusion detection, and pattern analysis of machine learning tasks. Recently proposed adversarial examples-slightly modified data that lead to incorrect classification-are a severe threat to the security of DNNs. In some situations, however, an adversarial example might be useful, such as when deceiving an enemy classifier on the battlefield. In such a scenario, it is necessary that a friendly classifier not be deceived. In this paper, we propose a friend-safe adversarial example, meaning that the friendly machine can classify the adversarial example correctly. To produce such examples, a transformation is carried out to minimize the probability of incorrect classification by the friend and that of correct classification by the adversary. We suggest two configurations for the scheme: targeted and untargeted class attacks. We performed experiments with this scheme using the MNIST and CIFAR10 datasets. Our proposed method shows a 100% attack success rate and 100% friend accuracy with only a small distortion: 2.18 and 1.54 for the two respective MNIST configurations, and 49.02 and 27.61 for the two respective CIFAR10 configurations. Additionally, we propose a new covert channel scheme and a mixed battlefield application for consideration in further applications.</P>"
유전체 자료분석을 위한 생존분석방법에 관한 고찰,2018,"['기계학습', '벌점함수', '비모수적인 방법', '생존시간', '중도절단', '통계예측모형', 'Censoring', 'machine learning', 'nonparametric methods', 'penalty function', 'statistical predictive model', 'survival time']","관심의 대상이 되는 사건이 발생할 때까지 걸리는 생존시간을 다루는 생존분석의 가장 큰 특성은 생존시간이 완전하게 관측되지 않고 중도 절단 된다는 점이다. 이러한 중도절단자료의 특성을 고려하여 추정, 검정 및 모형적합에 대하여 고전적인 생존분석 방법들이 많이 개발되어져 왔으나, 마이크로 어레이자료를 시작으로 대용량의 유전체 자료가 수집되면서 유전적 정보와 생존시간과의 연관성 연구가 진행되면서 표본의 수에 비하여 엄청나게 많은 수의 유전정보 변수들을 다루는 새로운 통계적인 방법들이 생존자료에 확장되었다. 결과적으로 기존의 임상자료로만 구축된 통계예측모형에 유전체 정보가 추가적으로 고려됨으로써 생존함수에 대한 예측력이 향상되었고, 개인의 유전정보에 따라 더 적합한 치료방법이나 치료약을 개발해야 한다는 개인맞춤의학의 필요성이 부각되기 시작되었다. 다양한 첨단 생물학 기술을 통하여 서로 다른 형태의 대용량의 유전체 자료를 통합하는 방법론에 대한 연구들이 이루어지면서 기계학습 방법이 생존분석에 접목되어 많은 연구방법들이 개발되고 있다. 본 연구에서는 기존의 임상자료를 기반으로 분석하는 전통적인 생존분석 방법들을 소개하고, 고차원의 유전체 자료를 분석하기 위한 생존분석 방법들과 통합적인 유전체 자료분석을 위하여 생존분석에 접목된 기계학습방법들에 대하여 간략하게 살펴보고자 한다.","Survival analysis focuses on the statistical inference for the time to event of interest, which cannot be often completely observed due to censoring. Considering the characteristics of these censored data, traditional survival analysis methods have been developed for estimation, testing, and model development to predict survival time for patients based on clinical data. However, large-scale data from high-throughput genomic technologies, especially microarrays, have been collected, which poses the challenging statistical issues in combining those with the survival time. Many statistical methods have been developed by additionally considering the high-dimensional genomic information in the statistical prediction model constructed only by the existing clinical data. Recently, there have been many studies on the methodology of integrating different types of genomic data through various advanced biologic techniques, which results in making an early prediction for the disease and developing personalized medicine. As well, there has been considerable interest in applying machine learning techniques to analyse these complex and huge amount of genomic data associated with the censored data. In this paper, we review the basic concepts in survival analysis, traditional statistical methods based on clinical data, more appropriate statistical methods dealing with genomic data, and machine learning methods extended to the survival analysis."
Optimal EEG Locations for EEG Feature Extraction with Application to User’s Intension using a Robust Neuro-Fuzzy System in BCI,2018,"['BCI (Brain Computer Interface)', 'EEG (Electroencephalogram)', 'Classification', 'Neuro-Fuzzy System', 'Robust Electrode Location.']",,"Electroencephalogram (EEG) recording provides a new way to support human-machine communication. It gives us an opportunity to analyze the neuro-dynamics of human cognition. Machine learning is a powerful for the EEG classification. In addition, machine learning can compensate for high variability of EEG when analyzing data in real time. However,the optimal EEG electrode location must be prioritized in order to extract the most relevant features from brain wave data. In this paper, we propose an intelligent system model for the extraction of EEG data by training the optimal electrode location of EEG in a specific problem. The proposed system is basically a fuzzy system and uses a neural network structurally. The fuzzy clustering method is used to determine the optimal number of fuzzy rules using the features extracted from the EEG data. The parameters and weight values found in the process of determining the number of rules determined here must be tuned for optimization in the learning process. Genetic algorithms are used to obtain optimized parameters. We present useful results by using optimal rule numbers and non - symmetric membership function using EEG data for four movements with the right arm through various experiments."
데이터 기반 항공기 지상 이동 시간 예측 알고리즘 개발,2018,"['Air Traffic Management', 'Departure Manager', 'Variable Taxi Time', 'Machine Learning', 'Node-Link Model', '항공 교통 관리', '출발 관리 시스템', '지상 이동 시간', '기계학습법', '노드링크 모델']",,"Departure Manager (DMAN) is a tool to optimize the departure sequence and to suggestappropriate take-off time and off-block time of each departure aircraft to the air trafficcontrollers. To that end, Variable Taxi Time (VTT), which is time duration of the aircraftfrom the stand to the runway, should be estimated. In this paper, a study for developmentof VTT prediction algorithm based on machine learning techniques is presented. The factorsaffecting aircraft taxi speeds were identified through the analysis of historical traffic data onthe airport surface. The prediction model suggested in this study consists of severalsub-models that reflect different types of surface maneuvers based on the analysis result.The prediction performance of the proposed method was evaluated using the actualoperational data."
실시간 기상 및 대기 데이터를 활용한도시안전서비스 시스템 설계 및 구현,2018,"['Urban Safety Service Model', 'Big Data Analysis', 'Regional Safety Index', 'Machine Learning Algorithm']",,"As natural disasters are increasing due to the unusual weather and the modern society is getting complicated, the rapid change of the urban environment has increased human disasters. Thus, citizens are becoming more anxious about social safety. The importance of preparation for safety has been suggested by providing the disaster safety services such as regional safety index, life safety map, and disaster safety portal application. In this paper, we propose an application framework to predict the urban safety index based on user's location with realtime weather/atmosphere data after creating a predication model based on the machine learning using number of occurrence cases and weather/atmosphere history data. Also, we implement an application to provide traffic safety index with executing preprocessing occurrence cases of traffic and weather/atmosphere data. The existing regional safety index, which is displayed on the Si-gun-gu area, has been mainly utilized to establish safety plans for districts vulnerable to national policies on safety. The proposed system has an advantage to service useful information to citizens by providing urban safety index based on location of interests and current position with realtime related data."
Multi-Radial Basis Function SVM Classifier,2018,"['Multi-RBF SVM', 'Composite kernel', 'Dual RBF structure', 'Clustering method', 'Particle Swam optimization']",,"In this study, Multi-Radial Basis Function Support Vector Machine (Multi-RBF SVM) classifier is introduced based on a composite kernel function. In the proposed multi- RBF support vector machine classifier, the input space is divided into several local subsets considered for extremely nonlinear classification tasks. Each local subset is expressed as nonlinear classification subspace and mapped into feature space by using kernel function. The composite kernel function employs the dual RBF structure. By capturing the nonlinear distribution knowledge of local subsets, the training data is mapped into higher feature space, then Multi-SVM classifier is realized by using the composite kernel function through optimization procedure similar to conventional SVM classifier. The original training data set is partitioned by using some unsupervised learning methods such as clustering methods. In this study, three types of clustering method are considered such as Affinity propagation (AP), Hard CMean (HCM) and Iterative Self-Organizing Data Analysis Technique Algorithm (ISODATA). Experimental results on benchmark machine learning datasets show that the proposed method improves the classification performance efficiently."
Classification of factoid questions intent using grammatical features,2018,"['Information retrieval', 'Question classification', 'Factoid questions', 'Grammatical features', 'Machine learning']",,"In question-answering systems, question classification is a fundamental task. Identifying the accurate question type enhances the retrieval of more accurate answers. Factoid questions are the most challenging type of question to classify in which many approaches have been proposed with the objective of enhancing the classification of this type of question. In this paper, a grammar-based framework is used. The framework makes use of three main features which are, grammatical features, domain specific features and patterns. Using machine learning algorithms for the classification process, experimental results show that our approach has a good level of accuracy."
Intelligent Object Detection and Extraction Method for Surveillance Applications in Smart City,2018,"['Object extraction', 'smart city', 'color space', 'urban surveillance', 'image enhancement', 'median filter']",,"Detecting and segmenting moving objects are advanced capacity required by greater part of machine learning, artificial intelligence and computer vision. Presently, there are numerous object extraction methods have been looked into many years and equipment devices improved for extracting moving objects without shadow and ghost artifacts. However, an assortment of issues exists, for example, shadows pixels also segmented as foreground object regions. In this paper, we suggest a robust and simple automatic object detection framework for indoor environment based on image enhancement and background subtraction. Extracting dynamic objects in video sequences are a challenging task in smart vision applications and machine learning research area. Our proposed method could help to detect human shape rapidly and accurately in urban surveillance systems without any noise. The method is implemented and tested widely used datasets and our system proved to achieve good performance solving object segmentation problems in indoor and outdoor scenes for delivering object identification and tracking tasks."
전통 문화 데이터를 이용한 메타 러닝 기반 전역 관계 추출,2018,"['관계 추출', '메모리 증강 신경망', '메타 러닝', '텍스트 요약', '자연어처리', '기계 학습', 'Relation Extraction', 'Augmented Memory Neural Networks', 'Meta Learning', 'Text  summarization', 'Natural language Processing', 'Machine Learning']","최근 존재하는 대부분의 관계 추출 모델은 언급 수준의 관계 추출 모델이다. 이들은 성능은 높지만, 장문의 텍스트에 존재하는 다수의 문장을 처리할 때, 문서 내에 주요 개체 및 여러 문장에 걸쳐서 표현되는 전역적 개체 관계를 파악하지 못한다. 그리고 이러한 높은 수준의 관계를 정의하지 못하는 것은 데이터의 올바른 정형화를 막는 중대한 문제이다. 이 논문 에서는 이러한 문제를 해결하고 전역적 관계를 추출하기 위하여 외부 메모리 신경망 모델을 이용하는 새로운 방식의 전역 관계 추출 모델을 제안한다. 제안하는 모델은 1차적으로는 단편적인 관계 추출을 실행한 뒤, 외부메모리 신경망을 이용하여 단편적인 관계들을 분석 및 종합하여 텍스트 전체로부터 전역적 관계들을 추출한다. 또한 제안된 모델은 외부 메모리를 통 하여 전역적 관계 추출 외에도 주어와 목적어 생략이 잦은 한국어 관계 추출에도 뛰어난 성능을 보인다.","Recent approaches to Relation Extraction methods mostly tend to be limited to mention level relation extractions. These types of methods, while featuring high performances, can only extract relations limited to a single sentence or so. The inability to extract these kinds of data is a terrible amount of information loss. To tackle this problem this paper presents an Augmented External Memory Neural Network model to enable Global Relation Extraction. the proposed model’s Global relation extraction is done by first gathering and analyzing the mention level relation extraction by the Augmented External Memory. Additionally the proposed model shows high level of performances in korean due to the fact it can take the often omitted subjects and objectives into consideration."
MMORPG 사용자 유형 분류를 통한 이탈 예측 모델 생성 및 평가,2018,"['사용자 이탈 예측', '사용자 유형 기반 분류', '기계학습 알고리즘', '이탈 예측 모델 평가', 'churn prediction', 'user type classification', 'machine learning algorithm', 'evaluating churn prediction model']","대규모 다중 사용자 온라인 롤플레잉 게임(MMORPG)은 세계적으로 많은 사용자들이 즐기는 게임의 장르로 사용자들이 즐길 수 있는 다양한 컨텐츠를 제공해준다. 하지만 다양한 컨텐츠를 제공함에도 불구하고 일부 사용자들은 게임에서 이탈한다. 지속적으로 게임을 즐기는 사용자는 게임회사의 수익과 밀접한 관계가 있기 때문에, 사용자 이탈 예측은 매우 중요한 문제이다. 본 연구에서는 게임 사용자 유형을 기반으로 이탈을 예측하는 방법을 제안한다. 실제 MMORPG 데이터를 이용하여 ‘이탈자’를 정의하고, 서로 다른 특징을 보이는 사용자들을 군집화 알고리즘을 통해 5가지 유형으로 나누어 분류하였다. 실험 결과로 약 98.3%의 이탈자가 라이트 사용자형에 속하는 것을 확인하였다. 분류한 유형을 이탈 예측 모델 생성의 피처로 사용하고, 기계학습 알고리즘을 이용하여 이탈 예측 모델을 구축하였다. 이탈 예측 모델은 최대 85.7%의 accuracy와 72.3%의 F-measure의 성능을 보였다.","Massively Multiplayer Online Role Playing Games (MMORPG) have been the most enjoyed genre of games by users all over the world, because of the many enjoyable contents they provide. However, there still are some users leaving MMORPG, in spite of the various contents. Because the users, who are constantly engaged in a game, are directly connected to the profit of the game company, it is necessary to study churn prediction. In this study, we propose a churn prediction method based on the user types. Using actual MMORPG data, we define “Churn Users” and categorize users into 5 types by means of the clustering algorithm. The experiment shows that about 98.3% of the churn users are the “Light user type”. We then use user types as a feature and construct a churn prediction model with various machine learning algorithms. The churn prediction model shows a maximum accuracy of 85.7% and an F-measure of 72.3%."
4차 산업혁명 시대와 기독교 인간론: 인공지능을 이기는 공동체적 인간성,2018,"['4차 산업혁명', '인공지능', '공동체', '인간', '기계학습', '블랙박스', '클라우스 슈밥.', 'the Fourth Industrial Revolution', 'artificial intelligence', 'community', 'human', 'machine learning', 'black box', 'Klaus Schwab.']","4차 산업혁명 시대의 중심 역할을 할 인공지능이 지속적으로 발전하여 인간 이상의 지적 능력을 지닌 ‘강한 인공지능’ 혹은 ‘초인공지능’ 로봇을 등장시킬 것인가? 터미네이터(Terminator, 1984~2015), 아이 로봇(I, Robot, 2004), 트랜센던스(Transcendence, 2014)와 같은 공상과학 영화에서와 같은 일이 현실화될 수 있을 것인가? 이 글은 강한 인공지능 또는 초인공지능의 출현이 불가능할 수밖에 없음을 컴퓨터 공학적, 인문학적, 그리고 신학적으로 밝히려 하였다. 특히 기독교 인간론이 이러한 주장의 근거를 근원적으로 제시하여 주고 있음을 강조하려 하였다. 예를 들어, 인간은 공동체적 본성을 지녔기 때문에 인류 파멸에 이르게 할 정도의 기술 발전을 허락하지 않을 것이라는 것이 그것이다. 클라우스 슈밥이 4차 산업혁명의 부정적 영향을 우려하여 ‘협력’을 제안하고 ‘거버넌스’라는 기구를 만들자고 호소하였다는 점이 바로 이러한 인간의 ‘공동체적 본성’에 그가 의지하였음을 증명한다. 인공지능이 알파고, 자율주행 자동차, 왓슨(Watson) 기계 의료 시스템과 같은 ‘약한 인공지능’을 넘어 ‘특이점’(singularity)에 돌입하여 ‘강한 인공지능’이 되고 결국 신적인 존재에까지 이르는 기계가 탄생할 것이라는 주장은 난센스가 될 것이라는 것이다. 약한 인공지능은 이미 상용화 단계를 거치고 있지만 그 이상의 초지능 로봇이 등장하여 기계가 인간을 지배하는 일은 불가능할 것이다.","Will artificial intelligence, which plays a central role in the era of the 4th Industrial Revolution, continue to evolve and introduce ‘strong artificial intelligence’ or ‘super artificial intelligence’ robots with more intellectual ability than humans? Will things like science fiction movies like Terminator(1984~2015), I, Robot(2004) and Transcendence(2014) be realized? This paper intends to reveal that the emergence of strong artificial intelligence or artificial intelligence is not inevitable, in view of computer engineering, humanism, and theology. In particular, Christian anthropology sought to emphasize the fact that it provided the basis for such claims. For example, humans will not allow technological development to lead to human destruction because they have a communal nature. The fact that Klaus Schwab, who was concerned about the negative impacts of the Fourth Industrial Revolution, appealed himself to propose ‘cooperation’ and to form an institution called ‘governance’, which proves that he relies on this ‘human nature of communities.’ Th claim that artificial intelligence goes beyond ‘weak artificial intelligence’ such as Alpha-Go, autonomous vehicle, and Watson machine medical system to ‘singularity’ to become ‘strong artificial intelligence’, will be nonsense. Weak artificial intelligence has already been commercialized, but it will not be possible for a machine to dominate humans due to the appearance of super intelligent robots."
평균 대조괴리도 알고리즘 기반 분류용 제한볼츠만기계,2018,"['대조괴리도', '분류용 제한볼츠만기계', '역전파 알고리즘', '제한볼츠만기계', '평균 대조괴리도', 'Average contrastive divergence', 'backpropagation algorithm', 'contrastive divergence', 'discriminative restricted Boltzmann machine', 'restricted Boltzmann machine']",제한볼츠만기계는 입력벡터에 대한 확률분포를 학습할 수 있는 생성모형으로서 주로 다른 학습 알고리즘을 위해 특징변수들을 추출하거나 심층 신경망의 가중치들의 초기값을 얻기 위해 사용되어 왔다. 그러나 최근 제한볼츠만기계에 라벨층을 추가하여 분류를 위한 제한볼츠만기계가 고안되었다. 분류용 제한볼츠만기계의 학습 알고리즘으로 주로 대조괴리도 알고리즘이 사용되고 있다. 본 논문에서는 분류용 제한볼츠만기계를 학습하기 위해 새로운 평균 대조괴리도 알고리즘을 제안하고 분류성능을 향상시킬 수 있음을 보인다. 제안된 방법을 적용한 분류용 제한볼츠만기계는 벤치마킹 자료들을 이용한 수치적 연구를 통하여 기존의 대조괴리도 알고리즘을 이용한 분류용 제한볼츠만기계보다 더 좋은 성능을 보여주는 것을 확인할 수 있었다.,"Restricted Boltzmann machine (RBM) is a generative model that can learn probability distributions over input vectors. It has been mainly used to extract features for other learning algorithms or to obtain initial values of weights of deep neural networks. However, a discriminative RBM has been recently devised by adding a label layer to ordinary RBM. Contrastive divergence (CD) algorithm is mainly used for training discriminative RBM. In this paper, we propose an average CD algorithm for discriminative RBM and show that classification performance can be improved. The proposed method is evaluated through numerical studies based on real data sets available from UCI machine learning repository and MNIST database."
인공지능시대에도 종교는 가능한가? - 칸트와 블로흐의 종교철학적 관점에서 -,2018,"['Artificial Intelligence', 'Religious Philosophy', 'Kant', 'Bloch', 'Morabeck', 'Kurzweil', 'Harrari', 'Tegmark', 'Bostrom', 'Super Intelligence', 'Ultra Intelligent Machine', 'Singularity', 'Matrix', 'Technology Religion', 'Homo Deus', '칸트', '블로흐', '모라벡', '커즈와일', '하라리', '테그마크', '보스트롬', '초지능', '초지능기계', '특이점', '매트릭스', '기술종교', '호모데우스']","이 논문은 인공지능시대에도 종교는 가능한가, 오직 인간만이 종교신앙의 주체일 수 있는가, 인간의 마음을 탑재한 초지능기계들도 신앙의 주체일 수 있는가를 다룬다. 초지능기계들이 인간과 동일한 조건에서 신앙의 주체가 되려면, 인간의 고유한 특성인 감정, 의지, 자의식 등을 가질 수 있어야 한다. ‘특이점’ 이후의 초지능기계들은 종교신앙의 주체를 넘어서서, 신과 같은 존재로서 인간과 자연과 세계를 지배하게 될 것이다. 이는 모라벡, 커즈와일, 하라리의 공통된 견해이다. 칸트가 구상한 ‘순수이성의 이념’과 ‘실천이성의 요청’으로서 신 개념은 제시 베링이 앞서 말한 것처럼 ‘간극의 신’처럼 보일 수 있다. 종교적 신앙 주체는 항상 도덕적인 선을 행하려고 부단하게 노력해야 하지만, 그런 노력 자체만으로는 완전선(完全善)에 도달할 수 없기 때문에 영혼불멸성을 요청하였다. 그러나 특이점을 넘어서 출현한 초지능기계가 지능폭발로 신적 지위를 가질 수 있다면, 인공지능로봇은 칸트적인 의미에서 종교적 수행을 불필요하게 여길 것이다. 에른스트 블로흐의 경우에는 초지능기계가 신적 존재라고 하더라도, 그것이 악신인가 선신인가를 비판적으로 물어야 한다. 칸트의 매트릭스에서는 선신일 수 있는 초지능기계가 블로흐의 매트릭스에서는 악신으로 추락할 수도 있다. 따라서 초지능기계-신이 우리를 유일한 종교신앙의 완성으로 이끌어 가는지, 인류와 지구촌의 몰락으로 내몰아갈 것인지를 부단하게 비판적으로 성찰해야 한다.","This paper discusses, whether religion is possible even in the age of artificial intelligence, and whether humans alone are the subject of religious faith or ultra intelligent machines with human minds can be also subjects of faith. In order for ultra intelligent machines to be subjects of faith in the same conditions as humans, they must be able to have unique characteristics such as emotion, will, and self-consciousness. With the advent of ultra intelligent machines with the same level of cognitive and emotional abilities as human beings, the religious actions of artificial intelligence will be inevitable. The ultra intelligent machines after ‘singularity’ will go beyond the subject of religious belief and reign as God who can rule humans, nature and the world. This is also the common view of Morabeck, Kurzweil and Harari. Leonhart also reminds us that technological advances should make us used to the fact that we are now ‘gods’. But we fear we may face distopia despite the general affluence of the ‘Star Trec’ economy. For this reason, even if a man says he has learned the religious truth, one can’t help but wonder if it is true.Kant and Bloch are thinkers who critically reflected on our religious ideals and highest concept in different world-view premises. Kant’s concept of God as ‘idea of pure reason’ and ‘postulate of practical reason’, can seem like a ‘god of gap’ as Jesse Bering said earlier. Kant recognized the need for religious faith only on a strict basis of moral necessity. The subjects of religious faith should always strive to do the moral good, but such efforts themselves were not enough to reach perfection and so postulated immortality of the soul. But if an ultra intelligent machines that has emerged above a singularity is given a new status in an intellectual explosion, it can reach its morality by blocking evil tendencies and by the infinite evolution of super intelligence. So it will no longer need Kant’s ‘Postulate for continuous progress towards greater goodness’, ‘Postulate for divine grace’ and ‘Postulate for infinite expansion of the kingdom of God on earth.’ Artificial intelligence robots would not necessarily consider religious performance in the Kant’s meaning, and therefore religion will also have to be abolished.Ernst Bloch transforms Kant’s postulate to be Persian dualism. Therefore, in Bloch, even though the ultra intelligent machines is a divine being, one must critically ask whether it is a wicked or a good God. Artificial intelligence experts warn that ultra intellectual machine as Pandora’s gift will bring disaster to mankind. In the Kant’s Matrix, a ultra intelligent machines, which is the com- pletion of morality and God itself, may fall into a bad god in Bloch’s Matrix. Therefore, despite the myth of singularity, we still believe that ultra intelligent machines, whether as God leads us to the completion of one of our only religious beliefs, or as bad god to the collapse of mankind through complete denial of existence."
제주 감귤 과수원에서의 이슬지속시간 예측 모델 평가,2018,"['Leaf Wetness Duration', 'Mean Square Deviation', 'Number of Hours of Relative Humidity', 'Classification And Regression Tree', 'Penman-Monteith', 'Deep-learning Neural Network']",,"Models to predict Leaf Wetness Duration (LWD) were evaluated using the observed meteorological and dew data at the 11 citrus orchards in Jeju, South Korea from 2016 to 2017. The sensitivity and the prediction accuracy were evaluated with four models (i.e., Number of Hours of Relative Humidity (NHRH), Classification And Regression Tree/Stepwise Linear Discriminant (CART/SLD), Penman-Monteith (PM), Deep-learning Neural Network (DNN)). The sensitivity of models was evaluated with rainfall and seasonal changes. When the data in rainy days were excluded from the whole data set, the LWD models had smaller average error (Root Mean Square Error (RMSE) about 1.5hours). The seasonal error of the DNN model had the similar magnitude (RMSE about 3 hours) among all seasons excluding winter. The other models had the greatest error in summer (RMSE about 9.6 hours) and the lowest error in winter (RMSE about 3.3 hours). These models were also evaluated by the statistical error analysis method and the regression analysis method of mean squared deviation. The DNN model had the best performance by statistical error whereas the CART/SLD model had the worst prediction accuracy. The Mean Square Deviation (MSD) is a method of analyzing the linearity of a model with three components: squared bias (SB), nonunity slope (NU), and lack of correlation (LC). Better model performance was determined by lower SB and LC and higher NU. The results of MSD analysis indicated that the DNN model would provide the best performance and followed by the PM, the NHRH and the CART/SLD in order. This result suggested that the machine learning model would be useful to improve the accuracy of agricultural information using meteorological data."
랜덤포레스트를 이용한 모기업의 하향 거래처 기업의 분류: 자동차 부품산업의 가치사슬을 중심으로,2018,"['가치사슬 분류', '전자세금계산서', '자동차 부품산업', '기계학습', '랜덤포레스트', 'Value Chain Classification', 'Electronic Tax Invoice', 'Industry of Automobile Parts', 'Machine Learning', 'Random Forest']","가치사슬은 경쟁우위 강화를 위한 전략적 도구로써 주로 기업수준, 산업수준에서 분석되어왔다. 그런데 기업수준에서 가치사슬 분석을 수행하기 위해서는 분석 기업의 거래처 기업들이그 기업의 가치 사슬에 속하는지의 여부에 따라 분류되어야 한다. 단일 기업에 대한 가치사슬분류는 전문가들에 의해 원활히 수행될 수 있지만 다수의 기업을 대상으로 분류할 때는 많은비용과 시간이 소요되는 등의 한계점이 따른다. 따라서 본 연구에서는 실거래 데이터를 기반으로특정 기업의 거래처 기업들을 분류해서 가치사슬 기업을 자동적으로 도출해주는 모형을 제안하고자 한다. 총 19개의 거래 속성 변수를 실거래 데이터로부터 도출하여 기계학습의 입력데이터의 형태로 가공하였고, 랜덤포레스트 알고리즘을 이용하여 가치사슬 분류 모형을 구축하였다. 자동차 부품 기업 사례에 본 연구 모형을 적용한 결과, 정확도 92%, F1-척도 76%그리고 AUC 94%로 자동적 가치사슬 분류의 가능성을 확인하였다. 또한 거래집중도, 거래금액그리고 거래처별 총 매출액 등과 같은 거래 속성들이 가치사슬에 속하는 기업들을 대표하는주요 특성임을 확인하였다.","The value chain has been utilized as a strategic tool to improve competitive advantage,mainly at the enterprise level and at the industrial level. However, in order to conduct valuechain analysis at the enterprise level, the client companies of the parent company shouldbe classified according to whether they belong to it’s value chain. The establishment ofa value chain for a single company can be performed smoothly by experts, but it takesa lot of cost and time to build one which consists of multiple companies. Thus, this study proposes a model that automatically classifies the companies that form a value chain basedon actual transaction data. A total of 19 transaction attribute variables were extracted fromthe transaction data and processed into the form of input data for machine learning method.The proposed model was constructed using the Random Forest algorithm. The experimentwas conducted on a automobile parts company. The experimental results demonstrate thatthe proposed model can classify the client companies of the parent company automaticallywith 92% of accuracy, 76% of F1-score and 94% of AUC. Also, the empirical study confirmthat a few transaction attributes such as transaction concentration, transaction amount andtotal sales per customer are the main characteristics representing the companies that forma value chain."
발전변동량을 고려한 SVR기반 제주도지역의단기풍력발전량예측,2018,"['Wind Power Forecasting', 'Support Vector Regression', 'Numerical Weather Prediction', 'Statical Method', 'Artificial Intelligence Method', 'Machine Learning', '풍력발전량예측', 'SVR', 'NWP', '통계적방법', '인공지능방법', '기계학습']","최근 한국의 저탄소 녹색 성장을 위해서는 지속 가능한 전기 생산이 필수적이고, 특히 풍력발전에너지는 잠재적으로무제한이므로 전 세계적으로 빠르게 성장하고 있다. 그러나 풍력발전기는 간헐성 및 변동성으로 인하여 풍력발전에너지를 효율적으로 저장하고, 전기전력그리드와 통합하는 데 어려움이 있다. 이를 대처하기 위해 풍속과 전력 예측을 위한 많은 연구가 수행중이다. 풍력발전에너지를 예측하는데 사용되는 모델은 NWP(Numerical Weather Prediction), 통계적 방법, 인공지능 방법 같이 3가지로 구분된다. 본 논문은 바람의 특성인 풍향과 풍속의 특징을추출하고, 시계열데이터 특성을 반영하여 변수를 선택한 후, SVR 기반으로 기계학습하여 풍력발전기의 단기풍력발전량을 효율적으로 예측하는 방법을 제안한다. 제안한 방법의 정확도와 타당성을 검증하기 위하여 제주도 A, B, C 지역의 풍력발전단지 데이터를 사용하여 발전량을 예측한다. 실험결과, 제안한 방법을 이용한 단기풍력발전예측 방법이 기존 방법보다 우수하였다.","In recent years, sustainable electricity production is essential for low-carbon green growth in Korea, and wind power generation is potentially unlimited, and is rapidly growing worldwide. However, due to intermittency and volatility, wind power generators have difficulties in efficiently storing and integrating wind power generation with current electric power grids. In order to cope with that, many studies are being carried out to predict wind speed and power. The models used to predict wind energy are divided into three categories: Numerical Weather Prediction, statistical methods, and Artificial Intelligence methods. In this paper, we propose a method to efficiently estimate short-term wind power generation of wind turbine by extracting features of wind direction and wind speed, characteristics of wind, selecting variables based on time-series data characteristics, and learning machine based on SVR. To verify the accuracy and feasibility of the proposed method, we estimate the power generation using the wind farm data of A, B, C region in Jeju Island. Experimental results show that the prediction method of short-term wind power generation using the proposed method is superior to the conventional method."
인공지능 시대와 고전문학,2018,"['인공지능', '제4차 산업혁명', '자명고각', '만파식적', '고전문학', '인공신경망 기계번역', '기계학습 도구', 'Artificial Intelligence', '4th Industrial Revolution', 'Jamyungkogak(自鳴鼓角)', 'Manpasikjeok(萬波息笛)', 'Classical Literature', 'Neural Machine Translation', 'Machine Learning Tools']",,"Entering the 21st century, humans are facing an era of rapid change through what is called the Fourth Industrial Revolution. Unlike the first and third industrial revolutions that we experienced, this change is fundamentally changing the way people live, and so is the literary realm. The classics are still in the spotlight today, and many scholars study them because they are not solidified as fossils of the past, but because they give constant emotion and wisdom to those who live today.At this point, this manuscript I wanted to find a way to use artificial intelligence for research into the convergence of artificial intelligence and classical literature and, technically, the research of classical literature. Both may be perceived as different in terms of high technology and traditional literature, but through the stories in classical literature, both confirmed that the imagination of human beings is rooted. In addition, the two dimensions of the artificial neural network translation, machine translation and machine learning tools, discussed the feasibility and necessity of artificial intelligence, and the future needs to be supplemented. The new methods of literature research that fit in the changing times have become an irreversible trend, but to the extent that artificial intelligence research and its use should be human-centric. Looking for new ways to study classical literature using artificial intelligence can be meaningful in that it can be used as an opportunity to expand the territory in the midst of a crisis in humanities."
인공지능시대에도 종교는 가능한가?,2018,"['칸트', '블로흐', '모라벡', '커즈와일', '하라리', '테그마크', '보스트롬', '초지능', '초지능기계', '특이점', '매트릭스', '기술종교', '호모데우스', 'Artificial Intelligence', 'Religious Philosophy', 'Kant', 'Bloch', 'Morabeck', 'Kurzweil', 'Harrari', 'Tegmark', 'Bostrom', 'Super Intelligence', 'Ultra Intelligent Machine', 'Singularity', 'Matrix', 'Technology Religion', 'Homo Deus']","이 논문은 인공지능시대에도 종교는 가능한가, 오직 인간만이 종교신앙의 주체일 수 있는가, 인간의 마음을 탑재한 초지능기계들도 신앙의 주체일 수 있는가를 다룬다. 초지능기계들이 인간과 동일한 조건에서 신앙의 주체가 되려면, 인간의 고유한 특성인 감정, 의지, 자의식 등을 가질 수 있어야 한다. ‘특이점’ 이후의 초지능기계들은 종교신앙의 주체를 넘어서서, 신과 같은 존재로서 인간과 자연과 세계를 지배하게 될 것이다. 이는 모라벡, 커즈와일, 하라리의 공통된 견해이다. 칸트가 구상한 ‘순수이성의 이념’과 ‘실천이성의 요청’으로서 신 개념은 제시 베링이 앞서 말한 것처럼 ‘간극의 신’처럼 보일 수 있다. 종교적 신앙 주체는 항상 도덕적인 선을 행하려고 부단하게 노력해야 하지만, 그런 노력 자체만으로는 완전선(完全善)에 도달할 수 없기 때문에 영혼불멸성을 요청하였다. 그러나 특이점을 넘어서 출현한 초지능기계가 지능폭발로 신적 지위를 가질 수 있다면, 인공지능로봇은 칸트적인 의미에서 종교적 수행을 불필요하게 여길 것이다. 에른스트 블로흐의 경우에는 초지능기계가 신적 존재라고 하더라도, 그것이 악신인가 선신인가를 비판적으로 물어야 한다. 칸트의 매트릭스에서는 선신일 수 있는 초지능기계가 블로흐의 매트릭스에서는 악신으로 추락할 수도 있다. 따라서 초지능기계-신이 우리를 유일한 종교신앙의 완성으로 이끌어 가는지, 인류와 지구촌의 몰락으로 내몰아갈 것인지를 부단하게 비판적으로 성찰해야 한다.","This paper discusses, whether religion is possible even in the age of artificial intelligence, and whether humans alone are the subject of religious faith or ultra intelligent machines with human minds can be also subjects of faith. In order for ultra intelligent machines to be subjects of faith in the same conditions as humans, they must be able to have unique characteristics such as emotion, will, and self-consciousness. With the advent of ultra intelligent machines with the same level of cognitive and emotional abilities as human beings, the religious actions of artificial intelligence will be inevitable. The ultra intelligent machines after ‘singularity’ will go beyond the subject of religious belief and reign as God who can rule humans, nature and the world. This is also the common view of Morabeck, Kurzweil and Harari. Leonhart also reminds us that technological advances should make us used to the fact that we are now ‘gods’. But we fear we may face distopia despite the general affluence of the ‘Star Trec’ economy. For this reason, even if a man says he has learned the religious truth, one can’t help but wonder if it is true.  Kant and Bloch are thinkers who critically reflected on our religious ideals and highest concept in different world-view premises. Kant’s concept of God as ‘idea of pure reason’ and ‘postulate of practical reason’, can seem like a ‘god of gap’ as Jesse Bering said earlier. Kant recognized the need for religious faith only on a strict basis of moral necessity. The subjects of religious faith should always strive to do the moral good, but such efforts themselves were not enough to reach perfection and so postulated immortality of the soul. But if an ultra intelligent machines that has emerged above a singularity is given a new status in an intellectual explosion, it can reach its morality by blocking evil tendencies and by the infinite evolution of super intelligence. So it will no longer need Kant’s ‘Postulate for continuous progress towards greater goodness’, ‘Postulate for divine grace’ and ‘Postulate for infinite expansion of the kingdom of God on earth.’ Artificial intelligence robots would not necessarily consider religious performance in the Kant’s meaning, and therefore religion will also have to be abolished.  Ernst Bloch transforms Kant’s postulate to be Persian dualism. Therefore, in Bloch, even though the ultra intelligent machines is a divine being, one must critically ask whether it is a wicked or a good God. Artificial intelligence experts warn that ultra intellectual machine as Pandora’s gift will bring disaster to mankind. In the Kant’s Matrix, a ultra intelligent machines, which is the completion of morality and God itself, may fall into a bad god in Bloch’s Matrix. Therefore, despite the myth of singularity, we still believe that ultra intelligent machines, whether as God leads us to the completion of one of our only religious beliefs, or as bad god to the collapse of mankind through complete denial of existence."
인공지능 시대 지방회계 공무원의 업무 변화에 대한 연구,2018,"['인공지능', '지방회계', '공무원', '업무', '빅데이터', 'Artificial Intelligence', 'Local Governmental Accounting', 'Public Official', 'Role', 'Big Data']","전문가가 주도적으로 이끌어오던 현재 공급자 중심의 정책결정 패러다임은 지능정보기술의 발달과 함께 데이터･알고리즘 기반 또는 인공지능 정책결정으로 변화할 것이다. 인공지능 발전의 핵심동력은 빅데이터이고, 빅데이터와 인공지능의 결합은 그 파급효과가 확대된다. 빅데이터 활용으로 예측 정확성을 높일 수 있고, 인공지능기술 도입으로 데이터분석 속도를 높일 수 있다. 수입관리, 신청허가, 사고보고, 사례관리, 계약관리, 대조, 클레임처리, 비용지출 등에 로보틱 프로세스 자동화가 도입된다면 업무 효율성이 증대되고, 공무원의 직무수행 역량이 강화될 것이다. 기계학습을 활용한 인공지능 예측시스템, 부정적발시스템 등을 통해 공무원의 전략적 사고 역량이 강화되어 효과적인 정책 집행관리가 가능하다. 이를 위해 지방회계 공무원이 산출하는 회계정보가 비재무정보를 포함하여 다양한 문제를 인식하고 해결할 수 있는 정보력을 가질 수 있도록 지방회계 관련 빅데이터 발굴이 선행되어야 한다.","The current supplier-oriented policy-making paradigm, led by experts, will shift toward data-based, algorithm-based, artificial intelligence policy making along with the development of emerging technology. Big data has reached at the tipping point for artificial intelligence in the accounting industry. The synergy between big data and artificial intelligence causes the ripple effect. By using big data, forecast accuracy can be improved, and artificial intelligence is speeding up the big data analytics process. Robotic process automation(RPA) will replace manual human efforts with local government-revenue collection, application approval, incident reporting, case management, contract administration, verification, claim processing, and expense payments thereby increasing efficiency and strengthening public servant performance. A prediction system to detect frauds through machine learning can enhance the strategic thinking ability of public officials and the effectiveness of policy enforcement management. In order to solve various problems, it is necessary to develop big data capabilities related to local governmental accounting information including non-financial information."
교육의 내적 논리에 비추어 본 정보기술기반 맞춤형 학습지원시스템의 가능성과 한계에 관한 시론,2018,"['정보기술기반 학습지원시스템', '맞춤형 교육', 'AIWBES', '교육의 내적 논리', '교육의 내재율', 'AIWBES', 'Educational Principle', 'Educational Epistemology', 'High-tech High-touch', 'Personalised learning']","본 논문은 교육본위론의 상구교육과 하화교육의 내재율 및 체험요소에 비추어 정보기술기반 학습지원시스템의 일종인 AIWBES(Adaptive and Intelligent Web-based Educational System)의 특징이 인간의 교육적 삶에 갖는 영향 및 의미를 가능성과 한계라는 측면에서 타진해 본 것이다. 정보기술기반의 학습지원시스템은, 하화교육의 요소 중 이타, 원조, 존우, 역차의 측면에서는 때로 인간의 한계를 뛰어넘어 탁월한 하화적 지원을 할 수 있을 것으로 보인다. 그러나 인간이 타인의 경험 속에 유사한 경험과 판단을 재창조한 결과로 자기 자신의 경험 계열의 가치를 재확인해 나가는 보수와 타증의 측면에서는 인간 대 인간의 교육에서보다 역동성이 떨어질 수 있다. 또한, 상구교육의 체험을 풍성하게 해 주는 기반이 될 수 있는 상구자의 소재계상의 결핍을 소위 ‘맞춤형’ 서비스로 정보기술기반 학습지원시스템이 지나치게 효율적으로만족시켜 줄 경우에, 상구교육의 과정에서 요청되는 새로운 경험의 탐색, 혼동에의 긍정, 좌절과 방황 같은 인간적인 체험이 발달하지 못하거나 퇴보할 가능성도 무시할 수 없다. 끝으로본 논문은 ‘하이터치 하이테크 학습(High-Touch High-Tech Learning)’의 변증법 속에서 인간이새로운 물질적, 기술적 기반을 토대로 새로운 형태의 교육을 탐색해 나갈 수 있는 가능성에대한 탐색을 제안한다.","The article intends to take a dispassionate look through the potentialities and the limitations oftechnology-based educational systems such as AIWBES(Adaptive and Intelligent Web-basedEducational System) in the era of precipitated worries over the replacement of human work byartificial intelligent. Adopting the perspective of an educational theory that tries to show theprinciples of education in its structural totality, the article examines what the AIWBES could doand could not in comparison with human practice. Classic AIWBESes such as ELM-ART aredesigned for curriculum sequencing that enables software to trace and satisfy the educational needson the side of ascending-educator, intelligent solution analysis, and problem-solving support. Thesefunctions in the software may meet some aspects of what humans usually do in thedescending-educational context, for example, foolishness-respecting, regressive order taking in thearrangement of experience for others, while they could have wide range of limitations on theexperiential and existential side of human education. The lack of human touch in the partiallyexcellent educational performance of the machine may prevent the ascending-educator fromexperiencing very humane process of ascending-education, i.e. contacting chaos and bewilderment inexperimental search of newer self. The article suggests in the end to explore the dialectics ofHigh-touch High-tech Learning discourse to further the intended reflections."
불균형 데이터 환경에서 로지스틱 회귀모형을 이용한 Cochlodinium polykrikoides 적조 탐지 기법 연구,2018,"['적조', '해수색 원격 탐사', '정지 궤도 해색 위성', '로지스틱 회귀 모델', '기계 학습', 'Red Tide', 'Ocean Color Remote Sensing', 'COMS/GOCI', 'Logistic Regression Model Machine Learning']","본 연구에서는 불균형 데이터 환경에서 기계학습 기법의 한 갈래인 로지스틱 회귀모형을 이용하여 인공위성 영상에서 Cochlodinium polykrikoides 적조 픽셀을 탐지하는 방법을 제안한다. 학습자료로 적조, 청수, 탁수 해역에서 추출된 수출광량 분광 프로파일을 활용하였다. 전체 데이터셋의 70%를 추출하여 모형 학습에 활용하였으며, 나머지 30%를 이용하여 모형의 분류 정확도를 평가하였다. 이 때, 청수와 탁수에 비해 자료 수가 상대적으로 적은 적조의 분광 프로파일에 백색 잡음을 추가하여 오버샘플링을 하여 불균형 데이터 문제를 해결하였다. 정확도 평가 결과 본 연구에서 제안하는 알고리즘은 약 94%의 분류 정확도를 보였다.","This study proposed a method to detect Cochlodinium polykrikoides red tide pixels in satellite images using a logistic regression model of machine learning technique under Imbalanced data. The spectral profiles extracted from red tide, clear water and turbid water were used as training dataset. 70% of the entire data set was extracted and used for model training, and the classification accuracy of the model was evaluated using the remaining 30%. At this time, the white noise was added to the spectral profile of the red tide, which has a relatively small number of data compared to the clear water and the turbid water, and oversampling was performed to solve the unbalanced data problem. As a result of the accuracy evaluation, the proposed algorithm showed about 94% classification accuracy."
데이터 과학시대 텍스트 데이터 분석기법에 대한 간략한 소개와 제도화를 위한 제언 : 텍스트 데이터에 대한 차원축소 기법을 중심으로,2018,"['텍스트 데이터', '오픈소스 컴퓨터 언어', '토픽모형', '감정분석', '어휘기반 텍스트 분석', '기계학습', 'text data', 'open-source computer language', 'topic model', 'sentiment analysis', 'lexicon-based text analysis', 'machine learning']",,"Due to the advent of digitalization, the amount and scope of textual data explodes and provides social scientists many opportunities to exploit the advantages of the increased volume of text data. However, the plausibility of traditional manual content analysis is hardly comprehensive and/or useful because of expensive cost hiring human coders and limited amount of time for the voluminous textual data. In this sense, algorithmic understanding of textual data (i.e., identifying textual data as matrix where documents are on the row and tokens, usually words, are on the column), provides theoretical and practical solutions for the analyses of textual data, in terms of topic detection and sentiment analysis. This study overviews a variety of algorithmic approach to textual data, and provides three groups: (1) lexicon-based approach, (2) unsupervised machine learning approach, and (3) supervised machine learning approach. Those three approaches were introduced with plain words to social scientists and how they can be exploited to understand large-scale textual data and how the predicted meanings of textual data for associational or causal analysis for social scientific theory building and testing. In the discussion section, some practical suggestions regarding how those methods can be used, and what should be done for the algorithmic approach settles in social scientific fields."
음성·영상 신호 처리 알고리즘 사례를 통해 본 젠더혁신의 필요성,2018,"['과학기술 젠더혁신', '성·젠더분석', '노인음성 신호처리', '기계학습과 젠더', '융복합 젠더 정책', '기계번역기술', '안면 젠더 인식 기술', 'Science and technology gendered innovation', 'Gender analysis', 'Elderly voice signal processing', 'Machine learning and gender', 'Convergence gender policy', 'Machine translation', 'Facial gender recognition']","젠더혁신은 연구개발의 전 과정에서 남녀의 생물학적, 인지적, 사회적 특성 및 행동방식의 차이에 의한 성⋅젠더 요소를 고려하여 남녀 모두를 위한 보다 나은 연구개발과 지식을 창출하는 과정을 의미한다. 본 논문의 연구목적은 ICT 산업, 자동차 산업, 빅데이터, 로봇 산업 등에 활용할 수 있는 영상·음성신호처리에서 문헌연구 및 기존 자료를 분석하고 사례 조사를 통하여 젠더혁신의 중요성을 고찰하는 것이다. 본 연구에서는 젠더 연구를 기반으로 영상·음성신호처리의 관련된 최신 국내외 문헌을 검색하고 총 8편의 논문을 선정한다. 그리고 젠더분석 측면에서, 연구대상, 연구 환경, 연구 설계로 구분하여 살펴본다. 연구결과로써, 노인음성 신호처리, 기계학습과 젠더, 기계번역 기술, 안면 젠더인식 기술의 음성·영상 신호 처리 알고리즘 논문 사례 분석을 통하여 기존의 알고리즘에 젠더편향성이 있음을 밝히고 이들 알고리즘 개발에서 상황에 맞는 성·젠더 분석이 필요함을 보인다. 또한 알고리즘 개발에 다양한 성⋅젠더 요소를 반영하는 젠더혁신 방법과 정책을 제안한다. 추후 ICT에서의 젠더혁신은 남녀 모두의 요구를 반영한 제품과 서비스를 개발로 새로운 시장 창출에 기여할 수 있다.","Gendered innovations is a term used by policy makers and academics to refer the process of creating better research and development (R&D) for both men and women. In this paper, we analyze the literatures in image and speech signal processing that can be used in ICT, examine the importance of gendered innovations through case study. Therefore the latest domestic and foreign literature related to image and speech signal processing based on gender research is searched and a total of 9 papers are selected. In terms of gender analysis, research subjects, research environment, and research design are examined separately. Especially, through the case analysis of algorithms of the elderly voice signal processing, machine learning, machine translation technology, and facial gender recognition technology, we found that there is gender bias in existing algorithms, and which leads to gender analysis is required. We also propose a gendered innovations method integrating sex and gender analysis in algorithm development. Gendered innovations in ICT can contribute to the creation of new markets by developing products and services that reflect the needs of both men and women."
단기 전력 부하 첨두치 예측을 위한 심층 신경회로망 모델,2018,"['융합', '전력수요 예측', '전력부하 첨두치 예측', '심층 신경회로망', '심층 학습', 'Convergence', 'Convergence', 'Power Demand Forecasting', 'Electric Peak Load Prediction', 'Deep Neural Network', 'Deep Learning']","스마트그리드에서 정확한 단기 부하 예측을 통한 자원의 이용 계획은 에너지 시스템 운영의 불확실성을 줄이고 운영 효율을 높이는데 있어서 매우 중요하다. 단기 부하 예측에 얕은 신경회로망을 포함한 다수의 머신 러닝 기법이 적용되어왔지만 예측 정확도의 개선이 요구되고 있다. 최근에는 컴퓨터 비전이나 음성인식 분야에서 심층 신경회로망의 뛰어난 연구 결과로 인해 심층 신경회로망을 단기 전력수요 예측에 적용해 예측 정확도를 개선하려는 시도가 주목 받고 있다. 본 논문에서는 일별 전력 부하 첨두치를 예측하기 위한 다층신경회로망 구조의 심층 신경회로망 모델을 제안한다. 제안된 심층 신경회로망은 층별 학습이 선행된 후 전체 모델의 학습이 이루어진다. 한국전력거래소에서 얻은 4년 동안의 일별 전력 수요 데이터를 사용, 하루 및 이틀 앞선 전력수요 첨두치를 예측하는 심층 신경회로망 모델을 구축하고 예측 정확도를 비교, 평가한다.","In smart grid an accurate load forecasting is crucial in planning resources, which aids in improving its operation efficiency and reducing the dynamic uncertainties of energy systems. Research in this area has included the use of shallow neural networks and other machine learning techniques to solve this problem. Recent researches in the field of computer vision and speech recognition, have shown great promise for Deep Neural Networks (DNN). To improve the performance of daily electric peak load forecasting the paper presents a new deep neural network model which has the architecture of two multi-layer neural networks being serially connected. The proposed network model is progressively pre-learned layer by layer ahead of learning the whole network. For both one day and two day ahead peak load forecasting the proposed models are trained and tested using four years of hourly load data obtained from the Korea Power Exchange (KPX)."
크라우드소싱 기반 이미지 태깅 시스템 구축 연구,2018,,,"This study aims to improve the access and retrieval of images and to find a way to effectively generate tags as a tool for providing explanation of images. To do this, this study investigated the features of human tagging and machine tagging, and compare and analyze them. Machine tags had the highest general attributes, some specific attributes and visual elements, and few abstract attributes. The general attribute of the human tag was the highest, but the specific attribute was high for the object and scene where the human tag constructor can recognize the name. In addition, sentiments and emotions, as well as subjects of abstract concepts, events, places, time, and relationships are represented by various tags. The tag set generated through this study can be used as basic data for constructing training data set to improve the machine learning algorithm."
수학교육의 변화와 인공지능과의 연관성 탐색,2018,"['artificial intelligence', 'education paradigm', 'Intelligent Computer Aided Instruction', '인공지능', '교육 패러다임', '인공지능 컴퓨터 보조학습']",인공지능(Artificial Intelligence)의 잠재력에 대한 기대로 여러 분야에서 이를 활용하고자 노력하고 있으며 교육 분야에서의 적용에 대한 관심 역시 높다. 교육에 있어서 인공지능 기술에 활용되는 기계학습(machine learning)과 딥러닝(deep learning)으로 스스로 학습하는 방법에 대한 관심을 가지게 되었으며 이러한 방식이 교육에 어떻게 활용될 수 있을 지와 인공지능을 어떻게 수학교육에 적용할 수 있을지에 대한 관심이 대두되고 있다. 이에 정보통신기술의 발달에 따른 수학교육의 변화를 고찰해 봄으로써 수학교육의 변화가 인공지능과 어떠한 연과성이 있는지를 살펴보는데 의의가 있다고 할 수 있다.,"Recently, we are working to utilize it in various fields with the expectation of the potential of artificial intelligence. There is also interest in applying to the field of education. In the field of education, machine learning and deep learning, which are used in artificial intelligence technology, are deeply interested in how to learn on their own. We are interested in how artificial intelligence and artificial intelligence technologies can be used in education and we have an interest in how artificial intelligence can be applied to mathematics education. The purpose of this study is to investigate the direction of mathematics education as the change of education paradigm and the development of artificial intelligence according to the development of information and communication technology. Furthermore, we examined how artificial intelligence can be applied to mathematics education."
Android malicious code Classification using Deep Belief Network,2018,"['malware classification', 'texture image', 'uncompressed gray-scale', 'Deep Belief Network']",,"This paper presents a novel Android malware classification model planned to classify and categorize Android malicious code at Drebin dataset. The amount of malicious mobile application targeting Android based smartphones has increased rapidly. In this paper, Restricted Boltzmann Machine and Deep Belief Network are used to classify malware into families of Android application. A texture-fingerprint based approach is proposed to extract or detect the feature of malware content. A malware has a unique image texture in feature spatial relations. The method uses information on texture image extracted from malicious or benign code, which are mapped to uncompressed gray-scale according to the texture image-based approach. By studying and extracting the implicit features of the API call from a large number of training samples, we get the original dynamic activity features sets. In order to improve the accuracy of classification algorithm on the features selection, on the basis of which, it combines the implicit features of the texture image and API call in malicious code, to train Restricted Boltzmann Machine and Back Propagation. In an evaluation with different malware and benign samples, the experimental results suggest that the usability of this method---using Deep Belief Network to classify Android malware by their texture images and API calls, it detects more than 94% of the malware with few false alarms. Which is higher than shallow machine learning algorithm clearly."
Analysis and Improvement Plans on Visualization Systems for Word Analysis: Focused on Word2Vec,2018,"['Visualization', 'Word2Vec', 'BigData', 'word analysis']",,"As a number of studies on big data have been conducted, a great deal of information is extracted and shared by analyzing data. Studies on extracting useful information through artificial neural network based machine learning from accumulated voluminous document data have been made. Recently, Word2Vec that has overcome complexity of natural language processing machine learning has appeared as an efficient model to extract a link between words. A study on extracting similar words and visualizing information through Word2Vec model is being conducted. Visualization system helps people to easily perceive information by maximizing understanding of information extracted from big data. This study will analyze visualization system cases of Word2Vec model to find visualization system which is easy for people to understand."
Daphnia Magna Toxicity Bioassays Using Shadow Tracking Sensor & Patten Recognition,2018,"['생태독성', '물벼룩', '패턴인식', '그림자추적센서', 'Ecotoxicology', 'Daphnia Magna', 'Patten recognition', 'Shadow Tracking sensor']",,
An Efficient One Class Classifier Using Gaussian-based Hyper-Rectangle Generation,2018,"['Imbalanced Dataset', 'One-Class Classification', 'Classifier Using Hyper-Rectangle', 'Classification Rate', 'Interpretability']",,"In recent years, imbalanced data is one of the most important and frequent issue for quality control in industrial field. As an example, defect rate has been drastically reduced thanks to highly developed technology and quality management, so that only few defective data can be obtained from production process. Therefore, quality classification should be performed under the condition that one class (defective dataset) is even smaller than the other class (good dataset). However, traditional multi-class classification methods are not appropriate to deal with such an imbalanced dataset, since they classify data from the difference between one class and the others that can hardly be found in imbalanced datasets. Thus, one-class classification that thoroughly learns patterns of target class is more suitable for imbalanced dataset since it only focuses on data in a target class. So far, several one-class classification methods such as one-class support vector machine, neural network and decision tree there have been suggested. One-class support vector machine and neural network can guarantee good classification rate, and decision tree can provide a set of rules that can be clearly interpreted. However, the classifiers obtained from the former two methods consist of complex mathematical functions and cannot be easily understood by users. In case of decision tree, the criterion for rule generation is ambiguous. Therefore, as an alternative, a new one-class classifier using hyper-rectangles was proposed, which performs precise classification compared to other methods and generates rules clearly understood by users as well. In this paper, we suggest an approach for improving the limitations of those previous one-class classification algorithms. Specifically, the suggested approach produces more improved one-class classifier using hyper-rectangles generated by using Gaussian function. The performance of the suggested algorithm is verified by a numerical experiment, which uses several datasets in UCI machine learning repository."
Predicting Employment Earning using Deep Convolutional Neural Networks,2018,['소득 예측'],"소득은 경제생활에서 중요하다. 소득을 예측할 수 있으면, 사람들은 음식, 집세와 같은 생활비를 지불 할 수 있는 예산을 세울 수 있을 뿐 아니라, 다른 재화 또는 비상사태를 위한 돈을 별도로 저축 할 수 있다. 또한 소득수준은 은행, 상점 및 서비스 회사에서 마케팅 목적 및 충성도가 높은 고객을 유치하는 데 활용 된다. 이는 소득이 다양한 고객 접점에서 사용되는 중요한 인구 통계 요소이기 때문이다. 따라서 기존 고객 및 잠재 고객에 대한 수입 예측이 필요하다. 이 연구에서는 소득을 예측하기 위해 SVM (Support Vector Machines), Gaussian, 의사 결정 트리, DCNN (Deep Convolutional Neural Networks)과 같은 기계 학습 기법을 사용하였다. 분석 결과 DCNN 방법이 본 연구에서 사용 된 다른 기계 학습 기법에 비해 최적의 결과(88%)를 제공하는 것으로 나타났다. 향후 PCA 같이 데이터 크기를 향상 시킨다면 더 좋은 연구 결과를 제시할 수 있을 것이다.","Income is a vital aspect of economic life. Knowing what their income will help people create budgets that allow them to pay for their living expenses. Income data is used by banks, stores, and service companies for marketing purposes and for retaining loyal customers; it is a crucial demographic element used at a wide variety of customer touch points. Therefore, it is essential to be able to make income predictions for existing and potential customers. This paper aims to predict employment earnings or income based on history, and uses machine learning techniques such as SVMs (Support Vector Machines), Gaussian, decision tree and DCNNs (Deep Convolutional Neural Networks) for predicting employment earnings. The results show that the DCNN method provides optimum results with 88% compared to other machine learning techniques used in this paper. Improvement of the data length such PCA has the potential to provide more optimum result."
State Prediction of High-speed Ballistic Vehicles with Gaussian Process,2018,"['Aerodynamics', 'Gaussian process', 'high-speed vehicles', 'state prediction', 'target trajectory']",,"This paper proposes a new method of predicting the future state of a ballistic target trajectory. There have been a number of estimation methods that utilize the variations of Kalman filters, and the prediction of the future states followed the simple propagations of the target dynamic equations. However, these simple propagations suffered from no observation of the future state, so this propagation could not estimate a key parameter of the dynamics equation, such as the ballistic coefficient. We resolved this limitation by applying a data-driven approach to predict the ballistic coefficient. From this learning of the ballistic coefficient, we calculated the future state with the future ballistic parameter that differs over time. Our proposed model shows the better performance than the traditional simple propagation method in this state prediction task. The value of this research could be recognized as an application of machine learning techniques to the aerodynamics domains. Our framework suggests how to maximize the synergy by linking the traditional filtering aproaches and diverse machine learning techniques, i.e., Gaussian process regression, support vector regression and regularized linear regression."
ITS를 위한 개인화 학습코스 추천 모델 개발,2018,"['유사성', '지능형교수시스템', '개인화', '추천시스템', 'TF-IDF', 'TF-IDF', 'Similarity', 'Intelligence Tutoring System', 'Individualization', 'Recommendation System']","학습코스 선정에 많은 어려움과 시행착오를 겪고 있는 사용자들에게 수준별 학습코스를 제공하기 위해, ITS (Intelligence Tutoring System)를 위한 동적인 학습자 맞춤형 학습코스 추천 모델을 개발하였다. 이를 위해, 개인화 학습코 스 추천모델에서는 먼저 학습자 프로파일을 분석하고, 단어별 가중치를 계산하여 핵심 키워드를 추출한다. 추출된 단어는 Cosine Similarity 기법을 통해 유사도를 측정하고, 최종적으로 유사도가 높은 상위 3개 과정이 학습자에게 추천된다. 추천 모델의 효과를 분석하기 위해, 경기도 소재 교육기관에 추천모델을 적용하였고, 만족도 조사를 통하여 설문 항목별 평균, 표준편차, 왜도, 첨도 값을 계산하였다. 실험결과, 정확성, 새로움, 자기참조, 유용성에서 높은 만족도를 보였으며, 추천모델 의 실효성을 검증했다. 본 연구는 그동안 국내·외에서 충분히 다뤄지지 않았던 기계학습 중심의 맞춤형 학습코스를 추천했 다는 점에서 의미가 있다.","To help users who are experiencing difficulties finding the right learning course corresponding to their level of proficiency, we developed a recommendation model for personalized learning course for Intelligence Tutoring System(ITS). The Personalized Learning Course Recommendation model for ITS analyzes the learner profile and extracts the keyword by calculating the weight of each word. The similarity of vector between extracted words is measured through the cosine similarity method. Finally, the three courses of top similarity are recommended for learners. To analyze the effects of the recommendation model, we applied the recommendation model to the Women's ability development center. And mean, standard deviation, skewness, and kurtosis values of question items were calculated through the satisfaction survey. The results of the experiment showed high satisfaction levels in accuracy, novelty, self-reference and usefulness, which proved the effectiveness of the recommendation model. This study is meaningful in the sense that it suggested a learner-centered recommendation system based on machine learning, which has not been researched enough both in domestic, foreign domains."
수질자료의 이상치 탐색을 위한 Isolation Forest기법의 적용,2018,"['Water Quality Dataset', 'Outlier', 'Distance-Based Outlier Detection', 'Isolation Forest', '다항목 수질자료', '이상치', '거리기반 이상치 탐색', 'Isolation Forest']","다변량 기반의 이상치 탐지기법은 다양한 분야에서 활발히 연구되어 왔으나 상수도 수질관리 분야에 대한 국내 연구는 상대적으로 미흡하며, 작은 범위에서 수행되어왔다. 이에 본 연구에서는 국내 G_정수장을 대상으로 다항목의 수질자료를수집하고 통계적 상관관계 유무에 따라 집단을 분류하였다. 그리고 상관관계가 유의미한 집단에 대해서는 거리기반 및Isolation Forest 기법을 적용하여 기법별 이상치 탐색 성능을 상호 비교·분석하였으며, 상관관계가 유의미하지 못한 집단에대해서는 Isolation Forest 기법만을 적용한 후 기계학습의 변화에 따른 이상치 탐색 성능을 분석하였다. 그 결과 Isolation Forest 기법이 거리기반 기법에 비해 보다 넓은 범위에서 이상치들을 탐색하는 것으로 분석되었으며, 기계학습량의 변화에따른 이상치 탐색 성능의 변화는 미소한 것으로 나타났다.","Although multivariate outlier detection techniques have been actively studied in various fields, domestic studies on the water quality management of waterworks are relatively inadequate and have been performed in a small range. In this study, water quality dataset were collected from G_water treatment plants in South Korea and classified by the statistical correlation. For the groups with significant correlations, we compared and analyzed the outlier detection performance by applying distance and isolation forest techniques. For the group with insignificant correlation, we analyzed the outlier detection performance according to the change of machine learning instance after applying Isolation Forest method. As a result, the distance-based and Isolation Forest methods were able to effectively search global and local outliers in the water quality dataset. Furthermore Isolation Forest method is analyzed to search outliers in a wider range than the distance-based method. In the Isolation Forest method, the change of the outlie search performance according to the change of the machine learning amount is small."
가우시안 기반 Hyper-Rectangle 생성을 이용한 효율적 단일 분류기,2018,"['Imbalanced Dataset', 'One-Class Classification', 'Classifier Using Hyper-Rectangle', 'Classification Rate', 'Interpretability']",,"In recent years, imbalanced data is one of the most important and frequent issue for quality control in industrial field. As an example, defect rate has been drastically reduced thanks to highly developed technology and quality management, so that only few defective data can be obtained from production process. Therefore, quality classification should be performed under the condition that one class (defective dataset) is even smaller than the other class (good dataset). However, traditional multi-class classification methods are not appropriate to deal with such an imbalanced dataset, since they classify data from the difference between one class and the others that can hardly be found in imbalanced datasets. Thus, one-class classification that thoroughly learns patterns of target class is more suitable for imbalanced dataset since it only focuses on data in a target class. So far, several one-class classification methods such as one-class support vector machine, neural network and decision tree there have been suggested. One-class support vector machine and neural network can guarantee good classification rate, and decision tree can provide a set of rules that can be clearly interpreted. However, the classifiers obtained from the former two methods consist of complex mathematical functions and cannot be easily understood by users. In case of decision tree, the criterion for rule generation is ambiguous. Therefore, as an alternative, a new one-class classifier using hyper-rectangles was proposed, which performs precise classification compared to other methods and generates rules clearly understood by users as well. In this paper, we suggest an approach for improving the limitations of those previous one-class classification algorithms. Specifically, the suggested approach produces more improved one-class classifier using hyper-rectangles generated by using Gaussian function. The performance of the suggested algorithm is verified by a numerical experiment, which uses several datasets in UCI machine learning repository."
최적화 알고리즘을 이용한 정보데이터 분할방법에 대한 연구,2018,"['RBFNNs 패턴분류기', 'FCM(Fuzzy C-Means) 클러스터링', 'PSO(Particle Swarm Optimization)', 'MOPSO(Multi Objective Particle Swarm Optimization)', '교차 검증법', 'RBFNNs pattern classifier', 'FCM(Fuzzy C-means) clustering', 'PSO(Particle Swarm Optimization)', 'MOPSO(Multi Objective Particle Swarm Optimization)', 'Cross Validation']","본 연구에서는 최적화 기법에 도움으로 설계된 개선된 교차 검증법을 소개한다. 교차 검증법은 적은 데이터를 가지고도 통계적 신뢰성을 높이기 위한 방법이고 개선된 교차 검증법은 최적화 기법에 알맞게 적용한 방법이다. 개선된 교차 검증법과 기존 교차 검증법을 이용하여 다양한 구조의 데이터 분할을 하고 이를 방사형 기저함수의 입력데이터로 사용한다. 은닉층을 FCM클러스터링 알고리즘기반의 RBFNNs을 분류기로 사용하고 은닉층의 연결가중치로는 규칙 후반부에 다항식 계수를 최소자승법으로 추정한다. RBFNNs에 사용되는 파라미터(예를 들면, 퍼지화 계수 클러스터의 개수) 뿐만 아니라 다항식 종류는 Multi Objective Particle Swarm Optimization와 Particle Swarm Optimization를 이용하여 최적화된다. 제안된 방법의 성능 평가를 위해 다양한 종류의 Machine Learning(ML)데이터를 사용하여 분류 성능을 구한다. 그리고 기존방법과 제안된 방법의 성능의 비교해석이 묘사된다.","In this study, an improved cross validation method designed with the aid of optimization techni ues is introduced. The cross validation method is a method to improve the statistical reliability even with a small amount of data, and the improved cross validation method is applied to the optimization technique. By using both the improved cross validation method and the existing cross validation method, the data is divided into various structures and used as the input data of the radial basis function. RBFNNs based on FCM clustering algorithm are used as a classifier. as hidden weighting factors, the polynomial coefficients of the consequent part of rules are estimated using least square method. The parameters(viz. fuzzification coefficient and number of clusters) as well as polynomial type used in RBFNNs is optimized by using both Multi Objective Particle Swarm Optimization and Particle Swarm Optimization. To evaluate the performance of the proposed method, classification performance is obtained by using various kinds of Machine Learning (ML) dataset. The comparative analysis between the performance of the proposed method and that of the existing methods is described."
효과적인 기업부도 예측모형을 위한 ROSE 표본추출기법의 적용,2018,"['ROSE', '데이터불균형', '표본추출', '부도 예측', 'Random Over Sampling Examples', 'Data Imbalance', 'Sampling', 'Bankruptcy Prediction']","분류 문제에서 특정 범주의 빈도가 다른 범주에 비해 과도하게 높은 경우, 왜곡된 기계 학습을 유발할 수 있는 데이터 불균형(imbalanced data) 문제가 발생한다. 기업부도 예측 문제도 그 중 하나인데, 일반적으로 금융기관과 거래하는 기업들의 부도율은 대단히 낮아서, 부도 사례보다 정상 사례의 빈도가 월등히 높은 데이터 불균형 문제가 발생하고 있다. 이러한 데이터 불균형 문제를 해결하기 위해서는 적절한 표본추출 기법이 적용될 필요가 있으며, 지금껏 소수 범주 데이터를 복원 추출함으로써 다수 범주 데이터와 비율 을 맞추어 데이터 불균형을 해결하는 오버 샘플링(oversampling) 기법이 주로 활용되어 왔다. 그러나 전통 적인 오버 샘플링은 과적합화(overfitting)가 발생할 위험이 높아질 수 있는 단점이 있다. 이러한 배경에서 본 연구는 효과적인 기업부도 예측 모형 학습을 위한 표본추출 기법으로 2014년에 Menardi와 Torelli가 제안한 ROSE(random over sampling examples) 기법을 제안한다. ROSE 기법은 학습에 사용될 사례를 반복적으로 새롭게 합성하여 생성(synthetic generation)하는 기법으로, 과적합화 문제를 회피하면서도 분류 예측 정확도 개선에 도움을 줄 수 있다. 이에 본 연구에서는 ROSE 기법을 가장 성능이 우수한 이분류기로 알려진 SVM(support vector machine)과 결합하여 국내 한 대형 은행의 기업부도 예측에 적용해 보고, 다른 표본추출 기법들과의 비교연구를 수행하였다. 실험 결과, ROSE 기법이 다른 기법에 비해 통계적으로 유의한 수준으로 SVM의 예측정확도 개선에 기여할 수 있음을 확인하였다. 이러한 본 연구의 결과는 부도 예측 외에 다른 사회과학 분야 예측문제의 데이터 불균형 문제 해결에도 ROSE가 우수한 대안이 될 수 있다는 사실을 시사한다.","If the frequency of a particular class is excessively higher than the frequency of other classes in the classification problem, data imbalance problems occur, which make machine learning distorted. Corporate bankruptcy prediction often suffers from data imbalance problems since the ratio of insolvent companies is generally very low, whereas the ratio of solvent companies is very high. To  mitigate these problems, it is required to apply a proper sampling technique. Until now, oversampling techniques which adjust the class distribution of a data set by sampling minor class with replacement have popularly been used. However, they are a risk of overfitting. Under this  background, this study proposes ROSE(Random Over Sampling Examples) technique which is proposed by  Menardi and Torelli in 2014 for the effective corporate bankruptcy prediction. The ROSE technique creates new learning samples by synthesizing the samples for learning, so it leads to better prediction accuracy of the classifiers while avoiding the risk of overfitting. Specifically, our  study proposes to combine the ROSE method with SVM(support vector machine), which is known as the best binary classifier. We applied the proposed method to a real world bankruptcy prediction case of a Korean major bank, and compared its performance with other sampling techniques. Experimental results showed that ROSE contributed to the improvement of the prediction accuracy of SVM in bankruptcy prediction compared to other techniques, with statistical significance. These results shed a light on the fact that ROSE can be a good alternative for resolving data imbalance problems of the prediction problems in social science area other than bankruptcy   prediction."
효율적인 변압기 유중가스 분석 및 분류 방법,2018,"['유중 가스 분석법', '기계학습', '고장진단', '유입변압기']",본 논문에서는 기계학습 기반의 효율적인 변압기 유중가스 분석 및 분류 방법을 제안하여 기존IEC 60599 진단기준 기반의 문제점을 해결하고 진단 성능을 개선한다. 기존 IEC 60599 진단기준은조성비가 진단 기준에 존재하지 않거나 경계조건에 있는 경우 진단 전문가에게 의뢰하지 않고는 해석에 어려움이 있으며 진단영역이 겹치는 부분이 존재하므로 정확한 원인분석을 수행하는 데에 한계가 있다. 따라서 IEC 60599 진단 기준만으로 변압기 유중가스 데이터를 분석 및 분류하는 경우 IEC60599 기준에 만족하지 않는 데이터를 분류하지 못한다는 문제점이 있다. 이와 같은 문제를 해결하기위해 기계학습 기반의 변압기 유중가스 분석 및 분류 방법을 제안하였다. 제안한 기계학습 기반의 변압기 유중가스 분석 방법은 IEC 60599 진단기준으로 판단이 불가능한 데이터를 서포트 벡터 머신을통해 정확히 분류 할 수 있다. 제안한 방법의 성능을 검증하기 위해 실제 유중가스 데이터를 사용하여 기계학습 기반의 변압기 유중가스 분석 방법의 효율성을 검증하였다.,"This paper proposes an efficient dissolved gas analysis(DGA) and classification method of an oil-filledtransformer using machine learning algorithms to solve problems inherent in IEC 60599. In IEC 60599, acertain diagnosis criteria do not exist, and duplication area is existed. Thus, it is difficult to make adecision without any experts since the IEC 60599 standard can not support analysis and classification ofgas date of a power transformer in that criteria. To address these issue. we propose a dissolved gasanalysis(DGA) and classification method using a machine learning algorithm. We evaluate the performanceof the proposed method using support vector machines with dissolved gas dataset extracted from a powertransformer in the real industry. To validate the performance of the proposed method, we compares theproposed method with the IEC 60599 standard. Experimental results show that the proposed methodoutperforms the IEC 60599 in the classification accuracy."
Bayesian-Based Decision Support System for Assessing the Needs for Orthodontic Treatment,2018,"['Machine Learning', 'Artificial Intelligence', 'Dental Informatics', 'Malocclusion', 'Angle’s Classification']",,"Objectives: In this study, a clinical decision support system was developed to help general practitioners assess the need fororthodontic treatment in patients with permanent dentition. Methods: We chose a Bayesian network (BN) as the underlyingmodel for assessing the need for orthodontic treatment. One thousand permanent dentition patient data sets chosen from ahospital record system were prepared in which one data element represented one participant with information for all variablesand their stated need for orthodontic treatment. To evaluate the system, we compared the assessment results based on thejudgements of two orthodontists to those recommended by the decision support system. Results: In a BN decision supportmodel, each variable is modelled as a node, and the causal relationship between two variables may be represented as a directedarc. For each node, a conditional probability table is supplied that represents the probabilities of each value of this node, giventhe conditions of its parents. There was a high degree of agreement between the two orthodontists (kappa value = 0.894) intheir diagnoses and their judgements regarding the need for orthodontic treatment. Also, there was a high degree of agreementbetween the decision support system and orthodontists A (kappa value = 1.00) and B (kappa value = 0.894). Conclusions: Thestudy was the first testing phase in which the results generated by the proposed system were compared with those suggested byexpert orthodontists. The system delivered promising results; it showed a high degree of accuracy in classifying patients intogroups needing and not needing orthodontic treatment."
Intelligent intrusion detection systems using artificial neural networks,2018,"['Machine learning', 'Intrusion detection systems', 'Computer security', 'Artificial Intelligence']",,"This paper presents a novel approach to detection of malicious network traffic using artificial neural networks suitable for use in deep packet inspection based intrusion detection systems. Experimental results using a range of typical benign network traffic data (images, dynamic link library files, and a selection of other miscellaneous files such as logs, music files, and word processing documents) and malicious shell code files sourced from the online exploit and vulnerability repository exploitdb [1], have shown that the proposed artificial neural network architecture is able to distinguish between benign and malicious network traffic accurately.The proposed artificial neural network architecture obtains an average accuracy of 98%, an average area under the receiver operator characteristic curve of 0.98, and an average false positive rate of less than 2% in repeated 10-fold cross-validation. This shows that the proposed classification technique is robust, accurate, and precise. The novel approach to malicious network traffic detection proposed in this paper has the potential to significantly enhance the utility of intrusion detection systems applied to both conventional network traffic analysis and network traffic analysis for cyber–physical systems such as smart-grids."
Wasserstein 거리를 이용한 연속형 변수 이산화 기법,2018,"['machine learning', 'statistical distance', 'distance function', 'Wasserstein distance', 'discretization', '기계 학습', '분포 거리 함수', '거리 함수', 'Wasserstein 거리', '이산화.']","연속형 변수의 이산화(Discretization)는 양적 변수(Quantitative variable)를 질적 변수(Qualitative variable)로 변형시켜 데이터 마이닝(Data mining) 기법 등 다양한 알고리즘의 성능을 향상시키는데 사용 목적이 있다. 데이터에 적절한 이산화 기법을 사용한다면 분류 알고리즘에 대해 더 좋은 성능뿐 아니라 간결한 결과 해석, 속도 향상까지 기대할 수 있다. 현재까지 다양한 이산화 기법들이 연구되었으며, 현재도 이산화와 관련한 연구에 수요가 많다. 본 논문은 데이터의 클래스에 대한 연속형 변수 값의 분포를 고려하여, Wasserstein 거리를 이용해 분할점을 자동 설정하는 이산화 기법을 제안한다. 본 논문에서 제안하는 기법과 우수함이 입증된 기존의 이산화 기법에 대해 성능비교를 통해 제안 기법의 우수성을 보인다.","Discretization of continuous variables intended to improve the performance of various algorithms such as data mining by transforming quantitative variables into qualitative variables. If we use appropriate discretization techniques for data, we can expect not only better performance of classification algorithms, but also accurate and concise interpretation of results and speed improvements. Various discretization techniques have been studied up to now, and however there is still demand of research on discretization studies. In this paper, we propose a new discretization technique to set the cut-point using Wasserstein distance with considering the distribution of continuous variable values with classes of data. We show the superiority of the proposed method through the performance comparison between the proposed method and the existing proven methods."
기계학습 기반 열차 자율주행 기법 개발을 위한 인프라 구축 및 데이터 분석,2018,"['Machine Learning', 'ATO', 'Stop of Train', 'Temperature', 'Humidity']",,
건강한 성인에서 피검사 결과와 환경적 요인에 의한 중증 우울도 데이터 예측,2018,"['Machine learning', 'ANN', 'DNN', 'PHQ-9', 'depression']",,
실생활 음향 데이터 기반 이중 CNN 구조를 특징으로 하는 음향 이벤트 인식 알고리즘,2018,"['Machine learning', 'Deep learning', 'Audio signal processing', 'Sound event detection', 'Dataset']",,"Sound event detection is one of the research areas to model human auditory cognitive characteristics by recognizing events in an environment with multiple acoustic events and determining the onset and offset time for each event. DCASE, a research group on acoustic scene classification and sound event detection, is proceeding challenges to encourage participation of researchers and to activate sound event detection research. However, the size of the dataset provided by the DCASE Challenge is relatively small compared to ImageNet, which is a representative dataset for visual object recognition, and there are not many open sources for the acoustic dataset. In this study, the sound events that can occur in indoor and outdoor are collected on a larger scale and annotated for dataset construction. Furthermore, to improve the performance of the sound event detection task, we developed a dual CNN structured sound event detection system by adding a supplementary neural network to a convolutional neural network to determine the presence of sound events. Finally, we conducted a comparative experiment with both baseline systems of the DCASE 2016 and 2017."
Microblog Sentiment Analysis Method Based on Spectral Clustering,2018,"['Machine Learning', 'RDM', 'Sentiment Analysis', 'Spectral Cluster']",,"This study evaluates the viewpoints of user focus incidents using microblog sentiment analysis, which hasbeen actively researched in academia. Most existing works have adopted traditional supervised machinelearning methods to analyze emotions in microblogs; however, these approaches may not be suitable inChinese due to linguistic differences. This paper proposes a new microblog sentiment analysis method thatmines associated microblog emotions based on a popular microblog through user-building combined withspectral clustering to analyze microblog content. Experimental results for a public microblog benchmarkcorpus show that the proposed method can improve identification accuracy and save manually labeled timecompared to existing methods."
자연어 처리 기반 맞춤형 트윗 추천 시스템,2018,"['머신러닝', '트위터', 'SNS', '자연어 처리', '키워드 추출', 'Machine learning', 'Twitter', 'SNS', 'Natural language processing', 'Keyword extracting']","트위터 사용자는 팔로우, 리트윗 등을 사용하여 자신이 관심 있어 하는 트윗을 찾는다. 하지만 사용자가 3억여 명에 달하는 트위터에서 사용자가 관심 있는 트윗을 찾기는 힘든 일이다. 이를 해결하기 위해 본 논문에서는 사용자 맞춤형 트윗 추천 시스템을 개발하였다. 우선, 사용자에게 추천할 수 있을 만한 가치가 있는 트윗을 수집하기 위해 현재 트랜드를 수집하고, 트랜드에 대해 이야기하는 인기 있는 트윗들을 수집한다. 이후 사용자를 분석하고 맞춤형 트윗을 추천하기 위해 사용자의 트윗과 수집한 트윗을 범주화한다. 최종적으로 웹서비스를 이용하여 사용자에게 본인과 카테고리가 일치하는 트윗과 관심사가 일치하는 사용자를 추천해준다. 결과적으로 67.2%로 적절한 트윗을 추천하였다.","Twitter users use ‘Following’, ‘Retweet’ and so on to find tweets that they are interested in. However, it is difficult for users to find tweets that are of interest to them on Twitter, which has more than 300 million users. In this paper, we developed a customized tweet recommendation system to resolve it. First, we gather current trends to collect tweets that are worth recommending to users and popular tweets that talk about trends. Later, to analyze users and recommend customized tweets, the users’ tweets and the collected tweets are categorized. Finally, using Web service, we recommend tweets that match with user categorization and users whose interests match. Consequentially, we recommended 67.2% of proper tweet."
파이썬 코딩을 도입한 수학 교과 지도 방안 개발 - 2015 개정 교육과정 중학교 수학 교과의 ‘소인수분해’ 내용을 중심으로 -,2018,"['파이썬(python) 언어1)', '주피터 노트북(Jupyter notebook)', '코딩(coding) 교육', '2015 개정 중학교 수학 교육과정', '수와 연산', 'Python Language', 'Jupyter Notebook', 'Coding Education', '2015 Revised Middle School Mathematics Curriculum', 'number and operation']","인공지능, 머신러닝, 딥러닝 등의 주제가 더욱 밀접하게 연결된 시대를 맞이하여 학교수학에서 개념과 원리에 대한 철학적이고 역사적인 접근으로 상상하고스스로 사고하는 교육을 바탕으로 컴퓨터를 이용하는 문제해결능력 개발을 중요한 역할로 고려하여야 한다. 이에 코딩 교육을 수학 교육과정에 자연스럽게 적용하여 두 가지 영역의 융합 교육을 시도하고자 한다. 본 논문에서는 오픈소스 프로그래밍 언어인 파이썬을 소개하고, 통합개발환경을 컴퓨터에 설치하는 방법을 설명한 후, 중학교 수학교과의 ‘수와 연산’ 영역의 한 내용 요소인 ‘소인수분해’에 대한 파이썬 코딩 지도 방안을 제시한다. 수학교과 문제를 컴퓨터로 해결하는 알고리즘 작성의 논리적 과정을 통하여 수학적 문제해결 교육의 한 방법을 모색하고자 한다.","In the era that the subjects of artificial intelligence, machine learning and deep learning and etc, are more closely related, school mathematics should consider as its important role to develop problem solving ability using computers on the base of the education which emphasizes a philosophical and historical approach to concepts and principles that must be imagined and thought of on their own. For this purpose, we propose to introduce coding education in mathematics curriculum as a fusion education of two subjects. In this paper, we adopt the open source Python language as a coding language, explain how to install the integrated development environment on a computer, and then suggest Python codes for teaching 'prime decomposition', a content element in the 'number and operation' in the middle school mathematics curriculum. Our aim is to explore a method of mathematical problem solving education through the logical process of writing computer algorithms to solve mathematics subjects."
연속형 속성을 갖는 인공 신경망의 규칙 추출,2018,"['symbolic learning and reasoning', 'knowledge extraction', 'neural network']","지난 수십 년 동안 인공 신경망은 음성 인식에서 이미지 분류에 이르기까지 수많은 분야에서 성공적으로 사용되었다. 그러나 인공 신경망은 특정 결론이 어떻게 도출되었는지 알 필요가 있음에도 불구하고 이러한 결과를 설명할 수 있는 능력이 부족하다. 대부분의 연구는 신경망에서 이진 규칙을 추출하는데 초점을 맞추고 있지만, 기계 학습 응용 프로그램에 사용되는 데이터는 연속된 값이 포함되어 있기 때문에 실용적이지 않은 경우가 있다. 이러한 격차를 줄이기 위해 본 논문에서는 연속된 값이 포함된 데이터로부터 학습된 신경망에서 논리 규칙을 추출하는 알고리즘을 제안한다. 초평면 기반 선형 분류기를 사용하여 입력 및 은닉 층 사이에서 학습된 가중치로부터 규칙을 추출하고, 비선형 분류 규칙을 생성하기 위해 은닉 층과 출력 층에서 학습된 이진 규칙과 분류기를 결합한다. 비선형 연속값으로 구성된 여러 데이터셋을 대상으로 진행한 실험에서 제안하는 방법이 논리적 규칙을 정확하게 추출할 수 있음을 보였다.","Over the decades, neural networks have been successfully used in numerous applications from speech recognition to image classification. However, these neural networks cannot explain their results and one needs to know how and why a specific conclusion was drawn. Most studies focus on extracting binary rules from neural networks, which is often impractical to do, since data sets used for machine learning applications contain continuous values. To fill the gap, this paper presents an algorithm to extract logic rules from a trained neural network for data with continuous attributes. It uses hyperplane-based linear classifiers to extract rules with numeric values from trained weights between input and hidden layers and then combines these classifiers with binary rules learned from hidden and output layers to form non-linear classification rules. Experiments with different datasets show that the proposed approach can accurately extract logical rules for data with nonlinear continuous attributes."
Extracting Rules from Neural Networks with Continuous Attributes,2018,"['symbolic learning and reasoning', 'knowledge extraction', 'neural network']",,"Over the decades, neural networks have been successfully used in numerous applications from speech recognition to image classification. However, these neural networks cannot explain their results and one needs to know how and why a specific conclusion was drawn. Most studies focus on extracting binary rules from neural networks, which is often impractical to do, since data sets used for machine learning applications contain continuous values. To fill the gap, this paper presents an algorithm to extract logic rules from a trained neural network for data with continuous attributes. It uses hyperplane-based linear classifiers to extract rules with numeric values from trained weights between input and hidden layers and then combines these classifiers with binary rules learned from hidden and output layers to form non-linear classification rules. Experiments with different datasets show that the proposed approach can accurately extract logical rules for data with nonlinear continuous attributes."
Deep Neural Architecture for Recovering Dropped Pronouns in Korean,2018,"['Deep learning', 'Dropped pronoun recovery', 'LSTM Encoding', 'Zero pronoun.']",,"Pronouns are frequently dropped in Korean sentences, especially in text messages in the mobile phone environment. Restoring dropped pronouns can be a beneficial preprocessing task for machine translation, information extraction, spoken dialog systems, and many other applications. In this work, we address the problem of dropped pronoun recovery by resolving two simultaneous subtasks: detecting zero‐pronoun sentences and determining the type of dropped pronouns. The problems are statistically modeled by encoding the sentence and classifying types of dropped pronouns using a recurrent neural network (RNN) architecture. Various RNN‐based encoding architectures were investigated, and the stacked RNN was shown to be the best model for Korean zero‐pronoun recovery. The proposed method does not require any manual features to be implemented; nevertheless, it shows good performance."
TensorFlow를 활용한 검색 키워드의 최적 순위 예측 알고리즘,2018,"['Prediction', 'Machine learning', 'keyword', 'search engine', 'Tensor Flow']",,
멀티 모달 학습을 사용한 시각적 특징 기반의 운전자 졸음 감지,2018,"['Multimodal-learning', 'Drowsy detection', 'Deep Boltzmann Machine', 'Restricted Boltzmann Machine', 'visual feature']",,
기계번역 담론에 대한 비판적 고찰,2018,"['neural machine translation', 'machine learning', 'BLEU', 'translator training', 'translation evaluation', '신경망기계번역', '머신러닝', '번역교육', '번역평가']",,
금속 표면의 결함 검출을 위한 영역 기반 CNN 기법 비교,2018,"['Defects detection', 'Metal surface', 'Convolution neural network', 'Faster R-CNN', 'YOLOv2']",,"A machine vision based industrial inspection includes defects detection and classification. Fast inspection is a fundamental problem for many applications of real-time vision systems. It requires little computation time and localizing defects robustly with high accuracy. Deep learning technique have been known not to be suitable for real-time applications. Recently a couple of fast region-based CNN algorithms for object detection are introduced, such as Faster R-CNN, and YOLOv2. We apply these methods for an industrial inspection problem. Three CNN based detection algorithms, VOV based CNN, Faster R-CNN, and YOLOv2, are experimented for defect detection on metal surface. The results for inspection time and various performance indices are compared and analysed."
교육적 인간의 기계적 환원에 관한 소고,2018,"['animal', 'machine', 'R. Descartes', 'E. Levinas', 'brain-based learning', '동물', '기계', '데카르트', '레비나스', '뇌기반학습과학']","전통적으로 교육학은 동물에 유비하여 인간의 인간학적 정체성을 규정하고, 이를 바탕으로 문화적·교육적 인간상을 구상하고 추구해 왔다. 그러나 현대에 들어서는 동물에 더하여 한 가지 새로운 비교대상이 등장하게 되었는데, 소위 인공지능으로 대표되는 기계류가 바로 그것이다. 이미 탁월한 능력으로 몇몇 분야에서 문화적 충격을선사하고 있는 인공지능의 가능성과 한계에 대한 논의는 제 4차 산업혁명이라는 화두와 아울러 지식사회 전반에걸쳐 활발하게 진행되고 있다. 이러한 기술사회적‧교육사회적 변화를 배경으로 하여, 본고에서는 이른바 기계론적 인간학의 고전적 사례라 할 수 있는 데카르트의 코기토를 고찰하되, 그 탄생과정에 전제된 인간의 기계화라는발상 및 이와 동시에 이루어진 인간 몸성의 망각 현상을 비판적으로 검토한다. 아울러 철학적으로 망각된 몸의현상들을 레비나스의 사유를 중심으로 간략히 복원해 보고자 한다. 이어지는 장에서는 현대 과학기술의 발달에힘입어 다양한 양상으로 실험되고 전개되고 있는 이른바 ‘몸 없는 인간’ 또는 ‘기계화된 인간’이라는 발상의 교육학적 버전이라 할 수 있는 뇌기반학습 또는 뇌교육이라는 신흥영역을 고찰하되, 그것의 인간학적·교육학적 전제들을 비판적으로 검토하려 한다.","Pedagogy is in its essence a science on human being, whose anthropological identity as an object and goal of education has been traditionally reconstructed through the comparison with God and animal. A new object for comparison emerged in the modern society, namely machinery represented as Artificial Intelligence. This new sort of being surprised the world with its unprecedented extraordinary competence in a few fields which have traditionally been dominated by human being. And now AI’s possibility and limit for or even against human being and human society are important issues in the knowledge society, especially in the era of the so called fourth industry revolution. In this background of techno-social and educational change, we trace back to the classical prototype of this idea called mechanistic anthropology by Rene Descartes. His finding or invention of cogito (the thinking ego) provides us with a clue to understand the theoretical process and result of the mechanization of or mechanistic understanding of human being as well as the history of oblivion of the corporality of human being. Based on this, we will try to rehabilitate the meaning of human corporality with the idea of Emmanuel Levinas who points out that human being consists not merely of his/her thinking function with his lightening reason, but also of his/her whole bodiness as a center of being as it cannot be fully explained with the cognitive-philosophical language by Descartes. In this connection, we also investigate the anthropological premise of the so called brain-based learning or brain-education, which, sharing the idea of Descartes, seems to be a educational version of the mechanized understanding of human being, in the hope of contributing to the contemporary science of education as a whole as well as to this new discipline of education."
“(인공)지능은 성별이 없다고?”,2018,"['Artificial intelligence', 'machine learning', 'mind uploading', 'robot', 'gender', 'gender stereotypes', 'female dislike', 'Body disgust', 'depersonalization', '인공지능 기계학습 마인드업로딩 로봇 젠더 성별화 고정관념 여성혐오 몸혐오 탈신체화']",,"Drawing on Londa Schiebinger’s book title The Mind Has No Sex?, this study questions the gender status of AI in its existing and imagined forms. Most of the major ANI digital assistants and chatbots are predominantly, or by default, female, while female AGI characters are increasing in cinema. Both of these reproduce gender stereotypes. The female gendering of AI serves a two-fold misogynous role, as anxiety about the new, potentially “monstrous” technology projects itself onto the monstrous female other while seeking to contain its threat by aligning female AI with children and puppies (Pepper and Aibo). Mind uploading is not free from gendered embodiment either, and with the fundamental misogyny programmed into the robot-bodied AI in Ex Machina the trans-human dream of disembodiment is in itself antisomatic and misogynous and thereby inscribes the hated gender onto the artificial consciousness. The absolute majority of AI programmers and other human agents are male and largely insensitive to gender discrimination in both reality and their own technology. With this unchallenged, the artificial mind does and will have asexofitsown and cause real-life consequences."
Connecting Technological Innovation in Artificial Intelligence to Real-world Medical Practice through Rigorous Clinical Validation: What Peer-reviewed Medical Journals Could Do,2018,"['Artificial Intelligence', 'Machine Learning', 'Decision Support Techniques', 'Peer Review', 'Journalism', 'Medical', 'Validation Studies']",,"Artificial intelligence (AI) is projected to substantially influence clinical practice in the foreseeable future. However, despite the excitement around the technologies, it is yet rare to see examples of robust clinical validation of the technologies and, as a result, very few are currently in clinical use. A thorough, systematic validation of AI technologies using adequately designed clinical research studies before their integration into clinical practice is critical to ensure patient benefit and safety while avoiding any inadvertent harms. We would like to suggest several specific points regarding the role that peer-reviewed medical journals can play, in terms of study design, registration, and reporting, to help achieve proper and meaningful clinical validation of AI technologies designed to make medical diagnosis and prediction, focusing on the evaluation of diagnostic accuracy efficacy. Peer-reviewed medical journals can encourage investigators who wish to validate the performance of AI systems for medical diagnosis and prediction to pay closer attention to the factors listed in this article by emphasizing their importance. Thereby, peer-reviewed medical journals can ultimately facilitate translating the technological innovations into real-world practice while securing patient safety and benefit."
기계학습기반 레이다기술 최신 연구 동향,2018,"['Cognitive Radar', 'machine learning', 'deep learning', 'radar resource management', 'radar signal processing']",,
Fault Diagnosis System based on Sound using Feature Extraction Method of Frequency Domain,2018,"['Pattern Recognition', 'Machine Learning', 'Machine Fault Diagnosis', 'Magnitude Spectrum', 'Principal Component Analysis', 'Artificial Neural Network']",,
의료인공지능: 인공지능 초심자를 위한 길라잡이,2018,['Artificial Intelligence Machine Learning Medicine Medical Imaging Diagnoses'],"인공지능 기술이 가까운 미래에 의료에 많은 영향을 미칠 것으로 예상한다. 하지만 인공지능 기술이 의학/의료 분야에 소개된 이후 많은 과장이 있었음을 부인할 수 없다. 실제로, 인공지능 기술의 임상 적용은 아직 초기 단계에 있으며 현재 임상진료에 널리 쓰이고 있는 것은 거의 없다. 인공지능 기술을 적절히 활용하여 의료를 발전시키고 궁극적으로 환자 진료에보다 큰 도움을 주기 위해서는, 이러한 피상적 과장을 넘어 보다 객관적이고 올바로 인공지능 기술을 바라보아야 한다. 인공지능이 의학/의료에 도움을 주는 방향으로 개발 도입되기 위해서는 의료인들의 적극적인 관심과 참여를 통한 방향 제시가 필요하다. 이를 위해, 의료인들은 인공지능 기술에 대한 기본 지식, 의료인공지능 기술의 올바른 임상검증 방법론, 그리고 의료 발전에 있어 인공지능 기술의 역할과 한계에 대한 폭넓은 시각을 습득하여야 한다. 이 논문은 인공지능을 잘 모르는 의료인들에게 이러한 내용에 대해 설명하고 공부에 도움이 되는 유용한 논문들과 인터넷 자료들을 소개하고자 한다.","Artificial intelligence is expected to influence clinical practice substantially in the foreseeable future. Despite all the excitement around the technology, it cannot be denied that the application of artificial intelligence in medicine is overhyped. In fact, artificial intelligence for medicine is presently in its infancy, and very few are currently in clinical use. To best leverage the potential of this technology to improve patient care, clinicians need to see beyond the hype, as the guidance and leadership of medical professionals are critical in this matter. To this end, medical professionals must understand the underlying technological basics of artificial intelligence, as well as the methodologies of its proper clinical validation. They should also have an impartial, complete view of the capabilities, pitfalls, and limitations of the technology and its use in healthcare. The present article provides succinct explanations of these matters and suggests further reading materials (peer-reviewed articles and web pages) for medical professionals who are unfamiliar with artificial intelligence."
딥 러닝 알고리즘을 활용한 뇌파 분석 기반 졸음운전 사고예방 시스템,2018,"['EEG', 'Deep learning', 'Drowsiness measurement', 'Brain Machine Interface']",,
적대적 데이터를 이용한 기계학습 기반의 악성코드 분류기 공격,2018,"['Malware Classifier', 'Machine Learning', 'Black-box Attack', 'Convolutional Neural Network', 'Vulnerability Analysis']",,
인공지능 생성 증거와 전문법칙,2018,"['Artificial Intelligence', 'Machine generated evidence', 'Algorithm', 'Machine Learning', 'Hearsay rule', 'Confrontation right', 'Cross-Examination', '인공지능', '기계적 증거', '알고리즘', '머신러닝', '전문법칙', '당사자 대면권', '반대신문']","반대신문권의 보장이 중요한 것은 이러한 반대신문권의 행사를 통해 증언의 신빙성을 검증할 수 있기 때문이다. 반대신문권의 보장이 이루어지지 않는 증거에 대하여 증거능력 자체를 배제하는 이유도 결국 신뢰성과 관련이 있다. 따라서 신뢰성이 보장되는 예외적 상황이고 필요성이 있는 증거라면 설사 그 증거에 대한 반대신문이 행하여지지 않더라도 증거능력이 부여된다. 당사자 대면권 자체는 미 수정헌법 제6조에서 보장하는 일종의 권리로서 이러한 당사자 대면권이 보장이 되면, 당연히 그 과정에서 반대신문이 행하여진다. 당사자 대면권은 단지 증인의 얼굴을 마주하는 것에 그치지 않는다. 그 대면과정에서 이루어지는 반대신문권의 행사가 실질적 이유이고, 그러한 반대신문이 가혹할 정도로 엄격하게 이루어지는 과정을 통해 증언의 신빙성 검증이 이루어진다.미 연방대법원은 어느 순간부터 이러한 당사자 대면권 권리 자체에 주목하기 시작했고, 그에 따라 반대신문에 대하여는 별반 주목하지 않는 쪽으로 태도를 변경하였다. 그러나 당사자 대면권과 반대신문권은 표리관계로서 불가분의 강한 결합관계에 있어, 비록 반대신문권 자체에 주목하지 않더라도 당사자 대면권이 철저하게 보장되면 저절로 반대신문권이 보장되고, 나아가 증거의 신뢰성까지 주어지는 것은 자연스런 귀결이다.그러나 인공지능 알고리즘 생성 증거 등 기계적 증거의 등장은 이러한 도식이 깨어질 정도로 증거 생태계에 변화를 가져왔다. 당사자 대면권 보장이나 반대신문권 보장이 더 이상 신뢰성을 담보하지 않게 되는 사태가 벌어지게 되었다. 인공지능 생성 증거 등 기계적 증거가 당사자 대면권이 보장되는 증거 부류에 속하는지에 대하여 미국에서 꽤 많은 연구가 이루어졌다. 특히 Crawford vs. California 사건에서 증언적(testimonial)이라는 기준을 세운 이후 기계적 증거도 증언적 증거로서 당사자 대면권의 대상이 되는지에 대하여 다양한 논의가 전개되고 있다. 그러나 이러한 기계적 증거가 당사자 대면권의 대상이 되는 증거인데도 당사자 대면권 보장이 이루어지지 아니하는 경우, 증거능력을 부여하지 않을 것인지에 대하여 기계적 증거가 증언인가 하는 분류체계의 타당성을 넘어, 기계적 증거에 대하여 당사자 대면권의 실질적 보장이 가능한지부터 그 실효성의 문제까지 다양한 쟁점이 생겨난다. 이런 부분은 결국 기계적 증거에 대하여는 당사자대면권이나 반대신문권 보장만으로는 그 증거의 신뢰성 검증이 어렵다는 점과 직결된 문제로, 증거의 신뢰성 검증은 기존의 당사자 대면권 보장 또는 반대신문권의 보장이라는 프레임으로 해결되지 않고, 새로운 형태의 검증 방법이 필요하다는 것은 명백하다. 당사자주의를 근간으로 하여, 소송상 당사자의 각종 권리를 두텁게 보호함으로써 해결되는 구조가 아닌, 신뢰성 여부에 대한 체계적이고 신뢰성 있는 검증을 해낼 독자적 기구가 필요하다.","Ensuring cross-examination is important. This is because the testimony of the testimony can be verified through the cross-examination. The reason for excluding evidence that cross-examination is not guaranteed is also due to reliability. Therefore, if the evidence is in an exceptional situation that guarantees credibility and is necessary, that evidence will be given even if there is no cross-examination. Confrontation right is a kind of right guaranteed by Article 6 of the US Constitution. When confrontation right is guaranteed, cross-examination are made. Confrontation right does not stop just facing the witness' face. During the face-to-face meeting, the testimony of the testimony is verified through a process in which the cross-examination are rigorously executed.The US Supreme Court has changed its attitude toward confrontation right from the crawford case in 2004 to not pay much attention to cross-examination. However, the confrontation right and the cross-examination are inseparable and in strong relationship, and even if we do not pay attention to the cross-examination itself, cross-examination right is guaranteed if the confrontation right is thoroughly guaranteed.However, the emergence of mechanical evidence, such as the evidence of artificial intelligence algorithms, has changed the evidence ecosystem to the point where it can not be protected by the confrontation right. Even if confrontation right guarantees or cross-examination guarantees are made, it is difficult to give credibility any longer.Much research has been done in the United States on whether mechanical evidence, such as artificial intelligence generated evidence, falls within the category of evidence of confrontation right. Especially from Crawford vs. California case, there have been various discussions as to whether mechanical evidence is subject to confrontation right. However, there is controversy as to whether this mechanical evidence is the evidence of confrontation right, and if the guarantee is not made, the evidence was not admissible. The reason is that there is a question whether mechanical evidence is a testimony, and whether it is possible to guarantee confrontation right against mechanical evidence. This is directly related to the fact that confrontation right or cross-examination guarantees the reliability of the evidence for mechanical evidence. Verification of the reliability of the evidence is not resolved by the frame of guaranteeing the existing the confrontation right or cross-examination. So a new type of verification method is needed. There is a need for a exclusive mechanism for systematic and reliable verification of reliability."
멀티미디어 및 언어적 특성을 활용한 크라우드펀딩캠페인의 성공 여부 예측,2018,"['Crowdfunding', 'Kickstarter', 'Machine Learning', 'Deep Learning', 'Success Prediction']",,"Crowdfunding has seen an enormous rise, becoming a new alternative funding source for emerging startup companies in recent years. Despite the huge success of crowdfunding, it has been reported that only around 40% of crowdfunding campaigns successfully raise the desired goal amount. The purpose of this study is to investigate key factors influencing successful fundraising on crowdfunding platforms. To this end, we mainly focus on contents of project campaigns, particularly their linguistic cues as well as multiple features extracted from project information and multimedia contents. We reveal which of these features are useful for predicting success of crowdfunding campaigns, and then build a predictive model based on those selected features. Our experimental results demonstrate that the built model predicts the success or failure of a crowdfunding campaign with 86.15% accuracy."
Estimation of greenhouse CO2 concentration via an artificial neural network that uses environmental factors,2018,"['Black box modeling', 'Machine learning', 'Mango', 'Solar radiation', 'Temperature']",,"In order to improve photosynthesis efficiency and crop growth, it is important to predict CO2concentration as well as CO2consumption in greenhouses. The objective of this study was to predict greenhouse CO2concentration via an artificial neuralnetwork (ANN) that incorporated environmental factors. Temperature, relative humidity, atmospheric pressure, solar radiation,and CO2concentration were measured every 10 min over a 6-month period in a greenhouse located in Boryeong, Korea.Measured environmental data were used to train the ANN. Among the 14,866 data points used in the experiment, 10,000and 4866 data points were used for training and testing, respectively. An ANN with an input layer with input neurons, twohidden layers with 32–2048 neurons, and an output later with one neuron was selected. A rectified linear unit was used asthe activation function in each node of the ANN. An ANN structure that included 256 neurons in the hidden layers showedthe highest test accuracy (R2 = 0.97) was selected from all the structures, while multivariate linear regression showed lowertest accuracy than the ANN (R2 = 0.78). The ANN accurately estimated CO2concentration in the greenhouse using big datafor changing patterns of the inside environmental factors without vent position data. Furthermore, it is possible to estimatecrop CO2consumption in greenhouses with this ANN using the change in greenhouse CO2concentration."
웨어러블 동작센서와 인공지능 학습모델 기반에서 행동인지의 개선,2018,"['Motion Sensor', 'Activity Recognition', 'Machine Learning Model', 'Smart Lifecare']",,
서울 치킨집 폐업 예측 모형 개발 연구,2018,"['Entrepreneurship', 'Restaurant', 'Survival', 'Machine Learning', 'Predictive Model', '자영업', '치킨집', '폐업', '예측 모형', '기계학습']","대한민국에서 치킨집은 전 세계 맥도날드 매장 수보다 많을 정도로 자영업의 큰 비중을 차지하는 창업 업종이다. 치킨집은 꾸준히 생겨나고 있지만, 소상공인의 창업 후 폐업률은 3년 62%, 5년 71%에 육박하는 것으로 나타났다. 특히, 숙박 및 음식점의 경우 70%가 3년을, 82%가 5년을 버티지 못하는 것으로 집계되었다. 이에 본 연구는 ‘서울 치킨집 폐업 예측 모형’을 개발하여, 예비창업자가 개업 후보지를 선정하는 의사결정 과정에 도움을 주고자 하였다. 먼저 행정자치부 지방행정 인허가 데이터의 업소별 개·폐업 신고 일자를 중심으로 다양한 변수를 수집하였다. 이후 다양한 분류 알고리즘을 적용하고, 예측 모형의 성능을 비교하였다. 그 결과, 인공신경망(Neural Networks)이 가장 높은 정확도를 보였지만 특이도와 민감도가 불균형적이었다. 이에 비해 유연판별분석(FDA)은 인공신경망보다 정확도는 낮지만, 상대적으로 균형적인 예측 성능을 보였다.",
4차 산업혁명에 따른 시장요구 변화와 한국 표면처리 산업의 발전방향에 대한 연구,2018,"['The Fourth Industrial Revolution', 'Machine Learning', 'Customering', 'Glocalization']",,"This paper examines various definitions of the fourth industrial revolution and its influence on typical market demands and manufacturing methods. And this study reviewed the policies of the major global competitors in preparedness for the fourth industrial revolution. In conclusion, this paper suggested various possible developing ways in which Korean companies, especially focused on surface treatment firms, could adapt and survive in such a revolutionary industrial circumstance change."
드론 활용 목표물 추적 응용에서의 인공지능 작업 실행 효율 비교 분석,2018,"['drone', 'target tracking', 'machine learning', 'cloud']",,
CNN Model to Classify Malware Using Image Feature,2018,"['악성코드', '악성코드분류', 'CNN', '머신러닝', 'malware', 'malware classification', 'convolutional neural network', 'machine learning']","인터넷에 발생하는 악성코드는 매우 심각한 위협 요소이며, 악성코드를 이용한 공격이 전 세계적으로 전파되며 심지어 점점 더 지능적으로 변조되고 있다. 그러므로 악성코드를 정확하게 탐지 하는 방법이 중요하다. 지금까지 널리 알려진 악성코드 대응방법은 악성코드를 탐지하여 삭제하거나 혹은 치료한다고 알고 있다. 이러한 악성코드를 탐지하기 위하여 악성코드에 따른 분류를 하여야 한다. 악성코드를 잘 분류하는 것은 알려진 악성코드를 더 잘 탐지할 수 있다는 것과 같다. 기존 연구들을 보면 같은 카테고리에 속하는 악성코드는 치료방법이 비슷하게 보이는 경향이 있다는 것을 입증한다. 그리고 많은 새로운 악성코드들이 기존에 있던 악성코드로부터 만들어진다는 것을 증명한다. 따라서 악성코드를 종류에 따라서 분류하는 것은 탐지하는 것 못지않게 아주 중요한 작업이다. 그러므로 멀웨어 분류 기술이 절실히 요구된다. 본 논문에서는 주어진 종류에 따라 악성코드를 분류하기 위한 컨볼루션 인공신경망 모델을 구축한다. 이 모델은 9,500 개의 악성코드 데이터 셋을 25 개의 종류로 분류하는 실험에서 98%의 정확도를 보인다. 본 연구의 목적은 다음 목표로 더 많은 양의 악성코드 파일에 적용되며 더 높은 정확도를 보이는 것이다.","Malware programs are common threats in the information and technology society. It has been proven that a number of developed malwares cripples the victim’s computer as well as launching malicious attacks. Therefore, it is important to find a reasonable technical way to counter these attacks. Malware can be easily detected by checking whether a file has a malicious code inside the source code, if you detect a malicious code inside your content, then take an appropriate action by eliminating the threat. The first countermeasure to take is to delete the file or follow any other action defined by an Anti-malware software. After a file is infected, means it can be classified to its corresponding family based on its behavior in the infected system.. In this paper, we use Convolutional Neural Network to classify malware binaries using image features. Our work relies on the previously conducted research on malware visualization, whereby we used the dataset consisted of about 9,500 samples of 25 different malware familys. The built architecture achieved an accuracy of 98%."
Enhanced technique for Arabic handwriting recognition using deep belief network and a morphological algorithm for solving ligature segmentation,2018,"['deep belief networks', 'deep learning', 'ligatures', 'morphology', 'restricted Boltzmann machine']",,"Arabic handwriting segmentation and recognition is an area of research that has not yet been fully understood. Dealing with Arabic ligature segmentation, where the Arabic characters are connected and unconstrained naturally, is one of the fundamental problems when dealing with the Arabic script. Arabic character‐recognition techniques consider ligatures as new classes in addition to the classes of the Arabic characters. This paper introduces an enhanced technique for Arabic handwriting recognition using the deep belief network (DBN) and a new morphological algorithm for ligature segmentation. There are two main stages for the implementation of this technique. The first stage involves an enhanced technique of the Sari segmentation algorithm, where a new ligature segmentation algorithm is developed. The second stage involves the Arabic character recognition using DBNs and support vector machines (SVMs). The two stages are tested on the IFN/ENIT and HACDB databases, and the results obtained proved the effectiveness of the proposed algorithm compared with other existing systems."
발전량 예측 모델 기반의 태양광 모니터링 시스템 고장 예측,2018,"['Photovoltaic monitoring system', 'machine learning', 'regression', 'predict', 'neural network']",,
기계학습을 활용한 항공기 연료 시스템 무결성 감시,2018,"['aircraft fuel system', 'machine learning', 'neural networks', 'levenberg-marquadt method']",,
접근 기록 분석 기반 적응형 이상 이동 탐지 방법론,2018,"['Physical Security', 'Anomaly Behavior', 'Machine Learning', 'Access Logs', 'Adaptive Framework']","데이터의 활용도와 중요성이 점차 높아짐에 따라 데이터와 관련된 사고와 피해는 점점 증가 하고 있으며, 특히 내부자에 의 한 사고는 그 위험성이 더 높다. 이런 내부자의 공격은 전통적인 보안 시스템으로 방어하기 힘들어, 규칙 기반의 이상 행동 탐 지 방법이 널리 활용되어오고 있다. 하지만, 새로운 공격 방식 및 새로운 환경과 같이 변화에 유연하게 적응하지 못하는 문제 점을 가지고 있다. 본 논문에서는 이에 대한 해결책으로서 통계적 마르코프 모델 기반의 적응형 이상 이동 탐지 프레임워크를 제안하고자 한다. 이 프레임워크는 사람의 이동에 초점을 맞추어 내부자에 의한 위험을 사전에 탐지한다. 이동에 직접적으로 영향을 주는 환경 요소와 지속적인 통계 학습을 통해 변화하는 환경에 적응함으로써 오탐지와 미탐지를 최소화하도록 설계 되었다. 프레임워크를 활용한 실험에서는 0.92의 높은 F2-점수를 얻을 수 있었으며, 나아가 정상으로 보여지지만, 의심해볼 이 동까지 발견할 수 있었다. 통계 학습과 환경 요소를 바탕으로 행동과 관련된 데이터와 모델링 알고리즘을 다양화 시켜 적용한 다면 보다 더 범위 넓은 비정상 행위에 대해 탐지할 수 있는 확장성을 제공한다.","As data utilization and importance becomes important, data-related accidents and damages are gradually increasing. Esp ecially, insider threats are the most harmful threats. And these insider threats are difficult to detect by traditional security systems, so rule-based abnormal behavior detection method has been widely used. However, it has a lack of adapting fle xibly to changes in new attacks and new environments. Therefore, in this paper, we propose an adaptive anomaly movem ent detection framework based on a statistical Markov model to detect insider threats in advance. This is designed to mini mize false positive rate and false negative rate by adopting environment factors that directly influence the behavior, and le arning data based on statistical Markov model. In the experimentation, the framework shows good performance with a hig h F2-score of 0.92 and suspicious behavior detection, which seen as a normal behavior usually. It is also extendable to det ect various types of suspicious activities by applying multiple modeling algorithms based on statistical learning and enviro nment factors."
Disease risk prediction system using correlated health indexes,2018,"['Database', 'Chronic disease', 'Machine learning', 'Self-symptom checker', 'Bioinformatics']",,"With developments in science and technology and improvement in living standards, human life expectancy is steadily increasing worldwide. For effective healthcare, it is necessary to check health conditions according to individuals' behavior and acquire prior knowledge on possible diseases. In this study, we classified the diseases that are major causes of death in Korea by referring to data provided by the Korea National Health and Nutrition Examination Survey. We selected indexes that could be used as indicators of major diseases and created the LCBB-SC. In the LCBB-SC, the data are systematically subdivided into related fields to provide integrated data related to each disease and to provide an infrastructure that can be used by researchers. In addition, by developing a web interface allowing for self-symptom assessments, this resource will be beneficial to people who want to check their own health condition using a list of diseases that might be caused by their behaviors."
SRGAN 기반의 CCTV 영상 화질 개선 기법,2018,"['CCTV', 'SRGAN', 'Video Quality', 'Machine Learning', 'Performance Evaluation']",,
활성화 함수의 근사화를 통한 MLP 가속기 구현,2018,"['Sigmoid function', 'PLAN', 'Machine Learning', 'MLP', 'ANN']",본 논문에서는 하드웨어레벨로 구현이 어렵고 속도가 느린 sigmoid 함수를 PLAN을 이용하여 근사치로 출력하였다. 이를 MLP 구조의 활성화 함수로 사용하여 자원소모를 줄이고 속도를 개선하고자 하였다. 본 논문에서 제안하는 방법은 5x5크기의 숫자 인식에 약 95%의 정확도를 유지하면서 GPGPU보다  약 1.83배의 빠른 속도를 보였다.  또한 MLPA가속기와 비슷한 자원을 사용함에도 더 많은 뉴런을 사용하여 높은 정확도에 빠른 속도로 수렴하는 것을  확인하였다.,"In this paper, sigmoid function, which is difficult to implement at hardware level and has a slow speed, is approximated by using PLAN. We use this as an activation function of MLP structure to reduce resource consumption and speed up. In this paper, we show that the proposed method maintains 95% accuracy in 5x5 size recognition and 1.83 times faster than GPGPU. We have found that even with similar resources as MLPA accelerators, we use more neurons and converge at higher accuracy and higher speed."
Disease risk prediction system using correlated health indexes,2018,"['Database', 'Chronic disease', 'Machine learning', 'Self-symptom checker', 'Bioinformatics']",,"With developments in science and technology and improvement in living standards, human life expectancy is steadily increasing worldwide. For effective healthcare, it is necessary to check health conditions according to individuals’ behavior and acquire prior knowledge on possible diseases. In this study, we classified the diseases that are major causes of death in Korea by referring to data provided by the Korea National Health and Nutrition Examination Survey. We selected indexes that could be used as indicators of major diseases and created the LCBB-SC. In the LCBB-SC, the data are systematically subdivided into related fields to provide integrated data related to each disease and to provide an infrastructure that can be used by researchers. In addition, by developing a web interface allowing for self-symptom assessments, this resource will be beneficial to people who want to check their own health condition using a list of diseases that might be caused by their behaviors."
AN OPTIMAL BOOSTING ALGORITHM BASED ON NONLINEAR CONJUGATE GRADIENT METHOD,2018,"['convex programming', 'boosting', 'machine learning', 'convergence analysis.']",,"Boosting, one of the most successful algorithms for supervised learning, searches the most accurate weighted sum of weak classiﬁers. The search corresponds to a convex programming with non-negativity and afﬁne constraint. In this article, we propose a novel Conjugate Gradient algorithm with the Modiﬁed Polak-Ribiera-Polyak conjugate direction. The convergence of the algorithm is proved and we report its successful applications to boosting."
EOG 신호를 활용한 체스게임 제어,2018,"['전기안구법', '특징 분류', '머신러닝', '지도학습', '신호처리', '인간 컴퓨터 인터페이스', 'electrooculogram', 'feature classification', 'machine learning', 'supervised learning', 'signal processing', 'human-computer interface']","전신마비 환자, 루게릭병 환자 등 신체를 자유자재로 움직이지 못하는 사람에게 눈 동작은 자율적으로 사용할 수 있는 몇 되지 않는 신체의 일부이다. 이러한 이유로, 사람의 눈 동작 분석에 사용되는 전기안구법(EOG, Electrooculogram)신호는 신체가 불편한 사람들의 각종 기기제어를 돕기 위해 다방면으로 활용된다. 본 논문에서는 망막의 전위를 측정하는 전기안구법 신호를 활용한 눈 깜빡임 검출 알고리즘을 제안한다. 본 연구는 또한 이 논문에서 서술한 눈 깜빡임 검출방법을 활용하여 좌측 눈 깜빡임과 우측 눈 깜빡임, 양측 눈 깜빡임과 눈 뜬 상태를 분류하고, 이를 체스게임 제어에 도입하여 알고리즘의 정확도를 측정한다. 본 논문에서 제시한 눈 깜빡임 검출 방법을 기반으로 환자들이 게임 콘텐츠를 적극적으로 활용할 수 있는 계기가 만들어질 것으로 기대된다.","For patients who are unable to move freely, such as patients with generalized paralysis or Lou Gehrig’s disease, eye movement is one of the few remaining parts of the body available to control. EOG(Electrooculogram) signal processing, a method used to analyze the movement of human eye, is often applied to support patients to control various devices. In this paper, we propose an eye blink detection method using EOG, which measures the electric potential derived from the retina. The purpose of the proposed method in this study is to classify the blinking state of left and right eyes, and is implemented into chess game control to verify its accuracy. It is anticipated that more opportunities would be provided to patients in the area of game contents based on the eye-blink detection method presented in this paper."
멀티스케일 및 심층 특징 추출 기반의 가로수종 및 상태 인식,2018,"['Deep Feature', 'Deep Learning', 'Fisher Vector', 'Sparse Coding', 'Gaussian Mixture Model']",,
Predictive Analysis of Financial Fraud Detection using Azure and Spark ML,2018,"['Fraud Detection', 'Spark', 'Azure', 'Machine Learning', 'Hadoop', 'Big Data']",,
기술력 평가항목을 이용한 고안정성 중소기업 판별력 검증,2018,"['Technology Financing', 'Technology Appraisal', 'Machine Learning', 'Decision Tree', 'High-stability Firms', '기술금융', '기술력 평가', '기계학습', '의사결정나무모형', '고안정성 기업']","본 연구는 기술력 평가항목 중 기업의 재무안정성과 관련된 항목을 신용평가모형에 반영하여 중소기업뿐만이 아닌 전체 기업을 대상으로 한 신용평가모형의 부도변별력을 높이기 위한 기술력 평가모형의 신용평가모형 내 내재화에 착안하여 시작되었다. 따라서 기술력 평가모형이 부채비율 기준의 고안정성 중소기업을 사전에 판별하는 데 적용될 수 있는지 검증하는 것을 목표로 한다. 대상 기업을 업종(제조업 vs. 非제조업)과 업력(창업기업 vs. 非창업기업)으로 구분하고, 3개년 동안 해당 군집의 평균 부채비율 1/2 이하를 달성한 기업에 대해 고안정성 중소기업으로 정의한 후, C5.0 기법을 적용하여 모형의 판별력을 검증하였다. 분석결과 소항목 수준에서는 업종과 업력에 따라 중요도 간 차이가 있지만, 중항목 수준에서는 기술개발역량이 고안정성 중소기업을 판별하는 중요변수로 도출되었으며, 기업의 업력에 따라 창업 초기에는 자금조달능력(수익창출능력을 고려한 자본구조, 자본비용 및 자금조달 방법의 다양성)이 미래 고안정성 중소기업 여부를 결정하는 중요변수이지만, 업력이 증가함에 따라 지속적인 성과를 가능하게 하는 기술개발 인프라가 재무안정성에 영향을 미치는 중요변수로 변화한다는 결론을 도출하였다. 업종과 업력에 따른 모형의 분류 정확도는 71~91% 수준이며, 기술력 평가항목을 이용하여 고안정성 중소기업을 판별할 수 있다는 가능성을 확인하였다.",
Short-term Predictive Models for Influenza-like Illness in Korea : Using Weekly ILI Surveillance Data and Web Search Queries,2018,"['한국', '인플루엔자 의사환자', '예측모형', '머신러닝', '웹 검색 정보', 'Korea', 'Influenza-like Illness', 'Predictive Model', 'Machine Learning', 'Web Search Data']",,
Convolutional Neural Network를 이용한 웹 어플리케이션 공격 탐지 기법,2018,"['convolutional neural network', 'supervised learning', 'SQL injection', 'cross site scripting', 'web application', '컨볼루션 신경망', '지도학습', 'SQL 인젝션', '크로스 사이트 스크립팅', '웹 어플리케이션']","웹 어플리케이션 공격이 급격하게 늘면서 기존의 기법들만으로는 이를 탐지하는 것이 한계가있어, 기계학습 기반의 탐지 기법이 연구되기 시작하였다. 기계학습을 활용한 기존 기법은 공격 탐지를 위해 적절한 특징(feature)을 선정해야 하는 어려움이 있으며, 새로운 공격 패턴이 등장할 경우 이에 적합하도록 특징을 재선정해야 할 경우도 발생한다. 본 논문에서는 HTTP 트래픽을 구성하는 입력이 허용되는 문자에 대한 제한 없이 문자 단위로 16진수 변환한 후 이미지화하고, 이를 입력으로 하는 convolutional neural network을 통해 웹 어플리케이션 공격을 탐지하는 기법을 제안한다. 제안 기법은 별도의 특징 선정 없이 지도학습을 통해 이미지화 된 HTTP 트래픽을 학습하며, 기존의 기계학습 기법보다 최대 84.4% 까지 공격 탐지 오류율 성능을 향상할 수 있음을 보였다.","Because rates of web application attacks are rapidly increasing, web application attack detection schemes using machine learning have recently become of interest. Existing schemes, however, require the selection of a suitable set of features representing the characteristics of expected attacks, and this set of features needs to be adjusted every time a new type of attack is discovered.In this paper, we propose a web application attack detection scheme employing a convolutional neural network (CNN) without the need to select any features in advance. Specifically, the CNN is trained in a supervised manner with images transformed from hexadecimally converted characters in HTTP traffic, without any restriction in the input characters used. Our experimental results show that the proposed scheme improves detection error rate performance by up to 84.4% over existing schemes."
Short-term Predictive Models for Influenza-like Illness in Korea:Using Weekly ILI Surveillance Data and Web Search Queries,2018,"['한국', '인플루엔자 의사환자', '예측모형', '머신러닝', '웹 검색 정보', 'Korea', 'Influenza-like Illness', 'Predictive Model', 'Machine Learning', 'Web Search Data']",,"Since Google launched a prediction service for influenza-like illness(ILI), studies on ILI prediction based on web search data have proliferated worldwide. In this regard, this study aims to build short-term predictive models for ILI in Korea using ILI and web search data and measure the performance of the said models. In these proposed ILI predictive models specific to Korea, ILI surveillance data of Korea CDC and Korean web search data of Google and Naver were used along with the ARIMA model. Model 1 used only ILI data. Models 2 and 3 added Google and Naver search data to the data of Model 1, respectively. Model 4 included a common query used in Models 2 and 3 in addition to the data used in Model 1. In the training period, the goodness of fit of all predictive models was higher than 95% (R2). In predictive periods 1 and 2, Model 1 yielded the best predictions (99.98% and 96.94%, respectively). Models 3(a), 4(b), and 4(c) achieved stable predictability higher than 90% in all predictive periods, but their performances were not better than that of Model 1. The proposed models that yielded accurate and stable predictions can be applied to early warning systems for the influenza pandemic in Korea, with supplementary studies on improving their performance."
XGBoost 모델 해석을 통한 노인의 인지능력 개선·악화 요인 탐,2018,"['XGBoost', 'the elderly', 'cognitive changes', 'machine learning', 'XGBoost', '노인', '인지개선', '인지악화', '기계학습']","본 연구는 의사결정나무 알고리즘 하나인 Extreme Gradient Boosting(XGBoost)을 활용하여 노인의 인지기 능 측 모델을 만들고 이를 바탕으로 인지능력 개선⋅악화 요인을 탐색하는 것을 목표로 한다. 2008년부터 2016 년까지 격년으로 시행된 고령화연구패조사(KLoSA)에서 인지능력이 변화한 패의 데이터가 연구에 사용되었다. XGBoost의 XGBoost Feature Importance 모듈과 XGBoostExplainer 패키지를 용하여 인지능력 개선, 악 화 요인을 탐색했다. 연구 결과 인지능력 개선⋅악화를 가르는 주요인은 도구 일상생활 수행 능력(IADL), 우울 감, 소득, 친한 사람과의 교류다. 우울감이 악화될 때, 우울감이 인지능력 악화 요인으로 강하게 작용하는 것으로 나타났다. 하지만 우울감 개선에 비례하여 우울감이 인지능력의 개선 요인으로 작용하는 계는 약하게 나타났다.","The purpose of this study is to build an elderly cognitive change predictive model and, as a result, to identify potential factors which lead to cognition improvement or deterioration using Extreme Gradient Boosting (XGBoost). Korean Longitudinal Study of Aging (KLoSA) conducted biennially from 2008 to 2016 was used as a dataset. Particularly, the XGBoost Feature Importance module and XGBoost Explainer package were used to explain elderly cognitive changes. The main findings of this study indicate that instrumental activities of daily living (IADL), depression, income, and interactions with close friends are potential improvement and/or deteriorating factors. Furthermore, when the depression level is exacerbated, depression was found to strongly influence as a factor of cognitive deterioration. However, in proportion to the improvement of depression, the relationship between depression and cognitive abilities is seemingly weak."
선형 강도 교정을 이용한 라만 스펙트럼 인식,2018,"['Chemical identification', 'Linear intensity calibration', 'Machine learning', 'Pattern recognition', 'Raman spectroscopy']","라만 스펙트럼은 측정 장비 및 환경 조건에 따라 동일한 물질이라도 스펙트럼의 강도 차이를 보인다. 이는 라만분광의 패턴 인식적인 접근에 제약을 주기 때문에 장비간의 호환성 및 라만 데이터베이스의 재사용을 위해 반드시 해결해야 하는 문제다. 이를 위해 이전의 주요 연구들에서는 측정 장비 간에 전달 함수를 가정하고 이를 구한 후 직접적인 스펙트럼의 교정을 수행하였다. 하지만 이 방식은 강도 왜곡을 발생시키는 다른 조건들에 대해서는 대처 할 수 없는 방법이다. 따라서 본 논문에서는 다양한 측정 조건에 보다 유연하게 대응 할 수 있는 선형 강도 교정을 이용한 분류 방법을 제안하였다. 제안한 방법의 성능 평가를 위해 실험에서는 14033종의 화학 물질에서 측정된 라만 라이브러리를 실험물질에 대한 판별 지표로 사용하였으며, 3개의 라만 분광기로부터 측정된 10종의 화학 물질 라만 스펙트럼을 실험 데이터로 사용하였다. 실험결과에 따르면 제안한 방법을 사용하였을 때 강도 왜곡된 스펙트럼에 대해 100%의 판별 성능을 보였으며, 판별된 스펙트럼에 대해서도 이전보다 높은 상관점수를 보여 사용자가 화학 물질을 판별하는 데 유용한 도구로 사용될 수 있음을 확인하였다.","Raman spectra exhibit differences in intensity depending on the measuring equipment and environmental conditions even for the same material. This restricts the pattern recognition approach of Raman spectroscopy and is an issue that must be solved for the sake of its practical application, so as to enable the reusability of the Raman database and interoperability between Raman devices. To this end, previous studies assumed the existence of a transfer function between the measurement devices to obtain a direct spectral correction. However, this method cannot cope with other conditions that cause various intensity distortions. Therefore, we propose a classification method using linear intensity calibration which can deal with various measurement conditions more flexibly. In order to evaluate the performance of the proposed method, a Raman library containing 14033 chemical substances was used for identification. Ten kinds of chemical Raman spectra measured using three different Raman spectroscopes were used as the experimental data. The experimental results show that the proposed method achieves 100% discrimination performance against the intensity-distorted spectra and shows a high correlation score for the identified material, thus making it a useful tool for the identification of chemical substances."
추천시스템에 활용되는 Matrix Factorization 중 FM과 HOFM의 비교,2018,"['행렬분해', '고차원 행렬분해', '희소행렬', 'Factorization Machines Learning', 'High-Order Factorization Machines Learning']",,
인공신경망을 이용한 KOMPSAT-3/3A/5 영상으로부터 자연림과 인공림의 분류,2018,"['Artificial Forest', 'Natural Forest', 'Forest Survey', 'Kompsat', 'Machine Learning', 'Artificial Neural Network', 'WEKA']","자연림은 산림의 조성 과 보육 등에 인공적인 사람의 힘이 가해지지 않은 자연 상태의 산림이다. 반면 인공림은 사람이 조성 및 보육관리 하는 숲으로 목재생산, 자연재해 예방, 방풍 등의 목적을 가지는 산림이다. 인공림은 목재생산 등 인간이 목적을 가지고 관리하여 단위 면적당 더 많은 목재를 생산할 수 있는 경제적 장점도 가지고 있다. 자연림과 인공림의 구분은 산림 형태의 관리 방법과 목정이 상이하여 산림조사에서 기본적으로 조사하는 요소이며, 자연림과 인공림의 구분은 항공사진 판독과 현지조사 등의 절차를 통해 이루어진다. 본 연구에서는 자연림과 인공림의 분류에 KOMPSAT-3, 3A, 5 위성 영상데이터에 인공신경망(Artificial Neural Network: ANN)을 적용하여 자연림과 인공림의 분류도를 만들고, 산림청의 1/5,000임상도의 자연림과 인공림 분류도와 비교하여 평가하였다. 인공신경망을 이용한 산림의 자연림과 인공림 구분의 연구를 진행한 결과, 1/5,000 임상도와 비교했을 때, 학습결과 분류 전체 정확도는 77.03%이다. 영상의 획득 시기와 산림의 침엽수와 활엽수 등 기타요인이 인공신경망을 이용한 산림의 인공림과 자연림의 구분에 많은 영향을 미치는 것을 확인하였다.","Natural forests are un-manned forests where the artificial forces of people are not applied to the formation of forests. On the other hand, artificial forests are managed by people for their own purposes such as producing wood, preventing natural disasters, and protecting wind. The artificial forests enable us to enhance economical benefits of producing more wood per unit area because it is well-maintained with the purpose of the production of wood. The distinction surveys have been performed due to different management methods according to forests. The distinction survey between natural forests and artificial forests is traditionally performed via airborne remote sensing or in-situ surveys. In this study, we suggest a classification method of forest types using satellite imagery to reduce the time and cost of in-situ surveying. A classification map of natural forest and artificial forest were generated using KOMPSAT-3, 3A, 5 data by employing artificial neural network (ANN). And in order to validate the accuracy of classification, we utilized reference data from 1/5,000 stock map. As a result of the study on the classification of natural forest and plantation forest using artificial neural network, the overall accuracy of classification of learning result is 77.03% when compared with 1/5,000 stock map. It was confirmed that the acquisition time of the image and other factors such as needleleaf trees and broadleaf trees affect the distinction between artificial and natural forests using artificial neural networks."
AI 등을 활용한 사업자간 담합과 경쟁법의 대응,2018,"['알고리즘', '인공지능', '디지털 시대', '디지털 카르텔', '묵시적 담합', '합의', '시장의 투명성', '의식적 병행행위', '동조적 행위', 'Algorithm', 'Artificial Intelligence', 'Digital Age', 'Digital Cartel', 'Tacit Collusion', 'Agreement', 'Market Transparency', 'Parallel Behavior', 'Concerted Practice']",,"In the digital age, through machine learning, corporations have improved their ability to collect, restore, and analyze information on customers, competitors, and the market in general. Based on cumulative data, these corporations have highly sophisticated algorithms that can set prices of their goods and services.Due to the algorithms that can proceed data and conduct autonomous decision-making capability, it is crucial to collect data on consumers and competitors. Based on these algorithms, it is possible to monitor consumers and competitors, and to recognize changes of market situations in real time.On the one hand, algorithms bring positive effects in numerous cases. On the other hand, the prevalent use of algorithms can create a substantial risk in fair and efficient competition in the market. Recently, in this respect, the OECD and competition agencies of many jurisdictions have discussed the impact of algorithms’ automatic price setting on the competition in the market.Regarding the issue of algorithms’ automatic price-setting, an influential view is that the price-setting technology in itself does not constitute a violation of competition law. So far, a majority view seems to explain that consent among competing business entities is a required component for a violation of competition law. However, if computer algorithms become more developed and autonomous in the near future, a crucial question of competition law will lie concerning the meaning of consent among competing business entities. In this respect, it is a high time to consider whether core standards of the current competition law such as a business entity’s awareness should be maintained as the standards under the circumstances where technologies and machines are dominant in setting business strategies.Therefore, in carrying out competition policies, it is necessary for the judiciary and competition agencies in the government to consider and examine the interpretation of “consent” and “intent” in accordance with the current and future technology."
GuessWhat?! 문제에 대한 분석과 파훼,2018,"['대화 시스템', '이미지 질의 응답', 'GuessWhat?!', '인공지능 게임', 'dialogue system', 'visual question answering', 'GuessWhat?!', 'artificial intelligence game']","GuessWhat?!은 질문자와 답변자로 구성된 두 플레이어가 이미지를 보고 질문자에게 비밀로 감추어진 정답 물체에 대해 예/아니오/잘 모르겠음 셋 중 하나로 묻고 답하며, 정답 물체를 추려 나가는 문제이다. GuessWhat?!은 최근 컴퓨터 비전과 인공지능 대화 시스템의 테스트베드로서 컴퓨터 비전과 인공지능 학계의 많은 관심을 받았다. 본 논문에서, 우리는 GuessWhat?! 게임 프레임워크가 가지는 특성에 대해 논의한다. 더 나아가, 우리는 제안된 틀을 기반으로 GuessWhat?!의 간단한 solution을 제안한다. 사람이 평균 4～5개 정도의 질문을 통하여 맞추는 이 문제에 대하여, 우리가 제안한 방법은 2개의 질문만으로 기존 딥러닝 기반 기술의 성능을 상회하는 성능을 보이며, 5개의 질문이 허용되면 인간 수준의 성능을 능가한다.","GuessWhat?! is a game in which two machine players, composed of questioner and answerer, ask and answer yes-no-N/A questions about the object hidden for the answerer in the image, and the questioner chooses the correct object. GuessWhat?! has received much attention in the field of deep learning and artificial intelligence as a testbed for cutting-edge research on the interplay of computer vision and dialogue systems. In this study, we discuss the objective function and characteristics of the GuessWhat?! game. In addition, we propose a simple solver for GuessWhat?! using a simple rule-based algorithm. Although a human needs four or five questions on average to solve this problem, the proposed method outperforms state-of-the-art deep learning methods using only two questions, and exceeds human performance using five questions."
외국어교육에서 멀티리터러시 모델 적용에 관한 제안,2018,"['multiliteracy', 'artificial intelligence', 'ICT literacy', 'content literacy', 'machine translation', 'publishing', 'Content-Language Integrated Learning']",,"In this study, a multiliteracy model is proposed that can be applied to foreign language education in the era of artificial intelligence (AI), in which language-related technologies are rapidly developing. Artificial intelligence-based translation and interpretation technologies are lowering the threshold of foreign language use, and speech recognition (SR) technology and text-to-speech (TTS) technology break down the boundary between spoken language and written language. With such Information Communication Technology (ICT) literacy, therefore, foreign language literacy along with first language literacy tends to be integrated into multiliteracy. Besides, as our society has become specialized, the importance of content literacy of each specialized field is emphasized more and more. As a result, in foreign language education, a multiliteracy model is needed with Content-Language Integrated Learning (CLIL) methodology. With introducing a multiliteracy model, in this study, a translation course between first and foreign languages and a content course of book publishing are introduced as samples of the application of the multiliteracy model."
Scour depth evaluation of a bridge with a complex pier foundation,2018,"['scour', 'flood', 'complicated foundation', 'optimization', 'machine learning']",,"A scour depth prediction formula for a river bridge is established using experimental data in which the effects of the pier, pile-capand pile group are considered. More than 170 experimental data entries, including different pier structural sizes, flow depths and soilcovering depths, are collected and verified by existing formulae, which failed to deliver a promising prediction. A machine learningprediction model was then developed to enhance the accuracy. For application purpose, a sequential quadratic programmingoptimization was adopted to construct an explicit prediction formula. The MAPE was significantly improved from 102.8 to 28.9. Theresults indicate that the proposed formula can simultaneously satisfy the requirements of accuracy and simplicity. The proposedformula has the advantages of being conceptually consistent with observed scour behaviors and provides a solid scour depthprediction, which is an important and critical step in the bridge safety evaluation if floods are considered."
악성코드 패킹유형 자동분류 기술 연구,2018,"['Packing', 'Malware classification', 'Section name', 'Clustering', 'Deep Learning']","대부분의 침해공격은 악성코드를 통해 발생하고 있으며, 침해공격으로 인한 피해는 사물인터넷/사이버 물리 시스템과 연결되면서 사이버공간에만 국한되지 않고 실생활에 큰 위협이 되고 있다. 이에 따라, 다양한 악성코드 동적분석, 정적분석기술들이 연구되었는데, 악성코드 동적분석들은 결과적인 악성행위를 쉽게 확인할 수 있어 널리 사용되었으나 VM 환경탐지 시 동작하지 않는 anti-VM 악성코드가 증가하면서 어려움을 겪고 있고, 악성코드 정적분석 기술들은 코드자체를 해석할 수 있어 많은 정보를 얻을 수 있으나 난독화, 패킹 기술들이 적용되어 분석가를 어렵게 하고 있다. 본 논문에서는 정적분석기술의 주요 장애물인 난독화 유형을 자동식별, 분류하는 기술을 제안한다. 특히, 제안하는 모델을 통해 알려진 패커나 알려지지 않은 패커와 상관없이 일정한 기준에 의해 모든 악성코드를 분류할 수 있는 것이 가능하다. 악성코드 분류는 다양한 활용이 가능하지만, 예를 들면 악성코드 정적 feature에 기반하여 머신러닝 기반 분석을 할 때, 전체 파일에 대해 학습 및 분석하는 방식보다 악성코드 유형별 학습 및 분석이 더욱 효과적일 것이다. 이를 위해, PE구조에서 활용 가능한 feature에 대해 지도 학습 및 비지도 학습 방식의 모델을 설계했고, 98,000여개 샘플을 통해 결과 검증을 진행하였다.","Most of the cyber attacks are caused by malicious codes. The damage caused by cyber attacks are gradually expanded to IoT and CPS, which is not limited to cyberspace but a serious threat to real life. Accordingly, various malicious code analysis techniques have been appeared. Dynamic analysis have been widely used to easily identify the resulting malicious behavior, but are struggling with an increase in Anti-VM malware that is not working in VM environment detection. On the other hand, static analysis has difficulties in analysis due to various packing techniques. In this paper, we proposed malware classification techniques regardless of known packers or unknown packers through the proposed model. To do this, we designed a model of supervised learning and unsupervised learning for the features that can be used in the PE structure, and conducted the results verification through 98,000 samples. It is expected that accurate analysis will be possible through customized analysis technology for each class."
Fault diagnosis method of rolling bearing based on deep belief network,2018,"['Deep belief network', 'Fault diagnosis', 'Restricted Boltzmann machine', 'Rolling bearing']",,"A method based on the theory of deep learning and feature extraction and a fault diagnosis model of a rolling bearing based on deep belief network are proposed in this study considering the complex, nonlinear, and non-stationary vibration signal of the rolling bearing.To some extent, the method avoids the complex structure of deep neural network and can be easily trained. Experimental results show that the recognition rate of the method reaches 100 %. The method can identify various types of faults accurately and has good fault diagnosis capability, which can provide the convenience for maintenance."
DeepPIM: A deep neural point-of-interest imputation model,2018,"['Point-of-interest', 'POI imputation', 'Deep-learning', 'Social network']",,"<P><B>Abstract</B></P>  <P>A point-of-interest (POI) is a specific location in which someone is interested. In social network services such as Instagram, users share their experiences with text and photos, and link POIs to their posts. POIs can be utilized to understand user preferences and behavior. However, not all posts have POI information. In our study, we found more than half of the posts do not have POI information. The current state-of-the-art POI imputation model adds missing POI information. However, it relies on a conventional machine learning method that requires a substantial amount of laborious feature engineering. To address this problem, we propose DeepPIM, a deep neural POI imputation model that does not require feature engineering. DeepPIM automatically generates textual, visual, user, and temporal features from text, photo, user, and posting time information, respectively. For evaluating DeepPIM, we construct a new large-scale POI dataset. We show that DeepPIM significantly outperforms the current state-of-the-art model on the dataset. Our newly created large-scale POI dataset and the source code of DeepPIM are available at http://github.com/qnfnwkd/DeepPIM.</P>"
영화 시나리오와 영화촬영기법을 이용한 감정 예측 시스템,2018,"['Emotion Prediction', 'Big Data', 'Cinematography', 'Support Vector Machine', 'Morphological Analysis', '감정 예측', '빅데이터', '영화촬영기법', '지지벡터기계', '형태소 분석']","최근에 다양한 정보로부터 감정을 예측하여 청중에게 감독이 알리고자 하는 정보를 빠르게 전달하고자 한다. 또한, 청중은 감독의 의도를 대화 내용에 나타나는 대사뿐만 아니라, 영상내의 다양한 정보인 촬영 기법, 장면의 배경, 배경 음악 등을 통해 비대사 구간에서도 감정의 흐름을 이해하려고 한다.본 논문에서는 대사와 같은 문맥의 상황뿐만 아니라, 촬영 영상에 담아낸 색상, 음향, 구도, 배치 등에 의해 표현된 정보를 혼합하여 감정을 추출하고자 한다. 즉, 다양한 감정 표현 기법을 대사 구간, 비대사 구간으로 나누어 학습하고 판별하여 영상의 완성도에 기여하고 새로운 변화에 빠르게 적용할 수 있는 감정 예측 시스템을 제안한다. 본 논문에서 제안한 감정 예측시스템이 변형된 n-gram 방식과 형태소 분석을 적용한 사례와 비교했을 때, 정확도는 약 5.1%, 0.4% 향상되었고, 재현율은 약 4.3%, 1.6% 향상되었다.","Recently, we are trying to predict the emotion from various information and to convey the emotion information that the supervisor wants to inform the audience. In addition, audiences intend to understand the flow of emotions through various information of non-dialogue parts, such as cinematography, scene background, background sound and so on.In this paper, we propose to extract emotions by mixing not only the context of scripts but also the cinematography information such as color, background sound, composition, arrangement and so on. In other words, we propose an emotional prediction system that learns and distinguishes various emotional expression techniques into dialogue and non-dialogue regions, contributes to the completeness of the movie, and quickly applies them to new changes. The precision of the proposed system is improved by about 5.1% and 0.4%, and the recall is improved by about 4.3% and 1.6%, respectively, when compared with the modified n-gram and morphological analysis."
감성분석 기반의 게임 소비자 온라인 구전효과 연구,2018,"['텍스트 마이닝', '감성분석', '오피니언 마이닝', '머신러닝', 'eWOM', 'eWOM', 'Text Mining', 'Sentimental Analysis', 'Opinion Mining', 'Machine Learning']",,
비 계층적 클러스터링 알고리즘 기반 저조도 상태 가시광 통신 시스템,2018,"['visible light communication', 'PAM', 'PPM', 'machine learning', 'k-means clustering']",,
Comparative Usefulness of Naver and Google Search Information in Predictive Models for Youth Unemployment Rate in Korea,2018,"['한국어 웹 검색어', '예측변수', '청년실업률', '시계열예측', '머신러닝', 'Korean Web Query', 'Predictor', 'Youth Unemployment', 'Time Series Prediction', 'Machine Learning']",,
STFT 소리맵을 이용한 컨볼루션 신경망 기반 화자식별 방법,2018,"['딥러닝', '컨볼루션신경망', 'STFT알고리즘', '화자식별', '잡음 강건성', 'Deep Learning', 'Convolutional Neural Network (CNN)', 'Short-time Fourier Transform (STFT) Algorithm', 'Speaker Identification', 'Noise Robustness']","화자식별은 개인 성도의 음성학적 특징을 모델링하고 분류하는 기술로 음성 인식 분야의 가장 어려운 분야에 속한다. 화자식별 기술은 보안인증, 접근제어, 개인화, 지능형 로봇제어 등의 분야에서 광범위하게 응용이 가능하지만, 실제 환경 요소로 인한 잡음 때문에 발생하는 학습과 테스트 데이터 간의 불일치를 해결하는 것이 필요하다. 본 논문에서는 잡음 강건성을 위해 컨볼루션-풀링 연산을 반복적으로 적용하는 화자식별 시스템을 제안하였다. 정적 신호가 아닌 시계열 특성을 지니는 스피치 데이터의 특징을 보다 잘 모델링 하기 위해서 STFT알고리즘을 사용하여 소리맵을 생성하여 분류하였다. 제안하는 화자식별 시스템은 다른 기계학습 알고리즘의 인식 성능을 크게 상회하였고, 단계별로 잡음을 삽입하는 실험의 결과로 잡음 강건성을 검증하였다.","Speaker identification which models and classifies the phonological characteristics of individuals, is one of the most difficult areas of speech recognition. While speaker identification can be widely applied in fields such as security authentication, access control, personalization and intelligent robot control, a solution needs to be found for the inconsistency between training and test data caused by noise due to real environment factors. In this paper, we propose a speaker identification system based on convolution-pooling operation for noise robustness. To model the characteristics of individuals"" speech using the time series characteristics, a sound map was generated using the Short-time Fourier Transform (STFT) algorithm. The proposed speaker identification system outperforms recognition performance of other machine learning algorithms, and the robustness of noise is verified as a result of the noise insertion at incremental steps."
기계학습 활용을 위한 학습 데이터세트 구축 표준화 방안에 관한 연구,2018,"['기계학습', '인공지능', '참조모델', '표준화', '학습 데이터세트', 'Machine learning', 'Artificial Intelligence', 'Reference model', 'Standardization', 'Learning data set']",,
태양광발전설비 원격 관제를 위한 빅데이터 분석 및 처리,2018,"['Photovoltaic', 'Solar Power', 'Big Data', 'Machine Learning\r\n광 발전', '태양광 에너지', '빅데이터', '기계 학습']","신재생에너지의 발전량 변동에 따라 기존 발전기의 발전량을 증가시키거나 감소시켜야 하는데, 발전량 증·감발에빠르게 반응을 하는 발전기들은 상대적으로 발전비용이 크므로 태양광발전의 예측 정확도에 따라서 기동발전계획의비용 효율성이 영향을 받게 된다. 이에 본 논문에서는 태양광 발전량 예측의 불확실성을 최소화하기 위하여 빅데이터 분석 및 처리를 적용한 태양광발전설비 원격관제 시스템을 제안하였다.","In order to increase the generation of renewable energy, it is necessary to increase or decrease the generation amount of existing generators. The generators that respond rapidly to increase / decrease the generation amount generally have high generation cost. Therefore, Cost effectiveness is affected. In this paper, we propose a PV remote control system with big data to minimize the uncertainty of solar power generation prediction."
인공지능을 이용한 과일 가격 예측 모델 연구,2018,"['인공지능', '기계학습', '딥러닝', '알고리즘', 'ML', 'AI', 'Deep Running', 'algorithm']",,
Improving the Subject Independent Classification of Implicit Intention By Generating Additional Training Data with PCA and ICA,2018,"['Implicit Intention', 'Subject Independent BCI', 'Support Vector Machine', 'Principal Component Analysis', 'Independent Component Analysis.']",,"EEG-based brain-computer interfaces has focused on explicitly expressed intentions to assist physically impaired patients. For EEG-based-computer interfaces to function effectively, it should be able to understand users’ implicit information. Since it is hard to gather EEG signals of human brains, we do not have enough training data which are essential for proper classification performance of implicit intention. In this paper, we improve the subject independent classification of implicit intention through the generation of additional training data. In the first stage, we perform the PCA (principal component analysis) of training data in a bid to remove redundant components in the components within the input data. After the dimension reduction by PCA, we train ICA (independent component analysis) network whose outputs are statistically independent. We can get additional training data by adding Gaussian noises to ICA outputs and projecting them to input data domain. Through simulations with EEG data provided by CNSL, KAIST, we improve the classification performance from 65.05% to 66.69% with Gamma components. The proposed sample generation method can be applied to any machine learning problem with fewer samples."
사용자의 음악 선호요인 분석을 통한 개인 맞춤형 음악추천모델 연구,2018,"['음악추천', '개인화 추천', '콘텐츠 기반', '음원추천', '머신러닝', 'Music Recommendation Model', 'Personalized Recommendation', 'Contents Based', 'Music Resource Recommendation', 'Machine Learning']",,
인공지능 기반 작곡 프로그램 현황 및 제언,2018,"['Artificial Intelligence', 'Music Composition', 'AI-based Composition', 'Machine Learning', 'Deep Learning', '인공지능', '작곡', '인공지능 작곡', '머신러닝', '딥러닝']","본 연구는 인공지능 기반 작곡 프로그램 현황을 살펴보고 실정을 고려한 제언을 제공하고자 한다. 인공지능기반 작곡 프로그램은 기존의 '전문가 시스템' 방식의 알고리즘을 벗어나 심층신경망 이론의 발전 및 빅데이터 처리기술 향상과 더불어 눈부신 성장을 보이고 있다. 이에 따라 클래식 음악과, 팝음악을 작곡하는데 있어 인공지능 기반작곡 프로그램이 학계와 산업계에서 다양하게 제안되고 있으며, 최근 수년 사이 대중의 평가도 달라지고 있다. 다만해당 기술 개발과 관련하여 여전한 한계점들이 분명히 존재하는 바, 대중의 인식 문제, 데이터베이스화되지 않은 가치 있는 사료들의 누락, 관련 법규의 미비, 음악적인 부분보다는 기술적 관점에서 해당 산업이 주도되는 점 등을 개선할 필요가 있겠다. 이 같은 점이 보완된다면, 인공지능 기반 기술은 국가 경쟁력 확보와 유지에 있어 중요한 역할을 해낼 것으로 보인다.","This study aimed to provide an overview of artificial intelligence based music composition programs.The artificial intelligence-based composition program has shown remarkable growth as the development of deep neural network theory and the improvement of big data processing technology. Accordingly, artificial intelligence based composition programs for composing classical music and pop music have been proposed variously in academia and industry. But there are several limitations: devaluation in general populations, missing valuable materials, lack of relevant laws, technology-led industries exclusive to the arts, and so on. When effective measures are taken against these limitations, artificial intelligence based technology will play a significant role in fostering national competitiveness."
GPS의 위치 정보 시스템을 활용한 자율주행 차량의 차선 검출 구현,2018,"['Lane Detection', 'Self-Driving Vehicle', 'Machine Learning', 'Tensor Flow', 'OpenCV']",,
소프트웨어 정의 무선 메쉬 네트워크에서 마스터 컨트롤러 선택방법,2018,"['Wireless Mesh Network', 'Software Defined Network', 'OpenFlow', 'Machine Learning', 'Link Failure Prediction', 'Flow Setup Latency']",,
7포커 인공지능 시뮬레이터 구현,2018,"['7-poker', 'AI Simulator', 'Emotion Analysis', 'Machine Learning', 'Keras', 'Neural Network']",,
오픈소스 기반 빅데이터 플랫폼을 활용한 선박 운항 효율 예측 연구,2018,"['Big data', 'Energy efficiency', 'Hadoop', 'Machine learning', 'R', 'Regression analysis', 'Ship navigation']",,"In this paper, we build an open source-based big data platform using Hadoop and R in order to support ship navigation considering energy efficiency. Based on this, a regression analysis is performed on the navigation data including the external force acting on the ship and the operating condition of the ship, and a method of predicting the fuel consumption rate of the ship is suggested. Finally, we discuss the results of predicting the fuel consumption rate using the test ship operation data according to the proposed method."
A Study of Image Classification using HMC Method Applying CNN Ensemble in the Infrared Image,2018,"['Infrared image', 'Convolutional neural network', 'Machine learning']",,"In the marine environment, many clutters have similar features with the marine targets due to the diverse changes of the air temperature, water temperature, various weather and seasons. Also, the clutters in the ground environment have similar features due to the same reason. In this paper, we proposed a robust Hybrid Machine Character (HMC) method to classify the targets from the clutters in the infrared images for the various environments. The proposed HMC method adopts human's multiple personality utilization and the CNN ensemble method to classify the targets in the ground and marine environments. This method uses an advantage of the each environmental training model. Experimental results demonstrate that the proposed method has better success rate to classify the targets and clutters than previously proposed CNN classification method."
A Study on Two-dimensional Array-based Technology to Identify Obfuscatied Malware,2018,"['정적 분석', '문자열', '심볼', '엔트로피', '머신 러닝', 'static analysis', 'string', 'symbol', 'entropy', 'machine learnings']",,
소형 무인 항공기 탐지를 위한 인공 신경망 기반 FMCW 레이다 시스템,2018,"['FMCW radar', 'Neural network', 'Detection', 'Signal processing', 'Machine learning']",,"Drone detection in FMCW radar system needs complex techniques because a drone beat frequency is highly dynamic and unpredictable. Therefore, the current static signal processing algorithms cannot show appropriate detection accuracy. With dynamic signal fluctuation and environmental clutters, it can fail to detect a drone or make false detection. It affects to the radar system integrity and safety. Constant false alarm rate (CFAR), one of famous static signal process algorithm is effective for static environment. But for drone detection, it shows low detection accuracy. In this paper, we suggest neural network based FMCW radar system for detecting a drone. We use recurrent neural network (RNN) because it is the effective neural network for signal processing. In our FMCW radar system, one transmitter emits FMCW signal and four-way fixed receivers detect reflected drone beat frequency. The coordinate of the drone can be calculated with four receivers information by triangulation. Therefore, RNN only learns and inferences reflected drone beat frequency. It helps higher learning and detection accuracy. With several drone flight experiments, RNN shows false detection rate and detection accuracy as 21.1% and 96.4%, respectively."
UNB 2012 침입탐지 데이터셋 기반의 네트워크 비정상 행위 탐지,2018,"['기계학습', '침입탐지', 'UNB 2012 데이터셋', '분류', '인공지능', 'machine learning', 'intrusion detection', 'UNB 2012 Dataset', 'classification', 'artificial intelligence']","UNB 2012 침입탐지 평가 데이터셋을 캐나다 뉴 브런스윅 대학교의 CIC (Canadian Institute for Cybersecurity)로부터 제공받았다. UNB 2012 침입탐지 데이터셋은 실제 네트워크 공격 상황을 시뮬레이션하여 생성되었다. 침입탐지와 관련하여 많은 연구가 이루어지고 있지만 대부분의 연구 결과는 실제 환경에 적용하기 어려운 측면이 있는데 CIC는 이런 점을 고려하여 UNB 2012 침입탐지 평가 데이터셋을 만들었다. 본 연구에서는 정상 클래스와 4개의 공격 클래스를 사용한다. UNB 2012 데이터셋은 일자별로 나뉜 서브 데이터셋을 갖는데 서브 데이터셋 간의 특징이 조금씩 다르다. 각 서브 데이터셋의 공통된 특징들을 선택 및 가공하여 16개의 특징을 추출한다. 대표적인 데이터 마이닝 도구 중 하나인 WEKA (Waikato Environment for Knowledge Analysis)를 사용하여 데이터셋 분할, 언더샘플링, 모델링 등의 과정을 거쳐 비교 실험을 한다. 실험 결과에서 k-NN 알고리즘이 가장 우수한 성능을 나타내었다.","UNB 2012 intrusion detection evaluation dataset was provided from CIC (Canadian Institude for Cybersecurity) of new brunswick university in Canada. The dataset is created by simulation considering real network intrusion. Many researches related to intrusion detection are conducted, but it is difficult to apply most of the results of the researches to real intrusion detection system. The CIC made the UNB 2012 intrusion detection evaluation dataset considering the difficulty. In this paper, we use a normal class and four attack classes. The dataset has several sub dataset separated by date. Each sub dataset has their own characteristics. We select or modify 16 features among common features of all sub dataset. We conduct comparative experiments after data partitioning, undersampling, and modeling using WEKA(Waikato Environment for Knowledge Analysis), a typical data mining tool. In the experimental results, the k-NN algorithm showed the best performance."
Improving the Subject Independent Classification of Implicit Intention By Generating Additional Training Data with PCA and ICA,2018,"['Implicit Intention', 'Subject Independent BCI', 'Support Vector Machine', 'Principal Component Analysis', 'Independent Component Analysis']",,"EEG-based brain-computer interfaces has focused on explicitly expressed intentions to assist physically impaired patients. For EEG-based-computer interfaces to function effectively, it should be able to understand users' implicit information. Since it is hard to gather EEG signals of human brains, we do not have enough training data which are essential for proper classification performance of implicit intention. In this paper, we improve the subject independent classification of implicit intention through the generation of additional training data. In the first stage, we perform the PCA (principal component analysis) of training data in a bid to remove redundant components in the components within the input data. After the dimension reduction by PCA, we train ICA (independent component analysis) network whose outputs are statistically independent. We can get additional training data by adding Gaussian noises to ICA outputs and projecting them to input data domain. Through simulations with EEG data provided by CNSL, KAIST, we improve the classification performance from 65.05% to 66.69% with Gamma components. The proposed sample generation method can be applied to any machine learning problem with fewer samples."
BIM 부재 및 IFC 클래스 간 시멘틱 매핑 검증을 위한 기계학습 기반 건축 부재 자동 분류,2018,"['BIM', 'IFC', 'Quality control', 'Semantic integrity', 'Support Vector Machine']",,"With the growing use of BIM in the construction industry, new software applications are being developed to meet these specific needs. Such developments have increased the importance of the Industry Foundation Classes (IFC), which is the open and neutral format for sharing BIM data and the de facto standard for interoperability. However, the IFC lacks formal logic rigidness and thus is susceptible to errors and omissions during data transfers. This research addressed the issue by applying machine learning techniques to automatically classify elements of a BIM model, thereby allowing for classification checks as well as enriching the semantics of the model. Naïve Bayes, logistic regression and support vector machines (SVM) were trained and tested using 4,187 unique elements from six BIM models. Features included elements’ geometries and the relational semantics between elements. Results showed that SVM provided the highest accuracy at 0.9081 with geometry, and 0.9439 when adding semantics. The algorithms provide a way to accelerate integrity checks and model element classification required for quality control of BIM models."
사물인터넷 기반의 집중도 및 명상도 검출을 통한 ASMR 콘텐츠 제어 기법,2018,"['뇌파', '사물인터넷', '기계학습', '정신건강', 'Electroencephalography', 'Internet-of-Things', 'Machine Learning', 'Mental Health']",,
AIS 데이터 분석을 통한 이상 거동 선박의 식별에 관한 연구,2018,"['기계학습', 'AIS', '해상교통 분석', '이상 거동 선박', '선박교통관제', 'Machine Learning', 'AIS', 'Maritime Traffic Analysis', 'Ship Movement Anomaly', 'Vessel Traffic Service']","최근 해상교통량이 증가하고 선박교통 관제구역이 확대됨에 따라 관제사의 업무 부하가 증가하고 있으며, 이로 인해 교통량이 급증하는 경우 관제사가 위험을 인지하지 못하는 상황도 발생하게 된다. 이러한 배경에서 본 논문에서는 관제 업무의 지원을 위해 이상 거동 선박을 자동으로 식별하는 방법을 제안한다. 본 방법은 누적된 AIS 데이터를 이용하여 관제구역 내의 통항 패턴을 학습하고, 학습된 모델과 의 비교를 통해 이상치를 계산하여 이상 거동 선박을 식별한다. 특히, 선박의 거동 상태에 대한 분류 정보가 없더라도 비지도 학습법을 기반으로 항적 데이터를 자동으로 분류하여 통항 패턴을 학습할 수 있으며, 항적의 군집화와 분류 과정을 통해 이상 거동 선박을 실시간으로 식별할 수 있는 특징을 가진다. 또한, 본 논문에서는 선박운항 시뮬레이터 및 실제 AIS 항적 데이터를 이용한 식별 실험을 수행하였으며, 이를 통해 선박교통관제 시스템에의 활용 가능성을 고찰하였다.","Recently, the Vessel Traffic Service (VTS) coverage has expanded to include coastal areas following the increased attention on vessel traffic safety. However, it has increased the workload on the VTS operators. In some cases, when the traffic volume increases sharply during the rush hour, the VTS operator may not be aware of the risks. Therefore, in this paper, we proposed a new method to recognize ship movement anomalies automatically to support the VTS operator’s decision-making. The proposed method generated traffic pattern model without any category information using the unsupervised learning algorithm.. The anomaly score can be calculated by classification and comparison of the trained model. Finally, we reviewed the experimental results using a ship-handling simulator and the actual trajectory data to verify the feasibility of the proposed method."
SNS 데이터와 Word2Vec을 이용한 게임 콘텐츠 평가,2018,"['자연어처리', 'Word2Vec', 'CBOW', '비지도 학습', 'SNS', 'NLP', 'Word2Vec', 'CBOW', 'Unsupervised Learning', 'SNS']",SNS는 각종 콘텐츠들에 대한 사용자들의 평가가 생성되는 곳으로 평가를 추론하는 데이터로 유용한 곳이다. 그러나 SNS 데이터는 비속어를 비롯해 채팅 용 문장들이 많으며 문법이 정형적이지 않아 기계적으로 의미를 해석하기가 어려움이 있다. 본 논문에서는 특정 게임 사용자들을 대상으로 SNS 데이터를 6개월간 취합하여 Word2Vec을 이용하여 게임 콘텐츠가 사용자들에 가진 의미를 분석하였다. SNS 데이터는 CBOW과 Skip-gram을 비롯하여 문장 간 거리를 비교하였으며 SNS 데이터에 대한 합리적인 기계 학습 모델을 제안한다.,"SNS is useful place for infer evaluation based on user generated feedback regarding various contents.However, SNS data contains many profanity and internet slangs, and wrong grammar. So it makes difficult to understanding and analyze meaning by the computer. In this paper, we collected SNS data for specific game users for 6 months. Then, Word2Vec was used to analyze the meaning of game contents to users. SNS data compares the distance between sentences including CBOW and Skip-gram, and suggests a reasonable machine learning model for SNS data."
건강행위정보기반 고혈압 위험인자 및 예측을 위한 통계분석,2018,"['고혈압', '예측모델', '기계학습', '임상정보', '신체계측', 'Hypertension', 'Prediction model', 'Machine Learning', 'Clinical Information', 'Anthropometry']",,
인공지능 기반의 TensorFlow 그래픽 사용자 인터페이스 개발에 관한 연구,2018,"['기계 학습', '인공지능', '그래픽 사용자 인터페이스', '알고리즘', 'TensorFlow', 'Machine learning', 'Artificial intelligence', 'Graphic User Interface', 'Algorithm', 'TensorFlow']",,
두 입력 단층 다단 인공신경망회로 특성함수에 의한 처리용량 계산과 시뮬레이션,2018,"['Artificial Intelligence', 'Artificial Neural Network', 'Multi-Valued Logic', 'Machine Learning', '인공신경망회로', '다치논리', '기계학습', '언어식 처리', '퍼셉트론']","입력이 2개인 2-input-CoreNet의 처리 용량은 3차원 무게값 공간에서 분할 영역을 찾아야 하는데 3차원이상에서 분할 공간 영역을 세는 것은 쉽지 않다. 입력 단 cot(x) 레벨링 방법을 사용한 단층 다단 입력 인공신경망회로에서 3차원 공간 분할에 의한 특성화 함수는 으로 표현된다. w2202(p=2x2, q=2) 모델의 특성화 함수는 으로 나왔고, w2203(p=2x2, q=3) 모델의 특성화 함수는 으로 표현되었다. 이들의 초평면 배열에서 총 분할 영역의 수는 으로 각각 14와 59개이다. 이 두 모델을 역전파 알고리즘을 사용한 인공신경망회로로 시뮬레이션 하여 그 결과 수렴, 즉 구현 가능한 함수의 수가 각각 14개와 59개로 앞 특성화 함수의 이론 결과와 정확히 일치함을 보였다.실험에서는 무게값 공간에서 가능한 중첩점의 수를 줄이기 위하여 입력단 레벨링 방법으로 NMLGR에 소개된 함수와, 출력단 레벨링 방법으로 을 사용하였다.","The characteristic function of a 2-input-CoreNet is represented as . This 3-dimensional weight space is divided by planes. It is difficult to find out the number of implementable functions for the given input and output levels in Multi-Level Artificial Neural Networks in more than a 2-dimensional space. I used the cot(x) input leveling method for the input leveling method. The characteristic function is for the model w2202(p=2x2, q=2) and for the model w2203(p=2x2, q=3). The number of separable sectors are 14 and 59 for the models w2202 and w2302 which are calculated from the equation . These numbers are exactly the same as those from the simulation results by a Multi-Level Artificial Neural Networks, a single layered Core-Net.I used the functions of and which were used in NMLGR for the leveling methods for the input and output values to maximize the number of sectors ."
Exploration of Service Improvement Based on a Content Analysis of Consumer Reviews,2018,"['Consumer Review', 'Consumer Sentiment', 'Topic Model', 'Service Dimension', 'Text Analytics', 'Web Scraping', 'Machine Learning']",,"Deriving meaningful insights from massive amount of user-generated contents is not a trivial task.To tackle this issue, this study proposes an integrated text mining framework to uncover important latent dimensions buried in the textual information to efficiently track the changes in the dimensions over time by covariate of interests. In doing so, this study applies two stages of text analytics of sentiment analysis and topic model utilizing consumer reviews scraped from a popular online review site. The sentiment analysis is conducted as an objective measure to classify the polarity of reviews in order to leverage positive ones connotative of strengths and negative ones connotative of weaknesses. Subsequently, the structural topic model(STM) discovers dimensions(topics). In the STM, each customer review is represented as a probabilistic distribution over a set of underlying dimensions. This interdisciplinary approach highlights several implications theoretically and practically and the research framework leverages textual information to uncover, track, and compare the latent dimensions, and enables us to understand the relationships among the dimensions and covariates of interest."
Exploration of Service Improvement Based on a Content Analysis of Consumer Reviews,2018,"['Consumer Review', 'Consumer Sentiment', 'Topic Model', 'Service Dimension', 'Text Analytics', 'Web Scraping', 'Machine Learning']",,"Deriving meaningful insights from massive amount of user-generated contents is not a trivial task. To tackle this issue, this study proposes an integrated text mining framework to uncover important latent dimensions buried in the textual information to efficiently track the changes in the dimensions over time by covariate of interests. In doing so, this study applies two stages of text analytics of sentiment analysis and topic model utilizing consumer reviews scraped from a popular online review site. The sentiment analysis is conducted as an objective measure to classify the polarity of reviews in order to leverage positive ones connotative of strengths and negative ones connotative of weaknesses. Subsequently, the structural topic model(STM) discovers dimensions(topics). In the STM, each customer review is represented as a probabilistic distribution over a set of underlying dimensions. This interdisciplinary approach highlights several implications theoretically and practically and the research framework leverages textual information to uncover, track, and compare the latent dimensions, and enables us to understand the relationships among the dimensions and covariates of interest."
지능형 기록정보서비스를 위한 선진 기술 현황 분석 및 적용 방안,2018,"['지능형 기록정보서비스', '기계 학습', '인공지능', '전자기록관리', 'Intelligent archival information services', 'machine learning', 'artificial intelligence', 'electronic records management']","디지털 트랜스포메이션 시대를 맞이하여 기존 제도적․행정적 측면을 강조하던 전통적인 시각에서 벗어나, 기록관리 영역에 신기술이 적용되기 시작하였다. 이에 본 연구는 지능화 선진 기술을 적용한 국내외 기록관, 도서관, 박물관의 서비스 현황을 분석하여 그 차이를 규명한 다음, 분석 결과를 토대로 지능형 기록정보서비스 적용 방안을 제안하고자 한다. 조사 대상에 기록관 이외에 도서관, 박물관을 포함한 이유는 해당 기관들이 정보서비스 제공 기관으로서 하나의 범주로 포괄되기 때문이며, 이들 기관을 대상으로 문헌 연구 및 사례 연구를 수행하였다. 국내외 사례 비교를 통해 도출된 시사점을 바탕으로 기록관에 지능형 기록정보서비스 적용을 위한 선결 조건, 적용 시 문제점, 적용방향에 대하여 정리하였다. 본 연구 결과를 통해 변화된 전자기록환경에 적합한 지능형 기록정보서비스 모델 수립에 도움이 될 수 있을 것이라 기대한다.","In the era of digital transformation, new technologies have begun to be applied in the field of records management, away from the traditional view that emphasized the existing institutional and administrative aspects. Therefore, this study analyzed the service status of archives, libraries, and museums applied with advanced intelligent technology and identified the differences. Then, we proposed how to apply intelligent archival information services based on the analysis results. The reason for including libraries and museums in the research is that they are covered by a single category as an information service provider. To achieve our study aims, we conducted literature and case studies. Based on the results of the case study, we proposed the application strategies of intelligent archival information services. The results of this study are expected to help develop intelligent archival service models that are suitable for the changed electronic records environment."
An Armband-Type Finger Language Recognition System Based on Ensemble Artificial Neural Network,2018,"['Armband sensor (암밴드 센서)', 'Pattern recognition (패턴 인식)', 'Ensemble machine learning (앙상블 기계 학습)', 'Electromyography (근전도)', 'Finger recognition (지화)']",,
Facial Age Estimation Using Convolutional Neural Networks Based on Inception Modules,2018,"['Convolutional neural networks', 'Face detection', 'Age estimation', 'Inception module', 'Machine learning']",,"Automatic age estimation has been used in many social network applications, practical commercial applications, and human–computer interaction visual-surveillance biometrics. However, it has rarely been explored. In this paper, we propose an automatic age estimation system, which includes face detection and convolutional deep learning based on an inception module. The latter is a 22-layer-deep network that serves as the particular category of the inception design. To evaluate the proposed approach, we use 4,000 images of eight different age groups from the Adience age dataset. k-fold cross-validation (k = 5) is applied. A comparison of the performance of the proposed work and recent related methods is presented. The results show that the proposed method significantly outperforms existing methods in terms of the exact accuracy and off-by-one accuracy. The off-by-one accuracy is when the result is off by one adjacent age label to the above or below. For the exact accuracy, the age label of “60+” is classified with the highest accuracy of 76%."
오토인코더 모델을 이용한 선박교통관제 지원 시스템의 개발,2018,"['기계학습', '선박교통관제', '선박자동식별장치', '해상교통 분석', '이상 거동 선박', 'machine learning', 'vessel traffic service', 'AIS', 'maritime traffic analysis', 'ship movement anomaly']","최근 해상 교통량이 증가하고 연안 항해에 대한 관제의 필요성이 요구되면서 관제 범위가 점차 확대되고 있는 추세이다. 이러한 관제구역의 확대는 관제사의 업무 부하를 초래하며, 이로 인해 교통량이 급증하는 경우에는 관제사가 사고 위험을 인지하지 못하는 상황도 발생한다. 이에 국제항로표지협회(IALA)에서는 관제사의 의사결정을 지원하는 기능들의 가이드라인을 권고하고 있지만, 현장의 상황에 맞지 않는 경우가 많아 널리 활용되지 못하고 있다. 이러한 배경에서 본 논문에서는 관제사의 관제 업무를 지원하기 위해 이상 거동 선박을 자동으로 식별하는 방법과 이를 이용한 관제 지원 시스템을 제안한다. 본 시스템은 누적된 항적 데이터를 이용하여 관제구역 내의 통항 패턴을 학습하고, 학습 모델과의 비교를 통해 식별된 이상 거동 선박 정보를 관제사에게 제공한다. 또한, 본 논문에서는 시뮬레이터 및 실제 항적 데이터를 이용하여 실험을 수행하고, 이를 통해 선박교통관제 시스템에의 활용 가능성을 고찰한다.","The primary purpose of the VTS (Vessel Traffic Service) is to prevent maritime accidents in the port. Recently, the VTS coverage has expanded to include coastal areas with an increase in the focus on maritime safety. However, the expansion led to an increase in the workload for the VTS operators. In some cases, due to an increase in the maritime traffic volume during rush hours, the VTS operator could not recognize the risks of accidents. Henceforth, IALA announced the guidelines to support the VTS operator’s decision-making process. But, the configuration of the guidelines is complicated and there are many useless alarms, thus, making it inapplicable for wide employment. In the present work, we propose a new system to automatically recognize anomalies in ship movement to support the VTS operator’s decision-making process. The proposed system makes the traffic pattern model using the accumulated AIS messages in VTS coverage. Subsequently, the anomaly score can be calculated by comparison with the trained model. Finally, we have reviewed experimental results using a ship-handling simulator and actual trajectory data to verify the feasibility of the proposed method."
Human and Robot Tracking Using Histogram of Oriented Gradient Feature,2018,"['Intelligent Space', 'human and robot tracking', 'histogram of oriented gradients', 'AdaBoost learning', 'feature']",,"This paper describes a real-time human and robot tracking method in Intelligent Space with multicameranetworks. The proposed method detects candidates for humans and robots by using thehistogram of oriented gradients (HOG) feature in an image. To classify humans and robots from thecandidates in real time, we apply cascaded structure to constructing a strong classifier which consistsof many weak classifiers as follows: a linear support vector machine (SVM) and a radial-basis function(RBF) SVM. By using the multiple view geometry, the method estimates the 3D position of humans androbots from their 2D coordinates on image coordinate system, and tracks their positions by usingstochastic approach. To test the performance of the method, humans and robots are asked to moveaccording to given rectangular and circular paths. Experimental results show that the proposedmethod is able to reduce the localization error and be good for a practical application of humancenteredservices in the Intelligent Space."
Time-adaptive support vector data description for nonstationary process monitoring,2018,"['Multivariate control chart', 'Support vector data description', 'Time-varying process', 'Process control', 'Machine learning', 'Nonstationary process']",,"<P><B>Abstract</B></P>  <P>Statistical process control techniques are widely used for quality control to monitor the stability of a process over time. In modern manufacturing systems with complex and variable processes, appropriate control chart techniques that can efficiently address nonnormal processes are required. Furthermore, in real manufacturing environments, process changes occur frequently because of various factors such as product and setpoint changes, catalyst degradation, seasonal variations, and sensor drift. However, conventional control chart schemes cannot necessarily accommodate all possible future conditions of a process because they are formulated based on information recorded in the early stages of the process. Several attempts have been made to accommodate process changes over time. In the present paper, we propose a time-adaptive support vector data description-based control chart that can address not only nonnormal in-control observations, but also time-varying processes. The effectiveness and applicability of the proposed chart was demonstrated through experiments with simulated data and real data from the metal frame process in mobile device manufacturing.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a time-adaptive support vector data description-based control chart. </LI> <LI>  Proposed chart can adaptively monitor the time-varying and nonnormal processes. </LI> <LI>  Proposed chart traces the natural changes, yet detects real faults effectively. </LI> <LI>  Simulation and real-case data demonstrate the efficiency of the proposed chart. </LI> </UL> </P>"
오픈소스 빅데이터 기술을 적용한 생명보험 예측모델 분석환경 구축에 관한 사례연구 : ING 예측모델을 중심으로,2018,"['Big data', 'Life insurance', 'Data analysis environment', 'Speech to Text', 'Text Analysis', 'Machine learning', 'Unstructured data analysis']",,"The analysis target data, analysis algorithm, and analysis utilization scenario were defined and developed by identifying eight key analysis services by the value chain of the insurance business. Thus, the insurance big data strategy model was shared and diffused to enable small and medium-sized insurance companies to apply the analysis results to their business while minimizing trial and error in the field of big data adoption.Since most business is processed online in the domestic financial sector, the volume of accumulated internal data is enormous, and its types are diverse, and this has consequently improved the level of big data activation compared to other industries; hence the high potential value and possibilities for the utilization of data analysis.Large insurance companies such as S Life Insurance, H Life Insurance, and K Life Insurance have introduced big data analysis to the domestic insurance industry, which is experiencing continuous trial and error due to the lack of shared information on the effects of the introduction and application of big data analysis.The main contents of this case study are as follows. First, development of a strategy model that internalizes big data analysis based on the value chain of the insurance industry. Second, formation of big data analysis environment through the application of open source technology and STT/TA environment for unstructured text analysis. At last, Sharing of big data analysis strategy model that is suitable for the business and data management status of medium-sized insurance companies."
2.5차원 다중뷰 기반 특징 및 데이터 확장을 통한 간유리음영 결절의 다중클래스 분류,2018,"['컴퓨터 단층촬영 영상(CT)', '간유리음영 결절(GGN)', '다중뷰', '특징 분류', '머신러닝', 'computed tomography (CT)', 'ground-glass nodule (GGN)', 'multiview', 'feature classification', 'machine learning']","간유리음영 결절은 내부 고형 성분의 포함 여부 및 크기에 따라 악성도가 달라지기 때문에 고형 성분의 크기에 따른 혼합 간유리음영 결절과 순수 간유리음영 결절을 구분하는 것이 중요하다. 그러나 고형 성분의 크기가 작은 혼합 간유리음영 결절은 순수 간유리음영 결절과 유사하게 나타나 구분이 어렵다. 본 논문에서는 다중뷰-슬랩 관심영역 기반 특징 및 데이터 확장을 통한 간유리음영 결절의 분류 방법을 제안한다. 첫째, 분류기의 훈련 데이터 수를 늘리고 과적합을 피하기 위해 데이터 확장을 수행한다. 둘째, 간유리음영 결절로부터 네 종류의 관심 영역을 생성한다. 셋째, 각 관심영역으로부터 고형 성분의 특성을 반영하는 특징을 추출하고 의미 있는 특징을 선별한다. 넷째, 랜덤 포레스트를 이용해 간유리음영 결절을 분류한다. 2.5차원 다중뷰-슬랩 관심영역을 이용한 분류 정확도는 84.05%로 3차원 관심영역과 2.5차원 다중뷰 관심영역을 이용한 정확도보다 각각 6.27%, 4.44% 높았다.","Differentiation between part-solid ground-glass nodules (GGNs) with a variable sized solid component from pure GGNs is important because the malignancy rate of GGN is different according to the presence and size of solid components in chest CT images. However, because of their similar appearance, it is difficult to distinguish between part-solid GGN and pure GGN when the part-solid GGN includes small solid components. In this paper, we propose a multi-class classification method for GGN using multiview-slab region of interest (ROI)-based features and data augmentation. First, data augmentation is performed to enlarge the training dataset of the classifier and to avoid the overfitting problem. Second, four ROIs are generated from a GGN. Third, features that reflect the characteristics of the solid component are extracted from each ROI, and significant features are selected for classification. Finally, GGNs are classified using the random forest (RF). In the experiments, the classification accuracy with 2.5-dimensional multiview-slab ROI was 84.05%, which was 6.27% and 4.44% higher than the classification accuracy with 3-dimensional ROI and 2.5-dimensional ROI, respectively."
메신저 내 그룹 대화방 문서 클러스터링 적용을 위한 클러스터 모델 비교,2018,"['기계 학습', '문서 클러스터링', '채팅 로그', '클러스터링 모델', 'Machine Learning', 'Document Clustering', 'Chat Log', 'Clustering Models']","본 논문은 메신저 상의 유사한 그룹의 사용자들에게 보다 효율적으로 서비스를 제공하기 위해 메신저 상의 대화방들을 문서 클러스터링 방법을 통해 클러스터링 할 때, 채팅 로그 데이터에 적절한 클러스터링 알고리즘을 테스트를 통해 찾는다. 대화방과 채팅 로그의 관계를 문서 클러스터링에서의 문서와 문서 내용의 관계로 대응시킨다. 사전에 준비된 3개 주제의 채팅 로그에 DBSCAN, k-means, Ward’s method 알고리즘을 대화방의 수, 가중치 부여 방식을 달리하여 적용한 뒤 올바르게 분류된 정도를 나타내는 Rand index 수치, 처리 속도, 그리고 모델에 따른 특징을 고려하여 적절한 정도를 평가한다. k-means 알고리즘은 클러스터의 수를 미리 정해야 하는 문제로 메신저에 사용하기 부적절해 보이며, DBSCAN은 Rand index의 평균이 가장 높은 수치를 보였으나 알고리즘 내 인수를 정하는 문제를 해결할 필요가 있다. Ward’s method는 특별한 인수 없이 사용 가능한 장점이 있으며, 가중치 부여 방식에 관계없이 Rand index가 0.9 전후로 좋은 결과를 보인다.","In this paper, text clustering models are compared and analyzed for chat rooms on messenger applications to provide appropriate service more effectively. We deal with the relation between the chat room and the chat log as corresponding to the relation the relation between the document and the content for the document clustering. First, DBSCAN, k-means, Ward’s method are used to cluster chat rooms based on chat logs with various number of chat rooms and weighting methods such as TF, TF-IDF, etc. Then we evaluate the quality of clustering results with the value of Rand index that indicate the degree of correct classification. In addition, execution times are measured, and the characteristics of clustering models utilized chat logs are considered. Since the k-means algorithm need to determine the number of clusters before clustering, it is inappropriate for clustering the chat rooms. On the other hand, the result of DBSCAN showed the highest Rand index, however the process to search the optimal epsilon is needed. Ward’s method require no additional work for the optimal argument, and the result of this method have about 0.9 Rand index regardless of the weighting methods."
양방향 LSTM을 활용한 전력수요 데이터 예측 기법 연구,2018,"['전력 수요 예측', '딥 러닝', '순환 신경망', '양방향 장단기 기억 네트워크', 'Electronic Demand Prediction', 'Deep Learning', 'Recurrent Neural Network', 'Bidirectional Long Short Term Memory Networks']",,"Power demand prediction is used to detect anomalies such as machine malfunction and power off when the measured power amount deviates from the predicted power amount by a certain range in the industrial sector. Power data is difficult to predict because it is time series data with strong seasonality and trend.In this paper, a power prediction model based on bi-directional LSTM algorithm, which is a deep learning based algorithm and the most popular algorithm in recent years, has been established along with LSTM. The model was learned, evaluated, and verified using four years of power data."
지능형 영상 감시 시스템에서 사람 자세 추정을 이용한 납치 상황 인식,2018,"['Intelligent Video Surveillance Systems', 'Kidnapping Detection', 'Human Pose Estimation', 'Machine Learning', 'Classification Schemes']",,"In this paper, a kidnapping detection scheme in which human pose estimation is used to classify accurately between kidnapping cases and normal ones is proposed. To estimate human poses from input video, human’s 10 joint information is extracted by OpenPose library. In addition to the features which are used in the previous study to represent the size change rates and the regularities of human activities, the human pose estimation features which are computed from the location of detected human’s joints are used as the features to distinguish kidnapping situations from the normal accompanying ones. A frame-based kidnapping detection scheme is generated according to the selection of J48 decision tree model from the comparison of several representative classification models. When a video has more frames of kidnapping situation than the threshold ratio after two people meet in the video, the proposed scheme detects and notifies the occurrence of kidnapping event. To check the feasibility of the proposed scheme, the detection accuracy of our newly proposed scheme is compared with that of the previous scheme. According to the experiment results, the proposed scheme could detect kidnapping situations more 4.73% correctly than the previous scheme."
Vector space based augmented structural kinematic feature descriptor for human activity recognition in videos,2018,"['human activity recognition', 'kinematic features', 'multiclass support vector machine classifier', 'structural features', 'vector space based augmented structural kinematic']",,"A vector space based augmented structural kinematic (VSASK) feature descriptor is proposed for human activity recognition. An action descriptor is built by integrating the structural and kinematic properties of the actor using vector space based augmented matrix representation. Using the local or global information separately may not provide sufficient action characteristics. The proposed action descriptor combines both the local (pose) and global (position and velocity) features using augmented matrix schema and thereby increases the robustness of the descriptor. A multiclass support vector machine (SVM) is used to learn each action descriptor for the corresponding activity classification and understanding. The performance of the proposed descriptor is experimentally analyzed using the Weizmann and KTH datasets. The average recognition rate for the Weizmann and KTH datasets is 100% and 99.89%, respectively. The computational time for the proposed descriptor learning is 0.003 seconds, which is an improvement of approximately 1.4% over the existing methods."
실시간 공격 탐지를 위한 Pearson 상관계수 기반 특징 집합 선택 방법,2018,"['Intrusion Detection System', 'Artificial Neural Network', 'Multi-objective Genetic Algorithm', 'Feature selection', 'Pearson Correlation Coefficient', 'NSL_KDD data set']","기계학습을 이용하는 침입 탐지 시스템의 성능은 특징 집합의 구성과 크기에 크게 좌우된다. 탐지율과 같은 시스템의 탐지 정확도는 특징 집합의 구성에, 학습 및 탐지 시간은 특징 집합의 크기에 의존한다. 따라서 즉각적인 대응이 필수인 침입 탐지 시스템의 실시간 탐지가 가능하도록 하려면, 특징 집합은 크기가 작으면서도 적절한 특징들로 구성하여야 한 다. 본 논문은 실시간 탐지를 위한 특징 집합 선택 문제를 해결하기 위해 사용했던 기존의 다목적 유전자 알고리즘에 특징 간의 Pearson 상관계수를 함께 사용하면 탐지율을 거의 낮추지 않으면서도 특징 집합의 크기를 줄일 수 있음을 보 인다. 제안한 방법의 성능평가를 위해 NSL_KDD 데이터를 사용하여 10가지 공격 유형과 정상적인 트래픽을 구별하도 록 인공신경망을 설계, 구현하여 실험한다.","The performance of a network intrusion detection system using the machine learning method depends heavily on the composition and the size of the feature set. The detection accuracy, such as the detection rate or the false positi ve rate, of the system relies on the feature composition. And the time it takes to train and detect depends on the siz e of the feature set. Therefore, in order to enable the system to detect intrusions in real-time, the feature set to be used should have a small size as well as an appropriate composition. In this paper, we show that the size of the feat ure set can be further reduced without decreasing the detection rate through using Pearson correlation coefficient bet ween features along with the multi-objective genetic algorithm which was used to shorten the size of the feature set in previous work. For the evaluation of the proposed method, the experiments to classify 10 kinds of attacks and be nign traffic are performed against NSL_KDD data set."
기술력 평가항목을 이용한 매출액 고성장기업 판별력 검증,2018,"['기술금융', '기술력 평가', '기계학습', '의사결정나무모형', '매출액 고성장기업', 'Technology Financing', 'Technology Appraisal', 'Machine Learning', 'Decision Tree', 'Sales-high-growth Firms']",,"This study was started to verify whether the ‘forward-looking’ based technology appraisal model can be used to identify sales-high-growth firms in advance. The firms was divided into four groups according to the type of industry and the age of company, and the discriminant power of the model was verified through decision tree. As a result of the analysis, management capability and technology superiority were found to be a key variable for determining the sales-high-growth companies in all industries and the age of company. The classification accuracy of the model for the 4 clusters is 89-95% level, and confirming the possibility that the technology appraisal model can be applied to discriminate sales-high-growth companies."
포터블 수면유도 뉴로피드백 시스템 구현을 위한 수면뇌파 상태 분류기 성능 평가,2018,"['뉴로피드백', '뇌파', '분류기', '수면 유도', '기계학습', 'neurofeedback', 'brainwave', 'classifier', 'sleep induction', 'machine learning']","최근 많은 사람들이 불면증으로 인한 노동력저하, 인지기능저하, 정신질환 증가 등의 불편을 겪고 있다. 이에 대한 해결책은 인지치료나 약물치료가 거의 전부인 수준이나 부작용과 의존성 문제로 인해 장기적으로는 권장되지 않는 방법이 다. 따라서 본 논문에서는 수면 유도에 도움이 되는 포터블 뇌파 측정기 기반 뉴로피드백 시스템을 제안한다. 그리고 시스템 을 구현하는 데 가장 핵심적인 기능인 뇌파 상태 분류기를 설계하고 평가하며 성능에 영향을 미칠 수 있는 여러 요인들에 대해 최적화된 분류기 모델링 방법을 제시한다. 제안한 분류기를 이용할 시 포터블 뇌파 측정기에서 각성과 수면 단계를 97.9% 정확하게 구분할 수 있었다.","Recently, many people have suffered from insomnia, labor loss, cognitive decline, and mental illness. The solution to this problem is almost entirely cognitive therapy or medication, but it is not recommended in the long term due to side effects and dependency problems. Therefore, in this paper, we propose a neuro feedback system based on portable EEG that helps induce sleeping. We design and evaluate the EEG classifier, which is the most important function to implement the system, and propose an optimized classifier modeling method for various factors that can affect performance. When using the proposed classifier, we could distinguish 97.9% of awakening and sleep phase in portable EEG."
"Estimation of Leaf Area in Paprika Based on Leaf Length, Leaf Width, and Node Number Using Regression Models and an Artificial Neural Network",2018,"['canopy structure', 'leaf length-width ratio', 'leaf shape', 'machine learning', 'non-destructive method']",,
온라인 커뮤니티 사용자의 행동 패턴을 고려한 동일 사용자의 닉네임 식별 기법,2018,"['online community', 'behavior pattern', 'user identification', 'malicious user', 'data fragmentation', 'machine learning', '온라인 커뮤니티', '행동 패턴', '사용자 식별', '악의적 사용자', '데이터 파편화', '기계학습']","온라인 커뮤니티란 SNS와 달리 사용자들이 닉네임을 통해 익명으로 관심사와 취미를 공유하는 가상 그룹 서비스이다. 그런데 이런 익명성을 악의적으로 활용하는 사용자들이 존재하고, 닉네임의 변경으로 인해 동일 사용자의 데이터가 서로 다른 닉네임에 존재하는 데이터 파편화 문제가 발생할 수 있다.또한 온라인 커뮤니티에서는 닉네임을 변경하는 일이 빈번하므로 동일 사용자를 식별하는데 어려움을 겪는다. 따라서 본 논문에서는 이러한 문제를 해결하기 위해 온라인 커뮤니티 특성을 고려한 사용자의 행동패턴 특징 벡터를 제시하며, 관계 패턴이라는 새로운 암시적 행동 패턴을 제안함과 동시에 랜덤 포레스트 분류기를 이용한 동일 사용자의 닉네임을 식별하는 기법을 제안한다. 또한 실제 온라인 커뮤니티 데이터를 수집해 제안한 행동패턴과 분류기를 이용해 동일 사용자를 유의미한 수준으로 식별할 수 있음을 실험적으로 보인다.","An online community is a virtual group whose members share their interests and hobbies anonymously with nicknames unlike Social Network Services. However, there are malicious user problems such as users who write offensive contents and there may exist data fragmentation problems in which the data of the same user exists in different nicknames. In addition, nicknames are frequently changed in the online community, so it is difficult to identify them. Therefore, in this paper, to remedy these problems we propose a behavior pattern feature vectors for users considering online community characteristics, propose a new implicit behavior pattern called relationship pattern, and identify the nickname of the same user based on Random Forest classifier. Also, Experimental results with the collected real world online community data demonstrate that the proposed behavior pattern and classifier can identify the same users at a meaningful level."
텍스트 긍정 부정 평가: 러시아 국립 코퍼스를 중심으로,2018,"['sentiment analysis', 'positive and negative evaluation', 'digital diplomacy', 'dictionary of sentiment lexicon', 'machine learning', '감정분석', '긍부정 평가', '디지털 외교', '감정어휘사전', '기계학습']",,"This research aims to design a complex data platform for analyzing public opinion data in order to provide valuable insights for devising digital diplomacy strategy and thus maximizing South Korea’s public diplomacy capacity towards Russia and Central Asian countries. Big data analytics can be a powerful tool for not only national security management but also diplomatic negotiation and national branding. In order to make big data accommodate foreign policy needs, it is crucial to develop a program for sentiment analysis of SNS texts and online articles regarding South Korea. Emotional analysis means judging and classifying whether the text is affirmative or negative. A macroscopic research goal is to grasp the attitudes of Russian media and Russian people towards Korea, and to suggest directions for maximizing the positive reaction towards Korea through analyzing sentiment on Internet bulletin boards, SNS and blogs.In this year, which is the first year of the research, we would like to evaluate how many texts and comments related to Korean politics exist on the Russian SNS and to estimate a possibility of the emotional analysis in Russian media. First, we examine the precedent researches related to the emotional analysis. Second, we try to judge which approach would produce more accurate results in analyzing emotions."
사물인터넷 기반 한우 생산성 향상을 위한 발정 감지 시스템 구현,2018,"['Internet of things', 'Prediction analysis', 'Information management system', 'Machine learning', 'Estrus detection']",,"The integration of IoT and livestock management, particularly the use of the Internet and networking technology in existing automation devices, to observe and quantify environmental and animal conditions without limits in time or space, is called smart livestock farming. In particular, the observation of estrus and timing of fertilization account for the greatest proportion of livestock breeding management. This paper proposes IoT-based system that provides service of estrus detection to the user based on the activity of korean native cattle. The proposed estrus detection system provides an alarm service to user by diagnosing and analysing the estrus state of korean native cattle through the characteristic of increasing activity compared to the korean native cattle of weak estrus. In this study, acceleration sensors were attached to livestock in a farms with poor prediction to measure livestock activity and to analyze the collected to data to enable rapid response in case of atypical symptoms, such as various diseases and estrus, in order to suggest a better system. Upon estrus, livestock movement increases above normal, while movement decreases in diseased livestock. Based on these characteristics, a livestock movement monitoring system was designed using an acceleration sensor. Also, we can calculate the expected delivery time and the next estrus through the implementation of database for estrus detection of livestock. The economic benefits and competitive advantages can be improved in livestock farmhouse by implementing the developed technology of livestock IoT convergence."
순환신경망을 이용한 자기장 기반 실내측위시스템,2018,"['indoor localization', 'geomagnetic field', 'recurrent neural network', 'deep learning', 'machine learning', '실내 위치인식', '자기장', '순환신경망', '딥러닝', '기계학습']","BLE 는 Wi-Fi 기반 지문인식과 같은 기존의 RF 신호 기반 실내 치인식 기술은 RF 신호의 불안정한 수신 신 호 세기로 인해 소규모 실내 환경에서도 작지 않은 오차를 발생시키며 공항, 백화과 같은 규모 실내 환경에 용하기가 어렵다. 이 논문에서는 RF 신호보다 안정인 신호 강도를 갖는 자기장 신호를 이용한 실내측 시스템을 제안한다. 유사한 자기장 값이 같은 실내 공간에 여럿 존재하지만, 사용자의 이동이 계속됨에 따라 자기장 신호는 고유 시스를 가지게 된다. 본 논문에서는 시간에 따라 변화하는 센서 데이터 시스를 인식하는 데 효과인 순환 신경망 (Recurrent neural network, RNN)이라 불리는 심층 신경망 모델을 사용하여 사용자의 재 치와 이 동 경로를 추한다. 제안된 신경망 기반의 지자기 실내측시스템의 평가를 해 약 94m x 26m 크기의 교내 테 스트베드에서 자기장 맵을 구축하고 자기장맵으로부터 추출한 다양한 이동 경로와 치 정보를 이용하여 RNN을 학습한 결과, 테스트베드에서 제안된 시스템은 평균 1.20 미터의 테스트 측 오차를 달성할 수 있었다.","Conventional RF signal-based indoor localization techniques such as BLE or Wi-Fi based fingerprinting method show considerable localization errors even in small-scale indoor environments due to unstable received signal strength(RSS) of RF signals. Therefore, it is difficult to apply the existing RF-based fingerprinting techniques to large-scale indoor environments such as airports and department stores. In this paper, instead of RF signal we use the geomagnetic sensor signal for indoor localization, whose signal strength is more stable than RF RSS. Although similar geomagnetic field values exist in indoor space, an object movement would experience a unique sequence of the geomagnetic field signals as the movement continues. We use a deep neural network model called the recurrent neural network (RNN), which is effective in recognizing time-varying sequences of sensor data, to track the user's location and movement path. To evaluate the performance of the proposed geomagnetic field based indoor positioning system (IPS), we constructed a magnetic field map for a campus testbed of about 94m x 26 m dimension and trained RNN using various potential movement paths and their location data extracted from the magnetic field map. By adjusting various hyperparameters, we could achieve an average localization error of 1.20 meters in the testbed."
고성능 컴퓨팅을 활용한 뉴럴 네트워크 기반의 휴대용질병 진단 플랫폼 구현 방법론,2018,"['disease diagnosis', 'feature selection', 'neural network', 'high performance computing', 'machine learning']","본 논문에서는 고성능 컴퓨팅을 활용한 뉴럴 네트워크 기반의 휴대용 질병 진단 플랫폼 구현 방법론을 제안한다. 제안하는방법론은 임상 데이터 수집, 진단 알고리즘 및 반응 물질 선정, 진단 플랫폼 구현으로 구성된다. 진단 알고리즘 검증을 위해서 총 401명(정상인 314명, 간암환자 87명)의 혈액과 1,146개의 압타머(aptamer)로 구성된 마이크로 어레이로부터 얻어진 임상 데이터를 사용 하였다. 검증 결과, 최종적으로 32개의 선별된 압타머를 사용하여 97.5%로 간암 여부를 판별 할 수 있었다.이것을 바탕으로 32개의 생체 신호를 입력으로 가지는 휴대용 질병 진단 플랫폼을 설계 및 구현하였다.","In this paper, we proposed a methodology for portable disease diagnosis platform using high performance computing. The proposedmethodology consists of gathering clinical data, diagnosis and feature selection algorithm, implementation of diagnosis platform. For thealgorithm verification, a clinical data which is obtained from 401 people(314 normal subjects and 87 liver cancer patients) using amicroarray consists of 1,146 aptamers were used. As the result, we could diagnosis liver cancer with 97.5% accuracy using the 32selected aptamers. Based on these results, we designed and implemented a portable disease diagnosis platform which has 32 bio-signalsas inputs."
순환신경망을 이용한 뜰개의 관측 데이터 보정,2018,"['데이터 보정', '순환신경망', '기계학습', '예측', '뜰개', 'Data Correction', 'RNN', 'Machine Learning', 'Prediction', 'Drifter']","해양 뜰개는 해수면을 떠다니며 해양 기상 등을 관측하는 장비로, 뜰개를 통해 관측한 데이터는 해양 기상 예측, 유류유출 예측 등의 상황에서 활용된다. 관측 데이터는 관측 시에 오측(error data) 또는 결측(missing data)이 발생할 수 있으며, 오측 또는 결측된 데이터가 포함 될 경우, 데이터를 사용하는 모델들의 정확도가 떨어질 수 있다. 본 논문에서는 데이터 보정을 위한 방법으로 순환신경망을 이용한 데이터 보정 모델을 제안한다. 2015년 7개, 2016년 8개의 뜰개를 통해 수집한 해양 데이터를 이용한 보정 실험 결과와 보정 결과를 검증하기 위한 뜰개 이동 예측 실험을 설명하며, 실험 결과, 데이터 보정을 통해 13.9%의 데이터가 보정되었으며, 이동 예측 모델의 성능이 1.4% 향상되는 것을 보였다.","The ocean drifter is a device for observing the ocean weather by floating off the sea surface. The data observed through the drifter is utilized in the ocean weather prediction and oil spill. Observed data may contain incorrect or missing data at the time of observation, and accuracy may be lowered when we use the data. In this paper, we propose a data correction model using recurrent neural networks. We corrected data collected from 7 drifters in 2015 and 8 drifters in 2016, and conducted experiments of drifter moving prediction to reflect the correction results. Experimental results showed that observed data are corrected by 13.9% and improved the performance of the prediction model by 1.4%."
이종의 OCT 기기로부터 생성된 볼륨 데이터로부터 심층 컨볼루션 신경망을 이용한 AMD 진단,2018,"['OCT', '노년기황반변성(AMD)', '기계 학습', '컨볼루션 신경망', '이미지 분할', 'Optical Coherence Tomography', 'Age-Related Macular Degeneration', 'Machine Learning', 'Convolutional Neural Network', 'Image Segmentation']",신경망을 이용하여 OCT 영상을 분석하고 다양한 망막 질환을 자동 진단하는 것에 관한 연구들이 활발하게 이루어지고 있다. 이러한 연구가 현실에 적용되기 위한 하나의 중요한 요건은 학습된 신경망이 학습에 사용된 데이터와는 다른 기기에서 생성된 데이터에 대해서도 성능의 큰 하락 없이 일반화될 수 있어야 한다는 것이다.본 논문에서는 심층 CNN을 이용하여 OCT 영상으로부터 노년기황반변성(AMD)을 자동 진단하는 것을 다룬다. 하나의 OCT 기기로부터 획득한 데이터 셋을 이용하여 신경망을 학습시킨 후 다른 OCT 기기로부터 생산된 이미지를 테스트한 결과 상당한 성능의 하락을 관찰할 수 있었다. 이러한 성능의 하락을 방지하기 위해서 OCT 이미지를 정규화 하는 기법을 제안하고 실험을 통해 그 효과를 분석하였다. 제안한 기법은 OCT 이미지를 분할하여 망막에 해당하는 영역을 찾아낸 후 이미지 내에서 망막 영역이 수평에 가까운 기울기를 가지도록 정렬(align)하여 형태적인 측면에서 OCT 이미지를 정규화 하는 것을 목적으로 한다. 실험을 통하여 제안한 기법이 이종의 기기에서 생성된 OCT 이미지로부터 AMD를 자동진단 하는데 있어서 상당한 성능의 향상을 달성함을 보였다.,"There have been active research activities to use neural networks to analyze OCT images and make medical decisions. One requirement for these approaches to be promising solutions is that the trained network must be generalized to new devices without a substantial loss of performance. In this paper, we use a deep convolutional neural network to distinguish AMD from normal patients.The network was trained using a data set generated from an OCT device. We observed a significant performance degradation when it was applied to a new data set obtained from a different OCT device. To overcome this performance degradation, we propose an image normalization method which performs segmentation of OCT images to identify the retina area and aligns images so that the retina region lies horizontally in the image. We experimentally evaluated the performance of the proposed method. The experiment confirmed a significant performance improvement of our approach."
로지스틱 회귀모형과 의사결정나무 모형을 이용한 Cochlodinium polykrikoides 적조 탐지 기법 연구,2018,"['Red Tide', 'Ocean Color Remote Sensing', 'COMS/GOCI', 'Decision Tree', 'Machine Learning\r\n적조', '해수색 원격 탐사', '정지 궤도 해색 위성', '로지스틱 회귀 모형', '의사 결정 나무', '기계 학습']","본 연구에서는 기계학습 기법의 한 갈래인 로지스틱 회귀모형과 의사결정나무 모형을 이용하여 인공위성영상에서 Cochlodinium polykrikoides 적조 픽셀을 탐지하는 방법을 제안한다. 학습자료로 적조, 청수, 탁수해역에서 추출된 수출광량 분광 프로파일(918개)을 활용하였다. 전체 데이터셋의 70%를 추출하여 모형 학습에 활용하였으며, 나머지 30%를 이용하여 모형의 분류 정확도를 평가하였다. 정확도 평가 결과 로지스틱 회귀모형은 약 97%의 분류 정확도를 보였으며, 의사결정나무 모형은 약 86%의 분류 정확도를 보였다.","This study propose a new method to detect Cochlodinium polykrikoides on satellite images using logistic regression and decision tree.We used spectral profiles(918) extracted from red tide, clear water and turbid water as training data. The 70% of the entire data set was extracted and used for model training, and the classification accuracy of the model was evaluated by using the remaining 30%. As a result of the accuracy evaluation, the logistic regression model showed about 97% classification accuracy, and the decision tree model showed about 86% classification accuracy."
Kinect v2에서 얼굴점간 거리 특징에 의한 얼굴표정 인식,2018,"['얼굴표정', '감정인식', '기계학습', 'Action Unit', 'facial expression', 'emotion recognition', 'machine learning', 'action unit']","30명의 한국인을 대상으로 얼굴 표정 비디오 데이터를 수집하고, Action Unit(AU)과 관련된 얼굴 표정 변화의 기하학적 특성을 반영한 feature을 선정, 추출하여 학습시킴으로써 감정 상태를 분류하고자 한다. Kinect 카메라와 SDK를 활용하여 얼굴 비디오를 촬영하고, 6개 기본 감정과 관련된 AU 모두를 19개의 거리로 표현하고, 평균 무표정 얼굴에서의 거리와의 차이를 입력 feature로 삼는다. 그 후 ELM 과 RBF-SVM 알고리즘에 대해 다음 5종의 feature set에 대해 인식률을 비교 분석한다: Animation Unit(AnU) 세트, 유클리드 거리 및 수평/수직 거리 변화 2 세트, AnU과 거리 차 2 세트. 실험 결과, Kinect Animation Unit과 수평/수직 거리 조합으로 feature를 선택한 RBF-SVM 분류기에서 74.92%의 인식 정확도를 얻었다.","The purpose of this study is to classify any input facial video sequence into the six different emotional states by training the model feeding the extracted features that reflect the geometric characteristics of facial movement related to the basic emotion states. Using Kinect v2 to capture 3D facial video sequences for the subjects, the 17 Animation Units (AnUs) and the 3D positions of face points for each frame have been collected by taking advantage of Kinect SDK.Representing all the Action Units (AUs) related to the basic emotions as 19 distances, input features are described by the difference of the distances from those of average neutral facial expression. We analyze the recognition rates with the five different feature sets. The RBF-SVM classifier with the feature set combining AnU and the horizontal/vertical distance differences shows 74.92% recognition rate."
사람 걸음 탐지 및 배경잡음 분류 처리를 위한도플러 레이다용 딥뉴럴네트워크,2018,"['Doppler Radar', 'Deep Neural Network', 'Micro-Doppler', 'Radar Pattern Recognition', 'Radar Machine Learning', '-']",,"The effectiveness of deep neural networks (DNNs) for detection and classification of micro-Doppler signals generated by human walking and background noise sources is investigated. Previous research included a complex process for extracting meaningful features that directly affect classifier performance, and this feature extraction is based on experiences and statistical analysis. However, because a DNN gradually reconstructs and generates features through a process of passing layers in a network, the preprocess for feature extraction is not required. Therefore, binary classifiers and multiclass classifiers were designed and analyzed in which multilayer perceptrons (MLPs) and DNNs were applied, and the effectiveness of DNNs for recognizing micro-Doppler signals was demonstrated.Experimental results showed that, in the case of MLPs, the classification accuracies of the binary classifier and the multiclass classifier were 90.3% and 86.1%, respectively, for the test dataset. In the case of DNNs, the classification accuracies of the binary classifier and the multiclass classifier were 97.3% and 96.1%, respectively, for the test dataset."
기술력 평가항목을 이용한 고수익 중소기업 판별력 검증,2018,"['기술금융', '기술력 평가', '기계학습', '의사결정나무모형', '고수익기업', 'Technology Financing', 'Technology Appraisal', 'Machine Learning', 'Decision Tree', 'High-profit Firms']","본 연구는 기업의 기술력을 기술성, 시장성, 사업성 관점에서 평가하는 기술력 평가모형이 영업이익률 기준의 고수익기업을 사전에 판별하는 데 적용될 수 있는지를 검증하는데 목적이 있다. 기업을 업종(제조업 vs. 非제조업)과 업력(창업기업 vs. 非창업기업)으로 구분하고, 해당 군집의 평균 매출액 영업이익률 2배 이상 달성한 기업을 고수익기업으로 정의한 후, 의사결정나무모형을 통해 모형의 판별력을 검증하였다. 분석결과 기술우위성과 기술개발역량이 고수익기업 여부를 결정하는 중요한 변수로 도출되었으며, 업력이 증가함에 따라 기업의 수익성을 결정하는 중요변수가 단순 기술차별성에서 지속적으로 기술우위성을 유지하게끔 하는 기술개발 인프라로 변화한다는 결론이 도출되었다. 모형의 분류 정확도는 非제조업 창업기업군을 제외하면 76-88% 수준으로, 기술력 평가모형이 고수익기업 판별에 적용될 수 있다는 가능성을 확인하였으며, 정부가 중소기업 지원정책 수립 시 업종과 업력에 따라 차별화된 지원책을 설계하는데 사용될 수 있을 것으로 판단된다.","The purpose of this study is to verify whether the technology appraisal model can be applied to distinguish high-profit firms. We classified companies into industries (manufacturing vs. non-manufacturing) and age of company(initial vs. non-initial), and defined companies with high operating margins of more than two times as high-profit companies. As a result of decision tree model analysis, technology superiority and R&D capability were found to be important variables for determining high-profit companies. Also, as the age of company increase, it is concluded that the crucial variable that determines the profitability of the company changes from the simple technology differentiation to the technology development infrastructure which maintains the technology superiority continuously. The classification accuracy of the model is 76~88% level excluding the non-manufacturing initial company group, confirming the possibility that the technology appraisal model can be applied to discriminate high-profit companies. These results suggest that the government can be used to design differentiated supports plans according to the industry and the age of company when establishing SMEs support policies."
하이브리드자동차 장기간 주행데이터 분석,2018,"['Hybrid electric vehicle', 'OBD-II', 'Driving data', 'Mileage', 'Machine learning']",,"In this work, we analyze the relationship between the accumulated mileage of hybrid electric vehicle(HEV) and the data provided from vehicle parts. Data were collected while traveling over 70,000 Km in various paths. The data collected in seconds are aggregated for 10 minutes and characterized in terms of centrality, variability, normality, and so on. We examined whether the statistical properties of vehicle parts are different for each cumulative mileage interval of a hybrid car. When the cumulative mileage interval is categorized into =< 30,000, <= 50,000, and >50,000, the statistical properties are classified by the mileage interval as 82.3% accuracy. This indicates that if the data of the vehicle parts is collected by operating the hybrid vehicle for 10 minutes, the cumulative mileage interval of the vehicle can be estimated. This makes it possible to detect the abnormality of the vehicle part relative to the accumulated mileage. It can be used to detect abnormal aging of vehicle parts and to inform maintenance necessity."
빅데이터 분석을 이용한 환경사무의 사회적 평가,2018,"['빅데이터 분석', '환경사무', '사회적 평가', '감성분석', '기계학습', 'Big Data Analysis', 'Environmental Administration', 'Social Evaluation', 'Sentiment Analysis', 'Machine Learning']",,"Using a big data-based approach, this study examines the societal evaluation of environmental administration before and after the devolution of administrative power from the central government to local governments. We have employed a big data-based analysis as the methodology to explore society’s assessment of administrative performance during each period. The term environmental administration is operationally defined as the environmental responsibilities that have been transferred from the central government to the local government. These can be classified into four parts: air quality, the natural environment, public health, and resource recirculation. The results of this study show the that society’s evaluation of environmental administration at the level of local government has been decidedly more negative than that of the central government. However, it should be noted that the proportion of negative evaluation has been decreasing over time. This study indicates that the central government is considered to be more qualified in conducting environmental administration than local governments."
Impact of Instance Selection on kNN-Based Text Categorization,2018,"['Classification Accuracy', 'Classification Efficiency', 'Data Reduction', 'Instance Selection', 'k-Nearest Neighbors', 'Text Categorization']",,"With the increasing use of the Internet and electronic documents, automatic text categorization becomes imperative. Several machine learning algorithms have been proposed for text categorization. The k-nearest neighbor algorithm (kNN) is known to be one of the best state of the art classifiers when used for text categorization. However, kNN suffers from limitations such as high computation when classifying new instances. Instance selection techniques have emerged as highly competitive methods to improve kNN through data reduction. However previous works have evaluated those approaches only on structured datasets. In addition, their performance has not been examined over the text categorization domain where the dimensionality and size of the dataset is very high. Motivated by these observations, this paper investigates and analyzes the impact of instance selection on kNN-based text categorization in terms of various aspects such as classification accuracy, classification efficiency, and data reduction."
알고리즘화(Algorithmification),2018,"['미디어화', '소프트웨어화', '알고리즘화', '미디어 논리', '기계 학습', '표상의 표상', 'mediatization', 'softwarization', 'algorithmification', 'media logic', 'machine learning', 'representation of representation']","이 글은 미디어 논리 관점에서 미디어의 발전 과정을 세 단계로 나눠 설명한다. 일상생활(everyday life)의 매개(mediation)로서 ‘미디어화’, 미디어의 표상으로서 ‘소프트웨어화’, 표상(representation)의 표상으로서 ‘알고리즘화’다. 현재 미디어 논리의 핵심을 알고리즘으로 규정하고 알고리즘화된 미디어 환경의 특성을 논의한다. 알고리즘은 절차를 규정한 코드의 집합이라기보다는 사회적으로 구성되어 제도적으로 운영되고 있는 체제로 볼 필요가 있다. 알고리즘은 새로운 지식 논리(knowledge logic)로서 이는 기존 미디어의 편집 논리(editorial logic)와 경쟁하는 논리다. 편집논리는 훈련과 확인, 혹은 시장논리를 통한 정당화 등을 통한 제도적 과정을 통해 정당성을 얻는 전문가들의 주관적인 선택에 의존한다. 알고리즘 논리는 인간의 판단을 자동화하고 수집된 사회적 흔적들의 패턴을 밝히기 위해 사람 운영자가 고안한 기계의 절차적인 선택에 의존한다.","This study explained the development process of media in three stages from the viewpoint of media logic. First, `mediation` is a mediation of everyday life, second, `softwareization` is a representation of media, and third `algorithmification` is a representation of representation. This article defined the core of current media logic as algorithm and discussed characteristics of algorithmificated media environment. The algorithm is not just a set of code according to the procedure, but it needs to be viewed as a socially constructed and institutionally operated system. Algorithm is a new knowledge logic which compete with editorial logic of existing media. Editorial logic relies on the subjective choice of professionals who gain legitimacy through institutional processes. Conversely, algorithmic logic relies on the procedural choice of machines designed by human operators to automate human judgment or to reveal patterns in collected social traces."
A Linguistic Study of Speech Act and Automatic Speech Act Classification for Korean Tutorial Dialog,2018,"['화행', '화행 자동분류', '화행 분류 자질', '기계학습', 'Speech act', 'Automatic speech act classification', 'Linguistic feature', 'Machine learning']",,
Impact of Instance Selection on kNN-Based Text Categorization,2018,"['Classification Accuracy', 'Classification Efficiency', 'Data Reduction', 'Instance Selection', 'k-Nearest Neighbors', 'Text Categorization']",,"With the increasing use of the Internet and electronic documents, automatic text categorization becomes imperative. Several machine learning algorithms have been proposed for text categorization. The k-nearest neighbor algorithm (kNN) is known to be one of the best state of the art classifiers when used for text categorization. However, kNN suffers from limitations such as high computation when classifying new instances. Instance selection techniques have emerged as highly competitive methods to improve kNN through data reduction. However previous works have evaluated those approaches only on structured datasets. In addition, their performance has not been examined over the text categorization domain where the dimensionality and size of the dataset is very high. Motivated by these observations, this paper investigates and analyzes the impact of instance selection on kNN-based text categorization in terms of various aspects such as classification accuracy, classification efficiency, and data reduction."
A Twitter News-Classification Scheme Using Semantic Enrichment of Word Features,2018,"['트위터 뉴스 분류', '단어 특징의 의미적 보강', '기계 학습', '인공 신경망', 'twitter news classification', 'semantic enrichment of word features', 'machine learning', 'artificial neural network']",,
인공지능(AI)과 로봇기술의 전개에 따른 호텔산업종사원의 인식과 영향 및 대응방안 연구,2018,"['4th Industrial Revolution', 'Artificial Intelligence(AI) and Robotics', 'Hotel Industry Employees Recognition', 'Job Substitution']",,"As the age of the fourth industrial revolution comes, automation technologies such as machine learning and artificial intelligence are affecting the profession of the tourism industry. The more specific purpose of this study was to analyze the recognition of hotel employee for job replacement level and influences of artificial intelligence and Robot service.As for the results of analysis, managers are more aware of the introduction of artificial intelligence and robot services than employees. it is analyzed that the possibility of substitution of artificial intelligence technology is shown as the reservation management rather then sales marketing field. In addition, human services related to the impact of artificial intelligence have positive effects on replacement efficiency, productivity and management efficiency. Finally, it was analyzed that manager 's perception change and response positively influenced future artificial intelligence. It also shows that the development of artificial intelligence technology is expected to be influential throughout the hotel industry in the near future, it is inevitable that a collaborative network both academia and industry sector should be established. especially, it is said that they should train artificial intelligence and big data experts in tourism field. Several academic and practical implications are suggested."
오픈소스 기반 빅데이터 플랫폼의 에너지 하베스터최적설계 적용 연구,2018,"['Electromagnetic Vibration Energy Harvester(전자기형 진동 에너지 하베스터)', 'Hadoop(하둡)', 'Design Optimization(설계 최적화)', 'Machine Learning(기계 학습)', 'R(알)']",,"Recently, as interest in the internet of things has increased, a vibration energy harvester has attractedattention as a power supply method for a wireless sensor. The vibration energy harvester can be divided intopiezoelectric types, electromagnetic type and electrostatic type, according to the energy conversion type. Theelectromagnetic vibration energy harvester has advantages, in terms of output density and design flexibility,compared to other methods. The efficiency of an electromagnetic vibration energy harvester is determined bythe shape, size, and spacing of coils and magnets. Generating all the experimental cases is expensive, interms of time and money. This study proposes a method to perform design optimization of anelectromagnetic vibration energy harvester using an open source, big data platform."
EU GDPR상 프로파일링 규정의 법적 분석,2018,"['프로파일링', 'GDPR', '개인정보보호', '정보주체', '컨트롤러', '자동화된 의사결정', '민감정보', 'profiling', 'data protection', 'data subjects', 'controllers', 'automated decision-making', 'special categories of personal data']","프로파일링은 금융, 건강, 마케팅과 광고 등 다양한 부문에서 의사결정에 도움을 준다. 빅데이터 분석기술, 인공지능 및 머신 러닝 등 과학기술적 발전으로 프로파일의 생성과 자동화된 의사결정이 보다 용이하게 되었고, 결과적으로 개인의 권리와 자유에도 중대한 영향을 주게 되었다. 개인이 이러한 프로파일링 등에서 자신의 개인정보의 처리 여부 및 그 과정을 이해하기 어렵다는 사실이 문제이고, 프로파일링으로 개인이 특정유형으로 분류됨에 따라 기존의 편견이나 사회적 격리 또는 차별에 따른 피해를 입게 될 수도 있다. 경우에 따라서는 프로파일링을 통한 예측이 정확하지 않을 수 있고 이런 경우 개인의 권리와 자유의 침해는 더욱 부당하게 될 수 있을 것이다.프로파일링을 명시적으로 규정하고 있는 유럽연합의 GDPR은 프로파일링을 포함한 자동화된 처리에만 기초한 의사결정에 따라 정보주체가 피해를 보지 않도록 규정하고 있다. 자동화된 의사결정에 관하여 GDPR은 1995년 개인정보보호지침과 유사한 제한을 두고 있지만, 다음과 같이 중요한 사항을 변경하였다. 첫째, 프로파일링의 개념을 정의하고 있고, 둘째, 정보주체의 명시적 동의가 프로파일링을 포함하는 자동화된 처리에만 기초한 결정을 허용하는 새로운 법적 근거가 되며, 셋째, 민감정보에 기초한 프로파일링을 포함하는 자동화된 처리에만 기초한 결정을 예외적으로 허용하고, 넷째, 컨트롤러는 정보주체에게 프로파일링에 관한 정보를 고지할 의무가 있으며, 다섯째, 개인정보의 역외이전을 허용하는 ‘구속력 있는 기업규칙’ (Binding Corporate Rules)은 최소한 14개 요건을 명시해야 하는데, 프로파일링을 포함하여 자동화된 처리에만 근거한 결정을 따르지 않을 권리가 포함되어야 한다.한국은 개인정보보호법 등에서 프로파일링을 포함한 자동화된 의사결정을 규정하지는 않지만, 일부 관련된 규정을 두고 있다. 이제 국내에서도 제4차 산업혁명에 순응하여 경제사회적 발전을 도모하는 마당에 개인정보보호법에 분명하게 프로파일링을 포함한 자동화된 의사결정에 대한 규정을 포함하도록 개정이 이루어질 필요가 있다. 개인정보보호 차원에서 정보주체와 개인정보처리자의 이익이 균형을 이루어져야 할 것이며, 이 점에서 GDPR이 좋은 선례가 될 수 있다.","Profiling helps decision-making in various areas such as finance, health, marketing and advertisement. Scientific and technological advancements with big data analytics, artificial intelligence and machine learning are making easier the creation of profiles and the consequent decision-making. However, the rights and freedoms of individuals, here data subjects for data protection purposes, would be negatively affected by those advancements. It must be a serious matter that individuals would not easily find the fact of processing of their personal data in this context and how the processing goes. They are likely to be subject to risks of unreasonable social segregation or discrimination from a certain way of classification. The assessments through profiling may not always be correct, and in this case the rights and freedoms of those individuals may be further breached unjustifiably.The General Data Protection Regulation (GDPR) of the European Union, to be applicable on 25 May 2018, provides for profiling explicitly. It provides for specific provisions that individuals are not to suffer from decisions solely based on automated processing including profiling. As to the provisions on automated decision-making, while GDPR is roughly similar to 1995 Directive, it has the following important changes. First, the concept of profiling is introduced. Second, the explicit consent of data subjects is a new lawful basis allowing decisions solely based on automated processing including profiling. Third, those decisions above are exceptionally allowed even for special categories of personal data. Fourth, controllers are obligatory to provide the information on profiling to data subjects. Fifth, binding corporate rules must contain the right of data subjects not to be subject to those decisions above.Korean laws on data protection have certain provisions relating to profiling, although they are not directly dealing with it. As the ways to take advantage of the fourth industrial revolution are seriously explored these days, it is a right time to provide the specific rules on profiling in those laws on data protection. There must be a right balance in data protection between data subjects and data processors in Korean terminologies. GDPR must be a good model for the Korean data protection laws in this respect."
메모리 요소를 활용한 신경망 연구 동향,2018,"['Recurrent Neural Networks', 'Memory-Augmented Neural Networks', 'Memory Component', 'Memory Networks', 'Neural Turing Machines', 'Stack-Augmented Neural Networks', '순환 신경망', '메모리-증대 신경망', '메모리 요소', '메모리 네트워크', '뉴럴 튜링 머신', '스택-증대 신경망']",,"Recently, recurrent neural networks have been attracting attention in solving prediction problem of sequential data through structure considering time dependency. However, as the time step of sequential data increases, the problem of the gradient vanishing is occurred. Long short-term memory models have been proposed to solve this problem, but there is a limit to storing a lot of data and preserving it for a long time. Therefore, research on memory-augmented neural network (MANN), which is a learning model using recurrent neural networks and memory elements, has been actively conducted. In this paper, we describe the structure and characteristics of MANN models that emerged as a hot topic in deep learning field and present the latest techniques and future research that utilize MANN."
잠재 의미 분석을 적용한 유사 특허 검색 서비스 시스템,2018,,,"Keyword searching used in the past as a method of finding similar patents, and automated classification by machine learning is using in recently. Keyword searching is a method of analyzing data that is formalized through data refinement. While the accuracy for short text is high, long one consisted of several words like as document that is not able to analyze the meaning contained in sentences. In semantic analysis level, the method of automatic classification is used to classify sentences composed of several words by unstructured data analysis. There was an attempt to find similar documents by combining the two methods. However, it have a problem in the algorithm w the methods of analysis are different ways to use simultaneous unstructured data and regular data. In this paper, we study the method of extracting keywords implied in the document and using the LDA(Latent Semantic Analysis) method to classify documents efficiently without human intervention and finding similar patents."
텍스트의 긍정 부정 평가: 러시아 국립 코퍼스를 중심으로,2018,"['감정분석', 'sentiment analysis', '긍부정 평가', 'positive and negative evaluation', '디지털 외교', 'digital diplomacy', '감정어휘사전', 'dictionary of sentiment lexicon', '기계학습', 'machine learning']",,"This research aims to design a complex data platform for analyzing public opinion data in order to provide valuable insights for devising digital diplomacy strategy and thus maximizing South Korea’s public diplomacy capacity towards Russia and Central Asian countries. Big data analytics can be a powerful tool for not only national security management but also diplomatic negotiation and national branding. In order to make big data accommodate foreign policy needs, it is crucial to develop a program for sentiment analysis of SNS texts and online articles regarding South Korea. Emotional analysis means judging and classifying whether the text is affirmative or negative. A macroscopic research goal is to grasp the attitudes of Russian media and Russian people towards Korea, and to suggest directions for maximizing the positive reaction towards Korea through analyzing sentiment on Internet bulletin boards, SNS and blogs. In this year, which is the first year of the research, we would like to evaluate how many texts and comments related to Korean politics exist on the Russian SNS and to estimate a possibility of the emotional analysis in Russian media. First, we examine the precedent researches related to the emotional analysis. Second, we try to judge which approach would produce more accurate results in analyzing emotions."
기계학습 알고리즘을 사용한 스포츠 경기장 방문객 마케팅 적용 방안,2018,"['데이터 분석', 'K-평균 군집화', 'K-근접 이웃', '기계학습 알고리즘', '스포츠마케팅', 'Big Data Analytics', 'K-Means Clustering', 'K-NN', 'Machine Learning Algorithm', 'Sport Marketing']",,
코드 분포의 선형 회귀를 이용한 프로그램 유사성 분석,2018,"['선형 회귀', '기계 학습', '유사성 분석', '코드 분석', '코드 분포', 'Code analysis', 'Code distribution', 'Linear regression', 'Machine learning', 'Similarity analysis']",,
모노 카메라 영상기반 시간 간격 윈도우를 이용한 광역 및 지역 특징 벡터 적용 AdaBoost기반 제스처 인식,2018,"['3D 제스처 인식', '패턴 인식', '기계 학습', 'AdaBoost 알고리즘', '신체 분할', '3D Gesture Recognition', 'Pattern Recognition', 'Machine Learning', 'AdaBoost', 'Body Segmentation']","최근 안드로이드, iOS 등의 셋톱박스 기반의 스마트 TV에 대한 보급에 따라 제스처로 TV를 컨트롤 할 수 있는 새로운 접근을 제안한다. 본 논문에서는 모노 카메라 센서를 이용한 AdaBoost 기반 제스처 인식에 관한 알고리즘을 제안한다. 우선, 신체 좌표 추출을 위해 가우시안 배경 제거 및 Camshift 기반 자세 추적 및 추정 알고리즘을 사용한다. AdaBoost 학습 모델을 신체 정규화된 광역 및 지역 특징 벡터의 집합을 특징 패턴으로 하여, 속도가 다른 동작들을 인식할 수 있도록 하였다. 또한 속도가 다른 다양한 제스처를 인식하기 위해 다중 AdaBoost 알고리즘을 적용하였다. CART 알고리즘을 이용하여 성공적인 중요 특징 벡터를 확인하고 중요도가 낮은 특징벡터를 제거하는 방식을 적용하면서 분류 성공률이 높은 최적의 특징 벡터를 탐색하였다. 그 결과 24개의 주성분 특징 벡터를 찾았으며, 기존 알고리즘에 비해 낮은 오분류율(3.73%)과 높은 인식률(95.17%)을 지닌 특징 벡터 및 분류기를 설계하였다.","Recently, the spread of smart TV based Android iOS Set Top box has become common. This paper propose a new approach to control the TV using gestures away from the era of controlling the TV using remote control. In this paper, the AdaBoost algorithm is applied to gesture recognition by using a mono camera. First, we use Camshift-based Body tracking and estimation algorithm based on Gaussian background removal for body coordinate extraction. Using global and local feature vectors, we recognized gestures with speed change. By tracking the time interval trajectories of hand and wrist, the AdaBoost algorithm with CART algorithm is used to train and classify gestures. The principal component feature vector with high classification success rate is searched using CART algorithm. As a result, 24 optimal feature vectors were found, which showed lower error rate (3.73%) and higher accuracy rate (95.17%) than the existing algorithm."
Multi-objective Bayesian optimization of chemical reactor design using computational fluid dynamics,2018,"['Multi-objective optimization', 'Bayesian optimization', 'Computational fluid dynamics', 'CFD-based optimization', 'Reactor design', 'Machine learning']",,"<P><B>Abstract</B></P>  <P>This study presents a computational fluid dynamics (CFD) based optimal design tool for chemical reactors, in which multi-objective Bayesian optimization (MBO) is utilized to reduce the number of required CFD runs. Detailed methods used to automate the process by connecting CFD with MBO are also proposed. The developed optimizer was applied to minimize the power consumption and maximize the gas holdup in a gas-sparged stirred tank reactor, which has six design variables: the aspect ratio of the tank, the diameter and clearance of each of the two impellers, and the gas sparger. The saturated Pareto front is obtained after 100 iterations. The resulting Pareto front consists of many near-optimal designs with significantly enhanced performances compared to conventional reactors reported in the literature. We anticipate that this design approach can be applied to any process unit design problems that require a large number of CFD simulation runs.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Multi-objective Bayesian optimization (MBO) using a CFD chemical reactor model is conducted. </LI> <LI>  Automated optimal design procedure of chemical reactors based on CFD is proposed. </LI> <LI>  Six design variables of gas-sparged stirred tank reactor are optimized and the saturated Pareto front are obtained within 90 CFD simulations. </LI> <LI>  The optimized designs showed significantly enhanced power consumption and gas holdup compared to initial and conventional designs. </LI> </UL> </P>"
표면 근전도를 이용한 손동작 인식,2018,"['Surface Electromyogram(표면 근전도)', 'Hand Gesture Classification(손동작 분류)', 'Pattern Recognition(패턴 인식)', 'Machine Learning(기계 학습법)', 'k-nearest Neighbor(k-근접 이웃)']",,
스마트 디바이스에 적용한 기계학습기반 이미지 분류 어플리케이션,2018,"['사물인터넷', '인공지능', '이미지 분류', '스마트워치 어플리케이션', 'Internet of things', 'Artificial intelligence', 'Image classification', 'Smartwatch application']","본 논문은 사물인터넷과 인공지능 기술을 적용한 이미지 분류 기법을 제안한다. 제안한 분류 기법은 과일과 채소 등을 인식하는데 사용하며, 대상 사물을 분별한 후 이 사물이 포함된 조리 기법을 추천하는 기능을 제공하는 어플리케이션을 구현한다. 어플리케이션은 조리 기법 책에서 제공하는 재료(종류 및 무게), 조리 순서 등의 모든 정보를 사용자에게 제공하도록 구현하고, 또한 조리 대상 사물을 인식하는 컨볼루션널 신경망 기반 인공지능 기술도 추가하여조리의 편리성을 향상하도록 한다. 스마트워치에서는 사용자의 일일 운동량 및 생체 정보를 바탕으로 사용자에게 가장 적합한 주스 조리 기법을 추천하는 기능을 제공하도록 어플리케이션을 구현한다.","This paper combines two of the most recent research topics for consumer electronic devices: Internet of Things (IoT) and Artificial Intelligence (AI), applied to solve an image classification problem for an electrical appliance’s recipe database. The first part of this article presents the development of an Android mobile application containing all the options from its recipe book manual. The problem addresses the inconvenience to manually search over the catalog categories to find the recipe that matches the actual ingredient available for the users in their home. The proposed solution establishes to recognize the ingredient with the mobile device camera using transfer learning over a pre-trained Convolutional Neural Network (CNN) to distinguish between the recipes that uses the ingredient, and exclude the recipe sets that are unrelated to the ingredient acquired with the camera. In the second part of the article, the availability of sensors on most of the wrist smartwatches and fitness bands is exploited to categorize the users according to the level of physical activity, in pursuance of making a healthy recommendation according to the number of calories in each of the recipes."
A Recognition of Violence Using Mobile Sensor Fusion in Intelligent Video Surveillance Systems,2018,"['지능형 CCTV', '폭력행위 인식', '인간행동인식', '옵티컬 플로우', '모바일 센서 융합', '기계 학습', 'intelligent video surveillance systems', 'violence detection', 'human activity recognition', 'optical flow', 'mobile sensor fusion', 'machine learning']",,
텍스트 마이닝을 이용한 갑상선암 관련 국내 연구 추세 분석,2018,"['hierarchical clustering', 'social network', 'text mining', 'thyroid cancer', 'word cloud']",,"In this paper, we propose a text-centered approach to identify the research trend of thyroid cancer in Korea. We incorporate statistical analysis, text mining and machine learning techniques with our clinical insights to find connective associations between terminologies and to discover informative clusters of literatures. The incidence of thyroid cancer in Korea increased rapidly in the 2000s, which fueled the debate regarding overdiagnosis, but recently the number of patients undergoing surgery has decreased significantly due to conscious reform efforts from various circles. We analyzed the abstracts and keywords of related research papers from DBpia. It was found that most were case reports in the 1980s, and some papers in the 1990s discussed the early detection of thyroid cancer by mass screening. While many papers focused on different diagnostic techniques and the detection of small cancers in the 2000s, many emphasized more on the quality of life of patients in the 2010s. There was an apparent change in the topics of thyroid cancer research over past decades. The results of this study would serve as a reference guide for current and future research directions."
Deep Convolutional Neural Network를 이용한 주차장 차량 계수 시스템,2018,"['주차장 관리', '물체 감지', '컴퓨터 비전', '기계 학습', '감시 카메라', 'deep convolutional neural network', 'Parking lot management', 'Object detection', 'Computer vision', 'Machine learning', 'Deep convolutional neural network', 'Surveillance camera.']",,
Marine gas turbine monitoring and diagnostics by simulation and pattern recognition,2018,"['Monitoring and diagnostics', 'Artificial neural networks', 'Ship simulation', 'Ship propulsion', 'Gas turbines']",,"Several techniques have been developed in the last years for energy conversion and aeronautic propulsion plants monitoring and diagnostics, to ensure non-stop availability and safety, mainly based on machine learning and pattern recognition methods, which need large databases of measures. This paper aims to describe a simulation based monitoring and diagnostic method to overcome the lack of data. An application on a gas turbine powered frigate is shown. A MATLAB-SIMULINK(R) model of the frigate propulsion system has been used to generate a database of different faulty conditions of the plant. A monitoring and diagnostic system, based on Mahalanobis distance and artificial neural networks have been developed. Experimental data measured during the sea trials have been used for model calibration and validation. Test runs of the procedure have been carried out in a number of simulated degradation cases: in all the considered cases, malfunctions have been successfully detected by the developed model."
Significance of variable selection and scaling issues for probabilistic modeling of rainfall-induced landslide susceptibility,2018,"['Landslide', 'Variable selector', 'Weka', 'Probability map', 'Susceptibility', 'Lake Atitla´n']",,"Identifying the input variables/attributes for probabilistic modeling of rainfall-induced landslides is critical for effective landslide susceptibility characterization.This study evaluates the capabilities of different attribute selectors available in Weka, an open source machine learning software, for identifying the most landslide-predictive combination of attributes. The study area is located in the Lake Atitla´n watershed in Guatemala, which is highly susceptible to landslides during the rainy season.Landslide initiation points were delineated in the field as well as in the ortho-photos, which were taken following Hurricane Stan of October 2005. Two datasets spanning different sized areas were used to compare the success of attribute selectors and to determine if the model results from the smaller area could be successfully applied to the larger one. The Weka Bayesian network classification algorithm was used to evaluate the success of different attribute selection methods and to identify the combination of attributes with the highest rate of landslide prediction for the two study areas. Filtered subset proved to be the most successful in identifying the ideal combination for both the smaller and the larger scale datasets."
Marine gas turbine monitoring and diagnostics by simulation and pattern recognition,2018,"['Monitoring and diagnostics', 'Artificial neural networks', 'Ship simulation', 'Ship propulsion', 'Gas turbines']",,"Several techniques have been developed in the last years for energy conversion and aeronautic propulsion plants monitoring and diagnostics, to ensure non-stop availability and safety, mainly based on machine learning and pattern recognition methods, which need large databases of measures. This paper aims to describe a simulation based monitoring and diagnostic method to overcome the lack of data. An application on a gas turbine powered frigate is shown. A MATLAB-SIMULINK® model of the frigate propulsion system has been used to generate a database of different faulty conditions of the plant. A monitoring and diagnostic system, based on Mahalanobis distance and artificial neural networks have been developed. Experimental data measured during the sea trials have been used for model calibration and validation. Test runs of the procedure have been carried out in a number of simulated degradation cases: in all the considered cases, malfunctions have been successfully detected by the developed model."
대화형 인공지능의 윤리적 언어 표현을 위한 기초 연구,2018,"['대화형 인공지능', '비윤리적 언어 표현', '욕설', '비어', '속어', '공격성', '비하성', '맥락', '내용', 'interactive artificial intelligence', 'unethical linguistic expressions', 'swear word', 'vulgar word', 'derogatory slang', 'aggression', 'degradation', 'context', 'content']",,"The purpose of this study is to set up the concept and classification standard of unethical linguistic expressions(ULEs) as word unit that can appear in the machine learning of interactive artificial intelligence systems and humans conversation. The study also examined the characteristics of each type, based on examples. According to the results of the study, ULEs as word unit can be divided into three categories: ‘swear words’, ‘vulgar words’, and ‘derogatory slangs’. These three types are common in that they are all regarded as ULEs in any variance of emergence. However, they differ in two attributes, aggression and degradation. This study also suggests that there are two other types of ULEs: the ‘Context’ type, in which certain expressions may or may not be used unethically according to the context, and the ‘Content’ type, which can not be considered unethical linguistic expression in of itself, but its related content can be unethical linguistic expression overall. Therefore, this study identifies that the word-based unethical linguistic expression is classified into five types such as ‘swear words’, ‘vulgar words’, ‘derogatory slang’, ‘context’, and ‘content’, and each of these characteristics and examples were reviewed extensively."
Causal Inference Network of Genes Related with Bone Metastasis of Breast Cancer and Osteoblasts Using Causal Bayesian Networks,2018,"['Bayes theorem', 'Breast neoplasms', 'Neoplasm metastasis', 'Osteoblasts']",,"Background: The causal networks among genes that are commonly expressed in osteoblasts and during bone metastasis (BM) of breast cancer (BC) are not well understood. Here, we developed a machine learning method to obtain a plausible causal network of genes that are commonly expressed during BM and in osteoblasts in BC. Methods: We selected BC genes that are commonly expressed during BM and in osteoblasts from the Gene Expression Omnibus database. Bayesian Network Inference with Java Objects (Banjo) was used to obtain the Bayesian network. Genes registered as BC related genes were included as candidate genes in the implementation of Banjo. Next, we obtained the Bayesian structure and assessed the prediction rate for BM, conditional independence among nodes, and causality among nodes. Furthermore, we reported the maximum relative risks (RRs) of combined gene expression of the genes in the model. Results: We mechanistically identified 33 significantly related and plausibly involved genes in the development of BC BM. Further model evaluations showed that 16 genes were enough for a model to be statistically significant in terms of maximum likelihood of the causal Bayesian networks (CBNs) and for correct prediction of BM of BC. Maximum RRs of combined gene expression patterns showed that the expression levels of UBIAD1, HEBP1, BTNL8, TSPO, PSAT1, and ZFP36L2 significantly affected development of BM from BC. Conclusions: The CBN structure can be used as a reasonable inference network for accurately predicting BM in BC."
Industrial Internet of Things Based Efficient and Reliable Data Dissemination Solution for Vehicular Ad Hoc Networks,2018,,,"<P>Industrial Internet of Things (IIoT) is the other name of industrial Internet. It integrates a variety of existing industrial automation technologies with computing, machine learning, and communication technologies. Vehicular ad hoc network, an application of IIoT, is a self-organized network of vehicles which tends to provide improved road safety, diminished traffic congestion, and ultimate comfort to the travellers. In VANETs, vehicles exchange data with each other directly or through roadside units (RSUs). Data dissemination in VANETs experiences numerous challenging issues including broadcast storm, network partitions, intermittent connectivity between vehicles, and limited bandwidth. In literature, various data dissemination schemes are proposed. However, most of these schemes are designed for either urban or highway VANET scenarios and evaluated under sparse or dense traffic conditions. Moreover, these schemes do not effectively overcome the aforementioned issues simultaneously. In this paper, we present a new data dissemination protocol for VANETs, which disseminates the emergency messages in different scenarios under varying traffic conditions. During dense traffic conditions, DDP4V employs the segmentation of transmission region of a vehicle in order to select the most appropriate next forwarding vehicle (NFV). Accordingly, it divides the transmission region of a vehicle in three distinct segments and selects vehicle(s) inside the highest priority segment to forward the message to all neighbour vehicles, whereas it also uses implicit acknowledgements for guaranteed message delivery during sparse traffic Conditions. Simulation results show that DDP4V protocol outperforms the other existing related protocols in terms of coverage, network overhead, collision, and end-to-end delay.</P>"
한국 주식시장에서의 Piotroski의 FSCORE와 Mohanram의 GSCORE를 활용한 패자추종 실시간 포트폴리오 전략의 비교에 관한 연구,2018,"['패자추종전략', '실시간 포트폴리오', '기계학습', 'FSCORE', 'GSCORE', 'RMR(중위수회귀전략)', 'OLMAR(온라인평균회귀전 략)', 'CWMR(확신가중평균회귀전략)', 'PMAR(수동적평균회귀전략)', 'Loser following on-line portfolio strategy', 'Machine Learning', 'F SCORE', 'GSCORE', 'RMR', 'OLMAR', 'CWMR', 'PMAR']",가치주 집단에 대해서 Piotroski(2000)의 FSCORE 를 적용하여 매수주집단과 매도주집단을 구분해 내고 이들에 대해서 여러 가지 패자추종 실시간 포트폴리오 전략을 적용한 결과 RMR전략과 OLMAR전략이 여러 가지 지표에 비추어 볼 때 가장 좋은 성과를 보였다. 반면에 CWMR과 PAMR를 이용한 포트폴리오 전략은 RMR과 OLMAR보다 누적수익률이 상대적으로 낮았다. 이는 가치주의 경우에는 기계학습으로 그 패턴을 추정해 낼 수 있는 평균회귀과정이나 추세과정을 따르기 때문으로 보인다. 성장주집단에 대해서 Mohanram의 GSCORE를 적용하여 매수주집단과 매도주집단을 구분해내고 이들에 대해서 여러 가지 패자추종 실시간 포트폴리오 전략을 실행하였다. 그 결과 어떤 패자추종 전략도 최종 누적수익률에서 시장 수익률을 이기지 못하였다. 이는 성장주의 경우에는 기계학습으로는 그 패턴을 추정해낼 수 없는 임의 보행과정을 따르기 때문으로 보인다.,
2D Human Pose Estimation based on Object Detection using RGB-D information,2018,"['RGB-D', 'Human Activity Recognition', 'Object Detection', 'Keypoint Localization', '2D Human Pose Estimation']",,"In recent years, video surveillance research has been able to recognize various behaviors of pedestrians and analyze the overall situation of objects by combining image analysis technology and deep learning method. Human Activity Recognition (HAR), which is important issue in video surveillance research, is a field to detect abnormal behavior of pedestrians in CCTV environment. In order to recognize human behavior, it is necessary to detect the human in the image and to estimate the pose from the detected human. In this paper, we propose a novel approach for 2D Human Pose Estimation based on object detection using RGB-D information. By adding depth information to the RGB information that has some limitation in detecting object due to lack of topological information, we can improve the detecting accuracy. Subsequently, the rescaled region of the detected object is applied to ConVol.utional Pose Machines (CPM) which is a sequential prediction structure based on ConVol.utional Neural Network. We utilize CPM to generate belief maps to predict the positions of keypoint representing human body parts and to estimate human pose by detecting 14 key body points. From the experimental results, we can prove that the proposed method detects target objects robustly in occlusion. It is also possible to perform 2D human pose estimation by providing an accurately detected region as an input of the CPM. As for the future work, we will estimate the 3D human pose by mapping the 2D coordinate information on the body part onto the 3D space. Consequently, we can provide useful human behavior information in the research of HAR."
The study of a full cycle semi-automated business process re-engineering,2018,"['Business process re-engineering', 'business process management systems', 'process mining', 'cloud computing', 'distributed computing']",,"This paper presents an idea and framework to automate a full cycle business process management and re-engineering by integrating traditional business process management systems, process mining, data mining, machine learning, and simulation. We build our framework on the cloud-based platform such that various data sources can be incorporated. We design our systems to be extensible so that not only beneficial for practitioners of BPM, but also for researchers. Our framework can be used as a test bed for researchers without the complication of system integration. The automation of redesigning phase and selecting a baseline process model for deployment are the two main contributions of this study. In the redesigning phase, we deal with both the analysis of the existing process model and what-if analysis on how to improve the process at the same time, Additionally, improving a business process can be applied in a case by case basis that needs a lot of trial and error and huge data. In selecting the baseline process model, we need to compare many probable routes of business execution and calculate the most efficient one in respect to production cost and execution time. We also discuss the challenges and limitation of the framework, including the systems adoptability, technical difficulties and human factors."
Construction of an Electrocardiogram Database Including 12 Lead Waveforms,2018,"['Electrocardiogram', 'Waveform', 'QT Interval', 'Database', 'Adverse Drug Reaction']",,"<P><B>Objectives</B></P><P>Electrocardiogram (ECG) data are important for the study of cardiovascular disease and adverse drug reactions. Although the development of analytical techniques such as machine learning has improved our ability to extract useful information from ECGs, there is a lack of easily available ECG data for research purposes. We previously published an article on a database of ECG parameters and related clinical data (ECG-ViEW), which we have now updated with additional 12-lead waveform information.</P><P><B>Methods</B></P><P>All ECGs stored in portable document format (PDF) were collected from a tertiary teaching hospital in Korea over a 23-year study period. We developed software which can extract all ECG parameters and waveform information from the ECG reports in PDF format and stored it in a database (meta data) and a text file (raw waveform).</P><P><B>Results</B></P><P>Our database includes all parameters (ventricular rate, PR interval, QRS duration, QT/QTc interval, P-R-T axes, and interpretations) and 12-lead waveforms (for leads I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, and V6) from 1,039,550 ECGs (from 447,445 patients). Demographics, drug exposure data, diagnosis history, and laboratory test results (serum calcium, magnesium, and potassium levels) were also extracted from electronic medical records and linked to the ECG information.</P><P><B>Conclusions</B></P><P>Electrocardiogram information that includes 12 lead waveforms was extracted and transformed into a form that can be analyzed. The description and programming codes in this case report could be a reference for other researchers to build ECG databases using their own local ECG repository.</P>"
교차 프로젝트 결함 예측 성능 향상을 위한 효과적인 하모니 검색 기반 비용 민감 부스팅 최적화,2018,"['비용민감 부스팅', '교차프로젝트 결함 예측', '하모니 검색', '검색기반 소프트웨어 공학', '전이 학습', 'Cost-Sensitive Boosting', 'Cross-Project Defect Prediction', 'Harmony Search', 'Search-Based Software Engineering', 'Transfer Learning']",,"Software Defect Prediction (SDP) is a field of study that identifies defective modules. With insufficient local data, a company can exploit Cross-Project Defect Prediction (CPDP), a way to build a classifier using dataset collected from other companies. Most machine learning algorithms for SDP have used more than one parameter that significantly affects prediction performance depending on different values. The objective of this study is to propose a parameter selection technique to enhance the performance of CPDP. Using a Harmony Search algorithm (HS), our approach tunes parameters of cost-sensitive boosting, a method to tackle class imbalance causing the difficulty of prediction. According to distributional characteristics, parameter ranges and constraint rules between parameters are defined and applied to HS. The proposed approach is compared with three CPDP methods and a Within-Project Defect Prediction (WPDP) method over fifteen target projects. The experimental results indicate that the proposed model outperforms the other CPDP methods in the context of class imbalance. Unlike the previous researches showing high probability of false alarm or low probability of detection, our approach provides acceptable high PD and low PF while providing high overall performance. It also provides similar performance compared with WPDP."
아파치 스파크 활용 극대화를 위한 성능 최적화 기법,2018,"['아파치 스파크', '성능 최적화', '시스템 튜닝', 'Apache Spark', 'Performance Optimization', 'System Tuning']",,"Enhancing performance of big data analytics in distributed environment has been issued because most of the big data related applications such as machine learning techniques and streaming services generally utilize distributed computing frameworks. Thus, optimizing performance of those applications at Spark has been actively researched. Since optimizing performance of the applications at distributed environment is challenging because it not only needs optimizing the applications themselves but also requires tuning of the distributed system configuration parameters. Although prior researches made a huge effort to improve execution performance, most of them only focused on one of three performance optimization aspect: application design, system tuning, hardware utilization. Thus, they couldn’t handle an orchestration of those aspects. In this paper, we deeply analyze and model the application processing procedure of the Spark. Through the analyzed results, we propose performance optimization schemes for each step of the procedure: inner stage and outer stage. We also propose appropriate partitioning mechanism by analyzing relationship between partitioning parallelism and performance of the applications. We applied those three performance optimization schemes to WordCount, Pagerank, and Kmeans which are basic big data analytics and found nearly 50% performance improvement when all of those schemes are applied."
실내 CO2 농도와 PIR 신호를 활용한 주거건물의 재실 추정 알고리즘에 관한 연구,2018,"['Occupancy Inference', 'CO2 Concentration', 'PIR', 'Occupancy Probability Function', 'Decrement Ratio', 'Residential Building', '재실추정', 'CO2 농도', 'PIR', '재실확률함수', '감쇠율', '주거건물']","재실 인식과 관련된 기술의 대부분은 업무용 건축물을 대상으로 한 것이 많으며, 데이터 학습과 예측 등 계산부하가 큰 알고리즘을 활용하고 있으므로, 주거 건물에 적용되기 위해서는 좀 더 적은 데이터와 단순한 모델로 재실 추정 알고리즘을 구현할 필요가 있다. 본 연구에서는 저비용, 저메모리로 구현 가능하며 사칙연산으로도 계산 가능한 재실 추정 방법을 제안하기 위해 실내환경 모니터링에 활용되는 CO2 농도와, 보안 또는 조명제어 용도로 활용되는 PIR 센서를 이용한 재실 추정 알고리즘을 도출하고, 이를 실제 주거에 적용하여 타당성을 검증하였다. 거주자 재실추정을 위해 CO2 농도와 PIR 신호를 변수로 하는 재실확률 감쇠함수를 상정하고, CO2 농도의 변화율과 PIR 신호의 값에 따른 재실확률 감쇠율을 적용한 재실 추정 방법을 제안하였다. 제안된 재실 추정 방법을 실제 주거건물에 적용한 결과, 실제 재실여부와 비교하여 75~99% (평균 93%)의 예측 정확도를 나타내었다.","Occupancy-based heating control is effective in reducing heating energy by preventing unnecessary heating during unoccupied period. Various technologies on detecting human occupancy have been developed using complicated machine learning algorithm and stochastic methodologies. This study aims at deriving low-cost and simple algorithm of occupancy inference that can be implemented to residential buildings. The core concept of the algorithm is to combine the occupancy probabilities based on indoor CO2 concentration and PIR(passive infrared) signals. The probability was estimated by applying different levels of decrement ratio depending on CO2 concentration change rate and aggregated PIR signals. The developed algorithm was validated by comparing the inference results with the occupancy schedule in a real residential building. The results showed that the inference algorithm can achieve the accuracy of 75~99%, which would be successfully implemented to the control of residential heating systems."
인공지능과 국토정보를 활용한 노인복지 취약지구 추출방법에 관한 연구,2018,,,"The social influence of the elderly population will accelerate in a rapidly aging society. The purpose of this study is to establish a methodology for extracting vulnerable districts of the welfare of the aged through machine learning(ML), artificial neural network(ANN) and geospatial analysis. In order to establish the direction of analysis, this progressed after an interview with volunteers who over 65-year old people, public officer and the manager of the aged welfare facility. The indicators are the geographic distance capacity, elderly welfare enjoyment, officially assessed land price and mobile communication based on old people activities where 500 m vector areal unit within 15 minutes in Yongin-city, Gyeonggi-do. As a result, the prediction accuracy of 83.2% in the support vector machine(SVM) of ML using the RBF kernel algorithm was obtained in simulation. Furthermore, the correlation result(0.63) was derived from ANN using backpropagation algorithm. A geographically weighted regression(GWR) was also performed to analyze spatial autocorrelation within variables. As a result of this analysis, the coefficient of determination was 70.1%, which showed good explanatory power. Moran's I and Getis-Ord Gi coefficients are analyzed to investigate spatially outlier as well as distribution patterns. This study can be used to solve the welfare imbalance of the aged considering the local conditions of the government recently."
Applying novelty detection to identify model element to IFC class misclassiﬁcations on architectural and infrastructure Building Information Models,2018,"['BIM', 'IFC', 'Novelty detection', 'One-class SVM']",,"Ensuring the correct mapping of model elements to Industry Foundation Classes (IFC) classes is funda-mental for the seamless exchange of information between Building Information Modeling (BIM) applica-tions, and thus achieve true interoperability. This research explored the possibility of employing novelty detection, a machine learning approach, as a way to detect potential misclassiﬁcations that occur during current ad hoc and manual mapping practices. By training the algorithm to learn the geometry of BIM elements for a given IFC class, outliers are detected automatically. A framework for leveraging multiple BIM models and training individual one-class SVM’s was formulated and tested on four IFC classes. Performance results demonstrate the classiﬁcation models to be robust and unbiased. The algorithms developed thus can be leveraged to check the integrity of IFC data, a prerequisite for BIM-based quality control and code compliance."
4차 산업혁명과 인문학 교육의 미래,2018,"['4차 산업혁명', '인문학', '인문학 교육', '과학', '비주체성', '창의성', 'The Fourth Revolution', 'humanities', 'humanities education', 'science', 'nonsubjectivity', 'creativity']",,"The Fourth Industrial Revolution brings about unprecedented social changes, overthrowing existing concepts and understandings of humanity and society. In particular, the Revolution makes possible new economic principles and systems based on artificial intelligence utilizing big data and deep learning, resulting in not only porous boundaries between humans and machines but also social relations built on nonsubjectivity. This radical change will make existing humanistic knowledge and insights useless, so a new humanities education compatible with the Revolution should be sought.By aiming at the fusion of humanities and science, humanities education in a new era should help gain objective perceptions of human beings and the world. In addition, it should play a role of helping creative thinking and practice by overthrowing and overcoming humanistic values and meanings."
Accurate Numerical Computation of Hot Deformation Behaviors by Integrating Finite Element Method with Artificial Neural Network,2018,"['Flow behaviors', 'Superalloy', 'Artificial neural network', 'Numerical computation']",,"Accurate flow behaviors characterization plays a decisive role in the design and optimization of hot plastic forming processes with finite element method (FEM). In this study, the hot compression tests at elevated temperature were performed on a Gleeble 3500 thermo-physical test machine to acquire the true stress-strain data of GH4169 superalloy. Subsequently, an artificial neural network (ANN) with back-propagation algorithm was employed to learn the experimental true stress-strain data and then predict the constitutive relationships outside experimental conditions. It was revealed that the ANN can precisely track and predict the flow behaviors of GH4169 superalloy. The optimally-constructed and well-trained ANN model was written into a general finite element (FE) software platform via a user defined material subroutine programmed in Fortran language. Finally, the simulated hot compression tests with the FE model implanted ANN model were conducted. The intercomparisons between the experimental and simulated stroke-load curves revealed that integration of FEM with ANN is a feasible approach to conduct quality numerical computation for the varied hot plastic forming processes."
ARIMA-SVM 하이브리드 모델을 활용한 탱커 운임지수 예측,2018,"['ARIMA-SVM hybrid models', 'Spot trading', 'BDTI', 'BCTI', 'ARIMA-SVM 하이브리드모델', '스팟거래', 'BDTI', 'BCTI']","탱커시장은 스팟거래의 비중이 상당히 높은 시장으로서 건화물시장이나 컨테이너시장과 달리 단기예측의 중요성이 강조된다. 본 논문은 탱커시황 예측에 기계학습 모델(ANN과 SVM)과 계량모델(ARIMA)을 결합한 하이브리드 모델(Zhang, 2003)을 적용하였다. 탱커시장을 대표하는 BDTI와 BCTI를 연구대상으로 하였으며 연구자료는 1998년 8월부터 2018년 7월까지 240개월이다. 변동성을 고려하여 연구기간을 하위구간 1(1998년∼2008년), 하위구간 2(2009년∼2018년), 전체구간으로 구분하였고 모형의 예측성과를 비교하였다. 단기비중이 높은 거래의 형태를 감안하여 월별예측을 시도하였는데 이는 스팟거래가 20∼50일을 기준으로 하는 계약이기 때문이다. 탱커시황 예측결과는 본 논문에서 제시한 ARIMA-SVM의 모델이 다른 모델들에 비해 성능이 우수하였다. 본 연구는 BDTI와 BCTI를 대상으로 하여 전체 탱커시장을 포괄할 뿐만 아니라 탱커시장에서 비중이 높은 스팟거래의 기간과도 부합하는 결과를 제시하였기 때문에 실무적인 성과로서 의의가 있다. 또한 학문적으로 해운시황예측에 시도되지 않았던 하이브리드 모델이라는 방법론을 제시하였다는 점에서 의미를 찾을 수 있다. 본 논문의 결과는 스팟거래 비중이 높은 탱커시장에 단기예측에 관한 과학적 근거로 제시되어 시장참여자들의 용선의사결정에 실질적으로 도움을 줄 것으로 기대된다.","The tanker market, unlike the container or bulk carrier markets, is dominated by spot transactions, and short-term forecasts play a crucial role in chartering decisions. A hybrid model suggested by Zhang (2003) was applied to forecast tanker freight indices. The model is a combination of the ARIMA and machine learning models i.e. ANN and the SVM. This paper covers not only the BDTI but also the BCTI, which makes it possible to generalize the results. The data length is 240 months, extending from August 1998 to July 2018. The performance test was carried out for the entire period, as well as for two sub-periods (1998-2008 and 2009-2018). The separation of the sub-period was based on the volatility of the index series. Considering spot market decisions, a monthly forecast was attempted. A period of one month is meaningful because spot transactions in the tanker market extend from 30 to 50 days. The results reveal that the hybrid models perform better than single models; they may be used as a guideline to make better decisions in the tanker market, where the share of spot trading is higher than in other sectors."
"A survey of 2D shape representation: Methods, evaluations, and future research directions",2018,"['Shape descriptor', 'Shape classification', 'Shape retrieval']",,"<P>In the past few years, the research studies in image-based shape representation have been proliferating due to its usefulness and importance for various application. This field has been evolved, from simple descriptor-based instance retrieval to utilization of machine learning approaches. Thus, this papers aims to provide a comprehensive survey to summarize the overall view of this research topic. It covers several concepts including the traditional shape descriptors, boundary and region partitioning strategies, and more advanced techniques which commonly exist in the recent studies. This manuscript discusses the advantages and drawbacks of these methods by providing comparisons of evaluation results on well-known public datasets under the various types of similarity metrics and assessment procedures. To complete the survey, it also suggests diverse possibilities of future research directions. (C) 2018 Published by Elsevier B.V.</P>"
GLCM 기반 UAV 영상의 감독분류를 이용한 저수구역 내 농경지 탐지,2018,"['농경지', '명암도 동시발생 행렬', '랜덤 포레스트', '저수구역', 'Cropland', 'Gray Level Co-occurrence Matrix', 'Random Forest', 'Reservoir Area']","저수구역은 계획된 홍수위에 의하여 둘러싸인 지역 혹은 댐의 계획된 홍수위 내에 있는 지역으로 정의된다. 본 연구에서는 저수구역 내 농경지를 탐지하기 위하여, 대표적인 기계학습 기법인 RF (Random Forest) 기반의 감독 분류 방법을 적용하다. 저수구역 내의 농경지를 효과적으로 분류하기 위하여, 질감정보를 정량화하기 위한 대표 적인 기법인 GLCM (Gray Level Co-occurrence Matrix)과 NDWI (Normalized Difference Water Index), NDVI (Normalized Difference Vegetation Index)를 추가적인 입력자료로 활용하다. 특히, 질감정보를 생성하는데 사 용된 윈도우 크기가 농경지의 분류 정확도에 미치는 향을 분석하여, 저수구역 내의 농경지를 효과적으로 분류하 기 위한 방법론을 제시하다. 실험결과, UAV 상을 이용한 분류결과를 통하여 취득된 다중분광상과 NDVI, NDWI, GLCM 상들을 이용하여 저수구역 내의 농경지를 효과적으로 탐지할 수 있음을 확인하다. 또한, GLCM의 윈도우 크기가 분류정확도를 향상시키기 위한 중요한 변수임을 확인하다.","The reservoir area is defined as the area surrounded by the planned flood level of the dam or the land under the planned flood level of the dam. In this study, supervised classification based on RF (Random Forest), which is a representative machine learning technique, was performed to detect cropland in the reservoir area. In order to classify the cropland in the reservoir area efficiently, the GLCM (Gray Level Co-occurrence Matrix), which is a representative technique to quantify texture information, NDWI (Normalized Difference Water Index) and NDVI (Normalized Difference Vegetation Index) were utilized as additional features during classification process. In particular, we analyzed the effect of texture information according to window size for generating GLCM, and suggested a methodology for detecting croplands in the reservoir area. In the experimental result, the classification result showed that cropland in the reservoir area could be detected by the multispectral, NDVI, NDWI and GLCM images of UAV, efficiently. Especially, the window size of GLCM was an important parameter to increase the classification accuracy."
Text Mining and Sentiment Analysis for Predicting Box Office Success,2018,"['Text Mining', 'Sentiment Analysis', 'Prediction', 'Box office Success', 'Word of Mouth']",,"After emerging online communications, text mining and sentiment analysis has been frequently applied into analyzing electronic word-of-mouth. This study aims to develop a domain-specific lexicon of sentiment analysis to predict box office success in Korea film market and validate the feasibility of the lexicon. Natural language processing, a machine learning algorithm, and a lexicon-based sentiment classification method are employed. To create a movie domain sentiment lexicon, 233,631 reviews of 147 movies with popularity ratings is collected by a XML crawling package in R program. We accomplished 81.69% accuracy in sentiment classification by the Korean sentiment dictionary including 706 negative words and 617 positive words. The result showed a stronger positive relationship with box office success and consumers’ sentiment as well as a significant positive effect in the linear regression for the predicting model. In addition, it reveals emotion in the user-generated content can be a more accurate clue to predict business success."
『루나 연대기』(The Lunar Chronicles)의 『신더』(Cinder) 연구 ― 세상은 유령을 쫓을 뿐이다,2018,"['사이보그', '경계', '면역', '자아', '유동성', '정체성', 'cyborg', 'boundaries', 'immunity', 'self', 'flexibility', 'identity']",,"Cinder is the first book in Marissa Meyer’s The Lunar Chronicles and is set against a future society after World War IV. The main character, Cinder, is a cyborg and this fact itself prepares readers to read Cinder as Donna Haraway’s cyborg: a metaphor to express a possibility of blurring boundaries, learning how not to be the human defined by liberal humanism, and accepting a self as fluid, flexible, and repeatedly dissembled and reassembled in relationality with non-humans. But Cinder, in the first part of the story, reveals unconscious adherence to the concept of a whole, intrinsic self by repeatedly mentioning “metal invaders”. She wants to establish her self by building a boundary along the line where her human body and artificial parts meld together. This attitude makes Cinder view her cyborg body less than human and want to hide metallic parts. It also justifies the practice of cyborg draft under an excuse of finding a cure for the epidemic, letumosis. Toward the end of the story, however, in the crisis of facing Levana, the Lunar Queen, Cinder perceives her opponent through the eyes of a camera, a human being and a Lunar. She cannot identify who or what is seeing Levana. Cinder circumvents Levana’s power by being her, that is a part human, a part machine, a part Lunar, and at the same time, that is not a machine, not a human, nor a Lunar. At the end of the story, Cinder destroys her identity chip and describes herself as a “ghost”. Traces may remain, but existing boundaries collapse and new boundaries are to appear. The possibility of self as fluid, flexible, and re-emergent in relationalities with not-mes makes Cinder recognized as a posthumanistic work in juvenile literature, a genre in which many authors choose to play it safe by staying conservative and keeping the value of fitting in through establishment of a stable identity."
A Comparative Study of Phishing Websites Classification Based on Classifier Ensemble,2018,"['Phishing Website', 'Classifier Ensembles', 'Performance Comparison', 'Significance Test']",,"Phishing website has become a crucial concern in cyber security applications. It is performed by fraudulently deceiving users with the aim of obtaining their sensitive information such as bank account information, credit card, username, and password. The threat has led to huge losses to online retailers, e-business platform, financial institutions, and to name but a few. One way to build anti-phishing detection mechanism is to construct classification algorithm based on machine learning techniques. The objective of this paper is to compare different classifier ensemble approaches, i.e. random forest, rotation forest, gradient boosted machine, and extreme gradient boosting against single classifiers, i.e. decision tree, classification and regression tree, and credal decision tree in the case of website phishing. Area under ROC curve (AUC) is employed as a performance metric, whilst statistical tests are used as baseline indicator of significance evaluation among classifiers. The paper contributes the existing literature on making a benchmark of classifier ensembles for web phishing detection."
Accurate and Efficient Log Template Discovery Technique,2018,"['Log template', 'Log analysis', 'Log parsing']",,"In this paper we propose a novel log template discovery algorithm which achieves high quality of discovered log templates through iterative log filtering technique. Log templates are the static string pattern of logs that are used to produce actual logs by inserting variable values during runtime. Identifying individual logs into their template category correctly enables us to conduct automated analysis using state-of-the-art machine learning techniques. Our technique looks at the group of logs column-wise and filters the logs that have the value of the highest proportion. We repeat this process per each column until we are left with highly homogeneous set of logs that most likely belong to the same log template category. Then, we determine which column is the static part and which is the variable part by vertically comparing all the logs in the group. This process repeats until we have discovered all the templates from given logs. Also, during this process we discover the custom patterns such as ID formats that are unique to the application. This information helps us quickly identify such strings in the logs as variable parts thereby further increasing the accuracy of the discovered log templates. Existing solutions suffer from log templates being too general or too specific because of the inability to detect custom patterns. Through extensive evaluations we have learned that our proposed method achieves 2 to 20 times better accuracy."
The 4<sup>th.</sup>industrial revolution and Korean university's role change,2018,,,"The interest about 4th Industrial Revolution was impressively increased from newspapers, iindustry, government and academic sectors. Especially AI what could be felt by the skin of many peoples, already overpassed the ability of the human's even in creative areas. Namely, now many people start fo feel that the effect of the revolution is just infront of themselves. There were several issues in this trend, the ability of deep learning by machine, the identity of the human, the change of job environment and the concern about the social change etc. Recently many studies have been made about the 4th industrial revolution in many fields like as AI(artificial intelligence), CRISPR, big data and driverless car etc. As many positive effects and pessimistic effects are existed at the same time and many preventing actions are being suggested recently, these opinions will be compared and analyzed and better solutions will be found eventually. Several educational, political, scientific, social and ethical effects and solutions were studied and suggested in this study. Clear implication from the study is that the world we will live from now on is changing faster than ever in the social, industrial, political and educational environment. If it will reform the social systems according to those changes, a society (nation or government) will grasp the chance of its development or take-off, otherwise, it will consume the resources ineffectively and lose the competition as a whole society. But the method of that reform is not that apparent in many aspects as the revolution is progressing currently and its definition should be made whether in industrial or scientific aspect. The person or nation who will define it will have the advantage of leading the future of that business or society."
크라우드펀딩에서의 사기 프로젝트 탐지,2018,"['Crowdfunding', 'Scam', 'Linguistic cues', 'Classification']",,"In this paper, we propose a model to detect crowdfunding scams, which have been reportedly occurring over the last several years, based on their project information and linguistic features. To this end, we first collect and analyze crowdfunding scam projects, and then reveal which specific project-related information and linguistic features are particularly useful in distinguishing scam projects from non-scams. Our proposed model built with the selected features and Random Forest machine learning algorithm can successfully detect scam campaigns with 84.46% accuracy."
대형 과수원 사과 분류 시스템,2018,"['AI', 'Deep Running', 'algorithm', '인공지능', '딥러닝', '알고리즘']","근례 무인화의 발전은 계속되고 있고, AI무인화의 발전은 산업, 복지, 인력등 인력으로 해결해 오던 작업들을좀더 인력보다 효율적이고 정확하고 신속하게하는 것을 목표로 하고 있다. AI무인화 기술은 다양한 곳에서 발전하고있는데 이중 많은 산업체나 공장에서 무인화 시스템으로 대대적 전환하는 시점이다. 우리는 이 점을 착안하여 대형 과수원에서 한번에 레일이 쏟아져 들어오는 과일들을 인력이 아닌 인공지능(AI) 핵심 기술중 하나인 Deep Learning 기술을 활용하여 대형 과수원에서 사람이 직접 과일을 분류하지 않아도 자동화 기계가 과일을 종류별, 등급별로 나누어원산지와 품종 등급별로 나누어 많은 인력을 소비하지 않고 관리자의 감독하에 가동가능한 무인화 과일 분류 기계를연구하고자 한다. 이러한 무인 자동화 분류 시스템은 인력을 최소한으로 줄여 인건비를 줄이고, 사람이 할 수 있는실수나 오류들을 최소한으로 줄여 일의 효율성을 증진시킬 수 있도록 하는 것을 목표로 본 연구를 진행하고자 한다.","The development of unmanned AI continues, and the development of AI unmanned is aimed at more efficiently, accurately, and speedily the work that has been resolved by manpower such as industry, welfare, and manpower. AI unmanned technology is evolving in various places, and it is time to switch to unmanned systems from many industries and factories. We take this into consideration, and use the Deep Learning technology, which is one of the core technologies of artificial intelligence (AI), not the manpower but the fruits that pour the rails at once in a large orchard. We want to study the unmanned fruit sorting machine that can be operated under manager's supervision without dividing the fruit by type and grade and dividing by country of origin and grade. This unmanned automated classification system aims to reduce the labor cost by minimizing the manpower and to improve the"
4차산업혁명을 준비하는 교육,2018,"['4차 산업혁명', '경험', '접속', '융합', '교육']","18세기 1차 산업혁명 이후로부터 여러 차례에 걸쳐 혁명적 산업 변화가 이루어졌다. 4차 산업혁명은 지능과 정보가 융합된 형태로 전개되는 새로운 형태의 산업혁명이다. 사회, 문화, 경제, 교육 시스템은 접속과 경험이라는 커다란 주제 안에서 전개될 것으로 예상된다. 4차 산업혁명의 특징적 요소인 지능적 기계화의 흐름 속에서, 인간과 기계의 분업화라는 관점은 반드시 필요하다. 도구에 관한 것은 기계와 인공지능에게 맡기고 인간은 본질적인 문제를 바라보아야 한다. 4차 산업혁명의 패러다임과 기술발전의 흐름 속에서 교육의 관점은 근본적으로 변화되어야 한다. 암기력을 기반으로 하는 소유의 개념이 아닌, 접속과 활용의 능력을 길러주는 교육으로 나아가야 한다. 로봇과 인공지능이 많은 부분을 담당할 수 있으므로 인간은 기계가 할 수 없는 토론, 협업, 의사소통, 감성, 예술성이라는 영역에 주목할 필요가 있다. 4차 산업혁명은 인간과 기술의 융합, 인문학과 과학기술의 융합이다. 융합적 교육과 독서가 중요하다.","A series of revolutionary industrial changes took place from the 18th century of the First Industrial Revolution. The fourth industrial revolution is a new industrial revolution in which intelligence and information unite. Social, cultural, economic and educational systems are expected to emerge within the category of access and experience. In the course of intelligent mechanization, manpower and machinery need to be commandeered. Tools should be left to the machine and humans should look at essential issues. In the 4th Industrial Revolution, the paradigm of education should fundamentally change. Instead of routine technologies based on memorization, one should learn how to access and utilize. It needs to focus on areas of debate, cooperation, communication, sensibility, and artistry that robots and artificial intelligence can not afford. The fourth industrial revolution is the fusion of human beings and technology, the humanities and the technology."
A Comparative Study of Phishing Websites Classification Based on Classifier Ensembles,2018,"['Phishing website', 'classifier ensembles', 'performance comparison', 'significance test']",,"Phishing website has become a crucial concern in cyber security applications. It is performed by fraudulently deceiving users with the aim of obtaining their sensitive information such as bank account information, credit card, username, and password. The threat has led to huge losses to online retailers, e-business platform, financial institutions, and to name but a few. One way to build anti-phishing detection mechanism is to construct classification algorithm based on machine learning techniques. The objective of this paper is to compare different classifier ensemble approaches, i.e. random forest, rotation forest, gradient boosted machine, and extreme gradient boosting against single classifiers, i.e. decision tree, classification and regression tree, and credal decision tree in the case of website phishing. Area under ROC curve (AUC) is employed as a performance metric, whilst statistical tests are used as baseline indicator of significance evaluation among classifiers. The paper contributes the existing literature on making a benchmark of classifier ensembles for web phishing detection."
A Comparative Study of Phishing Websites Classification Based on Classifier Ensembles,2018,"['Phishing Website', 'Classifier Ensembles', 'Performance Comparison', 'Significance Test']",,"Phishing website has become a crucial concern in cyber security applications. It is performed by fraudulently deceiving users with the aim of obtaining their sensitive information such as bank account information, credit card, username, and password. The threat has led to huge losses to online retailers, e-business platform, financial institutions, and to name but a few. One way to build anti-phishing detection mechanism is to construct classification algorithm based on machine learning techniques. The objective of this paper is to compare different classifier ensemble approaches, i.e. random forest, rotation forest, gradient boosted machine, and extreme gradient boosting against single classifiers, i.e. decision tree, classification and regression tree, and credal decision tree in the case of website phishing. Area under ROC curve (AUC) is employed as a performance metric, whilst statistical tests are used as baseline indicator of significance evaluation among classifiers. The paper contributes the existing literature on making a benchmark of classifier ensembles for web phishing detection."
The 4th industrial revolution and Korean university’s role change,2018,"['장벽타파', '사회의 공동자산', '실패에 대한 보상', '공유', '창조커리큘럼', '로봇세', '기본소득', '인정의 문화', 'Breaking the barrier', 'Common property of the society', 'Reward the failure', 'Common sharing', 'Curriculum of creativeness', 'Robot tax', 'Basic income', 'Culture of admitting']",,"The interest about 4th Industrial Revolution was impressively increased from newspapers, iindustry, government and academic sectors. Especially AI what could be felt by the skin of many peoples, already overpassed the ability of the human's even in creative areas. Namely, now many people start fo feel that the effect of the revolution is just infront of themselves. There were several issues in this trend, the ability of deep learning by machine, the identity of the human, the change of job environment and the concern about the social change etc.Recently many studies have been made about the 4th industrial revolution in many fields like as AI(artificial intelligence), CRISPR, big data and driverless car etc. As many positive effects and pessimistic effects are existed at the same time and many preventing actions are being suggested recently, these opinions will be compared and analyzed and better solutions will be found eventually. Several educational, political, scientific, social and ethical effects and solutions were studied and suggested in this study. Clear implication from the study is that the world we will live from now on is changing faster than ever in the social, industrial, political and educational environment.If it will reform the social systems according to those changes, a society (nation or government) will grasp the chance of its development or take-off, otherwise, it will consume the resources ineffectively and lose the competition as a whole society. But the method of that reform is not that apparent in many aspects as the revolution is progressing currently and its definition should be made whether in industrial or scientific aspect. The person or nation who will define it will have the advantage of leading the future of that business or society."
4차 산업혁명 시대의 주요 서비스업종을 통한 일자리 창출 전략,2018,"['The Fourth Industrial Revolution', 'Service Industry', 'Job Creation', '4차 산업혁명', '서비스업', '일자리 창출']","본 논문에서는 4차 산업혁명으로 인해 변화하는 인력과 산업구조에 주목하고 이에 선제적으로 대응할 수 있는 인력구조의 변화방향과 미래 일자리의 인력확보에 대한 정책적 제언을 하고자 한다. 이를 위해 먼저 4차 산업혁명에 따라 성장할 것으로 예측되는 다섯 가지 산업들을 선택하였는데, 이는 4차 산업혁명의 기반 기술이 되는 운수업과 통신업, 금융 및 보험업, 교육서비스업 그리고 보건 및 사회복지업이다. 이들 다섯 가지 산업 중 운수업과 금융 및 보험업에서는 고용 감소를, 통신업과 보건 및 사회복지업에서는 고용증가를, 교육서비스업에서는 평균보다 조금 높은 고용증가를 확인할 수 있었다. 이를 염두에 둔 일자리 창출 방안을 위해 이들 다섯 가지 산업에 대한 주요 특성과 사례를 살펴보았다. 이들 다섯 가지 산업에서의 4차 산업혁명에 필요한 새로운 일자리는 4차 산업혁명을 주도하는 신기술 및 이 신기술 적용과 관련하여 창출될 것이다. 일자리 창출에 있어서도 서비스 분야는 물론이고 중소기업에도 관심을 가질 필요가 있다. 정부에서는 이를 염두에 두고 다섯 가지 산업에 필요한 4차 산업혁명을 담당할 인력을 교육을 통해 선제적으로 확보하여 미래의 창출될 일자리에 준비시킬 필요가 있다. 운수업의 경우 제조혁신에 대한 직업교육 강화 및 기존 인력 재교육이 필요하며, 통신업의 경우에는 신기술 분야와 다양하게 접목되는 만큼 근로자들의 유연성과 신기술 분야에 대한 전문성 교육이 시급하다. 금융 및 보험업의 경우 빅데이터 전문가 및 시스템감시자 양성, 교육 서비스업의 경우 교육제도 개편과 신기술 적용 산업 분야의 전문 컨설팅 인력 양성이 요구된다. 마지막으로 보건 및 사회 복지 업은 인간공학기술자 및 의료용 로봇 전문가 등의 인력에 대한 교육이 필요하다.","This paper aims to address changes in the structure of the South Korean industry and its workforce the 4th industrial revolution brings about and offer policy advice on the country’s labor strategy to help them get ready for such changes. To that end, we first identify five specific industry sectors which are expected to grow rapidly with the 4th industrial revolution-namely, transportation and logistics, telecommunications, finance and insurance, education services, and health and social services- and examine characteristics of these industries along with specific examples to derive plans for job creation and job security. New jobs will be created around the technologies which have led the 4th revolution such as Block Chain, Big Data, Internet of Things, Machine Learning, Artificial Intelligence, Augmented/Virtual Reality. The government needs to equip its workforce with these technologies in order to cope with the changing demand actively. When devising plans to create jobs and secure workforce, it is important to pay special attention to SMEs since they often do not feel the pressure for innovation as much as the large firms do, yet they account for the majority of the Korean economy."
Model-based control of a molten carbonate fuel cell (MCFC) process,2018,"['Molten Carbonate Fuel Cells', 'ARMA Modeling', 'Model Predictive Control', 'Rigorous Model']",,"To improve availability and performance of fuel cells, the operating temperature of molten carbonate fuel cells (MCFC) stack should be strictly maintained within a specified operation range, and an efficient control technique should be employed to meet this objective. While most modern control strategies are based on process models, many existing models of MCFC are not ready to be applied in synthesis and operation of control systems. In this study, we developed an auto-regressive moving average (ARMA) model and machine learning methods of least squares support vector machine (LS-SVM), artificial neural network (ANN) and partial least squares (PLS) for the MCFC system based on input-output operating data. The ARMA model showed the best tracking performance. A model predictive control method for the operation of MCFC system was developed based on the proposed ARMA model. The control performance of the proposed MPC methods was compared with that of conventional controllers using numerical simulations performed on various process models including an MCFC process. Numerical results show that ARMA model based control provides improved control performance compared to other control methods."
인공지능에 대한 민사책임 법리,2018,"['인공지능', '민사책임', '과실책임', '위험책임', '편익책임', '유럽연합로봇법', 'Artificial Intelligence', 'Civil Liability', 'Fault Liability', 'Risk Liability', 'Benefit Liability', 'European Union Robot Law']","인공지능의 작동에 의하여 타인에게 손해가 발생한 경우에 그 배상책임을 인정하기 위해서는 인공지능의 작동이 법적 의미의 ‘행위’로 평가되어야 한다. 그런데 전통적인 관점에서 ‘행위’는 행위자의 자유의지를 전제로 하며, 만일 사람의 행위라고 하더라도 행위자의 자유의지가 부정되는 경우에는 행위성이 부정된다. 인공지능의 작동에 있어 가장 중요하고 지배적인 근원은 인공지능 알고리즘의 제작 및 설치이며, 인공지능의 작동은 알고리즘의 지배를 받는다. 또한 인공지능은 기계학습을 통하여 점차 진화되고 있어 인공지능의 작동을 인공지능 알고리즘 제작과 설치라는 인간의 행위로 환원할 수 없다. 나아가 인공지능 이용자는 인공지능의 작동에 대한 구체적인 통제가능성이 존재하지 않는다. 인공지능 이용자는 인공지능의 작동에 어떠한 주의를 기울여야 그것이 타인에게 손해를 야기하지 않을 것인지를 전혀 알지 못한다. 그러므로 인공지능에 대하여 지배가능성이 없는 점유자에게 주의의무 해태라는 부작위의 행위성을 인정하기 어렵다. 이와 같이 인공지능의 작동 결과를 전통적인 인간의 행위로 환원하려고 하는 시도는 논리적 설득력을 얻기 어렵다. 그 결과 인공지능의 작동으로 인한 위법행위가 고의 또는 과실로 인하여 발생하지 않더라도 인공지능과 일정한 규범적 관계에 있는 자에게 손해배상책임을 부담시키기 위한 책임 법리를 재구성할 필요가 있다.이하에서는 인공지능에 대한 민사책임 법리를 과실책임을 바탕으로 검토하되 행위성을 완화하는 책임규정과 행위성을 요건으로 하지 않는 무과실책임으로 나누어 검토해 보았다. 또한 인공지능에 대한 민사책임 법리를 모색하기 위하여 인공지능에 대해서 제한적인 법인격을 인정하고 있는 유럽연합로봇법에 대해서도 검토해 보았다.","In order to recognize liability for damages to others due to the operation of artificial intelligence, the operation of artificial intelligence should be evaluated as an ‘act’ of legal meaning. However, in the traditional view, ‘act’ presupposes the agent 's free will, and even if it is man's act, the act is denied if the agent 's free will is denied. The most important and dominant source of artificial intelligence is the production and installation of artificial intelligence algorithms, and the operation of artificial intelligence is subject to algorithms. Also, artificial intelligence is evolving gradually through machine learning, and artificial intelligence can not be reduced to human act of artificial intelligence algorithm creation and installation. Furthermore, AI users do not have specific control over the operation of artificial intelligence. An artificial intelligence user does not know at all how to pay attention to the operation of artificial intelligence will not cause harm to others. Therefore, it is difficult to recognize the conduct of the omission of the obligation to pay attention to the occupier who is not able to control the artificial intelligence. This attempt to reduce the result of artificial intelligence to traditional human behavior is hard to obtain logical persuasion. As a result, even if the illegal act caused by the operation of artificial intelligence does not occur due to intentional or negligent reason, it is necessary to reconstruct the principle for liability to the person who has a certain normative relationship with artificial intelligence.This Study examines the principle of liability based on fault liability and then examines the civil liability of artificial intelligence centered on liability for mitigating behavior and non. To this end, I will examine the European Union law that regulates the responsibility of artificial intelligence."
축구 경기 이벤트 단위 네트워크를 이용한 대한민국 축구 양식 측정,2018,"['축구 경기 이벤트', '양식측정법', '네트워크', 'Football game events', 'Stylometry', 'Network']","스포츠의 중계는 영상뿐만 아니라 문자로도 이루어진다. 문자 중계의 내용만으로도 축구 경기 대부분의 내용이 전달된다. 본 연구는 대한민국 국가대표 A매치 344경기에서 나타난 389,139개의 축구 경기 이벤트를 이용하여, 네트워크를 만들고 양식측정학(stylometry)으로 비교해본다. 다양한 이벤트 내용을 발생 위치에 따라 군집화하고, 이벤트의 빈도 분포에서 보이는 멱함수 법칙(power law)이 성립하는 것을 확인한다. 단어를 벡터로 변환하는 기계학습 방법인 Word2Vec으로 축구 경기 이벤트를 학습하여 이벤트 사이의 코사인 유사도를 측정하고, 축구 경기 이벤트의 관계를 파악한다. 이벤트의 발생 순서를 이용한 전이 네트워크와 Word2Vec으로 학습한 네트워크를 서로 비교하고, 각 네트워크에서 드러난 대한민국 축구 양식을 살펴본다.","Web-casting text is a text broadcast service for sports games. Just by using the web-casting text, most of the content of the game is delivered. In this study, we make a word network by using 389,139 football game events from 344 matches of Korean national team and analyze the network through the stylometry. We cluster the events according to the location of their occurrence, and confirm that the frequency distribution of the events follows power law. We utilize the Word2Vec, a machine learning method for converting words to vectors, to measure the cosine similarity between the events and to understand the relation between the football game events. We construct two networks, one is a transition network that uses the event sequence and the other is a Word2Vec network that learns the data by using Word2Vec. We compare the results to show the significance of the Korean football style revealed in each of the networks."
Normalization of Input Vectors in Deep Belief Networks (DBNs) for Automatic Incident Detection,2018,"['AID (Automatic Incident Detection)', 'Artificial Neural Network', 'Deep Neural Networks (DNNs)', 'Normalization', 'Input Vectors']",,"Traffic incidents have a serious negative impact on safety and traffic flow, and fast accurate automatic incident detection on freeways is a major theme in transportation engineering. Therefore, various types of AID (Automated Incident Detection) algorithms have been proposed for more accurate and rapid incident detection, and Artificial Neural Network models have provided significantly improved performance in terms of detection and false alarm rates. Recently, Deep Neural Networks (DNNs) has received much attention due to its excellent performance and was also used for automatic incident detection on highways. However, in learning algorithms such as Backpropagation and SVMs(Support Vector Machines), the prediction performance is known to be highly depend on the input vector characteristics. The purpose of this study is to examine whether the input detection performance of DNNs differs according to the normalization method of the input vector and to verify how sensitive it is to the method. Furthermore, the best way to normalize the input vector of the DNNs model has been proposed in order to obtain the best performance in terms of DR (Detection Rate) and FAR (False Alarm Rate) in AID (Automatic Incident Detection)."
기계 학습 및 딥러닝 알고리즘을 사용한 스마트 수도미터 시스템에서의 물 사용량 데이터 분석,2018,"['기계학습', '딥러닝', 'LSTM', '순환 신경망', '스마트 수도미터', 'AMI 시스템']",,
도로구간 특성에 따른 노면온도변화패턴 추정 모형 성능 분석,2018,"['Road surface temperature', 'Sound-Proof Tunnel', 'Thermal Mapping', 'Winter Maintenance', 'Mean Absolute Error']",,"PURPOSES: This study aimed to evaluate the performance of a model developed for road surface temperature change pattern in reflecting specific road characteristics. Three types of road sections were considered, namely, basic, tunnel, and soundproof tunnel.METHODS: A thermal mapping system was employed to collect actual road surface temperature and locational data of the survey vehicle. Data collection was conducted 12 times from 05:30 am to 06:30 am on the test route, which is an uninterrupted flow facility. A total of 9010 road surface temperature data were collected, and half of these were selected based on a random selection process. The other half was used to evaluate the performance of the model. The model used herein is based on machine learning algorithms. The mean absolute error (MAE) was used to evaluate the accuracy of the estimation performance of the model.RESULTS: The MAE was calculated to determine the difference between the estimated and the actual road surface temperature. A MAE of 0.48℃ was generated for the overall test route. The basic section obtained the smallest error whereas that of the tunnel was relatively high.CONCLUSIONS: The road surface temperature change is closely related to the air temperature. The process of data pre-processing is very important to improve the estimation accuracy of the model. Lastly, it was difficult to determine the influence of the data collection date on the estimation of the road surface temperature change pattern due to the same weather conditions."
인공지능과 인지 자본주의 비판,2018,"['cognitive capitalism', 'cybernetics', '4th industrial revolution', 'control society', 'control relation', 'artificial intelligence', 'universal market', 'the social', '인지 자본주의', '사이버네틱스', '4차 산업혁명', '통제 사회', '제어 관계', '공유 경제', '인공지능', '보편 시장', '사회적인 것']","정보 사회의 내용과 성격은 자본주의의 발전에 따라 지속적으로 변화한다. 초기인터넷의 방향을 보여 주던 탈중심화, 탈물질화, 탈상품화 추세는 약화되고, 플랫폼 독점과 빅데이터, 인공지능을 통해 재중심화, 재물질화와 재상품화 추세가강화되고 있다. 지금은 현단계 자본주의의 변화에 대응하여 기존 인지 자본주의분석의 범위를 넓히거나 더 구체화해야 하는 시점이다. 플랫폼 독점을 통해 이루어지는 데이터의 축적은 기계 학습과 인공지능을 통해 재물질화의 기반으로 활용되고 있다. 이러한 변화를 주도하는 ‘4차 산업혁명론’이 제시되고 있으나 본 논문에서는 ‘인지 자본주의’에 대한 비판의 입장에서 ‘사이버네틱스’와 ‘제어혁명’ 이라는 틀을 결합하여 현재의 추세가 갖는 성격을 분석할 것이다. 인터넷 이용자의 ‘인지행위’를 상업화하는 과정에 대한 분석은 인공지능과 빅데이터를 기반으로 하는 정치경제학적인 위상을 밝히는 데 모아진다. 빅데이터와 결합되는 기계학습과 인공지능, 클라우드 컴퓨팅은 데이터라는 질료에 형상을 부과하여, 재물질화를 향한 ‘정보화(in-formation)’의 기반을 마련하고, 정보와 물질을 다시 결합하여 ‘재물질화’를 이루면서 새로운 축적 구조를 만들려는 자본의 의도와 관련이 있다. 이런 흐름을 자본과 경영의 입장에서 선전하는 것이 ‘4차 산업혁명’이라는 구호이다. 이 글에서는 현재의 ‘규정적 기술’로 떠오르고 있는 인공지능과 빅데이터의 결합이 갖는 의미를 사이버네틱스와 제어혁명이라는 틀로 살펴보고, 112 　동향과 전망 103호인지 자본주의에서 ‘사적인 것’이 ‘사회적인 것’으로 변형되는 기제와 공유 경제를 통해 이루어지는 인지 자본주의의 확장과 새로운 축적 방식과 확대를 ‘디지털보편 시장’이라는 틀로 살펴본다.","The characteristics of information society is continuously changing according to capitalist development. The main trends toward decentralization, dematerialization and decommodification which were the central symbols of the early Internet is now changed into the new trends of recentralization, rematerialization and recommodification. In this situation we need to widen the subject and concretize the analysis of cognitive capitalism. The accumulation of data which is accomplished by platform is now used as the main resources and basement of rematerialization by machine learning and artificial intelligence. The discourse about 4th industrial revolution is affluent nowadays by journalistic standpoint but I will approach this current trend by combining ‘cybernetics’ and ‘control revolution’. To do this I will review the history of cybernetics from 1950s to 2010s from the perspective of control revolution. I also disclose the meaning of combining big data and artificial intelligence in the frame of cybernetics and control relation. The new ground and form of ‘the social’ in the age of cognitive capitalism is facilitated by the share economy. The share economy is converting the private into the social for the sake of profit. With this analysis the new form of digital universal market would be disclosed."
랜섬웨어 탐지를 위한 동적 분석 자료에서의 변수 선택 및 분류에 관한 연구,2018,,,"Attacking computer systems using ransomware is very common all over the world. Since antivirus and detection methods are constantly improved in order to detect and mitigate ransomware, the ransomware itself becomes equally better to avoid detection. Several new methods are implemented and tested in order to optimize the protection against ransomware. In our work, 582 of ransomware and 942 of normalware sample data along with 30,967 dynamic action sequence variables are used to detect ransomware efficiently. Several variable selection techniques combined with various machine learning based classification techniques are tried to protect systems from ransomwares. Among various combinations, chi-square variable selection and random forest gives the best detection rates and accuracy."
한국표준산업분류를 기준으로 한 문서의 자동 분류 모델에 관한 연구,2018,"['문서자동분류', '한국표준산업분류', '텍스트마이닝', '벡터공간모델', '자연어 처리', 'Automatic Document Classification', 'Korea Standard Industry Classification', 'Text mining', 'Vector space model', 'Natural language processing']",,"As we enter the knowledge society, the importance of information as a new form of capital is being emphasized. The importance of information classification is also increasing for efficient management of digital information produced exponentially. In this study, we tried to automatically classify and provide tailored information that can help companies decide to make technology commercialization. Therefore, we propose a method to classify information based on Korea Standard Industry Classification (KSIC), which indicates the business characteristics of enterprises. The classification of information or documents has been largely based on machine learning, but there is not enough training data categorized on the basis of KSIC. Therefore, this study applied the method of calculating similarity between documents. Specifically, a method and a model for presenting the most appropriate KSIC code are proposed by collecting explanatory texts of each code of KSIC and calculating the similarity with the classification object document using the vector space model. The IPC data were collected and classified by KSIC. And then verified the methodology by comparing it with the KSIC-IPC concordance table provided by the Korean Intellectual Property Office. As a result of the verification, the highest agreement was obtained when the LT method, which is a kind of TF-IDF calculation formula, was applied. At this time, the degree of match of the first rank matching KSIC was 53% and the cumulative match of the fifth ranking was 76%. Through this, it can be confirmed that KSIC classification of technology, industry, and market information that SMEs need more quantitatively and objectively is possible. In addition, it is considered that the methods and results provided in this study can be used as a basic data to help the qualitative judgment of experts in creating a linkage table between heterogeneous classification systems."
Estimation System of Blood Pressure Variation with Photoplethysmography Signals Using Multiple Regression Analysis and Neural Network,2018,"['Blood pressure estimation', 'Multiple regression analysis', 'Neural network', 'Correlation coefficient', 'Photoplethysmography']",,"In this study, a target is to improve the accuracy of a blood pressure (BP) estimation system using photoplethysmography (PPG) signals. A BP estimation algorithm using multiple regression analysis is proposed and a BP estimation using the neural network is studied.Experimental results have shown that estimation accuracy can be improved. Estimation error of systolic BP value using multiple regression analysis with the proposed algorithm was reduced by approximately 16.3%. Furthermore, estimation error was reduced by approximately 21.6% than conventional multiple regression analysis in case of a BP estimation by machine learning using the neural network. It has been found that estimation accuracy is improved and shows the possibility of BP estimation using the neural network"
실시간 관측 및 제어가 가능한 IoT 저수조 관리 시스템,2018,"['IoT(Internet of Things)', 'Ubiquitous', 'Real-Time', 'Water Tank', 'Management System', 'Monitoring', 'IoT(Internet of Things)', '유비쿼터스', '실시간', '저수조', '관리 시스템', '모니터링']","실시간 제어는 관리 시스템의 실질적인 사용을 확인하기 위해 해결해야 하는 주요 과제였다. 이와 관련하여 편의성과 효율성을 높이기 위해 처음으로 사물인터넷(IoT) 기반 저수조 시스템을 제안 및 개발하였다. 저수조의 상태가 불안정할 경우 사용자에게 알려 저수조를 효과적으로 제어할 수 있다. 제안된 시스템은 센서 데이터 측정 및 제어를 위한 내장형 H/W 장치, 웹 및 모바일 앱을 통한 관리 서버 구축을 위한 애플리케이션 S/W, 통계 관리 및 모니터링을 위한 효율적인 데이터베이스 구조로 구성되어 있다. 또한 기계 학습 알고리즘을 적용하여 실제 효율성을 더욱 향상시킬 수 있다.","Real-time controllability has been a major challenge that should be addressed to ascertain the practical usage of the management systems. In this regards, for the first time, we proposed and implemented an IoT(Internet of Things)-based water tank system to improve convenience and efficiency. The reservoir can be effectively controlled by notifying the user if the condition of the reservoir is unstable. The proposed system consists of embedded H/W unit for sensor data measuring and controling, application S/W for deployment of management server via web and mobile app, and efficient database structure for managing and monitoring statistics. And machine learning algorithms can be applied for further improvements of efficiency in practice."
루프 속의 프레카리아트,2018,"['기술과 노동', '인공지능', '데이터 레이블링', '콘텐츠 조정', '토픽 트렌딩', '긱 노동', '크라우드 워크', '기술정치', '노동의 비가시화', '경계 짓기의 정치경제', 'Technology and labor', 'Technology and work', 'Artificial Intelligence', 'Data labelling', 'Content moderation', 'Topics trending', 'Gig work', 'Crowd work', 'Politics of technology', 'Invisiblization of labor', 'Political economy of boundary making']","최근 인공지능(Artificial Intelligence, AI)과 로봇 기술들이 급격하게 발전하면서 기술과 노동의 관계가 과거와 확연히 다를 것이라는 전망이 힘을 얻고 있다. 기계 학습과 같은 AI는 단순 반복적인 사무 업무뿐만 아니라 복잡한 인지능력이 요구되는 직업까지 대체하면서 대량실업과 같은 어두운 노동의 미래를 가져온다는 예상도 팽배하다. 이 글은 대량실업을 예견하는 논평에 편승하기보다는 거대 디지털 기업의 실제 노동 현장에서 AI가 어떻게 실행되고 있는지, AI와 더불어 인간 노동은 어떤 임무를 수행하고 있는지 주목하고자 한다. 인간 대 기계를 대립시키고 이들을 경쟁시키기보다는 실제 현장에서 인간과 AI가 서로 어떻게 얽히는지 탐색하면서 이러한 과정에서 어떻게 “인간됨 (humanness)”과 “기계됨(machineness)”이 협상되고 구성되는지 살펴보고자 한다. AI를 구성하고 있는 인간 노동인 데이터 레이블링(data labelling), 콘텐츠 조정(content moderation), 토픽 트렌딩(topics trending)을 차례로 살펴본 후 이 글은 AI의 확산으로 ‘루프 속의 프레카리아트(Precariat-in-the-Loop)’라고 부를 수 있는 저임금의 불안정한 노동이 더 많이 생산되고 있다는 점을 보여줄 것이다. 또한 이 글은 혁신기업으로서의 이미지를 유지하기 위해 AI 속의 인간 노동을 비가시화하는 ‘노동의 비가시화’와, 정치 · 경제적 고려하에 인간 노동과 AI 노동이 배분되는 ‘경계 짓기의 정치경제’라는 기술정치가 작동하고 있다는 점을 주장할 것이다. 마지막으로 이 글은 AI와 노동의 미래와 관련해 노동의 소멸을 본격적으로 논의하기 이전에 이런 기술정치에 대항해 AI 기술의 투명성과 책임성을 요청할 필요가 있다고 제안할 것이다.","With the rapid advance of Artificial Intelligence(AI) and robot technologies in recent years, it is widely expected that the relationship between technology and labor will be drastically transformed unlike in the past. Some scholars and visionaries predict a gloomy future for human workers, saying that AI such as machine learning will replace humans’ jobs requiring sophisticated cognition abilities as well as routine clerical capabilities. This paper, far from adding comments to the debates on the massive technological unemployment, pays attention to how AI plays out in working practice of large digital corporations and what missions human workers carry out along with AI. Rather than pitting AI against humans, I explore how AI and humans are intertwined in work settings and how ‘humanness’ and ‘machineness’ are negotiated and constructed in this process. After investigating several human labors constituting AI, such as data labelling, content moderation and topics trending, this paper shows that AI has been increasingly producing lots of precarious low-income jobs, for gig workers whom I call ‘Precariat-in-the-Loop’, rather than just removing lots of human jobs. In addition, I argue that there are two underlying politics of technology, that is, one is ‘the invisiblization of labor’ to make human labor invisible in order to maintain the image as an innovative company, and the other is ‘the political economy of boundary making’ to distribute the work between humans and AI under the consideration of political economy. In the end, this paper suggests that we need to stand up to the dominant politics of technology and ask for more transparency and accountability of AI technology from digital giant companies, rather than discuss the end of labor."
거래량 급감 패턴의 감독 학습에 기반한 단기 주가 예측,2018,"['거래량', '거래량 패턴', '이동 평균', '신경망', '주가 예측', 'trading volume', 'volume pattern', 'moving average', 'neural network', 'stock price prediction']","기계 학습을 포함하는 인공 지능 기술의 급속한 발전에 힘입어, 최근 많은 연구자들이 지능형 주식 거래 및 포트폴리오 관리 시스템의 구축을 위한 다양한 방식들을 제안하였다. 본 논문은 거래량 급감 패턴에 기반한 새로운 단기 주가 예측 방식을 제안한다. 다중의 거래량 이동 평균선 간 조합에 기반하여 두 가지의 거래량 패턴을 정의한다. 이들 패턴에 의해 필터링된 데이터 집합에 대해 신경망에 의한 감독 학습을 수행한다. 한국 거래소 시장 및 코스닥 시장에서 수집한 데이터에 대해 수행한 실험 결과를 통해, 제안하는 예측 시스템이 시장 평균을 상회하는 거래 성능을 달성할 수 있음을 보인다.","Recently many researchers have proposed various methods to build an intelligent stock trading and portfolio management systems with the help of rapid advancement in the artificial intelligence including machine learning techniques. The present work proposes a novel method for short-term stock price prediction based on rapid volume decreasing patterns. Two volume patterns were defined based on the combinations of multiple moving average lines of volumes. The dataset filtered by those patterns was learned by supervised learning of neural networks. Experimental results based on the data from KOSPI and KOSDAQ, show that the proposed prediction system can achieve the trading performance by outperforming the market averages."
Efficient Hybrid Transactional Memory Scheme using Near-optimal Retry Computation and Sophisticated Memory Management in Multi-core Environment,2018,"['Bloom Filter', 'Concurrency Control', 'Hybrid Transactional Memory', 'Multi-core in-Memory Databases']",,"Recently, hybrid transactional memory (HyTM) has gained much interest from researchers because itcombines the advantages of hardware transactional memory (HTM) and software transactional memory(STM). To provide the concurrency control of transactions, the existing HyTM-based studies use a bloomfilter. However, they fail to overcome the typical false positive errors of a bloom filter. Though the existingstudies use a global lock, the efficiency of global lock-based memory allocation is significantly low in multicoreenvironment. In this paper, we propose an efficient hybrid transactional memory scheme using nearoptimalretry computation and sophisticated memory management in order to efficiently process transactionsin multi-core environment. First, we propose a near-optimal retry computation algorithm that provides anefficient HTM configuration using machine learning algorithms, according to the characteristic of a givenworkload. Second, we provide an efficient concurrency control for transactions in different environments byusing a sophisticated bloom filter. Third, we propose a memory management scheme being optimized for theCPU cache line, in order to provide a fast transaction processing. Finally, it is shown from our performanceevaluation that our HyTM scheme achieves up to 2.5 times better performance by using the Stanfordtransactional applications for multi-processing (STAMP) benchmarks than the state-of-the-art algorithms."
미세먼지 수치 예측 모델 구현을 위한 데이터마이닝 알고리즘 개발,2018,"['ANN', 'K-NN']",,"Recently, as the fine dust level has risen rapidly, there is a great interest. Exposure to fine dust is associated with the development of respiratory and cardiovascular diseases and has been reported to increase death rate. In addition, there exist damage to fine dusts continues at industrial sites. However, exposure to fine dust is inevitable in modern life. Therefore, predicting and minimizing exposure to fine dust is the most efficient way to reduce health and industrial damages. Existing fine dust prediction model is estimated as good, normal, poor, and very bad, depending on the concentration range of the fine dust rather than the concentration value. In this paper, we study and implement to predict the PM10 level by applying the Artificial neural network algorithm and the K-Nearest Neighbor algorithm, which are machine learning algorithms, using the actual weather and air quality data."
漢文科에서의 傳統的 價値觀 授業 方案 硏究 - Google Docs 활용을 기반으로 -,2018,"['전통적 가치관 교육', '인간 중심 교육', '인성교육', 'Google Docs', '책 쓰기', 'Traditional values education', 'Human-centered education', 'Personality education', 'Google Docs', 'Writing books']","고등학교 한문 수업 시간에 학생들이 학습한 한문 단문의 주제를 활용하여 동화, 소설, 에세이 등의 책 쓰기를 통한 전통적 가치관 교육을 시도하고자 한다. 그리고 대부분의 학습자들은 손 글씨 보다 컴퓨터 자판을 이용하여 글 쓰는 것을 선호한다. 손으로 쓰는 것보다 쓰는 속도가 빠르고, 틀린 것을 수정하거나 새로운 문장을 삽입하는 작업이 편하기 때문이다. 따라서 본 연구에서 정보검색, 퇴고 및 상호 교차 검토가 용이한 Google Docs를 활용한 책 쓰기 수업을 한문과에서 활용할 수 있는 전통적 가치관 수업 방법으로 제안하는 것을 목적으로 한다. 이와 같은 연구 목적을 달성하기 위해 ⅰ) 전통적 가치관의 의미를 이해시키고 삶의 맥락과 관련한 전통적 가치관 수업 방안을 모색하기 위해 관련 선행 연구를 고찰하고, 4차 산업혁명 시대를 맞이한 학생들에게 컴퓨터와 디지털 테크놀로지를 활용해 다양한 계통을 융합할 수 있는 능력을 배양하게 하는 수업 방법을 탐색하여 ⅱ) Google Docs 활용 책 쓰기를 통한 전통적 가치관 수업을 구안·적용하여 인간 중심의 가치를 생각하고, 앞으로의 한문과 전통적 가치관 교육이 나아가야할 방향을 모색해보는 것을 연구 문제로 상정한다. 전통적 가치관 교육이 단순히 과거의 전통적 규범과 가치를 배우는데 그칠 것이 아니라, 급변하는 미래 사회가 인간 중심 사회로서 유지될 수 있도록 하는 밑바탕을 만들어주는 교육이 되어야 한다고 생각한다. 사물인터넷과 인공지능, 머신러닝(MACHINE LEARNING), 가상･증강현실, 3D 프린팅, 생명공학과 바이오 등의 기술이 우리 삶 속에 깊이 자리 잡게 된 4차 산업혁명 시대는 언뜻 보기에는 과학이 인간의 삶을 관여하는 ‘기술 중심적 사회’로 보인다. 하지만 잘 들여다보면 오히려 사람과 기술이 조화를 이루고 비판적 사고와 창의력으로 문제를 해결해 나가야 하는 ‘인간 중심적 사회’라 할 수 있다. 따라서 이 시대에 걸맞은 능력을 가진 인재는 융･복합적 문제해결능력 뿐만 아니라 인간의 가치를 소중히 여길 줄 아는 건전한 가치관과 바른 인성을 갖추고 있어야 함을 기억해야 한다.","Utilizing the subject of Chinese short sentences students learned in a Chinese writing class of a high school, this paper aims to attempt traditional values education through writing books such as children’s stories, novels, essay, etc. This study was intended to propose book writing class utilizing Google Docs which easily enables information search, revision and mutual cross review in a traditional values education method which can be utilized by Chinese writing department. In order to achieve such a studying purpose, as study tasks, the author proposes ⅰ) to consider relevant preceding studies for the purpose of understanding meanings of traditional values and seeking a traditional values class related to context of life and, by searching a class method of giving students who greeted the 4th industrial age the ability to be able to combine various series utilizing a computer and digital technology ⅱ) to think men-centered value by applying traditional values class through writing books utilizing Google Docs, and seek the direction in which the future Chinese writing and traditional values education have to proceed. The traditional value education shall be an education forming the basis so that rapidly changing future society may be maintained as men-centered society, and focus on developing sound values and proper character able to cherish the value of human beings."
"Short-time Fourier transform 소음맵을 이용한 컨볼루션 기반 BSR (Buzz, Squeak, Rattle) 소음 분류",2018,"['BSR (Buzz', 'Squeak', 'Rattle)']",,"There are three types of noise generated inside the vehicle: BSR (Buzz, Squeak, Rattle). In this paper, we propose a classifier that automatically classifies automotive BSR noise by using features extracted from deep convolutional neural networks. In the preprocessing process, the features of above three noises are represented as noise-map using STFT (Short-time Fourier Transform) algorithm. In order to cope with the problem that the position of the actual noise is unknown in the part of the generated noise map, the noise map is divided using the sliding window method. In this paper, internal parameter of the deep convolutional neural networks is visualized using the t-SNE (t-Stochastic Neighbor Embedding) algorithm, and the misclassified data is analyzed in a qualitative way. In order to analyze the classified data, the similarity of the noise type was quantified by SSIM (Structural Similarity Index) value, and it was found that the retractor tremble sound is most similar to the normal travel sound. The classifier of the proposed method compared with other classifiers of machine learning method recorded the highest classification accuracy (99.15 %)."
Design of Reinforced Interval Type-2 Fuzzy C-Means-Based Fuzzy Classifier,2018,,,"<P>This paper is concerned with a new design methodology of a reinforced interval type-2 fuzzy c-means (FCM) based fuzzy classifier (FC). The key point of this study is to reduce the computational complexity of type-2 fuzzy set-based models and to alleviate the deterioration of its generalization abilities through the synergistic effect of two algorithms: First, interval type-2 FCM (IT2FCM) is used in the hidden layer of the network and connections (weights) are adjusted by invoking the least squares error estimation method. Second, an L<SUB>2</SUB>-norm regularization is considered in the cost function to avoid the construction of the network suffering from overfitting. In more detail, the hidden layer of the proposed FC is realized by interval type-2 FCM clustering to deal with the factor of uncertainty involved in the problem. This type of clustering is realized by using two values of the fuzzification coefficient resulting in the interval type-2 membership functions. Once completing type reduction, the membership grades of IT2FCM are used as the outputs of the hidden layer. Instead of the backpropagation training, least squares estimator based learning is applied to adjust the functional connection being regarded as linear functions mapping the hidden layer to the output layer. In order to reduce potential overfitting, L<SUB>2</SUB>-norm regularization is taken into account. The effectiveness of the proposed classifier is analyzed with the aid of a number of machine learning datasets as well as face image datasets. Thorough comparative studies are also included.</P>"
Efficient Hybrid Transactional Memory Scheme using Near-optimal Retry Computation and Sophisticated Memory Management in Multi-core Environment,2018,"['Bloom Filter', 'Concurrency Control', 'Hybrid Transactional Memory', 'Multi-core in-Memory Databases']",,"Recently, hybrid transactional memory (HyTM) has gained much interest from researchers because it combines the advantages of hardware transactional memory (HTM) and software transactional memory (STM). To provide the concurrency control of transactions, the existing HyTM-based studies use a bloom filter. However, they fail to overcome the typical false positive errors of a bloom filter. Though the existing studies use a global lock, the efficiency of global lock-based memory allocation is significantly low in multicore environment. In this paper, we propose an efficient hybrid transactional memory scheme using nearoptimal retry computation and sophisticated memory management in order to efficiently process transactions in multi-core environment. First, we propose a near-optimal retry computation algorithm that provides an efficient HTM configuration using machine learning algorithms, according to the characteristic of a given workload. Second, we provide an efficient concurrency control for transactions in different environments by using a sophisticated bloom filter. Third, we propose a memory management scheme being optimized for the CPU cache line, in order to provide a fast transaction processing. Finally, it is shown from our performance evaluation that our HyTM scheme achieves up to 2.5 times better performance by using the Stanford transactional applications for multi-processing (STAMP) benchmarks than the state-of-the-art algorithms."
핀테크 기반 주식투자 최적화 모델 구축 사례 연구 : 기관투자자 대상,2018,"['artificial intelligence', 'portfolio optimization', 'institutional investor`s equity investment style']",,"The finance-investment industry is currently focusing on research related to artificial intelligence and big data, moving beyond conventional theories of financial engineering. However, the case of equity optimization portfolio by using an artificial intelligence, big data, and its performance is rarely realized in practice. Thus, the purpose of this study is to propose process improvements in equity selection, information analysis, and portfolio composition, and lastly an improvement in portfolio returns, with the case of an equity optimization model based on quantitative research by an artificial intelligence. This paper is an empirical study of the portfolio based on an artificial intelligence technology of “D” asset management, which is the largest domestic active-quant-fiduciary management in accordance with the purpose of this paper. This study will apply artificial intelligence to finance, analyzing financial and demand-supply information and automating factor-selection and weight of equity through machine learning based on the artificial neural network. Also, the learning the process for the composition of portfolio optimization and its performance by applying genetic algorithms to models will be documented. This study posits a model that the asset management industry can achieve, with continuous and stable excess performance, low costs and high efficiency in the process of investment."
Reinforced hybrid interval fuzzy neural networks architecture: Design and analysis,2018,"['Data preprocessing technique', 'Fuzzy c-means', 'Interval fuzzy neural networks (ifnn)', 'Linear discriminant function', 'Particle swarm optimization', 'Principal component analysis', 'Type-2 fuzzy set']",,"<P>This paper is concerned with a new architecture of a reinforced hybrid interval fuzzy neural networks (RHIFNN) classifier developed with aid of Fuzzy C-Means (FCM) clustering and Particle Swarm Optimization (PSO). The key objectives of this study concern the following: (a) selection of preprocessing techniques for the dimensionality reduction of input space. Linear discriminant analysis (LDA) or principal component analysis (PCA) algorithm forms a front end of the network to form the low-dimensional input variables. (b) The efficient process of dealing with uncertain information by interval type-2 fuzzy sets using Fuzzy C-Means (FCM) clustering. The premise (condition) part of the rules is realized by two FCM clustering algorithms, which are invoked by using different values of the fuzzification coefficient subsequently resulting in interval-valued type-2 membership functions. (c) The simultaneous structural and parametric optimization of network by evolutionary algorithm is completed. The parameters of the network including both the premise and consequent parts are optimized by means of the particle swarm optimization (PSO). The proposed classifier is applied to a variety of machine learning datasets and the results are compared with those provided by other classifiers reported in the literature.</P>"
Digital Epidemiology: Use of Digital Data Collected for Non-epidemiological Purposes in Epidemiological Studies,2018,"['Public Health Surveillance', 'Epidemiology', 'Epidemiological Monitoring', 'Social Media', 'Internet']",,"Objectives: We reviewed digital epidemiological studies to characterize how researchers are using digital data by topic domain, study purpose, data source, and analytic method. Methods: We reviewed research articles published within the last decade that used digital data to answer epidemiological research questions. Data were abstracted from these articles using a data collection tool that we developed. Finally, we summarized the characteristics of the digital epidemiological studies. Results: We identified six main topic domains: infectious diseases (58.7%), non-communicable diseases (29.4%), mental health and substance use (8.3%), general population behavior (4.6%), environmental, dietary, and lifestyle (4.6%), and vital status (0.9%). We identified four categories for the study purpose: description (22.9%), exploration (34.9%), explanation (27.5%), and prediction and control (14.7%). We identified eight categories for the data sources: web search query (52.3%), social media posts (31.2%), web portal posts (11.9%), webpage access logs (7.3%), images (7.3%), mobile phone network data (1.8%), global positioning system data (1.8%), and others (2.8%). Of these, 50.5% used correlation analyses, 41.3% regression analyses, 25.6% machine learning, and 19.3% descriptive analyses. Conclusions: Digital data collected for non-epidemiological purposes are being used to study health phenomena in a variety of topic domains. Digital epidemiology requires access to large datasets and advanced analytics. Ensuring open access is clearly at odds with the desire to have as little personal data as possible in these large datasets to protect privacy. Establishment of data cooperatives with restricted access may be a solution to this dilemma."
Efficient Hybrid Transactional Memory Scheme using Near-optimal Retry Computation and Sophisticated Memory Management in Multi-core Environment,2018,"['Bloom Filter', 'Concurrency Control', 'Hybrid Transactional Memory', 'Multi-core in-Memory Databases']",,"Recently, hybrid transactional memory (HyTM) has gained much interest from researchers because it combines the advantages of hardware transactional memory (HTM) and software transactional memory (STM). To provide the concurrency control of transactions, the existing HyTM-based studies use a bloom filter. However, they fail to overcome the typical false positive errors of a bloom filter. Though the existing studies use a global lock, the efficiency of global lock-based memory allocation is significantly low in multi-core environment. In this paper, we propose an efficient hybrid transactional memory scheme using near-optimal retry computation and sophisticated memory management in order to efficiently process transactions in multi-core environment. First, we propose a near-optimal retry computation algorithm that provides an efficient HTM configuration using machine learning algorithms, according to the characteristic of a given workload. Second, we provide an efficient concurrency control for transactions in different environments by using a sophisticated bloom filter. Third, we propose a memory management scheme being optimized for the CPU cache line, in order to provide a fast transaction processing. Finally, it is shown from our performance evaluation that our HyTM scheme achieves up to 2.5 times better performance by using the Stanford transactional applications for multi-processing (STAMP) benchmarks than the state-of-the-art algorithms."
Korean Traditional Music Genre Classification Using Sample and MIDI Phrases,2018,"['Music genre classification', 'music sample analysis', 'MIDI analysis', 'Korean traditional music', 'music editor']",,"This paper proposes a MIDI- and audio-based music genre classification method for Korean traditional music. There are many traditional instruments in Korea, and most of the traditional songs played using the instruments have similar patterns and rhythms. Although music information processing such as music genre classification and audio melody extraction have been studied, most studies have focused on pop, jazz, rock, and other universal genres. There are few studies on Korean traditional music because of the lack of datasets. This paper analyzes raw audio and MIDI phrases in Korean traditional music, performed using Korean traditional musical instruments. The classified samples and MIDI, based on our classification system, will be used to construct a database or to implement our Kontakt-based instrument library. Thus, we can construct a management system for a Korean traditional music library using this classification system. Appropriate feature sets for raw audio and MIDI phrases are proposed and the classification results―based on machine learning algorithms such as support vector machine, multi-layer perception, decision tree, and random forest―are outlined in this paper."
5G-Smart Diabetes: Toward Personalized Diabetes Diagnosis with Healthcare Big Data Clouds,2018,,,"<P>Recent advances in wireless networking and big data technologies, such as 5G networks, medical big data analytics, and the Internet of Things, along with recent developments in wearable computing and artificial intelligence, are enabling the development and implementation of innovative diabetes monitoring systems and applications. Due to the life-long and systematic harm suffered by diabetes patients, it is critical to design effective methods for the diagnosis and treatment of diabetes. Based on our comprehensive investigation, this article classifies those methods into Diabetes 1.0 and Diabetes 2.0, which exhibit deficiencies in terms of networking and intelligence. Thus, our goal is to design a sustainable, cost-effective, and intelligent diabetes diagnosis solution with personalized treatment. In this article, we first propose the 5G-Smart Diabetes system, which combines the state-of-the-art technologies such as wearable 2.0, machine learning, and big data to generate comprehensive sensing and analysis for patients suffering from diabetes. Then we present the data sharing mechanism and personalized data analysis model for 5G-Smart Diabetes. Finally, we build a 5G-Smart Diabetes testbed that includes smart clothing, smartphone, and big data clouds. The experimental results show that our system can effectively provide personalized diagnosis and treatment suggestions to patients.</P>"
A study on Classification of Insider threat using Markov Chain Model,2018,"['Insider threat', 'Markov Chain', 'Classification']",,"In this paper, a method to classify insider threat activity is introduced. The internal threats help detecting anomalous activity in the procedure performed by the user in an organization. When an anomalous value deviating from the overall behavior is displayed, we consider it as an inside threat for classification as an inside intimidator. To solve the situation, Markov Chain Model is employed. The Markov Chain Model shows the next state value through an arbitrary variable affected by the previous event. Similarly, the current activity can also be predicted based on the previous activity for the insider threat activity. A method was studied where the change items for such state are defined by a transition probability, and classified as detection of anomaly of the inside threat through values for a probability variable. We use the properties of the Markov chains to list the behavior of the user over time and to classify which state they belong to. Sequential data sets were generated according to the influence of n occurrences of Markov attribute and classified by machine learning algorithm. In the experiment, only 15% of the Cert: insider threat dataset was applied, and the result was 97% accuracy except for NaiveBayes. As a result of our research, it was confirmed that the Markov Chain Model can classify insider threats and can be fully utilized for user behavior classification."
Gaussian Process Regression and Classification for Probabilistic Damage Assessment of Spatially Distributed Systems,2018,"['binary components', 'gaussian process classification', 'probabilistic inference', 'spatially distributed systems']",,"We illustrate how methods for non-parametric regression and classification based on Gaussian Processes can be adapted for inferring the condition state of infrastructure components under spatially distributed stressors. When the stressor is modeled by a random field, observations collected in one location can reduce the uncertainty about the stressor intensity also in other locations.Exact inference is possible when the field is Gaussian and observations are perfect or affected by Gaussian noise. However, often the available observations are binary, as those related to the failure or survival of components, and indicate whether the local field is above or below a threshold whose value may also be uncertain. While no efficient scheme for exact inference is available in that setting, we can perform efficient approximate inference when the field is Gaussian and so is the uncertainty on the threshold value.The mathematical formulation for this problem is analogous to that of classification in machine learning, that can be based on latent Gaussian processes. We show how to formulate the problem and how to adapt deterministic methods, as Laplace’s method and Expectation Propagation, and methods based on random number generation, as Monte Carlo uniform sampling and importance sampling, to perform approximate inference. Our illustrative application is the condition assessment of assets exposed to a seismic event. Under specific assumptions, the seismic demand can be modeled as a Gaussian random field, and measures about the demand and about the survival and failure of assets can be processed globally, to update the risk assessment. Specifically, we evaluate methods for approximate inference and discuss their merits."
Endpoint에 적용 가능한 정적 feature 기반 고속의 사이버 침투공격 분석기술 연구,2018,"['악성코드', '정적분석', '기계학습', 'Malware', 'Static analysis', 'Deep neural network']",,"Cyber penetration attacks can not only damage cyber space but can attack entire infrastructure such as electricity, gas, water, and nuclear power, which can cause enormous damage to the lives of the people. Also, cyber space has already been defined as the fifth battlefield, and strategic responses are very important. Most of recent cyber attacks are caused by malicious code, and since the number is more than 1.6 million per day, automated analysis technology to cope with a large amount of malicious code is very important. However, it is difficult to deal with malicious code encryption, obfuscation and packing, and the dynamic analysis technique is not limited to the performance requirements of dynamic analysis but also to the virtual There is a limit in coping with environment avoiding technology. In this paper, we propose a machine learning based malicious code analysis technique which improve the weakness of the detection performance of existing analysis technology while maintaining the light and high-speed analysis performance applicable to commercial endpoints. The results of this study show that 99.13% accuracy, 99.26% precision and 99.09% recall analysis performance of 71,000 normal file and malicious code in commercial environment and analysis time in PC environment can be analyzed more than 5 per second, and it can be operated independently in the endpoint environment and it is considered that it works in complementary form in operation in conjunction with existing antivirus technology and static and dynamic analysis technology. It is also expected to be used as a core element of EDR technology and malware variant analysis."
파티클 필터 기반 시계열 예측 결합 모델을 통한 전시장 방문 인원 예측,2018,"['Building occupancy data', 'Time-series prediction', 'ARIMA', 'Holt-Winters', 'Particle filter', '재실인원 데이터', '시계열 예측', 'ARIMA', 'Holt-Winters', '파티클 필터']",쾌적한 환경을 제공하면서 에너지 사용량을 최적화하는 기법에 대한 연구는 전시장 관리 시스템의 주요 문제 중 하나이다. 쾌적한 전시 환경을 유지함과 동시에 전시장 에너지 사용량을 최적화하기 위해서 재실 인원데이터 분석이 필수적이다. 전시장에서 수집된 시간별 방문객 데이터 분석에 기반 한 미래 재실 인원 예측을 통해 최적의 에너지를 사용하는 전시장 냉난방 제어 계획을 미리 수립하고 이를 전시장 제어 시스템에 적용할수 있다. 정확한 미래 재실 인원 예측을 위하여 시계열 예측에 널리 사용되는 Holt-Winters 모형과 ARIMA 모형을 적용해 볼 수 있으나 예측 시점이 멀어질수록 예측 정확도가 떨어진다는 문제점이 있다. 본 연구에서는 두 대표적인 시계열 모형을 활용하여 우선 시간별 인원 데이터 예측을 진행하고 머신러닝의 기법의 하나인 파티클 필터를 이용한 오차 스무딩으로 두 모델의 결과를 결합하는 시계열 예측 모델을 제안한다. 제안한 모델을 킨텍스 제 7홀 전시장에서 진행된 2017년 전시 관람객 데이터에 적용하여 기존의 예측 모델과의 정확도 비교를 통해 제안한 모델을 검증하였다. 미래 재실 인원에 대한 정확한 예측으로 보다 효율적인 대형 전시장 냉난방 제어를 통한 에너지 사용 최적화를 더욱 앞당길 것으로 기대한다.,"The demand for exhibition building management has been focused on optimizing energy consumption while providing a pleasant environment. To investigate a method for optimizing energy usage while maintaining the good exhibition condition, the analysis of visitors’ occupancy data is essential. The accurate prediction of visitors’ occupancy enables to schedule an efficient air conditioning plan and to apply it to air conditioning control systems. Holt-Winters and ARIMA models popular in time series data analysis can be applied to predict the occupancy of visitors accurately, but the prediction accuracy of these models drops substantially as the prediction time-point becomes further. In this study, we applied Holt-Winters and ARIMA models for predicting the number of visitors in various time-points first and then combined two results using error smoothing via a machine learning approach, particle filter. The prediction results obtained by our proposed model was compared with the pure ARIMA and Holts-Winter models for evaluation using visitors’ occupancy data collected in real time at the KINTEX exhibition hall 7 in 2017. The accurate prediction of building occupancy will accelerate the optimization of energy consumption via more efficient air conditioning control in large scale exhibition halls."
Flexible and Printed PPG Sensors for Estimation of Drowsiness,2018,,,"<P>We report printed flexible optoelectronic sensors composed of red organic light-emitting diodes (OLEDs) and organic photodiodes (OPDs) for detection of various biological signals in a photoplethysmograph (PPG) device. Fabricated flexible OLEDs achieved maximum luminance >1000 cd/m<SUP>2</SUP> at 9 V, with peak at 640 nm. Maximum flexible OPD photosensitivity for the poly(3-hexylthiophene-2, 5-diyl) and phenyl-C61-butyric acid methyl ester (PCBM) heterojunction is <TEX>$ {2} \times {10}^{{2}}$</TEX> at 0 V and 1.76 at −1 V, irradiated with 1.2 mW/cm<SUP>2</SUP> at 660 nm. The diketopyrrolopyrrole thieno [3,2-b]thiophene blended with PCBM OPDs with poly (3,4-ethylenedioxythiophene):polystyrene sulfonate anode showed photosensitivity = 84 at −1 V bias to almost <TEX>${6} \times {10}^{{4}}$</TEX> at 0 V accompanied by low dark current ( <TEX>${9.5} \times {10}^{-{8}}$</TEX> A/cm<SUP>2</SUP> at −1 V). PPG signals were successfully detected using the developed flexible PPG sensor and the conventional driving circuit. Human studies were conducted to evaluate the flexible PPG sensor performance in practical applications. Subject drowsiness was estimated from heart rate variability, extracted from the PPG signals, using machine learning algorithms. The flexible PPG sensor achieved 79.2% accuracy and 72.1% area under the receiver (AUC) to predict drowsiness (60-s window), which are meaningful results compared with conventional PPG sensors (83.3% accuracy and 69% AUC). Drowsiness estimation experiments using two PPG signals showed that the flexible PPG sensor achieved similar or better performance compared to conventional PPG sensors.</P>"
What’s app? Electronic health technology in inflammatory bowel disease,2018,"['Mobile applications', 'Electronic health records', 'Inflammatory bowel disease']",,"Electronic health (eHealth) data collection is increasingly used in many chronic illnesses, to track pattern of disease. eHealth systems have the potential to revolutionize care. Inflammatory bowel disease (IBD) is a paradigm for such an approach: this is a chronic disease that usually affects young and technologically literate patient population, who are motivated to be involved in their own care. A range of eHealth technologies are available for IBD. This review considers the strengths and weaknesses of 7 platforms that focus on patient-provider interaction. These have been developed in Denmark, United States, the Netherlands, and the United Kingdom, demonstrating an international interest in this form of technology and interaction. Not only do these technologies aim to improve care but they also have the potential to collect large amounts of information. Information includes demographics and patient reported outcomes (symptoms, quality of life), quality of care (steroid use, among other metrics) and outcomes such as hospitalization. These data could inform quality improvement programmes to improve their focus. eHealth technology is also open to machine learning to analyze large data sets, through which personalized algorithms may be developed."
Evaluation of summer passive microwave sea ice concentrations in the Chukchi Sea based on KOMPSAT-5 SAR and numerical weather prediction data,2018,"['Sea ice concentration', 'Sea ice algorithm', 'Passive microwave sensor', 'KOMPSAT-5', 'Synthetic aperture radar', 'Numerical weather prediction', 'Chukchi Sea']",,"<P><B>Abstract</B></P>  <P>Satellite passive microwave (PM) sensors have observed sea ice in Polar Regions and provided sea ice concentration (SIC) data since the 1970s. SIC has been used as a primary data source for climate change prediction and ship navigation. However, the accuracy of PM SIC is typically low and biased in summer. To provide more accurate information for climatic research and ship navigation, it is necessary to evaluate quantitatively the accuracy of PM SIC and to account for its errors. In this research, we evaluated the SIC data derived from PM measurements using four representative sea ice algorithms: NASA Team (NT), Bootstrap (BT), Ocean and Sea Ice Satellite Application Facility (OSISAF) hybrid, and Arctic Radiation and Turbulence Interaction STudy (ARTIST) Sea Ice (ASI). Analyses were performed for the Chukchi Sea in summer using KOrean Multi-Purpose SATellite-5 (KOMPSAT-5) Enhanced Wide-swath synthetic aperture radar (SAR) images. Ice/water maps were generated by binary classification of texture features in the SAR images based on Random Forest, a rule-based machine learning approach. SIC values estimated from the sea ice algorithms showed good correlation with those calculated from the KOMPSAT-5 ice/water maps, but the root mean square error was larger than 10%. SIC values estimated from the algorithms showed different error trends according to the KOMPSAT-5 SIC range. All algorithms overestimated SIC values in open drift ice zones (KOMPSAT-5 SICs ranged from 0% to 15%). In marginal ice zones (SICs ranged from 15% to 80%), the OSISAF SIC values were the least biased compared to those from KOMPSAT-5. The NT algorithm largely underestimated SIC values in marginal ice zones, while the BT and ASI algorithms overestimated them considerably. All algorithms, except for BT, underestimated SIC in consolidated pack ice zones (SICs ranged from 80% to 100%). By analyzing the correlations of biases of SIC from the algorithms with the numerical weather prediction (NWP) data from the European Reanalysis Agency Interim reanalysis, it was found that the overestimation of NT and ASI SICs was largely influenced by atmospheric water vapor content, while the underestimation of NT and OSISAF SICs was owing to ice surface melting. The overestimation of BT SICs was not significantly correlated with the NWP data. The underestimated SIC from the BT and ASI algorithms for high SIC regions might be compensated by the atmospheric water vapor content. The differences in SIC values estimated from each algorithm were due to different sensitivities to atmospheric water vapor content in the regions with KOMPSAT-5 SIC lower than 40% and to ice surface melting in the regions with higher KOMPSAT-5 SIC.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Summer sea ice concentration (SIC) was derived from KOMPSAT-5 SAR ice/water maps. </LI> <LI>  SICs from four sea ice algorithms for passive microwave measurements were evaluated. </LI> <LI>  SICs from the algorithms show different error trends by the KOMPSAT-5 SIC ranges. </LI> <LI>  Bias from algorithms' SICs was analyzed by using numerical weather prediction data. </LI> <LI>  SIC products by the algorithms are highly inaccurate for the Chukchi Sea in summer. </LI> </UL> </P>"
영미문학과 디지털인문학: 미국 디지털 영문학 연구 동향,2018,"['디지털인문학', '영미문학', '텍스트 분석', '멀리서 읽기', '말뭉치 분석', 'digital humanities', 'English literature', 'textual analysis', 'distant reading', 'corpus analysis']",,"Digital literary studies in the United States has developed in the form of computational text analysis since the 1960s. At first it was not properly appreciated by mainstream academia, but it began to draw public attention largely due to the rise of digital humanities discourse along with the rapid progress of digital technology at the turn of the century. English studies was one of the major disciplines that actively adopted digital humanistic methodology and applied it to research and education. Digital literary scholars have shed light on previously unknown aspects of English literature by combining text analysis and “distant reading” and by statistically analyzing large-scale corpora of literary works. They take advantage of such sophisticated methods as metadata analysis, social network analysis and visualization, topic modeling, machine learning, and geographic information system as well as traditional text analysis techniques. In contrast, Korean academics of English literature are completely indifferent to digital literary studies. Ignoring any new methodology to study literature cannot be justified at all. Someone should try it, and we should debate about its value and validity. This will surely enrich Korean academia. This paper examines major research achievements of American digital literary studies from the early years of humanities computing to the present, thus laying the groundwork for discussion on digital humanistic approaches to English literature in Korea."
SWAT 및 random forest를 이용한 기후변화에 따른 한강유역의 수생태계 건강성 지수 영향 평가,2018,"['수생태 건강성', '기후변화', '수질', 'SWAT', 'Random forest', 'Aquatic ecology health', 'Climate change', 'Water quality', 'SWAT', 'Random forest']","본 연구에서는 SWAT 모형과 random forest를 이용하여 미래 기후변화에 따른 한강유역(34,148 km2)의 수생태계 건강성을 평가하였다. 국립환경과학원에서 8년간(2008~2015년) 봄철(4~6월)에 모니터링한 부착돌말류 지수(TDI), 저서형 대형무척추동물지수(BMI), 어류평가지수(FAI)는 0~100점, A~E등급으로 평가되며, 이를 본 연구에서 사용하였다. 수생태 건강성에 영향을 미치는 변수로는 수질(T-N, NH4, NO3, T-P, PO4)과 수온을 선정하였으며, 수질 오염도가 낮은 경우에는 수생태계 건강성 점수가 광범위하게 분포되지만 수질 오염도가 높은 경우 수생태계 건강성 점수가 낮아지는 역상관관계를 확인하였다. 기계학습의 분류 분석 기법 중 하나인 random forest 모델을 이용한 세 개의 수생태 건강성 지수 등급 분류 결과 정밀도, 재현율, f1-score 모두 0.81 이상의 예측 정확도를 나타내었다. 기상청의 HadGEM3-RA RCP 4.5와 8.5 시나리오를 적용한 미래 SWAT 수문, 수질 결과 기저유출의 증가로 인해 질소 계열 수질 농도는 기준년도 대비 최대 43.2% 증가하였고, 지표유출 감소로 인해 인 계열 수질 오염도는 최대 18.9% 감소하는 것으로 분석되었다. 미래 FAI, BMI의 등급은 개선되는 경향을 보이지만 TDI는 등급이 악화되는 것으로 나타났다. 이를 통해 TDI는 질소 계열 수질에 민감하고 FAI, BMI는 인 계열 수질에 더 민감하다고 판단하였다.","The purpose of this study is to evaluate the future climate change impact on stream aquatic ecology health of Han River watershed (34,148 km2) using SWAT (Soil and Water Assessment Tool) and random forest. The 8 years (2008~2015) spring (April to June) Aquatic ecology Health Indices (AHI) such as Trophic Diatom Index (TDI), Benthic Macroinvertebrate Index (BMI) and Fish Assessment Index (FAI) scored (0~100) and graded (A~E) by NIER (National Institute of Environmental Research) were used. The 8 years NIER indices with the water quality (T-N, NH4, NO3, T-P, PO4) showed that the deviation of AHI score is large when the concentration of water quality is low, and AHI score had negative correlation when the concentration is high. By using random forest, one of the Machine Learning techniques for classification analysis, the classification results for the 3 indices grade showed that all of precision, recall, and f1-score were above 0.81. The future SWAT hydrology and water quality results under HadGEM3-RA RCP 4.5 and 8.5 scenarios of Korea Meteorological Administration (KMA) showed that the future nitrogen-related water quality in watershed average increased up to 43.2% by the baseflow increase effect and the phosphorus-related water quality decreased up to 18.9% by the surface runoff decrease effect. The future FAI and BMI showed a little better Index grade while the future TDI showed a little worse index grade. We can infer that the future TDI is more sensitive to nitrogen-related water quality and the future FAI and BMI are responded to phosphorus-related water quality."
약점지능향상을 위한 스마트단말 어플리케이션 개발 및 효과,2018,"['스마트 단말 어플리케이션', '다중지능', '약점지능', '자연친화지능', '언어지능', 'smart device application', 'multiple intelligence', 'weak intelligence', 'naturalistic intelligence', 'linguistic intelligence']","지속적인 정보통신기술의 발달로 인해서, 사회 및 경제 분야들과의 융합이 발생하는 4차 산업혁명이 예견되고 있다. 4차 산업혁명으로 인해 많은 업무들이 기계 또는 인공지능에 의해 대체되고, 새로운 형태의 산업들이 나타날 것으로 예상된다. 이러한 산업 변화에 빠르게 대응하기 위해서, 창의적 융합 인재의 중요성이 증가하고 있다. 창의적 융합 인재 양성을 위해서는 다양한 분야의 지식과 능력의 개발이 필수적이다. 인간의 지능이 8개의 지능으로 구성되어 있다는 다중지능이론을 기반으로 모든 지능들을 발달시켜야 한다. 기존의 IQ검사는 언어, 수리, 논리 능력만을 평가하여 다양한 분야의 지능 개발에 어려움이 있다. 다양한 지능 개발을 위해서는 지능간의 균형이 필요하다. 본 연구에서는 약점지능 향상을 위한 학습 효율을 높이기 위해서 스마트 단말 어플리케이션을 개발하고자 한다. 초등학생들을 대상으로 다중지능검사를 수행하고, 결과를 기반으로 두 지능을 약점지능으로 결정하였다. 개발한 어플리케이션을 통한 학습 후, 약점지능으로 선택된 자연친화지능과 언어지능의 점수가 향상된 것을 확인하였다.","Due to the continuous improvement of information and communication technology, the fourth industrial revolution will occur where the convergence of social, economy, and etc. will occur. In the fourth industrial revolution, many jobs are supposed to be replace by machine and AI, new types of industries will be emerged. In order to deal with the industrial change, the creative person who is able to combine different domain knowledge is required. For that, a person has to develop abilities and learn knowledge in various fields. According to the theory of multiple intelligence, an intelligence is composed of eight criteria. Since the IQ test focuses linguistic, mathematical, and logical intelligence, the improvement of multiple intelligences is limited. For balanced intelligence improvement, weak intelligence should be further improved. In this paper, we propose the smart device application to efficiently improve the weak intelligence. We conducted multiple intelligence test for elementary school student and determined two weak intelligences. Students learned through smart device application, and we confirmed that the test results improve."
베타 회귀분석과 R 텍스트 마이닝을 이용한 특허 마이닝,2018,"['특허마이닝', '기술예측', '베타회귀분석', 'R 데이터언어', '텍스트마이닝', 'Patent Mining', 'Technology Forecasting', 'Beta Regression', 'R Data Language', 'Text Mining']","개발된 기술에 대한 특허는 숫자, 문자, 그림 등으로 이루어진 문서형식이다. 특허 마이닝은 대규모 특허문서 데이터로부터 기술과 관련된 다양한 지식을 추출하는 도구와 방법이다. 문서는 대부분 텍스트로 구성되어 있기 때문에 특허 마이닝에서는 텍스트 데이터를 처리하고 분석할 수 있는 텍스트 마이닝이 필요하다. 텍스트 마이닝을 지원하는 프로그래밍 언어로 본 논문에서는 R을 사용한다. R은 텍스트 마이닝 뿐만 아니라 대부분의 통계분석과 기계학습 알고리즘을 지원한다. 제안 방법에서 사용되는 베타 회귀분석도 R의 통계 패키지를 이용하여 수행된다. 반응변수가 0에서 1사이의 값을 갖는 베타 회귀분석의 특성을 이용하여 본 연구에서는 특허문서로부터 추출된 키워드 사이의 기술 연관성을 찾는 방법을 제안한다. 제안모형의 성능평가를 위하여 실제 특허문서를 이용한 실험을 수행한다.","Patents for developed technologies are in the form of documents consisting of numbers, texts and pictures. Patent mining means tools and methods for extracting various knowledge related to technology from large-scale patent document data. Since documents are mostly text, patent mining requires text mining to process and analyze text data. Also, R is used as a programming language that supports text mining. R supports almost all statistical analysis and machine learning algorithms as well as text mining. The beta regression analysis used in the proposed method is also performed using the R statistical package. In this paper, we propose a method to find the technological relation between patent keywords extracted from patent documents by using the characteristics of beta regression analysis with response variables between 0 and 1. Experiments using real patent documents are performed to evaluate the performance of the proposed model."
그림자 추적 센서와 패턴인식 기술을 이용한물벼룩 생태독성 분석 장치 개발,2018,"['Ecotoxicology', 'Daphnia Magna', 'Patten recognition', 'Shadow Tracking sensor', '생태독성', '물벼룩', '패턴인식', '그림자추적센서']","본 논문에서는 독성물질에 노출된 물벼룩의 행동 패턴에 따라 독성도를 판단하는 방법을 제안하였다. 다양한 조건에서의 물벼룩의 그림자 추적 장치와 인공지능 기법을 이용하여 행동 패턴을 분석하여 범주화하고 범주화된 자료를 이용하여 행동 패턴의 변화만으로 독성도를 평가하였다. 이를 위하여 중크롬산칼륨(potassium dichromate, K2Cr2O7), 염화칼륨(potassium chloride, KCl), 염화카드뮴(cadmium chloride, CdCl2), 염화암모늄(ammonium chloride, NH4Cl)의 4가지 물질을 선정하여 생태독성시험 절차에 따라 실험을 진행하였으며 EC50 및 TU1~5에 해당하는 농도를 산정하였다. 또한 물벼룩 이동 경로 검출용 광 감지 시스템을 제작하여 각 TU에 해당하는 농도에서의 물벼룩의 행동 패턴 데이터를 수집하였다. 물벼룩의 움직임을 1초에 한번을 측정하여(x, y) 좌표로 인식하여 분석을 위한 데이터로 활용하였고 이 데이터는머신 러닝에서 인공 지능을 학습하는 용도와 학습된 인공 지능의 정확성을 검증하는 용도로 사용하였다. TU1~5 각각에대하여 5번의 생태독성실험을 실시하여 25개의 학습 데이터를 이용하여 50번을 반복적으로 학습하였다. 학습된 인공지능의 성능을 시험하기 위해서 5개의 검증 데이터를 사용하였고 5개 모두 분류에 성공하여 100%의 정확성을 도출하였다.","In this paper, we propose a method to determine toxicity according to the behavior pattern of Daphnia Magna exposed to toxic substances. The behavior pattern was analyzed by using the shadow tracking device and the artificial intelligence technique in various conditions and categorized. We show the toxicity can be evaluated only by the observation of the behavior pattern using the categorized data. For this purpose, we select four substances; potassium dichromate (K2Cr2O7), potassium chloride (KCl), cadmium chloride (CdCl2) and ammonium chloride (NH4Cl). Experiments were conducted according to the ecotoxicity test procedure and the density corresponding to EC50 and TU1~5 were calculated. In addition, a light sensing system for detecting the movement path of Daphnia Magna was constructed and the behavior pattern data of Daphnia Magna at the density corresponding to each TU was collected. The movement of the Daphnia Magna was measured once a second and used as data for analysis by recognizing them as (x, y) coordinates. This data was used to train artificial intelligence and to verify the accuracy of learned artificial intelligence. We conducted five ecotoxicity tests for each of TU1~5 and repeatedly learned 50 times using 25 training data. In order to test the performance of the learned artificial intelligence, five verification data were used and all five were classified successfully and 100% accuracy was obtained."
CNN 기반 동영상의 프레임 삭제 검출 기법,2018,"['Video Forensics', 'Frame Deletion', 'HEVC', 'CNN', 'Coding Pattern']",,"In this paper, we introduce a technique to detect the video forgery by using the regularity that occurs in the video compression process. The proposed method uses the hierarchical regularity lost by the video double compression and the frame deletion. In order to extract such irregularities, the depth information of CU and TU, which are basic units of HEVC, is used. For improving performance, we make a depth map of CU and TU using local information, and then create input data by grouping them in GoP units. We made a decision whether or not the video is double-compressed and forged by using a general three-dimensional convolutional neural network. Experimental results show that it is more effective to detect whether or not the video is forged compared with the results using the existing machine learning algorithm."
Noise-tolerance Investigation into Dual-kNN Pattern Classification,2018,"['k-NN', 'Dual-kNN', 'Logistic regression', 'Neural network', 'Robustness']",,"The performance of an algorithm is usually measured in three dimensions (simplicity, processing time, and prediction power). In addition, we should take into account the noise resistance level in those measures. For this reason, this paper focuses on investigating the noisetolerance level of dual k-nearest neighbors (dual-kNN) primarily based on five noisy medical diagnosis problems. Literally, dual-kNN is a reborn version of the k-nearest neighbors (k-NN) algorithm with a new observation idea in the classification process with a collaborative effort between the first and second nearest neighbors of an observed instance. It was recently proven that dual-kNN has high prediction accuracy for a variety of real-world data sets, especially so in unbiased data sets. Thus, in this report, not only the prediction accuracy of dual-kNN is compared with normal k-NN, logistic regression, and the neural network, but we additionally investigate the noise tolerance in the aforementioned approaches. The practical data sets applied in this paper are medical data files from the University of California, Irvine, Machine Learning Repository. In this report, the new approach to dual-kNN commences with better prediction accuracy, and higher noise resistance is presented, in comparison with normal k-NN, logistic regression, and neural networks."
빠른 클러스터 개수 선정을 통한 효율적인 데이터 클러스터링 방법,2018,"['Data Clustering', 'Heuristic Algorithm', 'Number of Clusters', 'Silhouette']",,"K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, this method has the limitation to be used with fixed number of clusters because of only considering the intra-cluster distance to evaluate the data clustering solutions. Silhouette is useful and stable valid index to decide the data clustering solution with number of clusters to consider the intra and inter cluster distance for unsupervised data. However, this valid index has high computational burden because of considering quality measure for each data object. The objective of this paper is to propose the fast and simple speed-up method to overcome this limitation to use silhouette for the effective large-scale data clustering. In the first step, the proposed method calculates and saves the distance for each data once. In the second step, this distance matrix is used to calculate the relative distance rate (Vｊ) of each data j and this rate is used to choose the suitable number of clusters without much computation time. In the third step, the proposed efficient heuristic algorithm (Group search optimization, GSO, in this paper) can search the global optimum with saving computational capacity with good initial solutions using Vｊ probabilistically for the data clustering. The performance of our proposed method is validated to save significantly computation time against the original silhouette only using Ruspini, Iris, Wine and Breast cancer in UCI machine learning repository datasets by experiment and analysis. Especially, the performance of our proposed method is much better than previous method for the larger size of data."
빠른 클러스터 개수 선정을 통한 효율적인 데이터 클러스터링 방법,2018,"['Data Clustering', 'Heuristic Algorithm', 'Number of Clusters', 'Silhouette']",,"K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, this method has the limitation to be used with fixed number of clusters because of only considering the intra-cluster distance to evaluate the data clustering solutions. Silhouette is useful and stable valid index to decide the data clustering solution with number of clusters to consider the intra and inter cluster distance for unsupervised data. However, this valid index has high computational burden because of considering quality measure for each data object. The objective of this paper is to propose the fast and simple speed-up method to overcome this limitation to use silhouette for the effective large-scale data clustering.In the first step, the proposed method calculates and saves the distance for each data once. In the second step, this distance matrix is used to calculate the relative distance rate (Vj) of each data j and this rate is used to choose the suitable number of clusters without much computation time. In the third step, the proposed efficient heuristic algorithm (Group search optimization, GSO, in this paper) can search the global optimum with saving computational capacity with good initial solutions using Vj probabilistically for the data clustering. The performance of our proposed method is validated to save significantly computation time against the original silhouette only using Ruspini, Iris, Wine and Breast cancer in UCI machine learning repository datasets by experiment and analysis. Especially, the performance of our proposed method is much better than previous method for the larger size of data."
Probabilistic Convective Initiation Nowcasting with Reduced Satellite - NWP Predictors over Iran,2018,"['Satellite .NWPmodel', 'Convective initiation', 'Dimensional reduction', 'Nowcasting']",,"Geostationary satellites are able to nowcast Convective Initiation (CI) for the next 0–6 h. Compared to using satellite predictors only, the incorporation of satellite and NumericalWeather Prediction (NWP) predictors can provide the possibility to reduce false alarm rates in 0–1:30 Convective Initiation Nowcasting (COIN). However, the correlation among these predictors not only can cause error in COIN, but also increases the runtime. In this study for the first time, all effective predictors in Satellite Convection Analysis and Tracking version 2 (SATCASTv2) and NWP were applied over Iran from22ndMarch 2015 to 9th January 2016. In applying SATCASTv2 over Iran, it was necessary to make some modifications to the algorithm, such as removing case specific thresholds of satellite predictors and rearranging COIN predictors. Then, SATCASTv2 was tested and evaluated with both the full and reduced set of predictors. The results suggested that using fixed thresholds for temporal difference predictors could miss COIN in some cases. To investigate the possibility of improving computational efficiency, a dimension reduction was conducted by Factor Analysis (FA) and the number of predictors was reduced from 22 to 11. TheNWP-satellite, reduced NWP-satellite, and satellite predictors were used as input in Random Forest (RF), as a parametric machine learning method, for COIN evaluation.The Combination ofNWP model and satellite predictors had lower false alarm rates in contrast with satellite predictors. This is in agreement with previous studies. The results from statistical metrics showed that the reduced NWP-satellite predictors had comparable performance to the NWP-satellite predictors over study area, but decreased the run time by almost 50%. The results indicated that Convective Inhibition (CIN) was the most significant predictor when the reduced set of predictors was used."
컴퓨터적 창의력을 위한 블록체인 기반 저작권 보호 연구,2018,"['블록체인', '저작권', '컴퓨터 창의력', '인공지능', '암호화폐', 'Blockchain', 'Copyright', 'Computational creativity', 'Artificial intelligence', 'Cryptocurrency']","컴퓨터적 창의력은 인간의 창의성을 모사하기 위한 인공지능 연구 분야로 다양한 분야에서 저작물을 창작하거나 인간 작가들의 창작을 돕고 있다. 컴퓨터적 창의력에 의해 저작된 저작물에 대한 저작권은 대부분 국가에서 아직 제도적으 로 정립되어 있지 않으나 앞으로 기술의 발전과 함께 관련 저작권을 보호하기 위한 시스템이 필요성이 커질 것이다. 본 논문 에서는 컴퓨터적 창의력의 저작물의 창작에 기여하는 다양한 참여자들의 저작권을 보호하고, 저작물의 기여를 투명하고 안 전하게 기록할 수 있는 블록체인 기술 기반 저작권 보호 시스템을 제안한다. 제안 시스템은 컴퓨터적 창의력의 기계 학습에 서부터 최종 저작물의 창작까지 관련된 모든 저작물의 기여를 블록체인 상에 기록함으로써 향후 저작권법 체계가 정비되었 을 때, 컴퓨터적 창의력의 저작권에 대한 정량적 평가 기준을 마련할 수 있다는데 그 의의가 있다.","Computational creativity is a field of artificial intelligence research to replicate creativity of human beings, creating works in various fields or helping human authors. The copyright of works produced by computational creativity has not been established in most countries yet, however, there will be the need for systems to protect the copyrights with the development of the technology in the future. In this paper, we propose a copyright protection system based on blockchain technology that protects the copyright of various contributors contributing to the creation of computer creative creativity, and transparently and safely records the contribution of copyrighted works. The proposed system records the contribution of all related works from the machine learning of computer creativity to the creation of the final work on the blockchain so that it is possible to establish quantitative evaluation criteria for the copyright when the future copyright law system is revised."
클라우드 기반 한국형 스마트 온실 연구 플랫폼 설계 방안,2018,"['agricultural information &amp', 'communication technology(ICT)', 'artificial intelligence(AI)', 'big data', 'decision-making support service', 'smart farm', '농업 ICT', '인공지능', '빅데이터', '의사결정지원서비스', '스마트팜']","본 연구는 농업 및 정보 통신 기술의 융합을 기반으로 국내외 스마트 농장 서비스 모델을 검토하고 한국의 스마트 온실을 개선하기 위해 필요한 다양한 요인을 조사하기 위해 수행되었다. 국내 스마트 온실의 작물 생육모델 및 환경모델에 관한 연구는 제한적이었고, 연구를 위한 인프라를 구축하는 데는 많은 시간이 필요하다. 이러한 문제의 대안으로 클라우드 기반 연구 플랫폼이 필요하다. 제안된 클라우드 기반 연구 플랫폼은 통합 데이터, 생육환경모델, 구동기 제어 모델, 스마트 온실 관리, 지식 기반 전문가 시스템 및 농가 대시보드 모듈을 통해 통합적 데이터 저장 및 분석을 위한 연구 인프라를 제공한다. 또한 클라우드 기반 연구 플랫폼은 작물 생육환경, 생산성 및 액추에이터 제어와 같은 다양한 요인들 간의 관계를 정량화하는 기능을 제공하며, 연구자는 빅데이터, 기계 학습 및 인공지능을 활용하여 작물 생육 및 생장환경 모델을 분석할 수 있다.","This study was performed to review the domestic and international smart farm service model based on the convergence of agriculture and information & communication technology and derived various factors needed to improve the Korean smart greenhouse. Studies on modelling of crop growth environment in domestic smart farms were limited. And it took a lot of time to build research infrastructure. The cloud-based research platform as an alternative is needed. This platform can provide an infrastructure for comprehensive data storage and analysis as it manages the growth model of cloud-based integrated data, growth environment model, actuators control model, and farm management as well as knowledge-based expert systems and farm dashboard. Therefore, the cloud-based research platform can be applied as to quantify the relationships among various factors, such as the growth environment of crops, productivity, and actuators control. In addition, it will enable researchers to analyze quantitatively the growth environment model of crops, plants, and growth by utilizing big data, machine learning, and artificial intelligences."
인공지능 로봇의 형사법이론 체계에 관한 일고,2018,"['인공지능로봇의 형사책임', '강인공지능', '약인공지능', '범죄주체성', '전자인격', 'criminal liability of artificial intelligence robots', 'strong AI', 'weak AI', 'crime identity', 'electronic persons']","최근 사물인터넷(Internet of Things) 기술과 인공지능(Artificial Intelligence) 기술의 결합체인 자율주행자동차의 상용화를 앞두고 있는 등 이른바 ‘제4차 산업혁명’의 성장가능성에 대한 기대가 높아지고 있다. 특히 제4차 산업의 총아인 인공지능형 로봇은 인간만이 독점해 왔던 학습능력, 추론능력, 지각능력, 자연언어의 이해능력, 논증 등의 기능을 갖춤으로써 상상 속에서나 가능했던 혁신 서비스나 제품의 생산을 가능케 하는 원천이 되고 있다.  특히 2016년 3월 인공지능 바둑프로그램인 알파고와 이세돌 9단의 세기의 대국(對局) 이후 인공지능의 무한한 가능성은 세간에 충격을 주기에 충분하였으며, 이에 따라 인간지능을 초월하는 인공지능의 기술력에 감탄하면서도 향후 그 파급력에 대한 우려도 나타나게 되었다. 이처럼 동 사건은 미래 인류의 청사진을 제시해 주고 있지만, 동시에 사람은 아니지만 ‘사람처럼 행동하는 인공지능 로봇(기계)’을 기존의 법제도로 통제가 가능한 것인지 난해한 과제를 던져 주고 있다. 왜냐하면 인공지능 기술의 활용이 목전에 다가오면서 문화인류사에서 그 어떤 법률도 스스로 판단하고 운행하는 차량을 상정하거나 로봇의사가 환자의 병을 진단하고 집도하는 상황에 대해 규범적 문제로 고민해 본 전례가 없었기 때문이다. 이처럼 경험하지 못한 다양한 문제 상황을 해결하기에는 종래의 법적 틀과 이론적 토대가 미흡한 상황임에 따라 향후 ‘인공지능에 의한 법익침해나 범죄행위’에 대한 효과적인 대응이 어려운 실정이다.   따라서 본 연구에서는 인공지능 및 로봇 기술이 이미 산업분야(자율주행자동차), 의료분야(수술용 로봇) 등에 적용되어 상용화를 앞두고 있다는 점에서 인공지능 로봇 행위의 형법적 행위성, 범죄주체성, 형사책임능력 등 형법이론의 적용방안과 해석론을 시급히 모색해 보고, ‘인공지능 로봇에 의한 범죄행위’에 대한 형법적 대응방안을 규명한다.","At present, the human society has entered the era of the fourth industrial revolution, such as artificial intelligence (AI) -based robots, commercialization of autonomous vehicles, which is a combination of Internet of Things (IoT) technology and artificial intelligence technology . In particular, artificial intelligent robots, which are the generals of the 4th industry, have functions and systems such as learning ability, reasoning ability, perception ability, and argumentation, which have been monopolized only by human intelligence, It is becoming a power to make. The endless possibilities of artificial intelligence after the confrontation of the anti-monarchy of the 9th century of Alpha Kogyo and Ise Se-dol, the artificial intelligence Go program in March 2016, were enough to shock the world. Therefore, while artificial intelligence admires the technological power beyond human intelligence, people have experienced the contemplation of future power, expectation and concern.  This case presents the blueprint of the future humanity, and it presents the difficult problem of being able to manage an artificial intelligence robot (machine) acting as a `person`, though it is not a person, with the existing legal system. As the use of artificial intelligence approaches to the fore, there was no precedent in the human history to assume a vehicle that judges and operates any laws, or a robot physician was worried about the normative problem of the operation to diagnose and collect the patient`s disease. is not simple to solve problems that have not been experienced like this and it is difficult to compete with the conventional legal framework that lacks the theoretical basis for it, The current law system can not effectively cope with the future robot and artificial intelligence era. Artificial intelligence, and robot technology have already entered the commercialization stage in autonomous vehicles and medical fields. Therefore, in this study, in the field of criminal law related to artificial intelligence robots, we are urgently looking for the ways to cope with and respond to criminal theories such as subjectivity, crime ability, criminal responsibility, We will focus on the necessity to prepare for the future crime that will be caused by artificial intelligence."
Design of Query Processing System to Retrieve Information from Social Network using NLP,2018,"['Query Processing', 'Social Network', 'LDA', 'Natural Language Processing']",,"Social Network Aggregators are used to maintain and manage manifold accounts over multiple online social networks. Displaying the Activity feed for each social network on a common dashboard has been the status quo of social aggregators for long, however retrieving the desired data from various social networks is a major concern. A user inputs the query desiring the specific outcome from the social networks. Since the intention of the query is solely known by user, therefore the output of the query may not be as per user’s expectation unless the system considers ‘user-centric’ factors. Moreover, the quality of solution depends on these user-centric factors, the user inclination and the nature of the network as well. Thus, there is a need for a system that understands the user’s intent serving structured objects. Further, choosing the best execution and optimal ranking functions is also a high priority concern. The current work finds motivation from the above requirements and thus proposes the design of a query processing system to retrieve information from social network that extracts user’s intent from various social networks. For further improvements in the research the machine learning techniques are incorporated such as Latent Dirichlet Algorithm (LDA) and Ranking Algorithm to improve the query results and fetch the information using data mining techniques.The proposed framework uniquely contributes a user-centric query retrieval model based on natural language and it is worth mentioning that the proposed framework is efficient when compared on temporal metrics. The proposed Query Processing System to Retrieve Information from Social Network (QPSSN) will increase the discoverability of the user, helps the businesses to collaboratively execute promotions, determine new networks and people. It is an innovative approach to investigate the new aspects of social network. The proposed model offers a significant breakthrough scoring up to precision and recall respectively."
동영상 시맨틱 이해를 위한 시각 동사 도출 및 액션넷 데이터베이스 구축,2018,"['동영상 이해', '시각 동사', '액션넷', '동영상 데이터베이스', '시맨틱 이해', 'Video understanding', 'visual verb', 'ActionNet', 'video database', 'semantic understanding']","영상 데이터에 대한 시맨틱 정보를 정확하게 이해하는 것은 인공지능 및 기계학습 분야에서 가장 어려운 도전과제의 하나로 알려져 있다. 본 논문에서는 동영상 시맨틱 이해를 위한 시각 동사 도출과 이를 바탕으로 하는 동영상 데이 터베이스인 액션넷 데이터베이스 구축에 관해 제안하고 있다. 오늘날 인공지능 기술의 눈부신 발달에는 인공지능 알 고리즘의 발전이 크게 기여하였지만 알고리즘의 학습과 성능 평가를 위한 방대한 데이터베이스의 제공도 기여한 바 가 매우 크다고 할 수 있다. 인공지능이 도전하기 어려운 분야였던 시각 정보 처리에 있어서도 정지 영상 내의 객체 인식에 있어서는 인간의 수준을 능가하기 시작하면서 점차 동영상에서의 내용에 대한 시맨틱 이해 기술 개발로 발전 하고 있다. 본 논문에서는 이러한 동영상 이해를 위한 학습 및 테스트 데이터베이스로서 액션넷 구축에 요구되는 시 각 동사의 후보를 도출한다. 이를 위해 언어학 기반의 동사 분류체계를 살펴보고, 영상에서의 시각 정보를 명세한 데이터 및 언어학에서의 시각 동사 빈도 등으로부터 시각 동사의 후보를 도출한다. 시각 동사 분류체계와 시각 동사 후보를 바탕으로 액션넷 데이터베이스 스키마를 정의하고 구축한다. 본 논문에서 제안하는 시각 동사 및 스키마와 이를 바탕으로 하는 액션넷 데이터베이스를 개방형 환경에서 확장하고 활용성을 제고함으로써 동영상 이해 기술 발 전에 기여할 수 있을 것으로 기대한다.","Visual information understanding is known as one of the most difficult and challenging problems in the realization of machine intelligence. This paper proposes deriving visual verb and construction of ActionNet database as a video database for video semantic understanding. Even though development AI (artificial intelligence) algorithms have contributed to the large part of modern advances in AI technologies, huge amount of database for algorithm development and test plays a great role as well. As the performance of object recognition algorithms in still images are surpassing human’s ability, research interests shifting to semantic understanding of video contents. This paper proposes candidates of visual verb requiring in the construction of ActionNet as a learning and test database for video understanding. In order to this, we first investigate verb taxonomy in linguistics, and then propose candidates of visual verb from video description database and frequency of verbs. Based on the derived visual verb candidates, we have defined and constructed ActionNet schema and database. According to expanding usability of ActionNet database on open environment, we expect to contribute in the development of video understanding technologies."
Understanding Neurogastroenterology From Neuroimaging Perspective: A Comprehensive Review of Functional and Structural Brain Imaging in Functional Gastrointestinal Disorders,2018,"['Dyspepsia', 'Homeostasis', 'Irritable bowel syndrome', 'Neuroimaging', 'Visceral pain']",,"This review provides a comprehensive overview of brain imaging studies of the brain-gut interaction in functional gastrointestinal disorders (FGIDs). Functional neuroimaging studies during gut stimulation have shown enhanced brain responses in regions related to sensory processing of the homeostatic condition of the gut (homeostatic afferent) and responses to salience stimuli (salience network), as well as increased and decreased brain activity in the emotional response areas and reduced activation in areas associated with the top-down modulation of visceral afferent signals. Altered central regulation of the endocrine and autonomic nervous responses, the key mediators of the brain-gut axis, has been demonstrated. Studies using resting-state functional magnetic resonance imaging reported abnormal local and global connectivity in the areas related to pain processing and the default mode network (a physiological baseline of brain activity at rest associated with self-awareness and memory) in FGIDs. Structural imaging with brain morphometry and diffusion imaging demonstrated altered gray- and white-matter structures in areas that also showed changes in functional imaging studies, although this requires replication. Molecular imaging by magnetic resonance spectroscopy and positron emission tomography in FGIDs remains relatively sparse. Progress using analytical methods such as machine learning algorithms may shift neuroimaging studies from brain mapping to predicting clinical outcomes. Because several factors contribute to the pathophysiology of FGIDs and because its population is quite heterogeneous, a new model is needed in future studies to assess the importance of the factors and brain functions that are responsible for an optimal homeostatic state.(J Neurogastroenterol Motil 2018;24:512-527)"
신경망을 이용한 다중 심리-생체 정보 기반의 부정 감성 분류,2018,"['Emotion Classification', 'Negative Emotion', 'Neural Network', 'Arousal', 'Physiological Signals', '감성 분류', '부정 감성', '신경망', '각성도', '생체 신호']","감성은 복잡하고 다양한 요인들에 의해 영향을 받기 때문에 다각적인 측면에서 고려되어야 한다. 본 연구에서는심리 평가 척도의 하나인 각성(arousal) 지표와 다중 생체신호에서 추출된 생체지표 반응을 이용하여 중립 및 부정 감성(슬픔, 공포, 놀람)의 분류하였다. 이를 위하여 감성에 따른 생체지표 반응의 차이를 확인하였고, 다중 신경망알고리즘 기반의 감성 인식기를 적용하여 이들 감성이 얼마나 정확하게 분류되는가를 확인하였다. 총 146명의 실험참가자(평균 연령 20.1±4.0, 남성 41%)를 대상으로 감성 유발 자극을 제시하고 동시에 생체신호(심전도, 혈류맥파,피부전기활동)를 측정하였다. 또한 감성 유발 자극에 대한 심리 반응을 감성 평가 척도로 평가하였다. 측정된 생체신호에서 심박률(HR), NN 간격의 표준편차(SDNN), 혈류량(BVP), 맥파전달시간(PTT), 피부전도수준(SCL), 피부전도반응(SCR)을 추출하였다. 결과 분석을 위하여 감성 자극에 대한 각성도와 안정 상태와 감성 상태의 생체지표 반응을활용하였다. 또한 감성 분류를 위하여 다중 신경망 기반의 감성 인식기를 활용하였다. 그 결과, 감성에 따른 생체지표반응의 차이를 확인하였고, 이들 감성의 분류 성능은 각성도와 모든 생체지표 특징들을 조합하였을 때 정확도가 가장높음(86.9%)을 확인하였다. 본 연구는 심리 및 생체지표 추출과 기계학습 기술의 적용을 통하여 부정 감성을 분류할수 있음을 제안하며, 이는 인간의 감성을 탐지하는 감성 인식 기술을 확립하는데 기여할 것으로 예상한다.","The mechanism of emotion is complex and influenced by a variety of factors, so that it is crucial to analyze emotion in broad and diversified perspectives. In this study, we classified neutral and negative emotions(sadness, fear, surprise) using arousal evaluation, which is one of the psychological evaluation scales, as well as physiological signals. We have not only revealed the difference between physiological signals coupled to the emotions, but also assessed how accurate these emotions can be classified by our emotional recognizer based on neural network algorithm. A total of 146 participants(mean age 20.1 ± 4.0, male 41%) were emotionally stimulated while their physiological signals of the electrocardiogram, blood flow, and dermal activity were recorded. In addition, the participants evaluated their psychological states on the emotional rating scale in response to the emotional stimuli.Heart rate(HR), standard deviation(SDNN), blood flow(BVP), pulse wave transmission time(PTT), skin conduction level(SCL) and skin conduction response(SCR) were calculated before and after the emotional stimulation. As a result, the difference between physiological responses was verified corresponding to the emotions, and the highest emotion classification performance of 86.9% was obtained using the combined analysis of arousal and physiological features. This study suggests that negative emotion can be categorized by psychological and physiological evaluation along with the application of machine learning algorithm, which can contribute to the science and technology of detecting human emotion."
주체사상 시기 북한 ‘사회주의현실주제작품’의 역사적 변모양상 1960∼1990년대 북한 서정시를 중심으로,2018,"['사회주의현실주제작품', '인민', '당', '생활', '정치', '갈등', '선도성', '관용성', '전향성', 'Works on Socialist Reality Theme', 'The People', 'The Party', 'Life', 'Politics', 'Conflict', 'Leadership', 'Tolerance', 'Conversion']",,"One of the important tasks for North Korean literature in performing a feat ― the revolution in Juche Idea ― is to create a ‘work on socialist reality theme.’ However, the ‘work on socialist reality theme’ reveals the point where the ‘politics’ of the Korean Workers’ Party and the ‘life’ of the people conflict each other in various manners. Because the party intends to control people more authoritatively through the ‘incorporation of politics into life’ and the people on the other hand wish to find the opportunity to resist in living through the ‘incorporation of living into politics’ and broaden the opportunity. This study used the ‘conflict between living and politics’ as the framework of analysis to investigate the trend of changes in history with respect to the ‘work on socialist reality theme’ of North Korea. The first phase (1965∼1978) is when the party displayed political ‘leadership’ in order to change people daily life in a constructive way. They embodied the images of the daily life where all people enjoy the benefit of education, men and women are equally participating in the social activities, farmers are learning new technologies to operate agricultural machine, workers are attending colleges at work to learn about new technologies and theories in comparison with the past. The political leadership was justified by raising aspiration and expectation for an equal society. The second phase (1978∼ 1985) is when the party showed political ‘tolerance’ so that the juche ideology could smoothly take root in the daily life of the people. The special ties between the chairman, party, and people was given prominence by concretely embodying the private experiences that the people enjoy in living and emphasizing that it requires the protection from the chairman and the party as the premise. Giving autonomy to the daily life of people also brought the illusion of political tolerance. The third phase (1985∼1995) is when the party revealed the political ‘conversion’ in order to catch up with the daily life of the people. The images of deviant people, exemplary people, or people with different values in everyday life are put together toward each other through conversation. A new attempt of political conversion has been made to delay the change by awakening them to realize individual deviation or urging them to reflect on augmented desire. The changes in the life of North Korean people will accelerate due to the innate repetitiveness in living, and thereby broadening the gap between the target culture of North Korea and realistic culture. Also, it is still uncertain whether the Korean Workers’ Party would choose the path to change its system by resetting the target culture, ‘Construction of Socialist and Communist Society’ or choose the path to maintain its system by broadening the pace of forward-looking politics which systematically accept the realistic culture saturated with capitalism. However, one thing that can be confirmed once again by examining the trend of changes in history with respect to the ‘work on socialist reality theme’ of North Korea centering on the ‘issue of conflict between living and politics’ is that the force that drives the development of the system, regardless of the type of the social system, is the ‘openness’ of the system."
19세기 후반 영국 지식인들의 일본 인식,2018,"['국민교육', '근대국가', '근면혁명', '메이지 유신', '서구화', '영국 중심주의', 'National Education', 'Modern State', 'Industrious Revolution', 'Meiji Revolution', 'Westernization', 'Anglo-centrism']","이 논문은 19세기 후반 영국의 지식인들이 메이지 혁명 이후 일본의 변화를 어떻게 바라보았는가를 검토하는 데 목적을 둔다. 1870년대 이후 일본의 서구화 과정과 내용을 소개하고 진단하는 논설이나 여행기들이 증가한다. 영국 지식인들은 대부분 일본의 개혁을 긍정적으로 평가하며 그 결과에 놀라움을 표시한다. 특히 그들은 일본 지배층이 개혁을 위해 기득권을 내려놓은 양보를 결정했다는 점을 높이 평가한다. 그들은 개혁과정에서 나타난 일본적인 특징으로 일본인의 근면성, 국민교육에 대한 새 정부의 장려, 각종 교육기관의 설립, 외국 문물의 학습 등을 꼽는다.  그러나 이런 긍정적인 평가 이면에는 영국중심적인 시각이 깃들어 있다. 예를 들어, 그들이 일본인의 근면성을 강조한 것은 산업화 이후 영국 사회에서 기계의 보급과 관련된다. 특히 그들은 일본이 발전하더라도 유럽을 추월하리라고는 예측하지 못했다. 그러나 개혁 이후 30년만에 일본은 서유럽 강대국들과 견줄 수 있는 강력한 근대국가를 만드는 데 성공을 거두었다.","The paper aims to examine how British intellectuals in the late 19th century viewed Japan’s change after the Meiji Revolution. At that time some articles and travel writings which intended to introduce Japan’s Westernization to English readers increased. Most British writers were positive about Japan’s reform, and expressed surprise at the result. In particular, they highly appreciated the decision of the Japanese ruling class to yield their existing power interest for reform. Considering the process of the reform, British intellectuals pointed out diligence and national education as ‘the Japanese’. And the new government tried to establish higher education institutes and to introduce learn European culture and civilization.  But behind this positive assessment were there Anglo-centric views. For example, their emphasis on the Japanese’ diligence is related to the spread of machines in British society since industrialization. In particular, they did not predict that Japan would surpass Europe even if it developed. But only 30 years after the Meiji restoration, Japan succeeded in making a powerful nation-state that could compete with European powers."
Efficient Data Clustering using Fast Choice for Number of Clusters,2018,"['Data Clustering', 'Heuristic Algorithm', 'Number of Clusters', 'Silhouette']",,"K-means algorithm is one of the most popular and widely used clustering method because it is easy to implement and very efficient. However, this method has the limitation to be used with fixed number of clusters because of only considering the intra-cluster distance to evaluate the data clustering solutions. Silhouette is useful and stable valid index to decide the data clustering solution with number of clusters to consider the intra and inter cluster distance for unsupervised data. However, this valid index has high computational burden because of considering quality measure for each data object. The objective of this paper is to propose the fast and simple speed-up method to overcome this limitation to use silhouette for the effective large-scale data clustering.In the first step, the proposed method calculates and saves the distance for each data once. In the second step, this distance matrix is used to calculate the relative distance rate (Vj) of each data j and this rate is used to choose the suitable number of clusters without much computation time. In the third step, the proposed efficient heuristic algorithm (Group search optimization, GSO, in this paper) can search the global optimum with saving computational capacity with good initial solutions using  probabilisticallyfor the data clustering. The performance of our proposed method is validated to save significantly computation timeagainst the original silhouette only using Ruspini, Iris, Wine and Breast cancer in UCI machine learning repository datasets by experiment and analysis. Especially, the performance of our proposed method is much better than previous method for the larger size of data."
Assessment of climate change impact on aquatic ecology health indices in Han river basin using SWAT and random forest,2018,"['Aquatic ecology health', 'Climate change', 'Water quality', 'SWAT', 'Random forest', '수생태 건강성', '기후변화', '수질', 'SWAT', 'Random forest']","본 연구에서는 SWAT 모형과 random forest를 이용하여 미래 기후변화에 따른 한강유역(34,148 km2)의 수생태계 건강성을 평가하였다. 국립 환경과학원에서 8년간(2008~2015년) 봄철(4~6월)에 모니터링한 부착돌말류 지수(TDI), 저서형 대형무척추동물지수(BMI), 어류평가지수(FAI)는 0~100점, A~E등급으로 평가되며, 이를 본 연구에서 사용하였다. 수생태 건강성에 영향을 미치는 변수로는 수질(T-N, NH4, NO3, T-P, PO4)과 수온을 선정하였으며, 수질 오염도가 낮은 경우에는 수생태계 건강성 점수가 광범위하게 분포되지만 수질 오염도가 높은 경우 수생태계 건강성 점수가 낮아지는 역상관관계를 확인하였다. 기계학습의 분류 분석 기법 중 하나인 random forest 모델을 이용한 세 개의 수생태 건강성 지수 등급 분류 결과 정밀도, 재현율, f1-score 모두 0.81 이상의 예측 정확도를 나타내었다. 기상청의 HadGEM3-RA RCP 4.5와 8.5 시나리오를 적용한 미래 SWAT 수문, 수질 결과 기저유출의 증가로 인해 질소 계열 수질 농도는 기준년도 대비 최대 43.2% 증가하였고, 지표유출 감소로 인해 인 계열 수질 오염도는 최대 18.9% 감소하는 것으로 분석되었다. 미래 FAI, BMI의 등급은 개선되는 경향을 보이지만 TDI는 등급이 악화되는 것으로 나타 났다. 이를 통해 TDI는 질소 계열 수질에 민감하고 FAI, BMI는 인 계열 수질에 더 민감하다고 판단하였다.","The purpose of this study is to evaluate the future climate change impact on stream aquatic ecology health of Han River watershed (34,148 km2) using SWAT (Soil and Water Assessment Tool) and random forest. The 8 years (2008~2015) spring (April to June) Aquatic ecology Health Indices (AHI) such as Trophic Diatom Index (TDI), Benthic Macroinvertebrate Index (BMI) and Fish Assessment Index (FAI) scored (0~100) and graded (A~E) by NIER (National Institute of Environmental Research) were used. The 8 years NIER indices with the water quality (T-N, NH4, NO3, T-P, PO4) showed that the deviation of AHI score is large when the concentration of water quality is low, and AHI score had negative correlation when the concentration is high. By using random forest, one of the Machine Learning techniques for classification analysis, the classification results for the 3 indices grade showed that all of precision, recall, and f1-score were above 0.81. The future SWAT hydrology and water quality results under HadGEM3-RA RCP 4.5 and 8.5 scenarios of Korea Meteorological Administration (KMA) showed that the future nitrogen-related water quality in watershed average increased up to 43.2% by the baseflow increase effect and the phosphorus-related water quality decreased up to 18.9% by the surface runoff decrease effect. The future FAI and BMI showed a little better Index grade while the future TDI showed a little worse index grade. We can infer that the future TDI is more sensitive to nitrogen-related water quality and the future FAI and BMI are responded to phosphorus-related water quality."
4차 산업혁명: 문학의 변화와 지향점,2018,"['4차 산업혁명', '기술적 특이점', '자유의지', '재현의 위기', '초지능', '원격현존', '틈과 참의 리얼리즘', '4th industrial revolution', 'technical singularity', 'free will', 'crisis of representation', 'super intelligence', 'tele-presence', 'the realism of cham and teum']","우리는 이 시점에서 4차 산업혁명에 대하여 호들갑을 떨지 말고 차분하고 냉철하게 인문학적 성찰을 해야 한다. 4차 산업혁명은 기업과 국가는 물론, 인류 문명자체의 대전환을 야기할 것이다. 문학도 이 흐름에서 벗어날 수 없다. 인간의 마음과 유전자와 뇌신경세포는 서로 연기적 관계에 있다. 인간의 마음이 유전자와 뇌신경세포의 소산이지만, 몸 전체의 네트워킹이 유전자와 뇌신경세포에도 영향을 미치므로 인간에게 자유의지가 없는 것은 아니다. 인공지능은 인간을 100% 완벽하게 대체하지 못하겠지만, 강 인공지능 로봇은 대략 2050년 경에 기술적 특이점을 돌파하여 지능폭발을 하고 초지능을 습득할 것이다. 인공지능은 여러 분야에서 인간을 대체함은 물론, 인간의 본성과 정체성에도 혼란을 가져올 것이며, 이 경우 인간, 기계, 인공지능, 사이보그의 네 존재가 서로 대립과 모순의 관계를 형성할 것이다. 이 경우 도구와 인간/창작자의 위치가 전복되어 네비게이션처럼 인간은 초기입력이 끝나는 순간 이를 보조하는 노예나 행위자로 전락할 것이다. 문학은 인공지능과 구분되는 인간의 본성, 생명성, 영성을 추구하고 이를 구현하는 차이의 글쓰기와 읽기를 해야 한다.발달된 가상현실로 인하여 우리는 점점 더 원격현존을 경험하고 있다. 이로 가상과 실재의 경계가 무너지고 재현의 위기는 증대한다. 앞으로 가상현실이 문학의 리얼리티를 넘어설 것이다. 그럼에도 문학의 리얼리티의 영역은 남을 것이다. 이의 지향점은 가상과 현실 사이에서 진동하면서 끊임없이 틈을 내고 진리를 추구하는 ‘틈과 참의 리얼리즘’이다.지금 세계는 거의 모든 사물과 공간, 데이터들이 지능을 가진 것처럼 서로 인터넷을 매개로 연결된 초연결사회로 전환하고 있다. 사물인터넷을 통한 초연결사회가 한계비용이 0인 공유사회의 영역을 늘릴 것이며, 이는 문학의 장에서도 마찬가지로 작동할 것이다. 초연결 사회에서 작가들은 홀로 동떨어져 존재하는 사물들이 아니라 네트워크에서 스스로 의미를 가지고 있는 사물들에 2차적 의미를 부여할 것이다. 이의 지향점은 노마드적이고 여성적인 글쓰기를 하는 것이다. 결국, 인간은 가상과 실상, 원본과 복사본, 현실과 비현실, 현존과 원격현존과 사이에서 진동하면서 고뇌하고 방황하지만, 인공지능과 공진화를 모색하며 생을 이어가고 이를 문학으로 표현할 것이다.","At this point, we should not be fussy about the Fourth Industrial Revolution, but should give a humanistic reflection on this matter in a calm and cool manner. The Fourth Industrial Revolution will bring about a massive transformation of the civilization itself, as well as corporations and the nation. Literature can not escape from this flow. The human mind, genes, and neurons are connected in the relationship of dependant origination with each other. Although the human mind is generated from genes and neurons, networking of the whole body also affects genes and neurons. Therefore, human beings have free will. Artificial intelligence will not replace humans perfectly, but strong AI Robot will break through technological singularity around 2050, making intelligent explosions and learning super-intelligence. AI will not only replace humans in many fields, but also confuse human nature and identity. In this case, the four beings of human, machine, AI, and cyborg will form a relationship of conflict and contradiction. In literature, tools and creators’ positions are overturned, and humans will fall into slavery or agents as the initial input ends. Literature must pursue human nature, life, and spirituality, which are distinct from AI. To achieve this, writing and reading should be done to create difference. We are experiencing more and more tele-presence because of the improved virtual reality. This breaks the boundaries between virtual and real and the crisis of representation increases. In the future, virtual reality will transcend the reality of literature. Nevertheless, the realm of literary reality will remain. The alternative of these matters is the “realism of teum(the gap) and cham(the ultimate truth)” that constantly makes a gap and pursues the truth while vibrating between the virtual and the reality. Now the world is transforming into a super-connected society that is connected to each other through the internet as if almost all objects, spaces, and data have intelligence. The hyper-linked society through the internet of things will increase the scope of a shared society with zero marginal cost, which will work in the field of literature as well. In a hyper-linked society, writers will give secondary meaning to objects that have their own meaning in the network, not objects that exist alone. Its aim is to make a nodal and feminine writing. In the end, humans will live and create literature in search of co-evolution with AI, while agonizing and wandering between the virtual and the real, the original and the copy, presence and tele-presence."
컨테이너 터미널에 적용 가능한 인더스트리 4.0 기반 제품/서비스의 개념 설계 및 중요성 분석,2018,"['컨테이너 터미널', '인더스트리 4.0', '제품/서비스 개념 설계', 'Container terminal', 'Industry 4.0', 'C onceptual design of products and services']",,"This study focuses on the products and services that need to be developed to improve the productivity and operational safety in container terminals, based on the increase of international container trade, the enlargement of vessel size, the increase of attention to port work safety, Industry 4.0 technologies, and the latest logistics trends. Industry 4.0 technologies, especially called the Fourth Industry Revolution, is expected to increase the uncertainty about future manpower supply. To respond to these changes, container terminals should be newly designed according to the future development directions. For this purpose, this study designs the concept of products and services for improving the productivity and safety in container terminals by utilizing Industry 4.0 technologies. We also analyze the importance of the products and services provided by the expert questionnaire. The importance analysis consists of the priority and the application period. For priority analysis, a linear assignment method, a type of multi-attribute decision making, is used and the priorities of products and services are decided. The application period of products and services is divided into 5 years or less and 5 years or more.As a result of the importance evaluation, the concept of products and services with a high priority and an application period of 5 years or less includes the high efficiency yard, the automated multi-functional sensor, the intelligent container identification tag, the external vehicle in-out control, the logistics marketplace, the container handling accident prevention, the equipment operation protector, and the intelligent unmanned vehicle. The concept of products and services with a high priority and an application period of 5 years or more includes the smart quay crane and the mobile repair robot. The analysis results show that the products and services designed based on technologies such as big data, digital identifiers, internet of things, sensor technologies, robots and automation, autonomous vehicles, machine learning, and unmanned aerial vehicles.Through this study, we confirmed that automation and smartization of logistics are the future trends that can not be rebutted. In particular, the automation and smartization using robots and machines are necessary to solve the uncertainty problem of the manpower expected in the future logistics industry. In addition, we confirmed that many improvements are needed in the quay crane operation, the container yard operation, and the gate-in/out management in the currently operated container terminals. For this, the integration of in and out services of the container terminals should be done. The results of this study can contribute to the improvement of the present container terminal problems and the design of the future container terminal."
고유명사와 관련된 신어의 유형과 특징,2018,"['신어', '고유명사', '보통명사', '고유명사와 관련된 신어', '고유명사와 의미적으로 관련된 신어', '고유명사와 형태적으로 관련된 신어', 'Proper noun', 'Common noun', 'Proper-noun-related neologisms', 'Neologisms semantically related to proper nouns', 'Neologisms morphologically related to proper nouns']","본 연구는 고유명사와 관련된 신어들이 가진 의미 및 형태적 특징들을 분석하여 이들 신어의 언어적 특성들을 밝히는 것을 목표로 한다. 본 연구에서는 최근 5년 동안 생성되어 뉴스 기사문에서 사용된 고유명사와 관련된 신어 238개를 수집하여 이들의 형태·의미적 특성들을 분석한다. 이 유형의 신어가 생성되는 방식은 일반적인 신어와 크게 차이 나지 않았다. 어휘 구성 요소 분석을 한 경우, 고유명사가 후행하여 결합되는 경우보다는 선행하여 결합하는 경우가 약 3배 정도 더 많았다. 의미적으로 고유명사로 볼 수 있는 신어는 123개였으나 형태적으로 고유명사가 사용된 경우보다 보통명사만으로 이루어진 경우가 더 많았다. 본 연구에서 주목한 신어들에서는 순간적인 맥락상황을 포착하여 하나의 단어로 표현한 경우가 많이 관찰되며 이러한 경향성은 최근 신어의 주 생산자들이 공유하는 의사소통 방식의 변화를 반영하는 것으로 이해할 수 있다. 본 연구의 결과는 지금까지의 신어 연구에서 공백으로 남아 있던 부분을 채우는 동시에 향후 신어 추출 방법론의 발전뿐만 아니라 자연언어처리나 기계 학습 분야에도 유용한 자료로 활용될 수 있다는 의의를 가진다.","This paper aims to determine the linguistic characteristics of neologisms related to proper nouns by analyzing their semantic and morphological features. For the purpose of this study, 238 new words, which are connected to proper nouns and have been created within the last 5 years, have been collected from news articles in order to analyze their morphological and semantic characteristics. The way of coining this type of new words does not differ greatly from the coinage of general words. The analysis of lexical constituents shows that there are around three times more neologisms wherein the proper noun precedes the other constituent than neologisms wherein the proper noun comes afterwards. 123 new words that could be semantically regarded as proper nouns have been founded, among which, however, coinages composed of solely common nouns are in fact more frequent than those including proper nouns. It can be observed that many of the neologisms studied in this study tend to capture the momentary nature of a contextual situation. Such a tendency seems to reflect changes in the way today’s creators of neologisms communicate. Previous literature on neologisms shows that researchers have mainly been focusing on new words as candidates for dictionary inclusion; therefore, little attention was given to proper-noun-related neologisms. This paper seeks to fill the lacunae in neologism studies as well as to develop a methodology of new word extraction. Moreover, the results of this study have great significance in that they constitute useful data for natural language processing and machine learning research."
사이버네틱스(cybernetics)의 현상학적 전환,2018,"['사이버네틱스', '지향성', '신체성', '수학적 형이상학', '존재론적 우열', 'Cybernetics', 'Intentionality', 'Corporeality', 'Mathematical metaphysics', 'Ontological superiority and inferiority']","본 연구는 초기 사이버네틱스의 기본이념에 대한 드레이퍼스(Hubert L. Dreyfus)의 비판적 성찰의 핵심 요소들을 부분적으로 간략하게 살펴보고, 그가 수행한 작업이 오늘날의 인공지능 연구자들에게 어떤 인간학적인 함의를 전해줄 수 있을지를 철학사적 관점에서 보충적으로 성찰하고 짚어보는 데 주된 목표를 설정한다. 본 연구의 핵심적인 물음은 다음과 같다. “오늘날까지 사이버네틱스 연구자들을 지배하는 존재론적 가정의 철학사적 기원은 무엇인가? 인간의 의식에 대한 이들의 가정은 인공지능 시대의 도래를 맞이하는 오늘날 어떤 양태의 근원적 문제들을 유발하는가?” 이 물음에 답하기 위해, 본 연구는 우선 사이버네틱스의 역사, 그리고 그 과정에서 드러난 사이버네틱스의 기본이념에 대한 드레이퍼스의 비판적 성찰을 간략히 고찰한다. 여기서는 인간 의식과 인공지능 간의 근원적 차이, 그리고 초기 사이버네틱스 연구자들 사이에 공유되던 존재론적 가정의 진면목과 문제점에 대한 드레이퍼스의 견해를 살피는 데 초점을 맞춘다. 다음으로 본 연구는 이런 존재론적 가정에 대해 그가 수행하지 못한 철학사적 분석을 추가로 진행함으로써 그의 사이버네틱스 성찰이 가진 함의를 오늘날의 인공지능 개발 현실에 발맞춰 길어내는 데 주력한다. 무엇보다 인공신경망 기반 기계학습 인공지능이 각광받는 오늘의 현실에서도 드레이퍼스의 현상학적 성찰이 유의미하게 받아들여질 수 있을지를 살피는 데 논의의 초점을 맞춘다.","The present study is aimed at examining core factors in Hubert L. Dreyfus` critical reflections on the basic ideology of early cybernetics, an investigation followed by an additional reflection on some anthropological implications of his critique for today`s artificial intelligence researchers. The present study raises the following questions: ""What is the philosophical origin of the ontological assumption which has dominated contemporary cybernetics researchers? What types of fundamental problems has this assumption on human consciousness caused by now?"" To answer these questions, this study first undertakes the task of looking over the history of cybernetics and its basic ideology, which has been subject to Dreyfus"" reflective criticism. The first part of this study concentrates on his observations on fundamental differences between human consciousness and artificial intelligence and his views on the real nature and problems of ontological assumption, which were widely shared by early cybernetics researchers. Afterwards, the present study proceeds to an additional philosophical-historical analysis of cybernetics` ontological assumption in such a way that this study can shed some light on the implications of Dreyfus` reflections on cybernetics. The focus of the later part of this study is on the existential validity of his phenomenological reflections in today`s reality in which an interest in machine learning, which is based on artificial neural networks, prevails among cybernetics researchers and the public."
