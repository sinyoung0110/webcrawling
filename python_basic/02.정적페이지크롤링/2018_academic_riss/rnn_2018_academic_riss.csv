title,date,keywords,abstract,multilingual_abstract
RNN을 이용한 코드 재사용 공격 탐지 방법 연구,2018,"['코드 재사용 공격', 'ROP(Return-Oriented Programming)', 'RNN(Recurrent Neural Network)', 'code reuse attack']","코드 재사용 공격은 프로그램 메모리상에 존재하는 실행 가능한 코드 조각을 조합하고, 이를 연속적으로 실행함으로써 스택에 직접 코드를 주입하지 않고도 임의의 코드를 실행시킬 수 있는 공격 기법이다. 코드 재사용 공격의 대표적인 종류로는 ROP(Return-Oriented Programming) 공격이 있으며, ROP 공격에 대응하기 위한 여러 방어기법들이 제시되어왔다. 그러나 기존의 방법들은 특정 규칙을 기반으로 공격을 탐지하는 Rule-base 방식을 사용하기 때문에 사전에 정의한 규칙에 해당되지 않는 ROP 공격은 탐지할 수 없다는 한계점이 존재한다. 본 논문에서는 RNN(Recurrent Neural Network)을 사용하여 ROP 공격 코드에 사용되는 명령어 패턴을 학습하고, 이를 통해 ROP 공격을 탐지하는 방법을 소개한다. 또한 정상 코드와 ROP 공격 코드 판별에 대한 False Positive Ratio, False Negative Ratio, Accuracy를 측정함으로써 제안한 방법이 효과적으로 ROP 공격을 탐지함을 보인다.","A code reuse attack is an attack technique that can execute arbitrary code without injecting code directly into the stack by combining executable code fragments existing in program memory and executing them continuously. ROP(Return-Oriented Programming) attack is typical type of code reuse attack and serveral defense techniques have been proposed to deal with this. However, since existing methods use Rule-based method to detect attacks based on specific rules, there is a limitation that ROP attacks that do not correspond to previously defined rules can not be detected. In this paper, we introduce a method to detect ROP attack by learning command pattern used in ROP attack code using RNN(Recurrent Neural Network). We also show that the proposed method effectively detects ROP attacks by measuring False Positive Ratio, False Negative Ratio, and Accuracy for normal code and ROP attack code discrimination."
RNN-LSTM을 이용한 태양광 발전량 단기 예측 모델,2018,"['Solar power generation forecasting', 'Deep learning', 'Artificial neural network', 'Sunshine', 'Solar radiation']","태양광 발전은 기상 상태에 따라 간헐적이기 때문에 태양광 발전의 효율과 경제성 향상을 위해 정확한 발전량 예측이 요구된다. 본 연구는 목포 기상대에서 예보하는 기상 데이터와 영암 태양광 발전소의 발전량 데이터를 이용하여 태양광 발전량 단기 딥러닝 예측모델을 제안하였다. 기상청은 기온, 강수량, 풍향, 풍속, 습도, 운량 등의 기상요소를 3일간 예보한다. 그러나 태양광 발전량 예측에 가장 중요한 기상요소인 일조 및 일사 일사량 예보하지 않는다. 제안 모델은 예보 기상요소를 이용하여, 일조 및 일사 일사량을 예측 하였다. 또한 발전량은 기상요소에 예측된 일조 및 일사 기상요소를 추가하여 예측하였다. 제안 모델의 발전량 예측 결과 DNN의 평균 RMSE와 MAE는 0.177과 0.095이며, RNN은 0.116과 0.067이다. 또한, LSTM은 가장 좋은 결과인 0.100과 0.054이다. 향후 본 연구는 다양한 입력요소의 결합으로 보다 향상된 예측결과를 도출할 수 있을 것으로 기대된다.","Since solar power generation is intermittent depending on weather conditions, it is necessary to predict the accurate generation amount of solar power to improve the efficiency and economical efficiency of solar power generation. This study proposes a short - term deep learning prediction model of solar power generation using meteorological data from Mokpo meteorological agency and generation data of Yeongam solar power plant. The meteorological agency forecasts weather factors such as temperature, precipitation, wind direction, wind speed, humidity, and cloudiness for three days. However, sunshine and solar radiation, the most important meteorological factors for forecasting solar power generation, are not predicted. The proposed model predicts solar radiation and solar radiation using forecast meteorological factors. The power generation was also forecasted by adding the forecasted solar and solar factors to the meteorological factors. The forecasted power generation of the proposed model is that the average RMSE and MAE of DNN are 0.177 and 0.095, and RNN is 0.116 and 0.067. Also, LSTM is the best result of 0.100 and 0.054. It is expected that this study will lead to better prediction results by combining various input."
RNN을 활용한 도시철도 역사 부하 패턴 추정,2018,"['Urban railway station', 'Load pattern', 'Deep learning', 'Recursive neural networks', 'Gated recurrent unit']",,"For effective electricity consumption in urban railway station such as peak load shaving, it is important to know each electrical load pattern by various usage. The total electricity consumption in the urban railway substation is already measured in Korea, but the electricity consumption for each usage is not measured. The author proposed the deep learning method to estimate the electrical load pattern for each usage in the urban railway substation with public data such as weather data. GRU (gated recurrent unit), a variation on the LSTM (long short-term memory), was used, which aims to solve the vanishing gradient problem of standard a RNN (recursive neural networks). The optimal model was found and the estimation results with that were assessed."
RNN을 이용한 동작기록 마이닝 기반의 추천 방법,2018,"['소프트웨어 공학', '딥러닝', '동작기록', 'Software Engineering', 'Deep Learning', 'Interaction History']",,"Developers spend a significant amount of time exploring and trying to understand source code to find a source location to modify. To reduce such time, existing studies have recommended the source location using statistical language model techniques. However, in these techniques, the recommendation does not occur if input data does not exactly match with learned data. In this paper, we propose a code location recommendation method using Recurrent Neural Networks and interaction histories, which does not have the above problem of the existing techniques. Our method achieved an average precision of 91% and an average recall of 71%, thereby reducing time for searching and exploring code more than the existing recommendation techniques."
RNN 알고리즘을 이용한 보행분석 기반 개인 인증방법 구현,2018,"['individual recognition', 'RNN', 'gait analysis', 'gait pattern', 'android accelerometer', '개인 인식', '개인 식별', 'RNN', '보행 분석', '보행 패턴', '안드로이드 가속도계']","개인 인증 기법에는 비밀번호, 또는 ID카드부터 지문인식, 정맥인식, 홍채인식 등 다수가 존재한다. 비밀번호나 ID카드의 경우 간단하게 구현이 되지만, 이는 쉽게 모방되거나 탈취되어 무력화될 수 있다. 지문인식, 정맥인식, 그리고 홍채인식의 경우 별도의 장비와 해당 장비에서의 사용자 등록 절차가 필요하다. 본 논문에서는 RNN(Recurrent Neural Network)을 이용해 안드로이드 기기의 가속도센서를 학습하여 보행 시 팔 동작 분석을 통한 개인 인증을 분석을 진행한다.","Many types of individual recognition techniques have been developed such as the use of a password, ID card, fingerprint recognition, vein recognition, and iris recognition. In the case of a password or ID card, while it is simple to implement, it can be easily imitated or captured and neutralized. In the case of fingerprint recognition, vein recognition, and iris recognition, specific equipment and user registration procedures are required in the corresponding equipment. In this paper, we study the accelerometer sensor data of android devices using Recurrent Neural Network (RNN) and analyze individual recognition through arm motion analysis during walking."
RNN을 이용한 범용 예측 시스템 구현,2018,"['deep learning', 'RNN', 'LSTM', 'CNN', 'artificial intelligence', 'prediction system']",,"Various algorithms and models of deep learning were developed, and RNN shows good performance in future prediction system. RNN and LSTM applied universal prediction system was realized in this paper, and performance was evaluated by cost value. Difference between input data was so big that we normalized this input data, and sequence size of learning input was 5 in the performance experiment. The legibility of the results was increased by displaying learning result, predictive execution result and cost values on a real-time graph. In this experiment, accomplishment of learning was confirmed by cost values decrease from learning number 150 to 0.085. future prediction system precisely learned learnin target value and test target value in a small number of learning time in a short time. Furthermore, cost value decreased to wanted value, confirming that the performance of suggested prediction system is excellent."
Speech-Act Analysis System Based on Dialogue Level RNN-CNN Effective on the Exposure Bias Problem,2018,"['화행 분석', 'RNN-CNN', '노출 편향 문제', '딥 러닝', 'speech-act analysis', 'exposure bias problem', 'deep learning']",,
RNN Auto-Encoder의 시계열 임베딩을 이용한 자동작곡,2018,"['RNN', 'Automatic Composition', 'Auto-Encoder']",,
스켈레톤 벡터 정보와 RNN 학습을 이용한 행동인식 알고리즘,2018,"['skeleton', 'feature vector', 'RNN', 'SELU', 'deep learning']",,"Behavior awareness is a technology that recognizes human behavior through data and can be used in applications such as risk behavior through video surveillance systems. Conventional behavior recognition algorithms have been performed using the 2D camera image device or multi-mode sensor or multi-view or 3D equipment. When two-dimensional data was used, the recognition rate was low in the behavior recognition of the three-dimensional space, and other methods were difficult due to the complicated equipment configuration and the expensive additional equipment. In this paper, we propose a method of recognizing human behavior using only CCTV images without additional equipment using only RGB and depth information. First, the skeleton extraction algorithm is applied to extract points of joints and body parts. We apply the equations to transform the vector including the displacement vector and the relational vector, and study the continuous vector data through the RNN model. As a result of applying the learned model to various data sets and confirming the accuracy of the behavior recognition, the performance similar to that of the existing algorithm using the 3D information can be verified only by the 2D information."
Malware Detection Model with Skip-Connected LSTM RNN,2018,"['악성코드 탐지', '딥러닝', 'Skip-Connected LSTM RNN', 'malware detection', 'deep-learning']",,
딥러닝 시계열 알고리즘 적용한 기업부도예측모형 유용성 검증,2018,"['Optimal Feature Selection', 'Lasso Regression', 'Deep Learning Time Series Algorithm', 'Corporate Bankruptcy', 'RNN', 'LSTM', '최적 변수 선별', 'Lasso 회귀분석', '딥러닝 시계열 알고리즘', '기업부도', 'RNN', 'LSTM']","본 연구는 경제적으로 국내에 큰 영향을 주었던 글로벌 금융위기를 기반으로 총 10년의 연간 기업데이터를이용한다. 먼저 시대 변화 흐름에 일관성있는 부도 모형을 구축하는 것을 목표로 금융위기 이전(2000~2006년) 의 데이터를 학습한다. 이후 매개 변수 튜닝을 통해 금융위기 기간이 포함(2007~2008년)된 유효성 검증 데이터가 학습데이터의 결과와 비슷한 양상을 보이고, 우수한 예측력을 가지도록 조정한다. 이후 학습 및 유효성 검증데이터를 통합(2000~2008년)하여 유효성 검증 때와 같은 매개변수를 적용하여 모형을 재구축하고, 결과적으로최종 학습된 모형을 기반으로 시험 데이터(2009년) 결과를 바탕으로 딥러닝 시계열 알고리즘 기반의 기업부도예측 모형이 유용함을 검증한다.부도에 대한 정의는 Lee(2015) 연구와 동일하게 기업의 상장폐지 사유들 중 실적이 부진했던 경우를 부도로선정한다. 독립변수의 경우, 기존 선행연구에서 이용되었던 재무비율 변수를 비롯한 기타 재무정보를 포함한다.이후 최적의 변수군을 선별하는 방식으로 다변량 판별분석, 로짓 모형, 그리고 Lasso 회귀분석 모형을 이용한다. 기업부도예측 모형 방법론으로는 Altman(1968)이 제시했던 다중판별분석 모형, Ohlson(1980)이 제시한 로짓모형, 그리고 비시계열 기계학습 기반 부도예측모형과 딥러닝 시계열 알고리즘을 이용한다.기업 데이터의 경우, ‘비선형적인 변수들’, 변수들의 ‘다중 공선성 문제’, 그리고 ‘데이터 수 부족’이란 한계점이 존재한다. 이에 로짓 모형은 ‘비선형성’을, Lasso 회귀분석 모형은 ‘다중 공선성 문제’를 해결하고, 가변적인데이터 생성 방식을 이용하는 딥러닝 시계열 알고리즘을 접목함으로서 데이터 수가 부족한 점을 보완하여 연구를 진행한다.현 정부를 비롯한 해외 정부에서는 4차 산업혁명을 통해 국가 및 사회의 시스템, 일상생활 전반을 아우르기위해 힘쓰고 있다. 즉, 현재는 다양한 산업에 이르러 빅데이터를 이용한 딥러닝 연구가 활발히 진행되고 있지만, 금융 산업을 위한 연구분야는 아직도 미비하다. 따라서 이 연구는 기업 부도에 관하여 딥러닝 시계열 알고리즘 분석을 진행한 초기 논문으로서, 금융 데이터와 딥러닝 시계열 알고리즘을 접목한 연구를 시작하는 비 전공자에게 비교분석 자료로 쓰이기를 바란다.","In addition to stakeholders including managers, employees, creditors, and investors of bankrupt companies, corporate defaults have a ripple effect on the local and national economy. Before the Asian financial crisis, the Korean government only analyzed SMEs and tried to improve the forecasting power of a default prediction model, rather than developing various corporate default models. As a result, even large corporations called 'chaebol enterprises' become bankrupt. Even after that, the analysis of past corporate defaults has been focused on specific variables, and when the government restructured immediately after the global financial crisis, they only focused on certain main variables such as 'debt ratio'.A multifaceted study of corporate default prediction models is essential to ensure diverse interests, to avoid situations like the 'Lehman Brothers Case' of the global financial crisis, to avoid total collapse in a single moment.The key variables used in corporate defaults vary over time. This is confirmed by Beaver (1967, 1968) and Altman’s (1968) analysis that Deakins'(1972) study shows that the major factors affecting corporate failure have changed. In Grice's (2001) study, the importance of predictive variables was also found through Zmijewski’s (1984) and Ohlson’s (1980) models. However, the studies that have been carried out in the past use static models. Most of them do not consider the changes that occur in the course of time. Therefore, in order to construct consistent prediction models, it is necessary to compensate the time-dependent bias by means of a time series analysis algorithm reflecting dynamic change.Based on the global financial crisis, which has had a significant impact on Korea, this study is conducted using 10 years of annual corporate data from 2000 to 2009. Data are divided into training data, validation data, and test data respectively, and are divided into 7, 2, and 1 years respectively. In order to construct a consistent bankruptcy model in the flow of time change, we first train a time series deep learning algorithm model using the data before the financial crisis (2000~2006). The parameter tuning of the existing model and the deep learning time series algorithm is conducted with validation data including the financial crisis period (2007~2008). As a result, we construct a model that shows similar pattern to the results of the learning data and shows excellent prediction power. After that, each bankruptcy prediction model is restructured by integrating the learning data and validation data again (2000 ~ 2008), applying the optimal parameters as in the previous validation. Finally, each corporate default prediction model is evaluated and compared using test data (2009) based on the trained models over nine years. Then, the usefulness of the corporate default prediction model based on the deep learning time series algorithm is proved. In addition, by adding the Lasso regression analysis to the existing methods (multiple discriminant analysis, logit model) which select the variables, it is proved that the deep learning time series algorithm model based on the three bundles of variables is useful for robust corporate default prediction.The definition of bankruptcy used is the same as that of Lee (2015). Independent variables include financial information such as financial ratios used in previous studies. Multivariate discriminant analysis, logit model, and Lasso regression model are used to select the optimal variable group. The influence of the Multivariate discriminant analysis model proposed by Altman (1968), the Logit model proposed by Ohlson (1980), the non-time series machine learning algorithms, and the deep learning time series algorithms are compared.In the case of corporate data, there are limitations of 'nonlinear variables', 'multi-collinearity' of variables, and 'lack of data'. While the logit model is nonlinear, the Lasso regression model solves the multi-collinear..."
단어의 의미와 문맥을 고려한 순환신경망 기반의 문서 분류,2018,"['문서 분류', 'Doc2vec 순환신경망']","본 논문에서는 단어의 순서와 문맥을 고려하는 특징을 추출하여 순환신경망(Recurrent Neural Network)으로 문서를 분류하는 방법을 제안한다. 단어의 의미를 고려한 word2vec 방법으로 문서내의 단어를 벡터로 표현하고, 문맥을 고려하기 위해 doc2vec으로 입력하여 문서의 특징을 추출한다. 문서분류 방법으로 이전 노드의 출력을 다음 노드의 입력으로 포함하는 RNN 분류기를 사용한다. RNN 분류기는 신경망 분류기 중에서도 시퀀스 데이터에 적합하기 때문에 문서 분류에 좋은 성능을 보인다. RNN에서도 그라디언트가 소실되는 문제를 해결해주고 계산속도가 빠른 GRU(Gated Recurrent Unit) 모델을 사용한다. 실험 데이터로 한글 문서 집합 1개와 영어 문서 집합 2개를 사용하였고 실험 결과 GRU 기반 문서 분류기가 CNN 기반 문서 분류기 대비 약 3.5%의 성능 향상을 보였다.","In this paper, we propose a method to classify a document using a Recurrent Neural Network by extracting features considering word sense and contexts. Word2vec method is adopted to include the order and meaning of the words expressing the word in the document as a vector. Doc2vec is applied for considering the context to extract the feature of the document. RNN classifier, which includes the output of the previous node as the input of the next node, is used as the document classification method. RNN classifier presents good performance for document classification because it is suitable for sequence data among neural network classifiers. We applied GRU (Gated Recurrent Unit) model which solves the vanishing gradient problem of RNN. It also reduces computation speed. We used one Hangul document set and two English document sets for the experiments and GRU based document classifier improves performance by about 3.5% compared to CNN based document classifier."
머신 러닝을 이용한 외란 관측기 구현,2018,"['machine learning', 'disturbance observer', 'robust control', 'Inverse model']",,"This paper presents a method of constructing an inverse model-based disturbance observer using two neural network methods: Multi-Layer Perceptron (MLP) and Recurrent Neural Network (RNN). Learning data is prepared for MLP and RNN by selecting input data such that it contains various signal shapes such as constant, step, sinusoidal and random number, and frequency components. This input data is injected into the nominal model of the system and the resulting state values are used as the measurement. The weights of MLP and RNN are optimized using these data, and how unknown disturbances are estimated is explained using the learned MLP and RNN. The simulation results show that the proposed method works well; in other words, the MLP- and RNN-based disturbance observer can reject both external disturbances and model uncertainties."
순환신경망을 이용한 자기장 기반 실내측위시스템,2018,"['indoor localization', 'geomagnetic field', 'recurrent neural network', 'deep learning', 'machine learning', '실내 위치인식', '자기장', '순환신경망', '딥러닝', '기계학습']","BLE 는 Wi-Fi 기반 지문인식과 같은 기존의 RF 신호 기반 실내 치인식 기술은 RF 신호의 불안정한 수신 신 호 세기로 인해 소규모 실내 환경에서도 작지 않은 오차를 발생시키며 공항, 백화과 같은 규모 실내 환경에 용하기가 어렵다. 이 논문에서는 RF 신호보다 안정인 신호 강도를 갖는 자기장 신호를 이용한 실내측 시스템을 제안한다. 유사한 자기장 값이 같은 실내 공간에 여럿 존재하지만, 사용자의 이동이 계속됨에 따라 자기장 신호는 고유 시스를 가지게 된다. 본 논문에서는 시간에 따라 변화하는 센서 데이터 시스를 인식하는 데 효과인 순환 신경망 (Recurrent neural network, RNN)이라 불리는 심층 신경망 모델을 사용하여 사용자의 재 치와 이 동 경로를 추한다. 제안된 신경망 기반의 지자기 실내측시스템의 평가를 해 약 94m x 26m 크기의 교내 테 스트베드에서 자기장 맵을 구축하고 자기장맵으로부터 추출한 다양한 이동 경로와 치 정보를 이용하여 RNN을 학습한 결과, 테스트베드에서 제안된 시스템은 평균 1.20 미터의 테스트 측 오차를 달성할 수 있었다.","Conventional RF signal-based indoor localization techniques such as BLE or Wi-Fi based fingerprinting method show considerable localization errors even in small-scale indoor environments due to unstable received signal strength(RSS) of RF signals. Therefore, it is difficult to apply the existing RF-based fingerprinting techniques to large-scale indoor environments such as airports and department stores. In this paper, instead of RF signal we use the geomagnetic sensor signal for indoor localization, whose signal strength is more stable than RF RSS. Although similar geomagnetic field values exist in indoor space, an object movement would experience a unique sequence of the geomagnetic field signals as the movement continues. We use a deep neural network model called the recurrent neural network (RNN), which is effective in recognizing time-varying sequences of sensor data, to track the user's location and movement path. To evaluate the performance of the proposed geomagnetic field based indoor positioning system (IPS), we constructed a magnetic field map for a campus testbed of about 94m x 26 m dimension and trained RNN using various potential movement paths and their location data extracted from the magnetic field map. By adjusting various hyperparameters, we could achieve an average localization error of 1.20 meters in the testbed."
Deep Neural Architecture for Recovering Dropped Pronouns in Korean,2018,"['Deep learning', 'Dropped pronoun recovery', 'LSTM Encoding', 'Zero pronoun.']",,"Pronouns are frequently dropped in Korean sentences, especially in text messages in the mobile phone environment. Restoring dropped pronouns can be a beneficial preprocessing task for machine translation, information extraction, spoken dialog systems, and many other applications. In this work, we address the problem of dropped pronoun recovery by resolving two simultaneous subtasks: detecting zero‐pronoun sentences and determining the type of dropped pronouns. The problems are statistically modeled by encoding the sentence and classifying types of dropped pronouns using a recurrent neural network (RNN) architecture. Various RNN‐based encoding architectures were investigated, and the stacked RNN was shown to be the best model for Korean zero‐pronoun recovery. The proposed method does not require any manual features to be implemented; nevertheless, it shows good performance."
CNN과 OpenPose 라이브러리를 활용한 실시간 수화 통역기,2018,"['OpenPose', 'Real-time system', 'Pose detection', 'Sign language']","인공지능 기술이 급속도로 발전하고 있다. 인공지능 기술이 발전함에 따라 많은 기업들이 제품에 인공지능 기술을 탑재하여 출시하고 있다. 인공지능 기술이 포함된 제품이 많아지면서 우리의 삶에 없어서는 안 될 필수요소로 자리잡고 있다. 최근 이러한 인공지능 제품들은 일반인뿐만 아니라 일상생활에 많은 불편함을 느끼는 장애인들을 타깃으로 다양하게 출시되고 있다. 그러나 이러한 제품들은 대부분 시각장애인들을 위해 촉각, 청각에 기반을 둔 개발로 초점이 맞춰져 있다. 따라서 본 논문에서는 CNN을 이용하여 특징을 추출하는 OpenPose 라이브러리와 RNN을 사용하여 청각장애인들을 위한 실시간 수화 번역 프로그램을 제작했다. 수화 번역기의 구현 가능성을 테스트하기 위해 0~9까지 숫자에 대해 테스트를 진행하였고, 그 결과를 손 상단에 출력하였다. 실험 결과 OpenPose를 통해 검출한 신체를 토대로 손의 움직임을 학습하여 수화로 나타내는 숫자를 손 상단에 정확히 출력하는 것을 확인할 수 있었다. 0~9 의 10개의 단어를 이용하여 테스트를 진행하였지만, 자음, 모음 혹은 단어를 학습하게 된다면 실생활에서 이용하는 다양한 문장을 해석할 수 있다. 또한 이는 대화에 어려움을 느끼는 장애인뿐만 아니라 이들과 대화를 함께하는 비장애인들에게도 유용하게 작용되어 장애인과 비장애인 사이의 대화의 벽을 허물 수 있을 것으로 기대된다.","Artificial Intelligent(AI) technology has shown a rapid development in recent years. With such a development, numerous businesses release commercialized devices equipped with AI. As the number of products including AI technology increases, it becomes an indispensable element in our lives. Recently, the AI products have been released in various forms not only for the general consumers but also for the disables who might have some troubles in their daily life. But this kind of products mostly focus on the blinds (and offer support in the matter of the sense of touch and sound.) For this reason, we made a real-time interpreter of sign language for the deaf using OpenPose library which extracts the feature using CNN and RNN. In order to verify its feasibility, we processed a test with the digit 0 to 9 and printed the output above the hand on the screen. As a result, it has been confirmed that our AI is able to accurately recognize each numerical value represented by sign language. If this can also differentiate consonants, vowels, words and even various sentences used in real life, it is expected that this will be worthwhile not only for the disables who have the difficulty in conversation with diverse people, but also for non-disabled people."
포지션 인코딩 기반 스택 포인터 네트워크를 이용한 한국어 상호참조해결,2018,"['포지션 인코딩', '동적 포지션 인코딩', '포인터 네트워크', '상호참조해결', '딥러닝', '스택', 'position encoding', 'dynamic position encoding', 'pointer networks', 'coreference resolution', 'deep learning', 'stacked pointer networks']","포지션 인코딩은 문장 내 등장하는 단어의 위치에 따라 가중치를 적용하는 방법이다. 포인터 네트워크는 입력열에 대응되는 위치를 출력하는 딥 러닝 모델이며, 상호참조해결에 적용될 수 있다. 그러나 포인터 네트워크는 입력열의 길이가 긴 경우에 성능이 저하되는 문제가 있다. 이러한 문제를 해결하기 위하여 본 논문에서는 포지션 인코딩과 동적 포지션 인코딩을 포인터 네트워크에 적용할 것을 제안하고, Encoder RNN의 레이어를 더 깊게 쌓아 높은 수준으로 추상화할 것을 제안하며, 이를 이용한 상호참조해결 모델을 제안한다. 실험 결과, 본 논문에서 제안한 포지션 인코딩 기반 스택 포인터 네트워크 모델이 기존의 포인터 네트워크 모델보다 6.01% 향상된 CoNLL F1 71.78%의 성능을 보였다.","Position encoding is a method of applying weights according to position of words that appear in a sentence. Pointer networks is a deep learning model that outputs corresponding index with an input sequence. This model can be applied to coreference resolution using attribute. However, the pointer networks has a problem in that its performance is degraded when the length of input sequence is long. To solve this problem, we proposed two contributions to resolve the coreference. First, we applied position encoding and dynamic position encoding to pointer networks. Second, we stack deeply layers of encoder to make high-level abstraction. As results, the position encoding based stacked pointer networks model proposed in this paper had a CoNLL F1 performance of 71.78%, which was improved by 6.01% compared to vanilla pointer networks."
순환신경망 기반의 사용자 의도 예측 모델,2018,"['big data', 'deep learning', 'human intention prediction', 'RNN', '빅데이터', '딥러닝', '사용자 의도 예측', '순환 신경망']","기계 학습 모델 구축을 통한 인간의 의도 예측은 기존에도 제공되어 왔으나, 특정 행위가 발생하는 시점으로부터 먼 과거의 정보를 반영한 의도 예측이 어렵다는 단점이 존재했다. 이 문제점의 극복을 위해, 본 논문에서는 순환 신경망(RNN – Recurrent Neural Network) 기반의 행위 의도 예측 모델 학습 기법을 제안한다. 순환 신경망 모델은 시계열(Time-Series) 데이터의 패턴을 분석하여 과거의 시점이 반영된 예측 결과를 생성한다. 본 논문이 제안하는 순환 신경망 기반의 의도 예측 모델은 시간, 공간, 행위, 물체, 의도로 구성된 생활 데이터 시퀀스를 바탕으로 사용자의 의도를 예측할 수 있도록 학습된다. 순환 신경망의 각 노드는 의도 예측 모델이 먼 과거의 데이터 시퀀스를 고려하여 의도를 예측 할 수 있도록 LSTM(Long-Short Term Memory) Cell로 구성하였다. 순환 신경망 기반의 의도 예측 모델의 성능 평가를 위해, 본 논문에서는 행위 의도에 대한 가중치 그래프 기반 데이터 생성기를 구축하여 실제 실내에서 발생하는 인간 활동에 가까운 데이터를 자동으로 생성하여 실험에 사용했다. 총 23,000개의 데이터가 의도 모델 학습과 검증에 사용되었으며, 학습된 모델의 의도 예측 정확도 측정 실험을 한 결과로 평균 90.52%의 예측 정확도를 보였다.","Several studies have been conducted on human intention prediction with the help of machine learning models. However, these studies have indicated a fundamental shortcoming of machine learning models since they are unable to reflect a long span of past information. To overcome this limitation, this paper proposes a human intention prediction model based on a recurrent neural network(RNN). For performing predictions, the RNN model classifies the patterns of time-series data by reflecting previous sequence patterns of the time-series data. For performing intention prediction using the proposed model, an RNN model was trained to classify predefined intentions by using attributes such as time, location, activity and detected objects in a house. Each RNN node is composed of a long short-term memory cell to solve the long term dependency problem. To evaluate the proposed intention prediction model, a data generator based on the weighted-graph structure has been developed for generating data on a daily basis. By incorporating 23,000 data instances for training and testing the proposed intention prediction model, a prediction accuracy value of 90.52% was achieved."
다목적댐 유입량 예측을 위한 Recurrent Neural Network 모형의 적용 및 평가,2018,"['댐 유입량 예측', '엘만순환신경망', '인공신경망', 'Dam inflow prediction', 'Elman recurrent neural network', 'Artificial neural network']","본 연구에서는 순환신경망을 이용한 댐 유입량 예측모형의 적용성 검토를 목적으로 하고 있으며, 이를 위해 소양강댐 유역 및 충주댐 유역을 대상으로 그간 댐 운영을 통해 축적된 기상 및 수문 빅데이터를 활용하여 인공신경망 모형과 엘만 순환신경망 모형을 구축하였다. 모형의 학습과 예측을 위하여 유역별 유입량, 강우량, 기온, 일조시간, 풍속자료가 입력자료로 사용되었고 10일간 일별 댐유입량 자료가 모델의 출력자료로 구조화 하여 학습을 진행한 후 검증을 목적으로 2016년 7월 ~ 2018년 6월까지 2개년에 대한 댐 유입량 예측을 수행하였다. 학습된 모형의 유입량 예측 결과를 비교분석한 결과, 소양강댐 유역에서는 인공신경망 모형과 순환신경망 모형 간 예측성능은 큰 차이를 보이지 않았으며, 충주댐 유역에서는 순환신경망 모형의 예측 결과가 인공신경망 모형에 비해 비교적 우수한 성능을 보임에 따라 엘만 순환신경망을 이용하여 댐 유입량 예측모형을 구축할 경우 예측성능은 기존의 인공신경망 모형과 비슷하거나 다소 우수할 것으로 판단된다. 또한 엘만 순환신경망은 갈수기 댐 유입량 예측에 있어서 인공신경망에 비해 예측결과의 재현성이 우수한 것으로 나타났으며, 엘만 순환신경망 학습에 있어 다중 은닉층 구조가 단일 은닉층 구조보다 예측성능 향상에 효과적인 것으로 분석되었다.","This paper aims to evaluate the applicability of dam inflow prediction model using recurrent neural network theory. To achieve this goal, the Artificial Neural Network (ANN) model and the Elman Recurrent Neural Network(RNN) model were applied to hydro-meteorological data sets for the Soyanggang dam and the Chungju dam basin during dam operation period. For the model training, inflow, rainfall, temperature, sunshine duration, wind speed were used as input data and daily inflow of dam for 10 days were used for output data. The verification was carried out through dam inflow prediction between July, 2016 and June, 2018. The results showed that there was no significant difference in prediction performance between ANN model and the Elman RNN model in the Soyanggang dam basin but the prediction results of the Elman RNN model are comparatively superior to those of the ANN model in the Chungju dam basin. Consequently, the Elman RNN prediction performance is expected to be similar to or better than the ANN model. The prediction performance of Elman RNN was notable during the low dam inflow period. The performance of the multiple hidden layer structure of Elman RNN looks more effective in prediction than that of a single hidden layer structure."
Application of recurrent neural network for inflow prediction into multi-purpose dam basin,2018,"['Dam inflow prediction', 'Elman recurrent neural network', 'Artificial neural network', '댐 유입량 예측', '엘만순환신경망', '인공신경망']","본 연구에서는 순환신경망을 이용한 댐 유입량 예측모형의 적용성 검토를 목적으로 하고 있으며, 이를 위해 소양강댐 유역 및 충주댐 유역을 대상 으로 그간 댐 운영을 통해 축적된 기상 및 수문 빅데이터를 활용하여 인공신경망 모형과 엘만 순환신경망 모형을 구축하였다. 모형의 학습과 예측 을 위하여 유역별 유입량, 강우량, 기온, 일조시간, 풍속자료가 입력자료로 사용되었고 10일간 일별 댐유입량 자료가 모델의 출력자료로 구조화 하여 학습을 진행한 후 검증을 목적으로 2016년 7월 ~ 2018년 6월까지 2개년에 대한 댐 유입량 예측을 수행하였다. 학습된 모형의 유입량 예측 결과를 비교분석한 결과, 소양강댐 유역에서는 인공신경망 모형과 순환신경망 모형 간 예측성능은 큰 차이를 보이지 않았으며, 충주댐 유역에서는 순환신경망 모형의 예측 결과가 인공신경망 모형에 비해 비교적 우수한 성능을 보임에 따라 엘만 순환신경망을 이용하여 댐 유입량 예측모형을 구축 할 경우 예측성능은 기존의 인공신경망 모형과 비슷하거나 다소 우수할 것으로 판단된다. 또한 엘만 순환신경망은 갈수기 댐 유입량 예측에 있어서 인공신경망에 비해 예측결과의 재현성이 우수한 것으로 나타났으며, 엘만 순환신경망 학습에 있어 다중 은닉층 구조가 단일 은닉층 구조보다 예측 성능 향상에 효과적인 것으로 분석되었다.","This paper aims to evaluate the applicability of dam inflow prediction model using recurrent neural network theory. To achieve this goal, the Artificial Neural Network (ANN) model and the Elman Recurrent Neural Network(RNN) model were applied to hydro-meteorological data sets for the Soyanggang dam and the Chungju dam basin during dam operation period. For the model training, inflow, rainfall, temperature, sunshine duration, wind speed were used as input data and daily inflow of dam for 10 days were used for output data. The verification was carried out through dam inflow prediction between July, 2016 and June, 2018. The results showed that there was no significant difference in prediction performance between ANN model and the Elman RNN model in the Soyanggang dam basin but the prediction results of the Elman RNN model are comparatively superior to those of the ANN model in the Chungju dam basin. Consequently, the Elman RNN prediction performance is expected to be similar to or better than the ANN model. The prediction performance of Elman RNN was notable during the low dam inflow period. The performance of the multiple hidden layer structure of Elman RNN looks more effective in prediction than that of a single hidden layer structure."
딥러닝 앙상블을 이용한 주가예측,2018,"['Deep Learning', 'Ensemble', 'Stacking', 'Stock Price Prediction', '딥러닝', '앙상블', '스태킹', '주가예측']","최근 딥러닝(Deep Learning)을 이용한 주가예측이 활발하게 연구되고 있으나, 서로 다른 딥러닝 모델들을 결합하는 앙상블(Ensemble) 방법에 대한 연구는 초기 단계이다. 딥러닝 모델에는 Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN)이 있다. 본 논문에서는 세 가지 딥러닝 모델(MLP, CNN, RNN)이 예측한 결과를 결합하고 MLP를 사용하여 다시 학습하는 스태킹(Stacking) 기반의 앙상블 모델을 사용하여 주가를 예측한다. KOSPI 상위 30 종목 중 18개 종목을 이용하여 실험한 결과, 제안한 방법이 기존 방법에 비해 절대평균백분율오차(MAPE)가 8.74%에서 3.35%로 감소하였다.","Recently, there have been research efforts on predicting stock price using deep learning, but little attention has been paid so far to ensemble methods, which combines different deep learning models. Deep learning models include Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN). In this paper, we propose a stacking-based ensemble model where a deep learning model combines predictions of three different deep learning models (MLP, CNN, and RNN). We use MLP as the second level model. The experimental results using 18 stock items among KOSPI top 30 items show that the proposed method improves the mean absolute percentage error (MAPE) from 8.74%, which is the MAPE of the state-of-the-art method, to 3.35%."
IoT 스트리밍 센서 데이터에 기반한 실시간 PM10 농도 예측 LSTM 모델,2018,"['Long Short Term Memory', 'PM10', 'Prediction model', 'Recurrent Neural Network', 'Sequence data']","최근 사물인터넷(IoT)의 등장으로 인터넷에 연결된 다양한 기기들에 의해 대규모의 데이터가 생성됨에 따라 빅데이터 분석의 중요성이 증가하고 있다. 특히 실시간으로 생성되는 대규모의 IoT 스트리밍 센서 데이터를 분석하여 새로운 의미있는미래 예측을 통해 다양한 서비스를 제공하는 것이 필요하게되었다. 본 논문은 AWS를 활용하여 IoT 센서로부터 생성되는 스트리밍 데이터에 기반하여 실시간 실내 PM10 농도 예측 LSTM 모델을 제안한다. 또한 제안 모델에 따른 실시간 실내 PM10 농도 예측 서비스를 구축한다. 논문에 사용된 데이터는 PM10 IoT 센서로부터 24시간 동안 수집된 스트리밍 데이터이다. 이를 LSTM의 입력 데이터로 사용하기 위해 PM10 시계열 데이터로부터 30개의 연속된 값으로 이루어진 시퀀스 데이터로 변환한다. LSTM 모델은 바로 인접한 공간으로 이동해 가는 슬라이딩 윈도우 프로세스를 통하여 학습한다. 또한 모델의 성능 개선을 위해 24시간마다 수집한 스트리밍 데이터에 대해 점진적 학습 방법을 적용한다. 제안한 LSTM 모델의 성능을 평가하기 위해 선형회귀 모델 및 순환형 신경망(RNN) 모델과 비교한다. 실험 결과는 제안한 LSTM 예측 모델이 선형 회귀보다 700%, RNN 모델보다는 140% 성능 개선이 있음을 보여주었다.","Recently, the importance of big data analysis is increasing as a large amount of data is generated by various devices connected to the Internet with the advent of Internet of Things (IoT). Especially, it is necessary to analyze various large-scale IoT streaming sensor data generated in real time and provide various services through new meaningful prediction. This paper proposes a real-time indoor PM10 concentration prediction LSTM model based on streaming data generated from IoT sensor using AWS. We also construct a real-time indoor PM10 concentration prediction service based on the proposed model. Data used in the paper is streaming data collected from the PM10 IoT sensor for 24 hours. This time series data is converted into sequence data consisting of 30 consecutive values from time series data for use as input data of LSTM. The LSTM model is learned through a sliding window process of moving to the immediately adjacent dataset. In order to improve the performance of the model, incremental learning method is applied to the streaming data collected every 24 hours. The linear regression and recurrent neural networks (RNN) models are compared to evaluate the performance of LSTM model. Experimental results show that the proposed LSTM prediction model has 700% improvement over linear regression and 140% improvement over RNN model for its performance level."
비지도학습 데이터의 정확성 측정을 위한 클러스터별 분류 평가 예측 모델에 대한 연구,2018,"['Cluster Verification', 'RNN', 'LSTM', 'Classification', 'Unsupervised Learning', 'Clustering k-LSTM RNN']",,
Adaptive Tracking Control of Nonholonomic Mobile Manipulators Using Recurrent Neural Networks,2018,"['Adaptive control', 'backstepping', 'mobile manipulators', 'nonholonomic systems', 'recurrent neural networks']",,"The trajectory tracking problem is considered for a class of nonholonomic mobile manipulators in the presence of uncertainties and disturbances. First, under the assumption that the kinematic subsystem of mobile manipulator is capable of being transformed into the chained form and the dynamic subsystem of mobile manipulator is exactly known without considering external disturbances, a model-based controller is designed at the torque level using backstepping design technology. However, the model-based control may be inapplicable for practical applications, as the uncertainties and disturbances do exist in the dynamics of mobile manipulators inevitably. Thus, a Recurrent Neural Network (RNN) based control system is developed without requiring explicit knowledge of the system dynamics. The control system comprises a RNN identifier and a compensation controller, in which the RNN is utilized to identify the unknown dynamics on-line, and the compensation controller is presented to compensate the approximation error and external disturbances. The online adaptive laws of the control system are derived in the Lyapunov sense so that the stability of the system can be guaranteed. Finally, simulation results for a wheeled mobile manipulator are provided to show the good tracking performance and robustness of the proposed control method."
Multi-objective optimization of tapered tubes for crashworthiness by surrogate methodologies,2018,"['multi-objective optimization', 'energy absorption', 'crushing force', 'metamodel', 'tapered tube', 'indentation']",,"In this paper, the single and multi-objective optimization of thin-walled conical tubes with different types of indentations under axial impact has been investigated using surrogate models called metamodels. The geometry of tapered thin-walled tubes has been studied in order to achieve maximum specific energy absorption (SEA) and minimum peak crushing force (PCF). The height, radius, thickness, tapered angle of the tube, and the radius of indentation have been considered as design variables. Based on the design of experiments (DOE) method, the generated sample points are computed using the explicit finite element code. Different surrogate models including Kriging, Feed Forward Neural Network (FNN), Radial Basis Neural Network (RNN), and Response Surface Modelling (RSM) comprised to evaluate the appropriation of such models. The comparison study between surrogate models and the exploration of indentation shapes have been provided. The obtained results show that the RNN method has the minimum mean squared error (MSE) in training points compared to the other methods. Meanwhile, optimization based on surrogate models with lower values of MSE does not provide optimum results. The RNN method demonstrates a lower crashworthiness performance (with a lower value of 125.7% for SEA and a higher value of 56.8% for PCF) in comparison to RSM with an error order of 10<sup>-3</sup>. The SEA values can be increased by 17.6% and PCF values can be decreased by 24.63% by different types of indentation. In a specific geometry, higher SEA and lower PCF require triangular and circular shapes of indentation, respectively."
소형 무인 항공기 탐지를 위한 인공 신경망 기반 FMCW 레이다 시스템,2018,"['FMCW radar', 'Neural network', 'Detection', 'Signal processing', 'Machine learning']",,"Drone detection in FMCW radar system needs complex techniques because a drone beat frequency is highly dynamic and unpredictable. Therefore, the current static signal processing algorithms cannot show appropriate detection accuracy. With dynamic signal fluctuation and environmental clutters, it can fail to detect a drone or make false detection. It affects to the radar system integrity and safety. Constant false alarm rate (CFAR), one of famous static signal process algorithm is effective for static environment. But for drone detection, it shows low detection accuracy. In this paper, we suggest neural network based FMCW radar system for detecting a drone. We use recurrent neural network (RNN) because it is the effective neural network for signal processing. In our FMCW radar system, one transmitter emits FMCW signal and four-way fixed receivers detect reflected drone beat frequency. The coordinate of the drone can be calculated with four receivers information by triangulation. Therefore, RNN only learns and inferences reflected drone beat frequency. It helps higher learning and detection accuracy. With several drone flight experiments, RNN shows false detection rate and detection accuracy as 21.1% and 96.4%, respectively."
순환신경망을 이용한 도플러 채널 예측,2018,"['Doppler channel estimation', 'RNN channel prediction', 'SCFDE system']",,
신경망 기계번역의 작동 원리와 번역의 정확률,2018,"['neural network model', 'NMT', 'machine translation', 'deep learning', 'RNN model', 'translation quality', 'Chinese-Korean NMT', 'accuracy of translation', 'GNMT', 'N2MT', 'Baidu NMT', '신경망 모델', '기계 번역', '심층 학습', 'RNN 모델', '번역 품질', '중국어 한국어 NMT', '번역의 정확성']",,"In this paper, we examined the mechanism of operation of the neural network model(NMT), which is attracting attention in the field of machine translation research.  The NMT model consists of a process in which the computer reads the original text in sentence units and then generates the optimal translation corresponding to the sentence using the parameters obtained by deep learning. In the process of finding the optimal translation there is no need to construct separate translation dictionaries or translation patterns because the computer will learn on its own with parallel corpus. The NMT model is simpler and more general than the existing models.  For the quality of neural network machine translation, research has been conducted mainly on English. However, the research on the translation quality of non-English languages has received relatively little attention. Especially, it is not an exaggeration to say that the study on Chinese - Korean NMT quality has not yet been successful. In this paper, we analyzed how accurately the NMT translates Chinese - Korean sentences. The programs used to evaluate the accuracy of translation are GNMT, N2MT, Baidu NMT. For the translation evaluation, we selected 370 sentences from Chinese textbooks, academic papers, newspapers, TV scripts. And the machine translation results were evaluated in terms of word translation, phrase translation, and sentence translation. According to the result of the evaluation, the accuracy of N2MT and Baidu NMT is higer than that of GNMT for the basic colloquial expressions. However, in translating practical sentences such as newspaper reports, product manuals, web documents, business expressions, and TV conversations, the accuracy of GNMT and N2MT was higher than that of Baidu NMT.  In this paper, we also discussed how to use the NMT effectively. It is true that the NMT model has improved the translation quality. However, it still does not produce very high quality translations for the source texts. It will not be easy for machine translation to completely replace human translation in the future. But machine translation programs can be an excellent aid to human translation. The NMT model learns the translation data on its own and can predict the optimal translation. Therefore, if the NMT model is specialized for the purpose of the translator, it can be used as a convenient translation tool. Developing a translation model based on the neural network theory will contribute to enhancing the accuracy and efficiency of the translation."
LSTM 기반의 sequence-to-sequence 모델을 이용한 한글 자동 띄어쓰기,2018,"['인코딩-디코딩', 'sequence-to-sequence', 'LSTM', '순차정보 신경망', '자동 띄어쓰기', '드롭아웃', '계층 정 규화', 'encoding-decoding', 'LSTM', 'sequence-to-sequence neural network', 'auto spacing', 'drop-out', 'layer normalization']","자동 띄어쓰기 특성을 효과적으로 처리할 수 있는 LSTM(Long Short-Term Memory Neural Networks) 기반의 RNN 모 델을 제시하고 적용한 결과를 분석하였다. 문장이 길거나 일부 노이즈가 포함된 경우에 신경망 학습이 쉽지 않은 문제를 해결하기 위하여 입력 데이터 형식과 디코딩 데이터 형식을 정의하고, 신경망 학습에서 드롭아웃, 양방향 다층 LSTM 셀, 계층 정규화기법, 주목 기법(attention mechanism)을 적용하여 성능을 향상시키는 방법을 제안하였다. 학습 데이터로는 세종 말뭉치 자료를 사용하였으며, 학습 데이터가 부분적으로 불완전한 띄어쓰기가 포함되어 있었음에도 불구하고, 대량의 학습 데이터를 통해 한글 띄어쓰기에 대한 패턴이 의미 있게 학습되었다. 이것은 신경망에서 드롭아웃 기법을 통해 학습 모델의 오버피팅이 되지않도록 함으로써 노이즈에 강한 모델을 만들었기 때문이다. 실험결과로 LSTM sequence-to-sequence 모델이 재현율과 정확도를 함께 고려한 평가 점수인 F1 값이 0.94로 규칙 기반 방식과 딥러닝 GRU-CRF보다 더 높은 성능을 보였다.","We proposed a LSTM-based RNN model that can effectively perform the automatic spacing characteristics. For those long or noisy sentences which are known to be difficult to handle within Neural Network Learning, we defined a proper input data format and decoding data format, and added dropout, bidirectional multi-layer LSTM, layer normalization, and attention mechanism to improve the performance. Despite of the fact that Sejong corpus contains some spacing errors, a noise-robust learning model developed in this study with no overfitting through a dropout method helped training and returned meaningful results of Korean word spacing and its patterns. The experimental results showed that the performance of LSTM sequence-to-sequence model is 0.94 in F1-measure, which is better than the rule-based deep-learning method of GRU-CRF."
An accident diagnosis algorithm using long short-term memory,2018,"['Accident Diagnosis', 'Long Short-term Memory', 'Recurrent Neural Network', 'Softmax']",,"Accident diagnosis is one of the complex tasks for nuclear power plant (NPP) operators. In abnormal oremergency situations, the diagnostic activity of the NPP states is burdensome though necessary.Numerous computer-based methods and operator support systems have been suggested to address thisproblem. Among them, the recurrent neural network (RNN) has performed well at analyzing time seriesdata. This study proposes an algorithm for accident diagnosis using long short-term memory (LSTM),which is a kind of RNN, which improves the limitation for time reflection. The algorithm consists ofpreprocessing, the LSTM network, and postprocessing. In the LSTM-based algorithm, preprocessed inputvariables are calculated to output the accident diagnosis results. The outputs are also postprocessedusing softmax to determine the ranking of accident diagnosis results with probabilities. This algorithmwas trained using a compact nuclear simulator for several accidents: a loss of coolant accident, a steamgenerator tube rupture, and a main steam line break. The trained algorithm was also tested to demonstratethe feasibility of diagnosing NPP accidents."
명령 실행 모니터링과 딥 러닝을 이용한 파워셸 기반 악성코드 탐지 방법,2018,"['PowerShell', 'malware', 'execution monitoring', 'deep learning']","파워셸은 닷넷 프레임워크를 기반에 둔, 커맨드 라인 셸이자 스크립트 언어로, 그 자체가 가진 다양한 기능 외에도 윈도우 운영체제 기본 탑재, 코드 은닉 및 지속의 수월함, 다양한 모의 침투 프레임워크 등 공격 도구로서 여러 이점을 가지고 있다. 이에 따라 파워셸을 이용하는 악성코드가 급증하고 있으나 기존의 악성코드 탐지 기법으로 대응하기에는 한계가 존재한다. 이에 본 논문에서는 파워셸에서 실행되는 명령들을 관찰할 수 있는 개선된 모니터링 기법과, Convolutional Neural Network(CNN)을 이용해 명령에서 특징을 추출하고 실행 순서에 따라 Recurrent Neural Network(RNN)에 전달하여 악성 여부를 판단하는 딥 러닝 기반의 분류 모델을 제안한다. 악성코드 공유 사이트에서 수집한 파워셸 기반 악성코드 1,916개와 난독화 탐지 연구에서 공개한 정상 스크립트 38,148개를 이용하여 제안한 모델을 5-fold 교차 검증으로 테스트한 결과, 약 97%의 True Positive Rate(TPR)와 1%의 False Positive Rate(FPR)로 모델이 악성코드를 효과적으로 탐지함을 보인다.","PowerShell is command line shell and scripting language, built on the .NET framework, and it has several advantages as an attack tool, including built-in support for Windows, easy code concealment and persistence, and various pen-test frameworks. Accordingly, malwares using PowerShell are increasing rapidly, however, there is a limit to cope with the conventional malware detection technique. In this paper, we propose an improved monitoring method to observe commands executed in the PowerShell and a deep learning based malware classification model that extract features from commands using Convolutional Neural Network(CNN) and send them to Recurrent Neural Network(RNN) according to the order of execution. As a result of testing the proposed model with 5-fold cross validation using 1,916 PowerShell-based malwares collected at malware sharing site and 38,148 benign scripts disclosed by an obfuscation detection study, it shows that the model effectively detects malwares with about 97% True Positive Rate(TPR) and 1% False Positive Rate(FPR)."
Synthesis of Expressive Talking Heads from Speech with Recurrent Neural Network,2018,"['Talking heads', 'Recurrent neural network', 'Acoustic features', 'Facial features']",,"The talking head (TH) indicates an utterance face animation generated based on text and voice input. In this paper, we propose the generation method of TH with facial expression and intonation by speech input only. The problem of generating TH from speech can be regarded as a regression problem from the acoustic feature sequence to the facial code sequence which is a low dimensional vector representation that can efficiently encode and decode a face image. This regression was modeled by bidirectional RNN and trained by using SAVEE database of the front utterance face animation database as training data. The proposed method is able to generate TH with facial expression and intonation TH by using acoustic features such as MFCC, dynamic elements of MFCC, energy, and F0. According to the experiments, the configuration of the BLSTM layer of the first and second layers of bidirectional RNN was able to predict the face code best. For the evaluation, a questionnaire survey was conducted for 62 persons who watched TH animations, generated by the proposed method and the previous method. As a result, 77% of the respondents answered that the proposed method generated TH, which matches well with the speech."
숫자 기호화를 통한 신경기계번역 성능 향상,2018,"['Neural Machine Translation', 'Number Translation', 'Mistranslation', 'Symbolization', 'Model Optimizatio', '신경 기계 번역', '숫자 번역', '오번역', '기호화', '모델 최적화']","기계 학습의 발전은 인간만이 할 수 있었던 섬세한 작업들을 기계가 할 수 있도록 이끌었고, 이에 따라 많은 기업체들은 기계 학습 기반의 번역기를 출시하였다. 현재 상용화된 번역기들은 우수한 성능을 보이지만 숫자 번역에서 문제가 발생하는 것을 발견했다. 번역기들은 번역할 문장에 큰 숫자가 있을 경우 종종 숫자를 잘못 번역하며, 같은 문장에서 숫자만 바꿔 번역할 때 문장의 구조를 완전히 바꾸어 번역하기도 한다. 이러한 문제점은 오번역의 가능성을 높이기 때문에 해결해야 될 사안으로 여겨진다. 본 논문에서는 Bidirectional RNN (Recurrent Neural Network), LSTM (Long Short Term Memory networks), Attention mechanism을 적용한 Neural Machine Translation 모델을 사용하여 데이터 클렌징, 사전 크기 변경을 통한 모델 최적화를 진행하였고, 최적화된 모델에 숫자 기호화 알고리즘을 적용하여 상기 문제점을 해결하는 번역 시스템을 구현하였다. 본 논문은 데이터 클렌징 방법과 사전 크기 변경, 그리고 숫자 기호화 알고리즘에 대해 서술하였으며, BLEU score (Bilingual Evaluation Understudy score) 를 이용하여 각 모델의 성능을 비교하였다.","The development of machine learning has enabled machines to perform delicate tasks that only humans could do, and thus many companies have introduced machine learning based translators. Existing translators have good performances but they have problems in number translation. The translators often mistranslate numbers when the input sentence includes a large number. Furthermore, the output sentence structure completely changes even if only one number in the input sentence changes. In this paper, first, we optimized a neural machine translation model architecture that uses bidirectional RNN, LSTM, and the attention mechanism through data cleansing and changing the dictionary size. Then, we implemented a number-processing algorithm specialized in number translation and applied it to the neural machine translation model to solve the problems above. The paper includes the data cleansing method, an optimal dictionary size and the number-processing algorithm, as well as experiment results for translation performance based on the BLEU score."
Political Opinion Mining from Article Comments using Deep Learning,2018,"['recurrent neural network', 'opinion mining', 'semantic analysis']",,"Policy polls, which investigate the degree of support that the policy　has for policy implementation, play an important role in making decisions. As the number of Internet users increases, the public is actively commenting on their policy news stories.　Current policy polls tend to rely heavily on phone and offline surveys. Collecting and analyzing policy articles is useful in policy surveys.　In this study, we propose a method of analyzing comments using deep learning technology showing outstanding performance in various fields. In particular, we designed various models based on the recurrent neural network (RNN) which is suitable for sequential data and compared the performance with the support vector machine (SVM), which is a traditional machine learning model. For all test sets, the SVM model show an accuracy of 0.73 and the RNN model have an accuracy of 0.83."
전력선통신 시스템을 위한 딥 러닝 기반 전력량 예측 기법,2018,"['PLC', 'Deep Learning', 'RNN', 'LSTM', 'Demand Forecast']",,"Recently, energy issues such as massive blackout due to increase in power consumption have been emerged, and it is necessary to improve the accuracy of prediction of power consumption as a solution for these problems. In this study, we investigate the difference between the actual power consumption and the predicted power consumption through the deep learning- based power consumption forecasting experiment, and the possibility of adjusting the power reserve ratio. In this paper, the prediction of the power consumption based on the deep learning can be used as a basis to reduce the power reserve ratio so as not to excessively produce extra power. The deep learning method used in this paper uses a learning model of long-short-term-memory (LSTM) structure that processes time series data. In the computer simulation, the generated power consumption data was learned, and the power consumption was predicted based on the learned model. We calculate the error between the actual and predicted power consumption amount, resulting in an error rate of 21.37%. Considering the recent power reserve ratio of 45.9%, it is possible to reduce the reserve ratio by 20% when applying the power consumption prediction algorithm proposed in this study."
콜센터 인입 콜량 예측을 위한 시계열 모델 비교 분석,2018,"['call center', 'call arrival forecasting', 'wfm', 'ARIMA', 'ARIMAX', 'LSTM-RNN', 'regression', 'TBATS', 'STL']",,"The critical decision-making task of the call center manager is to determine the appropriate number of agents who can respond to the call with minimal cost. To do this, it is necessary to predict the exact amount of incoming calls. However, there are not many studies on this at home and abroad. In actual call center, simple calculation method based on experience and intuition of the person in charge is still mainly used. In this study, we investigate various techniques and cases to predict call volume and develop and verify optimized models. We develop the call prediction model by using decomposition model, ARIMA model, regression model and artificial neural network based model, and fitting of optimized prediction model by using real call center data and verify its effectiveness."
Generative Adversarial Networks를 이용한 Face Morphing 기법 연구,2018,"['대립쌍 기계학습', '얼굴합성', '합성곱 신경망', '비지도 학습', 'Generative adversarial network', 'face morphing', 'DCGAN', 'dCNN', 'unsupervised learning']",,"Recently, with the explosive development of computing power, various methods such as RNN and CNN have been proposed under the name of Deep Learning, which solve many problems of Computer Vision have. The Generative Adversarial Network, released in 2014, showed that the problem of computer vision can be sufficiently solved in unsupervised learning, and the generation domain can also be studied using learned generators. GAN is being developed in various forms in combination with various models. Machine learning has difficulty in collecting data. If it is too large, it is difficult to refine the effective data set by removing the noise. If it is too small, the small difference becomes too big noise, and learning is not easy. In this paper, we apply a deep CNN model for extracting facial region in image frame to GAN model as a preprocessing filter, and propose a method to produce composite images of various facial expressions by stably learning with limited collection data of two persons."
양방향 LSTM 순환신경망 기반 주가예측모델,2018,"['Bidirectional', 'Deep learning', 'LSTM', 'Long Short-Term Memory', 'Prediction', 'Recurrent Neural Network(RNN)', 'Stock Price']","본 논문에서는 시계열 데이터인 주가의 변동 패턴을 학습하고, 주가 가격을 예측하기 적합한 주가 예측 딥러닝 모델을 제시하고 평가하였다. 일반신경망에 시계열 개념이 추가되어 은닉계층에 이전 정보를 기억시킬 수 있는 순환신경망이 시계열 데이터인 주가 예측 모델로 적합하다. 순환신경망에서 나타나는 기울기 소멸문제를 해결하며, 장기의존성을 유지하기 위하여, 순환신경망의 내부에 작은 메모리를 가진 LSTM을 사용한다. 또한, 순환신경망의 시계열 데이터의 직전 패턴 기반으로만 학습하는 경향을 보이는 한계를 해결하기 위하여, 데이터의 흐름의 역방향에 은닉계층이 추가되는 양방향 LSTM 순환신경망을 이용하여 주가예측 모델을 구현하였다. 실험에서는 제시된 주가 예측 모델에 텐서플로우를 이용하여 주가와 거래량을 입력값으로 학습을 하였다. 주가예측의 성능을 평가하기 위해서, 실제 주가와 예측된 주가 간의 평균 제곱근 오차를 구하였다. 실험결과로는 단방향 LSTM 순환신경망보다, 양방향 LSTM 순환신경망을 이용한 주가예측 모델이 더 작은 오차가 발생하여 주가 예측 정확성이 향상되었다.","In this paper, we proposed and evaluated the time series deep learning prediction model for learning fluctuation pattern of stock price. Recurrent neural networks, which can store previous information in the hidden layer, are suitable for the stock price prediction model, which is time series data. In order to maintain the long - term dependency by solving the gradient vanish problem in the recurrent neural network, we use LSTM with small memory inside the recurrent neural network. Furthermore, we proposed the stock price prediction model using bidirectional LSTM recurrent neural network in which the hidden layer is added in the reverse direction of the data flow for solving the limitation of the tendency of learning only based on the immediately preceding pattern of the recurrent neural network. In this experiment, we used the Tensorflow to learn the proposed stock price prediction model with stock price and trading volume input. In order to evaluate the performance of the stock price prediction, the mean square root error between the real stock price and the predicted stock price was obtained. As a result, the stock price prediction model using bidirectional LSTM recurrent neural network has improved prediction accuracy compared with unidirectional LSTM recurrent neural network."
순환신경망을 이용한 뜰개의 관측 데이터 보정,2018,"['데이터 보정', '순환신경망', '기계학습', '예측', '뜰개', 'Data Correction', 'RNN', 'Machine Learning', 'Prediction', 'Drifter']","해양 뜰개는 해수면을 떠다니며 해양 기상 등을 관측하는 장비로, 뜰개를 통해 관측한 데이터는 해양 기상 예측, 유류유출 예측 등의 상황에서 활용된다. 관측 데이터는 관측 시에 오측(error data) 또는 결측(missing data)이 발생할 수 있으며, 오측 또는 결측된 데이터가 포함 될 경우, 데이터를 사용하는 모델들의 정확도가 떨어질 수 있다. 본 논문에서는 데이터 보정을 위한 방법으로 순환신경망을 이용한 데이터 보정 모델을 제안한다. 2015년 7개, 2016년 8개의 뜰개를 통해 수집한 해양 데이터를 이용한 보정 실험 결과와 보정 결과를 검증하기 위한 뜰개 이동 예측 실험을 설명하며, 실험 결과, 데이터 보정을 통해 13.9%의 데이터가 보정되었으며, 이동 예측 모델의 성능이 1.4% 향상되는 것을 보였다.","The ocean drifter is a device for observing the ocean weather by floating off the sea surface. The data observed through the drifter is utilized in the ocean weather prediction and oil spill. Observed data may contain incorrect or missing data at the time of observation, and accuracy may be lowered when we use the data. In this paper, we propose a data correction model using recurrent neural networks. We corrected data collected from 7 drifters in 2015 and 8 drifters in 2016, and conducted experiments of drifter moving prediction to reflect the correction results. Experimental results showed that observed data are corrected by 13.9% and improved the performance of the prediction model by 1.4%."
Prediction of water level in a tidal river using a deep-learning based LSTM model,2018,"['Tidal river', 'Deep learning', 'lead time', 'Jamsu bridge', 'LSTM model', '감조하천', '딥러닝', '선행시간', '잠수교', 'LSTM 모형']","본 연구는 물리적 수리·수문모형의 적용이 제한적인 감조하천에서의 수위예측을 목적으로 하고 있으며, 이를 위해 한강 잠수교를 대상으로 딥러닝 오픈소스 소프트웨어 라이브러리인 TensorFlow를 활용하여 LSTM 모형을 구성하고 2011년부터 2017년까지의 10분 단위의 잠수교 수위, 팔당 댐 방류량과 한강하구 강화대교지점의 예측조위 자료를 이용하여 모형학습(2011~2016) 및 수위예측(2017)을 수행하였다. 모형 매개변수는 민감도 분석을 통해 은닉층의 개수는 6개, 학습속도는 0.01, 학습횟수는 3000번로 결정하였으며, 모형 학습 시 학습정보의 시간적 양을 결정하는 중요한 매개변수인 시퀀스길이는 1시간, 3시간, 6시간으로 변화시키며 모의하였다. 최종적으로 선행시간에 따른 모의 예측능력을 평가하기 위해 LSTM 모형의 예측 선행시간을 6개(1 ~ 24시간)로 구분하여 실측수위와 예측수위와의 비교·분석을 수행한 결과, LSTM 모형의 최적의 성능을 내 는 결과는 시퀀스길이를 1시간으로 하였을 때로 분석되었으며, 특히 선행시간 1시간에 대한 예측정확도는 RMSE는 0.065 m, NSE는 0.99로 실 측수위에 매우 근접한 예측 결과를 나타내었다. 또한 시퀀스길이에 상관없이 선행시간이 길어질수록 모형의 예측 정확도는 2017년 전기간에 걸쳐 평균적으로 RMSE 0.08 m에서 0.28 m로 오차가 증가하였으며, NSE는 0.99에서 0.74로 감소하였다.","Discharge or water level predictions at tidally affected river reaches are currently still a great challenge in hydrological practices. This research aims to predict water level of the tide dominated site, Jamsu bridge in the Han River downstream. Physics-based hydrodynamic approaches are sometimes not applicable for water level prediction in such a tidal river due to uncertainty sources like rainfall forecasting data. In this study, TensorFlow deep learning framework was used to build a deep neural network based LSTM model and its applications. The LSTM model was trained based on 3 data sets having 10-min temporal resolution: Paldang dam release, Jamsu bridge water level, predicted tidal level for 6 years (2011~2016) and then predict the water level time series given the six lead times: 1, 3, 6, 9, 12, 24 hours. The optimal hyper-parameters of LSTM model were set up as follows: 6 hidden layers number, 0.01 learning rate, 3000 iterations. In addition, we changed the key parameter of LSTM model, sequence length, ranging from 1 to 6 hours to test its affect to prediction results. The LSTM model with the 1 hr sequence length led to the best performing prediction results for the all cases. In particular, it resulted in very accurate prediction: RMSE (0.065 cm) and NSE (0.99) for the 1 hr lead time prediction case. However, as the lead time became longer, the RMSE increased from 0.08 m (1 hr lead time) to 0.28 m (24 hrs lead time) and the NSE decreased from 0.99 (1 hr lead time) to 0.74 (24 hrs lead time), respectively."
LSTM-based Anomaly Detection on Big Data for Smart Factory Monitoring,2018,"['Long Short-Term Memory (LSTM)', '이상탐지', 'SCADA', 'Anomaly Detection']",,"This article presents machine learning based approach on Big data to analyzing time series data for anomaly detection in such industrial complex system. Long Short-Term Memory (LSTM) network have been demonstrated to be improved version of RNN and have become a useful aid for many tasks. This LSTM based model learn the higher level temporal features as well as temporal pattern, then such predictor is used to prediction stage to estimate future data. The prediction error is the difference between predicted output made by predictor and actual in-coming values. An error-distribution estimation model is built using a Gaussian distribution to calculate the anomaly in the score of the observation. In this manner, we move from the concept of a single anomaly to the idea of the collective anomaly. This work can assist the monitoring and management of Smart Factory in minimizing failure and improving manufacturing quality."
인공지능을 이용한 과일 가격 예측 모델 연구,2018,"['인공지능', '기계학습', '딥러닝', '알고리즘', 'ML', 'AI', 'Deep Running', 'algorithm']","현재 우리가 사는 21세기에서 가장 핫한 이슈중 하나는 AI이다. 농경사회에서 산업혁명을 통해 육체노동의 자 동화를 이루었듯이 정보사회에서 SW혁명을 통해 지능정보사회가 도래햇다. Google ‘알파고’의 등장으로 인해 컴퓨터 가 스스로 학습하고 예측하는 machine learning (머신러닝) 사례를 보면서 이제 바둑의 세계 까지 인간이 컴퓨터를 이길 수 없는, 다시 말하면 컴퓨터가 인간을 뛰어넘는 시대가 왔다. 기계학습ML(machine learning)은 인공 지능 분야 로, 인공지능 컴퓨터가 인간을 뛰어넘는 시대가 도래했다. 기계학습ML(machine learning)은 인공지능의 분야로, 인공지능 컴퓨터가 혼자 학습 하도록 알고리즘 기술 개발을 하는 뜻을 의미하는데, 많은 기업들이 머신러닝을 바둑의 세계까지 인간이 컴퓨터를 이길 수 없는, 다시 말하면 컴퓨 터가 인간을 뛰어넘는 시대가 왔다. 많은 기업들이 머신러닝을 용하는데 그 예로는 Facebook에서 이미지를 계속 학습 하여 나중에 그 이미지가 누구인지 알려주는 것도 머신러닝의 한 사례이다. 또한 구글의 데이터 센터 최적화를 위해서 효율적인 에너지 사용 모델 구축을 위해 neural network(신경망)을 활용하였다. 또 다른 사례로 마이크로소프트의 실 시간 통역 모델은 번역 학습을 통해 언어관련 인풋 데이터가 증가할수록 더 정교한 번역을 해주는 모델이다. 이처럼 많은 분야에 머신러닝이 점차 쓰이면서 이제 우리 21세기 사회에서 앞으로 나아가려면 AI산업으로 뛰어들어야 한다.","One of the hottest issues in our 21st century is AI. Just as the automation of manual labor has been achieved through the Industrial Revolution in the agricultural society, the intelligence information society has come through the SW Revolution in the information society. With the advent of Google 'Alpha Go', the computer has learned and predicted its own machine learning, and now the time has come for the computer to surpass the human, even to the world of Baduk, in other words, the computer. Machine learning ML (machine learning) is a field of artificial intelligence. Machine learning ML (machine learning) is a field of artificial intelligence, which means that AI technology is developed to allow the computer to learn by itself. The time has come when computers are beyond human beings. Many companies use machine learning, for example, to keep learning images on Facebook, and then telling them who they are. We also used a neural network to build an efficient energy usage model for Google's data center optimization. As another example, Microsoft's real-time interpretation model is a more sophisticated translation model as the language-related input data increases through translation learning. As machine learning has been increasingly used in many fields, we have to jump into the AI industry to move forward in our 21st century society."
심층학습을 이용한 문서요약의 연구방법 분석,2018,"['Deep Neural Network', 'Text summarization', 'Deep Learning', 'Abstractive text summarization', 'Extractive text summarization']",,"In this study, we discuss the basic technology of Text Summarization based on the deep neural network for natural language processing(NLP). The text summarization task is divided into an extractive summary and an abstractive summary. The extractive summary is a method of extracting a summary of the words used in the input document in the output text, and the abstractive summary is a problem of understanding the input statement and generating a sentence of the same content. The abstractive sentence generation system is based on the encoder-decoder model with attention mechanism, and a selector that can select input sentence is added. The Copy network and Pointer network are the special mechanisms for selector. Such selector systems can make text summarization to be the hybrid form of abstractive and extractive summary. In the future, we expect that accuracy of text summarization will be improved by adding reinforcement learning method."
Recurrent Neural Network를 활용한 서비스 이벤트 관계 분석에 관한 연구,2018,"['Event Correlation Analysis', 'IT Service', 'Long Short Term Memory', 'Recurrent Neural Network', 'Root Cause Analysis']",,"Enterprises need to monitor systems for reliable IT service operations to quickly detect and respond to events affecting the service, thereby preventing failures. Events in non-critical systems can be seen as a precursor to critical system incidents. Therefore, event relationship analysis in the operation of IT services can proactively recognize and prevent faults by identifying non-critical events and their relationships with incidents.This study used the Recurrent Neural Network and Long Short Term Memory techniques to create a model to analyze event relationships in a system and to verify which models are suitable for analyzing event relationships. Verification has shown that both models are capable of analyzing event relationships and that RNN models are more suitable than LSTM models. Based on the pattern of events occurring, this model is expected to support the prediction of the next occurrence of events and help identify the root cause of incidents to help prevent failures and improve the quality of IT services."
Deep Neural Network Models to Recommend Product Repurchase at the Right Time,2018,"['Purchase Timing', 'Recommender', 'Multilayer Perceptron', 'Recurrent Neural Network', 'Retail Business', 'Product Repurchase', 'Promotion System']",,"Despite of increasing studies for product recommendation, the recommendation of product repurchase timing has not yet been studied actively. This study aims to propose deep neural network models usingsimple purchase history data to predict the repurchase timing of each customer and compare performances of the models from the perspective of prediction quality, including expected ROI of promotion, variability of precision and recall, and diversity of target selection for promotion. As an experiment result, a recurrent neural network (RNN) model showed higher promotion ROI and the smaller variability compared to MLP and other models. The proposed model can be used to develop a CRM system that can offer SMS or app-based promotionsto the customer at the right time. This model can also be used to increase sales for product repurchase businesses by balancing the level of ordersas well as inducing repurchases by customers."
Deep Neural Network Models to Recommend Product Repurchase at the Right Time : A Case Study for Grocery Stores,2018,"['Purchase Timing', 'Recommender', 'Multilayer Perceptron', 'Recurrent Neural Network', 'Retail Business', 'Product Repurchase', 'Promotion System']",,"Despite of increasing studies for product recommendation, the recommendation of product repurchase timing has not yet been studied actively. This study aims to propose deep neural network models usingsimple purchase history data to predict the repurchase timing of each customer and compare performances of the models from the perspective of prediction quality, including expected ROI of promotion, variability of precision and recall, and diversity of target selection for promotion. As an experiment result, a recurrent neural network (RNN) model showed higher promotion ROI and the smaller variability compared to MLP and other models. The proposed model can be used to develop a CRM system that can offer SMS or app-based promotionsto the customer at the right time. This model can also be used to increase sales for product repurchase businesses by balancing the level of ordersas well as inducing repurchases by customers."
Deep Neural Network Models to Recommend Product Repurchase at the Right Time : A Case Study for Grocery Stores,2018,"['Purchase Timing', 'Recommender', 'Multilayer Perceptron', 'Recurrent Neural Network', 'Retail Business', 'Product Repurchase', 'Promotion System']",,"Despite of increasing studies for product recommendation, the recommendation of product repurchase timing has not yet been studied actively. This study aims to propose deep neural network models usingsimple purchase history data to predict the repurchase timing of each customer and compare performances of the models from the perspective of prediction quality, including expected ROI of promotion, variability of precision and recall, and diversity of target selection for promotion. As an experiment result, a recurrent neural network (RNN) model showed higher promotion ROI and the smaller variability compared to MLP and other models. The proposed model can be used to develop a CRM system that can offer SMS or app-based promotionsto the customer at the right time. This model can also be used to increase sales for product repurchase businesses by balancing the level of ordersas well as inducing repurchases by customers."
Predicting Bitcoin Market Trend with Deep Learning Models,2018,"['Bitcoin', 'Deep learning', 'Deep neural network', 'Neural network', 'Recurrent neural network', 'Social network service', 'Text mining']",,"As bitcoin attracts public attention as a new method of investment, the bitcoin market becomes a field of research that should be technically analyzed. Since bitcoin market is very uncertain, time series associated with bitcoin prices are complex, nonstationary and chaotic. In this paper, we attempt to predict bitcoin market trend using deep neural network (DNN) and four types of recurrent neural networks (RNNs). Our data set consists of fourteen input variables related to the bitcoin prices recorded daily from September 1, 2013 to August 31, 2017. Thirteen input variables are related to bitcoin prices, which are date, market price, high price, low price and closing price, and eight technical indicators derived from bitcoin prices. The other is keyword feature value obtained through text mining for social network services (SNS) data.Empirical study shows that DNN outperforms four RNNs in terms of specificity, precision and accuracy. Bidirectional RNN outperforms the other four deep learning models in terms of sensitivity. As a whole, DNN works quite well compared with RNNs."
Predicting Bitcoin Market Trend with Deep Learning Models,2018,"['Bitcoin', 'Deep learning', 'Deep neural network', 'Neural network', 'Recurrent neural network', 'Social network service', 'Text mining']",,"As bitcoin attracts public attention as a new method of investment, the bitcoin market becomes a field of research that should be technically analyzed. Since bitcoin market is very uncertain, time series associated with bitcoin prices are complex, nonstationary and chaotic. In this paper, we attempt to predict bitcoin market trend using deep neural network (DNN) and four types of recurrent neural networks (RNNs). Our data set consists of fourteen input variables related to the bitcoin prices recorded daily from September 1, 2013 to August 31, 2017. Thirteen input variables are related to bitcoin prices, which are date, market price, high price, low price and closing price, and eight technical indicators derived from bitcoin prices. The other is keyword feature value obtained through text mining for social network services (SNS) data. Empirical study shows that DNN outperforms four RNNs in terms of specificity, precision and accuracy. Bidirectional RNN outperforms the other four deep learning models in terms of sensitivity. As a whole, DNN works quite well compared with RNNs."
