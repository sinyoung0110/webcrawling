title,date,keywords,abstract,multilingual_abstract
엣지에 민감한 합성곱 신경망를 이용한 뇌 네트워크 분해 기법,2018,[],국문 초록 정보 없음,"Brain networks consist of nodes, which is anatomically defined brain regions, and edges, which connects a pair of brain regions. The diffusion-weighted MR images and the advances in tractography provides a human brain networks, that is strongly associated with the cognitive functions. Analysis of local functional segregation or modular organization of the brain network implies that brain regions nearby dedicated a certain specific cognitive function. However, it is not well known that a certain sub-network has a role of building blocks of the brain networks. In this short paper, using a edge-specific convolutional neural network, we tried to extract such a building blocks."
< 구두-B-03 > 합성곱신경망을 이용한 국산 침엽수재의 자동수종식별,2018,[],"본 연구에서는 딥러닝 방법 중에 하나인 합성곱신경망 (Convolution neural network, CNN)을 이용하여 전문가 없이도 빠르고 정확한 목재수종식별이 가능한 자동목재수종식별 시스템을 개발하였다. CNN 은 이미지 고유의 대표 특징을 추출하고 올바르게 분류하는 용도로 사용될 수 있다. 보통 CNN을 이용한 분류 작업의 성능은 기존의 자동목재수종식별 시스템에 비해 분류 성능이 높은 것으로 알려져 있다.스마트폰 카메라를 이용하여 총 다섯 가지 수종(편백, 삼나무, 잣나무, 소나무, 낙엽송)의 시편에서 횡단면의 이미지를 획득하였다. 획득된 이미지에서 수종별로 3000개 이상의 이미지를 무작위로 추출하여 75%는 훈련용, 25%는 모델의 검증에 사용하였다.본 연구에서는 CNN 모델 중 LeNet과 VGGNet을 변형한 딥러닝 모델을 자동목재수종식별 시스템에 적용하였다. LeNet 모델은 2개의 히든레이어(CONV > ACT > POOL)와 2개의 Dense 레이어로 구성되어 있으며, 히든레이어의 수를 증가시켜 LeNet2, LeNet3 모델을 만들었다. MiniVGGNet은 기존의 VGGNet에서 2개의 히든레이어(CONV > ACT > BN > CONV > ACT > BN > POOL > DROP)만 남기고 이 후에 Dense > ACT > BN > DROP > Dense > ACT으로 마무리되는 축소모델이다. MiniVGGNet2와 MiniVGGNet3 모델은 MiniVGGNet의 히든레이어의 숫자를 증가시켜 만든 모델이다. 최적화 알고리즘으로는 Stochastic Gradient Decent(SGD)를 사용하였으며, Learning rate, batch size, epoch의 수, 입력 이미지의 크기에 변화를 주면서 가장 높은 분류 정확도를 보이는 조건을 탐색하였다.상기한 모델 중에서 LeNet3 모델이 가장 높은 식별률(99.3%)을 보였다. 본 연구에서 개발된 자동목재 수종식별 시스템은 빠르고 정확하며 생성된 인자의 크기도 작아서 스마트폰과 같은 휴대용 장치에 설치하여 사용할 수 있음 알 수 있었다.",다국어 초록 정보 없음
다중 센서 데이터 분석을 위한 설명 가능한 합성곱신경망 모델,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
경차 분류를 위한 상관적인 다중 해상도 합성곱신경망,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
완전 합성곱 신경망을 활용한 자동 포트홀 탐지 기술의 개발 및 평가,2018,"['포트홀', '도로노면 파손', '의미론적 분할', '심층신경망', '인공지능', '완전 합성곱 신경망', 'Pothole', 'Road surface damage', 'Semantic segmentation', 'Deep neural network', 'AI', 'Fully convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
효과적인 입력변수 패턴 학습을 위한 시계열 그래프 기반합성곱 신경망 모형: 주식시장 예측에의 응용,2018,"['기술적 분석가', '딥러닝', '분류기', '주가지수 등락 예측', '합성곱 신경망', 'Classifier', 'Convolutional Neural Network', 'Deep Learning', 'Stock Price Fluctuation Prediction', 'Technical Analyst']","지난 10여 년간 딥러닝(Deep Learning)은 다양한 기계학습 알고리즘 중에서 많은 주목을 받아 왔다. 특히 이미지를 인식하고 분류하는데 효과적인 알고리즘으로 알려져 있는 합성곱 신경망(Convolutional Neural Network, CNN)은 여러 분야의 분류 및 예측 문제에 널리 응용되고 있다. 본 연구에서는 기계학습 연구에서 가장 어려운예측 문제 중 하나인 주식시장 예측에 합성곱 신경망을 적용하고자 한다. 구체적으로 본 연구에서는 그래프를입력값으로 사용하여 주식시장의 방향(상승 또는 하락)을 예측하는 이진분류기로써 합성곱 신경망을 적용하였다. 이는 그래프를 보고 주가지수가 오를 것인지 내릴 것인지에 대해 경향을 예측하는 이른바 기술적 분석가를모방하는 기계학습 알고리즘을 개발하는 과제라 할 수 있다. 본 연구는 크게 다음의 네 단계로 수행된다. 첫 번째 단계에서는 데이터 세트를 5일 단위로 나눈다. 두 번째 단계에서는 5일 단위로 나눈 데이터에 대하여 그래프를 만든다. 세 번째 단계에서는 이전 단계에서 생성된 그래프를 사용하여 학습용과 검증용 데이터 세트를 나누고 합성곱 신경망 분류기를 학습시킨다. 네 번째 단계에서는 검증용 데이터 세트를 사용하여 다른 분류 모형들과 성과를 비교한다. 제안한 모델의 유효성을 검증하기 위해 2009년 1월부터 2017년 2월까지의 약 8년간의KOSPI200 데이터 2,026건의 실험 데이터를 사용하였다. 실험 데이터 세트는 CCI, 모멘텀, ROC 등 한국 주식시장에서 사용하는 대표적인 기술지표 12개로 구성되었다. 결과적으로 실험 데이터 세트에 합성곱 신경망 알고리즘을 적용하였을 때 로지스틱회귀모형, 단일계층신경망, SVM과 비교하여 제안모형인 CNN이 통계적으로 유의한 수준의 예측 정확도를 나타냈다.","Over the past decade, deep learning has been in spotlight among various machine learning algorithms. In particular, CNN(Convolutional Neural Network), which is known as the effective solution for recognizing and classifying images or voices, has been popularly applied to classification and prediction problems. In this study, we investigate the way to apply CNN in business problem solving. Specifically, this study propose to apply CNN to stock market prediction, one of the most challenging tasks in the machine learning research. As mentioned, CNN has strength in interpreting images. Thus, the model proposed in this study adopts CNN as the binary classifier that predicts stock market direction (upward or downward) by using time series graphs as its inputs. That is, our proposal is to build a machine learning algorithm that mimics an experts called 'technical analysts' who examine the graph of past price movement, and predict future financial price movements.Our proposed model named 'CNN-FG(Convolutional Neural Network using Fluctuation Graph)' consists of five steps. In the first step, it divides the dataset into the intervals of 5 days. And then, it creates time series graphs for the divided dataset in step 2. The size of the image in which the graph is drawn is 40 (pixels) × 40 (pixels), and the graph of each independent variable was drawn using different colors.In step 3, the model converts the images into the matrices. Each image is converted into the combination of three matrices in order to express the value of the color using R(red), G(green), and B(blue) scale. In the next step, it splits the dataset of the graph images into training and validation datasets. We used 80% of the total dataset as the training dataset, and the remaining 20% as the validation dataset. And then, CNN classifiers are trained using the images of training dataset in the final step. Regarding the parameters of CNN-FG, we adopted two convolution filters (5 × 5 × 6 and 5 × 5 × 9) in the convolution layer. In the pooling layer, 2 × 2 max pooling filter was used. The numbers of the nodes in two hidden layers were set to, respectively, 900 and 32, and the number of the nodes in the output layer was set to 2(one is for the prediction of upward trend, and the other one is for downward trend). Activation functions for the convolution layer and the hidden layer were set to ReLU(Rectified Linear Unit), and one for the output layer set to Softmax function.To validate our model - CNN-FG, we applied it to the prediction of KOSPI200 for 2,026 days in eight years (from 2009 to 2016). To match the proportions of the two groups in the independent variable (i.e. tomorrow's stock market movement), we selected 1,950 samples by applying random sampling. Finally, we built the training dataset using 80% of the total dataset (1,560 samples), and the validation dataset using 20% (390 samples). The dependent variables of the experimental dataset included twelve technical indicators popularly been used in the previous studies. They include Stochastic %K, Stochastic %D, Momentum, ROC(rate of change), LW %R(Larry William's %R), A/D oscillator(accumulation/distribution oscillator), OSCP(price oscillator), CCI(commodity channel index), and so on. To confirm the superiority of CNN-FG, we compared its prediction accuracy with the ones of other classification models. Experimental results showed that CNN-FG outperforms LOGIT(logistic regression), ANN(artificial neural network), and SVM(support vector machine) with the statistical significance. These empirical results imply that converting time series business data into graphs and building CNN-based classification models using these graphs can be effective from the perspective of prediction accuracy. Thus, this paper sheds a light on how to apply deep learning techniques to the domain of business problem solving."
합성곱 신경망을 사용한 화물차의 차종분류,2018,"['Vehicle Classification', 'Truck Cargo Box', 'Image Classification', 'Convolutional Neural Network', 'Machine Learning', '차종분류', '화물차 적재함', '영상분류', '합성곱 신경망', '기계학습']","본 논문에서는 화물차 차종을 분류하기 위해서 특징추출단계 없이 입력영상으로부터 차종분류결과를 얻을 수 있는 합성곱 신경망을 사용한 분류방법을 제안한다. 차량의 위에서 촬영된 영상을 입력으로 사용하고 입력영상에 적합한 합성곱 신경망의 구조를 설계한다. 차종과 화물칸의 형태에 따라 차종을 자동 분류하기 위한 학습데이터를 생성하고 지도학습의 형태로 학습시키기 위해 분류된 영상과 올바른 출력결과를 제시하여 신경망의 가중치를 학습시킨다. 실제 영상을 입력하여 합성곱 신경망의 출력을 계산하였고 실제 차종과의 비교를 통해 분류 성능을 평가 하였다. 실험결과 화물의 차종과 적재함의 형태에 따라 90%이상의 정확도로 영상을 분류할 수 있었고, 적재불량 검사의 사전 분류에 활용될 수 있다.","This paper proposes a classification method using the Convolutional Neural Network(CNN) which can obtain the type of trucks from the input image without the feature extraction step. To automatically classify vehicle images according to the type of truck cargo box, the top view images of the vehicle are used as input image and we design the structure of the CNN suitable for the input images. Learning images and correct output results is generated and the weights of neural network are obtained through the learning process. The actual image is input to the CNN and the output of the CNN is calculated. The classification performance is evaluated through comparison CNN output with actual vehicle types. Experimental results show that vehicle images could be classified with more than 90 percent accuracy according to the type of cargo box and this method can be used for pre-classification for inspecting loading defect."
합성곱 신경망을 이용한 대장내시경 영상 분류,2018,"['Polyp', '용종', 'Adenomacarcinoma', 'Convolution', 'Neural Network', '선암', '합성곱', '신경망']","대장암 검사의 가장 효과적인 진단 방법은 대장내시경 검사이다. 내시경 검사는 소형 카메라를 통하여 확인되는 대장 내부 영상을 의료인의 육안으로 대장에 돌출한 용종 또는 암으로 성장할 것으로 예측되어지는 용종을 찾아내는방법이다. 사람의 육안을 통하여 검사가 이루어지는 내시경 검사는 컴퓨터의 영상 학습 기술을 통하여 의료인에게도움을 제공할 수 있다. 본 연구에서는 내시경 검사를 보조하기 위하여 정상적인 대장, 선종성 용종, 그리고 선암세 종류로 이루어진 영상 데이터를 분류한다. 제안하는 영상 분류 방법은 심층학습 기반의 영상 분류 기술 중 하나인 합성곱 신경망(Convolutional Neural Networks) 방법을 통한 내시경 영상 분류 방법을 제안한다. 본 연구에서 구성한 합성곱 신경망은 총 34개의 합성곱 계층(Convolution Layer)과 하나의 완전연결계층(Fully Connected Layer)을 이룬다. 실험 결과 총 410개의 테스트 데이터에 대해서 94.39%의 인식률을 보였다.","The most effective method of diagnosing colorectal cancer is colonoscopy. colonoscopy is the process of finding protruding or cancerous polyps in a colon via inspection through an internal video of the colon taken with a small camera. The colonoscopy which is usually diagnosed by human visually, can be improved by adapting computer vision learning technology. In this study, classify the images in normal colon, adenomatous polyps, and adenocarcinoma to aid colonoscopy diagnosing.The use of convolutional neural network, one of the image classification techniques based on deep learning, is suggested as the way to classify the colonoscopy images. The convolutional neural network is constructed with 34 convolutional layers and 1 fully-connected layer. The result of this experiment showed a 94.39% accuracy over 410 tests."
합성곱 신경망을 이용한 농산물 기사 감성 분석,2018,"['감성분석', '오피니언 마이닝', '텍스트 마이닝', '농산물가격', '합성곱 신경망', 'emotional analysis', 'opinion mining', 'text mining', 'agricultural price', 'convolutional neural networks']","본 논문에서는 농산물 가격의 등락을 기준으로 감성사전을 구축하여 농산물 관련 온라인 뉴스의 긍정/부정을 분류하는 방법을 제안한다. 이를 위해 비정형 텍스트문서를 문장 단위로 분할한 뒤 분석내용과 연관 없거나 가격 등락에 상관없이 빈번하게 언급된 단어들을 불용어로 처리한다. 형태소 분석을 진행한 후 비지도 학습 기반으로 키워드를 추출하여 합성곱 신경망(Convolutional Neural Networks, CNN)을 이용해 긍정/부정 분류를 수행하였다. 그 결과 빈도기반 키워드를 이용한 긍정/부정 분류보다 비지도 학습기반 키워드 추출과 인공신경망의 일종인 합성곱 신경망을 이용했을 때 약 20% 이상 분류 정확도가 향상되었다.","In this paper, we propose a method for sentiment analysis of online news by constructing emotional dictionary base on the fluctuation in prices of various agriculture products. The collected unstructured text data were segmented into sentences and the frequently mentioned words which were not related to price fluctuation were removed as stop words. After the morphological analysis, the keyword was extracted based on the unsupervised learning and the experiments were conducted based on the proposed model using the convolutional neural network (CNN). Consequently, about 20% improvement in accuracy was observed when CNN was used than the word frequency based method."
자동 얼굴인식을 위한 얼굴 지역 영역 기반 다중 심층 합성곱 신경망 시스템,2018,"['얼굴인식', '심층 합성곱 신경망', '심층 지역 특징', '가중치 결합', '얼굴 지역 영역', '조인트 베이시안', 'face recognition', 'deep convolutional neural network', 'deep local features', 'weight combination', 'faciallocal region', 'Joint Bayesian']","본 논문에서는 얼굴인식 성능 향상을 위해 얼굴 지역 영역 영상들로 학습된 다중개의 심층 합성곱 신경망(Deep Convolutional Neural Network)으로부터 추출된 심층 지역 특징들(Deep local features)을 가중치를 부여하여 결합하는 방법 을 제안한다. 제안 방법에서는 지역 영역 집합으로 학습된 다중개의 심층 합성곱 신경망으로부터 추출된 심층 지역 특징들 과 해당 지역 영역의 중요도를 나타내는 가중치들을 결합한 특징표현인 ‘가중치 결합 심층 지역 특징’을 형성한다. 일반화 얼굴인식 성능을 극대화하기 위해, 검증 데이터 집합(validation set)을 사용하여 지역 영역에 해당하는 가중치들을 계산하고 가중치 집합(weight set)을 형성한다. 가중치 결합 심층 지역 특징은 조인트 베이시안(Joint Bayesian) 유사도 학습방법과 최근접 이웃 분류기(Nearest Neighbor classifier)에 적용되어 테스트 얼굴영상의 신원(identity)을 분류하는데 활용된다. 제 안 방법은 얼굴영상의 자세, 표정, 조명 변화에 강인하고 기존 최신 방법들과 비교하여 얼굴인식 성능을 향상시킬 수 있음이 체계적인 실험을 통해 검증되었다.","In this paper, we propose a novel face recognition(FR) method that takes advantage of combining weighted deep local features extracted from multiple Deep Convolutional Neural Networks(DCNNs) learned with a set of facial local regions. In the proposed method, the so-called weighed deep local features are generated from multiple DCNNs each trained with a particular face local region and the corresponding weight represents the importance of local region in terms of improving FR performance. Our weighted deep local features are applied to Joint Bayesian metric learning in conjunction with Nearest Neighbor(NN) Classifier for the purpose of FR. Systematic and comparative experiments show that our proposed method is robust to variations in pose, illumination, and expression. Also, experimental results demonstrate that our method is feasible for improving face recognition performance."
진동 신호 기반 합성곱 신경망을 이용한 다양한 하중 조건의 유성기어박스 고장 진단,2018,"['Planetary Gearbox(유성기어박스)', 'Artificial Intelligence(인공지능)', 'Convolutional Neural Network(합성곱 신경망)', 'Latent Feature Spaces(내부 피처 공간)', 'Varied Load Condition(하중 조건)']",국문 초록 정보 없음,"Since a planetary gearbox have been frequently adapted for rotational system, the fault diagnosis of planetary gearbox has been highly required. In this purpose, the physics-based approaches have been suggested but they have required enough domain knowledge which is time-consuming to achieve. Hence, there have been a lot of attempts based on datadriven approach, especially employing machine learning method to overcome the requirements of domain knowledge. Even though these attempts have shown excellent performance, there is too high randomness on designing the architecture of machine learning. In the same time, the physical explanation of process in machine learning have been required, since it is related with the reliability of result. In this research, the End-to-end One-Dimensional Convolutional Neural Network (EODCNN) is proposed for fault diagnosis of planetary gearbox. In the process of designing architecture, the physical properties are considered to optimized the diagnosis performance and the effects of physical properties are compared. Furthermore, the process of trained model is investigated to discover the physical meaning which bring the reliability on the performance of diagnosis model."
딥러닝을 위한 영역기반 합성곱 신경망에 의한 항공영상에서 건물탐지 평가,2018,"['Deep Learning', 'Region-based Convolutional Neural Network', 'Object Detection', 'Semantic Segmentation', '딥러닝', '역기반 합성곱 신경망', '객체탐지', '의미적 분할']","딥러닝은 인간의 학습 및 인지능력을 닮은 인공지능을 실현하기 위해 여러 분야에서 활용하고 있으며, 높은 사양 의 컴퓨팅 파워가 요구되고 연산 시간이 많이 소요되는 복잡한 구조의 인공신경망에 의한 딥러닝은 컴퓨터 사양이 향상됨에 따라 성능이 개선된 다양한 딥러닝 모델이 개발되고 있다. 본 논문의 주요 목적은 상의 딥러닝을 위한 합성곱 신경망 중에서 최근에 FAIR (Facebook AI Research)에서 개발한 Mask R-CNN을 이용하여 항공상에서 건물을 탐지하고 성능을 평가하는 것이다. Mask R-CNN은 역기반의 합성곱 신경망으로서 픽셀 정확도까지 객 체를 의미적으로 분할하기 위한 딥러닝 모델로서 성능이 가장 우수한 것으로 평가받고 있다. 딥러닝 모델의 성능은 신경망 구조뿐 아니라 학습 능력에 의해 결정된다. 이를 위해 본 논문에서는 모델의 학습에 이용한 상에 다양한 변화를 주어 학습 능력을 분석하으며, 딥러닝의 궁극적 목표인 범용화의 가능성을 평가하다. 향후 연구방안으 로는 상에만 의존하지 않고 다양한 공간정보 데이터를 복합적으로 딥러닝 모델의 학습에 이용하여 딥러닝의 신 뢰성과 범용화가 향상될 것으로 판단된다.","DL (Deep Learning) is getting popular in various fields to implement artificial intelligence that resembles human learning and cognition. DL based on complicate structure of the ANN (Artificial Neural Network) requires computing power and computation cost. Variety of DL models with improved performance have been developed with powerful computer specification. The main purpose of this paper is to detect buildings from aerial images and evaluate performance of Mask R-CNN (Region-based Convolutional Neural Network) developed by FAIR (Facebook AI Research) team recently. Mask R-CNN is a R-CNN that is evaluated to be one of the best ANN models in terms of performance for semantic segmentation with pixel-level accuracy. The performance of the DL models is determined by training ability as well as architecture of the ANN. In this paper, we characteristics of the Mask R-CNN with various types of the images and evaluate possibility of the generalization which is the ultimate goal of the DL. As for future study, it is expected that reliability and generalization of DL will be improved by using a variety of spatial information data for training of the DL models."
빗줄기 방향과 강도를 고려한 심층 합성곱 신경망 기반의 빗줄기 제거 기법,2018,"['Rain Removal', 'Residual Networks', 'Deep Convolutional Neural Networks', 'Sparse Coding']","최근 인공지능 기술의 발달로 무인자동차, 무인드론 및 자율운항선박시스템 등이 개발되고 있다. 그러나 컴퓨터 비전 기반의 보행자 검출, 영상분할 같은 기법은 기상 환경에 상당한 영향을 받는다. 특히 비가 내리는 상황에서 영상을 획득할 때 캡처된 영상에서 빗줄기 패턴이 형성되고 이러한 빗줄기 패턴은 컴퓨터 비전 알고리즘에서 사용되는 특징 추출에 부정적인 영향을 줄 수 있다. 따라서 본 논문에서는 빗줄기의 강도와 방향을 고려한 심층 합성곱 신경망 기법을 제안하고자 한다. 특히 빗줄기 강도와 방향을 구별 짓기 위한 심층 합성곱 신경망과 빗줄기 타입 별 빗줄기 제거를 위한 잔차 네크워크 즉, 두 종류의 서브 네트워크를 학습해서 빗줄기를 제거하고자 한다. 제안한 기법을 적용할 때, 기존의 방법보다 빗줄기 제거와 디테일 보존 성능 측면에서 더 나은 결과를 얻을 수 있었으며 정량적 화질 평가에서도 우위를 달성할 수 있었다.","Recently, autonomous cars, autonomous drones, and self-driving ship systems are being developed, thanks to the development of artificial intelligence technologies However, computer vision algorithms such as pedestrian detections and image segmentations, are significantly affected by weather conditions. When capturing images in a rainy day, rain streaks are formed in the captured images, thereby having negative effects on feature extractors used in comaputer vision algorithms. Therefore, this paper proposes the deep convolution neural networks that consider the strength and orientation of rain streaks. More specifically, in this paper, two types of sub-networks are learned for rain streaks removal. One is to detect the strength and orientation of rain streaks and the other is to remove rain streaks via residual networks, which are trained optimally to each type of rain streaks. Experimental results show that the proposed method is more effective in removing rain streaks and preserving details than the conventional methods. Moreover, quantitative image quality assessments also show that the performance of the proposed method is superior to the conventional methods."
합성곱 신경망 기반의 무인이동체 trail navigation,2018,"['Trail Navigation(트레일 네비게이션)', 'Machine Learning(기계 학습)', 'Convolutional Neural Network(합성곱 신경망)', 'Vision-Based control(영상 기반 제어)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망과 데이터 강화를 이용한 플랜트 기자재 형상 인식,2018,"['Convolutional Neural Network(합성곱 신경망)', 'Data Augmentation(데이터 강화)', 'Plant Equipment(플랜트기자재)', 'Shape Recognition(형상 인식)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반의 위상 불변에 강건한 GIS PD 고장 진단 모델 개발,2018,"['Gas Insulated Switchgear(가스절연개폐장치)', 'Partial Discharge(부분방전)', 'Ultra High Frequency(초고주파)', 'Phase Resolved Pulse Sequence(PRPS)', 'Convolutional Neural Network(합성곱신경망)']",국문 초록 정보 없음,"Gas Insulated Switchgear(GIS) is electrical equipment for stable transformation or transmission. Since GIS serves to transmit or disconnect high voltage currents, it is very important to maintain stable internal isolation condition. Previous researches have been conducted to detect Partial Discharge(PD) by Ultra High Frequency(UHF)sensors, focusing on partial discharge among the causes that deteriorate internal isolation condition. In this study, PD diagnostic method was developed using Phase Resolved Pulse Sequence(PRPS) image, which is an image of the UHF sensor signal of GIS used in the actual field. For actual data, there is a phase shift phenomenon of PRPS images due to measurement or synchronization errors, which makes it difficult to diagnose them. To solve this problem, a Convolutional Neural Network(CNN) based Deep learning architecture robust to phase shift is proposed and it showed high diagnosis accuracy compared to previous algorithm."
합성곱 신경망을 통한 강건한 온라인 객체 추적,2018,"['visual tracking', 'convolutional neural network', 'on-line tracking', 'probability map', 'color histogram']","본 논문에서는 객체를 추적하기 위해 합성곱 신경망 모델을 이용한 온라인 추적 기법을 제안한다. 오프라인에 모델을 학습시키기 위해서는 많은 수의 훈련 샘플이 필요하다. 이러한 문제를 해결하기 위해, 학습되지 않은 모델을 사용하고, 실험 영상으로부터 직접 훈련 샘플을 수집하여 모델을 갱신한다. 기존의 방법들은 많은 훈련 샘플을 획득하여 모델의 학습에 사용하였지만, 본 논문에서는 적은 수의 훈련 샘플만으로도 객체의 추적이 가능함을 증명한다. 또한 컬러 정보를 활용하여 새로운 손실 함수를 정의하였고 이로부터 잘못 수집된 훈련 샘플로 인해 모델이 잘못된 방향으로 학습되는 문제를 방지한다. 실험을 통해 4가지 비교 방법과 동등하거나 개선된 추적 성능을 보임을 증명하였다.",다국어 초록 정보 없음
합성곱 신경망의 필터 민감도 분석을 통한 진단 성능 평가,2018,"['Convolutional Neural Network (합성곱 신경망)', 'Weight Sensitivity (가중치 민감도)', 'Fault Diagnosis (고장 진단)']",국문 초록 정보 없음,다국어 초록 정보 없음
잔차 블록 기반의 깊은 합성곱 신경망을 통한 단일 영상 초해상도 복원,2018,[],"신경망은 깊어질수록 gradient vanishing/exploding과 같은 네트워크가 불안정해지는 문제가 발생 한다. 잔차 블록을 이용하여 이러한 문제를 해결 할 수 있다. 본 논문에서는 영상 인식 분야에서 휼륭한 성능을 보여준 잔차 블록 기반의 깊은 합성곱 신경망을 통한 단일 영상 초해상도 복원 기법을 제안 한다. 제안한 알고리듬은 EDSR에 사용된 잔차 블록을 다양한 크기의 합성곱 연산을 통해 영상의 특징들을 다르게 분석하도록 수정하고 VDSR과 비숫한 수준의 복잡도로 구성하여 향상된 성능을 얻었다. 실험 결과, VDSR에 비해 PSNR이 최대 0.1㏈까지 증가했다.",다국어 초록 정보 없음
합성곱 신경망(Convolution Neural Network)를 이용한 악성코드 탐지 방안 연구,2018,[],"새롭게 변형되는 대규모 악성코드들을 신속하게 탐지하기 위하여 인공지능 딥러닝을 이용한 악성코드 탐지 기법을 제안한다. 대용량의 고차원 악성코드를 저차원의 이미지로 변환하고, 딥러닝 합성곱신경망(Convolution Neural Network)을 통해 이미지의 악성코드 패턴을 학습하고 분류하였다. 본 논문에서는 악성코드 분류 모델의 성능을 검증하기 위하여 악성코드 종류별 분류 실험과 악성코드와 정상코드 분류 실험을 실시하였고 각각 97.6%, 87%의 정확도로 악성코드를 구별해 내었다. 본 논문에서 제안한 악성코드 탐지 모델은 차원 축소를 통해 10,868개(200GB)의 대규모 데이터에 대하여 10분 이내의 학습시간이 소요되어 새로운 악성코드 학습 및 대용량 악성코드 탐지를 신속하게 처리 가능함을 보였다.",다국어 초록 정보 없음
1-Bit 합성곱 신경망을 위한 정확도 향상 기법,2018,"['XNOR Neural Network', '1-Bit Neural Network', 'Quantized Neural Network', 'Convolutional Neural Network', 'Neural Network']",본 논문에서는 기존 1-Bit 합성곱 신경망의 성능 하락에 대한 분석과 이를 완화하기 위한 방안을 제시한다. 기존의 연구는첫 번째 층과 마지막 층만 32-Bit 연산을 적용하고 나머지 연산은 1-Bit 연산을 적용한 것과 달리 본 논문에서는 두 번째 층도 32-Bit로 연산한다. 또한 입력과 가중치를 이진화하고 1-Bit 연산을 적용한 후에는 비선형 활성화 함수를 제거할 수 있음을 제시한다. 본 논문에서 제시한 방법을 검증하기 위해 차량 번호판 검출을 위한 객체 검출 신경망을 실험하였다. 기존의방법으로 학습한 결과보다 정확도가 74%에서 96.1%로 상승하였다.,"In this paper, we analyze the performance degradation of previous 1-Bit convolutional neural network method andintroduce ways to mitigate it. Previous work applies 32-Bit operation to first and last layers. But our method applies32-Bit operation to second layer too. We also show that nonlinear activation function can be removed after binarizinginputs and weights. In order to verify the method proposed in this paper, we experiment the object detection neuralnetwork for korean license plate detection. Our method results in 96.1% accuracy, but the existing method results in 74%accuracy."
다양한 합성곱 신경망 접근법을 이용한 잡초 이미지 분류,2018,[],국문 초록 정보 없음,"In this paper, we present a multimodal approach for weeds classification. We apply the transfer learning to classify on Convolutional Neural Networks(CNN) VGG16, Inception-Resnet, and Mobilenet separately. Then, we combine probabilities returned from each model, and start voting by scoring classes. We choose a class that has the highest score to conclude the final classification. We experiment on own weeds dataset and achieve 95.927% accuracy after voting on fusion classification."
쇼크 필터와 합성곱 신경망 기반의 균일 모션 디블러링 기법,2018,"['Deblurring', 'Convolutional Neural Network (CNN)', 'Shock filter', 'Uniform Motion blur', 'Blind deconvolution']",Cho 등의 균일 모션 블러 제거 알고리듬은 영상 내 외곽선 영역을 선명하게 복원하지 못한다는 문제점이 있다. 이러한 문제점을 극복하기 위해 본 논문에서는 한 장의 정지 영상에서 발생하는 블러 (Blur)현상을 블러된 계단형 신호를 뚜렷한 외곽선으로 복원해주는 쇼크 필터 (Shock filter)와 영상에서 특징을 추출하여 학습하는 합성곱 신경망 (Convolutional Neural Network: CNN)을 이용하여 선명한 영상을 복원하고 이 영상으로부터 균일 모션 (Uniform motion) 블러를 측정하여 영상 내 블러 현상을 제거하는 효과적인 알고리듬을 제안하고자 한다. 제안된 알고리듬은 쇼크 필터와 합성곱 신경망을 이용하여 선명한 영상을 복원함으로써 기존 알고리듬의 단점을 개선하였다. 실험 결과를 통해 제안하는 알고리듬이 기존 알고리듬에 비해 객관적 및 주관적인 평가에서 우수한 복원 성능을 나타냄을 확인하였다.,다국어 초록 정보 없음
샘플 수준의 합성곱 신경망을 이용한 저널베어링 회전체 시스템 진단과 시각화 방법을 이용한 분석,2018,"['Sample-level Convolutional Neural Network(샘플 수준의 합성곱 신경망)', 'Journal Bearing Rotor System (저널베어링 회전체 시스템)', 'Health Diagnosis(건전성 진단)']",국문 초록 정보 없음,다국어 초록 정보 없음
PRPS 데이터 기반 오픈 셋-합성곱 신경망을 이용한 가스 절연 개폐기 부분 방전 발생 감지 및 진단,2018,"['Diagnosis (진단)', 'Detection (감지)', 'Partial Discharge (부분 방전)', 'Gas Insulated Switchgear (가스 절연 개폐기)', 'Open Set (오픈 셋)', 'Convolutional Neural Network (합성곱 신경망)', 'Phase Resolved Pulse Sequence (상분해 펄스 시퀀스)']",국문 초록 정보 없음,다국어 초록 정보 없음
비전 점유센서를 위한 합성곱 신경망 기반 사람 인식,2018,"['occupancy sensor', 'camera', 'CNN', 'people recognition', 'tracking']",대부분의 건물 등에 설치된 점유센서는 PIR(pyroelectric infra-red)이 주로 활용되고 있다. 하지만 PIR은 온도 변화를 감지하는 기능 때문에 정지된 사람을 감지할 수 없는 단점이 있다. 최근 이 단점을 극복하기 위해 카메라 비전 센서의 연구가 진행되고 있다. 비전 센서는 객체 트랙킹을 통해 정지된 사람을 검출한다. 그러나 객체 트랙킹은 트랙커 표류가 발생하는 문제점이 있다. 본 논문에서는 정지 트랙커가 사람을 포함하는지의 여부를 판단하기 위하여 합성곱 신경망 기반 사람 인식 기법을 제안한다. 실험에서는 카메라로 획득한 영상에 제안 방법을 적용한 결과 약 88%의 정확도로 사람과 비사람이 분류가 되어 실제 점유센서에 활용이 가능하다는 것을 증명하였다.,다국어 초록 정보 없음
합성곱 신경망을 이용한 3차원 CAD 모델의 형상 인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망에 대한 도메인 불변 사람 분류기를 위한 연관성 학습,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 위내시경 이미지 분류에서 전이학습의 효용성 평가,2018,"['Gastroscope', 'Convolutional Neual Network', 'Transfer learning', 'Resnet', 'Inception', 'VGGnet']",국문 초록 정보 없음,"Stomach cancer is the most diagnosed cancer in Korea. When gastric cancer is detected early, the 5-year survival rate is as high as 90%. Gastroscopy is a very useful method for early diagnosis. But the false negative rate of gastric cancer in the gastroscopy was 4.6~25.8% due to the subjective judgment of the physician. Recently, the image classification performance of the image recognition field has been advanced by the convolutional neural network. Convolutional neural networks perform well when diverse and sufficient amounts of data are supported. However, medical data is not easy to access and it is difficult to gather enough high-quality data that includes expert annotations. So This paper evaluates the efficacy of transfer learning in gastroscopy classification and diagnosis. We obtained 787 endoscopic images of gastric endoscopy at Gil Medical Center, Gachon University. The number of normal images was 200, and the number of abnormal images was 587. The image size was reconstructed and normalized. In the case of the ResNet50 structure, the classification accuracy before and after applying the transfer learning was improved from 0.9 to 0.947, and the AUC was also improved from 0.94 to 0.98. In the case of the InceptionV3 structure, the classification accuracy before and after applying the transfer learning was improved from 0.862 to 0.924, and the AUC was also improved from 0.89 to 0.97. In the case of the VGG16 structure, the classification accuracy before and after applying the transfer learning was improved from 0.87 to 0.938, and the AUC was also improved from 0.89 to 0.98. The difference in the performance of the CNN model before and after transfer learning was statistically significant when confirmed by T-test (p < 0.05). As a result, transfer learning is judged to be an effective method of medical data that is difficult to collect good quality data."
합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델,2018,[],국문 초록 정보 없음,"As urban population increases, research on urban environmental noise is getting more attention. In this study, we classify the abnormal noise occurring in traffic situation by using a deep learning algorithm which shows high performance in recent environmental noise classification studies. Specifically, we classify the four classes of tire skidding sounds, car crash sounds, car horn sounds, and normal sounds using convolutional neural networks. In addition, we add three environmental noises, including rain, wind and crowd noises, to our training data so that the classification model is more robust in real traffic situation with environmental noises. Experimental results show that the proposed traffic sound classification model achieves better performance than the existing algorithms, particularly under harsh conditions with environmental noises."
합성곱 신경망 기법을 이용한 팀원 역할 배분,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 뉴스 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 내부망보안 관제 시스템 제안,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 활용한 악성 이미지 탐지 모듈 제안,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 이용한 아토피 피부염 진단 도움 웹 페이지 개발,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망을 위한 커널별 일정하지 않은 정밀도를 지원하는 연산 블록 구조 설계,2018,[],국문 초록 정보 없음,"We propose a new hardware structure of arithmetic computation that is able to support kernel-level non-uniform computation precision on a Convolutional Neural Network (CNN). Since existing CNN compression techniques invariably assume uniform computation precision over all kernels in each convolutional layer of CNN, this work enables to further explore the CNN compression models, so that the compressed model can be fitted into a resource-limited architecture while minimizing the loss of prediction accuracy. We have implemented our proposed design in Virtex-7 FPGA and found that our design supporting the non-uniform kernel-level precision achieves higher utilization of the hardware resource than that of the layer-level kernel precision while using the same total amount of bits required for representing all kernel weights."
합성곱 신경망을 이용한 스마트 토이의 음성명령 학습에 관한 연구,2018,"['AI', 'CNN', 'IoT', 'Smart toy', 'Voice command', 'Voice learning']",국문 초록 정보 없음,"Recently, as the IoT(Internet of Things) and AI(Artificial Intelligence) technologies have developed, smart toys that can understand and act on the language of human beings are being studied. In this paper, we study voice learning using CNN(Convolutional Neural Network) by applying artificial intelligence based voice secretary technology to smart toy. When a human voice command gives, Smart Toy recognizes human voice, converts it into text, analyzes the morpheme, and conducts tagging and voice learning. As a result of test for the simulator program implemented using Python, no malfunction occurred in a single command. And satisfactory results were obtained within the selected simulation condition range."
합성 곱 신경망을 이용한 원단 결점 검출 시스템,2018,[],국문 초록 정보 없음,"Measuring the quality of clothes and fabrics is an indispensable factor in the respect to the satisfactory of consumers and the profitability for the apparel companies. We propose a method to automatically detect the flaws in fabric, which is the main material of apparel products, without human involvement. In the absence of data on defect samples, synthetic abnormal data is generated using classical method. Using the synthesized data, we train convolutional neural network (CNN) to determine a given patch contains defects or not. The fabric is inspected whether or not it contains defects through trained CNN. In this paper, it is shown that deep learning can be applied to practical applications related to the clothing industry."
합성곱 신경망을 이용한 웨이퍼 맵 기반 불량 탐지,2018,"['Semiconductor Manufacturing', 'Wafer Map', 'EDS test', 'Convolutional Neural Network', 'Deep Learning']",국문 초록 정보 없음,"The Electrical die sorting (EDS) test is performed to discriminate defective wafers for the purpose of improving the yield of the wafers during the semiconductor manufacturing process, and wafer maps are generated as a result. Semiconductor manufacturing process and equipment engineers use the patterns of the wafer map based on their knowledge to judge the defective wafer and estimate the cause. We use convolutional neural network which demonstrate good performance in the image classification. The convolutional neural network is used as a classification model of which the image of wafer map itself as input and whether the image is good or bad as output. While previous studies have used hand-crafted features for wafer map-based fault detection, the methodology used in this study is that the convolutional neural network learns the features useful for classification, it has the advantage of integrating knowledge. We show that the proposed classifier has better prediction accuracy than the conventional machine learning based techniques such as multilayer perceptron and random forest empirically by experiments on the data collected in the actual semiconductor manufacturing process."
순환 합성곱 신경망를 이용한다채널 뇌파 분석의 간질 발작 탐지,2018,"['recurrent CNN', 'deep learning', 'epileptic seizure detection', 'EEG', 'load balancin and simulation']","본 논문에서는 뇌파 신호를 이용하여 환자의 경련을 감지하는 순환 CNN (Convolutional Neural Networks)을 제안한다.제안 된 방법은 뇌파 신호의 스펙트럼 특성과 전극의 위치를 보존하기 위해 영상으로 데이터를 매핑하여 처리하였다. 스펙트럼 전처리 과정을 거친 후 CNN에 입력하고 공간 및 시간 특성을 웨이블릿 변환(wavelet transform)없이 추출하여 발작을검출하였다. 여기에 사용된 보스턴 매사추세츠 공과 대학 (Boston Massachusetts Institute of Technology, CHB-MIT) 아동병원의 데이터셋 결과는 시간당 0.85의 민감도와 90 %의 위양성 비율 (FPR)을 보였다.","In this paper, we propose recurrent CNN(Convolutional Neural Networks) for detecting seizures among patients usingEEG signals. In the proposed method, data were mapped by image to preserve the spectral characteristics of the EEGsignal and the position of the electrode. After the spectral preprocessing, we input it into CNN and extracted the spatialand temporal features without wavelet transform.Results from the Children's Hospital of Boston Massachusetts Institute of Technology (CHB-MIT) dataset showed asensitivity of 90% and a false positive rate (FPR) of 0.85 per hour."
축약 합성곱 신경망 특징 벡터를 이용한 유사 상표 검색 방법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
심층 합성곱 신경망 다단계 특징을 이용한 성별 인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
심층 합성곱 신경망 기반의 이미지 바코드의 은닉 데이터 검출,2018,[],국문 초록 정보 없음,"This paper presents a method of using pretrained deep convolutional neural networks to detect hidden data from the image barcode, which is generated based on two types of dithering matrixes. More details about how to collect two types of dot patterns, and then learn the deep convolutional neural networks is introduced for detections of hidden data from image barcodes. The proposed hidden data detection method can provide useful information including logo, images, speeches, or URLs from printed image barcodes for copyright protection, product advertisement, and voice message delivery."
ResNet-50 합성곱 신경망을 위한 고정 소수점 표현 방법,2018,['ASIC'],국문 초록 정보 없음,"Recently, the convolutional neural network shows high performance in many computer vision tasks. However, convolutional neural networks require enormous amount of operation, so it is difficult to adopt them in the embedded environments. To solve this problem, many studies are performed on the ASIC or FPGA implementation, where an efficient representation method is required. The fixed-point representation is adequate for the ASIC or FPGA implementation but causes a performance degradation. This paper proposes a separate optimization of representations for the convolutional layers and the batch normalization layers. With the proposed method, the required bit width for the convolutional layers is reduced from 16 bits to 10 bits for the ResNet-50 neural network. Since the computation amount of the convolutional layers occupies the most of the entire computation, the bit width reduction in the convolutional layers enables the efficient implementation of the convolutional neural networks."
심층 합성곱 신경망을 이용한 교통신호등 인식,2018,"['Traffic Light Recognition', 'Deep Convolutional Neural Network']",국문 초록 정보 없음,"The color of traffic light is sensitive to various illumination conditions. Especially it loses the hue information when oversaturation happens on the lighting area. This paper proposes a traffic light recognition method robust to these illumination variations. The method consists of two steps of traffic light detection and recognition. It just uses the intensity and saturation in the  first step of traffic light detection. It delays the use of hue information until it reaches to the second step of recognizing the signal of traffic light. We utilized a deep learning technique in the second step. We designed a deep convolutional neural network(DCNN) which is composed of three convolutional networks and two fully connected networks. 12 video clips were used to evaluate the performance of the proposed method. Experimental results show the performance of traffic light detection reporting the precision of 93.9%, the recall of 91.6%, and the recognition accuracy of 89.4%. Considering that the maximum distance between the camera and traffic lights is 70m, the results shows that the proposed method is effective."
심층 합성곱 신경망 기반 JND 모델을 이용한 인지 비디오 부호화,2018,[],본 논문에서는 사람의 인지 시각 특성 중 하나인 JND(Just Noticeable Difference)를 이용한 인지 비디오 부호화 기법을 제안한다. JND 기반 인지 부호화 방법은 사람의 인지 시각 특성을 이용해 시각적으로 인지가 잘 되지 않는 인지 신호를 제거함으로 부호화 효율을 높이는 방법이다. 제안된 방법은 기존 수학적 모델 기반의 JND 기법이 아닌 최근 각광 받고 있는 데이터 중심 (data-driven) 모델링 방법인 심층 신경망 기반 JND 모델 생성 기법을 제안한다. 제안된 심층 신경망 기반 JND 모델은 비디오 부호화 과정에서 입력 영상에 대한 전처리를 통해 입력 영상의 인지 중복(perceptual redundancy)를 제거하는 역할을 수행한다. 부호화 실험에서 제안된 방법은 동일하거나 유사한 인지화질을 유지한 상태에서 평균 16.86 %의 부호화 비트를 감소 시켰다.,다국어 초록 정보 없음
3차원 합성곱 신경망을 통한 축구 객체 모션 인식 기법,2018,[],국문 초록 정보 없음,"Recently, sports and ICT technology have been combined, enabling quantitative and objective analysis of sports and players. As a result, in the case of soccer game, quantitative analysis of competition and athletes is underway in various companies, but due to technical limitations, many data are still being generated based on the manual work of experts. In this paper, we propose an object motion recognition technique based on 3D CNN which is a basis for further automation of soccer analysis. As can be seen from the experimental results, it can be confirmed that the proposed technique not only has high speed performance but also satisfactory accuracy as compared with the existing technologies."
심층 합성곱 신경망 지도학습용 이미지 수집 및 사용자 협업 태깅 시스템,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
다중모달 합성곱 신경망을 사용한 유정 생산성 평가,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
실내 공간에서의 합성곱 신경망 기반 사람과 비사람의 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
증강현실 환경에서 합성곱 신경망 기반 6자유도 자세 추정 및 중앙 관리가 가능한 비콘 시스템 설계,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
순환 인셉션 합성곱 신경망을 이용한 초단기 다중 전력 수요 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
앙상블 기반 합성곱 신경망을 이용한 얼굴 표정 인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
열화상 비디오에서 합성곱 신경망 기반의 실시간 인간 탐지,2018,[],국문 초록 정보 없음,"In this paper, we have proposed a Convolution Neural Network based human classification technique that efficiently operates in real time. Background subtraction is done using improved Running Gaussian Average to get the initial background model. Background updating is implemented using selectivity updating and random selection of background pixel from every new frame. Morphology is applied to extract ROIs from each frame. For classification, CNN model is trained and tested with our own dataset. For incorporating the model with real-time application, we neglect the nodes from computational graph that have no weights and convert other weights to constants. With this trained CNN model, ROI is classified as human or non-human in real-time. The processing time depends on number of ROI present in the frame. For our testing data, average processing time is 25fps."
고해상도 영상을 위한 합성곱 신경망의 필터 크기에 대한 화질 비교,2018,[],국문 초록 정보 없음,"Convolution neural network (CNN) can learn the characteristics of images by training the network using different kinds of convolutional filters. In this paper, we present the experimental comparison of image qualities with respect to the sizes of filters in super-resolution convolution neural network(SRCNN)."
구조 인식 심층 합성곱 신경망 기반의 영상 잡음 제거,2018,"['image denoising', 'deep convolutional neural networks', 'feature extraction', 'image filtering']",국문 초록 정보 없음,"With the popularity of smartphones, most peoples have been using mobile cameras to capture photographs. However, due to insufficient amount of lights in a low lighting condition, unwanted noises can be generated during image acquisition. To remove the noise, a method of using deep convolutional neural networks is introduced. However, this method still lacks the ability to describe textures and edges, even though it has made significant progress in terms of visual quality performance. Therefore, in this paper, the HOG (Histogram of Oriented Gradients) images that contain information about edge orientations are used. More specifically, a method of learning deep convolutional neural networks is proposed by stacking noise and HOG images into an input tensor. Experiment results confirm that the proposed method not only can obtain excellent result in visual quality evaluations, compared to conventional methods, but also enable textures and edges to be improved visually."
머리 장착형 화면을 위한 합성곱 신경망을 활용한 근적외선 기반 시선 추적 방법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
깊이맵 생성 알고리즘의 합성곱 신경망 구현,2018,"['Depth map', 'CNN', 'Saliency map', 'Motion Hitsory Image', 'Ready-made depth map']",국문 초록 정보 없음,"Depth map has been utilized in a varity of fields. Recently research on generating depth map by artificial neural network (ANN) has gained much interest. This paper validates the feasibility of implementing the ready-made depth map generation by convolutional neural network (CNN). First, for a given image, a depth map is generated by the weighted average of a saliency map as well as a motion history image. Then CNN network is trained by test images and depth maps. The objective and subjective experiments are performed on the CNN and showed that the CNN can replace the ready-made depth generation method."
사전 클러스터링과 다중열 합성곱 신경망을 이용한 한글필기체 인식 연구,2018,[],국문 초록 정보 없음,"In the case of Hangul handwriting, unlike the form consisting of a single structure of alphabets or numbers, it is composed of a combination of a initial/medial/final consonants. So, the character similarity is very high in image data, and there is over 2000 characters. In this paper, we propose a method to improve the recognition performance by reducing the complexity of the problem of Hangeul handwriting recognition. We propose a structure that recognizes more than 2000 characters at the same level by grouping high similarity characters through pre-clustering and assigning a separate deep learning model to each cluster. Experimental results, we show about 65% recognition performance for 2350 characters that can be combined, and about 79% for commonly used 1052 characters."
진동 신호 및 합성곱 신경망을 이용한 공작기계 채터 진단,2018,"['Convolutional Neural Network', 'Machine Tools', 'Chatter', 'Fast Fourier Transform']",국문 초록 정보 없음,다국어 초록 정보 없음
해상 이미지 데이터와 합성곱 신경망을 활용한 유의파고 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
점유 센서를 위한 합성곱 신경망과 자기 조직화 지도를 활용한 온라인 사람 추적,2018,"['on-line tracking', 'convolutional neural network', 'self organizing map', 'occupancy sensor']",국문 초록 정보 없음,"Occupancy sensors installed in buildings and households turn off the light if the space is vacant. Currently PIR(pyroelectric infra-red) motion sensors have been utilized. Recently, the researches using camera sensors have been carried out in order to overcome the demerit of PIR that cannot detect stationary people. The detection of moving and stationary people is a main functionality of the occupancy sensors. In this paper, we propose an on-line human occupancy tracking method using convolutional neural network (CNN) and self-organizing map. It is well known that a large number of training samples are needed to train the model offline. To solve this problem, we use an untrained model and update the model by collecting training samples online directly from the test sequences. Using videos capurted from an overhead camera, experiments have validated that the proposed method effectively tracks human."
화소단위 유한상태기계와 심층 합성곱 인공-신경망을 이용한 버려진 객체 검출,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
단어와 자소 기반 합성곱 신경망을 이용한 문서 분류,2018,"['Document Classification', 'Convolutional Neural Network', 'Word Embedding', 'Character Embedding', 'Naive bayes', 'Logistic Regression']",국문 초록 정보 없음,"Documents classification aims to analyze keywords or contextual meanings from a given document and classify them into specific categories. In order to successfully perform document classification, it is necessary to accurately extract the word information included in a given document. However, there are many variations of Korean words depending on the types of postposition, rooting and ending. In the case of online documents, these variations become even more severe. Considering the characteristics of these Korean documents, in this paper we propose a document classification method using both word and character information. By using character information, it is possible to consider information that was difficult to express by word set such as typos and emoticons in the document classification process. This model, which combines the features of the whole sentence obtained from the word information and the local features obtained from the character information, experimentally confirmed that it has higher classification performance than the existing models using only word information."
기두부와 단 분리 시 조각의 식별을 위한 합성곱 신경망 구조 설계,2018,"['dynamic RCS', 'convolutional neural networks', 'radar target identification', 'warhead', 'debris']",국문 초록 정보 없음,"In this paper, we designed CNN(Convolutional Neural Network) structure to identify warhead and debris in boosting part separation phase. Through simulation, we determined variables of each layer constituting the CNN and designed CNN structure. Simulation were performed to classify four types of warhead with coning motion and six types of debris with tumbling motion through the CNN designed by the proposed method. Then we compared the performance of CNN with the well-known VGGNet. Simulation results show that the CNN structure optimized by the convolution filter, pooling method, and pooling size determined using the proposed method has equal classification performance or better classification performance than VGGNet for all SNR. In addition, the training time was improved approximately 22 times."
다양한 속도의 풍동 실험 결과 예측을 위한 합성곱 신경망,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
단백질 이차 구조 예측을 위한 합성곱 신경망의 구조,2018,[],국문 초록 정보 없음,"Deep learning has been actively studied for predicting protein secondary structure based only on the sequence information of the amino acids constituting the protein. In this paper, we compared the performances of the convolutional neural networks of various structures to predict the protein secondary structure. To investigate the optimal depth of the layer of neural network for the prediction of protein secondary structure, the performance according to the number of layers was investigated. We also applied the structure of GoogLeNet and ResNet which constitute building blocks of many image classification methods. These methods extract various features from input data, and smooth the gradient transmission in the learning process even using the deep layer. These architectures of convolutional neural networks were modified to suit the characteristics of protein data to improve performance."
다중 웨어러블 센서 기반의 사용자 행동 인식을 위한 효율적인 합성곱 순환 신경망,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
다중 웨어러블 센서 기반의 사용자 행동 인식을 위한 효율적인 합성곱 순환 신경망,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
실시간 손 제스처 인식을 위한 덴스넷 기반 이중흐름 3차원 합성곱 신경망 구조,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 및 완전연결 신경망을 이용한 원자력 사고예측 경보에 대한 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
인공신경망 연산에 최적화 된 Switched Capacitor 구조의 저전력 8-bit 합성곱 연산기,2018,"['Switched-Capacitor', 'Convolutional Neural Network', 'Deep Learning']",국문 초록 정보 없음,다국어 초록 정보 없음
신경망 기반의 유기된 물체 인식 방법,2018,"['deep learning', 'convolutional neural networks', 'difference image', 'abandoned object recognition', 'background estimation']","본 논문에서는 합성곱 신경망을 이용한 유기된 물체 인식 방법을 제안한다. 유기된 물체 인식 방법은 영상 내에서 유기 물체에 대한 영역을 먼저 검출하며 검출된 영역이 있을 경우 해당 영역에 합성곱 신경망을 적용하여 어떤 물체를 나타내는지인식하는 과정을 거친다. 실험은 쓰레기 무단투기를 검출하는 응용 시스템을 통해 진행되었다. 실험 결과, 유기 물체에 대한영역을 효율적으로 검출하는 것을 볼 수 있었다. 검출된 영역은 합성곱 신경망으로 들어가 쓰레기인지 아닌지 분류되는 과정을 거쳤다. 이를 위해 자체적으로 수집한 쓰레기 데이터와 오픈 데이터베이스로 합성곱 신경망을 학습시켰다. 학습 결과, 학습에 포함되지 않은 테스트셋에 대해 약 97%의 정확도를 달성하였다","This paper proposes a method of recognition abandoned objects using convolutional neural networks. The method firstdetects an area for an abandoned object in image and, if there is a detected area, applies convolutional neural networksto that area to recognize which object is represented. Experiments were conducted through an application system thatdetects illegal trash dumping. The experiments result showed the area of abandoned object was detected efficiently. Thedetected areas enter the input of convolutional neural networks and are classified into whether it is a trash or not. Todo this, I trained convolutional neural networks with my own trash dataset and open database. As a training result, Iachieved high accuracy for the test set not included in the training set."
심층신경망 기반 총채벌레 탐색에 관한 연구,2018,"['객체 탐색', '볼록총채벌레', '빠른 지역기반 객체 탐색', '심층신경망', '합성곱 신경망', 'Convolutinal network', 'deep learning', 'Faster R-CNN', 'object detection', 'Scirtothrips dorsalis Hood']","최근 감귤농업에서 주요해층으로 분류되는 미소 객체 (tiny object)인 볼록총채벌레 (Scirtothrips dorsalis Hood)의 탐색은 관심이 많고 어려운 작업으로 알려져 있다. 본 논문에서는 심층신경망을 이용하여 볼록총채벌레를 탐색 (detection)하고자 한다. 분석자료는 황색끈끈이트랩 이미지자료 (250×150mm, 5472×3648픽셀)이며 합성곱 신경망 (convolutional neural network, CNN)인 ResNet을 기반으로 하는 Faster R-CNN (faster regions with CNN) 탐색모형을 사용하였다. 이미지넷(ImageNet)을 사전 학습한 가중치를 사용하고 초모수 (hyperparameter)를 격자탐색법(grid search)으로 선택한 모형을 제안한다. 제안된 모형의 AUC (area under curve)는 0.91로 아주 좋은 결과를 보이는데, 제안된 모형으로 볼록총채벌레의 생태를 파악하여 보다 더 정밀한 방제가 이뤄질 수 있을 것으로 기대한다.","In this paper, we study on a detection of Scirtothrips dorsalis Hood, which is classified as a major insect in citrus farming. The detection is based on the deep neural networks, specifically the Faster R-CNN (faster regions with CNN) model based on CNN (convolutional neural network), with the yellow sticky trap image data (250×150mm, 5472×3648pixels). It was found that the model performance becomes unstable when the object is too small and rare. In order to solve this problem, we use pretrained weights to set the initial value of the model, as well as we select hyperparameters by grid search. Result shows that our proposed model has an high AUC (area under curve) value 0.91. We expect that it would be possible to know more precisely the lifespan of the Scirtothrips dorsalis Hood and to control them more precisely through our proposed model."
메모리 추가 신경망을 이용한 희소 악성코드 분류,2018,"['Malware Classification', 'Visualization', 'Memory Augmented Neural Network']","악성코드의 수가 가파르게 증가하면서 기업 및 공공기관, 금융기관, 병·의원 등을 타깃으로 한 사이버 공격 피해사례가 늘어나고 있다. 이러한 흐름에 따라 학계와 보안 업계에서는 악성코드 탐지를 위한 다양한 연구를 진행하고 있다. 최근 들어서는 딥러닝을 비롯해 머신러닝 기법을 적용하는 형태의 연구가 많이 진행되는 추세다. 이 중 합성곱 신경망(CNN: Convolutional Neural Network), ResNet 등을 이용한 악성코드 분류 연구의 경우에는 기존의 분류 방법에 비해 정확도가 크게 향상된 것을 확인할 수 있다. 그러나 타깃 공격의 특징 중 하나는 사용된 악성코드가 불특정 다수를 상대로 광범위하게 퍼뜨리는 형태가 아닌, 특정 대상을 타깃으로 한 맞춤형 악성코드라는 점이다. 이러한 유형의 악성코드는 그 수가 많지 않기 때문에 기존에 연구되어온 머신러닝이나 딥러닝 기법을 적용하기에 한계가 있다. 본 논문은 타깃형 악성코드와 같이 샘플의 양이 부족한 상황에서 악성코드를 분류하는 방법에 대해 다루고 있다. 메모리가 추가된 신경망(MANN: Memory Augmented Neural Networks) 모델을 이용하였고 각 그룹별 20개의 소량 데이터로 구성되어 있는 악성코드 데이터셋에 대해 최대 97%까지 정확도로 분류할 수있음을 확인하였다.","As the number of malicious code increases steeply, cyber attack victims targeting corporations, public institutions, financial institutions, hospitals are also increasing. Accordingly, academia and security industry are conducting various researches on malicious code detection. In recent years, there have been a lot of researches using machine learning techniques including deep learning. In the case of research using Convolutional Neural Network, ResNet, etc. for classification of malicious code, it can be confirmed that the performance improvement is higher than the existing classification method. However, one of the characteristics of the target attack is that it is custom malicious code that makes it operate only for a specific company, so it is not a form spreading widely to a large number of users. Since there are not many malicious codes of this kind, it is difficult to apply the previously studied machine learning or deep learning techniques. In this paper, we propose a method to classify malicious codes when the amount of samples is insufficient such as targeting type malicious code. As a result of the study, we confirmed that the accuracy of 97% can be achieved even with a small amount of data by applying the Memory Augmented Neural Networks model."
Optimization of convolutional neural network for prediction of chemotherapy,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
심층학습과 악성코드 분석 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 손 제스처 인식을 통한 3D 가상현실 게임,2018,"['손 제스처 인식', '딥러닝', '합성곱 신경망', 'DenseNet', '가상현실', '게임', 'Hand Gesture Recognition', 'Deep Learning', 'Convolutional Neural Network', 'Virtual Reality', 'Game']","가상 환경에서 몰입감을 높이고 자유로운 상호작용을 제공하기 위한 가장 자연스러운 방법은 사용자의 손을 이용한 제스처 인터페이스를 제공하는 것이다. 그러나 손 제스처 인식에 관한 기존의 연구들은 특화된 센서나 장비를 요구하거나 낮은 인식률을 보이는 단점이 있다. 본 논문은 손 제스처 입력을 위한 RGB 카메라 이외 별도 센서나 장비없이 손 제스처 인식이 가능한 3차원 DenseNet 합성곱 신경망 모델을 제안하고 이를 기반으로 한 가상현실 게임을 소개한다. 4개의 정적 손 제스처와 6개의 동적 손 제스처 인터페이스에 대해 실험한 결과 평균 50ms의 속도로 94.2%의 인식률을 보여 가상현실 게임의 실시간 사용자 인터페이스로 사용 가능함을 알 수 있었다. 본 연구의 결과는 게임 뿐 아니라 교육, 의료, 쇼핑 등 다양한 분야에서 손 제스처 인터페이스로 활용될 수 있다.","The most natural way to increase immersion and provide free interaction in a virtual environment is to provide a gesture interface using the user’s hand. However, most studies about hand gesture recognition require specialized sensors or equipment, or show low recognition rates. This paper proposes a three-dimensional DenseNet Convolutional Neural Network that enables recognition of hand gestures with no sensors or equipment other than an RGB camera for hand gesture input and introduces a virtual reality game based on it. Experimental results on 4 static hand gestures and 6 dynamic hand gestures showed that they could be used as real-time user interfaces for virtual reality games with an average recognition rate of 94.2% at 50ms. Results of this research can be used as a hand gesture interface not only for games but also for education, medicine, and shopping."
작성자 분석과 CNN을 적용한 소스 코드 작성자 식별 프레임워크,2018,"['작성자 식별', '작석자 분석', '합성곱 신경망', '기계학습', '코드 분석', 'Author Identification', 'Authorship Analysis', 'Convolutional Neural Network', 'Machine Learning', 'Code Analysis']","최근 인터넷 기술이 발전함에 따라 다양한 프로그램들이 만들어지고 있고 이에 따라 다양한 코드들이 많은 사람들을 통해 만들어진다. 이러한 측면을 이용하여 특정 작성자가 작성한 코드들 그대로 가져가 자신이 작성한 것처럼 보여주거나, 참고한 코드들에 대한 정확한 표기 없이 그대로 사용하여 이에 대한 보호가 점차 어려워지고 있다. 따라서 본 논문에서는 작성자 분석 이론과 합성곱 신경망 기반 자연어 처리 방법을 적용한 작성자 식별 프레임워크룰 제안한다. 작성자 분석 이론을 적용하여 소스 코드에서 작성자 식별에 적합한 특징들을 추출하고 이를 텍스트 마이닝에서 사용하고 있는 특징들과 결합하여 기계학습 기반의 작성자 식별을 수행한다. 그리고 합성곱 신경망 기반 자연어 처리 방법을 소스 코드에 적용하여 코드 작성자 분류를 수행한다. 본 논문에서는 작성자 분석이론과 합성곱 신경망을 적용한 작성자 식별 프레임워크를 통해 작성자를 식별하기 위해서는 작성자 식별만을 위한 특징들이 필요하다는 것과 합성곱 신경망 기반 자연어 처리 방법이 소스 코드등과 같은 특수한 체계를 갖추고 있는 언어에서도 적용이 가능하다. 실험 결과 작성자 분석 이론 기반 작성자 식별 정확도는 95.1%였으며 CNN을 적용한 결과 반복횟수가 90번 이상일 경우 98% 이상의 정확도를 보여줬다.","Recently, Internet technology has developed, various programs are being created and therefore various codes are being made through many authors. On this aspect, some author deceive a program or code written by other particular author as they make it themselves and use other writers' code indiscriminately, or not indicating the exact code which has been used. Due to this makes it more and more difficult to protect the code. In this paper, we propose author identification framework using Authorship Analysis theory and Natural Language Processing(NLP) based on Convolutional Neural Network(CNN). We apply Authorship Analysis theory to extract features for author identification in the source code, and combine them with the features being used text mining to perform author identification using machine learning. In addition, applying CNN based natural language processing method to source code for code author classification. Therefore, we propose a framework for the identification of authors using the Authorship Analysis theory and the CNN. In order to identify the author, we need special features for identifying the authors only, and the NLP method based on the CNN is able to apply language with a special system such as source code and identify the author. identification accuracy based on Authorship Analysis theory is 95.1% and identification accuracy applied to CNN is 98%."
표면근전도 신호를 활용한 한국 숫자지화 인식에서 CNN 학습의 일관성에 관한 연구,2018,"['convolutional neural network', 'time-series signal', 'surface electromyography', 'Korean finger number gesture recognition', 'consistency in cnn learning', 'repeated recognition application']","합성곱 신경망 (Convolutional Neural Network, CNN)은 컴퓨터 비전 분야에서 활발히 적용되어 왔으며, 이미지 분류, 문서 분류, 지문 인식 등에서 탁월한 인식 능력을 보여 왔음을 여러 연구를 통해서 검증되었다. 본 연구는 시계열의 표면근전도 신호를 입력데이터로 취하는 숫자지화 인식 응용에 이미지 분류에서 탁월한 인식 성능을 보이는 합성곱 신경망을 적용한 것으로, 반복적인 한국 숫자지화 인식 수행에서도 일관된 학습을 수행하는지를 검증하는 연구로, 문헌에서 보기 힘든 연구이다. 이를 검증하기 위해, 한국 숫자지화 영(0)부터 다섯(5)까지의 여섯 숫자지화를 시연하도록 훈련한 실험 대상 1인의 아래팔 근육으로부터 획득한 숫자별 60개씩 총 360개의 표면근전도 신호를 획득하였으며, 그 중에서 252개의 표면근전도 신호를 입력데이터, 108개의 표면근전도 신호는 테스트데이터로 CNN 인식에 활용하였다. CNN 인식을 위해 필요한 학습단계는 100 학습단계, CNN 인식의 반복 수행 횟수는 10회로 설정하였으며, 반복 수행마다 테스트데이터를 활용하여 인식률을 계산하였다. 본 연구에서 실험한 결과에서 보듯이, 반복 인식마다 CNN의 학습은 일관되었으며, 99.1% 이상 (60 숫자지화 중 하나의 숫자지화 인식에 오류발생)의 높은 인식률을 보였다. 따라서, CNN 기법은 시계열의 표면근전도 신호를 입력데이터로 하는 숫자지화 인식 분야에서도 전역 솔루션과 함께 우수한 인식 능력을 제공하는 기법 중에 하나이다.","Convolutional Neural Network (CNN) has been actively employed in the application of computer vision, and has been proved to have its superior performance in image classification, document classification, and finger print recognition. This work focuses on an application of CNN, having outstanding performance in image classification, to recognition of korean finger number using time series sEMG signals as input and validates CNN's capability in providing its consistent learning in repeated application for recognition of sEMG based Korean finger numbers, which has been rarely a topic in previous studies. To this end, 252 sEMG signals as input data and 108 sEMG signals as test data out of 360 sEMG signals (60 signals each number) acquired from a forearm muscle of the subject who is trained to consistently perform six Korean finger number gestures from zero(0) to five(5) were used for CNN based finger number recognition. CNN was set to have 100 learning iterations for each application of finger number recognition, and to have 10 repetitive applications of finger number recognition for the consistency of CNN's learning. Recognition rate at each repetition was calculated from test data. As can be seen from the results in this work, CNN shows consistent learning at each repetitive application of finger number recognition and outstanding recognition rates of more than 99.1% (missed one case out of 60 cases). Thus, CNN is one of powerful techniques for finger number recognition based on time-series sEMG signals to provide not only global solution but also excellent recognition rates."
배치 정규화와 CNN을 이용한 개선된 영상분류 방법,2018,"['배치 정규화', '합성곱 신경망', '영상 분류', '딥 러닝', 'Batch Normalization', 'Convolutional Neural Network', 'Image Classification', 'Deep Learning']","딥 러닝은 영상 분류를 위한 여러 방법 중 높은 정확도를 보이는 방법으로 알려져 있다. 본 논문에서는 딥 러닝 방법 가운데 합성곱 신경망 (CNN:Convolutional Neural Network)을 이용하여 영상을 분류함에 있어 배치 정규화 방법이 추가된 CNN을 이용하여 영상 분류의 정확도를 높이는 방법을 제시하였다. 본 논문에서는 영상 분류를 더 정확하게 수행하기 위해 기존의 뉴럴 네트워크에 배치 정규화 계층 (layer)를 추가하는 방법을 제안한다. 배치 정규화는 각 계층에 존재하는 편향을 줄이기 위해 고안된 방법으로, 각 배치의 평균과 분산을 계산하여 이동시키는 방법이다. 본 논문에서 제시된 방법의 우수성을 입증하기 위하여 SHREC13, MNIST, SVHN, CIFAR-10, CIFAR-100의 5개 영상 데이터 집합을 이용하여 영상분류 실험을 하여 정확도와 mAP를 측정한다. 실험 결과 일반적인 CNN보다 배치 정규화가 추가된 CNN이 영상 분류 시 보다 높은 분류 정확도와 mAP를 보임을 확인 할 수 있었다.","Deep learning is known as a method of high accuracy among several methods for image classification. In this paper, we propose a method of enhancing the accuracy of image classification using CNN with a batch normalization method for classification of images using deep CNN (Convolutional Neural Network). In this paper, we propose a method to add a batch normalization layer to existing neural networks to enhance the accuracy of image classification. Batch normalization is a method to calculate and move the average and variance of each batch for reducing the deflection in each layer. In order to prove the superiority of the proposed method, Accuracy and mAP are measured by image classification experiments using five image data sets SHREC13, MNIST, SVHN, CIFAR-10, and CIFAR-100. Experimental results showed that the CNN with batch normalization is better classification accuracy and mAP rather than using the conventional CNN."
Deep CNN 기반의 한국어 음소 인식 모델 연구,2018,[],본 연구에서는 심층 합성곱 신경망(Deep CNN)과 Connectionist Temporal Classification (CTC) 알고리즘을 사용하여 강제정렬(force-alignment)이 이루어진 코퍼스 없이도 학습이 가능한 음소 인식 모델을 제안한다. 최근 해외에서는 순환 신경망(RNN)과 CTC 알고리즘을 사용한 딥 러닝 기반의 음소 인식 모델이 활발히 연구되고 있다. 하지만 한국어 음소 인식에는 HMM-GMM 이나 인공 신경망과 HMM 을 결합한 하이브리드 시스템이 주로 사용되어 왔으며，이 방법은 최근의 해외 연구 사례들보 다 성능 개선의 여지가 적고 전문가가 제작한 강제정렬 코퍼스 없이는 학습이 불가능하다는 단점이 있다. 또한 RNN 은 학습 데이터가 많이 필요하고 학습이 까다롭다는 단점이 있어，코퍼스가 부족하 고 기반 연구가 활발하게 이루어지지 않은 한국어의 경우 사용에 제약이 있다. 이에 본 연구에서는 강제정렬 코퍼스를 필요로 하지 않는 CTC 알고리즘을 도입함과 동시에，RNN 에 비해 더 학습 속도가 빠르고 더 적은 데이터로도 학습이 가능한 합성곱 신경망(CNN)을 사용하여 딥 러닝 모델을 구축하여 한국어 음소 인식을 수행하여 보고자 하였다. 이 모델을 통해 본 연구에서는 한국어에 존재 하는 49 가지의 음소를 추출하는 세 종류의 음소 인식기를 제작하였으며，최종적으로 선정된 음소 인식 모델의 PER(Phoneme Error Rate)은 9.44 로 나타났다. 선행 연구 사례와 간접적으로 비교하였을 때，이 결과는 제안하는 모델이 기존 연구 사례와 대등하거나 조금 더 나은 성능을 보인다고 할 수 있다.,다국어 초록 정보 없음
MRI 영상의 전처리와 심층학습에 의한 뇌종양 진단보조 시스템 개발,2018,"['뇌종양', 'MRI', '전처리', '심층학습', '합성곱신경망', 'Brain tumor', 'Preprocessing', 'Deep learning', 'Convolutional neural network']","본 논문에서는 MRI 영상의 전처리와 심층학습에 의한 뇌종양 진단을 위한 보조시스템을 개발한다. 여기서 전처리는 DICOM 시스템으로부터 얻어진 MRI 뇌 영상의 이진마스크를 이용해 관심영역을 추출하고, 중간필터와 모폴로지 연산으로 추출된 영역의 잡음을 제거한 후, 크기를 재조정하여 학습부하를 줄인다. 또한 심층학습은 전처리된 영상을 대상으로 합성곱신경망을 이용하여 학습모델을 구현하여 새로이 입력되는 뇌 MRI의 정상과 비정상을 판단한다. 제안된 기법을 T2 MRI 13번째 수평절단 572*816 픽셀의 8비트 RGB 뇌 영상 72개를 대상으로 실험한 결과, 우수한 진단 성능이 있음을 확인할 수 있었다.","This paper presents a diagnostic assistant system of brain tumor by the preprocessing and deep learning of MRI images. The preprocessing extracts the region of interest by using a binary mask, and performs the median filter and morphology operation to remove the noise in MRI brain image, and reduce the learning load by resizing the image. And deep learning is performed on preprocessed images using convolutional neural network, determine the normality and abnormality of the newly entered MRI brain image. The proposed method has been applied to diagnose 8 bits RGB 72-brain MRI images of 572*816 pixels. The experimental results show that the proposed method has an excellent diagnoicst performance."
멀티스케일 및 심층 특징 추출 기반의 가로수종 및 상태 인식,2018,"['Deep Feature', 'Deep Learning', 'Fisher Vector', 'Sparse Coding', 'Gaussian Mixture Model']",국문 초록 정보 없음,다국어 초록 정보 없음
고밀도 그리드 모델과 앵커모델을 이용한 동적 객체검지 향상에 관한 연구,2018,"['합성곱 신경망', '차세대 ITS', '안전서비스', '객체 검지', '맹인 및 시각 장애인 보행자', 'CNNs', 'Next generation ITS', 'Safety Service', 'Object Detection', 'BVI pedestrian']",국문 초록 정보 없음,다국어 초록 정보 없음
Object Recognition in Low Resolution Images using a Convolutional Neural Network and an Image Enhancement Network,2018,"['합성곱 신경망', '심층 신경망', '저해상도 영상', '객체 인식', '영상 개선 신경망', 'convolutional neural networks', 'deep neural networks', 'low-resolution images', 'object recognition', 'image enhancement network']",국문 초록 정보 없음,다국어 초록 정보 없음
동적 환경에서의 비지도 학습 기반 깊이 예측 및 카메라 움직임 추정,2018,"['depth prediction', 'unsupervised learning', 'dynamic context understanding', 'visual odometry', 'deep learning']","최근 합성곱 신경망과 같은 딥 러닝 기술을 이용한 영상 기반 센싱 기술이 자율 주행을 위한 핵심기술로 각광받고 있다. 딥 러닝 기술은 필연적으로 많은 양의 학습 데이터를 필요로 하는데, 본 연구에서는 방대한 양의 영상이 주어졌을 때 실측 정보 없이 비지도 학습을 통해 깊이 정보 및 카메라의 움직임을 추정하는 방법에 대해 제안한다. 핵심 아이디어는 연속되는 영상에서 추정한 광류 정보와 가상 시점 생성 기술을 이용한 손실 함수를 설계한 것이며, 다양한 실험을 통해 최신 기술 대비 좋은 성능을 보임을 확인 하였다. 비지도 학습을 위한 손실 함수를 제안한다.",다국어 초록 정보 없음
Generative Adversarial Networks를 이용한 Face Morphing 기법 연구,2018,"['대립쌍 기계학습', '얼굴합성', '합성곱 신경망', '비지도 학습', 'Generative adversarial network', 'face morphing', 'DCGAN', 'dCNN', 'unsupervised learning']",국문 초록 정보 없음,"Recently, with the explosive development of computing power, various methods such as RNN and CNN have been proposed under the name of Deep Learning, which solve many problems of Computer Vision have. The Generative Adversarial Network, released in 2014, showed that the problem of computer vision can be sufficiently solved in unsupervised learning, and the generation domain can also be studied using learned generators. GAN is being developed in various forms in combination with various models. Machine learning has difficulty in collecting data. If it is too large, it is difficult to refine the effective data set by removing the noise. If it is too small, the small difference becomes too big noise, and learning is not easy. In this paper, we apply a deep CNN model for extracting facial region in image frame to GAN model as a preprocessing filter, and propose a method to produce composite images of various facial expressions by stably learning with limited collection data of two persons."
비정형 정보와 CNN 기법을 활용한 이진 분류 모델의 고객 행태 예측,2018,"['고객 행태 예측', '합성곱 신경망', '딥러닝', '고객의 소리', 'Customer Behavior Prediction', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Voice of Customer(VOC)']",국문 초록 정보 없음,"Deep learning is getting attention recently. The deep learning technique which had been applied in competitions of the International Conference on Image Recognition Technology(ILSVR) and AlphaGo is Convolution Neural Network(CNN). CNN is characterized in that the input image is divided into small sections to recognize the partial features and combine them to recognize as a whole. Deep learning technologies are expected to bring a lot of changes in our lives, but until now, its applications have been limited to image recognition and natural language processing.  The use of deep learning techniques for business problems is still an early research stage. If their performance is proved, they can be applied to traditional business problems such as future marketing response prediction, fraud transaction detection, bankruptcy prediction, and so on. So, it is a very meaningful experiment to diagnose the possibility of solving business problems using deep learning technologies based on the case of online shopping companies which have big data, are relatively easy to identify customer behavior and has high utilization values. Especially, in online shopping companies, the competition environment is rapidly changing and becoming more intense. Therefore, analysis of customer behavior for maximizing profit is becoming more and more important for online shopping companies.  In this study, we propose CNN model of Heterogeneous Information Integration using CNN as a way to improve the predictive power of customer behavior in online shopping enterprises. In order to propose a model that optimizes the performance, which is a model that learns from the convolution neural network of the multi-layer perceptron structure by combining structured and unstructured information, this model uses heterogeneous information integration, unstructured information vector conversion, ‘multi-layer perceptron design, and evaluate the performance of each architecture, and confirm the proposed model based on the results. In addition, the target variables for predicting customer behavior are defined as six binary classification problems: re-purchaser, churn, frequent shopper, frequent refund shopper, high amount shopper, high discount shopper.  In order to verify the usefulness of the proposed model, we conducted experiments using actual data of domestic specific online shopping company. This experiment uses actual transactions, customers, and VOC data of specific online shopping company in Korea. Data extraction criteria are defined for 47,947 customers who registered at least one VOC in January 2011 (1 month). The customer profiles of these customers, as well as a total of 19 months of trading data from September 2010 to March 2012, and VOCs posted for a month are used. The experiment of this study is divided into two stages. In the first step, we evaluate three architectures that affect the performance of the proposed model and select optimal parameters. We evaluate the performance with the proposed model.  Experimental results show that the proposed model, which combines both structured and unstructured information, is superior compared to NBC(Naïve Bayes classification), SVM(Support vector machine), and ANN(Artificial neural network). Therefore, it is significant that the use of unstructured information contributes to predict customer behavior, and that CNN can be applied to solve business problems as well as image recognition and natural language processing problems. It can be confirmed through experiments that CNN is more effective in understanding and interpreting the meaning of context in text VOC data. And it is significant that the empirical research based on the actual data of the e-commerce company can extract very meaningful information from the VOC data written in the text format directly by the customer in the prediction of the customer behavior. Finally, through various experiments, it is possible to say that the proposed model"
생성 기반 질의응답 채팅 시스템 구현을 위한 지식 임베딩 방법,2018,"['지식 개체 임베딩', '샴 순환 신경망', '생성 기반 채팅 시스템', 'sequence-to-sequence 모델', 'knowledge entity embedding', 'Siamese recurrent neural network', 'generative chat system', 'sequence-to-sequence model']",채팅 시스템은 사람의 말을 기계가 이해하고 적절한 응답을 하는 시스템이다. 채팅 시스템은사용자의 간단한 정보 검색 질문에 대답해야 하는 경우가 있다. 그러나 기존의 생성 채팅 시스템들은 질의응답에 필요한 정보인 지식 개체(트리플 형태 지식에서의 주어와 목적어)의 임베딩을 고려하지 않아 발화에 나타나는 지식 개체가 다르더라도 같은 형태의 답변이 생성되었다. 본 논문에서는 생성 기반 채팅시스템의 질의응답 정확도를 향상시키기 위한 지식 임베딩 방법을 제안한다. 개체와 유의어의 지식 임베딩을 위해 샴 순환 신경망을 사용하며 이를 이용해 주어와 술어를 인코딩 하고 목적어를 디코딩하는 sequence-to-sequence 모델의 성능을 향상 시켰다. 자체 구축한 채팅데이터를 통한 실험에서 제안된 임베딩 방법은 종래의 합성곱 신경망을 통한 임베딩 방법 보다 12.48% 높은 정확도를 보였다.,"A chat system is a computer program that understands user's miscellaneous utterances and generates appropriate responses. Sometimes a chat system needs to answer users’ simple information-seeking questions. However, previous generative chat systems do not consider how to embed knowledge entities (i.e., subjects and objects in triple knowledge), essential elements for question-answering. The previous chat models have a disadvantage that they generate same responses although knowledge entities in users’ utterances are changed. To alleviate this problem, we propose a knowledge entity embedding method for improving question-answering accuracies of a generative chat system. The proposed method uses a Siamese recurrent neural network for embedding knowledge entities and their synonyms. For experiments, we implemented a sequence-to-sequence model in which subjects and predicates are encoded and objects are decoded. The proposed embedding method showed 12.48% higher accuracies than the conventional embedding method based on a convolutional neural network."
CNN 딥러닝을 이용한 서울방문 관광객의 서울 이미지 분석,2018,"['서울 도시 이미지', '플리커 지오태깅된 사진', '딥러닝', '합성곱 신경망', '이미지 마이닝']",국문 초록 정보 없음,다국어 초록 정보 없음
Multi-sense Word Embedding to Improve Performance of a CNN-based Relation Extraction Model,2018,"['원격 지도학습', '관계추출', '단어 임베딩', '합성곱 신경망', 'distant supervision', 'relation extraction', 'word embedding', 'convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 알고리즘을 이용한 음장 예측 시스템 연구,2018,"['Circular baffled piston(원형배플피스톤)', 'Cross-spectrum(상호스펙트럼)', 'Convolution Neural Network(합성곱신경망)', 'Cepstrum(캡스트럼)']",국문 초록 정보 없음,다국어 초록 정보 없음
Business Application of Convolutional Neural Networks for Apparel Classification Using Runway Image,2018,"['Convolutional Neural Networks', 'Image Classification', 'Apparel', 'Runway', 'Mobility', '합성곱 신경망', '이미지 분류', '의류', '런웨이', '이동성']",국문 초록 정보 없음,"Large amount of data is now available for research and business sectors to extract knowledge from it. This data can be in the form of unstructured data such as audio, text, and image data and can be analyzed by deep learning methodology. Deep learning is now widely used for various estimation, classification, and prediction problems. Especially, fashion business adopts deep learning techniques for apparel recognition, apparel search and retrieval engine, and automatic product recommendation. The core model of these applications is the image classification using Convolutional Neural Networks (CNN). CNN is made up of neurons which learn parameters such as weights while inputs come through and reach outputs. CNN has layer structure which is best suited for image classification as it is comprised of convolutional layer for generating feature maps, pooling layer for reducing the dimensionality of feature maps, and fully-connected layer for classifying the extracted features. However, most of the classification models have been trained using online product image, which is taken under controlled situation such as apparel image itself or professional model wearing apparel. This image may not be an effective way to train the classification model considering the situation when one might want to classify street fashion image or walking image, which is taken in uncontrolled situation and involves people’s movement and unexpected pose. Therefore, we propose to train the model with runway apparel image dataset which captures mobility. This will allow the classification model to be trained with far more variable data and enhance the adaptation with diverse query image. To achieve both convergence and generalization of the model, we apply Transfer Learning on our training network. As Transfer Learning in CNN is composed of pre-training and fine-tuning stages, we divide the training step into two. First, we pre-train our architecture with large-scale dataset, ImageNet dataset, which consists of 1.2 million images with 1000 categories including animals, plants, activities, materials, instrumentations, scenes, and foods. We use GoogLeNet for our main architecture as it has achieved great accuracy with efficiency in ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Second, we fine-tune the network with our own runway image dataset. For the runway image dataset, we could not find any previously and publicly made dataset, so we collect the dataset from Google Image Search attaining 2426 images of 32 major fashion brands including Anna Molinari, Balenciaga, Balmain, Brioni, Burberry, Celine, Chanel, Chloe, Christian Dior, Cividini, Dolce and Gabbana, Emilio Pucci, Ermenegildo, Fendi, Giuliana Teso, Gucci, Issey Miyake, Kenzo, Leonard, Louis Vuitton, Marc Jacobs, Marni, Max Mara, Missoni, Moschino, Ralph Lauren, Roberto Cavalli, Sonia Rykiel, Stella McCartney, Valentino, Versace, and Yve Saint Laurent. We perform 10-folded experiments to consider the random generation of training data, and our proposed model has achieved accuracy of 67.2% on final test. Our research suggests several advantages over previous related studies as to our best knowledge, there haven’t been any previous studies which trained the network for apparel image classification based on runway image dataset. We suggest the idea of training model with image capturing all the possible postures, which is denoted as mobility, by using our own runway apparel image dataset. Moreover, by applying Transfer Learning and using checkpoint and parameters provided by Tensorflow Slim, we could save time spent on training the classification model as taking 6 minutes per experiment to train the classifier. This model can be used in many business applications where the query image can be runway image, product image, or street fashion image. To be specific, runway query image can be used for mobile application service during fashion week to facilitate brand search, street style query image"
KODAS DB를 이용한 교차로 신호등 인식 성능 분석,2018,"['Deep Learning(심층학습)', 'Traffic Signal(신호등)', 'Convolution Neural Network(합성곱 신경망)', 'Crossroad(교차로)', 'KODAS']",국문 초록 정보 없음,다국어 초록 정보 없음
Wasserstein Center 손실을 이용한 스케치 기반 3차원 물체 검색,2018,"['Convolutional Neural Network', 'Image retrieval', 'Deep Learning', 'Sketch-based 3D object retrieval', '합성곱 신경망', '영상 검색', '딥 러닝', '스케치 기반 3차원 물체 검색']","스케치 기반 3차원 물체 검색은 다양한 3차원 물체를 사람이 손으로 그린 스케치를 질의(query)로 사용하여 물체를 편리하게 검색하는 방법이다. 본 논문에서는 스케치 기반 3차원 물체 검색을 위해 스케치 CNN(Convolutional Neural Network)과 Wasserstein CNN 모델에 Wasserstein Center 손실을 적용하여 물체의 검색 성공률을 향상시키는 새로운 방법을 제안한다. 제안된 Wasserstein Center 손실이란 각 물체의 클래스(category)의 중심을 학습하고, 동일한 클래스의 특징과 중심 간의 Wasserstein 거리가 작아지도록 만드는 방법이다. 이를 위하여 제안된 3차원 물체 검색은 다음의 단계로 수행된다. 첫 번째로, 3차원 물체의 특징은 3차원 물체를 여러 방향에서 촬영된 2차원 영상의 특징을 CNN을 이용하여 추출하고, 각 영상 특징의 Wasserstein 중심을 계산한다. 두 번째로, 스케치의 특징은 별도의 스케치 CNN을 이용하여 추출하였다. 마지막으로, 추출한 3차원 물체의 특징과 스케치의 특징을 본 논문에서 제안한 Wasserstein Center 손실을 이용하여 학습하고 스케치 기반의 3차원 물체 검색에 적용하였다. 본 논문에서 제안한 방법의 우수성을 입증하기 위하여 SHREC 13과 SHREC 14의 두 가지 벤치마크 데이터 집합을 이용하여 평가하였으며, 제안된 방법이 기존의 스케치 기반 검색방법들과 비교하여 모든 측정 기준에서 우수한 결과를 나타냄을 확인할 수 있었다.","Sketch-based 3D object retrieval is a convenient way to search for various 3D data using human-drawn sketches as query. In this paper, we propose a new method of using Sketch CNN, Wasserstein CNN and Wasserstein center loss for sketch-based 3D object search. Specifically, Wasserstein center loss is a method of learning the center of each object category and reducing the Wasserstein distance between center and features of the same category. To do this, the proposed 3D object retrieval is performed as follows. Firstly, Wasserstein CNN extracts 2D images taken from various directions of 3D object using CNN, and extracts features of 3D data by computing the Wasserstein barycenters of features of each image. Secondly, the features of the sketch are extracted using a separate Sketch CNN. Finally, we learn the features of the extracted 3D object and the features of the sketch using the proposed Wasserstein center loss. In order to demonstrate the superiority of the proposed method, we evaluated two sets of benchmark data sets, SHREC 13 and SHREC 14, and the proposed method shows better performance in all conventional metrics compared to the state of the art methods."
PointNet을 이용한 3D 우주물체 분류 모델,2018,"['PointNet(포인트넷)', 'Point Cloud(포인트클라우드)', '3D Classification Model(3차원 분류 모델)', 'Convolution Neural Network(합성곱신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 이용한 히트펌프 시스템의 냉매량 고장 감지에 관한 연구,2018,"['Heat pump system(히트펌프 시스템)', 'Refrigerant charge fault detection(냉매량 고장진단)', 'Convolutional neural network(합성곱 신경망)', 'Classification(분류)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 손상된 흑백 얼굴 사진 컬러 복원,2018,"['Inpainting', 'Colorization', 'Deep Learning', 'BEGAN', 'CNN', '복원', '컬러화', '딥러닝', '경계 평형 생성 적대 네트워크', '합성곱 신경망']","본 논문에서는 손상된 흑백 얼굴 이미지를 컬러로 복원하는 방법을 제안한다. 기존 연구에서는 오래된 증명사진처럼 손상된 흑백 사진에 컬러화 작업을 하면 손상된 영역 주변이 잘못 색칠되는 경우가 있었다. 이와 같은 문제를 해결하기 위해 본 논문에서는 입력받은 사진의 손상된 영역을 먼저 복원한 후 그 결과를 바탕으로 컬러화를 수행하는 방법을 제안한다. 본 논문의 제안 방법은 BEGAN(Boundary Equilibrium Generative Adversarial Networks) 모델 기반 복원과 CNN(Convolutional Neural Network) 기반 컬러화의 두 단계로 구성된다. 제안하는 방법은 이미지 복원을 위해 DCGAN(Deep Convolutional Generative Adversarial Networks) 모델을 사용한 기존 방법들과 달리 좀 더 선명하고 고해상도의 이미지 복원이 가능한 BEGAN 모델을 사용하고, 그 복원된 흑백 이미지를 바탕으로 컬러화 작업을 수행한다. 최종적으로 다양한 유형의 얼굴 이미지와 마스크에 대한 실험 결과를 통해 기존 연구에 비해 많은 경우에 사실적인 컬러 복원 결과를 보여줄 수 있음을 확인하였다.","In this paper, we propose a method to restore corrupted black and white facial images to color. Previous studies have shown that when coloring damaged black and white photographs, such as old ID photographs, the area around the damaged area is often incorrectly colored. To solve this problem, this paper proposes a method of restoring the damaged area of input photo first and then performing colorization based on the result. The proposed method consists of two steps: BEGAN (Boundary Equivalent Generative Adversarial Networks) model based restoration and CNN (Convolutional Neural Network) based coloring. Our method uses the BEGAN model, which enables a clearer and higher resolution image restoration than the existing methods using the DCGAN (Deep Convolutional Generative Adversarial Networks) model for image restoration, and performs colorization based on the restored black and white image. Finally, we confirmed that the experimental results of various types of facial images and masks can show realistic color restoration results in many cases compared with the previous studies."
딥러닝 기반의 이미지 분류 기술 동향,2018,[],"본고에서는 딥러닝 기반의 이미지 분류 기술 분야에서 기존 방법 들보다 뛰어난 성능을 보이는 합성곱 신경망 (CNN, Convolutional Neural Network)의 최근 기술 동향을 소개한다.",다국어 초록 정보 없음
Generating Pixel Art from Game Characters with Convolutional-Neural Network,2018,"['pixel art', 'deep learning', 'image abstraction', 'non-photorealistic rendering']","픽셀 아트는 낮은 해상도와 제한된 색 팔레트를 가지고 영상을 표현한다. 픽셀 아트는 낮은 연산 성능과 적은 저장 공간을 가지는 초기 컴퓨터 게임에서 주로 사용되었다. 현대에 이르러, 픽셀 아트는 예술이나 퍼즐, 게임과 같은 다양한 분야에서 찾아볼 수 있게 되었다.본 논문에서는 게임 캐릭터 영상을 입력으로 받는 픽셀 아트 생성 모델을 제안한다. 기존 방법과는 달리, 합성곱 신경망(CNN:Convolutional-Neural Network)를 픽셀 아트 생성 목적에 맞게 변형하여 이를 이용하는 방법을 제시한다. 기존의 합성곱 연산 후에 upsampling 과정을 추가하여 픽셀 아트가 생성될 수 있도록 하였다. 네트워크는 ground truth와 생성된 픽셀 아트와의 평균 오차 제곱(MSE:Mean Squared Error)을 최소화해나가며 학습을 수행한다.Ground truth는 실제 아티스트가 생성하도록 하였고, 이미지 회전과 반전 기법을 이용하여 augumentation을 수행하였다. 생성된 데이터 집합은 학습, 검증, 시험 데이터로 나누었다. 이러한 데이터 집합을 기반으로 감독 학습을 실시하여 픽셀 아트 생성 네트워크를 학습하였다. 학습 모델의 학습 과정과 학습 정확도를 제시하고, 시험 데이터 뿐만 아니라 다양한 영상에 대한 픽셀아트 결과도 함께 제시한다.","Pixel art, which presents low-resolutional images with restricted color palette, has been employed frequently in the early computer games played on low memory capacity and computational performance. Recently, pixel art wides its applications to the area such as puzzle and game. In this paper, we present a pixel art generator from images of game characters. Unlike traditional framework, we employ and modify a Convolutional-Neural Network(CNN) to generate pixel art by placing an up-convolution layer after convolution layers. The up-convolution layer increases the resolution of the result images to satisfy user-required resolution. The network is trained by minimizing the Mean Squared Error(MSE) between ground truth images and generated pixel art images from the input high-resolutional image. Also, we employ artists to produce the ground truth of pixel art for our network and augment the data by rotating and fliping. We partition the ground truth images into three datasets: a training, validation and test dataset. With this dataset, we perform a supervised learning and train our network as the pixel art generator. We show a training process and a training accuracy. Moreover, we test our architecture for a various images as well as the test dataset to prove the excellence of our architecture."
< 전시-P-07 > 딥러닝 기술을 이용한 국산침엽수종 자동식별 온라인 웹서비스,2018,[],"현재 주로 이용되는 목재수종식별방법은 장기간 숙련된 전문가에 의한 육안식별이나 목재 샘플의 절편을 현미경으로 식별하는 방법이다. 하지만 이 방법은 전문가에게 시편을 전달하여 식별하기 때문에 유통과정에서 목재 수종을 바로 식별할 수 없다는 단점이 있다. 따라서 본 연구에서는 유통과정 중 실시간 목재 수종 식별이 가능하도록 딥러닝(Deep learning) 기술을 이용한 온라인 목재 수종 자동식별 시스템을 제작하였다.본 연구에서 사용한 시스템 환경으로 소프트웨어는 Linux(Ubuntu 16) 기반의 Tensorflow, Keras 및 개 발 언어인 Python을 설치하였고, 자동 식별된 이미지를 웹에서 확인할 수 있도록 Apache(웹서버), PHP, MySQL(데이터베이스 서버)를 설치하였다. 하드웨어는 Xeon 쿼드코어 CPU와 8GB RAM 사양의 서버를 사용하였다. 목재 이미지의 자동수종판별 모델은 선행 연구에서 가장 높은 식별률을 보인 LeNet 변형인 합성곱신경망(Convolutional neural network; CNN)을 개발하였다. 온라인 목재 수종 자동식별은 웹서비스(http://woodbank.snu.ac.kr)을 통해 이용할 수 있다. 웹사이트에서 사용자가 이동형 통신기기를 이용하여 획득한 목재 횡단면의 사진을 목재 수종 자동식별 시스템에 전달하면, 훈련된 LeNet 모델을 통해 전송된 목재 사진에 대한 식별결과를 얻을 수 있다. 식별결과는 웹사이트를 통해 확인할 수 있다.딥러닝 기술을 이용하여 개발된 목재 수종 온라인 식별 시스템은 목재 유통과정에서 목재 수종을 빠르고 정확하게 식별할 수 있을 것이라 기대된다.",다국어 초록 정보 없음
단-단계 물체 탐지기 학습을 위한 고난도 예들의 온라인 마이닝,2018,"['단-단계 물체 탐지', '심층 합성 곱 신경망', '온라인 고난도 예 마이닝', '손실 함수']","본 논문에서는 심층 합성 곱 신경망 모델 기반의 단-단계 물체 탐지기들의 탐지 성능을 향상시킬 수 있는 새로운 손실 함수와 온라인 고난도 예 마이닝 방식을 제안한다. 본 논문에서 제안하는 손실 함수와 온라인 고난도 예 마이닝 방식은 물체와 배경 간의 학습 데이터 불균형 문제를 해결할 뿐만 아니라, 각 물체의 위치 추정 정확도를 더 개선시킬 수 있다. 따라서 물체 탐지 속도가 빠른 단-단계 물체 탐지기들에 이-단계 물체 탐지기들과 비슷하거나 더 우수한 탐지 성능을 제공할 수 있다. PASCAL VOC 2007 벤치마크 데이터 집합을 이용한 다양한 실험들을 통해, 본 논문에서 제안하는 손실 함수와 온라인 고난도 예 마이닝 방식이 단-단계 물체 탐지기들의 성능 개선에 도움이 된다는 것을 입증해 보인다.","In this paper, we propose both a new loss function and an online hard example mining scheme for improving the performance of single-stage object detectors which use deep convolutional neural networks. The proposed loss function and the online hard example mining scheme can not only overcome the problem of imbalance between the number of annotated objects and the number of background examples, but also improve the localization accuracy of each object. Therefore, the loss function and the mining scheme can provide intrinsically fast single-stage detectors with detection performance higher than or similar to that of two-stage detectors. In experiments conducted with the PASCAL VOC 2007 benchmark dataset, we show that the proposed loss function and the online hard example mining scheme can improve the performance of single-stage object detectors."
충돌회피기술을 위한 광학센서를 이용한 원/근거리 딥러닝기반 항공기 검출,2018,"['EO sensor(영상 센서)', 'Detect-and-Avoid(탐지/회피)', 'Deep Convolutional Neural Network(심층합성곱 신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
