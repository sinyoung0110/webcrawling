title,date,keywords,abstract,multilingual_abstract
러시아 해외정보기관의 역할과 안보 인식의 변화: 해외정보국(SVR)과 정보총국(GRU)의 정보활동을 중심으로,2018,"['러시아 해외정보기관의 역할', '안보인식의 변화', '해외정보국', '정보총국', '해외 첩보 활동', 'Role of Russia’s Overseas Intelligence Agencies', 'Change of Awareness of Security', 'SVR', 'GRU', 'Overseas Intelligence Activities']","소련 해체와 함께, KGB가 연방보안국(FSB)과 해외정보국(SVR)으로 분리되었다. 정보총국(GRU)은 큰 폭의 변화 없이 그 역할을 계속해 오고 있다. 이들 중에서 해외정보를 수집하고 있는 정보기관의 역할을 조사하게 되면, 러시아의 안보인식이 변화되고 있음을 알 수 있다. 러시아의 SVR과 GRU의 역할을 중심으로 본다면, 옐친시기와 푸틴시기의 안보 인식에서 차이를 보인다. 옐친 시기 SVR과GRU의 해외정보 활동은 미온적인 수준의 정치 및 군사안보에 초점이 맞추어진경향이 강했고, 푸틴이 집권하는 2000년 이후부터는 보다 적극적인 정치 및 군사안보와 경제안보에 보다 많은 관심을 갖고 해외정보수집에 나서고 있음을 알수 있다. 이러한 현실은 당시의 안보 인식을 엿볼 수 있도록 한다.국가안보 문제가 다양한 분야에서 제기되고 있기 때문에, SVR이 담당하는 정보수집 활동은 정치 및 군사영역 중심에서 경제 및 산업기술, 안보영역 등 다양한 분야로 확장되었다. SVR과 GRU 국장의 과거 경력에서도 러시아의 당시 해외 첩보 활동 및 안보 상황을 엿볼 수 있도록 한다. SVR 국장의 경력은 임명권자인 대통령의 정책 방향을 이해하는 데 도움을 주고, SVR의 핵심 역할을 짐작할 수 있도록 한다. 정치 및 군사안보 영역에서 경제안보에 보다 많은 관심을기울이면서 해외정보 수집이 이루어지고 있음을 짐작하도록 한다. 그리고 GRU 의 해외 첩보 활동을 보면, 러시아가 당면한 안보 수준을 짐작할 수 있도록 한다.","Along with the collapse of Soviet Union, KGB was divided into Federal Security Service(FSB) and Foreign Intelligence Service(SVR).Main Intelligence Directorate(GRU) has continued the role without any huge change. A close look at the role of intelligence agencies gathering overseas information shows that there has been change in awareness of national security in Russia. When looking at the role of SVR and GRU in Russia, we can see the difference in awareness of national security at a time of Yeltsin Administration and Putin Administration. We can see that SVR and GRU’s overseas intelligence activities of Yeltsin Administration was likely to focus on political and military security in no active way but Putin Administration has been more interest in political and military security and economic security in gathering overseas information. This reality makes us see awareness of security of that time.As national security issues have been raised in various areas, intelligence collection activities have been expanded to various areas including economic, industrial technology and security area from focus on political and military area. Past career of directors of SVR and GRU shows then overseas intelligence activities and security situation of Russia. A look at the career of SVR director will be helpful in understanding policy direction of President who appoints them and make us guess core role of SVR. It makes us guess of gathering overseas information while taking more interest in economic security than political and military security area. And GRU’s overseas intelligence activities make us guess the security level that Russia is facing."
Bidirectional GRU-CRF 기반의 한국어 개체명 인식을 위한 어휘 사전 자질 적용 네트워크 토폴로지 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
LSTM 기반의 sequence-to-sequence 모델을 이용한 한글 자동 띄어쓰기,2018,"['인코딩-디코딩', 'sequence-to-sequence', 'LSTM', '순차정보 신경망', '자동 띄어쓰기', '드롭아웃', '계층 정 규화', 'encoding-decoding', 'LSTM', 'sequence-to-sequence neural network', 'auto spacing', 'drop-out', 'layer normalization']","자동 띄어쓰기 특성을 효과적으로 처리할 수 있는 LSTM(Long Short-Term Memory Neural Networks) 기반의 RNN 모 델을 제시하고 적용한 결과를 분석하였다. 문장이 길거나 일부 노이즈가 포함된 경우에 신경망 학습이 쉽지 않은 문제를 해결하기 위하여 입력 데이터 형식과 디코딩 데이터 형식을 정의하고, 신경망 학습에서 드롭아웃, 양방향 다층 LSTM 셀, 계층 정규화기법, 주목 기법(attention mechanism)을 적용하여 성능을 향상시키는 방법을 제안하였다. 학습 데이터로는 세종 말뭉치 자료를 사용하였으며, 학습 데이터가 부분적으로 불완전한 띄어쓰기가 포함되어 있었음에도 불구하고, 대량의 학습 데이터를 통해 한글 띄어쓰기에 대한 패턴이 의미 있게 학습되었다. 이것은 신경망에서 드롭아웃 기법을 통해 학습 모델의 오버피팅이 되지않도록 함으로써 노이즈에 강한 모델을 만들었기 때문이다. 실험결과로 LSTM sequence-to-sequence 모델이 재현율과 정확도를 함께 고려한 평가 점수인 F1 값이 0.94로 규칙 기반 방식과 딥러닝 GRU-CRF보다 더 높은 성능을 보였다.","We proposed a LSTM-based RNN model that can effectively perform the automatic spacing characteristics. For those long or noisy sentences which are known to be difficult to handle within Neural Network Learning, we defined a proper input data format and decoding data format, and added dropout, bidirectional multi-layer LSTM, layer normalization, and attention mechanism to improve the performance. Despite of the fact that Sejong corpus contains some spacing errors, a noise-robust learning model developed in this study with no overfitting through a dropout method helped training and returned meaningful results of Korean word spacing and its patterns. The experimental results showed that the performance of LSTM sequence-to-sequence model is 0.94 in F1-measure, which is better than the rule-based deep-learning method of GRU-CRF."
딥러닝 기반 기사단위 및 문단 단위별 분류,2018,"['Genre Classification', 'Deep Learning', 'Word2Vec', 'Long Short-Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Networks (CNN)', 'Word embedding']",국문 초록 정보 없음,"Text classification has been studied for a long time in the Natural Language Processing field. In this paper, we propose an article- and paragraph-level genre classification system using Word2Vec-based LSTM, GRU, and CNN models for large-scale English corpora. Both article- and paragraph-level classification performed best in accuracy with LSTM, which was followed by GRU and CNN in accuracy performance. Thus, it is to be confirmed that in evaluating the classification performance of LSTM, GRU, and CNN, the word sequential information for articles is better than the word feature extraction for paragraphs when the pre-trained Word2Vec-based word embeddings are used in both deep learning-based article- and paragraph-level classification tasks."
단어의 의미와 문맥을 고려한 순환신경망 기반의 문서 분류,2018,"['문서 분류', 'Doc2vec 순환신경망']","본 논문에서는 단어의 순서와 문맥을 고려하는 특징을 추출하여 순환신경망(Recurrent Neural Network)으로 문서를 분류하는 방법을 제안한다. 단어의 의미를 고려한 word2vec 방법으로 문서내의 단어를 벡터로 표현하고, 문맥을 고려하기 위해 doc2vec으로 입력하여 문서의 특징을 추출한다. 문서분류 방법으로 이전 노드의 출력을 다음 노드의 입력으로 포함하는 RNN 분류기를 사용한다. RNN 분류기는 신경망 분류기 중에서도 시퀀스 데이터에 적합하기 때문에 문서 분류에 좋은 성능을 보인다. RNN에서도 그라디언트가 소실되는 문제를 해결해주고 계산속도가 빠른 GRU(Gated Recurrent Unit) 모델을 사용한다. 실험 데이터로 한글 문서 집합 1개와 영어 문서 집합 2개를 사용하였고 실험 결과 GRU 기반 문서 분류기가 CNN 기반 문서 분류기 대비 약 3.5%의 성능 향상을 보였다.","In this paper, we propose a method to classify a document using a Recurrent Neural Network by extracting features considering word sense and contexts. Word2vec method is adopted to include the order and meaning of the words expressing the word in the document as a vector. Doc2vec is applied for considering the context to extract the feature of the document. RNN classifier, which includes the output of the previous node as the input of the next node, is used as the document classification method. RNN classifier presents good performance for document classification because it is suitable for sequence data among neural network classifiers. We applied GRU (Gated Recurrent Unit) model which solves the vanishing gradient problem of RNN. It also reduces computation speed. We used one Hangul document set and two English document sets for the experiments and GRU based document classifier improves performance by about 3.5% compared to CNN based document classifier."
환경 빅데이터 분석 및 서비스 개발 Ⅱ,2018,"['빅데이터', '기계학습', '심층신경망', '자연언어분석', '감성분석', 'Big Data', 'Machine Learning', 'Neural Network', 'Deep Learning', 'Sentiment Analysis']","본 연구는 2017년부터 시작된 계속사업으로서, 환경연구에 기계학습(Machine Learning) 연구방법론을 접목하여 환경정책 개발 가능성을 모색하는 연구이다. 본 연구는 환경연구에 빅데이터 방법론을 적용하는 ‘환경 빅데이터 연구’, 환경 빅데이터 연구에 필요한 대용량 데이터 수집 및 처리 인프라를 구축하는 ‘환경 빅데이터 인프라 구축’, 환경 빅데이터 연구 성과를 기반으로 원내·외 서비스를 개발하는 ‘원내·외 빅데이터 서비스 개발’ 등 3개 영역으로 구성되며, 연구단계별로 각 3년씩 총 3단계에 걸쳐 진행한다. 2018년은 환경 빅데이터 연구에 중점을 두는 제1단계(2017~2019년)의 2차 연도에 해당된다.2018년 환경 빅데이터 연구 영역에서는 2017년에는 인프라의 한계로 시도하기 어려웠던 대용량-비정형 데이터 분석을 시작하였고, 대기-기후 관련 매체 연구에 주력하였던 연구의 영역을 수질 및 수용체 반응을 대상으로 확대하였다. 환경 빅데이터 인프라 구축 영역에서는 대용량-비정형 데이터 연구를 수행할 수 있는 환경 빅데이터 플랫폼 구축을 병행하였다. 그리고 환경 빅데이터 서비스 개발 영역에서는 2017년 연구성과를 이용하여 환경연구 텍스트 데이터로부터 연구주제 및 연구키워드 네트워크를 파악하는 연구동향 파악 서비스를 구축하였다. 세부적인 연구의 성과들을 영역별로 요약하면 다음과 같다.첫 번째, 2018년 환경 빅데이터 연구 영역에서는 총 5건의 연구를 수행하였다. 5건의 연구 중 대용량-비정형 데이터 분석으로 환경 빅데이터 분석 영역을 확대한 연구는 ‘컨벌루션 신경망을 활용한 미세먼지 예측’, ‘기계학습 기반 환경이슈 감성분류기 개발: 기후변화를 중심으로’, ‘딥러닝을 이용한 국내 COPD 노인환자의 사망위험 추정’ 3건이다. 그리고 ‘데이터 기반 한강 수질 예측모형 개발’ 연구를 수행하여 매체 연구의 영역을 수질로 확장하였고, ‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’ 연구를 수행하여 수용체의 반응을 연구의 영역에 포괄하였다.‘컨벌루션 신경망을 활용한 미세먼지 예측’ 연구에서는 컨벌루션 신경망 모형을 이용하여 미세먼지 오염도를 예측하는 알고리듬을 개발하였다. 이 알고리듬은 전국을 10×10 격자로 구분한 공간의 미세먼지 오염도를 1~24시간 이전에 예측하는 데 활용되었다. 이 알고리듬은 4개 대기오염물질 오염도 정보 및 4개 기상 정보를 예측에 활용하였다. 이 알고리듬에 투입된 모든 정보는 컨벌루션 신경망의 입력자료로 활용될 수 있도록 전국을 10×10 격자로 구분한 공간에 역거리가중법(IDW)을 이용하여 할당되었다. 이 알고리듬은 1시간 이후 미세먼지 농도 예측의 평균제곱근오차를 2.07㎍/㎥ 까지 축소할 수 있었으며, 8시간 이후 예측의 평균제곱근오차도 9.09㎍/㎥ 까지 축소할 수 있었다. 이는 2017년에 개발한 KNN-순환신경망 모형의 1시간 이후 예측치 평균제곱근오차 7.96㎍/㎥ 를 획기적으로 개선한 결과이다.‘기계학습 기반 환경이슈 감성분류기 개발: 기후변화 중심으로’ 연구에서는 임베딩을 이용한 양방향 장단기 메모리(Bidirectional Long Short-Term Memory) 모형을 이용하여 기후변화와 관련된 SNS 문서의 감성을 7가지로 분류하는 감성분류기를 개발하였다. 이를 위해 기후변화 감성분류기 개발 과정에서 SNS 문서가 기후변화와 관련이 있는 문서인지 판별하는 기준이 되는 ‘기후변화 현상 사전’을 구축하여 SNS 문서 5만 건을 수집하였다. 그리고 수집된 5만 건을 수작업을 통해 7가지 감성으로 분류하여 감성 태그를 부여하였고, 이렇게 구축된 학습 데이터에 임베딩을 이용한 양방향 장단기 메모리(Bi-LSTM) 알고리듬을 적용하여 감성분류기를 개발하였다. Bi-LSTM을 이용한 감성분류기는 7가지 감성으로 분류했을 때 정확도가 85.10%였으며, 긍정-중립-부정 3가지로 감성을 단순화할 경우에는 정확도가 92.95%까지 향상되었다. 감성분류기의 개발과 더불어 이 연구를 통해 ‘기후변화 현상 사전’을 구축하였고 감성이 분류된 5만 건의 SNS 자료를 축적하였다. 사전 및 감성이 분류된 자료는 감성분류 연구에서 필수적으로 요구되는 도구로서 기후변화와 관련된 이들 도구는 본 연구에서 국내 최초로 구축하였다.‘딥러닝을 이용한 국내 COPD 노인환자의 사망위험 추정’ 연구는 대용량 자료인 건강보험 DB를 사용하는 연구이다. 이 연구는 전처리 단계에 많은 시간이 소요됨을 감안하여 2년에 걸쳐 2단계로 진행한다. 2018년에 추진한 제1단계에서는 입력 데이터를 구축하고, 2019년 진행 예정인 제2단계에서는 제1단계에서 구축한 자료를 이용하여 사망요인을 파악하고 사망 확률을 추정한다. 2018년 본 연구에서는 건강보험 맞춤형 연구자료로부터 추출한 65세 이상 COPD 환자 657,432명의 개인별 건강정보와 각 개인이 거주하는 시군구의 인구, 기상기후요인, 대기오염물질 오염도를 결합한 입력자료를 구축하였다.‘데이터 기반 한강 수질 예측모형 개발’ 연구에서는 순환신경망 모형 중 GRU(Gated Recurrent Unit) 모형을 이용하여 수질오염물질 오염도를 예측하는 알고리듬을 개발하였다. 이 알고리듬을 통해 가양, 노량진, 팔당 등 3개 한강 수계 수질측정소의 클로로필-a 농도를 1주일 전에 예측하는 데 활용되었다. 이 알고리듬은 예측지점 및 예측지점 상류지역의 수질오염 정보, 인근지역의 기상 정보, 그리고 인근지역의 수위 및 유량 정보를 예측에 활용하였다. 이 연구에서 개발한 GRU 알고리듬은 1주일 후 클로로필-a 농도 예측의 평균 제곱근오차를 10.93까지 축소할 수 있었다. 이는 단순회귀분석의 평균제곱근오차 16.95를 35.3% 개선한 성과이다. 특히 순환신경망 알고리듬은 급작스럽게 클로로필-a 농도가 증가하여도 근사한 예측치를 제공하였다. 통상적으로 사용되는 회귀분석 및 시계열 분석은 실측치가 급작스럽게 증가 또는 감소하면 그 증감이 증감시점 이후의 예측치에 반영되는 지연 예측 현상이 나타나는데, 이 연구의 결과는 이러한 회귀분석 및 시계열 분석의 약점을 개선할 수 있는 대안을 제시하였다.‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’ 연구에서는 미세먼지 농도가 서울 지하철 승하차 인원에 미치는 영향을 Boosted Decision Tree 모형을 사용하여 분석 하였다. 이 연구에서는 대기오염물질의 오염도, 그리고 기상 정보를 이용하여 개별 지하철역의 시간별 지하철 승하차 인원을 추정하는 Boosted Decision Tree 알고리듬을 구축하고 민감도 분석을 수행하여 미세먼지 오염도의 변화가 승하차 인원 예측치에 주는 영향을 정량적으로 파악하였다. 이 연구에서 구축한 Boosted Decision Tree 모형은 지하철 승하차 인원을 평균제곱근오차 0.11 이내로 예측할 수 있었다. 이는 선형회귀분석의 평균제곱근 오차 0.71을 84.5%나 개선한 결과이다. 이렇게 예측의 정확도를 높인 Boosted Decision Tree 모형을 사용하여 민감도 분석을 수행한 결과, 미세먼지 농도가 10% 증가하면 하차 인원이 0.2% 감소하고, 미세먼지 농도가 10% 감소하면 하차 인원이 1.4% 증가하는 것으로 파악되었다. 이렇게 미세먼지 농도 증가에 따른 하차 인원 감소가 미세먼지 농도 감소에 따른 하차 인원 증가보다 작은 경향은 승하차 인원, 승하차 시간 및 지하철역 주변 토지용도에 관계없이 일관되게 관찰되었다.두 번째, 2018년 환경 빅데이터 인프라 구축 영역에서는 대용량 자료 수집 및 자료 분석 기능을 구비한 환경 빅데이터 플랫폼을 설계하였고, 이를 1개 서버에 구현하였다. 자료 수집과 관련해서는 오픈데이터맵(Open Data Map)을 구축하여 환경연구 문헌에서 자주 인용되는 인터넷 자료의 검색 및 수집 기능을 부여하였고, 자료 분석과 관련해서는 대용량 자료를 분석할 수 있는 웹 개발 환경과 CLI(Command Line Interface) 환경을 설계하여 동일한 서버에 구현하였다.오픈데이터맵은 환경연구에서 자주 인용되는 온라인 자료들의 출처에 대한 정보와 링크를 제공한다. 본 연구에서 구축한 오픈데이터맵에 수록된 온라인 자료 출처는 2018년 현재 한국환경정책·평가연구원 도서관 DB에 수록된 한국환경정책·평가연구원 발간 문헌 1,925건의 전문에서 인용된 온라인 자료 출처들이다. 이 문헌들은 총 11개 부문(category)으로 분류하였고, 개별 온라인 자료 출처는 그 출처가 인용된 문건을 가장 많이 포괄하는 부문에 따라 부문별로 분류되었다. 각 부문 내에서는 그 부문에 속한 개별 온라인 자료 출처에 인용 문건의 수에 따라 순위를 부여하였고, 인용된 문건의 키워드를 개별 온라인 자료 출처의 키워드로 배정하였다. 오픈데이터맵은 이렇게 구축된 부문별 온라인 자료 출처의 순위, 온라인 주소(URL), 제목, 설명, 키워드를 사용자에게 보여주고 링크를 제공하여 사용자가 필요한 온라인 자료 출처를 찾아갈 수 있도록 하였다. 또한 키워드 검색 기능을 추가하여 부문이 아닌 키워드를 기준으로 자료 출처를 검색할 수도 있게 하였다.대용량 데이터 분석 기능을 갖추기 위해서는 프로그램 개발 언어 중 R과 Python을 사용할 수 있는 웹 환경과 Ubuntu Linux를 사용할 수 있는 CLI 환경을 구성하였다. 웹 환경은 이미 개발된 알고리듬을 웹 환경에 등재하여 분석을 수행하거나, R 또는 Python을 활용해서 알고리듬을 개발하고자 하는 연구자가 사용할 수 있는 환경이다. CLI 환경은 운영체제(Linux) 언어와 프로그램 개발 언어(R, Python)를 자유롭게 조합하여 사용할 수 있는 환경으로서, 데이터 수집-전처리-분석 전 과정을 포괄하는 연구를 수행하고자 하는 연구자가 활용하기에 적합하다. 이러한 분석 환경은 현재 본 연구단이 보유하고 있는 서버에 구현되어 있으며, 본 연구의 연구진들에게 제공되고 있다.마지막으로, 2018년 원내·외 환경 빅데이터 서비스 개발 영역에서는 그동안 한국환경정책·평가연구원에서 발간된 보고서들을 통해 연구주제의 동향을 파악하는 ‘연구동향 분석 서비스’를 개발하였고, 한국환경정책·평가연구원 보고서 제목의 키워드 및 네트워크를 파악하는 ‘연구키워드 분석 서비스’를 개발하였다. 두 서비스 모두 사용자가 임의의 텍스트 자료를 입력하면 입력자료의 토픽 및 키워드 네트워크를 실시간으로 파악할 수 있는 기능을 갖고 있다. 이들 서비스는 2017년 본 연구에서 수행하여 개발한 ‘텍스트 마이닝을 이용한 KEI 연구동향 분석’ 알고리듬을 임의로 입력하는 자료에도 구동될 수 있도록 개선하여 구축한 서비스이다.‘연구동향 분석 서비스’는 LDA 토픽 모델링 기법을 텍스트에 적용하여 텍스트의 주제를 추출하고, 그 결과를 시각화하여 보여주는 서비스이다. 이 서비스는 사용자가 복수의 문서로 구성된 텍스트 자료를 입력하면, 그 자료를 대상으로 LDA 분석을 수행하여 주제를 추출하고 개별 문서에 적합한 주제를 할당한다. LDA 분석에 필요한 텍스트 자료 전처리 과정(형태소 분석, 불용어 제거, 문서-단어 행렬 구축)은 서비스 내부에 구현되어 있어서 텍스트 자료를 입력하면 자동으로 수행된다. 사용자는 텍스트 자료에 수록된 문서의 주제 분포를 전반적으로 파악할 수 있고, 또한 문서 발간 시점의 시계열에 따라 파악할 수 있다. 현재 이 서비스는 1993~2016년에 발간된 한국환경정책·평가연구원 보고서의 제목, 목차, 요약으로 구성된 텍스트 자료의 토픽을 추출한 결과를 보여주고 있다.‘연구키워드 분석 서비스’는 키워드 추출 및 네트워크 파악 기법을 텍스트에 적용하여 키워드를 추출하고, 키워드 동시발생 테이블 및 키워드 네트워크를 구축하는 서비스이다. 이 서비스는 사용자가 텍스트 자료를 입력하면, 그 자료의 단어-단어 동시발생 테이블을 계산하고, Apriori 알고리듬을 수행하여 키워드 네트워크를 도출한다. ‘연구동향 분석 서비스’와 마찬가지로 텍스트 자료 전처리 과정은 서비스 내부에 구현되어서 자료가 입력되면 자동으로 수행된다. 사용자는 키워드 목록 및 2개 키워드 사이의 관계(Support, Confidence, Lift)를 보여주는 테이블과 여러 키워드 간의 네트워크를 시각화한 관계도를 파악할 수 있다. 현재 이 서비스을 통해 2018년 현재 한국환경정책·평가연구원 도서관 DB에 수록된 연구제목 텍스트의 키워드 분석 결과를 볼 수 있다.2018년 본 연구의 결과는 빅데이터 연구방법론의 장점인 예측의 정확도 및 결과의 재생-확장 가능성을 확인시켜 주었다. 본 연구의 환경 빅데이터 연구 영역의 성과는 빅데이터 연구방법론을 적용하면 기존의 방법론보다는 환경오염 및 환경오염 대응 수용체의 반응에 대한 예측오차를 크게 축소할 수 있음을 보여주었다. 특히 데이터의 규모가 1GB를 상회하는 2개 연구 ‘컨벌루션 신경망을 활용한 미세먼지 예측’, ‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’과 추정 대상 변수가 극단적인 값을 갖는 2개 연구 ‘데이터 기반 한강 수질 예측모형 개발’, ‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’에서 이러한 빅데이터 방법론의 예측오차 축소 성과가 두드러지게 나타났다.그리고 본 연구에서 개발한 2개의 연구동향 파악 서비스는 빅데이터 연구방법론과 연구 결과의 재활용 및 확장 가능성을 보여주었다. 2개 서비스 모두 2017년 연구에서 개발되었던 LDA 토픽 추출 알고리듬 및 키워드 파악 알고리듬을 사용하여 구축되었다. 2017년 연구에서는 이들 알고리듬을 특정한 텍스트 분석에서만 사용하였지만, 2018년 연구에서는 이들 알고리듬을 임의의 입력자료에 대해 분석을 수행할 수 있도록 범용성을 확대하였다. 그 결과 기계학습에 관련된 사전지식이 없는 사용자들도 2017년 연구의 성과를 활용할 수 있는 환경이 구축되었다.2018년 연구 중 ‘컨벌루션 신경망을 활용한 미세먼지 예측’ 연구에서 개발한 미세먼지 오염도 예측 알고리듬, ‘데이터 기반 한강 수질 예측모형 개발’ 연구에서 개발한 클로로필-a 농도 예측 알고리듬은 정책수요 파악에 필요한 정보를 제공한다. 이들 알고리듬은 소규모 지역 단위 환경오염 예측치를 실시간으로 제공하기 때문에, 정책대응이 필요한 시점 및 장소를 사전에 인지하여 정책대응 수단을 집중하는 데 필요한 정보를 제공한다. 그리고 ‘기계 학습 기반 환경이슈 감성분류기 개발: 기후변화 중심으로’ 연구에서 개발한 기후변화 관련 SNS 감성분석기는 기후변화 관련 국민 감성을 파악하여 정책 개입의 필요성을 진단하는 도구로 사용할 수 있다.중장기적으로는 이들 3개 알고리듬을 상시 가동할 수 있도록 개편하면 정책의 시행 전후에 이들을 가동함으로써 정책성과를 모니터링할 수 있다. 정책 개입 이전의 2개 예측 알고리듬의 환경오염 예측치는 ‘개입이 없을 경우(Business as usual)’의 예측치를 제공하므로, 이들 예측치와 정책 개입 이후의 실측치를 비교하면 정책 개입의 환경오염 개선 효과에 대한 정량적인 근사치를 얻을 수 있다. 그리고 특정 기후변화 정책 시행 이전과 이후에 기후 변화 관련 SNS 감성분석기를 가동하여 감성 수준을 파악하면, 정책이 국민감성의 호전에 도움이 되었는지 여부를 파악할 수 있다. 3개 알고리듬의 데이터 전처리 과정을 자동화하여 상시적으로 가동할 수 있도록 개편하면 이러한 정책 모니터링을 상시 수행할 수 있다.3년차 이후 본 연구는 이러한 정책 모니터링 기능을 환경정책 전 부문으로 확장하는 방향으로 진행할 예정이다. 구체적으로 환경오염 예측 알고리듬은 대기 및 수질오염 전반을 예측할 수 있는 알고리듬으로 확대 개편하고, SNS 감성분석기 역시 환경정책 전 영역에 대한 감성분석이 가능한 알고리듬으로 확대 개편하고자 한다. 그리고 이들 두 알고리듬을 상시적으로 가동하여 정책수요를 파악하고 정책대응을 모니터링하는 서비스를 개발하고자 한다.","This report reports the result from second year research of ‘Big Data analysis: Application to Environmental Research and Service’ project. In this project, we try to take advantage of machine learning in Environmental Research. This project consists of three sub-projects. The first one ‘Big Data Environment Research’, experiments machine learning algorithm to environmental research. The second one ‘Big Data Research Infra’ builds up large scale data collection and analysis facility. The third one ‘Big Data Environmental Service’ develops public environmental service using the results from ‘Big Data Environmental Research’ and ‘Big Data Research Infra’. We planned to spend three years for each sub-project, beginning from 2017. 2018 is the second year of first sub-project ‘Big Data Environment Research’.In 2018, we developed four machine learning algorithms - CNN algorithm predicting 1~8 hours ahead fine-dust pollution. GRU algorithm predicting 1 week ahead chlorophyl-a pollution. Bidirectional LSTM algorithm for sentiment analysis of climate change SNS data, and Boosted Tree algorithm for analyzing the effect of fine-dust pollution to the number of passengers of Seoul subway. Our sentiment analysis algorithm had 92.95% accuracy. Our CNN algorithm for fine dust pollution prediction cut down RMSE of 1 hour ahead estimation to as low as 2.07μg/㎥. Our GRU algorithm for chlorophyl-a pollution prediction had RMSE smaller than the RMSE of Vector Auto Regression by 35.3%. And our Boosted Tree algorithm for subway passenger analysis had RMSE smaller than the RMSE of linear regression by 84.5%. In general, we confirmed that machine learning algorithm had significant advantage in accurate prediction in wide range of environmental research."
Discriminative context learning with gated recurrent unit for group activity recognition,2018,"['Group activity recognition', 'Sequence modeling', 'Recurrent neural network', 'Gated recurrent unit', 'Data augmentation', 'Video surveillance']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>In this study, we address the problem of similar local motions that create confusion within different group activities. To reduce the influences of motions, we propose a discriminative group context feature (DGCF) that considers prominent sub-events. Moreover, we adopt a gated recurrent unit (GRU) model that can learn temporal changes in a sequence. In real-world scenarios, people perform activities with different temporal lengths. The GRU model handles an arbitrary length of data for training with nonlinear hidden units in the network. However, when we use a deep neural network model, data scarcity causes overfitting problems. Data augmentation methods for images are ineffective for trajectory data augmentation. Thus, we also propose a method for trajectory augmentation. We evaluate the effectiveness of the proposed method on three datasets. In our experiments on each dataset, we show that the proposed method outperforms the competing state-of-the-art methods for group activity recognition.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A novel feature DGCF to represent context information of group activity is proposed and used as input to GRU for sequence modeling. </LI> <LI>  A data augmentation method for trajectory data to reduce overfitting problem in neural network is proposed. </LI> <LI>  Superior performance by using the proposed DGCF and data augmentation method. </LI> </UL> </P>"
한글 음소 단위 딥러닝 모형을 이용한 감성분석,2018,"['Sentiment Analysis', 'Deep Learning', 'Sequential Model', 'Phoneme Unit', 'LSTM', 'GRU']",국문 초록 정보 없음,"Sentiment analysis is a technique of text mining that extracts feelings of the person who wrote the sentence like movie review. The preliminary researches of sentiment analysis identify sentiments by using the dictionary which contains negative and positive words collected in advance. As researches on deep learning are actively carried out, sentiment analysis using deep learning model with morpheme or word unit has been done. However, this model has disadvantages in that the word dictionary varies according to the domain and the number of morphemes or words gets relatively larger than that of phonemes. Therefore, the size of the dictionary becomes large and the complexity of the model increases accordingly.We construct a sentiment analysis model using recurrent neural network by dividing input data into phoneme-level which is smaller than morpheme-level. To verify the performance, we use 30,000 movie reviews from the Korean biggest portal, Naver. Morpheme-level sentiment analysis model is also implemented and compared. As a result, the phoneme- level sentiment analysis model is superior to that of the morpheme-level, and in particular, the phoneme-level model using LSTM performs better than that of using GRU model. It is expected that Korean text processing based on a phoneme-level model can be applied to various text mining and language models."
FastText와 셀프 매칭 어텐션 기반 포인터 네트워크를 이용한 한국어 상호참조해결,2018,"['상호참조해결', '셀프 매칭 어텐션', '포인터 네트워크', 'FastText', 'unknown word', 'coreference resolution', 'self-matching attention', 'pointer networks word']","셀프 매칭 어텐션 메커니즘은 자기 자신에 대한 얼라인먼트 점수를 계산하는 방법이며, 주어진 시퀀스에 대하여 서로 유사한 단어 간의 얼라인먼트 점수가 더 높게 계산되어 상호참조해결에 도움이 될 수 있다. FastText는 입력 단어를 음절 단위 n-gram으로 나누어 학습하는 방법으로, 단어의 변형이 심하거나 단어 사전에 없는 unknown 단어를 처리하는데 적합하다. 본 논문에서는 셀프 매칭 어텐션 매커니즘을 기반으로 한 포인터 네트워크를 상호참조해결에 적용하고, 상호참조해결에서 발생하는 unknown 단어문제를 해결하기 위하여 FastText로 사전 학습한 단어 표현을 사용할 것을 제안한다. 실험 결과, 본 논문에서 제안한 모델 중에서 Self_att_ffnn 모델이 CoNLL F1 (test) 73.55%, Self_att_gru4 모델이 CoNLL F1 (test) 73.60%로 일반 포인터 네트워크보다 각각 2.72%, 1.52%의 성능 향상을 보였다.","Self-matching attention mechanism is a method of calculating an alignment score for oneself, and two sequences applying an attention mechanism are the same sequence. Applying the self-matching attention mechanism to a given sequence, can facilitate solving coreference resolution by calculating higher alignment scores between similar words. FastText is a method to learn an input word by dividing the input word into a character n-gram. The FastText is suitable for dealing with unknown word not in a vocabulary or in a word variant. In this paper, we propose to apply pointer networks based on the self-matching attention mechanism to coreference resolution and to use word embedding pre-trained with FastText to solve an unknown word problem in coreference resolution. As a result, self_att_ffnn model showed 73.55% of CoNLL F1 (test) and self_att_gru4 model showed 73.60% of CoNLL F1 (test) among the proposed models, and models showed a performance improvement of 2.72% and 1.52%, respectively."
내부정보유출 위험등급 판단을 위한 딥 러닝 모델 성능비교에 관한 연구,2018,"['보안', '빅데이터', '보안로그', '이벤트', '내부정보 유출 방지', '위험관리', 'Insider Data Leakage', 'Risk classification', 'Deep Learning', 'Performance Comparison']",국문 초록 정보 없음,"Recently, there has been an increase in the leakage of internal information in the companies. Most of the internal information leakage is caused by insiders. Companies are applying several security solutions to prevent this. However, there is still a lack of research on solutions applying deep learning to detection of data leakage with limitations in preventing leakage in advance. In this paper, a method to judge internal data leakage risk classification is proposed by applying various deep learning models. Security events are generated for each user by mapping the security log and user information obtained through the security device to determine the risk of internal information leakage. Training data based on the mapped data is generated, and applied to deep learning models such as MLP, LSTM, and GRU to compare the performance between models. In addition, the number of hidden nodes and the activation function are changed and their effects are examined. Experimental results showed that the model with softmax activation function applied to the GRU model without dropout showed the highest performance and 93% accuracy."
RNN을 활용한 도시철도 역사 부하 패턴 추정,2018,"['Urban railway station', 'Load pattern', 'Deep learning', 'Recursive neural networks', 'Gated recurrent unit']",국문 초록 정보 없음,"For effective electricity consumption in urban railway station such as peak load shaving, it is important to know each electrical load pattern by various usage. The total electricity consumption in the urban railway substation is already measured in Korea, but the electricity consumption for each usage is not measured. The author proposed the deep learning method to estimate the electrical load pattern for each usage in the urban railway substation with public data such as weather data. GRU (gated recurrent unit), a variation on the LSTM (long short-term memory), was used, which aims to solve the vanishing gradient problem of standard a RNN (recursive neural networks). The optimal model was found and the estimation results with that were assessed."
