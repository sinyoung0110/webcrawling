title,date,keywords,abstract,multilingual_abstract
완전 합성곱 신경망을 활용한 자동 포트홀 탐지 기술의 개발 및 평가,2018,"['포트홀', '도로노면 파손', '의미론적 분할', '심층신경망', '인공지능', '완전 합성곱 신경망', 'Pothole', 'Road surface damage', 'Semantic segmentation', 'Deep neural network', 'AI', 'Fully convolutional neural network']",,
효과적인 입력변수 패턴 학습을 위한 시계열 그래프 기반합성곱 신경망 모형: 주식시장 예측에의 응용,2018,"['기술적 분석가', '딥러닝', '분류기', '주가지수 등락 예측', '합성곱 신경망', 'Classifier', 'Convolutional Neural Network', 'Deep Learning', 'Stock Price Fluctuation Prediction', 'Technical Analyst']","지난 10여 년간 딥러닝(Deep Learning)은 다양한 기계학습 알고리즘 중에서 많은 주목을 받아 왔다. 특히 이미지를 인식하고 분류하는데 효과적인 알고리즘으로 알려져 있는 합성곱 신경망(Convolutional Neural Network, CNN)은 여러 분야의 분류 및 예측 문제에 널리 응용되고 있다. 본 연구에서는 기계학습 연구에서 가장 어려운예측 문제 중 하나인 주식시장 예측에 합성곱 신경망을 적용하고자 한다. 구체적으로 본 연구에서는 그래프를입력값으로 사용하여 주식시장의 방향(상승 또는 하락)을 예측하는 이진분류기로써 합성곱 신경망을 적용하였다. 이는 그래프를 보고 주가지수가 오를 것인지 내릴 것인지에 대해 경향을 예측하는 이른바 기술적 분석가를모방하는 기계학습 알고리즘을 개발하는 과제라 할 수 있다. 본 연구는 크게 다음의 네 단계로 수행된다. 첫 번째 단계에서는 데이터 세트를 5일 단위로 나눈다. 두 번째 단계에서는 5일 단위로 나눈 데이터에 대하여 그래프를 만든다. 세 번째 단계에서는 이전 단계에서 생성된 그래프를 사용하여 학습용과 검증용 데이터 세트를 나누고 합성곱 신경망 분류기를 학습시킨다. 네 번째 단계에서는 검증용 데이터 세트를 사용하여 다른 분류 모형들과 성과를 비교한다. 제안한 모델의 유효성을 검증하기 위해 2009년 1월부터 2017년 2월까지의 약 8년간의KOSPI200 데이터 2,026건의 실험 데이터를 사용하였다. 실험 데이터 세트는 CCI, 모멘텀, ROC 등 한국 주식시장에서 사용하는 대표적인 기술지표 12개로 구성되었다. 결과적으로 실험 데이터 세트에 합성곱 신경망 알고리즘을 적용하였을 때 로지스틱회귀모형, 단일계층신경망, SVM과 비교하여 제안모형인 CNN이 통계적으로 유의한 수준의 예측 정확도를 나타냈다.","Over the past decade, deep learning has been in spotlight among various machine learning algorithms. In particular, CNN(Convolutional Neural Network), which is known as the effective solution for recognizing and classifying images or voices, has been popularly applied to classification and prediction problems. In this study, we investigate the way to apply CNN in business problem solving. Specifically, this study propose to apply CNN to stock market prediction, one of the most challenging tasks in the machine learning research. As mentioned, CNN has strength in interpreting images. Thus, the model proposed in this study adopts CNN as the binary classifier that predicts stock market direction (upward or downward) by using time series graphs as its inputs. That is, our proposal is to build a machine learning algorithm that mimics an experts called 'technical analysts' who examine the graph of past price movement, and predict future financial price movements.Our proposed model named 'CNN-FG(Convolutional Neural Network using Fluctuation Graph)' consists of five steps. In the first step, it divides the dataset into the intervals of 5 days. And then, it creates time series graphs for the divided dataset in step 2. The size of the image in which the graph is drawn is 40 (pixels) × 40 (pixels), and the graph of each independent variable was drawn using different colors.In step 3, the model converts the images into the matrices. Each image is converted into the combination of three matrices in order to express the value of the color using R(red), G(green), and B(blue) scale. In the next step, it splits the dataset of the graph images into training and validation datasets. We used 80% of the total dataset as the training dataset, and the remaining 20% as the validation dataset. And then, CNN classifiers are trained using the images of training dataset in the final step. Regarding the parameters of CNN-FG, we adopted two convolution filters (5 × 5 × 6 and 5 × 5 × 9) in the convolution layer. In the pooling layer, 2 × 2 max pooling filter was used. The numbers of the nodes in two hidden layers were set to, respectively, 900 and 32, and the number of the nodes in the output layer was set to 2(one is for the prediction of upward trend, and the other one is for downward trend). Activation functions for the convolution layer and the hidden layer were set to ReLU(Rectified Linear Unit), and one for the output layer set to Softmax function.To validate our model - CNN-FG, we applied it to the prediction of KOSPI200 for 2,026 days in eight years (from 2009 to 2016). To match the proportions of the two groups in the independent variable (i.e. tomorrow's stock market movement), we selected 1,950 samples by applying random sampling. Finally, we built the training dataset using 80% of the total dataset (1,560 samples), and the validation dataset using 20% (390 samples). The dependent variables of the experimental dataset included twelve technical indicators popularly been used in the previous studies. They include Stochastic %K, Stochastic %D, Momentum, ROC(rate of change), LW %R(Larry William's %R), A/D oscillator(accumulation/distribution oscillator), OSCP(price oscillator), CCI(commodity channel index), and so on. To confirm the superiority of CNN-FG, we compared its prediction accuracy with the ones of other classification models. Experimental results showed that CNN-FG outperforms LOGIT(logistic regression), ANN(artificial neural network), and SVM(support vector machine) with the statistical significance. These empirical results imply that converting time series business data into graphs and building CNN-based classification models using these graphs can be effective from the perspective of prediction accuracy. Thus, this paper sheds a light on how to apply deep learning techniques to the domain of business problem solving."
합성곱 신경망을 이용한 농산물 기사 감성 분석,2018,"['감성분석', '오피니언 마이닝', '텍스트 마이닝', '농산물가격', '합성곱 신경망', 'emotional analysis', 'opinion mining', 'text mining', 'agricultural price', 'convolutional neural networks']","본 논문에서는 농산물 가격의 등락을 기준으로 감성사전을 구축하여 농산물 관련 온라인 뉴스의 긍정/부정을 분류하는 방법을 제안한다. 이를 위해 비정형 텍스트문서를 문장 단위로 분할한 뒤 분석내용과 연관 없거나 가격 등락에 상관없이 빈번하게 언급된 단어들을 불용어로 처리한다. 형태소 분석을 진행한 후 비지도 학습 기반으로 키워드를 추출하여 합성곱 신경망(Convolutional Neural Networks, CNN)을 이용해 긍정/부정 분류를 수행하였다. 그 결과 빈도기반 키워드를 이용한 긍정/부정 분류보다 비지도 학습기반 키워드 추출과 인공신경망의 일종인 합성곱 신경망을 이용했을 때 약 20% 이상 분류 정확도가 향상되었다.","In this paper, we propose a method for sentiment analysis of online news by constructing emotional dictionary base on the fluctuation in prices of various agriculture products. The collected unstructured text data were segmented into sentences and the frequently mentioned words which were not related to price fluctuation were removed as stop words. After the morphological analysis, the keyword was extracted based on the unsupervised learning and the experiments were conducted based on the proposed model using the convolutional neural network (CNN). Consequently, about 20% improvement in accuracy was observed when CNN was used than the word frequency based method."
합성곱 신경망을 사용한 화물차의 차종분류,2018,"['Vehicle Classification', 'Truck Cargo Box', 'Image Classification', 'Convolutional Neural Network', 'Machine Learning', '차종분류', '화물차 적재함', '영상분류', '합성곱 신경망', '기계학습']","본 논문에서는 화물차 차종을 분류하기 위해서 특징추출단계 없이 입력영상으로부터 차종분류결과를 얻을 수 있는 합성곱 신경망을 사용한 분류방법을 제안한다. 차량의 위에서 촬영된 영상을 입력으로 사용하고 입력영상에 적합한 합성곱 신경망의 구조를 설계한다. 차종과 화물칸의 형태에 따라 차종을 자동 분류하기 위한 학습데이터를 생성하고 지도학습의 형태로 학습시키기 위해 분류된 영상과 올바른 출력결과를 제시하여 신경망의 가중치를 학습시킨다. 실제 영상을 입력하여 합성곱 신경망의 출력을 계산하였고 실제 차종과의 비교를 통해 분류 성능을 평가 하였다. 실험결과 화물의 차종과 적재함의 형태에 따라 90%이상의 정확도로 영상을 분류할 수 있었고, 적재불량 검사의 사전 분류에 활용될 수 있다.","This paper proposes a classification method using the Convolutional Neural Network(CNN) which can obtain the type of trucks from the input image without the feature extraction step. To automatically classify vehicle images according to the type of truck cargo box, the top view images of the vehicle are used as input image and we design the structure of the CNN suitable for the input images. Learning images and correct output results is generated and the weights of neural network are obtained through the learning process. The actual image is input to the CNN and the output of the CNN is calculated. The classification performance is evaluated through comparison CNN output with actual vehicle types. Experimental results show that vehicle images could be classified with more than 90 percent accuracy according to the type of cargo box and this method can be used for pre-classification for inspecting loading defect."
합성곱 신경망을 이용한 대장내시경 영상 분류,2018,"['Polyp', '용종', 'Adenomacarcinoma', 'Convolution', 'Neural Network', '선암', '합성곱', '신경망']","대장암 검사의 가장 효과적인 진단 방법은 대장내시경 검사이다. 내시경 검사는 소형 카메라를 통하여 확인되는 대장 내부 영상을 의료인의 육안으로 대장에 돌출한 용종 또는 암으로 성장할 것으로 예측되어지는 용종을 찾아내는방법이다. 사람의 육안을 통하여 검사가 이루어지는 내시경 검사는 컴퓨터의 영상 학습 기술을 통하여 의료인에게도움을 제공할 수 있다. 본 연구에서는 내시경 검사를 보조하기 위하여 정상적인 대장, 선종성 용종, 그리고 선암세 종류로 이루어진 영상 데이터를 분류한다. 제안하는 영상 분류 방법은 심층학습 기반의 영상 분류 기술 중 하나인 합성곱 신경망(Convolutional Neural Networks) 방법을 통한 내시경 영상 분류 방법을 제안한다. 본 연구에서 구성한 합성곱 신경망은 총 34개의 합성곱 계층(Convolution Layer)과 하나의 완전연결계층(Fully Connected Layer)을 이룬다. 실험 결과 총 410개의 테스트 데이터에 대해서 94.39%의 인식률을 보였다.","The most effective method of diagnosing colorectal cancer is colonoscopy. colonoscopy is the process of finding protruding or cancerous polyps in a colon via inspection through an internal video of the colon taken with a small camera. The colonoscopy which is usually diagnosed by human visually, can be improved by adapting computer vision learning technology. In this study, classify the images in normal colon, adenomatous polyps, and adenocarcinoma to aid colonoscopy diagnosing.The use of convolutional neural network, one of the image classification techniques based on deep learning, is suggested as the way to classify the colonoscopy images. The convolutional neural network is constructed with 34 convolutional layers and 1 fully-connected layer. The result of this experiment showed a 94.39% accuracy over 410 tests."
자동 얼굴인식을 위한 얼굴 지역 영역 기반 다중 심층 합성곱 신경망 시스템,2018,"['얼굴인식', '심층 합성곱 신경망', '심층 지역 특징', '가중치 결합', '얼굴 지역 영역', '조인트 베이시안', 'face recognition', 'deep convolutional neural network', 'deep local features', 'weight combination', 'faciallocal region', 'Joint Bayesian']","본 논문에서는 얼굴인식 성능 향상을 위해 얼굴 지역 영역 영상들로 학습된 다중개의 심층 합성곱 신경망(Deep Convolutional Neural Network)으로부터 추출된 심층 지역 특징들(Deep local features)을 가중치를 부여하여 결합하는 방법 을 제안한다. 제안 방법에서는 지역 영역 집합으로 학습된 다중개의 심층 합성곱 신경망으로부터 추출된 심층 지역 특징들 과 해당 지역 영역의 중요도를 나타내는 가중치들을 결합한 특징표현인 ‘가중치 결합 심층 지역 특징’을 형성한다. 일반화 얼굴인식 성능을 극대화하기 위해, 검증 데이터 집합(validation set)을 사용하여 지역 영역에 해당하는 가중치들을 계산하고 가중치 집합(weight set)을 형성한다. 가중치 결합 심층 지역 특징은 조인트 베이시안(Joint Bayesian) 유사도 학습방법과 최근접 이웃 분류기(Nearest Neighbor classifier)에 적용되어 테스트 얼굴영상의 신원(identity)을 분류하는데 활용된다. 제 안 방법은 얼굴영상의 자세, 표정, 조명 변화에 강인하고 기존 최신 방법들과 비교하여 얼굴인식 성능을 향상시킬 수 있음이 체계적인 실험을 통해 검증되었다.","In this paper, we propose a novel face recognition(FR) method that takes advantage of combining weighted deep local features extracted from multiple Deep Convolutional Neural Networks(DCNNs) learned with a set of facial local regions. In the proposed method, the so-called weighed deep local features are generated from multiple DCNNs each trained with a particular face local region and the corresponding weight represents the importance of local region in terms of improving FR performance. Our weighted deep local features are applied to Joint Bayesian metric learning in conjunction with Nearest Neighbor(NN) Classifier for the purpose of FR. Systematic and comparative experiments show that our proposed method is robust to variations in pose, illumination, and expression. Also, experimental results demonstrate that our method is feasible for improving face recognition performance."
딥러닝을 위한 영역기반 합성곱 신경망에 의한 항공영상에서 건물탐지 평가,2018,"['Deep Learning', 'Region-based Convolutional Neural Network', 'Object Detection', 'Semantic Segmentation', '딥러닝', '역기반 합성곱 신경망', '객체탐지', '의미적 분할']","딥러닝은 인간의 학습 및 인지능력을 닮은 인공지능을 실현하기 위해 여러 분야에서 활용하고 있으며, 높은 사양 의 컴퓨팅 파워가 요구되고 연산 시간이 많이 소요되는 복잡한 구조의 인공신경망에 의한 딥러닝은 컴퓨터 사양이 향상됨에 따라 성능이 개선된 다양한 딥러닝 모델이 개발되고 있다. 본 논문의 주요 목적은 상의 딥러닝을 위한 합성곱 신경망 중에서 최근에 FAIR (Facebook AI Research)에서 개발한 Mask R-CNN을 이용하여 항공상에서 건물을 탐지하고 성능을 평가하는 것이다. Mask R-CNN은 역기반의 합성곱 신경망으로서 픽셀 정확도까지 객 체를 의미적으로 분할하기 위한 딥러닝 모델로서 성능이 가장 우수한 것으로 평가받고 있다. 딥러닝 모델의 성능은 신경망 구조뿐 아니라 학습 능력에 의해 결정된다. 이를 위해 본 논문에서는 모델의 학습에 이용한 상에 다양한 변화를 주어 학습 능력을 분석하으며, 딥러닝의 궁극적 목표인 범용화의 가능성을 평가하다. 향후 연구방안으 로는 상에만 의존하지 않고 다양한 공간정보 데이터를 복합적으로 딥러닝 모델의 학습에 이용하여 딥러닝의 신 뢰성과 범용화가 향상될 것으로 판단된다.","DL (Deep Learning) is getting popular in various fields to implement artificial intelligence that resembles human learning and cognition. DL based on complicate structure of the ANN (Artificial Neural Network) requires computing power and computation cost. Variety of DL models with improved performance have been developed with powerful computer specification. The main purpose of this paper is to detect buildings from aerial images and evaluate performance of Mask R-CNN (Region-based Convolutional Neural Network) developed by FAIR (Facebook AI Research) team recently. Mask R-CNN is a R-CNN that is evaluated to be one of the best ANN models in terms of performance for semantic segmentation with pixel-level accuracy. The performance of the DL models is determined by training ability as well as architecture of the ANN. In this paper, we characteristics of the Mask R-CNN with various types of the images and evaluate possibility of the generalization which is the ultimate goal of the DL. As for future study, it is expected that reliability and generalization of DL will be improved by using a variety of spatial information data for training of the DL models."
합성곱 신경망을 통한 강건한 온라인 객체 추적,2018,"['visual tracking', 'convolutional neural network', 'on-line tracking', 'probability map', 'color histogram']","본 논문에서는 객체를 추적하기 위해 합성곱 신경망 모델을 이용한 온라인 추적 기법을 제안한다. 오프라인에 모델을 학습시키기 위해서는 많은 수의 훈련 샘플이 필요하다. 이러한 문제를 해결하기 위해, 학습되지 않은 모델을 사용하고, 실험 영상으로부터 직접 훈련 샘플을 수집하여 모델을 갱신한다. 기존의 방법들은 많은 훈련 샘플을 획득하여 모델의 학습에 사용하였지만, 본 논문에서는 적은 수의 훈련 샘플만으로도 객체의 추적이 가능함을 증명한다. 또한 컬러 정보를 활용하여 새로운 손실 함수를 정의하였고 이로부터 잘못 수집된 훈련 샘플로 인해 모델이 잘못된 방향으로 학습되는 문제를 방지한다. 실험을 통해 4가지 비교 방법과 동등하거나 개선된 추적 성능을 보임을 증명하였다.",
1-Bit 합성곱 신경망을 위한 정확도 향상 기법,2018,"['XNOR Neural Network', '1-Bit Neural Network', 'Quantized Neural Network', 'Convolutional Neural Network', 'Neural Network']",본 논문에서는 기존 1-Bit 합성곱 신경망의 성능 하락에 대한 분석과 이를 완화하기 위한 방안을 제시한다. 기존의 연구는첫 번째 층과 마지막 층만 32-Bit 연산을 적용하고 나머지 연산은 1-Bit 연산을 적용한 것과 달리 본 논문에서는 두 번째 층도 32-Bit로 연산한다. 또한 입력과 가중치를 이진화하고 1-Bit 연산을 적용한 후에는 비선형 활성화 함수를 제거할 수 있음을 제시한다. 본 논문에서 제시한 방법을 검증하기 위해 차량 번호판 검출을 위한 객체 검출 신경망을 실험하였다. 기존의방법으로 학습한 결과보다 정확도가 74%에서 96.1%로 상승하였다.,"In this paper, we analyze the performance degradation of previous 1-Bit convolutional neural network method andintroduce ways to mitigate it. Previous work applies 32-Bit operation to first and last layers. But our method applies32-Bit operation to second layer too. We also show that nonlinear activation function can be removed after binarizinginputs and weights. In order to verify the method proposed in this paper, we experiment the object detection neuralnetwork for korean license plate detection. Our method results in 96.1% accuracy, but the existing method results in 74%accuracy."
쇼크 필터와 합성곱 신경망 기반의 균일 모션 디블러링 기법,2018,"['Deblurring', 'Convolutional Neural Network (CNN)', 'Shock filter', 'Uniform Motion blur', 'Blind deconvolution']",Cho 등의 균일 모션 블러 제거 알고리듬은 영상 내 외곽선 영역을 선명하게 복원하지 못한다는 문제점이 있다. 이러한 문제점을 극복하기 위해 본 논문에서는 한 장의 정지 영상에서 발생하는 블러 (Blur)현상을 블러된 계단형 신호를 뚜렷한 외곽선으로 복원해주는 쇼크 필터 (Shock filter)와 영상에서 특징을 추출하여 학습하는 합성곱 신경망 (Convolutional Neural Network: CNN)을 이용하여 선명한 영상을 복원하고 이 영상으로부터 균일 모션 (Uniform motion) 블러를 측정하여 영상 내 블러 현상을 제거하는 효과적인 알고리듬을 제안하고자 한다. 제안된 알고리듬은 쇼크 필터와 합성곱 신경망을 이용하여 선명한 영상을 복원함으로써 기존 알고리듬의 단점을 개선하였다. 실험 결과를 통해 제안하는 알고리듬이 기존 알고리듬에 비해 객관적 및 주관적인 평가에서 우수한 복원 성능을 나타냄을 확인하였다.,
비전 점유센서를 위한 합성곱 신경망 기반 사람 인식,2018,"['occupancy sensor', 'camera', 'CNN', 'people recognition', 'tracking']",대부분의 건물 등에 설치된 점유센서는 PIR(pyroelectric infra-red)이 주로 활용되고 있다. 하지만 PIR은 온도 변화를 감지하는 기능 때문에 정지된 사람을 감지할 수 없는 단점이 있다. 최근 이 단점을 극복하기 위해 카메라 비전 센서의 연구가 진행되고 있다. 비전 센서는 객체 트랙킹을 통해 정지된 사람을 검출한다. 그러나 객체 트랙킹은 트랙커 표류가 발생하는 문제점이 있다. 본 논문에서는 정지 트랙커가 사람을 포함하는지의 여부를 판단하기 위하여 합성곱 신경망 기반 사람 인식 기법을 제안한다. 실험에서는 카메라로 획득한 영상에 제안 방법을 적용한 결과 약 88%의 정확도로 사람과 비사람이 분류가 되어 실제 점유센서에 활용이 가능하다는 것을 증명하였다.,
합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델,2018,[],,"As urban population increases, research on urban environmental noise is getting more attention. In this study, we classify the abnormal noise occurring in traffic situation by using a deep learning algorithm which shows high performance in recent environmental noise classification studies. Specifically, we classify the four classes of tire skidding sounds, car crash sounds, car horn sounds, and normal sounds using convolutional neural networks. In addition, we add three environmental noises, including rain, wind and crowd noises, to our training data so that the classification model is more robust in real traffic situation with environmental noises. Experimental results show that the proposed traffic sound classification model achieves better performance than the existing algorithms, particularly under harsh conditions with environmental noises."
합성곱 신경망을 이용한 스마트 토이의 음성명령 학습에 관한 연구,2018,"['AI', 'CNN', 'IoT', 'Smart toy', 'Voice command', 'Voice learning']",,"Recently, as the IoT(Internet of Things) and AI(Artificial Intelligence) technologies have developed, smart toys that can understand and act on the language of human beings are being studied. In this paper, we study voice learning using CNN(Convolutional Neural Network) by applying artificial intelligence based voice secretary technology to smart toy. When a human voice command gives, Smart Toy recognizes human voice, converts it into text, analyzes the morpheme, and conducts tagging and voice learning. As a result of test for the simulator program implemented using Python, no malfunction occurred in a single command. And satisfactory results were obtained within the selected simulation condition range."
합성곱 신경망을 활용한 위내시경 이미지 분류에서 전이학습의 효용성 평가,2018,"['Gastroscope', 'Convolutional Neual Network', 'Transfer learning', 'Resnet', 'Inception', 'VGGnet']",,"Stomach cancer is the most diagnosed cancer in Korea. When gastric cancer is detected early, the 5-year survival rate is as high as 90%. Gastroscopy is a very useful method for early diagnosis. But the false negative rate of gastric cancer in the gastroscopy was 4.6~25.8% due to the subjective judgment of the physician. Recently, the image classification performance of the image recognition field has been advanced by the convolutional neural network. Convolutional neural networks perform well when diverse and sufficient amounts of data are supported. However, medical data is not easy to access and it is difficult to gather enough high-quality data that includes expert annotations. So This paper evaluates the efficacy of transfer learning in gastroscopy classification and diagnosis. We obtained 787 endoscopic images of gastric endoscopy at Gil Medical Center, Gachon University. The number of normal images was 200, and the number of abnormal images was 587. The image size was reconstructed and normalized. In the case of the ResNet50 structure, the classification accuracy before and after applying the transfer learning was improved from 0.9 to 0.947, and the AUC was also improved from 0.94 to 0.98. In the case of the InceptionV3 structure, the classification accuracy before and after applying the transfer learning was improved from 0.862 to 0.924, and the AUC was also improved from 0.89 to 0.97. In the case of the VGG16 structure, the classification accuracy before and after applying the transfer learning was improved from 0.87 to 0.938, and the AUC was also improved from 0.89 to 0.98. The difference in the performance of the CNN model before and after transfer learning was statistically significant when confirmed by T-test (p < 0.05). As a result, transfer learning is judged to be an effective method of medical data that is difficult to collect good quality data."
심층 합성곱 신경망을 이용한 교통신호등 인식,2018,"['Traffic Light Recognition', 'Deep Convolutional Neural Network']",,"The color of traffic light is sensitive to various illumination conditions. Especially it loses the hue information when oversaturation happens on the lighting area. This paper proposes a traffic light recognition method robust to these illumination variations. The method consists of two steps of traffic light detection and recognition. It just uses the intensity and saturation in the  first step of traffic light detection. It delays the use of hue information until it reaches to the second step of recognizing the signal of traffic light. We utilized a deep learning technique in the second step. We designed a deep convolutional neural network(DCNN) which is composed of three convolutional networks and two fully connected networks. 12 video clips were used to evaluate the performance of the proposed method. Experimental results show the performance of traffic light detection reporting the precision of 93.9%, the recall of 91.6%, and the recognition accuracy of 89.4%. Considering that the maximum distance between the camera and traffic lights is 70m, the results shows that the proposed method is effective."
ResNet-50 합성곱 신경망을 위한 고정 소수점 표현 방법,2018,['ASIC'],,"Recently, the convolutional neural network shows high performance in many computer vision tasks. However, convolutional neural networks require enormous amount of operation, so it is difficult to adopt them in the embedded environments. To solve this problem, many studies are performed on the ASIC or FPGA implementation, where an efficient representation method is required. The fixed-point representation is adequate for the ASIC or FPGA implementation but causes a performance degradation. This paper proposes a separate optimization of representations for the convolutional layers and the batch normalization layers. With the proposed method, the required bit width for the convolutional layers is reduced from 16 bits to 10 bits for the ResNet-50 neural network. Since the computation amount of the convolutional layers occupies the most of the entire computation, the bit width reduction in the convolutional layers enables the efficient implementation of the convolutional neural networks."
순환 합성곱 신경망를 이용한다채널 뇌파 분석의 간질 발작 탐지,2018,"['recurrent CNN', 'deep learning', 'epileptic seizure detection', 'EEG', 'load balancin and simulation']","본 논문에서는 뇌파 신호를 이용하여 환자의 경련을 감지하는 순환 CNN (Convolutional Neural Networks)을 제안한다.제안 된 방법은 뇌파 신호의 스펙트럼 특성과 전극의 위치를 보존하기 위해 영상으로 데이터를 매핑하여 처리하였다. 스펙트럼 전처리 과정을 거친 후 CNN에 입력하고 공간 및 시간 특성을 웨이블릿 변환(wavelet transform)없이 추출하여 발작을검출하였다. 여기에 사용된 보스턴 매사추세츠 공과 대학 (Boston Massachusetts Institute of Technology, CHB-MIT) 아동병원의 데이터셋 결과는 시간당 0.85의 민감도와 90 %의 위양성 비율 (FPR)을 보였다.","In this paper, we propose recurrent CNN(Convolutional Neural Networks) for detecting seizures among patients usingEEG signals. In the proposed method, data were mapped by image to preserve the spectral characteristics of the EEGsignal and the position of the electrode. After the spectral preprocessing, we input it into CNN and extracted the spatialand temporal features without wavelet transform.Results from the Children's Hospital of Boston Massachusetts Institute of Technology (CHB-MIT) dataset showed asensitivity of 90% and a false positive rate (FPR) of 0.85 per hour."
깊이맵 생성 알고리즘의 합성곱 신경망 구현,2018,"['Depth map', 'CNN', 'Saliency map', 'Motion Hitsory Image', 'Ready-made depth map']",,"Depth map has been utilized in a varity of fields. Recently research on generating depth map by artificial neural network (ANN) has gained much interest. This paper validates the feasibility of implementing the ready-made depth map generation by convolutional neural network (CNN). First, for a given image, a depth map is generated by the weighted average of a saliency map as well as a motion history image. Then CNN network is trained by test images and depth maps. The objective and subjective experiments are performed on the CNN and showed that the CNN can replace the ready-made depth generation method."
점유 센서를 위한 합성곱 신경망과 자기 조직화 지도를 활용한 온라인 사람 추적,2018,"['on-line tracking', 'convolutional neural network', 'self organizing map', 'occupancy sensor']",,"Occupancy sensors installed in buildings and households turn off the light if the space is vacant. Currently PIR(pyroelectric infra-red) motion sensors have been utilized. Recently, the researches using camera sensors have been carried out in order to overcome the demerit of PIR that cannot detect stationary people. The detection of moving and stationary people is a main functionality of the occupancy sensors. In this paper, we propose an on-line human occupancy tracking method using convolutional neural network (CNN) and self-organizing map. It is well known that a large number of training samples are needed to train the model offline. To solve this problem, we use an untrained model and update the model by collecting training samples online directly from the test sequences. Using videos capurted from an overhead camera, experiments have validated that the proposed method effectively tracks human."
구조 인식 심층 합성곱 신경망 기반의 영상 잡음 제거,2018,"['image denoising', 'deep convolutional neural networks', 'feature extraction', 'image filtering']",,"With the popularity of smartphones, most peoples have been using mobile cameras to capture photographs. However, due to insufficient amount of lights in a low lighting condition, unwanted noises can be generated during image acquisition. To remove the noise, a method of using deep convolutional neural networks is introduced. However, this method still lacks the ability to describe textures and edges, even though it has made significant progress in terms of visual quality performance. Therefore, in this paper, the HOG (Histogram of Oriented Gradients) images that contain information about edge orientations are used. More specifically, a method of learning deep convolutional neural networks is proposed by stacking noise and HOG images into an input tensor. Experiment results confirm that the proposed method not only can obtain excellent result in visual quality evaluations, compared to conventional methods, but also enable textures and edges to be improved visually."
단백질 이차 구조 예측을 위한 합성곱 신경망의 구조,2018,[],,"Deep learning has been actively studied for predicting protein secondary structure based only on the sequence information of the amino acids constituting the protein. In this paper, we compared the performances of the convolutional neural networks of various structures to predict the protein secondary structure. To investigate the optimal depth of the layer of neural network for the prediction of protein secondary structure, the performance according to the number of layers was investigated. We also applied the structure of GoogLeNet and ResNet which constitute building blocks of many image classification methods. These methods extract various features from input data, and smooth the gradient transmission in the learning process even using the deep layer. These architectures of convolutional neural networks were modified to suit the characteristics of protein data to improve performance."
기두부와 단 분리 시 조각의 식별을 위한 합성곱 신경망 구조 설계,2018,"['dynamic RCS', 'convolutional neural networks', 'radar target identification', 'warhead', 'debris']",,"In this paper, we designed CNN(Convolutional Neural Network) structure to identify warhead and debris in boosting part separation phase. Through simulation, we determined variables of each layer constituting the CNN and designed CNN structure. Simulation were performed to classify four types of warhead with coning motion and six types of debris with tumbling motion through the CNN designed by the proposed method. Then we compared the performance of CNN with the well-known VGGNet. Simulation results show that the CNN structure optimized by the convolution filter, pooling method, and pooling size determined using the proposed method has equal classification performance or better classification performance than VGGNet for all SNR. In addition, the training time was improved approximately 22 times."
인공신경망 연산에 최적화 된 Switched Capacitor 구조의 저전력 8-bit 합성곱 연산기,2018,"['Switched-Capacitor', 'Convolutional Neural Network', 'Deep Learning']",,
신경망 기반의 유기된 물체 인식 방법,2018,"['deep learning', 'convolutional neural networks', 'difference image', 'abandoned object recognition', 'background estimation']","본 논문에서는 합성곱 신경망을 이용한 유기된 물체 인식 방법을 제안한다. 유기된 물체 인식 방법은 영상 내에서 유기 물체에 대한 영역을 먼저 검출하며 검출된 영역이 있을 경우 해당 영역에 합성곱 신경망을 적용하여 어떤 물체를 나타내는지인식하는 과정을 거친다. 실험은 쓰레기 무단투기를 검출하는 응용 시스템을 통해 진행되었다. 실험 결과, 유기 물체에 대한영역을 효율적으로 검출하는 것을 볼 수 있었다. 검출된 영역은 합성곱 신경망으로 들어가 쓰레기인지 아닌지 분류되는 과정을 거쳤다. 이를 위해 자체적으로 수집한 쓰레기 데이터와 오픈 데이터베이스로 합성곱 신경망을 학습시켰다. 학습 결과, 학습에 포함되지 않은 테스트셋에 대해 약 97%의 정확도를 달성하였다","This paper proposes a method of recognition abandoned objects using convolutional neural networks. The method firstdetects an area for an abandoned object in image and, if there is a detected area, applies convolutional neural networksto that area to recognize which object is represented. Experiments were conducted through an application system thatdetects illegal trash dumping. The experiments result showed the area of abandoned object was detected efficiently. Thedetected areas enter the input of convolutional neural networks and are classified into whether it is a trash or not. Todo this, I trained convolutional neural networks with my own trash dataset and open database. As a training result, Iachieved high accuracy for the test set not included in the training set."
심층신경망 기반 총채벌레 탐색에 관한 연구,2018,"['객체 탐색', '볼록총채벌레', '빠른 지역기반 객체 탐색', '심층신경망', '합성곱 신경망', 'Convolutinal network', 'deep learning', 'Faster R-CNN', 'object detection', 'Scirtothrips dorsalis Hood']","최근 감귤농업에서 주요해층으로 분류되는 미소 객체 (tiny object)인 볼록총채벌레 (Scirtothrips dorsalis Hood)의 탐색은 관심이 많고 어려운 작업으로 알려져 있다. 본 논문에서는 심층신경망을 이용하여 볼록총채벌레를 탐색 (detection)하고자 한다. 분석자료는 황색끈끈이트랩 이미지자료 (250×150mm, 5472×3648픽셀)이며 합성곱 신경망 (convolutional neural network, CNN)인 ResNet을 기반으로 하는 Faster R-CNN (faster regions with CNN) 탐색모형을 사용하였다. 이미지넷(ImageNet)을 사전 학습한 가중치를 사용하고 초모수 (hyperparameter)를 격자탐색법(grid search)으로 선택한 모형을 제안한다. 제안된 모형의 AUC (area under curve)는 0.91로 아주 좋은 결과를 보이는데, 제안된 모형으로 볼록총채벌레의 생태를 파악하여 보다 더 정밀한 방제가 이뤄질 수 있을 것으로 기대한다.","In this paper, we study on a detection of Scirtothrips dorsalis Hood, which is classified as a major insect in citrus farming. The detection is based on the deep neural networks, specifically the Faster R-CNN (faster regions with CNN) model based on CNN (convolutional neural network), with the yellow sticky trap image data (250×150mm, 5472×3648pixels). It was found that the model performance becomes unstable when the object is too small and rare. In order to solve this problem, we use pretrained weights to set the initial value of the model, as well as we select hyperparameters by grid search. Result shows that our proposed model has an high AUC (area under curve) value 0.91. We expect that it would be possible to know more precisely the lifespan of the Scirtothrips dorsalis Hood and to control them more precisely through our proposed model."
메모리 추가 신경망을 이용한 희소 악성코드 분류,2018,"['Malware Classification', 'Visualization', 'Memory Augmented Neural Network']","악성코드의 수가 가파르게 증가하면서 기업 및 공공기관, 금융기관, 병·의원 등을 타깃으로 한 사이버 공격 피해사례가 늘어나고 있다. 이러한 흐름에 따라 학계와 보안 업계에서는 악성코드 탐지를 위한 다양한 연구를 진행하고 있다. 최근 들어서는 딥러닝을 비롯해 머신러닝 기법을 적용하는 형태의 연구가 많이 진행되는 추세다. 이 중 합성곱 신경망(CNN: Convolutional Neural Network), ResNet 등을 이용한 악성코드 분류 연구의 경우에는 기존의 분류 방법에 비해 정확도가 크게 향상된 것을 확인할 수 있다. 그러나 타깃 공격의 특징 중 하나는 사용된 악성코드가 불특정 다수를 상대로 광범위하게 퍼뜨리는 형태가 아닌, 특정 대상을 타깃으로 한 맞춤형 악성코드라는 점이다. 이러한 유형의 악성코드는 그 수가 많지 않기 때문에 기존에 연구되어온 머신러닝이나 딥러닝 기법을 적용하기에 한계가 있다. 본 논문은 타깃형 악성코드와 같이 샘플의 양이 부족한 상황에서 악성코드를 분류하는 방법에 대해 다루고 있다. 메모리가 추가된 신경망(MANN: Memory Augmented Neural Networks) 모델을 이용하였고 각 그룹별 20개의 소량 데이터로 구성되어 있는 악성코드 데이터셋에 대해 최대 97%까지 정확도로 분류할 수있음을 확인하였다.","As the number of malicious code increases steeply, cyber attack victims targeting corporations, public institutions, financial institutions, hospitals are also increasing. Accordingly, academia and security industry are conducting various researches on malicious code detection. In recent years, there have been a lot of researches using machine learning techniques including deep learning. In the case of research using Convolutional Neural Network, ResNet, etc. for classification of malicious code, it can be confirmed that the performance improvement is higher than the existing classification method. However, one of the characteristics of the target attack is that it is custom malicious code that makes it operate only for a specific company, so it is not a form spreading widely to a large number of users. Since there are not many malicious codes of this kind, it is difficult to apply the previously studied machine learning or deep learning techniques. In this paper, we propose a method to classify malicious codes when the amount of samples is insufficient such as targeting type malicious code. As a result of the study, we confirmed that the accuracy of 97% can be achieved even with a small amount of data by applying the Memory Augmented Neural Networks model."
딥러닝 기반 손 제스처 인식을 통한 3D 가상현실 게임,2018,"['손 제스처 인식', '딥러닝', '합성곱 신경망', 'DenseNet', '가상현실', '게임', 'Hand Gesture Recognition', 'Deep Learning', 'Convolutional Neural Network', 'Virtual Reality', 'Game']","가상 환경에서 몰입감을 높이고 자유로운 상호작용을 제공하기 위한 가장 자연스러운 방법은 사용자의 손을 이용한 제스처 인터페이스를 제공하는 것이다. 그러나 손 제스처 인식에 관한 기존의 연구들은 특화된 센서나 장비를 요구하거나 낮은 인식률을 보이는 단점이 있다. 본 논문은 손 제스처 입력을 위한 RGB 카메라 이외 별도 센서나 장비없이 손 제스처 인식이 가능한 3차원 DenseNet 합성곱 신경망 모델을 제안하고 이를 기반으로 한 가상현실 게임을 소개한다. 4개의 정적 손 제스처와 6개의 동적 손 제스처 인터페이스에 대해 실험한 결과 평균 50ms의 속도로 94.2%의 인식률을 보여 가상현실 게임의 실시간 사용자 인터페이스로 사용 가능함을 알 수 있었다. 본 연구의 결과는 게임 뿐 아니라 교육, 의료, 쇼핑 등 다양한 분야에서 손 제스처 인터페이스로 활용될 수 있다.","The most natural way to increase immersion and provide free interaction in a virtual environment is to provide a gesture interface using the user’s hand. However, most studies about hand gesture recognition require specialized sensors or equipment, or show low recognition rates. This paper proposes a three-dimensional DenseNet Convolutional Neural Network that enables recognition of hand gestures with no sensors or equipment other than an RGB camera for hand gesture input and introduces a virtual reality game based on it. Experimental results on 4 static hand gestures and 6 dynamic hand gestures showed that they could be used as real-time user interfaces for virtual reality games with an average recognition rate of 94.2% at 50ms. Results of this research can be used as a hand gesture interface not only for games but also for education, medicine, and shopping."
작성자 분석과 CNN을 적용한 소스 코드 작성자 식별 프레임워크,2018,"['작성자 식별', '작석자 분석', '합성곱 신경망', '기계학습', '코드 분석', 'Author Identification', 'Authorship Analysis', 'Convolutional Neural Network', 'Machine Learning', 'Code Analysis']","최근 인터넷 기술이 발전함에 따라 다양한 프로그램들이 만들어지고 있고 이에 따라 다양한 코드들이 많은 사람들을 통해 만들어진다. 이러한 측면을 이용하여 특정 작성자가 작성한 코드들 그대로 가져가 자신이 작성한 것처럼 보여주거나, 참고한 코드들에 대한 정확한 표기 없이 그대로 사용하여 이에 대한 보호가 점차 어려워지고 있다. 따라서 본 논문에서는 작성자 분석 이론과 합성곱 신경망 기반 자연어 처리 방법을 적용한 작성자 식별 프레임워크룰 제안한다. 작성자 분석 이론을 적용하여 소스 코드에서 작성자 식별에 적합한 특징들을 추출하고 이를 텍스트 마이닝에서 사용하고 있는 특징들과 결합하여 기계학습 기반의 작성자 식별을 수행한다. 그리고 합성곱 신경망 기반 자연어 처리 방법을 소스 코드에 적용하여 코드 작성자 분류를 수행한다. 본 논문에서는 작성자 분석이론과 합성곱 신경망을 적용한 작성자 식별 프레임워크를 통해 작성자를 식별하기 위해서는 작성자 식별만을 위한 특징들이 필요하다는 것과 합성곱 신경망 기반 자연어 처리 방법이 소스 코드등과 같은 특수한 체계를 갖추고 있는 언어에서도 적용이 가능하다. 실험 결과 작성자 분석 이론 기반 작성자 식별 정확도는 95.1%였으며 CNN을 적용한 결과 반복횟수가 90번 이상일 경우 98% 이상의 정확도를 보여줬다.","Recently, Internet technology has developed, various programs are being created and therefore various codes are being made through many authors. On this aspect, some author deceive a program or code written by other particular author as they make it themselves and use other writers' code indiscriminately, or not indicating the exact code which has been used. Due to this makes it more and more difficult to protect the code. In this paper, we propose author identification framework using Authorship Analysis theory and Natural Language Processing(NLP) based on Convolutional Neural Network(CNN). We apply Authorship Analysis theory to extract features for author identification in the source code, and combine them with the features being used text mining to perform author identification using machine learning. In addition, applying CNN based natural language processing method to source code for code author classification. Therefore, we propose a framework for the identification of authors using the Authorship Analysis theory and the CNN. In order to identify the author, we need special features for identifying the authors only, and the NLP method based on the CNN is able to apply language with a special system such as source code and identify the author. identification accuracy based on Authorship Analysis theory is 95.1% and identification accuracy applied to CNN is 98%."
표면근전도 신호를 활용한 한국 숫자지화 인식에서 CNN 학습의 일관성에 관한 연구,2018,"['convolutional neural network', 'time-series signal', 'surface electromyography', 'Korean finger number gesture recognition', 'consistency in cnn learning', 'repeated recognition application']","합성곱 신경망 (Convolutional Neural Network, CNN)은 컴퓨터 비전 분야에서 활발히 적용되어 왔으며, 이미지 분류, 문서 분류, 지문 인식 등에서 탁월한 인식 능력을 보여 왔음을 여러 연구를 통해서 검증되었다. 본 연구는 시계열의 표면근전도 신호를 입력데이터로 취하는 숫자지화 인식 응용에 이미지 분류에서 탁월한 인식 성능을 보이는 합성곱 신경망을 적용한 것으로, 반복적인 한국 숫자지화 인식 수행에서도 일관된 학습을 수행하는지를 검증하는 연구로, 문헌에서 보기 힘든 연구이다. 이를 검증하기 위해, 한국 숫자지화 영(0)부터 다섯(5)까지의 여섯 숫자지화를 시연하도록 훈련한 실험 대상 1인의 아래팔 근육으로부터 획득한 숫자별 60개씩 총 360개의 표면근전도 신호를 획득하였으며, 그 중에서 252개의 표면근전도 신호를 입력데이터, 108개의 표면근전도 신호는 테스트데이터로 CNN 인식에 활용하였다. CNN 인식을 위해 필요한 학습단계는 100 학습단계, CNN 인식의 반복 수행 횟수는 10회로 설정하였으며, 반복 수행마다 테스트데이터를 활용하여 인식률을 계산하였다. 본 연구에서 실험한 결과에서 보듯이, 반복 인식마다 CNN의 학습은 일관되었으며, 99.1% 이상 (60 숫자지화 중 하나의 숫자지화 인식에 오류발생)의 높은 인식률을 보였다. 따라서, CNN 기법은 시계열의 표면근전도 신호를 입력데이터로 하는 숫자지화 인식 분야에서도 전역 솔루션과 함께 우수한 인식 능력을 제공하는 기법 중에 하나이다.","Convolutional Neural Network (CNN) has been actively employed in the application of computer vision, and has been proved to have its superior performance in image classification, document classification, and finger print recognition. This work focuses on an application of CNN, having outstanding performance in image classification, to recognition of korean finger number using time series sEMG signals as input and validates CNN's capability in providing its consistent learning in repeated application for recognition of sEMG based Korean finger numbers, which has been rarely a topic in previous studies. To this end, 252 sEMG signals as input data and 108 sEMG signals as test data out of 360 sEMG signals (60 signals each number) acquired from a forearm muscle of the subject who is trained to consistently perform six Korean finger number gestures from zero(0) to five(5) were used for CNN based finger number recognition. CNN was set to have 100 learning iterations for each application of finger number recognition, and to have 10 repetitive applications of finger number recognition for the consistency of CNN's learning. Recognition rate at each repetition was calculated from test data. As can be seen from the results in this work, CNN shows consistent learning at each repetitive application of finger number recognition and outstanding recognition rates of more than 99.1% (missed one case out of 60 cases). Thus, CNN is one of powerful techniques for finger number recognition based on time-series sEMG signals to provide not only global solution but also excellent recognition rates."
배치 정규화와 CNN을 이용한 개선된 영상분류 방법,2018,"['배치 정규화', '합성곱 신경망', '영상 분류', '딥 러닝', 'Batch Normalization', 'Convolutional Neural Network', 'Image Classification', 'Deep Learning']","딥 러닝은 영상 분류를 위한 여러 방법 중 높은 정확도를 보이는 방법으로 알려져 있다. 본 논문에서는 딥 러닝 방법 가운데 합성곱 신경망 (CNN:Convolutional Neural Network)을 이용하여 영상을 분류함에 있어 배치 정규화 방법이 추가된 CNN을 이용하여 영상 분류의 정확도를 높이는 방법을 제시하였다. 본 논문에서는 영상 분류를 더 정확하게 수행하기 위해 기존의 뉴럴 네트워크에 배치 정규화 계층 (layer)를 추가하는 방법을 제안한다. 배치 정규화는 각 계층에 존재하는 편향을 줄이기 위해 고안된 방법으로, 각 배치의 평균과 분산을 계산하여 이동시키는 방법이다. 본 논문에서 제시된 방법의 우수성을 입증하기 위하여 SHREC13, MNIST, SVHN, CIFAR-10, CIFAR-100의 5개 영상 데이터 집합을 이용하여 영상분류 실험을 하여 정확도와 mAP를 측정한다. 실험 결과 일반적인 CNN보다 배치 정규화가 추가된 CNN이 영상 분류 시 보다 높은 분류 정확도와 mAP를 보임을 확인 할 수 있었다.","Deep learning is known as a method of high accuracy among several methods for image classification. In this paper, we propose a method of enhancing the accuracy of image classification using CNN with a batch normalization method for classification of images using deep CNN (Convolutional Neural Network). In this paper, we propose a method to add a batch normalization layer to existing neural networks to enhance the accuracy of image classification. Batch normalization is a method to calculate and move the average and variance of each batch for reducing the deflection in each layer. In order to prove the superiority of the proposed method, Accuracy and mAP are measured by image classification experiments using five image data sets SHREC13, MNIST, SVHN, CIFAR-10, and CIFAR-100. Experimental results showed that the CNN with batch normalization is better classification accuracy and mAP rather than using the conventional CNN."
MRI 영상의 전처리와 심층학습에 의한 뇌종양 진단보조 시스템 개발,2018,"['뇌종양', 'MRI', '전처리', '심층학습', '합성곱신경망', 'Brain tumor', 'Preprocessing', 'Deep learning', 'Convolutional neural network']","본 논문에서는 MRI 영상의 전처리와 심층학습에 의한 뇌종양 진단을 위한 보조시스템을 개발한다. 여기서 전처리는 DICOM 시스템으로부터 얻어진 MRI 뇌 영상의 이진마스크를 이용해 관심영역을 추출하고, 중간필터와 모폴로지 연산으로 추출된 영역의 잡음을 제거한 후, 크기를 재조정하여 학습부하를 줄인다. 또한 심층학습은 전처리된 영상을 대상으로 합성곱신경망을 이용하여 학습모델을 구현하여 새로이 입력되는 뇌 MRI의 정상과 비정상을 판단한다. 제안된 기법을 T2 MRI 13번째 수평절단 572*816 픽셀의 8비트 RGB 뇌 영상 72개를 대상으로 실험한 결과, 우수한 진단 성능이 있음을 확인할 수 있었다.","This paper presents a diagnostic assistant system of brain tumor by the preprocessing and deep learning of MRI images. The preprocessing extracts the region of interest by using a binary mask, and performs the median filter and morphology operation to remove the noise in MRI brain image, and reduce the learning load by resizing the image. And deep learning is performed on preprocessed images using convolutional neural network, determine the normality and abnormality of the newly entered MRI brain image. The proposed method has been applied to diagnose 8 bits RGB 72-brain MRI images of 572*816 pixels. The experimental results show that the proposed method has an excellent diagnoicst performance."
멀티스케일 및 심층 특징 추출 기반의 가로수종 및 상태 인식,2018,"['Deep Feature', 'Deep Learning', 'Fisher Vector', 'Sparse Coding', 'Gaussian Mixture Model']",,
Object Recognition in Low Resolution Images using a Convolutional Neural Network and an Image Enhancement Network,2018,"['합성곱 신경망', '심층 신경망', '저해상도 영상', '객체 인식', '영상 개선 신경망', 'convolutional neural networks', 'deep neural networks', 'low-resolution images', 'object recognition', 'image enhancement network']",,
고밀도 그리드 모델과 앵커모델을 이용한 동적 객체검지 향상에 관한 연구,2018,"['합성곱 신경망', '차세대 ITS', '안전서비스', '객체 검지', '맹인 및 시각 장애인 보행자', 'CNNs', 'Next generation ITS', 'Safety Service', 'Object Detection', 'BVI pedestrian']",,
Generative Adversarial Networks를 이용한 Face Morphing 기법 연구,2018,"['대립쌍 기계학습', '얼굴합성', '합성곱 신경망', '비지도 학습', 'Generative adversarial network', 'face morphing', 'DCGAN', 'dCNN', 'unsupervised learning']",,"Recently, with the explosive development of computing power, various methods such as RNN and CNN have been proposed under the name of Deep Learning, which solve many problems of Computer Vision have. The Generative Adversarial Network, released in 2014, showed that the problem of computer vision can be sufficiently solved in unsupervised learning, and the generation domain can also be studied using learned generators. GAN is being developed in various forms in combination with various models. Machine learning has difficulty in collecting data. If it is too large, it is difficult to refine the effective data set by removing the noise. If it is too small, the small difference becomes too big noise, and learning is not easy. In this paper, we apply a deep CNN model for extracting facial region in image frame to GAN model as a preprocessing filter, and propose a method to produce composite images of various facial expressions by stably learning with limited collection data of two persons."
비정형 정보와 CNN 기법을 활용한 이진 분류 모델의 고객 행태 예측,2018,"['고객 행태 예측', '합성곱 신경망', '딥러닝', '고객의 소리', 'Customer Behavior Prediction', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Voice of Customer(VOC)']",,"Deep learning is getting attention recently. The deep learning technique which had been applied in competitions of the International Conference on Image Recognition Technology(ILSVR) and AlphaGo is Convolution Neural Network(CNN). CNN is characterized in that the input image is divided into small sections to recognize the partial features and combine them to recognize as a whole. Deep learning technologies are expected to bring a lot of changes in our lives, but until now, its applications have been limited to image recognition and natural language processing.  The use of deep learning techniques for business problems is still an early research stage. If their performance is proved, they can be applied to traditional business problems such as future marketing response prediction, fraud transaction detection, bankruptcy prediction, and so on. So, it is a very meaningful experiment to diagnose the possibility of solving business problems using deep learning technologies based on the case of online shopping companies which have big data, are relatively easy to identify customer behavior and has high utilization values. Especially, in online shopping companies, the competition environment is rapidly changing and becoming more intense. Therefore, analysis of customer behavior for maximizing profit is becoming more and more important for online shopping companies.  In this study, we propose CNN model of Heterogeneous Information Integration using CNN as a way to improve the predictive power of customer behavior in online shopping enterprises. In order to propose a model that optimizes the performance, which is a model that learns from the convolution neural network of the multi-layer perceptron structure by combining structured and unstructured information, this model uses heterogeneous information integration, unstructured information vector conversion, ‘multi-layer perceptron design, and evaluate the performance of each architecture, and confirm the proposed model based on the results. In addition, the target variables for predicting customer behavior are defined as six binary classification problems: re-purchaser, churn, frequent shopper, frequent refund shopper, high amount shopper, high discount shopper.  In order to verify the usefulness of the proposed model, we conducted experiments using actual data of domestic specific online shopping company. This experiment uses actual transactions, customers, and VOC data of specific online shopping company in Korea. Data extraction criteria are defined for 47,947 customers who registered at least one VOC in January 2011 (1 month). The customer profiles of these customers, as well as a total of 19 months of trading data from September 2010 to March 2012, and VOCs posted for a month are used. The experiment of this study is divided into two stages. In the first step, we evaluate three architectures that affect the performance of the proposed model and select optimal parameters. We evaluate the performance with the proposed model.  Experimental results show that the proposed model, which combines both structured and unstructured information, is superior compared to NBC(Naïve Bayes classification), SVM(Support vector machine), and ANN(Artificial neural network). Therefore, it is significant that the use of unstructured information contributes to predict customer behavior, and that CNN can be applied to solve business problems as well as image recognition and natural language processing problems. It can be confirmed through experiments that CNN is more effective in understanding and interpreting the meaning of context in text VOC data. And it is significant that the empirical research based on the actual data of the e-commerce company can extract very meaningful information from the VOC data written in the text format directly by the customer in the prediction of the customer behavior. Finally, through various experiments, it is possible to say that the proposed model"
Multi-sense Word Embedding to Improve Performance of a CNN-based Relation Extraction Model,2018,"['원격 지도학습', '관계추출', '단어 임베딩', '합성곱 신경망', 'distant supervision', 'relation extraction', 'word embedding', 'convolutional neural network']",,
생성 기반 질의응답 채팅 시스템 구현을 위한 지식 임베딩 방법,2018,"['지식 개체 임베딩', '샴 순환 신경망', '생성 기반 채팅 시스템', 'sequence-to-sequence 모델', 'knowledge entity embedding', 'Siamese recurrent neural network', 'generative chat system', 'sequence-to-sequence model']",채팅 시스템은 사람의 말을 기계가 이해하고 적절한 응답을 하는 시스템이다. 채팅 시스템은사용자의 간단한 정보 검색 질문에 대답해야 하는 경우가 있다. 그러나 기존의 생성 채팅 시스템들은 질의응답에 필요한 정보인 지식 개체(트리플 형태 지식에서의 주어와 목적어)의 임베딩을 고려하지 않아 발화에 나타나는 지식 개체가 다르더라도 같은 형태의 답변이 생성되었다. 본 논문에서는 생성 기반 채팅시스템의 질의응답 정확도를 향상시키기 위한 지식 임베딩 방법을 제안한다. 개체와 유의어의 지식 임베딩을 위해 샴 순환 신경망을 사용하며 이를 이용해 주어와 술어를 인코딩 하고 목적어를 디코딩하는 sequence-to-sequence 모델의 성능을 향상 시켰다. 자체 구축한 채팅데이터를 통한 실험에서 제안된 임베딩 방법은 종래의 합성곱 신경망을 통한 임베딩 방법 보다 12.48% 높은 정확도를 보였다.,"A chat system is a computer program that understands user's miscellaneous utterances and generates appropriate responses. Sometimes a chat system needs to answer users’ simple information-seeking questions. However, previous generative chat systems do not consider how to embed knowledge entities (i.e., subjects and objects in triple knowledge), essential elements for question-answering. The previous chat models have a disadvantage that they generate same responses although knowledge entities in users’ utterances are changed. To alleviate this problem, we propose a knowledge entity embedding method for improving question-answering accuracies of a generative chat system. The proposed method uses a Siamese recurrent neural network for embedding knowledge entities and their synonyms. For experiments, we implemented a sequence-to-sequence model in which subjects and predicates are encoded and objects are decoded. The proposed embedding method showed 12.48% higher accuracies than the conventional embedding method based on a convolutional neural network."
Wasserstein Center 손실을 이용한 스케치 기반 3차원 물체 검색,2018,"['Convolutional Neural Network', 'Image retrieval', 'Deep Learning', 'Sketch-based 3D object retrieval', '합성곱 신경망', '영상 검색', '딥 러닝', '스케치 기반 3차원 물체 검색']","스케치 기반 3차원 물체 검색은 다양한 3차원 물체를 사람이 손으로 그린 스케치를 질의(query)로 사용하여 물체를 편리하게 검색하는 방법이다. 본 논문에서는 스케치 기반 3차원 물체 검색을 위해 스케치 CNN(Convolutional Neural Network)과 Wasserstein CNN 모델에 Wasserstein Center 손실을 적용하여 물체의 검색 성공률을 향상시키는 새로운 방법을 제안한다. 제안된 Wasserstein Center 손실이란 각 물체의 클래스(category)의 중심을 학습하고, 동일한 클래스의 특징과 중심 간의 Wasserstein 거리가 작아지도록 만드는 방법이다. 이를 위하여 제안된 3차원 물체 검색은 다음의 단계로 수행된다. 첫 번째로, 3차원 물체의 특징은 3차원 물체를 여러 방향에서 촬영된 2차원 영상의 특징을 CNN을 이용하여 추출하고, 각 영상 특징의 Wasserstein 중심을 계산한다. 두 번째로, 스케치의 특징은 별도의 스케치 CNN을 이용하여 추출하였다. 마지막으로, 추출한 3차원 물체의 특징과 스케치의 특징을 본 논문에서 제안한 Wasserstein Center 손실을 이용하여 학습하고 스케치 기반의 3차원 물체 검색에 적용하였다. 본 논문에서 제안한 방법의 우수성을 입증하기 위하여 SHREC 13과 SHREC 14의 두 가지 벤치마크 데이터 집합을 이용하여 평가하였으며, 제안된 방법이 기존의 스케치 기반 검색방법들과 비교하여 모든 측정 기준에서 우수한 결과를 나타냄을 확인할 수 있었다.","Sketch-based 3D object retrieval is a convenient way to search for various 3D data using human-drawn sketches as query. In this paper, we propose a new method of using Sketch CNN, Wasserstein CNN and Wasserstein center loss for sketch-based 3D object search. Specifically, Wasserstein center loss is a method of learning the center of each object category and reducing the Wasserstein distance between center and features of the same category. To do this, the proposed 3D object retrieval is performed as follows. Firstly, Wasserstein CNN extracts 2D images taken from various directions of 3D object using CNN, and extracts features of 3D data by computing the Wasserstein barycenters of features of each image. Secondly, the features of the sketch are extracted using a separate Sketch CNN. Finally, we learn the features of the extracted 3D object and the features of the sketch using the proposed Wasserstein center loss. In order to demonstrate the superiority of the proposed method, we evaluated two sets of benchmark data sets, SHREC 13 and SHREC 14, and the proposed method shows better performance in all conventional metrics compared to the state of the art methods."
Business Application of Convolutional Neural Networks for Apparel Classification Using Runway Image,2018,"['Convolutional Neural Networks', 'Image Classification', 'Apparel', 'Runway', 'Mobility', '합성곱 신경망', '이미지 분류', '의류', '런웨이', '이동성']",,"Large amount of data is now available for research and business sectors to extract knowledge from it. This data can be in the form of unstructured data such as audio, text, and image data and can be analyzed by deep learning methodology. Deep learning is now widely used for various estimation, classification, and prediction problems. Especially, fashion business adopts deep learning techniques for apparel recognition, apparel search and retrieval engine, and automatic product recommendation. The core model of these applications is the image classification using Convolutional Neural Networks (CNN). CNN is made up of neurons which learn parameters such as weights while inputs come through and reach outputs. CNN has layer structure which is best suited for image classification as it is comprised of convolutional layer for generating feature maps, pooling layer for reducing the dimensionality of feature maps, and fully-connected layer for classifying the extracted features. However, most of the classification models have been trained using online product image, which is taken under controlled situation such as apparel image itself or professional model wearing apparel. This image may not be an effective way to train the classification model considering the situation when one might want to classify street fashion image or walking image, which is taken in uncontrolled situation and involves people’s movement and unexpected pose. Therefore, we propose to train the model with runway apparel image dataset which captures mobility. This will allow the classification model to be trained with far more variable data and enhance the adaptation with diverse query image. To achieve both convergence and generalization of the model, we apply Transfer Learning on our training network. As Transfer Learning in CNN is composed of pre-training and fine-tuning stages, we divide the training step into two. First, we pre-train our architecture with large-scale dataset, ImageNet dataset, which consists of 1.2 million images with 1000 categories including animals, plants, activities, materials, instrumentations, scenes, and foods. We use GoogLeNet for our main architecture as it has achieved great accuracy with efficiency in ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Second, we fine-tune the network with our own runway image dataset. For the runway image dataset, we could not find any previously and publicly made dataset, so we collect the dataset from Google Image Search attaining 2426 images of 32 major fashion brands including Anna Molinari, Balenciaga, Balmain, Brioni, Burberry, Celine, Chanel, Chloe, Christian Dior, Cividini, Dolce and Gabbana, Emilio Pucci, Ermenegildo, Fendi, Giuliana Teso, Gucci, Issey Miyake, Kenzo, Leonard, Louis Vuitton, Marc Jacobs, Marni, Max Mara, Missoni, Moschino, Ralph Lauren, Roberto Cavalli, Sonia Rykiel, Stella McCartney, Valentino, Versace, and Yve Saint Laurent. We perform 10-folded experiments to consider the random generation of training data, and our proposed model has achieved accuracy of 67.2% on final test. Our research suggests several advantages over previous related studies as to our best knowledge, there haven’t been any previous studies which trained the network for apparel image classification based on runway image dataset. We suggest the idea of training model with image capturing all the possible postures, which is denoted as mobility, by using our own runway apparel image dataset. Moreover, by applying Transfer Learning and using checkpoint and parameters provided by Tensorflow Slim, we could save time spent on training the classification model as taking 6 minutes per experiment to train the classifier. This model can be used in many business applications where the query image can be runway image, product image, or street fashion image. To be specific, runway query image can be used for mobile application service during fashion week to facilitate brand search, street style query image"
딥러닝 기반 손상된 흑백 얼굴 사진 컬러 복원,2018,"['Inpainting', 'Colorization', 'Deep Learning', 'BEGAN', 'CNN', '복원', '컬러화', '딥러닝', '경계 평형 생성 적대 네트워크', '합성곱 신경망']","본 논문에서는 손상된 흑백 얼굴 이미지를 컬러로 복원하는 방법을 제안한다. 기존 연구에서는 오래된 증명사진처럼 손상된 흑백 사진에 컬러화 작업을 하면 손상된 영역 주변이 잘못 색칠되는 경우가 있었다. 이와 같은 문제를 해결하기 위해 본 논문에서는 입력받은 사진의 손상된 영역을 먼저 복원한 후 그 결과를 바탕으로 컬러화를 수행하는 방법을 제안한다. 본 논문의 제안 방법은 BEGAN(Boundary Equilibrium Generative Adversarial Networks) 모델 기반 복원과 CNN(Convolutional Neural Network) 기반 컬러화의 두 단계로 구성된다. 제안하는 방법은 이미지 복원을 위해 DCGAN(Deep Convolutional Generative Adversarial Networks) 모델을 사용한 기존 방법들과 달리 좀 더 선명하고 고해상도의 이미지 복원이 가능한 BEGAN 모델을 사용하고, 그 복원된 흑백 이미지를 바탕으로 컬러화 작업을 수행한다. 최종적으로 다양한 유형의 얼굴 이미지와 마스크에 대한 실험 결과를 통해 기존 연구에 비해 많은 경우에 사실적인 컬러 복원 결과를 보여줄 수 있음을 확인하였다.","In this paper, we propose a method to restore corrupted black and white facial images to color. Previous studies have shown that when coloring damaged black and white photographs, such as old ID photographs, the area around the damaged area is often incorrectly colored. To solve this problem, this paper proposes a method of restoring the damaged area of input photo first and then performing colorization based on the result. The proposed method consists of two steps: BEGAN (Boundary Equivalent Generative Adversarial Networks) model based restoration and CNN (Convolutional Neural Network) based coloring. Our method uses the BEGAN model, which enables a clearer and higher resolution image restoration than the existing methods using the DCGAN (Deep Convolutional Generative Adversarial Networks) model for image restoration, and performs colorization based on the restored black and white image. Finally, we confirmed that the experimental results of various types of facial images and masks can show realistic color restoration results in many cases compared with the previous studies."
Generating Pixel Art from Game Characters with Convolutional-Neural Network,2018,"['pixel art', 'deep learning', 'image abstraction', 'non-photorealistic rendering']","픽셀 아트는 낮은 해상도와 제한된 색 팔레트를 가지고 영상을 표현한다. 픽셀 아트는 낮은 연산 성능과 적은 저장 공간을 가지는 초기 컴퓨터 게임에서 주로 사용되었다. 현대에 이르러, 픽셀 아트는 예술이나 퍼즐, 게임과 같은 다양한 분야에서 찾아볼 수 있게 되었다.본 논문에서는 게임 캐릭터 영상을 입력으로 받는 픽셀 아트 생성 모델을 제안한다. 기존 방법과는 달리, 합성곱 신경망(CNN:Convolutional-Neural Network)를 픽셀 아트 생성 목적에 맞게 변형하여 이를 이용하는 방법을 제시한다. 기존의 합성곱 연산 후에 upsampling 과정을 추가하여 픽셀 아트가 생성될 수 있도록 하였다. 네트워크는 ground truth와 생성된 픽셀 아트와의 평균 오차 제곱(MSE:Mean Squared Error)을 최소화해나가며 학습을 수행한다.Ground truth는 실제 아티스트가 생성하도록 하였고, 이미지 회전과 반전 기법을 이용하여 augumentation을 수행하였다. 생성된 데이터 집합은 학습, 검증, 시험 데이터로 나누었다. 이러한 데이터 집합을 기반으로 감독 학습을 실시하여 픽셀 아트 생성 네트워크를 학습하였다. 학습 모델의 학습 과정과 학습 정확도를 제시하고, 시험 데이터 뿐만 아니라 다양한 영상에 대한 픽셀아트 결과도 함께 제시한다.","Pixel art, which presents low-resolutional images with restricted color palette, has been employed frequently in the early computer games played on low memory capacity and computational performance. Recently, pixel art wides its applications to the area such as puzzle and game. In this paper, we present a pixel art generator from images of game characters. Unlike traditional framework, we employ and modify a Convolutional-Neural Network(CNN) to generate pixel art by placing an up-convolution layer after convolution layers. The up-convolution layer increases the resolution of the result images to satisfy user-required resolution. The network is trained by minimizing the Mean Squared Error(MSE) between ground truth images and generated pixel art images from the input high-resolutional image. Also, we employ artists to produce the ground truth of pixel art for our network and augment the data by rotating and fliping. We partition the ground truth images into three datasets: a training, validation and test dataset. With this dataset, we perform a supervised learning and train our network as the pixel art generator. We show a training process and a training accuracy. Moreover, we test our architecture for a various images as well as the test dataset to prove the excellence of our architecture."
단-단계 물체 탐지기 학습을 위한 고난도 예들의 온라인 마이닝,2018,"['단-단계 물체 탐지', '심층 합성 곱 신경망', '온라인 고난도 예 마이닝', '손실 함수']","본 논문에서는 심층 합성 곱 신경망 모델 기반의 단-단계 물체 탐지기들의 탐지 성능을 향상시킬 수 있는 새로운 손실 함수와 온라인 고난도 예 마이닝 방식을 제안한다. 본 논문에서 제안하는 손실 함수와 온라인 고난도 예 마이닝 방식은 물체와 배경 간의 학습 데이터 불균형 문제를 해결할 뿐만 아니라, 각 물체의 위치 추정 정확도를 더 개선시킬 수 있다. 따라서 물체 탐지 속도가 빠른 단-단계 물체 탐지기들에 이-단계 물체 탐지기들과 비슷하거나 더 우수한 탐지 성능을 제공할 수 있다. PASCAL VOC 2007 벤치마크 데이터 집합을 이용한 다양한 실험들을 통해, 본 논문에서 제안하는 손실 함수와 온라인 고난도 예 마이닝 방식이 단-단계 물체 탐지기들의 성능 개선에 도움이 된다는 것을 입증해 보인다.","In this paper, we propose both a new loss function and an online hard example mining scheme for improving the performance of single-stage object detectors which use deep convolutional neural networks. The proposed loss function and the online hard example mining scheme can not only overcome the problem of imbalance between the number of annotated objects and the number of background examples, but also improve the localization accuracy of each object. Therefore, the loss function and the mining scheme can provide intrinsically fast single-stage detectors with detection performance higher than or similar to that of two-stage detectors. In experiments conducted with the PASCAL VOC 2007 benchmark dataset, we show that the proposed loss function and the online hard example mining scheme can improve the performance of single-stage object detectors."
