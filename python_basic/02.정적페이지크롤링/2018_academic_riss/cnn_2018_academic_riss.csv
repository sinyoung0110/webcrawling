title,date,keywords,abstract,multilingual_abstract
표면근전도 신호를 활용한 한국 숫자지화 인식에서 CNN 학습의 일관성에 관한 연구,2018,"['convolutional neural network', 'time-series signal', 'surface electromyography', 'Korean finger number gesture recognition', 'consistency in cnn learning', 'repeated recognition application']","합성곱 신경망 (Convolutional Neural Network, CNN)은 컴퓨터 비전 분야에서 활발히 적용되어 왔으며, 이미지 분류, 문서 분류, 지문 인식 등에서 탁월한 인식 능력을 보여 왔음을 여러 연구를 통해서 검증되었다. 본 연구는 시계열의 표면근전도 신호를 입력데이터로 취하는 숫자지화 인식 응용에 이미지 분류에서 탁월한 인식 성능을 보이는 합성곱 신경망을 적용한 것으로, 반복적인 한국 숫자지화 인식 수행에서도 일관된 학습을 수행하는지를 검증하는 연구로, 문헌에서 보기 힘든 연구이다. 이를 검증하기 위해, 한국 숫자지화 영(0)부터 다섯(5)까지의 여섯 숫자지화를 시연하도록 훈련한 실험 대상 1인의 아래팔 근육으로부터 획득한 숫자별 60개씩 총 360개의 표면근전도 신호를 획득하였으며, 그 중에서 252개의 표면근전도 신호를 입력데이터, 108개의 표면근전도 신호는 테스트데이터로 CNN 인식에 활용하였다. CNN 인식을 위해 필요한 학습단계는 100 학습단계, CNN 인식의 반복 수행 횟수는 10회로 설정하였으며, 반복 수행마다 테스트데이터를 활용하여 인식률을 계산하였다. 본 연구에서 실험한 결과에서 보듯이, 반복 인식마다 CNN의 학습은 일관되었으며, 99.1% 이상 (60 숫자지화 중 하나의 숫자지화 인식에 오류발생)의 높은 인식률을 보였다. 따라서, CNN 기법은 시계열의 표면근전도 신호를 입력데이터로 하는 숫자지화 인식 분야에서도 전역 솔루션과 함께 우수한 인식 능력을 제공하는 기법 중에 하나이다.","Convolutional Neural Network (CNN) has been actively employed in the application of computer vision, and has been proved to have its superior performance in image classification, document classification, and finger print recognition. This work focuses on an application of CNN, having outstanding performance in image classification, to recognition of korean finger number using time series sEMG signals as input and validates CNN's capability in providing its consistent learning in repeated application for recognition of sEMG based Korean finger numbers, which has been rarely a topic in previous studies. To this end, 252 sEMG signals as input data and 108 sEMG signals as test data out of 360 sEMG signals (60 signals each number) acquired from a forearm muscle of the subject who is trained to consistently perform six Korean finger number gestures from zero(0) to five(5) were used for CNN based finger number recognition. CNN was set to have 100 learning iterations for each application of finger number recognition, and to have 10 repetitive applications of finger number recognition for the consistency of CNN's learning. Recognition rate at each repetition was calculated from test data. As can be seen from the results in this work, CNN shows consistent learning at each repetitive application of finger number recognition and outstanding recognition rates of more than 99.1% (missed one case out of 60 cases). Thus, CNN is one of powerful techniques for finger number recognition based on time-series sEMG signals to provide not only global solution but also excellent recognition rates."
딥러닝 기반의 R-CNN을 이용한 악성코드 탐지 기법,2018,"['악성코드 분석', '딥러닝', 'R-CNN', '특징 추출', '이미지 프로세싱', 'Malware', 'Deep learning', 'Regions with CNN', 'Image processing']","최근 기계학습의 발달로 인공지능을 구현하는 머신러닝과 딥러닝 같은 기술이 많은 관심을 받고 있다. 본 논문에서는  딥러닝 기반의 R-CNN을 이용한 바이너리 악성코드를 이미지화 하고 이미지에서 특징을 추출해 패밀리를 분류한다. 본 논문에서는 딥러닝에서 두 단계를 이용해 악성코드를 CNN을 이용해 이미지화하고 ,악성코드의 패밀리가 갖는 특징을 R-CNN을 이용해 분류함으로 악성코드를 이미지화하여 특징을 분류하고 패밀리를 분류한 후 악성코드의 진화를 자동 분류한다. 제안 기법은 검출율이 93.4%로 우수한 탐지 성능을 보였고 정확도는 98.6%로 매우 높은 성능을 보였다. 또한 악성코드를 이미지화 하는 CNN 처리속도가 23.3ms, 하나의 샘플을 분류하기 위해서 R-CNN처리 속도는 4ms로 비교적 빠르게 악성코드를 판별하고 분류가 가능함을 실험을 통해 증명하였다.","Recent developments in machine learning have attracted a lot of attention for techniques such as machine learning and deep learning that implement artificial intelligence. In this paper, binary malicious code using deep learning based R-CNN is imaged and the feature is extracted from the image to classify the family. In this paper, two steps are used in deep learning to image malicious code using CNN. And classify the characteristics of the family of malicious codes using R-CNN. Generate malicious code as an image, extract features, classify the family, and automatically classify the evolution of malicious code. The detection rate of the proposed method is 93.4% and the accuracy is 98.6%. In addition, the CNN processing speed for image processing of malicious code is 23.3 ms, and the R-CNN processing speed is 4ms to classify one sample."
배치 정규화와 CNN을 이용한 개선된 영상분류 방법,2018,"['배치 정규화', '합성곱 신경망', '영상 분류', '딥 러닝', 'Batch Normalization', 'Convolutional Neural Network', 'Image Classification', 'Deep Learning']","딥 러닝은 영상 분류를 위한 여러 방법 중 높은 정확도를 보이는 방법으로 알려져 있다. 본 논문에서는 딥 러닝 방법 가운데 합성곱 신경망 (CNN:Convolutional Neural Network)을 이용하여 영상을 분류함에 있어 배치 정규화 방법이 추가된 CNN을 이용하여 영상 분류의 정확도를 높이는 방법을 제시하였다. 본 논문에서는 영상 분류를 더 정확하게 수행하기 위해 기존의 뉴럴 네트워크에 배치 정규화 계층 (layer)를 추가하는 방법을 제안한다. 배치 정규화는 각 계층에 존재하는 편향을 줄이기 위해 고안된 방법으로, 각 배치의 평균과 분산을 계산하여 이동시키는 방법이다. 본 논문에서 제시된 방법의 우수성을 입증하기 위하여 SHREC13, MNIST, SVHN, CIFAR-10, CIFAR-100의 5개 영상 데이터 집합을 이용하여 영상분류 실험을 하여 정확도와 mAP를 측정한다. 실험 결과 일반적인 CNN보다 배치 정규화가 추가된 CNN이 영상 분류 시 보다 높은 분류 정확도와 mAP를 보임을 확인 할 수 있었다.","Deep learning is known as a method of high accuracy among several methods for image classification. In this paper, we propose a method of enhancing the accuracy of image classification using CNN with a batch normalization method for classification of images using deep CNN (Convolutional Neural Network). In this paper, we propose a method to add a batch normalization layer to existing neural networks to enhance the accuracy of image classification. Batch normalization is a method to calculate and move the average and variance of each batch for reducing the deflection in each layer. In order to prove the superiority of the proposed method, Accuracy and mAP are measured by image classification experiments using five image data sets SHREC13, MNIST, SVHN, CIFAR-10, and CIFAR-100. Experimental results showed that the CNN with batch normalization is better classification accuracy and mAP rather than using the conventional CNN."
Zero-skipping을 적용한 MNIST 분류 CNN 구현,2018,"['GPU', 'MNIST', 'CNN', 'Zero-skipping']","본 논문에서는 zero-skipping을 적용한 MNIST 분류 CNN을 구현했다. CNN의 activation에서 0이 30∼40% 나오고, 0은 MAC연산에 영향을 끼치지 않기 때문에 0을 branch를 통해 skip하게 되면 성능 향상을 시킬 수 있다. 그러나 컨볼루션 레이어에서는branch를 통해 skip하게 되면 성능 하락이 발생한다. 그에 따라 컨볼루션 레이어에서는 연산의 영향을 미치지 않는 NOP을 주어연산을 skip하고 풀리 커넥티드 레이어에서는 branch를 통해 skip했다. 기존의 CNN보다 약 1.5배의 성능 향상을 확인했다","In this paper, MNIST classification CNN with zero skipping is implemented. Activation of CNN results in 30% to 40%zero. Since 0 does not affect the MAC operation, skipping 0 through a branch can improve performance. However, at theconvolution layer, skipping over a branch causes a performance degradation. Accordingly, in the convolution layer, anoperation is skipped by giving a NOP that does not affect the operation. Fully connected layer is skipped through thebranch. We have seen performance improvements of about 1.5 times that of existing CNN."
능동소나 스펙트로그램 이미지와 CNN을 사용한표적/비표적 식별,2018,"['Sonar signal processing', 'Active sonar', 'Target classification', 'Convolutional Neural Networks', 'Spectrogram']","CNN(Convolutional Neural Networks)은 동물의 시각정보처리과정을 모델링한 신경망으로 다양한 분야에서 좋은 성능을보여주고 있다. 본 논문에서는 CNN을 사용하여 능동소나 신호의 스펙트로그램을 분석하고, 표적과 비표적을 식별하는 연구를 수행하였다. 데이터를 표적이 포함된 비율에 따라 8클래스로 구분하고, CNN의 학습에 사용하였다. 신호의 스펙트로그램을 프레임별로 나누어 입력으로 사용한 결과, 표적신호의 위치에서만 표적신호에 해당하는 7개 클래스의 식별 결과가 순차적으로 나타나는 특성을 사용하여 표적과 비표적을 식별해낼 수 있었다.","CNN (Convolutional Neural Networks) is a neural network that models animal visual information processing. And itshows good performance in various fields. In this paper, we use CNN to classify target and non-target data by analyzingthe spectrogram of active sonar signal. The data were divided into 8 classes according to the ratios containing thetargets and used for learning CNN. The spectrogram of the signal is divided into frames and used as inputs. As a result,it was possible to classify the target and non-target using the characteristic that the classification results of the sevenclasses corresponding to the target signal sequentially appear only at the position of the target signal."
작성자 분석과 CNN을 적용한 소스 코드 작성자 식별 프레임워크,2018,"['작성자 식별', '작석자 분석', '합성곱 신경망', '기계학습', '코드 분석', 'Author Identification', 'Authorship Analysis', 'Convolutional Neural Network', 'Machine Learning', 'Code Analysis']","최근 인터넷 기술이 발전함에 따라 다양한 프로그램들이 만들어지고 있고 이에 따라 다양한 코드들이 많은 사람들을 통해 만들어진다. 이러한 측면을 이용하여 특정 작성자가 작성한 코드들 그대로 가져가 자신이 작성한 것처럼 보여주거나, 참고한 코드들에 대한 정확한 표기 없이 그대로 사용하여 이에 대한 보호가 점차 어려워지고 있다. 따라서 본 논문에서는 작성자 분석 이론과 합성곱 신경망 기반 자연어 처리 방법을 적용한 작성자 식별 프레임워크룰 제안한다. 작성자 분석 이론을 적용하여 소스 코드에서 작성자 식별에 적합한 특징들을 추출하고 이를 텍스트 마이닝에서 사용하고 있는 특징들과 결합하여 기계학습 기반의 작성자 식별을 수행한다. 그리고 합성곱 신경망 기반 자연어 처리 방법을 소스 코드에 적용하여 코드 작성자 분류를 수행한다. 본 논문에서는 작성자 분석이론과 합성곱 신경망을 적용한 작성자 식별 프레임워크를 통해 작성자를 식별하기 위해서는 작성자 식별만을 위한 특징들이 필요하다는 것과 합성곱 신경망 기반 자연어 처리 방법이 소스 코드등과 같은 특수한 체계를 갖추고 있는 언어에서도 적용이 가능하다. 실험 결과 작성자 분석 이론 기반 작성자 식별 정확도는 95.1%였으며 CNN을 적용한 결과 반복횟수가 90번 이상일 경우 98% 이상의 정확도를 보여줬다.","Recently, Internet technology has developed, various programs are being created and therefore various codes are being made through many authors. On this aspect, some author deceive a program or code written by other particular author as they make it themselves and use other writers' code indiscriminately, or not indicating the exact code which has been used. Due to this makes it more and more difficult to protect the code. In this paper, we propose author identification framework using Authorship Analysis theory and Natural Language Processing(NLP) based on Convolutional Neural Network(CNN). We apply Authorship Analysis theory to extract features for author identification in the source code, and combine them with the features being used text mining to perform author identification using machine learning. In addition, applying CNN based natural language processing method to source code for code author classification. Therefore, we propose a framework for the identification of authors using the Authorship Analysis theory and the CNN. In order to identify the author, we need special features for identifying the authors only, and the NLP method based on the CNN is able to apply language with a special system such as source code and identify the author. identification accuracy based on Authorship Analysis theory is 95.1% and identification accuracy applied to CNN is 98%."
MLP 층을 갖는 CNN의 설계,2018,"['CNN(Convolutional Neural Network)(컨벌루션 신경망)', 'Deep network(깊은 신경망)', 'MLP(Multi Layer Perceptron)(다층퍼셉트론)']",,"After CNN basic structure was introduced by LeCun in 1989, there has not been a major structure change except for more deep network until recently. The deep network enhances the expression power due to improve the abstraction ability of the network, and can learn complex problems by increasing non linearity. However, the learning of a deep network means that it has vanishing gradient or longer learning time. In this study, we proposes a CNN structure with MLP layer. The proposed CNNs are superior to the general CNN in their classification performance. It is confirmed that classification accuracy is high due to include MLP layer which improves non linearity by experiment. In order to increase the performance without making a deep network, it is confirmed that the performance is improved by increasing the non linearity of the network."
영상 데이터 기반의 CNN을 이용한 제조 공정 데이터 분류 적용에 대한 연구,2018,"['빅데이터', '스마트팩토리', '딥러닝', 'CNN', '텐서플로우', 'Big Data', 'Smart Factory', 'Deep Learning', 'CNN', 'Tensorflow']","빅데이터 기술의 발달로 4차 산업혁명이 시작되면서 스마트 팩토리에 대한 관심이 증가하고 있다. 제조업에서는 여러 종류의 데이터들이 기하급수적으로 증가하고 있지만 관리하기가 어렵고, 데이터가 수집되어도 중요한 데이터를 찾기 힘들뿐더러 어떠한 데이터를 어떻게 사용하여야 할지도 알 수 없다. 또한, 기존의 공정에서는 공정물품에 대해 양품과 불량품만을 구분하여 불량품에 대해 작업자가 직접 눈으로 가성불량품과 불량품을 구별하였다. 이 경우 시간이 오래 걸릴뿐더러 작업자의 상태에 따라 생산성이 낮아지는 현상이 발생한다. 본 논문에서는 이러한 문제점을 해결하기 위해 딥러닝을 이용한 제조 공정 영상을 분류하는 기법을 제안한다. 제안하는 방법은 CNN(Convolutional Nueral Network)를 이용하여 화상검사 공정에서 결과로 나오는 2588*1940 크기의 영상에 대해 양품, 불량품, 가성불량(조명, 퓨즈, 뒤틀림(왜곡))에 대해 학습시켜 분류하고 테스트한다. 그 결과로 양품과 진성불량품에 대해 98% 정확도를 확인하였고, 가성불량에 대해서는 93%의 정확도를 확인할 수 있었다.","Interest in smart factory is increasing with the growth of 4th industrial revolution due to the development of big data technology. Diverse kinds of data in the manufacturing industry are growing exponentially, but it is difficult to manage, and even if the data is collected, it is hard to find important data and find the appropriate way to use the data. In addition, the worker sorted out defective products with the pseudo-defective products only through his/her direct eyes in the original manufacturing process. This takes long time and also is influenced a lot by the individual workers’ capability. In this paper, we propose a manufacturing process image classification methodusing deep learning to solve these problems. The proposed method uses CNN(Convolutional Neural Network) to learn the well-made, defective, and pseudo-defective (lights, fuse, distortion) products with the 2588*1940 size image that comes out as a result in the image inspection process. The outcomes show 98% accuracy in well-made and defective products, and 93% accuracy in pseudodefective products."
CNN과 Grad-CAM 기반의 실시간 화재 감지,2018,"['-', '2']",,"Rapidly detecting and warning of fires is necessary for minimizing human injury and property damage. Generally, when fires occur, both the smoke and the flames are generated, so fire detection systems need to detect both the smoke and the flames. However, most fire detection systems only detect flames or smoke and have the disadvantage of slower processing speed due to additional preprocessing task. In this paper, we implemented a fire detection system which predicts the flames and the smoke at the same time by constructing a CNN model that supports multi-labeled classification. Also, the system can monitor the fire status in real time by using Grad-CAM which visualizes the position of classes based on the characteristics of CNN. Also, we tested our proposed system with 13 fire videos and got an average accuracy of 98.73% and 95.77% respectively for the flames and the smoke."
웨어러블 응용을 위한 CNN 기반 손 제스처 인식,2018,"['MPEG-IoMT', 'Hand Gesture', 'Hand Contour', 'CNN', 'Gesture Recognition']","제스처는 스마트 글라스 등 웨어러블 기기의 NUI(Natural User Interface)로 주목받고 있다. 최근 MPEG에서는 IoT(Internet of Things) 및 웨어러블 환경에서의 효율적인 미디어 소비를 지원하기 위한 IoMT(Internet of Media Things) 표준화를 진행하고 있다. IoMT에서는 손 제스처 검출과 인식이 별도의 기기에서 수행되는 것을 가정하고 이들 모듈간의 인터페이스 규격을 제공하고 있다. 한편, 최근 인식률 개선을 위하여 딥러닝 기반의 손 제스처 인식 기법 또한 활발히 연구되고 있다. 본 논문에서는 IoMT의 유스 케이스(use case)의 하나인 웨어러블 기기에서의 미디어 소비 등 다양한 응용을 위하여 CNN(Convolutional Neural Network) 기반의 손 제스처 인식 기법을 제시한다. 제시된 기법은 스마트 글래스로 획득한 스테레오 비디오로부터 구한 깊이(depth) 정보와 색 정보를 이용하여 손 윤곽선을 검출하고, 검출된 손 윤곽선 영상을 데이터 셋으로 구성하여 CNN을 학습한 후, 이를 바탕으로 입력 손 윤곽선 영상의 제스처를 인식한다. 실험결과 제안기법은 95%의 손 제스처 인식율를 얻을 수 있음을 확인하였다.",
Over blur를 감소시킨 Deep CNN 구현,2018,"['Deep learning', 'Denoising', 'Image processing. Gaussian noise', 'Over blurring']","본 논문에서, Gaussian noise를 제거할 때 발생하는 over blurring 현상을 감소시키는 network를 구현하였다. 기존 filtering방식은 원 영상을 blurring하여 noise를 제거함으로써, edge나 corner 같은 high frequency 성분도 함께 지워지는 것을 확인할 수 있다. CNN (Convolutional Neural Network)기반 denoiser의 경우도 사소한 edge, keypoint를 noise로 인식하여 이러한정보를 잃게 된다. 우리는 CNN을 기반으로 denoising된 high frequency 성분만을 획득하여 기존 denoiser에 추가함으로써denoising 성능을 유지하면서 over blurring을 완화하는 network 제안한다.","In this paper, we have implemented a network that overcomes the over-blurring phenomenon that occurs whenremoving Gaussian noise. In the conventional filtering method, blurring of the original image is performed to removenoise, thereby eliminating high frequency components such as edges and corners. We propose a network that reducingover blurring while maintaining denoising performance by adding denoised high frequency components to denoisers basedon CNN."
CNN과 OpenPose 라이브러리를 활용한 실시간 수화 통역기,2018,"['OpenPose', 'Real-time system', 'Pose detection', 'Sign language']","인공지능 기술이 급속도로 발전하고 있다. 인공지능 기술이 발전함에 따라 많은 기업들이 제품에 인공지능 기술을 탑재하여 출시하고 있다. 인공지능 기술이 포함된 제품이 많아지면서 우리의 삶에 없어서는 안 될 필수요소로 자리잡고 있다. 최근 이러한 인공지능 제품들은 일반인뿐만 아니라 일상생활에 많은 불편함을 느끼는 장애인들을 타깃으로 다양하게 출시되고 있다. 그러나 이러한 제품들은 대부분 시각장애인들을 위해 촉각, 청각에 기반을 둔 개발로 초점이 맞춰져 있다. 따라서 본 논문에서는 CNN을 이용하여 특징을 추출하는 OpenPose 라이브러리와 RNN을 사용하여 청각장애인들을 위한 실시간 수화 번역 프로그램을 제작했다. 수화 번역기의 구현 가능성을 테스트하기 위해 0~9까지 숫자에 대해 테스트를 진행하였고, 그 결과를 손 상단에 출력하였다. 실험 결과 OpenPose를 통해 검출한 신체를 토대로 손의 움직임을 학습하여 수화로 나타내는 숫자를 손 상단에 정확히 출력하는 것을 확인할 수 있었다. 0~9 의 10개의 단어를 이용하여 테스트를 진행하였지만, 자음, 모음 혹은 단어를 학습하게 된다면 실생활에서 이용하는 다양한 문장을 해석할 수 있다. 또한 이는 대화에 어려움을 느끼는 장애인뿐만 아니라 이들과 대화를 함께하는 비장애인들에게도 유용하게 작용되어 장애인과 비장애인 사이의 대화의 벽을 허물 수 있을 것으로 기대된다.","Artificial Intelligent(AI) technology has shown a rapid development in recent years. With such a development, numerous businesses release commercialized devices equipped with AI. As the number of products including AI technology increases, it becomes an indispensable element in our lives. Recently, the AI products have been released in various forms not only for the general consumers but also for the disables who might have some troubles in their daily life. But this kind of products mostly focus on the blinds (and offer support in the matter of the sense of touch and sound.) For this reason, we made a real-time interpreter of sign language for the deaf using OpenPose library which extracts the feature using CNN and RNN. In order to verify its feasibility, we processed a test with the digit 0 to 9 and printed the output above the hand on the screen. As a result, it has been confirmed that our AI is able to accurately recognize each numerical value represented by sign language. If this can also differentiate consonants, vowels, words and even various sentences used in real life, it is expected that this will be worthwhile not only for the disables who have the difficulty in conversation with diverse people, but also for non-disabled people."
딥러닝(CNN)기반 저해상도 IR이미지 분석을 통한 작업자 인식,2018,"['Deep Learning', 'CNN', 'Human error', 'Object detection']","플랜트 내 위험지역의 안전을 위해 작업자 중심의 안전관리가 필요하다. 최근 5년간 가스 사고의 원인은 시설 노후 및 장비고장 뿐만 아니라, 사용자의 취급부주의나 고의사고, 공급자 취급부주의 등 작업자의 행동에 밀접한 관련이 있다. 이와 같은 사고를 미연에 방지하기 위해서, 플랜트 내 위험지역에 대한 실시간 모니터링이필요로 하다. 하지만 실시간 모니터링을 위해서 작업(근로)공간에 카메라 설치 시, 인권침해와 같은 문제가 발생한다. 이를 방지하기 위해서 작업자의 신원 노출이 적은 저해상도의 Infrared 카메라를 이용한다. 또한 실시간모니터링 시, 사람이 아닌 CNN알고리즘을 이용하여 이미지 분석을 통하여 인권침해 문제를 예방한다.",
질감 분석과 CNN을 이용한 잡음에 강인한 돼지 호흡기 질병 식별,2018,"['돼지 호흡기 질병', '잡음 강인성', '소리 분석', 'DNS', 'CNN', 'Porcine Respiratory Diseases', 'Noise Robustness', 'Sound Analysis', 'Dominant Neighborhood Structure', 'Convolutional Neural Network']",,"Automatic detection of pig wasting diseases is an important issue in the management of group-housed pigs. In particular, porcine respiratory diseases are one of the main causes of mortality among pigs and loss of productivity in intensive pig farming. In this paper, we propose a noise-robust system for the early detection and recognition of pig wasting diseases using sound data. In this method, first we convert one-dimensional sound signals to two-dimensional gray-level images by normalization, and extract texture images by means of dominant neighborhood structure technique. Lastly, the texture features are then used as inputs of convolutional neural networks as an early anomaly detector and a respiratory disease classifier. Our experimental results show that this new method can be used to detect pig wasting diseases both economically (low-cost sound sensor) and accurately (over 96% accuracy) even under noise-environmental conditions, either as a standalone solution or to complement known methods to obtain a more accurate solution."
적외선 카메라 영상에서의 마스크 R-CNN기반 발열객체검출,2018,"['Deep Learning', 'Infrared camera', 'Mask R-CNN', 'Image Specification', 'Object Detection', '딥러닝', '열적외선 카메라', 'Mask R-CNN', '이미지 명세화', '객체검출']","최근 비전분야에 소개된 Mask R-CNN은 객체 인스턴스 세분화를위한 개념적으로 간단하고 유연하며 일반적인 프레임 워크를 제시한다. 이 논문에서는 열적외선 카메라로부터 획득한 열감지영상에서 발열체인 인스턴스에 대해 발열부위의 세그멘테이션 마스크를 생성하는 동시에 이미지 내의 오브젝트 발열부분을 효율적으로 탐색하는 알고리즘을 제안한다. Mask R-CNN 기법은 바운딩 박스 인식을 위해 기존 브랜치와 병렬로 객체 마스크를 예측하기 위한 브랜치를 추가함으로써 Faster R-CNN을 확장한 알고리즘이다. Mask R-CNN은 훈련이 간단하고 빠르게 실행하는 고속 R-CNN에 추가된다. 더욱이, Mask R-CNN은 다른 작업으로 일반화하기 용이하다. 본 연구에서는 이 R-CNN기반 적외선 영상 검출알고리즘을 제안하여 RGB영상에서 구별할 수 없는 발열체를 탐지하였다. 실험결과 Mask R-CNN에서 변별하지 못하는 발열객체를 성공적으로 검출하였다.","Recently introduced Mask R - CNN presents a conceptually simple, flexible, general framework for instance segmentation of objects. In this paper, we propose an algorithm for efficiently searching objects of images, while creating a segmentation mask of heat generation part for an instance which is a heating element in a heat sensed image acquired from a thermal infrared camera. This method called a mask R - CNN is an algorithm that extends Faster R - CNN by adding a branch for predicting an object mask in parallel with an existing branch for recognition of a bounding box. The mask R - CNN is added to the high - speed R - CNN which training is easy and fast to execute. Also, it is easy to generalize the mask R - CNN to other tasks. In this research, we propose an infrared image detection algorithm based on R - CNN and detect heating elements which can not be distinguished by RGB images. As a result of the experiment, a heat-generating object which can not be discriminated from Mask R-CNN was detected normally."
R-CNN 기법을 이용한 건물 벽 폐색영역 추출 적용 연구,2018,"['3D Spatial information', 'Occlusion area', 'Deep-learning', 'R-CNN', '3차원 공간정보', '폐색영역', '딥러닝', 'R-CNN']","3차원 공간정보 구축을 위해 건물 텍스처를 촬영하는 과정에서 폐색영역 문제가 발생한다. 이를 해결하기 위해선 폐색영역을 자동 인식하여 이를 검출하고 텍스처를 자동 보완하는 자동화 기법 연구가 필요하다. 현실적으로 매우 다양한 구조물 형상과 폐색을 발생시키는 경우가 있으므로 이를 극복하는 대안들이 고려되고 있다. 본 연구는 최근 대두되고 있는 딥러닝 기반의 알고리즘을 이용하여 폐색지역 패턴화하고, 학습기반 폐색영역 자동 검출하는 접근을 시도한다. 영상 내 객체 추출에서 우수한 성과를 발표하는 Convolutional Neural Network (CNN) 기법의 향상된 알고리즘인 Faster Region-based Convolutional Network (R-CNN)과 Mask R-CNN 2가지를 이용하여, 건물 벽면 촬영 시 폐색을 유발하는 사람, 현수막, 차량, 신호등에 대한 자동 탐지하는 성능을 알아보기 위해 실험하고, Mask R-CNN의 미리 학습된 모델에 현수막을 학습시켜 자동탐지하는 실험을 통해 적용이 높은 결과를 확인할 수 있었다.","For constructing three-dimensional (3D) spatial information occlusion region problem arises in the process of taking the texture of the building. In order to solve this problem, it is necessary to investigate the automation method to automatically recognize the occlusion region, issue it, and automatically complement the texture. In fact there are occasions when it is possible to generate a very large number of structures and occlusion, so alternatives to overcome are being considered. In this study, we attempt to apply an approach to automatically create an occlusion region based on learning by patterning the blocked region using the recently emerging deep learning algorithm. Experiment to see the performance automatic detection of people, banners, vehicles, and traffic lights that cause occlusion in building walls using two advanced algorithms of Convolutional Neural Network (CNN) technique, Faster Region-based Convolutional Neural Network (R-CNN) and Mask R-CNN. And the results of the automatic detection by learning the banners in the pre-learned model of the Mask R-CNN method were found to be excellent."
CNN 기법에 의한 손글씨 인식 파라미터 연구,2018,"['딥러닝', 'CNN', '훈련 옵션', '손글씨', '학습층', '파라미터', 'deep learning', 'CNN', 'training options', 'handwriting', 'learning layer', 'parameter']","딥러닝을 위한 CNN 기술은 의학, 농업, 항공 및 자동차 산업 전반에 걸쳐 연구, 개발되고 있다. 또한 콘크리트 균열이나 강철 용접 결함과 같은 건설 분야에도 적용할 수 있다. 본 연구에서는 건설분야에 적용하기에 앞서, 이전 연구를 발전시키고 CNN 기법을 사용하여 손으로 쓴 이미지의 분류를 분석하였다. 딥러닝은 일반적으로 학습층의 깊이가 깊을수록 정확도가 높아지지만 분석 시간이 오래 걸리는 단점이 있다. 또한 훈련 옵션에 따라 많은 변화가 발생할 수 있다. 따라서, 많은 파라미터연구를 수행했고 학습 계층이 더욱더 깊어질 때 분석을 수행하였다.","CNN techniques for deep learning are being studied and developed throughout the medical, agricultural, aviation, and automotive industries. It can be also applied to construction fields such as concrete cracks and steel welding defects. In this study, we upgraded the previous study and analyzed the classification of handwritten images using CNN technique before applying them to construction field. Deep learning is generally more accurate with deeper and deeper layers, but analysis cost is high. In addition, many variations can occur depending on training options.Therefore, we performed many parametric studies and analyzed when the learning layer is deeper."
한국 전통문화 말뭉치구축 및 Bi-LSTM-CNN-CRF를 활용한 전통문화 개체명 인식 모델 개발,2018,"['개체명 인식', '전통문화', '말뭉치', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Traditional culture', 'Corpus', 'Deep Learning', 'feature augmentation']","개체명 인식(Named Entity Recognition)시스템은 문서로부터 고유한 의미를 가질 수 있는 인명(PS), 지명(LC), 기관명(OG) 등의 개체명을 추출하고 추출된 개체명의 범주를 결정하는 시스템이다. 최근 딥러닝 방식을 이용한 개체명 인식 연구에서 입력 데이터의 앞, 뒤 방향을 고려한 LSTM 기반의 Bi-LSTM 모델로부터 출력 데이터 간의 전이 확률을 이용한 CRF를 결합한 방식의 Bi-LSTM-CRF가 우수한 성능을 보이고, 문자 및 단어 단위의 효율적인 임베딩 벡터생성에 관한 연구와 CNN, LSTM을 활용한 모델에서도 좋은 성능을 보여주고 있다. 본 연구에서는 한국어 개체명 인식시스템 성능 향상을 위해 자질을 보강한 Bi-LSTM-CNN-CRF 모델에 관해 기술하고 전통문화 말뭉치구축 방식에 대해 제안한다. 그리고 구축한 말뭉치를 한국어 개체명 인식 성능 향상을 위한 자질 보강 모델 Bi-LSTM-CNN-CRF로 학습한 결과에 대해 제안한다.","Named Entity Recognition is a system that extracts entity names such as Persons(PS), Locations(LC), and Organizations(OG) that can have a unique meaning from a document and determines the categories of extracted entity names. Recently, Bi-LSTM-CRF, which is a combination of CRF using the transition probability between output data from LSTM-based Bi-LSTM model considering forward and backward directions of input data, showed excellent performance in the study of object name recognition using deep-learning, and it has a good performance on the efficient embedding vector creation by character and word unit and the model using CNN and LSTM. In this research, we describe the Bi-LSTM-CNN-CRF model that enhances the features of the Korean named entity recognition system and propose a method for constructing the traditional culture corpus. We also present the results of learning the constructed corpus with the feature augmentation model for the recognition of Korean object names."
Faster R-CNN과 이미지 오그멘테이션 기법을 이용한 화염감지에 관한 연구,2018,"['Artificial intelligency', 'Deep leaning', 'Object detection', 'Faster R-CNN', 'Image augmentation']","최근 딥러닝(deep learning) 인공지능 기반의 컴퓨터 비전 분야는 각종 영상분석 분야에서 화제로 떠오르고 있다. 본 연구에서는 딥러닝 기반의 여러 이미지 인식 알고리즘 중 이미지 내에서 객체를 검출하는 데 사용되는 Faster R-CNN 알고리즘을 이용하여 화재 이미지에서 불꽃을 검출하고자 한다. 학습 과정에서 소량의 데이터셋을 통한 화재검출 정확도 향상을 위해이미지 오그멘테이션(image augmentation) 기법을 이용하고, 이미지 오그멘테이션을 6가지 유형별로 나누어 학습하여 정확도, 정밀도, 검출률을 비교하였다. 그 결과, 이미지 오그멘테이션의 종류가 늘어날수록 검출률이 상승하지만, 다른 객체 검출모델들의 일반적인 정확도와 검출률의 관계와 마찬가지로 오검출율 또한 10%에서 최대 30%까지 증가하게 됨을 확인하였다","Recently, computer vision field based deep learning artificial intelligence has become a hot topic among various imageanalysis boundaries. In this study, flames are detected in fire images using the Faster R-CNN algorithm, which is usedto detect objects within the image, among various image recognition algorithms based on deep learning. In order toimprove fire detection accuracy through a small amount of data sets in the learning process, we use image augmentationtechniques, and learn image augmentation by dividing into 6 types and compare accuracy, precision and detection rate.As a result, the detection rate increases as the type of image augmentation increases. However, as with the generalaccuracy and detection rate of other object detection models, the false detection rate is also increased from 10% to 30%."
Binary Hashing CNN Features for Action Recognition,2018,"['Action Recognition', 'CNN Feature', 'Binary Hashing', 'Feature Normalization']",,"The purpose of this work is to solve the problem of representing an entire video using Convolutional Neural Network (CNN) features for human action recognition. Recently, due to insufficient GPU memory, it has been difficult to take the whole video as the input of the CNN for end-to-end learning. A typical method is to use sampled video frames as inputs and corresponding labels as supervision. One major issue of this popular approach is that the local samples may not contain the information indicated by the global labels and sufficient motion information. To address this issue, we propose a binary hashing method to enhance the local feature extractors. First, we extract the local features and aggregate them into global features using maximum/minimum pooling. Second, we use the binary hashing method to capture the motion features. Finally, we concatenate the hashing features with global features using different normalization methods to train the classifier. Experimental results on the JHMDB and MPII-Cooking datasets show that, for these new local features, binary hashing mapping on the sparsely sampled features led to significant performance improvements."
지역적 가중치 파라미터 제거를 적용한 CNN 모델 압축,2018,[],,"CNN requires a large amount of computation and memory in the process of extracting the feature of the object. Also, It is trained from the network that the user has configured, and because the structure of the network is fixed, it can not be modified during training and it is also difficult to use it in a mobile device with low computing power. To solve these problems, we apply a pruning method to the pre-trained weight file to reduce computation and memory requirements. This method consists of three steps. First, all the weights of the pre-trained network file are retrieved for each layer. Second, take an absolute value for the weight of each layer and obtain the average. After setting the average to a threshold, remove the weight below the threshold. Finally, the network file applied the pruning method is re-trained. We experimented with LeNet-5 and AlexNet, achieved 31x on LeNet-5 and 12x on AlexNet."
CNN Model to Classify Malware Using Image Feature,2018,[],"인터넷에 발생하는 악성코드는 매우 심각한 위협 요소이며, 악성코드를 이용한 공격이 전 세계적으로 전파되며 심지어 점점 더 지능적으로 변조되고 있다. 그러므로 악성코드를 정확하게 탐지 하는 방법이 중요하다. 지금까지 널리 알려진 악성코드 대응방법은 악성코드를 탐지하여 삭제하거나 혹은 치료한다고 알고 있다. 이러한 악성코드를 탐지하기 위하여 악성코드에 따른 분류를 하여야 한다. 악성코드를 잘 분류하는 것은 알려진 악성코드를 더 잘 탐지할 수 있다는 것과 같다. 기존 연구들을 보면 같은 카테고리에 속하는 악성코드는 치료방법이 비슷하게 보이는 경향이 있다는 것을 입증한다. 그리고 많은 새로운 악성코드들이 기존에 있던 악성코드로부터 만들어진다는 것을 증명한다. 따라서 악성코드를 종류에 따라서 분류하는 것은 탐지하는 것 못지않게 아주 중요한 작업이다. 그러므로 멀웨어 분류 기술이 절실히 요구된다. 본 논문에서는 주어진 종류에 따라 악성코드를 분류하기 위한 컨볼루션 인공신경망 모델을 구축한다. 이 모델은 9,500 개의 악성코드 데이터 셋을 25 개의 종류로 분류하는 실험에서 98%의 정확도를 보인다. 본 연구의 목적은 다음 목표로 더 많은 양의 악성코드 파일에 적용되며 더 높은 정확도를 보이는 것이다.",
영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구,2018,"['Fire Detection', 'Deep Learning', 'Kernel Size', 'Stride', '화재 검출', '심층학습', '커널 크기', '이동 간격']","본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와  이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다.","In this paper, a deep learning method is proposed to detect fire effectively using video of surveillance camera.  Based on AlexNet model, classification performance is compared according to kernel size and stride of convolution layer. Dataset for learning and inference are classified into two classes as normal and fire. Normal images are inlcude clouds and foggy and fire images include smoke and flames, respectively. As results of simulations, it is shown that the larger kernel size and smaller stride shows better performance"
CNN을 이용한 거리 사진의 분류와 안전도 평가,2018,"['CNN', 'street photo', 'classification', 'safety score']",,"CNN (convolution neural network) has become the most popular artificial intelligence technique and shows remarkable performance in image classification task. In this paper, we propose a CNN-based classification method for various street images as well as a method of evaluating the safety score for the street. The proposed method consists of learning four types of street images using CNN and classifying input street images using the learned CNN model followed by evaluating the safety score. During the learning process, four types of street images are collected and augmented, and then CNN learning is performed. It is shown that learned CNN model classifies input images correctly and the safety scores are evaluated quantitatively by combining the probabilities of different street types."
전처리와 특징 추출이 CNN기반 화재 탐지 성능에 미치는 효과,2018,"['화재 탐지', '딥러닝', 'CNN', '전처리', '특징 추출', 'Fire Detection', 'Deep Learning', 'Preprocessing', 'Feature Extraction']","최근 들어 머신 러닝 기술의 발달로 기존 영상 기반의 응용시스템에 딥러닝 기술을 적용하는 사례들이 늘고 있다. 이러한 맥락에서 화재 감지 분야에서도 CNN (Convolutional Neural Network)을 적용하는 시도들이 이루어지고 있다. 본 논문에서는 기존 전처리 방법과 특징 추출 방법이 CNN과 결합되었을 때 화재 탐지에 어떤 효과를 유발하는지를 검증하기 위해 인식 성능과 학습 시간을 평가해 보았다. VGG19 CNN 구조를 변경, 즉 컨볼루션층을 조금씩 늘리면서 실험을 진행한 결과, 일반적으로 전처리하지 않는 이미지를 사용한 경우가 성능이 훨씬 좋음을 확인할 수 있었다. 또한 성능적인 측면에서는 전처리 방법과 특징 추출 방법이 부정적인 영향을 미치지만 학습속도 측면에서는 많은 이득이 있음을 확인할 수 있었다.","Recently, the development of machine learning technology has led to the application of deep learning technology to existing image based application systems. In this context, some researches have been made to apply CNN (Convolutional Neural Network) to the field of fire detection. To verify the effects of existing preprocessing and feature extraction methods on fire detection when combined with CNN, in this paper, the recognition performance and learning time are evaluated by changing the VGG19 CNN structure while gradually increasing the convolution layer. In general, the accuracy is better when the image is not preprocessed. Also it’s shown that the preprocessing method and the feature extraction method have many benefits in terms of learning speed."
배경 차분과 CNN 기반의 CCTV 객체 검출,2018,"['Convolutional Neural Network', '배경차분', '객체 검출', 'CCTV', 'background subtraction', 'object detection']","본 연구는 영상 분석에서 최근 좋은 연구 성과를 내고 있는 컨볼루션 신경망 (Convolutional Neural Network: CNN) 기법을 실외 CCTV 영상 분석에 적용하여 객체 유형을 분류하는 방법론은 제안한다. 배경 차분 (background subtraction)을 사용하여 찾고자 하는 객체 후보들을 추출해내고 이를 CNN을 이용해 분류함으로써 계산량을 줄이는 효과를 얻는 방법이다. CNN 학습용 CCTV 영상 수집을 위해 범죄 발생이 주로 일어나는 골목길, 놀이터 등에서 촬영한 CCTV 영상 DB를 구축하였으며 우선적으로 사람인 객체만 검출하는 분류기를 학습하였다. 다양한 학습 데이터 사이즈와 세팅에 맞게 실험하였으며 실험 결과 약 80%의 분류 정확도를 보였으며 새로운 CCTV 영상으로 테스트했을 때 약 67.5%의 성능을 보였다.","In this paper, a method to classify objects in outdoor CCTV images using Convolutional Neural Network(CNN) and background subtraction is proposed. Object candidates are extracted using background subtraction and they are classified with CNN to detect objects in the image. At the end, computation complexity is highly reduced in comparison to other object detection algorithms. A database is constructed by filming alleys and playgrounds, places where crime occurs mainly. In experiments, different image sizes and experimental settings are tested to construct a best classifier detecting person. And the final classification accuracy became 80% for same camera data and 67.5% for a different camera."
CNN을 이용한 딥러닝 기반 하수관 손상 탐지 분류 시스템,2018,"['딥러닝', 'CNN', 'CCTVs', '인공지능', '손상 탐지', '하수관', 'Artificial Intelligence', 'Deep Learning', 'Demage Detection', 'Sewer Inspection']","연구는 인공지능 분야의 딥러닝 기술을 기반으로 한 하수관 손상의 자동 탐지 분류 시스템을 제안한다. 성능의 최적화를 위하여 DB 획득 시 발생된 조도 및 그림자 변화와 같은 다양한 환경변화에 강인한 시스템을 구현하였다. 제안된 시스템에서는 Convolutional Neural Network(CNN) 기반의 균열 탐지 및 손상 분류 기법을 구현하였다. 최적의 결과를 위하여 256 x 256 픽셀 해상도의 CCTV 영상 9,941개를 이용하여 CNN모델을 적용하여 손상부위에 대한 딥러닝을 수행하였고 그 결과 98.76 %의 인식률을 획득하였다. 기계학습을 통한 딥러닝 모델을 기반으로 다양한 환경의 하수도 DB에서 720 x 480 픽셀 해상도의 646개의 이미지를 추출하여 성능 평가를 수행 하였다. 본 시스템은 다양한 환경에서 구축된 하수관 데이터베이스 에서 손상 유형의 자동 탐지 및 분류에 최적화된 인식률을 제시한다.","We propose an automatic detection and classification system of sewer damage database based on artificial intelligence and deep learning. In order to optimize the performance, we implemented a robust system against various environmental variations such as illumination and shadow changes. In our proposed system, a crack detection and damage classification method using a deep learning based Convolutional Neural Network (CNN) is implemented. For optimal results, 9,941 CCTV images with 256 x 256 pixel resolution were used for machine learning on the damaged area based on the CNN model. As a result, the recognition rate of 98.76% was obtained. Total of 646 images of 720 x 480 pixel resolution were extracted from various sewage DB for performance evaluation. Proposed system presents the optimal recognition rate for the automatic detection and classification of damage in the sewer DB constructed in various environments."
SPAD과 CNN의 특성을 반영한 ToF 센서와 스테레오 카메라 융합 시스템,2018,"['Sensor Fusion', 'Time-of-Flight', 'Stereo camera', 'Single Photon Avalanche Diodes', 'Convolution Neural Network']",,"3D depth perception has played an important role in robotics, and many sensory methods have also proposed for it. As a photodetector for 3D sensing, single photon avalanche diode (SPAD) is suggested due to sensitivity and accuracy. We have researched for applying a SPAD chip in our fusion system of time-of-fight (ToF) sensor and stereo camera. Our goal is to upsample of SPAD resolution using RGB stereo camera. Currently, we have 64 x 32 resolution SPAD ToF Sensor, even though there are higher resolution depth sensors such as Kinect V2 and Cube-Eye. This may be a weak point of our system, however we exploit this gap using a transition of idea. A convolution neural network (CNN) is designed to upsample our low resolution depth map using the data of the higher resolution depth as label data. Then, the upsampled depth data using CNN and stereo camera depth data are fused using semi-global matching (SGM) algorithm. We proposed simplified fusion method created for the embedded system."
A Study on CNN based Production Yield Prediction Algorithm for Increasing Process Efficiency of Biogas Plant,2018,"['Biogas', 'Biogas plant', 'CNN', 'Production yield']",,"Recently, as the demand for limited resources continues to rise and problems of resource depletion rise worldwide, the importance of renewable energy is gradually increasing. In order to solve these problems, various methods such as energy conservation and alternative energy development have been suggested, and biogas, which can utilize the gas produced from biomass as fuel, is also receiving attention as the next generation of innovative renewable energy. New and renewable energy using biogas is an energy production method that is expected to be possible in large scale because it can supply energy with high efficiency in compliance with energy supply method of recycling conventional resources. In order to more efficiently produce and manage these biogas, a biogas plant has emerged. In recent years, a large number of biogas plants have been installed and operated in various locations. Organic wastes corresponding to biogas production resources in a biogas plant exist in a wide variety of types, and each of the incoming raw materials is processed in different processes. Because such a process is required, the case where the biogas plant process is inefficiently operated is continuously occurring, and the economic cost consumed for the operation of the biogas production relative to the generated biogas production is further increased. In order to solve such problems, various attempts such as process analysis and feedback based on the feedstock have been continued but it is a passive method and very limited to operate a medium/large scale biogas plant. In this paper, we propose ""CNN-based production yield prediction algorithm for increasing process efficiency of biogas plant"" for efficient operation of biogas plant process. Based on CNN-based production yield forecasting, which is one of the deep-leaning technologies, it enables mechanical analysis of the process operation process and provides a solution for optimal process operation due to process-related accumulated data analyzed by the automated process."
CNN을 적용한 한국어 상품평 감성분석,2018,"['감성분석', '형태소 벡터', '단어 벡터', '딥러닝', 'CNN', 'CBOW', 'Sentiment Analysis', 'Morpheme Vector', 'Word Vector', 'Deep Learning', 'CNN', 'CBOW']",,"With the increasing importance of sentiment analysis to grasp the needs of customers and the public, various types of deep learning models have been actively applied to English texts. In the sentiment analysis of English texts by deep learning, natural language sentences included in training and test datasets are usually converted into sequences of word vectors before being entered into the deep learning models. In this case, word vectors generally refer to vector representations of words obtained through splitting a sentence by space characters. There are several ways to derive word vectors, one of which is Word2Vec used for producing the 300 dimensional Google word vectors from about 100 billion words of Google News data. They have been widely used in the studies of sentiment analysis of reviews from various fields such as restaurants, movies, laptops, cameras, etc.  Unlike English, morpheme plays an essential role in sentiment analysis and sentence structure analysis in Korean, which is a typical agglutinative language with developed postpositions and endings. A morpheme can be defined as the smallest meaningful unit of a language, and a word consists of one or more morphemes. For example, for a word 예쁘고, the morphemes are 예쁘(= adjective) and 고(=connective ending). Reflecting the significance of Korean morphemes, it seems reasonable to adopt the morphemes as a basic unit in Korean sentiment analysis. Therefore, in this study, we use morpheme vector as an input to a deep learning model rather than word vector which is mainly used in English text. The morpheme vector refers to a vector representation for the morpheme and can be derived by applying an existent word vector derivation mechanism to the sentences divided into constituent morphemes.  By the way, here come some questions as follows. What is the desirable range of POS(Part-Of-Speech) tags when deriving morpheme vectors for improving the classification accuracy of a deep learning model? Is it proper to apply a typical word vector model which primarily relies on the form of words to Korean with a high homonym ratio? Will the text preprocessing such as correcting spelling or spacing errors affect the classification accuracy, especially when drawing morpheme vectors from Korean product reviews with a lot of grammatical mistakes and variations?  We seek to find empirical answers to these fundamental issues, which may be encountered first when applying various deep learning models to Korean texts. As a starting point, we summarized these issues as three central research questions as follows. First, which is better effective, to use morpheme vectors from grammatically correct texts of other domain than the analysis target, or to use morpheme vectors from considerably ungrammatical texts of the same domain, as the initial input of a deep learning model? Second, what is an appropriate morpheme vector derivation method for Korean regarding the range of POS tags, homonym, text preprocessing, minimum frequency? Third, can we get a satisfactory level of classification accuracy when applying deep learning to Korean sentiment analysis?  As an approach to these research questions, we generate various types of morpheme vectors reflecting the research questions and then compare the classification accuracy through a non-static CNN(Convolutional Neural Network) model taking in the morpheme vectors. As for training and test datasets, Naver Shoppings 17,260 cosmetics product reviews are used. To derive morpheme vectors, we use data from the same domain as the target one and data from other domain; Naver shoppings about 2 million cosmetics product reviews and 520,000 Naver News data arguably corresponding to Google’s News data.  The six primary sets of morpheme vectors constructed in this study differ in terms of the following three criteria. First, they come from two types of data source; Naver news of high grammatical correctness and Naver shopping’s cosme"
CNN-LSTM Coupled Model for Prediction of Waterworks Operation Data,2018,"['Big Data', 'CNN', 'Correlation Analysis', 'Deep-Learning', 'LSTM']",,"In this paper, we propose an improved model to provide users with a better long-term prediction ofwaterworks operation data. The existing prediction models have been studied in various types of models suchas multiple linear regression model while considering time, days and seasonal characteristics. But the existingmodel shows the rate of prediction for demand fluctuation and long-term prediction is insufficient.Particularly in the deep running model, the long-short-term memory (LSTM) model has been applied topredict data of water purification plant because its time series prediction is highly reliable. However, it isnecessary to reflect the correlation among various related factors, and a supplementary model is needed toimprove the long-term predictability. In this paper, convolutional neural network (CNN) model is introducedto select various input variables that have a necessary correlation and to improve long term prediction rate,thus increasing the prediction rate through the LSTM predictive value and the combined structure. Inaddition, a multiple linear regression model is applied to compile the predicted data of CNN and LSTM,which then confirms the data as the final predicted outcome."
CNN-LSTM Coupled Model for Prediction of Waterworks Operation Data,2018,"['Big Data', 'CNN', 'Correlation Analysis', 'Deep-Learning', 'LSTM']",,"In this paper, we propose an improved model to provide users with a better long-term prediction of waterworks operation data. The existing prediction models have been studied in various types of models such as multiple linear regression model while considering time, days and seasonal characteristics. But the existing model shows the rate of prediction for demand fluctuation and long-term prediction is insufficient. Particularly in the deep running model, the long-short-term memory (LSTM) model has been applied to predict data of water purification plant because its time series prediction is highly reliable. However, it is necessary to reflect the correlation among various related factors, and a supplementary model is needed to improve the long-term predictability. In this paper, convolutional neural network (CNN) model is introduced to select various input variables that have a necessary correlation and to improve long term prediction rate, thus increasing the prediction rate through the LSTM predictive value and the combined structure. In addition, a multiple linear regression model is applied to compile the predicted data of CNN and LSTM, which then confirms the data as the final predicted outcome."
CNN 기반 서명인식에서 시간정보를 이용한 위조판별 성능 향상,2018,"['CNN', '서명인식', '위조판별', 'Signature Recognition', 'Fake Discrimination']",,"In this paper, we propose a method for more accurate fake discrimination using time information in CNN-based signature recognition. To easily use the time information and not to be influenced by the speed of signature writing, we acquire the signature as a movie and divide the total time of the signature into equal numbers of equally spaced intervals to obtain each image and synthesize them to create signature data. In order to compare the method using the proposed signature image and the method using only the last signature image, various signature recognition methods based on CNN have been experimented in this paper. As a result of experiment with 25 signature data, we found that the method using time information improves performance in fake discrimination compared to the existing method at all experiments."
A Study on CNN based Production Yield Prediction Algorithm for Increasing Process Efficiency of Biogas Plant,2018,"['Biogas', 'Biogas plant', 'CNN', 'Production yield']",,"Recently, as the demand for limited resources continues to rise and problems of resource depletion rise worldwide, the importance of renewable energy is gradually increasing. In order to solve these problems, various methods such as energy conservation and alternative energy development have been suggested, and biogas, which can utilize the gas produced from biomass as fuel, is also receiving attention as the next generation of innovative renewable energy. New and renewable energy using biogas is an energy production method that is expected to be possible in large scale because it can supply energy with high efficiency in compliance with energy supply method of recycling conventional resources. In order to more efficiently produce and manage these biogas, a biogas plant has emerged. In recent years, a large number of biogas plants have been installed and operated in various locations. Organic wastes corresponding to biogas production resources in a biogas plant exist in a wide variety of types, and each of the incoming raw materials is processed in different processes. Because such a process is required, the case where the biogas plant process is inefficiently operated is continuously occurring, and the economic cost consumed for the operation of the biogas production relative to the generated biogas production is further increased. In order to solve such problems, various attempts such as process analysis and feedback based on the feedstock have been continued but it is a passive method and very limited to operate a medium/large scale biogas plant. In this paper, we propose ""CNN-based production yield prediction algorithm for increasing process efficiency of biogas plant"" for efficient operation of biogas plant process. Based on CNN-based production yield forecasting, which is one of the deep-leaning technologies, it enables mechanical analysis of the process operation process and provides a solution for optimal process operation due to process-related accumulated data analyzed by the automated process."
2D LiDAR 센서를 이용한 CNN 기반 군집 로봇의 위치 인식 및 제어,2018,"['Multi robot', 'Localization', 'LiDAR', 'Image processing', 'CNN']",,
SPAD과 CNN의 특성을 반영한 ToF 센서와 스테레오카메라 융합 시스템,2018,"['Sensor Fusion', 'Time-of-Flight', 'Stereo camera', 'Single Photon Avalanche Diodes', 'Convolution Neural Network']",,"3D depth perception has played an important role in robotics, and many sensory methods have also proposed for it. As a photodetector for 3D sensing, single photon avalanche diode (SPAD) is suggested due to sensitivity and accuracy. We have researched for applying a SPAD chip in our fusion system of time-of-fight (ToF) sensor and stereo camera. Our goal is to upsample of SPAD resolution using RGB stereo camera. Currently, we have 64 x 32 resolution SPAD ToF Sensor, even though there are higher resolution depth sensors such as Kinect V2 and Cube-Eye. This may be a weak point of our system, however we exploit this gap using a transition of idea. A convolution neural network (CNN) is designed to upsample our low resolution depth map using the data of the higher resolution depth as label data. Then, the upsampled depth data using CNN and stereo camera depth data are fused using semi-global matching (SGM) algorithm. We proposed simplified fusion method created for the embedded system."
Mixed-LGP와 해마 구조를 적용한 CNN을 이용한 얼굴검출 알고리즘 연구,2018,"['LBP', 'LGP', 'multi-feature channel', 'symmetry', 'uniform', 'hippocampus', 'CNN']",,"A precise preprocessing process is required for more accurate face recognition. The preprocessing process is based on LGP(Local Gradient Pattern), which is robust against external influences such as illumination, facial expression, and background, rather than the existing LBP(Local Binary Pattern). We use uniform features and multi-feature channel based on Gradient, Orientations, Intensity, and Edge to better locate facial features in LGP-based algorithms. Symmetry features are used to speed up complex patterns by reducing them. In this paper, we propose an algorithm that uses CNN (Convolution Neural Network) applied hippocampal structure for more accurate face Detection. We used Yale face data base, BioID face data base, and MU + MIT date base to evaluate the performance of the proposed algorithm. Experimental results show that the algorithm is improved by 3 ~ 9%."
CNN을 이용한 음성 데이터 성별 및 연령 분류 기술 연구,2018,"['voice', 'classification', 'neural network', 'deep learning', 'classification', 'CNN']",,"Research is carried out to categorize voices using Deep Learning technology. The study examines neural networkbased sound classification studies and suggests improved neural networks for voice classification. Related studies studied urban data classification. However, related studies showed poor performance in shallow neural network. Therefore, in this paper the first preprocess voice data and extract feature value. Next, Categorize the voice by entering the feature value into previous sound classification network and proposed neural network. Finally, compare and evaluate classification performance of the two neural networks. The neural network of this paper is organized deeper and wider so that learning is better done. Performance results showed that 84.8 percent of related studies neural networks and 91.4 percent of the proposed neural networks. The proposed neural network was about 6 percent high."
CNN과 가이드 영상을 이용한 세포핵 검출,2018,"['Semantic segmentation', 'Nuclei', 'Medical image', 'Guide image']",,
CNN을 이용한 능동 소나 표적/비표적 분류,2018,"['Convolutional Neural Networks', 'Active Sonar Classification', 'Spectrogram', 'Target/Non-target']",,
Multi-sense Word Embedding to Improve Performance of a CNN-based Relation Extraction Model,2018,"['원격 지도학습', '관계추출', '단어 임베딩', '합성곱 신경망', 'distant supervision', 'relation extraction', 'word embedding', 'convolutional neural network']",,
A Study of Facial Organs Classification System Based on Fusion of CNN Features and Haar-CNN Features,2018,"['AlexNet', 'CNN', 'softmax classifier', 'Haar-CNN', 'image classification']",,"In this paper, we proposed a method for effective classification of eye, nose, and mouth of human face. Most recent image classification uses Convolutional Neural Network(CNN). However, the features extracted by CNN are not sufficient and the classification effect is not too high. We proposed a new algorithm to improve the classification effect. The proposed method can be roughly divided into three parts. First, the Haar feature extraction algorithm is used to construct the eye, nose, and mouth dataset of face. The second, the model extracts CNN features of image using AlexNet. Finally, Haar-CNN features are extracted by performing convolution after Haar feature extraction. After that, CNN features and Haar-CNN features are fused and classify images using softmax. Recognition rate using mixed features could be increased about 4% than CNN feature. Experiments have demonstrated the performance of the proposed algorithm."
CNN 구조의 진화 최적화 방식 분석,2018,"['Convolutional neural network', 'Optimization', 'Genetic algorithm', 'Cartesian genetic programming']",,"Recently, some meta-heuristic algorithms, such as GA(Genetic Algorithm) and GP(Genetic Programming), have been used to optimize CNN(Convolutional Neural Network). The CNN, which is one of the deep learning models, has seen much success in a variety of computer vision tasks. However, designing CNN architectures still requires expert knowledge and a lot of trial and error. In this paper, the recent attempts to automatically construct CNN architectures are investigated and analyzed. First, two GA based methods are summarized. One is the optimization of CNN structures with the number and size of filters, connection between consecutive layers, and activation functions of each layer. The other is an new encoding method to represent complex convolutional layers in a fixed-length binary string, Second, CGP(Cartesian Genetic Programming) based method is surveyed for CNN structure optimization with highly functional modules, such as convolutional blocks and tensor concatenation, as the node functions in CGP. The comparison for three approaches is analysed and the outlook for the potential next steps is suggested."
초고속 R-CNN을 이용한 얼굴영상에서 눈 및 입술영역 검출방법,2018,"['딥러닝', '고속 R-CNN', '눈 및 입술영역 검출', '영상인식', 'Deep Learning', 'faster R-CNN', 'Eye and Lip Detection', 'Image Recognition']","얼굴인식, 홍채인식과 같은 생체보안 분야에서 눈, 코, 입술 등 얼굴특징을 추출하는 과정은 필수적이다. 본 논문은 초고속(faster) R-CNN을 이용하여 얼굴영상에서 눈 및 입술영역을 검출하는 방법을 연구하였다. 초고속 R-CNN은 딥러닝 을 이용한 물체검출 방법으로 기존의 특징기반 방법에 비해 성능이 우수한 것으로 알려져 있다. 본 논문에서는 얼굴영상에 콘볼루션, 선형정류과정, max pooling과정을 차례로 적용하여 특징맵을 추출하고 이로부터 제안영역(region proposal)을 검 출하는 RPN(region proposal network)을 학습한다. 그리고 제안영역과 특징맵을 이용하여 눈 및 입술 검출기(detector)를 학습한다. 제안방법의 성능을 검토하기 위해 남녀한국인 얼굴영상 800장으로 실험하였다. 학습을 위해 480장을 이용했으며 테스트용으로 320장을 사용하였다. 컴퓨터모의 실험결과 눈 및 입술영역 검출의 평균정확도는 50 에포치일 때 각각 97.7%, 91.0%를 얻을 수 있었다.","In the field of biometric security such as face and iris recognition, it is essential to extract facial features such as eyes and lips. In this paper, we have studied a method of detecting eye and lip region in face image using faster R-CNN. The faster R-CNN is an object detection method using deep running and is well known to have superior performance compared to the conventional feature-based method. In this paper, feature maps are extracted by applying convolution, linear rectification process, and max pooling process to facial images in order. The RPN(region proposal network) is learned using the feature map to detect the region proposal. Then, eye and lip detector are learned by using the region proposal and feature map. In order to examine the performance of the proposed method, we experimented with 800 face images of Korean men and women. We used 480 images for the learning phase and 320 images for the test one. Computer simulation showed that the average precision of eye and lip region detection for 50 epoch cases is 97.7% and 91.0%, respectively."
비정형 정보와 CNN 기법을 활용한 이진 분류 모델의 고객 행태 예측,2018,"['고객 행태 예측', '합성곱 신경망', '딥러닝', '고객의 소리', 'Customer Behavior Prediction', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Voice of Customer(VOC)']",,"Deep learning is getting attention recently. The deep learning technique which had been applied in competitions of the International Conference on Image Recognition Technology(ILSVR) and AlphaGo is Convolution Neural Network(CNN). CNN is characterized in that the input image is divided into small sections to recognize the partial features and combine them to recognize as a whole. Deep learning technologies are expected to bring a lot of changes in our lives, but until now, its applications have been limited to image recognition and natural language processing.  The use of deep learning techniques for business problems is still an early research stage. If their performance is proved, they can be applied to traditional business problems such as future marketing response prediction, fraud transaction detection, bankruptcy prediction, and so on. So, it is a very meaningful experiment to diagnose the possibility of solving business problems using deep learning technologies based on the case of online shopping companies which have big data, are relatively easy to identify customer behavior and has high utilization values. Especially, in online shopping companies, the competition environment is rapidly changing and becoming more intense. Therefore, analysis of customer behavior for maximizing profit is becoming more and more important for online shopping companies.  In this study, we propose CNN model of Heterogeneous Information Integration using CNN as a way to improve the predictive power of customer behavior in online shopping enterprises. In order to propose a model that optimizes the performance, which is a model that learns from the convolution neural network of the multi-layer perceptron structure by combining structured and unstructured information, this model uses heterogeneous information integration, unstructured information vector conversion, ‘multi-layer perceptron design, and evaluate the performance of each architecture, and confirm the proposed model based on the results. In addition, the target variables for predicting customer behavior are defined as six binary classification problems: re-purchaser, churn, frequent shopper, frequent refund shopper, high amount shopper, high discount shopper.  In order to verify the usefulness of the proposed model, we conducted experiments using actual data of domestic specific online shopping company. This experiment uses actual transactions, customers, and VOC data of specific online shopping company in Korea. Data extraction criteria are defined for 47,947 customers who registered at least one VOC in January 2011 (1 month). The customer profiles of these customers, as well as a total of 19 months of trading data from September 2010 to March 2012, and VOCs posted for a month are used. The experiment of this study is divided into two stages. In the first step, we evaluate three architectures that affect the performance of the proposed model and select optimal parameters. We evaluate the performance with the proposed model.  Experimental results show that the proposed model, which combines both structured and unstructured information, is superior compared to NBC(Naïve Bayes classification), SVM(Support vector machine), and ANN(Artificial neural network). Therefore, it is significant that the use of unstructured information contributes to predict customer behavior, and that CNN can be applied to solve business problems as well as image recognition and natural language processing problems. It can be confirmed through experiments that CNN is more effective in understanding and interpreting the meaning of context in text VOC data. And it is significant that the empirical research based on the actual data of the e-commerce company can extract very meaningful information from the VOC data written in the text format directly by the customer in the prediction of the customer behavior. Finally, through various experiments, it is possible to say that the proposed model"
금속 표면의 결함 검출을 위한 영역 기반 CNN 기법 비교,2018,"['Defects detection', 'Metal surface', 'Convolution neural network', 'Faster R-CNN', 'YOLOv2']",,"A machine vision based industrial inspection includes defects detection and classification. Fast inspection is a fundamental problem for many applications of real-time vision systems. It requires little computation time and localizing defects robustly with high accuracy. Deep learning technique have been known not to be suitable for real-time applications. Recently a couple of fast region-based CNN algorithms for object detection are introduced, such as Faster R-CNN, and YOLOv2. We apply these methods for an industrial inspection problem. Three CNN based detection algorithms, VOV based CNN, Faster R-CNN, and YOLOv2, are experimented for defect detection on metal surface. The results for inspection time and various performance indices are compared and analysed."
초음파 영상에서 질병 추출을 위한Keras 기반의 CNN 모델,2018,"['CNN', '간이미지', '의료초음파', '이미지분류', '케라스', 'Liver Image', 'Medical Ultrasonography', 'Image classification', 'Keras']",,"CNN algorithm is a deep learning algorithm which is mainly used for image recognition.In recent years, image classification using CNN algorithm has been used in many fields because of its improved accuracy and it is not easy to read disease using ultrasound image unless it is a skilled expert in medical image field. In this paper, we use CNN algorithm to predict the liver lesion by classifying the images according to the diseases shown in the liver ultrasound images. The liver ultrasound image was preprocessed through grayscale and size reordering and then added to the CNN algorithm. In this paper, we study the overfitting problem by learning CNN structure with 3 convolution layers and classify the images with accuracy of 92% of test image and 59% of test image."
진화연산 기반 CNN 필터 축소,2018,"['Convolutional neural network', 'Filter reduction', 'Genetic algorithm']",,"A convolutional neural network (CNN), which is one of the deep learning models, has been very successful in a variety of computer vision tasks. Filters of a CNN are automatically generated, however, they can be further optimized since there exist the possibility of existing redundant and less important features. Therefore, the aim of this paper is a filter reduction to accelerate and compress CNN models. Evolutionary algorithms is adopted to remove the unnecessary filters in order to minimize the parameters of CNN networks while maintaining a good performance of classification. We demonstrate the proposed filter reduction methods performing experiments on CIFAR10 data based on the classification performance. The comparison for three approaches is analysed and the outlook for the potential next steps is suggested."
Effects of Hyper-parameters and Dataset on CNN Training,2018,"['Hyper-parameter', 'CNN', 'classification accuracy', 'weight factor', 'neural network training']",,"The purpose of training a convolutional neural network (CNN) is to obtain weight factors that give high classification accuracies. The initial values of hyper-parameters affect the training results, and it is important to train a CNN with a suitable hyper-parameter set of a learning rate, a batch size, the initialization of weight factors, and an optimizer. We investigate the effects of a single hyper-parameter while others are fixed in order to obtain a hyper-parameter set that gives higher classification accuracies and requires shorter training time using a proposed VGG-like CNN for training since the VGG is widely used. The CNN is trained for four datasets of CIFAR10, CIFAR100, GTSRB and DSDL-DB. The effects of the normalization and the data transformation for datasets are also investigated, and a training scheme using merged datasets is proposed."
CNN 기반 토마토의 흰가루병 발병 인식 방법,2018,"['smart greenhouse', 'convolution neural network', 'tomato powdery mildew recognition']",,"The smart greenhouse, which is equipped with an autonomous environmental control system, is attracting attention as an effective alternative to solve problems in the modern agricultural industry. Although the smart greenhouse enables the monitoring of environmental information of the greenhouse, the system to directly capture the state of the crops is required to enhance the productivity of the smart greenhouse. In this paper, we propose an image recognition algorithm based on the convolution neural network (CNN) to detect an outbreak of powdery mildew on tomatoes. We propose a method to artificially generate the powdery mildew images using an image fusion technique to prepare various forms of CNN learning data. The artificial powdery mildew images are produced in three steps: mildew image extraction, transformation, and overlapping. The CNN is learned using these artificial images, and we test the recognition performance of the CNN using real tomato leap images captured in the greenhouse. The experimental results show that the proposed image recognition algorithm presents a recognition rate of 93.02% for 43 test images."
Effects of Hyper-parameters and Dataset on CNN Training,2018,"['Hyper-parameter', 'CNN', 'classification accuracy', 'weight factor', 'neural network training']",,"The purpose of training a convolutional neural network (CNN) is to obtain weight factors that give high classification accuracies. The initial values of hyper-parameters affect the training results, and it is important to train a CNN with a suitable hyper-parameter set of a learning rate, a batch size, the initialization of weight factors, and an optimizer. We investigate the effects of a single hyper-parameter while others are fixed in order to obtain a hyper-parameter set that gives higher classification accuracies and requires shorter training time using a proposed VGG-like CNN for training since the VGG is widely used. The CNN is trained for four datasets of CIFAR10, CIFAR100, GTSRB and DSDL-DB. The effects of the normalization and the data transformation for datasets are also investigated, and a training scheme using merged datasets is proposed."
Effects of Hyper-parameters and Dataset on CNN Training,2018,"['Hyper-parameter', 'CNN', 'classification accuracy', 'weight factor', 'neural network training']",,"The purpose of training a convolutional neural network (CNN) is to obtain weight factors that give high classification accuracies. The initial values of hyper-parameters affect the training results, and it is important to train a CNN with a suitable hyper-parameter set of a learning rate, a batch size, the initialization of weight factors, and an optimizer. We investigate the effects of a single hyper-parameter while others are fixed in order to obtain a hyper-parameter set that gives higher classification accuracies and requires shorter training time using a proposed VGG-like CNN for training since the VGG is widely used. The CNN is trained for four datasets of CIFAR10, CIFAR100, GTSRB and DSDL-DB. The effects of the normalization and the data transformation for datasets are also investigated, and a training scheme using merged datasets is proposed."
Low Resolution Rate Face Recognition Based on Multi-scale CNN,2018,"['Face Recognition', 'Intelligent Video Analysis Method', 'CNN', 'Multi-scale CNN']",,"For the problem that the face image of surveillance video cannot be accurately identified due to the low resolution, this paper proposes a low resolution face recognition solution based on convolutional neural network model. Convolutional Neural Networks (CNN) model for multi-scale input The CNN model for multi-scale input is an improvement over the existing ""two-step method"" in which low-resolution images are up-sampled using a simple bi-cubic interpolation method. Then, the up sampled image and the high-resolution image are mixed as a model training sample. The CNN model learns the common feature space of the high- and low-resolution images, and then measures the feature similarity through the cosine distance. Finally, the recognition result is given. The experiments on the CMU PIE and Extended Yale B datasets show that the accuracy of the model is better than other comparison methods. Compared with the CMDA_BGE algorithm with the highest recognition rate, the accuracy rate is 2.5%~9.9%."
Low Resolution Rate Face Recognition Based on Multi-scale CNN,2018,"['Face Recognition', 'Intelligent Video Analysis Method', 'CNN', 'Multi-scale CNN']",,"For the problem that the face image of surveillance video cannot be accurately identified due to the low resolution, this paper proposes a low resolution face recognition solution based on convolutional neural network model. Convolutional Neural Networks (CNN) model for multi-scale input The CNN model for multi-scale input is an improvement over the existing ""two-step method"" in which low-resolution images are up-sampled using a simple bi-cubic interpolation method. Then, the up sampled image and the high-resolution image are mixed as a model training sample. The CNN model learns the common feature space of the high- and low-resolution images, and then measures the feature similarity through the cosine distance. Finally, the recognition result is given. The experiments on the CMU PIE and Extended Yale B datasets show that the accuracy of the model is better than other comparison methods. Compared"
LGP-FL과 해마 구조를 이용한 H-CNN 기반 보행자 검출에 대한 연구,2018,"['pedestrian detection', 'object detection', 'LGP', 'CNN', 'hippocampal structure']",,"Recently, autonomous vehicles have been actively studied. Pedestrian detection and recognition technology is important in autonomous vehicles. Pedestrian detection using CNN(Convolutional Neural Netwrok), which is mainly used recently, generally shows good performance, but there is a performance degradation depending on the environment of the image. In this paper, we propose a pedestrian detection system applying long-term memory structure of hippocampal neural network based on CNN network with LGP-FL (Local Gradient Pattern-Feature Layer) added. First, change the input image to a size of 227x227. Then, the feature is extracted through a total of 5 layers of convolution layer. In the process, LGP-FL adds the LGP feature pattern and stores the high-frequency pattern in the long-term memory. In the detection process, it is possible to detect the pedestrian more accurately by detecting using the LGP feature pattern information robust to brightness and color change. A comparison of the existing methods and the proposed method confirmed the increase of detection rate of about 1~4%."
Recognition of Car Manufacturers using Faster R-CNN and Perspective Transformation,2018,"['Car Logo Detection', 'Faster R-CNN', 'Perspective Transformation', 'Vehicle Manufacturer Detection']",,"In this paper, we report detection and recognition of vehicle logo from images captured from street CCTV. Image data includes both the front and rear view of the vehicles. The proposed method is a two-step process which combines image preprocessing and faster region-based convolutional neural network (R-CNN) for logo recognition. Without preprocessing, faster R-CNN accuracy is high only if the image quality is good. The proposed system is focusing on street CCTV camera where image quality is different from a front facing camera. Using perspective transformation the top view images are transformed into front view images. In this system, the detection and accuracy are much higher as compared to the existing algorithm. As a result of the experiment, on day data the detection and recognition rate is improved by 2% and night data, detection rate improved by 14%."
CNN 소실점 검출을 이용한 차선 검출,2018,"['lane detection', 'deep learning', 'convolutional neural networks', 'transfer learning']",,"Lane detection is essential in autonomous navigation. Conventional algorithms use hand crafted features which produce difficulties because of diverse image variations from illumination variations, occlusions and shadows. Recently, deep learning based approaches have provided more robust results. In this paper, we present an algorithm for the robust detection of lanes by finding vanishing points with convolutional neural networks. We use two modified CNN architectures, where the final output layer consists of four elements. The epipole and the angles of the current driving lane each have two elements. Experiments are performed by using two modified structures of the NVIDIA end-to-end model[9] and the ResNet-50 model[10]."
표면근전도 신호를 활용한 CNN 기반 한국 지화숫자 인식을 위한 아래팔 근육과 전극 위치에 관한 연구,2018,"['surface electromyography', 'forearm', 'multi finger gesture recognition', 'electrode placements', 'Korean multi finger number']","표면근전도(sEMG) 신호의 응용은 초기에는 단순히 근육 활성도의 유무를 판별하여 On/Off 의 스위치 기능으로 많이 사용되어 왔으나, 표면근전도 신호처리와 알고리즘의 발달로 휠체어의 방향 제어는 물론 수화를 인식하는 분야까지 확대되었다. 청각 장애인들의 언어 소통을 위한 중요한 수단인 수화나 지화는 미학습자와는 소통의 어려움이 존재해왔으며, 이러한 어려움을 해결하기 위해 수화나 지화를 인식하는 기술에 대한 연구가 지속적으로 수행되어 왔다. 최근에는, 수화나 지화 시연시에 활성화되는 근육의 신호를 활용하여 수화나 지화를 인식하는 방법이 중국 숫자지화 중심으로 적용되고 있는 추세이다. 하지만, 수화나 지화는 일반 음성언어와 마찬가지로 중국 숫자지화와 한국 숫자지화가 다르므로, 중국 숫자지화 시연시에 관여하는 근육이 한국 숫자지화 시연시에는 관여하지 않을 수가 있어, 인식률이 현저히 떨어질 수 있다. 그러므로 한국 숫자지화 시연시에 활성화되는 근육의 선정은 표면근전도 신호에 기반한 한국 숫자지화 인식률에 매우 중요하다. 하지만, 표면근전도 신호에 기반한 한국 숫자지화 인식에 대한 연구는 문헌에서 드물다. 본 연구에서는 표면근전도 신호를 활용한 한국수화 또는 한국지화의 인식에 관한 초기 연구로서, 한국 숫자지화를 시연시에 관여하는 아래팔근육을 제안하고 실험을 통하여 검증하기 위해 숫자 영(0)부터 다섯(5)의 여섯 가지 한국 숫자지화를 대상으로 인식하는 연구를 수행하였다. 이를 위해, 표면근전도 신호를 활용한 CNN 기반 지화인식 방법에 적용하여 여섯 가지 한국 숫자지화에 대하여 100%의 인식률을 확인함으로써, 여섯 가지 한국 숫자지화 인식을 위해 제안된 아래팔근육과 전극위치의 타당성을 검증하였다.","Surface electromyography (sEMG) is mainly used as an on/off switch in the early stage of the study and was then expanded to navigational control of powered-wheelchairs and recognition of sign language or finger gestures. There are difficulties in communication between people who know and do not know sign language; therefore, many efforts have been made to recognize sign language or finger gestures. Recently, use of sEMG signals to recognize sign language signals have been investigated; however, most studies of this topic conducted to date have focused on Chinese finger number gestures. Since sign language and finger gestures vary among regions, Korean- and Chinese-finger number gestures differ from each other. Accordingly, the recognition performance of Korean finger number gestures based on sEMG signals can be severely degraded if the same muscles are specified as for Chinese finger number gestures. However, few studies of Korean finger number gestures based on sEMG signals have been conducted. Thus, this study was conducted to identify potential forearm muscles from which to collect sEMG signals for Korean finger number gestures. To accomplish this, six Korean finger number gestures from number zero to five were investigated to determine the usefulness of the proposed muscles and electrode placements by showing that CNN technique based on sEMG signal after sufficient learning recognizes six Korean finger number gestures in accuracy of 100%."
A Study of Image Classification using HMC Method Applying CNN Ensemble in the Infrared Image,2018,"['Infrared image', 'Convolutional neural network', 'Machine learning']",,"In the marine environment, many clutters have similar features with the marine targets due to the diverse changes of the air temperature, water temperature, various weather and seasons. Also, the clutters in the ground environment have similar features due to the same reason. In this paper, we proposed a robust Hybrid Machine Character (HMC) method to classify the targets from the clutters in the infrared images for the various environments. The proposed HMC method adopts human’s multiple personality utilization and the CNN ensemble method to classify the targets in the ground and marine environments. This method uses an advantage of the each environmental training model. Experimental results demonstrate that the proposed method has better success rate to classify the targets and clutters than previously proposed CNN classification method."
A Study of Image Classification using HMC Method Applying CNN Ensemble in the Infrared Image,2018,"['Infrared image', 'Convolutional neural network', 'Machine learning']",,"In the marine environment, many clutters have similar features with the marine targets due to the diverse changes of the air temperature, water temperature, various weather and seasons. Also, the clutters in the ground environment have similar features due to the same reason. In this paper, we proposed a robust Hybrid Machine Character (HMC) method to classify the targets from the clutters in the infrared images for the various environments. The proposed HMC method adopts human's multiple personality utilization and the CNN ensemble method to classify the targets in the ground and marine environments. This method uses an advantage of the each environmental training model. Experimental results demonstrate that the proposed method has better success rate to classify the targets and clutters than previously proposed CNN classification method."
CNN 기반의 소리 잡음에 강인한 돼지 호흡기 질병 탐지 및 식별 시스템,2018,"['porcine wasting diseases classification', 'sound analysis', 'convolution neural network']",,"Failure to detect pig wasting disease in a timely and accurate manner in the commercial pig farm can be a serious factor in achieving efficient livestock management. In this paper, we propose a noise-robust porcine wasting diseases detection and classification method in piglet farm monitoring system using sound data. First, we extract a spectrogram of sound signals and convert it into noise-robust features by a convolutional neural network (CNN), and lastly, use the multi-layer perceptron (MLP) as an early anomaly detector and classifier. On the basis of the experimental results, we confirmed that the proposed method could detect and classify the porcine wasting diseases with acceptable accuracy even under noise-environmental conditions. In particular, as a result of comparing the discrimination performance of the proposed method in this research and the MFCC-SVM method, it was confirmed that the f-score was improved by 15.1%."
CNN Model to Classify Malware Using Image Feature,2018,"['악성코드', '악성코드분류', 'CNN', '머신러닝', 'malware', 'malware classification', 'convolutional neural network', 'machine learning']","인터넷에 발생하는 악성코드는 매우 심각한 위협 요소이며, 악성코드를 이용한 공격이 전 세계적으로 전파되며 심지어 점점 더 지능적으로 변조되고 있다. 그러므로 악성코드를 정확하게 탐지 하는 방법이 중요하다. 지금까지 널리 알려진 악성코드 대응방법은 악성코드를 탐지하여 삭제하거나 혹은 치료한다고 알고 있다. 이러한 악성코드를 탐지하기 위하여 악성코드에 따른 분류를 하여야 한다. 악성코드를 잘 분류하는 것은 알려진 악성코드를 더 잘 탐지할 수 있다는 것과 같다. 기존 연구들을 보면 같은 카테고리에 속하는 악성코드는 치료방법이 비슷하게 보이는 경향이 있다는 것을 입증한다. 그리고 많은 새로운 악성코드들이 기존에 있던 악성코드로부터 만들어진다는 것을 증명한다. 따라서 악성코드를 종류에 따라서 분류하는 것은 탐지하는 것 못지않게 아주 중요한 작업이다. 그러므로 멀웨어 분류 기술이 절실히 요구된다. 본 논문에서는 주어진 종류에 따라 악성코드를 분류하기 위한 컨볼루션 인공신경망 모델을 구축한다. 이 모델은 9,500 개의 악성코드 데이터 셋을 25 개의 종류로 분류하는 실험에서 98%의 정확도를 보인다. 본 연구의 목적은 다음 목표로 더 많은 양의 악성코드 파일에 적용되며 더 높은 정확도를 보이는 것이다.","Malware programs are common threats in the information and technology society. It has been proven that a number of developed malwares cripples the victim’s computer as well as launching malicious attacks. Therefore, it is important to find a reasonable technical way to counter these attacks. Malware can be easily detected by checking whether a file has a malicious code inside the source code, if you detect a malicious code inside your content, then take an appropriate action by eliminating the threat. The first countermeasure to take is to delete the file or follow any other action defined by an Anti-malware software. After a file is infected, means it can be classified to its corresponding family based on its behavior in the infected system.. In this paper, we use Convolutional Neural Network to classify malware binaries using image features. Our work relies on the previously conducted research on malware visualization, whereby we used the dataset consisted of about 9,500 samples of 25 different malware familys. The built architecture achieved an accuracy of 98%."
CNN 기반 동영상의 프레임 삭제 검출 기법,2018,"['Video Forensics', 'Frame Deletion', 'HEVC', 'CNN', 'Coding Pattern']",,"In this paper, we introduce a technique to detect the video forgery by using the regularity that occurs in the video compression process. The proposed method uses the hierarchical regularity lost by the video double compression and the frame deletion. In order to extract such irregularities, the depth information of CU and TU, which are basic units of HEVC, is used. For improving performance, we make a depth map of CU and TU using local information, and then create input data by grouping them in GoP units. We made a decision whether or not the video is double-compressed and forged by using a general three-dimensional convolutional neural network. Experimental results show that it is more effective to detect whether or not the video is forged compared with the results using the existing machine learning algorithm."
Speech-Act Analysis System Based on Dialogue Level RNN-CNN Effective on the Exposure Bias Problem,2018,"['화행 분석', 'RNN-CNN', '노출 편향 문제', '딥 러닝', 'speech-act analysis', 'exposure bias problem', 'deep learning']",,
실생활 음향 데이터 기반 이중 CNN 구조를 특징으로 하는 음향 이벤트 인식 알고리즘,2018,"['Machine learning', 'Deep learning', 'Audio signal processing', 'Sound event detection', 'Dataset']",,"Sound event detection is one of the research areas to model human auditory cognitive characteristics by recognizing events in an environment with multiple acoustic events and determining the onset and offset time for each event. DCASE, a research group on acoustic scene classification and sound event detection, is proceeding challenges to encourage participation of researchers and to activate sound event detection research. However, the size of the dataset provided by the DCASE Challenge is relatively small compared to ImageNet, which is a representative dataset for visual object recognition, and there are not many open sources for the acoustic dataset. In this study, the sound events that can occur in indoor and outdoor are collected on a larger scale and annotated for dataset construction. Furthermore, to improve the performance of the sound event detection task, we developed a dual CNN structured sound event detection system by adding a supplementary neural network to a convolutional neural network to determine the presence of sound events. Finally, we conducted a comparative experiment with both baseline systems of the DCASE 2016 and 2017."
Recognition of Car Manufacturers using Faster R-CNN and Perspective Transformation,2018,"['Car Logo Detection', 'Faster R-CNN', 'Perspective Transformation', 'Vehicle Manufacturer Detection']",,
모바일 시스템을 위한 CNN 딥 러닝 가속화 알고리즘,2018,"['deep learning', 'convolutional neural network', 'pruning', 'low-rank approximation']",,"A mobile system with limited computing and storage capacity mainly processes the training and inference of deep learning in a data center. Therefore, it is difficult for a mobile system to provide private artificial intelligence services, and users may be reluctant to transfer personal information to data centers. Therefore, this paper proposes a deep learning acceleration algorithm for convolutional neural network where a mobile system enables learning and inference itself. The proposed algorithm efficiently reduces the size of the convolutional neural network by a low-rank approximation method that compacts the information of the neural network into some weights, and a pruning method that removes non-critical weights. Experimental results show that the proposed algorithm achieves the speed of inference 1.65 times faster, requires the number of fine-tune fewer 1.5 times, and reduces the memory capacity for storing weights 2 times less than the conventional prunning algorithm."
Tracking by Detection of Multiple Faces using SSD and CNN Features,2018,"['Image Processing', 'Human face tracking', 'Active Appearance Model']",,"Multi-tracking of general objects and specific faces is an important topic in the field of computer vision applicable to many branches of industry such as biometrics, security, etc. The rapid development of deep neural networks has resulted in a dramatic improvement in face recognition and object detection problems, which helps improve the multiple-face tracking techniques exploiting the tracking-by-detection method. Our proposed method uses face detection trained with a head dataset to resolve the face deformation problem in the tracking process. Further, we use robust face features extracted from the deep face recognition network to match the tracklets with tracking faces using Hungarian matching method. We achieved promising results regarding the usage of deep face features and head detection in a face tracking benchmark."
Tracking by Detection of Multiple Faces using SSD and CNN Features,2018,"['Image Processing', 'Human face tracking', 'Active Appearance Model']",,"Multi-tracking of general objects and specific faces is an important topic in the field of computer vision applicable to many branches of industry such as biometrics, security, etc. The rapid development of deep neural networks has resulted in a dramatic improvement in face recognition and object detection problems, which helps improve the multiple-face tracking techniques exploiting the tracking-by-detection method. Our proposed method uses face detection trained with a head dataset to resolve the face deformation problem in the tracking process. Further, we use robust face features extracted from the deep face recognition network to match the tracklets with tracking faces using Hungarian matching method. We achieved promising results regarding the usage of deep face features and head detection in a face tracking benchmark."
Pruning Method Using Correlation of Weight Changes and Weight Magnitudes in CNN,2018,"['Convolutional neural networks', 'Pruning weights', 'Weight correlation', 'Weight']",,"Very complex deep learning models need to be compressed to be memory and cost effective, especially for applications on a mobile platform. We propose a new method of selecting weights to prune to compress convolutional neural networks. To select unimportant weights and get the best result, we combine typical weight magnitude pruning method with our method, which evaluates correlation coefficients of weights to measure the strength of a relationship between weight magnitudes and weight changes through the iterations. In the experimental section, we show our result of pruning 94% of weights in LeNet-5 without significant accuracy loss."
A Real-time Citrus Segmentation and Detection System using Mask R-CNN,2018,"['과일 검출', '심층 콘볼루션 신경망', '빠른 학습', '실시간 성능', '자동 수확', 'Visual fruit detection', 'Deep convolutional neural network', 'Rapid training', 'Real-time performance', 'Auto-harvesting']",,"In this paper, 200 photograph of citrus were collected and converted to 800x800. The areas of each citrus in the photograph were mask-labeled and stored in JSON format to generate a data set. The latest algorithm, Mask R-CNN, I constructed a reliable system to detect and divide citrus fruits. In order to solve the over-fitting problem due to small data sets, the data augmentation was used and the detection performance was as high as 0.97 with small data sets. In order to meet the farmers practical needs, I plan to develop a platform that can take photographs, label them with a mask first, and then train them immediately after doing additional mask labeling work."
비전 점유센서를 위한 합성곱 신경망 기반 사람 인식,2018,"['occupancy sensor', 'camera', 'CNN', 'people recognition', 'tracking']",대부분의 건물 등에 설치된 점유센서는 PIR(pyroelectric infra-red)이 주로 활용되고 있다. 하지만 PIR은 온도 변화를 감지하는 기능 때문에 정지된 사람을 감지할 수 없는 단점이 있다. 최근 이 단점을 극복하기 위해 카메라 비전 센서의 연구가 진행되고 있다. 비전 센서는 객체 트랙킹을 통해 정지된 사람을 검출한다. 그러나 객체 트랙킹은 트랙커 표류가 발생하는 문제점이 있다. 본 논문에서는 정지 트랙커가 사람을 포함하는지의 여부를 판단하기 위하여 합성곱 신경망 기반 사람 인식 기법을 제안한다. 실험에서는 카메라로 획득한 영상에 제안 방법을 적용한 결과 약 88%의 정확도로 사람과 비사람이 분류가 되어 실제 점유센서에 활용이 가능하다는 것을 증명하였다.,
효과적인 입력변수 패턴 학습을 위한 시계열 그래프 기반합성곱 신경망 모형: 주식시장 예측에의 응용,2018,"['기술적 분석가', '딥러닝', '분류기', '주가지수 등락 예측', '합성곱 신경망', 'Classifier', 'Convolutional Neural Network', 'Deep Learning', 'Stock Price Fluctuation Prediction', 'Technical Analyst']","지난 10여 년간 딥러닝(Deep Learning)은 다양한 기계학습 알고리즘 중에서 많은 주목을 받아 왔다. 특히 이미지를 인식하고 분류하는데 효과적인 알고리즘으로 알려져 있는 합성곱 신경망(Convolutional Neural Network, CNN)은 여러 분야의 분류 및 예측 문제에 널리 응용되고 있다. 본 연구에서는 기계학습 연구에서 가장 어려운예측 문제 중 하나인 주식시장 예측에 합성곱 신경망을 적용하고자 한다. 구체적으로 본 연구에서는 그래프를입력값으로 사용하여 주식시장의 방향(상승 또는 하락)을 예측하는 이진분류기로써 합성곱 신경망을 적용하였다. 이는 그래프를 보고 주가지수가 오를 것인지 내릴 것인지에 대해 경향을 예측하는 이른바 기술적 분석가를모방하는 기계학습 알고리즘을 개발하는 과제라 할 수 있다. 본 연구는 크게 다음의 네 단계로 수행된다. 첫 번째 단계에서는 데이터 세트를 5일 단위로 나눈다. 두 번째 단계에서는 5일 단위로 나눈 데이터에 대하여 그래프를 만든다. 세 번째 단계에서는 이전 단계에서 생성된 그래프를 사용하여 학습용과 검증용 데이터 세트를 나누고 합성곱 신경망 분류기를 학습시킨다. 네 번째 단계에서는 검증용 데이터 세트를 사용하여 다른 분류 모형들과 성과를 비교한다. 제안한 모델의 유효성을 검증하기 위해 2009년 1월부터 2017년 2월까지의 약 8년간의KOSPI200 데이터 2,026건의 실험 데이터를 사용하였다. 실험 데이터 세트는 CCI, 모멘텀, ROC 등 한국 주식시장에서 사용하는 대표적인 기술지표 12개로 구성되었다. 결과적으로 실험 데이터 세트에 합성곱 신경망 알고리즘을 적용하였을 때 로지스틱회귀모형, 단일계층신경망, SVM과 비교하여 제안모형인 CNN이 통계적으로 유의한 수준의 예측 정확도를 나타냈다.","Over the past decade, deep learning has been in spotlight among various machine learning algorithms. In particular, CNN(Convolutional Neural Network), which is known as the effective solution for recognizing and classifying images or voices, has been popularly applied to classification and prediction problems. In this study, we investigate the way to apply CNN in business problem solving. Specifically, this study propose to apply CNN to stock market prediction, one of the most challenging tasks in the machine learning research. As mentioned, CNN has strength in interpreting images. Thus, the model proposed in this study adopts CNN as the binary classifier that predicts stock market direction (upward or downward) by using time series graphs as its inputs. That is, our proposal is to build a machine learning algorithm that mimics an experts called 'technical analysts' who examine the graph of past price movement, and predict future financial price movements.Our proposed model named 'CNN-FG(Convolutional Neural Network using Fluctuation Graph)' consists of five steps. In the first step, it divides the dataset into the intervals of 5 days. And then, it creates time series graphs for the divided dataset in step 2. The size of the image in which the graph is drawn is 40 (pixels) × 40 (pixels), and the graph of each independent variable was drawn using different colors.In step 3, the model converts the images into the matrices. Each image is converted into the combination of three matrices in order to express the value of the color using R(red), G(green), and B(blue) scale. In the next step, it splits the dataset of the graph images into training and validation datasets. We used 80% of the total dataset as the training dataset, and the remaining 20% as the validation dataset. And then, CNN classifiers are trained using the images of training dataset in the final step. Regarding the parameters of CNN-FG, we adopted two convolution filters (5 × 5 × 6 and 5 × 5 × 9) in the convolution layer. In the pooling layer, 2 × 2 max pooling filter was used. The numbers of the nodes in two hidden layers were set to, respectively, 900 and 32, and the number of the nodes in the output layer was set to 2(one is for the prediction of upward trend, and the other one is for downward trend). Activation functions for the convolution layer and the hidden layer were set to ReLU(Rectified Linear Unit), and one for the output layer set to Softmax function.To validate our model - CNN-FG, we applied it to the prediction of KOSPI200 for 2,026 days in eight years (from 2009 to 2016). To match the proportions of the two groups in the independent variable (i.e. tomorrow's stock market movement), we selected 1,950 samples by applying random sampling. Finally, we built the training dataset using 80% of the total dataset (1,560 samples), and the validation dataset using 20% (390 samples). The dependent variables of the experimental dataset included twelve technical indicators popularly been used in the previous studies. They include Stochastic %K, Stochastic %D, Momentum, ROC(rate of change), LW %R(Larry William's %R), A/D oscillator(accumulation/distribution oscillator), OSCP(price oscillator), CCI(commodity channel index), and so on. To confirm the superiority of CNN-FG, we compared its prediction accuracy with the ones of other classification models. Experimental results showed that CNN-FG outperforms LOGIT(logistic regression), ANN(artificial neural network), and SVM(support vector machine) with the statistical significance. These empirical results imply that converting time series business data into graphs and building CNN-based classification models using these graphs can be effective from the perspective of prediction accuracy. Thus, this paper sheds a light on how to apply deep learning techniques to the domain of business problem solving."
작물분류에서 기계학습 및 딥러닝 알고리즘의 분류 성능 평가: 하이퍼파라미터와 훈련자료 크기의 영향 분석,2018,"['Crop classification', 'Machine learning', 'Deep learning', 'Support vector machine', 'Convolutional neural network']",,"The purpose of this study is to compare machine learning algorithm and deep learning algorithm in crop classification using multi-temporal remote sensing data. For this, impacts of machine learning and deep learning algorithms on (a) hyper-parameter and (2) training sample size were compared and analyzed for Haenam-gun, Korea and Illinois State, USA. In the comparison experiment, support vector machine (SVM) was applied as machine learning algorithm and convolutional neural network (CNN) was applied as deep learning algorithm. In particular, 2D-CNN considering 2-dimensional spatial information and 3D-CNN with extended time dimension from 2D-CNN were applied as CNN. As a result of the experiment, it was found that the hyper-parameter values of CNN, considering various hyper-parameter, defined in the two study areas were similar compared with SVM. Based on this result, although it takes much time to optimize the model in CNN, it is considered that it is possible to apply transfer learning that can extend optimized CNN model to other regions. Then, in the experiment results with various training sample size, the impact of that on CNN was larger than SVM. In particular, this impact was exaggerated in Illinois State with heterogeneous spatial patterns. In addition, the lowest classification performance of 3D-CNN was presented in Illinois State, which is considered to be due to over-fitting as complexity of the model. That is, the classification performance was relatively degraded due to heterogeneous patterns and noise effect of input data, although the training accuracy of 3D-CNN model was high. This results imply that a proper classification algorithms should be selected considering spatial characteristics of study areas. Also, a large amount of training samples is necessary to guarantee higher classification performance in CNN, particularly in 3D-CNN."
이진화된 컨벌루션 신경망의 효율적인 SIMD 구현,2018,"['인공 신경망', '컨벌루션 신경망', '이진화', '이미지 분류', '임베디드 시스템']","본 논문에서는 이진화된 컨벌루션 신경망 (Convolutional Neural Network; CNN)의 효율적인 구현을 제시한다. 이진화된 CNN은 기존 CNN에 이진화 과정을 추가하여 각각의 파라미터와 컨벌루션의 입력이 단일 비트로 표현될 수 있도록 변형한 것이다. 제안하는 구현에서는, 다수의 이진화된 파라미터들과 컨벌루션의 입력들을 하나의 워드로 묶어서 저장하고, CNN에서 연산 량 대부분을 차지하는 기존 컨벌루션을 이진화된 컨벌루션으로 대체하여, Bitwise XNOR-Bitcount으로 구현하였다. 이러한 SIMD 처리 방식의 구현은 CNN의 전체적인 메모리 요구량과 연산 량을 크게 감소시킬 수 있다. 실제로 LeNet-5와 ResNet-18을 대상으로 제안하는 구현은 분석 성능에서 기존의 결과와 비교하여 대등한 수준을 유지하면서도, 수행 시간을 기존 구현의 결과 대비 최대 89% 단축하고, 메모리 요구량은 기존 구현의 결과 대비 최대 95% 축소한다.","This paper presents the efficient implementation of the binarized convolutional neural network (CNN). The binarized CNN is designed by modifying the conventional CNN so as to include the binarization processes for the parameters and the activation outputs. In the proposed implementation, multiple binarized parameters and multiple activation outputs are packed into a single word, and the inner-products are calculated by performing simple bitwise XNOR followed by bit-counting operations. Owing to such SIMD optimization, both the overall number of the computations and the memory footprint are reduced significantly. LeNet-5 and ResNet-18 are implemented based on the proposed SIMD optimization. When compared to the straightforward implementation of the non-binarized CNN model, the proposed implementation shows the significant reduction in terms of the inference time and the memory footprint, while maintaining the analysis performance."
Wasserstein Center 손실을 이용한 스케치 기반 3차원 물체 검색,2018,"['Convolutional Neural Network', 'Image retrieval', 'Deep Learning', 'Sketch-based 3D object retrieval', '합성곱 신경망', '영상 검색', '딥 러닝', '스케치 기반 3차원 물체 검색']","스케치 기반 3차원 물체 검색은 다양한 3차원 물체를 사람이 손으로 그린 스케치를 질의(query)로 사용하여 물체를 편리하게 검색하는 방법이다. 본 논문에서는 스케치 기반 3차원 물체 검색을 위해 스케치 CNN(Convolutional Neural Network)과 Wasserstein CNN 모델에 Wasserstein Center 손실을 적용하여 물체의 검색 성공률을 향상시키는 새로운 방법을 제안한다. 제안된 Wasserstein Center 손실이란 각 물체의 클래스(category)의 중심을 학습하고, 동일한 클래스의 특징과 중심 간의 Wasserstein 거리가 작아지도록 만드는 방법이다. 이를 위하여 제안된 3차원 물체 검색은 다음의 단계로 수행된다. 첫 번째로, 3차원 물체의 특징은 3차원 물체를 여러 방향에서 촬영된 2차원 영상의 특징을 CNN을 이용하여 추출하고, 각 영상 특징의 Wasserstein 중심을 계산한다. 두 번째로, 스케치의 특징은 별도의 스케치 CNN을 이용하여 추출하였다. 마지막으로, 추출한 3차원 물체의 특징과 스케치의 특징을 본 논문에서 제안한 Wasserstein Center 손실을 이용하여 학습하고 스케치 기반의 3차원 물체 검색에 적용하였다. 본 논문에서 제안한 방법의 우수성을 입증하기 위하여 SHREC 13과 SHREC 14의 두 가지 벤치마크 데이터 집합을 이용하여 평가하였으며, 제안된 방법이 기존의 스케치 기반 검색방법들과 비교하여 모든 측정 기준에서 우수한 결과를 나타냄을 확인할 수 있었다.","Sketch-based 3D object retrieval is a convenient way to search for various 3D data using human-drawn sketches as query. In this paper, we propose a new method of using Sketch CNN, Wasserstein CNN and Wasserstein center loss for sketch-based 3D object search. Specifically, Wasserstein center loss is a method of learning the center of each object category and reducing the Wasserstein distance between center and features of the same category. To do this, the proposed 3D object retrieval is performed as follows. Firstly, Wasserstein CNN extracts 2D images taken from various directions of 3D object using CNN, and extracts features of 3D data by computing the Wasserstein barycenters of features of each image. Secondly, the features of the sketch are extracted using a separate Sketch CNN. Finally, we learn the features of the extracted 3D object and the features of the sketch using the proposed Wasserstein center loss. In order to demonstrate the superiority of the proposed method, we evaluated two sets of benchmark data sets, SHREC 13 and SHREC 14, and the proposed method shows better performance in all conventional metrics compared to the state of the art methods."
Application of Convolutional Neural Network in the Diagnosis of Jaw Tumors,2018,"['Artificial Intelligence', 'Ameloblastoma', 'Odontogenic Tumors', 'Panoramic Radiography', 'Oral and Maxillofacial Surgeons']",,"Objectives: Ameloblastomas and keratocystic odontogenic tumors (KCOTs) are important odontogenic tumors of the jaw.While their radiological findings are similar, the behaviors of these two types of tumors are different. Precise preoperative diagnosis of these tumors can help oral and maxillofacial surgeons plan appropriate treatment. In this study, we created a convolutional neural network (CNN) for the detection of ameloblastomas and KCOTs. Methods: Five hundred digital panoramic images of ameloblastomas and KCOTs were retrospectively collected from a hospital information system, whose patient information could not be identified, and preprocessed by inverse logarithm and histogram equalization. To overcome the imbalance of data entry, we focused our study on 2 tumors with equal distributions of input data. We implemented a transfer learning strategy to overcome the problem of limited patient data. Transfer learning used a 16-layer CNN (VGG-16) of the large sample dataset and was refined with our secondary training dataset comprising 400 images. A separate test dataset comprising 100 images was evaluated to compare the performance of CNN with diagnosis results produced by oral and maxillofacial specialists. Results: The sensitivity, specificity, accuracy, and diagnostic time were 81.8%, 83.3%, 83.0%, and 38 seconds, respectively, for the CNN. These values for the oral and maxillofacial specialist were 81.1%, 83.2%, 82.9%, and 23.1 minutes, respectively. Conclusions: Ameloblastomas and KCOTs could be detected based on digital panoramic radiographic images using CNN with accuracy comparable to that of manual diagnosis by oral maxillofacial specialists. These results demonstrate that CNN may aid in screening for ameloblastomas and KCOTs in a substantially shorter time."
딥 러닝 및 서포트 벡터 머신기반 센서 고장 검출 기법,2018,"['Sensor fault diagnosis', 'Support vector machine', 'Genetic algorithm', 'Multi-layer support vector machine', 'Convolution neural network', 'Ensemble']","최근 산업현장에서 기계의 자동화가 크게 가속화됨에 따라 자동화 기계의 관리 및 유지보수에 대한 중요성이갈수록 커지고 있다. 자동화 기계에 부착된 센서의 고장이 발생할 경우 기계가 오동작함으로써 공정라인 운용에 막대한 피해가 발생할 수 있다. 이를 막기 위해 센서의 상태를 모니터링하고 고장의 진단 및 분류를 하는 것이 필요하다.본 논문에서는 센서에서 발생하는 대표적인 고장 유형인 erratic fault, drift fault, hard-over fault, spike fault, stuck fault를 기계학습 알고리즘인 SVM과 CNN을 적용하여 검출하고 분류하였다. SVM의 학습 및 테스트를 위해 데이터샘플들로부터 시간영역 통계 특징들을 추출하고 최적의 특징을 찾기 위해 유전 알고리즘(genetic algorithm)을 적용하였다. Multi-class를 분류하기 위해 multi-layer SVM을 구성하여 센서 고장을 분류하였다. CNN에 대해서는 데이터샘플들을 사용하여 학습시키고 성능을 높이기 위해 앙상블 기법을 적용하였다. 시뮬레이션 결과를 통해 유전 알고리즘에 의해 선별된 특징들을 사용한 SVM의 분류 결과는 모든 특징이 사용된 SVM 분류기 보다는 성능이 향상되었으나전반적으로 CNN의 성능이 SVM보다 우수한 것을 확인할 수 있었다.","As machines have been automated in the field of industries in recent years, it is a paramount importance to manage and maintain the automation machines. When a fault occurs in sensors attached to the machine, the machine may malfunction and further, a huge damage will be caused in the process line. To prevent the situation, the fault of sensors should be monitored, diagnosed and classified in a proper way. In the paper, we propose a sensor fault detection scheme based on SVM and CNN to detect and classify typical sensor errors such as erratic, drift, hard-over, spike, and stuck faults. Time-domain statistical features are utilized for the learning and testing in the proposed scheme, and the genetic algorithm is utilized to select the subset of optimal features. To classify multiple sensor faults, a multi-layer SVM is utilized, and ensemble technique is used for CNN. As a result, the SVM that utilizes a subset of features selected by the genetic algorithm provides better performance than the SVM that utilizes all the features. However, the performance of CNN is superior to that of the SVM."
순환 합성곱 신경망를 이용한다채널 뇌파 분석의 간질 발작 탐지,2018,"['recurrent CNN', 'deep learning', 'epileptic seizure detection', 'EEG', 'load balancin and simulation']","본 논문에서는 뇌파 신호를 이용하여 환자의 경련을 감지하는 순환 CNN (Convolutional Neural Networks)을 제안한다.제안 된 방법은 뇌파 신호의 스펙트럼 특성과 전극의 위치를 보존하기 위해 영상으로 데이터를 매핑하여 처리하였다. 스펙트럼 전처리 과정을 거친 후 CNN에 입력하고 공간 및 시간 특성을 웨이블릿 변환(wavelet transform)없이 추출하여 발작을검출하였다. 여기에 사용된 보스턴 매사추세츠 공과 대학 (Boston Massachusetts Institute of Technology, CHB-MIT) 아동병원의 데이터셋 결과는 시간당 0.85의 민감도와 90 %의 위양성 비율 (FPR)을 보였다.","In this paper, we propose recurrent CNN(Convolutional Neural Networks) for detecting seizures among patients usingEEG signals. In the proposed method, data were mapped by image to preserve the spectral characteristics of the EEGsignal and the position of the electrode. After the spectral preprocessing, we input it into CNN and extracted the spatialand temporal features without wavelet transform.Results from the Children's Hospital of Boston Massachusetts Institute of Technology (CHB-MIT) dataset showed asensitivity of 90% and a false positive rate (FPR) of 0.85 per hour."
Study on Using Deep Learning Method to Realize The Emotion Linkage between The Gamer and His Avatar in Poker Game,2018,"['Psychological game', 'Emotion recognition', 'CNN', 'SVM', 'Emotion linkage technology']","다른 장르의 게임에 비해 포커는 게이머의 심리적 요소가 많은 영향을 끼친다. 본 논문에서는 CNN과 SVM을 기반으로 온라인 포커 게임에 게이머와 아바타 간의 감성연결을 실현하기 위한 새로운 감성 인식방법을 제안한다. CNN모델을 이용하여 원래 얼굴 이미지의 특징을 추출하고, 다중 클래스 SVM분류기를 사용하여 목표 이미지를 인식하고 분류한다.FER-2013데이터베이스에서 이 방법은 감성인식률 68.79 %를 달성하였다. 기존의 다른 감성 인식 모델과 비교하면, 이 모델은 뚜렷한 장점을 보일 수 있다. 본 게임은 Socket 통신방식을 통해 감성인식결과를 Seven Poker로 전송하여 아바타가 게이머와 같은 감성을 표현하도록 설계하였다. 온라인 포커 게임에 감성연결 기술을 이용하면 게임과 인간의 상호작용이 향상될 뿐 아니라 게이머가 상대방의 심리적인 활동을 효과적으로 분석할 수 있다. 감성연결 기술은 게임에서 게이머들에게 새로운 게임 경험을 제공할 수 있는 기술이라고 생각된다.","Compared to other types of games, poker game is a psychological game based on gamer s psychological activity. This paper proposes a method based on convolutional neural network (CNN) and support vector machine (SVM) to realize the emotion recognition to link the gamer and his avatar in online poker game. The CNN model is used to extract feature of the original face images, and the multi-class SVM classifier is used to classify the emotions. On the FER-2013 database, the proposed method achieves 68.79% emotion recognition rate, and has obvious advantages compared with most other emotion recognition methods. Next, through the socket communication, the result of the emotion recognition is transferred to the designed seven poker game to realize the emotion linkage between the gamer and his avatar. More importantly, the emotion linkage technology not only helps the gamer to analyze the opponent’s psychological state, but also enhances the interaction of the game. It is undoubtedly a new breakthrough in game play that will give gamers a whole new gaming experience."
자동 표적 인식을 위한 이종 데이터 간 심층 전이 학습,2018,"['transfer learning', 'Automatic Target Recognition(ATR)', 'Heterogeneous sensor', 'InfraRed(IR)', 'Electro Optical(EO)']",,"Recently, convolutional neural network(CNN) has shown remarkable performance in the field of computer vision thanks to the availability of large-scale dataset. With its extremely high-level feature extraction capabilities, CNN has been expected to resolve automatic target recognition(ATR) problems. Since the automatic tareget recogntion(ATR) data is military-purpose data, it has a limited amount of labeled data, which is a problem in learning deep CNN. Thus, previous ATR methods have tried to supplement the data using simulated data or other available data. However, most of them are homogeneous sensor data rather than heterogeneous sensor due to distinctly different charateristics even though they have abundant knowledge to train CNN. To address these issues, we propose a transfer learning-based framework that can teach ATR algorithms using heterogeneous sensor data. As verification data of the method, we use unlabeled infrared(IR) data as target data and labeled electro optical(EO) data as source data. The verification results demonstrate that the transfer learning scheme can train IR-ATR CNN to learn sensor invariant features of the target with labeled heterogeneous sensor data i.e. EO, which is not possible with normal supervised learning."
3차원 특징볼륨을 이용한 깊이영상 생성 모델,2018,"['깊이영상', '컨볼루션 신경망', '딥러닝', '시차 영상', 'Depth Map', 'Convolutional Neural Network', 'Deep Learning', 'Stereo Image']","본 논문은 컨볼루션 신경망으로 이루어진 학습 모델을 통해 스테레오 영상의 깊이영상 생성 알고리즘을 제안한다. 제안하는 알고리즘은 좌, 우 시차 영상을 입력으로 받아 각 시차영상의 주요 특징을 추출하는 특징 추출부와 추출된 특징을 이용하여 시차 정보를 학습하는 깊이 학습부로 구성된다. 우선 특징 추출부는 2D CNN 계층들로 이루어진 익셉션 모듈(xception module) 및 ASPP 모듈(atrous spatial pyramid pooling) module을 통해 각각의 시차영상에 대한 특징맵을 추출한다. 그 후 각 시차에 대한 특징 맵을 시차에 따라 3차원 형태로 쌓아 3D CNN을 통해 깊이 추정 가중치를 학습하는 깊이 학습부를 거친 후 깊이 영상을 추정한다. 제안하는 알고리즘은 객체 영역에 대해 기존의 다른 학습 알고리즘들 보다 정확한 깊이를 추정하였다.","This paper proposes a depth image generation algorithm of stereo images using a deep learning model composed of a CNN (convolutional neural network). The proposed algorithm consists of a feature extraction unit which extracts the main features of each parallax image and a depth learning unit which learns the parallax information using extracted features. First, the feature extraction unit extracts a feature map for each parallax image through the Xception module and the ASPP(Atrous spatial pyramid pooling) module, which are composed of 2D CNN layers. Then, the feature map for each parallax is accumulated in 3D form according to the time difference and the depth image is estimated after passing through the depth learning unit for learning the depth estimation weight through 3D CNN. The proposed algorithm estimates the depth of object region more accurately than other algorithms."
잔향 환경 음성인식을 위한 다중 해상도 DenseNet 기반 음향 모델,2018,"['convolutional neural network', 'DenseNet', 'multi-resolution', 'speech recognition']",,"Although deep neural network-based acoustic models have greatly improved the performance of automatic speech recognition (ASR), reverberation still degrades the performance of distant speech recognition in indoor environments. In this paper, we adopt the DenseNet, which has shown great performance results in image classification tasks, to improve the performance of reverberant speech recognition. The DenseNet enables the deep convolutional neural network (CNN) to be effectively trained by concatenating feature maps in each convolutional layer. In addition, we extend the concept of multi-resolution CNN to multi-resolution DenseNet for robust speech recognition in reverberant environments. We evaluate the performance of reverberant speech recognition on the single-channel ASR task in reverberant voice enhancement and recognition benchmark (REVERB) challenge 2014. According to the experimental results, the DenseNet-based acoustic models show better performance than do the conventional CNN-based ones, and the multi-resolution DenseNet provides additional performance improvement."
Diabetes detection using deep learning algorithms,2018,"['Deep learning', 'Diabetes', 'Heart rate variability', 'ECG', 'CNN', 'LSTM']",,"Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%."
Generative Adversarial Network를 활용한 Image2Vec기반 이미지 검색 모델 개발,2018,"['Deep Learning', 'Information Retrieval', 'Sketch Retrieval', 'Fashion Technique', 'CNN', '딥러닝', '정보 검색', '스케치 검색', '패션 기술', 'CNN']","검색에서 이미지는 시각적 속성이 중요지만, 기존의 검색방법은 문서 검색을 위한 방법에 초점이 맞춰져 있어 이미지의 속성 정보가 미반영된 키워드 중심의 검색 시스템이 대부분이다. 본 연구는 이러한 한계를 극복하고자 이미지의 벡터 정보를 기반으로 유사 이미지를 검색할 수 있는 모델과 스케치로 검색 쿼리를 제공하여 유사 이미지를 검색할 수 있는 시스템을 개발하였다. 제안된 시스템은 GAN을 이용하여 스케치를 이미지 수준으로 업 샘플링하고, 이미지를 CNN을 통해 벡터로 변환한 후, 벡터 공간 모델을 이용하여 유사 이미지를 검색한다. 제안된 모델을 구현하기 위하여 패션 이미지를 이용하여 모델을 학습시켰고 패션 이미지 검색 시스템을 개발하였다. 성능 측정은 Precision at k를 이용하였으며, 0.774와 0.445의 성능 결과를 보였다. 제안된 방법을 이용하면 이미지 검색 의도를 키워드로 표현하는데 어려움을 느끼는 사용자들의 검색 결과에 긍정적 효과가 나타날 것으로 기대된다.","The most of the IR focus on the method for searching the document, so the keyword-based IR system is not able to reflect the feature information of the image. In order to overcome these limitations, we have developed a system that can search similar images based on the vector information of images, and it can search for similar images based on sketches. The proposed system uses the GAN to up sample the sketch to the image level, convert the image to the vector through the CNN, and then retrieve the similar image using the vector space model. The model was learned using fashion image and the image retrieval system was developed. As a result, the result is showed meaningful performance."
공분산과 모듈로그램을 이용한 콘볼루션 신경망 기반 양서류 울음소리 구별,2018,[],,"In this paper, a covariance matrix and modulogram are proposed for realizing amphibian sound classification using CNN (Convolutional Neural Network). First of all, a database is established by collecting amphibians sounds including endangered species in natural environment. In order to apply the database to CNN, it is necessary to standardize acoustic signals with different lengths. To standardize the acoustic signals, covariance matrix that gives distribution information and modulogram that contains the information about change over time are extracted and used as input to CNN. The experiment is conducted by varying the number of a convolutional layer and a fully-connected layer. For performance assessment, several conventional methods are considered representing various feature extraction and classification approaches. From the results, it is confirmed that convolutional layer has a greater impact on performance than the fully-connected layer. Also, the performance based on CNN shows attaining the highest recognition rate with 99.07 % among the considered methods."
라즈베리파이를 활용한 해충 인식 시스템 설계,2018,"['컨볼루션 뉴럴 네트워크', '해충 감지', '딥러닝', '라즈베리파이', '텐서플로우', 'Convolution Neural Network', 'Pest Detection', 'Deep Learning', 'Raspberry Pi', 'TensorFlow']","4차 산업혁명의 발달과 함께 농업에 최신 ICT기술을 도입하기 위한 많은 연구가 진행되고 있다. 그러나 노지농업의 경우 외부에서 작업하는 특성상 환경 제어가 힘들고 해충에 의한 질병이 가장 문제가 되고 있다. 이러한 문제를 해결하기 위해 현재 IT페로몬 트랩을 사용하여 문제를 해결하고 있으나, 진단 결과가 전문가에게 전달되기까지는 매우 오래 걸리며 이를 진단하기까지 전문 노동력을 소비하여 결과를 받을 수 있는 문제가 있다. 위의 문제점을 해결하기 위해 설치비용이 적게 드는 라즈베리파이를 활용한 CNN기법을 통해 해충 이미지에서 해충의 개수를 파악하는 시스템을 제안하고자 한다. CNN분석을 위해해충이미지를 국가기관 및 구글 이미지에서 추출하였으며 실제 해충이 발생하는 농가에 설치하여 추출한 이미지를 포함시켰다. 부족한 이미지는 8개의 방향으로 이미지를 회전시켜 학습시키고 1차적으로 라즈베리에서 해충의 특징을 추출한 뒤 2차로 클라우드 서버에서 이미지를 통해 분석을 실시하는 시스템이다. 위의 방법을 사용함으로써 농민 해충의 생산성을 증대시키고, 전문 조직의 선진 인력의 노동력을 감소시킬 것으로 기대된다.","With the development of the 4th industrial revolution, much research is underway to introduce the latest ICT technology in agriculture. In the case of the bare ground agriculture, however, it is difficult to control the environment in order to work from the outside, and diseases caused by pests are the most problematic. Currently, IT pheromone traps are being used by farmers to solve the above problems, but it takes a very long time to send the results to the experts to receive the diagnosis and the result of the action, which is problematic because of the high labor consumption. In order to solve the above problem, we try to understand the number of insect pests by analyzing the image through the proposed CNN method by taking pest image using Raspberry pie with low installation cost. For CNN analysis, pest images were extracted from national organizations and Google images, and images were extracted from farms where actual pests were generated. The insufficient pest image is a system that rotates the image in eight directions, first extracts the characteristics of the pest from raspberry pi, and secondly analyzes the image through the cloud server. By using the above method, it is expected that it will reduce productivity of pests of farmers and increase the productivity and reduce the labor force of advanced manpower of professional organizations."
합성곱 신경망을 이용한 스마트 토이의 음성명령 학습에 관한 연구,2018,"['AI', 'CNN', 'IoT', 'Smart toy', 'Voice command', 'Voice learning']",,"Recently, as the IoT(Internet of Things) and AI(Artificial Intelligence) technologies have developed, smart toys that can understand and act on the language of human beings are being studied. In this paper, we study voice learning using CNN(Convolutional Neural Network) by applying artificial intelligence based voice secretary technology to smart toy. When a human voice command gives, Smart Toy recognizes human voice, converts it into text, analyzes the morpheme, and conducts tagging and voice learning. As a result of test for the simulator program implemented using Python, no malfunction occurred in a single command. And satisfactory results were obtained within the selected simulation condition range."
사운드 이벤트 감지를 통한 기계 상태 모니터링,2018,"['Mechanical fault detection', 'CNN', 'Sound analysis', 'Status monitoring', 'STFT']",,
CT 영상의 심층학습에 의한 뇌 지주막하 출혈 진단 보조 시스템 개발,2018,"['Brain Subarachnoid Hemorrhage', 'CT Image', 'Deep Learing', 'CNN', 'Morphology Operation', 'Histogram Stretching', '뇌 지주막하 출혈', 'CT 영상', '심층학습', '모폴로지 연산', '히스토그램 스트레칭']","본 논문에서는 CT 영상의 전처리와 심층학습에 의한 뇌 지주막하 출혈의 진단을 위한 보조 시스템을 개발한다. 여기서 전처리는 CT 뇌 영상을 이진화하여 노이즈 제거를 위해 모폴로지 연산을 수행하고, 이진 마스크를 이용해 관심영역을 추출하며, 영상의 크기를 재조정하여 계산부하를 줄인다. 또한 심층학습은 Convolutional neural network(CNN)을 이용하여 전처리된 영상들을 대상으로 이루어지며, 새로이 입력되는 CT 뇌 영상의 정상과 비정상을 판단한다. 특히 비정상으로 판단된 영상에 대해서는 히스토그램 스트레칭으로 출혈 부분의 가시도를 증가시켜 강조함으로써 좀 더 빠르고 정확하게 진단될 수 있도록 한다. 제안된 시스템을 512*512 픽셀의 RGB DICOM 영상 124개를 대상으로 실험한 결과 우수한 진단 성능이 있음을 알 수 있다.","In this paper, we develop a diagnostic assistant system of brain subarachnoid hemorrhage by the pre-processing and deep learning of CT images. The pre-processing performs a morphology operation to remove the noise in CT brain image, and extract the region of interest by using a binary mask, and reduce the calculation load by resizing the image. And deep learning is performed on preprocessed images using convolutional neural network, determine the normality and abnormality of the newly entered CT brain image. Especially, the histogram stretching is performed for the images judged to be abnormal, which increases the visibility of the bleeding part and emphasizes it, so that it can be diagnosed more quickly and accurately. The proposed method has been applied to diagnose RGB 124-brain CT images of 512*512 pixels. The experimental results show that the proposed method has an excellent diagnostic performance."
카테고리 계층을 고려한 회선신경망의 이미지 분류,2018,"['Convolutional Neural Networks', 'Image Classification', 'Category Hierarchy']",,"In order to improve the performance of image classifications using Convolutional Neural Networks (CNN), applying a category hierarchy to the classification can be a useful idea. However, the visual separation of object categories is very different according to the upper and lower category levels and highly uneven in image classifications. Therefore, it is doubtable whether the use of category hierarchies for classification is effective in CNN. In this paper, we have clarified whether the image classification using category hierarchies improves classification performance, and found at which level of hierarchy classification is more effective. For experiments we divided the image classification task according to the upper and lower category levels and assigned image data to each CNN model. We identified and compared the results of three classification models and analyzed them. Through the experiments, we could confirm that classification effectiveness was not improved by reduction of number of categories in a classification model. And we found that only with the re-training method in the last network layer, the performance of lower category classification was not improved although that of higher category classification was improved."
Convolutional Neural Network based Audio Event Classification,2018,"['Audio event classification', 'Convolutional neural networks', 'Deep learning']",,"This paper proposes an audio event classification method based on convolutional neural networks (CNNs). CNN has great advantages of distinguishing complex shapes of image. Proposed system uses the features of audio sound as an input image of CNN. Mel scale filter bank features are extracted from each frame, then the features are concatenated over 40 consecutive frames and as a result, the concatenated frames are regarded as an input image. The output layer of CNN generates probabilities of audio event (e.g. dogs bark, siren, forest). The event probabilities for all images in an audio segment are accumulated, then the audio event having the highest accumulated probability is determined to be the classification result. This proposed method classified thirty audio events with the accuracy of 81.5% for the UrbanSound8K, BBC Sound FX, DCASE2016, and FREESOUND dataset."
딥러닝 기반의 무기 소지자 탐지,2018,"['Object-related human detection', 'Pose estimation', 'Object detection', 'CNN', 'Deep learning']",,"Nowadays, gun crimes occur very frequently not only in public places but in alleyways around the world. In particular, it is essential to detect a person armed by a pistol to prevent those crimes since small guns, such as pistols, are often used for those crimes. Because conventional works for armed person detection have treated an armed person as a single object in an input image, their accuracy is very low. The reason for the low accuracy comes from the fact that the gunman is treated as a single object although the pistol is a relatively much smaller object than the person. To solve this problem, we propose a novel algorithm called APDA(Armed Person Detection Algorithm). APDA detects the armed person using in a post-processing the positions of both wrists and the pistol achieved by the CNN-based human body feature detection model and the pistol detection model, respectively. We show that APDA can provide both 46.3% better recall and 14.04% better precision than SSD-MobileNet."
Generating Pixel Art from Game Characters with Convolutional-Neural Network,2018,"['pixel art', 'deep learning', 'image abstraction', 'non-photorealistic rendering']","픽셀 아트는 낮은 해상도와 제한된 색 팔레트를 가지고 영상을 표현한다. 픽셀 아트는 낮은 연산 성능과 적은 저장 공간을 가지는 초기 컴퓨터 게임에서 주로 사용되었다. 현대에 이르러, 픽셀 아트는 예술이나 퍼즐, 게임과 같은 다양한 분야에서 찾아볼 수 있게 되었다.본 논문에서는 게임 캐릭터 영상을 입력으로 받는 픽셀 아트 생성 모델을 제안한다. 기존 방법과는 달리, 합성곱 신경망(CNN:Convolutional-Neural Network)를 픽셀 아트 생성 목적에 맞게 변형하여 이를 이용하는 방법을 제시한다. 기존의 합성곱 연산 후에 upsampling 과정을 추가하여 픽셀 아트가 생성될 수 있도록 하였다. 네트워크는 ground truth와 생성된 픽셀 아트와의 평균 오차 제곱(MSE:Mean Squared Error)을 최소화해나가며 학습을 수행한다.Ground truth는 실제 아티스트가 생성하도록 하였고, 이미지 회전과 반전 기법을 이용하여 augumentation을 수행하였다. 생성된 데이터 집합은 학습, 검증, 시험 데이터로 나누었다. 이러한 데이터 집합을 기반으로 감독 학습을 실시하여 픽셀 아트 생성 네트워크를 학습하였다. 학습 모델의 학습 과정과 학습 정확도를 제시하고, 시험 데이터 뿐만 아니라 다양한 영상에 대한 픽셀아트 결과도 함께 제시한다.","Pixel art, which presents low-resolutional images with restricted color palette, has been employed frequently in the early computer games played on low memory capacity and computational performance. Recently, pixel art wides its applications to the area such as puzzle and game. In this paper, we present a pixel art generator from images of game characters. Unlike traditional framework, we employ and modify a Convolutional-Neural Network(CNN) to generate pixel art by placing an up-convolution layer after convolution layers. The up-convolution layer increases the resolution of the result images to satisfy user-required resolution. The network is trained by minimizing the Mean Squared Error(MSE) between ground truth images and generated pixel art images from the input high-resolutional image. Also, we employ artists to produce the ground truth of pixel art for our network and augment the data by rotating and fliping. We partition the ground truth images into three datasets: a training, validation and test dataset. With this dataset, we perform a supervised learning and train our network as the pixel art generator. We show a training process and a training accuracy. Moreover, we test our architecture for a various images as well as the test dataset to prove the excellence of our architecture."
A Deep-Learning Based Model for Emotional Evaluation of Video Clips,2018,"['Video emotion analysis', 'C3D', 'Transfer learning', 'LSTM']",,"Emotional evaluation of video clips is the difficult task because it includes not only stationary objects as the background but also dynamic objects as the foreground. In addition, there are many video analysis problems to be solved beforehand to properly address the emotionrelated tasks. Recently, however, the convolutional neural network (CNN)-based deep learning approach, opens the possibility by solving the action recognition problem. Inspired by the CNN-based action recognition technology, this paper challenges to evaluate the emotion of video clips. In the paper, we propose a deep learning model to capture the video features and evaluate the emotion of a video clip on Thayer 2D emotion space. In the model, the pre-trained convolutional 3D neural network (C3D) generates short-term spatiotemporal features of the video, LSTM accumulates those consecutive time-varying features to characterize long-term dynamic behaviors, and multilayer perceptron (MLP) evaluates emotion of a video clip by regression on the emotion space. Due to the limited number of labeled data, the C3D is employed to extract diverse spatiotemporal from various layers by transfer learning technique. The pre-trained C3D on the Sports-1M dataset and long short term memory (LSTM) followed by the MLP for regression are trained in end-to-end manner to fine-tune the C3D, and to adjust weights of LSTM and the MLP-type emotion estimator. The proposed method achieves the concordance correlation coefficient values of 0.6024 for valence and 0.6460 for arousal, respectively. We believe this emotional evaluation of video could be easily associated with appropriate music recommendation, once the music is emotionally evaluated in the same high-level emotional space."
YOLO 기반 외곽 사각형을 이용한 근접 돼지 분리,2018,"['Pig Monitoring', 'Touching Pigs', 'Segmentation', 'Convolution Neural Network', 'YOLO']",,"Although separation of touching pigs in real-time is an important issue for a 24-h pig monitoring system, it is challenging to separate accurately the touching pigs in a crowded pig room. In this study, we propose a separation method for touching pigs using the information generated from Convolutional Neural Network(CNN). Especially, we apply one of the CNN-based object detection methods(i.e., You Look Only Once, YOLO) to solve the touching objects separation problem in an active manner. First, we evaluate and select the bounding boxes generated from YOLO, and then separate touching pigs by analyzing the relations between the selected bounding boxes. Our experimental results show that the proposed method is more effective than widely-used methods for separating touching pigs, in terms of both accuracy and execution time."
전경 객체의 3차원 복원 정밀도 향상 기법 분석,2023,"['3차원 복원', '딥러닝', '배경 제거', '전경 분리', 'Three-dimensional reconstruction', 'Deep learning', 'Background removal', 'Foreground matting']","딥러닝 기술의 발전으로 2차원 영상으로부터 3차원 정보를 정밀하게 생성함으로써 높은 품질의 3차원 복원을 수행하는 기술이 발전하고 있다. 3차원 복원 기술이 일반적으로 갖는 느린 학습 속도의 단점을 개선하기 위해 다양한 연구가 진행되고 있다. 또한, 전경의 3차원 복원 정밀도를 향상시키기 위한 연구가 다양하게 시도되고 있다. 본 논문에서는 배경 영역을 제거하여 전경 영역만을 분리했을 때의 3차원 복원을 세분하여 정량적 및 정성적으로 비교·분석하였다. 실험 결과를 토대로 충분한 외관 특징이 확보 가능한 전경에 대해서 전경을 분리하여 학습하는 것과 학습 영상이 부족한 환경에 대해서 전경 영역을 선택적으로 학습하는 것이 효과적임을 확인했다.","Due to the rapid advancement of deep learning techniques, high-quality 3D reconstruction methods that generate precise 3D information from 2D images have been proposed. However, the long duration for model learning has been a major drawback of 3D reconstruction techniques, and many studies have been conducted to address this issue. In addition, there are many ongoing studies to enhance the precision of the 3D reconstruction for a foreground object. This paper conducts quantitative and qualitative comparisons and analyzes the 3D restoration of an object while matting the foreground areas but excluding the background areas from participating in the learning process. Based on experimental results, it has been noted that it is effective to separate foreground objects with sufficient visual features from background areas and to selectively train the foreground information in the condition of insufficient training data."
키넥트 깊이 정보와 컨볼루션 신경망을 이용한 개별 돼지의 탐지,2018,"['개별 돼지 탐지', '키넥트 깊이정보', '컨볼루션 신경망', '욜로', 'Individual Pig Detection', 'Kinect Depth Information', 'Convolutional Neural Network', 'YOLO']","혼잡한 돈방에서 사육되는 이유자돈들의 공격적인 이상행동들은 축산농가의 경제적 손실을 야기할 뿐만 아니라 동물복지입장에서도 바람직하지 않다. 이러한 문제점의 해결책으로, 최근 IT기반의 연구들이 소개되고 있으나 혼잡한 돈방에서의 돼지 객체 탐지는 여전히 도전적인 문제로 알려져 있다. 본 논문에서는 개별 돼지의 탐지를 위한 키넥트 카메라와 딥러닝 기반의 새로운 모니터링 시스템을 제안한다. 제안된 시스템은 다음과 같다. 1) 키넥트 카메라로부터 취득한 깊이 영상에서 배경 차영상 기법과 깊이 임계값을 이용하여 서있는 돼지만을 탐지한다, 2) 딥러닝 알고리즘 중 최근 가장 빠르고 높은 정확도를 보이는 YOLO(You Only Look Once)를 이용하여 서있는 돼지들을 탐지한다. 본 연구의 실험 결과에 의하면, 제안된 시스템은 경제적인 비용(저가의 키넥트 센서)과 시스템 정확도(평균 99.40% 객체 검출율과 탐지 정확도)로 개별 돼지 객체들을 실시간으로 탐지할 수 있음을 실험적으로 확인하였다.","Aggression among pigs adversely affects economic returns and animal welfare in intensive pigsties. Recently, some studies have applied information technology to a livestock management system to minimize the damage resulting from such anomalies. Nonetheless, detecting each pig in a crowed pigsty is still challenging problem. In this paper, we propose a new Kinect camera and deep learning-based monitoring system for the detection of the individual pigs. The proposed system is characterized as follows. 1) The background subtraction method and depth-threshold are used to detect only standing-pigs in the Kinect-depth image. 2) The standing-pigs are detected by using YOLO (You Only Look Once) which is the fastest and most accurate model in deep learning algorithms. Our experimental results show that this method is effective for detecting individual pigs in real time in terms of both cost-effectiveness (using a low-cost Kinect depth sensor) and accuracy (average 99.40% detection accuracies)."
픽셀단위 상대적 신뢰도와 일치상관계수를이용한 영상의 깊이 추정 알고리즘,2018,"['Convolutional Neural Network', 'Single Depth Image Estimation']",,"In this paper, we describe an algorithm for extracting depth information from a single image based on CNN. When acquiring three-dimensional information from a single two-dimensional image using a deep-learning technique, it is difficult to accurately predict the edge portion of the depth image because it is a part where the depth changes abruptly. in this paper, we introduce the concept of pixel-wise confidence to take advantage of these characteristics. We propose an algorithm that estimates depth information from a highly reliable flat part and propagates it to the edge part to improve the accuracy of depth estimation."
Criticality Enhancement through Critical Discourse,2018,"['criticality', 'critical discourse analysis', 'EFL learners', 'critical thinking', 'internet news resources']",,"This study was designed to explore criticality enhancement of EFL learners through reading with Critical Discourse Analysis (CDA). For the study, two pairs of articles were selected from four different news sources. Before CDA instruction, articles on the Sewol ferry disaster from the CNN.com and the Korea Times were used. After the CDA instruction, articles from the New York Times and the Korea Herald on President Park’s impeachment were used. The participants comprised 78 university students at a university of Gyeonggi-do. They took text analysis tests before and after CDA instructions. In the end, learners replied to 5 questions to inform any changes in their motivation, attitudes, criticality, interests, and class interaction. The findings indicated that learners’ critical analysis was clearly enhanced, though differently depending on the divisions of CDA. The findings of the questionnaire revealed that students’ motivation, criticality, interests and class interactions had changed. (Dankook University)"
메모리 추가 신경망을 이용한 희소 악성코드 분류,2018,"['Malware Classification', 'Visualization', 'Memory Augmented Neural Network']","악성코드의 수가 가파르게 증가하면서 기업 및 공공기관, 금융기관, 병·의원 등을 타깃으로 한 사이버 공격 피해사례가 늘어나고 있다. 이러한 흐름에 따라 학계와 보안 업계에서는 악성코드 탐지를 위한 다양한 연구를 진행하고 있다. 최근 들어서는 딥러닝을 비롯해 머신러닝 기법을 적용하는 형태의 연구가 많이 진행되는 추세다. 이 중 합성곱 신경망(CNN: Convolutional Neural Network), ResNet 등을 이용한 악성코드 분류 연구의 경우에는 기존의 분류 방법에 비해 정확도가 크게 향상된 것을 확인할 수 있다. 그러나 타깃 공격의 특징 중 하나는 사용된 악성코드가 불특정 다수를 상대로 광범위하게 퍼뜨리는 형태가 아닌, 특정 대상을 타깃으로 한 맞춤형 악성코드라는 점이다. 이러한 유형의 악성코드는 그 수가 많지 않기 때문에 기존에 연구되어온 머신러닝이나 딥러닝 기법을 적용하기에 한계가 있다. 본 논문은 타깃형 악성코드와 같이 샘플의 양이 부족한 상황에서 악성코드를 분류하는 방법에 대해 다루고 있다. 메모리가 추가된 신경망(MANN: Memory Augmented Neural Networks) 모델을 이용하였고 각 그룹별 20개의 소량 데이터로 구성되어 있는 악성코드 데이터셋에 대해 최대 97%까지 정확도로 분류할 수있음을 확인하였다.","As the number of malicious code increases steeply, cyber attack victims targeting corporations, public institutions, financial institutions, hospitals are also increasing. Accordingly, academia and security industry are conducting various researches on malicious code detection. In recent years, there have been a lot of researches using machine learning techniques including deep learning. In the case of research using Convolutional Neural Network, ResNet, etc. for classification of malicious code, it can be confirmed that the performance improvement is higher than the existing classification method. However, one of the characteristics of the target attack is that it is custom malicious code that makes it operate only for a specific company, so it is not a form spreading widely to a large number of users. Since there are not many malicious codes of this kind, it is difficult to apply the previously studied machine learning or deep learning techniques. In this paper, we propose a method to classify malicious codes when the amount of samples is insufficient such as targeting type malicious code. As a result of the study, we confirmed that the accuracy of 97% can be achieved even with a small amount of data by applying the Memory Augmented Neural Networks model."
Criticality Enhancement through Critical Discourse,2018,"['criticality', 'critical discourse analysis', 'EFL learners', 'critical thinking', 'internet news resources']",,"This study was designed to explore criticality enhancement of EFL learners through reading with Critical Discourse Analysis (CDA). For the study, two pairs of articles were selected from four different news sources. Before CDA instruction, articles on the Sewol ferry disaster from the CNN.com and the Korea Times were used. After the CDA instruction, articles from the New York Times and the Korea Herald on President Park’s impeachment were used. The participants comprised 78 university students at a university of Gyeonggi-do. They took text analysis tests before and after CDA instructions. In the end, learners replied to 5 questions to inform any changes in their motivation, attitudes, criticality, interests, and class interaction. The findings indicated that learners’ critical analysis was clearly enhanced, though differently depending on the divisions of CDA. The findings of the questionnaire revealed that students’ motivation, criticality, interests and class interactions had changed."
Adjusting the Difficulty of Running Game with Facial Expression Recognition Technology Using Convolutional Neural Network,2018,"['Game Fun', 'Game Difficulty', 'Convolutional Neural Network', 'Expression Recognition']","이제는 모바일 마켓순위에서 많은 게임이 높은 점유율을 차지하지만 점유율을 오랫동안 유지하는 것은 쉽지 않다. 게이머를 끌어당기는 중요한 요소는 게임 재미(Game Fun)이고, 게임을 재미있게 만드는 가장 중요한 요소는 게임 난이도이다. 하지만 게임 난이도를 디자인하는 것은 매우 어려운 일이다.본 논문은 두 개의 연속적인 컨볼루셔널 레이어를 사용한 컨볼루셔널 신경망과 SVM 분류기를 이용하여 게임 시 플레이어의 얼굴 표정을 실시간으로 검출하고 판단한다. 실험 결론은 CNN을 이용한 표정 시스템은 게임 play-time 및 score를 늘릴 수 있고, 게임 재미를 증진시키기에 도와준다고 증명하였다.","Many games nowadays have a certain share of the market. However, to maintain the market position for long is not common. The most appealing element for gamers is Game Fun. The element that can make game interesting is the game difficulty. While the game difficulty has no uniform evaluation standard until now. The proposed paper uses a continuous convolutional neural network with SVM classifier to recognize the player s expression in real time. The system infers the player s psychological activity based on different expressions and makes adjustments to the game difficulty level to meet the user s needs. And the experiment result shows that the facial expression recognition system using deep learning could increase the play-time and score of the game, and promote the fun of games."
준 지도학습과 여러 개의 딥 뉴럴 네트워크를 사용한 멀티 모달 기반 감정 인식 알고리즘,2018,"['Emotion recognition', 'Multi-task learning', 'Semi-supervised learning', 'Multi modal signal', 'EmotiW 2017 challenge']",,"Human emotion recognition is a research topic that is receiving continuous attention in computer vision and artificial intelligence domains. This paper proposes a method for classifying human emotions through multiple neural networks based on multi-modal signals which consist of image, landmark, and audio in a wild environment. The proposed method has the following features. First, the learning performance of the image-based network is greatly improved by employing both multi-task learning and semi-supervised learning using the spatio-temporal characteristic of videos. Second, a model for converting 1-dimensional (1D) landmark information of face into two-dimensional (2D) images, is newly proposed, and a CNN-LSTM network based on the model is proposed for better emotion recognition. Third, based on an observation that audio signals are often very effective for specific emotions, we propose an audio deep learning mechanism robust to the specific emotions. Finally, so-called emotion adaptive fusion is applied to enable synergy of multiple networks. The proposed network improves emotion classification performance by appropriately integrating existing supervised learning and semi-supervised learning networks. In the fifth attempt on the given test set in the EmotiW2017 challenge, the proposed method achieved a classification accuracy of 57.12%."
이종의 OCT 기기로부터 생성된 볼륨 데이터로부터 심층 컨볼루션 신경망을 이용한 AMD 진단,2018,"['OCT', '노년기황반변성(AMD)', '기계 학습', '컨볼루션 신경망', '이미지 분할', 'Optical Coherence Tomography', 'Age-Related Macular Degeneration', 'Machine Learning', 'Convolutional Neural Network', 'Image Segmentation']",신경망을 이용하여 OCT 영상을 분석하고 다양한 망막 질환을 자동 진단하는 것에 관한 연구들이 활발하게 이루어지고 있다. 이러한 연구가 현실에 적용되기 위한 하나의 중요한 요건은 학습된 신경망이 학습에 사용된 데이터와는 다른 기기에서 생성된 데이터에 대해서도 성능의 큰 하락 없이 일반화될 수 있어야 한다는 것이다.본 논문에서는 심층 CNN을 이용하여 OCT 영상으로부터 노년기황반변성(AMD)을 자동 진단하는 것을 다룬다. 하나의 OCT 기기로부터 획득한 데이터 셋을 이용하여 신경망을 학습시킨 후 다른 OCT 기기로부터 생산된 이미지를 테스트한 결과 상당한 성능의 하락을 관찰할 수 있었다. 이러한 성능의 하락을 방지하기 위해서 OCT 이미지를 정규화 하는 기법을 제안하고 실험을 통해 그 효과를 분석하였다. 제안한 기법은 OCT 이미지를 분할하여 망막에 해당하는 영역을 찾아낸 후 이미지 내에서 망막 영역이 수평에 가까운 기울기를 가지도록 정렬(align)하여 형태적인 측면에서 OCT 이미지를 정규화 하는 것을 목적으로 한다. 실험을 통하여 제안한 기법이 이종의 기기에서 생성된 OCT 이미지로부터 AMD를 자동진단 하는데 있어서 상당한 성능의 향상을 달성함을 보였다.,"There have been active research activities to use neural networks to analyze OCT images and make medical decisions. One requirement for these approaches to be promising solutions is that the trained network must be generalized to new devices without a substantial loss of performance. In this paper, we use a deep convolutional neural network to distinguish AMD from normal patients.The network was trained using a data set generated from an OCT device. We observed a significant performance degradation when it was applied to a new data set obtained from a different OCT device. To overcome this performance degradation, we propose an image normalization method which performs segmentation of OCT images to identify the retina area and aligns images so that the retina region lies horizontally in the image. We experimentally evaluated the performance of the proposed method. The experiment confirmed a significant performance improvement of our approach."
딥러닝 기술을 활용한 멀웨어 분류를 위한 이미지화 기법,2018,"['멀웨어 이미지 생성', '멀웨어 탐지 및 분류', '딥러닝', 'CNN', 'Malware visualization', 'mawlare detection and classification', 'deep learning']","Symantec의 인터넷 보안위협 보고서(2018)에 따르면 크립토재킹, 랜섬웨어, 모바일 등 인터넷 보안위협이 급증하고 있으며 다각화되고 있다고 한다. 이는 멀웨어(Malware) 탐지기술이 암호화, 난독화 등의 문제에 따른 질적 성능향상 뿐만 아니라 다양한 멀웨어의 탐지 등 범용성을 요구함을 의미한다. 멀웨어 탐지에 있어 범용성을 달성하기 위해서는 탐지알고리즘에 소모되는 컴퓨팅 파워, 탐지 알고리즘의 성능 등의 측면에서의 개선 및 최적화가 이루어져야 한다. 본고에서는 최근 지능화, 다각화 되는 멀웨어를 효과적으로 탐지하기 위하여 CNN(Convolutional Neural Network)을 활용한 멀웨어 탐지 기법인, stream order(SO)-CNN과 incremental coordinate(IC)-CNN을 제안한다. 제안기법은 멀웨어 바이너리 파일들을 이미지화 한다. 이미지화 된 멀웨어 바이너리는 GoogLeNet을 통해 학습되어 딥러닝 모델을 형성하고 악성코드를 탐지 및 분류한다. 제안기법은 기존 방법에 비해 우수한 성능을 보인다.","According to Symantec's Internet Security Threat Report(2018), Internet security threats such as Cryptojackings, Ransomwares, and Mobile malwares are rapidly increasing and diversifying. It means that detection of malwares requires not only the detection accuracy but also versatility. In the past, malware detection technology focused on qualitative performance due to the problems such as encryption and obfuscation. However, nowadays, considering the diversity of malware, versatility is required in detecting various malwares. Additionally the optimization is required in terms of computing power for detecting malware. In this paper, we present Stream Order(SO)-CNN and Incremental Coordinate(IC)-CNN, which are malware detection schemes using CNN(Convolutional Neural Network) that effectively detect intelligent and diversified malwares. The proposed methods visualize each malware binary file onto a fixed sized image. The visualized malware binaries are learned through GoogLeNet to form a deep learning model. Our model detects and classifies malwares. The proposed method reveals better performance than the conventional method."
심층신경망 기반 총채벌레 탐색에 관한 연구,2018,"['객체 탐색', '볼록총채벌레', '빠른 지역기반 객체 탐색', '심층신경망', '합성곱 신경망', 'Convolutinal network', 'deep learning', 'Faster R-CNN', 'object detection', 'Scirtothrips dorsalis Hood']","최근 감귤농업에서 주요해층으로 분류되는 미소 객체 (tiny object)인 볼록총채벌레 (Scirtothrips dorsalis Hood)의 탐색은 관심이 많고 어려운 작업으로 알려져 있다. 본 논문에서는 심층신경망을 이용하여 볼록총채벌레를 탐색 (detection)하고자 한다. 분석자료는 황색끈끈이트랩 이미지자료 (250×150mm, 5472×3648픽셀)이며 합성곱 신경망 (convolutional neural network, CNN)인 ResNet을 기반으로 하는 Faster R-CNN (faster regions with CNN) 탐색모형을 사용하였다. 이미지넷(ImageNet)을 사전 학습한 가중치를 사용하고 초모수 (hyperparameter)를 격자탐색법(grid search)으로 선택한 모형을 제안한다. 제안된 모형의 AUC (area under curve)는 0.91로 아주 좋은 결과를 보이는데, 제안된 모형으로 볼록총채벌레의 생태를 파악하여 보다 더 정밀한 방제가 이뤄질 수 있을 것으로 기대한다.","In this paper, we study on a detection of Scirtothrips dorsalis Hood, which is classified as a major insect in citrus farming. The detection is based on the deep neural networks, specifically the Faster R-CNN (faster regions with CNN) model based on CNN (convolutional neural network), with the yellow sticky trap image data (250×150mm, 5472×3648pixels). It was found that the model performance becomes unstable when the object is too small and rare. In order to solve this problem, we use pretrained weights to set the initial value of the model, as well as we select hyperparameters by grid search. Result shows that our proposed model has an high AUC (area under curve) value 0.91. We expect that it would be possible to know more precisely the lifespan of the Scirtothrips dorsalis Hood and to control them more precisely through our proposed model."
기두부와 단 분리 시 조각의 식별을 위한 합성곱 신경망 구조 설계,2018,"['dynamic RCS', 'convolutional neural networks', 'radar target identification', 'warhead', 'debris']",,"In this paper, we designed CNN(Convolutional Neural Network) structure to identify warhead and debris in boosting part separation phase. Through simulation, we determined variables of each layer constituting the CNN and designed CNN structure. Simulation were performed to classify four types of warhead with coning motion and six types of debris with tumbling motion through the CNN designed by the proposed method. Then we compared the performance of CNN with the well-known VGGNet. Simulation results show that the CNN structure optimized by the convolution filter, pooling method, and pooling size determined using the proposed method has equal classification performance or better classification performance than VGGNet for all SNR. In addition, the training time was improved approximately 22 times."
딥러닝을 위한 영역기반 합성곱 신경망에 의한 항공영상에서 건물탐지 평가,2018,"['Deep Learning', 'Region-based Convolutional Neural Network', 'Object Detection', 'Semantic Segmentation', '딥러닝', '역기반 합성곱 신경망', '객체탐지', '의미적 분할']","딥러닝은 인간의 학습 및 인지능력을 닮은 인공지능을 실현하기 위해 여러 분야에서 활용하고 있으며, 높은 사양 의 컴퓨팅 파워가 요구되고 연산 시간이 많이 소요되는 복잡한 구조의 인공신경망에 의한 딥러닝은 컴퓨터 사양이 향상됨에 따라 성능이 개선된 다양한 딥러닝 모델이 개발되고 있다. 본 논문의 주요 목적은 상의 딥러닝을 위한 합성곱 신경망 중에서 최근에 FAIR (Facebook AI Research)에서 개발한 Mask R-CNN을 이용하여 항공상에서 건물을 탐지하고 성능을 평가하는 것이다. Mask R-CNN은 역기반의 합성곱 신경망으로서 픽셀 정확도까지 객 체를 의미적으로 분할하기 위한 딥러닝 모델로서 성능이 가장 우수한 것으로 평가받고 있다. 딥러닝 모델의 성능은 신경망 구조뿐 아니라 학습 능력에 의해 결정된다. 이를 위해 본 논문에서는 모델의 학습에 이용한 상에 다양한 변화를 주어 학습 능력을 분석하으며, 딥러닝의 궁극적 목표인 범용화의 가능성을 평가하다. 향후 연구방안으 로는 상에만 의존하지 않고 다양한 공간정보 데이터를 복합적으로 딥러닝 모델의 학습에 이용하여 딥러닝의 신 뢰성과 범용화가 향상될 것으로 판단된다.","DL (Deep Learning) is getting popular in various fields to implement artificial intelligence that resembles human learning and cognition. DL based on complicate structure of the ANN (Artificial Neural Network) requires computing power and computation cost. Variety of DL models with improved performance have been developed with powerful computer specification. The main purpose of this paper is to detect buildings from aerial images and evaluate performance of Mask R-CNN (Region-based Convolutional Neural Network) developed by FAIR (Facebook AI Research) team recently. Mask R-CNN is a R-CNN that is evaluated to be one of the best ANN models in terms of performance for semantic segmentation with pixel-level accuracy. The performance of the DL models is determined by training ability as well as architecture of the ANN. In this paper, we characteristics of the Mask R-CNN with various types of the images and evaluate possibility of the generalization which is the ultimate goal of the DL. As for future study, it is expected that reliability and generalization of DL will be improved by using a variety of spatial information data for training of the DL models."
깊이맵 생성 알고리즘의 합성곱 신경망 구현,2018,"['Depth map', 'CNN', 'Saliency map', 'Motion Hitsory Image', 'Ready-made depth map']",,"Depth map has been utilized in a varity of fields. Recently research on generating depth map by artificial neural network (ANN) has gained much interest. This paper validates the feasibility of implementing the ready-made depth map generation by convolutional neural network (CNN). First, for a given image, a depth map is generated by the weighted average of a saliency map as well as a motion history image. Then CNN network is trained by test images and depth maps. The objective and subjective experiments are performed on the CNN and showed that the CNN can replace the ready-made depth generation method."
합성곱 신경망을 사용한 화물차의 차종분류,2018,"['Vehicle Classification', 'Truck Cargo Box', 'Image Classification', 'Convolutional Neural Network', 'Machine Learning', '차종분류', '화물차 적재함', '영상분류', '합성곱 신경망', '기계학습']","본 논문에서는 화물차 차종을 분류하기 위해서 특징추출단계 없이 입력영상으로부터 차종분류결과를 얻을 수 있는 합성곱 신경망을 사용한 분류방법을 제안한다. 차량의 위에서 촬영된 영상을 입력으로 사용하고 입력영상에 적합한 합성곱 신경망의 구조를 설계한다. 차종과 화물칸의 형태에 따라 차종을 자동 분류하기 위한 학습데이터를 생성하고 지도학습의 형태로 학습시키기 위해 분류된 영상과 올바른 출력결과를 제시하여 신경망의 가중치를 학습시킨다. 실제 영상을 입력하여 합성곱 신경망의 출력을 계산하였고 실제 차종과의 비교를 통해 분류 성능을 평가 하였다. 실험결과 화물의 차종과 적재함의 형태에 따라 90%이상의 정확도로 영상을 분류할 수 있었고, 적재불량 검사의 사전 분류에 활용될 수 있다.","This paper proposes a classification method using the Convolutional Neural Network(CNN) which can obtain the type of trucks from the input image without the feature extraction step. To automatically classify vehicle images according to the type of truck cargo box, the top view images of the vehicle are used as input image and we design the structure of the CNN suitable for the input images. Learning images and correct output results is generated and the weights of neural network are obtained through the learning process. The actual image is input to the CNN and the output of the CNN is calculated. The classification performance is evaluated through comparison CNN output with actual vehicle types. Experimental results show that vehicle images could be classified with more than 90 percent accuracy according to the type of cargo box and this method can be used for pre-classification for inspecting loading defect."
Iceberg-Ship Classification in SAR Images Using Convolutional Neural Network with Transfer Learning,2018,"['Convolutional Neural Network', 'Deep Learning', 'Transfer Learning', 'VGG-16', 'Pooling Layer', 'Adam Optimizer', 'Data Augmentation']",,"Monitoring through Synthesis Aperture Radar (SAR) is responsible for marine safety from floating icebergs. However, there are limits to distinguishing between icebergs and ships in SAR images. Convolutional Neural Network (CNN) is used to distinguish the iceberg from the ship. The goal of this paper is to increase the accuracy of identifying icebergs from SAR images. The metrics for performance evaluation uses the log loss. The two-layer CNN model proposed in research of C.Bentes et al.[1] is used as a benchmark model and compared with the four-layer CNN model using data augmentation. Finally, the performance of the final CNN model using the VGG-16 pre-trained model is compared with the previous model. This paper shows how to improve the benchmark model and propose the final CNN model."
Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Machine learning', 'Periodontal diseases', 'Supervised machine learning']",,"Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%–91.2%) for premolars and 73.4% (95% CI, 59.9%–84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT."
Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Machine learning', 'Periodontal diseases', 'Supervised machine learning']",,"Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%-91.2%) for premolars and 73.4% (95% CI, 59.9%-84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT."
심층 학습을 이용한 양식장 그물 찢김 판단,2018,"['smart fishery', 'deep learning', 'convolutional neural networks (CNN)', 'fish farming', 'data augmentation']",,"Damage in fish farming nets can lead to serious losses and/or adverse environmental impact. Nonetheless, detecting such damage is challenging. Human experts could inspect the nets, but this process is costly and time-consuming. Alternatively, remotely operated underwater vehicles (ROV) can be used to inspect the fishnets. By using advanced deep-learning techniques for autonomous navigation and object detection, fishnets can be inspected efficiently while minimizing human intervention. In this paper, a deep convolutional neural networks (CNN) is employed to classify images of torn and normal fishnets. Training deep CNN models requires numerous image data, whereas a limited amount of fishnet images are available. To resolve the dearth of available data, data-augmentation techniques are adopted to generate images of torn and normal fishnets. The trained CNN model shows high accuracy for classifying the given augmented test dataset."
Convolutional Neural Network Based Image Processing System,2018,"['Artificial intelligence', 'Convolutional neural network (CNN)', 'Deep learning', 'Pattern recognition']",,"This paper designed and developed the image processing system of integrating feature extraction and matching by using convolutional neural network (CNN), rather than relying on the simple method of processing feature extraction and matching separately in the image processing of conventional image recognition system. To implement it, the proposed system enables CNN to operate and analyze the performance of conventional image processing system. This system extracts the features of an image using CNN and then learns them by the neural network. The proposed system showed 84% accuracy of recognition. The proposed system is a model of recognizing learned images by deep learning. Therefore, it can run in batch and work easily under any platform (including embedded platform) that can read all kinds of files anytime. Also, it does not require the implementing of feature extraction algorithm and matching algorithm therefore it can save time and it is efficient. As a result, it can be widely used as an image recognition program."
전이학습에 방법에 따른 컨벌루션 신경망의영상 분류 성능 비교,2018,"['Deep Learning', 'Computer Vision', 'Convolutional Neural Network', 'Transfer Learnin']",,"Core algorithm of deep learning Convolutional Neural Network(CNN) shows better performance than other machine learning algorithms. However, if there is not sufficient data, CNN can not achieve satisfactory performance even if the classifier is excellent. In this situation, it has been proven that the use of transfer learning can have a great effect. In this paper, we apply two transition learning methods(freezing, retraining) to three CNN models(ResNet-50, Inception-V3, DenseNet-121) and compare and analyze how the classification performance of CNN changes according to the methods. As a result of statistical significance test using various evaluation indicators, ResNet-50, Inception-V3, and DenseNet-121 differed by 1.18 times, 1.09 times, and 1.17 times, respectively. Based on this, we concluded that the retraining method may be more effective than the freezing method in case of transition learning in image classification problem."
데이터 기반 영역 제안 및 심층 학습 분류 네트워크를 이용한 소형 적외선 드론 검출,2018,"['infrared small target detection', 'infrared small drone detection', 'deep learning', 'region proposal', 'classification']",,"In this paper, we propose a data-driven and deep-learning based classification scheme for small infrared target detection. Previous studies have shown feasible performance using conventional computer vision techniques, such as spatial and temporal filters. However, those handcrafted approaches are not optimized due to the nature of the application fields. Recently, deep-learning has shown excellent performance for many computer vision problems. The proposed data-driven proposal and convolutional neural network (DDP-CNN) approach can generate possible target locations through the DDP, and final targets are recognized through the CNN for classification. According to the experimental results using drone databases, the DDP-CNN shows an 0.85 average precision (AP) of target detection."
딥러닝 기반 기사단위 및 문단 단위별 분류,2018,"['Genre Classification', 'Deep Learning', 'Word2Vec', 'Long Short-Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Networks (CNN)', 'Word embedding']",,"Text classification has been studied for a long time in the Natural Language Processing field. In this paper, we propose an article- and paragraph-level genre classification system using Word2Vec-based LSTM, GRU, and CNN models for large-scale English corpora. Both article- and paragraph-level classification performed best in accuracy with LSTM, which was followed by GRU and CNN in accuracy performance. Thus, it is to be confirmed that in evaluating the classification performance of LSTM, GRU, and CNN, the word sequential information for articles is better than the word feature extraction for paragraphs when the pre-trained Word2Vec-based word embeddings are used in both deep learning-based article- and paragraph-level classification tasks."
딥러닝 앙상블을 이용한 주가예측,2018,"['Deep Learning', 'Ensemble', 'Stacking', 'Stock Price Prediction', '딥러닝', '앙상블', '스태킹', '주가예측']","최근 딥러닝(Deep Learning)을 이용한 주가예측이 활발하게 연구되고 있으나, 서로 다른 딥러닝 모델들을 결합하는 앙상블(Ensemble) 방법에 대한 연구는 초기 단계이다. 딥러닝 모델에는 Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN)이 있다. 본 논문에서는 세 가지 딥러닝 모델(MLP, CNN, RNN)이 예측한 결과를 결합하고 MLP를 사용하여 다시 학습하는 스태킹(Stacking) 기반의 앙상블 모델을 사용하여 주가를 예측한다. KOSPI 상위 30 종목 중 18개 종목을 이용하여 실험한 결과, 제안한 방법이 기존 방법에 비해 절대평균백분율오차(MAPE)가 8.74%에서 3.35%로 감소하였다.","Recently, there have been research efforts on predicting stock price using deep learning, but little attention has been paid so far to ensemble methods, which combines different deep learning models. Deep learning models include Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN). In this paper, we propose a stacking-based ensemble model where a deep learning model combines predictions of three different deep learning models (MLP, CNN, and RNN). We use MLP as the second level model. The experimental results using 18 stock items among KOSPI top 30 items show that the proposed method improves the mean absolute percentage error (MAPE) from 8.74%, which is the MAPE of the state-of-the-art method, to 3.35%."
Business Application of Convolutional Neural Networks for Apparel Classification Using Runway Image,2018,"['Convolutional Neural Networks', 'Image Classification', 'Apparel', 'Runway', 'Mobility', '합성곱 신경망', '이미지 분류', '의류', '런웨이', '이동성']",,"Large amount of data is now available for research and business sectors to extract knowledge from it. This data can be in the form of unstructured data such as audio, text, and image data and can be analyzed by deep learning methodology. Deep learning is now widely used for various estimation, classification, and prediction problems. Especially, fashion business adopts deep learning techniques for apparel recognition, apparel search and retrieval engine, and automatic product recommendation. The core model of these applications is the image classification using Convolutional Neural Networks (CNN). CNN is made up of neurons which learn parameters such as weights while inputs come through and reach outputs. CNN has layer structure which is best suited for image classification as it is comprised of convolutional layer for generating feature maps, pooling layer for reducing the dimensionality of feature maps, and fully-connected layer for classifying the extracted features. However, most of the classification models have been trained using online product image, which is taken under controlled situation such as apparel image itself or professional model wearing apparel. This image may not be an effective way to train the classification model considering the situation when one might want to classify street fashion image or walking image, which is taken in uncontrolled situation and involves people’s movement and unexpected pose. Therefore, we propose to train the model with runway apparel image dataset which captures mobility. This will allow the classification model to be trained with far more variable data and enhance the adaptation with diverse query image. To achieve both convergence and generalization of the model, we apply Transfer Learning on our training network. As Transfer Learning in CNN is composed of pre-training and fine-tuning stages, we divide the training step into two. First, we pre-train our architecture with large-scale dataset, ImageNet dataset, which consists of 1.2 million images with 1000 categories including animals, plants, activities, materials, instrumentations, scenes, and foods. We use GoogLeNet for our main architecture as it has achieved great accuracy with efficiency in ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Second, we fine-tune the network with our own runway image dataset. For the runway image dataset, we could not find any previously and publicly made dataset, so we collect the dataset from Google Image Search attaining 2426 images of 32 major fashion brands including Anna Molinari, Balenciaga, Balmain, Brioni, Burberry, Celine, Chanel, Chloe, Christian Dior, Cividini, Dolce and Gabbana, Emilio Pucci, Ermenegildo, Fendi, Giuliana Teso, Gucci, Issey Miyake, Kenzo, Leonard, Louis Vuitton, Marc Jacobs, Marni, Max Mara, Missoni, Moschino, Ralph Lauren, Roberto Cavalli, Sonia Rykiel, Stella McCartney, Valentino, Versace, and Yve Saint Laurent. We perform 10-folded experiments to consider the random generation of training data, and our proposed model has achieved accuracy of 67.2% on final test. Our research suggests several advantages over previous related studies as to our best knowledge, there haven’t been any previous studies which trained the network for apparel image classification based on runway image dataset. We suggest the idea of training model with image capturing all the possible postures, which is denoted as mobility, by using our own runway apparel image dataset. Moreover, by applying Transfer Learning and using checkpoint and parameters provided by Tensorflow Slim, we could save time spent on training the classification model as taking 6 minutes per experiment to train the classifier. This model can be used in many business applications where the query image can be runway image, product image, or street fashion image. To be specific, runway query image can be used for mobile application service during fashion week to facilitate brand search, street style query image"
딥러닝 기반 암세포 사진 분류 알고리즘,2018,"['CNN', 'Dilated Convolution', 'Image Recognition']",,"CNN (Convolution Neural Network) is one of the most important techniques to identify the kind of objects in the captured pictures. Whereas the conventional models have been used for low resolution images, the technique to recognize the high resolution images becomes crucial in the field of artificial intelligence. In this paper, we proposed an efficient CNN model based on dilated convolution and thresholding techniques to increase the recognition ratio and to decrease the computational complexity. The simulation results show that the proposed algorithm outperforms the conventional method and the thresholding technique enhances the performance of the proposed model."
트랜슬레이션 임베딩 기반 관계 학습을 이용한 GUI 위젯 인식,2018,"['Deep neural nets', 'Object recognition', 'Relation learning', 'Widget recognition', 'App test']",,"CNN based object recognitions have reported splendid results. However, the recognition of mobile apps raises an interesting challenge that recognition performance of similar widgets is not consistent. In order to improve the performance, we propose a noble method utilizing relations between input widgets. The recognition process flows from the Faster R-CNN based recognition to enhancement using a relation recognizer. The relations are represented as vector translation between objects in a relation space. Experiments on 323 apps show that our method significantly enhances the Faster R-CNN only approach."
GoogLenet 기반의 딥 러닝을 이용한 향상된 한글 필기체 인식,2018,"['한글 필기체 인식', 'CNN', 'GoogLenet', 'PE92 데이터베이스', 'Handwritten Hangeul Recognition', 'PE92 Database']","딥 러닝 기술의 등장으로 여러 나라의 필기체 인식은 높은 정확도 (중국어 필기체 인식은 97.2%, 일본어 필기체 인식은 99.53%)를 보인다. 하지만 한글 필기체는 한글의 특성으로 유사글자가 많은데 비해 문자의 데이터 수는 적어 글자 인식에 어려움이 있다. 하이브리드 러닝을 통한 한글 필기체 인식에서는 lenet을 기반으로 하여 낮은 레이어를 가진 모델을 사용하여 한글 필기체 데이터베이스 PE92에서 96.34%의 정확도를 보여주었다. 본 논문에서는 하이브리드 러닝에서 사용하였던 데이터 확장 기법(data augmentation)이나 multitasking을 사용하지 않고도 GoogLenet 네트워크를 기본으로 한글 필기체 데이터에 적합한 더 깊고 더 넓은 CNN(Convolution Neural Network) 네트워크를 도입하여 PE92 데이터베이스에서 98.64%의 정확도를 얻었다.","The advent of deep learning technology has made rapid progress in handwritten letter recognition in many languages. Handwritten Chinese recognition has improved to 97.2% accuracy while handwritten Japanese recognition approached 99.53% percent accuracy. Hanguel handwritten letters have many similar characters due to the characteristics of Hangeul, so it was difficult to recognize the letters because the number of data was small. In the handwritten Hanguel recognition using Hybrid Learning, it used a low layer model based on lenet and showed 96.34% accuracy in handwritten Hanguel database PE92. In this paper, 98.64% accuracy was obtained by organizing deep CNN (Convolution Neural Network) in handwritten Hangeul recognition. We designed a new network for handwritten Hangeul data based on GoogLenet without using the data augmentation or the multitasking techniques used in Hybrid learning."
Discriminative Manifold Learning Network using Adversarial Examples for Image Classification,2018,"['Manifold learning', 'Discriminative feature', 'CNN', 'Adversarial examples', 't-SNE', 'Dimensionality reduction']",,"This study presents a novel approach of discriminative feature vectors based on manifold learning using nonlinear dimension reduction (DR) technique to improve loss function, and combine with the Adversarial examples to regularize the object function for image classification. The traditional convolutional neural networks (CNN) with many new regularization approach has been successfully used for image classification tasks, and it achieved good results, hence it costs a lot of Calculated spacing and timing. Significantly, distrinct from traditional CNN, we discriminate the feature vectors for objects without empirically-tuned parameter, these Discriminative features intend to remain the lower-dimensional relationship corresponding high-dimension manifold after projecting the image feature vectors from high-dimension to lower-dimension, and we optimize the constrains of the preserving local features based on manifold, which narrow the mapped feature information from the same class and push different class away. Using Adversarial examples, improved loss function with additional regularization term intends to boost the Robustness and generalization of neural network. experimental results indicate that the approach based on discriminative feature of manifold learning is not only valid, but also more efficient in image classification tasks. Furthermore, the proposed approach achieves competitive classification performances for three benchmark datasets : MNIST, CIFAR-10, SVHN."
Discriminative Manifold Learning Network using Adversarial Examples for Image Classification,2018,"['Manifold learning', 'Discriminative feature', 'CNN', 'Adversarial examples', 't-SNE', 'Dimensionality reduction']",,"This study presents a novel approach of discriminative feature vectors based on manifold learning using nonlinear dimension reduction (DR) technique to improve loss function, and combine with the Adversarial examples to regularize the object function for image classification. The traditional convolutional neural networks (CNN) with many new regularization approach has been successfully used for image classification tasks, and it achieved good results, hence it costs a lot of Calculated spacing and timing. Significantly, distrinct from traditional CNN, we discriminate the feature vectors for objects without empirically-tuned parameter, these Discriminative features intend to remain the lower-dimensional relationship corresponding high-dimension manifold after projecting the image feature vectors from high-dimension to lower-dimension, and we optimize the constrains of the preserving local features based on manifold, which narrow the mapped feature information from the same class and push different class away. Using Adversarial examples, improved loss function with additional regularization term intends to boost the Robustness and generalization of neural network. experimental results indicate that the approach based on discriminative feature of manifold learning is not only valid, but also more efficient in image classification tasks. Furthermore, the proposed approach achieves competitive classification performances for three benchmark datasets : MNIST, CIFAR-10, SVHN."
딥러닝 기반 손상된 흑백 얼굴 사진 컬러 복원,2018,"['Inpainting', 'Colorization', 'Deep Learning', 'BEGAN', 'CNN', '복원', '컬러화', '딥러닝', '경계 평형 생성 적대 네트워크', '합성곱 신경망']","본 논문에서는 손상된 흑백 얼굴 이미지를 컬러로 복원하는 방법을 제안한다. 기존 연구에서는 오래된 증명사진처럼 손상된 흑백 사진에 컬러화 작업을 하면 손상된 영역 주변이 잘못 색칠되는 경우가 있었다. 이와 같은 문제를 해결하기 위해 본 논문에서는 입력받은 사진의 손상된 영역을 먼저 복원한 후 그 결과를 바탕으로 컬러화를 수행하는 방법을 제안한다. 본 논문의 제안 방법은 BEGAN(Boundary Equilibrium Generative Adversarial Networks) 모델 기반 복원과 CNN(Convolutional Neural Network) 기반 컬러화의 두 단계로 구성된다. 제안하는 방법은 이미지 복원을 위해 DCGAN(Deep Convolutional Generative Adversarial Networks) 모델을 사용한 기존 방법들과 달리 좀 더 선명하고 고해상도의 이미지 복원이 가능한 BEGAN 모델을 사용하고, 그 복원된 흑백 이미지를 바탕으로 컬러화 작업을 수행한다. 최종적으로 다양한 유형의 얼굴 이미지와 마스크에 대한 실험 결과를 통해 기존 연구에 비해 많은 경우에 사실적인 컬러 복원 결과를 보여줄 수 있음을 확인하였다.","In this paper, we propose a method to restore corrupted black and white facial images to color. Previous studies have shown that when coloring damaged black and white photographs, such as old ID photographs, the area around the damaged area is often incorrectly colored. To solve this problem, this paper proposes a method of restoring the damaged area of input photo first and then performing colorization based on the result. The proposed method consists of two steps: BEGAN (Boundary Equivalent Generative Adversarial Networks) model based restoration and CNN (Convolutional Neural Network) based coloring. Our method uses the BEGAN model, which enables a clearer and higher resolution image restoration than the existing methods using the DCGAN (Deep Convolutional Generative Adversarial Networks) model for image restoration, and performs colorization based on the restored black and white image. Finally, we confirmed that the experimental results of various types of facial images and masks can show realistic color restoration results in many cases compared with the previous studies."
Facial Expression Classification Using Deep Convolutional Neural Network,2018,"['Convolutional neural network', 'Facial expression', 'Data augmentation', 'Database']",,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. The proposed structure has general classification performance for any environment or subject. For this purpose, we collect a variety of databases and organize the database into six expression classes such as ‘expressionless’, ‘happy’, ‘sad’, ‘angry’, ‘surprised’ and ‘disgusted’. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. In the existing CNN structure, the optimal structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of nodes of fully-connected layer. The experimental results show good classification performance compared to the state-of-the-arts in experiments of the cross validation and the cross database. Also, compared to other conventional models, it is confirmed that the proposed structure is superior in classification performance with less execution time."
A Self-ensemble Approach for Noise and Compression Artifacts Removal using Convolutional Neural Network,2018,"['Image denoising', 'Compression artifacts removal', 'Convolutional neural network', 'Ensemble approach']",,"There have been many discriminative learning methods using convolutional neural networks (CNN) for image restoration problems, which learn the mapping function from a degraded input to the clean output. In this paper, we propose a self-ensemble method that can find enhanced restoration results from the multiple trials of a trained CNN with different but related inputs. Specifically, it is noted that the CNN sometimes finds different mapping functions when the input is transformed by a reversible transform and thus produces different but related outputs with the original. Hence averaging the outputs for several different transformed inputs can enhance the results as evidenced by the network ensemble methods. Unlike the conventional ensemble approaches that require several networks, the proposed method needs only a single network. Experimental results show that adding an additional transform usually brings additional gain on image denoising and artifacts removal problems."
HVS-Aware Single-Shot HDR Imaging Using Deep Convolutional Neural Network,2018,"['High dynamic range (HDR) imaging', 'spatially varying exposure (SVE) imaging', 'convolutional neural network (CNN)']",,"We propose a single-shot high dynamic range (HDR) imaging algorithm using a deep convolutional neural network (CNN) for row-wise varying exposures in a single image. The proposed algorithm restores missing information resulting from under- and/or over-exposed pixels in an input image and reconstructs the raw radiance map. The main contribution of this work is the development of a loss function for the CNN employing the human visual system (HVS) properties. Then, the HDR image is obtained by applying a demosaicing algorithm. Experimental results demonstrate that the proposed algorithm provides higher-quality HDR images than conventional algorithms."
HVS-Aware Single-Shot HDR Imaging Using Deep Convolutional Neural Network,2018,"['High dynamic range (HDR) imaging', 'spatially varying exposure (SVE) imaging', 'convolutional neural network (CNN)']",,"We propose a single-shot high dynamic range (HDR) imaging algorithm using a deep convolutional neural network (CNN) for row-wise varying exposures in a single image. The proposed algorithm restores missing information resulting from under- and/or over-exposed pixels in an input image and reconstructs the raw radiance map. The main contribution of this work is the development of a loss function for the CNN employing the human visual system (HVS) properties. Then, the HDR image is obtained by applying a demosaicing algorithm. Experimental results demonstrate that the proposed algorithm provides higher-quality HDR images than conventional algorithms."
합성곱 신경망을 이용한 농산물 기사 감성 분석,2018,"['감성분석', '오피니언 마이닝', '텍스트 마이닝', '농산물가격', '합성곱 신경망', 'emotional analysis', 'opinion mining', 'text mining', 'agricultural price', 'convolutional neural networks']","본 논문에서는 농산물 가격의 등락을 기준으로 감성사전을 구축하여 농산물 관련 온라인 뉴스의 긍정/부정을 분류하는 방법을 제안한다. 이를 위해 비정형 텍스트문서를 문장 단위로 분할한 뒤 분석내용과 연관 없거나 가격 등락에 상관없이 빈번하게 언급된 단어들을 불용어로 처리한다. 형태소 분석을 진행한 후 비지도 학습 기반으로 키워드를 추출하여 합성곱 신경망(Convolutional Neural Networks, CNN)을 이용해 긍정/부정 분류를 수행하였다. 그 결과 빈도기반 키워드를 이용한 긍정/부정 분류보다 비지도 학습기반 키워드 추출과 인공신경망의 일종인 합성곱 신경망을 이용했을 때 약 20% 이상 분류 정확도가 향상되었다.","In this paper, we propose a method for sentiment analysis of online news by constructing emotional dictionary base on the fluctuation in prices of various agriculture products. The collected unstructured text data were segmented into sentences and the frequently mentioned words which were not related to price fluctuation were removed as stop words. After the morphological analysis, the keyword was extracted based on the unsupervised learning and the experiments were conducted based on the proposed model using the convolutional neural network (CNN). Consequently, about 20% improvement in accuracy was observed when CNN was used than the word frequency based method."
3차원 점군 데이터를 이용한 수정 구형 특징 표현기 개발 및 도시 구조물 분류를 위한 컨볼루션 신경망의 응용,2018,"['Modified Spherical Signature Descriptor(수정 구형특징 표현기)', 'Convolutional Neural Network(컨볼루션신망망)', '3D Point Cloud(3차원 점군)', 'Geodesic Sphere(지오데식 구)', 'Deep Learning(심층 학습)']",,"This paper presents the novel observation model, called Modified Spherical Signature Descriptor(MSSD), capable of representing 2D image generated from 3D point cloud data. The Modified Spherical Signature Descriptor has a uniform mesh grid to accumulate the occupancy evidence caused by neighbor point cloud data. According to a kind of area such as wall, road, tree, car, and so on, the evidence pattern of 2D image looks so different each other. For the parameter learning of Convolutional Neural Network(CNN) layers, these 2D images were applied as the input layer. The Convolutional Neural Network, one of the deep learning methods and familiar with the image analysis, was utilized for the urban structure classification. The case study on CNN practice was introduced in detail in this paper. The simulation results shows that the classification accuracy of CNN with 2D images of the proposed MSSD was improved more than the traditional methods' one."
Variations of AlexNet and GoogLeNet to Improve Korean Character Recognition Performance,2018,"['Classification', 'CNN', 'Deep Learning', 'Korean Character Recognition']",,"Deep learning using convolutional neural networks (CNNs) is being studied in various fields of image recognition and these studies show excellent performance. In this paper, we compare the performance of CNN architectures, KCR-AlexNet and KCR-GoogLeNet. The experimental data used in this paper is obtained from PHD08, a large-scale Korean character database. It has 2,187 samples of each Korean character with 2,350 Korean character classes for a total of 5,139,450 data samples. In the training results, KCR-AlexNet showed an accuracy of over 98% for the top-1 test and KCR-GoogLeNet showed an accuracy of over 99% for the top-1 test after the final training iteration. We made an additional Korean character dataset with fonts that were not in PHD08 to compare the classification success rate with commercial optical character recognition (OCR) programs and ensure the objectivity of the experiment. While the commercial OCR programs showed 66.95% to 83.16% classification success rates, KCR-AlexNet and KCR-GoogLeNet showed average classification success rates of 90.12% and 89.14%, respectively, which are higher than the commercial OCR programs' rates. Considering the time factor, KCR-AlexNet was faster than KCR-GoogLeNet when they were trained using PHD08; otherwise, KCR-GoogLeNet had a faster classification speed."
Variations of AlexNet and GoogLeNet to Improve Korean Character Recognition Performance,2018,"['Classification', 'CNN', 'Deep Learning', 'Korean Character Recognition']",,"Deep learning using convolutional neural networks (CNNs) is being studied in various fields of image recognition and these studies show excellent performance. In this paper, we compare the performance of CNN architectures, KCR-AlexNet and KCR-GoogLeNet. The experimental data used in this paper is obtained from PHD08, a large-scale Korean character database. It has 2,187 samples of each Korean character with 2,350 Korean character classes for a total of 5,139,450 data samples. In the training results, KCR-AlexNet showed an accuracy of over 98% for the top-1 test and KCR-GoogLeNet showed an accuracy of over 99% for the top-1 test after the final training iteration. We made an additional Korean character dataset with fonts that were not in PHD08 to compare the classification success rate with commercial optical character recognition (OCR) programs and ensure the objectivity of the experiment. While the commercial OCR programs showed 66.95% to 83.16% classification success rates, KCR-AlexNet and KCR-GoogLeNet showed average classification success rates of 90.12% and 89.14%, respectively, which are higher than the commercial OCR programs’ rates. Considering the time factor, KCR-AlexNet was faster than KCR-GoogLeNet when they were trained using PHD08; otherwise, KCR-GoogLeNet had a faster classification speed."
A Deep Learning Approach for Classification of Cloud Image Patches on Small Datasets,2018,"['Cloud classification', 'CNN', 'Data augmentation', 'SWIMCAT dataset']",,"Accurate classification of cloud images is a challenging task. Almost all the existing methods rely on hand-crafted feature extraction. Their limitation is low discriminative power. In the recent years, deep learning with convolution neural networks (CNNs), which can auto extract features, has achieved promising results in many computer vision and image understanding fields. However, deep learning approaches usually need large datasets. This paper proposes a deep learning approach for classification of cloud image patches on small datasets. First, we design a suitable deep learning model for small datasets using a CNN, and then we apply data augmentation and dropout regularization techniques to increase the generalization of the model. The experiments for the proposed approach were performed on SWIMCAT small dataset with k-fold cross-validation. The experimental results demonstrated perfect classification accuracy for most classes on every fold, and confirmed both the high accuracy and the robustness of the proposed model."
Backbone Network for Object Detection with Multiple Dilated Convolutions and Feature Summation,2018,"['객체 검출', '백본 네트워크', '배수 팽창 된 컨볼루션', '특징합계', 'object detection', 'backbone network', 'multiple dilated convolutions', 'feature summation']",,"The advancement of CNN leads to the trend of using very deep convolutional neural network which contains more than 100 layers not only for object detection, but also for image segmentation and object classification. However, deep CNN requires lots of resources, and so is not suitable for people who have limited resources or real time requirements. In this paper, we propose a new backbone network for object detection with multiple dilated convolutions and feature summation. Feature summation enables easier flow of gradients and minimizes loss of spatial information that is caused by convolving. By using multiple dilated convolution, we can widen the receptive field of individual neurons without adding more parameters. Furthermore, by using a shallow neural network as a backbone network, our network can be trained and used in an environment with limited resources and without pre-training it in ImageNet dataset. Experiments demonstrate we achieved 71% and 38.2% of accuracy on Pascal VOC and MS COCO dataset, respectively."
A Study on the Facial Expression Recognition using Deep Learning Technique,2018,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Intelligent Phone.']",,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the symbols that users often use, you can identify facial expressions with a camera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar expressions, reached 66%. It doesn't need to search for symbols. If you use the camera to recognize the expression, it will appear symbols immediately. So, this service is the symbols used when people send messages to others, and it can feel a lot of convenience. In countless symbols, there is no need to find symbols, which is an increasing trend in deep learning. So, we need to use more suitable algorithm for expression recognition, and then improve accuracy."
쇼크 필터와 합성곱 신경망 기반의 균일 모션 디블러링 기법,2018,"['Deblurring', 'Convolutional Neural Network (CNN)', 'Shock filter', 'Uniform Motion blur', 'Blind deconvolution']",Cho 등의 균일 모션 블러 제거 알고리듬은 영상 내 외곽선 영역을 선명하게 복원하지 못한다는 문제점이 있다. 이러한 문제점을 극복하기 위해 본 논문에서는 한 장의 정지 영상에서 발생하는 블러 (Blur)현상을 블러된 계단형 신호를 뚜렷한 외곽선으로 복원해주는 쇼크 필터 (Shock filter)와 영상에서 특징을 추출하여 학습하는 합성곱 신경망 (Convolutional Neural Network: CNN)을 이용하여 선명한 영상을 복원하고 이 영상으로부터 균일 모션 (Uniform motion) 블러를 측정하여 영상 내 블러 현상을 제거하는 효과적인 알고리듬을 제안하고자 한다. 제안된 알고리듬은 쇼크 필터와 합성곱 신경망을 이용하여 선명한 영상을 복원함으로써 기존 알고리듬의 단점을 개선하였다. 실험 결과를 통해 제안하는 알고리듬이 기존 알고리듬에 비해 객관적 및 주관적인 평가에서 우수한 복원 성능을 나타냄을 확인하였다.,
Facial Expression Classification Using Deep Convolutional Neural Network,2018,"['Convolutional neural network', 'Facial expression', 'Data augmentation', 'Database']",,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. The proposed structure has general classification performance for any environment or subject. For this purpose, we collect a variety of databases and organize the database into six expression classes such as 'expressionless', 'happy', 'sad', 'angry', 'surprised' and 'disgusted'. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. In the existing CNN structure, the optimal structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of nodes of fully-connected layer. The experimental results show good classification performance compared to the state-of-the-arts in experiments of the cross validation and the cross database. Also, compared to other conventional models, it is confirmed that the proposed structure is superior in classification performance with less execution time."
Enhanced Network Intrusion Detection using Deep Convolutional Neural Networks,2018,"['Network Intrusion Detection', 'Deep Convolutional Neural Networks', 'Deep learning', 'CNN', 'IDS', 'Information Security']",,"Network Intrusion detection is a rapidly growing field of information security due to its importance for modern IT infrastructure. Many supervised and unsupervised learning techniques have been devised by researchers from discipline of machine learning and data mining to achieve reliable detection of anomalies. In this paper, a deep convolutional neural network (DCNN) based intrusion detection system (IDS) is proposed, implemented and analyzed. Deep CNN core of proposed IDS is fine-tuned using Randomized search over configuration space. Proposed system is trained and tested on NSLKDD training and testing datasets using GPU. Performance comparisons of proposed DCNN model are provided with other classifiers using well-known metrics including Receiver operating characteristics (RoC) curve, Area under RoC curve (AuC), accuracy, precision-recall curve and mean average precision (mAP). The experimental results of proposed DCNN based IDS shows promising results for real world application in anomaly detection systems."
Facial Expression Classification Using Deep Convolutional Neural Network,2018,"['Convolutional neural network', 'Facial expression', 'Data augmentation', 'Database']",,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. The proposed structure has general classification performance for any environment or subject. For this purpose, we collect a variety of databases and organize the database into six expression classes such as ‘expressionless’, ‘happy’, ‘sad’, ‘angry’, ‘surprised’ and ‘disgusted’. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. In the existing CNN structure, the optimal structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of nodes of fully-connected layer. The experimental results show good classification performance compared to the state-of-the-arts in experiments of the cross validation and the cross database. Also, compared to other conventional models, it is confirmed that the proposed structure is superior in classification performance with less execution time."
Convolutional Neural Network with Particle Filter Approach for Visual Tracking,2018,"['Computer Vision', 'Object Tracking', 'Convolutional Neural Network', 'Particle Filter', 'GPU']",,"In this paper, we propose a compact Convolutional Neural Network (CNN)-based tracker in conjunction with a particle filter architecture, in which the CNN model operates as an accurate candidates estimator, while the particle filter predicts the target motion dynamics, lowering the overall number of calculations and refines the resulting target bounding box. Experiments were conducted on the Online Object Tracking Benchmark (OTB) [34] dataset and comparison analysis in respect to other state-of-art has been performed based on accuracy and precision, indicating that the proposed algorithm outperforms all state-of-the-art trackers included in the OTB dataset, specifically, TLD [16], MIL [1], SCM [36] and ASLA [15]. Also, a comprehensive speed performance analysis showed average frames per second (FPS) among the top-10 trackers from the OTB dataset [34]."
A Comparative Study of Transfer Learning–based Methods for Inspection of Mobile Camera Modules,2018,"['Transfer learning', 'Machine vision', 'Camera module', 'Defect inspection']",,"We apply three transfer learning methods using the pretrained AlexNet convolutional neural network (CNN) model to detect defects in camera modules. In experiments, the performance of fine-tuning methods using random initial parameters in less than the two last fully connected layers while using predetermined weights as initial parameters for the remaining layers, showed better performance than other methods. We expect that the transfer learning–based CNN can be effectively applied to camera module inspection systems."
Generative Adversarial Networks를 이용한 Face Morphing 기법 연구,2018,"['대립쌍 기계학습', '얼굴합성', '합성곱 신경망', '비지도 학습', 'Generative adversarial network', 'face morphing', 'DCGAN', 'dCNN', 'unsupervised learning']",,"Recently, with the explosive development of computing power, various methods such as RNN and CNN have been proposed under the name of Deep Learning, which solve many problems of Computer Vision have. The Generative Adversarial Network, released in 2014, showed that the problem of computer vision can be sufficiently solved in unsupervised learning, and the generation domain can also be studied using learned generators. GAN is being developed in various forms in combination with various models. Machine learning has difficulty in collecting data. If it is too large, it is difficult to refine the effective data set by removing the noise. If it is too small, the small difference becomes too big noise, and learning is not easy. In this paper, we apply a deep CNN model for extracting facial region in image frame to GAN model as a preprocessing filter, and propose a method to produce composite images of various facial expressions by stably learning with limited collection data of two persons."
Runway visual range prediction using Convolutional Neural Network with Weather information,2018,"['Runway visual range', 'Convolutional neural network', 'Aviation weather', 'Weather forecast..']",,"The runway visual range is one of the important factors that decide the possibility of taking offs and landings of the airplane at local airports. The runway visual range is affected by weather conditions like fog, wind, etc. The pilots and aviation related workers check a local weather forecast such as runway visual range for safe flight. However there are several local airfields at which no other forecasting functions are provided due to realistic problems like the deterioration, breakdown, expensive purchasing cost of the measurement equipment. To this end, this study proposes a prediction model of runway visual range for a local airport by applying convolutional neural network that has been most commonly used for image/video recognition, image classification, natural language processing and so on to the prediction of runway visual range. For constituting the prediction model, we use the previous time series data of wind speed, humidity, temperature and runway visibility. This paper shows the usefulness of the proposed prediction model of runway visual range by comparing with the measured data.."
VGG-based BAPL Score Classification of 18F-Florbetaben Amyloid Brain PET,2018,"['Alzheimer`s disease', 'β-Amyloid', 'Convolutional neural network', '18F-florbetaben PET', 'Gray matter']",,"Amyloid brain positron emission tomography (PET) images are visually and subjectively analyzed by the physician with a lot of time and effort to determine the β-Amyloid (Aβ) deposition. We designed a convolutional neural network (CNN) model that predicts the Aβ-positive and Aβ-negative status. We performed 18F-florbetaben (FBB) brain PET on controls and patients (n=176) with mild cognitive impairment and Alzheimer""s Disease (AD). We classified brain PET images visually as per the on the brain amyloid plaque load score. We designed the visual geometry group (VGG16) model for the visual assessment of slice-based samples. To evaluate only the gray matter and not the white matter, gray matter masking (GMM) was applied to the slice-based standard samples. All the performance metrics were higher with GMM than without GMM (accuracy 92.39 vs. 89.60, sensitivity 87.93 vs. 85.76, and specificity 98.94 vs. 95.32). For the patientbased standard, all the performance metrics were almost the same (accuracy 89.78 vs. 89.21), lower (sensitivity 93.97 vs. 99.14), and higher (specificity 81.67 vs. 70.00). The area under curve with the VGG16 model that observed the gray matter region only was slightly higher than the model that observed the whole brain for both slice-based and patient-based decision processes. Amyloid brain PET images can be appropriately analyzed using the CNN model for predicting the Aβ-positive and Aβ-negative status."
원격해양감시영상에서 해파리 검출,2018,"['해파리검출', '원격해양감시시스템', '임베디드시스템', '무인선', 'Jellyfish Detection', 'Marine Surveillance System', 'Embedded Ssytem', 'Unmanned Surface Vehicle', 'Yolo']","최근 해파리의 증가로 인해 양식장이나 발전소 등이 큰 피해를 보고 있다. 본 연구의 최종적인 목표는 원격해양감시 시스템을 개발하는 것인데, 본 논문에서는 시스템에 탑재된 임베디드 보드에서 운용이 가능한 해파리 검출방법을 제안한다. 이 시스템에서는 알고리즘을 임베디드 보드에 탑재해야 하므로 정확도보다는 빠르면서 가벼운 모델개발이 목표이다. 따라서, 기존의 CNN 검출알고리즘 중에 실시간으로 적용이 가능한 Yolo 모델의 Layer를 줄이면서 초당 프레임을 늘리는데 초점을 두었다. 수중에서 촬영한 영상의 경우 미세한 부유물과 조명 때문에 물체가 뚜렷하게 나오지 않을 수 있으므로 CLAHE를 이용하여 적응적으로 히스토그램을 평활화하여 전경과 배경의 경계를 뚜렷하게 만들도록 전처리를 한다. 간소화된 Yolo 모델을 사용하여 해파리를 검출하는 실험을 수행한 결과, 검출성능이 나쁘지 않으면서 임베디드 보드에서 동작할 수 있음을 확인할 수 있었다.","Recently, the increase of jellyfish has given great damages to sea farms and power plants. The final goal of this study is to develop a remote ocean surveillance system. In this paper, we propose a method to detect jellyfish that can be operated on an embedded board built in the system. Because the algorithm should be mounted on the embedded board, the system aims to develop a model that is faster and lighter than its accuracy. Therefore, we focused on increasing the frames per second while reducing the layer of Yolo that could be applied in real time among existing CNN detection algorithms. For underwater images, objects may not be clearly shown owing to fine floating and lighting. Therefore, we adaptively preprocess them using CLAHE to make clear boundaries between foreground and background. Experiments to detect jellyisfh using the simplified Yolo model found that it can be opeera ton embedded boards with good detection performance."
Classification of Leukemia Disease in Peripheral Blood Cell Images Using Convolutional Neural Network,2018,"['Acute Leukemia', 'Convolutional Neural Network', 'Data Augmentation', 'Deep Learning', 'Image Classification']",,"Classification is widely used in medical images to categorize patients and non-patients. However, conventional classification requires a complex procedure, including some rigid steps such as pre-processing, segmentation, feature extraction, detection, and classification. In this paper, we propose a novel convolutional neural network (CNN), called LeukemiaNet, to specifically classify two different types of leukemia, including acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML), and non-cancerous patients. To extend the limited dataset, a PCA color augmentation process is utilized before images are input into the LeukemiaNet. This augmentation method enhances the accuracy of our proposed CNN architecture from 96.9% to 97.2% for distinguishing ALL, AML, and normal cell images."
명령 실행 모니터링과 딥 러닝을 이용한 파워셸 기반 악성코드 탐지 방법,2018,"['PowerShell', 'malware', 'execution monitoring', 'deep learning']","파워셸은 닷넷 프레임워크를 기반에 둔, 커맨드 라인 셸이자 스크립트 언어로, 그 자체가 가진 다양한 기능 외에도 윈도우 운영체제 기본 탑재, 코드 은닉 및 지속의 수월함, 다양한 모의 침투 프레임워크 등 공격 도구로서 여러 이점을 가지고 있다. 이에 따라 파워셸을 이용하는 악성코드가 급증하고 있으나 기존의 악성코드 탐지 기법으로 대응하기에는 한계가 존재한다. 이에 본 논문에서는 파워셸에서 실행되는 명령들을 관찰할 수 있는 개선된 모니터링 기법과, Convolutional Neural Network(CNN)을 이용해 명령에서 특징을 추출하고 실행 순서에 따라 Recurrent Neural Network(RNN)에 전달하여 악성 여부를 판단하는 딥 러닝 기반의 분류 모델을 제안한다. 악성코드 공유 사이트에서 수집한 파워셸 기반 악성코드 1,916개와 난독화 탐지 연구에서 공개한 정상 스크립트 38,148개를 이용하여 제안한 모델을 5-fold 교차 검증으로 테스트한 결과, 약 97%의 True Positive Rate(TPR)와 1%의 False Positive Rate(FPR)로 모델이 악성코드를 효과적으로 탐지함을 보인다.","PowerShell is command line shell and scripting language, built on the .NET framework, and it has several advantages as an attack tool, including built-in support for Windows, easy code concealment and persistence, and various pen-test frameworks. Accordingly, malwares using PowerShell are increasing rapidly, however, there is a limit to cope with the conventional malware detection technique. In this paper, we propose an improved monitoring method to observe commands executed in the PowerShell and a deep learning based malware classification model that extract features from commands using Convolutional Neural Network(CNN) and send them to Recurrent Neural Network(RNN) according to the order of execution. As a result of testing the proposed model with 5-fold cross validation using 1,916 PowerShell-based malwares collected at malware sharing site and 38,148 benign scripts disclosed by an obfuscation detection study, it shows that the model effectively detects malwares with about 97% True Positive Rate(TPR) and 1% False Positive Rate(FPR)."
Convolutional Neural Network를 이용한 웹 어플리케이션 공격 탐지 기법,2018,"['convolutional neural network', 'supervised learning', 'SQL injection', 'cross site scripting', 'web application', '컨볼루션 신경망', '지도학습', 'SQL 인젝션', '크로스 사이트 스크립팅', '웹 어플리케이션']","웹 어플리케이션 공격이 급격하게 늘면서 기존의 기법들만으로는 이를 탐지하는 것이 한계가있어, 기계학습 기반의 탐지 기법이 연구되기 시작하였다. 기계학습을 활용한 기존 기법은 공격 탐지를 위해 적절한 특징(feature)을 선정해야 하는 어려움이 있으며, 새로운 공격 패턴이 등장할 경우 이에 적합하도록 특징을 재선정해야 할 경우도 발생한다. 본 논문에서는 HTTP 트래픽을 구성하는 입력이 허용되는 문자에 대한 제한 없이 문자 단위로 16진수 변환한 후 이미지화하고, 이를 입력으로 하는 convolutional neural network을 통해 웹 어플리케이션 공격을 탐지하는 기법을 제안한다. 제안 기법은 별도의 특징 선정 없이 지도학습을 통해 이미지화 된 HTTP 트래픽을 학습하며, 기존의 기계학습 기법보다 최대 84.4% 까지 공격 탐지 오류율 성능을 향상할 수 있음을 보였다.","Because rates of web application attacks are rapidly increasing, web application attack detection schemes using machine learning have recently become of interest. Existing schemes, however, require the selection of a suitable set of features representing the characteristics of expected attacks, and this set of features needs to be adjusted every time a new type of attack is discovered.In this paper, we propose a web application attack detection scheme employing a convolutional neural network (CNN) without the need to select any features in advance. Specifically, the CNN is trained in a supervised manner with images transformed from hexadecimally converted characters in HTTP traffic, without any restriction in the input characters used. Our experimental results show that the proposed scheme improves detection error rate performance by up to 84.4% over existing schemes."
펄스 내 변조 저피탐 레이더 신호 자동 식별,2018,"['LPI Radar(저피탐 레이더)', 'Intrapulse Modulation(펄스 내 변조)', 'Convolutional Neural Network(콘볼루션신경망)', 'Parameter Extraction(식별인자 추출)']",,"In electronic warfare(EW), low probability of intercept(LPI) radar signal is a survival technique. Accordingly, identification techniques of the LPI radar waveform have became significant recently. In this paper, classification and extracting parameters techniques for 7 intrapulse modulated radar signals are introduced. We propose a technique of classifying intrapulse modulated radar signals using Convolutional Neural Network(CNN). The time-frequency image(TFI) obtained from Choi-William Distribution(CWD) is used as the input of CNN without extracting the extra feature of each intrapulse modulated radar signals. In addition a method to extract the intrapulse radar modulation parameters using binary image processing is introduced. We demonstrate the performance of the proposed intrapulse radar waveform identification system. Simulation results show that the classification system achieves a overall correct classification success rate of 90 % or better at SNR = -6 dB and the parameter extraction system has an overall error of less than 10 % at SNR of less than -4 dB."
단어의 의미와 문맥을 고려한 순환신경망 기반의 문서 분류,2018,"['문서 분류', 'Doc2vec 순환신경망']","본 논문에서는 단어의 순서와 문맥을 고려하는 특징을 추출하여 순환신경망(Recurrent Neural Network)으로 문서를 분류하는 방법을 제안한다. 단어의 의미를 고려한 word2vec 방법으로 문서내의 단어를 벡터로 표현하고, 문맥을 고려하기 위해 doc2vec으로 입력하여 문서의 특징을 추출한다. 문서분류 방법으로 이전 노드의 출력을 다음 노드의 입력으로 포함하는 RNN 분류기를 사용한다. RNN 분류기는 신경망 분류기 중에서도 시퀀스 데이터에 적합하기 때문에 문서 분류에 좋은 성능을 보인다. RNN에서도 그라디언트가 소실되는 문제를 해결해주고 계산속도가 빠른 GRU(Gated Recurrent Unit) 모델을 사용한다. 실험 데이터로 한글 문서 집합 1개와 영어 문서 집합 2개를 사용하였고 실험 결과 GRU 기반 문서 분류기가 CNN 기반 문서 분류기 대비 약 3.5%의 성능 향상을 보였다.","In this paper, we propose a method to classify a document using a Recurrent Neural Network by extracting features considering word sense and contexts. Word2vec method is adopted to include the order and meaning of the words expressing the word in the document as a vector. Doc2vec is applied for considering the context to extract the feature of the document. RNN classifier, which includes the output of the previous node as the input of the next node, is used as the document classification method. RNN classifier presents good performance for document classification because it is suitable for sequence data among neural network classifiers. We applied GRU (Gated Recurrent Unit) model which solves the vanishing gradient problem of RNN. It also reduces computation speed. We used one Hangul document set and two English document sets for the experiments and GRU based document classifier improves performance by about 3.5% compared to CNN based document classifier."
DNN 기반 컬러와 열 영상을 이용한 다중 스펙트럼 보행자 검출 기법,2018,"['CNN', 'pedestrian detection', 'multi-spectrum', 'network fusion']",,"As autonomous driving research is rapidly developing, pedestrian detection study is also successfully investigated. However, most of the study utilizes color image datasets and those are relatively easy to detect the pedestrian. In case of color images, the scene should be exposed by enough light in order to capture the pedestrian and it is not easy for the conventional methods to detect the pedestrian if it is the other case. Therefore, in this paper, we propose deep neural network (DNN)-based multi-spectrum pedestrian detection method using color and thermal images. Based on single-shot multibox detector (SSD), we propose fusion network structures which simultaneously employ color and thermal images. In the experiment, we used KAIST dataset. We showed that proposed SSD-H (SSD-Halfway fusion) technique shows 18.18% lower miss rate compared to the KAIST pedestrian detection baseline. In addition, the proposed method shows at least 2.1% lower miss rate compared to the conventional halfway fusion method."
Text Categorization with Improved Deep Learning Methods,2018,"['CNN', 'Disorder', 'LSTM', 'Text categorization']",,"Although deep learning methods of convolutional neural networks (CNNs) and long-/short-term memory (LSTM) are widely used for text categorization, they still have certain shortcomings. CNNs require that the text retain some order, that the pooling lengths be identical, and that collateral analysis is impossible; In case of LSTM, it requires the unidirectional operation and the inputs/outputs are very complex. Against these problems, we thus improved these traditional deep learning methods in the following ways: We created collateral CNNs accepting disorder and variable-length pooling, and we removed the input/output gates when creating bidirectional LSTMs. We have used four benchmark datasets for topic and sentiment classification using the new methods that we propose. The best results were obtained by combining LTSM regional embeddings with data convolution. Our method is better than all previous methods (including deep learning methods) in terms of topic and sentiment classification."
Human‐like sign‐language learning method using deep learning,2018,"['CNN', 'deep learning', 'sign language']",,"This paper proposes a human‐like sign‐language learning method that uses a deep‐learning technique. Inspired by the fact that humans can learn sign language from just a set of pictures in a book, in the proposed method, the input data are pre‐processed into an image. In addition, the network is partially pre‐trained to imitate the preliminarily obtained knowledge of humans. The learning process is implemented with a well‐known network, that is, a convolutional neural network. Twelve sign actions are learned in 10 situations, and can be recognized with an accuracy of 99% in scenarios with low‐cost equipment and limited data. The results show that the system is highly practical, as well as accurate and robust."
Variations of AlexNet and GoogLeNet to Improve Korean Character Recognition Performance,2018,"['Classification', 'CNN', 'Deep Learning', 'Korean Character Recognition']",,"Deep learning using convolutional neural networks (CNNs) is being studied in various fields of imagerecognition and these studies show excellent performance. In this paper, we compare the performance ofCNN architectures, KCR-AlexNet and KCR-GoogLeNet. The experimental data used in this paper is obtainedfrom PHD08, a large-scale Korean character database. It has 2,187 samples of each Korean character with2,350 Korean character classes for a total of 5,139,450 data samples. In the training results, KCR-AlexNetshowed an accuracy of over 98% for the top-1 test and KCR-GoogLeNet showed an accuracy of over 99% forthe top-1 test after the final training iteration. We made an additional Korean character dataset with fonts thatwere not in PHD08 to compare the classification success rate with commercial optical character recognition(OCR) programs and ensure the objectivity of the experiment. While the commercial OCR programs showed66.95% to 83.16% classification success rates, KCR-AlexNet and KCR-GoogLeNet showed averageclassification success rates of 90.12% and 89.14%, respectively, which are higher than the commercial OCRprograms’ rates. Considering the time factor, KCR-AlexNet was faster than KCR-GoogLeNet when they weretrained using PHD08; otherwise, KCR-GoogLeNet had a faster classification speed."
국방분야 비인가 이미지 파일 탐지를 위한 다중 레벨 컨볼루션 신경망 알고리즘의 구현 및 검증,2018,"['Multi-level CNN', 'Convolutional Neural Network', 'Image Processing', 'Intelligent Information System', 'Military Application']",,
도로 영역의 사전지식을 활용한 도로 인식 신경망,2018,"['Semantic Segmentation', 'CNN', 'Object Detection']",,
감시 카메라를 사용한 화재 감지 알고리즘에 관한 연구,2018,"['fire detection', 'deep learning', 'CNN(Convolutional Neural Network)', 'CaffeNet', 'cascade Model']",,
A Study on the Facial Expression Recognition using Deep Learning Technique,2018,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Intelligent Phone']",,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the symbols that users often use, you can identify facial expressions with a camera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar expressions, reached 66%. It doesn't need to search for symbols.If you use the camera to recognize the expression, it will appear symbols immediately. So, this service is the symbols used when people send messages to others, and it can feel a lot of convenience. In countless symbols, there is no need to find symbols, which is an increasing trend in deep learning. So, we need to use more suitable algorithm for expression recognition, and then improve accuracy."
RNN을 이용한 범용 예측 시스템 구현,2018,"['deep learning', 'RNN', 'LSTM', 'CNN', 'artificial intelligence', 'prediction system']",,"Various algorithms and models of deep learning were developed, and RNN shows good performance in future prediction system. RNN and LSTM applied universal prediction system was realized in this paper, and performance was evaluated by cost value. Difference between input data was so big that we normalized this input data, and sequence size of learning input was 5 in the performance experiment. The legibility of the results was increased by displaying learning result, predictive execution result and cost values on a real-time graph. In this experiment, accomplishment of learning was confirmed by cost values decrease from learning number 150 to 0.085. future prediction system precisely learned learnin target value and test target value in a small number of learning time in a short time. Furthermore, cost value decreased to wanted value, confirming that the performance of suggested prediction system is excellent."
A Study on the Facial Expression Recognition using Deep Learning Technique,2018,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Intelligent Phone']",,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the symbols that users often use, you can identify facial expressions with a camera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar expressions, reached 66%. It doesn't need to search for symbols. If you use the camera to recognize the expression, it will appear symbols immediately. So, this service is the symbols used when people send messages to others, and it can feel a lot of convenience. In countless symbols, there is no need to find symbols, which is an increasing trend in deep learning. So, we need to use more suitable algorithm for expression recognition, and then improve accuracy."
Research on Image Semantic Segmentation Based on FCN-VGG and Pyramid Pooling Module,2018,"['image semantic segmentation', 'FCN', 'VGG', 'CNN', 'deconvolution', 'pyramid pooling module']",,"This paper proposed an algorithm to extract new feature maps using pyramid pooling module based on FCN-VGG(Fully Convolutional Network-Visual Geometry Group) for image semantic segmentation. First, the VGG was changed to FCN-VGG in order to consider the variability of the input images. The FCN-8 feature is extracted using the changed FCN-VGG. Then the extracted 4-parts features using pyramid pooling module and the previously extracted FCN-8 features are fused to obtain the advanced features. Classification is performed using obtained advanced features. By the comparison experiment between the feature maps of the proposed algorithm and the existing feature maps, it is proved that the method improves the accuracy of image semantic segmentation by about 2%."
물체 변형 성능을 향상하기 위한 U-net 및 Residual 기반의Cycle-GAN,2018,"['Deep learning', 'AI', 'Image-to-image translation', 'CNN', 'GAN']",,"The image-to-image translation is one of the deep learning applications using image data. In this paper, we aim at improving the performance of object transfiguration which transforms a specific object in an image into another specific object. For object transfiguration, it is required to transform only the target object and maintain background images. In the existing results, however, it is observed that other parts in the image are also transformed. In this paper, we have focused on the structure of artificial neural networks that are frequently used in the existing methods and have improved the performance by adding constraints to the exiting structure. We also propose the advanced structure that combines the existing structures to maintain their advantages and complement their drawbacks. The effectiveness of the proposed methods are shown in experimental results."
Comparisons of Deep Learning Algorithms for MNIST in Real-Time Environment,2018,"['Capsule networks', 'Dynamic routing', 'Residual learning', 'CNN', 'Logistic regression']",,"Recognizing handwritten digits was challenging task in a couple of years ago. Thanks to machine learning algorithms, today, the issue has solved but those algorithms require much time to train and to recognize digits. Thus, using one of those algorithms to an application that works in real-time, is complex. Notwithstanding use of a trained model, if the model uses deep neural networks it requires much more time to make a prediction and becomes more complicated as well as memory usage also increases. It leads real-time application to delay and to work slowly even using trained model. A memory usage is also essential as using smaller memory of trained models works considerable faster comparing to models with huge pre-processed memory. For this work, we implemented four models on the basis of unlike algorithms which are capsule network, deep residual learning model, convolutional neural network and multinomial logistic regression to recognize handwritten digits. These models have unlike structure and they have showed a great results on MNIST before so we aim to compare them in real-time environment. The dataset MNIST seems most suitable for this work since it is popular in the field and basically used in many state-of-the-art algorithms beyond those models mentioned above. We purpose revealing most suitable algorithm to recognize handwritten digits in real-time environment. Also, we give comparisons of train and evaluation time, memory usage and other essential indexes of all four models."
Obstructive sleep apnoea detection using convolutional neural network based deep learning framework,2018,"['Artificial neural network (ANN)', 'Convolutional neural network (CNN)', 'Electrocardiography', 'Obstructive sleep apnoea (OSA)', 'Polysomnography (PSG)']",,"This letter presents an automated obstructive sleep apnoea (OSA) detection method with high accuracy, based on a deeplearning framework employing convolutional neural network. The proposed work develops a system that takes single leadelectrocardiography signals from patients for analysis and detects the OSA condition of the patient. The results show thatthe proposed method has some advantages in solving such problems and it outperforms the existing methods significantly.The present scheme eliminates the requirement of separate feature extraction and classification algorithms for the detectionof OSA. The proposed network performs both feature learning and classifies the features in a supervised manner. Thescheme is computation-intensive, but can achieve very high degree of accuracy—on an average a margin of more than 9%compared to other published literature till date. The method also has a good immunity to the contamination of the signalsby noise. Even with pessimistic signal to noise ratio values considered here, the methods already reported are not able tooutshine the present method. The software for the algorithm reported here can be a good contender to constitute a modulethat can be integrated with a portable medical diagnostic system."
영상수준과 픽셀수준 분류를 결합한 영상 의미분할,2018,"['Semantic Segmentation', 'Convolutional Neural Network']",,"In this paper, we propose a CNN based deep learning algorithm for semantic segmentation of images. In order to improve the accuracy of semantic segmentation, we combined pixel level object classification and image level object classification. The image level object classification is used to accurately detect the characteristics of an image, and the pixel level object classification is used to indicate which object area is included in each pixel. The proposed network structure consists of three parts in total. A part for extracting the features of the image, a part for outputting the final result in the resolution size of the original image, and a part for performing the image level object classification. Loss functions exist for image level and pixel level classification, respectively. Image-level object classification uses KL-Divergence and pixel level object classification uses cross-entropy. In addition, it combines the layer of the resolution of the network extracting the features and the network of the resolution to secure the position information of the lost feature and the information of the boundary of the object due to the pooling operation."
A Multi-Scale Parallel Convolutional Neural Network Based Intelligent Human Identification Using Face Information,2018,"['Face Recognition', 'Intelligent Human Identification', 'MP-CNN', 'Robust Feature']",,"Intelligent human identification using face information has been the research hotspot ranging from Internetof Things (IoT) application, intelligent self-service bank, intelligent surveillance to public safety and intelligentaccess control. Since 2D face images are usually captured from a long distance in an unconstrained environment,to fully exploit this advantage and make human recognition appropriate for wider intelligent applicationswith higher security and convenience, the key difficulties here include gray scale change caused byillumination variance, occlusion caused by glasses, hair or scarf, self-occlusion and deformation caused bypose or expression variation. To conquer these, many solutions have been proposed. However, most of themonly improve recognition performance under one influence factor, which still cannot meet the real facerecognition scenario. In this paper we propose a multi-scale parallel convolutional neural network architectureto extract deep robust facial features with high discriminative ability. Abundant experiments are conductedon CMU-PIE, extended FERET and AR database. And the experiment results show that the proposedalgorithm exhibits excellent discriminative ability compared with other existing algorithms."
Comparisons of Deep Learning Algorithms for MNIST in Real-Time Environment,2018,"['Capsule networks', 'Dynamic routing', 'Residual learning', 'CNN', 'Logistic regression']",,"Recognizing handwritten digits was challenging task in a couple of years ago. Thanks to machine learning algorithms, today, the issue has solved but those algorithms require much time to train and to recognize digits. Thus, using one of those algorithms to an application that works in real-time, is complex. Notwithstanding use of a trained model, if the model uses deep neural networks it requires much more time to make a prediction and becomes more complicated as well as memory usage also increases. It leads real-time application to delay and to work slowly even using trained model. A memory usage is also essential as using smaller memory of trained models works considerable faster comparing to models with huge pre-processed memory. For this work, we implemented four models on the basis of unlike algorithms which are capsule network, deep residual learning model, convolutional neural network and multinomial logistic regression to recognize handwritten digits. These models have unlike structure and they have showed a great results on MNIST before so we aim to compare them in real-time environment. The dataset MNIST seems most suitable for this work since it is popular in the field and basically used in many state-of-the-art algorithms beyond those models mentioned above. We purpose revealing most suitable algorithm to recognize handwritten digits in real-time environment. Also, we give comparisons of train and evaluation time, memory usage and other essential indexes of all four models."
A Multi-Scale Parallel Convolutional Neural Network Based Intelligent Human Identification Using Face Information,2018,"['Face Recognition', 'Intelligent Human Identification', 'MP-CNN', 'Robust Feature']",,"Intelligent human identification using face information has been the research hotspot ranging from Internet of Things (IoT) application, intelligent self-service bank, intelligent surveillance to public safety and intelligent access control. Since 2D face images are usually captured from a long distance in an unconstrained environment, to fully exploit this advantage and make human recognition appropriate for wider intelligent applications with higher security and convenience, the key difficulties here include gray scale change caused by illumination variance, occlusion caused by glasses, hair or scarf, self-occlusion and deformation caused by pose or expression variation. To conquer these, many solutions have been proposed. However, most of them only improve recognition performance under one influence factor, which still cannot meet the real face recognition scenario. In this paper we propose a multi-scale parallel convolutional neural network architecture to extract deep robust facial features with high discriminative ability. Abundant experiments are conducted on CMU-PIE, extended FERET and AR database. And the experiment results show that the proposed algorithm exhibits excellent discriminative ability compared with other existing algorithms."
Sparse Feature Convolutional Neural Network with Cluster Max Extraction for Fast Object Classification,2018,"['Deep learning', 'Online-training control', 'Object recognition', 'Classification']",,"We propose the Sparse Feature Convolutional Neural Network (SFCNN) to reduce the volume of convolutional neural networks (CNNs). Despite the superior classification performance of CNNs, their enormous network volume requires high computational cost and long processing time, making real-time applications such as online-training difficult. We propose an advanced network that reduces the volume of conventional CNNs by producing a region-based sparse feature map. To produce the sparse feature map, two complementary region-based value extraction methods, cluster max extraction and local value extraction, are proposed. Cluster max is selected as the main function based on experimental results. To evaluate SFCNN, we conduct an experiment with two conventional CNNs. The network trains 59 times faster and tests 81 times faster than the VGG network, with a 1.2% loss of accuracy in multi-class classification using the Caltech101 dataset. In vehicle classification using the GTI Vehicle Image Database, the network trains 88 times faster and tests 94 times faster than the conventional CNNs, with a 0.1% loss of accuracy."
Gastrointestinal polyp detection in endoscopic images using an improved feature extraction method,2018,"['Endoscopic image', 'Video endoscopy', 'Convolutional neural network (CNN)', 'Color wavelet features', 'Support vector machine (SVM)', 'Improved method']",,"Gastrointestinal polyps are treated as the precursorsof cancer development. So, possibility of cancerscan be reduced at a great extent by early detection andremoval of polyps. The most used diagnostic modality forgastrointestinal polyps is video endoscopy. But, as anoperator dependant procedure, several human factors canlead to miss detection of polyps. In this peper, an improvedcomputer aided polyp detection method has been proposed.Proposed improved method can reduce polyp miss detectionrate and assists doctors in finding the most importantregions to pay attention. Color wavelet features and convolutionalneural network features are extracted fromendoscopic images, which are used for training a supportvector machine. Then a target endoscopic image will begiven to the classifier as input in order to find whether itcontains any polyp or not. If polyp is found, it will bemarked automatically. Experiment shows that, colorwavelet features and convolutional neural network featurestogether construct a highly representative of endoscopicpolyp images. Evaluations on standard public databasesshow that, proposed system outperforms state-of-the-artmethods, gaining accuracy of 98.34%, sensitivity of98.67% and specificity of 98.23%. In this paper, thestrength of color wavelet features and power of convolutionalneural network features are combined. Fusion ofthese two methodology and use of support vector machineresults in an improved method for gastrointestinal polypdetection. An analysis of ROC reveals that, proposedmethod can be used for polyp detection purposes withgreater accuracy than state-of-the-art methods."
완전 합성곱 신경망을 활용한 자동 포트홀 탐지 기술의 개발 및 평가,2018,"['포트홀', '도로노면 파손', '의미론적 분할', '심층신경망', '인공지능', '완전 합성곱 신경망', 'Pothole', 'Road surface damage', 'Semantic segmentation', 'Deep neural network', 'AI', 'Fully convolutional neural network']",,
Deep Convolutional Neural Network를 이용한 주차장 차량 계수 시스템,2018,"['주차장 관리', '물체 감지', '컴퓨터 비전', '기계 학습', '감시 카메라', 'deep convolutional neural network', 'Parking lot management', 'Object detection', 'Computer vision', 'Machine learning', 'Deep convolutional neural network', 'Surveillance camera.']",,
인지 무선 네트워크에서 딥러닝을 이용한 특징 기반의 자동 변조기법 분류 방법,2018,"['Automatic modulation classification', 'convolutional neural network', 'spectral correlation function', 'feature extraction']",,
OpenCL을 이용한 랜더링 노이즈 제거를 위한 뉴럴네트워크 가속기 구현,2018,"['레이 트레이싱', 'LBF', '컨볼루션 뉴럴 네트워크', 'OpenCL', 'GEMM', 'Ray tracing', 'LBF', 'CNN', 'OpenCL', 'GEMM']",본 논문에서는 OpenCL을 이용한 랜더링 노이즈 제거를 위한 가속기 구현을 제안한다. 렌더링 알고리즘 중에 고품질 그래픽스를 보장하는 레이트레이싱을 선택하였다. 레이 트레이싱은 레이를 사용하여 렌더링하는데 레이를 적게 사용하면 노이즈가 발생한다. 레이를 많이 사용하게 되면 고화질의 이미지를 생성할 수 있으나 연산 시간이 상대적으로 길어지게 된다. 레이를 적게 사용하면서 연산시간을 줄이기 위해 뉴럴 네트워크를 이용한 LBF(Learning Based Filtering) 알고리즘을 적용하였다. 뉴럴 네트워크를 사용한다고 해서 항상 최적의 결과가 나오지는 않는다. 본 논문에서는 성능향상을 위해 일반적인 행렬 곱셈을 기반으로 하는 새로운 기법의 행렬 곱셈 접근법을 제시하였다. 개발환경으로는 고속병렬 처리가 특화된 OpneCL을 사용하였다. 제안하는 구조는 Kintex UltraScale XKU690T- 2FDFG1157C FPGA 보드에서 검증하였다. 하나의 픽셀에 사용되는 파라미터를 계산 시간은 Verilog-HDL 구조보다 약 1.12배 빠른 것으로 확인했다.,"In this paper, we propose an implementation of a neural network accelerator for reducing the rendering noise using OpenCL. Among the rendering algorithms, we selects a ray tracing to assure a high quality graphics. Ray tracing rendering uses ray to render, less use of the ray will result in noise. Ray used more will produce a higher quality image but will take operation time longer. To reduce operation time whiles using fewer rays, Learning Base Filtering algorithm using neural network was applied. it's not always produce optimize result. In this paper, a new approach to Matrix Multiplication that is based on General Matrix Multiplication for improved performance. The development environment, we used specialized in high speed parallel processing of OpenCL. The proposed architecture was verified using Kintex UltraScale XKU6909T-2FDFG1157C FPGA board. The time it takes to calculate the parameters is about 1.12 times fast than that of Verilog-HDL structure."
딥러닝을 통한 움직이는 객체 검출 알고리즘 구현,2018,"['Object Detection and Tracking', 'Object Recognition', 'Moving Object', 'Deep Learning', 'CNN(Convolution Neural Network)']",,"Object detection and tracking is an exciting and interesting research area in the field of computer vision, and its technologies have been widely used in various application systems such as surveillance, military, and augmented reality. This paper proposes and implements a novel and more robust object recognition and tracking system to localize and track multiple objects from input images, which estimates target state using the likelihoods obtained from multiple CNNs. As the experimental result, the proposed algorithm is effective to handle multi-modal target appearances and other exceptions."
Real-Time Action Detection in Video Surveillance using a Sub-Action Descriptor with Multi-Convolutional Neural Networks,2018,"['sub-action descriptor', 'action detection', 'video surveillance', 'convolutional neural network', 'multi CNN']",,"When we say a person is texting, can you tell the person is walking or sitting? Emphatically, no. In order to solve this incomplete representation problem, this paper presents a sub-action descriptor for detailed action detection. The sub-action descriptor consists of three levels: posture, locomotion, and gestures. The three levels provide three sub-action categories for a single action in order to address the representation problem. The proposed action detection model simultaneously localizes and recognizes the actions of multiple individuals in video surveillance using appearance-based temporal features with multi-convolutional neural networks. The proposed approach achieved a mean average precision of 76.6% for frame-based measurement and 83.5% for video-based measurement of the ICVL video surveillance dataset. Extensive experiments on the benchmark KTH dataset demonstrate that the proposed approach achieved better performance, which in turn improves action recognition performance in comparison to the stateof-the-art methods. The action detection model can run at around 25 fps with the ICVL dataset and at more than 80 fps with the KTH dataset, which is suitable for real-time surveillance applications."
STFT 소리맵을 이용한 컨볼루션 신경망 기반 화자식별 방법,2018,"['딥러닝', '컨볼루션신경망', 'STFT알고리즘', '화자식별', '잡음 강건성', 'Deep Learning', 'Convolutional Neural Network (CNN)', 'Short-time Fourier Transform (STFT) Algorithm', 'Speaker Identification', 'Noise Robustness']","화자식별은 개인 성도의 음성학적 특징을 모델링하고 분류하는 기술로 음성 인식 분야의 가장 어려운 분야에 속한다. 화자식별 기술은 보안인증, 접근제어, 개인화, 지능형 로봇제어 등의 분야에서 광범위하게 응용이 가능하지만, 실제 환경 요소로 인한 잡음 때문에 발생하는 학습과 테스트 데이터 간의 불일치를 해결하는 것이 필요하다. 본 논문에서는 잡음 강건성을 위해 컨볼루션-풀링 연산을 반복적으로 적용하는 화자식별 시스템을 제안하였다. 정적 신호가 아닌 시계열 특성을 지니는 스피치 데이터의 특징을 보다 잘 모델링 하기 위해서 STFT알고리즘을 사용하여 소리맵을 생성하여 분류하였다. 제안하는 화자식별 시스템은 다른 기계학습 알고리즘의 인식 성능을 크게 상회하였고, 단계별로 잡음을 삽입하는 실험의 결과로 잡음 강건성을 검증하였다.","Speaker identification which models and classifies the phonological characteristics of individuals, is one of the most difficult areas of speech recognition. While speaker identification can be widely applied in fields such as security authentication, access control, personalization and intelligent robot control, a solution needs to be found for the inconsistency between training and test data caused by noise due to real environment factors. In this paper, we propose a speaker identification system based on convolution-pooling operation for noise robustness. To model the characteristics of individuals"" speech using the time series characteristics, a sound map was generated using the Short-time Fourier Transform (STFT) algorithm. The proposed speaker identification system outperforms recognition performance of other machine learning algorithms, and the robustness of noise is verified as a result of the noise insertion at incremental steps."
이진 가중치 신경망의 하드웨어 구현을 위한 고정소수점 연산 정확도 분석,2018,"['Binary Weight Network', 'Low precision network', 'Fixed point approximation', 'FPGA', 'CNN']",,"In this paper, we analyze the change of accuracy when fixed point arithmetic is used instead of floating point arithmetic in binary weight network(BWN). We observed the change of accuracy by varying total bit size and fraction bit size. If the integer part is not changed after fixed point approximation, there is no significant decrease in accuracy compared to the floating-point operation. When overflow occurs in the integer part, the approximation to the maximum or minimum of the fixed point representation minimizes the decrease in accuracy. The results of this paper can be applied to the minimization of memory and hardware resource requirement in the implementation of FPGA-based BWN accelerator."
IoT 기반 스마트 냉장고 시스템,2018,"['Internet of Things', 'Deep learning', 'Refrigerator', 'Smart system', 'Smart home', 'Artificial Intelligence', 'Convolution Neural Network (CNN)']","최근 인구가 급격히 증가하면서 음식물의 부족 및 낭비의 심각성이 대두되고 있다. 이를 해결하기 위해 다양한 국가 및 기업에서는 소비자의 식재료 구매 패턴 연구 및 IoT 기술이 적용된 스마트 냉장고 제품개발 등의 시도를 진행 중에 있다. 그러나, 현재 판매되고 있는 스마트 냉장고들은 기존에 비해 상당한 가격대를 형성하고 있으며, 복잡한 구성으로 인한 오작동 및 파손으로 또 다른 낭비를 초래한다. 본 논문에서는 음식물 부족 및 낭비 해결과 가정 내 원활한 식재료 관리를 위한 저비용의 IoT 기반 스마트 냉장고 시스템을 제안한다. 본 시스템은 QR코드, 이미지 인식, 음성 인식을 통해 식재료를 인식하여 등록하고 이를 바탕으로 다양한 서비스를 제공할 수 있다. 이미지 인식의 정확도를 높이기 위해 우리는 딥 러닝 알고리즘을 사용한 모델을 활용하였으며 정확한 식재료 등록이 가능함을 검증하였다.","Recently, as the population rapidly increases, food shortages and waste are emerging serious problem. In order to solve this problem, various countries and enterprises are trying research and product development such as a study of consumers' purchasing patterns of food and a development of smart refrigerator using IoT technology. However, the smart refrigerators which currently sold have high price issue and another waste due to malfunction and breakage by complicated configurations. In this paper, we proposed a low-cost smart refrigerator system based on IoT for solving the problem and efficient management of ingredients. The system recognizes and registers ingredients through QR code, image recognition, and speech recognition, and can provide various services of the smart refrigerator. In order to improve an accuracy of image recognition, we used a model using a deep learning algorithm and proved that it is possible to register ingredients accurately."
"흉부 CT 영상에서 결절의 밝기값, 재질 및 형상 증강 영상 기반의 GGN-Net을 이용한 간유리음영 결절 자동 분류",2018,"['흉부 CT 영상', '간유리음영 결절', '결절 분류', '컨볼루션신경망', 'Chest CT image', 'Ground-glass Nodule', 'Nodule Classification', 'CNN']","본 논문에서는 흉부 CT 영상에서 결절의 밝기값, 재질 및 형상 증강 영상 기반의 GGN-Net을 이용해 간유리음영 결절 자동 분류 방법을 제안한다, 첫째, 입력 영상에 결절 내부의 고형 성분의 유무 및 크기 정보가 포함될 수 있도록 밝기값, 재질 및 형상 증강 영상의 활용을 제안한다. 둘째, 다양한 입력 영상을 여러 개의 컨볼루션 모듈을 통해 획득한 특징맵을 내부 네트워크에서 통합하여 훈련하는 GGN-Net를 제안한다. 제안 방법의 분류 정확성 평가를 위해 순수 간유리음영 결절 90개와 고형 성분의 크기가 5mm 미만인 혼합 간유리음영 결절 38개, 5mm 이상 고형 성분의 크기를 가지는 혼합 간유리음영 결절 23개의 데이터를 사용하였으며, 입력 영상이 간유리음영 결절 분류 결과에 미치는 영향을 비교하기 위해 다양한 입력 영상을 구성하여 결과를 비교하였다. 실험 결과, 밝기값, 재질 및 형상 정보가 함께 고려된 입력 영상을 사용한 제안 방법이 정확도가 82.75%로 가장 좋은 결과를 보였다.","In this paper, we propose an automated method for the ground-glass nodule(GGN) classification using GGN-Net based on intensity, texture, and shape-enhanced images in chest CT images. First, we propose the utilization of image that enhances the intensity, texture, and shape information so that the input image includes the presence and size information of the solid component in GGN. Second, we propose GGN-Net which integrates and trains feature maps obtained from various input images through multiple convolution modules on the internal network. To evaluate the classification accuracy of the proposed method, we used 90 pure GGNs, 38 part-solid GGNs less than 5mm with solid component, and 23 part-solid GGNs larger than 5mm with solid component. To evaluate the effect of input image, various input image set is composed and classification results were compared. The results showed that the proposed method using the composition of intensity, texture and shape-enhanced images showed the best result with 82.75% accuracy."
슈퍼픽셀 이미지 분할을 이용한 ResNet 기반 백혈구 감별 알고리즘 개발,2018,"['Super-pixel', 'Residual Network', 'Segmentation', 'Classification', 'White Blood Cell']",,"In this paper, we propose an efficient WBC 14-Diff classification which performs using the WBC-ResNet-152, a type of CNN model. The main point of view is to use Super-pixel for the segmentation of the image of WBC, and to use ResNet for the classification of WBC.  A total of 136,164 blood image samples (224x224) were grouped for image segmentation, training, training verification, and final test performance analysis.  Image segmentation using super-pixels have different number of images for each classes, so weighted average was applied and therefore image segmentation error was low at 7.23%.  Using the training data-set for training 50 times, and using soft-max classifier, TPR average of 80.3% for the training set of 8,827 images was achieved. Based on this, using verification data-set of 21,437 images, 14-Diff classification TPR average of normal WBCs were at 93.4% and TPR average of abnormal WBCs were at 83.3%. The result and methodology of this research demonstrates the usefulness of artificial intelligence technology in the blood cell image classification field.  WBC-ResNet-152 based morphology approach is shown to be meaningful and worthwhile method. And based on stored medical data, in-depth diagnosis and early detection of curable diseases is expected to improve the quality of treatment."
딥러닝을 이용한 양파 밭의 잡초 검출 연구,2018,"['잡초 분류', '잡초 검출', '컨볼루션 뉴럴네트워크', '딥러닝', 'weed classification', 'weed detection', 'convolutional neural network(CNN)', 'deep learning']","이 논문은 양파 밭에서 딥러닝 기반 자동 잡초 검출기의 설계 및 구현을 제시합니다. 이 시스템은 컨볼루션 뉴럴 네트워크를 기반으로 제안 된 영역을 선택합니다. 검출기는 양파 밭에서 직접 찍은 데이터 셋을 가지고 훈련됩니다. 학습이 완료 된 후에, 잡초가 될 확률이 매우 높은 후보 지역을 잡초로 간주합니다. Non-maximum suppression을 통해 오버랩된 박스가 최대한 적게 남게 됩니다. 다른 양파 농장을 통해 수집된 데이터를 통해 제안 된 분류기를 평가합니다. 분류 정확도는 고려 된 데이터 셋에서 약 99%를 보여주며, 제안된 방법이 양파 밭에서 잡초 검출과 관련하여 우수한 성능을 나타냄을 알 수 있습니다.","This paper presents the design and implementation of a deep learning-based automated weed detector on onion fields. The system is based on a Convolutional Neural Network that specifically selects proposed regions. The detector initiates training with a dataset taken from agricultural onion fields, after which candidate regions with very high probability of suspicion are considered weeds. Non-maximum suppression helps preserving the less overlapped bounding boxes. The dataset collected from different onion farms is evaluated with the proposed classifier. Classification accuracy is about 99% for the dataset, indicating the proposed method’s superior performance with regard to weed detection on the onion fields."
"고객만족, NPS, Bayesian Inference 및 Hidden Markov Model로 구현하는 명품구매에 관한확률적 추적 메카니즘",2018,"['고객만족', '고객추천', '추천의향', 'NPS', '추천행동', '시장 지분', 'Hidden Markov Model', 'Bayesian Inference', 'Maximum Likelihood Estimation', '인공지능망(DNN', 'CNN', 'GAN)', 'Customer Satisfaction', 'Customer Referral', 'Net Promoter Score', 'Bayesian Inference', 'Hidden Markov Model', 'Viterbi Algorithm']",,"The purpose of this study is to specify a probabilistic tracking mechanism for customer luxury purchase implemented by hidden Markov model, Bayesian inference, customer satisfaction and net promoter score. In this paper, we have designed a probabilistic model based on customer's actual data containing purchase or non-purchase states by tracking the SPC chain : customer satisfaction -> customer referral -> purchase/non-purchase. By applying hidden Markov model and Viterbi algorithm to marketing theory, we have developed the statistical model related to probability theories and have found the best purchase pattern scenario from customer's purchase records."
Recognition of Virtual Written Characters Based on Convolutional Neural Network,2018,"['Virtual Writing', 'Hand Written Character', 'Character Recognition', 'Convolutional Neural Network', 'Motion Recognition']",,"This paper proposes a technique for recognizing online handwritten cursive data obtained by tracing a motion trajectory while a user is in the 3D space based on a convolution neural network (CNN) algorithm. There is a difficulty in recognizing the virtual character input by the user in the 3D space because it includes both the character stroke and the movement stroke. In this paper, we divide syllable into consonant and vowel units by using labeling technique in addition to the result of localizing letter stroke and movement stroke in the previous study. The coordinate information of the separated consonants and vowels are converted into image data, and Korean handwriting recognition was performed using a convolutional neural network. After learning the neural network using 1,680 syllables written by five hand writers, the accuracy is calculated by using the new hand writers who did not participate in the writing of training data. The accuracy of phoneme-based recognition is 98.9% based on convolutional neural network. The proposed method has the advantage of drastically reducing learning data compared to syllable-based learning."
심층학습을 이용한 문서요약의 연구방법 분석,2018,"['Deep Neural Network', 'Text summarization', 'Deep Learning', 'Abstractive text summarization', 'Extractive text summarization']",,"In this study, we discuss the basic technology of Text Summarization based on the deep neural network for natural language processing(NLP). The text summarization task is divided into an extractive summary and an abstractive summary. The extractive summary is a method of extracting a summary of the words used in the input document in the output text, and the abstractive summary is a problem of understanding the input statement and generating a sentence of the same content. The abstractive sentence generation system is based on the encoder-decoder model with attention mechanism, and a selector that can select input sentence is added. The Copy network and Pointer network are the special mechanisms for selector. Such selector systems can make text summarization to be the hybrid form of abstractive and extractive summary. In the future, we expect that accuracy of text summarization will be improved by adding reinforcement learning method."
Generative Adversarial Network를 이용한 손실된 깊이 영상 복원,2018,"['Deep learning', 'generative adversarial network', 'depth image', 'depth camera', 'restoration']",,This paper proposes a method of restoring corrupted depth image captured by depth camera through unsupervised learning using generative adversarial network (GAN). The proposed method generates restored face depth images using 3D morphable model convolutional neural network (3DMM CNN) with large-scale CelebFaces Attribute (CelebA) and FaceWarehouse dataset for training deep convolutional generative adversarial network (DCGAN). The generator and discriminator equip with Wasserstein distance for loss function by utilizing minimax game. Then the DCGAN restore the loss of captured facial depth images by performing another learning procedure using trained generator and new loss function.
Ensemble of Degraded Artificial Intelligence Modules Against Adversarial Attacks on Neural Networks,2018,"['Adversarial attack', 'Artificial Intelligence', 'Image classification']",,"Adversarial attacks on artificial intelligence (AI) systems use adversarial examples to achieve the attack objective. Adversarial examples consist of slightly changed test data, causing AI systems to make false decisions on these examples. When used as a tool for attacking AI systems, this can lead to disastrous results. In this paper, we propose an ensemble of degraded convolutional neural network (CNN) modules, which is more robust to adversarial attacks than conventional CNNs. Each module is trained on degraded images. During testing, images are degraded using various degradation methods, and a final decision is made utilizing a one-hot encoding vector that is obtained by summing up all the output vectors of the modules. Experimental results show that the proposed ensemble network is more resilient to adversarial attacks than conventional networks, while the accuracies for normal images are similar."
인터뷰 대화에서 나타나는 관계범주 조정에 기반을 둔 칭찬전략 연구,2018,"['compliment', 'relationship category', 'categorization devices', 'membership category', 'interview talk']",,"This study attempts to show how entertainment-oriented talk-show interactions between the host and the guest are organized as a type of semi-institutional talk, which exhibits the characteristics of both ordinary conversation and institutional talk in terms of many aspects of its discursive configuration. The purpose of this study is to address the participants’ complementary work based on their mutual knowledge about membership category. The conversational data examined here are excerpted from ‘Talk Asia’ of CNN, in which the host interviews a single guest with celebrity or expert status, addressing various topics concerning the guest’s personal life, career, or relationship with others. Within a conversational analytic framework, this study analyzes that, when the host questions about the guest’s relationship member who has not participated in this show, creating complimentary context, the guest usually uses category transformation or category comparison strategies and maximizes compliment for the relationship category in their own way. In other words, this study indicates that the participants in interview talk perform the categorization work such as transformation or comparison as a resource for organizing complimentary discursive action."
Multi-scale Pedestrian Detection in Thermal Imaging Using Deep Convolutional Neural Network and Adaptive NMS,2018,"['human/pedestrian detection', 'thermal imaging', 'sliding window', 'DNN', 'adaptive NMS']",,"In this paper, we propose a new method for pedestrian detection in thermal image/video by improving the non-maxima suppression(NMS) algorithm. We apply the sliding window detector based deep convolutional neural networks(DNN) to extract pedestrian candidates. A sliding window combined with image pyramids is used to identify pedestrians at varying scales and locations in the image via Convolutional Neural Network(CNN) based binary classification. To improve the performance, we propose an adaptive NMS algorithm to remove false alarms. The proposed NMS uses adaptive overlap-thresholds to overcome the drawback of the standard NMS and improve performance of detection system. It is automatically adjusting the overlap-thresholds based on the density of overlapping windows to improve the accuracy of system. Pedestrian detection experiment results with our thermal database and OSU thermal pedestrian database confirm that the proposed method outperforms the baseline method."
Deep-learning-based automatic computer-aided diagnosis system for diabetic retinopathy,2018,"['Computer-aided diagnosis', 'Diabetic retinopathy', 'Deep neural network', 'AlexNet DNN', 'Convolutional neural network', 'Gaussian mixture model', 'Linear discriminant analysis', 'SVM']",,"The high-pace rise in advanced computing andimaging systems has given rise to a new research dimensioncalled computer-aided diagnosis (CAD) system forvarious biomedical purposes. CAD-based diabeticretinopathy (DR) can be of paramount significance toenable early disease detection and diagnosis decision.Considering the robustness of deep neural networks(DNNs) to solve highly intricate classification problems, inthis paper, AlexNet DNN, which functions on the basis ofconvolutional neural network (CNN), has been applied toenable an optimal DR CAD solution. The DR modelapplies a multilevel optimization measure that incorporatespre-processing, adaptive-learning-based Gaussian mixturemodel (GMM)-based concept region segmentation, connectedcomponent-analysis-based region of interest (ROI)localization, AlexNet DNN-based highly dimensional featureextraction, principle component analysis (PCA)- andlinear discriminant analysis (LDA)-based feature selection,and support-vector-machine-based classification to ensureoptimal five-class DR classification. The simulation resultswith standard KAGGLE fundus datasets reveal that theproposed AlexNet DNN-based DR exhibits a better performancewith LDA feature selection, where it exhibits aDR classification accuracy of 97.93% with FC7 features,whereas with PCA, it shows 95.26% accuracy. Comparativeanalysis with spatial invariant feature transform (SIFT)technique (accuracy—94.40%) based DR feature extractionalso confirms that AlexNet DNN-based DR outperformsSIFT-based DR."
Planetary Long-Range Deep 2D Global Localization Using Generative Adversarial Network,2018,"['Global Localization System', 'Conditional Generative Adversarial Network']",,"Planetary global localization is necessary for long-range rover missions in which communication with command center operator is throttled due to the long distance. There has been number of researches that address this problem by exploiting and matching rover surroundings with global digital elevation maps (DEM). Using conventional methods for matching, however, is challenging due to artifacts in both DEM rendered images, and/or rover 2D images caused by DEM low resolution, rover image illumination variations and small terrain features. In this work, we use train CNN discriminator to match rover 2D image with DEM rendered images using conditional Generative Adversarial Network architecture (cGAN). We then use this discriminator to search an uncertainty bound given by visual odometry (VO) error bound to estimate rover optimal location and orientation. We demonstrate our network capability to learn to translate rover image into DEM simulated image and match them using Devon Island dataset. The experimental results show that our proposed approach achieves ~74% mean average precision."
점유 센서를 위한 합성곱 신경망과 자기 조직화 지도를 활용한 온라인 사람 추적,2018,"['on-line tracking', 'convolutional neural network', 'self organizing map', 'occupancy sensor']",,"Occupancy sensors installed in buildings and households turn off the light if the space is vacant. Currently PIR(pyroelectric infra-red) motion sensors have been utilized. Recently, the researches using camera sensors have been carried out in order to overcome the demerit of PIR that cannot detect stationary people. The detection of moving and stationary people is a main functionality of the occupancy sensors. In this paper, we propose an on-line human occupancy tracking method using convolutional neural network (CNN) and self-organizing map. It is well known that a large number of training samples are needed to train the model offline. To solve this problem, we use an untrained model and update the model by collecting training samples online directly from the test sequences. Using videos capurted from an overhead camera, experiments have validated that the proposed method effectively tracks human."
A Video Smoke Detection Algorithm Based on Cascade Classification and Deep Learning,2018,"['smoke detection', 'deep learning', 'convolutional neural network', 'cascade classification', 'BAIR reference CaffeNet']",,"Fires are a common cause of catastrophic personal injuries and devastating property damage. Every year, many fires occur and threaten human lives and property around the world. Providing early important sign for early fire detection, and therefore the detection of smoke is always the first step in fire-alarm systems. In this paper we propose an automatic smoke detection system built on camera surveillance and image processing technologies. The key features used in our algorithm are to detect and track smoke as moving objects and distinguish smoke from non-smoke objects using a convolutional neural network (CNN) model for cascade classification. The results of our experiment, in comparison with those of some earlier studies, show that the proposed algorithm is very effective not only in detecting smoke, but also in reducing false positives."
딥러닝을 활용한 여드름 중증도 측정,2018,"['Acne severity', 'Convolutional Neural Network Korean acne grading system', 'Deep learning']",,"Background: Acne is a chronic inflammatory disease of the pilosebaceous unit, mainly on the face. It can have various clinical manifestations and should be appropriately treated based on the severity. In Korea, the 'Korea Acne Severity Rating System (KAGS)' is a standardized index to determine the severity of acne according to specific Korean characteristics. However, the actual use of the KAGS in clinical settings has been limited.Objective: We sought to analyze whether we could effectively measure acne severity using a deep learning algorithm, which is an image learning method.Methods: Acne severity was classified into three levels of mild, moderate, and severe based on the KAGS, and learning and verification were performed using the CNN (Convolutional Neural Network), a deep learning technique.Results: GoogLeNet's Inception-v3 algorithm showed the highest accuracy at 86.7%.Conclusion: This study confirmed that the use of a deep learning algorithm may facilitate the scoring of acne severity. (Korean J Dermatol 2018;56(7):421∼425)"
Structuring of Unstructured SNS Messages on Rail Services using Deep Learning Techniques,2018,"['Data Structuring', 'Deep neural network', 'Information of Rail services', 'Social network service', 'Text mining']",,"This paper presents a structuring process of unstructured social network service (SNS) messages on rail services. We crawl messages about rail services posted on SNS and extract keywords indicating date and time, rail operating company, station name, direction, and rail service types from each message. Among them, the rail service types are classified by machine learning according to predefined rail service types, and the rest are extracted by regular expressions. Words are converted into vector representations using Word2Vec and a conventional Convolutional Neural Network (CNN) is used for training and classification. For performance measurement, our experimental results show a comparison with a TF-IDF and Support Vector Machine (SVM) approach. This structured information in the database and can be easily used for services for railway users."
Application of Image Classification using Machine Learning Technique on Smart Device,2018,"['Internet of things', 'Artificial intelligence', 'Image classification', 'Smartwatch application', '사물인터넷', '인공지능', '이미지 분류', '스마트워치 어플리케이션']",,"This paper combines two of the most recent research topics for consumer electronic devices: Internet of Things (IoT) and Artificial Intelligence (AI), applied to solve an image classification problem for an electrical appliance’s recipe database. The first part of this article presents the development of an Android mobile application containing all the options from its recipe book manual. The problem addresses the inconvenience to manually search over the catalog categories to find the recipe that matches the actual ingredient available for the users in their home. The proposed solution establishes to recognize the ingredient with the mobile device camera using transfer learning over a pre-trained Convolutional Neural Network (CNN) to distinguish between the recipes that uses the ingredient, and exclude the recipe sets that are unrelated to the ingredient acquired with the camera. In the second part of the article, the availability of sensors on most of the wrist smartwatches and fitness bands is exploited to categorize the users according to the level of physical activity, in pursuance of making a healthy recommendation according to the number of calories in each of the recipes."
A Study on Drone Industry and Global Trend,2018,"['My drone', 'One Drone Per Person', 'Drone Technologies', 'Drone Industry', 'The Global Drone Market and Trend', 'Establishment of Direction for Drone Policy and Strategy', '마이드론', '1인 1드론시대', '드론기술력', '드론마켓과 글로벌트렌드', '드론정책수립과 방향', '드론산업의 글로벌 경쟁력']",,"Existing drones with expensive and limited functions used by armed forces, government institutions and large companies, are becoming cheaper recently, is getting cheaper and versatile for various functions thanks to eyecatching technologies development through incessant development Drones have emerged as the important indispensable presence in human daily living such as politics, economy, social culture, armed force·society·sports·industry etc, using the speedy, free movement characteristics of drone in space comprising postal transportation, goods transportation, medicine transportation, traffic control, facilities management, fire and forest fire surveillance, coast surveillance etc , in addition to the service using cameras. Furthermore broadcasters such as U. S. CNN deeply moved the global society by taking movies and reporting the dangerous sites such as earthquake sites in recent Nepal and Indonesia as well as anti-government protest in Turkey, in safe and various angles of drones. The drone industry as technology concentrated industry using all of computer engineering, mechanical engineering, control engineering, aviation and air space engineering, electronic engineering, requires steady research and investment over a long period. From the material engineering where the structure of drone body is designed and the strength is computed, to the sophisticated automatic control to put the drone in action by real time computation of optimal path from current position to the destination, all technologies start with basic scientific rules. drone Concurrently with drone body technologies, development of devices mounted on small scale drones is being accelerated. In consideration of current speed of dissemination and impact of drones, the age of ‘My drone’, meaning one drone per person, is anticipated to come soon. The global drone market is expected to grow by 29% per year, reaching 82 billion USD size by year 2026. It is the time for manless aircraft industry to indulge in establishing industry infrastructure to enhance competitiveness by government’s policy support, enterprises’ technologies development, and prompt and proper revision of system and legislation. This thesis rearranges and analyzes the technologies, market prospect, major issues etc concentrating on the drone industry, and highlights the related core promising project areas, and focuses on improvement and establishment of direction for drone policy and strategy through analysis·research mainly on support policy for fostering the industry of major advanced countries."
스마트 디바이스에 적용한 기계학습기반 이미지 분류 어플리케이션,2018,"['사물인터넷', '인공지능', '이미지 분류', '스마트워치 어플리케이션', 'Internet of things', 'Artificial intelligence', 'Image classification', 'Smartwatch application']","본 논문은 사물인터넷과 인공지능 기술을 적용한 이미지 분류 기법을 제안한다. 제안한 분류 기법은 과일과 채소 등을 인식하는데 사용하며, 대상 사물을 분별한 후 이 사물이 포함된 조리 기법을 추천하는 기능을 제공하는 어플리케이션을 구현한다. 어플리케이션은 조리 기법 책에서 제공하는 재료(종류 및 무게), 조리 순서 등의 모든 정보를 사용자에게 제공하도록 구현하고, 또한 조리 대상 사물을 인식하는 컨볼루션널 신경망 기반 인공지능 기술도 추가하여조리의 편리성을 향상하도록 한다. 스마트워치에서는 사용자의 일일 운동량 및 생체 정보를 바탕으로 사용자에게 가장 적합한 주스 조리 기법을 추천하는 기능을 제공하도록 어플리케이션을 구현한다.","This paper combines two of the most recent research topics for consumer electronic devices: Internet of Things (IoT) and Artificial Intelligence (AI), applied to solve an image classification problem for an electrical appliance’s recipe database. The first part of this article presents the development of an Android mobile application containing all the options from its recipe book manual. The problem addresses the inconvenience to manually search over the catalog categories to find the recipe that matches the actual ingredient available for the users in their home. The proposed solution establishes to recognize the ingredient with the mobile device camera using transfer learning over a pre-trained Convolutional Neural Network (CNN) to distinguish between the recipes that uses the ingredient, and exclude the recipe sets that are unrelated to the ingredient acquired with the camera. In the second part of the article, the availability of sensors on most of the wrist smartwatches and fitness bands is exploited to categorize the users according to the level of physical activity, in pursuance of making a healthy recommendation according to the number of calories in each of the recipes."
합성곱 신경망을 활용한 위내시경 이미지 분류에서 전이학습의 효용성 평가,2018,"['Gastroscope', 'Convolutional Neual Network', 'Transfer learning', 'Resnet', 'Inception', 'VGGnet']",,"Stomach cancer is the most diagnosed cancer in Korea. When gastric cancer is detected early, the 5-year survival rate is as high as 90%. Gastroscopy is a very useful method for early diagnosis. But the false negative rate of gastric cancer in the gastroscopy was 4.6~25.8% due to the subjective judgment of the physician. Recently, the image classification performance of the image recognition field has been advanced by the convolutional neural network. Convolutional neural networks perform well when diverse and sufficient amounts of data are supported. However, medical data is not easy to access and it is difficult to gather enough high-quality data that includes expert annotations. So This paper evaluates the efficacy of transfer learning in gastroscopy classification and diagnosis. We obtained 787 endoscopic images of gastric endoscopy at Gil Medical Center, Gachon University. The number of normal images was 200, and the number of abnormal images was 587. The image size was reconstructed and normalized. In the case of the ResNet50 structure, the classification accuracy before and after applying the transfer learning was improved from 0.9 to 0.947, and the AUC was also improved from 0.94 to 0.98. In the case of the InceptionV3 structure, the classification accuracy before and after applying the transfer learning was improved from 0.862 to 0.924, and the AUC was also improved from 0.89 to 0.97. In the case of the VGG16 structure, the classification accuracy before and after applying the transfer learning was improved from 0.87 to 0.938, and the AUC was also improved from 0.89 to 0.98. The difference in the performance of the CNN model before and after transfer learning was statistically significant when confirmed by T-test (p < 0.05). As a result, transfer learning is judged to be an effective method of medical data that is difficult to collect good quality data."
표정 분류 연구,2018,[],,"Effective interaction between user and device is considered an important ability of IoT devices. For some applications, it is necessary to recognize human facial expressions in real time and make accurate judgments in order to respond to situations correctly. Therefore, many researches on facial image analysis have been preceded in order to construct a more accurate and faster recognition system. In this study, we constructed an automatic recognition system for facial expressions through two steps - a facial recognition step and a classification step. We compared various models with different sets of data with pixel information, landmark coordinates, Euclidean distances among landmark points, and arctangent angles. We found a fast and efficient prediction model with only 30 principal components of face landmark information. We applied several prediction models, that included linear discriminant analysis (LDA), random forests, support vector machine (SVM), and bagging; consequently, an SVM model gives the best result. The LDA model gives the second best prediction accuracy but it can fit and predict data faster than SVM and other methods. Finally, we compared our method to Microsoft Azure Emotion API and Convolution Neural Network (CNN). Our method gives a very competitive result."
인공지능을 이용한 파프리카 실내 양액 재배 시 발생하는 병해충 자동 검출,2018,"['paprika', 'AI', 'disease/pest', 'detection']",,A method for the automatic detection of diseases/infestations in paprika cultivation using AI is investigated. Powdery mildew was the paprika disease observed during hydroponic cultivation in a greenhouse environment. The two-spotted-spider-mite was the pest. Paprika leaves with either the disease or the pest were automatically detected using a Faster R-CNN network architecture. The detection performance was high with mAP 96.76 %. The training and testing arrangements and the training data set are described in detail.
Improved Sliding Shapes for Instance Segmentation of Amodal 3D Object,2018,"['instance segmentation', 'detector', 'fully convolution network', 'amodal proposals']",,"State-of-art instance segmentation networks are successful at generating 2D segmentation mask for region proposals with highest classification score, yet 3D object segmentation task is limited to geocentric embedding or detector of Sliding Shapes. To this end, we propose an amodal 3D instance segmentation network called A3IS-CNN, which extends the detector of Deep Sliding Shapes to amodal 3D instance segmentation by adding a new branch of 3D ConvNet called A3IS-branch. The A3IS-branch which takes 3D amodal ROI as input and 3D semantic instances as output is a fully convolution network(FCN) sharing convolutional layers with existing 3d RPN which takes 3D scene as input and 3D amodal proposals as output. For two branches share computation with each other, our 3D instance segmentation network adds only a small overhead of 0.25 fps to Deep Sliding Shapes, trading off accurate detection and point-to-point segmentation of instances. Experiments show that our 3D instance segmentation network achieves at least 10% to 50% improvement over the state-of-art network in running time, and outperforms the state-of-art 3D detectors by at least 16.1 AP."
무인 항공기를 이용한 밀집영역 자동차 탐지,2018,"['Vehicle Detection', 'Deep Learning', 'Darknet', 'YOLOv2', 'Object Detection']",본 논문은 최근 물체탐지 분야에서 실시간 물체 탐지 알고리즘으로 주목을 받고 있는 YOLOv2(You Only Look Once) 알고리즘을 이용하여 밀집 영역에 주차되어 있는 자동차 탐지 방법을 제안한다. YOLO의 컨볼루션 네트워크는 전체 이미지에서 한 번의 평가를 통해서 직접적으로 경계박스들을 예측하고 각 클래스의 확률을 계산하고 물체 탐지 과정이 단일 네트워크이기 때문에 탐지 성능이 최적화 되며 빠르다는 장점을 가지고 있다. 기존의 슬라이딩 윈도우 접근법과 R-CNN 계열의 탐지 방법은 region proposal 방법을 사용하여 이미지 안에 가능성이 많은 경계박스를 생성하고 각 요소들을 따로 학습하기 때문에 최적화 및 실시간 적용에 어려움을 가지고 있다. 제안하는 연구는 YOLOv2 알고리즘을 적용하여 기존의 알고리즘이 가지고 있는 물체 탐지의 실시간 처리 문제점을 해결하여 실시간으로 지상에 있는 자동차를 탐지하는 방법을 제안한다. 제안하는 연구 방법의 실험을 위하여 오픈소스로 제공되는 Darknet을 사용하였으며 GTX-1080ti 4개를 탑재한 Deep learning 서버를 이용하여 실험하였다. 실험결과 YOLO를 활용한 자동차 탐지 방법은 기존의 알고리즘 보다 물체탐지에 대한 오버헤드를 감소 할 수 있었으며 실시간으로 지상에 존재하는 자동차를 탐지할 수 있었다.,"This paper proposes a vehicle detection method for parking areas using unmanned aerial vehicles (UAVs) and using YOLOv2, which is a recent, known, fast, object-detection real-time algorithm. The YOLOv2 convolutional network algorithm can calculate the probability of each class in an entire image with a one-pass evaluation, and can also predict the location of bounding boxes. It has the advantage of very fast, easy, and optimized-at-detection performance, because the object detection process has a single network. The sliding windows methods and region-based convolutional neural network series detection algorithms use a lot of region proposals and take too much calculation time for each class. So these algorithms have a disadvantage in real-time applications. This research uses the YOLOv2 algorithm to overcome the disadvantage that previous algorithms have in real-time processing problems. Using Darknet, OpenCV, and the Compute Unified Device Architecture as open sources for object detection. a deep learning server is used for the learning and detecting process with each car. In the experiment results, the algorithm could detect cars in a dense area using UAVs, and reduced overhead for object detection. It could be applied in real time."
사이드 스캔 소나 영상에서 수중물체 자동 탐지를 위한 컨볼루션 신경망 기법 적용,2018,['-'],,"In this paper, we have studied how to search an underwater object by learning the image generated by the side scan sonar in the convolution neural network. In the method of human side analysis of the side scan image or the image, the convolution neural network algorithm can enhance the efficiency of the analysis. The image data of the side scan sonar used in the experiment is the public data of NSWC (Naval Surface Warfare Center) and consists of four kinds of synthetic underwater objects. The convolutional neural network algorithm is based on Faster R-CNN (Region based Convolutional Neural Networks) learning based on region of interest and the details of the neural network are self-organized to fit the data we have. The results of the study were compared with a precision-recall curve, and we investigated the applicability of underwater object detection in convolution neural networks by examining the effect of change of region of interest assigned to sonar image data on detection performance."
심층 신경망을 활용한 전자문서 내 객체의 자동 추출 방법 연구,2018,"['Object Extraction', 'Deep Learning', 'Tensorflow', 'PDF Document', '객체 추출', '심층 학습', '텐서플로우', '전자문서']",,"With the proliferation of artificial intelligence technology, it is becoming important to obtain, store, and utilize scientific data in research and science sectors. A number of methods for extracting meaningful objects such as graphs and tables from research articles have been proposed to eventually obtain scientific data. Existing extraction methods using heuristic approaches are hardly applicable to electronic documents having heterogeneous manuscript formats because they are designed to work properly for some targeted manuscripts. This paper proposes a prototype of an object extraction system which exploits a recent deep-learning technology so as to overcome the inflexibility of the heuristic approaches. We implemented our trained model, based on the Faster R-CNN algorithm, using the Google TensorFlow Object Detection API and also composed an annotated data set from 100 research articles for training and evaluation. Finally, a performance evaluation shows that the proposed system outperforms a comparator adopting heuristic approaches by 5.2%."
