title,date,keywords,abstract,multilingual_abstract
표면근전도 신호를 활용한 한국 숫자지화 인식에서 CNN 학습의 일관성에 관한 연구,2018,"['convolutional neural network', 'time-series signal', 'surface electromyography', 'Korean finger number gesture recognition', 'consistency in cnn learning', 'repeated recognition application']","합성곱 신경망 (Convolutional Neural Network, CNN)은 컴퓨터 비전 분야에서 활발히 적용되어 왔으며, 이미지 분류, 문서 분류, 지문 인식 등에서 탁월한 인식 능력을 보여 왔음을 여러 연구를 통해서 검증되었다. 본 연구는 시계열의 표면근전도 신호를 입력데이터로 취하는 숫자지화 인식 응용에 이미지 분류에서 탁월한 인식 성능을 보이는 합성곱 신경망을 적용한 것으로, 반복적인 한국 숫자지화 인식 수행에서도 일관된 학습을 수행하는지를 검증하는 연구로, 문헌에서 보기 힘든 연구이다. 이를 검증하기 위해, 한국 숫자지화 영(0)부터 다섯(5)까지의 여섯 숫자지화를 시연하도록 훈련한 실험 대상 1인의 아래팔 근육으로부터 획득한 숫자별 60개씩 총 360개의 표면근전도 신호를 획득하였으며, 그 중에서 252개의 표면근전도 신호를 입력데이터, 108개의 표면근전도 신호는 테스트데이터로 CNN 인식에 활용하였다. CNN 인식을 위해 필요한 학습단계는 100 학습단계, CNN 인식의 반복 수행 횟수는 10회로 설정하였으며, 반복 수행마다 테스트데이터를 활용하여 인식률을 계산하였다. 본 연구에서 실험한 결과에서 보듯이, 반복 인식마다 CNN의 학습은 일관되었으며, 99.1% 이상 (60 숫자지화 중 하나의 숫자지화 인식에 오류발생)의 높은 인식률을 보였다. 따라서, CNN 기법은 시계열의 표면근전도 신호를 입력데이터로 하는 숫자지화 인식 분야에서도 전역 솔루션과 함께 우수한 인식 능력을 제공하는 기법 중에 하나이다.","Convolutional Neural Network (CNN) has been actively employed in the application of computer vision, and has been proved to have its superior performance in image classification, document classification, and finger print recognition. This work focuses on an application of CNN, having outstanding performance in image classification, to recognition of korean finger number using time series sEMG signals as input and validates CNN's capability in providing its consistent learning in repeated application for recognition of sEMG based Korean finger numbers, which has been rarely a topic in previous studies. To this end, 252 sEMG signals as input data and 108 sEMG signals as test data out of 360 sEMG signals (60 signals each number) acquired from a forearm muscle of the subject who is trained to consistently perform six Korean finger number gestures from zero(0) to five(5) were used for CNN based finger number recognition. CNN was set to have 100 learning iterations for each application of finger number recognition, and to have 10 repetitive applications of finger number recognition for the consistency of CNN's learning. Recognition rate at each repetition was calculated from test data. As can be seen from the results in this work, CNN shows consistent learning at each repetitive application of finger number recognition and outstanding recognition rates of more than 99.1% (missed one case out of 60 cases). Thus, CNN is one of powerful techniques for finger number recognition based on time-series sEMG signals to provide not only global solution but also excellent recognition rates."
딥러닝 기반의 R-CNN을 이용한 악성코드 탐지 기법,2018,"['악성코드 분석', '딥러닝', 'R-CNN', '특징 추출', '이미지 프로세싱', 'Malware', 'Deep learning', 'Regions with CNN', 'Image processing']","최근 기계학습의 발달로 인공지능을 구현하는 머신러닝과 딥러닝 같은 기술이 많은 관심을 받고 있다. 본 논문에서는  딥러닝 기반의 R-CNN을 이용한 바이너리 악성코드를 이미지화 하고 이미지에서 특징을 추출해 패밀리를 분류한다. 본 논문에서는 딥러닝에서 두 단계를 이용해 악성코드를 CNN을 이용해 이미지화하고 ,악성코드의 패밀리가 갖는 특징을 R-CNN을 이용해 분류함으로 악성코드를 이미지화하여 특징을 분류하고 패밀리를 분류한 후 악성코드의 진화를 자동 분류한다. 제안 기법은 검출율이 93.4%로 우수한 탐지 성능을 보였고 정확도는 98.6%로 매우 높은 성능을 보였다. 또한 악성코드를 이미지화 하는 CNN 처리속도가 23.3ms, 하나의 샘플을 분류하기 위해서 R-CNN처리 속도는 4ms로 비교적 빠르게 악성코드를 판별하고 분류가 가능함을 실험을 통해 증명하였다.","Recent developments in machine learning have attracted a lot of attention for techniques such as machine learning and deep learning that implement artificial intelligence. In this paper, binary malicious code using deep learning based R-CNN is imaged and the feature is extracted from the image to classify the family. In this paper, two steps are used in deep learning to image malicious code using CNN. And classify the characteristics of the family of malicious codes using R-CNN. Generate malicious code as an image, extract features, classify the family, and automatically classify the evolution of malicious code. The detection rate of the proposed method is 93.4% and the accuracy is 98.6%. In addition, the CNN processing speed for image processing of malicious code is 23.3 ms, and the R-CNN processing speed is 4ms to classify one sample."
배치 정규화와 CNN을 이용한 개선된 영상분류 방법,2018,"['배치 정규화', '합성곱 신경망', '영상 분류', '딥 러닝', 'Batch Normalization', 'Convolutional Neural Network', 'Image Classification', 'Deep Learning']","딥 러닝은 영상 분류를 위한 여러 방법 중 높은 정확도를 보이는 방법으로 알려져 있다. 본 논문에서는 딥 러닝 방법 가운데 합성곱 신경망 (CNN:Convolutional Neural Network)을 이용하여 영상을 분류함에 있어 배치 정규화 방법이 추가된 CNN을 이용하여 영상 분류의 정확도를 높이는 방법을 제시하였다. 본 논문에서는 영상 분류를 더 정확하게 수행하기 위해 기존의 뉴럴 네트워크에 배치 정규화 계층 (layer)를 추가하는 방법을 제안한다. 배치 정규화는 각 계층에 존재하는 편향을 줄이기 위해 고안된 방법으로, 각 배치의 평균과 분산을 계산하여 이동시키는 방법이다. 본 논문에서 제시된 방법의 우수성을 입증하기 위하여 SHREC13, MNIST, SVHN, CIFAR-10, CIFAR-100의 5개 영상 데이터 집합을 이용하여 영상분류 실험을 하여 정확도와 mAP를 측정한다. 실험 결과 일반적인 CNN보다 배치 정규화가 추가된 CNN이 영상 분류 시 보다 높은 분류 정확도와 mAP를 보임을 확인 할 수 있었다.","Deep learning is known as a method of high accuracy among several methods for image classification. In this paper, we propose a method of enhancing the accuracy of image classification using CNN with a batch normalization method for classification of images using deep CNN (Convolutional Neural Network). In this paper, we propose a method to add a batch normalization layer to existing neural networks to enhance the accuracy of image classification. Batch normalization is a method to calculate and move the average and variance of each batch for reducing the deflection in each layer. In order to prove the superiority of the proposed method, Accuracy and mAP are measured by image classification experiments using five image data sets SHREC13, MNIST, SVHN, CIFAR-10, and CIFAR-100. Experimental results showed that the CNN with batch normalization is better classification accuracy and mAP rather than using the conventional CNN."
Zero-skipping을 적용한 MNIST 분류 CNN 구현,2018,"['GPU', 'MNIST', 'CNN', 'Zero-skipping']","본 논문에서는 zero-skipping을 적용한 MNIST 분류 CNN을 구현했다. CNN의 activation에서 0이 30∼40% 나오고, 0은 MAC연산에 영향을 끼치지 않기 때문에 0을 branch를 통해 skip하게 되면 성능 향상을 시킬 수 있다. 그러나 컨볼루션 레이어에서는branch를 통해 skip하게 되면 성능 하락이 발생한다. 그에 따라 컨볼루션 레이어에서는 연산의 영향을 미치지 않는 NOP을 주어연산을 skip하고 풀리 커넥티드 레이어에서는 branch를 통해 skip했다. 기존의 CNN보다 약 1.5배의 성능 향상을 확인했다","In this paper, MNIST classification CNN with zero skipping is implemented. Activation of CNN results in 30% to 40%zero. Since 0 does not affect the MAC operation, skipping 0 through a branch can improve performance. However, at theconvolution layer, skipping over a branch causes a performance degradation. Accordingly, in the convolution layer, anoperation is skipped by giving a NOP that does not affect the operation. Fully connected layer is skipped through thebranch. We have seen performance improvements of about 1.5 times that of existing CNN."
능동소나 스펙트로그램 이미지와 CNN을 사용한표적/비표적 식별,2018,"['Sonar signal processing', 'Active sonar', 'Target classification', 'Convolutional Neural Networks', 'Spectrogram']","CNN(Convolutional Neural Networks)은 동물의 시각정보처리과정을 모델링한 신경망으로 다양한 분야에서 좋은 성능을보여주고 있다. 본 논문에서는 CNN을 사용하여 능동소나 신호의 스펙트로그램을 분석하고, 표적과 비표적을 식별하는 연구를 수행하였다. 데이터를 표적이 포함된 비율에 따라 8클래스로 구분하고, CNN의 학습에 사용하였다. 신호의 스펙트로그램을 프레임별로 나누어 입력으로 사용한 결과, 표적신호의 위치에서만 표적신호에 해당하는 7개 클래스의 식별 결과가 순차적으로 나타나는 특성을 사용하여 표적과 비표적을 식별해낼 수 있었다.","CNN (Convolutional Neural Networks) is a neural network that models animal visual information processing. And itshows good performance in various fields. In this paper, we use CNN to classify target and non-target data by analyzingthe spectrogram of active sonar signal. The data were divided into 8 classes according to the ratios containing thetargets and used for learning CNN. The spectrogram of the signal is divided into frames and used as inputs. As a result,it was possible to classify the target and non-target using the characteristic that the classification results of the sevenclasses corresponding to the target signal sequentially appear only at the position of the target signal."
작성자 분석과 CNN을 적용한 소스 코드 작성자 식별 프레임워크,2018,"['작성자 식별', '작석자 분석', '합성곱 신경망', '기계학습', '코드 분석', 'Author Identification', 'Authorship Analysis', 'Convolutional Neural Network', 'Machine Learning', 'Code Analysis']","최근 인터넷 기술이 발전함에 따라 다양한 프로그램들이 만들어지고 있고 이에 따라 다양한 코드들이 많은 사람들을 통해 만들어진다. 이러한 측면을 이용하여 특정 작성자가 작성한 코드들 그대로 가져가 자신이 작성한 것처럼 보여주거나, 참고한 코드들에 대한 정확한 표기 없이 그대로 사용하여 이에 대한 보호가 점차 어려워지고 있다. 따라서 본 논문에서는 작성자 분석 이론과 합성곱 신경망 기반 자연어 처리 방법을 적용한 작성자 식별 프레임워크룰 제안한다. 작성자 분석 이론을 적용하여 소스 코드에서 작성자 식별에 적합한 특징들을 추출하고 이를 텍스트 마이닝에서 사용하고 있는 특징들과 결합하여 기계학습 기반의 작성자 식별을 수행한다. 그리고 합성곱 신경망 기반 자연어 처리 방법을 소스 코드에 적용하여 코드 작성자 분류를 수행한다. 본 논문에서는 작성자 분석이론과 합성곱 신경망을 적용한 작성자 식별 프레임워크를 통해 작성자를 식별하기 위해서는 작성자 식별만을 위한 특징들이 필요하다는 것과 합성곱 신경망 기반 자연어 처리 방법이 소스 코드등과 같은 특수한 체계를 갖추고 있는 언어에서도 적용이 가능하다. 실험 결과 작성자 분석 이론 기반 작성자 식별 정확도는 95.1%였으며 CNN을 적용한 결과 반복횟수가 90번 이상일 경우 98% 이상의 정확도를 보여줬다.","Recently, Internet technology has developed, various programs are being created and therefore various codes are being made through many authors. On this aspect, some author deceive a program or code written by other particular author as they make it themselves and use other writers' code indiscriminately, or not indicating the exact code which has been used. Due to this makes it more and more difficult to protect the code. In this paper, we propose author identification framework using Authorship Analysis theory and Natural Language Processing(NLP) based on Convolutional Neural Network(CNN). We apply Authorship Analysis theory to extract features for author identification in the source code, and combine them with the features being used text mining to perform author identification using machine learning. In addition, applying CNN based natural language processing method to source code for code author classification. Therefore, we propose a framework for the identification of authors using the Authorship Analysis theory and the CNN. In order to identify the author, we need special features for identifying the authors only, and the NLP method based on the CNN is able to apply language with a special system such as source code and identify the author. identification accuracy based on Authorship Analysis theory is 95.1% and identification accuracy applied to CNN is 98%."
MLP 층을 갖는 CNN의 설계,2018,"['CNN(Convolutional Neural Network)(컨벌루션 신경망)', 'Deep network(깊은 신경망)', 'MLP(Multi Layer Perceptron)(다층퍼셉트론)']",국문 초록 정보 없음,"After CNN basic structure was introduced by LeCun in 1989, there has not been a major structure change except for more deep network until recently. The deep network enhances the expression power due to improve the abstraction ability of the network, and can learn complex problems by increasing non linearity. However, the learning of a deep network means that it has vanishing gradient or longer learning time. In this study, we proposes a CNN structure with MLP layer. The proposed CNNs are superior to the general CNN in their classification performance. It is confirmed that classification accuracy is high due to include MLP layer which improves non linearity by experiment. In order to increase the performance without making a deep network, it is confirmed that the performance is improved by increasing the non linearity of the network."
Distant Cache Prefetching in CNN Algorithms Run on CPU,2018,[],국문 초록 정보 없음,"As the availability of CPUs still outnumbers FPGAs and GPUs, further analysis of CNN algorithms run on CPU is important. The weak performance of CNN algorithms run on CPUs is further degraded by high cache miss rates in the CNN’s convolution layers which effectively limit the required bandwidth between cache and CPU. Thus, this paper proposes distant prefetching, a new idea in cache prefetching that proves to increase performance over exisiting schemes like Stride Prefetcher or Tagged Prefetcher for CNN algortihms. The improved performance is shown in simulations of VGGnet and TinyYOLO (v2) on the gem5 simulator."
영상 데이터 기반의 CNN을 이용한 제조 공정 데이터 분류 적용에 대한 연구,2018,"['빅데이터', '스마트팩토리', '딥러닝', 'CNN', '텐서플로우', 'Big Data', 'Smart Factory', 'Deep Learning', 'CNN', 'Tensorflow']","빅데이터 기술의 발달로 4차 산업혁명이 시작되면서 스마트 팩토리에 대한 관심이 증가하고 있다. 제조업에서는 여러 종류의 데이터들이 기하급수적으로 증가하고 있지만 관리하기가 어렵고, 데이터가 수집되어도 중요한 데이터를 찾기 힘들뿐더러 어떠한 데이터를 어떻게 사용하여야 할지도 알 수 없다. 또한, 기존의 공정에서는 공정물품에 대해 양품과 불량품만을 구분하여 불량품에 대해 작업자가 직접 눈으로 가성불량품과 불량품을 구별하였다. 이 경우 시간이 오래 걸릴뿐더러 작업자의 상태에 따라 생산성이 낮아지는 현상이 발생한다. 본 논문에서는 이러한 문제점을 해결하기 위해 딥러닝을 이용한 제조 공정 영상을 분류하는 기법을 제안한다. 제안하는 방법은 CNN(Convolutional Nueral Network)를 이용하여 화상검사 공정에서 결과로 나오는 2588*1940 크기의 영상에 대해 양품, 불량품, 가성불량(조명, 퓨즈, 뒤틀림(왜곡))에 대해 학습시켜 분류하고 테스트한다. 그 결과로 양품과 진성불량품에 대해 98% 정확도를 확인하였고, 가성불량에 대해서는 93%의 정확도를 확인할 수 있었다.","Interest in smart factory is increasing with the growth of 4th industrial revolution due to the development of big data technology. Diverse kinds of data in the manufacturing industry are growing exponentially, but it is difficult to manage, and even if the data is collected, it is hard to find important data and find the appropriate way to use the data. In addition, the worker sorted out defective products with the pseudo-defective products only through his/her direct eyes in the original manufacturing process. This takes long time and also is influenced a lot by the individual workers’ capability. In this paper, we propose a manufacturing process image classification methodusing deep learning to solve these problems. The proposed method uses CNN(Convolutional Neural Network) to learn the well-made, defective, and pseudo-defective (lights, fuse, distortion) products with the 2588*1940 size image that comes out as a result in the image inspection process. The outcomes show 98% accuracy in well-made and defective products, and 93% accuracy in pseudodefective products."
웨어러블 응용을 위한 CNN 기반 손 제스처 인식,2018,"['MPEG-IoMT', 'Hand Gesture', 'Hand Contour', 'CNN', 'Gesture Recognition']","제스처는 스마트 글라스 등 웨어러블 기기의 NUI(Natural User Interface)로 주목받고 있다. 최근 MPEG에서는 IoT(Internet of Things) 및 웨어러블 환경에서의 효율적인 미디어 소비를 지원하기 위한 IoMT(Internet of Media Things) 표준화를 진행하고 있다. IoMT에서는 손 제스처 검출과 인식이 별도의 기기에서 수행되는 것을 가정하고 이들 모듈간의 인터페이스 규격을 제공하고 있다. 한편, 최근 인식률 개선을 위하여 딥러닝 기반의 손 제스처 인식 기법 또한 활발히 연구되고 있다. 본 논문에서는 IoMT의 유스 케이스(use case)의 하나인 웨어러블 기기에서의 미디어 소비 등 다양한 응용을 위하여 CNN(Convolutional Neural Network) 기반의 손 제스처 인식 기법을 제시한다. 제시된 기법은 스마트 글래스로 획득한 스테레오 비디오로부터 구한 깊이(depth) 정보와 색 정보를 이용하여 손 윤곽선을 검출하고, 검출된 손 윤곽선 영상을 데이터 셋으로 구성하여 CNN을 학습한 후, 이를 바탕으로 입력 손 윤곽선 영상의 제스처를 인식한다. 실험결과 제안기법은 95%의 손 제스처 인식율를 얻을 수 있음을 확인하였다.",다국어 초록 정보 없음
CNN과 Grad-CAM 기반의 실시간 화재 감지,2018,"['-', '2']",국문 초록 정보 없음,"Rapidly detecting and warning of fires is necessary for minimizing human injury and property damage. Generally, when fires occur, both the smoke and the flames are generated, so fire detection systems need to detect both the smoke and the flames. However, most fire detection systems only detect flames or smoke and have the disadvantage of slower processing speed due to additional preprocessing task. In this paper, we implemented a fire detection system which predicts the flames and the smoke at the same time by constructing a CNN model that supports multi-labeled classification. Also, the system can monitor the fire status in real time by using Grad-CAM which visualizes the position of classes based on the characteristics of CNN. Also, we tested our proposed system with 13 fire videos and got an average accuracy of 98.73% and 95.77% respectively for the flames and the smoke."
Over blur를 감소시킨 Deep CNN 구현,2018,"['Deep learning', 'Denoising', 'Image processing. Gaussian noise', 'Over blurring']","본 논문에서, Gaussian noise를 제거할 때 발생하는 over blurring 현상을 감소시키는 network를 구현하였다. 기존 filtering방식은 원 영상을 blurring하여 noise를 제거함으로써, edge나 corner 같은 high frequency 성분도 함께 지워지는 것을 확인할 수 있다. CNN (Convolutional Neural Network)기반 denoiser의 경우도 사소한 edge, keypoint를 noise로 인식하여 이러한정보를 잃게 된다. 우리는 CNN을 기반으로 denoising된 high frequency 성분만을 획득하여 기존 denoiser에 추가함으로써denoising 성능을 유지하면서 over blurring을 완화하는 network 제안한다.","In this paper, we have implemented a network that overcomes the over-blurring phenomenon that occurs whenremoving Gaussian noise. In the conventional filtering method, blurring of the original image is performed to removenoise, thereby eliminating high frequency components such as edges and corners. We propose a network that reducingover blurring while maintaining denoising performance by adding denoised high frequency components to denoisers basedon CNN."
CNN과 OpenPose 라이브러리를 활용한 실시간 수화 통역기,2018,"['OpenPose', 'Real-time system', 'Pose detection', 'Sign language']","인공지능 기술이 급속도로 발전하고 있다. 인공지능 기술이 발전함에 따라 많은 기업들이 제품에 인공지능 기술을 탑재하여 출시하고 있다. 인공지능 기술이 포함된 제품이 많아지면서 우리의 삶에 없어서는 안 될 필수요소로 자리잡고 있다. 최근 이러한 인공지능 제품들은 일반인뿐만 아니라 일상생활에 많은 불편함을 느끼는 장애인들을 타깃으로 다양하게 출시되고 있다. 그러나 이러한 제품들은 대부분 시각장애인들을 위해 촉각, 청각에 기반을 둔 개발로 초점이 맞춰져 있다. 따라서 본 논문에서는 CNN을 이용하여 특징을 추출하는 OpenPose 라이브러리와 RNN을 사용하여 청각장애인들을 위한 실시간 수화 번역 프로그램을 제작했다. 수화 번역기의 구현 가능성을 테스트하기 위해 0~9까지 숫자에 대해 테스트를 진행하였고, 그 결과를 손 상단에 출력하였다. 실험 결과 OpenPose를 통해 검출한 신체를 토대로 손의 움직임을 학습하여 수화로 나타내는 숫자를 손 상단에 정확히 출력하는 것을 확인할 수 있었다. 0~9 의 10개의 단어를 이용하여 테스트를 진행하였지만, 자음, 모음 혹은 단어를 학습하게 된다면 실생활에서 이용하는 다양한 문장을 해석할 수 있다. 또한 이는 대화에 어려움을 느끼는 장애인뿐만 아니라 이들과 대화를 함께하는 비장애인들에게도 유용하게 작용되어 장애인과 비장애인 사이의 대화의 벽을 허물 수 있을 것으로 기대된다.","Artificial Intelligent(AI) technology has shown a rapid development in recent years. With such a development, numerous businesses release commercialized devices equipped with AI. As the number of products including AI technology increases, it becomes an indispensable element in our lives. Recently, the AI products have been released in various forms not only for the general consumers but also for the disables who might have some troubles in their daily life. But this kind of products mostly focus on the blinds (and offer support in the matter of the sense of touch and sound.) For this reason, we made a real-time interpreter of sign language for the deaf using OpenPose library which extracts the feature using CNN and RNN. In order to verify its feasibility, we processed a test with the digit 0 to 9 and printed the output above the hand on the screen. As a result, it has been confirmed that our AI is able to accurately recognize each numerical value represented by sign language. If this can also differentiate consonants, vowels, words and even various sentences used in real life, it is expected that this will be worthwhile not only for the disables who have the difficulty in conversation with diverse people, but also for non-disabled people."
딥러닝(CNN)기반 저해상도 IR이미지 분석을 통한 작업자 인식,2018,"['Deep Learning', 'CNN', 'Human error', 'Object detection']","플랜트 내 위험지역의 안전을 위해 작업자 중심의 안전관리가 필요하다. 최근 5년간 가스 사고의 원인은 시설 노후 및 장비고장 뿐만 아니라, 사용자의 취급부주의나 고의사고, 공급자 취급부주의 등 작업자의 행동에 밀접한 관련이 있다. 이와 같은 사고를 미연에 방지하기 위해서, 플랜트 내 위험지역에 대한 실시간 모니터링이필요로 하다. 하지만 실시간 모니터링을 위해서 작업(근로)공간에 카메라 설치 시, 인권침해와 같은 문제가 발생한다. 이를 방지하기 위해서 작업자의 신원 노출이 적은 저해상도의 Infrared 카메라를 이용한다. 또한 실시간모니터링 시, 사람이 아닌 CNN알고리즘을 이용하여 이미지 분석을 통하여 인권침해 문제를 예방한다.",다국어 초록 정보 없음
CNN을 적용한 안개 제거기,2018,"['CNN', 'DehazeNet', 'Image processing MAC', 'FPGA']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 CRNN을 이용한 오디오 이벤트 검출 성능 비교,2018,"['Machine Learning', 'DNN', 'CNN', 'CRNN']",국문 초록 정보 없음,다국어 초록 정보 없음
질감 분석과 CNN을 이용한 잡음에 강인한 돼지 호흡기 질병 식별,2018,"['돼지 호흡기 질병', '잡음 강인성', '소리 분석', 'DNS', 'CNN', 'Porcine Respiratory Diseases', 'Noise Robustness', 'Sound Analysis', 'Dominant Neighborhood Structure', 'Convolutional Neural Network']",국문 초록 정보 없음,"Automatic detection of pig wasting diseases is an important issue in the management of group-housed pigs. In particular, porcine respiratory diseases are one of the main causes of mortality among pigs and loss of productivity in intensive pig farming. In this paper, we propose a noise-robust system for the early detection and recognition of pig wasting diseases using sound data. In this method, first we convert one-dimensional sound signals to two-dimensional gray-level images by normalization, and extract texture images by means of dominant neighborhood structure technique. Lastly, the texture features are then used as inputs of convolutional neural networks as an early anomaly detector and a respiratory disease classifier. Our experimental results show that this new method can be used to detect pig wasting diseases both economically (low-cost sound sensor) and accurately (over 96% accuracy) even under noise-environmental conditions, either as a standalone solution or to complement known methods to obtain a more accurate solution."
소음 · 진동을 이용한 CNN기반 원동 구동장치 고장진단,2018,"['산업구조분석(Industrial Structural Analysis)', '경쟁분석(Competitive Analysis)', '차별성(Differentiation)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN-LSTM기반 알고리즘을 이용한 연속시간 감정인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 열화 영상 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 깊이 영상의 얼굴 각도 측정,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 MI-FL을 이용한 회전 불변의 보행자 검출에 관한 연구,2018,"['Pedestrian detection', 'Convolutional Neural Network', 'Moment invariant', 'Rotation invariant']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 고해상도 세포사진 분류 알고리즘,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
디지털 포렌식을 위한 CNN기반 한글 폰트 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
3D CNN을 활용한 자동화된 간 종양 분할,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
A Survey on Deep CNN-based Medical Image Classification,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
스마트폰에서 CNN을 이용한 실시간 객체인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 시스템에서 CPU와 GPU를 모두 이용한 CNN의 가속,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Python에 의한 CNN을 이용한 154kV 변전소의 고장위치 판별,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
임베디드 기기의 이종 프로세서에 대한 CNN의 ILP-기반 스케줄링,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Particle Swarm Optimization 기반 CNN-LSTM 신경망을 이용한 주거용 에너지 소비 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
데이터 가공을 통한 수면무호흡증 진단 CNN모델 성능 평가 및 분석,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
적외선 카메라 영상에서의 마스크 R-CNN기반 발열객체검출,2018,"['Deep Learning', 'Infrared camera', 'Mask R-CNN', 'Image Specification', 'Object Detection', '딥러닝', '열적외선 카메라', 'Mask R-CNN', '이미지 명세화', '객체검출']","최근 비전분야에 소개된 Mask R-CNN은 객체 인스턴스 세분화를위한 개념적으로 간단하고 유연하며 일반적인 프레임 워크를 제시한다. 이 논문에서는 열적외선 카메라로부터 획득한 열감지영상에서 발열체인 인스턴스에 대해 발열부위의 세그멘테이션 마스크를 생성하는 동시에 이미지 내의 오브젝트 발열부분을 효율적으로 탐색하는 알고리즘을 제안한다. Mask R-CNN 기법은 바운딩 박스 인식을 위해 기존 브랜치와 병렬로 객체 마스크를 예측하기 위한 브랜치를 추가함으로써 Faster R-CNN을 확장한 알고리즘이다. Mask R-CNN은 훈련이 간단하고 빠르게 실행하는 고속 R-CNN에 추가된다. 더욱이, Mask R-CNN은 다른 작업으로 일반화하기 용이하다. 본 연구에서는 이 R-CNN기반 적외선 영상 검출알고리즘을 제안하여 RGB영상에서 구별할 수 없는 발열체를 탐지하였다. 실험결과 Mask R-CNN에서 변별하지 못하는 발열객체를 성공적으로 검출하였다.","Recently introduced Mask R - CNN presents a conceptually simple, flexible, general framework for instance segmentation of objects. In this paper, we propose an algorithm for efficiently searching objects of images, while creating a segmentation mask of heat generation part for an instance which is a heating element in a heat sensed image acquired from a thermal infrared camera. This method called a mask R - CNN is an algorithm that extends Faster R - CNN by adding a branch for predicting an object mask in parallel with an existing branch for recognition of a bounding box. The mask R - CNN is added to the high - speed R - CNN which training is easy and fast to execute. Also, it is easy to generalize the mask R - CNN to other tasks. In this research, we propose an infrared image detection algorithm based on R - CNN and detect heating elements which can not be distinguished by RGB images. As a result of the experiment, a heat-generating object which can not be discriminated from Mask R-CNN was detected normally."
R-CNN 기법을 이용한 건물 벽 폐색영역 추출 적용 연구,2018,"['3D Spatial information', 'Occlusion area', 'Deep-learning', 'R-CNN', '3차원 공간정보', '폐색영역', '딥러닝', 'R-CNN']","3차원 공간정보 구축을 위해 건물 텍스처를 촬영하는 과정에서 폐색영역 문제가 발생한다. 이를 해결하기 위해선 폐색영역을 자동 인식하여 이를 검출하고 텍스처를 자동 보완하는 자동화 기법 연구가 필요하다. 현실적으로 매우 다양한 구조물 형상과 폐색을 발생시키는 경우가 있으므로 이를 극복하는 대안들이 고려되고 있다. 본 연구는 최근 대두되고 있는 딥러닝 기반의 알고리즘을 이용하여 폐색지역 패턴화하고, 학습기반 폐색영역 자동 검출하는 접근을 시도한다. 영상 내 객체 추출에서 우수한 성과를 발표하는 Convolutional Neural Network (CNN) 기법의 향상된 알고리즘인 Faster Region-based Convolutional Network (R-CNN)과 Mask R-CNN 2가지를 이용하여, 건물 벽면 촬영 시 폐색을 유발하는 사람, 현수막, 차량, 신호등에 대한 자동 탐지하는 성능을 알아보기 위해 실험하고, Mask R-CNN의 미리 학습된 모델에 현수막을 학습시켜 자동탐지하는 실험을 통해 적용이 높은 결과를 확인할 수 있었다.","For constructing three-dimensional (3D) spatial information occlusion region problem arises in the process of taking the texture of the building. In order to solve this problem, it is necessary to investigate the automation method to automatically recognize the occlusion region, issue it, and automatically complement the texture. In fact there are occasions when it is possible to generate a very large number of structures and occlusion, so alternatives to overcome are being considered. In this study, we attempt to apply an approach to automatically create an occlusion region based on learning by patterning the blocked region using the recently emerging deep learning algorithm. Experiment to see the performance automatic detection of people, banners, vehicles, and traffic lights that cause occlusion in building walls using two advanced algorithms of Convolutional Neural Network (CNN) technique, Faster Region-based Convolutional Neural Network (R-CNN) and Mask R-CNN. And the results of the automatic detection by learning the banners in the pre-learned model of the Mask R-CNN method were found to be excellent."
CNN 기법에 의한 손글씨 인식 파라미터 연구,2018,"['딥러닝', 'CNN', '훈련 옵션', '손글씨', '학습층', '파라미터', 'deep learning', 'CNN', 'training options', 'handwriting', 'learning layer', 'parameter']","딥러닝을 위한 CNN 기술은 의학, 농업, 항공 및 자동차 산업 전반에 걸쳐 연구, 개발되고 있다. 또한 콘크리트 균열이나 강철 용접 결함과 같은 건설 분야에도 적용할 수 있다. 본 연구에서는 건설분야에 적용하기에 앞서, 이전 연구를 발전시키고 CNN 기법을 사용하여 손으로 쓴 이미지의 분류를 분석하였다. 딥러닝은 일반적으로 학습층의 깊이가 깊을수록 정확도가 높아지지만 분석 시간이 오래 걸리는 단점이 있다. 또한 훈련 옵션에 따라 많은 변화가 발생할 수 있다. 따라서, 많은 파라미터연구를 수행했고 학습 계층이 더욱더 깊어질 때 분석을 수행하였다.","CNN techniques for deep learning are being studied and developed throughout the medical, agricultural, aviation, and automotive industries. It can be also applied to construction fields such as concrete cracks and steel welding defects. In this study, we upgraded the previous study and analyzed the classification of handwritten images using CNN technique before applying them to construction field. Deep learning is generally more accurate with deeper and deeper layers, but analysis cost is high. In addition, many variations can occur depending on training options.Therefore, we performed many parametric studies and analyzed when the learning layer is deeper."
한국 전통문화 말뭉치구축 및 Bi-LSTM-CNN-CRF를 활용한 전통문화 개체명 인식 모델 개발,2018,"['개체명 인식', '전통문화', '말뭉치', '딥러닝', '자질 보강', 'Named Entity Recognition', 'Traditional culture', 'Corpus', 'Deep Learning', 'feature augmentation']","개체명 인식(Named Entity Recognition)시스템은 문서로부터 고유한 의미를 가질 수 있는 인명(PS), 지명(LC), 기관명(OG) 등의 개체명을 추출하고 추출된 개체명의 범주를 결정하는 시스템이다. 최근 딥러닝 방식을 이용한 개체명 인식 연구에서 입력 데이터의 앞, 뒤 방향을 고려한 LSTM 기반의 Bi-LSTM 모델로부터 출력 데이터 간의 전이 확률을 이용한 CRF를 결합한 방식의 Bi-LSTM-CRF가 우수한 성능을 보이고, 문자 및 단어 단위의 효율적인 임베딩 벡터생성에 관한 연구와 CNN, LSTM을 활용한 모델에서도 좋은 성능을 보여주고 있다. 본 연구에서는 한국어 개체명 인식시스템 성능 향상을 위해 자질을 보강한 Bi-LSTM-CNN-CRF 모델에 관해 기술하고 전통문화 말뭉치구축 방식에 대해 제안한다. 그리고 구축한 말뭉치를 한국어 개체명 인식 성능 향상을 위한 자질 보강 모델 Bi-LSTM-CNN-CRF로 학습한 결과에 대해 제안한다.","Named Entity Recognition is a system that extracts entity names such as Persons(PS), Locations(LC), and Organizations(OG) that can have a unique meaning from a document and determines the categories of extracted entity names. Recently, Bi-LSTM-CRF, which is a combination of CRF using the transition probability between output data from LSTM-based Bi-LSTM model considering forward and backward directions of input data, showed excellent performance in the study of object name recognition using deep-learning, and it has a good performance on the efficient embedding vector creation by character and word unit and the model using CNN and LSTM. In this research, we describe the Bi-LSTM-CNN-CRF model that enhances the features of the Korean named entity recognition system and propose a method for constructing the traditional culture corpus. We also present the results of learning the constructed corpus with the feature augmentation model for the recognition of Korean object names."
CNN 을 이용한 다중 환경 지도에서의 위치 인식,2018,"['다중 환경 지도 관리', '위치 인식', 'CNN']",본 논문에서는 CNN 을 활용하여 입력 영상에 대해서 다수의 환경 지도에서 위치를 인식하는 방법을 소개한다. 본 연구에서의 위치 인식은 환경 추정과 위치 추정의 두 단계로 이루어진다. 각 공간에 대한 정보와 공간 위치는 위치 인식 기술이 내장된 모바일 디바이스를 활용하여 수집한다. 수집된 데이터로 CNN 을 학습하여 다중 환경에서 위치를 인식한다.,다국어 초록 정보 없음
용접 표면결함 검출을 위한 Faster R-CNN 분류기 구조 설계,2018,[],"본 논문은 용접부의 표면결함의 위치와 결함의 종류를 검출하기 위하여 Faster R-CNN를 기반으로 한 분류기의 구조를 설계하는 방법을 설명한다. 용접 표면결함은 3 가지의 형태로 구분하였으며, 각 결함 당 1,000개의 구성된 데이터 셋을 사용한다. 각 결함 당 1,000개의 데이터 중 80%는 학습에 사용하였으며 20%는 평가를 위해 데이터 셋을 나눈다. Faster-RCNN의 구조 중 RPN의 구조는 그대로 사용하되, 특징 추출 및 분류를 위한 CNN 구조는 분리하여 구축한다. 본 논문에서 제안한 CNN 구조는 용접 결함 검출을 수행했을 시 96.83%의 정확도를 보였다.",다국어 초록 정보 없음
R-CNN based Setting Region of Interest(RoI) and Tracking Algorithm using Agricultural UAV Image,2018,"['recognition and tracking', 'deep-learning', 'R-CNN', 'feature extraction', 'RoI']",국문 초록 정보 없음,"In this paper, we propose an algorithm of setting region of interest(RoI) using R-CNN and tracking it. This algorithm is designed to apply to the system that automatically recognizes the surrounding environment information of agricultural UAV. The suggested algorithm can be divided into three main categories. The first step is the feature extraction for region proposal. The direction of gradient based on histogram of gradient(HOG) is applied to detect all characteristics of mobile objects, and random Hough transform is applied to search for ground and stationary objects. The second step is deep-learning for recognition. In this step, we used R-CNN method which need to set region proposal. Extracted feature from the first step helps to get RoI. The data information was then learned to Convolutional Neural Network with a sample of 1000 images per each categories. The third step is tracking RoI. The recognized objects are then tracked and the position data is input into the database in real time to accumulate. The direction is predicted and tracked based on cumulative data, even if objects overlap or are temporarily invisible. Assessment of the recognition and tracking performance of the object was tested using the method of Mean Average Precision(MAP) and Recall to calculate the probability of how accurate it was to detect it. Tests had shown that the MAP is 77% and the Recall is 85%, with good detection and tracking."
Faster R-CNN과 이미지 오그멘테이션 기법을 이용한 화염감지에 관한 연구,2018,"['Artificial intelligency', 'Deep leaning', 'Object detection', 'Faster R-CNN', 'Image augmentation']","최근 딥러닝(deep learning) 인공지능 기반의 컴퓨터 비전 분야는 각종 영상분석 분야에서 화제로 떠오르고 있다. 본 연구에서는 딥러닝 기반의 여러 이미지 인식 알고리즘 중 이미지 내에서 객체를 검출하는 데 사용되는 Faster R-CNN 알고리즘을 이용하여 화재 이미지에서 불꽃을 검출하고자 한다. 학습 과정에서 소량의 데이터셋을 통한 화재검출 정확도 향상을 위해이미지 오그멘테이션(image augmentation) 기법을 이용하고, 이미지 오그멘테이션을 6가지 유형별로 나누어 학습하여 정확도, 정밀도, 검출률을 비교하였다. 그 결과, 이미지 오그멘테이션의 종류가 늘어날수록 검출률이 상승하지만, 다른 객체 검출모델들의 일반적인 정확도와 검출률의 관계와 마찬가지로 오검출율 또한 10%에서 최대 30%까지 증가하게 됨을 확인하였다","Recently, computer vision field based deep learning artificial intelligence has become a hot topic among various imageanalysis boundaries. In this study, flames are detected in fire images using the Faster R-CNN algorithm, which is usedto detect objects within the image, among various image recognition algorithms based on deep learning. In order toimprove fire detection accuracy through a small amount of data sets in the learning process, we use image augmentationtechniques, and learn image augmentation by dividing into 6 types and compare accuracy, precision and detection rate.As a result, the detection rate increases as the type of image augmentation increases. However, as with the generalaccuracy and detection rate of other object detection models, the false detection rate is also increased from 10% to 30%."
A Study of Facial Organs Classification Based on Fusion of CNN Features and Haar Fearture,2018,"['Alexnet', 'CNN', 'Softmax', 'Image classification', 'Haar']","현재 영상처리의 주류는 인공 지능 시스템이다. 그 중에서도 Deep learning은 인공 지능의 가능성을 크게 향상 시켰다. 본 논문에서는 얼굴의 세부 분류를 구현 하는 방법을 제안한다. 본 논문에서 사용된 방법은 크게 세 부분으로 나눌 수 있다. 첫 번째 부분은 전처리이다. 이 과정에서 Haar 특징을 사용하여 눈, 코, 입을 분리하여 각각의 Dataset을 추출한다. 두 번째 부분은 Convolution network 부분으로 Alexnet convolution 신경망을 사용하여 Convolution 연산을 수행하여 특징을 추출한다. 마지막은 Haar 특징과 CNN 특징을 융합한 특징을 이용하여 Softmax 함수를 이용해 분류 한다. 실험을 통해 제안하는 방법의 성능을 증명 하였다.","Currently, the mainstream of image processing is artificial intelligence system. Among them, Deep learning greatly improved the possibility of artificial intelligence. In this paper, we propose a method to implement detailed classification of faces. The method used in this paper can be roughly divided into three parts. The first part is preprocessing. In this process, each dataset is extracted by separating eyes, nose, and mouth using the Haar feature. In the second part, the convergence network is used to perform convolution operation using the Alexnet convolution neural network. Finally, we classify it using Softmax function using the feature that combines Haar feature and CNN feature. Experiments have demonstrated the performance of the proposed method."
UAV 영상 정보를 이용한 개선된 R-CNN 기반 주변환경 장애물 인식 및 추적 알고리즘,2018,"['R-CNN', 'ROI', '장애물 인식', '객체 추적']","UAV의 영상 데이터를 통해 주변 환경의 장애물들을 자동으로 인식하는 시스템에 부합하기 위해 개선된 R-CNN 기반 장애물 인식 및 추적 알고리즘을 제안한다. 제안하는 알고리즘은 크게 세 개로 분류할 수 있다. 첫 째는 검출하고자 하는 ROI (Region Of Interesting)를 설정하기 위하여 장애물들을 1차적으로 검출하는 것이다. 동물 및 보행자 등 이동형 장애물은 기울기의 방향성 특징들의 검출기법을 기반으로 분류하며, 전신주 및 바위 등 고정형 장애물은 변형된 랜덤하프변환을 기반으로 윤곽선 정보를 추출하여 위치정보를 판단하여 분류한다. 두 번째는 장애물 판단에 적합하게 구조적으로 개선된 CNN 기법을 기반으로 각각의 장애물 카테고리별로 1000장씩의 표본을 가지고 학습하는 과정이다. 세 번째는 인식된 장애물들에 추적 알고리즘을 적용하여 위치 데이터를 실시간으로 데이터베이스에 입력하여 누적시키고 장애물 이동에 맞춰 방향벡터를 생성하는 과정이다. 장애물들이 겹치거나 잠시 보이지 않는 현상이 발생하였을 경우에도 누적된 방향벡터 데이터들을 기반으로 이동반경과 과정을 예측하여 추적한다. 장애물의 인식 및 추적 성능 평가는 얼마나 정확히 검출하는 지에 대한 확률을 계산하기 위해 평균 검출 정확도(MAP)와 재현율(Recall)의 방법을 채택하여 테스트 하여, MAP는 평균 84%, Recall은 89%로 검출 및 추적성능이 우수함을 확인하였다.",다국어 초록 정보 없음
Binary Hashing CNN Features for Action Recognition,2018,"['Action Recognition', 'CNN Feature', 'Binary Hashing', 'Feature Normalization']",국문 초록 정보 없음,"The purpose of this work is to solve the problem of representing an entire video using Convolutional Neural Network (CNN) features for human action recognition. Recently, due to insufficient GPU memory, it has been difficult to take the whole video as the input of the CNN for end-to-end learning. A typical method is to use sampled video frames as inputs and corresponding labels as supervision. One major issue of this popular approach is that the local samples may not contain the information indicated by the global labels and sufficient motion information. To address this issue, we propose a binary hashing method to enhance the local feature extractors. First, we extract the local features and aggregate them into global features using maximum/minimum pooling. Second, we use the binary hashing method to capture the motion features. Finally, we concatenate the hashing features with global features using different normalization methods to train the classifier. Experimental results on the JHMDB and MPII-Cooking datasets show that, for these new local features, binary hashing mapping on the sparsely sampled features led to significant performance improvements."
얼굴 검출을 위한 캐스케이드 CNN 정확도에 관한 연구,2018,[],국문 초록 정보 없음,"Convolutional Neural Network is arguably the most popular deep learning architecture that is one of the most attractive area of research since it has various applications including face detection and recognition. The cascaded CNN operates at multiple resolution and rejects the background regions in the fast low resolution stages. By considering that advantage, we carry out the study on accuracy of cascaded CNN for face detection applications. The key point for our study is to analysing and improving the accuracy of cascaded CNN by applying simulations of algorithm where by we used Google's Tensorflow GPU as deep learning framework."
지역적 가중치 파라미터 제거를 적용한 CNN 모델 압축,2018,[],국문 초록 정보 없음,"CNN requires a large amount of computation and memory in the process of extracting the feature of the object. Also, It is trained from the network that the user has configured, and because the structure of the network is fixed, it can not be modified during training and it is also difficult to use it in a mobile device with low computing power. To solve these problems, we apply a pruning method to the pre-trained weight file to reduce computation and memory requirements. This method consists of three steps. First, all the weights of the pre-trained network file are retrieved for each layer. Second, take an absolute value for the weight of each layer and obtain the average. After setting the average to a threshold, remove the weight below the threshold. Finally, the network file applied the pruning method is re-trained. We experimented with LeNet-5 and AlexNet, achieved 31x on LeNet-5 and 12x on AlexNet."
Deep CNN 기반의 한국어 음소 인식 모델 연구,2018,[],본 연구에서는 심층 합성곱 신경망(Deep CNN)과 Connectionist Temporal Classification (CTC) 알고리즘을 사용하여 강제정렬(force-alignment)이 이루어진 코퍼스 없이도 학습이 가능한 음소 인식 모델을 제안한다. 최근 해외에서는 순환 신경망(RNN)과 CTC 알고리즘을 사용한 딥 러닝 기반의 음소 인식 모델이 활발히 연구되고 있다. 하지만 한국어 음소 인식에는 HMM-GMM 이나 인공 신경망과 HMM 을 결합한 하이브리드 시스템이 주로 사용되어 왔으며，이 방법은 최근의 해외 연구 사례들보 다 성능 개선의 여지가 적고 전문가가 제작한 강제정렬 코퍼스 없이는 학습이 불가능하다는 단점이 있다. 또한 RNN 은 학습 데이터가 많이 필요하고 학습이 까다롭다는 단점이 있어，코퍼스가 부족하 고 기반 연구가 활발하게 이루어지지 않은 한국어의 경우 사용에 제약이 있다. 이에 본 연구에서는 강제정렬 코퍼스를 필요로 하지 않는 CTC 알고리즘을 도입함과 동시에，RNN 에 비해 더 학습 속도가 빠르고 더 적은 데이터로도 학습이 가능한 합성곱 신경망(CNN)을 사용하여 딥 러닝 모델을 구축하여 한국어 음소 인식을 수행하여 보고자 하였다. 이 모델을 통해 본 연구에서는 한국어에 존재 하는 49 가지의 음소를 추출하는 세 종류의 음소 인식기를 제작하였으며，최종적으로 선정된 음소 인식 모델의 PER(Phoneme Error Rate)은 9.44 로 나타났다. 선행 연구 사례와 간접적으로 비교하였을 때，이 결과는 제안하는 모델이 기존 연구 사례와 대등하거나 조금 더 나은 성능을 보인다고 할 수 있다.,다국어 초록 정보 없음
"로봇 핸들링에 필요한 물체 종류, 위치, 회전각을 동시에 인식 가능한 CNN 아키텍처 설계",2018,"['CNN', 'machine learning', 'robot', 'object detection', 'visual recognition']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 소음을 이용한 원동 구동장치 고장 원인 분류 시스템,2018,"['CNN(Convolution Neural Network)', '기계 소음(Machine Noise)', '건전성관리(PHM : prognostics and health management)']",국문 초록 정보 없음,다국어 초록 정보 없음
Mask R-CNN을 이용한 실내도면 내의 객체 추출,2018,"['Mask R-CNN', '실내 도면', '객체 탐지', '3D 모델링']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on CNN Classifier for Sorting of Black Plastic Wastes,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN Model to Classify Malware Using Image Feature,2018,[],"인터넷에 발생하는 악성코드는 매우 심각한 위협 요소이며, 악성코드를 이용한 공격이 전 세계적으로 전파되며 심지어 점점 더 지능적으로 변조되고 있다. 그러므로 악성코드를 정확하게 탐지 하는 방법이 중요하다. 지금까지 널리 알려진 악성코드 대응방법은 악성코드를 탐지하여 삭제하거나 혹은 치료한다고 알고 있다. 이러한 악성코드를 탐지하기 위하여 악성코드에 따른 분류를 하여야 한다. 악성코드를 잘 분류하는 것은 알려진 악성코드를 더 잘 탐지할 수 있다는 것과 같다. 기존 연구들을 보면 같은 카테고리에 속하는 악성코드는 치료방법이 비슷하게 보이는 경향이 있다는 것을 입증한다. 그리고 많은 새로운 악성코드들이 기존에 있던 악성코드로부터 만들어진다는 것을 증명한다. 따라서 악성코드를 종류에 따라서 분류하는 것은 탐지하는 것 못지않게 아주 중요한 작업이다. 그러므로 멀웨어 분류 기술이 절실히 요구된다. 본 논문에서는 주어진 종류에 따라 악성코드를 분류하기 위한 컨볼루션 인공신경망 모델을 구축한다. 이 모델은 9,500 개의 악성코드 데이터 셋을 25 개의 종류로 분류하는 실험에서 98%의 정확도를 보인다. 본 연구의 목적은 다음 목표로 더 많은 양의 악성코드 파일에 적용되며 더 높은 정확도를 보이는 것이다.",다국어 초록 정보 없음
CNN 모델 이전학습을 이용하여 고기의 익힘 정도 성능 측정,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 딥러닝을 이용한 서울방문 관광객의 서울 이미지 분석,2018,"['서울 도시 이미지', '플리커 지오태깅된 사진', '딥러닝', '합성곱 신경망', '이미지 마이닝']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기법을 이용한 차량 종류 식별,2018,"['Deep Learning', 'Convolutional Neural Network', 'TensorFlow', 'OpenCV']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 전자소자의 표면 결함 검출,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 전방 Road-view의 직관적 상황인지 가능한 학습 모델 및 성능평가,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Text-CNN을 사용한 영화 정보 제공 챗봇 설계 및 구현,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 한국어 텍스트 분류를 활용한 운동 목적에 따른 운동 추천에의 적용,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 Structural Similarity를 활용한 단일 영상에서의 빗줄기 제거 기법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
카메라에 의한 효과적인 성별 예측을 위한 CNN 학습방법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster R-CNN을 이용한 프레스 공정 내 작업자 검출,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Spectrogram을 이용한 CNN 기반 음성 감정인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝 기반 LSTM-CNN을 활용한 단기 수요 예측에 관한 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
내용 기반 이미지 검색을 위한 CNN 특징 벡터 합성,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
SoC 가상화 플랫폼 기반 CNN 가속기 통합 시뮬레이션 플랫폼 개발,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구,2018,"['Fire Detection', 'Deep Learning', 'Kernel Size', 'Stride', '화재 검출', '심층학습', '커널 크기', '이동 간격']","본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와  이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다.","In this paper, a deep learning method is proposed to detect fire effectively using video of surveillance camera.  Based on AlexNet model, classification performance is compared according to kernel size and stride of convolution layer. Dataset for learning and inference are classified into two classes as normal and fire. Normal images are inlcude clouds and foggy and fire images include smoke and flames, respectively. As results of simulations, it is shown that the larger kernel size and smaller stride shows better performance"
자소 단위 기반의 양방향 LSTM-CNN을 활용한 영화 평점 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
모바일 장치에서 캐시 및 메모리 접근이 CNN 성능에 미치는 영향 분석,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
1-D 수평 Convolution Filter를 이용한 Super Resolution용 Streaming 구조 CNN 하드웨어 최적화,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
MRI 기반 알츠하이머병 진단을 위한 CNN 모델의 복잡도와 성능의 연관성 분석,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
"자연 환경에서 1,000 종류의 한글 문자를 검출 및 인식 가능한 CNN 기반 프레임워크",2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CCTV 영상 개선을 위한 Deep-CNN 기반 후처리 기술 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Fault Detection of Electric Vehicle Charging Pile on Basis of CNN-LSTM,2018,"['Fault detection', 'CNN-LSTM', 'Deep learning.']",국문 초록 정보 없음,"This paper presented a fault detection method based on deep learning Convolutional Neural Networks(CNN) and Long Short-Term Memory. Using CNN we get more abstract features representation in the higher level to find the distributed characteristics of the data. After obtaining the features, use LSTM to further mining useful information in the time dimension. First, we presented a CNN model which has 9 layers to extract more abstract features. By comparing three different CNN models, we realized that the shape of the original data set is much important. 16×16 shape of data set has high accuracy, it is 95%. Also comparing with traditional fault detection model, it is much better than random forest and Deep Neutral network(DNN). And the results show that the proposed CNN model can extract the features automatically for fault detection intelligently. However, data has a complex time correlation with each other. How to get the most information in the data for fault detection? We presented LSTM to extract more useful information in the time dimension. The proposed CNN-LSTM method has the highest accuracy which up to 96.13%. The proposed CNN-LSTM exhibits the best performance in the electric vehicle charging pile diagnosis."
CNN을 이용한 거리 사진의 분류와 안전도 평가,2018,"['CNN', 'street photo', 'classification', 'safety score']",국문 초록 정보 없음,"CNN (convolution neural network) has become the most popular artificial intelligence technique and shows remarkable performance in image classification task. In this paper, we propose a CNN-based classification method for various street images as well as a method of evaluating the safety score for the street. The proposed method consists of learning four types of street images using CNN and classifying input street images using the learned CNN model followed by evaluating the safety score. During the learning process, four types of street images are collected and augmented, and then CNN learning is performed. It is shown that learned CNN model classifies input images correctly and the safety scores are evaluated quantitatively by combining the probabilities of different street types."
전처리와 특징 추출이 CNN기반 화재 탐지 성능에 미치는 효과,2018,"['화재 탐지', '딥러닝', 'CNN', '전처리', '특징 추출', 'Fire Detection', 'Deep Learning', 'Preprocessing', 'Feature Extraction']","최근 들어 머신 러닝 기술의 발달로 기존 영상 기반의 응용시스템에 딥러닝 기술을 적용하는 사례들이 늘고 있다. 이러한 맥락에서 화재 감지 분야에서도 CNN (Convolutional Neural Network)을 적용하는 시도들이 이루어지고 있다. 본 논문에서는 기존 전처리 방법과 특징 추출 방법이 CNN과 결합되었을 때 화재 탐지에 어떤 효과를 유발하는지를 검증하기 위해 인식 성능과 학습 시간을 평가해 보았다. VGG19 CNN 구조를 변경, 즉 컨볼루션층을 조금씩 늘리면서 실험을 진행한 결과, 일반적으로 전처리하지 않는 이미지를 사용한 경우가 성능이 훨씬 좋음을 확인할 수 있었다. 또한 성능적인 측면에서는 전처리 방법과 특징 추출 방법이 부정적인 영향을 미치지만 학습속도 측면에서는 많은 이득이 있음을 확인할 수 있었다.","Recently, the development of machine learning technology has led to the application of deep learning technology to existing image based application systems. In this context, some researches have been made to apply CNN (Convolutional Neural Network) to the field of fire detection. To verify the effects of existing preprocessing and feature extraction methods on fire detection when combined with CNN, in this paper, the recognition performance and learning time are evaluated by changing the VGG19 CNN structure while gradually increasing the convolution layer. In general, the accuracy is better when the image is not preprocessed. Also it’s shown that the preprocessing method and the feature extraction method have many benefits in terms of learning speed."
배경 차분과 CNN 기반의 CCTV 객체 검출,2018,"['Convolutional Neural Network', '배경차분', '객체 검출', 'CCTV', 'background subtraction', 'object detection']","본 연구는 영상 분석에서 최근 좋은 연구 성과를 내고 있는 컨볼루션 신경망 (Convolutional Neural Network: CNN) 기법을 실외 CCTV 영상 분석에 적용하여 객체 유형을 분류하는 방법론은 제안한다. 배경 차분 (background subtraction)을 사용하여 찾고자 하는 객체 후보들을 추출해내고 이를 CNN을 이용해 분류함으로써 계산량을 줄이는 효과를 얻는 방법이다. CNN 학습용 CCTV 영상 수집을 위해 범죄 발생이 주로 일어나는 골목길, 놀이터 등에서 촬영한 CCTV 영상 DB를 구축하였으며 우선적으로 사람인 객체만 검출하는 분류기를 학습하였다. 다양한 학습 데이터 사이즈와 세팅에 맞게 실험하였으며 실험 결과 약 80%의 분류 정확도를 보였으며 새로운 CCTV 영상으로 테스트했을 때 약 67.5%의 성능을 보였다.","In this paper, a method to classify objects in outdoor CCTV images using Convolutional Neural Network(CNN) and background subtraction is proposed. Object candidates are extracted using background subtraction and they are classified with CNN to detect objects in the image. At the end, computation complexity is highly reduced in comparison to other object detection algorithms. A database is constructed by filming alleys and playgrounds, places where crime occurs mainly. In experiments, different image sizes and experimental settings are tested to construct a best classifier detecting person. And the final classification accuracy became 80% for same camera data and 67.5% for a different camera."
CNN을 이용한 딥러닝 기반 하수관 손상 탐지 분류 시스템,2018,"['딥러닝', 'CNN', 'CCTVs', '인공지능', '손상 탐지', '하수관', 'Artificial Intelligence', 'Deep Learning', 'Demage Detection', 'Sewer Inspection']","연구는 인공지능 분야의 딥러닝 기술을 기반으로 한 하수관 손상의 자동 탐지 분류 시스템을 제안한다. 성능의 최적화를 위하여 DB 획득 시 발생된 조도 및 그림자 변화와 같은 다양한 환경변화에 강인한 시스템을 구현하였다. 제안된 시스템에서는 Convolutional Neural Network(CNN) 기반의 균열 탐지 및 손상 분류 기법을 구현하였다. 최적의 결과를 위하여 256 x 256 픽셀 해상도의 CCTV 영상 9,941개를 이용하여 CNN모델을 적용하여 손상부위에 대한 딥러닝을 수행하였고 그 결과 98.76 %의 인식률을 획득하였다. 기계학습을 통한 딥러닝 모델을 기반으로 다양한 환경의 하수도 DB에서 720 x 480 픽셀 해상도의 646개의 이미지를 추출하여 성능 평가를 수행 하였다. 본 시스템은 다양한 환경에서 구축된 하수관 데이터베이스 에서 손상 유형의 자동 탐지 및 분류에 최적화된 인식률을 제시한다.","We propose an automatic detection and classification system of sewer damage database based on artificial intelligence and deep learning. In order to optimize the performance, we implemented a robust system against various environmental variations such as illumination and shadow changes. In our proposed system, a crack detection and damage classification method using a deep learning based Convolutional Neural Network (CNN) is implemented. For optimal results, 9,941 CCTV images with 256 x 256 pixel resolution were used for machine learning on the damaged area based on the CNN model. As a result, the recognition rate of 98.76% was obtained. Total of 646 images of 720 x 480 pixel resolution were extracted from various sewage DB for performance evaluation. Proposed system presents the optimal recognition rate for the automatic detection and classification of damage in the sewer DB constructed in various environments."
Mosaic-CNN: A Combined Two-Step Zero Prediction Approach to Trade off Accuracy and Computation Energy in Convolutional Neural Networks,2018,[],국문 초록 정보 없음,"<P>In convolutional neural networks (CNNs), convolutional layers consume dominant portion of computation energy due to large amount of multiply-accumulate operations (MACs). However, those MACs become meaningless (zeroes) after rectified linear unit when the convolution results become negative. In this paper, we present an efficient approach to predict and skip the convolutions generating zero outputs. The proposed two-step zero prediction approach, called mosaic CNN, can be effectively used for trading off classification accuracy for computation energy in CNN. In the mosaic CNN, the outputs of each convolutional layer are computed considering their spatial surroundings in an output feature map. Here, the types of spatial surroundings (mosaic types) can be selected to save computation energy at the expense of accuracy. In order to further save the computations, we also propose a most significant bits (MSBs) only computation scheme, where a constant value representing least significant bits compensates the MSBs only computations. The CNN accelerator supporting the combined two approaches has been implemented using the 65-nm CMOS process. The numerical results show that compared with the state-of-art processor, the proposed reconfigurable accelerator can achieve energy savings ranging from 16.99% to 29.64% for VGG-16 without seriously compromising the classification accuracy.</P>"
SPAD과 CNN의 특성을 반영한 ToF 센서와 스테레오 카메라 융합 시스템,2018,"['Sensor Fusion', 'Time-of-Flight', 'Stereo camera', 'Single Photon Avalanche Diodes', 'Convolution Neural Network']",국문 초록 정보 없음,"3D depth perception has played an important role in robotics, and many sensory methods have also proposed for it. As a photodetector for 3D sensing, single photon avalanche diode (SPAD) is suggested due to sensitivity and accuracy. We have researched for applying a SPAD chip in our fusion system of time-of-fight (ToF) sensor and stereo camera. Our goal is to upsample of SPAD resolution using RGB stereo camera. Currently, we have 64 x 32 resolution SPAD ToF Sensor, even though there are higher resolution depth sensors such as Kinect V2 and Cube-Eye. This may be a weak point of our system, however we exploit this gap using a transition of idea. A convolution neural network (CNN) is designed to upsample our low resolution depth map using the data of the higher resolution depth as label data. Then, the upsampled depth data using CNN and stereo camera depth data are fused using semi-global matching (SGM) algorithm. We proposed simplified fusion method created for the embedded system."
A Study on CNN based Production Yield Prediction Algorithm for Increasing Process Efficiency of Biogas Plant,2018,"['Biogas', 'Biogas plant', 'CNN', 'Production yield']",국문 초록 정보 없음,"Recently, as the demand for limited resources continues to rise and problems of resource depletion rise worldwide, the importance of renewable energy is gradually increasing. In order to solve these problems, various methods such as energy conservation and alternative energy development have been suggested, and biogas, which can utilize the gas produced from biomass as fuel, is also receiving attention as the next generation of innovative renewable energy. New and renewable energy using biogas is an energy production method that is expected to be possible in large scale because it can supply energy with high efficiency in compliance with energy supply method of recycling conventional resources. In order to more efficiently produce and manage these biogas, a biogas plant has emerged. In recent years, a large number of biogas plants have been installed and operated in various locations. Organic wastes corresponding to biogas production resources in a biogas plant exist in a wide variety of types, and each of the incoming raw materials is processed in different processes. Because such a process is required, the case where the biogas plant process is inefficiently operated is continuously occurring, and the economic cost consumed for the operation of the biogas production relative to the generated biogas production is further increased. In order to solve such problems, various attempts such as process analysis and feedback based on the feedstock have been continued but it is a passive method and very limited to operate a medium/large scale biogas plant. In this paper, we propose ""CNN-based production yield prediction algorithm for increasing process efficiency of biogas plant"" for efficient operation of biogas plant process. Based on CNN-based production yield forecasting, which is one of the deep-leaning technologies, it enables mechanical analysis of the process operation process and provides a solution for optimal process operation due to process-related accumulated data analyzed by the automated process."
CNN을 적용한 한국어 상품평 감성분석,2018,"['감성분석', '형태소 벡터', '단어 벡터', '딥러닝', 'CNN', 'CBOW', 'Sentiment Analysis', 'Morpheme Vector', 'Word Vector', 'Deep Learning', 'CNN', 'CBOW']",국문 초록 정보 없음,"With the increasing importance of sentiment analysis to grasp the needs of customers and the public, various types of deep learning models have been actively applied to English texts. In the sentiment analysis of English texts by deep learning, natural language sentences included in training and test datasets are usually converted into sequences of word vectors before being entered into the deep learning models. In this case, word vectors generally refer to vector representations of words obtained through splitting a sentence by space characters. There are several ways to derive word vectors, one of which is Word2Vec used for producing the 300 dimensional Google word vectors from about 100 billion words of Google News data. They have been widely used in the studies of sentiment analysis of reviews from various fields such as restaurants, movies, laptops, cameras, etc.  Unlike English, morpheme plays an essential role in sentiment analysis and sentence structure analysis in Korean, which is a typical agglutinative language with developed postpositions and endings. A morpheme can be defined as the smallest meaningful unit of a language, and a word consists of one or more morphemes. For example, for a word 예쁘고, the morphemes are 예쁘(= adjective) and 고(=connective ending). Reflecting the significance of Korean morphemes, it seems reasonable to adopt the morphemes as a basic unit in Korean sentiment analysis. Therefore, in this study, we use morpheme vector as an input to a deep learning model rather than word vector which is mainly used in English text. The morpheme vector refers to a vector representation for the morpheme and can be derived by applying an existent word vector derivation mechanism to the sentences divided into constituent morphemes.  By the way, here come some questions as follows. What is the desirable range of POS(Part-Of-Speech) tags when deriving morpheme vectors for improving the classification accuracy of a deep learning model? Is it proper to apply a typical word vector model which primarily relies on the form of words to Korean with a high homonym ratio? Will the text preprocessing such as correcting spelling or spacing errors affect the classification accuracy, especially when drawing morpheme vectors from Korean product reviews with a lot of grammatical mistakes and variations?  We seek to find empirical answers to these fundamental issues, which may be encountered first when applying various deep learning models to Korean texts. As a starting point, we summarized these issues as three central research questions as follows. First, which is better effective, to use morpheme vectors from grammatically correct texts of other domain than the analysis target, or to use morpheme vectors from considerably ungrammatical texts of the same domain, as the initial input of a deep learning model? Second, what is an appropriate morpheme vector derivation method for Korean regarding the range of POS tags, homonym, text preprocessing, minimum frequency? Third, can we get a satisfactory level of classification accuracy when applying deep learning to Korean sentiment analysis?  As an approach to these research questions, we generate various types of morpheme vectors reflecting the research questions and then compare the classification accuracy through a non-static CNN(Convolutional Neural Network) model taking in the morpheme vectors. As for training and test datasets, Naver Shoppings 17,260 cosmetics product reviews are used. To derive morpheme vectors, we use data from the same domain as the target one and data from other domain; Naver shoppings about 2 million cosmetics product reviews and 520,000 Naver News data arguably corresponding to Google’s News data.  The six primary sets of morpheme vectors constructed in this study differ in terms of the following three criteria. First, they come from two types of data source; Naver news of high grammatical correctness and Naver shopping’s cosme"
CNN-LSTM Coupled Model for Prediction of Waterworks Operation Data,2018,"['Big Data', 'CNN', 'Correlation Analysis', 'Deep-Learning', 'LSTM']",국문 초록 정보 없음,"In this paper, we propose an improved model to provide users with a better long-term prediction of waterworks operation data. The existing prediction models have been studied in various types of models such as multiple linear regression model while considering time, days and seasonal characteristics. But the existing model shows the rate of prediction for demand fluctuation and long-term prediction is insufficient. Particularly in the deep running model, the long-short-term memory (LSTM) model has been applied to predict data of water purification plant because its time series prediction is highly reliable. However, it is necessary to reflect the correlation among various related factors, and a supplementary model is needed to improve the long-term predictability. In this paper, convolutional neural network (CNN) model is introduced to select various input variables that have a necessary correlation and to improve long term prediction rate, thus increasing the prediction rate through the LSTM predictive value and the combined structure. In addition, a multiple linear regression model is applied to compile the predicted data of CNN and LSTM, which then confirms the data as the final predicted outcome."
CNN 기반 서명인식에서 시간정보를 이용한 위조판별 성능 향상,2018,"['CNN', '서명인식', '위조판별', 'Signature Recognition', 'Fake Discrimination']",국문 초록 정보 없음,"In this paper, we propose a method for more accurate fake discrimination using time information in CNN-based signature recognition. To easily use the time information and not to be influenced by the speed of signature writing, we acquire the signature as a movie and divide the total time of the signature into equal numbers of equally spaced intervals to obtain each image and synthesize them to create signature data. In order to compare the method using the proposed signature image and the method using only the last signature image, various signature recognition methods based on CNN have been experimented in this paper. As a result of experiment with 25 signature data, we found that the method using time information improves performance in fake discrimination compared to the existing method at all experiments."
CNN-LSTM Coupled Model for Prediction of Waterworks Operation Data,2018,"['Big Data', 'CNN', 'Correlation Analysis', 'Deep-Learning', 'LSTM']",국문 초록 정보 없음,"In this paper, we propose an improved model to provide users with a better long-term prediction ofwaterworks operation data. The existing prediction models have been studied in various types of models suchas multiple linear regression model while considering time, days and seasonal characteristics. But the existingmodel shows the rate of prediction for demand fluctuation and long-term prediction is insufficient.Particularly in the deep running model, the long-short-term memory (LSTM) model has been applied topredict data of water purification plant because its time series prediction is highly reliable. However, it isnecessary to reflect the correlation among various related factors, and a supplementary model is needed toimprove the long-term predictability. In this paper, convolutional neural network (CNN) model is introducedto select various input variables that have a necessary correlation and to improve long term prediction rate,thus increasing the prediction rate through the LSTM predictive value and the combined structure. Inaddition, a multiple linear regression model is applied to compile the predicted data of CNN and LSTM,which then confirms the data as the final predicted outcome."
2D LiDAR 센서를 이용한 CNN 기반 군집 로봇의 위치 인식 및 제어,2018,"['Multi robot', 'Localization', 'LiDAR', 'Image processing', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on CNN based Production Yield Prediction Algorithm for Increasing Process Efficiency of Biogas Plant,2018,"['Biogas', 'Biogas plant', 'CNN', 'Production yield']",국문 초록 정보 없음,"Recently, as the demand for limited resources continues to rise and problems of resource depletion rise worldwide, the importance of renewable energy is gradually increasing. In order to solve these problems, various methods such as energy conservation and alternative energy development have been suggested, and biogas, which can utilize the gas produced from biomass as fuel, is also receiving attention as the next generation of innovative renewable energy. New and renewable energy using biogas is an energy production method that is expected to be possible in large scale because it can supply energy with high efficiency in compliance with energy supply method of recycling conventional resources. In order to more efficiently produce and manage these biogas, a biogas plant has emerged. In recent years, a large number of biogas plants have been installed and operated in various locations. Organic wastes corresponding to biogas production resources in a biogas plant exist in a wide variety of types, and each of the incoming raw materials is processed in different processes. Because such a process is required, the case where the biogas plant process is inefficiently operated is continuously occurring, and the economic cost consumed for the operation of the biogas production relative to the generated biogas production is further increased. In order to solve such problems, various attempts such as process analysis and feedback based on the feedstock have been continued but it is a passive method and very limited to operate a medium/large scale biogas plant. In this paper, we propose ""CNN-based production yield prediction algorithm for increasing process efficiency of biogas plant"" for efficient operation of biogas plant process. Based on CNN-based production yield forecasting, which is one of the deep-leaning technologies, it enables mechanical analysis of the process operation process and provides a solution for optimal process operation due to process-related accumulated data analyzed by the automated process."
SPAD과 CNN의 특성을 반영한 ToF 센서와 스테레오카메라 융합 시스템,2018,"['Sensor Fusion', 'Time-of-Flight', 'Stereo camera', 'Single Photon Avalanche Diodes', 'Convolution Neural Network']",국문 초록 정보 없음,"3D depth perception has played an important role in robotics, and many sensory methods have also proposed for it. As a photodetector for 3D sensing, single photon avalanche diode (SPAD) is suggested due to sensitivity and accuracy. We have researched for applying a SPAD chip in our fusion system of time-of-fight (ToF) sensor and stereo camera. Our goal is to upsample of SPAD resolution using RGB stereo camera. Currently, we have 64 x 32 resolution SPAD ToF Sensor, even though there are higher resolution depth sensors such as Kinect V2 and Cube-Eye. This may be a weak point of our system, however we exploit this gap using a transition of idea. A convolution neural network (CNN) is designed to upsample our low resolution depth map using the data of the higher resolution depth as label data. Then, the upsampled depth data using CNN and stereo camera depth data are fused using semi-global matching (SGM) algorithm. We proposed simplified fusion method created for the embedded system."
Mixed-LGP와 해마 구조를 적용한 CNN을 이용한 얼굴검출 알고리즘 연구,2018,"['LBP', 'LGP', 'multi-feature channel', 'symmetry', 'uniform', 'hippocampus', 'CNN']",국문 초록 정보 없음,"A precise preprocessing process is required for more accurate face recognition. The preprocessing process is based on LGP(Local Gradient Pattern), which is robust against external influences such as illumination, facial expression, and background, rather than the existing LBP(Local Binary Pattern). We use uniform features and multi-feature channel based on Gradient, Orientations, Intensity, and Edge to better locate facial features in LGP-based algorithms. Symmetry features are used to speed up complex patterns by reducing them. In this paper, we propose an algorithm that uses CNN (Convolution Neural Network) applied hippocampal structure for more accurate face Detection. We used Yale face data base, BioID face data base, and MU + MIT date base to evaluate the performance of the proposed algorithm. Experimental results show that the algorithm is improved by 3 ~ 9%."
CNN을 활용한 손 치수 측정 기준점의 자동 추출 방법 개발,2018,"['CNN 모델', '인체 측정 기준점', '3D 스캐닝', '3차원 손 형상', '손 치수']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 음성 데이터 성별 및 연령 분류 기술 연구,2018,"['voice', 'classification', 'neural network', 'deep learning', 'classification', 'CNN']",국문 초록 정보 없음,"Research is carried out to categorize voices using Deep Learning technology. The study examines neural networkbased sound classification studies and suggests improved neural networks for voice classification. Related studies studied urban data classification. However, related studies showed poor performance in shallow neural network. Therefore, in this paper the first preprocess voice data and extract feature value. Next, Categorize the voice by entering the feature value into previous sound classification network and proposed neural network. Finally, compare and evaluate classification performance of the two neural networks. The neural network of this paper is organized deeper and wider so that learning is better done. Performance results showed that 84.8 percent of related studies neural networks and 91.4 percent of the proposed neural networks. The proposed neural network was about 6 percent high."
CNN-Based Drug Recognition and Braille Embosser System for the Blind,2018,"['Human-computer interaction', 'Deep learning', 'Drug recognition', 'Braille embosser']",국문 초록 정보 없음,"Visual impairments reduce one’s ability to perform daily tasks such as taking medicine. While the sighted can use their vision to effortlessly locate and identify drugs, the blind must rely on external assistance to complement their visual sense. Thus, receiving appropriate aid at the right time is crucial to avoid the misuse of drugs. We conducted interviews regarding medicine intake with 30 partially or completely blinded persons registered at three supporting facilities. Participants reported limitations of their current methods in finding their medication which led to them taking unintentional irregular doses caused by the lack of aid. Based on the results of the interview, we developed a drug recognition model and braille embosser system for Android smartphones. Using a picture of a medicine taken with a built-in camera, the CNN-based recognition model can classify 11 types of medicines with 99.6% accuracy. In addition, a low-cost braille embosser, which can connect to one’s smartphone via Bluetooth, can print the classification results as a braille label for future identification without a smartphone."
Faster R-CNN을 이용한 고속도로 UAV 이미지 속 차량 인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
야지 환경에서 3D 라이다와 CNN을 활용한 사람 인식,2018,"['Human recognition', '3D lidar', 'CNN(Convolution Neural Network)', 'rough terrain']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 실루엣 이미지 연령 및 성별 판별,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 IR 영상으로부터의 운전자 시선 인식 기술,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 얼굴의 감정변화 패턴 인식 및 연기 수행을 위한 추천,2018,"['Convolution Neural Network', 'Recognition', 'Emotion Facial Expression', 'Recommendation']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 RNN의 성능 비교,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 RNN의 성능 비교,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 영구자석 동기전동기의 선간 단락 고장 진단,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 활용한 악성코드 탐지 모델 구현,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN-based License Plate Recognition Using Capsule Networks,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 SIFT-NonSIFT 영상 패치 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 이용한 능동 소나 표적/비표적 분류,2018,"['Convolutional Neural Networks', 'Active Sonar Classification', 'Spectrogram', 'Target/Non-target']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN을 사용한 법률문서 분류 시스템에 관한 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN과 가이드 영상을 이용한 세포핵 검출,2018,"['Semantic segmentation', 'Nuclei', 'Medical image', 'Guide image']",국문 초록 정보 없음,다국어 초록 정보 없음
Siamese CNN-Bidirectional LSTM 기반 문장 유사도 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
PCA기반 CNN을 이용한 사용자 행위 인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
TU 블록 크기에 따른 CNN기반 인루프필터,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
몬테 카를로 렌더링 채널에 대한 CNN의 노이즈 제거 효율 조사,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Novel Leakage Detection by Ensemble CNN-SVM and Graph-Based Localization in Water Distribution Systems,2018,[],국문 초록 정보 없음,"<P>In many water distribution systems, a significant amount of water is lost because of leakage during transit from the water treatment plant to consumers. As a result, water leakage detection and localization have been a consistent focus of research. Typically, diagnosis or detection systems based on sensor signals incur significant computational and time costs, whereas the system performance depends on the features selected as input to the classifier. In this paper, to solve this problem, we propose a novel, fast, and accurate water leakage detection system with an adaptive design that fuses a one-dimensional convolutional neural network and a support vector machine. We also propose a graph-based localization algorithm to determine the leakage location. An actual water pipeline network is represented by a graph network and it is assumed that leakage events occur at virtual points on the graph. The leakage location at which costs are minimized is estimated by comparing the actual measured signals with the virtually generated signals. The performance was validated on a wireless sensor network based test bed, deployed on an actual WDS. Our proposed methods achieved 99.3% leakage detection accuracy and a localization error of less than 3 m.</P>"
Research on Pedestrian Detection Using CNN-Based Faster-RCNN Algorithm,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
셋업 코스트가 있는 병렬 기계에서 CNN을 활용한 실시간 일정계획,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
서울 랜드마크 인식을 위한 학습 이미지 데이터셋 구축 및 CNN을 이용한 인식 실험,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Multi-sense Word Embedding to Improve Performance of a CNN-based Relation Extraction Model,2018,"['원격 지도학습', '관계추출', '단어 임베딩', '합성곱 신경망', 'distant supervision', 'relation extraction', 'word embedding', 'convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study of Facial Organs Classification System Based on Fusion of CNN Features and Haar-CNN Features,2018,"['AlexNet', 'CNN', 'softmax classifier', 'Haar-CNN', 'image classification']",국문 초록 정보 없음,"In this paper, we proposed a method for effective classification of eye, nose, and mouth of human face. Most recent image classification uses Convolutional Neural Network(CNN). However, the features extracted by CNN are not sufficient and the classification effect is not too high. We proposed a new algorithm to improve the classification effect. The proposed method can be roughly divided into three parts. First, the Haar feature extraction algorithm is used to construct the eye, nose, and mouth dataset of face. The second, the model extracts CNN features of image using AlexNet. Finally, Haar-CNN features are extracted by performing convolution after Haar feature extraction. After that, CNN features and Haar-CNN features are fused and classify images using softmax. Recognition rate using mixed features could be increased about 4% than CNN feature. Experiments have demonstrated the performance of the proposed algorithm."
CNN 구조의 진화 최적화 방식 분석,2018,"['Convolutional neural network', 'Optimization', 'Genetic algorithm', 'Cartesian genetic programming']",국문 초록 정보 없음,"Recently, some meta-heuristic algorithms, such as GA(Genetic Algorithm) and GP(Genetic Programming), have been used to optimize CNN(Convolutional Neural Network). The CNN, which is one of the deep learning models, has seen much success in a variety of computer vision tasks. However, designing CNN architectures still requires expert knowledge and a lot of trial and error. In this paper, the recent attempts to automatically construct CNN architectures are investigated and analyzed. First, two GA based methods are summarized. One is the optimization of CNN structures with the number and size of filters, connection between consecutive layers, and activation functions of each layer. The other is an new encoding method to represent complex convolutional layers in a fixed-length binary string, Second, CGP(Cartesian Genetic Programming) based method is surveyed for CNN structure optimization with highly functional modules, such as convolutional blocks and tensor concatenation, as the node functions in CGP. The comparison for three approaches is analysed and the outlook for the potential next steps is suggested."
초고속 R-CNN을 이용한 얼굴영상에서 눈 및 입술영역 검출방법,2018,"['딥러닝', '고속 R-CNN', '눈 및 입술영역 검출', '영상인식', 'Deep Learning', 'faster R-CNN', 'Eye and Lip Detection', 'Image Recognition']","얼굴인식, 홍채인식과 같은 생체보안 분야에서 눈, 코, 입술 등 얼굴특징을 추출하는 과정은 필수적이다. 본 논문은 초고속(faster) R-CNN을 이용하여 얼굴영상에서 눈 및 입술영역을 검출하는 방법을 연구하였다. 초고속 R-CNN은 딥러닝 을 이용한 물체검출 방법으로 기존의 특징기반 방법에 비해 성능이 우수한 것으로 알려져 있다. 본 논문에서는 얼굴영상에 콘볼루션, 선형정류과정, max pooling과정을 차례로 적용하여 특징맵을 추출하고 이로부터 제안영역(region proposal)을 검 출하는 RPN(region proposal network)을 학습한다. 그리고 제안영역과 특징맵을 이용하여 눈 및 입술 검출기(detector)를 학습한다. 제안방법의 성능을 검토하기 위해 남녀한국인 얼굴영상 800장으로 실험하였다. 학습을 위해 480장을 이용했으며 테스트용으로 320장을 사용하였다. 컴퓨터모의 실험결과 눈 및 입술영역 검출의 평균정확도는 50 에포치일 때 각각 97.7%, 91.0%를 얻을 수 있었다.","In the field of biometric security such as face and iris recognition, it is essential to extract facial features such as eyes and lips. In this paper, we have studied a method of detecting eye and lip region in face image using faster R-CNN. The faster R-CNN is an object detection method using deep running and is well known to have superior performance compared to the conventional feature-based method. In this paper, feature maps are extracted by applying convolution, linear rectification process, and max pooling process to facial images in order. The RPN(region proposal network) is learned using the feature map to detect the region proposal. Then, eye and lip detector are learned by using the region proposal and feature map. In order to examine the performance of the proposed method, we experimented with 800 face images of Korean men and women. We used 480 images for the learning phase and 320 images for the test one. Computer simulation showed that the average precision of eye and lip region detection for 50 epoch cases is 97.7% and 91.0%, respectively."
비정형 정보와 CNN 기법을 활용한 이진 분류 모델의 고객 행태 예측,2018,"['고객 행태 예측', '합성곱 신경망', '딥러닝', '고객의 소리', 'Customer Behavior Prediction', 'Deep Learning', 'Convolution Neural Network(CNN)', 'Voice of Customer(VOC)']",국문 초록 정보 없음,"Deep learning is getting attention recently. The deep learning technique which had been applied in competitions of the International Conference on Image Recognition Technology(ILSVR) and AlphaGo is Convolution Neural Network(CNN). CNN is characterized in that the input image is divided into small sections to recognize the partial features and combine them to recognize as a whole. Deep learning technologies are expected to bring a lot of changes in our lives, but until now, its applications have been limited to image recognition and natural language processing.  The use of deep learning techniques for business problems is still an early research stage. If their performance is proved, they can be applied to traditional business problems such as future marketing response prediction, fraud transaction detection, bankruptcy prediction, and so on. So, it is a very meaningful experiment to diagnose the possibility of solving business problems using deep learning technologies based on the case of online shopping companies which have big data, are relatively easy to identify customer behavior and has high utilization values. Especially, in online shopping companies, the competition environment is rapidly changing and becoming more intense. Therefore, analysis of customer behavior for maximizing profit is becoming more and more important for online shopping companies.  In this study, we propose CNN model of Heterogeneous Information Integration using CNN as a way to improve the predictive power of customer behavior in online shopping enterprises. In order to propose a model that optimizes the performance, which is a model that learns from the convolution neural network of the multi-layer perceptron structure by combining structured and unstructured information, this model uses heterogeneous information integration, unstructured information vector conversion, ‘multi-layer perceptron design, and evaluate the performance of each architecture, and confirm the proposed model based on the results. In addition, the target variables for predicting customer behavior are defined as six binary classification problems: re-purchaser, churn, frequent shopper, frequent refund shopper, high amount shopper, high discount shopper.  In order to verify the usefulness of the proposed model, we conducted experiments using actual data of domestic specific online shopping company. This experiment uses actual transactions, customers, and VOC data of specific online shopping company in Korea. Data extraction criteria are defined for 47,947 customers who registered at least one VOC in January 2011 (1 month). The customer profiles of these customers, as well as a total of 19 months of trading data from September 2010 to March 2012, and VOCs posted for a month are used. The experiment of this study is divided into two stages. In the first step, we evaluate three architectures that affect the performance of the proposed model and select optimal parameters. We evaluate the performance with the proposed model.  Experimental results show that the proposed model, which combines both structured and unstructured information, is superior compared to NBC(Naïve Bayes classification), SVM(Support vector machine), and ANN(Artificial neural network). Therefore, it is significant that the use of unstructured information contributes to predict customer behavior, and that CNN can be applied to solve business problems as well as image recognition and natural language processing problems. It can be confirmed through experiments that CNN is more effective in understanding and interpreting the meaning of context in text VOC data. And it is significant that the empirical research based on the actual data of the e-commerce company can extract very meaningful information from the VOC data written in the text format directly by the customer in the prediction of the customer behavior. Finally, through various experiments, it is possible to say that the proposed model"
금속 표면의 결함 검출을 위한 영역 기반 CNN 기법 비교,2018,"['Defects detection', 'Metal surface', 'Convolution neural network', 'Faster R-CNN', 'YOLOv2']",국문 초록 정보 없음,"A machine vision based industrial inspection includes defects detection and classification. Fast inspection is a fundamental problem for many applications of real-time vision systems. It requires little computation time and localizing defects robustly with high accuracy. Deep learning technique have been known not to be suitable for real-time applications. Recently a couple of fast region-based CNN algorithms for object detection are introduced, such as Faster R-CNN, and YOLOv2. We apply these methods for an industrial inspection problem. Three CNN based detection algorithms, VOV based CNN, Faster R-CNN, and YOLOv2, are experimented for defect detection on metal surface. The results for inspection time and various performance indices are compared and analysed."
초음파 영상에서 질병 추출을 위한Keras 기반의 CNN 모델,2018,"['CNN', '간이미지', '의료초음파', '이미지분류', '케라스', 'Liver Image', 'Medical Ultrasonography', 'Image classification', 'Keras']",국문 초록 정보 없음,"CNN algorithm is a deep learning algorithm which is mainly used for image recognition.In recent years, image classification using CNN algorithm has been used in many fields because of its improved accuracy and it is not easy to read disease using ultrasound image unless it is a skilled expert in medical image field. In this paper, we use CNN algorithm to predict the liver lesion by classifying the images according to the diseases shown in the liver ultrasound images. The liver ultrasound image was preprocessed through grayscale and size reordering and then added to the CNN algorithm. In this paper, we study the overfitting problem by learning CNN structure with 3 convolution layers and classify the images with accuracy of 92% of test image and 59% of test image."
Effects of Hyper-parameters and Dataset on CNN Training,2018,"['Hyper-parameter', 'CNN', 'classification accuracy', 'weight factor', 'neural network training']",국문 초록 정보 없음,"The purpose of training a convolutional neural network (CNN) is to obtain weight factors that give high classification accuracies. The initial values of hyper-parameters affect the training results, and it is important to train a CNN with a suitable hyper-parameter set of a learning rate, a batch size, the initialization of weight factors, and an optimizer. We investigate the effects of a single hyper-parameter while others are fixed in order to obtain a hyper-parameter set that gives higher classification accuracies and requires shorter training time using a proposed VGG-like CNN for training since the VGG is widely used. The CNN is trained for four datasets of CIFAR10, CIFAR100, GTSRB and DSDL-DB. The effects of the normalization and the data transformation for datasets are also investigated, and a training scheme using merged datasets is proposed."
진화연산 기반 CNN 필터 축소,2018,"['Convolutional neural network', 'Filter reduction', 'Genetic algorithm']",국문 초록 정보 없음,"A convolutional neural network (CNN), which is one of the deep learning models, has been very successful in a variety of computer vision tasks. Filters of a CNN are automatically generated, however, they can be further optimized since there exist the possibility of existing redundant and less important features. Therefore, the aim of this paper is a filter reduction to accelerate and compress CNN models. Evolutionary algorithms is adopted to remove the unnecessary filters in order to minimize the parameters of CNN networks while maintaining a good performance of classification. We demonstrate the proposed filter reduction methods performing experiments on CIFAR10 data based on the classification performance. The comparison for three approaches is analysed and the outlook for the potential next steps is suggested."
CNN 기반 토마토의 흰가루병 발병 인식 방법,2018,"['smart greenhouse', 'convolution neural network', 'tomato powdery mildew recognition']",국문 초록 정보 없음,"The smart greenhouse, which is equipped with an autonomous environmental control system, is attracting attention as an effective alternative to solve problems in the modern agricultural industry. Although the smart greenhouse enables the monitoring of environmental information of the greenhouse, the system to directly capture the state of the crops is required to enhance the productivity of the smart greenhouse. In this paper, we propose an image recognition algorithm based on the convolution neural network (CNN) to detect an outbreak of powdery mildew on tomatoes. We propose a method to artificially generate the powdery mildew images using an image fusion technique to prepare various forms of CNN learning data. The artificial powdery mildew images are produced in three steps: mildew image extraction, transformation, and overlapping. The CNN is learned using these artificial images, and we test the recognition performance of the CNN using real tomato leap images captured in the greenhouse. The experimental results show that the proposed image recognition algorithm presents a recognition rate of 93.02% for 43 test images."
Effects of Hyper-parameters and Dataset on CNN Training,2018,"['Hyper-parameter', 'CNN', 'classification accuracy', 'weight factor', 'neural network training']",국문 초록 정보 없음,"The purpose of training a convolutional neural network (CNN) is to obtain weight factors that give high classification accuracies. The initial values of hyper-parameters affect the training results, and it is important to train a CNN with a suitable hyper-parameter set of a learning rate, a batch size, the initialization of weight factors, and an optimizer. We investigate the effects of a single hyper-parameter while others are fixed in order to obtain a hyper-parameter set that gives higher classification accuracies and requires shorter training time using a proposed VGG-like CNN for training since the VGG is widely used. The CNN is trained for four datasets of CIFAR10, CIFAR100, GTSRB and DSDL-DB. The effects of the normalization and the data transformation for datasets are also investigated, and a training scheme using merged datasets is proposed."
Effects of Hyper-parameters and Dataset on CNN Training,2018,"['Hyper-parameter', 'CNN', 'classification accuracy', 'weight factor', 'neural network training']",국문 초록 정보 없음,"The purpose of training a convolutional neural network (CNN) is to obtain weight factors that give high classification accuracies. The initial values of hyper-parameters affect the training results, and it is important to train a CNN with a suitable hyper-parameter set of a learning rate, a batch size, the initialization of weight factors, and an optimizer. We investigate the effects of a single hyper-parameter while others are fixed in order to obtain a hyper-parameter set that gives higher classification accuracies and requires shorter training time using a proposed VGG-like CNN for training since the VGG is widely used. The CNN is trained for four datasets of CIFAR10, CIFAR100, GTSRB and DSDL-DB. The effects of the normalization and the data transformation for datasets are also investigated, and a training scheme using merged datasets is proposed."
Pedestrian detection based on faster R-CNN in nighttime by fusing deep convolutional features of successive images,2018,"['Pedestrian detection', 'Faster R-CNN', 'Nighttime image', 'Fusion of deep convolutional features']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Existing studies using visible-light cameras have mainly focused on methods of pedestrian detection during daytime. However, these studies found it difficult to detect pedestrians during nighttime with low external light. The NIR illuminator has limitations in terms of illumination angle and distance, and the illuminator's power needs to be adjusted depending on whether an object is near or distant. Although, thermal cameras were used for nighttime pedestrian detection, thermal cameras are currently expensive and thus difficult to install in many places. To solve these problems, attempts have been made to use visible-light cameras for nighttime pedestrian detection. However, most of these attempts considered an indoor environment where the distance to the object was short. This study proposes a method of pedestrian detection at nighttime using a visible-light camera and faster region-based convolutional neural network (R-CNN). In addition, as pedestrians cannot be reliably detected from a single nighttime image, we combined deep convolutional features in successive frames.</P> <P>Using Korea advanced institute of science and technology (KAIST) open database, we conducted experiments and observed that the proposed method performed better than the baseline methods at all times (day and night). In addition, through the experiments with national ICT Australia Ltd. (NICTA) open database, we confirm that the proposed method is effective for pedestrian detection at all times. Finally, we present theoretical grounds for the proposed fusion.</P>   <P><B>Hightlights</B></P>  <P> <UL> <LI>  CNN training with augmented data was found effective in improving detection accuracy. </LI> <LI>  Fusion of convolutional features in successive images enhanced detection accuracy. </LI> <LI>  Effectiveness of our method of fusing successive-frame features is theoretically proved. </LI> <LI>  Our analysis of complex faster R-CNN architecture helps other researchers for understanding. </LI> <LI>  We open the trained CNN model, algorithm, and generated images to other researchers. </LI> </UL> </P>"
Partitioning Compute Units in CNN Acceleration for Statistical Memory Traffic Shaping,2018,[],국문 초록 정보 없음,"<P>Convolutional Neural Networks (CNNs) have become the default choice for processing visual information, and the design complexity of CNNs has been steadily increasing to improve accuracy. To cope with the massive amount of computation needed for such complex CNNs, the latest solutions utilize blocking of an image over the available dimensions (e.g., horizontal, vertical, channel, and kernel) and batching of multiple input images to improve data reuse in the memory hierarchy. While there has been a large collection of works on maximizing data reuse, only a few studies have focused on the memory bottleneck problem caused by limited bandwidth. Bandwidth bottleneck can easily occur in CNN acceleration as CNN layers have different sizes with varying computation needs and as batching is typically performed over each layer of CNN for an ideal data reuse. In this case, the data transfer demand for a layer can be relatively low or high compared to the computation requirement of the layer, and therefore temporal fluctuations in memory access can be induced eventually causing bandwidth problems. In this paper, we first show that there exists a high degree of fluctuation in memory access to computation ratio depending on CNN layers and functions in the layer being processed by the compute units (cores), where the compute units are tightly synchronized to maximize data reuse. Then we propose a strategy of partitioning the compute units where the cores within each partition process a batch of input data in a synchronous manner to maximize data reuse but different partitions run asynchronously. Because the partitions stay asynchronous and typically process different CNN layers at any given moment, the memory access traffic sizes of the partitions become statistically shuffled. Thus, the partitioning of compute units and asynchronous use of them make the total memory access traffic size be smoothened over time, and the degree of partitioning determines a tradeoff between data reuse efficiency and memory bandwidth utilization efficiency. We call this smoothing statistical memory traffic shaping, and we show that it can lead to 8.0 percent of performance gain on a commercial 64-core processor when running ResNet-50.</P>"
Low Resolution Rate Face Recognition Based on Multi-scale CNN,2018,"['Face Recognition', 'Intelligent Video Analysis Method', 'CNN', 'Multi-scale CNN']",국문 초록 정보 없음,"For the problem that the face image of surveillance video cannot be accurately identified due to the low resolution, this paper proposes a low resolution face recognition solution based on convolutional neural network model. Convolutional Neural Networks (CNN) model for multi-scale input The CNN model for multi-scale input is an improvement over the existing ""two-step method"" in which low-resolution images are up-sampled using a simple bi-cubic interpolation method. Then, the up sampled image and the high-resolution image are mixed as a model training sample. The CNN model learns the common feature space of the high- and low-resolution images, and then measures the feature similarity through the cosine distance. Finally, the recognition result is given. The experiments on the CMU PIE and Extended Yale B datasets show that the accuracy of the model is better than other comparison methods. Compared"
Low Resolution Rate Face Recognition Based on Multi-scale CNN,2018,"['Face Recognition', 'Intelligent Video Analysis Method', 'CNN', 'Multi-scale CNN']",국문 초록 정보 없음,"For the problem that the face image of surveillance video cannot be accurately identified due to the low resolution, this paper proposes a low resolution face recognition solution based on convolutional neural network model. Convolutional Neural Networks (CNN) model for multi-scale input The CNN model for multi-scale input is an improvement over the existing ""two-step method"" in which low-resolution images are up-sampled using a simple bi-cubic interpolation method. Then, the up sampled image and the high-resolution image are mixed as a model training sample. The CNN model learns the common feature space of the high- and low-resolution images, and then measures the feature similarity through the cosine distance. Finally, the recognition result is given. The experiments on the CMU PIE and Extended Yale B datasets show that the accuracy of the model is better than other comparison methods. Compared with the CMDA_BGE algorithm with the highest recognition rate, the accuracy rate is 2.5%~9.9%."
LGP-FL과 해마 구조를 이용한 H-CNN 기반 보행자 검출에 대한 연구,2018,"['pedestrian detection', 'object detection', 'LGP', 'CNN', 'hippocampal structure']",국문 초록 정보 없음,"Recently, autonomous vehicles have been actively studied. Pedestrian detection and recognition technology is important in autonomous vehicles. Pedestrian detection using CNN(Convolutional Neural Netwrok), which is mainly used recently, generally shows good performance, but there is a performance degradation depending on the environment of the image. In this paper, we propose a pedestrian detection system applying long-term memory structure of hippocampal neural network based on CNN network with LGP-FL (Local Gradient Pattern-Feature Layer) added. First, change the input image to a size of 227x227. Then, the feature is extracted through a total of 5 layers of convolution layer. In the process, LGP-FL adds the LGP feature pattern and stores the high-frequency pattern in the long-term memory. In the detection process, it is possible to detect the pedestrian more accurately by detecting using the LGP feature pattern information robust to brightness and color change. A comparison of the existing methods and the proposed method confirmed the increase of detection rate of about 1~4%."
Power Signal Classification with Combinational Spectrogram-based CNN for Embedded System Health Management,2018,"['Power signal classification', 'Convolutional neural networks', 'Combinational spectrogram']",국문 초록 정보 없음,"This paper addresses the problem of the embedded system health management for high-speed flight systems. Especially, we focus the variation of power signals used in embedded systems because the electrical degeneration is strongly related to the power levels and frequencies. If the power signals can be classified into normal status and abnormal status, the sudden electrical degeneration of embedded systems can be successfully detected. The conventional threshold-based classification which has been used in aerospace and defense fields cannot find out the hidden anomaly within the thresholds. This paper proposes an accurate power signal classification method using combinational spectrogram-based convolutional neural networks (CNN). The power signals are combined with eigenvalues and converted to spectrogram which can analyze them on time and frequency domain simultaneously. Then, the CNN for power signal classification is trained and validated using the combinational spectrograms. Inference results showed that the proposed method can accurately classify the power signals into normal status and abnormal status."
Recognition of Car Manufacturers using Faster R-CNN and Perspective Transformation,2018,"['Car Logo Detection', 'Faster R-CNN', 'Perspective Transformation', 'Vehicle Manufacturer Detection']",국문 초록 정보 없음,"In this paper, we report detection and recognition of vehicle logo from images captured from street CCTV. Image data includes both the front and rear view of the vehicles. The proposed method is a two-step process which combines image preprocessing and faster region-based convolutional neural network (R-CNN) for logo recognition. Without preprocessing, faster R-CNN accuracy is high only if the image quality is good. The proposed system is focusing on street CCTV camera where image quality is different from a front facing camera. Using perspective transformation the top view images are transformed into front view images. In this system, the detection and accuracy are much higher as compared to the existing algorithm. As a result of the experiment, on day data the detection and recognition rate is improved by 2% and night data, detection rate improved by 14%."
주행 환경 다중 객체 검출을 위한 실시간 CNN 모델,2018,"['Autonomous driving(자율주행)', 'Real-time driving scene understanding(실시간 주행 환경 인식)', 'Multi-object detection(다중 객체 검출)', 'Deep learning(심층 학습)', 'CNN(Convolutional Neural Network)']",국문 초록 정보 없음,"Real-time driving scene understanding system have been received more attention from may autonomous driving research community as following the advent of deep learning technology. In this paper, we proposed real-time multi-object detection model based on Convolution Neural Network(CNN) deep learning model. In order to reduce computational load for multi-scale object detection, we consider Rezoom layer rather than conventional methods which are based on muti-scale template(Anchors) and feature approach. Moreover, in order to enhance of detection performance for occluded/small size object in driving road scene, we consider simple aggregation layer which can preserve small receptive field feature information in deep CNN feature domain. Experimental results for KITTI datasets show that the proposed model can successfully detect multi-objects in road driving scene."
CNN 소실점 검출을 이용한 차선 검출,2018,"['lane detection', 'deep learning', 'convolutional neural networks', 'transfer learning']",국문 초록 정보 없음,"Lane detection is essential in autonomous navigation. Conventional algorithms use hand crafted features which produce difficulties because of diverse image variations from illumination variations, occlusions and shadows. Recently, deep learning based approaches have provided more robust results. In this paper, we present an algorithm for the robust detection of lanes by finding vanishing points with convolutional neural networks. We use two modified CNN architectures, where the final output layer consists of four elements. The epipole and the angles of the current driving lane each have two elements. Experiments are performed by using two modified structures of the NVIDIA end-to-end model[9] and the ResNet-50 model[10]."
Faster R-CNN을 이용한 영상 기반 신호등 인식 시스템 연구,2018,"['Real-Time Image Recognition(실시간 영상 인식)', 'Faster R-CNN(페스트 알씨엔엔)', 'Autonomous Driving(자율 주행 자동차)', 'Small Region Proposal Network(소규모 구역 제안 네트워크)', 'Traffic Light(신호등)', 'Artificial Intelligence (인공지능)']",본 연구에서는 Faster R-CNN 기반 뉴럴 네트워크를 활용한 주행 전방 영상 내 신호등 검출 알고리즘을 제안한다. 이때 정확성과 실시간적 물체 검출 성능을 보장하기 위하여 전방 영상 내 검출 대상이 위치할 관심 영역 설정 및 네트워크 구조의 최적화를 통하여 영상 내 작은 영역으로 나타나는 신호등을 효율적으로 검출할 수 있도록 설계하였다. 또한 해외의 학습 데이터와 현지 상황에서의 학습 데이터를 함께 활용하기 위한 데이터 전처리를 수행하여 보다 효율적이고 높은 성능을 확보할 수 있도록 하였다. 본 연구에서 제안하는 알고리즘은 실차 주행 기반으로 취득된 영상으로부터 실험적으로 그 성능을 확인하였다.,다국어 초록 정보 없음
표면근전도 신호를 활용한 CNN 기반 한국 지화숫자 인식을 위한 아래팔 근육과 전극 위치에 관한 연구,2018,"['surface electromyography', 'forearm', 'multi finger gesture recognition', 'electrode placements', 'Korean multi finger number']","표면근전도(sEMG) 신호의 응용은 초기에는 단순히 근육 활성도의 유무를 판별하여 On/Off 의 스위치 기능으로 많이 사용되어 왔으나, 표면근전도 신호처리와 알고리즘의 발달로 휠체어의 방향 제어는 물론 수화를 인식하는 분야까지 확대되었다. 청각 장애인들의 언어 소통을 위한 중요한 수단인 수화나 지화는 미학습자와는 소통의 어려움이 존재해왔으며, 이러한 어려움을 해결하기 위해 수화나 지화를 인식하는 기술에 대한 연구가 지속적으로 수행되어 왔다. 최근에는, 수화나 지화 시연시에 활성화되는 근육의 신호를 활용하여 수화나 지화를 인식하는 방법이 중국 숫자지화 중심으로 적용되고 있는 추세이다. 하지만, 수화나 지화는 일반 음성언어와 마찬가지로 중국 숫자지화와 한국 숫자지화가 다르므로, 중국 숫자지화 시연시에 관여하는 근육이 한국 숫자지화 시연시에는 관여하지 않을 수가 있어, 인식률이 현저히 떨어질 수 있다. 그러므로 한국 숫자지화 시연시에 활성화되는 근육의 선정은 표면근전도 신호에 기반한 한국 숫자지화 인식률에 매우 중요하다. 하지만, 표면근전도 신호에 기반한 한국 숫자지화 인식에 대한 연구는 문헌에서 드물다. 본 연구에서는 표면근전도 신호를 활용한 한국수화 또는 한국지화의 인식에 관한 초기 연구로서, 한국 숫자지화를 시연시에 관여하는 아래팔근육을 제안하고 실험을 통하여 검증하기 위해 숫자 영(0)부터 다섯(5)의 여섯 가지 한국 숫자지화를 대상으로 인식하는 연구를 수행하였다. 이를 위해, 표면근전도 신호를 활용한 CNN 기반 지화인식 방법에 적용하여 여섯 가지 한국 숫자지화에 대하여 100%의 인식률을 확인함으로써, 여섯 가지 한국 숫자지화 인식을 위해 제안된 아래팔근육과 전극위치의 타당성을 검증하였다.","Surface electromyography (sEMG) is mainly used as an on/off switch in the early stage of the study and was then expanded to navigational control of powered-wheelchairs and recognition of sign language or finger gestures. There are difficulties in communication between people who know and do not know sign language; therefore, many efforts have been made to recognize sign language or finger gestures. Recently, use of sEMG signals to recognize sign language signals have been investigated; however, most studies of this topic conducted to date have focused on Chinese finger number gestures. Since sign language and finger gestures vary among regions, Korean- and Chinese-finger number gestures differ from each other. Accordingly, the recognition performance of Korean finger number gestures based on sEMG signals can be severely degraded if the same muscles are specified as for Chinese finger number gestures. However, few studies of Korean finger number gestures based on sEMG signals have been conducted. Thus, this study was conducted to identify potential forearm muscles from which to collect sEMG signals for Korean finger number gestures. To accomplish this, six Korean finger number gestures from number zero to five were investigated to determine the usefulness of the proposed muscles and electrode placements by showing that CNN technique based on sEMG signal after sufficient learning recognizes six Korean finger number gestures in accuracy of 100%."
A Study of Image Classification using HMC Method Applying CNN Ensemble in the Infrared Image,2018,"['Infrared image', 'Convolutional neural network', 'Machine learning']",국문 초록 정보 없음,"In the marine environment, many clutters have similar features with the marine targets due to the diverse changes of the air temperature, water temperature, various weather and seasons. Also, the clutters in the ground environment have similar features due to the same reason. In this paper, we proposed a robust Hybrid Machine Character (HMC) method to classify the targets from the clutters in the infrared images for the various environments. The proposed HMC method adopts human’s multiple personality utilization and the CNN ensemble method to classify the targets in the ground and marine environments. This method uses an advantage of the each environmental training model. Experimental results demonstrate that the proposed method has better success rate to classify the targets and clutters than previously proposed CNN classification method."
A Study of Image Classification using HMC Method Applying CNN Ensemble in the Infrared Image,2018,"['Infrared image', 'Convolutional neural network', 'Machine learning']",국문 초록 정보 없음,"In the marine environment, many clutters have similar features with the marine targets due to the diverse changes of the air temperature, water temperature, various weather and seasons. Also, the clutters in the ground environment have similar features due to the same reason. In this paper, we proposed a robust Hybrid Machine Character (HMC) method to classify the targets from the clutters in the infrared images for the various environments. The proposed HMC method adopts human's multiple personality utilization and the CNN ensemble method to classify the targets in the ground and marine environments. This method uses an advantage of the each environmental training model. Experimental results demonstrate that the proposed method has better success rate to classify the targets and clutters than previously proposed CNN classification method."
CNN 기반 동영상의 프레임 삭제 검출 기법,2018,"['Video Forensics', 'Frame Deletion', 'HEVC', 'CNN', 'Coding Pattern']",국문 초록 정보 없음,"In this paper, we introduce a technique to detect the video forgery by using the regularity that occurs in the video compression process. The proposed method uses the hierarchical regularity lost by the video double compression and the frame deletion. In order to extract such irregularities, the depth information of CU and TU, which are basic units of HEVC, is used. For improving performance, we make a depth map of CU and TU using local information, and then create input data by grouping them in GoP units. We made a decision whether or not the video is double-compressed and forged by using a general three-dimensional convolutional neural network. Experimental results show that it is more effective to detect whether or not the video is forged compared with the results using the existing machine learning algorithm."
CNN Model to Classify Malware Using Image Feature,2018,"['악성코드', '악성코드분류', 'CNN', '머신러닝', 'malware', 'malware classification', 'convolutional neural network', 'machine learning']","인터넷에 발생하는 악성코드는 매우 심각한 위협 요소이며, 악성코드를 이용한 공격이 전 세계적으로 전파되며 심지어 점점 더 지능적으로 변조되고 있다. 그러므로 악성코드를 정확하게 탐지 하는 방법이 중요하다. 지금까지 널리 알려진 악성코드 대응방법은 악성코드를 탐지하여 삭제하거나 혹은 치료한다고 알고 있다. 이러한 악성코드를 탐지하기 위하여 악성코드에 따른 분류를 하여야 한다. 악성코드를 잘 분류하는 것은 알려진 악성코드를 더 잘 탐지할 수 있다는 것과 같다. 기존 연구들을 보면 같은 카테고리에 속하는 악성코드는 치료방법이 비슷하게 보이는 경향이 있다는 것을 입증한다. 그리고 많은 새로운 악성코드들이 기존에 있던 악성코드로부터 만들어진다는 것을 증명한다. 따라서 악성코드를 종류에 따라서 분류하는 것은 탐지하는 것 못지않게 아주 중요한 작업이다. 그러므로 멀웨어 분류 기술이 절실히 요구된다. 본 논문에서는 주어진 종류에 따라 악성코드를 분류하기 위한 컨볼루션 인공신경망 모델을 구축한다. 이 모델은 9,500 개의 악성코드 데이터 셋을 25 개의 종류로 분류하는 실험에서 98%의 정확도를 보인다. 본 연구의 목적은 다음 목표로 더 많은 양의 악성코드 파일에 적용되며 더 높은 정확도를 보이는 것이다.","Malware programs are common threats in the information and technology society. It has been proven that a number of developed malwares cripples the victim’s computer as well as launching malicious attacks. Therefore, it is important to find a reasonable technical way to counter these attacks. Malware can be easily detected by checking whether a file has a malicious code inside the source code, if you detect a malicious code inside your content, then take an appropriate action by eliminating the threat. The first countermeasure to take is to delete the file or follow any other action defined by an Anti-malware software. After a file is infected, means it can be classified to its corresponding family based on its behavior in the infected system.. In this paper, we use Convolutional Neural Network to classify malware binaries using image features. Our work relies on the previously conducted research on malware visualization, whereby we used the dataset consisted of about 9,500 samples of 25 different malware familys. The built architecture achieved an accuracy of 98%."
CNN 기반의 소리 잡음에 강인한 돼지 호흡기 질병 탐지 및 식별 시스템,2018,"['porcine wasting diseases classification', 'sound analysis', 'convolution neural network']",국문 초록 정보 없음,"Failure to detect pig wasting disease in a timely and accurate manner in the commercial pig farm can be a serious factor in achieving efficient livestock management. In this paper, we propose a noise-robust porcine wasting diseases detection and classification method in piglet farm monitoring system using sound data. First, we extract a spectrogram of sound signals and convert it into noise-robust features by a convolutional neural network (CNN), and lastly, use the multi-layer perceptron (MLP) as an early anomaly detector and classifier. On the basis of the experimental results, we confirmed that the proposed method could detect and classify the porcine wasting diseases with acceptable accuracy even under noise-environmental conditions. In particular, as a result of comparing the discrimination performance of the proposed method in this research and the MFCC-SVM method, it was confirmed that the f-score was improved by 15.1%."
CNN 인공지능을 이용한 서울 지역의 PM<SUB>10</SUB> 예측 모델 개발,2018,"['인공지능', 'Convolutional Neural Network (CNN)', '서울', 'PM&lt', 'SUB&gt', '10&lt', '/SUB&gt', '\ue034\ue03d']",국문 초록 정보 없음,다국어 초록 정보 없음
효율적 메모리 관리를 통한 모바일 CNN 가속기의 최적화,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Faster R-CNN을 이용한 고속도로 영상 속 차량 추적,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Convolutional Neural Network(CNN)을 이용한 회전 변조 시준기(RMC) 영상화 알고리즘,2018,[],국문 초록 정보 없음,"Rotating Modulation Collimators(RMC) is a indirect imaging device for estimating radiation sources. A new RMC image reconstruction algorithm proposed in this paper uses Convolutional Neural Network (CNN). it solves RMC imaging by simplifying reconstruction into classification to focus on accurately detecting the location of the source. In addition, the simulation show that the proposed algorithm has higher improved results compared to the baseline algorithm."
Speech-Act Analysis System Based on Dialogue Level RNN-CNN Effective on the Exposure Bias Problem,2018,"['화행 분석', 'RNN-CNN', '노출 편향 문제', '딥 러닝', 'speech-act analysis', 'exposure bias problem', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
Recognition of Car Manufacturers using Faster R-CNN and Perspective Transformation,2018,"['Car Logo Detection', 'Faster R-CNN', 'Perspective Transformation', 'Vehicle Manufacturer Detection']",국문 초록 정보 없음,다국어 초록 정보 없음
실생활 음향 데이터 기반 이중 CNN 구조를 특징으로 하는 음향 이벤트 인식 알고리즘,2018,"['Machine learning', 'Deep learning', 'Audio signal processing', 'Sound event detection', 'Dataset']",국문 초록 정보 없음,"Sound event detection is one of the research areas to model human auditory cognitive characteristics by recognizing events in an environment with multiple acoustic events and determining the onset and offset time for each event. DCASE, a research group on acoustic scene classification and sound event detection, is proceeding challenges to encourage participation of researchers and to activate sound event detection research. However, the size of the dataset provided by the DCASE Challenge is relatively small compared to ImageNet, which is a representative dataset for visual object recognition, and there are not many open sources for the acoustic dataset. In this study, the sound events that can occur in indoor and outdoor are collected on a larger scale and annotated for dataset construction. Furthermore, to improve the performance of the sound event detection task, we developed a dual CNN structured sound event detection system by adding a supplementary neural network to a convolutional neural network to determine the presence of sound events. Finally, we conducted a comparative experiment with both baseline systems of the DCASE 2016 and 2017."
Detection of Abnormal Shadows on Temporal Subtraction Images Based on Multi-phase CNN,2018,"['Computer Aided Diagnosis', 'Temporal Subtraction Technique', 'Deep Leaning']",국문 초록 정보 없음,"Recently, visual screening based on CT images become useful tools in the medical fields. However, due to the large number of images and the complexity of the image processing algorithms, image processing technique for the high screening quality is still required. To overcome this problem, some computer aided diagnosis (CAD) algorithms are proposed. Cancer is a leading cause of death both in Japan and worldwide. Detection of cancer region in CT images is the most important task to early detection and early treatment. We have designed and developed a framework combining machine learning based on multi-phase convolutional neural networks (CNN) and temporal subtraction techniques based on non-rigid image registration algorithm. Our main classification method can be built into three main steps; i) preprocessing for image segmentation, ii) image matching for registration, and iii) classification of abnormal regions based on machine learning algorithms. We performed our proposed technique to 25 thoracic MDCT sets and obtained true positive rates of 93.55%, false positive rates of 10.93 /case."
도심 교차로 주행환경에서 야간 및 기후 악조건 주행환경에서 열화상 영상을 이용한 객체 인지를 위한 CNN 구조의 비교,2018,"['Night vision(나이트비전)', 'Object recognition(객체인식)', 'Object classification(객체분류)', 'Deep Learning (딥러닝)', 'CNN(Convolutional Neural Network)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 자동차 로고 인식 모델 구현,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 알고리즘을 이용한 음장 예측 시스템 연구,2018,"['Circular baffled piston(원형배플피스톤)', 'Cross-spectrum(상호스펙트럼)', 'Convolution Neural Network(합성곱신경망)', 'Cepstrum(캡스트럼)']",국문 초록 정보 없음,다국어 초록 정보 없음
CNN(Convolutional Neural Network)을 이용한 콘크리트 포장 표면결함 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 네트워크 침해 탐지 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN based Factory Lane Marker Recognition for Indoor Path tracking of Automated Guided Vehicle,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 을 이용한 자동변조구분,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 구조 얼굴 식별의 정확도 향상을 위한 최적화,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN(Convolution Neural Network) 기반의 심혈관질환 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 암세포 현미경 이미지 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반 HEVC 압축된 동영상의 삭제 검출 기법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 구조의 Hyper-parameter 를 조정한 자율주행의 성능 개선,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CNN 기반의 VVC 인-루프 필터 설계,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
LGP-PL 기반 CNN 학습 알고리즘을 이용한 얼굴 유사도 분석에 관한 연구,2018,"['Face Recognation', 'Convolutional Neural Network', 'Local Gradient Pattern']",국문 초록 정보 없음,다국어 초록 정보 없음
음향신호를 활용한 CNN 기반 불량 모터 분류기 개발,2018,"['Defective motor classification', 'Convolutional neural network', 'Acoustic signal']",국문 초록 정보 없음,다국어 초록 정보 없음
VOC를 활용한 CNN 기반 전자상거래 이진 고객 행위 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
VOC를 활용한 CNN 기반 전자상거래 이진 고객 행위 예측,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Clothing Style Classificaion Using CNN (Convolutional Neural Network) For Recycled Clothing In Africa,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
모바일 시스템을 위한 CNN 딥 러닝 가속화 알고리즘,2018,"['deep learning', 'convolutional neural network', 'pruning', 'low-rank approximation']",국문 초록 정보 없음,"A mobile system with limited computing and storage capacity mainly processes the training and inference of deep learning in a data center. Therefore, it is difficult for a mobile system to provide private artificial intelligence services, and users may be reluctant to transfer personal information to data centers. Therefore, this paper proposes a deep learning acceleration algorithm for convolutional neural network where a mobile system enables learning and inference itself. The proposed algorithm efficiently reduces the size of the convolutional neural network by a low-rank approximation method that compacts the information of the neural network into some weights, and a pruning method that removes non-critical weights. Experimental results show that the proposed algorithm achieves the speed of inference 1.65 times faster, requires the number of fine-tune fewer 1.5 times, and reduces the memory capacity for storing weights 2 times less than the conventional prunning algorithm."
SIMD 병렬화를 활용한 CNN 가속화,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
스마트 팜을 위한 CNN 기반 과일 분류,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
심음 데이터 분할에 따른 CNN 과 MFCC 를 통한 심장병 진단 및 예측 결과 비교 연구,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
"[미국] 백악관 출입증 박탈당한 CNN 기자, 그리고 언론의 자유",2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
두 개의 이종 CNN 융합을 이용한 차선 검출,2018,"['Lane Detection', 'Deep Learning', 'Convolutional Neural Networks']",국문 초록 정보 없음,다국어 초록 정보 없음
Convolutional Neural Networks(CNN)를 이용한 실내 위치 측정 시스템,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
비가청 음향 신호 기반의 CNN 을 활용한 멀티 포인트 제스처 인식,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Pyramid pooling을 이용한 CNN 기반의 Human Parsing 기법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
후방 보행자 보호를 위한 어안 카메라 영상에서의 CNN 기반 보행자 검출기 성능 분석,2018,"['Pedestrian detection(보행자 검출)', 'Fisheye camera(어안 카메라)', 'Convolutional Neural Network (컨볼루션신경망)']",국문 초록 정보 없음,다국어 초록 정보 없음
꽃 이미지 분류를 위한 텐서플로우 기반의 CNN 설계,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
엣지 디텍션 필터 적용 병렬 CNN 구조를 통한 단일 이미지 초해상도 성능 향상,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Pruning Method Using Correlation of Weight Changes and Weight Magnitudes in CNN,2018,"['Convolutional neural networks', 'Pruning weights', 'Weight correlation', 'Weight']",국문 초록 정보 없음,"Very complex deep learning models need to be compressed to be memory and cost effective, especially for applications on a mobile platform. We propose a new method of selecting weights to prune to compress convolutional neural networks. To select unimportant weights and get the best result, we combine typical weight magnitude pruning method with our method, which evaluates correlation coefficients of weights to measure the strength of a relationship between weight magnitudes and weight changes through the iterations. In the experimental section, we show our result of pruning 94% of weights in LeNet-5 without significant accuracy loss."
Tracking by Detection of Multiple Faces using SSD and CNN Features,2018,"['Image Processing', 'Human face tracking', 'Active Appearance Model']",국문 초록 정보 없음,"Multi-tracking of general objects and specific faces is an important topic in the field of computer vision applicable to many branches of industry such as biometrics, security, etc. The rapid development of deep neural networks has resulted in a dramatic improvement in face recognition and object detection problems, which helps improve the multiple-face tracking techniques exploiting the tracking-by-detection method. Our proposed method uses face detection trained with a head dataset to resolve the face deformation problem in the tracking process. Further, we use robust face features extracted from the deep face recognition network to match the tracklets with tracking faces using Hungarian matching method. We achieved promising results regarding the usage of deep face features and head detection in a face tracking benchmark."
Tracking by Detection of Multiple Faces using SSD and CNN Features,2018,"['Image Processing', 'Human face tracking', 'Active Appearance Model']",국문 초록 정보 없음,"Multi-tracking of general objects and specific faces is an important topic in the field of computer vision applicable to many branches of industry such as biometrics, security, etc. The rapid development of deep neural networks has resulted in a dramatic improvement in face recognition and object detection problems, which helps improve the multiple-face tracking techniques exploiting the tracking-by-detection method. Our proposed method uses face detection trained with a head dataset to resolve the face deformation problem in the tracking process. Further, we use robust face features extracted from the deep face recognition network to match the tracklets with tracking faces using Hungarian matching method. We achieved promising results regarding the usage of deep face features and head detection in a face tracking benchmark."
Facial expression recognition using feature additive pooling and progressive fine-tuning of CNN,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Alzheimer’s disease detection from Brain MRI using Feature extraction from CNN network and classification by KNN,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
CT 데이터와 레이저 스캔 데이터의 초기 정합을 위한 CNN(Convolutional Neural Network)기반의 분리 라인 검출 기법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
Pixel-Label-Based Segmentation of Cross-Sectional Brain MRI Using Simplified SegNet Architecture-Based CNN,2018,[],국문 초록 정보 없음,"<P>Using deep neural networks for segmenting an MRI image of heterogeneously distributed pixels into a specific class assigning a label to each pixel is the concept of the proposed approach. This approach facilitates the application of the segmentation process on a preprocessed MRI image, with a trained network to be utilized for other test images. As labels are considered expensive assets in supervised training, fewer training images and training labels are used to obtain optimal accuracy. To validate the performance of the proposed approach, an experiment is conducted on other test images (available in the same database) that are not part of the training; the obtained result is of good visual quality in terms of segmentation and quite similar to the ground truth image. The average computed Dice similarity index for the test images is approximately 0.8, whereas the Jaccard similarity measure is approximately 0.6, which is better compared to other methods. This implies that the proposed method can be used to obtain reference images almost similar to the segmented ground truth images.</P>"
A Real-time Citrus Segmentation and Detection System using Mask R-CNN,2018,"['과일 검출', '심층 콘볼루션 신경망', '빠른 학습', '실시간 성능', '자동 수확', 'Visual fruit detection', 'Deep convolutional neural network', 'Rapid training', 'Real-time performance', 'Auto-harvesting']",국문 초록 정보 없음,"In this paper, 200 photograph of citrus were collected and converted to 800x800. The areas of each citrus in the photograph were mask-labeled and stored in JSON format to generate a data set. The latest algorithm, Mask R-CNN, I constructed a reliable system to detect and divide citrus fruits. In order to solve the over-fitting problem due to small data sets, the data augmentation was used and the detection performance was as high as 0.97 with small data sets. In order to meet the farmers practical needs, I plan to develop a platform that can take photographs, label them with a mask first, and then train them immediately after doing additional mask labeling work."
Automatic Extraction of Abnormalities on Temporal CT Subtraction Images Using Sparse Coding and 3D-CNN,2018,"['Ground Glass Opacity', 'Temporal Subtraction Technique', 'Sparse Coding', '3D Convolutional Neural Network']",국문 초록 정보 없음,"In recent years, the proportion of deaths from cancer tends to increase in Japan, especially the number of deaths from lung cancer is increasing. CT device is effective for early detection of lung cancer. However, there is concern that an increase in burden on doctors will be caused by high performance of CT improving. Therefore, by presenting the “second opinion” by the CAD system, it reduces the burden on the doctor. In this paper, we develop a CAD system for automatic detection of lesion candidate regions such as lung nodules or ground glass opacity (GGO) from 3D CT images. Our proposed method consists of three steps. In the first step, lesion candidate regions are extracted using temporal subtraction technique. In the second step, the image is reconstructed by sparse coding for the extracted region. In the final step, 3D Convolutional Neural Network (3D-CNN) identification using reconstructed images is performed. We applied our method to 51 cases and True Positive rate (TP) of 79.81 % and False Positive rate (FP) of 37.65 % are obtained."
Cross-CNN 기반의 초해상도 기술,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
비전 점유센서를 위한 합성곱 신경망 기반 사람 인식,2018,"['occupancy sensor', 'camera', 'CNN', 'people recognition', 'tracking']",대부분의 건물 등에 설치된 점유센서는 PIR(pyroelectric infra-red)이 주로 활용되고 있다. 하지만 PIR은 온도 변화를 감지하는 기능 때문에 정지된 사람을 감지할 수 없는 단점이 있다. 최근 이 단점을 극복하기 위해 카메라 비전 센서의 연구가 진행되고 있다. 비전 센서는 객체 트랙킹을 통해 정지된 사람을 검출한다. 그러나 객체 트랙킹은 트랙커 표류가 발생하는 문제점이 있다. 본 논문에서는 정지 트랙커가 사람을 포함하는지의 여부를 판단하기 위하여 합성곱 신경망 기반 사람 인식 기법을 제안한다. 실험에서는 카메라로 획득한 영상에 제안 방법을 적용한 결과 약 88%의 정확도로 사람과 비사람이 분류가 되어 실제 점유센서에 활용이 가능하다는 것을 증명하였다.,다국어 초록 정보 없음
열화상 비디오에서 합성곱 신경망 기반의 실시간 인간 탐지,2018,[],국문 초록 정보 없음,"In this paper, we have proposed a Convolution Neural Network based human classification technique that efficiently operates in real time. Background subtraction is done using improved Running Gaussian Average to get the initial background model. Background updating is implemented using selectivity updating and random selection of background pixel from every new frame. Morphology is applied to extract ROIs from each frame. For classification, CNN model is trained and tested with our own dataset. For incorporating the model with real-time application, we neglect the nodes from computational graph that have no weights and convert other weights to constants. With this trained CNN model, ROI is classified as human or non-human in real-time. The processing time depends on number of ROI present in the frame. For our testing data, average processing time is 25fps."
카메라-라이다 센서 퓨전을 이용한 고장 허용 차량 검출,2018,"['Vehicle Detection(차량 검출)', 'Sensor Fusion(센서 융합)', 'CNN(컨볼루션 신경망)', 'Deep Learning(딥 러닝)', 'Autonomous Driving(자율 주행)']",국문 초록 정보 없음,다국어 초록 정보 없음
합성곱 신경망 기반의 무인이동체 trail navigation,2018,"['Trail Navigation(트레일 네비게이션)', 'Machine Learning(기계 학습)', 'Convolutional Neural Network(합성곱 신경망)', 'Vision-Based control(영상 기반 제어)']",국문 초록 정보 없음,다국어 초록 정보 없음
축약 합성곱 신경망 특징 벡터를 이용한 유사 상표 검색 방법,2018,[],국문 초록 정보 없음,다국어 초록 정보 없음
효과적인 입력변수 패턴 학습을 위한 시계열 그래프 기반합성곱 신경망 모형: 주식시장 예측에의 응용,2018,"['기술적 분석가', '딥러닝', '분류기', '주가지수 등락 예측', '합성곱 신경망', 'Classifier', 'Convolutional Neural Network', 'Deep Learning', 'Stock Price Fluctuation Prediction', 'Technical Analyst']","지난 10여 년간 딥러닝(Deep Learning)은 다양한 기계학습 알고리즘 중에서 많은 주목을 받아 왔다. 특히 이미지를 인식하고 분류하는데 효과적인 알고리즘으로 알려져 있는 합성곱 신경망(Convolutional Neural Network, CNN)은 여러 분야의 분류 및 예측 문제에 널리 응용되고 있다. 본 연구에서는 기계학습 연구에서 가장 어려운예측 문제 중 하나인 주식시장 예측에 합성곱 신경망을 적용하고자 한다. 구체적으로 본 연구에서는 그래프를입력값으로 사용하여 주식시장의 방향(상승 또는 하락)을 예측하는 이진분류기로써 합성곱 신경망을 적용하였다. 이는 그래프를 보고 주가지수가 오를 것인지 내릴 것인지에 대해 경향을 예측하는 이른바 기술적 분석가를모방하는 기계학습 알고리즘을 개발하는 과제라 할 수 있다. 본 연구는 크게 다음의 네 단계로 수행된다. 첫 번째 단계에서는 데이터 세트를 5일 단위로 나눈다. 두 번째 단계에서는 5일 단위로 나눈 데이터에 대하여 그래프를 만든다. 세 번째 단계에서는 이전 단계에서 생성된 그래프를 사용하여 학습용과 검증용 데이터 세트를 나누고 합성곱 신경망 분류기를 학습시킨다. 네 번째 단계에서는 검증용 데이터 세트를 사용하여 다른 분류 모형들과 성과를 비교한다. 제안한 모델의 유효성을 검증하기 위해 2009년 1월부터 2017년 2월까지의 약 8년간의KOSPI200 데이터 2,026건의 실험 데이터를 사용하였다. 실험 데이터 세트는 CCI, 모멘텀, ROC 등 한국 주식시장에서 사용하는 대표적인 기술지표 12개로 구성되었다. 결과적으로 실험 데이터 세트에 합성곱 신경망 알고리즘을 적용하였을 때 로지스틱회귀모형, 단일계층신경망, SVM과 비교하여 제안모형인 CNN이 통계적으로 유의한 수준의 예측 정확도를 나타냈다.","Over the past decade, deep learning has been in spotlight among various machine learning algorithms. In particular, CNN(Convolutional Neural Network), which is known as the effective solution for recognizing and classifying images or voices, has been popularly applied to classification and prediction problems. In this study, we investigate the way to apply CNN in business problem solving. Specifically, this study propose to apply CNN to stock market prediction, one of the most challenging tasks in the machine learning research. As mentioned, CNN has strength in interpreting images. Thus, the model proposed in this study adopts CNN as the binary classifier that predicts stock market direction (upward or downward) by using time series graphs as its inputs. That is, our proposal is to build a machine learning algorithm that mimics an experts called 'technical analysts' who examine the graph of past price movement, and predict future financial price movements.Our proposed model named 'CNN-FG(Convolutional Neural Network using Fluctuation Graph)' consists of five steps. In the first step, it divides the dataset into the intervals of 5 days. And then, it creates time series graphs for the divided dataset in step 2. The size of the image in which the graph is drawn is 40 (pixels) × 40 (pixels), and the graph of each independent variable was drawn using different colors.In step 3, the model converts the images into the matrices. Each image is converted into the combination of three matrices in order to express the value of the color using R(red), G(green), and B(blue) scale. In the next step, it splits the dataset of the graph images into training and validation datasets. We used 80% of the total dataset as the training dataset, and the remaining 20% as the validation dataset. And then, CNN classifiers are trained using the images of training dataset in the final step. Regarding the parameters of CNN-FG, we adopted two convolution filters (5 × 5 × 6 and 5 × 5 × 9) in the convolution layer. In the pooling layer, 2 × 2 max pooling filter was used. The numbers of the nodes in two hidden layers were set to, respectively, 900 and 32, and the number of the nodes in the output layer was set to 2(one is for the prediction of upward trend, and the other one is for downward trend). Activation functions for the convolution layer and the hidden layer were set to ReLU(Rectified Linear Unit), and one for the output layer set to Softmax function.To validate our model - CNN-FG, we applied it to the prediction of KOSPI200 for 2,026 days in eight years (from 2009 to 2016). To match the proportions of the two groups in the independent variable (i.e. tomorrow's stock market movement), we selected 1,950 samples by applying random sampling. Finally, we built the training dataset using 80% of the total dataset (1,560 samples), and the validation dataset using 20% (390 samples). The dependent variables of the experimental dataset included twelve technical indicators popularly been used in the previous studies. They include Stochastic %K, Stochastic %D, Momentum, ROC(rate of change), LW %R(Larry William's %R), A/D oscillator(accumulation/distribution oscillator), OSCP(price oscillator), CCI(commodity channel index), and so on. To confirm the superiority of CNN-FG, we compared its prediction accuracy with the ones of other classification models. Experimental results showed that CNN-FG outperforms LOGIT(logistic regression), ANN(artificial neural network), and SVM(support vector machine) with the statistical significance. These empirical results imply that converting time series business data into graphs and building CNN-based classification models using these graphs can be effective from the perspective of prediction accuracy. Thus, this paper sheds a light on how to apply deep learning techniques to the domain of business problem solving."
작물분류에서 기계학습 및 딥러닝 알고리즘의 분류 성능 평가: 하이퍼파라미터와 훈련자료 크기의 영향 분석,2018,"['Crop classification', 'Machine learning', 'Deep learning', 'Support vector machine', 'Convolutional neural network']",국문 초록 정보 없음,"The purpose of this study is to compare machine learning algorithm and deep learning algorithm in crop classification using multi-temporal remote sensing data. For this, impacts of machine learning and deep learning algorithms on (a) hyper-parameter and (2) training sample size were compared and analyzed for Haenam-gun, Korea and Illinois State, USA. In the comparison experiment, support vector machine (SVM) was applied as machine learning algorithm and convolutional neural network (CNN) was applied as deep learning algorithm. In particular, 2D-CNN considering 2-dimensional spatial information and 3D-CNN with extended time dimension from 2D-CNN were applied as CNN. As a result of the experiment, it was found that the hyper-parameter values of CNN, considering various hyper-parameter, defined in the two study areas were similar compared with SVM. Based on this result, although it takes much time to optimize the model in CNN, it is considered that it is possible to apply transfer learning that can extend optimized CNN model to other regions. Then, in the experiment results with various training sample size, the impact of that on CNN was larger than SVM. In particular, this impact was exaggerated in Illinois State with heterogeneous spatial patterns. In addition, the lowest classification performance of 3D-CNN was presented in Illinois State, which is considered to be due to over-fitting as complexity of the model. That is, the classification performance was relatively degraded due to heterogeneous patterns and noise effect of input data, although the training accuracy of 3D-CNN model was high. This results imply that a proper classification algorithms should be selected considering spatial characteristics of study areas. Also, a large amount of training samples is necessary to guarantee higher classification performance in CNN, particularly in 3D-CNN."
이진화된 컨벌루션 신경망의 효율적인 SIMD 구현,2018,"['인공 신경망', '컨벌루션 신경망', '이진화', '이미지 분류', '임베디드 시스템']","본 논문에서는 이진화된 컨벌루션 신경망 (Convolutional Neural Network; CNN)의 효율적인 구현을 제시한다. 이진화된 CNN은 기존 CNN에 이진화 과정을 추가하여 각각의 파라미터와 컨벌루션의 입력이 단일 비트로 표현될 수 있도록 변형한 것이다. 제안하는 구현에서는, 다수의 이진화된 파라미터들과 컨벌루션의 입력들을 하나의 워드로 묶어서 저장하고, CNN에서 연산 량 대부분을 차지하는 기존 컨벌루션을 이진화된 컨벌루션으로 대체하여, Bitwise XNOR-Bitcount으로 구현하였다. 이러한 SIMD 처리 방식의 구현은 CNN의 전체적인 메모리 요구량과 연산 량을 크게 감소시킬 수 있다. 실제로 LeNet-5와 ResNet-18을 대상으로 제안하는 구현은 분석 성능에서 기존의 결과와 비교하여 대등한 수준을 유지하면서도, 수행 시간을 기존 구현의 결과 대비 최대 89% 단축하고, 메모리 요구량은 기존 구현의 결과 대비 최대 95% 축소한다.","This paper presents the efficient implementation of the binarized convolutional neural network (CNN). The binarized CNN is designed by modifying the conventional CNN so as to include the binarization processes for the parameters and the activation outputs. In the proposed implementation, multiple binarized parameters and multiple activation outputs are packed into a single word, and the inner-products are calculated by performing simple bitwise XNOR followed by bit-counting operations. Owing to such SIMD optimization, both the overall number of the computations and the memory footprint are reduced significantly. LeNet-5 and ResNet-18 are implemented based on the proposed SIMD optimization. When compared to the straightforward implementation of the non-binarized CNN model, the proposed implementation shows the significant reduction in terms of the inference time and the memory footprint, while maintaining the analysis performance."
Wasserstein Center 손실을 이용한 스케치 기반 3차원 물체 검색,2018,"['Convolutional Neural Network', 'Image retrieval', 'Deep Learning', 'Sketch-based 3D object retrieval', '합성곱 신경망', '영상 검색', '딥 러닝', '스케치 기반 3차원 물체 검색']","스케치 기반 3차원 물체 검색은 다양한 3차원 물체를 사람이 손으로 그린 스케치를 질의(query)로 사용하여 물체를 편리하게 검색하는 방법이다. 본 논문에서는 스케치 기반 3차원 물체 검색을 위해 스케치 CNN(Convolutional Neural Network)과 Wasserstein CNN 모델에 Wasserstein Center 손실을 적용하여 물체의 검색 성공률을 향상시키는 새로운 방법을 제안한다. 제안된 Wasserstein Center 손실이란 각 물체의 클래스(category)의 중심을 학습하고, 동일한 클래스의 특징과 중심 간의 Wasserstein 거리가 작아지도록 만드는 방법이다. 이를 위하여 제안된 3차원 물체 검색은 다음의 단계로 수행된다. 첫 번째로, 3차원 물체의 특징은 3차원 물체를 여러 방향에서 촬영된 2차원 영상의 특징을 CNN을 이용하여 추출하고, 각 영상 특징의 Wasserstein 중심을 계산한다. 두 번째로, 스케치의 특징은 별도의 스케치 CNN을 이용하여 추출하였다. 마지막으로, 추출한 3차원 물체의 특징과 스케치의 특징을 본 논문에서 제안한 Wasserstein Center 손실을 이용하여 학습하고 스케치 기반의 3차원 물체 검색에 적용하였다. 본 논문에서 제안한 방법의 우수성을 입증하기 위하여 SHREC 13과 SHREC 14의 두 가지 벤치마크 데이터 집합을 이용하여 평가하였으며, 제안된 방법이 기존의 스케치 기반 검색방법들과 비교하여 모든 측정 기준에서 우수한 결과를 나타냄을 확인할 수 있었다.","Sketch-based 3D object retrieval is a convenient way to search for various 3D data using human-drawn sketches as query. In this paper, we propose a new method of using Sketch CNN, Wasserstein CNN and Wasserstein center loss for sketch-based 3D object search. Specifically, Wasserstein center loss is a method of learning the center of each object category and reducing the Wasserstein distance between center and features of the same category. To do this, the proposed 3D object retrieval is performed as follows. Firstly, Wasserstein CNN extracts 2D images taken from various directions of 3D object using CNN, and extracts features of 3D data by computing the Wasserstein barycenters of features of each image. Secondly, the features of the sketch are extracted using a separate Sketch CNN. Finally, we learn the features of the extracted 3D object and the features of the sketch using the proposed Wasserstein center loss. In order to demonstrate the superiority of the proposed method, we evaluated two sets of benchmark data sets, SHREC 13 and SHREC 14, and the proposed method shows better performance in all conventional metrics compared to the state of the art methods."
Comparison of Convolutional Neural Network Models for Image Super Resolution,2018,[],국문 초록 정보 없음,"Recently, a convolutional neural network (CNN) models at single image super-resolution have been very successful. Residual learning improves training stability and network performance in CNN. In this paper, we compare four convolutional neural network models for super-resolution (SR) to learn nonlinear mapping from low-resolution (LR) input image to high-resolution (HR) target image. Four models include general CNN model, global residual learning CNN model, local residual learning CNN model, and the CNN model with global and local residual learning. Experiment results show that the results are greatly affected by how skip connections are connected at the basic CNN network, and network trained with only global residual learning generates highest performance among four models at objective and subjective evaluations."
Infrared image super-resolution using auxiliary convolutional neural network and visible image under low-light conditions,2018,"['Near-infrared and visible images', 'Super-resolution', 'Convolutional neural networks', 'Low-light images']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Convolutional neural networks (CNN) have been successfully applied to visible image super-resolution (SR) methods. In this study, we propose a CNN-based SR algorithm for up-scaling near-infrared (NIR) images under low-light conditions, using corresponding visible images. Our algorithm first extracts high-frequency (HF) components from the up-scaled low-resolution (LR) NIR image and its corresponding high-resolution (HR) visible image, and then takes them as multiple inputs of the CNN. Next, the CNN outputs the HR HF component of the input NIR image. Finally, an HR NIR image is synthesized by adding the HR HF component to the up-scaled LR NIR image. The simulation results show that the proposed algorithm outperforms the state-of-the-art methods, in terms of both qualitative and quantitative aspects.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The proposed scheme focuses on SR of an NIR image, not a VIS image in a low-light environment. </LI> <LI>  The proposed scheme utilizes a VIS image, obtained at the same time as the NIR image, as auxiliary information. </LI> <LI>  The proposed scheme is based on a CNN structure that simultaneously receives the HF information of the NIR and VIS images. </LI> <LI>  The proposed scheme achieved a further performance improvement by employing an auxiliary CNN network. </LI> </UL> </P>"
Application of Convolutional Neural Network in the Diagnosis of Jaw Tumors,2018,"['Artificial Intelligence', 'Ameloblastoma', 'Odontogenic Tumors', 'Panoramic Radiography', 'Oral and Maxillofacial Surgeons']",국문 초록 정보 없음,"Objectives: Ameloblastomas and keratocystic odontogenic tumors (KCOTs) are important odontogenic tumors of the jaw.While their radiological findings are similar, the behaviors of these two types of tumors are different. Precise preoperative diagnosis of these tumors can help oral and maxillofacial surgeons plan appropriate treatment. In this study, we created a convolutional neural network (CNN) for the detection of ameloblastomas and KCOTs. Methods: Five hundred digital panoramic images of ameloblastomas and KCOTs were retrospectively collected from a hospital information system, whose patient information could not be identified, and preprocessed by inverse logarithm and histogram equalization. To overcome the imbalance of data entry, we focused our study on 2 tumors with equal distributions of input data. We implemented a transfer learning strategy to overcome the problem of limited patient data. Transfer learning used a 16-layer CNN (VGG-16) of the large sample dataset and was refined with our secondary training dataset comprising 400 images. A separate test dataset comprising 100 images was evaluated to compare the performance of CNN with diagnosis results produced by oral and maxillofacial specialists. Results: The sensitivity, specificity, accuracy, and diagnostic time were 81.8%, 83.3%, 83.0%, and 38 seconds, respectively, for the CNN. These values for the oral and maxillofacial specialist were 81.1%, 83.2%, 82.9%, and 23.1 minutes, respectively. Conclusions: Ameloblastomas and KCOTs could be detected based on digital panoramic radiographic images using CNN with accuracy comparable to that of manual diagnosis by oral maxillofacial specialists. These results demonstrate that CNN may aid in screening for ameloblastomas and KCOTs in a substantially shorter time."
딥 러닝 및 서포트 벡터 머신기반 센서 고장 검출 기법,2018,"['Sensor fault diagnosis', 'Support vector machine', 'Genetic algorithm', 'Multi-layer support vector machine', 'Convolution neural network', 'Ensemble']","최근 산업현장에서 기계의 자동화가 크게 가속화됨에 따라 자동화 기계의 관리 및 유지보수에 대한 중요성이갈수록 커지고 있다. 자동화 기계에 부착된 센서의 고장이 발생할 경우 기계가 오동작함으로써 공정라인 운용에 막대한 피해가 발생할 수 있다. 이를 막기 위해 센서의 상태를 모니터링하고 고장의 진단 및 분류를 하는 것이 필요하다.본 논문에서는 센서에서 발생하는 대표적인 고장 유형인 erratic fault, drift fault, hard-over fault, spike fault, stuck fault를 기계학습 알고리즘인 SVM과 CNN을 적용하여 검출하고 분류하였다. SVM의 학습 및 테스트를 위해 데이터샘플들로부터 시간영역 통계 특징들을 추출하고 최적의 특징을 찾기 위해 유전 알고리즘(genetic algorithm)을 적용하였다. Multi-class를 분류하기 위해 multi-layer SVM을 구성하여 센서 고장을 분류하였다. CNN에 대해서는 데이터샘플들을 사용하여 학습시키고 성능을 높이기 위해 앙상블 기법을 적용하였다. 시뮬레이션 결과를 통해 유전 알고리즘에 의해 선별된 특징들을 사용한 SVM의 분류 결과는 모든 특징이 사용된 SVM 분류기 보다는 성능이 향상되었으나전반적으로 CNN의 성능이 SVM보다 우수한 것을 확인할 수 있었다.","As machines have been automated in the field of industries in recent years, it is a paramount importance to manage and maintain the automation machines. When a fault occurs in sensors attached to the machine, the machine may malfunction and further, a huge damage will be caused in the process line. To prevent the situation, the fault of sensors should be monitored, diagnosed and classified in a proper way. In the paper, we propose a sensor fault detection scheme based on SVM and CNN to detect and classify typical sensor errors such as erratic, drift, hard-over, spike, and stuck faults. Time-domain statistical features are utilized for the learning and testing in the proposed scheme, and the genetic algorithm is utilized to select the subset of optimal features. To classify multiple sensor faults, a multi-layer SVM is utilized, and ensemble technique is used for CNN. As a result, the SVM that utilizes a subset of features selected by the genetic algorithm provides better performance than the SVM that utilizes all the features. However, the performance of CNN is superior to that of the SVM."
순환 합성곱 신경망를 이용한다채널 뇌파 분석의 간질 발작 탐지,2018,"['recurrent CNN', 'deep learning', 'epileptic seizure detection', 'EEG', 'load balancin and simulation']","본 논문에서는 뇌파 신호를 이용하여 환자의 경련을 감지하는 순환 CNN (Convolutional Neural Networks)을 제안한다.제안 된 방법은 뇌파 신호의 스펙트럼 특성과 전극의 위치를 보존하기 위해 영상으로 데이터를 매핑하여 처리하였다. 스펙트럼 전처리 과정을 거친 후 CNN에 입력하고 공간 및 시간 특성을 웨이블릿 변환(wavelet transform)없이 추출하여 발작을검출하였다. 여기에 사용된 보스턴 매사추세츠 공과 대학 (Boston Massachusetts Institute of Technology, CHB-MIT) 아동병원의 데이터셋 결과는 시간당 0.85의 민감도와 90 %의 위양성 비율 (FPR)을 보였다.","In this paper, we propose recurrent CNN(Convolutional Neural Networks) for detecting seizures among patients usingEEG signals. In the proposed method, data were mapped by image to preserve the spectral characteristics of the EEGsignal and the position of the electrode. After the spectral preprocessing, we input it into CNN and extracted the spatialand temporal features without wavelet transform.Results from the Children's Hospital of Boston Massachusetts Institute of Technology (CHB-MIT) dataset showed asensitivity of 90% and a false positive rate (FPR) of 0.85 per hour."
자동 표적 인식을 위한 이종 데이터 간 심층 전이 학습,2018,"['transfer learning', 'Automatic Target Recognition(ATR)', 'Heterogeneous sensor', 'InfraRed(IR)', 'Electro Optical(EO)']",국문 초록 정보 없음,"Recently, convolutional neural network(CNN) has shown remarkable performance in the field of computer vision thanks to the availability of large-scale dataset. With its extremely high-level feature extraction capabilities, CNN has been expected to resolve automatic target recognition(ATR) problems. Since the automatic tareget recogntion(ATR) data is military-purpose data, it has a limited amount of labeled data, which is a problem in learning deep CNN. Thus, previous ATR methods have tried to supplement the data using simulated data or other available data. However, most of them are homogeneous sensor data rather than heterogeneous sensor due to distinctly different charateristics even though they have abundant knowledge to train CNN. To address these issues, we propose a transfer learning-based framework that can teach ATR algorithms using heterogeneous sensor data. As verification data of the method, we use unlabeled infrared(IR) data as target data and labeled electro optical(EO) data as source data. The verification results demonstrate that the transfer learning scheme can train IR-ATR CNN to learn sensor invariant features of the target with labeled heterogeneous sensor data i.e. EO, which is not possible with normal supervised learning."
Study on Using Deep Learning Method to Realize The Emotion Linkage between The Gamer and His Avatar in Poker Game,2018,"['Psychological game', 'Emotion recognition', 'CNN', 'SVM', 'Emotion linkage technology']","다른 장르의 게임에 비해 포커는 게이머의 심리적 요소가 많은 영향을 끼친다. 본 논문에서는 CNN과 SVM을 기반으로 온라인 포커 게임에 게이머와 아바타 간의 감성연결을 실현하기 위한 새로운 감성 인식방법을 제안한다. CNN모델을 이용하여 원래 얼굴 이미지의 특징을 추출하고, 다중 클래스 SVM분류기를 사용하여 목표 이미지를 인식하고 분류한다.FER-2013데이터베이스에서 이 방법은 감성인식률 68.79 %를 달성하였다. 기존의 다른 감성 인식 모델과 비교하면, 이 모델은 뚜렷한 장점을 보일 수 있다. 본 게임은 Socket 통신방식을 통해 감성인식결과를 Seven Poker로 전송하여 아바타가 게이머와 같은 감성을 표현하도록 설계하였다. 온라인 포커 게임에 감성연결 기술을 이용하면 게임과 인간의 상호작용이 향상될 뿐 아니라 게이머가 상대방의 심리적인 활동을 효과적으로 분석할 수 있다. 감성연결 기술은 게임에서 게이머들에게 새로운 게임 경험을 제공할 수 있는 기술이라고 생각된다.","Compared to other types of games, poker game is a psychological game based on gamer s psychological activity. This paper proposes a method based on convolutional neural network (CNN) and support vector machine (SVM) to realize the emotion recognition to link the gamer and his avatar in online poker game. The CNN model is used to extract feature of the original face images, and the multi-class SVM classifier is used to classify the emotions. On the FER-2013 database, the proposed method achieves 68.79% emotion recognition rate, and has obvious advantages compared with most other emotion recognition methods. Next, through the socket communication, the result of the emotion recognition is transferred to the designed seven poker game to realize the emotion linkage between the gamer and his avatar. More importantly, the emotion linkage technology not only helps the gamer to analyze the opponent’s psychological state, but also enhances the interaction of the game. It is undoubtedly a new breakthrough in game play that will give gamers a whole new gaming experience."
3차원 특징볼륨을 이용한 깊이영상 생성 모델,2018,"['깊이영상', '컨볼루션 신경망', '딥러닝', '시차 영상', 'Depth Map', 'Convolutional Neural Network', 'Deep Learning', 'Stereo Image']","본 논문은 컨볼루션 신경망으로 이루어진 학습 모델을 통해 스테레오 영상의 깊이영상 생성 알고리즘을 제안한다. 제안하는 알고리즘은 좌, 우 시차 영상을 입력으로 받아 각 시차영상의 주요 특징을 추출하는 특징 추출부와 추출된 특징을 이용하여 시차 정보를 학습하는 깊이 학습부로 구성된다. 우선 특징 추출부는 2D CNN 계층들로 이루어진 익셉션 모듈(xception module) 및 ASPP 모듈(atrous spatial pyramid pooling) module을 통해 각각의 시차영상에 대한 특징맵을 추출한다. 그 후 각 시차에 대한 특징 맵을 시차에 따라 3차원 형태로 쌓아 3D CNN을 통해 깊이 추정 가중치를 학습하는 깊이 학습부를 거친 후 깊이 영상을 추정한다. 제안하는 알고리즘은 객체 영역에 대해 기존의 다른 학습 알고리즘들 보다 정확한 깊이를 추정하였다.","This paper proposes a depth image generation algorithm of stereo images using a deep learning model composed of a CNN (convolutional neural network). The proposed algorithm consists of a feature extraction unit which extracts the main features of each parallax image and a depth learning unit which learns the parallax information using extracted features. First, the feature extraction unit extracts a feature map for each parallax image through the Xception module and the ASPP(Atrous spatial pyramid pooling) module, which are composed of 2D CNN layers. Then, the feature map for each parallax is accumulated in 3D form according to the time difference and the depth image is estimated after passing through the depth learning unit for learning the depth estimation weight through 3D CNN. The proposed algorithm estimates the depth of object region more accurately than other algorithms."
Deep Visual Discomfort Predictor for Stereoscopic 3D Images,2018,[],국문 초록 정보 없음,"<P>Most prior approaches to the problem of stereoscopic 3D (S3D) visual discomfort prediction (VDP) have focused on the extraction of perceptually meaningful handcrafted features based on models of visual perception and of natural depth statistics. Toward advancing performance on this problem, we have developed a deep learning-based VDP model named deep visual discomfort predictor (DeepVDP). The DeepVDP uses a convolutional neural network (CNN) to learn features that are highly predictive of experienced visual discomfort. Since a large amount of reference data is needed to train a CNN, we develop a systematic way of dividing the S3D image into local regions defined as patches and model a patch-based CNN using two sequential training steps. Since it is very difficult to obtain human opinions on each patch, instead a proxy ground-truth label that is generated by an existing S3D visual discomfort prediction algorithm called 3D-VDP is assigned to each patch. These proxy ground-truth labels are used to conduct the first stage of training the CNN. In the second stage, the automatically learned local abstractions are aggregated into global features via a feature aggregation layer. The learned features are iteratively updated via supervised learning on subjective 3D discomfort scores, which serve as ground-truth labels on each S3D image. The patch-based CNN model that has been pretrained on proxy ground-truth labels is subsequently retrained on true global subjective scores. The global S3D visual discomfort scores predicted by the trained DeepVDP model achieve the state-of-the-art performance as compared with previous VDP algorithms.</P>"
잔향 환경 음성인식을 위한 다중 해상도 DenseNet 기반 음향 모델,2018,"['convolutional neural network', 'DenseNet', 'multi-resolution', 'speech recognition']",국문 초록 정보 없음,"Although deep neural network-based acoustic models have greatly improved the performance of automatic speech recognition (ASR), reverberation still degrades the performance of distant speech recognition in indoor environments. In this paper, we adopt the DenseNet, which has shown great performance results in image classification tasks, to improve the performance of reverberant speech recognition. The DenseNet enables the deep convolutional neural network (CNN) to be effectively trained by concatenating feature maps in each convolutional layer. In addition, we extend the concept of multi-resolution CNN to multi-resolution DenseNet for robust speech recognition in reverberant environments. We evaluate the performance of reverberant speech recognition on the single-channel ASR task in reverberant voice enhancement and recognition benchmark (REVERB) challenge 2014. According to the experimental results, the DenseNet-based acoustic models show better performance than do the conventional CNN-based ones, and the multi-resolution DenseNet provides additional performance improvement."
Diabetes detection using deep learning algorithms,2018,"['Deep learning', 'Diabetes', 'Heart rate variability', 'ECG', 'CNN', 'LSTM']",국문 초록 정보 없음,"Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%."
< 구두-B-03 > 합성곱신경망을 이용한 국산 침엽수재의 자동수종식별,2018,[],"본 연구에서는 딥러닝 방법 중에 하나인 합성곱신경망 (Convolution neural network, CNN)을 이용하여 전문가 없이도 빠르고 정확한 목재수종식별이 가능한 자동목재수종식별 시스템을 개발하였다. CNN 은 이미지 고유의 대표 특징을 추출하고 올바르게 분류하는 용도로 사용될 수 있다. 보통 CNN을 이용한 분류 작업의 성능은 기존의 자동목재수종식별 시스템에 비해 분류 성능이 높은 것으로 알려져 있다.스마트폰 카메라를 이용하여 총 다섯 가지 수종(편백, 삼나무, 잣나무, 소나무, 낙엽송)의 시편에서 횡단면의 이미지를 획득하였다. 획득된 이미지에서 수종별로 3000개 이상의 이미지를 무작위로 추출하여 75%는 훈련용, 25%는 모델의 검증에 사용하였다.본 연구에서는 CNN 모델 중 LeNet과 VGGNet을 변형한 딥러닝 모델을 자동목재수종식별 시스템에 적용하였다. LeNet 모델은 2개의 히든레이어(CONV > ACT > POOL)와 2개의 Dense 레이어로 구성되어 있으며, 히든레이어의 수를 증가시켜 LeNet2, LeNet3 모델을 만들었다. MiniVGGNet은 기존의 VGGNet에서 2개의 히든레이어(CONV > ACT > BN > CONV > ACT > BN > POOL > DROP)만 남기고 이 후에 Dense > ACT > BN > DROP > Dense > ACT으로 마무리되는 축소모델이다. MiniVGGNet2와 MiniVGGNet3 모델은 MiniVGGNet의 히든레이어의 숫자를 증가시켜 만든 모델이다. 최적화 알고리즘으로는 Stochastic Gradient Decent(SGD)를 사용하였으며, Learning rate, batch size, epoch의 수, 입력 이미지의 크기에 변화를 주면서 가장 높은 분류 정확도를 보이는 조건을 탐색하였다.상기한 모델 중에서 LeNet3 모델이 가장 높은 식별률(99.3%)을 보였다. 본 연구에서 개발된 자동목재 수종식별 시스템은 빠르고 정확하며 생성된 인자의 크기도 작아서 스마트폰과 같은 휴대용 장치에 설치하여 사용할 수 있음 알 수 있었다.",다국어 초록 정보 없음
Generative Adversarial Network를 활용한 Image2Vec기반 이미지 검색 모델 개발,2018,"['Deep Learning', 'Information Retrieval', 'Sketch Retrieval', 'Fashion Technique', 'CNN', '딥러닝', '정보 검색', '스케치 검색', '패션 기술', 'CNN']","검색에서 이미지는 시각적 속성이 중요지만, 기존의 검색방법은 문서 검색을 위한 방법에 초점이 맞춰져 있어 이미지의 속성 정보가 미반영된 키워드 중심의 검색 시스템이 대부분이다. 본 연구는 이러한 한계를 극복하고자 이미지의 벡터 정보를 기반으로 유사 이미지를 검색할 수 있는 모델과 스케치로 검색 쿼리를 제공하여 유사 이미지를 검색할 수 있는 시스템을 개발하였다. 제안된 시스템은 GAN을 이용하여 스케치를 이미지 수준으로 업 샘플링하고, 이미지를 CNN을 통해 벡터로 변환한 후, 벡터 공간 모델을 이용하여 유사 이미지를 검색한다. 제안된 모델을 구현하기 위하여 패션 이미지를 이용하여 모델을 학습시켰고 패션 이미지 검색 시스템을 개발하였다. 성능 측정은 Precision at k를 이용하였으며, 0.774와 0.445의 성능 결과를 보였다. 제안된 방법을 이용하면 이미지 검색 의도를 키워드로 표현하는데 어려움을 느끼는 사용자들의 검색 결과에 긍정적 효과가 나타날 것으로 기대된다.","The most of the IR focus on the method for searching the document, so the keyword-based IR system is not able to reflect the feature information of the image. In order to overcome these limitations, we have developed a system that can search similar images based on the vector information of images, and it can search for similar images based on sketches. The proposed system uses the GAN to up sample the sketch to the image level, convert the image to the vector through the CNN, and then retrieve the similar image using the vector space model. The model was learned using fashion image and the image retrieval system was developed. As a result, the result is showed meaningful performance."
공분산과 모듈로그램을 이용한 콘볼루션 신경망 기반 양서류 울음소리 구별,2018,[],국문 초록 정보 없음,"In this paper, a covariance matrix and modulogram are proposed for realizing amphibian sound classification using CNN (Convolutional Neural Network). First of all, a database is established by collecting amphibians sounds including endangered species in natural environment. In order to apply the database to CNN, it is necessary to standardize acoustic signals with different lengths. To standardize the acoustic signals, covariance matrix that gives distribution information and modulogram that contains the information about change over time are extracted and used as input to CNN. The experiment is conducted by varying the number of a convolutional layer and a fully-connected layer. For performance assessment, several conventional methods are considered representing various feature extraction and classification approaches. From the results, it is confirmed that convolutional layer has a greater impact on performance than the fully-connected layer. Also, the performance based on CNN shows attaining the highest recognition rate with 99.07 % among the considered methods."
라즈베리파이를 활용한 해충 인식 시스템 설계,2018,"['컨볼루션 뉴럴 네트워크', '해충 감지', '딥러닝', '라즈베리파이', '텐서플로우', 'Convolution Neural Network', 'Pest Detection', 'Deep Learning', 'Raspberry Pi', 'TensorFlow']","4차 산업혁명의 발달과 함께 농업에 최신 ICT기술을 도입하기 위한 많은 연구가 진행되고 있다. 그러나 노지농업의 경우 외부에서 작업하는 특성상 환경 제어가 힘들고 해충에 의한 질병이 가장 문제가 되고 있다. 이러한 문제를 해결하기 위해 현재 IT페로몬 트랩을 사용하여 문제를 해결하고 있으나, 진단 결과가 전문가에게 전달되기까지는 매우 오래 걸리며 이를 진단하기까지 전문 노동력을 소비하여 결과를 받을 수 있는 문제가 있다. 위의 문제점을 해결하기 위해 설치비용이 적게 드는 라즈베리파이를 활용한 CNN기법을 통해 해충 이미지에서 해충의 개수를 파악하는 시스템을 제안하고자 한다. CNN분석을 위해해충이미지를 국가기관 및 구글 이미지에서 추출하였으며 실제 해충이 발생하는 농가에 설치하여 추출한 이미지를 포함시켰다. 부족한 이미지는 8개의 방향으로 이미지를 회전시켜 학습시키고 1차적으로 라즈베리에서 해충의 특징을 추출한 뒤 2차로 클라우드 서버에서 이미지를 통해 분석을 실시하는 시스템이다. 위의 방법을 사용함으로써 농민 해충의 생산성을 증대시키고, 전문 조직의 선진 인력의 노동력을 감소시킬 것으로 기대된다.","With the development of the 4th industrial revolution, much research is underway to introduce the latest ICT technology in agriculture. In the case of the bare ground agriculture, however, it is difficult to control the environment in order to work from the outside, and diseases caused by pests are the most problematic. Currently, IT pheromone traps are being used by farmers to solve the above problems, but it takes a very long time to send the results to the experts to receive the diagnosis and the result of the action, which is problematic because of the high labor consumption. In order to solve the above problem, we try to understand the number of insect pests by analyzing the image through the proposed CNN method by taking pest image using Raspberry pie with low installation cost. For CNN analysis, pest images were extracted from national organizations and Google images, and images were extracted from farms where actual pests were generated. The insufficient pest image is a system that rotates the image in eight directions, first extracts the characteristics of the pest from raspberry pi, and secondly analyzes the image through the cloud server. By using the above method, it is expected that it will reduce productivity of pests of farmers and increase the productivity and reduce the labor force of advanced manpower of professional organizations."
딥러닝을 이용한 딸기 형상 선별에 관한 연구,2018,"['딸기', '2차원 영상', '형상', '딥러닝']","최근 영상처리 기술의 발달로 인한 농산물의 비파괴적인 품질 계측에 관한 연구가 활발하게 이루어지고 있다. 특히, 딸기는 농산물 중에서 경도가 매우 약한 편에 속하여 비파괴적인 방법을 이용한 수확, 선별, 포장 및 유통에 관한 연구가 요구되고 있는 실정이다. 현재 딸기 선별은 전문가들의 육안으로 진행되어 개인차가 발생하고 있고, 이러한 개인차를 방지하기 위해 영상처리 기술을 이용하여 일관성 있는 선별을 하고자 딸기의 색상 및 형상에 관한 연구가 진행되고 있다. 하지만 딸기의 형상에 있어서 정상과를 제외한 비정상과들의 특징이 불규칙적으로 나타나 정확한 특징을 추출하고 분류하는데 어려움을 겪고있다. 본 연구는 딸기의 색상 및 형상을 측정하기 위해 획득한 2차원 RGB 영상에 대해 딥러닝 기술을 이용하여 기존의 형상 선별 기술보다 높은 정확도의 선별이 가능한지에 대한 가능성을 파악하기 위해 수행되었다. 딥러닝은 매트랩의 Alexnet Convolutional Neural Network (CNN)를 이용하였다. Alexnet CNN은 25개의 레이어로 구성되어 있으며, 100만 개 이상의 이미지에 대해 학습된 네트워크이다. Alexnet CNN을 이용하기 위해 딸기 형상에 있어서 불규칙적인 비정상과 이미지 100개를 하나의 클래스로 지정하였고, 정상과 이미지 100개를 또 다른 클래스로 지정하였다. 두 개의 클래스로 분류된 이미지를 각각 100개 중60개는 학습시키는데 이용하였고, 40개는 학습된 네트워크를 이용하여 테스트를 진행하였다. 테스트 결과는 비정상과 40개 중 33개를 비정상과로 분류하였고, 정상과는 40개 중 35개를 정상과로 분류하여 각각 88%, 83%로 높은 정확도를 나타내었다. Alexnet CNN에 대해 새로운 레이어의 추가와 수정을 진행하고, 더 많은 이미지를 학습시킨다면 보다 더 높은 정확도를 나타낼 것으로 기대된다.",다국어 초록 정보 없음
합성곱 신경망을 이용한 스마트 토이의 음성명령 학습에 관한 연구,2018,"['AI', 'CNN', 'IoT', 'Smart toy', 'Voice command', 'Voice learning']",국문 초록 정보 없음,"Recently, as the IoT(Internet of Things) and AI(Artificial Intelligence) technologies have developed, smart toys that can understand and act on the language of human beings are being studied. In this paper, we study voice learning using CNN(Convolutional Neural Network) by applying artificial intelligence based voice secretary technology to smart toy. When a human voice command gives, Smart Toy recognizes human voice, converts it into text, analyzes the morpheme, and conducts tagging and voice learning. As a result of test for the simulator program implemented using Python, no malfunction occurred in a single command. And satisfactory results were obtained within the selected simulation condition range."
사운드 이벤트 감지를 통한 기계 상태 모니터링,2018,"['Mechanical fault detection', 'CNN', 'Sound analysis', 'Status monitoring', 'STFT']",국문 초록 정보 없음,다국어 초록 정보 없음
CT 영상의 심층학습에 의한 뇌 지주막하 출혈 진단 보조 시스템 개발,2018,"['Brain Subarachnoid Hemorrhage', 'CT Image', 'Deep Learing', 'CNN', 'Morphology Operation', 'Histogram Stretching', '뇌 지주막하 출혈', 'CT 영상', '심층학습', '모폴로지 연산', '히스토그램 스트레칭']","본 논문에서는 CT 영상의 전처리와 심층학습에 의한 뇌 지주막하 출혈의 진단을 위한 보조 시스템을 개발한다. 여기서 전처리는 CT 뇌 영상을 이진화하여 노이즈 제거를 위해 모폴로지 연산을 수행하고, 이진 마스크를 이용해 관심영역을 추출하며, 영상의 크기를 재조정하여 계산부하를 줄인다. 또한 심층학습은 Convolutional neural network(CNN)을 이용하여 전처리된 영상들을 대상으로 이루어지며, 새로이 입력되는 CT 뇌 영상의 정상과 비정상을 판단한다. 특히 비정상으로 판단된 영상에 대해서는 히스토그램 스트레칭으로 출혈 부분의 가시도를 증가시켜 강조함으로써 좀 더 빠르고 정확하게 진단될 수 있도록 한다. 제안된 시스템을 512*512 픽셀의 RGB DICOM 영상 124개를 대상으로 실험한 결과 우수한 진단 성능이 있음을 알 수 있다.","In this paper, we develop a diagnostic assistant system of brain subarachnoid hemorrhage by the pre-processing and deep learning of CT images. The pre-processing performs a morphology operation to remove the noise in CT brain image, and extract the region of interest by using a binary mask, and reduce the calculation load by resizing the image. And deep learning is performed on preprocessed images using convolutional neural network, determine the normality and abnormality of the newly entered CT brain image. Especially, the histogram stretching is performed for the images judged to be abnormal, which increases the visibility of the bleeding part and emphasizes it, so that it can be diagnosed more quickly and accurately. The proposed method has been applied to diagnose RGB 124-brain CT images of 512*512 pixels. The experimental results show that the proposed method has an excellent diagnostic performance."
카테고리 계층을 고려한 회선신경망의 이미지 분류,2018,"['Convolutional Neural Networks', 'Image Classification', 'Category Hierarchy']",국문 초록 정보 없음,"In order to improve the performance of image classifications using Convolutional Neural Networks (CNN), applying a category hierarchy to the classification can be a useful idea. However, the visual separation of object categories is very different according to the upper and lower category levels and highly uneven in image classifications. Therefore, it is doubtable whether the use of category hierarchies for classification is effective in CNN. In this paper, we have clarified whether the image classification using category hierarchies improves classification performance, and found at which level of hierarchy classification is more effective. For experiments we divided the image classification task according to the upper and lower category levels and assigned image data to each CNN model. We identified and compared the results of three classification models and analyzed them. Through the experiments, we could confirm that classification effectiveness was not improved by reduction of number of categories in a classification model. And we found that only with the re-training method in the last network layer, the performance of lower category classification was not improved although that of higher category classification was improved."
Convolutional Neural Network based Audio Event Classification,2018,"['Audio event classification', 'Convolutional neural networks', 'Deep learning']",국문 초록 정보 없음,"This paper proposes an audio event classification method based on convolutional neural networks (CNNs). CNN has great advantages of distinguishing complex shapes of image. Proposed system uses the features of audio sound as an input image of CNN. Mel scale filter bank features are extracted from each frame, then the features are concatenated over 40 consecutive frames and as a result, the concatenated frames are regarded as an input image. The output layer of CNN generates probabilities of audio event (e.g. dogs bark, siren, forest). The event probabilities for all images in an audio segment are accumulated, then the audio event having the highest accumulated probability is determined to be the classification result. This proposed method classified thirty audio events with the accuracy of 81.5% for the UrbanSound8K, BBC Sound FX, DCASE2016, and FREESOUND dataset."
진단명 자동 레이블링을 위한 딥러닝기반 판독기록문으로부터 최종 진단명 추출,2018,[],국문 초록 정보 없음,"A variety of studies are being conducted to solve the medical field problems that require high accuracy as well as professional anatomical knowledge by combining AI, which has been a huge success in the field of vision. However, implementing final diagnosis training data by analyzing extensive amount medical treatment record is slowing the progress of the study due to the time consuming issue. This paper proposed a combined network of CNN and RNN to automatically extract final diagnosis from medical treatment record. Also, Weights of pre-learned embedding vectors is transferred to the embedding layer in front of CNN-RNN model. This has solved the problem of performance degradation due to insufficient training data and the combination of feature maps created through parallel CNN-RNN model allows analysis between long sentences as well as between adjacent words."
Fingerprint liveness map construction using convolutional neural network,2018,[],국문 초록 정보 없음,"<P>With increasing markets for fingerprint authentication, there are also increasing concerns about spoofs or synthetically produced fingerprint identifications that can bypass the authentication process. In this Letter, the authors introduce a new convolutional neural networks (CNNs) architecture for fingerprint liveness detection problem that can provide a more robust framework for network training and detection than previous methods. The proposed method employs squared regression error for each receptive field without the usage of the fully connected layer. Such structure provides following advantages from the previous liveness fingerprint CNN. First, unlike the previous techniques which rely on the pre-trained features, the proposed CNN can be trained directly from fingerprints as the loss is minimised for each receptive field. Second, in contrast to the cross-entropy layer, the squared error layer allows them to set up a threshold value that can control the acceptable level of false positives or false negatives. Third, the absence of a fully connected layer allows them to crop the input fingerprints such that a trade-off between accuracy and computation time can be made without the negative effects of re-scaling. The proposed CNN is shown to provide higher accuracy for three out of four datasets when evaluated against the state-of-the-art method.</P>"
Improving the Accuracy of Simultaneously Reconstructed Activity and Attenuation Maps Using Deep Learning,2018,"['deep learning', 'simultaneous reconstruction', 'crosstalk', 'denoising', 'quantification']",국문 초록 정보 없음,"<P>Simultaneous reconstruction of activity and attenuation using the maximum-likelihood reconstruction of activity and attenuation (MLAA) augmented by time-of-flight information is a promising method for PET attenuation correction. However, it still suffers from several problems, including crosstalk artifacts, slow convergence speed, and noisy attenuation maps (μ-maps). In this work, we developed deep convolutional neural networks (CNNs) to overcome these MLAA limitations, and we verified their feasibility using a clinical brain PET dataset. <B>Methods:</B> We applied the proposed method to one of the most challenging PET cases for simultaneous image reconstruction (<SUP>18</SUP>F-fluorinated-<I>N</I>-3-fluoropropyl-2-β-carboxymethoxy-3-β-(4-iodophenyl)nortropane [<SUP>18</SUP>F-FP-CIT] PET scans with highly specific binding to striatum of the brain). Three different CNN architectures (convolutional autoencoder [CAE], Unet, and Hybrid of CAE) were designed and trained to learn a CT-derived μ-map (μ-CT) from the MLAA-generated activity distribution and μ-map (μ-MLAA). The PET/CT data of 40 patients with suspected Parkinson disease were used for 5-fold cross-validation. For the training of CNNs, 800,000 transverse PET and CT slices augmented from 32 patient datasets were used. The similarity to μ-CT of the CNN-generated μ-maps (μ-CAE, μ-Unet, and μ-Hybrid) and μ-MLAA was compared using Dice similarity coefficients. In addition, we compared the activity concentration of specific (striatum) and nonspecific (cerebellum and occipital cortex) binding regions and the binding ratios in the striatum in the PET activity images reconstructed using those μ-maps. <B>Results:</B> The CNNs generated less noisy and more uniform μ-maps than the original μ-MLAA. Moreover, the air cavities and bones were better resolved in the proposed CNN outputs. In addition, the proposed deep learning approach was useful for mitigating the crosstalk problem in the MLAA reconstruction. The Hybrid network of CAE and Unet yielded the most similar μ-maps to μ-CT (Dice similarity coefficient in the whole head = 0.79 in the bone and 0.72 in air cavities), resulting in only about a 5% error in activity and binding ratio quantification. <B>Conclusion:</B> The proposed deep learning approach is promising for accurate attenuation correction of activity distribution in time-of-flight PET systems.</P>"
Learning-Based Just-Noticeable-Quantization- Distortion Modeling for Perceptual Video Coding,2018,[],국문 초록 정보 없음,"<P>Conventional predictive video coding-based approaches are reaching the limit of their potential coding efficiency improvements, because of severely increasing computation complexity. As an alternative approach, perceptual video coding (PVC) has attempted to achieve high coding efficiency by eliminating perceptual redundancy, using just-noticeable-distortion (JND) directed PVC. The previous JNDs were modeled by adding white Gaussian noise or specific signal patterns into the original images, which were not appropriate in finding JND thresholds due to distortion with energy reduction. In this paper, we present a novel discrete cosine transform-based energy-reduced JND model, called ERJND, that is more suitable for JND-based PVC schemes. Then, the proposed ERJND model is extended to two learning-based just-noticeable-quantization-distortion (JNQD) models as preprocessing that can be applied for perceptual video coding. The two JNQD models can automatically adjust JND levels based on given quantization step sizes. One of the two JNQD models, called LR-JNQD, is based on linear regression and determines the model parameter for JNQD based on extracted handcraft features. The other JNQD model is based on a convolution neural network (CNN), called CNN-JNQD. To our best knowledge, our paper is the first approach to automatically adjust JND levels according to quantization step sizes for preprocessing the input to video encoders. In experiments, both the LR-JNQD and CNN-JNQD models were applied to high efficiency video coding (HEVC) and yielded maximum (average) bitrate reductions of 38.51% (10.38%) and 67.88% (24.91%), respectively, with little subjective video quality degradation, compared with the input without preprocessing applied.</P>"
딥러닝 기반의 무기 소지자 탐지,2018,"['Object-related human detection', 'Pose estimation', 'Object detection', 'CNN', 'Deep learning']",국문 초록 정보 없음,"Nowadays, gun crimes occur very frequently not only in public places but in alleyways around the world. In particular, it is essential to detect a person armed by a pistol to prevent those crimes since small guns, such as pistols, are often used for those crimes. Because conventional works for armed person detection have treated an armed person as a single object in an input image, their accuracy is very low. The reason for the low accuracy comes from the fact that the gunman is treated as a single object although the pistol is a relatively much smaller object than the person. To solve this problem, we propose a novel algorithm called APDA(Armed Person Detection Algorithm). APDA detects the armed person using in a post-processing the positions of both wrists and the pistol achieved by the CNN-based human body feature detection model and the pistol detection model, respectively. We show that APDA can provide both 46.3% better recall and 14.04% better precision than SSD-MobileNet."
Deep Power Control: Transmit Power Control Scheme Based on Convolutional Neural Network,2018,[],국문 초록 정보 없음,"<P>In this letter, deep power control (DPC), which is the first transmit power control framework based on a convolutional neural network (CNN), is proposed. In DPC, the transmit power control strategy to maximize either spectral efficiency (SE) or energy efficiency (EE) is learned by means of a CNN. While conventional power control schemes require a considerable number of computations, in DPC, the transmit power of users can be determined using far fewer computations enabling real-time processing. We also propose a form of DPC that can be performed in a distributed manner with local channel state information, allowing the signaling overhead to be greatly reduced. Through simulations, we show that the DPC can achieve almost the same or even higher SE and EE than a conventional power control scheme, with a much lower computation time.</P>"
A Deep-Learning Based Model for Emotional Evaluation of Video Clips,2018,"['Video emotion analysis', 'C3D', 'Transfer learning', 'LSTM']",국문 초록 정보 없음,"Emotional evaluation of video clips is the difficult task because it includes not only stationary objects as the background but also dynamic objects as the foreground. In addition, there are many video analysis problems to be solved beforehand to properly address the emotionrelated tasks. Recently, however, the convolutional neural network (CNN)-based deep learning approach, opens the possibility by solving the action recognition problem. Inspired by the CNN-based action recognition technology, this paper challenges to evaluate the emotion of video clips. In the paper, we propose a deep learning model to capture the video features and evaluate the emotion of a video clip on Thayer 2D emotion space. In the model, the pre-trained convolutional 3D neural network (C3D) generates short-term spatiotemporal features of the video, LSTM accumulates those consecutive time-varying features to characterize long-term dynamic behaviors, and multilayer perceptron (MLP) evaluates emotion of a video clip by regression on the emotion space. Due to the limited number of labeled data, the C3D is employed to extract diverse spatiotemporal from various layers by transfer learning technique. The pre-trained C3D on the Sports-1M dataset and long short term memory (LSTM) followed by the MLP for regression are trained in end-to-end manner to fine-tune the C3D, and to adjust weights of LSTM and the MLP-type emotion estimator. The proposed method achieves the concordance correlation coefficient values of 0.6024 for valence and 0.6460 for arousal, respectively. We believe this emotional evaluation of video could be easily associated with appropriate music recommendation, once the music is emotionally evaluated in the same high-level emotional space."
합성 곱 신경망을 이용한 원단 결점 검출 시스템,2018,[],국문 초록 정보 없음,"Measuring the quality of clothes and fabrics is an indispensable factor in the respect to the satisfactory of consumers and the profitability for the apparel companies. We propose a method to automatically detect the flaws in fabric, which is the main material of apparel products, without human involvement. In the absence of data on defect samples, synthetic abnormal data is generated using classical method. Using the synthesized data, we train convolutional neural network (CNN) to determine a given patch contains defects or not. The fabric is inspected whether or not it contains defects through trained CNN. In this paper, it is shown that deep learning can be applied to practical applications related to the clothing industry."
Generating Pixel Art from Game Characters with Convolutional-Neural Network,2018,"['pixel art', 'deep learning', 'image abstraction', 'non-photorealistic rendering']","픽셀 아트는 낮은 해상도와 제한된 색 팔레트를 가지고 영상을 표현한다. 픽셀 아트는 낮은 연산 성능과 적은 저장 공간을 가지는 초기 컴퓨터 게임에서 주로 사용되었다. 현대에 이르러, 픽셀 아트는 예술이나 퍼즐, 게임과 같은 다양한 분야에서 찾아볼 수 있게 되었다.본 논문에서는 게임 캐릭터 영상을 입력으로 받는 픽셀 아트 생성 모델을 제안한다. 기존 방법과는 달리, 합성곱 신경망(CNN:Convolutional-Neural Network)를 픽셀 아트 생성 목적에 맞게 변형하여 이를 이용하는 방법을 제시한다. 기존의 합성곱 연산 후에 upsampling 과정을 추가하여 픽셀 아트가 생성될 수 있도록 하였다. 네트워크는 ground truth와 생성된 픽셀 아트와의 평균 오차 제곱(MSE:Mean Squared Error)을 최소화해나가며 학습을 수행한다.Ground truth는 실제 아티스트가 생성하도록 하였고, 이미지 회전과 반전 기법을 이용하여 augumentation을 수행하였다. 생성된 데이터 집합은 학습, 검증, 시험 데이터로 나누었다. 이러한 데이터 집합을 기반으로 감독 학습을 실시하여 픽셀 아트 생성 네트워크를 학습하였다. 학습 모델의 학습 과정과 학습 정확도를 제시하고, 시험 데이터 뿐만 아니라 다양한 영상에 대한 픽셀아트 결과도 함께 제시한다.","Pixel art, which presents low-resolutional images with restricted color palette, has been employed frequently in the early computer games played on low memory capacity and computational performance. Recently, pixel art wides its applications to the area such as puzzle and game. In this paper, we present a pixel art generator from images of game characters. Unlike traditional framework, we employ and modify a Convolutional-Neural Network(CNN) to generate pixel art by placing an up-convolution layer after convolution layers. The up-convolution layer increases the resolution of the result images to satisfy user-required resolution. The network is trained by minimizing the Mean Squared Error(MSE) between ground truth images and generated pixel art images from the input high-resolutional image. Also, we employ artists to produce the ground truth of pixel art for our network and augment the data by rotating and fliping. We partition the ground truth images into three datasets: a training, validation and test dataset. With this dataset, we perform a supervised learning and train our network as the pixel art generator. We show a training process and a training accuracy. Moreover, we test our architecture for a various images as well as the test dataset to prove the excellence of our architecture."
Object-oriented convolutional features for fine-grained image retrieval in large surveillance datasets,2018,"['Image retrieval', 'Object-oriented features', 'Convolutional neural network', 'Fine-grained retrieval']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Large scale visual surveillance generates huge volumes of data at a rapid pace, giving rise to massive image repositories. Efficient and reliable access to relevant data in these ever growing databases is a highly challenging task due to the complex nature of surveillance objects. Furthermore, inter-class visual similarity between vehicles requires extraction of fine-grained and highly discriminative features. In recent years, features from deep convolutional neural networks (CNN) have exhibited state-of-the-art performance in image retrieval. However, these features have been used without regard to their sensitivity to objects of a particular class. In this paper, we propose an object-oriented feature selection mechanism for deep convolutional features from a pre-trained CNN. Convolutional feature maps from a deep layer are selected based on the analysis of their responses to surveillance objects. The selected features serve to represent semantic features of surveillance objects and their parts with minimal influence of the background, effectively eliminating the need for background removal procedure prior to features extraction. Layer-wise mean activations from the selected features maps form the discriminative descriptor for each object. These object-oriented convolutional features (OOCF) are then projected onto low-dimensional hamming space using locality sensitive hashing approaches. The resulting compact binary hash codes allow efficient retrieval within large scale datasets. Results on five challenging datasets reveal that OOCF achieves better precision and recall than the full feature set for objects with varying backgrounds.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Proposed to represent vehicle images with appropriate convolutional features. </LI> <LI>  Our method reduces number of feature maps without performance degradation. </LI> <LI>  Selected features yield better retrieval performance than the full feature set. </LI> </UL> </P>"
YOLO 기반 외곽 사각형을 이용한 근접 돼지 분리,2018,"['Pig Monitoring', 'Touching Pigs', 'Segmentation', 'Convolution Neural Network', 'YOLO']",국문 초록 정보 없음,"Although separation of touching pigs in real-time is an important issue for a 24-h pig monitoring system, it is challenging to separate accurately the touching pigs in a crowded pig room. In this study, we propose a separation method for touching pigs using the information generated from Convolutional Neural Network(CNN). Especially, we apply one of the CNN-based object detection methods(i.e., You Look Only Once, YOLO) to solve the touching objects separation problem in an active manner. First, we evaluate and select the bounding boxes generated from YOLO, and then separate touching pigs by analyzing the relations between the selected bounding boxes. Our experimental results show that the proposed method is more effective than widely-used methods for separating touching pigs, in terms of both accuracy and execution time."
Efficient Conversion of Deep Features to Compact Binary Codes Using Fourier Decomposition for Multimedia Big Data,2018,[],국문 초록 정보 없음,"<P>Exponential growth of multimedia data has been witnessed in recent years from various industries, such as e-commerce, health, transportation, and social networks, etc. Access to desired data in such gigantic datasets require sophisticated and efficient retrieval methods. In the last few years, neuronal activations generated by a pretrained convolutional neural network (CNN) have served as generic descriptors for various tasks including image classification, object detection and segmentation, and image retrieval. They perform incredibly well compared to hand-crafted features. However, these features are usually high dimensional, requiring a lot of memory and computations for indexing and retrieval. For very large datasets, utilization of these high dimensional features in raw form becomes infeasible. In this paper, a highly efficient method is proposed to transform high dimensional deep features into compact binary codes using bidirectional Fourier decomposition. This compact bit code saves memory and eases computations during retrieval. Further, these codes can also serve as hash codes, allowing very efficient access to images in large datasets using approximate nearest neighbor (ANN) search techniques. Our method does not require any training and achieves considerable retrieval accuracy with short length codes. It has been tested on features extracted from fully connected layers of a pretrained CNN. Experiments conducted with several large datasets reveal the effectiveness of our approach for a wide variety of datasets.</P>"
Single-view 2D CNNs with fully automatic non-nodule categorization for false positive reduction in pulmonary nodule detection,2018,"['Computer-aided detection', 'Pulmonary nodule detection', 'False positive reduction', 'Automatic non-nodule categorization', 'Deep learning']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Background and Objective: In pulmonary nodule detection, the first stage, candidate detection, aims to detect suspicious pulmonary nodules. However, detected candidates include many false positives and thus in the following stage, false positive reduction, such false positives are reliably reduced. Note that this task is challenging due to 1) the imbalance between the numbers of nodules and non-nodules and 2) the intra-class diversity of non-nodules. Although techniques using 3D convolutional neural networks (CNNs) have shown promising performance, they suffer from high computational complexity which hinders constructing deep networks. To efficiently address these problems, we propose a novel framework using the ensemble of 2D CNNs using single views, which outperforms existing 3D CNN-based methods.</P> <P>Methods: Our ensemble of 2D CNNs utilizes single-view 2D patches to improve both computational and memory efficiency compared to previous techniques exploiting 3D CNNs. We first categorize non-nodules on the basis of features encoded by an autoencoder. Then, all 2D CNNs are trained by using the same nodule samples, but with different types of non-nodules. By extending the learning capability, this training scheme resolves difficulties of extracting representative features from non-nodules with large appearance variations. Note that, instead of manual categorization requiring the heavy workload of radiologists, we propose to automatically categorize non-nodules based on the autoencoder and k-means clustering.</P> <P>Results: We performed extensive experiments to validate the effectiveness of our framework based on the database of the lung nodule analysis 2016 challenge. The superiority of our framework is demonstrated through comparing the performance of five frameworks trained with differently constructed training sets. Our proposed framework achieved state-of-the-art performance (0.922 of the competition performance metric score) with low computational demands (789K of parameters and 1024M of floating point operations per second).</P> <P>Conclusion: We presented a novel false positive reduction framework, the ensemble of single-view 2D CNNs with fully automatic non-nodule categorization, for pulmonary nodule detection. Unlike previous 3D CNN-based frameworks, we utilized 2D CNNs using 2D single views to improve computational efficiency. Also, our training scheme using categorized non-nodules, extends the learning capability of representative features of different non-nodules. Our framework achieved state-of-the-art performance with low computational complexity.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a novel framework, an ensemble of 2D CNNs using single views, for efficient and accurate false positive reduction in pulmonary nodule detection. </LI> <LI>  We introduce a fully automatic non-nodule categorization by utilizing an autoencoder and k-means clustering to extend the learning capability of our network. </LI> <LI>  The proposed framework utilizes 2D patches to improve memory usage and computational efficiency without a decrease in performance. </LI> </UL> </P>"
전경 객체의 3차원 복원 정밀도 향상 기법 분석,2023,"['3차원 복원', '딥러닝', '배경 제거', '전경 분리', 'Three-dimensional reconstruction', 'Deep learning', 'Background removal', 'Foreground matting']","딥러닝 기술의 발전으로 2차원 영상으로부터 3차원 정보를 정밀하게 생성함으로써 높은 품질의 3차원 복원을 수행하는 기술이 발전하고 있다. 3차원 복원 기술이 일반적으로 갖는 느린 학습 속도의 단점을 개선하기 위해 다양한 연구가 진행되고 있다. 또한, 전경의 3차원 복원 정밀도를 향상시키기 위한 연구가 다양하게 시도되고 있다. 본 논문에서는 배경 영역을 제거하여 전경 영역만을 분리했을 때의 3차원 복원을 세분하여 정량적 및 정성적으로 비교·분석하였다. 실험 결과를 토대로 충분한 외관 특징이 확보 가능한 전경에 대해서 전경을 분리하여 학습하는 것과 학습 영상이 부족한 환경에 대해서 전경 영역을 선택적으로 학습하는 것이 효과적임을 확인했다.","Due to the rapid advancement of deep learning techniques, high-quality 3D reconstruction methods that generate precise 3D information from 2D images have been proposed. However, the long duration for model learning has been a major drawback of 3D reconstruction techniques, and many studies have been conducted to address this issue. In addition, there are many ongoing studies to enhance the precision of the 3D reconstruction for a foreground object. This paper conducts quantitative and qualitative comparisons and analyzes the 3D restoration of an object while matting the foreground areas but excluding the background areas from participating in the learning process. Based on experimental results, it has been noted that it is effective to separate foreground objects with sufficient visual features from background areas and to selectively train the foreground information in the condition of insufficient training data."
Boosting Proximal Dental Caries Detection via Combination of Variational Methods and Convolutional Neural Network,2018,[],국문 초록 정보 없음,"<P>Proximal dental caries are diagnosed using dental X-ray images. Unfortunately, the diagnosis of proximal dental caries is often stifled due to the poor quality of dental X-ray images. Therefore, we propose an automatic detection system to detect proximal dental caries in periapical images for the first time. The system comprises four modules: horizontal alignment of pictured teeth, probability map generation, crown extraction, and refinement. We first align the pictured teeth horizontally as a pre-process to minimize performance degradation due to rotation. Next, a fully convolutional network are used to produce a caries probability map while crown regions are extracted based on optimization schemes and an edge-based level set method. In the refinement module, the caries probability map is refined by the distance probability modeled by crown regions since caries are located near tooth surfaces. Also we adopt non-maximum suppression to improve the detection performance. Experiments on various periapical images reveal that the proposed system using a convolutional neural network (CNN) and crown extraction is superior to the system using a na < ve CNN.</P>"
CCN3 secretion is regulated by palmitoylation via ZDHHC22,2018,"['Palmitoylation', 'Secretion', 'CCN3', 'Zinc finger DHHC-type containing 22', 'Neuron']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Normal extracellular secretion of nephroblastoma overexpressed (NOV, also known as CCN3) is important for the adhesion, migration, and differentiation of cells. In previous studies, we have shown that the intracellular accumulation of CCN3 inhibits the growth of prominent neurons. Increased intracellular CCN3 can be induced through various processes, such as transcription, detoxification, and posttranslational modification. In general, posttranslational modifications are very important for protein secretion. However, it is unclear whether posttranslational modification is necessary for CCN3 secretion. In this study, we have conducted mutational analysis of CCN3 to demonstrate that its thrombospondin type-1 (TSP1) domain is important for CCN3 secretion and intracellular function. Point mutation analysis confirmed that CCN3 secretion was inhibited by cysteine (C)241 mutation, and overexpression of CCN3-C241A inhibited neuronal axonal growth <I>in vivo</I>. Furthermore, we demonstrated that palmitoylation is important for the extracellular secretion of CCN3 and that zinc finger DHHC-type containing 22 (ZDHHC22), a palmityoltransferase, can interact with CCN3. Taken together, our results suggest that palmitoylation by ZDHHC22 at C241 in the CCN3 TSP1 domain may be required for the secretion of CCN3. Aberrant palmitoylation induces intracellular accumulation of CCN3, inhibiting neuronal axon growth.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The CCN3 thrombospondin type-1 (TSP1) domain is required for its secretion. </LI> <LI>  The TSP1 domain is also involved in CNN3 intracellular function. </LI> <LI>  Residue C241 is important for CNN3 secretion, but not its intracellular function. </LI> <LI>  Palmitoylation at C241 is necessary for CCN3 secretion. </LI> <LI>  Zinc finger DHHC-type containing 22 interacts with CCN3. </LI> </UL> </P>"
인공신경망 기반의 Decolorization 파라메터 자동 결정 방법,2018,[],국문 초록 정보 없음,"In this paper, we propose a method to find optimal parameters for decolorization using convolutional neural networks. Decolorization is a technique for converting color images into gray images. The conventional decolorization methods have a problem that the parameter can not be determined automatically. The proposed method automatically finds optimal parameters with a deep neural network. In the experiment, the proposed method generates a visually pleasing gray image compared to the conventional method."
키넥트 깊이 정보와 컨볼루션 신경망을 이용한 개별 돼지의 탐지,2018,"['개별 돼지 탐지', '키넥트 깊이정보', '컨볼루션 신경망', '욜로', 'Individual Pig Detection', 'Kinect Depth Information', 'Convolutional Neural Network', 'YOLO']","혼잡한 돈방에서 사육되는 이유자돈들의 공격적인 이상행동들은 축산농가의 경제적 손실을 야기할 뿐만 아니라 동물복지입장에서도 바람직하지 않다. 이러한 문제점의 해결책으로, 최근 IT기반의 연구들이 소개되고 있으나 혼잡한 돈방에서의 돼지 객체 탐지는 여전히 도전적인 문제로 알려져 있다. 본 논문에서는 개별 돼지의 탐지를 위한 키넥트 카메라와 딥러닝 기반의 새로운 모니터링 시스템을 제안한다. 제안된 시스템은 다음과 같다. 1) 키넥트 카메라로부터 취득한 깊이 영상에서 배경 차영상 기법과 깊이 임계값을 이용하여 서있는 돼지만을 탐지한다, 2) 딥러닝 알고리즘 중 최근 가장 빠르고 높은 정확도를 보이는 YOLO(You Only Look Once)를 이용하여 서있는 돼지들을 탐지한다. 본 연구의 실험 결과에 의하면, 제안된 시스템은 경제적인 비용(저가의 키넥트 센서)과 시스템 정확도(평균 99.40% 객체 검출율과 탐지 정확도)로 개별 돼지 객체들을 실시간으로 탐지할 수 있음을 실험적으로 확인하였다.","Aggression among pigs adversely affects economic returns and animal welfare in intensive pigsties. Recently, some studies have applied information technology to a livestock management system to minimize the damage resulting from such anomalies. Nonetheless, detecting each pig in a crowed pigsty is still challenging problem. In this paper, we propose a new Kinect camera and deep learning-based monitoring system for the detection of the individual pigs. The proposed system is characterized as follows. 1) The background subtraction method and depth-threshold are used to detect only standing-pigs in the Kinect-depth image. 2) The standing-pigs are detected by using YOLO (You Only Look Once) which is the fastest and most accurate model in deep learning algorithms. Our experimental results show that this method is effective for detecting individual pigs in real time in terms of both cost-effectiveness (using a low-cost Kinect depth sensor) and accuracy (average 99.40% detection accuracies)."
픽셀단위 상대적 신뢰도와 일치상관계수를이용한 영상의 깊이 추정 알고리즘,2018,"['Convolutional Neural Network', 'Single Depth Image Estimation']",국문 초록 정보 없음,"In this paper, we describe an algorithm for extracting depth information from a single image based on CNN. When acquiring three-dimensional information from a single two-dimensional image using a deep-learning technique, it is difficult to accurately predict the edge portion of the depth image because it is a part where the depth changes abruptly. in this paper, we introduce the concept of pixel-wise confidence to take advantage of these characteristics. We propose an algorithm that estimates depth information from a highly reliable flat part and propagates it to the edge part to improve the accuracy of depth estimation."
Deep Learning을 위한 학습 의료영상 데이터셋 및 분석에 관한 연구,2018,[],"최근 의료 현장에 인공지능 기술의 도입이 가속화 되고 있다. 특히, 의료영상 분석 분야의 관련된 기시스템 및 소프트웨어의 패러다임을 변화시키고 있다. 본 연구는 인공지능 기술을 적용하기 위한 학습의료영상 구성을 제안하고 이를 기반으로 X-ray 영상 중 손 부위에 적용하여 오른손과 왼손을 판별하는 응용에 적용하였다. 그리고 Deep Learning Algorithm의 CNN을 개선하여 개발한 Advanced GoogLeNet를 적용하여 97%이상의 정확도를 보였다. 본 연구를 통해 얻어진 인공지능에 적용하기 위한 학습데이터 셋 구성과 개선된 알고리즘은 다양한 의료영상분석에 적용하고자 한다.",다국어 초록 정보 없음
메모리 추가 신경망을 이용한 희소 악성코드 분류,2018,"['Malware Classification', 'Visualization', 'Memory Augmented Neural Network']","악성코드의 수가 가파르게 증가하면서 기업 및 공공기관, 금융기관, 병·의원 등을 타깃으로 한 사이버 공격 피해사례가 늘어나고 있다. 이러한 흐름에 따라 학계와 보안 업계에서는 악성코드 탐지를 위한 다양한 연구를 진행하고 있다. 최근 들어서는 딥러닝을 비롯해 머신러닝 기법을 적용하는 형태의 연구가 많이 진행되는 추세다. 이 중 합성곱 신경망(CNN: Convolutional Neural Network), ResNet 등을 이용한 악성코드 분류 연구의 경우에는 기존의 분류 방법에 비해 정확도가 크게 향상된 것을 확인할 수 있다. 그러나 타깃 공격의 특징 중 하나는 사용된 악성코드가 불특정 다수를 상대로 광범위하게 퍼뜨리는 형태가 아닌, 특정 대상을 타깃으로 한 맞춤형 악성코드라는 점이다. 이러한 유형의 악성코드는 그 수가 많지 않기 때문에 기존에 연구되어온 머신러닝이나 딥러닝 기법을 적용하기에 한계가 있다. 본 논문은 타깃형 악성코드와 같이 샘플의 양이 부족한 상황에서 악성코드를 분류하는 방법에 대해 다루고 있다. 메모리가 추가된 신경망(MANN: Memory Augmented Neural Networks) 모델을 이용하였고 각 그룹별 20개의 소량 데이터로 구성되어 있는 악성코드 데이터셋에 대해 최대 97%까지 정확도로 분류할 수있음을 확인하였다.","As the number of malicious code increases steeply, cyber attack victims targeting corporations, public institutions, financial institutions, hospitals are also increasing. Accordingly, academia and security industry are conducting various researches on malicious code detection. In recent years, there have been a lot of researches using machine learning techniques including deep learning. In the case of research using Convolutional Neural Network, ResNet, etc. for classification of malicious code, it can be confirmed that the performance improvement is higher than the existing classification method. However, one of the characteristics of the target attack is that it is custom malicious code that makes it operate only for a specific company, so it is not a form spreading widely to a large number of users. Since there are not many malicious codes of this kind, it is difficult to apply the previously studied machine learning or deep learning techniques. In this paper, we propose a method to classify malicious codes when the amount of samples is insufficient such as targeting type malicious code. As a result of the study, we confirmed that the accuracy of 97% can be achieved even with a small amount of data by applying the Memory Augmented Neural Networks model."
Criticality Enhancement through Critical Discourse,2018,"['criticality', 'critical discourse analysis', 'EFL learners', 'critical thinking', 'internet news resources']",국문 초록 정보 없음,"This study was designed to explore criticality enhancement of EFL learners through reading with Critical Discourse Analysis (CDA). For the study, two pairs of articles were selected from four different news sources. Before CDA instruction, articles on the Sewol ferry disaster from the CNN.com and the Korea Times were used. After the CDA instruction, articles from the New York Times and the Korea Herald on President Park’s impeachment were used. The participants comprised 78 university students at a university of Gyeonggi-do. They took text analysis tests before and after CDA instructions. In the end, learners replied to 5 questions to inform any changes in their motivation, attitudes, criticality, interests, and class interaction. The findings indicated that learners’ critical analysis was clearly enhanced, though differently depending on the divisions of CDA. The findings of the questionnaire revealed that students’ motivation, criticality, interests and class interactions had changed."
Criticality Enhancement through Critical Discourse,2018,"['criticality', 'critical discourse analysis', 'EFL learners', 'critical thinking', 'internet news resources']",국문 초록 정보 없음,"This study was designed to explore criticality enhancement of EFL learners through reading with Critical Discourse Analysis (CDA). For the study, two pairs of articles were selected from four different news sources. Before CDA instruction, articles on the Sewol ferry disaster from the CNN.com and the Korea Times were used. After the CDA instruction, articles from the New York Times and the Korea Herald on President Park’s impeachment were used. The participants comprised 78 university students at a university of Gyeonggi-do. They took text analysis tests before and after CDA instructions. In the end, learners replied to 5 questions to inform any changes in their motivation, attitudes, criticality, interests, and class interaction. The findings indicated that learners’ critical analysis was clearly enhanced, though differently depending on the divisions of CDA. The findings of the questionnaire revealed that students’ motivation, criticality, interests and class interactions had changed. (Dankook University)"
Adjusting the Difficulty of Running Game with Facial Expression Recognition Technology Using Convolutional Neural Network,2018,"['Game Fun', 'Game Difficulty', 'Convolutional Neural Network', 'Expression Recognition']","이제는 모바일 마켓순위에서 많은 게임이 높은 점유율을 차지하지만 점유율을 오랫동안 유지하는 것은 쉽지 않다. 게이머를 끌어당기는 중요한 요소는 게임 재미(Game Fun)이고, 게임을 재미있게 만드는 가장 중요한 요소는 게임 난이도이다. 하지만 게임 난이도를 디자인하는 것은 매우 어려운 일이다.본 논문은 두 개의 연속적인 컨볼루셔널 레이어를 사용한 컨볼루셔널 신경망과 SVM 분류기를 이용하여 게임 시 플레이어의 얼굴 표정을 실시간으로 검출하고 판단한다. 실험 결론은 CNN을 이용한 표정 시스템은 게임 play-time 및 score를 늘릴 수 있고, 게임 재미를 증진시키기에 도와준다고 증명하였다.","Many games nowadays have a certain share of the market. However, to maintain the market position for long is not common. The most appealing element for gamers is Game Fun. The element that can make game interesting is the game difficulty. While the game difficulty has no uniform evaluation standard until now. The proposed paper uses a continuous convolutional neural network with SVM classifier to recognize the player s expression in real time. The system infers the player s psychological activity based on different expressions and makes adjustments to the game difficulty level to meet the user s needs. And the experiment result shows that the facial expression recognition system using deep learning could increase the play-time and score of the game, and promote the fun of games."
잡음 환경에 강인한 돼지 호흡기 질병 탐지,2018,[],"국내 축산 농가들은 대부분 돼지우리의 구역을 나눈 후 해당 구역별로 30여 마리의 돼지들을 합사하여 사육하고 있다. 따라서 전염성이 강한 호흡기 질병이 발병하게 되면 돼지우리 전체로 확산되어 심각한 피해가 발생하게 된다. 본 논문에서는 돼지우리에서 발생하는 다양한 소음에도 강인한 소리 기반의 호흡기 질병 탐지 시스템을 제안한다. 제안된 시스템은 먼저, 소리 신호에서 스펙트로그램 정보를 추출하고, 이를 CNN을 기반으로 돼지 호흡기 질병에 효과적인 특징 벡터를 생성한다. 마지막으로, 추출된 특징 벡터를 MLP에 적용하여 해당 호흡기 질병을 탐지 및 식별과정을 수행한다. 본 연구의 실험 결과, 다양한 잡음 환경에서도 돼지 호흡기 질병 탐지 및 식별이 가능함을 확인하였다.",다국어 초록 정보 없음
End to End 딥러닝 기반의 자율주행을 위한 실세계 환경을 반영한 가상 주행 데이터 수집 및 활용,2018,[],최근 인공지능 연구가 활발하게 진행이 되면서 여러 기업에서 자율 주행연구도 활발하게 진행되고 있다. 하지만 실제 상황에서 자동차 주행 데이터를 얻기에는 여러 위험사항들과 경제적인 낭비가 있다. 그렇기 때문에 게임 상에서 데이터를 수집하고 딥러닝을 이용해 학습을 하기로 했다. 본 논문에서는 실제 세계와 유사한 환경을 가지고 있는 자동차 게임을 이용하여 자율 주행을 시도 했다. 자율 주행 시 많이 쓰이는 End to End 방법으로 데이터를 수집하면 두 가지 데이터가 저장된다. 하나는 이미지 데이터고 두 번째는 방향키 데이터다. 이러한 데이터들을 numpy 타입으로 40분간 데이터를 수집한 후 딥러닝에 많이 쓰이는 tensorflow를 사용하여 구현한 CNN을 이용하여 학습이 되는 것을 확인을 하고 91.9%의 정확도를 얻었다. 이를 기반으로 실세계에서의 사용 가능성을 확인했다.,다국어 초록 정보 없음
준 지도학습과 여러 개의 딥 뉴럴 네트워크를 사용한 멀티 모달 기반 감정 인식 알고리즘,2018,"['Emotion recognition', 'Multi-task learning', 'Semi-supervised learning', 'Multi modal signal', 'EmotiW 2017 challenge']",국문 초록 정보 없음,"Human emotion recognition is a research topic that is receiving continuous attention in computer vision and artificial intelligence domains. This paper proposes a method for classifying human emotions through multiple neural networks based on multi-modal signals which consist of image, landmark, and audio in a wild environment. The proposed method has the following features. First, the learning performance of the image-based network is greatly improved by employing both multi-task learning and semi-supervised learning using the spatio-temporal characteristic of videos. Second, a model for converting 1-dimensional (1D) landmark information of face into two-dimensional (2D) images, is newly proposed, and a CNN-LSTM network based on the model is proposed for better emotion recognition. Third, based on an observation that audio signals are often very effective for specific emotions, we propose an audio deep learning mechanism robust to the specific emotions. Finally, so-called emotion adaptive fusion is applied to enable synergy of multiple networks. The proposed network improves emotion classification performance by appropriately integrating existing supervised learning and semi-supervised learning networks. In the fifth attempt on the given test set in the EmotiW2017 challenge, the proposed method achieved a classification accuracy of 57.12%."
"Integrated neural network model for identifying speech acts, predicators, and sentiments of dialogue utterances",2018,"['Integrated intention identification model', 'Speech act identification', 'Predicator identification', 'Sentiment identification', 'Partial error backpropagation']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>A dialogue system should capture speakers’ intentions, which can be represented by combinations of speech acts, predicators, and sentiments. To identify these intentions from speakers’ utterances, many studies have independently dealt with speech acts, predicators, and sentiments. However, these three elements composing speakers’ intentions are tightly associated with each other. To resolve this problem, we propose a convolutional neural network model that simultaneously identifies speech acts, predicators, and sentiments. The proposed model has well-designed hidden layers for embedding informative abstractions appropriate for speech act identification, predicator identification, and sentiment identification. Nodes in the hidden layers are partially trained by three cycles of error backpropagation: training the nodes associated with speech act identification, predicator identification, and sentiment identification. In the experiments, the proposed model showed higher F1-scores than independent models: 6.8% higher in speech act identification, 6.2% higher in predicator identification, and 4.9% higher in sentiment identification. Based on the experimental results, we conclude that the proposed integration architecture and partial error backpropagation can help to increase the performance of intention identification.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  CNN-based integration model for simultaneously identifying speech acts, predicators, and sentiments. </LI> <LI>  A new layout of hidden nodes for effective integration. </LI> <LI>  Better performance than independent identification models. </LI> </UL> </P>"
이종의 OCT 기기로부터 생성된 볼륨 데이터로부터 심층 컨볼루션 신경망을 이용한 AMD 진단,2018,"['OCT', '노년기황반변성(AMD)', '기계 학습', '컨볼루션 신경망', '이미지 분할', 'Optical Coherence Tomography', 'Age-Related Macular Degeneration', 'Machine Learning', 'Convolutional Neural Network', 'Image Segmentation']",신경망을 이용하여 OCT 영상을 분석하고 다양한 망막 질환을 자동 진단하는 것에 관한 연구들이 활발하게 이루어지고 있다. 이러한 연구가 현실에 적용되기 위한 하나의 중요한 요건은 학습된 신경망이 학습에 사용된 데이터와는 다른 기기에서 생성된 데이터에 대해서도 성능의 큰 하락 없이 일반화될 수 있어야 한다는 것이다.본 논문에서는 심층 CNN을 이용하여 OCT 영상으로부터 노년기황반변성(AMD)을 자동 진단하는 것을 다룬다. 하나의 OCT 기기로부터 획득한 데이터 셋을 이용하여 신경망을 학습시킨 후 다른 OCT 기기로부터 생산된 이미지를 테스트한 결과 상당한 성능의 하락을 관찰할 수 있었다. 이러한 성능의 하락을 방지하기 위해서 OCT 이미지를 정규화 하는 기법을 제안하고 실험을 통해 그 효과를 분석하였다. 제안한 기법은 OCT 이미지를 분할하여 망막에 해당하는 영역을 찾아낸 후 이미지 내에서 망막 영역이 수평에 가까운 기울기를 가지도록 정렬(align)하여 형태적인 측면에서 OCT 이미지를 정규화 하는 것을 목적으로 한다. 실험을 통하여 제안한 기법이 이종의 기기에서 생성된 OCT 이미지로부터 AMD를 자동진단 하는데 있어서 상당한 성능의 향상을 달성함을 보였다.,"There have been active research activities to use neural networks to analyze OCT images and make medical decisions. One requirement for these approaches to be promising solutions is that the trained network must be generalized to new devices without a substantial loss of performance. In this paper, we use a deep convolutional neural network to distinguish AMD from normal patients.The network was trained using a data set generated from an OCT device. We observed a significant performance degradation when it was applied to a new data set obtained from a different OCT device. To overcome this performance degradation, we propose an image normalization method which performs segmentation of OCT images to identify the retina area and aligns images so that the retina region lies horizontally in the image. We experimentally evaluated the performance of the proposed method. The experiment confirmed a significant performance improvement of our approach."
An Application of Machine Vision on Identification of Sugarcane Nodes,2018,"['Sugarcane', 'Image Classification', 'Real-time Recognition', 'R-CNN']",국문 초록 정보 없음,"Due to labor shortage, modern agriculture goes up on automation gradually, the planting of sugarcane is no exception. If the automatic planting machine is used, sugarcane seedlings should be prepared in advance. A sugarcane node is the main place where bud is grown from. The existing sugarcane node cutting machines rely on human judgement to determine the node locations. There are time-consuming and laborious to collect the sugarcane nodes. This study intends to use machine vision to identify sugarcane nodes for developing automatic machine. The two algorithms of R-CNN and FASTER R-CNN were used to identify sugarcane node and to compare their performance. The R-CNN algorithm is usually used for the identification of multiple targets, and its accuracy is less than FASTER R-CNN, but the processing speed is faster. In this study, 530 sugarcane photos (1300 nodes) were analyzed, 400 and 130 sugarcane photos were selected as the calibration and validation groups, respectively. The experimental results show that the processing time of the R-CNN can be completed within 0.02 sec with the identification rate of 97.9%, and the processing time and identification rate of the FASTER R-CNN are similar to those of the R-CNN. The both algorithms have good results, and can be applied to the development of automated sugarcane node cutting machines."
Computed tomography super-resolution using deep convolutional neural network,2018,[],국문 초록 정보 없음,"<P>The objective of this study is to develop a convolutional neural network (CNN) for computed tomography (CT) image super-resolution. The network learns an end-to-end mapping between low (thick-slice thickness) and high (thin-slice thickness) resolution images using the modified U-Net. To verify the proposed method, we train and test the CNN using axially averaged data of existing thin-slice CT images as input and their middle slice as the label. Fifty-two CT studies are used as the CNN training set, and 13 CT studies are used as the test set. We perform five-fold cross-validation to confirm the performance consistency. Because all input and output images are used in two-dimensional slice format, the total number of slices for training the CNN is 7670. We assess the performance of the proposed method with respect to the resolution and contrast, as well as the noise properties. The CNN generates output images that are virtually equivalent to the ground truth. The most remarkable image-recovery improvement by the CNN is deblurring of boundaries of bone structures and air cavities. The CNN output yields an approximately 10% higher peak signal-to-noise ratio and lower normalized root mean square error than the input (thicker slices). The CNN output noise level is lower than the ground truth and equivalent to the iterative image reconstruction result. The proposed deep learning method is useful for both super-resolution and de-noising.</P>"
딥러닝 기술을 활용한 멀웨어 분류를 위한 이미지화 기법,2018,"['멀웨어 이미지 생성', '멀웨어 탐지 및 분류', '딥러닝', 'CNN', 'Malware visualization', 'mawlare detection and classification', 'deep learning']","Symantec의 인터넷 보안위협 보고서(2018)에 따르면 크립토재킹, 랜섬웨어, 모바일 등 인터넷 보안위협이 급증하고 있으며 다각화되고 있다고 한다. 이는 멀웨어(Malware) 탐지기술이 암호화, 난독화 등의 문제에 따른 질적 성능향상 뿐만 아니라 다양한 멀웨어의 탐지 등 범용성을 요구함을 의미한다. 멀웨어 탐지에 있어 범용성을 달성하기 위해서는 탐지알고리즘에 소모되는 컴퓨팅 파워, 탐지 알고리즘의 성능 등의 측면에서의 개선 및 최적화가 이루어져야 한다. 본고에서는 최근 지능화, 다각화 되는 멀웨어를 효과적으로 탐지하기 위하여 CNN(Convolutional Neural Network)을 활용한 멀웨어 탐지 기법인, stream order(SO)-CNN과 incremental coordinate(IC)-CNN을 제안한다. 제안기법은 멀웨어 바이너리 파일들을 이미지화 한다. 이미지화 된 멀웨어 바이너리는 GoogLeNet을 통해 학습되어 딥러닝 모델을 형성하고 악성코드를 탐지 및 분류한다. 제안기법은 기존 방법에 비해 우수한 성능을 보인다.","According to Symantec's Internet Security Threat Report(2018), Internet security threats such as Cryptojackings, Ransomwares, and Mobile malwares are rapidly increasing and diversifying. It means that detection of malwares requires not only the detection accuracy but also versatility. In the past, malware detection technology focused on qualitative performance due to the problems such as encryption and obfuscation. However, nowadays, considering the diversity of malware, versatility is required in detecting various malwares. Additionally the optimization is required in terms of computing power for detecting malware. In this paper, we present Stream Order(SO)-CNN and Incremental Coordinate(IC)-CNN, which are malware detection schemes using CNN(Convolutional Neural Network) that effectively detect intelligent and diversified malwares. The proposed methods visualize each malware binary file onto a fixed sized image. The visualized malware binaries are learned through GoogLeNet to form a deep learning model. Our model detects and classifies malwares. The proposed method reveals better performance than the conventional method."
심층신경망 기반 총채벌레 탐색에 관한 연구,2018,"['객체 탐색', '볼록총채벌레', '빠른 지역기반 객체 탐색', '심층신경망', '합성곱 신경망', 'Convolutinal network', 'deep learning', 'Faster R-CNN', 'object detection', 'Scirtothrips dorsalis Hood']","최근 감귤농업에서 주요해층으로 분류되는 미소 객체 (tiny object)인 볼록총채벌레 (Scirtothrips dorsalis Hood)의 탐색은 관심이 많고 어려운 작업으로 알려져 있다. 본 논문에서는 심층신경망을 이용하여 볼록총채벌레를 탐색 (detection)하고자 한다. 분석자료는 황색끈끈이트랩 이미지자료 (250×150mm, 5472×3648픽셀)이며 합성곱 신경망 (convolutional neural network, CNN)인 ResNet을 기반으로 하는 Faster R-CNN (faster regions with CNN) 탐색모형을 사용하였다. 이미지넷(ImageNet)을 사전 학습한 가중치를 사용하고 초모수 (hyperparameter)를 격자탐색법(grid search)으로 선택한 모형을 제안한다. 제안된 모형의 AUC (area under curve)는 0.91로 아주 좋은 결과를 보이는데, 제안된 모형으로 볼록총채벌레의 생태를 파악하여 보다 더 정밀한 방제가 이뤄질 수 있을 것으로 기대한다.","In this paper, we study on a detection of Scirtothrips dorsalis Hood, which is classified as a major insect in citrus farming. The detection is based on the deep neural networks, specifically the Faster R-CNN (faster regions with CNN) model based on CNN (convolutional neural network), with the yellow sticky trap image data (250×150mm, 5472×3648pixels). It was found that the model performance becomes unstable when the object is too small and rare. In order to solve this problem, we use pretrained weights to set the initial value of the model, as well as we select hyperparameters by grid search. Result shows that our proposed model has an high AUC (area under curve) value 0.91. We expect that it would be possible to know more precisely the lifespan of the Scirtothrips dorsalis Hood and to control them more precisely through our proposed model."
Geometric Convolutional Neural Network for Analyzing Surface-Based Neuroimaging Data,2018,"['cortical thickness', 'surface-based analysis', 'geometric convolutional neural network', 'sex differences', 'Machine learning', 'neuroimage']",국문 초록 정보 없음,"<P>In machine learning, one of the most popular deep learning methods is the convolutional neural network (CNN), which utilizes shared local filters and hierarchical information processing analogous to the brain’s visual system. Despite its popularity in recognizing two-dimensional (2D) images, the conventional CNN is not directly applicable to semi-regular geometric mesh surfaces, on which the cerebral cortex is often represented. In order to apply the CNN to surface-based brain research, we propose a geometric CNN (gCNN) that deals with data representation on a mesh surface and renders pattern recognition in a multi-shell mesh structure. To make it compatible with the conventional CNN toolbox, the gCNN includes data sampling over the surface, and a data reshaping method for the convolution and pooling layers. We evaluated the performance of the gCNN in sex classification using cortical thickness maps of both hemispheres from the Human Connectome Project (HCP). The classification accuracy of the gCNN was significantly higher than those of a support vector machine (SVM) and a 2D CNN for thickness maps generated by a map projection. The gCNN also demonstrated position invariance of local features, which rendered reuse of its pre-trained model for applications other than that for which the model was trained without significant distortion in the final outcome. The superior performance of the gCNN is attributable to CNN properties stemming from its brain-like architecture, and its surface-based representation of cortical information. The gCNN provides much-needed access to surface-based machine learning, which can be used in both scientific investigations and clinical applications.</P>"
Detection and diagnosis of dental caries using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Dental caries', 'Machine learning', 'Supervised machine learning']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P><B>Objectives</B></P> <P>Deep convolutional neural networks (CNNs) are a rapidly emerging new area of medical research, and have yielded impressive results in diagnosis and prediction in the fields of radiology and pathology. The aim of the current study was to evaluate the efficacy of deep CNN algorithms for detection and diagnosis of dental caries on periapical radiographs.</P>   <P><B>Materials and methods</B></P> <P>A total of 3000 periapical radiographic images were divided into a training and validation dataset (<I>n</I> = 2400 [80%]) and a test dataset (<I>n</I> = 600 [20%]). A pre-trained GoogLeNet Inception v3 CNN network was used for preprocessing and transfer learning. The diagnostic accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, and area under the curve (AUC) were calculated for detection and diagnostic performance of the deep CNN algorithm.</P>   <P><B>Results</B></P> <P>The diagnostic accuracies of premolar, molar, and both premolar and molar models were 89.0% (80.4–93.3), 88.0% (79.2–93.1), and 82.0% (75.5–87.1), respectively. The deep CNN algorithm achieved an AUC of 0.917 (95% CI 0.860–0.975) on premolar, an AUC of 0.890 (95% CI 0.819–0.961) on molar, and an AUC of 0.845 (95% CI 0.790–0.901) on both premolar and molar models. The premolar model provided the best AUC, which was significantly greater than those for other models (<I>P</I> < 0.001).</P>   <P><B>Conclusions</B></P> <P>This study highlighted the potential utility of deep CNN architecture for the detection and diagnosis of dental caries. A deep CNN algorithm provided considerably good performance in detecting dental caries in periapical radiographs.</P>   <P><B>Clinical signiﬁcance</B></P> <P>Deep CNN algorithms are expected to be among the most effective and efficient methods for diagnosing dental caries.</P>"
기두부와 단 분리 시 조각의 식별을 위한 합성곱 신경망 구조 설계,2018,"['dynamic RCS', 'convolutional neural networks', 'radar target identification', 'warhead', 'debris']",국문 초록 정보 없음,"In this paper, we designed CNN(Convolutional Neural Network) structure to identify warhead and debris in boosting part separation phase. Through simulation, we determined variables of each layer constituting the CNN and designed CNN structure. Simulation were performed to classify four types of warhead with coning motion and six types of debris with tumbling motion through the CNN designed by the proposed method. Then we compared the performance of CNN with the well-known VGGNet. Simulation results show that the CNN structure optimized by the convolution filter, pooling method, and pooling size determined using the proposed method has equal classification performance or better classification performance than VGGNet for all SNR. In addition, the training time was improved approximately 22 times."
딥러닝을 위한 영역기반 합성곱 신경망에 의한 항공영상에서 건물탐지 평가,2018,"['Deep Learning', 'Region-based Convolutional Neural Network', 'Object Detection', 'Semantic Segmentation', '딥러닝', '역기반 합성곱 신경망', '객체탐지', '의미적 분할']","딥러닝은 인간의 학습 및 인지능력을 닮은 인공지능을 실현하기 위해 여러 분야에서 활용하고 있으며, 높은 사양 의 컴퓨팅 파워가 요구되고 연산 시간이 많이 소요되는 복잡한 구조의 인공신경망에 의한 딥러닝은 컴퓨터 사양이 향상됨에 따라 성능이 개선된 다양한 딥러닝 모델이 개발되고 있다. 본 논문의 주요 목적은 상의 딥러닝을 위한 합성곱 신경망 중에서 최근에 FAIR (Facebook AI Research)에서 개발한 Mask R-CNN을 이용하여 항공상에서 건물을 탐지하고 성능을 평가하는 것이다. Mask R-CNN은 역기반의 합성곱 신경망으로서 픽셀 정확도까지 객 체를 의미적으로 분할하기 위한 딥러닝 모델로서 성능이 가장 우수한 것으로 평가받고 있다. 딥러닝 모델의 성능은 신경망 구조뿐 아니라 학습 능력에 의해 결정된다. 이를 위해 본 논문에서는 모델의 학습에 이용한 상에 다양한 변화를 주어 학습 능력을 분석하으며, 딥러닝의 궁극적 목표인 범용화의 가능성을 평가하다. 향후 연구방안으 로는 상에만 의존하지 않고 다양한 공간정보 데이터를 복합적으로 딥러닝 모델의 학습에 이용하여 딥러닝의 신 뢰성과 범용화가 향상될 것으로 판단된다.","DL (Deep Learning) is getting popular in various fields to implement artificial intelligence that resembles human learning and cognition. DL based on complicate structure of the ANN (Artificial Neural Network) requires computing power and computation cost. Variety of DL models with improved performance have been developed with powerful computer specification. The main purpose of this paper is to detect buildings from aerial images and evaluate performance of Mask R-CNN (Region-based Convolutional Neural Network) developed by FAIR (Facebook AI Research) team recently. Mask R-CNN is a R-CNN that is evaluated to be one of the best ANN models in terms of performance for semantic segmentation with pixel-level accuracy. The performance of the DL models is determined by training ability as well as architecture of the ANN. In this paper, we characteristics of the Mask R-CNN with various types of the images and evaluate possibility of the generalization which is the ultimate goal of the DL. As for future study, it is expected that reliability and generalization of DL will be improved by using a variety of spatial information data for training of the DL models."
깊이맵 생성 알고리즘의 합성곱 신경망 구현,2018,"['Depth map', 'CNN', 'Saliency map', 'Motion Hitsory Image', 'Ready-made depth map']",국문 초록 정보 없음,"Depth map has been utilized in a varity of fields. Recently research on generating depth map by artificial neural network (ANN) has gained much interest. This paper validates the feasibility of implementing the ready-made depth map generation by convolutional neural network (CNN). First, for a given image, a depth map is generated by the weighted average of a saliency map as well as a motion history image. Then CNN network is trained by test images and depth maps. The objective and subjective experiments are performed on the CNN and showed that the CNN can replace the ready-made depth generation method."
합성곱 신경망을 사용한 화물차의 차종분류,2018,"['Vehicle Classification', 'Truck Cargo Box', 'Image Classification', 'Convolutional Neural Network', 'Machine Learning', '차종분류', '화물차 적재함', '영상분류', '합성곱 신경망', '기계학습']","본 논문에서는 화물차 차종을 분류하기 위해서 특징추출단계 없이 입력영상으로부터 차종분류결과를 얻을 수 있는 합성곱 신경망을 사용한 분류방법을 제안한다. 차량의 위에서 촬영된 영상을 입력으로 사용하고 입력영상에 적합한 합성곱 신경망의 구조를 설계한다. 차종과 화물칸의 형태에 따라 차종을 자동 분류하기 위한 학습데이터를 생성하고 지도학습의 형태로 학습시키기 위해 분류된 영상과 올바른 출력결과를 제시하여 신경망의 가중치를 학습시킨다. 실제 영상을 입력하여 합성곱 신경망의 출력을 계산하였고 실제 차종과의 비교를 통해 분류 성능을 평가 하였다. 실험결과 화물의 차종과 적재함의 형태에 따라 90%이상의 정확도로 영상을 분류할 수 있었고, 적재불량 검사의 사전 분류에 활용될 수 있다.","This paper proposes a classification method using the Convolutional Neural Network(CNN) which can obtain the type of trucks from the input image without the feature extraction step. To automatically classify vehicle images according to the type of truck cargo box, the top view images of the vehicle are used as input image and we design the structure of the CNN suitable for the input images. Learning images and correct output results is generated and the weights of neural network are obtained through the learning process. The actual image is input to the CNN and the output of the CNN is calculated. The classification performance is evaluated through comparison CNN output with actual vehicle types. Experimental results show that vehicle images could be classified with more than 90 percent accuracy according to the type of cargo box and this method can be used for pre-classification for inspecting loading defect."
Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Machine learning', 'Periodontal diseases', 'Supervised machine learning']",국문 초록 정보 없음,"Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%-91.2%) for premolars and 73.4% (95% CI, 59.9%-84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT."
Iceberg-Ship Classification in SAR Images Using Convolutional Neural Network with Transfer Learning,2018,"['Convolutional Neural Network', 'Deep Learning', 'Transfer Learning', 'VGG-16', 'Pooling Layer', 'Adam Optimizer', 'Data Augmentation']",국문 초록 정보 없음,"Monitoring through Synthesis Aperture Radar (SAR) is responsible for marine safety from floating icebergs. However, there are limits to distinguishing between icebergs and ships in SAR images. Convolutional Neural Network (CNN) is used to distinguish the iceberg from the ship. The goal of this paper is to increase the accuracy of identifying icebergs from SAR images. The metrics for performance evaluation uses the log loss. The two-layer CNN model proposed in research of C.Bentes et al.[1] is used as a benchmark model and compared with the four-layer CNN model using data augmentation. Finally, the performance of the final CNN model using the VGG-16 pre-trained model is compared with the previous model. This paper shows how to improve the benchmark model and propose the final CNN model."
Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm,2018,"['Artificial intelligence', 'Machine learning', 'Periodontal diseases', 'Supervised machine learning']",국문 초록 정보 없음,"Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%–91.2%) for premolars and 73.4% (95% CI, 59.9%–84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT."
Automatic Fish Species Identification using Convolutional Neural Networks,2018,"['Fish species identification', 'Convolutional neural networks', 'Transfer learning']",국문 초록 정보 없음,"Fish is a worldwide major food source. In recent years, overfishing has become a serious problem. Overfishing exhausts fish resources, endangers some fish species, and also threatens the entire marine food chain. Hence, organizations put regulations to prevent overfishing. Typically, the species of the fish caught are recorded and reported by ocean observers. However, the manual reporting method is laborious and time-consuming. This study proposed to recognize fish species from images automatically using deep convolutional neural networks (CNN). A first deep CNN was used to identify fish types (e.g., tuna, marlin, shark, and other). A second deep CNN was used to distinguish species of tuna fish, including Thunnus alalunga (Albacore), Thunnus obesus (Bigeye tuna), Thunnus albacares (Yellowfin tuna). A third deep CNN was used to determine the species of marlin fish, including Makaira nigricans (Atlantic blue marlin), Istiophorus platypterus (Indo-Pacific sailfish), Xiphias gladius (Swordfish). Each deep CNN was a fine-tuned VGG-16 model. The experimental results showed that the proposed method reached an average accuracy of 97.9%."
Evaluation of Deep Learning Convolution Neural Network Models to Develop Real-Time Expressway Pavement Distress Detection System,2018,"['Deep Learning', 'CNN Models', 'Real-Time', 'Pavement Distress Detection', 'Pothole', 'Spalling']",국문 초록 정보 없음,"Three CNN (Convolutional Neural Network) models of GoogLeNet, VGGNet, and Alexnet were evaluated to select the best deep learning based image analysis mothod that can detect pavement distresses of pothole, spalling, and punchout on expressway. Education data was obtained using pavement surface images of 11,056km length taken by Gopro camera equipped with an expressway patrol car. Also, deep learning framework of Caffe developed by Berkeley Vision and Learning Center was evaluated to use the three CNN models with other frameworks of Tensorflow developed by Google, and CNTK developed by Microsoft. After determing the optimal CNN model applicable for the distress detection, the analyzed images and corresponding GPS locations, distress sizes (greater than distress length of 150mm), required repair material quantities are trasmitted to local maintenance office using LTE wireless communication system through ICT center in Korea Expressway Corporation. It was found out that the GoogLeNet, AlexNet, and VGG-16 models coupled with the Caffe framework can detect pavement distresses by accuracy of 93%, 86%, and 72%, respectively. In addition to four distress image groups of cracking, spalling, pothole, and punchout, 22 different image groups of lane marking, grooving, patching area, joint, and so on were finally classified to improve the distress detection rate."
심층 학습을 이용한 양식장 그물 찢김 판단,2018,"['smart fishery', 'deep learning', 'convolutional neural networks (CNN)', 'fish farming', 'data augmentation']",국문 초록 정보 없음,"Damage in fish farming nets can lead to serious losses and/or adverse environmental impact. Nonetheless, detecting such damage is challenging. Human experts could inspect the nets, but this process is costly and time-consuming. Alternatively, remotely operated underwater vehicles (ROV) can be used to inspect the fishnets. By using advanced deep-learning techniques for autonomous navigation and object detection, fishnets can be inspected efficiently while minimizing human intervention. In this paper, a deep convolutional neural networks (CNN) is employed to classify images of torn and normal fishnets. Training deep CNN models requires numerous image data, whereas a limited amount of fishnet images are available. To resolve the dearth of available data, data-augmentation techniques are adopted to generate images of torn and normal fishnets. The trained CNN model shows high accuracy for classifying the given augmented test dataset."
Convolutional Neural Network Based Image Processing System,2018,"['Artificial intelligence', 'Convolutional neural network (CNN)', 'Deep learning', 'Pattern recognition']",국문 초록 정보 없음,"This paper designed and developed the image processing system of integrating feature extraction and matching by using convolutional neural network (CNN), rather than relying on the simple method of processing feature extraction and matching separately in the image processing of conventional image recognition system. To implement it, the proposed system enables CNN to operate and analyze the performance of conventional image processing system. This system extracts the features of an image using CNN and then learns them by the neural network. The proposed system showed 84% accuracy of recognition. The proposed system is a model of recognizing learned images by deep learning. Therefore, it can run in batch and work easily under any platform (including embedded platform) that can read all kinds of files anytime. Also, it does not require the implementing of feature extraction algorithm and matching algorithm therefore it can save time and it is efficient. As a result, it can be widely used as an image recognition program."
Multiclass classification of obstructive sleep apnea/hypopnea based on a convolutional neural network from a single-lead electrocardiogram,2018,[],국문 초록 정보 없음,"<P> <I>Objective</I>: In this paper, we propose a convolutional neural network (CNN)-based deep learning architecture for multiclass classification of obstructive sleep apnea and hypopnea (OSAH) using single-lead electrocardiogram (ECG) recordings. OSAH is the most common sleep-related breathing disorder. Many subjects who suffer from OSAH remain undiagnosed; thus, early detection of OSAH is important. <I>Approach</I>: In this study, automatic classification of three classes—normal, hypopnea, and apnea—based on a CNN is performed. An optimal six-layer CNN model is trained on a training dataset (45 096 events) and evaluated on a test dataset (11 274 events). The training set (69 subjects) and test set (17 subjects) were collected from 86 subjects with length of approximately 6 h and segmented into 10 s durations. <I>Main results</I>: The proposed CNN model reaches a mean <img ALIGN='MIDDLE' ALT='' SRC='http://ej.iop.org/images/0967-3334/39/6/065003/pmeaaac7b7ieqn001.gif'/>-score of 93.0 for the training dataset and 87.0 for the test dataset. <I>Significance</I>: Thus, proposed deep learning architecture achieved a high performance for multiclass classification of OSAH using single-lead ECG recordings. The proposed method can be employed in screening of patients suspected of having OSAH.</P>"
Building cellular neural network templates with a hardware friendly learning algorithm,2018,"['Cellular neural network', 'Cloning templates', 'Random weight change']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>A general solution for the construction of Cellular Neural Network (CNN) weights (cloning template) with Random Weight Change (RWC) algorithm is proposed. A target image for each input image is prepared via a sketch or any other kind of image processing technique for learning of Cellular Neural Network templates. A vector of randomly generated small values is added to the original weights and tested upon the input-target image pair. As a result, if the learning error decreases, the weight is taken for learning in the next iteration and updated using the same vector of random values. Otherwise, a new random vector for updating the weights is regenerated. One of the strong benefits of the proposed weight learning method is the simplicity of its learning algorithm and hence a simpler hardware architecture. Moreover the proposed method provides a unified solution to the problem of learning CNN templates without having to modify the original CNN structure and is applicable for all types of CNNs and input images. Successful learning of templates for various image processing tasks using different CNN structures are also demonstrated in this paper.</P>"
전이학습에 방법에 따른 컨벌루션 신경망의영상 분류 성능 비교,2018,"['Deep Learning', 'Computer Vision', 'Convolutional Neural Network', 'Transfer Learnin']",국문 초록 정보 없음,"Core algorithm of deep learning Convolutional Neural Network(CNN) shows better performance than other machine learning algorithms. However, if there is not sufficient data, CNN can not achieve satisfactory performance even if the classifier is excellent. In this situation, it has been proven that the use of transfer learning can have a great effect. In this paper, we apply two transition learning methods(freezing, retraining) to three CNN models(ResNet-50, Inception-V3, DenseNet-121) and compare and analyze how the classification performance of CNN changes according to the methods. As a result of statistical significance test using various evaluation indicators, ResNet-50, Inception-V3, and DenseNet-121 differed by 1.18 times, 1.09 times, and 1.17 times, respectively. Based on this, we concluded that the retraining method may be more effective than the freezing method in case of transition learning in image classification problem."
데이터 기반 영역 제안 및 심층 학습 분류 네트워크를 이용한 소형 적외선 드론 검출,2018,"['infrared small target detection', 'infrared small drone detection', 'deep learning', 'region proposal', 'classification']",국문 초록 정보 없음,"In this paper, we propose a data-driven and deep-learning based classification scheme for small infrared target detection. Previous studies have shown feasible performance using conventional computer vision techniques, such as spatial and temporal filters. However, those handcrafted approaches are not optimized due to the nature of the application fields. Recently, deep-learning has shown excellent performance for many computer vision problems. The proposed data-driven proposal and convolutional neural network (DDP-CNN) approach can generate possible target locations through the DDP, and final targets are recognized through the CNN for classification. According to the experimental results using drone databases, the DDP-CNN shows an 0.85 average precision (AP) of target detection."
딥러닝 기반 기사단위 및 문단 단위별 분류,2018,"['Genre Classification', 'Deep Learning', 'Word2Vec', 'Long Short-Term Memory (LSTM)', 'Gated Recurrent Unit (GRU)', 'Convolutional Neural Networks (CNN)', 'Word embedding']",국문 초록 정보 없음,"Text classification has been studied for a long time in the Natural Language Processing field. In this paper, we propose an article- and paragraph-level genre classification system using Word2Vec-based LSTM, GRU, and CNN models for large-scale English corpora. Both article- and paragraph-level classification performed best in accuracy with LSTM, which was followed by GRU and CNN in accuracy performance. Thus, it is to be confirmed that in evaluating the classification performance of LSTM, GRU, and CNN, the word sequential information for articles is better than the word feature extraction for paragraphs when the pre-trained Word2Vec-based word embeddings are used in both deep learning-based article- and paragraph-level classification tasks."
합성곱 신경망을 위한 커널별 일정하지 않은 정밀도를 지원하는 연산 블록 구조 설계,2018,[],국문 초록 정보 없음,"We propose a new hardware structure of arithmetic computation that is able to support kernel-level non-uniform computation precision on a Convolutional Neural Network (CNN). Since existing CNN compression techniques invariably assume uniform computation precision over all kernels in each convolutional layer of CNN, this work enables to further explore the CNN compression models, so that the compressed model can be fitted into a resource-limited architecture while minimizing the loss of prediction accuracy. We have implemented our proposed design in Virtex-7 FPGA and found that our design supporting the non-uniform kernel-level precision achieves higher utilization of the hardware resource than that of the layer-level kernel precision while using the same total amount of bits required for representing all kernel weights."
딥러닝 앙상블을 이용한 주가예측,2018,"['Deep Learning', 'Ensemble', 'Stacking', 'Stock Price Prediction', '딥러닝', '앙상블', '스태킹', '주가예측']","최근 딥러닝(Deep Learning)을 이용한 주가예측이 활발하게 연구되고 있으나, 서로 다른 딥러닝 모델들을 결합하는 앙상블(Ensemble) 방법에 대한 연구는 초기 단계이다. 딥러닝 모델에는 Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN)이 있다. 본 논문에서는 세 가지 딥러닝 모델(MLP, CNN, RNN)이 예측한 결과를 결합하고 MLP를 사용하여 다시 학습하는 스태킹(Stacking) 기반의 앙상블 모델을 사용하여 주가를 예측한다. KOSPI 상위 30 종목 중 18개 종목을 이용하여 실험한 결과, 제안한 방법이 기존 방법에 비해 절대평균백분율오차(MAPE)가 8.74%에서 3.35%로 감소하였다.","Recently, there have been research efforts on predicting stock price using deep learning, but little attention has been paid so far to ensemble methods, which combines different deep learning models. Deep learning models include Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN). In this paper, we propose a stacking-based ensemble model where a deep learning model combines predictions of three different deep learning models (MLP, CNN, and RNN). We use MLP as the second level model. The experimental results using 18 stock items among KOSPI top 30 items show that the proposed method improves the mean absolute percentage error (MAPE) from 8.74%, which is the MAPE of the state-of-the-art method, to 3.35%."
Establishment and Characterization of Paired Primary and Peritoneal Seeding Human Colorectal Cancer Cell Lines: Identification of Genes That Mediate Metastatic Potential <sup>1</sup>,2018,[],국문 초록 정보 없음,"<P>Peritoneal metastasis is one of the major patterns of unresectability in colorectal cancer (CRC) and a cause of death in advanced CRC. Identification of distinct gene expressions between primary CRC and peritoneal seeding metastasis is to predict the metastatic potential of primary human CRC. Three pairs of primary CRC (SNU-2335A, SNU-2404A, and SNU-2414A) and corresponding peritoneal seeding (SNU-2335D, SNU-2404B, and SNU-2414B) cell lines were established to determine the different gene expressions and resulting aberrated signaling pathways in peritoneal metastasis tumor using whole exome sequencing and microarray. Whole exome sequencing detected that mutation in <I>CYP2A7</I> was exclusively shared in peritoneal seeding cell lines. Microarray identified that there were five upregulated genes (<I>CNN3</I>, <I>SORBS1</I>, <I>BST2</I>, <I>EPSTI1</I>, and <I>KLHL5</I>) and two downregulated genes (<I>TRY6</I> and <I>STYL5</I>) in the peritoneal metastatic cell lines. <I>CNN3</I> expression was highly augmented in both mRNA and protein levels in peritoneal metastasis cells. Knockdown of Calponin 3 resulted in augmented level of E-cadherin in peritoneal metastasis cells, and migration and invasiveness decreased accordingly. We suggest that <I>CNN3</I> takes part in cell projection and movement, and the detection and distribution of <I>CNN3</I> may render prognostic information for predicting peritoneal seeding metastasis from primary colorectal cancer.</P>"
Sentiment classification with word localization based on weakly supervised learning with a convolutional neural network,2018,"['Weakly supervised learning', 'Word localization', 'Convolutional neural network', 'Class activation mapping', 'Sentiment analysis']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>In order to maximize the applicability of sentiment analysis results, it is necessary to not only classify the overall sentiment (positive/negative) of a given document but also to identify the main words that contribute to the classification. However, most datasets for sentiment analysis only have the sentiment label for each document or sentence. In other words, there is a lack of information about which words play an important role in sentiment classification. In this paper, we propose a method for identifying key words discriminating positive and negative sentences by using a weakly supervised learning method based on a convolutional neural network (CNN). In our model, each word is represented as a continuous-valued vector and each sentence is represented as a matrix whose rows correspond to the word vector used in the sentence. Then, the CNN model is trained using these sentence matrices as inputs and the sentiment labels as the output. Once the CNN model is trained, we implement the word attention mechanism that identifies high-contributing words to classification results with a class activation map, using the weights from the fully connected layer at the end of the learned CNN model. To verify the proposed methodology, we evaluated the classification accuracy and the rate of polarity words among high scoring words using two movie review datasets. Experimental results show that the proposed model can not only correctly classify the sentence polarity but also successfully identify the corresponding words with high polarity scores.</P>"
Business Application of Convolutional Neural Networks for Apparel Classification Using Runway Image,2018,"['Convolutional Neural Networks', 'Image Classification', 'Apparel', 'Runway', 'Mobility', '합성곱 신경망', '이미지 분류', '의류', '런웨이', '이동성']",국문 초록 정보 없음,"Large amount of data is now available for research and business sectors to extract knowledge from it. This data can be in the form of unstructured data such as audio, text, and image data and can be analyzed by deep learning methodology. Deep learning is now widely used for various estimation, classification, and prediction problems. Especially, fashion business adopts deep learning techniques for apparel recognition, apparel search and retrieval engine, and automatic product recommendation. The core model of these applications is the image classification using Convolutional Neural Networks (CNN). CNN is made up of neurons which learn parameters such as weights while inputs come through and reach outputs. CNN has layer structure which is best suited for image classification as it is comprised of convolutional layer for generating feature maps, pooling layer for reducing the dimensionality of feature maps, and fully-connected layer for classifying the extracted features. However, most of the classification models have been trained using online product image, which is taken under controlled situation such as apparel image itself or professional model wearing apparel. This image may not be an effective way to train the classification model considering the situation when one might want to classify street fashion image or walking image, which is taken in uncontrolled situation and involves people’s movement and unexpected pose. Therefore, we propose to train the model with runway apparel image dataset which captures mobility. This will allow the classification model to be trained with far more variable data and enhance the adaptation with diverse query image. To achieve both convergence and generalization of the model, we apply Transfer Learning on our training network. As Transfer Learning in CNN is composed of pre-training and fine-tuning stages, we divide the training step into two. First, we pre-train our architecture with large-scale dataset, ImageNet dataset, which consists of 1.2 million images with 1000 categories including animals, plants, activities, materials, instrumentations, scenes, and foods. We use GoogLeNet for our main architecture as it has achieved great accuracy with efficiency in ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Second, we fine-tune the network with our own runway image dataset. For the runway image dataset, we could not find any previously and publicly made dataset, so we collect the dataset from Google Image Search attaining 2426 images of 32 major fashion brands including Anna Molinari, Balenciaga, Balmain, Brioni, Burberry, Celine, Chanel, Chloe, Christian Dior, Cividini, Dolce and Gabbana, Emilio Pucci, Ermenegildo, Fendi, Giuliana Teso, Gucci, Issey Miyake, Kenzo, Leonard, Louis Vuitton, Marc Jacobs, Marni, Max Mara, Missoni, Moschino, Ralph Lauren, Roberto Cavalli, Sonia Rykiel, Stella McCartney, Valentino, Versace, and Yve Saint Laurent. We perform 10-folded experiments to consider the random generation of training data, and our proposed model has achieved accuracy of 67.2% on final test. Our research suggests several advantages over previous related studies as to our best knowledge, there haven’t been any previous studies which trained the network for apparel image classification based on runway image dataset. We suggest the idea of training model with image capturing all the possible postures, which is denoted as mobility, by using our own runway apparel image dataset. Moreover, by applying Transfer Learning and using checkpoint and parameters provided by Tensorflow Slim, we could save time spent on training the classification model as taking 6 minutes per experiment to train the classifier. This model can be used in many business applications where the query image can be runway image, product image, or street fashion image. To be specific, runway query image can be used for mobile application service during fashion week to facilitate brand search, street style query image"
딥러닝 기반 암세포 사진 분류 알고리즘,2018,"['CNN', 'Dilated Convolution', 'Image Recognition']",국문 초록 정보 없음,"CNN (Convolution Neural Network) is one of the most important techniques to identify the kind of objects in the captured pictures. Whereas the conventional models have been used for low resolution images, the technique to recognize the high resolution images becomes crucial in the field of artificial intelligence. In this paper, we proposed an efficient CNN model based on dilated convolution and thresholding techniques to increase the recognition ratio and to decrease the computational complexity. The simulation results show that the proposed algorithm outperforms the conventional method and the thresholding technique enhances the performance of the proposed model."
트랜슬레이션 임베딩 기반 관계 학습을 이용한 GUI 위젯 인식,2018,"['Deep neural nets', 'Object recognition', 'Relation learning', 'Widget recognition', 'App test']",국문 초록 정보 없음,"CNN based object recognitions have reported splendid results. However, the recognition of mobile apps raises an interesting challenge that recognition performance of similar widgets is not consistent. In order to improve the performance, we propose a noble method utilizing relations between input widgets. The recognition process flows from the Faster R-CNN based recognition to enhancement using a relation recognizer. The relations are represented as vector translation between objects in a relation space. Experiments on 323 apps show that our method significantly enhances the Faster R-CNN only approach."
GoogLenet 기반의 딥 러닝을 이용한 향상된 한글 필기체 인식,2018,"['한글 필기체 인식', 'CNN', 'GoogLenet', 'PE92 데이터베이스', 'Handwritten Hangeul Recognition', 'PE92 Database']","딥 러닝 기술의 등장으로 여러 나라의 필기체 인식은 높은 정확도 (중국어 필기체 인식은 97.2%, 일본어 필기체 인식은 99.53%)를 보인다. 하지만 한글 필기체는 한글의 특성으로 유사글자가 많은데 비해 문자의 데이터 수는 적어 글자 인식에 어려움이 있다. 하이브리드 러닝을 통한 한글 필기체 인식에서는 lenet을 기반으로 하여 낮은 레이어를 가진 모델을 사용하여 한글 필기체 데이터베이스 PE92에서 96.34%의 정확도를 보여주었다. 본 논문에서는 하이브리드 러닝에서 사용하였던 데이터 확장 기법(data augmentation)이나 multitasking을 사용하지 않고도 GoogLenet 네트워크를 기본으로 한글 필기체 데이터에 적합한 더 깊고 더 넓은 CNN(Convolution Neural Network) 네트워크를 도입하여 PE92 데이터베이스에서 98.64%의 정확도를 얻었다.","The advent of deep learning technology has made rapid progress in handwritten letter recognition in many languages. Handwritten Chinese recognition has improved to 97.2% accuracy while handwritten Japanese recognition approached 99.53% percent accuracy. Hanguel handwritten letters have many similar characters due to the characteristics of Hangeul, so it was difficult to recognize the letters because the number of data was small. In the handwritten Hanguel recognition using Hybrid Learning, it used a low layer model based on lenet and showed 96.34% accuracy in handwritten Hanguel database PE92. In this paper, 98.64% accuracy was obtained by organizing deep CNN (Convolution Neural Network) in handwritten Hangeul recognition. We designed a new network for handwritten Hangeul data based on GoogLenet without using the data augmentation or the multitasking techniques used in Hybrid learning."
Discriminative Manifold Learning Network using Adversarial Examples for Image Classification,2018,"['Manifold learning', 'Discriminative feature', 'CNN', 'Adversarial examples', 't-SNE', 'Dimensionality reduction']",국문 초록 정보 없음,"This study presents a novel approach of discriminative feature vectors based on manifold learning using nonlinear dimension reduction (DR) technique to improve loss function, and combine with the Adversarial examples to regularize the object function for image classification. The traditional convolutional neural networks (CNN) with many new regularization approach has been successfully used for image classification tasks, and it achieved good results, hence it costs a lot of Calculated spacing and timing. Significantly, distrinct from traditional CNN, we discriminate the feature vectors for objects without empirically-tuned parameter, these Discriminative features intend to remain the lower-dimensional relationship corresponding high-dimension manifold after projecting the image feature vectors from high-dimension to lower-dimension, and we optimize the constrains of the preserving local features based on manifold, which narrow the mapped feature information from the same class and push different class away. Using Adversarial examples, improved loss function with additional regularization term intends to boost the Robustness and generalization of neural network. experimental results indicate that the approach based on discriminative feature of manifold learning is not only valid, but also more efficient in image classification tasks. Furthermore, the proposed approach achieves competitive classification performances for three benchmark datasets : MNIST, CIFAR-10, SVHN."
Discriminative Manifold Learning Network using Adversarial Examples for Image Classification,2018,"['Manifold learning', 'Discriminative feature', 'CNN', 'Adversarial examples', 't-SNE', 'Dimensionality reduction']",국문 초록 정보 없음,"This study presents a novel approach of discriminative feature vectors based on manifold learning using nonlinear dimension reduction (DR) technique to improve loss function, and combine with the Adversarial examples to regularize the object function for image classification. The traditional convolutional neural networks (CNN) with many new regularization approach has been successfully used for image classification tasks, and it achieved good results, hence it costs a lot of Calculated spacing and timing. Significantly, distrinct from traditional CNN, we discriminate the feature vectors for objects without empirically-tuned parameter, these Discriminative features intend to remain the lower-dimensional relationship corresponding high-dimension manifold after projecting the image feature vectors from high-dimension to lower-dimension, and we optimize the constrains of the preserving local features based on manifold, which narrow the mapped feature information from the same class and push different class away. Using Adversarial examples, improved loss function with additional regularization term intends to boost the Robustness and generalization of neural network. experimental results indicate that the approach based on discriminative feature of manifold learning is not only valid, but also more efficient in image classification tasks. Furthermore, the proposed approach achieves competitive classification performances for three benchmark datasets : MNIST, CIFAR-10, SVHN."
딥러닝 기반 손상된 흑백 얼굴 사진 컬러 복원,2018,"['Inpainting', 'Colorization', 'Deep Learning', 'BEGAN', 'CNN', '복원', '컬러화', '딥러닝', '경계 평형 생성 적대 네트워크', '합성곱 신경망']","본 논문에서는 손상된 흑백 얼굴 이미지를 컬러로 복원하는 방법을 제안한다. 기존 연구에서는 오래된 증명사진처럼 손상된 흑백 사진에 컬러화 작업을 하면 손상된 영역 주변이 잘못 색칠되는 경우가 있었다. 이와 같은 문제를 해결하기 위해 본 논문에서는 입력받은 사진의 손상된 영역을 먼저 복원한 후 그 결과를 바탕으로 컬러화를 수행하는 방법을 제안한다. 본 논문의 제안 방법은 BEGAN(Boundary Equilibrium Generative Adversarial Networks) 모델 기반 복원과 CNN(Convolutional Neural Network) 기반 컬러화의 두 단계로 구성된다. 제안하는 방법은 이미지 복원을 위해 DCGAN(Deep Convolutional Generative Adversarial Networks) 모델을 사용한 기존 방법들과 달리 좀 더 선명하고 고해상도의 이미지 복원이 가능한 BEGAN 모델을 사용하고, 그 복원된 흑백 이미지를 바탕으로 컬러화 작업을 수행한다. 최종적으로 다양한 유형의 얼굴 이미지와 마스크에 대한 실험 결과를 통해 기존 연구에 비해 많은 경우에 사실적인 컬러 복원 결과를 보여줄 수 있음을 확인하였다.","In this paper, we propose a method to restore corrupted black and white facial images to color. Previous studies have shown that when coloring damaged black and white photographs, such as old ID photographs, the area around the damaged area is often incorrectly colored. To solve this problem, this paper proposes a method of restoring the damaged area of input photo first and then performing colorization based on the result. The proposed method consists of two steps: BEGAN (Boundary Equivalent Generative Adversarial Networks) model based restoration and CNN (Convolutional Neural Network) based coloring. Our method uses the BEGAN model, which enables a clearer and higher resolution image restoration than the existing methods using the DCGAN (Deep Convolutional Generative Adversarial Networks) model for image restoration, and performs colorization based on the restored black and white image. Finally, we confirmed that the experimental results of various types of facial images and masks can show realistic color restoration results in many cases compared with the previous studies."
Facial Expression Classification Using Deep Convolutional Neural Network,2018,"['Convolutional neural network', 'Facial expression', 'Data augmentation', 'Database']",국문 초록 정보 없음,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. The proposed structure has general classification performance for any environment or subject. For this purpose, we collect a variety of databases and organize the database into six expression classes such as ‘expressionless’, ‘happy’, ‘sad’, ‘angry’, ‘surprised’ and ‘disgusted’. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. In the existing CNN structure, the optimal structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of nodes of fully-connected layer. The experimental results show good classification performance compared to the state-of-the-arts in experiments of the cross validation and the cross database. Also, compared to other conventional models, it is confirmed that the proposed structure is superior in classification performance with less execution time."
A Self-ensemble Approach for Noise and Compression Artifacts Removal using Convolutional Neural Network,2018,"['Image denoising', 'Compression artifacts removal', 'Convolutional neural network', 'Ensemble approach']",국문 초록 정보 없음,"There have been many discriminative learning methods using convolutional neural networks (CNN) for image restoration problems, which learn the mapping function from a degraded input to the clean output. In this paper, we propose a self-ensemble method that can find enhanced restoration results from the multiple trials of a trained CNN with different but related inputs. Specifically, it is noted that the CNN sometimes finds different mapping functions when the input is transformed by a reversible transform and thus produces different but related outputs with the original. Hence averaging the outputs for several different transformed inputs can enhance the results as evidenced by the network ensemble methods. Unlike the conventional ensemble approaches that require several networks, the proposed method needs only a single network. Experimental results show that adding an additional transform usually brings additional gain on image denoising and artifacts removal problems."
HVS-Aware Single-Shot HDR Imaging Using Deep Convolutional Neural Network,2018,"['High dynamic range (HDR) imaging', 'spatially varying exposure (SVE) imaging', 'convolutional neural network (CNN)']",국문 초록 정보 없음,"We propose a single-shot high dynamic range (HDR) imaging algorithm using a deep convolutional neural network (CNN) for row-wise varying exposures in a single image. The proposed algorithm restores missing information resulting from under- and/or over-exposed pixels in an input image and reconstructs the raw radiance map. The main contribution of this work is the development of a loss function for the CNN employing the human visual system (HVS) properties. Then, the HDR image is obtained by applying a demosaicing algorithm. Experimental results demonstrate that the proposed algorithm provides higher-quality HDR images than conventional algorithms."
HVS-Aware Single-Shot HDR Imaging Using Deep Convolutional Neural Network,2018,"['High dynamic range (HDR) imaging', 'spatially varying exposure (SVE) imaging', 'convolutional neural network (CNN)']",국문 초록 정보 없음,"We propose a single-shot high dynamic range (HDR) imaging algorithm using a deep convolutional neural network (CNN) for row-wise varying exposures in a single image. The proposed algorithm restores missing information resulting from under- and/or over-exposed pixels in an input image and reconstructs the raw radiance map. The main contribution of this work is the development of a loss function for the CNN employing the human visual system (HVS) properties. Then, the HDR image is obtained by applying a demosaicing algorithm. Experimental results demonstrate that the proposed algorithm provides higher-quality HDR images than conventional algorithms."
합성곱 신경망을 이용한 농산물 기사 감성 분석,2018,"['감성분석', '오피니언 마이닝', '텍스트 마이닝', '농산물가격', '합성곱 신경망', 'emotional analysis', 'opinion mining', 'text mining', 'agricultural price', 'convolutional neural networks']","본 논문에서는 농산물 가격의 등락을 기준으로 감성사전을 구축하여 농산물 관련 온라인 뉴스의 긍정/부정을 분류하는 방법을 제안한다. 이를 위해 비정형 텍스트문서를 문장 단위로 분할한 뒤 분석내용과 연관 없거나 가격 등락에 상관없이 빈번하게 언급된 단어들을 불용어로 처리한다. 형태소 분석을 진행한 후 비지도 학습 기반으로 키워드를 추출하여 합성곱 신경망(Convolutional Neural Networks, CNN)을 이용해 긍정/부정 분류를 수행하였다. 그 결과 빈도기반 키워드를 이용한 긍정/부정 분류보다 비지도 학습기반 키워드 추출과 인공신경망의 일종인 합성곱 신경망을 이용했을 때 약 20% 이상 분류 정확도가 향상되었다.","In this paper, we propose a method for sentiment analysis of online news by constructing emotional dictionary base on the fluctuation in prices of various agriculture products. The collected unstructured text data were segmented into sentences and the frequently mentioned words which were not related to price fluctuation were removed as stop words. After the morphological analysis, the keyword was extracted based on the unsupervised learning and the experiments were conducted based on the proposed model using the convolutional neural network (CNN). Consequently, about 20% improvement in accuracy was observed when CNN was used than the word frequency based method."
Machine-learning-based automatic identification of fetal abdominal circumference from ultrasound images,2018,[],국문 초록 정보 없음,"<P> <I>Objective</I>: Obstetricians mainly use ultrasound imaging for fetal biometric measurements. However, such measurements are cumbersome. Hence, there is urgent need for automatic biometric estimation. Automated analysis of ultrasound images is complicated owing to the patient-specific, operator-dependent, and machine-specific characteristics of such images. <I>Approach</I>: This paper proposes a method for the automatic fetal biometry estimation from 2D ultrasound data through several processes consisting of a specially designed convolutional neural network (CNN) and U-Net for each process. These machine learning techniques take clinicians’ decisions, anatomical structures, and the characteristics of ultrasound images into account. The proposed method is divided into three steps: initial abdominal circumference (AC) estimation, AC measurement, and plane acceptance checking. <I>Main results</I>: A CNN is used to classify ultrasound images (stomach bubble, amniotic fluid, and umbilical vein), and a Hough transform is used to obtain an initial estimate of the AC. These data are applied to other CNNs to estimate the spine position and bone regions. Then, the obtained information is used to determine the final AC. After determining the AC, a U-Net and a classification CNN are used to check whether the image is suitable for AC measurement. Finally, the efficacy of the proposed method is validated by clinical data. <I>Significance</I>: Our method achieved a Dice similarity metric of <img ALIGN='MIDDLE' ALT='' SRC='http://ej.iop.org/images/0967-3334/39/10/105007/pmeaaae255ieqn001.gif'/> for AC measurement and an accuracy of 87.10% for our acceptance check of the fetal abdominal standard plane.</P>"
3차원 점군 데이터를 이용한 수정 구형 특징 표현기 개발 및 도시 구조물 분류를 위한 컨볼루션 신경망의 응용,2018,"['Modified Spherical Signature Descriptor(수정 구형특징 표현기)', 'Convolutional Neural Network(컨볼루션신망망)', '3D Point Cloud(3차원 점군)', 'Geodesic Sphere(지오데식 구)', 'Deep Learning(심층 학습)']",국문 초록 정보 없음,"This paper presents the novel observation model, called Modified Spherical Signature Descriptor(MSSD), capable of representing 2D image generated from 3D point cloud data. The Modified Spherical Signature Descriptor has a uniform mesh grid to accumulate the occupancy evidence caused by neighbor point cloud data. According to a kind of area such as wall, road, tree, car, and so on, the evidence pattern of 2D image looks so different each other. For the parameter learning of Convolutional Neural Network(CNN) layers, these 2D images were applied as the input layer. The Convolutional Neural Network, one of the deep learning methods and familiar with the image analysis, was utilized for the urban structure classification. The case study on CNN practice was introduced in detail in this paper. The simulation results shows that the classification accuracy of CNN with 2D images of the proposed MSSD was improved more than the traditional methods' one."
An Insect Counting and Recognition Method for Greenhouse Insect Pests on Sticky Paper using Convolutional Neural Network,2018,"['Pattern recognition', 'YOLO', 'Integrated pest management', 'Classification']",국문 초록 정보 없음,"Greenhouses are built to promote crop growth, but the same environment also allows pests to reproduce and affect crops. Placing sticky papers in the greenhouse allows monitoring of the number of insect pests in order to predict the breakout of insects and to take appropriate action. Currently, the insect pests on sticky papers are counted and identified by manual inspection which is very time consuming and laborious. In this study, an automatic counting and recognition system for whiteflies and thrips using a convolutional neural network (CNN) approach was developed. The system makes use of a scanner to scan the images of sticky papers with insects and to recognize the objects as whiteflies or thrips. A graphical user interface (GUI) is provided; it was designed using Qt with an OpenCV image processing library. To apply CNN for object detection and recognition, we used the YOLO (You Only Look Once) real-time object detection tool. The sticky papers were collected from several greenhouses and preserved by using cellophane sheets as cover. They were then scanned to obtain high resolution images. Insect image samples were labeled from the scanned sticky paper images to train the CNN object detector model. The object detector model was further optimized in terms of iteration time, detection threshold level, and sample image size. The optimized average recognition accuracies were 86.30% and 90.45% for whitefly and thrip, respectively. This work can be used for automated insect sticky paper checking which is necessary for quarantine purposes."
A Real-time Multi-class Insect Pest Identification Method using Cascaded Convolutional Neural Networks,2018,"['Classifier', 'Image processing', 'Integrated pest management', 'Greenhouse']",국문 초록 정보 없음,"Insect pest identification is very important for greenhouse management. Having the knowledge of what insects exist in their greenhouse, farmers will be able to determine which pesticide will be more effective to prevent insect pest outbreaks and protect their crops. The most common technique to monitor insect pests is the use of strips of yellow sticky papers. Insects trapped on these yellow sticky papers are usually counted by human inspection without the assistance of any machine or device. To replace this inefficient method, this work presents a multi-class insect identification method for yellow sticky paper, obtained from wireless cameras using cascaded convolutional neural networks (CNN). The designed algorithm makes use of a marker-based image segmentation technique for object detection. The objects are sorted using an insect vs. non-insect filter CNN model to remove non-insect objects such as glare, dirt, and water droplets with 88-95% counting accuracy, while the multi-class insect classifier has an accuracy of 86-92%. The CNN models are optimized based on accuracy and computation time for real-time insect pest monitoring application. The combined algorithm can process each yellow sticky paper image with an average processing time of 13-15 seconds and 2-3 seconds using a quad-core Cortex A53 1.2GHz CPU and GTX1080 2.2GHz GPU, respectively. This work can be applied for real-time and remote insect pest monitoring using wireless camera networks and for observing insect population dynamics of different species."
Automatic Estimation of Fetal Abdominal Circumference From Ultrasound Images,2018,[],국문 초록 정보 없음,"<P>Ultrasound diagnosis is routinely used in obstetrics and gynecology for fetal biometry, and owing to its time-consuming process, there has been a great demand for automatic estimation. However, the automated analysis of ultrasound images is complicated because they are patient specific, operator dependent, and machine specific. Among various types of fetal biometry, the accurate estimation of abdominal circumference (AC) is especially difficult to perform automatically because the abdomen has low contrast against surroundings, nonuniform contrast, and irregular shape compared to other parameters. We propose a method for the automatic estimation of the fetal AC from two-dimensional ultrasound data through a specially designed convolutional neural network (CNN), which takes account of doctors’ decision process, anatomical structure, and the characteristics of the ultrasound image. The proposed method uses CNN to classify ultrasound images (stomach bubble, amniotic fluid, and umbilical vein) and Hough transformation for measuring AC. We test the proposed method using clinical ultrasound data acquired from 56 pregnant women. Experimental results show that, with relatively small training samples, the proposed CNN provides sufficient classification results for AC estimation through the Hough transformation. The proposed method automatically estimates AC from ultrasound images. The method is quantitatively evaluated and shows stable performance in most cases and even for ultrasound images deteriorated by shadowing artifacts. As a result of experiments for our acceptance check, the accuracies are 0.809 and 0.771 with expert 1 and expert 2, respectively, whereas the accuracy between the two experts is 0.905. However, for cases of oversized fetus, when the amniotic fluid is not observed or the abdominal area is distorted, it could not correctly estimate AC.</P>"
Branch Detection with Deep Learning -Developing Branch Angle Detector-,2018,"['Tree mensuration', 'image processing', 'classification', 'deep learning']",국문 초록 정보 없음,"In Japan, decreasing the number of farmers and aging are big problem, so mechanization and automatization of agriculture has been promoted. In fruit growing, measuring tree height and stem diameter is carried out for the purpose of calculating annual growth or deciding proper amount of fertilizer and chemicals. But it consumes a lot of time and labor because it is measured by human power. So, we address automatization of tree mensuration by using image processing. If we can apply it to tree mensuration easily, it will contribute to precision agriculture and improve the quality and quantity of agricultural products.Our proposing method for tree mensuration consists of three steps. First, detect tree part from pictures of orchard tree. Second, make 3D model from the pictures of tree part. Finally, calculate tree volume from the 3D model. In this study, we focused on the first step, especially branch detection from pictures. However, it is difficult to detect branch directly from picture because it need to distinguish branch from background and other trees. So in this study, we first cope with a method of detecting branch angle with deep learning to make subsequent blanch detection easier. The aim of this study is branch angle detection and classing branch picture by its angle. After classifying pictures by branch angle, it becomes easy to extract the branch from orchard tree image.We adopted convolutional neural network (CNN) for the classification system that achieved many remarkable results in image recognition field. We developed 8 layer CNN classifier. This was four class (0°, 45°, 90°, 135°) classifier, and achieved a recall of 93.43%. The result shows that machine learning can be used for detecting branch.To know which part in the image contribute to the judgement, we implemented Grad-CAM that is the visualization tool of CNN system. Through the result of Grad-CAM, we considered that the system didn't pay attention to the branches but may watch the whole of the picture."
Variations of AlexNet and GoogLeNet to Improve Korean Character Recognition Performance,2018,"['Classification', 'CNN', 'Deep Learning', 'Korean Character Recognition']",국문 초록 정보 없음,"Deep learning using convolutional neural networks (CNNs) is being studied in various fields of image recognition and these studies show excellent performance. In this paper, we compare the performance of CNN architectures, KCR-AlexNet and KCR-GoogLeNet. The experimental data used in this paper is obtained from PHD08, a large-scale Korean character database. It has 2,187 samples of each Korean character with 2,350 Korean character classes for a total of 5,139,450 data samples. In the training results, KCR-AlexNet showed an accuracy of over 98% for the top-1 test and KCR-GoogLeNet showed an accuracy of over 99% for the top-1 test after the final training iteration. We made an additional Korean character dataset with fonts that were not in PHD08 to compare the classification success rate with commercial optical character recognition (OCR) programs and ensure the objectivity of the experiment. While the commercial OCR programs showed 66.95% to 83.16% classification success rates, KCR-AlexNet and KCR-GoogLeNet showed average classification success rates of 90.12% and 89.14%, respectively, which are higher than the commercial OCR programs’ rates. Considering the time factor, KCR-AlexNet was faster than KCR-GoogLeNet when they were trained using PHD08; otherwise, KCR-GoogLeNet had a faster classification speed."
Variations of AlexNet and GoogLeNet to Improve Korean Character Recognition Performance,2018,"['Classification', 'CNN', 'Deep Learning', 'Korean Character Recognition']",국문 초록 정보 없음,"Deep learning using convolutional neural networks (CNNs) is being studied in various fields of image recognition and these studies show excellent performance. In this paper, we compare the performance of CNN architectures, KCR-AlexNet and KCR-GoogLeNet. The experimental data used in this paper is obtained from PHD08, a large-scale Korean character database. It has 2,187 samples of each Korean character with 2,350 Korean character classes for a total of 5,139,450 data samples. In the training results, KCR-AlexNet showed an accuracy of over 98% for the top-1 test and KCR-GoogLeNet showed an accuracy of over 99% for the top-1 test after the final training iteration. We made an additional Korean character dataset with fonts that were not in PHD08 to compare the classification success rate with commercial optical character recognition (OCR) programs and ensure the objectivity of the experiment. While the commercial OCR programs showed 66.95% to 83.16% classification success rates, KCR-AlexNet and KCR-GoogLeNet showed average classification success rates of 90.12% and 89.14%, respectively, which are higher than the commercial OCR programs' rates. Considering the time factor, KCR-AlexNet was faster than KCR-GoogLeNet when they were trained using PHD08; otherwise, KCR-GoogLeNet had a faster classification speed."
A Deep Learning Approach for Classification of Cloud Image Patches on Small Datasets,2018,"['Cloud classification', 'CNN', 'Data augmentation', 'SWIMCAT dataset']",국문 초록 정보 없음,"Accurate classification of cloud images is a challenging task. Almost all the existing methods rely on hand-crafted feature extraction. Their limitation is low discriminative power. In the recent years, deep learning with convolution neural networks (CNNs), which can auto extract features, has achieved promising results in many computer vision and image understanding fields. However, deep learning approaches usually need large datasets. This paper proposes a deep learning approach for classification of cloud image patches on small datasets. First, we design a suitable deep learning model for small datasets using a CNN, and then we apply data augmentation and dropout regularization techniques to increase the generalization of the model. The experiments for the proposed approach were performed on SWIMCAT small dataset with k-fold cross-validation. The experimental results demonstrated perfect classification accuracy for most classes on every fold, and confirmed both the high accuracy and the robustness of the proposed model."
A Study on the Facial Expression Recognition using Deep Learning Technique,2018,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Intelligent Phone.']",국문 초록 정보 없음,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the symbols that users often use, you can identify facial expressions with a camera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar expressions, reached 66%. It doesn't need to search for symbols. If you use the camera to recognize the expression, it will appear symbols immediately. So, this service is the symbols used when people send messages to others, and it can feel a lot of convenience. In countless symbols, there is no need to find symbols, which is an increasing trend in deep learning. So, we need to use more suitable algorithm for expression recognition, and then improve accuracy."
Backbone Network for Object Detection with Multiple Dilated Convolutions and Feature Summation,2018,"['객체 검출', '백본 네트워크', '배수 팽창 된 컨볼루션', '특징합계', 'object detection', 'backbone network', 'multiple dilated convolutions', 'feature summation']",국문 초록 정보 없음,"The advancement of CNN leads to the trend of using very deep convolutional neural network which contains more than 100 layers not only for object detection, but also for image segmentation and object classification. However, deep CNN requires lots of resources, and so is not suitable for people who have limited resources or real time requirements. In this paper, we propose a new backbone network for object detection with multiple dilated convolutions and feature summation. Feature summation enables easier flow of gradients and minimizes loss of spatial information that is caused by convolving. By using multiple dilated convolution, we can widen the receptive field of individual neurons without adding more parameters. Furthermore, by using a shallow neural network as a backbone network, our network can be trained and used in an environment with limited resources and without pre-training it in ImageNet dataset. Experiments demonstrate we achieved 71% and 38.2% of accuracy on Pascal VOC and MS COCO dataset, respectively."
쇼크 필터와 합성곱 신경망 기반의 균일 모션 디블러링 기법,2018,"['Deblurring', 'Convolutional Neural Network (CNN)', 'Shock filter', 'Uniform Motion blur', 'Blind deconvolution']",Cho 등의 균일 모션 블러 제거 알고리듬은 영상 내 외곽선 영역을 선명하게 복원하지 못한다는 문제점이 있다. 이러한 문제점을 극복하기 위해 본 논문에서는 한 장의 정지 영상에서 발생하는 블러 (Blur)현상을 블러된 계단형 신호를 뚜렷한 외곽선으로 복원해주는 쇼크 필터 (Shock filter)와 영상에서 특징을 추출하여 학습하는 합성곱 신경망 (Convolutional Neural Network: CNN)을 이용하여 선명한 영상을 복원하고 이 영상으로부터 균일 모션 (Uniform motion) 블러를 측정하여 영상 내 블러 현상을 제거하는 효과적인 알고리듬을 제안하고자 한다. 제안된 알고리듬은 쇼크 필터와 합성곱 신경망을 이용하여 선명한 영상을 복원함으로써 기존 알고리듬의 단점을 개선하였다. 실험 결과를 통해 제안하는 알고리듬이 기존 알고리듬에 비해 객관적 및 주관적인 평가에서 우수한 복원 성능을 나타냄을 확인하였다.,다국어 초록 정보 없음
딥러닝을 이용한 불교 미술 채색 연구,2018,[],"컬러 사진을 흑백으로 바꿔 데이터 셋을 구축해 CNN 모델을 트레이닝 시킨다. HSI 컬러 모델에서 흑백 사진으로부터 밝기 값은 알고 있음으로, 나머지 두 컬러 영역 색상, 채도를 CNN 모델이 추측하도록 학습을 시켜, 흑백사진으로부터 컬러 사진을 만들어낸다. 이 기술을 채색이 안된 불교 미술 그림에 적용하여 채색을 시키는 것에 대한 연구를 진행하였다.",다국어 초록 정보 없음
Facial Expression Classification Using Deep Convolutional Neural Network,2018,"['Convolutional neural network', 'Facial expression', 'Data augmentation', 'Database']",국문 초록 정보 없음,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. The proposed structure has general classification performance for any environment or subject. For this purpose, we collect a variety of databases and organize the database into six expression classes such as ‘expressionless’, ‘happy’, ‘sad’, ‘angry’, ‘surprised’ and ‘disgusted’. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. In the existing CNN structure, the optimal structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of nodes of fully-connected layer. The experimental results show good classification performance compared to the state-of-the-arts in experiments of the cross validation and the cross database. Also, compared to other conventional models, it is confirmed that the proposed structure is superior in classification performance with less execution time."
딥신경망 기반 운전자 시선 영역 검출,2018,"['야간운전', '선글라스', '시선 영역', '딥신경망', 'Convolutional Neural Network']","본 논문은 야간주행 중 운전자의 시선 방향을 Convolutional Neural Network (CNN)모델 중 VGG-19 를 사용하여 검출하는 시스템을 제안한다. 운전자의 시선 방향을 검출하기 위한 방법으로 선글라스/안경착용 운전자와 착용하지 않은 운전자 각각 차량 내 시선 방향을 8 가지, 눈을 감은 상태 1 가지, 알 수 없는 상태 1 가지, 총 20 가지 시선영역으로 분류한다. 적외선 카메라 (IR)로 촬영한 운전자의 얼굴 영상을 사용하여 CNN 학습 및 실험을 진행하였으며 평균 97% 정확도로 시선영역을 검출할 수 있음을 보였다.",다국어 초록 정보 없음
Enhanced Network Intrusion Detection using Deep Convolutional Neural Networks,2018,"['Network Intrusion Detection', 'Deep Convolutional Neural Networks', 'Deep learning', 'CNN', 'IDS', 'Information Security']",국문 초록 정보 없음,"Network Intrusion detection is a rapidly growing field of information security due to its importance for modern IT infrastructure. Many supervised and unsupervised learning techniques have been devised by researchers from discipline of machine learning and data mining to achieve reliable detection of anomalies. In this paper, a deep convolutional neural network (DCNN) based intrusion detection system (IDS) is proposed, implemented and analyzed. Deep CNN core of proposed IDS is fine-tuned using Randomized search over configuration space. Proposed system is trained and tested on NSLKDD training and testing datasets using GPU. Performance comparisons of proposed DCNN model are provided with other classifiers using well-known metrics including Receiver operating characteristics (RoC) curve, Area under RoC curve (AuC), accuracy, precision-recall curve and mean average precision (mAP). The experimental results of proposed DCNN based IDS shows promising results for real world application in anomaly detection systems."
Facial Expression Classification Using Deep Convolutional Neural Network,2018,"['Convolutional neural network', 'Facial expression', 'Data augmentation', 'Database']",국문 초록 정보 없음,"In this paper, we propose facial expression recognition using CNN (Convolutional Neural Network), one of the deep learning technologies. The proposed structure has general classification performance for any environment or subject. For this purpose, we collect a variety of databases and organize the database into six expression classes such as 'expressionless', 'happy', 'sad', 'angry', 'surprised' and 'disgusted'. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. In the existing CNN structure, the optimal structure that best expresses the features of six facial expressions is found by adjusting the number of feature maps of the convolutional layer and the number of nodes of fully-connected layer. The experimental results show good classification performance compared to the state-of-the-arts in experiments of the cross validation and the cross database. Also, compared to other conventional models, it is confirmed that the proposed structure is superior in classification performance with less execution time."
Convolutional Neural Network with Particle Filter Approach for Visual Tracking,2018,"['Computer Vision', 'Object Tracking', 'Convolutional Neural Network', 'Particle Filter', 'GPU']",국문 초록 정보 없음,"In this paper, we propose a compact Convolutional Neural Network (CNN)-based tracker in conjunction with a particle filter architecture, in which the CNN model operates as an accurate candidates estimator, while the particle filter predicts the target motion dynamics, lowering the overall number of calculations and refines the resulting target bounding box. Experiments were conducted on the Online Object Tracking Benchmark (OTB) [34] dataset and comparison analysis in respect to other state-of-art has been performed based on accuracy and precision, indicating that the proposed algorithm outperforms all state-of-the-art trackers included in the OTB dataset, specifically, TLD [16], MIL [1], SCM [36] and ASLA [15]. Also, a comprehensive speed performance analysis showed average frames per second (FPS) among the top-10 trackers from the OTB dataset [34]."
Generative Adversarial Networks를 이용한 Face Morphing 기법 연구,2018,"['대립쌍 기계학습', '얼굴합성', '합성곱 신경망', '비지도 학습', 'Generative adversarial network', 'face morphing', 'DCGAN', 'dCNN', 'unsupervised learning']",국문 초록 정보 없음,"Recently, with the explosive development of computing power, various methods such as RNN and CNN have been proposed under the name of Deep Learning, which solve many problems of Computer Vision have. The Generative Adversarial Network, released in 2014, showed that the problem of computer vision can be sufficiently solved in unsupervised learning, and the generation domain can also be studied using learned generators. GAN is being developed in various forms in combination with various models. Machine learning has difficulty in collecting data. If it is too large, it is difficult to refine the effective data set by removing the noise. If it is too small, the small difference becomes too big noise, and learning is not easy. In this paper, we apply a deep CNN model for extracting facial region in image frame to GAN model as a preprocessing filter, and propose a method to produce composite images of various facial expressions by stably learning with limited collection data of two persons."
"도심 자율주행을 위한 센서, 좌표지도 기반의 교차로 주행 시스템 구현",2018,"['Autonomous Driving(자율주행)', 'Traffic Light Recognition(신호등인식)', 'A Intersection Driving(교차로 주행)', 'Coordinates Map(좌표지도)', 'CNN(Convolutional Neural Network', '콘볼루션 신경망)']","본 논문은 차량의 도심 자율주행을 위한 교차로 주행 시스템을 구현한 논문이다. 연구에 포함된 시스템에서는 교차로 상황, 주행 차량, 신호등만 고려하여 직진과 좌회전을 구현하였으며 이 외의 변수들은 고려하지 않았다. 시스템은 신호등 인식, 차량의 위치 인식, 차량의 주행 경로 계획 및 차량 제어로 구성되어 있다. 신호등 인식은 카메라를 기반으로 한 CNN(Convolutional Neural Network)모델을 사용하였고, 차량의 위치 인식은 GNSS 센서의 RTK(Real-Time Kinematic)방식을 사용하였으며 차량의 주행 경로 계획은 좌표지도의 도로 좌표점을 이용하였다. 차량 제어는 임베디드 제어모듈을 이용한 스티어링 휠, 브레이크, 엑셀레이터 제어를 이용해 종/횡방향 제어 알고리즘을 구현하였다. 구현된 자율주행 시스템은 충북대 오창 자율주행 성능시험장의 교차로에서 실차를 기반으로 성능 평가를 진행하였다. 성능평가는 교차로 진입 전 직선도로에서 30kph 의 속도로 주행에 성공하였으며 코너지점에서는 최대 10kph 로 시스템을 구현을 성공하였다.",다국어 초록 정보 없음
A Comparative Study of Transfer Learning–based Methods for Inspection of Mobile Camera Modules,2018,"['Transfer learning', 'Machine vision', 'Camera module', 'Defect inspection']",국문 초록 정보 없음,"We apply three transfer learning methods using the pretrained AlexNet convolutional neural network (CNN) model to detect defects in camera modules. In experiments, the performance of fine-tuning methods using random initial parameters in less than the two last fully connected layers while using predetermined weights as initial parameters for the remaining layers, showed better performance than other methods. We expect that the transfer learning–based CNN can be effectively applied to camera module inspection systems."
Runway visual range prediction using Convolutional Neural Network with Weather information,2018,"['Runway visual range', 'Convolutional neural network', 'Aviation weather', 'Weather forecast..']",국문 초록 정보 없음,"The runway visual range is one of the important factors that decide the possibility of taking offs and landings of the airplane at local airports. The runway visual range is affected by weather conditions like fog, wind, etc. The pilots and aviation related workers check a local weather forecast such as runway visual range for safe flight. However there are several local airfields at which no other forecasting functions are provided due to realistic problems like the deterioration, breakdown, expensive purchasing cost of the measurement equipment. To this end, this study proposes a prediction model of runway visual range for a local airport by applying convolutional neural network that has been most commonly used for image/video recognition, image classification, natural language processing and so on to the prediction of runway visual range. For constituting the prediction model, we use the previous time series data of wind speed, humidity, temperature and runway visibility. This paper shows the usefulness of the proposed prediction model of runway visual range by comparing with the measured data.."
Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet Residual Network,2018,[],국문 초록 정보 없음,"<P>Model-based iterative reconstruction algorithms for low-dose X-ray computed tomography (CT) are computationally expensive. To address this problem, we recently proposed a deep convolutional neural network (CNN) for low-dose X-ray CT and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the textures were not fully recovered. To address this problem, here we propose a novel framelet-based denoising algorithm using wavelet residual network which synergistically combines the expressive power of deep learning and the performance guarantee from the framelet-based denoising algorithms. The new algorithms were inspired by the recent interpretation of the deep CNN as a cascaded convolution framelet signal representation. Extensive experimental results confirm that the proposed networks have significantly improved performance and preserve the detail texture of the original images.</P>"
Medical Image Retrieval with Compact Binary Codes Generated in Frequency Domain Using Highly Reactive Convolutional Features,2018,[],국문 초록 정보 없음,"<P>Efficient retrieval of relevant medical cases using semantically similar medical images from large scale repositories can assist medical experts in timely decision making and diagnosis. However, the ever-increasing volume of images hinder performance of image retrieval systems. Recently, features from deep convolutional neural networks (CNN) have yielded state-of-the-art performance in image retrieval. Further, locality sensitive hashing based approaches have become popular for their ability to allow efficient retrieval in large scale datasets. In this paper, we present a highly efficient method to compress selective convolutional features into sequence of bits using Fast Fourier Transform (FFT). Firstly, highly reactive convolutional feature maps from a pre-trained CNN are identified for medical images based on their neuronal responses using optimal subset selection algorithm. Then, layer-wise global mean activations of the selected feature maps are transformed into compact binary codes using binarization of its Fourier spectrum. The acquired hash codes are highly discriminative and can be obtained efficiently from the original feature vectors without any training. The proposed framework has been evaluated on two large datasets of radiology and endoscopy images. Experimental evaluations reveal that the proposed method significantly outperforms other features extraction and hashing schemes in both effectiveness and efficiency.</P>"
원격해양감시영상에서 해파리 검출,2018,"['해파리검출', '원격해양감시시스템', '임베디드시스템', '무인선', 'Jellyfish Detection', 'Marine Surveillance System', 'Embedded Ssytem', 'Unmanned Surface Vehicle', 'Yolo']","최근 해파리의 증가로 인해 양식장이나 발전소 등이 큰 피해를 보고 있다. 본 연구의 최종적인 목표는 원격해양감시 시스템을 개발하는 것인데, 본 논문에서는 시스템에 탑재된 임베디드 보드에서 운용이 가능한 해파리 검출방법을 제안한다. 이 시스템에서는 알고리즘을 임베디드 보드에 탑재해야 하므로 정확도보다는 빠르면서 가벼운 모델개발이 목표이다. 따라서, 기존의 CNN 검출알고리즘 중에 실시간으로 적용이 가능한 Yolo 모델의 Layer를 줄이면서 초당 프레임을 늘리는데 초점을 두었다. 수중에서 촬영한 영상의 경우 미세한 부유물과 조명 때문에 물체가 뚜렷하게 나오지 않을 수 있으므로 CLAHE를 이용하여 적응적으로 히스토그램을 평활화하여 전경과 배경의 경계를 뚜렷하게 만들도록 전처리를 한다. 간소화된 Yolo 모델을 사용하여 해파리를 검출하는 실험을 수행한 결과, 검출성능이 나쁘지 않으면서 임베디드 보드에서 동작할 수 있음을 확인할 수 있었다.","Recently, the increase of jellyfish has given great damages to sea farms and power plants. The final goal of this study is to develop a remote ocean surveillance system. In this paper, we propose a method to detect jellyfish that can be operated on an embedded board built in the system. Because the algorithm should be mounted on the embedded board, the system aims to develop a model that is faster and lighter than its accuracy. Therefore, we focused on increasing the frames per second while reducing the layer of Yolo that could be applied in real time among existing CNN detection algorithms. For underwater images, objects may not be clearly shown owing to fine floating and lighting. Therefore, we adaptively preprocess them using CLAHE to make clear boundaries between foreground and background. Experiments to detect jellyisfh using the simplified Yolo model found that it can be opeera ton embedded boards with good detection performance."
VGG-based BAPL Score Classification of 18F-Florbetaben Amyloid Brain PET,2018,"['Alzheimer`s disease', 'β-Amyloid', 'Convolutional neural network', '18F-florbetaben PET', 'Gray matter']",국문 초록 정보 없음,"Amyloid brain positron emission tomography (PET) images are visually and subjectively analyzed by the physician with a lot of time and effort to determine the β-Amyloid (Aβ) deposition. We designed a convolutional neural network (CNN) model that predicts the Aβ-positive and Aβ-negative status. We performed 18F-florbetaben (FBB) brain PET on controls and patients (n=176) with mild cognitive impairment and Alzheimer""s Disease (AD). We classified brain PET images visually as per the on the brain amyloid plaque load score. We designed the visual geometry group (VGG16) model for the visual assessment of slice-based samples. To evaluate only the gray matter and not the white matter, gray matter masking (GMM) was applied to the slice-based standard samples. All the performance metrics were higher with GMM than without GMM (accuracy 92.39 vs. 89.60, sensitivity 87.93 vs. 85.76, and specificity 98.94 vs. 95.32). For the patientbased standard, all the performance metrics were almost the same (accuracy 89.78 vs. 89.21), lower (sensitivity 93.97 vs. 99.14), and higher (specificity 81.67 vs. 70.00). The area under curve with the VGG16 model that observed the gray matter region only was slightly higher than the model that observed the whole brain for both slice-based and patient-based decision processes. Amyloid brain PET images can be appropriately analyzed using the CNN model for predicting the Aβ-positive and Aβ-negative status."
Classification of Leukemia Disease in Peripheral Blood Cell Images Using Convolutional Neural Network,2018,"['Acute Leukemia', 'Convolutional Neural Network', 'Data Augmentation', 'Deep Learning', 'Image Classification']",국문 초록 정보 없음,"Classification is widely used in medical images to categorize patients and non-patients. However, conventional classification requires a complex procedure, including some rigid steps such as pre-processing, segmentation, feature extraction, detection, and classification. In this paper, we propose a novel convolutional neural network (CNN), called LeukemiaNet, to specifically classify two different types of leukemia, including acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML), and non-cancerous patients. To extend the limited dataset, a PCA color augmentation process is utilized before images are input into the LeukemiaNet. This augmentation method enhances the accuracy of our proposed CNN architecture from 96.9% to 97.2% for distinguishing ALL, AML, and normal cell images."
명령 실행 모니터링과 딥 러닝을 이용한 파워셸 기반 악성코드 탐지 방법,2018,"['PowerShell', 'malware', 'execution monitoring', 'deep learning']","파워셸은 닷넷 프레임워크를 기반에 둔, 커맨드 라인 셸이자 스크립트 언어로, 그 자체가 가진 다양한 기능 외에도 윈도우 운영체제 기본 탑재, 코드 은닉 및 지속의 수월함, 다양한 모의 침투 프레임워크 등 공격 도구로서 여러 이점을 가지고 있다. 이에 따라 파워셸을 이용하는 악성코드가 급증하고 있으나 기존의 악성코드 탐지 기법으로 대응하기에는 한계가 존재한다. 이에 본 논문에서는 파워셸에서 실행되는 명령들을 관찰할 수 있는 개선된 모니터링 기법과, Convolutional Neural Network(CNN)을 이용해 명령에서 특징을 추출하고 실행 순서에 따라 Recurrent Neural Network(RNN)에 전달하여 악성 여부를 판단하는 딥 러닝 기반의 분류 모델을 제안한다. 악성코드 공유 사이트에서 수집한 파워셸 기반 악성코드 1,916개와 난독화 탐지 연구에서 공개한 정상 스크립트 38,148개를 이용하여 제안한 모델을 5-fold 교차 검증으로 테스트한 결과, 약 97%의 True Positive Rate(TPR)와 1%의 False Positive Rate(FPR)로 모델이 악성코드를 효과적으로 탐지함을 보인다.","PowerShell is command line shell and scripting language, built on the .NET framework, and it has several advantages as an attack tool, including built-in support for Windows, easy code concealment and persistence, and various pen-test frameworks. Accordingly, malwares using PowerShell are increasing rapidly, however, there is a limit to cope with the conventional malware detection technique. In this paper, we propose an improved monitoring method to observe commands executed in the PowerShell and a deep learning based malware classification model that extract features from commands using Convolutional Neural Network(CNN) and send them to Recurrent Neural Network(RNN) according to the order of execution. As a result of testing the proposed model with 5-fold cross validation using 1,916 PowerShell-based malwares collected at malware sharing site and 38,148 benign scripts disclosed by an obfuscation detection study, it shows that the model effectively detects malwares with about 97% True Positive Rate(TPR) and 1% False Positive Rate(FPR)."
펄스 내 변조 저피탐 레이더 신호 자동 식별,2018,"['LPI Radar(저피탐 레이더)', 'Intrapulse Modulation(펄스 내 변조)', 'Convolutional Neural Network(콘볼루션신경망)', 'Parameter Extraction(식별인자 추출)']",국문 초록 정보 없음,"In electronic warfare(EW), low probability of intercept(LPI) radar signal is a survival technique. Accordingly, identification techniques of the LPI radar waveform have became significant recently. In this paper, classification and extracting parameters techniques for 7 intrapulse modulated radar signals are introduced. We propose a technique of classifying intrapulse modulated radar signals using Convolutional Neural Network(CNN). The time-frequency image(TFI) obtained from Choi-William Distribution(CWD) is used as the input of CNN without extracting the extra feature of each intrapulse modulated radar signals. In addition a method to extract the intrapulse radar modulation parameters using binary image processing is introduced. We demonstrate the performance of the proposed intrapulse radar waveform identification system. Simulation results show that the classification system achieves a overall correct classification success rate of 90 % or better at SNR = -6 dB and the parameter extraction system has an overall error of less than 10 % at SNR of less than -4 dB."
Convolutional Neural Network를 이용한 웹 어플리케이션 공격 탐지 기법,2018,"['convolutional neural network', 'supervised learning', 'SQL injection', 'cross site scripting', 'web application', '컨볼루션 신경망', '지도학습', 'SQL 인젝션', '크로스 사이트 스크립팅', '웹 어플리케이션']","웹 어플리케이션 공격이 급격하게 늘면서 기존의 기법들만으로는 이를 탐지하는 것이 한계가있어, 기계학습 기반의 탐지 기법이 연구되기 시작하였다. 기계학습을 활용한 기존 기법은 공격 탐지를 위해 적절한 특징(feature)을 선정해야 하는 어려움이 있으며, 새로운 공격 패턴이 등장할 경우 이에 적합하도록 특징을 재선정해야 할 경우도 발생한다. 본 논문에서는 HTTP 트래픽을 구성하는 입력이 허용되는 문자에 대한 제한 없이 문자 단위로 16진수 변환한 후 이미지화하고, 이를 입력으로 하는 convolutional neural network을 통해 웹 어플리케이션 공격을 탐지하는 기법을 제안한다. 제안 기법은 별도의 특징 선정 없이 지도학습을 통해 이미지화 된 HTTP 트래픽을 학습하며, 기존의 기계학습 기법보다 최대 84.4% 까지 공격 탐지 오류율 성능을 향상할 수 있음을 보였다.","Because rates of web application attacks are rapidly increasing, web application attack detection schemes using machine learning have recently become of interest. Existing schemes, however, require the selection of a suitable set of features representing the characteristics of expected attacks, and this set of features needs to be adjusted every time a new type of attack is discovered.In this paper, we propose a web application attack detection scheme employing a convolutional neural network (CNN) without the need to select any features in advance. Specifically, the CNN is trained in a supervised manner with images transformed from hexadecimally converted characters in HTTP traffic, without any restriction in the input characters used. Our experimental results show that the proposed scheme improves detection error rate performance by up to 84.4% over existing schemes."
Biased Dropout and Crossmap Dropout: Learning towards effective Dropout regularization in convolutional neural network,2018,"['Dropout', 'Regularization', 'Convolutional neural network']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Training a deep neural network with a large number of parameters often leads to overfitting problem. Recently, Dropout has been introduced as a simple, yet effective regularization approach to combat overfitting in such models. Although Dropout has shown remarkable results on many deep neural network cases, its actual effect on CNN has not been thoroughly explored. Moreover, training a Dropout model will significantly increase the training time as it takes longer time to converge than a non-Dropout model with the same architecture. To deal with these issues, we address Biased Dropout and Crossmap Dropout, two novel approaches of Dropout extension based on the behavior of hidden units in CNN model. Biased Dropout divides the hidden units in a certain layer into two groups based on their magnitude and applies different Dropout rate to each group appropriately. Hidden units with higher activation value, which give more contributions to the network final performance, will be retained by a lower Dropout rate, while units with lower activation value will be exposed to a higher Dropout rate to compensate the previous part. The second approach is Crossmap Dropout, which is an extension of the regular Dropout in convolution layer. Each feature map in a convolution layer has a strong correlation between each other, particularly in every identical pixel location in each feature map. Crossmap Dropout tries to maintain this important correlation yet at the same time break the correlation between each adjacent pixel with respect to all feature maps by applying the same Dropout mask to all feature maps, so that all pixels or units in equivalent positions in each feature map will be either dropped or active during training. Our experiment with various benchmark datasets shows that our approaches provide better generalization than the regular Dropout. Moreover, our Biased Dropout takes faster time to converge during training phase, suggesting that assigning noise appropriately in hidden units can lead to an effective regularization.</P>"
Privacy-preserving image retrieval for mobile devices with deep features on the cloud,2018,"['Artificial intelligence', 'Image retrieval', 'Deep features', 'Cloud', 'Privacy preservation', 'Features extraction']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>With the prevalent use of mobile cameras to capture images, the demands for efficient and effective methods for indexing and retrieval of personal image collections on mobile devices have also risen. In this paper, we propose to represent images with hash codes, which is a compressed representation of deep convolutional features using deep auto-encoder on the cloud. To ensure user's privacy, the image is first encrypted using a light-weight encryption algorithm on mobile device prior to offloading it to the cloud for features extraction. This approach eliminates the computationally expensive process of features extraction on resource constrained devices. A pre-trained convolutional neural network (CNN) is used to extract features which are then transformed to compact binary codes using a deep auto-encoder. The hash codes are then sent back to the mobile device where they are stored in a hash table along with image location. Approximate nearest neighbor (ANN) search approach is utilized to efficiently retrieve the desired images without exhaustive searching of the entire image collection. The proposed method is evaluated against three different publicly available image datasets namely Corel-10K, GHIM-10K, and Product image dataset. Experimental results demonstrate that features representation using CNN and auto-encoder shows much better results than several state-of-the-art hashing schemes for image retrieval on mobile devices.</P>"
DSIP: A Scalable Inference Accelerator for Convolutional Neural Networks,2018,[],국문 초록 정보 없음,"<P>This paper presents a scalable inference accelerator called a deep-learning specific instruction-set processor (DSIP) to support various convolutional neural networks (CNNs). For CNNs requiring a large amount of computations and memory accesses, a programmable inference system called master–slave instruction set architecture (ISA) is newly proposed to achieve high flexibility, processing speed, and energy efficiency. The master is responsible for sending and receiving feature maps in order to deal with neural networks in a scalable way, and the slave performs CNN operations, such as multiply accumulate, max pooling, and activation functions, on the features received from the master. The master–slave ISA maximizes computation speed by overlapping the off-chip data transmission and the CNN operations, and reduces power consumption by performing the convolution incrementally to reuse input and partial-sum data as maximally as possible. An inference system can be configured by connecting multiple DSIPs in a form of either 1-D or 2-D chain structure in order to enhance computation speed further. To evaluate the proposed accelerator, a prototype chip is implemented and evaluated for AlexNet. Compared to the state-of-the-art accelerator, the DSIP-based system enhances the energy efficiency by 2.17 <TEX>$\times $</TEX>.</P>"
Image retrieval using BIM and features from pretrained VGG network for indoor localization,2018,"['Image-based indoor localization', 'Cross-domain image retrieval', 'BIM', 'Feature extraction', 'Global descriptor']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Various devices that are used indoors require information regarding the user's position and orientation. This information enables the devices to offer the user customized and more relevant information. This study presents a new image-based indoor localization method using building information modeling (BIM) and convolutional neural networks (CNNs). This method constructs a dataset with rendered BIM images and searches the dataset for images most similar to indoor photographs, thereby estimating the indoor position and orientation of the photograph. A pretrained CNN (the VGG network) is used for image feature extraction for the similarity evaluation of two different types of images (BIM rendered and real images). Experiments were performed in real buildings to verify the method, and the matching accuracy is 91.61% for a total of 143 images. The results also confirm that pooling layer 4 in the VGG network is best suited for feature selection.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A method utilizing CNN and BIM for image-based indoor localization is proposed. </LI> <LI>  The image most similar to the photo is retrieved from the dataset built from BIM. </LI> <LI>  Features are extracted by the VGG for evaluating similarity between images. </LI> <LI>  The most suitable layer in the VGG for cross-domain image retrieval is identified. </LI> <LI>  A high performance in the experiment verified the proposed method. </LI> </UL> </P>"
딥러닝을 이용한 히트펌프 시스템의 냉매량 고장 감지에 관한 연구,2018,"['Heat pump system(히트펌프 시스템)', 'Refrigerant charge fault detection(냉매량 고장진단)', 'Convolutional neural network(합성곱 신경망)', 'Classification(분류)']",국문 초록 정보 없음,다국어 초록 정보 없음
Photographic composition classification and dominant geometric element detection for outdoor scenes,2018,"['Image classification', 'Photographic composition', 'Composition element detection', 'Geometric element detection', 'Sky detection', 'Rule of thirds']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Despite the practical importance of photographic composition for improving or assessing the aesthetical quality of photographs, only a few simple composition rules have been considered for its classification. In this work, we propose novel techniques to classify photographic composition rules of outdoor scenes and detect dominant geometric elements, called composition elements, for each composition class. Specifically, we first categorize composition rules of outdoor photographs into nine classes: <I>RoT</I>, <I>center</I>, <I>horizontal</I>, <I>symmetric</I>, <I>diagonal</I>, <I>curved</I>, <I>vertical</I>, <I>triangle</I>, and <I>pattern</I>. Then, we develop a photographic composition classification algorithm using a convolutional neural network (CNN). To train the CNN, we construct a photographic composition database, which is publicly available. Finally, for each composition class, we propose an effective scheme to locate composition elements, <I>i.e.</I>, bounding boxes for main subjects, leading lines, axes of symmetry, triangles, and sky regions. Extensive experimental results demonstrate that the proposed algorithm classifies composition classes reliably and detects composition elements accurately.</P>"
Classification of apple leaf conditions in hyper-spectral images for diagnosis of <i>Marssonina</i> blotch using mRMR and deep neural network,2018,"['Hyper-spectral image', 'Apple Marssonina blotch', 'Feature selection', 'Deep neural network', 'Plant disease diagnosis']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>In general, in order to reduce the number of bands in hyper-spectral images, transformed features such as principal component analysis (PCA) cannot directly provide information indicating which raw spectral bands are essential, even though they provide reduced dimensionality for the consecutive analysis. This paper proposes minimum redundancy and maximum relevance (mRMR) feature selection techniques to directly choose essential raw bands from hyper-spectral images. In addition a deep neural network is suggested to classify the hyper-spectral data with reduced dimension, which consists of a convolutional neural network (CNN) followed by a fully connected network (FCN). The CNN extracts meaningful features like PCA, but in a nonlinear, supervised manner, and the FCN classifies the six apple leaf conditions including normal, young, malnutrition, early and late stages of apple <I>Marssonina</I> blotch (AMB), and background. Experimentally, we found five essential spectral bands using the mRMR techniques (777.24 nm, 547.77 nm, 474.32 nm, 859.45 nm, and 735.85 nm), which proved to have better accuracy than RGB image for the classification using the deep neural network. The proposed scheme is applicable for band reduction to obtain the efficient multispectral sensor system in the sense that only several essential spectral bands are chosen, and more accurate diagnosis of plant diseases is possible by reducing the complexity involved in hyper-spectral images.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  mRMR band selection preserves the necessary information for monitoring AMB in apple leaves. </LI> <LI>  DNN is excellent for classifying leaf conditions not only using RGB images, but also hyper-spectral images with a reduced number of bands. </LI> <LI>  Essential spectrums from hyper-spectral show high performance DNN-type classifiers. </LI> </UL> </P>"
단어의 의미와 문맥을 고려한 순환신경망 기반의 문서 분류,2018,"['문서 분류', 'Doc2vec 순환신경망']","본 논문에서는 단어의 순서와 문맥을 고려하는 특징을 추출하여 순환신경망(Recurrent Neural Network)으로 문서를 분류하는 방법을 제안한다. 단어의 의미를 고려한 word2vec 방법으로 문서내의 단어를 벡터로 표현하고, 문맥을 고려하기 위해 doc2vec으로 입력하여 문서의 특징을 추출한다. 문서분류 방법으로 이전 노드의 출력을 다음 노드의 입력으로 포함하는 RNN 분류기를 사용한다. RNN 분류기는 신경망 분류기 중에서도 시퀀스 데이터에 적합하기 때문에 문서 분류에 좋은 성능을 보인다. RNN에서도 그라디언트가 소실되는 문제를 해결해주고 계산속도가 빠른 GRU(Gated Recurrent Unit) 모델을 사용한다. 실험 데이터로 한글 문서 집합 1개와 영어 문서 집합 2개를 사용하였고 실험 결과 GRU 기반 문서 분류기가 CNN 기반 문서 분류기 대비 약 3.5%의 성능 향상을 보였다.","In this paper, we propose a method to classify a document using a Recurrent Neural Network by extracting features considering word sense and contexts. Word2vec method is adopted to include the order and meaning of the words expressing the word in the document as a vector. Doc2vec is applied for considering the context to extract the feature of the document. RNN classifier, which includes the output of the previous node as the input of the next node, is used as the document classification method. RNN classifier presents good performance for document classification because it is suitable for sequence data among neural network classifiers. We applied GRU (Gated Recurrent Unit) model which solves the vanishing gradient problem of RNN. It also reduces computation speed. We used one Hangul document set and two English document sets for the experiments and GRU based document classifier improves performance by about 3.5% compared to CNN based document classifier."
환경 빅데이터 분석 및 서비스 개발 Ⅱ,2018,"['빅데이터', '기계학습', '심층신경망', '자연언어분석', '감성분석', 'Big Data', 'Machine Learning', 'Neural Network', 'Deep Learning', 'Sentiment Analysis']","본 연구는 2017년부터 시작된 계속사업으로서, 환경연구에 기계학습(Machine Learning) 연구방법론을 접목하여 환경정책 개발 가능성을 모색하는 연구이다. 본 연구는 환경연구에 빅데이터 방법론을 적용하는 ‘환경 빅데이터 연구’, 환경 빅데이터 연구에 필요한 대용량 데이터 수집 및 처리 인프라를 구축하는 ‘환경 빅데이터 인프라 구축’, 환경 빅데이터 연구 성과를 기반으로 원내·외 서비스를 개발하는 ‘원내·외 빅데이터 서비스 개발’ 등 3개 영역으로 구성되며, 연구단계별로 각 3년씩 총 3단계에 걸쳐 진행한다. 2018년은 환경 빅데이터 연구에 중점을 두는 제1단계(2017~2019년)의 2차 연도에 해당된다.2018년 환경 빅데이터 연구 영역에서는 2017년에는 인프라의 한계로 시도하기 어려웠던 대용량-비정형 데이터 분석을 시작하였고, 대기-기후 관련 매체 연구에 주력하였던 연구의 영역을 수질 및 수용체 반응을 대상으로 확대하였다. 환경 빅데이터 인프라 구축 영역에서는 대용량-비정형 데이터 연구를 수행할 수 있는 환경 빅데이터 플랫폼 구축을 병행하였다. 그리고 환경 빅데이터 서비스 개발 영역에서는 2017년 연구성과를 이용하여 환경연구 텍스트 데이터로부터 연구주제 및 연구키워드 네트워크를 파악하는 연구동향 파악 서비스를 구축하였다. 세부적인 연구의 성과들을 영역별로 요약하면 다음과 같다.첫 번째, 2018년 환경 빅데이터 연구 영역에서는 총 5건의 연구를 수행하였다. 5건의 연구 중 대용량-비정형 데이터 분석으로 환경 빅데이터 분석 영역을 확대한 연구는 ‘컨벌루션 신경망을 활용한 미세먼지 예측’, ‘기계학습 기반 환경이슈 감성분류기 개발: 기후변화를 중심으로’, ‘딥러닝을 이용한 국내 COPD 노인환자의 사망위험 추정’ 3건이다. 그리고 ‘데이터 기반 한강 수질 예측모형 개발’ 연구를 수행하여 매체 연구의 영역을 수질로 확장하였고, ‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’ 연구를 수행하여 수용체의 반응을 연구의 영역에 포괄하였다.‘컨벌루션 신경망을 활용한 미세먼지 예측’ 연구에서는 컨벌루션 신경망 모형을 이용하여 미세먼지 오염도를 예측하는 알고리듬을 개발하였다. 이 알고리듬은 전국을 10×10 격자로 구분한 공간의 미세먼지 오염도를 1~24시간 이전에 예측하는 데 활용되었다. 이 알고리듬은 4개 대기오염물질 오염도 정보 및 4개 기상 정보를 예측에 활용하였다. 이 알고리듬에 투입된 모든 정보는 컨벌루션 신경망의 입력자료로 활용될 수 있도록 전국을 10×10 격자로 구분한 공간에 역거리가중법(IDW)을 이용하여 할당되었다. 이 알고리듬은 1시간 이후 미세먼지 농도 예측의 평균제곱근오차를 2.07㎍/㎥ 까지 축소할 수 있었으며, 8시간 이후 예측의 평균제곱근오차도 9.09㎍/㎥ 까지 축소할 수 있었다. 이는 2017년에 개발한 KNN-순환신경망 모형의 1시간 이후 예측치 평균제곱근오차 7.96㎍/㎥ 를 획기적으로 개선한 결과이다.‘기계학습 기반 환경이슈 감성분류기 개발: 기후변화 중심으로’ 연구에서는 임베딩을 이용한 양방향 장단기 메모리(Bidirectional Long Short-Term Memory) 모형을 이용하여 기후변화와 관련된 SNS 문서의 감성을 7가지로 분류하는 감성분류기를 개발하였다. 이를 위해 기후변화 감성분류기 개발 과정에서 SNS 문서가 기후변화와 관련이 있는 문서인지 판별하는 기준이 되는 ‘기후변화 현상 사전’을 구축하여 SNS 문서 5만 건을 수집하였다. 그리고 수집된 5만 건을 수작업을 통해 7가지 감성으로 분류하여 감성 태그를 부여하였고, 이렇게 구축된 학습 데이터에 임베딩을 이용한 양방향 장단기 메모리(Bi-LSTM) 알고리듬을 적용하여 감성분류기를 개발하였다. Bi-LSTM을 이용한 감성분류기는 7가지 감성으로 분류했을 때 정확도가 85.10%였으며, 긍정-중립-부정 3가지로 감성을 단순화할 경우에는 정확도가 92.95%까지 향상되었다. 감성분류기의 개발과 더불어 이 연구를 통해 ‘기후변화 현상 사전’을 구축하였고 감성이 분류된 5만 건의 SNS 자료를 축적하였다. 사전 및 감성이 분류된 자료는 감성분류 연구에서 필수적으로 요구되는 도구로서 기후변화와 관련된 이들 도구는 본 연구에서 국내 최초로 구축하였다.‘딥러닝을 이용한 국내 COPD 노인환자의 사망위험 추정’ 연구는 대용량 자료인 건강보험 DB를 사용하는 연구이다. 이 연구는 전처리 단계에 많은 시간이 소요됨을 감안하여 2년에 걸쳐 2단계로 진행한다. 2018년에 추진한 제1단계에서는 입력 데이터를 구축하고, 2019년 진행 예정인 제2단계에서는 제1단계에서 구축한 자료를 이용하여 사망요인을 파악하고 사망 확률을 추정한다. 2018년 본 연구에서는 건강보험 맞춤형 연구자료로부터 추출한 65세 이상 COPD 환자 657,432명의 개인별 건강정보와 각 개인이 거주하는 시군구의 인구, 기상기후요인, 대기오염물질 오염도를 결합한 입력자료를 구축하였다.‘데이터 기반 한강 수질 예측모형 개발’ 연구에서는 순환신경망 모형 중 GRU(Gated Recurrent Unit) 모형을 이용하여 수질오염물질 오염도를 예측하는 알고리듬을 개발하였다. 이 알고리듬을 통해 가양, 노량진, 팔당 등 3개 한강 수계 수질측정소의 클로로필-a 농도를 1주일 전에 예측하는 데 활용되었다. 이 알고리듬은 예측지점 및 예측지점 상류지역의 수질오염 정보, 인근지역의 기상 정보, 그리고 인근지역의 수위 및 유량 정보를 예측에 활용하였다. 이 연구에서 개발한 GRU 알고리듬은 1주일 후 클로로필-a 농도 예측의 평균 제곱근오차를 10.93까지 축소할 수 있었다. 이는 단순회귀분석의 평균제곱근오차 16.95를 35.3% 개선한 성과이다. 특히 순환신경망 알고리듬은 급작스럽게 클로로필-a 농도가 증가하여도 근사한 예측치를 제공하였다. 통상적으로 사용되는 회귀분석 및 시계열 분석은 실측치가 급작스럽게 증가 또는 감소하면 그 증감이 증감시점 이후의 예측치에 반영되는 지연 예측 현상이 나타나는데, 이 연구의 결과는 이러한 회귀분석 및 시계열 분석의 약점을 개선할 수 있는 대안을 제시하였다.‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’ 연구에서는 미세먼지 농도가 서울 지하철 승하차 인원에 미치는 영향을 Boosted Decision Tree 모형을 사용하여 분석 하였다. 이 연구에서는 대기오염물질의 오염도, 그리고 기상 정보를 이용하여 개별 지하철역의 시간별 지하철 승하차 인원을 추정하는 Boosted Decision Tree 알고리듬을 구축하고 민감도 분석을 수행하여 미세먼지 오염도의 변화가 승하차 인원 예측치에 주는 영향을 정량적으로 파악하였다. 이 연구에서 구축한 Boosted Decision Tree 모형은 지하철 승하차 인원을 평균제곱근오차 0.11 이내로 예측할 수 있었다. 이는 선형회귀분석의 평균제곱근 오차 0.71을 84.5%나 개선한 결과이다. 이렇게 예측의 정확도를 높인 Boosted Decision Tree 모형을 사용하여 민감도 분석을 수행한 결과, 미세먼지 농도가 10% 증가하면 하차 인원이 0.2% 감소하고, 미세먼지 농도가 10% 감소하면 하차 인원이 1.4% 증가하는 것으로 파악되었다. 이렇게 미세먼지 농도 증가에 따른 하차 인원 감소가 미세먼지 농도 감소에 따른 하차 인원 증가보다 작은 경향은 승하차 인원, 승하차 시간 및 지하철역 주변 토지용도에 관계없이 일관되게 관찰되었다.두 번째, 2018년 환경 빅데이터 인프라 구축 영역에서는 대용량 자료 수집 및 자료 분석 기능을 구비한 환경 빅데이터 플랫폼을 설계하였고, 이를 1개 서버에 구현하였다. 자료 수집과 관련해서는 오픈데이터맵(Open Data Map)을 구축하여 환경연구 문헌에서 자주 인용되는 인터넷 자료의 검색 및 수집 기능을 부여하였고, 자료 분석과 관련해서는 대용량 자료를 분석할 수 있는 웹 개발 환경과 CLI(Command Line Interface) 환경을 설계하여 동일한 서버에 구현하였다.오픈데이터맵은 환경연구에서 자주 인용되는 온라인 자료들의 출처에 대한 정보와 링크를 제공한다. 본 연구에서 구축한 오픈데이터맵에 수록된 온라인 자료 출처는 2018년 현재 한국환경정책·평가연구원 도서관 DB에 수록된 한국환경정책·평가연구원 발간 문헌 1,925건의 전문에서 인용된 온라인 자료 출처들이다. 이 문헌들은 총 11개 부문(category)으로 분류하였고, 개별 온라인 자료 출처는 그 출처가 인용된 문건을 가장 많이 포괄하는 부문에 따라 부문별로 분류되었다. 각 부문 내에서는 그 부문에 속한 개별 온라인 자료 출처에 인용 문건의 수에 따라 순위를 부여하였고, 인용된 문건의 키워드를 개별 온라인 자료 출처의 키워드로 배정하였다. 오픈데이터맵은 이렇게 구축된 부문별 온라인 자료 출처의 순위, 온라인 주소(URL), 제목, 설명, 키워드를 사용자에게 보여주고 링크를 제공하여 사용자가 필요한 온라인 자료 출처를 찾아갈 수 있도록 하였다. 또한 키워드 검색 기능을 추가하여 부문이 아닌 키워드를 기준으로 자료 출처를 검색할 수도 있게 하였다.대용량 데이터 분석 기능을 갖추기 위해서는 프로그램 개발 언어 중 R과 Python을 사용할 수 있는 웹 환경과 Ubuntu Linux를 사용할 수 있는 CLI 환경을 구성하였다. 웹 환경은 이미 개발된 알고리듬을 웹 환경에 등재하여 분석을 수행하거나, R 또는 Python을 활용해서 알고리듬을 개발하고자 하는 연구자가 사용할 수 있는 환경이다. CLI 환경은 운영체제(Linux) 언어와 프로그램 개발 언어(R, Python)를 자유롭게 조합하여 사용할 수 있는 환경으로서, 데이터 수집-전처리-분석 전 과정을 포괄하는 연구를 수행하고자 하는 연구자가 활용하기에 적합하다. 이러한 분석 환경은 현재 본 연구단이 보유하고 있는 서버에 구현되어 있으며, 본 연구의 연구진들에게 제공되고 있다.마지막으로, 2018년 원내·외 환경 빅데이터 서비스 개발 영역에서는 그동안 한국환경정책·평가연구원에서 발간된 보고서들을 통해 연구주제의 동향을 파악하는 ‘연구동향 분석 서비스’를 개발하였고, 한국환경정책·평가연구원 보고서 제목의 키워드 및 네트워크를 파악하는 ‘연구키워드 분석 서비스’를 개발하였다. 두 서비스 모두 사용자가 임의의 텍스트 자료를 입력하면 입력자료의 토픽 및 키워드 네트워크를 실시간으로 파악할 수 있는 기능을 갖고 있다. 이들 서비스는 2017년 본 연구에서 수행하여 개발한 ‘텍스트 마이닝을 이용한 KEI 연구동향 분석’ 알고리듬을 임의로 입력하는 자료에도 구동될 수 있도록 개선하여 구축한 서비스이다.‘연구동향 분석 서비스’는 LDA 토픽 모델링 기법을 텍스트에 적용하여 텍스트의 주제를 추출하고, 그 결과를 시각화하여 보여주는 서비스이다. 이 서비스는 사용자가 복수의 문서로 구성된 텍스트 자료를 입력하면, 그 자료를 대상으로 LDA 분석을 수행하여 주제를 추출하고 개별 문서에 적합한 주제를 할당한다. LDA 분석에 필요한 텍스트 자료 전처리 과정(형태소 분석, 불용어 제거, 문서-단어 행렬 구축)은 서비스 내부에 구현되어 있어서 텍스트 자료를 입력하면 자동으로 수행된다. 사용자는 텍스트 자료에 수록된 문서의 주제 분포를 전반적으로 파악할 수 있고, 또한 문서 발간 시점의 시계열에 따라 파악할 수 있다. 현재 이 서비스는 1993~2016년에 발간된 한국환경정책·평가연구원 보고서의 제목, 목차, 요약으로 구성된 텍스트 자료의 토픽을 추출한 결과를 보여주고 있다.‘연구키워드 분석 서비스’는 키워드 추출 및 네트워크 파악 기법을 텍스트에 적용하여 키워드를 추출하고, 키워드 동시발생 테이블 및 키워드 네트워크를 구축하는 서비스이다. 이 서비스는 사용자가 텍스트 자료를 입력하면, 그 자료의 단어-단어 동시발생 테이블을 계산하고, Apriori 알고리듬을 수행하여 키워드 네트워크를 도출한다. ‘연구동향 분석 서비스’와 마찬가지로 텍스트 자료 전처리 과정은 서비스 내부에 구현되어서 자료가 입력되면 자동으로 수행된다. 사용자는 키워드 목록 및 2개 키워드 사이의 관계(Support, Confidence, Lift)를 보여주는 테이블과 여러 키워드 간의 네트워크를 시각화한 관계도를 파악할 수 있다. 현재 이 서비스을 통해 2018년 현재 한국환경정책·평가연구원 도서관 DB에 수록된 연구제목 텍스트의 키워드 분석 결과를 볼 수 있다.2018년 본 연구의 결과는 빅데이터 연구방법론의 장점인 예측의 정확도 및 결과의 재생-확장 가능성을 확인시켜 주었다. 본 연구의 환경 빅데이터 연구 영역의 성과는 빅데이터 연구방법론을 적용하면 기존의 방법론보다는 환경오염 및 환경오염 대응 수용체의 반응에 대한 예측오차를 크게 축소할 수 있음을 보여주었다. 특히 데이터의 규모가 1GB를 상회하는 2개 연구 ‘컨벌루션 신경망을 활용한 미세먼지 예측’, ‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’과 추정 대상 변수가 극단적인 값을 갖는 2개 연구 ‘데이터 기반 한강 수질 예측모형 개발’, ‘미세먼지 오염이 서울시 지하철 이용에 미치는 영향 분석’에서 이러한 빅데이터 방법론의 예측오차 축소 성과가 두드러지게 나타났다.그리고 본 연구에서 개발한 2개의 연구동향 파악 서비스는 빅데이터 연구방법론과 연구 결과의 재활용 및 확장 가능성을 보여주었다. 2개 서비스 모두 2017년 연구에서 개발되었던 LDA 토픽 추출 알고리듬 및 키워드 파악 알고리듬을 사용하여 구축되었다. 2017년 연구에서는 이들 알고리듬을 특정한 텍스트 분석에서만 사용하였지만, 2018년 연구에서는 이들 알고리듬을 임의의 입력자료에 대해 분석을 수행할 수 있도록 범용성을 확대하였다. 그 결과 기계학습에 관련된 사전지식이 없는 사용자들도 2017년 연구의 성과를 활용할 수 있는 환경이 구축되었다.2018년 연구 중 ‘컨벌루션 신경망을 활용한 미세먼지 예측’ 연구에서 개발한 미세먼지 오염도 예측 알고리듬, ‘데이터 기반 한강 수질 예측모형 개발’ 연구에서 개발한 클로로필-a 농도 예측 알고리듬은 정책수요 파악에 필요한 정보를 제공한다. 이들 알고리듬은 소규모 지역 단위 환경오염 예측치를 실시간으로 제공하기 때문에, 정책대응이 필요한 시점 및 장소를 사전에 인지하여 정책대응 수단을 집중하는 데 필요한 정보를 제공한다. 그리고 ‘기계 학습 기반 환경이슈 감성분류기 개발: 기후변화 중심으로’ 연구에서 개발한 기후변화 관련 SNS 감성분석기는 기후변화 관련 국민 감성을 파악하여 정책 개입의 필요성을 진단하는 도구로 사용할 수 있다.중장기적으로는 이들 3개 알고리듬을 상시 가동할 수 있도록 개편하면 정책의 시행 전후에 이들을 가동함으로써 정책성과를 모니터링할 수 있다. 정책 개입 이전의 2개 예측 알고리듬의 환경오염 예측치는 ‘개입이 없을 경우(Business as usual)’의 예측치를 제공하므로, 이들 예측치와 정책 개입 이후의 실측치를 비교하면 정책 개입의 환경오염 개선 효과에 대한 정량적인 근사치를 얻을 수 있다. 그리고 특정 기후변화 정책 시행 이전과 이후에 기후 변화 관련 SNS 감성분석기를 가동하여 감성 수준을 파악하면, 정책이 국민감성의 호전에 도움이 되었는지 여부를 파악할 수 있다. 3개 알고리듬의 데이터 전처리 과정을 자동화하여 상시적으로 가동할 수 있도록 개편하면 이러한 정책 모니터링을 상시 수행할 수 있다.3년차 이후 본 연구는 이러한 정책 모니터링 기능을 환경정책 전 부문으로 확장하는 방향으로 진행할 예정이다. 구체적으로 환경오염 예측 알고리듬은 대기 및 수질오염 전반을 예측할 수 있는 알고리듬으로 확대 개편하고, SNS 감성분석기 역시 환경정책 전 영역에 대한 감성분석이 가능한 알고리듬으로 확대 개편하고자 한다. 그리고 이들 두 알고리듬을 상시적으로 가동하여 정책수요를 파악하고 정책대응을 모니터링하는 서비스를 개발하고자 한다.","This report reports the result from second year research of ‘Big Data analysis: Application to Environmental Research and Service’ project. In this project, we try to take advantage of machine learning in Environmental Research. This project consists of three sub-projects. The first one ‘Big Data Environment Research’, experiments machine learning algorithm to environmental research. The second one ‘Big Data Research Infra’ builds up large scale data collection and analysis facility. The third one ‘Big Data Environmental Service’ develops public environmental service using the results from ‘Big Data Environmental Research’ and ‘Big Data Research Infra’. We planned to spend three years for each sub-project, beginning from 2017. 2018 is the second year of first sub-project ‘Big Data Environment Research’.In 2018, we developed four machine learning algorithms - CNN algorithm predicting 1~8 hours ahead fine-dust pollution. GRU algorithm predicting 1 week ahead chlorophyl-a pollution. Bidirectional LSTM algorithm for sentiment analysis of climate change SNS data, and Boosted Tree algorithm for analyzing the effect of fine-dust pollution to the number of passengers of Seoul subway. Our sentiment analysis algorithm had 92.95% accuracy. Our CNN algorithm for fine dust pollution prediction cut down RMSE of 1 hour ahead estimation to as low as 2.07μg/㎥. Our GRU algorithm for chlorophyl-a pollution prediction had RMSE smaller than the RMSE of Vector Auto Regression by 35.3%. And our Boosted Tree algorithm for subway passenger analysis had RMSE smaller than the RMSE of linear regression by 84.5%. In general, we confirmed that machine learning algorithm had significant advantage in accurate prediction in wide range of environmental research."
Human‐like sign‐language learning method using deep learning,2018,"['CNN', 'deep learning', 'sign language']",국문 초록 정보 없음,"This paper proposes a human‐like sign‐language learning method that uses a deep‐learning technique. Inspired by the fact that humans can learn sign language from just a set of pictures in a book, in the proposed method, the input data are pre‐processed into an image. In addition, the network is partially pre‐trained to imitate the preliminarily obtained knowledge of humans. The learning process is implemented with a well‐known network, that is, a convolutional neural network. Twelve sign actions are learned in 10 situations, and can be recognized with an accuracy of 99% in scenarios with low‐cost equipment and limited data. The results show that the system is highly practical, as well as accurate and robust."
열화상 영상 잡음 제거 알고리즘 성능 비교,2018,"['CNN', 'Denoising', 'Non-local self similarity', 'Discriminative learning', 'Thermal image']",국문 초록 정보 없음,다국어 초록 정보 없음
Text Categorization with Improved Deep Learning Methods,2018,"['CNN', 'Disorder', 'LSTM', 'Text categorization']",국문 초록 정보 없음,"Although deep learning methods of convolutional neural networks (CNNs) and long-/short-term memory (LSTM) are widely used for text categorization, they still have certain shortcomings. CNNs require that the text retain some order, that the pooling lengths be identical, and that collateral analysis is impossible; In case of LSTM, it requires the unidirectional operation and the inputs/outputs are very complex. Against these problems, we thus improved these traditional deep learning methods in the following ways: We created collateral CNNs accepting disorder and variable-length pooling, and we removed the input/output gates when creating bidirectional LSTMs. We have used four benchmark datasets for topic and sentiment classification using the new methods that we propose. The best results were obtained by combining LTSM regional embeddings with data convolution. Our method is better than all previous methods (including deep learning methods) in terms of topic and sentiment classification."
DNN 기반 컬러와 열 영상을 이용한 다중 스펙트럼 보행자 검출 기법,2018,"['CNN', 'pedestrian detection', 'multi-spectrum', 'network fusion']",국문 초록 정보 없음,"As autonomous driving research is rapidly developing, pedestrian detection study is also successfully investigated. However, most of the study utilizes color image datasets and those are relatively easy to detect the pedestrian. In case of color images, the scene should be exposed by enough light in order to capture the pedestrian and it is not easy for the conventional methods to detect the pedestrian if it is the other case. Therefore, in this paper, we propose deep neural network (DNN)-based multi-spectrum pedestrian detection method using color and thermal images. Based on single-shot multibox detector (SSD), we propose fusion network structures which simultaneously employ color and thermal images. In the experiment, we used KAIST dataset. We showed that proposed SSD-H (SSD-Halfway fusion) technique shows 18.18% lower miss rate compared to the KAIST pedestrian detection baseline. In addition, the proposed method shows at least 2.1% lower miss rate compared to the conventional halfway fusion method."
컨볼루션 신경망을 이용한 철도역사 화재 감지 시스템 구현,2018,"['철도역사', 'CNN', '학습', '연기', '화염']",국문 초록 정보 없음,다국어 초록 정보 없음
Variations of AlexNet and GoogLeNet to Improve Korean Character Recognition Performance,2018,"['Classification', 'CNN', 'Deep Learning', 'Korean Character Recognition']",국문 초록 정보 없음,"Deep learning using convolutional neural networks (CNNs) is being studied in various fields of imagerecognition and these studies show excellent performance. In this paper, we compare the performance ofCNN architectures, KCR-AlexNet and KCR-GoogLeNet. The experimental data used in this paper is obtainedfrom PHD08, a large-scale Korean character database. It has 2,187 samples of each Korean character with2,350 Korean character classes for a total of 5,139,450 data samples. In the training results, KCR-AlexNetshowed an accuracy of over 98% for the top-1 test and KCR-GoogLeNet showed an accuracy of over 99% forthe top-1 test after the final training iteration. We made an additional Korean character dataset with fonts thatwere not in PHD08 to compare the classification success rate with commercial optical character recognition(OCR) programs and ensure the objectivity of the experiment. While the commercial OCR programs showed66.95% to 83.16% classification success rates, KCR-AlexNet and KCR-GoogLeNet showed averageclassification success rates of 90.12% and 89.14%, respectively, which are higher than the commercial OCRprograms’ rates. Considering the time factor, KCR-AlexNet was faster than KCR-GoogLeNet when they weretrained using PHD08; otherwise, KCR-GoogLeNet had a faster classification speed."
Convolutional Neural Network 기반 무형대용어 해결 기법,2018,"['무형대용어', 'CNN', '인공지능', '딥런닝', '언어모델']",국문 초록 정보 없음,다국어 초록 정보 없음
국방분야 비인가 이미지 파일 탐지를 위한 다중 레벨 컨볼루션 신경망 알고리즘의 구현 및 검증,2018,"['Multi-level CNN', 'Convolutional Neural Network', 'Image Processing', 'Intelligent Information System', 'Military Application']",국문 초록 정보 없음,다국어 초록 정보 없음
용량성 심전도 신호에서 QRS 파의 오 검출을 감소시키기 위한 Convolutional Neural Network 기반의 알고리즘,2018,"['Capacitive ECG', 'CNN', 'QRS detection', 'R peak detection', 'deep learning']",국문 초록 정보 없음,다국어 초록 정보 없음
도로 영역의 사전지식을 활용한 도로 인식 신경망,2018,"['Semantic Segmentation', 'CNN', 'Object Detection']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on the Facial Expression Recognition using Deep Learning Technique,2018,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Intelligent Phone']",국문 초록 정보 없음,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the symbols that users often use, you can identify facial expressions with a camera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar expressions, reached 66%. It doesn't need to search for symbols.If you use the camera to recognize the expression, it will appear symbols immediately. So, this service is the symbols used when people send messages to others, and it can feel a lot of convenience. In countless symbols, there is no need to find symbols, which is an increasing trend in deep learning. So, we need to use more suitable algorithm for expression recognition, and then improve accuracy."
고해상도 영상을 위한 합성곱 신경망의 필터 크기에 대한 화질 비교,2018,[],국문 초록 정보 없음,"Convolution neural network (CNN) can learn the characteristics of images by training the network using different kinds of convolutional filters. In this paper, we present the experimental comparison of image qualities with respect to the sizes of filters in super-resolution convolution neural network(SRCNN)."
지상기반 라디오미터 원시자료를 이용한 연직 온 · 습도 프로파일 산출 알고리즘 개발,2018,"['라디오미터', 'Random Forests', 'CNN', '온습도 프로파일 산출알고리즘']",국문 초록 정보 없음,다국어 초록 정보 없음
A Study on the Facial Expression Recognition using Deep Learning Technique,2018,"['Deep Learning', 'Tensor Flow', 'CNN', 'Facial Expression Recognition', 'Android Intelligent Phone']",국문 초록 정보 없음,"In this paper, the pattern of extracting the same expression is proposed by using the Android intelligent device to identify the facial expression. The understanding and expression of expression are very important to human computer interaction, and the technology to identify human expressions is very popular. Instead of searching for the symbols that users often use, you can identify facial expressions with a camera, which is a useful technique that can be used now. This thesis puts forward the technology of the third data is available on the website of the set, use the content to improve the infrastructure of the facial expression recognition accuracy, to improve the synthesis of neural network algorithm, making the facial expression recognition model, the user's facial expressions and similar expressions, reached 66%. It doesn't need to search for symbols. If you use the camera to recognize the expression, it will appear symbols immediately. So, this service is the symbols used when people send messages to others, and it can feel a lot of convenience. In countless symbols, there is no need to find symbols, which is an increasing trend in deep learning. So, we need to use more suitable algorithm for expression recognition, and then improve accuracy."
관절 위치 변화 정보를 이용한 행동인식,2018,"['Action recognition', 'Feature transform', 'CNN']",국문 초록 정보 없음,다국어 초록 정보 없음
RNN을 이용한 범용 예측 시스템 구현,2018,"['deep learning', 'RNN', 'LSTM', 'CNN', 'artificial intelligence', 'prediction system']",국문 초록 정보 없음,"Various algorithms and models of deep learning were developed, and RNN shows good performance in future prediction system. RNN and LSTM applied universal prediction system was realized in this paper, and performance was evaluated by cost value. Difference between input data was so big that we normalized this input data, and sequence size of learning input was 5 in the performance experiment. The legibility of the results was increased by displaying learning result, predictive execution result and cost values on a real-time graph. In this experiment, accomplishment of learning was confirmed by cost values decrease from learning number 150 to 0.085. future prediction system precisely learned learnin target value and test target value in a small number of learning time in a short time. Furthermore, cost value decreased to wanted value, confirming that the performance of suggested prediction system is excellent."
라이다와 영상정보를 이용한 장애물 탐지 및 회피 기능을 갖춘 소형 무인 헬리콥터,2018,"['Convolutional Neural Network (CNN)', 'multi-segment Lidar module', 'Jetson tx2', 'Mission Control System', 'data fusion', 'obstacle avoidance', 'intruder detection and tracking']",국문 초록 정보 없음,다국어 초록 정보 없음
감시 카메라를 사용한 화재 감지 알고리즘에 관한 연구,2018,"['fire detection', 'deep learning', 'CNN(Convolutional Neural Network)', 'CaffeNet', 'cascade Model']",국문 초록 정보 없음,다국어 초록 정보 없음
Research on Image Semantic Segmentation Based on FCN-VGG and Pyramid Pooling Module,2018,"['image semantic segmentation', 'FCN', 'VGG', 'CNN', 'deconvolution', 'pyramid pooling module']",국문 초록 정보 없음,"This paper proposed an algorithm to extract new feature maps using pyramid pooling module based on FCN-VGG(Fully Convolutional Network-Visual Geometry Group) for image semantic segmentation. First, the VGG was changed to FCN-VGG in order to consider the variability of the input images. The FCN-8 feature is extracted using the changed FCN-VGG. Then the extracted 4-parts features using pyramid pooling module and the previously extracted FCN-8 features are fused to obtain the advanced features. Classification is performed using obtained advanced features. By the comparison experiment between the feature maps of the proposed algorithm and the existing feature maps, it is proved that the method improves the accuracy of image semantic segmentation by about 2%."
Comparisons of Deep Learning Algorithms for MNIST in Real-Time Environment,2018,"['Capsule networks', 'Dynamic routing', 'Residual learning', 'CNN', 'Logistic regression']",국문 초록 정보 없음,"Recognizing handwritten digits was challenging task in a couple of years ago. Thanks to machine learning algorithms, today, the issue has solved but those algorithms require much time to train and to recognize digits. Thus, using one of those algorithms to an application that works in real-time, is complex. Notwithstanding use of a trained model, if the model uses deep neural networks it requires much more time to make a prediction and becomes more complicated as well as memory usage also increases. It leads real-time application to delay and to work slowly even using trained model. A memory usage is also essential as using smaller memory of trained models works considerable faster comparing to models with huge pre-processed memory. For this work, we implemented four models on the basis of unlike algorithms which are capsule network, deep residual learning model, convolutional neural network and multinomial logistic regression to recognize handwritten digits. These models have unlike structure and they have showed a great results on MNIST before so we aim to compare them in real-time environment. The dataset MNIST seems most suitable for this work since it is popular in the field and basically used in many state-of-the-art algorithms beyond those models mentioned above. We purpose revealing most suitable algorithm to recognize handwritten digits in real-time environment. Also, we give comparisons of train and evaluation time, memory usage and other essential indexes of all four models."
A Multi-Scale Parallel Convolutional Neural Network Based Intelligent Human Identification Using Face Information,2018,"['Face Recognition', 'Intelligent Human Identification', 'MP-CNN', 'Robust Feature']",국문 초록 정보 없음,"Intelligent human identification using face information has been the research hotspot ranging from Internet of Things (IoT) application, intelligent self-service bank, intelligent surveillance to public safety and intelligent access control. Since 2D face images are usually captured from a long distance in an unconstrained environment, to fully exploit this advantage and make human recognition appropriate for wider intelligent applications with higher security and convenience, the key difficulties here include gray scale change caused by illumination variance, occlusion caused by glasses, hair or scarf, self-occlusion and deformation caused by pose or expression variation. To conquer these, many solutions have been proposed. However, most of them only improve recognition performance under one influence factor, which still cannot meet the real face recognition scenario. In this paper we propose a multi-scale parallel convolutional neural network architecture to extract deep robust facial features with high discriminative ability. Abundant experiments are conducted on CMU-PIE, extended FERET and AR database. And the experiment results show that the proposed algorithm exhibits excellent discriminative ability compared with other existing algorithms."
Comparisons of Deep Learning Algorithms for MNIST in Real-Time Environment,2018,"['Capsule networks', 'Dynamic routing', 'Residual learning', 'CNN', 'Logistic regression']",국문 초록 정보 없음,"Recognizing handwritten digits was challenging task in a couple of years ago. Thanks to machine learning algorithms, today, the issue has solved but those algorithms require much time to train and to recognize digits. Thus, using one of those algorithms to an application that works in real-time, is complex. Notwithstanding use of a trained model, if the model uses deep neural networks it requires much more time to make a prediction and becomes more complicated as well as memory usage also increases. It leads real-time application to delay and to work slowly even using trained model. A memory usage is also essential as using smaller memory of trained models works considerable faster comparing to models with huge pre-processed memory. For this work, we implemented four models on the basis of unlike algorithms which are capsule network, deep residual learning model, convolutional neural network and multinomial logistic regression to recognize handwritten digits. These models have unlike structure and they have showed a great results on MNIST before so we aim to compare them in real-time environment. The dataset MNIST seems most suitable for this work since it is popular in the field and basically used in many state-of-the-art algorithms beyond those models mentioned above. We purpose revealing most suitable algorithm to recognize handwritten digits in real-time environment. Also, we give comparisons of train and evaluation time, memory usage and other essential indexes of all four models."
ROI-based Fully Automated Liver Registration in Multi-phase CT Images,2018,"['Computer Aided Diagnosis', 'Liver', 'Cancer', 'Registration', 'Segmentation', 'CNN', 'ROI', 'Multi-phase CT']",국문 초록 정보 없음,"In this paper, we propose a registration method for fully automated liver tumor detection. Multiple phases CT is used for the detection of the liver tumor because multiple phase CT can give different characteristic features of lesions for each time phases. Registration accuracy is important when obtaining image features from multiple time phases. However, since each time phases have different image density characteristics, therefore registration of multi-phase CT is a challenging task. In this paper, we propose a robust initial alignment method independent of changing image density features in each time phase, and deformable registration method with region of interests (ROI) as liver region extracted by U-Net. Our proposed method is evaluated on 15 patient image sets. This method is applied to the early arterial phase and the equilibrium phase to registries. Experimental results show that segmentation of early arterial phase is 83% and registration is 93% accuracy."
Sparse Feature Convolutional Neural Network with Cluster Max Extraction for Fast Object Classification,2018,"['Deep learning', 'Online-training control', 'Object recognition', 'Classification']",국문 초록 정보 없음,"We propose the Sparse Feature Convolutional Neural Network (SFCNN) to reduce the volume of convolutional neural networks (CNNs). Despite the superior classification performance of CNNs, their enormous network volume requires high computational cost and long processing time, making real-time applications such as online-training difficult. We propose an advanced network that reduces the volume of conventional CNNs by producing a region-based sparse feature map. To produce the sparse feature map, two complementary region-based value extraction methods, cluster max extraction and local value extraction, are proposed. Cluster max is selected as the main function based on experimental results. To evaluate SFCNN, we conduct an experiment with two conventional CNNs. The network trains 59 times faster and tests 81 times faster than the VGG network, with a 1.2% loss of accuracy in multi-class classification using the Caltech101 dataset. In vehicle classification using the GTI Vehicle Image Database, the network trains 88 times faster and tests 94 times faster than the conventional CNNs, with a 0.1% loss of accuracy."
Gastrointestinal polyp detection in endoscopic images using an improved feature extraction method,2018,"['Endoscopic image', 'Video endoscopy', 'Convolutional neural network (CNN)', 'Color wavelet features', 'Support vector machine (SVM)', 'Improved method']",국문 초록 정보 없음,"Gastrointestinal polyps are treated as the precursorsof cancer development. So, possibility of cancerscan be reduced at a great extent by early detection andremoval of polyps. The most used diagnostic modality forgastrointestinal polyps is video endoscopy. But, as anoperator dependant procedure, several human factors canlead to miss detection of polyps. In this peper, an improvedcomputer aided polyp detection method has been proposed.Proposed improved method can reduce polyp miss detectionrate and assists doctors in finding the most importantregions to pay attention. Color wavelet features and convolutionalneural network features are extracted fromendoscopic images, which are used for training a supportvector machine. Then a target endoscopic image will begiven to the classifier as input in order to find whether itcontains any polyp or not. If polyp is found, it will bemarked automatically. Experiment shows that, colorwavelet features and convolutional neural network featurestogether construct a highly representative of endoscopicpolyp images. Evaluations on standard public databasesshow that, proposed system outperforms state-of-the-artmethods, gaining accuracy of 98.34%, sensitivity of98.67% and specificity of 98.23%. In this paper, thestrength of color wavelet features and power of convolutionalneural network features are combined. Fusion ofthese two methodology and use of support vector machineresults in an improved method for gastrointestinal polypdetection. An analysis of ROC reveals that, proposedmethod can be used for polyp detection purposes withgreater accuracy than state-of-the-art methods."
Obstructive sleep apnoea detection using convolutional neural network based deep learning framework,2018,"['Artificial neural network (ANN)', 'Convolutional neural network (CNN)', 'Electrocardiography', 'Obstructive sleep apnoea (OSA)', 'Polysomnography (PSG)']",국문 초록 정보 없음,"This letter presents an automated obstructive sleep apnoea (OSA) detection method with high accuracy, based on a deeplearning framework employing convolutional neural network. The proposed work develops a system that takes single leadelectrocardiography signals from patients for analysis and detects the OSA condition of the patient. The results show thatthe proposed method has some advantages in solving such problems and it outperforms the existing methods significantly.The present scheme eliminates the requirement of separate feature extraction and classification algorithms for the detectionof OSA. The proposed network performs both feature learning and classifies the features in a supervised manner. Thescheme is computation-intensive, but can achieve very high degree of accuracy—on an average a margin of more than 9%compared to other published literature till date. The method also has a good immunity to the contamination of the signalsby noise. Even with pessimistic signal to noise ratio values considered here, the methods already reported are not able tooutshine the present method. The software for the algorithm reported here can be a good contender to constitute a modulethat can be integrated with a portable medical diagnostic system."
딥러닝을 적용한 이동로봇의 자율주행 프로그램 개발,2018,"['Autonomous Driving', 'Lane Tracing', 'Deep Learning', 'CNN Algorithm']",국문 초록 정보 없음,다국어 초록 정보 없음
단안카메라를 이용한 주행 가능 공간 검출 알고리즘,2018,"['Obstacle Detection(장애물 검출)', 'Deep Learning(심층학습)', 'CNN(회귀 신경망)', 'Lane Detection(차선 검출)', 'Collision Warning (충돌경고)']",국문 초록 정보 없음,다국어 초록 정보 없음
2018 스키 로봇 챌린지를 위한 인간형 로봇 개발,2018,"['Ski Robot Challenge', 'Humanoid', 'R-CNN', 'ZMP', 'Outdoor Robot']",국문 초록 정보 없음,다국어 초록 정보 없음
영상수준과 픽셀수준 분류를 결합한 영상 의미분할,2018,"['Semantic Segmentation', 'Convolutional Neural Network']",국문 초록 정보 없음,"In this paper, we propose a CNN based deep learning algorithm for semantic segmentation of images. In order to improve the accuracy of semantic segmentation, we combined pixel level object classification and image level object classification. The image level object classification is used to accurately detect the characteristics of an image, and the pixel level object classification is used to indicate which object area is included in each pixel. The proposed network structure consists of three parts in total. A part for extracting the features of the image, a part for outputting the final result in the resolution size of the original image, and a part for performing the image level object classification. Loss functions exist for image level and pixel level classification, respectively. Image-level object classification uses KL-Divergence and pixel level object classification uses cross-entropy. In addition, it combines the layer of the resolution of the network extracting the features and the network of the resolution to secure the position information of the lost feature and the information of the boundary of the object due to the pooling operation."
6축 다관절 아크용접 로봇의 고장진단 알고리즘 개발에 관한 연구,2018,"['Welding robot', 'Signal processing', 'Deep learning', 'CNN (Convolutional Neural Network)']",국문 초록 정보 없음,다국어 초록 정보 없음
A Multi-Scale Parallel Convolutional Neural Network Based Intelligent Human Identification Using Face Information,2018,"['Face Recognition', 'Intelligent Human Identification', 'MP-CNN', 'Robust Feature']",국문 초록 정보 없음,"Intelligent human identification using face information has been the research hotspot ranging from Internetof Things (IoT) application, intelligent self-service bank, intelligent surveillance to public safety and intelligentaccess control. Since 2D face images are usually captured from a long distance in an unconstrained environment,to fully exploit this advantage and make human recognition appropriate for wider intelligent applicationswith higher security and convenience, the key difficulties here include gray scale change caused byillumination variance, occlusion caused by glasses, hair or scarf, self-occlusion and deformation caused bypose or expression variation. To conquer these, many solutions have been proposed. However, most of themonly improve recognition performance under one influence factor, which still cannot meet the real facerecognition scenario. In this paper we propose a multi-scale parallel convolutional neural network architectureto extract deep robust facial features with high discriminative ability. Abundant experiments are conductedon CMU-PIE, extended FERET and AR database. And the experiment results show that the proposedalgorithm exhibits excellent discriminative ability compared with other existing algorithms."
물체 변형 성능을 향상하기 위한 U-net 및 Residual 기반의Cycle-GAN,2018,"['Deep learning', 'AI', 'Image-to-image translation', 'CNN', 'GAN']",국문 초록 정보 없음,"The image-to-image translation is one of the deep learning applications using image data. In this paper, we aim at improving the performance of object transfiguration which transforms a specific object in an image into another specific object. For object transfiguration, it is required to transform only the target object and maintain background images. In the existing results, however, it is observed that other parts in the image are also transformed. In this paper, we have focused on the structure of artificial neural networks that are frequently used in the existing methods and have improved the performance by adding constraints to the exiting structure. We also propose the advanced structure that combines the existing structures to maintain their advantages and complement their drawbacks. The effectiveness of the proposed methods are shown in experimental results."
Real-Time Action Detection in Video Surveillance using a Sub-Action Descriptor with Multi-Convolutional Neural Networks,2018,"['sub-action descriptor', 'action detection', 'video surveillance', 'convolutional neural network', 'multi CNN']",국문 초록 정보 없음,"When we say a person is texting, can you tell the person is walking or sitting? Emphatically, no. In order to solve this incomplete representation problem, this paper presents a sub-action descriptor for detailed action detection. The sub-action descriptor consists of three levels: posture, locomotion, and gestures. The three levels provide three sub-action categories for a single action in order to address the representation problem. The proposed action detection model simultaneously localizes and recognizes the actions of multiple individuals in video surveillance using appearance-based temporal features with multi-convolutional neural networks. The proposed approach achieved a mean average precision of 76.6% for frame-based measurement and 83.5% for video-based measurement of the ICVL video surveillance dataset. Extensive experiments on the benchmark KTH dataset demonstrate that the proposed approach achieved better performance, which in turn improves action recognition performance in comparison to the stateof-the-art methods. The action detection model can run at around 25 fps with the ICVL dataset and at more than 80 fps with the KTH dataset, which is suitable for real-time surveillance applications."
fault diagnosis modeling of industrial robot gear based on convolutional neural network,2018,"['Fault diagnosis', 'Industrial robot gear', 'Convolutional neural network (CNN)', 'Short time fourier transform (STFT)']",국문 초록 정보 없음,다국어 초록 정보 없음
딥러닝을 통한 움직이는 객체 검출 알고리즘 구현,2018,"['Object Detection and Tracking', 'Object Recognition', 'Moving Object', 'Deep Learning', 'CNN(Convolution Neural Network)']",국문 초록 정보 없음,"Object detection and tracking is an exciting and interesting research area in the field of computer vision, and its technologies have been widely used in various application systems such as surveillance, military, and augmented reality. This paper proposes and implements a novel and more robust object recognition and tracking system to localize and track multiple objects from input images, which estimates target state using the likelihoods obtained from multiple CNNs. As the experimental result, the proposed algorithm is effective to handle multi-modal target appearances and other exceptions."
STFT 소리맵을 이용한 컨볼루션 신경망 기반 화자식별 방법,2018,"['딥러닝', '컨볼루션신경망', 'STFT알고리즘', '화자식별', '잡음 강건성', 'Deep Learning', 'Convolutional Neural Network (CNN)', 'Short-time Fourier Transform (STFT) Algorithm', 'Speaker Identification', 'Noise Robustness']","화자식별은 개인 성도의 음성학적 특징을 모델링하고 분류하는 기술로 음성 인식 분야의 가장 어려운 분야에 속한다. 화자식별 기술은 보안인증, 접근제어, 개인화, 지능형 로봇제어 등의 분야에서 광범위하게 응용이 가능하지만, 실제 환경 요소로 인한 잡음 때문에 발생하는 학습과 테스트 데이터 간의 불일치를 해결하는 것이 필요하다. 본 논문에서는 잡음 강건성을 위해 컨볼루션-풀링 연산을 반복적으로 적용하는 화자식별 시스템을 제안하였다. 정적 신호가 아닌 시계열 특성을 지니는 스피치 데이터의 특징을 보다 잘 모델링 하기 위해서 STFT알고리즘을 사용하여 소리맵을 생성하여 분류하였다. 제안하는 화자식별 시스템은 다른 기계학습 알고리즘의 인식 성능을 크게 상회하였고, 단계별로 잡음을 삽입하는 실험의 결과로 잡음 강건성을 검증하였다.","Speaker identification which models and classifies the phonological characteristics of individuals, is one of the most difficult areas of speech recognition. While speaker identification can be widely applied in fields such as security authentication, access control, personalization and intelligent robot control, a solution needs to be found for the inconsistency between training and test data caused by noise due to real environment factors. In this paper, we propose a speaker identification system based on convolution-pooling operation for noise robustness. To model the characteristics of individuals"" speech using the time series characteristics, a sound map was generated using the Short-time Fourier Transform (STFT) algorithm. The proposed speaker identification system outperforms recognition performance of other machine learning algorithms, and the robustness of noise is verified as a result of the noise insertion at incremental steps."
OpenCL을 이용한 랜더링 노이즈 제거를 위한 뉴럴네트워크 가속기 구현,2018,"['레이 트레이싱', 'LBF', '컨볼루션 뉴럴 네트워크', 'OpenCL', 'GEMM', 'Ray tracing', 'LBF', 'CNN', 'OpenCL', 'GEMM']",본 논문에서는 OpenCL을 이용한 랜더링 노이즈 제거를 위한 가속기 구현을 제안한다. 렌더링 알고리즘 중에 고품질 그래픽스를 보장하는 레이트레이싱을 선택하였다. 레이 트레이싱은 레이를 사용하여 렌더링하는데 레이를 적게 사용하면 노이즈가 발생한다. 레이를 많이 사용하게 되면 고화질의 이미지를 생성할 수 있으나 연산 시간이 상대적으로 길어지게 된다. 레이를 적게 사용하면서 연산시간을 줄이기 위해 뉴럴 네트워크를 이용한 LBF(Learning Based Filtering) 알고리즘을 적용하였다. 뉴럴 네트워크를 사용한다고 해서 항상 최적의 결과가 나오지는 않는다. 본 논문에서는 성능향상을 위해 일반적인 행렬 곱셈을 기반으로 하는 새로운 기법의 행렬 곱셈 접근법을 제시하였다. 개발환경으로는 고속병렬 처리가 특화된 OpneCL을 사용하였다. 제안하는 구조는 Kintex UltraScale XKU690T- 2FDFG1157C FPGA 보드에서 검증하였다. 하나의 픽셀에 사용되는 파라미터를 계산 시간은 Verilog-HDL 구조보다 약 1.12배 빠른 것으로 확인했다.,"In this paper, we propose an implementation of a neural network accelerator for reducing the rendering noise using OpenCL. Among the rendering algorithms, we selects a ray tracing to assure a high quality graphics. Ray tracing rendering uses ray to render, less use of the ray will result in noise. Ray used more will produce a higher quality image but will take operation time longer. To reduce operation time whiles using fewer rays, Learning Base Filtering algorithm using neural network was applied. it's not always produce optimize result. In this paper, a new approach to Matrix Multiplication that is based on General Matrix Multiplication for improved performance. The development environment, we used specialized in high speed parallel processing of OpenCL. The proposed architecture was verified using Kintex UltraScale XKU6909T-2FDFG1157C FPGA board. The time it takes to calculate the parameters is about 1.12 times fast than that of Verilog-HDL structure."
Comparative Study for Prediction of Neural Network models,2018,"['ARIMA', 'Neural Network', 'Stochastic Process', 'Deterministic process', 'Time series']",국문 초록 정보 없음,"In this study, ARIMA model and neural network models including MLP, CNN and RNN are compared according to their prediction power. Given assumption is that a neural network model would more suitable to the data that has regular patterns. To prove the assumption, the study set two simulations for stochastic process and deterministic process, which can represent randomness and visible pattern respectively. Finally, solution to develop the neural network model for time series is suggested regarding the result of simulations."
이진 가중치 신경망의 하드웨어 구현을 위한 고정소수점 연산 정확도 분석,2018,"['Binary Weight Network', 'Low precision network', 'Fixed point approximation', 'FPGA', 'CNN']",국문 초록 정보 없음,"In this paper, we analyze the change of accuracy when fixed point arithmetic is used instead of floating point arithmetic in binary weight network(BWN). We observed the change of accuracy by varying total bit size and fraction bit size. If the integer part is not changed after fixed point approximation, there is no significant decrease in accuracy compared to the floating-point operation. When overflow occurs in the integer part, the approximation to the maximum or minimum of the fixed point representation minimizes the decrease in accuracy. The results of this paper can be applied to the minimization of memory and hardware resource requirement in the implementation of FPGA-based BWN accelerator."
인지 무선 네트워크에서 딥러닝을 이용한 특징 기반의 자동 변조기법 분류 방법,2018,"['Automatic modulation classification', 'convolutional neural network', 'spectral correlation function', 'feature extraction']",국문 초록 정보 없음,다국어 초록 정보 없음
완전 합성곱 신경망을 활용한 자동 포트홀 탐지 기술의 개발 및 평가,2018,"['포트홀', '도로노면 파손', '의미론적 분할', '심층신경망', '인공지능', '완전 합성곱 신경망', 'Pothole', 'Road surface damage', 'Semantic segmentation', 'Deep neural network', 'AI', 'Fully convolutional neural network']",국문 초록 정보 없음,다국어 초록 정보 없음
조명 변화에 강인한 농작물 병해충 영상 분류 알고리즘,2018,[],국문 초록 정보 없음,"This study is a research on classification algorithm of CNN (Convolutional Neural Network) which is robust against illumination change. The crop pest image is mainly photographed in an outdoor environment where artificial light control is difficult. Unlike the original color of crops, images that are shot with uncontrolled amounts of light distort the color values of the image. For example, in the image, the leaf in which powdery mildew that occurs in berries and cucumber is ongoing, and the normal leaf that is photographed very brightly because the light is not controlled appears to be the same. Distorted images may be appropriate in training Feature Map is not formed and there is possibility of Overfitting. A poorly trained model shows low accuracy and high error rate in the experimental results. In order to solve such a problem, an algorithm for classifying the images photographed in various illumination environments by minimizing the influence of light is needed.  Therefore, in this study, we propose a homomorphic filter in the preprocessing process and a classification accuracy algorithm using Gabor filter instead of the weight kernel in the convolutional layer to develop a crop pest image classification algorithm robust against illumination change."
Deep Convolutional Neural Network를 이용한 주차장 차량 계수 시스템,2018,"['주차장 관리', '물체 감지', '컴퓨터 비전', '기계 학습', '감시 카메라', 'deep convolutional neural network', 'Parking lot management', 'Object detection', 'Computer vision', 'Machine learning', 'Deep convolutional neural network', 'Surveillance camera.']",국문 초록 정보 없음,다국어 초록 정보 없음
"흉부 CT 영상에서 결절의 밝기값, 재질 및 형상 증강 영상 기반의 GGN-Net을 이용한 간유리음영 결절 자동 분류",2018,"['흉부 CT 영상', '간유리음영 결절', '결절 분류', '컨볼루션신경망', 'Chest CT image', 'Ground-glass Nodule', 'Nodule Classification', 'CNN']","본 논문에서는 흉부 CT 영상에서 결절의 밝기값, 재질 및 형상 증강 영상 기반의 GGN-Net을 이용해 간유리음영 결절 자동 분류 방법을 제안한다, 첫째, 입력 영상에 결절 내부의 고형 성분의 유무 및 크기 정보가 포함될 수 있도록 밝기값, 재질 및 형상 증강 영상의 활용을 제안한다. 둘째, 다양한 입력 영상을 여러 개의 컨볼루션 모듈을 통해 획득한 특징맵을 내부 네트워크에서 통합하여 훈련하는 GGN-Net를 제안한다. 제안 방법의 분류 정확성 평가를 위해 순수 간유리음영 결절 90개와 고형 성분의 크기가 5mm 미만인 혼합 간유리음영 결절 38개, 5mm 이상 고형 성분의 크기를 가지는 혼합 간유리음영 결절 23개의 데이터를 사용하였으며, 입력 영상이 간유리음영 결절 분류 결과에 미치는 영향을 비교하기 위해 다양한 입력 영상을 구성하여 결과를 비교하였다. 실험 결과, 밝기값, 재질 및 형상 정보가 함께 고려된 입력 영상을 사용한 제안 방법이 정확도가 82.75%로 가장 좋은 결과를 보였다.","In this paper, we propose an automated method for the ground-glass nodule(GGN) classification using GGN-Net based on intensity, texture, and shape-enhanced images in chest CT images. First, we propose the utilization of image that enhances the intensity, texture, and shape information so that the input image includes the presence and size information of the solid component in GGN. Second, we propose GGN-Net which integrates and trains feature maps obtained from various input images through multiple convolution modules on the internal network. To evaluate the classification accuracy of the proposed method, we used 90 pure GGNs, 38 part-solid GGNs less than 5mm with solid component, and 23 part-solid GGNs larger than 5mm with solid component. To evaluate the effect of input image, various input image set is composed and classification results were compared. The results showed that the proposed method using the composition of intensity, texture and shape-enhanced images showed the best result with 82.75% accuracy."
딥러닝을 이용한 양파 밭의 잡초 검출 연구,2018,"['잡초 분류', '잡초 검출', '컨볼루션 뉴럴네트워크', '딥러닝', 'weed classification', 'weed detection', 'convolutional neural network(CNN)', 'deep learning']","이 논문은 양파 밭에서 딥러닝 기반 자동 잡초 검출기의 설계 및 구현을 제시합니다. 이 시스템은 컨볼루션 뉴럴 네트워크를 기반으로 제안 된 영역을 선택합니다. 검출기는 양파 밭에서 직접 찍은 데이터 셋을 가지고 훈련됩니다. 학습이 완료 된 후에, 잡초가 될 확률이 매우 높은 후보 지역을 잡초로 간주합니다. Non-maximum suppression을 통해 오버랩된 박스가 최대한 적게 남게 됩니다. 다른 양파 농장을 통해 수집된 데이터를 통해 제안 된 분류기를 평가합니다. 분류 정확도는 고려 된 데이터 셋에서 약 99%를 보여주며, 제안된 방법이 양파 밭에서 잡초 검출과 관련하여 우수한 성능을 나타냄을 알 수 있습니다.","This paper presents the design and implementation of a deep learning-based automated weed detector on onion fields. The system is based on a Convolutional Neural Network that specifically selects proposed regions. The detector initiates training with a dataset taken from agricultural onion fields, after which candidate regions with very high probability of suspicion are considered weeds. Non-maximum suppression helps preserving the less overlapped bounding boxes. The dataset collected from different onion farms is evaluated with the proposed classifier. Classification accuracy is about 99% for the dataset, indicating the proposed method’s superior performance with regard to weed detection on the onion fields."
"고객만족, NPS, Bayesian Inference 및 Hidden Markov Model로 구현하는 명품구매에 관한확률적 추적 메카니즘",2018,"['고객만족', '고객추천', '추천의향', 'NPS', '추천행동', '시장 지분', 'Hidden Markov Model', 'Bayesian Inference', 'Maximum Likelihood Estimation', '인공지능망(DNN', 'CNN', 'GAN)', 'Customer Satisfaction', 'Customer Referral', 'Net Promoter Score', 'Bayesian Inference', 'Hidden Markov Model', 'Viterbi Algorithm']",국문 초록 정보 없음,"The purpose of this study is to specify a probabilistic tracking mechanism for customer luxury purchase implemented by hidden Markov model, Bayesian inference, customer satisfaction and net promoter score. In this paper, we have designed a probabilistic model based on customer's actual data containing purchase or non-purchase states by tracking the SPC chain : customer satisfaction -> customer referral -> purchase/non-purchase. By applying hidden Markov model and Viterbi algorithm to marketing theory, we have developed the statistical model related to probability theories and have found the best purchase pattern scenario from customer's purchase records."
슈퍼픽셀 이미지 분할을 이용한 ResNet 기반 백혈구 감별 알고리즘 개발,2018,"['Super-pixel', 'Residual Network', 'Segmentation', 'Classification', 'White Blood Cell']",국문 초록 정보 없음,"In this paper, we propose an efficient WBC 14-Diff classification which performs using the WBC-ResNet-152, a type of CNN model. The main point of view is to use Super-pixel for the segmentation of the image of WBC, and to use ResNet for the classification of WBC.  A total of 136,164 blood image samples (224x224) were grouped for image segmentation, training, training verification, and final test performance analysis.  Image segmentation using super-pixels have different number of images for each classes, so weighted average was applied and therefore image segmentation error was low at 7.23%.  Using the training data-set for training 50 times, and using soft-max classifier, TPR average of 80.3% for the training set of 8,827 images was achieved. Based on this, using verification data-set of 21,437 images, 14-Diff classification TPR average of normal WBCs were at 93.4% and TPR average of abnormal WBCs were at 83.3%. The result and methodology of this research demonstrates the usefulness of artificial intelligence technology in the blood cell image classification field.  WBC-ResNet-152 based morphology approach is shown to be meaningful and worthwhile method. And based on stored medical data, in-depth diagnosis and early detection of curable diseases is expected to improve the quality of treatment."
딥러닝 기반의 이미지 분류 기술 동향,2018,[],"본고에서는 딥러닝 기반의 이미지 분류 기술 분야에서 기존 방법 들보다 뛰어난 성능을 보이는 합성곱 신경망 (CNN, Convolutional Neural Network)의 최근 기술 동향을 소개한다.",다국어 초록 정보 없음
IoT 기반 스마트 냉장고 시스템,2018,"['Internet of Things', 'Deep learning', 'Refrigerator', 'Smart system', 'Smart home', 'Artificial Intelligence', 'Convolution Neural Network (CNN)']","최근 인구가 급격히 증가하면서 음식물의 부족 및 낭비의 심각성이 대두되고 있다. 이를 해결하기 위해 다양한 국가 및 기업에서는 소비자의 식재료 구매 패턴 연구 및 IoT 기술이 적용된 스마트 냉장고 제품개발 등의 시도를 진행 중에 있다. 그러나, 현재 판매되고 있는 스마트 냉장고들은 기존에 비해 상당한 가격대를 형성하고 있으며, 복잡한 구성으로 인한 오작동 및 파손으로 또 다른 낭비를 초래한다. 본 논문에서는 음식물 부족 및 낭비 해결과 가정 내 원활한 식재료 관리를 위한 저비용의 IoT 기반 스마트 냉장고 시스템을 제안한다. 본 시스템은 QR코드, 이미지 인식, 음성 인식을 통해 식재료를 인식하여 등록하고 이를 바탕으로 다양한 서비스를 제공할 수 있다. 이미지 인식의 정확도를 높이기 위해 우리는 딥 러닝 알고리즘을 사용한 모델을 활용하였으며 정확한 식재료 등록이 가능함을 검증하였다.","Recently, as the population rapidly increases, food shortages and waste are emerging serious problem. In order to solve this problem, various countries and enterprises are trying research and product development such as a study of consumers' purchasing patterns of food and a development of smart refrigerator using IoT technology. However, the smart refrigerators which currently sold have high price issue and another waste due to malfunction and breakage by complicated configurations. In this paper, we proposed a low-cost smart refrigerator system based on IoT for solving the problem and efficient management of ingredients. The system recognizes and registers ingredients through QR code, image recognition, and speech recognition, and can provide various services of the smart refrigerator. In order to improve an accuracy of image recognition, we used a model using a deep learning algorithm and proved that it is possible to register ingredients accurately."
확장 네트워크 기반의 객체 검출 및 영상 분할,2018,"['Deep Learning(딥러닝)', 'Object Detection(객체 검출)', 'Semantic Segmentation(영상 분할)', 'Autonomous Vehicle(자율주행 자동차)', 'Convolutional Neural Network (CNN)']","자율주행자동차, 로봇, CCTV등 다양한 분야에서 주변 환경을 인지하는 기술이 요구되고 있으며, 최근에는 딥러닝 기술의 발전으로 인해 인지 성능이 급격하게 향상되고 있다. 주변 환경을 정확하게 인지하기 위해서는 객체 검출 기술 및 영상 분할 기술과 같은 영상 인지 기술이 필요하다. 객체 검출 기법은 R-FCN<SUP>1)</SUP>, SSD<SUP>2)</SUP>, YOLO<SUP>3)</SUP> 등이 있으며 영상 분할 기법은 FCN<SUP>4)</SUP>, SegNet<SUP>5)</SUP> 등의 방법들이 최근 개발되어서 좋은 성능을 보여주고 있다. 최근에 작은 객체에 대한 검출 정확도 및 정밀도를 향상시키기 위하여 마지막 특징맵을 확장시키는 객체 검출 방법들이 제안되었으며, 대표적인 방법으로 FPN 방법이 있다. 본 논문에서는 하나의 네트워크에서 객체 검출과 영상 분할을 수행할 수 있는 방법을 제안한다. 먼저 실시간성을 보장하는 YOLO v2 기반의 ExtendNet 검출방법을 사용하고, 동시에 upsampling을 통하여 영상 분할까지 제공한다.",다국어 초록 정보 없음
MSCNN와 cGAN을 이용한 실내안개제거,2018,[],국문 초록 정보 없음,"We propose an indoor haze removal method using MSCNN and cGAN. The structure of the network consists of multi-scale CNN and cGAN for photo realistic result. Our method outputs the haze removal image immediately, unlike the existing methods of estimating the depth map. Our method has a quantitative evaluation of 22.6879 in PSNR and 0.8872 in SSIM, which is higher than state of the art by 1.342 in PSNR and 0.0116 in SSIM. It also has good results in qualitative evaluation."
다양한 합성곱 신경망 접근법을 이용한 잡초 이미지 분류,2018,[],국문 초록 정보 없음,"In this paper, we present a multimodal approach for weeds classification. We apply the transfer learning to classify on Convolutional Neural Networks(CNN) VGG16, Inception-Resnet, and Mobilenet separately. Then, we combine probabilities returned from each model, and start voting by scoring classes. We choose a class that has the highest score to conclude the final classification. We experiment on own weeds dataset and achieve 95.927% accuracy after voting on fusion classification."
딥러닝을 활용한 향상된 라벨인식 방법에 관한 연구,2018,[],"라벨인식과 같은 광학 문자 인식은 영상처리를 활용한 컴퓨터 비전의 대표적인 연구분야이다. 본 연구에서는 딥러닝 기반의 라벨인식 시스템을 고안하였다, 생산 라인에 적용되는 라벨인식 시스템은 인식 속도가 중요하기 때문에 기존의 R-CNN기반의 딥러닝 신경망보다 월등히 빠른 오브젝트 검출 시스템 YOLO를 활용하여 문자를 학습 및 인식 시스템을 개발하였다. 본 시스템은 기존 시스템에 근접하는 문자인식 정확도를 제공하고 자동으로 문자영역을 검출 가능하며, 라벨의 인쇄불량을 판독하도록 하였다. 또한 개발, 배포, 적용이 한번에 가능한 프레임워크를 통하여 생산현장에서 발생하는 다양한 이미지 처리에 활용될 전망이다.",다국어 초록 정보 없음
ZeNA: Zero-Aware Neural Network Accelerator,2018,[],국문 초록 정보 없음,"<P><I>Editor’s note:</I> It has been observed that the majority of the kernel weights and input activations in the state-of-the-art convolution neural networks (CNNs) have zero values. This article proposes a CNN hardware accelerator that exploits this property to achieve significant performance and energy improvements. <I>—Mustafa Ozdal, Bilkent University</I></P>"
Recognition of Virtual Written Characters Based on Convolutional Neural Network,2018,"['Virtual Writing', 'Hand Written Character', 'Character Recognition', 'Convolutional Neural Network', 'Motion Recognition']",국문 초록 정보 없음,"This paper proposes a technique for recognizing online handwritten cursive data obtained by tracing a motion trajectory while a user is in the 3D space based on a convolution neural network (CNN) algorithm. There is a difficulty in recognizing the virtual character input by the user in the 3D space because it includes both the character stroke and the movement stroke. In this paper, we divide syllable into consonant and vowel units by using labeling technique in addition to the result of localizing letter stroke and movement stroke in the previous study. The coordinate information of the separated consonants and vowels are converted into image data, and Korean handwriting recognition was performed using a convolutional neural network. After learning the neural network using 1,680 syllables written by five hand writers, the accuracy is calculated by using the new hand writers who did not participate in the writing of training data. The accuracy of phoneme-based recognition is 98.9% based on convolutional neural network. The proposed method has the advantage of drastically reducing learning data compared to syllable-based learning."
Convolutional Neural Network Architecture 에 따른 Cone beam artifact 제거 성능 비교,2018,[],국문 초록 정보 없음,"CBCT(Cone beam CT) is widely used in diagnosis and treatment planning of implant dentistry, orthopedics, and interventional radiology. However, the reconstructed images by CBCT geometry generate cone beam artifacts, which would disturb lesion detectability and degrade diagnostic accuracy. In this work, we present convolutional neural network(CNN) based cone beam artifacts correction method, which is computationally efficient and achieve better performance in artifact correction. We compared the performance of the cone beam artifacts reduction via U-Net and ResNet models, which are trained with simulated CBCT images. Our result showed that U-Net performs better than ResNet in cone beam artifact reduction."
핸드 제스처를 이용한 프레젠테이션 제어 시스템,2018,[],"본 연구는 일반적인 프레젠테이션 제어 환경에서 능동적인 세미나 참여도를 위하여 청중이 핸드 제스처를 이용해 프레젠테이션을 제어하는 방법을 제안한다. 이를 위해 제스처와 제어 동작을 분석하여 프레젠터이션에 적절한 제스처를 선정하였고, 이를 바탕으로 데이터셋을 수집하여 3D-CNN으로 핸드 제스처를 분류 하였다. 시나리오를 적용한 실제 세미나 상황에서의 사용자 실험을 통해 제스처의 동작의 인식률을 평가하였다. 그 결과 위치에 따라 다소 인식률에 차이를 보였으나 대부분의 상황에서 청중이 프레젠테이션을 조작하는데 어려움이 없었다. 이를 통해 여러 사람을 대상으로 하는 제스처 인터페이스의 성능 및 가능성이 있다는 것을 증명할 수 있었다.",다국어 초록 정보 없음
Generative Adversarial Network를 이용한 손실된 깊이 영상 복원,2018,"['Deep learning', 'generative adversarial network', 'depth image', 'depth camera', 'restoration']",국문 초록 정보 없음,This paper proposes a method of restoring corrupted depth image captured by depth camera through unsupervised learning using generative adversarial network (GAN). The proposed method generates restored face depth images using 3D morphable model convolutional neural network (3DMM CNN) with large-scale CelebFaces Attribute (CelebA) and FaceWarehouse dataset for training deep convolutional generative adversarial network (DCGAN). The generator and discriminator equip with Wasserstein distance for loss function by utilizing minimax game. Then the DCGAN restore the loss of captured facial depth images by performing another learning procedure using trained generator and new loss function.
A Two-Track Strategy for Sustainability of Korean MNEs Using Text Mining,2018,"['Korean Multinational Enterprises', 'Text mining', 'News media', 'Social media', 'Sustainability']",국문 초록 정보 없음,"This study aims to utilize big data contents of news and social media for developing a corporate strategy of multinational enterprises and global decision-making through the text mining technique. In this paper, the data of 2 news media(BBC and CNN) and 2 social media(Facebook and Twitter) was collected for the three Korean Multinational Enterprises(Samsung, Hyundai Motor Company, and LG) from April, 2018 to April, 2019. The findings of this paper have shown that traditionally, news media, and especially social media such as Facebook and Twitter, which are global real-time platforms, have become important channels to reflect key issues in showing global trends and phenomena for businesses. Moreover, analyzing the unstructured texts of those media and understanding the association rules between them lead to greatly contribute to understanding consumer behavior and their responses by creating steady communication and empathy with consumers. In conclusion, this study provides a basis and meaningful implication for establishing a two-track strategy through future forecasting of global corporations and generate important insights for global decision- making for sustainability of business."
딥러닝을 이용한 실시간 영상기반 콘크리트 손상 탐지,2018,[],국문 초록 정보 없음,"This paper proposes real-time image-based damage detection method for concrete structures using deep learning. The proposed method is composed of three steps: (1) collection of a large volume of images containing damage information from internet, (2) development of a deep learning model (i.e., convolutional neural network (CNN)) using collected images, and (3) automatic selection of damage images using the trained deep learning model. The whole procedure of the proposed method has been applied to some figures taken in a real structure. This method is expected to facilitate the regular inspection and speed up the assessment of detailed damage distribution the without losing accuracy."
지능형 CCTV를 위한 비정상 이벤트 검출 방법,2018,"['intelligent CCTV', 'abnormal event detection', 'video surveillance']",국문 초록 정보 없음,"In this paper, we propose a noble method of detecting abnormal events for intelligent CCTV service. The method detects the object asynchronously by using object classification and bounding-box estimation, which are based on a light-weight CNN model. To analyze the abnormal events, we categorized four human-related events (loitering, intrusion, abandoned object, and violence) that are classified by time series data analysis. Experimental results showed that the average accuracy of the event detection is 95.8%. We expect that the proposed method can be applied to a real-time commercial intelligent CCTV service."
심층학습을 이용한 문서요약의 연구방법 분석,2018,"['Deep Neural Network', 'Text summarization', 'Deep Learning', 'Abstractive text summarization', 'Extractive text summarization']",국문 초록 정보 없음,"In this study, we discuss the basic technology of Text Summarization based on the deep neural network for natural language processing(NLP). The text summarization task is divided into an extractive summary and an abstractive summary. The extractive summary is a method of extracting a summary of the words used in the input document in the output text, and the abstractive summary is a problem of understanding the input statement and generating a sentence of the same content. The abstractive sentence generation system is based on the encoder-decoder model with attention mechanism, and a selector that can select input sentence is added. The Copy network and Pointer network are the special mechanisms for selector. Such selector systems can make text summarization to be the hybrid form of abstractive and extractive summary. In the future, we expect that accuracy of text summarization will be improved by adding reinforcement learning method."
파프리카 수확작업의 자동화를 위한 인공지능 및 영상처리를 이용한 수확로봇 개발,2018,"['파프리카', '인공지능', '영상처리', '심층학습', '수확로봇']","본 연구는 파프리카 재배 환경의 영상 정보를 얻고 파프리카의 인식 및 위치 정보를 추출하는 인공지능 및 영상처리 알고리즘을 구현하였다. 위치 정보를 통하여 파프리카를 수확 할 수 있는 알고리즘을 개발하고 수확로봇을 제어하여 파프리카의 자동 수확을 수행하였다. 파프리카의 색상 정보를 분석하여 특징적인 색상(Hue)의 임계값과 그를 보조하기 위한 채도(Saturation)의 임계값을 설정하였다. 인공 신경망을 통하여 은닉층이 1개인 BP 알고리즘과 은닉층이 3개 이상인 심층 신경망 및 CNN 알고리즘을 통하여 학습을 수행하였으며 영상에서 파프리카 영역을 분할해 내는 알고리즘을 완성하였다. 수확로봇의 매니 퓰레이터는 좁은 공간에서 효율적으로 작업할 수 있도록 회전축, 수평, 수직축으로 이루어진 원통 형 로봇의 형태로 제작 하였으며, 엔드이펙터는 파프리카 외형 치수에 기반 하여 하부에서부터 접근하여 수확할 수 있는 형태로 제작하였다. 파프리카의 과실만을 이용하여 수확작업이 가능한 형태로 제작하였으며 수직방향의 줄기를 절단 할 수 없도록 절단부를 수직방향으로 제작하였다. 수확로봇을 제어 할 수 있도록 서보 모터와 앰프 및 모션 컨트롤러 시스템을 구성하였다. 엔드이펙터에 설치된 카메라를 이용하여 파프리카를 인식하고 ROI의 상단 중심과 하단 중심을 이용하여 파프리카의 위치와 자세를 추출하였다. 추출된 정보를 바탕으로 3단계에 걸친 수확 작업 알고리즘을 개발하였다. 수확을 시도한 110개의 파프리카 과실 중에서 97개는 수확이 가능하였으며, 전체 대상 작물 중 88.2%의 수확 성공률을 보였으며, 총 수확 작업을 하는데 소요된 시간은 79분 04초이다.",다국어 초록 정보 없음
3차원 합성곱 신경망을 통한 축구 객체 모션 인식 기법,2018,[],국문 초록 정보 없음,"Recently, sports and ICT technology have been combined, enabling quantitative and objective analysis of sports and players. As a result, in the case of soccer game, quantitative analysis of competition and athletes is underway in various companies, but due to technical limitations, many data are still being generated based on the manual work of experts. In this paper, we propose an object motion recognition technique based on 3D CNN which is a basis for further automation of soccer analysis. As can be seen from the experimental results, it can be confirmed that the proposed technique not only has high speed performance but also satisfactory accuracy as compared with the existing technologies."
인터뷰 대화에서 나타나는 관계범주 조정에 기반을 둔 칭찬전략 연구,2018,"['compliment', 'relationship category', 'categorization devices', 'membership category', 'interview talk']",국문 초록 정보 없음,"This study attempts to show how entertainment-oriented talk-show interactions between the host and the guest are organized as a type of semi-institutional talk, which exhibits the characteristics of both ordinary conversation and institutional talk in terms of many aspects of its discursive configuration. The purpose of this study is to address the participants’ complementary work based on their mutual knowledge about membership category. The conversational data examined here are excerpted from ‘Talk Asia’ of CNN, in which the host interviews a single guest with celebrity or expert status, addressing various topics concerning the guest’s personal life, career, or relationship with others. Within a conversational analytic framework, this study analyzes that, when the host questions about the guest’s relationship member who has not participated in this show, creating complimentary context, the guest usually uses category transformation or category comparison strategies and maximizes compliment for the relationship category in their own way. In other words, this study indicates that the participants in interview talk perform the categorization work such as transformation or comparison as a resource for organizing complimentary discursive action."
Ensemble of Degraded Artificial Intelligence Modules Against Adversarial Attacks on Neural Networks,2018,"['Adversarial attack', 'Artificial Intelligence', 'Image classification']",국문 초록 정보 없음,"Adversarial attacks on artificial intelligence (AI) systems use adversarial examples to achieve the attack objective. Adversarial examples consist of slightly changed test data, causing AI systems to make false decisions on these examples. When used as a tool for attacking AI systems, this can lead to disastrous results. In this paper, we propose an ensemble of degraded convolutional neural network (CNN) modules, which is more robust to adversarial attacks than conventional CNNs. Each module is trained on degraded images. During testing, images are degraded using various degradation methods, and a final decision is made utilizing a one-hot encoding vector that is obtained by summing up all the output vectors of the modules. Experimental results show that the proposed ensemble network is more resilient to adversarial attacks than conventional networks, while the accuracies for normal images are similar."
Deep-learning-based automatic computer-aided diagnosis system for diabetic retinopathy,2018,"['Computer-aided diagnosis', 'Diabetic retinopathy', 'Deep neural network', 'AlexNet DNN', 'Convolutional neural network', 'Gaussian mixture model', 'Linear discriminant analysis', 'SVM']",국문 초록 정보 없음,"The high-pace rise in advanced computing andimaging systems has given rise to a new research dimensioncalled computer-aided diagnosis (CAD) system forvarious biomedical purposes. CAD-based diabeticretinopathy (DR) can be of paramount significance toenable early disease detection and diagnosis decision.Considering the robustness of deep neural networks(DNNs) to solve highly intricate classification problems, inthis paper, AlexNet DNN, which functions on the basis ofconvolutional neural network (CNN), has been applied toenable an optimal DR CAD solution. The DR modelapplies a multilevel optimization measure that incorporatespre-processing, adaptive-learning-based Gaussian mixturemodel (GMM)-based concept region segmentation, connectedcomponent-analysis-based region of interest (ROI)localization, AlexNet DNN-based highly dimensional featureextraction, principle component analysis (PCA)- andlinear discriminant analysis (LDA)-based feature selection,and support-vector-machine-based classification to ensureoptimal five-class DR classification. The simulation resultswith standard KAGGLE fundus datasets reveal that theproposed AlexNet DNN-based DR exhibits a better performancewith LDA feature selection, where it exhibits aDR classification accuracy of 97.93% with FC7 features,whereas with PCA, it shows 95.26% accuracy. Comparativeanalysis with spatial invariant feature transform (SIFT)technique (accuracy—94.40%) based DR feature extractionalso confirms that AlexNet DNN-based DR outperformsSIFT-based DR."
Multi-scale Pedestrian Detection in Thermal Imaging Using Deep Convolutional Neural Network and Adaptive NMS,2018,"['human/pedestrian detection', 'thermal imaging', 'sliding window', 'DNN', 'adaptive NMS']",국문 초록 정보 없음,"In this paper, we propose a new method for pedestrian detection in thermal image/video by improving the non-maxima suppression(NMS) algorithm. We apply the sliding window detector based deep convolutional neural networks(DNN) to extract pedestrian candidates. A sliding window combined with image pyramids is used to identify pedestrians at varying scales and locations in the image via Convolutional Neural Network(CNN) based binary classification. To improve the performance, we propose an adaptive NMS algorithm to remove false alarms. The proposed NMS uses adaptive overlap-thresholds to overcome the drawback of the standard NMS and improve performance of detection system. It is automatically adjusting the overlap-thresholds based on the density of overlapping windows to improve the accuracy of system. Pedestrian detection experiment results with our thermal database and OSU thermal pedestrian database confirm that the proposed method outperforms the baseline method."
스마트폰 사진 합성을 통한 3D 아바타 모델링,2018,[],현대 사회의 발전으로 인해 사람들의 삶의 질이 향상됨에 따라 사람들은 다양한 방식으로 자신 및 자신의 개성을 표출하려는 시도를 한다. 특히 IT 기술의 발전은 가상현실 및 3D 기술의 성장을 이끌어냈다. 본 논문은 다가올 4차 산업혁명에 발맞추어 사용자의 개성을 표출할 실용적이고 개성 있는 3D 모델링 아이디어를 제안하고자 한다. 스마트폰 사진 촬영과 동시에 사용자가 선택한 다른 캐릭터 사진과의 합성 사진을 Convolutional Neural Network (CNN)과 Generative Adversarial Network (GAN) 기반 딥러닝 기술을 통해 생성한다. 생성된 이미지는 사용자의 모습과 합성의 대상이 되는 캐릭터의 모습을 동시에 담고 있다. 본 연구의 결과물로 생성된 합성 사진을 3D 프린터를 이용하여 자신만의 모습이 담긴 굿즈를 생산 혹은 이모티콘을 생성하는 등 다양한 실용적인 응용분야에 적용 가능하다.,다국어 초록 정보 없음
교대 형식 라멘교에 대한 손상 예측 시스템 개발,2018,"['Damage Prediction', 'Rigeid-Frame Bridge', 'Deep-Learning']",국문 초록 정보 없음,"In this study, to develop the basis of damage prediction system for abutment type rigid-frame bridge, measurement data is generated by artificially expressing damage by Abaqus, a commercial structural analysis program, and applied to machine-learning. The rigid-rame bridge structural analysis model is expressed as closely as possible to the actual bridge condition considering the specification, damage expression, analysis method, boundary condition, and load. CNN(Convolutional Neural Network), one of the neural network algorithm, is used for machine-learning and accuracy is confirmed when there was no measurement error as a result of machine learning."
영상기반의 End-to-end 자율주행 알고리즘 개발을 위한 데이터셋 및 평가환경 구축,2018,[],국문 초록 정보 없음,"In this paper, we constructed a public dataset for training and evaluation of an algorithm model for Vision based Autonomous Steering Control(V-ASC), and built a benchmark environment to analyze and provide qualitative and quantitative evaluation results. We also developed a baseline V-ASC model based on the handcrafted feature and the newly proposed convolutional neural network (CNN) based end-to-end driving model to verify the evaluation environment of the constructed dataset and simulator. Through the comparative evaluation between the models, we confirmed that the proposed evaluation framework is effective for performance analysis of V-ASC."
Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system,2018,"['Breast cancer', 'Mass detection and classification', 'Computer Aided Diagnosis', 'Deep learning', 'You Only Look Once (YOLO)']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P><B>Background and objective</B></P> <P>Automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. In this paper, we propose a novel Computer-Aided Diagnosis (CAD) system based on one of the regional deep learning techniques, a ROI-based Convolutional Neural Network (CNN) which is called You Only Look Once (YOLO). Although most previous studies only deal with classification of masses, our proposed YOLO-based CAD system can handle detection and classification simultaneously in one framework.</P>   <P><B>Methods</B></P> <P>The proposed CAD system contains four main stages: preprocessing of mammograms, feature extraction utilizing deep convolutional networks, mass detection with confidence, and finally mass classification using Fully Connected Neural Networks (FC-NNs). In this study, we utilized original 600 mammograms from Digital Database for Screening Mammography (DDSM) and their augmented mammograms of 2,400 with the information of the masses and their types in training and testing our CAD. The trained YOLO-based CAD system detects the masses and then classifies their types into benign or malignant.</P>   <P><B>Results</B></P> <P>Our results with five-fold cross validation tests show that the proposed CAD system detects the mass location with an overall accuracy of 99.7%. The system also distinguishes between benign and malignant lesions with an overall accuracy of 97%.</P>   <P><B>Conclusions</B></P> <P>Our proposed system even works on some challenging breast cancer cases where the masses exist over the pectoral muscles or dense regions.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A novel computer-aided diagnosis system based on deep learning techniques is proposed. </LI> <LI>  The proposed YOLO-based CAD system simultaneously handles both detection and classification of breast cancer masses. </LI> <LI>  YOLO-based CAD has a capability to handle most challenging cases of breast abnormalities. </LI> </UL> </P>"
딥러닝 기법을 이용한 가짜뉴스 탐지,2018,[],"SNS가 급속도로 확산되며 거짓 정보를 언론으로 위장한 형태인 가짜뉴스는 큰 사회적 문제가 되었다. 본 논문에서는 이를 해결하기 위해 한글 가짜뉴스 탐지를 위한 딥러닝 모델을 제시한다. 기존 연 구들은 영어에 적합한 모델들을 제시하고 있으나, 한글은 같은 의미라도 더 짧은 문장으로 표현 가능 해 딥러닝을 하기 위한 특징수가 부족하여 깊은 신경망을 운용하기 어렵다는 점과，형태소 중의성으로 인한 의미 분석의 어려움으로 인해 기존 모델들을 적용하기에는 한계가 있다. 이를 해결하기 위해 얕은 CNN 모델과 음절 단위로 학습된 단어 임베딩 모델인 Fasttext'를 활용하여 시스템을 구현하고, 이를 학습시켜 검증하였다.",다국어 초록 정보 없음
A Study on Drone Industry and Global Trend,2018,"['My drone', 'One Drone Per Person', 'Drone Technologies', 'Drone Industry', 'The Global Drone Market and Trend', 'Establishment of Direction for Drone Policy and Strategy', '마이드론', '1인 1드론시대', '드론기술력', '드론마켓과 글로벌트렌드', '드론정책수립과 방향', '드론산업의 글로벌 경쟁력']",국문 초록 정보 없음,"Existing drones with expensive and limited functions used by armed forces, government institutions and large companies, are becoming cheaper recently, is getting cheaper and versatile for various functions thanks to eyecatching technologies development through incessant development Drones have emerged as the important indispensable presence in human daily living such as politics, economy, social culture, armed force·society·sports·industry etc, using the speedy, free movement characteristics of drone in space comprising postal transportation, goods transportation, medicine transportation, traffic control, facilities management, fire and forest fire surveillance, coast surveillance etc , in addition to the service using cameras. Furthermore broadcasters such as U. S. CNN deeply moved the global society by taking movies and reporting the dangerous sites such as earthquake sites in recent Nepal and Indonesia as well as anti-government protest in Turkey, in safe and various angles of drones. The drone industry as technology concentrated industry using all of computer engineering, mechanical engineering, control engineering, aviation and air space engineering, electronic engineering, requires steady research and investment over a long period. From the material engineering where the structure of drone body is designed and the strength is computed, to the sophisticated automatic control to put the drone in action by real time computation of optimal path from current position to the destination, all technologies start with basic scientific rules. drone Concurrently with drone body technologies, development of devices mounted on small scale drones is being accelerated. In consideration of current speed of dissemination and impact of drones, the age of ‘My drone’, meaning one drone per person, is anticipated to come soon. The global drone market is expected to grow by 29% per year, reaching 82 billion USD size by year 2026. It is the time for manless aircraft industry to indulge in establishing industry infrastructure to enhance competitiveness by government’s policy support, enterprises’ technologies development, and prompt and proper revision of system and legislation. This thesis rearranges and analyzes the technologies, market prospect, major issues etc concentrating on the drone industry, and highlights the related core promising project areas, and focuses on improvement and establishment of direction for drone policy and strategy through analysis·research mainly on support policy for fostering the industry of major advanced countries."
Auto-Tuning CNNs for Coarse-Grained Reconfigurable Array-Based Accelerators,2018,[],국문 초록 정보 없음,"<P>As more and more deep learning tasks are pushed to mobile devices, accelerators for running these networks efficiently gain in importance. We show a that an existing class of general purpose accelerators, modulo-scheduled coarse-grained reconfigurable array (CGRA) processors typically used to accelerate multimedia workloads, can be a viable alternative to dedicated deep neural network processing hardware. To this end, an auto-tuning compiler is presented that maps convolutional neural networks (CNNs) efficiently on such architectures. The auto-tuner analyzes the structure of the CNN and the features of the CGRA, then explores the large optimization space to generate code that allows for an efficient mapping of the network. Evaluated with various CNNs, the auto-tuned code achieves an 11-fold speedup over the initial mapping. Comparing the energy per interference, the CGRA outperforms other general-purpose accelerators and an ARMv8 processor by a significant margin.</P>"
딥러닝을 활용한 여드름 중증도 측정,2018,"['Acne severity', 'Convolutional Neural Network Korean acne grading system', 'Deep learning']",국문 초록 정보 없음,"Background: Acne is a chronic inflammatory disease of the pilosebaceous unit, mainly on the face. It can have various clinical manifestations and should be appropriately treated based on the severity. In Korea, the 'Korea Acne Severity Rating System (KAGS)' is a standardized index to determine the severity of acne according to specific Korean characteristics. However, the actual use of the KAGS in clinical settings has been limited.Objective: We sought to analyze whether we could effectively measure acne severity using a deep learning algorithm, which is an image learning method.Methods: Acne severity was classified into three levels of mild, moderate, and severe based on the KAGS, and learning and verification were performed using the CNN (Convolutional Neural Network), a deep learning technique.Results: GoogLeNet's Inception-v3 algorithm showed the highest accuracy at 86.7%.Conclusion: This study confirmed that the use of a deep learning algorithm may facilitate the scoring of acne severity. (Korean J Dermatol 2018;56(7):421∼425)"
A Video Smoke Detection Algorithm Based on Cascade Classification and Deep Learning,2018,"['smoke detection', 'deep learning', 'convolutional neural network', 'cascade classification', 'BAIR reference CaffeNet']",국문 초록 정보 없음,"Fires are a common cause of catastrophic personal injuries and devastating property damage. Every year, many fires occur and threaten human lives and property around the world. Providing early important sign for early fire detection, and therefore the detection of smoke is always the first step in fire-alarm systems. In this paper we propose an automatic smoke detection system built on camera surveillance and image processing technologies. The key features used in our algorithm are to detect and track smoke as moving objects and distinguish smoke from non-smoke objects using a convolutional neural network (CNN) model for cascade classification. The results of our experiment, in comparison with those of some earlier studies, show that the proposed algorithm is very effective not only in detecting smoke, but also in reducing false positives."
< 전시-P-07 > 딥러닝 기술을 이용한 국산침엽수종 자동식별 온라인 웹서비스,2018,[],"현재 주로 이용되는 목재수종식별방법은 장기간 숙련된 전문가에 의한 육안식별이나 목재 샘플의 절편을 현미경으로 식별하는 방법이다. 하지만 이 방법은 전문가에게 시편을 전달하여 식별하기 때문에 유통과정에서 목재 수종을 바로 식별할 수 없다는 단점이 있다. 따라서 본 연구에서는 유통과정 중 실시간 목재 수종 식별이 가능하도록 딥러닝(Deep learning) 기술을 이용한 온라인 목재 수종 자동식별 시스템을 제작하였다.본 연구에서 사용한 시스템 환경으로 소프트웨어는 Linux(Ubuntu 16) 기반의 Tensorflow, Keras 및 개 발 언어인 Python을 설치하였고, 자동 식별된 이미지를 웹에서 확인할 수 있도록 Apache(웹서버), PHP, MySQL(데이터베이스 서버)를 설치하였다. 하드웨어는 Xeon 쿼드코어 CPU와 8GB RAM 사양의 서버를 사용하였다. 목재 이미지의 자동수종판별 모델은 선행 연구에서 가장 높은 식별률을 보인 LeNet 변형인 합성곱신경망(Convolutional neural network; CNN)을 개발하였다. 온라인 목재 수종 자동식별은 웹서비스(http://woodbank.snu.ac.kr)을 통해 이용할 수 있다. 웹사이트에서 사용자가 이동형 통신기기를 이용하여 획득한 목재 횡단면의 사진을 목재 수종 자동식별 시스템에 전달하면, 훈련된 LeNet 모델을 통해 전송된 목재 사진에 대한 식별결과를 얻을 수 있다. 식별결과는 웹사이트를 통해 확인할 수 있다.딥러닝 기술을 이용하여 개발된 목재 수종 온라인 식별 시스템은 목재 유통과정에서 목재 수종을 빠르고 정확하게 식별할 수 있을 것이라 기대된다.",다국어 초록 정보 없음
UAV 영상에서의 딥러닝 기반 조류 검출 알고리즘 개발,2018,"['야생조류', '철새', '딥러닝', 'YOLO', 'UAV', '항공영상']","야생조류의 거주지역과 개체수의 파악은 야생조류에 대한 보존과 관리에 있어 중요한 요소이며, 생태계의 건전성에 대한 지표가 된다. 조류의 개체수 조사는 포인트 카운트나 라인 트랜섹트 등의 방법으로 이루어지는데, 이는 사람이 직접 일부 지역의 조류 개체수를 조사하여 전체 지역의 개체수를 파악하는 방식으로, 시간 소모적이며 전체 지역의 정보가 정확히 반영되지 않는다. 또한 야생조류의 거주지역의 경우 지상으로의 접근이 어려우며, 지상에서의 시야는 공중에서의 시야에 비해 제한적이다. 야생동물 조사 시 이러한 단점을 개선하기 위하여 항공영상을 이용한 연구가 1900년대 후반부터 활발히 진행되고 있다. 특히 최근 간단히 운용 가능한 무인항공기(UAV; Unmanned aerial vehicle)의 발전에 따라 UAV를 이용한 야생조류의 개체수 파악과 관련된 연구들이 진행되고 있다.항공영상으로부터 야생조류를 검출하는 연구들은 대부분 기존의 영상처리나 머신러닝 기반의 학습을 이용하였다. 최근, 영상 검출의 분야에서 Faster-rcnn, YOLO, SSD, Mask-rcnn 등 CNN (Convolutional neural network) 기반의 딥러닝 검출 알고리즘들이 뛰어난 성능을 보이고 있으나, 야생조류에 대한 항공영상의 데이터 부족 등의 이유로 해당 분야에서 많은 연구가 이루어지고 있지 않다. 본 연구에서는 야생조류에 대한 항공영상 데이터를 확보하기 위하여 시화호와 영종도 등지에서 UAV를 이용하여 야생조류 군락지를 촬영하였으며, 항공영상을 이용한 야생조류의 생태와 개체수 파악을 위하여 YOLO 알고리즘 기반 검출 기법을 적용하였다.",다국어 초록 정보 없음
Planetary Long-Range Deep 2D Global Localization Using Generative Adversarial Network,2018,"['Global Localization System', 'Conditional Generative Adversarial Network']",국문 초록 정보 없음,"Planetary global localization is necessary for long-range rover missions in which communication with command center operator is throttled due to the long distance. There has been number of researches that address this problem by exploiting and matching rover surroundings with global digital elevation maps (DEM). Using conventional methods for matching, however, is challenging due to artifacts in both DEM rendered images, and/or rover 2D images caused by DEM low resolution, rover image illumination variations and small terrain features. In this work, we use train CNN discriminator to match rover 2D image with DEM rendered images using conditional Generative Adversarial Network architecture (cGAN). We then use this discriminator to search an uncertainty bound given by visual odometry (VO) error bound to estimate rover optimal location and orientation. We demonstrate our network capability to learn to translate rover image into DEM simulated image and match them using Devon Island dataset. The experimental results show that our proposed approach achieves ~74% mean average precision."
Correcting Misclassified Image Features with Convolutional Coding,2018,[],국문 초록 정보 없음,"The aim of this study is to rectify the misclassified image features and enhance the performance of image classification tasks by incorporating a channel-coding technique, widely used in telecommunication. Specifically, the proposed algorithm employs the error-correcting mechanism of convolutional coding combined with the convolutional neural networks (CNNs) that are the state-of-the-arts image classifiers. We develop an encoder and a decoder to employ the error-correcting capability of the convolutional coding. In the encoder, the label values of the image data are converted to convolutional codes that are used as target outputs of the CNN, and the network is trained to minimize the Euclidean distance between the target output codes and the actual output codes. In order to correct misclassified features, the outputs of the network are decoded through the trellis structure with Viterbi algorithm before determining the final prediction. This paper demonstrates that the proposed architecture advances the performance of the neural networks compared to the traditional one-hot encoding method."
Application of Convolution Neural Network Analysis on Intra-row Weeding System for Vegetables,2018,"['Cabbage', 'Image Recognition', 'Weeding', 'Deep Learning']",국문 초록 정보 없음,"Weeds play an important, non-negligible role in crop cultivation because their competition for sunlight, moisture, nutrients, space and other resources directly affects the growth of crops. Application of chemical treatment on weed control will pollute the environment and agricultural products, while physical treatments is time-consuming and laborious, which leads to low efficiency. This research intends to develop an intelligent vegetable intra-row weeding system using image positioning technology to conduct physical weeding. Total of 474 cabbage images with weeds were captured in the field with camera, in which 379 of these images were used as training data, and the other 95 images were used as testing data. Through the image processing method of Convolutional Neural Network (CNN), the features were extracted and classified between identify cabbages and weeds. There were 381 cabbages in the verified images in total, only 3 of which were unidentified, with a success rate of 99.2%. No weed was identified as cabbage, and the positions of cabbages were also obtained. Field tests were conducted using this built model to identify cabbage and had good recognition rates even when weeds were more than training samples."
A Two-Step Neural Dialog State Tracker for Task-Oriented Dialog Processing,2018,[],국문 초록 정보 없음,"<P>Dialog state tracking in a spoken dialog system is the task that tracks the flow of a dialog and identifies accurately what a user wants from the utterance. Since the success of a dialog is influenced by the ability of the system to catch the requirements of the user, accurate state tracking is important for spoken dialog systems. This paper proposes a two-step neural dialog state tracker which is composed of an informativeness classifier and a neural tracker. The informativeness classifier which is implemented by a CNN first filters out noninformative utterances in a dialog. Then, the neural tracker estimates dialog states from the remaining informative utterances. The tracker adopts the attention mechanism and the hierarchical softmax for its performance and fast training. To prove the effectiveness of the proposed model, we do experiments on dialog state tracking in the human-human task-oriented dialogs with the standard DSTC4 data set. Our experimental results prove the effectiveness of the proposed model by showing that the proposed model outperforms the neural trackers without the informativeness classifier, the attention mechanism, or the hierarchical softmax.</P>"
Human-level blood cell counting on lens-free shadow images exploiting deep neural networks,2018,[],국문 초록 정보 없음,"<P>In point-of-care testing, in-line holographic microscopes paved the way for realizing portable cell counting systems at marginal cost. To maximize their accuracy, it is critically important to reliably count the number of cells even in noisy blood images overcoming various problems due to out-of-focus blurry cells and background brightness variations. However, previous studies could detect cells only on clean images while they failed to accurately distinguish blurry cells from background noises. To address this problem, we present a human-level blood cell counting system by synergistically integrating the methods of normalized cross-correlation (NCC) and a convolutional neural network (CNN). Our comprehensive performance evaluation demonstrates that the proposed system achieves the highest level of accuracy (96.7-98.4%) for any kinds of blood cells on a lens-free shadow image while others suffer from significant accuracy degradations (12.9-38.9%) when detecting blurry cells. Moreover, it outperforms others by up to 36.8% in accurately analyzing noisy blood images and is 24.0-40.8× faster, thus maximizing both accuracy and computational efficiency.</P>"
Application of Image Classification using Machine Learning Technique on Smart Device,2018,"['Internet of things', 'Artificial intelligence', 'Image classification', 'Smartwatch application', '사물인터넷', '인공지능', '이미지 분류', '스마트워치 어플리케이션']",국문 초록 정보 없음,"This paper combines two of the most recent research topics for consumer electronic devices: Internet of Things (IoT) and Artificial Intelligence (AI), applied to solve an image classification problem for an electrical appliance’s recipe database. The first part of this article presents the development of an Android mobile application containing all the options from its recipe book manual. The problem addresses the inconvenience to manually search over the catalog categories to find the recipe that matches the actual ingredient available for the users in their home. The proposed solution establishes to recognize the ingredient with the mobile device camera using transfer learning over a pre-trained Convolutional Neural Network (CNN) to distinguish between the recipes that uses the ingredient, and exclude the recipe sets that are unrelated to the ingredient acquired with the camera. In the second part of the article, the availability of sensors on most of the wrist smartwatches and fitness bands is exploited to categorize the users according to the level of physical activity, in pursuance of making a healthy recommendation according to the number of calories in each of the recipes."
Underground Object Classification using 3D GPR Data,2018,"['Ground Penetrating Radar', 'Deep Learning', 'Image arrangement']",국문 초록 정보 없음,"In this study, a novel method based on ground penetration radar (GPR) is proposed to categorize underground objects by using both B-scan and C-scan images. Three-dimensional GPR data obtained from a multichannel GPR system are reconstructed into a two-dimensional (2D) grid image which consists of several B-scan and C-scan images. Three-dimensional shape information of an underground object can be well represented in 2D grid image. The 2D grid images are then trained using deep convolutional neural networks (CNN) that is a state-of-the-art technique for image classification problem. The proposed method is validated through field applications on urban roads in Seoul, South Korea."
(영상 기반) 백혈구 감별 기기 개발,2018,"['백혈구 검출', '백혈구 감별', '오토포커싱(Auto Focusing)', 'ISP(Image Signal Processing)']","본 논문은 (영상 기반) 백혈구(WBC, White Blood Cell) 감별 기기 개발을 제안하며, 기기는 영상 인터페이스, {검출, 감별}부로 구성한다. 먼저, 영상 인터페이스 부 내에, {고속, 고해상도} 산업용 카메라와 트리거(Trigger) 조명을 이용하여 백혈구 영상의 분해능을 향상 시키고, ISP(Image Signal Processing)을 적용하여, 영상을 보정한다. 백혈구 검출은 {저,고}배율로 구분하여 수행한다. (저배율 내에) 백혈구 후보를 검출한 후에, 고배율로 이동하여 최종적인 백혈구를 검출한다. 여기서 최종적인 백혈구는 AR(Artifact Cell)을 제외한 {정상, 비정상} 백혈구를 의미한다. 크로핑(Cropping)된 백혈구 영역 내에, 단일기반 영역 분할을 수행하고, (분할된 영상 내에) CNN(Convolutional Neural Network)[1]와 Random Forest[2]을 이용하여 14-클래스의 백혈구를 감별한다. 성능 검증은 TPR(True Positive Rate)방식으로, 정확도를 평가하였고, 처리시간은 (S/W 기준) 각각의 모듈 별로 측정하였다. 결론적으로, 95% 이상의 성능으로 실시간 처리가 가능함을 확인하였다.",다국어 초록 정보 없음
Structuring of Unstructured SNS Messages on Rail Services using Deep Learning Techniques,2018,"['Data Structuring', 'Deep neural network', 'Information of Rail services', 'Social network service', 'Text mining']",국문 초록 정보 없음,"This paper presents a structuring process of unstructured social network service (SNS) messages on rail services. We crawl messages about rail services posted on SNS and extract keywords indicating date and time, rail operating company, station name, direction, and rail service types from each message. Among them, the rail service types are classified by machine learning according to predefined rail service types, and the rest are extracted by regular expressions. Words are converted into vector representations using Word2Vec and a conventional Convolutional Neural Network (CNN) is used for training and classification. For performance measurement, our experimental results show a comparison with a TF-IDF and Support Vector Machine (SVM) approach. This structured information in the database and can be easily used for services for railway users."
점유 센서를 위한 합성곱 신경망과 자기 조직화 지도를 활용한 온라인 사람 추적,2018,"['on-line tracking', 'convolutional neural network', 'self organizing map', 'occupancy sensor']",국문 초록 정보 없음,"Occupancy sensors installed in buildings and households turn off the light if the space is vacant. Currently PIR(pyroelectric infra-red) motion sensors have been utilized. Recently, the researches using camera sensors have been carried out in order to overcome the demerit of PIR that cannot detect stationary people. The detection of moving and stationary people is a main functionality of the occupancy sensors. In this paper, we propose an on-line human occupancy tracking method using convolutional neural network (CNN) and self-organizing map. It is well known that a large number of training samples are needed to train the model offline. To solve this problem, we use an untrained model and update the model by collecting training samples online directly from the test sequences. Using videos capurted from an overhead camera, experiments have validated that the proposed method effectively tracks human."
수중 소나 영상의 부분 왜곡에 따른 학습 데이터 Augmentation을 통한 마커 검출 성능에 관한 연구,2018,"['Marker(마커)', 'Image distortion(영상 왜곡)', 'Data augmentation(데이터 확장)', 'Object detection(물체 검출)', 'Underwater sonar image(수중 소나 이미지)']",국문 초록 정보 없음,"The existing SLAM study refines the position of the mobile robot by using the landmarks obtained from the environment based on GPS. However, since it is impossible to use GPS in an underwater environment, detection of landmarks by sensors becomes very important. Unfortunately, the use of artificial landmarks is necessary because few features make it a natural landmark in a typical aquatic environment. The purpose of this study is to detect artificial markers based on the deep learning technique robustly. It always does not guarantee good results to use a complex deep-learning model, so it is needed to find the best model by adjusting the layers to get the best performance. In addition, the recognition rate of the deep-learning model is reduced by several noise such as distortion etc. during data acquisition. To solve this problem, the training data augmentation for the distortion was executed with the rotation. In this paper, we apply the object detection for the sonar image data of three types of artificial markers by using the Faster R-CNN."
Multimodal sensor-based semantic 3D mapping for a large-scale environment,2018,"['Semantic mapping', 'Semantic reconstruction', '3D mapping', 'Semantic segmentation', '3D refinement']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Semantic 3D mapping is one of the most important fields in robotics, and has been used in many applications, such as robot navigation, surveillance, and virtual reality. In general, semantic 3D mapping is mainly composed of 3D reconstruction and semantic segmentation. As these technologies evolve, there has been great progress in semantic 3D mapping in recent years. Furthermore, the number of robotic applications requiring semantic information in 3D mapping to perform high-level tasks has increased, and many studies on semantic 3D mapping have been published. Existing methods use a camera for both 3D reconstruction and semantic segmentation. However, this is not suitable for large-scale environments and has the disadvantage of high computational complexity. To address this problem, we propose a multimodal sensor-based semantic 3D mapping system using a 3D Lidar combined with a camera. In this study, the odometry is obtained by high-precision global positioning system (GPS) and inertial measurement unit (IMU), and it is estimated by iterative closest point (ICP) when a GPS signal is weak. Then, we use the latest 2D convolutional neural network (CNN) for semantic segmentation. To build a semantic 3D map, we integrate the 3D map with semantic information by using coordinate transformation and Bayes’ update scheme. In order to improve the semantic 3D map, we propose a 3D refinement process to correct wrongly segmented voxels and remove traces of moving vehicles in the 3D map. Through experiments on challenging sequences, we demonstrate that our method outperforms state-of-the-art methods in terms of accuracy and intersection over union (IoU). Thus, our method can be used for various applications that require semantic information in 3D map.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A novel method to generate semantic 3D map by combining a 3D Lidar and a camera for large-scale environments. </LI> <LI>  A refinement method to remove traces of moving vehicles in a 3D map. </LI> <LI>  Experiments on challenging sequences and real-world data to compare against state-of-the-art methods. </LI> <LI>  Demonstration of superiority in terms of 3D accuracy and intersection over union (IoU). </LI> </UL> </P>"
합성곱 신경망 기반의 위상 불변에 강건한 GIS PD 고장 진단 모델 개발,2018,"['Gas Insulated Switchgear(가스절연개폐장치)', 'Partial Discharge(부분방전)', 'Ultra High Frequency(초고주파)', 'Phase Resolved Pulse Sequence(PRPS)', 'Convolutional Neural Network(합성곱신경망)']",국문 초록 정보 없음,"Gas Insulated Switchgear(GIS) is electrical equipment for stable transformation or transmission. Since GIS serves to transmit or disconnect high voltage currents, it is very important to maintain stable internal isolation condition. Previous researches have been conducted to detect Partial Discharge(PD) by Ultra High Frequency(UHF)sensors, focusing on partial discharge among the causes that deteriorate internal isolation condition. In this study, PD diagnostic method was developed using Phase Resolved Pulse Sequence(PRPS) image, which is an image of the UHF sensor signal of GIS used in the actual field. For actual data, there is a phase shift phenomenon of PRPS images due to measurement or synchronization errors, which makes it difficult to diagnose them. To solve this problem, a Convolutional Neural Network(CNN) based Deep learning architecture robust to phase shift is proposed and it showed high diagnosis accuracy compared to previous algorithm."
The interpretable model for prediction sepsis in Intensive Care Unit : CNEWS (Convolutional Network for Early Warning System),2018,"['패혈증', '머신러닝', '중환자실', 'Sepsis', 'Machine learning', 'Critical care']",국문 초록 정보 없음,"Sepsis is defined as “life-threatening organ dysfunction caused by a dysregulated host response to infection”. To improve the result of sepsis, early identification and appropriate management in the initial hours after sepsis are emphasized. This study validates the CNEWS (Convolutional Network for Early Warning System) for detection and prediction of sepsis in ICU patients based on a machine learning algorithm at the tertiary academic hospital in Korea. We derive the development cohort from the patients who admitted to the ICU at the tertiary academic hospital with 200 ICU Beds. in South Korea, from 2013 to 2017. We make MIMIC-III as the validation cohort. The definition of sepsis is split into two concepts: suspected infection as blood culture taken and more than four qualifying antibiotic days with the first new antibiotic within±2 days of blood culture day, and organ failure as two or more points increased from baseline SOFA scores. Eighteen features including vital signs as dynamic features, and laboratory tests as static features are used to make the model based on Convolutional Neural Network (CNN). 21,700 patients are included in the development cohort and 4.4% of patients detected as sepsis. AUROCs of the CNEWS to predict sepsis before 4 hours, 6 hours, and 8 hours are 0.863, 0.864, 0.861, respectively. We demonstrate that high-performance algorithm models can predict the onset of sepsis by combining data from vital signs and laboratory data. This system can help physician decision-make, and also allocate restricted resources."
Convolutional Neural Networks for Analyzing Unmanned Aerial Vehicles Sound,2018,"['UAV', 'acoustics', 'FFT', 'CNNs']",국문 초록 정보 없음,"The emergence of Unmanned Aerial Vehicles (UAV) is pervasive throughout society. A growing segment of usage is of a dubious nature for harassment, illegal activity and terrorism. Detection of unknown UAV’s has become a requirement for many organizations and agencies to thwart the emergence of UAV’s that are in some way threatening. To detect UAV, the use of acoustic signals has become an useful area of research. Convolutional Neural Networks (CNNs) are one of several models of deep learning, applied in various fields such as image recognition and natural language processing. In this project, we design a system to detect the presence of possible detection and payload detection using CNNs on the basis of sound data generated from UAV flights. The sound of recorded drones is pre-processed into spectral data by Fast Fourier Transform (FFT) and Mel-Frequency Cepstrum (MFCC) and given as the input value to the CNN model. The results show that it is possible to detect and differentiate UAVs which have standard weight and also with additional payload. In short, the project has two detection goals. One is the acoustic detection of a UAV, and the second is the determination if that UAV has a payload."
"Deep-Learning-based Automatic Identification of Wildlife Species : A Case Study in Sobaeksan National Park, Korea",2018,['camera trap data processor deep learning wildlife identification convolutional neural network'],국문 초록 정보 없음,"Camera traps are mainly used to detect wildlife in protected areas. The captured images are interpreted by the human eye. Such visual interpretation is not only time consuming, but also makes it difficult to maintain data consistency when investigators changed. Recently, deep learning has been detecting object identification, counts, and image description in imagery with high accuracy. In this paper, we introduce the camera trap data processor that can automatically database wildlife species identification by deep learning. The Sobaeksan National Park's Jukryong eco-corridor was selected as a study area. Through the image-tracking algorithm, the minimum bounding rectangle of the wild animal object was detected and each frame was used as a training image. For deep learning, we used a convolutional neural network (CNN) technique, which is preferred in image recognition field. Open source libraries (OpenCV, TensorFlow, and Keras) were used to implement the model, and the software was developed through Python. The study results showed possibilities that it can reduce the survey time and minimize human errors."
"Intelligent intrusion detection system featuring a virtual fence, active intruder detection, classification, tracking, and action recognition",2018,"['Nuclear facilities', 'Intrusion detection', 'Virtual fence', 'Deep learning', 'Action recognition']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>An intrusion detection system (IDS) is primarily used to protect nuclear power plants from external threats, such as sabotage and malicious attacks. However, earlier versions of IDSs are configured to detect an intrusion from visual inspection by an operator. This has the disadvantages of requiring standby human resources and relying on operator capabilities. In this paper, therefore, we propose an image-based intelligent intrusion detection system (IIDS) with a virtual fence, active intruder detection, classification, and tracking, and motion recognition to solve these limitations. An integrated acquisition device was manufactured combining optical and thermal cameras to compensate for the disadvantages of optical cameras, which have difficulty detecting an intrusion at night, under adverse weather conditions, and when the intruder is camouflaged. The virtual fence has a function to set the boundary between surveillance and external areas in a graphical user interface, and to define an early pre-alarm area if necessary. The background model is designed to detect moving objects, and detected objects are segmented into bounding boxes. We implemented a network model based on a convolutional neural network (CNN) to classify moving objects as either intruders or wild animals. If an intruder is detected in real time and is crossing the virtual fence, the alarm tile blinks with the associated color. Five types of intruder behavior patterns are recognized by optimizing a long-term recurrent convolutional network (LRCN) model. The proposed IIDS meets the physical protection requirements recommended in the nuclear regulatory guidelines, and can be used as an unmanned surveillance system. It is expected to perform more active and reliable intrusion detection in combination with existing sensors, such as microwaves, electric fields, and fence disturbance sensors in a nuclear power plant.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Provide IIDS used to protect nuclear facilities from external threats. </LI> <LI>  Provide virtual fence function with multi-level intrusion alarms. </LI> <LI>  Provide automatic intruder classification feature with wild animals. </LI> <LI>  Provide five intruder behaviors (Running, walking, crawling, jumping, and climbing). </LI> </UL> </P>"
상전류 신호를 이용한 합성곱 네트워크 기반 유도전동기 고장 진단,2018,"['Induction motor(유도전동기)', 'stator current(상전류)', 'motor current signature analysis(모터 전류 분석)', 'convolution neural network(합성곱 네트워크)', 'unbalance(불균형)', 'broken rotor bar(회전자 봉 결함)', 'eccentricity(편심)']",국문 초록 정보 없음,"Induction motors (IMs), which are mainly applied to water pump, crane, and air handling unit in a large vessel, are widely used due to their low costs and high reliability compared to dc motors. Although the reliability of IM is quite high, their unexpected manifestation due to some manufacturing tolerance, various environmental conditions and mistakes in the field lead to huge loss even with a small down-time. The fault detection of IM is thus necessary, and motor current signature analysis (MCSA) is one of the most effective methods for diagnosing motor faults. MCSA has advantages in the part of non-invasive data acquisition, however, suffers from noise and difficulties in feature extraction. This study thus proposes an automated feature extraction and fault diagnosis method using convolutional neural network (CNN). The proposed method is validated with the experimental data measured from a 160kW IM, and the improved performance of it is confirmed by comparing it with the results obtained from the conventional methods."
표정 분류 연구,2018,[],국문 초록 정보 없음,"Effective interaction between user and device is considered an important ability of IoT devices. For some applications, it is necessary to recognize human facial expressions in real time and make accurate judgments in order to respond to situations correctly. Therefore, many researches on facial image analysis have been preceded in order to construct a more accurate and faster recognition system. In this study, we constructed an automatic recognition system for facial expressions through two steps - a facial recognition step and a classification step. We compared various models with different sets of data with pixel information, landmark coordinates, Euclidean distances among landmark points, and arctangent angles. We found a fast and efficient prediction model with only 30 principal components of face landmark information. We applied several prediction models, that included linear discriminant analysis (LDA), random forests, support vector machine (SVM), and bagging; consequently, an SVM model gives the best result. The LDA model gives the second best prediction accuracy but it can fit and predict data faster than SVM and other methods. Finally, we compared our method to Microsoft Azure Emotion API and Convolution Neural Network (CNN). Our method gives a very competitive result."
스마트 디바이스에 적용한 기계학습기반 이미지 분류 어플리케이션,2018,"['사물인터넷', '인공지능', '이미지 분류', '스마트워치 어플리케이션', 'Internet of things', 'Artificial intelligence', 'Image classification', 'Smartwatch application']","본 논문은 사물인터넷과 인공지능 기술을 적용한 이미지 분류 기법을 제안한다. 제안한 분류 기법은 과일과 채소 등을 인식하는데 사용하며, 대상 사물을 분별한 후 이 사물이 포함된 조리 기법을 추천하는 기능을 제공하는 어플리케이션을 구현한다. 어플리케이션은 조리 기법 책에서 제공하는 재료(종류 및 무게), 조리 순서 등의 모든 정보를 사용자에게 제공하도록 구현하고, 또한 조리 대상 사물을 인식하는 컨볼루션널 신경망 기반 인공지능 기술도 추가하여조리의 편리성을 향상하도록 한다. 스마트워치에서는 사용자의 일일 운동량 및 생체 정보를 바탕으로 사용자에게 가장 적합한 주스 조리 기법을 추천하는 기능을 제공하도록 어플리케이션을 구현한다.","This paper combines two of the most recent research topics for consumer electronic devices: Internet of Things (IoT) and Artificial Intelligence (AI), applied to solve an image classification problem for an electrical appliance’s recipe database. The first part of this article presents the development of an Android mobile application containing all the options from its recipe book manual. The problem addresses the inconvenience to manually search over the catalog categories to find the recipe that matches the actual ingredient available for the users in their home. The proposed solution establishes to recognize the ingredient with the mobile device camera using transfer learning over a pre-trained Convolutional Neural Network (CNN) to distinguish between the recipes that uses the ingredient, and exclude the recipe sets that are unrelated to the ingredient acquired with the camera. In the second part of the article, the availability of sensors on most of the wrist smartwatches and fitness bands is exploited to categorize the users according to the level of physical activity, in pursuance of making a healthy recommendation according to the number of calories in each of the recipes."
Suitable Activity Function of Neural Networks for Data Enlargement,2018,"['Data enlargement', 'multi-layer neurons network', 'Suitable activity function', 'multi teacher training signals', 'backpropagation neural network and convolution neural networks']",국문 초록 정보 없음,"In this paper, we present a study on activity functions for a multi-layered neural networks (MLNNs) and propose a suitable activity function for data enlargement (DE). We have carefully studied the training performance of Sigmoid, ReLu, Leaky-ReLu and L & exp. activity functions for three inputs to multiple output training patterns. Our MLNNs model has L hidden layers with two inputs to four or six outputs by backpropagation neural network training (BP). We focused on the multi teacher training signals to investigate and evaluate the training performance in MLNNs and select the best and good activity function for data enlargement and hence could be applicable for image and signal processing (synaptic divergence). We specifically used four activity functions from which we found out that L & exp. activity function can suite data enlargement neural network training (DENN) since it could give the highest percentage training abilities compared to the other activity functions of Sigmoid, ReLu and Leaky-ReLu during simulation and training of data in the network. And finally, we recommend L & exp. function to be good for MLNNs and may be applicable for signal processing of data and information enlargement because of its performance training characteristics with multiple training logic patterns hence convolution neural networks (CNN)."
Estimation of termite population size using convolution neural network,2018,[],국문 초록 정보 없음,"In this study we present a new approach to estimating termite populations size. So far, termite researchers have been using the mark-capture-recapture method. This method has a disadvantage that measurement time is long and error range is large. To this end, we built an agent-based model to simulate termite tunneling behavior. Using this model, we made simulated tunnel patterns that are determined by three variables: the number of simulated termites (N), the passing probability of two encountering termites (P), and the distance that termites move soil parcels (D). To explore whether the N value can be estimated with a partial termite tunnel pattern, we generated four groups of tunnel patterns that are partially obscured in complete tunnel pattern image: (1) A pattern group in which the outer area of the tunnel pattern is obscured (I-pattern), (2) a pattern group in which half of the tunnel pattern is obscured (H-pattern), (3) a pattern group in which the inner region of the tunnel pattern is obscured (O-pattern), and (4) a pattern group combining I- and O-pattern (IO-pattern). For each group, 80% of the tunnel patterns were learned through a convolution neural network (CNN) and the remaining 20% of the patterns were used for estimating N value. The estimation results showed that the N estimates for the IO-pattern are the most accurate and are in the order I-, H-, and O-patterns. This means that the termite population size can be estimated based on tunnel information near the center of the colony."
Real-time apnea-hypopnea event detection during sleep by convolutional neural networks,2018,"['Apnea-hypopnea event detection', 'Convolutional neural networks', 'Real-time monitoring', 'Sleep apnea and hypopnea syndrome diagnosis', 'Nasal pressure signal']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Sleep apnea-hypopnea event detection has been widely studied using various biosignals and algorithms. However, most minute-by-minute analysis techniques have difficulty detecting accurate event start/end positions. Furthermore, they require hand-engineered feature extraction and selection processes. In this paper, we propose a new approach for real-time apnea-hypopnea event detection using convolutional neural networks and a single-channel nasal pressure signal. From 179 polysomnographic recordings, 50 were used for training, 25 for validation, and 104 for testing. Nasal pressure signals were adaptively normalized, and then segmented by sliding a 10-s window at 1-s intervals. The convolutional neural networks were trained with the data, which consisted of class-balanced segments, and were then tested to evaluate their event detection performance. According to a segment-by-segment analysis, the proposed method exhibited performance results with a Cohen's kappa coefficient of 0.82, a sensitivity of 81.1%, a specificity of 98.5%, and an accuracy of 96.6%. In addition, the Pearson's correlation coefficient between estimated apnea-hypopnea index (AHI) and reference AHI was 0.99, and the average accuracy of sleep apnea and hypopnea syndrome (SAHS) diagnosis was 94.9% for AHI cutoff values of ≥5, 15, and 30 events/h. Our approach could potentially be used as a supportive method to reduce event detection time in sleep laboratories. In addition, it can be applied to screen SAHS severity before polysomnography.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose an automated apnea-hypopnea (AH) event detection model, based on Convolutional Neural Network (CNN). </LI> <LI>  Overlapping nasal pressure signal segments are used to precisely detect AH events. </LI> <LI>  Event detection performance was evaluated via segment analysis and apnea-hypopnea index (AHI) estimation analysis. </LI> <LI>  The proposed model exhibited a kappa of 0.82 in event detection and an average accuracy of 94.9% in SAHS severity diagnosis. </LI> </UL> </P>"
합성곱 신경망을 활용한 위내시경 이미지 분류에서 전이학습의 효용성 평가,2018,"['Gastroscope', 'Convolutional Neual Network', 'Transfer learning', 'Resnet', 'Inception', 'VGGnet']",국문 초록 정보 없음,"Stomach cancer is the most diagnosed cancer in Korea. When gastric cancer is detected early, the 5-year survival rate is as high as 90%. Gastroscopy is a very useful method for early diagnosis. But the false negative rate of gastric cancer in the gastroscopy was 4.6~25.8% due to the subjective judgment of the physician. Recently, the image classification performance of the image recognition field has been advanced by the convolutional neural network. Convolutional neural networks perform well when diverse and sufficient amounts of data are supported. However, medical data is not easy to access and it is difficult to gather enough high-quality data that includes expert annotations. So This paper evaluates the efficacy of transfer learning in gastroscopy classification and diagnosis. We obtained 787 endoscopic images of gastric endoscopy at Gil Medical Center, Gachon University. The number of normal images was 200, and the number of abnormal images was 587. The image size was reconstructed and normalized. In the case of the ResNet50 structure, the classification accuracy before and after applying the transfer learning was improved from 0.9 to 0.947, and the AUC was also improved from 0.94 to 0.98. In the case of the InceptionV3 structure, the classification accuracy before and after applying the transfer learning was improved from 0.862 to 0.924, and the AUC was also improved from 0.89 to 0.97. In the case of the VGG16 structure, the classification accuracy before and after applying the transfer learning was improved from 0.87 to 0.938, and the AUC was also improved from 0.89 to 0.98. The difference in the performance of the CNN model before and after transfer learning was statistically significant when confirmed by T-test (p < 0.05). As a result, transfer learning is judged to be an effective method of medical data that is difficult to collect good quality data."
Body-movement-based human identification using convolutional neural network,2018,"['Low-illumination corridor', 'The front and back view of body', 'Human identification', 'Convolutional neural network']",국문 초록 정보 없음,"<P><B>Abstract</B></P>  <P>Biometric technology based on human gait identifies humans at a far distance even if the individual's face is covered, hidden, or not visible to cameras in dark environments. Previous studies based on human gait were conducted considering both bright and dark environments for human identification in surveillance systems. The studies conducted in low-illumination environments (dark environments) are based on side view images (horizontal walking) of subjects. However, there are cases in which people only show the front and back views of their bodies while they are walking in low-illumination corridors. In these views, it is difficult to identify humans by using conventional features such as cycle, cadence, stride length of walking, and distance between points (ankle, knee, and hip). Additionally, the cases of problems such as people carrying cellphones and/or small personal items (a purse, bag, clothes, etc.) have critical effects on the accuracy of human identification. To overcome these problems, we propose a new human identification technique, which is based on the front and back view images of a human, captured by using a thermal camera sensor. Our technique uses movements of the human body for identification, particularly movement of the head, shoulders, and legs. We have used a convolutional neural network for feature extraction and classification in this study. Five datasets were compiled by collecting data of 80 people including men and women in both bright and dark environments. The experimental results with our collected data and open database showed a higher performance by using our method compared to those of previous studies.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Our method is body movement-based human identification using front and back view. </LI> <LI>  Our identification method is robust to the cases of people carrying items or with various poses. </LI> <LI>  Deep learning method using thermal difference image-based three-channel inputs is used. </LI> <LI>  Our collected database and trained CNN are public to other researchers. </LI> </UL> </P>"
An Efficient Color Space for Deep-Learning Based Traffic Light Recognition,2018,[],국문 초록 정보 없음,"<P>Traffic light recognition is an essential task for an advanced driving assistance system (ADAS) as well as for autonomous vehicles. Recently, deep-learning has become increasingly popular in vision-based object recognition owing to its high performance of classification. In this study, we investigate how to design a deep-learning based high-performance traffic light detection system. Two main components of the recognition system are investigated: the color space of the input video and the network model of deep learning. We apply six color spaces (RGB, normalized RGB, Ruta’s RYG, YCbCr, HSV, and CIE Lab) and three types of network models (based on the Faster R-CNN and R-FCN models). All combinations of color spaces and network models are implemented and tested on a traffic light dataset with 1280&times720 resolution. Our simulations show that the best performance is achieved with the combination of RGB color space and Faster R-CNN model. These results can provide a comprehensive guideline for designing a traffic light detection system.</P>"
Improved Sliding Shapes for Instance Segmentation of Amodal 3D Object,2018,"['instance segmentation', 'detector', 'fully convolution network', 'amodal proposals']",국문 초록 정보 없음,"State-of-art instance segmentation networks are successful at generating 2D segmentation mask for region proposals with highest classification score, yet 3D object segmentation task is limited to geocentric embedding or detector of Sliding Shapes. To this end, we propose an amodal 3D instance segmentation network called A3IS-CNN, which extends the detector of Deep Sliding Shapes to amodal 3D instance segmentation by adding a new branch of 3D ConvNet called A3IS-branch. The A3IS-branch which takes 3D amodal ROI as input and 3D semantic instances as output is a fully convolution network(FCN) sharing convolutional layers with existing 3d RPN which takes 3D scene as input and 3D amodal proposals as output. For two branches share computation with each other, our 3D instance segmentation network adds only a small overhead of 0.25 fps to Deep Sliding Shapes, trading off accurate detection and point-to-point segmentation of instances. Experiments show that our 3D instance segmentation network achieves at least 10% to 50% improvement over the state-of-art network in running time, and outperforms the state-of-art 3D detectors by at least 16.1 AP."
인공지능을 이용한 파프리카 실내 양액 재배 시 발생하는 병해충 자동 검출,2018,"['paprika', 'AI', 'disease/pest', 'detection']",국문 초록 정보 없음,A method for the automatic detection of diseases/infestations in paprika cultivation using AI is investigated. Powdery mildew was the paprika disease observed during hydroponic cultivation in a greenhouse environment. The two-spotted-spider-mite was the pest. Paprika leaves with either the disease or the pest were automatically detected using a Faster R-CNN network architecture. The detection performance was high with mAP 96.76 %. The training and testing arrangements and the training data set are described in detail.
무인 항공기를 이용한 밀집영역 자동차 탐지,2018,"['Vehicle Detection', 'Deep Learning', 'Darknet', 'YOLOv2', 'Object Detection']",본 논문은 최근 물체탐지 분야에서 실시간 물체 탐지 알고리즘으로 주목을 받고 있는 YOLOv2(You Only Look Once) 알고리즘을 이용하여 밀집 영역에 주차되어 있는 자동차 탐지 방법을 제안한다. YOLO의 컨볼루션 네트워크는 전체 이미지에서 한 번의 평가를 통해서 직접적으로 경계박스들을 예측하고 각 클래스의 확률을 계산하고 물체 탐지 과정이 단일 네트워크이기 때문에 탐지 성능이 최적화 되며 빠르다는 장점을 가지고 있다. 기존의 슬라이딩 윈도우 접근법과 R-CNN 계열의 탐지 방법은 region proposal 방법을 사용하여 이미지 안에 가능성이 많은 경계박스를 생성하고 각 요소들을 따로 학습하기 때문에 최적화 및 실시간 적용에 어려움을 가지고 있다. 제안하는 연구는 YOLOv2 알고리즘을 적용하여 기존의 알고리즘이 가지고 있는 물체 탐지의 실시간 처리 문제점을 해결하여 실시간으로 지상에 있는 자동차를 탐지하는 방법을 제안한다. 제안하는 연구 방법의 실험을 위하여 오픈소스로 제공되는 Darknet을 사용하였으며 GTX-1080ti 4개를 탑재한 Deep learning 서버를 이용하여 실험하였다. 실험결과 YOLO를 활용한 자동차 탐지 방법은 기존의 알고리즘 보다 물체탐지에 대한 오버헤드를 감소 할 수 있었으며 실시간으로 지상에 존재하는 자동차를 탐지할 수 있었다.,"This paper proposes a vehicle detection method for parking areas using unmanned aerial vehicles (UAVs) and using YOLOv2, which is a recent, known, fast, object-detection real-time algorithm. The YOLOv2 convolutional network algorithm can calculate the probability of each class in an entire image with a one-pass evaluation, and can also predict the location of bounding boxes. It has the advantage of very fast, easy, and optimized-at-detection performance, because the object detection process has a single network. The sliding windows methods and region-based convolutional neural network series detection algorithms use a lot of region proposals and take too much calculation time for each class. So these algorithms have a disadvantage in real-time applications. This research uses the YOLOv2 algorithm to overcome the disadvantage that previous algorithms have in real-time processing problems. Using Darknet, OpenCV, and the Compute Unified Device Architecture as open sources for object detection. a deep learning server is used for the learning and detecting process with each car. In the experiment results, the algorithm could detect cars in a dense area using UAVs, and reduced overhead for object detection. It could be applied in real time."
A Video Processing Strategy using Camera Movement Estimation for Apple Yield Forecasting,2018,"['Computer Vision', 'Deep Learning', 'Image Processing', 'Precision Agriculture', 'Yield Mapping']",국문 초록 정보 없음,"Yield prediction or yield forecasting is an important procedure in the planning of farm management. An accurate and site-specific yield prediction system performs a pre-harvesting inspection of agricultural fields and help labor demand projections, precision crop management, inventory and storage planning. In this study, a machine vision system was developed to deliver more objective and detailed forecasts of an apple orchard. Image frame sequences of a camera moving along the tree canopy were collected for real-time video processing in a Tall Spindle apple production system. To develop a high-accuracy apple detection system, a deep learning framework using Faster R-CNN and an image matching technique using cross-correlation were adopted for fruit detection and tracking. The results of this study showed 0.99 and 0.79 of precision and recall, respectively. Also, the tracking algorithm showed 38.5 pixels of root mean square errors (RMSE) between the estimated locations and true locations of objects. The techniques developed in this study could be further developed into a commercial machine vision system suitable for yield prediction, and mechanization of various orchard tasks such as fruit thinning and harvest."
카메라를 활용한 딥러닝 기반 자율주행자동차의 사각 지대 객체 검출 및 경고 시스템에 관한 연구,2018,"['Autonomous car(무인자동차)', 'Deep Learning(딥러닝)', 'Image Processing(영상처리)', 'Blind Spot Area(사각  지대)', 'Object Detection(객체 검출)']",국문 초록 정보 없음,"In this paper, we propose blind spot area detection and warning system for autonomous driving automobiles based on deep running using a camera to prevent accidents caused by autonomous vehicles due to angle limitation of side mirrors. Recently, algorithms capable of real-time object detection through deep learning have attracted attention in the image processing field of autonomous driving. In this paper, SSD(Single Shot Multibox Detector) algorithm is used for detection of blind spot objects. SSD has an accuracy similar to that of conventional Faster R-CNN and has the advantage of detecting objects faster than YOLO(You Only Look Once). Experimental results show that we can solve the trade-off problem of accuracy and real-time performance of existing algorithm by applying SSD in well-balanced manner, and confirm warning and real-time detection possibility of blind spot objects of autonomous vehicles."
사이드 스캔 소나 영상에서 수중물체 자동 탐지를 위한 컨볼루션 신경망 기법 적용,2018,['-'],국문 초록 정보 없음,"In this paper, we have studied how to search an underwater object by learning the image generated by the side scan sonar in the convolution neural network. In the method of human side analysis of the side scan image or the image, the convolution neural network algorithm can enhance the efficiency of the analysis. The image data of the side scan sonar used in the experiment is the public data of NSWC (Naval Surface Warfare Center) and consists of four kinds of synthetic underwater objects. The convolutional neural network algorithm is based on Faster R-CNN (Region based Convolutional Neural Networks) learning based on region of interest and the details of the neural network are self-organized to fit the data we have. The results of the study were compared with a precision-recall curve, and we investigated the applicability of underwater object detection in convolution neural networks by examining the effect of change of region of interest assigned to sonar image data on detection performance."
인공지능 프로세서 기술 동향,2018,[],국문 초록 정보 없음,"The Von Neumann based architecture of the modern computer has dominated the computing industry for the past 50 years, sparking the digital revolution and propelling us into today’s information age. Recent research focus and market trends have shown significant effort toward the advancement and application of artificial intelligence technologies. Although artificial intelligence has been studied for decades since the Turing machine was first introduced, the field has recently emerged into the spotlight thanks to remarkable milestones such as AlexNet-CNN and Alpha-Go, whose neural-network based deep learning methods have achieved a ground-breaking performance superior to existing recognition, classification, and decision algorithms. Unprecedented results in a wide variety of applications (drones, autonomous driving, robots, stock markets, computer vision, voice, and so on) have signaled the beginning of a golden age for artificial intelligence after 40 years of relative dormancy. Algorithmic research continues to progress at a breath-taking pace as evidenced by the rate of new neural networks being announced. However, traditional Von Neumann based architectures have proven to be inadequate in terms of computation power, and inherently inefficient in their processing of vastly parallel computations, which is a characteristic of deep neural networks. Consequently, global conglomerates such as Intel, Huawei, and Google, as well as large domestic corporations and fabless companies are developing dedicated semiconductor chips customized for artificial intelligence computations. The AI Processor Research Laboratory at ETRI is focusing on the research and development of super low-power AI processor chips. In this article, we present the current trends in computation platform, parallel processing, AI processor, and super-threaded AI processor research being conducted at ETRI."
딥러닝을 이용한 돼지 돈사 내 돼지 행동 및 상태 분석,2018,"['돈사', '개체 인식', '딥러닝', '영상분석']","국내 돼지 생산은 생산성 향상을 위해 밀집도가 높은 집중사육 방식으로 이루어지고 있다. 이러한 높은 밀집도의 집중사육은 인력으로 관리가 어려워 돈사 내부의 작업환경을 열악하게 하고 질병감염 가능성과 스트레스를 높여 오히려 생산성을 떨어뜨릴 수 있다. 개별 돼지는 지속적으로 모니터링하면서 이상증상이 발견될 시 조기 처방하는 것이 가장 이상적이나 열악한 작업환경에서 장시간 인력으로 관리하는 것은 매우 어렵다. 따라서 본 연구에서는 인력의 도움이 없이 개별 돼지의 행동 및 상태를 실시간 자동으로 분석할 수 있는 영상분석 기술을 개발하고자 하였다. 본 연구에 활용된 영상시스템은 Grayscale 초광각 카메라를 이용하였으며, 돈사 내 천장에서 돈사내부전경을 촬영하여 영상을 분석하도록 하였다. 실시간으로 획득한 영상들은 일정기간동안 보관되며 돼지의 상태를 분석하는데 사용된다. Faster R-CNN (Region-Convolutional Neural Network) 알고리즘을 이용하여 실시간 돼지 개체를 자동으로 인식하고, 획득된 개별 돼지들의 영상을 통해 행동 및 상태를 분석할 수 있는 모델을 개발하고자 하였다. 본 연구에서 분석된 결과를 통해 딥러닝 영상분석 기술이 개별 돼지의 인식은 물론, 식사, 배설, 건강상태 등의 행동분석에도 활용될 수 있음을 확인 할 수 있었다.",다국어 초록 정보 없음
심층 신경망을 활용한 전자문서 내 객체의 자동 추출 방법 연구,2018,"['Object Extraction', 'Deep Learning', 'Tensorflow', 'PDF Document', '객체 추출', '심층 학습', '텐서플로우', '전자문서']",국문 초록 정보 없음,"With the proliferation of artificial intelligence technology, it is becoming important to obtain, store, and utilize scientific data in research and science sectors. A number of methods for extracting meaningful objects such as graphs and tables from research articles have been proposed to eventually obtain scientific data. Existing extraction methods using heuristic approaches are hardly applicable to electronic documents having heterogeneous manuscript formats because they are designed to work properly for some targeted manuscripts. This paper proposes a prototype of an object extraction system which exploits a recent deep-learning technology so as to overcome the inflexibility of the heuristic approaches. We implemented our trained model, based on the Faster R-CNN algorithm, using the Google TensorFlow Object Detection API and also composed an annotated data set from 100 research articles for training and evaluation. Finally, a performance evaluation shows that the proposed system outperforms a comparator adopting heuristic approaches by 5.2%."
