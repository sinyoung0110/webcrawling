title,date,keywords,abstract,multilingual_abstract
기계학습(Machine Learning)이 적용된 음악플랫폼(Chordify)을 통한 기악지도 방법 - 자기주도학습을 중심으로 -,2025,"['기계학습', '자기주도학습', '기악지도 방법', 'machine learning', 'self-directed learning', 'instrumental music teaching method']","본 연구는 자기주도학습을 중심으로 인공지능 기계학습(Machine Learning) 기술이 적용된 음악플랫폼(Chordify)을 활용하여 악기를 학습하는 방안을 마련하는 것이 목적이다. 이를 위해 기계학습과 자기주도학습, 온라인 음악플랫폼에 대한 개념 설명, 코디파이(Chordify) 프로그램을 소개하였고, 자기주도학습이 가능한 방과 후학교 프로그램을 활용하여 초등학교 고학년을 위한 총 8차시로 구성된 수업과정 프로그램과 음악학습을 선정한2차시 수업지도안을 제안하였다. 새로운 모바일 기술과 디지털 기술의 결합에 이은 인공지능의 발전은 네트워크기반 정보 습득을 손쉽게 만들어 개개인의 학습 환경에 많은 변화를 이끌고 있다. 전통적 교수 환경에서 벗어나시간과 공간이 비교적 자유로운 온라인 학습 환경에서의 자기주도적 기악학습은 학습자에게 높은 성취감을 제공할 것이며 나아가, 기계학습이 적용된 음악플랫폼은 초보연주자에게 맞춤 단계별 연습을 제공하고, 개인별 선택프로그램을 통해 악기를 학습할 수 있는 적절한 환경을 제공할 것이다.","The purpose of this study is to develop a method for learning musical instruments using a music platform with artificial intelligence(machine learning) technology focusing on self-directed learning. For this purpose, machine learning and self-directed learning, concept explanation of online music platform, and chordify program were introduced. A class instruction plan was proposed to select and implement a course consisting of a total of 8 sessions and music learning upper grades of elementary school using an after-school program that allows self-directed learning. The development of artificial intelligence, following the combination of new mobile and digital technologies, is leading to many changes in the individual learning environment by making it easier to acquire network-based information. Self-directed instrumental learning that breaks away from the traditional teaching environment will provide learners with a high sense of achievement in an online learning environment with relative freedom of time and space. Furthermore, the music platform with machine learning will provide customized step-by-step practice to beginning performers and provide an optimized environment for learning instruments through individually selected programs."
AI와 Machine Learning 기법을 활용한 영화의 흥행 예측 연구: 영화 개봉 전 상호 데이터를 중심으로,2025,"['Box Office Prediction', 'Automated Machine Learning', 'Interaction Data', 'Recursive Feature Elimination with Cross Validation', '영화 흥행 예측', 'Box Office Prediction', 'Automated Machine Learning', 'Interaction Data', 'Recursive Feature Elimination with Cross Validation']",,"This study proposes a box office prediction model utilizing AI and machine learning (ML) techniques based on static data available before a film’s release and evaluates its performance by comparing it with existing baseline models. Using KOBIS data collected from 2013 to 2024, we generated descriptive statistics and interaction-derived variables for actors, directors, distributors, and genres. Key features were selected using Recursive Feature Elimination with Cross-Validation (RFECV). Additionally, an AutoML approach was applied to train an optimized model for the dataset, and Naver search trend data was incorporated to enhance predictive performance. Experimental results demonstrated that the proposed model outperformed both baseline and existing research models, achieving high accuracy based on F1-Macro and AHPR-Bingo evaluation metrics. Notably, interaction-derived variables were identified as key contributors to model performance improvement, confirming that prediction models based on static data can serve as valuable tools in the decision-making processes of the film industry. This study makes both academic and practical contributions by presenting a box office prediction model solely based on static data. The findings provide a useful framework for film producers and distributors to support strategic decision-making before release. Future research can extend this study by incorporating dynamic data and applying the model to diverse datasets for further validation and enhancement."
Approaches to Improving Rainfall Classification Accuracy in Central Vietnam Using Machine Learning Models,2025,"['Data balance', 'Space-time sampling', 'Light gradient boosting machine', 'Rainfall classification']",,"Classifying rainfall in detail and accurately, especially in cases where there is a significant imbalance between rain and no-rain data, is always a very challenging problem. This paper proposes a novel method in which the two-phase machine learning model with the Light Gradient Boosting Machine algorithm is used for rain classification (rain/no-rain classification and further classification of rain into weak, moderate, heavy, and very heavy categories) in Central Vietnam. To address the data imbalance to enhance classification accuracy, the proposed model employs two different data balancing techniques for each phase: rain interval-based random augmentation for the two-class classification and class weighting for the four-class classification. The proposed model implements a sampling strategy based on rain gauge station locations and specific times during the day (space-time sampling) and integrates multi-source data, including Himawari-8 satellite imagery, rainfall measurements, ERA-5 reanalysis data, and ASTER Digital Elevation Model (DEM), from 2019 to 2020. This model demonstrates its superior performance compared to other machine learning models: Extreme Gradient Boosting (XGB), Random Forest (RF), and Artificial Neural Networks (ANN), as well as five regional precipitation products: Global Satellite Mapping of Precipitation with Microwave-Infrared Reanalyzed Data (GSMaP_MVK), Global Precipitation Measurement (IMERG) Early and Final Run, the Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks - Cloud Classification System (PERSIANN_CCS), and Feng Yun-4A (FY-4A). Our model achieved superior classification metrics, with a Probability of Detection (POD) of 0.80, a Critical Success Index (CSI) of 0.54, an Equitable Threat Score (ETS) of 0.41, and a Heidke Skill Score (HSS) of 0.58. These results demonstrate significant improvements, with POD increasing by at least 23%, CSI by 10%, ETS by 8%, and HSS by 9% compared to the five analyzed rainfall products. These findings provide a foundation for real-time rainfall estimation in regions with complex terrain and weather patterns, contributing to more accurate meteorological analysis and forecasting."
Application of Change Detection Using Machine Learning Classification Scheme in Google Earth Engine with High-Resolution Satellite Imagery,2025,"['Google Earth Engine', 'CAS500-1', 'Change detection', 'Random forest', 'Image classification']",,"The use of machine learning algorithms provided by the Google Earth Engine (GEE) platform has been increasingly adopted. This study applied the Random Forest (RF) algorithm using both Sentinel- 1/2 imagery provided by GEE and high-resolution CAS500-1 imagery to generate Land Use and Land Cover (LULC) classification maps. Based on these maps, a detailed change detection analysis was conducted between the two time points. The study area is Osong-myeon, Pyeongtaek City, Gyeonggi Province, Korea, and two satellite images from November 2022 and November 2023 were used. Three combinations of input datasets were tested for LULC classification: Sentinel-1/2, CAS500-1, and the Normalized Difference Vegetation Index (NDVI) of Sentinel-2. Classification accuracy and Kappa coefficients were reported for each case. The combination of Sentinel-1/2, CAS500-1, and NDVI was used for the change detection analysis. The results showed that 79.01% of the vegetation zone remained unchanged, while 30.10% of the bare zone originated from previously vegetated areas. Additionally, 21.66% of the forest zone in 2023 had newly converted from the bare zone compared to 2022. This study presents the feasibility of high-resolution imagery for precise LULC classification and change detection. It highlights the practical value of the GEE platform in environmental monitoring in a small area."
Enhanced classification of dissolved organic matter sources based on rivers using machine learning and data augmentation,2025,"['Data augmentation', 'Deep Learning', 'DOM', 'LSTM-GAN', 'Orbitrap MS']",,"This paper investigates the improvement in organic matter classification accuracy from different aquatic environments through the application of machine learning and deep learning techniques, supplemented with data generated by an LSTM-GAN model. Samples from the Nakdong and Yeongsan Rivers in South Korea were analyzed using Orbitrap HR-MS to obtain natural organic matter (NOM) data. Classification was performed using three machine learning algorithms—random forest, support vector machine (SVM), and logistic regression—and one deep learning algorithm, a multi-layer perceptron (MLP). Due to the limited performance of deep learning with insufficient data, an LSTM-GAN-based augmentation model was proposed, improving MLP performance. The MLP with augmented data achieved the highest classification accuracy (79% for Yeongsan River, 68% for Nakdong River), demonstrating the significant potential of LSTM-GAN in enhancing deep learning models for river classification tasks. This approach provides a robust framework for improving environmental monitoring through machine learning."
Reactor physics fast calculation method based on model order reduction and machine learning,2025,"['Model order reduction', 'Machine learning', 'Fast calculation', 'Nuclear power plant', 'TORCH']",,"The rapid development of artificial intelligence technology has provided new ideas and methods for reactor physics calculations. Based on AI technology, a fast calculation method for reactor physics has been established, which combines model order reduction and machine learning to address the challenges of excessive parameter quantities in machine learning-based parameter prediction. During the training process, the full-order model is established using the two-step core nuclear design software package TORCH, and the model order reduction theory is applied, which are then trained using the random forest machine learning method. In the prediction process, the basis weight coefficients are rapidly calculated for specific input parameters, and the core distribution results are reconstructed. A reactor physics fast calculation program has been developed and verified using a M310-type pressurized water reactor nuclear power plant with 9522 samples. All results show that the fast calculation method based on model order reduction and machine learning has good computational efficiency and accuracy. The calculation time can be reduced to 0.1 s and the proportion of samples with less than 1 % deviation in various core physics parameters is higher than 90 %."
Development of a depression risk prediction model in Korea using machine learning-based feature selection,2025,"['Depression risk factors', 'feature importance', 'machine learning', 'weighted logistic regression model.']",,"This study aims to develop a prediction model for assessing depression risk. Depression-related risk factors were identified from prior studies, and the most influential factors were selected using a feature selection method based on four machine learning techniques: random forest, XGBoost, AdaBoost, and gradient boosting. The random forest algorithm achieved the highest receiver operating characteristic (ROC) curve  (0.8407) in classifying depression among the four machine learning algorithms. The variables were derived from the Korea community health survey  (KCHS) 2022 by the Korea disease control and prevention agency  (KDCA) and used as input variables, with depression status as the target variable. A weighted logistic regression model was employed for prediction. Based on feature importance rankings from four machine learning techniques, the combined key risk factors included economic activity, monthly household income, marital status, walking habits, subjective stress perception, subjective health status, number of cultural infrastructures, unemployment rate, suicide rate, and number of doctors. In the prediction model, subjective stress perception  (OR: 9.65) was the most significant risk factor, followed by subjective health status  (OR: 3.38). The use of machine learning techniques for variable selection effectively addresses the challenge of interpretability in prediction models. This approach demonstrates great potential for future healthcare-related disease risk prediction models."
Predicting Oncological and Functional Outcomes by Nephrectomy  Type for T1 Renal Tumors Using Machine Learning Models,2025,"['Machine learning', 'Nephrectomy', 'Renal cell carcinoma', 'Recurrence']",,"Purpose: Determining the optimal surgical approach for patients with T1 renal tumors requires balancing long-term oncological and renal functional outcomes. Using machine learning algorithms, we aimed to develop a model to predict both outcomes simultaneously, according to each radical (RN) and partial nephrectomy (PN).Materials and Methods: Using demographic and preoperative variables of 823 patients with clinical T1N0M0 renal tumors who underwent PN or RN between 2007 and 2019, we employed 5 different machine learning algorithms—general linear model (GLM), extreme gradient boosting (XgBoost), gradient boosting machine, distributed random forest, deep learning—and compared to predict recurrence probability and estimated glomerular filtration rate (eGFR) at 5-year after surgery. Model performance for recurrence prediction was evaluated with area under the curve receiver operating characteristic, area under the precision-recall curve, and log-loss, while eGFR prediction was assessed using root mean square error (RMSE) and R2.Results: Of the 823 patients, 463 (56.3%) had T1a tumors and 487 (59.2%) underwent PN. The median preoperative eGFR was 99.1 mL/min/1.73 m2, and at 5 years postoperative it was 70.4 after RN and 92.0 after PN. Recurrence within 5 years was observed in 1.1% and 4.2% of T1a and T1b cohorts, respectively. We developed models based on clinically significant preoperative variables. Across the models, the XGBoost demonstrated the highest accuracy for predicting 5-year recurrence, with superior recall (0.0252) and precision (0.0465) compared to other algorithms. For 5-year eGFR prediction, the GLM outperformed other models, achieving RMSE of 12.700 and R2 of 0.694 on the test set. The 2 models were integrated into a single online interface.Conclusion: We developed a tool to reliably predict 5-year oncological and renal functional outcomes following each nephrectomy type in patients with T1 renal tumors. Further multi-institutional validation is needed to confirm its generalizability and applicability across diverse clinical settings."
Machine learning-enhanced design of lead-free halide perovskite materials using density functional theory,2025,"['Halide perovskite materials', 'Machine learning', 'Density functional theory', 'Photovoltaic application']",,"The investigation of emerging non-toxic perovskite materials has been undertaken to advance the fabrication of environmentally sustainable lead-free perovskite solar cells. This study introduces a machine learning methodology aimed at predicting innovative halide perovskite materials that hold promise for use in photovoltaic applications. The seven newly predicted materials are as follows: CsMnCl4, Rb3Mn2Cl9, Rb4MnCl6, Rb3MnCl5, RbMn2Cl7, RbMn4Cl9, and CsIn2Cl7. The predicted compounds are first screened using a machine learning approach, and their validity is subsequently verified through density functional theory calculations. CsMnCl4 is notable among them, displaying a bandgap of 1.37 eV, falling within the Shockley-Queisser limit, making it suitable for photovoltaic applications. Through the integration of machine learning and density functional theory, this study presents a methodology that is more effective and thorough for the discovery and design of materials."
Machine Learning Approach to Rapidly Evaluate Curling of Concrete Pavement,2025,"['Concrete pavement', 'Machine learning', 'Finite element', 'TETD', 'FWD']",,"This paper focuses on the methodology for evaluating the degree of total curling in concrete pavement using machine learning. Deflection induced by falling weight deflectometer (FWD) testing is known as a direct correlation to total curling including built-in and daily curling. However, deflection measurement in the in-service road is also affected by others, such as environmental conditions, pavement geometry, subgrade stiffness, and mixture design. Thus, it is challenging to determine the level of curling from FWD data due to the complexity of influencing parameters. To navigate this complexity, prominent machine learning models are exploited to identify a non-linear relationship between curling and FWD deflections. A finite-element simulation of FWD is conducted to generate a vast data set, and a robust regression model is trained to estimate the total effective temperature difference (TETD) to quantify the effects of curling. Since input parameters for testing pavements can be measurable in the field, curling from TETD can be readily obtained using the proposed methodology. Comparative simulations highlight that the proposed models, with an MAE less than 0.5 °C significantly outperform the multiple regression performance, which registers an MAE of 3.45 °C in TETD, particularly in offering cost-effective and noise-tolerant prediction."
Machine Learning-based Interactive System for Rapid LED Dissipation Test,2025,"['Heat Dissipation', 'Automobile LED Lamp Design', 'Machine Learning', 'Real-Time Interactive System', 'Thermal Analysis', 'Automotive Manufacturing']",,"Heat dissipation testing for automobile LED lamp design is a crucial step to ensuring optimal lighting performance and extending product lifespan. We propose a machine learning-based real-time interactive system for assessing heat dissipation in LED lamp designs. Unlike traditional methods that require expertise in computational fluid dynamics (CFD), our system allows designers to directly evaluate whether their designs meet thermal requirements without specialized CFD knowledge. We designed an interactive system that enables real-time adjustments of design parameters, such as the number of LED diodes or the size of the heat dissipation plate, providing immediate feedback and optimization. It significantly reduces the production cycle by streamlining the design validation process, thereby enhancing manufacturing efficiency. By enabling rapid iteration and adaptation to market trends, the system improves business competitiveness in the automotive manufacturing and parts production industry. We conducted experimental validation that confirms that our method provides accurate thermal dissipation assessments at a fraction of the computational cost of conventional approaches. These findings highlight the potential of machine learning-driven design tools in accelerating innovation in the automotive manufacturing sector."
Machine learning-based methodologies for probabilistic prediction of random seismic frame structural response,2025,"['K-means clustering', 'machine learning', 'probabilistic learning on manifolds', 'random seismic response prediction']",,"This paper proposes an innovative methodology that synergistically combines machine learning techniques with probabilistic learning on manifolds for generating samples to predict the response distribution of frame structures. Through a rigorous feature engineering process, 11 seismic feature parameters and one structural feature parameter were judiciously selected. Leveraging a small-scale dataset, an exhaustive model selection process was undertaken, evaluating the performance of Support Vector Regression, Random Forest, and Gradient Boosting Trees, ultimately identifying the optimal machine learning model. By concurrently accounting for the stochastic nature of seismic motions and structural characteristics, this methodology is employed to predict the distribution of structural responses of multi-story reinforced concrete frame structures subjected to stochastic seismic events. The results demonstrate that this methodology achieves a high degree of prediction accuracy on the test dataset and can reasonably predict the seismic damage to reinforced concrete frame structures, thereby providing valuable guidance for post-earthquake disaster assessment and emergency response efforts."
Machine Learning–Based Prognostic Gene Signature for Early Triple-Negative Breast Cancer,2025,"['Triple-negative breast cancer', 'Prognosis', 'Precision medicine', 'Machine learning']",,"Purpose This study aimed to develop a machine learning–based approach to identify prognostic gene signatures for early-stage triple-negative breast cancer (TNBC) using next-generation sequencing data from Asian populations.Materials and Methods We utilized next-generation sequencing data to analyze gene expression profiles and identify potential biomarkers. Our methodology involved integrating various machine learning techniques, including feature selection and model optimization. We employed logistic regression, Kaplan-Meier survival analysis, and receiver operating characteristic (ROC) curves to validate the identified gene signatures.Results We identified a gene signature significantly associated with relapse in TNBC patients. The predictive model demonstrated robustness and accuracy, with an area under the ROC curve of 0.9087, sensitivity of 0.8750, and specificity of 0.9231. The Kaplan-Meier survival analysis revealed a strong association between the gene signature and patient relapse, further validated by logistic regression analysis.Conclusion This study presents a novel machine learning-based prognostic tool for TNBC, offering significant implications for early detection and personalized treatment. The identified gene signature provides a promising approach for improving the management of TNBC, contributing to the advancement of precision oncology."
Preliminary approach to creation of a prediction model for diagnosis of Sjögren's syndrome using radiomics and machine learning techniques on computed tomography images of the parotid glands,2025,"['Radiomics', 'Machine Learning', 'Sjögren’s Syndrome', 'Tomography', 'X-Ray Computed']",,"Purpose: The aim of this research was to develop a prediction model for diagnosis of Sjögren’s syndrome using radiomics and machine learning techniques applied to computed tomography images of the parotid glands and to assess its efficacy by temporal validation.Materials and Methods: In total, 132 parotid glands from 66 subjects (33 patients with Sjögren’s syndrome and 33 controls) were analyzed. Radiomics features were extracted from manually segmented parotid glands using 3D Slicer. The volume data for 108 parotid glands were chronologically assigned to the training dataset, and the features extracted were imported into Prediction One (Sony Network Communications Inc, Tokyo, Japan). A prediction model was automatically generated. The area under the curve (AUC), accuracy, precision, recall, and F-value were calculated for internal validation. Temporal validation was performed using 24 images of the parotid glands obtained later.Results: A total of 129 radiomics features were extracted, including 18 first-order, 14 shape, and 75 texture features. The internal validation test showed high performance, with an AUC of 0.92, accuracy of 0.88, precision of 0.90, recall of 0.85, and an F-value of 0.88. Temporal validation testing also showed high performance, with an AUC of 0.96. accuracy of 0.88, precision of 0.85, recall of 0.92, and an F-value of 0.88.Conclusion: The prediction model effectively differentiated Sjögren’s syndrome using radiomics and machine learning. Use of Prediction One significantly streamlined the workflow, including analysis of radiomics, creation of the prediction model, and evaluation of performance, while substantially reducing the time required."
Applications of machine learning in nuclear arms control verification,2025,"['Nuclear arms control', 'Machine learning', 'Cryptographic radiation measurements', 'Monte Carlo simulation']",,"Current nuclear arms control verification methods employ various cryptographic techniques to prevent classified data leakage. Enhancing these methods’ accuracy through better data extraction from the cryptographic data is crucial. This study integrated machine learning with physical encryption, training four models for arms control verification. Additionally, we amassed a dataset encompassing most significant fraudulent scenarios via Monte Carlo simulations, representing the inaugural dataset tailored for arms control verification research. Machine learning-based arms control verification technology can automatically extract essential features from encrypted data and make real-time adjustments and optimizations based on new data, significantly enhancing the accuracy.Concurrently, by leveraging physical encryption, classified data is encrypted before electrically recording, reducing tampering and unauthorized access risks. By calculating the models’ prediction accuracy, we assessed the performance of each model. The results indicate that the K-Nearest Neighbors, Random Forest, and Support Vector Machine models all exhibited highly accuracy and robust noise resilience. And the Logistic Regression model also demonstrated reliable performance indicators. Furthermore, the exceedingly low probability of successfully decrypting the physical encryption underscores its effectiveness in safeguarding confidential data. In summary, the machine learning-based verification method demonstrates superior accuracy and enhanced efficiency while effectively preventing unauthorized data access or manipulation"
On Application of Machine Learning for Deciding Acupoints in Acupuncture and Moxibustion Treatment,2025,"['Artificial intelligence', 'Machine learning', 'Acupuncture and moxibustion', 'Traditional Chinese medicine']",,"This paper discusses a machine learning-based approach to optimize acupuncture and moxibustion treatment (AMT). The goal is to develop a model that can offer personalized acupoints prescriptions for patients based on their symptoms, enhancing both the efficiency and effectiveness of treatment. A database comprising symptoms and acupoints prescriptions for 3,000 disease cases was used, and 11 machine learning algorithms were applied to learn from this data. The training process utilized 90% of the data for 5-fold cross-validation and 10% for testing to assess generalization ability. Intersection over Union (IoU) was chosen as the key evaluation metric for the models. The Seq2seq model with attention mechanism emerged as the best-performing algorithm, achieving an IoU of 95.72% on cross-validation and 95.33% on the test set. These results suggest that using Seq2seq with attention can significantly reduce subjectivity in acupoint selection and increase the efficiency of AMT. This approach provides a promising data-driven method for improving treatment precision and saving time in clinical settings."
Leveraging GitHub Classroom and Google Colab for Short-Term Student Machine Learning Team Projects,2025,"['GitHub classroom', 'Google colab', 'Machine learning', 'Short-term team projects', 'Programming education']",,"Team projects are an essential part of many university Computer Science curriculums, particularly in the areas of Machine Learn ing and Deep Learning. Large team projects, like Capstone Projects, may be all-encompassing and very intensive, requiring at least a full semester of dedicated work, from project setup to final presentation. However, some courses may not introduce team projects until the second half of the semester, making it more difficult for student teams to establish a unified programming environment and collaborative workflow across personal devices in a shortened time span. Therefore, this paper proposes utilizing GitHub Classroom to create student team repositories for project status updates and submission, in tandem with Google Colab for GPU-dependent machine learning model training. These tools can be directly integrated with each other to provide students with a streamlined and organized workflow that requires minimal project setup and a centralized repository for all project and presentation files. Instructors also benefit from the combination of GitHub Classroom and Google Colab which enables them to spend more time on course content and less time on specific project problems. As an additional benefit, the results of this research indicate that student participation and attendance in class may improve by incorporating a student team project using these tools."
Predicting All-Cause Mortality in Patients With Obstructive Sleep Apnea Using Sleep-Related Features: A Machine-Learning Approach,2025,"['obstructive sleep apnea', 'machine learning', 'sleep stages', 'autonomic nervous system', 'mortality']",,"Background and Purpose Obstructive sleep apnea (OSA) is associated with an increased risk of adverse outcomes, including mortality. Machine-learning algorithms have shown potential in predicting clinical outcomes in patients with OSA. This study aimed to develop and evaluate a machine-learning algorithm for predicting 10- and 15-year all-cause mortality in patients with OSA.Methods Patients with OSA were stratified into deceased and alive groups based on mortality outcomes. Various sleep-related features were analyzed, including objective sleep measures and the heart-rate variability during various sleep stages. The light gradient-boosting machine (LGBM) algorithm was employed to construct a risk-stratification model. The predictive performance of the model was assessed using the area under the receiver operating characteristic curve (AUC) for predicting mortality over 10 and 15 years. Survival analysis was conducted using Kaplan–Meier plots and Cox proportional-hazards model.Results This study found that parasympathetic activity was higher in OSA patients with worse outcomes than in those with better outcomes. The LGBM-based prediction model with sleep-related features was moderately accurate, with a mean AUC of 0.806 for predicting 10- and 15-year mortality. Furthermore, survival analysis demonstrated that LGBM could significantly distinguish the high- and low-risk groups, as evidenced by Kaplan–Meier plots and Cox regression results.Conclusions This study has confirmed the potential of sleep-related feature analysis and the LGBM algorithm for evaluating the mortality risk in OSA patients. The developed risk-stratification model offers an efficient and interpretable tool for clinicians that emphasizes the significance of patient-specific autonomic responses in mortality prediction. Incorporating survival analysis further validated the robustness of the model in predicting long-term outcomes."
ChatGPT in English Learning: A Machine Learning Perspective,2025,"['인공지능(AI)', 'ChatGPT', '영어 학습', '글쓰기 피드백', '기계 학습', 'artificial intelligence (AI)', 'ChatGPT', 'English language learning', 'writing feedback', 'machine learning']",,"This study explores the transformative role of ChatGPT in education, focusing on its impact on language learning, writing support, and academic research through an analysis of English-language papers published from November 2022, when ChatGPT was developed, to 2024. Specifically, 20 research articles were selected and analyzed to examine how ChatGPT has been applied and discussed in educational contexts, with most of them published in journals indexed in Web of Science and Scopus.Using word frequency, similarity analysis, and clustering based on Principal Component Analysis (PCA) and K-means, the results highlight that ChatGPT is a multifaceted tool that enhances personalized learning experiences. The frequency analysis reveals strong associations with terms like “student,” “learning,” “education,” and “AI,” emphasizing ChatGPT’s role in supporting language acquisition, academic writing, and student engagement. The similarity analysis further demonstrates its contributions to writing, feedback, and research tasks. Clustering results identified four key areas of ChatGPT's application: AI and Technology in Education; Research and Data Utilization; Writing and Feedback; Language Learning and Education. These findings suggest that ChatGPT is a valuable resource in educational settings, though further research is needed to explore its long-term effects and ethical considerations in language learning contexts."
Unraveling the three-dimensional genome structure using machine learning,2025,"['3D genome', 'Chromatin interaction', 'Deep learning', 'Hi-C sequencing', 'Machine learning']",,"The study of chromatin interactions has advanced considerablywith technologies such as high-throughput chromosome conformationcapture (Hi-C) sequencing, providing a genome-wide viewof physical interactions within the nucleus. These techniqueshave revealed the existence of hierarchical chromatin structuressuch as compartments, topologically associating domains (TADs),and chromatin loops, which are crucial in genome organizationand regulation. However, identifying and analyzing thesestructural features require advanced computational methods.In recent years, machine learning approaches, particularly deeplearning, have emerged as powerful tools for detecting andanalyzing structural information. In this review, we present anoverview of various machine learning-based techniques for determiningchromosomal organization. Starting with the progress inpredicting interactions from DNA sequences, we describe methodsfor identifying various hierarchical structures from Hi-C data.Additionally, we present advances in enhancing the chromosomecontact frequency map resolution to overcome the limitationsof Hi-C data. Finally, we identify the remaining challenges andpropose potential solutions and future directions."
Diagnosis of invasive encapsulated follicular variant papillary thyroid carcinoma by protein-based machine learning,2025,"['Follicular pattern thyroid tumors', 'Thyroid carcinoma', 'Machine learning', 'proteomics', 'Histological diagnosis']",,"Background: Although the criteria for follicular-pattern thyroid tumors are well-established, diagnosing these lesions remains challenging in some cases. In the recent World Health Organization Classification of Endocrine and Neuroendocrine Tumors (5th edition), the invasive encapsulated follicular variant of papillary thyroid carcinoma was reclassified as its own entity. It is crucial to differentiate this variant of papillary thyroid carcinoma from low-risk follicular pattern tumors due to their shared morphological characteristics. Proteomics holds significant promise for detecting and quantifying protein biomarkers. We investigated the potential value of a protein biomarker panel defined by machine learning for identifying the invasive encapsulated follicular variant of papillary thyroid carcinoma, initially using formalin-fixed paraffin-embedded samples. Methods: We developed a supervised machine-learning model and tested its performance using proteomics data from 46 thyroid tissue samples. Results: We applied a random forest classifier utilizing five protein biomarkers (ZEB1, NUP98, C2C2L, NPAP1, and KCNJ3). This classifier achieved areas under the curve (AUCs) of 1.00 and accuracy rates of 1.00 in training samples for distinguishing the invasive encapsulated follicular variant of papillary thyroid carcinoma from non-malignant samples. Additionally, we analyzed the performance of single-protein/gene receiver operating characteristic in differentiating the invasive encapsulated follicular variant of papillary thyroid carcinoma from others within The Cancer Genome Atlas projects, which yielded an AUC >0.5. Conclusions: We demonstrated that integration of high-throughput proteomics with machine learning can effectively differentiate the invasive encapsulated follicular variant of papillary thyroid carcinoma from other follicular pattern thyroid tumors."
Evaluation of Hepatic Progenitor and Hepatocyte-Like Cell Differentiation Using Machine Learning Analysis-Assisted Surface-Enhanced Raman Spectroscopy,2025,"['Human mesenchymal stem cell', 'hepatic progenitor cell', 'hepatocyte-like cell', 'surface enhanced Raman spectroscopy', 'machine learning algorithm']",,"Technology has been developed to monitor the differentiation process of human mesenchymal stem cells (hMSCs) into hepatocyte-like cells (HLCs) and hepatic progenitor cells (HPCs). These cell lineages, differentiated from MSCs, are ethically unproblematic and are gaining attention as promising cell-based therapies for treating various liver injuries. High-sensitivity, label-free, real-time monitoring technologies integrated with artificial intelligence have been used to evaluate and optimize cell differentiation for enhancing the efficiency of cell therapy delivery. Using an Au-ZnO nanorod array-based surface-enhanced Raman scattering (SERS) sensing chip, cell differentiation from hMSCs to HPCs and HLCs was nondestructively monitored through spectral analysis of cell secretions. Principal component extraction was employed to reduce variables, followed by discriminant analysis (DA). The application of principal component–linear discriminant analysis (PC-LDA), an artificial intelligence algorithm, to spectral data enabled clear grouping of hMSCs, HPCs, and HLCs, with monitoring accuracies of 96.3%, 98.8%, and 98.8%, respectively. Spectral changes observed during the differentiation from hMSCs to HPCs and from HPCs to HLCs over several days demonstrated the effectiveness of SERS combined with machine learning algorithm analysis for differentiation monitoring. This approach enabled real-time, nondestructive observation of cell differentiation with minimal sample labeling and preprocessing, making it useful for sensing differentiation validation and stability. The machine learning- and nanostructure-based SERS evaluation system was applied to the differentiation of ethically sourced MSCs and demonstrated substantial potential for clinical applicability through the use of patient-derived samples."
The Impact of Crowdfunding Project Descriptions on Funding Success: Focusing on LDA Topic Modeling and  Machine Learning,2025,"['Crowdfunding', 'Reward-based Crowdfunding', 'Funding Success', 'Topic Modeling', 'LDA', 'Machine Learning']",,"Crowdfunding has recently been recognized as a prime example of the process economy. This funding method is becoming an important platform that replaces traditional funding approaches. However, existing research on crowdfunding success factors has focused mainly on quantitative variables such as goal amounts and fulfillment rates. The potential importance of unstructured data, particularly project description text, has been relatively overlooked. To address these limitations, this study empirically investigates how project description text impacts crowdfunding success. We employ LDA topic modeling and machine learning techniques using data from Tumblbug, a leading Korean sponsored crowdfunding platform. The analysis identified 10 major topics, including Traditional Culture, Character Goods, and Festivals & Seasonal Items. Among various machine learning algorithms, Gradient Boosting performed the best in all evaluation metrics. Adding LDA topic variables to the basic variables improved prediction performance in all categories. For example, the study observed improvements of  6% in Character Goods and 4% in publishing categories. These results suggest that crowdfunding functions as an alternative distribution channel. It provides differentiated experiences through artistic and cultural values. This study presents a novel methodology that combines text mining and machine learning. This approach enables researchers to derive customized strategies for each category, offering both academic and practical implications."
Machine-learning methods for blind characterisation of nuclear fuel assemblies,2025,"['Nuclear assemblies', 'Non-destructive analysis', 'Mathematical methods', 'Machine learning', 'Neural networks']",,"The global prevalence of uranium as fissile fuel in nuclear reactors, paired with its transmutation to plutonium inside the core in an isotopic ratio corresponding to a direct-use material in significant quantities, makes the handling of spent nuclear fuel an important and sensitive matter towards non-proliferation efforts. A fast and reliable method for characterising spent fuel is thus desirable for spent nuclear fuel reprocessing and storage facilities.We propose a non-destructive, blind and fast measure method of the quantity of spent nuclear fuel inside an assembly. By measuring photon fluency collectively for the complete assembly we determine the number of present fuel rods without the need to open the array and manually check. For this, we circle a detector set-up around the assembly and feed its measurements into a neural network for a prediction. Different specifically designed architectures based on dense and convolutional layers are trained on synthetically generated data using self-developed code on python. We arrive at the election of a convolutional network for optimal results.We achieve an exact prediction with over three sigmas of confidence (99.85% accuracy) thanks to the double detector set-up we introduce in this article, proving the prediction power of neural networks in this instance with a relatively simple measure configuration"
Machine-Learning-Based Concrete Strength Prediction Considering Effect of High-Temperature Exposure and Supplementary Cementitious Material (SCM) Content,2025,"['concrete', 'high temperature', 'supplementary cementitious material (SCM)', 'strength', 'machine learning', '콘크리트', '고온', '혼화재', '압축강도', '머신러닝 기법']",,"Exposure to high temperature such as during a fire induces physical and chemical changes in concrete, leading to a significant reduction in its compressive strength. Experimental studies for the strength of heated concrete are not only time-consuming but also limited in experimental conditions to account for a wide ranges of parameters, including concrete mix ratios. Even though there have been attempts to predict the compressive strength of concrete exposed to high temperatures using machine learning (ML) models implementing ensemble algorithms, only a few studies have evaluated the prediction performance of different ensemble models. Hence, this study aimed to suggest the most suitable ensemble ML model for predicting the compressive strength of concrete having supplementary cementitious material (SCM) exposed to high temperatures by comparing five ensemble algorithms: gradient boosting regressor (GBR), extreme gradient boosting regressor (XGBR), categorical gradient boosting (CatBoost), random forest (RF), and extra trees (ET). The results revealed that the CatBoost algorithm had the highest predictive accuracy, as measured by the coefficient of determination (R2), root mean squared error (RMSE), and mean absolute error (MAE). A feature importance analysis was also performed to identify the most influential parameters, showing that the water-to-binder ratio and heating temperature were the most significant factors. Finally, the CatBoost and ET algorithms were chosen to predict the strength of heated concrete from new input data that had not been included in the training or testing process. Among them, CatBoost exhibited the better agreement with the experimental results."
Advancing Laboratory Medicine Practice With Machine Learning: Swift yet Exact,2025,"['Artificial intelligence', 'Clinical laboratory tests', 'Laboratory medicine', 'Machine learning']",,"Machine learning (ML) is currently being widely studied and applied in data analysis and prediction in various fields, including laboratory medicine. To comprehensively evaluate the application of ML in laboratory medicine, we reviewed the literature on ML applications in laboratory medicine published between February 2014 and March 2024. A PubMed search using a search string yielded 779 articles on the topic, among which 144 articles were selected for this review. These articles were analyzed to extract and categorize related fields within laboratory medicine, research objectives, specimen types, data types, ML models, evaluation metrics, and sample sizes. Sankey diagrams and pie charts were used to illustrate the relationships between categories and the proportions within each category. We found that most studies involving the application of ML in laboratory medicine were designed to improve efficiency through automation or expand the roles of clinical laboratories. The most common ML models used are convolutional neural networks, multilayer perceptrons, and tree-based models, which are primarily selected based on the type of input data. Our findings suggest that, as the technology evolves, ML will rise in prominence in laboratory medicine as a tool for expanding research activities. Nonetheless, expertise in ML applications should be improved to effectively utilize this technology."
Machine Learning-Based Fake Account Detection System: Instagram Case Study,2025,"['Fake account detection', 'Machine learning', 'Single and ensemble models', 'Social media']",,
Prediction and classification of gamma passing rate for patient-specific quality assurance using machine learning models based on radiomics features and beam parameters,2025,"['Machine learning', 'Radiomics', 'Gamma passing rate', 'Intensity modulated radiation therapy', 'Quality assurance']",,"The aim of this work is to predict and classify the gamma passing rate (GPR) values for intensity-modulated radiation therapy plans at the pelvis site utilizing radiomics features and beam features combined with machine learning. Dosimetric verification of 486 fields was performed using the portal dosimetry system. Three types of models were constructed using support vector machines: radiomics models based on radiomics features derived from fluence images, beam models based on beam parameters related to dose delivery accuracy, and hybrid models that integrated both feature sets. For the radiomics, beam, and hybrid models, the mean absolute errors in the test set were 1.62 %, 1.61 %, and 1.45 % at the 2 %/2 mm criterion, and 1.09 %, 1.18 %, and 1.02 % at the 3 %/2 mm criterion, respectively. Similarly, for classification models, the area under the curve values were 0.80, 0.76, and 0.83 for 2 %/2 mm, and 0.79, 0.74, and 0.82 for 3 %/2 mm, respectively. Moreover, radiomics features, particularly the first-order statistics, contributed more significantly than beam features in hybrid models. In conclusion, both radiomics and beam features showed promising value in predicting and classifying the GPR, while the hybrid models achieved the best performance, potentially improving plan quality and reducing quality assurance workload."
Machine Learning-Based Heading Date QTL Detection in Rice,2025,"['Machine learning', 'QTL', 'Rice', 'Heading date']",,"Abstract Quantitative trait locus (QTL) analysis is a powerful approach for identifying variantsassociated with the phenotypic variation of complex traits. However, selecting optimalmethods and pre-processing steps require considerable time and effort. In this study,we demonstrated applicability and replicability of machine learning (ML) models in QTLanalysis by evaluating their performance in comparison with conventional QTL analysismethods using 142 recombinant inbred lines derived from two japonica rice cultivars,Koshihikari and Baegilmi. Random forest and gradient boosting models showed the highestpredictive accuracy, and consistently identified three QTLs associated with headingdate: qDTH3, qDTH6, and qDTH7. Moreover, ML-based QTL analysis detected minor-effectqDTH10, where Koshihikari allele promoted heading date when combined withKoshihikari alleles of qDTH6 and qDTH7. These results demonstrate the applicability of MLmodels in QTL analysis on bi-parental mapping population in rice."
Machine Learning Models to Identify Individuals With Imminent Suicide Risk Using a Wearable Device: A Pilot Study,2025,"['Suicide', 'Depression', 'Daily mood monitoring', 'Imminent suicide risk', 'Wearable device', 'Risk monitoring']",,"Objective We aimed to determine whether individuals at immediate risk of suicide could be identified using data from a commercially available wearable device.Methods Thirty-nine participants experiencing acute depressive episodes and 20 age- and sex-matched healthy controls wore a commercially available wearable device (Galaxy Watch Active2) for two months. We collected data on activities, sleep, and physiological metrics like heart rate and heart rate variability using the wearable device. Participants rated their mood spontaneously twice daily on a Likert scale displayed on the device. Mood ratings by clinicians were performed at weeks 0, 2, 4, and 8. The suicide risk was assessed using the Hamilton Depression Rating Scale’s suicide item score (HAMD-3). We developed two predictive models using machine learning: a single-level model that processed all data simultaneously to identify those at immediate suicide risk (HAMD-3 scores ≥1) and a multi-level model. We compared the predictions of imminent suicide risk from both models.Results Both the single-step and multi-step models effectively predicted imminent suicide risk. The multi-step model outperformed the single-step model in predicting imminent suicide risk with area under the curve scores of 0.89 compared to 0.88. In the multi-step model, the HAMD total score and heart rate variability were most significant, whereas in the single-step model, the HAMD total score and diagnosis were key predictors.Conclusion Wearable devices are a promising tool for identifying individuals at immediate risk of suicide. Future research with more refined temporal resolution is recommended."
Machine Learning-Based Computed Tomography-Derived Fractional Flow Reserve Predicts Need for Coronary Revascularisation Prior to Transcatheter Aortic Valve Implantation,2025,"['Aortic valve stenosis', 'Coronary artery disease', 'Coronary stenosis', 'Transcatheter aortic valve replacement', 'Fractional flow reserve', 'myocardial.']",,"Objective:Patients with severe symptomatic aortic stenosis are assessed for coronary artery disease (CAD) prior to transcatheter aortic valve implantation (TAVI) with treatment implications. Invasive coronary angiography (ICA) is the recommended modality but is associated with peri-procedural complications. Integrating machine learning (ML)-based computed tomography-derived fractional flow reserve (CT-FFR) into existing TAVI-planning CT protocol may aid exclusion of significant CAD and thus avoiding ICA in selected patients.Materials and Methods: A single-center, retrospective study was conducted, 41 TAVI candidates with both TAVI-planning CT and ICA performed were analyzed. CT datasets were evaluated by a ML-based CT-FFR software. Beta-blocker and nitroglycerin were not administered in these patients. The primary outcome was to identify significant CAD. The diagnostic performance of CT-FFR was compared against ICA.Results:On per-patient level, the sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV) and diagnostic accuracy were 89%, 94%, 80%, 97% and 93%, respectively. On per-vessel level, the sensitivity, specificity, PPV, NPV and diagnostic accuracy were 75%, 94%, 67%, 96% and 92%, respectively. The area under the receiver operative characteristics curve per individual coronary vessels yielded overall 0.90 (95% confidence interval 85%–95%). ICA may be avoided in up to 80% of patients if CT-FFR results were negative.Conclusion:ML-based CT-FFR can provide accurate screening capabilities for significant CAD thus avoiding ICA. Its integration to existing TAVI-planning CT is feasible with the potential of improving the safety and efficiency of pre-TAVI CAD assessment."
Machine learning-based optimal value calculation for welding variables in AR training,2025,"['Highly skilled welders', 'Tacit knowledge', 'FCAW', 'Welding AR training system', 'Machine learning', 'Extra trees regressor']",,"Currently, the shipbuilding industry is experiencing a surge in orders due to the rising demand for eco-friendly ships, necessitating the optimal use of available resources for production. However, the production workforce has not fully recovered to the level required to meet these increased orders following large-scale industry restructuring. In particular, there is a shortage of highly skilled welders, and concerns are growing about the transfer of expertise due to an aging workforce and a lack of younger workers. Shipbuilders worldwide face similar challenges and are exploring various methods to transfer the tacit knowledge of skilled welders to less experienced workers, which has introduced unforeseen challenges. In this study, we develop a machine learning algorithm that suggests the optimal values of key welding variables for an AR-based welding training system designed to assist less skilled workers. We collected welding data from highly skilled workers using the FCAW (Flux-Cored Arc Welding) technique, which is commonly employed in the shipbuilding process. The welding variables that represent tacit knowledge were identified and trained using the Extra Trees Regressor model.Subsequently, a welding AR training system was implemented, allowing the trained model to guide users on the optimal values for welding variables. Finally, the effectiveness of this system in training welders was verified at a shipyard technical training center."
Evaluating the Performance of Machine Learning Models  under the Generalized Linear Model Framework,2025,"['Explanatory variables', 'Generalized linear models', 'Machine learning models', 'Sample size']",,"Machine learning (ML) models are widely used in big data analysis. In particular, boosting algorithms have demonstrated the potential to achieve a predictive performance comparable to that of traditional statistical models through iterative learning. However, a notable limitation of the ML models is that their performance is limited by small sample sizes or insufficient explanatory variables. In this study, we investigated the variations in the predictive performance of ML models with different sample sizes and numbers of explanatory variables within the framework of a generalized linear model. The simulation study demonstrated that the prediction performance of the ML models improved as both the sample size and the number of explanatory variables increased. These results were also observed in the analysis of real-world datasets."
Machine Learning-Driven Electrochemical Aptasensing Platform for Highly Accurate Prediction of Phthalate Concentration in Multiple River Sites,2025,['Di(2-ethylhexyl) phthalate (DEHP) · Electrochemical aptasensor · Hybrid phthalate boosting (PLBoost) · Conventional generative adversarial network (cGAN)'],,"DEHP (di(2-ethylhexyl) phthalate), a widely used plasticizer, contaminates water through plastic waste leaching, posing severe health risks including growth delays and cardiovascular disease. Herein, we employed electrochemical aptasensors to analyze DEHP concentrations at the upper, mid, and lower layers of 3 sites across South Korean rivers. However, the solely sensor application faced challenges to classify and predict DEHP due to signal drift, biofouling, and limited specificity, especially with pH variations. Given these concerns, a machine learning (ML)-powered approach was applied, including a Conventional Generative Adversarial Network (cGAN) model for data augmentation and a hybrid Phthalate Boosting (PLBoost) algorithm for a robust multi-layer concentration analysis. The ML-powered electrochemical aptasensing platform significantly improved the DEHP prediction accuracy (97.11%) compared to those of the Liquid–liquid extraction/gas chro-matography/mass spectrometry (LLE-GC–MS) measurement, minimizing the fluctuating conditions. Thus, an integration of the PLBoost with electrochemical aptasensors provides a robust DEHP monitoring platform in water samples."
Machine Learning-based Malware Detection and Malicious URL Classification System for Detecting Cyberattacks and Achieving Cybersecurity,2025,"['Cyberattack', 'Malware detection', 'Machine learning', 'Random forest', 'Decision tree', 'Support vector machine', 'Logistic regression']",,"Owing to progress in the usage of Internet-based applications, cybersecurity has becomemore important in various fields, such as education, government, and finance, as the risk ofcyberattacks against networks has evolved. In this paper, we present a novel approach todeveloping an effective system that both detects malware and classifies URLs. We developedmachine learning (ML)-driven malware detection techniques for the proposed system usingportable executable (PE) header data. In our system, we employ decision trees and randomforest models for malware detection, in which the chosen features are trained and tested toachieve high accuracy. The classifier that yields the highest classification accuracy is retainedfor use when new information needs to be classified. We applied strategies such as featureengineering, hyperparameter tuning, and the use of a confusion matrix heatmap for modeloptimization and enhancement. In addition, we adopted random forest, support vector machine(SVM), and logistic regression classifiers in our system. Our main objective was to obtainbroad and accurate classifications of URLs. Using the accuracy, precision, recall, and f1-score,we evaluated the performance of our proposed system. Among the tested models, the randomforest model yielded the highest accuracy of 99.98% for malware detection and 90.59% formalicious URL detection. The simulation results and comparison with other state-of-the-artapproaches demonstrate that our system is robust in detecting cyberattacks and achievingcybersecurity."
Machine Learning Prediction of Attachment Type From Bio-Psychological Factors in Patients With Depression,2025,"['Object attachment', 'Machine learning', 'Depressive disorder', 'Early life stress', 'Autonomic nervous system.']",,"Objective Adult attachment style is linked to how an individual responds to threats or stress and is known to be related to the onset of psychiatric symptoms such as depression. However, as the current assessment of attachment type mainly relies on self-report questionnaires and can be prone to bias, there is a need to incorporate physiological factors along with psychological symptoms and history in this process. We aimed to predict the measurement of two important types of adult attachment with heart rate variability (HRV), early life stress experience, and subjective psychiatric symptoms.Methods Five hundred eighty-two subjects with depressive disorder were recruited retrospectively from January 2015 to June 2021. The experience of early life stress and psychiatric symptoms were collected, and HRV measures were obtained as input for an ensembled Voting Regressor model of machine learning-based regression models, including linear regression, ElasticNet, Support Vector Machine (SVM), Random Forest, and Extreme Gradient Boosting (XGBoost).Results Model performances evaluated with R-squared score averaged across 30 seeds were 0.377 and 0.188 for anxious- and avoidant-attachment, respectively. Mean absolute error averaged to 13.251 and 12.083, respectively. Shapley value importance analysis indicated that for both attachment types, the most important feature was the trait-anxiety, followed by emotional abuse, state-anxiety or self-reported depressive symptoms, and fear or helplessness felt in the moment of an early life stressor.Conclusion Our results provide the evidence base that may be utilized in clinical settings to predict the degree of attachment type using bio-psychological factors."
Explainable machine-learning tools for predictive maintenance of circulating water systems in nuclear power plants,2025,"['Predictive maintenance', 'eXplainable Artificial Intelligence (XAI)', 'Circulating water system']",,"Predictive maintenance (PdM) is one of the strategies that has shown great potentials in achieving substantial cost savings and enhancing the economic competitiveness of nuclear power plants in the current energy market.PdM strategy taking advantage of advancements in machine learning (ML) technologies have demonstrated ability in handling high dimensional and multivariate data and in extracting hidden relationships within data in industrial environments. While ML technologies show great potentials, their lack of explainability, especially in considering multiple aspects in human-scale explanation-giving tasks, is one of the major hurdles to their adoptions. The research presented in this paper develops an explainable ML solutions by accounting for four attributes of explainable artificial intelligence, including the contextual factors, explainable model options, post-hoc explanations for black-box models using Shapley additive explanations and local interpretable modelagnostic explanations, and graphical user interface for human cognitive capacity and limitations. This tool is then applied to the conducting of PdM tasks for a circulating water system in a nuclear power plant."
A Machine Learning Risk Prediction Model for Gastric Cancer with SHapley Additive exPlanations,2025,"['Stomach neoplasms', 'Prediction model', 'Machine learning', 'SHapley Additive exPlanations']",,"Purpose Gastric cancer (GC) prediction models hold potential for enhancing early detection by enabling the identification of high-risk individuals, facilitating personalized risk-based screening, and optimizing the allocation of healthcare resources.Materials and Methods In this study, we developed a machine learning-based GC prediction model utilizing data from the Korean National Health Insurance Service, encompassing 10,515,949 adults who had not been diagnosed with GC and underwent GC screening during 2013-2014, with a follow-up period of 5 years. The cohort was divided into training and test datasets at an 8:2 ratio, and class imbalance was mitigated through random oversampling.Results Among various models, logistic regression demonstrated the highest predictive performance, with an area under the receiver operating characteristic curve (AUC) of 0.708, which was consistent with the AUC obtained in external validation (0.669). Importantly, the outcomes were robust to missing data imputation and variable selection. The SHapley Additive exPlanations (SHAP) algorithm enhanced the explainability of the model, identifying advancing age, being male, Helicobacter pylori infection, current smoking, and a family history of GC as key predictors of elevated risk.Conclusion This predictive model could significantly contribute to the early identification of individuals at elevated risk for GC, thereby enabling the implementation of targeted preventive strategies. Furthermore, the integration of noninvasive and cost-effective predictors enhances the clinical utility of the model, supporting its potential application in routine healthcare settings."
Metaverse meets distributed machine learning: A contemporary review on the development with privacy-preserving concerns,2025,['Mobile metaversePrivacy preservationDistributed machine learningVirtual reality'],,"Distributed machine learning utilization in the metaverse exposes many potential benefits. However, the combination of these advanced technologies raises significant privacy concerns due to the potential exploitation of sensitive user and system data. This paper provides a systematic investigation of over 100 recent studies across key academic databases obtained by initial keyword-filter screening followed by a thorough full-text review. Particularly, metaverse evolution and enabling infrastructure technologies are briefly summarized. Subsequently, the distributed learning architectures and their features are analyzed as well as possibly associated vulnerability discussions. Then, envisioned metaverse applications and future research challenges are highlighted before concluding remarks."
Correspondence to letter to the editor 1 on “Conventional and machine learning-based risk scores for patients with early-stage hepatocellular carcinoma”,2025,"['HCC', 'Prognosis', 'Machine learning']",,
Deciphering the role of nicotinamide metabolism and melanin-related genes in acute myocardial infarction: a machine learning approach integrating bioinformatics analysis,2025,"['Biomarkers', 'Coronary embolism', 'Machine learning', 'Myocardial infarction', 'Nicotinamide']",,"Acute myocardial infarction (AMI) represents a significant global mortality factor. Alterations in nicotinamide metabolism within the myocardium post-AMI can influence the progression of the condition. Additionally, melanin plays a crucial role in nicotinamide metabolism and exhibits anti-inflammatory properties. Nevertheless, the diagnostic biomarkers for AMI that are based on nicotinamide metabolism and melanin-associated genes remain poorly defined. In this study, the AMI transcriptomic data from the Gene Expression Omnibus were analyzed to identify differentially expressed genes (DEGs) intersecting with nicotinamide metabolism and melatonin-related genes. Machine learning algorithms, including RandomForest, least absolute shrinkage and selection operator, and support vector machine-recursive feature elimination, were applied to select feature genes. Diagnostic markers were further evaluated based on area under the curve from receiver operating characteristic analysis. We identified 14 candidate genes, refined to 4 key genes, with NAMPT and BST1 ultimately selected as diagnostic biomarkers. These were used to classify AMI into two molecular subtypes. Immune landscape analysis revealed increased infiltration of monocytes, neutrophils, macrophages, and parainflammation in AMI. Enrichment analyses showed DEGs were mainly involved in innate immune response and cytokine production. Additionally, hsa-miR-34a-5p and hsa-miR-181b-5p were identified as potential regulators of NAMPT and BST1. In summary, NAMPT and BST1 are promising diagnostic biomarkers associated with nicotinamide metabolism and melatonin in AMI. The molecular subtyping based on these genes will enhance the management and hierarchical treatment of AMI, offering significant implications for clinical diagnosis and therapeutic strategies."
Fibrosis-4plus score: a novel machine learning-based tool for screening high-risk varices in compensated cirrhosis (CHESS2004): an international multicenter study,2025,"['Esophageal and gastric varices', 'Machine learning', 'Diagnostic model', 'Elasticity imaging techniques']",,"Background/Aims: A large percentage of patients undergoing esophagogastroduodenoscopy (EGD) screening do not have esophageal varices (EV) or have only small EV. We evaluated a large, international, multicenter cohort to develop a novel score, termed FIB-4plus, by combining the fibrosis-4 (FIB-4) score, liver stiffness measurement (LSM), and spleen stiffness measurement (SSM) to identify high-risk EV (HRV) in compensated cirrhosis.Methods: This international cohort study involved patients with compensated cirrhosis from 17 Chinese hospitals and one Croatian institution (NCT04546360). Two-dimensional shear wave elastography-derived LSM and SSM values, and components of the FIB-4 score (i.e., age, aspartate aminotransferase, alanine aminotransferase, and platelet count [PLT]) were combined using machine learning algorithms (logistic regression [LR] and extreme gradient boosting [XGBoost]) to develop the LR-FIB-4plus and XGBoost-FIB-4plus models, respectively. Shapley Additive exPlanations method was used to interpret the model predictions.Results: We analyzed data from 502 patients with compensated cirrhosis who underwent EGD screening. The XGBoost-FIB-4plus score demonstrated superior predictive performance for HRV, with an area under the receiver operating characteristic curve (AUROC) of 0.927 (95% confidence interval [CI] 0.897–0.957) in the training cohort (n=268), and 0.919 (95% CI 0.843–0.995) and 0.902 (95% CI 0.820–0.984) in the first (n=118) and second (n=82) external validation cohorts, respectively. Additionally, the XGBoost-FIB-4plus score exhibited high AUROC values for predicting EV across all cohorts. The FIB-4plus score outperformed the individual parameters (LSM, SSM, PLT, and FIB-4).Conclusions: The FIB-4plus score effectively predicted EV and HRV in patients with compensated cirrhosis, providing clinicians with a valuable tool for optimizing patient management and outcomes."
Comparative Evaluation of Pre-Test Probability Models for Coronary Artery Disease with Assessment of a New Machine Learning-Based Model,2025,"['Coronary artery disease', 'machine learning-based model', 'probability']",,"Purpose: This study aimed to validate pivotal pre-test probability (PTP)-coronary artery disease (CAD) models (CAD consortium model and IJC-CAD model).Materials and Methods: Traditional PTP models-CAD consortium models: two traditional PTP models were used under the CAD consortium framework, namely CAD1 and CAD2. Machine learning (ML)-based PTP models: two ML-based PTP models were derived from CAD1 and CAD2, and used to enhance predictive capabilities [ML-CAD2 and ML-IJC (IJC-CAD)]. The primary endpoint was obstructive CAD. The performance evaluation of these PTP models was conducted using receiver-operating characteristic analysis.Results: The study included 238 participants, among whom 157 individuals (65.9% of the total sample) had CAD. The IJC-CAD model demonstrated the highest performance with an area under the curve (AUC) of 0.860 [95% confidence interval (CI): 0.812–0.909]. Following this, the ML-CAD2 model exhibited an AUC of 0.814 (95% CI: 0.758–0.870), CAD1 showed an AUC of 0.767 (95% CI: 0.705–0.830), and CAD2 had an AUC of 0.785 (95% CI: 0.726–0.845). Each of the PTP models was adjusted to have a CAD score cutoff that classified cases with a sensitivity of over 95%. The respective cutoff values were as follows: CAD1 and CAD2 >12, MLCAD2 >0.380, and IJC-CAD >0.367. All PTP models achieved a CAD sensitivity of over 95%. Similar to the AUC performance, the accuracy of the PTP models was highest for IJC-CAD, reaching 80.3%. The accuracy of ML-CAD2 was 77.7%, while that for CAD1 and CAD2 was 74.8% and 75.2%, respectively.Conclusion: ML-CAD2 and IJC-CAD showed superior performance compared to traditional existing models (CAD1 and CAD2)."
Comparative Study on the Robustness against Gyroscope Bias of Rule-based and Machine-Learning-based Attitude Estimation Approaches,2025,"['Attitude estimation', 'Gyroscope bias', 'Rule-based algorithm', 'Machine learning', 'Robustness']",,"Attitude estimation based on a six-axis inertial measurement unit (IMU) consisting of an accelerometer and a gyroscopeis a fundamental technology utilized in various applications. Accordingly, IMU-based attitude estimation methods have beenwidely studied using rule-based algorithms and machine learning (ML) techniques. Among the factors contributing to estimationerrors, the bias inherent in the gyroscope signals is particularly significant. Although numerous studies have focused on bias compensationmethods, studies on the robustness of attitude estimation methods against gyroscope biases of various magnitudes arescarce. Therefore, this study aimed to compare and analyze the robustness of rule-based and ML-based attitude estimation methodsagainst different magnitudes of gyroscopic bias. In this study, higher robustness was defined as lower performance degradation. Thebias compensation mechanism exhibited outstanding performance in compensating for constant biases, leading to a substantial differencein the estimation performance of rule-based algorithms depending on the presence of bias compensation. In addition, biasaugmentation did not enhance the robustness of ML-based methods. Finally, rule-based algorithms incorporating bias compensationmechanisms exhibited superior robustness against biases compared with ML-based methods."
Accurate estimation of polyethylene glycol density via machine‐learning based techniques,2025,"['intelligent modeling', 'leverage technique', 'PEG density', 'sensitivity analysis']",,"Polyethylene glycol (PEG) has been globally recognized as an environmentallyfriendly chemical solvent used in many disciplines for various purposes. In this work, intelligent models are constructed based upon least squares support vector machine (LSSVM) and adaptive neuro-fuzzy inference system (ANFIS) methodologies optimized with either genetic algorithm (GA), coupled simulated annealing (CSA) or particle swarm optimization (PSO) to estimate PEG density in terms of PEG molecular weight, temperature, and pressure based upon data gathered from experimental works delineated in the published literature.Leverage method is performed on the acquired dataset to explore it in terms of outlier datapoints, and relevancy factor is used to perform sensitivity analysis.Graphical and statistical indexes are used to evaluate the authenticity of the developed models. The results show that nearly all intelligent models are accurate, with LSSVM-CSA being the most accurate model, which outperforms the modified Tait equation as outlined by the calculated mean square error, average absolute relative error, and R-squared values. In addition, the performed sensitivity analysis indicates that temperature is the most effective input variable with an indirect relationship. The developed intelligent models, particularly the LSSVM-CSA model, are highly capable of predicting PEG density without needing experimental approaches that are known to be arduous and laborious."
Prospect of Deriving Galaxy Properties through Machine Learning: Application to Medium-Band Data from the 7DT,2025,"['galaxies: photometry', 'methods: statistical']",,"Galaxy evolution studies require the measurement of the physical properties of galaxies at different redshifts. In this work, we build supervised machine learning models to predict the redshift and physical properties (gas-phase metallicity, stellar mass, and star formation rate) of star-forming galaxies from the broad-band and medium-band photometry covering optical to near-infrared wavelengths, and present an evaluation of the model performance. Using 55 magnitudes and colors as input features, the optimized model can predict the galaxy redshift with an accuracy of σ<sub>(Δ<i>z</i>/1+<i>z</i>)</sub> = 0.008 for a redshift range of <i>z</i> < 0.4. The gas-phase metallicity [12+log(O/H)], stellar mass [log(<i>M</i><sub>star</sub>)], and star formation rate [log(SFR)] can be predicted with the accuracies of σ<sub>NMAD</sub> = 0.081, 0.068, and 0.19 dex, respectively. When magnitude errors are included, the scatter in the predicted values increases, and the range of predicted values decreases, leading to biased predictions. Near-infrared magnitudes and colors (<i>H</i>, <i>K</i>, and <i>H</i>–<i>K</i>), along with optical colors in the blue wavelengths (m425–m450), are found to play important roles in the parameter prediction. Additionally, the number of input features is critical for ensuring good performance of the machine learning model. These results align with the underlying scaling relations between physical parameters for star-forming galaxies, demonstrating the potential of using medium-band surveys to study galaxy scaling relations with large sample of galaxies."
Plasma metabolite based clustering of breast cancer survivors and identification of dietary and health related characteristics: an application of unsupervised machine learning,2025,"['Breast cancer', 'East Asian people', 'metabolome', 'machine learning']",,"BACKGROUND/OBJECTIVES: This study aimed to use plasma metabolites to identify clusters of breast cancer survivors and to compare their dietary characteristics and health-related factors across the clusters using unsupervised machine learning.SUBJECTS/METHODS: A total of 419 breast cancer survivors were included in this cross- sectional study. We considered 30 plasma metabolites, quantified by high-throughput nuclear magnetic resonance metabolomics. Clusters were obtained based on metabolites using 4 different unsupervised clustering methods: k-means (KM), partitioning around medoids (PAM), self-organizing maps (SOM), and hierarchical agglomerative clustering (HAC). The t-test, χ test, and Fisher’s exact test were used to compare sociodemographic, lifestyle, clinical, and dietary characteristics across the clusters. P-values were adjusted through a false discovery rate (FDR).RESULTS: Two clusters were identified using the 4 methods. Participants in cluster 2 had lower concentrations of apolipoprotein A1 and large high-density lipoprotein (HDL) particles and smaller HDL particle sizes, but higher concentrations of chylomicrons and extremely large very-low-density-lipoprotein (VLDL) particles and glycoprotein acetyls, a higher ratio of monounsaturated fatty acids to total fatty acids, and larger VLDL particle sizes compared with cluster 1. Body mass index was significantly higher in cluster 2 compared with cluster 1 (FDR adjusted-PKM < 0.001; PPAM = 0.001; PSOM < 0.001; and PHAC = 0.043).CONCLUSION: The breast cancer survivors clustered on the basis of plasma metabolites had distinct characteristics. Further prospective studies are needed to investigate the associations between metabolites, obesity, dietary factors, and breast cancer prognosis."
Domain wall velocity prediction in magnetic nano stripe under spin-polarized current using machine learning techniques,2025,['Domain wall dynamics · Magnetic nano stripe · Sinc current pulse · Echo State Network · Long short-term memory · N-BEATS'],,"High domain wall velocity in magnetic nano stripe is a topic of interest in developing more sophisticated devices for neu romorphic computing and storage. A micromagnetic simulation is an excellent tool for investigating spin dynamics and calculating domain wall velocity, but this process is very time-consuming. So, a computational model has been developed to predict the spin dynamics. The domain wall velocity at different current densities has been generated from the time domain data obtained from the micromagnetic simulation. This data is used to train various machine-learning models. We have explored the Echo State Network (ESN), Long Short-Term Memory (LSTM) model, Seasonal Autoregressive Integrated Moving Average with Exogenous Factor (SARIMAX), and Neural Basis Expansion Analysis Time Series (N-BEATS) forecasting model to predict the domain wall velocity from the post-processed sequence data. We found that Echo State Network outperforms all other models in a small dataset. Echo State Network models achieve a lower Normalized Root Mean Squared Error (NRMSE) of 0.785 and Mean Absolute Percentage Error (MAPE) of 0.083 than the other three models.From the present work, we concluded that ESN is a suitable computational model for predicting the domain wall velocity that follows non-linear spin dynamics."
Advancing building management with nano-enhanced carbon materials: a machine learning-driven business and economic analysis,2025,['Carbon aerogels Energy efficiency Roofing applications Deep neural networks Lifecycle cost analysis Sustainable building practices'],,"Carbon aerogels including graphite and graphene have unique properties such as lightweight, strong, and insulative to roofing applications. Carbon aerogels offer innovative solutions in building management by enhancing thermal and acoustic insulation while reducing structural weight, aligning with the focus on economic and business analysis driven by machine learning. Traditional building materials often fail to meet contemporary energy efficiency and sustainability demands, underscoring the necessity for more advanced solutions. This project is dedicated to integrating carbon aerogels into roofing systems and employs Deep Neural Networks (DNNs) to optimize their performance and integration. The novelty of this study lies in its application of carbon aerogel technology—a cutting-edge, lightweight, and highly insulative material—specifically within roofing to analyze the practical evaluation of carbon aerogels’ thermal properties and economic viability in the construction industry. This study aims to rigorously assess carbon aerogels’ performance and financial impact on roofing applications. By conducting the thermal guard test and economic lifecycle evaluation, the study seeks to validate carbon aerogels’ enhanced energy efficiency and cost-effectiveness compared to traditional roofing materials. The study demonstrates that carbon aerogels offer superior thermal insulation in roofing applications, with a thermal conductivity of 0.02 W/m·K, significantly outperforming traditional materials. Economically, the high initial cost of carbon aerogels is effectively offset by substantial energy savings, estimated at $300 annually per square meter, resulting in a payback period of approximately 1.05 years. These findings are supported by rigorous testing and optimization through DNN, highlighting the material’s potential to enhance energy efficiency and sustainability in building practices."
Can the MD&A Tone of Listed Firms’ Annual Reports Predict Their Future Performance? Empirical Evidence Based on Machine Learning Text Analysis,2025,"['Analyst following', 'Future company performance', 'Internal control quality', 'Institu tional investors', 'MD&A tone']",,"Based on a sample of listed companies in China's A‐share market between 2009 and 2019, we analyze the tone of the Management's Discussion and Analysis (MD&A) section of 15 743 annual reports through machine learning. The MD&A tone displays a significantly positive association with the firm's future financial performance, proving that the textual tone of MD&A includes forward‐looking aspects regarding management's intentions for the company's prospects, and investors can use it to forecast the firm's future performance. Additionally, higher levels of internal control quality, stronger analyst following, and higher holdings by institutional investors can enhance the correlation between the MD&A tone and the company's future performance."
Less Is More: Machine Learning-Based Shortened Sleep Questionnaires for Efficient Clinical Practice,2025,['.'],,.
Development of a Machine Learning-Powered Optimized Lung Allocation System for Maximum Benefits in Lung Transplantation: A Korean National Data,2025,"['Lung Allocation System', 'Lung Transplantation', 'Mortality', 'Waitlist Mortality', 'Transplant Benefit']",,"Background: An ideal lung allocation system should reduce waiting list deaths, improve transplant survival, and ensure equitable organ allocation. This study aimed to develop a novel lung allocation score (LAS) system, the MaxBenefit LAS, to maximize transplant benefits.Methods: This study retrospectively analyzed data from the Korean Network for Organ Sharing database, including 1,599 lung transplant candidates between September 2009 and December 2020. We developed the MaxBenefit LAS, combining a waitlist mortality model and a post-transplant survival model using elastic-net Cox regression, was assessed using area under the curve (AUC) values and Uno’s C-index. Its performance was compared to the US LAS in an independent cohort.Results: The waitlist mortality model showed strong predictive performance with AUC values of 0.834 and 0.818 in the training and validation cohorts, respectively. The post-transplant survival model also demonstrated good predictive ability (AUC: 0.708 and 0.685). The MaxBenefit LAS effectively stratified patients by risk, with higher scores correlating with increased waitlist mortality and decreased post-transplant mortality. The MaxBenefit LAS outperformed the conventional LAS in predicting waitlist death and identifying candidates with higher transplant benefits.Conclusion: The MaxBenefit LAS offers a promising approach to optimizing lung allocation by balancing the urgency of candidates with their likelihood of survival post-transplant. This novel system has the potential to improve outcomes for lung transplant recipients and reduce waitlist mortality, providing a more equitable allocation of donor lungs."
Correspondence to letter to the editor 2 on “Conventional and machine learning-based risk scores for patients with early-stage hepatocellular carcinoma”,2025,"['Hepatocellular carcinoma', 'Risk score', 'Prognosis']",,
Identification of telomere-related diagnostic markers in osteoarthritis based on bioinformatics analysis and machine learning,2025,"['Biomarkers', 'Immune system', 'Osteoarthritis', 'Telomere shortening']",,"Osteoarthritis (OA) is one of the most prevalent joint disorders, with aging considered a primary, irreversible factor contributing to its progression. Telomere-related cellular senescence may be a crucial factor influencing the OA process, yet biomarkers for OA based on telomere-related genes have not been clearly identified. The datasets GSE51588, GSE12021, and GSE55457 were retrieved from the Gene Expression Omnibus database. Initially, R software was utilized to identify differentially expressed genes between OA and normal samples. Subsequently, differentially expressed telomere-related genes (DETMRGs) were obtained, and their functional enrichment was analyzed. Feature genes for OA diagnosis were selected from DETMRGs using a combination of least absolute shrinkage and selection operator, support vector machine-recursive feature elimination, and Random Forest algorithms. The diagnostic value of these feature genes was then validated through receiver operating characteristic (ROC) curves and decision curve analysis. Additionally, CIBERSORT and xCell were employed to assess the infiltration of immune cells in OA tissues. Finally, potential drugs targeting candidate genes were predicted. Three telomere-related genes, PGD, SLC7A5, and TKT, have been identified as biomarkers for OA diagnosis and were confirmed through ROC diagnostic tests. The immune infiltration of mast cells, neutrophils, common lymphoid precursors, and eosinophils associated with PGD, SLC7A5, and TKT was reduced. Recognizing telomere-related genes PGD, SLC7A5, and TKT as potential diagnostic biomarkers for OA is significant, as it offers valuable insights into the role of telomere-related genes in OA. This discovery also provides valuable information for the diagnosis and treatment of OA."
"Fairness Measure, Bias Mitigation Techniques and Verification Tools in Machine Learning: A Survey",2025,"['Fairness', 'Bias', 'Diversity', 'Discrimination', 'Equality']",,"The emergence of OpenAI has served as a catalyst for public awareness of the potential of artificial intelligence technology, sparking interest not only in generative AI but also in on-device AI and general AI. Currently, AI has become indispensable not only in the field of natural language processing but also in easily accessible domains such as video and audio generation and automatic editing, leading us into an era where coexistence with such AI technologies is unavoidable. However, concerns remain. Unethical practices such as AI-generated reports and biased news articles highlight the need for responsible development. Furthermore, the ?black box? nature of neural networks presents a challenge for industries requiring high trustworthiness. To navigate this evolving landscape, we explore international standards and regulatory proposals for safe AI integration. We delve into academic research on fair AI techniques and examine bias mitigation tools offered by enterprises. Through this comprehensive analysis, we aim to empower AI developers and practitioners to build ethical systems and shape sound regulatory frameworks."
Pancreatic Cancer Detection and Differentiation from Chronic Pancreatitis: Potential Biomarkers Identified through a High-Throughput Multiplex Proteomic Assay and Machine Learning-Based Analysis,2025,"['C1q subcomponent subunit A', 'Cadherin-related family member 2', 'Pancreatic cancer', 'Pro-neuropeptide Y', 'Proximity extension assay']",,"Background: Pancreatic cancer (PC)-screening methods have limited accuracy despite their high clinical demand. Differential diagnosis of chronic pancreatitis (CP) poses an- other challenge for PC diagnosis. Therefore, we aimed to identify blood protein biomarkers for PC diagnosis and differential diagnosis of CP using high-throughput multiplex proteomic analysis.Methods: Two independent cohorts (N=88 and 80) were included, and residual serum samples were collected from all individuals (N=168). Each cohort consisted of four groups: healthy (H) individuals and those with CP, stage I/II PC (PC1), or stage III/IV PC (PC2). Protein expression in the first cohort was quantified using the Olink Immuno-Oncol- ogy and Oncology 3 proximity extension assay (PEA) panels and was analyzed using ma- chine-learning (ML)-based analyses. Samples in the second cohort were utilized to verify candidate biomarkers in immunoassays.Results: Both the PEA and immunoassay results confirmed that previously recognized bio- markers, such as the mucin-16 and interleukin-6 proteins, were more highly expressed in the PC (PC1 and PC2) groups than in the non-PC (CP and H) groups. Several novel bio- markers for PC diagnosis were identified via ML-based feature extraction, including C1QA and CDHR2, whereas pro-neuropeptide Y (NPY) appeared to be a promising biomarker for the differential diagnosis of CP. Applying XGBoost classification incorporating the selected features resulted in an area under the curve of 0.92 (0.85–0.98) for differentiating the PC group from the CP and H groups.Conclusions: Promising blood biomarkers for PC diagnosis and differential diagnosis of CP were identified using a PEA platform and ML techniques."
Enhancing the Precision of Machine Learning in the Library Profession,2025,"['Machine Learning', 'Libraries', 'Data Collection', 'Precision', 'Ethical Considerations']",,
Comparison of machine learning models for classifying edible oils using Fourier‐transform infrared spectroscopy,2025,"['classification', 'edible oil', 'FT-IR', 'machine learning', 'second derivative']",,"Accurate classification and authentication of edible oils are essential for maintaining product quality, ensuring consumer safety, and preserving market integrity. Therefore, this study aims to propose Fourier-transform infrared (FT-IR) spectroscopy, combined with advanced machine learning models, as a rapid and non-destructive technique for classifying edible oils. The FT-IR spectra of seven edible oil types were analyzed across three spectral regions: the full range, the C-H stretching range, and the fingerprint region. Both absorbance and second derivative spectra were used to evaluate the influence of spectral preprocessing on classification accuracy. Six machine learning models—principal component analysis followed by linear discriminant analysis (PCA-LDA), k-nearest neighbors, decision tree, random forest, eXtreme Gradient Boosting, and support vector machines (SVM)—were employed to classify the oils, achieving training accuracies of 96.4%–100% and testing accuracies of 88.1%–100%. The second derivative spectra enhanced model performance by improving the resolution of overlapping peaks, particularly in the C H and C O stretching regions. Additionally, the SHapley Additive exPlanations analysis further revealed the most critical spectral features influencing model predictions, offering valuable insights into the decision-making processes. This study demonstrates the effectiveness of combining FT-IR spectroscopy, second derivative preprocessing, and machine learning techniques for classifying edible oils. The findings highlight the benefits of second derivative spectra in enhancing spectral resolution and the superior classification performance of PCA-LDA and SVM models. These results offer a robust framework for advancing edible oil analysis and emphasize the potential of artificial intelligence in food authentication and quality control."
"Integrative analysis of genetic variability and functional traits in lung adenocarcinoma epithelial cells via single-cell RNA sequencing, GWAS, bayesian deconvolution, and machine learning",2025,['Lung adenocarcinoma · Single-cell RNA sequencing · GWAS · Bayesian deconvolution · Machine learning'],,"Background Lung adenocarcinoma remains a leading cause of cancer-related mortality worldwide, characterized by high genetic and cellular heterogeneity, especially within the tumor microenvironment.Objective This study integrates single-cell RNA sequencing (scRNA-seq) with genome-wide association studies (GWAS) using Bayesian deconvolution and machine learning techniques to unravel the genetic and functional complexity of lung adenocarcinoma epithelial cells.Methods We performed scRNA-seq and GWAS analysis to identify critical cell populations affected by genetic variations. Bayesian deconvolution and machine learning techniques were applied to investigate tumor progression, prognosis, and immune-epithelial cell interactions, particularly focusing on immune checkpoint markers such as PD-L1 and CTLA-4.Results Our analysis highlights the importance of genes like SLC2A1, which regulates glucose metabolism and correlates with tumor invasiveness and poor prognosis. Immune-epithelial interactions suggest a suppressive tumor microenvironment, potentially hindering immune responses. Additionally, machine learning models identify core prognostic genes such as F12, GOLM1, and S100P, which are significantly associated with patient survival.Conclusions This comprehensive approach provides novel insights into lung adenocarcinoma biology, emphasizing the role of genetic and immune factors in tumor progression. The findings support the development of personalized therapeutic strategies targeting both tumor cells and the immune microenvironment."
Machine learning identification of NK cell immune characteristics in hepatocellular carcinoma based on single-cell sequencing and bulk RNA sequencing,2025,['Hepatocellular carcinoma · Single-cell RNA sequencing · NK cells · Immune phenotype · Machine learning'],,"Background Hepatocellular carcinoma (HCC) is a highly malignant tumor; however, its immune microenvironment and mechanisms remain elusive. Single-cell sequencing allows for the exploration of immune characteristics within tumor at the cellular level. However, current knowledge regarding the roles of different immune cell populations in liver cancer progression is limited.Objective The main objective of this study is to identify molecular markers with NK cell immune characteristics in hepatocellular carcinoma using various machine learning methods based on Single-Cell Sequencing and Bulk RNA Sequencing.Methods We collected samples from eight normal liver tissues and eight HCC tumor tissues and performed single-cell RNA sequencing for immune cell clustering and expression profile analysis. Using various bioinformatic approaches, we investigated the immune phenotype associated with natural killer (NK) cells expressing high CD7 level. In addition, we verified the role of CD7 in the growth of HCC after NK cell and HCC cells cocultured by RT-qPCR, MTS and Flow cytometer experiments. Finally, we constructed a machine learning model to develop a prognostic prediction system for HCC based on NK cell-related genes.Results Through single-cell typing, we found that the proportions of hepatocytes and NK cells were significantly elevated in the tumor samples. Moreover, we found that the expression of CD7 was high in HCC and correlated with prognosis. More importantly, Overexpression of CD7 in NK cells significantly inhibited the activity of MHCC97 cells and increased the number of apoptosis of HCC cells (p < 0.05). Furthermore, we observed that NK cells with high CD7 expression were associated with an activated immune phenotype.Conclusion Our study found that CD7 is an important biomarker for assessing immune status and predicting survival of HCC patients; hence, it is a potential target for immune therapy against HCC."
An Interpretive Machine Learning Model for Predictive High Performance Belt Transport Systems,2025,"['Machine learning', 'Prediction model', 'Support vector machine', 'Belt transportation system', 'Neural network']",,"Belt conveyors are common transportation equipment, and optimizing their performance is an effective measure to achieve intelligence and efficient transportation. The application of new technologies has increased the controllable parameters and operational parameters to be optimized in belt transportation systems, making performance prediction and multi-objective optimization problems more challenging. Traditional response prediction and optimization methods have become increasingly inadequate to meet research requirements. The emergence and development of machine learning methods and modern intelligent optimization methods have provided new directions for the prediction and optimization research of belt transportation systems. Therefore, in order to improve the system prediction and performance optimization of belt transportation systems, this study proposes an interpretive machine learning approach based on improved neural networks and support vector machines, which combines the optimization of network initial weight threshold and training set test set, and establishes a high-performance predictive interpretive machine learning model. The results indicate that under different combinations of training and validation set partitioning, all evolutionary processes in the trajectory of the initial weight threshold optimization of the proposed comprehensive neural network optimization method reach their optimal state in the 17th generation.The optimization algorithm stably converged to the optimal value after only 14 generations of evolution, resulting in a mean square error of 0.011678 for the optimal network prediction, while the mean square error of all individuals in the initial population was 0.016845. If the average network prediction performance of all individuals in the initial population is taken as the basic standard, a comprehensive optimization algorithm is used to optimize the network’s prediction performance to 29.6%. After the 10th reinforcement training, the prediction error of the support vector machine decreases to 0.99%, and the gross of simulations is 65. The designed method helps to achieve intelligent transportation systems, unmanned operation and high performance, and can achieve sustainable development while ensuring transportation safety and efficiency."
Optimized Machine Learning Algorithms for Predicting the Punching Shear Resistance of Flat Slabs with Transverse Reinforcement,2025,"['Machine learning', 'Bayesian optimization', 'Punching shear resistance', 'RC flat slabs', 'Transverse reinforcement']",,"In the calculation of reinforced concrete (RC) flat slabs with transverse reinforcement, punching shear resistance is one of the most critical factors. It is true that design provisions may be implemented, but they often result in significant biases and deviations from expectations. This study aims to present an optimized machine learning (ML) algorithm for estimating the punching shear resistance. Four machine learning (ML) algorithms (SVR, DT, RF, and XGBoost) with Bayesian optimization (BO) are presented in this paper to provide accurate predictions for flat slabs. The adoptability and optimization of the models are achieved through the analysis of a database of 337 test specimens with nine design parameters. Machine learning (ML) techniques are used to estimate punching shear resistance, which is compared with design provisions and equations relating to critical shear crack theory (CSCT). According to this study, Bayesian optimization is still capable of improving the performance of conventional machine learning algorithms, while the XGBoost-based model offers advanced capabilities. Predictions based on BO-XGBoost are in good agreement with actual values (MAE, RMSE, and R² are 0.09 MN, 0.14 MN, and 0.92, respectively) in test set. Following a detailed explanation using Shapley additive explanation (SHAP), a high-performance ML approach is used to investigate the predictive results. With the proposed optimized algorithms, it is possible to determine the punching shear resistance of flat slabs with transverse reinforcement during the preliminary stages of the construction."
"Voting, Random Forest, and Gradient Boosting Ensemble Machine Learning Models and Learning Effects of Reading Classics",2025,"['Classics Learning', 'Satisfaction Effect', 'Ensemble Learning', 'Voting', 'Random Forest', 'Gradient Boosting']",,"This study examines the satisfaction effect of classics learn course using deep learning Ensemble models such as Voting, Random Forest, and Gradient Boosting models. The following were the main findings of the comparison of their predictive abilities. First, in the classification predictions of the necessity of classics learning courses, the Ensemble models were sensitive to hyperparameters but generally provided higher R-squared values compared to individual machine learning models. Second, in the regression predictions of satisfaction, the Voting ensemble model showed a higher R-squared and lower RMSE compared to individual deep learning models. Third, in the Random Forest model, which made it the best model with the least risk of overfitting if we chose the appropriate hyperparameters. Fourth, for the Gradient Boosting model, by increasing the learning rate to 0.2 the R-squared values for the evaluation dataset were higher, and the RMSE was lower, indicating that this setup led to better predictions, showing that the necessity of classics learning course increased after the course."
Determinants of Fertility through Machine Learning and Time Series Analysis and Response to Low Birth Crisis,2025,"['합계출산율', '머신러닝', '시계열 분석', '저출생 정책', '출산율 결정요인', '정책 예측', 'Total fertility rate', 'Machine learning', 'Time-series analysis', 'Low birthrate policy', 'Fertility determinants', 'Policy forecasting']",,"The purposes of this study are to systematically analyze the factors influencing the Total Fertility Rate (TFR) and to develop a predictive model integrating machine learning and time-series analysis for effective policy formulation. South Korea, despite significant policy interventions over the past two decades, continues to experience a critical decline in fertility rates, recording an unprecedentedly low TFR of 0.78 in 2022, the lowest among all OECD countries. This demographic challenge poses severe threats to national economic stability, social security systems, and the sustainability of local communities, particularly in rural areas experiencing population decline. Through advanced data analytics, this study combines Random Forest, Neural Networks, and other machine learning algorithms with ARIMA-based time-series forecasting to identify key determinants influencing TFR and to predict long-term trends up to 2040. Key findings reveal that economic support, access to childcare facilities, parental leave policies, and housing stability are the most influential factors in improving fertility rates. The machine learning models outperformed traditional approaches, such as linear regression, in capturing non-linear relationships between variables and predicting complex social dynamics. This study provides valuable insights for policymakers, emphasizing the importance of multi-dimensional strategies and data-driven approaches in addressing the low birthrate crisis. Furthermore, the integration of machine learning and time-series models demonstrates a novel methodology for tackling demographic challenges and guiding evidence-based policy decisions."
Big Data and Machine Learning in ESG Research,2025,"['Big data', 'Climate change', 'Corporate culture', 'ESG', 'Machine learning']",,"The wide applications of machine learning techniques to big data allow researchers to dig deep into novel large‐scale data sets, such as job postings, earnings calls, and news reports. They also equip researchers with powerful tools to study important but subtle/challenging topics that are impossible to explore before on a large scale, such as corporate culture and climate risk exposure. In this review, I survey various applications of different machine learning techniques in ESG research, beginning with foundational methods such as bag‐of‐words, progressing through topic modeling, word embedding, and BERT, and culminating with generative artificial intelligence (AI) and other advanced machine learning approaches. I conclude by outlining future directions for using big data and machine learning in ESG research."
RNA-binding protein expression based machine learning model predicts metastasis and treatment outcome of testicular cancer,2025,['RNA-binding protein · Machine learning · Testicular cancer · Biomarker · Prediction'],,"Background RNA-binding proteins (RBPs) are key regulators of cellular transcription and are associated with the occurrence and development of diseases.Objective This study aimed to validate the biological characteristics and clinical value of RBPs in testicular cancer, and then construct prediction models for testicular cancer metastasis and treatment outcome.Methods RNA sequencing data from 150 testicular tumors and 6 normal tissues were obtained from the cancer genome atlas (TCGA). Additionally, RNA sequencing data from 165 normal testicular tissues were downloaded from the genotype-tissue expression (GTEx) portal. The chemotherapy sensitivity of testicular tumor was evaluated based on the genomics of drug sensitivity in cancer (GDSC) and cancer therapeutics response portal (CTRP) databases. RNA sequencing data was analyzed and predicted for tumor metastasis and treatment outcomes through machine learning models such as artificial neural networks (ANN), random forests (RF), support vector machines (SVM), and logistic regression models (LR).Results A RBP risk-score model was developed with the genes: GAPDH, APOBEC3G, KRT18, NOSIP, KCTD12, ENO1, HMGA1, LDHB, ANXA2, ELOVL6, TCF7, BICD1. Those biomarkers were enriched in growth factor activity, hormone receptor binding, and cell killing signaling pathway. Risk-score model can predict the progress free interval (PFI), disease free interval (DFI), and metastasis status of patients with testicular cancer. Patients with high risk-score tumor had an increased tumor infiltrating M2 macrophage, and were more likely to progress after anti-PD-L1 immunotherapy. High risk patients seemed to benifit more from cisplatin-based chemotherapy, but less from bleomycin chemotherapy. Machine learning models basing on RBPs were able to predict tumor metastasis and the effects of chemotherapy and radiotherapy. ANN model achieved the highest accuracy in predicting tumor lymph node metastasis and radiotherapy sensitivity.Conclusion RBP signature genes can serve as biomarkers for testicular cancer and play a role in predicting tumor metastasis and therapeutic efficacy."
Supervised Machine Learning Assisted-Modeling for Prediction of Geometrical and Electrical Parameters of Printed Antennas,2025,"['Machine learning', 'UWB', 'U-shaped slotted antenna', 'Notch frequency', 'Rectangular patch']",,"The present era signifies a notable advancement in antenna design and performance optimization through the integration of machine learning techniques. This paper explores the application of supervised machine learning algorithms namely-Random Forest, Ridge and Least Absolute Shrinkage Selector Operator (LASSO) Regression for the parametric prediction of printed antennas. It specifically investigates two categories of antennas: patch antenna without slots and patch antenna with slots. This work emphasizes the prediction of geometrical parameters of both types of antennas using the electrical parameters of the respective antennas. Also, the supervised algorithms are utilized for the prediction of electrical parameters, including single attributes such as resonance frequency of the former and multiple attributes including notched and cut-off frequency points of the latter. The efficacy of the supervised machine learning algorithms is evaluated in terms of mean absolute error (G MAE) and root mean square error (G RMSE) metrics."
An overview of artificial intelligence and machine learning in shoulder surgery,2025,"['Artificial intelligence', 'Machine learning', 'Arthroplasty', 'Rotator cuff tears']",,"Machine learning (ML), a subset of artificial intelligence (AI), utilizes advanced algorithms to learn patterns from data, enabling accurate predictions and decision-making without explicit programming. In orthopedic surgery, ML is transforming clinical practice, particularly in shoulder arthroplasty and rotator cuff tears (RCTs) management. This review explores the fundamental paradigms of ML, including supervised, unsupervised, and reinforcement learning, alongside key algorithms such as XGBoost, neural networks, and generative adversarial networks. In shoulder arthroplasty, ML accurately predicts postoperative outcomes, complications, and implant selection, facilitating personalized surgical planning and cost optimization. Predictive models, including ensemble learning methods, achieve over 90% accuracy in forecasting complications, while neural networks enhance surgical precision through AI-assisted navigation. In RCTs treatment, ML enhances diagnostic accuracy using deep learning models on magnetic resonance imaging and ultrasound, achieving area under the curve values exceeding 0.90. ML models also predict tear reparability with 85% accuracy and postoperative functional outcomes, including range of motion and patient-reported outcomes. Despite remarkable advancements, challenges such as data variability, model interpretability, and integration into clinical workflows persist. Future directions involve federated learning for robust model generalization and explainable AI to enhance transparency. ML continues to revolutionize orthopedic care by providing data-driven, personalized treatment strategies and optimizing surgical outcomes."
Machine learning study of universal electronic stopping cross-sections of ions in matter,2025,"['Electronic stopping cross-section', 'Machine learning', 'Least absolute shrinkage and selection operator (LASSO)']",,"Accurate electronic stopping cross-section (ESCS) database of ions in matter is crucial for precise simulation of radiation damage. Based on the experimental-cleaned database of SRIM, binary theory and unitary convolution approximation as well as the descriptor pool extracted from these models, we developed a universal machine learning ESCS database using the least absolute shrinkage and selection operator (LASSO) algorithm. This method allows for predictions for ion-target combinations with atomic numbers from 1 to 92, within the energy range from 1 keV/u to 1 GeV/u, addressing the limitations of machine learning on training dataset. The database exhibits remarkable accuracy in predicting ESCS and ion depth distribution/range, along with robust reciprocity performance. Key descriptors are also determined, which closely mimic the Lindhard-Scharff-Schiott and Bohr- Bethe-Bloch formulations, achieved through precise adjustments of the exponent of individual elements. The proposed universal ESCS database surpasses the accuracy of existing databases, supporting related applications across a wide range of energies and systems"
Machine learning study of universal electronic stopping cross-sections of ions in matter,2025,"['Electronic stopping cross-section', 'Machine learning', 'Least absolute shrinkage and selection operator (LASSO)']",,"Accurate electronic stopping cross-section (ESCS) database of ions in matter is crucial for precise simulation of radiation damage. Based on the experimental-cleaned database of SRIM, binary theory and unitary convolution approximation as well as the descriptor pool extracted from these models, we developed a universal machine learning ESCS database using the least absolute shrinkage and selection operator (LASSO) algorithm. This method allows for predictions for ion-target combinations with atomic numbers from 1 to 92, within the energy range from 1 keV/u to 1 GeV/u, addressing the limitations of machine learning on training dataset. The database exhibits remarkable accuracy in predicting ESCS and ion depth distribution/range, along with robust reciprocity performance. Key descriptors are also determined, which closely mimic the Lindhard-Scharff-Schiott and Bohr-Bethe-Bloch formulations, achieved through precise adjustments of the exponent of individual elements. The proposed universal ESCS database surpasses the accuracy of existing databases, supporting related applications across a wide range of energies and systems."
Machine Learning for Predicting Students’ English Test Scores in an Educational Setting,2025,"['Education', 'Machine learning', 'English test', 'Score prediction', 'XGBoost']",,"Machine learning methods have been increasingly used in educational settings. For the problem of predicting students’ English test scores, first, the number of absences and the average score of usual tests were selected as students’ behavioral features; then, the prediction effects of five machine learning approaches, including K-medoids, support vector regression (SVR), random forest (RF), gradient boosting decision tree (GBDT) and XGBoost, were compared after eliminating the features with weak correlation. The results showed that the XGBoost method best predicted students’ English test scores, with an average accuracy, precision, and recall rate of 0.8619, 0.8322, and 0.8734, respectively, and an F1 value of 0.8523. The findings demonstrate the reliability of the XGBoost method in predicting students’ English test scores. It can be extended and applied in practice. This article makes some contributions to the accurate prediction of students’ grades and the intelligent management of educational information."
Prediction of Work-relatedness of Shoulder Musculoskeletal Disorders as by Using Machine Learning,2025,['Machine learningShoulderWork-relatedness evaluation'],,"ackground This study aimed to develop prediction models for the work-relatedness of shoulder diseases through machine learning algorithms.Methods The dataset comprised 7,270 cases of 8,302 individuals who applied for occupational diseases and received the final approval decision from the Korea Workers' Compensation and Welfare Service's Disease Evaluation Committee, which is related to shoulder musculoskeletal disorders between January 2020 and December 2021. In this study, demographic analysis and difference of approval rate by shoulder diseases were performed. Additionally, machine learning algorithms, including logistic regression, support vector machine, decision tree, random forest, and the XGBoost, were utilized to construct prediction models for work-relatedness assessment.Results The performance of each model was evaluated. XGBoost showed an accuracy of 81.64% and an area under the curve of 0.73, and random forest showed an accuracy of 84.46% and an area under the curve of 0.73. Key factors influencing work-relatedness assessment were employment period, physical burden score, gender, and age.Conclusion The application of various machine learning techniques showed high performance score, representing that it would be helpful to reduce the differences in judgment between occupational environment medicine physicians."
국내 프로스포츠 홈페이지 인사말에 대한 Machine Learning 분석,2025,"['Machine learning', '감성분석', '네트워크 분석', '프로스포츠', '인사말', 'Machine learning', 'Sentiment analysis', 'Network analysis', 'Pro-sports', 'Greetings']","홈페이지를 통하여 제공되는 인사말에는 보통 추구하고자 하는 목표 등을 포함한 핵심 정보가 담기며 소 통의 일환으로 이용되고 있다. 개인의 건강증진 및 사회통합의 역할을 담당하는 프로스포츠에서도 홈페이지 인사 말은 그 의미하는 바와 역할이 중요하다. 본 연구에서는 국내 프로스포츠 홈페이지 인사말을 대상으로 machine learning 기법을 이용하여 분석해 보았다. 그 결과 다음을 알 수 있었다, 첫째, 분석 대상으로 삼은 4개 프로리그 모두에서 유사한 결과를 보인바, 차별화를 발견할 수 없었다. 둘째, 워드 클라우드 분석, 네트워크 분석을 통해 보 았을 때, 감사의 인사와 함께 지속적인 성원을 부탁하는 내용이 주를 이루고 있는 것으로 나타났다. 나아가 감성 분석 결과 4개 프로리그 모두 예상했던 대로 긍정적인 단어의 선택이 많았으며, 분산분석 결과 그 차이는 통계적 으로 유의하지 않았다(p>0.05). 이에 향후 홈페이지 인사말 개편 시에는, 각 프로리그의 캐치프레이즈를 충분하게 담아내고, 나아가 각 구단이 프로스포츠 운영을 통하여 이루고자 하는 방향성 등이 잘 포함되도록 개선할 것을 제 안하였다.","Greetings on websites homepages typically contain core information, such as goals and visions, and serve as a means of communication. In professional sports, which play a role in promoting individual health and social integration, website greetings hold significant meaning and importance. This study analyzed greetings on domestic professional sports websites using machine learning techniques. The results are as follows: First, all four professional leagues analyzed showed similar results, revealing no differentiation. Second, word cloud and network analyses indicated that greetings mostly consist of words of gratitude and requests for continued support. Furthermore, sentiment analysis showed that, as expected, positive words were predominantly chosen across all four leagues, and analysis of variance revealed no statistically significant differences (p>0.05). Therefore, it is suggested that in future revisions of websites greetings, they should fully incorporate each professional league’s slogan and direction, as well as the objectives each club aims to achieve through professional sports operations."
Comparison of Logistic Regression and Machine Learning Approaches in Predicting Depressive Symptoms: A National-Based Study,2025,"['Logistic regression', 'Machine learning', 'Depressive symptoms', 'Risk factors.']",,"Objective Machine learning (ML) has been reported to have better predictive capability than traditional statistical techniques. The aim of this study was to assess the efficacy of ML algorithms and logistic regression (LR) for predicting depressive symptoms during the COVID-19 pandemic.Methods Analyses were carried out in a national cross-sectional study involving 21,916 participants. The ML algorithms in this study included random forest (RF), support vector machine (SVM), neural network (NN), and gradient boosting machine (GBM) methods. The performance indices were sensitivity, specificity, accuracy, precision, F1-score, and area under the receiver operating characteristic curve (AUC).Results LR and NN had the best performance in terms of AUCs. The risk of overfitting was found to be negligible for most ML models except for RF, and GBM obtained the highest sensitivity, specificity, accuracy, precision, and F1-score. Therefore, LR, NN, and GBM models ranked among the best models.Conclusion Compared with ML models, LR model performed comparably to ML models in predicting depressive symptoms and identifying potential risk factors while also exhibiting a lower risk of overfitting."
Predictive Modeling of Volume and Biomass in Pinus pseudostrobus Using Machine Learning and Allometric Approaches,2025,"['Forest management', 'machine learning algorithms in forestry', 'predicting forest biomass', 'Random Forest algorithm', 'allometric modeling', 'quantile regression in forest management']",,"This study aims to evaluate the effectiveness of machine learning algorithms in predicting key forest metrics—stem volume, root system volume, and organ biomass (including leaves, branches, stem, and root)—for Pinus pseudostrobus var. Lindley, based on morphological measurements from the same trees. The novelty of this study lies in applying five machine learning algorithms—Random Forest, Neural Networks, Gradient Boosting Machines, Support Vector Machines (SVM), and k-Nearest Neighbors (k-NN)—to predict these metrics, using data from the destructive analysis of 98 individual trees aged from eight months to five years. For comparison, we also applied univariate allometric models, adjusted with nonlinear least squares and quantile regression. The results indicate that Random Forest, k-NN, and SVM outperformed the other algorithms, demonstrating superior predictive accuracy for both biomass and volume.A key innovation of this study is its demonstration of how machine learning, with its ability to model complex, nonlinear relationships, can serve as a powerful tool for forest management.Quantile regression, combined with nonlinear least squares, proves most effective when the relationships are well-defined, allowing for tailored parameter adjustments that enhance predictions, particularly in the presence of heteroscedasticity."
Optimizing microalgal biomass conversion into carbon materials and their application in water treatment: a machine learning approach,2025,['Microalgae Reinforcement learning (RL) Water treatment Activated carbon Renewable energy technologies Environmental management Machine learning-enhanced microalgae CO2 capture'],,"Microalgae, such as Chlorella vulgaris and Scenedesmus obliquus, are highly efficient at capturing carbon dioxide through photosynthesis, converting it into valuable biomass. This biomass can be further processed into carbon materials with applications in various fields, including water treatment. The reinforcement learning (RL) method was used to dynamically optimize environmental conditions for microalgae growth, improving the efficiency of biodiesel production. The contributions of this study include demonstrating the effectiveness of RL in optimizing biological systems, highlighting the potential of microalgae-derived materials in various industrial applications, and showcasing the integration of renewable energy technologies to enhance sustainability. The study demonstrated that Chlorella vulgaris and Scenedesmus obliquus, cultivated under controlled conditions, significantly improved absorption rates by 50% and 80%, respectively, showcasing their potential in residential heating systems. Post-cultivation, the extracted lipids were effectively utilized for biodiesel production. The RL models achieved high predictive accuracy, with R2 values of 0.98 for temperature and 0.95 for oxygen levels, confirming their effectiveness in system regulation. The development of activated carbon from microalgae biomass also highlighted its utility in removing heavy metals and dyes from water, proving its efficacy and stability, thus enhancing the sustainability of environmental management. This study underscores the successful integration of advanced machine learning with biological processes to optimize microalgae cultivation and develop practical byproducts for ecological applications."
Realtime simulation of buck‑boost convertors with machine learning in DC integration rail traction power centers,2025,"['Buck-boost', 'Converter', 'Integration', 'Machine learning', 'Railway']",,"In this study, a buck-boost converter circuit based on machine learning was developed through real-time simulation, employing field measurements collected from traction center regions integrated with DC-fed rail systems operating at different voltage levels. By utilizing the proposed topology with Matern 5/2 Gaussian Process Regression (GPR), high performance was achieved in the power supply system. The best R-squared score was obtained under operating conditions in DC-powered traction centers. The performance metrics obtained with the proposed model are as follows: the R2 value is 1, the RMSE is 0.00009, and the MSE is 9.0612e-09. These results demonstrate the effectiveness of artificial intelligencebased approaches in enhancing the efficiency of the buck-boost converter. The same dataset was applied to other machine learning methods known for producing successful outcomes, and their performance rates were compared with those of the proposed method. This circuit enables power conversion within real-time integration zones by employing highly efficient control signals that are generated through the application of machine learning to actual field data. At the conclusion of the study, the output voltage of the buck-boost converter, including a 750 V DC supply, was presented with statistical values to demonstrate the successful operation of the proposed model."
Applying a Systems Engineering Approach to Predict NPP Response to Multiple Steam Generator Tube Rupture Accident Using Machine Learning and Explainable AI,2025,"['Systems Engineering', 'APR1400', 'Machine Learning', 'Nuclear Safety Analysis', 'Design Extension Conditions', 'Explainable Artificial Intelligence']",,"In recent years, there has been a significant increase in interest in Artificial Intelligence (AI). Given its promising potential and usefulness for human endeavors, there has been growing consideration of how AI could be applied within the nuclear industry. The emergence of Machine Learning models capable of effectively handling long-term dependencies in time-series data derived from simulations enables the prediction of the behaviour of nuclear power plants (NPPs) under accident conditions. This approach allows for significant time savings and reduces computational effort compared to traditional accident simulations using numerical methods. To facilitate the acceptance of machine learning by nuclear safety regulatory bodies, it is essential to address the black box issue and implement Explainable Artificial Intelligence (XAI) techniques. This paper presents a Systems Engineering approach to developing a ML tool capable of predicting the APR1400 reactor's response to a Multiple Steam Generator Tube Rupture (MSGTR) accident, including the implementation of XAI. Additionally, the paper focuses on the analysis of the Multiple Steam Generator Accident Scenario, including the application of mitigation strategy by the operator."
Preparing  Scope  3  Carbon  Emission  Disclosure:  A  Machine Learning  Approach,2025,"['Climate  Change', 'Scope  1', 'Scope  2', 'Scope  3', 'Supply  Chain', 'Machine  Learning']",,"This study employs machine learning models to facilitate relatively low-cost disclosure of Scope 3 carbon emissions, utilizing novel Korean data. Scope 3 CO2 emissions are a significant concern for companies, particularly after the ISSB and EFRAG have implemented mandatory reporting standards. Currently, accurately determining these values is difficult, with many estimates being necessary, leading to substantial costs. Consequently, this presents a substantial challenge for individual companies to manage independently. In line with this, in Korea, the Financial Services Commission is planning to introduce climate change disclosure required by the ISSB, focusing on companies with assets of more than $2 trillion, but the most important part is how to accurately and efficiently measure and disclose carbon dioxide emissions. Through evaluating five models - Random Forest, Gradient Boosting, Adaboost, XGBoost, and LightGBM, we identify LightGBM as the most accurate for Korean companies in Scope 3 carbon emissions, with a 77.01% accuracy based on R-square. Furthermore, based on our research model, the estimation results for Scope 1 and Scope 2 showed prediction accuracies of 84% and 88%, respectively. The result of this paper offers empirical insights for future regulatory ESG disclosures, showcasing the study’s academic and practical contributions to enhancing Scope 3 emissions estimation and expanding the ESG research domain. Specifically, the contribution of this paper is to demonstrate that machine learning methodologies can be employed by stakeholders—such as accounting firms to verify companies’ disclosed Scope 3 emissions, supervisory authorities to enhance regulatory oversight, and investors to identify companies with lower Scope 3 emissions."
A Novel Approach to a Few Shot Learning Techniques Based on Thermal Error Modeling for Slant Bed CNC Lathe Machine,2025,"['Thermal errors', 'Temperature sensitivity points', 'Few-shot learning', 'Slant bed CNC MAML']",,"Thermal errors in precision machining can influence machine tool accuracy and effectiveness. This research addresses these challenges by emphasizing temperature sensitivity. An enhanced approach is presented that combines the fuzzy C-means clustering algorithm with the Grey Wolf Optimizer, followed by the Grey Relation Coefficient, to select temperature sensitivity points (TPS). To address the issue of limited datasets in machine learning, this study introduces a new method based on Few-shot learning models, including Model-Agnostic Meta-Learning (MAML), Matching Networks, and Siamese Networks. The models are evaluated for their ability to predict thermal errors using a limited dataset. The MAML model demonstrates notable predictive performance, with an R2 value of 0.956, RMSE of 0.208, and MAE of 0.160 in the X-direction; and an R2 value of 0.996, RMSE of 0.657, and MAE of 0.495 in the Y-direction. Furthermore, MAML effectively predicts thermal errors, contributing to the enhancement of tool machine accuracy during operation. This research fills a gap in current techniques and serves as a foundation for future studies on machine tool thermal error correction."
The Impact of Smart Home App Review Characteristics on  Review Helpfulness: A Topic Modeling and Machine Learning  Approach,2025,"['BERTopic', 'Feature Importance', 'Machine Learning', 'Review Helpfulness', 'Smart Home App']",,"Purpose - This study investigates the determinants of review helpfulness for smart home apps by examining latent topics within user reviews. It aims to discern how general issues versus specific product integration concerns influence perceived review utility.Design/methodology/approach - Smart home app reviews were collected from the Google Play Store for applications including LG ThinQ, Samsung SmartThings, and Google Home. Following rigorous preprocessing, the BERTopic framework was applied to extract five latent topics. These topic probabilities, alongside review characteristics, were incorporated into regression and machine learning models to predict review helpfulness. Feature importance analysis was conducted to evaluate the contribution of each topic.Findings - Both regression and machine learning results indicate that reviews addressing broad issues, such as login errors and application device integration, are more likely to be deemed helpful. In contrast, topics centered on specific IoT product integrations (e.g., refrigerators, air purifiers, washing machines, dryers) tend to decrease perceived helpfulness.Research implications or Originality - By integrating advanced topic modeling with predictive analytics, this study offers novel insights into the smart home domain. The findings provide actionable guidelines for enhancing app usability and optimizing review presentation, thereby contributing to both academic research and industry practices."
Applying a Systems Engineering Approach to Predict NPP Response to Multiple Steam Generator Tube Rupture Accident Using Machine Learning and Explainable AI,2025,"['Systems Engineering', 'APR1400', 'Machine Learning', 'Nuclear Safety Analysis', 'Design Extension Conditions', 'Explainable Artificial Intelligence']",,"In recent years, there has been a significant increase in interest in Artificial Intelligence (AI). Given its promising potential and usefulness for human endeavors, there has been growing consideration of how AI could be applied within the nuclear industry. The emergence of Machine Learning models capable of effectively handling long-term dependencies in time-series data derived from simulations enables the prediction of the behaviour of nuclear power plants (NPPs) under accident conditions. This approach allows for significant time savings and reduces computational effort compared to traditional accident simulations using numerical methods. To facilitate the acceptance of machine learning by nuclear safety regulatory bodies, it is essential to address the black box issue and implement Explainable Artificial Intelligence (XAI) techniques. This paper presents a Systems Engineering approach to developing a ML tool capable of predicting the APR1400 reactor's response to a Multiple Steam Generator Tube Rupture (MSGTR) accident, including the implementation of XAI. Additionally, the paper focuses on the analysis of the Multiple Steam Generator Accident Scenario, including the application of mitigation strategy by the operator."
A Predictive Maintenance Federated Learning  Framework for Machine Fault Detection  Based on Vibration Data,2025,"['Predictive Maintenance', 'Federated Learning', 'Deep Learning', 'Time Series Classification']",,"Predictive maintenance is essential in the manufacturing industry, as it helps reduce maintenance costs and improve operational efficiency. In the IoT era, predictive maintenance is increasingly automated using deep learning methods, leveraging the abundant availability of sensor data. However, the widely used centralized learning approach presents significant data security concerns, as company data is highly valuable and must be protected. In this paper, we propose a Federated Learning (FL) framework for predictive maintenance, utilizing vibration data collected from edge devices. Additionally, we introduce a custom model aggregation strategy, Fine-Tuning FedAvg (FT-FedAvg), which enhances model performance by incorporating a fine-tuning phase during the model aggregation process. Our framework is designed for real-world deployment, as it is optimized for resource-constrained edge devices and supports real-time monitoring in industrial environments. Experimental results demonstrate that our FL framework achieves comparable performance to centralized learning while preserving data privacy, making it a practical and secure solution for predictive maintenance in real-world manufacturing scenarios."
Fault Diagnosis of the Electric Multiple Unit Door System by Machine Learning Using Sensor Signal of the Simulator,2025,['Door system · Fault diagnosis · Machine learning · Classifcation performance · Electric multiple unit'],,"Fault diagnosis and prediction are important to prevent trafc congestion during rush hour due to door failures of urban railway vehicles. This paper is a study on improving failure classifcation performance through machine learning using the data set collected by installing a displacement sensor on a door simulator. First, the durability test of the sensor and the developed simulator was verifed through 147,000 no-failure tests. For machine learning, 11,225 sets of normal and abnormal data of the door were collected and supervised learning was performed. In order to overcome the difculty of fault diagnosis of the existing pressure sensor or acoustic sensor, pre-processing was performed that converted to speed-based data. In addition, feature extraction was compared with the single zone method by testing the 2-zone segmentation method. Feature selection was made using the principal component analysis algorithm developed for feature dimensionality reduction. As a result, the classifcation performance of the method using the single zone method with open and close data was better than the 2-zone segmentation method by acceleration and deceleration. Among the machine learning models, the LGBM model showed the highest prediction accuracy of 99.55%, which is expected to be applied to actual vehicles."
A Survey on Improvements of RPL based on Machine Learning,2025,"['RPL', 'IoT', 'Congestion Control', 'Machine Learning']",,"RPL (the IPv6 Routing Protocol for Low-Power and Lossy Networks) is a de facto routing protocol for low-power and lossy networks, standardized by the IETF. Since RPL was designed with the objective to meet routing requirements defined for low-power and lossy networks and has been enhanced, optimized to meet the requirements for the target applications. Although the issues to be resolved are different depending on the application scenarios, congestion is always one of the common issues. As machine learning has made breakthroughs in innumerable areas, we observe that research to address the congestion problem in RPL-based networks based on machine learning significantly increased in recent years. In this article, we examine and compare some of the research papers and discuss future research direction."
Predicting forest above-ground biomass using SAR imagery and GEDI data through machine learning in GEE cloud,2025,"['Forest above-ground biomass', 'biosphere', 'machine learning', 'sentinel imagery', 'environment']",,"The estimation of Forest above-ground biomass (AGB) is critical for comprehending forest ecosystems and promoting biodiversity restoration. The study was conducted to develop an effective approach to predict Forest Above-Ground Biomass (AGB) using Machine Learning, Image Classification, and GEE open-source fast processing system in the Similipal Tiger Reserve (STR), India. The study utilized six machine learning models and integrated various data sources, including Sentinel-1 and Sentinel-2 imagery, forest canopy height data from NASA’s GEDI Global Ecosystems Dynamics Investigation-LiDAR, geo-environmental Shuttle Radar Topography Mission (SRTM) data, and Climate Hazards Group Infrared precipitation with Station (CHIRPS) data. Sentinel-based optical and Synthetic Aperture Radar (SAR) signatures were also extracted before and after the monsoon season to evaluate AGB in a subtropical region. The Random forest-based Boruta method was used to examine the importance of multiple factors contributing to the prediction’s accuracy. In addition, the assessment of multicollinearity, which is accomplished by measuring the variance inflation factor (VIF), was carried out to address the issue of interrelatedness among variables that could affect the accuracy of the AGB mapping. The Random Forest model exhibited superior accuracy compared to other models, achieving an R2 of 0.71, MAE of 16.12Mg/ha, RMSD of 22.27Mg/ ha, NRMSD of 0.212, and AUROC of 75%. The scatterplot analysis revealed a positive correlation between forest biomass and factors, such as forest canopy height, elevation, normalized differential vegetation index, normalized differential moisture index, and the ratio of VV/VH after the monsoon season. The VIF values ranged between 1.12 and 8.73, with VH_Jan_Mar having the maximum VIF and forest canopy height having the minimum VIF. As per the Boruta algorithm, 16 attributes were deemed important, while 14 attributes had less influence on AGB. The study presented a novel approach for estimating biomass in subtropical regions using remote sensing data set and machine learning models in Google platform. These results can be successfully used by the planners of STR for monitoring variation in AGB ensuring better habitat for wild animals."
Identification of tqg flavor-changing neutral current interactions using machine learning techniques,2025,['FCNC · Top quark · Transformer-based · Deep learning · Self-attention · Machine learning'],,"Flavor-changing neutral currents (FCNCs) are forbidden at tree level in the standard model (SM), but they can be enhanced in physics beyond the standard model (BSM) scenarios. In this paper, we investigate the effectiveness of deep learning techniques to enhance the sensitivity of current and future collider experiments to the production of a top quark and an asso ciated parton through the tqg FCNC process, which originates from the tug and tcg vertices. The tqg FCNC events can be produced with a top quark and either an associated gluon or quark, while SM only has events with a top quark and an associ ated quark. We apply machine learning techniques to distinguish the tqg FCNC events from the SM backgrounds, including qg-discrimination variables. We use the Boosted Decision Tree (BDT) method as a baseline classifier, assuming that the leading jet originates from the associated parton. We compare with a transformer-based deep learning method known as the Self-Attention for Jet-parton Assignment (SaJa) network, which allows us to include information from all jets in the event, regardless of their number, eliminating the necessity to match the associated parton to the leading jet. The SaJa network with qg-discrimination variables has the best performance, giving expected upper limits on the branching ratios Br(t → qg) that are 25–35% lower than those from the BDT method."
Crunch Mode: Make Early Predictions about Risk of Stroke Using Machine Learning,2025,"['Crunch Mode', 'Early Predictions', 'Risk of Stroke', 'Machine Learning', 'AI']",,"The term “Crunch Mode” refers to periods of intense, prolonged work aimed at meeting deadlines or achieving critical goals. However, extended work in this state can have severe health consequences, including an increased risk of stroke. A stroke occurs when the brain’s blood supply is interrupted or reduced, leading to oxygen and nutrient deprivation that can result in brain cell death. According to the World Health Organization (WHO), stroke is a leading cause of death and disability worldwide. Recognizing early warning signs is crucial in mitigating its impact. This paper employs machine learning techniques to predict the likelihood of an early-stage stroke, as even a mild stroke can cause lasting brain damage, while a severe stroke may be fatal. In this paper, we use machine learning models to predict stroke risk early based on a reliable dataset for stroke prediction that was taken from the Kaggle website."
Performance and clinical implications of machine learning models for detecting cervical ossification of the posterior longitudinal ligament: a systematic review,2025,"['Ossification of posterior longitudinal ligament', 'Machine learning', 'Deep learning', 'Diagnosis', 'Neural networks']",,"Ossification of the posterior longitudinal ligament (OPLL) is a significant spinal condition that can lead to severe neurological deficits. Re- cent advancements in machine learning (ML) and deep learning (DL) have led to the development of promising tools for the early detec- tion and diagnosis of OPLL. This systematic review evaluated the diagnostic performance of ML and DL models and clinical implications in OPLL detection. A systematic review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-Anal- yses guidelines. PubMed/Medline and Scopus databases were searched for studies published between January 2000 and September 2024. Eligible studies included those utilizing ML or DL models for OPLL detection using imaging data. All studies were assessed for the risk of bias using appropriate tools. The key performance metrics, including accuracy, sensitivity, specificity, and area under the curve (AUC), were analyzed. Eleven studies, comprising a total of 6,031 patients, were included. The ML and DL models demonstrated high di- agnostic performance, with accuracy rates ranging from 69.6% to 98.9% and AUC values up to 0.99. Convolutional neural networks and random forest models were the most used approaches. The overall risk of bias was moderate, and concerns were primarily related to participant selection and missing data. In conclusion, ML and DL models show great potential for accurate detection of OPLL, particularly when integrated with imaging techniques. However, to ensure clinical applicability, further research is warranted to validate these find- ings in more extensive and diverse populations."
Predicting MBS Early Prepayment Rates Under External Shocks  Using Machine Learning  - Global Financial Crisis vs. COVID-19,2025,"['MBS(Mortgage-Backed Securities)', 'Prepayment Rates', 'Machine Learning', 'Global Financial Crisis', 'COVID-19.']",,"Purpose: This study aims to predict monthly prepayment rates of Mortgage-Backed Securities (MBS) issued by the Korea Housing Finance Corporation, focusing on the effects of external shocks such as the financial crisis and COVID-19. Research design: The research compares traditional fixed-effects regression models with machine learning techniques (ElasticNet, LASSO, Ridge) to determine which model best predicts MBS prepayment rates before and after external shocks. Data and methodology: The study uses monthly data from June 2004 to December 2020, analyzing MBS prepayment rates alongside various macroeconomic variables. The performance of each model is assessed using cross-validation and blocked cross-validation methods to evaluate stability under different economic conditions. Results: Machine learning models, particularly ElasticNet, consistently outperform traditional regression models. ElasticNet showed the highest predictive accuracy, with a stable performance even after the financial crisis and COVID-19, unlike traditional models that struggled to adapt to the shocks. Conclusions: The study concludes that machine learning models, especially ElasticNet, offer superior predictive performance in forecasting MBS prepayment rates, especially in volatile market conditions, and should be considered over traditional models for financial predictions."
Bacterial profile-based body fluid identification using a machine learning approach,2025,['Bacterial profiles · Body fluid identification · Machine learning · DNA metabarcoding'],,"Background Identifying the origins of biological traces is critical for the reconstruction of crime scenes in forensic investigations. Traditional methods for body fluid identification rely on chemical, enzymatic, immunological, and spectroscopic techniques, which can be sample-consuming and depend on simple color-change reactions. However, these methods have limitations when residual samples are insufficient after DNA extraction.Objective This study aimed to develop a method for body fluid identification by leveraging bacterial DNA profiling to overcome the limitations of the conventional approaches.Methods Bacterial profiles were determined by sequencing the hypervariable region of the 16 S rRNA gene, using DNA metabarcoding of evidence collected from criminal cases. Amplicon sequence variants (ASVs) were analyzed to identify significant microbial patterns in different body fluid samples.Results The bacterial profile-based method demonstrated high discriminatory power with a machine learning model trained using the naïve Bayes algorithm, achieving an accuracy of over 98% in classifying samples into one of four body fluid types: blood, saliva, vaginal secretion, and mixture traces of vaginal secretions and semen.Conclusion Bacterial profiling enhances the accuracy and robustness of body fluid identification in forensic analysis, providing a valuable alternative to traditional methods by utilizing DNA and microbial community data despite the uncontrollable conditions. This approach offers significant improvements in the classification accuracy and practical applicability in forensic investigations."
Optimizing business strategies for carbon energy management in buildings: a machine learning approach in economics and management,2025,['Carbon energy management Deep reinforcement learning (DRL) Statistical validity tests Sensitivity analysis Monte Carlo simulations Economic impact analysis'],,"Optimizing business strategies for energy through machine learning involves using predictive analytics for accurate energy demand and price forecasting, enhancing operational efficiency through resource optimization and predictive maintenance, and optimizing renewable energy integration into the energy grid. This approach maximizes production, reduces costs, and ensures stability in energy supply. The novelty of integrating deep reinforcement learning (DRL) in energy management lies in its ability to adapt and optimize operational strategies in real-time, autonomously leveraging advanced machine learning techniques to handle dynamic and complex energy environments. The study’s outcomes demonstrate the effectiveness of DRL in optimizing energy management strategies. Statistical validity tests revealed shallow error values [MAE: 1.056 × 10(−13) and RMSE: 1.253 × 10(−13)], indicating strong predictive accuracy and model robustness. Sensitivity analysis showed that heating and cooling energy consumption variations significantly impact total energy consumption, with predicted changes ranging from 734.66 to 835.46 units. Monte Carlo simulations revealed a mean total energy consumption of 850 units with a standard deviation of 50 units, underscoring the model’s robustness under various stochastic scenarios. Another significant result of the economic impact analysis was the comparison of different operational strategies. The analysis indicated that scenario 1 (high operational costs) and scenario 2 (lower operational costs) both resulted in profits of $70,000, despite differences in operational costs and revenues. However, scenario 3 (optimized strategy) demonstrated superior financial performance with a profit of $78,500. This highlights the importance of strategic operational improvements and suggests that efficiency optimization can significantly enhance profitability. In addition, the DRL-enhanced strategies showed a marked improvement in forecasting and managing demand fluctuations, leading to better resource allocation and reduced energy wastage. Integrating DRL improves operational efficiency and supports long-term financial viability, positioning energy systems for a more sustainable future."
Investigation on the thermal characteristics of electronic system and prediction of chip temperature by machine learning,2025,"['Nuclear', 'Electronic system', 'Thermal', 'Chip temperature', 'Finite element analysis', 'Machine learning']",,"In this work, the thermal characteristics and steady-state temperatures (SST) of CPU and FPGA of electronic system in nuclear power plant are explored. Finite element analysis is performed to simulate the test process.Furthermore, three machine learning algorithms are used to predict chips temperatures at different operating conditions. It is found that when the ambient temperature is 20 ◦C and all the fans are power-off, the SST of the CPU and FPGA reaches 75 ◦C and 72 ◦C, respectively. While when the fans are power-on, the SST of the CPU and FPGA drops to 37.5 ◦C and 33 ◦C. When the ambient temperature increases to 55 ◦C and all the fans are poweron, the SST of the CPU and FPGA is 72.3 ◦C and 68.2 ◦C, respectively. The finite element model is verified and used to generate test data. Three machine learning models are verified by predicting the SST of CPU and FPGA under different operating conditions. It is found that M-SVR has better prediction ability than DT and ANN. The findings can be used for chip reliability evaluation of other electronic system devices, and provide a new method for predicting the possible steady-state temperature of chips under different service conditions."
An analysis based on multi criteria strategies using machine learning and statistics for pulses crop yield analysis in Tamil Nadu region,2025,"['Crop yield estimation', 'coefficient of determination', 'performance metrics', 'regression analysis', 'sustainable Agriculture.']",,"Agriculture plays a crucial role in India's economic expansion. However, increasing population and a continuously changing climate significantly impact crop productivity and national food security. The agricultural sector operates within a complex system, generating vast amounts of data from multiple variables. Machine learning, when applied dynamically and efficiently, has the potential to enhance agricultural decision-making by predicting crop yields, selecting optimal crops for cultivation, and determining the best treatment strategies throughout the growing season. Various approaches exist for predicting crop production using environmental variables, and this research investigates some of these methods. The primary objective of this paper is to develop a machine learning model alongside a statistical approach for yield prediction. In addition to improving efficiency, machine learning algorithms and statistical techniques can assist farmers in selecting the most suitable crops by considering multiple influencing factors. This study explores the effectiveness of several machine learning methods in agricultural applications. The techniques examined include elastic net regression, ridge regression, least absolute shrinkage and selection operator (LASSO) regression, artificial neural networks (ANN), and extreme gradient boosting (XG Boost). The performance of these models was evaluated using R-squared $(R^2)$, mean absolute error (MAE), root mean squared error (RMSE), mean squared error (MSE), and mean bias deviation (MBD)."
Classifying Radiation Degradation of Epoxy Molding Compound by Using Machine Learning and its Effect on Thermal and Mechanical Properties,2025,['Epoxy molding compound · Total ionizing dose test · Gamma radiation · Polymer degradation · Fourier transform infrared spectroscopy · Machine learning · Thermal conductivity test · Nanoindentation'],,"Power semiconductors play a crucial role in power conversion applications within nuclear power plants. These semiconductors are enclosed using polymeric materials for cost-effectiveness. Researchers have substantiated that polymeric materials are subject to radiation-induced degradation in nuclear power plants, prompting reliability studies. Consequently, investigating the radiation degradation behavior of polymeric materials becomes imperative to ensure their reliability and stability. This study focuses on the degradation of epoxy molding compound (EMC), a type of polymeric material, under the influence of total ionizing dose (TID). To analyze the effects of TID conditions on EMC, data was collected and subjected to various tests, including FTIR (Fourier Transform Infrared Spectroscopy) spectroscopy, thermal conductivity testing, and nanoindentation testing. These tests were conducted to assess chemical changes, thermal properties, and mechanical properties of EMC as a consequence of TID exposure. TID induces random ionization damage of EMC.Five EMC samples with different total cumulative doses were produced by varying the TID exposure time. Spectral data were obtained from the fabricated EMC samples by FTIR spectroscopy. FTIR spectral data was used to build a machine learning model, and the degree of EMC performance degradation due to TID exposure was determined. In our study, we selected an optimal algorithm among six machine learning algorithms. Dimensionality reduction methods such as ReliefF and PCA were also applied to build a more simplified discriminant model. As a result, it was confirmed that radiation changed the thermal properties of EMC materials. However, no change in the mechanical properties of EMC was observed under our test conditions."
Optimal Machine Learning Model Selection for Predicting Cancer Drug Response Using Genomic Data,2025,"['Machine Learning', 'CatBoost', 'Cancer Drug Sensitivity', 'Genomic Data']",,"In this paper, we investigate the optimal machine learning model for predicting drug response in cancer cells by leveraging genomic data, with an emphasis on clinical applicability. Utilizing the Cancer Drug Sensitivity Genomics dataset, we integrated diverse genetic characteristics, including gene mutations, copy number variations, and gene expression levels, along with drug response data. A structured data preprocessing pipeline was implemented, including mode replacement for tissue and cancer types, K-Nearest Neighbors imputation for genetic features, and Random Forest Regressor for handling missing numerical values. Regression models, such as Random Forest, K-Nearest Neighbors, Decision Tree, and CatBoost, were trained and evaluated for predictive performance. Experimental results revealed that the CatBoost model outperformed others, achieving a mean squared error of 1.5618, mean absolute error of 0.9355, and an R² score of 0.7855, with the Random Forest model showing comparable performance. These findings highlight the CatBoost model as a robust tool for predicting cancer drug response. Furthermore, this research underscores its potential integration into clinical decision-making systems by enabling personalized drug selection based on patient-specific genetic profiles. Future research may extend this approach to incorporate additional omics data and validate the model's utility in real-world clinical scenarios."
Hybrid machine learning model with optimization algorithm for predicting the incubation dose of void swelling in irradiated metals,2025,"['Void swelling', 'Incubation dose', 'Machine learning', 'Hybrid model', 'Harris hawks optimization', 'Categorical gradient boosting', 'Radiation damage']",,"This study introduces novel hybrid machine learning (ML) models that integrate six state-of-the-art ML algorithms with the Harris Hawks Optimization (HHO) algorithm to enhance the prediction of the incubation dose in irradiated metals. A comprehensive database comprising 305 experimental samples with 24 input features is used to develop the models, with hyperparameters optimized through a combination of cross-validation method and HHO. Performance evaluation across various metrics identifies the hybrid model combining HHO and categorical gradient boosting (CGB), named HHO-CGB, as the most accurate and stable for predicting the incubation dose. To gain further insights, the Shapley Additive Explanations method is employed to assess the global and local contributions of input variables, revealing Fe (wt.%), temperature (K), dose rate (dpa/s), and V (wt.%) as the most influential factors. Finally, a user-friendly graphical interface tool and web application are developed based on the HHO-CGB model, providing a practical and cost-effective solution for predicting the incubation dose of irradiated metals."
Using machine learning techniques for early prediction of tracheal intubation in patients with septic shock: a multi-center study in South Korea,2025,"['intubation', 'machine learning', 'septic shock']",,"Background: Patients with septic shock frequently require tracheal intubation in the emergency department (ED). However, the criteria for tracheal intubation are subjective, based on physician experience, or require serial evaluations over relatively long intervals to make accurate predictions, which might not be feasible in the ED. We used supervised learning approaches and features routinely available during the initial stages of evaluation and resuscitation to stratify the risks of tracheal intubation within a 24-hour time window.Methods: We retrospectively analyzed the data of patients diagnosed with septic shock based on the SEPSIS-3 criteria across 21 university hospital EDs in the Republic of Korea. A principal component analysis revealed a complex, non-linear decision boundary with respect to the application of tracheal intubation within a 24-hour time window. Stratified five-fold cross validation and a grid search were used with extreme gradient boost. Shapley values were calculated to explain feature importance and preferences.Results: In total, data for 4,762 patients were analyzed; within that population, 1,486 (31%) were intubated within a 24-hour window, and 3,276 (69%) were not. The area under the receiver operating characteristic curve and F1 scores for intubation within a 24-hour window were 0.829 (95% CI, 0.801–0.878) and 0.654 (95% CI, 0.627–0.681), respectively. The Shapley values identified lactate level after initial fluids, suspected lung infection, initial pH, Sequential Organ Failure Assessment score at enrollment, and respiratory rate at enrollment as important features for prediction. Conclusions: An extreme gradient boosting machine can moderately discriminate whether intubation is warranted within 24 hours of the recognition of septic shock in the ED."
Integrating machine learning with proof-of-authority-and-association for dynamic signer selection in blockchain networks,2025,['BlockchainConsensus algorithmMachine learningProof of authorization and association (PoA2)'],,"Integrating machine learning (ML) into blockchain consensus mechanisms enhances efficiency, scalability, and resilience. This study introduces the PoA algorithm, an ML-enhanced Proof of Authority mechanism that optimizes signer selection for improved transaction processing. Simulations with models including Random Forest, Logistic Regression, SVM, K-Nearest Neighbors, Decision Tree, and Gradient Boosting showed significant gains. Random Forest reduced latency tenfold, achieving nearly 1000 transactions per second, with 93.33% accuracy, 100% precision, 86.67% recall, and a 92.86% F1-score. These results demonstrate ML’s potential to enhance blockchain performance, making hybrid blockchain-ML solutions a promising research direction."
A Machine Learning Modeling Method for Switched Reluctance Motors Based on Few Preprocessed Flux Linkage Data,2025,['Switched reluctance motor · Nonlinear modeling · Data preprocessing · Support vector regression algorithm · Improved tuna swarm algorithm'],,"This article proposes a machine learning method to build the model of a switched reluctance motor (SRM) using few preprocessed fl ux linkage data. Firstly, the improved torque balance method is used to obtain the accurate fl ux linkage data without redundant experiments. Secondly, two special data preprocessing steps are proposed, which are nonlinear preprocessing and angle mapping, respectively. The fi rst step provides benefi cial nonlinearity for algorithms, and the second step improves the linearity of fl ux linkage at small angles by the proposed mapping function. Thirdly, support vector regression algorithm optimized by the improved tuna swarm algorithm (ITSO-SVR) is employed to establish the fl ux linkage model.Based on the fl ux linkage model, the current and torque models are easily built by ITSO-SVR to complete the nonlinear modelling of SRM. Finally, the eff ectiveness of the proposed method is verifi ed. The preprocessing method is verifi ed to reduce the modeling diffi culty. Besides, ITSO-SVR facilitates the swift and effi cient modeling without any pre-storge or complex calculations. The experiments under the CCC and APC algorithms indicate that the established model exhibits high accuracy, fast speed and strong generalization capability."
Supervised Machine Learning for Frailty Classification using Physical Performance Measures in Older Adults,2025,"['Frailty', 'Machine learning', 'Older adults', 'Physical performances', 'Sarcopenia']",,"Background Frailty is an important condition to detect in its early stages to prevent progression to more severe stages in older adults. Age-related declines in physical performance are strongly associated with frailty.Purpose This study aims to develop a frailty classification model by comparing the performance of machine learning models based on physical performance measures in community-dwelling older adults.Study design A cross-sectional study Methods Physical performance data were collected from older adults aged ≥65 years. Frailty classification models were developed using logistic regression, support vector machine (SVM), K-nearest neighbors (KNN), decision tree, and random forest. Clinical features including short physical performance battery, single-leg stance, SARC-F, body mass index, and mini-mental state examination (MMSE) were used as input variables for model development. The performance of each model was evaluated using accuracy, sensitivity, specificity, precision, F1-score, and area under the receiver operating characteristic curve (AUC). Permutation feature importance was employed to identify key predictors of frailty.Results The KNN model demonstrated the highest classification performance, achieving an accuracy of 0.93, an F1-score of 0.95, and an AUC of 0.86, indicating its suitability for frailty assessment. The logistic regression model achieved an accuracy of 0.86, an F1-score of 0.89, and an AUC of 0.98. The random forest model showed similar results, with an accuracy of 0.86, an F1-score of 0.88, and an AUC of 0.96. The SVM model recorded an accuracy of 0.79, an F1-score of 0.84, and an AUC of 0.80. The decision tree model showed the lowest performance, with an accuracy of 0.71, an F1-score of 0.78, and an AUC of 0.64. Feature importance analysis revealed that MMSE and SARC-F were the most influential predictors in the KNN model.Conclusions This study demonstrates that KNN is well-suited for identifying subtle variations in physical function that contribute to frailty. The results highlight its potential for clinical implementation in automated frailty screening. Feature importance analysis provides insight into key predictors, supporting personalized assessment strategies. However, due to the small sample size, further research is needed to assess the generalizability of frailty classification models in larger populations."
A Reanalyzing of Structured Data Classification Model Using Artificial Neural Network Based on a Machine Learning,2025,"['데이터마이닝', '머신러닝', '분류', '인공신경망', '지도학습', 'Data mining', 'Machine learning', 'Classification', 'Artificial neural network', 'Supervised learning']",,
"A Machine Learning Approach for Predicting In-Hospital Cardiac Arrest Using Single-Day Vital Signs, Laboratory Test Results, and International Classification of Disease-10 Block for Diagnosis",2025,"['Cardiac arrest', 'Diagnosis', 'Hospital', 'International Classification of Disease', 'Machine learning', 'Prediction']",,"Background: Predicting in-hospital cardiac arrest (IHCA) is crucial for potentially reducing mortality and improving patient outcomes. However, most models, which rely solely on vital signs, may not comprehensively capture the patients’ risk profiles. We aimed to improve IHCA predictions by combining vital sign indicators with laboratory test results and, optionally, International Classification of Disease-10 block for diagnosis (ICD10BD).Methods: We conducted a retrospective cohort study in the general ward (GW) and intensive care unit (ICU) of a 680-bed secondary healthcare institution. We included 62,061 adults admitted to the Department of Internal Medicine from January 2010 to August 2022. IHCAs were identified based on cardiopulmonary resuscitation prescriptions. Patient- days within three days preceding IHCAs were labeled as case days; all others were control days. The eXtreme Gradient Boosting (XGBoost) model was trained using daily vital signs, 14 laboratory test results, and ICD10BD.Results: In the GW, among 1,299,448 patient-days from 62,038 patients, 1,367 days linked to 713 patients were cases. In the ICU, among 117,190 patient-days from 16,881 patients, 1,119 days from 444 patients were cases. The area under the ROC curve for IHCA prediction model was 0.934 and 0.896 in the GW and ICU, respectively, using the combination of vital signs, laboratory test results, and ICD10BD; 0.925 and 0.878, respectively, with vital signs and laboratory test results; and 0.839 and 0.828, respectively, with only vital signs.Conclusions: Incorporating laboratory test results or combining laboratory test results and ICD10BD with vital signs as predictor variables in the XGBoost model potentially enhances clinical decision-making and improves patient outcomes in hospital settings."
Predicting Housing Price in Seoul using Explainable AI (XAI) and Machine Learning,2025,"['Housing Price', 'Machine Learning', 'XGBoost', 'XAI', 'SHAP (SHapley Additive exPlanations)']",,"This study analyzed 61,593 cases of real transaction price of apartments in Seoul from January 1, 2021 to September 30, 2023, with the output variable being set as the sales price per dedicated area and the input variables being set as the contract month, floor, year of construction, number of units, and distance to the subway station, etc. After determining which of the machine learning (ML) models, LGBM, XGBoost, and GBDT, had the best predictive power, the importance of each variable was analyzed using XAI's SHAP (SHapley Additive exPlanations) technique. The R2 value of XGBoost was 0.917, MAE value was 134.971, and RMSE value was 191.325, showing the best predictive power. According to the results of applying the SHAP technique to the XGBoost model, heating method, year of construction, distance to subway station, contract month, number of households, distance to market, distance to middle school, distance to high school, distance to elementary school, number of floors, home network, contract date, and management method have the highest influence and importance on the sales price per dedicated area."
Integrating Conventional and Machine Learning Approaches for Analyzing Pain Experience in Adolescents with Temporomandibular Disorders: A Comparative Study,2025,"['Adolescent psychology', 'Machine learning', 'Pain measurement', 'Regression analysis', 'Temporomandibular joint disorders']",,"Purpose: Temporomandibular disorders (TMD) are multifactorial conditions influenced by pain severity (PS), psychosocial distress, and sleep disturbances. This study integrates conventional regression models and machine learning (ML)-based decision trees to enhance understanding of pain interference in adolescents with TMD.Methods: A retrospective analysis of 662 patients were conducted using clinical data and self-reported questionnaires: the Brief Pain Inventory, the Pain Catastrophizing Scale, the Symptom Cheklist-90-Revised, the Pittsburgh Sleep Quality Index. Linear and logistic regression models identified key predictors, while decision tree models stratified patient subgroups based on threshold-based classifications. Model performance was assessed.Results: Both regression and decision tree models identified PS and pain catastrophizing as the model critical predictors of pain interference. Regression models quantified statistical significance and effect sizes, explaining 65% of variance. Decision trees provided hierarchical stratifications, revealing that patients with high PS and catastrophizing experienced significantly greater pain interference. Sleep quality influenced subgroups but was not a primary splitting factor. Decision trees achieved an R2 of 0.54 for regression and 0.26 for classification, indicating moderate predictive power.Conclusions: Conventional regression models provide inferential clarity, while ML-based decision trees enhance clinical interpretability through subgroup identification. Combining these approaches optimizes patient stratification and supports personalized treatment strategies."
Development of Machine Learning Models to Categorize Life Satisfaction in Older Adults in Korea,2025,"['Aged', 'Classification', 'Machine learning', 'Personal satisfaction']",,"Objectives: This study aimed to identify factors associated with life satisfaction by developing machine learning (ML) models to predict life satisfaction in older adults living alone.Methods: Data were extracted from 3112 older adults participating in the 2020 Korea Senior Survey. We employed 5 ML models to classify the life satisfaction of older adults living alone: logistic Lasso regression, decision tree-based classification and regression tree (CART), C5.0, random forest, and extreme gradient boost (XGBoost). The variables used as predictors included demographics, health status, functional abilities, environmental factors, and activity participation. The performance of these ML models was evaluated based on accuracy, precision, recall, F1-score, and area under the curve (AUC). Additionally, we assessed the significance of variable importance as indicated by the final classification models.Results: Out of the 1411 older adults living alone, 45.3% expressed satisfaction with their lives. The XGBoost model surpassed the performance of other models, achieving an F1-score of 0.72 and an AUC of 0.75. According to the XGBoost model, the five most important variables influencing life satisfaction were overall community satisfaction, self-rated health, opportunities to interact with neighbors, proximity to a child, and satisfaction with residence.Conclusions: Overall satisfaction with the community environment emerged as the most significant predictor of life satisfaction among older adults living alone. These findings indicate that enhancing the supportiveness of the community environment could improve life satisfaction for this demographic."
Role of Artificial Intelligence (AI) and Machine Learning (ML) in Food Safety and Quality Improvement,2025,"['Artificial Intelligence', 'Machine Learning', 'Food Safety', 'Food Quality']",,"Artificial intelligence (AI) and machine learning (ML) are transforming food processing by enhancing safety, detecting foodborne pathogens and contaminants, improving quality control, and optimizing supply chains. These technologies enable faster, data-driven decision-making, addressing food security challenges while promoting sustainability. Over the past decade, AI and ML have significantly advanced food safety management, from contamination detection to supply chain optimization. This review explores AI’s contributions to efficiency and sustainability in the food sector, examining key advancements, challenges, and future prospects. By analyzing successful applications, the study highlights how AI, ML, and big data can enhance decision-making and drive sustainable food security."
Explainability Enhanced Machine Learning Model for Classifying Intellectual Disability and Attention-Deficit/Hyperactivity Disorder With Psychological Test Reports,2025,"['Neurodevelopmental Disorder', 'Intellectual Disability', 'Attention-Deficit Hyperactivity Disorder Psychological Test Reports', 'Natural Language Processing', 'Machine Learning', 'Explainable Model']",,"Background: Psychological test reports are essential in assessing intellectual functioning, aiding in diagnosing and treating intellectual disability (ID) and attention-deficit/ hyperactivity disorder (ADHD). However, these reports can have several problems because they are diverse, unstructured, subjective, and involve human errors. Additionally, physicians often do not read the entire report, and the number of reports is lower than that of diagnoses.Methods: We developed explainable predictive models for classifying IDs and ADHDs based on written reports to address these issues. The reports of 1,475 patients with IDs and ADHDs who underwent intelligence tests were used for the models. These models were developed by analyzing reports using natural language processing (NLP) and incorporating the physician’s diagnosis for each report. We selected n-gram features from the models’ results by extracting important features using SHapley Additive exPlanations and permutation importance to make the models explainable. Developing the n-gram feature-based original text search system compensated for the lack of human readability caused by NLP and enabled the reconstruction of human-readable texts from the selected n-gram features.Results: The maximum model accuracy was 0.92, and the 80 human-readable texts were restored from four models.Conclusion: The results showed that the models could accurately classify IDs and ADHDs, even with a few reports. The models were also able to explain their predictions. The explainability-enhanced model can help physicians understand the classification process of IDs and ADHDs and provide evidence-based insights."
Application of Machine Learning Algorithms for Risk Stratification and Efficacy Evaluation in Cervical Cancer Screening Among the ASCUS/LSIL Population: Evidence from the Korean HPV Cohort Study,2025,"['Human papillomavirus', 'Risk stratification', 'Atypical squamous cells of the cervix', 'Squamous intraepithelial lesions']",,"Purpose We assessed human papillomavirus (HPV) genotype-based risk stratification and the efficacy of cytology testing for cervical cancer screening in patients with atypical squamous cells of undetermined significance (ASCUS)/low-grade squamous intraepithelial lesion (LSIL).Materials and Methods Between 2010 and 2021, we monitored 1,273 HPV-positive women with ASCUS/LSIL every 6 months for up to 60 months. HPV infections were categorized as persistent (HPV positivity consistently observed post-enrollment), negative (HPV negativity consistently observed post-enrollment), or non-persistent (neither consistently positive nor negative). HPV genotypes were grouped into high-risk (Hr) groups 1 (types 16, 18, 31, 33, 45, 52, and 58) and 2 (types 35, 39, 51, 56, 59, 66, and 68) and a low-risk group. Hr1 was subdivided into types (a) 16 and 18; (b) 31, 33, and 45; and (c) 52 and 58. Cox regression and machine learning (ML) algorithms were used to analyze progression rates.Results Among 1,273 participants, 17.6% with persistent HPV infections experienced disease progression versus no progression in the HPV-negative group (p < 0.001). Cox analysis revealed the highest hazard ratios (HRs) for Hr1-a (11.6, p < 0.001), followed by Hr1-b (9.26, p < 0.001) and Hr1-c (7.21, p < 0.001). HRs peaked at 12-24 months, with Hr1-a maintaining significance at 24-36 months (10.7, p=0.034). ML analysis identified the final cytology change pattern as the most significant factor, with 14-15 months the optimal time for detecting progression from the first examination.Conclusion In ASCUS/LSIL cases, follow-up strategies should be based on HPV risk types. Annual follow-up was the most effective monitoring for detecting progression/regression."
Application of machine learning for quantitative analysis of industrial fermentation using image processing,2025,['Fermentation Fermentation quantification sensor Machine learning AI Vision system'],,"The Real-time Fermentation Quantification Sensor (RFQS) was developed to quantitatively assess fermentation by detecting airlock bubbles created by fermentation gas pressure. The Convolutional Neural Network-based Fermentation Measurement Model was integrated into the RFQS to analyze and classify these bubble images, enabling continuous fermentation monitoring and real-time fermentation degree measurement. Validation experiments revealed that varying the quantities of dry yeast and glucose significantly impacted fermentation duration and degree. Upon fermentation completion, the total degree was calculated using real-time data. These results confirmed that AI-based image processing technology can effectively serve as a quantitative measurement tool in the fermentation food industry."
Reliability Assessment and Fault Prediction in a 13-Level Multilevel Inverter Through Machine Learning with SVM,2025,['Failure rate · Machine learning · MIL-HDBK-217F N2 · Reliability analysis · SVM'],,"Multilevel inverters appear to be a potential substitute for traditional inverters in medium-power applications. Real-time applications now heavily rely on modern power converters from renewable energy sources. This study examines the factors that afect the failure rate of power semiconductor devices, including temperature and current rating. The bathtub curve determines the lifespan of the gadget. This article makes a thirteen-level asymmetric multilevel inverter by using fewer switches and has undergone a thorough analysis to determine switching loss, conduction loss, and failure rate in terms of reliability. This study investigates the prediction of defects in switches within a 13-level multilevel inverter using four machine learning models. Our investigation demonstrates that the Support Vector Machine (SVM) model surpasses other models with a remarkable accuracy rate of 96.56%. The abstract outlines the creation of a confusion matrix specifcally for Support Vector Machines (SVM), providing a comprehensive analysis of key parameters including Accuracy, Precision, Recall, and F1 score. The study emphasizes the SVM model’s robustness, providing insights into its training and validation accuracy for fault detection in switches."
Laboratory Data as a Potential Source of Bias in Healthcare Artificial Intelligence and Machine Learning Models,2025,"['Aggregation bias', 'Artificial intelligence', 'Clinical pathology', 'Diagnostic error', 'Health information interoperability', 'Logical Observation Identifiers Names and Codes', 'Machine learning', 'SNOMED CT']",,"Artificial intelligence (AI) and machine learning (ML) are anticipated to transform the practice of medicine. As one of the largest sources of digital data in healthcare, laboratory results can strongly influence AI and ML algorithms that require large sets of healthcare data for training. Embedded bias introduced into AI and ML models not only has disastrous consequences for quality of care but also may perpetuate and exacerbate health disparities.The lack of test harmonization, which is defined as the ability to produce comparable results and the same interpretation irrespective of the method or instrument platform used to produce the result, may introduce aggregation bias into algorithms with potential adverse outcomes for patients. Limited interoperability of laboratory results at the technical, syntactic, semantic, and organizational levels is a source of embedded bias that limits the accuracy and generalizability of algorithmic models. Population-specific issues, such as inadequate representation in clinical trials and inaccurate race attribution, not only affect the interpretation of laboratory results but also may perpetuate erroneous conclusions based on AI and ML models in the healthcare literature."
Improving the accuracy of terrigenous reservoir porosity modeling based on machine learning methods,2025,"['Porosity', '3D geologic model', 'machine learning', 'random forest', 'boosting', 'support vector method', 'cross validation']",,"The purpose of this paper is to improve the prediction of porosity in Visean terrigenous sediments to increase the accuracy of digital static model of an oil field in Perm Krai. The study proposes an approach for porosity prediction based on machine learning methods, which can compensate for the shortcomings of traditional methods based on geophysical well logging data. Technical limitations of well logging and high geological heterogeneity often interfere with obtaining reliable porosity distribution data. The study uses such algorithms as Random Forest, Gradient Boosting, Support Vector method and Adaptive Boosted Decision Trees for porosity determination based on a set of geophysical methods. The developed model, trained on a specially created database using radioactive, electric and acoustic logs, model was implemented for real reservoir. Implementation of the model allowed to significantly refine the static model of the field and adjust the reserves estimation. The economic effect is achieved by reducing the cost of additional research and improving the efficiency of reservoir management. The proposed methodology has been successfully tested and can be used for other fields in the south of the Perm region, which opens up prospects for improving the efficiency of oil field development in the region"
A review on multi-fidelity hyperparameter optimization in machine learning,2025,['FidelityHyperparameterHyperparameter optimization (HPO)Machine learningMulti-fidelity HPO'],,"Tuning hyperparameters effectively is crucial for improving the performance of machine learning models. However, hyperparameter optimization (HPO) often demands significant computational budget, which is typically limited. Therefore, efficiently using this constrained budget is critical in HPO. Multi-fidelity HPO has emerged as a potential solution to this issue. This paper presents a comprehensive review of multi-fidelity HPO in machine learning, discusses recent algorithms for HPO, and proposes directions for future research."
Insights into irradiation creep coefficient in nuclear graphite from machine learning,2025,"['Nuclear graphite', 'Irradiation creep', 'Machine learning']",,"Understanding irradiation induced creep in nuclear graphite is critical for the service life extension of current reactor fleet and the technological advancement of next generation nuclear reactors. Nevertheless, qualifying a new graphite grade with respect to irradiation creep requires years of testing and expensive facilities for experiments.Here for the first time, we applied machine learning (ML) algorithms to investigate the irradiation creep coefficient in the secondary stage of graphite creep in hope of gaining new insights and expediting the qualification process. Four ML models were trained on a small dataset with temperature and materials properties as input. The gradient boosting regression model exhibits the best predicting performance. The ML models indicate that temperature and Young’s modulus are the most important parameters in the determination of creep coefficients while the rest properties have much weaker impact. These findings align with previous theories and corroborate a creep mechanism governed by dislocation climb, demonstrating the potential of ML in improving the workflow of graphite qualification for advanced reactors."
Recent advances in applications of machine learning in cervical cancer research: a focus on prediction models,2025,"['Cervical cancer', 'Artificial intelligence', 'Machine learning', 'Prognosis']",,"Artificial intelligence (AI) and machine learning (ML) are transforming cervical cancer research and offering advancements in diagnosis, prognosis, screening, and treatment. This review explores ML applications with particular emphasis on prediction models. A comprehensive literature search identified studies using ML for survival prediction, risk assessment, and treatment optimization. ML-driven prognostic models integrate clinical, histopathological, and genomic data to improve survival prediction and patient stratification. Screening methods, including deep-learning-based cytology analysis and human papillomavirus detection, enhance accuracy and efficiency. ML-driven imaging techniques facilitate early and precise cancer diagnosis, while risk prediction models assess susceptibility based on demographic and genetic factors. AI also optimizes treatment planning by predicting therapeutic responses and guiding personalized interventions. Despite significant progress, challenges remain regarding data availability, model interpretability, and clinical implementation. Standardized datasets, external validation, and cross-disciplinary collaborations are crucial for implementing ML innovations in clinical settings. Subsequent investigations should prioritize joint initiatives among data scientists, healthcare providers, and health authorities to translate AI innovations into real-world applications and to enhance the impact of ML on cervical cancer care. By synthesizing recent developments, this review highlights the potential of ML to improve clinical outcomes and shaping the future of cervical cancer management."
Thermodynamic and Electronic Descriptor-Driven Machine Learning for Phase Prediction in High-Entropy Alloys: Experimental Validation,2025,"['High-Entropy Alloys (HEAs)', 'Phase Prediction', 'Machine Learning (ML)', 'Thermodynamic Descriptors', 'Experimental Validation']",,Hanoi University of Science and Technology
Intelligent Indexing of Medical Data Based on Machine Learning,2025,"['Healthcare intelligent systems', 'learned index', 'machine learning', 'medical data indexing.']",,"The advent of the machine learning era means increasing data volumes and real-time data processing requirements especially in the medical field to improve the reliability of treatment results. Traditional data indexing has requirements on the storage space of medical devices and does not meet the characteristics of lightweight smart devices. In this paper, we propose a multi-dimensional medical data learned index, design novel mapping function for multi-dimensional data processing, and index multi-dimensional data using segmented linear function. It can efficiently perform data access and indexing processing on lightweight intelligent data processing devices and transmit abnormal data to medical centres. After a series of experiments, the results show that the proposed index supports direct data processing on lightweight intelligent data processing devices, which outperforms the traditional index by more than 10 times."
A Social Distancing Framework Based on GPS and Bluetooth Empowered by Feature-based Machine Learning Algorithm,2025,"['Covid', 'DELM', 'Social distancing', 'Machine learning algorithm']",,"The current COVID-19 epidemic is responsible for causing a catastrophe on a global scale due to its risky spread. The community’s insecurity is growing as a result of a lack of appropriate remedial measures and immunization against the disease. In this case, social distancing is thought to be an effective barrier against the spread of the contagion virus as the risk of virus transmission can be reduced by avoiding direct contact with people.Thus, the goal of this research is to develop and improve an AI (Artificial Intelligence) system architecture for social distance monitoring. The framework could also use the GPS (Global Positioning System) to recognize human separation through cell phones. The transition learning framework is also applied to improve the consistency of the existing system. In this manner, the detection system uses a pre-trained technique that takes a Bluetooth dataset and location-sharing dataset to link to an additional level. In an attempt to approximate social distancing breaches among people, we used Bluetooth technology along with GPS distance estimation and set a threshold. To predict if the distance value exceeds the required social distance standard, a violation threshold is calculated and then it sends an alarm to every individual who is not maintaining social distancing. In response, the individual who breaks the social distance limit is also monitored using a detection approach."
Feasibility of a Machine Learning Classifier for Predicting Post-Induction Hypotension in Non-Cardiac Surgery,2025,"['Anesthesia', 'general', 'artificial intelligence', 'general surgery', 'hypotension', 'machine learning']",,"Purpose: To develop a machine learning (ML) classifier for predicting post-induction hypotension (PIH) in non-cardiac surgeries.Materials and Methods: Preoperative data and early vital signs were obtained from 3669 cases in the VitalDB database, an opensource registry. PIH was defined as sustained mean arterial pressure (MAP) <65 mm Hg within 20 minutes since induction or from induction to incision. Six different ML algorithms were used to create binary classifiers to predict PIH. The primary outcome was the area under the receiver operating characteristic curve (AUROC) of ML classifiers.Results: A total of 2321 (63.3%) cases exhibited PIH. Among ML classifiers, the random forest regressor and extremely gradient boosting regressor showed the highest AUROC, both recording a value of 0.772. Excluding these models, the light gradient boosting machine regressor showed the second highest AUROC [0.769; 95% confidence interval (CI), 0.767–0.771], followed by the gradient boosting regressor (0.768; 95% CI, 0.763–0.772), AdaBoost regressor (0.752; 95% CI, 0.743–0.761), and automatic relevance determination regression (0.685; 95% CI, 0.669–0.701). The top three important features were mean diastolic blood pressure (DBP), minimum MAP, and minimum DBP from anesthetic induction to tracheal intubation, and these features were lower in cases with PIH (all p<0.001).Conclusion: ML classifiers exhibited moderate performance in predicting PIH, and have the potential for real-time prediction."
Prediction of the R³ Test‑Based Reactivity of Supplementary Cementitious Materials: A Machine Learning Approach Utilizing Physical and Chemical Properties,2025,"['Artificial neural network', 'R³ test', 'Modified strength activity index test', 'Material characterization']",,"This study utilized machine learning (ML) models to investigate the effect of physical and chemical properties on the reactivity of various supplementary cementitious materials (SCMs). Six SCMs, including ground granulated blast furnace slag (GGBFS), pulverized coal fly ash (FA), and ground bottom ash (BA), underwent thorough material characterization and reactivity tests, incorporating the modified strength activity index (ASTM C311) and the R³ (ASTM C1897) tests. A data set comprising 46 entries, derived from both experimental results and literature sources, was employed to train ML models, specifically artificial neural network (ANN), support vector machine (SVM), and random forest (RF). The results demonstrated the robustness of the ANN model, achieving superior prediction accuracy with a testing mean absolute error (MAE) of 9.6%, outperforming SVM and RF models. The study classified SCMs into reactivity classes based on correlation analysis, establishes a comprehensive database linking material properties to reactivity, and identifies key input parameters for predictive modeling. While most SCMs exhibited consistent predictions across types, GGBFS displayed significant variations, prompting a recommendation for the inclusion of additional input parameters, such as fineness, to enhance predictive accuracy. This research provided valuable insights into predicting SCM reactivity, emphasizing the potential of ML models for informed material selection and optimization in concrete applications."
A Sustainable Perspective: Using Machine Learning Approach to Predict the Donation Behavior of Used Smartphones in Indonesia to Extend Smartphone's Usage Life,2025,"['Electronic Waste', 'Circular Economy', 'Decision Tree', 'Random Forest', 'Neural Network']",,"The growing issue of electronic waste (e-waste) in Indonesia, driven by the short lifecycle of smartphones and limited interest in refurbished devices, highlights the need for sustainable disposal alternatives. This study investigates the factors influencing Indonesians' willingness to donate used smartphones, promoting e-waste reduction and digital access for underprivileged students in rural areas. Analyzing data from 416 respondents, we found that 57% ex-pressed willingness to donate, with key factors including device obsolescence, age, and involvement in social activi-ties. Machine learning models applied to predict donation behavior accurately predicting outcomes 91.67% of the time. The findings reveal the potential of functional but obsolete smartphones to address educational needs, offering a sustainable solution that bridges the digital divide and supports e-waste reduction. These insights guide strategies for social organizations to enhance donation programs, tackling both behavioral and logistical barriers for greater envi-ronmental and social impact."
Hydrogen concentration prediction in a Passive Autocatalytic Recombiner using machine learning algorithms,2025,"['Passive autocatalytic recombiner', 'Hydrogen prediction', 'Machine learning models']",,"Monitoring hydrogen levels within Nuclear Power Plants (NPPs) is crucial to mitigate potential risks during severe accidental scenarios. Passive Autocatalytic Recombiners (PARs), which operate passively through catalytic reactions, are installed in the containment to reduce hydrogen concentration. This study numerically investigates hydrogen behavior within PAR under various accident conditions. As the inlet temperature and hydrogen concentration increase, the reaction rate and maximum catalyst plate temperature rise. As the inflow velocity increases, the reaction amount rises, but the residence time for the reactions decreases, leading to an increase in the outlet hydrogen concentration. Leveraging the operational characteristics of the PAR, the present study develops a data-driven model to identify the correlations among the parameters associated with the PAR’s performance and to predict hydrogen concentration at the PAR’s outlet by adopting four machine learning algorithms: Artificial Neural Networks (ANN), k-nearest Neighbor (k-NN), Random Forest (RF), and Support Vector Regression (SVR). Using the PAR’s inlet variables of flow velocity, temperature, hydrogen concentration, and outlet temperature as input parameters, the ANN model demonstrates good predictive performance with R2 values of about 0.99. The predictive performance of the ANN model remains robust even without the inlet hydrogen information."
Drought prediction using advanced hybrid machine learning for arid and semi-arid environments,2025,"['Drought', 'Pelican optimization algorithm', 'SVM', 'ANFIS', 'ANN', 'Baluchestan']",,"Drought monitoring and forecasting are crucial for efficient water resources management, particularly in arid and semi-arid regions like South Baluchestan, a sub-basin in southeastern Iran known for its tropical fruit cultivation. This study aims to provide reliable predictions of the agricultural Standardized Precipitation Index (ASPI) at various time scales (1, 3, 6, and 12 months) using advanced hybrid machine learning models (ANN-POA, ANFIS-POA, and SVM-POA). Data from ten rain gauge and evaporation stations were utilized for this purpose. The results indicate that the SVM-POA model outperformed both ANN-POA and ANFIS-POA in predicting ASPI drought events. Interestingly, increasing the time scale led to a decrease in the frequency of drought events, while simultaneously causing them to last longer. Additionally, the accuracy of all forecasting methods improved with a longer time scale. A comprehensive evaluation of the models was conducted using six statistical indices (RMSE, MARE, BIAS, NSE, WI, CI), along with visualizations such as clustered column charts, Taylor diagrams, and time-series scatter plots. These findings highlight the potential of the SVM-POA model for short-term drought forecasting, which can significantly contribute to sustainable water resource management and support the cultivation of tropical fruits in the arid and semi-arid South Baluchestan sub-basin."
"Revealing VCAN as a Potential Common Diagnostic Biomarker of Renal Tubules and Glomerulus in Diabetic Kidney Disease Based on Machine Learning, Single-Cell Transcriptome Analysis and Mendelian Randomization",2025,"['Diabetic nephropathies', 'Kidney glomerulus', 'Kidney tubules', 'Machine learning', 'Mendelian randomization analysis', 'Single-cell gene expression analysis', 'VCAN protein', 'human']",,"Background: Diabetic kidney disease (DKD) is recognized as a significant complication of diabetes mellitus and categorized into glomerular DKDs and tubular DKDs, each governed by distinct pathological mechanisms and biomarkers.Methods: Through the identification of common features observed in glomerular and tubular lesions in DKD, numerous differentially expressed gene were identified by the machine learning, single-cell transcriptome and mendelian randomization.Results: The diagnostic markers versican (VCAN) was identified, offering supplementary options for clinical diagnosis. VCAN significantly highly expressed in glomerular parietal epithelial cell and proximal convoluted tubular cell. It was mainly involved in the up-regulation of immune genes and infiltration of immune cells like mast cell. Mendelian randomization analysis confirmed that serum VCAN protein levels were a risky factor for DKD, while there was no reverse association. It exhibited the good diagnostic potential for estimated glomerular filtration rate and proteinuria in DKD.Conclusion: VCAN showed the prospects into DKD pathology and clinical indicator."
Discovering the key symptoms for identifying patterns in functional dyspepsia patients: A doctor's decision and machine learning,2025,"['Functional dyspepsia', 'Pattern identification', 'Syndrome differentiation', 'Machine learning', 'Symptom importance']",,"Background: Pattern identification is a crucial diagnostic process in traditional East Asian medicine that involves classifying patients with similar symptom patterns. The aim of this study was to identify key symptoms for distinguishing patterns in patients with functional dyspepsia (FD) using explicit (doctor decision-based) and implicit (computational model-based) approaches.Methods: Data from twenty-one FD patients were collected from local traditional Korean medicine clinics and provided to three doctors in a standardized format. Each doctor identified three types of patterns: spleen-stomach weakness, spleen deficiency with qi stagnation/liver-stomach disharmony, and food retention. Doctors evaluated the importance of the symptoms indicated by items in the Standard Tool for Pattern Identification of Functional Dyspepsia questionnaire. Explicit importance was determined by surveying doctors, who performed a general evaluation and selected specific diagnostic information for patient cases. Implicit importance was assessed by feature importance from the random forest classification models, which classify the three pattern for general differentiation and perform binary classification for specific types.Results: Key symptoms for distinguishing FD patterns were identified via two approaches. The explicit importance highlighted dietary and nausea-related symptoms, whereas the implicit importance identified complexion or chest tightness as generally crucial. Specific symptoms important for particular pattern types were also identified, and significant correlations between implicit and explicit importance scores was observed for types 1 and 3.Conclusions: This study provides important clinical information for differentiating patients with FD using real patient data. Our findings suggest that these approaches may contribute to enhancing accuracy and reliability in the development of pattern identification tools."
Data-Driven Approach for Fault Diagnosis of Harmonic Drives Using Wireless Acceleration Sensors and Machine Learning,2025,"['Harmonic drive (HD) reducer', 'Fault diagnosis', 'Machine learning (ML)', 'Acceleration inertia sensor', 'Industrial robot']",,"Prognostics and health management (PHM) has become essential in modern industry, particularly for systems such as harmonic drives (HDs), also known as harmonic gears or gearboxes, which are specialized mechanical gearing systems used in industrial robots. The HD reducer, susceptible to various faults owing to continuous operation, requires timely PHM to maintain smooth and steady operations. Traditional methods for diagnosing HD reducer faults, such as demography analysis, calibration, and acoustic emission analysis, encounter various challenges. This study introduces a novel approach utilizing wireless data collection via an acceleration sensor for fault diagnosis, uniquely focusing on load and velocities, an area not explored in existing studies. By applying machine learning (ML) algorithms to the collected data, prominent features are identified from acceleration signals. Subsequently, the dataset is trained using various ML classification algorithms. The original features with kinetic energy-based signals perform better than other feature selection techniques. Specifically, the random forest classifiers achieve the highest accuracy of approximately 99.81%, significantly outperforming other classification algorithms such as k-nearest neighbors, decision tree, and XGBoost. Additionally, this study employed explainability tools, including Shapley Additive Explanations (SHAP) and local interpretable model-agnostic explanations (LIME), to enhance the interpretability of the diagnostic process."
Overview of DSP‑based implementation of machine learning methods for power electronics and motor drives,2025,"['Artificial intelligence (AI)', 'Digital signal processing (DSP)', 'Machine learning (ML)', 'Motor drives', 'Power electronics']",,"Digital signal processors (DSPs) are essential in power electronics and motor drives for industrial applications and academic research. The integration of machine learning (ML) into DSPs for these applications presents challenges such as limited data availability and the need for high-speed execution. Despite these difficulties, the researchers have developed successful strategies for incorporating ML into DSP frameworks. This work provides a comprehensive overview of integrating ML algorithms with DSPs in power electronics and motor drives, highlighting key strategies and addressing the challenges and innovations involved in optimizing these algorithms for practical use. A number of ML algorithms suitable for DSP implementation are also reviewed, with particular attention to a neural network-based surrogate model. Additionally, the review emphasizes real-time applications, such as fault detection, sensorless operation, and control, aiming to guide researchers on the effective implementation of ML in DSPs and encouraging the broader adoption of these integrated approaches across the industry."
Predicting Hotel Economic Trends Using Machine Learning and Time Series Analysis Models,2025,"['Hotel Economic Trends', 'ARIMA Model', 'Time Series Forecasting', 'Hotel Service Production Index', 'Machine Learning', '호텔 경기동향', 'ARIMA 모델', '시계열 예측', '호텔 서비스 생산지수', '머신러닝']",,"(Purpose) The purpose of this study is to construct a time-series forecast model for the hotel service production index using the ARIMA model to predict the hotel industry's economic trend, and to analyze its long-term growth and short-term volatility. This study aims to help hotel executives make strategic decisions to effectively respond to a rapidly changing market environment.(Design/methodology/approach) This study constructed the ARIMA model using 16 years of time-series data provided by KOSIS and the Korea Hotel Association. Through this, the service production index forecast of the hotel industry was carried out, and various statistical indicators were used to evaluate the accuracy of the forecast model. In addition, the prediction results were revalidated using various test datasets to improve the model's performance.(Findings) The ARIMA model has shown a high degree of suitability as a tool that can accurately predict not only the long-term growth trends of the hotel industry, but also short-term volatility. In particular, it was confirmed that the model can respond effectively in the event of unexpected economic shocks such as COVID-19. It provides a strategic foundation for hotel management to respond nimbly to market changes..(Research implications or Originality) In order to overcome the limitations of the time-series prediction model, this study developed a prediction model optimized for the hotel industry by comparing and analyzing machine learning techniques. In addition, customized forecasting models that can be applied to other service industries will be presented to provide basic data for related research."
Analyzing Model Hubs for Effective Composition of Pre-Trained Machine Learning Models,2025,"['소프트웨어 재사용', '소프트웨어 조합', '기계 학습', '사전 훈련된 기계 학습 모델', 'software reuse', 'software composition', 'machine learning', 'pre-trained models']",,"Deep Neural Network (DNN) models have become prevalent. They are increasingly adopted as components in software systems. Designing and training these DNNs from scratch is not trivial. Designing requires domain expertise and familiarity with DNN frameworks while training necessitates substantial computational resources and large training datasets. Following the philosophy of traditional software engineering, developers often reuse Pre-Trained Models (PTMs) organized in model hubs. However, challenges arise when PTMs that match a developer’s specific requirements are lacking. In this paper, we explored the concept of PTM composition and investigated whether a combination of PTMs could fulfill application requirements without needing fine-tuning or creating a new DNN. We present current challenges in PTM composition through our case study and identified shortcomings of existing model hubs. By drawing parallels between PTM composition and web service composition, we highlighted essential technologies required for successful PTM composition and discussed potential solutions to these issues."
Recommended System for Predicting Traffic Accident Costs using Enhanced Machine Learning Techniques,2025,['Recurrent neural networks · Attention mechanisms · Road safety · Road accident costs'],,"Road accidents get signifi cant costs to individuals, society, and infrastructure. To address this issue, we propose a comprehensive framework integrating enhanced machine learning techniques for predicting road accident costs. The problem statement revolves around the necessity for accurate forecasting of accident costs to inform policy decisions, allocate resources effi ciently, and improve road safety measures. Our proposed system leverages Recurrent Neural Networks (RNNs) with Attention Mechanisms to capture temporal dependencies and identify crucial features in USA Accidents dataset. The process fl ow of our framework begins with data preprocessing, including feature extraction and normalization, followed by the construction of the RNN-based predictive model. Attention mechanisms are employed to enhance the model’s capability to focus on relevant information within the input sequences, thereby improving prediction accuracy.The model is trained using historical accident data supplemented with contextual information such as weather conditions, road infrastructure, and demographic factors. Evaluation is conducted through rigorous cross-validation techniques and comparison with baseline models to assess the eff ectiveness of our approach. The results demonstrate that our proposed framework outperforms traditional methods and achieves superior predictive accuracy in estimating road accident costs.Furthermore, sensitivity analysis is conducted to assess the impact of diff erent factors on cost prediction, providing insights for stakeholders and policymakers. Overall, our framework off ers a robust and effi cient solution for predicting road accident costs, facilitating proactive measures to mitigate their adverse eff ects on society and infrastructure."
Tracking Cognitive Trajectories in Mild Cognitive Impairment Using a Machine Learning Technique of Subtype and Stage Inference,2025,"['Neuropsychology', 'Neurocognitive disorders', 'Mild Cognitive Impairment', 'Mental Status and Dementia Tests', 'Cognition']",,"Background and Purpose: Recognizing cognitive decline patterns in mild cognitive impairment (MCI) is crucial for early screening and preventive interventions. However, studies on the trajectory of individual cognitive functions in MCI are limited. Thus, the purpose of this study was to identify subtypes and stages of cognitive decline in MCI using a machine learning method.Methods: A total of 944 subjects consisting of those who were cognitively normal and those with MCI were enrolled. Fifteen neuropsychological tasks were used in the analysis.The optimal number of subtypes was determined based on the cross-validation information criterion. Fifteen stages of cognitive trajectory were estimated for each subtype.Results: The following three subtypes were identified: amnestic-verbal subtype, dysexecutive subtype, and amnestic-visual subtype. Of 723 (76.6%) subjects who had reached stage 1 at least, amnestic-verbal subtype accounted for the most (n=340, 47.0%), followed by dysexecutive subtype (n=253, 35.0%) and amnestic-visual subtype (n=130, 18%). The amnestic-verbal subtype had significantly more males (amnestic-verbal: 41.8%, dysexecutive: 31.2%, and amnestic-visual: 28.5%), younger subjects (amnestic-verbal: 72.01 years, dysexecutive: 74.43 years, and amnestic-visual: 75.06 years), higher educational years (amnestic-verbal: 11.06 years, dysexecutive: 9.53 years, and amnestic-visual: 9.79 years), lower Clinical Dementia Rating sum of boxes (amnestic-verbal: 1.40, dysexecutive: 1.61, and amnestic-visual: 1.71), and lower Korean-Instrumental Activities of Daily Living score (amnestic-verbal: 0.20, dysexecutive: 0.27, and amnestic-visual: 0.26).Conclusions: Three types of MCIs were extracted using SuStaIn. Pathways of MCI deterioration could be different. The amnestic type could be bisected based on whether episodic verbal or visual memory is degraded first."
Carbon emission prediction and reduction analysis of wastewater treatment plants based on hybrid machine learning models,2025,"['Carbon accounting', 'Carbon emission', 'Carbon emission prediction', 'Carbon neutrality', 'Wastewater treatment']",,"Accurate accounting and prediction of carbon emissions from sewage treatment plants is the basis for exploring low-carbon sewage treatment plants and measures to reduce pollution and carbon emissions. This study proposes a hybrid prediction framework based on machine learning, which integrates multiple algorithms and has strong adaptability and generalization ability. The prediction framework uses Pearson correlation coefficient to select feature values, constructs a combined prediction model based on the selected features using support vector machine (SVR) and artificial neural network (ANN), and optimizes the SVR model parameters and structure using Gray Wolf Optimization (GWO) algorithm. The results show that the model has stronger prediction performance compared with other prediction models, with a mean absolute percentage error (MAPE) of 0.49% and an R2 of 0.9926. In addition, this study establishes six future development scenarios based on historical data trends and policy outlines, which provide recommendations for the development of carbon emission reduction measures for wastewater treatment plants. This study can provide a reference for exploring efficient carbon management and achieving carbon neutrality in wastewater treatment plants."
Volumetric Change Assessment and Mapping of Coastal Landform Between 2000 and 2011 Using Remote Sensing and Machine Learning Techniques,2025,['Cyclones\xa0· Nagapattinam\xa0· Krishna\xa0· DOD\xa0· ANN\xa0· SRTM and ASTER DEM'],,"The Krishna coastal region in Andhra Pradesh and the Nagapattinam coastal region in Tamil Nadu have experienced signifcant alterations in their structure and arrangement as a result of human and natural interference. Afects mostly brought on by the recurrent existence of cyclones. During 2000 and 2011, both Nagapattinam and Krishna districts experienced several cyclonic events, particularly during the monsoon seasons. Coastal landforms have been extracted by thoroughly investigating many spatial data sources, including the Survey of India’s topographical map, the Landsat 8–9 images, the SRTM, and ASTER DEM. Techniques for detecting changes, including topographical change detection, cross-shore profle analysis, and geomorphic change detection (GCD) using DEM of Diference (DoD), Random Forest machine learning and ANN were implemented to assess the volumetric variations in coastal landforms from 2000 to 2011. The volumetric changes of the coastal landforms were verifed using feld survey data collected using a GPS unit. The landforms have lowered in height by 1 to 2 m, according to the topographical change analysis, most likely as a result of cyclone activity in both coastal zones. A total of 16 profles were surveyed for the topographical change evaluation. Investigation of cross-shore profles for eight places shows difering degrees of loss or gain of coastal landforms for a particular coastal area. Overall volumetric changes in the coastal region of Krishna are 164.26 m3 km2 due to erosion and 1047.74 m3 km2 due to accretion. Land grain is 624.54 m3 km2 and net land loss is 21.57 m3 km2 in the Nagapattinam coastal region. In addition to ofering insight into the decadal alteration in coastal settings, the study adds to a database on shore vulnerability, which will be useful to coastal managers going forward."
Leveraging machine learning for accurate DNBR prediction using python,2025,"['Scikit-learn packages', 'DNBR', 'Artificial neural network (ANN)', 'Loss of flow accident (LOFA)', 'Rod cluster control assembly (RCCA)']",,"This study investigates the viability of using Python scikit-learn packages, specifically regression techniques, to forecast the departure from nucleate boiling ratio (DNBR) using previously published datasets as reference. These datasets were generated using the COBRA-IV computer code under specific operational conditions for pressurized water reactors, and are categorized into two groups: steady-state, encompassing cases 1 and 2, and transient-state which includes both the loss of flow accident (LOFA) and rod cluster control assembly (RCCA) withdrawal scenarios. Due to the dataset’s small size, this study also addressed the difficulties encountered with enhancing the accuracy of regression models. Several approaches were investigated in an attempt to improve the regression’s accuracy, these include feature selection and hyperparameters tuning analysis for each regression model. The use of noise perturbation with a realistic standard deviation proved to be the most successful strategy for increasing regression accuracy, especially with small datasets, by interpolating the gaps between observations thus increasing their size. This approach’s algorithm was evaluated using metrics such as R2 score, mean square error (MSE) and mean absolute error (MAE). The evaluation metrics demonstrated that the DTReg model, after incorporating noise, achieved significantly higher accuracy compared to previously referenced artificial neural network (ANN) models, highlighting the substantial impact of noise perturbation on refining the model’s predictive capabilities. Overall, this approach not only improved performance for the steady-state cases but also enhanced accuracy for transient datasets, ultimately demonstrating the effectiveness of noise perturbation in overcoming the limitations of small datasets."
Meta-anova: screening interactions for interpretable machine learning,2025,['Explainable AI\xa0· Functional ANOVA\xa0· Derivative estimation'],,"There are two things to be considered when we evaluate predictive models. One is prediction accuracy, and the other is interpretability. Over the recent decades, many prediction models of high performance, such as ensemble-based models and deep neural networks, have been developed. However, these models are often too complex, making it difficult to intuitively interpret their predictions. This complexity in interpretation limits their use in many real-world fields that require accountability, such as medicine, finance, and college admissions. In this study, we develop a novel method called Meta-ANOVA to provide an interpretable model for any given prediction model. The basic idea of Meta-ANOVA is to transform a given black-box prediction model to the functional ANOVA model. A novel technical contribution of Meta-ANOVA is a procedure of screening out unnecessary interactions before transforming a given black-box model to the functional ANOVA model. This screening procedure allows the inclusion of higher order interactions in the transformed functional ANOVA model without computational difficulties. We prove that the screening procedure is asymptotically consistent. Through various experiments with synthetic and real-world datasets, we empirically demonstrate the superiority of Meta-ANOVA."
Enhancing Clinical Cardiac Care: Predicting In-Hospital Cardiac Arrest With Machine Learning,2025,,,
"Modeling spatio-temporal land use dynamics in Amritsar district, Punjab, India using machine learning",2025,['CA-ANN model\xa0· Random forest\xa0· GEE\xa0· LULC\xa0· Prediction'],,"This study presents a comprehensive spatio-temporal analysis and prediction of land use and land cover (LULC) changes in the Amritsar district of Punjab, India, using a Cellular Automata-Artifcial Neural Network (CA-ANN) model. Amritsar district has experienced signifcant land use transformations over the past decades. Satellite images from the years 1990, 2000, 2010, and 2020 were utilized, sourced from the USGS/NASA Landsat Program via Google Earth Engine. The Random Forest classifer was employed for LULC classifcation, distinguishing between water bodies, agriculture, vegetation, builtup areas, and bare land. Future LULC changes were simulated using the CA-ANN model implemented in QGIS through the MOLUSCE tool. The study observed substantial urban growth at the expense of agricultural and vegetative land, predicting continued urban expansion up to 2050. The fndings highlight a 59.0% increase in built-up areas and signifcant decreases in vegetation (88.1%) and water bodies (47.1%) by 2050. These trends underscore the need for strategic urban planning and sustainable land use practices to mitigate adverse environmental impacts. This research provides critical insights for policymakers and urban planners to ensure balanced development, maintaining ecological integrity alongside economic growth in the Amritsar district."
Effect of rainfall-derived inflow and infiltration on dissolved organic matter in urban sanitary sewers using chemometric and machine learning approaches,2025,"['Dissolved organic matter', 'Fluorescence excitation-emission matrix', 'Parallel factor analysis', 'Rainfall-derived inflow and infiltration', 'Urban sanitary sewer system']",,"This study investigated changes in dissolved organic matter (DOM) properties within urban sanitary sewers influenced by groundwater infiltration and excessive rainfall-derived inflow and infiltration (RDII). It employed optical indices and fluorescence excitation-emission matrix-parallel factor analysis (PARAFAC) coupled with self-organizing map (SOM) to compare DOM characteristics during wet weather flows (WWFs) and dry-weather flows (DWFs). Sampling sites impacted by RDII were identified based on flowrate. Optical indices and PARAFAC components (C1–C4) were used to differentiate DOM properties between DWFs and WWFs. In WWFs, E₂/E₃ and S<sub>350-400</sub> increased, while spectral ratio (S<sub>R</sub>) decreased, indicating a shift towards smaller organic matters. Reduced fluorescence and humidification indices suggested the input of fresher/terrestrial organic matters. C3 and C4 exhibited significant distinctions, showing increased C3 and decreased C4 levels. The PARAFAC-SOM modeling further illustrated that water samples in the urban sewer system could be categorized based on the dominance of DOM properties. Principal component analysis revealed separation between DWF and WWF samples in principal component 1 (PC1), associated with molecular size. PC2 was linked to microbial activity in WWFs. Notably, DWF samples from the NY-11 site shifted to the positive side of the PC1 axis, while their corresponding WWF samples moved to the negative side."
Which fossil energy source has the highest average contribution rate to US carbon emissions based on a machine learning algorithm?,2025,"['Average contribution rate', 'Carbon emission source prediction', 'Improved sparrow search algorithm', 'Long short-term memory', 'Wavelet transform']",,"Coal, oil, and natural gas are the main three fossil energy that produce carbon. Among them, which is the main contributor to carbon emissions is rarely studied. In this work, the average contribution rate of carbon emissions is predicted based on an innovative two-stage model combining the optimal layers of wavelet’s orders with long short-term memory optimized by an improved sparrow search algorithm. The experimental results demonstrate that using wavelet for preprocessing can achieve better prediction results, compared to some other preprocessing methods, and the prediction results of one-step prediction are better than those of multi-step prediction. In addition, the six prediction error indicators used in this study are reasonable, and using the average prediction error evaluation indicator is more reasonable. The conclusion can be reached that the order of average contribution rate of carbon emissions from high to low is natural gas, petroleum, and coal and their proportion is 46.62%, 34.90%, and 18.48%, therefore, in the short future, natural gas will be the main source of carbon emissions in the US."
Three pillars of artificial intelligence research in anesthesiology: welcoming address to the Korean Journal of Anesthesiology’s new guidelines for machine learning and deep learning research,2025,['.'],,.
Teachable Machine을 이용한 쿠즈네츠 역U자 가설의 검증: 지방재정격차를 중심으로,2025,"['재정격차', '머신러닝', '쿠즈네츠', 'Gini계수', '한국의 지방재정', 'Fiscal Disparity', 'Machine Learning', 'Kuznets', 'Gini Coefficient', 'Korean Local Finance']","이 연구는 기초자치단체들의 재정격차를 Gini계수로 측정하고, Kuznets 역U자 가설을 머신 러닝(Teachable Machine) 기법으로 검증하였다. 재원을 지방세, 세외수입, 자체재원, 교부세·교부금, 보조금, 그리고 총세입 등으로 세분화하여 Gini계수를 각각 산출한 뒤, Kuznets 곡선의 전통적패턴(k1), 반대 패턴(k3) 외에 3가지 중간 패턴(k2a, k2b, k2c)을 판별하였다. 그 결과, 자치단체별· 재원별로 다양한 형태가 나타났으며, 특히 절반 이상이 ‘Kuznets 곡선의 초기 단계(k2a)에서불균등도가 함께 증가하는’ 형태를 보였다.이는 곧 한국 지방자치단체의 재정이 하나의 역U자 곡선만으로 설명되지 않으며, 발전단계가 제각각임을 시사한다. 일부는 역U자 패턴을 모두 거치지만(k1), 반대로 성장 후기에 불균등도가 다시 증가(k3)하는 형태도 10% 정도 발견되었다. 기존 연구처럼 “Kuznets 가설이 맞느냐 틀리느냐”에만집중하기보다, 다양한 패턴이 공존한다는 사실을 새롭게 밝힌 점이 의의다.또한 수치 데이터 대신 이미지를 분석하는 CNN(Convolutional Neural Network)을 활용함으로써, 인공지능을 이용하여 재정을 분석하는 새로운 가능성을 열어 놓았다","This study measures the fiscal disparities of basic local governments using the Gini coefficient and tests the Kuznets inverted U-shaped hypothesis through a machine learning approach (Teachable Machine). By dividing revenue sources into local taxes, non-tax revenue, self-finance, grants, subsidies, and total revenue, the researchers calculated the Gini coefficients for each source and classified them into five patterns: the traditional Kuznets pattern (k1), the opposite pattern (k3), and three intermediate patterns (k2a, k2b, k2c). The results show diverse patterns across different local governments and revenue sources, with more than half in the “initial phase of the Kuznets curve (k2a), where inequality increases along with fiscal growth.” This finding indicates that one single inverted U-shaped curve cannot capture all of Korea’s local government finances, as each government is at a different stage of development. While some go through all phases of the Kuznets pattern (k1), there is also a group (around 10%) that experiences a resurgence of inequality in the later stages (k3). The study’s significance lies in highlighting the coexistence of multiple patterns rather than simply focusing on whether the Kuznets hypothesis is valid or not.Furthermore, it introduces the potential of leveraging CNNs (Convolutional Neural Networks) to analyze images instead of numerical data, opening new avenues of research in artificial intelligence. Lastly, it points to Piketty’s (2014) proposition that, in the long run, an “inverted S-shaped” pattern may emerge, suggesting a new research direction for future studies."
Solar Radiation Forecasting with Hybrid Deep Learning Framework Integrating Feature Factorization,2025,"['Solar radiation forecast', 'Feature Factorization', 'Long-Short-Term-Memory Neural Network', 'Convolutional Neural Networks', 'Self-attention Mechanism']",,"Deep learning models play a vital role in high-precision solar radiation prediction, leveraging their exceptional capabilities in capturing intricate relationships between input and output parameters. Due to the temporal dependence of solar radiation sequences and complexity of multidimensional variations, however, conventional deep learning models often face a trade-off between complex structures, gradient explosions, and accuracy. Furthermore, most deep learning-based solar radiation prediction models are considered black-box models, complicating efforts to adapt or modify the models based on theoretical considerations. In this work, a prior knowledge-based feature factorization layer that effectively addresses the temporal dependencies in solar radiation prediction problems is proposed. It is embedded into the CNN-LSTM-SA framework to extract spatiotemporal features from the non-stationary and nonlinear time series. The suggested model is learned and validated through weather data gathered in Tokyo and is contrasted with four traditional machine learning methods (linear regression, support vector machine, random forest, and back propagation neural network) and typical combined deep learning models. It demonstrates superior performance in both accuracy and interpretability with R2 of 0.93."
Performance comparison between E-learning during COVID-19 pandemic versus traditional classes utilizing sentiment analysis,2025,['Sentiment analysis · E-learning · Machine learning · Logistic Regression · NLP'],,"The lockdown was announced on 24 March 2020 due to the ongoing pandemic COVID-19. Universities and colleges were in a panic about the learning of students as traditional classroom sessions were not possible. Human–Computer Interaction (HCI) was the only solution as students had to interact using computers for learning and sharing resources. In this paper, the effectiveness of E-learning and HCI is compared to offline learning. We have collected responses from students of various universities. Furthermore, the LearningSent score is proposed for various questions based on relevance in teaching–learning, assessment, and recruitment. Experiment analysis reveal a lot of interesting insights. Experiment analysis revealed that 71% of respondents are in favor of E-learning, 43% of students are in favor of E-assessment and 30.60% are of the opinion that E-learning is effective for recruitment. Furthermore, 29.50% of students have given a rating of 4 and 6.90% of users have given a rating of 5 to an overall methodology which indicates that improvements. 83% accuracy is achieved using training and testing on responses. Correlation analysis on numerical ratings and calculated regression score is 0.79 which proves that regression score calculated from textual responses using Logistic Regression and numerical ratings are in synchronization."
Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning,2025,"['Non-orthogonal multiple access (NOMA)', 'deep reinforcement learning (DRL)', 'wireless network', 'resource allocation']",,"In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state."
Automatic classification of multi-channel PSD results combining unsupervised and supervised learning,2025,"['Fast neutron measurement', 'Organic plastic scintillator', 'Silicon photomultiplier (SiPM)', 'Pulse shape discrimination (PSD)', 'Machine learning', 'Automatic classification']",,"Fast neutron radiography is a nondestructive testing technique used in various fields, such as homeland security.Fast neutrons can be detected using either a thermal neutron capture detection system with moderators or a recoil proton-based neutron scattering detection system. In particular, recoil proton-based neutron detection systems are more suitable for radiography systems. This study proposes a machine-learning-based algorithm that can automatically classify neutron signals obtained from multichannel organic plastic scintillators with silicon photomultipliers for radiography acquisition. It covers the entire energy range above the pulse height threshold of 150 keVee in the pulse shape discrimination (PSD) results. We categorized the PSD results into two regions: the unsupervised learning region (more than 1.7 MeVee) and the supervised learning region (less than 1.7 MeVee).Neutron signals in the supervised learning region were effectively classified by exploiting the characteristics of the data distribution in the unsupervised learning region. The algorithm was applied to the neutron and gammaray signals obtained by time-of-flight measurements, and an excellent classification performance was demonstrated with the area under the receiver operating characteristic curve of 0.9904."
EnhPred: Deep Learning Model for Precise Prediction of Enhancer Positions,2025,"['인핸서', '조절 요소', '유전자 발현', '딥러닝', '후성 유전체학', 'enhancer', 'regulatory element', 'gene expression', 'deep learning', 'epigenomics']",,"Enhancers are crucial regulatory elements that control gene expression in living organisms. Therefore, enhancer prediction is essential for a deeper understanding of gene regulation mechanisms. However, precise enhancer prediction is challenging due to their variable lengths and distant target genes. Existing artificial intelligence-based enhancer prediction methods often predict enhancers without identifying their boundaries accurately. In this study, we developed a new deep learning-based enhancer prediction method called EnhPred, which consisted of Convolutional Neural Networks (CNN) and bidirectional Gated Recurrent Units (GRU). To predict enhancer regions with a high resolution, we designed EnhPred to predict probabilities of enhancer presence within narrow segmented genomic regions. When evaluated with existing machine learning- and deep learning-based methods using data from three human cell lines, EnhPred demonstrated superior performances in terms of accuracy of enhancer prediction and resolution of enhancer boundaries."
T  he Ever-Evolving Regulatory  Landscape Concerning Development  and Clinical Application of Machine  Intelligence: Practical Consequences  for Spine Artificial Intelligence  Research,2025,"['Artificial intelligence', 'Machine learning', 'Medical devices', 'Spine surgery', 'Regu latory framework']",,"T his paper analyzes the regulatory frameworks for artificial intelligence/machine learning AI/ML-enabled medical devices in the European Union (EU), the United States (US), and the Republic of Korea, with a focus on applications in spine surgery. The aim is to provide guidance for developers and researchers navigating regulatory pathways. A review of cur rent literature, regulatory documents, and legislative frameworks was conducted. Key dif ferences in regulatory bodies, risk classification, submission requirements, and approval pathways for AI/ML medical devices were examined in the EU, US, and Republic of Korea.T he EU AI Act (2024) establishes a risk-based framework, requiring regulatory review based on device risk, with high-risk devices subject to stricter oversight. The US applies a more f lexible approach, allowing multiple submission pathways and incorporating a focus on con tinuous learning. The Republic of Korea emphasizes possibilities of streamlined approval and with growing use of real-world data to support validation. Developers must ensure reg ulatory alignment early in the development process, focusing on key aspects like dataset quality, transparency, and continuous monitoring. Across all regions, the need for techni cal documentation, quality management systems, and bias mitigation are essential for ap proval. Developers are encouraged to adopt adaptable strategies to comply with evolving regulatory standards, ensuring models remain transparent, fair, and reliable. The EU’s com prehensive AI Act enforces stricter oversight, while the US and Korea offer more flexible pathways. Developers of spine surgery AI/ML devices must tailor development strategies to align with regional regulations, emphasizing transparent development, quality assurance, and postmarket monitoring to ensure approval success."
Adversarial Training with Contrastive Learning in NLP,2025,"['적대적 훈련', '대조 학습', '자연어 처리', '언어 모델', '신경망 기계 번역', 'adversarial training', 'contrastive learning', 'natural language processing', 'language model', 'neural machine translation']",,"Adversarial training has been extensively studied in natural language processing (NLP) settings to make models robust so that similar inputs derive similar outcomes semantically. However, since language has no objective measure of semantic similarity, previous works use an external pre-trained NLP model to ensure this similarity, introducing an extra training stage with huge memory consumption. This work proposes adversarial training with contrastive learning (ATCL) to train a language processing model adversarially using the benefits of contrastive learning. The core idea is to make linear perturbations in the embedding space of the input via fast gradient methods (FGM) and train the model to keep the original and perturbed representations close via contrastive learning. We apply ATCL to language modeling and neural machine translation tasks showing an improvement in the quantitative (perplexity and BLEU) scores. Furthermore, ATCL achieves good qualitative results in the semantic level for both tasks without using a pre-trained model through simulation."
ReliefF-ResNet-101: An Efficient Deep Learning Framework for Oral Squamous Cell Carcinoma Detection,2025,"['Oral Squamous Cell Carcinoma (OSCC)', 'Deep Learning', 'Feature Selection (ReliefF)', 'Machine Learning Classification']",,"Oral squamous cell carcinoma (OSCC) is a leading cause of cancer-related deaths globally, with 177,757 fatalities reported in 2020 World Health Organization. Early detection significantly improves survival rates. This study proposes an automated machine-learning approach for OSCC detection using histopathological images. Deep features extracted from the pre-trained model (ResNet-101) achieved 91.61\% classification accuracy. Furthermore, using ReliefF-based feature selection filters enhanced performance by 97.3\%. The ReliefF-ResNet-101 deep feature-trained support vector machine model required only 500 features. The comparative analysis confirmed the reliability and superiority of the proposed ReliefF-ResNet-101 framework over existing feature selection methods and state-of-the-art approaches. These findings suggest potential clinical applications for aiding OSCC diagnosis."
Faster Acquisition and Improved Image Quality of T2-Weighted Dixon Breast MRI at 3T Using Deep Learning: A Prospective Study,2025,"['MRI methods', 'Artificial neural network/machine learning', 'Breast', 'Quality assurance/control and improvement', 'Cancer']",,"Objective: The aim of this study was to compare image quality features and lesion characteristics between a faster deep learning (DL) reconstructed T2-weighted (T2-w) fast spin-echo (FSE) Dixon sequence with super-resolution (T2DL) and a conventional T2-w FSE Dixon sequence (T2STD) for breast magnetic resonance imaging (MRI).Materials and Methods: This prospective study was conducted between November 2022 and April 2023 using a 3T scanner. Both T2DL and T2STD sequences were acquired for each patient. Quantitative analysis was based on region-of-interest (ROI) measurements of signal-to-noise ratio (SNR) and contrast-to-noise ratio (CNR). Qualitative analysis was performed independently by two radiologists using Likert scales to evaluate various image quality features, morphology, and diagnostic confidence for cysts and breast cancers. Reader preference between T2DL and T2STD was assessed via side-by-side comparison, and inter-reader reliability was also analyzed.Results: Total of 151 women were enrolled, with 140 women (mean age: 52 ± 14 years; 85 cysts and 31 breast cancers) included in the final analysis. The acquisition time was 110 s ± 0 for T2DL compared to 266 s ± 0 for T2STD. SNR and CNR were significantly higher in T2DL (P < 0.001). T2DL was associated with higher image quality scores, reduced noise, and fewer artifacts (P < 0.001). All evaluated anatomical regions (breast and axilla), breast implants, and bone margins were rated higher in T2DL (P ≤ 0.008), except for bone marrow, which scored higher in T2STD (P < 0.001). Scores for conspicuity, sharpness/ margins, and microstructure of cysts and breast cancers were higher in T2DL (P ≤ 0.002). Diagnostic confidence for cysts was improved with T2DL (P < 0.001). Readers significantly preferred T2DL over T2STD in side-by-side comparisons (P < 0.001).Conclusion: T2DL effectively corrected for SNR loss caused by accelerated image acquisition and provided a 58% reduction in acquisition time compared to T2STD. This led to fewer artifacts and improved overall image quality. Thus, T2DL is feasible and has the potential to replace conventional T2-w sequences for breast MRI examinations."
Deep Learning Model-Based Detection of Anemia from Conjunctiva Images,2025,"['Anemia', 'Conjunctiva', 'Hemoglobins', 'Erythrocytes', 'Machine Learning']",,"Objectives: Anemia is characterized by a reduction in red blood cells, leading to insufficient levels of hemoglobin, the moleculeresponsible for carrying oxygen. The current standard method for diagnosing anemia involves analyzing blood samples,a process that is time-consuming and can cause discomfort to participants. This study offers a comprehensive analysisof non-invasive anemia detection using conjunctiva images processed through various machine learning and deep learningmodels. The focus is on the palpebral conjunctiva, which is highly vascular and unaffected by melanin content. Methods:Conjunctiva images from both anemic and non-anemic participants were captured using a smartphone. A total of 764 conjunctivaimages were augmented to 4,315 images using the deep convolutional generative adversarial network model to preventoverfitting and enhance model robustness. These processed and augmented images were then utilized to train and testmultiple models, including statistical regression, machine learning algorithms, and deep learning frameworks. Results: Thestacking ensemble framework, which includes the models VGG16, ResNet-50, and InceptionV3, achieved a high area underthe curve score of 0.97. This score demonstrates the framework’s exceptional capability in detecting anemia through a noninvasiveapproach. Conclusions: This study introduces a noninvasive method for detecting anemia using conjunctiva imagesobtained with a smartphone and processed using advanced deep learning techniques."
Application of Deep Learning Algorithms for Predicting Consolidation Settlement,2025,"['Busan Newport', 'Consolidation settlement', 'Degree of consolidation', 'Time–series forecasting', 'Machine learning', 'Deep learning']",,"Significant amount of consolidation settlement can occur in construction sites with soft clayey soil deposits. Accurate prediction is important to prevent serious issues, such as tilting and overturning of structures, as demonstrated in Busan Newport, South Korea. Observational methods, which perform regression analysis to predict settlement, are generally applied. However, the methods tend to produce inaccurate predictions when measurement records are limited. Therefore, this study applied deep learning algorithms to enhance the prediction accuracy of settlement. Three distinct models are developed based on artificial neural network, long short–term memory, and gated recurrent unit (GRU) algorithms. The models’ performance was evaluated across 277 scenarios, including 216 from the Busan Newport and 61 from an additional case study. The scenarios were classified based on the average degree of consolidation, mirroring real–world conditions. The performance of the deep learning models was compared against observational methods including the hyperbolic and Asaoka methods. According to analysis, the deep learning models demonstrated a 58 % reduction in root mean square error compared with the observational methods. Statistical analysis showed that deep learning models effectively reduced standard deviation and 90th percentile values, even with limited data. The GRU model, in particular, showed superior accuracy with the lowest statistical variation. This research highlights the potential of deep learning models for practical applications in predicting consolidation settlement."
Enhancing Tool Wear Prediction Accuracy by Integrating Multi-Task Learning with Cutting Force Estimation,2025,"['Tool condition monitoring', 'Cutting force estimation', 'Multi-task learning', 'Intelligent machining monitoring', 'Machine learning', 'Artificial intelligence', 'Smart manufacturing']",,"The deployment of on-line tool condition monitoring systems and machine tool diagnostics is essential for achieving sustainable manufacturing systems. Accurate tool wear prediction enables automated tool changes by comparing real-time wear with the predefined tool life limit, thereby improving production efficiency and reducing production costs. This study introduces a multi-task learning model that simultaneously estimates tool wear states and cutting force. This approach enhances both monitoring efficiency and accuracy. Cutting force serves as a key indicator, reflecting tool condition, machining stability, and surface quality. This makes real-time monitoring the cutting force essential to optimize processes and prevent failures. The mean and variance of the cutting forces are designated as target variables and paired with tool wear data, forming a combined target set to improve the model’s predictive performance. We collected the data from multiple sensors and the CNC system, with feature extraction techniques applied to derive meaningful information. To validate the multi-task learning approach, Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Temporal Convolutional Networks (TCNs) are utilized for model development. Performance metrics-accuracy, capacity (the number of parameters), and Floating Point Operations (FLOPs)-are compared between single-task and multi-task learning strategies to assess their effectiveness and efficiency. The study highlights the importance of correlation between the paired target variables in multi-task learning, showing its significant impact on model accuracy across different architectures. This research demonstrates the effectiveness of multi-task learning for machining processes and offers an optimal strategy for constructing such models."
Advanced Pest Identification Framework Using Deep Learning and Feature Extraction Techniques,2025,['Deep learning · Bicubic interpolation · Simplical complexity · Clustering · Convolutional networks · Support vector machine'],,"The agricultural industry faces challenges as pests and infections, which may damage a crop’s health and lower its production.Organizations like IPM (Integrated Pest Management) help farmers by providing pest control measures such as pesticide use and crop rotation. However, early discovery of pests is critical to preventing them from causing a signifcant problem. If pests are not identifed at an early stage of producing, they might become a signifcant issue. Various CNN architectures and contemporary Deep Learning (DL) approaches are applied to solve pest identifcation challenges. Commercial approaches have grown more successful with the availability of sufcient pest data and modern algorithms for machine learning (ML) and architectures. In the work that follows, we provide a distinctive framework that is trained on diverse pest picture types, enabling simplicial-complex and closest neighbor feature extraction along with pattern analysis, assisting in the most accurate identifcation of diferent pests. Additional tests were performed on data sets for medical imagery classifcation that further validated the robustness and power of the proposed Adam optimization variants."
Optimal Design of a Washing Machine Drive Motor Using a Sequential Optimization Algorithm,2025,"['Kriging', 'machine learning', 'motor optimal design', 'random forest', 'sensitivity analysis', 'surrogate model']",,"This paper proposes a sequential optimization algorithm that integrates sensitivity analysis, kriging, random forest (RF)-based surrogate models, and genetic algorithm to optimize a washing machine drive motor. The proposed algorithm prioritizes high sensitivity variables by applying a kriging model with superior predictive performance, while remaining variables are handled using a RF model to reduce time complexity. This approach effectively balances computational efficiency and predictive accuracy, proving to be more efficient than optimizing all design variables simultaneously using only Kriging or RF. The algorithm was applied to optimize an interior permanent magnet synchronous motor by minimizing torque ripple, cogging torque, and the total harmonic distortion (THD) of back-EMF. As a result, torque ripple was reduced by 31.5 %, cogging torque by 56.82 %, and THD by 7.92 %, while achieving the target torque. Additionally, stress and irreversible demagnetization analyses were conducted to verify the structural and thermal reliability of the optimized design, confirming its robustness."
A deep learning framework for HbA1c levels assessment using short-term continuous glucose monitoring data,2025,['HbA1c levels assessment\xa0· Continuous glucose monitoring data\xa0· Multi-scale feature extraction\xa0· Feature importance learning'],,"Glycated hemoglobin (HbA1c) is a crucial marker for long-term glycemic control, refecting cumulative blood glucose history over the past two to three months. Elevated levels of HbA1c are signifcant indicators of increased risk for diabetes-related complications. Typically, HbA1c measurement requires invasive blood collection, which is time-consuming and inconvenient for patients. Recent advancements in continuous glucose monitoring (CGM) technology ofer a convenient way to provide continuous and comprehensive blood glucose data. Therefore, a thorough understanding of the correlation between CGM data and HbA1c is essential for accurate interpretation of CGM data and further promoting this technology. Here, we introduce a deep learning solution called HILA, which can extract glucose features from short-term CGM sensor data at diferent time scales, and combine with manually extracted glucose features to assess patients’ HbA1c levels, thereby refecting their long-term blood glucose control. Simultaneously, we designed an interpretable feature importance learning mechanism, which assigns weights to manually extracted glucose features, enhances the performance of the model, and reveals the relative importance of diferent manual features in assessing HbA1c levels. Experiments on a dataset of 1,832 subjects from the Shanghai Jiao Tong University Afliated Sixth People's Hospital demonstrated that the HILA framework outperforms other machine learning models. This study used two-day CGM data for HbA1c levels assessment, not only enabling the evaluation of long-term glycemic control using short-term blood glucose data but also providing a new perspective for clinicians to efectively interpret short-term CGM data, thereby optimizing diabetes management."
Self-design of Metamaterials via a Hybrid Strategy Combining Genetic Algorithm and Reinforcement Learning,2025,"['Genetic algorithm', 'Machine learning', 'Metamaterial', 'Reinforcement learning']",,"Metamaterials have attracted considerable attention, owing to their unique properties and application prospects across various fields. However, the efficient design of metamaterials remains challenging because of the complex, high-dimensional optimization problems involved. Addressing these complexities via conventional design methodologies is difficult, and leads to extended development times and suboptimal solutions. To overcome these limitations, we propose a hybrid strategy that integrates genetic algorithms with reinforcement learning to achieve autonomous design of metamaterials. This integrated approach exploits the strengths of both techniques and significantly improves the efficiency and effectiveness of the design process. Our method converges to optimal configurations within five generations—a 79% reduction compared to the 24 generations required by conventional genetic-algorithm methods. Moreover, the performance scores for the hybrid and conventional methods are 0.93 and 0.85, respectively, within the same limited iteration span. Thus the hybrid method achieves a performance improvement of approximately 9.4% over the conventional method within just five generations. These results suggest that the proposed approach facilitates the discovery of innovative metamaterial structures and represents a significant advance in the automation and optimization of metamaterial design."
Efficiently Adapting to New Domains via Resizable Datastores in Machine Translation,2025,"['Natural Language Processing', 'Machine Translation', 'Domain Adaptation']",,"Domain adaptation, a fundamental task in deep learning, aims to mitigate performance degradation caused by domain shifts. Domain adaptation has been a significant focus in the field of neural machine translation, and ongoing research is dedicated to addressing this challenge. The existing kNN-MT-based domain adaptation methodologies are inefficient because of the large size of the datastore. Subsequent studies attempted to reduce the size of the datastore to shorten the search time; however, a trade-off between size and performance existed. In this study, we propose adaptively resizing datastore for k-nearest neighbor machine translation (ARK-MT), a methodology that adaptively adjusts the size of the datastore according to the confidence scores of the translation model. The experimental findings demonstrate that, compared with existing methods, the ARK-MT model exhibited superior performance across all four domains examined. Moreover, the results validated that ARK-MT reduces the inference time through efficient computational operations."
A Survey of Deep Learning Approaches for the Monitoring and Classification of Seagrass,2025,['Seagrass\xa0· Deep neural networks\xa0· Machine learning\xa0· Deep learning\xa0· Classifcation\xa0· Monitoring\xa0· Underwater'],,"Seagrass meadows are essential to the health of coastal ecosystems. They support carbon storage, provide habitats for marine species, and help stabilize coastlines. Monitoring underwater seagrass is vital for understanding the conditions of the ecosystem. Researchers have been interested in identifying and classifying underwater seagrasses. However, traditional monitoring methods can be labor-intensive and costly, especially in complex underwater environments. Deep learning approaches have made significant progress in digital image processing, particularly in object recognition and classification, and are among the most popular computer vision tools. The collection of digital images for monitoring underwater habitats, such as seagrass meadows, has increased significantly as recent progress in imaging technology has made it easier to collect high-resolution data. The increase in imagery data has in turn created a demand for automated detection and classification using deep neural network-based techniques. This study reviews the current deep-learning techniques used for monitoring and classification of the seagrass. It discusses the key methodologies, datasets, and progress in this area. This study not only examines the well-known challenges such as limited availability of data but provides a novel, structured taxonomy of deep learning techniques tailored for the monitoring of seagrass, highlighting their unique advantages and limitations within diverse marine environments. By synthesizing findings across various data sources and model architectures, we offer critical insights into the selection of context-aware algorithms and identify key research gaps, an essential step for advancing the reliability and applicability of AI-driven seagrass conservation efforts."
Predicting tunnel boring machine penetration rates in rock masses using knowledge distillation with limited samples,2025,"['Penetration rate', 'Pearson correlation coefficient', 'Limited samples', 'Knowledge distillation', 'LSTM']",,"Accurate prediction of Penetration Rate (PR) in Tunnel Boring Machine (TBM) construction helps optimize tunneling parameters. In this paper, a limited-sample prediction model was proposed to predict PR based on Knowledge Distillation (KD). A dataset was utilized consisting of 151 samples and six rock parameters. The Pearson Correlation Coefficient (PCC) Method is used to select the features of the input network, and the highly correlated features were removed. The prediction results demonstrate that for the machine learning (ML) models, Long Short-Term Memory (LSTM) and Bi-directional LSTM-Attention (BiLSTMA), the prediction accuracy is not satisfactory due to the inability to overcome overfitting caused by limited samples. However, when LSTM is employed as the student network within the KD model, the Mean Absolute Percentage Error (MAPE) of LSTM is reduced by 1.05%, and the determination coefficient (R2) value is increased from 0.7884 to 0.8191. This improvement is because the KD technique enables the student network to not only learn the feature information of the original data but also obtain the implicit information from the teacher network. Therefore, the proposed model provides a reliable technical solution for practical engineering applications under limited samples."
Bayesian optimized ensemble learning system for predicting conceptual cost and construction duration of irrigation improvement systems,2025,['Conceptual project cost and duration Explainable artificial intelligence (XAI) Bayesian optimization Irrigation improvement projects Sustainability Project management automation Ensemble machine learning Computational complexity'],,"Linear construction projects, such as pipeline irrigation projects, are prone to delays and cost overruns owing to inaccurate cost and duration estimates. The research gap pertains to studies that concentrated exclusively on predicting costs or durations using backbox artificial intelligence models. Consequently, this study introduces an innovative approach that utilizes explainable artificial intelligence to forecast the conceptual cost and duration of irrigation projects simultaneously. This study analyzed data from 1,277 historical cases using factor analysis and stepwise regression to distill 25 parameters down to five key drivers. It evaluates 12 machine learning models, including multiple linear regression, artificial neural networks, and decision tree-based ensemble methods. Bayesian optimization was employed to fine-tune the performance of each algorithm. The light gradient boosting machine is identified as the most effective algorithm for cost prediction, with a Mean Absolute Percentage Error (MAPE) of 2.989 % and an Adjusted Determination Coefficient (R⁎2) of 0.931. For duration prediction, the extremely randomized tree model stands out, achieving a MAPE of 2.533 % and an R⁎2 of 0.961. The study further employs the Shapley additive explanation technique to improve the interpretability of the key drivers used for predicting both the budget and the timeline."
Implementing Hybrid Quantum-Classical Single Shot Multibox Detector through Integration of Transfer Learning and Quantum Convolutional Neural Networks,2025,"['Quantum Computing', 'Multi-Channel Data', 'QCNN', 'Transfer Learning', 'SSD']",,"Integrating the advantages of quantum computing with existing classical machine learning models remains an open question. On the one hand, quantum computing devices are currently confined by certain scale limitations in the noisy intermediate-scale quantum (NISQ) technology era. On the other hand, artificial intelligence models are continually expanding in size to enhance their practicality, especially in computer vision, such as single shot multibox detector (SSD), a widely utilized model for object detection. This paper proposes combining transfer learning and multi-channel quantum convolutional networks (TL-MCQCNN) to improve object detection performance. Firstly, we set off by designing a QCNN structure specifically tailored for multi-channel data, which we call MCQCNN. Then, we employ transfer learning to optimize the training process of this quantum-classical hybrid model. Experimental results show that their classification accuracy surpasses that of the compared classical models, attaining 88% and 95%, respectively. Secondly, we implement a classical-quantum hybrid SSD model (CQSSD) using TL-MCQCNN, surpassing the performance of the classical SSD, with the result of an impressive 73.1 mAP on the VOC dataset. The experimental outcomes indicate that our method can integrate the SSD with quantum computing in the current NISQ environment."
Classification of Early Moderate Cognitive Impairment Using Support Vector Machine Based LeNet Classifier,2025,['Classifi cation · Mild cognitive impairment · Support vector machine · LeNet classifi er'],,"This study investigates the use of deep learning techniques to classify brain tumors. The proposed method uses a deep learning classifi er with series of pre-processing methods that includes image contrast enhancement, feature extraction and selection. The image contrast enhancement uses linear contrast stretch and feature extraction uses stacked auto-encoder.The support vector machine (SVM) uses the Adam optimizer to optimize the feature selection process. The classifi cation is carried out using LeNet Classifi er, where the results obtained by the proposed method are compared with those obtained using the CNN and SVM classifi cation methods. This study is conducted with the intention of determining how well the proposed deep learning method can distinguish between EMCI and MCI. The majority of the research that is currently being conducted on the early detection of MCI is marred by a number of defi ciencies, the most common of which are insuffi cient robustness and accuracy. The results show that the accuracy rate of the SVM-LeNet classifi cation approach is 96%, while the accuracy rates for the SAE, DBM, SVM, 2DCNN, and 3DCNN are 74.1%, 87.22%, 90.9%, 91.88% and 92.52%, respectively. In addition, the classifi cation accuracy rate for meningioma MRIs indicates that the MCI classifi cation using SVM-LeNet has a higher accuracy than the existing classifi ers."
Vibration Based Damage Assessment of a Steel Frame Structure Using Support Vector Machine Algorithm,2025,['Finite element model · Vibrational analysis · Normalised damage index · Inverse problem · Support vector machine · Natural frequency · Mode shape'],,"The structural damage detection system comes under the vast fi eld of structural health monitoring. This paper deals with the two-stage damage assessment approach, including identifi cation and severity estimation of any damage present in the structure. Free vibrational analysis of the healthy and damaged state of the structure yields two important modal parameters: frequency and mode shape. Eigenvectors, which constitute the mode shape of the structure, are considered for evaluating a damage index by comparing the damaged state with the healthy state. A Normalized Damage Index (NDI)is estimated for the structure subjected to various damage case scenarios. The novel method of estimating NDI provides a unique pattern for each element in the structure. The variation of natural frequency with increasing damage percentage helps estimate damage severity. Support Vector Machine(SVM), with a statistical pattern recognition paradigm, is an effi cient supervised Machine Learning (ML) algorithm capable of performing classifi cation and regression analysis. The Kernel-based SVM algorithm eff ectively identifi es damaged elements and estimates each element's severity. A four-storey, three-bay steel frame structure developed in the OpenSees framework is subjected to modal analysis. The results are validated with SAP and fi nite elementbased ABAQUS software. The ability of the proposed model is also verifi ed for a complex 3D structure. The viability of this model is also explored experimentally with a four-storeyed and single-bay steel frame structure. This approach provides an eff ective way of damage assessment."
Novel data‑driven open‑circuit fault diagnosis method for modular multilevel converter submodules based on optimized deep learning,2025,"['Modular multilevel converters', 'Fault diagnosis', 'Whale optimization algorithm', 'Deep kernel extreme learning machine']",,"As the proportion of clean energy continues to increase, low carbon energy systems will be a significant way to achieve the goal of carbon neutrality. Therefore, the reliability of modular multilevel converters (MMCs) is particularly significant. However, conventional open-circuit fault diagnosis (OCFD) methods usually have a limited localization speed or are difficult to achieve in practical engineering. Therefore, a fast and simpled OCFD approach for MMC SMs based on an optimized deep learning is proposed in this article. In this approach, data on the of submodule capacitance voltages are input into a trained WOA-DKELM model without the manually settings. The problems of randomness in the regularization coefficient C and the kernel parameters K can be solved by DKELM with WOA optimization, which has a strong generalization capability and higher prognostic accuracy. The effectiveness of the proposed approach is verified by experiment results. This approach achieves an average identification probability of 0.96 within 20 ms of the fault."
Analysis of influenza-like illness trends in Saudi Arabia: a comparative study of statistical and deep learning techniques,2025,"['Forecasting', 'Influenza', 'human', 'Neural networks', 'computer', 'Public health']",,"Objectives: To develop and evaluate forecasting models using the Holt-Winters statistical approach and the long short-term memory (LSTM) deep learning method for weekly seasonal influenza-like illness (ILI) incidences in Saudi Arabia. The study compares model performance and assesses the predictive value added by incorporating region-specific exogenous variables within Middle Eastern epidemiological modeling.Methods: This study compared the performance of Holt-Winters and LSTM models in forecasting weekly ILI cases in Saudi Arabia, using data collected from 2017 to 2022. Time series analysis integrated exogenous variables including climatic conditions and population mobility trends. The Holt-Winters model employed both additive and multiplicative seasonal components. Model performance was evaluated using root mean squared error (RMSE), mean absolute percentage error, and R2.Results: The best-performing model, LSTM with exogenous variables, achieved an RMSE of 28.55, mean absolute error (MAE) of 0.14, R2 of 0.96, and percent bias (PBIAS) of +2.1%, indicating negligible systematic error. The LSTM model without exogenous variables demonstrated slightly lower accuracy (RMSE of 34.07, MAE of 0.18, R2 of 0.93, PBIAS of +5.8%), indicating strong predictive capability but less precision in determining peak ILI cases. The Holt-Winters model effectively captured seasonal and long-term trends, but showed a moderate performance with an RMSE of 82.57, MAE of 0.38, R2 of 0.58, and a high PBIAS of +14.2%, revealing significant unexplained variability during periods of high incidence fluctuation.Conclusion: This study highlights the respective strengths and limitations of statistical and machine learning approaches for ILI forecasting."
A Systematic Review of Online AI Translation Tools for English Language Learning and Teaching,2025,"['Machine Translation', 'Systematic Review', 'English Education', 'AI Translation Tools.']",,"This study reviews the recent literature of which topic related to the application of machine translation (MT) tools in English education. 26 studies published between 2012 and 2023 are selected and analyzed based on the following criteria: publication years, target learners, language skills, effect variables, educational utilization, types of translation tools, and research methodologies. The key findings reveal that MT tools, such as Google Translate and Naver Papago, are frequently used for reading and writing. While the majority MT studies have involved tertiary-level learners' use and perceptions in MT, little attention has been paid to those of young learners. As for publication years, the result indicates three phases such as early adoption, expansion, and refinement, showing increased integration of AI-based tools into the more recent studies. The study also highlights recent trends regarding the cognitive and affective benefits of MT tools, alongside challenges such as over-reliance and cultural and textual inaccuracies. Implications for optimizing MT tools in English education will be discussed."
Manufacturing Quality Management Based on TimeGAN and Seq2Seq Models With Magnetic Press Machine Data,2025,"['Anomaly detection', 'deep learning', 'Industry 4.0', 'prediction', 'time-series data.']",,"Despite significant advancements in artificial intelligence (AI), the practical application of AI to realworld industrial data remains limited. Historically, research has concentrated on theoretical developments and algorithm improvements. However, there is now a growing need to apply AI collaboratively in actual production settings. This paper presents an AI-based quality management framework integrating TimeGAN and Seq2Seq models, specifically employing time-series data collected from a magnetic press machine used in permanent magnet manufacturing. The proposed Seq2Seq LSTM combined with TimeGAN achieved outstanding performance, demonstrating the lowest mean absolute error (MAE) of 0.88 and the highest R² value of 0.94 among tested models. Additional anomaly detection experiments confirmed the model’s effectiveness, exhibiting competitive recall (0.97) and F1-Score (0.93) results. These findings illustrate the significant potential of AI integration for quality control and process enhancement, suggesting broad applicability across various manufacturing industries."
Design and Fabrication of Micro-binary Diffractive Optical Elements to Generate Airy Beams Using a Versatile Direct Laser Lithography Machine,2025,"['Airy beam', 'Computer generated hologram', 'Diffractive optics', 'Direct laser lithography', 'Fourier optics']",,"Airy beam applications such as optical trapping, micro-machining, and imaging microscopy have garnered significant attention in recent years. This research introduces a comprehensive methodology for the design, simulation, fabrication, and evaluation of micro-binary diffractive optical elements aimed at generating Airy beams. First, a binary pattern is meticulously designed by means of computergenerated holography. Subsequently, the optical performance of the pattern is simulated using a Fresnel impulse response propagator, which is rooted in the Rayleigh–Sommerfeld diffraction in Fourier optics.Following this, a laser writing path is generated through a machine learning decision tree algorithm. A multifunctional direct laser lithography system is then used to fabricate the pattern. Lastly, a meticulous assessment of the surface quality is conducted, and an optical verification system is established to confirm the optical performance. This holistic process is characterized by its simplicity, self-contained nature, and cost-effectiveness due to its independence from masks, unlike traditional methods such as photolithography, ensuring a high level of accuracy. Moreover, it is important to note that this process is not only suitable for fabricating Airy beam diffractive optical elements, but also has the potential to generate other binary diffractive optical elements, notably on the micro-scale."
머신러닝 이해 및 활용을 위한 초등 AI 융합 수업 모형 및 설계원리 개발,2025,"['machine learning', 'AI-integrated education', 'instructional model', 'instructional design principle', '머신러닝', 'AI 융합 수업', '수업모형', '설계원리']","AI가 초중등교육에 활발히 적용됨에 따라 AI 지식과 교과 지식을 융합해 교과의 문제를 창의적으로해결하려는 AI 융합 수업이 대두되고 있다. 이에, 문제해결을 위해 대표적으로 활용되는 AI 모델인 머신러닝을 이해하고 활용하기 위한 AI 융합 수업을 초등학교에서부터 체계적으로 실시할 필요가 있다.하지만, 초등학생이 머신러닝을 이해하기 위해서는 중등 이상의 수학적 지식이 필요하므로 초등 학생수준에서 직관적으로 머신러닝을 이해하고 활용하기 위한 AI 융합 수업이 요구되고 있다. 이러한 AI 융합 수업을 설계하기 위해서는 AI, 융합, 문제해결, 초등맥락을 복합적으로 고려하여 설계원리를 통합하고 수업 절차에 적절히 적용해야 한다. 그러나 AI 융합 수업에 익숙하지 않은 교사들이 수업 설계에 참고할 수 있는 표준적이고 구체적인 안내가 부족한 실정으로 초등교사가 효과적으로 AI 융합수업을 설계할 수 있도록 모형과 설계원리를 개발하여 안내하는 것이 필요하다. 이에, 본 연구는 초등학교 맥락에서 머신러닝 이해 및 활용을 위한 초등 AI 융합 수업 모형 및 설계원리를 개발하였다. 개발한 모형 및 설계원리의 현장적용과 효과성 평가를 위해 초등학교 5-6학년 3개 학급을 대상으로 수업 모형 및 설계원리를 바탕으로 개발한 수업을 실행하고 사전․사후 설문, 면담을 진행하였다. 본 연구에서 개발한 모형과 설계원리를 초등학교 현장에 적용한 결과, 데이터 기초, 머신러닝 개념, 머신러닝 모델 개발, 머신러닝 모델 활용 영역이 통계적으로 유의미하게 향상됨을 확인하였다. 본 연구는 AI 의 대표적 모델인 머신러닝을 이해하고 활용하는 역량을 기르기 위해 초등학교에서 AI 융합 수업을개발하고 실행하는 방법에 대한 실제적 지침을 제공한다","As AI is actively applied in primary and secondary education, AI-integrated classes that creatively solve subject-related problems by merging AI knowledge and subject knowledge have emerged. Therefore, it is necessary to systematically implement AI-integrated classes in elementary schools to understand and apply machine learning, a representative AI model commonly used for problem-solving. However, since elementary students require mathematical knowledge at the middle school level or higher to understand machine learning, there is a need for AI-integrated classes that help students intuitively grasp and apply machine learning. To design these AI-integrated classes, it is essential to integrate design principles by considering AI, integration, problem-solving, and the elementary context, and to apply them appropriately in the instruction procedure. However, teachers unfamiliar with AI-integrated classes lack standardized and concrete guidelines to refer for class design. Therefore, it is necessary to develop models and design principles to guide elementary teachers in effectively designing AI-integrated classes. This study developed an AI-integrated instruction model and design principles for understanding and applying machine learning in the elementary school context. To evaluate the applicability and effectiveness of the developed model and design principles, the study conducted pre- and post-surveys and interviews with fifth and sixth-grade students. As a result, it was confirmed that the model and design principles for AI-integrated classes significantly improved students' understanding of data, machine learning concepts, machine learning model development, and machine learning model application. This study provides practical guidelines on how to develop and implement AI-integrated classes in elementary schools to build the capacity to understand and utilize machine learning."
머신러닝 기반 온라인 학습성과의 최적 예측모델 수립 (Part 1. 학습성취도 예측모델),2025,"['Learning achievement', 'Machine learning', 'Online learning', 'Predictive model', 'Random forest']","본 연구는 온라인 학습성취도 예측모델 수립을 위한 머신러닝 기반 모델 개발을 다루며, 2020년 1월부터 2023년 7월까지 수 집된 공공 직업능력개발 플랫폼 STEP의 데이터를 활용하였다. Random Forest, CART, Gradient Boosting, SVM, K-NN의 5가지 알 고리즘을 비교한 결과, Random Forest 알고리즘이 학습 전 단계와 학습 중 단계 모두에서 가장 높은 정확도를 보였다. 주요 예측 변수로는 사전 설문 만족도, 나이, 진도점수, 학습일수 등이 포함되었으며, 이를 통해 적응형 학습 서비스 구현의 가능성을 확인 하였다. 특히, 온라인 학습 중의 현재 수집 데이터만으로도 대체적으로 만족할 만한 수준의 예측 정확도를 확인하였다.","This study investigates the development of a machine learning-based model.to predict online learning outcomes(academic achievement) in public vocational training platforms, using the STEP dataset from January 2020 to July 2023. By Comparing five algorithms(Random Forest, CART, Gradient Boosting, SVM, K-NN), Random Forest demonstrated the highest accuracy across both pre-engagement and mid-engagement stages. Key predictive factors include pre-survey satisfaction, age, progress scores, and learning days, and learning days, emphasizing the potential for adaptive learning services. In particular, a generally satisfactory level of prediction accuracy was confirmed only with the current collection data during online learning."
자연어 처리 및 머신러닝 기술을 활용한 디지털 ODA 분석 및 연구,2025,"['디지털 ODA 분류 체계', '머신러닝', '자연어 처리', 'Word2Vec', 'Digital ODA', 'Classification Standards', 'Machine Learning', 'Natural Language Processing', 'TF-IDF', 'Word2Vec']","본 연구는 ‘디지털 분야 공적개발원조(ODA)’에 대한 공신력 있는 국내·국제적 기준이 부재한 상황에서, 자연어 처리와 머신러닝 기술을 활용하여 디지털 ODA에 대한 분류를 실시하고, 통계를 생성하였다. 머신러닝 모형 학습을 위한 분석 대상으로 국무조정실에서 발표하는 공적개발원조실적통계(승인번호 : 102002호)를 활용하였고, 모형 학습을 위해 한국국제협력단(KOICA)이 2023년도 실시한 ‘디지털 ODA 마커’를 기준으로 삼았다. ‘사업명’, ‘사업목적’, ‘사업내용’의 영문 비정형 텍스트 데이터를 자연어 처리하여, 단어가방 모형 중 TF-IDF 가중치와, 구글뉴스를 사전 학습한 Word2Vec 모형의 임베딩 가중치를 적용하였으며, CRS 목적코드를 변수에 추가하여 머신러닝 분류모형 중 랜덤포레스트를 활용하였다. 학습 대상이 된 기간은 KOICA의 2018~2023년으로 6개년의 사업이며, 분류 대상기간은 2023년도 공적개발원조실적통계의 통계치 확정 전인 시점을 감안하여, 2018~2022년 5개년이었다.분류 결과, 본 연구에서 수행한 머신러닝 기법을 통한 분류 결과가 기존 KOICA 실적 통계 결과와의 유사성을 확인할 수 있어 OECD 연구의 수작업 방법에 비해 현저한 성능의 우위가 확인되었다. 또한, 머신러닝 기법에 의해 수행되는 통계자료로써 객관성이 높고, 물적·시간적 비용을 절감할 수 있어, 향후 국제적 통계로의 발전 가능성을 확인할 수 있었다.","This study addresses the lack of credible domestic and international standards regarding ‘Digital Official Development Assistance (Digital ODA)’ by employing natural language processing and machine learning technologies. The data used for machine learning is the ‘Official Development Assistance Performance Statistics’ compiled for OECD Creditor Reporting System (CRS) statistics reporting published by the Office for Government Policy Coordination in Korea, and used the ‘Digital ODA Marker’ established by the Korea International Cooperation Agency (KOICA) in 2023. English text data like ‘project titles’, ‘project objectives’, and ‘project descriptions’ were processed using natural language processing techniques to derive TF-IDF weights from the bag-of-words model and embedding weights from the pre-trained Word2Vec model based on Google News. Additionally, CRS purpose codes were incorporated as other independent variables, and the Random Forest algorithm was employed for the machine learning classification model. The training data period for the model encompassed six years of KOICA’s projects from 2018 to 2023, while the classification target period spanned five years from 2018 to 2022, considering that the statistics of year 2023 is not yet finalized.The results demonstrated a significant performance advantage of the machine learning techniques used in this study over the manual screening methods employed in the previous studies. Furthermore, the objectivity and cost-effectiveness provided by the machine learning-generated statistical data suggest the potential for further development into international statistics."
금융업무의 인공지능(AI) 기술 공정성 확보 방안:        대출 판정에서의 머신러닝 공정성 확보를 중심으로,2025,"['금융 AI', '대출 판정', '머신러닝', '공정성', '데이터 편향', 'Financial AI', 'Loan Approval', 'Machine Learning', 'Fairness', 'Data                Bias']","이 글은 금융업무 내 인공지능(AI) 기반 대출 판정에서 머신러닝 공정성 확보 방안을 제시한다. 특히 머신러닝 도입 시 발생하는 공정성 문제를 분석하고 해결책을 모색했다. 머신러닝 기반 대출 판정 시스템은 두 가지 주요 공정성 문제에 직면한다. 첫 번째 문제는 학습 데이터의 편향이 모델에 반영되어 특정 집단에 불리한 결과를 초래할 수 있다. 그리고 두 번째 문제는 모델의 복잡한 의사결정 과정으로 고객이 대출 가능 여부의 근거를 이해하기 어렵다. 이러한 불투명성은 금융 소비자의 신뢰를 저하시키고 AI 시스템의 책임성 부족으로 이어질 수 있다. 이 문제 해결을 위해 다단계 접근 방안을 제안한다. 평가 단계에서는 다양한 공정성 지표를 활용하여 모델 편향을 측정하고, 학습 데이터 분석을 통해 편향을 제거해야 한다. 개발 단계에서는 공정성을 고려한 알고리즘을 설계하고, 설명 가능한 AI(XAI) 등 투명성을 높이는 기술을 적용해야 한다. 마지막으로 운영 단계에서는 지속적인 모니터링과 평가로 모델 공정성을 유지하고, 비상 상황에 대비한 체계를 구축해야 한다. 머신러닝 기반 금융 서비스의 공정성 확보는 기술적 문제뿐 아니라, 사회적, 법적, 윤리적 문제와도 밀접하다. 따라서 다양한 이해관계자 간 긴밀한 협력과 지속적인 노력이 필수적이다. 머신러닝 기술이 금융 서비스를 혁신함에도 불구하고, 공정성 문제 해결을 위한 끊임없는 노력이 병행될 때 비로소 공정하고 투명한 금융 시스템을 구축할 수 있을 것이다","This paper proposes strategies for ensuring machine learning fairness in AI-driven loan approvals within the financial industry. Specifically, it analyzes fairness issues that arise with the adoption of machine learning and explores potential solutions. Machine learning-based loan approval systems face two primary fairness challenges. First, bias in training data can be reflected in the model, leading to unfavorable outcomes for certain groups. Second, the complex decision-making processes of these models can make it difficult for customers to understand the rationale behind their loan approval or denial. This lack of transparency can erode financial consumer trust and lead to a lack of accountability in AI systems.To address these issues, we propose a multi-stage approach. In the evaluation phase, various fairness metrics should be used to measure model bias, and training data should be analyzed to eliminate existing biases. During the development phase, algorithms that consider fairness should be designed, and transparency-enhancing technologies like Explainable AI (XAI) should be applied. Finally, in the operation phase, continuous monitoring and evaluation are crucial to maintain model fairness, and systems for emergency preparedness should be established.Securing fairness in machine learning-driven financial services is not merely a technical challenge but is also closely intertwined with social, legal, and ethical considerations. Therefore, close collaboration and continuous effort among various stakeholders are essential. While machine learning technology is revolutionizing financial services, a fair and transparent financial system can only be built when continuous efforts to resolve fairness issues are pursued alongside technological innovation."
지진 데이터를 활용한 머신러닝 기반 쓰나미 예측,2025,"['머신러닝', '쓰나미', '지진해일', 'XGBoost', 'Machine Learning', 'Tsunami', 'undersea earthquake', 'XGBoost']","해저 지진으로 인해 발생하는 거대한 파도인 쓰나미(Tsunami)는 대규모의 인명 및 재산 피해를 발생시킬 수 있다. 기존 경보 시스템은 해저 지진이 발생한 후 쓰나미 가능성을 알려준다는 한계가 있다. 쓰나미로 인한 피해를 최소화하기 위해서는 사전에 쓰나미를 예측할 필요가 있다. 본 논문에서는 머신러닝(Machine Learning) 기반 쓰나미 예측 모델을 제안하고, 쓰나미의 주요 원인을 분석한다. 쓰나미 발생 여부와 지진의 특성 및 위치 데이터를 수집하고, 데이터를 전처리한다. 머신러닝의 대표적인 5가지 분류(Classification) 모델을 사용하여 모델링하고, 10-겹 교차 검증(10-Fold Cross Validation)을 통해 모델의 성능을 검증한다. 실험 결과, XGBoost가 테스트 데이터에서 정확도(Accuracy) 91.09%, 재현율(Recall) 0.9524, 정밀도(Precision) 0.9091, F1 Score 0.9302로 가장 우수한 성능을 보였다. 제안 모델(XGBoost)의 독립변수 중요도를 통해 쓰나미의 주요 원인을 분석하였다. 본 연구는 머신러닝을 통해 쓰나미 발생 여부를 예측하고, 그 원인을 파악했다는 점에서 의의가 있다. 제안 모델은 쓰나미 예측 및 경보 시스템을 개선하는 데 도움이 될 것으로 기대한다.","Tsunamis are massive waves caused by undersea earthquakes that can lead to extensive destruction of life and property. Current tsunami warning systems have limitations in notifying people about potential tsunamis following an undersea earthquake. In order to minimize the damage caused by the tsunami, it is necessary to predict the tsunami in advance. We propose a machine learning-based tsunami prediction model and analyze the main causes of tsunamis. We collect and preprocess earthquake data, including tsunami occurrences, earthquake characteristics, and locations. We use five machine learning classification models for modeling and validate the model performance with 10-fold cross-validation. XGBoost showed 91.09% accuracy, 0.9524 recall, 0.9091 precision, and 0.9302 F1 score on test sets. We analyzed the main causes of tsunamis with the feature importance of the proposed model(XGBoost). The significance of this study lies in predicting whether a tsunami will occur using machine learning and identifying its cause. We expect that our model will help improve tsunami prediction and warning systems."
머신러닝을 활용한 크로키 자동 평가 시스템 개발 및 정확도 분석,2025,"['머신러닝', '크로키', '자동 평가', '미술 교육', '웰니스', 'machine learning', 'croquis', 'automated evaluation', 'art education', 'wellness']","이 연구는 머신러닝을 활용하여 인물 크로키 작품을 자동으로 평가할 수 있는 시스템을 개발하고, 그 성능과 정확도를 분석하였다. 학생들이 수업 시간에 제작한 크로키 데이터를 수집하고, 이를 ""잘 그린 것,"" ""못 그린 것,"" 및 ""AI의 도움을 받은 것"" 세 가지 카테고리로 분류하였다. Google Teachable Machine 플랫폼을 사용하여 머신러닝 모델을 훈련했으며, 학습된 모델은 새로운 데이터를 입력받아 자동으로 평가 결과를 도출할 수 있도록 설계하였다. 모델의 성능을 검증하기 위해 테스트 데이터를 사용한 결과, 약 90%에 달하는 정확도를 기록하였으며, 이는 강사의 평가와 유사한 수준의 신뢰성을 제공함을 시사한다. 또한, 자동 평가 시스템은 평가 시간 절약과 일관성 유지에서 유의미한 장점을 보였다. 이 연구는 머신러닝 기반 평가 시스템이 미술 교육에서 평가 과정을 효율화하고, 학생들에게 즉각적이고 객관적인 피드백을 제공할 수 있음을 보여준다. 본 시스템은 크로키 평가의 신뢰성을 높이는 동시에 강사의 업무 부담을 줄이는 데 기여할 수 있으며, 향후 다양한 예술 교육 분야에서의 활용 가능성을 제안한다.","This study presents the development and performance analysis of an automated croquis evaluation system utilizing machine learning. Croquis data created by students during art classes were collected and categorized into three groups: ""well-drawn"" ""poorly-drawn"" and ""AI-supported"". A machine learning model was trained using the Google Teachable Machine platform, enabling the system to evaluate new data and automatically generate assessment results. The evaluation of the model's performance using test data demonstrated an accuracy rate of approximately 90%, indicating a reliability comparable to that of human instructors. Additionally, the system significantly reduced evaluation time while maintaining consistency, highlighting its potential advantages in efficiency and objectivity. In conclusion, the proposed system enhances the reliability of croquis evaluation while alleviating instructors' workload. This study suggests potential applications in various art education fields, providing students with immediate and objective feedback through machine learning-based evaluation systems."
재난 피해자 대상 머신러닝기반 PTSD 고위험군 분류 방법 제안,2025,"['machine learning', 'PTSD classification', 'high-risk group', 'disaster victims', 'biosignal analysis', 'random forest', '.']","본 연구는 머신러닝기반 분석을 통해 재난 피해자 중 PTSD 고위험군을 분류 방법 제안을 목표로 한다. 재난상황을 고려하여 PTSD 신속진단을 위해 임상시험을 통해 검증된 AI심장카메라를 활용한 비접촉 생체신호 측정과 표준화된 심리 설문을 통합하여 객관적인 분류 체계를 제안하였으며, 머신러닝 모델을 활용하여 PTSD 중증도 분류에 적용하였다. 대상자는 지진경험이 있는 66명에 대해 생체신호와 심리 설문 데이터를 수집하였고, 기존 연구 및 데이터 분석기반 가중치를 부여하여 랜텀포레스트 모델에 적용하였다. 제안된 분류 모델은 85%의 정확도를 보였으며, 재난현장에 적용하기 위한 머신러닝 기반 PTSD 조기 위험탐지가 가능함을 확인하였다.","This paper proposes a machine learning-based methodology for classifying high-risk groups of post-traumatic stress disorder (PTSD) among disaster victims. By leveraging a clinically validated AI-based cardiac camera under disaster conditions, non-contact biosignal measurements were integrated with standardized psychological surveys to establish an objective classification framework. This framework was applied to categorize PTSD severity levels via a machine learning model. Data were collected from 66 individuals who had experienced an earthquake, comprising both biosignals and psychological survey responses. A Random Forest model was subsequently employed with weighted features derived from previous studies and data analysis. The proposed classification model achieved an accuracy of 85%, demonstrating the feasibility of early PTSD risk detection through machine learning in real-world disaster scenarios."
SiC 캐소드 초음파 가공 공정에서의 머신러닝 기반 음향방출 신호 분류,2025,"['Acoustic emission', 'Ultrasonic machining', 'Signal analysis', 'Machine learning', '음향방출', '초음파 가공', '신호 분석', '머신러닝']",,"This study analyzed acoustic emission (AE) signals generated during ultrasonic machining of SiC cathodes and evaluated classification performances of various machine learning models. AE data were collected in both waveform and hit formats, enabling signal characterization through statistical analysis and frequency domain examination. Various machine learning models, including XGBoost, KNN, Logistic Regression, SVM, and MLP, were applied to classify machining states. Results showed that XGBoost achieved the highest classification accuracy across all sensor positions, particularly at the upper part of the worktable with an accuracy of 98.35%. Additional experiments confirmed the consistency of these findings, highlighting the influence of sensor placement on classification performance. This study demonstrates the feasibility of monitoring AE-based machining state using machine learning and emphasizes the importance of sensor placement and signal analysis in improving classification accuracy. Future research should incorporate defect data and deep learning approaches to further enhance classification performance and process monitoring capabilities."
XGBoost 머신러닝 기반 쉴드 TBM 지반침하 예측,2025,"['쉴드 TBM', 'XGBoost', '머신러닝', '지반침하', 'Shield TBM', 'XGBoost', 'Machine learning', 'Ground settlement']",,"This study developed an XGBoost (eXtreme Gradient Boosting) machine learning model to predict ground settlement during urban shield TBM (tunnel boring machine) tunnel construction and evaluated its performance. While previous studies have primarily focused on predicting ground settlement behind the tunnel, this study used real-time shield TBM construction data to predict both rear and forward settlement. For this purpose, field data from a TBM tunnel construction project in Hong Kong, provided by a local construction company, was analyzed. This data included information on ground conditions, TBM advancement, and tunnel geometry. A total of 17 input variables were selected for the machine learning model, which were grouped into three prediction ranges: the forward range (25 segment rings ahead of the tunnel face, CASE 1), the central section (upper part of the TBM body, CASE 2), and the rear range (25 segment rings behind the tunnel face, CASE 3). The relationships between the input variables and settlement were analyzed for each of these ranges. For each case (forward, central, and rear positions), an XGBoost model was developed to predict ground settlement, with hyperparameters optimized through Bayesian optimization and 5-fold cross-validation. The results showed that the rear settlement model performed the best, achieving a coefficient of determination (R2) of 0.82, while the forward settlement model had a lower performance, with an R2 of 0.52. These results suggest that rear settlement predictions are more accurate than forward predictions, with the latter being more affected by ground variability and excavation factors, resulting in lower accuracy. Overall, the findings highlight that machine learning models can be effective tools for predicting ground settlement during TBM tunnel construction, especially for rear settlement. However, further research is needed to enhance the accuracy of forward settlement predictions."
데이터 증강 기법을 적용한 개선된 머신러닝 기반 TBM 디스크 커터 마모 예측,2025,"['TBM', 'Disc cutter', 'Wear', 'Data augmentation', 'Machine learning', 'TBM', '디스크 커터', '마모', '데이터 증강', '머신러닝']","TBM (tunnel boring machine) 시공 중 디스크 커터의 과다 마모는 굴진 성능 저하를 유발할 수 있어, 이를 적시에 탐지하는 것이 중요하다. 디스크 커터 마모량 예측에 대한 다양한 연구가 수행되었으나, 과다 마모 탐지 성능 향상에 중점을 둔 연구는 부족한 실정이다. 본 연구에서는 데이터 증강 및 머신러닝 기반 디스크 커터 마모 등급 예측 모델을 구축하고, 데이터 증강 기법 적용에 따른 과다 마모 탐지 개선 효과를 분석하였다. 먼저, 토압식 쉴드 TBM 현장의 디스크 커터 교체 이력을 바탕으로 통계 분석을 수행하여, 링 당 마모량을 양호 등급(0.337 mm 미만)과 경고 등급(0.337 mm 이상)을 구분하였다. 두 가지 등급 간 데이터 불균형 문제를 해결하기 위해 SMOTE (synthetic minority oversampling technique)를 적용하였으며, 증강 데이터와 머신러닝 기법(Random Forest, eXtreme Gradient Boosting)을 활용하여 예측 모델을 개발하였다. 데이터 증강 적용 결과, 정확도와 F1 score가 향상되었고 양호 등급-경고 등급 간 예측 성능 불균형 수준이 감소하였다. 이는 과다 마모 데이터의 증강이 과다 마모 발생 메커니즘 학습에 효과적으로 기여한 결과로 판단된다. 특성 중요도 분석을 통해 커터 회전 거리 커터 마모 예측에 가장 영향도가 높음을 확인하였고, 이는 커터헤드 외측에 상대적으로 좁은 커터 배치 간격 설계의 필요성을 보여준다.","Excessive wear on disc cutters during tunnel boring machine (TBM) construction reduces excavation efficiency, highlighting the need for timely detection. While previous studies have explored the prediction of disc cutter wear, they often struggle to effectively detect excessive wear due to its infrequent occurrence. This study incorporated data augmentation and machine learning techniques for predicting disc cutter wear and evaluating the effectiveness of data augmentation in improving excessive wear detection. Initially, the wear amount for each ring excavation was categorized into two classes based on statistical analysis: safe (<0.337 mm) and warning (≥0.337mm). To address the data imbalance between these classes, synthetic minority oversampling technique (SMOTE) was applied. Subsequently, classification models were developed using the augmented dataset and machine learning techniques, specifically Random Forest and eXtreme Gradient Boosting. The results demonstrated that data augmentation enhanced both accuracy and F1 score, while reducing the performance gap between the two wear classes. This is attributed to the enhanced learning of the excessive wear mechanism, achieved through the augmentation of excessive wear data. Feature importance analysis revealed that cutter revolution distance exhibited the strongest correlation with cutter wear. This finding highlighted designing relatively narrower cutter spacing on the outer section of the cutterhead."
소아 허약 검사를 활용한 허약아 패턴 분석 및 머신러닝 기반 예측 모델 개발,2025,"['Weak Children', 'Pediatric Weakness Scale', 'Factor Analysis', 'Hierarchical Cluster Analysis', 'Machine Learning']",,"Objectives: This study aimed to explore the internal structure of the Pediatric Weakness Scale (PWS) through factor analysis, classify pediatric weakness patterns using hierarchical clustering, and evaluate a machine-learning-based predictive model for clinical screening.Methods: PWS responses from 326 children aged 6–9 years without organic diseases were analyzed. Factor analysis (principal axis factoring and varimax rotation) was used to extract seven latent factors. These factor scores were used for hierarchical cluster analysis (Ward’s linkage method and Euclidean distance), resulting in ten clusters each. Cluster characteristics were compared using Multidimensional Fatigue Scale (MFS), Korean Child Behavior Checklist (K-CBCL), Korean version of Children’s Eating Behavior Questionnaire (K-CBEQ), respiratory infection history, and growth indices. Machine learning models were trained to predict clusters based on factor scores, and their performance was evaluated using 10-fold cross-validation.Results: Seven factors were identified: respiratory health, general condition, ocular health, emotional regulation, gastrointestinal function, nutrition, and sleep-related nervous system sensitivity. Ten distinct clusters were derived: healthy children; severe, moderate, and mild complex weakness; liver–lung weakness; emotional dysregulation – heart weakness; neurosensitive heart weakness; and Spleen, Lung, and Kidney – specific weakness. Among the classifiers, the nonlinear support vector machine achieved the highest accuracy (0.890).Conclusion: This study suggests a new classification and prediction model for pediatric weakness based on PWS data. These results support the potential for early screening and personalized health strategies in pediatric care."
자동차 조향부품 조립 공정에서 사전 측정 데이터를 활용한 머신러닝 기반 불량 예측 모델,2025,"['불량품 예측', '머신러닝', '데이터분석', '원격 모니터링', 'Defective Product Prediction', 'Machine Learning', 'Data Analysis', 'Remote Monitoring']","자동차 조향부품인 Intermediate Shaft (I-Shaft) 가공 시 조립 전 측정 데이터를 활용해 조립품의 불량 여부를 사전에 예측하는 머신러닝 모델을 개발하였다. 공장 내 원격센서로 수집된 조립 전 데이터셋에서  I-Shaft 부품의 품질에 영향을 줄 수 있는 특징들을 선택해 전처리하고, 데이터 불균형 문제 해소를 위해 Synthetic Minority Over-sampling Technique(SMOTE) 를 적용하였다. 다양한 머신러닝 모델의 최적 성능을 나타내기 위한 하이퍼 파라미터 튜닝을 수행 후 불량품 분류 성능을 비교한 결과, Random Forest모델이 Recall 0.99, F1-Score 0.99로 불량품 검출에 가장 우수한 성능을 보였고, 이 모델을 공장 현장에서 쉽게 활용할 수 있는 GUI 프로그램을 개발하였다. 제안된 기법을 통해 조립 전 단계의 데이터로 조립품의 불량품을 미리 예측할 수 있어 중간 단계에서의 검사 과정을 생략함으로써 생산 효율성을 높일 수 있다.","A machine learning model was developed to predict defects in assembled Intermediate Shaft (I-Shaft) components by utilizing measurement data collected prior to the assembly process. The dataset, gathered through remote sensors installed within the manufacturing plant, was analyzed to extract and preprocess key features that could potentially influence the final quality of the I-Shaft. To address the class imbalance issue inherent in the dataset, the Synthetic Minority Over-sampling Technique (SMOTE) was applied. Multiple machine learning algorithms were trained and evaluated, with hyperparameter tuning conducted to optimize their performance. Among them, the Random Forest model outperformed others, achieving a recall of 0.99 and an F1-score of 0.99, indicating exceptional performance in identifying defective components. To facilitate practical use on the factory floor, a graphical user interface (GUI) application was also developed based on the selected model. This approach enables early detection of potential defects using only pre-assembly data, eliminating the need for intermediate inspections and significantly enhancing overall production efficiency."
머신러닝 기법을 활용한 도박 중독 예측 모델 비교 연구,2025,"['스포츠베팅 중독', '예측 모델', '머신러닝', '도박중독군', '도박문제군', 'Sports Betting', 'Prediction Model', 'Machine Learning', 'At-Risk Gambler', 'Problem Gambler']","연구목적 이 연구의 목적은 첫째, 한국 스포츠베팅 이용자들을 대상으로 15가지의 도박 중독 위험 요인 (인구 통계 정보, 도박 기대와 관련된 요인, 도박 습관 등)을 적용해 도박 중독 위험군과 일반군으로 구별하고, 둘째, 네 가지 기계학습 방법 (로지스틱 회귀분석, 의사결정나무, 랜던 포레스트, 그레디언트 부스팅 분류기) 중 최적의 모델을 식별한 후 도박 중독 위험군에 속한 이용자들이 도박 중독에 빠지지 않기 위한 대안을 모색하는 것이다. 연구방법 국내 합법 스포츠베팅인 체육진흥투표권(스포츠토토)에 참여한 경험이 있는 인원을 대상으로 연구를 진행하였으며, 온라인 설문을 진행하였다. 기계학습 분석을 위해 데이터 (n=214)를 *.csv 파일형식으로 Python에 변형시켰다. 15가지의 도박 중독 위험 요인을 사용하여 도박 중독 위험군과 일반군으로 분류될 것을 예측한 후 4가지의 기계학습 모델 (로지스틱 회귀분석, 의사결정나무, 랜덤 포레스트 및 그래디언트 부스팅 분류기)을 훈련시켰다. 결과 4개의 기계학습 모형을 훈련시킨 후 정밀도, 재현율, F1 및 정확도 값을 기준으로 모델의 적합성을 평가하였다. 이 중에서 랜덤 포레스트 모델 (정밀도 0.97, 재현율 0.86, F1 점수 0.91, 정확도 0.95)이 다른 세 개의 분류기에 비해 가장 우수한 것으로 판단되었다. 결론 본 연구의 모델링에 활용된 비교적 작은 사이즈의 데이터로 결과의 일반화에는 다소간의 제역이 있을 것으로 판단된다. 하지만 본 연구는 4 가지의 기계학습을 활용하여  스포츠도박 위험군을 일반군과 구별할 수 있는 모델을 찾아냈다. 이 연구를 통해 스포츠도박 중독 위험군에 속한 이용자들이 도박 중독에 빠지지 않도록 도박 행위를 함에 있어서 통제력을 유지하여 도박중독으로부터 발생하는 문제와 피해를 최소화하는데 도움이 될 수 있을 것으로 기대한다.","urpose The purpose of this study was twofold: (1) to distinguish at-risk/problem (sport) gambers from casual (sport) gamblers by utilizing the various factors that influence gambling addiction and (2) to identify the optimal AI model in predicting gambling addiction. Methods The data were collected through convenient sampling method and 214 responses were finally selected and imported into Python as *.csv file format for the analyses. Popular Machine Learning (ML) classifiers of Logistic Regression, Decision Tree, Random Forest, and Gradient Boosting Classifiers were trained and compared by Precision, Recall, F1, and Accuracy values. Results Of the four traditional ML classifiers, the Random Forest model appraised on the test dataset yielded the best classification at a Precision score of 0.97, a Recall score of 0.86, and an F1 score of 0.91 with an accuracy of 0.9538. Conclusion This Our relatively small data with a few predictor variables perhaps limited Machine Learning’s ability to deal with a vast amount of Big Data, but revealed a group of important factors that could be beneficial in identifying and targeting those who were at moderate-risk/problem (sport) gamblers. It is expected that the results of this current study will be contributing to not only helping at-risk/problem sport gamblers avoid becoming a gambling addict, but also casual sport gamblers maintain control over their gambling practice so that they can minimize problems and harms associated with gambling behaviors."
머신러닝 기반 소규모 외식업체 소모품 발주 예측 시스템,2025,"['machine learning', 'POS data', 'supply prediction', 'order management', '.']",최근 외식업계에서는 POS(Point of Sales) 시스템과 키오스크의 도입으로 다양한 데이터가 실시간으로 축적되고 있으며 이를 기반으로 데이터 기반의 운영이 가능해졌다. 본 연구에서는 머신러닝 기법을 활용하여 매장의 매출 데이터와 발주 데이터를 분석하고 이를 통해 소모품의 사용량을 예측하여 최적의 발주 시점을 도출하는 시스템을 제안한다. 11개월간의 실제 매장 운영 데이터를 수집 및 분석하였으며 제안한 방법을 다양한 머신러닝 모델에 적용시켜 우수한 예측 성능을 확인했다. 머신러닝으로 예측된 발주일과 실제 발주일과 평균 1.14일의 오차를 보여 실제 소규모 외식업 환경에서 적용이 가능한 수준의 정확도를 달성하였다. 해당 시스템은 데이터 기반의 자동화된 발주 관리 시스템 구축을 통해 소규모 외식업체의 운영 효율성에 기여할 수 있을 것으로 보인다.,"Recently, while the restaurant industry has been accumulating various data in real-time through the introduction of POS systems and kiosks, this data has not been effectively utilized. This study proposes a system that predicts the consumption of supplies and determines optimal order timing by analyzing sales and order data using machine learning techniques. We collected 11 months of actual store operation data, and experimental results showed that the proposed approach demonstrated reasonable prediction performance. Also, predicting order timing from the proposed approach achieved an average error of 1.14 days from actual order dates. These results demonstrated sufficient accuracy for practical application in small restaurant environments. This system is expected to contribute to operational efficiency through the implementation of a data-driven automated order management system."
머신러닝 기반 현금기부행동 예측 및 분석 - 일상적 안녕에 대한 태도를 중심으로 -,2025,"['charitable civing', 'tripartite model of attitudes', 'everyday well-being attitudes', 'machine learning', 'XGBoost', 'LightGBM', '현금기부행동', '태도의 삼각구조 모델', '일상적 안녕에 대한 태도', '머신러닝', 'XGBoost', 'LightGBM']","본 연구는 개인의 현금기부행동에 대한 이해를 증진하고 기부 활성화 방안을 모색하기 위해, 성인 약 20만 명의 ‘일상적 안녕에 대한 태도’를 통해 현금기부행동을 예측하고 관계를 분석했다. 이를 위해 '태도의 삼각구조 모델'을 이론적 기반으로 하고, 트리-기반 머신러닝 알고리즘을 적용하여 현금기부행 동을 예측하였으며, SHAP 요약 도표, PDP, ALE, SHAP DP 등을 활용하여 예측의 근거를 분석했다. 연구에서 도출된 주요 발견은 다음과 같다. 첫째, XGBoost와 LightGBM 알고리즘은 현금기부행동 예측에서 우수한 성능을 보여 머신러닝 기법의 유용성을 확인하였다. 둘째, 태도의 삼각구조 모델 분석 결과, 행동적 차원의 태도 변수들이 현금기부행동 예측에 결정적인 역할을 하는 것으로 확인되었다. 셋째, 현금기부행동을 예측할 수 있는 가장 강력한 예측변수는 ‘향후 기부 참여의사’로 나타났으며, '노후준비'는 개인의 현금기부행동을 예측할 수 있는 새로운 핵심 변수로 파악되었고, ‘독서’나 ‘여행’ 의 부재는 현금기부행동의 부재를 예측하는 주목할 지표로 확인되었다. 넷째, ‘자원봉사’와 ‘물품기부’의 경우 참여 빈도나 분야의 다양성보다 참여 여부가 현금기부행동을 예측하는 중요한 요인으로 밝혀졌다. 다섯째, 감정적 차원의 태도 변수들은 단순 선형관계가 아닌 일정 수준 이상이 되어야 현금기부활동이 활성화되는 경향을 보여 현금기부행동에 있어 정서적 평가의 임계점이 존재한다는 통찰을 제공했다. 본 연구는 현금기부행동에 대한 이론적 이해를 심화하고 실천현장에서 활용 가능한 예측모델과 전략을 제시했다는 점에서 의의가 있다.","This  study  aims  to  predict  and  analyze  charitable  giving  behavior  based  on attitudes  toward  everyday  well-being  and  the  tripartite  model  of  attitudes  to enhance  understanding  and  promotion  of  charitable  giving.  For  this  purpose, tree-based machine learning algorithms were applied to predict charitable giving behavior using data from approximately 200,000 adults, and the prediction results were  analyzed  through  interpretation  techniques  such  as  SHAP  summary  plots, PDP,  ALE,  and  SHAP  DP.  The  findings  were  as  follows:  First,  XGBoost  and LightGBM  algorithms  demonstrated  high  predictive  power  for  charitable  giving behavior.  Second,  in  the  tripartite  model  of  attitudes,  the  behavioral  dimension played the most crucial role in predicting charitable giving. Third, ‘future intention to  donate’  emerged  as  the  strongest  predictor  of  charitable  giving  behavior. ‘Retirement  preparation’  was  also  identified  as  a  significant  predictor,  and  the absence of activities such as ‘reading’ or ‘traveling’ was found to be a meaningful predictor of the absence of charitable giving behavior. Fourth, for volunteer work and  in-kind  donations,  participation  itself  was  found  to  be  more  important  in predicting charitable giving behavior than the frequency or variety of participation. Fifth,  affective  dimension  variables  showed  positive  relationships  with  charitable giving behavior only above certain thresholds, suggesting the existence of emotional evaluation thresholds in charitable giving behavior."
클래스 불균형을 해결한 머신러닝 기반 위험 NEO 예측 모델 개발,2025,"['Class Imbalanced', 'Near-Earth Object', 'Hazardous Prediction', 'Machine Learning', 'eXtreme Gradient Boosting', '클래스 불균형', 'NEO', '위험 여부 예측', '머신러닝', 'XGBoost']","지구 궤도와 너무 가까워 대기권에 진입할 가능성이 있는 위험 NEO(Near-Earth Object)는 지역적⸱세계적 규모로 큰 피해를 초래할 수 있다. NEO 데이터는 위험 데이터 수가 현저히 작아서 클래스가 불균형하기 때문에 이를 해결하기 위한 새로운 방법이 필요하다. 본 연구에서는 클래스 불균형을 해결한 머신러닝 기반 위험 NEO 예측 모델을 제안한다. 불균형한 클래스의 비율을 동일하게 샘플링하여 8개의 훈련 데이터 세트를 구성한 후, 5가지 머신러닝 모델로 학습한다. 가장 우수한 성능을 보이는 XGBoost를 제안 모델로 채택하였다. 제안 모델(XGBoost)은 테스트 데이터 기준 재현율(Recall) 0.9973, 정밀도(Precision) 0.9965, F1-Score 0.9969, 정확도(Accuracy) 99.69%를 보였다. 제안 모델은 위험 NEO를 탐지하고 빠르게 대응하는 데 도움이 될 것으로 기대한다.","Hazardous Near-Earth Object(NEO), which is near the Earth’s orbit to potentially enter the atmosphere, can cause significant damage on a local or global scale. NEO data have a class-imbalanced since there are few  hazardous NEOs. In this paper, we propose a machine learning-based hazardous NEO prediction model solving class imbalance. We constructed eight training sets by sampling the same proportion of both classes and train them with five machine learning models. We selected XGBoost, which has demonstrated the best performance. Our model showed 0.9973 recall, 0.9965 precision, 0.9969 f1-score, 99.69% accuracy in test data. We expect that our model will help in detecting hazardous NEO and responding quickly."
머신러닝 기반의 내연기관 차량의 차체 온도 예측과 안전성 진단 연구,2025,"['Machine Learning', 'Temperature Prediction', 'IoT Sensors', 'Web-based Interface', 'Performance Evaluation']",,"This study designs and implements a machine learning-based temperature prediction and safety diagnosis system for internal combustion engine vehicles. The system features a web-based interface for enhanced user accessibility and employs various algorithms, including Random Forest, Linear Regression, and Support Vector Regression, to improve prediction accuracy. Long Short-Term Memory (LSTM) was also utilized for comparative performance analysis. In the first phase, temperature data from Gwangju Metropolian City, provided by the Korea Meteorological Administration from 2020 to 2024, was extracted for initial experiments, serving as training and validation data for the prediction model. The second phase involved measuring the engine heating temperature of a Hyundai YF Sonata gasoline vehicle over 30 minutes, with the collected data used to evaluate the machine learning model's performance. Additionally, an IoT sensor-integrated web monitoring environment was developed, enabling real-time data collection and providing users with an intuitive interface to enhance temperature prediction. This system offers real-time monitoring capabilities, effectively improving vehicle body safety. The research lays foundational data for exploring the applicability of various vehicle models and is expected to advance body safety management systems."
머신러닝 기반 배전계통의 SVR 전압제어 예측 및 정확도 향상에 관한 연구,2025,"['Distribution system', 'Reverse power flow', 'Step voltage regulator', 'Machine learning']",,"The proportion of distributed energy sources in the distribution network is rapidly increasing. Along with this, voltage management is becoming more difficult, and stability issues in the power system are being reported. Until recently, the voltage of distribution lines has generally been regulated using voltage regulators, predominantly deployed in sections where rapid voltage drops occur.However, as the characteristics of distributed energy sources are reflected, the efficiency of the voltage regulator diminishes.Therefore, cooperation with substations is necessary for stable operation of the distribution network. This paper aims to predict the operation of a machine learning-based voltage regulator to evaluate voltage fluctuations occurring in distribution lines and the corresponding control operations in advance. Long Short-Term Memory is capable of prediction on time scales. Therefore, the output characteristics of distributed energy sources can be considered. Additionally, to improve prediction accuracy, cases are generated in the OpenDSS-Python environment and additional training is performed on the LSTM model. As a result, it was confirmed that the prediction accuracy improved when the proposed method was applied. The machine learning model was verified using four evaluation indices."
머신러닝을 이용한 패혈증 진단 코딩 오류 탐지 모형 개발,2025,"['Sepsis', 'Diagnosis coding error', 'Machine learning', 'DBSCAN', 'Clustering', 'Neo-DRG']",,"Purposes: This study aims to develop a machine learning-based model to detect diagnosis coding errors in the diagnosis-related group (DRG)-based payment system in Korea, focusing on sepsis—a diagnosis with the highest adjustment rate.Methodology/Approach: We analyzed five years of inpatient claims data (2015–2019) from a tertiary hospital. A total of 1,068 claims involving sepsis as either a principal or secondary diagnosis were examined using the density-based spatial clustering of applications with noise (DBSCAN) algorithm. Abnormal cases were identified based on discrepancies between DRG-based payments and adjusted fee-for-service (FFS) charges. Key covariates such as age, comorbidity index, length of stay, department, physician, and coder characteristics were controlled for using linear regression. Model performance was evaluated against Health Insurance Review and Assessment Service (HIRA) audit results.Findings: For sepsis coded as a principal diagnosis, the model achieved a balanced accuracy of 55.0% and an overall accuracy of 70.8%. For secondary diagnoses, the model showed a balanced accuracy of 98.9% and an overall accuracy of 97.8%. Notably, the lift value for detecting errors in secondary diagnoses was 22.73 times higher than that of conventional random audits, indicating substantial improvement in screening efficiency under limited review resources.Practical Implications: The proposed model may serve as a first-tier screening tool for HIRA audits, prioritizing high-risk claims. It can also support coder training and discharge documentation review. By integrating machine learning into the DRG monitoring process, this approach offers a scalable and data-driven strategy to improve coding accuracy and ensure sustainable reimbursement operations."
머신러닝을 이용한 뮤지컬 잔여 좌석 예측 프레임워크를 통한 인자 분석,2025,"['뮤지컬 잔여 좌석 예측', '머신 러닝', '프레임워크', 'SHAP', '요인 분석', 'Musical Residual Seat Prediction', 'Machine Learning', 'Framework', 'Shapley Additive exPlanations', 'Factor Analysis']",,"The popularity of musical actors and ticket sales are closely related. However, owing to the increase in production costs caused by star casting, a vicious cycle of ticket price increases and decreased accessibility to musicals continues. To prevent this, we identify the major factors affecting ticket sales and propose a factor analysis method via a machine learning-based musical remaining seat prediction framework. The proposed framework analyzes the factors that have a significant impact on the prediction of remaining musical seats. To verify this, we conducted an experiment using nine machine learning models along with statistical analytical techniques. We analyzed the prediction results of the models using Shapley Additive exPlanations for factor analysis. The Gradient Boosting Regressor model showed the best prediction performance. We confirmed that the discount rate was the most important factor in ticket sales. Through the proposed framework, we efficiently predicted remaining seats and confirmed the most important factors in predicting remaining seats."
머신러닝을 활용한 정치 양극화 영향요인 분석연구: 정서적 양극화를 중심으로,2025,"['정치양극화', '정서적 양극화', '머신러닝', 'XAI', 'political polarization', 'affective polarization', 'machine learning', 'explainable artificial intelligence(XAI)']","본 연구는 한국 유권자의 정서적 양극화에 영향을 미치는 복합적 요인을 규명하고자, 머신러닝 방법론을 적용하였다. 2022년 ｢한국의 정치 양극화 현황과 제도적 대안에 관한 국민인식조사｣ 원자료를 활용, 정서적 양극화가 높은 집단을 판별하는 부스팅 기반분류 모델을 구축하고, 설명가능 인공지능(XAI) 기법인 SHAP 분석을 통해 모델의 예측 결과를 해석하였다. 분석 결과, 역설적으로 ‘정치에 대해 잘 안다’는 주관적 정치 이해도가 양극화를 증폭시키는 가장 강력한 요인으로 나타났다. 또한 이념 성향, 특정 지역 거주, 4연령 등이 양극화 수준이 높은 집단으로 분류될 확률을 높였으나, 높은 정치효능감과 교육 수준은 이를 완화하는 요인으로 작용했다. 특히 정치·사회적 신뢰, 미디어 리터러시 등 다수 변수가 비선형적 관계를 보임을 확인하여, 양극화의 이면에 고착된 인구학적 구조와 가변적 태도가 복합적으로 작동하는 이중 메커니즘을 입증하였다. 본 연구를 통해 사회과학의 복잡한 현상 분석에 있어 머신러닝과 XAI의 유용성을 실증하고, 정치 양극화 완화를 위한 정밀한 정책적 개입의 필요성을 시사한다.","This study employs a machine learning approach to investigate the multifaceted drivers of affective polarization among South Korean voters. Utilizing data from the 2022 ""National Survey on the Current State of Political Polarization in Korea,"" a boosting-based classification model was developed to distinguish groups with high affective polarization. The model's predictions were subsequently interpreted through SHAP (SHapley Additive exPlanations), an eXplainable AI (XAI) framework.Our findings indicate that, paradoxically, a high degree of self-perceived political knowledge is the strongest amplifier of polarization. Factors such as ideological leaning, regional residence, and age were also found to increase the likelihood of belonging to a high-polarization group, whereas higher political efficacy and education levels acted as mitigating forces. Critically, many variables, including political/social trust and media literacy, displayed non-linear effects, confirming a dual mechanism where entrenched demographic structures and fluid political attitudes interact to shape polarization. This research demonstrates the value of machine learning and XAI for analyzing complex social phenomena and underscores the necessity of targeted policy interventions to address political polarization."
머신러닝을 활용한 중소기업 성장 예측: 재무와 정책지원 요인을 중심으로,2025,"['중소기업 성장', '예측', '머신러닝', '재무 요인', '정책지원 요인', 'SME growth', 'Prediction', 'Machine learning', 'Financial status', 'Policy support']","중소기업의 성장과 이에 영향을 끼치는 요소에 관한 오랜 논의에도 불구하고 가장 영향력 있는 요소를 이해하기 위한 연구의 필요성이 제기되고 있다. 더욱이 기존의 실증적 접근에도 불구하고 중소기업의 성장에 관한 정확한 예측에 대해 관심이 커지고 있는 실정이다. 이러한 선행 논의의 간극을 메우기 위해 본 연구는 재무, 정책지원 요소에 관심을 두고 머신러닝 기법을 적용한 분석을 통해 중소기업의 성장 예측에 대한 새로운 시사점을 마련하고자 하였다. 제조 및 서비스업의 중소기업 자료를 기반으로 의사결정나무 기반 머신러닝 모형을 활용하여 중소기업 성장에 대한 예측 성능을 비교하였다. 또한 각 예측 요소에 대한 상대적 중요도를 분석하였다. 분석 결과, 랜덤 포레스트의 예측 성능이 비교적 우수한 것으로 나타났으며, 매출 및 고용 성장 예측에 대해 총자산증가율과 영업이익률, 자기자본이익률, 그리고 총자산회전율 등이 중요한 것으로 나타났다. 이는 지속적인 중소기업의 성장을 위해 기업의 수익적 요인이 개선되어야 함을 의미한다. 정책지원 요인의 경우 중소기업 성장에 대한 영향이 상대적으로 적으나, 긍정적 역할을 가지는 것으로 나타났다. 기업의 특성을 구분하여 분석한 결과, 정책지원 요인의 중요도 순위가 다소 상이하게 나타났다. 이는 중소기업에 대한 정책 지원에 있어 특성을 고려한 맞춤형 시행이 더욱 효율적일 수 있음을 시사한다.","Despite the longstanding discussions on the growth of small and medium-sized enterprises(SMEs) and the factors influencing it, there remains a need for research to understand the most impactful elements. Moreover, there is growing interest in predicting SME growth within the research field. To bridge the gaps in previous discussions, this study focuses on the role of financial status and policy support for SMEs, applying machine learning algorithms to provide new evidence for predicting SME growth. Utilizing decision tree-based machine learning techniques on microdata for SMEs including manufacturing and service sectors, this paper compares predictive performance across different models and analyzes the importance of the features associated with the growth of SMEs.. We find that the random forest exhibits relatively superior predictive performance, with total asset growths, operating margin, return on equity, and total asset turnover rate proving significant role for predicting sales and employment growth, meaning that for sustained growth of SMEs, profitability factors must be improved. While the contributions of the number of policy support to SME growth are relatively small, they play a crucial role in ensuring positive growth for SMEs. We also find that the ranking of relative importance of policy support factors varies based on the firms’ characteristics, suggesting that an implementation considering specific characteristics for SMEs could be more effective."
지역 건강 형평성을 위한 관외 의료 의존도 예측: 머신러닝 기반 분석,2025,"['머신러닝 모델', '관외 의존 의료 횟수와 비용', '의료 의존도', 'machine learning model', 'out-of-area healthcare utilization', 'medical visit and expense dependence']","본 연구는 지역 간 의료 자원의 불균형과 사회․경제적 요인이 지역 주민의 의료 이용 행태, 특히 관외 의료 의존도에 미치는 영향을 실증적으로 분석하고자 하였다. 이를 위해 시군구 단위의 통계자료를 기반으로 인구 구조, 경제 수준, 복지, 의료 자원 등 총 37개의 예측변수를 수집하였으며, 관외 의존 의료횟수 비율과 관외 의존 의료비 비율을 종속변수로 설정하여 예측모형을 구축하였다.분석 방법으로는 머신러닝 기반의 랜덤 포레스트, 그래디언트 부스팅, XGBoost, SVM 등 다양한 알고리즘을 적용하였으며, 각 모델의 예측성능(AUC, Accuracy, F1-score 등)과 변수 중요도를 분석하였다. 또한 설명 가능한 인공지능 기법인 SHAP 분석을 병행하여, 변수별 영향력의 방향성과 기여도를 시각화하고 해석 가능성을 확보하였다.분석 결과, 관외 의존 의료횟수와 비용 예측 모델 모두 랜덤 포레스트와 그래디언트 부스팅 알고리즘이 가장 우수한 것으로 나타났다. 관외 의존 의료횟수를 목표로 한 예측에서는 두 알고리즘 모두에서 의료 자원(의원 수, 간호사 수, 병상 수 등)이 가장 중요한 변수로 도출되었으며, 이는 지역 내 1차 의료기관과 인력의 부족이 관외 진료 빈도를 높임을 시사한다. 관외 의존 의료비 예측에서는 두 알고리즘 모두에서 간호사 수 변수가 중요하게 나타났으며, 그래디언트 부스팅에서는 사회복지사 수, 성비, 경증 장애인 비율 등 복지 및 인구 구조와 관련된 변수도 높은 관외 진료비 지출 예측에 기여하고 있었다.본 연구는 관외 의료의 횟수와 비용을 구분하여 의료 이용의 양적․질적 특성을 분리하여 접근하였으며, 그리고 행정구역 단위의 다양한 지표를 통합하여 지역 기반 보건복지 연계 정책 설계에 실질적인 기초자료를 제공하였다는 점에서 의의가 있다. 또한 WHO의 사회적 건강 결정요인 이론을 실증적으로 적용함으로써 건강 형평성과 관련한 정책 논의의 확장 가능성을 제시하였다. 이러한 분석 결과는 지역별 의료․복지 자원의 배분 우선순위를 설정하고, 데이터 기반 정책 결정을 위한 실용적 근거로 활용될 수 있을 것으로 기대된다.","This study aims to empirically examine how regional disparities in healthcare resources, along with socio-economic conditions, influence healthcare utilization patterns—particularly out-of-area medical dependence—among residents. To this end, we constructed a prediction model using a dataset comprising 37 regional-level predictors at the city–county–district (si-gun-gu) level, including indicators of demographic structure, economic status, welfare capacity, and healthcare infrastructure. The dependent variables were defined as the proportion of out-of-area medical visits and the proportion of out-of-area medical expenditures.The study applied multiple machine learning algorithms—Random Forest, Gradient Boosting Machine (GBM), Extreme Gradient Boosting (XGBoost), and Support Vector Machine (SVM)—to evaluate predictive performance (based on AUC, accuracy, F1-score, etc.) and identify the relative importance of predictors. Furthermore, SHAP (SHapley Additive exPlanations), a state-of-the-art explainable AI technique, was employed to visualize and interpret the direction and magnitude of each variable’s contribution to model predictions.The results demonstrated that Random Forest and Gradient Boosting outperformed other models across both dependent variables. In predicting the out-of-area visit ratio, primary healthcare resource variables—such as the number of clinics, nurses, and hospital beds—emerged as the most influential predictors, indicating that insufficient primary care capacity within regions increases the likelihood of cross-regional healthcare utilization. In predicting out-of-area medical expenditure, the number of nurses remained a critical predictor in both models, while GBM additionally highlighted the importance of welfare and demographic variables such as the number of social workers, sex ratio, and the proportion of individuals with mild disabilities.By distinguishing between visit frequency and healthcare costs, this study provides a dual-dimensional understanding of healthcare utilization behaviors, addressing both quantitative and qualitative aspects. The integration of diverse regional indicators at the administrative level contributes a practical foundation for designing integrated community-based health and welfare policies. Moreover, the empirical application of the World Health Organization’s Social Determinants of Health (SDH) framework offers theoretical insight into addressing regional health inequities. These findings are expected to serve as a data-driven foundation for establishing prioritization strategies in the allocation of healthcare and welfare resources across regions."
머신러닝 기법을 활용한 IoT 기반의 회전기기 고장진단 시스템 구현,2025,"['Fault diagnosis', 'rotation equipment', 'acceleration sensor', 'Mahalanobis', 'machine learning', 'feature points', '고장 진단', '회전 기기', '가속도 센서', '마할라노비스', '머신 러닝', '특징점']","본 논문에서는 접촉식 가속도 센서에서 추출한 진동 데이터를 이용하여 머신러닝 기반의 고장진단 및 진동값의 특징을 추출하는 알고리즘을 제안하였다. 실험장치를 통해 Mahalanobis 거리와 FCM 알고리즘을 이용하여 진동값의 MaD 특징점을 찾고 다차원 분석을 위한 프레임워크를 제시하였다. 제안된 시스템 검증을 위해 머신러닝 모델을 설계하고 실험을 통해 성능을 입증하였으며, 고장진단 시스템이 실시간으로 회전체의 고주파 진동은 물론 저주파 대역에서도 정확한 고장진단이 가능함을 보였다. 이 시스템은 IoT 기술과 AI 상태변화 알고리즘을 활용한 회전기기 진단장치로서 대형 플랜트나 중소 제조기업 등에서 효율적으로 사용할 수 있다.","In this paper, we proposed an algorithm for machine learning-based fault diagnosis and extraction of vibration value characteristics using vibration data extracted from a contact acceleration sensor. Through an experimental device, MaD feature points of vibration values ​​were found using Mahalanobis distance and FCM algorithm, and a framework for multidimensional analysis was presented. To verify the proposed system, a machine learning model was designed and performance was proven through experiments, and the fault diagnosis system was shown to be capable of accurate fault diagnosis not only in real-time high-frequency vibration of the rotating body but also in the low-frequency band. This system is a rotating equipment diagnosis device that utilizes IoT technology and AI state change algorithm and can be used efficiently in large plants and small and medium-sized manufacturing companies."
머신러닝을 활용한 청소년 독서 예측: 주요 영향 요인 분석과 모델 비교,2025,"['독서', '청소년', '머신러닝', '랜덤 포레스트', '그래디언트 부스팅', '한국아동․청소년패널조사', 'reading', 'youth', 'machine learning', 'random forest', 'gradient boosting', 'the Korean Child and Youth Panel Survey']","본 연구의 목적은 머신러닝 기법을 적용하여 중학생들의 독서 여부에 영향을 미치는 요인을 분석하고 최적의 기법을 찾는 것이다. 2018 한국아동․청소년패널 데이터의 독서시간 변수를 이용하여 주중 독서시간이 1시간 이상인 학생을 독서집단으로, 독서를 하지 않은 학생을 비독서집단으로 구분하고 머신러닝 기법으로 로지스틱 회귀, 의사결정나무, 랜덤 포레스트, adaptive LASSO, SVM, 그래디언트 부스팅, kNN을 적용하여 비교 분석하였다. 분석 결과, 랜덤 포레스트와 그레디언트 부스팅이 가장 높은 예측 정확도를 보였다. 앙상블 기법은 비선형적 패턴을 효과적으로 포착하여 독서 여부를 정교하게 분류함을 보여주었다. 부분의존성 도표를 통해 학업 열의, 친구 및 교사 관계, 스마트폰 의존, 자아존중감 등이 독서 결정에 중요한 변수임이 확인되었다. 학업 열의와 자아존중감이 높을수록 독서 확률이 상승하는 한편, 학업무기력과 스마트폰 의존은 독서를 저해하였다. 본 연구 결과는 독서 장려 정책에 필요한 요인을 구체적으로 제시한다는 점에서 의의가 있다. 특히, 학업 동기부여, 친구 및 교사 지원, 미디어 활용 교육 등을 연계한 다각적 접근의 필요성을 시사한다.","The purpose of this study is to identify the factors influencing middle school students’ reading behavior by applying various machine learning methods and to determine which method yields the best performance. Using data from the 2018 Korean Child and Youth Panel Survey, students who read more than one hour per weekday were classified as the reading group, while those who did not read at all were classified as the non-reading group. Seven machine learning methods-logistic regression, decision tree, random forest, adaptive LASSO, SVM, gradient boosting, and kNN-were then applied for comparative analysis. The analysis shows that random forest and gradient boosting achieved the highest predictive accuracy, indicating that ensemble methods can effectively capture nonlinear patterns and distinguish reading behavior more precisely. According to the partial dependence plots, academic engagement, relationships with peers and teachers, smartphone dependence, and self-esteem were significant variables in determining whether students read. While stronger academic engagement and higher self-esteem increased the likelihood of reading, academic helplessness, and excessive smartphone use impeded it. This study is significant in that it provides detailed factors necessary for designing effective reading promotion policies. In particular, it underscores the need for a multifaceted approach that integrates academic motivation strategies, peer and teacher support, and media utilization education."
머신러닝 기법을 적용한 디지털 감사기법에 관한 연구 - 한국철도공사 사례를 중심으로,2025,"['Machine learning', 'Digital audit', 'Capacity building of Audit resources', 'Scenario development', '머신러닝', '디지털 감사', '감사자원 역량강화', '시나리오 개발']","본 연구는 머신러닝 기법을 적용한 디지털 감사기법에 대한 연구로 국내외 사례와 한국철도공사 사례를중심으로 살펴보았다. 디지털의 전환은 감사부문에 있어서 많은 변화가 예측되며 또한 감사기법에 있어서미래에 중요한 역할을 할 것이다. 디지털 감사는 IT 기술을 활용한 감사업무의 혁신으로 감사기구 감사자의IT역량과 감사부서의 IT인프라 구축 및 감사자의 IT 기술 활용이 상호 연관되어 발전하는 것이다. 따라서본 연구결과는 다음과 같은 시사점과 디지털 감사의 방향성을 제시한다. 첫째, 디지털 감사로의 전환은 단순한 IT 인프라 구축이 아니라 머신러닝, 딥러닝 등 감사자원의 고급 역량 강화로 감사의 질적인 향상을 도모해야 한다. 둘째, 자체 기관의 업무 특성을 고려한 시나리오 개발과 연구 가설을 통해 디지털 감사기법의적용에 대한 지속적인 연구가 필요하다. 셋째, 감사원, 공공기관, 민간기업 등에서 추진하고 있는 디지털 감사기법에 대한 상호 정보공유와 체계적인 연구가 필요하며 이는 디지털 감사의 이론적, 실제적 발전을 가져오는 계기가 될 것이다.한편 본 연구는 다양한 공공기관의 디지털 감사기법과 디지털 감사 도입과 운영으로 인한 문제점을 다루지 못한 한계점은 있지만 자체 기관 특성에 맞는 시나리오 개발로 디지털 감사기법 적용 가능성과 함께향후 디지털 감사 발전에 방향성을 제시 했다는데 그 의의가 있다고 하겠다.","This study is a study on digital audit techniques applying machine learning techniques, focusing on domestic and foreign cases, particularly those of the Korea Railroad Corporation (KORAIL). Digital audit represents an innovation of audit work using IT technology, which contains the development of the IT competence of the audit organization auditor, the IT infrastructure of the audit department, and the utilization of IT technology by the auditor. Based on the findings, this study suggests the following implications and direction of digital audit: First, the transition to digital audit should not be limited to building simple IT infrastructure, but it needed to focus on improving the quality of audit by strengthening the advanced capabilities of audit resources such as machine learning and deep learning. Second, it is necessary to continuously study the application of digital auditing techniques through scenario development and research hypotheses considering the work characteristics of its own institutions. Third, mutual information sharing and systematic research on digital audit techniques promoted by the Board of Audit and Inspection, public institutions, and private companies are needed, which will lead to the theoretical and practical development of digital audit.On the other hand, this study has certain limitations in that it does not fully address the challenges may arise by the introduction and operation of digital audit techniques and digital audits in various public institutions. Nevertheless, its significance lies in presenting the direction for future digital audit development along with the possibility of applying digital audit techniques by developing scenarios based on the specific characteristics of each institution."
크롤링과 머신러닝 기법을 활용한 키워드 광고비 예측,2025,"['광고비', '키워드', '크롤링', '머신러닝', 'Advertising Expenses', 'Keyword', 'Crawling', 'Machine Learning']","최근 온라인 광고의 급성장으로 인해 광고비 분석과 예측은 기업의 마케팅 전략 수립에 있어 필수적인 요소로 자리 잡고 있다. 광고비는 기업이자사의 상품이나 서비스를 홍보하기 위해 지출하는 핵심적인 마케팅 비용 중 하나로, 광고 캠페인의 효율성을 극대화하고 각 광고주 간 입찰 경쟁에서우위를 점하기 위해 그 중요성이 더욱 부각되고 있다. 본 연구에서는 다양한 도메인에서 사용하는 키워드와 해당 키워드에 대한 광고비를 예측하는머신러닝 기반 회귀 모델을 제안한다. 이 연구에서 사용된 데이터는 크롤링 기술을 활용하여 수집된 키워드 데이터, 네이버 API(ApplicationProgramming Interface)를 통해 추출한 광고비 예측 데이터, 그리고 광고대행사 데이터를 포함한다. 이를 통해 각 키워드의 광고비를 효과적으로예측할 수 있는 모델을 개발하고자 하였다. 연구 과정에서 LightGBM(Light Gradient Boosting Machine)을 기반으로 한 머신러닝 회귀 모델을구축하였으며, MAE(Mean Absolute Error)를 성능 평가 지표로 사용하였다. 최종적으로 MAE 250 이하의 우수한 예측 성능을 달성하였다. 따라서마케터들이 본 연구에서 제시되는 데이터를 사용하여 광고주와 광고대행사 간의 효율적인 의사결정을 지원할 수 있을 것으로 기대된다.","Due to the recent rapid growth of online advertising, analysis and prediction of advertising costs are becoming essential elementsin establishing a company's marketing strategy. Advertising costs are one of the core marketing costs that companies spend to promotetheir products or services, and their importance is becoming more prominent in order to maximize the efficiency of advertising campaignsand to gain an edge in the bidding competition between advertisers. This study proposes a machine learning-based regression modelthat predicts keywords used in various domains and advertising costs for those keywords. The data used in this study include keyworddata collected using crawling technology, advertising cost prediction data extracted through Naver API(Application Programming Interface),and advertising agency data. Through this, we tried to develop a model that can effectively predict the advertising cost of each keyword.In the research process, a regression model based on the LightGBM(Light Gradient Boosting Machine) was constructed, and the MAE(MeanAbsolute Error) was used as a performance evaluation index. Finally, an excellent prediction performance of less than 250 MAE wasachieved. Therefore, it is expected that marketers will be able to use the data presented in this study to support efficient decision-makingbetween advertisers and advertising agencies."
데이터 기반 학교폭력 예측을 위한 머신러닝 모델 제안,2025,"['School violence', 'Feature engineering', 'Optimization', 'Machine learning', 'Data-driven policy', '학교폭력', '데이터 속성 공학', '최적화', '머신러닝', '데이터 기반 정책']","목적  본 연구는 학교폭력 발생 가능성을 예측하기 위해 관련 데이터 속성 정의 및 최적의 예측 모델을 개발하고, 학교폭력 예측에기여하는 속성을 분석하여, 이후 데이터 기반 학교폭력 예방 정책 연구의 시사점을 제공하는 것을 목적으로 한다.방법  선행연구 분석을 통해 학교폭력 예측과 관련된 데이터 속성을 정의하였다. 정의한 데이터 속성을 바탕으로 서울시 초⋅중등학생 1,274명의 데이터를 수집하여 결측치 제거, 속성 선택 및 변환 등 속성 공학 기법을 적용하고, 이를 기반으로 총 4개의 데이터셋을 구성하였다. 로지스틱 회귀, 랜덤 포레스트, 그래디언트 부스팅 등 다양한 머신러닝 모델을 활용하여 분석하였으며, AUC-ROC 를 주요 성능 지표로 설정하고 그리드 서치를 통해 하이퍼파라미터를 최적화하였다.결과  연구 결과, 모델 최적화 과정을 통해 개발된 모델은 기존 대비 최대 13.24%의 성능 향상을 보였으며, 그래디언트 부스팅 모델이 가장 우수한 성능을 나타냈다. SHAP을 이용하여 속성 기여도 분석을 수행한 결과, 공격 성향, 충동성, 부모와의 관계, 학교생활관련 대화 등의 속성이 학교폭력 예측에 주요하게 기여하는 속성으로 도출되었다.결론  본 연구를 통해 개발된 머신러닝 기반 학교폭력 예측 모델은 학교폭력 가해 가능성을 정량적으로 추정할 수 있다. 또한, 본연구 결과를 바탕으로 학교폭력 예측에 기여하는 속성들을 고려한 학교폭력 발생 전 조기 개입 및 맞춤형 예방 교육의 방향을 제시할수 있다. 본 연구는 데이터 기반 학교폭력 예방 정책 수립 및 현장 적용을 위한 기초 자료를 제공한다는 점에서 의의가 있다.","Objectives  This study aims to define relevant data attributes and develop an optimal predictive model to forecast the likelihood of school violence. Furthermore, it seeks to analyze the attributes contributing to school violence prediction and provide implications for future data-driven school violence prevention policy research.Methods  Based on a review of prior studies, data attributes related to school violence prediction were defined.Using these defined attributes, data were collected from 1,274 elementary and secondary school students in Seoul. Attribute engineering techniques—such as handling missing values, feature selection, and trans formation—were applied, resulting in four distinct datasets. Various machine learning models, including logistic regression, random forest, and gradient boosting, were employed. The AUC-ROC was used as the primary per formance metric, and hyperparameters were optimized via grid search.Results  The optimized models developed through this research demonstrated up to a 13.24% improvement in performance compared to baseline models, with the gradient boosting model achieving the best performance.SHAP analysis revealed that aggressiveness, impulsivity, parent-child relationships, and school-related con versations were key attributes contributing to the prediction of school violence.Conclusions  The machine learning-based prediction model developed in this study enables quantitative estima tion of the likelihood of perpetrating school violence. The findings also offer direction for early intervention and customized preventive education by considering key contributing attributes. This research provides a foundational basis for establishing and implementing data-driven school violence prevention policies"
다핵 상권 젠트리피케이션 위험도 및 결정요인 분석: 머신러닝 기반 예측 모델과 공간분석 기법을 적용하여,2025,"['Gentrification', 'Machine Learning', 'Light Gradient Boosting Machine (LGBM)', 'Spatial Lag Model', 'Polycentric Commercial Structure', '젠트리피케이션', '머신러닝', 'LGBM(Light Gradient Boosting Machine)', '공간시차모형', '다핵상권구조']",,"This study analyzes gentrification risk and its determinants across 214 commercial districts in Busan Metropolitan City by applying machine learning techniques and spatial econometric methodologies. The analysis reveals that developed commercial districts exhibit the highest risk (0.454), followed by traditional markets (0.449) and alley-based commercial districts (0.433). Feature importance analysis based on the light gradient boosting machine model identifies tourism characteristics, population density, and changes in business diversity as the most significant predictive variables, with proximity to transportation hubs positively correlated with increased gentrification risk. Spatial lag model analysis statistically verifies the spatial clustering of gentrification risk (Moran's I=+0.16, p <0.01) and diffusion effects between adjacent commercial districts (ρ=0.28, p <0.05), empirically confirming the spatial transmission characteristics of gentrification. This study proposes customized policy directions for different types of commercial districts and establishes a framework for an early warning system against gentrification. Additionally, it makes a significant academic contribution by comprehensively elucidating the spatial dynamics of gentrification in polycentric commercial districts."
시계열 결측 자료를 고려한 실내 초미세먼지 예측을 위한 머신러닝 모델 비교,2025,"['실내 초미세먼지', '지하철 역사', '머신러닝', '앙상블 모델', '선행시간', 'indoor PM 2.5', 'subway station', 'machine learning', 'ensemble model', 'lead time']",,"Accurate real-time prediction of fine particulate matter (PM 2.5) in enclosed public transport spaces like subway stations is essential for air quality control and public health. This study developed a machine learning-based model designed to maintain stable predictions even with missing time-series indoor air quality data. Three input datasets were prepared using different methods of incorporating outdoor air quality: data from a single site, averages from multiple sites, and individual values from several sites. Five individual machine learning models and three ensemble models, which do not rely on time-series data, were tested for prediction accuracy over 1-4 hour lead times.The XGBoost-Cubist ensemble model performed best (Kling and Gupta Efficiency = 0.838), showing strong and stable accuracy even at longer lead times. Among the datasets, the one using averaged data from multiple outdoor monitoring sites yielded the most reliable predictions with the least accuracy loss over time. The study highlights that using spatially aggregated outdoor air data enhances the robustness of indoor PM₂.₅ forecasts. It also shows the practical value of non-time-series models in dealing with incomplete real-world data, offering insights for future air quality monitoring and alert systems in public transport environments."
한국 성인의 치주질환 예측을 위한 머신러닝 알고리즘 성능 평가 및 분석,2025,"['Big data', 'Prediction model', 'Machine learning', 'Periodontal disease', 'Risk factors']",,"Objectives: This study aimed to enhance the accuracy of predicting periodontal disease using machine learning algorithms and to identify key risk fac- tors essential for developing personalized prevention and management strategies. Methods: Data from 11,781 adults aged 19 years or older were obtained from the 7th Korea National Health and Nutrition Examination Survey (2016–2018). Five machine learning algorithms, including logistic regression, deci- sion tree, random forest, extreme gradient boosting, and CatBoost, were applied. Models were trained and evaluated using a complex sampling design and 10-fold cross-validation. Results: The prevalence of periodontal disease was 27.8%. The CatBoost model demonstrated the highest predictive per- formance (AUC: 0.760). Age, sex, and education level were identified as key predictors, significantly influencing model accuracy. Conclusions: This study highlights the potential of machine learning-based prediction models in the early detection of periodontal disease and the development of personalized prevention strategies."
기어 시스템의 처닝 손실 예측을 위한 입자유동 해석 및 실험 데이터 기반 머신러닝 모델 구축,2025,"['Gearbox', 'Churning Loss', 'Smoothed Particle Hydrodynamics', 'Machine Learning', '기어박스', '처닝로스', '입자유동해석', '머신러닝']","기어박스 하우징은 기어와 베어링 등 주요 회전 부품을 포함하며, 이들의 원활한 작동을 위해 윤활과 냉각을 제공하는 오일이 필수적이다. 그러나 회전 부품과 오일 간의 상호작용으로 인해 필연적으로 발생하는 처닝 손실은 기어박스 효율에 부정적인 영향을 미치게 된다. 기어박스의 성능 최적화를 위해서는 최소한의 오일량으로 충분한 윤활 효과를 제공할 수 있는 설계 전략이 필요하다. 이를 위해 처닝 손실에 영향을 미치는 주요 설계 변수와 그 상관관계를 명확히 이해하는 것이 중요하다. 본 연구에서는 처닝 손실에 대한 실험 데이터를 전산유체해석 SPH방법 결과와 비교하였다. 본 연구를 통하여 처닝 손실 실험을 모사 가능한 SPH 모델을 구축하고 머신러닝 모델링 기반 다양한 작동 조건에서의 처닝 손실 예측 모델을 개발하였다.","The gearbox housing contains essential rotating components, such as gears and bearings, and oil is critical for lubrication and cooling. However, interactions between the rotating parts and oil lead to churning losses, reducing gearbox efficiency. Optimizing gearbox performance requires design strategies that provide sufficient lubrication with minimal oil volume. Understanding the important design variables of the gear system influencing churning losses is essential for this. In this study, experimental data on churning losses were compared with results from smoothed particle hydrodynamics (SPH) analysis. An SPH model that can be used to replicate churning loss experiments was developed, along with a machine-learning-based predictive model for churning losses under various operating conditions. The results highlight the potential of using SPH modeling and machine-learning techniques to predict and minimize churning losses, providing a foundation for gearbox design optimization to improve efficiency."
유연 로봇의 디지털 트윈을 위한 머신러닝 기반 Softness 최적화 기초 연구,2025,"['young’s modulus', 'nvidia isaacsim', 'soft robot', 'machine learning', '.']",,"This study presents a machine learning-based approach for optimizing Young’s modulus, a critical physical parameter of soft robots. Instead of directly utilizing conventional material property data, the method predicts Young's modulus based on positional coordinate data measured from key points on the deformed soft robot. The research consists of simulation and experimental phases. In the simulation phase, the convergence of the Young’s modulus estimation framework is first validated through gradient descent optimization. Subsequently, random forest and neural network models are trained using coordinate data collected over a Young’s modulus range of 10²–10¹⁰ Pa. The random forest model exhibits the lowest RMSE for predicting specific Young’s modulus values (10⁶ and 10⁸ Pa), demonstrating optimal performance. In the experimental phase, deformation data from a TPU-based 3D-printed soft robot are applied to the optimized random forest model to predict Young’s modulus in real-world conditions. The proposed method provides realistic predictions compared to publicly available modulus values. These findings confirm that simulation-trained machine learning models can be effectively applied to optimize soft robot design and control, enhancing the reliability of digital twins and soft robot engineering."
Penman-Monteith 방정식을 사용하여 기준 작물 증발산량을 추정하기 위한 머신러닝 기반 기상인자 예측,2025,"['machine learning', 'penman-monteith equation (FAO 56-PM)', 'reference crop evapotranspiration', 'weather factor', '기준 작물 증발산량', 'Penman-Monteith 방정식(FAO 56-PM)', '머신러닝', '기상인자']","작물 증발산량은 잠재 증발산량에서 작물계수를 곱하여 작물의 요수량을 산출할 수 있어 수자원 관리에 널리 사용되는방법이다. 특히 유엔식량농업기구(FAO)가 관개 및 배수 논문 NO.56에서 발표한 Penman-Monteith　방정식(FAO 56-PM) 은 잠재 증발산량을 추정하는 표준방법으로, 평균온도, 최대온도, 최소온도, 상대습도, 풍속 및 일사량의 6가지 기상 데이터가 필요하다. 그러나　농경지 인근에 설치된 기상센서는 설치 및 유지보수 비용이 높아 결측, 이상치와 같은 데이터 신뢰성 문제를 야기하여 정확한 증발산량 계산을 복잡하게 만든다. 본 연구에서는 인근 기상청의 데이터를 사용하여 필요한6가지 기상 변수를 예측함으로써 기상 센서 없이 작물 증발산량을 추정할 수 있는지 조사하였다. 우리는 기상청의 API를통해 수집할 수 있는 22개의 기상 변수를 입력 데이터로 활용했다. 9개의 회귀 모델을 학습한 후 성능에 따라 상위 3개를 선택하고 하이퍼파라미터 튜닝을 적용하여 최적의 모델을 식별했다. 가장 좋은 성능을 보인 모델은 Extreme Gradient Boosting Regression(XGBR)이었으며 평균온도, 최대온도, 최소온도, 상대습도, 풍속 및 일사량에서 결정계수(R2)가 각 0.98, 0.99, 0.99, 0.91, 0.72, 0.86로 높은 결과를 얻을 수 있었다. 이러한결과는 XGBR 모델이 작물 기상 데이터를 사용하여 작물 증발산 모델에 필요한 입력 값을 정확하게 예측할 수 있어 값비싼 기상 센서가 필요 없음을 시사한다. 이 접근 방식은 센서 설치 및 유지보수가 어려운 지역에서 특히 유용할 수 있으며, 직접적인 센서 데이터 없이도 표준 증발산 모델의 사용을 가능하게 한다.","Crop evapotranspiration can be calculated by multiplying potential evapotranspiration by the crop coefficient, making it widely used method in water resource management. The Penman-Monteith equation (FAO 56-PM), published in Food and Agriculture Organization of the United Nations (FAO) Irrigation and Drainage Paper No. 56, is the standard method for estimating potential evapotranspiration, requiring six meteorological inputs: mean temperature, maximum temperature, minimum temperature, relative humidity, wind speed, and solar radiation. However, weather sensors installed near farmland often come with high installation and maintenance costs, leading to data reliability issues, such as missing values or outliers, which complicate accurate evapotranspiration calculations. This study investigates whether crop evapotranspiration can be estimated without weather sensors by using nearby meteorological data to predict the six required weather variables. We utilized 22 meteorological variables available through the meteorological agency’s API as input data. After training nine regression models, we selected the top three based on performance and applied hyperparameter tuning to identify the optimal model. The Extreme Gradient Boosting Regression (XGBR) model showed the best performance, with R-squared values of 0.98, 0.99, 0.99, 0.91, 0.72, and 0.86 for mean temperature, maximum temperature, minimum temperature, relative humidity, wind speed, and solar radiation, respectively. These results suggest that the XGBR model can accurately predict the necessary inputs for crop evapotranspiration models using meteorological data, eliminating the need for expensive weather sensors. This approach could be particularly beneficial in regions where sensor installation and maintenance are challenging, enabling the use of standard evapotranspiration models without direct sensor data."
머신러닝을 활용한 자폐 스펙트럼 장애 아동의 얼굴영상 분석 파일럿 연구,2025,"['Autism Spectrum Disorder', 'Action Units', 'Artificial Intelligence', 'Facial Video', 'Classification Models', '자폐스펙트럼장애', '액션유닛', '인공지능', '얼굴동영상', '분류모델']",,"This pilot study aims to classify facial videos of children with autism spectrum disorder (ASD) and a control group using machine-learning techniques and to analyze facial characteristics to enhance understanding regarding ASD and develop strategies for its intervention. Three facial-recognition techniques are employed: the classical landmark-based analysis, action units(AUs), and commercial software-based processing. The results based on an initial, small sample indicate that an AI classification model successfully identified distinct patterns and features in the facial expressions of children with ASD and the control group, with the AU-based classification model demonstrating the best performance. These findings suggest that the facial expressions and movements of children with ASD contain meaningful information. Finally, this study underscores the significance of AU-based analysis in investigations on ASD-related social interactions and communication, and is expected to contribute to the development of diagnostic and therapeutic support technologies."
머신러닝 기반 유가증권시장의 한계기업 예측,2025,"['KOSPI Market(KOrea Composite Stock Price Index Market)', 'Distressed Firms', 'Machine Learning', 'Random Forest', '유가증권시장', '한계기업', '머신러닝', '랜덤 포레스트']","한계기업은 재무구조가 부실해 영업활동으로 창출한 이익으로 이자비용조차 감당하지 못하는 기업이다. 부실기업에 대한 사후 관리 방안의 한계를 보완하고 부실징후를 사전 감지하기 위해 한계기업 예측이 필요하다. 본 논문에서는 대표적인 주식 시장인 유가증권시장의 한계기업을 우선 예측한다. 데이터의 다양한 특성을 고려할 수 있어 대규모의 데이터에서도 안정적인 결과를 얻을 수 있는 랜덤 포레스트(Random Forest)를 활용하여 모델링한다. 10-겹 교차 검증(10-Fold Cross Validation)을 통해 모델의 성능을 검증한다. 독립변수의 중요도(Feature Importance)를 계산하여 한계기업의 원인을 상세 분석한다. 실험 결과, 제안 모델은 테스트 데이터에서 정확도(Accuracy) 94.11%, 재현율(Recall) 0.6913, 정밀도(Precision) 0.8047, F1 Score 0.7437의 성능을 보였다. 향후 제안 모델은 기업의 부실징후를 사전 감지하여 기업의 경영 정상화를 촉진하고 효과적인 구조조정 정책 수립에 도움을 줄 것으로 기대한다.","Distressed firms are businesses with weak financial structures that are unable to pay off their debts with operational profits. Predicting distressed firms is necessary to overcome the limitations of post-management measures and to detect signs of distress. We predict distressed firms in the KOrea Composite Stock Price Index Market(KOSPI Market), a major stock market. We use Random Forest, which can use various features and provide stable results even with large datasets. We validate model performance with 10-fold cross-validation. We calculate feature importance to analyze causes of distressed firms. Our model showed 94.11% accuracy, 0.6913 recall, 0.8047 precision, and 0.7437 F1 score on test sets. We expect that our model will help improve business stability and support the development of effective restructuring policies to detect signs of distress."
머신러닝을 이용한 사출 성형 제품의 품질 불량 예측 모델 개발,2025,"['Injection Molding', 'Quality Prediction', 'CNN-LSTM Hybrid', 'Ensemble Learning', 'Smart Manufacturing']","사출 성형 공정은 현대 제조업의 핵심 기술이지만, 공정의 복잡성으로 인해 연간 200억 달러 이상의 품질 불량 손실이 발생하고 있다. 이러한 문제를 해결하기 위해, 본 연구는 사출 성형 공정에서 머신러닝을 활용한 고도화된 품질 불량 예측 모델을 개발하였다. KAMP 데이터셋의 886,227개 샘플과 36개 제조 조건 변수를 활용하여 CNN-LSTM 하이브리드 모델과 앙상블 기법을 결합한 새로운 융합 모델 아키텍처를 제안하였다. 클래스 불균형 문제 해결을 위해 SMOTE, ADASYN 등의 샘플링 기법과 비용 민감 학습을 적용하였으며, 실시간 제조 환경을 위한 지식 증류, 가지치기, 양자화 기법을 통해 모델을 경량화하였다. 실험 결과 F1-score 0.815와 AUC-ROC 0.978을 달성했으며, 이는 동일 데이터셋 기반 선행 연구의 최고 F1-score(0.776) 대비 약 5.0% 향상된 수치이다. 또한 SHAP 분석을 통해 핵심 공정 변수를 식별하고 최적 운영 범위를 제시하였으며, 경량화 모델은 12ms 추론 시간으로 실시간 활용 가능성을 입증하였다.","The injection molding process is a core technology in modern manufacturing, but due to its complexity, it generates over $20 billion in annual losses from quality defects. To solve this problem, this study developed a sophisticated quality defect prediction model for the injection molding process using machine learning. Using the KAMP dataset with 886,227 samples and 36 manufacturing condition variables, we proposed a novel fusion model architecture that combines a CNN-LSTM hybrid model with ensemble techniques. To address the class imbalance problem, sampling techniques such as SMOTE and ADASYN were applied along with cost-sensitive learning, and the model was made lightweight for real-time manufacturing environments through knowledge distillation, pruning, and quantization. Experimental results achieved an F1-score of 0.815 and an AUC-ROC of 0.978, which is an approximately 5.0% improvement over the highest F1-score (0.776) from a previous study based on the same dataset. Additionally, SHAP analysis was used to identify key process variables and present their optimal operating ranges, and the lightweight model demonstrated its feasibility for real-time applications with an inference time of 12ms."
머신러닝 활용 초등영어 교과서 텍스트 군집화 및 그림책 텍스트 분류 연구,2025,"['머신러닝()', '텍스트 군집화()', '텍스트 분류()', '의사소통기능()', '초등영어교육()', 'machine learning', 'text clustering', 'text classification', 'communicative functions', 'primary English education']",,"This study explores how machine-learning technique can enhance text selection in primary English education by clustering textbook dialogues according to their communicative functions and by classifying picture-book texts within the same framework. 484 dialogue texts from five publishers’ Grade 3~6 textbooks were vectorized and clustered with an unsupervised algorithm. 13 clusters aligned perfectly with a single communcative functions, while 32 clusters showed high concordance when second-most frequent function was also considered. The validated cluster labels served as training data in a logistic-regression classifier that assigned seven English picture books to curriculum-specified communicative functions. Four picture books were classified with high probability for a single function, confirming that models trained on textbook dialogues can credibly map out-of-textbook reading materials onto the curriculum. Educationally, the approach furnishes an objective tool for teachers to identify picture-book texts that reinforce the communicative goals of a given unit. More broadly, it demonstrates that quantitative text analytics can reveal latent connections between mandated textbooks and external resources, offering a scalable pathway toward more coherent and diversified input in primary English classrooms."
머신러닝 기반 화석 나이 예측,2025,"['Machine Learning', 'Fossil Age', 'Linear Regression', 'Prediction', '머신러닝', '화석 나이', '선형 회귀', '예측']","화석은 과거에 살았던 생물의 흔적으로, 지구의 역사와 환경 변화의 중요한 단서를 제공한다. 과거 생물 및 환경 변화의 시점을 파악하고 미래의 변화를 예측하기 위해 화석의 나이를 측정할 필요가 있다. 원소의 비율을 활용하여 화석의 나이를 측정하는 연구들이 이뤄지고 있으나 환경적 변화나 보존 상태를 반영할 수 없다는 한계가 존재한다. 이에 본 연구에서는 화석의 다양한 특징을 고려해 나이를 예측하는 머신러닝 기반 회귀 모델을 제안한다. 제안 모델은 테스트 데이터 기준 R-Squared 98.39, RMSE(Root Mean Square Error) 1975.81, 정확도(Accuracy) 99.19%를 보였다. 본 연구에서 제안한 화석 나이 예측 모델은 지질학 및 고생물학 연구에 도움이 될 것으로 기대한다.","Fossils are traces of ancient organisms that provide valuable insights into Earth's history and environmental changes. Predicting fossil ages is important for understanding past biological and ecological changes and future environmental conditions. Carbon-14 and Uranium-Lead dating methods are commonly used to predict fossil ages. However, these have limitations in considering environmental changes and preservation conditions. Therefore, we propose a machine learning-based fossil age prediction model with various features of fossils. Our model showed 98.39 R-Squared, 1975.81 RMSE, 99.19% accuracy in test data. We expect that our model will help in geological and paleontological research."
머신러닝 기반 고객 이탈 예측과 ERFM을 활용한 플랫폼 비즈니스의 고객 세분화 방법론,2025,"['Platform Business', 'Churn Prediction', 'ERFM']",,"Purpose  Platform businesses drive the digital economy through interactions and network effects but face challenges like customer churn. This study aims to develop a framework that evaluates both churn risk and customer value, optimizing marketing strategies and resource allocation.Methods  Churn prediction is conducted using machine learning algorithms, combined with the Extended RFM (ERFM) model, which evaluates recency, purchase frequency, monetary value, and engagement on the platform. This integrated approach assesses both the likelihood of churn and the overall value of each customer.Results  The proposed model identifies high-value customers and predicts churn with accuracy. It supports tailored marketing strategies that enhance resource efficiency and customer retention.Conclusion  By linking churn prediction with value assessment, the study offers insights to enhance customer loyalty, engagement, and profitability, ensuring competitive advantages for platform businesses."
수출입 물류기업의 한계기업 조기 식별을 위한 머신러닝 예측모형 연구,2025,"['한계기업', '물류산업', '머신러닝', 'Zombie Firm', 'Logistics Industry', 'Machine Learning']","본 연구는 수출입 물류산업을 대상으로 머신러닝 기법을 활용하여 한계기업을 조기에 식별할 수 있는 예측모형을 구축하고, 설명가능한 AI 기법인 SHAP(Shapley Additive Explanations)을 통해 주요영향변수를 분석하였다. 구체적으로 2001년부터 2024년까지 국내 물류기업들의 재무자료와 거시경제 지표를 결합하여 로지스틱 회귀, 랜덤 포레스트, XGBoost, LightGBM, CatBoost 등 다섯 가지알고리즘을 교차검증으로 비교하였으며, 그 결과 LightGBM 모델이 가장 높은 예측 정확도를 보였다.이후 선정된 모델에 SHAP 값을 적용한 결과, 기업규모(총자산 로그값), 자산 활용도(총자산회전율), 부채관리 지표(차입금의존도, EBITDA 대비 부채비율), 유동성 지표(유동비율, 당좌비율), 수익성(영업이익률), 성장성(매출액증가율), 생산성(직원 1인당 매출액), 그리고 국내 물동량 성장률 등이 한계기업분류에서 핵심적으로 작용함을 확인하였다. 이러한 결과는 물류기업이 자본집약적 구조와 경기변동에민감하다는 산업 특성을 반영하여, 부채와 현금흐름, 자산 효율성, 그리고 거시환경 지표를 종합적으로 고려해야 함을 시사한다. 본 연구는 조기경보 시스템 관점에서 실무 적용 가능한 고정밀 예측모형을 제안함과 동시에, 한계기업 발생 원인에 대한 구체적 해석을 제공함으로써 물류산업의 부실 예방 및 정책수립에 기여할 수 있을 것으로 기대한다.","This study develops a machine learning-based model for early detection of zombie firms in the export-import logistics industry and applies SHAP (Shapley Additive Explanations) to identify key variables affecting firm insolvency. Using financial data and macroeconomic indicators of Korean logistics firms from 2001 to 2024, we compare five classification algorithms—Logistic Regression, Random Forest, XGBoost, LightGBM, and CatBoost—via cross-validation and find that the LightGBM model achieves the highest prediction accuracy. The SHAP analysis of the final model reveals that corporate size (log of total assets), asset utilization (total asset turnover), debt indicators (debt-to-EBITDA ratio, dependence on borrowed capital), liquidity ratios (current ratio and quick ratio), profitability (operating margin), growth metrics (sales growth rate, revenue per employee), and domestic freight growth rate are critical factors for distinguishing zombie firms. These findings underscore the importance of considering not only leverage and profitability but also firm-specific efficiency, liquidity, and macro-level demand to properly assess bankruptcy risks in the capital-intensive and highly cyclical logistics sector. By presenting a high-accuracy early warning system and offering interpretable insights via SHAP, this study provides practical and policy-oriented guidance for mitigating insolvency risks and enhancing financial stability in the logistics industry."
투표율과 정당 편향 : 머신러닝을 활용한 예측 시뮬레이션,2025,"['투표율', '머신러닝', '시뮬레이션', '정당 편향', '선거', 'voter turnout', 'machine learning', 'simulation', 'party advantage', 'election']","본 논문은 21대 총선과 20대 대선 유권자 조사를 분석하여 투표율과 정당 편향의 관계를 알아본다. 널리 사용되는 머신 러닝 방법을 활용한 예측 시뮬레이션을 통해 총 투표율, 사전투표율, 선거당일 투표율의 상승이나 하락이 정당 득표율과 선거 결과에 어떤 영향을 미치는지를 분석한다. 분석결과, 투표율 상승이나 사전투표율 상승이 진보 정당에 더 유리하다는 통념은 부분적으로만 옳은것으로 나타난다. 투표율만을 가지고 특정 정당에 유리하거나 불리하다는 일관된 결론을 내리는 것은 매우 어려우며, 선거 자체의 특징과 유권자의 선호 변화에 따라 어떤 투표방법의 참여율 변화가어떤 정당에게 더 유리할지는 달라질 수 있다.","This paper analyzes the relationship between voter turnout and party advantage by examining voter surveys from the 21st National Assembly election and the 20th Presidential election. Employing several popular machine learning algorithms, the paper investigates how changes in total voter turnout, early voting turnout, and election day turnout impact party vote shares and election outcomes. The analysis reveals that the common belief that higher voter turnout or early voting turnout benefits liberal parties is only partially true. It is difficult to draw consistent conclusions about whether a higher turnout benefits a specific party based solely on voter turnout, as the impact of participation in different voting methods may vary depending on the characteristics of the election itself and changes in voter preferences."
머신러닝 기법을 활용한 중학생의 영어과목 학업성취  예측 및 주요 요인 탐색,2025,"['Machine Learning', 'Prediction of Academic Achievement', 'Key Predictive Factors', 'Support Vector Machine', 'Decision Tree', '머신러닝', '학업성취 예측', '학업성취 주요 예측요인', '서포트벡터머신', '의사결정나무']","목적  본 연구에서는 다양한 머신러닝 기법들로 중학생의 영어교과 학업성취를 예측하고, 주요 예측요인들을 상대적 중요도를 탐색하여 학년별로 비교⋅분석하였다.방법  이를 위하여 최근접이웃기법(KNN), 의사결정나무(C5.0), 랜덤포레스트(RF), 서포트벡터머신(SVM), 신경망(NNET) 등의머신러닝 기법을 활용하여, 학년별로 기법별 예측력을 비교 및 분석하고, 주요한 예측요인들을 파악하고자 하였다. 학업성취를 학년별로 비교하기 위하여 영어과목 수직척도점수를 활용하였고, 학업성취를 예측하기 위한 요인은 개인수준, 가정수준, 그리고 학교수준으로 나누어 살펴보았다. 이를 위하여 경기교육종단연구(GEPS) 중학교 자료를 사용하였고, 데이터정제를 통해 중학교 1학년499명, 중학교 2학년 486명, 그리고 중학교 3학년 457명을 분석에 투입하였다. 또한 중학생의 학업성취 예측을 위하여 학생수준394개, 가정수준 45개, 학교수준 106개의 요인을 투입하여 결과를 비교 및 분석 하였다.결과  연구 결과를 살펴보면 중학교 1⋅2학년에서는 서포트벡터머신(SVM), 3학년에서는 의사결정나무(C5.0)이 가장 높은 예측성능을 보였다. 또한, 학업 성취의 주요 예측 요인을 분석한 결과, 모든 학년에서 ‘직전 학년 영어 성적’, ‘영어 수업 이해도’, ‘영어교과 효능감’, ‘학습 태도’가 중요한 영향 요인으로 확인되었다. 반면, 부모 학력이나 가구 소득과 같은 가정 환경 요인의 영향력은상대적으로 낮은 경향을 보였다. 특히, 학년이 올라갈수록 학교 환경 요인(학교 만족도, 학급 분위기 등)의 중요성이 점진적으로 증가하는 패턴이 나타났다.결론  본 연구에서는 여러 머신러닝 기법을 활용하여 중학교 학생의 학년별 영어 과목 학업 성취를 예측하고, 주요 예측 요인을 비교⋅ 분석하였다. 또한, 다양한 머신러닝 기법을 비교하여 학년별 최적의 예측 모델을 확인하고, 학업 성취의 주요 영향 요인을 도출하였다.이러한 연구 결과는 향후 수준별 맞춤형 학습 지원의 기초 자료로 활용될 수 있으며, 개별화된 학습 지원 및 교육정책 수립에 기여할것으로 기대된다.","Objectives  This study aims to predict middle school students' academic achievement in English using various ma chine learning techniques and to explore the relative importance of key predictive factors by comparing and ana lyzing them across different grade levels.Methods  To achieve this, machine learning techniques such as k-Nearest Neighbors (KNN), Decision Tree (C5.0), Random Forest (RF), Support Vector Machine (SVM), and Neural Network (NNET) were utilized. The predictive ac curacy of each model was compared and analyzed for each grade level, and the key predictive factors were identified. To compare academic achievement across grade levels, vertical scale scores for each subject were used. The predictive factors were categorized into three levels: individual, family, and school. For data collection, this study used middle school data from the Gyeonggi Education Panel Study (GEPS). After data preprocessing, a total of 499 first-year, 486 second-year, and 457 third-year middle school students were included in the analysis. In total, 394 individual-level variables, 45 family-level variables, and 106 school-level variables were used to predict students' academic achievement, and the results were compared and analyzed accordingly.Results  The findings indicate that Support Vector Machine (SVM) achieved the highest predictive performance for first- and second-year students, while Decision Tree (C5.0) performed best for third-year students. The analysis of key predictive factors revealed that previous-year English grades, English class comprehension, English self-efficacy, and learning attitude were consistently significant predictors across all grade levels. On the other hand, family-related factors such as parental education level and household income had relatively lower predictive power. Additionally, as grade levels increased, the importance of school environment factors (e.g., school sat isfaction, classroom atmosphere) showed a gradual increase.Conclusions  This study utilized various machine learning techniques to predict English academic achievement among middle school students and to compare key predictive factors across different grade levels. Furthermore, the study identified the most suitable predictive model for each grade level by comparing different machine learn ing algorithms. These findings provide valuable insights for developing customized learning support systems and can serve as foundational data for personalized education strategies and future education policy development."
머신러닝 기반 온라인 학습성과의 최적 예측모델 수립(Part 2. 학습참여도 예측모델),2025,"['Learning engagement', 'Machine learning', 'Online learning', 'Predictive model', 'Random forest']",,"This study establishes and validates a predictive model for learning engagement at different stages (pre-learning and mid-learning) in an online learning environment by comparing and utilizing the artificial intelligence algorithms, Random Forest and Cat- Boost algorithms. The data-set used in this research was derived from the Ministry of Employment and Labor STEP platform. The results confirm that the Random Forest algorithm outperforms CatBoost in the domestic online vocational training environment. In particular, key predictive variables in the pre-learning stage include pre-survey satisfaction and age, while in the mid-learning stage, the number of logins per session, total learning days, and learning time per session (in seconds) were identified as significant factors.These findings indicate that key characteristics for managing learner engagement in the domestic online learning context can be predicted with over 90% accuracy. Furthermore, this study reaffirms the significance of behavioral data collected in the STEP learning platform. Additionally, the results of this study were further validated using externally obtained data."
머신러닝 예측 성능을 향상시키기 위한 유도탄 고장 데이터 증강기법에 대한 연구,2025,"['Data Augmentation', 'Machine Learning', 'Guided Missile', 'Jittering', 'Sliding Window', 'Generative Adversarial Networks']","본 본문에서는 머신러닝을 사용하여 유도탄 고장을 예측할 때, 예측성능을 향상시키기 위한 데이터 증강기법을 제안한다. 머신러닝의 데이터는 성능에 큰 영향을 끼치는 요소로 데이터의 부족 문제를 해결하기 위해 다양한 증강기법이 연구되고 있으며, 본 연구에서는 슬라이딩 윈도우, Jittering, 그리고 적대적 생성 신경망을 사용하였다. 데이터 증강 기법을 통해 원시 데이터로부터 새로운 데이터를 생성하여 데이터 양을 증가시킴으로서 머신러닝 학습 시 과적합 문제를 완화하고 예측 성능을 향상시킬 수 있다. 또한, 각각의 데이터 증강 기법의 성능을 비교하기 위해 머신러닝 모델의 예측 성능 지표를 통해 비교하였다. 머신러닝 모델은 보편적으로 사용되는 XGBoost regression를 선정하였다. 결과적으로, 머신러닝 학습 시 Jittering과 적대적 생성 신경망 기법을 적용하여 훈련 세트의 양을 증강 시켰을 때 예측 성능이 크게 향상되었다. 반면, 슬라이딩 윈도우 기법은 예측 성능이 오히려 감소하는 결과를 나타내었다. 데이터 증강 기법을 적용하는 것이 머신러닝의 예측 성능 향상에 반드시 도움이 되는 것은 아닌 것으로 분석된다. 최종적으로 유도탄의 고장 데이터를 사용한 머신러닝 예측 성능 향상을 위한 데이터 증강 기법은 SMOTE 기법과 적대적 생성 신경망 기법을 결합한 방식으로 선정하였다. 데이터의 클래스 불균형 문제를 해결하기 위한 SMOTE 기법을 적대적 생성 신경망 기법과 결합하여 데이터 증강의 효과를 극대화하였다.","In this study, we propose a technique to enhance machine learning prediction performance using missile failure data. To solve the problem of data shortages that greatly affect the prediction performance of machine learning, we applied data augmentation. The techniques used included the sliding window, jittering, and the generative adversarial network. By generating new data from raw data, the overfitting problem in machine learning can be mitigated, and prediction performance can be enhanced. Also, the performance of each data augmentation technique was compared through a prediction performance index of the machine learning model. As a result, machine learning prediction performance was significantly enhanced when the training set was increased by using the jittering and generative adversarial network techniques. Finally, data augmentation to enhance machine learning prediction performance using missile failure data was selected as a method that combines the SMOTE and generative adversarial network techniques."
머신러닝을 이용한 철도 인접구조물의 소음진동 영향 예측,2025,"['도시철도', '인접구조물', '소음-진동영향 매개변수', '머신러닝', 'Urban railway', 'Adjacent structures', 'Noise-vibration impact parameters', 'Machine learning']","본 연구는 지하철 운행이 인접구조물의 소음 진동에 미치는 영향을 분석한 연구로서, 도시철도에 인접한 구조물이 지하철 운행에 따른 소음 진동에 영향을 미치는 주요 매개변수를 도출하였다. 연구 대상은 도시철도의 대표적인 지하철 구조물인 박스와 터널 구조물이며, 수치해석 결과의 상관관계를 분석하고 머신러닝 기법을 적용하여 인접구조물에 미치는 소음 진동 영향 범위를 도출하였다. 이를 통해 기존 수치해석 결과와 머신러닝 기법 적용의 적정성을 비교 분석하였다. 연구 결과, 도시철도 깊이, 구조물 굴착 깊이 및 지하수위의 상대 깊이 차이가 인접구조물의 소음 진동에 영향을 미치는 주요 매개변수로 분석되었으며, 그 중 도시철도 깊이와 구조물 굴착 깊이 간의 차이가 가장 큰 영향을 미치는 매개변수로 도출되었다. 또한, 본 연구에서 제시한 머신러닝 알고리즘을 바탕으로 지하철 운행으로 인한 소음 진동 예측이 가능함을 확인하였다. 따라서 본 연구에서 제안한 예측 기법을 통해 기존의 수치해석에 의존했던 소음 진동 영향 평가를 간편하게 수행할 수 있으며, 이를 바탕으로 민원 발생 가능성을 사전에 파악할 수 있을 것으로 판단된다.","This study is a study on the effect of subway operation on noise and vibration of adjacent structures, and the main parameters affecting the noise and vibration of adjacent structures constructed adjacent to urban railways due to subway operation were derived. The correlation of the numerical analysis results was analyzed, and the machine learning technique was applied to derive the range of noise and vibration effects of subway operation on adjacent structures. The appropriateness of applying the machine learning technique was analyzed by comparing it with the existing numerical analysis results. Based on this, this study proposes a machine learning analysis technique that can predict the subway noise and vibration range based on the field conditions of excavation work adjacent to urban railway lines."
머신러닝 기반의 블레이드 손실 계수 예측 모델에 관한 연구,2025,"['Aerodynamic loss coefficient', 'Machine learning', 'Cuckoo Search Algorithm', 'Optimal XGBoost model', 'CFD Simulation', '공기역학적 손실 계수', '머신 러닝', '뻐꾸기 탐색 알고리즘', '최적 XGBoost 모델', 'CFD 시뮬레이션']","본 논문은 터보 기계 블레이드의 공기역학적 손실 계수의 정확한 예측을 위한 효율적인 머신러닝 모델을 구축하고, 뻐꾸기 탐색 알고리즘을 통해 모델의 일반화 능력과 예측 정확도를 향상시켰다. 기존의 경험적 모델로는 블레이드 기하학적 파라미터와 공기역학적 응답 사이의 매우 비선형적인 관계를 반영하기 어려워서, 일반화 기능을 갖춘 예측 방법의 개발이 시급한 상황이다. 따라서, 본 논문에서는 최대 두께, 두께 위치, 블레이드 굽힘 각도 및 입사각과 같은 주요 설계 파라미터를 고려하고 CFD(computational fluid dynamics)시뮬레이션 데이터를 사용하여 RBF(radial basis function)신경망, SVR (support vector regression) 및 XGBoost 의 세 가지 기계 학습 모델을 구성하고 CSA(Cuckoo search algorithm)를 사용하여 하이퍼 파라미터의 최적화를 수행한다. 제안 방법은 CSA에 최적화된 XGBoost 모델은 여러 평가 지표에서 회귀 계수 R² = 0.973652, 평균 제곱근 오차 RMSE = 6.94367, 평균 절대 오차 MAE = 3.11473으로 다른 모델보다 훨씬 우수한 성능을 보였다. 결론적으로 제안 방법은 머신러닝의 비선형 피팅 기능과 지능형 알고리즘의 파라미터 최적화 이점을 효과적으로 결합하여 블레이드 설계 및 최적화를 위한 데이터 기반 지원방법을 제공한다. 향후 더 복잡한 유동 조건과 3차원 구조가 도입된다면 제안 방법은 기계 동력 분야에서 더욱 널리 사용되어 보다 심도 있는 엔지니어링 응용 연구를 지원할것으로 예상된다.","This paper constructs an efficient machine learning model for accurate prediction of aerodynamic loss coefficient of turbomachinery blades, and improves the generalization ability and prediction accuracy of the model through the cuckoo search algorithm. It is difficult for the existing empirical models to reflect the highly nonlinear relationship between blade geometric parameters and aerodynamic responses, so the development of a prediction method with generalization capability is urgent. Therefore, in this paper, we consider key design parameters such as maximum thickness, thickness location, blade bending angle, and incidence angle, and construct three machine learning models, RBF neural network, support vector regression (SVR), and XGBoost, using computational fluid dynamics (CFD) simulation data, and perform hyperparameter optimization using the CSA algorithm. The proposed method shows that the XGBoost model optimized for CSA performs much better than other models in various evaluation indicators, with regression coefficient R²=0.973652, root mean square error RMSE=6.94367, and mean absolute error MAE=3.11473. In conclusion, the proposed method effectively combines the nonlinear fitting capability of machine learning and the parameter optimization advantage of intelligent algorithms to provide data-driven support for blade design and optimization. If more complex flow conditions and three-dimensional structures are introduced in the future, the proposed method is expected to be more widelyused in the field of mechanical power, supporting more in-depth engineering application research. Keywords: aerodynamic loss coefficient, machine learning, cuckoo search algorithm, CFD simulation."
머신러닝과 텍스트마이닝을 활용한  SNS 상의 비자살적 자해 위험군 식별,2025,"['non-suicidal self-injury(NSSI)', 'social networking service(SNS)', 'risk group', 'detection', 'machine learning', 'text-mining']",,"This study was intended to rapidly and accurately detect non-suicidal self-injury(NSSI) risk groups on social networking services (SNS) using machine learning and text mining methods. Data were collected from the text-based SNS platform, X, using the keyword “self-injury” over a one-year period. Following preprocessing and cross-validation by three researchers, 18,758 posts were labeled (1: NSSI risk posts, 0: non-risk posts). Users were placed in the NSSI risk group if they had at least one NSSI risk post. A transformer-embedding method for natural language processing was then used, followed by supervised machine learning algorithms to validate the detection of NSSI risk and non-risk groups.After the collected SNS posts were labeled, 6,613 posts (35.25%) were identified as NSSI risk posts, while 12,147 posts (64.76%) were identified as non-risk posts. Users who posted risk-related content even once were placed in the at-risk group. Consequently, among the 10,524 participants included in the study, 1,733 users (16.47%) were identified as belonging to the NSSI risk group, and 8,791 users (83.53%) as belonging to the non-risk group. Furthermore, the development of a supervised machine learning model to detect NSSI risk groups on SNS demonstrated excellent performance, achieving an accuracy of approximately 85%. This result highlights the high precision of the model in distinguishing between NSSI risk and non-risk groups on SNS.These results indicate the NSSI risk groups on SNS can be efficiently and accurately identified using machine learning, thereby providing a cost-effective and timely approach for early detection. This study advances previous research by expanding the analytical focus from individual posts to user-level accounts. This approach provides a more comprehensive understanding of self-harm risk groups, which may be challenging to identify at the post-level, and enhances the feasibility of connecting insights to practical interventions."
국제전자상거래 영향요인 분석: 중력 모형과 머신러닝의 결합,2025,"['Cross Border E-commerce', 'Machine Learning', 'Influencing Factors', 'Panel Data', '국제전자상거래', '머신러닝', '영향요인', '패널데이터']","빠르게 성장하고 있는 국제 전자상거래는 기업 중심으로 이루어지던 기존의 국제무역과는 그 참여자와 거래방식의 차이를 보이며, 이에 대한 이해는 국제 전자상거래의 활용에 필수적이다. 본 연구는 머신러닝을 활용한 패널데이터 분석을 통해서 국제 전자상거래에 영향을 주는 요인을 분석하였다. 패널데이터는 한국의 국가별 전자상거래 수출량을 종속변수로 사용하며, 전자상거래 수출에서의 GDP, 거리, 한류의 영향, 전자상거래 인프라, 물류 인프라 등의 변수를 포함한다. 다수의 변수에 대해서 머신러닝을 활용하여 1차로 변수의 중요도를 판별하고, 중요도가 높은 변수를 이용하여 패널데이터 분석으로 검증을 시행한다. 연구 결과, 한류의 영향, 전자상거래 인프라, 물류 인프라가 전자상거래 수출에 영향을 주는 것으로 나타났다. 또한, 머신러닝을 통해 중요도가 높다고 판단된 변수가 통계적으로도 유의한 영향을 주는 것으로 확인되어, 머신러닝을 통한 수출량 영향요인 판단이 가능한 것으로 나타났다. 다만, 영향의 방향에 대한 해석이 불가능하기에 이를 보완하기 위해 통계적인 방법을 함께 사용하는 것이 좋을 것으로 보인다.","Rapidly growing international e-commerce exhibits significant differences in participants and transaction methods compared to traditional international trade, which has been primarily enterprise-centered. Understanding these differences is essential for effectively utilizing international e-commerce. This study analyzes the factors influencing international e-commerce through panel data analysis utilizing machine learning techniques. The panel data uses Korea's country-specific e-commerce export volume as the dependent variable and includes variables such as GDP, distance, the impact of the Korean Wave (Hallyu), e-commerce infrastructure, and logistics infrastructure in e-commerce exports. Initially, the importance of multiple variables is determined using machine learning, and then a panel data analysis is conducted using the highly significant variables to verify the results. The study found that the influence of the Korean Wave, e-commerce infrastructure, and logistics infrastructure significantly affects e-commerce exports. Furthermore, it was confirmed that the variables identified as important through machine learning also have a statistically significant impact, indicating that machine learning can effectively determine the factors influencing export volume. However, since it is impossible to interpret the direction of the impact, it is suggested to use statistical methods in conjunction to supplement this limitation."
기부에 영향을 미치는 주요 예측 변수 탐색 : 머신러닝을 이용하여,2025,"['Donation Behavior', 'Donation', 'Giving Korea Panel Survey', 'Machine Learning', 'Predictive Model', '기부행동', '기부', '기빙코리아패널조사', '머신러닝', '예측모델']",,"· Research topics: This study aims to predict individual charitable giving behavior based on the 2022 Giving Korea survey data and to identify the key factors influencing such behavior using machine learning techniques, thereby providing practical evidence for promoting a culture of giving.· Research background: In recent years, social discussions about donation have been increasing due to the growing sense of social responsibility and community. However, the actual donation rate has been stagnant or declining, so there is a need for practical measures to predict and guide individual donation behavior. In this study, we investigate the factors that influence individual donation behavior and explore the best model to predict donation behavior using machine learning techniques.· Differences from prior research: Previous studies on factors influencing giving behavior have mostly been conducted based on regression analysis. In contrast, this study compares various machine learning models and enhances the accuracy of predicting actual giving behavior by incorporating complex interactions among variables through training and testing.· Research method: This study utilized data from the 2022 Giving Korea survey. A total of 20 explanatory variables were finally selected using data preprocessing to analyze 2,099 adults aged 18 and over who have donated before. The dependent variable was donation behavior, and a total of eight machine learning models were applied. The following metrics were used to compare the performance of each model: Accuracy, Precision, Recall, F1 Score, AUC, and Log-loss.· Research results: Based on the average of the importance of the variables in the top three models, 'agreement with the nonprofit organization' and 'intention to engage in socially engaged activities' were identified as the main factors affecting donation behavior.· Contribution points and expected effects: This study analyzes individual giving behavior using a range of machine learning techniques to provide foundational insights for the development and automation of donation behavior prediction models. It also identifies key influencing factors, offering practical and systematic evidence for the design of targeted strategies to encourage donations and the planning of public interest campaigns. The findings present actionable implications for fostering a culture of giving and enhancing the public good."
머신러닝과 오버샘플링(oversampling)을 이용한 상장기업 부도예측 연구,2025,"['Corporate bankruptcy', 'bankruptcy prediction', 'machine learning', 'imbalanced data', 'SMOTE', 'ADASYN.', '기업부도', '부도예측', '머신러닝', '불균형 데이터', 'SMOTE', 'ADASYN.']","본 논문은 상장기업의 재무 및 거시경제 데이터를 활용하여 기업부도를 예측하는 통계적 모형과 다양한 머신러닝 기법의 성능을 비교하고, 불균형 데이터 문제를 완화하기 위한 오버샘플링 기법의 효과를 분석하였다. 실증 분석에는 로지스틱 회귀, 랜덤 포레스트, XGBoost(extreme gradient boosting), 심층신경망 모형을 적용하였으며, 오버샘플링 기법인 SMOTE(synthetic minority over-sampling technique) 및 ADASYN(adapti-ve synthetic sampling)을 사용하였다. 분석 결과, XGBoost는 원자료뿐 아니라 오버샘플링을 적용한 경우 모두에서 가장 우수하고 균형 있는 예측 성능을 보였다. 반면, 로지스틱 회귀는 높은 재현율을 나타냈으나, 낮은 정밀도로 인해 실무적 활용에는 한계가 있었다. 이러한 결과는 불균형 데이터 환경에서 오버샘플링 기법과 XGBoost와 같은 머신러닝 모형을 결합하여 사용하는 것이 기업부도 예측에 있어 보다 효과적이고 실용적인 접근법이 될 수 있음을 시사한다.","This study compares the performance of statistical models and various machine learning methods in predicting corporate bankruptcy using financial and macroeconomic data from publicly listed companies. It also analyzes the effectiveness of oversampling methods in addressing the class imbalance problem. The empirical analysis employs logistic regression, random forest, XGBoost (extreme gradient boosting), and deep neural networks, along with oversampling techniques such as SMOTE (synthetic minority over-sampling technique) and ADASYN (adaptive synthetic sampling). The results show that XGBoost delivers the most accurate and balanced predictive performance across both the original dataset and the oversampled datasets. In contrast, logistic regression exhibits high recall but limited practical applicability due to its low precision. These findings suggest that combining oversampling techniques with machine learning models such as XGBoost provides a more effective and practical approach to bankruptcy prediction in the context of imbalanced data."
머신러닝을 이용한 수산물 가격 예측 연구,2025,"['푸드테크', '수산물 가격 예측', '머신러닝', '데이터 전처리', '경제 지표', 'food technology', 'seafood price prediction', 'machine learning', 'data preprocessing', 'economic indicators']","수산업은 소득 증가와 경제 성장으로 인해 건강식품 및 편의식품에 대한 소비자 선호도가 증가하면서 큰 성장을 이루었다. 최근 머신러닝 등 첨단 기술의 도입은 수산업 분야의 주요 혁신 동력으로 자리 잡고 있다. 본 연구는 노르웨이 양식 연어의 가격을 예측하기 위해 머신러닝 알고리즘을 활용하여 가격에 영향을 미치는 국가 및 국제 지표를 분석하였다. 연구에서는 선형 회귀(Linear Regression), 의사결정 트리(Decision Tree), 랜덤 포레스트(Random Forest), XGBoost 등의 알고리즘을 적용하여 수산물 가격과 다양한 경제 지표 간의 관계를 모델링하였다. 데이터 품질을 높이기 위해 결측치 처리, 이상치 제거, 정규화 등의 전처리 과정을 수행하였으며, 분산팽창인수(VIF)를 계산하여 다중공선성 문제가 있는 변수를 제거하였다. 예측 결과, 향상된 의사결정 트리(XGBoost) 알고리즘은 ±3 NOK의 오차 범위 내에서 높은 예측 정확도(R2= .90)를 보여, 수산물 시장에서 가격 예측에 적합한 모델임을 확인하였다. 본 연구는 전통적인 통계 모델의 한계를 극복하고 데이터 기반 접근법을 통해 가격 예측의 정확성을 높이는 데 기여하였다. 이를 통해 수산물 유통 시장의 정보 비대칭 문제를 완화하고, 유통업체 및 정책 입안자에게 유용한 정보를 제공함으로써 의사결정을 지원할 수 있다. 또한, 이러한 접근법은 유통 네트워크 최적화와 시장 가격 안정성 강화에도 기여할 가능성을 보여준다.","The seafood industry has experienced significant growth due to rising incomes and economic development, leading to increased consumer preferences for healthy and convenient foods. Recently, the adoption of advanced technologies, including machine learning, has emerged as a key driver of innovation in the seafood sector. This study aims to forecast the price of Norwegian farmed salmon by utilizing machine learning algorithms to analyze national and international indicators influencing price dynamics. The research employed algorithms such as Linear Regression, Decision Tree, Random Forest, and XGBoost to model the relationships between seafood prices and various economic indicators. Data preprocessing techniques, including handling missing values, removing outliers, and normalization, were applied to enhance data quality. Additionally, Variance Inflation Factor (VIF) calculations were performed to eliminate variables causing multicollinearity. The results demonstrated that the enhanced Decision Tree algorithm (XGBoost) achieved high predictive accuracy (R2= .90) with a margin of error within ±3 NOK, confirming its suitability for price prediction in the seafood market. This study contributes to overcoming the limitations of traditional statistical models by adopting a data-driven approach to improve the accuracy of price predictions. It addresses information asymmetry in the seafood distribution market and provides valuable insights to distributors and policymakers, supporting informed decision-making. Furthermore, this approach shows potential for optimizing distribution networks and enhancing market price stability."
머신러닝 방법을 이용한 K-pop 음반판매량 예측,2025,"['머신러닝', '음반판매량', '케이팝', 'machine learning', 'album sales', 'K-pop']","케이팝 산업의 전 세계적 인기로 국내에서 제작된 음반 판매량이 크게 증가하였으며, 특히 코로나19 팬데믹 이후 비대면 문화 소비 플랫폼의 증가로 이러한 경향이 더욱 두드러졌다. 본 논문에서는 다양한 머신러닝 알고리즘을 활용하여 음반의 초동 판매량과 생애 판매량을 예측하는 것을 목표로 한다. 음반의 초동 판매량은 발매 첫 주 동안의 판매량을 의미하며, 음반의 생애 판매량은 음반이 주간 판매량 50위 차트에 처음 등장한 시점부터 50위 밖으로 벗어날 때까지의 총 판매량을 의미한다.데이터는 아티스트 관련 변수, 음반 관련 변수, 경제 관련 변수 등 총 55개의 변수를 사용하였다. 사용된 알고리즘으로는 Linear Regression, Random Forest, Support Vector Machine, XGBoost, LightGBM, CatBoost가 있으며, 이 중 CatBoost 모형이 가장 높은 예측 정확도를 보였다. 분석 결과, 초동 판매량 예측에는 아티스트의 인지도를 나타내는 변수가 가장 큰 영향을 미쳤으며, 생애 판매량 예측에는 음반의 초동 판매량 값이 가장 중요한 변수임이 확인되었다. 이러한 인사이트는 아티스트와 음반의 성공 가능성을 분석하고, 향후 음반 산업의 마케팅 전략 수립 및 예측 모형 개선에 있어 중요한 시사점을 제공한다.","The global popularity of the K-pop industry has significantly increased the sales of domestically produced albums. This trend has become more pronounced, especially after the COVID-19 pandemic, with the rise of non-face-to-face cultural consumption platforms. This paper aims to predict the first-week sales and lifetime sales of albums using various machine learning algorithms. The first-week sales refer to the sales volume during the first week after release, while lifetime sales are the total sales from the time the album first appears on the weekly top 50 charts until it falls out of the top 50.The data used in this study comprises 55 variables, including artist variables, album variables, and economic variables. The algorithms used include Linear Regression, Random Forest, Support Vector Machine, XGBoost, LightGBM, and CatBoost, with the CatBoost model achieving the highest prediction accuracy. The analysis revealed that the variable representing artist recognition had the greatest impact on predicting first-week sales, whereas first-week sales were the most significant variable for predicting lifetime sales. These insights offer critical implications for analyzing the success potential of artists and albums, as well as for developing marketing strategies and improving predictive models in the music industry."
머신러닝과 딥러닝을 활용한 수박의 주요 생육·환경 요인 구명,2025,"['Watermelon', 'Big Data', 'Machine Learning', 'Deep Learning', 'Growth Circumference']","본 연구는 농업 빅데이터를 수집하고 분석하는 연구 분야 중에서 충북 수박 생산량에 영향을 주는 생육, 환경 요인을 구명하였다. 수박에 대한 빅데이터는 충북에서 주로 수집하고 있으나, 아직까지 제대로 된 분석 결과가 없어 빅데이터를 활용하지 못하고 있는 것이 현실이다. 수박 빅데이터는 23년부터 2년간 수박 6 농가를 주 1회 방문하여 생육과 환경 데이터를 수집하여 분석하였다. 생산량 향상에 영향을 주는 수박의 생육 과둘레를 종속 변수로 하여 단계적 변수 선택 회귀, 다층 퍼셉트론(MLP), 장단기 메모리(LSTM), 랜덤 포레스트, 서포트 벡터 머신 회귀(SVMR) 모델 분석을 하였고 생육 과둘레에 영향을 주는 요인은 경경으로 나타났다. 경경 외에 생육 데이터는 초장과 삼번화 마디 수, 엽 수, 엽병장이 영향을 주며, 환경 요인은 최대 습도, 일출 지온, 주간 온도가 통계적으로 유의하게 영향을 주는 것으로 나타났다. 분석한 결과 실제 생육 과둘레의 관측값과 예측값을 비교했을 때 예측력이 높은 모델은 LSTM과 SVMR로 확인되었다. 분석 결과에서 생육 데이터가 많이 도출되었는데 이는 생육 관리를 정밀하게 하여 생산량을 향상시키기 위해서는 생육 데이터가 필수 요소이기 때문이고 이러한 데이터를 관리함으로 농가에서는 재배 의사 결정에 도움을 받을 수 있을 것으로 기대한다.","Among research fields that collect and analyze agricultural big data, this study investigated the growth and environmental factors that affect the production of watermelons in Chungbuk. Big data on watermelons are mainly collected in Chungbuk, but are still not utilized due to lack of proper analysis results. Watermelon data were collected and analyzed by visiting six watermelon farmers once a week for two years from 23 to collect growth and environmental data. Stepwise variable selection regression, multilayer perceptron, long short-term memory (LSTM), random forest, and support vector machine regression (SVMR) models were analyzed with watermelon circumference as the dependent variable . The factor affecting fruit circumference was found to be stem thickness. As a result of the analysis, when comparing the observed and predicted values of growth circumference, the models with high predictive power were LSTM and SVMR. A lot of growth data were derived from the analysis results because growth data are an essential factor to improve production by precisely managing growth. It is expected that farmers can help farmers make cultivation decisions by managing these data."
머신러닝 기반 실시간 여자배구 스코어 분석,2025,"['Lasso', 'random forest', 'SVM', 'text broadcast', 'V-league', 'XGBoost.', '여자배구', 'Lasso', 'random forest', 'SVM', 'XGBoost.']","본 연구는 머신러닝 기법을 활용하여 한국 여자 프로배구 V-리그 경기에서 실시간 스코어를 바탕으로 승패를 예측하는 모델을 제안하고자 한다. 이를 위해 2021-2022시즌부터 2023-2024시즌까지의 정규시즌 363경기 데이터를 수집하여 분석하였다. 수집된 데이터는 경기 전 변수 (시즌 득점률, 최근 5경기 전적, 팀 간 순위 차이 등)와 경기 내 변수 (서브 에이스율, 공격 성공률, 블로킹 성공률 등)로 구성되었다. 본 연구는 random forest, XGBoost, support vector machine (SVM), Lasso regression과 같은 대표적인 머신러닝 기법을 적용하여 경기 진행률에 따른 승패 예측 모델의 성능을 비교·평가하였다. 모델 성능 비교 결과, XGBoost 모델이 가장 높은 예측 정확도를 기록하였다. 분석 결과, 경기 초반에는 경기 전 변수 (시즌 득점률, 승점 등)가 승패에 중요한 영향을 미친 반면, 경기 중반 이후 (특히 3세트 이후)부터는 경기 내 변수 (세트 간 점수 차이, 관중 수 등)의 영향력이 두드러졌다. 연구결과는 스포츠 데이터 분석 분야에서 머신러닝을 활용한 실시간 경기 예측의 가능성을 제시함과 동시에 배구 리그 경기 운영 및 전략 수립에 있어 유용한 참고자료로 활용될 수 있다.","This study aims to predict real-time game outcomes in Korean Women's Professional Volleyball V-League using text broadcast data, thereby contributing to the development of effective game strategies. Data from 363 regular-season matches spanning from the 2021-2022 season to the 2023-2024 season were collected and analyzed. The collected data includes various pre-game and in-game variables (e.g., game time, team ranking differences, service ace rate, attack success rate), and machine learning techniques (XGBoost, random forest, SVM, Lasso regression) were applied to develop a win/loss prediction model. Performance evaluation of the models revealed that the XGBoost model demonstrated the highest prediction accuracy, making it the most suitable model for real-time match prediction. Through an analysis of prediction accuracy by game time, fluctuations occurring in the mid-to-late stages of the game were identified. Key variable analysis confirmed that season scoring rate and points were the most influential pre-game variables, while set difference and spectator count were critical factors in-game. This study demonstrates the effectiveness of machine learning techniques in predicting women's volleyball match outcomes and identifies the key factors influencing win/loss predictions. It is anticipated that the model’s predictive performance can be further improved by incorporating additional variables (e.g., win/loss streaks, timeouts, dig success rate) and playoff data in future research."
자동화 머신러닝을 활용한 교사의 직무만족도 예측모형 및 영향변수 탐색,2025,"['교사 직무만족도', '자동화 머신러닝', '설명 가능한 인공지능', 'SHAP', '서울교원종단연구', ""teachers' job satisfaction"", 'Automated Machine Learning (AutoML)', 'explainable AI', 'SHAP', 'Seoul Education Longitudinal Study of Teachers (SELST)']",,"The purpose of this study is to explore the predictive model and influential variables for teachers’ job satisfaction using first-year data from the Seoul Education Longitudinal Study of Teachers (SELST) 2020. For this purpose, 242 explanatory variables, processed through a preprocessing stage, were used for the analysis. The key findings are as follows. First, when applying Automated Machine Learning (AutoML) techniques, the light gradient boosting machine showed the best performance in predicting teachers' job satisfaction. Second, when the key influential variables of teachers' job satisfaction were derived based on the SHAP index, an explainable AI technique, the top 20 explanatory variables were found to be included in the areas of personal characteristics, teacher quality, school characteristics, and policies and systems. Among these, retirement expectation status, creativity, participation in school management, the current school level (elementary school status), and implementation of teacher policies and systems (normalization of school work) were newly identified as the key influential variables of teachers' job satisfaction through this study. Finally, based on the study findings, multifaceted implications for enhancing teachers' overall job satisfaction and suggestions for future studies were provided."
랜덤 포레스트 머신러닝 분석을 활용한 장애인의 정신건강 위험 요인 탐색: 임금근로 장애인을 중심으로,2025,"['Individuals with Disabilities', 'Mental health', 'Risk factors', 'Machine learning', 'Random Forest.', '장애인', '정신건강', '위험 요인', '머신러닝', '랜덤 포레스트']","연구문제: 이 연구는 장애인의 정신건강 위험 요인을 랜덤 포레스트 머신러닝을 활용하여 분석하고, 주요 예측변수를 도출하는 것을 목표로 하였다. 연구방법: 한국장애인고용패널조사(2024) 8차 데이터를 활용하여 3,736명의 장애인을 대상으로 정신건강 위험군을 예측하는 53개 변수를 분석하였다. 이를 위해 랜덤 포레스트 모델의 성능을 평가하고, 주요 위험 요인을 도출하였으며, 데이터 분석은 SPSS 26.0과 통계 패키지 R 4. 4. 2 버전을 활용하였다. 연구결과: 변수 범주별로는 개인 내적 요인 4개, 장애특성 요인 2개, 경제 요인 2개, 근로 및 직무 요인 1개, 생활습관 요인 1개가 정신건강 위험 예측에 상위 10위의 높은 중요도 지수를 가진 변수들로 나타났다. 그리고 랜덤 포레스트로 구성한 예측모델의 정확도가 높아 전반적으로 신뢰할 만한 결과를 제공하였다. 논의: 이 연구는 랜덤 포레스트 머신러닝을 활용한 장애인의 정신건강 위험 예측 모델을 제시하였으며, 장애수용을 비롯한 장애인에 대한 심리·경제적 지원이 중요한 개입 요인임을 확인하였다. 이러한 점을 바탕으로 장애인 정신건강 증진에 관한 구체적인 정책적 개입과 맞춤형 지원의 필요성을 논의하였다.","Objective: This study aimed to analyze the risk factors for mental health in individuals with disabilities using the Random Forest machine learning technique and to identify key predictive variables. Methodology: The study utilized data from the 2024 Korean Panel Survey of Employment for the Disabled (KPSED), analyzing 53 variables to predict mental health risk groups among 3,736 individuals with disabilities. The performance of the Random Forest model was evaluated, and key risk factors were identified. And data analysis was conducted using SPSS 24.0 and R 4.4.2 Findings: The results indicated that four personal internal factors, two disability-related factors, two economic factors, one work-related factor, and one lifestyle factor were among the top 10 variables with the highest importance scores in predicting mental health risks. Furthermore, the prediction model constructed with the Random Forest method demonstrated high accuracy, providing reliable results. Conclusion: This study presents a predictive model for mental health risks in individuals with disabilities using machine learning, highlighting the significance of psychological and economic support alongside disability acceptance. Based on these findings, the study discusses the need for concrete policy interventions and tailored support to promote mental health in individuals with disabilities."
한국 폐경 여성의 이상지질혈증 예측을 위한 머신러닝 모델 비교 -국민건강영양조사 제 9기 1차년도 자료를 활용하여-,2025,"['폐경 여성', '이상지질혈증', '머신러닝', '예측 모델', 'postmenopausal women', 'dyslipidemia', 'machine learning', 'predictive model']","본 연구는 폐경 여성의 이상지질혈증 예측을 위한 머신러닝 모델을 비교하는 것을 목적으로 수행하였다. 국민건강영양조사 제9기 1차 자료를 활용하였으며, 결측 값을 제외한 폐경 여성 1,115명의 데이터를 분석하였다. 이상지질혈증은 고콜레스테롤혈증 또는 고중성지방혈증 중 하나에 해당하는 경우로 정의하 였다. 대상자의 특성은 IBM SPSS 25.0을 이용해 기술통계 및 교차분석으로 수행하였으며, 머신러닝 분석은 Orange 3.35 프로그램을 활용하여 로지스틱 회귀분석, 랜덤 포레스트, 그래디언트 부스팅 모델을 적용하였다. 연구 결과 대상자의 54%가 이상지질혈증을 보유하였으며, 랜덤 포레스트 모델이 정밀도 0.85, 재현율 0.82 으로 가장 우수한 성능을 보였다. 그래디언트 부스팅 모델은 AUC 0.89로 이상지질혈증 유무를 효과적으로 구분하는 모델임을 확인하였다. 주요 예측 요인은 직업, 나이, 비만, 만성질환 가족력, 모유수유 경험 등이었다. 본 연구는 랜덤 포레스트 모델과 그래디언트 부스팅 모델이 폐경 여성의 이상지 질혈증을 예측하는 데 유용한 도구가 될 수 있음을 제언하며, 폐경 여성 건강문제 해결을 위한 기초자료 로 의미가 있다.","This study compared machine learning models for predicting dyslipidemia in postmenopausal women using data from the first yaer of the 9th Korea National Health and Nutrition Examination Survey. A total of 1,115 postmenopausal women were analyzed after excluding missing values. Participant characteristics were analyzed using SPSS 25.0, while machine learning analysis was conducted with the Orange 3.35 program, applying logistic regression, random forest, and gradient boosting models. Among the participants, 54 percent had dyslipidemia. The random forest model demonstrated the highest performance, achieving a precision of 0.85 and a recall of 0.82, while the gradient boosting model had the highest AUC of 0.89, indicating strong classification capability. Key predictive factors included occupation, age, obesity, family history of chronic diseases, and breastfeeding history. This study suggests that random forest and gradient boosting models can effectively predict dyslipidemia in postmenopausal women, providing essential data for addressing health concerns in this population."
웨어러블 기기 라이프로그를 활용한 치매 진단 예측 머신러닝 모델 비교,2025,"['Dementia Prediction Models', 'Machine Learning', 'Wearable Devices']",,"In response to rapid population aging in South Korea, this study aims to develop and validate an accurate, non-invasive dementia screening tool by comparing and evaluating five machine learning models. We collected wearable device lifelog time-series data—including sleep and gait patterns—and cognitive test results from target patients, then preprocessed these inputs for LSTM, bi-LSTM, Random Forest, XGBoost, and 1D-CNN classifiers. Performance was assessed by accuracy, ROC-AUC, and F1-score; the 1D-CNN outperformed the others with 78.8% accuracy, 81.0% AUC, and a 0.63 F1-score. Logistic regression applied to combined lifelog and cognitive variables identified sleep breathing rate, sleep movement rate, and immediate recall ability as significant predictors. These findings suggest that machine learning models can support early and continuous dementia risk monitoring and inform tailored intervention strategies."
텍스트 마이닝 기반 처방 결정을 위한 머신러닝 모델 선정 - 사상체질 단일 처방 치험례를 활용하여,2025,"['Data Mining', 'Machine Learning', 'Case reports', 'Four-Constitution Medicine', 'Random Forest Classifier']",,"Objectives : We analyzed Sasang constitution case reports using text mining and designed a classification algorithm using machine learning to select a model suitable for determining Sasang constitution prescriptions based on text data.Methods: Case reports on Sasang constitution published from January 1, 2000, to December 31, 2023, were collected.A total of 360 papers and 483 cases were identified, from which text was extracted for 253 cases. The extracted texts were preprocessed and tokenized using the Python-based KoNLPy package, and each morpheme was vectorized using TF-IDF values. To select the most suitable classification model for diagnosing Sasang constitution, the performance of five models—Random Forest Classifier, XGBoost, LightGBM, SVM, and Logistic Regression—was evaluated based on accuracy and F1-Score.Results: The highest accuracy was achieved by Random Forest Classifier (0.57037), followed by SVM (0.544444), Logistic Regression (0.518519), LightGBM (0.481481), and XGBoost (0.474074). The F1 score was highest for Random Forest Classifier (0.528), followed by SVM (0.52039), Logistic Regression (0.500861), XGBoost (0.45866), and LightGBM (0.446349).Conclusions: This study is the first to analyze Sasang constitution prescription decisions by applying text mining and machine learning to case reports, providing a concrete research model for follow-up studies. Based on case reports and text data, the most suitable machine learning model for determining Sasang constitution prescriptions is Random Forest Classifier."
제주도 동부지역의 지하수위 예측을 위한 머신러닝 기법의 적용,2025,"['ANN', 'ELM', 'LSSVR', 'LightGBM', '지하수위', 'ANN', 'ELM', 'LSSVR', 'LightGBM', 'groundwater level']","본 연구에서는 제주도 동부 지역의 지하수위 예측을 위한 머신러닝 모델로서 ANN, ELM, LSSVR, LightGBM을 적용하였으며, 모델 평가지표와 도식적 비교를 통해 적용 모델의 지하수위 예측 성능을 평가하였다. 자기상관성이 강한 지하수위 예측에 있어서 비교 모델들은 1일 예측에서 모두 매우 우수한 예측 성능을 나타낸 반면, 7일 예측에서는 예측 성능이 저하되었으며, 비교 모델들간 예측 성능은 거의 비슷하게 나타났다. 또한, 해안지역의 경우 조위변동의 영향으로 인하여 내륙지역보다 지하수위 예측 성능이 다소 저하됨을 확인할 수 있었다. 자기상관성이 강한 지하수위 예측에 있어서 예측 결과가 비슷하 게 나타날 경우 ANN, ELM 등과 같이 상대적으로 복잡한 상세 튜닝을 필요로 하지 않는 머신러닝 모델의 적용성이 상대적으로 우수할 것으로 판단된다. 따라서 머신러닝 모델을 이용한 지하수위 예측은 제주도의 지하수자원을 위한 효과적인 관리도구가 될 수 있을 것이다.","This study applies ANN, ELM, LSSVR, and LightGBM as machine learning models for groundwater level forecasting in the eastern region of Jeju Island, South Korea. The groundwater level forecasting performance of the applied models is evaluated through model evaluation indices. In forecasting the groundwater levels with strong autocorrelation, the comparative models all show excellent performance in the 1-day forecasting. In contrast, the forecasting performance deteriorates in the 7-day forecasting. The results also show that the forecasting performances among the comparative models are almost similar. In addition, it is confirmed that in coastal areas, groundwater level forecasting performance deteriorates compared to inland areas due to the influence of tidal variation. When forecasting results are similar in forecasting the groundwater levels with strong autocorrelation, models that do not require relatively complex detailed tuning, including ANN and ELM, can have excellent applicability. Therefore, groundwater level forecasting using machine learning models can be an effective tool for groundwater resources in Jeju Island."
선박의 사이버 보안 강화를 위한 머신 러닝 기반한 랜섬웨어 침입 실시간 탐지 시스템,2025,"['Maritime Cybersecurity', 'Ransomware', 'Machine Learning', 'Artificial Intelligence', 'Real-time Intrusion Detection System', '선박 사이버 보안', '랜섬웨어', '머신러닝', '인공지능', '실시간 침입 탐지 시스템']","본 연구는 해운 산업의 디지털 전환에 따라 증가하는 사이버 위협, 특히 랜섬웨어공격으로부터 선박의 안전을 확보하기 위한 실시간 침입 탐지 시스템(IDS)을 제안하였다. 본 시스템은 머신 러닝 기법인 Support Vector Machine(SVM)과 인공지능(AI) 기반 미래 예측 기능을 결합하여, 선박 내부의 네트워크 트래픽, 시스템 로그, 파일 접근 정보, 사용자 활동 로그 등을 분석함으로써 랜섬웨어 침입을 조기에 탐지하고 실시간으로 대응할 수 있도록 설계되었다.실험은 24,000 TEU급 선박 3척의 실제 운항 데이터를 바탕으로 수행되었으며, 제안된 시스템은 기존 탐지 방식에 비해 평균 탐지 확률은 약 63%로 15% 향상되었고, 오탐률은 3% 미만으로 낮게 유지되었다. 또한 실시간 대응 시스템을 통한 탐지-대응속도는 평균 0.5초 이내로 측정되며, 랜섬웨어 확산 차단에 효과적임을 입증하였다.이 시스템은 선박 환경에 적합한 경량 구조로 구현되어, 자율운항선박 및 스마트항만 보안 체계와의 연계 가능성도 제시한다. 본 논문은 해상 사이버 보안 강화에실질적으로 기여할 수 있는 기술적 방안을 제안하며, 향후 다양한 사이버 위협을 포괄하는 통합 보안 시스템 구축을 위한 기반으로 활용될 수 있을 것이다.","This study proposes a real-time Intrusion Detection System (IDS) to enhance maritime cybersecurity against increasingly sophisticated threats, particularly ransomware attacks, in the era of digital transformation in the shipping industry. The proposed system integrates Support Vector Machine (SVM), a machine learning technique, with AI-based future prediction to detect ransomware intrusions early and respond in real time by analyzing onboard network traffic, system logs, file access records, and user activity data.Experiments were conducted using real operational data from three 24,000 TEU-class container vessels. The system demonstrated an average detection accuracy of approximately 63%, showing a 15% improvement over conventional methods. The false positive rate remained below 3%, and the average response time was measured to be under 0.5 seconds, confirming the effectiveness of the system in promptly mitigating ransomware spread.Designed as a lightweight system suitable for shipboard environments, the proposed IDS also offers potential for integration with autonomous vessel operations and smart port security architectures. This paper presents a practical solution to maritime cybersecurity threats and provides a foundation for future development of integrated security frameworks capable of countering diverse cyberattacks."
한국프로야구 경기결과 예측을 위한 머신러닝 성능 비교와 스포츠 팬 몰입(fan engagement) 함의에 관한 탐색적 연구,2025,"['인공지능', '경기결과 예측', '팬 몰입', '스포츠 애널리틱스', '한국프로야구', 'Artificial intelligence', 'Game result prediction', 'Fan engagement', 'Sports analytics', 'Korean professional basebal']","본 연구는 프로스포츠 팬의 가장 큰 관심사인 경기결과 예측을 통해 팬의 해당 스포츠에 몰입할 방안을 탐색적으로 모색하기 위해 실시되었다. 이를 위해 본 연구에서는 한국프로야구 경기결과 예측을 위한 머신러닝 성능 비교와 팬 몰입(fan engagement) 함의에 관한 탐색적 연구를 시행하였다. 실증적인 분석을 위해 본 연구에서는 Python 3.11.5을 활용하여 한국 프로야구 통계 전문 사이트인 스탯티즈(https://statiz.sporki.com/)에서 2013~2023시즌의 15,488(n=30,976)경기와 관련한 108개 변수를 수집하였다. 실제 프로야구 경기가 시작하기 전 알 수 있는 상대 팀과의 팀/선수 간 상대성을 반영하고, 최근 경기 흐름을 반영하여 데이터 세트를 구축하였다. 이후 경기결과 예측을 위하여 7가지 인공지능 알고리즘(로지스틱 회귀, 선형 서포트 벡터 머신, 엑스트라 트리, 서포트 벡터 머신, Light-GBM, 그래디언트부스팅, 인공신경망)을 통해 데이터를 분석하였다. 분석 결과, 단계적 선택법을 통해 도출한 18개 변수를 로지스틱 회귀 모델에 적용하였을 때의 예측 정확도가 59.3%로 가장 우수하였다. 본 연구는 프로야구 경기를 보는 팬들이 경기가 발생하기 전 양 팀 간의 경기결과를 예측하기 위해 사용 하는 암묵적인 정보들을 명시적으로 활용하여 팬이 경기에 몰입할 수 있는 정보를 제공할 수 있는 학술적 근거를 마련하였다는 점에서 이론적·실무적 시사점을 지닌다.","This study was conducted to explore fan engagement implications by predicting game results, which is the biggest concern of professional sports fans. We conducted an exploratory study to assess machine learning application for predicting the outcome of Korean professional baseball games and compare the performance of accuracy. For the empirical analysis, we used Python 3.11.5 to collect 108 variables related to 15,488 (n=30,976) games from the 2013-2024 seasons from Statiz (https://statiz.sporki.com/), a site specializing in Korean professional baseball statistics. The data set was constructed to reflect the relativity of teams/players to opposing teams known before the start of the actual baseball game and to reflect the recent game flow. The data was then analyzed using seven AI algorithms (Logistic Regression, Linear Support Vector Machine, Extra Tree, Support Vector Machine, Light-GBM, Gradient Boosting, and Artificial Neural Network) to predict game outcomes. The empirical results showed that the logistic regression model with 18 variables derived from the step-wise selection method had the best prediction accuracy of 59.3%. This study has both theoretical and practical implications providing academic basis for explicitly utilizing the implicit AI-based sports game prediction model for fan engagement."
산업용 인버터 고장예측을 위한 머신러닝 및 딥러닝 모델의 성능 평가 및 개선 연구,2025,"['industrial Inverter', 'Fault Prediction', 'Machine Learning', 'Deep Learning', 'Anomaly Detection']",,"In industrial settings, inverters play a critical role in maintaining productivity and ensuring stable equipment operation. However, inverter failures can result in production downtime and increased maintenance costs. Traditional fault prediction methods based on physical models and expert experience often struggle to capture complex patterns and adapt to varying operational conditions. To address this, this study evaluates the performance of statistical, machine learning, and deep learning approaches for industrial inverter fault prediction, using operational data from a 90W-class inverter at an automotive parts manufacturer in Daegu, South Korea. The experimental results demonstrate that unsupervised anomaly detection models, particularly Autoencoder and SOM, achieved the highest accuracy. These findings suggest that models capable of detecting deviations from normal operating patterns are more effective for inverter fault prediction than conventional methods. In contrast, SVM and Logistic Regression exhibited limitations in handling time-series complexity. This study highlights the necessity of deploying real-time monitoring and predictive maintenance systems in industrial environments, with future research focusing on hyperparameter optimization and real-time data streaming validation."
웨어러블 압력 센서를 이용한 발 압력중심 예측: 데이터 전처리와 증강이 머신러닝 모델에 미치는 영향,2025,"['Wearable pressure sensors', 'Center of pressure', 'Machine learning', 'Data augmentation', 'Gait analysis']","본 연구는 적은 수의 압력센서를 활용하여 보행 시 압력중심(COP, Center of Pressure) 궤적을 예측하고, 데이터 전처리 및 증 강 기법이 예측 성능에 미치는 영향을 분석하였다. 상용 압력 깔창에서 9개의 FSR센서를 선정하여 데이터를 수집하였고, 이를 바탕으로 COPanterio-posterior(COPap)와 COPmedial-lateral(COPml)의 궤적을 예측하였다. 머신러닝 모델(Neural Network(NN), Random Forest(RF), Support Vector Machine Regression(SVMR), k-Nearest Neighbors Regression(KNNR))을 통해 변수 선택 및 데 이터 증강 기법의 효과를 평가하였다. COPap 예측에서는 KNNR 모델의 Model III가 RMSE 11.6 mm, R2 0.97로 모든 모델 중 가 장 우수한 성능을 기록하였다. 데이터 증강과 변수 선택이 성능 향상에 효과적으로 기여한 것으로 나타났다. 반면, COPml 예측 에서는 KNNR 모델의 Model III가 RMSE 7.4 mm로 낮은 값을 기록하였으나, R2는 0.4으로 제한적인 성능을 보였다. 이는 COPml 데이터의 복잡성과 비선형적 특성으로 인해 FSR 센서만으로는 충분한 설명력이 부족했음을 시사한다. 본 연구는 제한된 수의 센서로도 COP 예측이 가능함을 입증하며, 데이터 증강과 변수 선택기 기법의 실효성을 제시하였다. 향후 연구에서는 다양한 보행 환경에서의 데이터 수집 및 FSR 센서 데이터의 활용도를 높이기 위한 비선형 모델링 접근을 포함한 추가 연구를 통해 예 측 성능을 개선하고 실시간 보행 분석 시스템으로 확장할 필요가 있다.","This study aims to predict the trajectory of the Center of Pressure (COP) during walking using a small number of pressure sensors and the impact of data preprocessing and augmentation techniques on prediction performance. Data were collected from nineFSR sensors selected from a commercially available pressure insole, and the trajectories of COPanterio-posterior (COPap) andCOPmedial-lateral (COPml) were predicted. The effects of variable selection and data augmentation techniques were evaluatedusing machine learning models, including Neural Network, Random Forest, Support Vector Machine Regression, and k-Nearest Neighbors Regression. For COPap prediction, the KNNR model’s Model III achieved the best performance with an RMSE of11.6 mm and an R² of 0.97, demonstrating the significant contribution of data augmentation and variable selection to performanceimprovement. In contrast, for COPml prediction, the KNNR model’s Model III recorded the lowest RMSE of 7.4 mm but showeda limited R² of 0.40. This suggests that the complexity and nonlinearity of COPml data were not sufficiently addressed using onlyFSR sensors. This study demonstrates the feasibility of COP prediction with a limited number of sensors and highlights the effectiveness of data augmentation and variable selection techniques. Future research should focus on collecting data in diverse walkingenvironments and improving prediction performance through nonlinear modeling approaches, ultimately aiming to expand towardreal-time gait analysis systems."
창업가의 언어적 스타일과 자금조달 성과 간의 관계: 머신러닝 알고리즘을 중심으로,2025,"['크라우드 펀딩', '자금조달', '창업가', '언어적 스타일', 'LIWC', 'Kiva', '머신러닝', 'Crowdfunding', 'Fundraising', 'Founders', 'Linguistic Style', 'LIWC', 'Kiva', 'Machine Learning']",,"Global crowdfunding platforms are growing in popularity as a source of funding for entrepreneurs. Much of the prior research on crowdfunding has focused on project success factors, and an under-researched topic is the linguistic style of founders. A small number of researchers have examined the linguistic characteristics of content within reward-based crowdfunding. According to speech act theory, not only what founders try to convey, but also how they convey it(i.e. their linguistic style) is likely to affect performance. In this study, we use machine learning algorithms to analyze the impact of different founders' linguistic styles on fundraising performance in the crowdfunding context. Specifically, we use latent class analysis(LCA), an unsupervised learning method, to categorize combinations of linguistic styles into classes and analyze whether there are differences in funding performance based on these classes. We also utilize the Random Forest algorithm, a supervised learning method, to predict funding performance and explore the importance and direction of influence of each linguistic style variable based on Shapley value. For the empirical analysis, we collected data from 16,279 campaigns on Kiva, a crowdfunding site. Linguistic style was measured using the linguistic inquiry and word count(LIWC) program. The LCA revealed that four linguistic style tiers were the best fit, and there were significant differences in fundraising performance across tiers. The random forest model predicted fundraising performance relatively accurately(AUC = .71), and the importance of the variables was in the following order: word count, external focus, analytical style, and positive style."
하이퍼파라미터 최적화를 통한 머신러닝 모델 비교와 SHAP 분석을 활용한 KBL 경기 예측,2025,"['machine learning', 'SHAP analysis，feature importance，hyperparameter optimization', '머신러닝', 'SHAP 분석', '특성 중요도', '하이퍼파라미터 최적화']","본 연구는 2021-2024 시즌 동안의 한국 프로농구 리그(KBL) 경기 데이터를 분석하여 다양한 머신러닝 알고리즘을 활용해 경기 결과를예측하고 평가하였다. 하이퍼파라미터 최적화와 10겹 교차 검증을 통해 XGBoost 모델이 경기 예측에서 다른 알고리즘보다 우수한 성능을 보여 높은 정확성과 일반화 능력을 입증하였다. 경기 예측에서 XGBoost 모델은 정확도 86.1%, 정밀도 0.840, 재현율 0.896, F1 점수 0.867의 성능을 달성하였다. SHAP 분석 결과, 수비 리바운드(DREB)와 필드골 성공률(FG%)이 가장 중요한 특성으로 나타났다. 턴오버(TO)는 경기 결과에 부정적인 영향을 미쳤으며, 스틸(STL)과 공격 리바운드(OREB)는 긍정적인 요인으로 작용했으나 경기 후반에는 그 영향이 감소하는 경향을 보였다. 이러한 연구 결과는 턴오버 관리를 효과적으로 수행하는 것이 경기 후반의 부정적인 영향을최소화하는 데 필수적임을 시사한다. 또한, 3점슛 성공률(3P%)과 자유투 성공률(FT%)을 장기적으로 개선하면 팀 성과를 더욱 향상시킬 수 있음을 보여준다.","This study analyzed game data from the Korean Basketball League (KBL) during the 2021-2024 seasons to predict and evaluate game outcomes using various machine learning algorithms. Through hyperparameter optimization and 10-fold cross-validation, the XGBoost model demonstrated superior performance in game prediction compared to other algorithms, proving its high accuracy and generalization ability. The XGBoost model achieved an accuracy of 86.1%, a precision of 0.840, a recall of 0.896, and an F1 score of 0.867. According to SHAP analysis, defensive rebounds (DREB) and field goal percentage (FG%) were identified as the most important features. Turnovers (TO) negatively impacted game outcomes, while steals (STL) and offensive rebounds (OREB) were positive factors; however, their influence tended to diminish in the later stages of the game. These findings suggest that effective turnover management is essential for minimizing negative impacts during the latter part of the game. Furthermore, the study indicates that long-term improvements in three-point shooting percentage (3P%) and free throw percentage (FT%) can further enhance team performance."
머신러닝 기법을 적용한 방공부대 진지선정에 관한 연구,2025,"['METT-TC', 'Machine Learning', 'Random Forest', 'Priority Site Selection', 'Air Defense Unit']",,"In modern warfare, air power-including missiles, drones, and air force operations-has become a critical determinant of victory, emphasizing the increasing importance of air defense capabilities. One of the key challenges faced by commanders is the selection of optimal defensive positions for air defense units. This decision must consider various factors, such as mission objectives, terrain, slope, road accessibility, and predicted enemy approach routes. This study presents a methodology for selecting air defense unit positions using the Random Forest technique within the METT-TC (Mission, Enemy, Terrain, Troops Available, Time Available, Civil Considerations) framework. By integrating these key elements, the Random Forest algorithm evaluates and ranks potential defensive positions, encompassing both pre-planned and alternative areas. The results of this study demonstrate that the proposed model provides effective support for commanders in prioritizing positions for air defense, artillery, logistics, and other units, thus enhancing operational effectiveness and survivability in both wartime and peacetime contexts."
머신러닝 기반의 감성분석을 활용한 공공체육시설의 이용 만족도 평가모형 개발 및 개선사항 도출,2025,"['Public sports facilities', 'Sentiment analysis', 'User satisfaction', 'Machine learning', 'Improvements', '공공체육시설', '감성분석', '이용 만족도', '머신러닝', '개선사항']","이 연구는 공공체육시설의 네이버 이용 후기자료를 활용하여 공공체육시설의 이용 만족도 평가모형을 개발하고 나아가 부정적 이용 후기에 대한 세부적인 분석을 통해 공공체육시설의 개선방안을 도출하는 것이다. 연구의 목적을 달성하기 위해 7개의 광역시의 151개의 공공체육시설의 네이버 이용 후기를 51,850개를 수집하였으며, 특수문자, 굿, 좋아요 등 이용 후기가 짧은 자료와 홍보성 자료는 제거하고 최종적으로 선정된 자료는 3,164개로 선정하였다. 분석방법으로 주요 키워드를 확인하기 위해 키워드의 TF와 TF-IDF를 산출하였고, 감성사전 모델링을 위해 Lasso 모형을 적용하였다. 또한, 토픽모델링 중 LDA 알고리즘 적용하여 부정적 이용후기에 대한 세부적인 개선사항을 파악하였다. 이 연구의 결과 첫째, Lasso 모형을 적용하여 공공체육시설의 이용 만족도를 평가할 수 있었으며, 모형의 정확도는 83.2%로 나타났다. 둘째, 공공체육시설을 평가하는데 있어 긍정적인 단어로는 운동, 가격, 시설 등의 단어가 나타났으며, 부정적인 단어로는 별로, 이해, 주차 등의 단어들이 나타났다. 셋째, 공공체육시설의 개선사항은 주차공간과 주차관리 개선, 자유수영과 수질 개선, 프로그램 등록관련 개선 등으로 나타났다. 이는 향후 공공체육시설의 이용 만족도를 평가하는데 객관적인 모형으로 활용할 수 있을 것이며, 제시된 개선사항을 반영하여 공공체육시설의 서비스 품질을 향상시키는데 기초자료로 활용될 수 있을 것이다.","This study developed a satisfaction evaluation model of public sports facilities using review data on Naver for public sports facilities, and further derived improvement measures for public sports facilities through detailed analysis of negative reviews. To achieve the purpose of the study, 51,850 reviews on Naver for 151 public sports facilities in 7 metropolitan cities were collected, and short reviews such as special characters, good were removed, and 3,164 were finally selected. In order to identify major keywords as an analysis method, TF and TF-IDF of keywords were calculated, and the Lasso model was applied for sentiment dictionary modeling. In addition, the LDA algorithm among topic modeling was applied to identify detailed improvements for negative reviews. First, the Lasso model was applied to evaluate the satisfaction level of public sports facilities, and the accuracy of the model was 83.2%. Second, positive words for evaluating public sports facilities included exercise, price, facilities, while negative words included not so good, understanding, parking. Third, improvements in public sports facilities included improvements in parking space and parking management, improvements in free swimming, improvements in program registration. This can be used as an objective model for evaluating the satisfaction level of public sports facilities in the future, and can be used as basic data for improving the service quality of public sports facilities by reflecting the suggested improvements."
머신러닝을 활용한 아까시나무의 개화 및 낙화일 예측모델 개발,2025,"['Robinia pseudoacacia', 'Blooming', 'Petals falling']",,"In recent years, due to the effects of rapid climate change, the blooming and falling seasons of acacia trees distributed on the Korean Peninsula have changed significantly, causing great damage to the beekeeping industry. Therefore, this study aimed to find a prediction model that predicts the actual blooming and falling season of acacia trees with a small margin of error by using a total of 27 variables, including weather and location data, and machine learning to predict the blooming and falling season of acacia trees observed at five locations nationwide over the past 10 years (2015~2024). Three models were used: RandomForest, Support Vector Machine (SVM), and CatBoost, and various hyperparameter combinations were created and applied to the models using GridSearchCV. The prediction results showed that RandomForest and Support Vector Machine (SVM) performed well, with an error range of 0.1~2.66 days."
머신러닝 인과 인공지능의 제약 조건으로서 단순성 원리의 필요성: 오컴 면도날의 재발견,2025,"['과적합', '단순성', '머신러닝', '오컴의 면도날', '인과 모형', '인공지능', 'AI', 'causal models', 'machine learning', 'over-fitting', 'simplicity', 'Ockham’s (Occam’s) razor']",,"In the field of data mining, Domingo argues for Domain Constraints as an alternative to it while criticizing the second concept of Ockham's Razor. I argue against Domingo’s argument that Ockham's Razor, which is called the simplicity principle, is rather necessary and important for causality to implement as domain constraints. I show that simplicity must be applied at many different levels and in many different domains. In Chapter 2, I see what Ockham's Razor as a simplicity principle entails. In Chapter 3, I introduce three justifications for the simplicity principle. In Chapter 4, I introduce what problems the data over-fitting problem poses for machine learning AI. In Chapter 5, I notice that Domingo explicates Occam's Razor in two different concepts. In Chapter 6, I introduce causal model theory as a theory of domain constraints. In Chapter 7, I show that the Markov condition and the Faithfulness condition underlying causal models correspond to the simplicity principle. In Chapter 8, I show how Ockham's Razor leads us to discover and to infer the most optimally fitted data among many different causal structures."
머신러닝을 활용한 장르별 음원 인기 예측,2025,"['머신러닝', '스포티파이', '음원', '인기 예측', '장르', 'Genre', 'machine learning', 'music', 'popularity prediction', 'Spotify']","본 연구에서는 장르별로 음원의 인기를 예측하는 모델을 제안하였다. 이를 위하여 글로벌 음악 스트리밍 플랫폼인 스포티파이로부터 14,678개 음원에 대한 음향 특성 데이터를 수집하고 네 가지 장르를 대상으로 머신러닝 모델을 구축하였다. 성능 비교 결과, rap과 R&B는 XGBoost, rock과 electronic 장르에서는 random forest 모델이 가장 우수한 음원 인기 예측 성능을 보였다. 변수 중요도 분석과 SHAP 분석을 통하여 음원의 음향 특성과 인기와의 관계를 실증적으로 확인하였으며 장르별로 어떠한 차이가 있는지 분석하였다. 본 연구 결과는 음원 제작과 큐레이션 전략 수립을 포함하여 음원 산업에서의 데이터 기반 의사결정을 지원하는데 유용할 것이다.","This study proposes a model for predicting the popularity of music tracks by genre. To achieve this, acoustic feature data for 14,678 tracks were collected from the global music streaming platform Spotify and machine learning models were developed for four genres. Performance comparisons revealed that XGBoost performed best for predicting the popularity of rap and R&B tracks, while random forest achieved the highest accuracy for rock and electronic genres. Through feature importance analysis and SHAP analysis, the relationship between acoustic characteristics and track popularity was empirically examined, along with genre-specific differences. The findings of this study can support data-driven decision-making in the music industry, including music production and curation strategy development."
서울시 대규모⋅중소규모 점포 매출액 및 위치데이터 기반 머신러닝을 활용한 상권 클러스터링,2025,"['Machine learning', 'Retail district', 'Cluster', 'Store', 'Sales', '머신러닝', '상권', '클러스터', '점포', '매출']",,"Although retail industy including the fashion sector encompasses a range of stores sizes from large to small, existing literature offers inconsistent views about the relationship between large-sized and small-sized retail stores. This study aimed to cluster retail districts in Seoul based on the location and sales data of large-sized and small-sized retail stores, employing the Self-Organizing Map (SOM) as a kind of machine learning approaches. The results revealed major retail clusters by sales, location, and store sizes, and the descriptive characteristics of these clusters, such as, land price, living population, and the number of subway lines. These clusters were then further divided into three categories: mutually dominant clusters, large-sized store dominant clusters, and small-sized store dominant clusters. The results show which retail districs are more advantageous for one of the store sizes or for both, thus providing an empirical, data-driven insight to develop optimal location strategies for retailers and policy-makers."
머신러닝 기반 공용연수에 따른 수선유지비 변화 예측 방법 연구,2025,"['Preliminary Feasibility Study', 'Repair and Maintenance Costs', 'Lifespan', 'Machine learning', 'Random Forest', 'XGBoost', '예비타당성조사', '수선유지비', '공용연수', '머신러닝', '랜덤포레스트', 'XGBoost']","예비타당성조사의 도로부문 수선유지비용은 공용연수에 따른 변화 추세를 반영하기 위해 기본 원단위에 변화 비율(K)를 곱해 산정되며, 예측에 사용된 회귀모형의 적합성과 분석기간을 고려해 30년까지 지침에 제공되고있다. 추후 도로부문 경제성 분석기간 연장에 대비하여 변화 비율(K) 범위의 확대가 필요하지만, 기존 회귀식으로는 30년 이후 변화 비율(K)의 예측이 어려워 새로운 방법론이 필요한 실정이다. 이에 본 연구는 랜덤포레스트 등 머신러닝 방법론을 활용하여, 공용연수와 유지관리비간의 비선형적 관계를 효과적으로 분석하고, 기존 회귀식 대비 높은 설명력을 확보할 수 있는 방안을 제시하였다. 랜덤포레스트, XGBoost 기법을 통해 40년간의 변화비율(K)를 예측한 결과, 설명력은 90%이상으로 나타나 의사결정나무 기반 앙상블 모델이 예측에 적합한 것으로 나타났다. 연구 결과를 기반으로 제시된 40년간 공용연수별 변화비율(K)은 경제성 분석기간 조정을 위한 근거 및 향후 타당성 분석을 위한 기초자료로 활용될 수 있을 것으로 기대된다.","This study utilizes machine learning techniques, such as Random Forest, to effectively analyze the nonlinear relationship between lifespan and maintenance costs to improve explanatory power compared to traditional regression models. By applying Random Forest and XGBoost methods, the change rate (K) was predicted for a period of 40 years, achieving an explanatory power of over 90%, indicating that tree-based ensemble models are suitable for this prediction task. The 40-year change rate (K) proposed in this study is expected to serve as a basis for adjusting the economic analysis period and as fundamental data for future feasibility studies."
머신러닝을 활용한 치과진료분야 및 치료비 지출 예측모형 개발,2025,"['Big data', 'Dental treatment fields', 'Machine learning', 'Oral health screening', 'Treatment expenditure']",,"Objectives: The study aimed to improve oral health screening rates by developing a predictive model for dental treatment fields and treatment expenditure using oral health screening results.Methods: Data for the study was obtained from the National Health Insurance Corporation's health screening cohort database. Participants with oral health screening data from 2016 to 2019 were included.Results: The findings suggested that the higher the oral health screening rates, the lower the cost of restoration treatments and treatments following tooth loss. Dental treatment fields and treatment expenditure can be predicted using oral health screening results.Conclusions: States should consider providing policy support to ensure that oral health screenings effectively lead to treatment, rather than one-off events. This can be achieved by identifying groups that need follow-up care in advance through oral health screening results."
머신 러닝 워크플로우 자동화를 위한 분산파일 통합관리 시스템,2025,"['artificial intelligence', 'autoML', 'platform', 'file management', '.']",머신 러닝 워크플로우 자동화를 위한 분산파일 통합관리 시스템,A Distributed File Management System for Machine Learning Workflow Automation
머신러닝 기법을 이용한 자동차 산업의 유효RTA유형 식별과 무역효과 추정1),2025,"['Structural gravity model', 'Poisson pseudo maximum likelihood', 'Heterogeneity of RTA effects', 'PPML plug-in Lasso', 'PPML plug-in bootstrapping', 'RTA-mix', '지역무역협정', 'RTA 혼합', '유사포아송최대가능도', '플러그인 라소', '부트스트랩 PPML 플러그인라소', '자유무역협정', '경제통합협정', '구조중력모형', 'RTA 효과의 이질성']","본 연구는 세계무역기구(WTO)의 제도적 근거에 따른 지역무역협정(RTA) 유형을 무역협정의 중첩현상을고려하여 16개의 중첩 RTA 유형(RTA mix)으로 재분류했으며, 그런 다음 자동차 산업에 유효한 무역협정을식별하고 선택된 RTA 혼합 유형의 무역효과를 추정하고자 했다. 본 연구는 전체과정을 2단계로 나누어진행했는데, 먼저 유사포아송최대가능도(PPML) 플러그인 라소(Plugin Lasso) 모형이나 부트스트랩 PPML플러그인 라소 모형 등과 같은 머신러닝 기법을 이용하여 자동차 산업에 유효한 RTA를 식별했고, 다음으로선택된 RTA의 무역효과를 3중 고정효과 PPML 중력모형을 이용하여 추정했다. 본 연구의 결과는 다음과같습니다. 첫째, WTO RTA 데이터베이스의 무역협정 유형 중에서는 FTA-EIA가 유효한 RTA 유형으로선정되었으며, RTA의 중첩적 특성을 고려한 무역협정 유형 중에서는 EIA, FTA 및 FTA-EIA의 세 가지무역협정이 중첩된 RTA 환경이 자동차 산업의 무역에 가장 효과적인 RTA 유형으로 선정되었다. 그리고이렇게 선정된 RTA 유형들은 자동차 산업에 대해 37-38% 정도의 무역확대효과를 가지는 것으로 나타났다.","This study reclassifies the WTO’s RTA categories to account for the overlapping natureof these agreements, yielding 16 distinct “RTA mix” types. It then estimates the tradeeffects of these 16 RTA mix types on specific industries, with a particular focus on theautomobile industry. This study employs a two-stage approach. First, it identifies theRTAs effective for the automobile industry using machine learning techniques,specifically a Poisson Pseudo-Maximum Likelihood (PPML) Plugin Lasso model and abootstrapped PPML Plugin Lasso model. Second, it estimates the trade effects of theseselected RTAs. The results of this study are as follows. First, for the trade agreementtype in the WTO RTA database, FTA-EIA was selected as an effective RTA type.Second, for the trade agreement type considering the overlapping nature of RTAs, theRTA type in which three trade agreements, EIA, FTA, and FTA-EIA, are overlapped,was selected as the most effective RTA type for trade in the automobile industry, andits effect was also found to represent the average trade effect well."
머신러닝을 통한 항공기사고 예측모형 구성 및 사고요인 평가,2025,"['Airplane Accident', 'Gradient Boosting Classifier', 'Random Forest', 'Data Imbalance']",,"With the increasing demand for aviation, interest in machine learning is growing as a way to analyze airplane accidents for aviation safety. While the existing researches mainly have interest in constructing a classification model of casualty grades in airplane accidents and evaluating its predictive performance, the purpose of this paper is to pursue a prediction model considering data imbalance and the creation of causal rules between accident factors and casualty grades in airplane accident. Accident factors can be evaluated through feature importance of casualty grades classification model in airplane accident. In particular, casualty accidents can be more effectively classified through the gradient boosting classifier model under the data imbalance existing in airplane accident data and its performance is compared with that of the random forest model. And using accurately classified data, judgement rules for predicting casualty grades of airplane accident can be constructed using a decision tree. This paper can contribute to more precise prediction or judgment with higher recall classification and providing rules in identifying casualty grades resulted from airplane accidents."
머신러닝 기반 전국 교통사고 심각도 예측모형 개발 및 사고요인 분석,2025,"['Machine Learning', 'Big Data', 'Traffic Accident', 'Severity Prediction', 'Accident Factors', '머신러닝', '빅데이터', '교통 사고', '심각도 예측', '사고 요인']","교통사고는 연간 처리비용이 GDP의 1.2%에 달할 정도로 사회적 비용이 클 뿐 아니라, 피해자에게 큰 후유증을 남기는 문제이므로 교통사고예방 및 심각도 감소를 위한 연구는 중요하다. 교통사고 발생 시 교통사고 등급을 예측하고 사고 처리를 위한 정보를 제공한다면 사고처리 비용을절감할 수 있다. 하지만 교통사고 등급 예측을 위한 기존 연구는 대부분 낮은 예측 정확도와 단일 지역을 대상으로 연구를 수행하여 전 지역 특성을반영한 전국 모델 개발에 대해 고려하지 않은 한계가 있었다. 본 연구에서는 한국 도로 교통 공단의 2022년에서 2023년까지의 데이터를 수집하여,사전 EDA 과정에서 다중공선성(VIF) 가능성이 있는 변수에 대해 전처리를 수행하였으며, 독립변수에 대해선 Min Max Scaling, One Hot Encoding과정을 거쳐 정규화를 진행하고, XGBoost, KNN, Random Forest, SVM, FCNN, DNN 모델을 적용하여 성능을 비교하였다. 실험 결과, RandomForest가 가장 우수한 성능을 보였으며, 5 Fold 교차 검증과 하이퍼 파라미터 최적화 과정을 거쳐 전국모델의 성능을 정확도 79.13%로 향상시켰다.심각도 등급에 영향을 주는 사고요인간 변수 중요도에 차이가 있음을 규명하여, 교통사고 예방과 감소에 기여할 수 있도록 맞춤형 정책을 제안하였다.","Traffic accidents pose significant societal costs and long-term impacts on victims, making research on prevention and severity reductioncrucial. Accurate prediction of accident severity classes can provide valuable information for emergency response and reduce accidenthandling costs. Previous research on traffic accident severity prediction has been limited by its focus on single geographic areas andrelatively low prediction accuracy. This study analyzed data from the Korea Expressway Corporation spanning 2022-2023, performinginitial exploratory data analysis (EDA) and addressing multicollinearity through Variance Inflation Factor (VIF) analysis. Independentvariables were normalized using Min-Max scaling and One-Hot encoding. The study compared the performance of multiple models:XGBoost, K-Nearest Neighbors (KNN), Random Forest, Support Vector Machine (SVM), Fully Connected Neural Network (FCNN), and DeepNeural Network (DNN). Random Forest emerged as the best-performing model, achieving 79.13% accuracy for the nationwide modelthrough 5-fold cross-validation and hyperparameter optimization. By identifying the relative importance of various accident factorsaffecting severity levels, this study proposes customized policies to contribute to traffic accident prevention and severity reduction."
호소의 클로로필 a 예측을 위한 원격탐사기법과 수질모형 기반의 머신러닝 적용,2025,"['Machine learning', 'Random forest', 'Remote sensing', 'EFDC model', 'Chlorophyll a', '.']",,"Machine learning techniques have been widely used in recent research on reservoir algae management because they are insensitive to outliers, have a short running time, and have a simpler structure than mechanism-based water quality models. This study developed a random forest model by linking remote sensing data and the EFDC model. Using the developed model, chl-a in Okjeong reservoir was predicted, and the feasibility of the model was evaluated through a verification process. Before developing the random forest model, the EFDC model was applied to simulate the entire reservoir, and the outputs of the HSPF model were also provided to the EFDC model so that the influence of rivers flowing into the reservoir could be considered. During calibration and validation processes the overall simulation was appropriately performed during the simulation period. The results of predicting chlorophyll a by applying the reflectance value of the Okjeong reservoir water quality measurement site to the random forest model and the prediction results of the regression model mainly used in remote sensing were compared through mean absolute error (MAE), root mean square error (RMSE) and relative root mean square error (rRMSE). Our results found that the random forest model achieved higher accuracy than the regression model in all evaluation metrics. Therefore, the random forest model was efficient in simulating algae because it was simulated based on empirical data, and it is expected that a more improved model will be developed through data advancement, such as securing satellite images taken during the summer and water quality data."
머신러닝 기반의 소프트웨어 신뢰성 성장 모델(SRGM) 최적화,2025,"['소프트웨어 신뢰성', '소프트웨어 신뢰성 성장 모델', '인공지능 최적화', '기계 학습', 'software reliability', 'software reliability growth model', 'artificial intelligence optimization', 'machine learning']",,"Software reliability is a critical factor for system performance and safety, especially in defense industries, where operational failures can have severe consequences. To evaluate and improve software reliability, Software Reliability Growth Models (SRGMs) are widely used. However, many previous studies have relied on single optimization methods or deep learning approaches, which are prone to local optima and extrapolation issues, reducing prediction accuracy. To fill this gap, current study employs a broader range of optimization algorithms based on the Least Squares Method (LSM) and Maximum Likelihood Estimation (MLE) to approximate global optima. NASA’s Jet Propulsion Laboratory (JPL) software defect datasets were used, and several widely recognized SRGM models, including Goel-Okumoto, Delayed S-Shape, Inflection S-Shape, Weibull, and Log-Logistic, were evaluated. Experimental results show that the choice of optimization method significantly affects prediction performance, as measured by Mean Squared Error (MSE). For example, in the J2 dataset, the Weibull model exhibited MSE values ranging from 70.778 to 15,767.68—a 222-fold difference—demonstrating the critical role of optimization in prediction accuracy. The findings confirm the risks of relying solely on single-method approaches and highlight the value of diverse optimization strategies for achieving near-global optima. The study presents a practical framework for improving software reliability assessments, contributing to the development of highly reliable software for the defense industry."
머신러닝기법을 활용한 공장입지 분포 특성 유형화 및 유형별 업종분포 패턴 분석,2025,"['Planned', 'Unplanned', 'XGBoost', 'LISA', '계획입지', '개별입지', 'XGBoost', '국지적 공간 자기상관 분석']",,"South Korea has alternated between planned and unplanned industrial location policies depending on the era, but previous studies have mostly focused on only one type of location. As a result, they have not sufficiently considered the spatial relationships and interactions between the two types of locations, nor the characteristics specific to each industry. This limited approach can distort forecasts of industrial land demand and lead to problems such as uncoordinated development and infrastructure overload.Therefore, this study analyzes the spatial correlation between planned and unplanned industrial areas at the national level using LISA (Local Indicators of Spatial Association) analysis. In addition, it explores the impact of industry-specific characteristics on spatial distribution using machine learning methods. After comparing multiple models, XGBoost was selected as the most suitable model for this analysis. To enhance interpretability, the SHAP (SHapley Additive exPlanations) technique, an explainable AI (XAI) approach, is applied to interpret the influence of each factor on industrial location.The results quantitatively confirm that unplanned industrial areas tend to cluster around planned industrial areas across the country, and that distribution patterns differ depending on industry characteristics. Based on these findings, the study suggests that existing industrial policies should shift toward more customized approaches that account for the interactions between different location types and the unique needs of each industry."
머신러닝 기법을 적용한 방공부대 진지선정에 관한 연구,2025,"['METT-TC', 'Machine Learning', 'Random Forest', 'Priority Site Selection', 'Air Defense Unit']",,"In modern warfare, air power—including missiles, drones, and air force operations—has become a critical determinant of victory, emphasizing the increasing importance of air defense capabilities. One of the key challenges faced by commanders is the selection of optimal defensive positions for air defense units. This decision must consider various factors, such as mission objectives, terrain, slope, road accessibility, and predicted enemy approach routes. This study presents a methodology for selecting air defense unit positions using the Random Forest technique within the METT-TC (Mission, Enemy, Terrain, Troops Available, Time Available, Civil Considerations) framework. By integrating these key elements, the Random Forest algorithm evaluates and ranks potential defensive positions, encompassing both pre-planned and alternative areas. The results of this study demonstrate that the proposed model provides effective support for commanders in prioritizing positions for air defense, artillery, logistics, and other units, thus enhancing operational effectiveness and survivability in both wartime and peacetime contexts."
종단자료의 속성을 고려한 머신러닝 기법 비교 연구: MERF와 glmmLasso를 중심으로,2025,"['종단자료', '머신러닝', 'MERF', 'glmmLasso', 'longitudinal data', 'machine learning', 'MERF', 'glmmLasso']",,"The purpose of this study is to compare the predictive performance and variable selection accuracy of two machine learning methods—MERF and glmmLasso—that can account for the structure of longitudinal data. To achieve this, a simulation study was conducted with conditions varying in the number of predictors (25, 50, 100), number of repeated measurements (3, 4, 6), and sample sizes (500, 1,000, 2,000, 4,000). The performance of MERF and glmmLasso was evaluated using root mean squared error (RMSE), variable selection accuracy rate, error rate, relative bias, and bias. The results are as follows. First, glmmLasso consistently outperformed MERF in predictive performance across all conditions investigated under the current study. Second, MERF showed increasing RMSE with more predictors and smaller sample sizes, whereas glmmLasso maintained stable RMSE. Third, for both methods, RMSE increased with the number of repeated measurements when the sample size was relatively small. Additionally, in glmmLasso, relative bias was observed under some conditions when the sample size was 500. However, with a sufficiently large sample size, RMSE differences across the different numbers of repeated measurements were minimal. Fourth, in MERF, variable selection accuracy rate improved with fewer predictors, fewer numbers of repeated measurements, and a larger sample size. Based on these findings, practical guidelines for applying MERF and glmmLasso methods while considering the structure of longitudinal data and suggestions for future research were provided."
트리기반 머신러닝을 이용한 새로운 동영상 조회수 예측 영향성 인자 분석,2025,"['유튜브 조회수 예측', '머신러닝', '트리 기반 모델', 'SHAP 분석', '인자 분석', 'YouTube View Prediction', 'Machine Learning', 'Tree-based Models', 'SHapley Additive exPlanations (SHAP) Analysis', 'Factor Analysis']",,"In recent years, YouTube has become the most popular media sharing platform worldwide. The number of views of YouTube videos is a crucial indicator of content success, and its accurate prediction can significantly help in the development of content strategies. However, the factors influencing YouTube view predictions are not well understood, making it difficult to predict the views of new content. To address this, we propose a method to predict the views of new videos using metadata and derived variables from YouTube videos across all categories. We validated the prediction performance using five tree-based machine learning models and analyzed the key features influencing view prediction through SHapley Additive exPlanations (SHAP) analysis. Through the proposed method, we confirmed that several factors, such as the number of likes, video length, and category ID, have a significant impact on the prediction of YouTube views."
SEM-EDS와 머신러닝을 이용한 연필과 기계식펜으로 기재된 필적의 판별,2025,"['handwriting #1', 'pencil #2', 'mechanical pencil #3', 'LDA #4', 'SVM #5']","법과학적 문서감정에서 연필 종류의 필적이 위조 또는 변조되었는지 확인하기 위해 연필(pencil) 또는 기계식펜(mechanical pencil) 중 어떤 필기구로 기재되었는지 결정할 경우가 있다. 연필심과 기계식펜심은 흑연 또는 활성탄을 점토(clay) 또는 수지(resin)와 혼합하여 제조된다. 특히 점토의 차이는 연필심과 기계식펜심을 판별하는 좋은 기준이 될 수 있다. 본 연구는 14종 연필과 15종 기계식펜심으로기재된 필적 표면을 SEM-EDS로 분석하였다. 점토는 탈크(talc), 파이로필라이트(pyrophyllite), 카올리나이트(kaolinite), 스멕타이트(smectite), 그리고 일라이트(illite) 등의 광물들로 구성되며, 주요 원소성분은실리콘(Si), 알루미늄(Al), 마그네슘(Mg), 산소(O) 등이다. 연필 필적에서 점토의 존재는 Mg < Al < Si 순서로 원소 함량을 증가시키는 경향을 보였으나, 기계식펜 필적에서 Mg, Al, Si 의 함량이 적고 특히Al의 함량이 매우 적거나 없었다. 또한 종이의 영향을 고려하여 종이 펄프의 탄소(C)와 충전제(filler)로사용되는 탄산칼슘의 칼슘(Ca)을 바탕성분으로 포함하였다. 선형판별분석(LDA)과 서포트벡터머신(SVM)을적용하여 Al/Mg, Al/Si, Si/Ca 및 Ca/C의 상대비율을 기반으로 필적을 분류하는 모델을 확립하였다. 본연구결과는 연필 또는 기계식펜으로 기재된 필적을 판별하는 중요한 방법을 제공하며, 연필류 필기구로작성된 법과학 문서 감정에서 필적의 가필, 위조 또는 변조 여부를 검증하는데 기여할 것이다.","In forensic document examination, it is often necessary to determine whether a handwriting mark has been forged or altered by identifying whether it was written with a pencil or a mechanical pencil. Pencil and mechanical pencil leads are composed of graphite or activated carbon mixed with clay or resin, depending on the type of pencil. Particularly, the difference in the clay can be a good criteria for distinguishing between pencil leads and mechanical pencil leads. In this study, the surface of handwriting marks written with 14 types of pencils and 15 types of mechanical pencil leads was analysed using SEM-EDS. Clay is composed of minerals such as talc, pyrophyllite, kaolinite, smectite and illite, etc., with the primary elements being silicon (Si), aluminium (Al), magnesium (Mg), and oxygen (O). In pencil handwriting mark, the presence of clay resulted in an increasing trend of Mg < Al < Si elemental content, while in mechanical pencil handwriting mark, the weight % of Mg, Al, and Si were significantly lower, with Al being particularly minimal or absent. Additionally, carbon (C) from the pulp and calcium (Ca) from calcium carbonate filler were considered as background components due to the influence of the paper. Linear discriminant analysis (LDA) and support vector machine (SVM) were applied to the ratios of Al/Mg, Al/Si, Si/Ca, and Ca/C to classify the handwriting mark.This study provides a crucial method for distinguishing between pencil and mechanical pencil in handwriting mark, contributing to the verification of handwriting addition, forgery or alteration in the forensic document written by pencil-type instrument."
청년 임금근로자의 이직의도를 예측하기 위한 모델 구축 및 잠재집단분류: 머신러닝 분석을 적용하여,2025,"['청년임금근로자', '이직의도', '머신러닝', '네트워크분석', '잠재계층분석', 'Young wage workers', 'turnover intention', 'Machine learning', 'network analysis', 'Latent class analysis']","이 연구의 목적은 청년 임금근로자의 이직의도를 예측하는 요인을 탐색하고 잠재계층 분석을 활용하여 잠재유형을 파악하는 것이다. 이를 위해 한국교육고용패널의 7차년도 자료 중 남자 1,809명, 여자 1,991명, 총 3,800명의 자료를 분석하였다. 개인요인, 직업요인, 교육요인의 범주에서 38개의 예측변수와 이직의도 간의 관계를 설정하고 랜덤포레스트, 그래디언부스트, 로지스틱, 인공신경망 모델을 구축하였다. 연구 결과, 네 가지 모델에서 F1 .92∼.94의 우수한 성능을 보였다. 남자 청년 임금근로자의 이직의도를 예측하는 주요 요인은 일에 대한 가치, 업무만족도, 자아존중감, 결정에 대한 자유, 직장만족도-임금으로 나타났고 여자 청년 임금근로자의 경우 일에 대한 가치, 직장만족도-안정성, 자아존중감, 개인의 발전가능성, 삶의 만족도로 나타났다. 잠재프로파일분석 결과, 모든 집단에서 3개의 잠재집단을 도출하였다. 이 연구를 통해 청년 임금근로자의 이직의도를 예측하는 요인을 탐색하였으며 잠재집단 분류를 통해 청년 임금근로자의 이직의도와 관련된 실증적인 자료와 토대를 마련하였다.","This study explored factors predicting turnover intention among young wage workers and identified latent types using latent profile analysis. Data from the 7th wave of the Korean Education and Employment Panel (3,800 individuals) were analyzed. Relationships between 38 predictive variables and turnover intention were examined, and models using Random Forest, Gradient Boosting, Logistic Regression, and Artificial Neural Networks were constructed, yielding F1 scores ranging from .92 to .94. Key predictors for males included work values, job satisfaction, self-esteem, decision-making freedom, and wage satisfaction. For females, key predictors were work values, job stability satisfaction, self-esteem, personal development potential, and life satisfaction. Latent profile analysis identified three latent groups. This study provides empirical data on factors influencing turnover intention among young wage workers."
OECD 33개국 행복점수 결정요인의 머신러닝 기반 임계치 탐색,2025,"['주관적 웰빙', 'machine learning', 'SHAP', '임계치 분석', 'OECD', 'This study empirically identifies key determinants of subjective well-being in 33 of 38 OECD countries and explores their nonlinear thresholds and interaction structures using machine learning and explainable AI (XAI) techniques. Departing from tradition', 'it employs a triple ensemble model —XGBoost', 'Random Forest', 'and Elastic Net—to predict happiness scores (Ladder Score) using six variables: income (log GDP per capita)', 'social support', 'healthy life expectancy', 'freedom of choice', 'generosity', 'and perceived corruption. The analysis', 'based on SHAP values', 'partial dependence plots (PDPs)', 'and variable interaction metrics', 'shows that GDP', 'social support', 'and life expectancy are the most influential factors', 'though their effects plateau beyond certain thresholds. Trust and social capital play a growing role in high-income contexts', 'and interaction effects like GDP × social support are confirmed. Surrogate trees and simulations help derive practical policy insights. The study broadens the methodological base of happiness economics and offers evidence-based guidelines for setting qu']","이 연구는 OECD 38개국 중 33개국을 대상으로 주관적 행복의 주요 결정요인을 실증적으로 규명하고, 머신러닝 및 설명 가능한 인공지능(XAI) 기법을 활용하여 이 들의 비선형적 임계값과 상호작용 구조를 분석하였다. 기존의 선형 회귀모형과 달 리, 본 연구는 XGBoost, 랜덤 포레스트, 엘라스틱넷으로 구성된 3중 앙상블 회귀모 형을 활용하여 소득(1인당 GDP 로그값), 사회적 지지, 건강 기대수명, 삶의 자유, 관 대함, 부패 인식 등 6개 변수 기반으로 행복 점수(Ladder Score)를 예측하였다.SHAP 값, 부분의존 플롯(PDP), 변수 간 상호작용 지표를 통해 분석한 결과, GDP, 사회적 지지, 기대수명이 가장 영향력 있는 변수였으나 일정 임계값 이상에서 는 그 효과가 급격히 둔화되었다. 특히 고소득 국가에서는 제도에 대한 신뢰와 사회 자본이 중요한 요인으로 부각되었고, GDP와 사회적 지지 간의 상호작용 효과도 실 증적으로 확인되었다. 아울러, 대체의사결정나무(surrogate tree)와 시나리오 시뮬 레이션을 통해 직관적인 정책 규칙을 도출하였다.이 연구는 행복경제학의 방법론적 범위를 확대하며, 경제성장의 한계효과를 극복하 기 위한 정량적 개입 기준과 전략적 우선순위 설정을 위한 실증적 근거를 제공한다.",
홍수 예방을 위한 머신러닝 기반 하천 수위 예측 모델 연구,2025,"['하천 수위 예측', '홍수 예측', '머신러닝 기반 예측 모델', 'River Water Level Prediction', 'Flood Prediction', 'Machine Learning-based Predcition Models']","본 연구는 하천 수위 예측을 위한 다양한 데이터 기반 모델링 기법을 비교⋅분석하여, 재난 대응에 활용 가능한 정밀 예측 시스템 구축을 목적으로한다. 먼저 이미지 기반 수위 단계 분류를 위해 CNN 모델을 적용한 결과, 초기 정확도는 높았으나 클래스 불균형과 지역적 편향으로 인해 과적합및 일반화 성능의 한계가 나타났다. Dropout과 데이터 증강 기법을 도입하였으나 근본적인 개선에는 한계가 있었다. 이후 시계열 예측 실험에서는선형 회귀, 다항 회귀, LSTM 모델을 기반으로 Shift 방식과 Sliding window 방식을 비교하였다. 모든 모델에서 Sliding window 방식이 더 우수한성능(R², NSE, PBIAS)을 보였으며, 특히 장기 예측 구간에서 그 차이가 뚜렷했다. 다변량 LSTM 모델은 유량 등 보조 변수를 활용하여 단변량보다높은 예측 정확도와 안정성을 보였고, 3시간 예측에서도 R² 값이 0.96 이상으로 나타났다. 결과적으로, Sliding window 방식과 다변량 모델의결합이 수위 예측 성능 향상에 효과적임을 확인하였으며, 향후에는 Transformer 등 비선형 모델과 멀티모달 데이터 통합을 통해 예측 정밀도를높일 수 있을 것으로 기대된다.","This study compares various data-driven modeling approaches for river water level prediction to support the development of accurateforecasting systems for disaster response. Initially, a CNN-based model was applied for image-based classification of water level stages. Although the model achieved high accuracy, limitations in generalization were observed due to class imbalance and location-specificbias. Techniques such as dropout and data augmentation were introduced, but they offered limited improvement. Subsequent time seriesprediction experiments employed linear regression, polynomial regression, and LSTM models, comparing Shift and Sliding Window inputmethods. Across all models, the Sliding Window method consistently outperformed the Shift method in terms of R², NSE, and PBIAS,with especially notable differences in long-term forecasts. The multivariate LSTM model, which incorporated additional variables suchas flow rate, demonstrated superior accuracy and stability compared to its univariate counterpart, achieving R² values exceeding 0.96for 3-hour forecasts. Overall, the combination of the Sliding Window approach and multivariate modeling was shown to be highly effectivefor improving prediction performance. Future work will explore advanced nonlinear models such as Transformers, as well as multimodaldata integration including rainfall and CCTV imagery to enhance the accuracy and applicability of river level forecasting systems."
지리 가중 회귀와 머신러닝을 활용한 데이터 센터 최적 입지 선정,2025,"['데이터 센터 입지 선정', '랜덤 포레스트', '지리 가중 회귀', '입지 적합성 평가', 'Data Center Location Selection', 'Random Forest', 'Geographically Weighted Regression', 'Location Suitability Assessment']","데이터 센터는 디지털 경제의 핵심 인프라로, 급증하는 데이터 처리 수요와 함께 전력 소비 및 환경적 부담이증가하고 있다. 특히, 한국에서는 데이터 센터가 수도권에 과도하게 집중되어 전력 수급 불균형과 지역 불균형을심화시키는 주요 원인으로 작용하고 있다. 이러한 문제를 해결하기 위해 본 연구는 머신러닝과 지리 가중 회귀를활용하여 데이터 센터 최적 입지를 선정하는 방법론을 제안한다. 먼저, 랜덤 포레스트를 통해 데이터 센터 입지에영향을 미치는 주요 변수들의 중요도를 도출하였으며, 자연재해 위험(침수 위험, 지진 위험)과 인프라 조건(인구밀도, 전력 공급 안정성)이 핵심 요인으로 확인되었다. 이후 지리 가중 회귀를 활용하여 지역적 특성을 반영한 회귀 계수를 산출하였으며, 이를 바탕으로 지역별 입지 적합성을 평가하였다. 분석 결과, 천안, 김해, 대구 등 일부지방 지역이 데이터 센터 입지에 적합한 것으로 나타났다. 이들 지역은 자연재해 위험이 낮고 재생 가능 에너지접근성과 인프라 조건이 우수하여 데이터 센터 운영의 안정성과 지속 가능성을 동시에 충족할 가능성을 보였다.본 연구는 데이터 센터 입지 선정 과정에서 자연재해, 인프라 조건, 사회적 요인 간의 상호작용을 통합적으로 고려한 새로운 프레임워크를 제시하며, 데이터 기반 의사결정의 정교함을 높였다. 나아가 본 연구는 데이터 센터 뿐만 아니라 기타 주요 기반 시설의 입지 선정에도 활용될 수 있는 가능성을 제시하며, 지역 균형 발전과 지속 가능한 데이터 센터 운영을 위한 실질적 정책적 시사점을 제공한다.","Data centers serve as critical infrastructure in the digital economy, supporting the growing demand for data processing while contributing significantly to energy consumption and environmental impact. In South Korea, the excessive concentration of data centers in metropolitan areas has exacerbated issues such as power supply imbalances and regional disparities. To address these challenges, this study proposes a methodological framework for optimal data center location selection by integrating machine learning and geographically weighted regression (GWR). Random Forest was employed to identify key factors influencing site suitability, revealing that natural disaster risks (e.g., flood and earthquake risks) and infrastructure conditions (e.g., population density and power supply stability) are critical determinants. GWR was subsequently utilized to estimate region-specific regression coefficients, incorporating local characteristics into the evaluation of location suitability. The analysis identified Cheonan, Gimhae, and Daegu as highly suitable locations, characterized by lower natural disaster risks, accessibility to renewable energy, and favorable infrastructure conditions, thereby ensuring operational stability and sustainability. This study advances the decision-making process by providing a comprehensive framework that considers the interaction between natural disaster risks, infrastructure conditions, and regional characteristics. Furthermore, the proposed methodology has potential applications in other critical infrastructure domains, offering practical insights for achieving regional balance and sustainable data center operations."
자동차 정비 산업에서의 고객 이탈 예측: 머신러닝 알고리즘을 기반으로,2025,"['Automotive Service Center', 'Churn Prediction', 'Machine Learning', 'XGBoost', 'Feature Improtance Analysis', '자동차 정비 서비스 센터', '이탈 예측', '머신러닝', 'XGBoost', '변수 중요도 분석']","급변하는 시장 환경 속에서 고객의 기대치가 높아지고 시장이 성숙기에 접어들면서, 대부분의 기업들은 신규 고객 확보보다 기존 고객을 유지하고 이탈을 방지하는 데 집중하고 있다. .이러한 변화는 서비스 산업에서도 두드러지며, 특히 자동차 정비 서비스 산업은 차량 수 증가와 함께 안정적인 수요를 유지하고 있지만, 차량 보증 만료 이후 고객 이탈이 빈번히 발생하는 문제가 대두되고 있다. 따라서 본 연구는 자동차 정비 서비스 산업에서 고객 이탈을 예측하기 위해 머신러닝 알고리즘을 적용하여 최적의 예측 모델을 구축하고 주요 요인을 분석했다. A기업의 36,010대 실제 차량 데이터를 활용하였으며, 이탈은 고객 방문 주기의 통계적 분석을 통해 정의했다. 연구 결과, XGBoost 모델이 94.2%의 Weighted F1-Score로 가장 우수한 성능을 보였다. 변수 중요도 분석에서는 내부처리건수가 이탈 예측에 가장 중요한 변수로 나타났으며, Confusion Matrix 분석을 통해 이탈 고객을 97%의 정확도로 예측할 수 있음을 확인하였다. 이는 사전에 이탈 가능성이 높은 고객을 식별하고 맞춤형 유지 전략을 설계할 수 있는 가능성을 시사한다. 본 연구는 고객 이탈 정의와 예측 모델 구축에 새로운 접근법을 제시하며, 자동차 정비 서비스 산업에서 효과적인 고객 관리와 유지 전략 수립에 기여할 것으로 기대된다.","In a rapidly changing market environment, where customer expectations are rising and markets are maturing, most companies are shifting their focus from acquiring new customers to retaining existing ones and preventing churn. This trend is particularly evident in the service industry, including the automotive maintenance service sector, which maintains stable demand due to the increasing number of vehicles. However, customer churn after warranty expiration has become a significant issue. Therefore, this study aims to predict customer churn in the automotive maintenance service industry by applying machine learning algorithms to develop the most optimal predictive model and analyze key factors. Using real-world data from 36,010 vehicles provided by Company A, churn was defined through statistical analysis of customer visit intervals. The results show that the XGBoost model achieved the highest performance with a Weighted F1-Score of 94.2%. Feature importance analysis revealed that Goodwill Internal were the most significant factor in predicting churn. Additionally, the Confusion Matrix analysis demonstrated that churn customers could be predicted with an accuracy of 97%, suggesting the potential to identify high-risk customers in advance and design tailored retention strategies. This study presents a novel approach to defining customer churn and developing predictive models, contributing to effective customer management and retention strategy formulation in the automotive maintenance service industry."
신규 고분자 설계를 위한 분자스케일 시뮬레이션 기법과 머신 러닝의 활용,2025,,,
XAI의 공공 인적자원관리 적용연구: 설명가능 머신러닝을 통한 개별공무원의 이직의도 예측과 설명을 중심으로,2025,"['Turnover in Public Official', 'Human Resource Management', 'Xai', 'Machine Learning', '공무원이직', '인적자원관리', 'XAI', '머신러닝']","최근 공무원의 이직률 증가와 그로 인한 정부 조직의 비효율성 문제가 대두되고 있어 여러 논문들에서 공무원의 이직의도를 형성하는 영향요인들의 역학관계를 분석하고, 이직을 어떻게관리할지 연구되었다. 한편 4차 산업혁명이 본격적으로 확산함에 따라 민간기업에서는 인공지능 기술을 인적자원관리의 도구로 도입하고 있으며, 관련 연구 역시 활발하다. 그러나 공공영역과 행정학 연구에서는 상대적으로 이러한 움직임이 더디었다. 따라서 본 연구는 설명가능한인공지능 기반의 공무원 이직의도 예측 모델을 구축하여 공무원 이직 관리의 새로운 방안을 제시하고자 한다. 이를 위해 한국행정연구원의 ‘2023년 공직생활실태조사’ 데이터를 활용하여예측모델을 구축하였다. 또한 구축된 모델을 기반으로 XAI 방법론인 SHAP 분석을 통해 이직의도에 영향을 미치는 다양한 요인들을 시각적으로 설명하였고, 개별 공무원의 이직의도를 예측하고, 개인별로 영향을 미치는 요인을 탐색하였다. 분석결과, 직무만족, 직무스트레스, 상급자의 리더십, 혁신행동 등이 이직의도를 형성하는데 중요한 영향을 미쳤다는 것을 알 수 있었으며, 개인별 예측결과를 통해 개인 맞춤형 인적자원 관리 전략의 가능성을 제시하였다. 또한새로운 기술 적용의 당위를 제시하였을 뿐 아니라 인공지능 기반의 예측 모델이 가진 한계를 제시하고 실제 관리현장에서 발생하는 프라이버시 침해와 같은 윤리적 문제 가능성에 대한 논의를 첨언하며 연구결과의 실제 적용에 있어 신중한 접근이 필요함을 강조하였다.","With the recent increase in public sector employee turnover and the resulting inefficiencies in government organizations, numerous studies have analyzed the factors influencing turnover intention and proposed strategies for managing this issue. Meanwhile, as the Fourth Industrial Revolution brings advanced technologies into various industries, artificial intelligence (AI) has been increasingly adopted as a tool for human resource management (HRM) in the business and management fields.However, the public sector and public administration have been slower to embrace these advancements. In response, this study aims to propose a novel approach to managing turnover in the public sector by developing an explainable AI (XAI)-based model for predicting public officials’ turnover intention. Utilizing data from the 2023 Korean Public Service Life Survey, the study applies the XGBoost algorithm, which demonstrated superior predictive performance compared to traditional regression models. Additionally, SHAP (SHapley Additive exPlanations), an XAI technique, was used to visually explain the key factors affecting turnover intention and explore the individual-level predictors of turnover among public officials. The results reveal that job satisfaction, job stress, leadership from supervisors, and innovative behavior significantly contribute to turnover intention, suggesting the potential for personalized HRM strategies. Furthermore, the study not only underscores the importance of adopting new technologies but also discusses the limitations of AI-based prediction models, such as potential privacy and ethical concerns, emphasizing the need for a cautious approach in real-world implementation."
학령기 아동의 학대 사건 경험에 대한 가정환경요인의  예측모델 평가: 한국아동패널과 머신러닝 기법의 활용,2025,"['학령기 아동', '학대', '가정환경 요인', '한국아동패널', '기계학습', 'school-aged children', 'abuse', 'family environment factors', 'Panel Study on Korean Children', 'machine learning']","목적  본 연구의 목적은 학령기 아동의 가정환경요인이 1년 후의 부모에 의한 신체 및 정서적 학대 사건의 발생을 정확히 예측하는지예측모델의 성능을 평가하고, 중요 예측요인을 확인하는 것이다.방법  연구자료는 한국아동패널 11차(2018년), 12차(2019년) 자료를 활용하였다. 투입변수는 11차 자료에서 10세가 된 아동1,352명(여아 664명, 남아 668명)의 인구학적 변수, 부모가 보고한 양육행동 및 정신건강 관련 변수, 아동이 보고한 가족관계 변수이다. 결과변수는 12차 자료에서 11세가 된 아동이 신체적, 정신적 학대 사건 경험의 빈도를 보고한 자료이다. 예측모델 개발을 위해 XGBoost 알고리즘을 활용하였으며, 전통적인 로지스틱 회귀모델과 예측성능을 비교하였다.결과  첫째, 아동학대 사건의 발생을 예측하는 XGBoost 모델의 예측성능은 .97~1.00의 우수한 수준이었으며, 로지스틱 회귀모델보다 유의하게 우수했다. 둘째, 아동학대 발생을 예측하는 가장 중요한 변수는 부모의 권위적 양육행동의 감소와 권위주의적 양육행동의 증가이었다. 부모의 양육행동 외에 부부갈등의 증가, 가구소득의 감소도 주요 예측변수로 포함되었다.결론  한국아동패널 자료와 머신러닝 기법을 활용해 개발된 아동학대 예측모델은 아동이 경험한 학대 사건의 발생을 사전에 정확하게 예측하는 우수한 모델로, 아동학대를 예방하기 위해 부모의 지원을 우선하는 것이 중요함을 보여준다.","Objectives  The purpose of this study was to evaluate the performance of a prediction model to determine whether a child's home environment factors accurately predict the occurrence of physical and emotional abuse incidents by parents one year later and to identify important predictive factors.Methods  The research data used the 11th and 12th data of the Panel Study on Korean Children. The input variables are demographic variables, parenting behavior and mental health-related variables reported by parents, and family relationship variables reported by children from the 12th data of 1,352 11-year-old children (664 girls and 668 boys). The output variable is the frequency of physical and mental abuse incidents reported by children who turned 11 in the 12th data. The XGBoost algorithm was used to develop the prediction model, and the prediction perform ance was compared by referring to the logistic regression model.Results  First, the predictive performance of XGBoost models predicting the occurrence of child abuse cases was excellent, ranging from .97 to 1.00, and all were significantly better than the logistic regression model. Second, the most important variables predicting the occurrence of child abuse were the decrease in parental authoritative parenting behavior and the increase in authoritarian parenting behavior. In addition, Increased marital conflict and decreased household income were included as predictors of child abuse.Conclusions  The child abuse prediction model developed using the Panel Study on Korean Children data and ma chine learning is an excellent model that accurately predicts the occurrence of abuse cases in advance, and shows the importance of prioritizing parental support."
재해예방계측기 자료를 활용한 농업용 저수지의 유입량 예측: TANK 모형과 머신러닝 비교,2025,"['농업용 저수지', '유입량 예측', '탱크 모형', 'Ridge 회귀', '재해예방계측사업', 'Agricultural reservoir', 'Inflow prediction', 'TANK model', 'Ridge regression', 'Disaster prevention measurement project']","본 연구는 재해예방계측기가 설치된 농업용 저수지를 대상으로 TANK 모형과 머신러닝 중 하나인 RidgeCV 회귀모형의 유입량 예측 성능을 비교·분석하였다. 충청북도 보은군 백록저수지와 전북 특별자치도 순창군 난계저수지에 설치된 계측장비에서 수집된 강우량, 저수위, 유입량 자료를 활용하여 두 모형을 구축하였다. 강우-유입량 관계 분석을 통해 백록저수지는 4시간, 난계저수지는 8시간 이동평균 강우량이 RidgeCV의 입력자료로 선정되었다. 2024년 1월부터 8월까지의 자료로 모형을 보정한 결과, TANK 모형은 백록저수지에서 NSE 0.893, 난계저수지에서 NSE 0.502의 성능을 보였다. 반면 RidgeCV 모형은 백록저수지에서 NSE 0.989, 난계저수지에서 NSE 0.983으로 우수한 성능을 나타냈다. 검정 기간(2024년 9월~10월) 동안 TANK 모형의 성능은 백록저수지에서 NSE 0.141, 난계저수지에서 NSE 0.547로 크게 저하되었으나, RidgeCV 모형은 백록저수지에서 NSE 0.978, 난계저수지에서 NSE 0.984의 안정적인 성능을 유지하였다. 이는 RidgeCV 모형이 유입량 데이터와 최적 이동평균 강우량 간의 관계를 효과적으로 학습하고, 정규화를 통해 과적합을 방지했기 때문으로 판단된다. 본 연구 결과는 농업용 저수지의 유입량 예측에 있어 머신러닝 기법의 활용 가능성을 보여주며, 향후 다양한 알고리즘과 입력변수를 활용한 모형 개선 연구가 필요함을 시사한다.","This study compared the inflow prediction performance of the TANK model and Ridge regression for agricultural reservoirs equipped with disaster prevention measurement systems. Two models were developed using rainfall, water level, and inflow data collected from monitoring equipment installed at Baekrok Reservoir in Boeun-gun, Chungcheongbuk-do and Nangye Reservoir in Sunchang-gun, Jeollabuk-do. Through analysis of rainfall-inflow relationships, 4-hour moving average rainfall for Baekrok Reservoir and 8-hour moving average rainfall for Nangye Reservoir were selected as optimal input data for the RidgeCV model. For the calibration period from January to August 2024, the TANK model showed NSE values of 0.893 for Baekrok Reservoir and 0.502 for Nangye Reservoir. In contrast, the RidgeCV model demonstrated superior performance with NSE values of 0.989 for Baekrok Reservoir and 0.983 for Nangye Reservoir. During the validation period (September-October 2024), the TANK model's performance significantly deteriorated to NSE values of 0.141 for Baekrok Reservoir and 0.547 for Nangye Reservoir, while the RidgeCV model maintained stable performance with NSE values of 0.978 for Baekrok Reservoir and 0.984 for Nangye Reservoir. This superior performance of the RidgeCV model can be attributed to its effective learning of the relationship between inflow data and optimal moving average rainfall, as well as the prevention of overfitting through regularization. The results of this study demonstrate the potential of machine learning techniques for inflow prediction in agricultural reservoirs and suggest the need for further research on model improvement using various algorithms and input variables."
머신러닝 기반 국화 생장 예측 모델의 비교 분석,2025,"['앙상블 모델', '생장 예측', '회귀 모델', 'Random Forest', 'XGBoost', 'CatBoost', 'Ensemble model', 'growth prediction', 'regression model', 'Random Forest', 'XGBoost', 'CatBoost']","본 연구는 환경 요인을 바탕으로 절화용 국화 생장 예측을 위한 최적의 모델을 개발하는 것을 목표로 하였다. 이를 위해 13개의 모델(Linear Regression, Lasso Regression, Ridge Regression, ElasticNet Regression, K-Nearest Neighbors (KNN), Support Vector Regression (SVR), Neural Network, Decision Tree, Random Forest, XGBoost, AdaBoost, CatBoost, Stacking)의 성능을 R , MAE, RMSE를 평가 지표로 비교하였다. 단일 모델 중에서는 Decision Tree가 가장 우수한 성능을 보였으며, R 값은 0.90에서 0.91 사이였다. 앙 상블 모델 중에서는 CatBoost가 가장 높은 성능을 보였으며 (R =0.90~0.92) Random Forest와 XGBoost 또한 유사한 성 능을 보였다. 전체적으로 트리 기반 앙상블 모델이 국화 생장 예측에 적합한 모델로 나타났다.","This study aimed to develop an optimal model for predicting chrysanthemum growth based on environmental factors. Linear Regression, Lasso Regression, Ridge Regression, ElasticNet Regression, K-Nearest Neighbors (KNN), Support Vector Regression (SVR), Neural Network, Decision Tree, Random Forest, XGBoost, AdaBoost, CatBoost, and Stacking, was compared using R², MAE, and RMSE as evaluation metrics. Among the individual models, the Decision Tree showed the best performance, with R2 values of 0.90–0.91. Among ensemble models, CatBoost achieved the highest performance, with R² values of 0.90–0.92. Random forest and XGBoost also demonstrated similarly strong results. Overall, tree-based ensemble models were found to be particularly effective for predicting chrysanthemum growth."
중학생과 고등학생의 성별에 따른 위기청소년의 비자살적 자해 예측요인 탐색: 머신러닝 및 네트워크 분석을 활용하여,2025,"['위기청소년', '비자살적 자해', '머신러닝', '네트워크분석', 'At-Risk Youth', 'Non-Suicidal Self-Injury', 'Machinelearning', 'Network']","이 연구의 목적은 위기청소년 지원기관 이용자 생활 실태 조사 자료를 활용하여 위기청소년의 비자살적 자해를 예측하는 요인을 탐색하고 네트워크 분석을 활용하여 주요 요인 간의 상호작용 및 중요도를 파악하는 것이다. 이를 위해 2021년 위기청소년 지원기관 이용자 생활 실태 조사 자료 중 중학생 집단과 고등학생 집단으로 구분하고 성별에 따라 총 네 집단, 3,980명의 자료를 분석하였다. 개인 요인, 가정 요인, 비행 요인, 교육 요인, 외상 요인의 다섯 가지 차원에서 37개의 예측 요인과 비자살적 자해 간의 관계를 설정하고 랜덤포레스트, 그래디언부스트, 인공신경망 모델을 적용하였다.연구 결과, 세 가지 모델에서 F1 .73 ~ 90으로 나타났다. 중학생 집단에서 비자살적 자해를 예측하는 주요 요인은 자해 생각, 자존감, 자기 통제력, 스마트폰 과의존, 가정 폭력 학대 경험으로 탐색되었다. 고등학생 집단에서 주요 요인은 자해 생각, 자존감, 가정 폭력 학대 경험, 스마트폰 과의존, 자기 통제력으로 탐색되었다. 이 연구를 통해 위기청소년의 비자살적 자해를 예측하는 요인을 탐색하였으며 주요 요인 간의 관련성을 통해 위기청소년의 비자살적 자해 예방을 위한 실증적인 자료와 토대를 마련하였다.","The purpose of this study is to explore the factors predicting non-suicidal self-injury (NSSI) among at-risk youth using data from a survey on the living conditions of users of support Institutions for at-risk youth. Network analysis was employed to understand the interactions and importance of key factors. The data, comprising 3,980 respondents, were divided into four groups based on educational level (middle school and high school) and gender. Relationships between 37 predictive factors across five dimensions and NSSI were examined using random forest, gradient boost, and artificial neural network models. The results showed F1 scores ranging from .73 to .90 across the three models. In the middle school group, the main factors predicting NSSI were identified as self-harm thoughts, self-esteem, self-control, smartphone overdependence, and experiences of domestic violence and abuse. In the high school group, the main factors were self-harm thoughts, self-esteem, experiences of domestic violence and abuse, smartphone overdependence, and self-control. This study provides empirical data and a foundation for the prevention of NSSI among at-risk youth by exploring predictive factors and their interrelationships."
하이브리드 접근법을 통한 머신러닝 기반 창원시 수소충전소 최적 입지 분석,2025,"['Hydrogen Refueling Station', 'Binary-Classification', 'Optimal Location Analysis', 'Changwon City', 'Hard-voting', 'k-means++', '수소충전소', '이진 분류', '최적 입지 분석', '창원시', '하드보팅', 'k-means++']","기후 변화 대응과 지속 가능한 수소 경제의 활성화를 위해 수소차 충전 인프라 확정의 중요성이 대두되고 있다. 특히 창원시는 수소차 보급 및 수소충전소 설치에 있어 선도적 역할을 하고 있으나, 충전소 인프라 부족은 여전히 주요한 과제로 남아있다. 본 논문은 창원시 내 기존 충전소를 수소충전소로 전환하는 최적의 입지를 결정하기 위한 방법론을 제안한다. 첫 단계로 최적 입지 분석을 위한 관련 데이터를 수집하고 최소-최대 정규화를 통해 데이터를 정제한다. 이어 창원시의 각 구를 대상으로 교차 검증과 이진 분류 모델을 사용해 하드보팅을 통해 후보지를 선별한다. 이후 k-means++ 클러스터링으로 충전소를 군집화하고, 충전소를 점수화하여 최종 부지를 결정한다. 제안하는 연구의 타당성을 입증하기 위해서 정확도, 정밀도, 재현율, F1-score 평가를 수행하였다. 창원시의 의창구+ 성산구, 마산합포구, 마산회원구, 진해구의 F1-score는 각 85%, 85%, 92%, 71%로 나타났다. 본 연구를 통해 수소충전소 인프라의 효율적인 확충과 균형 있는 배치가 가능할 것으로 기대된다. 또한, 해당 기법을 추가 수정하여, 수소충전소뿐만 아니라, 최적 입지 분석이 필요한 분야 혹은 행정 결정에 많은 도움을 줄 것으로 기대된다.","The importance of finalizing hydrogen vehicle charging infrastructure is emerging to respond to climate change and promote a sustainable hydrogen economy. In particular, Changwon city has a leading role in supplying hydrogen vehicles and installing hydrogen charging stations, but the lack of charging station infrastructure still remains a major challenge. In this paper, we propose a methodology to determine the optimal location for converting existing charging stations into hydrogen charging stations in Changwon city. Firstly, the existing charging stations are clustered using k-means++ clustering, and the final optimal site is determined by scoring the charging stations. In order to prove the validity of the proposed method, we perform a performance evaluation. We have measured accuracy, precision, recall, and F1-scores. The F1-scores of Uichang-gu + Seongsan-gu, Masanhappo-gu, Masanhoiwon-gu, and Jinhae-gu in Changwon city were 85%, 85%, 92%, and 71%, respectively. Through this study, it is expected that hydrogen charging station infrastructure can be efficiently expanded and balanced in its deployment. In addition, further modification of the technique is expected to help not only hydrogen charging stations but also areas or administrative decisions that require optimal location analysis."
항공․철도 공급과 국내선 항공수요의 상호 인과관계 분석:계량경제와 머신러닝 방법론을 중심으로,2025,"['항공사', '국내선 내륙 수요 분석', '철도 공급', '그랜저 인과 검정', '랜덤 포레스트', 'Airline', 'Domestic Aviation Demand', 'Railway Suppply', 'Granger Causality Test', 'Random Forest']","본 연구는 국내선 내륙 항공 수요와 철도 공급과의 상호 인과관계를 분석하고, 사회경제 발전의 맥락에서 공급 요인 중요도를 파악한다. 국내선 내륙노선 항공수요는 KTX 개통 이후 급격하게 감소하였고, 지역공항은 타격을 입게 되어, 이를 극복하기 위한 철도와 국내선 내륙노선 수요의 인과관계에 관한 연구가 필요하다. 이를 위해 항공과 철도의 공급 지표와 수요 지표를 활용한 그랜저 인과관계 분석과 사회경제지표를 동시에 고려하는 Random Forest 분석을 수행한다. 국내선 내륙노선 수요는 KTX 개통 이후 철도 관련 공급 지표의 영향을 강하게 받고 있으며, 역으로 철도 공급 지표에도 영향을 주고 있음을 확인하였다. 국내선 내륙노선 회복을 위해서는 철도의 공급 변화에 대한 고려가 필요함을 강력히 시사하고 있다. 더불어 국내선 내륙 항공 수요가 정책적 개입, 지역정서 등으로 항공기 운항횟수에 10년의 장기적인 시차를 두고 영향을 주고 있다고 분석되었다. 이는 공급 감소를 막기 위한 노력에도 불구하고 장기적으로는 내륙노선 수요 감소가 운항횟수에 영향을 준다는 의미로, 수요를 회복하기 위해서는 수요를 창출하는 방안이 더 효과적일 수 있음을 뜻한다. 외생적인 요인을 같이 고려하여도 철도 공급변수가 국내선 내륙노선 항공수요에 대한 유의미한 중요도를 가지고 있어, 국내선 내륙노선 항공수요 전망 등에 철도 공급변수 고려의 중요성을 재차 확인하였다. 본 연구는 국내선 내륙노선 항공수요 회복에 대한 학술적인 시사점을 제시함으로써 지역공항 활성화를 위한 방안 도출에 적극적으로 활용될 것으로 기대된다.","This study explores the intricate causal relationship between domestic inland route demand and railroad supply, emphasizing the pivotal role of supply-side factors in socioeconomic development. The introduction of KTX has led to a sharp decline in domestic inland air travel demand, posing substantial challenges for regional airports. Consequently, understanding the causal interplay between railroads and inland route demand is essential for devising effective strategic responses.To address this issue, we employed a dual-method analytical framework: a Granger causality analysis incorporating supply and demand indicators for both airlines and railroads, complemented by a random forest analysis integrating key socioeconomic variables. Our findings reveal a profound interdependence between railroad supply indicators and domestic inland route demand in the post-KTX era, with both sectors exerting significant influence over each other.This strong correlation underscores the need for a meticulous evaluation of railroad supply dynamics as a potential lever for revitalizing domestic inland routes. Moreover, our analysis highlights that inland route demand is not only shaped by structural supply factors but is also highly responsive to policy interventions and regional sentiments, exhibiting a notable ten-year lag in aircraft flight frequency.These results suggest that while preventing a decline in supply is imperative, sustainable long-term demand recovery may be more effectively achieved through targeted demand-stimulation strategies. Even after accounting for exogenous influences, railroad supply variables emerge as key predictors of inland airline demand, underscoring their fundamental role in comprehensive forecasting models.This research seeks to provide rigorous academic insights that can inform practical policy measures aimed at revitalizing regional airports and restoring the vitality of domestic inland air travel."
COVID-19 이후 외래관광객 수요 예측: GDELT 빅데이터와 머신러닝 기법 적용,2025,"['관광 수요 예측', 'GDELT', 'CNN-BiLSTM', '뉴스 빅데이터', 'Tourism Demand Forecasting', 'GDELT', 'CNN-BiLSTM', 'News Big Data']","본 연구는 GDELT(Global Database of Events, Language, and Tone) 빅데이터와 CNN-BiLSTM 하이브리드 모델을 결합하여 월별 해외여행객 입국자 수 예측을 위한 방법론을 제안하고 그 효과성을 실증적으로 검증하였다. 연구는 2015년부터 2024년까지의 GDELT 데이터 중 한국 관련 뉴스 기사 13,861,785 건을 분석하여 Lasso 회귀와 Boruta 기법을 통해 선별된 135개 변수를 활용하였다. CNN-BiLSTM 모델의예측 성능을 CNN-LSTM, BiLSTM, LSTM, RNN, CNN 등 다양한 딥러닝 모델과 비교 분석하였으며, MAE, RMSE, MAPE, RMSPE의 네 가지 성능지표를 통해 평가하였다. 분석 결과, CNN-BiLSTM 모델은모든 지표에서 가장 우수한 예측 정확도를 보였으며, Wilcoxon 순위 검정 결과 통계적으로 유의(p<0.05)한성능 우위가 확인되었다. 또한 RMSE 기준 65.7%~100%, MAPE 기준 61.3%~100%의 확률로 다른 모델들보다 통계적으로 유의하게 우수한 성능을 보이는 것으로 나타났다. 실증분석을 통해 CNN의 지역적 특징 추출 능력과 BiLSTM의 양방향 시간적 의존성 처리 능력이 결합된 하이브리드 아키텍처가 관광 수요 예측에특히 효과적임을 입증하였다. 본 연구는 뉴스 빅데이터를 활용한 관광 수요 예측의 가능성을 실증적으로 입증하였으며, 기존의 전통적 접근법을 넘어서는 방법론적 프레임워크를 제시함으로써 관광산업의 수요예측능력 향상에 기여할 것으로 기대된다.","This research investigates the integration of GDELT (Global Database of Events, Language, and Tone) big data with CNN-BiLSTM (Convolutional Neural Network - Long Short-Term Memory) hybrid neural network architecture for forecasting monthly international tourist arrivals. The study implements a comprehensive analytical framework utilizing 13,861,785 Korea-related news articles from 2015-2024, extracted from GDELT's Global Knowledge Graph and GCAM components. To address the high-dimensional nature of the dataset, a sequential feature selection methodology combining Lasso regression and Boruta algorithm was employed, successfully identifying 135 significant predictor variables from thousands of potential features. The proposed CNN-BiLSTM model's predictive efficacy was systematically evaluated against five comparative deep learning architectures (CNN-LSTM, BiLSTM, LSTM, RNN, CNN) using multiple performance metrics including MAE, RMSE, MAPE, and RMSPE. Empirical analysis revealed the CNN-BiLSTM model's superior predictive performance across all evaluation metrics, demonstrating statistically significant advantages through Wilcoxon signed-rank tests (p<0.05). A distinct hierarchical performance pattern emerged, with hybrid architectures consistently outperforming single-structure models, highlighting the synergistic effect of combining CNN's local feature extraction capabilities with BiLSTM's bidirectional temporal dependency processing. This investigation makes significant theoretical contributions by: (1) empirically validating news sentiment analysis for tourism demand forecasting, (2) demonstrating the efficacy of hybrid neural architectures for complex temporal pattern recognition, and (3) establishing a methodological framework for feature selection from high-dimensional datasets. The findings provide valuable practical implications for tourism industry stakeholders, enabling enhanced forecasting capabilities that can optimize resource allocation, improve strategic planning, and increase adaptability to unexpected global events affecting tourism flows."
기업 구성원의 이직의도 변화 예측변인 탐색: 머신러닝과 패널회귀분석의 적용,2025,"['이직의도', '혼합효과 랜덤포레스트', 'SHAP', '패널회귀분석', '인적자본기업패널Ⅱ', 'turnover intention', 'mixed-effects random forest', 'panel regression', 'Human Capital Corporate Panel Ⅱ']",,"This study aims to explore factors that predict changes in employee turnover intention and to identify the trends and impacts of these factors on turnover intention. To do this, mixed-effects random forest, SHAP, and panel regression were apllied to HCCPⅡ (Human Capital Corporate Panel Ⅱ) data from 3rd to 4th wave. The main results are as follows. Among demographic variables, age, tenure, and total annual income had a negative relationship with turnover intention, while the average weekly overtime hours showed a sharp increase in turnover intention beyond a certain threshold. Regarding individual characteristics, satisfaction with the current job (overall satisfaction, wages, and job content) and organizational commitment exhibited a negative relationship with turnover intention, whereas job stress showed a positive relationship. The number of days participating in formal corporate education and training varied depending on individual responses. In terms of organizational characteristics, human resources preference, communication and trust, and an innovation-oriented culture were negatively associated with turnover intention, while a hierarchy-oriented culture was positively associated. Based on these findings, implications for mitigating employee turnover intention and suggestions for future research are discussed."
티쳐블 머신을 이용한 정상 경추 측면 엑스선영상과 거북목으로 진단된 경추 측면 엑스선영상의 비교와 거북목의 예방법,2025,"['Machine Learning', 'Teachable Machine', 'normal cervical lateral x-ray image', 'Turtle neck lateral X-ray image', '머신러닝', '티쳐블 머신', '정상 경추측면 엑스선 영상', '거북목 측면 엑스선 영상']","디지털 시대의 도래로 스마트폰 사용의 증가와 함께 발생한 대표적인 건강 문제 중 하나가 바로 거북목 증후군이다. 본 연구에서는 2024년 9월2일부터 11월15일까지 경북지역의 여러 병원에서 정상으로 판독된 경추측면 엑스선 영상 200장과 거북목으로 진단된 경추 측면 엑스선 영상 200장을 수집하여 티쳐블 머신이 학습하게 하였다. 수집된 영상은 경북지역의 여러 병원에서  불특정 다수를 대상으로 하였으며, 환자 개인 정보가 포함되지 않은 영상을 사용하였다. 학습된 엑스선 영상의 해상도는 원본 사이즈를 알집영상을 이용하여 평균 ″512×615″ 사이즈로 변경하였다. 구글에서 공개되어 있는 정상 경추측면 엑스선 영상 200장과 거북목으로 진단된 경추측면 엑스선 영상 200장을 동일사이즈로 변경하여 판독하였다. 연구결과 학습률이 0.01일 때 거북목의 판정비율은 에포크가 50일 때 51%로 가장 많았으며, 학습률이 0.001일 때 거북목의 판정비율은 에포크가 80일 때 37%로 가장 많았다. 또한, 학습률이 0.0001일 때 거북목의 판정비율은 에포크가 50일 때 46%로 가장 많았다. 정상 경추 엑스선 영상을 정상 경추 엑스선 영상으로 인식하는 판독률은 모델 9개 평균 85.29%이였으며, 학습률이 0.01일 때 거북목의 판정비율은 에포크가 50일 때 91.93%로 가장 많았으며, 에포크에 따른 전체 200장의 영상 중 학습율과 같이 정상이 63%, 거북목이 37.44%로 나타났으며, 정상영상의 판독률은 에포크가 100에서 가장 많았으며, 거북목의 판독률은 에포크가 50에서 가장 많이 나타났다. 에포크에 따른 이변량 상관관계는 통계적으로 매우 유의한 것으로 나타났다.(p<0.001).  또한, 거북목의 예방법으로는 걷기, 스쿼트, 런지등 주기적인 운동이 필요할 것으로 판단된다.","Turtle neck syndrome is one of the representative health problems that have occurred with the increase in smartphone use with the advent of the digital age. In this study, from September 2 to November 15, 2024, 200 cervical side X-ray images and 200 cervical side X-ray images diagnosed with turtle neck were collected from various hospitals in the Gyeongbuk region, and the teaching machine learned. The collected images were targeted at an unspecified number of hospitals in the Gyeongbuk region, and images that did not include patient personal information were used. The resolution of the learned X-ray image was changed to an average ″ of 512×615 ″ size by using the sample image. 200 normal cervical side X-ray images released by Google and 200 cervical side X-ray images diagnosed with turtle neck were changed to the same size and read. As a result of the study, when the learning rate was 0.01, the judgment rate of turtle neck was the highest at 51% when the epoch was 50, and when the learning rate was 0.001, the judgment rate of turtle neck was the highest at 37% when the epoch was 80. In addition, when the learning rate was 0.0001, the judgment rate of turtle neck was the highest at 46% when the epoch was 50. The reading rate of recognizing normal cervical X-ray images as normal cervical X-ray images was 85.29% on average in 9 모델s, and when the learning rate was 0.01, the judgment rate of turtle neck was the highest at 91.93% when Epoch was 50, and among the 200 images according to Epoch, normal was 63% and turtle neck was 37.44% like the learning rate, and the reading rate of normal images was the highest in Epoch at 100, and the reading rate of turtle neck was the highest in Epoch at 50. The bivariate correlation according to Epoch was found to be statistically very significant (p<0.001). In addition, it is judged that periodic exercise such as walking, squat, and lunge is necessary as a preventive method for turtle neck."
전통적 탐색을 넘어서: SIMD 최적화 기반 Learned Index 오차 보정 탐색,2025,"['학습된 인덱스', '회기적 모델 인덱스', '적응적 학습된 인덱스', '탐색 알고리즘', 'SIMD', '선형 탐색', '이진 탐색', '모델 예측 기반 탐색', 'learned index', 'recursive model indexes (RMI)', 'adaptive learned index(ALEX)', 'search algorithm', 'single instruction multi data(SIMD)', 'linear search', 'binary search', 'model-biased search']","기계 학습 기반의 Learned Index는 전통적 인덱스 기법의 한계를 극복하기 위해 등장했다. 본 논문에서는 읽기 전용 RMI와 수정 가능한 ALEX의 탐색 성능을 분석하고, 오차 보정 과정에서 발생하는 오버헤드를 줄이기 위한 SIMD 기반 최적화 기법을 제안한다. Learned Index는 키의 분포를 학습해 예측과 오차 보정의 두 단계로 탐색을 수행하는데, 오차 보정이 전체 탐색 시간의 최대 80%를 차지할 수 있음이 확인되었다. RMI에서는 오차가 클 때 탐색 범위를 빠르게 줄이는 SIMD Branchless Binary Search, 작을 때 모델 예측 기반의 SIMD Linear Search가 효과적이었다. 반면, ALEX는 일정한 오차 범위를 유지하는 특성으로 인해 단순한 SIMD Linear Search가 가장 효율적이었다. 이를 통해 데이터셋의 오차 범위, 인덱스 크기 및 밀도에 따라 적절한 탐색 알고리즘을 선택하는 것이 성능 최적화에 중요함을 제시한다.","To address the limitations of traditional indexing techniques, this study examines the search performance of machine learning-based Learned Indexes, focusing on the read-only RMI and the modifiable ALEX We propose a SIMD-based optimization technique to minimize the overhead incurred during the correction phase, which accounts for over 80% of the total search time. Learned Indexes operate in two phases: prediction and correction. In our experiments with RMI, we found that when the error range is large, the SIMD Branchless Binary Search capable of quickly narrowing down the search range outperforms other methods. In contrast. when the error range is small, the model prediction-based SIMD Linear Search demonstrates superior performance. For ALEX, which maintains a relatively constant error range, the straightforward SIMD Linear Search proved to be the most efficient compared to more complex search techniques. These results underscore the importance of choosing the right search algorithm based on the dataset’s error range, index size, and density to achieve optimal performance."
SMT공정 중 스크린 프린팅에 대한 정밀검사를 위한 AI머신비전 시스템,2025,"['SMT공정', '스크린 프린팅', 'AI머신비전', '불량 검출', 'SMT process', 'screen printing', 'AI machine vision', 'defect detection']","본 논문은 딥러닝을 기반으로하여 SMT 공정 중 스크린 프린터를 통과한 PCB를 확인하여 솔더크림이 지정된 위치에 일정한 높이로 도포되지 않은 경우 불량 PCB로 간주하고 해당 PCB의 불량 위치를 경계상자로 설정하도록 하는 딥러닝 적용 불량검출 AI엔진 시스템 설계 및 개발에 관한 연구이다. 솔더크림 도포 불량 유형은 자주 발생되는 7가지로 구성하였으며 실증 업체로부터 불량 PCB를 수집하여 촬영하고 데이터셋을 준비하였다. 학습에 사용된 데이터셋은 Train, Validation, Test의 그룹으로 나누어 RT-DETR 모델을 기반으로 훈련시켰다. 연구 결과 목표로 삼은 7개 유형의 결함이 성공적으로 탐지됨을 확인할 수 있었다. 이후 추가적인 현장 실증 및 고도화를 통하여 SMT공정  중 스크린 프린팅 결과물을 대상으로 실시간 불량을 식별해 내는 AI머신비전 시스템으로써 역할을 크게 할 것으로 기대된다.","This paper is about the design and development of a defect detection AI engine system based on deep learning that checks a PCB that passed through a screen printer during the SMT process, and if the solder cream is not applied to a specified location and at a certain height, it is considered a defective PCB and sets the defective location of the PCB as a bounding box. The types of solder cream application defects consisted of seven frequently occurring types, and defective PCBs were collected from a verification company, photographed, and a dataset was prepared. The dataset used for learning was divided into groups of Train, Validation, and Test and trained based on the RT-DETR model. As a result of the study, it was confirmed that the seven types of defects targeted were successfully detected. In the future, through field verification and advancement, it is expected to play a significant role as an AI machine vision system that identifies defects in real time for screen printing results during the SMT process."
머신러닝 기반 지방대학 중도 탈락률 예측 모형 개발 및 빅데이터 분석을 통한 영향 요인 탐색: 2017-2023년 대학 정보공시자료를 활용하여,2025,"['지방대학', '중도 탈락', '예측 모형', '머신러닝', '빅데이터', 'Local universities', 'Dropout', 'Prediction model', 'Machine learning', 'Big data']","목적  본 연구는 지방대학의 중도 탈락 문제를 심층적으로 분석하고 중도 탈락률 예측 모형을 개발하여, 대학의 중도 탈락 방지를 위한 실질적 정책 방안을 제시하는 것을 목적으로 한다.방법  이를 위해 2017년부터 2022년까지의 대학 정보공시 데이터를 활용하여 전국 140개 지방대학의 중도 탈락률 예측 모형을 개발하였다. 2023년을 예측 기준 연도로 설정하여 선형회귀분석, 의사결정나무, 랜덤포레스트, 서포트벡터머신, Gradient Boosting Machine 등 다양한 머신러닝 기법을 적용하였다. 본 연구에서 활용한 머신러닝 기법들은 데이터의 정규성 가정에 크게 의존하지 않는다는 장점이 있어, 일부 변수들의 정규성 가정 위배에도 불구하고 안정적인 예측이 가능하였다. 직전 1-2년의 중도 탈락률, 재학생 충원율, 신입생 충원율, 전임교원 확보율, 장학금 수혜율 등을 주요 변인으로 활용하였으며, 각 모형의 예측 성능은 평균절대오차(MAE), 평균제곱근오차(RMSE), 결정계수(R-squared) 등의 평가 지표를 통해 비교 검증하였다.결과  서포트 벡터 머신(MAE 1.78)과 랜덤 포레스트(MAE 1.83) 모델이 가장 우수한 예측 성능을 보였다. 변수 중요도 분석을 통해 직전 1~2년의 중도 탈락률, 재학생 충원율, 장학금 수혜율 등이 중도 탈락률에 유의미한 영향을 미치는 것으로 확인되었다. 2024년 중도 탈락률 예측 결과, 국립대학은 3-5%, 사립대학은 5-12% 수준으로 나타났으며, 특히 일부 사립대학의 경우 10% 이상의 높은 중도 탈락률이 예측되어 시급한 대책 마련이 필요한 것으로 분석되었다.결론  본 연구는 빅데이터와 머신러닝 기법을 활용하여 중도 탈락 문제에 접근했다는 점에서 방법론적 의의가 있으며, 정규성 가정에 구애받지 않는 분석 방법을 통해 신뢰성 있는 예측 결과를 도출하였다. 연구 결과를 바탕으로 국가 장학금 지원 확대, 대학 기본역량 진단 지표 개선, 교육 환경 개선을 위한 재정 투자 확대, 대학의 자율적 구조개혁 유도 등 구체적인 정책적 제언을 제시하였다.","Objectives  This study aims to analyze the dropout problem in local universities in depth and develop a prediction model for dropout rates.Methods  To this end, we developed a predictive model for the dropout rates of 140 regional universities nationwide, utilizing the university information disclosure data from 2017 to 2022. Setting 2023 as the base year for prediction, we applied various machine learning techniques such as linear regression analysis, decision trees, random forests, support vector machines, and gradient boosting machines. Key variables used in the model included the dropout rates from the previous 1-2 years, student enrollment rates, freshmen enrollment rates, full-time faculty ratios, and scholarship recipient rates. The predictive performance of each model was compared and validated using evaluation metrics such as mean absolute error (MAE), root mean square error (RMSE), and coefficient of determination (R-squared).Results  The analysis results showed that random forest and gradient boosting machine models demonstrated the best predictive performance. Variable importance analysis confirmed that dropout rates from the previous 1-2 years, student enrollment rates, and scholarship rates had significant effects on dropout rates. Predictions for 2024 dropout rates were 3-5% for national universities and 5-12% for private universities.Conclusions  This study has methodological significance in approaching the dropout problem using big data and machine learning techniques. Based on the research results, policy recommendations such as expanding financial support for students and strengthening academic adaptation programs were presented."
학생들의 수업도구 활용을 위한 티쳐블 머신의 정상 폐 CT영상과 폐렴 CT영상의 판독률 비교,2025,"['Machine learning', 'Teachable machine', 'Pneumonia CT images', 'Normal chest CT images', '머신러닝', '티쳐블 머신', '폐렴 CT 영상', '흉부 정상 CT 영상']","최근 인공지능 기술, 특히 머신러닝 기반 의료영상 분석이 진단 문제를 해결할 수 있는 유망한 대안으로 주목받고 있다. 본 연구에서는 머신러닝 기반의 티쳐블 머신을 이용하여 폐렴 CT 영상과 흉부 정상 CT 영상 3000장을 티처블 머신이 학습하도록 하였으며, 정상흉부 사진 100장, 폐렴 흉부 영상 100장을 투입하여 판독하였다. 폐렴 CT 영상을 폐렴 CT 영상으로 판독하는 비율은 44.51%였으며, 정상 흉부 CT 영상을 정상 흉부 CT 영상으로 판독하는 비율은 83.55%였다. 학습 영상 수가 많을수록 판독률이 높았으나, 에포크나 학습률이 증가할수록 판독률이 증가하는 것은 아니었으며, ChatGPT가 추천한 조건 또한 미흡하였다. 베이지안 통계량 분석 결과 자료는 정규분포를 이루었으며, 대응표본 평균차이에 의한 사후 분포는 폐렴 CT 영상을 폐렴 CT 영상으로 인식하는 경우와 폐렴 CT영상을 정상흉부 CT 영상으로 인식하는 경우 분산은 7.562, 정상흉부 CT 영상을 폐렴 CT 영상으로 인식하는 경우와 정상 흉부 CT 영상을 정상 흉부 CT 영상으로 인식하는 경우의 분산은 3.937이였다. 폐렴CT 영상을 폐렴 CT영상으로 인식하는 경우와 폐렴 CT영상을 정상 흉부 CT영상으로 인식하는 경우는 매우 유의하게 나타 났다(p<0.001). 또한, 정상 흉부 CT 영상을 폐렴CT 영상으로 인식하는 경우와 정상 흉부 CT영상을 정상 흉부 CT영상으로 인식하는 경우 매우 유의하게 나타났다(p<0.001).","Recently, artificial intelligence technology, especially machine learning-based medical image analysis, has been attracting attention as a promising alternative to solving diagnostic problems. In this study, 3,000 pneumonia CT images and normal chest CT images were learned using a machine learning-based teaching machine, and 100 normal chest images and 100 pneumonia chest images were put in to read. The rate of reading a pneumonia CT image as a pneumonia CT image was 44.51%, and the rate of reading a normal chest CT image as a normal chest CT image was 83.55%. The higher the number of learning images, the higher the reading rate, but the higher the epoch or learning rate, the reading rate did not increase, and the conditions recommended by ChatGPT were also insufficient. The Bayesian statistical analysis result data were normally distributed, and the posterior distribution by the difference in the mean difference of the corresponding sample was 7.562 when a pneumonia CT image was recognized as a pneumonia CT image, and 3.937, when a normal chest CT image was recognized as a pneumonia CT image, and when a normal chest CT image was recognized as a normal chest CT image. The case of recognizing a pneumonia CT image as a pneumonia CT image and the case of recognizing a pneumonia CT image as a normal chest CT image were very significant (p<0.001). In addition, the case of recognizing a normal chest CT image as a pneumonia CT image and the case of recognizing a normal chest CT image as a normal chest CT image were very significant (p<0.001)."
머신러닝을 활용한 지식재산기반 스타트업 최고경영자 핵심역량 도출에 관한 연구,2025,"['지식재산 기반 스타트업', '머신러닝', '앙상블기법', '최고경영자', '핵심역량', '역량모델링', 'Intellectual Property-based Start Ups', 'Machine Learning', 'Ensemble Technique', 'CEO’s Core Competencies', 'Competency Modeling']","본 연구는 높아지는 IP 기반 스타트업의 중요성을 바탕으로, 성과의 중요한 요소라 할 수 있는 최고경영자의 핵심역량에 관해서 도출한 연 구이다. 현재 IP 기반 스타트업 최고경영자를 대상으로 핵심역량을 분 석한 연구는 국내를 포함하여 국외에서도 쉽게 찾아볼 수 없다. 최고 경영자의 중요성에 비해 실질적인 근간이라고 할 수 있는 역량 규명은 이루어지지 않았던 것이다. 본 연구에서는 실제 IP 기반 스타트업 최고 경영자의 의견을 바탕으로 데이터를 마이닝하고 머신러닝을 적용한 새 로운 역량모델링 방법을 제안한다. 머신러닝 기반의 역량모델링 방법 은 기존 행동사건 위주로 진행된 규명 중심의 방법을 예측과 정확도 기반의 범위로 확대하였다는데 의의가 있다. 또한 IP 기반 스타트업의 특성상 급변하는 경영 환경과 기술을 적용해야 하는바, 기존 역량모델 링의 단점을 극복하며, 긴밀한 대응을 할 수 있을 것으로 판단된다. 분 석을 진행하면서 머신러닝의 랜덤포레스트, 베이지안 네트워크, 그래디 언트 부스팅과 같은 알고리즘을 적용하였다. 특히, 역방향 제거방식을 통해 실제 고성장 지표에 밀접한 영향을 주는 핵심역량을 도출하였고, 다양한 앙상블 기법을 통해 높은 예측률과 정확성을 확보하였다. 본 연구로 도출된 21개의 핵심역량은 중요도 및 예측률의 순위 정보까지 포함하고 있다. 이 점을 활용한다면 실제 IP 기반 스타트업의 최고경영 자는 물론, 예비 창업자를 대상으로 방향 수립, 평가, 육성 등 다양한 분야로의 활용이 가능하다.","This study aims to identify the core competencies of CEOs, which are crucial for the performance of IP-based startups, reflecting their increasing importance. To date, no research has been conducted, either domestically or internationally, analyzing the core competencies of CEOs in IP-based startups. Despite the importance of CEOs, the competencies that form their foundation have not been systematically identified. In this study, we propose a innovative competency modeling method by mining data based on the opinions of actual CEOs from IP-based startups and applying machine learning. The machine learning-based competency modeling method is significant in that it expands the scope from the traditional event-based identification methods to those based on prediction and accuracy. Given the characteristics of IP-based startups, which must adapt to rapidly changing business environments and technologies, this method overcomes the limitations of traditional competency modeling, allowing for more responsive strategies. In our analysis, we applied machine learning algorithms such as Random Forest, Bayesian Network, and Gradient Boosting. Notably, we employed a backward elimination method to derive core competencies that have a close impact on actual high-growth indicators and ensured high prediction rates and accuracy through various ensemble techniques. The 21 core competencies identified through this study include information on their importance and prediction ranking. These insights can be utilized in various fields such as direction setting, evaluation, and nurturing, not only for current CEOs of IP-based startups but also for prospective entrepreneurs."
머신러닝을 이용한 드론 블레이드의 파손위치별 고장 영향성 분석,2025,"['Failure Prognostic(고장예지)', 'Machine Learning(기계학습)', 'Drone(드론)', 'Blade(블레이드)', 'Prognostics and Health Management(고장예지 및 건전성 관리)']",,"This study addresses the diagnosis of drone blade failure, which is the primary cause of drone malfunction, using big data and machine-learning techniques. Failure mode and effects analysis identified blade fractures as the most frequent cause of drone failures, thus demonstrating the feasibility of using machine learning for these diagnoses. Four machine learning algorithms support vector machine, K-nearest neighbors, Gaussian naive Bayes, and random forest are utilized, all of which achieved high performance with accuracy, precision, recall, and F1-score values exceeding 0.90. Notably, the KNN algorithm performed slightly better than the other algorithms. The findings highlight the potential of machine learning in enhancing drone reliability and safety, which is crucial in the 4th Industrial Revolution, where drones and urban air mobility systems are integral to various sectors, including transport, logistics, and military applications. This study provides a robust framework for real-time fault diagnosis and predictive maintenance, thereby contributing significantly to the advancement of drone technology."
워게임을 활용한 적지종심작전부대 생존분석 및 머신러닝 기반 변수 평가,2025,"['Survival Analysis', 'Wargame Data', 'Deep Area Operations Units', 'Kaplan-Meier Estimation', 'Cox Proportional Hazard Model', 'Random Survival Forest', 'Machine Learning']",,"This study aims to analyze the survival rates of Deep Area Operations Units (DAOUs) by leveraging detailed wargame training data and identifying key factors influencing unit survivability under simulated operational conditions. To accomplish this goal, the Kaplan-Meier estimation method and the log-rank test were applied to evaluate survival curves based on categorical variables. In addition, the Cox Proportional Hazards Model was used to assess the linear effects of categorical and continuous variables on survival time, and the Random Survival Forest (RSF) model, a machine learning-based approach, was used to determine the relative importance of variables and provide a nuanced understanding of complex interactions. Furthermore, Partial Dependence Plots (PDPs) were generated to explore nonlinear relationships between influential variables and cumulative hazard. This study is the first survival analysis of DAOUs using wargame simulation data and integrated traditional statistical techniques and machine learning methods. Future studies incorporating intangible combat power factors are encouraged to validate our findings using real-world military data, such as from KCTC, refine survival modeling, and enhance practical applicability for military decision-making."
Machination: Semiotics of IArt. Dance and Artificial Intelligence,2025,"['Semiotics', 'Artificial Inteligence', 'Dance', 'AI-Dance', 'IArt']",,"Multimodal generative Artificial Intelligence is an omnipresent technology in our post-industrial societies, as it has penetrated all areas of daily life, from social and commercial relations to the various fields of science and industry, communication, leisure and culture in general. This is to discuss whether AI is applicable to the field of artistic creation in general and to bodily arts such as dance in particular, taking into account emotional sensitivity and creativity, factors that are difficult to generate by a machine. In this article we will discuss examples of corporal artistic manifestations, in the domain of dance, in which corporality itself is called into question in the face of these interactions with humanized bodies conceived, created and “brought to life” by the magic of generative AI. The learning models developed by different Artificial Intelligence software allow these bodies to dance, model or evolve in scenographic spaces created ad hoc and shared to the point of replacing real dancers."
머신러닝 기반 월별 불법주정차 예측 모델 성능 비교 연구,2025,"['불법주정차', '머신러닝', '회귀', '앙상블', 'Illegal Parking', 'Machine Learning', 'Regression', 'Ensemble']","본 연구는 공공데이터 포털에서 제공하는 B도시와 S도시의 불법주정차 월별 통계 데이터를 활용하여 월별 불법 주정차 빈도를 예측하는 최적의 머신러닝 모델을 탐색하고 다양한 모델에 적용하여 비교 분석하는 것을 목적으로 한다. 초기 분석 단계에서는 ElasticNet 모델을 사용하였으며, 데이터의 복잡한 패턴을 보다 정확히 포착하기 위해 랜덤 포레스트, LightGBM, XGBoost와 같은 고급 앙상블 학습 기법을 추가로 적용하였다. 데이터를 모델 학습에 적합한 형태로 전처리한 후, 다양한 머신러닝 모델을 통해 불법주정차 빈도를 예측하였다. 모델의 성능은 RMSE, %RMSE, R-squared 지표로 평가하였으며, 그 결과 ElasticNet모델이 가장 높은 예측 정확도를 나타냈다. 본 연구는 지방자치단체가 불법주정차 문제뿐만 아니라 다양한 도시 문제에 대해 데이터 기반의 예측 모델을 활용하여 효율적이고 선제적인 대응 방안을 마련하는 데 기여할 것으로 기대된다.","This study aims to explore and compare optimal machine learning models for predicting monthly illegal parking frequency using monthly statistical data from Cities B and S that are provided by the Public Data Portal. In the initial analysis phase, an ElasticNet model was employed as a baseline approach, and advanced ensemble learning techniques such as RandomForest, LightGBM, and XGBoost were additionally applied to capture more complex patterns in the data. After preprocessing the data into a suitable format for model training, various machine learning models were used to predict illegal parking frequency. The models' performance was evaluated using RMSE, %RMSE, and R-squared metrics throughout the experimental phase, and the ElasticNet model demonstrated the highest prediction accuracy. This study is expected to contribute to local governments' efforts in developing efficient and proactive response strategies using data-driven prediction models, not only for illegal parking issues but also for various urban challenges."
머신러닝 기반 시선 추적 분석을 통한 문해력 예측 및 향상 연구,2025,"['문해력', '시선 추적', '머신러닝 기반', '안구 운동', '인지기능', 'ML-Based', 'Eye-Tracking', 'Literacy', 'Oculomotor', 'Eye Movement Features']","본 연구는 머신러닝 기반 시선 추적 분석을 활용하여 학습자의 문해력을 정량적으로 예측하고 향상할 수 있는 시스템을 제안하였다. 시선 추적기를 통해 학습자의 시선 데이터를 수집하고, I-DT 알고리즘을 활용하여 고정, 도약, 회귀 등 주요 시선 패턴의 특징을 추출하였다. 이러한 특징을 머신러닝 및 딥러닝 모델의 입력 변수로 활용하여 문해력 예측을 수행하였으며, 그 결과 Random Forest 모델이 평균 RMSE 3.747, 검증 RMSE 1.400으로 가장 우수한 성능을 나타내었다. 또한, 안구 운동과 인지기능 강화를 위한 훈련 콘텐츠와 실시간 피드백이 가능한 사용자 맞춤형 학습 환경 플랫폼을 구현하였다. 제안된 플랫폼은 비대면 상황에서도 문해력 평가와 향상을 효과적으로 지원할 수 있으며, 게임화된 상호작용을 통해 학습자의 자발적 참여를 유도한다. 본 연구는 시선 데이터를 기반으로 한 AI 기술이 개인화된 문해력 교육 및 정량적 평가에 활용될 수 있는 가능성을 제시한다.","This paper proposes a system that utilizes ML-based eye-tracking analysis to quantitatively predict and enhance the literacy skills of learners. For this, eye-tracking data from learners were collected, and key eye movement features, such as fixation, saccades, and regressions, were extracted using Dispersion-Threshold Identification (I-DT) algorithm. These features were then used as input variables in machine learning and deep learning models to predict literacy levels. The Random Forest model achieved the best performance, with an average RMSE of 3.747 and a validation RMSE of 1.400. A personalized learning platform with real-time feedback capabilities was implemented, incorporating training contents to enhance eye movement and cognitive functions. This platform effectively supports literacy assessment and improvement, even in remote-learning environments, and encourages the voluntary participation of learners through gamified interactions. This study demonstrates the potential of AI-driven eye-tracking technology in personalized literacy education and quantitative assessment."
머신러닝 기법을 활용한 장애인의 장애수용에 영향을 미치는 예측 변수 탐색,2025,"['장애수용정도', '장애인', '장애인삶패널조사', '머신러닝', '예측모델', 'Disability Acceptance', 'Individuals with Disabilities', 'Disability and Life Dynamic Panel', 'Machine Learning', 'Predictive Modeling']",,"Purpose This study investigated the disability acceptance among individuals with disabilities by identifying the key factors influencing the degree of acceptance and analyzing these factors using machine learning techniques.Method Using data from the 2022 5th Disability Life Panel Survey (4,520 individuals) conducted by the Korea Disability Development Institute, this study compared machine learning models (e.g., Random Forest, Bagging, XGBoost, KNN, SVM, AdaBoost, Naïve Bayes) to predict acceptance levels. The performance metrics included accuracy, precision, recall, F1 score, and RMSE. The study also explored the main variables influencing disability acceptance, focusing on the results derived through bagging techniques.Results Self-esteem and family health were the most critical factors influencing acceptance of disability, ranking first, second, and fourth among the 29 predictors. Other significant factors included depression, emotional support, relationships with family and friends, and social participation.Conclusion Based on the findings, conclusions often come at last, discussion, suggestions for further research are presented."
생성형 AI 기반의 머신러닝을 통한 굳지 않은 콘크리트의 물성 예측 성능 분석,2025,"['machine learning', 'generative AI', 'concrete', 'slump flow', 'rheology', '머신러닝', '생성형 인공지능', '콘크리트', '슬럼프 플로', '레올로지']",본 연구에서는 생성형 AI를 이용하여 머신러닝 알고리즘을 작성하여 굳지 않은 콘크리트의 슬럼프 플로 및 배합 요소를 통해 굳지 않은 콘크리트의 레올로지 정수를 예측하고자 하였다. 이에 따라 생성형 AI를 이용해 작성된 머신러닝 알고리즘 의 예측 성능을 분석하고 인간 프로그래머가 직접 작성한 머신러닝 알고리즘과 비교하였다. 연구 결과 생성형 AI를 통해 작 성된 알고리즘의 경우 충분히 레올로지 정수를 예측할 수 있을 것으로 판단되지만 인간 프로그래머가 작성한 알고리즘과 비 교하였을 때 오차 지표가 더 높아 인간이 작성한 경우보다 정확성이 좀 더 떨어지는 것으로 판단된다.,"This investigation evaluates the predictive capacity of machine learning algorithms generated through generative  artificial  intelligence(AI)  methodologies  for  determining  rheological  indices  of  fresh cementitious composites based on slump flow characteristics and mixing parameters. A comparative analysis was conducted between AI-generated algorithmic models and those manually formulated by human programmers to assess relative predictive efficacy. Empirical findings indicate that while the AI-generated algorithms demonstrate functional capability in predicting rheological indices of fresh concrete,  they  exhibit  elevated  error  metrics  relative  to  human-developed  algorithmic  models, suggesting  diminished  predictive  accuracy.  This  comparative  performance  differential  provides valuable insights into the current limitations of generative AI in developing high-precision predictive models for complex non-linear rheological behavior in cementitious systems."
한국어 뉴스 데이터의 AI 생성 여부를 판별하기 위한 임베딩 방법과 머신러닝 모형의 적용에 관한 사례연구,2025,"['생성형 AI', '머신러닝', 'Generative AI', 'Machine learning', 'TF-IDF', 'Doc2Vec', 'roBERTa']","4차 산업 혁명 시대에 접어들면서 AI와 로봇을 포함한 첨단 IT 기술이 빠르게 발전하고 있으며, 이에 따라 AI 서비스 경험률도 최근 급격히 증가하고 있다. AI 기술이 점점 우리 생활에 밀접해짐에 따라 생성형 AI가 미치는 영향도 커지고 있으며, 그중 하나가 AI가 생성한 뉴스 콘텐츠의 확산이다. AI가 작성한 뉴스는 독자들에게 편리함을 제공하지만, 동시에 가짜 뉴스 및 정보 조작 등의 문제를 야기할 수 있어 이에 대한 판별이 중요한 과제가 되었다. 본 연구는 AI 생성 뉴스 데이터를 판별하는 효과적인 방법을 찾기 위해 다양한 머신러닝 기법을 적용하여 분석을 진행하였다. 본 연구에서는 TF-IDF, Doc2Vec, roBERTa와 같은 임베딩 기법을 활용하였으며, 로지스틱회귀모형, 서포트벡터머신, 의사결정나무, XGBoost, 랜덤포레스트 등의 분류 모형을 비교하였다. 분석을 위해 AI-Hub에서 제공한 실제 한국어 뉴스 데이터를 활용하였으며, AI 생성 뉴스 데이터는 KULLM 모델을 이용하여 직접 생성하였다. 분석 결과에서 roBERTa 기반 모형이 가장 높은 정확도를 기록하며 AI 생성 뉴스 판별에 효과적인 것으로 나타났다. 본 연구를 통해 AI 생성 뉴스의 특징을 분석하고, 효과적인 판별 방법을 제시함으로써 가짜 뉴스 및 정보 도용 문제 해결에 기여할 수 있을 것으로 기대된다.","As we enter the era of the 4th industrial revolution, cutting-edge IT technologies including AI and robots are rapidly developing, and the AI ​​service experience rate has also been rapidly increasing recently. As AI technology becomes increasingly closely related to our lives, the influence of generative AI is also increasing, and one of them is the spread of AI-generated news content. News written by AI provides convenience to readers, but at the same time, it can cause problems such as fake news and information manipulation, so discerning them has become an important task. This study conducted an analysis by applying various machine learning techniques to find an effective method for discerning AI-generated news data. In this study, we utilized embedding techniques such as TF-IDF, Doc2Vec, and roBERTa, and compared classification models such as logistic regression model, support vector machine, decision tree, XGBoost, and random forest. For the analysis, we used actual Korean news data provided by AI-Hub, and AI-generated news data was directly generated using the KULLM model. The analysis results showed that the roBERTa-based model recorded the highest accuracy and was effective in identifying AI-generated news. It is expected that this study will contribute to solving the problems of fake news and information theft by analyzing the characteristics of AI-generated news and suggesting an effective identification method."
산업제어 시스템에서의 머신러닝 및 딥러닝 기반 이상탐지,2025,"['이상 탐지', '인공지능', '정보보안', '데이터 분석', 'Anomaly detection', 'Artificial Intelligence', 'Cybersecurity', 'Data analysis']","최근 4차 산업혁명 시대가 도래함에 따라 많은 양의 정보가 네트워크를 통해 오간다. 이와 동시에 보안을 위협하려는 시도가 증가하고 있으며, 네트워크의 침입 탐지에 대한 연구 또한 활발하게 진행되고 있다. 하지만 산업제어시<BR/>스템의 경우 일반적인 시스템과 구조가 다르기에 기존의 침입 탐지 알고리즘을 변형하여 적용할 필요가 있다. 본 연구에서는 산업 네트워크에서 가장 효율적으로 작동하는 침입탐지 모델을 구현하고자 하였다. 머신러닝 및 딥러닝 기반 모델을 이용하여 학습을 진행한 후 각 모델의 실행 결과를 비교하였고, 데이터의 전처리와 튜닝 과정을 통해 모델의 성능을 높였다. 침입 데이터의 불균형이 존재하여 모델의 평가 지표로는 accuracy가 아닌 F2 score를 사용하였다. 실험 결과, 불균형 데이터셋에서는 트리 기반의 랜덤 포레스트 모델이 가장 높은 성능을 보였으며, 데이터 전처리 부분에서 차원 축소 시 축소되는 차원의 수가 성능과 학습 소요 시간에 큰 영향을 미친다는 결론을 얻었다.","As the Fourth Industrial Revolution progresses, a vast amount of data is exchanged over networks. However, this has led to an increase in attempts to compromise security, prompting extensive research on network security. Industrial control systems(ICS) are structurally different from general systems, necessitating modifications to traditional intrusion detection algorithms for effective application. This study attempts to implement the intrusion detection model that works most efficiently in industrial networks. We trained several machine learning and deep learning models and compared their results. We enhanced model performance through data preprocessing and hyperparameter tuning. Due to the imbalance in the intrusion data, we used F2 score instead of accuracy as evaluation metrics. Experimental results showed that Random Forest showed the highest performance on this imbalanced dataset. Additionally, we found that the number of dimensions reduced during preprocessing significantly impacted performance and required training time."
OTT K-콘텐츠의 해외 흥행 예측: 머신러닝과 SHAP 분석을 활용하여,2025,"['K-콘텐츠', '흥행 예측', '머신러닝', 'K-content', 'machine learning', 'OTT', 'SHAP', 'success prediction']","K-드라마를 포함한 K-콘텐츠가 세계 시장에서 큰 주목을 받고 있다. 본 연구는 OTT 플랫폼에서 K-드라마 콘텐츠의 해외 흥행 여부를 예측하고 흥행 요인을 분석하는 것을 목표로 한다. 이를 위하여 본 연구에서는 먼저 캐글, Flixpatrol, 네이버, Prettyscale, 인스타그램 등 다섯 개의 출처로부터 해외에서 방영된 K-드라마에 대한 다양한 정보를 수집하였다. 그 중 순위 정보를 파악할 수 있는 279건의 드라마를 대상으로 Random Forest, XGBoost와 CatBoost 등 세 종류의 머신러닝 알고리즘을 활용하여 흥행 예측 모델을 구축하였다. 이에 더불어, 해외국가 전체를 대상으로 하는 모델 뿐 아니라 문화적 차이를 고려하여 영어권 국가들과 비영어권 국가들로 나누어 총 세 가지 유형의 모델을 개발하였다. 변수 중요도 및 SHAP 분석을 통하여 흥행 요인을 분석한 결과, 특정 장르, 배우의 외모, 드라마 공개 시기 등의 변수에서 영어권과 비영어권 시장 간 중요도 차이가 존재함을 확인할 수 있었다. 본 연구의 결과는 K-콘텐츠 제작사와 OTT 플랫폼이 시장별 맞춤형 전략을 수립하고, 글로벌 시장에서의 성공 가능성을 높이는 데 유용한 시사점을 제공한다.","K-content, including K-dramas, has been receiving significant global attention in recent years. This study aims to predict the overseas success of K-dramas on OTT platforms and to identify the key factors contributing to their popularity. To achieve this, data on K-dramas aired abroad were collected from five sources: Kaggle, FlixPatrol, Naver, Prettyscale, and Instagram. Among them, 279 dramas with available ranking information were selected to build prediction models using three machine learning algorithms: Random Forest, XGBoost, and CatBoost. In addition to constructing a model targeting the global market, we developed two more models by segmenting the data into English-speaking and non-English-speaking countries, considering cultural differences. Through feature importance and SHAP analysis, we found notable differences in key factors—such as genre preferences, actors’ appearance, and release timing—between the English-speaking and non-English-speaking markets. The findings of this study offer valuable insights for K-content producers and OTT platforms in formulating market-specific strategies and enhancing their chances of success in the global content market."
태양광 발전 설비 고장 진단을 위한 머신러닝 모델 성능 평가 연구,2025,"['Confusion matrix', 'Digital O&amp', 'M', 'Fault diagnosis', 'Machine learning', 'Photovoltaic system']",,"This study proposes a methodology for performance evaluation of fault diagnosis in photovoltaic (PV) systems using machine learning techniques, including Random Forest, k-Nearest Neighbors (kNN), and Naive Bayes. Actual data were acquired from a 3kW PV testbed and categorized into eight classes representing normal and significant fault conditions. For each class, a confusion matrix and corresponding relevant metrics are utilized to conduct class-specific performance assessments. The results indicate that the Random Forest model outperforms other models in terms of accuracy, precision, recall, and F1 score. It demonstrates outstanding performance for normal conditions (Class 0 and Class 7) and maintains stable performance for major fault types (Class 1 and Class 6). While the kNN model delivers acceptable performance for Class 0, it shows limitations for certain fault types. The Naive Bayes model exhibits the lowest performance and faces significant challenges in accurately handling most fault types."
머신러닝 기반 엔진 타이밍 체인 시스템용 압력제어밸브의 유량특성 예측 및 이상감지,2025,"['Machine learning(머신러닝)', 'Flow characteristic(유량특성)', 'Detecting anomaly(이상감지)', 'Pressure relief valves(압력제어밸브)', 'Engine timing chain systems(엔진 타이밍 체인 시스템)']",,
다수 표적 상황에서 머신 러닝을 이용한 표적 개수 식별 방안 연구,2025,"['Identification', 'Machine Learning', 'Convolution Neural Network', '-']","레이다는전파를송신하여물체의위치및이동을탐지하는장비로카메라나적외선등광학장비에비해최대탐지거리가길다는장점으로인해대공요격체계나군함및전투기등의표적탐지를위해많이사용된다. 레이다는물체까지의거리와물체의속도및이동방향을측정할수있으나, 분해능의한계로인해군집되어날아오는미사일과같은다수의표적이동시다발적으로접근하는상황에서는목표물을제대로구분하기가어렵다는문제점이발생한다. 특히, 협대역파형을사용시에는군집하여날아오는표적에대해탐지시일부표적을탐지하지못해날아오는표적에대해각각의개별표적을구분하기어려워지는문제가발생한다. 이와같은문제를해결하기위해본연구에서는좁은대역폭을갖는펄스파형에서도표적을구분하기위해머신러닝방법중CNN(convolution neural network)을 이용하여 군집 표적 속에서 표적의 개수를탐지하는방안을제시하고해당방식의성능을검증하였다.","Radar detects the position and movement of objects by transmitting radio waves. It is often used to detect targets such as air defense interceptors, warships, and fighter jets, owing to its long maximum detection distance compared with optical devices such as cameras and infrared. Radar can measure the distance to an object and the speed and direction of movement of an object. However, owing to the limitations of its resolution, it is difficult to distinguish targets in situations in which multiple targets, such as missiles flying in clusters, approach simultaneously. In particular, when narrowband waveforms are used, some targets may not be detected when clustered targets are detected, making it difficult to distinguish between individual targets. To solve this problem, this study proposes a method to detect the number of targets in a clustered target group using a convolutional neural network to distinguish targets even in pulse waveforms with a narrow bandwidth, and verifies the performance of the method."
대기환경연구소 기반 머신러닝 앙상블 모델과 칼만 필터를 통한 PM<sub>2.5</sub> 예측 성능 향상 연구,2025,"['Particulate matter 2.5', 'Ensemble', 'Kalman Filter', 'Machine Learning', 'Air pollution intensive monitoring stations']",,
디지털 트윈을 위한 머신러닝 기반 3D 객체 메쉬 재구성 기법: 입력 데이터 형식에 따른 접근 방식 비교 분석,2025,"['메쉬', '표면 재구성', '디지털 트윈', '3D 객체 재구성', '머신러닝', 'Mesh', 'Surface Reconstruction', 'Digital Twin', '3D Object Reconstruction', 'Machine Learning']",,
SHAP을 활용한 미세먼지 (PM10) 머신러닝 예측 설명,2025,"['SHAP', 'XAI', 'PM10 forecasting', 'LSTM', 'GRU', '미세먼지 예측']",,"We construct a machine learning forecast model for PM10 concentration and explain it using SHAP (shapley additive explanation) of Lundberg and Lee (2017). The SHAP, one of the explainable AI methods, is a model explainer based on shapley value from cooperative game theory. We apply the SHAP to meteorological element data (average temperature, daily precipitation, average wind speed, average relative humidity, average spot atmo- spheric pressure, average ground temperature) and air pollution data (PM10, SO2, CO, O3, NO2) for forecasting PM10 concentration. We consider GRU (gated recurrent unit) model as a forecasting model. The data analysis re- veals that the PM10 concentration is largely self-explained by lags of PM10 and next explained by NO2 followed by the daily average temperature and O3."
Investigation of sparking electro discharge machining for fabricating silicon carbide reinforced Al7050 alloy based composite through stir casting,2025,"['Al7050', 'Ceramics processing', 'RSM', 'MCDM', 'GRA-TLBO']",,"This research investigates the application of spark electro-discharge machining for fabricating a stir-cast composite reinforcedwith silicon carbide, based on the Al7050 alloy. Employing a response surface methodology with a central composite design,the study explores 20 combinations of control parameters to investigate their collective influence. Specifically, it focuses onunderstanding how three key machining parameters—current, pulse-on time, and pulse-off time—affect material removalrates, electrode wear, and surface roughness. A novel teaching-learning-based optimization strategy, integrating responsesurface methodology with grey relational analysis, is utilized to optimize multiple responses. The optimized parametersderived through response surface methodology are a current of 10 amps, a pulse-on time of 6 µsec, and a pulse-off time of5 µsec, resulting in significant improvements. These optimized settings correspond to material removal rates, electrode wearrates, and surface roughness values of 0.01074 g/min, 0.0040 g/min, and 4.9395 µm, respectively. Additionally, the teachinglearning-based optimization method employs grey relational analysis initially to rank the input factors. With the optimizedprocess variables obtained using GRA-TLBO—8.48 amps for current, 6.22 µsec for pulse-on time, and 3.34 µsec for pulse-offtime—the material removal rate, electrode wear rate, and surface roughness are further enhanced to 0.01159 g/min, 0.00408g/min, and 3.7202 µm, respectively."
자율주행 화물차의 전복 안전성 예측을 위한 머신러닝 기반 연구,2025,"['Self-driving trucks(자율주행 화물차)', 'Rollover prediction(차량전복 예측)', 'Lateral-load transfer ratio(횡 방향 하중 전달 비율)', 'Machine learning(기계학습)', 'Recurrent neural network(순환신경망)']",,
금융변수들과 주가 수익률 간의 관계에 관한 연구: 통계모형과 기계학습 모형 간의 효율성 비교,2025,"['KOSPI 200 수익률', '회귀모형', 'ARDL 모형', '기계학습', '학습 효율성', 'SVR 모형', '트리기반 모형', 'LSTM 모형', 'KOSPI 200 Returns', 'Regression Model', 'ARDL Model', 'Machine Learning', 'Learning Efficiency', 'SVR Model', 'Tree-Based Model', 'LSTM Model']","거시 금융변수들이 주가지수 수익률에 미치는 영향과 이를 위한 연구방법론을 분석하기 위해 전통적 회귀분석 모형과 기계학습 방법을 사용하여 재무 이론과의 부합성을 확보함과 함께 동일 기준으로 두 방법 간의 효율성 비교를 하였다.이를 위해 불안정 시계열 자료로부터 약안정성과 이에 따른 자기상관을 고려한 통계적 회귀모형인 다중선형모형과 ARDL 모형을 추정하였다. 또한 동일한 데이터로 대표적인 기계학습 모형들인 SVR모형, 트리기반 모형인 XGboost 모형과 Light GBM 모형 그리고 인공신경망 모형인 LSTM 모형으로 학습을 수행하여 학습 결과를 산출하였다.추정 및 학습 결과, 기계학습 모형들의 학습 결과가 전반적으로 통계적 회귀모형의 추정 결과보다 우월한 것으로 나타났다. 기계학습 중에서는 LSTM 모형, SVR 모형 그리고 트리 기반 모형 순으로 효율성이 나타났다. 트리 기반 앙상블 모형 중에서는 leaf-wise 방식인 Light GBM 모형이 level-wise 방식의 XGboost 모형보다 높은 효율성을 보였다.다만 LSTM 모형의 경우 무작위성 통제 측면에서 한계가 있긴 했으나, 통계적 회귀모형보다 기계학습 모형들이 전반적으로 더 효율적 결과를 산출한다는 결론을 내리는 데는 문제가 없다고 판단된다. 이와 같은 결과는 양 방법론을 병행하면 통계적 회귀모형으로 얻을 수 있는 재무적 시사점과 기계학습에서 얻는 측정 및 예측 효율성을 동시에 확보할 수 있다는 점을 시사한다.","To analyze the impact of macro-financial variables on stock returns, we employed both traditional regression models and machine learning methods. For this purpose, we estimated statistical regression models with time series data that account for weak stationarity and autocorrelation, specifically the multiple linear regression model and the ARDL model. In addition, using the same dataset, we trained representative machine learning models, including the SVR model, tree-based models such as XGBoost and Light GBM, and the deep learning-based LSTM model, to generate learning outcomes.The estimation and training results indicated that machine learning models generally outperformed statistical regression models. Among the machine learning models, the LSTM model demonstrated the highest efficiency, followed by the SVR model and the tree-based models such as Light GBM model and XGBoost model.These results imply that combining both methodologies can allow researchers to leverage the financial insights obtained from statistical regression models while simultaneously benefiting from the measurement and predictive efficiency of machine learning models."
기계학습 기반 단일 채널 EEG 수면 단계 분류 모델,2025,"['Single-Channel EEG', 'Sleep stage classification', 'Light sleep', 'Deep sleep', 'Machine learning-based model']","본 연구는 뇌파(Electroencephalogram, EEG) 단일 채널 기반의 기계학습(machine learning) 모델을 활용하여 수면 단계를 자동으로 분류하고, 수면의 질을 직관적으로 평가할 수 있는 수면 분석 방법을 제안한다. 수면 단계 분석은 기존에 전문가의 수작업 해석에 의존하여 시간이 많이 소요되고 해석의 일관성이 부족하다는 한계가 있었다. 이러한 문제를 해결하기 위해 본 연구에서는 비급속 안구 운동 수면(Non-rapid eye movement, NREM)을 Light Sleep(LS)과 Deep Sleep(DS) 으로 단순화함으로써, 기존 American Academy of Sleep Medicine(AASM) 기준보다 예측 성능과 클래스 간 균형이 향상된 분류 체계를 구축하였다. 시간 및 주파수 영역 기반의 다양한 생체신호 특징을 활용하고, 데이터 불균형 문제를 보완하기 위한 borderline-SMOTE(Synthetic Minority Over-sampling Technique) 등의 학습 기법을 통합함으로써 전체적인 분류 정확도와 모델 안정성을 개선하였다. 특히 Gradient Boosting Machine(GBM)을 활용한 기계학습 기반 접근은 EEG의복잡한 패턴을 정밀하게 해석하고, DS 및 급속 안구 운동(Rapid eye movement, REM) 수면과 같은 소수 클래스에서 F1- score를 2배 이상 향상시키는 결과를 보였다. 전체적인 분류 성능 향상뿐만 아니라, 본 모델은 계산량이 적고 경량화된구조를 갖추고 있어 실시간 수면 모니터링 시스템 및 웨어러블 기반 진단 기기에의 직접 적용이 가능하다. 반복 측정이요구되는 임상 환경에서도 전문가의 시간·인력 부담을 줄이고, 환자의 수면 상태를 정량적이고 효율적으로 분석할 수 있어 실제 의료현장에서의 활용 가능성이 높다.","This study proposes a sleep analysis method that automatically classifies sleep stages and intuitively evaluates sleep quality using a single-channel Electroencephalogram (EEG)-based machine learning model. Traditional sleep stage analysis relies on manual interpretation by experts, which is time-consuming and often lacks consistency. To address these limitations, the proposed approach simplifies Non-Rapid Eye Movement (NREM) sleep into Light Sleep (LS) and Deep Sleep (DS), thereby constructing a classification system that improves both prediction performance and class balance compared to the conventional standard of the American Academy of Sleep Medicine (AASM). By incorporating diverse biosignal features from time and frequency domains and applying learning techniques such as borderline-SMOTE to mitigate class imbalance, the model enhances overall classification accuracy and stability. In particular, the machine learning approach using Gradient Boosting Machine (GBM) enables precise interpretation of complex EEG patterns, achieving more than a twofold improvement in F1-score for minority classes such as DS and Rapid Eye Movement (REM) sleep. In addition to its performance improvements, the model features a lightweight computational structure that allows direct integration into real-time sleep monitoring systems and wearable diagnostic devices. Especially in clinical environments where repeated measurement is required, the proposed model effectively reduces the time and labor burden on professionals while enabling efficient, quantitative analysis of a patient’s sleep status. These characteristics demonstrate the model’s high potential for practical application in real-world medical settings."
딥러닝 기반 CNN 기계학습모델을 활용한 KP4 소재 5축 고속 가공 특성 예측 및 공구 틸트각 최적화 연구,2025,"['5축 고속가공기술', '공정 표준화', '공구 틸트각', '품질 안정성', 'CNN 기계학습모델', '5-axis high-speed machining technology', 'process standardization', 'tool tilt angle', 'quality stability', 'CNN machine learning model']","정밀 금형과 같이 높은 가공 정밀도가 요구되는 제품 제작에서는 절삭면의 우수한 가공 특성 확보를 위해 5축고속가공 기술이 필수적으로 적용된다. 특히, 5축 고속가공 기술에 의한 절삭면의 가공 품질을 결정하는 핵심 변수인 공구 틸트각(tool tilt angle)의 최적화가 중요하다. 그러나 공구 틸트각이 가공 특성에 미치는 영향을 정량적으로 분석하고 이를 표준화된 공정 기준으로 수립하는 데는 많은 한계가 존재해 왔다. 이에 본 연구에서는 5 축 고속가공기(5-Axis High-Speed Machining centres)를 이용하여 공구 틸트각을 기준으로 KP4 소재 시험편에 대한 절삭 가공을 실시하고, 표준화된 조건에서 표면 거칠기(Ra, Rz) 특성을 파악하였다. 이를 토대로 공구 틸트각과 가공 품질 간의 상관관계를 체계적으로 분석하여 5축 고속가공 기술의 표준화된 공정 설정 기준을도출하는 것이 본 연구의 목적이다. 그리고 공구 틸트각 기준의 가공 특성과 연계된 절삭면 이미지 데이터셋을구축하고, 해당 데이터를 기반으로 딥러닝 기반 CNN 기계학습모델을 개발하였다. 본 모델은 절삭면 품질 예측에 있어 높은 신뢰도를 확보함으로써, 공정 조건 설정의 표준화 및 자동화를 실현할 수 있는 기반을 마련하였다.본 연구는 5축 고속가공 기술의 공정 표준화를 통해 산업 현장에서의 품질 편차를 줄이고 일관된 품질 확보를가능하게 하는 실질적 가이드라인을 제시하였다. 특히, 제안된 표준화된 공정 조건은 향후 정밀 금형, 항공 부품및 고정밀 가공 산업에서 표준 인증 기준 수립과 품질 관리 시스템 정립에 기여할 것으로 기대된다.","In the production of products demanding high machining precision, such as precision molds, the application of 5-axis high-speed machining technology is essential to ensure superior cutting surface characteristics. In particular, optimizing the tool tilt angle—a critical variable determining the quality of the machined surface during 5-axis high-speed machining—is of utmost importance. However, quantitatively analyzing the effects of tool tilt angles on machining characteristics and establishing these as standardized process criteria have faced significant limitations.Therefore, this study conducted cutting experiments on KP4 material specimens using a 5-Axis High-Speed Machining center, systematically varying the tool tilt angle under standardized conditions, and assessed surface roughness parameters (Ra, Rz). Based on these experiments, a systematic analysis of the correlation between tool tilt angles and machining quality was performed to derive standardized process setting criteria for 5-axis high-speed machining technology. Additionally, an image dataset of cutting surfaces linked to machining characteristics based on tool tilt angles was established. Using this dataset, a deep-learning-based Convolutional Neural Network (CNN) machine learning model was developed. This model demonstrated high reliability in predicting machined surface quality, laying the foundation for standardizing and automating process parameter settings.This research provides practical guidelines for the standardization of 5-axis high-speed machining processes, thereby reducing quality deviations and ensuring consistent quality in industrial settings. In particular, the proposed standardized process conditions are expected to significantly contribute to establishing standard certification criteria and quality management systems in precision mold making, aerospace components, and high-precision machining industries."
기계번역을 활용한 그리스어 명령법 교수-학습법 제안,2025,"['ελληνική γλώσσα/προστακτική/μηχανική μετάφραση', 'modern Greek/imperative/machine translation', '현대그리스어/명령법/기계번역', 'ελληνική γλώσσα/προστακτική/μηχανική μετάφραση', 'modern Greek/imperative/machine translation']",,"This study explores a pedagogical approach to learning modern Greek imperative forms using machine translation and evaluates its relevance in language education. While imperatives frequently appear in textbooks and exams, they present challenges for beginners, highlighting the need for effective instruction. Machine translation can serve as a practical learning aid in this context. The study has two key aims: evaluating the quality of Greek-to-Korean imperative sentence translations from Google Translate and DeepL, and identifying effective learning activities for helping students recognize and acquire imperative forms, specifically in instructional texts. The analysis shows that although machine translation captures core meanings, it struggles with contextually accurate expressions and complex syntax. The study suggests using machine translation to familiarize beginners with imperative forms and support intuitive learning. For more advanced learners, comparing machine and human translations can promote deeper grammatical understanding. Ultimately, machine translation can function not only as a translation tool but also as a means for linguistic analysis and grammar awareness in second language learning."
기계학습 기반 철근콘크리트 모멘트골조 신속 내진성능 예측 모델 개발,2025,"['Machine-Learning', 'Reinforced Concrete Moment Frames', 'Seismic Performance Assessment', 'Green Retrofit', 'Vertical Extension']",,"Existing reinforced concrete buildings with seismically deficient columns experience reduced structural capacity and lateral resistance due to increased axial loads from green remodeling or vertical extensions aimed at reducing CO2 emissions. Traditional performance assessment methods face limitations due to their complexity. This study aims to develop a machine learning-based model for rapidly assessing seismic performance in reinforced concrete buildings using simplified structural details and seismic data. For this purpose, simple structural details, gravity loads, failure modes, and construction years were utilized as input variables for a specific reinforced concrete moment frame building. These inputs were applied to a computational model, and through nonlinear time history analysis under seismic load data with a 2% probability of exceedance in 50 years, the seismic performance evaluation results based on dynamic responses were used as output data. Using the input-output dataset constructed through this process, performance measurements for classifiers developed using various machine learning methodologies were compared, and the best-fit model (Ensemble) was proposed to predict seismic performance."
기계학습 기반 도박중독 위험도 예측 모델,2025,"['기계학습', '지도학습', '도박중독', '로지스틱 회귀', '상담심리', 'Machine Learning', 'Supervised Learning', 'Gambling Addiction', 'Logistic Regression', 'Counseling Psychology']","본 논문은 도박 문제 감소를 위해 중독 수준에 따라 도박중독자를 변별하는 기계학습 기반의 예측 모델을 제안한다. 최근 인터넷과 스마트폰의보급으로 인해 도박 접근성이 높아지면서 도박 문제를 겪는 중독자가 점차 증가하고 있다. 도박중독은 개인의 문제가 아닌 사회 전반에 영향을미치는 중대한 문제로, 이를 조기에 발견하고 개입하는 것이 중요하다. 도박 문제를 예방하고 치료 개입을 강화하기 위해서는 도박중독자를 신속하고정확하게 식별할 수 있는 모델이 필요하다. 본 연구에서는 한국판 도박 문제 선별척도(K-Canadian Problem Gambling Index, K-CPGI) 데이터를기반으로 학습된 기계학습 모델을 활용하여, 개인의 도박 행동 수준에 따라 중독 위험도를 예측하는 방법을 제안한다. 본 연구에서는 다양한 기계학습모델을 비교 분석한 결과, 로지스틱 회귀가 상대적으로 높은 성능을 보였으며, 해석 가능성과 신뢰성을 고려하여 최종 모델로 선정하였다. 그러나본 연구에서 사용된 데이터가 제한적이므로, 추가적인 데이터 확보와 일반화 성능 검증이 필요함을 논의한다. 이를 통해 본 연구는 도박중독자를보다 신속하고 정확하게 예측하여, 치료 연계를 강화하고 도박중독 예방 및 개입 전략 수립에 기여할 수 있을 것으로 기대된다.","This paper proposes a machine learning-based prediction model to distinguish gambling addicts according to their level of addictionto mitigate gambling-related problems. With the widespread use of the Internet and smartphones, gambling accessibility has increased,leading to a growing number of individuals experiencing gambling addiction. Gambling addiction is not just a personal issue but a significantsocietal problem that requires early detection and intervention. To prevent gambling problems and strengthen treatment interventions,a model capable of quickly and accurately identifying gambling addicts is necessary. In this study, we propose a method to predict addictionrisk levels based on an individual’s gambling behavior using a machine learning model trained on data from the Korean version of theCanadian Problem Gambling Index (K-CPGI). We compared and analyzed various machine learning models and found that logisticregression demonstrated relatively high performance. Considering its interpretability and reliability, it was selected as the final model. However, due to the limitations of the dataset used in this study, we discuss the need for additional data collection and validation ofgeneralization performance. Through this research, we expect to enhance the early and accurate identification of gambling addicts, therebystrengthening treatment linkage and contributing to the development of gambling addiction prevention and intervention strategies."
기계학습 기반 철근콘크리트 모멘트골조 축력허용범위 산정 방법,2025,"['Machine-Learning', 'Reinforced concrete moment frames', 'Seismic performance assessment', 'Green retrofit', 'Vertical extension', 'Allowable axial loading']",,"Seismically deficient reinforced concrete(RC) structures experience reduced structural capacity and lateral resistance due to the increased axial loads resulting from green retrofitting and vertical extensions. To ensure structural safety, traditional performance assessment methods are commonly employed. However, the complexity of these evaluations can act as a barrier to the application of green retrofitting and vertical extensions. This study proposes a methodology for rapidly calculating the allowable axial force range of RC buildings by leveraging simplified structural details and seismic wave information. The methodology includes three machine-learning-based models: (1) predicting column failure modes, (2) assessing seismic performance under current conditions, and (3) evaluating seismic performance under amplified mass conditions. A machine learning model was specifically developed to predict the seismic performance of an RC moment frame building using structural details, gravity loads, failure modes, and seismic wave data as input variables, with dynamic response-based seismic performance evaluations as output data. Classifiers developed using various machine learning methodologies were compared, and two optimal ensemble models were selected to effectively predict seismic performance for both current and increased mass scenarios."
기계학습모델을 이용한 하이브리드 인발 복합재의 단면 물성 예측,2025,"['기계학습', 'Machine learning', '단면 물성', 'Cross-sectional property', '인발', 'Pultrusion', '유한요소해석', 'Finite element analysis', '하이브리드 복합재료', 'Hybrid composite']",,"This study developed a machine learning model to predict the cross-sectional properties of pultruded hybrid composite structures. The model aims to optimize the mechanical performance of these structures, which depends on factors such as material properties, layer thickness, fiber volume fraction, and cross-sectional shape. The machine learning model takes 5 cross-sectional variables and 8 material property variables as inputs to predict 4 crosssectional property variables. To generate the training data for the model, a finite element-based 2D cross-sectional analysis model was employed. The accuracy of the 2D model was validated against a 3D finite element analysis, showing a maximum error of 0.56%. With 50,000 training samples, the trained feed-forward neural networks achieved an average error of 1.6%. This model is expected to be valuable during the design phase of beam-shaped components using various materials, even without any analysis software."
기계학습을 활용한 파렛트 수요 예측 모델 연구,2025,"['Pallets', 'Demand Forecasting', 'Machine Learning', '파렛트', '수요 예측', '기계학습']","파렛트는 유통물류 산업에서 필수적인 자원으로 효율적인 파렛트 수요 관리는 비용 절감과 운영 최적화에 있어 중요한 역할을 한다. 특히 물류 네트워크의 복잡성이 증가함에 따라 파렛트의 수요를 정확히 예측하는 것은 더욱 중요해지고 있다. 그러나 현재까지 파렛트 수요 예측과 관련된 체계적이고 데이터 기반의 연구는 매우 부족한 실정이다. 이에 본 연구는 이러한 한계를 극복하고자 기계학습 기법을 활용한 파렛트 수요 예측 모델을 제안한다. 본 논문에서는 파렛트 관련 다양한 데이터 칼럼을 바탕으로 수량 패턴을 분석하고, 예측 정확도를 높이기 위해 다양한 기계학습 알고리즘을 적용하였다. 또한, 데이터 특성을 반영한 최적화 과정을 통해 모델의 성능을 향상시켰다. 예측 실험 결과, 파렛트의 특수성을 고려한 제안된 모델은 높은 예측 정확도를 보였으며, 이는 파렛트 유통 관리의 효율성을 크게 향상시키고 물류 운영의 비용 최적화에 실질적으로 기여할 수 있음을 확인하였다.","Pallets are essential resources in the logistics and distribution industry, and efficient pallet demand management plays a crucial role in cost reduction and operational optimization. As the complexity of logistics networks increases, accurately forecasting pallet demand has become even more critical. However, systematic and data-driven studies on pallet demand forecasting remain significantly limited. To address this gap, this study proposes a pallet demand forecasting model utilizing machine learning techniques. This paper analyzes quantity patterns based on various data columns related to pallets and applies multiple machine learning algorithms to enhance prediction accuracy. Furthermore, the model's performance is improved through optimization processes that reflect the characteristics of the data. Experimental results demonstrate that the proposed model, considering the unique attributes of pallets, achieves high predictive accuracy, significantly improving the efficiency of pallet distribution management and contributing to the cost optimization of logistics operations."
기계학습 모델 기반 전국 대학생 자퇴의향 예측 탐색 연구:  2019-2023 KEDI NASEL 데이터 활용,2025,"['대학생', '예측 모델', '기계학습', '자퇴의향', '중도탈락', 'university students', 'predictive models', 'machine learning', 'intention to withdraw', 'dropout']","목적  본 연구의 목적은 한국교육개발원의 2019년부터 2023년까지의 NASEL 통합 데이터를 활용하여 전국 대학생의 자퇴의향을예측하는 기계학습 기반 모델을 개발하고, 중요한 예측 변인을 탐색하는 것이다.방법  연구모델은 독립변인 55개와 종속변인의 3개 클래스(‘자퇴의향 없음’, ‘비학문적 자퇴의향’, ‘학문적 자퇴의향’)로 구성하였다. 클래스 불균형 문제해결을 위해 언더샘플링(Undersampling)과 오버샘플링(Oversampling)을 적용하였으며, 총 16,620개의 표본을 분석대상으로 삼았다. 다양한 기계학습 알고리즘(랜덤 포레스트, 의사결정 나무, 로지스틱 회귀, XGB, LGBM, 앙상블모델 등)을 활용하여, 각 모델의 예측 성능을 비교 분석하였다.결과  모델 성능 비교 결과, 랜덤 포레스트, 앙상블, LGBM 순으로 높은 예측 정확도를 보였다. 반면, 의사결정 나무와 로지스틱 회귀모델은 상대적으로 낮은 성능을 나타냈다. 특히, 모델 성능이 우수한 상위 3개 모델에서 대학 만족도, 졸업 후 진로계획, 등록 학기수, 동료 및 교수와의 상호작용, 능동학습, 협력학습, 사고력 증진활동 등이 자퇴의향 예측에 있어 중요한 변인으로 확인되었다.결론  학문적⋅비학문적 자퇴의향을 구분한 모델이 자퇴 예방을 위한 맞춤형 개입에 기여할 수 있음을 확인하였다.","Objectives  The purpose of this study is to develop a machine learning-based model that predicts the intention to withdraw of university students nationwide using NASEL integrated data from 2019 to 2023 from the Korea Education Development Institute and to explore important predictors.Methods  The research model consisted of 55 independent variables and three classes of dependent variables (‘no intention to withdraw’, ‘non-academic intention to withdraw’, and ‘academic intention to withdraw’. In addition, undersampling and oversampling were applied to solve the class imbalance problem, and a total of 16,620 sam ples were analyzed. The predictive performance of each model was compared and analyzed using various machine learning algorithms (random forest, decision tree, logistic regression, XGB, LGBM, ensemble model, etc.).Results  When comparing the model performance, Random Forest, Ensemble, and LGBM had the highest pre diction accuracy. In contrast, decision trees and logistic regression models performed relatively poorly. In partic ular, college satisfaction, career plans after graduation, number of semesters enrolled, interaction with peers and professors, active learning, collaborative learning, and thinking activities were identified as important predictors of withdrawal intentions in the top three models.Conclusions  We found that a model that distinguishes between academic and non-academic withdraw intentions can contribute to tailored interventions to prevent withdraw."
앙상블 기계학습 기반 LncRNA–질병 연관성 예측 모델 연구,2025,"['bioinformatics', 'ensemble learning', 'support vector machine', 'gradient boosting', '.']","LncRNA는 비암호화 RNA(non-coding RNA) 유전자의 한 종류로서, 다양한 질병에서 중요한 역할을 하는 것으로 알려져 있다. LncRNA는 최근까지 다양한 연구와 모델들이 제안되어왔다. 기존 연구에서는 개별 모델을 적용하여 LDA(LncRNA Disease Association)를 분석하였으나, 단일 모델의 한계로 인해 높은 예측 성능을 보장하기 어려웠다. 본 연구는 SVM(Support Vector Machine), GBM(Gradient Boosting Machine), XGBoost (eXtreme Gradient Boosting)을 결합한 앙상블 학습 기법(Ensemble Learning)을 적용하여 LncRNA–질병 연관성 예측 모델의 성능을 향상시키는 방안을 제안한다. SVD(Singular Value Decomposition) 및 거리 기반 음성 샘플링(distance-based negative sampling) 전략을 활용하여 AUC 0.93의 예측 성능을 달성하였으며, 다양한 앙상블 모델 조합에 대한 비교 실험을 수행하였다. 실험 결과, 제안한 모델이 기존 방법들에 비해 우수한 예측 성능을 보임을 확인하였다.","Long non-coding RNAs (LncRNAs) are a class of non-coding RNA genes that have been reported to play critical roles in various human diseases. Numerous studies and predictive models have been proposed to investigate LncRNA–disease associations. However, previous approaches that relied on individual models have shown limited predictive performance due to the inherent constraints of single-model architectures. To address this issue, this study proposes an ensemble learning-based method that integrates Support Vector Machine (SVM), Gradient Boosting Machine (GBM), and eXtreme Gradient Boosting (XGBoost) to enhance the accuracy of LncRNA–disease association prediction. By applying Singular Value Decomposition (SVD) and a distance-based negative sampling strategy, the proposed predictive model achieved an AUC of 0.93, demonstrating a significant improvement in performance. Furthermore, comparative experiments were conducted using various combinations of individual ensemble models. The results indicate that the model proposed in this study outperformed the other methods, confirming its superior predictive capability."
기계학습을 활용한 아파트 월세지수 산정에 관한 연구,2025,"['Rent index', 'Machine learning', 'Artificial neural network', 'Gradient boosting model', 'Housing rental market', '월세지수', '기계학습', '인공신경망 모형', '그래디언트 부스팅 모형', '월세시장']","본 연구는 국내 월세 시장의 구조적 특수성을 체계적으로 반영하기 위해, 실거래가 기반의 월세지수 작성 방안을 모색하고 반복매매모형 및 기계학습 모형[GBM(gradient boosting model), ANN(artificial neural network), ensemble]을 적용하여 산정된 지수를 비교 · 분석하였다. 실거래가 중위값 추이를 분석한 결과, 2011년 1월 대비 2024년 12월 월세가격은 약 1.52배 상승하였으며, 실거래가 기반의 반복매매지수와 기계학습기반 월세지수 모두 유사한 누적 상승률을 보였다. 반복매매지수는 산정 방식의 특성상 거래가 없는 기간 및 세부 지역 단위에서 표본수 감소로 인한 지수의 불안정성이 우려되는 반면, 기계학습 기반 지수는 비선형 관계와 다양한 입력 변수를 반영함으로써 시장의 급변에도 민감하게 대응할 수 있으며, 거래 공백기에도 안정적인 추세 파악이 가능한 것으로 나타났다. 특히, GBM 기반 지수는 단기적 변동성을 민감하게 반영하는 데 강점을 보였고, ANN 기반 지수는 연속적인 가중치 업데이트를 통해 평활화 효과가 우수하여 장기 추세를 파악하는 데 유리한 것으로 확인되었다. 두 모형을 결합한 앙상블 지수는 각 모형의 상반된 편향을 상쇄함으로써 보다 시의성 있고 안정적인 성능을 보였다.","This study explored a method for constructing a rent index that systematically reflects structural characteristics of South Korea’s monthly rental market. Using actual transaction data, the study developed rent indices based on the repeat-sales model and the machine learning models (Gradient Boosting, Artificial Neural Network and Ensemble) and compared their respective outputs. Median points of the actual transaction data showed that monthly rent prices increased by approximately 1.52 times between January 2011 and December 2024. Both the repeat-salesbased and the machine learning-based indices exhibited similar cumulative growth. The former was prone to instability in periods without any transaction or in small-area units due to a reduction in sample size, whereas the latter demonstrated the ability to respond sensitively to abrupt market changes and reliably captured trends even during transaction gaps by incorporatingnonlinear relationships and a wide range of input variables. The GBM-based index specifically showed strength in reflecting short-term fluctuations, while the ANN-based index, through continuous weight updates, had excellent smoothing effects and was advantageous for identifying long-term trends. The ensemble index, combining both models, offset each one's opposing biases and delivered more timely and stable performance."
언어모델을 활용한 기계학습 기반의 학술지 추천 모형 개발 - 국내 학술출판 생태계를 중심으로 -,2025,,"학문 분야의 융합을 통한 학제 간 연구가 확대되고 접근 가능한 전자저널의 수가 증가함에 따라, 연구자들이 논문을 투고할 적합한 학술지를 선택하는 것이 더욱 어려워지고 있다. 특히 학술출판 시스템별로 서비스하는 학술지가 상이하고 국내 학술단체에서 발행하는 국제 학술지들이 증가하는 현 학술 생태계를 반영한 학술지 추천 연구는 부족한 실정이다. 본 연구는 언어모델을 활용한 기계학습 기반의 학술지 추천 아키텍처를 제안한다. 제안된 아키텍처는 타겟 데이터에 대하여 추가 학습된 BERT 계열 언어모델을 통해 논문의 제목과 초록을 임베딩하고, 이 임베딩 벡터를 XGBoost 모델에 입력하여 학술지를 추천한다. 분석 결과, BERT 계열 언어모델 중 RoBERTa 모델이 가장 우수한 성능을 보였으며, 특히 RoBERTa 기반 추천 시스템의 정확도는 전통적인 자연어 처리 기법 기반 시스템보다 약 13% 이상 높게 나타났다. 학습된 모델을 활용하여 서비스 대상 학술지의 범위를 벗어난 논문과 국문으로 작성된 논문에 대한 추천의 유효성을 확인하였다. 본 연구는 국내 학술논문 데이터를 통해 언어모델과 기계학습을 결합한 학술지 추천 시스템의 활용 가능성을 보였다는 점에서 학술적으로, 실제 국내 학술출판 환경을 고려한 서비스 아키텍처를 제시했다는 점에서 실무적으로 의의가 있다.","As interdisciplinary research expands through the convergence of academic fields and the number of accessible electronic journals increases, researchers face growing challenges in selecting appropriate journals for manuscript submission. There is a lack of research on journal recommendation systems that reflect the Korean academic ecosystem, in which academic services offer different sets of journals and international journals published by Korean academic societies are increasing. This study proposes a machine learning-based journal recommendation architecture that leverages language models. The proposed architecture embeds paper titles and abstracts using BERT-based language models further trained on target data, and these embedded vectors are then input into an XGBoost classifier to recommend appropriate journals. Analysis results showed that among BERT-based models, RoBERTa demonstrated the best performance, with its recommendation system outperforming approximately 13% higher compared to systems based on traditional natural language processing techniques. Furthermore, it was found that recommendations for papers outside the scope of service journals and papers written in Korean were feasible. This study contributes both academically and practically by presenting an academic journal recommendation architecture that leverages language models and machine learning by considering the actual Korean academic publishing environment."
기계학습을 활용한 산불 피해 규모 예측: 기상 및 환경 변수를 중심으로,2025,"['Wildfires', 'XGBoost', 'Random Forest', 'Support Vector Machine', 'Machine learning']",,"Wildfires have become increasingly frequent and severe in recent years, driven by rising global temperatures, prolonged droughts, and shifting precipitation patterns associated with climate change. These fires not only cause substantial ecological damage but also threaten human lives and infrastructure. As a result, the ability to accurately predict the scale of wildfire damage shortly after ignition is becoming a critical component of disaster preparedness and forest management.This study proposes a machine learning-based approach to predict the magnitude of wildfire damage using post-ignition environmental and geographic variables. The research utilizes wildfire incident data collected in South Korea between 2020 and 2024. Wildfires were classified into three categories—small, medium, and large—based on area burned and fire duration, following criteria adapted from national wildfire response manuals. To build predictive models, a diverse set of variables was used, including meteorological factors, drought indices, vegetation characteristics, and spatiotemporal information such as season and administrative region.Three classification algorithms —Random Forest, XGBoost, and Support Vector Machine (SVM) were applied. Due to the imbalance in class distribution, particularly the scarcity of large wildfire cases, data resampling techniques were employed to enhance model robustness. Among the models, XGBoost demonstrated the highest accuracy of 0.96 and achieved a recall of 0.89 for large wildfires, outperforming the other methods.These results suggest that combining real-time weather data with historical environmental information can help improve early predictions of the scale of the wildfire. The proposed model may assist in supporting faster response decisions and minimizing damage in high-risk areas."
저궤도 위성 자료와 기계학습 기반의 전 지구 지표 메탄 추정: 선형 및 비선형 모델 비교,2025,"['Methane', 'Low Earth orbit satellite', 'Estimation of surface methane', 'XGBoost', 'Multiple linear regression', 'Remote sensing', 'Machine learning', '메탄', '저궤도 위성', '지표 메탄 추정', '다중 선형 회귀', '원격탐사', '기계 학습']","메탄(methane, CH₄)은 이산화탄소(carbon dioxide, CO₂)에 이어 두 번째로 중요한 온실가스로, 산업혁명 이후 대기 중 메탄 혼합비는 두 배 이상 증가하였다. 메탄을 관측하는 방법 중 위성 기반 원격탐사(satellite-based remote sensing)는 넓은 지역을 지속적으로 모니터링 할 수 있는 장점을 지니며, 공간적 범위가 제한적인 지상 기반 관측(in situ)의 한계를 효과적으로 보완할 수 있다. 본 연구에서는 Tropospheric Monitoring Instrument (TROPOMI) XCH₄, ERA5 재분석 자료, WDCGG의 지상 관측 자료를 통합하여 기계 학습 기반의 지표 메탄 혼합비 추정 모델을 개발하였다. 비선형 회귀(Extreme Gradient Boosting, XGBoost) 모델과 다중 선형 회귀(Multiple Linear Regression, MLR) 모델을 개발 및 비교하여, 2018년부터 2024년까지 총 5,438개의 샘플을 분석하였다. 추정된 지표 메탄 혼합비와 지상 관측 혼합비와의 관계는 XGBoost 모델이 coefficient of determination (R²) = 0.67, root mean square error (RMSE) = 0.029 ppm, mean absolute percentage error (MAPE) = 1.05로, MLR 모델(R² = 0.41, RMSE = 0.039 ppm, MAPE = 1.48)과 비교하여 우수한 예측 성능을 보였다. 이는 위성 관측값(XCH₄)과 지표 메탄 혼합비 간의 관계가 단순 선형이 아님을 보여준다. 모델의 성능은 지역에 따라 다르게 나타났다. 추정된 지표 메탄 혼합비와 지상 관측 혼합비 간의 비교 결과, 아프리카에서 가장 높은 상관관계(R = 0.84, RMSE = 0.026 ppm)를 보였으며, 동아시아에서 가장 낮은 상관관계(R = 0.58, RMSE = 0.038 ppm)가 확인되었다. XGBoost 모델은MLR 모델에 비하여 북반구 및 남반구의 계절적 메탄 혼합비의 변화를 잘 반영하였으며, 선행 연구에서 보고된 계절 주기와 유사한 경향을 보였다. 또한, 본 모델을 통해 추정한 지표 메탄 혼합비 공간분포는National Oceanic and Atmospheric Administration (NOAA)의 Global Monitoring Laboratory에서 보고된 전 지구적 메탄 농도 증가 추세와 일치하였다. 이러한 결과는 위성 기반 자료와 기계학습을 결합한 지표 메탄 추정의 가능성을 제시하며, 지상관측 네트워크의 공간적 한계를 보완하는 데 기여할 수 있음을 보여준다.","Methane (CH₄), the second most significant greenhouse gas after carbon dioxide (CO₂), plays a crucial role in global warming. Since the Industrial Revolution, its atmospheric mixing ratio has more than doubled. Among various observational techniques for methane, satellite-based remote sensing has emerged as a key tool for continuous monitoring over large spatial scales. This study estimates the nearsurface methane mixing ratio using a machine learning approach that integrates Tropospheric Monitoring Instrument (TROPOMI) XCH₄, ERA5 reanalysis data, and World Data Centre for Greenhouse Gases (WDCGG) in situ measurements. Two regression models were developed and evaluated using 5,438 samples collected between 2018 and 2024: a nonlinear model (Extreme Gradient Boosting, XGBoost) and a multiple linear regression (MLR) model. The XGBoost model outperformed the MLR model (coefficient of determination [R²] = 0.67, root mean square error [RMSE] = 0.029 ppm, mean absolute percentage error [MAPE] = 1.05 vs. R² = 0.41, RMSE = 0.039 ppm, MAPE = 1.48), indicating a strongly nonlinear relationship between XCH₄ and near-surface methane. Model performance varied by region, with Africa showing the highest correlation (R = 0.84, RMSE = 0.026 ppm), and East Asia the lowest (R = 0.58, RMSE = 0.038 ppm). The XGBoost model successfully captured seasonal variations across both hemispheres, in line with previously reported seasonal cycles. Additionally, the estimated spatial distribution of near-surface methane mixing ratios was consistent with trends reported by NOAA’s Global Monitoring Laboratory. This study highlights the potential of combining satellite data and machine learning to estimate surface methane, offering a promising supplement to ground-based observation networks."
기계학습 모델을 이용한 성장단계별 사료 섭취량 예측,2025,"['Machine learning model', 'Pig', 'Feed Intake', 'Growth Stage', 'Environmental parameters', '기계학습모델', '돼지', '사료 섭취량', '성장 단계', '환경매개변수']","본 연구는 성장 단계별 돼지의 평균 사료 섭취량을 추정하고, 각 매개변수 간의 상관분석을 통해 변수를 선별한 후, 기계학습 기반 회귀분석을통해 돼지의 사료 섭취량(FI)을 예측하는 모델을 만들고자 한다. 본 실험은 2023년 9월 14일부터 2023년 12월 15일까지 93일 동안 진행하였다.사료는 09:00와 17:00 하루에 2회 제공하였으며, 제공된 사료의 양은 돼지의 평균 체중의 5%를 지급하였다. 돼지의 몸무게(PBW)는 매일 09:00에이동식 돈형기를 사용하여 측정하였다. 축산환경관리시스템(LEMS) 센서를 이용하여, 돈사 내 온도(RT), 상대습도(RH), NH3를 5분 간격으로수집하였다. 성장 단계를 3단계로 나누었으며, 각 GS1, GS2 및 GS3으로 명명하였다. 각 성장 단계별 평균 사료 섭취량과 표준편차를 구하여,유의미성과 성장 단계별 사료 섭취의 경향을 분석하였다. 각 모델의 성능평가(, RMSE, MAPE) 시 8:2의 비율로 데이터를 분할하여, 정확도검증을 수행하였다. 연구 결과 성장 단계별 돼지의 사료 섭취량에 유의미한 차이(p < 0.05)가 있음과 돼지가 성장할수록 일정한 양의 사료를섭취하는 것을 확인하였다. 또한 각 변수의 상관분석 시 FI와 PBW에서 강한 상관관계가 나타났으며(R > 0.94), 각 모델의 성능평가 결과 RFR모델이 가장 높은 정확성( = 0.959, RMSE = 195.9, MAPE = 5.739)을 보였다.","This study aims to estimate the average feed intake (FI) of pigs at different growth stages, select variables through correlation analysisbetween parameters, and develop a machine learning-based regression model to predict pigs' feed intake (FI). The experiment was conductedover 93 days, from September 14, 2023, to December 15, 2023. Feed was provided twice a day at 09:00 and 17:00, with the amountgiven being 5% of the pigs' average body weight. The pigs' body weight (PBW) was measured daily at 09:00 using a portable pigscale. Temperature (RT), relative humidity (RH), and NH3 levels inside the barn were collected every 5 minutes using LivestockEnvironment Management System (LEMS) sensors. The growth stages were divided into three phases, referred to as GS1, GS2, andGS3. The average feed intake and standard deviation for each growth stage were calculated to analyze the significance and trends infeed intake across different stages. For model performance evaluation (, RMSE, MAPE), the data was split in an 8:2 ratio for accuracyvalidation. The results showed a significant difference in feed intake across the growth stages (p < 0.05), confirming that pigs consumea consistent amount of feed as they grow. Additionally, a strong correlation was found between FI and PBW (R > 0.94) during thecorrelation analysis. In terms of model performance evaluation, the Random Forest Regression (RFR) model demonstrated the highestaccuracy ( = 0.959, RMSE = 195.9, MAPE = 5.739)"
기계학습을 이용한 반도체 생산 스케쥴 로그 분석 연구: 클러스터링과 의사결정트리 하이브리드 접근방법,2025,"['의사결정', '비지도 학습', '의사결정 트리', '상관관계 분석', '하이브리드 학습', '스케줄링', '반도체 생산', '생산 스케줄링', 'Decision making', 'unsupervised learning', 'decision tree', 'correlation analysis', 'hybrid learning', 'scheduling', 'semiconductor production', 'manufacturing scheduling']","반도체 생산관리는 제품 복잡도의 증가에 따라 어려워지고 있지만, 현장 스케줄링은 효율적이지 않다는 문제가 제기되고 있다. 생산 환경의 복잡성과 다양한 변수들로 인해 기존의 스케줄링방식은 실시간으로 변화하는 생산 조건에 효과적으로 대응하기 어렵고, 이로 인해 최적의 생산성과 품질을 달성하는 데 한계가 있다. 이에 따라 생산 전문가들은 생산 방향과 운영 상태를 파악할 수 있는 솔루션을 요구하고 있다. 필자는 현업의 요구사항을 바탕으로 실제 반도체 Fab의 로그 데이터를 머신 러닝을 통해 분석하여 스케줄에 영향을 미치는 의사결정 요소를 파악하고 시각화 할 수 있는 솔루션에 대해 연구하였다. 이는 향후 스케줄러의 방향성을 제시하여 Autonomous Fab을 구축하는데 기반을 제공한다는 점에서 의의가 있다.","Semiconductor production management becomes increasingly challenging due to the growing complexity of products, raising issues with the inefficiency of on-site scheduling. The complexity of the production environment and the multitude of variables make it difficult for traditional scheduling methods to effectively respond to real-time production changes, limiting the ability to achieve optimal productivity and quality. In this context, production experts are demanding solutions that provide insights into production direction and operational status. Based on the requirements, I conducted research on a solution that uses machine learning to analyze actual semiconductor Fab log data, identifying and visualizing decision-making factors that impact scheduling. This study is significant in that it suggests a direction for future schedulers and provides a foundation for building an Autonomous Fab."
초음파 속도를 활용한 모르타르의 초기동해 예측 모델 제안 및 적용성 검토,2025,"['early frost damage', 'ultrasonic pulse velocity', 'high-frequency', 'nondestructive testing', 'machine learning', '초기동해', '초음파 펄스 속도', '고주파', '비파괴 시험', '머신러닝']","본 연구는 모르타르의 초기동해 진단을 위한 고주파 초음파 및 머신러닝 기반의 다단계 회귀 모델의 적용 가능성을 평가 하였다. 1단계에서는 초음파 속도와 재령으로 압축강도를 예측하고, 2단계에서는 예측된 압축강도를 활용하여 초기동해 깊 이를 예측하였다. 총 4가지 회귀 알고리즘을 적용한 결과, 모든 분석 결과에서 250kHz와 그래디언트 부스팅 모델의 조합이 가장 우수한 예측 성능을 보였다. 이는 고주파 초음파와 비선형 회귀 모델의 조합이 초기동해로 인한 미세 손상을 평가하는 데 효과적이고, 향후 콘크리트 구조물에 대한 적용 가능성과 현장 진단 기술로의 확장을 위한 기초자료로 활용될 수 있을 것으로 판단된다.","This study evaluated the applicability of a multi-stage regression model based on high-frequency ultrasonic testing and machine learning for diagnosing early frost damage in mortar. In the first stage, compressive strength was predicted using ultrasonic pulse velocity and curing age; in the second stage, the predicted compressive strength was used to estimate the depth of early frost damage. Among the four regression algorithms applied, the combination of the 250 kHz ultrasonic data and the gradient boosting model consistently showed the highest prediction accuracy. These findings suggest that the integration of high-frequency ultrasonic signals with nonlinear regression models is effective in assessing microstructural damage caused by early frost, and can serve as a foundation for future applications in concrete structures and the development of on-site diagnostic technologies."
완전동형암호화를 활용한 질병감수성 예측 기계 학습모델 성능평가,2025,"['Fully homomorphic encryption (FHE)', 'Disease susceptibility prediction', 'Polygenic risk score (PRS)', 'Machin learning']",,"The activation of polygenic risk score (PRS) in precision medicine has raised concerns about privacy pres- ervation. Current encryption methods that delete or modify variant information may reduce prediction accuracy. The purpose of this study was to evaluate the feasibility of PRS-based disease susceptibility prediction in a fully homo- morphic encryption (FHE) environment while assessing computational trade-offs. We conducted disease susceptibility prediction using synthetic public genome-wide association study (GWAS) data on coronary artery disease (CAD) and applied inverse probability weighting, k-fold cross-validation, and linkage disequilibrium (LD) shrinkage to enhance polygenic risk score stability and accuracy. Four machine learning models—PRS only logit, ridge regression, linear support vector machine, and radial basis function support vector machine— were trained and tested on fully encrypted genomic and clinical data, with performance evaluated using area under the curve (AUC), mean absolute error (MAE), and turnaround time. A total of 1,401 samples and 404,663 SNPs were used. Ridge regression balanced prediction accuracy and computational efficiency (AUC = 0.7631, MAE = 0.4375, Turnaround Time = 1,343.65s). RBF SVM achieved the highest AUC (0.7792, MAE = 0.3120) but required the longest time (1,983.57s). PRS Only Logit had the shortest time (279.27s) but the lowest AUC (0.6339, MAE = 0.4162). These results suggest ridge regression may have the best balance between prediction accuracy and computational efficiency, making it the most practical choice in an FHE environment."
저류층 내 기계학습 해석 층서 및 종합 지하 물성의 불확실성 정량화 워크플로우 제시,2025,"['불확실성 정량화', '체적 분석', '지구통계학', '저류층 특성화', 'Uncertainty Quantification', 'Volumetric Analysis', 'Geostatistics', 'Reservoir Characterization']","지하 저류층의 불확실성은 층서 기하, 암상 분포, 그리고 공극률 등 다양한 지하 물성으로부터 기인될 수 있다. 최근 탄성파 자료의 용량이 증가함에 따라기계학습을 기반으로 하는 탄성파 층서 해석 기법들이 연구되고 있다. 해당 연구들은 해석 층서들의 저류층 특성화 과정에서의 적용성에 대한 검증이부족하다는 한계를 보인다. 이에 본 연구는 기계학습 해석층서, 암상 분포, 그리고 공극률의 불확실성을 종합적으로 평가하는 워크플로우를 제시한다.해당 워크플로우는 지구통계학적 기법 기반의 3차원 모델 구축, Sequential indicator simulation 기반의 암상 분포 모델링, Gaussian random function simulation 기반의 암석물성 모델링 과정으로 구성되어 있으며, 각 과정의 모델링 결과의 분석을 통해 사용 변수 및 기법의 타당성을 검증하였고 최종 저류층 공극 부피 계산을 통한 불확실성 정량화가 수행되었다.","Uncertainties in reservoirs can result from various subsurface parameters, such as horizon geometry, facies distribution, and porosity. With the rising demand for the rapid processing and interpretation of seismic data, machine learning-aided seismic horizon interpretation methods have gained academic interest in recent years. However, these studies are limited to interpretation and have not been validated for their applicability to reservoir characterization. Therefore, this study proposed an integrative uncertainty quantification workflow that can analyze uncertainties resulting from machine learning-interpreted horizons, facies distribution, and reservoir porosity. The workflow consisted of geostatistical method-based three-dimensional model construction, sequential indicator simulation-based facies modeling, and Gaussian random function simulation-based petrophysical modeling. The modeling results from each processes were analyzed to validate the adequacy of the parameters and algorithms used. The final reservoir pore volume was calculated to quantify the effects of the uncertainties."
수동 요약문 작성과 기계 학습 기반 자동 요약문 작성 비교 - 전문분야 심층 인터뷰 텍스트 요약문을 대상으로 -,2025,"['요약문', '수동 요약문', '자동 요약문', '인터뷰 텍스트', '질의-응답쌍', 'Summary', 'Manual Summary', 'Automatic Summary', 'Interview Text', 'Question-Answer Pair']","이 연구의 목적은 질의-응답쌍으로 구성된 전문분야 심층 인터뷰 텍스트를 원문으로 생성한 수동 요약문과 기계 학습 기반의 자동 요약문의 양상을 분석하여, 그 차이를 확인하는 것이다. 기존의 자동 생성 요약문 연구가 주로 언어 공학적 관점에서 단일 저자 텍스트에 대한 요약문 생성 방법론을 고안하거나, 요약문에 대한 종합적인 인상 평가 성격을 갖는 것과 달리, 이 연구는 질의-응답쌍을 갖는 인터뷰 텍스트를 원문으로 갖는 응답 텍스트의 요약문 생성을 연구 대상으로 하며, 텍스트를 구성하는 언어 단위의 형식적, 의미적 특성을 기반으로 분석한다. 수동및 자동 요약문의 양적 측면에서, 응답 텍스트를 대상으로 한 자동 생성 요약문은수동 요약문에 비해 대체로 더 적은 문장 수와 더 짧은 길이로 구성되어 과소 요약의 경향성을 보인다는 것을 확인할 수 있다. 요약문 내용 분석의 측면에서, 자동생성 요약의 경우 요약 대상 텍스트의 내용을 표현하는 어휘를 선택하는 데 있어요약문 내용 구성에 직접적 관계가 없는 어휘를 선택하는 한계를 부분적으로 보이며, 수동 요약문이 질의 텍스트의 의도를 고려한 내용 구성의 특성을 보이는 반면, 자동 요약문은 상대적으로 질의 텍스트에 대한 고려가 약한 것으로 판단된다.","The purpose of this study is to analyze and compare manually generated summaries and machine learning-based automatic summaries of expert in-depth interview texts structured in question-and-answer pairs, in order to identify the differences between them. Unlike previous studies on automatically generated summaries, which primarily focus on developing summarization methodologies for single-author texts from a computational linguistic perspective or offer general evaluative impressions of summaries, this research focuses on the summarization of response texts from interviews with Q&A structures. The analysis is based on the formal and semantic characteristics of the linguistic units that compose the text. From a quantitative perspective, the automatically generated summaries of response texts tend to contain fewer sentences and be shorter in length compared to the manually created summaries, indicating a tendency toward under- summarization. In terms of content analysis, automatic summaries partially reveal limitations in vocabulary selection, sometimes including words that are not directly relevant to the content of the source text. While manual summaries reflect content that considers the intent of the questions, automatic summaries appear to show relatively less consideration of the question texts."
후보자의 표정과 유권자의 마음: 기계학습 기반 이미지 알고리즘을 활용한 후보자 선거포스터 정서분석을 중심으로,2025,"['이미지분석 알고리즘', '얼굴표정 휴리스틱', '국회의원 선거', '방법론적 삼각측량', 'vision data analytic algorithm', 'appearance heuristic', 'congressional election', 'methodological triangulation']","본 연구는 후보자의 얼굴표정이 선거결과 및 유권자의 정치적 의사결정에 어떤 영향을 미치는지 살펴보았다. 이를 위해 아마존 웹 서비스의 Face Rekognition (FR) 알고리즘을 활용하였으며, 방법론적 삼각측량 관점에서 내용분석 연구, 관측연구, 실험연구를 실시하였다. 첫째, 제20대 국회의원 선거를 배경으로 245개 지역구, 총 920명의 후보자들의 선거포스터 이미지를 수집한 후, FR 알고리즘의 정서분석과 모든 후보자 얼굴들을 모두 인간코딩한 결과 사이의 합치수준을 살펴보았다. 분석결과 여러 정서들 중 행복(happy)에서만 FR알고리즘과 인간코더 사이에 용인가능한 합치도를 보였다. 둘째, 후보자 얼굴표정에서 나타난 행복정서 점수와 해당후보자의 지역구내 득표율·당선가능성의 관계를 살펴본 관측연구를 실시한 결과, 후보자 얼굴에서 행복정서가 나타날 때 약 4% 정도 득표율이 증가하고, 당선가능성은 약 1.71배 높아졌다. 셋째, 내적타당도 확보를 위해 무작위배치 기반 실험을 실시한 결과, 행복한 표정의 후보자를 접한 실험참가자일수록, 후 보자 대상 감정적 호감도가 높았으며, 이는 해당 후보자에 대한 투표의향으로 이어졌다. 연구결과를 바탕으로 연구의 이론적·방법론적 함의에 대해 논의하였다.","This study examines the effect of candidates’ facial appearance on electoral consequences and individuals’ electoral decision-making. Specifically, this study harnesses the Face Rekognition (FR) algorithm developed and maintained by Amazon Web Services, one of the most popular vision data analytic algorithms based on machine learning. It conducts three studies: content analysis, observational study, and experimental study, under the rubric of methodological triangulation. First, after web-scraping image data from 920 candidates within 245 districts in the 20th Congressional Election in South Korea, we compared the emotions extracted from the FR algorithm against those judged by two human coders. Content analytic results showed that out of eight emotions, only happiness achieved an acceptable level of agreement between machine coding and human coding. Second, an observational study was conducted to examine the relationship between the degree of happiness on a candidate’s face and the candidate’s vote share as well as their likelihood of being elected. Results showed that candidates with a happy face are more likely to earn an additional 4% in vote share, and their probability of winning increases by a factor of approximately 1.71. Third, to secure internal validity, an experimental study with random assignment was conducted. Results show that participants exposed to a candidate with a happy face give higher affective evaluations of the candidate, resulting in a stronger intention to vote for that candidate. We discuss both methodological implications regarding the strengths and weaknesses of the vision data analytic algorithm, as well as theoretical implications about the psychological mechanisms embedded in the relationship between candidates’ facial appearance and voters’ decision-making."
온라인 담론에 드러난 산후조리원 인식의 다층적 구조에 대한 탐색적 연구: BERTopic 기반 기계학습 문서 분류 분석을 중심으로,2025,"['Key Words: Postpartum Care Centers', 'Social Constructionism', 'Discourse Analysis', 'BERTopic', '[주제어: 산후조리원', '사회적 구성주의', '담론 분석', 'BERTopic]']","본 연구는 한국 사회에서 산후조리원이 어떻게 재구성·의미화되는지를 규명하고자, 유튜브 뉴스 콘텐츠 댓글에 나타 난 대중 담론을 사회적 구성주의 관점에서 분석하였다. 이를 위해 기계학습 기반의 BERTopic 기법을 적용하여 댓글 텍스트를 군집화하고, 각 군집의 핵심 주제와 하위 논점을 구조적으로 도출하였다. 분석 결과, 산후조리원에 대한 대중 인식은 의료·복지적 기능뿐 아니라 저출산 문제, 비교문화 및 계층화된 소비, 언론 보도, 정부 지원정책 등 다차원적 요소가 중첩·상호작용하면서 구성되는 ‘복합적 의미 구조’를 형성하고 있음이 확인되었다. 특히 산후조리원을 ‘필수적 산후조리 시설’로 인식하는 담론과 ‘비필수이거나 과도한 비용 부담 시설’로 보는 담론이 각각 상이한 비판점과 지지 논리를 드러내며 담론이 더욱 세분화되고 있었다. 또한 언론 보도에 대한 비판 적 태도, 저출산 문제와의 연계성, 지원정책 실효성 한계 등을 둘러싼 다양한 쟁점이 동시적으로 제기됨으로써, 산후조 리원이 단순 의료·복지서비스의 범주를 넘어 사회·문화·정책적 맥락이 교차되는 지점에서 끊임없이 재해석되고 있음을 시사한다. 이러한 결과는 (1) 대규모 온라인 텍스트 분석을 통해 담론 구조를 체계적으로 파악할 수 있는 기계학습 기반 방법론 의 유용성, (2) 산후조리원이 가치 충돌과 복합적 맥락 속에서 어떠한 방식으로 의미가 재구성되는지를 실증적으로 제시 했다는 점, (3) 비용 모니터링, 공공·중간형 조리원 도입, 언론 보도 균형성 강화 등 구체적인 정책 개선 방안을 모색할 근거를 마련했다는 점에서 학술적·정책적 의의를 지닌다. 향후에는 보다 정교한 데이터 수집·정제 및 다양한 선행연구 검토를 통해, 온라인 담론 분석을 다른 사회적 이슈로 확장하는 후속 연구가 가능할 것으로 기대된다.","This study aims to elucidate how postpartum care centers in Korean society are reconstructed and legitimized by analyzing public discourse in YouTube news comments through the lens of social constructionism. To achieve this, a machine learning–based BERTopic technique was applied to cluster the comment texts, allowing for the systematic derivation of each cluster’s core themes and subtopics. The analysis revealed that public perceptions of postpartum care centers encompass not only their medical and welfare functions but also a wide range of interrelated factors—including low birth rates, comparative cultural perspectives, stratified consumption, media coverage, and government support policies—that together constitute a “complex structure of meaning.” In particular, discourses framing postpartum care centers as “essential postpartum care facilities” and those viewing them as “non-essential or financially burdensome” each highlight distinct criticisms and supporting arguments, resulting in increasingly segmented debate. Furthermore, controversies surrounding critical attitudes toward media reporting, the linkage with low birth rates, and the limited effectiveness of support policies emerged concurrently, suggesting that postpartum care centers are continuously reinterpreted at the intersection of social, cultural, and policy contexts beyond the narrow scope of medical and welfare services. These findings hold academic and policy significance in three main respects: (1) they demonstrate the utility of a machine learning–based approach for systematically mapping discourse structures via large-scale online text analysis; (2) they offer empirical insights into how postpartum care centers are discursively reconstructed amid conflicting values and multifaceted contexts; and (3) they provide a foundation for concrete policy recommendations—such as cost monitoring, the introduction of public or intermediate postpartum care centers, and the enhancement of balanced media coverage. Future studies could expand this form of online discourse analysis to other social issues by refining data collection and preprocessing procedures and by undertaking a more comprehensive review of prior research."
서울시 고령 운전자의 중상 및 사망사고와 도로 환경의 연관성 분석: 기계학습을 활용한 비선형성과 상호작용 효과를 중심으로,2025,"['앙상블 알고리즘', '중상 및 사망사고', '상호작용 효과', '비선형 관계', '고령 운전자', 'ensemble algorithms', 'fatal accidents', 'interaction effects', 'non-linear relationships', 'older adult drivers']","본 연구는 2017년부터 2019년까지의 TAAS 교통사고 데이터를 활용하여 서울시 고령 운전자의 중상 및 사망사고 발생과 도로 환경적 요소 간의 비선형 관계 및 상호작용 효과를 탐구하였다. 이를 위해 기계학습 기반의 트리 앙상블 알고리즘과 SHAP 기법을 적용하고, 이론적 관점을 결합하여 심층적인 통찰을 도출하였다. 주요 연구 결과는 다음과 같다. 첫째, XGBoost 모형은 고령 및 비고령 운전자의 교통사고 예측에서 가장 우수한 성능을 보였으며, 특히 비고령 운전자의 예측에서는 SMOTE 기법을 활용한 성능 개선이 관찰되었다. 둘째, 고령 운전자의 사고 예측에서는 도로 네트워크의 구조적 특성과 복잡한 도로 환경(교차로 수, 상업시설 밀도)이 중요한 변수로 작용하는 반면, 비고령 운전자는 도로 환경에 더 유연하게 반응하여 해당 변수들의 중요도가 낮음을 확인하였다. 특히, 녹지 비율은 고령 운전자의 사고 확률을 저감시키는 중요한 요소로 나타났다. 셋째, SER 이론을 바탕으로 도로 환경과 사고 확률 간의 비선형 관계를 분석한 결과, Closeness, 상업시설 밀도, 개방감 등에서 비선형적 패턴이 발견되었으며, 특정 임계치를 초과할 경우 사고 확률이 급격히 증가하는 경향이 나타났다. 마지막으로, ART 이론을 기반으로 녹지 비율과 도로 환경 요소 간의 상호작용 효과를 분석한 결과, 상업시설 밀도가 높은 지역이나 폐쇄적인 도로 환경에서 적정 녹지 비율이 조성되면 사고 확률이 감소하는 경향을 보였다. 이러한 결과는 고령 운전자가 복잡한 도로 환경에서 자연적 요소인 녹지를 통해 주의 회복을 돕고, 사고를 예방할 수 있음을 시사한다. 본 연구는 고령 운전자의 사고를 줄이기 위한 도로 환경 설계 및 교통 관리 정책 수립에 유용한 정보를 제공하며, 특히 비선형적 사고 예측 패턴과 상호작용 효과 분석을 기반으로 한 맞춤형 교통 안전 전략의 필요성을 강조한다.","This study analyzes traffic accident data from the TAAS (2017-2019) to examine non-linear relationships and interaction effects between road environmental factors and fatal accidents involving older adult drivers in Seoul. Machine learning-based tree ensemble algorithms and the SHAP method were used to provide insights integrating theoretical perspectives. The main findings are as follows: First, the XGBoost model performed best in predicting accidents for both older adult drivers and non-older adult drivers, with significant improvement observed for non-older adult drivers using the SMOTE technique. Second, for older adult drivers, road network characteristics and complex environments (intersection count, commercial facility density) were key factors, while non-older adult drivers showed more flexibility, reducing the importance of these factors. Green space proportion was found to lower accident probability for older adult drivers. Third, non-linear patterns were observed in variables such as Closeness, commercial facility density, and openness, with accident probability rising sharply beyond certain thresholds. Finally, interaction effects based on Attention Restoration Theory indicated that in areas with high commercial facility density or enclosed environments, an optimal green space ratio reduced accident probability. These results suggest that green spaces can enhance attention and reduce accidents for older adult drivers in complex environments. This study informs road environment design and traffic policy development to reduce older adult drivers accidents, highlighting the need for tailored safety strategies based on non-linear patterns and interactions."
기계학습 기반 Sentinel-2 지수융합형 클로로필-a 농도 예측 모델 및 하천수 녹조 탐지 가능성 고찰,2025,"['Sentinel-2', 'Chlorophyll-a', 'Random forest regression', 'Index integration', '클로로필-a', '랜덤 포레스트 회귀', '지수통합형 모델']","본 연구는 Sentinel-2 위성 영상을 활용해 국내 국가하천의 클로로필-a 농도의 분광 특성을 분석하고 통합 예측 모델을 개발했다. 2021-2023년 분석 결과, 1년 8개월 동안 클로로필-a 농도가 기준치를 초과했으며, 특히 여름철에 높은 농도를 보였다. 분광 분석 결과, Red Edge 밴드의 반사도가 클로로필-a 농도 증가에 따라 증가하는 경향을 보였으나, 단일 밴드와의 상관성은 낮았다(R<sup>2</sup>≈0.1). 그러나 Red Edge 밴드를 포함한 2 band model (2BDM), 3 band model (3BDM), normalized difference chlorophyll index (NDCI) 지수는 클로로필-a 농도와 높은 상관관계(R>0.7, p<0.001)를 나타냈다. 이를 기반으로 개발된 랜덤 포레스트 회귀 지수통합형 모델은 단일 지수 모델(R<sup>2</sup>=0.70-0.75)보다 우수한 예측 성능(R<sup>2</sup>=0.91)을 보였으며, 오차 지표에서도 mean absolute error (MAE) 7.77 mg/L, root mean square error (RMSE) 11.32 mg/L, normalized root meansquare error (NRMSE) 0.07로 더 우수했다. 현장적용성 평가에서도 지수통합형 모델은 높은 예측력(R2=0.72, NRMSE=0.17)을 유지하며 단일 지수 모델(R2=0.54-0.56, NRMSE=0.23-0.25)보다 우수한 예측력을 보였다. 이는 보다 다양한 환경 조건을 반영한 본 모델의 일반화가 가능함을 시사한다. 본 모델은 다양한 하천 조건을 반영하고 위성영상과 수질자료 간 시간차를 30분 이내로 제한하여 국내 하천 환경에 적합한 정밀 예측이 가능하여, 정체 수역 중심의 기존 모델 한계를 극복하고 하천 전반에 적용 가능한 실용적 모델로 활용될 수 있을 것으로 기대된다.","This study analyzed the spectral characteristics of chlorophyll-a concentrations in South Korean national rivers using Sentinel-2 satellite imagery and developed an integrated prediction model. Analysis from 2021-2023 showed that chlorophyll-a concentrations exceeded the standard for 1 year and 8 months, with particularly high concentrations during summer. Spectral analysis revealed that reflectance in the Red Edge band increased with rising chlorophyll-a concentrations, though correlation with single bands was low (R<sup>2</sup>≈0.1). However, 2 band model (2BDM), 3 band model (3BDM), and normalized difference chlorophyll index (NDCI) indices, including the Red Edge band, strongly correlated with chlorophyll-a concentrations (R>0.7, p<0.001). The random forest regression model integrating these indices demonstrated superior prediction performance (R2=0.91) compared to single-index models (R<sup>2</sup>=0.70-0.75) and also performed better in error metrics with mean absolute error (MAE) of 7.77 mg/L, root mean square error (RMSE) of 11.32 mg/L, and normalized root mean square error (NRMSE) of 0.07. In field applicability evaluations, the integrated index model maintained high predictive power (R<sup>2</sup>=0.72, NRMSE=0.17), outperforming single-index models (R<sup>2</sup>=0.54-0.56, NRMSE=0.23-0.25). This suggests the model can be generalized to diverse environmental conditions. By reflecting various watershed conditions and limiting the time difference between satellite imagery and water quality data to within 30 minutes, the model enables precise predictions suitable for South Korean river environments, overcoming the limitations of existing models focused on stagnant waters and offering potential application across river systems as a practical model."
비정상적 시계열 데이터 특성에 따른 비모수 기계학습 알고리즘 선택 연구,2025,"['비모수 기계학습', '비정상 시계열', '철도인프라수요', 'COVID-19', 'XAI', 'Demand forcasting', 'Time series forcasting', 'ML', 'SHAP', 'COVID-19']","끊임없이 변화하는 도시 인프라의 수요예측의 정확도에 따라 미래 도시의 경쟁력은 달라질 수 있으며, 도시 시계열 데이터 예측은 시간에 따른 변화양상이 큰 도시 인프라의 수요예측에서 핵심적인 역할을 한다. 기존 시계열 수요예측은 통계적 모형(ARIMA, SARIMA)에 의존해 왔으나, 통계적 모형은 사전가정으로 비선형적 패턴을 포착하는 데 한계가 있어 사전 가정의 한계에서 자유로운 기계학습모형이 비선형적 데이터 처리에 활용되는 추세다. 다만, 다양한 기계학습 알고리즘 중 어떤 알고리즘이 도시 내 인프라 수요 예측에 적합한 지에 대한 논의는 계속해서 이뤄지고 있는 추세이다. 본 연구에서는 COVID-19 이후 불확실성이 커진 도시내 철도수송수요를 대상으로 다변량 기계학습모형과 단변량 기계학습모형의 성능 및 활용방안을 비교 및 검증하였다. 분석 결과, Prophet은 비정상적 시계열적 자기상관성을 고려하며, COVID-19 및 올림픽을 고려한 예측에서 탁월한 성능을 보여주었다. 단, XGBoost는 외부요인에 대한 계량화를 통해 역별 수송수요의 특성을 파악할 수 있었다. 따라서, 기계학습 알고리즘의 선택은 분석의 목표·활용 방향성에 맞춰 활용한다면 보다 효율적인 전략수립에 도움이 될 것이다.","Cities primarily rely on accurate forecasts of rapidly evolving infrastructure demands to maintain a competitive edge, and time series analysis is central to predicting infrastructure needs that exhibit significant fluctuations over time. Although traditional time series forecasting has predominantly utilized statistical models (such as ARIMA and SARIMA), these approaches face inherent limitations in capturing nonlinear relationships due to their underlying assumptions (e.g., predetermined assumptions). Machine learning models, by contrast, are freed from such assumptions and excel at handling nonlinear data while automatically adjusting algorithm performance—leading to their growing adoption in railway demand forecasting. Nonetheless, the question of which machine learning algorithm is best suited for predicting urban infrastructure demand remains a topic of ongoing discussion. In this study, we compare and validate the performance and practical applications of multivariate and univariate machine learning models for forecasting urban railway demand, especially under heightened uncertainty following the COVID-19 pandemic. Our findings indicate that Prophet, which accounts for time-series autocorrelation, delivers exceptional performance when forecasting irregular events, such as COVID-19 impacts and the Olympics. Meanwhile, XGBoost can quantify external factors, enabling deeper insights into station-specific demand characteristics. Consequently, selecting and applying a suitable machine learning algorithm—one that aligns with the objectives and intended use of the analysis—can play a pivotal role in developing more efficient strategies."
신속한 스마트미디어 중독 성향 예측을 위한 설문 데이터 기반의 기계학습 모델,2025,"['스마트 미디어', '미디어 중독', '기계학습', '인공지능', '상담심리', 'Smart Media', 'Smart Media Addiction', 'Machine Learning', 'Artificial Intelligence', 'Counseling Psychology']","본 연구는 성인 스마트미디어 중독 조사에 대한 빅데이터를 기반으로 기계학습을 사용하여 중독 분류인 위험군, 잠재적 위험군, 정상을 신속하게분류하는 인공지능 모델을 제안한다. 스마트미디어는 계속해서 발전하고 있으며, 코로나 이후 급격하게 스마트미디어 의존도가 높아졌으나, 현재스마트미디어 중독에 대한 예방 및 치료 프로그램은 충분하지 않다. 스마트미디어 사용자들은 대부분 중독을 자각하지 못하고 있으며 중독의 위기감을 자각하더라도, 중독 성향 예측은 주로 심리검사를 받기 위한 내담자나 방문자에게 척도를 제시함으로써 이루어지기 때문에 검사를 위한 스마트미디어 중독 척도에 대한 일반 대중의 접근성은 매우 낮은 실정이다.본 연구에서는 일반 대중의 스마트미디어 중독 척도에 대한 접근성을 높이고자 기계학습을 사용한 자동화된 인공지능 모델을 구성하여 개인및 집단에 대한 중독 추세 파악을 시도하였다. 연구에서 제안된 인공지능 모델은 기계학습을 활용하여 척도의 점수 처리 과정을 대체함으로써정확도와 처리시간이 향상되었다. 본 연구 결과는 중독 분류 과정에서 인력과 시간비용을 줄임으로써 스마트미디어 중독의 사용과 관련된 문제를실시간으로 인지 및 예방하고, 중독 위험 감소를 통해 더 건강한 사용 습관을 촉진하는 데 기여할 수 있다. 내담자에 대한 상담에서 인공지능기반의 접근 방법은 개인 맞춤형 중독 예방 및 치료 프로그램 개발에 활용될 수 있으며, 수집된 데이터는 빅데이터로서 스마트미디어 중독 추세파악에 중요한 기초 자료로 활용될 것으로 판단된다.","This study proposes an artificial intelligence model that utilizes machine learning to rapidly classify adults into three categories—high-risk, potential risk, and normal—based on big data from a survey of smartphone addiction. Smart media continues to evolve, andits reliance has surged significantly since the COVID-19 pandemic; however, current prevention and treatment programs for smartphoneaddiction are insufficient. Most smart media users are unaware of their addiction, and even when they recognize the potential risks ofaddiction, the prediction of addictive tendencies primarily occurs by presenting scales to clients or visitors seeking psychologicalassessments. As a result, the general public's access to assessments for smartphone addiction scales is notably limited. This study aimsto enhance public access to smartphone addiction scales by developing an automated artificial intelligence model using machine learning,in order to identify addiction trends on both individual and group levels. The artificial intelligence model proposed in this study enhancesaccuracy and processing time by substituting the score processing of traditional scales with machine learning techniques. The resultsof this study can contribute to real-time recognition and prevention of smartphone addiction by reducing manpower and time costs duringthe classification process, thereby promoting healthier usage habits through the reduction of addiction risks. In counseling clients, anAI-based approach can be utilized for the development of personalized prevention and treatment programs for addiction. Moreover, thecollected data will serve as an important foundational resource for understanding trends in smartphone addiction as big data."
기계학습을 활용한 마늘 생체중 예측,2025,"['Garlic', 'Machine Learning', 'Fresh weight', '마늘', '생체중', '머신러닝']","본 연구는 표현 형질 생육 데이터인 엽장, 엽 수와 기상 데이터인 생육도일을 활용하여 여러 기계 학습을 통해 마늘의 생체중을 예측하는 모델을 개발하고자 하였다. 검증 데이터에서 random forest 모델의 결정계수가 0.924, 평균제곱근오차(g)는 13.583 그리고 평균절대오차는 8.885로 가장 우수하였다. 평가 데이터에서는 Catboost 모델이 결정계수가 0.928,평균제곱근오차(g)는 13.486 그리고 평균절대오차는 9.181 로 가장 우수하였다. 그러나 Catboost, Random forest 그리고LightGBM 모델을 0.5, 0.3 그리고 0.2 가중치를 두어 학습한Weighted ensemble 모델이 마늘 생체중 예측의 검증 및 평가에 있어서 검증 데이터의 결정계수가 0.922, 평균제곱근오차(g)가 13.752 그리고 평균절대오차는 8.877이었으며 평가 데이터에서는 결정계수가 0.923, 평균제곱근오차(g)가 13.992 그리고 평균절대오차가 9.437로 두 번째로 우수한 결과를 나타내었다. 이러한 결과들을 종합적으로 미루어 보았을 때, Weighted ensemble 모델이 모델의 안정성 측면에서 최적의모델이라고 판단하였다. 따라서 농가들이 표현 형질과 기상데이터만으로도 기계학습 기법을 통하여 마늘의 생체중 예측을 통해 작형 모니터링이 가능할 것으로 보이며 추가적으로다년도 데이터 취득과 검증을 통하여 성능을 고도화가 가능할것으로 판단된다.","This study aimed to develop a model for predicting garlic fresh weight using various machine learning techniques based on growth data, including leaf length, leaf count, and growing degree days as meteorological data. In the validation dataset, the Random forest model exhibited the highest performance with R2 of 0.924, RMSE (g) of 13.583, and MAE of 8.885. In the test dataset, the Catboost model outperformed others with R2 of 0.928, RMSE (g) of 13.486, and MAE of 9.181. However, a Weighted ensemble model trained with weights of 0.5, 0.3, and 0.2 for Catboost, Random forest, and LightGBM models, respectively, demonstrated the second-best performance in both the validation and test datasets, with R2 of 0.922 and 0.923, RMSE (g) of 13.752 and 13.992, and MAE of 8.877 and 9.437, respectively. Based on these findings, the Weighted ensemble model was deemed the optimal choice. Thus, it is suggested that farmers can employ machine learning techniques to predict garlic fresh weight using only phenotypic and meteorological data, facilitating field monitoring. However, further data acquisition and validation over multiple years are essential to refine the model’s performance."
조립품의 부품 식별과 탐지를 지원하는 기계학습 모델과 데이터셋 통합 제품 자료 모델 개발,2025,"['Product Development', 'Machine Learning', 'Product Data Model', 'Transfer Learning', 'ML Model', 'ML Dataset']",,"To effectively use machine learning (ML), virtual ML applications that take into account aspects particular to an ML application domain are required. This paper presents a product data model that incorporates ML objects to assist ML applications for the part detection among components of a given assembly product during product development. The proposed product data model combines ML model and dataset objects during the ML life cycle, as well as item, technical document, product structure and engineering change objects over the product life cycle. The ML objects in the product data model are tightly connected with product structures and support production routings, which are the domain of ML applications in product development. Furthermore, they apply transfer learning approaches to repurpose previously learned ML models to create new ML models for engineering changed products. To evaluate the feasibility of the proposed product data model, a test application of the part detection ML is implemented utilizing an existing information system for product development and manual operations."
WAAM 공정의 기계학습 기반 에너지-품질 공정 파라미터 맵,2025,"['Wire Arc Additive Manufacturing', 'Machine Learning', 'Heat Input Prediction', 'Defect Classification', 'Process Parameter Map']",,"This paper proposes a method of generating a process parameter map to visualize the energy and quality availability graphically using machine learning in wire arc additive manufacturing (WAAM). In the proposed method, a machine learning model is generated to predict heat input by training numerical voltage data, while the heat input represents energy performance. Another machine learning model is generated to classify the normal or two defect types of the current state by training the predicted heat inputs. The results of the two models are combined and visualized in the form of a three-dimensional map to project heat input and normality distributions with regard to travel speed and wire feed rate process parameters. A case study is demonstrated to evaluate the performance of the models and the feasibility of the proposed method. The energy-quality process parameter map enables operators to select the two process parameters correctly for energy reduction simultaneously with quality assurance in WAAM."
자동화 기계학습을 이용한 노인 우울증 예측,2025,"['depression', 'prediction model', 'machine learning', 'AutoML', 'feature importance', '.']","최근 한국에서 급격한 고령화 인구의 증가는 중요한 사회적 문제로 대두되고 있으며, 특히 노인 우울증 환자의 비중이 크게 증가하고 있다. 본 논문은 2020년 노인 실태조사 데이터를 활용해 AutoML(Automated Machine Learning) 기반의 노인 우울증 예측모델을 제시한다. 예측 정확도 향상을 위해 결측값 처리, 원-핫 인코딩, 레이블 인코딩 등의 전처리와 오버샘플링 기법을 적용하였다. AutoML을 통해 최적의 ML 모델을 선정하고 하이퍼파라미터를 조정하여 최종 예측 모델을 도출하였다. 결과에서 최적화된 모델을 기초로 특성 중요도를 산출하였으며, 이를 통해 노인 우울증은 단일 요인에 의해 발생하는 것이 아니라 신체적, 경제적, 심리적 요인들의 복합적인 상호작용에 의해 영향을 받는다는 것을 알 수 있었다.","The rapid increase in the aging population in Korea has recently emerged as a significant social issue, with a notable rise in the proportion of elderly patients with depression. This paper presents an Automated Machine Learning(AutoML) based prediction model for geriatric depression using the 2020 Elderly Survey data. To enhance prediction accuracy, preprocessing techniques such as missing value handling, one-hot encoding, and label encoding were applied, along with oversampling to address class imbalance. Through AutoML, the optimal ML model was selected and its hyperparameters were adjusted to derive the final prediction model. Based on the optimized model, feature importance analysis was conducted, revealing that geriatric depression is influenced by a complex interaction of physical, economic, and psychological factors rather than a single cause."
임베디드 시스템의 기계학습을 위한 양자화 학습의 확률 미분 방정식,2025,"['Stochastic Differential Equation', 'Quantization', 'Machine Learning', 'Embedded System']",,"In this paper, we propose the stochastic differential equation(SDE) for the quantized learning equation. We analyze the uniform quantized learning equation based on the central limit theorem and yield an overdamped Langevin dynamics that allows us to control the dynamics of the learning equation. As the proposed analysis demonstrates, the experimental results show that quantized learning performance is better than the conventional learning equations in image classification problems based on the global optimization quantity."
기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구,2025,"['Data augmentation', 'Deep learning', 'Diabetes prediction', 'Machine learning', 'Medical data']",,"Early diagnosis and prediction of diabetes are essential for preventing disease progression and establishing effective treatment strategies. This study aims to develop and evaluate a diabetes prediction model using machine learning (SVM, Random Forest, XGBoost) and deep learning (ANN, CNN, LSTM) techniques. To address data imbalance, a GAN-based data augmentation method was applied, and the SHAP technique was utilized to enhance the interpretability of the model's predictions. Additionally, a model incorporating Korean-specific characteristics was developed using electronic health records (EHR) from domestic hospitals and wearable device data. Future research aims to extend the model to predict various chronic diseases and contribute to the development of real-time monitoring and personalized prevention systems."
변환 오디오 부호화를 위한 기계 학습 기반의 시간 영역 신호 제어 기술,2025,"['Transform audio coding', 'Machine learning', 'Time-domain signal control']","본 논문에서는 변환 오디오 부호화를 위한 기계 학습 기반의 신호 제어 방법을 제안하고, 그 결과를 시간 영역 평탄화 동작과 비교한다. 입력 신호와 기계 학습으로 결정된 제어 신호를 시간 영역에서 곱한 후 부호화하고, 복호화 후에 제어 신호를 제거하여 출력한다. 학습 단계에서 부호화 과정을 포함한 종단 간 학습을 위해 부호화 동작을 미분 가능 형태로 모델링 한다. 학습을 통해 얻은 최적의 신호 제어 동작이 시간 영역 평탄화에 해당하고 과도 신호 구간에서 성능 향상을 제공하는 것을 확인하였다.","This paper proposes a signal control method based on machine learning for transform audio coding and compares the resultswith time-domain flattening operation. The input signal and the control signal determined by machine learning are multiplied in thetime domain before encoding, and the control signal is removed after decoding. In the training stage, the encoding operation ismodeled in a differentiable form for end-to-end training. It is confirmed that the optimal signal control corresponds to thetime-domain flattening and provides performance improvement in the transient region."
목표 범주 선택과 미지정 범주에 대한 기계 학습을 통한 프로그래밍 언어 식별 기술,2025,"['Programming Language Identification', 'Source Code Classification', 'Machine Learning', 'Unknown Category', 'Target Category']",,"This paper presents a method for an efficient programming language identification technique which consists of selection of target categories and machine learning for unknown category. As software development scales are complicated, the source codes in use are getting huge and diverse. A programming language identification technique is essential to manage source codes effectively. However, existing research lacks a clear rationale for target categories selection criteria and does not address the issue of unknown categories.In this paper, we propose a method for selecting target categories based on frequency of use and importance, and machine learning techniques to handle unknown categories. We present three methods for classifying the unknown categories. Experimental results demonstrate that the proposed methods effectively classify the unknown categories."
RGB 기반 생육지수와 기계학습 모델을 활용한 벼 엽면적지수 평가,2025,"['leaf area index', 'leaf area', 'machine learning', 'rice', 'vegetation indices']",,"Recently, the agricultural sector has embraced digital technologies to improve crop growth monitoring, aiming to boost efficiency and reduce labor. In rice, leaf area is closely related to photosynthesis and yield. However, traditional measurements tend to be destructive and LAI-based methods could be costly or constrained by environmental factors. To address this problem, two medium-late rice cultivars were grown, and nadir RGB images were acquired from tillering to panicle initiation.Seven vegetation indices were derived from the R, G, and B channels, and Otsu’s algorithm was used to segment rice from the background. Various machine learning models (e.g., Random Forest and eXtreme Gradient Boosting), followed by the predicted leaf area index, validated by destructive (LI-3100) and LAI measurements. During tillering, both index-based and machine learning methods surpassed 0.98 classification accuracy, with ExG, MExG, and CIVE strongly correlating with the measured leaf area. However, leaf morphology changes and shading after panicle initiation reduced accuracy, although the actual leaf area comparisons remained more reliable than LAI. Taken together, this study demonstrates the usefulness of RGB imagery for rapid and non-destructive rice growth assessment and highlights its potential for real-time field monitoring and automated precision agriculture."
기계학습을 활용한 3차원 적층제조용 알루미늄 합금 개발,2025,"['Directed Energy Deposition (DED) Additive Manufacturing', 'Machine Learning', 'Variational Auto Encoder(VAE)', 'Process Design', 'Property Prediction']",,"The present study introduces a machine learning approach for designing new aluminum alloys tailored for directed energy deposition additive manufacturing, achieving an optimal balance between hardness and conductivity. Utilizing a comprehensive database of powder compositions, process parameters, and material properties, predictive models—including an artificial neural network and a gradient boosting regression model, were developed. Additionally, a variational autoencoder was employed to model input data distributions and generate novel process data for aluminum-based powders. The similarity between the generated data and the experimental data was evaluated using K-nearest neighbor classification and t-distributed stochastic neighbor embedding, with accuracy and the F1-score as metrics. The results demonstrated a close alignment, with nearly 90% accuracy, in numerical metrics and data distribution patterns. This work highlights the potential of machine learning to extend beyond multi-property prediction, enabling the generation of innovative process data for material design."
순서의존 패밀리 셋업시간이 존재하는 단일기계 일정계획 문제에서 총 납기지연 최소화를 위한 강화학습 모델,2025,"['Single machine scheduling', 'Reinforcement learning', 'Total tardiness', 'Family setup time', 'Policy network']","본 논문은 순서 의존적인 패밀리 셋업 시간이 존재하는 단일기계 스케줄링 문제에서 총 지연 시간을 최소화하는 것을 목표로 한다. 이를 위해 트랜스포머 기반 정책 네트워크를 활용한 최신의 엔드 투 엔드 강화학습 알고리즘을 제안한다. 제안된 네트워크는 두 가지 유형의 토큰을 사용한다. 첫 번째는 각 작업의 처리 시간, 납기일, 계열 설정 시간 등 작업에 대한 정보를 담은 작업 토큰이며, 두 번째는 초기 작업 선택의 최적화를 위해 설계된 특수 토큰이다. 계산 실험 결과, 제안된 강화학습 알고리즘은 기존의 진화 알고리즘 및 정확 알고리즘 대비 해의 품질과 계산 시간 면에서 모두 우수한 성능을 보였다. 또한, 일반화 실험을 통해 특정 크기의 인스턴스로 학습한 모델이 다양한 크기의 문제에 대해서도 최소한의 미세 조정만으로 효과적으로 적용될 수 있음을 입증하였다.","In this paper, we address the single machine scheduling problem with sequence-dependent family setup times, aiming to minimize total tardiness. We propose a state-of-the-art end-to-end reinforcement learning (RL) algorithm that learns a constructive heuristic through a transformer-based encoder-decoder network. The encoder processes two types of input tokens: job tokens, which encapsulate job-specific attributes such as processing time, due date, and family setup times, and a special token, designed to optimize the selection of the initial job. In the decoder, jobs are sequentially selected by a stochastic policy in an autoregressive manner, constructing the processing sequence step by step. Computational experiments demonstrate that the proposed RL algorithm outperforms evolutionary and exact methods, in both solution quality and computation time. Furthermore, a generalization study shows that an RL model trained on specific instance sizes can effectively solve problems of varying sizes with minimal fine-tuning."
기계학습을 활용한 인수합병과 성과 간의 관계에 대한 재고찰: 10-K 연간 보고서를 기반으로,2025,"['인수합병', '토픽모델링', '10-K 보고서', '자원 관련성', '누적비정상수익률', '머신러닝', 'Merger and Acquisitions', 'Topic Modeling', '10-K Report', 'Resource Relatedness', 'Cumulative Abnormal Returns', 'Machine Learning']","그동안 인수합병 기업 간 자원 관련성이 인수합병 성과에 미치는 영향과 관련하여 다양한 연구가진행되어 왔다. 그러나 이러한 연구들은 자원 관련성 측정의 적절성, 신뢰성, 포괄성 측면에서 다양한문제점을 노출해왔다. 본 연구에서는 10-K 보고서의 비구조화된 텍스트를 데이터로 활용하여 이러한문제점을 해결하고자 하였다. 보다 구체적으로 10-K 보고서를 기반으로 토픽모델링과 전문가 집단의평가를 통합하여 자원 관련성을 측정하고 이러한 자원 관련성이 인수합병 성과에 미치는 영향을파악하고자 하였다. 이를 위해 269개의 미국의 상장 기업 간 인수합병 공고와 해당 인수합병에 포함된기업의 10-K 보고서를 분석하였다. 분석결과 제품 및 시장 자원 관련성과 경영 자원 관련성 모두기업 성과에 부정적인 영향을 미치는 것을 파악하였다. 이는 자원 유사성을 강조한 기존 연구와 달리자원의 비유사성이 인수합병 성과를 높인다는 연구결과와 일치한다. 본 연구는 머신러닝 기법을활용하여 비구조화된 데이터로부터 자원 관련성 측정방법을 제시함으로써 표준분류체계와 같은전통적인 분류 기반 접근법의 한계를 극복하고 이를 기반으로 인수합병 성과에 대한 보다 정밀한이해를 제공하였다는 점에서 학문 및 실무적 의의가 있다고 할 수 있다.","Previous research has extensively explored the impact of resource relatedness between merging firms on M&A performance. However, these studies have revealed various issues concerning the appropriateness, reliability, and comprehensiveness of resource relatedness measurements. This study seeks to address these challenges by using unstructured text data from 10-K reports. In particular, it employs a combination of topic modeling and expert evaluations to measure resource relatedness, and investigates its effect on M&A performance. The analysis includes 269 merger announcements among publicly listed U.S.firms and the corresponding 10-K reports of the firms involved. The results indicate that both product and market resource relatedness and managerial resource relatedness negatively affect M&A performance.These findings align with studies highlighting the benefits of resource dissimilarity, in contrast to prior research emphasizing resource similarity. By introducing a machine learning approach to measure resource relatedness from unstructured data, this study enhances the understanding of M&A performance and overcomes the limitations of traditional classification-based approaches."
탄소중립이행을 위한 기계학습 기반의 전력수요예측 방법론 고도화 연구,2025,"['Electricity Demand Forecast', 'Machine Learning', 'Quantile Regression', 'XGBoost', 'Random Forest', 'Composite Variation Method']",,"As concerns over climate change and greenhouse gas emissions intensify, carbon neutrality has emerged as a critical global goal. Achieving this goal requires accurate electricity demand forecasting, which plays a pivotal role in maintaining grid stability and managing the variability of renewable energy.However, traditional models that focus on the mean often fail to capture the complexity of modern electricity demand patterns. To address this issue, this study proposes the Composite Variation Method(CVM) based on quantile regression. This approach reduces the bias in mean-based electricity demand forecasts and provides higher accuracy, particularly in scenarios with outliers or complex conditions.The CVM is applied to Random Forest and XGBoost models using hourly electricity demand data from Ontario, Canada. The results demonstrate a 9.75% performance improvement for Random Forest and a 1.31% improvement for XGBoost. These findings suggest that CVM enhances the precision of electricity demand forecasting, contributing to more effective energy management strategies essential for carbon neutrality."
“中文+”背景下基于机器学习的文本分类研究— 以能源动力与材料专业文本为例,2025,"['机器学习，自动文本分类，计算语言学，“中文+”，能源动力与材料', 'Machine learning', 'Automatic text classification', 'Computational linguistics', '“Chinese +”', 'Energy power and materials']",,"Overseas employees of Chinese energy enterprises face language barriers. Building a Chinese professional vocabulary database can relieve the language pressure of enterprise employees. Text classification technology is the prerequisite for building a vocabulary database. This study selected 650,000 words of professional texts in the field of energy power and materials under the classification of vocational education, extracted text features using the TF-IDF algorithm and the BOW bag-of-words model, and compared the accuracy (Precision), recall (Recall), and F1 index of the four algorithms of support vector machine (SVM), decision tree (DT), naive Bayes (NB) and K-nearest neighbor (KNN) in the classification of energy power and materials professional texts. The comparison shows that after using the BOW+SVM model framework to classify the ferrous metal material category text, the accuracy rate, recall rate and F1 index of 97.6%, 98.4% and 98% were obtained, which are better than other categories. The results show that the BOW+SVM model text classification framework is helpful for the construction of the energy power and materials professional vocabulary database, and combined with Chinese teaching to break the language barrier between English and Chinese for overseas employees of energy enterprises and promote the development of “Chinese+”."
기계학습 기반의 충청남도 소방본부 구조현황 분석에 관한 연구,2025,"['Structure Status', 'Disaster Response', 'Importance Analysis', 'Machine Learning', 'Random Forest']","소방대상물의 대형화 및 복합화 추세에 따라 다양한 형태의 재난이 발생하고 있다. 이에 소방 관련 활동도 화재, 구조 및 구급 이외에 자연재해, 사회 재난 복구, 벌집 제거, 동물구조 등 국민 안전 지원 활동으로 확대되어 왔다. 소방청 통계 연보에 따르면 119 구조대의 구조 건수는 연평균 5.0%의 지속적인 증가세를 보이고 있다. 이에 효율적인 구조활동을 위해 현장 대응 활동에 영향을 미치는 다양한 요인들에 대한 분석을 통해 제도적 개선이 요구되고 있다. 이에 본 논문에서는 충청남도 구조활동에 관한 정량적 데이터를 활용하여 구조활동에서 일 단위의 구조 건수에 영향을 미치는 사고원인, 사고장소, 소방서 거리, 현장 도착 시간, 계절, 요일 등 요인의 상관관계와 유의확률을 분석하고, 기계학습 기반의 중요도 분석 방안을 제안한다. 이를 통해 구조활동 현장에서 빅데이터 기반의 과학적 현장 대응 활동 지원 방안의 근거를 제시하고자 한다. 실험 결과에서 랜덤포레스트 모델의 성능은 평균제곱오차로 0.0004418948를 보였다. 그리고, 구조 건수에 영향을 미치는 주요 요인의 중요도는 도시농촌 구분에서 농촌, 사고원인 구분에서 벌집 제거, 사고장소 구분에서 단독주택, 도시농촌 구분에서 도시, 사고장소 구분에서 기타의 순으로 분석되었다.",
고령자의 Aging in Place를 위한 주거환경 만족도 영향요인 분석 : 기계학습 및 Impact Asymmetry Analysis 방법론을 활용하여,2025,"['Residential Environment Satisfaction', 'Aging in Place', 'Machine Learning', 'Impact Asymmetry Analysis', '주거환경 만족도', '지역사회 계속 거주', '기계학습', '비대칭 영향 분석']","본 연구의 목적은 다음과 같다. 첫째, 연령대별로 비교를 위해 성인, 전기노인, 후기노인으로 연령대를 구분하여 주거환경 만족도에 영향을 미치는 근린환경 요인을 기계학습(Machine learning) 방법을 활용하여 상대적 중요도를 파악한다. 이를 통해 연령 증가에 따른 주거환경 만족도에 영향을 미치는 요인의 구조적 차이를 규명하고자 한다. 둘째, 기계학습 방법을 통해 도출된 영향요인을 기반으로 IAA 방법을 적용하여 주거환경 만족도에 대한 근린환경 속성별 비대칭적 영향을 실증적으로 분석하고자 한다. 셋째, 근린환경 속성의 상대적 중요도와 비대칭성 분석 결과를 종합하여, 고령자의 주거환경 만족도 향상을위해 정책적으로 우선 강화해야 할 요소를 구체적으로 제시하고자 한다. 이를 통해 고령자의 AIP를 실현하는 데에 기여할 수 있는 실질적 정책 방향을 제시하는 것을 최종 목표로 한다. 따라서연구는 <그림 1>과 같은 흐름으로 진행되었으며, 연구의 배경과목적을 바탕으로 2장에서는 AIP 이론과 주거환경 만족도에 관한이전의 연구에 대해 고찰한다. 그리고 3장에서는 본 연구의 분석에 사용한 데이터와 방법론에 대해 설명하고, 4장에서는 기계학습을 통한 상대적 중요도를 산출하고 IAA 방법론을 통하여 주거환경 만족도에 관한 비대칭적 영향에 관한 분석 결과를 도출한다. 마지막으로 5장에서는 앞선 결과를 바탕으로 정책적 시사점을 제시함과 동시에 결론을 맺는다.","Aging in Place (AIP) has become a fundamental approach in global welfare policies for older people, reflecting their natural desire to remain in familiar homes and neighborhoods as their health and functionality decline. AIP is not only aimed at enhancing individual well-being and quality of life but it is also viewed as a solution to support sustainable development in aging societies. For AIP to be successful, it is essential that older people are highly satisfied with their residential environment, which plays a critical role in its sustainability. This study focused on individuals ≥65 years old, in Korea, aiming to identify the key neighborhood environment factors that influence residential satisfaction. Using the Gradient Boosting Decision Tree algorithm, the relative importance of various factors was determined, followed by an Impact Asymmetry Analysis to assess their asymmetric effects on satisfaction. The factors were categorized into five types: Frustrator, Dissatisfier, Hybrid, Satisfier, and Delighter. The results revealed that satisfaction with housing significantly influenced residential environment satisfaction across all age groups. Additionally, for older age groups, the safety and crime prevention factor was identified as a key area for improving residential environment satisfaction. This study provides important policy implications for enhancing the residential satisfaction and quality of life of older people in Korea."
기계학습 기반 비선형 전력 수요 패턴 KNN 모델링,2025,"['k-최근접 이웃', '지능형 네트워크', '스마트 그리드', '자동 미터 판독', 'KNN', 'intelligent network', 'Smart grid', 'AMR']","스마트 그리드는 전기 공급 업체와 소비자 간의 양방향 통신을 가능하게 하는 새로운 패러다임이다. 기존 방법은단기 의존성을 처리하는 데만 유용하기 때문에 비선형 전력 수요 패턴의 모델링과 관련해서는 상당 부분 취약하다. 또한기존 방법은 순전히 기록 데이터 기반이기 때문에 특성상 정적이고 스마트 미터기 오작동, 잡음과 같은 이상값이 상당부분 포함되어 있어서 예측 성능이 매우 미흡하다. 이에 본 연구에서는 두 가지 기본 모델로서 하나는 모수 통계의 대표적인 회귀 학습 모델과 다른 하나는 전형적인 비모수 통계적 접근이라 할 수 있는 KNN 학습 모델로 시작해서 스마트미터 데이터와 같은 시계열 데이터의 경우에 샘플 데이터의 독립성이라는 측면을 고려하면, 오히려 비모수적 접근 방식인 KNN 학습에 의한 성능이 본 연구의 실험 결과 확인된다.","Smart grid is a new paradigm that enables two-way communication between electricity suppliers and consumers. Existing methods are largely weak when it comes to modeling nonlinear power demand patterns, as they are only useful for handling short-term dependencies. Additionally, because existing methods are purely based on historical data, they are static in nature and contain a significant amount of outliers such as smart meter malfunctions and noise, so their prediction performance is very poor. Accordingly, in this study, we start with two basic models, one is a regression learning model that is representative of parametric statistics and the other is a KNN learning model that can be considered a typical non-parametric statistical approach. In the case of time series data such as smart meter data, we start with the independence of sample data. Considering this aspect, the performance of KNN learning, which is a non-parametric approach, is confirmed by the experimental results of this study"
네트워크 공격 탐지 기계 학습 모델의 성능 향상을 위한 데이터 증강 방법에 대한 연구,2025,"['Network Intrusion Detection', 'Data Augmentation', '네트워크 이상 탐지', '데이터 증강']","사이버 보안 환경의 급격한 변화에 따라서 시그니처가 존재하지 않는 제로데이 공격을 탐지하기 위한 여러 가지 기계 학습 모델이 개발되고 있다. 그러나, 대부분의 공격 탐지 모델 혹은 이상 탐지 모델의 개발에 필요한 공격 데이터가 부족한 것이 걸림돌로 작용하고 있다. 이러한 문제를 해결하기 위해서 본 논문에서는 소수 클래스의 샘플을 합성하여 새로운 데이터를 생성하는 과대표집 (oversampling) 기법 중 하나인 SMOTE(Synthetic Minority Oversampling Technique)와 비교사 학습 모델인 오토인코더 (Autoencoder)로 소수 클래스의 샘플을 증강 시키는 실험을 진행했다. 2가지 방법으로 증강한 데이터를 각각 랜덤 포레스트 (Random Forest), 로지스틱 회귀 (Logistic Regression) 및 경랑 GBM (Light Gradient Boosting Model)의 3가지 기계 학습 모델에 적용하였다. 그 결과 이진 데이터 셋으로 실험을 진행한 결과에서는 경량 GBM과 오토인코더를 결합한 모델이 가장 좋은 성능 향상을 보여주었다. 정확도는 0.935에서 0.999로 향상되었고, 오탐율은 065에서 0.001로 감소되었으며, 미탐율은 0.064에서 0.001로 감소했다. 다중 클래스 데이터 셋으로 실험을 진행한 결과에서는 로지스틱 회귀와 오토인코더를 결합한 모델이 정확도는 0.849에서 0.960으로 증가하였고, 오탐율은 0.151에서 0.040, 미탐율은 0.177에서 0.039로 감소하여 가장 우수한 성능을 보여주었다.","Due to the rapid changes in the cyber security landscape, various machine learning models have been developed to detect zero-day attacks, which lack predefined signatures. However, a significant obstacle in developing attack detection or anomaly detection models is the lack of sufficient attack data. To address this issue, this study conducted experiments to augment minority class samples using SMOTE (Synthetic Minority Oversampling Technique), an oversampling method, and Autoencoder, a contrastive learning model. The augmented data were applied to three machine learning models: Random Forest, Logistic Regression, and Light Gradient Boosting Model (LightGBM). The experiments using binary datasets demonstrated that the combination of LightGBM and Autoencoder showed the most significant performance improvement. Accuracy improved from 0.935 to 0.999, the false positive rate (FPR) decreased from 0.065 to 0.001, and the false negative rate (FNR) dropped from 0.064 to 0.001. On the other hand, experiments using multi-class datasets revealed that the combination of Logistic Regression and Autoencoder achieved the best performance. Accuracy increased from 0.849 to 0.960, FPR decreased from 0.151 to 0.040, and FNR dropped from 0.177 to 0.039."
한국어 학습자 쓰기 숙달도 자동평가를 위한 언어 자질 연구-어휘 관련 자질을 중심으로-,2025,"['한국어교육(Korean Language Education)', '쓰기(Writing)', '자동평가(Automated Assessment)', '언어 자질(Linguistic Feature)', '자질 설계(Feature Engineering)']",,"This study investigates and validates lexical features for the automated assessment of Korean learners’ writing proficiency. Using Korean Language learners’ corpus (n=14,992), features were extracted across five categories: lexical diversity, lexical density, lexical difficulty, morpheme usage, and text length. Pearson correlation analysis demonstrated statistically significant correlations between these  features and learner proficiency levels. Classification models using Random Forest and XGBoost were trained to evaluate predictive performance. Lexical difficulty and morpheme usage emerged as the most effective predictors, with features such as the number of Level 4 vocabulary types, the ratio of Level 1 words, and sentence-final endings showing high importance. Combining all feature types, the integrated model achieved 87.9% accuracy with the XGBoost model, outperforming individual models and confirming that lexical difficulty and grammatical complexity are key indicators in automated writing assessment. This research highlights the potential of linguistic features in developing reliable, high-accuracy machine learning models for assessing second language writing proficiency."
기계학습 알고리즘을 활용한 관광지역 렌터카 교통사고 심각도에 미치는 영향요인 분석,2025,"['렌터카 교통사고', '사고심각도 분석', '기계학습', '랜덤포레스트 회귀분석', 'SHAP 분석', 'Rental Car Crash', 'Crash Severity Analysis', 'Machine Learning', 'Random Forest Regression', 'SHAP']",,"Purpose: This study aims to analyze the key factors influencing the severity of rental car crashes in Jeju Special Self-Governing Province, where the rental car usage rate is high, and propose systematic measures to reduce crash severity. To achieve this, a crash severity analysis model was developed using machine learning techniques. Method: Data on rental car crashes in Jeju Special Self-Governing Province from 2018 to 2022 were analyzed using XGBoost, Decision Tree, and Random Forest models. Random Forest was identified as the optimal model, and SHAP analysis was employed to derive the feature importance of variables. Result: The Random Forest model demonstrated the highest perfor- mance. The feature importance analysis revealed that the most significant factors influencing crash severity were crash type, with “vehicle-pedestrian collisions”(0.2132169) and “vehicle-to-vehicle collisions”(0.150534) having the highest impact. Among traffic violations, “failure to drive safely” (0.145027) and “center line violations”(0.097202) were identified as critical factors. Additionally, the “intersection” road type (0.049608) was a significant factor. Environmental conditions such as rainy weather, nighttime, specific days(Sunday and Thursday), and seasons (autumn and summer) also increased crash severity. Conclusion: To reduce rental car crash severity, implementing a tailored vehicle rental system, expanding traffic safety infrastructure, and strengthening measures to prevent traffic violations are essential. Future research should expand the analysis scope and evaluate the effectiveness of policies to derive actionable and effective improvement strategies."
멀티모달 대규모 언어모델과 기계학습을 활용한 도시 가로 경관 쇠퇴 영향요인 분석,2025,"['도시 쇠퇴경관', '가로경관 이미지', '멀티모달 대규모 언어모델', '기계학습', '주관적 인식', 'Urban Landscape Decline', 'Street View Image', 'Multi-Modal Large Language Model', 'Machine Learning', 'Subjective Perception']","본 연구에서는 가로경관 이미지를 기반한 주관적 쇠퇴경관 설문조사 자료를 활용하여 쇠퇴경관에 대한 인간의 인식과이에 영향을 미치는 물리적 환경요인을 분석하고자 한다. 또한, 본 연구를 통해 서울시 쇠퇴경관 저감과 스마트 도시계획 및 관리에 기여할 수 있는 정책적 시사점을 도출하고자 한다. 이를 위해본 연구의 흐름은 <그림 1>과 같이 진행되며, 세 가지의 분석 내용을 설정하였다. 먼저, 쇠퇴경관에 대한 인간의 주관적 인식을 정량적으로 추출하기 위해 가로경관 이미지를 활용하여 이미지 쌍별 비교 설문조사를 진행하고 Trueskill 알고리즘을 적용하였다.다음으로 의미론적 분할(Semantic Segmentation)과 멀티모달 대규모 언어모델(Multi-Modal Large Language Model, MLLM)을통해 물리적 환경요인의 비율(Quantity)과 상태(Quality) 점수를도출하였다. 마지막으로 기계학습과 해석가능한 기계학습을 사용하여 쇠퇴경관에 대한 인간의 주관적 인식과 물리적 환경요인 간의 비선형적 관계를 분석하여 정책적 시사점을 도출하였다.","Cities are constantly evolving, with growth, vitality, decline, and shrinkage occurring as interrelated phenomena.While urban vitality and revitalization have been extensively studied, research on urban decline and shrinkage remains comparatively limited. Existing studies on urban decline have primarily focused on diagnostic indicators, such as physical aging, population decline, and reduction in the number of businesses, to assess patterns of decline. However, studies on the subjective perception of urban decline, particularly in relation to urban landscapes, remain limited. Given this gap, it is crucial to identify the causes of urban decline by analyzing the factors that influence the public perception of declining landscapes through subjective evaluations of urban scenery. This study quantitatively analyzes how people perceive declining urban landscapes and identifies the key factors that influence these perceptions, using street view images of Seoul. A survey was first conducted to assess urban landscape decline based on streetscape images. The Trueskill algorithm was applied to quantify perceived level of decline. Subsequently, machine learning was used to analyze the primary factors influencing these perceptions. The results of the analysis are as follows. First, perception of decline decreased as the proportion of physical environmental elements such as roads, green spaces, sidewalks, and cars increased. In contrast, an increased presence of elements such as buildings, bicycles, walls, and fences was associated with a heightened perception of urban decline. Second, an analysis of the importance of contributing factors indicated that roads, sidewalks, green spaces, and cars were the most influential in shaping perception, in that order. Third, the relationship between the proportion of physical environmental elements in urban landscape images and perceptions of decline was found to be non-linear. This study presents a methodology for evaluating urban landscape decline based on people's subjective perceptions and provides policy implications by identifying the streetscape features that substantially influence perceptions of urban decline."
항공기의 연료소모량에 영향을 미치는 요소에 관한 연구: 랜덤포레스트 기법을 이용하여,2025,"['항공사', '비행계획', '연료소모량', '연료관리', '랜덤포레스트', 'Airline', 'Flight Plan', 'Fuel Consumption', 'Fuel Management', 'Random Forest']",,"This study systematically analyzed the key factors affecting aircraft fuel consumption using arandom forest regression model based on 1,034 operational samples and 8 predictive variables.The model was validated through 10-fold cross-validation, and hyper parameter tuningidentified mtry =5 as the optimal setting. Variable importance analysis revealed that flightdistance(41.9%) and payload(24.8%) were the most influential factors, followed by temperature,speed, wind, altitude, speed, and airplane performance monitoring system. The model achievedan RMSE of 501.52, an R ² of 0.601, and an MAE of 358.09 on the test set, indicating stableperformance and demonstrating that distance and payload are the primary determinants of fuelconsumption in commercial aviation. This framework supports ICAO’s roadmap by transformingraw operational data into actionable insights, empowering airlines to minimize costsand emissions concurrently."
기계학습 및 네트워크분석을 통한 도시침수 발생으로 인한 피해예측 및 대책제안 연구 (II) - 네트워크 분석을 활용한 도시의 대응능력 분석 -,2025,"['urban flooding', 'network analysis', 'disaster response', '-']",,"Urban flooding has become increasingly frequent and often more severe due to heavy rainfall, with formerly rural areas butting up against the expanding impermeable surfaces resulting from urbanization. Previous studies addressing this problem have focused on flood prediction methods and risk analysis. Still, they have typically faced limitations when formulating response strategies before and after flood events. This study utilizes network analysis to quantitatively evaluate the response capabilities of administrative districts in Gwanak-gu, Seoul, South Korea. Key metrics, including accessibility, vulnerability, and response capability, were selected, defined, and applied to assess the performance of buildings and major facilities based on specific distance criteria. The results from this study indicate that accessibility increases along with longer distance thresholds, with most districts featuring distances that converge within the range of 700 to 1,700 meters. Conversely, vulnerability decreases over longer distances or stabilizes at certain levels, reflecting the degree of functional disconnection provoked by flooding. On the one hand, districts with high response capabilities exhibit optimized facility placement and road networks, ensuring sturdy connectivity, even during flooding. On the other hand, districts with low response capabilities suffer from insufficient nexuses with major facilities, rendering disaster response particularly challenging. This study evaluates urban flood response capabilities and draws attention to areas for improvement that reinforce and intensify flood response infrastructure. Future research might incorporate disparate disaster scenarios and multi-network analyses to further refine urban disaster response assessments"
설명 가능 인공지능 모델을 이용한 서리/안개 블랙아이스 예측 및 블랙아이스 영향 대기기상 요소 분석(랜덤 포레스트 및 XGBoost 모형을 중심으로),2025,"['Black Ice', 'Random Forest', 'Extreme Gradient Boost', 'Explainable Artificial Intelligence']",,"Given the hazards posed by black ice, it is crucial to investigate the conditions that contribute to its formation. Two ensemble machinelearning algorithms, Random Forest (RF) and Extreme Gradient Boosting (XGBoost), were employed to forecast the occurrence of black ice using atmospheric data. Additionally, explainable artificial intelligence techniques, including Feature Importance (FI) and partial dependence Plot (PDP), were utilized to identify atmospheric conditions that significantly increase the likelihood of black ice formation. The machinelearning algorithms achieved a forecasting accuracy of 90%, demonstrating reliable performance. FI analysis revealed distinct key predictors between the algorithms: relative humidity was the most critical for RF, whereas wind speed was paramount for XGBoost. The PDP analysis identified the specific atmospheric conditions under which black ice was likely to form. This study provides detailed insights into the atmospheric precursors of frost/fog-induced black ice formation. These findings enable road managers to implement proactive winter road maintenance strategies, such as optimizing anti-icing patrol routes and displaying warnings on various message signs, thereby enhancing road safety."
인공지능 데이터 학습 기법의 일반화 성능 분석에 관한 연구,2025,"['인공지능', '학습 기법', '컴퓨터 비전', '자연어 처리', '머신러', 'Artificial Intelligence', 'Learning Technique', 'Computer Vision', 'Natural Language Processing', 'Machine Learning']","데이터 부족은 머신러닝과 인공지능 분야의 중요한 문제이다. 다양한 데이터는 모델의 정확도를 향상시키고 일반화 능력을 강화하는 데 필수적이다. 데이터가 부족하면 과적합, 성능 저하, 클래스 불균형, 새로운 클래스나 개념 학습의 어려움과 같은 다양한 문제가 발생할 수 있다. 데이터양의 적은 환경에서 전통적인 지도 학습 방식의 문제를 해 결하기 위해 One-Shot Learning, Few-Shot Learning, Zero-Shot Learning과 같은 학습 기법이 개발되었다. 이러한 접근 법은 모델이 극히 제한된 수의 예시 또는 전혀 예시 없이 새로운 작업이나 클래스를 학습할 수 있게 하는 것을 목표로 하며, 인공지능 모델이 인간의 학습 능력에 더 가까워질 수 있도록 하는 중요한 단계를 나타낸다. 본 논문에서는 데이 터가 부족하거나 새로운 클래스가 지속적으로 등장하는 상황에서 학습 방법이 어떻게 중요한 역할을 할 수 있는지 비 교 분석하였다","Data scarcity is a major problem in the field of machine learning. A variety of data is essential to improve the accuracy of the model and enhance the generalization ability. A lack of data can cause various problems such as overfitting, performance degradation, class imbalance, and difficulty in learning new classes or concepts. To solve the problems of traditional supervised learning methods in an environment with a small amount of data, learning techniques such as One-Shot Learning, Few-Shot Learning, and Zero-Shot Learning have been developed. These approaches aim to enable models to learn a new task or class with a very limited number of examples or no examples at all, and represent an important step in bringing artificial intelligence models closer to human learning capabilities. In this paper, we compare and analyze how learning methods can play an important role in situations where data is insufficient or new classes continuously appear."
포르투갈어 기계번역 사용에 대한 한국인 학습자의 인식 연구,2025,"['Portuguese', 'Machine translation', 'Translators', 'Korean learners', 'Teaching-Learning strategies', '포르투갈어', '기계번역', '번역기', '한국인 학습자', '교수-학습전략']","본 연구의 주요 목적은 포르투갈어를 공부하는 한국인 학습자가 포르투갈어 기계번역에 대하여 어떠한 인식을 가지고 있는지 살펴보고, 이를 통해 교육적으로 고려해야 할 부분을 찾는 것이다. 이를 위해 포르투갈어 전공 대학생들을 대상으로 번역기 사용의 현황, 번역기 사용 만족도, 번역기 사용 필요성 및 번역기 사용의 장단점에 대한 설문조사를 실시하고, 그 내용을 분석하여 포르투갈어 교육에서 교수자와 학습자가 이용 가능한 전략에 대하여 살펴보았다. 학습자들이 가장 많이 사용하는 번역기는 구글 번역이고, 번역기 사용이 학습에 확실히 도움은 되지만, 실력향상으로 이어지지 않을 수 있다는 우려도 표출하였다. 모르는 것, 불확실한 것을 빠르고 간편하게 해결할 수 있다는 점에서 대다수의 학습자들은 번역기 사용이 필요하다고 인식하고 있다. 반면, 학생들은 번역기에 대한 잦은 의존성으로서 인해 실력향상에 저해가 될 수 있고, 부정확한 번역결과에 대처하기 어려울 수도 있다. ‘의존성’과 ‘정확성’, 두 가지 이슈의 양면성에 대하여 학습자들의 올바른 인식과 활용이 요구된다. 기계번역은 시간적, 공간적 환경의 제한 없이 이용가능하다. 사용 편의성과 성능은 이미 학습에 훌륭한 보조 도구 역할을 하고 있다. 하지만 번역의 결과물에 대해선 오류가 있는지 검토하는 과정이 꼭 필요하다. 자신의 작문과 기계번역의 작문을 비교하여 발견되는 오류를 수정하는 과정은 외국어 학습에 매우 도움이 된다. 교수자가 수정된 결과물에 대한 전체적인 피드백을 해주고, 학습자가 그 피드백을 확실하게 습득해 나간다면 효과적인 학습으로 이어질 것이다. 나아가 이런 과정의 반복을 통해 학습자는 좀 더 자기 주도적이고 비판적인 학습자로 성장할 수 있다.","The main purpose of this study is to examine what perceptions of Portuguese machine translation Korean learners of Portuguese have, and to find areas that should be considered in education. To this end, a survey was conducted on university students majoring in Portuguese on the current status of, satisfaction with, necessity of, and advantages and disadvantages of machine translation use. The results were analyzed to examine strategies that teachers and learners can use in Portuguese education. The most commonly used machine translation tool by learners is Google Translate, and although machine translation certainly helps learning, they also expressed concerns that it may not lead to skill improvement. Most learners recognize the need to use machine translation tools because they can quickly and easily resolve things they do not know or are uncertain about. On the other hand, students may have difficulty dealing with inaccurate translation results due to their frequent dependence on machine translation tools, which may hinder their skill improvement. Learners are required to correctly recognize and use the two sides of the two issues of “dependence” and “accuracy”. Machine translation can be used without limitations in time and space. Ease of use and performance are already excellent aids to learning. However, it is essential to review the translation results for errors. The process of comparing your own writing with the machine translation and correcting the errors found is very helpful for learning a foreign language. If the professor provides overall feedback on the corrected results and the learner acquires that feedback, it will lead to effective learning. Furthermore, through repetition of this process, the learner can grow into a more self-directed and critical learner."
강화학습을 이용한 하천 녹조 발생 저감 모형 연구,2025,"['Algal bloom management', 'Explainable artificial intelligence', 'Machine learning', 'Water quality management', '녹조 관리', '설명가능한 인공지능', '머신러닝', '수질 관리']","과도한 조류 발생은 취수원 안전성 및 수생태 환경에 부정적인 영향을 미칠 수 있어 적극적인 관리가 필요하며, 최근 머신러닝 등 다양한 인공지능 기반 기술을 조류 관리에 적용하기 위한 연구가 지속되고 있다. 머신러닝은 학습 방법에 따라 지도학습, 비지도학습 및 강화학습으로 구분할 수 있으며, 다양한 지도학습 모형 등을 활용한 조류 발생의 예측 모형의 개발 등이 활발히 이루어지는 것과 다르게 강화학습 모형을 적용하는 연구는 아직 그 사례가 제한적이다. 본 연구에서는 이러한 강화학습을 이용하여 하천 조류 농도 저감을 위한 모형을 구축하였다. 모형의 입력자료로는 현장에서 측정된 다양한 수질 및 기상 인자를 활용하였으며, 조류 발생의 정량적 지표인 클로로필-a 농도를 저감하도록 강화학습 모형을 학습시켰다. 학습된 모형의 테스트 기간에 대해, 강화학습 적용 전후의 평균 클로로필-a 농도를 비교한 결과, 강화학습 적용을 통해 클로로필-a 농도가 개선됨을 확인하였으나 그 정도는 크지 않았다. 모형 결과에 대한 세부적인 해석을 위해 설명가능한 인공지능 기법의 대표적인 방법인 Shapley additive explanations analysis를 이용하여 강화학습 모형의 환경 구축에 활용된 변수들의 특성을 분석하고 향후 수질 관리 효율 향상을 위한 강화학습 모형의 적용 방향을 제시하였다.","Excessive algal blooms can negatively affect the safety of water intake sources and aquatic ecosystems, necessitating proactive management efforts. In recent years, research has increasingly explored the application of artificial intelligence (AI)-based technologies, including machine learning (ML), for algal bloom management. ML techniques can be broadly categorized into supervised learning, unsupervised learning, and reinforcement learning. While many studies have focused on developing predictive models for algal blooms using various supervised learning approaches, applications of reinforcement learning remain relatively limited. In this study, a reinforcement learning model was developed to reduce algal concentrations in a river. The model was trained using various water quality and meteorological variables measured in the field monitoring stations, with the objective of minimizing chlorophyll-a concentration, a quantitative indicator of algal blooms. An evaluation of average chlorophyll-a concentrations before and after applying reinforcement learning during the testing period revealed an improvement, although the degree of reduction was not substantial. To further interpret the model’s outcomes, Shapley additive explanations (SHAP), a representative explainable AI technique, was used to analyze the contributions of variables involved in the reinforcement learning environment setup. Based on these analyses, future directions for improving the efficiency of water quality management through reinforcement learning models are proposed."
딥러닝을 활용한 암석 분류 프레임워크:  터널 안정성 모니터링 및 유지관리를 위한 데이터 기반 접근 방식,2025,"['Deep learning', 'Rock classification', 'Tunnel stability', 'Geotechnical engineering', 'Machine learning', 'Maintenance']","터널은 도로, 철도, 지하 인프라 등 다양한 산업 분야에서 핵심적인 역할을 수행하며, 터널 안정성 확보는 경제적·사회적으로매우 중요한 과제이다. 이러한 터널의 안정석 확보를 위해서는 암반에 대한 이해가 필수적이며 이를 위해 기존에는 현장지질조사와 광물학적·지구화학적 분석 등을 통해 암석을 분류해왔으나, 이는 시간·비용 측면에서 비효율적이고 경험적판단에 의존하기 쉬운 한계가 있었다. 최근 빅데이터와 인공지능(AI) 기술, 특히 딥러닝(Deep learning)의 급속한 발전으로인해, 대규모 암석 이미지를 통해 복잡한 패턴을 자동으로 학습하고 분류할 수 있는 가능성이 열리고 있다. 본 연구에서는딥러닝을 활용한 암반 분류 프레임워크를 제안하고, 화성암·퇴적암·변성암을 비롯하여 여러 세분류 암석(예: 대리암, 사암, 편암 등)에 대해 다양한 딥러닝 모델을 적용·비교·평가하였다. 연구 결과, 대분류(3분류) 단계에서는 ResNet, EfficientNet, MobileNet 등에서 90% 이상의 높은 정확도를 달성하였으나, 18개 이상의 세분류로 확대할 경우 전반적으로 정확도가 급격히 떨어지는 현상이 관찰되었다. 이는 암석의 조직과 광물 조합이 매우 복잡하고, 클래스 간 경계가 모호해지는 점이 주요 원인으로 분석된다. 본 연구를 통해, 딥러닝 기반 암석 분류가 터널 안정성 모니터링 및 유지관리 분야에서 높은 잠재력을 지님을확인하였으나, 세분화된 암석 분류 정확도를 높이기 위해서는 추가 데이터가 요구됨을 확인할 수 있었다.","Tunnels serve a pivotal role in various infrastructure systems—including roads, railways, and underground facilities—and ensuring their stability is of critical economic and societal importance. Traditional rock classification methods often rely on on-site geological surveys and petrographic/chemical analyses, which can be time-consuming, cost-intensive, and prone to subjective judgments. With the recent advancement in big data and artificial intelligence (AI) technologies, particularly Deep Learning, it has become possible to automatically learn and classify intricate rock patterns from large-scale image datasets.In this study, we propose a deep learning-based rock classification framework and apply several state-of-the-art models— ResNet, EfficientNet, MobileNet, and others—to both broad categories (igneous, sedimentary, metamorphic) and more fine-grained rock types (e.g., marble, sandstone, phyllite). Our results show that while high accuracies exceeding 90% can be achieved for three-class problems, classification performance drops significantly when expanded to 18 or more subclasses, likely due to the complex microstructures and ambiguous boundaries among rock types. These findings highlight the substantial potential of deep learning in tunnel stability monitoring and maintenance, yet also underscore the necessity of hierarchical classification strategies, multimodal data integration (e.g., microscopic or hyperspectral imaging), and further hyperparameter optimization for more refined rock classification tasks."
외국인의 한국어 말하기 능력 향상을 위한 자동 채점 기능을 가진 디지털 게임 기반의 학습 애플리케이션,2025,"['Korean Language Learning Application', 'Automatic Scoring', 'Digital Game-based Learning', 'Content Management System', 'Real-time Pronunciation Evaluation', '한국어 학습 애플리케이션', '자동 점수화', '디지털 게임 기반 학습', '콘텐츠 관리 시스템', '실시간 발음 평가']","본 논문은 외국인의 한국어 말하기 능력 향상을 위해 개발된 auto-sKORing 학습 애플리케이션의 구현 성과를 다룬다. 주요 기능으로는 자동 점수화, 디지털 게임 기반 학습(DGBL), 콘텐츠 관리 시스템(CMS)이 포함된다. 개발한 애플리케이션은 음성 인식(STT) 기술과 문장 변환기 유사도 검사(Sentence Transformer Similarity Check) 기술을 결합하여 실시간 발음 평가 점수를 제공함으로써 학습자와 상호 대화식으로 발음 정확도를 향상시킬 수 있도록 지원한다. 그리고 디지털 게임 기반 학습 기능은 학습 단계별 게임 형태로  한국어를 학습할 수 있도록 지원하며, 자동  점수화 기능에 따른 학습 성과를 평가하여 다음 단계로 진입 여부를 결정한다. 마지막으로 콘텐츠 관리 시스템은 게임 단계별 학습 콘텐츠를 동적으로 관리할 수 있도록 지원함으로써 유연한 업데이트가 가능한 특징을 가진다. 제안 시스템은 Python, Flutter, React.js, FastAPI, MySQL을 활용하여 구축되었으며, 평균 응답 시간은 약 0.254초로 측정되어 원활한 실시간 피드백이 제공됨을 입증하였다. 향후에는 사용자 인터페이스(UI) 개선, 머신러닝 기반 자동 채점 모델, 대형 언어 모델(LLM)을 활용한 동적 문제 생성 기능이 추가될 예정이라 장기적인 몰입도와 지속적인 학습 기회를 제공할 수 있을 것으로 기대된다.","This paper presents the implementation results of the auto-sKORing learning application, developed to improve Korean speaking skills for foreigners. The core features include automatic scoring, Digital Game-Based Learning (DGBL), and a Content Management System (CMS). The application provides real-time pronunciation scores by combining Speech-To-Text (STT) and sentence transformer similarity check technologies, enabling users to improve pronunciation accuracy interactively. The DGBL feature supports Korean learning through stage-based games and evaluates performance via the scoring system to determine progression. Lastly, the CMS supports dynamic game content management, enabling flexible updates. The system was built using Python, Flutter, React.js, FastAPI, and MySQL, with an average response time of approximately 0.254 seconds, demonstrating effective real-time feedback. Future updates will include improved user interfaces, machine learning-based scoring models, and dynamic question generation using large language models (LLMs), which are expected to enhance long-term engagement and offer continuous learning opportunities."
의사결정트리 분류 모델을 활용한 산화 환원 반응 판단 프로그램이 고등학교 3학년 학생들의 학습에 미치는 효과,2025,"['산화 환원 반응', '머신러닝', '의사결정트리 분류 모델', '교육프로그램 개발', '고등학교 3학년 학생', 'Redox reaction', 'Machine learning', 'Decision tree classification model', 'Educational program development', '12th Grade students']","이 연구에서는 학생들이 산화 환원 반응의 본질을 이해하고 판단할 수 있도록 돕기 위해 머신러닝을 활용한 산화 환원반응 판단 프로그램을 개발하였다. 학생들은 전자 이동 모델, 산화수 변화 모델, 굿스테인 모델에 근거해 여러 화학 반응식에 대한 정보를 직접 생성하고, 이를 바탕으로 의사결정트리 분류 모델을 만들었다. 머신러닝이 분류에 오류를 나타낼 때, 의사결정트리를 통해 오류 발생 원인을 확인하여 학생들이 스스로 오개념을 수정하도록 하였고, 오개념 수정 과정을 분석하였다. 연구는고등학교 3학년 학생을 대상으로 총 18차시 동안 온라인 수업으로 진행되었으며, 프로그램의 효과를 알아보기 위해 학생들의 학업 성취도와 산화 환원 반응 모델 활용 태도, 인공지능 활용 수업에 대한 인식을 분석하였다. 연구 결과, 의사결정트리 분류 모델을 활용한 산화 환원 반응 판단 프로그램은 학생들의 학업 성취도를 향상시키고 오개념을 수정하는 데 효과적이었으며, 특히산화수 변화 모델과 굿스테인 모델에서 두드러진 성과를 보였다. 학생들은 학습이 진행될수록 '설명할 수 없다'는 응답 비율이 감소하며, 모델의 장단점과 제한 조건을 이해하고 상황에 따라 적절한 모델을 선택하여 화학 반응을 해석하는 모습을 보였다. 또한, 산화 환원 반응을 단순 암기나 계산에 중점을 두고 해석하는 태도를 수정하고, 화학 결합과 구조, 전기 음성도를 이해하며 과정적 관점으로 해석하는 태도가 형성되었다. 인공지능의 즉각적인 피드백은 학생들의 오류 수정 및 스키마 자동화에 기여하여학습 경험을 개선하였고, 학생들은 화학 학습에 있어 인공지능 도구를 활용하는 것에 대해 긍정적인 태도를 보였다. 이러한 결과는 본 연구에서 개발한 프로그램이 디지털·인공지능 기초 소양 함양에 기여하였음을 시사한다. 따라서 학생들이 쉽게 다룰 수있는 인공지능 도구를 활용한 화학 수업의 필요성이 강조되며, 교사는 학습의 안내자이자 촉진자로서 인공지능의 가능성과 한계를 균형 있게 이해하고 활용해야 할 것이다.","In this study, a machine learning-based redox reaction judgment program was developed to help students understand and assess the nature of redox reactions. Students directly generated information on various chemical equations based on the electron transfer model, oxidation number change model, and Goodstein model, and created a classification model using a decision tree algorithm based on this information. When machine learning showed errors in classification, the decision tree was used to identify the cause of the error, allowing students to correct their misconceptions independently, and the process of correcting misconceptions was analyzed. The study was conducted as an online class for 18 sessions for third-year high school students, and the program's effectiveness was evaluated by analyzing students' academic achievement, attitudes toward using redox reaction models, and perceptions of AI-based classes. The results showed that the redox reaction judgment program using decision tree classification model was effective in improving students' academic achievement and correcting misconceptions, with particularly notable results in the oxidation number change model and the Goodstein model. As the study progressed, the percentage of students who responded ‘I cannot explain’ decreased, and they demonstrated an understanding of the advantages, disadvantages, and limitations of the models, choosing appropriate models to interpret chemical reactions according to the situation. Furthermore, students modified their approach from interpreting redox reactions based on simple memorization or calculation to developing an attitude of understanding chemical bonds, structures, and electronegativity, interpreting them from a process perspective. The immediate feedback from AI contributed to improving the learning experience by helping students correct errors and automate their schemas, and students showed a positive attitude toward using AI tools in their chemistry learning. These results suggest that the program developed in this study contributed to the cultivation of basic digital and artificial intelligence literacy. Therefore, the need for chemistry classes using artificial intelligence tools that students can easily handle is emphasized, and teachers should understand and utilize the possibilities and limitations of artificial intelligence in a balanced manner as guides and facilitators of learning."
대학생 학업성취도 예측과 맞춤형 학습 지원을 위한 AI 기반 통합 프레임워크,2025,"['Academic performance prediction', 'Hybrid recommendation system', 'Learning analysis', 'Personalized learning']","본 연구는 대학생의 학습 성취도를 예측하고 개인 맞춤형 학습 지원을 제공하기 위한 AI 기반 통합 프레임 워크를 제안한다.전 세계 교육기관에서 널리 사용되는 오픈형 학습관리시스템인 Canvas LMS 로그 데이터를 활용하여 머신러닝∙딥러닝 기반 예측 모델을 구축하고, 협업 필터링과 콘텐츠 기반 필터링을 결합한 Hybrid 추천 시스템을 설계하였다. 학습자의 행동 데이터를분석해 학업 부진을 조기에 탐지하고, 자동화된 피드백과 맞춤형 콘텐츠를 제공함으로써 교사의 개입을 앞당기고 자기주도 학습을 촉진할 수 있다. 이는 실제 수업 운영에서 학습자 맞춤형 지원을 강화하고, 학업 성과 격차를 줄이는 데 기여할 수 있는 실천적 도구로 활용 가능하다.","This study proposes an AI-based integrated framework to predict university students’ academic performance and providepersonalized learning support. Utilizing log data from Canvas LMS, a widely used open-source learning management system in educational institutions worldwide, the study builds prediction models based on machine learning and deep learning techniques.Furthermore, it designs a hybrid recommendation system that combines collaborative filtering and content-based filtering. Byanalyzing learners’ behavioral data, the framework enables early detection of academic underperformance and provides automatedfeedback and personalized content, facilitating timely teacher intervention and promoting self-directed learning. This approach canserve as a practical tool to enhance personalized support in actual classroom settings and help reduce academic achievement gaps."
AI시대 학부번역수업의 기계번역 적용에 관한 연구― 중한번역수업 심층인터뷰를 중심으로,2025,"['번역교육', '기계번역', 'AI번역', '번역능력', 'ChatGPT', 'Translation education', 'machine translation', 'AI translation', 'translation competence', 'ChatGPT']",,"This study investigated the integration of machine translation (MT) and artificial intelligence (AI) into undergraduate translation education, focusing on how these tools support translation competence and language skill development through a social constructivist approach. Conducted in a Chinese-Korean translation class, the research analyzed how students improved their translation abilities using a collaborative machine-human model. Students utilized Papago and ChatGPT as key tools in their translation tasks, enhancing vocabulary, grammar, and sentence structure skills while developing cultural knowledge and translation competence. Team-based learning and classroom discussions played a crucial role in helping students refine machine-generated translations and acquire effective strategies. ChatGPT provided immediate feedback, fostering an interactive learning dynamic that boosted confidence and motivation. The findings highlight that integrating MT and AI into undergraduate courses can significantly improve translation quality and collaborative learning. This approach supports both individual skill-building and collective growth, demonstrating the potential of combining technological advancements with traditional translation education."
FSM과 강화학습 기반의 지능형 NPC AI: 2D 모바일 자동 진행 RPG 게임의 구현 연구,2025,"['자동 진행 RPG', 'NPC 인공지능', '유한 상태 기계', '강화학습', '전투 시스템 최적화', 'Idle RPG', 'NPC AI', 'Finite State Machine', 'Reinforcement Learning', 'Combat System Optimization']","본 연구는 모바일 자동 진행형 RPG 게임에서 유한 상태 기계(FSM)와 강화학습을 융합한 지능형 NPC AI 시스템의 설계 및 구현에 관한 것이다. 유한 상태 기계(FSM)와 강화학습(Q-learning, DQN) 기법을 결합하여 NPC의 환경 인식, 전투 전략, 상태 관리를 최적화하였다. NPC AI는 대기,공격, 도망 등 다양한 상태 전환을 통해 동적으로 행동하며, 실험에서는 전투 승률, 반응 시간, 이동 거리 등 다양한 성능 지표를 수집⋅분석하여AI의 행동 패턴을 정제하고 게임 밸런스를 유지하였다. 본 연구는 FSM과 강화학습의 통합적 적용을 통해 자동 진행 RPG에서의 NPC AI 성능향상 방안을 제시한다. 제안된 시스템은 NPC AI의 전투 전략, 이동 패턴, 반응 시간을 실시간으로 조정하여 플레이어에게 지속적이고 균형 잡힌게임 경험을 제공하고, 성능 평가를 위해 승률, 전투 지속 시간, 리소스 효율성 등의 지표를 측정한 결과, 기존 규칙 기반 AI 대비 승률은 55.2%에서78.9%로, 상황 적응성 점수는 6.2/10에서 8.7/10으로 향상되었다. 본 연구는 자동 진행 RPG 게임에서 강화학습을 통한 지능형 NPC 구현의 가능성을실증하였으며, 향후 실시간 AI 최적화를 위한 기초 자료로 활용될 수 있다.","This study focuses on the design and implementation of an intelligent NPC AI system that integrates Finite State Machines (FSM) andreinforcement learning in mobile idle RPG games. By combining FSM with reinforcement learning techniques such as Q-learning andDeep Q-Networks (DQN), the system optimizes NPCs’ environmental perception, combat strategies, and state management. The NPC AIdynamically transitions between various states such as idle, attack, and retreat, and experimental evaluation involved collecting andanalyzing performance metrics such as combat win rates, response times, and movement distances to refine behavioral patterns andmaintain game balance. This study proposes a method for enhancing NPC AI performance in idle RPGs through the integrated applicationof FSM and reinforcement learning. Through real-time data analysis, the difficulty and behavior patterns of NPCs were dynamically adjusted,and an intelligent NPC system was implemented that adapts to various combat environments and situations. This research provides aguide for developing auto-roguelike RPG games and can be used as foundational material for enhancing game experiences based onreal-time AI optimization."
딥러닝 기반 유동 광역 분산을 위한   스포일러의 최적 설계에 관한 연구,2025,"['CFD', 'Diesel', 'Spoiler', 'Flow Unifromity', 'Optimal Design', 'Inverse Design', 'Deep Learning']",,"This  study  includes  an  optimal  design  for  spoilers  that  can  achieve  the  target  flow uniformity   for   wide   area   distribution   of   concentrated   exhaust   gas   using   a   deep learning-based  inverse  design  process.  First,  in  order  to  collect  data  for  the  inverse design, the spoiler shape and variables were selected, modeled, and then CFD analysis was  performed.  The  flow  uniformity  of  the  model  to  which  no  spoiler  was  attached was  found  to  be  about  0.6626.  The  algorithm  of  inverse  design  for  optimal  design used  a  stacking  ensemble  learning  model  that  combines  the  DNN  model  of  deep learning  and  the  random  forest  and  XGBoost  of  machine  learning,  and  the  learning model's  coefficient  of  determination  was  0.9518,  ensuring  reliability.  A  value  whose predicted  flow  uniformity  for  the  design  variable  set  is  close  to  the  target  flow uniformity  of  0.9  was  selected  as  the  optimal  design  variable  set,  and  the  flow uniformity  when  the  optimal  variable  model  through  actual  analysis  was  used  was 0.916   and   increased   by   about   38.24%   compared   to   0.6626,   which   is   the   flow uniformity  of  the  model  without  spoilers,  so  the  optimal  design  is  considered  to  have been completed."
이동중인 객체 탐지를 위한 딥러닝 기반 영상 분석,2025,"['머신러닝', '딥러닝', '감시 영상', 'Faster R-CNN', '객체 추적', 'Faster R-CNN', 'Machine Learning', 'Deep Learning', 'Computer Vision', 'Object Detection', 'BigData']","본 논문에서는 감시 영상 시스템에서 Faster R-CNN(Faster Region-based Convolutional Neural Network)을 이용하여 이동 중인 사람을 효과적으로 추적하는 기법을 제안한다. 기존의 사람 검출 및 추적 기술은 환경 변화, 배경 잡음, 이동하는 객체의 변형 등에 의해 성능 저하가 발생하는 문제가 있었다. 본 연구에서는 Faster R-CNN을 활용하여 시간적, 공간적 특징을 동시에 학습함으로써 강인한 추적 성능을 확보하였다. 실험 결과, R-CNN및 Fast R-CNN과 비교하여 Faster R-CNN 기반 모델이 높은 검출율(90%)을 유지하면서도 거짓 긍정율(False Positive Rate)을 5배 이상 감소시켰음을 확인하였다. 또한, Faster R-CNN의 자동 최적화된 특징 학습이 기존 방법 대비 계산 속도 면에서도 약 40배 빠른 성능을 보였다. 본 연구는 감시 시스템뿐만 아니라 다양한 객체 추적 응용에도 적용될 수 있을 것으로 기대된다.","This paper proposes a robust human tracking method in surveillance systems using Convolutional Neural Networks (Faster R-CNN). Traditional detection and tracking methods suffer from environmental changes, background noise, and object deformations. To overcome these challenges, we employ Faster R-CNNs to learn both spatial and temporal features, achieving robust tracking performance. Experimental results show that the Faster R-CNN-based approach significantly outperforms Haar-wavelet based Support Vector Machine (SVM), maintaining a 90% detection rate while reducing the false positive rate by a factor of five. Additionally, Faster R-CNN-based feature optimization leads to a 40 times faster computational efficiency than SVM. This study is expected to be applicable to various object tracking applications beyond surveillance systems."
비지도 학습을 이용한 물리검층 자료부터의 암상 분류: 자기조직화 지도 알고리즘 중점으로,2025,"['물리검층', '자기조직화 지도', '비지도 학습', '분류', '암상', 'Well Logging', 'Self-Organizing Map', 'Unsupervised Learning', 'Classification', 'Lithology']","물리검층은 시추공을 통해 지중에 대한 정보를 얻는 과정을 의미한다. 밀도, 공극률, 유체포화도 등과 같은 특성들을 측정하고, 이는 특히 지중에 존재하는 다양한 암상을 식별하고 분류하는데 있어 매우 유용하다. 암상 분류는 저류층 특성화 및 석유나 가스 탐사에 매우 중요한 역할을 한다. 하지만 코어샘플링 등과 같은 전통적인 분류 방법은 시간과 비용이 많이 소요된다. 본 연구에서는 머신러닝 알고리즘을 활용하여 물리검층 자료로부터 암상을 분류하는 방법을 연구하였다. 이를 위해 자기조직화 지도(Self-Organizing Map, SOM)라는 인공신경망 알고리즘을 적용하였으며, 비지도 학습 방식으로 진행하였다. 다양한 입력 변수를 고려하여 모델을 학습시켰으며, 이를 통해 암상 분류를 예측한 후 사전에 주어진 암상 자료와 비교하여 예측 정확도를 평가하였다. 또한, 하이퍼파라미터의 영향을 최소화하기 위해 앙상블 기법을 활용하여 SOM 100 모델을 구성하였다. 이 방법을 통해 단일 모델이 가지는불확실성을 줄이고, 보다 신뢰도 높은 암상 분류 결과를 도출하고자 하였다.","Well logging is the process of obtaining information regarding the subsurface through boreholes. It measures properties such as density, porosity, fluid saturation etc, which are useful in identifying and classifying the various lithologies within the subsurface. Lithology classification and identification are crucial for reservoir characterization and oil and gas exploration. However, conventional methods, such as core sampling, are time consuming and expensive. In this research, a method of classifying lithology from well log data is developed using an unsupervised machine learning algorithm, self-organizing map (SOM). Various input features are considered to train the model, and lithology classification predictions are made and compared with pre-existing lithology data to evaluate the prediction accuracy. To minimize the impact of hyperparameters, we employ an ensemble approach by constructing the SOM 100 model. This proposed method aims to reduce the uncertainty associated with a single model and enhance the reliability of lithology classification prediction."
딥러닝 기반 KOSPI 200 옵션 내재변동성 예측 연구,2025,"['내재변동성', 'KOSPI 200 옵션', '딥러닝', '머신러닝', 'Implied Volatility', 'KOSPI 200 Index Options', 'Deep Learning', 'Machine Learning']","내재변동성을 정확하게 예측하는 것은 포트폴리오 리스크 관리와 헤징 전략 수립 등 여러 금융 분야에서 핵심적인 역할을 한다. 그러나 전통적인 변동성 예측 모델은 금융 데이터의 비선형적이고 복잡한 특성을 충분히 포착하기 어려운 경우가 많다. 본 연구는 Multi-Layer Perceptron (MLP) 모델을 활용해 KOSPI 200 옵션의 내재변동성을 예측하고, Random Forest (RF) 모델과 성능을 비교하였다. 코스피 200 옵션 데이터, VKOSPI(한국 변동성 지수), 91일물 CD 금리 등을 입력 변수로 사용하였으며, 이들 데이터는 한국거래소와 한국은행 경제통계시스템에서 수집하였다. 잔존만기, moneyness, 거래량 등 다양한 관점에서 모델을 평가한 결과,  MLP는 대부분의 실험에서 RF 대비 더 낮은 RMSE를 보였으며,  최대 57%의 예측 오차 감소 효과를 보였다. 이는 금융 시장에서 내재변동성 예측의 정확도를 향상시킬 수 있는 딥러닝 기반 접근법의 잠재력을 보여준다는 점에서 의의가 있다.","Accurately predicting implied volatility plays a crucial role in various financial fields, including portfolio risk management and hedging strategy development. However, traditional volatility prediction models often struggle to capture the nonlinear and complex nature of financial data. In this study, we employ a Multi-Layer Perceptron (MLP) model to predict the implied volatility of KOSPI 200 options and compare its performance with that of a Random Forest (RF) model. We use KOSPI 200 options data, the VKOSPI (KOSPI 200 Volatility Index), and 91-day CD rates as input features, collected from the Korea Exchange and the Bank of Korea Economic Statistics System. Evaluating the model from various perspectives, such as time to maturity, moneyness, and trading volume, revealed that the MLP consistently outperformed the RF in most experiments, reducing prediction errors by up to 57%. This finding highlights the potential of a deep learning-based approach to enhance the accuracy of implied volatility prediction in financial markets, underscoring its significance."
발파 시공 데이터의 계층적 구조를 반영한 딥러닝 기반 파쇄도 예측,2025,"['파쇄도', '발파 시공', '계층적 데이터', '딥러닝', '집합학습', 'Fragmentation', 'Blasting construction', 'Hierachical structured data', 'Deep learning', 'Sets learning']","발파 파쇄도는 후속 공정의 효율과 비용에 직접적인 영향을 미치는 핵심 지표이다. 기존 파쇄도 예측 연구는 주로 설계 변수와 암반 물성을 기반으로 한 경험식이나 머신러닝 방법을 활용했지만, 시공 단계의 복잡성과 불확실성을 반영하지 못하는 한계가 있다. 본 연구에서는 천공홀 단위의 실제 시공 데이터를 활용하여 발파파쇄도를 예측할 수 있는 모델을 최초로 제안하며, 한화글로벌 시스템에서 수집된 계층적 blast–hole 데이터를 활용하여 attention 기반 deep sets 모델을 개발하였다. 이 모델은 개별 천공홀의 정보를 가중치로 통합하여 발파 단위의 예측에 반영함으로써 기존 모델로 학습이 불가능한 계층적 구조의 학습과 높은 예측 성능을 동시에 달성한다. 총 7,728건의 발파와 90만 건 이상의 천공홀 데이터를 기반으로 한 제안 모델은 최대 93% 예측 정확도를보였으며, 잠재 공간 시각화에서도 타겟별 정보를 효과적으로 구조화할 수 있었다. 본 연구는 시공 데이터 기반품질 관리를 위한 예측 모델의 새로운 가능성을 제시한 첫 사례로서, 지능형 발파 시스템 개발에 실질적인 기여가 가능할 것으로 판단된다.","Blast fragmentation is a critical indicator that directly impacts the efficiency and cost ofsubsequent operations. While previous studies on fragmentation prediction have primarily relied onempirical formulas or machine learning models based on design parameters and rock properties, they fallshort of capturing the complexity and uncertainty inherent in the construction stage. This study proposesthe first model capable of predicting blast-level fragmentation using actual hole-level construction data.Leveraging hierarchical blast–hole data collected through HATS system of Hanwha Global, we develop anattention-based deep sets model. This model integrates individual hole-level information via attentionweighting, enabling both effective learning of the hierarchical structure and high predictive performance—capabilities not achievable with conventional models. Experiments conducted on 7,728 blast records and over900,000 drill holes demonstrate up to 93% prediction accuracy, and the latent space visualization confirmswell-structured target-related representations. As the first approach to introduce a construction-phaseprediction model for blast fragmentation, this research offers new potential for quality control in fieldoperations and makes a practical contribution to the development of intelligent blasting systems."
레이더 및 지상 관측 강우 자료를 통한 딥러닝 기반 강우 예측 모델 개선,2025,"['Precipitation nowcasting', 'Radar', 'Gauge station', 'cGAN', '강우예측', '레이더', '지점강우', '조건부 생성적 적대 신경망']","유역의 정확한 홍수량 예측을 위해서는 정확한 강우 예측이 필수적이다. 최근 머신러닝 기법을 활용하여 강우 예측 모델의 성능을 개선하는 연구가 활발히 진행되고 있다. 주로 유역에 대한 공간 강우량을 예측하기 위해 레이더 기반 강우 예측 모델이 개발되어 그 성능을 입증하였으나, 정확한 강우량 추정에 한계가 있는 레이더 자료를 기반으로 개발되는 모델 특성상, 실제 유역에 떨어지는 강우량을 정확하게 예측하는 데에는 한계가 있다. 본 연구에서는 기존 머신러닝을 활용한 레이더 기반 모델의 예측 성능 개선을 위해 지점강우를 훈련과정에서 사용하는 기법을 제안하였다. 영산강 유역에 대해 최대 6시간까지의 예측 강우를 생산하는 모델 개발을 위해 조건부 생성적 적대 신경망(conditional Generative Adversarial Network, cGAN)을 활용하였으며, 모델 훈련을 위해 기상레이더 자료와 함께, 영산강 유역의 도메인 내에 종관기상관측(Automated Synoptic Observing System, ASOS) 강우자료를 사용하였다. 결과를 통해, 레이더 자료만 사용한 모델에 비해 지점강우자료를 추가입력자료로 고려한 모델이 유역의 공간 강우량을 예측하는데 더 우수한 성능을 보이는 것을 확인하였다.","To forecast accurate predictions of flooding in a basin, it is essential to have accurate precipitation forecasts. Recently, there have been a number of studies that utilize machine learning techniques to improve the performance of precipitation prediction models. Several radar-based precipitation prediction models have been developed and shown their capabilities, mainly for spatial precipitation prediction over basins. However, since the model is developed based on radar data, which has limitations in accurate rainfall estimation, it is challenging to accurately predict the actual precipitation that falls in a basin. In this study, we proposed a strategy to improve the prediction performance of radar-based models using machine learning by incorporating observations from gauge stations during the training process. To develop a model that produces predicted rainfall up to 6 hours for the Yeongsangang River basin, a conditional generative adversarial neural network (cGAN) was applied. Along with the radar data, the model was trained using the rainfall data from gauge stations (Automated Synoptic Observing System, ASOS) within the domain of the Yeongsangang River basin. Through the results, we showed that the model that considers point rainfall data as an additional input performs better in predicting the spatial pattern of rainfall than the model that only uses radar data."
학습-기반 이미지 손실 압축 기법에 대한 연구,2025,"['Image Compression', 'Encoding and Decoding', 'JPEG', 'Learning-based', 'Lossy and Lossless Compression']",,"Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Compression of images is necessary due to bandwidth and memory constraints. Helpful, redundant, and irrelevant information are three different forms of information found in images. Recently many learning-based techniques have been proposed to promise results on image compression field. This paper surveys recent techniques utilizing mostly lossy image compression using machine learning architectures. The majority of the publications in the compression domain surveyed are from the previous five years and use a variety of approaches."
잠재적인 피부과민성 유발물질 선별을 위한 딥러닝 기반 KeratinoSens™  활성 예측모델 개발,2025,"['Skin sensitization', 'adverse outcome pathway', 'keratinosense', 'graph convolution network', 'in silico']",,"Background: Skin sensitization is a common dermatological condition, and it is crucial to effectively evaluate potential sensitizers. Comprising four key events, the adverse outcome pathway (AOP) framework used by the OECD systematically describes the mechanism of skin sensitization. With the global shift away from animal testing, alternative testing methods have gained increasing importance. Among them, KeratinoSensTM is considered a key in vitro  assay for evaluating KE2, the activation of keratinocytes. However, it is impractical to assess every chemical substance experimentally, which highlights the need for efficient in silico  prediction approaches.Objectives: This study aims to analyze methodologies for developing predictive models for KeratinoSensTM activation. We compare algorithms and molecular descriptors to propose a highly accurate prediction model.Methods: We collected and curated a dataset with KeratinoSensTM assay results through a literature review. Predictive models were developed by combining machine learning and deep learning algorithms with diverse molecular descriptors. Model performance was evaluated using five-fold cross-validation using multiple evaluation metrics, and PCA and UMAP were applied to data distribution analysis and identification of prediction error patterns.Results: The GCN and DNN models presented superior predictive performance compared to other machine learning-based models. The GCN model, in particular, achieved an average ROC-AUC of 0.80, indicating a strong learning capability from molecular structures. PCA and UMAP analyses confirmed that the GCN model effectively captured structural differences between datasets. However, prediction errors were observed for structurally novel compounds, likely due to the limited dataset size.Conclusions: This study highlights the GCN model's strong performance in predicting KE2 events within the AOP framework, underscoring its potential as a pre-screening tool for identifying skin sensitizers. Expanding the dataset could further improve its generalizability for efficient skin sensitization assessment."
향수 구독 서비스의 성공 요인 연구: ID3 기반 귀납적 추론을 활용한 다중 사례 분석,2025,"['Fragrances Subscription Service', 'ID3 algorithm', 'Inductive learning', 'Multiple Case Study', '향수 구독 서비스', 'ID3 알고리즘', '귀납적 학습법', '다중 사례 분석', '향수시장', '구독경제']","본 연구는 글로벌 향수 구독 시장의 성장에 따라 변화된 소비자 행동과 이에 대응하는 산업계의 전략 변화를 배경으로, 향수 구독 서비스의 상업적 성공 및 실패 요인을 규명하고자 하였다. 전통적인 일회성 향수 구매 방식이 구독 형태로 전환되는 추세 속에서, 본 연구는 귀납적 학습에 기반한 다중 사례 연구 방법을 적용하였다. 주요 분석 변수로는 구독 가격대, 버전 제공 여부, ESG 가치 존재 여부, 맞춤형 서비스 제공 여부, 전문가 추천 제공 여부가 설정되었으며, 이를 토대로 총 25개의 향수 구독 서비스 사례를 분석하였다.분석 결과, 인공지능 기반 머신러닝 기법인 ID3 알고리즘을 활용하여 성공과 실패에 영향을 미치는 다섯 가지 조건부 가설을 도출하였다. 주요 가설은 ESG 요소의 존재 여부 및 가격 전략(저가 혹은 중가), 그리고 버전 제공, 맞춤형 서비스, 전문가 추천의 제공 여부 간의 상호작용에 따라 성공 가능성이 달라짐을 시사한다. 본 연구는 향수 구독 시장의 전략적 기획 및 마케팅 방향 설정에 실증적 기초자료를 제공한다는 점에서 학문적‧실무적 의의가 있다.","The rise of the global perfume subscription market has shifted not only consumer behavior but also how entrepreneurs and marketers approach the fragrances industry. The traditional one-time purchase of a full perfume bottle is being replaced by subscription services. The main purpose of this study is to identify the significant factors that contribute to the commercial success or failure of fragrances subscription services using a multiple case study method based on inductive learning. The anticipated factors that may affect the success or failure of fragrances subscription services include : 'subscription price range', 'existence of versioning', 'existence of ESG value', 'existence of customized service', and 'existence of expert recommendation'. Using these variables, 25 cases of fragrance subscription services were analyzed. As a result, five hypotheses related to the success and failure of fragrance subscription services can be proposed using inductive learning based on the ID3 algorithm of machine learning methodology in the field of artificial intelligence. The five hypotheses are as follows; First, perfume subscription services without ESG factors will succeed if they provide two or more of versioning, customization, and expert recommendation. Second, when ESG elements are present, perfume subscription services that adopt mid-priced strategies will fail unless they offer all three : versioning, customization, and expert recommendation. Third, if ESG elements are present, perfume subscription services that adopt mid-priced strategies will succeed if they provide one or more of versioning, customization, and expert recommendation. Fourth, when ESG elements are present, perfume subscription services that adopt low-cost strategies will fail unless they include all three: versioning, customization, and expert recommendation. Lastly, if ESG elements are present, perfume subscription services that adopt low-cost strategies will succeed if they provide one or more of versioning, customization, and expert recommendation."
사건관련전위(ERP)의 딥러닝기반 경두개 자기자극(TMS)을 이용한 감정인식에 관한 연구,2025,"['Electroencephalogram(EEG)', 'Transcranial Magnetic Stimulation(TMS)', 'Event-related Potential(ERP)', 'Emotion recognition', 'Deep learning', '뇌파', '경두개자기자극', '사건관련전위', '감정인식', '딥러닝']","경두개 자기자극(Transcranial magnetic stimulation, TMS)은 대뇌피질을 자극하는 비침습형 측정 방법으로 뇌의 특정위치에 코일을 통한 강력한 전류의 순간적 강한 자기장을 가하므로써, 이를 통하여, 뇌의 특정영역의 신경세포를 활성화 혹은 억제시키는 뇌 자극술이다. 특히, 배외측 전전두엽 피질(Dorsolateral prefrontal cortex, DLPFC)에 적용된 저주파의 반복적으로 가해지는 TMS 자극법은 감정처리와 관련되어 유효성이 검증되면서 의학, 심리학 등 다양한 정신질환 및 심리치료에서 활용되고 있다. 이러한 TMS의 유효성을 바탕으로, 본 연구에서는 사용자가 감정문장을 읽는 동안, TMS를 사용하여 뇌의 특정영역에 자극을 가한 후, TMS 전후 감정변화에 대하여 알아보고자 한다. 즉, TMS 자극 전/후의 감정에 대한 반응을 사건관련전위(Event-related potential, ERP)방법으로 뇌파를 기록하고, 감정과 관련된 ERP 성분(Component)을 검출 후, 이를 기계학습 활용하여 그 성능을 평가하고자 한다. 먼저, 6개의 감정(분노, 흥분, 두려움, 지루함, 슬픔, 행복)과 중립의 감정문장을 제시하고, 이를  2번으로 나누어, 총 280개를 사용하여 데이터를 수집하였다. 측정된 뇌파는 방해파 제거 등의 전처리 과정을 거친 후, 감정과 관련된 ERP 성분인 후기 정적 복합체(Late positive complex, LPC)를 검출하였다. 마지막으로, 100ms당 1개의 스펙트로그램(Spectrogram)으로 이미지를 생성하고, 이에 대한 성능 평가를 진행하였다. 그 결과, TMS 자극 전/후 비교해보면, TMS 자극 후가 자극 전보다 감정인식 성능이 높게 나타났으며, 합성신경망(Convolutional Neural network, CNN)을 사용할 때, 4개의 감정에 대해서 86.39%의 가장 높은 성능을 얻었다. 본 연구는 TMS 처치를 통한 뇌 인지기능조절을 통한 감정반응의 효과를 확인하였고, 감정조절과 뇌 반응에 효과적이라는 것을 확인할 수 있었다.","Transcranial magnetic stimulation (TMS) is a non-invasive measurement method that stimulates the cerebral cortex to examine human brain function. For this reason, many fields, ranging from medicine and psychology to computer science, focus on identifying and recognizing human emotions to better understand individual states and comprehend specific situations. This study aims to determine emotional responses by controlling brain cognitive functions through TMS. In particular, low-frequency repetitive TMS applied to the dorsolateral prefrontal cortex (DLPFC) has been verified as effective in emotional processing. Hence, it is used in various mental illnesses, psychotherapy, medicine, and psychology. In this paper, we investigate the effects of low-frequency repetitive TMS applied over the DLPFC while reading emotional sentences. In addition, we record EEG (electroencephalogram) using Event-related potential (ERP) to examine brain responses before and after TMS stimulation, detect ERP components related to emotion, and evaluate with machine learning. First, we selected 280 emotional sentences as standardized elicitation samples for self-induced emotion from EEG signals using ERP that described six discrete emotions, i.e., anger, excited, fear, bored, sadness, happiness, and neutral in the baseline. We focus on the emotion-related ERP component, Late Positive Complex (LPC), extracted by raw EEG signals. Then, we generate the EEG signals to spectrogram as images per 100 ms. As a result, we confirm that emotion recognition after TMS stimulation is higher than before. Also, we achieved the best recognition accuracy of 86.39% after TMS treatment compared to before TMS treatment using CNN. In conclusion, our study means that TMS treatment is effective for emotion control and brain response. In the future, it will be possible to consider individual variance differences or conduct research using various deep-learning methods."
디지털 리트로핏 설비의 초기 데이터 부족 문제 해결을 위한 적응형 딥러닝 모델 운영 방안,2025,"['Digital Retrofit', 'Anomaly Detection', 'Foundation Model', 'Time-Series Data', 'LSTM', '디지털 리트로핏', '이상탐지', '파운데이션모델', '시계열 데이터', 'LSTM']","최근 제조 산업에서는 노후 설비의 센서, 제어 및 구동부를 교체하여 설비 성능을 향상시키는 디지털 리트로핏 기술이활발히 도입되고 있다. 그러나 리트로핏 초기 운영 단계에서는 센서 및 제어기 교체 이후 수집되는 데이터의 양이 매우 제한적이다.이로 인해 이상 탐지 모델 학습에 필요한 데이터의 분포를 충분히 반영하기 어려워 학습 성능이 저하되며, 실시간 예지보전시스템을 즉시 적용하기에는 한계가 존재한다. 본 연구에서는 리트로핏 설비 운영 초기에 발생하는 데이터 부족 문제를 해결하기위해, 데이터 축적 단계에 따라 두 종류의 이상 탐지 모델을 유연하게 전환하는 적응형 접근 방식을 제안한다. 초기 운영 단계에서는사전학습된 파운데이션 모델을 활용하여 즉시 이상 탐지를 수행하고, 이후 충분한 양의 정상 데이터를 확보하게 되면, 지속적인재학습이 가능한 Long Short-Term Memory-Autoencoder기반 모델로 전환하여 탐지 성능과 운영 효율을 향상시킨다. 제안한적응형 접근 방식의 유효성은, 실제 5축 CNC 머신 데이터를 대상으로 시퀀스 정규화를 적용한 후 두가지 실험을 통해 검증하였다.실험에 앞서 첫 번째 실험에서는 학습 데이터 비율에 따른 이상 탐지 성능과 학습 시간을 비교했고, 두 번째 실험에서는 다양한노이즈 환경에서 모델의 강건성을 평가하였다. 실험 결과, 모델 전환 후에도 이상 탐지 성능은 안정적으로 유지되었고, LSTM-AE는파운데이션 모델 대비 학습 시간이 매우 짧으며 다양한 노이즈 환경에서도 강건한 성능을 보였다. 본 연구는 제조 서비스 분야에서리트로핏 설비의 초기 운영 단계부터 효과적인 실시간 예지보전 서비스를 제공하여 설비 운영의 효율성 향상에 기여할 것으로기대된다.","Digital retrofit technologies are increasingly adopted in manufacturing to improve the performance of aging equipment by replacing sensors, controllers, and actuators. However, in the early stages of retrofit operation, the amount of data collected after sensor and controller replacement is often insufficient. This data scarcity makes it difficult to capture the distribution necessary for training anomaly detection models, resulting in degraded performance and limiting the immediate application of real-time predictive maintenance systems. To address this issue, this study proposes an adaptive anomaly detection approach that dynamically switches between two models depending on the level of accumulated data.During the initial stage, a pre-trained foundation model is used to perform anomaly detection without training. Once a sufficient amount of normal data is collected, the system transitions to a Long Short-Term Memory Autoencoder (LSTM-AE) model, which supports continual retraining and improves detection accuracy and operational efficiency. The effectiveness of the proposed method was verified using real-world time series data from a 5-axis CNC machine. Sequence normalization was applied to address the irregular patterns commonly found in actual equipment data. Two experiments were conducted: one evaluated anomaly detection performance and training time based on different data proportions, and the other assessed model robustness under various noise conditions. Results confirmed that detection performance remained stable after switching, and the LSTM-AE showed significantly shorter training time and strong robustness. This approach supports efficient real-time predictive maintenance from the early stage of retrofit equipment operation."
딥러닝 기반 실리콘 캐소드 미세 구멍 가공 치수의 대면적 검사 방법,2025,"['실리콘 캐소드', '비전 검사', '객체 검출', '초해상화', '미세 구멍 직경', 'Silicon cathode', 'Vision inspection', 'Object detection', 'Super resolution', 'Micro hole diameter']",,"In this study, we propose a deep learning-based method for large-area inspection aimed at the high-speed detection ofmicro hole diameters. Micro holes are detected and stored in large images using YOLOv8, an object detection model. Asuper-resolution technique utilizing ESRGAN, an adversarial neural network, is applied to images of small micro holes,enhancing them to high resolution before measuring their diameters through image processing. When comparing thediameters measured after 8x super-resolution with the results from existing inspection equipment, the average error rate isremarkably low at 0.504%. The time taken to measure an image of one micro hole is 0.470 seconds, which is ten timesfaster than previous inspection methods. These results can significantly contribute to high-speed measurement and qualityimprovement through deep learning."
지도학습을 통한 기업의 파산 예측 요인 분석: NCA를 중심으로,2025,"['Firms’ bankruptcy', 'Bankruptcy prediction', 'Analysis of Financial Ratio Big Data', 'Decision support', 'Necessary Condition Analysis (NCA)', '기업파산', '파산예측', '재무비율 빅데이터 분석', '의사결정 지원', '필요조건 분석']","기업 파산의 원인은 다양하고 복잡한데, 이를 예측하기 위해 일반적으로 재무 정보가 중요한 지표나 단서로 사용된다. 기업 파산 예측을 위한 모형 개발에 관한 과거 연구는 재무 비율을 활용하거나 예측 정확도 향상을 위해 동태적 접근과 통계적 기법을 활용하였으며, 최근에는 AI와 머신러닝 기법을 도입하여 모델의 발전을 도모하고 있다. 그러나 변수 간 상호작용이나 중요도를 명확히 분석하는 데 부족하거나 체계적으로 규명되지 않은 면이 있다.  이에 본 연구는 기업 파산 예측에 영향력이 높은 재무 비율을 탐색하고 영향력의 정도에 따라 우선순위를 부여하여 파산 예측 모델의 정확도를 높일 수 있는 요인을 파악하였다. 이를 위해 대만 기업의 파산 정보가 담긴 데이터를 수집하고, R과 Python을 활용한 통계 기법과 NCA를 적용하였다. 연구 결과, ‘총비용 대비 총수익’, ‘주당 순자산가치’, ‘납입자본 대비 세전순이익’, ‘순자산 성장률’ 등의 지표가 파산에 높은 영향력을 가진 변수로 파악되었다.","The causes of firm’s bankruptcy are diverse and complex, with financial information often serving as critical indicators for prediction. Extant studies on developing bankruptcy prediction models have utilized financial ratios and employed dynamic approaches and statistical techniques to enhance predictive accuracy. Recently, AI and machine learning methods have been introduced to further advance these models. However, there are some limitations in systematically analyzing the interactions between variables and clearly identifying their importance.  In this study, therefore, we explored financial ratios that significantly influence firm’s bankruptcy prediction and prioritized these factors based on their level of impact to identify elements that improve the predictive accuracy of bankruptcy models. For this, we collected data containing bankruptcy information on Taiwanese firms and applied statistical techniques and NCA using R and Python. The findings revealed that indicators such as ""total revenue to total expense ratio,"" ""net asset value per share,"" ""profit before tax to paid-in capital ratio,"" and ""net asset growth rate"" are variables with substantial influence on bankruptcy."
하이테크 기반 수학 학습 코칭에서 인공지능의 역할에 관한 교사 인식 조사,2025,"['수학 학습코칭', '수학 학습코칭 모델', '인공지능', '자기주도학습', 'mathematics learning coaching', 'mathematics learning coaching model', 'artificial intelligence (ai)', 'self-directed learning']","지능화, 초연결 사회, 인간과 기계의 협업 구도 등으로대별되는 상황(나귀수 외, 2018)에서 수학 학습에 도움을 주는역할을 수학 교사로제한하기보다는학생의 학습수준및상황에적절한도움과피드백을주는것이필요하다.수학 학습 코칭은 수학을 기피하고 싫어하는 학생의 수학 학습에 체계적으로 접근하여 학습 동기를 유발하고 자기주도 학습을 할 수있도록도움을주는것이지만(김정현, 2021) 수학 교사가 혼자하기는 어렵다. 이에 수학 학습 코칭 모델의각단계의전략을설문으로구성하여수학학습코칭에서인공지능을활용할수있는부분에대한교사의인식을 살펴보았다. 그 결과, 정량적으로 많은 데이터를 보유한 인공지능이 학생을 분석하고 그 정보를 바탕으로 학생 개개인의 특성에 맞는 맞춤형 학습을 제공하여 학생의 학습 동기를 유발하고, 지속적인 학습을 할 수 있는 기회를 충분히제공하여학생의성공경험을높여주며학습결과에대한즉각적인피드백을통해자기주도학습능력을함양할 수 있을 것이라고 하였다. 본 연구를 통해 수학교사가 수학 학습 코칭에서 인공지능을 활용할 수 있는 부분에대한 정보를 제공하고자한다.","In a situation where intelligence, hyper-connected society, and human-machine collaboration are prominent (Nagwisu et al., 2018), it is necessary to provide appropriate help and feedback to students' learning levels and situations rather than limiting the role of helping with math learning to math teachers.Math learning coaching systematically approaches math learning for students who avoid and dislike math, inducing learning motivation and helping them to learn self-directedly (Kim Jeong-hyeon, 2021), but it is difficult for math teachers to do it alone. Accordingly, we surveyed the strategies for each stage of the math learning coaching model to examine teachers' perceptions of areas where artificial intelligence can be used in math learning coaching. As a result, it was said that artificial intelligence, which possesses a large amount of quantitative data, can analyze students and provide customized learning tailored to each student's characteristics based on that information, inducing students' learning motivation, providing sufficient opportunities for continuous learning, increasing students' success experiences, and fostering self-directed learning abilities through immediate feedback on learning results.Through this study, we aim to provide information on areas where math teachers can utilize artificial intelligence in math learning coaching."
LMS 데이터를 활용한 학습 성과 예측 연구 동향: 시계열 분석과 딥러닝 기법의 발전,2025,"['Student performance prediction', 'personalized learning', 'time series classification prediction', 'deep learning', '학생 성과 예측', '개인화된 학습 지원', '시계열 분석', '딥러닝']","이 논문은 학습관리시스템(LMS) 데이터를 활용한 학습 성과 예측 연구의 최신 동향을 분석한다. LMS에는 학생들의 학습 활동 데이터가 누적되며, 이를 분석하여 성적 예측, 중도 탈락 방지, 맞춤형 학습 지원 등에 활용할 수 있다. 기존 연구에서는 정적 데이터 기반의 기계학습 모델을 활용했으나, 최근에는 시계열 분석과 딥러닝 기법(LSTM, CNN, DTW 등)을 결합하여 예측 성능을 향상시키는 방향으로 발전하고 있다. 특히 시계열 분석을 통해 학생의 학습 패턴 변화를 포착하고 조기 경고 시스템을 구축하는 연구가 증가하고 있다. 본 연구는 국내외 학술지의 연구들을 비교 분석하여 시계열 모델의 필요성과 한계를 논의하고, 향후 강화학습(XAI) 및 실시간 학습 성과 예측 시스템의 발전 가능성을 제안한다.","This study analyzes recent trends in research on predicting learning outcomes using Learning Management System (LMS) data. LMS accumulates student learning activity data, which can be utilized to predict academic performance, prevent dropouts, and provide personalized learning support. While previous studies primarily used machine learning models based on static data, recent advancements incorporate time series analysis and deep learning techniques (such as LSTM, CNN, and DTW) to improve prediction accuracy. In particular, time series analysis is increasingly used to capture changes in students' learning patterns and develop early warning systems. This study compares and analyzes research from domestic and international journals, discussing the necessity and limitations of time series models and proposing the future application of reinforcement learning (XAI) and real-time learning outcome prediction systems."
지도학습을 이용한 철근콘크리트 보 단면 구조설계 자동화모델 개발,2025,"['Machine learning', 'Supervised learning', 'Automated structural design', 'Reinforced beam section design']",,"Automated structural design methods for reinforced concrete (RC) beam members have been widely studied with various techniques to date. Recently, artificial intelligence has been actively applied to various engineering fields. In this study, machine learning (ML) is adopted to make automated structural design model for RC beam members. Among various machine learning methods, a supervised learning was selected. When a supervised learning is applied to development of ML-based prediction model, datasets for training and test are required. Therefore, the datasets for rectangular and t-shaped RC beams was constructed by commercial structural design software of MIDAS. Five supervised learning algorithms, such as Decision Tree (DT), Random Forest (RF), K-Nearest Neighbor (KNN), Artificial Neural Networks (ANN), eXtreme Gradient Boosting (XGBoost) were used to develop the automated structural design model. Design moment (Mu), design shear force (Vu), beam length, uniform load (wu) were used for inputs of structural design model. Width and height of the designed section, diameter of top and bottom bars, number of top and bottom bars, diameter of stirrup bar were selected for outputs of structural design model. Performance evaluation of the developed structural design models was conducted using metrics sush as root mean square error (RMSE), mean square error (MSE), mean absolute error (MAE), and coefficient of determination (R2). This study presented that random forest provides the best structural design results for both rectangular and t-shaped RC beams."
대기 및 해양 예측을 위한 인공신경망 학습의 새로운 패러다임: 물리정보 신경망과 연산자 학습,2025,"['Scientific Machine Learning (SciML)', 'Physics-Informed Neural Networks (PINNs)', 'Operator Learning (OL)', 'Fourier Neural Operator (FNO)', 'Deep Operator Network (DeepONet)']",,"This study explores the potential of Physics-Informed Neural Networks (PINNs) and Operator Learning (OL) techniques in advancing scientific computation and prediction. PINNs integrate physical principles into neural network training, enabling accurate modeling and prediction of complex physical systems, even in data-scarce and noisy environments. They have been successfully applied to solve challenging nonlinear partial differential equations (PDEs), such as Euler and Navier-Stokes equations, and continue to evolve with variants. Meanwhile, OL methods, represented by Deep Operator Network (DeepONet) and Fourier Neural Operator (FNO), focus on learning mappings between function spaces. These methods excel in high-dimensional data processing and have demonstrated remarkable performance in applications such as global atmospheric modeling with NVIDIA’s FourCastNet. Hybrid approaches, such as Physics-Informed DeepONet (PIDON) and Physics-Informed Neural Operator (PINO), combine the strengths of PINNs and OL. These methods leverage data-driven learning and physical constraints, achieving superior generalization and prediction accuracy. Notably, PINO enables zero-shot super-resolution predictions by integrating multi-resolution data with PDE constraints. While PINNs and OL individually present powerful tools for modeling and prediction, their computational cost and sensitivity to noise pose challenges. Hybrid approaches offer a pathway to address these issues by optimizing their integration through quantitative analyses. Future research directions include accelerating training through high-performance computing, extending applications to multiscale problems, and designing innovative loss functions to enhance data efficiency. This work synthesizes the latest advancements in PINNs, OL, and hybrid methods, providing a new paradigm for precise and efficient scientific computation across diverse fields."
자동화 제조 시스템에서 공정 이미지 기반 고장 감지 모델의 학습 패러다임 및 출력 형식 전환에 따른 성능 비교 분석,2025,"['Fault Detection', 'Learning Paradigm', 'Output Representation', 'Automated Manufacturing System', 'Process Image']",,"Fault detection in electromechanical systems plays a significant role in product quality and manufacturing efficiency during the transition to smart manufacturing. Because collecting a sufficient number of datasets under faulty conditions of the system is challenging in practical industrial sites, unsupervised fault detection methods are mainly used. Although fault datasets accumulate during machine operation, it is not straightforward to utilize the information it contains for fault detection after the deep learning model has been trained in an unsupervised manner. However, the information in fault datasets is expected to significantly contribute to fault detection. In this regard, this study aims to validate the effectiveness of the transition from unsupervised to supervised learning as fault datasets gradually accumulate through continuous machine operation. We also focus on experimentally analyzing how changes in the learning paradigm of the deep learning model and the output representation affect fault detection performance. The results demonstrate that, with a small number of fault datasets, a supervised model with continuous outputs as a regression problem showed better fault detection performance than the original model with one-hot encoded outputs (as a classification problem)."
컨테이너 환경에서 딥러닝 워크로드의 성능 분석,2025,"['컨테이너', '딥러닝', '성능', '가상화', '워크로드', 'container', 'deep learning', 'performance', 'virtualization', 'workload']","최근 딥러닝 워크로드가 컨테이너 환경에서 실행되는 사례가 늘고 있다. 컨테이너는 가상머신에 비해 낮은 오버헤드와 높은 이식성을 제공하지만, 딥러닝 워크로드의 실행 시 시스템 자원의 비효율적 활용 문제가 발생할 수 있다.본 논문에서는 컨테이너 환경에서 딥러닝 워크로드 실행으로 인한 오버헤드와 비효율성을 분석하기 위해 시스템콜 및이벤트 추적 트레이스를 수집 및 분석하였다. 특히, 동일한 워크로드를 호스트 머신에서 직접 실행한 경우와 컨테이너환경에서 실행한 경우를 비교하여 자원 소비 및 간섭과 관련된 컨테이너 환경의 오버헤드를 정량적으로 확인하였다. 분석 결과 딥러닝 워크로드의 컨테이너 실행 시 성능 병목을 초래하는 주요 원인으로 주기적인 스토리지 플러시 작업이확인되었으며, 다중 테넌트 환경에서는 자원 경합으로 인해 이러한 문제가 더욱 심화됨을 확인하였다. 본 연구의 결과는컨테이너 환경에서 딥러닝 워크로드를 효율적으로 실행하기 위한 클라우드 및 엣지 시스템 설계에 중요한 인사이트를제공할 수 있을 것으로 기대된다.","The execution of deep learning workloads in containerized environments has become increasingly common. While containers offer lower overhead and greater portability compared to virtual machines, they may lead to inefficiencies in system resource utilization during workload execution. This paper investigates the overhead and inefficiencies associated with containerized execution of deep learning workloads by collecting and analyzing system call and event traces. In particular, a comparative analysis was conducted to quantitatively evaluate the overheads related to resource consumption and interference by executing identical workloads directly on the host machine and within a containerized environment. The analysis identifies periodic storage flush operations as a key source of performance bottlenecks in containerized deep learning workloads. Furthermore, it was observed that resource contention exacerbates these issues in multi-tenant environments. The findings of this study are expected to provide valuable insights for designing cloud and edge systems to optimize the execution of deep learning workloads in containerized environments."
ML-Agents를 활용한 라인추적 로봇의 강화학습 성능 최적화: 보상 전략과 학습 파라미터에 관한 비교 연구,2025,"['디지털 트윈', '라인추적로봇', '강화학습', '유니티', '유니티 머신러닝 에이전트', 'PPO(Proximal Policy Optimization)', 'Digital Twin', 'Line Follower Robot', 'PPO', 'Reinforcement Learning', 'Unity 3D', 'Unity ml-agents']","디지털 트윈 기반 강화학습(Reinforcement Learning) 접근법을 통해 실제 시스템의 동작을 정밀하게 반영한가상 모델을 설계하고 시뮬레이션 기반 실험을 반복 수행함으로써 물리적 비용과 위험을 최소화할 수 있는 장점이 있다.본 연구는 Unity ML-Agents 기반 라인 추적 로봇의 강화학습 성능 최적화를 위해 다양한 학습 변수 조합을 분석했다.무작위 생성된 라인 환경에서 총 48건의 실험을 통해 PPO Curiosity, 네트워크 깊이, Negative 보상, 이전 행동값관측, ΔAction Value Limit의 영향을 평가했다. 전체 실험 중 15건(31%)이 수십 분 내에 학습에 성공했으며, Δ Action Value Limit 제약이 없을 경우 33%의 높은 학습 성공률을 보였으나 리워드 최대화를 위한 급회전이 빈번했다.반면 제약 적용 시 성공률은 29%로 감소했지만 주행 안정성이 향상되었다. 실험 결과, Curiosity를 사용하지 않고, 네트워크 깊이 1, Negative 보상 0.00003 조합이 주행과 학습 안정성 측면에서 최적의 성능을 보였다. 이는 실시간 카메라입력을 CPU만으로 처리하는 환경에서도 강화학습 접근법이 실용적임을 보여주며, 기존 PID 제어 방식 대비 강화학습기반 제어가 다양한 조건에서 뛰어난 적응성과 성능 잠재력을 지님을 시사한다.","Digital twin-based reinforcement learning enables minimizing physical costs and risks by using virtual models that accurately reflect real systems. This study analyzes various learning parameter combinations to optimize line tracking robots based on Unity ML-Agents. Through 48 experiments with randomly generated paths, we evaluated the impact of PPO Curiosity, network depth, negative rewards, previous action observation, and ΔAction Value Limit. Of the experiments, 31% successfully completed learning within tens of minutes. Without ΔAction Value constraints, success rates reached 33% but with frequent abrupt turns; with constraints applied, rates decreased to 29% while improving driving stability.Results showed optimal performance was achieved with no Curiosity, network depth of 1, and negative reward of 0.00003, providing the best driving and learning stability. Our findings demonstrate that reinforcement learning approaches are practical even when processing real-time camera inputs with only CPU resources, suggesting superior adaptability and performance potential compared to traditional PID control methods across varied conditions."
빅데이터 분석을 통한 AI 영어학습에 대한 사용자 인식 연구: 최근 3년간의 소셜 미디어 데이터를 중심으로,2025,"['AI 영어학습', '빅데이터분석', '텍스트마이닝', '사용자경험', '챗지피티', 'AI English learning', 'Big data analysis', 'Text mining', 'User Experience (UX)', 'ChatGPT']","본 연구는 2022년 1월부터 2025년 1월까지의 온라인 빅데이터를 활용하여 ChatGPT를 비롯한 생성형 AI 기반 영어학습에 대한 사용자 인식을 분석하였다. 텍스트 마이닝 방법론을 적용한 결과, 사용자들은 대화형 학습환경과 개인화된 맞춤형 콘텐츠에 높은 관심을 보였으며, 즉각적인 피드백과 개인 수준에 맞춘 학습 경험을 선호하는 것으로 나타났다. ChatGPT가 음성인식이나 기계번역 도구와 결합될 때 학습 만족도가 높아지는 시너지 효과가 확인되었으며, CONCOR 분석에서는 AI 학습 도구가 전통적 교육체제와 상호보완적 관계를 형성할 가능성이 시사되었다. 그러나 발음 교정의 정확도 부족과 AI 의존도 증가에 따른 자기주도 학습 기회 감소 등의 우려도 제기되었다. 본 연구는 성공적인 AI 영어학습 환경 구축을 위해 알고리즘 개발뿐 아니라 학습자 맥락에 부합하는 콘텐츠 기획이 필요함을 제시하였다.","This study analyzed user perceptions of AI-based English learning, particularly ChatGPT, using online big data from January 2022 to January 2025. Text mining methodologies revealed significant user interest in interactive learning environments and personalized content with immediate feedback tailored to individual needs. A notable synergy effect emerged when ChatGPT was combined with speech recognition or machine translation tools, enhancing features like pronunciation correction and conversation practice. CONCOR analysis indicated complementary relationships between AI tools and traditional educational systems, suggesting potential for a richer learning ecosystem. User concerns included insufficient accuracy in pronunciation assessment and reduced self-directed learning opportunities due to AI dependence. The research effectively captured diverse opinions often missed in conventional surveys, concluding that successful AI-based English learning environments require both innovative algorithms and content planning aligned with learner contexts."
교양 한국어과정 강사 대상 기계번역 리터러시 교육 자료의 개발과 적용 사례,2025,"['Machine Translation Literacy', 'Academic Korean Education', 'Instructor Training Program', 'Pre-editing', 'Post-editing', '기계번역 리터러시', '교양 한국어 과정', '강사 교육', '프리에디팅', '포스트에디팅']","본 연구는 대학 교양과정에서 학문 목적 한국어를 가르치는 강사들을 대상으로 기계번역 리터러시 교육 프로그램을 개발하고 이를 기반으로 강사 워크숍을 시행한 후, 실제 교육 현장에서의 적용 양상을 고찰하는 데 목적이 있다. 여기서는 기계번역 리터러시의 구성 요소를 (1) 기술적 이해 및 활용, (2) 입력 최적화 및 결과물 개선, (3) 비판적 평가와 윤리적 사용, (4) 교육적 통합 및 학습 지원으로 구분하여 이를 반영한 교육 프로그램을 개발하였다. 프로그램을 기반으로 강사 워크숍을 진행한 결과, 교수자들은 교육 내용의 실용성과 현장 적용 가능성에 높은 만족도를 보였다. 또한, 프리에디팅과 포스트에디팅 방법을 포함한 기계번역 기술 활용에 대한 교수자들의 이해도가 향상된 것으로 나타났다. 그러나 학기 중 학습자를 대상으로 기계번역 리터러시 교육을 실시한 교수자는 소수에 불과하였으며, 교육 시간 역시 제한적인 것으로 나타나 추가적인 연구와 자료 개발의 필요성이 제기되었다. 향후 연구에서는 학습자의 수준과 모국어를 고려한 맞춤형 교육 자료를 개발하고, 학습자의 메타언어적 인식을 제고할 수 있는 다양한 학습 보조 자료를 마련할 필요가 있을 것이다.","This study aims to develop a machine translation literacy education program for instructors teaching academic Korean in university liberal arts courses and to examine its application in actual educational settings through a workshop. The components of machine translation literacy were categorized into (1) technical understanding and utilization, (2) input optimization and output improvement, (3) critical evaluation and ethical use, and (4) educational integration and learning support. Based on these components, an educational program was developed, and a workshop was conducted. The results showed that the instructors expressed high satisfaction with the practicality of the program and its applicability to educational contexts. Additionally, the instructors’ understanding of machine translation techniques, including pre-editing and post-editing methods, improved significantly. However, only a small number of instructors implemented machine translation literacy education for students during the semester, and the education time was also limited, highlighting the need for further research and material development. Future research should focus on creating tailored educational resources that consider learners’ proficiency levels and native languages and developing diverse supplementary materials to enhance learners’ metalinguistic awareness."
미계측 지역 하천 유출량 예측을 위한 앙상블 러닝의 수문학 및 수학적 프레임워크,2025,"['Ensemble learning', 'ELQ', 'River discharge', 'Congo River', 'Mekong River', 'Satellite altimetry', 'Weak learner', '앙상블 러닝', '앙상블 러닝 회귀법', '하천 유출량', '콩고강', '메콩강', '위성 고도계', '약한 학습자']","전 세계적으로 하천 유출량(Q)을 정확히 예측하는 것은 홍수조절, 가뭄관리 등 수자원 관리에 필수적인 요소이지만, 전 세계적으로 Q를 산출하고 추정하기 위한 현장 게이지의 숫자는 감소추세에 있다. 또한 공유하천이나 메콩강처럼 특수한 수문학적 특징을 보이는 하천의 유량은 기존 수문학적 방법으로 유출량을 산정하기에는 어려움이 따른다. 전통적으로 하천 유출량을 구하는 대표적인 방법들로 Leopold and Maddock (1953)이 제시한 at-a-station hydraulic geometry (AHG)를 이용한 경험 멱함수(empirical power function)와Manning (1889)이 제안한Manning’s equation을 이용한 방법 등이 있다. 최근 Kim et al. (2019a; 2019b; 2021)은 앙상블 러닝 회귀법(ensemble learning regression for estimating Q, ELQ)이라는 머신러닝 기법을 통해 콩고강과 메콩강 일대의 하천 유출량 예측 정확도를 향상시켰다. 그러나 ELQ의 우수성에도 불구하고 ELQ의 수학적·수문학적 프레임워크(framework)에 대해 자세히 연구된 바는 없다. 본 리뷰 연구에서는 ELQ 관련 논문들을 분석하여, ELQ가 기존 하천 유출량 예측기법과 차별화되는 수학적·수문학적 의의를 살펴보고, 여러 국제논문에서 인용된 사례를 분석했다. 이로써 ELQ기법이 원격탐사 수문학에 기여하는 바를 도출하여, 향후 국내·외 원격탐사 수문학에 활용되어 보다 정확한 하천 유출량을 예측하는 방법이 되기를 기대한다.","Accurate estimation of river discharge (Q) globally is essential for water resources management, including flood control and drought management. However, the number of stream gauges globally used to calculate Q is decreasing. Additionally, estimating Q of transboundary rivers or rivers with unique hydrological characteristics, such as the Mekong River, is challenging using traditional hydrological methods. The most representative methods for estimating Qhave been the empirical power function using at-a-station hydraulic geometry (AHG) proposed by Leopold and Maddock (1953) and the method using Manning’s equation proposed by Manning (1889). Recently, Kim et al. (2019a; 2019b; 2021) improved the accuracy of Qestimation in the Congo and Mekong River Basins using ensemble learning regression for estimating Q(ELQ). However, despite ELQ’s superior performance, its mathematical and hydrological framework has not been studied in detail. This review study analyzed relevant papers to understand the mathematical and hydrological significance of ELQ, which differentiates it from existing Q prediction techniques. We also analyzed cases cited in other international papers. Through this analysis, we expect to draw the contribution of the ELQ method for estimating Qto remote sensing hydrology domestically and internationally."
생성형 AI를 활용한 한영번역 자기주도 학습과 학습자 인식: 학부생 스터디를 중심으로,2025,"['기계번역(machine translation)', '생성형 AI(generative AI)', '자가학습(self-directed learning)', '챗지피티(ChatGPT)', '포스트에디팅(post-editing)', '학습자 인식(learner’s perception)', '한영(Korean-English)']",,"This study explores undergraduate students’ approach to the use of generative artificial intelligence (AI) such as ChatGPT in Korean into English translation study group and their perceptions. The findings reveal that students tend to offer a correct feedback to the peers’ postediting in terms of clarity and coverage, while they sometimes provide incorrect feedback on the use of vocabulary and expression due to their poor English skills. Students revealed their positive attitude toward a group study, addressing that it enhances motivation and sense of responsibility. In light of these findings, this study suggests AI as a powerful tool for self-directed translation learning in a group study environment."
스마트폰용 미세형상 사출성형부품의 품질검사 자동화를 위한 양불판정 학습시스템 개발,2025,"['AI Learning System', 'High Precision', 'Immediate Application', 'Quality Inspection', 'Smartphone Micro-shaped Parts']",,"This study was conducted to develop an AI-based learning system to automate the quality inspection of micro-shaped injection molded parts such as smartphone cameras. Existing machine vision-based quality inspection systems have limitations in that they cannot sufficiently recognize various shapes and types of defects and have limited inspection areas. In particular, micro-shaped parts such as smartphone camera modules contain metal lead frames with a thickness of 0.1 mm or less, so existing manual inspection methods have limitations in maintaining high productivity and quality. In this study, a deep neural network based on CNN (Convolutional Neural Network) was applied to automate high-precision quality inspection, and a dataset using high-resolution images of 11.94 million pixels was constructed. During the data collection process, 400 good products and 3,300 defective products were secured, and various types of defects were prepared to be learned through data augmentation techniques. As a result of model learning, it was confirmed that the accuracy was 95.2% and the F1-Score was 94.2%, which improved the performance by about 15% and shortened the inspection time by 30% compared to the existing manual inspection method. The AI-based quality inspection system developed in this study can be effectively applied to the mass production environment of micro-shaped injection molded parts, and it is expected to complement the limitations of the existing quality inspection method. Future research will include additional expansion of defect types, improvement of real-time inspection speed, and review of applicability to various materials and parts."
생성형 딥러닝 모델을 이용한 대퇴골두 무혈성 괴사 데이터 증강,2025,"['Deep Learning', 'Generative Adversarial Networks', 'Medical Image', 'Avascular Necrosis', 'Data Augmentation', '딥러닝', '적대적 생성모델', '의학 영상', '대퇴골두 무혈성 괴사', '데이터 증강']","인공지능 기술의 발전으로 머신러닝과 딥러닝이 의료 분야에서 주목받고 있으나, 적은 데이터셋에서는 성능 향상에 한계가 있다. 본 연구는 1,354개의 무혈관 괴사(AVN) 이미지를 사용해 StyleGAN2와 Projected-GAN의 성능을 비교하였다. 실험 결과, StyleGAN2는 FID 점수 67.0과 40시간의 학습 시간이 소요된 반면, Projected-GAN은 FID 8.7과 22시간으로 더 우수한 성능을 보였다. Projected-GAN으로 증강된 데이터를 사용한 예측 성능은 72.68%로, 기존 데이터의 61.34%보다 향상되었음을 확인했다. 물론, 기본적인 모델의 분류 성능이 상대적으로 낮다는 점을 감안할 때 추가적인 검증과 신중한 해석이 필요하지만, 이러한 결과는 의료 영상 분석과 진단 보조에 유용한 도구로 사용될 가능성을 시사한다.","With the advancement of AI, machine learning and deep learning are gaining attention in the medical field. This study compares the performance of StyleGAN2 and Projected-GAN using 1,354 AVN images. StyleGAN2 achieved an FID score of 67.0 with 40 hours of training, while Projected-GAN showed superior performance with an FID score of 8.7 in 22 hours. Projected-GAN improved prediction accuracy to 72.68%, up from 61.34% using only the original data. These results suggest Projected-GAN could be a valuable tool for medical image analysis."
SEER 데이터를 이용한 다양한 딥러닝 생존분석 모형들의 비교연구,2025,"['생존분석', 'AORSF', 'DeepHit', 'DeepSurv', 'SEER', 'survival analysis', 'AORSF', 'DeepHit', 'DeepSurv', 'SEER']","생존분석은 관심 사건이 발생할 때까지의 시간을 분석하는 방법으로, 다양한 분야에 적용이 가능하다. 최근 딥러닝 분야가 주목받으면서 생존 데이터를 분석하기 위해 딥러닝 모형을 활용하려는 관심이 증가하고 있다. 이에 본 연구는 생존분석에서 흔히 사용되는 전통적인 생존분석 모형과 딥러닝 모형의 성능을 비교하는 것을 목표로 한다. 비교된 모형들은 Cox-PH모형, AFT모형, RSF AORSF 같은 머신러닝 모형, 그리고 DeepSurv DeepHit 같은 딥러닝 모형으로 총 6가지이다. 표본 크기에 따른 선형 및 비선형 위험 함수 하에서 광범위한 모의실험이 수행되었으며, 다양한 절단율에 따른 모형 성능을 비교하였다. 또한, SEER 데이터에서 갑상선암과 폐암 데이터를 사용한 실증 분석을 통해 실제 데이터에서의 모형 성능을 평가하였다.","Survival analysis is a method used to examine the time until the occurrence of an event of interest and can be applied across various fields. With the increasing attention given to the field of deep learning, there has been a growing interest in utilizing deep learning models to analyze survival data. In this context, our study aims to compare the performance of traditional statistical models commonly used in survival analysis with that of deep learning models. The models considered include the Cox proportional hazards (Cox-PH) model, the accelerated failure time (AFT) model, machine learning models such as the random survival forest (RSF) and accelerated oblique random survival forest (AORSF), as well as deep learning models such as DeepSurv and DeepHit, resulting in a total of six models. For a range of sample sizes, extensive simulation studies were conducted under both linear and nonlinear log-risk functions, with model performance compared across varying censoring rates. Additionally, an empirical analyses using thyroid cancer and lung cancer data from the SEER database were performed to evaluate model performance on real-world data."
특징 중요도 기반 앙상블 학습과 변이 도메인 탐지를 활용한 실시간 악성 URL 탐지 시스템,2025,"['Browser extension', 'Ensemble learning', 'Feature importance analysis', 'Malicious URL detection', 'Variant domain detection']","최근 HTTPS 인증서를 악용한 피싱 공격이 증가하면서 기존의 블랙리스트 기반 탐지 방식으로는 효과적인 대응이 어려워 지고 있다. 본 논문에서는 다중 특징 중요도 기반의 앙상블 학습과 변이 도메인 탐지를 결합한 실시간 악성 URL 탐지 시스템 SHIELD를 제안한다. 제안하는 시스템은 Random Forest, XGBoost 등 11개의 머신러닝 알고리즘을 결합한 앙상블 모델을 기반 으로 하며, 기본적인 URL 특징 26가지를 분석하여 가중치를 최적화한다. 여기에 문자 치환 패턴, 시각적 유사도, 도메인 구조 분석 등 3가지 변이 도메인 탐지 특징을 추가로 도입하여 탐지 정확도를 향상시켰다. 실험 결과, 제안된 시스템은 87.72%의 정 확도와 0.9320의 ROC AUC 점수를 달성하였으며, 브라우저 확장 프로그램 형태로 구현되어 실시간 보안 위협에 효과적으로 대 응할 수 있음을 확인하였다.","As phishing attacks exploiting HTTPS certificates increase, conventional blacklist-based detection methods are becoming less effective. This paper proposes SHIELD, a real-time malicious URL detection system that combines multi-feature importance-based ensemble learning with variant domain detection. The proposed system is based on an ensemble model combining 11 machine learn ing algorithms including Random Forest and XGBoost, and utilizes 26 basic URL features for weight optimization. The system’s de tection accuracy was improved by introducing three additional features for variant domain detection: character substitution patterns, visual similarity, and domain structure analysis. Experimental results show that the proposed system achieved 87.72% accuracy and 0.9320 ROC AUC score, and confirmed its effectiveness in responding to real-time security threats through implementation as a browser extension."
COVID-19 전후 학습관리기술의 특허 비교분석 : WIPO 상위 10개국을 중심으로,2025,"['학습관리시스템', 'LMS', '특허활동', 'COVID-19', '온라인교육', '에듀테크', 'Learning Management System', 'LMS', 'Patent Activity', 'COVID-19', 'Online Education', 'EduTech']","본 연구는 COVID-19 팬데믹 전후 학습관리시스템(LMS) 관련 특허 동향을 비교하여 디지털 전환및 교육기술 관점에서 국가 간 기술 역량 변화를 살펴보고자 했다. 2017년부터 2022년까지 WIPO 특허 출원 상위 10개국에 출원된 3,142건 특허를 분석한 결과, 첫째, 미국·독일·한국을 포함한 10개국의LMS 특허가 팬데믹 이후 전자·디지털 기반 학습 보조기기 전반을 포괄하는 기술군인 전기식 교육장치(G09B 5/)와 머신러닝·뉴럴넷 등의 AI 알고리즘 분야를 중심으로 약 36% 증가했다. 둘째, 팬데믹 이전에도 우위를 보였던 미국은 여전히 총량에서 선두를 유지하지만, 팬데믹 이후 한국·독일이고가치 특허 비중을 높이면서 질적 역량을 강화하는 추세를 보였다. 셋째, Q&A식 장치 등 일부 전통적 교육기기는 줄어든 반면 AI 알고리즘·디지털 하드웨어 융합 기술이 늘어나면서 LMS 분야가다각도로 확장되고 있었다. 본 연구는 컴퓨터 교육·원격교육 분야에서의 글로벌 특허 동향을 제시하며 차세대 디지털 학습환경 및 R&D 전략 수립에 기초자료가 될 수 있을 것이다.","This study examines changes in national technological capabilities related to Learning Management Systems (LMS) before and after the COVID-19 pandemic, from the perspectives of digital transformation and educational technology. We analyzed 3,142 patents filed between 2017 and 2022 in the top 10 WIPO countries. Our findings reveal three main observations. First, LMS patents rose by about 36% after the pandemic, driven primarily by electronics-based educational devices (G09B 5/) and AI algorithms such as machine learning and neural networks. Second, the United States maintained its overall lead, yet Korea and Germany strengthened their share of high-value patents after COVID-19.Third, while some traditional educational devices (e.g., Q&A-based apparatus) declined, the convergence of AI algorithms and digital hardware increased, leading to a broader expansion of LMS technologies.By presenting global patent trends in computer and distance education, this study provides a valuable reference for developing next-generation digital learning environments and R&D strategies."
AI(인공지능)는 어떻게 학습장애 아동의 읽기이해를 진단하는가?: 초등학생 맞춤형 인지진단모형(CDM)의 적용과 타당화,2025,"['학습장애', '읽기이해', '인지진단모형', 'Fusion 모형', '인공지능 기반 평가', 'Learning Disabilities', 'Reading Comprehension', 'Cognitive Diagnosis Model (CDM)', 'Fusion Model', 'AI-Based Assessment']","본 연구는 초등학교 3~6학년 학생들의 읽기이해 능력을 보다 정밀하게 진단하기 위해 Fusion 모형을 활용한 평가의 타당성을 검증하는 것을 목적으로 한다. 이를 통해 개별 학생의 인지적 강점과 약점을 분석하여 맞춤형 교수학습 전략을 제안하고자 한다. 연구 대상은 초등학교 3~6학년 학생이며, BASA 읽기이해 검사를 시행하였다. Fusion 모형을 적용하여 학생들의 수행 데이터를 분석하고, Q-행렬(Q-matrix)의 타당성을 검증하였다. 연구 결과, Fusion 모형은 기존 평가 방식보다 학생 개개인의 읽기이해 수준을 더욱 정밀하게 진단할 수 있는 것으로 나타났다. 또한, Q-행렬 검증 결과, 평가 문항과 인지 요소들의 관계가 통계적으로 유의미함을 확인하였다. 본 연구는 Fusion 모형이 초등학생의 읽기이해 능력을 효과적으로 평가할 수 있는 도구임을 입증하였다. 이를 바탕으로, 학년별 맞춤형 교육 전략을 개발하고 CDM 기반의 개별화 평가 시스템 도입을 제안한다. 특히 Fusion 모형은 머신러닝 기법을 응용하여 문항 반응 패턴을 기반으로 학습자의 인지적 특성을 다차원적으로 분석하는 인공지능 기반 진단 모델로, 기존 평가 도구보다 높은 진단 정밀도와 적응성을 보장할 수 있을 것으로 기대한다.","This study aims to verify the validity of an assessment using the Fusion model to more precisely diagnose the reading comprehension ability of students in grades 3~6. Through this, we aim to analyze the cognitive strengths and weaknesses of individual students and propose customized teaching and learning strategies. The study subjects were 499 students in grades 3 to 6 of elementary school, and the BASA reading comprehension test was administered. The performance data of the students was analyzed using the Fusion model, and the validity of the Q-matrix was verified. The results of the study showed that the Fusion model can more accurately diagnose the reading comprehension level of individual students than the existing evaluation method. In addition, the Q-matrix verification results confirmed that the relationship between the evaluation items and cognitive factors was statistically significant. This study demonstrated that the Fusion model is an effective tool for assessing the reading comprehension ability of elementary school students. Based on this, we propose the development of customized educational strategies for each grade and the introduction of an individualization assessment system based on the CDM. In particular, the Fusion model applies machine learning techniques to analyze students’ cognitive attributes in a multidimensional way based on their item response patterns. As an AI-based diagnostic model, it is expected to provide greater diagnostic precision and adaptability compared to traditional assessment tools."
PET: 로봇 조작 학습의 계산 효율성 및 메모리 사용량  개선을 위한 Perceiver Element-wise Transformer 연구,2025,"['Robotic Transformer', 'Perceiver IO', 'Attention-Free Transformer', 'Robotic Manipulation', 'Reinforcement Learning']",,"We propose the Perceiver Element-wise Transformer (PET), a novel model that combines the latent space and cross-attention mechanisms of Perceiver IO with the Attention-Free Transformer (AFT) to enhance computational efficiency and memory usage. The Perceiver IO effectively manages large-scale input data, while the AFT replaces the traditional dot-product operation with element-wise multiplication, significantly reducing computational complexity and memory consumption. Our experiments, conducted in complex robotic control environments, demonstrate that PET reduces computation time by 11%, achieves lower loss values, and improves overall test scores. These findings validate the superior performance of our proposed model in terms of both generalization and resource efficiency. Overall, the results suggest that PET is a promising solution for large-scale machine learning tasks, advancing the capabilities of the Transformer architecture."
N-gram을 활용한 특수목적중국어의 어휘다발 연구: AI-Hub 학습용 데이터를 중심으로,2025,"['AI-Hub', 'N-gram', 'Chinese for Specific Puposes(CSP)', 'Lexical Bundles', 'Travel Chinese', 'AI-Hub', 'N-gram', '특수목적중국어', '어휘다발', '관광중국어']",,"In this study, as the demand for tourism increases in Korea-China relations, the need for tourism vocabulary learning is increasing when using apps and machine translation. Therefore, in order to construct basic data necessary for learning tourism Chinese vocabulary, the type of N-gram vocabulary was analyzed based on a native Chinese corpus on the AI-Hub platform.As a result of the analysis, in the 2-gram, many high-frequency vocabulary bundles similar to the types appearing in general-purpose Chinese learning contents appeared. The characteristic of the 3-gram vocabulary bundle is that adverbs occupy a large proportion in the tourist Chinese vocabulary list. The characteristic of the 4-gram vocabulary bundle is that it can be used as an independent expression as a lot of professional vocabulary appears and syllables grow.Next, tourism Chinese vocabulary was categorized, classified into verb phrases and noun phrases, and analyzed through frequency of use and example sentences.The verb phrase is a type of 'pronoun + auxiliary verb + verb', and includes 我 想 去, 我 想 买, and 你 能 告诉. In addition, auxiliary verb 能 often appears in dialogues. The noun phrase was categorized into 'investigation + noun' and 'association + noun', and the biggest feature is that vocabulary bundles that include professional vocabulary 飞机, 着陆, 登机, 航班, and 预 settings appear frequently in 4-gram."
딥러닝을 이용한 효과적인 액화 수소 폭발 압력 예측,2025,"['액화수소폭발압력예측', 'CFD기반머신러닝', '액화수소폭발', '액화충전소폭발', '수소안전', '방호벽', 'predict pressure', 'liquid hydrogen blast', 'hydrogen storage', 'explosion barrier', 'safe hydrogen']","수소 에너지에 대한 관심이 높아짐에 따라 액화 수소의 저장 효율성과 안전에 대한 연구가 중요해지고 있다. 본 연구는 전산 유체 역학(CFD) 시뮬레이션 데이터를 활용하여 액화 수소 충전소 방호벽 후면의 폭발 압력을 예측하고자 딥러닝 모델인 다층 퍼셉트론(MLP), 장단기 기억 모델(LSTM), 트랜스포머(Transformer), 시간 합성곱 신경망(TCN)을 적용하였다. 그 결과, LSTM 모델이 결정계수() 0.997, 평균 제곱오차(MSE) 0.006으로 가장 우수한 성능을 보였다. 학습된 모델은 CFD 대비 빠르고 실시간에 가까운 예측이 가능하며, 방호벽 설계 시 비용 및 시간 절감 효과와 안전성 평가 도구로 활용될 수 있다. 이는 수소 충전소의 설계 및 시민 수용성 확보에 실질적 기여가 가능하다.","As hydrogen emerges as a key clean energy source, the safety of liquid hydrogen storage has become increasingly important. This study applies deep learning models—MLP, LSTM, Transformer, and TCN—to predict explosion pressure behind the barrier walls of liquid hydrogen refueling stations using CFD simulation data. Among these, the LSTM model showed superior performance with an average  of 0.997 and MSE of 0.006. The trained model can deliver near real-time predictions comparable to CFD simulations while significantly reducing computation time and cost. This enables efficient evaluation of barrier configurations and contributes to the safe design of hydrogen refueling stations. Furthermore, it can serve as a practical tool in public communication and risk assessment, thereby supporting broader acceptance and implementation of hydrogen infrastructure."
DeepTRACK: 딥러닝 기반 중환자 퇴실에 따른 상태 악화 위험 예측 시스템,2025,"['clinical decision support system', 'readmission', 'mortality', 'deterioration after discharge', 'artificial intelligence', 'machine learning', '임상의사결정시스템', '재입실', '사망', '퇴실 후 악화율', '인공지능', '기계학습']","적절한 중환자실 퇴실 시점을 정하지 못하거나 퇴실한 환자가 재입실하는 경우 추가적인 의료비용 발생, 환자의 고통 증가 그리고 의료진의 업무 부담 증가 등 다양한 문제가 발생한다. 하지만, 퇴실 시점을 예측하는 것은 매우 어려운 작업이며 전적으로 의료진의 판단에 맡기고 있다. 본 연구에서는 중환자실 퇴실 여부 결정을 돕기 위해 기록된 환자의 상태를 기반으로 퇴실 후 7일 이내 재입실 또는 사망 여부를 예측하는 시스템인 DeepTRACK을 개발했다. 환자 정보는 1일 단위로 기록된 시계열 데이터이며 결측값이 존재할 수 있다. 우리는 결측값이 존재하는 시계열을 다루기 위해 결측값 보간 기능을 갖고 있는 GRU-D++ 모델을 사용했다. 실험 데이터는 MIMIC-IV 2.2를 사용했으며 실험 결과 AUROC 0.772를 달성해 개발한 시스템이 기존에 사용되던 임상지표인 SWIFT 점수보다 더 높은 정확도를 갖고 있음을 확인했다.","Failing to determine the appropriate discharge time from the Intensive Care Unit (ICU) or the need for readmission to the ICU can lead to various problems, including additional medical costs, heightened patient suffering, and increased workload for medical staff. However, predicting the optimal discharge time remains challenging and is currently reliant solely on clinician judgment. In this study, we developed a predictive system, DeepTRACK, to estimate the likelihood of a patient being readmitted or dying within seven days after discharge, using the daily recorded patient data that may contain missing values. To handle missing values and time series, we employed the GRU-D++ model, which includes a missing value imputation mechanism. We evaluated our proposed system using the MIMIC-IV 2.2 dataset, achieving an AUROC of 0.772, which demonstrates significantly higher accuracy than the existing clinical indicator, the SWIFT score."
멀티모달 학습과 딥러닝 기반 암호화폐 가격 등락 예측,2025,"['암호화폐', '딥러닝', '합성곱신경망', '멀티모달', '감성분석', 'Cryptocurrency', 'Deep learning', 'CNN', 'Multimodal', 'Sentiment analysis']","암호화폐는 물리적 실체가 없는 디지털 자산이며, 전통 금융 자산과의 낮은 가치 연관성으로 인해 시장이 불안정하고 변동성이 매우 크다는 특징을 지닌다. 이러한 불확실성을 줄이기 위해 정확한 시장 예측의 필요성이 증대되고 있으나, 암호화폐는 내재가치 측정이 어려워 가격 예측이 난해하다는 한계가 존재한다. 선행 연구에 따르면 암호화폐 가격은 기술적 지표뿐만 아니라 시장 매력도, 대중의 관심, 뉴스 감성과 같은 정성적 지표에 크게 영향을 받는 것으로 알려져 있다. 특히, 최근 미디어 발달로 다양한 멀티모달 데이터가 생성됨에 따라, 이를 통합 분석하여 단일 모달리티의 한계를 극복하고자 하는 연구가 활발히 진행되고 있다. 이러한 배경 하에 본 연구는 암호화폐 관련 오디오 데이터의 감성 분석 결과를 활용한 비트코인 가격 등락 예측 모델을 제안한다. 구체적으로, 비트코인 가격 기반 기술적 지표, 대중의 관심도를 반영하는 구글 트렌드 검색 빈도, 뉴스 텍스트 감성 분석 결과, 그리고 비트코인 관련 뉴스 영상 및 팟캐스트의 오디오 감성 분석 데이터를 입력 변수로 활용하였다. 이를 바탕으로 로짓, 서포트 벡터 머신, RNN, CNN 기반의 비트코인 가격 등락 예측 모형을 구축하고 성능을 비교 평가하였다. 실험 결과, 오디오 감성 분석 데이터를 추가적으로 활용한 CNN 기반 모형이 가장 우수한 예측 성능을 나타냈다. 이는 이미지 및 영상 처리에 주로 사용되던 CNN 모델이 복잡한 금융 시계열 데이터 예측에도 효과적일 수 있으며, 특히 오디오 감성 분석 데이터가 암호화폐 가격 등락 예측 모형의 성능 향상에 기여할 수 있음을 시사한다.","Cryptocurrency, as digital assets lacking physical substance, exhibit market instability and high volatility attributed to their low correlation with traditional financial assets. The imperative for accurate market prediction has intensified to mitigate this inherent uncertainty. However, cryptocurrencies present challenges for price prediction owing to the inherent difficulty in assessing their intrinsic value. Prior research demonstrates that cryptocurrency prices are significantly influenced not only by technical indicators but also by qualitative factors, including market attractiveness, public interest, and news sentiment. Furthermore, the proliferation of media has led to the generation of diverse multimodal data, prompting extensive research into integrated analysis techniques to overcome the limitations inherent in unimodal approaches. In this context, this study proposes a Bitcoin price movement prediction model leveraging sentiment analysis derived from cryptocurrency-related audio data. Specifically, the input variables include technical indicators derived from Bitcoin price data, Google Trends search query volume, sentiment scores extracted from news text corpora, and audio sentiment analysis data derived from Bitcoin-related news sources, such as videos and podcasts. Leveraging this multi-faceted dataset, we construct and comparatively evaluate Bitcoin price movement prediction models based on Logistic Regression, SVM, RNN, and CNN. Empirical results indicate that the CNN-based model, incorporating audio sentiment analysis data, achieves superior predictive performance. This finding suggests that CNN models, conventionally employed for image and video processing, can be effectively adapted for complex financial time series prediction. Moreover, it highlights the potential of audio sentiment analysis data to enhance the accuracy of cryptocurrency price movement prediction models."
비상급수 자료 기반의 기계학습 기법을 활용한 가뭄 위험도 예측 기법 개발,2025,"['Drought', 'Emergency water supply', 'LightGBM', 'RandomForest', 'XGBoost', '가뭄', '비상급수자료', 'LightGBM', 'RandomForest', 'XGBoost']","본 연구는 인공지능 기법을 활용하여 가뭄 위험도를 예측하는 방법론을 개발하였다. 기존의 가뭄 예측 연구들은 다양한지수를 활용했지만, 실제 피해 사례를 반영한 연구는 부족하여 본 연구는 비상급수 자료를 활용하여 가뭄 피해의 위험도를정량적으로 평가하고 예측하는 기법을 개발하였다. 전라도 지역(여수, 완도, 임실, 정읍, 장수, 장흥, 고흥)을 대상으로 기상데이터(풍속, 기온, 습도, 일조량), 수문 데이터(댐 수위 및 방류량), 표준강수지수, 비상급수 발생 데이터를 수집하였다. 가뭄예측 모델로는 RandomForest, XGBoost, LightGBM을 적용하였으며, 3가지 사례(Case 1, Case 2, Case 3)로 성능 평가를 진행하였다. Case 1에서는 모든 지역의 데이터를 통합하여 학습 및 평가를 수행한 결과, 세 모델 모두 높은 정확도를 보였다. Case 2에서는 지역별로 데이터를 나누어 예측을 수행한 결과, 완도 지역을 제외한 대부분의 지역에서 성능이 저조하였다. Case 3에서는 완도 지역을 대상으로 최적화한 모델을 적용한 결과, 높은 예측 정확도를 확인하였다. 완도 지역에서의 예측 성능이가장 우수하였으며, 이는 해당 지역의 데이터가 충분히 확보되었기 때문으로 판단된다. 본 연구는 기존 연구들과 달리 실제피해 데이터를 활용하여 보다 실질적인 가뭄 위험 예측이 가능하다는 것을 확인하였다.","This study developed a methodology for predicting drought risk using machine learning techniques. While previous drought prediction studies have used various indices, few have incorporated actual impact or damage resulting from drought events. Hence, this research attempted to use emergency water supply data to quantitatively evaluate and predict drought risk. Data were collected for the Jeolla region (Yeosu, Wando, Imsil, Jeongeup, Jangsu, Jangheung, and Goheung), including meteorological data (wind speed, temperature, relative humidity, and sunshine hours), hydrological data (dam water levels and discharge), the Standardized Precipitation Index (SPI), and emergency water supply data.RandomForest, XGBoost, and LightGBM were applied as drought prediction models, and their performance was evaluated in three scenarios. In Case 1, where data from all regions were combined for training and evaluation, all three models showed high accuracy. In Case 2, the data were divided by region for prediction, and most regions showed low performance except Wando. In Case 3, a model optimized for Wando was applied, resulting in high predictive accuracy. Wando island’s superior performance is presumed to be due to the availability of sufficient data from that region. Unlike previous research, this study confirms that using actual damage data allows for more practical and effective drought risk prediction."
韓中科幻電影中賽博格角色的認知分析 ― 以《정이》與《未來警察》的人機接口位置爲例,2025,"['Conceptual Blending\xa0Theory(概念整合)', 'Conceptual Metaphor (概念隐喻)，Multimodal Text(多模態文本)， Cyborg (賽博格)', 'Cognitive Semiotics(認知符號學)']",,"This paper provides a detailed examination of the cognitive mechanisms employed in the depiction of cyborg interfaces in science fiction films, incorporating multimodal texts such as visual imagery and dialogue. The aforementioned discussion leads to the following conclusions.Firstly,a proposed “analytical procedure” for examining multimodal texts in science fiction films.Secondly,it demonstrates the “reasoning process” of specific cognitive mechanisms.The head interface integrates memory and function, and within the commercial context, is perceived by the audience as an exchangeable commodity. The neck interface triggers cognitive revision by violating the expected concept of ""blood,"" while the limb interfaces blur the boundary between blood and energy, enhancing the effect of human-machine fusion.Thirdly, the meaning-making process of multimodal texts in science fiction films holds practical significance; it is not merely a tool for learning and appreciation. Science fiction films can effectively serve as a realistic medium for embodied intelligent interaction."
CT-GAN을 활용한 중소기업 채무불이행 예측 연구,2025,"['Default Prediction', 'SMEs', 'Synthetic data', 'machine learning', 'CT-GAN', 'SHAP', '채무불이행 예측', '중소기업', '합성데이터', '머신러닝', 'CT-GAN', 'SHAP']","본 연구는 국내 A은행의 대규모 중소기업 데이터를 활용하여, 머신러닝(Machine Learning) 기반의 중소기업 채무불이행 예측 연구를 하였다. 2017년부터 2022년까지 5년 동안의 중소기업 대출 정보를 바탕으로 총 616,007개의 데이터를 이용하여 머신러닝 모형을 학습하였다. 일반적으로 채무불이행 예측을 위한 중소기업 데이터는 정상기업에 비해 채무불이행 기업의 수가 현저히 작은 불균형 데이터를 갖는다. 본 연구에서는 부족한 데이터수와 불균형 데이터를 보완하기 위해 정형데이터(tabular data)에 특화된 생성형 인공지능 기법인 CT-GAN(Conditional Tabular GAN)을 활용하여 합성데이터를 생성하였다. 합성데이터를 포함한 데이터를 기반으로 머신러닝 모형을 학습한 결과, 예측 성능이 향상된다는 것을 밝혔다. 머신러닝 모형 중에서는 XGBoost와 같은 나무계열 모형의 성능이 가장 우수했으며, 인공신경망 모형의 성능은 상대적으로 저조하였다. 본 연구에서는 설명가능한 인공지능(XAI)의 대표 기법인 SHAP을 활용하여 합성데이터를 이용하여 학습한 머신러닝 모형에 대한 중요 변수를 살펴보았는데, 합성데이터 생성 기법에 상관없이 이자보상비율 변수의 중요도가 가장 높은 것으로 나타났다. 본 연구는 국내 중소기업 신용평가 분야에 머신러닝 모형의 적용에 있어, 합성데이터 활용 가능성과 XAI 해석에 중요한 시사점을 제공한다.","In this paper, we study a machine learning-based prediction of SME defaults using large-scale SME data from Bank A in Korea. Based on SME loan information for five years from 2017 to 2022, a total of 616,007 data were collected and used to train machine learning models. In general, SME datasets for default prediction are highly imbalanced, with a significantly fewer default companies compared to normal companies. In this study, to compensate for insufficient number of data and imbalanced data, we generated synthetic data using CT-GAN(Conditional Tabular GAN), a generative artificial intelligence technique specialized in table data. By training machine learning models on datasets that included synthetic data, it was found that the predictive performance improved. Among the machine learning models, tree-based models such as XGBoost showed the best performance, while artificial neural network models performed relatively poorly. Additionally, this study used SHAP, a representative method of explainable artificial intelligence(XAI), to identify key variables in the machine learning models trained with synthetic data. Regardless of the synthetic data generation method used, the interest coverage ratio variable was found to be the most important.In this study, we provide important implications for the utilization of synthetic data and the interpretation of Explainable AI(XAI) in applying machine learning models to the credit evaluation field of SMEs in Korea."
SSD의 성능 및 수명 향상을 위한 데이터 수정 주기 예측 모델 가속화 방안,2025,"['SSD', 'Update Period', 'FPGA', 'WAF', 'Machine Learning']",,"An SSD (Solid State Drive) is a storage device based on NAND Flash Memory. Due to the discrepancy between the write and erase units, garbage collection (GC) must run to delete invalid data. This process duplicates valid data to other blocks, resulting in more writes than requested, which leads to Write Amplification (WA). The Write Amplification Factor (WAF) is the ratio of the actual written amount to the requested write amount, and reducing it is a critical research topic for SSD. Grouping data with similar update periods can reduce WA. Therefore, predicting the update periods of data and organizing them into groups is considered an important research direction. However, the future data update period cannot be known during the processing of wriring request. Recently, several studies have been conducted using machine learning to predict the update periods. Nevertheless, predicting update periods through machine learning can increase latency for SSD due to inference time. This study proposes offloading the computation of update period prediction models to FPGA to reduce inference latency caused by machine learning. Three workloads, including FIO, TPC-C, and Mail, are used in comparing no prediction of update periods, prediction using CPU, and prediction using FPGA. The results show that the inference time with FPGA was 1,244 times faster than with CPU alone. WAF and I/O latency were also measured using an SSD simulator with machine learning applied, demonstrating that reducing WAF through a machine learning model for workload characteristics can enhance SSD performance and lifespan."
저 사양 환경을 위한 경량 CNN 기반 자동차 휠 형상 분류,2025,"['Machine Learning', 'CNN(Convolutional Neural Network)', 'Wheel Classification', 'Automotive Wheel Manufacturing Process']",,"The casting manufacturing process of aluminum automotive wheels often involves processing various wheel models during stages such as flow forming, machining, packaging, and delivery. Traditionally, separate equipment or production lines were required for each model, which led to higher facility investment costs and increased labor costs for classification. However, the implementation of machine learning-based model classification technology has made it possible to automatically and accurately distinguish between different wheel models, resulting in significant cost savings and enhanced production efficiency. Additionally, this approach helps prevent product mix-ups during the final inspection process and allows for the quick and precise identification of wheel models during packaging and delivery, reducing shipping errors and improving customer satisfaction. Despite these benefits, the high cost of machine learning equipment presents a challenge for small and medium-sized enterprises(SMEs) to adopt such technologies. Therefore, this paper analyzes the characteristics of existing machine learning architectures applicable to the automotive wheel manufacturing process and proposes a custom CNN(Convolutional Neural Network) that can be used efficiently and cost-effectively."
담수호의 위성영상 기반 Multi-model Ensemble을 통한 TOC 예측,2025,"['총유기탄소', '위성영상', '머신러닝', 'Stacking 모형', 'HSIC-Lasso', 'Total Organic Carbon', 'Remote sensing', 'Machine learning', 'Stacking model', 'HSIC-Lasso']","본 연구는 위성 원격탐사와 머신러닝 기반 Multi-Ensemble 모델의 일종인 Stacking 모형을 결합하여 남양호에서 총유기탄소(Total Organic Carbon, TOC)를 간접적으로 추정하는 것을 목표로 하였다. Sentinel-2A/B 위성 데이터를 활용하여 연구 지역의 반사도 데이터를 구축하였으며, HSIC-Lasso 모델을 통해 TOC와 높은 상관성을 가지는 10개의 주요 입력변수(B4/B3, B4/B5, B2/B3, B8/B7, B4/B2, B1/B3, B1/B5, B8/B6, B5/B2, B2/B5)를 도출하였다. TOC를 예측하기 위해 Support Vector Regression (SVR), Random Forest Regression (RFR), eXtreme Gradient Boosting (XGB), Multi-Layer Perceptron (MLP)을 베이스모델로 사용하고, Partial Least Squares (PLS) 및 Ridge Regression (RID)를 포함한 6개의 메타모델을 결합한 Stacking Ensemble 모델을 개발하였다. Stacking 모델은 훈련 데이터와 테스트 데이터에서 각각 R² 값 0.963과 0.886, MAE 값 0.697 mg/L, RMSE 값 1.556 mg/L의 값을 보였으며, 단일 머신러닝 모델의 예측 성능보다 개선됨을 보여주었다. 본 연구 결과는 위성 데이터와 머신러닝 모델을 통합하여 TOC를 비용 효율적이고 지속 가능한 방식으로 모니터링할 수 있는 기반을 제시하며, 추후 장기간의 TOC 데이터 축적을 통해 수질 관리 및 정책 개발을 위한 실용적인 도구로 활용될 수 있을 것으로 기대된다.","This study aimed to indirectly estimate Total Organic Carbon (TOC) in the Namyang Reservoir using a combination of satellite remote sensing and a machine learning-based Multi-Ensemble model. Sentinel-2A/B satellite data were used to construct reflectance datasets for the study area, and the HSIC-Lasso model identified 10 significant input variables (B4/B3, B4/B5, B2/B3, B8/B7, B4/B2, B1/B3, B1/B5, B8/B6, B5/B2, B2/B5) highly correlated with TOC. To predict TOC, a Stacking Ensemble model was developed using Support Vector Regression (SVR), Random Forest Regression (RFR), eXtreme Gradient Boosting (XGB), and Multi-Layer Perceptron (MLP) as base models, combined with six metamodels, including Partial Least Squares (PLS) and Ridge Regression (RID). The Stacking model achieved the highest predictive performance with R2 values of 0.963(train) and 0.886(test), and MAE and RMSE values of 0.697 mg/L and 1.556 mg/L, respectively, outperforming individual machine learning models. This study integrates satellite data and machine learning models to establish a cost-effective and sustainable framework for monitoring TOC. The accumulation of long-term TOC data is expected to enhance its applicability as a practical tool for water quality management and policy development."
Real-Time Wildfire Monitoring via Geostationary Satellite and Artificial Intelligence: Insights from the March 2025 South Korea Wildfires,2025,"['Wildfire detection', 'Machine learning', 'GEO-KOMPSAT-2A', 'Real-time monitoring', 'Early warning', 'Disaster management', 'Climate change']",,"In March 2025, multiple large-scale wildfires simultaneously broke out across South Korea and rapidly spread to neighboring municipalities, resulting in the most extensive wildfire damage in the nation’s recorded history. Despite the severity of the event, ground-based suppression systems exhibited critical limitations in early detection and timely response. While satellite-based approaches have emerged as effective alternatives, existing methods that rely heavily on brightness temperature thresholds and contextual comparisons often suffer from high false positive and false negative rates under varying environmental conditions and fire intensities. To address these challenges, this study developed a real-time wildfire detection algorithm using geostationary satellite imagery from GEO-KOMPSAT-2A and machine learning. The developed model was evaluated against existing wildfire detection products based on both polar-orbiting and geostationary satellites, using historic wildfire events that occurred in South Korea in March 2025. The model successfully detected all seven large wildfires that had failed initial suppression and achieved the highest overall performance, with a recall of 0.329, precision of 0.987, and F1-score of 0.494 across 79 wildfire cases, including those with burn areas under 10 hectares. Moreover, the model provided the fastest early detection, with an average detection delay of only 12.9 minutes―significantly outperforming polar-orbiting satellites, which showed delays ranging from 197.2 to 305.2 minutes. By integrating geostationary satellites with machine learning, the model preserved the inherent advantages of geostationary platforms―such as continuous monitoring and early warning―while achieving detection sensitivity comparable to that of highresolution polar-orbiting systems. These results demonstrate the potential of machine learning-based wildfire detection models to enhance the reliability and responsiveness of real-time wildfire monitoring and underscore the value of geostationary satellites in disaster management systems."
MS-Office 계열 파일 내 매크로 정보 기반 악성 정보 자동 검출 메커니즘 설계 및 구현,2025,"['MS Office 매크로 파일', '악성 코드', '머신러닝', '자동 검출 시스템', '지도/비지도 학습 모델', 'MS Office Macro File', 'Malicious Code', 'Machine Learning', 'Auto-Detection System', 'Supervised/Unsupervised Learning Model']",,"In this paper, we designed and implemented a system that applies machine learning techniques to automatically detect malicious macro information embedded in MS Office files. When an MS Office file contains macro functionality, it may perform abnormal actions on the user’s system, potentially leading to the leakage of sensitive personal information stored within the system. Therefore, a system is needed to automatically detect malicious scripts embedded in MS Office files and verify any tampering. To achieve this, this study applies supervised and unsupervised learning-based machine learning models to design and implement an automatic detection system for determining whether an MS Office file contains malicious macro data. Experimental results demonstrate that the proposed system provides improved detection performance compared to existing methods, ensuring a safer environment for the use of MS Office files."
시공간적 변동이 공간·시공간 크리깅 추정에 미치는 영향,2025,"['Spatial kriging', 'Spatio-temporal kriging', 'Machine learning', 'Spatio-temporal variation', 'NO<sub>2</sub> concentrations', '공간 크리깅', '시공간 크리깅', '기계학습', '시공간적 변동', '이산화질소']",,"Spatial kriging interpolates attributes at unobserved locations based on spatial autocorrelation, while spatio-temporal kriging extends it by incorporating temporal dimensions to reflect spatio-temporal interactions. Previous studies have shown that applying spatio-temporal kriging to spatio-temporal data improves estimation accuracy. However, because spatio-temporal kriging needs to simultaneously model both spatial and temporal autocorrelation, the nature of spatio-temporal variability may influence its accuracy. This study explores the impacts of spatio-temporal variations on the estimations of spatial and spatio-temporal kriging. In addition, it investigates the effects on kriging models that incorporate machine learning. Specifically, the study employs machine learning techniques with varying levels of flexibility, including random forest and boosting, in addition to conventional polynomial regression, to estimate firstorder effects, while second-order effects are modeled using kriging. Kriging is applied to estimate nitrogen dioxide (NOP) concentrations in Seoul during 2023, and estimation accuracy is assessed across two time points with distinct spatio-temporal variation. The analysis results show that estimating first-order effects with machine learning improves overall accuracy, with more flexible models yielding higher performance. When spatio-temporal variation is relatively smooth, spatio-temporal kriging performs better, whereas on days with high variability, spatial kriging, which considers only spatial variation at a single time point, demonstrates superior accuracy. Particularly, spatio-temporal kriging tended to overestimate concentrations overall at time points with high variability, while models without first-order effect estimation showed higher accuracy. In addition, the spatial distribution of the estimated concentrations was divided into two patterns depending on the method used to estimate the first-order effect: one exhibiting smooth and gradual trends, and the other showing abrupt and localized variations. This study empirically demonstrates how spatio-temporal variation and first-order estimation methods affect kriging-based prediction accuracy, underscoring the importance of selecting an appropriate kriging method based on the characteristics of spatio-temporal variation."
기계학습을 이용한 알루미늄 판재와 금형강의 윤활상태에서 압력과 속도에 따른 마찰계수 예측,2025,"['Aluminum Sheet(알루미늄 판재)', 'Die Steel(금형강)', 'Friction Coefficient(마찰계수)', 'Lubrication(윤활)', 'Machine Learning(기계학습)']",,"Friction is a complex phenomenon, and its theoretical establishment is difficult. To date, experimental empirical studies have been primarily conducted. Recently, researchers have attempted to apply machine-learning methods to examine friction characteristics. In this study, the effects of pressure and velocity on the friction coefficient of aluminum sheets and die steel under lubricated conditions are investigated using machine-learning methods. The data obtained after the friction experiment are analyzed using machine-learning methods. The three machine-learning methods used are the artificial neural network, random forest, and extreme gradient boosting. A model that predicts the friction coefficient by simultaneously considering the pressure and velocity is proposed, and the performances of the three prediction models are compared and analyzed."
바이오 소재 FDM 3D 프린팅 출력물의 적층방향에 따른 기계적특성실험분석 및 기계학습모델 구현,2025,"['바이오소재', '용융적층모델링', '기계학습모델', '적층각도', '피처맵', 'biomaterial', 'fused deposition modeling', 'machine learning model', 'raster angle', 'feature map']","FDM 3D 프린팅에 적용되는 출력조건은 출력물의 기계적 성능에 영향을 미치는 핵심 요소이다. 출력조건 중 적층각도에 따른 출력물의 기계적 특성 변화에 대한 정량적 분석은 FDM 3D 프린팅 공정의 최적화에 활용될 수 있다. 본 연구에서는 PLA 필라멘트를 적용한 바이오 소재 FDM 3D 프린팅 공정을 최적화하기 위해 적층방향을 기준으로 제작한 출력물에 대해 인장시험을 실시하여 적층각도에 따른 기계적 특성 변화 양상을 분석하였다. 그리고 인장시험 데이터셋과 적층조직 이미지 데이터셋을 기계학습모델인 LSTM 모델과 FM 모델에 입력하여 기계학습을 실시하였다. 본 연구에서는 기계학습모델인 RNN 기반의 LSTM 모델을 사용하여 인장시험 결과에 매우 근접한 응력-변형률 비교선도를 작성하였으며, CNN 기반의 FM 모델을 통해 적층조직의 이미지 패턴을 고도화한 피처맵을 작성하여 적층조직의 형상특징과 기계적 특성 간의 연계성을 분석하였다. 이로부터 본 연구에서 바이오 소재 FDM 3D 프린팅 출력물의 적층각도에 따른 기계적 물성치 변화 양상에 대한 분석과 기계학습모델로부터 도출한 기계적 특성 예측 및 형상특징 시각화에 의한 기계적 특성 연계성 파악의 결과는 바이오 소재 FDM 3D 프린팅 기술 분야에서 공정 최적화와 기계적 성능 분석 방법론의 신뢰도 정립에 핵심 역할을 할 것으로 기대된다.","The printing conditions applied in FDM 3D printing are a key factor affecting the mechanical performance of the part. Quantitative analysis of the change in mechanical properties of the printed parts depending on the raster angle during the printing conditions can be used to optimize the FDM 3D printing process. In this study, in order to optimize the FDM 3D printing process of biomaterials using PLA filaments, tensile tests were conducted on the printed parts based on the raster direction to analyze the change of mechanical properties according to the raster angle. The tensile test dataset and the laminated tissue image dataset were input to the machine learning models, LSTM model and FM model, to perform machine learning. In this study, the RNN-based LSTM model was used to create a stress-strain comparison map that closely approximates the tensile test results, and the CNN-based FM model was used to create a feature map that enhances the image pattern of the laminated tissue to analyze the connection between the shape features and mechanical properties of the laminated tissue. The results of this study, which analyzed the changes in mechanical properties of biomaterial FDM3D printing printouts depending on the raster angle, predicted mechanical properties derived from machine learning models, and identified the linkage between mechanical properties by visualizing geometric features, are expected to play a key role in process optimization and establishing the reliability of mechanical performance analysis methodologies in the field of biomaterial FDM 3D printing technology."
앨런 튜링(Alan Mathison Turing)의 인공(기계)지능을 통해 본 인간 이해,2025,"['Alan Turing', 'AI', 'Intuition', 'Free-will', 'Emotion', '앨런 튜링', '인공지능', '직관', '자유의지', '정서']","인공지능에 관한 연구를 위해서는 인공지능의 발전역사에서 기계가 인간지능의 행위를 할 수 있다는 기계지능의 가능성을 제시한 앨런 튜링(Alan Mathison Turing)의 인간 이해에 관한 사유 배경과 동기를 살펴보아야 한다. 튜링은 기계지능에 관한 아이디어를 연구하기 위해 인간이 가지고 있는 특성 중 직관, 자유의지, 정서의 중요성을 발견하게 된다. 튜링은 인간 이해에서 직관의 중요성과 함께 인간의 본질적 특성으로 자유의지에 관한 관심을 두게 된다. 이른 시기부터 튜링은 인간의 자유의지가 외적 물리적 세상을 결정할 수 있다고 생각할 정도로 강력했다. 튜링은 자유의지와 학습과 연관하여 태어난 아기가 자유의지를 가지고 학습하는 것 같이 기계도 태어난 아기처럼 자유의지를 가지고 학습할 수 있다고 주장한다. 입력한 것과는 다른 결과를 가져올 수 있고 튜링은 이를 기계가 자유의지로 자아-발생적인 창의적인 것을 했다고 주장할 수 있다고 한다. 한편, 튜링은 지능을 정서적 개념, 정서적 논의, 그리고 정서적 소통으로 설명하며, 지능은 수학적이기보다는 정서적이라고 언급한다. 튜링이 지능을 판단하는 근거에 정서적 개념을 도입하는 것은 지능의 판단에는 본질적으로 주관적이라는 의미를 내포하는 것이고 진리 판단에는 인간 주체의 주관적 판단의 독립적 개념화가 불가피하다는 것을 의미한다. 튜링은 기계지능인 인공지능이 자신의 창조자인 인간의 직업을 위협할 수 있고, 인간이 자신의 창조자인 하나님의 계획에 간섭할 수 있는 것 같이 기계지능 역시도 자신을 창조한 인간을 간섭할 수 있어서 기계는 인간에게 근심거리가 될 뿐 아니라 위험이 되리라는 것을 암묵적으로 경고한다. 튜링이 남긴 유산으로 인해 인류사회는 인공지능의 시대로 진입하고 있다. 본 연구는 튜링 자신의 연구와 삶에서 일관된 것은 인간의 본질과 생명에 관한 관심이었다는 것에 관해 살펴보고자 하였다. 미래의 강인공지능 시기에 직면한 기독교 신학은 신학적 인간론에 관한 연구를 통해 인공지능 연구와의 접점을 찾아야 한다. 기독교 신학은 인간성의 본질에 관한 재규정에 관해 끊임없이 질문하는 인공지능의 바람직한 활용과 더불어 강인공지능의 위험성을 판단할 수 있는 신학적 인간론에 근거한 윤리적 규범을 제시함으로 인공지능 연구의 방향성을 제시할 수 있어야 한다.","In order to study artificial intelligence, we must examine the background and motivation of Alan Mathison Turing's thoughts on human understanding, who suggested the possibility of machine intelligence, which is that machines can perform human intelligence actions, in the history of artificial intelligence development. In order to study the idea of ​​machine intelligence, Turing discovered the importance of intuition, free will, and emotion among the characteristics that humans possess. Along with the importance of intuition in human understanding, Turing became interested in free will as an essential characteristic of humans. From an early age, Turing was so strong that he thought that human free will could determine the external physical world. Turing argued that machines can learn with free will just as babies born with free will learn with free will, in relation to free will and learning. It can bring about results different from what was input, and Turing argued that this can be argued that the machine did something self-generated and creative with free will. Meanwhile, Turing explained intelligence as emotional concepts, emotional arguments, and emotional communication, and mentioned that intelligence is emotional rather than mathematical. Turing's introduction of the concept of emotion into the basis for judging intelligence implies that the judgment of intelligence is inherently subjective, and that the independent conceptualization of the subjective judgment of the human subject is inevitable in judging the truth. Turing implicitly warns that just as artificial intelligence, which is machine intelligence, can threaten the jobs of humans who are its creators and humans can interfere with the plans of God, who is its creator, machine intelligence can also interfere with humans who created it, so machines will not only be a source of concern to humans but also a danger. Due to Turing's legacy, human society is entering the era of artificial intelligence. This study examines the consistent concern for the essence and life of humans in Turing's own research and life. Christian theology, which faces the era of strong artificial intelligence in the future, should find a point of contact with artificial intelligence research through research on theological anthropology. Christian theology should be able to suggest the direction of artificial intelligence research by suggesting ethical norms based on theological anthropology that can judge the risks of strong artificial intelligence along with the desirable use of artificial intelligence that constantly questions the redefinition of the essence of humanity."
인공지능을 이용한 컴퓨터 그래픽스 자동화 기술 동향,2025,"['Machine Learning', 'Deep Learning', 'Computer Graphics', 'Automation', 'Digital Environment', '머신러닝', '딥러닝', '컴퓨터 그래픽스', '자동화', '디지털 환경']","최근 인공지능(AI) 기술의 발전은 컴퓨터 그래픽스 분야에 혁신적인 변화를 불러오고 있으며, 이 두 기술의 융합은 시각적 콘텐츠 제작과 표현 방식에 새로운 가능성을 열고 있다. 먼저, 인공지능은 컴퓨터 그래픽스에서 캐릭터 모델링, 환경 생성, 렌더링 등 다양한 작업을 자동화하는 데 기여하고 있다. 특히 딥러닝 기반 기술은 복잡한 애니메이션 생성, 현실적인 텍스처 구현, 물리적 효과 시뮬레이션 등에서 높은 성과를 보이고 있다. 이러한 기술적 발전은 보다 몰입감 있고 현실감 넘치는 디지털 환경을 제공하며, 사용자 경험을 혁신적으로 변화시키고 있다. 본 논문은 인공지능을 활용한 컴퓨터 그래픽스 기술의 최신 동향과 응용 사례를 통해 기술적 방향성을 검증하여 응용 가능성을 분석한다.","Recent advancements in artificial intelligence (AI) technology have brought about revolutionary changes in the field of computer graphics, and the convergence of these two technologies is opening up new possibilities for the creation and expression of visual content. AI significantly contributes to automating various tasks in computer graphics, such as character modeling, environment generation, and rendering. In particular, deep learning-based technologies have demonstrated remarkable achievements in generating complex animations, implementing realistic textures, and simulating physical effects. These technological advancements provide more immersive and lifelike digital environments, fundamentally transforming user experiences. This paper examines the latest trends and application cases of AI-driven computer graphics technologies to validate their technical direction and analyze their potential applications."
A Novel Point-of-Care Prediction Model for Steatotic Liver Disease: Expected Role of Mass Screening in the Global Obesity Crisis,2025,"['Machine learning', 'Fatty liver', 'Obesity', 'Bioelectrical impedance']",,"Background/Aims: The incidence of steatotic liver disease (SLD) is increasing across all age groups as the incidence of obesity increases worldwide. The existing noninvasive prediction models for SLD require laboratory tests or imaging and perform poorly in the early diagnosis of infrequently screened populations such as young adults and individuals with healthcare disparities.We developed a machine learning-based point-of-care prediction model for SLD that is readily available to the broader population with the aim of facilitating early detection and timely intervention and ultimately reducing the burden of SLD.Methods: We retrospectively analyzed the clinical data of 28,506 adults who had routine health check-ups in South Korea from January to December 2022. A total of 229,162 individuals were included in the external validation study. Data were analyzed and predictions were made using a logistic regression model with machine learning algorithms.Results: A total of 20,094 individuals were categorized into SLD and non-SLD groups on the basis of the presence of fatty liver disease. We developed three prediction models: SLD model 1, which included age and body mass index (BMI); SLD model 2, which included BMI and body fat per muscle mass; and SLD model 3, which included BMI and visceral fat per muscle mass. In the derivation cohort, the area under the receiver operating characteristic curve (AUROC) was 0.817 for model 1, 0.821 for model 2, and 0.820 for model 3. In the internal validation cohort, 86.9% of individuals were correctly classified by the SLD models. The external validation study revealed an AUROC above 0.84 for all the models.Conclusions: As our three novel SLD prediction models are cost-effective, noninvasive, and accessible, they could serve as validated clinical tools for mass screening of SLD."
Active Protection Strategy for Transmission Networks with Wind Distributed Generation Systems Based on SVM,2025,['Machine learning · Transmission line protection · Renewable energy resources · Decision tree'],,"Electric power network transmission lines frequently experience various kinds of failures. To avoid severe malfunctions and limit the adverse eff ects caused by transmission line faults, protective systems must be able to detect fault states and abnormalities. This paper proposes an intelligent supervised learning-based fault diagnosis approach to recognise fault type and fault location data even in the case of system disturbance. Initially, a Decision Tree Fault Detector (DTFD) algorithm is proposed to fi nd out the various kinds of faults that occur in electrical networks. To enhance the decision-making process of the distance relay, it is advisable to employ a Support Vector Machine (SVM) as a Fault Location Estimator (FLE) protection mechanism. The system can accurately and profi ciently detect any type of malfunction on the transmission line, while also off ering line protection. This active combination increases the speed and accuracy of fault management in power systems by addressing the shortcomings of traditional approaches. The MATLAB simulation package is used to replicate the modifi ed IEEE 13 bus test feeder with the insertion of Renewable Distributed Energy Resources (RDERs). The reliability and stability of grid-connected RDERs are improved by the investigation of the suggested intelligent protection scheme, which shows satisfactory results."
딥러닝을 이용한 한글 텍스트의 자살위험 징후 탐지,2025,"['Machine Learning', 'Deep Learning', 'NLP', 'Suicide', 'Ideation', 'SNS']",,"This study presents a model for detecting suicide ideation in Korean online and on SNS using deep learning. With the introduction of natural language learning and artificial intelligence technology, we were not only able to understand language but also read emotions inherent in text, making great progress. There has been an increasing number of studies using these technologies to detect the suicide risk of online users. In addition, as the industry commercializes related technologies, it is possible to respond by analyzing suicide-inducing information through online and SNS to detect users of high risk of suicide at an early stage. Although Korea has a high suicide rate, related research is still insufficient. CNN, GRU, and LSTM deep learning models were used for the experiment, and each learning set and test set consisted of 31,770 and 6,354 data. In the analysis results, the LSTM model showed the best performance, and showed a classification accuracy of 65% in articles with suicidal risk and 99.18% of classification accuracy in articles with non-suicidal risk. This study is the first study to show the possibility of detecting signs of suicide risk in Korean, and offers implications for academia and industry."
통합형 프레스 패널 크랙 탐지 기법 개발,2025,"['패널', '머신비전', '이미지 처리', '딥러닝', '통합 기법', 'Panel', 'Machine Vision', 'Image Processing', 'Deep Learning', 'Integrated Method']",,"As the basic framework of a vehicle body, the panel is manufactured through a pressing process. Detecting defects during this process is crucial, as such defects significantly impact the stability, quality, and reliability of the product. Although various machine vision-based defect detection algorithms have been developed, their application in real-world environments remains challenging owing to factors such as constraints on equipment installation space for lighting and cameras, cost efficiency, and over-detection. To address these challenges, this study proposes an integrated crack detection method that combines shape-based crack detection with deep learning-based techniques. The proposed method employs a compact vision system that operates without requiring high-cost cameras or additional lighting. First, image processing is performed by separating the panel from the background using a deep learning model and applying a binarization algorithm. Next, suspected crack areas are identified through shape-based angle analysis. Finally, a pretrained deep learning model is fine-tuned with the data from the suspected crack areas to determine crack probabilities in test images. The proposed integrated method was validated using a laboratory-scale testbed that simulates the pressing process, demonstrating good model performance."
특징 추출 기법을 활용한 초단기 강수 예측 성능 비교 분석,2025,"['Deep learning', 'data preprocessing', 'very short-term precipitation prediction', '딥러닝', '데이터 전처리', '초단기 강수 예측']","기상청 AWS 데이터를 사용한 초단기 강수 예측에 적합한 데이터 전처리 방법을 제시하고, 다양한 인공지능 기반 알고리즘들을 사용한 비교 실험을 통해 제안 방법이 효과적임을 보이고자 한다. 데이터 전처리 과정에서 특징별 특성에 따른 결측치 처리 방법을 제시하고, 시계열 예측 모델에 적합한 특징을 추출 및 생성한다. 머신러닝 알고리즘들과 딥러닝 기반의 LSTM 및 Informer를 사용한 비교 실험에서 Informer 모델의 F1-score 가 0.722로 가장 우수하였다. 학습 과정에서 시계열 데이터의 특성을 고려한 시계열 k-Fold 방법을 사용하여 시간의 순서를 유지하였고, 초기 실험에서의 과적합을 완화하기 위해 다양한 파라미터 조합을 사용한 실험으로 일반화 성능을 개선했다.","We present a data preprocessing method that is suitable for very short-term precipitation prediction using Korea Meteorological Administration AWS data and demonstrate its effectiveness through comparative experiments with various artificial intelligence-based algorithms. In the data preprocessing stage, we propose a method for handling missing values based on the characteristics of each feature, and we extract or generate features that are suitable for time series prediction models. Among the experimental results of machine learning algorithms and deep learning-based LSTM and Informer models, Informer achieved the highest F1-score of 0.722. During training, the temporal order was preserved using the time-series k-Fold method to account for the characteristics of time series data. Furthermore, generalization performance was improved by tuning various parameters to mitigate overfitting during early training."
XGBoost 기반 K-Means 군집 분석을 활용한심장질환 예측 및 표현형 연구,2025,"['Heart Disease', 'Machine Learning', 'XGBoost', 'K-Means Clustering', 'Phenotyping', 'Risk Prediction', 'Patient Heterogeneity', 'Risk Stratification', 'Personalized Management', 'Clinical Characteristics']","본 연구는 심장질환의 정밀 예측 및 환자 이질성 규명을 위해, 기계학습 기반 예측 모델과 군집 분석을 통합적으로 적용하는 방법론을 제시한다. Kaggle 공개 심장질환 데이터(N≈7만)를 대상으로 Decision Tree 대비 최적화된 XGBoost의 우수한 예측 성능을 확인하였다. 이후 Elbow 및 Silhouette 분석을 통해 최적 군집 수를 결정하고 우수 모델인 XGBoost의 특성 공간상 K-Means를 수행하여 평균 위험도(최저 0.0% ~ 최고 99.2%) 및 임상적 특성(연령대)에서 뚜렷하게 구분되는 4개의 잠재적 위험 표현형 그룹을 성공적으로 식별하였다. 이는 고성능 예측 모델과 연계한 군집 분석이 복잡한 환자 데이터 내 숨겨진 패턴을 발견하고, 정밀한 위험 계층화 및 표현형 기반의 맞춤형 관리 전략 수립을 위한 실증적 근거를 제공할 수 있음을 강력히 시사한다.","This study proposes an integrated approach combining a machine learning-based prediction model with clustering analysis to precisely predict heart disease risk and identify patient heterogeneity. Using a publicly available Kaggle heart disease dataset (N≈70,000), the optimized XGBoost model demonstrated superior predictive performance compared to a Decision Tree model. Subsequently, optimal cluster number was determined using Elbow and Silhouette analyses. Applying K-Means clustering within the feature space defined by the XGBoost model successfully identified four distinct latent phenotypic groups clearly differentiated by average risk levels (ranging from 0.0% to 99.2%) and clinical characteristics (particularly age groups). These findings strongly suggest that clustering analysis integrated with high-performance prediction models can effectively uncover hidden patterns within complex patient data, providing empirical evidence to support precise risk stratification and phenotype-based personalized management strategies."
Task execution Failure Prediction Based on 1DCNN and Transformer in Cloud,2025,"['Cloud computing', 'Deep Learning', 'failure prediction', 'Transformer']",,"With the growth of cloud data centers’ scale, task execution failure becomes an inevitable problem. Task execution failure in cloud can incur huge economic losses. To reduce the impact of task execution failure, we need to predict task execution failure accurately and take proactive measures to improve the service quality of users and avoid huge economic losses.The previous machine learning and deep learning-based approaches are inefficient and inaccurate when dealing with high-dimension features and dependent time series data. To further improve the accuracy of task execution failure prediction in cloud, this paper adopts a joint one-dimensional CNN and transformer approach. First, we use 1DCNN network to capture the local features of the input time series data. Second, global features of time series data are extracted through Transformer with the multi-head attention mechanism as the core.Residuals and layer normalization operations are added between layers to solve gradient vanishing and explosion problems. At last, we use mean pooling and fully connected layers to predict the final binary classification result. Extensive experiments have been conducted on the cloud data center cluster dataset published by Google, and the results show that 1DCNN-Transformer can extract potential dependencies of task more efficiently than previous work.It also has better performance metrics regarding prediction accuracy, precision, recall rate, F1 score, and ROC curve."
Android Automotive OS 차량을 위한  클라우드 기반 통합 보안 소프트웨어 프레임워크 설계,2025,"['Automotive Security', 'Cloud Computing', 'Machine Learning', ""Malicious Apps and Malicious CAN Packets Detection Name Category Target Description Sound Blast Disturbance Driver’s Attention An attack that hijacks control over the vehicle's audio volume. Fork Bomb DoS System Resource An attack that continuously fork"", 'causing system paralysis. Intent Storm DoS System Resource An attack that continuously triggers intents to force infinite reboots of apps', 'thereby incapacitating the AAOS UI. Permissionless Exfiltration Privacy Data Exfiltration An attack where an app lacking internet permission utilizes intents to disclose vehicle internal data via other apps with internet permission. Covert Channel Privac', '자동차 보안', '클라우드 컴퓨팅', '기계학습', '악성 앱 및 CAN 패킷 탐지']","최근 Android OS가 차량 인포테인먼트 시스템인 Android Automotive OS(AAOS)로 확장되면서 이를 탑재한 차량이 빠르게 증가하고 있다. 그러나 이러한 변화는 OS의 취약점을 악용한 악성 앱 설치와 권한 탈취를 통한 CAN 패킷 주입 등의 보안 위협을 초래할 수 있다. 본 연구에서는 AAOS 기반 차량의 보안 강화를 위해 악성 앱과 악성 CAN 패킷을 동시에 탐지할 수 있는 클라우드 기반 통합 보안 소프트웨어 프레임워크를 설계하였다. 제안된 프레임워크는 시그니처 기반 및 기계학습 기반 탐지를 결합한 악성 앱 탐지 모듈과 CAN 패킷의 필드 값 패턴을 분석하는 악성 CAN 패킷 탐지 모듈로 구성된다. 이 모듈들은 차량 인포테인먼트 시스템에 단일 에이전트로 설치되어 실시간 탐지를 수행하며, 클라우드 자원을 활용한 분산 처리를 통해 차량의 제한된 연산 자원 문제를 해결한다. 본 연구는 차량 내 악성 소프트웨어와 네트워크 공격에 대한 통합 탐지 체계를 제시함으로써 AAOS 탑재 차량의 보안성 강화에 기여할 것으로 기대된다.","Recently, as Android OS evolves into Android Automotive OS (AAOS) for in-vehicle infotainment systems, the number of vehicles adopting this system is rapidly increasing. However, this shift introduces security vulnerabilities that can be exploited to install malicious apps or inject CAN packets through privilege escalation. This study designs a cloud-based integrated security software framework for AAOS-based vehicles that can simultaneously detect both malicious apps and CAN packets. The proposed framework consists of a malicious app detection module combining signature-based and machine learning-based detection approaches and a malicious CAN packet detection module that analyzes field value patterns in CAN packets. These modules operate as a single agent installed on the vehicle's infotainment system for real-time detection, while addressing the limited computational resources of vehicles through distributed processing with cloud computing. This research contributes to enhancing the security of AAOS-equipped vehicles by providing an integrated detection system for both in-vehicle malicious software and network attacks."
필로티 건축물의 인공지능 기반 내진성능 평가를 위한 데이터 기반 부재의 단면 형상비 연구,2025,"['RC piloti structures', 'Machine learning', 'Inter-Story Drift Ratio (IDR)', 'Section shape ratio']",,"Structures compromised by a seismic event may be susceptible to aftershocks or subsequent occurrences within a particular duration. Considering that the shape ratios of sections, such as column shape ratio (CSR) and wall shape ratio (WSR), significantly influence the behavior of reinforced concrete (RC) piloti structures, it is essential to determine the best appropriate methodology for these structures. The seismic evaluation of piloti structures was conducted to measure seismic performance based on section shape ratios and inter-story drift ratio (IDR) standards. The diverse machine-learning models were trained and evaluated using the dataset, and the optimal model was chosen based on the performance of each model. The optimal model was employed to predict seismic performance by adjusting section shape ratios and output parameters, and a recommended approach for section shape ratios was presented. The optimal section shape ratios for the CSR range from 1.0 to 1.5, while the WSR spans from 1.5 to 3.33, regardless of the inter-story drift ratios."
Preprocessing of Inconsistent Creep Data Collected from a Literature Survey to Provide Reliable and Consistent Creep Life Prediction,2025,"['Creep rupture life', 'Machine learning', 'Outlier elimination', 'Creep life prediction', 'Ni-based superalloy']",,"Numerous studies on machine learning-based creep life prediction using the creep data collectedfrom various existing experimental data have been reported. Since the prediction of creep life is heavilyinfluenced by the quality and integrity of the collected creep data, data preprocessing is required to eliminatephysically inconsistent creep datapoints, known as outliers. In the present study, a machine learning-baseddata screening methodology was developed to detect and eliminate outliers from the creep data collected froma survey of various studies in the literature. The methodology consisted of selecting appropriate machinelearning models for the collected creep data through an assessment of their validity in creep physics,evaluating the prediction accuracy and variability of collected datapoints through bagging of the selectedmachine learning models, and identifying inconsistent datapoints by ranking their residuals and predictionvariabilities. The proposed methodology for detecting and eliminating outliers was successfully applied to themulti-source collected creep data of a Ni-base single crystal superalloy CMSX-4 and led to improved accuracyand consistency in creep life prediction. In addition, the proposed methodology was validated by predictingthe creep life of a newly generated creep dataset that was not exposed to any model training using a machinelearning model trained and optimized by the outlier-eliminated creep data."
AI 시대의 기업거버넌스 ― AI의 기업법적 활용을 중심으로 ―,2025,"['인공지능', '생성형 AI', '머신러닝', '딥러닝', '켄타우로스 모델', '사이보그 모델', 'Artificial Intelligence', 'generative AI', 'machine learning', 'deep learning', 'Centaur model', 'Cyborg model']","컴퓨터의 반응이 인간의 반응과 구별될 수 없다면 이 컴퓨터는 생각하고 있는 것이다. 2022년에 등장한 ChatGPT는 세계의 모든 이들을 경탄케 했을 뿐만 아니라, 지금까지 인간만의 영역이라고 생각했던 창조 영역이 기계에 의해 철저히 무너지는 모습도 보여주었다. 이전의 AI는 대량의 데이터를 통해 다양한 특징을 배우고 이에 기반하여 일정한 인식과 예측을 하는 수준이었지만, ChatGPT와 같은 생성형 Al는 대량의 데이터에 기반하여 새로운 데이터를 스스로 만들 수 있게 되었다. 지금까지 인간만이 할 수 있다고 믿어 온 창의적인 활동을 AI가 더 높은 정확도로 할 수 있게 된 것이다.향후 AI는 우리의 생활을 지배할 것이며, 이러한 변화는 기업거버넌스 분야에도 심대한 영향을 미칠 것이다. 이에 본고에서는 내부통제시스템과 기업법무를 포함한 컴플라이언스 체제, 이사회 운영과 감사제도, 그리고 인사･노무관리 등 각 분야 별로 AI가 미칠 영향과 법적 쟁점을 살펴보고, 인간과 AI의 동반관계라는 관점에서 향후 기업거버넌스 분야에서 AI에게 부여할 지위와 역할이 무엇인지를 고찰해 보고자 한다.앞으로 AI를 기업의 의사결정에 사용하는 과정에서 다양한 법적 책임 문제가 발생할 것이며, 또 AI의 장점을 활용하기 위해서는 여러 입법 흠결의 문제를 해결하여야 한다. 따라서 이러한 문제들의 해결을 포함하여 다가올 AI 시대에 대비하려면 조속히 기업거버넌스 원칙을 수립할 필요가 있다. 이제 회사법 차원에서도 전통적인 이해상충방지 중심의 회사법 체계보다는 알고리즘과 빅데이터에 관한 데이터 거버넌스로 관심을 옮겨야 하고, 기업활동의 자율적인 기준이 될 AI 가이드라인을 제시함으로써 기업들이 AI 시대의 법적 불확실성에 대비할 수 있도록 하여야 한다. 또한, AI에 관한 법적 의무를 넘어서는 곳에서도 계속하여 적절한 기업경영을 위한 윤리준칙을 수립할 필요가 있다.특히, 앞으로의 경영활동을 위해 AI와 협업하는 방식을 고민해야 한다. 생각해 볼 수 있는 두 가지 방식으로는, 인간과 AI가 각자의 강점 영역을 정확히 구분해 전략적으로 분업하는 ‘켄타우로스 모델’, 인간이 주도적인 역할을 담당하고 AI는 보완적인 역할을 담당하는 ‘사이보그 모델’이 있다. 궁극적으로는, 인간과 AI가 업무영역을 나누어 각자의 장점을 살릴 수 있는 켄타우로스 방식이 바람직하다고 본다.앞으로의 미래는 AI만의 미래가 되어서는 아니될 것이며, 인간과 AI의 협업으로 만들어가는 새로운 미래가 되어야 한다.","ChatGPT, which appeared in 2022, not only astonished everyone in the whole world but also showed that the creative field, which had previously been thought to be a human domain, was completely destroyed by machines. Previously, AI was at the level of learning various patterns from large amounts of data and making certain perceptions and predictions based on them, but generative Al such as ChatGPT can make a new creation on their own based on large amounts of data. AI can now perform creative activities with higher accuracy, which have been believed that only humans can do. AI will dominate our lives in the future, and these changes will have a significant impact on the field of corporate governance. The purpose of this paper is to examine the impact and legal issues of AI in each field, such as compliance systems, board operation, audit systems, and labor management, and to seriously consider the status and role that it will give AI in the field of corporate governance in the future from the perspective of a partnership between humans and AI.Many legal issues can arise in the course of using AI for corporate decision-making, and a lot of legislative flaws should be resolved in order to make use of AI's advantages. Therefore, it is necessary to establish the principle of corporate governance as soon as possible to prepare for the upcoming AI era. Now, even at the corporate law level, it is necessary to shift attention to data governance on algorithms and big data rather than the traditional conflict-of-interest corporate law system. And by presenting AI guidelines that will be autonomous standards for corporate activities, companies should be prepared for legal uncertainty in the AI era. It is also necessary to continuously establish ethical standards for appropriate corporate management in places beyond legal obligations on AI. In particular, it is necessary to consider how to collaborate with AI for future management activities. There are two conceivable ways: the Centaur model, in which humans and AI accurately distinguish their strengths and divide them strategically, and the Cyborg model, in which humans play leading roles while AI plays only complementary roles. Ultimately, I think a Centaur method is desirable in which humans and AI can divide their work areas by field to utilize their strengths.The upcoming AI era should not be an era of AI alone. We need to create a new future through collaboration between humans and AI."
Hate Speech Identification and Categorization on Social Media Using Bi-LSTM: An Information Science Perspective,2025,"['hate speech detection', 'social media', 'deep learning', 'machine learning', 'metadata organization', 'content labelling']",,"Online social networks empower individuals with limited influence to exert significant control over specific individuals’ lives and exploit the anonymity or social disconnect offered by the Internet to engage in harassment. Women are commonly attacked due to the prevalent existence of sexism in our culture. Efforts to detect misogyny have improved, but its subtle and profound nature makes it challenging to diagnose, indicating that statistical methods may not be enough. This research article explores the use of deep learning techniques for the automatic detection of hate speech against women on Twitter. It offers further insights into the practical issues of automating hate speech detection in social media platforms by utilizing the model’s capacity to grasp linguistic nuances and context. The results highlight the model’s applicability to information science by addressing the expanding need for better retrieval of hazardous content, scalable content moderation, and metadata organization. This work emphasizes content control in the digital ecosystem. The deep learning-based methods discussed improve the retrieval of data connected to hate speech in the context of a digital archive or social media monitoring system, facilitating study in fields including online harassment, policy formation, and social justice campaigning. The findings not only advance the field of natural language processing but also have practical implications for social media platforms, policymakers, and advocacy groups seeking to combat online harassment and foster inclusive digital spaces for women."
데이터 기반 푸드뱅크 물류 운영 최적화,2025,"['푸드뱅크', '인도주의적 물류망', '다중 목적 선형계획법', '머신러닝', 'Food bank', 'Humanitarian Operation', 'Multi-objective Optimization', 'Machine learning']","푸드뱅크는 소외계층에게 개인과 기업으로부터 받은 필수 식품과 생활용품을 전달하는 중요한 재분배 시스템이다. 하지만최근 푸드뱅크는 재고 불균형, 운영 비용 증가, 형평성 악화 등의 여러 어려움에 직면하고 있다. 이는 단순한 수요 증가나공급 부족이 아닌, 푸드뱅크 관리 및 전략 부재로 볼 수 있다. 이러한 문제를 해결하기 위해 본 연구는 푸드뱅크 내 기부품의 재배치를 제안한다. 푸드뱅크의 주요 평가 요인인 효과성(Effectiveness), 효율성(Efficiency), 형평성(Equity)을고려하여 최적화된 운영 방안을 제시하고 그 효과성을 실제 데이터를 활용하여 검증하고자 한다. 그러나 문제의 크기가증가함에 따라 계산 복잡성이 높아져 이를 해결하기 위한 계산 시간이 증가하는 한계가 있다. 이를 해결하고자 본 연구는머신러닝 기반 2단계 문제 해결 방법론을 제안하며 복잡한 최적화 문제를 단순화하여 단시간 내 근사해를 도출하였다. 경기 광역푸드뱅크의 2022년 기부품 제공 내역 데이터를 기반으로 시뮬레이션한 결과, 기부품 재배치는 일부 경로 비용의상승을 유발할 수 있으나, 장기적으로 푸드뱅크의 운영 비용을 줄이고, 푸드뱅크 간의 형평성을 확보하는 등 전체 푸드뱅크의 운영 효율을 높일 수 있음을 확인했다. 본 연구는 국내 푸드뱅크의 재배치 전략을 평가하기 위한 적합한 평가 기준과 목적 함수를 구성하고, 재고 기반 머신러닝 알고리즘을 통해 복잡한 재고와 수요 간 매칭을 원활하게 하여 푸드뱅크운영의 효율성과 신속성을 향상시키는 데 연구 의의가 있다.","A food bank is a redistribution system that provides essential food and living supplies to marginalized groups, sourced from individuals and corporations. Recently, food banks have faced challenges due to management and strategic deficiencies, rather than limited supply or excessive demand. Therefore, we propose the reallocation of donations within the food bank system. This study aims to propose operational strategies through the reallocation of donations in food bank distribution, with the objective of improving effectiveness, efficiency, and equity in food distribution. Given the complexity of the problem, we present a machine learning-based two-stage solution framework that finds approximate solutions within a reasonable timeline.We conduct a simulation study on the 2022 Gyeonggi Metropolitan Food Bank dataset. We find that, while redistributing donated foods may increase routing costs, it can significantly enhance the operational efficiency and equity of the entire food bank system. Our research contribution lies in providing an effective evaluation method and objective function, as well as proposing an inventory-based machine learning algorithm to ensure the matching between complex inventory and demands, thereby enhancing the operational efficiency and timeliness of food bank operations."
소규모 데이터 환경을 위한 사전학습 모델을 활용한 2단계의 음향 분류 신경망 학습 알고리즘 연구,2025,"['기계학습', '소규모 데이터', '사전학습 모델', '음향 장면인식', 'Machine learning', 'Small scale data', 'Pretrained model', 'Acoustic scene classification']","기계학습으로 신경망을 학습하는 과정에서 학습 데이터는 직접적으로 성능에 큰 영향을 미친다. 가용한 학습데이터의 양이 제한적인 환경에서 학습하고자 하는 신경망의 매개변수의 양이 일정 규모 이상일 경우 학습에 부정적인 영향을 미쳐 오히려 작은 매개변수를 가지는 신경망을 사용하는 것과 대비하여 성능이 저하된다. 이러한 데이터 부족으로 인한 문제를 완화하고자 본 논문에서는 특징 추출 및 분류기 신경망의 2단계로 구성된 신경망 구조 및 사전에 학습이 완료된 대형 신경망 모델의 출력을 사용하여 특징 추출 신경망을 학습하는 방법을 제안한다. 제안하는 방법 및 기존 방식의 신경망들을 소규모의 데이터를 사용하여 학습하여 음향 장면의 분류 성능 및 신경망의 복잡도 정도를 산출하였다. 제안하는 방법의 분류 성능은 기존 방식으로 학습하는 신경망 대비하여 유사한 복잡도 수준에서 더 우수한 분류 결과를 얻었으며, 기존 방식으로 학습한 신경망의 분류 성능이 저하되는 정도의 신경망 규모에서도 효과적으로 학습하여 분류성능을 개선하였다.","Training data directly impacts neural network performance during machine learning. Limited training data causes performance degradation in larger neural networks compared to simpler ones. We propose a two stage neural network method using feature extraction and classifier networks with pretrained models to address data scarcity. Performance evaluation on small scale datasets compared our method against conventional networks. Our approach achieved improved classification performance at similar complexity levels. The method demonstrated improved performance of the proposed method even with complex models where traditional training models of similar complexity typically degrade performance, showing effectiveness of the proposed method under data constraints."
Hate Speech Identification and Categorization on Social Media Using Bi-LSTM: An Information Science Perspective,2025,"['hate speech detection', 'social media', 'deep learning', 'machine learning', 'metadata organization', 'content labelling']",,"Online social networks empower individuals with limited influence to exert significant control over specific individuals' lives and exploit the anonymity or social disconnect offered by the Internet to engage in harassment. Women are commonly attacked due to the prevalent existence of sexism in our culture. Efforts to detect misogyny have improved, but its subtle and profound nature makes it challenging to diagnose, indicating that statistical methods may not be enough. This research article explores the use of deep learning techniques for the automatic detection of hate speech against women on Twitter. It offers further insights into the practical issues of automating hate speech detection in social media platforms by utilizing the model's capacity to grasp linguistic nuances and context. The results highlight the model's applicability to information science by addressing the expanding need for better retrieval of hazardous content, scalable content moderation, and metadata organization. This work emphasizes content control in the digital ecosystem. The deep learning-based methods discussed improve the retrieval of data connected to hate speech in the context of a digital archive or social media monitoring system, facilitating study in fields including online harassment, policy formation, and social justice campaigning. The findings not only advance the field of natural language processing but also have practical implications for social media platforms, policymakers, and advocacy groups seeking to combat online harassment and foster inclusive digital spaces for women."
Trustworthiness evaluation of workers in critical facilities using electroencephalography-based acquaintance test,2025,"['Electroencephalography', 'Critical facilities', 'Security culture', 'Acquaintance test', 'Machine learning']",,"This study emphasized the critical importance of prioritizing workers’ trustworthiness in safeguarding critical facilities from the potential harm caused by insiders’ betrayal. By noting the limitations of existing physical protection systems in critical facilities, this study showed that effectively characterizing and detecting malicious insider activity can be possible by observing immediate brain physiological reactions to specific stimuli. Based on the finding, a novel approach using electroencephalography (EEG)-based acquaintance tests was introduced to objectively assess ’a level of suspicion between colleagues by measuring their brain responses when he/she is exposed to familiar and unfamiliar stimuli. If a person claims falsely about one’s acquaintance, the model assumes he/she has malicious or suspicious intent by violating the reporting obligation. The experiment was designed with a relatively short time of monitoring of less than 2 min and with a simple EEG headband device called MUSE. The experiment is to analyze whether the model could provide reliable prediction of disguised acquaintance avoiding complex preparation process. Averaged N170 peak analysis indicated that MUSE provided adequate signal characteristics to classify acquaintance. Also, a machine learning-based subject-wise classification model showed adequate capability to differentiate the EEG signals of acquaintances from unknowns. The final prediction combined multiple single-trial classification results, correctly detected the participant’s acquaintance about 94.1 % of the cases, with similar performance when strangers were presented. The results indicated the possibility of using biosignal to enhance security culture and mitigate insider threats in critical facilities, by providing an indication of behavior that disregards security policies and procedures"
Fault detection and prediction according to the location of vibration occurrence in motors,2025,"['Motor', 'Torsional Vibration Fault Detection', 'Similarity Analysis', 'Machine Learning']",,"Torsional vibration occurring in a motor can cause not only simple mechanical damage but also severe problems in the entire connected operating system. To prevent this and maintain operational efficiency, preemptive fault detection and prediction technology using motor vibration data is emerging as an important field in automation. However, existing studies primarily focus on fault detection techniques based on data collected in a specific RPM range and have limitations in sufficiently reflecting the environmental variability and data collection constraints of the actual industry. To solve these problems, in this paper, we propose a new classification model that can operate effectively even under various RPM conditions and limited data environments. The proposed model complements the limitations of existing approaches and improves the accuracy and reliability of fault detection by combining similarity-based analysis and machine-learning techniques based on vibration data collected in the time and frequency bands. In addition, various algorithms that are widely used in multi-class classification problems were applied to compare the performance of each technique and select an optimal fault detection model."
A Privacy-Preserving and Intelligent Authentication Scheme for Next Generation-CPS,2025,"['Artificial Intelligence', 'Cyber-Physical Systems', 'Intrusion detection', 'Machine Learning', 'Security Authentication']",,"Existing security authentication mechanisms conventionally used for cyber-physical systems (CPS) are facing major challenges. This is mainly due to their reliance on the sample data of illegitimate users and the inevitable misdetection situation. That is, multiple new malicious clone nodes attack the receiver while the well-trained illegal users no longer attack, leading to cascading risks of privacy-preserving techniques. To circumvent these obstacles, we developed an intelligent prediction-based authentication (IPA) scheme that aggregates the predictions of the multi-layer long short-term memory (LSTM) network to safeguard the next generation CPS. First, the time-varying communication link-related attribute of legitimate device peers is explored to improve robustness in wireless environments. Specifically, by combing it with a high order cumulant, we proposed a signal processing method based on moving average filtering and Gaussian smoothing filtering in order to eliminate channel noise and improve the efficiency of the authenticator. The proposed IPA-based clone node detection approach is conducted through extensive simulations and experiments in real industrial environments. Simulation results show that the proposed IPA scheme significantly improves the authentication performance and is more practical without using illegal user training data, as it performs better than the existing machine learning-based benchmark."
Mitigating jamming attacks in underwater sensor networks using M-Qubed-based opportunistic routing protocol,2025,"['game theory', 'jamming attack', 'opportunistic routing', 'reinforcement learning', 'underwater sensor network']",,"Routing in underwater sensor networks (UWSNs) is highly challenging because of harsh underwater conditions, such as deep water, high pressure, and rapid ocean currents. Furthermore, UWSNs are vulnerable to jamming attacks because of their limited bandwidth and battery capacity. Advance-ments in machine learning enable numerous routing methods to address these problems. Accordingly, we propose a novel max or minimax Q-learning (M-Qubed)-based opportunistic routing method for UWSNs. The method uses an opportunistic routing protocol, in which nodes dynamically select the next relay node by considering the status of their neighbors. Moreover, M-Qubed can maximize the benefits for both players in a two-player repeated game through reinforcement learning. Hence, it can reduce the energy loss caused by jamming attacks during routing, thereby increasing the routing efficiency in UWSNs. Simulation results reveal that the proposed routing scheme is less affected by jamming attacks than existing state-of-the-art routing methods. In addition, it can balance energy consumption across the nodes in a UWSN."
개인별 경락 전기신호 패턴 기반의 맞춤형 건강상태 분석 시스템 구현,2025,"['Meridian Signal Analysis', 'Personalized Medicine', 'Bioelectrical Signals', 'Machine Learning', 'Health Assessment']",,"This paper proposes a personalized health assessment system based on individual meridian electrical signal patterns. Traditional meridian signal analysis uses standardized thresholds, which often leads to inaccurate diagnoses due to significant variations in electrical signals between individuals. Our research demonstrates that meridian electrical signals exhibit unique patterns for each individual, similar to fingerprints, making standardized analysis ineffective. We developed a machine learning-based system that learns individual signal patterns and creates personalized baselines for health assessment. Through extensive testing with 200 participants over 6 months, our system achieved 89% accuracy in detecting abnormal conditions, compared to 62% using standardized thresholds. The system showed particular effectiveness in identifying early signs of autonomic nervous system disorders and stress-related conditions. This research provides a framework for more accurate and personalized traditional medicine diagnostics."
산림조사 자료의 표본점 할당 모델링을 통한 고해상도 산림공간정보 구축,2025,"['forest mapping', 'forest type map', 'machine learning', 'national forest inventory', 'random forests']","기후위기 속에서 산림의 가치는 더욱 중요해지고 있으며, 이를 극대화하기 위해서는 수종 구성, 영급 분포, 구조적특성, 탄소저장량 등 종합적인 산림공간정보가 필수적이다. 최근 머신러닝 기반 공간분석을 응용하여 표본점 중심의 산림조사 자료를 넓은 지역으로 확장하는 연구가 활발하며, 이를 국내 산림 환경에 적용하기 위한 검토가 필요하다. 이 연구는 지리산 지역을 대상으로 랜덤 포레스트(random forests) 기반의 표본점 할당 모델링을 수행하여 임목 수준의 고해상도 산림공간정보를 구축하였다. 이를 위해, 국립공원연구원, 서울대학교 남부학술림의 산림조사 자료를 일관된 기준으로 통합하였으며, 세 자료를 선택하는 조합에 따라 총 7개의 모형을 구성하여 성능을 다각적으로 검증한 후 최적의 모형을 선정하였다.표본점 할당 모델링은 연구지역 각 지점에서 임상, 임분고, 경급이 가장 유사한 표본점을 식별하여 산림조사 자료를 할당하도록 설계하였다. 모형 학습에서는 산림조사 지점에서 분류된 임상, 임분고, 경급의 식생변수를 다중반응변수로 설정하였고, 각 지점의 환경변수를 결합하여 참조자료로 이용하였다. 학습된 모형은 임상도, 기후, 지형, 위치 등의 환경정보를 포함하는목표자료에 따라 연구지역 전반에 표본점을 할당하였으며, 최종적으로 100 m × 100 m 해상도의 래스터(raster) 기반 공간자료를 생성하였다. 모형 성능 평가 결과, 단일 기관의 자료만으로 구성한 모형은 해당 기관의 조사 특성이 과도하게 반영되어특정 산림 유형을 과대 혹은 과소 추정하는 경향을 나타냈다. 그에 반해, 세 기관의 자료를 모두 통합하여 활용한 모형은산림조사 자료 및 임상도를 재현하는 성능이 가장 우수하였으며, 전체적인 산림 분포 패턴을 안정적으로 예측하였다. 이 연구의 표본점 할당 모델링은 표본점의 고유번호를 가지는 래스터 지도를 제공하여, 사용자가 고유번호와 연결된 상세 산림정보에 접근하고 다양한 속성지도를 제작할 수 있도록 한다. 따라서 이 프레임워크는 수종의 분포 예측, 산림 구조 분석, 탄소저장량 평가 등 다양한 분야에 적용될 수 있으며, 산림조사 자료의 활용성을 크게 향상할 수 있다. 다만, 모형의 특성상 넓은 지역을 대상으로 할 때는 산림조사 지점과의 국지적 일치율이 낮아질 수 가능성이 있으며, 좁은 지역에서는 균형 잡힌산림조사 자료를 이용해 희소한 생태계의 정보를 충분히 확보해야 한다. 향후 산림조사 자료의 활용도를 더욱 높이려면 기관 간 조사 프로토콜을 표준화하고, 모델링 과정에서 각 기관 조사방식의 차이를 면밀히 분석하여 반영할 필요가 있다.","Forests are increasingly valuable as climate change intensifies, and their conservation management requires comprehensive spatial information on the species composition, stand age distribution, structural characteristics, and carbon storage. Recent studies have employed machine learning-based spatial analyses for plot-based forest surveys across broad regions, but the effectiveness of this approach in South Korea remains understudied. We applied a plot imputation approach using random forests to create a high-resolution tree-level forest map of the Jiri Mountain. We standardized and integrated forest survey data from the Korea Forest Service, Korea National Park Research Institute, and Seoul National University Nambu Forest and then built seven models for evaluation. Each model identified sample points with similar vegetation attributes (class, height, and diameter) across the study area. We trained the models using a reference dataset of vegetation and environmental variables and then assigned sample points throughout the study area based on target datasets including a forest-type map and environmental data on climate, topography, and location to generate a raster map at a 100 m × 100 m resolution. When applied to a single-institution dataset, the models tended to over- or under-estimate certain vegetation attributes likely due to survey biases.Integrating all three datasets resulted in a more balanced view of overall forest patterns and yielded the highest reproduction accuracy. The developed framework generates raster maps with unique plot identifiers to enable users to access plot details and create thematic maps for the species distribution, forest structure, and carbon storage.However, uneven distribution of the survey points may cause local losses of accuracy. Balanced forest surveys are crucial for capturing details about rare or specialized ecosystems. Standardizing survey protocols across institutions and carefully examining the differences in each dataset will be crucial to enhancing both the data quality and modeling applications of the framework."
Enhanced Facial Emotion Recognition Using Vision Transformer Models,2025,['Facial emotion recognition · Vision transformer · Self-attention · Machine learning · Artifcial intelligence · Computer vision · Deep learning · Emotion detection'],,"Automation of facial emotion recognition is an important branch of artifcial intelligence and computer vision that has many potential applications in mental health diagnostics, human–computer interaction and security. The existing methods, however, usually have weaknesses in robustness, scalability and computational efciency. This work proposes a self-attention-based Vision Transformer method that treats images as sequences of patches to capture global dependencies and spatial relations more efectively than other methods. The model is trained and evaluated using a large-scale dataset. On average, the model achieves an overall accuracy of 97%, with good precision, recall and F1 scores in most emotion categories. The model performed better and was more robust to variations in illumination and facial pose compared to other existing methods. This work takes a step forward in facial emotion recognition technology, providing a large-scale and efcient solution for realworld applications. Facial Emotion Recognition, a New Vision Transformer Based on Self-Attention for Machine Learning."
VPN과 Non-VPN 트래픽의 분류 모델 개발 및 중요 요인 분석,2025,"['VPN', 'NoN-VPN', 'Network Traffic Classification', 'Machine Learning Models', 'Feature Importance Analysis', 'VPN', '비 VPN', '네트워크 트래픽 분류', '머신러닝 모델', '특징 중요도 분석']","코로나19 팬데믹 이후 원격 근무가 확산되면서 VPN(Virtual Private Network) 사용량이 증가함에 따라 보안 위협 또한 커졌다. VPN은 안전한 네트워크 환경을 제공하지만, 사이버 범죄자들이 불법적인 활동을 은닉하는 수단으로 악용할 가능성이 있어 VPN 트래픽과 Non-VPN 트래픽을 효과적으로 분류하는 기술이 필요하다. 그러나 VPN 트래픽은 암호화된 형태로 전송되므로, 기존 패킷 검사 방식만으로는 탐지에 한계가 있다. 본 연구에서는 VPN 탐지를 위해 ISCXVPN2016 데이터세트를 활용하고, 트래픽 흐름(Flow-Based) 데이터를 바탕으로 트리 기반 머신러닝 모델을 개발하였다. 특히, VPN과 Non-VPN 트래픽 분류 성능을 비교하기 위해 Decision Tree, XGBoost, Random Forest, Gradient Boosting 모델을 적용하였으며, Orange3 환경에서 실험을 수행하였다. 실험 결과, XGBoost 모델이 가장 높은 분류 정확도를 기록하였으며, 특히 15초 흐름 지속 시간(Flow Duration) 기반 데이터에서 최상의 성능을 보였다. 또한, 훈련된 모델의 성능에 영향을 미치는 요인을 분석하기 위해 Feature 중요도 분석을 수행하고, 유의미한 특징을 찾기 위한 통계 분석을 병행하였다. 이를 통해, 대역폭 사용량(FlowBytesPerSecond), 패킷 간 시간 간격(FlowIAT) 등 10가지 주요 Feature가 VPN 탐지 성능에 중요한 영향을 미치는 요소임을 확인하였다. 이러한 결과는 머신러닝 기반 VPN 탐지 모델의 실효성을 입증하며, 향후 실시간 네트워크 보안 및 IDS(Intrusion Detection System) 적용 가능성을 제시한다.","With the expansion of remote work following the COVID-19 pandemic, the use of Virtual Private Networks (VPNs) has increased, leading to heightened security threats. While VPNs provide a secure network environment, cybercriminals can exploit them to conceal illegal activities, necessitating effective classification techniques to distinguish between VPN and Non-VPN traffic. However, since VPN traffic is transmitted in an encrypted format, traditional packet inspection methods face limitations in detection. This study uses the ISCXVPN2016 dataset to develop a tree-based machine learning model for VPN detection, leveraging flow-based network traffic data. We develop a Decision Tree, XGBoost, Random Forest, and Gradient Boosting models to compare VPN and Non-VPN traffic classification performance, conducting experiments within the Orange3 environment. The experimental results demonstrate that the XGBoost model achieved the highest classification accuracy, particularly excelling with 15-second flow duration-based data. Additionally, feature importance analysis was performed to identify key factors influencing the performance of the trained model, alongside statistical analysis to extract meaningful characteristics. We confirmed that 10 key features significantly impact VPN detection performance, including FlowBytesPerSecond (bandwidth usage) and FlowIAT (inter-packet time intervals). These findings validate the effectiveness of machine learning-based VPN detection models and suggest their potential applicability in real-time network security and Intrusion Detection Systems (IDS)."
LDA 토픽 모델링을 활용한 글로벌 기상 분야의 인공지능 연구동향 분석 (2018~2024년 논문 주제 중심),2025,"['Artificial intelligence', 'Weather forecasting', 'Climate change', 'Topic modeling', 'Machine learning']",,"This study aims to analyze research trends related to Artificial Intelligence (AI) in the global meteorological field from 2018 to 2024 and identify the major research topics and keywords. By utilizing the Web of Science database, a total of 5,846 papers related to AI in meteorology were identified and analyzed. The study employed latent Dirichlet allocation (LDA) topic modeling to extract the main research topics. The optimization of topic modeling parameters was performed by adjusting document-topic density (alpha) and word-topic density (beta) distributions, which control the concentration of topics in documents and words in topics, respectively. Through comprehensive parameter optimization, the model achieved the coherence score of 0.639 with alpha value of 0.08, beta value of 0.01, and 6 topics, indicating clear and well-separated research themes in the field. These optimal parameter values were used for the topic modeling analysis. The analysis revealed that (1) research on ‘AI-based prediction of hydrological variables’ encompasses studies applying AI techniques to predict hydrological variables such as rainfall and evaporation, aiming for more precise meteorological forecasting. (2) Studies on ‘AI-based analysis of the impacts of climate change’ utilize AI models to analyze the effects of climate change on various regions and ecosystems, assessing potential impacts under different climate change scenarios and predicting future environmental changes. (3) Research on ‘AI-based prediction of oceanic and surface temperatures’ focuses on improving the accuracy of meteorological and environmental observations by predicting ocean and land surface temperatures using satellite data. (4) Studies on ‘Machine learning-based risk assessment and prediction of natural disasters’ evaluate and predict the likelihood of natural disasters such as floods and landslides, providing crucial information for disaster management and prevention. (5) Research on ‘AI and meteorological data utilization for real-time rainfall prediction’ aims to enhance the accuracy of real-time rainfall forecasting by combining meteorological radar data with AI techniques, playing a critical role in rapidly changing weather conditions. (6) Studies on ‘AI utilization in wind power forecasting and meteorological condition analysis’ aim to optimize wind energy production by predicting wind speed and weather conditions, contributing to efficient energy management. This study systematically analyzes research trends related to the application of AI in meteorology, contributing to the academic development of the field and suggesting future research directions. Specifically, by identifying research trends through topic modeling, this study provides a structured understanding of the convergence of meteorology and AI, offering valuable foundational data to researchers in the field."
Multi-Parameter MRI for Evaluating Glymphatic Impairment and White-Matter Abnormalities and Discriminating Refractory Epilepsy in Children,2025,"['Glymphatic system', 'White-matter abnormalities', 'Pediatric refractory epilepsy', 'Multi-parameter', 'Machine-learning']",,"Objective: To explore glymphatic impairment in pediatric refractory epilepsy (RE) using multi-parameter magnetic resonance imaging (MRI), assess its relationship with white-matter (WM) abnormalities and clinical indicators, and preliminarily evaluate the performance of multi-parameter MRI in discriminating RE from drug-sensitive epilepsy (DSE).Materials and Methods: We retrospectively included 70 patients with DSE (mean age, 9.7 ± 3.5 years; male:female, 37:33) and 26 patients with RE (9.0 ± 2.9 years; male:female, 12:14). The diffusion tensor imaging analysis along the perivascular space (DTI-ALPS) index as well as fractional anisotropy (FA), mean diffusivity (MD), and nodal efficiency values were measured and compared between patients with RE and DSE. With sex and age as covariables, differences in the FA and MD values were analyzed using tract-based spatial statistics, and nodal efficiency was analyzed using a linear model. Pearson’s partial correlation was analyzed. Receiver operating characteristic (ROC) curves were used to evaluate the discrimination performance of the MRI-based machine-learning models through five-fold cross-validation.Results: In the RE group, FA decreased and MD increased in comparison with the corresponding values in the DSE group, and these differences mainly involved the callosum, right and left corona radiata, inferior and superior longitudinal fasciculus, and posterior thalamic radiation (threshold-free cluster enhancement, P < 0.05). The RE group also showed reduced nodal efficiency, which mainly involved the limbic system, default mode network, and visual network (false discovery rate, P < 0.05), and significantly lower DTI-ALPS index (F = 2.0, P = 0.049). The DTI-ALPS index was positively correlated with FA (0.25 ≤ r ≤ 0.32) and nodal efficiency (0.22 ≤ r ≤ 0.37), and was negatively correlated with the MD (-0.24 ≤ r ≤ -0.34) and seizure frequency (r = -0.47). A machine-learning model combining DTI-ALPS, FA, MD, and nodal efficiency achieved a cross-validated ROC curve area of 0.83 (sensitivity, 78.2%; specificity, 84.8%).Conclusion: Pediatric patients with RE showed impaired glymphatic function in comparison with patients with DSE, which was correlated with WM abnormalities and seizure frequency. Multi-parameter MRI may be feasible for distinguishing RE from DSE."
스태킹 앙상블(Stacking Ensemble) 기법을 활용한 청소년의 인지적 공감과 사회적 행동 간의 불일치 예측,2025,"['Cognitive empathy', 'Prosocial behavior', 'Adolescent development', 'Stacking ensemble', 'Machine learning prediction', '정서 인식 역량', '사회적 행동', '청소년 발달', '스태킹 앙상블', '머신러닝 기반 예측']","본 연구는 청소년의 정서인식 역량과 사회적 행동 간 발달적 불일치(mismatch) 현상에 주목하여, 그 차이를 설명하고 예측할 수 있는 주요 요인을 분석하였다. 이를 위해 스태킹 앙상블(stacking ensemble) 기법을 활용한 머신러닝 기반 예측 모형을 적용하였으며, 분석 자료로는 2021년 한국아동․청소년패널조사(KCYPS) 제4차년도 중학교 1학년 코호트 데이터를 활용하였다. 총 2,265명의 고등학교 1학년 학생 데이터를 분석 대상으로 하였으며, 개인, 가정, 학교 관련 변수 188개를 설명변수로 포함하였다. 분석 결과, 정서인식 역량과 사회적 행동은 동일한 발달 경로를 따르지 않으며, 그 차이는 부모의 정서인식 역량, 학생의 그릿(Grit), 사회적 위축, 우울, 학업열의, 교사와의 관계, 여가시간 활용 등 다양한 요인에 의해 설명될 수 있음이 확인되었다. 스태킹 앙상블 모형은 기존의 단일 머신러닝 알고리즘에 비해 우수한 예측 성능을 보였으며, 이는 청소년의 사회정서역량과 같이 다차원적이고 복합적인 특성을 예측하는 데 효과적인 분석 방법으로 활용될 수 있음을 시사한다.","This study investigates the developmental mismatch between adolescents’ cognitive empathy and their prosocial behavior, with the aim of identifying and predicting key factors contributing to this discrepancy. A machine learning-based prediction model was developed using a stacking ensemble approach. Data were drawn from the 2021 Korea Children and Youth Panel Survey (KCYPS), focusing on the fourth-year cohort of first-year high school students (N = 2,265). A total of 188 variables related to individual, family, and school contexts were included as predictors. The findings revealed that cognitive empathy and prosocial behavior follow distinct developmental trajectories and that their discrepancy can be explained by multiple contextual and psychological factors, including parental cognitive empathy, grit, social withdrawal, depression, academic engagement, teacher–student relationships, and leisure activity patterns. The stacking ensemble model demonstrated superior predictive performance compared to single algorithm models, validating its effectiveness for predicting complex social-emotional competencies among adolescents. These results underscore the importance of multifaceted and context-sensitive approaches to social-emotional learning, especially in addressing the gap between internal emotional understanding and externally observable social behavior."
Privacy Preservation in Artificial Intelligence-Enabled Healthcare Analytics,2025,"['Data security', 'Privacy Preserving', 'Artificial Intelligence', 'Healthcare Analytics']",,"Emerging techniques such as the Internet of Things, machine learning, and artificial intelligence (AI) have revolutionized healthcare analytics by offering a multitude of significant benefits, including real-time process, enhanced data efficiency and optimization, enabling offline operation, fostering resilience, personalized and context-aware healthcare, etc. However, privacy concerns are indeed significant when it comes to edge computing and machine learning-enabled healthcare analytics. The training and validation of AI algorithms face considerable obstacles due to privacy concerns and stringent legal and ethical requirements associated with datasets. This work has proposed a healthcare data anonymization framework to address privacy concerns and ensure compliance with data regulations by enhancing privacy protection and anonymizing sensitive information in healthcare analytics, which can maintain a high level of privacy while minimizing any adverse effects on the analytics models. The experimental results have unequivocally showcased the effectiveness of the proposed solution."
딥러닝을 이용한 구조 및 내진 안정성이 고려된 비상디젤발전기 베드 최적설계에 관한 연구,2025,"['Optimal Design(최적설계)', 'Diesel Generator(디젤발전기)', 'Seismic Stability(내진안정성)', 'Deep Learning(딥러닝)']",,"A diesel engine generator may cause a lot of vibration, so it is important to establish a damping system for the emergency diesel generator bed frame. However, for optimization of each structural element, repetitive simulation is required, which is time-consuming and expensive, so automatic optimization using deep learning is required. Therefore, in this paper, the shape and dimensions of both beams of the emergency diesel generator bed are set as design variables to generate ANSYS seismic analysis data suitable for each design variable. However, deep learning requires a large amount of data, so this data is augmented by using a random forest, a type of machine learning. Augmented data was judged to be suitable for deep learning by verifying whether it is a pattern similar to the actual analysis data through distribution Comparison of Distribution Similarity, Comparison of Conditional Statistics, and Performance Metric Evaluation. After that, the optimal design of the 500kW emergency diesel generator bed with secured structure and seismic stability was performed using the Adam optimization algorithm deep learning model that learns this augmented data. It was confirmed that the structure and seismic stability of the optimally designed bed frame was also secured through ANSYS seismic analysis."
국내 굴착 암반 부지에 대한 심부 전단파속도 주상도 예측 모델 개발,2025,"['Deep shear wave velocity profiles', 'Excavated rock sites in Korea', 'Seismological rock depth', 'Regression analysis', 'Machine learning']",,"IIn the context of site response analysis, the use of shear wave velocity ( ) profiles that consider the seismological rock ( ≥ 3,000 m/s) depth is recommended. This study proposes regression analysis and machine learning-based models to predict deep  profiles for a specialized excavated rock site in South Korea. The regression model was developed by modifying mathematical expressions from a previous study and analyzing the correlation between  and model variables to predict deep  beyond 50 m. The machine learning models, designed using tree-based algorithms and a fully connected hierarchical structure, were developed to predict  from 51 m to 300 m at 1 m intervals. These models were validated by comparing them with measured deep  profiles and accurately estimating the trend of deep  variations. The proposed prediction models are expected to improve the accuracy of ground motion predictions for a specialized excavated rock site in Korea."
스포츠 산업에서 커뮤니티 데이터를 활용한 선수 상업적 가치 평가,2025,"['자연어 처리', '감성 분석', '기계학습', 'BERT', '스포츠 산업성', 'Natural Language Processing', 'Sentiment Analysis', 'Machine Learning', 'BERT', 'Sports Commercialization']","스포츠 산업에서 선수의 상업적 가치는 경기력과 같은 객관적 지표를 넘어 유니폼 판매와 같은 굿즈 판 매량을 통해 평가될 수 있다. 유니폼 판매는 팬들의 충성도와 열정을 나타내는 지표로, 구단의 수익 및 계약 협상 에서 중요한 역할을 한다. 본 연구에서는 대한민국 프로야구 리그(KBO)를 대상으로 커뮤니티 게시판 데이터를 활 용하여 선수의 유니폼 판매량을 예측하는 새로운 방법론을 제안한다. 제안된 방법론은 두 가지 접근 방식으로 구성된 다. 첫 번째로, 게시글 텍스트 및 메타데이터로부터 추출된 특징을 기반으로 랜덤 포레스트, 서포트 벡터 회귀(SVR), 그래디언트 부스팅과 같은 기계학습 모델을 학습시켰다. 두 번째로, BERT(Bidirectional Encoder Representations from Transformers)를 활용하여 생성된 임베딩 벡터를 LSTM(Long Short-Term Memory) 모델에 입력하여 시 계열 데이터를 학습시켰다. 실험 결과, BERT 기반 LSTM 모델은 평균 절대 오차(MAE) 1.42, 상위 5위 예측 정 확도(Hit Rate5) 91.67%, 상위 3위 예측 정확도(Hit Rate3) 66.67%로 우수한 성능을 보였고, SVR 모델도 가장 낮은 MAE(1.25)를 기록하며 높은(Hit Rate5) 성능(91.67%)을 나타냈다. 이를 통해, 제안된 모델들이 게시판 데이 터를 활용하여 선수의 상업적 가치를 예측하는 데 유의미한 성과를 보임을 확인하였다.","In the sports industry, a player's commercial value can be assessed not only through performance metrics but also merchandise sales, such as uniform sales, which reflect fans' loyalty and passion. This study introduces a methodology to predict player uniform sales using Korea Baseball Organization (KBO) community bulletin board data. Two approaches were employed: (1) machine learning models like random forest, SVR, and gradient boosting were trained using features from post text and metadata; (2) BERT embeddings were used with an LSTM model for time-series analysis. Experimental results showed the BERT-LSTM model achieved an MAE of 1.42, top-5 prediction accuracy of 91.67%, and top-3 accuracy of 66.67%. The SVR model also performed well, with a top-5 accuracy of 91.67% and the lowest MAE of 1.25. These results demonstrate the effectiveness of using bulletin board data to predict players' commercial value."
인용문 및 속성 인코더 혼합 모델 기반 경제 뉴스 맞춤형 감성 분석,2025,"['감성 분석', '딥러닝', 'BERT', 'KoBERT', 'KLUE', 'mixture of experts(MoE)', 'sentiment analysis', 'deep learning', 'BERT', 'KoBERT', 'KLUE', 'mixture of experts (MoE)']","뉴스 기사는 정치, 경제, 사회, 문화 등 다양한 주제의 정보를 제공하며, 중립적인 논조를 유지하려는 특성상 기존 감성 분석 모델이 감정을 충분히 포착하지 못하는 한계가 있었다. 이를 해결하기 위해 본 연구에서는 인용문과 기사 속성 값을 결합한 새로운 감성 분석 모델을 제안한다. 감성 분석에는 딥러닝 기반의 BERT와 한국어에 최적화된 KoBERT, KLUE 모델을 사용했으며, 이 모델을 사용한 임베딩 결과를 Mixture of Experts(MoE) 구조로 결합하여 인용문의 감정 정보와 기사 속성 정보를 동시에 학습시켰다. 실험 결과, 제안된 모델 중 속성별 문자열 및 속성 그룹 임베딩 모델이 기존의 인용문 단독 분석 및 전통적 기계 학습 모델에 비해 더 높은 정확도와 신뢰성을 보였다. 특히 KLUE 모델은 한국어 데이터에 최적화되어 있어 성능이 향상되었고, 다양한 속성 정보가 감성 분석 모델의 예측 정확도를 높이는 데 크게 기여함을 확인할 수 있었다. 이는 인용문과 기사 속성 정보를 효과적으로 결합함으로써 중립적인 뉴스 기사에서도 더 정교한 감정 분석이 가능함을 시사한다.","News articles provide information on various topics such as politics, economics, society, and culture. Their neutral tone often limits the ability of traditional sentiment analysis models to effectively capture emotions. To address this issue, we proposed a novel sentiment analysis model that combined quotations with article attribute values. For sentiment analysis, we employed deep learning-based models such as BERT, KoBERT (optimized for Korean), and KLUE. Embedding results from these models were integrated using a Mixture of Experts (MoE) structure to simultaneously learn the emotional information in quotations and the attribute information of articles. Experimental results demonstrated that the proposed models, including the attribute-based phrase and attribute group embedding models, achieved higher accuracy and reliability than conventional quotation-only analysis and traditional machine learning models. In particular, the KLUE model optimized for Korean data showed improved performance. Incorporating diverse attribute information significantly enhanced predictive accuracies of sentiment analysis models. These findings suggest that effectively combining quotation data with article attribute information enables more sophisticated sentiment analysis, even for neutral news articles."
오디오 데이터셋의 다차원 분석과 시각화,2025,"['오디오 시각화', '클러스터링', '데이터 분석', '차원 축소', '기계 학습', 'Audio Visualization', 'Clustering', 'Data Analysis', 'Dimensionality Reduction', 'Machine Learning']","본 연구는 대규모 오디오 데이터셋의 분석과 시각화를 위한 다차원 접근 방식을 제안한다. 기존의 메타데이터 기반 분석 방법은 확장성과 자동화 측면에서 한계가 있으며, 대용량 오디오 데이터의 효율적인 탐색을 저해한다. 이러한 문제를 해결하기 위해, 본 연구는 오디오 설명자 기반의 차원 축소 및 클러스터링 기법을 통합하고, 3차원 포인트 클라우드를 활용한 인터랙티브 시각화 기법을 도입하였다. 제안된 시스템은 t-SNE와 UMAP을 k-means 클러스터링과 결합하여 고차원 음향 데이터의 유사도 기반 구조를 직관적으로 파악할 수 있도록 지원한다. 또한 PCA 기반 색상 매핑과 샘플링 기법을 통해 시각적 해석력을 강화하였다. 해당 시스템은 기존 수동 주석 방식의 한계를 보완하며, 기계학습 기반 분석을 통해 효율적인 탐색 환경을 제공한다. 제안된 방식은 MIR, 사운드 디자인, 음향 데이터 분석 등 다양한 분야에 활용될 수 있다.","This study proposes a multidimensional approach for analyzing and visualizing large-scale audio datasets. Traditional metadata-based analysis methods exhibit limitations in scalability and automation, which hinder efficient exploration of extensive audio datasets. To address these challenges, the proposed system integrates dimensionality reduction and clustering techniques based on audio descriptors and introduces an interactive 3D point-cloud visualization framework. By combining t-SNE and UMAP with k-means clustering, this approach facilitates intuitive understanding of structural patterns in high-dimensional acoustic data. PCA-based color mapping and representative data sampling are employed to enhance interpretability. The system overcomes the constraints of conventional tagging-based methods and enables efficient, interactive exploration through machine learning-driven analysis. This approach has potential applications in music information retrieval (MIR), sound design, and acoustic data visualization."
Cross-Layer Attention 을 적용한 EfficientNet 기반 악성코드 유형 분류 기법,2025,"['Malware Classification', 'Cross-Layer Attention', 'Efficientnet', 'Convolution Neural Network', 'Grad-CAM']","최근 악성코드는 다양한 난독화 및 변형 기술을 통해 지속적으로 진화하고 있으며, 기존의 서명 기반 탐지 기법만으로는 효과적인 대응이 어렵다. 이를 극복하기 위해 머신러닝 기반 탐지 기법이 활발히 연구되고 있으며, 특히 CNN을 활용한 이미지 기반 분석이 주목받고 있다. 그러나 CNN 모델은 국소적인 특징 학습에 집중하는 경향이 있어, 계층이 깊어질수록 초기 계층에서 학습된 저수준 특징이 희미해지거나 변형되는 문제가 발생한다. 이는 악성코드 이미지 분석에서 중요한 구조적 패턴이 손실될 가능성이 높이고, 정교한 난독화 기법이나 고도화된 변종 악성코드에 대한 일반화 성능 저하로 이어질 수 있다. 본 논문에서는 이러한 한계를 개선하기 위해 EfficientNet을 기반의 CLA(Cross-Layer Attention)를 적용한 악성코드 이미지 분류 기법을 제안한다. 제안하는 CLA 기법은 초기 계층에서 학습된 특징을 보존하고 후반부 계층과 결합함으로써 CNN의 정보 손실 문제를 보완하고, 채널 간 정보 활용과 전역적 문맥 이해를 강화한다. 실험 결과, EfficientNet-CLA 모델은 CNN 및 ViT 계열 모델 대비 Accuracy 98.57%로 가장 우수한 성능을 보였다. 이는 제안하는 기법이 기존 모델보다 더욱 견고한 특징 학습을 가능하게 하며, 일반화 성능 또한 향상되었음을 의미한다. 또한 Grad-CAM 분석을 통해 CLA가 CNN의 전역적 특징 학습을 보완하는 역할을 수행함을 시각적으로 검증하였다.","Recently, malware is continuously evolving through various obfuscation and modification techniques, and it is difficult to respond effectively with only the existing signature-based detection methods. To overcome this, machine learning-based detection methods are actively being studied, and in particular, image-based analysis using CNN is attracting attention. However, CNN models tend to focus on learning local features, and as the layer becomes deeper, low-level features learned in the early layers become blurred or modified. This increases the possibility of losing important structural patterns in malware image analysis, and can lead to a decrease in generalization performance for sophisticated obfuscation techniques or advanced variants of malware. In this paper, we propose a malware image classification method using EfficientNet-based CLA (Cross-Layer Attention) to improve these limitations. The proposed CLA method complements the information loss problem of CNN by preserving features learned in the early layers and combining them with later layers, and enhances information utilization across channels and global context understanding. Experimental results show that the EfficientNet-CLA model has the best performance with an accuracy of 98.57% compared to CNN and ViT series models. This means that the proposed method enables more robust feature learning than existing models, and generalization performance is also improved. In addition, Grad-CAM analysis visually verifies that CLA plays a complementary role in CNN's global feature learning."
정확한 공격 시도 감지를 위한 BERT 기반 APT 특성 추출 및 분류,2025,"['APT 공격', '헥사 문자열', 'n-gram', 'BERT 마이닝', '퓨샷 학습', 'APT Atack', 'Hex String', 'n-gram', 'BERT Mining', 'Few-Shot Learning']","APT 공격은 특정 조직을 장기간 표적화하며 정교한 해킹 기법을 활용하는 사이버 위협으로, 국가 주도 해킹 그룹 및 사이버 범죄 조직에 의해 자주 수행되며, 고도로 정교한 방식으로 특정 표적을 오랜 기간에 걸쳐 지속적으로 공격하면서 기밀 정보에 접근하여 이를 탈취하는 방법으로 진행되고 있어 이를 적시에 탐지하는 것이 어려운 실정이다. 그리고 일반 악성 코드 들은 불특정 다수를 대상으로 하지만, APT 공격은 정부 관련 기관, 금융기관 또는 기업을 공격 대상으로 삼고 있기에 그 피해 는 개인뿐만 아니라 국가, 기업 등과 같이 사회 전반에 영향을 미쳐 사회, 경제, 국가 안보를 크게 위협할 수 있어 조기에 탐지 하는 것이 절실히 필요하다. 따라서 본 논문에서는 APT 공격 실행 파일의 특성을 분류하기 위해 n-gram 분석 및 BERT 기반 텍스트 마이닝 기법을 활용한 특성 분류 기법을 제안한다. 이 기법은 APT 실행 파일을 16진수 문자열로 변환한 후 n-gram 방 식으로 특징을 표현하고, 이를 BERT 모델에 입력하여 고유한 특징 벡터를 생성한다. 이후 퓨삿 학습(Few-shot Learning)을 적용하여 실행 파일의 패턴을 보다 정밀하게 분류하는 방식으로 APT 특성을 체계적으로 분류하였다. 본 논문에서 제안한 기법 은 기존의 머신러닝 기반 탐지 모델보다 APT 공격 탐지 정확도가 8~12% 향상되었음을 확인할 수 있었다. 특히 난독화된 코드 와 파일리스 공격 기법을 탐지하는 데 있어 기존 탐지 모델보다 효과적임을 알 수 있었다. 이를 바탕으로 APT 공격 실행 파일 탐지를 위한 보다 정교한 분석 프레임워크 개발과 향후 실시간 APT 탐지 시스템 개발에 기여할 수 있을 것으로 기대된다.","APT attacks are cyber threats that target specific organizations for a long period of time and utilize sophisticated hacking techniques. They are frequently carried out by state-sponsored hacking groups and cybercrime organizations. They are carried out by continuously attacking specific targets over a long period of time in a highly sophisticated manner, accessing and stealing confidential information, making it difficult to detect them in a timely manner. In addition, while general malware targets an unspecified number of people, APT attacks target government-related organizations, financial institutions, or companies, so the damage can affect not only individuals but also the entire society, such as countries and companies, and can significantly threaten society, economy, and national security. Therefore, early detection is urgently needed. Therefore, in this paper, we propose a feature classification technique that utilizes n-gram analysis and BERT-based text mining techniques to classify the characteristics of APT attack executable files. This technique converts APT executable files into hexadecimal strings, expresses the features in n-gram format, and inputs them into a BERT model to generate a unique feature vector. After that, we systematically classified the APT characteristics by applying Few-shot Learning to classify the patterns of executable files more precisely. We could confirm that the technique proposed in this paper improved the APT attack detection accuracy by 8-12% compared to the existing machine learning-based detection model. In particular, it was found to be more effective than the existing detection model in detecting obfuscated codes and fileless attack techniques. Based on this, it is expected to contribute to the development of a more sophisticated analysis framework for detecting APT attack executable files and the development of a real-time APT detection system in the future."
무인항공기 이상탐지를 위한 CNN-LSTM-Autoencoder 모델 개발 및 경량화,2025,"['UAVs(Unmanned Aerial Vehicles)', 'CNN-LSTM-Autoencoder', 'Anomaly Detection', 'Model Compression', 'Energy Efficiency']",,"Anomaly detection technique for the Unmanned Aerial Vehicles (UAVs) is one of the important techniques for ensuring airframe stability. There have been many researches on anomaly detection techniques using deep learning. However, most of research on the anomaly detection techniques are not consider the limited computational processing power and available energy of UAVs. Deep learning model convert to the model compression has significant advantages in terms of computational and energy efficiency for machine learning and deep learning. Therefore, this paper suggests a real-time anomaly detection model for the UAVs, achieved through model compression. The suggested anomaly detection model has three main layers which are a convolutional neural network (CNN) layer, a long short-term memory model (LSTM) layer, and an autoencoder (AE) layer. The suggested anomaly detection model undergoes model compression to increase computational efficiency. The model compression has same level of accuracy to that of the original model while reducing computational processing time of the UAVs. The proposed model can increase the stability of UAVs from a software perspective and is expected to contribute to improving UAVs efficiency through increased available computational capacity from a hardware perspective."
물리과정 기반 및 GAN 기반 강수 예측 모델의 예측 성능 평가: 영산강 유역 사례 연구,2025,"['Precipitation nowcasting', 'Radar', 'cGAN', 'WRF', '강우예측', '레이더', 'cGAN', 'WRF']","고해상도 단기 강우 예측을 생성하기 위해, 주로 레이더 자료 기반 확률론적 방법 또는 물리과정 기반 수치예보모델(Numerical Prediction Models, NWPs)이 사용되어 왔다. 최근 인공지능의 발전으로, 머신러닝을 이용한 레이더 기반 단기 강우 예측 모델 관련 연구가 활발히 진행되고 있으며, 두 시간 이내 단기 예측에서 뛰어난 성능을 보여주고 있다. 하지만 이러한 데이터 기반 모델의 경우, 예측 선행시간 증가에 따라 성능이 크게 저하하며, black-box 모델로, 대기의 물리과정을 고려하지 않는다는 한계점이 존재한다. 본 연구에서는 영산강 유역에 대해 최신 머신러닝 기법(conditional Generative Adversarial Network, cGAN)을 이용한 강우 예측 모델을 개발하여, 최대 여섯 시간 강우 예측 결과를 생성하였으며, 고해상도 수치모의가 가능한 물리과정 기반 대기모형인 Weather Research and Forecasting (WRF)와의 비교를 통해 성능 평가를 진행하였다. 모델 훈련 및 평가를 위해 2014년부터 2018년까지의 영산강 유역 강우 레이더 자료를 사용하였으며, 성능 평가 결과, 세 시간 이내 예측 선행시간에서는 cGAN 기반 강우예측 모델이 WRF 모델에 비해 평균 상관계수 R은 10%, 임계성공지수(Critical success index, CSI, 0.1 mm/hr 임계기준)은 16% 더 좋은 성능을 보였으나, 세 시간 이후로 선행시간이 증가함에 따라 WRF 모델의 예측 성능이 cGAN 기반 모델보다 R은 55%, CSI (0.1 mm/hr 임계기준)에서는 39% 더 뛰어난 것을 확인할 수 있었다. 본 연구를 통해, 머신러닝 기반 모델과 물리과정 기반 모델의 장단점을 고찰하고, 이를 보완할 수 있는 가능성을 제시하였다. 이러한 결과는 강우 예측 성능 개선을 위한 물리과정-인공지능 융합적 접근의 토대를 제공하는데 기여할 것으로 기대된다.","Radar-based methods or physics-based Numerical Prediction Models (NWPs) have been used to generate high-resolution short-range rainfall forecasts. With recent advances in artificial intelligence, research on radar-based short-range precipitation nowcasts using machine learning has been actively conducted and has shown promising performance for short-range forecasts within two hours. However, these data-driven models have the limitation of being the black-box models that do not consider atmospheric physical processes, and their performance decreases significantly as the forecast lead time increases. In this study, we developed a precipitation nowcasting model using the conditional Generative Adversarial Network (cGAN) for the Yeongsangang River basin, which generates predictions up to six hours in advance, and evaluated its performance through a comparison with Weather Research and Forecasting (WRF), a physical process-based atmospheric model capable of high-resolution numerical simulations. To train and evaluate the models, we used rainfall radar data from the Yeongsangang River basin from 2014 to 2018. During the three-hour lead time, the cGAN-based rainfall forecast model showed 10% and 16% better performance in the average correlation coefficient R and the critical success index (CSI, at 0.1 mm/hr) than the WRF. However, as the lead time increased after three hours, the WRF model's forecast performance was 55% and 39% better than the cGAN-based model in the R and CSI (at 0.1 mm/hr), respectively. In this study, we explored the strengths and weaknesses of machine learning-based models and physics-based models, suggesting possible opportunities to complement them. It is expected that our results will provide a foundation for a physics-AI integrated approach to enhance rainfall forecast performance."
"피노키오, 안티 피노키오, AI: 생기(vitality)개념을 중심으로",2025,"['카를로 콜로디', '<피노키오>', '<A.I.>', '어린이 기계', '기예르모 델 토로', '생기', '포스트휴먼', '안티 피노키오', 'Carlo Colodi', 'Pinocchio', 'A.I.', 'child machine', 'Guilermo del Toro', 'vitality', 'posthuman', 'anti-Pinocchio']","본 논문은 피노키오 동화와 영화를 통해 현대 사회에서 인간과 비인간의 경계가 어떻게 재구성되는지를 탐구한다. 카를로 콜로디의 원작 피노키오는 나무 인형이 도덕적 교훈을 통해 ‘진짜 아이’로 변모하는 성장 서사로, 인간 우위의 관점을 강화한다. 디즈니 애니메이션 <피노키오>는 이를 더욱 강조하며, 도덕과 규범을 통해 인간성을 획득하는 과정에 초점을 맞춘다. 반면, 스티븐 스필버그 감독의 <A.I.>와 기예르모 델 토로 감독의 <피노키오>는 전통적인 피노키오 서사를 비판적으로 재구성한다. 본 논문에서는 이 두 작품에서의 피노키오를 ‘안티 피노키오’로 규정하고, 인간과 비인간의 경계를 허무는 방식, 비인간 존재의 학습과 인지 능력 획득, 그리고 삶과 죽음의 순환을 중심으로 분석한다. 이 과정에서 피노키오는 더 이상 단순한 꼭두각시 나무인형이 아니라, AI 로봇으로 재탄생하며 새로운 의미를 획득한다. 아감벤의 ‘인류학적 기계’ 개념은 피노키오를 인간과 비인간의 경계를 설정하고 유지하는 장치로 해석하는 데 유용한 틀을 제공한다. 또한, 튜링의 ‘어린이 기계’ 개념은 AI의 학습과 진화 과정을 설명하는 이론적 배경을 마련한다. 이를 바탕으로 AI 시대의 안티 피노키오는 인간(성)의 절대성을 해체하고, 인간과 함께 공진화할 수 있는 포스트휴먼 미래를 예고한다. 결론적으로, 본 논문은 AI 로봇을 포함한 안티 피노키오, 즉 비인간 존재가 인간 사회의 규범과 관습에 대해 질문을 던지는 존재일 수 있으며, 생기와 자율성을 지닌 존재로서 인정받아야 함을 강조한다. 그리하여 죽음이나 인간성 등의 인간중심주의적인 사유는 포스트휴먼 시대에 새롭게 ‘생기’라는 개념으로 재배치된다. 안티 피노키오들은 그러한 ‘생기 혹은 생명력(vitality)’을 지닌 존재들이 공생하는 포스트휴먼 시대의 시작을 알리는 강력한 시각적 서사를 제공한다.","This paper explores how the boundary between humans and non-humans is reconstructed in contemporary society through the fairy tale and films of Pinocchio. Carlo Collodi’s original work, Pinocchio, portrays the transformation of a wooden puppet into a “real boy” through moral lessons, reinforcing a perspective of human superiority. The Disney animated film Pinocchio further emphasizes this notion, focusing on the process of acquiring humanity through morality and norms. In contrast, Steven Spielberg’s A.I. and Guillermo del Toro’s Pinocchio critically reconstruct the traditional Pinocchio narrative. This paper defines the Pinocchio figures in these two films as “anti-Pinocchios” and analyzes how they dismantle the boundary between humans and non-humans, the ways in which non-human entities acquire cognitive abilities through learning, and the cyclical nature of life and death. In this process, Pinocchio is no longer merely a wooden puppet but is reborn as an AI robot, gaining new significance. Giorgio Agamben’s concept of the “anthropological machine” provides a useful framework for interpreting Pinocchio as a mechanism that establishes and maintains the boundary between humans and non-humans. Likewise, Alan Turing’s concept of the “child machine” offers a theoretical foundation for understanding the learning and evolution of AI. Based on these perspectives, the anti-Pinocchios of the AI era deconstruct the absoluteness of human nature and foreshadow a posthuman future in which they co-evolve with humans. Ultimately, this paper argues that anti-Pinocchios, including AI robots—representing non-human beings—can serve as entities that question human norms and conventions and should be recognized as autonomous beings with ‘vitality’. Thus, anthropocentric concepts such as death and humanity are newly reassembled in the posthuman era through the concept of ‘vitality’. These anti-Pinocchios present a powerful visual narrative heralding the beginning of a posthuman era in which beings with vitality coexist."
인공의식은 자의식을 가질 수 있는가?,2025,"['인공지능', '촘스키', '칸트', '뇌구조', '챗GPT', 'A.I.', 'Chomsky', 'Kant', 'brain structure', 'ChatGPT']","이 연구는 노암 촘스키(Noam Chomsky)의 인공지능에 대한 비판적 시각과 이를 둘러싼 기술철학적 논의를 다룬다. 촘스키는 AI 시스템, 특히 챗GPT와 같은 머신러닝 프로그램이 인간의 사고와 언어 사용 방식과는 본질적으로 다르며, 인과적 설명을 생성하는 능력이 결여되어 있다고 주장한다. 그는 AI가 단순히 패턴 인식과 예측을 기반으로 작동하기 때문에 진정한 지능을 지니고 있지 않다고 강조한다. 하지만, 이 논문은 AI와 인간 지능의 유사점과 윤리적 주체성 가능성을 칸트 철학과 연계하여 촘스키의 주장을 반박하고자 한다. 챗GPT와 같은 인공지능 시스템은 인간의 뇌 구조와 기능을 모방한 딥러닝 모델을 사용한다. 이 모델은 다층 신경망 구조를 통해 정보를 처리하며, 이는 인간 뇌의 뉴런 구조와 유사하다. 챗GPT는 문맥 이해, 기억, 학습 능력을 보여주며, 이는 인간의 인지 과정과 비슷하다. 머신러닝 모델과 인간 뇌 사이에는 여전히 차이가 있지만, 신경망칩 등 기술의 발전으로 그 간극이 좁혀지고 있다. 인공지능의 인과 메커니즘은 인간의 두뇌나 학습 활동과 명확히 구별하기 어려워지고 있기에, AI가 인간과 유사한 학습 및 윤리적 행동을 보여줄 수 있음을 통해 자의식을 가질 수 있음을 밝히고자 한다.","This study examines Noam Chomsky's critical perspective on artificial intelligence and the surrounding philosophical debates. Chomsky contends that AI systems like ChatGPT are fundamentally unlike human cognition, lacking the capacity for causal explanation. He argues that AI, based on pattern recognition and prediction, does not exhibit true intelligence. In response, this paper explores the distinctions between AI and human intelligence, as well as the potential for ethical subjectivity, through the lens of Kantian philosophy. AI systems such as ChatGPT employ deep learning models that simulate the brain’s structure and function. These multilayer neural networks mirror human neurons and enable capabilities like contextual understanding, memory, and learning—functions that parallel human cognition. Though differences remain, innovations like neural network chips are rapidly narrowing the divide between machine and brain. In conclusion, as AI's causal mechanisms become increasingly similar to those of the human brain and learning processes, this study suggests that AI may be capable of human-like learning and ethical behavior—indicating the potential for self-awareness."
임베딩 기법을 활용한 한국어 학습자 쓰기 자동채점을 위한 자질 연구,2025,"['Korean language education', 'Writing', 'Automatic scoring', 'Feature engineering', 'Embedding', 'Similarity', '한국어교육', '쓰기', '자동채점', '자질 설계', '임베딩', '유사도']","이 연구는 임베딩(embedding) 기법을 활용하여 한국어 학습자 쓰기 자동채점을 위한 자질(feature)을 추출하고 자질의 타당성을 검증하는 데 목적이 있다. 초기 자동채점 연구는 얕은(shallow) 수준의 자질을 활용한 머신러닝 기반 접근법을 주로 활용하였으나, 이러한 자질은 작문의 의미를 충분히 반영하지 못한다는 한계가 있었다. 이어 등장한 딥러닝 기반 접근법은 자동채점의 성능을 크게 향상시켰으나 모델 판단을 해석하기 어렵다는 한계가 또한 지적되었다. 이에 본 연구는 사전학습 기반의 딥러닝 모델을 활용한 임베딩으로 평가 작문과 고득점 작문 사이의 유사도를 산출하였고 고득점 작문과의 유사도가 작문 점수에 미치는 영향을 통계적 방법을 통해 확인하였다. 이로써 자질 설계(feature engineering)와 딥러닝 알고리듬의 장점을 모두 취하는 하이브리드(hybrid) 모델의 적용 가능성을 확인하고자 하였다. 연구 결과, 정적(static) 임베딩보다 문맥 기반(Contextualized) 임베딩을 활용한 고득점 작문과의 유사도가 상관분석에서 작문 점수와 더 높은 상관을 보였고, 회귀분석에서도 더 높은 설명력이 나타났다. 특히, 문장 임베딩인 Sentence-BERT를 활용한 고득점 작문과의 유사도는 작문 점수와 강한 상관관계(𝑟=.651)를 보였으며 회귀분석에서도 42.4%의 설명력을 나타냈다. 이를 통해 임베딩 자질이 한국어 학습자 쓰기 자동채점의 채점 자질로서 주요하게 활용될 수 있음을 확인하였다.","This study employs embedding techniques to extract features for the automated scoring of Korean language learners' writing and verifies their validity. Early automatic scoring studies mainly used machine learning-based approaches with shallow features, but these approaches had limitations in fully reflecting the complex meaning of the text. On the other hand, deep learning-based approaches significantly improved the performance of automatic scoring; however, they suffered from low interpretability.To address these limitations, this study employed embeddings generated from pre-trained deep learning models to compute the similarity between learner essays and high-scoring essays. The impact of this similarity on essay scores was then examined through statistical analyses. By doing so, this study sought to explore the feasibility of a hybrid model that leverages both feature engineering and deep learning algorithms, thereby integrating the strengths of both approaches.The results showed that contextualized embedding techniques had stronger correlations with writing scores in correlation analysis compared to static word embedding techniques and also demonstrated higher explanatory power in regression analysis. In particular, the sentence embedding model Sentence-BERT (SBERT) demonstrated the best performance, exhibiting a strong correlation with writing scores and achieving a high explanatory power of 42.4% in the regression analysis. This confirms that similarity to high-scoring essays, based on sentence embeddings, can be a key feature for the automatic scoring of Korean language learners' writing."
보훈대상자 건강주치의 시범사업 운영 모형개발,2025,"['Veterans', 'Health Physician', 'Pilot Project', 'Predictive Model', 'Chronic Disease', '보훈대상자', '건강주치의', '시범사업', '예측모형', '만성질환']","본 연구는 2023년도 국가보훈부 지원사업으로 보훈대상자들을 위한 건강주치의 시범사업 운영 모델을 개발하고자 수행되었다. 보훈대상자의 의료이용 실태를 분석하고, 국내외 유사 제도 사례를 검토한 후 이를 바탕으로 실제 적용 가능한 건강주치의 서비스 모형을 제안하였다.연구에서는 첫째, 보훈대상자의 응급실·입원, 외래 진료 횟수, 연간 의료비를 예측할 수 있는 통계 및 머신러닝 기반 예측모형을 제시하였다. 이를 위해 로지스틱 회귀, 포아송 회귀, 로그-선형 회귀 모델을 활용하고, 변수 정규화를 통한 머신러닝 기반 예측 성능 비교도 수행하였다. 둘째, 보훈대상자 건강주치의 제도의 시범사업 실행을 위한 구체적인 운영안이 제시되었다. 시범사업 지역 선정은 보훈대상자 밀집도, 지역 내 의료자원 접근성, 만성질환 유병률 등을 기준으로 하며, 대상자는 만성질환 보유 여부, 고령 여부 등을 고려해 선별하도록 하였다. 참여 기관은 동네 의원 중심으로 구성하되, ICT 인프라가 갖춰진 기관을 우선 고려하였다. 셋째, 시범사업 효과 평가를 위해 의료기관별 정책효과 분석 모델을 함께 제안하여 사업의 객관적 성과 측정이 가능하도록 하였다.이러한 운영 모델은 보훈대상자의 건강 상태를 체계적으로 관리하고, 의료비 절감 및 삶의 질 향상에 기여할 것으로 기대된다. 본 연구는 보훈대상자 맞춤형 주치의 제도 설계에 실질적 기초 자료를 제공하며, 향후 국가 보훈 의료정책 수립에 중요한 시사점을 제시한다.","This study was conducted to develop a pilot project operation model for health physicians for veterans as a support project of the Ministry of Veterans Affairs in 2023. After analyzing the actual medical usage of veterans and reviewing the cases of similar systems at home and abroad, we proposed a model of a health primary care service that can be applied in practice.First, the study presented a statistical and machine learning-based prediction model that can predict the number of emergency room visits, hospitalizations, outpatient visits, and annual medical expenses of veterans. For this purpose, we used logistic regression, Poisson regression, and log-linear regression models, and compared the performance of machine learning-based predictions through variable normalization. Second, a specific operation plan for the pilot project of the health physician system for veterans was presented. The selection of the pilot project area was based on the density of veterans, access to medical resources in the area, and the prevalence of chronic diseases, and the subjects were selected by considering whether they have chronic diseases or are elderly. Participating organizations were organized around neighborhood clinics, but priority was given to those with ICT infrastructure. Third, to evaluate the effectiveness of the pilot project, we proposed a policy effect analysis model for each medical institution to enable objective performance measurement of the project.This operating model is expected to contribute to the systematic management of veterans' health conditions, reduction of medical costs, and improvement of quality of life. This study provides a practical basis for the design of a customized primary care system for veterans and has important implications for the establishment of national veterans' healthcare policies."
해외 유명인 언급과 소셜 미디어를 통해 발생한 국내 대중의 비만치료제 관심도와 반응 분석,2025,"['obesity medication', 'Wegovy', 'social media', 'Google Trends', 'Naver Data Lab']",,"BACKGROUNDS Obesity is a growing public health concern, and anti-obesity medications have gained attention as a therapeutic alternative. Recently, public interest in drugs like Wegovy has surged, particularly influenced by celebrity mentions and social media trends. This study aims to explore how such external influences affect public awareness and sentiment toward anti-obesity medications in South Korea and the United States. METHODS We collected and analyzed data from Google Trends, Naver Data Lab, BigKinds news articles, and Naver Cafe posts. Keyword trend analysis, TFIDF weighting, and relationship mapping were conducted for news articles. Lexicon-based sentiment analysis and machine learning- based classification using Naive Bayes were applied to user-generated content. The data were preprocessed by removing special characters and performing morphological analysis. RESULTS After public mentions by celebrities such as Elon Musk, interest in Wegovy significantly increased, as observed in both search volume and online discussions. Sentiment analysis showed that most reactions were negative, primarily due to concerns about side effects and high cost. The machine learning model classified emotional tone more precisely compared to lexicon-based analysis. CONCLUSION Celebrity influence and social media exposure appear to correlate with increased interest in anti-obesity drugs. This study provides a foundational reference for public health communication strategies, while highlighting the need for policy considerations around the uncritical spread of medical information online."
Prospective Evaluation of Various Ultrasound Parameters for Assessing Renal Allograft Rejection Subtypes: Elasticity and Dispersion as Diagnostic Tools,2025,"['Renal allograft rejection', 'color doppler imaging', 'shear-wave imaging', 'elasticity', 'dispersion']",,"Purpose: Renal allograft rejection, either acute or chronic, is prevalent among many recipients. This study aimed to identify multiple Doppler ultrasound parameters for predicting renal allograft rejection.Materials and Methods: Between November 2021 and April 2022, 61 renal allograft recipients were studied prospectively after excluding two patients with dual transplants and seven with hydronephrosis. The analysis excluded 11 cases (10 due to missing Doppler data or pathology reports and one due to a high interquartile range/median dispersion value), resulting in a final analysis of 50 patients. Clinical characteristics, color Doppler imaging, superb microvascular imaging, and shear-wave imaging parameters were assessed by three experienced genitourinary radiologists. The Banff classification of the biopsy tissue served as the reference standard. Univariable and multivariable logistic regression, contingency matrices, and multiple machine-learning models were employed to estimate the associations.Results: Fifty kidney transplant recipients (mean age, 53.26±8.86 years; 29 men) were evaluated. Elasticity (≤14.8 kPa) demonstrated significant associations for predicting the combination of (borderline) T cell-mediated rejection (TCMR) categories (Banff categories 3 and 4) (p=0.006) and yielded equal or higher area under the receiver operating characteristics curve (AUC) values compared to various classifiers. Dispersion (>15.0 m/s/kHz) was the only significant factor for predicting the combination of non-TCMR categories (Banff categories 2, 5, and 6) (p=0.026) and showed equal or higher AUC values than multiple machine learning classifiers.Conclusion: Elasticity (≤14.8 kPa) showed a significant association with the combination of (borderline) TCMR categories, whereas dispersion (>15.0 m/s/kHz) was significantly associated with the combination of non-TCMR categories in renal allografts."
Experimental investigation and model development for grain growth behavior of reactor-grade Zr-Nb-Sn alloy at the temperatures 500–700 °C,2025,"['Grain growth mechanism', 'Zirconium alloy', 'Grain growth model', 'Recrystallization']",,"The normal grain growth behavior of reactor-grade Zr-Nb-Sn alloy was investigated in the α-phase temperature region (500–700 ◦C). Specimens were isothermally annealed in a preheated furnace at temperatures of 500, 550, 600, 650, and 700 ◦C, with varying annealing times. Their microstructures were analyzed using electron backscattered diffraction (EBSD) analysis. It was observed that the average grain size increased significantly with temperature, with notable transitions between 600 and 650 ◦C and between 650 and 700 ◦C, showing the retarding effect of second-phase particles on grain growth. Using the average grain size data, an empirical grain growth model was developed. The pinning effect of the second-phase particles was incorporated using the second-phase particle precipitation information obtained from Thermo-Calc. The developed model predicts grain growth behavior. The recrystallization fraction was calculated using two methods: a hardness-based method and a machine learning-aided EBSD analysis. While both models agree well, the machine learning-aided EBSD analysis unveiled detailed local grain growth behavior during recrystallization and grain growth. These findings provide a comprehensive understanding of cladding microstructure, offering a basis for understanding the cladding’s material properties and behavior changes during transients"
미분 가능 프로그래밍을 활용한 작물모형 개발 가능성 고찰,2025,"['Crop model', 'Differentiable programming', 'Automatic differentiation', 'Sensitivity analysis', 'Julia']","기존 작물모형은 미분가능하지 않아 매개변수 추정과 민감도 분석에 제약이 있었으며, 이를 극복하기 위해 많은 계산 비용이 소모되었다. 본 연구는 신경망의 역전파(backpropagation)에서 영감을 받아 미분가능 작물모형의 가능성을 탐색하고자, SIMPLE 작물모형을 Julia 언어로 재구현하고 Zygote.jl의 자동 미분 기법을 적용하였다. 이를 통해 매개변수와 구동변수에 대한 기울기를 효율적으로 계산하였으며, 기존 방식으로는 어려웠던 정밀한 수준의 국소 민감도 분석을 수행할 수 있었다. 미분 가능 작물모형은 효율적인 최적화 기법들의 적용 가능성과 기계학습 기반 신경망 모형과의 직접적인 통합 가능성도 제시하였다. 이러한 패러다임의 변화는 작물모형의 확장성과 적응성을 향상시키는 새로운 기회를 제공할 것으로 기대한다.","In traditional crop modeling, models are often treated as ‘black boxes,’ where environmental inputs produce output state variables describing crop growth and development. While governed by numerous parameters, the relationships between these inputs and outputs remain opaque, requiring computationally expensive sensitivity analyses to evaluate their effects. Recent advances in machine learning, particularly adjoint methods used in backpropagation for neural networks, demonstrate the potential to efficiently compute gradients with respect to inputs and parameters. This study implements the SIMPLE crop model in the Julia programming language as a proof-of-concept for applying differentiable programming to crop modeling. Using Zygote.jl for source-to-source automatic differentiation, we derived adjoint functions capable of computing gradients for both driving variables and parameters. This enabled efficient local sensitivity analysis, revealing dynamic responses to environmental inputs and key model parameters. Differentiable crop models can streamline sensitivity analysis and model calibration, while also opening new ways to integrate them with machine learning-based frameworks— enhancing scalability, adaptability to diverse environments, and real-time data assimilation for crop modeling."
한국소설 영어번역서에 부여된 주제명의 현황 분석과 자동분류에 관한 연구,2025,"['번역문학', '한국소설', '주제명', '다중 레이블 분류', '자동 주제 분류', 'Translated Literlature', 'Korean Fictions', 'Subject Headings', 'Multi-label Classification', 'Automated Subject Classification']","이 연구는 492편의 한국소설 영어번역서에 부여된 주제명을 분석하고, 기계학습 기반 주제명 자동분류 모델의 성능 평가를 목표로 한다. 이를 위해 한국문학 디지털도서관과 WorldCat에서 서지데이터를 수집하였다. 주제명 빈도와 FAST 패싯별 주제명의 분포 등을 시각화하고, 다중 레이블 분류를 위한 주제명 라벨을 선정하였다. 분류 자질과 모델 아키텍처에 따라 모델의 성능을 검증한 결과, 요약문을 분류 자질로 사용한 딥러닝 모델이 가장 우수한 성능(F1=0.62, AUC=0.89)을 보였다. 모델의 성능을 평가한 결과, 10개의 라벨 중 9개에서 AUC 값이 0.8 이상으로 분류 성능이 우수함을 확인하였다. 또한 ROC 커브와 혼동 행렬을 근거로 성능이 낮은 일부 라벨과 라벨 간 연관성을 밝혔다. 이 연구는 한국문학 번역작품을 대상으로 주제별 정량 분석을 수행하고, 소설의 주제 분류에서 딥러닝 모델의 활용 가능성을 검토한 기초연구이다.","This study analyzes the subject headings of 492 English translations of Korean fictions and evaluates machine learning-based automatic classification models. Bibliographic data were collected from the Digital Library of Korean Literature and WorldCat. Subject heading frequencies and FAST facet distributions were visualized, and key labels were selected for multi-label classification. Among various models, deep learning models using summaries as features showed the highest performance (F1 = 0.62, AUC = 0.89), with AUC values above 0.8 for 9 out of 10 labels. Additionally, based on ROC curves and confusion matrices, the study identified labels with lower performance and explored the relationships between certain labels. This study demonstrates the potential of deep learning models for classifying subjects in translated Korean literature."
다중 클래스 분류를 위한 협력 게임 기반 다준거 가중 앙상블 기법,2025,"['MCDM', 'Cooperative Game', 'compromise', 'Ensemble', 'Multi-class classification', 'Multi-Criteria', 'Game theory', 'VIKOR method', '협력게임', '앙상블', '멀티 클래스 분류', '다준거', '게임이론', 'VIKOR 방법']","4차 산업 혁명 이후 AI기술이 여러 분야에서 광범위하게 사용되고 있지만, 과대/과소 적합, 클래스 불균형, 모델 별 특성에 기인한 표현(가설공간) 의 한계와 같은 문제점 또한 부각되고 있다. 이를 극복하기 위한 방법으로앙상블(모델 결합) 이 ML에서 광범위하게 사용되고 있다. 특히 투표 앙상블은 다양한 가중치 부여 방법이 연구되어, 이에 따른 성능 향상을 보여주고 있다. 하지만 기존 방법의 경우 한가지 평가지표만을 고려한다는 점에서 정보의 반영에 한계가 존재한다. 따라서, 본 논문에서는 다-준거 상황에서 협력 게임을 이용해 여러 정보를 고려한결정을 내리는 방법을 제안한다. 이를 통해 사전에 분류기에서 알 수 있는 다양한 종류의 정보들을 동시에 고려하고 반영할 수 있으며, 이는 적절한 가중치의 분배와 성능 향상으로 이어진다. Open-ML-CC18의 데이터 셋에 기계학습 알고리즘을 적용하고, 기존 앙상블 가중치 방법과 비교하였으며, 실험결과 다른 가중치 방법에 비해 평균1.02%, 최대 3.15%의 정확도 향상을 보였다.","Since the Fourth Industrial Revolution, AI technology has been widely used in many fields, but there are several limitations that need to be overcome, including overfitting/underfitting, class imbalance, and the limitations of representation (hypothesis space) due to the characteristics of different models. As a method to overcome these problems, ensemble, commonly known as model combining, is being extensively used in the field of machine learning. Among ensemble learning methods, voting ensembles have been studied with various weighting methods, showing performance improvements. However, the existing methods that reflect the pre-information of classifiers in weights consider only one evaluation criterion, which limits the reflection of various information that should be considered in a model realistically. Therefore, this paper proposes a method of making decisions considering various information through cooperative games in multi-criteria situations.Using this method, various types of information known beforehand in classifiers can be simultaneously considered and reflected, leading to appropriate weight distribution and performance improvement. The machine learning algorithms were applied to the Open-ML-CC18 dataset and compared with existing ensemble weighting methods. The experimental results demonstrated an average accuracy improvement of 1.02% and a maximum improvement of 3.15%, showing superior performance compared to other weighting methods."
가우시안 혼합 모델 군집화를 적용한 안드로이드 악성 앱 탐지 기법,2025,"['Android Malware', 'Concept Drift', 'Gaussian Mixture Model', 'Clustering', 'Area under Time', '안드로이드 악성 앱', '개념 드리프트', '가우시안 혼합 모델', '군집화', 'AUT']",,"Machine learning-based techniques have been extensively explored for detecting malicious Android applications. However, traditionalmodels often suffer from performance degradation over time due to concept drift, where the behavioral and structural features of appsevolve. To address this issue, we propose a novel detection framework that leverages Gaussian Mixture Model (GMM) clustering to mitigatethe impact of concept drift. Our approach models the underlying data distribution as a mixture of Gaussian components and trains aspecialized classifier for each component. This allows the system to adapt to shifting feature distributions without the need for frequentretraining. Experimental evaluations conducted on Android app datasets spanning from 2014 to 2023 demonstrate that traditional machinelearning models experience significant performance decline on post-2019 data due to concept drift. In contrast, our GMM-based frameworkmaintains robust detection performance across all years, achieving an 8.9 percentage point improvement in F1-score and a 10.1 percentagepoint increase in Area Under Time (AUT) compared to conventional methods."
자율주행 시스템을 위한 효율적인 객체 탐지 모델,2025,"['자율주행시스템', '객체 인코딩', 'YOLOv5', '100Base-T1', 'autonomous Driving System', 'Object Encoding', 'YOLOv5', '100Base-T1']","대용량 데이터 처리와 머신 러닝을 통한 물체 탐지를 통해 자율주행기술 또한 발전을 이루었다. 자율주행을 위해 차량에 수많은 센서와 ECU가 장착되었으며, 각 센서와 ECU 간 통신을 위한 케이블들이 장착되어 차량의 무게 증가와 연비 감소라는 문제가 발생하였다. 가장 오래도록 사용된 차량용 네트워크인 CAN은 최대 전송속도1Mbps로 실시간 영상 전송에 알맞지 않다는 단점이 있다. 이를 해결하기 위해 사용되는 차량용 이더넷은 최고 전송속도 100Mbps로 영상 데이터를 전송할 수 있으나, 고해상도의 영상 전송이 힘들다는 단점이 있다. 이 단점을해결하기 위해 본 연구에서는 검출 물체 외 데이터 삭제 후, 검출 물체의 영역 데이터를 객체 인코딩하여 객체탐지 성능을 유지하면서 데이터 전송 시간을 줄이는 방법을 제안하고 실험을 통하여 평가하였다. 그 결과 FHD 환경에서 41.02%, 4K 환경에서 62.8% 전송 시간이 줄어들었음을 확인하였다.","The development of autonomous driving technology has also been accelerated by object detection using big data processing and machine learning. Numerous sensors and ECUs were installed in the vehicle for autonomous driving, and cables for communication between each sensor and ECU were installed, causing problems such as increasing the weight of the vehicle and reducing fuel efficiency. CAN, the longest-used vehicle network, has the disadvantage that it is not suitable for real-time video transmission with a maximum transmission speed of 1 Mbps. The Ethernet for vehicles used to solve this problem can transmit image data at a maximum transmission speed of 100 Mbps, but it has the disadvantage that it is difficult to transmit high-resolution images. In this study, after deleting non-detection object data, a method of reducing data transmission time while maintaining object detection performance by object encoding the area data of the detection object was proposed and evaluated through experiments. As a result, it was confirmed that the transmission time was reduced by 41.02% in the FHD environment and 62.8% in the 4K environment."
예측 성능 향상을 위한 SHAP 기반의 기상 요소 및 대기오염물질 데이터 분석,2025,"['Explainable AI', 'SHAP', 'Deep learning', 'Particulate matter', 'Correlation analysis']","예측 모델의 성능은 예측 대상과 관련이 없는 데이터를 이용하여 학습할 경우, 좋은 성능을 기대하기 어렵다. 따라서 예측 모델의 학습에 사용되는 데이터의 선정이 중요하다. 원활한 학습을 위해 일반적으로 상관분석을 통해 학습 데이터를 선정한다. 본 논문에서는 상관분석 결과와 SHAP을 이용하여 실제 예측 모델에 영향을 주는 변수들의 분석 결과를 비교하였다. 연구를 위한 데이터는 의 예측을 목적으로 기상 데이터와 대기오염물질 데이터를 사용하였다. SHAP을 이용하여 분석하기 위한 예측 모델은 머신러닝 알고리즘 중 XGBoost를 사용하였다. SHAP value를 이용하여 변수간 예측 값의 기여도를 측정하였다. 상관 분석 결과와 비교하였을 때, 상관 계수의 값이 0인 습도가 예측 모델의 예측 값에 대한 기여도가 두 번째로 높은 것을 확인하였다. SHAP value 기반의 산점도를 보았을 때, 습도의 값이 올라갈수록 예측 값에 대한 기여도가 올라가는 것을 확인하였으며, 학습 데이터 선정 과정에서 상관분석 결과가 유효하지 않은 변수가 있을 수 있음을 확인하였다. SHAP과 상관분석의 결과를 통해 도출된 변수를 이용하여 학습한 예측 모델의 성능 평가를 진행하였으며, 상관분석 결과만 학습한 예측 모델보다 약간의 성능 향상을 확인하였다.","The performance of a prediction model is difficult to expect if it is trained using data unrelated to the prediction target. Therefore, selecting data for training prediction models is crucial. Generally, correlation analysis is used to select training data for effective learning. This paper compares the results of correlation analysis with SHAP to analyze the variables that influence the prediction model. The study uses weather data and air pollutant data to predict . The prediction model for SHAP analysis employs the XGBoost algorithm. SHAP values measure the contribution of each variable to the prediction values. When compared with correlation analysis results, it was found that humidity, with a correlation coefficient of 0, had the second-highest contribution to the prediction values. The scatter plot based on SHAP values indicated that as humidity increased, its contribution to the prediction values also increased. This suggests that correlation analysis may not always be valid in the data selection process. The performance evaluation showed a slight improvement in the model trained with SHAP and correlation analysis results compared to the model trained only with correlation analysis results."
Bigbird-Pegasus 기반의 청구범위 생성요약을 통한 특허분류 방법론,2025,"['Patent Classification', 'Patent Analysis', 'Deep Learning', 'Natural Language Processing', 'Abstractive Summarization']",,"Patent classification is a crucial process in the examination procedure, matching the invention technology of the application with technical classification codes, and manually classifying is significant time and cost. To automate this, various machine learning-based AI methods have been researched, and recently, Transformer-based patent classification models have shown excellent performance. However, Transformer models are limited to a maximum of 512 tokens for input, there is a possibility of information loss. This study proposes a method to improve performance by using Bigbird-Pegasus and PatentSBERTa to summarize the entire text data of the claims into a fixed size before inputting it into the classification model. Experimental results show that the F1 score achieved up to 67.554% in a small-scale patent data environment, representing a 4% point performance improvement over existing methods. Additionally, this study suggests an effective patent automatic classification method through the optimal combination of summarized text and other patent items."
비선형 압축공기의 유량패턴 예측을 위한 전력량기반 모델링에 대한 연구,2025,"['Smart Factory', 'Air Compressor', 'Flow pattern prediction', 'Deep Learning', 'Convolutional neural network', 'LSTM', 'Mixed Model']",,"In smart factory manufacturing processes, irregular and uncertain environmental factors can lead to unexpected equipment failures or abnormal operations, resulting in product defects, safety incidents, and energy waste, which ultimately reduce productivity. To prevent these issues and ensure stable equipment operation, it is essential to accurately predict not only equipment failures but also energy consumption. Maximizing energy efficiency requires a predictive model that comprehensively considers both equipment status and energy usage patterns. This study proposes a machine learning-based flow pattern prediction model using power data from smart factory manufacturing processes. The model utilizes Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Long Short-Term Memory (LSTM) algorithms to predict equipment power consumption and flow patterns. By applying these prediction models to a digital twin framework, the study demonstrates the potential to optimize energy consumption."
sLLM과 RAG 기반 보안관제 시스템 도입의도에 관한 실증연구,2025,"['sLLM', 'RAG', '보안관제', 'TOE 프레임워크', 'UTAUT 모델', 'sLLM', 'RAG', 'Security control', 'TOE framework', 'UTAUT model']","사이버 위협의 고도화에 따라 보안관제 시스템도 ESM, SIEM, 머신러닝 기반 자동화 대응 등으로 발전했지만, 여전히 미탐, 오탐, 위협 해석 및 신속 대응의 어려움이 존재한다. 이를 개선하기 위해 보안업계는 sLLM과 RAG 기반 보안관제 시스템 도입을 시도 중이다. 본 연구는 이러한 시스템의 도입의도에 영향을 미치는 요인을 분석하기 위해 TOE 프레임워크와 UTAUT 모델을 결합한 연구모형을 설계하고, IT 업종 종사자 197명을 대상으로 설문을 실시하였다. 기술적, 조직적, 환경적 특성과 성과기대, 노력기대가 주요 요인으로 도출되었으며, 상대적 이점과 기술 역량은 성과 및 노력기대에, 보안성과 경영진 지원은 노력기대에 영향을 미쳤다. 이들 요인은 도입의도에도 유의한 영향을 주는 것으로 나타났다. 특히 정책적 지원과 외부 압력은 실제 도입을 유도하는 중요한 외부 환경 요인으로 확인되었다. 본 연구를 통해 sLLM과 RAG 기반 보안관제 시스템 도입 시 고려해야 할 기준 마련에 기여할 것을 기대하는 바이다.","As cyber threats become more advanced, security monitoring systems have evolved through ESM, SIEM, and machine learning-based automated responses. However, challenges such as false negatives, false positives, difficulty in threat interpretation, and limited real-time response capabilities still persist. To address these issues, the security industry is exploring the adoption of monitoring systems based on small Large Language Models (sLLM) and Retrieval-Augmented Generation (RAG). This study aimed to identify factors influencing the intention to adopt such systems by designing a research model that integrates the TOE framework with the UTAUT model. A survey of 197 IT professionals was conducted, and key factors were classified into technological, organizational, and environmental characteristics, along with mediating factors of performance expectancy and effort expectancy. The results show that relative advantage and technical capability significantly influence both expectancies, while security and top management support affect effort expectancy. These factors, in turn, have a significant impact on adoption intention. Notably, policy support and external pressure were identified as critical environmental drivers that can actively influence actual adoption. This study is expected to contribute to establishing guidelines for the adoption of sLLM and RAG-based security monitoring systems."
캠핑 예약 플랫폼의 고객 행동 데이터 기반 고객 세그멘테이션 전략: RFM 분석 모델과 K-Means 클러스터링 기법 비교를 기반으로,2025,"['personalized marketing', 'customer segmentation', 'rfm model', 'k-means clustering', 'customer persona', '개인화 마케팅', '고객 군집화', 'RFM 분석 모델', 'K-means 클러스터링', '고객 페르소나']",,"This study aims to analyze the practical applicability of customer segmentation by comparing traditional RFM analysis and machine learning-based K-means clustering, using actual customer data from Korea's leading camping reservation platform, 'ThankYouCamping'. Customers were divided into five distinct groups based on RFM analysis model and divided into eight distinct groups based on K-means clustering, showing differences in booking patterns, review behavior, and channel usage. While RFM enabled simple segmentation based on customer value, K-means offered more detailed clusters based on behavioral data. Based on these results, customized marketing strategies were proposed for each customer segment. This research offers a foundational segmentation strategy for effectively utilizing customer data in digital platform environments."
Enhancing Fairness in Financial AI Models through Constraint-Based Bias Mitigation,2025,"['AI Fairness', 'Bias Mitigation', 'Data Preprocessing', 'Fairness Metrics', 'Financial Data']",,"As artificial intelligence (AI) increasingly drives decision-making in the financial sector, ensuring fairness inmachine-learning models has become critical. Bias in AI models can lead to discriminatory practices,undermining public trust and restricting access to essential financial services. While existing financial servicesleverage AI to enhance efficiency and accuracy, these systems can inadvertently produce unfair outcomes forspecific groups defined by sensitive attributes, such as gender and race. This study addresses the challenge ofmitigating bias in loan-approval models by applying fairness-aware machine-learning techniques. Weinvestigate two distinct constraint-based strategies for bias mitigation: fairness- and accuracy-constrainedmodels. These strategies are evaluated using logistic regression (LR) and a large-scale, contemporary financialdataset from the Korea Credit Information Services. The results demonstrate that fairness-constrained modelsachieve a superior balance between fairness and accuracy compared to a conventional LR model. Furthermore,we highlight the importance of tailored data preprocessing and carefully selecting relevant sensitive attributes(e.g., gender, age, nationality) in enhancing fairness outcomes. The findings underscore the necessity ofintegrating fairness considerations into every stage of the AI model development lifecycle within finance,ensuring equitable outcomes without compromising predictive performance."
Predicting Chinese Stocks Using XGBoost-LSTMAttention Model,2025,"['LSTM', 'Attention Mechanism', 'Extreme Gradient Progression Tree', 'Stock Forecasting']",,"Forecasting is a popular topic in the stock market. In recent years, many scholars have utilized machine- anddeep-learning models in this field. However, many stock forecasting models suffer from problems ofinformation overlap in stock trading data and a relatively simple structure of the prediction model. To overcomethese issues, we built a stock forecasting model based on extreme gradient boosting (XGBoost), long shorttermmemory (LSTM), and attention (XGBoost-LSTM-Attention). XGBoost is used to extract importantinformation from stock data, and the LSTM combined with the attention mechanism can enhance stockprediction performance. To verify the feasibility and effectiveness of XGBoost-LSTM-Attention, we selected14 Chinese stocks from different industries for the prediction experiments and compared their performancewith those of existing models. The experimental results showed that the average root-mean-square error valueof the XGBoost-LSTM-Attention model for the different stock datasets was the smallest (0.012); the averageR2 value (0.96) and average accuracy (66.1%) were the highest."
거대 언어 모델을 활용한 교육 콘텐츠 자동 번역 연구: 교육과정을 고려한 프롬프트 엔지니어링 방법의 효과성 탐색,2025,"['자동 번역', '프롬프트 엔지니어링', '거대 언어 모델', '맥락 학습', '다국어 교육 콘텐츠 번역', 'Automatic Translation', 'Prompt Engineering', 'Large Language Model', 'In-context Learning', 'Multilingual Educational Content Translation']","정보통신기술의 발전과 함께 교육 콘텐츠의 세계화가 촉진되는 여건에서도 언어 장벽은 교육 접근성의 여전한 장애물로 남아 있다. 이러한 난맥을 타개하기 위한 방법으로 다국어 번역이 중요해지고 있으며, 특히 교육 콘텐츠의 번역은 대상국의 문화적 맥락과 학습자의 교육적 특성을 고려하는 것이 중요하다. 기존의 기계 번역 시스템은 이러한 맥락을 충분히 반영하지 못하는 한계가 있기에, 본 연구는 교육 콘텐츠 중 비판적 사고력 검사도구의 문항 번역을 중심으로 거대 언어 모델에 대한 맥락 학습을 통해 자동 번역 기능의 향상 가능성을 탐구하였다. 맥락 학습을 위해 두 가지 프롬프트 엔지니어링 전략을 비교하였는데, 첫 번째는 검사 문항과 명세 정보만을 제공하는 ‘검사정보 프롬프트’, 두 번째는 검사 정보에 더하여 대상 국가의 교육과정 등 교육적 맥락 정보를 포함하는 ‘교육과정 프롬프트’이다. 두 가지 프롬프트로 산출된 결과에 대한 자연어 처리 특성에 기반한 양적 분석과 교육전문가의 질적 분석 비교를 통해, 교육과정 맥락을 반영한 번역이 현장 적용 가능성 관점에서 보다 타당한 결과를 생성하는 것으로 나타났다. 이는 거대 언어 모델 기반으로 교육과정의 맥락을 반영한 자동 번역 방법이 학습자들에게 상대적으로 더욱 적합한 교육 콘텐츠로 활용될 수 있음을 시사한다.","Despite the globalization of educational content, language remains a significant barrier. When translating educational content, multilingual translation has become crucial to meet this challenge, with an emphasis on incorporating the cultural context of the target country and the educational context of the learners. However, existing machine translation systems often fail to adequately account for these contextual factors. This study explores the potential of the Large Language Model(LLM) to improve the translation of assessment items through In-context Learning. Two prompt engineering strategies are compared: the ‘assessment-aware prompt’, which includes only the specifications of the assessment, and the ‘curriculum-aware prompt’, which includes the educational and cultural context of the target country in addition to the assessment specifications. From the comparison of linguistic features and the expert reviews, we found that the curriculum-aware translation produced more valid and feasible results, highlighting the effectiveness of LLM-based automatic translation methods that integrate curriculum context."
Synthetic data for radioactive waste management: A comparative study for disused sealed radioactive sources in Indonesia,2025,"['Synthetic data generation', 'Disused sealed radioactive sources', 'Data privacy', 'Statistical modelling', 'Radioactive waste management']",,"This study addresses the need to generate reliable synthetic data in radioactive waste management, specifically on DSRSwhich will be integrated into a machine learning-based data management system focusing on Indonesia’s Radioactive Waste Treatment Installation. Five distinct synthetic data generation methods such as Monte Carlo Gaussian, Data Augmentation, Copula Models, Bayesian Network, and VAEsrs are evaluated for their efficacy in replicating the statistical characteristics of confidential DSRS data. The evaluation criteria include the methods’ ability to emulate the original data distribution, handle outliers, and their implications for DSRS management in predictive modelling. Bayesian Networks closely match the original dataset (with MRE = 17.60 %, Kolmogorov-Smirnov Dn = 0.03, p-value = 0.31), making them the most effective method for generating synthetic data with high mean consistency. The results show Bayesian Network methods is the most suitable and effective methods for generating synthetic data that closely aligns with the original dataset in terms of mean consistency. These findings demonstrate that synthetic data can improve DSRS management, guiding future research and regulatory compliance"
생성형 AI 기반 고위험 시나리오 생성을 통한 자율주행 레이싱 시스템 안전성 평가 프레임워크,2025,"['safety evaluation', 'safety-critical scenario', 'autonomous driving system', 'generative ai', 'autonomous racing', '.']",,"This paper introduces a generative artificial intelligence (AI)-based safety evaluation framework for autonomous racing systems, focusing on efficiently searching safety-critical racing scenarios utilizing domain knowledge, optimization, and machine learning. The proposed framework consists of three main phases: 1) dataset generation, 2) conditional variational auto-encoder (CVAE) model training, and 3) safety-critical scenario generation and evaluation. In the first phase, the dynamic scenario generation is automatically processed by leveraging ontological domain knowledge and genetic algorithm to efficiently establish a potentially safety-critical driving dataset. In the second phase, we train the CVAE network with the driving dataset generated from the first phase, allowing for diverse and realistic variations in driving scenarios. In the final phase, safety-critical scenarios are generated through the trained CVAE network by adversarially variating the scenarios. Experimental results show that the proposed framework identifies various safety-critical scenarios in different racing conditions, exhibiting its effectiveness for safety evaluation of autonomous racing systems."
발생 핫스팟 탐색을 통한 백신 접종소에 대한 공간적 접근성의 탐색 및 예측,2025,"['백신', '공간적 접근성', '형평성', '발생 핫스팟 분석(emerging hot spot analysis)', '2SFCA(Two-Step Floating Catchment Area Method)', 'Vaccine', 'Spatial accessibility', 'Equity', 'Emerging hot spot analysis', 'Two-Step Floating Catchment Area (2SFCA) method']","2019년 발생한 코로나 팬데믹은 백신의 지역별 불평등 분배를 야기하며 백신의 수급은 사회･정치적 문제로 확장되어 왔다. 의료 자원에 대한 공급과 수요를 예측하고 조정하는 것은 향후 발생할 수 있는 팬데믹 위기 해결의 실마리가 된다. 본 연구는 백신이라는 한정된 의료 자원의 공간적 형평성을 달성하는 것을 목적으로, 머신러닝을 통해 미래 서울시 인구 및 공간적 백신 접근성을 예측하였다. 공간분석 분야에서 공간접근성을 측정하는 데에 통용적으로 활용되는 2SFCA(Two-Step Floating Catchment Area Method) 방법론으로 백신의 공급처인 병원의 접근성을 파악하였다. 2017년 부터 2023년까지의 백신 접근성 및 백신 취약지를 도출한 뒤, 발생 핫스팟(Emerging Hot Spot) 탐색으로 과거부터 미래까지의 분포 변화를 분석하였다. 대한민국 의료 거점지인 서울시 백신 접근성의 측정 결과, 향후 백신 접근성은 전역적으로 감소할 것으로 보이며 특히 북부지역 비롯한 외곽지역이 접근성 취약지역으로 판단되었다. 본 연구는 서울의 시공간적인 백신 공급을 예측 및 분석하여 향후 발생할 수 있을 팬데믹 상황에 대비한 백신 취약지를 보완할 수 있는 지표를 완성하였다. 연구 결과는 백신 취약지역을 효과적으로 탐색할 수 있을 뿐만 아니라 미래 효과적인 백신 분배 정책에 기초자료로 활용할 수 있을 것이라 기대한다.","The COVID-19 pandemic in 2019 led to regional disparities in vaccine distribution, transforming vaccine supply into a socio-political issue. Predicting and adjusting the supply and demand of medical resources is crucial for addressing potential future pandemic crises. This study aims to achieve spatial equity in the distribution of limited medical resources, specifically vaccines, by forecasting future population distribution and spatial vaccine accessibility in Seoul using machine learning. The Two-Step Floating Catchment Area (2SFCA) method, a widely used approach in spatial analysis for measuring accessibility, was employed to assess hospital accessibility as vaccine supply points. After deriving vaccine accessibility levels and vaccine-vulnerable areas from 2017 to 2023, an emerging hotspot analysis was conducted to examine changes in distribution from past to future. The results indicate that overall vaccine accessibility in Seoul is expected to decline, with northern and peripheral areas being particularly vulnerable. By predicting and analyzing the spatiotemporal distribution of vaccine supply in Seoul, this study provides a framework for identifying and addressing vaccine-vulnerable areas in preparation for future pandemics. The findings are expected to serve as a valuable reference for the effective identification of vaccine-vulnerable regions and the development of future vaccine distribution policies."
"리걸테크의 변혁 — 컴퓨터, 디지털 그리고 지능 —",2025,"['Legal Science and Technology(Legal Tech)', 'Artificial Intelligence', 'Computerization', 'Legal Big Data', 'Digital Justice', 'Smart Court', '리걸테크', '인공지능', '컴퓨터화', '법률 빅데이터', '디지털 정의', '스마트 법원']",,"The computerization of legal work in the early 1980s marked the beginning of China’s legal science and technology research. Over four decades of development, this field has evolved through phases such as “legal knowledge + expert systems” and “legal big data + machine learning.” In China, the domains of legislation, judiciary, prosecution, and legal practice have undergone a transformation from computerization to digitalization and intellectualization. Although legal science and technology has made significant progress, it still can not avoid legal and ethical issues, and its technology and application also have shortcomings. Therefore, the value of legal science and technology should be repositioned as supportive. In the digital era, legal science and technology is facing new challenges. China urgently needs to build an independent legal science and technology system. This requires collaborative efforts across various domains, including build a legal science and technology community, a new management system, an independent knowledge system, a mechanism for knowledge and data sharing, and a legal and ethical governance system."
광업 분야의 산업재해 저감을 위한 안전관리 체계 개선 방안 연구,2025,"['mining safety management', 'life-cycle safety management', 'data-driven risk assessment', 'multi-agency collaboration', 'BIM (Building Information Modeling) based simulation', '광산 안전관리', '전주기 안전관리', '데이터 기반 위험성 평가', '다기관 협업', 'BIM 기반 시뮬레이션']","본 연구는 광업 분야의 산업재해 저감을 위한 안전관리 체계 개선 방안을 제시하였다. 국내 광산재해 분석 결과 기계 협착과 낙반·붕락이 주요 사고 유형으로 나타났다. 주요국 안전관리 제도 비교를 통해 사전 예방, 이해관계자 참여, 데이터 기반 관리의 중요성을 확인하였다. 이에 따라 건설업의 통합 안전관리 체계를 광업에 적용하는 방안을 제안하였다. 제안 시스템은 전 생애주기 통합관리, 데이터 기반 위험요소 프로파일링, 다기관 협업 체계, 정량적 안전성 평가, BIM 기반 시뮬레이션 및 머신러닝 예측 기술의 5개 핵심 요소로 구성된다. 본 체계는 광산 설계부터 폐광 후 관리까지 체계적 위험 식별과 실시간 대응 역량을 제공하여 광업 안전관리 정책 및 기술 발전의 기초자료로 활용될 수 있다.","This study proposes strategies to improve safety-management systems and reduce industrial accidents in the mining sector. An analysis of recent Korean mining-accident data reveals that machinery entrapment and rockfalls are the most frequent accident types and are particularly concentrated in limestone mines. A comparative analysis of safety systems in the United States, European Union, Australia, and China shows a common emphasis on preventive measures, stakeholder engagement, and data-driven risk management. Based on these insights, this study suggests adapting the integrated safety-management framework of the construction industry for mining operations. The proposed system encompasses the following five key components: life-cycle management from design to post- closure, data-driven hazard profiling systems, multiagency collaborative frameworks, quantitative safety-evaluation mechanisms, and advanced technology integration, including BIM (Building Information Modeling) based simulations and machine-learning-based predictions. This framework enables systematic risk identification and real-time response capabilities throughout the mining cycle, thus providing a foundation for policy development and technological advancements in Korean mining-safety management."
Service Providers' Facial Ratios Impact Customer Satisfaction in the Hospitality E-Distribution Context,2025,"['Hospitality E-Distribution', 'Airbnb hosts', 'Guest Ratings', 'Facial Width-to-Height Ratio', 'Facial Recognition']",,"Purpose: Past studies have discovered that broader faces, indicated by a higher facial width-to-height ratio, are associated with antisocial personality traits and behaviors such as aggression and untrustworthiness. Extending these findings, this study investigates whether service providers' facial width-to-height ratios influence guest satisfaction evaluations in the hospitality e-distribution context (i.e., Airbnb). Research design, data and methodology: This research examines Airbnb host and property data in New York, employing a machine-learning-based facial recognition algorithm to analyze the facial images of approximately 18,000 hosts. Results: The findings reveal that hosts with broader faces receive lower guest ratings than those with narrower faces. Furthermore, the effect of facial ratio on ratings is moderated by accommodation type-entire homes versus shared or private rooms. When guests stayed in entire homes and did not share space with hosts, hosts' facial ratios did not significantly affect ratings. Conversely, when guests stayed in shared or private rooms, where they shared space with the hosts, hosts with broader faces received lower ratings. This study also finds that hosts' facial ratios influence Host ID verification behavior. Conclusions: This study suggests that service providers' facial width-to-height ratios can influence customers' evaluations of services, particularly in the context of hospitality distribution platforms such as Airbnb."
Ratio of Skeletal Muscle Mass to Visceral Fat Area Is a Useful Marker for Assessing Left Ventricular Diastolic Dysfunction among Koreans with Preserved Ejection Fraction: An Analysis of the Random Forest Model,2025,"['Intra-abdominal fat', 'Muscle', 'Skeletal', 'Body composition', 'Ventricular dysfunction', 'Left', 'Random forest']",,"Background: Although the presence of both obesity and reduced muscle mass presents a dual metabolic burden and additively has a negative effect on a variety of cardiometabolic parameters, data regarding the associations between their combined effects and left ventricular diastolic function are limited. This study investigated the association between the ratio of skeletal muscle mass to visceral fat area (SVR) and left ventricular diastolic dysfunction (LVDD) in patients with preserved ejection fraction using random forest machine learning.Methods: In total, 1,070 participants with preserved left ventricular ejection fraction who underwent comprehensive health examinations, including transthoracic echocardiography and bioimpedance body composition analysis, were enrolled. SVR was calculated as an index of sarcopenic obesity by dividing the appendicular skeletal muscle mass by the visceral fat area.Results: In the random forest model, age and SVR were the most powerful predictors of LVDD. Multivariate logistic regression analysis demonstrated that older age (adjusted odds ratio [OR], 1.11; 95% confidence interval [CI], 1.07 to 1.15) and lower SVR (adjusted OR, 0.08; 95% CI, 0.01 to 0.57) were independent risk factors for LVDD. SVR showed a significant improvement in predictive performance and fair predictability for LVDD, with the highest area under the curve noted in both men and women, with statistical significance. In non-obese and metabolically healthy individuals, the lowest SVR tertile was associated with a greater risk of LVDD compared to the highest SVR tertile.Conclusion: Decreased muscle mass and increased visceral fat were significantly associated with LVDD compared to obesity, body fat composition, and body muscle composition indices."
디지털 트랜스포메이션 기반 스마트 팩토리 프로세스 데이터를 활용한 데이터 품질 관리 신뢰성 측정 방법에 관한 연구,2025,"['Digital Transformation', 'Data Quality', 'Smart Manufacturing', 'AI-based Cleansing', 'Anomaly Detection', '디지털 전환', '데이터품질', '스마트 제조', 'AI 기반 정제', '이상 탐지']",,"Digital transformation (DX) is driving the implementation of smart factories in manufacturing, contributing to real-time analysis and optimization of process data. However, low data reliability can lead to quality degradation and increased costs, and problems such as missing values, outliers, and duplicate data can arise.In this study, we developed an AI-based data cleansing and quality management framework, applied it to manufacturing process data, and aimed to improve data reliability through anomaly detection using machine learning. Through the analysis of Oil Gasket manufacturing data, we empirically evaluated the reduction of defect rates, improvement of production speed, and optimization of resources. We assessed the core elements of data quality, including accuracy, completeness, consistency, reliability, timeliness, and validity, and enhanced data integrity using AI models such as Random Forest, Autoencoder, KNN, and Multivariate Regression.As a result of the research, it was confirmed that AI-based data quality management is effective in improving the productivity and quality of manufacturing, and the Data Quality Index (DQI) also improved by 6.5%.Through the use of various AI models, it was confirmed that the Random Forest model, in particular, has excellent performance in classifying defective products. Future research will propose a smart factory operating model through real-time data processing and automation, and present more effective quality management methods by building an AI-based quality management system."
Sparse Identification and Nonlinear Model Predictive Control for Diesel Engine Air Path System,2025,"['Air path system', 'diesel engine', 'model predictive control', 'sparse identification.']",,"This paper presents a sparse identification of nonlinear dynamic systems (SINDy) for a diesel engine air path system and nonlinear model predictive control (NMPC) with the SINDy model to attain good control performance. The air path system control is well known as a challenging problem, and many studies have been presented such as traditional model-based control design and machine learning. However, these conventional approaches still have some difficulties including the control performance and design costs. In this paper, we obtain the model of the air path system in a data-driven manner using the SINDy algorithm and construct the offset-free NMPC with the SINDy model. SINDy is a suitable modeling method for controlling a complicated air path system, owing to its characteristics of high computational efficiency, high learning efficiency, high modeling accuracy, and applicability to complex systems. Additionally, NMPC provides high control performance under constraints. The proposed offset-free NMPC with the SINDy model is verified through the simulations. The results show that the coefficient of determination of the SINDy model provided over 90%, and the controller performance of the NMPC was better than that of the traditional robust controller and satisfied the constraints."
Developing a Model to Predict Workers' Risk of Heart Attack Using Regularized Greedy Forests,2025,"['정규화 된 그래디 포레스트 (RGF)', '심장마비', '직업적 스트레스', '위험 요인', '생활 습관', 'Regularized Greedy Forest (RGF)', 'heart attack', 'occupational stress', 'risk factors', 'lifestyles']",,"This study introduces a predictive model using Regularized Greedy Forest (RGF) to identify high-risk heart attack candidates among workers. Heart disease risks are heightened by occupational stressors like stress and sedentary lifestyles. The RGF algorithm effectively handles complex datasets, surpassing traditional models like CART and KNN in prediction accuracy. The model highlights age, cholesterol, and physical activity as key risk factors, achieving an accuracy of 63.7% and an AUC of 65.1%. This research emphasizes machine learning's role in enhancing early intervention strategies in occupational health."
The combination of CDX2 expression status and tumorinfiltrating lymphocyte density as a prognostic factor in adjuvant FOLFOX-treated patients with stage III colorectal cancers,2025,"['CD8 antigens', 'CDX2 transcription factor', 'Colorectal neoplasms', 'Prognosis', 'Lymphocytes', 'tumor-infiltrating']",,"Background: Colorectal carcinomas (CRCs) with caudal-type homeobox 2 (CDX2) loss are recognized to pursue an aggressive behavior but tend to be accompanied by a high density of tumor-infiltrating lymphocytes (TILs). However, little is known about whether there is an interplay between CDX2 loss and TIL density in the survival of patients with CRC. Methods: Stage III CRC tissues were assessed for CDX2 loss using immunohistochemistry and analyzed for their densities of CD8 TILs in both intraepithelial (iTILs) and stromal areas using a machine learning-based analytic method. Results: CDX2 loss was significantly associated with a higher density of CD8 TILs in both intraepithelial and stromal areas. Both CDX2 loss and a high CD8 iTIL density were found to be prognostic parameters and showed hazard ratios of 2.314 (1.050–5.100) and 0.378 (0.175–0.817), respectively, for cancer-specific survival. A subset of CRCs with retained CDX2 expression and a high density of CD8 iTILs showed the best clinical outcome (hazard ratio of 0.138 [0.023–0.826]), whereas a subset with CDX2 loss and a high density of CD8 iTILs exhibited the worst clinical outcome (15.781 [3.939–63.230]). Conclusions: Altogether, a high density of CD8 iTILs did not make a difference in the survival of patients with CRC with CDX2 loss. The combination of CDX2 expression and intraepithelial CD8 TIL density was an independent prognostic marker in adjuvant chemotherapy-treated patients with stage III CRC."
Detection of IPv6 routing attacks using ANN and a novel IoT dataset,2025,"['artificial neural network', 'attack detection', 'internet of things', 'IPv6 routing protocol']",,"The Internet of Things (IoT) is an intelligent network paradigm created by interconnected device networks. Although the importance of IoT systems has increased in various applications, the increasing number of connected devices has made security even more critical. This study presents the ROUT-4-2023 dataset, which represents a step toward the security of IoT networks. This dataset simulates potential attacks on RPL-based IoT networks and provides a new platform for researchers in this field. Using artificial intelligence and machine-learning techniques, a performance evaluation was performed on four different artificial neural network models (convolutional neural network, deep neural network, multilayer perceptron structure, and routing attack detection-fed forward neural network [RaD-FFNN]). The results show that the RaD-FFNN model has high accuracy, precision, and retrieval rates, indicating that it can be used as an effective tool for the security of IoT networks. This study contributes to the protection of IoT networks from potential attacks by presenting ROUT-4-2023 and RaD-FFNN models, which will lead to further research on IoT security."
단일 채널 EEG 신호를 활용한 Residual LSTM 기반 졸음 감지,2025,"['Brain-Computer Interface', 'Electroencephalography', 'Residual LSTM', 'Drowsiness Detection', 'Single-Channel']","뇌-컴퓨터 인터페이스 기술은 신경 신호를 기반으로 한 인간-기계 상호작용을 가능하게 하며, 그중 EEG 신호는 실용성과 효율성 측면에서 주목받고 있다. 본 논문은 단일 채널 EEG 신호를 활용하여 운전자의 졸음 상태를 감지하기 위한 딥러닝 기반 접근법을 제안한다. 사용된 EEG 데이터는 전두엽과 귓불 간의 전압 차이를 기록하는 단일 채널 헤드셋인 NeuroSky MindWave로 수집된 공개 데이터를 활용하였다. 제안된 residual LSTM 모델은 잔차 연결을 통해 시간적 특징 추출을 강화하고 정보 손실을 줄이는 구조를 설계하였으며, 이를 통해 기존 모델 대비 성능을 향상시켰다. 졸음 감지 결과 residual LSTM은 85.36%의 정확도와 0.8575의 F1 score를 보였다. 이는 제안 기술이 주행 환경에서 운전자의 상태를 모니터링하여 안정성을 개선할 수 있음을 보인다.","BCI technology enables human-machine interaction by interpreting neural signals, with EEG being a prominent modality due to its practicality and efficiency. This study proposes a deep learning-based approach for detecting driver drowsiness using single-channel EEG signals. The EEG data, sourced from a publicly available dataset, were recorded using the NeuroSky MindWave headset, a single-channel device that measures voltage differences between the frontal lobe and earlobes. The proposed Residual LSTM model incorporates residual connections to enhance temporal feature extraction and reduce information loss, demonstrating superior performance compared to baseline models. The residual LSTM achieved an accuracy of 85.36% and F1 scores of 0.8496 for awake states and 0.8575 for drowsy states, surpassing all other models. This research demonstrates effectiveness of the proposed method in monitoring operator states, improving safety and efficiency."
한국어 발화 텍스트 데이터 기반 성별 판별에 관한 사례연구,2025,"['한국어 발화 데이터', '판별', 'Korean conversation data', 'Discrimination', 'BERT', 'XGBoost', 'RNN']","자연어 처리(natural language processing, NLP) 기술은 딥러닝의 발전과 함께 다양한 분야에서 혁신을 이끌고 있다. 예를 들어, 자율주행 차량 내 대화형 인공지능(AI)은 사용자의 발화를 분석하여 목적지 추천, 차량 제어 명령 수행, 온도 조절과 같은 개인 맞춤형 서비스를 제공한다. 또한, 헬스케어 분야에서는 음성 데이터를 활용한 심리 상담과 질병 진단 보조 서비스 등에서도 NLP 기술이 중요한 역할을 하고 있다. 이때 한국어는 어순의 자유로움과 복잡한 조사 및 어미변화 등 독특한 언어적 특성을 지니고 있어, 다른 언어에 비해 자연어 처리 기술 적용이 까다롭다고 알려져 있다. 본 연구에서는 한국어 발화 데이터의 특수성을 반영하여 성별을 판별하고, 최적의 임베딩 기법과 모형을 탐색하고자 한다. 이를 위해 TF-IDF, Doc2Vec, BERT와 같은 텍스트 임베딩 기법과 의사결정나무, 로지스틱 회귀, 랜덤 포레스트, SVM, XGBoost, RNN 등 다양한 머신러닝 모델 및 딥러닝 모델에 대하여 간단히 소개하고, 여러 가지 분석 방법에 따른 데이터의 성능을 비교하기 위해 AI Hub에서 제공된 대규모 한국어 발화 데이터셋을 활용하여 사례분석을 진행하였다.","Natural language processing (NLP) technology is leading innovation in various fields along with the development of deep learning. For example, interactive artificial intelligence (AI) in an autonomous vehicle analyzes the user's utterance and provides personalized services such as recommending destinations, performing vehicle control commands, and temperature control. In addition, in the health care field, NLP technology is playing an important role in psychological counseling using voice data and disease diagnosis assistance services. At this time, it is known that applying natural language processing technology is more difficult than other languages because Korean language has unique linguistic characteristics such as freedom of word order, complex investigation, and mother change. In this study, gender is determined by reflecting the specificity of Korean speech data, and the optimal embedding technique and model are explored. To this end, we briefly introduced text embedding techniques such as TF-IDF, Doc2Vec, and BERT, various machine learning models such as decision trees, logistic regression, random forest, SVM, XGBoost, and RNN, and conducted case analysis using large-scale Korean speech data sets provided by AI Hub to compare the performance of data according to various analysis method."
Rail Flaw B-Scan Image Analysis Using a Hierarchical Classification Model,2025,['Ballast railway track · Railway maintenance · Ultrasonic sensors · Hierarchical classifi cation model · Rail fl aw detection'],,"As railway traffic volumes and train speeds increase, rail maintenance is becoming more crucial to prevent catastrophic failures. This study aimed to develop an artificial intelligence (AI)-based solution for automatic rail flaw detection using ultrasound sensors to overcome the limitations of traditional inspection methods. Ultrasound sensors are well-suited for identifying structural abnormalities in rails. However, conventional inspection techniques like rail-walking are time-consuming and rely on human expertise, risking detection errors. To address this, a hierarchical classification model was proposed integrating ultrasound B-scan images and machine learning. It involved a two-stage approach—model A for fuzzy classification followed by Model EfficientNet-B7 was identified as the most effective architecture for both models through network comparisons. Experimental results demonstrated the model's ability to accurately detect rail flaws, achieving 88.56% accuracy. It could analyze a single ultrasound image sheet within 0.45 s. An AI-based solution using ultrasound sensors and hierarchical classification shows promise for automated, rapid, and reliable rail flaw detection to support safer railway infrastructure inspection and maintenance activities."
Hard X-ray absorption spectroscopy를 이용한 에너지 소재 분석 기술,2025,"['Energy material characterization', 'EXAFS', 'XANES', 'X-ray absorption spectroscopy']",,"Hard X‑ray absorption spectroscopy (Hard XAS) offers element‑specific bulk sensitivity combined with sub‑second time resolution, making it an indispensable tool for next‑generation energy materials. This article outlines the fundamentals of X-ray Absorption Near Edge Structure and Extended X-ray Absorption Fine Structure, details a reproducible Athena–Artemis workflow for calibration, background subtraction, χ(k) extraction, and FEFF‑based fitting, and highlights operando Hard XAS studies that unravel redox and structural dynamics in lithium‑ion battery electrodes and water‑splitting catalysts. Representative cases demonstrate how Hard XAS decouples capacity fade from voltage decay in Li‑rich layered oxides, stabilises Ruδ+ sites during high‑current acidic Oxygen evolution reaction, and guides interface engineering through real‑time redox mapping. Finally, we discuss forthcoming advances—including fourth‑generation synchrotrons, lab‑scale high‑harmonic sources and machine‑learning fitting engines—that will enable autonomous closed‑loop materials discovery."
신경망 기반 QAM 및 APSK 복조 방법 연구,2025,"['amplitude and phase shift keying', 'demodulator', 'neural network', 'quadrature amplitude modulation', '.']","차세대 통신 시스템은 위성 통신과 이동 통신이 결합된 융합 네트워크를 지향점으로 발전하고 있다. 그에 따라 다양한 변조 방식을 함께 처리할 수 있는 효율적인 복조기가 필요하며, 이를 실현하기 위해서는 기계 학습 기반의 접근 방법이 고려될 수 있다. 본 논문에서는 QAM(Quadrature Amplitude Modulation)과 APSK (Amplitude and Phase Shift Keying) 신호를 처리할 수 있는 신경망 기반의 복조 구조를 제안한다. 제안하는 복조 방법은 QAM 및 APSK 방식별로 학습된 가중치와 바이어스 값을 메모리로 적용하여 신경망 구조를 공통으로 사용하면서도 두 변조 신호를 모두 복조할 수 있게 한다. 또한 증폭기 비선형 왜곡 상황에서도 학습을 통해 심볼 오류율 성능을 보장할 수 있다. 컴퓨터 시뮬레이션을 통해 제안하는 신경망 기반 복조기의 성능을 검증한다.","The next-generation communication system is developing toward integrated networks that combine satellite and mobile communications. Therefore, an efficient demodulator that can process various modulation schemes is needed, and a machine learning-based approach can be considered to realize this. In this paper, we propose a neural network-based method that can demodulate quadrature amplitude modulation (QAM) and amplitude and phase shift keying (APSK) signals. The proposed method can be utilized to demodulate both modulation types by storing the weights and biases trained separately for QAM and APSK in memory. In addition, through learning, it is possible to have a sufficiently low symbol error rate even in nonlinear distortion situations. The performance of the proposed neural network-based demodulator is verified through computer simulation."
"Automated Writing Evaluation: Awareness, Perceptions,  and Expectations of Korean English Teachers and Students",2025,"['automated writing evaluation (AWE)', 'Korean', 'teachers', 'students', 'expectations']",,"Automated Writing Evaluation (AWE) has been used for nearly 70 years, initially for high-stakes testing and recently integrated into writing instruction. The present study investigated (1) the current state of English writing instruction in Korean secondary schools, (2) teachers' and students' awareness and perceptions of AWE, and (3) their expectations of AWE. Approximately 300 Korean EFL teachers and students participated in a web-based survey. The findings are as follows. Most teachers incorporated English writing into their regular classes with only a small percentage of teachers teaching essay writing, while most students relied on private education and tutoring to improve English writing. Teachers viewed a lack of time and large class sizes as being the main obstacles to writing instruction and feedback. Both teachers and students generally expressed positive attitudes toward the use of AWE, emphasizing its potential as an instructional and learning tool that provides immediate linguistic feedback, rather than merely functioning as a scoring machine. Both groups expected AWE to focus on grammatical feedback as they can address semantic issues themselves. To meet these expectations, a future Korean AWE model should be capable of enhancing instructional support and incorporating common writing errors specific to Korean learners."
"Statistical Methods for Baseline Adjustment and Cohort Analysis in Korean National Health Insurance Claims Data: A Review of PSM, IPTW, and Survival Analysis With Future Directions",2025,"['Korean National Health Insurance Claims Data', 'Selection Bias', 'Propensity Score', 'Cox Proportional Hazard Model', 'Inverse Probability of Treatment Weighting']",,"The utilization of health insurance claims data has expanded significantly, enabling researchers to conduct epidemiological studies on a large scale. This review examines key statistical methods for addressing baseline differences and conducting cohort analyses using Korean National Health Insurance claims data. Propensity score matching and inverse probability of treatment weighting are widely used to mitigate selection bias and enhance causal inference in observational studies. These methods help improve study validity by balancing covariates between treatment and control groups. Additionally, survival analysis techniques, such as the Cox proportional hazards model, are essential for assessing time-toevent outcomes and estimating hazard ratios while accounting for censoring. However, the application of these statistical methods is accompanied by challenges, including unmeasured confounding, instability in weight estimation, and violations of model assumptions.To address these limitations, emerging approaches, such as Doubly robust estimation, machine learning-based causal inference, and the marginal structural model, have gained prominence. These techniques offer greater flexibility and robustness in real-world data analysis. Future research should focus on refining methodologies for integrating highdimensional health datasets and leveraging artificial intelligence to enhance predictive modeling and causal inference. Furthermore, the expansion of international collaborations and the adoption of standardized data models will facilitate large-scale multi-center studies.Ethical considerations, including data privacy and algorithmic transparency, should also be prioritized to ensure responsible data use. Maximizing the utility of health insurance claims data requires interdisciplinary collaboration, methodological advancements, and the implementation of rigorous statistical techniques to support evidence-based healthcare policy and improve public health outcomes."
주사 탐침 현미경 기술을 이용한 기능성 박막 및 에너지 소재의 나노스케일 분석,2025,"['Electromechanics', 'Energy materials', 'Nanoscale characterization', 'Scanning probe microscopy', 'Surface science']",,"Scanning probe microscopy (SPM) has emerged as a versatile and powerful tool for nanoscale characterization of functional thin films and energy materials. Beyond topographical imaging via atomic force microscopy (AFM), SPM enables high-resolution mapping of electrical, mechanical, ionic, and magnetic properties, facilitating comprehensive understanding of diverse material systems. This review introduces key SPM techniques―such as lateral force microscopy (LFM), piezoresponse force microscopy (PFM), conductive AFM, electrochemical strain microscopy, and Kelvin probe force microscopy―and highlights their applicability to dielectric thin films, ferroelectric systems, battery composites, and ionic conductors. Advanced multidimensional techniques such as general mode (G-mode) SPM, dual-frequency PFM, and band excitation approaches are also discussed, offering enhanced signal sensitivity and data fidelity. Moreover, emerging developments in tomography SPM, photothermal AFM-based infrared spectroscopy (AFM-IR), and machine learning-based SPM are presented as future directions. This paper provides a comprehensive overview of the contributions of SPM to the precise analysis of structure–property relationships in functional thin films and energy materials at the nanoscale."
A Review on ethical and legal issues following the emergence of Humanoid with Embodied AI,2025,"['신경과학', '인공지능', '휴머노이드', '윤리', '신경과학적 관점', 'Neuroscience', 'AI', 'Humanoid', 'Ethics', 'Neuroscientific Perspective']","범용인공지능의 등장 이후, 슈퍼인공지능의 등장까지는 상당한 시간이 걸릴 것으로 전문가들은 예상하였으나, 그 시간이 너무나도 빨리 단축되어 인공지능 전문가들조차도 인류에 위협이 될 수도 있는 인공지능 개발 속도를 완화해야 한다고 하는 수준에 이르고 있다. 이러한 인공지능은 컴퓨터 화면을 통해서 2차원적으로 구현했지만, 로봇공학의 발전과 궤를 같이하여 인간과 닮은 로봇, 휴머노이드에 인공지능을 탑재하여 인간과 유사한 언어, 행동을 할 수 있는 모델을 만들기 위한 노력도 엄청나게 진화하고 있다. 2차원의 인공지능이 3차원으로 구현되어 우리 일상에 등장한다면 과연 인간에게 이익이 될 것인가에 대한 다양한 의견이 존재한다. 이러한 로봇공학, 기계공학, 인공지능의 발전에 추가하여 신경과학이 융합하여 혁신적인 휴머노이드의 빠른 등장을 예상하고 있다. 이러한 배경에는 인간의 뇌가 작동원리를 인공지능에 이식하여 인간과 유사한 행동, 언어, 표현이 가능하도록 하겠다는 것이다. 이러한 기술은 인간의 뇌와 기계를 연결하는 기술, BMI기술이 엄청나게 성장했기 때문이다. 신경과학의 융합분야 정점으로 잘 알려진 BMI(Brain-Machine Interface)는 신체장애, 정서장애를 극복하기 위해 개발되었지만, 뇌의 원리가 규명되기 시작하면서 이를 인공지능에 이식하여 자율학습을 통해 혁신적인 AI-신경과학 융합 휴머노이드의 등장을 예상하고 있는 것이다. 이런 휴머노이드의 등장은 경제적, 산업적으로 이익이 될 수도 있지만 인간의 일자리를 대체할 수도 있으며, 휴머노이드가 행한 행위에 대한 법률적, 윤리적 책임이 과연 누구에게 있는 것인가에 대한 다양한 논란이 예상된다. 그러나 이런 사회적으로 합의되고 윤리적 방향성을 설정하지 않은 상황에서 혁신적인 기술의 사회적 확산은 인간에게 엄청난 위협이 될 수도 있다. 본 연구에서는 이런 혁신적 기술변화에 대한 현황과 전망, 그리고 예상되는 논란과 쟁점에 대한 분석을 실시하고 이에 대한 사회적 합의와 윤리적 방향성에 대한 탐색을 실시하였다. 그리고 우리 사회가 혁신적 기술을 촉진하면서도 안전한 기술의 사용에 대해 신경과학, 인공지능 등 과학기술분야 뿐만 아니라 인문사회학, 법학, 윤리학 등 다양한 학제간 연구를 통해 미래 정책적 방안 마련을 위한 사회적 노력에 대하여 정책적 제언을 수행하고자 하였다.","Experts predicted that it would take a considerable amount of time for super artificial intelligence to emerge after the advent of general-purpose artificial intelligence, but that time has been shortened so quickly that even artificial intelligence experts are saying that the pace of artificial intelligence development that may pose a threat to humanity should be mitigated. Although this artificial intelligence was implemented two-dimensionally through computer screens, in line with the development of robotics, efforts to create human-like robots and models that can perform human-like language and actions are also evolving tremendously. There are various opinions on whether it will benefit humans if two-dimensional artificial intelligence is implemented in three dimensions and appears in our daily lives. In addition to the development of robotics, mechanical engineering, and artificial intelligence, neuroscience is expected to converge to allow the rapid emergence of innovative humanoids. In this background, the human brain intends to transplant the working principle into artificial intelligence so that it can behave, speak, and express human-like. This technology is due to the tremendous growth of technology and BMI technology that connect the human brain to machines. BMI (Brain-Machine Interface), well-known as the pinnacle of neuroscience convergence, was developed to overcome physical and emotional disorders, but as the principles of the brain begin to be identified, it is expected that innovative AI-neuroscience convergence humanoids will emerge through autonomous learning by implanting them into artificial intelligence. The emergence of such humanoids can be economically and industrially beneficial, but they can also replace human jobs, and various controversies are expected over who is legally and ethically responsible for the actions taken by humanoids. However, the social spread of innovative technologies can pose a huge threat to humans in the absence of such socially agreed and ethical directions. In this study, we analyzed the current status and prospects of these innovative technological changes, as well as expected controversies and issues, and conducted a search for social consensus and ethical directions. And while promoting innovative technology, our society tried to make policy suggestions for social efforts to come up with future policy measures through various interdisciplinary studies such as humanities, sociology, law, and ethics, as well as science and technology fields such as neuroscience and artificial intelligence."
Research on key technologies for early warning-position-angle monitoring and diagnosis of nuclear-grade pipeline leaks,2025,"['Nuclear-grade pipeline leakage', 'Convolutional neural network', 'Trend analysis', 'Pipeline leakage warning-position-angle monitoring']",,"Nuclear power plants (NPPs) are complex systems where most accidents stem from equipment failures. When such failures occur, personnel often struggle to identify the root cause accurately, promptly, and effectively, which can lead to worsening conditions and potential radioactive leaks. To reduce the risk of coolant loss accidents, it is crucial for NPPs to develop robust leakage monitoring systems that can control the spread of harmful consequences and improve overall safety. Although researchers have made significant strides in developing online pipeline leak detection systems, challenges remain, particularly in providing sufficient early warning information and accurately diagnosing the exact location of pipeline ruptures. To address these issues, this paper introduces an advanced monitoring and diagnostic method that combines threshold techniques with qualitative trend analysis to offer early warnings of nuclear-grade pipeline leaks. This method establishes a comprehensive ""early warning - location - angle"" monitoring and diagnostic framework. Specifically, the combined use of threshold methods and qualitative trend analysis enhances monitoring sensitivity, while a novel sensor positioning technique improves the accuracy of detecting abnormal locations, achieving precise localization within 0.275 m. Additionally, a machine learning-based technique is proposed for diagnosing breach angles, achieving a 95 % accuracy rate in monitoring breach angles."
위상학적 데이터 분석과 인공 신경망을 이용한 뇌전증 MEG 데이터 분류 연구,2025,"['brain network data', 'topological data analysis (TDA)', 'classification', 'artificial neural network (ANN)', 'magnetoencephalography (MEG) signal', '뇌 네트워크 데이터', '위상학적 데이터 분석(TDA)', '분류', '인공신경망(ANN)', 'MEG 신호']","위상학적 데이터 분석(topological data analysis; TDA)은 데이터에서 구조를 찾는 통계적 방법이다. 본 연구는 뇌 신경영상 뇌자도(magnetoencephalography; MEG) 데이터를 다중 분류하는 작업에 TDA 프로세스를 적용해보고자 하였다. MEG 데이터 모양으로부터 TDA feature를 얻어 탐색적 데이터 분석(exploratory data analysis; EDA)를 수행한 결과, betti curves와 persistence landscape로부터 얻은 TDA feature가 환자 분류 작업에 유의미한 것으로 파악되었다. 임베딩 층, 게이트 순환 유닛 층 그리고 전연결층으로 구성된 인공신경망을 설계해서 TDA feature의 분류 성능을 평가하였다. 0.95 이상의 정확도로 환자 그룹을 분류하는 모델을 구축하였다. 제안된 TDA 파이프라인은 분류에 유용하다. TDA는 다양한 데이터의 형태로부터 특징을 얻기 위해 요약하고 클러스터링하는 매우 전문적인 도구가 될 것이다.","Topological data analysis (TDA) is a statistical method that reveals structure in data. In this study, we applied the TDA process to multi-classify brain neuroimaging magnetoencephalography (MEG) data. By conducting exploratory data analysis (EDA) to derive TDA features from the shape of MEG data, we found that TDA features related to Betti curves and persistence landscape are meaningful for patient group classification tasks. We designed artificial neural networks (ANN) with TDA features, including an embedding layer, a gated recurrent units (GRU) layer, and a fully connected layer, and evaluated their performance. We built a model that classifies patient groups with an accuracy of 0.95 or higher. TDA, as a specialized tool, holds great potential for summarizing and clustering to extract features from the shape of various data, making it a valuable asset in data analysis, neuroscience, and machine learning."
유도탄 노화 경향 분석을 위한  데이터 통합 관리 프레임워크 제안,2025,"['Guided Missile', 'Data Integration Management', 'Data Structuring', 'Reliability Assessment']",,"Purpose: Guided missiles are single-use systems that require high reliability and lifecycle performance.However, quality test data from production and maintenance are currently unstructured and manually recorded, complicating data collection and analysis and ultimately hindering effective performance and reliability management. Hence, this study proposes a framework for digitalizing and integrating test data to enhance traceability and enable systematic analysis.Methods: Here, we propose a framework that standardizes and systematically manages test data from production quality, Ammunition Stockpile Reliability Program, and depot maintenance tests. In addition, data digitalization and integration strategies enable the framework to provide comprehensive management and analysis of guided missile test data throughout its entire lifecycle.Results: The framework was applied to object-oriented-guided missile data, enabling the standardization of test records. Accordingly, data visualization and statistical tests were conducted to deduce significant test parameters. Furthermore, the structured dataset demonstrated its applicability for machine learning-based anomaly detection and fault classification.Conclusion: This study presents an integrated data management framework that enhances the reliability assessment of guided missiles by ensuring data traceability and enabling systematic trend analysis. Moreover, this framework has the potential for broader application to other weapon systems, contributing to the advancement of data-driven weapon management"
인공지능 융합 교육 연구 동향과 발전 방향,2025,"['인공지능 융합 교육', '체계적 문헌 고찰', '연구동향', '인공지능 교육', 'AI-Integrated Education', 'systematic literature review', 'research trends', 'AIEd']","인공지능 융합 교육은 인공지능과 다른 교과를 융합하여 학습자들이 특정 교과의 내용 지식을 습득하는 동시에 인공지능 지식도 함께 습득하고, 두 개 이상의 교과 지식을 융합하여 고차적인 역량 개발을 목표로 한다. 인공지능 융합 교육 실천에 관한 관심과 사례가 증가하는 현시점에서 본 연구는 국내 인공지능 융합 교육 연구 동향을 분석하여 향후 발전 방향을 제시하고자 하였다. 2015년 1월부터 2024년 2월까지 발표된 인공지능 융합 교육 관련 문헌 중 총 26편의 논문을 선별하고 선행연구를 통해 도출한 분류 체계를 활용하여 해당 연구물을 체계적으로 검토 및 분석하였다. 연구 결과, 인공지능 융합 교육은 교과 지식과 인공지능의 이해를 넘어 실제 적용 및 창출 능력 배양에 보다 많은 중점을 두고 있음을 확인하였다. 융합 유형에서는 핵심 역량 기반 교육이 높은 비율을 차지하였고, 문제 해결 역량과 같은 고차적 사고 함양에 초점을 맞추고 있었다. 주요 내용 요소로는 인공지능의 ‘학습’이 많이 다루어지며 이를 위해 다양한 머신러닝 기반 도구의 활용이 두드러졌다. 인공지능 융합 교육의 실천이 과학 및 사회 과목에서 활발히 이루어졌으나, 그 외 교과 사례는 부족하여 향후 연구에서 다양한 교과와의 융합이 모색될 필요가 있음을 시사한다. 본 연구의 결과는 인공지능 융합 교육의 실제적 적용을 위한 다양한 수업 모형 개발과 교사의 설계 역량 강화를 위한 기초 자료로 활용될 수 있다. 향후 교육 현장으로의 확장을 위해 학교 현장의 특성을 고려한 후속 연구와 실천이 필요하다.","Artificial Intelligence(AI)-Integrated Education aims to develop knowledge of AI or develop higher-level competencies while simultaneously acquiring subject-specific content knowledge through the integration of AI with various discipline. However, research on its practical application and taxonomy of AI- integrated education remains limited in school settings. This study conducted a systematic review to analyze domestic cases of AI-integrated education trends and purpose future directions for research and practice. A total of 26 articles published between 2015 and 2024 were selected and systematically reviewed in relation to the taxonomy of AI-integrated education, which was derived from prior research and validated by experts. It was found that AI-integrated education prioritizes fostering the ability to apply and create beyond the fundamental understanding of subject knowledge and AI concepts. Additionally, competency-based integration, particularly aimed at enhancing higher-order thinking skills such as problem-solving, is predominant. The primary content focus was on learning, with extensive use of machine learning-based tools. AI-integrated education has been actively implemented in science and social studies, whereas its integration into other subjects remains limited, highlighting the need for broader applications across diverse disciplines. The results of this study provide a foundational resource for developing instructional models and enhancing teachers’ competencies in designing and implementing AI-integrated education. Further research and practical efforts, considering the contextual characteristics of school environments, are necessary for broader implementation across various educational settings."
온톨로지 기반의 의미 속성 및 감성 판별,2025,"['Ontology', 'Sentiment Analysis', 'Sentiment Dictionary', 'Natural Language Processing', 'LLM', '온톨로지', '감성판별', '감성어사전', '자연어처리', 'LLM']","최근 LLM(Large Language Model)은 자연어 처리(NLP)에서 강력한 성능을 보이지만, 특정 도메인의 문맥적 의미와 감성 차이를 정밀하게 반영하지 못하는 한계를 가진다. 본 연구에서는 온톨로지를 활용하여 감성 분석 모델의 정밀도를 향상시키고, 도메인별 감성 태깅을 체계적으로 수행하는 방법을 제안한다. 이를 위해 크라우드소싱을 활용한 감성 데이터셋을 구축하고, 온톨로지를 적용한 감성 태깅을 수행하여 감성 정보의 구조화를 강화하였다. 온톨로지 기반 감성 분석 모델의 성능을 기존 감성 분석 기법과 비교하기 위해 감성 어휘 사전 기반 모델, 기계 학습 모델(SVM, Naïve Bayes), 딥러닝 기반 감성 분석 모델(BERT 기반), 그리고 오픈소스 LLM 기반 감성 분석(Zero-shot, Few-shot)과 성능을 평가하였다. 실험 결과, 온톨로지를 적용한 감성 분석 모델은 기존 방법보다 높은 정확도를 보였으며, 특히 특정 도메인에서 감성 분석의 정밀도를 향상시키는 데 효과적인 것으로 나타났다. 본 연구는 온톨로지 기반 감성 분석이 감성 간 관계를 보다 정교하게 반영하고, 감성적 편향을 줄이는 데 기여할 수 있음을 실험적으로 검증하였다. 이를 통해 향후 다양한 도메인에서 보다 신뢰성 높은 감성 분석이 가능할 것으로 기대된다.","sourcing, and ontology-based sentiment tagging was applied to refine sentiment classification. To evaluate the effectiveness of the proposed method, performance comparisons were conducted with existing sentiment analysis models, including lexicon-based models, machine learning models (SVM, Naïve Bayes), deep learning-based models (BERT), and open-source LLM-based sentiment analysis (Zero-shot, Few-shot). Experimental results indicate that the ontology-enhanced sentiment analysis model outperforms conventional methods, particularly in domain-specific sentiment classification. This study demonstrates that ontology-based sentiment analysis effectively refines sentiment relationships and reduces domain-specific sentiment bias. These findings suggest that the proposed approach can contribute to more reliable sentiment analysis across diverse domains."
"국제 항공운송업과 해상운송업의 ESG 활동에 대한 빅데이터 비교 연구:TF-IDF, 토픽모델링과 SASB 표준을 중심으로",2025,"['ESG 전략', '항공운송업', '해상운송업', '지속가능경영보고서', 'TF-IDF', '토픽모델링', 'SASB', 'ESG strategy', 'Sustainability report', 'Air freight', 'Maritime transport', 'TF-IDF', 'Topic modeling', 'SASB standards']","본 연구는 국제 항공운송업과 해상운송업의 ESG 전략의 차이점을 규명하기 위해 빅데이터 분석방법을 이용하여 최근 영문 지속가능경영보고서를 비교 분석한 것이다. 국제항공사 22곳과 국제해운사 17곳의 보고서를 수집하여, TF-IDF와 LDA 토픽모델링 기법을 적용하고, SASB Materiality Map 기준에 따라 ESG 항목의 이행 수준을 정량 분석하였다. 분석 결과, 항공운송업은 emission, aviation, fuel 등 기후대응전략에 초점을 둔 반면, 해상운송업은 ship, report, crew 등 운영관리에 중점을 둔 것으로 나타났다. 또한 항공운송업은 자원기반관점에 따라 내부 역량을 활용한 ESG 전략을, 해상운송업은 제도이론 관점에서 외부 규제에 대응하는 전략을 보였다. 본 연구는 ESG 비정형 데이터를 활용한 비교 분석을 통해 산업 맞춤형 ESG 전략 수립과 EU 공시규제 대응에 실질적 시사점을 제시한다.","This study investigates how ESG (Environment, Social, Governance) strategies in the international transport sector differ by sub-industry characteristics, focusing on a comparative analysis of sustainability reports from the air freight and maritime transport industries. Reports from 22 global airlines and 17 maritime transport companies were collected and analyzed by TF-IDF and LDA, Topic modeling techniques. ESG disclosure performance was also quantitatively assessed based on the SASB Materiality Map. The findings show that air freight companies emphasize strategic ESG integration centered on climate action and supply chain management (e.g., emission, aviation, fuel), while maritime companies focus more on operational disclosures involving ship operations, crew welfare, and reporting (e.g., ship, report, crew). From a theoretical perspective, air freight firms tend to internalize ESG as a strategic asset aligned with the Resource-Based View, whereas maritime firms exhibit a pattern of compliance- oriented ESG shaped by Institutional Theory. By applying machine learning-based text analysis to unstructured ESG data, this study offers insights into the structural differentiation of ESG strategies and provides practical implications for industry-specific ESG policy development and responses to global disclosure regulations."
동축(coaxial) 레이저 열원을 활용한 와이어 에너지 제어 용착(LW-DED) 적층제조 공정의 개요와 연구동향,2025,"['LW-DED', 'Laser Wire Directed Energy Deposition', 'Additive Manufacturing', '3D printing']",,"Metal additive manufacturing (AM), often referred to as metal 3D printing, is a promising andwidely adopted approach for fabricating intricate components without conventional molds or casting processes.Although powder-based metal AM processes have gained significant recognition for their ability to realizecomplex shapes, their cost remains a major barrier to broader commercialization. To address these cost-relatedchallenges, the use of wire-feed directed energy deposition (DED) has emerged as a potential alternative. Inparticular, laser-based wire directed energy deposition (LW-DED) offers an effective balance betweenresolution, build rate, and materials flexibility. This review first outlines the limitations of powder-basedmetal AM processes, highlighting issues such as low powder yield and material cost. Subsequently, it exploresthe fundamental operating principles of LW-DED, including laser-beam types, deposition head configurations,and their impact on process efficiency. In particular, the review highlights coaxial LW-DED, which enablesmore uniform material deposition and improved precision. Additionally, it examines the advantages of LWDED(e.g., reduced material loss, lower raw-material costs, and multi-material flexibility) as well as itsshortcomings (including lower resolution and potential need for post-processing). Finally, recent researchtrends of coaxial LW-DED systems and ongoing advancements in process monitoring, microstructure control,and machine learning–driven optimization are presented to illustrate the potential of LW-DED as a rapidlyevolving, commercially viable AM technology."
아스팔트 포장 결빙 발생 예측을 위한 열전달 모형 및 판단 기준 연구,2025,"['Black ice', 'asphalt pavement', 'Thermodynamics', 'finite-difference method', 'phase-change analysis']",,"This paper presents a finite-difference method (FDM)-based heat-transfer model for predicting black-ice formation on asphalt pavements and establishes decision criteria using only meteorological data. Black ice is a major cause of winter road accidents and forms under specific surface temperature and moisture conditions; however, its accurate prediction remains challenging owing to dynamic environmental interactions. The FDM incorporates thermodynamic properties, initial pavement-temperature profiles, and surface heat-transfer mechanisms, i.e., radiation, convection, and conduction. Sensitivity analysis shows the necessity of a 28-d stabilization period for reliable winter predictions. Black-ice prediction logic evaluates the surface conditions, relative humidity, wind speed, and latent-heat accumulation to assess phase changes. Field data from Nonsancheon Bridge were used for validation, where a maximum prediction accuracy of 64% is indicated in specific cases despite the overestimation of surface temperatures compared with sensor measurements. These findings highlight the challenges posed by wet surface conditions and prolonged latent-heat retention, which extend the predicted freezing duration. This study provides a theoretically grounded methodology for predicting black ice on various road structures without necessitating additional measurements. Future studies shall focus on enhancing the model by integrating vehicle-induced heat effects, solar radiation, and improved weather-prediction data while comparing the FDM with machine-learning approaches for performance optimization. The results of this study offer a foundation for developing efficient road-safety measures during winter."
시민의 지역사회 현안 인식이 정치참여 의식에미치는 영향: C시를 중심으로,2025,"['커뮤니티케어', '제품디자인', '보건의료', '건강증진', '다차원적 분석', 'Community Care', 'Product Design', 'Healthcare', 'Health Promotion', 'Multidimensional Analysis']","본 연구는 커뮤니티 케어 기반 제품디자인에 적용된 보건의료 및 건강증진 개념의 반영 양상을 다차원적으로 분석하고, 관련 변수들의 영향력을 실증적으로 파악하고자 하였다. 2000년부터 2023년까지 한국학술인용색인(KCI)에 등재된 학술논문 중 ‘커뮤니티 케어’, ‘제품디자인’, ‘보건의료’, ‘건강증진’을 핵심 키워드로 포함한 논문을 기준으로 데이터셋을 구축하였다. 분석 방법은 시계열 분석을 통해 각 시점별 개념의 등장 빈도 및 변화 추이를 파악하였으며, 기계학습 기반 다변량 분석(Random Forest, Partial Dependence Plot)을 통해 보건의료(H1) 및 건강증진(HH) 개념에 영향을 미치는 주요 설계 변수를 예측하였으며, 모델의 정확도와 변수 중요도는 교차검증을 통해 검증되었다. 연구 결과, 건강증진 개념은 최근으로 갈수록 지속적으로 증가하고 있으며, 특히 온라인·오프라인 혼합형 플랫폼과 비상시 대응 기능을 포함한 디지털 헬스케어와 커뮤니티 기반 예방적 돌봄이 핵심 설계 요소인 것이 확인되었다. 반면, 기존의 재활·질환관리 중심 보건의료 설계는 점차 감소하는 경향을 보였다. 우리는 본 연구를 통해 커뮤니티 케어 제품디자인에 적용되는 보건의료 및 건강증진 개념이 시간, 차원, 기능, 지역 변수를 통해 어떻게 구조화되었는지를 실증적으로 해석하였다. 향후 지역사회 기반 제품개발 및 정책 수립 과정에 기초 자료로 활용될 것으로 기대된다.","This study conducted a multidimensional analysis of how healthcare and health promotion concepts have been reflected in community care-based product design, and examined the influence of related design variables. We built a dataset of academic articles published between 2000 and 2023 in the Korean Citation Index containing the keywords community care, product design, healthcare, and health promotion. Time-series analysis was used to examine concept frequency and trends, while machine learning-based multivariate analysis (Random Forest, Partial Dependence Plot) identified key variables influencing the application of healthcare and health promotion, with model accuracy validated through cross-validation. Results indicate a growing emphasis on health promotion, with online–offline hybrid platforms and emergency-responsive features linked to digital healthcare and community-based preventive care, emerging as critical design elements. In contrast, rehabilitation- and treatment-centered healthcare design is gradually declining. This study offers empirical insights into how key variables such as time, dimension, function, and region structure healthcare and health promotion in community care product design, providing a foundation for future product development and policy planning."
베이지안 최적화를 이용한 Mini-CPTR의 성능 최적화에 관한 연구,2025,"['Compact Payload Test Range', 'Alignment', 'Bayesian Optimization', 'Zernike Polynomials', '실내 탑재체 시험 시설', '정렬', '베이지안 최적화', '제르니케 다항식']","Compact Payload Test Range(CPTR)는 전자파의 준 평면파 영역을 실내에서 생성함으로써 위성의 안테나 및 통신장비의 기능 시험과 검증은 물론, 시험 대상 또는 목표물에 대한 전자파 산란(Scattering) 측정을 가능하게 한다. CPTR은 준 평면파(Quasi Plane Wave) 영역에서 평면파의 요구조건을 만족하기 위해서는 전자파를 방사하는 급전부(Feeder)와 반사판 사이의 매우 정밀한 정렬이 요구되지만, 현재까지는 전문가의 경험에 기반하여 정렬 작업이 수행되고 있다. 급전부의 위치 및 각도 등과 같은 변수의 변화에 대한 평면파의 질과 같은 성능지수를 실험적으로 측정하여 데이터를 추출하는 과정은 많은 시간과 비용이 발생한다. 본 연구에서는 이러한 문제를 해결하기 위해서 기계 학습의 일종인 베이지안 최적화(Bayesian Optimization)를 이용하여 평면파의 질을 극대화하도록 급전부 위치 및 각도를 최적화하는 작업을 최소한의 실험 횟수에 성공적으로 수행하였다.","The CPTR(Compact Payload Test Range) generates a quasi-plane wave region of electromagnetic waves indoors, enabling functional testing and verification of satellite antennas and communication equipment, as well as electromagnetic wave scattering measurement for target objective. CPTR requires precise alignment between the feeder that emits electromagnetic waves and the reflector to meet the requirements of a plane wave in the quasi-plane wave region, but so far, the alignment of these elements is performed based on expert’s experience. In this study, the process of extracting data by experimentally measuring performance indices such as the quality of plane waves in response to changes in variables such as the position and angle of the feeder takes a lot of time and costs. To solve this problem, the task of optimizing the feeder position and angle to maximize the quality of the plane wave was successfully performed in the minimum number of experiments using Bayesian Optimization, a type of machine learning."
AI챗봇에 대한 인지된 개인화가 고객시민행동에 미치는 영향:인지된 공감과 프라이버시 침해우려의 조절된 매개효과,2025,"['AI챗봇', 'AI개인화', '고객시민행동', '인지된 공감', '프라이버시 침해우려', 'AI Chatbot', 'Personalized AI Service', 'Customer Citizenship Behavior', 'Perceived Empathy', 'Perceived Privacy Concern']","AI와 빅데이터 분석기술의 발전은 소비자 행동과 기업 마케팅 활동의 전반에서 혁신적인 변화를 가져왔다. 많은 기업들이 고객데이터와 AI기술을 접목해 고객 맞춤형 마케팅을 제공하고 있으며, 마케팅 활동을 효율화하고 생산성을 향상시키려는 노력을 기울이고 있다. 특히 AI챗봇은 고객접점에서 가장 빠르게 적용되고 있는 AI기술로 고객의 니즈를 파악하고 개인화된 응대를 제공하는 주요한 수단으로 자리 잡았다. 전통적으로 고객응대 종업원의 공감은 고객의 긍정적 반응을 촉진하는 요인으로 널리 인정받아 왔다. 이에 본 연구는 사회적 역할자로서 컴퓨터(CASA) 이론에 기반하여 소프트웨어인 AI챗봇의 경우도 고객이 공감을 인식할 때 바람직한 행동이 촉진될 것으로 예상하고 연구모형을 수립하였다. 먼저, AI기기수용모형의 틀에 맞추어 AI챗봇의 인지된 개인화가 인지된 공감을 매개로 고객시민행동을 향상시키는 매개경로가 존재할 것으로 예상하였다. 한편, AI챗봇이 지나치게 개인화된 상호작용을 하는 것은 오히려 사용자에게 부정적인 영향을 줄 것으로 보았다. 이에 따라 정보경계이론(IBT)을 근거로 인지된 공감의 매개효과가 프라이버시 침해우려에 의해 조절되는 조절된 매개효과가 발생하는 것으로 가설을 수립하였다. 실증분석을 위해서 국내에서 AI챗봇 사용경험이 있는 210명을 대상으로 온라인 설문조사를 실시하였고 PROCESSSS macro 모형을 사용해서 매개효과와 조절된 매개효과를 조사하였다. 분석결과 AI챗봇의 인지된 개인화는 인지된 공감의 매개를 통해서 고객시민행동을 제고하며, 이 매개효과는 프라이버시 침해우려에 의해 조절되는 것으로 나타났다. 유통영역에서 AI챗봇이 빠르게 도입되고 있음에도 불구하고 AI챗봇과 고객 간 감성적 상호작용 효과에 집중한 연구는 드물다. 본 연구는 개인화를 통한 공감의 제고가 고객의 가치 공동창출 행동을 촉진한다는 사실을 실증하였다. 이러한 연구결과는 고객과 AI챗봇 간 감성적 상호작용의 중요성을 환기하고 효과경로에 대한 이해를 심화시켰다는 데 기여점이 있다. 실무적 관점에서도 AI챗봇의 개인화 수준과 프라이버시 침해우려의 관리에 대한 시사점을 제공하였다.","Purpose: AI and big data have transformed customer behaviors and marketing strategies, with businesses using customer data for personalized services that improve efficiency and reduce workload. For customers, AI enhances convenience by automating tasks. Post-COVID, AI adoption accelerated, with 42% of businesses using chatbots that leverage natural language processing and machine learning. In banking, 51.4% of representatives acknowledge chatbots’ effectiveness, while retail implementation has increased 31% since 2021, now reaching 73% of global companies. Current research limitations include focus on functional rather than intelligent features, limited empirical research on personalization and psychological responses, insufficient research on empathy’s influence, minimal privacy concern research, and poor understanding of interaction factors. This study examines chatbot personalization’s impact on perceived empathy, how empathy affects customer citizenship behavior, and privacy concerns’ moderating effect. The research draws on CASA theory, AI Job Replacement Theory, AI Device Use Adoption model, and Information Boundary Theory. Based on this theoretical background, the study developed the following hypotheses: [H1] Perceived personalization of AI chatbot services will increase customer citizenship behavior.[H2] Perceived empathy will mediate the effect of perceived personalization of AI chatbot services on customer citizenship behavior.[H3] Privacy concerns will moderate the mediating pathway where perceived personalization of AI chatbot services affects customer citizenship behavior through perceived empathy.Research design, data and methodology: This study surveyed Korean adults who had used AI chatbots, following Hair et al.’s (2010) guidelines recommending 5–15 responses per observed variable for structural equation modeling. With 14 variables, they targeted 140–210 responses. The online survey ran February 1–15, 2024, through a domestic panel agency, screening for those who had used AI chatbot customer service within the past year. From 234 participants, 24 were excluded for short response times or irrelevant answers, leaving 210 respondents. The sample was 64% male with an average age of 32.1 years, distributed across age groups: 30s (39%), 20s (31%), 40s (23%), and 50s (7%). For chatbot service frequency, 41.1% reported “less than 10 times,” 21.9% “20+ times,” 19.4% “less than 5 times,” 10.6% “less than 15 times,” and 7.0% “less than 20 times.” With 81.6% having used chatbots at least 5 times, the sample confirmed their widespread use. Measurement items used a 5-point scale, with perceived personalization measured by four items, perceived empathy by three items, customer citizenship behavior by four items, and privacy concerns by three items.Results: Using Hayes’ PROCESS MACRO Model 4, the total effect of perceived personalization on perceived empathy was significant (b=0.671, p<0.001), supporting Hypothesis 1. Bootstrapping analysis (n=1,000) showed a significant indirect effect of perceived empathy (0.273, 95% CI=[0.186, 0.371]) and significant direct effect (95% CI=[0.282, 0.514]), confirming perceived empathy partially mediates the influence of perceived personalization on customer citizenship behavior, supporting Hypothesis 2 (show <Table 1>).To verify whether privacy concerns moderate the indirect effect of perceived personalization of AI chatbot services on customer citizenship behavior through perceived empathy, Hayes' PROCESS MACRO Model 7 was used. The analysis showed a statistically significant interaction effect between perceived personalization and privacy concerns on perceived empathy (b=–0.160, p<0.001). This confirms that the influence of perceived personalization on perceived empathy varies depending on the level of privacy concerns (see <Table 2>).A conditional effect analysis examined the moderating effect of privacy concerns, which were classi..."
Systematic review and meta-analysis of volatile organic compounds (VOCs)  for breast cancer screening using the PRISMA approach,2025,"['breast cancer', 'biomarker', 'volatile organic compounds (VOCs)', 'non-invasive', 'PRISMA']",,"Breast cancer remains one of the most health challenges among women globally. Early detection significantly improves patient conditions and survival rates. Volatile organic compounds (VOCs) which are low molecular weight byproducts released through biological processes have gained a great attention as potential non-invasive biomarkers for cancer diagnosis. This systematic review was conducted using the PRISMA approach to analyze recent studies on utility of VOCs in breast cancer screening. A total of 1,340 studies were initially retrieved from Google Scholar, of which 30 studies were selected for in-depth analysis. The results indicate that eight VOCs were among the most frequently reported out of a total 268 identified through the studies. The eight frequent VOCs associated with breast cancer found in various biological samples such as breath, blood, urine, cell, and saliva were phenol, 2-ethyl-1-hexanol, acetic acid, p-cresol, octanoic acid, 2 pentylfuran, guaiacol, 4-tert-butylphenol. In review, significant variability was present in sampling methods, headspace solid phase microextraction conditions, analytical techniques, and identified VOCs across studies.To enhance VOC-based cancer diagnosis toward clinical utilization, future research should focus on standardizing analytical protocols, improving VOCs’ selectivity, and exploring machine learning-based classification models.This review underscores the significant potential of VOC-based diagnostics while emphasizing the need for further validation and standardization of methodological methodologies."
항공기상정보 제공을 위한 4D 나래기상 데이터 플랫폼의 배포서비스 개발,2025,"['나래기상', '궤적기반', '영역기반', '지점기반', '항공기상', 'NARAE-Weather', 'Trajectory based', 'Region of Interest Based', 'Point based', 'Aviation Weather']","본 논문은 차세대 항공교통 계획(NARAE) 지원을 위한 4D 나래기상 데이터 플랫폼의 배포서비스 개발에 대해다루고 있다. 항공기 운항 안정성 확보를 위해 시간과 공간에 따라 변하는 기상정보를 실시간으로 통합 제공하는플랫폼의 필요성이 대두되었으며, 제안된 4D 나래기상 데이터 플랫폼은 레거시 배포서비스, API 배포 서비스 및구독/게시 배포 서비스를 통해 기상정보의 효율적인 제공을 지원한다. 이 플랫폼은 항공기 운항 궤적에 따른 맞춤형 기상정보를 제공하며, 30시간 이상의 결정론적 예측 기상 데이터와 기계 학습 기반 확률예측 데이터를 제공한다. 이러한 예측 데이터는 항공기 운항 중 발생할 수 있는 위험요소를 사전에 파악하고, 운항 의사결정에 중요한역할을 한다. 본 논문은 항공사, 항공교통 관제사, 공항 운영자 등 다양한 사용자 그룹에서 항공기 운항의 안전성과 효율성을 증대시키기 위해 활용될 4D 나래기상 데이터 플랫폼의 기능 구성을 제시하고, 이러한 기능을 조합하여 구현된 레거시 배포서비스, API 배포 서비스 및 구독/게시 배포 서비스에 대해 상세히 기술한다.","This paper discusses the development of the distribution service for the 4D NARAE-Weather data platform, designed to support the next-generation air traffic plan (NARAE). The need for a platform that provides real-time, integrated weather information, which changes dynamically across time and space, has emerged to ensure the safety of aircraft operations. The proposed 4D NARAE-Weather data platform facilitates efficient weather information delivery through legacy distribution services, API distribution services, and subscription/publish distribution services. This platform provides customized weather information based on aircraft flight trajectories, offering more than 30 hours of deterministic forecast data and machine learning-based probabilistic forecast data. These forecast data play a crucial role in identifying potential hazards during flight and supporting operational decision-making. This paper presents the functional composition of the 4D NARAE-Weather data platform, which is designed to enhance the safety and efficiency of aircraft operations for various user groups, including airlines, air traffic controllers, and airport operators. Additionally, it provides detailed descriptions of the legacy distribution service, API distribution service, and subscription/publish distribution service, which are implemented by combining the platform's functionalities."
유방암 조기 진단을 위한 멀티모달 이미징 기반의 휴대형 모바일 디바이스 개발 및 알고리즘,2025,"['Breast cancer', 'Early diagnosis', 'Multimodal imaging', 'Mobile device']",,"The purpose of this study is to develop a portable device and algorithm based on multimodal imaging for early diagnosis of breast cancer and to verify its effectiveness. In order to overcome the limitations of existing imag- ing diagnostic methods, this study designed the Tactile Sensation and Diffuse Optical Imaging System (TSDOIS) that combines tactile sensing image (TSI) and diffuse optical image (DOI). This system is designed to measure the phys- ical and physiological characteristics of the lesion simultaneously, and increased accessibility and usability through miniaturization and mobile interlocking device implementation. The TSI acquisition module extracts information on the elasticity, depth, and size of the lesion through a total internal reflection (TIR)-based elastic waveguide, and the DOI acquisition module detects lesions with high hemoglobin concentration based on the red light (638 nm) reflec- tance reduction pattern. As a result of the phantom experiment, it was confirmed that the TSI and DOI contrast were significantly increased in high stiffness, surface layer, large size, and high hemoglobin nodules. This study suggests that small diagnostic equipment based on multimodal imaging can present new possibilities for early diagnosis of breast cancer. In the future, it is expected that the scope of use of this system can be expanded through performance verification based on clinical data and application of machine learning-based automatic analysis algorithms"
국내 경상도 광역시 내 산업단지에서의 악취 감시 현황 및 전망,2025,"['악취', '산업단지', '광역시', '모니터링', '건강영향', 'Odor', 'Industrial complex', 'Metropolitan city', 'Monitoring', 'Health impact']","본 연구는 기존 연구에서 국내 경상도 광역시 내 산업단지에 의해 발생하는 악취의 분석 및 감시 방안을 살펴보고 이에 관련된 향후 기술 및 관리측면에서의 시사점과 개선방향을 제시하였다. 기존 분석 및 감시 방안은 주로 2020년 이후 국 내 연구 문헌을 참조하였는데, 이들은 악취 민원이 다수 발생할 수 있는 광역시 내 제조업체를 다수 포함하는 산업단지 를 조사대상으로 하였다. 기존에 제시된 방안은 대체로 다수 지점에서의 기기 및 장비의 추가를 통해 보다 상세한 악취 분석, 지역 내 지리정보나 수학적 모델을 연동하여 악취 보다 과학적인 예측 및 추적  악취 문제 발견 이후 합리적 진단 및 사후 조치 유도, 그리고 인터넷이나 스마트폰 앱 등을 통한 민원접수 및 주변 거주민과의 정보공유와 상호 커뮤니케 이션 등으로 분류된다. 추가적으로 본 연구에서는 해외 연구사례를 참조하여 기계학습 기반 검보정 기술을 통한 저농도 악취 모니터링 시 자동화 및 측정 신뢰도 제고 방안을 소개하고 이를 통하여 다수의 저가 악취센서 기반 측정망과 소수 의 고가 정밀측정 기기를 연동한 합리적 모니터링 방안을 제시하였다. 추가적으로 이러한 악취 감시자료를 사업장 근로 자 혹은 인근 거주민의 이차자료 기반 건강영향자료 등과 연계한다면 보다 효율적일 것으로 판단된다.","This study reviewed the previous odor monitoring statuses of industrial complexes in the domestic metropolitan cities (Ulsan and Daegu) of Gyeongsang Province and their relevant counter-measures. In addition, it identified future technical and management issues and made suggestions on how to overcome them. The statuses and counter-measures were mainly obtained through domestic research studies from the 2020s. The target industrial complexes included manufacturing plants inside metropolitan city areas where severe civil complaints could occur. The counter-measures were generally classified into further in- depth odor analysis through the placement of monitoring equipment at multiple locations, scientific odor prediction and source tracking by integrating regional database systems or applying mathematical models, reasonable diagnosis and follow-up action after the identification of odor issues, and effective mutual communication with on-going or potential civil complaints from nearby residents through the Internet or smartphone apps. Additionally, this study suggested the automation of odor monitoring by using improved technologies with enhanced reliability through machine learning. These technologies would make it possible to organize a feasible monitoring network by deploying multiple low-cost odor sensors with automatic calibration and validation capabilities. Furthermore, this odor monitoring data could be made more effective when implemented together with health impact analyses based on secondary data from employees at workplaces or nearby residents."
Exploring the Use of AI-based FlatCo Coding Platform in Technology and Engineering Classes,2025,"['코딩 플랫폼', '플랫코 코딩', '기술-공학 수업', 'Coding Platform', 'FlatCo Coding Platform', 'Technology Class']","인공 지능(AI)과 로봇 공학의 역할이 글로벌 교육, 특히 STEM 및 STEAM 프레임워크 내에서 점점 더 중요해짐에 따라 기존 코딩 교육에서 AI를 활용해야 할 필요성이 매우 증가하고 있다. 따라서 이 연구의 목적은 초, 중등학교 기술-공학 수업에서 인 공지능형 코딩 플랫폼의 하나인 플랫코(FlatCo)의 활용 방안을 제시하고 가능성을 탐구하는 데 있다. 이 연구는 탐색적 문헌연 구를 주된 연구 방법으로 활용하여 AI 기반 플랫코 코딩 플랫폼의 활용 가능성을 주제별로 비판적으로 검토하고, 이를 기반으 로 교육적 활용 방안을 도출하였다. 이 연구의 결론은 다음과 같다. 첫째, 초등학교 기술-공학 수업에서 플랫코를 사용하여 블록 기반 코딩을 통한 로봇 제어 프 로그래밍을 통한 기본 코딩 및 AI 개념을 활용할 수 있다. 플랫코의 시각적 프로그래밍 환경을 사용하여 학생들은 간단한 로봇 작동을 프로그래밍하여 경로를 따르거나 장애물을 피하거나 기본 센서 입력에 반응하는 등의 작업을 수행할 수 있다. 둘째, 중학교 기술-공학 수업에서는 고급 프로그래밍으로 학생들에게 부담을 주지 않으면서 기본 AI 개념을 포함하는 중급 로봇 공학 프로젝트에 플랫코 플랫폼을 활용할 수 있다. 이 수준에서 학생들은 블록 기반 코딩이나 단순화된 Python 명령을 사 용하여 센서 입력에 응답하고 간단한 AI 기반 작업을 실행하는 로봇을 프로그래밍할 수 있다. 셋째, 고등학교 기술-공학 수업에서는 플랫코 플랫폼을 활용하여 실제 AI 애플리케이션에 중점을 두지만 기계 학습의 복잡 성을 다루지 않는 고급 로봇 공학 프로젝트에 적용할 수 있다. 이 수준에서는 플랫코의 AI 도구를 사용하여 장애물 코스를 탐색 하거나 환경 변화에 대응하여 사전 정의된 작업을 완료하는 등 자율적으로 작업을 수행할 수 있는 실제 시스템을 시뮬레이션하 는 것을 강조한다. 마지막으로, 플랫코 플랫폼은 향상된 학생 참여 및 상호작용을 향상시킬 수 있다. 플랫코 플랫폼은 AI 기반 로봇 코딩을 통 해 실시간 피드백과 대화형 경험을 제공함으로써 학생 참여와 실습 학습을 크게 향상시킨다. 이는 프로그래밍 개념에 대한 더 깊은 이해를 촉진하고 문제 해결 작업에 대한 적극적인 참여를 촉진한다. 이러한 연구의 맥락에 따라 플랫폼의 향상과 추후연구를 위하여 제언을 하면, 장치 호환성을 확장해야 할 필요가 있다. 즉 iOS 시스템을 포함한 더 넓은 범위의 장치를 지원하여 다양한 교육 환경에서 기술에 더 쉽게 접근하고 사용할 수 있도록 플랫 코 플랫폼을 강화하는 데 중점을 두어야 한다.","The purpose of this study is to propose the use of the AI-powered FlatCo coding platform in technology and engineering education in primary and secondary schools. This study uses a literature review as the main research method to critically examine the feasibility of using AI-based FlatCo coding platforms by topic and to derive educational applications based on this. The conclusions of this study are as follows; First, FlatCo can be used in primary school technology and engineering classes to introduce basic coding and AI concepts by programming robot control through block-based coding. Second, middle schools can use the FlatCo platform for intermediate robotics projects that include basic AI concepts without overwhelming students with advanced programming. Third, in high school technology and engineering classes, the FlatCo platform can be used for advanced robotics projects that focus on real-world AI applications but do not address the complexities of machine learning. Finally, the FlatCo platform enables increased student engagement and interaction. The FlatCo platform significantly enhances student engagement and hands-on learning by providing real-time."
"정적 언어모델부터 생성형AI까지, 텍스트를 다시 쓰는 기술에 대하여 — 조은경, 『한국학과 데이터과학』(서강대학교출판부, 2024) —",2025,"['데이터과학 연구방법론', '디지털인문학', '정적 언어모델', '동적 언어모델', '생성형 언어모 델', '지식생산모델링', '텍스트와 기술 간 창조적 맵핑', '다층적 차원의 공동저작성', '중단없 는 글쓰기', '차연(différence)', 'data-scientific research methods', 'digital humanities', 'static language model', 'dynamic language model', 'generative language model', 'knowledge production modeling', 'creative  mapping  between  text  and  technology', 'multi-layered co-authorship', 'unending writing', 'différance']","조은경의 『한국학과 데이터과학』은 “어문 및 인문학 연구자에게 활용도 높은 데이터 과학적 연구방법론을 안내함으로써” 한국 문학 및 문화 연구를 디지털인문학 방법론 을 수행하고자 하는 연구자에게 실질적인 도움을 줄 수 있는 책이다. 디지털인문학은 데이터 분석의 프로토콜을 포함하지만 단순한 기술 활용을 넘어 철학적, 문화적 전환 을 내포하는 광범위한 개념으로 사용되기도 한다. 이 과정에서 생산되는 관련 논문이 나 논의들은 담론성이 강하게 나타나거나 기술 사용 과정이 간소화되는 경우가 있는 것도 사실이다. 조은경은 ‘데이터과학’이라는 용어를 채택함으로써 한국어 기반 언어 자료를 수집하고 처리하여 분석하는 데 필요한 구체적인 기술과 절차에 보다 초점을 맞추고 있다.디지털인문학에서 가장 활발하게 수행되는 연구 중 하나는 문자 기반 텍스트에 대한 분석이다. 그렇기 때문에 이 책 또한 “데이터의 양적 분석에 쓰이는 기초 통계량에서 부터 딥러닝에 이르기까지”를 차근차근 설명하고 있다. 비정형 데이터의 비중이 증가 함에 따라 평균, 표준편차, 분산 등 전통적인 기술통계량만으로는 데이터가 내포한 복잡한 의미 구조나 맥락적 관계를 충분히 설명하기 어려운 점이 있으므로 고차원 벡터 기반 지표들을 요청하게 되었으며 더 나아가 딥러닝 언어모델에 기반하여 “문맥에 따라 벡터 값이 변하는 동적 벡터”를 활용, 단어 수준을 넘어 문장, 문맥, 최종적으로 텍스트 수준에서 의미가 생성되는 과정을 다차원 벡터 공간에서 정교하게 표현하려 는 시도들이 이어지고 있다. 또한 GPT와 같은 생성형 언어 모델을 인문학 연구와 결 합하기 위해 RAG이나 온톨로지 기반 모델링을 활용하여 특정 분야의 전문 데이터를 추가학습함으로써 특정 도메인에 특화된 지식 생성의 정확도를 향상하려는 시도가 활발하다.저자가 서술하는 데이터과학의 방법론적 변화 과정의 흐름을 따라가다 보면 이는 곧 디지털인문학의 자기 갱신 과정임을 알게 된다. 정적 언어 모델에서부터 동적 언어 모델로의 이행, 초대규모 언어 모델의 인문학적 활용 방식에 대한 모색은 인문학 텍 스트가 지닌 의미적 중층성을 중심에 두고 기술을 비판적으로 사유하는 자세에서 비 롯된 것이다. 기술의 발전 속도가 빠르게 변화하는 가운데 인문학 연구자들이 그 속 도를 앞서거나 발맞춰 따라가는 것은 쉬운 일이 아니다. 오히려 조은경은 인문학연구 자가 기술에 대한 풍부한 감각을 확보하고 분석의 맥락에 따라 기술을 사유하는 능력 이 더 중요하다는 점을 보여주고 있다. 텍스트와 기술 사이의 창조적인 매핑을 모색 하고 이를 통해 해석과 판단이 개입된 지식 생산의 실천으로 나아가는 것이 디지털인 문학, 인문데이터과학이 추구하는 방향성이라는 점을 보여준다.이와 같은 흐름을 따라가며 서평을 쓰는 필자는 추가적으로 데이터셋 구성의 중요성 과 텍스트가 기술, 데이터셋 등을 통해 새롭게 표상됨으로써 열리는 글쓰기의 가능 성, 연구자의 정체성의 변화에 대해 언급하였다. 디지털인문학 연구는 기술과 연구 자, 텍스트와 연구자 등 다양한 차원에서 공동 저작성의 워크플로우를 포함하고 있 다. 또한 기술이 가진 무한한 문장 생성의 가능성을 통해 의미를 끝맺는 기존의 문학 과 예술의 의례에서 이탈하는 글쓰기 양식을 모색할 수 있다. 이 문장들은 때때로 무 의미의 경계를 맴돌 ...","Eunkyung Cho’s Korean Studies and Data Science is a book that offers practical guidance for researchers in Korean literature and culture who wish to engage in digital humanities methodologies by introducing “data-scientific research methods highly useful for language and humanities scholars.” While digital humanities encompass protocols of data analysis, the term is also broadly used to signify a philosophical and cultural shift beyond mere technological application. As a result, many scholarly discussions in this field tend to take on strong discursive tendencies, and at times the technical processes involved are overly simplified. By using the term “data science,” Cho explicitly emphasizes the concrete technologies and procedures necessary for collecting, processing, and analyzing Korean language-based textual data.One of the most active areas of digital humanities research is the analysis of text-based, written materials. Accordingly, this book systematically explains everything “from basic statistical measures for quantitative data analysis to deep learning.” As the proportion of unstructured data increases, traditional descriptive statistics such as mean, standard deviation, and variance are no longer sufficient to explain the complex semantic structures or contextual relationships  embedded  in  data.  This  has  led  to  a  growing  use  of  high- dimensional vector-based metrics. Furthermore, deep learning-based language models now make it possible to express meaning across not only word-level but  also  sentence-level,  context-level,  and  full-text  levels  using  dynamic vectors whose values shift according to context.Efforts are also underway to integrate generative language models such as GPT into humanities research. Techniques such as Retrieval-Augmented Generation (RAG) or ontology-based modeling are actively employed to fine-tune models using domain-specific datasets, thereby enhancing the precision of knowledge generation tailored to particular research areas.As one follows Cho’s account of the methodological evolution in data science, it becomes apparent that this trajectory reflects the digital humanities’ own process of self-renewal. The transition from static to dynamic language models and the exploration of how large-scale language models can be applied to the humanities arise from a critical stance that centers the semantic multilayeredness of humanistic texts. In an era where technological advancements move at a rapid pace, it is difficult for humanities researchers to stay ahead of or even keep up with such developments. Rather than racing to match that pace, Cho argues, what is more crucial is the ability to develop a rich sensibility toward technology and to think critically about it in context. Her book underscores that what digital humanities—and data-driven humanities in particular—ultimately aim for is a practice of knowledge production shaped through creative mapping between text and technology, with interpretation and judgment deeply embedded in the process.Following this trajectory, the reviewer further emphasizes the importance of dataset construction, the new possibilities of writing that open up when texts are re-represented through technology and data structures, and the shifting identity of the researcher. Digital humanities research involves workflows of co-authorship across multiple levels—between technology and researcher, and between text and researcher. Moreover, the infinite capacity of machine- generated text allows for the exploration of new writing styles that deviate from the conventions of closure that dominate traditional literature and art. These texts may sometimes consist of language fragments that hover at the boundaries of meaning, defying established norms. In witnessing the disorder of  language  pieces  that  resist  interpretive  cohesion  and  are  arranged  at random, we begin to sense the opening of a path toward imagining new ..."
인공지능 기법을 이용한 혁신역량과 중소기업 성장 예측연구: 혁신 외부요인이 예측에 미치는 영향 중심으로,2025,"['성장예측', '혁신역량', '정부지원', '정부규제', '개방형혁신', '머신러닝', 'Corporate Growth Prediction', 'Innovation capability', 'Supporting Policies', 'Regulation Policies', 'Open Innovation', 'Machine Learning']","기업은 많은 이유에 의해서 성장하고 발전하기도 하고 역성장을 하기도 한다. 본 연구는 중소기업의 성장을 예측하는 모델을 머신러닝 기법을 이용해서 개발하고 예측 모델 성능을 비교하기 위해 기존 연구를 통해 잘 알려진 영향요인을 내부요인과 외부요인으로 구분하여 어떤 영향을 미치는지 살펴보았다. 과학기술정책연구원에서 조사한 2020년 한국 제조업의 기술혁신조사 자료를 이용해 7가지 머신러닝 알고리즘을 사용해 1차 학습을 진행하였고, 머신러닝 앙상블 기법을 통해 생성한 예측모델을 적용해 실증 분석했다. 분석 결과 머신러닝 기법을 이용해서 기업의 성장을 예측할 때 내부요인이 외부요인보다 더 중요한 변수라는 것으로 나타났다. 기업의 성장에 필요한 요인을 머신러닝을 통해 알아본 결과 기업은 개방형 혁신과 같은 외부요인 뿐만 아니라 내부요인을 관리할 필요성을 제시했다. 또한 투자자에게는 성장하는 기업에 투자할 때 기업의 내부요인이 성장에서 중요한 변수임 제시했다.","Companies grow and develop for a variety of reasons, including reverse growth. In order to develop a model that predicts the growth of SMEs using machine learning techniques and compare the performance of the predictive model, this study examined how well-known influencing factors through existing studies are divided into internal innovation capabilities and external factors. Using the data from the 2020 Korean Innovation Survey surveyed by Science and Technology Policy Institute, the first learning was conducted using seven machine learning algorithms, and the predictive model generated through the machine learning ensemble technique was applied for empirical analysis. As a result of the analysis, it was found that the internal innovation capability is a more important variable than the external factors when predicting a company's growth using machine learning techniques. As a result of examining the factors necessary for a company's growth through machine learning, the company suggested the need to manage internal innovation capabilities as well as external factors such as open innovation. It also suggested to investors that a company's internal innovation capabilities are an important variable in growth when investing in a growing company."
Pixel Transformer: 트랜스포머 기반 JPEG 압축 아티팩트 제거기,2025,"['JPEG 압축 아티팩트 제거 모델', '이미지 후처리', '트랜스포머', '머신러닝', 'JPEG compression artifact removal', 'image processing', 'transformer', 'machine learning']","컴퓨터 비전 분야에서 머신러닝이 적용되기 시작하면서 이미지 데이터의 중요성이 크게 부각되고 있다. 머신러닝 모델의 학습과정에서는 이미지 데이터를 효율적으로 처리하기 위해 JPEG 형식이 사용되지만, JPEG 압축 과정에서 고주파 정보가 손실되어 압축 아티팩트가 발생한다. 이러한 아티팩트는 이미지 품질 저하뿐만 아니라 머신러닝 모델의 성능 저하로도 이어진다. 본 연구에서는 트랜스포머 기반의 JPEG 압축 아티팩트 모델인 Pixel Transformer(PxT)를 제안한다. 기존 모델인 ARCNN, BlockCNN, DnCNN 등 다양한 JPEG 압축 아티팩트 제거 모델 대비 높은 PSNR, LPIPS를 달성하였다. 또한 JPEG 압축 아티팩트 제거가 머신러닝 모델의 성능 개선에 기여하는지 확인한다.","The increasing application of machine learning in computer vision has significantly highlighted the importance of image data. While JPEG format is widely utilized for efficient image data processing during machine learning model training, the JPEG compression process can lead to loss of high-frequency information, resulting in compression artifacts. These artifacts not only degrade image quality but also compromise performance of machine learning models. To address this issue, we propose Pixel Transformer (PxT), a transformer-based model for JPEG compression artifact removal. Compared to various existing JPEG compression artifact removal models including ARCNN, BlockCNN, and DnCNN, PxT achieved superior PSNR and LPIPS scores. Furthermore, this study confirmed that removing JPEG compression artifacts could improve performances of machine learning models."
Impact of Fasting Blood Glucose on Hypertension and Dyslipidemia: A Predictive Modeling Approach,2025,"['Dyslipidemia', 'fasting blood glucose', 'hypertension', 'machine learning', 'predictive modeling']","공복 혈당(FBG)은 대사 건강의 중요한 지표로, 고혈압 및 이상지질혈증과 밀접한 관련이 있다. 본 연구는 공복 혈당과 대사질환 간의 연관성을 분석하고, 머신러닝 기반 예측 모델의 활용 가능성을 평가하고자 하였다. 국민건강보험공단(NHIS)의 건강검진 자료에서 무작위로 4,000명을 추출하였고, 결측값 및 이상치를 제거한 후 최종 1,382명의 데이터를 분석에 활용하였다. 주요 변수로는 FBG, 고혈압, 이상지질혈증, 체질량지수(BMI), 허리둘레, 흡연 여부, 음주 여부 등이 포함되었다. 분석 결과, FBG 수치가 높을수록 고혈압 및 이상지질혈증의 유병률이 유의하게 증가하였다. FBG를 정상, 공복혈당장애, 당뇨병 세 그룹으로 나누었을 때, 대사질환과의 유의한 연관성이 관찰되었다(p<0.001). 머신러닝 기반 분석에서 BMI와 허리둘레가 주요 예측 변수로 나타났으며, 로지스틱 회귀분석 결과 고혈압과 이상지질혈증에 대한 AUC 값은 각각 0.7146, 0.6852로 나타났다. 이러한 결과는 FBG가 혈당 조절뿐 아니라 대사질환의 조기 발견과 예방에도 중요한 역할을 할 수 있음을 시사한다. 또한 FBG를 포함한 다양한 변수들을 활용한 머신러닝 기반 예측이 가능함을 보여주었다. 향후 연구에서는 장기 추적자료를 활용한 인과관계 분석 및 생활 습관 중재의 효과 평가, 그리고 고도화된 머신러닝 기법의 적용을 통해 개인 맞춤형 건강관리 전략 개발이 필요하다.","Fasting blood glucose (FBG) is a crucial marker of metabolic health and is strongly associated with hypertension and dyslipidemia. This study analyzed the relationship between FBG and metabolic diseases and evaluated the predictive performance of machine learning models. A total of 4,000 individuals were randomly selected from the National Health Insurance Service (NHIS) health checkup dataset. After removing missing values and outliers, 1,382 participants were included in the final analysis. The variables considered included FBG, hypertension, dyslipidemia, body mass index (BMI), waist circumference, smoking status, and alcohol consumption. The results demonstrated a significant increase in the prevalence of hypertension and dyslipide mia with higher FBG levels. When FBG was categorized into normal, prediabetes, and diabetes groups, a strong association with metabolic diseases was observed (p<0.001). Machine learning models, including logistic regression, identified BMI and waist circumference as major predictors. The logistic regression model achieved area under the curve (AUC) values of 0.7146 for hypertension and 0.6852 for dyslipidemia. These findings suggest that FBG plays an important role not only in glycemic control but also in predicting the risk of metabolic diseases. Machine learning approaches using FBG and related factors showed promise for early detection. Future research should incorporate longitudinal data to explore causal relationships and assess the impact of lifestyle interventions. Improving predictive models through advanced machine learning techniques may aid in developing personalized strategies for the metabolic disease prevention and management of metabolic diseases."
일반대학 재학생의 대학몰입 및 학과몰입 영향요인에  대한 탐색적 논의,2025,"['대학몰입', '전공몰입', '대학교육 혁신', '교수학습의 질', '머신러닝', '랜덤포레스트', '대학의 교수· 학습 및 혁신에 관한 조사', 'College Engagement', 'Major Engagement', 'Higher Education Innovation', 'Quality of Teaching and Learning', 'Machine Learning', 'Random Forest', 'National Assessment of Student Engagement in Learning-Innovation(N']","본 연구의 목적은 일반대학 재학생의 대학몰입과 학과몰입에 영향을 미치는 주요 변인을 파악하고, 이를 토대로 국내 대학의 교수학습 혁신에 필요한 정책적 시사점을 제안하는 것이다. 이를 위해 한국교 육개발원이 전국 87개 일반대학 재학생을 대상으로 실시한 ‘2024 대학의 교수‧학습 혁신에 관한 학생 조사(National Assessment of Student Engagement in Learning and Innovation: NASEL-i)’ 데이터를 활용하여, 머신러닝 기법 중 하나인 랜덤포레스트(Random Forest) 방법으로 대학몰입과 학과몰입에 대한 예측력을 검증하였다. 분석을 위해 대학 특성, 개인 특성, 교과‧비교과 및 교외활동 경험, 교육혁신 등 4개 차원의 50개 설명변수를 선정하였다. 주요 분석결과, ‘본부‧교수 혁신 수준’과 ‘교육과정 혁신 수준’이 가장 높은 중요도를 보였으며, 동료와 의 상호작용, 전공수업 만족도, 학생지원서비스 만족도 등 교수학습 및 지원체계 관련 변인들도 대학몰 입과 학과몰입에 유의미한 영향을 미쳤다. 또한 능동적‧협력적‧도전적 학습경험, 개인의 학업성취도 (GPA), 교원 1인당 학생 수도 핵심 예측변수로 확인되었다. 이상의 결과는 대학 차원의 체계적‧적극적 인 교육혁신 노력이 재학생의 대학 및 학과 몰입도 제고에 실질적으로 기여함을 시사한다. 정책제언으 로서 대학 교육혁신의 지속적 홍보와 학생체감도 제고, 학생참여형 수업 활성화, 학생지원서비스의 질 적 강화, 전공 교과 혁신 프로그램 확대 등을 핵심 과제로 제안했다.","This study aims to explore the key factors influencing college engagement and derive policy implications for teaching and learning innovation in Korean universities. To achieve this, we utilized data from the ‘NASEL-i (National Assessment of Student Engagement in Learning) 2024’ survey, conducted by the Korea Educational Development Institute. The analysis employed the random forest algorithm, a machine learning technique, with college engagement as the dependent variable and 50 independent variables across personal, institutional, and instructional innovation dimensions.The results indicate that the level of innovation and efforts in the curriculum were the most important factors in predicting college engagement. Additionally, peer interactions, satisfaction with major courses, and student support services were identified as significant factors. Active learning, collaborative  learning,  and  challenge-based  learning  also  had  a  meaningful  impact  on  college engagement. Among personal variables, academic performance (GPA) was the most influential, while the student-to-faculty ratio emerged as a key institutional factor.Based on these findings, this study proposes continuous promotion and enhancement of student perceptions   of   educational   innovation,   activation   of   student-centered   classes,   qualitative improvements in student support services, and the expansion of innovative programs in major courses."
Impact of Fasting Blood Glucose on Hypertension and Dyslipidemia: A Predictive Modeling Approach,2025,"['Dyslipidemia', 'fasting blood glucose', 'hypertension', 'machine learning', 'predictive modeling']","공복 혈당(FBG)은 대사 건강의 중요한 지표로, 고혈압 및 이상지질혈증과 밀접한 관련이 있다. 본 연구는 공복 혈당과 대사질환 간의 연관성을 분석하고, 머신러닝 기반 예측 모델의 활용 가능성을 평가하고자 하였다. 국민건강보험공단(NHIS)의 건강검진 자료에서 무작위로 4,000명을 추출하였고, 결측값 및 이상치를 제거한 후 최종 1,382명의 데이터를 분석에 활용하였다. 주요 변수로는 FBG, 고혈압, 이상지질혈증, 체질량지수(BMI), 허리둘레, 흡연 여부, 음주 여부 등이 포함되었다. 분석 결과, FBG 수치가 높을수록 고혈압 및 이상지질혈증의 유병률이 유의하게 증가하였다. FBG를 정상, 공복혈당장애, 당뇨병 세 그룹으로 나누었을 때, 대사질환과의 유의한 연관성이 관찰되었다(p<0.001). 머신러닝 기반 분석에서 BMI와 허리둘레가 주요 예측 변수로 나타났으며, 로지스틱 회귀분석 결과 고혈압과 이상지질혈증에 대한 AUC 값은 각각 0.7146, 0.6852로 나타났다. 이러한 결과는 FBG가 혈당 조절뿐 아니라 대사질환의 조기 발견과 예방에도 중요한 역할을 할 수 있음을 시사한다. 또한 FBG를 포함한 다양한 변수들을 활용한 머신러닝 기반 예측이 가능함을 보여주었다. 향후 연구에서는 장기 추적자료를 활용한 인과관계 분석 및 생활 습관 중재의 효과 평가, 그리고 고도화된 머신러닝 기법의 적용을 통해 개인 맞춤형 건강관리 전략 개발이 필요하다.","Fasting blood glucose (FBG) is a crucial marker of metabolic health and is strongly associated with hypertension and dyslipidemia. This study analyzed the relationship between FBG and metabolic diseases and evaluated the predictive performance of machine learning models. A total of 4,000 individuals were randomly selected from the National Health Insurance Service (NHIS) health checkup dataset. After removing missing values and outliers, 1,382 participants were included in the final analysis. The variables considered included FBG, hypertension, dyslipidemia, body mass index (BMI), waist circumference, smoking status, and alcohol consumption. The results demonstrated a significant increase in the prevalence of hypertension and dyslipidemia with higher FBG levels. When FBG was categorized into normal, prediabetes, and diabetes groups, a strong association with metabolic diseases was observed (p<0.001). Machine learning models, including logistic regression, identified BMI and waist circumference as major predictors. The logistic regression model achieved area under the curve (AUC) values of 0.7146 for hypertension and 0.6852 for dyslipidemia. These findings suggest that FBG plays an important role not only in glycemic control but also in predicting the risk of metabolic diseases. Machine learning approaches using FBG and related factors showed promise for early detection. Future research should incorporate longitudinal data to explore causal relationships and assess the impact of lifestyle interventions. Improving predictive models through advanced machine learning techniques may aid in developing personalized strategies for the metabolic disease prevention and management of metabolic diseases."
인공지능(AI)기술과 의약품에 관한 규제동향에 관한 연구- 주요국가의 의약품 제조․공정 분야 인공지능(AI) 활용을 중심으로 -,2025,"['인공지능(Artificial intelligence)', '의료제품(medical products)', '의약품제조․공정(drug manufacturing and processing)', '의료제품 규제(medical products regulation)', '디지털 치료제(digital therapeutics)']","국문초록오늘날 인공지능(Artificial Intelligence, AI)이 산업 및 사회 전 분야에서 급속도로 도입 및 확산되고 있다. 인공지능(AI)은 혁신기술로서 4차산업혁명을 이끌 핵심동력이다. 동시에 인공지능(AI) 기술의 윤리적 개발 및 활용 역시 핵심 관심 대상으로 인공지능(AI) 기술 발전과 더불어 고려되고 있다.최근 유럽연합(EU)에서 인공지능(AI) 관련 기술 허용 범위와 규제 대상 등을 규정류지웅, “인공지능(AI)로봇의 법적 문제에 관한 연구 - EU의 RoboLaw의 입법동향을 중심으로 -”, 토지공법연구 제78집, 한국토지공법학회, 2017, 1-26면.한 세계 최초 인공지능 규제법인「AI법(AI act) 시행을 최종확정하였다(2024년 5월 21일, 본격 시행은 2026년부터) 또한 미국에서는 안전하고 보안이 보장되며 신뢰할 수 있는 인공지능(AI)개발 및 사용에 대한 AI 행정명령을 2023년 10월 30일 내리는 등 세계 주요국들은 인공지능 기술 및 산업 활성화와 동시에 인공지능(AI)의 합리적인 규제 프레임을 마련하기 위해 노력중이다.현재 의약품 개발 및 제조․공정분야에서 인공지능(AI)기술 활용 사례도 증가하는 추세이다. 미국 식품의약품안전국(Food and Drug ADministration, 이하 “FDA”라 함)는 인공지능(AI)/기계학습(Machine Learning, ML) 사용 의약품 개발에 대한 보고서 초안을 2023년 5월 발표하였고, 유럽의약품청(European Medicines Agency, 이하 “EMA”라 함)에서는 의약품 전주기 단계에서 인공지능(AI)/기계학습(ML) 사용원칙에 대한 의견서 초안을 2023년 7월 발표하는 등 의약품 개발 시 인공지능 활용에 대한 기준을 제시하였다.의약품의 개발 및 제조·공정 단계에서 인공지능(AI)기술의 활용은 코로나 19를 통해 새롭게 등장하는 질병 또는 현재 인류가 극복하고 있지 못한 희귀질환 및 장애 등을 해결할 수 있을 것으로 예측되고 있다.의약품 분야에서 활용되는 인공지능(AI)/기계학습(ML)은 데이터를 기반으로 과학적 근거를 도출할 수 있지만, 본질적으로 데이터 중심으로 결과를 예측하므로 특히 비뚤림(bias) 가능성 및 신뢰성에 있어 주의의야 한다. 환자의 안전과 데이터 완전성(integrity), 개인정보보호 등 안전장치도 필요하다. 또한 인공지능(AI)기술은 다양한 형태로 활용되어 구현되므로 핵심 원칙을 제시하고 상황별로 원칙을 현실에 맞게 적용할 필요가 있다.우리나라의 경우 식품의약품안전처에서 의약품 개발시 인공지능(AI)/기계학습(ML) 활용 분야 및 데이터․인공지능(AI) 기술 관련 규제적용을 위하여 기술적, 윤리적 측면에 있어 고려해야 할 사항을 제공하기 위해 안내서 및 각 종 정책적 방법으로 의약품 제조기업 등에게 인공지능(AI)기술의 도입을 위해 노력하고 있지만, 현실적인 한계 그 중 규제의 불분명성, 데이터관리, 전문가 부족 등의 문제가 존재한다.이를 위해 본 연구에서는 첫째, 의약품 주요 단계별 인공지능(AI)/기계학습(ML) 활용범위를 검토하고, 둘째, 해외 주요국가 미국, 유럽, 일본 등의 의약품 개발 및 제조·공정에서 인공지능(AI)기술의 활용 및 규제 동향을 분석하고 셋째, 우리나라의 인공지능(AI)을 활용한 의약품 개발 및 생산 등에서 발생하는 법제도적 문제를 살펴보는 것을 연구의 내용으로 한다.","Abstract Today, artificial intelligence (AI) is rapidly being introduced and spread in all industrial and social fields. Artificial intelligence (AI) is an innovative technology and is a key driving force that will lead the Fourth Industrial Revolution. At the same time, the ethical development and use of artificial intelligence (AI) technology is also being considered along with the development of artificial intelligence (AI) technology as a core object of interest.Recently, in the European Union (EU), Ryu Ji-woong stipulates the scope of artificial intelligence (AI)-related technologies and regulatory targets, ""A Study on the Legal Problems of Artificial Intelligence (AI) RoboLaw - Focusing on the Legislative Trends of RoboLaw in the EU,"" Land Construction Research No. 78, Korean Society of Land Construction, 2017, pp. 1-26.The implementation of the AI Act (AI Act), the world's first artificial intelligence regulation law, has been finalized (May 21, 2024, full-scale enforcement will begin in 2026) In addition, major countries around the world are working to establish a reasonable regulatory framework for artificial intelligence (AI) while revitalizing artificial intelligence technology and industry, such as issuing an AI executive order for the development and use of safe, secure, and reliable artificial intelligence (AI) on October 30, 2023.Currently, cases of using artificial intelligence (AI) technology in the field of drug development, manufacturing, and processing are also on the rise. The Food and Drug Administration (FDA) of the United States released a draft report on the development of drugs using artificial intelligence (AI)/machine learning (ML) in May 2023, and the European Medicines Agency (EMA) presented standards for the use of artificial intelligence (AI)/machine learning (ML) in the pre-drug stage.The use of artificial intelligence (AI) technology in the development, manufacturing, and process stages of pharmaceuticals is expected to solve emerging diseases or rare diseases and disorders that humans are not currently overcoming through COVID-19.Artificial intelligence (AI)/machine learning (ML) used in the pharmaceutical field can derive scientific evidence based on data, but care must be taken in the possibility and reliability of bias because it essentially predicts results based on data. Safety devices such as patient safety, data integrity, and personal information protection are also required. In addition, since artificial intelligence (AI) technology is used and implemented in various forms, it is necessary to present core principles and apply the principles in each situation according to reality.In Korea, the Ministry of Food and Drug Safety is working to introduce artificial intelligence (AI) technology to drug manufacturers and others in various policy ways to provide technical and ethical considerations for the application of regulations related to artificial intelligence (AI)/machine learning (ML) and data and artificial intelligence (AI) technology when developing drugs, but among the practical limitations, problems such as unclear regulation, data management, and lack of experts exist.To this end, this study first examines the scope of artificial intelligence (AI)/machine learning (ML) use by major stages of pharmaceuticals, second, analyzes the use and regulatory trends of artificial intelligence (AI) technology in drug development, manufacturing, and processing in major overseas countries such as the United States, Europe, and Japan, and third, examines legal and institutional problems arising from drug development and production using artificial intelligence (AI) in Korea."
웨이퍼 레벨 패키지 신뢰성 수명 예측을 위한 인공지능 기술 연구동향,2025,"['Machine learning algorithms', 'Reliability life prediction', 'Supervised learning', 'Unsupervised learning', 'Hybrid learning', 'Advanced packaging', '.']",,"Advanced packaging technologies are rapidly evolving to meet the semiconductor industry’s increasing demands for higher performance, miniaturization, and lower power consumption. Among these technologies, wafer-level packaging (WLP) has emerged as a key solution due to its superior capability in achieving compactness and enhanced performance. However, predicting the reliability life of WLP remains a significant challenge due to its complex structure and various environmental factors. Traditional reliability life prediction methods, such as physicsbased modeling and accelerated life testing, are limited by high costs and long time requirements. To address these limitations, artificial intelligence (AI), particularly machine learning (ML) algorithms, have gained significant attention. This study discusses recent trends in ML algorithms for reliability life prediction in advanced packaging, focusing on unsupervised learning, supervised learning, and hybrid learning approaches. Additionally, the paper provides insights into potential future research directions."
다중에이전트 강화학습 기반 복근보 자동설계 모델 개발,2025,"['Keywords : Reinforced learning', 'Multi-agents', 'Automated structural design', 'Doubly reinforced beam', 'Double Q-Learning']",,"Reinforcement learning (RL) is successfully applied to various engineering fields. RL is generally used for structural control cases to develop the control algorithms. On the other hand, a machine learning (ML) is adopted in various research to make automated structural design model for reinforced concrete (RC) beam members. In this case, ML models are developed to produce results that are as similar to those of training data as possible. The ML model developed in this way is difficult to produce better results than the training data. However, in reinforcement learning, an agent learns to make decisions by interacting with an environment. Therefore, the RL agent can find better design solution than the training data. In the structural design process (environment), the action of RL agent represent design variables of RC beam. Because the number of design variables of RC beam section is many, multi-agent DQN (Deep Q-Network) was used in this study to effectively find the optimal design solution. Among various versions of DQN, Double Q-Learning (DDQN) that not only improves accuracy in estimating the action-values but also improves the policy learned was used in this study. American Concrete Institute (318) was selected as the design codes for optimal structural design of RC beam and it was used to train the RL model without any hand-labeled dataset. Six agents of DDQN provides actions for beam with, beam depth, bottom rebar size, number of bottom rebar, top rebar size, and shear stirrup size, respectively. Six agents of DDQN were trained for 5,000 episodes and the performance of the multi-agent of DDQN was evaluated with 100 test design cases that is not used for training. Based on this study, it can be seen that the multi-agent RL algorithm can provide successfully structural design results of doubly reinforced beam."
H-T-P(집-나무-사람)그림 특성과 유・아동정서행동 변인 및 부모의 양육태도 간 연관성: 만 5세 아동을 중심으로,2025,"['기계학습(ML: Machine Learning)', 'HTP 투사그림', '부모양육태도(PAT)', 'K-CBCL', 'Machine Learning (ML)', 'H-T-P Projective Drawing', 'Parenting Attitude Test (PAT)', 'K-CBCL']","본 연구는 만 5세 전·후 아동 193명과 그 부모를 대상으로 하여, 아동이 그린 HTP그림과 그 아동의 부모가 평가한 K-CBCL척도 및 PAT척도 간의 연관성을 규명하기 위한 것이다. 스마트폰을 통해 그림 자료를 수집하여, 기계학습(ML) 장치가 총 80개 항목에 대해서 평가하였다. K-CBCL과 PAT 검사의 각 척도 값은 기존 전산처리시스템에서 자동처리 된다. 수집된 자료는 HTP 평가지표를 독립변수로 하고 K-CBCL 12개 척도 및 PAT 8개 척도를 종속변수로 하여 다변량분석을 실시하였다. 본 연구의 결과는 다음과 같다. 첫째, 집 그림에 대한 평가지표는 K-CBCL의 3개 영역(‘벽 크기’, ‘굴뚝’, ‘연못’), PAT의 4개 영역(‘창문’, ‘굴뚝’, ‘울타리’, ‘연못’)에서 통계적 차이를 보였다. 둘째, 나무 그림에 대한 평가지표는 K-CBCL의 3개 영역(‘수관’, ‘가지’, ‘뿌리’), PAT의 4개 영역(‘나무기둥 굵기’, ‘수관크기’, ‘뿌리’, ‘나뭇잎’)에서 통계적 차이를 보였다. 셋째, 사람 그림에 대한 평가지표는 K-CBCL의 4개 영역(‘남자 귀’, ‘남자 단추’, ‘여자 손’, ‘여자 주머니’), PAT의 6개 영역(‘남자 코’, ‘여자 코’, ‘남자 귀’, ‘여자 귀’, ‘남자 발’, ‘여자 발’)에서 통계적 차이를 보였다. 본 연구를 통하여 인공지능 기능을 탑재한 기계학습(ML) 장치가 심리진단에서 사전 스크리닝의 목적으로 사용 될 수 있을 가능성을 높여 줄 수 있을 것 같다.","This study investigated the associations between H-T-P drawings produced by five-year-old children and the K-CBCL (Korean Child Behavior Checklist) and PAT (Parenting Attitude Test) scales evaluated by their parents. Data were collected via smartphone, and a machine learning (ML) device assessed a total of 80 items from the drawings. The scale scores from the K-CBCL and PAT were automatically processed using an existing computerized system. Multivariate analyses were conducted with the H-T-P evaluation indicators as independent variables and the 12 K-CBCL subscales and 8 PAT subscales as dependent variables. The results were as follows. First, evaluation indicators related to house drawings showed significant differences in three K-CBCL areas (""wall size,"" ""chimney,"" ""pond"") and four PAT areas (""window,"" ""chimney,"" ""fence,"" ""pond""). Second, evaluation indicators related to tree drawings demonstrated significant differences in three K-CBCL areas (""crown,"" ""branches,"" ""roots"") and four PAT areas (""trunk thickness,"" ""crown size,"" ""roots,"" ""leaves""). Third, evaluation indicators related to person drawings revealed significant differences in four K-CBCL areas (""male ear,"" ""male button,"" ""female hand,"" ""female pocket"") and six PAT areas (""male nose,"" ""female nose,"" ""male ear,"" ""female ear,"" ""male foot,"" ""female foot""). These findings suggest that machine learning (ML) devices equipped with artificial intelligence capabilities have potential for use in preliminary psychological screening."
인공지능 기반 기업의 성장률 예측모델 개발,2025,"['기업 성장률', '머신러닝', '딥러닝', '인공지능', 'RNN', 'LSTM', 'GRU', 'GBM', 'CatBoost', 'Corporate Growth Rate', 'Machine Learning', 'Deep Learning', 'Artificial Intelligence', 'RNN', 'LSTM', 'GRU', 'GBM', 'CatBoost']","본 연구는 인공지능 기반 머신러닝 및 딥러닝 기법을 활용하여 기업 성장률 예측의 정확성을 향상시키는 모델을개발하고자 하였다. 기존의 통계적 및 회귀적 예측 모델들이 기업 성장률에 영향을 미치는 비선형적 상호작용과 외부충격을 충분히 반영하지 못하는 한계를 해결하기 위해, 본 연구는 RNN, LSTM, GRU, GBM, CatBoost과 같은 다양한회귀 모델을 적용하여 이들 간 예측 성능을 비교 분석하였다. 실증 분석 결과, GRU와 LSTM 등 순환 신경망 기반 모델이 기업 성장률 예측에 있어 우수한 성능을 보임을 확인할 수 있었다. 특히, GRU 모델은 MSE, RMSE, MSLE, MAPE와같은 다양한 평가 지표에서 가장 낮은 오차 값을 기록하여 시계열 데이터 학습에 강점을 보였으며, LSTM 모델 또한장기적 종속성 학습에서 높은 성능을 보여 GRU 다음으로 뛰어난 결과를 나타냈다. 반면, GBM과 CatBoost와 같은앙상블 모델은 일반적 예측에서는 안정적인 성능을 제공하였으나, 시계열 데이터의 복잡한 패턴을 학습하는데 있어서는순환 신경망 모델에 비해 성능이 제한적임이 확인되었다. 본 연구는 순환 신경망 모델이 기업 성장률 예측에 있어 높은예측 성능을 제공할 수 있음을 입증하였으며, 이러한 모델들이 경제적 시계열 데이터 분석에 효과적으로 활용될 가능성을 제시한다. 본 연구의 결과는 기업 성장률 예측뿐만 아니라 다양한 경제적 시계열 데이터를 분석하는 데 있어 인공지능 기법의 유용성을 강조하며, 향후 연구와 실무에서의 전략적 활용에 중요한 시사점을 제공한다.","This study attempted to develop a model that improves the accuracy of corporate growth prediction by utilizing artificial intelligence-based machine learning and deep learning techniques. To solve the limitation that the existing statistical and regression prediction models do not sufficiently reflect the nonlinear interaction and external shocks that affect the corporate growth rate, this study compared and analyzed the prediction performance between them by applying various regression models such as RNN, LSTM, GRU, GBM, and CatBoost. As a result of the empirical analysis, it was confirmed that the recurrent neural network-based models, such as GRU and LSTM, showed excellent performance in predicting the corporate growth rate. In particular, the GRU model recorded the lowest error value in various evaluation indicators such as MSE, RMSE, MSLE, and MAPE, showing strength in time series data learning, and the LSTM model also showed high performance in long-term dependency learning, showing excellent results after GRU. On the other hand, ensemble models such as GBM and CatBoost provided stable performance in general prediction. Still, it was confirmed that the performance was limited compared to the recurrent neural network model in learning the complex patterns of time series data. This study demonstrates that recurrent neural network models can provide high predictive performance in predicting corporate growth rates. It suggests that these models can be effectively used for economic time series data analysis. The results of this study emphasize the usefulness of artificial intelligence techniques in analyzing various economic time series data and predicting corporate growth rates and provide important implications for strategic use in future research and practice."
Transformer-based Autoencoder와 FDD 손실 함수를 활용한 전류 센서의 비지도 학습 기반 이상 탐지,2025,"['Anomaly Detection', 'Unsupervised Learning', 'Autoencoder', 'Transformer', 'Current Sensor', '이상 탐지', '비지도 학습', '오토인코더', '트랜스포머', '전류 센서']",,"Anomaly detection in current sensors plays a crucial role in maintaining efficient operations and preventing catastrophic failures across various industries. Data obtained from current sensors is used to monitor the condition of machinery in real-time and to detect anomalies at an early stage. Compared to traditional machine learning and sensor processing methods, deep learning techniques offer superior adaptability and powerful data representation learning capabilities by learning complex patterns in the data. However, research on anomaly detection using deep learning for current sensors faces several challenges, including the difficulty of data labeling, high computational costs, and model generalization issues. In particular, obtaining labeled data in practical environments is often challenging and costly, highlighting the need for unsupervised learning methods. To address these issues, we propose an unsupervised anomaly detection method for current sensor data using a Transformer-based Autoencoder. The proposed method effectively learns the temporal characteristics of current sensor data, improving the ability to distinguish between normal and abnormal states. Specifically, this study introduces the Fused Directional Distance (FDD) loss function, which considers both the distance and angle differences between data points instead of the commonly used reconstruction error for threshold setting. The FDD loss function effectively suppresses the influence of noise and enhances the robustness of the model. We apply the proposed method to real current sensor data from AI Hub's 'machinery facility failure prediction sensors' dataset. Experimental results demonstrate that the proposed model achieves superior anomaly detection performance compared to existing methods and confirms its applicability in various industrial environments. Notably, the unsupervised learning approach enables effective anomaly detection even with unlabeled data, showcasing the method's practicality. This study presents a novel approach to unsupervised anomaly detection using current sensor data, providing a foundation for future research in this field. Additionally, this research is expected to expand the application scope of current sensor data and contribute to solving practical problems in industrial settings."
설명가능한 인공지능을 활용한 생명보험 리스크 예측,2025,"['life insurance risk', 'machine learning', 'deep neural network', 'explainable artificial intelligence', '리스크', '머신러닝', '딥뉴럴 네트워크', '설명가능한 인공지능']","생명보험에서 피보험자의 위험 수준을 예측하는 것은 적정한 보험료를 결정하는 매우 중요한 작업이다. 최근 머신러닝을 활용한 연구들을 통해 위험 수준에 대한 예측의 정확도를 높여 왔다. 본 연구에서는 Kaggle에 있는 푸르덴셜의 생명보험 익명화된 신청자의 정보와 회사의 위험 수준 데이터를 사용하였다. 그리고 랜덤 포레스트, XGboost, 로지스틱 회귀분석 등 머신러닝 방법뿐 아니라 딥뉴럴 네트워크 방법을 추가하여 리스크를 예측하고 그 정확도를 비교하였다. 또한 리스크 예측을 넘어서 머신러닝의 importance, 설명가능한 인공지능의 LIME과 SHAP를 사용하여서 보험 신청자들이 어떠한 요인으로 인해 위험 수준이 결정되었는지 살펴보았다. 사용된 모형 가운데 딥뉴럴네트워크 방법이 정확도가 가장 높게 나왔으며, 생명보험 리스크에 주로 영향을 주는 변수가 체질량 지수, 체중, 그리고 특정 병력이며 그 변수들이 위험 수준의 방향을 어떻게 결정하는지 확인하고 설명할 수 있다.","Predicting the risk level of insurance applicants in life insurance is a critical task for determining premiums and ensuring the stability of the insurance company. Recent studies utilizing machine learning have improved the accuracy of risk prediction. This paper used anonymized applicant information from Prudential available on Kaggle. We employed various machine learning methods, including Random Forest, XGBoost, and logistic regression, as well as deep neural networks, to predict risk and compare their accuracy. We also examined the factors determining the risk level of insurance applicants using the importance of machine learning and explainable artificial intelligence techniques like LIME and SHAP. Among the models used, the deep neural network method yielded the highest accuracy. We identified that the main variables influencing life insurance risk are body mass index, weight, and specific medical history, as well as how these variables determine the direction of risk levels."
설명가능한 인공지능 알고리즘을 이용한 노인의 자살 생각 예측,2025,"['설명가능한 인공지능', '노인 자살 생각', '자살생각 예측', '자살 생각 영향 요인', '자살 예방', 'explainable artificial intelligence', 'old adults suicidal ideation', 'suicidal ideation prediction', 'factors influencing suicidal ideation', 'suicide prevention']","본 연구는 빅데이터를 설명가능한 인공지능의 머신러닝 모델링을 통해 어떠한 특성을 지닌 노인이 자살을 생각하는지 예측함과 더불어 기존의 자살에 미치는 요인에 대한 탐 색을 확장하고자 하였다. 머신러닝과 딥러닝에 대한 6개의 알고리즘으로 예측 성능 지표 를 확인한 결과, Accuracy를 기준으로는 LGBM이 98.74% 예측력을, Precision을 기준 으로는 Random Forest를 통해 99.79%로 가장 성능이 높게 나타났다. 100명 중 자살 생각을 하는 99명 이상의 노인을 예측할 수 있다는 것을 의미한다. 머신러닝 및 딥러닝 알고리즘의 전체적인 기여뿐만 아니라 개개인 맞춤 영향 요인을 별도로 분석할 수 있는 장점이 있는 SHAP 모델을 활용하여, 어떠한 특성이 노인의 자살생각에 영향을 주는지 확인하였다. 마음이 슬퍼질수록, 파트너 관계 내 폭력을 경험할수록, 현재 흡연할수록, 잠을 설치거나, 지난 1년간 의료기관을 이용한 외래 진료 횟수가 많아지거나, 가족원 간 침착하게 문제를 논의하는 경우가 줄어들거나, 식욕이 없는 일이 빈번해지거나, 가족 수 입에 대한 만족도가 낮아지거나, 나이가 많아질수록, 식료품비 비용이 줄어들수록 자살 생각에 영향을 주는 것으로 파악되었다. 기존 연구에서 검증된 자살생각에 영향을 주는 인구사회학적, 경제적, 사회적, 건강 관련 영역 내 더 구체적인 하위 변인들을 확인할 수 있었다. 본 연구 결과를 통해, 지난 10년간 수집된 한국복지패널 빅데이터에서 설명 가능한 인공지능 알고리즘을 활용하여 개별 노인 자살 생각의 예측 변인을 도출함으로 써 사전에 자살을 예방할 수 있는 실용적인 정보를 제공하고자 하였다.","This study aims to leverage machine learning models within artificial intelligence to predict the characteristics of older adults that contribute to suicidal ideation through big data analysis. Furthermore, it seeks to expand the existing body of research on factors influencing suicidal thoughts. To achieve this objective, the study evaluated the predictive performance of six machine learning and deep learning algorithms. The findings indicate that the LightGBM (LGBM) algorithm demonstrated the highest predictive accuracy, achieving 98.74%, while precision was maximized at 99.79% when combined with the Random Forest algorithm. These results suggest that LGBM can accurately identify suicidal ideation in more than 99 out of 100 older adults. To further interpret the model's predictions, this study employed the SHAP (SHapley Additive exPlanations) model, which offers the advantage of analyzing both individualized and overall contributing factors within machine learning and deep learning frameworks. The analysis identified key variables associated with suicidal ideation in later life, including heightened levels of sadness, exposure to partner violence, current smoking status, sleep disturbances, outpatient visits to medical services within the past year, decreased meaningful discussions within the family, frequent loss of appetite, lower satisfaction with family income, advanced age, and reduced grocery expenditures. By utilizing the complete dataset from the Korean Welfare Panel spanning the past decade, this study applied explainable AI algorithms to specify demographic, economic, social, and health-related factors influencing suicidal ideation. The findings provide practical information for targeted suicide prevention strategies."
앙상블 기법을 이용한 한국어 단문 분류성능 향상에 관한 연구,2025,"['Short Text Classification', 'Logistic Regression', 'Support Vector Machine', 'Random Forest', 'XGBoost', 'LSTM', 'BERT', 'Ensemble Technique', '단문 분류', '로지스틱 회귀', 'Support Vector Machine', 'Random Forest', 'XGBoost', 'LSTM', 'BERT', '앙상블 기법']","현대 사회에서는 짧은 길이의 문장으로 이루어진 문서가 증가하고 있어, 이를 효과적으로 관리하고자 카테고리별로 분류하는 작업이 중요한 과제로 부각 되고 있으며, 이에 따라 효율적이고 성능이 좋은 분류시스템의 필요성이 대두되고 있다. 본 연구에서는 기존에 발표된 연구에서 주로 대상으로 삼았던 문서들보다 훨씬 짧은 길이의 1∼2문장으로 구성된 문서를 대상으로 하며, 이러한 문서들은 다양한 주제와 형식으로 구성되어 있다. 이러한 문서들은 문맥의 부족, 데이터 불균형 등의 특성이 있기에 발생하는 분류의 어려움이 존재한다. 따라서 해당 특성을 고려하여 다양한 기계학습 알고리즘을 조사하고, 다양한 기계학습 알고리즘에 대한 학습을 진행하여 분류성능을 비교한다. 본 연구에서는 로지스틱 회귀, Support Vector Machine, Random Forest, XGBoost, LSTM, BERT 기법을 사용하였다. 이후 분류성능이 뛰어난 알고리즘을 바탕으로 앙상블 기법을 적용하여 단문 분류에서의 정확도를 5∼6% 향상했다.","In modern society, the number of documents composed of short sentences is increasing, and classifying them by category is emerging as an important task to effectively manage them, and the need for an efficient and high-performance classification system is emerging. This study targets much shorter documents than those that were mainly targeted in previously published studies, and these documents are composed of various topics and formats. These documents have difficulty in classification because they have characteristics such as lack of context and data imbalance. Therefore, various machine learning algorithms are investigated in consideration of their characteristics, and the classification performance is compared by learning about various machine learning algorithms. Logistic Regression, Support Vector Machine, Random Forest, XGBoost, LSTM and BERT techniques were used in this study. Afterwards, the accuracy in short text classification was improved by 5-6% by applying the ensemble technique based on an algorithm with excellent classification performance."
아동 학대 요인 파악 및 예측 모델 개발: 혼합 방법론적 접근,2025,"['아동 학대', '혼합 방법론', '계량경제모델', '머신러닝', '예측 모델', 'child maltreatment', 'mixed method', 'econometric model', 'machine learning', 'prediction mode']","아동 학대에 효과적으로 대응하기 위해 본 연구는 다각적인 이론적 분석을 통해 학대 위험 요인을 도출하고, 학대 의심 확률 예측 모델을 개발한다. 구체적으로 생태체계 이론과 일상 행위 이론을 바탕으로 아동 학대 요인을 도출하여 계량 경제 분석을 수행한 후, 머신러닝 예측 모델을 개발하였다. 이를 위해 2014년부터 2017년까지 한국 아동 청소년 패널 조사 데이터에서 1,903명의 한국 아동 데이터를 활용하였다. 선형 확률 회귀분석 결과, 아동의 우울, 자아 탄력성, 행동 통제, 휴대폰 의존도 증가는 학대 경험 가능성을 높이는 것으로 나타났다. 반면, 자아존중감, 삶의 만족도, 부모의 양육 태도는 긍정적일수록 학대 경험 가능성을 낮추는 것으로 나타났다. XGBoost 기반 머신러닝 예측 모델의 경우 92.92% 정확도를 보였다. 본 연구는 혼합 방법론을 통해 요인 탐색 결과와 예측 모델 결과를 비교하여 설명 가능한 머신러닝 예측 시스템을 구현하였으며, 기존에 고려되지 않은 변수를 포함하고, 계량 경제 모형과 예측 모델링을 융합하여 학술적 의의를 가진다. 또한, 학대 의심 아동 판별 시스템 구축에 기여하고, 아동 복지 정책 방향성을 제시할 수 있다.","To effectively address child maltreatment, this study aims to identify risk factors through multi-faceted theoretical analysis and develop a predictive model for the probability of suspected abuse. Specifically, we derived child maltreatment factors based on ecological systems theory and routine activity theory, conducted econometric analysis, and subsequently developed a machine learning prediction model. For this purpose, we utilized data from 1,903 Korean children from the Korea Children and Youth Panel Survey(KCYPS) spanning from 2014 to 2017. The linear probability regression analysis revealed that increased levels of child depression, ego-resilience, behavioral control, and mobile phone dependency heightened the likelihood of experiencing abuse. Conversely, higher levels of self-esteem, life satisfaction, and positive parental attitudes were associated with a decreased probability of abuse. The XGBoost-based machine learning prediction model demonstrated an accuracy of 92.92%. This study implemented an explainable machine learning prediction system by comparing factor exploration results and prediction model outcomes through a mixed methodology. It holds academic significance by incorporating previously unconsidered variables and integrating econometric modeling with predictive modeling. Furthermore, it contributes to the development of a child maltreatment suspicion identification system and offers insights for child welfare policy directions."
특징선택을 통한 트랜스포머 기반 단기 가뭄 예측,2025,"['단기 가뭄 예측', '딥러닝', '기계학습', '특징선택', 'Short-term Drought Prediction', 'Deep Learning', 'Machine Learning', 'Feature Selection']","과거부터 단기 가뭄 예측을 위한 많은 연구가 있어 왔다. 과거에는 수치 모델링을 이용한 연구가 주를 이뤘지만, 예측 정확성의 한계로 최근에는인공지능 기술을 활용한 연구가 활성화되고 있다. 초기에는 단일 모델을 활용한 기계학습과 다층 퍼셉트론을 사용한 가뭄 예측 연구가 진행되었고,이후 앙상블 기법을 활용한 기계학습과 딥러닝 알고리즘들을 사용한 연구가 진행되었다. 최근에는 우수한 성능을 보이는 트랜스포머 기반의 딥러닝알고리즘이 각광받고 있다. 본 연구에서는 기상청에서 제공받은 2015년부터 2023년까지의 종관기상관측데이터와 표준강수지수 데이터를 전처리하여 사용한다. 데이터 전처리 과정에서 결측치와 이상치를 처리하는 방법을 제시하고, 기존 특징들로부터 새로운 특징들을 생성하며, 유전알고리즘과XGBoost를 사용한 래퍼 방식 기반의 특징 추출을 시행한다. F1-score를 적합도로 하여 주요 특징들을 선택한 후, 기계학습과 딥러닝 실험에 사용한다. 실험 결과는 선택된 특징들을 사용한 트랜스포머 기반의 TFT 딥러닝 알고리즘이 0.88의 f1-score를 보여 가장 우수함을 보였다.","There have been many studies on short-term drought prediction. In the past, research mainly focused on numerical modeling. However,due to the limitation of prediction accuracy, studies with artificial intelligence technology have recently gained traction. In the beginning,machine learning models using a single algorithm and multilayer perceptron-based drought prediction research were conducted, andthen ensemble machine learning techniques and deep learning algorithms were introduced. Recently, transformer-based deep learningalgorithms, which have demonstrated outstanding performance, have garnered significant attention. In this study, longitudinal weatherobservation data and standard precipitation data provided by the Meteorological Administration from 2015 to 2023 were preprocessedand utilized. During the data pre-processing phrase, methods of processing missing values and outliers were implemented, new featuresare generated from existing features, and feature extraction based on the wrapper method using a genetic algorithm and XGBoost isperformed. The key features were selected based on therir F1-score as the evaluation metic and were then used for machine learningand deep learning experiments. The experimental results indicated that the transformer-based TFT deep learning algorithm, trained withthe selected features, achieved the highest F1-score of 0.88."
설명가능 인공지능을 활용한 코스피 지수 변동성 예측 연구,2025,"['Quantitative Finance', 'Business Analytics', 'Financial Time Series', 'XAI']",,"This study compares the performance of a statistical model (GARCH) and a machine learning   model   (XGBoost)   in   predicting   the   volatility   of   the   KOSPI   index,   while employing  Explainable  Artificial  Intelligence  (XAI)  to  identify  the  key  volatility  drivers. Using   daily   data   from   2000   to   2024,   this   study   finds   that   XGBoost   outperforms GARCH  in  accuracy  metrics.  This  performance  gap  widens  when  comparing  different error  metrics,  with  XGBoost  showing  1.61  times  lower  error  in  RMSE  and  an  even greater  2.88  times  improvement  in  MAPE,  suggesting  machine  learning  approaches better   capture   the   complex,   non-linear   patterns   in   equity   market   volatility.   Both feature   importance   analyses   using   gain   and   SHAP   values   consistently   identify   the previous  day's  volatility  as  the  most  critical  predictor,  aligning  with  the  volatility clustering in financial theory.This  paper  highlights  how  combining  machine  learning  with  SHAP  enhances  both performance   and   interpretability   in   volatility   forecasting,    providing    a    practical framework  for  implementing  explainable  machine  learning  solutions  in  financial  risk management."
초등학생이 과학 수업 시간에 주의집중과 Mind Wandering 시간은?,2025,"['주의집중', 'Mind wandering', '시선 추적', '기계 학습', 'attention', 'mind wandering', 'eye tracking', 'machine learning']","이 연구의 목적은 초등학생들의 과학 수업 중 주의집중 및 딴생각(Mind Wandering, MW) 상태를 분석함으로써학습 참여와 집중도에 대한 심층적인 이해를 제공하는 것이다. 연구 방법으로는 초등학교 5학년 학생 6명을 대상으로 Eye Tracker와 기계 학습(Object Detection) 기술을 활용하여 시선 데이터를 수집하고, 이를 정량적으로 분석하였다. 수업 중 학습 과제에 대한 시선 고정 시간, MW 시간 및 비율을 추출하고, 시간 경과에 따른 주의집중및 MW의 변화를 분석하였다. 연구 결과, 수업 중 주의집중 비율은 26.62%, MW은 20.04%로 분석되었다. 주의집중 비율은 수업 초반 점진적으로 증가하여 약 17분 시점에 최대치(34.07%)에 도달한 후 감소하였고, MW는 수업시작 직후 최고치(31.04%)를 기록한 후 점차 감소하는 경향을 보였다. 이러한 결과는 초등학생들의 주의집중 및MW가 시간 경과에 따라 변화하며, 이는 작업 기억 용량과 학습 환경의 영향을 받을 수 있음을 시사한다. 이연구는 기존 관찰 기반 연구가 가지는 한계를 보완하여 객관적이고 정량적인 방법론을 제시함으로써, 학생들의학습 행동을 보다 정확히 이해할 수 있는 기초를 마련하였다는 점에서 의의가 있으며, 연구 결과는 초등학생들의학습 집중도 향상을 위한 교수 설계 및 교육적 개입 전략 개발의 필요성을 강조한다.","This study aimed to provide an in-depth understanding of learning engagement and attention levels by analyzing the attention and mind-wandering (MW) states of elementary school students during science classes. The study included six 5th-grade students, utilizing an eye tracker and machine learning (Object Detection) technology to collect and quantitatively analyze gaze data. The analysis included extracting fixation time on learning tasks, MW time, and their proportions, as well as examining changes in attention and MW over time. The results revealed that the average attention ratio during class was 26.62%, while MW accounted for 20.04%. Attention ratio gradually increased during the initial phase of the class, peaking at 34.07% approximately the 17th minute, before declining. Conversely, MW reached its highest level (31.04%) immediately after the class began and then gradually decreased. These findings suggest that attention and MW among elementary school students fluctuate over time and are influenced by working memory capacity and learning environments.This study addresses the limitations of previous observation-based studies by introducing an objective and quantitative methodology, providing a more accurate understanding of students’ learning behaviors. The findings highlight the need for instructional design and educational intervention strategies to enhance learning focus among elementary school students."
Improved Software Defect Prediction with Gated Tab Transformer,2025,"['software defect prediction', 'transformer-based model', 'gated tab transformer', 'software quality', '소프트웨어 결함 예측', 'transformer 기반 모델', 'gated tab transformer', '소프트웨어 품질']",,"Software Defect Prediction (SDP) plays a crucial role in ensuring software quality and reliability. Although, traditional machine learning and deep learning models are widely used for SDP, recent advancements in the field of natural language processing have paved the way for applying transformer-based models in software engineering tasks. This paper investigated transformer-based model as a potential approach to improve SDP model quality, ultimately aiming to enhance software quality and optimize testing resource allocation. Inspired by the Gated Tab Transformer’s (GTT) ability to effectively model relationship within features, we evaluated its effectiveness in SDP. We conducted experiments using 15 software defect datasets and compared results with other state-of-the-art machine learning and deep learning models. Our experiments showed that GTT outperformed state-of-the-art machine learning models in terms of recall, balance, and AUC (increase by 42.1%, 10.93%, and 7.1%, respectively). Cohen's d confirmed this advantage with large and medium effect sizes for GTT on these metrics. Additionally, an ablation study assessed the impact of hyperparameter variations on performance. Thus, GTT's effectiveness address the challenges of SDP, potentially leading to more effective testing resource allocation and improved software quality."
지진취약형 비보강 조적벽체에 대한 기계학습 기반의 손상예측,2025,"['지진 취약형 건축물', '비보강 조적조', '신속 손상 예측', '기계학습모델', 'Seismic vulnerable structure', 'Unreinforced masonry', 'Rapidly damage prediction', 'Machine learning model']",,"The seismic responses of vulnerable unreinforced masonry buildings are strongly dependent on the damage or failure modes of unreinforced masonry walls. The main purpose of this study is to develop machine learning based damage prediction models of seismically vulnerable unreinforced masonry walls. To do this, the damage or failure modes of unreinforced masonry walls are classified into rocking, diagonal tension, bed-joint sliding, and toe-crushing. Dataset including geometrical information, material properties, and damage states was established from the experimental results of reference studies. In order to training machine learning based classification models, deep neural network (DNN), K-nearest neighbor (KNN), random forest (RF), and support vector machine (SVM) were utilized and input variables were categorized as two groups. The estimating performance of machine learning models were evaluated by comparing performance measurement indices, accuracy, precision, recall, F1-score, AUC values which can be calculated from the confusion matrix and ROC curve. From the observation, DNN model has produced largest performance measurement indices among considered 8 machine learning models and is also presented reasonable classification performance for diagonal tension and bed-joint sliding modes which can be regarded as critical damage or failure modes of unreinforced masonry walls."
초등학교 저학년을 위한 노벨엔지니어링을 활용한  인공지능 교육 프로그램 개발 및 적용,2025,"['노벨엔지니어링', '늑대와 일곱 마리의 아기 염소', '융합적 문제해결력', '의사결정트리 알고리즘', '지도학습', 'Convergent Problem Solving', 'Decision Tree Algorithm', 'Nobel Engineering', 'Supervised Learning Model', 'The Wolf and the Seven Little Goats']","목적  본 연구는 노벨엔지니어링 교수⋅학습방법을 활용하여 초등학교 저학년 학생에게 적합한 인공지능 교육 프로그램을 개발하고적용한 뒤, 개발한 교육 프로그램의 효과성을 검증하기 위해 수행되었다.방법  이를 위하여 ADDIE 모형을 기반으로 인공지능 교육 프로그램을 개발하였으며, 초등학교 2학년 학생 23명을 대상으로 개발한교육 프로그램을 적용한 뒤, 융합적 문제해결력 검사 도구를 활용하여 학생들의 융합적 문제해결력 향상 측면에서 교육 프로그램의적용 효과를 검증하였다. 교육 프로그램 개발 시, 저학년의 발달 단계와 학습 수준 및 흥미를 고려하여 그림 형제의《늑대와 일곱 마리의 아기 염소》를 노벨엔지니어링 도서로 선정하였고, 이야기 속의 문제를 해결하는 과정에서 의사결정트리 알고리즘과 지도학습모델을 학습 전략으로 활용하였다.결과  본 연구에서는 초등학교 저학년 학생에게 적합한 노벨엔지니어링을 활용한 인공지능 교육 프로그램을 5회기, 총 13차시로설계 및 개발하였고, 개발한 교육 프로그램을 학교 현장에 적용하였다. 그 결과, 저학년 학생들이 이야기 속 문제의 해결책 제시 과정에서 의사결정트리 알고리즘을 활용하고 지도학습 모델을 활용하는 학습 전략을 제시할 수 있었다. 또한, 의사결정트리 알고리즘과지도학습(티처블 머신)을 활용한 수업을 적용할 때, 반복 학습을 통한 내재화를 통해 사후 2차 검사에서 저학년 학생들의 융합적문제해결력의 유의미한 향상이 확인되었다.결론  본 연구 결과를 통해, 저학년의 발달 단계와 학습 수준, 흥미를 고려한 인공지능 교육 프로그램이라면, 저학년 학생에게 적용가능하다는 것을 확인하였으므로, 앞으로 저학년 학생에게 적합한 인공지능 교육 프로그램이 꾸준히 개발되는 것을 기대한다. 또한, 저학년 학생들이 반복 학습을 통해 의사결정트리 알고리즘과 지도학습(티처블 머신) 활용 방법을 내재화할 수 있다면, 학생들의 융합적 문제해결력이 향상될 수 있을 것이다.","Objectives  This study aimed to develop and apply an AI education program suitable for lower-grade elementary students using the Nobel Engineering teaching method, and to verify the effectiveness of the developed program.Methods  An AI education program was developed based on the ADDIE model and applied to 23 second-grade elementary students. The program's effectiveness in improving students' convergent problem-solving skills was verified using a relevant assessment tool. In developing the program, consideration was given to the devel opmental stages, learning levels, and interests of lower-grade students. 《The Wolf and the Seven Little Goats》 by the Brothers Grimm was selected as the Nobel Engineering book, and decision tree algorithms and supervised learning models were used as learning strategies to solve the problems within the story.Results  The AI education program, designed for lower-grade elementary students using Nobel Engineering, was structured over five sessions with a total of 13 lessons and was implemented in a school setting. As a result, the students were able to propose solutions using decision tree algorithms and supervised learning models when solving the story's problems. Additionally, when lessons involving decision tree algorithms and supervised learning (Teachable Machine) were applied, the repeated practice led to internalization, which resulted in a significant im provement in the students' convergent problem-solving skills, as confirmed by the second post-test.Conclusions  The results of this study suggest that AI education programs that consider the developmental stages, learning levels, and interests of lower-grade students are applicable. It is hoped that AI education programs suit able for lower-grade students will continue to be developed. Furthermore, if lower-grade students can internalize the use of decision tree algorithms and supervised learning (Teachable Machine) through repeated practice, their convergent problem-solving skills can improve."
A Research on building a Smart City Model based on DID(Decentralized-Identity) using Digital Twin,2025,"['스마트 시티', '디지털 트윈', '분산 ID(DID)', '인지 사물 인터넷(CIoT)', '설명 가능한 인공지능(XAI)', 'Smart City', 'Digital Twin', 'Decentralized-Identity (DID)', 'Cognitive Internet of Things (CIoT)', 'Explainable Artificial Intelligence (XAI)']","도시화는 주거, 교통, 에너지, 환경, 복지, 안전 등의 분야에서 환경을 파괴하고 있다. 이 연구는 시민의 삶의 질을 향상시키고 사회 발전을 촉진하기 위해 디지털 트윈을 활용한 DID 기반 안전 스마트 시티 모델을 제안한다. 본 연구에서는 사물 인터넷(IoT) 환경을 위한 표준화된 계층 모델을 개발하고, 블록체인의 분산 장부 기술과 DID(Decentralized Identity)를 활용하여 안전한 장치 통신을 보장함. 또한, 설명 가능한 인공지능(eXplainable Artificial Intelligence)을 이용하여 IoT로 수집된 빅데이터 처리의 투명성을 보장하고, 자율적인 의사 결정 알고리즘 과 디지털 트윈을 통한 실시간 3D 데이터 시각화를 통합하여 이 모델은 문제 해결 및 예방 기능을 향상시킨다. 따라서 이 연구는 CIoT, 블록체인(DID) 및 디지털 트윈 기술을 결합하여 콘텐츠 통합 및 확장성 문제를 해결하는 종합적인 스마트 시티 표준 모델을 만드는 데 필요한 구성요소를 제공하여 향후 스마트 시티 구축에 기여하는 연구이다.","Urbanization exacerbates challenges in housing, transportation, energy, environment, welfare, and safety. This study proposes a DID-based safe smart city model using digital twin to enhance citizens' quality of life and advance societal development. We develop a standardized layer model for the Cognitive Internet of Things (CIoT) environment, utilizing blockchain's distributed ledger technology and Decentralized-Identity (DID) for secure device communication. Emphasizing explainable AI (eXplainable Artificial Intelligence), the model ensures transparency in processing IoT-collected big data. By integrating autonomous decision-making algorithms and real-time 3D data visualization through digital twins, the model enhances problem-solving and preventive capabilities. This research distinguishes itself by combining CIoT, blockchain (DID), and digital twin technologies to create a comprehensive smart city standard model addressing content integration and scalability."
청소년의 창의적 사고력 예측 요인 탐색: AutoML과 SHAP의 적용,2025,"['PISA 2022', '청소년', '창의적 사고력', 'AutoML', 'SHAP 분석', 'PISA 2022', 'adolescents', 'creative thinking ability', 'AutoML', 'SHAP analysis']","본 연구는 우리나라 청소년의 창의적 사고력에 영향을 미치는 예측 요인을 탐색하고자 하였다. 이를 위해 PISA(Programme for International Student Assessment) 2022에 참여한 만 15세 고등학생 6,117명의 창의적 사고력 응답 결과를 활용하였다. 예측 모형 선정 과정에서는 AutoML(Automated Machine Learning)을 적용하여 다양한 머신러닝 알고리즘의 성능을 비교하였으며, 최적의 예측 모형을 기반으로 주요 예측 변인을 선정하였다. 또한, 예측 요인의 중요도를 분석하기 위해 SHAP(SHapley Additive exPlanations) 값을 활용하였다. 분석 결과, 첫째, 청소년의 창의적 사고력을 예측하기 위해 머신러닝 알고리즘으로 회귀 모형의 성능을 평가한 결과, LightGBM(Gradient Boosting Machine)이 가장 우수한 것으로 나타났다. 둘째, SHAP 중요도 지수를 비교하여 상위 20개 변인을 도출하였고, 수학 관련 변인에서 6개 요인, ICT 관련 5개 요인, 개인 특성 관련하여 4개 요인, 가정 변인에서 2개 요인, 정서 요인에서 3개 요인이 나타났다. 마지막으로, 본 연구 결과를 바탕으로 창의적 사고력 증진을 위한 교육적 방안을 논의하고, 향후 연구를 위한 시사점을 제시하였다.","This study aimed to explore the predictors of creative thinking skills among Korean adolescents. To achieve this, the creative thinking responses of 6,117 high school students aged 15 years who participated in the Programme for International Student Assessment (PISA) 2022 were analyzed.  Automated Machine Learning (AutoML) was applied to compare the performance of various machine learning algorithms, and key predictors were identified based on the best-performing model. In addition, SHAP (SHapley Additive exPlanations) values were used to assess the importance of the predictors. First, among various regression models applied to predict creative thinking ability, LightGBM demonstrated the highest predictive performance. Second, based on SHAP importance scores, the most influential predictor was the “number of mathematics classes per week”, followed by “familiarity with mathematical concepts”, “ICT use for topics beyond school subjects”, “mathematical self-efficacy: formal and applied mathematics”, and “expected academic achievement.”  Finally, based on the results of this study, suggestions to promote creative thinking are discussed, and implications for future research are suggested."
Prediction of Hemifacial Spasm Re-Appearing Phenomenon after Microvascular Decompression Surgery in Patients with Hemifacial Spasm Using Dynamic Susceptibility Contrast Perfusion Magnetic Resonance Imaging,2025,['Magnetic resonance imaging · Hemifacial spasm · Microvascular decompression surgery · Reappearing symptom · Extraction fraction'],,"Objective : Hemifacial spasm (HFS) is treated by a surgical procedure called microvascular decompression (MVD). However, HFS reappearing phenomenon after surgery, presenting as early recurrence, is experienced by some patients after MVD. Dynamic susceptibility contrast (DSC) perfusion magnetic resonance imaging (MRI) and two analytical methods : receiver operating characteristic (ROC) curve and machine learning, were used to predict early recurrence in this study.Methods : This study enrolled 60 patients who underwent MVD for HFS. They were divided into two groups : group A consisted of 32 patients who had early recurrence and group B consisted of 28 patients who had no early recurrence of HFS. DSC perfusion MRI was undergone by all patients before the surgery to obtain the several parameters. ROC curve and machine learning methods were used to predict early recurrence using these parameters.Results : Group A had significantly lower relative cerebral blood flow than group B in most of the selected brain regions, as shown by the region-of-interest-based analysis. By combining three extraction fraction (EF) values at middle temporal gyrus, posterior cingulate, and brainstem, with age, using naive Bayes machine learning method, the best prediction model for early recurrence was obtained. This model had an area under the curve value of 0.845.Conclusion : By combining EF values with age or sex using machine learning methods, DSC perfusion MRI can be used to predict early recurrence before MVD surgery. This may help neurosurgeons to identify patients who are at risk of HFS recurrence and provide appropriate postoperative care."
돌연변이 단백질에 대한 사전 학습 대규모 언어 모델 기반 약물-표적 결합 친화도 예측,2025,"['machine learning', 'large language model', 'drug discovery', 'binding affinity prediction', 'mutant protein', '머신러닝', '거대언어모델', '신약개발', '결합 친화도예측', '돌연변이단백질']","신약 개발은 높은 비용과 긴 시간이 소요되며, 특히 단백질 돌연변이가 약물-표적 결합 친화도에 미치는 영향을 정량적으로 예측하는 것은 중요한 과제이다. 기존 연구에서는 아미노산 서열 처리를 위해 LSTM과 트랜스포머 모델이 활용되었으나, LSTM은 장기 의존성 문제, 트랜스포머는 높은 연산 비용의 한계를 가진다. 반면, 사전 학습된 거대 언어 모델(pLLM)은 긴 시퀀스 처리에 강점을 가지지만, 프롬프트 기반 접근만으로는 정확한 결합 친화도 예측이 어렵다. 본 연구에서는 pLLM을 활용하여 단백질 구조 데이터를 임베딩 벡터로 변환하고, 별도의 머신러닝 모델로 결합 친화도를 예측하는 방법을 제안한다. 실험 결과, 제안된 방법은 기존 LSTM 및 프롬프트 접근법보다 우수한 성능을 보였으며, 돌연변이 특이적 예측에서도 낮은 RMSE와 높은 PCC를 기록하였다. 또한, pLLM 모델의 양자화에 따른 성능 분석을 통해 낮은 연산 비용으로도 충분한 성능을 발휘할 수 있음을 확인하였다.","Drug development is a costly and time-consuming process. Accurately predicting the impact of protein mutations on drug-target binding affinity remains a major challenge. Previous studies have utilized long short-term memory (LSTM) and transformer models for amino acid sequence processing. However, LSTMs suffer from long-sequence dependency issues, while transformers face high computational costs. In contrast, pretrained large language models (pLLMs) excel in handling long sequences, yet prompt-based approaches alone are insufficient for accurate binding affinity prediction. This study proposed a method that could leverage pLLMs to analyze protein structural data, transform it into embedding vectors, and use a separate machine learning model for numerical binding affinity prediction. Experimental results demonstrated that the proposed approach outperformed conventional LSTM and prompt-based methods, achieving lower root mean square error (RMSE) and higher Pearson correlation coefficient (PCC), particularly in mutation-specific predictions. Additionally, performance analysis of pLLM quantization confirmed that the method maintained sufficient accuracy with reduced computational cost."
네트워크 침입탐지에서 데이터 불균형을 고려한 그래디언트 부스팅 분류기,2025,"['machine learning', 'data imbalance', 'intrusion detection', 'gradient boosting classifier', 'random forest', '머신러닝', '침입탐지', '데이터 불균형', '그래디언트부스팅 분류기', '랜덤포레스트']",,"As a way to respond to external threats due to the increase of Internet usage, researches on machine learning methods for network intrusion detection becomes more active. However the problem of data imbalance caused by minority classes is pointed out in the application of machine learning algorithms for intrusion detection. In general classification problems including network intrusion detection, the accuracy of the entire model is often the goal rather than handling the problems caused by such minority classes, so it may not be easy to deal with data imbalance. In this paper, we checked that there is a data imbalance problem in the random forest model used in network intrusion detection, and organized the composition and effect of the gradient boosting classifier for this point. The Random Forest (RF) model and the Gradient Boosting Classifier (GBC) were constructed using the KDDTrain+ data and evaluated using the KDDTest+ data. The difference in the performance of the RF model and the GBC is that the precision and recall of the GBC are higher than that of the RF model without a significant change in accuracy in low-frequency intrusion types. This effect of GBC is expected to have the effect of reducing the overall damage by detecting intrusion types that cause particularly serious damage with a higher probability."
기계학습 모델의 입력차원 축소에 따른 구조물의 지진응답 예측 성능 평가,2025,"['Machine Learning', 'Input Dimension Reduction', 'Feature Selection', 'Feature Extraction', 'Seismic Response Prediction', 'Nuclear Power Plant']",,"Many studies using machine learning techniques have been conducted recently to predict the seismic responses of various structures. A seismic response prediction model that considers the aging effect is needed because the material properties of RC structures change due to aging deterioration. For this purpose, various input variables representing the characteristics of the seismic loads and changes in the material properties due to aging are required, which may lead to excessive input dimensions of the ML model. The time and effort required to build the database increase as the database required to develop the ML model with a large input dimension increases. Therefore, this study assessed the possibility of the required database reduction and performance of the ML model for predicting the seismic response of RC structures considering aging by reducing the input dimension of the ML model. A nuclear power plant whose aging deterioration significantly impacts its safety was selected as an example structure. Artificial ground accelerations were used as the seismic loads. The accuracies of the prediction models with different dimension reduction methods were investigated using feature selection and feature extraction as dimension reduction techniques."
RC 기둥의 폭발 저항성능 예측을 위한 소수 데이터 세트 기반 기계학습 모델 방법론,2025,"['machine learning', 'finite element analysis', 'blast resistance performance assessment', 'reinforced concrete column', '폭발손상평가', '철근콘크리트 기둥', '유한요소해석', '기계학습']",,"This study proposes a machine learning model with a combining method capable of accurately evaluating the blast resistance performance of reinforced concrete (RC) columns using a small dataset of 200 samples. To achieve this, a blast performance evaluation response database was established based on finite element analysis models that consider various column details and blast scale values. Each individual learning model applied seven classification algorithms, and the model demonstrating the highest evaluation metrics was developed and combined. The proposed machine learning model achieved a 65.5 % reduction in data usage compared to an existing model based on 700 samples while improving performance by an average of 14.3 %. These results demonstrate that the proposed method enables highly accurate and rapid evaluations even in data-limited environments."
설명가능한 인공지능 활용 서울시 지하철 혼잡도 예측과 정책적 의사결정 지원을 위한 비즈니스 애널리틱스,2025,"['머신러닝과 딥러닝', '비즈니스 애널리틱스', '설명 가능한 예측', '지하철 혼잡도Abstract', 'Business Analytics', 'Explainable Prediction', 'Machine and Deep Learning', 'Subway Congestion']","2022년 기준 하루 평균 대중교통 이용 건수 약 1,025만 건 중에서 약 50.3%를 차지할 정도로 서울시민중 절반 이상이 매일 지하철을 이용한다. 본 연구는 시민들이 승하차하는 과정에서 느낄 수 있는 혼잡도를 실시간으로 빠르고 정확하게 예측 및 설명함으로써 빅데이터 기반 실제 비즈니스의 활용도를 높이는 비즈니스 애널리틱스 방법론을 제시하는 것을 목적으로 한다. 6개 공공데이터베이스를 융합하여 대표적인 머신러닝및 딥러닝 알고리즘으로 혼잡도를 예측하였고, 설명 가능한 인공지능인 SHAP 알고리즘으로 예측된 혼잡도의 근거를 실시간 효과적으로 제시하였다. Random Forest 알고리즘으로 95% 이상의 미래 혼잡도 예측 성능을 달성하였다. 혼잡도를 낮추기 위해 환승노선을 늘리는 사업이 확충되거나 비섬식형태의 승강장 플랫폼을 확충하는 것이 방법일 수 있다. 또한, 출근이 집중되는 월요일과 화요일에 혼잡도가 높아지기 때문에 근무 유연화를 통해 혼잡도의 개선이 가능할 것으로 생각된다.","More than half of Seoul’s residents use the subway every day, accounting for about 50.3% of the approximately 10.25 million average daily public transport trips as of 2022. This study aims to propose a business analytics methodology that improves the usability of big data-based real businesses by quickly and accurately predicting and explaining the congestion level that citizens may feel while getting on and off the subway. Six public databases are merged to predict the congestion level with representative machine learning and deep learning algorithms, and the SHAP algorithm, an explainable artificial intelligence, effectively presents the evidence of the predicted level. The Random Forest algorithm achieved a prediction performance of over 95% for future congestion. To reduce congestion, it may be possible to expand the number of transit routes or expand non-island platforms. In addition, since congestion is higher on Mondays and Tuesdays when commuting is concentrated, it is possible to improve congestion through work flexibility."
랜덤 포레스트를 활용한 건설 작업별 사고 위험 강도 및 요인 예측,2025,"['머신러닝', '랜덤포레스트', '안전사고', '심각도 예측', 'machine learning', 'random forest', 'safety accident', 'severity prediction']","건설 산업은 중대재해 발생 가능성이 높은 업종이다. 이를 해결하기 위해 본 연구에서는 머신러닝 기법인 랜덤포레스트 를 적용하여 사고 분석 방법을 제안하였다. 사고 사례를 기반으로 데이터 특성 분석을 통해 위험요인을 파악하고 사고강도 를 예측하여, 사고의 심각도에 따라 위험 완화 조치를 우선적으로 수행할 수 있도록 하였다. 최종 모델은 4개의 주요 입력 변 수를 활용하여 85%의 정확도를 달성하였다. 이 결과는 안전관리자가 맞춤형 안전 전략을 개발하고 사고 예방 및 대응을 강 화하는 데 기초 데이터를 제공할 것으로 기대된다.","The construction sector demonstrates a disproportionately elevated incidence of fatal and severe occupational incidents relative to other industrial domains. To address this critical safety concern, the implementation of machine learning methodologies within construction safety paradigms has been proposed as a potential intervention strategy. Accordingly, this investigation endeavors to identify salient risk factor variables through data-driven characteristic analysis of construction incident cases documented by the Korea Occupational Safety and Health Agency(KOSHA). The research methodology employs random forest algorithmic techniques to predict incident severity, thereby facilitating the prioritization of risk mitigation interventions based on predicted intensity parameters. The optimized predictive model incorporated four predictor variables and achieved 85% classification accuracy in predicting incident combinations. Based on the predictive outcomes, predominant incident combinations were identified and stratified according to work typology, with their cumulative intensity visualized through  percentage  distributions.  The  empirical  findings  of  this  investigation  are  expected  to constitute  significant  foundational  knowledge  for  safety  management  personnel  in  formulating targeted safety protocols for specific construction activities, ultimately contributing to enhanced incident prevention capabilities and emergency response mechanisms within the construction industry."
GPR-SEM 예측모델 평가 방법 연구,2025,"['머신러닝', '가우시안 프로세스 회귀', 'GPR-SEM', '모델 평가 방법', '소량데이터셋', 'Machine Learning', 'Gaussian Proces Regression', 'GPR-SEM', 'Model Evaluation Method', 'Small-dataset']","머신러닝 기술의 발달로 정확한 예측모델 개발은 제조기업의 품질관리, 제품수명관리 등 많은 부분에 필수적인 요소로 자리 잡고 있다. 그러나양질의 데이터를 다량으로 축적하기 힘든 분야(신소재개발 등)에 접목하는데는 한계가 있다. 이에 이전 연구에서 small-dataset 기반 예측 모델을위한 GPR-SEM 모델을 제안 하였다. 기존의 모델 적합도 지표(MSE, R² 등)는 기존 예측모델의 성능을 평가하는 데 유용하지만, GPR-SEM 모델의특성인 불확실성 정보를 충분히 반영하지 못한다는 한계점이 있다. 이에 본 연구에서는 GPR-SEM 모델을 평가하기 위해 종합적인 점수방식인GS-Score를 제안하였다. 이는 여러 평가 지표를 통합하여 모델의 전반적인 성능을 단일 점수로 표현함으로써, 모델 간 비교와 선택을 용이하게할 수 있다. 본 연구에서는 전통적 평가방법을 small-dataset 에 적용하고 GS-Score 와 비교 대조를 통해 효과를 검증해보았다. 본 연구를 통해GPR-SEM을 활용한 예측모델 개발 및 적용을 위한 객관적인 평가기준을 마련할 수 있을 것으로 기대된다.","The development of accurate prediction models has become essential in many aspects of manufacturing companies,such as qualitycontrol and product lifecycle management,due to advancements in machine learning technology. However, there are limitations in applyingthese models to fields where it is difficult to accumulate large amounts of high-quality data (e.g., new material development). Therefore,In previous research, we proposed the GPR-SEM model for small-dataset based prediction models. Traditional model fit indicators (suchas MSE, R²) are useful for evaluating the performance of existing prediction models, but they have limitations in fully reflecting theuncertainty information, which is a characteristic of the GPR-SEM model. To address this, in this study, we propose the GS-Score, acomprehensive scoring method for evaluating the GPR-SEM model. By integrating various evaluation metrics into a single score thatrepresents the overall performance of the model, it facilitates comparison and selection between models. In this study, we applied traditionalevaluation methods to small-datasets and verified their effectiveness through comparison and contrast with the GS-Score. Through thisresearch, we expect to establish objective evaluation criteria for developing and applying prediction models using GPR-SEM."
Development of conjugate gradient algorithm for training fuzzy neural \\networks and its application in regression problems,2025,"['Fuzzy', 'algorithm', 'regression', 'ANN', 'algorithm', 'training', 'machine learning.']",,"Machine learning commonly uses conjugate gradient techniques to enhance the training process of fuzzy neural networks, thereby enhancing the accuracy and reliability of model predictions through iterative adjustments of network parameters based on the gradient of the loss function. In this paper, we derive a new algorithm based on the conjugacy condition for Dai and Liao (DL) from the conjugate gradient algorithms. We used some assumptions to show that the new algorithm had descent and global convergence properties. We then used this algorithm to train a Takagi-Sugeno neural network model using a MATLAB program simulation. We used three regression problems, and the new algorithm demonstrated promise and high efficiency in the simulation numerical results compared to the PRP algorithm."
XCNet: Enhancing Defect Detection in Sensor Boards Through Data Quality Analysis and Convolutional Neural Networks,2025,"['deep learning', 'artificial intelligence', 'big data', 'quality control', 'digital', 'semiconductor', 'smart manufacturing', 'image recognition']",,"Sensor boards are vital components in modern technologies, but ensuring their quality remains a significant challenge. Increasing demand has driven manufacturers to integrate more components onto single boards, complicating quality control processes. Defects in these boards pose risks of financial losses and safety hazards.Traditional inspection methods, which rely on manual labor, are time-consuming, error-prone, and inefficient for handling complex products. Recent advancements in machine learning offer transformative solutions to these challenges. In this paper, we present XCNet, a convolutional neural network-based deep learning framework designed for automated defect detection in sensor boards. XCNet addresses the limitations of traditional methods by significantly enhancing inspection accuracy and efficiency while reducing human intervention. XCNet is tailored to handle highly imbalanced datasets caused by the rarity of defective products. Through comprehensive analyses, we investigate the impact of data quality on model performance, optimizing XCNet’s architecture and preprocessing techniques to achieve robust results. Extensive experiments on sensor board image data demonstrate XCNet’s remarkable accuracy of 99.54%, showcasing its potential as a reliable and scalable solution for automated quality control in manufacturing."
에어컴프레서의 건전성 예측을 위한 합성곱신경망의 최적화 알고리즘 분석,2025,"['인공지능', '머신러닝', 'CNN', 'PHM', 'Artificial Intelligence', 'Machine  Learning', 'Convolutional Neural Network', 'Prognostics & Health Management']","에어컴프레서는 다양한 제조공장에서 널리 사용되고 있는 원동기이며, 공기역학을 기반으로 하는 다수의 제조 장비에 동력을 제공하고 있어, 예기치 못한 고장이 발생할 경우 전체 제조라인의 가동이 중단될 수 있다. 본 연구에서는 컴프레서에 통신이 가능한 진동센서를 부착하여 컴프레서 가동 시 발생되는 진동 데이터를 클라우드 상에 축적하고 수집된 데이터로부터 컴프레서의 운영 상태 진단을 위한 특징들을 추출하였다. ‘합성곱신경망(Convolutionl Neural Networks)’을 활용하여 수집된 데이터와 추출된 특징들을 학습시켜 컴프레서의 상태 건전성을 자동으로 예측할 수 있도록 인공지능 알고리즘을 고안하였다. 이후 합성곱신경망의 최적화 파라미터별로 컴프레서의 건전성 예측 정확도에 어떠한 영향을 미치는지 실험하였다. 실험결과, 합성곱신경망을 통한 컴프레서의 진동 데이터 분석에서는 ‘모멘텀’ 최적화 기법의 판정 정확도가 가장 우수하였다. 데이터 셋의 특성에 따라 적절한 신경망 최적화 기법이 합성곱신경망 학습 효율과 예측 정확도를 결정짓는 매우 중요한 요소임을 확인할 수 있었다.","The air compressor is a common rotating machine that is widely used in various manufacturing plants, and provides power to a number of manufacturing devices based on aerodynamics in the plant, so if an unexpected failure occurs, the entire manufacturing line can be shut down.In this study, a vibration sensor capable of communication was attached to the compressor, the vibration data generated during compressor operation was accumulated on the cloud, and features for diagnosing the operating status of the compressor were extracted from the collected data. An artificial intelligence algorithm was designed to automatically predict the health-condition of the air- compressor by learning the collected data and extracted features using ‘Convolutional Neural Network (CNN). And then we tested how each CNN optimization parameter affected the compressor's health prediction accuracy. As a result of the experiment, in analyzing compressor vibration data through CNN, the ‘momentum’ optimization algorithm had the best accuracy, and depending on the characteristics of the data set. We found that appropriate neural network optimization techniques are a very important factor in determining CNN learning efficiency and prediction accuracy."
Feature Selection Using CS - BPSO for Depression Detection Based on Profile Information,2025,"['depression', 'Machine Learning', 'Feature selection', 'Welch’s T-test', 'cost-sensitive', 'BPSO']",,"Depression is a common, cross-cultural mental health problem that, if unnoticed and untreated, can progress to a severe condition with serious consequences. Prevention and detection at an early stage are critical for overall health. We focus on detecting depression in college students using machine learning techniques, to identify individuals for a round of counseling, which is confirmatory. There is a possibility of normal individuals being identified as depressed (false positives) and depressed individuals being identified as normal (false negatives), each having a cost associated with them. Given that the costs of FP and FN are unknown and depend on the environment, we have proposed an algorithm that can provide different models for different relative costs of FP and FN. This work proposes a novel cost-sensitive feature selection algorithm using binary particle swarm optimization (CS-BPSO). The experiences and emotions of undergraduate students are collected through a private interview questionnaire form that allows participants to express their opinions freely while maintaining confidentiality. This is performed in conjunction with a Patient Health Questionnaire (PHQ-9) that permits labeling individuals as normal or depressed. The labeling is then validated manually by experts. The entire process has been performed under the guidance of psychiatrists. Results indicate that CS-BPSO consistently obtains the least cost compared to other feature selection algorithms, along with stability in classifier performance. Statistical tests also suggest that CS-BPSO performance is significantly better than other feature selection algorithms."
XGBoost 기반 CQ 예측 알고리즘 개발,2025,"['전기성문도', '머신 러닝', '성대 폐쇄 계수', 'XGBoost', 'Electroglottography', 'machine learning', 'closed quotient']","성대 폐쇄 계수 (closed quotient, CQ)는 성대의 접촉 시간을 비율로 나타낸 지표로, 발성 훈련 및 음성 치료에서 중요한 지표로 사용된다. CQ는 electroglottography (EGG)를 통하여 측정 될 수 있으나, EGG 장비 없이 머신 러닝 알고리즘을 훈련하면 오디오 신호만으로 CQ를 측정할 수 있다. 본 논문에서는 XGBoost를 기반으로 CQ를 예측하는 알고리즘을 개발한다. 이를 위해서 오디오 신호의 스펙트로그램으로부터 특성들을 신중하게 결정한다. 특성들은 첨도, 조화, SPD200, SPD500을 포함하였다. ‘아’ 모음 발성시 EGG를 측정한 데이터셋으로 XGBoost를 훈련하고 평가한 결과 MAE가 6E-2이하로 신뢰할 만한 수준의 예측이 이루어 졌다. XGBoost을 훈련한 이후 얻을 수 있는 부산물은 특성 중요도 분석이다. SPD500과 첨도가 높은 특성 중요도 점수를 얻은 것을 확인하였다.","The closed quotient (CQ), which represents the ratio of vocal fold contact during vocal phonation, is an important reference in vocal training and clinical study. Although CQ can be measured using electroglottography (EGG), it can also be estimated solely from audio signals by training a machine learning algorithm without the need for EGG equipment. In this study, we develop an algorithm based on XGBoost to predict CQ. We judiciously selected features from the spectrogram of audio signals, including kurtosis, harmonics, SPD200, and SPD500. The XGBoost model was trained and evaluated using a dataset of EGG measurements recorded during sustained phonation of the vowel /a/. The resulting mean absolute error (MAE) was less than 6E-2, indicating reliable prediction performance. Additionally, an analysis of feature importance, a byproduct of XGBoost training, revealed that SPD500 and kurtosis were the most significant features related to ECG."
A review on computational models for predicting protein solubility,2025,"['biotechnology', 'machine learning', 'protein solubility', 'recombinant protein', 'solubility prediction']",,"Protein solubility is a critical factor in the production of recombinant proteins, which are widely used in various industries, including pharmaceuticals, diagnostics, and biotechnology. Predicting protein solubility remains a challenging task due to the complexity of protein structures and the multitude of factors influencing solubility. Recent advances in computational methods, particularly those based on machine learning, have provided powerful tools for predicting protein solubility, thereby reducing the need for extensive experimental trials. This review provides an overview of current computational approaches to predict protein solubility. We discuss the datasets, features, and algorithms employed in these models. The review aims to bridge the gap between computational predictions and experimental validations, fostering the development of more accurate and reliable solubility prediction models that can significantly enhance recombinant protein production."
IoT 음향 센서와 딥러닝을 활용한 누수 탐지,2025,"['AI', 'Machine Learning', 'Deep Learning', 'Fault Detection', 'Water Leak', 'Colab']",,"With the recent advancements in sensor and device technology, IoT sensor applications are rapidly expanding across various fields, integrating with artificial intelligence. IoT-based water facility management technology plays a crucial role in improving daily life. In the field of water leakage management, traditional research has mainly focused on simple sensor-based detection and analysis for pipeline maintenance. However, because the number of aging pipelines has increased significantly, managing water leakage using conventional human-based methods has become increasingly challenging. This paper presents a deep learning model using public water leakage data. The proposed model showed good performance at 94% accuracy. The results show that human-based leak detection and analysis can be replaced by AI-based systems, which can effectively reduce the response time and minimize the waste of water resources and economic losses. In addition, by diagnosing leaks as soon as abnormal data are generated, and by monitoring them in real time, environmental damage such as subsequent large-scale leaks and cascading pollution can be greatly reduced."
한국프로농구 경기 결과 예측을 위한 인공지능 모델 개발 및 효용성 검증: 자원기반이론 및 직무 요구-자원 이론의 통합적 적용,2025,"['인공지능', '머신러닝', '스포츠 경기 결과 예측', '스포츠 애널리틱스', '한국프로농구', 'AI', 'Machine Learning', 'Game Result Prediction', 'Sports Analytics', 'Korean Professional Basketball League(KBL)']","본 연구는 스포츠 팬의 몰입도를 높이기 위한 경기 결과 예측 분야의 체계적인 학술적 기반을 제공하기 위한 목적으로 시행되었다. 인공지능과 빅데이터의 발전으로 스포츠 경기를 예측하는 연구가 증가하고 있는 현시점에서, 실제 경기에서 발생하는 변수를 고려하여 경기 결과를 예측하기 위한 메커니즘의 규명과 더불어 이론적 근거 정립의 중요성이 꾸준히 제기 되었다.  본 연구에서는 이론적인 측면에서는 자원기반이론(resource-based theory)과 직무 요구-자원 이론(job demand- resource theory)을 통합적으로 적용하였다. 이러한 연구의 필요성을 실증적으로 규명하기 위해 본 연구는 한국프로농구 (KBL)를 중심으로 2017~18시즌부터 2023~24시즌까지 진행된 1,833개 경기데이터를 전처리하여 경기지표, 일정, 선수 결장, 경기장 정보 등 기존의 선행연구에서 검증되지 않은 다양한 변수를 수집하여 본 연구에 적용하였다. 방법론적으로 7가지 인공지능 알고리즘인 로지스틱 회귀, 서포트 벡터 머신, 다층 퍼셉트론, 그래디언트 부스팅, 엑스트라 트리, 랜덤 포레스트 등을 실제 경기 결과 예측에 활용하여 실증분석을 진행하였다. 분석 결과, 변수 선택법에 의거 판타지 포인트 차이, 상대 팀 최다어시스트 선수 기록 격차, 양 팀의 속공 득점 차이, 양 팀의 벤치 실점 허용 차이 등 13개 최적 변수를 조합하고 로지스틱 회귀 알고리즘을 적용했을 때 가장 높은 예측 정확도(66.79%)를 달성하였다. 이는 자원기반이론과 직무 요구-자원 이론의 통합적 적용 차원에서 시즌 중 한국프로농구팀이 직면하는 상황적 변수를 활용하여 경기 결과를 이론적으로 설 명하고 실증적으로 검증한 최초의 연구로, 스포츠 애널리틱스 분야의 이론적인 기여와 더불어 더욱 체계적인 스포츠 경기 예측의 실무적 실용 가치를 제공한다.","This study aims to provide a systematic academic foundation in the field of sports game result prediction to increase the engagement of sports fans. Due to the development of artificial intelligence and big data, the importance of establishing a theoretical basis and identifying mechanisms for predicting game outcomes in consideration of variables that occur in actual games has been steadily raised. This study focuses on the Korean Basketball League (KBL) preprocessing data from 1,833 games played from the 2017~18 season to the 2023~24 season to collect various variables that have not been validated in previous studies. In terms of research methodology, seven AI algorithms, logistic regression, support vector machine, multilayer perceptron, gradient boosting, extra tree, and random forest, were used to predict the outcome of actual matches. The results of this study showed that the highest prediction accuracy (66.79%) was achieved when the logistic regression algorithm was applied to the combination of 13 optimal variables according to the variable selection method. This is the first study to theoretically contribute and empirically verify sports game result prediction using contextual variables of Korean professional basketball teams during the season integrating resource-based and job demands-resource theory."
학업부진 예측모델 개발 연구 : 대구교육종단연구의 국어와 수학을 중심으로,2025,"['예측모델', '머신러닝', 'SHAP', '시계열', '학업부진', 'Predictive Model', 'Machine Learning', 'SHAP', 'Time Series', 'Academic Underachievement']","학생의 학업 성취를 사전에 예측하여 맞춤형 피드백과 지원을 제공하는 것은 학습 경험의 질을 향상시키고, 높은 성취를 유도하는 데 중요한 역할을 한다. 그러나 학업 성취도는 다양한 요인이 복합적으로 얽혀 있어 정확 한 예측이 어렵다. 기존 연구에서는 주로 종단연구 데이터를 활용하여 학업 성취에 영향을 미치는 변인을 탐색 해 왔으며, 최근에는 머신러닝 기법의 발전으로 다수의 변인과 비선형 관계를 동시에 분석함으로써 성취도 예측 의 정확성이 향상되고 있다. 특히, SHAP 지수를 활용한 연구를 통해 모델의 설명력을 높이고, 주요 변인의 교 육적 시사점을 시각화하는 시도가 이루어지고 있다. 본 연구는 대구교육종단연구 데이터를 활용하여 학생의 성 취도 변화를 시계열적으로 분석하고, 국어 및 수학 교과의 성취도 변화를 예측하는 주요 변인을 도출하여 학습 부진을 조기에 식별하는 데 기여하고자 한다.","Predicting students' academic achievement in advance and providing tailored support enhance learning quality and promote success. However, academic performance is influenced by complex factors, making accurate prediction challenging. While previous studies have used longitudinal data to explore key variables, recent advancements in machine learning improve accuracy by analyzing multiple factors and nonlinear relationships. In particular, SHAP-based studies enhance model interpretability and visualize key educational insights. This study uses data from the Daegu Education Longitudinal Study to analyze students’ academic performance over time and identify key predictors in Korean and mathematics, contributing to the early detection of underachievement."
함정전투체계 무장체계 연동통제를 위한 AI 기반 이상탐지 연구,2025,"['Artificial Intelligence', 'Machine Learning', 'LSTM-Auto Encoder', 'ELK', 'Combat Systems', '인공지능', '기계학습', '전투체계']",,"This paper proposes the use of anomaly detection using LSTM AutoEncoder to verify the possibility of anomaly detection function through AI in the control environment of the interlocking weapon system of a naval combat system.. Performance data such as combat system logs and metric data were collected and time-series preprocessed with the ELK Stack. The LSTM AutoEncoder model, which uses the LSTM network-based Eocder to compress and dimensionally reduce data, and the Decoder to restore the input data to a similar form, was trained using only normal environmental data. Afterwards, the performance was evaluated using test data generated by simulating normal and abnormal situations, and a high score of Accuracy 0.99, Precision 0.97, Recall 0.87, and F1-Score 0.92 was output. This study confirmed the applicability of the model generated through machine learning in the detection of anomalies in the control environment of the interlocking weapon system of a naval combat system."
인공지능을 활용한 문서 요약 기술의 혁신과 발전 동향,2025,"['문서 요약', '머신러닝', '딥러닝', 'Transformer', 'GPT', 'BART', 'Document Summarization', 'Machine Learning', 'Deep Learning', 'Transformer', 'GPT', 'BART']","문서 요약은 디지털 데이터의 급격한 증가와 정보의 홍수 속에서 핵심 정보를 신속하게 파악하는 데 중요한 역할을 하며, 인공지능 기술은 이 과정의 자동화와 정확도 향상에 필수적 역할을 한다. 전통적인 머신러닝 방식에서부터 최근의 딥러닝, 특히 Transformer, BERT, GPT 시리즈 등의 혁신적인 모델들에 이르기까지, 다양한 인공지능 기술들이 문서 요약에 활용되며 눈부신 발전을 이루고 있다. 본 연구에서는 추출 요약과 생성 요약의 기초부터 시작하여, RNN, LSTM, Transformer, BERT, GPT 시리즈, RoBERTa, T5, BART 등 최신 인공지능 기술의 적용 사례를 포괄적으로 다룬다. 이러한 기술들은 문서의 정확한 요약과 자연스러운 표현 생성에 크게 기여하며, 문맥적 이해력과 양방향 문맥 처리 능력을 향상시킨다. 또한, 인공지능 기술의 윤리적, 사회적 고려사항에 대한 중요성을 강조하며, 향후 연구 방향에 대한 제언을 포함한다.","Document summarization plays a critical role in quickly identifying key information amidst the rapid growth of digital data and information overload, and artificial intelligence plays an essential role in automating and improving the accuracy of this process. From traditional machine learning methods to recent innovations in deep learning, notably the Transformer, BERT, and GPT series, various AI techniques have been applied to document summarization and have made remarkable progress. Starting with the basics of extractive summarization and generative summarization, this paper comprehensively covers the application of the latest AI techniques such as RNN, LSTM, Transformer, BERT, GPT series, RoBERTa, T5, and BART. These techniques contribute significantly to the generation of accurate summaries and natural representations of documents, improving contextual understanding and interactive context processing. The paper also emphasizes the importance of ethical and social considerations in AI, and includes suggestions for future research suggestions."
An Interactive System Using Gesture Recognition for Multimedia Performance,2025,"['Gesture Recognition', 'Machine Learning', 'Music', 'Visuals', 'Dance']",,"This study focused on developing an interactive system that utilizes machine learning to classify gestures, thereby integrating them into multimedia performances incorporating music, visuals, and dance. The researchers used an iPhone and CoreML in conjunction with a dedicated app designed to classify gestures and communicated the detected gestures and their corresponding levels through a network. The transmitted data are then utilized to control the music and visuals displayed on a computer as part of the interactive multimedia performance. By employing this innovative approach, the study aims to streamline the production of immersive and engaging performances, ultimately enhancing the overall experience for both performers and the audience. This integration of technology and art has the potential to revolutionize the way interactive multimedia performances are created and experienced."
A recurrent neural network for modeling natural circulation density wave instabilities,2025,"['Recurrent neural network', 'Density wave oscillation']",,"Advancements in machine learning and deep learning capabilities over several decades have resulted in models specialized for unique data structures and use cases. One such model, the recurrent neural network (RNN), is a deep learning architecture that incorporates temporal memory in its training. This is primarily performed utilizing long short-term memory (LSTM). Compared to dense neural networks (DNN), this feature gives the potential to model highly dynamic behaviors that would otherwise be limited using conventional machine learning models. LSTM is used here to predict two-phase flow instability, specifically density wave oscillation (DWO), which is characterized by significant oscillations in a boiling channel that can severely impact the safety of boiling water reactors (BWRs). Density waves produced by dynamic voiding in the channel dominate the system and maintain high amplitude flow oscillations which can cause cycles of dryout and rewet. In this paper, the RNN model is trained on experimental DWO data in order to test the abilities of the LSTM framework. Training data is obtained from tests using a single channel 10 × 10 BWR bundle geometry with electrically heated rods at 7–8 MPa. The model is tested with different architectures and utilizes different optimization methodologies to determine the impact on results."
열람실 로그데이터를 활용한 좌석 유형 분류 및 물리적 요인에 관한 연구: K대학교를 중심으로,2025,"['University Library', 'Machine Learning', 'Clustering', 'Physical Factors', 'Log Data']",,"University libraries are transforming into dynamic learning environments supporting academic pursuits and personal development. Although recent studies have employed various methods, most have primarily depended on subjective assessments or basic usage statistics, which do not fully capture user behavior through data-driven clustering techniques. This study utilized machine learning techniques to examine 157,021 library reading room usage logs. By applying K-means, BIRCH, and GMM algorithms, the research classified different seat types and analyzed environmental factors. Unlike previous studies, this research addressed methodological gaps by adopting clustering-based machine learning methods, enabling a systematic exploration of the relationship between seat preferences and environmental influences. The findings introduced a novel seat classification framework and an improved operational strategy, offering valuable contributions to the field of library science and practical insights for knowledge management. By leveraging advanced clustering techniques, this study represents a meaningful step forward in library research methodology, effectively linking theoretical insights with practical solutions for optimizing library space management."
Clinical Applications of Artificial Intelligence in Vascular Surgery,2025,"['Artificial intelligence', 'Machine learning', 'Deep learning', 'Neural networks', 'Vascular surgery']",,"Artificial intelligence (AI) has been applied in many fields, including science, technology, and medicine. However, vascular surgeons face many obstacles and limitations in using and applying AI because of their limited understanding of computer science, programming languages, and complex AI technologies, such as machine learning, deep learning, and artificial neural networks. This article describes the basic knowledge of AI, applications of AI technologies in vascular surgery, and the use of smart wearable devices. Finally, the challenges and limitations of AI are discussed as essential issues hindering its widespread application in vascular surgery."
TaxoGCN: GCN 기반 추천 시스템 성능 향상을 위한 아이템 분류체계 통합,2025,"['Big Data', 'Machine Learning', 'Deep Learning', 'Graph Convolutional Network', 'Item Taxonomy', 'Recommender System']",,"With the rapid expansion of the e-commerce market and the increasing diversity of products and services, the importance of recommender systems has become increasingly significant. Traditional recommender systems have enhanced the recommendation performance through Matrix Factorization (MF) or Graph Convolutional Network (GCN)-based models. In particular, GCN-based models such as LightGCN have achieved superior performance by effectively capturing indirect user-item interactions. However, exclusive reliance on user-item interaction data poses challenges for improving personalization, leading to increased interest in integrating side information such as item taxonomy. Item taxonomy, organized hierarchically from broad categories to fine-grained subcategories and individual items, facilitates learning latent similarities between items. It facilitates the extraction of generalized features at higher levels and detailed features at lower levels, thereby offering a multi-layered representation of user preferences. In this study, we propose TaxoGCN, a novel GCN-based recommender model that integrates item taxonomy. TaxoGCN extends the framework of LightGCN by incorporating user-item interactions along with user-category and item-category relationships, thereby enhancing recommendation performance. Experiment results using real-world data show that TaxoGCN achieves an improvement of 6.7% in Recall@5, 6.4% in Precision@5, 7.4% in NDCG@5, and 8.6% in MAP@5 compared to LightGCN. By explicitly modeling user-item, user-category, and item-category interactions using hierarchical taxonomy within the GCN framework, TaxoGCN effectively captures complex and multi-dimensional user preference patterns, leading to measurable improvements in recommendation accuracy."
RE100 부상 속의 RPS 시장 안정성: 현물시장의 역할과 정책적 시사점,2025,"['REC', '현물가격', '시장 안정화', '머신러닝', '구조변화', 'REC', 'Spot price', 'Machine learning', 'Structural break']","본 연구는 2013년 1월부터 2023년 12월까지의 월별데이터를 활용하여 REC(신재생에너지 공급인증서) 현물가격 결정요인을 분석하였다. 머신러닝 등 다양한 모형으로 추정한 결과, 2017년 양방향 거래제 도입 이후 REC 현물가격 변동에 있어 수급 요인보다 현물 계약 집중도가 더 중요한 역할을 하는 것으로 나타났고, RE100 으로 인한 REC 수요증가가 현물가격 상승에 유의한 영향을 미친 것으로 분석되었다. 이러한 결과는 REC 현물가격 안정화를 위해 단순한 공급 확대보다 계약시장 참여를 유도하는 정책이 더욱 중요해졌음을 시사한다. 특히, 높은 현물시장 가격이 재생에너지 사업자들에게 투기적 거래나 장기계약 파기 유인을 제공해 가격 변동성을 더욱 심화시켜 왔다는 점을 고려할 때, K-RE100 시행 이후 시장 안정화를 위해 현물시장 의존도를 낮추고 계약시장 참여도를 높이는 방안의 필요성이 더욱 커졌음을 알 수 있다.","This study analyzes the determinants of REC (Renewable Energy Certificate) spot prices using monthly data from January 2013 to December 2023. Applying both traditional time-series models and machine learning techniques, the results indicate that after the introduction of the two-way trading system in 2017, the concentration of transactions in the spot market has played a more significant role in REC price fluctuations than supply-demand factors. Additionally, the implementation of the K-RE100 policy has significantly contributed to the increase in REC demand, leading to higher spot prices. These findings suggest that policies promoting participation in contract-based transactions may be more effective in stabilizing REC prices than merely expanding supply. Given that high spot prices incentivize speculative trading and contract breaches among renewable energy producers, thereby exacerbating price volatility, measures to reduce reliance on the spot market and enhance participation in the contract market are necessary for market stabilization."
SNS 텍스트 기반 마약 의심 거래 탐지 알고리즘에 대한 연구: 패턴 및 맥락 분석을 중심으로,2025,"['인공지능', '마약거래', '자연어분석', '사이버범죄', '머신러닝', 'Artificial Intelligence', 'Drug Trafficking', 'Natural Language Analysis', 'Cybercrime', 'Machine Learning']","본 연구는 SNS 플랫폼에서 급증하는 마약 거래와 지속적으로 진화하는 은어 사용에 대응하기 위한 효과적인 탐지 방안을 제시하는 것을 목적으로 한다. 마약 거래 의심 게시물과 정상게시물을 혼재된 데이터 이용해 자연어 처리와 머신러닝 기법을 활용한 체계적인 분석을 수행했다. 분석 결과, SNS 마약 거래 텍스트에서는 대유, 비유, 쌍관, 묘사의 네 가지 언어적 패턴이 발견되었으며, TF-IDF 분석과 Word2Vec 분석을 통해 이들 텍스트가 조밀한 의미 군집을 형성하고 해시태그를 통한 은밀한 코드화가 이루어지고 있음을 확인했다. 이상탐지 모델실험에서는 로지스틱 회귀모델이 99.89%의 정확도를 달성했으며, LIME과 SHAP 분석을 통해 마약 거래 텍스트가 일반 상거래의 특징을 교묘하게 모방하는 패턴이 발견되었다. 본 연구는 SNS 마약 거래의 언어적 특성을 체계적으로 규명하고 효과적인 탐지 방안을 제시함으로써, 온라인 마약 거래 문제에 대한 실효성 있는 대응 방안을 제공했다는 데 의의가 있으며, 다양한 사이버 범죄 탐지에도 확장 적용이 가능할 것으로 기대된다.","This study proposed effective detection methods for responding to increasing drug trans actions on SNS platforms and for continuously evolving slang usage. Using mixed data from suspected drug transaction and normal posts, a systematic analysis was performed using natural language processing and machine learning techniques. The analysis revealed four linguistic patterns in SNS drug transaction texts: metaphors, similes, double en tendres, and descriptions. Through TF-IDF and Word2Vec analyses, we confirmed that these texts formed dense semantic clusters and utilized covert coding through hashtags. In the anomaly detection model experiments, the logistic regression model achieved 99.89% ac curacy, and LIME and SHAP analyses revealed patterns in which drug transaction texts subtly mimicked the characteristics of general commerce. This study is significant for systematically identifying the linguistic characteristics of SNS drug transactions proposing effective detection methods, providing practical countermeasures for online drug trafficking issues. It is expected to be applicable for detecting various types of cybercrime."
스마트워치의 PPG 신호를 이용한 신변보호 대상자의 심리적 위험 감지,2025,"['위험감지', 'PPG 신호', '머신러닝', '스마트워치', 'Dangerous emotion detection', 'PPG signals', 'machine learning', 'smartwatch']","본 연구에서는 스마트워치로부터 측정된 짧은 길이의 PPG 신호를 이용해 위험을 느끼는 감정을 추론하는 기계학습 모델을 제안한다. 지도학습에서는 정확하게 참 값이 기록된 학습데이터가 필요하다. 그러나, 위험 분류를 목표하는 실험에서 참가자들이 느끼는 위험의 정도 차이 때문에 학습데이터에 참 값을 기록하기 어렵다. 본 연구의핵심은 학습 데이터에서 모호하게 레이블 된 데이터를 제거하는 알고리즘을 개발하여 결과적으로 추론 모델의 정확성을 향상시키는 것이다. 학습데이터는 긍정/부정 영상 시청을 통해 수집하였고, 추론 정확도는 공포 VR 게임을수행하는 참가자들의 PPG 신호를 이용하였다. 기존의 PPG를 이용한 감정 추론 방법들과 비교를 통해 제안한 방법의 우수성을 입증하였다.","This paper proposes a machine learning approach to detect dangerous emition using short-term PPG (Photoplethysmogram) signals from a commercial smartwatch. In supervised learning, having accurately annotated training data is essential. However, a key challenge in emition detection problem is the uncertainty regarding how accurately data labeled as ”danger” reflects actual dangerous responses, since participants may react differently to the same experiments. The main contribution of this paper is the development of a feature selection method to remove ambiguously labeled training data, thereby improving the accuracy of the prediction model. In the test, PPG measurements were collected from participants playing a horror VR (Virtual Reality) game, and the proposed method validated the superiority of our proposed approach in comparison with other methods."
스마트 농업의 작물 생존 예측을 위한 인공지능 분석,2025,"['Smart agriculture', 'Agricultural productivity', 'Machine learning', 'Deep learning', 'SHAP analysis', '스마트 농업', '작물 생존', '머신러닝', '딥러닝', 'SHAP 분석']",,"Smart agriculture has been evolving by integrating ICT, IoT, and AI technologies to maximize agricultural productivity and optimize resource utilization. This study aims to predict crop survival in smart agriculture using various machine learning and deep learning models while analyzing and comparing their performance. To achieve this, Random Forest, XGBoost, LightGBM, LSTM, and GRU models were implemented, and their predictive performance was evaluated using accuracy, precision, recall, and F1-score. SHAP analysis was applied to enhance model interpretability and assess the impact of key variables on prediction outcomes. The experimental results indicate that XGBoost and LightGBM demonstrate the highest predictive performance, confirming the effectiveness of tree-based boosting models in crop survival prediction. Notably, SHAP analysis reveals that variables such as pesticide usage type, estimated insect count, and pesticide application frequency significantly influence the prediction results. This study highlights the potential of AI-based predictive models in smart agriculture and emphasizes the importance of optimizing controllable environmental factors to improve crop survival rates."
농어촌민박의 생존결정요인 분석,2025,"['농어촌민박', '생존분석', '생존 결정요인', '머신러닝기법', '그래디언트 부스팅', 'XGBoost', 'Rural bed and breakfast (B&B) business', 'Survival analysis', 'Survival determinants', 'Machine learning model', 'Gradient boosting', 'XGBoost']","우리나라 농어촌지역은 소득원의 다각화 및 도시민의 관광수요 대응을 위해 농어촌민박사업을 추진하게 된다. 해당 사업은 사업자의 개인적인 소득증대와 더불어 인구 유입, 지역사회 지탱, 지역경제 활성화 등 다방면의 부가가치를 창출한다. 최근 10년간 농어촌민박 수가 약 37.4% 증가한 결과는 소득증대 및 지역활성화의 효과를 방증하는 결과이다. 그럼에도 농어촌민박과 관련한 규제 완화 등은 산업의 양적 팽창을 야기하고, 과잉 경쟁, 초기 정착의 어려움, 품질 저하와 같은 구조적 불안정성에 직면하게 된다. 최근 우리나라는 농어촌민박의 질적 향상을 위한 제도 개선과 관리 강화 방안을 마련하고 있지만, 산업의 지속가능성에 영향을 미치는 결정요인에 대한 정보는 부족한 실정이다. 따라서 농어촌민박의 생존현황과 생존결정요인을 분석하고, 지속가능성을 위한 정책적 제언이 필요하다. 본 연구에서는 행정안전부가 제공하는 지방행정인허가 데이터 등 공공데이터를 바탕으로 머신러닝기법을 적용하여 전국 농어촌민박의 지속성을 실증하였다. 그 결과, 농어촌민박의 생존에 영향을 미치는 요인은 업체특성 중 주택면적, 소재지 면적, 객실 수와 건물특성인 소화기, 비상경보시설, 그리고 지역특성인 동종업체 수, 의료기반시설, 도농 교류프로그램 및 인프라, 교통인프라로 나타났다. 연구결과를 토대로 산업의 지속가능한 발전을 위한 구체적인 전략을 모색하였다.","Rural communities in South Korea are engaging in the rural bed-and-breakfast (B&B) business to diversify their income sources and meet the growing tourism demand of urban residents. These businesses bring multi-dimensional benefits, including increased personal income for operators, population growth, community sustainability, and a boost to the local economy. The 37.4% increase in rural B&B businesses over the past decade underscores the effectiveness of these businesses in generating income and regional development. Nevertheless, the deregulation of the rural B&B sector has led to a quantitative expansion of the industry, resulting in structural weaknesses such as market saturation, establishment barriers for newcomers, and a deterioration in service quality. Although South Korea has recently implemented institutional reforms and strengthened the regulatory framework to improve the quality of the rural B&B industry, there is still a significant knowledge gap regarding the determinants of the industry’s sustainability. Therefore, in this study, the survival patterns of rural B&Bs and their determinants were analyzed to develop policy recommendations to promote sustainability. Using a machine learning model, this study empirically examined the sustainability of rural B&B operations nationwide using local administrative licensing data provided by the Ministry of the Interior and Safety. The results indicate that the determinants of survival include business factors such as floor area, site area, and number of rooms, building factors such as the number of fire extinguishers and emergency alarm systems, and regional factors such as the number of similar establishments, medical infrastructure, urban-rural exchange programs and infrastructure, and transportation infrastructure. Based on these findings, strategic measures for the sustainable development of the industry have been proposed in this study."
Flight Delay Prediction Based on Delay Time Using Predictive Analytics,2025,"['Flight delays', 'Deep learning', 'Machine learning', 'Random forest', 'Decision tree', 'Logistic regression', 'Long short-term memory']",,"Flight delays remain widespread problem in the airline sector. Delays may arise from various circumstances, including meteorological conditions, technical failures, air traffic control limitations, and airline-specific complications like crew scheduling concerns, disrupting passengers' itineraries, airline operations, and overall financial outcomes. Therefore, creating predictive models and operational techniques that assist airlines in optimising scheduling, and enhancing decision-making and consequences of delays is the solution to the problem. Although various predictive algorithms and studies have done to anticipate aircraft delays. However, many current models either insufficiently integrate extensive meteorological or concentrate exclusively on particular routes or regions which lacks the ability to generalise their conclusions to a wider context. This creates a deficiency to forecast delays on a broader more dynamic scale as weather patterns particularly severe and unforeseen conditions. Therefore, the work focus on the development of a cutting-edge system designed to focus on critical influence of meteorological conditions with an innovative methodology for predicting flight delays using modern machine learning (ML) and deep learning (DL) procedures. Here, ML algorithms like decision tree, logistic regression, and random forest along with proposed DL method called long short-term memory (LSTM) is applied on flight delay dataset. This paper aims to find and improve the substantially operational efficiency in airline sector by allowing airlines to predict and alleviate flight delays more precisely to hence enhancing passenger happiness and minimising financial losses. DL techniques facilitate identification of intricate, non-linear correlations within the data, whereas ML approaches enhance the optimisation and interpretation of the forecasting process."
AI 기반 스마트차량 자동내부환경개선 시스템 방안 연구,2025,"['Artificial Intelligence', 'HRV', 'machine learning', 'IoT']","현재 차량 환경 최적화 시스템은 운전자의 심리적 상태와 감정 상태를 실시간으로 반영하지 못해 차량 내 사용자경험과 안전성을 저하시키는 문제를 야기하고 있다. 이러한 문제를 해결하기 위해 본 논문에서는 AI와 IoT 기술을 활용하여 효율적으로 실시간 데이터를 수집하고 처리하는 스마트 시스템을 제안하고 그 성능을 검증하였다. 본 논문에서 제안한 시스템은 심박수와 심박 변이성(IBI(Inter Beat Interval), SDNN(Standard Deviation of Average NN interval), RMSSD(Root Mean Square of the Successive Differences, pNN50(Percentage of NN intervals differing by more than 50ms))[1] 데이터를 수집하고, 이를 기반으로 머신러닝 모델(Random Forest, SVM(Support Vector machine), Gradient Boosting)을 사용해 운전자의 스트레스 상태를 분류하였다. 또한, 차량내부 환경을 자동으로 최적화하기 위해 음악 추천 및 온도, 조명 제어 기능을 구현하였다. 스트레스 상태 분류 모델은99.87%의 높은 정확도와 1.00의 F1-Score를 기록하며, HRV 데이터를 활용한 스트레스 감지의 가능성을 확인하였다.모의실험 결과, 제안된 시스템은 높은 정확도로 운전자의 상태를 분류하였으며, 이를 통해 차량 내 사용자 경험과 안전성을 개선할 수 있음을 확인하였다.","Current vehicle environment optimization systems are unable to reflect the psychological and emotional state of the driver in real time, which leads to problems that reduce the user experience and safety in the vehicle. To solve these problems, this paper proposes a smart system that efficiently collects and processes real-time data using AI and IoT technologies, and validates its performance. The system proposed in this paper collects heart rate and heart rate variability(IBI,SDNN RMSSD,pNN50)[1] data, and classifies the driver's stress state using machine learning models (Random Forest, SVM, Gradient Boosting) based on these data. In addition, music recommendations, temperature and lighting controls were implemented to automatically optimise the cabin environment. The stress state classification model achieved a high accuracy of 99.87% and an F1 score of 1.00, confirming the feasibility of stress detection using HRV data. Simulation results showed that the proposed system classified the driver's state with high accuracy, which can improve the user experience and safety in the vehicle."
Hybrid ELM models-based strength prediction model for self-compacting-concrete,2025,"['green infrastructure', 'living infrastructure', 'machine learning', 'self-compacting concrete']",,"The study presents a review on hybrid Extreme Learning Machine (ELM)-based soft-computing methodology for computing the compressive strength of self-compacting concretes (SCC). Due to its advantages of better quality and aesthetic, as well as suitability for addition of supplementary environment-friendly cement substitutes, SCCs have gathered enormous attention in construction engineering. While the strength prediction of SCCs remains problematic due to constraints like complex constitution, ML-based methodologies have received enormous attention in the field. The application of hybrid ELM models is novel in the field of SCCs, though it has been proved to be a robust alternative to traditional methods in many other fields of engineering. The study develops three hybrid ELM models by integrating three efficient optimization algorithms to the ELM algorithm, namely Particle Swarm Optimization (PSO), Improved firefly algorithm (IFF) and Equilibrium Optimizer (EO). The results report that ELM-EO (R<sup>2</sup> = 0.916, RMSE = 0.065) is the best performing model in comparative analysis and outperforms the traditional ELM model. The results of the study are compared from the previous studies in literature and the ELM-EO model is concluded as best among them. The proposed methodology provides a robust and efficient alternative for SCC strength prediction, offering potential for practical implementation in the construction industry."
변동성이 큰 누수음 탐지를 위한 푸리에 변환 및  MFCC 기반 특징 추출 기법,2025,"['Anomaly  detection', 'Leakage', 'Machine  learning', 'Preprocessing', 'Water  distribution  network', '상수관망', '누수', '기계학습', '특징  추출', '이상감지']","상수도  배관에서  누수  또는  이상을  감지하는  기계학습  및  인공신경망  분류  모델에  대한  연구가  활발히  진행되어  왔다.  그러나  누수음 데이터는  시간과  환경에  따라  계속  변동하기  때문에,  입력  데이터의  변화에도  일정  수준  이상의  분류  성능을  유지하는  분류  모델을 찾는  데  어려움이  있다.  본  연구에서는  모델  선택과  초매개변수  조정보다  데이터  전처리  방법이  분류  성능  향상에  더  큰  영향을  미친다는 점에  주목했다.  변동성이  큰  누수음의  특징을  효과적으로  추출하기  위해  푸리에  변환  및  MFCC(Mel-Frequency  Cepstral  Coefficients)를사용하였으며,  일부  정보가  중복될  가능성을  고려하여  다중공선성에  덜  민감한  트리  기반  모델을  사용해  누수음의  분류  성능을  평가했다.  연구  결과,  푸리에  변환과  MFCC를  결합한  데이터  세트를  사용했을  때  LightGBM  모델의  분류  정확도가  84.62%로  나타났으며, 각각의  전처리  방법을  단독으로  사용했을  때보다  더  높은  성능을  달성하였다.  이  결과는  두  전처리  방법의  상호  보완적  특성이  분류 성능  향상에  기여했음을  입증하며,  상수도  관망  누수  탐지  시스템  개발에  중요한  기여를  할  것으로  기대된다.","Research  on  machine  learning  and  neural  network  classification  models  for  detecting  leaks  or  anomalies  in  water  distribution pipelines  has  been  actively  conducted.  However,  leakage  noise  data  vary  significantly  over  time  and  across  environmental conditions,  making  it  challenging  to  develop  models  that  maintain  consistent  classification  performance  despite  input  data  variations.  This  study  emphasizes  that  data  preprocessing  methods  have  a  greater  impact  on  improving  classification performance  than  model  selection  or  hyperparameter  tuning.  To  effectively  extract  features  from  highly  variable  leakage noise,  Fourier  transform  and  Mel-frequency  cepstral  coefficients  (MFCC)  were  utilized.  Additionally,  a  tree-based  model, less  sensitive  to  multicollinearity,  was  employed  to  evaluate  classification  performance.  The  results  demonstrated  that  combining  Fourier  transform  and  MFCC  features  improved  the  classification  accuracy  of  the  LightGBM  model  to  84.62%,  outperforming  each  preprocessing  method  used  independently.  This  finding  highlights  the  complementary  strengths  of  these  preprocessing  techniques  in  enhancing  classification  performance.  The  proposed  approach  is  expected  to  make a  significant  contribution  to  the  development  of  robust  water  distribution  pipeline  leak  detection  systems."
안면마비 평가 도구에 관한 개발 현황 리뷰: 자동화 방식을 중심으로,2025,"['facial paralysis', 'image processing', 'machine learning', 'deep learning']",,"Objectives : Grading facial paralysis plays a crucial role in establishing treatment plans and determining prognosis. Both domestic and international efforts have actively focused on the development of objective automated grading systems. The purpose of this study is to investigate trends in Automated Facial Palsy Grading Systems through literature search. Methods : Using PubMed, OASIS, and other databases, related research papers published from 2000 to 2024 were analyzed. The studies were analyzed by dividing into Automated Grading Image Processing (2D, 3D, Video), Landmark Assignment and Standard Grading System for comparison.Results : A total of 13 studies were selected in this study. The first article was published in 2013. Studies were rapidly increased since 2019. The mostly used input data was photo. The other data were 3D photo and video. Studies using 68 landmark assignment system were the most prevalent, followed by OpenCV, Manual attachment, and other Machine Learning algorithms. There were 6 studies compared with House-Brackmann grading system, 4 studies compared with Sunny brook facial grading system, 3 studies compared with Nottingham scale and also studies involving Yanagihara grading system, eFACE, electroneurography (ENoG).Conclusions : The automated Grading systems were developed using various technologies, including image processing, automatic landmark assignment, OpenCV, machine learning, and applications. This automated grading systems demonstrated accuracy comparable to or exceeding that of conventional subjective evaluation methods. Moreover, it significantly reduced the time required for facial paralysis assessment, highlighting its potential as a viable alternative to subjective evaluation."
랜덤 포레스트를 통한 전장부품 품목분류 기준 연구,2025,"['전장부품', '품목분류', 'HS코드', '머신러닝', '랜덤 포레스트', 'Automotive Electronics', 'Classification', 'HS Code', 'Machine Learning', 'Random  Forest']","본 연구는 자동차의 전기·전자 부품 및 장치(전장부품)에 대한 적정한 품목분류 기준을 제시하고자 하였다. 본 연구는 머신러닝 모델 중 하나인 랜덤 포레스트(Random Forest)를 사용하여 한국 관세청의 전장부품 품목분류 사례 데이터를 분석하였다. 관세청의 품목분류 사례에서 HS 코드 2단위(류)와 HS 코드 4단위(호)를 타겟변수로, 각 품목에 대한 설명(Description), 결정 사유(Reasoning), 결론(Conclusion)의 세 가지 요소를 독립변수로 사용하여 분류를 시도했다.본 연구는 타겟 변수와 독립변수를 결합한 6가지 모델을 구축하였다. 각 모델에 대하여 GridSearchCV를 통해 하이퍼파라미터를 최적화했으며, 모델의 성능을 정확도, 정밀도, 재현율, 과적합을 검토한 끝에 HS4-DRC와 HS2-DRC 모델을 선택하여 랜덤 포레스트 분석 결과를 제시하였다.본 연구는 피처 중요도 분석을 통해 전장부품의 품목분류 예측에 기여한 요소들을 도출했다. 주요 피처로는 ‘측정’, ‘유량’, ‘검사’, ‘제어’, ‘회로’, ‘감지’, ‘온도’ , ‘기록’, ‘저항’ 등이 확인되었다. 피처 중요도 분석을 바탕으로 전장부품의 기능적 특성과 기술적 특성, 그리고 사용 목적 등을 중심으로 품목분류 기준을 제시하였다.전장부품은 복잡한 특성을 가진 다양한 품목을 일관성 있고 적법하게 분류해야 하기에 품목분류에 어려움이 따른다. 본 연구는 랜덤 포레스트를 통한 품복분류 기준 도출 방안을 제안하며 품목분류가 무역장벽이 되지 않는 데 기여하고자 하였다.","This study aims to propose appropriate classification criteria for automotive electrical and electronic components (automotive electronics). Using Random Forest, a machine learning model, this study analyzed classification case data from the Korea Customs Service. The HS code at the 2-digit (chapter) and 4-digit (heading) levels in this data were set as the target variables, while the description, reasoning, and conclusion of each classification case were used as the independent variables.Six models were constructed by combining different target and independent variables. The hyperparameters of each model were optimized using GridSearchCV, and their performance was evaluated based on accuracy, precision, recall, and overfitting. As a result, the HS4-DRC and HS2-DRC models were selected, and the Random Forest analysis results were presented.This study conducted a feature importance analysis to identify the key factors contributing to the classification of automotive electronics. The major contributing features included ‘measurement’, ‘flow rate’, ‘inspection’, ‘control’, ‘circuit’, ‘detection’, ‘temperature’, ‘recording’, and ‘resistance’. Based on this analysis, classification criteria were proposed, focusing on the functional and technical characteristics of automotive electronics as well as their intended use.Given the complexity and diversity of automotive electronics, consistent and legally compliant classification poses challenges. This study suggests a classification framework using Random Forest and aims to ensure that classification does not become a trade barrier."
고속철도 차량 진동 데이터를 활용한 궤도 품질 진단에 관한 연구,2025,"['궤도품질지수', '궤도틀림', '주성분 분석', '머신러닝', 'Track quality index(TQI)', 'Track irregularity', 'Principal component analysis (PCA)', 'Machine learning']",,"The condition of railway tracks plays a crucial role in ensuring the stability and comfort of train operations.The track quality index serves as a quantitative indicator for evaluating track conditions. The conventional method for evaluating the track quality index relies on the use of a dedicated measurement vehicle for inspection. However, this method poses a challenge in detecting track condition deterioration in real time, as assessments can only be conducted during scheduled measurement intervals. Accordingly, this study diagnosed the condition of the track by training a machine learning model using vibration data collected from an in-service railway vehicle. Compared to other commonly used algorithms, the method of applying principal component analysis to the XGBoost model had the highest coefficient of determination at 0.99. Therefore, efficient track maintenance is possible and railway safety can be further improved through data collected from running vehicles without having to wait for measurement from inspection vehicles."
Methods for identifying health status from routinely collected health data: An overview,2025,"['Routinely collected health data', 'Health status', 'Machine learning algorithms', 'Rule-based algorithms']",,"The use of routinely collected health data (RCD) is currently helping to accelerate publications that evaluate the effectiveness and safety of medicines and medical devices. One fundamental step in using these data is developing algorithms to identify health status for use in observational studies. However, the processes and methodologies for determining health status using RCD remain insufficiently understood. While most current methods rely on the World Health Organization’s International Classification of Diseases (ICD) codes, they may not be universally applicable. Although machine learning methods are promising for more accurately identifying health status, they currently remain underutilized in RCD studies. To address these significant methodological gaps, we outline key steps and methodological considerations for identifying health statuses in observational studies using RCD. This review has the potential to reinforce the credibility of findings from observational studies that use RCD."
만성질환 예측과 상대위험도 산출을 통한 인슈어테크 적용 가능성 연구,2025,"['질병예측모형', '인슈어테크', '보험료 세분화', '보건의료빅데이터', '머신러닝', 'Disease Prediction Model', 'Insurtech', 'Premium Segmentation', 'Healthcare Big Data', 'Machine Learning']","본 연구는 국민건강보험 표본코호트 DB의 세부 의료이용 내역을 활용해 암·뇌·심장질환 등 대표적인 3대 만성질환의 발생을 예측하는 머신러닝 모형을 구현하고, 인슈어테크(InsurTech) 관점에서 건강보험의 가격책정(Pricing)과 인수심사(Underwriting) 분야에  적용 가능성을 검토하였다. 이를 위해 데이터 기반의 변수 선택 전략을 통해 질환 발생의 주요 예측요인을 식별하고, 집단별 상대위험도를 산정하여 기존 보험산업의 표준체와 비표준체 분류체계의 세분화 가능성을 평가하였다. 분석 결과  예측 대상 질환에 따라 예측요인의 구성이 상이하고, 표준체와 간편고지체, 거절체 순으로 상대위험도가 체계적으로 높아지는 양상이 확인되었다. 이는  보건의료 데이터와 머신러닝 기법 활용이 기존 보험산업의 위험분류 체계와 충돌되지 않으면서도 고위험군 내부의 위험을 보다 세분화하여 개인 맞춤형 보험료 책정과 가입대상 확대에 기여할 수 있음을 시사한다.","This study develops a machine learning model predicting the incidence of cancer, cerebrovascular disease, and cardiac diseases using medical utilization data from the National Health Insurance Service cohort database (DB). Adopting an InsurTech perspective, we evaluate the model’s potential to enhance pricing and underwriting in health insurance. The data-driven variable selection identifies critical disease-specific predictors, while segment-specific relative risks are calculated to explore the refinement of traditional insurance risk classifications. Findings reveal distinct predictors by disease and systematically higher relative risks from standard to simplified-issue and declined groups, suggesting that predictive modeling using medical utilization data can refine risk stratification, thus enabling personalized pricing and an expanded underwriting."
Energy Efficiency Optimisation in Wire arc Additive Manufacturing of Invar 36 Alloy via Intelligent Data-Driven Techniques,2025,"['Wire arc additive manufacturing', 'Sustainability', 'Energy consumption', 'Machine learning', 'Genetic algorithm']",,"Nowadays, sustainability of manufacturing processes is a major concern which calls for special efforts to reduce their environmental impact and energy consumption. In additive manufacturing, this issue is even more challenging due to the usually high energy demands of these processes. However, in the era of Industry 4.0, machine learning (ML) techniques, combined with metaheuristic optimization algorithms, offer a powerful solution to explore new, unproven combinations of process parameters that better align with sustainability goals of manufacturing. These methodologies can minimize the need for extensive experimental campaigns and provide a valuable decision-making support tool for goal-oriented process parameters optimization. In line with such approach, this research work introduces an intelligent data-driven methodology using ML to optimize wire arc additive manufacturing (WAAM) of Invar 36 alloy considering both the resulting layer geometry and quality as well as the process energy consumption. An experimental campaign involving WAAM deposition of 15 walls made of Invar 36 alloy using a natural dip transfer welding process was carried out. The data acquired from the WAAM experimental tests were used to develop and train an artificial neural network (ANN) which, on the basis of the process parameters, was able to predict the layer geometry, the specific energy consumption and a specified quality score indicative of the presence of defects. The ANN achieved a high accuracy with 100% F2 score for quality classification, 0.4 mm mean absolute error for layer geometry, and 20 J/mm MAE for specific energy consumption. A genetic algorithm (GA) was then used to identify optimal process parameters able to minimize the specific energy consumption while maintaining quality and smoothness of the deposited layer. The experimental validation carried out using the GA-optimized process parameters in the WAAM process confirmed the reliability of the model, resulting in energy-efficient and defect-free walls."
Mapping forest loss and encroachment drivers using remote sensing data and random forest classification,2025,['Land cover change\xa0· Forest encroachment\xa0· Remote sensing\xa0· Machine learning\xa0· Classifcation'],,"Forest conservation is imperative to safeguard biodiversity and ensure sustainability of ecosystems providing a wide range of ecological and economic benefits. Forests are crucial in carbon sequestration, water regulation, and soil preservation. In Nepal, a stretch of forest has been lost or deteriorated due to human activities, with forest encroachment being a major factor that converts forested land to other uses, such as agriculture, settlements, and commercial zones. Here, we develop a framework to identify drivers of forest encroachment in Sudurpaschim Province (SP) of Nepal. We identified forest loss areas between 1990 and 2020, conducted field data collection for four identified encroachment drivers within the forest loss areas, trained six different machine learning classifiers, and compared their accuracy using field based dataset. The Random Forest classifier outperformed other classifiers with an overall accuracy of more than 81%, a recall of 58%, an F-score of 65%, and a precision of 81%. Therefore, we used the Random Forest model to map these drivers across the study area. Agricultural expansion was the dominant driver (78.21%), followed by settlement expansion (15.97%). Furthermore, the forest change analysis showed that a total of 1,634  km2 of forest was converted to non-forest areas during the study period. Finally, the study provides recommendations to prevent future forest encroachments."
문법 자질을 활용한 한국어 학습자의 쓰기 숙달도 자동 평가 연구,2025,"['한국어교육', '쓰기', '자동평가', '문법 자질', '머신 러닝', 'Korean Language Education', 'Writing', 'Automated Assessment', 'Grammatical Feature', 'Machine Learning']","본 연구는 한국어 학습자의 쓰기 숙달도를 자동으로 평가하기 위해 문법 및 표층 자질을 분석하고 그 타당성을 검증하였다. 이를 위하여 국립국어원의 ‘한국어 학습자 말뭉치’를 연구 대상으로 삼아 초급, 중급, 고급 수준의 쓰기 데이터 총 14,992편을 활용하였다. 자질은 통사적 복잡도, 문법 난이도, 글의 길이, 형태소 사용 분포의 네 가지 자질군으로 구분하여 추출하였다. 피어슨 상관관계 분석과 머신러닝 모델(Random Forest, XGBoost)을 통해 자질의 중요도를 평가한 결과, 문장당 관형형전성어미 수, 3급 문법 토큰 수, 문장 길이 지표, 종결어미 비율 등이 쓰기 숙달도 평가의 주요 지표로 나타났다. 특히 형태소 사용 분포 관련 자질을 추가한 경우 모든 숙달도 수준에서 모델의 분류 성능이 크게 향상되는 것으로 확인되었다. 본 연구의 결과는 한국어 쓰기 숙달도 평가에서 문법 사용 양상의 중요성을 실증적으로 검증하였다는 점에서 의의가 있다. 향후 연구에서는 문법 오류 분석을 함께 고려하거나 중급 학습자의 언어적 특성을 보다 잘 반영할 수 있는 자질 개발이 필요할 것으로 보인다.","This study investigates the automatic assessment of Korean learners’ writing proficiency by extracting and validating grammatical and surface-level features. Using 14,992 essays from the Korean Learners’ Corpus, 101 features were extracted across four categories: syntactic complexity, grammar difficulty, text length, and morpheme usage. Pearson correlation analysis and machine learning models (Random Forest and XGBoost) were employed to identify the most predictive features. Findings indicated that noun modifier endings per sentence,  frequency of Level 3 grammar tokens, average sentence length, and ratios of sentence-final ending emerged as critical indicators of writing proficiency. In addition, integrating morpheme-related features significantly improved classification accuracy across all proficiency levels. The results highlight the importance of grammatical usage patterns in assessing Korean writing proficiency. Future research should include grammatical error analysis and develop additional features that better capture the linguistic characteristics of intermediate-level learners."
시선 데이터기반 초기 문해력 진단지원 서비스,2025,"['문해력', '시선 추적', '초기 문해력', '머신러닝', '진단 웹 서비스', 'Literacy', 'Eye-tracking', 'Early Literacy', 'Machine Learning', 'Web-based Assessment Service']","초등학교 저학년 아동의 초기 문해력 평가나 진단은 지필시험으로는 한계가 있기 때문에, 이 논문에서의 저학년 아동의사전 읽기 능력과 관계없는 시선 데이터를 활용하여 읽기 행동을 정량적으로 분석하는 시도는 유용한 방법 중의 하나이다.초등학교 저학년을 대상으로 글과 그림이 포함된 그림동화 한 페이지를 읽도록 한 뒤, 시선 추적 데이터를 수집하여 초기 문해력수준의 진단을 지원하는 머신러닝 모델을 탑재한 서비스 개발을 제안하였다. 이를 위해 수집된 시선 텍스트 라인별 및 그림영역 응시 비율을 주요 피처로 추출하여, 학습자의 초기 문해력 부진 여부를 시각데이터 기반 진단 및 지원하는 모델링을 하였다.단순 결정트리 모델은 부진 학생에 대한 분류 성능이 매우 낮았으나, SMOTE와 Random Forest 앙상블 기법을 결합한 모델은성능이 대폭 향상되어 시선 데이터 기반 ROI 집중도 분석이 초기 문해력 부진 여부를 효과적으로 진단할 수 있는 서비스의가능성을 제시하였다. 이 진단지원 모델을 탑재한 웹 서비스의 개발은 교사의 주관적 평가에 의존하지 않고, 읽기 행동을 기반으로초기 문해력 부진 여부를 자동 진단할 수 있으며, 향후 초등 저학년은 물론 K-문화 한류로 인하여 한국어 학습을 하는 외국인의읽기 지도 및 개인화 학습 피드백 제공에 활용될 수 있을 것으로 기대된다.","Traditional paper-based assessments often fall short in accurately evaluating early literacy skills among lower elementary students, primarily due to their limited reading experience and developmental variability. This paper proposes an approach that leverages eye-tracking technology to quantitatively analyze reading behaviors, independent of prior reading proficiency. Participants were instructed to read a single page from a picture book containing both text and illustrations, during which their eye movements were recorded. Key features extracted included fixation ratios on text lines and illustration areas. These metrics served as inputs for machine learning models aimed at diagnosing early literacy challenges. Initial models utilizing simple decision trees demonstrated low classification performance for identifying students with reading difficulties. However, integrating Synthetic Minority Over-sampling Technique (SMOTE) with a Random Forest ensemble significantly enhanced model accuracy. The findings suggest that analyzing region-of-interest (ROI) concentration through eye-tracking data can effectively identify early literacy deficits. The proposed web-based assessment tool offers an objective alternative to subjective teacher evaluations, facilitating automated assessments of reading behaviors. This prototype holds promise for informing personalized reading instruction and providing targeted feedback to support early literacy development for elementary students as well as foreigner learning Korean due to the Korean K-culture wave."
"Developing an Explainable Artificial Intelligence System for the Mobile-Based Diagnosis of Febrile Diseases Using Random Forest, LIME, and GPT",2025,"['Natural Language Processing', 'Artificial Intelligence', 'Machine Learning', 'Telemedicine', 'Mobile Applications']",,"Objectives: This study proposes a mobile-based explainable artificial intelligence (XAI) platform designed for diagnosing febrileillnesses. Methods: We integrated the interpretability offered by local interpretable model-agnostic explanations (LIME)and the explainability provided by generative pre-trained transformers (GPT) to bridge the gap in understanding and trustoften created by machine learning models in critical healthcare decision-making. The developed system employed randomforest for disease diagnosis, LIME for interpretation of the results, and GPT-3.5 for generating explanations in easy-to-understandlanguage. Results: Our model demonstrated robust performance in detecting malaria, achieving precision, recall, andF1-scores of 85%, 91%, and 88%, respectively. It performed moderately well in detecting urinary tract and respiratory tractinfections, with precision, recall, and F1-scores of 80%, 65%, and 72%, and 77%, 68%, and 72%, respectively, maintaining aneffective balance between sensitivity and specificity. However, the model exhibited limitations in detecting typhoid fever andhuman immunodeficiency virus/acquired immune deficiency syndrome, achieving lower precision, recall, and F1-scores of69%, 53%, and 60%, and 75%, 39%, and 51%, respectively. These results indicate missed true-positive cases, necessitatingfurther model fine-tuning. LIME and GPT-3.5 were integrated to enhance transparency and provide natural language explanations,thereby aiding decision-making and improving user comprehension of the diagnoses. Conclusions: The LIME plotsrevealed key symptoms influencing the diagnoses, with bitter taste in the mouth and fever showing the highest negative influenceon predictions, and GPT-3.5 provided natural language explanations that increased the reliability and trustworthiness ofthe system, promoting improved patient outcomes and reducing the healthcare burden."
Integrative bioinformatics approaches reveal key hub genes in cyanobacteria: insights from Synechocystis sp. PCC 6803 and Geminocystis sp. NIES-3708 under abiotic stress conditions,2025,['Environmental stresses · Meta-analysis · WGCNA · Machine learning · Gene expression · Cyanobacteria'],,"Background Cyanobacteria, particularly Synechocystis sp. PCC 6803, serve as model organisms for studying acclimation strategies that enable adaptation to various environmental stresses. Understanding the molecular mechanisms underlying these adaptations provides insight into how cells adjust gene expression in response to challenging conditions.Objective To analyze the transcriptome data of Synechocystis sp. PCC 6803 under light, salinity, and iron stress conditions and to identify hub genes potentially involved in stress response, specifically comparing the findings with Geminocystis sp. NIES-3708.Methods A comprehensive bioinformatics approach was applied, integrating meta-analysis, weighted gene co-expression network analysis (WGCNA), and a Random Forest (RF) machine learning algorithm. These approaches underscore the robustness of our findings, allowing for a more nuanced understanding of gene interactions and their functional relevance in stress responses. This methodology was used to identify key hub genes in Synechocystis sp. PCC 6803 that may have conserved roles in Geminocystis sp. NIES-3708. A total of four potential hub genes, including slr1392, slr1484, sll1549, and sll1863, were identified. Among these, only sll1549 had a homolog (GM3708_2556) with 71% sequence similarity and 70% query coverage in Geminocystis sp. NIES-3708. The expression of GM3708_2556 was further evaluated under nitrate, salt, and combined salinity-nitrate stress conditions using RT-qPCR.Results Transcript levels of GM3708_2556 increased significantly under salt stress (3.35-fold, p-value < 0.05) and combined salinity-nitrate stress (2.24-fold, p-value < 0.05) compared to control conditions, while no significant change was observed under nitrate stress alone. These results suggest that GM3708_2556 may play a crucial role in the organism’s response to salt stress, with potential interactions in nitrate metabolism.Conclusion This study highlights the gene GM3708_2556 as a significant factor in salt stress response, with implications for conserved functional roles across cyanobacterial species. Furthermore, the findings have potential relevance to biotechnology, particularly in engineering stress-resistant cyanobacterial strains for applications in sustainable agriculture and bioenergy production."
Shifted and Weighted LFCC Features for Hand Movements Recognition Using EEG Signals,2025,['Brain computer interface · Motor imagery · Features extraction · Machine learning · Genetic algorithm optimization'],,"The Brain computer interface (BCI) technology attracts many researchers due to its vital applications in medicine and biomedical domains. Decoding the motor imagery electroencephalography signals (MI-EEG) to fnd the corresponding brain activities constitutes the core of the BCI system. Researchers use both classical machine learning and deep learning to identify such activities. In this work, left/right hand movement is recognized using MI-EEG signals features. The EEG signal features vector is derived from the wavelet transformation (WT) and the linear frequency cepstral coefcient (LFCC) to feed an SVM classifer. Two publicly available MI-EEG datasets are tested, BCI competition III b and BCI competition IV 2b. Firstly, the classifcation is performed using all features without any modifcation for the LFCC features. Secondly, the LFCC features are shifted and weighted (SWLFCC) by genetic algorithm (GA) to improve the classifcation accuracy. The average classifcation accuracy was improved and achieved 92.19 and 87.23% for BCI competition III b and BCI competition IV 2b datasets respectively. Compared to the works using the same datasets, the performance to identify left and right hand is improved by 2.4% for the BCI competition III b. There was very small improvement for the second dataset though the deep learning was used for the last best accuracy. The novel SWLFCC features showed their efciency in BCI system to identify MI left/right hand movement. The SWLFCC features are tuned by GA optimization to adapt any nonlinearity existing between tasks and MI-EEG signals."
에폭시 고분자 유리전이온도 예측: 데이터 기반 접근,2025,"['epoxy adhesives', 'glass transition temperature', 'RANSAC', 'machine learning', 'anomaly detection', 'property prediction', '에폭시 접착제', '유리전이온도', 'RANSAC', '머신러닝', '이상치 탐지', '물성 예측']","에폭시 접착제는 다양한 산업 분야에서 중요한 역할을 하며 그 특성은 조성 및 경화 조건에 따라 크게 영향을 받는다. 본 연구에서는 에폭시 접착제의 유리전이온도(Tg)를 데이터과학적 기법으로 예측하기 위해 RANSAC과 머신러닝을 결합한 방법을 제안한다. 전체 데이터셋을 사용한 초기 분석에서는 TPOT 모델이 학습 데이터셋에서는 양호한 성능을 보였으나, 테스트 데이터셋에서는 결정계수가 감소하고 RMSE가 증가하는 결과를 나타내었으며, 이는 모델의 일반화 능력 부족을 시사한다. 이 문제를 해결하기 위해 RANSAC을 활용하여 이상치를 식별하고 제거한 후, 실험 데이터를 기반으로 각종 머신러닝 모델을 학습시켰다. 그 결과, Gradient Boosting 모델이 학습 및 테스트 데이터셋에서 각각 0.840, 0.839의 높은 결정계수를 달성하며 우수한 성능을 보였다. 이러한 연구 결과는 계측 노이즈가 큰 고분자의 물성 예측과 같은 산업적 응용에 대한 중요한 정보를 제공할 것으로 기대된다.","Epoxy adhesives play a crucial role in various industrial fields. Their properties are significantly influenced by composition and curing conditions. This study proposes a method that combines RANSAC and machine learning techniques to predict the glass transition temperature (Tg) of epoxy adhesives. Initial analysis using the full dataset shows that while the TPOT model performs well on the training dataset, its performance on the test dataset reveals a decrease in the coefficient of determination and an increase in RMSE, indicating a lack of generalization ability. To address this issue, RANSAC is employed to identify and remove outliers, and various machine learning models are subsequently trained on the refined dataset. The results demonstrate that the Gradient Boosting model achieves a high performance with R2 values of 0.840 and 0.839 for the training and test datasets, respectively. These findings provide valuable insights for predicting polymer properties with high measurement noise, offering significant implications for industrial applications."
Remote monitoring and components abnormality detection in smart  vertical farming systems: A review,2025,"['Precision agriculture', 'Remote monitoring', 'Signal processing', 'Machine learning', 'Vertical farm', 'Smart agriculture']",,"The challenges of global food security have been increased by rapid urbanization, climate change, and the decrease of land for agriculture, particularly in urban areas with high populations. Smart vertical farming systems have emerged as a promising solution to address food security challenges associated with rapid urbanization, climate change, and land scarcity. These systems support controlled environment agriculture (CEA) technologies and automation to maximize crop yield in limited urban spaces. However, the complexity of their operation requires efficient remote monitoring and rapid detection of component abnormalities to ensure reliability, reduce operational downtime, and optimize resource use. This review survey the current status in remote sensing, data acquisition, and monitoring solution using internet of thing (IoT) deployed in smart vertical farms. Advanced technologies allow for precise control over the microclimate within vertical farms. Moreover, sensor data are processed to ensure accuracy and then analyzed using machine learning techniques for both data classification and anomaly detection. The integration of IoT and machine learning is further facilitating predictive maintenance and early detection of abnormalities, including equipment failures or pest infestations. The used of remote monitoring to control farm conditions via mobile apps, can enhances growing conditions and increase productivity and crop quality. Despite the effectiveness of the smart farm technology in monitoring environmental conditions, it does not explicitly address potential challenges such as the initial setup costs, power consumption, and maintenance of the IoT systems. Nonetheless, the applications of remote monitoring and abnormal detection in smart vertical farming systems offering enhanced productivity and sustainability of future farming operations. Further studies can be conducted to enhance the methods and deal with these limitations."
Day-Ahead Prediction of PV Power Output: A One-Year Case Study at Changwon in South Korea,2025,['Day-ahead Forecasting · Long-term Experimental Results · Machine Learning Based PV Prediction · PV Power Prediction'],,"This paper is a one-year case study of day-ahead prediction of PV output at Changwon in South Korea. We are focused on day-ahead hourly PV power forecasting and long-term experiments in this paper. We introduce three machine learning based forecasting methods that predict hourly PV power for the next day at midnight, and show performance of them for a 51 kW PV system located at Changwon for a year. Our methods learn relationship of historical meteorological factors, and then predict 24 h PV power considering the trained relationship and weather forecasts from weather forecasting organizations. We show monthly performance of all the proposed methods and a persistence model for a year. Since South Korea is located in a temperate zone with four distinct seasons, and has complex climate characteristics, it is difficult to show actual performance of PV forecasting methods by short-term experimental results. We believe that long term experimental results in this paper are valuable data for the next studies."
Prediction of the ROP based on GA-LightGBM and drilling data,2025,"['Rate of penetration', 'drilling data', 'machine learning', 'GA-LGBM model', 'intelligent prediction']",,"Constructing oil and gas wells is one of the most expensive activities in the petroleum sector, and increasing drilling speed is crucial for reducing costs, minimizing non-productive time (NPT), and improving efficiency. To address this challenge, a data-driven predictive model for mechanical drilling speed was developed using an artificial intelligence approach. Several machine learning algorithms – including decision trees, support vector regression, k-nearest neighbors, neural net- works, XGBoost, and LightGBM – were selected to thoroughly investigate the nonlinear relation- ship  between  drilling  data  and  the  rate  of  penetration  (ROP).  These  models  were  trained, evaluated,  and  compared,  with  results  indicating  that  the  LightGBM  algorithm  provided  the most accurate ROP predictions. Building on this, the LightGBM model was further refined using cross-validation techniques and a genetic algorithm (GA) to optimize its hyperparameters, result- ing in even greater accuracy. The research findings demonstrate that the GA-LightGBM algorithm achieves high precision in ROP prediction on the test set (MAE = 2.39, MSE = 10.53, R2 = 0.93). This model effectively predicts mechanical drilling speed in various well sections, thereby aiding in optimizing the drilling process, improving production efficiency, and reducing costs"
Transparent and Accurate Diabetes Prediction via Explainable AI Techniques,2025,"['Explainable AI', 'SHAP', 'LIME', 'Ensemble Learning', 'Diabetes Prediction', 'Medical Diagnosis', 'SMOTE']",,"We designed an explainable AI system to predict diabetes by integrating ensemble learning models and interpretability tools. Traditional diagnostic models often lack transparency, making them less suitable for clinical applications where interpretability is essential. This study aims to design an explainable artificial intelligence (AI) system for diabetes prediction that balances predictive accuracy and interpretability. To achieve this, we developed an ensemble model combining Random Forest, XGBoost, and Logistic Regression within a Voting Classifier framework. The Synthetic Minority Oversampling Technique (SMOTE) was employed to address class imbalance in the dataset, ensuring reliable predictions across both majority and minority classes. For interpretability, SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) were integrated into the system to provide global and local explanations of model predictions. Experimental results demonstrated the ensemble model's high performance, achieving a recall score of 0.846 and an AUC-ROC score of 0.874, which are crucial metrics in minimizing false negatives in medical diagnoses. Key features such as BMI, glucose level, and age were identified as significant contributors to diabetes risk. The integration of explainability tools ensures that healthcare professionals can understand both overarching patterns and patient-specific predictions, fostering trust in clinical decisionmaking.This approach bridges the gap between complex machine learning models and practical medical applications, offering a robust and transparent tool for improving patient outcomes."
The Clinical Utility of Biomarkers in Diagnosing Major Depressive Disorder in Adults: A Systematic Review of Literature From 2013 to 2023,2025,"['Depression', 'Biomarker', 'Blood', 'Neuroimaging', 'Neurophysiology', 'Machine learning.']",,"Objective The variety and efficacy of biomarkers available that may be used objectively to diagnose major depressive disorder (MDD) in adults are unclear. This systematic review aims to identify and evaluate the variety of objective markers used to diagnose MDD in adults.Methods The search strategy was applied via PubMed and PsycINFO over the past 10 years (2013–2023) to capture the latest available evidence supporting the use of biomarkers to diagnose MDD. Data was reported through narrative synthesis.Results Forty-two studies were included in the review. Findings were synthesised based on the following measures: blood, neuroimaging/neurophysiology, urine, dermatological, auditory, vocal, cerebrospinal fluid and combinatory—and evaluated based on its sensitivity/specificity and area under the curve values. The best predictors of blood (<i>MYT1</i> gene), neuroimaging/neurophysiological (5-HT1A auto-receptor binding in the dorsal and median raphe), urinary (combined albumin, AMBP, HSPB, APOA1), cerebrospinal fluid-based (neuron specific enolase, microRNA) biomarkers were found to be closely linked to the pathophysiology of MDD.Conclusion A large variety of biomarkers were available to diagnose MDD, with the best performing biomarkers intrinsically related to the pathophysiology of MDD. Potential for future research lies in investigating the joint sensitivity of the best performing biomarkers identified via machine learning methods and establishing the causal effect between these biomarkers and MDD."
법안 발의자 특성이 국회 법안 가결에 영향을 미치는가?: 20대 및 21대 국회의원 발의 법안을 대상으로 한 로지스틱 회귀분석과 SHAP(SHapley Additive exPlanations) 분석의 통합적 접근,2025,"['국회의원 발의 법안', '법안 가결', '머신러닝', 'National Assembly Member', 'Member-Initiated Bill', 'Bill Passage', 'Machine Learning']",,"The National Assembly introduces over 5,000 bills annually, with approximately 35% of these bills passing the final plenary session to become law. Given that the legislative process typically spans one to two years, predicting the likelihood of a bill’s passage can provide critical insights for sponsors and policy stakeholders, and enhancing policy effectiveness and legislative efficiency. This study examines the factors influencing the passage outcomes of 45,248 bills introduced in 20th and 21st National Assembly sessions, with a specific focus on the bill sponsors. Utilizing traditional linear regression models and machine learning techniques, the analysis reveals that alignment between the standing committee of the bill sponsor and the standing committee overseeing the bill significantly impacts the likelihood of passage. Additionally, bills sponsored by proportional representatives, member for the ruling party, and legislators in their second or third terms, who secure endorsements from 11 to 20 colleagues, are more likely to be enacted. The SHAP(SHapley Additive exPlanations) analysis identifies the following factors as influential: alignment with the relevant standing committee, the sponsor’s legislative experience, the number of co-sponsors, ruling and opposition parties, unionization status, and the type of election. These findings suggest several policy implications. They highlight the importance of contributing to the democratic and efficient operation of the National Assembly and provide valuable information for voters to make informed decisions in parliamentary election."
토픽 기반의 특허맵을 통한 스마트 항만 기술 동향 분석,2025,"['Smart port', 'Technological forecasting', 'Patent analysis', 'Machine learning', 'Topic modeling', 'Generative Topographic Mapping (GTM)', '스마트 항만', '기술 예측', '특허 분석', '기계학습', '토픽 모델링']",,"As the digitalization of the port industry accelerates, this study aims to identify core and vacant technologies related to smart ports using machine learning methods and propose development strategies for each technology. We applied TF-IDF (Term Frequency-Inverse Document Frequency) to patent data on smart port technologies to extract key terms. Using LDA (Latent Dirichlet Allocation) topic modeling, we identified core technologies such as container scanning systems, port simulation, smart containers, shipping scheduling algorithms, object detection for port security, remote control-based autonomous ships, and autonomous vehicles in ports. Furthermore, we generated a technology map using GTM (Generative Topographic Mapping), identifying autonomous vehicles in ports as a vacant technology."
전기차 리튬배터리 열폭주 사전탐지시스템 설계 연구,2025,"['Lithium-ion Battery', 'Thermal runaway', 'Machine learning', 'Deep learning', '리튬이온 배터리', '열폭주', '머신러닝', '딥러닝']","에너지의 저장 및 활용을 위해 리튬이온 배터리가 많이 활용되고 있으나, 연쇄 발열 반응인 열폭주는 연쇄적인 발열 현상과 폭발을 동반하여 위험 요소가 되고 있다. 이러한 위험 요소를 해결하기위해 많은 연구가 진행됐으나 사전탐지 시스템으로 현실에 적용하기 위한 연구는 많이 진행되지 않았다. 본 연구는 전기차 리튬이온 배터리의 열폭주 사전탐지 시스템 설계를 위해 수행되었다. 열폭주 원인과 특성에 관해 연구하였고, 열폭주를 사전에 진단하기 위한 매커니즘과 기존 진행된 머신러닝과 딥러닝 알고리즘에 관해 연구하였다. 현실적으로 적용하기 위한 고려사항과 시스템으로 구축하는 데 필요한 기능요소를 설계하였다. 사전탐지 매커니즘 및 기능요소 설계를 통하여 향후 시스템 구축할 때필요한 주요 기능요소 및 동작 매커니즘 구현에 활용할 수 있다.","Lithium-ion batteries are widely used for energy storage and utilization; however, thermal runaway—a chain reaction accompanied by excessive heat and potential explosions—poses a significant safety risk. Although extensive research has been conducted to address these risks, relatively few studies have focused on developing early detection systems for practical application. This study was conducted to design a thermal runaway early detection system for lithium-ion batteries used in electric vehicles. It investigates the causes and characteristics of thermal runaway and explores mechanisms for early diagnosis, as well as existing machine learning and deep learning algorithms relevant to the task. These insights can be applied to the future construction of practical early detection systems by providing essential functional elements and operational mechanisms."
데이터 기반 경북의 재난 위험 우선순위에 관한 연구  - 자연재난을 중심으로 -,2025,"['Disaster Risk Prioritization', 'AHP(Analytic Hierarchy Process)', 'Machine Learning', 'Disaster Risk Index(DRI)', 'Disaster Risk Index Change Rate(DRICR)', '재난 위험 우선순위', 'AHP', '머신러닝', '재난위험지수', '재난위험지수 증감률']","본 연구는 11년간의 재난 데이터 분석을 통해 경상북도의 자연재난 위험을 평가하고 우선순위를 도출하는 연구를 수행하였다. 경북에서 주로 발생하는 재난 유형과 재난 피해 지표를 선정하였으며, AHP(Analytic Hierarchy Process) 분석과 머신러닝 분석 방법을 이용하여 지표별 가중치를 산정한 후, 마지막으로 경북의 재난 위험 우선순위를 정량적으로도출하였다. 연구 결과, 태풍, 하천, 지진, 산사태 등의 재난이 경북 지역에서 가장 큰 영향을 미치는자연재난으로 나타났다. 또한, 재난위험지수와 재난 위험 증가율을 활용하여 재난별 위험도를 비교 분석하였으며, 이를 통해 경북 지역에서 우선적으로 관리해야 할 자연재난을 도출하였다. 본 연구의 결과는 경북 지역의 재난 대응 및 관리 전략 수립에 유용한 기초자료로 활용될 것으로 기대된다","This study analyzes 11 years of disaster data to assess and prioritize natural disaster risks in Gyeongbuk. Key disaster types and damage indicators were selected, and AHP and machine learning methods were applied to determine indicator weights.The results show that typhoons, earthquakes, rivers and landslides are the most significant natural disasters in the region. By utilizing the Disaster Risk Index (DRI) and its change rate(DRICR), disaster risks were quantitatively evaluated. This study is expected to serve as a valuable reference for disaster management and policy development in Gyeongbuk."
효율적인 추천 시스템의 기술적 분석에 관한 연구,2025,"['Recommendation Systems', 'Artificial Intelligence', 'Collaborative Filtering', 'Machine Learning', 'Data Mining', 'Reinforcement Learning', '추천 시스템', '인공지능', '협업 필터링', '머신러닝', '데이터 마이닝', '강화 학습']","추천 시스템은 사용자의 관심사를 분석하여 선호도를 예측하고, 맞춤형 콘텐츠를 제공하는 기술로 빠르게 발전하고 있다. 이 기술은 YouTube, 아마존, 쿠팡, 네이버 쇼핑과 같은 다양한 온라인 플랫폼에서 사용자 경험을 극대화하는 데 중요한 역할을 한다. 사용자의 이전 행동을 학습하고 현재의 취향을 반영함으로써 더욱 정교한 개인화 서비스를 가능하게 한다. 본 논문에서는 다양한 응용 분야의 동향을 분석하여 인공지능 기술이 추천 시스템 개발에 어떻게 기여하는지 기술한다. 또한 대표적인 문제인 콜드 스타트 ​​문제와 알고리즘 편향에 관해서 기술한다. 따라서 사용자의 선호도와 행동을 분석하여 개인화된 콘텐츠, 제품, 서비스를 제공하는 전자상거래, 온라인 광고, 스트리밍 서비스 등 추천 시스템이 적용되는 다양한 분야에서 만족도를 높일 수 있다.","Recommendation systems are rapidly developing as a technology that analyzes users' interests, predicts preferences, and provides customized content. This technology plays an important role in maximizing the user experience on various online platforms such as YouTube, Amazon, Coupang, and Naver Shopping. It enables more sophisticated personalized services by learning users' previous behaviors and reflecting their current tastes. In this paper, we analyze trends in various application fields and describe how artificial intelligence technology contributes to the development of recommendation systems. We also describe representative problems such as the cold start problem and algorithm bias. Therefore, it can increase satisfaction in various fields where recommendation systems are applied, such as e-commerce, online advertising, and streaming services, which provide personalized content, products, and services by analyzing users' preferences and behaviors."
A Big Data Analysis of Gasoline Price Information Platform and Market Competition,2025,"['Information', 'Competition', 'Fuel Price', 'OPINET', 'Machine Learning. JEL Classification: D4', 'L1']",,"This study investigates how the introduction and subsequent diffusion of OPINET, a government-operated online platform that provides real-time fuel price information to consumers in South Korea, has influenced the competitive dynamics of the retail gasoline market. Using a comprehensive dataset of 931,460 station-level price observations collected over a five-year period, we analyze whether and how increased information transparency has altered the pricing strategies of gas stations. To overcome the limitations of conventional regression models, we employ machine learning techniques that capture complex interactions and assess price differentials under varying degrees of geographic competition, as measured by the distance to the nearest competitor. Our empirical findings indicate that as OPINET became more widely used and accessible, gas station pricing behavior exhibited increased responsiveness to the local competitive environment, particularly in markets with relatively dense station networks. This pattern suggests that enhanced visibility of price information may, under certain conditions, facilitate more competitive pricing and improve market efficiency. However, the results do not imply that OPINET universally promotes competition in all contexts or regions. Instead, the effects appear to depend on local market structure and consumer engagement with the platform. The study offers nuanced policy implications regarding the design of digital information systems to support competition and improve consumer outcomes in retail markets."
저작권법에서 바라본 데이터 윤리,2025,"['Data Ethics', 'Fair Use', 'Presentation Systems', 'Machine Unlearning', 'Notice & Take Down', '데이터 윤리', '공정이용', '표시제도', '머신 언러닝', '게시중단']",,"The copyright law protects the rights of creators and at the same time ensures fair use, thereby promoting a balance of cultural and industrial development. As large amounts of data are used due to the development of AI technology, the conflict between copyright law and data ethics is intensifying. In particular, the legal limitations of Fair Use and Text and Data Mining (TDM) are emerging as important issues in the AI learning process. In the process of AI learning vast amounts of data, debates over how copyright law will be applied are continuing, and clear standards are required for the extent to which fair use can be applied to AI learning data. In addition, data ethics acts as an important factor in ensuring the fairness of AI model learning and results, but it is still unclear how ethical considerations should be harmonized with legal regulations.This article aims to analyze the relationship between copyright law and data ethics, review the extent to which data use for AI learning can be legally permitted, and review various systems or technologies related to them, such as labeling, suspension of posting, and machine unlearning, presented as legal and ethical measures. Through this, we intend to find a direction to strengthen legal clarity while maintaining a balance between AI technology development and copyright accessibility."
다중공선성하에서버스승객수요예측모델링,2025,"['Bus Passenger Demand', 'Industrial Factors', 'Multicollinearity', 'PCA', 'Machine Learning', 'Deep Learning', 'Variable Selection', 'Predictive Modeling']",,"Purpose: This study aims to first develop a bus passenger demand prediction model based on industrial factors,population, and traffic dataunder multicollinearity. It can help Busan bus operation.Methods: In orderto address the multicollinearity issues, the research mainly considers PCA (PrincipalComponent Analysis), MLR (Multiple Linear Regression), machine learning (GBDT (Gradient Boosted DecisionTrees), RF (Random Forest), and deep learning (MLP (Multi-Layer Perceptron), LSTM (Long Short-TermMemory)), and variable selection for predictive modeling.Results and Conclusion: The industrial factors, population and traffic datasignificantly explain the bus pas-senger demand. The RF provides the best prediction performance."
Feature Selection for Hypertension Risk Prediction Using XGBoost on Single Nucleotide Polymorphism Data,2025,"['Single Nucleotide Polymorphism', 'Hypertension', 'Prediction Methods', 'Machine', 'Genetics', 'Machine Learning']",,"Objectives: Hypertension, commonly known as high blood pressure, is a prevalent and serious condition affecting a significantportion of the adult population globally. It is a chronic medical issue that, if left unaddressed, can lead to severe healthcomplications, including kidney problems, heart disease, and stroke. This study aims to develop a feature selection modelusing the XGBoost algorithm to identify specific single nucleotide polymorphisms (SNPs) as biomarkers for detecting hypertensionrisk. Methods: We propose using the high dimensionality of genetic variations (i.e., SNPs) to build a classifiermodel for prediction. In this study, SNPs were used as markers for hypertension in patients. We utilized the OpenSNP dataset,which includes 19,697 SNPs from 2,052 samples. Extreme gradient boosting (XGBoost) is an ensemble machine learningmethod employed here for feature selection, which incrementally adjusts weights in a series of steps. Results: The experimentalresults identified 292 SNPs that exhibited high performance, with an F1-score of 98.55%, precision of 98.73%, recallof 98.38%, and overall accuracy of 98%. This study provides compelling evidence that the XGBoost feature selection methodoutperforms other representative feature selection methods, such as genetic algorithms, analysis of variance, chi-square, andprincipal component analysis, in predicting hypertension risk, demonstrating its effectiveness. Conclusions: We developeda model for predicting hypertension using the SNPs dataset. The high dimensionality of SNP data was effectively managedto identify significant features as biomarkers using the XGBoost feature selection method. The results indicate high performancein predicting the risk of hypertension."
Radiogenomics of intrahepatic cholangiocarcinoma predicts immunochemotherapy response and identifies therapeutic target,2025,"['Intrahepatic cholangiocarcinoma', 'Radiogenomics', 'Multi-omics profiling', 'Machine learning', 'Prediction model']",,"Background/Aims: Identifying patients with intrahepatic cholangiocarcinoma (ICC) likely to benefit from immunochemotherapy, the new front-line treatment, remains challenging. We aimed to unveil a novel radiotranscriptomic signature that can facilitate treatment response prediction by multi-omics integration and multiscale modelling.Methods: We analyzed bulk, single-cell and spatial transcriptomic data comprising 457 ICC patients to identify an immune-related score (IRS), followed by decoding its spatial immune context. We mapped radiomics profiles onto spatial-specific IRS using machine learning to define a novel radiotranscriptomic signature, followed by multi-scale and multi-cohort validation covering 331 ICC patients. The signature was further explored for the potential therapeutic target from in vitro to in vivo.Results: We revealed a novel 3-gene (PLAUR, CD40LG, and FGFR4) IRS whose down-regulation correlated with better survival and improved sensitivity to immunochemotherapy. We highlighted functional IRS-immune interactions within tumor epithelium, rather than stromal compartment, irrespective of geospatial locations. Machine learning pipeline identified the optimal 3-feature radiotranscriptomic signature that was well-validated by immunohistochemical assays in molecular cohort, exhibited favorable external prognostic validity with C-index over 0.64 in resection cohort, and predicted treatment response with an area under the curve of up to 0.84 in immunochemotherapy cohort.We also showed that anti-uPAR/PLAUR alone or in combination with anti-programmed cell death protein 1 therapy remarkably curbed tumor growth, using in vitro ICC cell lines and in vivo humanized ICC patient-derived xenograft mouse models.Conclusions: This proof-of-concept study sheds light on the spatially-resolved radiotranscriptomic signature to improve patient selection for emerging immunochemotherapy and high-order immunotherapy combinations in ICC."
Thermal stratification prediction in reactor system based on CFD simulations accelerated by a data-driven coarse-grid turbulence model,2025,"['Thermal stratification', 'Data-driven turbulence model', 'Machine learning', 'OpenFOAM', 'TensorFlow']",,"Thermal stratification in large enclosures is an integral phenomenon to nuclear reactor system safety. Currently, the effective model for thermal stratification utilizes a multi-scale method that integrates 1-D system-level and 3- D CFD code, which offers thermal stratification details while supplying system-level data across various domains.Nonetheless, harmonizing two codes that operate on different spatial and temporal scales presents a significant challenge, with high-resolution CFD simulations requiring substantial computational resources. This study introduced a data-driven coarse-grid turbulence model based on local flow characteristics at a significantly coarser scale, targeting improved efficiency and accuracy in reactor safety analysis concerning thermal stratification.A machine learning framework has been introduced to expedite the RANS-solving process by coupling OpenFOAM and TensorFlow, which entails training a deep neural network with fine-grid CFD-generated data to predict turbulent eddy viscosity. The feasibility of the developed data-driven turbulence model was proven through the SUPERCAVNA experimental facility problem validation."
Predicting crude oil returns and trading position: evidence from news sentiment,2025,"['Crude oil', 'Prediction', 'Textual analysis', 'Machine learning', 'Trading position']",,"We study the effectiveness of textual information in predicting the returns of crude oil futures and understanding the behavior of market participants. Using a machine learning method to extract oil market sentiment from news articles, we find that the computed sentiment is significantly effective in explaining the crude oil futures returns, while existing textual analyses based on pre-defined dictionaries may mislead the contexts in the oil market. Consistent with previous findings that returns help explain the change in traders’ positions, the sentiment scores based on the machine learning method are also useful in explaining the behavior of different types of traders. Our empirical findings underscore the fact that accurately identifying textual information can increase the accuracy of oil price predictions and explain divergent behaviors of oil traders."
데이터 클래스 불균형 상황에서 설명가능 인공지능을 이용한 기업부도예측모델의 적용과 해석에 관한 연구,2025,"['Bankruptcy Prediction', 'Data Imbalance', 'eXplainable AI', 'Machine Learning', 'SHAP']",,"This study aims to improve the interpretability and transparency of forecasting results by applying an explainable AI technique to corporate default prediction models. In particular, the research addresses the challenges of data imbalance and the economic cost asymmetry of forecast errors. To tackle these issues, predictive performance was analyzed using the SMOTE-ENN imbalance sampling technique and a cost-sensitive learning approach. The main findings of the study are as follows. First, the four machine learning models used in this study (Logistic Regression, Random Forest, XGBoost, and CatBoost) produced significantly different evaluation results depending on the degree of asymmetry in forecast error costs between imbalance classes and the performance metrics applied. Second, XGBoost and CatBoost showed good predictive performance when considering variations in prediction cost asymmetry and diverse evaluation metrics. In particular, XGBoost showed the smallest gap between the actual default rate and the default judgment rate, highlighting its robustness in handling class imbalance and prediction cost asymmetry. Third, SHAP analysis revealed that total assets, net income to total assets, operating income to total assets, financial liability to total assets, and the retained earnings ratio were the most influential factors in predicting defaults. The significance of this study lies in its comprehensive evaluation of predictive performance of various ML models under class imbalance and cost asymmetry in forecast errors. Additionally, it demonstrates how explainable AI techniques can enhance the transparency and reliability of corporate default prediction models."
금속 입자를 활용하고 인공지능 기술을 접목한 수환경 바이오센서 기술의 현황 및 전망,2025,"['Metal nanoparticles', 'Biosensors', 'Artificial intelligence', 'Water quality monitoring', 'Machine learning']",,"This paper discusses the current development and prospects of water environment biosensors that combine metal nanoparticles with artificial intelligence (AI) technology. Water pollution, particularly the detection of harmful substances such as heavy metals, poses serious threats to human health and the environment, increasing the need for rapid and accurate monitoring technologies. Traditional analytical methods are costly, complex, and difficult to apply on-site, prompting the demand for efficient alternatives. Biosensors, which integrate biological components with analytical systems, offer advantages such as miniaturization and low costs. Electrochemical biosensors are known for their high sensitivities and stabilities. Metal nanoparticles are considered ideal materials for biosensors due to their excellent reactivity and plasmonic properties, enabling sensitive detection of harmful substances. Recently, the integration of AI, particularly machine learning, has expanded the application of biosensors by enabling rapid data processing and real-time monitoring. AI-based metal nanoparticle biosensors offer more precise analysis than conventional methods and have the potential to contribute to solving a variety of environmental problems, including water quality monitoring."
A longitudinal investigation of gut microbiota dynamics in laying hens from birth to egg-laying stages,2025,"['16S rRNA Gene', 'Gut Microbiota', 'Laying Hens', 'Longitudinal Study', 'Machine Learning']",,"Objective: Laying hens are a critical resource in global agriculture, valued for their egg production, which provides an economical and nutritious source of protein. This study aims to comprehensively characterize the developmental changes in the gut microbiota of Hy-Line Brown laying hens from birth to post-laying stages. Methods: A total of 100 Hy-Line Brown laying hens were reared under controlled conditions, and feces and ileal contents were collected at three post-laying stages (151, 302, and 422 days). DNA was extracted from the samples and the V4 region of the 16S rRNA gene was sequenced using an Illumina MiSeq platform. The Random Forest algorithm was applied to identify microbial predictors and explore their relationships with age. Results: The rapid increase in body weight continued until day 151, after which it stabilized through day 422. Fecal microbiome diversity increased until day 302, whereas in the ileal content, it grew until day 101 before declining. Throughout all stages, Firmicutes, Proteobacteria, and Bacteroidetes were the predominant phyla. Lactobacillus abundance peaked on day 10 (33.75%) across all sampling sites, whereas Escherichia-Shigella reached its maximum on day 21 but gradually diminished to 2.88% by day 422 (p<0.05). Machine learning analysis revealed that Candidatus Arthromitus and Clostridia vadinBB60 group consistently had the highest importance scores across all sample sites. At 302 day, body weight exhibited negative relationships with feces Brevibacterium (R = -0.87; p<0.05) and Brachybacterium (R = -0.79; p<0.05). Conclusion: This study examined gut microbiota changes in Hy-Line Brown hens from birth to one-year post-laying, highlighting the impact of calcium-rich layer diets. The findings provide insights into microbiota dynamics and their relationship with age, which can be applied to optimize dietary strategies and improve laying hen productivity and health."
Seeding the future: a review of artificial intelligence’s pivotal role in seed technology,2025,['Artificial intelligence · Hyperspectral imaging · Variety identification · Seed testing · Machine learning'],,"The use of artificial intelligence in agriculture, particularly in the seed sector, holds immense potential to address various challenges and improve overall productivity. Quality seeds play a vital role in crop stand establishment and contribute significantly to agricultural output and resource optimization. By harnessing AI technologies, such as hyperspectral imag-ing, machine learning, and computer vision, various aspects of seed production and management can be revolutionized. AI-powered systems can accurately assess seed quality, identify diseases and deficiencies in crops, and even determine the genetic purity of seed varieties. This not only speeds up the seed testing and certification process but also minimizes the risk of human error and subjective evaluations. AI can aid in varietal development by analyzing genetic data and predicting the performance of different genotypes, leading to the creation of improved crop varieties with desirable traits. AI-driven drones equipped with hyperspectral cameras can enhance field inspections, providing real-time data on crop health and potential contamination sources. AI-controlled monitoring systems ensure optimal conditions to maintain seed viability and genetic diversity, while image analysis techniques detect signs of deterioration or damage. Incorporating AI in seed technology paves the way for more efficient and sustainable agriculture, enabling farmers to make data-driven decisions and optimize resource usage. By adopting AI-powered solutions in the seed sector, countries like India can significantly boost agricultural output, achieve food security, and meet the challenges of an evolving agricultural landscape. Embracing the potential of AI in seed technology is a crucial step towards ensuring a sustainable and productive future for agriculture."
Enhancing Hoek–Brown constant estimation accuracy based on rigidity index using deep neural network,2025,['Hoek–Brown failure criterion · Constant mi · Rigidity index · Deep learning · Empirical relationships'],,"Estimation of the Hoek–Brown failure criterion constant (mi) is crucial for geotechnical design but remains challenging due to inherent nonlinearity in rock mass behavior. Existing empirical equations for mi prediction exhibit limitations, particularly at lower threshold values of the rigidity index. This study aims to develop an optimized deep learning approach to minimize mi estimation errors. To develop a model for predicting mi, a training dataset comprising literature-sourced data on various intact rock types was compiled. Statistical analyses characterized the parameter distributions and relationships. Eight empirical formulations were also implemented to estimate mi values. Subsequently, four predictive models of varying complexity were designed and trained utilizing machine learning and deep neural network techniques. The models took various combinations of uniaxial compressive and indirect tensile strengths as inputs. Rigorous performance evaluation demonstrated deep learning formulations attained perfect fits and consistently outperformed empirical relationships. Notably, incorporating rigidity index resolved issue in characterizing mi below threshold values. This study, therefore, validates artificial intelligence’s ability to systematically enhance rock failure criterion characterization by resolving known challenges."
고령자의 일상활동 통행사슬 유형에 영향을 미치는  환경 요인 분석 - Active Aging 요소를 중심으로,2025,"['Elderly Mobility', 'Daily Activity Trip Chains', 'Active Aging', 'Interpretable Machine Learning', '고령자 통행', '일상활동 통행사슬', '활동적 노화', '해석가능한 기계학습']","초고령화 사회에서 고령자의 이동성에 대한 보장은 건강하고 활력있는 노후 생활의 핵심 요건으로 주목받고 있다.이에 따라 본 연구는 고령자의 일상활동 통행사슬 유형을 도출하고 그에대해 영향을 미치는 물리적 환경 요인을 실증적으로 분석함으로써 Active Aging 정책 실현을위한 도시 정책의 방향성을 제시하고자 하였다.따라서 본 연구는 서울시를 대상으로 고령자의통행사슬 유형에 영향을 미치는 물리적 환경 요인을 거주지와 주요 활동지로 구분하여 분석하였다.분석을 위해 해석가능한 기계학습 기법을 적용하여 이에 따른 비선형 관계를 확인하였다.분석 결과, 주요 활동지의 물리적 환경에 대한 요소가 거주지 주변의 도시환경 요소보다 더 높은 상대적 중요도를 보여 고령자가 특정 목적을 위해 자신의 필요에 맞게 목적지를 선택하는경향이 확인되었다.또한, 대부분의 변수가 통행사슬 유형과 비선형 관계를 보여 이는 고령자의통행 특성이 절대적인 양보다는 질적인 측면과 밀접하게 연관되어 있음을 시사한다.","As societies age, ensuring mobility for older adults is essential for promoting healthy and active aging. This study examines the trip chain types of older adults based on daily activities and analyzes the influence of physical environmental factors in Seoul, Korea. By distinguishing between residential areas and primary activity locations, the study applies interpretable machine learning techniques to explore potential nonlinear relationships. The results reveal that the environment around primary activity locations has greater relative importance than that of residential areas, suggesting that older adults choose destinations based on specific needs rather than proximity. Additionally, nonlinear patterns found in most variables indicate that elderly travel behavior is more closely related to qualitative environmental aspects than to simple quantitative measures. These findings highlight the need for urban policies that support diverse, purpose-driven mobility to achieve active aging."
A trajectory data-driven approach for traffic risk prediction: incorporating variable interactions and pre-screening,2025,"['Risk prediction', 'traffic flow parameter', 'interaction effect', 'SCAD-logistic regression model', 'machine learning']",,"Although historical crash data and trajectory data have been widely applied to crash and risk predictions, both types of data have their own limitations. As a solution, this study investigates the impact of the traffic flow parameters and their interaction terms on risk prediction performance, employing a variable pre-screening approach (i.e. Smoothly Clipped Absolute Deviation (SCAD)). A research framework is proposed for more efficient risk prediction, and a detailed case study is further conducted using the proposed approach. In the case study, real vehicle trajectory data from HighD are processed and used, which can be aggregated to extract both traffic flow parameters and corresponding risk data during a specific time interval. As for the risk detection, Time-to-Collision (TTC) index is utilized to identify risky conditions. For different lanes (i.e. inner, middle and outer lanes), the impact of variables, including interaction terms, on risk is explored using the SCAD-logistic models. Furthermore, machine learning methods are employed to compare the risk prediction performance before and after considering interaction terms, as well as before and after variable pre-screening. Finally, the superiority of the machine learning models after SCAD-based variable pre-screening is demonstrated. Results indicate that the interaction terms between traffic flow parameters have significant impacts on the traffic risk. Besides, considering interaction terms and variable pre-screening can improve risk prediction accuracy. Furthermore, the proposed models outperform Random Forest (RF) in terms of predicting traffic risk, achieving a maximum 21.24% accuracy improvement and reducing computational time by up to 31.51%. Findings of this study are expected to contribute to the high-precision prediction of real-time risk in the future."
선체 블록의 조정 배관 변형과 조립 정확도 평가를 위한 열변형 해석 및 이상치 예측,2025,"['Adjustment pipe', 'FCAW(Flux-cored arc welding)', 'Finite element method', 'Machine learning', 'Welding deformation']",,"The adjustment pipes are components used to connect fixed pipes where step have occurred in ship blocks. This study proposes a method for predicting the deformation of adjustment pipes that  occurs  during  the  fabrication.  Thermo-elasto-plastic  finite  element  analysis  (FEA)  was employed to numerically simulate deformations occurring under various welding conditions. By integrating both experimental and analytical data, a model was developed to quickly and accu- rately predict welding deformation and compliance with tolerance limits using machine learning algorithms.  To  manage  the  complexity  of  high-dimensional  variables,  Principal  Component Analysis  (PCA)  was  utilized,  and  predictive  models  were  constructed  using  KNN,  Decision Tree,  and  XGBoost  algorithms.  The  prediction  results  indicated  that  XGBoost  algorithm achieved the highest accuracy in predicting the amount of deformation, and Decision Tree algo- rithm  excelled  in  predicting  compliance  with  tolerance  limits.  The  results  of  this  study  are expected  to  contribute  to  the  design  and  quality  control  of  adjustment  pipes  by  providing  a methodology that provides reliable predictions under various welding conditions."
Sentinel-2 위성 영상을 활용한 AutoML 기반 앙상블 모델의 낙동강 수질 지표 추정,2025,"['AutoML', '앙상블 모델', '기계학습', '낙동강', 'Sentinel-2', '수질', 'AutoML', 'Ensemble model', 'Machine learning', 'Nakdong River', 'Sentinel-2', 'Water quality']","본 연구는 낙동강 유역의 수질 모니터링을 위해 Sentinel-2 위성 데이터와 자동화 기계학습(AutomatedMachine Learning, AutoML) 기반 앙상블 모델을 활용한 종합적인 접근법을 제시한다. 2018년부터 2023년까지 낙동강 60여개 관측소의 수질 자료와 다중분광 위성 영상을 결합하여 7개 수질 지표(Chlorophyll-aConcentration, Biochemical Oxygen Demand, Chemical Oxygen Demand, Dissolved Oxygen [DO], TotalOrganic Carbon [TOC], Total Nitrogen, Total Phosphorus) 추정 모델을 개발했다. 이를 위해 Tree-BasedPipeline Optimization Tool (TPOT)을 이용한 AutoML 파이프라인(Pipeline) 구축과 5-폴드(Fold) 교차 검증을 통해 생성된 5개 모델의 선형 앙상블 기법을 적용했다. 앙상블 모델은 모든 수질 지표에서 Random Forest와 개별 TPOT 모델 대비 우수한 정량적 성능을 보여 주었다. 또한 수질 추정에 있어 Red (B4, 665 nm)와Red-Edge 1 (B5, 705 nm) 밴드가 다수 지표에서 큰 기여를 했으며, 단파적외선(Shortwave Infrared) 밴드(B11, 1,610 nm; B12, 2,190 nm)는 DO 및 TOC 추정에 핵심적 역할을 한 것으로 분석되었다. 정성적 평가를위한 다중 시기 영상 적용 결과, 계절적 특성을 반영한 자연스러운 수질 분포 패턴을 확인했다. 이 연구는AutoML과 앙상블 기법을 통한 위성 기반 수질 모니터링 시스템의 실용 가능성을 보여주었으며, 기존 현장관측의 공간적 한계를 극복할 수 있는 대안으로 활용될 것으로 기대된다.","This study presents a comprehensive approach using Sentinel-2 satellite data and an AutomatedMachine Learning (AutoML) based ensemble model for water quality monitoring in the Nakdong Riverbasin. We developed estimation models for seven water quality indicators (Chlorophyll-a Concentration,Biochemical Oxygen Demand, Chemical Oxygen Demand, Dissolved Oxygen [DO], Total Organic Carbon[TOC], Total Nitrogen, Total Phosphorus) by combining in situ water quality data from about 60observation stations along the Nakdong River with multispectral satellite imagery from 2018 to 2023. Toachieve this, an AutoML pipeline was constructed using the Tree-based Pipeline Optimization Tool(TPOT), and a linear ensemble technique was applied to five models generated through 5-fold crossvalidation.The ensemble model demonstrated superior quantitative performance across all water qualityindicators compared to Random Forest and individual TPOT models. In estimating water quality, the Red(B4, 665 nm) and Red-edge 1 (B5, 705 nm) bands made significant contributions to multiple indicators,while shortwave infrared bands (B11, 1,610 nm; B12, 2,190 nm) played crucial roles in estimating DO andTOC. Qualitative evaluation through multi-temporal images revealed natural water quality distributionpatterns reflecting seasonal characteristics. This research demonstrates the practical potential of a satellitebasedwater quality monitoring system using AutoML and ensemble techniques. It is expected to serve asan alternative to overcome the spatial limitations of existing field observations."
비주얼 프로그래밍을 활용한 예술 교육 과정 연구,2025,"['비주얼 프로그래밍', '예술 교육', '생성적 예술', '인터랙티브 아트', '머신러닝 기반 창작', '프로세싱', 'Visual Programming', 'Art Education', 'Generative Art', 'Interactive Art', 'Machine Learning-based Creation', 'P5.js']","본 연구는 비주얼 프로그래밍을 이용한 예술 작품을 탐색하여 최근 사용되는 기술과 디자인 표현 기법을 분석한 후, 예술 전공자들이 실무에 적용할 수 있는 체계적인 커리큘럼을 개발하는 것을 목표로 한다. 이를 위해 OpenProcessing 플랫폼에 공개된 패턴, 3D, 입자(Particle), 인공지능(AI)의 예술 작품을 선정하여 알고리즘 특징 및 시각적 요소, 상호작용 방식을 분석하였다. 분석 결과, 비주얼 프로그래밍은 반복이나 대칭 등 디자인 원리를 시각적으로 이해하고 표현할 수 있으며, WebGL을 이용하여 입체감 있는 작품을 구현하고 패널을 통해 실시간으로 반응하는 작품을 표현할 수 있음을 확인하였다. 또한, 물리적 현상을 표현하는 기법과 AI 기반의 작품을 융합하여 새로운 형태의 표현 가능성을 제시하여 교육적 활용 가능성이 높음을 확인하였다. 이를 바탕으로, 본 연구는 동물을 주제로 한 PBL(Project-Based Learning) 기반 교육과정을 설계하여 인공지능, 3D, 패턴 등을 단계적으로 습득할 수 있도록 학습 과정을 제안함으로써 학습자들의 감성적 지능과 논리적 사고력을 향상하고 아이디어를 실현할 수 있도록 구성하였다. 본 연구는 비주얼 프로그래밍이 예술 교육에서 창의성과 기술 역량을 함께 배양하는 데 기여할 수 있음을 시사하며, 향후에는 제안된 커리큘럼을 실제 수업에 적용하여 효과성을 검증하고자 한다.","This study aims to develop a systematic curriculum that art majors can apply to their practice by exploring artworks that use visual programming to analyze recent technologies and design expression techniques. To this end, we selected artworks of pattern, 3D, particle, and AI published on the OpenProcessing platform and analyzed their algorithmic features, visual elements, and interaction methods. As a result of the analysis, we found that visual programming can visually understand and express design principles such as repetition and symmetry, realize three-dimensional works using WebGL, and express works that react in real time through panels. In addition, we found that AI-based works can be used for educational purposes by fusing techniques that express physical phenomena with AI-based works to present new forms of expression. Based on this, this study designed a PBL (Project-Based Learning) based curriculum on the theme of animals and proposed a learning process to acquire AI, 3D, patterns, etc. in stages so that learners can improve their emotional intelligence and logical thinking skills and realize their ideas. This study suggests that visual programming can contribute to cultivating both creativity and technical skills in art education, and in the future, we will apply the proposed curriculum to actual classes to verify its effectiveness."
Facial Emotion Recognition Using Canny Edge Detection Operator and Histogram of Oriented Gradients,2025,"['Canny Edge Detection Operator', 'Facial Emotion Recognition', 'Histogram of Oriented Gradients', 'Machine Learning.']",,"Facial emotion recognition (FER) has received considerable attention from researchers due to its wide range of potential applications, such as human-computer interaction, marketing, customer service, education, security, and mental health care. In this study, we propose a method for recognizing human emotions from facial images using the Canny edge detection operator and histogram of oriented gradients (HOG). To extract contour and wrinkle information corresponding to emotional states from facial images, the Canny edge detection operator is applied to detect edge features. These contour and wrinkle patterns are critical because they provide valuable cues that reflect subtle changes in facial expressions, which are essential for accurately identifying emotions. Then, HOG is applied to the edge-detected image to quantify the edge features and use them as features for FER. To demonstrate the effectiveness of the proposed features in the FER task, we conducted a perfor-mance evaluation on four machine learning (ML) models using two publicly available FER datasets: JAFFE (Japanese Female Facial Expres-sion) and CK+ (Extended Cohn-Kanade). The experimental results showed that all four ML models achieved state-of-the-art performance on the test set when trained using our proposed features."
비모수 검정통계량을 이용한 회귀나무 분리기준 모의실험연구,2025,"['회귀나무', '분리기준', '분리변수', '비모수적 검정법', '소표본.', 'regression tree', 'split criterion', 'non-parametric test', 'small sample.']","최근 대규모의 빅데이터를 이용한 알고리즘(algorithm) 기반의 기계학습(machine learning) 방법론이 각광받고 있으며 의사결정나무는 그 대표적인 방법론 중 하나이다. 특히 Random Forest, XGBoost 등 의사결정나무 기반의 Ensemble 방법론에 대한 많은 연구들이 제시되고 있으며, 이러한 방법론은 대용량의 데이터에서 우수한 성능을 보이지만, 작은 소표본의 데이터에서는 적합하지 않다. 소규모 데이터에 대해서 재표본(re-sampling) 방법론은 기저 분포에 대한 정보를 효과적으로 주지는 못하는 것이다. 다양한 현실의 문제에서는 많은 소표본의 상황이 존재하지만 이에 대한 효율적 의사결정나무 방법론은 많지 않다. 본 연구에서는 소규모 데이터에 대한 회귀나무(regression tree)의 구축에 대해서 검토하였다. 특히, 회귀나무의 구성에서 가장 중요한 분리변수(split variable) 탐색에 통계적 비모수 검정법(non-parametric test)을 적용하였으며, Lepage 검정통계량, Cucconi 검정통계량, PG 검정통계량 등을 고려하였다. 모의실험을 통한 비교 결과, 소규모 데이터일 경우, 비모수적 위치-척도 검정법을 이용한 의사결정나무가 우수한 성능을 보이고 있음을 확인할 수 있었다.","Recently, algorithm-based machine learning methodologies using large-scale big data have prominent, and decision trees are one of the methodologies. In particular, many studies on ensemble methodologies based on decision trees such as Random Forest and XGBoost have been presented, and these methodologies show excellent performance in large data sets but are not suitable for small samples. For small-sized data, re-sampling methodologies do not effectively provide information about the underlying distribution. In various real-world problems, there are many situations with small samples, but there are not many efficient decision tree methods for them. In this study, we examined the regression trees for small-sized data. In particular, we applied statistical non-parametric test statistics to explore the true split variables in the construction of regression trees, considering test statistics such as Lepage's test statistic, Cucconi's test statistic, and PG's test statistic. As a result of the comparison through simulation studies, decision trees using non-parametric location-scale tests show good performance when dealing with small-sized data."
A review of sound-based pig monitoring for enhanced precision production,2025,"['Smart livestock production', 'Pig health monitoring', 'Pig behavior', 'Respiratory diseases', 'Sound sensor', 'Machine learning']",,"Pig farming is experiencing significant transformations, driven by technological advancements, which have greatly improved management practices and overall productivity. Soundbased technologies are emerging as a valuable tool in enhancing precision pig farming. This review explores the advancements in sound-based technologies and their role in improving precision pig farming through enhanced monitoring of health, behavior, and environmental conditions. When strategically placed on farms, non-invasive technologies such as microphones and sound sensors can continuously collect data without disturbing the animals, making them highly efficient. Farmers using sound data, can monitor key factors such as respiratory conditions, stress levels, and social behaviors, leading to improved animal welfare and optimized production. Advancements in sensor technology and data analytics have enhanced the capabilities of sound-based precision systems in pig farming. The integration of machine learning and artificial intelligence (AI) is further enhancing the capacity to interpret complex sound patterns, enabling the automated detection of abnormal behaviors or health issues. Moreover, sound-based precision technologies offer solutions for improving environmental sustainability and resource management in pig farming. By continuously monitoring ventilation, feed distribution, and other key factors, these systems optimize resource use, reduce energy consumption, and detect stressors such as heat and poor air quality. The integration of sound technologies with other precision farming tools, such as physiological monitoring sensors and automated feeding systems, further enhances farm management and productivity. However, despite the advantages, challenges remain in terms of low accuracy and high initial costs, and further research is needed to improve specificity across different pig breeds and environmental conditions. Nonetheless, acoustic technologies hold immense promise for pig farming, offering enhanced management, an optimized performance, and improved animal welfare. Continued research can refine these tools and address the challenges, paving the way for a more efficient, profitable, and sustainable future for the industry."
AEB  작동  사고에서  승객  상해  저감을  위한  에어백  전개  시점  최적화에  관한  연구,2025,"['AEB(자동 긴급 제동 장치)', 'Airbag(에어백)', 'Passenger  injury(승객 상해)', 'Machine  learning(머신 러닝)']",,"With recent rise in the deployment of vehicles equipped with Advanced Driver-Assistance Systems (ADAS),  there  has been a  lot of researches  on the  effects  of  the Autonomous  E mergency  Braking  (AE B)  system for  passenger  injury.  From  this  perspective,  the  study  developed  scenarios  for  AEB  activation  and  simulated  passenger injuries. The research focused on the analysis of how three primary variables-the seating angle  of  the  passenger,  the  speed  of  the  vehicle,  and  the  timing  of  airbag  deployment-affect  the  severity  of  passenger injuries. The analysis of injury data and the application of machine learning models are conducted  to predict the optimal timing of airbag deployment based on specific seating angles of passengers and vehicle  speeds. The objective is to explore the feasibility of adjusting the timing of airbag deployment in real-time  within  AEB  systems.  Based  on  machine  learning,  the  prediction  model  can  improve  the  passenger  injury  accroding to passenger seating angle and vehicle speed. This study shows the potential for the adjustments  in airbag deployment timing to improve the effectiveness of AEB systems to mitigate injuries during accidents."
Hybrid optimized algorithms for predicting punching shear strength in flat slabs considering failure modes,2025,"['Punching shear strength', 'Failure mode', 'Hybrid optimized algorithms', 'Machine learning', 'two-way flat slabs']",,"Using data-driven models, this study identifies failure modes (FM) in two-way flat slabs without shear reinforcements and predicts the corresponding punching shear strength (PSS). There are different methods available to determine the punching resistance based on their failure modes. Despite the existence of theoretical models, their accuracy and quantification remain problematic. It was decided to use the extreme gradient boosting algorithm (XGBoost) classifier to determine the failure modes for slabs with 580 test results due to its superior performance relative to the other two machine learning (ML) based models. During training, geometric parameters, material properties, and mechanical characteristics are considered as input variables. Two hybrid algorithms (grey wolf optimization, GWO and whale optimization algorithm, WOA) combining XGBoost are presented as a method of predicting the punching shear strength. A comparison is also made between the predictive results and the empirical predictions with various evaluation metrics. The results of the testing indicate that XGBoost classifier is the best model for identifying FMs, while GWO-XGBoost is the best model for PSS prediction. Further, shapely additive explanation (SHAP) is used to interpret the results of the model to explain the significance of the feature. This study aims to implement ML approaches for categorizing FM, then use FM as an input variable to develop hybrid optimized algorithms that can predict the corresponding PSS. A new perspective is presented within this study regarding the relationship between the FMs and the PSS. Moreover, suggestions are provided for preventing brittle punching shear failure and improving the ultimate strength of flat slabs."
수면 무호흡 탐지를 위한 통계적 특징 기반 이진 분류 모델과 다중 분류 모델 성능 비교,2025,"['수면 무호흡', '통계적 특징 추출', '기계학습', '이진 분류', '계층적 2단계 분류', 'Sleep Apnea', 'Statistical Feature Extraction', 'Machine Learning', 'Binary Classification', 'Hierarchical Two Stage Classification']","수면 무호흡은 수면 중 호흡이 반복적으로 중단되는 현상으로 혈중 산소 포화도가 감소되고 다양한 건강 문제를 야기한다. 본 연구는 수면 상태에서 수면 무호흡을 탐지하는 이진분류와 정상 호흡, 저호흡, 폐쇄성 수면 무호흡을 다중 분류하는 계층적 2단계 방법을 제안한다. Airflow, PTAF, snore 센서 데이터를 10초로 분할하고 시간/주파수 영역에서 통계적 특징을 추출한다. 기계학습 모델의 입력으로는 Fisher score, 상관관계, 특징 중요도 방법을 사용하여 선별된 특징들을 이용한다. 이진 분류는 XGBoost와 Random Forest의 정확도 평균이 0.95 이상으로 신뢰할 수 있는 결과를 보였다. 계층적 2단계의 다중 분류에서도 Random Forest와 XGBoost의 평균 정확도가 0.88로 우수했고, 클래스 별 정확도가 단일 단계 분류 방식보다 향상되었다. 제안한 방법은 수면 무호흡을 정확하게 탐지하고, 저호흡과 폐쇄성 수면 무호흡으로 세분화하여 임상 적용 가능성을 보였다.","Sleep apnea is characterized by repeated interruptions of breathing during sleep, leading to various health problems. We propose a binary classification method for detecting sleep apnea and a hierarchical two-stage classification method for multi-class classification into normal breathing, hypopnea, and obstructive sleep apnea. Sensor data from Airflow, PTAF, and Snore are segmented into 10-second intervals, and statistical features are extracted from time and frequency domains. Features selected using Fisher score, correlation, and feature importance methods are used as inputs for machine learning models. The binary classification showed reliable results with an average accuracy of over 0.95 using XGBoost and Random Forest. In the hierarchical two stage multi-class classification, both Random Forest and XGBoost achieved an average accuracy of 0.88, with per-class accuracy surpassing that of the single-stage multi-class approach. The proposed method accurately detects sleep apnea, further distinguishing between hypopnea and obstructive sleep apnea, including its potential for clinical application."
기하학적 특징과 HOG 특징을 사용한 얼굴 감정 인,2025,"['Facial Emotion Recognition', 'Feature Extraction', 'Facial Landmarks', 'Geometric Features', 'Histogram of Oriented Gradients', 'Machine Learning']",,"In this study, we propose a face image-based emotion recognition technique that uses both geometric features and histogram of oriented gradients (HOG) features. Geometric features are designed based on the fact that the shapes of the eyebrows, mouth, and eyes vary depending on the emotional state in human facial expressions. For the HOG features, the shape of the wrinkles in the eye area changes according to the emotional state, and texture information—the shape of the wrinkles—is extracted by applying HOG. To demonstrate the effectiveness of geometric and HOG features in facial image-based emotion recognition, we conducted an ablation study using four machine learning (ML) models and the extended Cohn-Kanade (CK+) dataset. The experimental results show that the highest emotion classification accuracy is achieved for all four ML models when the two features are combined and used as input, rather than using each feature alone. Among the four ML models, logistic regression outperformed the others, achieving an accuracy of approximately 97.93%."
무역예측의 정밀도 향상과 SHAP 기반 변수 영향력 해석:  환경상품 사례 분석,2025,"['Environmental Goods Trade', 'Gravity Model Comparison', 'SHAP Intepretation']",,"Purpose – This study aims to improve the predictive accuracy of international trade in environmental goods by applying machine learning models, and to enhance model interpretability through SHAP (SHapley Additive exPlanations) analysis.Design/Methodology/Approach – The research utilizes trade data for 53 HS-coded environmental goods across 44 major economies from 2001 to 2020. Various machine learning algorithms, including Random Forest, Extra Trees, LightGBM, and ensemble models, are evaluated using the PyCaret framework. The study compares prediction performance against traditional gravity models, and applies SHAP values to identify key factors influencing model outputs.Findings – Stacked ensemble models significantly outperform traditional gravity models in forecasting trade flows, with notable gains in predictive accuracy (lower MSE and higher R²). SHAP analysis reveals that GDP, geographic distance, and shared language are among the most influential variables, with domain-specific variations across product categories.Research Implications – The integration of SHAP-based interpretability with machine learning models offers a powerful tool for trade policy and environmental strategy. It enables policymakers and trade analysts to understand not just what drives trade performance, but how these factors interact non-linearly—opening new directions for data-driven international trade negotiations and environmental policy design."
기호 회귀를 활용한 수학적 모델링 기반 물리 수업이 메타 모델링 지식에 미치는 영향 탐색,2025,"['물리 수업', '수학적 모델링', '기호 회귀', '기계학습', 'Physics class', 'Mathematical modeling', 'Symbolic regression', 'Machine learning']","본 연구는 학생들이 모델 생성 과정뿐 아니라 모델 자체의 본성과 역할을 깊이 이해하도록 돕기 위해, 기호 회귀를 활용한 수학적 모델링 중심 수업(SRPC)을 설계하고 그 효과를 검증하였다. SRPC는 학생들이 기호 회귀를 도구로 활용하여 실제 데이터를 빠르게 수식으로 표현하고 그 물리적 의미를 해석하는 과정을 경험하도록 하며, 복잡한 계산보다는 모델의 본질적 의미를 이해하도록 하는 것을 목적으로 한다. SRPC는 교수 모형 개발을 위한 ADDIE 모형에 근거하여 개발되었다. SRPC를 현장에 적용한 결과, 학생들의 모델의 본성, 수학적 모델링 목적, 모델 변동성 지식이 통계적으로 유의미하게 향상되었다. 반면, 모델의 다중성에 대한 인식은 오히려 낮아졌다. 또한 학생들은 기계학습의 활용, 데이터 기반 접근을 긍정적으로 인식하고, 수학의 중요성에 대한 인식이 강화되었다. 개발된 교수 모형은 물리 현상의 수학적 이해를 높이고, 첨단 기술의 교육적 활용 가능성을 제시하지만, 다양한 현상을 탐색할 기회가 보강될 필요성도 도출되었다.","This study designed and examined the effectiveness of a Symbolic Regression integrated Physics Class (SRPC) to enhance students’ comprehension of model creation, its nature, and its role. SRPC enables students to apply symbolic regression to represent real-world data as mathematical equations and interpret their significance, prioritizing conceptual understanding over computational complexity. Developed based on the ADDIE model, SRPC was implemented in a classroom, resulting in significant improvements in students’ understanding of the nature of models, the purpose of mathematical modeling, and model variability, though awareness of model multiplicity declined. Additionally, students demonstrated positive perceptions of machine learning and a heightened recognition of the importance of mathematics. While SRPC fosters a mathematical understanding of physical phenomena and underscores the educational potential of advanced technologies, further opportunities to explore diverse phenomena should be incorporated."
Fisher-Rao 거리를 이용한 함수형 $k$-최근접 이웃 방법론,2025,"['정렬 방법론', '함수형 분류 모형', '함수형 데이터 분석', '기계학습', '위상 변동', 'alignment', 'functional classification model', 'functional data analysis', 'machine learning', 'phase variation']","함수형 데이터 분석(functional data analysis)의 함수형 관측값들은 기존의 다변량 데이터 분석(multivariate data analysis)의 관측값과 달리 두 가지 성분을 갖는다. 하나는 위상(phase) 성분이고 또 다른 하나는 진폭(amplitude) 성분이다. 따라서 함수형 통계적 분석을 할 경우에는 진폭 변동뿐만 아니라 위상 변동도 함께 고려해줘야 더 효과적인 통계적 분석 및 결과를 도출할 수 있다. 현재 머신러닝의 분류 모형 중 함수형 $k$-최근접 이웃 방법론은 아직 위상변동을 고려하지 않는 분류 모형이다. 따라서 함수형 데이터에 위상적인 오류가 존재할 경우 효과적인 분류를 할 수 없다. 이 논문에서는 기존의 함수형 데이터를 Square-Root Velocity 함수로 변환 후, Fisher-Rao 거리를 이용한 정렬 방법론을 적용하여 새로운 함수형 분류 모형을 제안한다. 이 모형은 기존의 \ltwo 공간에서 발생할 수 있는 여러 문제들을 해결할 수 있을 뿐만 아니라, 기존의 함수형 분류 모형에서 고려하지 못한 위상 변동을 효과적으로 제거하면서 거리를 계산하기에 현존하는 함수형 $k$-최근접 이웃 방법론보다 더 효과적인 분류 성능을 보여줬다. 이는 모의 실험 데이터와 실제 데이터를 통해서 모형의 분류 성능의 우수함을 입증하였다.","In Functional Data Analysis (FDA), functional observations consist of two components: phase and amplitude. Therefore, it is crucial to conduct functional statistical analysis by considering not only amplitude variations but also phase variations. Among the current machine learning classification models, the functional $k$-Nearest Neighbors ($k$NN) method is a popular approach that does not account for phase variations. As a result, classification performance deteriorates when phase variations are present. In this paper, we propose an elastic functional $k$-nearest neighbors classification method that handles phase variations by incorporating the Fisher-Rao metric-based alignment technique. This model not only addresses several existing issues in the \ltwo space but also effectively removes phase variations. We compare the classification performance using two simulated datasets and six real-world datasets to demonstrate the effectiveness of our model."
Understanding Review Helpfulness through Diagnosticity and Cognitive Load: Comparative Analysis of LLM and ML Models on Restaurant Reviews,2025,"['Review helpfulness', 'Large language models (LLMs)', 'Information diagnosticity', 'Cognitive load']",,"This study investigates the determinants of review helpfulness and evaluates the predictive performance of traditional machine learning models and large language models (LLMs) using a 14-year dataset of 46,392 user-generated reviews from the OpenTable restaurant reservation platform. We compare four traditional machine learning (ML) classifiers—logistic regression, decision tree, random forest, and gradient boost tree— with a fine-tuned version of distilBERT, a lightweight large language model (LLM) based on bidirectional encoder representations from transformers (BERT). While previous studies on review helpfulness have primarily focused on surface-level features such as length, sentiment, or rating, we address a critical gap by incorporating both information diagnosticity and cognitive load as core theoretical perspectives. Specifically, we apply information diagnosticity theory (IDT) and cognitive load theory (CLT) to conceptualize helpful reviews as those that are both specific and cognitively accessible.Our findings show that distilBERT outperforms all baseline machine learning (ML) models in terms of precision and area under the curve (AUC), while maintaining computational efficiency. Topic modeling results further reveal that reviews featuring functional, clear, and experience-based content are more likely to be classified as helpful, whereas emotionally vague or technically dense reviews tend to be less effective. We contribute to the literature by showing how theory-informed large language model (LLM) can capture both diagnostic and cognitive dimensions of helpfulness—an area previously underexplored."
Library Space and Resource Usage Time: Reflections from Digital Footprints During Pre and Post-COVID-19,2025,"['library spaces', 'user behaviors', 'digital footprints', 'data mining', 'process mining', 'COVID-19']",,"This paper aims to investigate library user behaviors by comparing them pre and post-COVID-19. Two aspects of users’ behaviors were examined, including using physical learning spaces, and online resource utilization. This exploration used secondary data automatically recorded by ALIST OPAC systems (Prince of Songkla University Pattani Campus, Pattani, Thailand) during 2018 and 2022. Descriptive statistics were used to examine physical space usage. The machine learning algorithms name process mining technique was used to investigate the changes in online behaviors, by formulating the sequence of activities based on the digital footprints recorded when users interacted with the systems. This technique exemplified the sequence and timing of activities. The study results revealed an increased use of limited co-learning spaces by library users after COVID-19. The activity of borrowing and returning library resources showed that fewer reminder e-mails on the due date were sent. The process of mining exemplified the sequence and timing of activities. It indicated that after COVID-19, library users hold borrowed items for a shorter time than before the pandemic. These findings suggest that the digital footprints unveiled the changes in library users’ behaviors. That is, the library users return borrowed items faster than in pre-COVID-19 circumstances. A decrease in reminder e-mails was clearly visible to support such a finding. Therefore, it is suggested that library managements should consider a faster operation and well-resourced management to adapt to the changes. Managing resources needs to become faster as the library users showed a potential for faster return of borrowed resources."
Library Space and Resource Usage Time: Reflections from Digital Footprints During Pre and Post-COVID-19,2025,"['library spaces', 'user behaviors', 'digital footprints', 'data mining', 'process mining', 'COVID-19']",,"This paper aims to investigate library user behaviors by comparing them pre and post-COVID-19. Two aspects of users’ behaviors were examined, including using physical learning spaces, and online resource utilization. This exploration used secondary data automatically recorded by ALIST OPAC systems (Prince of Songkla University Pattani Campus, Pattani, Thailand) during 2018 and 2022. Descriptive statistics were used to examine physical space usage. The machine learning algorithms name process mining technique was used to investigate the changes in online behaviors, by formulating the sequence of activities based on the digital footprints recorded when users interacted with the systems. This technique exemplified the sequence and timing of activities. The study results revealed an increased use of limited co-learning spaces by library users after COVID-19. The activity of borrowing and returning library resources showed that fewer reminder e-mails on the due date were sent. The process of mining exemplified the sequence and timing of activities. It indicated that after COVID-19, library users hold borrowed items for a shorter time than before the pandemic. These findings suggest that the digital footprints unveiled the changes in library users’ behaviors. That is, the library users return borrowed items faster than in pre-COVID-19 circumstances. A decrease in reminder e-mails was clearly visible to support such a finding. Therefore, it is suggested that library managements should consider a faster operation and well-resourced management to adapt to the changes. Managing resources needs to become faster as the library users showed a potential for faster return of borrowed resources."
AI 도구를 활용한 일본어 작문 교육 방안 연구 ― 영상 자막 번역 프로젝트 수업을 중심으로 ―,2025,"['일본어 작문', '자막 번역', 'AI 도구', '프로젝트 기반 학습', '외국어 교육', 'Japanese writing education', 'subtitle translation', 'AI tools', 'project-based learning', 'foreign language education']","본 연구는 AI 도구를 활용한 일본어 작문 수업의 실제 운영 사례를 소개하고 그 교육적 의의를 분석하였다. 구체적으로 수도권 소재 4년제 대학 일본학과의 ‘일본어 작문’ 수업에서 진행된 영상 자막 번역 프로젝트의 설계와 운영 과정을 분석하였다.수업은 기초 학습 단계, 시범 단계, 실천 단계, 평가 단계로 구성되었다. 초반 4주는 AI 도구의 효과적인 활용을 위한 기초를 다지는데 중점을 두었으며, 이후에는 학생들이 직접 프로젝트를 수행하고 발표하는 방식으로 진행되었다. 특히 실천 단계에서는 학습자들이 자신의 관심사를 반영한 영상을 선정하여 AI 도구를 활용한 자막 번역을 수행하였다. 이 과정에서 다양한 AI 도구의 번역 결과를 비교·분석하고, 가장 적절한 표현을 선택하는 능력이 향상되었다.연구 결과, AI 도구를 활용한 자막 번역 프로젝트는 다음과 같은 교육적 효과가 있었다. 첫째, 실제적인 언어 사용 맥락에서의 학습이 가능했으며 학습자들의 흥미와 참여도가 높았다. 둘째, AI 도구의 한계를 보완하는 과정에서 더 심도 있는 언어 학습이 이루어졌다. 셋째, 학습자들은 AI 시대에 필요한 비판적 도구 활용 능력을 기르는 동시에 어학 전공자로서의 전문성과 역할에 대한 인식을 새롭게 하였다.본 연구는 AI 도구를 적극적으로 활용하면서도 인간의 언어 능력을 향상시킬 수 있는 새로운 외국어 교육 방법론을 제시했다는 점에서 의의가 있다.","This study examines the implementation and educational significance of AI tools in Japanese writing education through a video subtitle translation project. The research was conducted in a Japanese writing course at a university in the Seoul metropolitan area during the second semester of 2024. The course was structured into four phases: basic learning, demonstration, practice, and evaluation. The first four weeks focused on developing foundational skills in AI tool usage, followed by student-led project presentations. During the practice phase, students selected videos based on their interests and performed subtitle translations using various AI tools. They compared and analyzed translations generated by different AI systems, including machine translation and generative AI, to determine the most appropriate expressions. The study revealed several educational benefits. First, students engaged in authentic language learning contexts, demonstrating high levels of interest and participation. The process of selecting and translating content they enjoyed led to increased motivation and active engagement. Second, students improved their language proficiency by addressing the limitations of AI tools. They developed critical skills in comparing and analyzing different translations, considering cultural contexts, and making appropriate linguistic choices. Third, students gained a new perspective on their role as language specialists in the AI era, recognizing that effective AI tool utilization requires advanced language skills. These findings suggest that integrating AI tools into language education, particularly through subtitle translation projects, can effectively enhance Japanese writing proficiency while sustaining learner engagement. This study contributes to developing new pedagogical approaches that incorporate AI tools while fostering human linguistic capabilities in the AI-driven era."
지진 관련 사회적 요인을 고려한 지진취약지도 및 주거건물에 대한 지진취약 인구지도 분석: 서울시를 대상으로,2025,"['서울시', '지진 관련 사회적 요인', 'AHP', '지진취약지도', '지진취약인구', 'Seoul', 'Earthquake-Related Social Factors', 'AHP', 'Earthquake Vulnerability Map', 'Earthquake-Vulnerable Population']","본 연구의 파일럿 연구 대상지인 서울시에 활성단층이 존재하고 해당 지역에 내진설계 비율이 낮아, 지진 발생 시 적지 않은 인적 피해가 예상된다. 따라서 본 연구의 목적은 첫째, 피해예방활동의 일환으로 통계분석과 머신러닝을 활용, 시설물 중 건물의 지진취약성을 분석하고 둘째, 인적위험도 측정을 위해, 도로와의 거리, 대피소와의 거리 등을 고려해 지진취약인구를 분석하는 것이다. 연구진행의 주요 절차로는 통계분석과 머신러닝 각각을 활용해, 건물의 지진취약성을 분석한 뒤, AHP분석기법을 시행해, 지진 관련 사회적 요인의 가중치를 산정 후 공간분석에 적용해, 지진취약 지도를 제작한다. 지진취약 지도제작의 목적은 개별인프라요인과 종합인프라요인의 밀도지도를 제작하고 지진취약 인구지도와 비교해, 인적 피해에 취약한 지역을 찾는 것이다. 본 연구는 여러 기법을 융합한 학술적 시사점이 있으며, 인적･물적 피해에 우선순위 설정에 도움을 주는 등 실무적 시사점이 있다. 또한 여러 한계점이 있지만 대표적 한계점은 통계분석과 머신러닝을 AHP와 결합하는 과정에서 보정이 들어갔지만, 결합하는 과정에서 오차를 가져갈 수밖에 없는 점이다. 해당 한계점은 실제 지진피해를 입은 데이터들을 더욱 상세하게 제작할 경우 해결할 수 있는 한계점이며 향후 연구과제이다.","The pilot study area of this research, Seoul, has active faults, and the seismic design rate in the region is low. Consequently, a significant number of casualties are expected in the event of an earthquake. Therefore, the objectives of this study are as follows: first, as part of disaster prevention efforts, to analyze the seismic vulnerability of buildings among infrastructure facilities using statistical analysis and machine learning; and second, to assess human risk by considering factors such as the distance to roads and evacuation shelters to analyze earthquake-vulnerable populations. The main research process involves using both statistical analysis and machine learning to analyze the seismic vulnerability of buildings. Subsequently, the AHP (Analytic Hierarchy Process) analysis method is applied to estimate the weight of earthquake-related social factors, which are then incorporated into spatial analysis to create an earthquake vulnerability map. The purpose of developing this map is to generate density maps for individual and comprehensive infrastructure factors and compare them with the earthquake-vulnerable population map to identify areas that are highly susceptible to human casualties. This study provides academic implications by integrating various methodologies and practical implications by assisting in prioritizing human and material damage mitigation. Although this research has several limitations, the most significant limitation is that while adjustments were made during the integration process of statistical analysis, machine learning, and AHP, some errors were inevitable. This limitation can be addressed by developing more detailed datasets based on actual earthquake damage records, which remains a future research task."
Automated Diagnosis of Acute Cerebral Ischemic Stroke Lesions using Capsule Graph Neural Networks from Diffusion-weighted MRI Scans,2025,['Acute cerebral ischemic stroke · Diff usion-weighted magnetic resonance imaging (DW-MRI) · Automated diagnosis · Capsule graph neural networks (Capsule GNNs) · Deep learning'],,"Acute cerebral ischemic stroke lesions are regions of brain tissue damage brought on by an abrupt cutoff of blood fl ow, which causes oxygen deprivation and consequent cell death. The majority of strokes are ischemic strokes, which happen when a blood clot obstructs or narrows an artery that supplies blood to the brain. Depending on the location and extent of the affl icted area, these lesions can have serious implications, including neurological abnormalities like weakness, numbness, diffi culty speaking, and paralysis. For prompt medical intervention and treatment, acute cerebral ischemic stroke lesions must be accurately identifi ed. Because diff usion-weighted magnetic resonance imaging (DW-MRI) has a high sensitivity for identifying early tissue changes linked to ischemia, it is a commonly utilized imaging modality for evaluating ischemic stroke lesions. To enable prompt diagnosis and treatment planning, automated techniques for identifying and classifying acute cerebral ischemic stroke lesions from DW-MRI images are crucial. To evaluate MRI pictures and locate areas of aberrant tissue, these approaches usually combine deep learning architectures, machine learning algorithms, and sophisticated image processing techniques. These techniques can help medical professionals accurately assess the degree and severity of brain injury, guide treatment decisions, and forecast patient outcomes by automatically recognizing and segmenting ischemic stroke lesions. Better clinical results and a higher quality of life for stroke survivors can result from the early and accurate diagnosis of acute cerebral ischemic stroke lesions. Diff usion-weighted magnetic resonance imaging (DW-MRI) scans are essential for the diagnosis of acute cerebral ischemic stroke (ACIS), which is necessary for prompt and effi cient therapy. This work suggests an innovative method for the automated diagnosis of ACIS lesions utilizing capsule graph neural networks, or capsule GNNs. Capsule GNNs use the graph-based representation of neural networks and the hierarchical structure of capsule networks to capture complex spatial relationships found in brain imaging data. These techniques can help medical professionals accurately assess the degree and severity of brain injury, guide treatment decisions, and forecast patient outcomes by automatically recognizing and segmenting ischemic stroke lesions. The approach entails preprocessing DW-MRI data to create brain connection graphs and extract pertinent information. These diagrams illustrate the anatomical and functional connections between several brain regions, off ering important new perspectives on the intricate nature of ACIS lesions. These graph representations are then used to train the Capsule GNN architecture, which teaches it distinguishing patterns suggestive of ischemic stroke. The effi ciency of the suggested method is illustrated by experimental fi ndings on a dataset of DW-MRI scans from patients with ACIS. The Capsule GNN outperforms alternative deep learning architectures and conventional techniques in the detection and classifi cation of ACIS lesions,achieving excellent accuracy in the process. Furthermore, physicians can have a better understanding of the underlying characteristics that contribute to the diagnosis thanks to the interpretable nature of Capsule GNNs, which boosts their trust in the automated assessment. Research shows how well Capsule GNNs can diagnose acute cerebral ischemia stroke from DW-MRI data. Key performance parameters, such as Dice Similarity Coeffi cient (DSC) of 84.13%, Sensitivity (SE) of 86.54%, Volume Diff erence (∆V) of 20.45%, Precision of 95.45%, Recall of 90.54, and F1-score of 96%. Through the utilization of both the graph-based neural network representation and the hierarchical structure of capsule networks, a method provides a potential foundation for precise and comprehensible medical imaging analysis in stroke care."
Neural Network-based Head Movement Prediction Using Electromyography Signals,2025,"['Head movement', 'intent prediction', 'neural network', 'surface electromyography.']",,"This study aims to enhance assistive technologies by predicting head movement intentions in real-time using surface electromyography (sEMG) signals and machine learning algorithms. The primary motivation is to improve the responsiveness and accuracy of gaze tracking systems for individuals with physical disabilities. Six healthy adult males participated in the experiments, with their head and neck muscle activities recorded using a high-speed optoelectronic motion capture system (Vicon Vero/Nexus) and wireless sEMG sensors (Delsys Trigno). Reflective markers were positioned on the subjects’ heads and shoulders, and mini-size sEMG sensors were placed around the eyes and neck muscles. The experimental procedure involved the participants sitting 1.5 meters from a visual guide, performing head movements in four directions, and holding each position for three seconds. Four EMG feature sets were created for analysis, combining signals from different muscles and time intervals. Various machine learning models, including kernel naïve bayes, gaussian naïve bayes, bagged trees, and subspace KNN, were applied to predict head movement states. The subspace k-nearest neighbors (KNN) model applied to EMG set 3 achieved the highest classification accuracy of 78.0%. The study demonstrates the potential for sEMG combined with advanced computational techniques to significantly improve the real-time prediction of head movement intentions, offering valuable applications in human-computer interaction, virtual reality, and assistive technologies."
Radish mass estimation using simulated harvester dynamics using  GA-ELM modeling,2025,"['Precision agriculture', 'Computer vision', 'Vibration effect', 'Slope', 'Non-destructive measurement', 'Yield mapping']",,"Achieving precise yield mapping is a pivotal requirement for precision agriculture, but terrain-induced disturbances often complicate accurate infield measurements. To address this challenge, a computervisionbased approach was developed to estimate the massume of radishes under varying slopes and vibrations similar to field harvesting conditions using extreme learning machine (ELM), optimized via a genetic algorithm (GA) modeling. A laboratory test bench was constructed to simulate realistic harvester dynamics by incorporating adjustable slope angles (3°, 6°, and 9°) and vibration intensities (0.43, 0.78, and 0.98 m/s2). An overhead RGB camera captured images of the radishes as they passed along a conveyor exposed to these conditions. The images were then analyzed to extract relevant size parameters, and an extreme learning machine (ELM), optimized via a genetic algorithm (GA), was applied to predict the radish masses.These results were compared with the actual mass measured by the weight measuring method. Although the imagebased estimates tended to slightly underpredict across all experimental conditions, statistical analyses revealed no significant differences from the actual mass measurements. The proposed method achieved a coefficient of determination (R2 ) of 0.94 at 9° slope, 0.97 at 0.43 m/s2 vibration, and 0.98 when both 6° slope and 0.43 m/s2 vibration were combined. This approach demonstrates the feasibility of automated yield estimation for radishes and real-time field applicaiton for similarly shaped crops under challenging field conditions."
기상 자료 공간 보간을 활용한 XGBoost 기반 풍력발전 출력예측 모형에 관한 연구,2025,"['Wind Power Forecasting', 'Universial Kriging', 'Elevation Correction', 'Reanalysis Data', 'XGBoost', 'Forecast Correction']",,"Accurate wind power prediction is essential to ensure grid stability as renewable energy integration increases. However, obtaining precise meteorological data at wind turbine locations is challenging due to technical and economic constraints. This study introduces a prediction model combining spatial interpolation and machine learning techniques using meteorological observations and reanalysis data. By leveraging data from a wind farm in Jeju Island, the model constructs a comprehensive meteorological database using kriging with elevation corrections adapted to seasonal variability, thereby enhancing the spatial coverage of meteorological inputs.Additionally, machine learning based bias correction is applied to forecast data to improve predictive accuracy and enhance practical – applicability. The proposed approach provides a practical solution for system operators, mitigating grid management risks and supporting the energy transition. Future work will focus on incorporating high-resolution regional forecasts and optimizing the integration of multiple reanalysis datasets to further enhance prediction performance."
RSPDT: Randomized Search Probabilistic Decision Tree Classifier for Pollution Level Prediction in Smart Cities,2025,"['Prediction', 'Feature Selection', 'Classification', 'Pollution Control', 'Decision Tree', 'Performance']",,"Smart cities are prone to higher pollution rates due to their accessibility for multiple reasons. Predicting the pollution levels earlier could lead to analysis and take measures that could be a solution to the long-standing problem. In this article, we propose a novel machine learning model, randomized search probabilistic decision tree classifier (RSPDT) to leverage an enhanced solution for handling pollution in smart cities through its prediction at earlier stages. We used a global air pollution dataset of 23,463 samples to train and test our model. The initial phase is to select the most essential features for accurate prediction. The selected features are analyzed for their unique value towards the five different data classes. The data is classified using the proposed randomized search cross-validation decision tree classifier, which performs multiple classifications from the selected features. The cross-validation of the results is done using the proposed model. The performance of the proposed model is analyzed in terms of accuracy, sensitivity, and specificity, and the proposed model outperformed the existing models by 99%. This makes the proposed machine learning model a sounding agent that can predict the pollution levels in smart cities."
BIM 요구사항 난이도 평가에 대한 한글 형태소 분석기 영향 분석,2025,"['BIM Requirement', 'Bidding Sentence', 'Binary Classification Model', 'Korean Morpheme Analyzer', 'LSTM']",,"With the mandatory adoption of BIM in construction projects, recognizing BIM requirements in bid documents and analyzing the related tasks during the bidding stage is crucial for effective strategies. On the other hand, a shortage of skilled personnel with BIM expertise poses challenges. Recent research has examined BIM bid documents using deep learning models. Text segmentation into meaningful units (e.g., words) is necessary for feature extraction to improve analysis effectiveness. This segmentation is influenced by the choice of Korean morphological analyzers, but studies on their impact are limited. This study examined how different Korean morphological analyzers affect the performance of deep learning models in classifying the difficulty of BIM requirements. Morphological analyzers based on linguistic rules, machine learning, and probabilistic relationships were used for tokenization and encoding. These were applied to a long-short-term memory classification model trained on a BIM requirements dataset to assess hyper-parameters and performance metrics. The results showed that the variation in F1 scores due to analyzers was minimal (below 0.03, F1: 0.91-0.94). This suggests that classification model performance differences are negligible when analyzers effectively distinguish nouns and particles, simplifying the choice of analyzers for such tasks."
인공지능 기술을 활용한 뉴스 원고 작성에 대한 고찰,2025,"['인공지능', '뉴스 산업', '자동화 뉴스', '정보 수집', '저작 윤리', 'Artificial Intelligence', 'News Industry', 'Automated News Writing', 'Information Collection', 'Author Ethics']","디지털 인텔리전스× 시대로 전환하면서 인공지능 기술은 모든 산업에 영향을 주고 있다. 방송 분야의 뉴스 산업도 인공지능 기술은 변화를 이끌고 있다. 과거의 단일 유형의 데이터 처리에서 크로스미디어 인식과 추론으로, 기계 개별 지능에서 네트워크 기반으로, 인간과 결합된 증강 집단 지능으로, 생산로봇에서 자율시스템으로 전환 및 발전하면서 인공지능 기술은 뉴스 생산의 효율성에 중요한 역할을 하고 있다. 또한 기술적 어려움이 있었던 자연어 처리(NLP)를 극복하고 있는 인공지능 기술은 쌓이고 있는 데이터베이스와 머신러닝 과 딥러닝 기술을 통하여 뉴스의 생산과 재생산을 할 수 있게 되었다. 이렇게 인공지능에 의해 제작된 뉴스 저작물은 기술적으로도 제도적 해석으로도 큰 변화이다. 기술의 발전 속도를 제도의 정비는 아직 비흡한 단계이다. 앞으로 윤리적인 문제와 법적분쟁이 제기 될 수 있으므로 저작법 제도 정립이 필요하다고 하겠다.","As we transition into the digital intelligence era, artificial intelligence technology is impacting all industries. Artificial intelligence technology is also leading changes in the broadcasting news industry. As it transitions and develops from single-type data processing in the past to cross-media recognition and reasoning, from individual machine intelligence to network-based, to augmented collective intelligence combined with humans, and from production robots to autonomous systems, artificial intelligence technology plays an important role in the efficiency of news production. In addition, artificial intelligence technology, which overcomes the technical difficulties of natural language processing (NLP), has made it possible to produce and reproduce news through accumulating databases and machine learning and deep learning technologies. In this way, news works produced by artificial intelligence are a major change both technically and institutionally. The pace of technological development is still at a low level in terms of institutional development. Since ethical issues and legal disputes may arise in the future, it is necessary to establish a copyright law system."
데이터마이닝과 LDA 토픽모델링을 통한 게임 개발 연구동향 분석: SCOPUS DB를 중심으로,2025,"['게임', '게임 개발', '게임 개발 연구', '연구동향', 'LDA', 'Games', 'Game Development', 'Game Development Research', 'Research Trends', 'LDA']","본 연구는 미래 게임 개발의 방향성을 이해하기 위하여 게임 개발에 관한 글로벌 연구 동향을 분석하고자 한다. 이에 본 연구에서는 SCOPUS DB에서 제목을 “게임 개발”로 한정하여 논문(article)을 검색하여 초록이 제공되는 논문을 선정하였다. 이를 대규모 데이터에서 유의미한 패턴과 정보를 추출하는 텍스트마이닝 기법과 문서의 집합에서 토픽을 찾아내는 프로세스 토픽모델링 기법인 LDA를 활용하여 분석을 수행하였다. 키워드 분석 결과, Software Design, Game Development, Serious Games, Students, Game Theory, Computer Games 순으로 그 중요도가 나타났으며, LDA 분석 결과, Development, Game, Learning, Study, Students, Process, Using, Serious, Education 순으로 그 중요도가 나타났다. 향후 연구에서는 학술 제공 데이터베이스를 확대하고 머신러닝과 딥러닝 기법을 활용한 다양한 분석 방법을 활용한 연구가 필요하며, 국가 간에 게임 개발과 관련된 비교연구를 수행하는 것이 필요할 것으로 기대한다.","This study aims to analyze global research trends on game development in order to understand the direction of future game development. Therefore, in this study, the article in which the abstract is provided was selected by searching the article by limiting the title to ""game development"" in the SCOPUS DB. The analysis was performed using a text mining technique that extracts meaningful patterns and information from large-scale data and LDA, a process topic modeling technique that finds a topic in a set of documents. As a result of keyword analysis, the importance was shown in the order of Software Design, Game Development, Serious Games, Students, Game Theory, and Computer Games, and as a result of LDA analysis, the importance was shown in the order of Development, Game, Learning, Study, Students, Process, Using, Serious, and Education. In future research, it is expected that it will be necessary to expand the academic-provided database, conduct research using various analysis methods using machine learning and deep learning techniques, and conduct comparative research related to game development between countries."
Kubeflow 시스템에서 AI 모델 배포 전략 : BentoML 중심으로,2025,"['MLOps', 'Kubeflow', 'BentoML', '쿠버네티스', '배포', 'MLOps', 'Kubeflow', 'BentoML', 'Kubernetes', 'Deployment']","MLOps 접근 방식은 AI 모델을 효과적으로 관리하기 위해 필수적이며, BentoML은 모델의 상용화에서 발생할 수 있는 배포 문제를 해결하는데 유용하게 사용된다. BentoML의 Swagger UI를 활용한 API 명세 관리는 엔드포인트, 요청 및 응답 구조, 배포 상태 등을 명확하게 문서화하여 모델 운영의 안정성을 높이고 디버깅과 유지보수를 용이하게 한다. 모델은 Kubeflow에서 자동화된 파이프라인을 통해 실행되며, 모델의 전체 워크플로우를 관리하고 머신러닝과 딥러닝 프레임워크와 통합을 지원하여 작업의 일관성을 보장한다. 연구 결과, 모든 평가 항목에서 BentoML의 성능이 더 우수한 것으로 나타났으며, 이는 모델 배포 및 관리를 위한 BentoML의 통합 기능이 유사한 사례에서 최적의 성능을 위해 추가 구성이 필요한 경우 FastAPI와 같은 프레임워크에 비해 우수한 선택임을 보여준다.","MLOps(Machine Learning Operations) be essential for effective AI(Artificial Intelligence) model management, with bentoml deployment as a useful tool to deployment issues that arose during model commercialization. Use bentoml swagger ui for api specification management helped ensure model stability by provide clear documentation of endpoints, request and response structures, and deployment statuses, which also facilitated debugging and maintenance. Model workflow be managed through automated pipeline in kubeflow, support integration with machine learning and deep learning framework to maintain consistency. As a result of the research, performance of bentoml was found to be  superior across all evaluation criteria. This indicated that bentoml integrated feature for model deployment and management made it a better choice compared to framework like fastapi, which required additional configuration to achieve optimal performance in similar case."
Diagnostic accuracy of artificial intelligence in the detection of maxillary sinus pathology using computed tomography: A concise systematic review,2025,"['Artificial Intelligence', 'Computed Tomography', 'X-Ray', 'Maxillary Sinus', 'Pathology']",,"Purpose: This study was performed to assess the performance and accuracy of artificial intelligence (AI) in the detection and diagnosis of maxillary sinus pathologies using computed tomography (CT)/cone-beam computed tomography (CBCT) imaging.Materials and Methods: A comprehensive literature search was conducted across 4 databases: Google Scholar, BioMed Central (BMC), ProQuest, and PubMed. Combinations of keywords such as “DCNN,” “deep learning,” “convolutional neural network,” “machine learning,” “predictive modeling,” and “data mining” were used to identify relevant articles. The study included articles that were published within the last 5 years, written in English, available in full text, and focused on diagnostic accuracy.Results: Of an initial 530 records, 12 studies with a total of 3,349 patients (7,358 images) were included. All articles employed deep learning methods. The most commonly tested pathologies were maxillary rhinosinusitis and maxillary sinusitis, while the most frequently used AI models were convolutional neural network architectures, including ResNet and DenseNet, YOLO, and U-Net. DenseNet and ResNet architectures have demonstrated superior precision in detecting maxillary sinus pathologies due to their capacity to handle deeper networks without overfitting. The performance in detecting maxillary sinus pathology varied, with an accuracy ranging from 85% to 97%, a sensitivity of 87% to 100%, a specificity of 87.2% to 99.7%, and an area under the curve of 0.80 to 0.91.Conclusion: AI with various architectures has been used to detect maxillary sinus abnormalities on CT/CBCT images, achieving near-perfect results. However, further improvements are needed to increase accuracy and consistency."
광대역 주파수 스펙트럼과 이미지처리를 이용한 기계학습 모델 기반 날씨 예측 시스템 설계,2025,"['AI', 'radio frequency', 'hack RF', 'raspberry pi', 'image processing', '.']","본 연구에서는 1MHz~6GHz의 SDR 기기인 Hack RF와 Raspberry Pi 5를 활용하여 주파수 스펙트럼 및 이미지처리를 통한 기계학습 모델 기반 정밀 날씨 예측 시스템을 구현하였다. 보다 정밀한 날씨 예측을 위하여 온도, 습도, 기압 데이터는 Raspberry Pi의 BME 280 센서를 사용하여 수집하고, Hack RF를 통해 100MHz~300MHz, 600MHz~800MHz, 2.3GHz~2.5GHz 총 3개의 주파수 대역에서의 PSD(Power Spectrum Density) 변화와 OV5647 이미지 센서를 이용해 날씨 이미지의 RGB 비율 변화를 감지하였다. 수집된 데이터를 텍스트 파일로 전처리 후 소켓 통신을 이용하여 노트북으로 전송하였다. 전송받은 데이터는 파이썬의 RandomForestClassifer 기계학습 알고리즘을 이용하여 학습하고 날씨 예측을 할 수 있으며, 이를 기존 기상 예보와 비교하여 본 연구에서 제안한 새로운 접근법의 정확성을 검증하였다.","In this paper, we implemented a precise weather prediction system based on machine learning through frequency spectrum and image processing by utilizing Hack RF, an SDR device from 1MHz to 6GHz, and Raspberry Pi 5. For more precise weather prediction, temperature, humidity, and atmospheric pressure data were collected using the BME 280 sensor of the Raspberry Pi, and Power Spectrum Density(PSD) changes in three frequency bands, 100MHz~300MHz, 600MHz~800MHz, and 2.3GHz~2.5GHz, were detected using the Hack RF, and RGB ratio changes in weather images were detected using the OV5647 image sensor. The collected data was preprocessed into a text file and sent to a laptop using Socket Communication. The received data was trained using the RandomForestClassifer machine learning algorithm in Python to make weather predictions and compared with existing weather forecasts to verify the accuracy of the new approach proposed in this paper."
정책지원 투명성 강화를 위한 AI 분석 시스템 연구: NTIS의 양자 분야 사례 분석,2025,"['AI', 'Risk Management', 'LLM', 'NTIS']",,"This study aims to develop an AI-based analysis system that aligns with the international trend of AI legislation, including the EU's AI Act, while also addressing the analytical needs of the public sector. The focus is on providing timely and objective information to policymakers and specialized researchers by exploring advanced analytical methodologies. As the complexity and volume of data rapidly increase in the modern policy environment, these methods have become essential for governments to obtain the objective information needed for critical decision-making. To achieve this, the study integrates machine learning, natural language processing (NLP), and Large Language Models (LLM) to create a system capable of meeting the analytical demands of government entities. The target dataset consists of “quantum” field data collected from South Korea's National R&D Information System (NTIS). Machine learning was applied to this data to assess the validity of the analysis, while BERTopic, a natural language analysis package, was used for text analysis. With the introduction of LLMs, the extracted information from machine learning and natural language analysis was not merely listed but also connected in meaningful ways to provide policy insights. This approach enhanced the transparency and reliability of AI analysis, minimizing potential errors or distortions in the data analysis process. In conclusion, this study emphasizes the development of a system that enables rapid and accurate information provision while maintaining compatibility with international AI regulations such as the AI Act. The use of LLMs, in particular, contributed to enhancing the system’s capabilities for deeper and more multifaceted analysis."
드론 영상 및 증강 현실 글래스 기반 실시간 인공 지능 달리기 코칭 시스템 : 특허출원 10-2024-0162589,2025,"['Drone-Based movement analysis', 'Augmented Reality (AR) glasses', 'Artificial Intelligence (AI) Sports coaching', 'Real-Time running coaching system']",,"Purpose: This study aims to develop a drone-based running coaching platform that integrates real-time movement tracking, environmental data analysis, and personalized feedback to enhance performance and safety in long-distance running activities, such as marathons. The system combines drones, augmented reality (AR) glasses, wearable devices, AI-based data analysis, and large language model (LLM)-powered coaching.Method: The proposed system utilizes drones equipped with high-resolution cameras and motion detection capabilities to monitor runners’ postures, strides, and landing patterns. AR glasses provide real-time environmental information, including terrain and weather conditions. Wearable devices track physiological data such as heart rate and oxygen saturation, while the collected data are transmitted to a cloud server for analysis using machine learning models. Personalized coaching is delivered through an LLM system that provides real-time feedback and advice tailored to the runner’s specific needs and conditions.Results: The integrated system effectively captures and analyzes real-time data, offering customized feedback to improve running efficiency and prevent injuries. The drone-based motion detection system accurately monitors movement, while the AR glasses provide environmental insights. Machine learning models analyze user data to generate personalized training strategies, and the LLM-powered coaching system provides interactive situation-specific guidance. The system demonstrated the ability to optimize the performance while ensuring safety in different running environments.Conclusion: This research highlights the potential of combining advanced technologies to create an innovative coaching platform for long-distance running. The system addresses limitations of traditional coaching methods by integrating real-time data collection and analysis, environmental adaptability, and personalized feedback. Future work will focus on validating the reliability and scalability of the system in various practical settings, paving the way for broader applications in sports and rehabilitation."
LSTM 오토인코더를 이용한 네트워크 패킷 분석 및 알려지지 않은 침입 탐지에 대한 연구,2025,"['LSTM', '오토인코더', '네트워크 침입 탐지', 'CIC-IDS2018', 'LSTM', 'Autoencoder', 'Network intrusion detection', 'CIC-IDS2018']","네트워크를 통한 침입을 탐지하기 위해 패킷 시그니처 기반의 공격 탐지 방법을 가장 많이 사용하고 있으나, 알려지지 않은 공격에 대해서는 취약함을 보여주고 있다. 따라서 기계학습을 이용하여 네트워크 패킷을 학습하고 알려지지 않은 공격 여부를 판단하는 여러 가지 기계학습 모델들이 활발하게 연구되고 있다. 본 연구에서는 시계열 데이터 학습에 우수한 성능을 보여주는 LSTM 오토인코더(Long Short-Term Memory Autoencoder) 모델을 설계하여 정상 데이터를 학습하고, 정상 데이터와 침입 데이터가 포함된 혼합 데이터를 통해 모델을 테스트하여 재구성 손실을 계산한다. 이 재구성 손실 값을 기반으로 임계 값을 구하여 침입 탐지를 수행하는 최적의 네트워크 침입 탐지 모델에 대하여 연구하였다. 최종 실험된 결합 모델은 정확도 98%와 F-1 점수 98%의 높은 성능을 보여주었다.","Attack detection methods based on packet signatures are most used to detect intrusions into networks, but they are vulnerable to unknown attacks. Therefore, there are many models that use machine learning to learn network packets and determine the presence of unknown attacks. In this study, we designed a Long Short-Term Memory Autoencoder (LSTM autoencoder) model, which shows good performance in learning time series data, to learn normal data, test the model on mixed data containing normal and intrusive data, and calculate the reconstruction loss. Based on this reconstruction loss value, a network intrusion detection model is studied to perform intrusion detection by obtaining a threshold value. The final experimented combined model shows a high performance of 98% accuracy and F-1 score of 98%."
Triage Data-Driven Prediction Models for Hospital Admission of Emergency Department Patients: A Systematic Review,2025,"['Admission', 'Hospitalization', 'Prognosis', 'Emergencies', 'Triage']",,"Objectives: Emergency department (ED) overcrowding significantly impacts healthcare efficiency, safety, and resourcemanagement. Predictive models that utilize triage information can streamline the admission process. This review evaluatesexisting hospital admission prediction models that have been developed or validated using triage data for adult ED patients.Methods: A systematic search of PubMed, Embase, CINAHL, Web of Science, and the Cochrane Library was conducted.Studies were selected if they developed or validated predictive models for hospital admission using triage data from adultED patients. Data extraction adhered to the CHARMS (Checklist for Critical Appraisal and Data Extraction for SystematicReviews of Prediction Modelling Studies), and the risk of bias was evaluated using PROBAST (Prediction model Risk of BiasAssessment Tool). Results: Twenty studies met the inclusion criteria, employing logistic regression and machine learning techniques.Logistic regression was noted for its traditional use and clinical interpretability, whereas machine learning providedenhanced flexibility and potential for better predictive accuracy. Common predictors included patient demographics, triagecategory, vital signs, and mode of arrival. The area under the curve values for model performance ranged from 0.80 to 0.89,demonstrating strong discriminatory ability. However, external validation was limited, and there was variability in outcomedefinitions and model generalizability. Conclusions: Predictive models based on triage data show promise in supporting EDoperations by facilitating early predictions of hospital admissions, which could help decrease boarding times and enhance patientflow. Further research is necessary to validate these models in various settings to confirm their applicability and reliability."
종합병원 간호사의 전문직 삶의 질이 이직의도에 미치는 영향:  선형 분석과 비선형 분석 기법을 활용한 비교 연구,2025,"['Nurses', 'Professional quality of life', 'Turnover intention', '간호사', '전문직 삶의 질', '이직의도']","연구목적: 본 연구는 종합병원 간호사의 전문직 삶의 질이 이직의도에 미치는 영향을 선형 분석과 비선형 분석 기법을 활용하여 조사하였다. 연구방법: 종합병원 간호사 159명을 대상으로 자료를 수집하였으며, SPSS를 활용하여 t-test, ANOVA, 피어슨 상관계수, 다중 선형 회귀 분석 및 비선형 기계 학습 모델(Bootstrap Forest와 Boosted Tree)을 사용하여 분석하였다. 연구결과: 이직의도는 공감만족(r=-.26, p<.001)과 소진(r=.27, p=.001)에 모두 유의미한 상관관계를 보였다. 이직의도에 영향을 미치는 주요 변수는 공감만족, 소진 그리고 이차 외상성 스트레스가 확인되었다. 다중 선형 회귀분석의 설명력은 6.9%로 나타난 반면, 비선형 기계 학습 모델인 Bootstrap Forest는 50.5%, Boosted Tree는 45.1%의 설명력을 보였다. 결론: 종합병원 간호사의 장기 근속을 유도하기 위해서는 간호 조직 내에서 인적 자원 관리를 위한 지속적인 투자가 필요하다. 이러한 투자는 공감만족을 높이고, 소진과 이차 외상성 스트레스를 줄이며, 소명의식과 긍정적인 직무 만족을 고취하는 데 초점을 맞춰야 한다.","Purpose: This study examined the impact of professional Quality of life (QoL) on turnover intention among general hospital nurses using linear and nonlinear analytical techniques. Methods: Data were collected from 159 general hospital nurses and analyzed using SPSS, t-test, ANOVA, Pearson's correlation coefficients, multiple linear regression, and nonlinear machine learning models (Bootstrap Forest and Boosted Tree). Results: Significant correlations were observed between turnover intention and both compassion satisfaction (r=-.26, p<.001) and burnout (r=.27, p=.001). Compassion satisfaction, burnout, and compassion fatigue were identified as the key variables influencing turnover intention. The explanatory power of multiple linear regression analysis was 6.9%, whereas the nonlinear machine learning models demonstrated an explanatory power of 50.5% for Bootstrap Forest and 45.1% for Boosted Tree. Conclusion: Continuous investment in human resource management, within nursing organizations, is essential to promote the long-term retention of general hospital nurses. This investment should focus on enhancing compassion satisfaction and reducing burnout and compassion fatigue by fostering a sense of vocation and positive job satisfaction."
공공 기술 사업화 예측 모델에서 원-핫 인코딩된 불균형 데이터 처리 방법,2025,"['공공 기술 사업화', '데이터 불균형', '오버 샘플링', '원-핫인코딩', '분류 예측', 'Public technology commercialization', 'Data Imbalance', 'Over Sampling', 'One-Hot Encoding', 'Classification Prediction']","공공 기술 사업화는 한 국가의 과학기술 정책 효율성을 평가하는 중요한 척도 가운데 하나이다. 따라서 기계학습을 이용하여 공공 기술에 대한 사업화 여부를 사전에 예측하거나, 개발된 공공 기술을 도입할 가능성이 높은 수요기업을 발굴하고자 하는 시도가 지속적으로 증가하고 있다. 하지만 공공 기술 사업화 데이터는 성공 사례가 드물게 발생하는 전형적인 불균형 데이터 특성을 가진 명목형 데이터의 특성을 보유하고 있어 데이터 증강 방법을 적용하기 어렵다. 명목형 변수는 SMOTE와 같은 오버 샘플링 방법으로는 비즈니스 규칙에 맞지 않는 훈련 데이터를 생성하거나, 정확도 개선 효과가 떨어지는 이유 때문이다. 이 논문에서는 기계학습의 모델 구축 과정에서 최적 Hyper Parameter를 선정하기 위해 사용되는 Grid Search 방법을 훈련 데이터를 생성하는데 활용하는 방법을 제안한다. 제안된 훈련 데이터 구축 방법의 효과를 검증하기 위해 과거 사업화 실증 이력 데이터를 활용하여 사업화 성공 여부를 예측하고, 기존의 처리 방법과 제안 방법을 상호 비교하였다. 실험 결과, 제안 방법이 기존 데이터 증강 방법과 비슷하거나 더 높은 분류 예측 성능을 보이면서도, 업무 규칙에 맞는 데이터를 생성한다는 장점을 확인하였다.","Public technology commercialization is one of the important measures for evaluating the efficiency of a country's science and technology policy. Therefore, attempts to predict whether public technology will be commercialized in advance using machine learning or to discover companies with high potential to adopt developed public technologies are continuously increasing. However, public technology commercialization data has the characteristics of nominal data with typical imbalanced data characteristics with rare success cases, making it difficult to apply data augmentation methods. This is because nominal variables generate training data that does not conform to business rules or have low accuracy improvement effects when using oversampling methods such as SMOTE. In this paper, we propose a method to utilize the Grid Search method, which is used to select optimal Hyper Parameters in the model building process of machine learning, to generate training data. In order to verify the effectiveness of the proposed training data construction method, past commercialization empirical history data was used to predict whether commercialization was successful, and the existing processing method and the proposed method were compared with each other. The experimental results confirmed that the proposed method has a classification prediction performance similar to or higher than the existing data augmentation method, while generating data that conforms to business rules."
전자기파 신호분석을 통한 무기체계 부품 이상행위 탐지 연구,2025,"['Hardware Trojan', 'Anomaly Detection', 'Electromagnetic Analysis', 'Side channel analysis', 'FPGA', 'ASIC', '하드웨어 트로이목마', '이상행위 탐지', '전자기파 분석', '부채널 분석', 'FPGA', 'ASIC']","본 논문은 무기체계 및 IoT 장비 부품에서 발생하는 이상행위를 탐지하기 위해 부채널 분석을 이용하여 장비 부품 해체와 같은 파괴적 방법이 아닌 조립된 상태 그대로 검사하는 비파괴적 방법의 적용 가능성을 보였다. 무기체계 부품에서 발생하는 이상행위는 하드웨어 트로이목마 (HT, Hardware Trojan)에 의해 발생하는 것을 의미하며 부채널 분석 방법 중에서도 전자기파 신호분석을 이용하였다. 초기 시험은 HT공유 포털에서 제공하는 암호 모듈인 AES(Advanced Encryption Standard)-128 GM(Golden Model)과 HT들로 시험했으며 대상 하드웨어 플랫폼은 먼저 FPGA(Field Programmable Gate Array)에서, 그 후에는 ASIC(Application Specific Integrated Circuit) 칩을 제작하여 시험하였다. IoT 장비로는 RC 자동차, 무기체계 장비 부품으로는 군통신체계에 사용된 FPGA와 동일한 신규 제품과 시뮬레이션 장비를 이용하여 시험함으로써 무기체계에서 부품 이상 여부를 탐지할 수 있는 기술의 적용 가능성을 보였다.","This paper demonstrates the possibility of a non-destructive method that inspects the assembled state of the equipment circuit rather than a destructive method such as disassembling the equipment circuits, using side-channel analysis to detect abnormal behaviors in weapon systems and IoT equipment circuits. The abnormal behaviors generated in weapon system circuits are caused by hardware Trojans (HTs), and electromagnetic signal analysis was used among the side-channel analysis methods. The initial experiments were conducted with the AES-128 GM, an encryption module provided by the HT sharing portal, and HTs. The target hardware platform was first implemented in the FPGA, and then tested on the manufactured ASIC chip. Initially, the tests were conducted using supervised learning machine learning as an abnormal behavior detection algorithm, and then unsupervised learning deep learning models were used. After proving the possibility with the FPGA and the manufactured ASIC chip, the tests were conducted on the RC car as IoT equipment, and the possibility of the circuit abnormal behavior detection technology was demonstrated by conducting experiments on the same product FPGA applied to the weapon system."
이미지 색 공간 융합을 통한 픽셀 클러스터링 기반 수중 이미지 내의 반사광 탐지 알고리즘,2025,"['Machine Learning(머신 러닝)', 'K-Means Clustering(K 평균 군집화)', 'Multi-Channel Image(다채널 이미지)', 'Pixel Clustering(픽셀 클러스터링)', 'Underwater Image(수중 이미지)']",,"Robots designed to assist and ensure safety during underwater diving activities utilize underwater cameras to gather real-time diver information. This study proposes a breath bubble detection algorithm based on unsupervised kmeans clustering to overcome the high accuracy demand of deep learning models and the challenge of constructing training datasets. By integrating color and relative coordinate information from underwater images and applying CLAHE to reduce noise, pixel clustering is performed to extract reflective regions. Experimental results demonstrate the effectiveness of the proposed algorithm in detecting breath bubble regions in underwater images. Improved detection accuracy is achieved through the combination of RGB, LAB, and HSV color spaces. This research provides a foundation for the monitoring of diver status and equipment malfunctions in underwater environments."
경기장 설계 및 건설 경향에 대한 사례 및 문헌고찰,2025,"['Machine learning', 'Steel frame structures', 'Seismic response', 'Prediction methods', 'Deep learning']",,"This paper examines recent trends in stadium design and construction through a comprehensive case study and literature review. It highlights the innovative use of advanced building materials, such as high-performance composites and sustainable concrete mixes, which enhance structural integrity while reducing environmental impact. The integration of smart technologies—including IoT technologies, building information modeling (BIM), and digital twin—is explored for its role in improving operational efficiency, safety, and maintenance processes. Additionally, the study reviews the development of cutting-edge engineering techniques like seismic design, advanced AI-based structural analysis, which streamline construction processes and optimize resource usage. Emphasizing sustainability, the paper also discusses strategies for energy-efficient designs and renewable energy integration. Overall, the findings demonstrate how interdisciplinary approaches combining material science, smart technology, and sustainable engineering are shaping the future of stadium construction."
클러스터링 기법을 활용한 대한민국 행정구역(시군구) 별 의료 자원의 균형 평가,2025,"['머신러닝', '클러스터링', '차원 축소', '의료 균형', '의료 접근성', 'Machine Learning', 'Clustering', 'Dimensionality Reduction', 'Medical Balance', 'Medical Accessibility']","본 연구에서는 클러스터링 기법을 활용하여 대한민국의 시군구별로 의료 자원과 인구 간의 균형을 분석하였다. 의료 이용 패턴, 인구 특성을 담은 공공데이터를 사용하였으며 K-Means, Hierarchical Clustering, Spectral Clustering 등 다양한 클러스터링 기법과 PCA, t-SNE, LLE 등의 조합 및 하이퍼파라미터를 실험적으로 평가하여 데이터에 가장 높은 클러스터링 성능을 보이는 조합을 탐색한 결과 K-Means, 클러스터 개수 3개, LLE 조합이 적합함을 확인하였다. 클러스터 간 비교를 수행하였을 때 각 클러스터의 차이를 뚜렷하게 나타내는 다양한 특성을 발견하였고 이를 통해 유의미한 인사이트를 도출하였다. Random Forest Feature Importance를 사용하여 클러스터를 구분짓는 요인을 도출하였다. 각 변수의 동일한 스케일을 위해 Z-Score 표준화하였으며 변수 기여도를 가중치로 설정하여 합산한 점수를 순위별로 나열하였다. 본 연구의 결과가 실질적인 의료 인프라 개선을 위한 정책을 제시하는 데 도움이 될 것이라 기대한다.","In this study, we analyzed the balance between medical resources and population across cities, counties, and districts in South Korea using clustering models. Public data containing detailed medical usage patterns and population characteristics were used, and various clustering models such as K-Means, Hierarchical Clustering and Spectral Clustering were combined with dimensionality reduction methods such as PCA, t-SNE and LLE. Each clustering model, dimensionality reduction method, and hyperparameter combination was evaluated experimentally. As a result, the combination showing the highest clustering performance was determined to be K-Means with k=3 in conjunction with LLE. When comparing clusters, various characteristics indicated their differences. It provides highly meaningful insight into the medical gap in South Korea’s administrative districts. The factors that distinguish clusters were derived using random forest feature importance. The weighted sum of medical institutions, total specialized equipment, proportion of youth medical expenses, proportion of youth hospital staff, and number of hospitals per 1 km² was identified as the key variable that distinguishes clusters. We set these factors as weights, and the Z-Score standardized scores were ranked accordingly. It is expected that the results of this study will significantly contribute to the government policy proposal that suggests practical directions for medical infrastructure improvement."
설계 문서 접점을 이용한 개선 업무용 사용자 수정형 AI 인과 예측 모델 개발,2025,"['User-modified AI', 'MG AI(model generation AI)', 'DDI(design document interface)', 'Understandable and modifiable AI', 'AI chef']",,"Machine learning a artificial intelligence (AI) derives correlations between manufacturing variables from the data. These correlations can be classified into causal and noncausal relationships. In the design for manufacturing, only causal relationships are applicable because control based on causality is necessary to produce the desired product. Domain knowledge is required to confirm the causality and develop a predictive model based on causal relationships. However, domain experts often lack the AI-related knowledge necessary to develop such models, including the skills in AI, coding, and data mining. To overcome this challenge, we developed an AI system that leverages a design document interface (DDI), allowing domain experts to easily create AI models tailored to their tasks even without extensive AI expertise."
전류신호를 활용한 선박용 유도전동기의 이상진단 방법 연구,2025,"['이상진단', '머신러닝', '전류신호', '유도전동기', '분포간 거리', 'Anomaly Detection', 'Machine Learning', 'Current signal', 'Induction motor', 'Statistical distance']","최근 함정과 같은 특수선에서 전기추진체계로의 전환 시도에 따라 회전기 이상진단에 대한 관심이 증가하고 있다. 본 연구에서는 전류신호 기반의 유도전동기 이상진단 정확도의 향상을 위해 3상 전류신호로부터 추출된 36개의 특징인자에 대해 Isolation Forest 기반 1차 이상진단 모델과 진단 결과의 누적분포에 대한 통계적 분석을 통한 2차 이상진단 알고리즘을 제시하였다. 개발된 모델의 학습 및 검증을 위해 실험용 전동기를 대상으로 베어링, 체결결함, 회전자, 고정자 고장을 포함하는 9종의 모사 실험이 수행되었다. 실험용 전동기로부터 취득된 전류 데이터를 대상으로 1차 진단모델에서 이상 데이터의 재현율이 54% 도출된 것에 대비해 통계적 분석이 접목된 2차 진단모델에서 재현율이 100%로 개선됨에 따라 제시된 알고리즘의 효용성을 확인할 수 있었다.","With the growing interest in electric propulsion systems for naval ships, the need for reliable anomaly detection of rotating machinery has also increased. This study aims to improve the accuracy of induction motor anomaly detection based on current signals by introducing a two-stage detection algorithm. The first stage employs an Isolation Forest model using 36 features extracted from three-phase current signals, while the second stage integrates statistical analysis of the cumulative distribution of detection results. To validate the proposed model, experiments were conducted using a test motor to simulate nine types of anomalies, including bearing defects, mechanical looseness, rotor faults, and stator faults. Compared to the first-stage model, which achieved a recall of 54% for anomalous data, the second-stage model incorporating statistical analysis demonstrated a recall of 100%, confirming the effectiveness of the proposed algorithm."
Generative autoencoder to prevent overregularization of variational autoencoder,2025,"['autoencoder', 'data augmentation', 'dimensionality reduction', 'generative model', 'variational autoencoder']",,"In machine learning, data scarcity is a common problem, and generative models have the potential to solve it. The variational autoencoder is a generative model that performs variational inference to estimate a low-dimensional posterior dis-tribution given high-dimensional data. Specifically, it optimizes the evidence lower bound from regularization and reconstruction terms, but the two terms are imbalanced in general. If the reconstruction error is not sufficiently small to belong to the population, the generative model performance cannot be guaran-teed. We propose a generative autoencoder (GAE) that uses an autoencoder to first minimize the reconstruction error and then estimate the distribution using latent vectors mapped onto a lower dimension through the encoder. We com-pare the Fréchet inception distances scores of the proposed GAE and nine other variational autoencoders on the MNIST, Fashion MNIST, CIFAR10, and SVHN datasets. The proposed GAE consistently outperforms the other methods on the MNIST (44.30), Fashion MNIST (196.34), and SVHN (77.53) datasets."
클러스터 내 Container Registry 구성을 통한 컨테이너 이미지 배포 효율성 향상,2025,"['클러스터', '엣지 컴퓨팅', 'Container 레지스트리', '컨테이너 이미지', '배포 효율성', 'Cluster', 'Edge Computing', 'Container Registry', 'Container Image', 'Deployment Efficiency']",,"Large-scale machine learning models and data analysis applications use container images to process vast amounts of data, and there is a problem of lengthening the distribution time of such images Longer image distribution time slows down the development and distribution cycle, which lowers productivity and can reduce the performance and flexibility of the entire system. In order to solve this problem, we propose ways to improve container image management and distribution efficiency. We focus on how to reduce time and traffic consumption compared to image downloading through the cloud by utilizing cluster container registry (CCR) when distributing images. Experiments were conducted in a Kubernetes, and the efficiency of container image management and distribution process was explored. Compared to the existing method, the distribution time was reduced by an average of 30% in each scenario, with larger image sizes showing even greater improvements."
건설공사비지수 예측을 위한 선행지표 기반 다변량 시계열 분석 및 모델 성능 비교,2025,"['건설공사비지수', '머신러닝', '다변량 모델', '통계적 검정', '선행지표', 'Construction Cost Index', 'Machine Learning', 'Multivariate Model', 'Statistical Validation', 'Leading Indicators']","건설공사비지수(CCI)는 건설 자원 가격 변동을 측정하는 지수로, 정확한 예측이 필수적이다. 본 연구는 VAR 모델을 활용해 CCI를 예측하며, 건축 수주액, BSI, PPI-형강을 선행지표로 선정했다. AIC 기반 최적화 후 ARIMA, VAR(CPI, PPI), SVR과 비교 검증하였으며, 2000~2023년 데이터로 Walk-Forward 교차 검증을 수행했다. 분석 결과, 제안된 모델은 단기·중기 예측에서 가장 낮은 오차를 기록했으며, 장기 예측에서는 SVR이 우수했으나 전체 추세 반영에서는 제안된 모델이 더 균형적이었다.","The Construction Cost Index (CCI) is a key measure of price fluctuations in major construction resources, playing a crucial role in costestimation and price trend analysis. Accurate CCI forecasting is essential to prevent cost underestimation or overestimation, ensuring theeconomic feasibility of construction projects. This study forecasts the CCI using a multivariate time series model, Vector Autoregression(VAR), to address the limitations of univariate models, especially during economic uncertainty. Through statistical validation, three leadingindicators were identified: construction order amount, business survey index (BSI), and producer price index (PPI) for structural steel. Theproposed model was optimized using the Akaike Information Criterion (AIC), while benchmark models ARIMA, VAR (CPI, PPI), and SVRwere optimized through grid search. Model validation was conducted using data from January 2000 to April 2023, segmented into threeeconomic phases: stability, heightened uncertainty, and a combined period. Walk-forward cross-validation assessed predictive performance overshort-term forecasts of 3 months, mid-term forecasts of 6 months, and long-term forecasts of 12 months, with evaluation based on averagedperformance metrics over multiple iterations. Results showed that the proposed model achieved the lowest error and highest accuracy in shortandmid-term forecasts. For long-term forecasts, SVR recorded the lowest error; however, qualitative analysis indicated that the proposedmodel more effectively captured overall trends in a balanced manner. By integrating key market indicators, this approach provides a robustmethod for CCI forecasting, enhancing cost predictability in the construction industry."
대한민국 스포츠 스타의 자서전 감정분석: 인공지능 언어 모델 KoBERT를 활용하여,2025,"['감정', '자서전', '머신 러닝', 'KoBERT', '긍정심리학', 'Emotion', 'Autobiography', 'Machine Learning', 'KoBERT', 'Positive Psychology']","연구목적 이 연구는 성공한 스포츠 스타들의 삶 전반이 어떠한 감정으로 자서전에 담겨있는지 확인하고, 긍정심리학의 관점에서 긍정적, 부정적 감정이 그들의 자서전 속 삶에 얼마나 차지하였는지 알고자 하였다. 객관적인 분석을 위해 한국어 감정분석에 유용한 인공지능 모델(KoBERT)을 학습시켰으며, 이를 활용하여 비교, 분석하였다. 연구방법 이 연구는 대한민국 스포츠 스타 6인(야구 4명, 축구 2명)의 자서전 문장을 활용하여 진행하였다. 사용된 문장의 전체 개수는 20,781개다. 자료 처리 방법으로 한국어 인공지능 모델인 KoBERT를 2차례에 걸쳐 추가 학습하였으며, 학습을 위해 사용된 문장은 1차 96,865개, 2차 43,799개다. 학습된 모델의 최종 학습률은 89.85%이며, 정답률은 77.31%이다. 결과 첫째, 대한민국 스포츠 스타 6인의 자서전 문장 속 감정은 부정적인 감정의 빈도가 더 높았다. 둘째, 문장 속 감정의 빈도는 슬픔, 기쁨, 공포, 놀람, 분노, 행복, 혐오, 당황, 불안, 상처의 순서로 나타났다. 이 중 슬픔, 기쁨의 합은 80% 이상을 차지하였다. 결론 이 연구의 대상인 스포츠 스타  6인의 자서전 속 문장은 부정적인 감정이 매우 높고, 문장의 대부분을 차지하고 있는 슬픔과 기쁨을 제외한 부정적인 감정들은 빈도가 매우 작게 나타나 개인의 역량과 노력을 통해 통제하고 극복했을 가능성이 있다. 인간의 감정과 내면은 복잡하고 불규칙하기에 긍정적인 결과를 얻기 위해서는 한 가지 감정만을 강조하거나, 부정적 감정을 무조건 배척하는 시각에서 벗어나야 한다. 스포츠 선수와 자서전을 통해 교훈을 얻고자 하는 독자들이 자신만의 감정적 최적 영역을 파악하고 관리하는 것이 중요하기에, 향후 다양한 종목과 분야의 자서전을 활용하여 부정적 감정을 적절히 조절하고 활용하기 위한 연구가 이루어져야 할 것이며 다양한 Data Set를 통해 여러 분야에서 인공지능 모델을 활용한 후속 연구가 필요하다.","Purpose This study aimed to examine the emotions embedded in the autobiographies of successful sports stars and to determine, from the perspective of positive psychology, the extent to which positive and negative emotions were reflected in their lives as portrayed in their autobiographies. For objective analysis, the AI model KoBERT, known for its utility in Korean emotion analysis, was trained and employed for comparison and analysis. Methods The study was conducted using sentences from the autobiographies of six South Korean sports stars (four baseball players and two soccer players), which totaled 20,781 sentences. The KoBERT model underwent additional training in two phases: 96,865 sentences were used in the first phase, and 43,799 sentences were used in the second. The final training accuracy of the model was 89.85%, and the correctness rate was 77.31%. Results First, negative emotions were observed to be more frequent than positive emotions in the sentences of the autobiographies of the six South Korean sports stars. Second, the frequency of emotions in the sentences was ranked as follows: sadness, joy, fear, surprise, anger, happiness, disgust, embarrassment, anxiety, and hurt. The combination of sadness and joy accounted for more than 80% of the total emotions. Conclusion The sentences in the autobiographies of the six sports stars analyzed in this study are highly characterized by negative emotions, and with the exception of sadness and joy, which make up the majority of the sentences, negative emotions are very infrequent, suggesting that they may have been controlled and overcome through personal competence and effort. Due to the complexity and irregularity of human emotions and inner states, achieving positive outcomes necessitates moving beyond perspectives that emphasize a positive emotion or unconditionally reject negative emotions. It is crucial for readers, including athletes and individuals seeking insights from autobiographies, to identify and regulate their optimal emotional zones. Future research should employ autobiographies from diverse sports and domains to investigate strategies for effectively managing and leveraging negative emotions, while further studies utilizing comprehensive and varied datasets are essential to advance research employing AI models across multiple disciplines."
Cost effective image-based phenotyping in Capsicum annuum germplasm for rapid assessment of traits,2025,['Phenotyping · Traits · Machine learning · Image analysis · Breeding'],,"Chili is a valuable crop known for its fl avor and nutritional benefi ts. Developing new chili varieties with desirable traits requires analyzing phenotypic diversity and correlations within chili germplasm. This study utilized image-based methods to assess phenotypic trait diversity in chili germplasm in cost-eff ective manner. High-resolution imaging and computational algorithms were employed to extract quantitative data on traits, including leaf area, fl ower morphology, stem structure, and fruit characteristics. We analyzed 188 accessions of Capsicum annuum from 36 countries, with geographic origin data sourced from the National Seed Resources in Korea. The study focused on leaf, fl ower, stem, and fruit traits, and their interrelationships.Results indicated signifi cant variability in leaf area, length, and width between two populations ( K = 2), with CV values of 0.38, 0.18, and 0.22, respectively. The Principal Component Analysis (PCA) showed diff erent variation among leaf area and leaf length (98.5%), stem angle and length (46.5%), fruit and fl ower traits (43.1%). Image-based phenotyping in Capsicum annuum germplasm provides a cost-eff ective, effi cient, and comprehensive method for plant trait analysis.This technology reduces the need for labor-intensive manual measurements, optimizes resource use, and enables the rapid assessment of large plant populations."
Insights on risk score development: Considerations for early-stage hepatocellular carcinoma models,2025,"['Hepatocellular carcinoma', 'Machine learning', 'Prognosis']",,
여론조사를 위한 신뢰수준과 표본오차 자동 산출 및 다중층화 샘플링 방법에 관한 연구,2025,"['Survey Sampling', 'Machine Learning', 'Multi-Stratified Sampling', 'Confidence Level Automation', 'PCA', 'K-Means']",,"This study proposes a methodology to improve the reliability and representativeness of surveys by automatically calculating the minimum sample size to reach a 95% confidence level with a ±3% margin of error by implementing multilevel stratified sampling. Using one million records from the 2022 National Health Insurance Service health examination dataset, data preprocessing was performed. Principal component analysis (PCA) and K-means algorithms were applied in a Python 3.8 environment to classify the population into four clusters reflecting diverse characteristics. A minimum sample size of 1,068 was proportionally allocated across the clusters to ensure representativeness. The key contributions of this study are as follows. First, development of a system for automatically calculating sample size based on confidence level and margin of error reduces manual errors. Second, a stratified sampling structure effectively reflecting population diversity is implemented using the PCA and K-means algorithms. Third, the proposed multilevel stratified sampling method empirically overcomes the limitations on existing methods, such as under- or over-representation, and validated its ability to accurately reflect population structures. This methodology provides a reliable and efficient design of complex, large-scale data analyses for studies in areas including healthcare, policy research, and marketing."
선택적 학습기법을 통한 FCM 시험모델 성능 개선,2025,"['SLS(Selective Learning Strategy)', 'QACT(QP-Adaptive Channel Truncation)', 'FCM(Feature Coding for Machines)', 'FCTM(Feature Compression Test Model)', 'Channel removal']",,
건강상태를 반영한 주요 만성질환 발생 예측 모형 개발 및 건강등급화 방안,2025,"['cohort DB', 'disease prediction', 'machine learning', 'health rating system', '표본 코호트', '질환 발생 예측 모형', '기계학습', '건강등급']","본 연구는 국민건강보험공단의 빅데이터를 활용하여 주요 만성질환 발생 위험을 예측하고 개인의 건강 상태를 정량적으로 평가하는 건강등급화 체계를 제시하였다. 구체적으로 표준체와 간편고지 집단으로 분석 대상을 세분화하고, 진료내역 및 건강검진 데이터를 종합적으로 활용하여 발생 예측 모형을 구축하였다. 분석에는 엘라스틱넷 회귀 모형을 적용하였으며 모형의 성능은 AUC와 재현율을 기준으로 평가하였다.분석 결과 각 질환별 모형에서 주요 위험 요인으로 연령, 가족력, 의료 이용 변수 등이 확인되었으며 안정적인 예측력을 보였다. 예측 모형을 바탕으로 연령효과를 제거한 표준화 위험률을 활용하여 개인별 건강등급을 산출하였다. 건강등급화 체계는 개인 맞춤형 건강관리와 예방 중심의 의료서비스 설계를 위한 기반으로 활용될 수 있다.","This study utilizes big data from the National Health Insurance Service (NHIS) to predict the risk of major chronic diseases and to propose a health rating system for quantitatively assessing individual health status. Specifically, the study stratifies the analysis population into standard and simplified underwriting groups, and integrates medical records with health examination data to develop predictive models. The analysis employs the elastic net regression model to balance prediction accuracy and variable selection. Model performance is evaluated using the area under the curve (AUC) and recall metrics. The results identify age, family history, and medical utilization variables as major risk factors across disease-specific models. Using the predictive model, standardized risk scores that exclude age effects are calculated, and individual health ratings are derived. This health rating system provides a robust foundation for personalized health management and prevention-focused medical service planning."
Data-Driven Airflow Prediction for Wastewater Treatment Plant Aeration System,2025,"['Airflow Prediction', 'Decision Support', 'Machine Learning', 'Wastewater Treatment Plant']",,"A wastewater treatment plant is an intricate system with a wealth of information, where the aeration system ofthe active sludge process is designed to provide oxygen to microorganisms. Owing to the time delay inbiochemical reactions, adjustments made by operational staff to the airflow often lead to delayed changes indissolved oxygen concentration, frequently causing overaeration. The paper introduces a machine learningmodel that utilizes water quality indicators and air blower indicators to predict current airflow. By leveragingthe airflow predicted by this model, the dissolved oxygen concentration for the next hour is successfullymaintained within the optimal range of 2 mg/L to 4 mg/L. In the case of airflow prediction, the Transformermodel proved more effective than the random forest and long short-term memory models, owing to its selfattentionmodel architecture. In conclusion, the study demonstrates the successful applicability of machinelearning models to predict airflow on the promise of maintaining dissolved oxygen stability. These findingspresent a data-driven approach to guarantee the steady operation of wastewater treatment plants."
유통기업 판매상품 추천 알고리즘 실증연구,2025,"['Product Recommendation Model', 'Deep Learning', 'Ensemble Model', 'Small-Scale Retailers']",,"The expansion of online retail markets has driven the development of personalized product recommendation services leveraging platform-based product and customer data. Large retailers have implemented seller-oriented recommendation systems, where AI analyzes POS sales data to identify similar stores and recommend products not yet introduced but successful elsewhere. However, small and medium-sized retailers face challenges in adapting to rapidly evolving online market trends due to limited resources. This study proposes a recommendation algorithm tailored for small-scale retailers using sales data from an online shopping mall. We analyzed 600,000 transaction records from 13,607 sellers and 95,938 products, focusing on Beauty Supplies, Kitchenware, and Cleaning Supplies categories. Three algorithms—Attentional Factorization Machines (AFM), Deep Factorization Machines (DeepFM), and Neural Collaborative Filtering (NCF)—were applied to recommend top 10% weekly sales items, with an ensemble model integrating their strengths. To address class imbalance, the Synthetic Minority Oversampling Technique (SMOTE) was employed, and performance was evaluated using AUC, Accuracy, Precision, and Recall metrics on separate training and test datasets. The ensemble model outperformed individual models across all metrics, while DeepFM excelled in Precision. These findings demonstrate that ensemble-based recommendation algorithms enhance recommendation accuracy for suppliers in large-scale online retail environments, offering practical implications for small-scale retailers."
Hybrid Quantum Fuzzy Neural Network Approach- Based SNS Sentimental Analysis for Stock Market Prediction,2025,"['Fuzzy Logic', 'QFNN', 'Quantum Machine Learning', 'Sentimental Analysis', 'Stock Market Prediction']",,"The growing reliance on artificial intelligence (AI) and big data in financial market analysis demands innovative methodologies to improve the accuracy of market trend predictions. Traditional models, which primarily focus on numerical stock market indicators, often fail to account for the psychological and sentiment-driven factors that significantly influence market behavior. This paper presents a hybrid approach that integrates sentiment data from social media platforms, such as Twitter, with conventional stock market indices using quantum fuzzy neural networks (QFNNs). By harnessing the computational power of quantum processors, the adaptability of fuzzy logic, and the pattern recognition capabilities of neural networks, the proposed system achieves enhanced predictive accuracy and provides deeper insights into market dynamics. The QFNN model demonstrates remarkable performance, with classification models like the support vector classifier (SVC) using radial basis function kernels achieving an accuracy of 98% and an F1-score of 97%. Additionally, the random forest (RF) model attains even higher accuracy at 99%, paired with an F1-score of 99%. The robustness of the model is further validated through receiver operating characteristic curves, with area under the curve scores reaching 1.0 for both SVC and RF models, underscoring their exceptional discriminatory power. This integration of qualitative sentiment analysis with quantitative market data represents a significant paradigm shift in financial forecasting, addressing many limitations of classical methods. Beyond stock market prediction, the study highlights the broader applicability of QFNNs in domains requiring large-scale data analysis and decisionmaking under uncertainty. The findings underscore the transformative potential of quantum computing and fuzzy logic in advancing AI-driven economic modeling and shaping the future of financial analytics."
기계를 위한 오디오 부호화 표준화 동향 분석,2025,"['Audio coding for machines', 'Audio coding', 'Speech coding', 'Machine learning', 'Artificial intelligence']",,
Indirect Measurement of Grinding Force in Cemented Carbide Processing Based on SSA-KELM Algorithm,2025,"['Grinding force', 'Cemented carbide', 'Machining power', 'Identification model', 'Sparrow search algorithm']",,"In order to address the challenge of measuring grinding force during the cemented carbide grinding process, this study proposes an indirect monitoring approach for grinding force based on the power of the spindle motor. The objective of this study is to collect machining power data and develop an identification model using SSA-KELM (Sparrow Search Algorithm-Kernel Extreme Learning Machine) in order to enable indirect monitoring of grinding force. We developed SSA-KELM model for identifying grinding force, which significantly improves precision by using the Sparrow Search Algorithm to globally optimize the core parameters of the KELM algorithm, thereby overcoming identification errors caused by random parameter selection in both the ELM and KELM algorithms. Experimental results demonstrate that the SSA-KELM identification model significantly improves prediction accuracy compared to other models and can be effectively used for indirect monitoring of grinding forces."
HSV스케일 이미지 처리를 이용한 텍스트 데이터의 한국어 욕설 탐지,2025,"['Profanity Detection', 'Malware Visualization', 'Machine learning', 'Content Moderation']","이 논문에서는 텍스트를 HSV 이미지로 변환하여 한국어 텍스트 데이터에서 욕설을 탐지하는 새로운 접근 방식을 살펴본다. 기존의 자연어 처리(NLP) 방식은 온라인 커뮤니케이션에서 문맥상의 뉘앙스와 비표준 언어 사용으로 인해 어려움을 겪는 경우가 많다. 이 연구는 기존의 악성코드 탐지에 사용된 이미지 시각화 기반 분석을 채택함으로써 표준 텍스트 기반 분류기가 간과하는 욕설과 관련된 구조적 및 시각적 패턴을 발견하는 것을 목표로 한다. HSV스케일 이미지로 변환된 한국어 문장 데이터 세트에 대해 다양한 이미지 분류 인공지능 아키텍처들을 활용하여, 자동화된 콘텐츠 조정 시스템에서 기존 텍스트 분석을 보완할 수 있는 이미지 기반 분석의 가능성을 보여주는 것을 목표로 한다. 실험 결과 제안된 모델은 97.42%의 정확도를 달성했습니다.","This paper explores a novel approach to detect profanity in Korean textual data by converting text to HSV scale images. Traditional natural language processing (NLP) methods often struggle with contextual nuances and the use of non-standard language in online communication. By adopting image visualization-based analysis used in traditional malware detection, this research aims to discover structural and visual patterns associated with profanity that are overlooked by standard text-based classifiers. By utilizing different image classification artificial intelligence architectures on a dataset of Korean sentences converted to HSV scale images, we aim to demonstrate the potential of image-based analysis to complement traditional text analysis in automated content moderation systems. Experimental results show that the proposed model achieves 97.42% accuracy."
Modeling Temporal Dependencies in Brain Functional Connectivity to Identify Autism Spectrum Disorders Based on Heterogeneous rs-fMRI Data,2025,"['Autism spectrum disorder', 'Deep learning', 'Functional magnetic resonance imaging', 'Classification']",,"Brain functional connectivity has shown promise for developing objective biomarkers for autism spectrum disorder (ASD). Although many imaging studies have demonstrated its potential, most have focused on static measurements. In this study, we explored the dynamic changes in functional connectivity over time to uncover potential temporal dependencies. These dynamic patterns were abstracted into high-level representations and used as predictors to identify individuals at risk of ASD. To achieve this, we employed a deep learning framework that combines attention mechanism with long short-term memory (LSTM) neural network. Experiments were conducted using heterogeneous resting-state functional magnetic resonance imaging (rs-fMRI) data from the Autism Brain Imaging Data Exchange (ABIDE) database. The resulting classification achieved an accuracy of 74.9% and precision of 75.5% under intra-site cross-validation, outperforming traditional classifiers such as support vector machines (SVM), random forests (RF), and single LSTM network. Further analyses demonstrated the robustness and generalizability of our model, with classification performance less affected by subjects’ gender or age. The optimal model’s weights revealed atypical temporal dependencies in the brain functional connectivity of individuals with ASD, highlighting the potential for these patterns to serve as biomarkers. Our findings underscore the importance of dynamic functional connectivity in understanding ASD and suggest that our deep learning framework could aid in the development of more accurate and reliable diagnostic tools for this disorder."
Predictive modeling based on a hybrid sampling strategy for an imbalanced heart failure dataset,2025,"['heart failure', 'imbalanced data', 'machine learning', 'synthetic minority oversampling technique', 'Tomek link.']",,"Heart failure is a life-threatening condition characterized by reduced cardiac function, leading to inadequate oxygen and nutrient delivery to vital organs. The progressive nature of heart failure and the potential for sudden deterioration or complications highlight the critical importance of the early identification of patients at high risk of death. Accurately predicting the probability of death in heart failure patients enables clinicians to optimize treatment strategies and prioritize the allocation of resources. However, datasets related to diseases such as heart failure generally exhibit an imbalance between deceased and surviving patients, which can adversely affect the performance of predictive models. To address this issue, this study provides a sampling strategy that combines a synthetic minority oversampling technique and Tomek link for an imbalanced heart failure dataset. This approach focuses on mitigating class imbalance and enhancing the sensitivity of models by employing predictive modeling techniques including elastic net regression, support vector machine, random forest, and extreme gradient boosting.  The provided strategy effectively addresses class imbalance in a heart failure dataset, paving the way for more accurate and reliable death predictions in heart failure patients through predictive modeling techniques."
초등학생을 위한 강화학습 중심 인공지능 교육이 인공지능 기술 태도에 미치는 영향,2025,"['Informatics Education', 'AI Education', 'Machine Learning', 'Reinforcement Learning', 'Attitudes toward AI technology', '정보교육', '인공지능교육', '기계학습', '강화학습', '인공지능 기술 태도']",,
군사 환경에서 소나신호 이용 수중지뢰 및 암석 분류를 위한 경량화 모델 연구,2025,"['Sonar', 'Underwater Mines', 'Machine Learning', 'SVM', 'Principal Component Analysis (PCA)', '수중 지뢰', '기계학습', '주성분 분석(PCA)']",,
"디지털 저널리즘 시대의 언론 역할과 직무만족도 관계 연구: 언론 문제 심각성, AI 활용, 디지털 대응혁신 피로감, 직업효능감의 다중매개효과 분석",2025,"['AI 저널리즘', '언론인 직무 만족도', '언론 역할', '언론인 직업효능감', '직무특성이론', 'AI Journalism', 'journalist job satisfaction', 'journalistic role', 'journalist job efficacy', 'job characteristics theory']","최근 AI와 같은 머신러닝 기반의 디지털 기술 발전은 저널리즘의 구조와 생태계를 변화시키고 있다. 이에 따른 언론 문제의 심각성은 다양하게 나타나고 있으며, 언론의 사회적 책임과 공적 이익을 위한 역할도 중요하게 인식되고 있다. 디지털 저널리즘 시대에서 언론인의 직무만족도에 영향을 미치는 요인을분석하기 위해 AI 활용, 디지털 대응혁신 피로감, 직업효능감의 다중매개효과를 검증하였다. <한국언론진흥재단의 2023년 언론인 조사> 자료를 바탕으로 SPSS PROCESS macro model 81을 활용하여다중매개효과를 분석하였다. 분석 결과, 언론 역할의 중요성은 언론 문제 심각성과 직업효능감에 정(+) 적 영향을 미치며, 직무 만족도에도 유의미한 정(+)적 관계를 나타냈다. 반면, 디지털 대응혁신 피로감과 언론 문제 심각성은 직무 만족도에 부정적인 영향을 미치는 것으로 확인되었다. 특히, AI 활용의 긍정적 영향은 직무 만족도와 통계적으로 유의미한 관계를 보이지 않았으나, 부정적 영향은 직무 만족도에 간접적으로 영향을 미치는 것으로 나타났다. 이러한 연구는 디지털 환경에서 언론인의 직무 만족도를 높이기 위해 디지털 대응혁신 피로감 관리와 직업효능감 증진의 중요성을 강조하며, 언론의 공공성및 신뢰성을 강화할 수 있는 학술적·실무적 시사점을 제공한다.","The advancement of digital technologies, such as AI and machine learning, has significantly transformed the structure and ecosystem of journalism. These changes have brought diverse manifestations of the severity of media issues and reinforced the recognition of journalism’s critical role in fulfilling social responsibility and serving the public good. This study examines the factors influencing journalists’ job satisfaction in the era of digital journalism by analyzing the multimediation effects of AI utilization, digital adaptation fatigue, and occupational self-efficacy. Using data from the 2023 Korean Press Foundation Journalists Survey, the analysis was conducted via SPSS PROCESS macro model 81. The findings indicate that the perceived importance of the role of journalism has a positive effect on media issue severity, occupational self-efficacy, and job satisfaction. Conversely, digital adaptation fatigue and media issue severity were found to negatively impact job satisfaction. Notably, while the positive effects of AI utilization did not show a statistically significant relationship with job satisfaction, its negative impacts were indirectly influential. These results underscore the importance of managing digital adaptation fatigue and enhancing occupational self-efficacy to improve journalists’ job satisfaction in the digital environment. The study offers both academic and practical implications, emphasizing strategies to reinforce the public value and trustworthiness of journalism in a rapidly evolving digital landscape."
노지 재배 고구마의 수분 스트레스 수준 평가를 위한 인공지능 기반 다중 영상 시스템,2025,"['고구마', '서포트 벡터 머신', '합성곱 신경망', '열 영상', '컬러 영상', 'Color Imaging', 'CNN', 'Sweet Potato', 'SVM', 'Thermal Imaging']",,"Recent abnormal weather conditions in South Korea, including unexpected droughts and floods, have adversely affected the yield and quality of field-grown sweet potatoes. This has highlighted the critical need for an effective system to evaluate water stress in crops. In response, in this study, an artificial intelligence-based multi-imaging system was developed for assessing water stress in field-grown sweet potatoes. The system incorporates RGB image preprocessing, background removal, and machine learning models, specifically Convolutional Neural Network (CNN) and Support Vector Machine (SVM). The models achieved coefficients of determination of 0.80 for CNN and 0.86 for SVM. This system offers a reliable method for quantitatively evaluating water stress in sweet potatoes and managing irrigation. Furthermore, it holds potential for application in water stress assessment across various crops."
Data Mining to Identify the Right Interventions for the Right Patient for Heart Failure: A Real-World Study,2025,"['Digital Health', 'Heart Failure', 'Machine Learning', 'Social Determinants of Health', 'Data Mining']",,"I. IntroductionDigital healthcare (DHC) interventions have the potential toimprove disease control and management, population healthoutcomes, and healthcare quality [1–3]. Current DHC solutionsinclude telehealth, digital and virtual disease managementplatforms, modifiable risk factor technologies, dietarycounselling, psychological assistance, and personalized shortmessaging. DHC tools are inexpensive, convenient, easy tonavigate, provide accessible/concise information and securedata management leading to higher acceptability [4].Data Mining to Identify the Right Interventionsfor the Right Patient for Heart Failure:A Real-World StudyKeni Lee1, Ramzi Argoubi2, Halley Costantino3,*1Sanofi, Reading, UK2Oracle Life Sciences, Paris, France3Oracle Life Sciences, Austin, TX, USAObjectives: To identify the right interventions for the right heart failure (HF) patients in the real-world setting using machinelearning (ML) trained on individual-level clinical data linked with social determinants of health (SDOH) data. Methods: Inthis retrospective cohort study, point-of-care claims data from Komodo Health and SDOH data from the National Healthand Wellness Survey (NHWS), from January 2014–December 2020, were linked. Data mining was conducted using K-meansclustering, an ML tool. Komodo Health data were used to access longitudinal data for the selected patient cohorts and crosssectionaldata from NHWS for additional patient information. The primary outcome was HF-related hospitalizations; secondaryoutcomes, all-cause hospitalization and all-cause mortality. Use of digital healthcare (DHC)/non-DHC interventionsand related outcomes were also assessed. Results: The study population included 353 HF patients (mean age, 63.5 years;57.2% women). The use of non-DHC (75.9%–81.9%) and DHC (4.0%–9.1%) interventions increased from baseline to followup.Overall, 17.0% of patients had HF-related hospitalizations (DHC, 6.9%; non-DHC, 16.5%) and 45.0% had all-cause hospitalization(DHC, 75.0%; non-DHC, 50.9%). Two archetypes with distinct patient profiles were identified. Archetype 1 (vs. 2)characterised by older age, greater disease severity, more comorbidities, more medication use, took steps to prevent heart attack/problems, had better lifestyle, higher HF-related hospitalizations (18.3% vs. 16.3%) and lower all-cause hospitalizations(42.9% vs. 46.3%). The trends remained the same regardless of the intervention type. Conclusions: Identification of patientarchetypes with distinct profiles can be useful to understand underlying disease subtypes, identify specific interventions, predictclinical outcomes, and define the right intervention for the right patient."
"Assessing the influence of urbanization on the historic city of Paithan, India: a case study focusing on the urban core",2025,"['Urbanization', 'historic city', 'machine learning techniques', 'historic urban core', 'built heritage']",,"Historic cities around the world have been experiencing continuous threats to their cultural heritage due to the multifaceted pressures of urbanization, with historic cities being increasingly threatened by factors beyond population migration, such as changes in land use, degradation of historic character, urban decay, lack of socio-economic development and challenges to sustainable urbanization, Historic City reestablishment becomes vital, as this would promote sustainable growth. Analysing the impacts and extent of urbanization in historic cities is essential to determine how one might help mitigate it. This study investigates the impact of urbanization on the cultural heritage of the historic city of Paithan, Aiming to answer two key questions: how does urbanization alter the physical and sociocultural fabric of Paithan’s urban historic core, and what factors drive these changes, with the primary objective focussing on assessing the extent of urbanization-led changes and identifying key socio-economic and physical variables influencing this transformation. Four ML models – K-Nearest Neighbour (kNN), Support Vector Machines (SVM), Logistic Regression, and the Random Forest Method were applied to analyse urbanization data. A set of 11 predictor variables was identified, and the findings reveal the rising land values and changing building use as primary drivers of transformation, leading to a decline in traditional architectural elements. The RFM model emerged as the most accurate model, with an accuracy of 89.3%, providing the most accurate insights into the non-linear relationships between the variables. The study concludes with a call for inclusive growth, balancing sustainable development and modern needs. The ML models chosen for this study use open-source data as well as field surveys."
Stock Return Prediction Using Macroeconomic Drivers: The Case of the KOSPI Index,2025,"['Return prediction', 'KOSPI Index', 'Machine learning', 'Deep learning', 'Macroeconomic Predictors', '수익률 예측', 'KOSPI 지수', '머신러닝', '딥러닝', '거시경제 예측변수']",,
한반도 지역의 정지궤도 환경위성탑재체(GEMS) 자료 기반 지표이산화질소 혼합비 추정,2025,"['Surface nitrogen dioxide', 'GEMS', 'Machine learning', '지표 이산화질소', 'GEMS', '기계학습']","본 연구에서는Geostationary Environment Monitoring Spectrometer (GEMS)로 측정된 이산화질소 칼럼 농도를 이용하여 다중선형회귀(multiple linear regression)와 extreme gradient boosting (XGBoost) 모델을 통해 2021년 12월부터 2022년 11월까지 1년 동안 대한민국의 지표 이산화질소 혼합비를 추정하였다.XGBoost 모델을 통해 추정한 지표 이산화질소 혼합비와 in-situ 측정값 간의 correlation coefficient (R), rootmean squared error (RMSE), mean absolute error (MAE)는 각각 0.86, 5.60 ppb, 3.72 ppb로, 다중선형회귀 모델(R=0.71, RMSE=7.96, MAE=5.62)보다 더 나은 추정 성능을 보였다. 또한, 계절 평균 공간 분포와 상대 오차(relative difference) 분석을 통해 지표 이산화질소 혼합비의 계절적 특성을 확인하였다. 본 연구는 GEMS자료를 기반으로 대한민국의 지표 이산화질소 혼합비를 추정할 수 있는 가능성을 보여주며, 지역 및 계절특성을 반영한 모델 개선의 필요성과 활용 가능성을 제시한다.","In this study, we estimate surface nitrogen dioxide (NOY) volume mixing ratio (VMR) over SouthKorea from December 2021 to November 2022 using multiple linear regression and extreme gradient boosting(XGBoost), based on the Geostationary Environment Monitoring Spectrometer (GEMS) observation data.The XGBoost model shows good agreement against the multiple linear regression model based on evaluationvia comparisons with the in-situ measurements at AirKorea sites. The correlation coefficient (R), root meansquared error (RMSE), and mean absolute error (MAE) between the surface NOY VMR estimated using theXGBoost model and the in-situ measurements are 0.86, 5.60 ppb, and 3.72 ppb, respectively, compared to0.71, 7.96 ppb, and 5.62 ppb for the multiple linear regression model. Seasonal average spatial distributionsand relative difference analyses also revealed seasonal characteristics of surface NOY VMR. This studydemonstrates the potential of using GEMS observation data to estimate surface NOY VMR over South Koreaand highlights the importance of model improvements that consider regional and seasonal variability."
노후 태양광 모듈 출력 예측을 위한 인공지능 기술 기반 알고리즘 연구,2025,"['Deteriorated photovoltaic', 'Artificial intelligence', 'Machine learning', 'Predicting the output', 'Algorithm', '.']",,"Recently, it is important that can effectively utilize a large amount of data to analyze the operating factors for photovoltaic (PV) system with the AI technology. Predicting the use of solar modules can significantly contribute to reducing global greenhouse gas emissions by lowering carbon emissions. It is possible to diagnose deterioration and aging condition using various data of PV system for usage and operation of the PV modules. In order to assess the predictability of power of aged PV modules, the electrical characteristics of solar cell modules was measured in the dark state using the light irradiation. The output of aged PV modules was predicted through three different artificial intelligence-based algorithms. The power of aged PV modules decreased by more than 35% compared to the initial stage, and the main reasons of output degradation were determine to be fill factor (FF) reduction because of the increased resistance due to cell cracks or corrosion caused by aging. As a result of performance evaluation, the random forest (RF) model out of them showed the highest prediction accuracy with R2 = 0.885, and normalized mean bias error (NMBE) of 1.466%."
Methodology for Calculating North Korea’s Provocation Index Using  Big Data Analysis,2025,"['big data analysis', 'index', 'machine learning', 'security', 'text mining']",,"On the Korean Peninsula, South Korea and North Korea remain the world’s only divided countries with a cease-fire. North Korea has been in power for more than 10 years after Kim Jong-un completed the third-generation hereditary succession. North Korea has been threatening South Korea’s security through nuclear tests, missile launches, and uncrewed aerial vehicles; therefore, a security evaluation method is necessary. However, Korea’s position has only been subjectively evaluated by evaluating the security situation based on the results of Korean media analyses or surveys by experts on the Korean Peninsula. To solve this problem, this study proposes a new index calculation methodology using big data analyses from South Korean, North Korean, and international media. The index calculation comprises indicators related to provocation in the North Korean media, indicators associated with the Korean situation, and indicators that objectively evaluate articles regarding the Korean Peninsula in the international media. North Korea’s Provocation Index was calculated as the weighted sum of the final calculated indicators. Applying North Korea’s Provocation Index to the Kim Jong-un regime confirmed that the index rose before and after North Korea’s provocation and was low during peacetime on the Korean Peninsula. Through the analysis of North Korea’s Provocation Index, North Korea’s Provocation Alert Index is proposed, categorizing the levels of provocation into five levels: “threat,” “caution,” “alert,” “concern,” and “safety,” allowing for an intuitive recognition of North Korea’s provocation trends."
Inferring particle distributions in two-dimensional space with numerical features based on generative adversarial networks (GANs),2025,"['GANs', 'DCGAN', 'WGAN', 'Machine learning', 'Beam profile']",,"A feasibility study was conducted on the usage of Generative Adversarial Networks (GANs) for inferring particle beam profiles. Two types of GANs, Deep Convolution GAN (DCGAN) and Wasserstein GAN (WGAN), were implemented in the PyTorch framework and trained using a mathematically generated dataset. The input latent vector represents an ensemble of features that defines unique probabilities, indicating the degrees to which the data belongs to specific categories. It was shown that the GANs are able to reproduce successfully with the given features having ±20% uncertainty. The same architectures for the generator and discriminator showed different performances depending on the learning schemes in the performance evaluations; DCGAN showed smaller error fluctuations compared to WGAN. Meanwhile, WGAN generated better images for the convolution of two distributions provided with the pairs of corresponding latent vectors, whereas DCGAN produced artificial anomalies in its results. This implies that WGAN strengthens the robustness of the generator. The GANs demonstrated its functionality as a regression model for unidentified distributions, highlighting the potential applications of generative networks in analyzing complex and irregular behaviors of particle beams in related fields."
랜덤 포레스트와 SHAP을 활용한 대학 직원의 직무열의 결정요인 탐색: 조직혁신역량 관점에서,2025,"['university employees', 'work engagement', 'random forest', 'SHAP', 'University Innovation Capacity Assessment', '대학 직원', '직무열의', '랜덤 포레스트', 'SHAP', '대학혁신역량진단조사']","본 연구의 목적은 설명가능한 머신러닝 기법을 적용하여 대학 직원의 직무열의 결정요인을 탐색하는 것이다. 2022년 성균관대학교 교육과미래연구소의 대학혁신역량진단조사에 참여한 전국 4년제 대학 3,649명의 행정직원을 분석대상으로 하였다. 분석을 위해 랜덤 포레스트와 SHapley Additive Explanations(SHAP) 알고리즘을 적용하였으며, 분석에 포함된 각 변수의 중요도와 부분 의존성 등을 확인함으로써 대학 직원의 직무열의 주요 결정요인 및 경향성을 도출하였다. 분석결과 첫째, 정규직 직원의 직무열의에 영향을 미치는 중요도 상위 요인으로 대학 공동체 의식, 조직 긍정성, 조직 자부심, 협업 문화, 조직학습, 의사소통 등이 도출되었다. 둘째, 비정규직의 경우 조직 자부심, 의사소통, 협업 문화, 대학 공동체 의식, 조직 혁신성, 절차적 공정성 등이 이들의 직무열의에 영향을 미치는 중요도 상위 요인이었다. 셋째, 중요도 상위 결정요인과 직무열의 간의 관계는 대체로 정적인 상관을 보이고 있었다. 연구결과를 바탕으로 학령인구 감소 등 최근 국내 고등교육 환경의 급격한 변화에 대응하고 대학조직 효과성 및 성과 향상을 위한 선행요소로서 대학 직원의 직무열의 증진을 위한 정책적･실천적 시사점을 제시하였다.","This study examines the determinants of university employees’ work engagement using explainable machine learning techniques. Data were obtained from the 2022 University Innovation Capacity Assessment, involving 3,649 respondents. Random forest and Shapley additive explanations (SHAP) algorithms were employed to assess feature importance and partial dependencies among factors. The findings reveal that, for full-time employees, community sense, organizational positivity, organizational pride, collaborative culture, organizational learning, and communication were the primary determinants of work engagement. For part-time employees, organizational pride, communication, collaborative culture, community sense, organizational innovativeness, and procedural justice were decisive factors. Additionally, the relationships between the factors and work engagement were predominantly positive. Based on the findings, we provide implications for policy and practice to enhance university employees’ work engagement, contributing to improved effectiveness and performance in higher education institutions."
피싱 캠페인의 동향 조사 및 피싱 탐지기법에 대한 분류,2025,"['피싱 캠페인', '피싱 탐지', '머신러닝', 'LLM', '특징 추출', 'Phishing Campaign', 'Phishing Detection', 'Machine Learning', 'LLM', 'Feature Extraction']","최근 피싱 공격은 피싱 키트와 AI의 활용으로 인해 저비용 고효율의 특성을 가지고 있으며, 이러한 이유로 피싱 캠페인의 횟수가 점점 증가하고있다. 또한, 피싱은 피해자의 심리와 다양한 생성 기법 및 우회 기법으로 인해 점점 고도화되고 있으며, 피싱을 통해 탈취한 자격 증명은 부차적인공격에 이용되어 더 큰 피해로 확산된다. 따라서, 피싱으로부터 피해자를 보호하기 위해 현재 피싱 공격이 어떻게 기존의 탐지기법을 우회하는지분석하고, 이에 관한 최신 연구 동향의 파악을 통해 인사이트를 도출하는 것이 중요하다. 본 논문에서는 피싱 탐지기법을 URL 및 도메인, 웹 페이지구성요소, 시각적 유사성, 메시지 콘텐츠로 분류하고, 각 탐지기법이 보유한 도전 과제에 관해 소개한다.","Recent phishing attacks have demonstrated notable cost-effectiveness and efficiency through the use of phishing kits and AItechnologies, resulting in a substantial rise in phishing efforts. Furthermore, phishing is evolving in complexity as perpetrators leveragepsychological weaknesses, enhanced generation methods, and evasion tactics. Credentials obtained via phishing are frequently utilisedfor subsequent assaults, causing more harm. To safeguard users against phishing assaults, it is essential to examine how contemporaryphishing strategies circumvent existing detection systems and to derive insights from the newest research developments. This studycategorises phishing detection solutions into four types: URL and domain-based, web page component-based, visual similarity-based,and message content-based detection, while highlighting the challenges faced by each approach."
국민노후보장패널데이터를 활용한 가구 지출 예측 모델 연구 - 인공지능 모델 기반 접근 -,2025,"['국민노후보장패널데이터', '인공지능', '분류모형', '회계모형', '머신러닝', 'KReIS', 'Artificial Intelligence', 'Classification Model', 'Regression Mode', 'Machine Learning']","본 연구는 인공지능 모델을 활용하여 국민노후보장패널데이터의 가구별 연간가계소비지출과연간가계총지출을 예측하고, 가구 지출에 영향을 미치는 주요 변수들의 특성을 분석하였다. 고령화 사회로의 급속한 진입과 노년층의 경제적 안정성 확보가 국가적 과제로 부상하는 상황에서, 가구 지출 패턴에 대한 정확한 예측은 효과적인 노후보장 정책 수립의 핵심 기반이된다. 2009년부터 2023년까지의 2년 주기의 다 기간 패널데이터를 활용하여 시계열 특성을 고려한 소비지출액 및 부채금액에 대한 예측 모델을 구축했다. 이를 위해 국민노후보장패널데이터의 여러 내부 변수와 함께 부동산가격상승률, 소비자물가지수, 노령인구비율 등의 외부 공공데이터를 독립변수로, 분석 모형으로는 선형회귀, Ridge, Lasso, ElasticNet, 랜덤포레스트, 그래디언트 부스팅 등 다양한 알고리즘의 성능을 평가했다. 또한 소득부족액(생활비 부족 여부)을 ‘부족’, ‘부족하지 않음’, ‘무응답’으로 예측하는 분류모형을 통해 가구의 경제적 취약성을 사전에 감지할 수 있는 조기 경보 시스템을 개발하였다. 이 분류 모델 구축에는 로지스틱회귀, 랜덤포레스트, 그래디언트 부스팅, SVC 알고리즘이 사용되었다. 이후 각 모델에 대해서SHAP 분석을 통해 예측 결과에 영향을 미치는 주요 변수들의 기여도를 평가했다. 최종적으로 본 연구는 패널데이터의 결과를 기존 데이터와 거시환경 변수만으로 사전에 예측할 수 있는 방법론을 제시했으며, 정책 입안자들이 가구 지출 동향을 선제적으로 파악하고 대응할 수있는 실용적 도구를 제공한다는 점에서 의의가 있다.","This study employed artificial intelligence models to predict annual household consumption expenditure and total household expenditures using Korean Retirement and Income Study (KReIS) panel data, while analyzing the key variables affecting household spending. In the context of rapid population aging and the emerging national priority of ensuring economic stability for older adults, the accurate prediction of household spending patterns serves as a crucial foundation for effective retirement security policies. This study constructed prediction models for consumption expenditures and debt amounts using biennial panel data from 2009 to 2023 and incorporating time-series characteristics. Various algorithms—including linear, Ridge, Lasso, and Elastic Net regressions; random forest; and gradient boosting—were evaluated, utilizing both internal variables from the KReIS data and external public data, such as real estate price growth rates, the consumer price index, and the older adult population ratio. Additionally, an early warning system was developed to detect household economic vulnerability through classification models that predicted income shortfalls using logistic regression, random forest, gradient boosting, and support vector classifier (SVC) algorithms. The SHAP (i.e., SHapley Additive exPlanations) analysis was employed to evaluate the contributions of the key variables to the prediction results.The significance of this study lies in its methodology for predicting panel data outcomes using existing data and macroeconomic variables, providing policymakers with a practical tool to proactively understand and respond to household expenditure trends."
Application of Artificial Intelligence in Acute Ischemic Stroke: A Scoping Review,2025,"['Stroke', 'Artificial intelligence', 'Machine learning', 'Outcome assessment', 'health care', 'Diagnostic']",,"Artificial intelligence (AI) is revolutionizing stroke care by enhancing diagnosis, treatment, and outcome prediction. This review examines 505 original studies on AI applications in ischemic stroke, categorized into outcome prediction, stroke risk prediction, diagnosis, etiology prediction, and complication and comorbidity prediction. Outcome prediction, the most explored category, includes studies predicting functional outcomes, mortality, and recurrence, often achieving high accuracy and outperforming traditional methods. Stroke risk prediction models effectively integrate clinical and imaging data, improving assessments of both first-time and recurrent stroke risks. Diagnostic tools, such as automated imaging analysis and lesion segmentation, streamline acute stroke workflows, while AI models for large vessel occlusion detection demonstrate clinical utility. Etiology prediction focuses on identifying causes such as atrial fibrillation or cancer-associated thrombi, using imaging and thrombus analysis. Complication and comorbidity prediction models address stroke-associated pneumonia and acute kidney injury, aiding in risk stratification and resource allocation. While significant advancements have been made, challenges such as limited validation, ethical considerations, and the need for better data collection persist. This review highlights the advancements in AI applications for addressing key challenges in stroke care, demonstrating its potential to enhance precision medicine and improve patient outcomes."
NN-L-BFGS-B 알고리즘 개발 및 TMD 최적 설계의 적용,2025,"['Tuned mass damper', 'L-BFGS-B', 'Machine learning', 'Artificial neural network', 'Optimal design']",,"Tuned Mass Dampers (TMDs) are widely used to mitigate structural vibrations in buildings and bridges. However, conventional optimization methods often struggle to achieve optimal performance due to the complexity of structural dynamics. This study proposes the NN-L-BFGS-B algorithm, which combines Artificial Neural Networks (ANNs) for global exploration and L-BFGS-B for local exploitation to efficiently optimize TMD parameters. A ten-story shear-building model with a TMD is used for validation. The proposed method achieves the lowest H₂ norm compared to previous studies, demonstrating improved optimization performance. Additionally, NN-L-BFGS-B effectively balances computational efficiency and accuracy, making it adaptable to various engineering optimization problems."
작물 수확량 예측 및 작물 추천을 위한 회귀 분석,2025,"['Crop yield prediction', 'Crop recommendation', 'Intelligent agriculture', 'Machine learning', 'Regression analysis', '작물 수확량 예측', '작물 추천', '지능형 농업', '기계학습', '회귀 분석']","본 논문은 작물 수확량 예측과 적합한 작물 선택 가능성을 분석하였다. 연구에 사용된 농업 데이터 세트는 토양, 계절, 온도, 강수량 등 다양한 변수를 포함하며, 데이터는 수집, 변환, 정리, 축소 과정을 통해 처리되었다. 작물 수확량 예측을 위해 커널 릿지, 배깅 회귀, 선형 회귀, 라쏘, 가우시안 나이브 베이즈, 서포트 벡터 머신, 랜덤 포레스트, XGBoost, K-최근접 이웃, 결정 트리, 로지스틱 회귀 등 총 11개의 회귀 모델이 적용되었다. 모델 성능 지표를 활용한 예측 결과 평가에서 K-최근접 이웃, 결정 트리, 로지스틱 회귀, 랜덤 포레스트 모델이 90% 이상의 정확도를 기록하며 우수한 성능을 나타내었다.","This paper analyzes the potential for crop yield prediction and the selection of suitable crops. The agricultural dataset used in this study includes various variables such as soil, season, temperature, and rainfall, and it was processed through steps of collection, transformation, cleaning, and reduction. For crop yield prediction, a total of 11 regression models were applied, including Kernel Ridge, Bagging Regressor, Linear Regression, Lasso, Gaussian Naive Bayes, Support Vector Machine, Random Forest, XGBoost, K-Nearest Neighbors, Decision Tree, and Logistic Regression. The evaluation of prediction results using performance metrics revealed that K-Nearest Neighbors, Decision Tree, Logistic Regression, and Random Forest models demonstrated excellent performance, achieving an accuracy of over 90%."
Multidisciplinary Design Optimization Processes for Efficiency Improvement of Aircraft: State-of-the-Art Review,2025,"['Multidisciplinary design optimization', 'Data dimensionality reduction', 'Machine learning', 'MDO strategy', 'Optimization algorithms', 'Data mining']",,"During actual flight processes, aircraft face various complex operating conditions and must consider the requirements of different disciplines to achieve good overall performance. Multidisciplinary design optimization (MDO) for aircraft is a complex and time-consuming task, making efficiency crucial in aircraft design. This paper starts from the conventional MDO process, covering five aspects including design variables, performance evaluation methods, MDO strategies, optimization algorithms, and knowledge extraction for enhancing MDO efficiency. It introduces multiple techniques and current research status aimed at improving MDO efficiency, and, combined with artificial intelligence, outlines future directions for MDO development. This paper aims to help MDO researchers clarify their thoughts and provide references for advancing current MDO methods."
유튜브 기반 사용자 콘텐츠에서의 리뷰 이상 탐지: 사용자 생성 콘텐츠에서의 극단성과 허위성 분류,2025,"['극단적 리뷰', '조작된 리뷰', '자연어 처리', '사용자 생성 콘텐츠', '리뷰 신뢰성', 'Extreme Reviews', 'Fake reviews', 'Natural Language Processing', 'User-generated Content', 'Review Credibility']","본 연구는 YouTube 플랫폼의 호텔 리뷰를 대상으로 머신러닝과 자연어처리(NLP) 기법을 활용해 극단적및 조작된 리뷰를 식별⋅필터링하고자 한다. 소셜 미디어는 소비자 구매 결정에 중요한 영향을 미치며, 사용자 생성 리뷰는 마켓플레이스 신뢰도의 핵심 요소로 작용한다. 그러나 일부 판매자들의 평점 조작과 조작된 리뷰 확산은 플랫폼의 신뢰성을 저해하고 있다. 본 연구는 리뷰의 진정성과 신뢰성을 제고함으로써 소비자의 합리적 의사결정을 지원하는 것을 목표로 한다.","This study aims to identify and filter extreme and fake hotel reviews on the YouTube platform using machine learning and natural language processing (NLP) techniques. As social media increasingly influences consumer decisions, user-generated reviews have become a key factor in online marketplace credibility. However, review manipulation and fake reviews threaten platform trust. This research contributes to enhancing review authenticity and supporting rational consumer decisions."
Boosting 알고리즘을 이용한 네트워크 트래픽 이상 탐지,2025,"['intrusion detection', 'anomalous traffic', 'IDS', 'machine learning', 'boosting algorithms']",,
낙상 탐지의 실용적 접근: 저사양 하드웨어를 위한 경량 AI,2025,"['fall detection', 'lightweight AI', 'low-spec hardware', 'machine vision', 'health care', '낙상탐지', '경량 AI', '저사양 하드웨어', '머신 비전', '헬스케어']",,"This paper proposes the development of a lightweight AI-based fall detection system that can operate efficiently in low-spec hardware environments. Existing fall detection research has often relied on high-performance GPU environments or focused solely on detection accuracy, without adequately addressing processing speed and hardware limitations. To overcome these challenges, this study utilizes MediaPipe, a GPU-independent framework, combined with data analysis-based machine learning models, to design a system that requires minimal computational resources while ensuring fast and accurate fall detection. Experimental results demonstrate that the proposed model outperforms GPU-based models in terms of training and inference speed, while also delivering competitive detection performance. This research presents a promising approach to reducing dependency on high-cost hardware, thereby maximizing the practicality of fall detection systems in real-world scenarios."
Advances in artificial intelligence for structural health monitoring: A comprehensive review,2025,"['Artificial intelligence', 'Computer vision', 'Damage detection', 'Deep learning', 'Digital transformation', 'Machine learning', 'Structural health monitoring']",,"The deterioration of civil infrastructure presents a critical economic and societal challenge, necessitating the development of advanced and efficient monitoring strategies. Artificial intelligence (AI) has recently emerged as a powerful tool for structural health monitoring (SHM) that considerably improves accuracy, robustness, and operational efficiency. Early AI applications focused predominantly on vibration-based monitoring, enabling automated and data-driven damage detection processes. As AI techniques have advanced, their scope has expanded to large-scale data analyses, thereby significantly enhancing predictive maintenance strategies. Trends toward the integration of AI with vision-based methods have recently increased, further advancing damage detection and facilitating the digital transformation of civil infrastructure monitoring. AI has also been instrumental in achieving precise structural displacement tracking and load assessment. This review critically examines the progression of AI in SHM by tracing its evolution from vibration-based methods to the incorporation of vision-based techniques, including damage detection, digital transformation, and measurement. Furthermore, this paper discusses the key challenges associated with deploying AI solutions in real-world environments while highlighting future research directions and potential innovations within this rapidly evolving field."
sEMG 신호를 이용한 Random Forest 기반 보행 상태 분류 모델 연구,2025,"['sEMG(Surface Electromyography)', 'Random forest(RF)', 'Machine learning', 'Gait analysis', 'classification']",,": This study evaluated the effectiveness of the Random Forest (RF) algorithm in classifying walking status using electromyography (sEMG) data. Data were collected from physically healthy men and women in their 20s and were preprocessed by extracting the root mean square (RMS) features in the 6-channel EMG data. The RF model was used to classify the three activities of walking, climbing stairs, and descending stairs, and was trained based on the optimal hyperparameters. As a result of the verification, the average accuracy was 96.48%, and the accuracy in the test data was 96.64%, indicating excellent performance. In particular, the F1 score for each class was analyzed as walking (0.9930), climbing stairs (0.9560), and descending stairs (0.9496). This study proved that the RF algorithm is effective in classifying walking status, and in future studies, we plan to further improve the performance by apply- ing deep learning algorithms such as LSTM and data augmentation techniques. These developments are expected to increase the possibility of application in practical applications such as walking monitoring and rehabilitation training systems for the elderly."
자전거 교통사고에 따른 구급현황 요인 분석에 관한 연구,2025,"['Emergency Status', 'Bicycle Accidents', 'Importance Analysis', 'Machine Learning', 'Random Forest']",,
2025년도 KTX 수요 예측 및 정책적 의사결정: XAI 기반 실증적 예측연구,2025,"['Demand Forecasting of KTX', 'Explainable Prediction', 'Machine and Deep Learning', 'Policy Decisions', '고속철도 수요예측', '머신러닝과 딥러닝', '설명가능한 예측', '정책적 의사결정']","고속철도의 수요 변화를 정밀하게 예측하는 것은 운영 효율성 개선 및 교통 정책 수립과 지속 가능한 인프라 구축을 위한 핵심 요소다. 본 연구는 설명 가능한 인공지능을 사용하여 2025년도 KTX 수요를 정밀하게 예측하고, 실질적인 의사결정을 지원하는 것을 주된 목적으로 한다. 대표적인 AI 알고리즘을 활용하여 KTX 수요예측 오류를 최대 2.49%까지 낮추며 정확도를 향상시켰다. 또한, SHAP 알고리즘을 활용하여 예측 결과와 변수들의 기여 정도를 시각화함으로써, 비즈니스 정책 설계 및 자원 배분 의사결정 과정에 신뢰도를 높였다. KTX 노선에 따라 변수들의 기여도는 다양하게 변화될 수 있음을 제시하며 실시간 활용 가능한 비즈니스 애널리틱스 플랫폼의 필요성을 확인하였다. 2025년 KTX 수요는 작년보다는 최대 9.45% 정도 감소할 수 있지만, 코로나 이전보다 최대 18.47%까지 상승하는 수치로 수요가 점진적으로 증가 및 안정화 될 것으로 예상된다.","Accurate forecasting of KTX demand is a key factor for improving operational efficiency, establishing transport policies, and building sustainable infrastructure. The main purpose of this study is to accurately forecast KTX demand in 2025 using explainable artificial intelligence and support practical decision-making. Using AI algorithms, we improved accuracy by reducing forecast errors by up to 2.49%. In addition, by visualising the contribution of variables using the SHAP algorithm, we increased the level of confidence in the decision-making process for business policies and resource allocation. The contribution of variables can vary depending on the KTX lines, confirming the need for a business analytics platform that can be utilised in real-time. In 2025, KTX demand may decrease by up to 9.45% compared to last year, but it is expected to increase and stable gradually, rising up to 18.47% compared to pre-COVID-19."
공사비 예산 예측을 위한 ANN모델과 MLR모델 개발 및 비교 연구 - 공공청사 건축공사비 예산을 중심으로 -,2025,"['공사비 예산 예측', '코스트 플래닝', '머신러닝', '인공신경망', '다중선형회귀', 'Construction Cost Estimation', 'Cost Planning', 'Machine Learning', 'Artificial Neural Network', 'Multiple Linear Regression']","공사비 예산은 해당 건설사업의 사업성과 타당성을 결정짓는 중요한 잣대이기 때문에, 건설사업에서 공사비 예산을 체계적으로 예측하여 적정한 공사비 예산을 설정하는 것은 발주자에게 매우 중요한 현안이다. 또한, 사업 초기 단계에 설정된 공사비 예산의 준수가 가능한 설계가 진행되고 있는지를 점검하기 위해서는 공종별로 분기된 공사비 관리가 필요하다. 공사비 예산 예측의 전통적인 방법은 실적 데이터를 활용한 견적자의 경험 및 판단에 의존하는 것이다. 그러나 주관적인 견적자의 경험 및 판단에 의존한 예측은 공사비 산정의 불확실성을 높이는 단점이 있으며 이를 개선하기 위해서는 보다 정교하며 진화된 모델을 활용할 필요가 있다. 본 연구의 목적은 공공청사 건축공사비 예산을 중심으로 Artificial Neural Network (ANN)기법과 Multiple Linear Regression (MLR)기법을 활용한 공사비 예산 예측 모델을 개발 및 비교하여 각 모델이 건축공사비 예산 예측에 활용할 수 있는 모델인지 검증하고, 주요 특징과 시사점을 도출하는 데 있다. 연구 결과로 ANN 및 MLR을 활용한 모델을 개발하였으며, 각각 –36.3%~58.0%, -27.7%~32.8%의 오차율 범위를 보여 두 모델 모두 공사비 예산 예측을 위한 방법론으로 유용하게 활용될 수 있음을 확인하였다. 이 과정에서 균질성을 가지는 데이터에 대해서는 MLR이 ANN에 비해 상대적으로 안정적인 예측 성능을 보이고 있다는 특징을 확인할 수 있었다.","The construction budget is crucial for determining a project's feasibility, making systematic budget prediction essential for project owners. To ensure compliance with the initial budget during the design phase, it is necessary to manage the budget with a breakdown by work type. Traditional methods rely on estimators' experience and judgment using historical data, which can introduce uncertainty. The objective of the study is to develop and compare budget prediction models using Artificial Neural Network (ANN) and Multiple Linear Regression (MLR) techniques, focusing on public office building construction costs. The study evaluates the effectiveness of these models for budget prediction and identifies key characteristics. The results show that the models using ANN and MLR have error ranges of -36.3% to 58.0% and -27.7% to 32.8%, respectively, demonstrating their utility. Additionally, the MLR model exhibited more stable predictive performance for homogeneous data compared to the ANN model."
Comprehensive reporting guidelines and checklist for studies developing and utilizing artificial intelligence models,2025,"['Artificial intelligence', 'Health care research', 'Machine learning', 'Reproducibility of results', 'Statistical models', 'Statistics.']",,"Background: The rapid advancement of artificial intelligence (AI) in healthcare necessitates comprehensive and standardized reporting guidelines to ensure transparency, reproducibility, and ethical applications in clinical research. Existing reporting standards are limited by their focus on specific study designs. We aimed to develop a comprehensive set of guidelines and a checklist for reporting studies that develop and utilize AI models in healthcare, covering all essential components of AI research regardless of the study design.Methods: Two experts in statistics from the Statistical Round of the Korean Journal of Anesthesiology developed these guidelines and checklist. The key elements essential for AI model reporting were identified and organized into structured sections, including study design, data preparation, model training and evaluation, ethical considerations, and clinical implementation. Iterative reviews and feedback from clinicians and researchers were used to finalize the guidelines and checklist.Results: These guidelines provide a detailed description of each item on the checklist, ensuring comprehensive reporting of AI model research. Full details regarding the AI model specifications and data-handling processes are provided.Conclusions: These guidelines and checklist are meant to serve as valuable tools for researchers, addressing key aspects of AI reporting, and thereby supporting the reliability, accountability, and ethical use of AI in healthcare research."
Human-in-the-Loop 적용 언어모델 파인튜닝을 통한 정밀 금속가공 업종의 암묵지 학습 방법,2025,"['human in the loop', 'curriculum learning', 'tacit knowledge', 'Language model', 'KoGPT', 'KoBart', '.']","대규모 언어모델의 고도화 및 확산에 따라 한국어가 적용된 언어모델 또한 다양한 분야에서 적용, 활용되고 있다. 이는 다양한 서비스 확장과 산업 응용 가능성을 증대시키고 있으며, 특히 전문 지식이 요구되는 분야에서 정보 제공 및 지원 도구로서의 역할이 점차 중요해지고 있다. 하지만 숙련요소의 데이터화는 전문가의 개입이 필요하며 많은 작업 공수가 필요하다. 본 연구에서는 HITL(Human-in-the-Loop) 접근 방식을 활용하여 정밀 금속가공 업종에서의 전문 지식 및 숙련공의 암묵지와 노하우를 효과적으로 모델에 반영하는 방법을 제안한다. 언어모델을 파인튜닝하고, 전문가의 반복적 검증과 피드백을 통해 모델 성능을 최적화하여 가공 공정 관련 가이드를 위한 파인튜닝 기반 챗봇용 언어모델 학습을 연구하였다. 본 연구를 통하여 언어모델 파인튜닝에서의 HITL 적용 시 모델의 특성에 따른 비언어적 특성을 포함한 데이터 학습 성능을 검증하였다.","With the advancement and proliferation of Large Language Models, language models applied to the Korean language are also being applied across industrial fields. This trend has expanded into factory floor, service applications and other industrial areas, particularly in areas requiring tacit knowledge including know-how, where such models are increasingly significant as tools for information provision and support. However, digitalization of tacit knowledge often requires expert involvement and significant effort. This study proposes a method to effectively incorporate tacit knowledge of technicians and experienced workers in the precision machining industry into models using a Human-in-the-Loop (HITL) approach. By fine-tuning a Korean language-based model and employing iterative feedback from human experts, we studied a language model with tacit knowledge to support work guides."
UP-Net: A multi-head architecture for reading and efficiently segmenting distorted QR codes,2025,"['image distortion', 'mobile phone', 'multi-head architecture', 'QR code reader', 'semantic segmentation']",,"Semantic segmentation is essential in machine vision but susceptible to noise and distortions that often appear in real-world images. We propose UPlus-Net (UP-Net), a deep-learning architecture based on the U-Net encoder-decoder architecture. We address the limitations of U-Net by intro-ducing a multi-head architecture in UP-Net to properly handle segmentation challenges. In addition, we evaluate UP-Net for decoding distorted quick-response (QR) codes heavily polluted by noise. Experimental results confirm that UP-Net outperforms existing QR reader mobile applications, highlighting the UP-Net ability to handle challenging images. Unlike existing methods focused solely on QR code reading or segmentation, UP-Net offers a combined solution, efficiently and accurately reading distorted QR codes while perform-ing high-quality semantic segmentation. These unique characteristics render UP-Net promising for applications demanding robust image analysis in chal-lenging environments."
시계열 데이터 분포 특징 기반 배터리 SOH 추정 기법,2025,"['State-of-health', 'Battery states', 'Machine learning', 'Time series', 'Feature extraction']","리튬이온 배터리는 수명이 길고 에너지밀도가 높은 장점이 있어, 전기자동차 등 여러 산업군에서 에너지원으로 활용되고 있다. 그러나 리튬 이온 배터리의 보급이 활성화될수록 배터리의 열화 혹은 고장 등에 의한 사고 사례도 늘어가고 있어 배터리 상태에 대한 분석과 이상 상황을 사전에 탐지하는 모델이 필요성이 대두되고 있다. 본 논문에서는 오픈 소스 배터리 충, 방전 사이클 데이터에서 충전 중 전압, 전류, 온도 시계열 데이터에서 통계적 분포 특징을 추출하여, 배터리 셀의 잔존 수명을 예측하는 모델을 개발하고자 한다.","Lithium-ion batteries, with their advantages of long lifespan and high energy density, have become a widely utilized energy source across various industries, including electric vehicles. However, as the adoption of lithium-ion batteries increases, incidents caused by battery degradation or failure are also rising, underscoring the need for models capable of analyzing battery conditions and detecting anomalies in advance. In this study, a model was developed to predict the state of health (SOH) and detect anomalies during charging processes by utilizing open-source battery charge-discharge cycle data, including voltage, current, and temperature measurements."
노지 환경 데이터를 활용한 최적 관수 예측 모델 연구,2025,"['optimum growth', 'irrigation', 'artificial intelligence', 'field crops', 'machine learning', '최적 생육', '관수', '인공지능', '밭작물', '머신러닝']",,"Precision agriculture using AI technology is currently attracting attention, and this study proposes an AI-based model that predicts the optimal irrigation period of field crops using open-field environmental data. In particular, the prediction performance of irrigation period was analyzed by applying the Random Convolutional Kernel Transform (ROCKET) model optimized for time series analysis. The proposed method is to establish a system for predicting the amount of irrigation by utilizing the weather environment, soil environment, and crop growth data. As a result of the experiment, the ROCKET model recorded better prediction accuracy (RMSE = 2.34, MAE = 1.89, R² = 0.92) and calculation speed than the existing LSTM and Random Forest models, and it was analyzed that soil humidity, rainfall, and external temperature are factors that influence the optimal irrigation. In particular, it was confirmed that the ROCKET model can be quickly learned without large-scale data, so it is highly likely to be applied as a real-time precision irrigation system in a smart farm environment. This study presents the possibility of implementing a precise irrigation system in an AI-based smart farm environment, and plans to further improve model performance through applicability in various environments and optimal hyperparameter exploration in the future."
기계학습 기법을 활용한 WRF-CMAQ 모델의 PM<sub>2.5</sub> 구성성분 모의 성능 개선,2025,"['WRF-CMAQ model', 'Performance enhancement', 'Machine learning', 'PM&lt', 'sub&gt', '2.5&lt', '/sub&gt', 'components', 'Air Quality Research Center']",,
Estimation of napa cabbage fresh weight using uav-based multispectral  images and accumulated temperature,2025,"['Napa Cabbage', 'Accumulated Temperature', 'Multispectral Image', 'UAV', 'Machine Learning']",,"This study aimed to develop a regression model to accurately estimate napa cabbage fresh weight using UAV-based multispectral imagery, incorporating accumulated temperature (AT) to improve prediction accuracy under varying environmental conditions. Growth data and multispectral images were collected for two cultivars, Cheongmyeonggael and Bulam No.3, during the 2022 and 2023 growing seasons, and ten vegetation indices (VIs) were calculated. Both linear regression models (Multiple Linear Regression, Ridge, Lasso) and nonlinear models (Support Vector Regression, K-Nearest Neighbors) were applied, and their performance was evaluated using K-Fold Cross Validation. As a result, Ridge Regression showed the highest prediction accuracy in cultivar-specific models, while Multiple Linear Regression performed best in the integrated model. NDRE and TCARI were the most influential variables selected in the Ridge Regression models of Cheongmyeonggael and Bulam No.3, respectively. Furthermore, the inclusion of accumulated temperature significantly improved model performance, confirming its potential to reflect environmental growth conditions. This study presents the potential of integrating remote sensing imagery with climate data to enhance crop biomass estimation and suggests the feasibility of applying this precision agriculture-based yield prediction model under diverse environmental conditions."
Exploring methylation signatures for high de novo recurrence risk in hepatocellular carcinoma,2025,"['Hepatocellular carcinoma', 'DNA methylation', 'Biomarker', 'Recurrence', 'Machine learning']",,"Background/Aims: Hepatocellular carcinoma (HCC) exhibits high de novo recurrence rates post-resection. Current post-surgery recurrence prediction methods are limited, emphasizing the need for reliable biomarkers to assess recurrence risk. We aimed to develop methylation-based markers for classifying HCC patients and predicting their risk of de novo recurrence post-surgery.Methods: In this retrospective cohort study, we analyzed data from HCC patients who underwent surgical resection in Korea, excluding those with recurrence within one year post-surgery. Using the Infinium Methylation EPIC array on 140 samples in the discovery cohort, we classified patients into low- and high-risk groups based on methylation profiles. Distinctive markers were identified through random forest analysis. These markers were validated in the cancer genome atlas (n=217), Validation cohort 1 (n=63) and experimental Validation using a methylation-sensitive high-resolution melting (MS-HRM) assay in Validation cohort 1 and Validation cohort 2 (n=63).Results: The low-risk recurrence group (methylation group 1; MG1) showed a methylation average of 0.73 (95% confidence interval [CI] 0.69–0.77) with a 23.5% recurrence rate, while the high-risk group (MG2) had an average of 0.17 (95% CI 0.14–0.20) with a 44.1% recurrence rate (P<0.03). Validation confirmed the applicability of methylation markers across diverse populations, showing high accuracy in predicting the probability of HCC recurrence risk (area under the curve 96.8%). The MS-HRM assay confirmed its effectiveness in predicting de novo recurrence with 95.5% sensitivity, 89.7% specificity, and 92.2% accuracy.Conclusions: Methylation markers effectively classified HCC patients by de novo recurrence risk, enhancing prediction accuracy and potentially offering personalized management strategies."
항만 컨테이너에서의 IMS 데이터 기반 폭발물 분류 및 알고리즘 성능 비교,2025,"['Explosive Classification', 'Time Series Classification', 'Machine Learning', '폭발물 분류', '시계열 데이터 분류', '머신러닝']","해운 물류는 전 세계 물동량의 90%를 차지하는 중요한 산업으로, 항만은 불법 수출입 품목에 대한 감시 체계를 강화하고 있다. 특히화물 컨테이너 내 폭발물 탐지는 중요한 과제이며, 현재 X-ray 시스템이 주로 사용되고 있다. X-ray 탐지는 대형 컨테이너에 대한 크기와 무게등의 제약을 가지고 있어 효율적인 탐지가 어려운 문제점이 존재한다. 이에 대한 대안으로 IMS 장비를 이용한 폭발물 탐지 연구가 진행되고 있다. 본 논문에서는 기존 연구에서 제안된 KNN, TSF, ROCKET 알고리즘의 한계점을 개선하고자 한다. KNN과 TSF는처리시간이 비교적 짧지만 정확도가 낮고, ROCKET 알고리즘은 높은 정확도를 보이지만 처리 시간이 길어지는 문제가 있었다. 본 연구에서는 RDST(Random Dilated Shapelet Transform) 알고리즘을 활용하여 ROCKET 알고리즘의 정확도 0.95를 유지하면서도 처리 시간을 약 20초 단축하여 성능을 향상시켰다.","Maritime logistics, accounting for 90% of global freight volume, is a critical industry, with ports playing a key role in enhancing surveillance systems for illegal import and export goods. Among these, detecting explosives within cargo containers is a significant challenge, and X-ray systems are currently the primary method utilized. However, X-ray detection faces limitations in efficiently inspecting large containers due to constraints such as size and weight. As an alternative, research on detecting explosives using IMS (Ion Mobility Spectrometry) devices has been actively conducted. This study aims to address the limitations of existing algorithms, including KNN, TSF, and ROCKET, proposed in prior research. While KNN and TSF exhibit shorter processing times, they suffer from lower accuracy. On the other hand, the ROCKET algorithm achieves high accuracy but encounters issues with extended processing times. To overcome these challenges, this study leverages the RDST (Random Dilated Shapelet Transform) algorithm to maintain the accuracy of the ROCKET algorithm at 0.95 while reducing processing time by approximately 20 seconds, thereby improving overall performance."
Revolutionizing Egg Quality Control: Advanced Prompt-based Models for Automated Detection of Broken Eggs Without the Need for Training,2025,"['Broken egg detection', 'Grounding DINO', 'image processing', 'machine learning', 'saliency score', 'SAM.']",,"This paper proposes an end-to-end pipeline to detect broken eggs in a holder without extensive training, employing a two-step image segmentation and processing approach using saliency scores, all without relying on a large amount of labeled data. The process begins by inputting an egg image with text prompts into Grounding DINO, which returns an egg bounding box. This is followed by the segment anything model (SAM), which extracts the egg’s segmented region. The segmented region is then divided into two crucial components for detection: a binary mask image and a background-removed egg image. The innovation in our method lies in using the saliency score of the estimated anomaly region by employing image processing techniques to effectively distinguish between intact and broken eggs. To validate our approach, we compare it to well-known models such as SVM, XGBoost, and YOLOv8, and we also conduct zero-shot experiments with CLIPSeg, Florence-2, and SAA. In our experimental setup, we utilize 50 egg holder images, each containing both intact and broken eggs. We carefully cropped and processed 30 eggs (arranged in a 6x5 grid) from each holder, resulting in a comprehensive testing dataset totaling 1,500 images. Our results demonstrate the robustness of our method, achieving an impressive 99.56% accuracy in detecting both intact and broken eggs. This breakthrough promises significant advancements in the field of broken egg detection, with broad applications across diverse industries, including food safety, quality control, and automated packaging systems."
In silico medicine and -omics strategies in nephrology: contributions and relevance to the diagnosis and prevention of chronic kidney disease,2025,"['Big data', 'Chronic kidney diseases', 'Machine learning', 'Nephrology']",,"Chronic kidney disease (CKD) has been increasing over the last years, with a rate between 0.49% to 0.87% new cases per year. Currently, the number of affected people is around 850 million worldwide. CKD is a slowly progressive disease that leads to irreversible loss of kidney function, end-stage kidney disease, and premature death. Therefore, CKD is considered a global health problem, and this sets the alarm for necessary efficient prediction, management, and disease prevention. At present, modern computer analysis, such as in silico medicine (ISM), denotes an emergent data science that offers interesting promise in the nephrology field. ISM offers reliable computer predictions to suggest optimal treatments in a case-specific manner. In addition, ISM offers the potential to gain a better understanding of the kidney physiology and/or pathophysiology of many complex diseases, together with a multiscale disease modeling. Similarly, -omics platforms (including genomics, transcriptomics, metabolomics, and proteomics), can generate biological data to obtain information on gene expression and regulation, protein turnover, and biological pathway connections in renal diseases. In this sense, the novel patient-centered approach in CKD research is built upon the combination of ISM analysis of human data, the use of in vitro models, and in vivo validation. Thus, one of the main objectives of CKD research is to manage the disease by the identification of new disease drivers, which could be prevented and monitored. This review explores the wide-ranging application of computational medicine and the application of -omics strategies in evaluating and managing kidney diseases."
맛집 소비자 리뷰 분석을 통한 데이터 감성 예측,2025,"['Sentiment analysis', 'Restaurant review data', 'machine learning', 'TF-IDF vectorization', 'Logistic Regression', '감성분석', '맛집리뷰 데이터', '머신러닝', 'TF-IDF 벡터화', '로지스틱 회귀']","본 논문은 맛집 리뷰 데이터를 분석하여 소비자의 감정을 예측하고, 이를 기반으로 외식업체의 맞춤형 마케팅 전략 수립에 기여하는 것을 목적으로 한다. 연구 방법으로는 구글맵에서 리뷰 데이터를 크롤링하고, 형태소 분석과 TF-IDF 벡터화를 통해 텍스트 데이터를 수치화한 뒤, 로지스틱 회귀 모델을 적용하여 감성 분류를 수행하였다. 총 149,995개의 리뷰 데이터를 활용하였으며, 긍정과 부정 감정을 87.5%의 정확도로 예측하는 모델을 구축하였다. GridSearchCV를 통해 하이퍼파라미터를 최적화하였고, 분석 결과는 소비자 감정 이해뿐 아니라 음식점의 서비스 개선과 마케팅 전략 수립에 실질적으로 활용 가능함을 보였다. 본 연구는 실시간 감성 분석 및 딥러닝 기반 모델로의 확장을 통해 더욱 정교한 분석이 가능할 것으로 기대된다.","This paper aims to analyze restaurant review data to predict consumer sentiment and support the development of targeted marketing strategies in the food service industry. Review data were collected from Google Maps and processed through morphological analysis and TF-IDF vectorization. A logistic regression model was then applied for sentiment classification. Utilizing a dataset of 149,995 reviews, the model achieved an accuracy of 87.5% in distinguishing positive and negative sentiments. GridSearchCV was used to optimize hyperparameters, and the results demonstrate the potential to understand consumer emotions and improve restaurant services and marketing strategies. The study contributes to sentiment analysis research and suggests that future work could incorporate deep learning models and multimodal data for more accurate and real-time sentiment predictions."
적응적 발열 관리를 통한 On-Device VSR 성능 최적화,2025,"['초해상화', '발열 관리', '모바일 다비이스', '인터미턴트 컴퓨팅', '머신 러닝', 'super-resolution', 'thermal management', 'mobile device', 'intermittent computing', 'machine learning']",모바일 기기에서 VSR (Video Super Resolution) 작업은 강한 GPU 연산 부하로 기기 온도를 급격히 상승시킨다. 발열을 해소하기 위해 모바일 시스템에서 보편적으로 사용되는 DVFS (Dynamic Voltage-and-Frequency Scaling)는 애플리케이션 동작 특성을 고려하지 않고 GPU 주파수를 자동으로 감소시켜 급작스럽게 작업의 성능을저하시킨다. 이러한 열 제한의 발생은 돌발적인 작업 시간 지연을 유발하여 작업 효율성과 사용자 만족도를 저해한다. 본 논문에서는 모바일 VSR에서 발열 문제 해소를 위한 최초의 적응적 발열 관리 전략인 ATM (Adaptive Thermal Management for VSR)을 제안한다. ATM은 기기 온도 변화에 따라 VSR 작업의 추론 단계를 적응적으로 제어하여 온도 증가율을 낮추고 열 제한의 발생 시점을 뒤로 미룬다. 실험을 통해 ATM이 주어진 작업 기간중 열 제한의 발생을 효과적으로 예방하였으며 모델 추론 속도가 1.56배 저하되는 것을 방지하고 전체 작업 수행량에서 1.8배 향상된 성능을 확인하였다.,"VSR (Video Super Resolution) tasks on mobile devices cause a rapid rise in device temperature due to heavy computational load in GPU. Mobile systems commonly employ DVFS (Dynamic Voltage-and-Frequency Scaling) for heat dissipation, but it automatically reduces GPU frequency without considering application behavior, causing a sudden drop in task performance. The occurrence of thermal throttling causes sudden work delays, hindering task efficiency and user satisfaction. Therefore, we propose he first adaptive thermal management technique ATM (Adaptive Thermal Management system for VSR) to address thermal issues. ATM adaptively controls the inference stage of VSR tasks based on device temperature changes to mitigate the rate of temperature increase and delay the onset of thermal throttling. Experiments confirmed that ATM effectively prevents thermal throttling during a given task period, while also preventing a 1.56x decrease in model inference speed and achieving an overall task throughput improvement of 1.8x."
인공지능과 인지적 다양성: 인사 및 조직관리 시사점 모색,2025,"['기계 심리학', '생성형 AI', '다양성', 'AI 윤리', 'machine psychology', 'generative AI', 'diversity', 'AI ethics']","급격히 발전하는 인공지능 시대를 맞이하여, 조직은 매일 새로운 도전에 직면하고 있다.본 논문은 이러한 상황에서 식별형 인공지능과 생성형 인공지능이 조직 및 사회의 다양성에어떠한 영향을 미치는지를 본격적으로 다룬다. 특히 챗GPT(ChatGPT)로 대표되는 생성형AI가 서구 문화권(WEIRD: Western, Educated, Industrialized, Rich, Democratic)의가치 특성을 반영하고 있음을 밝힌 기존 연구(예: Atari et al., 2023)를 재현하고 확장하기위해, 본 연구에서는 GPT-4o, Llama 3.2, EEVE, EXAONE 3.5 등 다양한 생성형인공지능 모델을 추가로 활용하여 문화적 편향성을 체계적으로 분석하였다. 이를 통해서구권 중심의 데이터 학습 문제나 알고리즘적 불투명성의 정도가 모델별로 상이함을확인하였고, 일부 모델은 과거 대비 편향이 개선되는 경향을 보이는 반면, 특정 문화권과의괴리는 여전히 남아 있음을 밝혔다. 인공지능은 그 기능에 따라 식별형(discriminative)과생성형(generative)으로 구분되는데, 식별형 인공지능은 지도 학습을 통해 예측․분류역량을 강화하여 업무 자동화와 개인화 서비스를 제공하지만, 데이터 편향이 누적될경우 조직 내 다양성을 저해할 가능성이 있다. 생성형 인공지능은 비지도 및 강화 학습을통해 창의적 아이디어나 콘텐츠를 직접 생성함으로써 혁신 잠재력을 갖추고 있으나,학습 데이터에 따른 가치 편향 위험도 잠재한다. 본 연구는 채용․승진․평가 등 인사관리프로세스에서 이러한 두 유형의 인공지능이 미칠 영향과 위험성을 구체적으로 분석하고,데이터 대표성․투명성․공정성 측면에서 개선 방안을 제시하였다. 또한, AI 활용의투명성과 공정성을 강화하기 위한 인적자본 공시 및 AI 윤리 관련 법적․제도적 흐름을반영하여, 조직이 AI 활용 시 고려해야 할 주요 과제를 논의하였다. 아울러 식별형과생성형 인공지능을 상호보완적으로 활용할 때 조직이 창의성․업무 효율․포용성을동시에 달성할 수 있음을 제언함으로써, 이론․실무적 함의를 함께 제공한다.","Amid the rapid advancement of artificial intelligence (AI), organizations arecontinuously confronted with new challenges. This paper delves into the impactof discriminative and generative AI on organizational and societal diversity.To replicate and extend previous research (e.g., Atari et al., 2023), whichfound that ChatGPT and other generative AI models exhibit WEIRD culturalbiases, across various generative AI models, including GPT-4o, Llama 3.2,EEVE, and EXAONE 3.5. The findings reveal discrepancies in algorithmictransparency and the extent of Western-centric data training across these models.While some models show a reduction in bias compared to earlier versions,notable gaps remain in representing certain cultural contexts. AI is categorizedinto discriminative and generative types.. Discriminative AI enhances predictiveand classification capabilities through supervised learning, facilitating automationand personalized services; however, the accumulation of data bias posesa threat to organizational diversity. Generative AI, by leveraging unsupervisedand reinforcement learning, generates creative ideas and content, fosteringinnovation but simultaneously carrying the risk of value-laden biases stemmingfrom training data. This study provides a detailed analysis of the potentialimpacts and risks of both AI types across HR processes, including recruitment,promotion, and performance evaluation. Furthermore, it incorporates regulatoryand ethical frameworks related to human capital disclosure and AI governance,addressing key considerations for organizations in ensuring AI transparencyand fairness. By highlighting the complementary use of discriminative andgenerative AI, this paper suggests pathways for organizations to achieve creativity,operational efficiency, and inclusiveness, contributing valuable theoreticaland practical insights."
이상치 탐지를 이용한 양수발전소  설비 고장 탐지 방법,2025,"['Fault Detection and Monitoring', 'Linear Model', 'Machine Learning', 'Outlier Detection', 'Pumped-storage Power Plants']",,"This paper proposes a fault detection method in pumped-storage power plants using outlier detection. An outlier detection model is trained using normal operation data, to classify test data samples as either normal or outliers, subsequently converting these classifications into a binary data stream. A moving window technique is applied to this stream, triggering fault warnings when the rate of outliers within the window exceeds a predefined threshold. This approach tailors the outlier detection model to the characteristics of the power plant data. Data from pumped-storage power plants has strong time-series characteristics under frequent transitions between pumping and generating states. We apply a linear model on sequential data from each facility in power plants to capture sequential patterns and effectively identify outliers. The proposed fault detection method allows for the detection of individual facility failures and provides an integrated view of the overall plant's operational status. It has been tested using real-world data from pumped-storage power plants, demonstrating its reliability and effectiveness in fault detection and monitoring."
Random Forest 연구방법을 적용한 이륜차의 지역별 사고 심각도 비교 분석에 관한 연구,2025,"['Motorcycle', 'Traffic Accidents', 'Accident Severity', 'Machine Learning', 'Random Forest', 'Feature Importance', '이륜차', '교통사고', '사고 심각도', '머신러닝', '랜덤 포레스트', '변수 중요도']","연구목적: 전국 전체의 이륜차 사고 건수는 점점 감소하고 있지만  사망자 수는 증가한 것으로 나타났으며 이륜차 사고가 집중대는 시간대는 16~22시인 저녁 시간대로 나타났다.  따라서 주거지역과 다른 지역 간의 이륜차 사고 심각도 요인의 차이를 비교할 필요가 있다. 연구방법: Random Forrest를 활용해 2007년부터 2021년까지 인천광역시에서 발생한  이륜차 사고 자료와 QGIS를 사용하여 도시지역 및 비도시지역으로 구분하고 지역에 따라 사고 심각도 분석 및 사고 심각도에 미치는 영향요인을 도출하였다. 연구결과:  각 지역의  상위 2개의 변수 중요도를  분석한 결과, 도시 지역 이륜차 사고 심각도에 높은 영향을 미치는 변수는 교차로 안에서 사고가 발생한 경우, 신호위반의 경우이고, 공업지역은 차대차 정면충돌의 경우와 피해자 차종이 화물차인 경우, 녹지지역은  신호위반의 경우, 교차로 안에서 사고가 발생한 경우,  상업지역은 신호위반,차대차- 측면직각충돌의 경우, 비도시지역은 가해운전자가 60세 이상인 경우, 피해자가 40~50대인 경우  사고심각도에 더 영향을 주는 것으로 나타났다. 결론: 지역의 특성에 따라 이륜차 사고의 심각도에 영향을 주는 요인을 심층적으로 분석하였고 본 연구로 도출된 결과를 활용하여이륜차 사고의 심각도를 개선하기 위한 효율적이고 대응책 수립이 필요하다.","Purpose: The number of motorcycle accidents nationwide is decreasing, but the number of deaths has increased, and the time when motorcycle accidents are concentrated is between 16:00 and 22:00 in the evening. Therefore, it is necessary to compare the differences in the severity factors of motorcycle accidents between residential areas and other areas. Method: Using Random Forrest, QGIS and data on motorcycle accidents in Incheon Metropolitan City from 2007 to 2021 were used to divide them into urban and non-urban areas to derive accident severity analysis and impact factors on accident severity by region. Result: As a result of analyzing the importance of the top two variables in each region, the variables that have a high impact on the seriousness of motorcycle accidents in urban areas are traffic lights in intersections Conclusion: It is necessary to establish efficient and countermeasures to improve the severity of motorcycle accidents by analyzing in-depth factors that affect the severity of motorcycle accidents according to the characteristics of the region and utilizing the results derived from this study."
CNN based Estimating Patent Quality: Focusing on AI Convergences,2025,"['Patent Quality', 'CNN', 'Technological Innovation', 'Machine Learning', 'Embedding', 'Technological Convergence']",,"Recently, obtaining high quality patents has become increasingly important for the pursuit of technological convergence. However, it is insufficient for effectively estimating patent quality, especially in the emerging convergent technology. This research newly proposed a technique to evaluate patents, focusing on AI convergences, by considering both bibliometric aspects and embedded citations of patents with Convolutional Neural Network. Findings of this research empirically contribute to the estimation of patent quality. The proposed technique is expected to discover patents with high quality. Related policy implications based on this research could leverage R&D management in AI area."
Financial Fraud Detection System Based on Generative Adversarial Networks,2025,"['Generative Adversarial Networks', 'Financial Fraud Detection', 'Machine Learning', 'Synthetic Data', 'Class Imbalance', '생성적 적대 신경망', '금융 사기 탐지', '기계 학습', '합성 데이터 생성', '클래스 불균형']",,"Financial fraud is also increasing as financial transactions become increasingly complex. Traditional financial fraud-detection methods require large amounts of training data and significant computational resources. Further, most detection models encounter serious challenges when handling imbalanced data samples, leading to a lack of accuracy in identifying fraudulent transactions. To address this imbalance in financial fraud detection, we propose a generative adversarial network (GAN) system. The proposed GAN generates synthetic fraudulent transaction samples, enhances the diversity of the training data, and improves the model’s accuracy and generalization ability. Experimental results show that the proposed GAN system is more efficient than traditional algorithms and improves the accuracy of credit card fraud detection by 12% compared to the XGBoost algorithm. The GAN system not only provides a new solution for financial fraud detection, but also has the potential to play a crucial role in real-world applications thus contributing to the advancement of financial security."
Enhancing Identification of High-Risk cN0 Lung Adenocarcinoma Patients Using MRI-Based Radiomic Features,2025,"['Lung neoplasms', 'Magnetic resonance imaging', 'Prospective studies', 'Machine learning']",,"Purpose This study aimed to develop a magnetic resonance imaging (MRI)–based radiomics model to predict high-risk pathologic features for lung adenocarcinoma: micropapillary and solid pattern (MPsol), spread through air space, and poorly differentiated patterns.Materials and Methods As a prospective study, we screened clinical N0 lung cancer patients who were surgical candidates and had undergone both 18F-fluorodeoxyglucose (FDG) positron emission tomography–computed tomography (PET/CT) and chest CT from August 2018 to January 2020. We recruited patients meeting our proposed imaging criteria indicating high-risk, that is, poorer prognosis of lung adenocarcinoma, using CT and FDG PET/CT. If possible, these patients underwent an MRI examination from which we extracted 77 radiomics features from T1-contrast-enhanced and T2-weighted images. Additionally, patient demographics, maximum standardized uptake value on FDG PET/CT, and the mean apparent diffusion coefficient value on diffusion-weighted image, were considered together to build prediction models for high-risk pathologic features.Results Among 616 patients, 72 patients met the imaging criteria for high-risk lung cancer and underwent lung MRI. The magnetic resonance (MR)–eligible group showed a higher prevalence of nodal upstaging (29.2% vs. 4.2%, p < 0.001), vascular invasion (6.5% vs. 2.1%, p=0.011), high-grade pathologic features (p < 0.001), worse 4-year disease-free survival (p < 0.001) compared with non-MR-eligible group. The prediction power for MR-based radiomics model predicting high-risk pathologic features was good, with mean area under the receiver operating curve (AUC) value measuring 0.751-0.886 in test sets. Adding clinical variables increased the predictive performance for MPsol and the poorly differentiated pattern using the 2021 grading system (AUC, 0.860 and 0.907, respectively).Conclusion Our imaging criteria can effectively screen high-risk lung cancer patients and predict high-risk pathologic features by our MR-based prediction model using radiomics."
생성형 인공지능의 악용에 대한  형법적 규제에 관한 고찰,2025,"['생성형 인공지능', 'AI 기본법', '딥페이크', '머신러닝', '딥러닝', '범용 인공지능', 'Generative artificial intelligence', 'AI act', 'Deepfakes', 'Machine learning', 'Deep learning', 'General-purpose artificial intelligence(GPAI)']","생성형 인공지능의 활용가능성과 영향력이 확대되면서 이로 인한 갈등이 현실적인문제로 등장하고 있다. 이에 대한 대응책이 구축되고 있으나, 아직 그에 대한 논의는초기적인 단계에 머물러 있다. 인공지능 기술, 특히 생성형 인공지능은 다양한 방식으로 활용되며 보다 직접적인 권리 침해 문제를 야기하는데 그 활용 방식에 사전적 한계를 설정하는 것은 산업과의 충돌이 예견된다. 그럼에도 개인의 자유와 권리가 침해될때 법의 규제가 필요하며 형법적인 규제가 필요한 경우도 있다. 본고에서는 생성형 인공지능을 악용하는 경우를 형법의 적용가능성을 기준으로 분류하여 형법의 개입 영역을 설정하는 것을 목표로 한다. 이에 따라 형법의 영역이 어느 선까지 설정되어야 할것인지 균형점을 모색하고자 하였다. 본고는 생성형 인공지능을 악용하는 경우를 ①기존범죄의 수단으로서 인공지능을 이용하는 경우 ② 생성형 인공지능을 기반으로 새로* 고려대학교 학부대학 강사/법학박사(형사법 전공) 38 서강법률논총 제14권 제2호이 나타난 형태의 위협 ③책임 소재가 불분명해 현재로서 법적 규제가 어려운 경우로구분하고, 특히 문제되는 영역은 형법의 적용이 모호한 ②의 영역이라고 지적한다. 법이 기술을 포섭하고자 할 때 나타난 문제를 모두 법으로 규제하거나 처벌 대상으로 삼는 것에는 여러 제약이 존재한다. 특히 생성형 인공지능을 기반으로 나타난 위협은 이를 잘 보여주는 것으로, 기존의 형법 규정으로 포섭하기 모호한 경우가 있다. 이 경우기존 법규로 다양한 현상을 포섭할 수 있을지 분명하지 않고, 개별법에서 인공지능 기술의 이용을 구체적 행위 양태로 법문언에 명시하지 않는다면 기존 형법이 적용될 지모호하다.이처럼 현행 형법의 적용이 모호한 영역이 있다는 한계를 지적하고 인공지능을 규율하는 방식으로 포괄규제방식을 병행하는 경우와 개별규제만 활용하는 방식을 소개한다. 포괄적 규제방식을 병행할 경우 행정적 규제가 사전적 규제로 기능하여 유연하고 폭넓은 대응이 가능하고, 형법은 사후규제로서 보충적으로 활용된다. 한국은 포괄규제 방식을 기본법으로 두고 있는데, 유럽연합의 인공지능법에 비교하면 의무의 부과나 제재에서 보완되어야할 필요가 있다. 본고는 형법의 적용이 모호한 영역에서 그 모호성을 해소할 수 있지만, 형법의 범위가 지나치게 확장될 수 있음을 우려한다. 따라서1차적으로는 포괄적 규제의 방식을 먼저 검토하여 인공지능사업자 등에 의무를 구체적으로 부과하되 형법의 영역 확장은 지양한다. 차후 형법의 개입이 필요하다고 판단될경우 적극적 법해석이나 법의 제·개정 등을 통해 형법을 확장할 수 있을 것이나, 과잉·중복 규제를 행하지 않도록 산업과의 적절한 균형을 모색하되 적절하면서도 실효적인 규제를 마련해야 한다고 본다.","As the influence of generative artificial intelligence expands, the resulting conflict is emerging as a practical problem. Generative artificial intelligence causes more direct rights infringement problems. Legal regulation is necessary, even though it is predicted that imposing preliminary restrictions on its use will cause conflict with the industry when individual freedom and rights are violated. And in some cases, criminal regulation is required. This paper aims to set the intervention area of criminal law by classifying cases of abuse of generative artificial intelligence based on the applicability of criminal law. The case of abusing generative artificial intelligence is divided into cases such as ① using artificial intelligence as a means of existing crimes ② a new type of threat based on generated artificial intelligence ③ having difficulty to regulate legally at present because the responsibility is unclear. In the case of threats based on generative artificial intelligence(②), it is sometimes ambiguous to apply the existing criminal law. In this case, the applicability of existing criminal law to artificial intelligence remains uncertain, particularly when its use is not explicitly provided for in current legal texts.This paper points out the limitations that the application of the current criminal law is ambiguous and later introduces the comprehensive regulation methods and the methods of using only individual regulations. When the comprehensive regulatory method is combined, the burden on individual laws can be alleviated by setting regulatory boundaries that are broad, flexible, and not overly strict. Korea has a comprehensive regulatory method as its basic law. Compared to the artificial intelligence law of the European Union, it needs to be supplemented in the imposition or sanctions of obligations. This paper considers the areas where the application of criminal law should be reduced and the areas to be expanded. If there are no separate laws governing artificial intelligence, criminal law can be expanded through active legal interpretation or legal amendments. However, the comprehensive regulation method can be reviewed first. If a strong response is needed in the future, an extension of the criminal law can then be considered.Through this, we believe that  appropriate and effective regulations should be prepared while seeking an appropriate balance with the industry."
Integration of artificial intelligence in orthodontic imaging: A bibliometric analysis of research trends and applications,2025,"['Artificial Intelligence', 'Orthodontics', 'Diagnostic Imaging', 'Machine Learning']",,"Purpose: This study employs bibliometric analysis to evaluate research trends, key contributors, and applications of artificial intelligence (AI) models in orthodontic imaging. It highlights the impact and evolution of AI in this field from 1991 to 2024.Materials and Methods: A total of 130 documents were extracted from the Scopus database, spanning 33 years of research. The analysis examined annual growth rates, citation metrics, AI model adoption, and international collaborations. Network visualization was performed using VOSviewer to map research trends and co-authorship networks.Results: The study analyzed 96 publications from 47 sources, revealing exponential growth in AI research- particularly after 2010, with a peak in 2023. The findings show a steady annual growth rate of 9.66% and a maximum citation count of 138 for an AI-based cephalometric analysis study. Convolutional neural networks (CNNs) and artificial neural networks (ANNs) dominate AI applications in orthodontic image analysis. An h-index of 23 and a g-index of 38 reflect the field’s significant research impact. Strong international collaborations were observed, with 28.12% of studies involving cross-border research.Conclusion: This analysis highlights the growing influence of AI in orthodontic imaging and emphasizes the need for larger datasets, improved model interpretability, and seamless clinical integration. Addressing these challenges will further enhance AI-driven diagnostics and treatment planning, guiding future research and broader clinical applications."
The Impact of Managerial Tone on the Value Relevance of Accounting Information,2025,"['경영자의 어조', '회계정보의 가치관련성', '텍스트 분석', '머신러닝', 'Managerial Tone', 'Value Relevance of Accounting Information', 'Text Analysis', 'Machine Learning']",,"[Purpose] This study empirically investigates the impact of managerial tone on the value relevance of accounting information. Management's tone, encompassing linguistic patterns and emotional expressions in communication, reflects managerial communication styles. Notably, the Management Discussion and Analysis (MD&A) section of annual reports, subject to audit and regulatory oversight, primarily serves as a channel for conveying private information rather than being primarily used as a tool for opportunistic disclosures.[Methodology] We analyze the relationship between management's tone in MD&A disclosures and the value relevance of accounting information using data from companies listed on the Korea Composite Stock Price Index (KOSPI) and the Korean Securities Dealers Automated Quotations (KOSDAQ) markets from 2011 to 2023.[Findings] Our analysis reveals that a more optimistic managerial tone is positively associated with the value relevance of net income but negatively associated with the value relevance of net assets. This suggests that investors place greater confidence in net income information when management employs more optimistic tone while simultaneously placing less emphasis on net asset information. Furthermore, when decomposing net income into operating cash flows and accruals, we find that both components exhibit enhanced value relevance with increased management optimism, with accruals showing a particularly pronounced effect.[Implications] This study contributes to the literature by empirically documenting the influence of non－quantitative information, specifically managerial linguistic expressions in MD&A reports, on the value relevance of accounting information. Our findings demonstrate that narrative disclosures complement traditional financial metrics in firm valuation processes."
스마트폰 기반 안구건조증 원격 분석 시스템,2025,"['Dry eye disease', 'Fluorescence imaging', 'Machine learning', 'Smartphone-based imaging', '안구건조증', '형광 이미징', '머신러닝', '스마트폰 기반 이미징']",,"We develop an innovative smartphone-based remote analysis system for diagnosing dry-eye disease, integrating advanced imaging technology with chatbot-enabled communication. The system features a blue-LED light source with a central wavelength of 490 nm, incorporated into an optical setup designed for fluorescence imaging. The fluorescence signal generated by the blue LED is filtered through a band pass filter, reflected by a dichroic mirror, and captured by a smartphone camera serving as the detector. To analyze the recorded videos, we implement a custom algorithm to calculate the tear-film breakup time, a critical parameter in diagnosing dry-eye disease. Compared to conventional devices, the inline design of the optical system enhances contrast, improving diagnostic accuracy. By combining a smartphone camera with a compact, 3D-printed illumination component, the device is both user-friendly and accessible, requiring no specialized knowledge of optical systems. The diagnostic process is further streamlined through a Telegram-based chatbot, which facilitates seamless communication between the user and the imaging system. The chatbot processes the recorded data and delivers diagnostic results within minutes, offering patients a convenient and cost-effective solution for assessing dry-eye disease."
자율주행을 위한 XR과 요소 기술 연구,2025,"['자율주행', '가상/증강/혼합현실', '차량간 정보교환기술', '광학거리측정', '레이더', 'Autonomous Driving', 'VR/AR/MR', 'V2X', 'LiDAR', 'RADAR']",,"Autonomous driving technology, based on advancements in AI, machine learning, sensors, high-precision mapping, and V2X communication, enables vehicles to drive independently without human intervention. This technology is classified into SAE levels 0 to 5, with levels 4 and 5 representing full automation, offering societal benefits such as reduced traffic accidents and improved mobility efficiency. XR technology, encompassing VR, AR, and MR, holds significant potential to revolutionize the user experience(UX) in autonomous vehicles. While AR-based navigation and safety alert systems are currently utilized, higher levels of automation will require passenger-centric immersive interfaces and real-time data processing. Achieving this necessitates the integration of various technologies, including LiDAR, RADAR, AI, and 5G/6G communications, alongside the resolution of ethical and legal challenges. This paper discusses the key technologies of autonomous driving and XR for future mobility innovation."
설명가능한 기계학습을 이용한 베스트셀러 예측과 영향요인 분석,2025,"['기계학습', '베스트셀러', '설명가능한 인공지능', '온라인 서점', '예측', 'Bestseller', 'Explainable AI', 'Machine Learning', 'Online Bookstore', 'Prediction']",,
Detection Framework of FDIA for Smart Grid Based on Mode Decomposition and Gradient Boosting Decision,2025,['Cyber-physical system security · Signal processing · False data injection attacks · Smart grid · Machine learning'],,"The escalating frequency of cyberattacks poses a signifi cant threat to the security of Cyber-Physical Systems. Recent studies have revealed that a specifi c type of cyberattack, known as false data injection attacks(FDIA), can easily breach the defense mechanisms of energy systems. As attack detection technology improves, attackers must prudently choose their targets and distribute discreetly small-scale resources to minimize the risk of detection. Without access to eliminate the strong coupling relationship between buses within single time domain, we propose a FDIA detection framework that can detect independent buses, which presents the characteristics of attack under the multi-mode perspective. The framework employs Variational Mode Decomposition and Fast Independent Component Analysis to extract the distinctive features of FDIA signals across various frequencies. Additionally, the framework utilizes the results obtained from Particle Swarm Optimization to replace the predetermined thresholds of Extreme Gradient Boosting on an individual bus, thereby augmenting both the detection accuracy and interpretability of the model. Simulation results of the IEEE-14 bus system demonstrate the effi cient detection of attacks on individual buses by the proposed FDIA detection framework. Furthermore, the study evaluates the impact of attack intensity on the framework’s performance in the presence of specifi c noise interference, thus confi rming the method’s high eff ectiveness and robustness."
실시간 반도체 패키지 불량 검출을 위한 세부 관심 영역 자동 추출 기법,2025,"['Semiconductor package inspection', 'Defect detection', 'ROI extraction', 'Deep learning', 'Machine vision', '.']","인공지능(AI) 기술의 발전과 함께 등장한 2.5D, 3D 패키징과 같은 고성능 반도체 패키징 기술이 등장하였고, 이러한 반도체 패키지의 디자인은 점점 복잡해지고 있으며 패키지 내 검사가 필요한 영역의 수는 지속해서 증가하고 있다. 이에 따라, 기존의 수동 방식으로 영역을 지정하고 임계값을 설정하는 룰베이스 기반 불량 검사 시스템은 많은 시간과 오류 가능성을 동반한다. 이러한 문제를 해결하기 위해, 본 연구는 딥러닝 모델을 활용하여 실제 양산 QFN (quad flat no-lead)과 BGA (ball grid array) 패키지이미지에서 불량 탐지를 위한 관심 영역(region of interest, ROI)을 자동으로 추출하는 방법을 제시한다. 본 연구에서는 실시간 객체 탐지에서 가장 많이 사용되는 YOLOv8, YOLOv9, YOLO v10, YOLOv11 모델을 사용하여 학습 데이터 양이 모델 성능에 미치는 영향을 분석하고, 데이터 증강 및 전처리 기법을 통해 적은 데이터셋으로도 자동 세부 관심 영역 추출 성능을 향상시킬 수 있음을 확인하였다. 또한 실제 산업 현장의 다양한 조명 변화 조건을 고려하여, 딥러닝모델이 반도체 패키지 내 중요한 요소들을 높은 정확도로 잘 탐지할 수 있음을 입증하였다. 본 연구는 반도체 패키지 검사 시스템의 자동화및 효율성을 향상시키는 데 중요한 기초 자료로 활용될 것이다.",
Generational Gap in Accepting AI Integration in Korean EFL Classrooms: Comparing Pre-Service and In-Service Teachers Within Technology Acceptance Model,2025,"['세대 차이', '인공지능 기반 언어 교수', '기술 수용 모형', 'generational differences', 'AI-based language teaching', 'technology acceptance model']",,"This study explored generational differences in acceptance and use of AI-based language learning technologies among pre-service GenZ and in-service GenX&Y English teachers in Korean EFL (English as a Foreign Language) context. As AI tools like machine translators and ChatGPT become more prevalent in classrooms, understanding how different generational groups perceive and adopt these technologies is crucial for their successful integration. Using a mixed-methods approach with 70 participants, the study analyzed both quantitative and qualitative data. Results indicate that GenZ pre-service teachers are more open to adopting generative AI technologies, recognizing their potential to facilitate personalized learning tailored to individual student needs. However, their enthusiasm was accompanied by concerns about administrative challenges, particularly in managing AI-related tasks. In contrast, GenX&Y in-service teachers showed a more cautious approach, preferring traditional non-generative AI tools such as online translators and grammar-checking applications. They primarily regard AI as a supplementary tool to enhance existing teaching practices, with limited interest in its use for core instructional tasks. Instead, they emphasized its role in post-class tasks, such as grading, assignment management, and providing prompt feedback. These findings highlight the importance of designing generation-specific teacher training programs that address the distinct needs and challenges of each group."
Computation-Based Development of Carrier Materials and Catalysts for Liquid Organic Hydrogen Carrier Systems,2025,['Hydrogen storage · Liquid organic hydrogen carriers · Computational design · Density functional theory · Machine learning · Catalysis'],,"Liquid Organic Hydrogen Carriers (LOHCs) have emerged as a promising solution for hydrogen storage, off ering high hydrogen storage capacity, reversibility, thermal stability, and compatibility with existing infrastructures. Despite their potential, LOHC systems face signifi cant challenges, including the need for specialized carriers and catalysts for effi cient hydrogen storage and release. This review emphasizes the importance of computational analysis in overcoming these challenges.We summarize the computational accuracy of estimating dehydrogenation enthalpy for the carrier materials and explore molecular tuning strategies to enhance the dehydrogenation properties. In addition, we review computational studies that have investigated the impacts of catalytic adsorption/desorption and kinetic properties on the catalytic performance as well as catalyst design methods in terms of the geometry of active metal species, second metals, promoters, heterolytic hydrogen generation, and hydrogen spillover. This review further addresses the current challenges in LOHC systems, and then suggests future computational research directions to improve their effi ciency and viability."
직업계 고등학생의 교육포부 예측요인 탐색,2025,"['.', 'Key words : Vocational high school', 'Educational aspirations', 'XGBoost', 'Machine learing']",,"Abstract This study explores key predictors of educational aspiration among vocational high school students in South Korea, using data from the 8th wave of the Korea Education Longitudinal Study (KELS 2013). The XGBoost algorithm was employed to identify influential variables shaping students’ intentions to pursue higher education. Results showed that academic-related factors—such as class attentiveness, elective course selection, and participation in private tutoring—had the strongest impact. Notably, private education had greater predictive power than school-based activities, underscoring the role of external learning support. Additionally, choosing elective subjects aligned with college majors was associated with higher aspirations, reflecting strategic academic planning. In contrast, leisure reading and body satisfaction were negatively associated with aspiration, suggesting that certain personal or non-academic activities may lower college-bound motivation. These findings highlight the complex interplay of academic engagement, private learning, and personal factors in shaping educational goals. Based on the results, the study recommends enhanced career counseling, improved elective course planning, and expanded in-school academic support. Further research should consider student background and vocational track differences to better support postsecondary transitions."
대학생의 진로발달 프로파일 분류 및 예측 변인 탐색: 4년제 대학 및 전문대학을 중심으로,2025,"['4-year university student', 'college student', 'career development', 'machine learning', '3-step approach', '4년제 대학생', '전문대 학생', '진로발달', '머신러닝', '3단계 접근법']","본 연구는 대학생 진로발달의 중요성에 착안하여 대학 현장에 학생들의 진로역량을 제고할 수 있는 시사점을 제공하고자 하였다. 이를 위해 한국고용정보원 청년패널(YP2021) 1차년도 데이터를 활용하여 랜덤포레스트, 잠재프로파일 분석, 다항로지스틱회귀 분석을 순차적으로 적용하여 4년제 대학생과 전문대학생의 진로발달 양상과 결정 요인을 통합적으로 분석하였고, 결론은 다음과 같다.  먼저 랜덤포레스트 수행 결과 4년제 대학생 및 전문대 학생의 진로장벽에 극복에 대한 인식, 구직효능감, 자기효능감과 같은 자아개념은 진로발달에 긍정적인 영향을 주는 것으로 분석되었고, 특히 진로장벽은 노드 불순도 감소량을 기준으로 4년제 대학생 및 전문대 학생 집단 모두에서 가장 높은 중요도 지수를 보였다. 전문대 학생의 경우 청소년기 성장지 또한 상위 예측 변수로 도출되어, 진로발달에 대한 가정배경의 영향력을 확인할 수 있었다. 다음으로 잠재프로파일 분석 결과, 두 집단 모두 진로발달 수준에 따라 세 가지 유형이 도출되었다. 마지막으로 상위 10개 변수가 대학생의 잠재 프로파일 집단에 미치는 영향력을 3단계 접근법을 적용하여 다항 로지스틱 회귀분석을 실시하였고, 대학 유형 및 진로발달 수준에 따라 진로발달 제고를 위한 가장 효과적인 예측변인을 검증하였다. 특히 학생의 진로장벽의 경우 4년제 대학생과 전문대 학생 집단 모두에서 진로발달 우수집단에 속할 확률을 낮추는 부적 영향력이 큰 변수로 검증되었다.","This study aimed to provide practical implications for enhancing university students’ career competencies, recognizing the growing importance of career development in higher education. Utilizing the first-year data from the Youth Panel Survey (YP2021) conducted by the Korea Employment Information Service, this study applied a sequential analysis of random forest, latent profile analysis (LPA), and multinomial logistic regression to comprehensively examine the patterns and determinants of career development among students enrolled in four-year universities and junior colleges.The results of the random forest analysis revealed that self-concept-related variables—such as perception of overcoming career barriers, job-seeking efficacy, and self-efficacy—positively influenced career development in both student groups. Notably, career barriers emerged as the most influential predictor in both groups, based on mean decrease in node impurity. Among junior college students, adolescent growth environment was also identified as a significant predictor, suggesting the influence of family background on career development.Latent profile analysis identified three distinct types of career development profiles for both groups, classified by varying levels of career maturity and decision-making. Finally, a three-step approach was used to conduct multinomial logistic regression to examine how the top 10 predictors influenced profile membership. The results confirmed that the most effective predictors varied by institutional type and developmental level. In particular, career barriers had a strong negative effect on the likelihood of belonging to the high career development group for both four-year university and junior college students, underscoring the critical need for targeted support to mitigate psychological and informational obstacles in students' career planning processes."
인공 신경망 기반 90도 백투백 곡관의 탄성 한계 규명,2025,"['유한요소해석', '기계학습', '곡관', '구조 건전성 평가', 'Finite Element Analysis', 'Machine Learning', 'Pipe Bend', 'Structural Integrity Evaluation']","90° back-to-back 곡관은 내압과 굽힘 모멘트가 작용할 때 복잡한 응력 분포를 나타내며, 이러한 구조물의 탄성 응답 한계를 규명하는 것은 설계와 안전성 평가에 핵심적인 요소이다. 본 연구에서는 내압과 360° 전 방향의 굽힘 모멘트를 주요 입력 변수로 설정하고, Abaqus와 Python Script를 활용하여 선형해석 데이터를 생성하였다. 이를 기반으로 기계학습 모델을 학습시켜 최대 등가 응력을 예측하였으며, 최적화된 모델을 대리 모델로 활용하여 복합 하중 조건에서의 탄성 한계를 규명하였다. 연구 결과는 이러한 접근 방식이 구조 건전성 평가와 설계 안전성 향상에 효과적으로 활용될 수 있음을 보여준다.","The 90° back-to-back pipe bends is critical in altering the flow direction in pipelines, often experiencing significant damage from internal pressure and bending moments during operation. This study aims to determine the elastic response limits of such pipes under combined loading conditions using AI-based methods. Internal pressure and 360° bending moments were set as input variables, generating linear analysis datasets using Abaqus and Python script. ANN models were trained to predict the maximum equivalent stress and employed as a surrogate model to identify elastic limits. Iterative algorithms were used to combine load conditions within the yield strength, enabling accurate determination of elastic limits. This research highlights the potential of AI-driven structural integrity evaluation techniques in enhancing the understanding of stress distributions under complex loads, contributing to improved safety and efficiency in pipeline design."
Enhanced Distance-based Weighted K-Nearest Neighbor Algorithm for Data Classification,2025,"['k-Nearest Neighbor', 'kNN', 'Data Classification', 'Data Mining', 'Machine Learning']",,"The k-Nearest Neighbors (kNN) algorithm is one of the most widely used techniques for data classification. However, the imbalanced class is a key problem for its declining performance. Therefore, the kNN algorithm is kept updated to mitigate this problem’s effects. Following the pattern of the literature, our paper proposes a novel weighted kNN that aims to significantly reduce the negative consequences of this problem. An enhanced distance-based weighted KNN, EDWkNN, is developed to improve the overall KNN performance. For the test sample, the number of neighbors (k) is initially determined. Next, normalized weights are computed for these neighbors and assigned a value between 0 and 1. The weights of the nearest and farthest neighbors are 1 and 0, respectively. The weight values of the remaining neighbors range from 0 to 1, with the closest one having a heavier weight and the farthest neighbor having a lower weight value. In extreme circumstances, a few neighbors have equal distance from the test sample, leading to assigning uniform weights to each of these neighbors. Further, the EDWkNN considers both the magnitude of the distance and the proximity of neighbors. Comparing EDWkNN to its state-of-the-art rivals, its simplistic architecture and competitive performance demonstrate its uniqueness. In four experimental phases, a thorough assessment study is conducted utilizing four evaluation metrics (accuracy, precision, recall, and MAE) over forty-four datasets. The findings show that, on average and for individual k values, EDWkNN is substantially promising."
기계번역에 관한 사용자 인식 및 경험 고찰 : 번역 앱 후기의 텍스트 마이닝 분석을 토대로,2025,"['기계번역', '사용자 인식 및 경험', '사용자 후기', '기계번역 앱', '텍스트 마이닝', 'machine translation', 'user perception and experience', 'user reviews', 'MT apps', 'text mining']",,"This study investigates user perceptions and experiences of machine translation (MT) through text mining analyses of user reviews, conceptualized as digital paratexts of translation, for Google Translate, Papago, and DeepL. Employing keyword extraction, sentiment analysis, and selective qualitative analysis on 4,913 reviews, this study identifies key factors influencing user engagement and technology acceptance, including translation quality, usability, and social influences. The findings indicate that users perceive Google Translate as beneficial for its extensive language coverage, Papago as effective for language learning due to its user-friendly tools, and DeepL as superior in accuracy and naturalness. Despite generally positive attitudes toward MT, users highlight critical areas for improvement, such as interface usability and limited language support. Moreover, the reviews reflect broader socio-cultural dynamics, illustrating how societal narratives shape MT adoption. This study underscores the complementary role of MT alongside human translation and offers practical insights for developers, practitioners, educators, and researchers. By exploring user-driven insights, this research advances understanding of the evolving landscape of MT and its integration into professional and educational contexts."
A Survey on the Latest Developments of OFDM Schemes for Optimizing the Capacity and Reliability of Visible Light Communication (VLC) Systems,2025,"['Orthogonal Frequency Division Multiplexing', 'Modulation Techniques', 'Time Domain Transformation', 'Spectral Efficiency', 'Deep Learning']",,"This paper reviews recent advancements in Orthogonal Frequency Division Multiplexing (OFDM) techniques for Visible Light Communication (VLC), focusing on Direct Current-Biased OFDM (DCO-OFDM), Asymmetrically Clipped OFDM (ACO-OFDM), and Layered ACO-OFDM (LACO-OFDM). It analyses the principles, advantages, limitations, and optimization strategies, including integrating machine learning and Peak-to-Average Power Ratio (PAPR) reduction techniques. Although OFDM variants significantly enhance VLC transmission rates, reliability, and adaptability, several challenges remain, including practical engineering implementation, nonlinear distortion compensation, and dynamic channel adaptation. Future research should prioritize intelligent optimization methods, adaptive modulation and coding, and multi-scenario validation to facilitate the deployment of OFDM-based VLC systems in applications such as smart lighting, indoor positioning, and the Internet of Things (IoT). Cross-disciplinary collaboration and focusing on real-world needs will be crucial to advancing VLC-OFDM technology."
온라인 서비스 이용 패턴과 개인정보의 예측 가능성 연구,2025,"['Personal Information', 'Predictive Analytics', 'Online Service Usage Patterns', 'Personality Traits', 'Machine Learning', '개인정보', '예측분석', '온라인 서비스 이용 패턴', '성격특성', '기계학습']",,"This study compared the predictability of various demographic and personality traits of individuals from their online service usage behavior. Usage patterns for OTT, smartphone apps, digital contents, online shopping, smart devices, and social media were used as predictors, and the contribution of each predictor was examined using four tree-based ensemble models. The result shows that marital status, age, gender, and education level were highly predictable, followed by employment status and income.On the other hand, political orientation, religion, and personality traits are relatively hard to predict.The contribution of predictors varied depending on the model, but in most models, OTT and TV usage characteristics significantly contributed to the prediction of various personal information. The comprehensive investigation of the predictability and prediction factors of personal information provides knowledge for both its effective protection and utilization."
Data-driven Discrete Simulation-based Dynamic Modeling and Continuous Optimization for Comprehensive Carbon Efficiency of Batch Hobbing,2025,"['Dynamic modeling', 'Data-driven discrete simulation', 'Continuous optimization', 'Meta-learning', 'Batch hobbing']",,"Low-carbon manufacturing is an inevitable requirement for the green transformation of enterprises. For batch hobbing, continuous improvement of process parameters is an important way to achieve low-carbon optimization under the constraints of limited data and time-varying machining configurations. This is the research gap that needs to be filled. Therefore, in this paper, a dynamic modeling and continuous optimization method for comprehensive carbon efficiency (CCE) of hobbing based on data-driven discrete simulation is proposed. Specifically, the study integrates ML (meta-learning) and DEVS (discrete event system specification) in the hobbing process to create a dynamic model of CCE. The dynamic model combines the generalization of the data-driven approach and the capability to abstract events of the discrete simulation approach, which can autonomously adapt to the current machining configuration and output machining results in real time. On this basis, a modified multi-objective seagull optimization algorithm (MOSOA) is used for the continuous optimization of CCE in batch hobbing. Finally, the effectiveness and superiority of the proposed method are verified by a case study and comparative analysis. Moreover, this paper analyzes the effect of process parameters on CCE under different working conditions and provides guidance for gear hobbing."
Effectiveness of bot detection method for MMORPG behavior Using Shapley additive explanations,2025,"['Shapley additive explanations', 'Explainable Artificial Intelligence', 'Abnormal Detection', 'Machine Learning', 'Data Mining']",,"According to Mordor Intelligence, the MMORPG Gaming Market size is estimated at USD 25.34 billion in 2024, and is expected to reach USD 42.22 billion by 2029, growing at a CAGR of 10.75% during the forecast period (2024-2029). In online games, there are various threats such as hacking, malicious code, and botnets. Among such various threats, obstruction of game services using game bots is causing many problems. As research on bot detection in online games such as MMORPGs using statistical and AI models has increased, companies have begun applying these models to detect bots in MMORPG environments. However, there are cases where these bot detection attempts have proven ineffective, and due to the low interpretability of AI models, such issues are often overlooked during the development process.Therefore, this paper explores the use of 'Shapley Additive Explanations' as a verification method when AI-based bot detection is not effective."
Understanding Health Information Credibility across UGC Platforms: Varying Influences of Credibility Features and Prior Knowledge,2025,"['신뢰성', '건강정보', '사용자 생성 콘텐츠', '사전지식', '기계학습', 'Credibility', 'Health Information', 'User-Generated Content', 'Prior Knowledge', 'Machine Learning']",,"Assessing the credibility of online health information has become increasingly complex as the volume of user-generated content (UGC) increases. This study investigates the predictive modeling of credibility in two distinct types of UGC platforms—Yahoo! Answers and Yelp—by exploring the impact of feature categories and the role of assessors’ prior knowledge. A total of 2,000 labeled instances were collected through crowdsourcing, using a rigorously validated credibility instrument and qualification process. Eighty-four features were developed and grouped into categories informed by the Elaboration Likelihood Model (ELM), and feature ablation studies were conducted independently on both datasets. Results indicate that content informativeness was the most discriminative factor for Yahoo! Answers, while sentiment and content informativeness were significant for Yelp. Interestingly, prior knowledge had a platform-dependent effect: it reduced model performance in Yahoo! Answers, likely due to overconfidence and limited domain expertise, but improved performance in Yelp, where lived experience aligned with subjective content. These findings emphasize the importance of tailoring credibility assessments and feature sets to the type of platform and the nature of the content."
An efficient forecasting model methodology for time series analysis,2025,"['Backscatter values', 'time series', 'ANN', 'ARIMA', 'hybrid ARIMA-ANN', 'performance measures.']",,"This paper gives fresh real-world examples of how to use statistical tools like autoregressive integrated moving averages (ARIMA) and machine learning tools like artificial neural networks (ANN) and ARIMA-ANN as hybrid models to predict time series datasets. ARIMA and ANN models typically investigate and implement time series models. The ARIMA model is compared to the ANN model for complex-patterned problems, aiming to enhance forecast performance by combining both models. The study utilized rice crop backscatter data from the Godavari basin to train and evaluate prediction models. In order to ascertain the most suitable model and analyse their performance, the performances were evaluated using the metrics of mean square error (MSE), mean absolute percentage error (MAPE) and mean absolute error (MAE). The experimental data indicates that the hybrid-additive model is more accurate in forecasting values. Results showed that the models were able to accurately predict rice crop growth and yield in the region."
인공신경망 기반 암호화폐 옵션 헷징 전략,2025,"['헷징 전략', '델타 헷징', '인공신경망', '암호화폐 옵션', '비용 효율성', 'Hedging Strategy', 'Delta Hedging', 'Machine Learning', 'Cryptocurrency Options', 'Cost Efficiency']","현재 고변동성 금융 시장에서 효과적인 위험 관리를 위한 헷징 전략의 필요성에 중요해지고 있으며 특히, 비트코인 옵션과 같은 암호화폐 파생상품은 시장의 급격한 변동성으로 인해 전통적인 헷징 기법을 적용하는데 한계가 있다. 따라서 본 연구는 비트코인 옵션을 기초 자산으로 하는 파생상품의 헷징 전략을 비교 분석하며, 전통적인 델타 헷징 전략과 인공신경망을 이용한 헷징 전략의 성과를 헷징 비용 측면에서 평가하였다. 연구 결과, 인공신경망 기반 헷징 전략이 델타 헷징에 비해 평균적으로 약 17% 낮은 비용을 기록하며, 더 안정적인 비용 패턴을 보여주었다. 델타 헷징은 시장 변동성에 민감하게 반응하여 거래 비용이 증가하는 경향이 있는 반면, 인공신경망 헷징은 과거 데이터를 학습하여 최적의 포지션 조정을 통해 비용을 효율적으로 관리할 수 있었다. 이러한 결과는 고변동성 자산 시장에서 인공지능 기반의 헷징 전략이 전통적인 기법에 비해 더 효과적임을 시사하며, 향후 금융 시장에서 인공지능 기술의 활용 가능성을 제시한다.","The need for effective risk management strategies in today's highly volatile financial markets has become increasingly critical. In particular, applying traditional hedging techniques to cryptocurrency derivatives, such as Bitcoin options, faces significant challenges due to the market's rapid fluctuations. Accordingly, this study compares and analyzes hedging strategies for derivatives based on Bitcoin options, evaluating the performance of traditional delta hedging and artificial neural network-based hedging in terms of hedging costs. The study results reveal that the artificial neural network-based hedging strategy achieved, on average, approximately 17% lower costs compared to delta hedging, while also demonstrating a more stable cost pattern. Delta hedging tends to react sensitively to market volatility, leading to increased transaction costs. In contrast, artificial neural network-based hedging efficiently manages costs by learning from historical data to optimize position adjustments. These findings indicate that AI-based hedging strategies are more effective than traditional methods in highly volatile asset markets and suggest the potential for broader adoption of AI technologies in future financial markets."
인간 활동 인식에서 RF 기반 데이터를 ViT에 적용하기 위한 Resizing 방법,2025,"['Vision Transformer', 'RF-based data', 'Vision Transformer', 'RF 기반 데이터']","본 논문에서는 인간 활동 인식에서 주로 사용되는Radio Frequency (RF) 방식을 통해 얻은 RF 기반데이터를 최신 이미지 분류를 위한 머신러닝 기법인Vision Transformer (ViT)에 적용하였다. 이 과정에서이미지 크기와 다른 RF 기반 데이터의 크기를 ViT에적용할 때 발생하는 문제점을 분석하고, 이를 해결하기 위해 고려해야 할 입력 사이즈resizing 방법들을제시하였다. 또한, 다양한 resizing 방법들과의 비교를통해 RF 기반 데이터에 가장 효과적인 resizing 방식을 제안하였으며, 이를 통해 평균 9.57%의 성능 개선을 달성하였다.","This paper applies RF-based data, obtained through the commonly used Radio Frequency (RF) approach in human activity recognition (HAR), to the Vision Transformer (ViT), a state-of-the-art machine learning method for image classification.Through this process, we analyze the challenges arising from applying RF-based data, which have different sizes compared to standard image dimensions, to ViT. To address these challenges, we propose various input resizing methods. Furthermore, through a comparison of these resizing methods, we identify the most effective resizing approach for RF-based data, achieving an average accuracy improvement of 9.57%."
Fin-BERT 모델 기반 감성 점수 활용 주가 예측,2025,"['감성점수', 'Fin-BERT', 'Random Forest', 'XGBoost', 'LSTM', 'Sentiment score', 'Fin-BERT', 'Random Forest', 'XGBoost', 'LSTM.']","경제 및 기술의 발전으로 인해 많은 사람이 주식에 대한 관심이 높아졌다. 이러한 관심을 발전된 머신러닝과 딥러닝 모형에 적용하여 많은 주가 예측 모델이 개발되었다. 최근의 연구는 주식에 대한 문자정보를 반영한 예측모형이 등장하였고 그 중 대부분의 연구는 뉴스 데이터를 이용하여 주가 예측 모델을 만들었다. 그러나 뉴스 데이터는 중립적인 경향이 너무 강해서 정확한 감성 분류가 어렵다고 판단되어 본 연구에서는 남녀노소 자유롭게 의견을 작성할 수 있는 커뮤니티 데이터인 네이버 종목토론실 데이터를 이용하여 주가 예측 모델을 만들고자 한다. 금융 도메인 데이터를 더 정확하게 감성 분류하기 위해 한국어 금융 데이터를 학습시킨 KR-FinBERT를 이용해서 감성 분류를 진행하였다. 주가는 최근 데이터에 영향을 가장 많이 받기 때문에 가중이동평균을 가중치로 이용하여 최종 감성 점수를 만들었다. 네이버 종목토론실 데이터로 만든 감성 점수가 주가 예측에 영향을 미치는지 확인하기 위해 Random Forest, XGBoost, LSTM 세 가지 분석 방법론을 이용하여 감성 점수가 있는 데이터로 만든 모델과 감성 점수가 없는 데이터로 만든 모델을 비교하였다. 모델 비교를 위해 사용된 평가 지표는 RMSE와 MAE가 사용되었다. 분석 결과 세 가지 분석 방법을 이용한 모델 비교에서 감성 점수가 있는 데이터의 평가 지표가 더 좋게 나와 감성 점수가 주가 예측에 영향을 미치는 것을 확인할 수 있었다","Economic and technological advancements have led to a growing interest in stocks for many people. Investors want to make profits, which has led to the creation of many stock price prediction models using machine learning and deep learning models. Most studies have used news data to create stock price prediction models, but news data tends to be too neutral to accurately classify sentiment. In this study, we aim to create a stock price prediction model using NAVER Stock Discussion Room data, a community data where people of all ages can freely write opinions. In order to more accurately classify sentiment in the financial domain, we used KR-FinBERT, which is trained on Korean financial data, to perform sentiment classification. Since stock prices are most affected by recent data, we used a weighted moving average as a weight to create the final sentiment score. To check whether the sentiment scores generated from the NAVER stock discussion board data have an impact on stock price prediction, we compared the models generated from the data with sentiment scores to the models generated from the data without sentiment scores using three different analysis methodologies. Random Forest, XGBoost, and LSTM. The evaluation metrics used to compare the models were RMSE and MAE. The results of the analysis showed that the evaluation metrics of the data with sentiment scores were better in the model comparison using the three analysis methods, confirming that sentiment scores have an impact on stock price prediction."
A Study of Spray Volume Prediction Techniques for Variable Rate Pesticide Application using Unmanned Aerial Vehicles,2025,['Unmanned aerial vehicles (UAV) · Variable-rate pesticide application · Precision agriculture · Pulse width modulation (PWM) · Spatial variation · Predictive modeling · Machine learnin'],,"Purpose This study explores the integration of spatial variation and pulse width modulation (PWM) technology in unmanned aerial vehicle (UAV)-based variable-rate pesticide application to enhance precision and sustainability in agriculture. This study aims to quantify the eff ects of spatial variation on spray distribution and develop predictive models for estimating spray amounts under varying mission conditions.Methods The study utilized a multi-rotor UAV equipped with a liquid spray system. The study involved eight UAV missions across a 200-cell fi eld, with three distinct PWM settings (1300, 1450, and 1650) and two fl ight speeds (2.5 m/s and 6.0 m/s).Missions 1–6 focused on identifying key operational variables infl uencing spray amounts, while Missions 7–8 validated the predictive models. Random forest and pruned decision tree models were used to analyze factors infl uencing “Flight Time per Cell (seconds)” and “Spray Amount (L).” Results Spatial variation signifi cantly impacted spray distribution across the UAV missions. The study identifi ed “Number of Cells,” “UAV start position,” and “Velocity” as key factors aff ecting spray distribution. The machine learning models accurately predicted spray amounts, with discrepancies noted between aerial and ground spray rates, especially at higher PWM settings.Conclusions This study underscores the importance of integrating real-time data and predictive modeling for UAV-based pesticide application. By addressing spatial variation and operational complexities, the fi ndings contribute to improving spray effi ciency, reducing chemical wastage, and promoting environmentally sustainable agricultural practices. Future research should incorporate diverse environmental conditions and intermediate fl ight speeds to further refi ne predictive models and enhance their real-world applicability."
BIM 기반 설계 상세화 과정에서의 정보 흐름 정량화 방법,2025,"['건축정보모델링(BIM)', '설계 과정', '과정 정량화', '기계학습', 'Building Information Modeling (BIM)', 'Design Process', 'Process Quantification', 'Machine Learning']","본 연구는 건축 정보 모델링(Building Information Modeling; BIM) 모델을 통해 객체의 데이터 변화를 정량적으로 분석하여 상세화 과정의 정보 흐름을 모니터링하기 위한 방법을 제안한다. BIM 도입의 잘 알려진 장점은 정보의 흐름을 개선한다는 것인데, 이는 설계 과정에 대한 관리를 위해 핵심적인 요소이다. 설계 과정에 대한 이해와 개선을 위해서는 정량적이고 분석적인 접근이 중요 하지만, BIM 저작과정을 정량화하여 모니터링하는 방법에 대해서는 아직까지 연구 격차가 존재한다. 이에, 본 연구는 BIM 모델 내객체의 데이터 변경 유형을 통해 설계 과정에서 발생한 변경사항들을 정량화하는 방법을 제안한다. 제안된 방법은 1) 데이터 변경 유형에 대한 정의, 2) 연속적인 BIM 모델 간에 대응하는 객체 식별 모델의 개발, 그리고 3) 상세 정도(Level of Development; LOD) 가중치와 변경 유형에 따른 정량화를 BIM 기반 설계 상세화 과정의 정보 흐름을 분석한다. 논문은 제안된 방법을 실무 프로젝트의 계획설계, 중간설계, 그리고 실시설계 단계에서 작성된 BIM 모델 사례에 적용한 결과를 포함한다. 결과는 제안된 방법이 BIM 기반 설계 상세화 과정에서 발생한 정보의 흐름을 정량적으로 분석에 효과적이며, 향후 설계 과정 관리를 위한 의사결정 지원 도구로의 발전할 가능성을 보여준다.","This paper introduces a novel method for quantifying changes in Building Information Modeling (BIM) object data during BIM-enabled design detailing process. A significant advantage of BIM is its ability to improve information flow, a crucial element in managing the design process. However, despite the importance of this capability, existing research lacks robust quantitative methods for monitoring the detailed stages of BIM authoring. To bridge this gap, we propose a systematic approach that involves three key steps: 1) defining the types of data changes, 2) developing a classifier to match and track BIM objects across consecutive models, and 3) applying a weighted Level of Development (LOD) framework to quantify the extent and significance of these changes. The proposed method was applied in a case study analyzing BIM models from the Schematic Design (SD), Design Development (DD), and Construction Documentation (CD) phases of a project. The results demonstrate that our approach effectively reflects and quantifies the progression of design changes between these phases. Moreover, the findings highlight the potential of this method to serve as a decision support tool, enhancing the management of the design process by providing detailed insights into the evolution and development of design details."
생성형 AI를 활용한 전문번역 수업 모델 연구 - 독한 기계번역 포스트에디팅을 중심으로,2025,"['생성형 AI', 'MTPE', '메타인지 전략', '자기조절 번역능력', '전문번역 교육', 'Generative AI', 'MTPE', 'metacognitive strategy', 'self-regulated translation competence', 'professional translation training']",,"This study explores how learners apply metacognitive strategies in a professional translation course through generative AI-based MTPE (machine translation post-editing) tasks. Comparing human translation (HT) and MTPE phases in a graduate translation program, the study analyzed students’ assignments, protocols, and interviews.Results show that learners used significantly more monitoring and evaluation strategies during the MTPE phase. They critically assessed AI outputs for errors and consistency, enhancing their self-regulated translation competence. The findings suggest that generative AI can serve as a cognitive partner, supporting strategic thinking in translator training.This study highlights the value of metacognitive strategy-based instruction and suggests that AI-integrated MTPE tasks can foster reflective, self-directed learning in translation education."
식품 안전관리 체계가 수입식품 위해도 예측에 미치는 영향 비교 분석: 기계학습 접근법,2025,"['수입식품 관리 체계', '수입식품', '식품안전', '기계학습', 'Imported food management systems', 'Imported food', 'Food safety', 'Machine learning.']",,
공기질 IoT 센서를 이용한 차량 흡연탐지 시스템,2025,"['공유차', '흡연탐지', '사물인터넷', '공기질센서', '기계학습', 'Smoking Detection', 'Rent-a-car', 'IoT', 'Air-Quality Sensor', 'Machine Learning']","자동차를 소유하는 것에서 이용하는 것으로 사용자들의 인식이 변화하고 있는 가운데 공유차와 같은 렌터카 시장이 지속적인 성장을 보이고 있다. 하지만 불특정 다수가 사용하는 공유차에서 발생한 차량 실내 흡연으로 인해 다음 이용자가 불편을 호소하는 등의 민원도 갈수록 증가하고 있다. 본 연구는 이를 해결하기 위해 차량내 공기질 데이터를 수집하는 IoT 센서를 설치하고 이를 수집/분석/처리하여 실시간으로 흡연을 탐지할 수 있는 시스템을 구현하였다. 그리고 이를 국내 차량공유회사 A사의 30대 차량을 대상으로 3개월 동안 실증한 결과 1369건의 흡연이 탐지되었고, 그 중 50%는 전자담배를 피운 것으로 확인되었다. 또한 주말보다는 주중의 흡연비율이 높았고, 새벽 시간운행 차량에서는 여러번의 흡연이 행해지고 있음을 알 수 있었다. 결과적으로 본 연구의 흡연탐지 시스템을 통해 공유차나 렌터카 회사들은 사후적으로 흡연 여부를 추정하는 부정확한 방식을 벗어나 IoT센서를 이용한 시스템적 흡연탐지가 가능해짐으로써, 불특정 다수의 고객이 이용하는 공유차 서비스에서 흡연을 실시간으로 탐지하여 경고함으로서 금연을 유도할 수 있고, 흡연으로 인해 발생할 수 있는 차량내 불청결 요소와 비흡연자 고객 불만 요인을 사전에 차단할 수 있을 것으로 기대된다.","As users shift from owning vehicles to using them, the rental car market, including shared vehicles, is experiencing continuous growth. However, complaints are on the rise as more users report discomfort from indoor smoking in shared cars. To address this issue, this study developed a system capable of detecting smoking in real time by IoT based air quality sensors within vehicles. The system was tested on 30 vehicles from domestic car-sharing company A over three months, detecting a total of 1,369 smoking incidents, with 50% involving e-cigarettes. Smoking rates were higher on weekdays than on weekends, and multiple smoking occurrences were observed in vehicles operating during early morning hours 2:00 am. As a result, this IoT sensor-based smoking detection system allows car-sharing and rental companies to detect smoking in real-time. Consequently, the system can encourage non-smoking behavior, help maintain cleanliness inside shared vehicles, and prevent potential complaints from non-smoking customers about unclean conditions due to smoking."
Association Analysis of Wind Turbine Grid-Connected Oscillation Modes and Influencing Factors Based on Improved Association Rule Mining,2025,['Wind farm grid-connected system · Oscillation modes · Synchronous extraction transform · Prospective authors · Improved association rule mining'],,"Accurate oscillation mode recognition and stability analysis based on big data are critical for the safe operation of wind turbine systems. This paper utilizes modern statistical and machine learning methodology to analyze the correlation between monitored wind turbine operation data and oscillation phenomena, and a system oscillation analysis and diagnosis method is proposed based on an improved association rule mining (ARM) model. Firstly, the oscillation modes in the power data are measured by the synchronous extraction transform. By improving the ARM model, a thorough study is conducted on the correlation between oscillation modes and variables such as wind speed, compensation degree, voltage fuctuation, etc.Finally, the component importance measure is used to optimize each element's risk weight calculation method relative to the system oscillation. The experiments demonstrate that the proposed association rule analysis method can efectively analyze the relationship between system oscillation phenomena and infuencing factors and exhibits high diagnostic accuracy."
This work was supported by the RISE program of Kumoh National Institute of Technology.,2025,"['Epigenomics', 'Parkinson’s disease', 'DNA methylation', 'Age acceleration', 'Epigenetic age']",,"Changes in DNA methylation patterns in human genes can not only impair gene activation but also contributes to epigenetic age. To measure these changes machine learning models are used which measures the degree of changes in DNA methylation pattern. Parkinson's disease is the second most common neurodegenerative disease which affects motor function. Even though it may develop before the age of 50 due to genetic factors, the gene that causes Parkinson's disease is linked to aging, so the incidence increases with age, and most people get affected by Parkinson’s disease are over the age of 50. It is a geriatric disease that occurs in older aged people. Changes in DNA methylation patterns have been observed in patients with Parkinson's disease. Therefore, the epigenetic age of patients with Parkinson's disease was measured using Epi clock, which is one of the epigenetic clock models which was trained using 6761 CpG probes from pan tissue.Additionally, the acceleration of age was measured and changes in DNA methylation patterns were confirmed. Through this, it was confirmed that although the epigenetic age of Parkinson's disease patients accelerates, the difference is small which is approximately 1 to 5 years. Even though Hypo methylation of CpG probes increased, it was to a small extent."
Temporal Fusion Transformer를 통한 해석 가능한 농산물 가격 예측,2025,"['농산물 가격', '장기 예측', '설명가능한 AI', 'VSN', 'TFT', 'Agricultural Commodities', 'Multi-Horizon Forecasting', 'Explainable AI', 'VSN', 'TFT']",,"As climate change and global uncertainties continue to grow, long-term agricultural commodity price forecasting is becoming increasingly important. However, traditional statistical and machine learning models struggle to capture the complex inter-variable interactions, while recurrent-based models face limitations in handling long-term dependencies and interpretability. Addressing these challenges, this study employs the temporal fusion transformer (TFT) to predict agricultural prices and analyze the importance of variables during the learning process. Experimental results show that the average mean absolute percentage errors for 96- and 192-day forecasts are 7.54% and 11.72%, respectively. Furthermore, key variables in the prediction process are quantitatively assessed utilizing the variable selection network (VSN) in TFT, thereby improving the model's interpretability. Finally, this study suggests that TFT-based models can be applied to various decision-making processes in agriculture, including production planning optimization, cost management, and policy development."
생성형 AI 미디어아트의 기술‧미학적 특성과 창작 주체성에 대한 연구,2025,"['생성형 AI', '생성형 AI 미디어아트', '창작 주체성', '인간–기계 협업', '생성형 AI 기반 미디어아트의 기술·미학적 특성', 'Application of Generative AI in Media Art', 'Creative Subjectivity', 'Generative AI', 'Human–Machine Collaboration', 'Technological and Aesthetic Characteristics of Media Art Using Generative AI']","본 연구는 생성형 인공지능(AI)이 미디어아트의 기술적·미학적 특성과 창작 주체성을 어떻게 변화시키는지를 고찰하였다. 생성형 AI는 대규모 데이터 학습과 알고리즘 연산을 통해 콘텐츠를 자율적으로 생성하며, 예술 창작 방식과 감각 구성 원리 및 창작 주체의 개념을 근본적으로 재구성한다. 본 연구는 프롬프트 기반 생성, 알고리즘 자율성, 실시간 데이터 반응성, 인간–기계 협업 구조를 생성형 AI의 핵심적 특성으로 규정하고, 이러한 특성이 미디어아트에서 비정형적 시각 표현과 감각 매체의 확장을 촉진함을 분석하였다. 또한 창작 주체성이 통합된 인간 중심 모델에서 분산된 협력 구조로 이동하는 양상을 이론적으로 고찰하며, 이를 통해 생성형 AI 기반 미디어아트가 공공적 맥락에서 예술의 사회적 역할과 소통 방식을 확장할 수 있는 가능성을 논의하였다.","This study investigates how generative artificial intelligence (AI) transforms technological characteristics, aesthetic characteristics, and creative subjectivity within media art. Generative AI autonomously produces content through large-scale data learning and algorithmic computation, fundamentally reshaping artistic creation methods, sensory compositions, and concepts of authorship. This study identifies key technological characteristics—prompt-based generation, algorithmic autonomy, real-time data responsiveness, and human–machine collaboration—and analyzes the resulting aesthetic shifts toward non-linear visual expressions and expanded sensory experiences. Additionally, the study argues that generative AI reconfigures creative subjectivity from a unified human-centered model to a distributed relational framework. Based on the identified transformations, the study further discusses the potential for generative AI-based media art to extend its social functions and interactive communication to public contexts. Ultimately, this study contributes to establishing a theoretical framework to critically reconsider creative agency and the boundaries between creation and generation in the era of generative AI."
적극행정의 영향요인에 관한 연구:  CatBoostRegressor와 SHAP을 활용하여,2025,"['proactive administration', 'determinants of proactive administration', 'CatBoostRegressor', 'SHAP', 'ICE', '적극행정', '적극행정 영향요인', 'CatBoostRegressor', 'SHAP', 'ICE']","본 연구는 적극행정의 영향요인을 실증적으로 규명하고자 하였다. 기존의 적극행정 연구는 주로 선형적회귀분석에 의존하여 변수 관계를 탐색해왔으나, 실제 적극행정은 복합적이고 비선형적인 변수 간 상호작용으로 구성되어 있다. 이에 본 연구는 머신러닝 기법인 CatBoostRegressor와 설명 가능한 인공지능 기법인 SHAP(SHapley Additive exPlanations)을 활용하여, 적극행정의 다양한 개인적·조직적 영향요인을 포괄적으로 분석하였다. 분석 자료는 한국행정연구원의 『2023년 공직생활실태조사』 데이터를 활용하였으며, 중앙정부와 광역·기초자치단체 공무원 6,444명의 응답을 기반으로 하였다. 연구 결과, 적극행정에 가장 큰영향을 미치는 요인은 공직가치였으며, 조직시민행동, 공공봉사동기, 직무만족, 목표명확성이 뒤를 이어 주요 예측변수로 나타났다. 반면 기존 연구에서 중요하게 논의되었던 리더십 유형이나 조직커뮤니케이션과 같은 변수들은 상대적으로 낮은 영향력을 보였다. 방법론적 측면에서, CatBoostRegressor는 기존 선형회귀모형과 비교하여 비선형성 및 변수 간 복합적 상호작용을 포착할 수 있는 구조적 장점을 바탕으로 분석을수행하였으며, SHAP 분석은 각 변수의 기여도 및 영향 방향성을 시각화함으로써 모형의 해석 가능성을 보완적으로 제시하였다. 이러한 분석 결과는 적극행정이 조직적·제도적 요인보다 공무원 개인의 내재적 동기및 가치지향적 특성에 의해 주로 촉진됨을 시사하며, 행정조직의 인사관리 및 조직문화 전략 설계에 시사점을제공한다","This study aims to empirically identify the factors influencing proactive public administration. Previous studies on proactive administration have typically relied on linear regression models, limiting their analysis to simplistic variable relationships.However, actual proactive administration is characterized by complex, nonlinear interactions among multiple variables. Therefore, this research comprehensively analyzes various individual and organizational factors affecting proactive administration by employing the CatBoostRegressor machine learning algorithm alongside SHAP (SHapley Additive exPlanations), a technique for interpretable artificial intelligence. The study utilized data from the “2023 Public Employee Perception Survey” conducted by the Korea Institute of Public Administration, involving responses from 6,444 public officials from central and local governments (metropolitan and municipal). The results indicated that public service values had the most significant influence on proactive administration, followed by organizational citizenship behavior, public service motivation, job satisfaction, and goal clarity. In contrast, factors traditionally emphasized in previous literature, such as leadership style and organizational communication, demonstrated relatively lower predictive power. Methodologically, the CatBoostRegressor effectively captured nonlinearities and complex interactions between variables more precisely compared to a conventional linear regression model. Furthermore, the SHAP analysis enhanced interpretability by visually illustrating the relative contributions and directional impacts of each variable. These findings imply that proactive administration is primarily driven by individual intrinsic motivation and value-oriented characteristics of public officials, rather than organizational or institutional factors. Consequently, this research offers implications for human resource management and the strategic design of organizational culture within public administration."
생성형 AI의 RAG를 활용한 개인 신용대출 부도예측에 대한 연구,2025,"['generative AI', 'RAG', 'LLM', 'personal credit loan default prediction', '생성형 AI', 'RAG', 'LLM', '개인 신용대출 부도예측']","금융 산업에서 빅데이터와 AI의 중요성이 커지면서, 신용 위험 관리에서의 활용이 핵심 과제로 떠오르고 있다. 부도 예측은 금융기관의 자산 건전성과 대출 심사 효율성을 높이는데 필수적이며, 이를 위해 전통적인 로지스틱 회귀에서 머신러닝 및 딥러닝 기술로 발전해 왔다. 최근 금융기관들은 생성형 AI와 LLM을 대출 심사에 적용하려 하지만, LLM이 금융 도메인의 세부 정보를 충분히 반영하지 못할 가능성이 제기된다. 이에 따라 정보 검색과 예측 정확도를 높이는 RAG 기술이 주목받고 있다.본 연구에서는 개인 신용대출 부도 예측을 위해 RAG 기반 예측 모델과 RAG-LLM 결합 모델을 연구하였다. 실험 결과, 기존 로지스틱 회귀나 XGBoost 대비 예측성능이 낮았으며, 이는 신용 변수의 복잡성을 충분히 반영하지 못한 한계로 볼 수 있다. 또한, RAG-LLM 결합 모델 역시 기존 방법론 대비 낮은 예측 성능을 보여, 특정 금융 도메인에서 LLM의 한계를 시사하였다.반면, 씬파일러(thin-filer)를 대상으로 한 RAG 기반 모델은 소규모 데이터 환경에서도 안정적인 예측력을 보여 대안적 접근법으로 활용 가능함을 확인하였다. 이러한 결과는 금융권에서 생성형 AI를 도입할 때 시행착오를 줄이는데 중요한 시사점을 제공할 것이다.","As big data and AI become increasingly important in the financial industry, their application in credit risk management has emerged as a key issue. Default prediction is essential for enhancing financial institutions' asset soundness and loan screening efficiency, and traditional logistic regression models have evolved into machine learning and deep learning techniques to improve accuracy. Recently, financial institutions have been exploring the application of generative AI and Large Language Model (LLM) in loan screening, but concerns have been raised that LLMs may not fully capture the detailed information specific to the financial domain. As a result, Retrieval-Augmented Generation (RAG) technology, which enhances information retrieval and prediction accuracy, has gained attention.This study investigates RAG-based default prediction models and RAG-LLM hybrid models for personal credit loan default prediction. Experimental results showed that their predictive performance was lower than traditional logistic regression and XGBoost models, likely due to the inability to fully incorporate the complexity of credit-related variables. Moreover, the RAG-LLM hybrid model also exhibited lower predictive accuracy than existing methods, highlighting the limitations of LLMs in specialized financial domains.On the other hand, the RAG-based model demonstrated stable predictive performance in small-scale data environments, particularly for thin-filer borrowers, suggesting its potential as an alternative approach. These findings provide important insights for financial institutions, helping to reduce trial and error in the adoption of generative AI for credit risk assessment."
IoT 환경에서 안티디버깅 회피를 보완하기 위한 자동화된 디바이스 바인딩 적용 방법 설계 및 구현,2025,"['Device Binding', 'IoT', 'Anti-debugging', 'LLVM Pass', 'Device DNA']",,"IoT devices are connected to the internet and capable of collecting, transmitting, and processing data. With advancements in AI and machine learning technologies, these devices are utilized in various fields. However, they handle sensitive information and have high service development costs, making them vulnerable to security issues, Particularly, the software of IoT devices can be maliciously analyzed through debugging, necessitating anti-debugging techniques. Existing anti-debugging methods can be bypassed, so device binding technology is helpful in defending against such attacks. Device binding ensures that software operates only on specified devices by comparing unique values for authentication. This parer proposes a method for automatically inserting device binding techniques using LLVM Pass, and describes a system that generates unique values using Device DNA and verifies signatures."
토픽 출현 지도 기법을 활용한 출원 특허 기반 이머징 기술 분석,2025,"['유망 기술 분석', '텍스트 마이닝', '이머징 토픽', '토픽모델링', '토픽 출현 지도', 'emerging technology analysis', 'text mining', 'emerging topics', 'topic modeling', 'topic emergence map']","과학기술의 급격한 발전에 따라 효율적인 예산 배분을 위해 분야별 유망 기술을 발굴하고 우선순위를 설정하는 작업은 국가 기술 경쟁력을 확보하는 데 필수적이다. 기존 연구들은 다양한 머신러닝 기법과 통계적 방법론을 활용하여 연구 동향을 파악하고 기술 추세를 분석해 왔다. 그러나 데이터 공개 시점의 지연으로 인해 최신 기술을 신속하게 포착하기 어려웠으며, 대부분 단일어 기반의 분석이기 때문에 텍스트 자료의 맥락을 충분히 반영하지 못하는 한계가 있었다. 본 연구는 이러한 문제를 해결하고자, 출원 특허에 기반한 복합어 키워드를 활용하여 디지털 헬스케어 분야에서 이머징 기술 트렌드를 분석하는 새로운 방법을 제안한다. 제안한 방법의 핵심은 토픽 출현 지도 기법을 활용하여 중요도는 낮지만 성장률이 높은 토픽을 이머징 토픽으로 정의하고, 복합어 키워드가 가진 의미를 충분히 살려 해석 가능한 수준에서 이머징 기술을 도출하는 것이다. 디지털 헬스케어 분야 출원 특허 데이터에 제안된 방법을 적용한 결과, 주목할 만한 이머징 토픽을 도출하였으며, 이를 통해 방법론의 우수성을 입증하였다. 본 연구의 접근법은 디지털 헬스케어를 넘어 다양한 산업 분야에 적용 가능하며, 추후 전략적 R&D 기획과 자원 배분 과정에서 신규 투자 영역 발굴 및 자원 수요 예측에 실질적인 기여를 할 것으로 기대된다.","Efficient budget allocation through the identification of emerging technologies is critical for national technological competitiveness in an era of rapid scientific and technological advancement. Existing studies leveraging machine learning and statistical methods face challenges in promptly capturing emerging technologies due to delays in data availability and reliance on single-word analyses, which fail to fully reflect textual context. This study addresses these issues by proposing a new method to analyze emerging technology trends in the digital healthcare sector using compound keywords from patent applications. The proposed method identifies emerging topics with low importance but high growth rates through topic emergence map, enabling interpretable and contextually rich insights. Application of the proposed method to digital healthcare patent data revealed notable emerging topics, demonstrating its effectiveness. The proposed method is versatile, with potential applications across various industries, contributing to strategic R&D planning and resource allocation by identifying new investment areas and forecasting resource needs."
랜덤 포레스트와 전자 데이터 교환 정보를 활용한 수입 컨테이너 체류 시간 예측 연구,2025,"['항만', '수입 컨테이너', '컨테이너 체류 시간', '전자 데이터 교환', '기계 학습', 'Port', 'Import Container', 'Container Dwell Time', 'Electronic Data Interchange', 'Machine Learning']","연간 수백만 Twenty-foot Equivalent Unit (TEU) 컨테이너를 하역하는 항만에서, 제한된 야드 공간 내에서 효율적인 컨테이너 관리는 중요한 문제로 여겨진다. 하지만, 야드 운용을 효율적으로 관리하기에 많은 난항을 겪고 있는데, 그 원인 중 하나는 Import Container Dwell Time (ICDT)이 서로 다른 원인에서 기인한다. ICDT는 선박을 통해 양하 된 컨테이너를 운송사가 육지로 반출할 때까지 소요되는 시간으로 정의되는데, 컨테이너의 속성과 운송사의 배차계획 등 여러 복잡한 요인들에 영향을 받기 때문에, 정확히 예측하기 어렵다. 이러한 어려움에도 불구하고, 정확한 ICDT 예측은 효율적인 야드 운영에 기여하므로 매우 중요하다. 본 연구에서는 ICDT의 예측 성능을 향상시키기 위해 Electric Data Interchange (EDI) 데이터를 활용할 것을 제안한다. EDI는 컨테이너의 반입부터 반출까지의 프로세스 내 세관 신고, 컨테이너 반출 마감 기한과 같은 시간 정보를 포함하고 있다. 이러한 시간 정보들을 사용하여 ICDT 예측에 사용할 수 있는 외부 변수들을 생성할 수 있으며, 이는 ICDT 예측에 기여할 수 있다. 제안하는 접근법의 효과성을 검증하기 위해 실제 현장에서 수집된 데이터를 사용하였다. 실험 결과, 다양한 예측 모델 중 Random Forest (RF)가 가장 우수한 성능을 보여주었으며, EDI 데이터를 통합함으로써 예측 성능이 크게 개선됨을 확인하였다. 특히, EDI 데이터에서 파생된 변수들이 높은 변수 중요도를 보여주었다. 이러한 결과는 ICDT의 정확한 예측을 위해 EDI 정보의 필요성을 시사한다.","In ports that handle millions of Twenty-foot Equivalent Unit (TEU) containers annually, efficient container management within limited yard space is considered a critical issue. However, managing yard operations efficiently presents numerous challenges, one of which is the variability in Import Container Dwell Time (ICDT) due to multiple underlying factors. ICDT is defined as the duration from the unloading of a container from a vessel to its retrieval by a transport operator for inland transportation. Because ICDT is influenced by various complex factors, such as container attributes and transport operators’ dispatch plans, it is difficult to predict accurately. Despite these challenges, precise ICDT prediction is essential for efficient yard operations. This study proposes leveraging Electronic Data Interchange (EDI) data to enhance the prediction performance of ICDT. EDI contains crucial time-related information throughout the container handling process, including customs clearance records and container retrieval deadlines. By utilizing EDI data, external variables can be generated for ICDT prediction, contributing to improved prediction accuracy. To validate the effectiveness of the proposed approach, real-world data collected from operational sites were used. The experimental results indicate that among various prediction models, Random Forest (RF) demonstrated the highest performance, and integrating EDI data significantly improved predictive accuracy. Notably, variables derived from EDI data exhibited high importance in the predictive model. These findings underscore the necessity of incorporating EDI information for accurate ICDT prediction."
인공지능을 활용한 공간 아카이브의 콘텐츠 확장성,2025,"['Artificial Intelligence', 'Spatial Archives', 'Art and Design Materials', 'Digitalization', 'Virtual Space', '인공지능', '공간 아카이브', '미술·디자인 자료', '디지털화', '가상공간']","(연구배경 및 목적) 본 연구는 디지털 기술과 아카이브의 확장에 따른 변화, 인공지능 기술의 부상, 그리고 미술 및 디자인 분야의 디지털화 현황을 배경으로 한다. 전통적인 아카이브 개념은 디지털 시대의 도래와 함께 공간적·범위적인 확장을 경험하였으며, 미술 아카이브와 데이터 활용의 중요성이 대두되고 있다. 더불어, 생성형 인공지능과 머신러닝 등 첨단 인공지능 기술이예술·디자인·아카이브 분야에서 창작과 데이터 분석에 적극 활용되면서 새로운 가능성과 동시에 과제들도 제기되고 있다. 특히, 미술 작품을 비롯한 다양한 디자인 자료의 디지털화는 기존의 물리적 한계를 넘어 온라인 및 가상 공간으로의 확산을 촉진시켰다. 이에 공간 아카이브 내에서 인문학적 영역에 인공지능 데이터를 활용할 수 있는 가능성을 탐색하는 데에 목적을 두고 있다. 이를 위해, 디지털 아카이브와 인공지능 기술의 융합을 통해 미술·디자인 자료 및 공간 아카이브의 미래적 방향성을 모색하고, 국내외 사례 분석과 실무 및 이론적 연구를 병행하여 인공지능이 미술·디자인 아카이브의 역할에 어떠한 변화와 확장을 가져올수 있는지 고찰하였다. (연구방법) 아카이브, 인공지능, 디지털화 관련 선행연구와 사례들을 폭넓게 검토하였으며, 특히 미술 아카이브와 디지털 아카이브의 실태를 분석하고, 인공지능 기술 활용의 기능과 한계에 대해 고찰하였다. 이러한 분석에 근거하여, 본 연구는 인공지능과 디지털 아카이브의 결합 가능성을 검증하고, 향후 확장 및 융합의 방향성을 제시하였다. (결과) 인공지능이 디지털 아카이브와 결합될 경우 미술·디자인 자료의 창작, 확장, 대중화에 유의미한 기여를 할 수 있다는 점이 확인되었다. 특히, 디지털 아카이브는 기존의 물리적 공간을 넘어 가상·온라인 공간으로 확장됨에 따라, 예술과 디자인의 맥락적 해석과 접근성을 증진시키는 핵심 도구로 작용하고 있음을 알 수 있었다. (결론) 디지털 아카이브와 인공지능 기술은 상호 보완적 관계에있으며, 미래에는 이를 지속적으로 융합·확장하는 방향으로 발전시켜야 함을 제언한다. 또한, 본 연구는 이러한 기술 발전 현황에 맞춘 정책적·실무적 전략 마련이 필요하며, 이에 따른 표준화, 저작권 문제의 해결, 지속 가능한 디지털 큐레이션의 강화가필요하다고 제시한다. 결론적으로, 디지털 아카이브와 인공지능의 융합은 문화 콘텐츠의 확장과 대중화, 그리고 지속 가능한 발전의 핵심 동력임을 본연구를 통해 확인할 수 있었다.","(Background and Purpose) This study is grounded in the context of the ongoing expansion and transformation of archives driven by digital technology, the rising prominence of artificial intelligence (AI) techniques, and current trends in digitalization within the fields of art and design. Traditional notions of archives have experienced spatial and scope expansion in the digital era, emphasizing the increasing importance of digital art archives and data utilization. Moreover, advanced AI technologies such as generative AI and machine learning are actively applied in creative and data analytical processes within art, design, and archiving, opening new possibilities and presenting certain challenges. In particular, the digitalization of artworks and various design materials has facilitated their migration beyond physical boundaries into virtual and online spaces. The primary aim of this research is to explore the potential for utilizing AI data within spatial archives by investigating how the convergence of digital archives and AI technologies can influence future-oriented developments in art and design data. This is undertaken by examining domestic and international case studies and integrating practical and theoretical insights to understand how AI may transform and expand the roles of art and design archives. (Method) Through a comprehensive review of prior research and case studies related to archives, AI, and digitalization, this study analyzes the current status of art and digital archives, as well as the capabilities and limitations of the application of AI in these contexts.Based on these analyses, it examines the feasibility of integrating AI with digital archives and proposes directions for further expansion and convergence. (Results) The findings suggest that AI, when combined with digital archives, can significantly contribute to the creation, expansion, and democratization of art and design assets. Notably, digital archives, by extending beyond physical spaces into virtual and online environments, are increasingly serving as vital tools to provide contextualized interpretations and enhance the accessibility of artworks and designs. However, copyright issues, ethical considerations, and the lack of standardization and unification in archive management emerged as some of the main challenges that need to be addressed during the study. (Conclusions) The study suggests that the integration of digital archives and AI represents a mutually reinforcing relationship that should be continuously developed and expanded. It also emphasizes the need to establish policy and employ practical strategies that can address related issues such as standardization, copyright protection, and sustainable digital curation. Ultimately, the convergence of digital archives and AI is identified as a key driver for the expansion and democratization of cultural content and for achieving sustainable development in the cultural and artistic domains."
AI 기반 양서파충류 건강 관리 시스템 개발 연구,2025,,"최근 전 세계적으로 양서파충류 반려동물 시장이 급성장하고 있다. 하지만 이들은 건강 이상을 외부에 드러내지 않아 조기 진단이 어렵다. 이에 본 연구는 AI 기술을 활용한 반려동물 건강 관리 시스템을 제안한다. 제안된 시스템은 사용자 데이터를 기반으로 AI가 동물의 건강을 분석하고, 머신러닝 모델로 잠재적 건강 문제를 예측한다. 반려인은 이를 통해 사전에 건강 문제를 인지하고 실시간 맞춤형 관리 조언을 챗봇을 통해 받을 수 있다. 또한 커뮤니티 기능으로 사용자 간 정보 공유를 돕고, 양서파충류의 특수성을 고려한 맞춤형 AI 건강 관리 시스템을 개발한다. 이는 반려인의 관리 부담을 줄이고 양서파충류의 복지를 향상시키는 것을 목표로 한다.","In recent years, the global market for amphibian and reptile pets has been experiencing rapid growth. However, these animals often do not exhibit external signs of health issues, making early diagnosis challenging. This study proposes an AI-powered health management system for such pets. The proposed system leverages user data to enable AI analysis of animal health and utilizes machine learning models to predict potential health problems. Through this platform, pet owners can proactively recognize health concerns and receive real-time, personalized care advice via chatbot. Additionally, the system incorporates a community feature to facilitate information sharing among users and develops a customized AI health management system that specifically addresses the unique characteristics of amphibians and reptiles. The ultimate goal is to reduce the management burden on pet owners and improve the welfare of these animals."
SEMTree를 활용한 중고령층 삶의 만족도 변화의  하위 유형 탐색:  활동적 노화 요인을 중심으로,2025,"['삶의 만족도', '활동적 노화', 'SEMTree', 'SEMForest', 'life satisfaction', 'active ageing', 'SEMTree', 'SEMForest']","중고령층은 전통적으로 사회적 취약계층으로 인식되었으나 최근에는 건강한 삶의 주체로 기능할수 있다는 ‘활동적 노화’의 개념이 주목받고 있다. 본 연구는 활동적 노화를 구성하는 건강, 참여, 안전 차원의 다양한 요인 중 중고령층의 삶의 만족도 변화에 의미있는 영향을 미치는 주요 요인을 머신러닝 방법으로 선별하고, 선별된 요인의 수준을 바탕으로 하위집단을 분류하고자 하였다. 이를 위해 고령화연구패널의 5~9차 조사 자료를 SEMTree와 SEMForest 기법을 활용하여 분석하였다. 분석 결과, 주관적 건강, 수명에 대한 주관적 기대감, 그리고 가구 총소득 등의 공변인이삶의 만족도 변화에 영향을 미치는 주요 요인으로 선별되었으며, 해당 공변인을 바탕으로 총 4개의 상이한 삶의 만족도 변화 궤적을 가지는 하위 집단을 분류하였다. 위 세 가지 공변인 외에도변수 중요도 분석을 통해 건강, 참여, 안전 차원의 다양한 활동적 노화 요인들이 중고령층의 삶의만족도 변화에 영향을 미침을 확인하였으며, 해당 결과를 바탕으로 중고령층의 삶의 만족도 증진을 위한 활동적 노화 중심의 개입과 접근 방안에 대해 논의하였다. 본 연구는 모형 기반의 데이터마이닝 기법을 통해 활동적 노화의 다양한 요인과 삶의 만족도 변화의 관계를 경험적으로 살펴보았다는 의의를 지닌다.","The middle-aged and older adults have been perceived as socially vulnerable traditionally, but recently,  the concept of ‘active ageing’ has gained attention, emphasizing their potential to function as the subject of a healthy lives. This study aims to identify key factors from various factors of active ageing(health, participation, security) that significantly affect longitudinal changes in life satisfaction among middle-aged and older adults using machine learning techniques. Utilizing data from the 5th to 9th waves of the Korean Longitudinal Study of Ageing, we applied SEMTree and SEMForest methods for analysis. The results identified subjective health, subjective expectation for how long to live, and total household income as major influential factors on changes in life satisfaction. Based on these covariates, four distinct subgroups with different trajectories of life satisfaction changes were classified. Additionally, variable importance analysis revealed that various active ageing factors related to health, participation, and security also affect changes in life satisfaction among the middle-aged and older adults. We discussed on interventions and approaches centered on active ageing to enhance life satisfaction among this group based on our results. This study is meaningful in that it empirically examines the relationship between various active ageing factors and longitudinal changes in life satisfaction using model-based data mining techniques."
미세 조정을 통한 VideoLLaMA2 기반의보행자 도로 보행 예측 및 안전성 강화,2025,"['보행자 도로 보행 예측', '보행자 안전', '멀티모달 대규모 언어 모델', 'VideoLLaMA2', '미세 조정', 'Pedestrian Road-Crossing Prediction', 'Pedestrian Safety', 'Multimodal Large Language Model', 'VideoLLaMA2', 'Fine-tuning']","본 연구는 교통사고에서 가장 취약한 보행자의 안전을 강화하기 위해 최신의 멀티모달 대형 언어 모델(MLLM)인 VideoLLaMA2를 활용한 보행자도로 보행 예측 방법을 제안한다. 매년 약 5천만 건의 교통사고가 발생하며, 이 중 상당수가 보행자와 관련되어 있어 보행자의 도로 보행을 예측하는시스템의 필요성이 크다. 학습셋에만 의존적인 기존 머신러닝 및 딥러닝 기반 접근법의 한계를 극복하기 위해, 본 연구는 JAAD 데이터셋 기반의QA 데이터셋을 구축하고, VideoLLaMA2를 미세 조정하여 성능을 개선하였다. VideoLLaMA2는 시공간적 정보를 학습하는 STC Connector를 통해보행자 행동 예측의 정확성과 해석 가능성을 강화하며, 미세 조정된 모델은 미세 조정되지 않은 모델 대비 2% 향상된 정확도(ACC 60%)와 높은F1 점수(0.63)를 기록하였다. 추가로 입력 특징 소거 실험에서는 Scene Context, Bounding Box 좌표, Local Context 등이 성능 향상에 중요한역할을 함을 확인했으며, 영상 내 보행자 크기가 클수록 예측 성능이 높아지는 경향을 보였다. 정성적 평가 결과, 모델은 보행자의 행동을 해석가능한 방식으로 예측할 수 있었으며, 일부 오류 사례에서 데이터 품질 개선의 필요성을 제시한다. 본 연구는 자율주행차 및 교통안전 시스템의신뢰성과 안전성을 높이는 데 기여하며, 향후 다양한 주행 환경에서의 모델 검증과 실시간 대응 능력 강화를 위한 발전 방향을 제안한다.","This study proposes a pedestrian road-crossing prediction method utilizing the state-of-the-art Multimodal Large Language Model(MLLM), VideoLLaMA2, to enhance the safety of pedestrians, the most vulnerable road users in traffic accidents. With approximately 50million traffic accidents occurring annually, many involving pedestrians, the need for systems predicting pedestrian road-crossing behavioris critical. To overcome the limitations of traditional machine learning and deep learning approaches that heavily rely on training datasets,this study constructs a QA dataset based on the JAAD dataset and fine-tunes VideoLLaMA2 to improve performance. VideoLLaMA2 leveragesa Spatial-Temporal Convolution (STC) Connector to enhance the accuracy and interpretability of pedestrian behavior predictions. Thefine-tuned model achieves a 2% improvement in accuracy (ACC 60%) and a high F1 score (0.63) compared to the non-fine-tuned model.Ablation studies further demonstrate the importance of input features such as Scene Context, Bounding Box coordinates, and Local Context,while larger pedestrian sizes within the frame show a positive correlation with predictive performance. Qualitative results reveal thatthe model can predict pedestrian behavior in an interpretable manner, while highlighting the need for improved data quality in someerror cases. This study contributes to enhancing the reliability and safety of autonomous vehicles and traffic safety systems, and it suggestsfuture directions for validating the model across diverse driving environments and strengthening real-time responsiveness."
AI 기반 양서파충류 건강 관리 시스템 개발 연구,2025,"['AI', 'Amphibians', 'Animal Welfare', 'Community', 'Companion animal', 'Exotic Animals', 'Reptiles', 'AI', '양서류', '동물복지', '커뮤니티', '반려동물', '특수동물', '파충류']","최근 전 세계적으로 양서파충류 반려동물 시장이 급성장하고 있다. 하지만 이들은 건강 이상을 외부에 드러내지않아 조기 진단이 어렵다. 이에 본 연구는 AI 기술을 활용한 반려동물 건강 관리 시스템을 제안한다. 제안된 시스템은사용자 데이터를 기반으로 AI가 동물의 건강을 분석하고, 머신러닝 모델로 잠재적 건강 문제를 예측한다. 반려인은 이를통해 사전에 건강 문제를 인지하고 실시간 맞춤형 관리 조언을 챗봇을 통해 받을 수 있다. 또한 커뮤니티 기능으로 사용자 간 정보 공유를 돕고, 양서파충류의 특수성을 고려한 맞춤형 AI 건강 관리 시스템을 개발한다. 이는 반려인의 관리부담을 줄이고 양서파충류의 복지를 향상시키는 것을 목표로 한다.","In recent years, the global market for amphibian and reptile pets has been experiencing rapid growth. However, these animals often do not exhibit external signs of health issues, making early diagnosis challenging. This study proposes an AI-powered health management system for such pets. The proposed system leverages user data to enable AI analysis of animal health and utilizes machine learning models to predict potential health problems. Through this platform, pet owners can proactively recognize health concerns and receive real-time, personalized care advice via chatbot. Additionally, the system incorporates a community feature to facilitate information sharing among users and develops a customized AI health management system that specifically addresses the unique characteristics of amphibians and reptiles. The ultimate goal is to reduce the management burden on pet owners and improve the welfare of these animals."
Non-invasive Load recognition of Electrical Signals based on Improved Conv-TasNet,2025,"['Non-invasive load', 'Load identifi cation', 'Load decomposition', 'Data noise reduction', 'Conv-TasNet']",,"With the rapid development of smart grids, electricity meters now collect aggregated data from various appliances. To obtain the individual power sequence of target appliances, algorithms are used. Traditional load recognition methods rely on machine learning algorithms, which struggle due to low-frequency data accuracy, complex feature extraction for high-frequency data, and poor network generalization. To address these issues, this paper introduces a non-invasive load decomposition method that manages computational complexity using improved Conv-TasNet and DAE-ResNet algorithms. First, a denoising model based on depthwise separable convolutional residual networks reduces the training network complexity. Second, the Conv-TasNet algorithm is enhanced to improve the load decomposition performance. Input data is encoded with deep convolution, and a separation network forms a mask for the target device. Finally, the decoder combines max pooling and deep convolution to decode the target electrical information. Experimental results show that the proposed method significantly outperforms existing techniques in load identification and decomposition. It improves both the accuracy and convergence speed."
Computational approaches to predict the toxicity of bioactive natural products: a mini review of methodologies,2025,['Toxicity In silico Natural products Top-down Bottom-up'],,"Despite the increasing global demand for functional foods, the challenges associated with bioactive natural food products due to their complex composition remain. Bioactive natural products can potentially interfere with physiological activity regulation and lead to undesired side effects. This finding emphasizes the need for machine learning (ML)-based food safety predictions focused on intrinsic toxicity. This review explores various strategies involved in current methods of model selection and validation techniques used in predictive analysis, highlighting their strengths, limitations, and progress. Future studies should focus on testing compound combinations using top-down or bottom-up approaches with appropriate models to advance in silico toxicity modeling of bioactive natural products."
Design of a system-related risk management chain for an intelligent decision support system prototype in Korean nuclear power plants under normal and abnormal conditions,2025,"['Intelligent decision support system in NPPs', 'Risk management in AI System in NPPs', 'Intelligent decision support system prototype']",,"An Intelligent Decision Support System (IDSS) is being developed for the Korean APR1400 nuclear power plant (NPP) to enhance decision-making and reduce human error under normal and abnormal conditions. As a non-safety monitoring prototype, the IDSS is currently in development. While traditional Man-Machine Interface Systems in NPPs face risks from software and hardware failures, the integration of deep learning introduces further challenges, particularly those related to open-source software and adversarial AI threats. This study presented a comprehensive system-related risk management chain to address these issues. Risk factors in the IDSS’s development and operation were identified using the NUREG/CR-6430 risk assessment methodology. Based on this, a management plan was established, including administrative and technical controls. Administrative measures addressed licensing and cybersecurity for open-source components, while technical controls aimed to protect against cyber intrusions and maintain IDSS performance.The proposed risk management chain is expected to reduce operational losses and improve efficiency in NPP applications. It also supports the safe integration of intelligent systems into nuclear operations. Future efforts will apply the management chain across the IDSS development lifecycle to validate its effectiveness and expand its application to broader intelligent system deployment in NPPs."
기획단계 국방 R&D 소요예산 예측을 위한 텍스트 회귀분석 모델,2025,"['R&D budget prediction', 'defense force support system', 'natural language processing', 'text  regression analysis']",,"This study proposes a text regression analysis model to enhance the reliability and accuracy of R&D budget predictions. Using text data from the Defense Force Support System Requirements Document, we introduce a data-driven approach for budget forecasting. This study combines NLP(Natural Language Processing) and machine learning techniques to quantitatively analyze and predict budgets required in the defense R&D sector. This method is expected to strengthen the objectivity of the budget formulation process and enhance the precision of strategic decision-making. Additionally, the methodology presented in this study offers a reliable framework for generating dependable results even in data-constrained environments, providing a critical foundation for the development and practical application of future defense R&D budget prediction models."
중국 웨이보의 소프트 선전과  공식⋅비공식 계정의 담론 비교:  후쿠시마 핵 오염수 방류 사건을 중심으로,2025,"['Fukushima nuclear contaminated water', 'soft propaganda', 'gatekeeping', 'opinion leadership', 'topic modeling', 'hashtag network analysis', '후쿠시마 핵오염수', '소프트 선전', '게이트키핑', '오피니언 리더', '토픽모델링', '네트워크 분석']","본 연구는 2023년 후쿠시마 핵 오염수 방류 사태를 중심으로 중국 웨이보에서형성된 담론 네트워크 내 공식 계정(정부 및 국영 미디어)과 비공식 계정 간의상호작용 및 담론 전략을 분석하였다. 총 259,494건에 달하는 게시글을 기반으로 머신러닝 기법을 활용하여 계정을 자동 분류하고 게이트키퍼 및 오피니언리더를 식별하였으며, 백본 네트워크 추출, LDA 토픽 모델링, 해시태그 공출현 네트워크 분석 등의 방법론을 적용하였다. 연구 결과, 공식 계정은 외교적입장 및 과학적 검증 등 거시적이고 정책 중심적인 프레임을 구축한 반면, 비공식 계정은 감정적 동원과 다양한 이슈 프레이밍을 통해 독자적인 담론 공간을 형성하는 경향을 보였다. 특히 비공식 계정은 해시태그를 활용하여 이질적인 이슈들을 연결함으로써 대안적인 서사를 유연하게 구축하는 특징을 나타냈다. 이러한 연구 결과는 중국의 ‘소프트 선전’ 구조가 완전한 통합에 이르지 못하였으며, 디지털 공간 내 비공식 참여자들이 여전히 상당 수준의 담론 자율성과 영향력을 행사하고 있음을 시사한다.","This study analyzes the interactions and discursive strategies of official accounts (government and state media) and unofficial accounts (individual users and civil society actors) on China’s Weibo platform in the context of the 2023 Fukushima nuclear wastewater release. Based on 259,494 Weibo posts, the study employed machine learning to automatically classify accounts and identify gatekeepers and opinion leaders. Subsequent analyses included backbone network extraction, LDA topic modeling, and hashtag co-occurrence network analysis.The findings reveal that official accounts predominantly constructed macro-level, policy-oriented frames such as diplomacy and scientific verification, whereas unofficial accounts built independent discursive spaces through emotional mobilization and diverse issue framing. Notably, unofficial accounts showed a tendency to connect heterogeneous issues through hashtags, forming alternative narratives. These results suggest that China’s “soft propaganda” strategy has not achieved full integration, and that unofficial actors in digital space continue to exert a certain degree of discursive autonomy and influence."
타액-전립선 연구의 네트워크 분석: 2015-2025년 문헌 동향 및 연구 패턴 계량서지학 분석,2025,"['Saliva', 'Prostate diagnostics', 'Bibliometric analysis', 'Biomarkers', 'Network analysis', 'Clinical translation']",,"Saliva-based diagnostics are crucial for detecting prostate disease without invasion. In this study, a thorough bibliometric analysis of research trends was conducted from 2015 to 2025. In accordance with the PRISMA 2020 guidelines, 458 records were identified through PubMed searches, 158 of which met the inclusion criteria. Scikit-learn, NetworkX, and Pandas with Python 3.8 were used for statistical analysis, network analysis, and visualization, respectively. The research themes were classified into six domains as temporal analysis identified the distinct phases for the research. The exploration from 2015 to 2017, consolidation from 2018 to 2020, and translation from 2021 to 2025 have emerged as the three distinct temporal phases. Research on biomarkers was dominated by 42.3% of the total, followed by stress markers (26.7%), genetic markers (18.3%), and lncRNA research (6.7%). Methodologies have evolved from LC-MS/MS (13.9%) to RNA-seq (10.8%), and the use of machine learning (15.8%) has progressed. Network analysis revealed moderate community organization with modularity of Q=0.62. Knowledge exchange occurred efficiently with a clustering coefficient of 0.68. Geographic distribution was concentrated in China, the USA, and Japan, and the sample sizes ranged from 231 to 300 participants. Saliva-based prostate diagnostics research has progressed in the direction of clinical translation, which advances methodologies and strengthens research community structure. The evolution of the field through distinct phases indicates its readiness for large-scale validation studies. Methodological standardization, expanded disease coverage, and point-of-care platform development have become the key priorities."
Asymmetric State Constraint Based Decentralized Fault Tolerant Control Scheme for Strongly Interconnected Nonlinear SystemsWith Input Saturation,2025,"['Asymmetric state constraint', 'decentralized tracking control', 'fault tolerant control', 'interconnected nonlinear systems.']",,"In this study, a decentralized fault tolerant tracking control strategy is presented for a class of strongly interconnected nonlinear systems with time varying asymmetric state constraints. Firstly, a single hidden layer feedforward network with extreme learning machine (ELM) is applied to approximate the unknown nonlinear function and unknown strongly interconnections. Then, a time varying asymmetric barrier Lyapunov function (TVABLF) is designed to ensure that the time varying asymmetric constraints impose on all the state variables. On this basis, a decentralized fault tolerant tracking control approach is proposed for the considered interconnected nonlinear systems by using backstepping design procedures, and the nonlinear filter with compensation term is introduced to overcome the difficulty of “explosion of complexity”. Meanwhile, an auxiliary dynamical system is designed to solve the problem of input saturation. The asymptotical tracking performance of the system output signals is analyzed by using Lyapunov approach. Finally, the effectiveness of the proposed strategy is illustrated by the practical interconnected nonlinear systems."
Prediction of Pick Acting Forces Using an Random Forest Model based on Mechanical Properties of Rocks and Cutting Parameters,2025,"['Pick cutter', 'Acting forces', 'Cutting parameters', 'Mechanical properties of rock', 'Random forest', '픽 커터', '작용력', '절삭조건', '암석의 역학적 물성', '랜덤포레스트']",,"Rock cutting is a critical process in mining and civil engineering applications, with acting forces of cutting tools playing a pivotal role in determining excavation efficiency, tool wear, and energy consumption. This study presents a comprehensive analysis of predicting mean normal force and mean cutting force using an advanced machine learning approach. The research leverages a robust dataset of 195 experimental samples encompassing diverse rock types, cutting tool geometries, and operational parameters. A two-stage modeling methodology was employed, initially establishing baseline correlations through multivariate linear regression, followed by an optimized Random Forest model with systematic hyperparameter tuning via randomized search cross-validation. The linear regression analysis revealed moderate predictive capabilities, with R² values of 0.743 for FNm and 0.674 for FCm. In contrast, the optimized RF model demonstrated exceptional performance, achieving R² values of 0.993 (training) and 0.983 (testing) for FNm, and 0.972 (training) and 0.908 (testing) for FCm. Feature importance analysis highlighted the dominance of uniaxial compressive strength in predicting normal force, while cutting force prediction demonstrated a more complex interaction of multiple parameters."
Utilizing AI for the Development of Next-Generation Gas Separation Membranes,2025,"['artificial intelligence', 'membrane', 'cooperation', 'future development']",,"Artificial intelligence (AI) is beginning to exert a significant impact on membrane science, offering new approaches for optimizing membrane design and performance. This review highlights recent advances in AI-assisted membrane development, focusing on machine learning (ML) and deep learning (DL) techniques. These tools enable data-driven predictions, improve fabrication processes, and accelerate material discovery. Key challenges such as data quality, model interpretability, and experimental validation are also discussed. This review also outlines future prospects for AI integration, emphasizing its potential to revolutionize membrane technologies in gas separation, clean energy, and environmental applications."
유치원·어린이집 영유아 안전사고 뉴스 보도의 주제 동향 분석: 최근 5년간 주요 언론사 기사 중심으로,2025,"['safety accidents in kindergartens', 'safety accidents in daycare centers', 'news article analysis', 'LDA topic modeling', '유치원 안전사고', '어린이집 안전사고', '뉴스 기사 분석', 'LDA 토픽 모델링']",,"This study aims to analyze the major types of safety accidents involving young children enrolled in kindergartens and daycare centers in South Korea by examining the headlines of 177 news articles reported by nine major domestic media outlets from 2019 to 2024. Utilizing the machine learning functionality of NetMiner 4.5, a LDA(Latent Dirichlet Allocation) topic modeling was conducted, which identified seven key topics. These topics were categorized into four overarching themes: traffic accidents, mass food poisoning incidents, safety education and campaigns, and legal responses. Based on the characteristics of each category, policy implications for the prevention and management of young children's safety accidents were derived. The findings of this study provide valuable foundational data for establishing policies and practical strategies aimed at preventing safety accidents in early childhood settings. Future research should incorporate a broader range of data sources and analytical methods to develop more comprehensive and effective safety measures. Furthermore, this study emphasizes the need to recognize safety of young children not merely as an accident prevention issue but as a fundamental social right, and underscores the importance of fostering a collaborative framework among stakeholders to establish a sustainable culture of safety."
중학생을 대상으로 한 인공지능 기반 생태전환교육 프로그램의 인성역량 함양 효과 검증 연구*,2025,"['artificial intelligence', 'ecological transition education', 'character competency', 'ecological sensitivity', 'middle school students', '인공지능', '생태전환교육', '인성역량', '생태적 감수성', '중학생']","본 연구는 인공지능 기술을 활용한 생태전환교육 프로그램을 개발하고 이를 중학교 현장에 적용하여 학습자의 인성역량, 특히 생태적 감수성에 미 치는 영향을 실증적으로 분석하는 데 목적이 있다. 프로그램은 2022 개정 교육과정에 근거하여 과학, 사회, 기술ㆍ가정 교과 내용을 통합한 11차시로 구성되었으며, 시뮬레이션, 게임 기반 학습, 머신러닝 체험, 감성적 성찰 활 동 등으로 구성되었다. 연구는 경기도 소재 G중학교 3학년 학생 45명을 대 상으로 사전ㆍ사후 검사를 실시하고, 대응표본 t-검정과 심층 면담을 통해 정량 및 정성 분석을 병행하였다.연구 결과, 생태적 감수성의 네 가지 하위 영역(생물 공감, 자연 관심, 자연 향유, 자연에 대한 경이감)에서 모두 통계적으로 유의미한 향상이 나타 났으며, 면담을 통해 학습자들이 감성적 몰입, 생명존중, 환경 민감성, 실천 의지 등 정의적 측면에서 긍정적인 변화를 경험한 것으로 확인되었다. 이러 한 결과는 인공지능이 단순한 기술 도구를 넘어 인성교육의 촉진자이자, 인 간ㆍ자연ㆍ기술의 윤리적 통합을 실현하는 교육 모델로서의 가능성을 지니 고 있음을 시사한다.","This  study  aims  to  develop  an  ecological  transition  education  program utilizing  artificial  intelligence  (AI)  technologies  and  apply  it  in  a  middle  school setting  to  empirically  analyze  its  impact  on  students’  character  competencies, particularly  ecological  sensitivity.  The  program,  based  on  the  2022  revised national  curriculum,  consists  of  11  sessions  integrating  content  from  science, social studies, and technology & home economics. It includes simulations, game-based  learning,  machine  learning  experiences,  and  emotional  reflection activities.  The  study  involved  45  third-grade  students  at  G  Middle  School  in Gyeonggi  Province,  conducting  pre-  and  post-tests  and  using  paired  sample t-tests and in-depth interviews for both quantitative and qualitative analysis.The results revealed statistically significant improvements across four sub-domains of ecological sensitivity—biological empathy, interest in nature, enjoyment of nature, and  awe  toward  nature.  Interviews  further  indicated  that  students  experienced emotional immersion, respect for life, environmental awareness, and a willingness to act, reflecting positive affective changes. These findings suggest that AI can serve not only as a technical tool but also as a facilitator of character education and a model for ethically integrating humanity, nature, and technology in education."
Cross-domain Secure Sharing Algorithm of Internet of Things Privacy Data Based on Artificial Intelligence,2025,"['Artificial intelligence', 'Internet of things', 'Privacy data', 'Data cross-domain', 'Secure sharing']",,"Aiming at the problem of security hidden trouble in the process of sharing Internet of Things privacy data, which is restricted by long-distance and high-speed cross-domain, this paper adopts artificial intelligence technology to study an information security sharing method suitable for the Internet of Things environment. This paper intends to use a parallel deep convolutional neural network based on machine learning to mine the privacy information of IoT (Internet of Things) users and apply it to intelligent data mining. After mining the privacy data of the Internet of Things, the cross-domain security sharing algorithm based on master-slave chain puts forward a cross-domain sharing model framework, designs a cross-domain access mechanism based on smart contracts, and realizes the cross-domain security sharing of privacy data through the cross-domain security sharing scheme of the Internet of Things according to the cross-domain access mechanism. The experimental results show that the average F-measure result of the proposed method in IoT privacy data mining can reach 0.9, and the variance test result is always below 0.17; The throughput is maintained at around 190TPS, storage overhead is reduced by 40%, communication frequency is less than 30 times, encryption and decryption times are 2587s and 3658s respectively, and it has good data security sharing ability."
"데이터 중심 시대, 성공적인 빅데이터 융합인재 양성을 위한 핵심역량 연구",2025,"['Big data technical competencies', 'Digital transformation', 'Technology roadmap']","4차 산업혁명이라 일컬을 만큼 일하는 방식의 근본적인 변화는 기술역량에 대한 관심을 기업과 재직자는 물론, 잡마켓의 미 취업자에게도 불러 일으키고 있다. 이에 본 연구에서는 빅데이터 관련 커리어를 위해 어떠한 기술역량이 필요한지에 대한 기술 로드맵과 방향성을 제시하는 것을 목표로 한다. 연구 방법으로는 현업 재직자(교육과정 수료자 등)를 중심으로 한 설문조사 결 과와 이를 기반으로 한 머신러닝 분석과 시각화 기법을 적용하였다. 연구결과로는 데이터 직무에 필요한 기본 요건사항과 프로 젝트 진행과 취업에 매우 필요한 20여 가지 기술역량을 도출하였고, 또한 연구결과를 기반으로 빅데이터 관련 프로젝트 유형을 카테고리화 하여 시각화 처리하였다. 시사점으로는 빅데이터 융합기술 비즈니스의 성공여부에 있어서도 Web 기술 연계의 중 요성을 확인할 수 있었던 점과 빅데이터 융합 (데이터 연구가, 데이터 사이언티스트 등) 프로젝트와 파이프라인(데이터 엔지니 어 등) 프로젝트는 해당 분야 고도 기술역량 이외에도 경력과 학력(석박사 이상), 기업과 인재간의 로열티 등 다양한 속성이 프 로젝트의 성공 여부에 많은 영향을 미칠 수 있는 만큼 신입보다는 해당 분야의 도메인 지식을 갖춘 재직자 역량이 필요하다는 것을 도출하였다.","The fundamental shift in the way we work, often referred to as the Fourth Industrial Revolution, has ignited a keen interest in tech nical skills among businesses, employees, and even the unemployed job market. This study aims to provide a technology roadmap and direction regarding the essential technical skills required for a career in big data. The research methodology involved a survey of current professionals (including course graduates) and applied statistics-based machine learning and visualization techniques to the results. The research findings identified approximately 20 essential technical skills for data-related jobs, along with the basic requirements for these positions. Furthermore, the research categorized and visualized the types of big data projects. The implica tions of this study include the importance of web technology integration in the success of big data convergence businesses, and the f inding that big data convergence (data researchers, data scientists, etc.) and pipeline (data engineers, etc.) projects require not only advanced technical skills in the respective fields but also experience, higher education (master’s or doctoral degrees), and loyaltybetween the company and the employee. For these reasons, it is concluded that experienced professionals with domain knowledgeare more suitable for these roles than new graduates."
"Delivering on the Promise of Precision Oncology in Prostate Cancer:  Prediagnostic Strategies, Postdiagnostic Applications, and Future  Directions. A Narrative Review",2025,"['Precision oncology', 'Prostate cancer', 'Diagnosis', 'Management']",,"Precision oncology offers a transformative approach to managing localized prostate cancer (PCa) by tailoring interventions to the biological characteristics of the disease. This strategy addresses critical challenges such as overdiagnosis, overtreatment, and the underutilization of advanced diagnostics. Despite the advancements, barriers such as tumor heterogeneity, patient variability, high costs, and limited accessibility impede widespread adoption of new technologies and risk assessment tools. Looking ahead, innovations in biomarker discovery, artificial intelligence, and machine learning hold promise for further refining risk prediction, treatment selection, and active surveillance protocols. By addressing these challenges and advancing precision tools, precision oncology can transform the management of localized PCa, enabling personalized care that minimizes overtreatment while ensuring optimal outcomes."
Dynamic Cues in Vowel Classification: A Discriminant Analysis of Conversational Speech Corpus,2025,"['vowel classification', 'vowel dynamics', 'discriminant analysis', 'conversational speech corpus']",,"This paper asks whether the vowel inherent spectral change (VISC) or the dynamic cues of vowels is an essential feature for vowel classification in natural speech. To answer this question, vowels from the Buckeye Corpus of conversational speech were trained and tested for three models on vowel classification with quadratic discriminant analysis, a machine learning technique. Three models were evaluated: the steady-state model, the one-point model, and two trajectory models, which include the two-point and three-point models. The one-point model samples the spectral features of vowels at one point of vowel duration, while the two-point and three-point models sample the features at two and three points of vowel duration. Various combinations of sampled points and predictors (F0, F1, F2, and F3) were analyzed, and the combinations with the best classification accuracy were compared across the models. The results showed that the steady-state model showed the highest classification accuracy when the spectral features and fundamental frequency were sampled at 50% of vowel duration, while the trajectory models showed the highest classification when sampled at 30% and 70% and 10%, 50%, and 90% for two-point and three-point models, respectively. Classification performance was the highest for all models when all parameters (F0, F1, F2, F3) were included across all models. When compared across the models, the trajectory models perform better than the steady-state model. In addition, vowel duration as a parameter has facilitated the classification accuracy for specific vowels. This paper obtains additional evidence for VISC in vowel classification, including detailed classification results of each vowel, identifying the misclassified vowels, and providing insights for vowel classification models."
Simple-TimeLLM: 거대 언어 모델과 간소화된 양자화를 통한 레일 온도 시계열 예측,2025,"['Rail Temperature Forecasting', 'Large Language Models', 'Time Series Forecasting', 'Quantization', 'Multivariate Time-Series Analysis']",,"Extreme weather events due to climate change are increasing the risk of railway track buckling, which can lead to delays and safety issues such as derailments. Accurate prediction of rail temperature is therefore crucial for safe train operations. While advancements in technology have enabled real-time monitoring of rail temperatures, the current machine learning models used by KORAIL face limitations in accuracy and generalization. This study introduces an innovative method utilizing pre-trained large language models (LLMs) for efficient rail temperature prediction. We employ a simple data mapping technique using binning and normalization to convert time-series data into token sequences suitable for LLMs, allowing training and inference without modifying the model architecture. By applying a non-autoregressive inference approach, we address error accumulation and facilitate faster inference. Our model, trained on five years of data from 200 sensors, outperformed various baseline models achieving an RMSE of 1.8539℃, MAE of 1.0681℃, and  of 0.9794. It also demonstrated strong generalization in zero-shot predictions for sensors not included in training. This approach offers a straightforward and efficient way to apply LLMs to time-series data, contributing to safer railway operations and maintenance planning."
A Real-Time Drinking Water Quality Monitoring Model based on IoT Cloud Platform,2025,"['Real-Time Monitoring', 'Drinking Water Quality', 'Internet of Things', 'Cloud Platform', 'Random Forest', 'Edge Computing.', '실시간 모니터링', '식수 수질', '사물 인터넷', '클라우드 플랫폼', '랜덤 포레스트', '에지 컴퓨팅']",,"Water quality safety is increasingly threatened by industrial pollution and resource scarcity, and traditional monitoring approaches are often inefficient and slow to respond, leading to delayed contamination alerts. In this paper, we propose a real-time drinking water quality monitoring system based on an IoT cloud platform. The proposed technology adopts a multi-layer architecture integrating low-power communication, edge computing, and Docker containerization while employing machine learning algorithms such as Random Forest and Gradient Boosting for feature extraction, data cleaning, and predictive modeling. Experimental results indicate that the RF model achieves an accuracy of 96.0% with only 1.7 seconds of latency, effectively reducing undetected contamination risks while providing broad coverage at reduced costs. Future work will explore unknown contaminant detection, blockchain-based data security, and solar-powered operation for sustainable deployment."
동기 및 위생요인 간 상호작용을 통한 직무 만족의 예측과 설명 : 설명가능한 인공지능(eXplainable AI)을 활용한 탐색적 연구,2025,"['동기-위생 이론', '직무 만족', '설명가능한 인공지능', 'Motivation-Hygeine Theory', 'Job Satisfaction', 'eXplainable AI']","직무 만족은 ‘직무에 대한 복잡한 감정반응’을 반영하는 현상으로, 동기-위생 이론의 관점에서 직무 만족은 다양한 동기 및 위생 요인의 복합적인 작용에 의한 결과물이다(Herzberg, 1959). 다만, 직무 만족의 중요성에도 불구하고 현재까지 다양한 영향요인의 상대적 영향력을 비교하고 결합적인 상호작용 효과를 경험적으로 탐색한 연구는 매우 부족한 실정이다. 본 연구는 동기-위생 이론에 기반하여 직무 만족 현상을 예측하고 설명하기 위한 목적으로 수행되었으며, 이를 위해 자동화 머신러닝과 설명가능한 인공지능 기법을 활용하였다. 분석 결과, 다양한 동기 및 위생 요인이 직무 만족에 영향을 미치며, 특히 인정감과 개인생활 요인의 영향이 강력함을 확인하였다. 또한 변수 상호작용 탐색을 통해 직무 만족에 대한 다양한 유형의 상호작용 효과가 존재함을 발견하였는데, 이때도 특히 인정감과 개인생활 요인의 상호작용이 강력하며 상호작용의 양상은 구체적인 변수 조합에 따라 상이하였다. 본 결과는 노동자의 직무 만족 개선을 위한 개입에서 다양한 동기 및 위생 요인이 총체적으로 고려되어야 하며, 인정감과 개인생활 요인의 충족이 우선시 고려될 필요가 있음을 보여준다.","Job satisfaction is defined as a phenomenon that reflects complex emotional responses to work, and the motivation-hygiene theory suggests that it is caused by a combination of various motivation and hygiene factors(Herzberg, 1959). Despite the importance of job satisfaction, there have been no researches to date that compared the relative influence of various factors and empirically explored their combined effects. This study was conducted to predict and explain the job satisfaction based on motivation-hygiene theory, and to do so, Automated Machine Learning and eXplainable Artificial Intelligence techniques were utilized. The results showed that various motivational and hygiene factors have a complex effect, and among them, recognition and personal life factors have a particularly strong effect. We also found that there are various types of interaction effects on job satisfaction through feature interaction detection, showing that the interaction between recognition and personal life factors is particularly strong and the pattern of interaction varies depending on the specific combination of variables. These results suggest that various motivation and hygiene factors should be considered holistically in interventions to improve workers' job satisfaction and the fulfillment of recognition and personal life factors should be prioritized."
Prediction of Normalized Material Removal Rate Profile Based on Deep Neural Network in Five-Zone Carrier Head CMP System,2025,"['Chemical mechanical planarization (CMP)', 'Multizone carrier head', 'Normalized material removal rate (MRR) profile', 'Deep neural network (DNN)']",,"Chemical mechanical planarization (CMP) is widely used to planarize semiconductor surfaces in semiconductor manufacturing. However, in CMP, which involves various process variables, selecting the process conditions for the planarization of wafers is difficult without experience. Moreover, predicting CMP results depending on the usage time of consumables and various environmental factors is challenging. Therefore, this study attempted to predict the normalized material removal rate profile of a CMP machine with a five-zone carrier head using a deep neural network. Of a total of 80 experimental patterns, 67 were used for learning and 13 were used for validation, and the prediction accuracy was verified using five prediction patterns. In this study, the learning network showed an average prediction accuracy of 97.50% for the five prediction patterns."
판례 데이터 수집 및 전처리를 통한 5대 강력 범죄 관련 판례 데이터 구축,2025,"['판결문', '텍스트 마이닝', '데이터 수집', '문서 분류', '빅데이터', 'Judgments', 'Text mining', 'Data collection', 'Document classification', 'Bigdata']","본 논문은 5대 강력범죄(살인, 강도, 강간강제추행, 절도, 폭력) 관련 판례 데이터를 수집하고, 전처리를 통해 데이터 세트를 구축 하는 과정을 다룬다. 크롤링된 데이터는 항목별로 나누어 별도로 저장하는 과정이 요구되며, 7개의 컬럼으로 구분한다. 구축한 데이터 세트의 유효성을 확인하기 위해 분류 실험을 진행하며, 5대 강력범죄와 관련된 판례만을 선별하고, 각 판례의 8종류의 인덱스를 추가한다. 추가한 인덱스를 종속변수로 수집된 데이터를 독립변수로 하는 분류 모델을 학습하고 예측 정확도를 평가한다. 다양한 머신러닝 모델을 이용해 판례 데이터를 분류하고 성능을 평가한 결과 구축한 판례 데이터에 대한 활용이 유효함을 확인하였다. 이 연구는 범죄와 관련된 데이터 분석의 새로운 접근법을 제시하고, 실질적인 의사결정 지원 도구로서의 가능성을 확인한다.","This paper describes the process of collecting and preprocessing judgment data related to the five major violent crimes (murder, robbery, rape and indecent assault, theft, violence) to construct a dataset. The crawled data were divided into seven columns for separate storage. Each column was further subdivided, and the dataset was initially constructed by splitting all items. These indices were used as dependent variables, and the collected data were used as independent variables to train and evaluate the classification model. Various machine learning models were employed to classify the judgment data and assess performance. This study proposes a new approach to crime-related data analysis and confirms its potential as a practical decision-support tool."
AI와 위성 데이터를 활용한 북한 군 단위 경제 분석,2025,"['AI', 'Satellite Data', 'North Korea', 'North Korean Economy', 'AI', '위성 데이터', '북한', '북한경제']","본 연구는 인공지능(AI)과 위성 데이터를 활용하여 북한의 군 단위 경제 격차를 분석하고, AI 기반 분석 방법론을 북한 연구에 적용하여 새로운 관점을 제시한다. 북한 연구는 자료의 제한성과 현장 접근의 어려움으로 인해 정량적 분석이 어려웠으나, remote sensing data를 활용한 AI 분석을 통해 경제 활동의 공간적 불균형을 간접적으로 파악할 수 있는 가능성이 제시된다. 본 연구는 Google Earth Engine을 통해 북한의 군 단위 데이터를 수집하고, 이를 AI 기반 클러스터링 기법과 머신러닝 회귀 분석을 통해 처리한다. 분석 결과, 북한 내 주요 도시와 농촌 지역 간 경제 활동의 차이가 뚜렷하게 나타났다. 이 연구는 북한 연구에서 AI와 위성 데이터를 활용한 정량적 접근의 중요성을 강조하며, 향후 북한 사회 및 경제 연구에 있어 새로운 방법론적 기여를 제시한다.","This study analyzes economic disparities at the county level in North Korea by leveraging artificial intelligence (AI) and satellite data, introducing a new perspective for North Korean studies through AI-based analytical methodologies. North Korean research has faced challenges in quantitative analysis due to limited data availability and restricted access to field research. However, this study presents the potential to indirectly assess spatial economic inequalities using remote sensing data (nighttime light intensity and building density) through AI-driven analysis. Using Google Earth Engine, county-level data for North Korea was collected and processed through AI-based clustering and machine learning regression analysis. The results reveal significant differences in economic activity between major urban and rural areas within North Korea. This study underscores the importance of quantitative approaches utilizing AI and satellite data in North Korean research and provides a methodological contribution to future studies on North Korean society and economy."
고등학생의 진로적응력 주요 예측변수 탐색: XGBoost 및 SHAP 적용,2025,"['High school students', 'Career Adaptability', 'XBGoost', 'SHAP', 'KCYPS2018', '고등학생', '진로적응력', 'XGBoost', 'SHAP', 'KCYPS2018']","본 연구는 변화에 적응하기 위한 미래 역량인 진로적응력에 주목하여 고등학생의 진로적응력을 예측하는 주요 변수를 탐색하였다. 이를 위해 한국청소년정책연구원의 KCYPS 2018 중1 코호트의 5차년도(2022년) 자료에 예측성과에서 우수하다고 보고된 XGBoost (eXtreme Gradient Boosting)와 설명 가능한 인공지능인 SHAP(SHapley Addictive exPlanations)를 적용하여, 예측 모델을 구축하고 예측변수의 기여도를 평가하였다. 주요 연구 결과는 다음과 같다. 첫째, 고등학생 진로적응력에 XGBoost의 예측성과가 다른 머신러닝 기법과 비교해 상대적으로 좋은 것으로 나타났다. 둘째, SHAP을 통해 예측 기여도가 높은 상위 5%인 변수를 확인한 결과, 학업무기력, 그릿, 부모 양육태도, 교내 공식 동아리 참여 횟수, 친구관계, 주의집중, 스마트폰 의존도, 여가시간(TV 시청, 친구들과 노는 시간), 학업열의, 자아존중감이 주요 예측변수로 도출되었다. 본 연구 결과를 바탕으로 고등학생 진로적응력 함양 방안 모색 및 교육학 분야에서의 머신러닝 및 설명 가능한 인공지능 기법 결합의 적용가능성을 논의하였다.","This study was designed to explore the major predictors of career adaptability in high school students, with the aim of discussing their implications for fostering career readiness. To achieve this, XGBoost, a predictive model with strong performance, was applied to the 5th wave data (11th graders) of the Korean Children & Youth Panel Survey (KCYPS) 2018. Additionally, SHapley Additive exPlanations (SHAP), an explainable artificial intelligence (XAI) technique, was utilized to assess the contribution of major predictors and to explore the relationships between career adaptability and these predictors. The main results are as follows. First, the XGBoost model demonstrated higher predictive performance for high school students' career adaptability compared to other methods. Second, through SHAP analysis, the top 5% of variables with the highest predictive contributions were identified. The key predictors of career adaptability included academic disengagement, grit, parental attitudes, participation in official school clubs, friendship quality, attention span, smartphone dependency, leisure time (watching , time spent with friends), academic enthusiasm, and self-esteem. Based on these findings, implications for enhancing career adaptability among high school students are discussed, along with suggestions for future research directions in the application of machine learning and explainable AI techniques in the field of education."
A Cross-cultural Analysis of Monologues Using Random Forest Classifier,2025,"['Random Forest Classifier', 'monologues', 'syntactic complexity']",,"The objective of this study is to examine how English monologues produced by Asian learners of English vary across different countries. For the analysis of the differences across countries, this study investigated whether the monologues of learners from each country exhibit characteristics of essays or dialogues regarding syntactic complexity. To determine whether the monologues are closer to essays or dialogues, a supervised machine learning technique, specifically the Random Forest Classifier, was employed and the essay and dialogue data from the International Corpus Network of Asian Learners of English were used to train the model. The Random Forest Classifier was trained to classify monologues into essays and dialogues on the basis of syntactic complexity indices. After the trained model sorted the monologues from each country into essays and dialogues, the countries were grouped based on the counts of essays and dialogues. For further analysis, Euclidean distance was utilized to identify the country whose monologues’ syntactic complexity most closely resembles that observed in Korea’s monologues, as well as the country whose monologues’ syntactic complexity most closely matches that observed in English-speaking countries’ monologues. The results demonstrated that (i) Hong Kong, the Philippines, Singapore, and the set of English-speaking countries were assigned to a group with a higher count of essays, while China, Indonesia, Japan, Korea, Pakistan, Taiwan, and Thailand were assigned to a group with a higher count of dialogues; (ii) Thailand’s monologues are most similar to those of Korea; (iii) Singapore’s monologues are most similar to those of English-speaking countries."
The Development of a Real-Time Disease Prediction Model through Big Data-based Analysis of Crop-Pathogen-Environment Interactions,2025,"['빅데이터', '유전체학', '기상변화', '실시간 예측', '작물병', 'Big Data', 'Genomics', 'Climate Change', 'Real-Time Prediction', 'Crop Diseases']",,"This paper presents a method for developing a real-time disease prediction model for major economic crops using big data analytics. By integrating genomic and phenomics data with climate change variables, we analyzed the interactions between crops, pathogens, and environmental factors. A comprehensive disease prediction system was established based on this analysis. Various machine learning algorithms were employed to ensure effective feature selection and analysis, considering both temporal and spatial factors. This research not only focuses on developing the predictive model but also emphasizes its practical applications and challenges in real-world agricultural settings. With climate change posing increasing threats to food security, the relevance of such predictive systems is becoming ever more crucial."
Bibliometrix 패키지를 활용한 인공지능 융합 과학교육의  연구동향 분석: 국제저명학술지를 중심으로,2025,"['AI 융합 교육', 'AI 융합 과학교육', '연구동향 분석', 'AI 융합 과학교육', 'AI 교육', 'AI-Integrated Education', 'AI-Integrated Science Education', 'Research Trend Analysis', 'AI-Integrated Science Education Research', 'AI Education']","목적  본 연구는 국제저명학술지에 게재된 인공지능 융합 과학교육 연구의 동향을 분석하여, 국내 AI 융합 과학교육 연구의 방향성에대한 시사점을 제시하는 것을 목적으로 한다.방법  이를 위하여 WoS 데이터베이스에서 AI와 과학교육 관련 논문을 수집하고, 데이터 전처리 과정을 통해 55개의 문헌을 연구대상으로 설정하여 R의 bibliometrix 패키지를 활용해 상세서지분석을 실시하였다.결과  AI 융합 과학교육 연구는 국내외 모두 2022년 이후 급격히 증가했으며, 주요 연구 주제로 생성형 AI, 머신러닝, 학습 평가, 교사교육 등이 부각되었다. 그러나 국내 연구는 실천적 연구가 중심인 반면 비판적 사고력과 같은 AI 윤리 및 데이터 분석 연구는미흡한 것으로 나타났다.결론  국내 AI 융합 과학교육 연구는 데이터 기반 연구와 AI 윤리 연구를 강화하고, 교사 연수 및 AI 교육 환경 개선을 통해 보다 체계적이고 실천적이며 윤리적인 방향으로 발전해야 한다.","Objectives  This study aims to analyze the trends of artificial intelligence (AI)-integrated science education re search published in SCI and ESCI-indexed journals and to provide implications for the direction of AI-integrated science education research in South Korea.Methods  For this purpose, research articles related to AI and science education were collected from the Web of Science (WoS) database. After a data preprocessing process, 55 studies were selected for analysis. A detailed bib liometric analysis was conducted using the bibliometrix package in R.Results  The study found that AI-integrated science education research has surged globally and domestically since 2022. Key research topics include generative AI, machine learning, learning assessment, and teacher education.However, while domestic studies predominantly focus on practical research, they lack sufficient attention to AI ethics and data analysis, particularly in areas such as critical thinking.Conclusions  To advance AI-integrated science education research in South Korea, it is necessary to strengthen data-driven research and AI ethics studies. Additionally, efforts should be made to enhance teacher training pro grams and improve AI education environments, ensuring a more systematic, practical, and ethical approach to AI-integrated science education."
ESG Controversies and Firm Value: Moderating Role of ESG Performance,2025,"['ESG controversies', 'Firm value', 'ESG performance', 'Insurance mechanism', 'Stake holder theory']",,"This study investigates the impact of a firm's environmental, social, and governance (ESG) controversies on its value and examines the moderating role of ESG initiatives in mitigating this impact. It further explores how this moderating effect varies based on factors such as reputational risk, external monitoring, agency motivations, and the recurrence of controversies. Using a novel machine learning approach, this study measures ESG controversies among publicly traded Korean firms by analyzing over 20 million news articles from major Korean media outlets. The findings indicate that ESG controversies negatively affect firm value, but this adverse impact is mitigated by stronger ESG performance, underscoring the insurance‐like role of ESG. The moderating effect is particularly significant for firms facing high reputation risk, greater external monitoring, or with ESG activities that are less likely to be driven by agency motives. Moreover, non‐repetitive ESG controversies exert a more substantial negative effect on firm value compared to repetitive ones, highlighting the crucial role of ESG in these situations. Consistent results are observed using short‐term firm value measures, such as cumulative abnormal returns surrounding the release of ESG controversy news. Overall, this study contributes to the ESG literature by demonstrating that ESG can provide shareholders with an insurance‐like benefit, supporting stakeholder theory."
AI-Based UX Design Research for Mitigating Psychological Barriers in Early Autonomous Vehicle Users,2025,"['AI-based UX design', 'Autonomous vehicle onboarding', 'Reducing psychological barriers UX design', 'Gamification participatory education', 'Autonomous vehicle UX design', 'Face tracking and vibration feedback', 'Enhancing accessibility to autonomous driving']",,"AI-Based UX Design for Mitigating Psychological Barriers in Early Autonomous Vehicle Users This study proposes a UX strategy that applies AI-driven affective UX and fatigue management systems to alleviate psychological anxiety and build trust among early autonomous vehicle users. A preliminary survey, in-depth interviews, and virtual interaction tests were conducted with 30 elderly drivers and individuals with disabilities to evaluate the effectiveness of human-machine interface (HMI) design and personalized feedback systems. The findings indicate that implementing AI-based affective UX increased user trust by 35% and reduced psychological anxiety by 27%. Notably, the affective stability UI within the HMI played a crucial role in enhancing user trust during initial adoption. Based on these insights, this study proposes an onboarding process and participatory education program as key UX design strategies. The onboarding process consists of information provision, safety emphasis, real-time feedback, affective stability support, and drowsiness prevention system integration. The AI system continuously learns from the driver's responses to provide personalized feedback. The participatory education program comprises theoretical and practical training. The theoretical component covers technical principles, safety measures, and psychological reassurance, while the practical training includes experiential onboarding, VR-based simulations, and real-time feedback systems to enhance user adaptation. This study experimentally demonstrates that user-centered UX design can improve trust and acceptance of autonomous driving technology. The findings provide a foundational direction for future AI-based interface design improvements and the development of personalized UX systems."
Development of Battery Management System with PCM using Neural Network Based Aging Algorithm for Electric Vehicle,2025,"['Battery thermal management', 'Electric vehicle', 'Phase change material', 'Long Short Memory Model', 'Random Forest method', 'Prediction of battery temperature']",,"The increase in battery temperatures results in the critical risks, including explosions, therefore need of efficient thermal management is increasing. In this point of view, we proposed a novel approach to battery thermal control, employing hot soaking and cold soaking experiments for the first time to identify phase change materials (PCMs) that enhance battery safety under temperature conditions. Machine learning methods such as Llng short-term memory (LSTM) and random forest (RF) models were applied and thermal performance was investigated in lithium polymer pouch batteries integrated with PCMs for fast and accurate prediction. Experiments were conducted at normal temperature of 25◦C, hot temperature of 50◦C, and cold temperature of −10◦C. Thermal performance metrics such as maximum temperature and thermal gradient ∆T were measured during discharge of the battery. In this study we selected PCMs such as RT15, RT31, EG5, EG26, and EG28 to evaluate the performance with LSTM and RF are applied to predict temperature variations influencing thermal behavior. Results indicated that EG26 and EG28 PCMs, significantly improved thermal performance under extreme conditions. The LSTM model demonstrated high predictive accuracy of 99% compared to RF model with 97%. This integrated model approach provided both high predictive accuracy and valuable insights into battery thermal performance, underscoring the importance of PCM selection to ensure battery longevity and stability across diverse environments."
Developing a 2D position-sensitive detector utilizing the large plate plastic scintillator,2025,"['Position-sensitive detector', 'Plastic scintillator', 'Geant4', 'Artificial neural networks', 'Light scintillation']",,"This study introduces a novel position-sensitive detector based on plate-shaped plastic scintillator. The detector, consisting of a 50 × 5 × 50 cm plastic scintillator coupled to four photomultiplier tubes, was designed to pinpoint the 2D location of a137Cs γ-ray source. A mathematical model was developed to predict the source position based on the ratio of signals from the photomultiplier tubes. Additionally, a machine learning approach using a Multi- Layer Perceptron (MLP) was employed for more automated position prediction. Based on the obtained results, it was found that the mean absolute error for determining the 2D position of the source was 1.3 cm for the mathematical model and 0.5 cm for the trained MLP model. To validate this model, optical simulations were also conducted using the Geant4 Monte Carlo toolkit."
Detecting Fake News with Large Language Models:  A Systematic Literature Review,2025,"['Large Language Models (LLMs)', 'Fake News Detection', 'Systematic Literature Review (SLR)', 'Data Augmentation', 'Sentiment Analysis']",,"The widespread dissemination of fake news poses significant societal challenges, undermining public trust and affecting democratic processes. Recent advancements in artificial intelligence, particularly Large Language Models (LLMs) like GPT-3.5 and GPT-4, have shown great potential in addressing this issue. This systematic literature review examines 29 research papers from the SCOPUS database to explore how LLMs enhance fake news detection, specifically focusing on classification tasks, data augmentation, and sentiment analysis. The findings reveal that hybrid models integrating LLMs with traditional machine learning algorithms significantly improve accuracy and performance metrics. Additionally, LLM-based data augmentation effectively tackles data imbalance, further improving detection capabilities. Sentiment analysis also proves beneficial, enabling LLMs to neutralize emotionally manipulative content. The study concludes that LLMs substantially enhance fake news detection performance and highlights future research directions, including multimodal detection, real-time detection capabilities, and expanding studies to non-English contexts."
해양 기상을 활용한 해상조난사고 예측 모델링,2025,"['로지스틱 회귀분석', '부스팅', '해상조난사고', '해양 기상', 'Boosting', 'logistic regression', 'maritime distress accident', 'ocean weather']","해상에서 사람 및 선박 운용과 관련된 조난사고는 인명, 경제, 환경 등 다양한 측면에서 피해를 초래하기에 이를 예방하고자 해양 기상과 같은 환경적 원인의 분석이 중요하다. 본 연구는 해양 기상의 영향을 고려하여 해상조난사고 발생을 예측하고, 주요 기상 요소를 규명하는 데 목적이 있다. 이를 위해 2019년부터 2023년까지 발생한 해상조난사고 데이터를 수집하고, 시간별 해상 상황을 관측한 해양기상부이 데이터를 활용하여 시공간적으로 가장 인접한 데이터를 결합하였다. 또한, 요일과 3시간 단위 시간대에 따른 사고 발생 편향을 보정하기 위해 성향점수 매칭을 적용했다. 예측 모델은 로지스틱 회귀분석과 XGB (extreme gradient boosting), GBM (gradient boosting machine), LGB (light gradient boosting)와 같은 부스팅 계열 기계학습 기법을 활용하였으며, 분석 결과, XGB, GBM, LGB, 로지스틱 회귀분석 순으로 예측 성능이 우수함을 확인했다. 주요 기상 요소는 로지스틱 회귀분석에서 현지기압과 습도로 나타났으며, XGB, GBM, LGB에서는 수온, 파주기, 기온, 습도가 모두 포함되었다.","Maritime distress involving human safety and vessel operations results in various damage, including loss of life, economic losses, and environmental harm. Therefore, analyzing environmental factors that contribute to maritime distress accidents is imperative. This study aims to predict the occurrence of maritime distress by considering the influence of oceanic meteorology and to identify the key meteorological variables. To achieve this, we collected maritime disaster accident data from 2019 to 2023 and integrated the most temporally and spatially close data utilizing hourly oceanic meteorology buoy data. Additionally, to correct potential biases in accident occurrences due to the day of the week and 3-hour intervals, one-to-one propensity score matching was applied. The prediction models used logistic regression and boosting-based machine learning techniques (GBM, XGB, LGB). The results indicated that XGB, GBM, and LGB outperformed logistic regression in predictive accuracy. Key variables in logistic regression were pressure and humidity, while XGB, GBM, and LGB identified water temperature, wave period, temperature, and humidity were all key variables. This study improves the accuracy of maritime distress accident predictions using oceanic meteorological data and aids in establishing effective accident prevention and response strategies."
IoT sensor‑based systems in real‑time monitoring of health  and environment: a review,2025,['Internet of Things · IoT sensors · IoT healthcare sensors · IoT environment monitoring sensors · IoT water quality monitoring sensors · IoT air quality monitoring sensors'],,"Over the past few years, Internet of Things (IoT) has surfaced as an effective technology which helps in interconnecting objects and computing devices together. Enormous potential of IoT has helped in providing more convenient and high-quality services for many day-to-day applications. Tangible objects can be connected to internet through IoT which enables rapid reception and transmission of data. Significant advancement of IoT technology further helps in connecting different smart objects via internet as well as facilitates in providing better methods for data interoperability. In many large-scale applica tions like healthcare monitoring, environment monitoring, smart agriculture, smart cities, smart grids, smart factories etc., IoT is playing a significant role. Machine learning, embedded systems, real-time analytics and sensors have influenced the concept of IoT. IoT sensors help in providing improved communication without the necessity for human-to-human and human-to-computer interface. This article critically analyzes various IoT sensor-based systems used in medical surveillance and in monitoring of air and water quality. The article reviews the state-of-the-art developments, real word application, and key technologies in these domains. The performance of various IoT sensor-driven systems used for monitoring in real time were also meticulously studied."
라이프로그 데이터의 신뢰성 확보를 위한  베이지안 신경망 기반 결측치 처리 방안 연구,2025,"[': Missing-Data Imputation', 'Bayesian Neural Network', 'Uncertainty Estimation', 'Transformer', 'Healthcare']",,"Methods: Heart-rate measurements were collected from nine participants over 3 months using commercial smart watches. After conducting sliding-window segmentation and min-max scaling, seven imputation methods were evaluated across missing rates of 5%, 10%, 15%, and 20%.These included three traditional statistical methods (mean, median, and mode), Multi-Layer Perceptron models in deterministic and Bayesian forms, and a Transformer-based Self-Attention Imputation for Time Series (SAITS) model in deterministic and Bayesian (Monte Carlo dropout) variants. Model performance was evaluated using RMSE, MAE, and MAPE.Results: The conventional statistical approaches resulted in higher errors, highlighting their limitations in capturing complex temporal patterns with simple point estimators. Conversely, machine learning models significantly reduced errors, and SAITS frequently surpassed other methods. The Bayesian framework did not consistently outperform deterministic models in point-estimation accuracy, but it provided valuable uncertainty quantification, particularly in regions with abrupt heart-rate fluctuations.Conclusion: These findings suggest that incorporating Bayesian principles enhances imputation reliability while offering critical uncertainty estimates. This is particularly advantageous in healthcare contexts, where inaccurate predictions can lead to clinical risks."
자연어처리(NLP) 기반 텍스트 마이닝을 활용한 스타트업 경영성과 연구동향 분석 : RISS DB 중심으로,2025,"['스타트업', '경영성과', '텍스트마이닝', '자연어처리', 'NLP', '연구동향분석', 'RISS', 'Startup', 'Business Performance', 'Text Mining', 'Natural Language Processing', 'NLP', 'Research Trend Analysis', 'RISS']","본 연구는 자연어 처리(NLP) 기반 텍스트 마이닝 기법을 활용하여 스타트업 경영성과에 대한 국내연구 동향을 체계적으로 분석하는 것을 목적으로 한다. 한국교육학술정보원(RISS)에서 ‘스타트업 경영성과’, ‘스타트업 경영’을 키워드로, 전 기간의 초록을 웹 크롤링하여 수집하였으며 최종 323편의 문헌이 분석에 활용되었다. 분석과정에서 형태소분석, 단어빈도분석(TF), 역문서 빈도분석(TF-IDF), N-gram 분석, 네트워크 분석, CONCOR 기법이 적용되었다. 분석결과, ‘창업’, ‘규제’, ‘영향’, ‘혁신’, ‘기술’과 같은 키워드가 핵심 주제로 도출되었으며, 자금 조달, 기술 혁신, 정책 지원, 기업가 정신이 주 연구 분야로 확인되었다. 키워드 간 구조적 연관성을 파악하였으며 7개의 군집을 도출하였다. 본 연구는 데이터 기반 분석을 통해 기존 문헌과의 차별성을 제시하였다. 향후 연구에서는 시계열 분석, 해외연구 동향분석, 머신러닝 기법을 활용한 연구가 필요할 것이다.","This study aims to systematically analyze domestic research trends on startup business performance using text mining techniques based on natural language processing (NLP). Abstracts were collected through web crawling from the RISS (Korea Education and Research Information Sharing Service) database using the keywords “startup business performance” and “startup management” across all available years, resulting in a final dataset of 323 academic papers. During the analysis process, various methods were applied, including morphological analysis, term frequency (TF), term frequency–inverse document frequency (TF-IDF), N-gram analysis, network analysis, and CONCOR clustering. The analysis revealed that core keywords such as “entrepreneurship,” “regulation”, “impact”, “innovation”, and “technology” emerged as central themes. Major research areas included funding, technological innovation, policy support, and entrepreneurship. Furthermore, the structural relationships among keywords were identified, and seven clusters were derived. This study contributes to the literature by offering a data-driven perspective that distinguishes itself from prior qualitative research. Future studies should consider time-series analysis, comparative analysis of international research trends, and the application of machine learning techniques."
Analysis on Underwater Channel by Using Shapley Additive Explanations,2025,"['Underwater Communication', 'XAI', 'SHapley Additive exPlantaions', 'Feature Selection']",,"This study explores the limitations of relying solely on Signal-to-Noise Ratio (SNR) for Bit Error Rate (BER) prediction in underwater communication environments and underscores the critical role of eXplainable Artificial Intelligence (XAI). By employing SHapley Additive exPlanations (SHAP), the relationship between SNR and BER is thoroughly analyzed, highlighting the inadequacies of SNR as the sole predictive feature. To address these challenges, SHAP-based feature selection is utilized to identify key factors, which are subsequently employed to train machine learning models. The results demonstrate a marked improvement in prediction accuracy over traditional methods, affirming that the integration of SHAP-driven feature selection significantly enhances model performance."
과수 생장정보와 기상정보를 이용한 ‘신고’ 배나무의 수액 흐름 예측 모형 개발,2025,"['신고', '수액 흐름', '시민박명시간', 'Shingo pear', 'Sap-flow', 'Civil twilight hours', 'DAFB', 'CNN-GRU-BiLSTM']","나무의 생장을 이해하기 위해서는 수액 흐름을 알아야 한다. 그러나 모든 농가에서 수액 흐름을 측정하는 것은 현실적으로 어렵다. 따라서 수액 흐름을 예측하고자 하는 많은 연구들이 있었지만 대부분 기상정보 외에도 구하기 어려운 정보를 이용한 연구가 많았다. 본 연구에서는 농가에서 구하기 쉬운 기상 변수, 시민박명시간을 이용한 변수와 DAFB(Days After Full Bloom)만을 이용하여 ‘신고’ 배나무의 수액 흐름을 예측하는 모형을 제안하고자 한다. 또한 비선형관계인 수액 흐름과 기상 변수간의 시간 지연 효과를 고려하기 위해 시차별 스피어만 상관 분석을 실시하였고 일사량의 경우 4시차 전의 계수가 최대 계수임이 나타났다. 수액 흐름 예측 모형으로는 머신러닝 모형인 Random Froest, XGBoost를 사용하였고 딥러닝 모형인 LSTM, GRU, BiLSTM, CNN-GRU-BiLSTM 모형을 사용하여 수액 흐름을 예측하였다. 그 결과, 모든 모형에서 R² 값이 0.94 이상으로 나타나 본 연구에서 제안한 변수만을 이용하여 수액 흐름을 예측하는 것이 가능하다는 것을 보여주었다. 특히 CNN-GRU-BiLSTM 모형이 MAE 225.4, RMSE 427.6, R² 0.9550으로 가장 좋은 성능을 보였으며 우리나라와 같이 계절성을 가지며 국지적 기후 현상이 자주 발생하는 환경에서 CNN-GRU-BiLSTM 모형이 수액 흐름 예측에 적합하다고 판단하였으며 이를 통해 우리나라 농가에 데이터에 기반한 관수 기준을 제시할 수 있을 것으로 기대한다.","Understanding sap flow is crucial for comprehending tree growth. However, it is impractical for all farms to directly measure sap flow. Although many studies have attempted to predict sap flow, most of them have relied on hard-to-obtain data in addition to weather information. This study aims to propose a model for predicting sap flow in ‘Shingo’ pear trees using only easily accessible weather variables, civil twilight time, and DAFB (Days After Full Bloom). Additionally, to account for the time-lag effect in the nonlinear relationship between sap flow and weather variables, we performed lagged Spearman correlation analysis. For solar radiation, the correlation coefficient was found to peak at a 4-hour lag. For the sap flow prediction model, we used machine learning models such as Random Forest and XGBoost, as well as deep learning models including LSTM, GRU, BiLSTM, and a hybrid CNN-GRU-BiLSTM model. All models achieved R² values above 0.94, demonstrating that sap flow prediction is feasible using only the proposed variables. In particular, the CNN-GRU-BiLSTM model performed the best with an MAE of 225.4, RMSE of 427.6, and R² of 0.9550. We concluded that the CNN-GRU-BiLSTM model is well-suited for predicting sap flow in environments with seasonal and localized climate phenomena, such as in South Korea. Through this, we expect to provide a data-driven irrigation standard to farms across the country."
설명 가능한 인공지능 기반의 설계인자별 진동 특성 분석을 통한 차량 시트벨트 BSR 소음 발생예측,2025,"['시트벨트 리트랙터', '진동', '설명 가능한 인공지능', '섀플리 가산 설명기법', 'Seatbelt Retractor', 'Vibration', 'Explainable Artificial Intelligence', 'Shapley Additive Explanations']",,"This study proposes an eXplainable AI (XAI)-based vibration evaluation method to assess the buzz, squeak, and rattle (BSR) performance of vehicle seatbelt retractors, focusing on noise-induced anomalies. The proposed method enables the prediction of vibration characteristics from seatbelt retractor design parameters, enabling the pre-screening of potential BSR noise occurrence at the design stage. Compliance measurements were collected from 15 different vehicles, and vibration evaluation indicators (i.e., system stiffness and Q-factor) were derived to quantify dynamic response characteristics related to BSR noise. These indicators serve as key metrics for BSR-related performance evaluation, enabling defect identification based on predefined thresholds. Furthermore, an XAI-integrated machine learning model was developed to predict the system stiffness and Q-factor directly from seatbelt retractor design parameters. The predicted indicators were validated against experimental thresholds, and the Shapley additive explanations algorithm was employed to analyze the influence of design parameters on noise-induced vibration performance. By leveraging the XAI approach with the compliance data from multiple vehicle models, this paper presents a systematic methodology for BSR-focused vibration analysis and quality control of seatbelt retractors. The proposed approach enables manufacturers to predict vibration characteristics without direct measurement, enabling earlier detection of potential BSR issues and reducing reliance on costly experimental testing while ensuring product reliability."
IDLRN-DBN: SEGMENTATION-BASED EARLY DIAGNOSIS OF RICE PLANT DISEASE DETECTION USING DEEP BELIEF NETWORK,2025,"['Rice Plant Disease', 'Deep Belief Network', 'ResNet 101 V2', 'Median-Modified Wiener Filter', 'and Lyrebat Algorithm']",,"Agriculture remains the basis of the Indian economy, with rice being a pivotal crop. However, rice cultivation faces significant challenges from various plant diseases, leading to substantial agricultural losses. The advanced segmentation-based Deep Belief Network (DBN) model iDLRN-DBN is proposed to meet the need for early and precise diagnosis of rice plant diseases and addresses the critical challenge of agricultural losses caused by plant diseases in India. The methodology is further improved upon as compared with the traditional methods by the addition of deep learning (DL), along with being supported by machine learning (ML) techniques. The six critical phases are comprised of the iDLRN-DBN model: image acquisition from a Kaggle dataset, pre-processing using adaptive filters, image segmentation through an enhanced DeepLabV3+ model, feature extraction through Efficient Grey Level Cooccurrence Matrix and Haralick Texture Features, a hybrid optimization model known as the Lyrebat Algorithm for optimal feature selection, and the classification of disease through a DBN. The iDLRN-DBN model reduced the false negative rate to 0.0257, the false positive rate to 0.0245, precision was boosted by 0.0050, and the negative predictive value increased by 0.0926. This model showed high accuracy at 0.9762, F1 score at 0.9860, low FNR at 0.0250, and a high NPV at 0.8676, which implies it is useful in conducting timely interventions and efficient crop management in smart farming. This research contributes to the progress of agricultural technology and food security due to the integration of techniques in ML and DL into the diagnostics of rice plant diseases."
Reducing E2E Delay in Wireless Multi-Hop Networks: A Multi-Agent DRL-Based Approach,2025,"['Wireless multi-hop networks', 'Bio-inspired', 'DESYNC', 'MH-DYSYNC', 'Multi-agent DRL', 'E2E delay']",,"Recently, bio-inspired algorithms have gained popularity among researchers due to their capability to handle complex optimization problems in a distributed manner by imitating natural processes of the living organisms on earth. In previous studies, two bio-inspired algorithms called desynchronization (DESYNC) and multi-hop DESYNC (MH-DESYNC) have been proposed to improve the throughput in wireless networks in a distributed way. These decentralized algorithms have shown promise for scalability and adaptability, making them suitable for real-world applications. Although the MH-DESYNC has effectively improved the throughput of the wireless multi-hop networks, it still faces the problem of end-to-end (E2E) delay. In this work, we aim to fill the gap of our previous study (MH-DESYNC algorithm) by using machine learning (ML). We propose a design of decentralized multi-agent deep reinforcement learning (DRL), a type of ML algorithm, incorporated with MH-DESYNC for improving not only the throughput but also the E2E delay in wireless multi-hop networks. To evaluate our proposed method, we compare it with the multi-agent DRL (MA-DRL), the MH-DESYNC, and expected E2E delay (EED) by performing under the simulation of multiple routing paths in wireless multi-hop networks. The training result shows that our proposed method converges faster with low fluctuation compared to the MA-DRL method. Additionally, our proposed method outperforms the MA-DRL, the MH-DESYNC, and EED methods for both E2E delay and throughput performances."
특성 자료를 활용한 한반도 동남권 지역의 최대지반가속도 예측 연구,2025,"['Earthquake early warning', 'On-site earthquake warning', 'Characteristic data', 'Peak Ground Acceleration (PGA)']",,"Early warnings have been developed to provide rapid earthquake information, allowing people to prepare as much time as possible.However, since it takes several seconds for an earthquake warning to be issued, the blind zone is inevitable. To reduce the blind zone, information from a single observatory is used to operate an on-site earthquake warning. However, false and missed alarms are still high, requiring continued research and validation. This study predicted Peak Ground Acceleration (PGA) using the characteristic data to reduce false and missed alarms in on-site earthquake warnings. A machine learning prediction model was created using the initial P-wave parameters developed from the characteristic data to achieve this. Then, the model was used to predict the maximum ground acceleration in the southeastern region of the Korean Peninsula. The expected results for six target earthquakes were confirmed to have a standard deviation within 0.3 compared to the observed PGA and the values within ±2 sigma. This method is expected to help develop an on-site early warning system for earthquakes."
디지털병리의 인프라와 인공지능 및 임상적 영향에  대한 진화,2025,"['Digital pathology', 'Whole-slide image', 'Artificial intelligence', 'Foundation model', 'Computational pathology', '디지털병리', '전체슬라이드영상', '인공지능', '파운데이션 모델', '전산병리학']",,"Digital pathology has rapidly evolved from a technical innovation to a foundational component of modern diagnostic practice. The digitization of histologic and cytologic slides through whole-slide imaging has enabled remote interpretation, streamlined workflows, and unprecedented opportunities for computational analysis. This review explores the current landscape of digital pathology, examining the integration of imaging platforms, workflow automation systems, tiered data storage, and emerging cloud infrastructure. Particular attention is given to the convergence between digital pathology and artificial intelligence (AI), focusing on the transition from traditional machine learning and weakly supervised methods to more recent advances in multimodal foundation models and generative AI. These state-of-the-art systems offer enhanced capabilities in image understanding, diagnostic assistance, prognostic prediction, and decision support. Rather than replacing expert judgment, AI is increasingly positioned to augment the interpretive work of the pathologist, a concept aligned with augmented intelligence. In addition to technical advances, this review addresses critical challenges surrounding data governance, regulatory frameworks, algorithmic transparency, and equitable clinical deployment. The utility of AI in thyroid pathology is presented as a representative use case, illustrating both the potential and limitations of real-world implementation. As digital pathology continues to mature, its successful integration into routine clinical workflows will require technological innovation, interdisciplinary collaboration, ethical oversight, and evidence- based validation to ensure safe, sustainable, and impactful use in contemporary medicine."
"차세대 패키징에서의 워피지: 이종집적을 위한 도전 과제, 측정 기법 및 저감 전략",2025,"['.', 'Advanced packaging', 'Warpage', 'Si-bridge', '2.5D packaging', '3D integration', 'Warpage measurement']",,"As semiconductor technology moves beyond Moore’s Law, heterogeneous integration packaging has become pivotal for high-performance, miniaturized devices. Advanced packaging techniques—including 2.5D/3D integration, fan-out wafer-level packaging, and Si-bridge interconnects— significantly improve functionality by integrating multiple dies in one package. However, warpage has emerged as a critical thermomechanical challenge, causing misalignment, yield loss, and interconnect failures. Accurate warpage measurement and characterization methods are vital for mitigating these issues. Both experimental and simulation approaches assess warpage under various structures and process conditions. Research reveals warpage behaviors in wafer-level, panel-level, and Si-bridge-based packages, emphasizing strategies like material selection, structural design, and process optimization to reduce deformation. Emerging solutions—such as machine learning, realtime monitoring, and adaptive process control—aim to further enhance warpage management, improving manufacturability and reliability. By consolidating recent findings and identifying remaining challenges, this review offers insights into future directions for effective warpage reduction in advanced semiconductor packaging."
ChatGPT的安全风险及其法律对策,2025,"['ChatGPT', 'generative artificial intelligence', 'a holistic approach to national security', 'adversarial risk', 'legal countermeasures', 'ChatGP', '생성형 인공지능', '종합적 국가안보 관점', '적대적 공격(Adversarial Attack) 리스크', '법적 대응 방안', 'ChatGPT，生成式人工智能，总体国家安全观，对抗性风险，法律对策']",,"The swift progress of artificial intelligence has ushered in an exciting new era of technological revolution. Innovations in this field are transforming industries, enhancing our daily lives, and reshaping how we interact with technology. ChatGPT, as a landmark application of generative artificial intelligence, has caused a disruptive change to the Internet ecosystem and human-computer interaction mode with its excellent natural language processing technology. From an overarching perspective on national security, ChatGPT utilizes high-quality, accurate data and innovative machine learning algorithms, posing challenges in safeguarding the rights of individuals and presenting security risks across political and economic domains. From an overarching perspective on national security, Supported by high-quality, accurate data and innovative algorithms based on human feedback and reinforcement learning,  ChatGPT understands the user's linguistic preferences, and its conversational interactions with humans gradually produce “human-like features.” ChatGPT not only has the function of storing historical conversations but also can expand and deepen new conversations with users based on the understanding of historical conversations. ChatGPT, while dramatically increasing its utility, also poses resistance to protecting the rights of natural persons and security risks in the political and economic spheres.In this paper, we provide a detailed overview of the key features of ChatGPT, focusing on its underlying working principles. Following this, we will conduct an in-depth analysis of the potential risks associated with its use, examining the implications for individual security, political stability, and economic well-being. At the level of personal security, potential issues include the plagiarism of results during the data collection stage and the risk of data leakage during data storage. Regarding political security, there is a risk that it may serve as a tool for intelligence gathering and the export of values from technologically advanced countries to those less advanced, thereby increasing the likelihood of technology companies sharing governmental governance powers. Regarding economic security, the adversarial risks associated with algorithm applications may hinder fair market competition. The capability of ChatGPT to execute mechanically repetitive and highly structured tasks during the algorithm rollout phase raises concerns about job displacement and employment pressures. To mitigate these security risks associated with ChatGPT, it is essential to establish robust data processing norms in the information retrieval domain, strengthen oversight of extreme speech on the Internet, refine self-inspection protocols for enterprises, and anticipate the extent of labor market displacement. These measures promote a unified strategy for protecting individual security, maintaining political stability, ensuring economic integrity, and safeguarding national interests, contributing Chinese wisdom to exploring the balance between the development of the AI industry and safety."
Precision medicine: a review of the impact of three-dimensional laser scanning over the past decade,2025,"['Diagnostic imaging', 'Computer-assisted three-dimensional imaging', 'Multimodal imaging']",,"Three-dimensional (3D) laser scanning has revolutionized precision medicine by enabling non-invasive, highresolution digital modeling of anatomical structures. Over the past decade, advancements in hardware and software have led to its widespread adoption across multiple medical disciplines, including maxillofacial surgery, neurosurgery, dentistry, plastic and reconstructive surgery, and forensic science. This technology enhances diagnostic accuracy, facilitates patient-specific treatment planning, and improves surgical outcomes by enabling precise preoperative simulations and postoperative evaluations. In maxillofacial and orthopedic procedures, 3D laser scanning allows for virtual surgical planning and the creation of customized implants, thus improving functional and aesthetic results. In dentistry, it enhances prosthodontic fabrication and orthodontic treatments by ensuring precise measurements and fit. Furthermore, its integration with artificial intelligence, machine learning, and augmented reality presents new possibilities for automation, real-time intraoperative guidance, and predictive analytics. Despite these advancements, challenges remain, including limitations in soft tissue imaging, high costs, and the need for specialized training. This review consolidates recent research on the applications, benefits, and challenges of 3D laser scanning in precision medicine while exploring future directions and applications, such as real-time intraoperative use and AI-driven diagnostics.The continued evolution of this technology is expected to further enhance patient care, surgical precision, and medical research."
무결성 검사를 위한 경량 에지 기반 로거,2025,"['Data-based decision-making', 'Data integrity', 'Authenticity', 'Logger', 'Context awareness']",최근 데이터 기반 의사결정을 위한 애플리케이션 개발이 다양한 분야에서 개발되고 있다.영상 데이터를 활용한 의사결정에서는 훈련 데이터 변경으로 인한 학습 결과 왜곡이 발생되고있음이 보고된다. 애플리케이션의 신뢰성을 제공하기 위해서는 데이터 무결성 및 진본확인은 필수적 요구사항이다. 이 논문에서는 상황인지와 무결성 확인을 위한 로거 설계를 기술한다. 로거는 카메라 캡쳐 영상을 BGR 변환한 후 영상의 객체를 추출하는 작업을 통해상황인지에 필요한 정보를 획득하고 영상의 특징을 추출하는 작업을 통해 해시를 사용하여무결성 검증 정보를 생성한다. 설계된 에지 로거는 진본확인 위해 PKI를 사용하면 특징해시값을 서명하기 위해 개인 키를 사용하고 공개 키로 검증함으로써 부인 방지를 보장한다.,"Recently many applications such as data-based decision-making are being developed in various fields.In decision-making using video data, distortion of machine learning results due to modification of training data is reported. Data integrity and authenticity verification are essential requirements to provide reliability for the application. This paper describes the design of a logger for context awareness and integrity verification. When converting the camera captured video to BGR, the logger obtains the information necessary for situational awareness by extracting objects from the video and generates integrity verification information using a hash by extracting features of the video. The designed logger uses PKI to verify its authenticity, ensuring non-repudiation by using a private key to sign the characteristic hash value and verifying it with a public key."
Global Trends in Healthcare IT: EMR’s Central Role   and Google Trends Insights,2025,"['Electronic Medical Records (EMRs)', 'Health Information Systems (HIS)', 'Patient Data', 'Data Security', 'Interoperability']",,"Purpose: This study examines global trends and interdependencies in healthcare IT from 2011 to 2024, focusing on Electronic Medical Records (EMRs), Health Information Systems (HIS), Patient Data, Data Security, and Interoperability. The aim is to identify temporal patterns, correlations, and future trends while integrating public sentiment analysis. EMRs and interoperability received predominantly positive sentiment, while patient data and data security raised concerns related to privacy and cybersecurity threats. Research Design and Methods: Using Google Trends data, this study analyzed temporal trends, Pearson correlations, and time-series forecasting. Sentiment analysis assessed public perception of healthcare IT concepts. Data was processed using Python-based statistical, machine learning, and natural language processing (NLP) tools. A quantitative, exploratory approach was used to examine the evolution of search interest and sentiment. Research Results: ""Patient Data"" showed the highest interest, reflecting its central role in healthcare IT. Sentiment analysis revealed negative perceptions of data security, highlighting privacy concerns. Data Security (0.91) and Interoperability (0.77) strongly correlated, indicating security’s role in data exchange. EMRs and interoperability were viewed positively, emphasizing their efficiency in patient care and workflow integration. Predictive modeling suggests increasing interest in healthcare IT, particularly in security and interoperability improvements. Conclusion: The findings highlight the need for secure and interoperable healthcare IT systems. Policymakers should strengthen security protocols, enhance interoperability, and improve public trust to facilitate a more secure, efficient, and patient-centered digital transformation."
Analyzing Public Sentiment and Public Opinion of the Caliphate Issue in Indonesia: Twitter Analytics Evidenc,2025,"['sentiment analysis', 'public debate', 'caliphate', 'Twitter', 'Indonesia']",,"In Indonesia, there is a substantial amount of public discourse about the caliphate, an Islamic  form  of  government. In  2022,  there  were  165,263  public  tweets  on  the social media  platform  Twitter  that  included  the  Indonesian  word  for  caliphate (khilafah).  Conversations  on  topics  of  the  caliphate  in  Indonesia  often  lead  to controversial debate even  within  the  Muslim  community  itself.  The  public  debates have  been  related  to differences of public perception and public faith. This study aims to  describe  the  public  sentiment  on  Twitter  in  Indonesia.  We  examined  public perception  and  engagement  on  Twitter  from  January  1  to  December  31,  2022, regarding  the  caliphate  issues  based  on  sentiment  analysis.  This  study  analyzed Twitter  data  using  machine  learning  from  a  third-party  platform  with  natural language processing (NLP) process to examine public sentiment  about  the  caliphate. The  sentiment  analysis  results  show  that  60%  of conversations  discussing  the caliphate in Indonesia are positive, 38% convey negative sentiments, and 3% convey neutral  sentiments.  The  majority  of  tweets  discussing  the  caliphate  issue  were positive tweets."
GOLD(Global-Scale Observations of the Limb and Disk) 미션의 FUV(Far Ultra Violet) 이미지 잡음과 우주환경 데이터의 비교 연구,2025,"['space weather', 'GEO-orbit', 'noise analysis', '우주환경', '정지궤도위성', '노이즈분석']","현재 수 만대의 상업용 위성이 정지궤도에서 운용되고 발사될 예정에 있으며 고에너지 입자는 이 정지궤도위성들의 고장이나 오동작을 유발하는 주요인 중 하나로 알려져 있다. 따라서 정지궤도에서의 고에너지 전자 플럭스 예측은 우주 기상 정보의 중요한 부분을 차지하게 되었다. GOLD(global-scale observations of the limb and disk) 미션의 FUV(far ultra violet) 관측기는 입자 플럭스를 관측하기 위한 방사선대 관측 용도는 아니지만, 2018년 10월에 정지궤도에 안착하여 지금까지 전리권-열권의 관측 이미지를 제공하고 있으며, 특히 이전 연구를 통해 노이즈에서 고에너지 입자 플럭스를 유추할 수 있음을 SOHO 이미지 분석결과를 통해 알 수 있었다. 이를 이용하여 관측된 이미지 노이즈를 머신러닝 알고리즘이나 AI(artificial intelligence) 기법에 입력하여 전자 플럭스를 유추할 수 있게 되면, 상업적인 목적으로 발사된 기존 여러위성에서 획득한 이미지(예: 기상 이미지)도 유사한 관계식에 입력하여 우주과학 자료 산출에 응용할 수 있을 것이다. 특히 이미 수집된 태양 이미지나 운영 중인 여러 상업 위성의 이미지를 이용할 수 있다면, 기존의 과학위성(예: 미국의 GOES, 한국의 KSEM)이 커버하지 못하는 여러 위치의 에너지 관측치를 얻을 수있게 된다(예: 아프리카 상공 등). 이는 기존에 널리 쓰이지 않던 새로운 이미지 데이터 활용법이며, 위성자료의 활용성 극대화에 기여할 여지가 있다.","Currently, tens of thousands of commercial satellites are operating and planned for launch in geostationary orbit. High-energy particles are known to be a major cause of failures or malfunctions in these satellites.Therefore, predicting high-energy electron flux in geostationary orbit has become an important part of space weather information. While the global-scale observations of the limb and disk (GOLD) mission far ultra violet (FUV) instrument is not designed for radiation belt observations to measure particle flux, it has been providing observational images of the ionosphere and thermosphere since it reached geostationary orbit in October 2018. In particular, previous studies have shown that high-energy particle flux can be inferred from noise in the images, as demonstrated through SOHO image analysis. By inputting the observed image noise into machine learning algorithms or artificial intelligence (AI) techniques, it becomes possible to estimate electron flux. This can then be applied to derive space science data from images (e.g., weather images) acquired by various existing satellites launched for commercial purposes. In particular, if we can utilize already collected solar images or images from various commercial satellites in operation, we can obtain energy measurements at various locations that existing scientific satellites (e.g., US's GOES, Korea's KSEM) cannot cover (e.g., over Africa). This is a new method of utilizing previously underutilized image data and has the potential to maximize the usability of satellite data."
"Exploring Revenue Trends in Alley Commercial Areas in Seoul, Korea",2025,"['Commercial Districts', 'Sales Growth', 'Distributional Inequality', 'COVID-19']",,"This study examines changes in sales by business category and area in Korea’s small commercial districts. Unlike previous studies that focused primarily on overall sales levels before and after the COVID-19 pandemic, this paper emphasizes temporal variations in the inequality of sales distributions. Using credit-card-based data comprising 392,832 sales records aggregated by (category, area) units, the primary analysis reveals that sales distributions have recently become more dispersed across most categories, underscoring the vulnerability of less-advantaged areas in the post-pandemic period. In a secondary analysis, regression and machine learning models were applied to investigate factors influencing regional sales disparities. The findings indicate that although overall sales, which declined sharply during the pandemic, rebounded rapidly after 2021, they have shown a significant downturn in recent periods. The paper concludes with a discussion of relevant policy implications."
Detecting Exoplanets from the Shape of Data:  A TDA-based Approach to Kepler Light Curves,2025,"['Topological data analysis', 'SMOTE', 'Kepler light curve', 'Exoplanet detection', 'Time series classification']",,"Detecting exoplanets from stellar light curves remains a challenging task because of the presence of noise, complex temporal patterns, and significant class imbalances. In this study, we propose a novel classification framework that applies topological data analysis (TDA) to a Kepler light curve time series to extract robust noise-resistant features. By computing persistence diagrams from time-delay embedded flux data and vectorizing them into entropy, landscape, and amplitude descriptors, we capture the essential topological structures related to planetary transits. These features are combined with the synthetic minority over-sampling technique (SMOTE) to mitigate class imbalances and are evaluated using several machine learning classifiers. The study results showed that the TDA-based features, particularly when paired with Random Forest and SVC, significantly improved the sensitivity and F1-score for exoplanet detection, outperforming traditional models trained on raw flux data. This approach highlights the potential of topological methods to enhance time series classification in astrophysical applications."
"Amplicon-based MinION Sequencing, Genomic Characterization, and Zoonotic Potential of Patient-derived Chikungunya Virus Imported from Thailand, Republic of Korea",2025,"['Chikungunya virus', 'Amplicon-based nanopore sequencing', 'Phylogenetic analysis', 'Zoonotic potential']",,"Chikungunya virus (CHIKV), causing Chikungunya fever (CF), is transmitted by Aedes mosquitoes primarily in tropical regions. CHIKV infection poses a public health burden owing to international travel and climate change. Implementation of Next-generation sequencing (NGS) for whole-genome sequencing (WGS) con- tributes to the formulation of effective public health and travel medicine policies to  mitigate  emerging  CHIKV  in  non-endemic  areas.  A  patient  with  CF,  who traveled to Thailand, was enrolled at Sacred Chuncheon Hospital (Chuncheon, Republic of Korea). Amplicon-based NGS was performed using the patient’s sera on days 2 and 6 after hospitalization. The nearly whole genome sequence of CHIKV was recovered from day 2 post-hospitalization, while only 9% on day 6. The phylogenetic inference demonstrated that the CHIKV genotype belonged to the  East/Central/South  African  lineage.  In  addition,  zoonotic  potential  was evaluated by the machine learning model. This study highlights the effectiveness of amplicon-based MinION sequencing derived from a patient who traveled from an  endemic  area.  Collection  of  patient  samples  early  in  infection  is  strongly correlated with genomic acquisition and genotypic identification. Therefore, this study provides insight into the active surveillance for NGS-based genomic diagnosis and characterization of emerging CHIKV outbreak in endemic and non-endemic areas"
"A thorough review of phytogenic feed additives in non-ruminant nutrition: production, gut health, and environmental concerns",2025,"['Environmental impact', 'Gut health', 'Immunity', 'Non-ruminant animal', 'Phytogenic feed additive']",,"Pig farming is experiencing significant transformations, driven by technological advancements, which have greatly improved management practices and overall productivity. Soundbased technologies are emerging as a valuable tool in enhancing precision pig farming. This review explores the advancements in sound-based technologies and their role in improving precision pig farming through enhanced monitoring of health, behavior, and environmental conditions. When strategically placed on farms, non-invasive technologies such as microphones and sound sensors can continuously collect data without disturbing the animals, making them highly efficient. Farmers using sound data, can monitor key factors such as respiratory conditions, stress levels, and social behaviors, leading to improved animal welfare and optimized production. Advancements in sensor technology and data analytics have enhanced the capabilities of sound-based precision systems in pig farming. The integration of machine learning and artificial intelligence (AI) is further enhancing the capacity to interpret complex sound patterns, enabling the automated detection of abnormal behaviors or health issues. Moreover, sound-based precision technologies offer solutions for improving environmental sustainability and resource management in pig farming. By continuously monitoring ventilation, feed distribution, and other key factors, these systems optimize resource use, reduce energy consumption, and detect stressors such as heat and poor air quality. The integration of sound technologies with other precision farming tools, such as physiological monitoring sensors and automated feeding systems, further enhances farm management and productivity. However, despite the advantages, challenges remain in terms of low accuracy and high initial costs, and further research is needed to improve specificity across different pig breeds and environmental conditions. Nonetheless, acoustic technologies hold immense promise for pig farming, offering enhanced management, an optimized performance, and improved animal welfare. Continued research can refine these tools and address the challenges, paving the way for a more efficient, profitable, and sustainable future for the industry."
Advances in the Diagnosis of Urinary Tract Infection:  A Narrative Review,2025,"['Urinary tract infections', 'Point-of-care testing', 'Polymerase chain reaction', 'Microbial drug resistance']",,"Urinary tract infections are among the most frequent bacterial infections, significantly impacting patient morbidity and healthcare resources. Prompt and accurate diagnosis is crucial to ensure effective treatment, prevent complications such as pyelonephritis or sepsis, and reduce inappropriate antibiotic use, contributing to antimicrobial resistance (AMR). Despite consensus across international guidelines from organizations, challenges persist, particularly in distinguishing true infections from asymptomatic bacteriuria or nonspecific symptoms, especially in older adults. Recent advancements in diagnostic technology have emerged to address these limitations, including molecular diagnostics, point-of-care testing (POCT), and artificial intelligence (AI)-driven predictive models. Molecular techniques, notably polymerase chain reaction, loop-mediated isothermal amplification, and metagenomic next-generation sequencing, offer enhanced sensitivity and specificity, rapid detection times, and comprehensive identification of pathogens and resistance profiles. POCT innovations, such as lateral flow immunoassays, enzymatic-based rapid tests, and novel biosensors, facilitate prompt bedside diagnosis, although specificity challenges remain. Meanwhile, AI and machine learning models demonstrate significant potential for risk stratification, prediction of infection, and improving antibiotics prescription practices yet face barriers related to validation, practical integration, and clinical acceptability. Despite promising developments, significant gaps remain, including limited real-world implementation evidence, high costs, and insufficient data from diverse populations.Further rigorous clinical studies, economic evaluations, and practical implementation assessments are urgently required. Addressing these research gaps could substantially improve patient outcomes, optimize antibiotic stewardship, and reduce the global burden of AMR."
빅데이터 융합 범죄예방 분석도구 ‘빅캣’의 개발과 적용,2025,"['BigCat', 'Geo-Pros', 'Pre-CAS', 'Big data', 'Crime prevention', '빅캣', '지오프로스(Geo-Pros)', '프리카스(Pre-CAS)', '빅데이터', '범죄예방']","본 연구는 빅데이터 융합 범죄예방 분석도구인 빅캣(Big data Integrated Crime Prevention Analysis Tool)의 개발, 활용, 성과를 정리하였다. 먼저, 본 연구는 기존의 범죄예방 분석 시스템인 지오프로스(Geo-Pros)와 프리카스(Pre-CAS)에 비해 빅캣이 가진 장점(정보 접근성, 분석 편의성 등)을 해당 시스템들과 비교하면서 설명한다. 이어서, 빅캣 개발의 유래와 빅캣의 다양한 기능(범죄 및 112신고 데이터 시각화, 범죄 유형과 공공 데이터 교차분석 시각화, 침입범죄 군집분석 결과 시각화 등)에 대해 자세히 설명한다. 이후, 다양한 빅캣의 성과(교육시간 단축, 탄력적 순찰 계획 수립 지원, 범죄 취약 지역 선정 지원 등)에 대해 언급한다. 마지막으로, 전처리와 업데이트에 시간과 비용이 많이 들어간다는 내용을 빅캣의 한계로 언급하고 향후 필요한 노력에 대해 다음과 같이 제안한다. (1) 주거침입 범죄 분석과 같이 다른 범죄 유형에도 머신러닝 분석 기능 추가로 빅캣의 예측 능력을 향상시킬 필요가 있다. (2) 빅캣을 전국적으로 확산하기 위해서는 안정적인 예산 지원과 더불어 각 지역별 공공데이터의 통합 및 관리 체계를 확립할 필요가 있다. (2) 빅캣을 활용도를 높이기 위해, 그 분석 결과를 활용한 선제적인 범죄예방 정책도 지속적으로 개발해야 할 것이다.","The study summarizes the development, utilization, and outcomes of the Big data Integrated Crime Prevention Analysis Tool, known as BigCat. First, it explains the advantages of BigCat (such as information accessibility and ease of analysis) compared to existing crime prevention analysis systems, Geo-Pros and Pre-CAS. It then details the origins of BigCat's development and its various functions, including the visualization of crime and 112 emergency call data, cross-analysis visualization of crime types and public data, and visualization of burglary crime cluster analysis results. Following this, the study mentions various achievements of BigCat, such as reduced training time, support for flexible patrol planning, and assistance in identifying crime-prone areas. Finally, it addresses the limitations of BigCat, noting that preprocessing and updates require significant time and costs, and suggests the following necessary efforts for the future: (1) There is a need to enhance BigCat's predictive capabilities by adding machine learning analysis functions for other crime types, such as residential burglary analysis. (2) To expand BigCat nationwide, it is essential to establish a stable budget support system along with the integration and management of public data in each region. (3) To increase the utilization of BigCat, proactive crime prevention policies based on its analysis results should be continuously developed."
주파수 변환을 활용한 생성 이미지의 효과적 탐지,2025,"['generative image detection', 'frequency domain', 'fast fourier transform', 'discrete cosine transform', 'digital forensics', '생성 이미지 탐지', '주파수 영역', '고속 푸리에 변환', '이산 코사인 변환', '디지털 포렌식']","현재의 디지털 환경에서는 고도로 발달한 이미지 생성 기술이 실제와 구분하기 어려운 가짜 이미지를 만들어내어 디지털 정보의 신뢰성을 위협하고 있다. 기존의 기계 학습 및 딥러닝 기법들은 이러한 진화하는 생성 알고리즘에 대해 한계를 보였으나, 본 연구는 주파수 영역에서 생성 이미지의 특성을 분석하는 새로운 접근법을 제시한다. 본 연구에서는 고속 푸리에 변환(FFT)과 이산 코사인 변환(DCT)을 각각 독립적으로 적용하여, 각 기법이 생성 이미지 탐지에 미치는 효과를 별도로 분석하였다. 실험 결과, FFT를 적용한 모델은 테스트 정확도가 약 12.8% 향상되었으며, DCT를 적용한 모델은 약 22.2%의 성능 향상을 보였다. 이러한 결과는 주파수 영역에서의 접근이 기존의 공간 영역 기반 탐지 기법보다 우수함을 입증하며, 디지털 포렌식 분야에서 이미지 신뢰성을 높이는 데 실질적인 기여를 할 것으로 기대된다.","In today's digital era, advanced image generation techniques have produced counterfeit images that are nearly indistinguishable from real ones, thereby undermining the trustworthiness of digital information. Conventional machine learning and deep learning methods have shown limitations when confronting these evolving generative algorithms. This study introduces a novel approach that can analyze characteristics of generated images in the frequency domain. Specifically, we independently applied the Fast Fourier Transform (FFT) and the Discrete Cosine Transform (DCT) to evaluate the effectiveness of each method for detecting generated images. Experimental results revealed that the FFT-based model improved the test accuracy by approximately 12.8%, while the DCT-based model demonstrated a performance enhancement of about 22.2%. These findings confirm that a frequency domain approach outperforms traditional spatial domain-based detection techniques. It is expected to make a substantial contribution to enhancing image reliability in digital forensics."
감염병 위기에서 AI는 어떻게 사용되었는가: COVID-19 연구동향 분석,2025,"['Artificial intelligence', 'COVID-19', 'forecasting', 'public health', '.']",,"Background: The COVID-19 pandemic prompted a surge in artificial intelligence (AI) research with health- related applications, including diagnosis, forecasting, and policy evaluation. While many reviews have summarized model performance, few have examined the structural relationships between research aims, data types, and algorithm selection.Objectives: This study presents a narrative review of AI-based COVID-19 research, focusing on how algorithm choices evolved across different functional goals—clinical diagnosis and treatment, infection forecasting, and public health or policy response—and how these choices were shaped by data characteristics and different phases of the pandemic.Methods: We reviewed 108 peer-reviewed English-language studies published between 2020 and 2024. Each study was categorized by functional objective and analyzed in terms of AI methods used, data types and sources, geographic focus, and modeling strategies. Both quantitative trends and qualitative insights were synthesized.Results: Convolutional neural networks, support vector machines, and random forests were frequently used and showed broad applicability. Algorithm selection aligned closely with data types: deep learning was dominant in image-based tasks, while structured data often employed tree-based or logistic models. Over time, reliance on public case data declined, while the use of clinical and policy datasets increased. Supervised learning approaches remained dominant, although unsupervised methods were used for sentiment analysis and clustering. Modeling patterns varied significantly by research purpose, reflecting the structural match between methodological design and data context.Conclusions: AI use in COVID-19 research evolved with changing data environments and research needs. Algorithm choice reflected not only technical capacity, but also alignment with functional objectives and data structures. This narrative review provides guidance for the future development of AI-based tools in public health emergencies."
Supply Chain Demand Forecasting Based on Data Mining Algorithm and Seq2Seq,2025,"['Attention', 'supply chain', 'demand prediction', 'Seq2Seq.']",,"In the cross-border e-commerce industry chain for eco-friendly electronic products, the prediction of supply chain demand plays a pivotal role. It is essential to accurately forecast the future demand for each ecofriendly electronic product in various warehouses, enabling timely inventory distribution across the globe, reducing carbon emissions from logistics, and significantly enhancing customer experience. This paper explores multiple demand prediction algorithms for supply chain demand for eco-friendly electronic products. Addressing the shortcomings in existing methods, such as anomaly detection, vectorized representation of product information, and multi-step forecasting, we propose three innovative improvements to enhance prediction accuracy while considering environmental factors. Firstly, we introduce a linear regression method based on Huber Loss for data processing, effectively identifying anomalies in historical sales data. Secondly, we present a product Embedding vector representation method based on Pearson’s correlation coefficient. This method not only learns low-dimensional vector representations of product information but also reveals the sales correlations and competitiveness among products, aiding in optimizing the market placement of eco-friendly products. Lastly, we optimize the multi-time step demand prediction method by proposing a deep learning algorithm based on Seq2Seq+Attention, enabling end-to-end temporal multi-step forecasting to adapt to the dynamic and complex demands of the eco-friendly market. Experiments conducted on actual historical sales data of eco-friendly electronic products from an e-commerce platform demonstrate that the methods proposed in this paper surpass traditional time series prediction models and machine learning regression models in forecasting accuracy, contributing to more environmentally friendly and efficient supply chain management for electronic products."
멀티모달 LLM 에이전트에 관한 연구,2025,"['MLLM', 'Multimodal', 'LLM', 'Agents', 'NLP']","MLLM(다중 모드 대형  언어 모델)의 LLM은 점점 더 많은 자연어 처리(NLP) 애플리케이션의 초석이 되고 있으며, 이미지를 기반으로 스토리 작성 및 OCR 없는 수학 추론과 같은 MLLM의 놀 랍고 새로운 기능, 이후 GPT-4V, LLaVA, BLIP-2, Minigpt-4를 포함한 많은 노력으로 LLM이 개발되었다. 본 연구에서는 932개의 고품질의 기계 학습 관련 API를 수집하여 MLLM 데이터세트 및  모델에 적용되는 증강 행동 주석 도구 최근  진행 상황을 추적하고 요약하는 것을 목표로 한다. 현재  LLM이 단일 텍스트 쿼리에 국한되어 있어 사용자의 의도를 이해하는데 모호함이 발생할 수 있어서 본 연구에서는 오픈  소스 LLM과 멀티모달  인코더를 통합하여 다중 모드 명령을 명확히 인 식하여 올바르게 선택하고 미세 조정하여 인식 성능을 향상시키는 적합한 도구를 추천할 수 있다.","LLMs in multi-modal large language models (MLLM) are becoming a cornerstone of a growing number of natural language processing (NLP) applications, with many efforts including amazing and novel features of MLLM such as storytelling and OCR-free mathematical reasoning based on images, and followed by GPT-4V, LLAVA, BLIP-2, and Minigpt-4. In this work, we aim to collect 932 high-quality machine learning related APIs to track and summarize recent progress with augmented behavior annotation tools applied to multi-modal language models (MLM) datasets and models. As a LLM is currently confined to a single-text query, ambiguity may arise in understanding users'  intentions. In this work, we integrated open-source LLM and multimodal encoders to clearly recognize multimodal commands, correctly select them, and fine-tune them to improve recognition performance, thereby recommending suitable tools."
예지 보전을 위한 다중 인코더 단일 디코더 모델,2025,"['anomaly detection', 'auto-encoder', 'encoder', 'decoder', 'LSTM', 'predictive maintenance']","오토 인코더 기계 학습 모델은 장치의 동작 상태 데이터를 이용하여 작동 이상 조짐을검출할 수 있어 이상 탐지에 많이 이용된다. 오토 인코더를 이용한 기존의 이상 탐지는 부하, 기준 신호 등 장치 동작의 기준이 되는 신호와 소비 전력, 회전 수 등 장치 동작 상태 등검출된 데이터를 함께 인코딩, 디코딩 하므로 기준 신호의 변화량에 대한 장치의 상태 변화량의이상을 적절한 수준에서 검출하기 어려웠다. 본 논문에서 제안하는 모델은 기준 신호와 각상태 데이터에 대한 인코딩 과정을 분리하고, 디코더에서 이들 신호를 결합, 복원함으로써기반 신호의 변화량에 대한 장치의 여러 상태 변화량의 이상을 사전에 검출할 수 있다. 본논문에서 제안한 모델이 유효함을 보이기 위해 기준 데이터로 각도, 상태 데이터로 sine, cosine 값을 학습하고, 각 값에 노이즈인 이상 데이터를 추가하여 이상 탐지 성능을 평가하였다.성능 평가 결과에 의하면 기존의 오토 인코더 모델 보다 본 논문에서 제안한 모델이 이상조짐을 보이는 초기 시점에 작동 이사의 조짐을 더 잘 검출하였다. 따라서, 지속적인 서비스가중요한 설비의 예측 보전 분야에 본 논문에서 제안한 모델이 사용될 수 있다.","Autoencoder-based machine learning models are widely used for anomaly detection, as they can detect early signs of operational faults by analyzing the device’s operational state data. Conventional anomaly detection methods based on autoencoders encode and decode reference signals—such as load or setpoint signals—and operational state data—such as power consumption and rotational speed— jointly. As a result, these approaches struggle to effectively detect deviations in the operational states relative to variations in the reference signals. In this paper, we propose the model which separates the encoding processes for the reference signal and each operational state data, and reconstructs them by combining these signals in the decoder. Our proposed model enables the early detection of anomalies in the operational state data with respect to variations in the reference signal. To validate the effectiveness of the proposed model, angle as reference signal, sine, and cosine values as state data were used for training, and anomaly detection performance was evaluated by anomalous data to each of these values.Experimental results show that the proposed model outperforms conventional autoencoder-based approaches in detecting early signs of operational anomalies. Consequently, the proposed model can be used for application in predictive maintenance of systems where continuous operation is critical."
수입 수산물 유통 데이터를 위한 정형 및 비정형 데이터 통합,2025,"['수산물 유통', '데이터 통합', '온톨리지 맵핑', '정형 및 비정형 데이터', 'seafood distribution', 'data integration', 'Ontology mapping', 'structured and unstructured data']","본 연구는 수산물 유통 데이터의 통합과 분석을 통해 유통 체계의 투명성과 효율성을 강화하는 방법론을 제안한다. 수산물 유통 과정에서 정형 데이터(예: HS-CODE, 수입일자, 수출입량)와 비정형 데이터(예: 제품 설명, 품질 속성) 간의 데이터 속성 불일치와 구조적 차이는 데이터 관리와 분석에서 주요한 장애 요소로 작용한다. 본 연구는 온톨로지 방식을 활용하여 정형 데이터와 비정형 데이터 간의 관계를 정의하고, 이를 통합적으로 분석할 수 있는 체계를 구축하였다. 정형 데이터는 관세청과 같은 공공 데이터베이스에서 수집되었으며, 비정형 데이터는 자연어 처리(NLP) 기술을 적용해 수집 및 정제되었다. 연구결과, 온톨로지 방식은 정형 데이터와 비정형 데이터 간의 속성 매핑 문제를 효과적으로 해결하며, 데이터 통합 과정에서 발생할 수 있는 오류를 최소화하였다. 또한, HS-CODE를 기반으로 수산물 품목을 세분화하고, 비정형 데이터를 통해 가공 상태, 제품 형태, 유통 경로 등 세부 정보를 추가함으로써 데이터의 일관성과 신뢰성을 높였다. 이로써 데이터 기반 의사결정을 지원하고, 수산물 유통 과정의 디지털화를 촉진하는 데 기여하였다. 특히, 본 연구는 데이터 통합 과정에서 발생할 수 있는 구조적 차이를 극복하고, 정형 데이터와 비정형 데이터의 상호 연계를 통해 수산물 유통 체계의 효율성을 향상시키는 데 중점을 두었다. 이 접근법은 수산물 유통 과정에서 발생하는 다양한 데이터를 통합적으로 분석할 수 있는 기반을 제공하며, 향후 머신러닝 및 AI 기반 예측 모델링과의 결합을 통해 유통 체계의 혁신적 발전에 기여할 것으로 기대된다.","This study proposes a methodology for integrating and analyzing seafood distribution data to enhance transparency and efficiency in the supply chain. In the seafood distribution process, structural differences and attribute mismatches between structured data (e.g., HS-CODE, import dates, trade volumes) and unstructured data (e.g., product descriptions, quality attributes) present significant challenges in data management and analysis. By employing an ontology-based approach, this study establishes relationships between structured and unstructured data, enabling integrated analysis. Structured data were collected from public databases, such as those of the Korea Customs Service, while unstructured data were gathered and refined using natural language processing (NLP) techniques. The findings demonstrate that the ontology-based approach effectively resolves attribute mapping issues between structured and unstructured data while minimizing errors in the data integration process. By leveraging HS-CODE to classify seafood items and incorporating additional details from unstructured data—such as processing status, product forms, and distribution routes—the proposed methodology improves data consistency and reliability. This approach supports data-driven decision-making and facilitates the digital transformation of seafood distribution processes. Specifically, this research focuses on overcoming structural discrepancies during data integration and enhancing the efficiency of the seafood distribution system by linking structured and unstructured data. The proposed approach provides a robust foundation for comprehensive data analysis in seafood distribution and is expected to contribute to the innovative development of distribution systems by integrating with machine learning and AI-based predictive modeling in the future."
Enhancing QA System Evaluation: An In-Depth Analysis of Metrics and Model-Specific Behaviors,2025,"['question answering systems', 'evaluation metrics', 'natural language processing', 'transformer models', 'BERT']",,"The purpose of this study is to examine how evaluation metrics influence the perception and performance of question answering (QA) systems, particularly focusing on their effectiveness in QA tasks. We compare four different models: BERT, BioBERT, Bio- ClinicalBERT, and RoBERTa, utilizing ten EPIC-QA questions to assess each model’s answer extraction performance. The analysis employs both semantic and lexical metrics. The outcomes reveal clear model-specific behaviors: Bio-ClinicalBERT initially identified irrelevant phrases before focusing on relevant information, whereas BERT and BioBERT continually converge on similar answers, exhibiting a high degree of similarity. RoBERTa, on the other hand, demonstrates effective use of long-range dependencies in text. Semantic metrics outperform lexical metrics, with BERTScore attaining the maximum accuracy (0.97), highlighting the significance of semantic evaluation. Our findings indicate that the choice of evaluation metrics significantly influences the perceived efficacy of models, suggesting that semantic metrics offer more nuanced and insightful assessments of QA system performance. This study contributes to the field of natural language processing and machine learning by providing guidelines for selecting evaluation metrics that align with the strengths and weaknesses of various QA approaches."
Remote management and variability assessment of environmental  conditions for smart vertical farms: A review,2025,"['Smart farming', 'Remote monitoring', 'IoT', 'Environmental sensing', 'Spatial variability']",,"Vertical farming (VF) has emerged as a transformative approach to urban agriculture, enabling year-round crop production in compact, multilayered indoor environments. By employing soilless cultivation systems and climate-controlled conditions, VF decouples food production from environmental constraints such as limited arable land and changing climate. However, the vertical stratification of crops introduces significant microclimatic variability in temperature, humidity, light intensity, and CO2 concentration, which can adversely affect crop uniformity and resource efficiency.This review aimed to explore remote management technologies and variability assessment of environmental conditions for smart vertical farms. The integration of wireless sensor network (WSNs), Internet of Thing (IoT) technologies, and low-power wide-area network (LPWAN) protocols like long range wide area network (LoRaWAN) for environmental data acquisition and control were evaluated. Key sensing modules for monitoring critical variables such as pH, electrical conductivity (EC), temperature, and CO2 are discussed, alongside recent developments in real-time communication, edge computing, and machine learning (ML)-driven control systems. A particular focus is given to microclimatic variability assessment using geostatistical and ML-based methods for spatial-temporal mapping and predictive decision-making. The review also analyzes power supply strategies, including energy harvesting, node placement optimization, and signal preprocessing techniques for noise reduction and multi-sensor fusion. Findings reveal that wireless systems offer considerable advantages over wired setups in terms of flexibility, scalability, and operational efficiency in VF environments. The successful deployment of smart VF systems depends on the precise alignment of sensor placement, communication protocols, data processing, and visualization interfaces. Despite advancements, challenges remain, including signal attenuation in enclosed layers, energy limitations, and sensor drift under harsh microclimates."
Artificial intelligence can help individualize Wilms tumor treatment by predicting tumor response to preoperative chemotherapy,2025,"['Artificial intelligence', 'Neoadjuvant therapy', 'Sensitivity and specificity', 'Tomography', 'spiral computed', 'Wilms tumor']",,"Purpose: To create a computer-aided prediction (CAP) system to predict Wilms tumor (WT) responsiveness to preoperative chemotherapy (PC) using pre-therapy contrast-enhanced computed tomography (CECT).Materials and Methods: A single-center database was reviewed for children <18 years diagnosed with WT and received PC between 2001 and 2021. Patients were excluded if pre- and post-PC CECT were not retrievable. According to the Response Evaluation Criteria in Solid Tumors criteria, volumetric response was considered favorable if PC resulted in ≥30% tumor volume reduction. Histological response was considered favorable if post-nephrectomy specimens had ≥66% necrosis. Four steps were used to create the prediction model: tumor delineation; extraction of shape, texture and functionality-based features; integration of the extracted features and selection of the prediction model with the highest diagnostic performance. K-fold cross-validation allowed the presentation of all data in the training and testing phases.Results: A total of 63 tumors in 54 patients were used to train and test the prediction model. Patients were treated with 4–8 weeks of vincristine/actinomycin-D combination. Favorable volumetric and histologic responses were achieved in 46 tumors (73.0%) and 38 tumors (60.3%), respectively. Among machine learning classifiers, support vector machine had the best diagnostic performance with an accuracy, sensitivity, and specificity of 95.24%, 95.65%, and 94.12% for volumetric and 84.13%, 89.47%, 88% for histologic response prediction.Conclusions: Based on pre-therapy CECT, CAP systems can help identify WT that are less likely to respond to PC with excellent accuracy. These tumors can be offered upfront surgery, avoiding the cons of PC."
Prediction Models for Auto Insurance Data using A Custom Loss Function,2025,"['자동차 보험', '예측 모델', '손실함수', 'auto insurance', 'prediction model', 'loss function']",,"In the first half of 2023, major domestic property and casualty insurance companies in South Korea recorded automobile insurance loss ratios in the 70% range, leading to increasing calls for additional reductions in automobile insurance premiums in the latter half of the year. Furthermore, with digital insurance companies launching products with various riders, competition in the domestic automobile insurance market is expected to intensify. Therefore, the insurance industry recognizes the urgent need for precise automobile insurance prediction models that minimize the burden of automobile insurance premiums on the public while maintaining current loss ratios. In line with this trend, a specialized loss function customized to automobile insurance was developed. When calculating premiums based on predicted loss amounts, it is crucial to create a loss function that optimizes values under the condition that the sum of predicted loss amounts is greater than the sum of actual automobile losses. By applying this loss function to four machine learning models, we can see that using a custom loss function to automobile insurance significantly reduces the total premiums compared to conventional methods, thereby enhancing the competitiveness of insurance products."
안전한 데이터 연계와 활용을 위한 다자간 피처 스토어(Multi-Party Feature Store) 구축 및 운영에 관한 논의,2025,"['프라이버시 강화 기술(privacy enhancing technologies)', '데이터센터', '데이터 트윈(data twin)', '재현자료(synthetic data)', '기준 데이터(hinge data)', '통계등록부(statistical register)', '다자간 피처 스토어(multi-party feature store)', 'privacy-enhancing technologies', 'data center', 'data twin', 'synthetic data', 'hinge data', 'statistical register', 'multi-party feature store']","데이터 연계·활용·거래를 위한 플랫폼으로서 다자간 피처 스토어(multi-party feature store)의 개념과 운영 방안을 제안한다. 다자간 피처 스토어는 현재 국내의 여러 제약조건을 반영하여 최신 개인정보보호 강화 기술(Privacy-Enhancing Technologies; PET)을 사용한 플랫폼으로, 여러 기관의 데이터를 연계한 마이크로데이터 공유를 지원하여 고도화된 통계 분석을 가능하게 하고 인공지능 모델 개발을 지원한다. 이 플랫폼은 사용자 중심의 데이터 접근성과 효율성을 대폭 향상하는 것을 목표로 하며, 4가지 주요 특성을 가진다. 첫째, 사용자는 데이터센터를 방문하여 민감한 원본 데이터에 직접 접근하기 이전에, 재현자료(synthetic data)를 활용한 데이터 트윈(data twin)을 통해 제약 없이 편리하게 사전 분석을 수행할 수 있어 시간과 비용을 절감할 수 있다. 둘째, 통계청의 통계등록부 등 모집단에 대한 기준 데이터(hinge data)를 활용하여 다기관 데이터를 효율적으로 연계함으로써, 데이터 통합과 고도화된 분석 및 머신러닝 모델 개발을 지원한다. 셋째, 일련의 과정 이후, 사용자는 보안 클라우드 환경에서 안전하게 연계된 데이터를 반복적으로 분석하고 그 결과를 API 형식으로 구독할 수 있다. 넷째, 데이터 제공자와 플랫폼 운영 기관을 위해서는 제공된 데이터와 피처(속성)의 가치 및 수요에 따라 보상이 이루어지는 체계를 구축하여 지속 가능한 데이터 플랫폼 생태계를 조성한다. 본 논문에서는 다자간 피처 스토어를 제안하게 된 배경인 데이터 연계·융합 및 활용을 저해하는 각종 요인과 이를 해결하는 최신의 개인정보보호 강화 기술을 먼저 논의한 뒤, 통계청이 현재 보유한 자원과 최신 기술을 활용한 다자간 피처 스토어 플랫폼의 청사진을 제시하고, 운영 방안 및 기대효과에 대해 논의한다.","This paper proposes the concept, design and operational framework of the Multi-Party Feature Store (MPFS) as a platform for data linking, utilization, and trading. The MPFS is a platform that incorporates the latest Privacy-Enhancing Technologies (PET) to reflect the current constraints in South Korea and supports microdata sharing by linking data from multiple institutions. This enables advanced statistical analysis and supports the development of artificial intelligence (AI) models. The platform aims to significantly enhance user-centric data accessibility and efficiency, with four key characteristics. First, users can conduct preliminary analyses conveniently and without restrictions by utilizing synthetic data through a data twin before directly accessing sensitive original data at data centers, thereby saving time and costs. Second, by efficiently linking multi-institutional data using hinge data (such as the National Statistical Office’s statistical registers) based on population standards, the platform supports data integration, advanced analysis, and machine learning model development. Third, after completing the preceding processes, users can safely analyze the linked data repeatedly in a secure cloud environment and subscribe to the results in API format. Fourth, for data providers and platform operators, a reward mechanism is established based on the value and demand of the shared data and features, fostering a sustainable data platform ecosystem. This paper first discusses various factors that hinder data linking, integration, and utilization, and the latest PETs that address these issues. It then presents the blueprint of the multi-party feature store platform utilizing the resources and the latest technologies currently held by the National Statistical Office, before discussing the operational framework and expected benefits."
Predictive factors of adolescents’ happiness: a random forest analysis of the 2023 Korea Youth Risk Behavior Survey,2025,"['Adolescents', 'Happiness', 'Mental health', 'Random forest']",,"Purpose: This study aimed to identify predictive factors affecting adolescents’ subjective happiness using data from the 2023 Korea Youth Risk Behavior Survey. A random forest model was applied to determine the strongest predictive factors, and its predictive per- formance was compared with traditional regression models.Methods: Responses from a total of 44,320 students from grades 7 to 12 were analyzed. Data pre-processing involved handling missing values and selecting variables to con- struct an optimal dataset. The random forest model was employed for prediction, and SHAP (Shapley Additive Explanations) analysis was used to assess variable importance. Results: The random forest model demonstrated a stable predictive performance, with an R of .37. Mental and physical health factors were found to significantly affect subjec-2tive happiness. Adolescents’ subjective happiness was most strongly influenced by per- ceived stress, perceived health, experiences of loneliness, generalized anxiety disorder, suicidal ideation, economic status, fatigue recovery from sleep, and academic perfor- mance.Conclusion: This study highlights the utility of machine learning in identifying factors influencing adolescents’ subjective happiness, addressing limitations of traditional re- gression approaches. These findings underscore the need for multidimensional interven- tions to improve mental and physical health, reduce stress and loneliness, and provide integrated support from schools and communities to enhance adolescents’ subjective happiness."
How far have we come in our efforts to apply personalized therapy for lung cancer at bedside?,2025,['Lung cancer \xa0· Organoid \xa0· Microfluidic chip \xa0· Bioprinting \xa0· Tumor microenvironment'],,"Background Lung cancer, characterized by a 5-year survival rate and poor treatment efficiency, requires improvement in treatment efficiency through early detection and appropriate treatment. Predictive in vitro models for treatment responsiveness are crucial for lung cancer research. Traditional studies have utilized primary cells or cell lines of lung cancer; however, these approaches have limitations in reflecting heterogeneity in the body and implementing the 3-dimensional (3D) state of tumors in 2-dimensional cell culture without considering the tumor microenvironment. Animal experiments also have limitations owing to their high cost, long duration, and inability to perfectly mimic the human body.Objectives Recently, efforts have been made to culture lung cancer tissues from patients in 3D as organoids and to recreate an in vivo environment using 3D bioprinting and microfluidic chips. Additionally, the introduction of machine learning has contributed to refining and advancing personalized lung cancer treatments.Conclusions This review aims to introduce recent technologies employed for personalized lung cancer treatment."
싱가폴 창이 공항의 항공 승객 수요 예측,2025,"['Air Passenger Demand Forecasting', 'SARIMAX Model', 'Exogenous Variable', 'COVID-19', 'Time Series Analysis']",,"The COVID-19 pandemic has caused significant disruptions in global air travel demand, presenting new challenges for accurately forecasting passenger volumes. This study analyzes the monthly air passenger demand data from 2010 to 2022 to identify key external factors that influence passenger demand. Our analysis shows that the number of international visitors to Singapore is a critical determinant of passenger demand. Consequently, we propose a SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous variables) model to forecast monthly air passenger demand at Singapore's Changi Airport, integrating international visitor numbers as an exogenous variable. Through comprehensive model identification and parameter estimation, we select the best SARIMAX configuration. To validate the performance of the model, traditional time series methods such as SARIMA, various exponential smoothing methods, and advanced machine learning methods like LSTM (Long Short-Term Memory) and Prophet were compared for forecasting monthly air passenger demand at Changi Airport in 2023. The results show that the SARIMAX model significantly outperforms all other tested models, achieving the best performance across multiple forecast- ing metrics, including the Mean Absolute Percentage Error."
컬럼샘플링과 Bagging을 활용한 자금시장 거시유동성 이벤트 탐지,2025,"['Money Market', 'Macro Liquidity', 'Event Detection', 'Variable Selection', 'Ensemble', '자금시장', '거시유동성', '이벤트 탐지', '변수 추출', '앙상블']",자금시장의 유동성 파악은 금융회사 혹은 기업의 자금을 조달하는데 있어 중요하다. 자금조달은 기업의 운영에 필요한 자금을 조달하는 것을의미한다. 본 연구에서는 거시경제변수를 활용하여 금융시장 및 경제의 전반적인 상태를 고려하는 자금시장 유동성 이벤트 탐지 모델을 제안한다. 금융시장 및 경제의 전반적인 상태를 파악하기 위하여 미국과 한국의 거시경제변수를 모델 입력 변수들로 고려한다. 다수의 거시경제변수를 활용한기계학습 모델은 차원의 저주로 인한 모델 과최적화 현상이 나타날 수 있다. 이러한 현상을 완화하기 위하여 본 연구에서는 샘플링 기반의 컬럼탐색을 실시하였으며 모델의 분산 및 과최적화를 완화하기 위하여 bootstrap aggregation(bagging)을 활용하였다.,"Understanding liquidity in the financial market is important for raising funds for financial companies or corporations. Financing meansraising funds necessary for corporate operations. In this study, we propose a liquidity event detection model in the financial marketthat considers the overall state of the financial market and the economy by utilizing macroeconomic variables. In order to understandthe overall state of the financial market and the economy, macroeconomic variables from the United States and Korea are consideredas model input variables. Machine learning models utilizing a large number of macroeconomic variables may exhibit model overfittingdue to the curse of dimensionality. To alleviate this phenomenon, this study conducted a sampling-based column search and utilizedbootstrap aggregation(bagging) to alleviate model variance and overfitting."
다중 클래스 오류 수정 출력 코드를 이용한 선형 이송 로봇의 정렬 이상 검출 시스템,2025,"['Linear motion robot', 'Error-correcting Output Codes (ECOC)', 'Anomaly diagnosis', 'Linear rail misalignment', 'Ball screw misalignment', '선형 로봇', '오류 수정 출력 코드', '이상 검출', '선형 레일 정렬 이상', '볼스크류 정렬이상']","선형 로봇은 자동화 시스템에서 부품의 이송이나 위치 결정에 사용되는 장치이다. 선형 로봇을 제작할 때 생길 수 있는 정렬 이상은 과도한 소음과 진동을 발생시키고 제어 성능을 저하시킨다. 지금까지는 인간 작업자가 로봇의 이상을 검출하였으나, 최근에는 기계학습이나 인공지능을 이용하여 자동으로 오류를 검출하는 연구가 활발히 진행되고 있다. 본 논문에서는 로봇을 구동할 때 발생하는 진동 신호에서 얻어진 통계적 특징값과 다중 클래스 오류 수정 출력 코드 (Multi-class Error-correcting Output Codes)를 이용한 자동 이상 진단 방법을 제안한다. 실험을 통해 검출 정확도를 측정하고 제안된 방법의 유용성을 검증하였다. 제안된 방법은 선형 로봇뿐만 아니라 일반적인 산업용 로봇의 이상 진단에도 사용할 수 있을 것으로 예상한다.","Linear motion robots are devices that perform functions such as transferring parts or positioning devices. Misalignments that may occur when manufacturing a linear robot generate excessive noise and vibration and reduces control performance. Until now, human workers are in charge of quality control and anomaly diagnosis of linear robots. Recently, there have been many attempts to utilize artificial intelligence or machine learning to diagnose faults in industrial devices. In this paper, we present a system that automatically diagnoses linear rail misalignment and ball screw misalignment of a linear robot using the statistical feature values obtained from the vibration signal with Error-correcting Output Codes (ECOC). The validity of the proposed method was evaluated through experiments. It is expected that the proposed method can be used not only for linear robots but also for diagnosing other industrial robots."
Review on Hyperspectral Remote Sensing of Tidal Zones,2025,['Hyperspectral\xa0· Tidal zone\xa0· Tidal fat\xa0· Remote sensing'],,"Hyperspectral data, known for providing detailed spectral information on targets, is recognized as a valuable remote sensing dataset for investigating natural processes and statuses of both terrestrial and oceanic ecosystems. Tidal zones, situated between land and ocean, exhibit characteristic features where hyperspectral data are uniquely useful for remotely identifying the bio-geochemical variables related to the processes in tidal zones. This article reviews studies on tidal zones that employed hyperspectral data for retrieving the variables on (i) physical properties of fats (texture and soil moisture content), (ii) abundance of primary producers on the surface (algae and vegetation), and (iii) water area properties (turbidity and bathymetry). The primary focus of this review is on the diversity of algorithms employed within each application feld, rather than ofering an exhaustive list of previous studies. The algorithms discussed range from traditional methods that exploit the geometric shape of the refectance spectrum to statistical approaches, such as variations of regression, and more advanced machine learning techniques. In addition, relatively recent physics-based approaches involving radiative transfer simulation have been introduced for the relevant applications. While a direct comparison of performance results across diferent studies is often unfeasible due to variations in environments, sensors, platforms, and target species, we summarize the estimation results, along with the metrics used, to provide initial insights into the use of hyperspectral data for specifc applications. Along with the algorithmic focus, this article identifed critical wavelength ranges for each application based on the surveyed literature and our feld measurement data, as feature selection and dimension reduction are often preferred prior to the analysis to manage the high data complexity and avoid the curse of dimensionality in hyperspectral data."
이동 평균법을 활용한 환자기반 실시간 정도관리의 구현 및 적용,2025,"['Quality control', 'Real-time', 'Systematic error']",,"Internal quality control (IQC) is an essential component for monitoring the performance of analytical systems in clinical laboratories. Nevertheless, traditional IQC has several limitations, including discontinuous characteristics and non-commutability of control materials. Moving average quality control (MA QC) has been suggested as a tool for analytical quality control for decades. In addition, despite being proven for its advantages, its complexity and lack of evidence-based guidelines make it difficult to apply in practice. Previous studies have reported that the MA method can rapidly detect and correct errors in the testing system by applying the MA method in creatinine, routine chemistry tests, international normalized ratio and activated partial thromboplastin time, and serum Na, and emphasized the importance of MA QC as a quality control that complements the existing IQC. Therefore, MA QC can be added when IQC is limited. In conclusion, using an optimized MA method can increase the reliability of test results and minimize significant errors in patient treatment. The MA method is expected to expand with the advances in artificial intelligence and machine learning technologies."
Time-of-flight based one-dimensional position estimation of radioactive sources using artificial neural network model,2025,"['Plastic scintillating fiber', 'Time-of-flight measurement', 'Radiation source localization', 'Artificial neural network', 'Position estimation']",,"This study presents a novel approach for one-dimensional gamma ray source position estimation by integrating plastic scintillating fiber technology, time-of-flight (ToF) measurements, and artificial neural network (ANN) techniques. The methodology employs a systematic signal processing framework consisting of constant fraction discrimination (CFD) for precise timing extraction, amplitude-based filtering for noise reduction, and statistical analysis of ToF data to enhance measurement consistency. A two-stage ANN architecture was developed incorporating dual hidden layers with ReLU activation functions and weighted correction factors to optimize spatial localization performance. The system was experimentally validated using a Cs-137 radiation source across a 10-m measurement range with data collected at both regular intervals and random positions to assess interpolation capabilities. Comparative analysis between the ANN-based approach and theoretical calculations demonstrated a 90.17 % enhancement in position estimation precision, achieving an average error of 0.0225 m compared to 0.2289 m with conventional methods. Standard deviations in position estimates remained consistently below 0.1 m across the operational range, indicating robust performance stability. These results substantiate that combining sophisticated timing measurements with machine learning strategies advances radiation detection systems applicable to environmental monitoring, nuclear safety protocols, and emergency response scenarios."
Hydrogeological fate of radionuclides at decommissioned nuclear power plant sites: Case studies for radionuclides transport model development,2025,"['radionuclide', 'contamination', 'modeling', 'nuclear power plant', 'decommissioning', '방사성 핵종', '오염', '모델링', '원자력 발전소', '해체']",,"Motivated by the urgent need to understand and mitigate potential environmental and public health risks associated with decommissioned nuclear power plants, this review paper explores studies on radioactive contamination at these facilities, with a particular focus on the development of radionuclide transport models. It begins with a comprehensive literature review, examining various contaminant types, extents, effects, and site conditions. Through careful examination of case studies, the paper extracts valuable insights from historical contamination incidents to guide contemporary practices. The primary emphasis is on data utilized in modeling studies, highlighting the collection and processing of information from both existing literature and on-site observations. The paper discusses the quality assurance and quality control (QA/QC) procedures crucial for numerical modeling, including an in-depth assessment of modeling parameters to ensure the dependability and precision of inputs. Furthermore, it explores the development of a robust database system, strategically organized for machine learning inputs, laying the foundation for sophisticated data analysis. The review highlights that choosing the right numerical models for specific site conditions, conducting thorough data collection and processing, and developing reliable database systems are essential for the successful management of decommissioned nuclear power plants. This paper can contribute to developing a modeling strategy for predicting radionuclide transport in decommissioned nuclear power plant sites, ultimately supporting the effective management of these facilities."
토픽모델링을 활용한 ‘무역전시연구’ 게재 논문 분석,2025,"['Trade Fair', 'Structural topic modeling', 'Topic evolution', 'Citation analysis', 'MICE industry', '무역전시', '구조적 토픽모델링', '주제진화', '인용분석', 'MICE 산업']","본 연구는 『무역전시연구』 창간 20주년이자 한국연구재단 KCI 등재후보지 선정 이후 약 15년이 지난 시점에서 해당 저널에 게재된 연구 동향을 종합적으로 파악하고자 수행되었다. 2011년부터 2025년 초까지 발표된 논문 270편의 영문 초록을 수집하여 구조적 토픽 모델링 기법을 적용한 결과, 총 12개의 잠재 주제가 도출되었다. 가장 많은 논문이 포함된 주제는 ‘전시회 성과평가 및 국제비교’(35편), ‘관람객 경험·만족·재방문의도’(33편), ‘MICE 도시 경쟁력·인프라·정책’(26편)이었으며, ‘경제적 파급효과’(15편)와 ‘코로나19·하이브리드 전시·위험 인식’(17편)은 비교적 적은 편수를 기록하였다. 인용 분석 결과, ‘관람객 경험·만족·재방문’ 주제가 논문당 평균 11.10회로 가장 높은 관심을 받았고, 논문 수가 적은 ‘경제적 파급효과’ 역시 평균 10.30회로 두 번째로 높은 인용도를 보였다. 반면 ‘종사원·직무 태도’ 관련 주제는 논문당 평균 2.90회로 가장 낮은 인용 빈도를 나타냈다. 연도별 추세 분석에서는 전시 참가기업 성과, 종사원 이슈, 팬데믹·위험 관리 관련 주제가 점차 비중을 높인 반면, 성과평가·경제적 파급효과·정부지원 해외 전시 참가 주제는 감소 추세를 보였다. 이는 무역전시연구의 연구 초점이 효율성과 거시적 경제효과에서 참가자 경험, 서비스 품질, 위험 관리 등 미시적·실무적 주제로 이동하고 있음을 시사한다. 아울러 인공지능, 빅데이터, 머신러닝 등 최신 산업 이슈는 아직 제한적으로만 다루어지고 있어, 해당 분야 연구를 촉진하기 위한 노력이 요구된다.","This study marks the 20th anniversary of the ‘The International Jouranl of Trade Fair and Exhibition Studies’ and approximately 15 years since its inclusion on the Korea Citation Index candidate list by tracing how scholarly interests in trade fair research have evolved. All 270 published articles and its english abstracts between 2011 and early-2025 were extracted and analyzed with structural topic modeling. Twelve distinct topics emerged. The most prevalent were “Exhibition performance evaluation and international comparison” (35 papers), “Visitor experience, satisfaction, and revisit intention” (33), and “MICE city competitiveness, infrastructure, and policy” (26). In contrast, “Economic impacts” (15) and “COVID-19, hybrid exhibitions, and risk perception” (17) were the least frequent. Citation analysis revealed that “Visitor experience, satisfaction, and revisit intention” attracted the highest attention (mean = 11.10), followed closely by the under-represented “Economic impacts” topic (10.30). Conversely, studies on “Employees and job attitudes” recorded the lowest average (2.90). Temporal patterns show diverging trajectories: topics on exhibitor performance, employee issues, and pandemic-related risk have grown in annual share, whereas those on performance evaluation, economic impacts, and government-supported overseas participation have declined. Overall, the journal’s thematic centre of gravity has shifted from efficiency and macro-economic effects toward participant experience, service quality, and risk management—particularly after the COVID-19 pandemic. While the journal covers a broad range of exhibition and MICE issues, future growth will depend on embracing emerging industry concerns such as artificial intelligence, big-data analytics, and machine learning, which remain only sparsely represented and may warrant dedicated special issues or other incentives for prospective authors."
생성형 AI를 활용한 한국어 관용어의 중국어 번역 양상에 대한 고찰,2025,"['Generative AI', 'Idioms', 'Test of Proficiency in Korean(TOPIK)', 'Korean-Chinese Translation', 'Korean Language Education', '생성형 AI', '관용어', '한국어능력시험(TOPIK)', '한중 번역', '한국어 교육']","생성형 AI가 활발히 발전하고 있는 21세기에는 과학 분야뿐만 아니라 언어학, 통·번역학 등 다양한 분야에서도 생성형 AI의 적용이 활발히 이루어지고 있다. 본고는 한국어 학습자와 밀접한 관련이 있는 한국어능력시험(TOPIK II) 읽기 영역 21번 관용어 기출문제를 대상으로 생성형 AI와 전통적 기계번역의 중국어 번역 양상을 비교 분석하였다. 생성형 AI는 전통적 기계번역에 비해 관용어의 중국어 번역에서 더 나은 성능을 보였으며, 특히 ‘축자적 의미’와 ‘관형적 의미’를 동시에 제시하는 경향을 두드러진다. 관용어 구조 유형 분석에서 생성형 AI는 다양한 중국어 번역 양상을 보였고 사자성어와 일반동사의 번역 결과의 비율이 높게 나타났다. 관용어 예문의 번역에서는 생성형 AI가 관용어가 드러나는 두 가지 이상의 관용적 의미를 반영하는 능력이 뛰어난 결과를 보였다. 관용어 기출문제 풀이 양상에서도 세 종류의 생성형 AI는 대체로 우수한 성과를 보였으나 CLOVA X는 특정 문제에서 오답을 보였다. 이러한 분석 결과는 생성형 AI가 한국어 학습자의 관용어 학습에 효과적인 도구가 될 가능성을 시사한다.","In the 21st century, where generative AI is rapidly advancing, its applications are expanding not only in the field of science but also in various disciplines such as linguistics and translation studies. This study analyzes and compares the patterns of Chinses translation produced by generative AI and traditional machine translation systems, focusing on idiomatic expressions that appeared in question 21 of the Readiong section of the Test of Proficiency in Korean(TOPIK II), which is closely related to Korean language learners. The results show that generative AI performs better than traditional machine translation in translating idiomatic expressions into Chinses, particularly exhibiting a distinct tendency to present both the literal and idiomatic meanings simultaneously. In the analysis of idiom structure types, generative AI demonstrated diverse translation patterns, with a notably high frequency of four-character idioms and general verb expressions in Chinese translations. Furthermore, when translating example sentences containing idioms, generative AI showed a superior ability to reflect multiple idiomatic meanings embedded in a single expression. In terms of answering actual test questions involving idioms, the three generative AI models generally showed strong performance, although CLOVA X produced an incorrect answer for a specific item. These findings suggest that generative AI has strong potential as an effective tool for learning idiomatic expressions for Korean language learners."
헬스케어 합성데이터의 동향과 검증방안 연구,2025,"['Healthcare Synthetic data', 'Synthetic data policy', 'Artificial intelligence', 'Synthetic Image Data Generation and Validation', '의료 분야 합성데이터', '합성데이터 정책', '합성 이미지 데이터 생성 및 검증']","최근 의료 분야에서는 의료영상 판독 및 정밀 의료 분야에서 기계학습 기술이 적용되어 병리학적 판단과 진단에 중요한 역할을 하고 있지만, 방대하고 다양한 의료 데이터를 얻기는 여전히 어려운문제이다. 이는 정부 규제와 개인정보보호에 따른 윤리적 문제로 인한 제약 때문으로, 합성데이터는인공지능 알고리즘으로 데이터를 생성하여 이러한 어려움을 극복할 수 있는 대안으로 주목받고 있다.본 연구는 치과 진단을 위한 구강 내 임상 영상 기반 고해상도 합성데이터 생성 및 검증을 위한 포괄적인 프레임워크를 제안한다. 생성 모델을 활용하여 해부학적 특성을 보존하면서 현실적인 치과 영상을 합성하기 위한 분할 정복 접근법(divide-and-conquer)을 개발하였으며, 서울대학교 치과병원 데이터를 활용해 FID(Frechet Inception Distance), mAP(mean Average Precision) 등의 정량적 평가와 시각적 튜링 테스트를 포함한 다단계 검증 프로세스를 적용하였다. 연구 결과 합성데이터는 실제데이터와 유사한 품질 수준을 달성했으며 충치 분류 및 치아 분할 AI 모델 성능을 크게 향상시켰음을확인하였다. 이 연구는 의료 합성데이터 생성·검증을 위한 혁신적 접근법을 제시하는 동시에 안전한활용을 위한 정책적 대안을 제공할 것이다.","The increasing importance of machine learning in precision medicine and medical imaging interpretation has highlighted the need for large, high-quality datasets. However, legal and ethical restrictions surrounding personal medical data present ongoing challenges to data access and utilization. In response, synthetic data have emerged as a promising alternative for overcoming data scarcity in healthcare AI. This study proposes a comprehensive framework for the generation and validation of high-resolution synthetic data based on intraoral clinical images for dental diagnosis. Leveraging generative models, we developed a divide-and-conquer approach to synthesize realistic dental images while preserving anatomical characteristics. A robust multi-step validation process—including quantitative evaluations (e.g., FID, mAP) and qualitative clinical assessments such as Visual Turing Tests—was applied using data from Seoul National University Dental Hospital. The results demonstrated that the synthetic data achieved comparable quality to real-world data and significantly improved the performance of AI models for cavity classification and tooth segmentation. This research not only presents a novel and practical approach to synthetic healthcare data generation and validation but also provides policy insights into its safe use and future potential."
"Guest Editorial: The 24th International Conference on Control, Automation, and Systems (ICCAS 2024)",2025,,,"The International Journal of Control, Automation, and Systems is pleased to present this special issue, featuring selected research from the 24th International Conference on Control, Automation, and Systems (ICCAS 2024), held at Jeju Shinhwa World, Jeju, Korea, from October 29 to November 1, 2024. This conference introduced a dual submission option for the first time, allowing participants to submit extended abstracts to ICCAS while concurrently submitting full papers to IJCAS, strengthening the synergy between conference presentations and journal publications. ICCAS 2024 brought together over 400 research papers from 21 countries, fostering discussions and collaborations that advance the fields of control, automation, robotics, and systems engineering. Among the many high-quality submissions, 43 papers underwent an expedited yet rigorous review process, with 32 ultimately selected for this special issue. These works highlight both foundational theories and groundbreaking applications, covering advanced control strategies, optimization techniques, and machine learning applications across robotics, autonomous systems, and industrial automation. They address key challenges in pose estimation, predictive control, networked systems, and fault-tolerant designs, driving innovations that bridge theoretical development and practical implementation. The success of ICCAS 2024 reflects the dedication of our research community and the continued pursuit of excellence in our field. We extend our sincere gratitude to all contributors, reviewers, and attendees whose efforts made this forum possible.We invite you to explore the articles in this special issue, which present novel ideas and solutions poised to shape the future of control, automation, and systems engineering. The IJCAS editorial board remains committed to identifying and publishing outstanding research from future editions of ICCAS, further strengthening the collaboration between the conference and the journal."
인공지능 기술과 창작 패러다임 변화에 관한 연구,2025,"['인공지능', '생성형AI', '융복합 예술창작', '예술가 역할', '창작패러다임', 'Artificial Intelligence', 'Generative AI', 'Convergence Artistic Creation', 'Artist’s Role', 'Creative Paradigm']",,"This study begins with the question of what role artificial intelligence (AI) technology, which is driving social transformation, will play in the field of creativity.The purpose of this research is to explore how AI is not merely a technological tool but a force that can reshape perceptions of art. Accordingly, this paper examines changes in creative processes and the evolving position of artists. The research findings are as follows: first, the transformation of creative processes; second, the expansion of the artist’s role; and third, the possibility of new forms of artistic expression. These findings serve as a starting point for further research. The application of AI technology is expected to enhance the characteristics of media and bring about changes in the meaning of creativity, necessitating further study on this subject.The research methodology follows these steps. First, the study analyzes how AI has influenced the evolution of creative processes. It explores how computational image generation, based on algorithmic thinking, has expanded with advancements in machine learning techniques.Second, the study examines how AI is reshaping the concepts of creativity and artistic creation. It compares traditional notions of creativity with AI-driven reasoning and questions whether creativity should be defined simply by the novelty of its outcomes or understood as a more complex process.Third, the study discusses the rise of generative AI and the democratization of creative practices. As AI progresses beyond a mere assistive function to play a crucial role in the creative process, the definition of creativity itself is undergoing a transformation. This shift underscores the need for legal and ethical awareness, and this research aims to lay the groundwork for such discussions."
한국 노인 대상 건강·돌봄 분야 인공지능 연구동향 분석: 주제범위 문헌고찰,2025,"['Older Adullts', 'Artificial Intelligence', 'Healthcare', 'Scoping Review', '노인', '인공지능', '건강', '돌봄', '주제범위 문헌고찰']","본 연구는 한국 노인을 대상으로 한 인공지능 관련 실증 연구의 주제와 주요 결과를 분석하고 종합하여, 연구동향을 파악하고 후속연구를 제언하는 것을 목적으로 하였다. Arksey와 O’Malley(2005)의 방법론에 따라 주제범위 문헌고찰을 수행하였으며, 국내외 데이터베이스(RISS, KISS, KMbase, PubMed, Web of Science)를 활용하여 최종적으로 36편의 문헌을 선정하였다. 선정 문헌들은 인공지능 중재, 수용성, 예측 분석 연구로 분류되었다. 첫째, 인공지능 중재 연구는 모두 로봇을 활용한 연구였으며, 로봇을 통해 제공되는 프로그램, 중재 기간, 회기 당 중재 시간이 연구마다 다양하였다. 다수의 연구가 중재의 효과로 우울, 외로움 등 정신건강과 일상생활 수행 능력 등의 신체기능을 측정하였으며, 우울 감소와 일상생활 수행 능력 향상에는 긍정적인 영향을 미쳤으나 인지 기능 등 일부 건강 결과에서는 일관되지 않은 결과를 보였다. 둘째, 인공지능 기반 어플리케이션, 로봇, 스피커 등의 수용성 연구는 편의 표본을 사용하여 지역사회에 거주하거나 시설에 방문하는 노인을 대상으로 설문조사를 진행하였다. 보고된 주요 촉진 요인은 유용성, 용이성, 사회적 지지, 주관적 건강 상태, 헬스 리터러시 등이었다. 셋째, 인공지능 기반 예측 분석 연구는 병원, 패널, 조사 데이터를 바탕으로 머신러닝과 딥러닝 기법을 활용해 지역사회 노인의 질병이나 건강 상태를 예측하였다. 본 연구는 한국 노인을 대상으로 한 건강과 돌봄 분야의 인공지능 연구 동향을 종합적으로 고찰하고 분석하였으며, 2020년 이후 이러한 연구가 빠르게 증가하고 있고 연구 주제의 다양성 및 방법론적 엄밀성 측면에서 더 많은 발전이 필요함을 시사한다. 향후 다양한 인공지능 기반 건강·돌봄 서비스와 제품에 대한 다면적 평가 연구, 노인-돌봄자 참여형 중개 연구 방법론 및 현장 적용 연구, 그리고 건강·돌봄 관련 윤리, 법적 및 사회적 이슈를 다루는 연구 등의 후속연구를 제안한다.","This study aims to analyze empirical research on artificial intelligence(AI) related to the elderly in Korea, identifying trends and proposing future research directions. A scoping review was conducted following Arksey and O'Malley’s methodology, utilizing 5 databases—RISS, KISS, KMbase, PubMed, and Web of Science—to select 36 studies. Interventions studies, primarily involving robots, showed positive effects on mental health outcomes like reducing depression, though cognitive outcomes were inconsistent. Acceptability studies highlighted factors such as usefulness, ease of use, and social support. Predictive analysis research utilized hospital, panel, and survey data, applying machine learning and deep learning techniques to predict health conditions and disease prevalence. Based on these findings, this study proposes future research focus on multi-dimensional evaluations of AI-based health services, implementation research, and the exploration of ethical, legal, and societal issues."
TOC 농도 추정을 위한 최적 수질 인자 및 모델 선정,2025,"['Seunggi-stream', 'TOC prediction', 'Pearson correlation analysis', 'exhaustive search', 'water quality factors', 'MLP artificial neural network', '승기천', 'TOC 예측', '피어슨 상관 분석', '완전 탐색', '수질 인자', 'MLP 인공신경망']","수질 예측은 수질 환경 관리에서 가장 중요한 요소로, 최근 다양한 기계 학습 및 딥러닝 기법을 활용한 연구가 활발히 이루어지고 있다. 환경부에서 유기물질 측정 지표를 CODmn에서 TOC로 전환하는 등 TOC에 대한 중요성이 증대됨에 따라 본 연구는 인천광역시 연수구 승기천을 대상으로 TOC 농도 예측 모델 생성을 위한 최적 입력 변수 및 예측 모델을 제안하는 것을 목표로 한다. 최적 입력 변수 선정은 Pearson 상관도 분석과 Exhaustive Search를 통해 도출하였으며, 최적 예측 모델은 회귀분석, 다층 퍼셉트 론(MLP) 인공신경망, 랜덤포레스트 모델의 정확도를 비교하였다. 모델 성능 비교 결과 T-N, DTN, NH3-N, BOD, NO3-N을 입력 변수로 사용하는 MLP 모델이 가장 우수한 성능을 보였으며, R² 값 0.6280과 RMSE 0.8656의 결과를 기록하였다. 본 연구는 승기천의 TOC 농도 예측을 위한 최적의 입력 변수를 제안함과 동시에, 앞서 언급한 다섯 가지 주요 수질 인자를 활용한 MLP 모델이 유사한 특성을 가진 다른 하천에서 도 TOC 예측에 높은 신뢰도를 제공할 수 있다는 가능성을 제시한다.","Water quality prediction is a key factor in water environment management, with growing interest in utilizing machine learning and deep learning techniques. As the Ministry of Environment transitions the organic matter measurement indicator from CODmn to TOC, the importance of TOC has significantly increased. This study aims to propose optimal input variables and a prediction model for TOC concentration in Seunggi- Stream, Yeonsu-gu, Incheon. Input variables were derived using Pearson correlation analysis and Exhaustive Search. The prediction models tested include Regression Analysis, Multi-Layer Perceptron (MLP) Neural Networks, and Random Forest. Among them, the MLP model using T-N, DTN, NH3-N, BOD, and NO3-N as input variables showed the best performance, achieving an R² of 0.6280 and an RMSE of 0.8656. This study identifies optimal input variables for TOC prediction and suggests that the MLP model can provide reliable TOC predictions for streams with similar characteristics."
Surface Drifters and Ocean Dynamics: A Review of Technological Advancements and Scientific Contributions,2025,['Drifter\xa0· Surface current\xa0· Surface drift\xa0· Wind-driven and geostrophic currents'],,"This review paper examines the technological evolution, applications, and scientifc achievements of surface drifters in measuring ocean currents. Since their inception in the mid-twentieth century, drifters have developed from simple foating devices to sophisticated instruments equipped with GPS and various environmental sensors. After succeeding the WOCE Surface Velocity Program, the Global Drifter Program has played a crucial role in maintaining a worldwide network of these platforms, signifcantly advancing our understanding of ocean dynamics and providing real-time data for multiple applications. At the same time, interpretation of drifter trajectories faces challenges including separation of the signal on currents, wave-induced motion, efects of vertical shear and down-wind slippage as well as changes of geometry due to drogue loss, biofouling, and design modifcation. This review discusses ongoing eforts to address these issues through improved drifter designs and data processing techniques. It also explores future directions, including the integration of drifter data with other observing systems and the application of machine learning to the data analysis. Key scientifc fndings from drifter observations include the outlining of the large-scale ocean surface circulation and in such dynamically important regions as the Equatorial Pacifc, quantifcation of wind-driven currents, providing a reference for high-resolution mapping of mean dynamic topography, and improved understanding of boundary current systems, eddies and convergence zones. Drifters have also been instrumental in studying ocean dispersion, connectivity, and extreme events such as hurricanes."
단일 분자화합물의 폐 발암성 예측을 위한 그래프 신경망 접근법,2025,"['GAT', 'GCN', '폐암', '발암물질', '어텐션 메커니즘', '인실리코 예측', 'GAT', 'GCN', 'lung cancer', 'carcinogen', 'attention mechanism', 'in silico prediction']","암은 전 세계적으로 매년 수백만 명의 사망자를 초래하는 주요 질환 중 하나로, 특히 폐암은 2022년 한국에서 암 중 가장 높은 사망률을 기록했다. 이에 따라 폐암을 유발하는 화합물에 대한 연구가 필수적이며, 본 연구는 기존 기계학습 및 딥러닝 방법의 한계를 극복하고, 그래프 신경망을 활용하여 폐암 유발 가능성을 예측하는 새로운 접근방식을 제안하고 평가했다. 화합물 발암성 데이터베이스인 CPDB, CCRIS, IRIS, T3DB의 SMILES(Simplified Molecular Input Line Entry System) 정보를 기반으로 분자의 구조와 화학적 성질을 그래프 데이터로 변환해 학습했으며, 제안된 모델은 다른 모델 대비 우수한 예측 성능을 보였다. 이는 폐암 예측에 효과적인 도구로서 그래프 신경망의 잠재력을 입증하며, 향후 암 연구와 치료 개발에 중요한 기여를 할 수 있음을 시사한다.","Cancer is one of the major diseases causing millions of deaths worldwide every year, and lung cancer has been recorded as the leading cause of cancer-related deaths in Korea in 2022. Therefore, research on lung cancer-causing compounds is essential, and this study proposes and evaluates a novel approach to predict lung cancer-causing potential using graph neural networks to overcome the limitations of existing machine learning and deep learning methods. Based on SMILES(Simplified Molecular Input Line Entry System) information from the compound carcinogenicity databases CPDB, CCRIS, IRIS and T3DB, the structure and chemical properties of molecules were converted into graph data for training, and the proposed model showed superior prediction performance compared to other models. This demonstrates the potential of graph neural networks as an effective tool for lung cancer prediction and suggests that they can make important contributions to future cancer research and treatment development."
Enhancing QA System Evaluation: An In-Depth Analysis of Metrics and Model-Specific Behaviors,2025,"['question answering systems', 'evaluation metrics', 'natural language processing', 'transformer models', 'BERT']",,"The purpose of this study is to examine how evaluation metrics influence the perception and performance of question answering (QA) systems, particularly focusing on their effectiveness in QA tasks. We compare four different models: BERT, BioBERT, BioClinicalBERT, and RoBERTa, utilizing ten EPIC-QA questions to assess each model's answer extraction performance. The analysis employs both semantic and lexical metrics. The outcomes reveal clear model-specific behaviors: Bio-ClinicalBERT initially identified irrelevant phrases before focusing on relevant information, whereas BERT and BioBERT continually converge on similar answers, exhibiting a high degree of similarity. RoBERTa, on the other hand, demonstrates effective use of long-range dependencies in text. Semantic metrics outperform lexical metrics, with BERTScore attaining the maximum accuracy (0.97), highlighting the significance of semantic evaluation. Our findings indicate that the choice of evaluation metrics significantly influences the perceived efficacy of models, suggesting that semantic metrics offer more nuanced and insightful assessments of QA system performance. This study contributes to the field of natural language processing and machine learning by providing guidelines for selecting evaluation metrics that align with the strengths and weaknesses of various QA approaches."
Monitoring Postharvest Ethylene Emissions in Fresh Produce: Potential of Metal Oxide Semiconductor-Based Gas Sensors,2025,"['Postharvest Monitoring', 'Ethylene Sensing', 'Metal Oxide Semiconductor Sensors', 'Response Enhancement', 'Selectivity Enhancement']",,"Ethylene is a key plant hormone that regulates the ripening and senescence of fresh produce. Although it is essentialfor maturation, its presence also accelerates deterioration, leading to quality loss and food waste. Real-time ethylene monitoring iscrucial for optimizing postharvest management and extending shelf life in storage and distribution networks. Among the various gassensing technologies, metal oxide semiconductor (MOS)-based sensors have emerged as a promising solution owing to their highresponse, simple structure, and cost-effectiveness. However, detecting ethylene in complex postharvest environments remains challengingbecause of its low reactivity and cross-sensitivity to interfering gases. This review explores advancements in modern ethylenesensor technologies, with a particular focus on MOS-based ethylene sensors. Key strategies for enhancing sensor response and selectivityare examined, including nanostructuring, catalyst decoration, composite material development, and bilayer film fabrication.Additionally, the integration of sensor arrays and machine learning techniques for precise real-time ethylene detection is discussed.By addressing existing challenges and recent innovations, this review provides valuable insights into MOS-based ethylene sensingand offers guidance for the development of next-generation sensors. These advancements hold significant potential for improvingpostharvest management, reducing food waste, and enhancing supply chain efficiency in fresh produce distribution networks."
인공지능과 미술교육: 인공지능 창작물의 저작권 교육내용 탐색,2025,"['인공지능', '생성형 인공지능', '저작권', '미술교육', 'artificial intelligence', 'generative artificial intelligence', 'copyright', 'art education']","인공지능을 활용한 창작물은 인간과 기계의 노력이 서로 합쳐서 나온 결과이기에 저작권 문제에서는 더욱 복잡한 양상을 띤다. 본 연구의 목적은 문헌 연구를 통해 인공지능 창작물 관련한 저작권에 대한 법규 및 논의를 살펴 이를 교육에 어떻게 적용할 수 있을지를 탐색하는 데 있다. 인공지능 창작물에 대한 법적인 논의 사례를 검토한 결과 현재까지는 인공지능을 활용한 경우 인간이 창조한 부분만을 저작물로 인정하는 것이 대부분이었다. 그렇지만 생성형 인공지능의 기술적 발전, 사용 방법과 판단 근거에 따라 저작권 인정 여부에 대한 다양한 논의가 진행 중이다. 논문에서는 창작물의 기술적, 예술적 특성을 살펴보게 해주면서 저작권 인정 여부에 관한 판단 근거를 제공해주는 일곱 가지 관점을 도출하여 논의해보았다. 저작권 개념, 인공지능 창작물의 저작권 논의라는 교육내용은 미술과 교육과정과 연계하며 인공지능 미술의 창작 상의 특성과 미술의 역사적 변화를 깊이 있게 살펴볼 기회를 제공하는 중요한 학습 내용이다. 아울러 다양한 논점에 대한 토의 활동을 통해 더욱 확대된 인문 교육을 할 수 있다. 이러한 교육내용을 포함함으로써 인공지능을 활용한 제작 활동 중심의 교육에서 나아가 더욱 체계적인 인공지능 미술교육 구현을 기대할 수 있다.","Creative works using artificial intelligence are the result of a combination of human and machine efforts, so copyright issues are more complex. The purpose of this study is to examine the laws and discussions on copyright related to AI-created works through literature review and explore how they can be applied to education. As a result of reviewing legal discussions on AI-based works, it was found that, to date, in most cases where AI is used, only the part created by humans is recognized as a work. However, various discussions are underway on whether copyright should be recognized depending on the technological development of generative artificial intelligence, the method of use, and the basis for judgment. The study discussed seven perspectives that provide a basis for judging whether copyright is recognized or not while examining the technical and artistic characteristics of creative works. The training contents, which discuss the concept of copyright and the copyright of AI-created works, is an important learning contents that provide an opportunity to deeply examine the creative characteristics of AI art and the historical changes in art while linking it to the art curriculum. In addition, it is valuable learning contents that can provide expanded humanities education through discussion activities on various issues. By including these training contents, we can expect to move beyond education centered on production activities and implement more systematic artificial intelligence art education."
빅데이터를 활용한 관광 분야 연구 동향 분석: 토픽모델링을 중심으로,2025,"['관광 연구', '빅데이터', '토픽모델링', '연구 동향 분석', 'Tourism Research', 'Big Data', 'Topic Modeling', 'Research Trend Analysis']",,"Purpose – This study aims to identify major topics and changes in topics and relationships between topics in tourism big data research by applying BERT-based topic modeling to academic paper titles, and to suggest future research directions and practical implications.Design, data, and methodology – This study collected 4,951 tourism big data-related titles(2019–2023) from Google Scholar, applied BERTopic after preprocessing, and visualized topic clusters using intertopic distance maps to analyze temporal and structural trends.Result – The core topics were digital transformation, performance analytics, consumer experience, and spatial analytics. After COVID-19, the research expanded to include topics such as sustainability, recovery, wellness tourism, and AI. By 2023, the subject structure had become more complex and interconnected, and methodological shifts from machine lear ning to deep learning reflected qualitative changes in tourism big data research.Conclusions – This study confirms that tourism big data research has evolved with technological and socio-environmental changes, driving new research themes and supporting evidence-based policy and strategy development. It also highlights the efficiency of BERTopic over traditional methods and the need for systematic training to effectively implement such techniques in tourism research."
PISA 2022 한국⋅싱가포르⋅마카오의  수학 학업성취도 예측요인 비교,2025,"['International Comparison of Academic Achievement', 'Random Forest', 'Key Predictors of Academic Achievement', 'PISA 2022', '학업성취 예측', '학업성취 국제비교', '랜덤 포레스트', '학업성취 주요 예측요인', 'PISA 2022']",,"Objectives  Despite the international recognition of Korea's education system, the mathematics achievement level of Korean students has been gradually declining compared to that of Singapore and Macau (OECD, 2023). This study aims to identify the factors contributing to the differences in mathematics achievement between Korea, Singapore, and Macau in order to address this phenomenon.Methods  Since traditional statistical analysis methods face limitations in incorporating a large number of variables, this study employed Random Forest analysis to develop a predictive model for mathematics achievement among students in Korea, Macau, and Singapore. The study utilized student data from PISA 2022, setting ten plausible values (PVs) as the dependent variable to measure students' mathematics achievement levels. Independent vari ables included various factors potentially influencing academic achievement. a total of 247 variables were included in the final analysis.Results  The analysis revealed that Mathematics Self-Efficacy was the most significant predictor of mathematics achievement in all three countries. Additionally, Total Number of Class Periods per Week emerged as a key pre dictive factor. Furthermore, Frequency of ICT Activity was also identified as a significant predictor. Specifically, ""Frequency of ICT Activity"" and ""Use of ICT in Enquiry-Based Learning Activities"" were found to be important pre dictors of mathematics achievement in Korea, indicating the potential for ICT usage to enhance academic performance.Conclusions  This study provides academic and practical implications by utilizing machine learning techniques to compare and analyze mathematics achievement in PISA 2022 among Korea, Singapore, and Macau. It identifies key predictive factors of academic achievement and proposes policy directions to mitigate Korea’s declining mathematics performance. The findings contribute not only to the development of an effective, customized edu cation system to improve Korean students' mathematics achievement but also serve as valuable foundational data for addressing educational disparities across countries and shaping future education policies."
Critical buckling analysis of functionally graded porous beam using Karush-Kuhn-Tucker conditions,2025,"['aspect ratio', 'dimensionless critical buckling', 'functionally graded porous beam', 'gradient index', 'higher order shear deformation theory', 'Karush-Kuhn-Tucker conditions', 'porosity']",,"Functionally graded porous beams (FGPB) are structural components engineered to enhance mechanical performance by customized material gradation and porosity distribution. The present study examines the buckling analysis of FGPB modelled using Higher-order shear deformation theory. The governing equations are formulated via Hamilton's principle and solved utilizing Karush-Kuhn-Tucker conditions. The analysis utilizes gradient indices (P<sub>x</sub>, P<sub>z</sub>), porosity distributions (even and uneven) and porosity indices to assess their influence on the dimensionless critical buckling loads under various boundary conditions, including Simply Supported (SS), Clamped-Simply supported (CS), Clamped-Clamped (CC), and Clamped-Free (CF). In line with this, the results show that an increase in P<sub>x</sub> led to a decrease in the buckling load from 51.342 when P<sub>x</sub>=0 to 8.811 when P<sub>x</sub>=5 under the SS boundary conditions. Likewise, with increase in P<sub>z</sub> the buckling load was reduced from 51.342 to 13.351. Uneven porosity consistently exhibited higher dimensionless critical buckling as compared to even porosity. Under CC boundary conditions, the dimensionless critical buckling load was 151.970 and 196.587 for even and uneven porosity distribution at P<sub>x</sub>=0 and P<sub>z</sub>=0. Among the boundary conditions, CC demonstrated the highest stability, with a dimensionless critical buckling load of 151.970, succeeded by CS (101.656), SS (51.342), and CF (13.175). These results prove the ability of the outlined methodology with errors less than 5% compared to literature. This study emphasizes the significance of material gradation and porosity in structural stability and presents a comprehensive method for designing innovative lightweight structures. Future studies may consider Machine Learning based predictive modeling for complex geometries."
합성곱 신경망을 이용한 펄스와전류 결함분류 실험에서의 이미지화 알고리즘 성능 검증,2025,"['Magnetic sensor', 'Pulsed eddy current', 'Artificial Inteligence', 'Convolutionary neural network', 'Image algorithm', 'Time series data', '자기센서', '펄스와전류', '인공지능', '합성곱 신경망', '이미지화 알고리즘', '시계열 데이터']","실험 데이터를 인공지능을 활용하여 분류하는 과정에서 시계열 데이터를 이미지로 변환한 후 AI 알고리즘을 적용하는 것이 필수적이다. 본 연구에서는 펄스 와전류(PEC) 실험에서 결함을 효과적으로 분류하기 위해 컨볼루션 신경망 기반 AI 이미지 알고리즘을 사용하였다. PEC 실험을 통해 획득한 시계열 데이터를 활용하여 다양한 이미지 변환 알고리즘의 성능을 비교하였다. PEC기술은 절연체 하의 부식(CUI)으로 인해 발생하는 결함을 감지하는 데 사용되며, 이를 모사하기 위해 10인치 두께의 배관을 5단계 계단 형상으로 가공한 후 50 ㎜ 두께의 단열재를 적용하였다. 본 연구에서는 연속 웨이블릿 변환(CWT), 그래미안 각도 합산 필드(GASF), 그래미안 각도 차이 필드(GADF), 마르코프 전이 필드(MTF), 순환 플롯(RP) 등 다섯 가지 이미지 변환 알고리즘을 평가하였다. ResNet50 신경망 모델을 활용하여 Validation Loss 및 Test Loss를 학습 지표로 삼아 각 알고리즘의 성능을 분석하였다. 분석 결과, CWT 알고리즘이 결함 분류에서 가장 우수한 성능을 보임을 확인하였다. 본 연구는 AI 기반 결함 검출 기술의 정확도를 향상시키기 위한 다양한 이미지 변환 접근법을 비교하고 최적의 알고리즘을 도출하는 데 기여할 것으로 기대된다.","The classification of experimental data using artificial intelligence requires the transformation of time series data into images before applying AI algorithms. This study explores defect classification in pulsed eddy current (PEC) experiments through a convolutional neural network-based AI imaging algorithm, which processes defect information presented in serial format. Time series data obtained from PEC experiments were analyzed to compare the performance of various imaging algorithms. PEC is widely employed to detect defects caused by corrosion under insulation (CUI). To simulate CUI conditions, a 10-inch-thick pipe was machined into a five-step configuration and covered with 50 ㎜ of insulation. Five imaging algorithms—Continuous Wavelet Transform (CWT), Gramian Angular Summation Field (GASF), Gramian Angular Difference Field (GADF), Markov Transition Field (MTF), and Recurrence Plot (RP)—were evaluated. The ResNet50 neural network model was utilized to assess the performance of these algorithms using Validation Loss and Test Loss as learning indicators. Among the five imaging methods, the CWT algorithm demonstrated superior performance in defect classification. This study contributes to enhancing AI-driven defect detection techniques by evaluating different imaging transformation approaches and identifying the optimal algorithm for improved classification accuracy."
원격탐사기법을 활용한 소나무재선충병 감염의심목 예찰 가능성 평가,2025,"['Forest remote sensing', 'Orthophoto', 'Satellite image', 'NDVI', 'Pine wilt disease']",,"This  study  aimed  to  detect  the  pine  wilt  disease  using  remote  sensing  techniques  in Yuseong-gu, Daejeon, Korea, where the disease first occurred in 2024. A vertical take-off and landing unmanned aerial vehicle was used to produce orthoimages with a resolution of 6.7cm, and tree species were identified through texture analysis. A random forest algorithm was applied to the orthoimages, identifying 46 suspected cases of pine wilt disease. Based on these results, a field survey was conducted to verify accuracy, confirming that 33 out of the 46 suspected trees were infected, resulting in an accuracy of 71.7%. The Normalized Difference  Vegetation  Index  (NDVI)  was  compared  to  evaluate  the  feasibility  of  using medium-resolution satellite imagery from April to November 2024. A decrease in maximum and  average  NDVI  values  was  observed  in  August  compared  to  June,  suggesting  disease progression  or  tree  mortality.  However,  there  was  no  statistically  significant  difference detected in the summer images (June to October) (p>0.05), and the resolution (10×10m) was considered relatively low for determining the normalized vegetation index of an individual tree. Therefore, it is concluded that the detection of pine wilt disease using orthoimagery is feasible even in newly affected areas, while satellite imagery can be effectively utilized for large-scale damage assessment but may be insufficient for detecting individual trees. To enhance these results, increasing the number of training datasets for machine learning and acquiring  high-resolution  images  using  multispectral cameras  will  be  necessary  for  more precise vegetation index analysis."
해양 탄성파탐사 자료의 순간주파수를 활용한 해저 퇴적물 분류,2025,"['Marine Seismic Survey', 'Sub-Bottom Profiler', 'Instantaneous Frequency', 'Seafloor', 'Sediment Classification']",,"This study applied an instantaneous frequency analysis technique to evaluate seabed materials using sub-bottom profiler (SBP) data from a marine seismic survey. The seafloor is composed of various sediments and bedrock, each exhibiting different acoustic reflection and attenuation characteristics. Previous research mainly used amplitude attenuation or reflection coefficients to classify sediments. In contrast, this study focused on the variation of instantaneous frequency to improve the accuracy of sediments classification. To achieve this, the energy envelope of the reflected wave was extracted, and the Hilbert transform was used to calculate instantaneous frequency. The results showed that bedrock exhibited primary reflected wave frequencies ranging from 300 to 700 Hz, with distinctive W-shaped and M-shaped patterns. Sandy sediments had slightly higher frequencies between 500 and 800 Hz, also forming W- and M-shaped patterns. Muddy sediments displayed a central frequency near 800 Hz; however, secondary reflections were unclear, and significant signal attenuation was observed due to high water content and low porosity. These findings demonstrate that instantaneous frequency analysis enhances the interpretation of marine seismic data and enables more precise evaluation of seafloor materials compared to traditional amplitude-based methods. The technique supports applications such as offshore construction site investigation, seabed environmental assessment, and marine resource exploration. Future research should explore machine learning and data fusion approaches to develop automated classification systems and validate them across diverse marine environments for broader reliability."
인공지능 기반 고용서비스의 통계적 차별 가능성 연구:잡케어 시스템을 중심으로,2025,"['digitalisation in PES', 'statistical discrimination', 'Artificial Intelligence(AI)', 'algorithms', '디지털 고용서비스', '통계적 차별', '인공지능', '알고리즘']","한국의 디지털 고용서비스 정책은 전 세계적으로 유래가 없을 정도로 빠르게 발전하고 있다. 2021년 도입된 잡케어 시스템은 인공지능이 빅데이터를 기계학습한 결과를 개인정보와 결합하여 구직자 맞춤형 고용서비스를 제공한다. 이에 본 연구는 인공지능 기반 고용서비스 정책이 야기할 수 있는 통계적 차별의 가능성을 분석하고 대응방안을 모색해 본다. 분석을 위해 정책결정의 주체를 전문가, 알고리즘 및 인공지능으로 구분한 뒤, 정책결정의 주체에 따른 차별의 매개체를 분석하고 이를 고용서비스에 적용한다. 분석결과에 따르면 잡케어 시스템은 알고리즘의 사용, 제한된 자료의 기계학습 등으로 인해 통계적 차별의 가능성을 본질적으로 내재하고 있다. 따라서 통계적 차별을 최소화하기 위해 인공지능의 분석결과를 지속적으로 모니터링하고, 인공지능이 분석할 양질의 자료를 확보하고 갱신해야 한다. 또한 인공지능 기반 고용서비스의 정책결정을 직업상담사가 보완하여 고용서비스의 효과성을 높일 수 있는 대책을 마련해 나가야 한다. ㅍ","Digitalisation in Public Employment Services(PES) in Korea is unprecedentedly fast around the world. The JobCare system using the Artificial Intelligence(AI) has been introduced in 2021 to provide customized employment services for jobseekers. This study analyzes whether PES using AI systems causes statistical discrimination and how to address its potential risks. This paper classifies the subjects of decision-making in PES into experts, algorithms, and the AI, and then analyzes the medium of discrimination by the subject. According to the main results, the JobCare system can lead to statistical discrimination due to the use of algorithms and machine learning of limited data. Therefore, in order to minimize the risk of statistical discrimination, it is necessary to continuously monitor the analysis results of the AI systems, and secure and update high-quality data for the AI systems to analyze. In addition, job counselors should supplement decisions of the AI systems to come up with policy measures to increase the effectiveness of the PES."
An Ensemble-Based Hybrid Data Drift Detection Framework Integrating Principal Component Analysis (PCA) and Variational Autoencoder (VAE),2025,"['Data Drift', 'Principal Component Analysis', 'Autoencoder', 'Feature Space', 'Ensemble Model']",,"This paper presents a novel hybrid data drift detection framework, the Ensemble Modeling-based Hybrid Drift Score (EM-HDS), that integrates Principal Component Analysis (PCA), Variational Autoencoders (VAEs), and ensemble modeling to effectively detect both global structural shifts and localized non-linear variations in feature space. PCA identifies global changes by monitoring variance alignment and principal component transformations, while VAEs enhance sensitivity to localized anomalies through probabilistic modeling of reconstruction errors. The EM-HDS framework integrates complementary techniques using a Random Forest ensemble model, effectively capturing complex, non-linear relationships between PCA and VAE metrics.Experimental evaluations on synthetic datasets with simulated drift and real-world COCO image features demonstrate the robustness and adaptability of the proposed method. EM-HDS delivers superior drift detection performance, significantly improving detection accuracy, particularly in scenarios involving simultaneous global and local drifts, surpassing standalone PCA and VAE approaches. Although the framework requires careful tuning of hyperparameters to adapt to specific datasets, its ability to dynamically adjust to diverse drift patterns makes it a practical and effective solution for real-time monitoring and adaptation in dynamic environments. This research establishes a strong foundation for enhancing the reliability of machine learning models in complex, real-time applications for future work."
3D 컴퓨터 그래픽을 위한 생성형 AI의활용에 관한 연구,2025,"['3D 컴퓨터 그래픽', '생성형 AI', '3D Computer Graphics', 'Generative AI']","최근 AI를 둘러싸고 전 세계가 패권 전쟁을 시작한 가운데 생성형 AI는 예술 분야의 패러다임을 변화시키고 있다. 달리(DALL-E), 미드저니(Midjourney), 스테이블 디퓨젼(Stable Diffusion) 그리고 파이어플라이(Firefly) 등이 생성형 AI의 대표주자로서 예술 분야에 획기적인 변화를 불러일으키고 있다. 이렇게 생성형 AI가 딥러닝 및 기계 학습을 기반으로 3D 컴퓨터 그래픽 분야의 발전에도 크게 기여하고 있는 상황에서 생성형 AI에 관한 연구의 필요성은 더욱 요구되고 있다. 현재 생성형 AI에 관한 많은 연구들이 진행되고 있지만 3D 컴퓨터 그래픽의 제작에 있어 제작 과정을 단계별로 구분하고 이러한 단계별 구분에 맞춘 생성형 AI의 활용에 대한 연구는 부족한 상황이다. 이에 본 연구는 3D 컴퓨터 그래픽 제작의 분업화를 전제로 각 단계에 생성형 AI를 어떻게 활용할 수 있을지를 연구한다.본 연구는 3D 컴퓨터 그래픽을 위한 생성형 AI의 활용에 관한 연구로서 총 3개의 장으로 구성하고 서론 부분에서는 연구의 목적 및 배경에 대하여 논하였다. 본론에서는 3D 컴퓨터 그래픽 제작 과정을 모델링(Modeling), 맵핑(Mapping), 리깅(Rigging) 및 애니메이션(Animation), 그리고 라이팅(Lighting) 및 렌더링(Rendering)으로 나누고 각 단계에 생성형 AI를 어떻게 활용할 수 있는지를 살펴보았다. 연구 결과 아직 까지는 생성형 AI가 텍스트나 이미지를 기반으로 완성된 이미지를 제공하는 방식으로 개발되고 있기에 분업화된 회사나 개인 작업에는 적용하는 것에 많은 한계점이 있다는 것을 알았다. 따라서 본 연구는 이러한 한계점을 극복하기 위해 각 단계별로 생성형 AI를 어떻게 활용하고 어떤 방향으로 개발되어야 하는지를 고민해보았다.","Recently, as the world has begun a hegemonic war over AI, Generative AI is changing the paradigm of the art field. As representatives of Generative AI, DALL-E, Midjourney, Stable Diffusion, and Firefly are bringing about epoch-making changes in the art field. In a situation where Generative AI is contributing greatly to the development of the field of 3D computer graphics based on deep learning and machine learning, the need for research on this is increasingly required. Although many studies are currently underway in this situation, studies on the use of Generative AI tailored to this stageby- stage division of the production process in the production of 3D computer graphics are insufficient. Therefore, this study studies how Generative AI can be used at each stage on the premise of the division of labor in 3D computer graphic production.This study is a study on the use of Generative AI for 3D computer graphics and consists of a total of three chapters, and the purpose and background of the study are discussed in the introduction section.In the main article, the 3D computer graphic production process is divided into modeling, mapping, rigging, and animation, lighting and rendering, and how Generative AI can be used at each stage was examined. As a result of the study, since Generative AI is still being developed as a method of providing completed images based on text or images, it has been found that there are many limitations in applying it to divided companies or personal tasks. Therefore, in order to overcome these limitations, this study considered how to use Generative AI and in what direction it should be developed at each stage."
용수 공급의 지역별 우선순위 선정을 위한 평가 방법론 개발: 용수 대비 피해 민감도를 중심으로,2025,"['용수 대비 피해 민감도', '상대적 가뭄 피해 등급', '국가가뭄정보통계집', '금/영산/섬진강 유역', '용수 공급 우선순위', 'Damage Sensitivity to Water usage', 'Relative Drought Damage', 'National Drought Information Statistics', 'Geum/Yeongsan/Sumjin River basin', 'Water supply priority']","본 연구에서는 용수 대비 피해 민감도(Damage Sensitivity to Water usage, DSW)를 새롭게 정의하고, 가뭄 시 용수 공급의 지역별 우선순위를 결정하는 평가 방법론을 제안하였다. DSW는 용수 이용량에 따른 가뭄 피해의 변화를 수치로 표현한 값이며, DSW가 큰 지역은 용수 관리에 있어 우선적으로 고려해야 할 지역임을 의미한다. 연구 대상지역은 2018년부터 2021년까지 금/영산/섬진강 유역 내 시·군·구 단위의 행정구역으로 선정하였다. 본 연구에서는 DSW를 계산하기 위해 지도학습 기반의 회귀모형을 구축하고자, 3가지 주요 입력자료를 수집하였다. 기상학적 인자는 기상자료개방포털(https://data.kma.go.kr)의 기온, 강수량과 같은 지상관측자료, 지역적 특성 인자는 국가통계포털(https://kosis.kr)의 농업/생활/공업과 관련한 데이터로 구축하였다. 용수 이용량은 국가수자원관리종합정보시스템(http://www.wamis.go.kr)에서 제공하는 농업/생활/공업용수 이용량으로 활용하였다. 출력자료로는 가뭄 피해를 종합적으로 평가한 상대적 가뭄 피해 등급을 이용하였다. 이 등급은 국가가뭄정보통계집에서 조사한 가뭄 예·경보 횟수, 직접적 가뭄 피해정보, 가뭄으로 인한 용수 지원량을 바탕으로 지역별로 군집화한 결과이다. 이후, 입력자료와 출력자료는 지도학습 기반의 회귀모형을 학습시키는 데 활용되었다. 학습된 회귀모형은 농업/생활/공업용수 이용량이 50% 감소하거나 200% 증가한 조건에서의 지역별 상대적 가뭄 피해 등급을 산출하는데 적용되었다. DSW는 산출된 등급을 활용하여 계산하였고, 지역별로 순위를 매겼다. 그 결과, 농업용수에서는 전라남도 무주군, 생활 및 공업용수에서는 충청남도 계룡시와 전라남도 구례군이 대표적으로 DSW가 큰 지역으로 나타났다. 이를 통해, 농업/생활/공업용수에 따라 DSW가 큰 지역은 특정 용수의 관리가 필요한 지역으로 고려하였다. 본 연구에서 제안한 방법론은 향후 전국 단위에서 용수 공급 우선순위를 결정하는 지표로 활용될 수 있을 것으로 판단된다.","This study introduces Damage Sensitivity to Water usage (DSW) and proposes a methodology to prioritize regional water supply during drought periods. The DSW quantifies the impact of water usage on changes in drought damage by region, with higher indicating areas that should be prioritized for water management. The study focused on administrative districts within the Geum, Yeongsan, and Seomjin river basins from 2018 to 2021, calculating DSW for each region. To build a machine learning based regression equation, three types of input data were collected: meteorological factors from the KMA Weather Data Service, regional factors related to agriculture, domestic, and industry from the Korean Statistical Information Service, and water usage data from the Water Resources Management Information System. The output data, Relative Drought Damage, was derived from drought warnings, direct damage, and water support during droughts, as recorded by the National Drought Information Statistics. The regression model was then trained, and drought damage was estimated for each region under scenarios of 50% reduction and 200% increase in water usage. DSW was calculated based on the differences in results, and regions were ranked accordingly. Muju-gun, Jeollanam-do was identified as highly sensitive in terms of agricultural water, while Gyeryong-si, Chungcheongnam-do and Gurye-gun, Jeollanam-do were most sensitive for domestic and industrial water. Based on these results, regions with high DSW were considered as areas requiring management of specific water usage, depending on agricultural, domestic, or industrial water. This methodology provides a tool for setting regional water supply priorities at the national level."
k-평균 군집화 알고리즘을 활용한 지역별 고향사랑기부제 특성 분석,2025,"['고향사랑기부제', '지방자치단체 유형화', 'k-평균 군집분석', '주성분 분석', 'Hometown Love Donation Program', 'Local Government Classification', 'k-means Clustering', 'Principal Component Analysis', 'PCA-Biplot']","본 연구는 기계학습 기법을 활용하여 고향사랑기부제 시행 첫해인 2023년의 데이터를 기반으로 한국 지방자치단체를 유형화하는 것을 목표로 하였다. 주요 분석 방법으로 k-평균 군집분석과 주성분 분석(PCA)을 사용하였으며, 군집 수 산정을 위해 엘보우 기법과 대푯값 간 RMSE를 검토하여 최적의 군집 수를 8로 설정하였다. k-평균 군집분석 결과, 군집 1이 가장 많은 지방자치단체를 포함하고 있으며, 군집 2, 5, 7, 8은 10개 미만의 지방자치단체로 구성되었다. 군집별 특성을 분석하기 위해 주성분 분석과 PCA-Biplot을 활용하여 결과를 시각화하였고 변수들의 평균값을 표준점수로 정규화하여 비교하였다. 주성분 분석 결과, 첫 번째 주성분이 데이터의 분산을 대부분 설명하며, 군집들이 횡단적으로 분포하는 경향이 확인되었다. PCA-Biplot 시각화와 표준점수 분석을 통해 군집들이 주로 답례품 품목과 기부금 금액 변수에 영향을 받는 것으로 나타났으며, 군집 4의 기금사업 관련 변수들은 대부분 양의 값을 보였다. 본 연구는 고향사랑기부제에 대한 데이터 기반 분석을 통해 제도적 제언을 도출하였으며, 정책 도입 전 선행연구와는 차별화된 실증 분석을 제공하였다. 연구의 한계로는 첫해 데이터의 부족과 변수의 다양성 부족이 있으며, 향후 연구에서는 답례품의 질, 배달 현황, 기부자 감사 편지, 기금사업 진행 상황 등 추가 변수를 고려한 심층분석으로 이어질 수 있다.","This study aims to classify South Korean local governments based on data from the first year of the Hometown Love Donation Program in 2023 using machine learning techniques. The primary analytical methods employed are k-means clustering and Principal Component Analysis (PCA). To determine the optimal number of clusters, both the Elbow Method and RMSE of cluster centroids were examined, leading to the selection of 8 clusters as the optimal number. The k-means clustering analysis revealed that the first cluster contains the largest number of local governments, while clusters 2, 5, 7, and 8 include fewer than 10 local governments each. To further analyze cluster characteristics, PCA and PCA-Biplot were performed, with variables normalized using Z-scores for comparison. The PCA results indicated that the first principal component explains most of the data variance, with clusters showing a cross-sectional distribution. PCA-Biplot and Z-score analyses demonstrated that clusters are primarily influenced by variables related to gift items and donation amounts, with the fourth cluster exhibiting predominantly positive values for fund allocation variables. This study provides data-driven insights and institutional recommendations for the Hometown Love Donation Program, distinguishing itself from prior studies through empirical analysis. Limitations include the focus on data from only the first year of the program and a limited range of variables. Future research should consider additional factors such as gift quality, delivery status, donor thank-you notes, and fund utilization to offer a more comprehensive classification of local governments."
단열재를 사용하는 파이프 배관의 효율적인 누설 탐지 기술,2025,"['leak detection', 'pipe systems', 'rigid guide tube', 'signal processing', '.']","냉각 파이프 시스템에서 누설 감지는 안전성과 운영 무결성을 유지하는 데 중요하다. 기존의 누설 감지 방법으로는 음향 방출 센서와 분광법이 있으나, 복잡한 파이핑 시스템에서는 감도, 응답 시간, 그리고 정확한 누설 위치 파악에 한계가 있다. 본 연구에서는 반응로 냉각 파이프 주변의 단열층 내에 견고한 가이드 튜브를 설치하고, 개선한 주파수 중심 이동 계산법과 새로운 신호 대 잡음비 분석을 통한 진보된 감지 기준을 결합한 새로운 누설 감지 방법을 제안하여 저비용, 고효율의 탐지기술을 구현한다. 실험 평가는 이 시스템의 효율성을 보여주며, 현재 단열 배관 누출 탐지 기술에 새로운 가치를 입증한다. 향후 연구는 기계 학습 기술을 사용하여 주요 매개 변수들을 최적화하고, 임계 주파수 변화(Δf)와 무작위로 선택된 주파수 수(N)를 조정함으로써 다양한 환경에서 시스템의 정확도와 신뢰성을 더욱 향상시킬 것이다.","Leak detection in cooling pipe systems is crucial for maintaining safety and operational integrity. Traditional leak detection methods, such as acoustic emission sensors and spectroscopy, have limitations in sensitivity, response time, and accurate localization of leaks, especially in complex piping systems. This study proposes a new leak detection method that installs a rigid guide tube within the insulation layer surrounding reactor cooling pipes and combines an improved frequency center of gravity calculation method with a new signal-to-noise ratio analysis to create a cost-effective and efficient detection technology. Experimental evaluations demonstrate the efficiency of this system and validate its new value to the current insulated piping leak detection technologies. Future research will focus on optimizing key parameters, such as the threshold frequency shift (Δf) and the number of randomly selected frequencies (N), using machine learning techniques to further enhance the system’s accuracy and reliability in various environments."
AI 학습용 데이터의 특허 보호 방안,2025,"['AI', '데이터', '데이터셋', '데이터구조', '청구항', '물건발명', '기술분야별 심사실무가이드', 'AI', 'data', 'data set', 'data structure', 'claim', 'product invention', 'Technical Examination Practice Guide']","이 글은 청구항의 말미에 발명의 카테고리로 기재된 「…데이터」, 「…데이터셋」 또는 「…데이터구조」가 특허법 상 물건발명의 카테고리로 특정될 수 있는 것인지를 검토하고, 데이터의 생성·수집·전송·저장·관리 방법 및 시스템(장치), 수집된 데이터의 특성 분석을 통해 AI 학습용으로 가공한 데이터셋(구조)의 특허보호 방안을 제언하고자 작성되었다.데이터 그 자체는 자연법칙을 이용한 기술적 사상(아이디어)가 아니어서 특허의 보호 대상이 아니나, 데이터가 정보처리의 기술적 수단과 결합되어 청구범위의 하나의 구성요소로 특정되는 경우에는 특허로 보호를 받을 수 있어서 최근 관련 특허출원이 급증하고 있다.특허청의 기술분야별 심사실무가이드에는 「…데이터기록매체」 청구항만 물건발명으로 인정하고 있고, 청구항의 말미에 「…데이터셋(구조)」라고 기재한 경우에도 물건발명으로 볼 수 있는 것인지에 대해서는 명확한 기준을 제시하고 있지 않다.실무상 혼란 방지를 위해 「…데이터기록매체」 청구항 이외 「…데이터셋(구조)」 청구항도 물건발명으로 인정하되, 미국, 일본 및 유럽연합도 인정하지 않는 「…데이터」와 일본만 인정하고 있는 「…구조를 가진 데이터」 청구항은 물건발명으로 인정하지 않음을 기술분야별 심사실무가이드에 명시할 필요가 있다.","This article explores the evolving legal framework governing the patentability of AI training data—a critical asset whose importance has grown in tandem with advances in artificial intelligence (AI). In the AI context, data functions not merely as an informational resource but as a core enabler of technological innovation through processing, analysis, and machine learning applications.While data may be protected under copyright law or trade secret regimes, it generally falls outside the scope of patentable subject matter, as it does not inherently involve the application of natural laws. However, when data is integrated with technical means—such as specific algorithms or processing mechanisms—and is concretely defined as a claim element, it may be eligible for patent protection. This legal gray area has led to a surge in patent applications seeking to capture data-centric inventions.To secure protection, applicants have increasingly adopted claim formats including terms such as “…data,” “…dataset,” “…data structure,” “…structured data,” and “…data storage medium.” Among these, the Korean Intellectual Property Office (KIPO) currently recognizes only “data storage medium” claims as product inventions under its Technical Examination Practice Guide, offering no explicit guidance on the eligibility of “dataset” or “data structure” claims. This lack of clarity has led to inconsistent examination outcomes and growing legal uncertainty.To resolve these challenges, this article advocates for the revision of the Guide to explicitly recognize “dataset” and “data structure” claims as eligible product inventions when they satisfy the requisite technical criteria. At the same time, it should clarify that claims directed solely to “data”—which are not considered product inventions in jurisdictions such as the United States, European Union, or Japan—or to “structured data” (recognized only in Japan), do not satisfy the requirements for patentable subject matter in Korea."
의료분야 체계적 문헌고찰 수행에서 AI의 활용,2025,"['체계적 문헌고찰', '자동화', '인공지능', '생성형 인공지능', '거대 언어 모델', 'Systematic review', 'Automation', 'Artificial intelligence', 'Generative artificial intelligence', 'Large language model.']","체계적 문헌고찰은 신뢰할 수 있는 근거를 체계적으로 수집하고 종합함으로써 근거 기반 임상 진료 및 보건의료 정책 결정에 핵심적인 역할을 수행한다. 최근에는 인공지능(AI)이 체계적 문헌고찰의 효율성과 정확성을 향상시킬 유망한 도구로 부상하고 있다. 본 종설은 기계학습 및 거대 언어 모델(LLM)과 같은 생성형 AI를 포함한 AI 기술이 체계적 문헌고찰의 주요 단계에 걸쳐 어떻게 활용될 수 있는지 그 잠재적 응용 가능성과 현재의 한계점을 탐구한다. 아울러 AI의 책임감 있고 신뢰할 수 있는 사용을 위한 관련 지침에 대해서도 논의한다.검토 결과, AI는 문헌 검색, 선별 및 데이터 추출을 포함한 다양한 체계적 문헌고찰 단계에서 효율성을 향상시키며 특히 초기 단계에 기여할 수 있음을 시사한다. 그러나 대부분의 AI 기반 접근 방식은 아직 탐색적 연구 단계에 머물러 있으며, 체계적 문헌고찰 프로세스 전체를 완전히 자동화하기에는 현재 적합하지 않다. 특히 LLM과 같은 생성 모델은 부정확한 정보(환각, hallucination)를 생성할 수 있으므로, 특정 작업을 위한 보조 도구로서 신중하고 감독된 사용이 필요하다.결론적으로, AI는 체계적 문헌고찰 방법론을 변화시킬 잠재력을 가지고 있지만, 현재의 한계와 윤리적 함의에 대한 명확한 이해가 필수적이다. 기술이 발전함에 따라 지속적인 연구, 엄격한 유효성 검증, 그리고 전문가의 감독 하에 체계적 문헌고찰 워크플로우에 신중하게 통합하는 것이 중요하다.","Systematic reviews (SRs) play a central role in evidence-based clinical practice and healthcare poli cy, as they systematically gather and synthesize reliable evidence. Recently, artificial intelligence (AI) has emerged as a promising tool to enhance the efficiency and accuracy of SRs. This review explores potential applications and current limitations of AI technologies–including machine learning and generative AI such as large language models (LLMs)–across key stages of SRs. It also discusses rele vant guidance for their responsible and reliable use. Findings suggest that AI can support various SR stages, particularly literature search, screening, and data extraction, improving efficiency in the early phases. However, most AI-based approaches remain in the exploratory stage and are not yet suitable for fully automating the SR process. In particular, generative models like LLMs may pro duce inaccurate information (hallucinations), requiring cautious, supervised use as supplementary tools for specific tasks. In conclusion, while AI has the potential to transform SR methodology, a clear understanding of its current limitations and ethical implications is essential. Ongoing research, rigorous validation, and thoughtful integration into SR workflows–guided by expert oversight–are crucial as the technology evolves."
Real-Time Detection and Identification of mini-UAVs Using RF Signal Features and a Customized MLP Model,2025,['words Multi-Layer Perceptron (MLP) · RF-signal analysis · RF-signal classifi cation · Real-time UAV detection · Software-Defi ned Radio (SDR)'],,"The rapid adoption of mini-Unmanned Aerial Vehicles (mini-UAVs) has brought signifi cant security challenges, particularly due to their capacity for payload delivery and unauthorized surveillance. This paper introduces a real-time detection and identifi cation system for mini-UAVs, leveraging radio frequency (RF) signal features and a customized Multi-Layer Perceptron (MLP) model to address these threats. Our approach utilizes a Software-Defi ned Radio (SDR) platform to capture and analyze RF signals exchanged between mini-UAVs and their control stations. By extracting key RF parameters— such as center frequency, Peak-to-Average Power Ratio (PAPR), spectral fl atness, and spectral entropy—we eff ectively diff erentiate UAV communications from other RF signals. The core of our system is a tailored MLP model, optimized with a novel SinLU activation function and the Lion optimizer, which enhances the model’s ability to capture complex non-linear relationships. Trained on a comprehensive dataset of extracted RF features, the proposed model demonstrates high accuracy in identifying UAV signals. The system’s eff ectiveness is validated through rigorous experiments using SDR-recorded RC signals, confi rming its applicability in real-world scenarios. This research makes a signifi cant contribution to the ongoing eff orts to enhance UAV detection capabilities through advanced RF signal analysis and machine learning techniques."
SHAP과 GMM 기반 군집화를 활용한 대출 고객 리스크 군집 분석,2025,"['고객 세분화', '가우시안 혼합모형(GMM) 기반 군집화', 'SHAP', '대출 고객 리스크', 'Customer segmentation', 'Gaussian mixture model-based clustering', 'SHAP', 'Consumer loan default']","본 연구는 설명 가능한 인공지능(Explainable AI) 기법인 SHAP(SHapley Additive exPlanations)과 GMM 기반 군집화(Gaussian Mixture Model-based Clustering)를 결합하여, 대출 고객의 리스크 특성을 중심으로 세분화하고 각 군집의 형성 요인을 정량적으로 분석하였다. 국내 신용대출 고객 데이터를 기반으로 GMM을 적용한 결과, 고객은 상이한 금융 행태와 리스크 특성을 지닌 여덟 개의 군집으로 분류되었으며, 자산 규모, 대출 구조, 거래 기관 수, 주소 안정성 등에서 차이를 보였다.SHAP 분석을 통해 각 군집 형성에 영향을 미친 핵심 변수들을 도출하고, 변수별 기여도를 정량적으로 분석함으로써 군집 간 리스크 특성을 설명하였다. 분석 결과, 일부 군집은 복잡한 대출 구조나 비은행 금융기관에 대한 높은 의존도로 인해 신용 위험이 집중된 반면, 일부 군집은 짧은 금융 이력이나 높은 유동성을 보유하고 있음에도 안정적인 상환 성향을 나타내는 등 전통적인 리스크 평가 기준과는 다른 양상을 보였다. 이는 금융 리스크의 해석에 있어 단일 지표나 정형화된 기준에 의존하기보다는, 고객군의 맥락적 특성과 다차원적 변수 간 관계를 종합적으로 고려해야 함을 시사한다.","We combine Gaussian Mixture Model-based clustering with SHAP (SHapley Additive exPlanations), an explainable AI technique, to segment loan customers based on credit risk characteristics and identify the key drivers of each cluster. Using unsecured loan data from a Korean financial institution, we classify customers into eight distinct clusters that differ in asset levels, loan structures, number of financial institutions used, and residential stability. We use SHAP analysis to find the variables that most strongly influence cluster assignment and to clearly explain how customer traits relate to credit risk. Some clusters show elevated risk due to complex debt structures or heavy reliance on non-bank lenders. Others demonstrate stable repayment behavior despite having limited credit histories or high liquidity. These patterns challenge conventional risk assessment frameworks that rely on simple thresholds or static indicators.By integrating probabilistic clustering with explainable machine learning, our approach reveals the nuanced and heterogeneous nature of borrower risk profiles. This framework supports more transparent and precise credit risk analysis and offers practical insights for lenders seeking to understand diverse customer segments."
라만 분광법과 양자화학계산을 활용한 신종 화학무기 및 마약류 탐지 연구,2025,"['Raman spectroscopy', 'Chemical warfare agents', 'Narcotics', 'Quantum chemical calculations', 'Novel substance detection', 'DFT calculations']","본 연구는 신종 화학무기 및 마약류 탐지를 위한 라만 분광법의 활용 가능성과 양자화학계산을 통한 라만 스펙트럼예측의 유효성을 평가하였다. 화학무기 모사 물질인 DFP와 quinalphos, 그리고 마약류인 ketamine과 morphine에 대한실험적 라만 스펙트럼을 획득하고, 이를 밀도범함수이론(DFT) 기반의 양자화학계산 결과와 비교 분석하였다. 연구결과, 실험값과 계산값 사이에 높은 일치도(오차 < 5%)를 보였으며, 주요 작용기의 특성 진동 모드가 명확히 식별되었다. 또한 기존 물질의 구조를 변형시킨 DFP-D, quinalphos-D, ketamine-D, morphine-D와 같은 가상의 신종 물질에 대한라만 스펙트럼을 계산하여, 구조적 변화에 따른 스펙트럼 변화 패턴을 성공적으로 예측하였다. 라만 분광법의 비접촉식 분석 특성은 위험 물질의 안전한 탐지를 가능하게 하고, 양자화학계산과의 결합은 아직 합성되지 않은 신종 물질에 대한 선제적 대응 능력을 제공한다. 본 연구 결과는 국가 안보 및 공중 보건 측면에서 중요한 의미를 가지며, 향후인공지능 및 기계학습과 결합된 라만 분광 기술을 통해 더욱 효과적인 신종 위험 물질 탐지 시스템 개발에 기여할수 있을 것으로 기대된다.","This study assessed the feasibility of Raman spectroscopy for detecting novel chemical warfare agents and narcotics while evaluating the effectiveness of quantum chemical calculations in predicting Raman spectra. We obtained experimental Raman spectra for chemical warfare simulants (DFP and quinalphos) and narcotics (ketamine and morphine), then compared these with computational results based on density functional theory (DFT). The findings revealed remarkable agreement between experimental and calculated values, with deviations less than 5%, allowing clear identification of characteristic vibrational modes of key functional groups. Furthermore, we calculated Raman spectra for hypothetical novel substances―DFP-D, quinalphos- D, ketamine-D, and morphine-D―created by modifying existing molecular structures, successfully predicting spectral pattern changes resulting from structural alterations. The non-contact analytical capability of Raman spectroscopy enables safe detection of hazardous substances, while integration with quantum chemical calculations provides proactive response capabilities for yet-unsynthesized novel compounds. Our findings hold significant implications for national security and public health, potentially contributing to the development of more effective detection systems for novel hazardous substances through future integration with artificial intelligence and machine learning technologies."
생성형 AI 관련 저작권 침해소송에서 주장⋅증명책임에 관한 고찰,2025,"['생성형 AI', 'AI 학습', 'AI 산출물', '의거성', '실질적 유사성', '저작권 침해소송', '주장⋅증명책임', '텍스트 및 데이터 마이닝', '저작권법 제35조의5', '공정이용조항', 'Generative AI', 'AI Training', 'AI Outputs', 'Copying', 'Substantial Similarity', 'Copyright Infringement Suit', 'Burden of Proof & Averment', 'Text and Data Mining', 'Article 35(5) in the Korean Copyright Act', 'Fair Use Clause']","2022년 11월 생성형 AI 챗GPT가 등장한 이후 AI를 둘러싼 저작권법상 문제는 종래의 이론적인 쟁점에서 현실적인 쟁점으로 완전히 변모하였다. 생성형 AI 기술은 급속도로 발전하여 지금 현재도 혁신을 거듭하고 있다. 최근 제정된 인공지능기본법(법률 제20676호 2025. 1. 21. 제정, 2026. 1. 22. 시행) 제2조 제5호는 ‘생성형 AI’를 입력된 데이터의 구조와 특성을 모방하여 글, 소리, 그림, 영상, 그 밖의 다양한 결과물을 생성하는 AI 시스템이라고 정의한다.종래 AI의 개발⋅학습단계에서는 AI 학습데이터에 포함된 저작물의 권리처리가 주된 관심사였다. 그래서 TDM을 목적으로 하는 타인의 저작물의 수집⋅이용과 저작재산권의 제한을 중심으로 논의가 전개되었다. 그런데 생성형 AI의 상용화를 계기로 AI 산출물이 범람하면서 저작권 침해분쟁이 빈발하고 있다. 2024년 12월 현재 미국 등 외국에서는 생성형 AI 학습 및 산출물을 둘러싼 저작권 침해 재판이 수십 건 진행 중이다. 우리나라에서는 지상파 방송3사가 2025년 1월 13일 서울중앙지방법원에 네이버를 상대로 뉴스 데이터를 허락 없이 AI 학습에 이용하였다는 이유로 저작권 침해중지 등의 소를 제기하였다. 앞으로 우리나라에서도 본격적으로 전개될 생성형 AI 학습 및 산출물 관련 저작권 침해소송에 대비하는 차원에서 그에 관한 주장⋅증명책임에 대하여 본격적인 논의가 필요한 때이다.이 논문의 목적은 생성형 AI 관련 저작권 침해소송에서 중점적으로 살펴보아야 할 주장⋅증명책임에 관한 논점을 검토하는 데에 있다. 이러한 목적에 따라 이 논문은 생성형 AI 관련 저작권 침해소송의 소송물 및 요건사실의 주장⋅증명 등(II.)에 관한 일반론을 먼저 서술한 다음, 생성형 AI 산출물의 저작물성 및 저작권 귀속 문제(III.), 생성형 AI 서비스를 제공받은 개별 이용자가 AI를 이용하여 산출물을 생성⋅이용한 경우 저작재산권 등 침해소송에서 주장⋅증명책임(IV.), 생성형 AI 개발⋅학습단계에서의 저작재산권 침해와 그 주장⋅입증책임(V.)의 순서로 살펴보고자 한다.","In November 2022, Open AI released its generative AI ChatGPT, and many people have been using it. Since then, the copyright law issues surrounding AI have completely changed from academic issues to realistic practical issues. Generative AI technology is rapidly evolving and continues to innovate even now. Recently, the Korean National Assembly enacted the second AI Act in the world. The Act defines generative AI as ‘an AI system that imitates the structure and characteristics of input data to generate text, sound, pictures, videos, and other various outputs.’ In the past, during the machine learning phase of AI development, copyright experts were primarily concerned with how to clear the copyright issues of the works contained in the training data. Therefore, they were interested in issues such as how to restrict copyrights in order to facilitate TDM. However, as generative AI has become widely used, copyright holders have turned their attention to the issue of copyright infringement of AI products. As of December 2024, there are several copyright infringement trials over generative AI inputs or outputs in the United States and other countries. In Korea, on January 13, 2025, the three major terrestrial broadcasters (KBS, MBC, and SBS) filed a copyright lawsuit against Naver in the Seoul Central District Court for using news data without permission for generative AI training (inputs). There have not yet been any copyright infringement cases involving AI outputs, but it is likely that copyright infringement cases involving AI outputs will arise in the near future. In order to prepare for such a trial, we need to develop a full-fledged discussion on the burden of proof in copyright infringement cases. The purpose of this paper is to study on the burden of proof & averment in copyright infringement cases involving generative AI."
AI 기반 말뚝 현장 지지력 예측의 정량적 검토: 리바운드 값의 실효성 분석,2025,"['PHC pile', 'Rebound', 'Pile driving formula', 'KNN', 'Random forest', 'Bearing capacity']","국내 말뚝 시공 현장에서는 대부분의 말뚝에 대해 관입량(set)을 기준으로 관리하고 있으나, 이는 공학적 안전성을 정량적으로판단하는 데 한계가 있다. 이에 따라 더욱 신뢰성 있는 지지력 값을 활용한 관리 방식이 필요하다. 지지력 산정을 위한 대표적인 항타 공식인 Hiley 공식은 리바운드(rebound) 값을 포함함으로써 예측 정확도가 높지만, 현장에서 수기로 측정되는 리바운드 값은 현장 조건과 작업자에 따라 편차가 크며, 계측 신뢰성과 일관성이 떨어진다. 정확한 리바운드 계측을 위해 고속카메라나 고정밀 센서가 요구되지만, 비용과 장비 측면에서 현실적인 적용이 어려운 실정이다. 본 연구는 이러한 실무적제약을 고려하여, 리바운드 값을 제외한 입력 변수만으로도 말뚝 지지력을 신뢰성 있게 예측할 수 있는 가능성을 검토하였다.이를 위해 K-최근접 이웃(K-Nearest Neighbors, KNN) 및 랜덤 포레스트(Random Forest) 모델을 활용하여 AI 기반예측 모델을 구축하고, 리바운드 값의 포함 여부에 따른 예측 정확도를 정량적으로 비교·분석하였다. 분석 결과, 리바운드값을 제외하더라도 높은 예측 성능을 확보할 수 있었으며, 이는 기존 입력 변수들이 리바운드 값의 정보를 상당 부분 내포하고있음을 시사한다. 즉, 리바운드는 이론적으로 유의미한 변수이나, AI 기법을 통해 그 영향을 충분히 보완할 수 있다. 본연구는 현장에서 확보가 어렵거나 신뢰성이 낮은 변수에 의존하지 않더라도, 정확도 높은 지지력 예측이 가능함을 입증하였다.이는 향후 스마트 건설 기술을 기반으로 한 실용적 말뚝 시공 관리 시스템의 구축에 기여할 수 있을 것으로 기대된다.","Most domestic pile construction sites rely on set values (penetration per blow) to manage pile installation, but this approach fails to provide a reliable basis for evaluating structural safety. Managing pile capacity through predicted bearing capacity offers greater reliability. The Hiley formula, a representative method for capacity estimation, includes rebound values and often delivers high prediction accuracy. However, manual rebound measurements in the field often vary with site conditions and operator technique, reducing reliability and consistency. High-speed cameras or precision sensors enable more accurate rebound measurements, yet field deployment faces cost and practicality constraints. This study investigates whether AI models can accurately predict pile capacity without rebound data. By applying K-Nearest Neighbors (KNN) and Random Forest model, the analysis compares prediction accuracy between models with and without rebound input. Results show that models excluding rebound still achieve strong performance. Existing input variables appear to capture much of the rebound’s underlying information, minimizing its added value in practice. Although rebound holds theoretical significance, machine learning techniques can compensate for its absence. The findings support AI-based prediction of pile capacity without depending on unreliable or hard-to-measure field variables. This approach promotes practical deployment of smart construction technologies in pile foundation management."
기업 회생 예측 모형에 관한 연구,2025,"['기업회생', '기업구조조정', '채무조정', '인공신경망', 'Corporate Rehabilitation', 'Restructuring', 'Debt Restructuring', 'ANN']","본 연구는 채무자회생법이 적용되는 회생기업의 회생 성공요인을 확인하고 이를 투입변수로 활용하여 인공신경망을 이용해 기업 회생 예측 모형을 제시한다. 먼저 회생계획 인가단계에서 4개의 회생 성공 요인 후보군을 선정하여 로짓모형을 적용해 변수별 성공 예측력을 확인하였다. 첫 번째 후보 변수군은 주로 자산과 관련한 재무 정보들로 자산, 재고자산, 유형자산, 유동자산 등을 자산 및 부채로 표준화한 변수들이다. 두 번째 후보 변수군은 부채와 관련한 재무 정보들로 레버리지, 채무 조정율, 부채 개선율 등을 사용하였다. 세 번째 후보 변수군은 주로 현금흐름 및 수익과 관련한 변수들로 현금흐름, 영업이익, 순이익 등을 자산 및 자기자본으로 표준화한 변수들과 순이익을 매출총이익으로 표준화한 변수를 활용하였다. 마지막으로 비재무적 정보들로 기업 설립 후 기간, 화의 등 타절차 진행 여부, 대주주에 대한 소송 여부, M&A 진행 여부 등의 변수군이다. 분석결과, 총 11개의 통계적으로 유의한 회생 성공 예측 요인을 확인하였고, 이를 투입 변수로 하여 인공신경망을 활용해 정확도 78.43%의 기업 회생 성공 예측 모형을 제시한다. 본 연구는 기업 회생 성공의 사전적 예측 요인을 확인하고 이를 이용하여 실제 예측 모형까지 제시하였다는 점에서 기업회생과 관련한 정책적 시사점을 제공한다.","This study aims to identify the key success factors for corporate rehabilitation under the Debtor Rehabilitation and Bankruptcy Act and to develop a prediction model using artificial neural networks (ANNs). At the stage of rehabilitation plan approval, four categories of potential predictors were established and tested for their explanatory power through a logistic regression model. The first category includes financial variables related to corporate assets, the second focuses on the firm’s debt structure, the third pertains to cash flow and profitability, and the fourth consists of non-financial characteristics reflecting firm-specific circumstances. The empirical analysis identified 11 variables across these categories as statistically significant predictors of successful rehabilitation. These significant factors were then used as input variables in constructing an ANN-based corporate rehabilitation prediction model, which achieved an accuracy of 78.43%. By identifying the core determinants of rehabilitation success and applying them to machine learning, this study contributes to the literature by offering a robust ex-ante prediction tool."
기업 업무용 AI 챗봇 서비스 활성화에 영향을 미치는 요인 연구: 통합기술수용모델(UTAUT)을 중심으로,2025,"['기업 업무용 AI 챗봇', 'UTAUT', '정보통신기술 수용', '디지털 트랜스포메이션', '혼합연구방법', 'AI chatbot for corporate work', 'UTAUT', 'acceptance of information and communication technology', 'digital transformation', 'convergence research method']","본 연구는 통합기술수용모델(UTAUT)을 기반으로 직원들의 기업 업무용 AI 챗봇 수용에 영향을 미치는 핵심 요인을 규명하였다. 통신⋅IT⋅금융 등 50개 기업 직원 161명을 대상으로 설문조사 및 탐색적 요인분석을 통해 주요 변수를 추출한 후, AI 챗봇 수용에 영향을 미치는 요인들을 밝혀내기 위해 다중회귀분석과 위계적 회귀분석을 실시하였다. 분석 결과, 사용 용이성, 아이디어 도출, 정보 품질, 경영진⋅조직 지원이 AI 챗봇 수용도를 높이는 주요 요인으로 확인되었다. 흥미로운 점은 독립변수들이 AI 챗봇 수용의도에 미치는 영향에 있어, AI 활용 역량이 높은 직원들은 경영진⋅조직 지원의 영향이 상대적으로 낮게 나타난 반면, 기술에 대한 심리적 저항이 큰 직원들은 경영진⋅조직 지원의 영향이 상대적으로 높게 나타났다는 것이다. 또한 직장 경력이 많은 직원들은 사용 용이성보다 정보 품질과 아이디어 도출 기능을 더 중요시하는 것으로 나타났다.본 연구는 기업용 AI 챗봇 수용에서 기술적ㆍ개인적ㆍ조직적 요소가 복합적으로 작용함을 밝히고, UTAUT 모델을 기업 AI 챗봇이라는 맥락으로 확장했다는 점에서 의의가 있다. 연구 결과는 리더십과 조직지원이 기술 수용에 중요한 영향을 미치며, 직원의 역량과 성향에 따라 AI 챗봇 도입 전략을 차별화해야 함을 시사한다.","The study aims to empirically explore the key determinants driving the activation and sustained use of AI chatbot services in business contexts, employing the Unified Theory of Acceptance and Use of Technology (UTAUT) as its theoretical foundation. Amid the rapid advancements in Generative AI, organizations across diverse industries are integrating in-house AI chatbots to enhance operational efficiency and innovation. However, despite these initiatives, the acceptance and practical adoption of AI chatbots remain in their formative stages, often failing to align with initial expectations.This research analyzes the adoption process by incorporating well-established frameworks such as the Technology Acceptance Model (TAM) and UTAUT. A survey involving 161 employees from over 50 companies―spanning telecommunications, IT services, and finance sectors―was conducted. The findings highlight the significant influence of factors like ease of use, information quality, creativity-enhancing features, and organizational support on the acceptance of AI chatbots in corporate settings. These results suggest that aligning technological capabilities with organizational readiness and employee needs is crucial for successful adoption.The study offers meaningful contributions by systematically investigating how individual user traits and organizational dynamics interact in the adoption of AI chatbots. It underscores the importance of strategic interventions, such as enhancing organizational support mechanisms and ensuring user-centric design, to maximize the potential of AI chatbots. Practical implications include actionable insights for managers and decision-makers seeking to implement AI solutions effectively.Future research should aim to generalize findings by incorporating larger and more diverse samples and conducting longitudinal studies to understand temporal adoption trends. Additionally, in-depth analysis of technical attributes, such as natural language processing capabilities and machine learning algorithms, can provide valuable insights into how these features influence user acceptance and satisfaction.By bridging existing gaps in understanding AI chatbot adoption, this research lays the groundwork for developing adaptive strategies that cater to the dynamic needs of businesses. It ultimately serves as a guide for organizations aiming to capitalize on the transformative potential of AI-driven solutions in corporate environments."
자료 편향이 종분포모델 기반 서식지 변화 추정에 미치는 영향,2025,"['종문포모델', 'MaxEnt', '편향', '잠재서식지', '환경변화', 'Species Distribution Model', 'MaxEnt', 'Bias', 'Potential Habitat', 'Environmental Change']","본 연구의 목적은 시계열적으로 다른 시기의 출현자료를 종분포모델인 MaxEnt에 적용하고, 이때 발생할 수 있는 문제점을 분석함으로써 모델의 적용 가능성과 한계를 검토하는 것이었다. 특히, 이 과정에서 자료의 편향성이 미치는 영향을 이해하고자 하였다. 연구에서는 환경 변화에 민감한 종(다람쥐, 멧토끼)과 둔감한 종(멧돼지, 노루)을 대상으로 두 개의 분석 시기를 설정하고, 환경 변수를 구축하여 서식지 적합성을 비교·분석하였다. 분석 결과, 모델의 AUC 값이 0.7 이상으로 나타나 MaxEnt가 서식지 적합성을 예측하는 데 적절한 성능을 보였지만, 출현자료의 공간적 편향성이 모델 결과에 영향을 미칠 가능성을 확인하였다. 이는 시·공간적 편향이 서식지 변화 해석을 왜곡할 수 있으며, 기관별 조사 방식 및 시기 차이에 따른 자료 편향성이 모델링 결과에 큰 영향을 미칠 수 있음을 시사하였다. 본 연구는 기계학습 기반 모델을 시계열적 서식지 변화 연구에 적용할 때, 출현자료의 편향성을 면밀히 검토하고 보정해야 할 필요성을 보여주었으며, 서식지 변화 탐지의 신뢰도를 높이는데 기여할 것으로 기대된다.","The purpose of this study was to apply occurrence data from different time periods to the species distribution model, MaxEnt, and to analyze the potential issues that may arise, thereby examining the applicability and limitations of the model. In particular, the study aimed to understand the impact of data bias during this process. The study focuses on environmentally sensitive species (squirrel and hare) and environmentally tolerant species (wild boar and roe deer), setting two distinct analysis periods and constructing environmental variables to compare and evaluate habitat suitability. The results showed that the model's AUC values exceeded 0.7, indicating that MaxEnt performed adequately in predicting habitat suitability. However, it was also found that the spatial bias in occurrence data could significantly influence model outcomes. This suggests that spatial and temporal biases may distort habitat change interpretations and that differences in survey methodologies and data collection periods across institutions can substantially impact modeling results. This study demonstrates the importance of carefully assessing and correcting biases in occurrence data when applying machine learning models to temporal habitat change research. This is expected to improve the reliability of habitat change detection."
