title,date,keywords,abstract,multilingual_abstract
Harder-Samples Based Contrastive Learning Method with Mixup Strategy for Unsupervised Person Re- Identification,2025,"['Unsupervised Person Re-Identification', 'Mixup Cluster Contrast Learning', 'Hybrid Attention']",,"Unsupervised person re-identification can identify certain person from gallery images obtained from various cameras without supervision labels. Existing methods propose a hard-sample mining strategy to improve the ability to distinguish easily confused samples. An excellent hard-sample should have a similar appearance to the anchor and some negative characteristics to control the hardness. However, hard-samples obtained from the source dataset cannot satisfy these characteristics simultaneously. In this paper, we propose a hybrid attention and mixup contrastive learning-based unsupervised method. First, we implement a hybrid attention mechanism with a spatial-channel attention inside a ResNet-like architecture and a coordinate attention to capture global functional correlations, channel-wise aggregation with less overhead and inter-channel relationships, and long-range dependencies with precise positional information. Subsequently, we propose a harder negative generation-based strategy to mix the features between the query and negative samples to obtain even harder samples. Finally, we learn discriminative representations with a combined loss function. Experiments demonstrate that the proposed method achieve good performance on Market1501, DukeMTMC-reID, and MSMT17."
Plasma metabolite based clustering of breast cancer survivors and identification of dietary and health related characteristics: an application of unsupervised machine learning,2025,"['Breast cancer', 'East Asian people', 'metabolome', 'machine learning']",,"BACKGROUND/OBJECTIVES: This study aimed to use plasma metabolites to identify clusters of breast cancer survivors and to compare their dietary characteristics and health-related factors across the clusters using unsupervised machine learning.SUBJECTS/METHODS: A total of 419 breast cancer survivors were included in this cross- sectional study. We considered 30 plasma metabolites, quantified by high-throughput nuclear magnetic resonance metabolomics. Clusters were obtained based on metabolites using 4 different unsupervised clustering methods: k-means (KM), partitioning around medoids (PAM), self-organizing maps (SOM), and hierarchical agglomerative clustering (HAC). The t-test, χ test, and Fisher’s exact test were used to compare sociodemographic, lifestyle, clinical, and dietary characteristics across the clusters. P-values were adjusted through a false discovery rate (FDR).RESULTS: Two clusters were identified using the 4 methods. Participants in cluster 2 had lower concentrations of apolipoprotein A1 and large high-density lipoprotein (HDL) particles and smaller HDL particle sizes, but higher concentrations of chylomicrons and extremely large very-low-density-lipoprotein (VLDL) particles and glycoprotein acetyls, a higher ratio of monounsaturated fatty acids to total fatty acids, and larger VLDL particle sizes compared with cluster 1. Body mass index was significantly higher in cluster 2 compared with cluster 1 (FDR adjusted-PKM < 0.001; PPAM = 0.001; PSOM < 0.001; and PHAC = 0.043).CONCLUSION: The breast cancer survivors clustered on the basis of plasma metabolites had distinct characteristics. Further prospective studies are needed to investigate the associations between metabolites, obesity, dietary factors, and breast cancer prognosis."
Automatic classification of multi-channel PSD results combining unsupervised and supervised learning,2025,"['Fast neutron measurement', 'Organic plastic scintillator', 'Silicon photomultiplier (SiPM)', 'Pulse shape discrimination (PSD)', 'Machine learning', 'Automatic classification']",,"Fast neutron radiography is a nondestructive testing technique used in various fields, such as homeland security.Fast neutrons can be detected using either a thermal neutron capture detection system with moderators or a recoil proton-based neutron scattering detection system. In particular, recoil proton-based neutron detection systems are more suitable for radiography systems. This study proposes a machine-learning-based algorithm that can automatically classify neutron signals obtained from multichannel organic plastic scintillators with silicon photomultipliers for radiography acquisition. It covers the entire energy range above the pulse height threshold of 150 keVee in the pulse shape discrimination (PSD) results. We categorized the PSD results into two regions: the unsupervised learning region (more than 1.7 MeVee) and the supervised learning region (less than 1.7 MeVee).Neutron signals in the supervised learning region were effectively classified by exploiting the characteristics of the data distribution in the unsupervised learning region. The algorithm was applied to the neutron and gammaray signals obtained by time-of-flight measurements, and an excellent classification performance was demonstrated with the area under the receiver operating characteristic curve of 0.9904."
Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior,2025,"['Thick pinhole imaging system', 'Point spread function', 'Single image super-resolution', 'Unsupervised deep learning', 'Deep image prior']",,"Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified."
Cross-domain autonomous driving visual segmentation based on enhanced target data learning,2025,['Self-trainingSemantic segmentationUnsupervised domain adaptationAutonomous driving'],,"Within the broader context of Information and Communications Technology (ICT), the quest for reliable and scalable visual segmentation methods poses significant challenges, particularly in autonomous driving, where real-world scene complexity requires advanced solutions. To address data scarcity and improve segmentation performance, we propose a novel unsupervised domain adaptation (UDA) approach that enhances target domain learning. Our method introduces multiple perturbations consistency, leveraging spatial context within the target domain to improve recognition. By applying perturbations at input and feature levels and using a consistency loss, we enhance contextual learning. Additionally, a weight mapping technique reduces the impact of detrimental source domain information. Experimental results demonstrate that our approach outperforms baseline methods on the GTAV->Cityscapes and SYNTHIA->Cityscapes datasets."
An overview of artificial intelligence and machine learning in shoulder surgery,2025,"['Artificial intelligence', 'Machine learning', 'Arthroplasty', 'Rotator cuff tears']",,"Machine learning (ML), a subset of artificial intelligence (AI), utilizes advanced algorithms to learn patterns from data, enabling accurate predictions and decision-making without explicit programming. In orthopedic surgery, ML is transforming clinical practice, particularly in shoulder arthroplasty and rotator cuff tears (RCTs) management. This review explores the fundamental paradigms of ML, including supervised, unsupervised, and reinforcement learning, alongside key algorithms such as XGBoost, neural networks, and generative adversarial networks. In shoulder arthroplasty, ML accurately predicts postoperative outcomes, complications, and implant selection, facilitating personalized surgical planning and cost optimization. Predictive models, including ensemble learning methods, achieve over 90% accuracy in forecasting complications, while neural networks enhance surgical precision through AI-assisted navigation. In RCTs treatment, ML enhances diagnostic accuracy using deep learning models on magnetic resonance imaging and ultrasound, achieving area under the curve values exceeding 0.90. ML models also predict tear reparability with 85% accuracy and postoperative functional outcomes, including range of motion and patient-reported outcomes. Despite remarkable advancements, challenges such as data variability, model interpretability, and integration into clinical workflows persist. Future directions involve federated learning for robust model generalization and explainable AI to enhance transparency. ML continues to revolutionize orthopedic care by providing data-driven, personalized treatment strategies and optimizing surgical outcomes."
Semi supervised learning using Otherside view consistency regularizati,2025,"['Semi-supervised learning', 'consistency', 'exponential moving average', 'otherside view', 'pseudo label', 'roubstness']",,"Semi-supervised learning (SSL) has shown great promise in utilizing both labeled and unlabeled data, especially using consistency regularization To enhance the model's learning efficiency, we proposed a dualbranch co-training approach. After dividing the training data into two subsets, each branch utilizes a teacherstudent model pair, where the teacher's weights are updated via an exponential moving average (EMA). The framework combines supervised loss and unsupervised loss to optimize the model. Upon label expansion (e.g pseudo labeling), an additional otherside view is introduced, promoting agreement between the branches' predictions on shared data. This loss mitigates errors arising from incorrect pseudo-labels and enhances the overall robustness of the training process. By dynamically adjusting pseudo-label inclusion based on confidence thresholds, our methodology reduces the impact of noisy data and prevents overfitting. As a result, we could demonstrate the effectiveness of the proposed method in leveraging unlabeled data while maintaining high performance."
Evaluating Unsupervised Parsing: Do Language Models Truly Capture Syntax?,2025,"['Hierarchical Syntactic Structures', 'Unsupervised Syntactic Parsing', 'Latent Tree Chart Parser']",,"This study critically examines the claim that unsupervised parsing algorithms can infer the syntactic structure of natural language without explicit supervision. Specifically, it investigates the Deep Inside-Outside Recursive Autoencoder (DIORA) model, which uses bidirectional LSTMs to purportedly capture sentence structure based solely on raw word order and semantic relationships (Drozdov et al. 2019).Given the inherently hierarchical and recursive nature of linguistic structure(Chomsky 1956; Montague 1970)—a feature often opaque even to native speakers—this research hypothesizes that models like DIORA may prioritize semantic chunking driven by word meanings and frequent word sequences rather than accurately representing syntactic structures. To test this, synthetic sentences of syntactically valid but semantically nonsensical sentences, akin to Chomsky’s “Colorless green ideas sleep furiously,” were developed.By comparing DIORA’s parsing outputs to tree structures represented utilizing manually constructed Chomskyan-style Context-Free Grammar (CFG), this paper elucidates the linguistic representations learned by unsupervised parsing models. The findings provide critical insights into whether such models genuinely capture syntactic structures or primarily rely on semantic patterns, contributing to the broader understanding of unsupervised language parsing."
Perceptual Enhancement for Unsupervised Monocular Visual Odometry,2025,"['Local low-light image', 'monocular visual odometry', 'perceptual enhancement', 'unsupervised learning.']",,"Visual odometry is pivotal in robotics and autonomous driving, serving as a key component of visual simultaneous localization and mapping technology. In real-world scenarios, humans in local low-light conditions perceive less information, which can impact our judgments and actions. Similarly, visual odometry can become confused under these conditions, leading to compromised performance. To address the challenges posed by local low-light images on monocular visual odometry, we propose an unsupervised framework for monocular visual odometry. To the best of our knowledge, this is the first instance of unsupervised monocular visual odometry and local low-light image enhancement accomplished within a unified framework. Initially, we employ retinex theory and the discrete Fourier transform to decompose, filter, and synthesize the original image. For the filtering process, we propose a novel learnable global filtering network. Subsequently, we input the enhanced images into the depth and pose networks, generating the corresponding depth maps and inter-frame poses. Ultimately, we construct a photometric consistency loss, a depth loss, and a novel low-light smoothness loss to train the entire network. Through experimental validation, our method exhibits superior performance on the KITTI dataset. Furthermore, it demonstrates satisfactory generalization ability in unseen environments from the Oxford RobotCar dataset."
도메인 적응 및 준지도학습 기반의 단일 세포 시퀀싱 세포 타입 분류,2025,"['단일 세포 시퀀싱', '비지도 도메인 적응', '준지도학습', '세포 타입 분류', 'single-cell RNA sequencing', 'unsupervised domain adaptation', 'semi-supervised learning', 'cell type classification']","개별 세포에서 유전자 발현을 측정하는 단일 세포 시퀀싱 (scRNA-seq) 기술이 빠르게 발전되고 있다. 최근 scRNA-seq 데이터 기반의 세포 타입 분류에서 딥러닝 기술이 활용되고 있다. 대부분의 방법은 세포 타입 라벨을 보유한 데이터를 사용하여 모델을 훈련한 후 해당 모델을 다른 데이터에 적용한다. 그러나 여러 데이터의 통합은 시퀀싱 기술 등의 차이로 인해 배치 효과를 초래하며, 이는 유의미한 유전자 발현 차이 발견을 방해한다. 이 논문에서는 데이터셋 간 분포 차이를 줄이기 위해 비지도 도메인 적응 및 준지도 학습 기반의 세포 타입 예측 모델을 제안한다. 먼저, 세포 타입 정보를 포함하는 소스 데이터를 기반으로 제안 모델을 사전 훈련시킨다. 그 후, 적대적 훈련을 기반으로 타겟 데이터의 분포를 소스 데이터의 분포와 정렬시킨다. 마지막으로, 준지도 학습을 기반으로 모델을 재훈련시킨다. 제안 모델은 배치 효과를 제거하여 기존의 배치 효과 보정 모델보다 높은 분류 성능을 보였다.","Single-cell RNA sequencing (scRNA-seq) techniques for measuring gene expression in individual cells have developed rapidly. Recently, deep learning has been employed to identify cell types in scRNA-seq analysis. Most methods utilize a dataset containing cell-type labels to train the model and then apply this model to other datasets. However, integrating multiple datasets can result in unexpected batch effects caused by variations in laboratories, experimenters, and sequencing techniques. Since batch effect can obscure the biological signals of interest, an effective batch correction method is essential. In this paper, we present a cell-type prediction model for scRNA-seq that utilizes unsupervised domain adaptation and semi-supervised learning to minimize distributional differences between datasets. First, we pre-train the proposed model using a source dataset that contains cell-type information. Subsequently, we train the model on the target dataset by leveraging adversarial training to align its distribution of the target dataset with that of the source dataset. Finally, we re-train the model to enhance performance through semi-supervised learning, utilizing both the source and target datasets with consistency regularization. The proposed model outperformed the other deep learning-based batch correction models by effectively removing batch effects."
무감독 세그멘테이션을 이용한 열영상의 학습기반 주간영상 모의 개선,2025,"['영상변환', '무감독 세그멘테이션', 'UNSB', '열적외 영상', '라이다', 'Image translation', 'Unsupervised segmentation', 'UNSB', 'Thermal image', 'LiDAR']","야간영상은 재난상황과 감시 작전 등 다양한 분야에서 중요한 영상정보로 활용되었고, 야간영상의 선명도와 가시성 향상을 위해 카메라, 센서와 영상처리 연구가 활발히 이루어지고 있다. 본 연구에서는 다양한 특성을 가진 센서로 촬영한 야간영상에 대하여 영상 내 객체별 특징영역을 구분하여 학습시켜 주간영상으로 모의하는 방법을 제안하였다. 주간과 야간영상 간의 온도 차이가 피복별로 다른 점을 고려해 학습방법을 제안한 것으로써, CNN 기반 무감독 세그멘테이션 기법과 UNSB 모델을 적용하였다. 무감독 세그멘테이션 기법을 적용한 실험환경은, 특성 유사성, 공간 연속성, 클러스터 수 제한과 같은 세 가지 제약 조건을 만족하도록 하였다. 딥러닝 학습 자료로 열적외 영상, 라이다 강도 영상, 라이다 거리 영상 그리고 피복별로 구별될 수 있는 세그멘테이션 영상을 정합하였으며, 해당 영상과 광학영상을 UNSB 모델 기반으로 학습하여 주간 광학영상을 모의하였다. 실험결과, 120 에포크 학습 기준으로 SSIM 0.593, PSNR 14.34, R² 0.218을 나타내었다. 시각적으로 유사한 형상이 생성되고, 객체별 세부 요소들에 대하여 원영상과 유사한 색상을 구현하여, 객체의 특징이 명확한 경우 변환 결과가 우수함을 입증하였다.","Nightyime image serves as critical visual information in a wide range of applications, including disaster response and surveillance operations. To improve the clarity and visibility of such imagery, extensive research has been conducted on imaging devices, sensor technologies, and image processing techniques. This study proposes a method to simulate daytime images from nighttime image acquired by various sensors by learning object-specific feature regions within the image. Considering that temperature differences between daytime and nighttime images vary depending on the object, a CNN-based unsupervised segmentation technique, and the UNSB (Unpaired Neural Schrödinger Bridge) model were applied. The experimental setting for the unsupervised segmentation technique was designed to satisfy three constraints: feature similarity, spatial continuity, and a limited number of clusters. Training data were composed by compositing thermal infrared images, LiDAR intensity images, LiDAR range images, and segmentation images, which were then learned in conjunction with corresponding optical images using the UNSB model to simulate daytime optical image. The experimental results showed SSIM 0.593, PSNR 14.34, and R² 0.218 based on 120 epochs of training. For each object detail, the colors were similar to the original image, proving that the conversion result is excellent when the object features are clear."
비지도 학습을 이용한 물리검층 자료부터의 암상 분류: 자기조직화 지도 알고리즘 중점으로,2025,"['물리검층', '자기조직화 지도', '비지도 학습', '분류', '암상', 'Well Logging', 'Self-Organizing Map', 'Unsupervised Learning', 'Classification', 'Lithology']","물리검층은 시추공을 통해 지중에 대한 정보를 얻는 과정을 의미한다. 밀도, 공극률, 유체포화도 등과 같은 특성들을 측정하고, 이는 특히 지중에 존재하는 다양한 암상을 식별하고 분류하는데 있어 매우 유용하다. 암상 분류는 저류층 특성화 및 석유나 가스 탐사에 매우 중요한 역할을 한다. 하지만 코어샘플링 등과 같은 전통적인 분류 방법은 시간과 비용이 많이 소요된다. 본 연구에서는 머신러닝 알고리즘을 활용하여 물리검층 자료로부터 암상을 분류하는 방법을 연구하였다. 이를 위해 자기조직화 지도(Self-Organizing Map, SOM)라는 인공신경망 알고리즘을 적용하였으며, 비지도 학습 방식으로 진행하였다. 다양한 입력 변수를 고려하여 모델을 학습시켰으며, 이를 통해 암상 분류를 예측한 후 사전에 주어진 암상 자료와 비교하여 예측 정확도를 평가하였다. 또한, 하이퍼파라미터의 영향을 최소화하기 위해 앙상블 기법을 활용하여 SOM 100 모델을 구성하였다. 이 방법을 통해 단일 모델이 가지는불확실성을 줄이고, 보다 신뢰도 높은 암상 분류 결과를 도출하고자 하였다.","Well logging is the process of obtaining information regarding the subsurface through boreholes. It measures properties such as density, porosity, fluid saturation etc, which are useful in identifying and classifying the various lithologies within the subsurface. Lithology classification and identification are crucial for reservoir characterization and oil and gas exploration. However, conventional methods, such as core sampling, are time consuming and expensive. In this research, a method of classifying lithology from well log data is developed using an unsupervised machine learning algorithm, self-organizing map (SOM). Various input features are considered to train the model, and lithology classification predictions are made and compared with pre-existing lithology data to evaluate the prediction accuracy. To minimize the impact of hyperparameters, we employ an ensemble approach by constructing the SOM 100 model. This proposed method aims to reduce the uncertainty associated with a single model and enhance the reliability of lithology classification prediction."
비지도 대조학습 시계열 인코더를 활용한 표현벡터 기반 시계열 유사도 분석 기법,2025,"['Deep learning', 'Energy demand forecasting', 'Representation vector', 'Transfer learning', 'Unsupervised contrastive learning', '심층 학습', '에너지 요구량 예측', '표현벡터', '전이학습', '비지도 대조학습']",비지도 대조학습 시계열 인코더를 활용한 표현벡터 기반 시계열 유사도 분석 기법,Representation Vector-Based Time Series Similarity Analysis Using Unsupervised Contrastive Learning Time Series Encoder
비지도학습 알고리즘 기반 UAV LiDAR 반사 강도 필터링을 통한 지면 추출 및 토공량 산정 정확도 평가,2025,"['위성항법시스템', '무인항공기', '라이다', '반사 강도', '비지도학습', '토공량', 'Global navigation satellite system', 'Unmanned aerial vehicle', 'Light detection and ranging', 'Reflectance intensity', 'Unsupervised learning', 'Earthwork volume']","본 연구에서는 식생의 존재로 인한 계절적, 공간적 제한 및 인공적 식생 제거로 발생하는 인력과 시간 소요로 인한 토공량 산정 방식의 다양한 한계점을 극복하기 위해 RTK(Real-Time Kinematic)-UAV(Unmanned Aerial Vehicle) 기반의 LiDAR(Light Detection and Ranging) 센서를 활용하여 대상지의 포인트 클라우드(Point Cloud) 영상을 취득하고, 취득 요소 중 하나인 반사 강도(Reflectance Intensity)를 기준으로 식생과 지면이 구분된 데이터를 생성하였다. 이를 통해 생성된 데이터를 기반으로 산정된 토공량을, 전통적으로 각종 토목공사 및 연구에서 널리 사용되어 온 위성항법시스템(Global Navigation Satellite System, GNSS) 기반의 VRS(Virtual Reference Station) 측량 방식을 통해 산출된 토공량 성과와 비교·정확도 평가를 진행하였으며, 이를 바탕으로 효율적인 토공량 산정 방식에 대한 대안을 제시하였다. 본 연구에서는 널리 사용되는 비지도학습 기법 중 대표적으로 사용되는 기법인 K-Means, K-Medoids 그리고 밀도 기반 클러스터링 기법인 DBSCAN(Density-Based Spatial Clustering of Application with Noise) 클러스터링 기법을 통해 대상 요소의 광학적 특성 및 표면 질감에 따라 고유한 밀도를 가지는 반사 강도의 특징을 활용하여 취득된 영상에 대해 필터링 과정을 수행하였다. 클러스터링 결과 대상물 특성에 따라 고유한 밀도를 가지는 중심 클러스터를 설정할 수 있었고, 다중반사를 통해 기존 수집된 지면 포인트와 더불어 식생 하부에 존재하는 지면 포인트까지 수집되어 결과적으로 포인트 밀도가 가장 높은 클러스터를 지면으로 판단하여 해당 클러스터를 추출할 수 있었다. 이를 통해 LiDAR 센서 반사 강도를 기반으로 K-Means, K-Medoids 그리고 DBSCAN 클러스터링을 적용하여 추출된 지면에 대해 절토량과 성토량을 합산한 최종 토공량을 산정한 결과, 각각 1.4 %와 0.3 %의 과대 산정 그리고 0.5 %의 과소 산정을 보였다. 전체 토공량에서 성토량과 절토량이 차지하는 비율에 따라 계산된 가중치를 고려하여 정확도를 비교 및 분석한 결과 비지도학습 기법 중 K-Means 클러스터링 기법이 가장 정확도가 높게 측정됨을 확인하였다. 이를 통해 무인항공기 LiDAR 센서 촬영을 기반으로 취득된 반사 강도를 활용하여 대상지에 대해 비지도학습 알고리즘을 적용한 방법이 계절적 한계를 극복하여 효율적인 토공량 산정 방식의 대안이 될 수 있는 잠재적 가능성을 확인하였다.","In this study, we addressed the limitations of conventional earthwork volume estimation methods caused by seasonal and spatial restrictions due to vegetation and the labor-intensive process of artificial vegetation removal. To overcome these challenges, a GNSS(Global Navigation Satellite System) and UAV(Unmanned Aerial Vehicle) equipped with a LiDAR(Light Detection and Ranging) sensor were used to acquire point cloud data. The Reflectance Intensity feature of the data was utilized to generate vegetation and ground-separated datasets. These datasets were then employed to estimate earthwork volume, which was compared and evaluated against the widely used GNSS-based VRS(Virtual Reference Station) surveying method, a standard in civil engineering and research applications This study implemented unsupervised learning algorithms, including K-Means, K-Medoids, and DBSCAN(Density-Based Spatial Clustering of Applications with Noise), to filter reflectance intensity data based on its unique density characteristics and surface textures. The clustering results identified distinct core clusters, and multiple reflections enabled the inclusion of ground points beneath vegetation.The cluster with the highest point density was classified as ground and extracted for further analysis. The ground data, filtered using these clustering algorithms, were employed to calculate total earthwork volume, combining cut and fill volumes. The results indicated overestimations of 1.4 % and 0.3 % and an underestimation of 0.5 %. A weighted accuracy analysis, considering the proportions of cut and fill volumes, confirmed that the K-Means clustering algorithm achieved the highest accuracy among the methods. This research demonstrates the potential of UAV-based LiDAR data and unsupervised learning algorithms to enhance the accuracy and efficiency of earthwork volume estimation, offering a robust alternative to traditional methods while overcoming seasonal limitations and operational inefficiencies."
비지도 학습 방법을 활용한 터빈 이상신호 진단 사례 연구,2025,"['Gas Turbine', 'Steam Turbine', 'Early Warning', 'Anomaly Diagnostics', 'Updating Training Data', '가스터빈', '증기터빈', '조기경보', '이상신호 진단', '메모리 행렬 갱신']","고온·고압 가스 및 증기를 통해 전력을 생성하는 터빈은 운전 중 다양한 원인으로 기계 결함이 발생한다. 이를 방치할 경우 부품 손상이나 대형 사고로 이어질 위험이 있어, 발전소에서는 진동, 압력, 온도 등 다양한 신호를 감시하고 분석하여 고장을 예방하고 있다. 특히 최근에는 터빈 시스템 제작 시 고효율, 대형화, 연료 다변화 기술이 적용되면서 새로운 이상 현상 발생 가능성이 커짐에 따라 이를 사전에 감지하기 위해 MSET과 같은 조기경보 기술이 설비 이상감지에 활용되는 사례가 증가하고 있다. 그러나 대부분의 조기경보 알고리즘 예측 정확도는 정상 운전 데이터로 구성된 메모리 행렬에 크게 의존적이며, 메모리 행렬이 주기적으로 갱신되지 않으면 모델 성능이 급격히 저하되는 문제를 발생한다. 이러한 현상을 최소화하기 위해 수작업을 통해 메모리 행렬을 재구성하여 사용하고 있지만, 데이터 분석 시간과 운영비용이 소요되어 활용성이 저하되는 한계가 존재한다. 따라서 본 논문에서는 MSET 메모리 행렬 갱신 과정을 자동화하기 위해 이상지표와 가중치를 기반으로 UDI (Update Discrimination Index)를 도입하여 정상 데이터와 이상 데이터를 실시간으로 구별하고, 메모리 행렬을 자동 갱신할 수 있는 방안을 제시하였다. 이를 통해 MSET 예측 모델 신뢰도를 일정하게 유지하여 발전소 설비의 고장감시 효율성을 높일 뿐만 아니라 운영비용과 유지보수 부담을 최소화하고자 한다.","Turbines, which utilize hot, high-pressure gases and steam to generate electrical power, are subject to mechanical failures during operation due to various factors. If these failures are not promptly addressed, they can lead to severe component damage and even catastrophic accidents. Accordingly, power plants monitor and analyze signals such as vibration, pressure, and temperature to prevent them. With the advancement of high-efficiency and large-scale technologies, the complexity of turbine operations has increased, leading to a higher likelihood of new types of failures. To address this challenge, early warning technologies such as the Multivariate State Estimation Technique (MSET) are widely utilized for anomaly detection in power plants. However, the accuracy of MSET heavily relies on memory matrix obtained from normal operating conditions. If the memory matrix is outdated or does not reflect the latest operating conditions, the model’s performance degrades significantly. To prevent this, major facilities are manually reconstructing and using training data. However, they are struggling with increased data analysis time and operational costs. To resolve this issue, this paper proposes a method to automatically update the memory matrix using a discrimination index, which consists of an anomaly index and weight. This approach ensures continuous model reliability, enhances the efficiency of power plant fault monitoring, and minimizes operational costs and maintenance efforts."
강화학습을 이용한 하천 녹조 발생 저감 모형 연구,2025,"['Algal bloom management', 'Explainable artificial intelligence', 'Machine learning', 'Water quality management', '녹조 관리', '설명가능한 인공지능', '머신러닝', '수질 관리']","과도한 조류 발생은 취수원 안전성 및 수생태 환경에 부정적인 영향을 미칠 수 있어 적극적인 관리가 필요하며, 최근 머신러닝 등 다양한 인공지능 기반 기술을 조류 관리에 적용하기 위한 연구가 지속되고 있다. 머신러닝은 학습 방법에 따라 지도학습, 비지도학습 및 강화학습으로 구분할 수 있으며, 다양한 지도학습 모형 등을 활용한 조류 발생의 예측 모형의 개발 등이 활발히 이루어지는 것과 다르게 강화학습 모형을 적용하는 연구는 아직 그 사례가 제한적이다. 본 연구에서는 이러한 강화학습을 이용하여 하천 조류 농도 저감을 위한 모형을 구축하였다. 모형의 입력자료로는 현장에서 측정된 다양한 수질 및 기상 인자를 활용하였으며, 조류 발생의 정량적 지표인 클로로필-a 농도를 저감하도록 강화학습 모형을 학습시켰다. 학습된 모형의 테스트 기간에 대해, 강화학습 적용 전후의 평균 클로로필-a 농도를 비교한 결과, 강화학습 적용을 통해 클로로필-a 농도가 개선됨을 확인하였으나 그 정도는 크지 않았다. 모형 결과에 대한 세부적인 해석을 위해 설명가능한 인공지능 기법의 대표적인 방법인 Shapley additive explanations analysis를 이용하여 강화학습 모형의 환경 구축에 활용된 변수들의 특성을 분석하고 향후 수질 관리 효율 향상을 위한 강화학습 모형의 적용 방향을 제시하였다.","Excessive algal blooms can negatively affect the safety of water intake sources and aquatic ecosystems, necessitating proactive management efforts. In recent years, research has increasingly explored the application of artificial intelligence (AI)-based technologies, including machine learning (ML), for algal bloom management. ML techniques can be broadly categorized into supervised learning, unsupervised learning, and reinforcement learning. While many studies have focused on developing predictive models for algal blooms using various supervised learning approaches, applications of reinforcement learning remain relatively limited. In this study, a reinforcement learning model was developed to reduce algal concentrations in a river. The model was trained using various water quality and meteorological variables measured in the field monitoring stations, with the objective of minimizing chlorophyll-a concentration, a quantitative indicator of algal blooms. An evaluation of average chlorophyll-a concentrations before and after applying reinforcement learning during the testing period revealed an improvement, although the degree of reduction was not substantial. To further interpret the model’s outcomes, Shapley additive explanations (SHAP), a representative explainable AI technique, was used to analyze the contributions of variables involved in the reinforcement learning environment setup. Based on these analyses, future directions for improving the efficiency of water quality management through reinforcement learning models are proposed."
정치 뉴스 기사 댓글에 대한 딥러닝 기반 이상치 탐지 모형 비교 연구,2025,"['딥러닝 모형', '비지도 학습', '자연어 처리', '지도 학습', '텍스트 이상치 탐지.', 'Deep learning model', 'natural language processing', 'supervised learning', 'text anomaly detection', 'unsupervised Learning.']","현대 사회에서 소셜 미디어 및 인터넷 활용이 급속도로 증가함에 따라, 악성 댓글 및 스팸 메일과 같이 정상적인 분포에서 벗어나는 비정상적인 텍스트 데이터가 증가하고 있다. 이러한 문제의 해결을 위해 스팸 메일 및 악성 댓글 등을 식별하기 위한 텍스트 이상치 탐지 및 자연어 처리와 관련된 연구가 활발히 이루어지고 있다. 본 논문에서는 네이버 정치 뉴스 기사 댓글 데이터를 활용하여 딥러닝 기반 모형의 텍스트 이상치 탐지 성능을 비교하였다. 네이버 클린 봇에 의한 검열 정보의 활용 유무에 따라 지도 학습과 비지도 학습 접근 방식을 적용하여 모형의 성능을 비교하였으며, 한국어를 기반으로 사전 학습된 자연어 처리 모형을 활용하여 임베딩 벡터를 산출하였다. 이상치 탐지 성능 비교 결과, 지도 학습 기반 모형에서는 KcELECTRA 임베딩 기반의 FFNN 이진 분류 모형이 가장 우수한 성능을 보였으며, 비지도 학습 기반 모형에서는 KcBERT 임베딩 기반의 Deep SVDD모형이 가장 우수한 성능을 나타내었다.","Abnormal text data, such as malicious comments and spam emails, has significantly increased as the use of social media and online media services rapidly expands. To address these issues, text anomaly detection and natural language processing for identifying spam emails and malicious comments have gained considerable attention. This paper compares the performance of deep learning-based models for text anomaly detection using comment data from Naver's political news articles. The study applied supervised and unsupervised learning approaches based on the results from Naver's Cleanbot, and embedding vectors were derived using pre-trained natural language processing models for the Korean language. From the comparison results, the supervised learning model with the KcELECTRA embedding-based FFNN classification model achieved the best performance, while the unsupervised learning model with the KcBERT embedding-based Deep SVDD model demonstrated the best performance."
기계학습을 이용한 반도체 생산 스케쥴 로그 분석 연구: 클러스터링과 의사결정트리 하이브리드 접근방법,2025,"['의사결정', '비지도 학습', '의사결정 트리', '상관관계 분석', '하이브리드 학습', '스케줄링', '반도체 생산', '생산 스케줄링', 'Decision making', 'unsupervised learning', 'decision tree', 'correlation analysis', 'hybrid learning', 'scheduling', 'semiconductor production', 'manufacturing scheduling']","반도체 생산관리는 제품 복잡도의 증가에 따라 어려워지고 있지만, 현장 스케줄링은 효율적이지 않다는 문제가 제기되고 있다. 생산 환경의 복잡성과 다양한 변수들로 인해 기존의 스케줄링방식은 실시간으로 변화하는 생산 조건에 효과적으로 대응하기 어렵고, 이로 인해 최적의 생산성과 품질을 달성하는 데 한계가 있다. 이에 따라 생산 전문가들은 생산 방향과 운영 상태를 파악할 수 있는 솔루션을 요구하고 있다. 필자는 현업의 요구사항을 바탕으로 실제 반도체 Fab의 로그 데이터를 머신 러닝을 통해 분석하여 스케줄에 영향을 미치는 의사결정 요소를 파악하고 시각화 할 수 있는 솔루션에 대해 연구하였다. 이는 향후 스케줄러의 방향성을 제시하여 Autonomous Fab을 구축하는데 기반을 제공한다는 점에서 의의가 있다.","Semiconductor production management becomes increasingly challenging due to the growing complexity of products, raising issues with the inefficiency of on-site scheduling. The complexity of the production environment and the multitude of variables make it difficult for traditional scheduling methods to effectively respond to real-time production changes, limiting the ability to achieve optimal productivity and quality. In this context, production experts are demanding solutions that provide insights into production direction and operational status. Based on the requirements, I conducted research on a solution that uses machine learning to analyze actual semiconductor Fab log data, identifying and visualizing decision-making factors that impact scheduling. This study is significant in that it suggests a direction for future schedulers and provides a foundation for building an Autonomous Fab."
Transformer-based Autoencoder와 FDD 손실 함수를 활용한 전류 센서의 비지도 학습 기반 이상 탐지,2025,"['Anomaly Detection', 'Unsupervised Learning', 'Autoencoder', 'Transformer', 'Current Sensor', '이상 탐지', '비지도 학습', '오토인코더', '트랜스포머', '전류 센서']",,"Anomaly detection in current sensors plays a crucial role in maintaining efficient operations and preventing catastrophic failures across various industries. Data obtained from current sensors is used to monitor the condition of machinery in real-time and to detect anomalies at an early stage. Compared to traditional machine learning and sensor processing methods, deep learning techniques offer superior adaptability and powerful data representation learning capabilities by learning complex patterns in the data. However, research on anomaly detection using deep learning for current sensors faces several challenges, including the difficulty of data labeling, high computational costs, and model generalization issues. In particular, obtaining labeled data in practical environments is often challenging and costly, highlighting the need for unsupervised learning methods. To address these issues, we propose an unsupervised anomaly detection method for current sensor data using a Transformer-based Autoencoder. The proposed method effectively learns the temporal characteristics of current sensor data, improving the ability to distinguish between normal and abnormal states. Specifically, this study introduces the Fused Directional Distance (FDD) loss function, which considers both the distance and angle differences between data points instead of the commonly used reconstruction error for threshold setting. The FDD loss function effectively suppresses the influence of noise and enhances the robustness of the model. We apply the proposed method to real current sensor data from AI Hub's 'machinery facility failure prediction sensors' dataset. Experimental results demonstrate that the proposed model achieves superior anomaly detection performance compared to existing methods and confirms its applicability in various industrial environments. Notably, the unsupervised learning approach enables effective anomaly detection even with unlabeled data, showcasing the method's practicality. This study presents a novel approach to unsupervised anomaly detection using current sensor data, providing a foundation for future research in this field. Additionally, this research is expected to expand the application scope of current sensor data and contribute to solving practical problems in industrial settings."
자동화 제조 시스템에서 공정 이미지 기반 고장 감지 모델의 학습 패러다임 및 출력 형식 전환에 따른 성능 비교 분석,2025,"['Fault Detection', 'Learning Paradigm', 'Output Representation', 'Automated Manufacturing System', 'Process Image']",,"Fault detection in electromechanical systems plays a significant role in product quality and manufacturing efficiency during the transition to smart manufacturing. Because collecting a sufficient number of datasets under faulty conditions of the system is challenging in practical industrial sites, unsupervised fault detection methods are mainly used. Although fault datasets accumulate during machine operation, it is not straightforward to utilize the information it contains for fault detection after the deep learning model has been trained in an unsupervised manner. However, the information in fault datasets is expected to significantly contribute to fault detection. In this regard, this study aims to validate the effectiveness of the transition from unsupervised to supervised learning as fault datasets gradually accumulate through continuous machine operation. We also focus on experimentally analyzing how changes in the learning paradigm of the deep learning model and the output representation affect fault detection performance. The results demonstrate that, with a small number of fault datasets, a supervised model with continuous outputs as a regression problem showed better fault detection performance than the original model with one-hot encoded outputs (as a classification problem)."
머신러닝 활용 초등영어 교과서 텍스트 군집화 및 그림책 텍스트 분류 연구,2025,"['머신러닝()', '텍스트 군집화()', '텍스트 분류()', '의사소통기능()', '초등영어교육()', 'machine learning', 'text clustering', 'text classification', 'communicative functions', 'primary English education']",,"This study explores how machine-learning technique can enhance text selection in primary English education by clustering textbook dialogues according to their communicative functions and by classifying picture-book texts within the same framework. 484 dialogue texts from five publishers’ Grade 3~6 textbooks were vectorized and clustered with an unsupervised algorithm. 13 clusters aligned perfectly with a single communcative functions, while 32 clusters showed high concordance when second-most frequent function was also considered. The validated cluster labels served as training data in a logistic-regression classifier that assigned seven English picture books to curriculum-specified communicative functions. Four picture books were classified with high probability for a single function, confirming that models trained on textbook dialogues can credibly map out-of-textbook reading materials onto the curriculum. Educationally, the approach furnishes an objective tool for teachers to identify picture-book texts that reinforce the communicative goals of a given unit. More broadly, it demonstrates that quantitative text analytics can reveal latent connections between mandated textbooks and external resources, offering a scalable pathway toward more coherent and diversified input in primary English classrooms."
자기지도학습 표현을 적용한 심층 신경망 기반 음성 향상 기법 연구,2025,"['자기지도학습 표현', 'U-Net', 'Skip-connection', '음성 향상', 'Self-supervised learning representation', 'U-Net', 'Skip-connection', 'Speech enhancement']","자기지도학습(Self-Supervised Learning, SSL) 표현을 음성 처리 기법에 적용하는 다양한 연구가 진행되어왔다. 자기지도학습은 비지도 학습 중 하나로 대량의 데이터에 대해 스스로 라벨을 생성하여 학습을 수행하는 방식을말한다. 이 과정에서 모델은 입력된 대량의 데이터에서 잠재된 특징을 학습할 수 있게 된다. 본 논문에서는 자기지도학습에서 추출된 잠재된 음성 표현을 마스크 추정 기반 U-Net 모델에 적용한 음성 향상 연구를 제안한다. U-Net 모델의Encoder-Decoder 구조는 입력 신호를 압축하고 skip-connection을 통해 복원하여 음성 명료도를 효과적으로 향상시킨다. 제안하는 방법에서 skip-connection에 자기지도학습 표현을 추가적으로 전달함으로써 기존의 시스템과 비교하여 깨끗한 음성 예측 성능이 향상된 마스크를 추정하도록 한다. 음성 향상의 결과를 평가하기 위한 지표로 Source-toDistortion Ratio(SDR), Perceptual Evaluation of Speech Quality(PESQ), Short-Time Objective Intelligibility (STOI)를 사용하였으며, 본 논문에서 제안하는 방법이 SDR, PESQ, STOI 모든 지표에서 개선된 성능을 보였다.","Various studies have been conducted to apply Self-Supervised Learning (SSL) representation to speech processing. SSL is one of the unsupervised learning, which refers to a method of performing learning by generating labels on large amount of data by itself. In this progress, the model can learn the latent features of the input large amount of data. In this paper, we propose a study on speech enhancement by applying the latent speech representation extracted from SSL to a mask estimation-based U-Net model. The encoder-decoder structure of the U-Net model compresses the input signal and effectively restores it through skip-connection to improve speech clarity. At this time, the SSL representation is additionally delivered to skip-connection to estimate the mask with improved performance than the existing system. Source-to-Distortion Ratio (SDR), Perceptual Evaluation of Speech Quality (PESQ), and Short-Time Objective Intelligibility (STOI) were used as performance measure to evaluate speech enhancement, and the method proposed in this paper showed improved performance in SDR, PESQ, and STOI. Through this, we showed that the proposed method can improve speech clarity and quality."
결함 검사 시스템에서 단일 클래스 학습을 통한 이상 탐지 제어,2025,"['anomaly detection', 'unsupervised learning', 'one-class classification', 'MVTec-AD', 'Deep SVDD', '.']",,"This paper presents a novel image-level anomaly detection control method for defect inspection, which comprises feature- extraction from high-dimensional data and feature-learning to analyze the observed patterns. we focus on the feature-learning step, especially in Deep SVDD. To determine anomalies from images of object suspected to be defective, Deep SVDD learns the decision boundaries for the normal feature distribution in the latent space. When a new image is received by the defect inspection system, Deep SVDD maps its features to the latent space and detects anomalies based on whether the observed features fall within the decision boundaries for normal features. The decision boundary of Deep SVDD is determined based on the center-point, which is the center position of the decision boundary. The center-point is randomly fixed at the beginning of training of Deep SVDD. However, this limits the possibility of finding the optimal decision boundary. Therefore, we propose a center-point-moving method to optimize the center-point location and improve the performance of Deep SVDD. To confirm the suitability of the proposed method, we conducted experiments on MVTec-AD, a defect inspection dataset for several products in the manufacturing industry. Based on the results, the proposed method improved the performance of Deep SVDD in 11 of the 15 class domains in the MVTec-AD dataset."
산업용 인버터 고장예측을 위한 머신러닝 및 딥러닝 모델의 성능 평가 및 개선 연구,2025,"['industrial Inverter', 'Fault Prediction', 'Machine Learning', 'Deep Learning', 'Anomaly Detection']",,"In industrial settings, inverters play a critical role in maintaining productivity and ensuring stable equipment operation. However, inverter failures can result in production downtime and increased maintenance costs. Traditional fault prediction methods based on physical models and expert experience often struggle to capture complex patterns and adapt to varying operational conditions. To address this, this study evaluates the performance of statistical, machine learning, and deep learning approaches for industrial inverter fault prediction, using operational data from a 90W-class inverter at an automotive parts manufacturer in Daegu, South Korea. The experimental results demonstrate that unsupervised anomaly detection models, particularly Autoencoder and SOM, achieved the highest accuracy. These findings suggest that models capable of detecting deviations from normal operating patterns are more effective for inverter fault prediction than conventional methods. In contrast, SVM and Logistic Regression exhibited limitations in handling time-series complexity. This study highlights the necessity of deploying real-time monitoring and predictive maintenance systems in industrial environments, with future research focusing on hyperparameter optimization and real-time data streaming validation."
창업가의 언어적 스타일과 자금조달 성과 간의 관계: 머신러닝 알고리즘을 중심으로,2025,"['크라우드 펀딩', '자금조달', '창업가', '언어적 스타일', 'LIWC', 'Kiva', '머신러닝', 'Crowdfunding', 'Fundraising', 'Founders', 'Linguistic Style', 'LIWC', 'Kiva', 'Machine Learning']",,"Global crowdfunding platforms are growing in popularity as a source of funding for entrepreneurs. Much of the prior research on crowdfunding has focused on project success factors, and an under-researched topic is the linguistic style of founders. A small number of researchers have examined the linguistic characteristics of content within reward-based crowdfunding. According to speech act theory, not only what founders try to convey, but also how they convey it(i.e. their linguistic style) is likely to affect performance. In this study, we use machine learning algorithms to analyze the impact of different founders' linguistic styles on fundraising performance in the crowdfunding context. Specifically, we use latent class analysis(LCA), an unsupervised learning method, to categorize combinations of linguistic styles into classes and analyze whether there are differences in funding performance based on these classes. We also utilize the Random Forest algorithm, a supervised learning method, to predict funding performance and explore the importance and direction of influence of each linguistic style variable based on Shapley value. For the empirical analysis, we collected data from 16,279 campaigns on Kiva, a crowdfunding site. Linguistic style was measured using the linguistic inquiry and word count(LIWC) program. The LCA revealed that four linguistic style tiers were the best fit, and there were significant differences in fundraising performance across tiers. The random forest model predicted fundraising performance relatively accurately(AUC = .71), and the importance of the variables was in the following order: word count, external focus, analytical style, and positive style."
오토 인코더 기반의 앙상블 기법을 활용한 전동기 고장 상태 분류 방법,2025,"['Deep Learning', 'Motor fault diagnosis', 'Auto-encoder', 'LRP', 'Ensemble']",,"In the field, unsupervised learning-based fault diagnosis is necessary due to the lack of fault data. However, conventional auto-encoder models face challenges in fault classification. To address this issue, this study proposes an unsupervised learning-based auto-encoder model enhanced with an ensemble approach. The proposed model performs fault classification using gear, bearing, and eccentricity fault data, and employs the Layer-wise Relevance Propagation (LRP) technique to improve fault classification. Through the LRP technique, the key frequency bands relevant to each fault are identified and incorporated into the learning process, allowing for frequency band-based training. As a result, the proposed auto-encoder model improves classification performance and effectively distinguishes between different types of faults."
비지도 대조학습 시계열 인코더를 활용한 표현벡터 기반 시계열 유사도 분석 기법,2025,"['Deep learning(심층 학습)', 'Energy demand forecasting(에너지 요구량 예측)', 'Representation vector(표현벡터)', 'Transfer learning(전이학습)', 'Unsupervised contrastive learning(비지도 대조학습)']",,"Data scarcity and high development costs pose significant challenges to building-specific energy demand forecasting models. To address these issues, this study introduces a time series similarity assessment method that utilizes TS2Vec, an unsupervised learning-based encoder for extracting time series representation vectors. The efficacy of this approach is demonstrated using anonymized datasets of building electricity usage from Cambridge, UK. The proposed methodology stands out for its ability to identify high-similarity data segments by flexibly adjusting the evaluation time window used for extracting representation vectors, outperforming traditional average similarity assessments. Principal component analysis was employed for dimensionality reduction and visualization, alongside a moving window cosine similarity approach to enhance the interpretability of complex multivariate time series data similarities. The study's key findings are as follows. First, dynamic similarity analysis effectively captured the complexity of building energy use patterns. Second, the approach demonstrated the potential to optimize transfer learning by automatically identifying the most suitable source data. Third, the study explored the feasibility of employing dynamic model selection and ensemble techniques based on temporal similarity changes. This study proposes a practical and scalable methodology to mitigate data scarcity and reduce model development costs, thereby facilitating more efficient, adaptive, and accurate energy demand forecasting."
에지 분리를 통한 단일 이미지 기반 반사 성분 제거,2025,"['Computer vision', 'Image processing', 'Deep learning', 'Unsupervised learning', 'Reflection removal']","본 논문에서는 단일 영상에서 반사 성분을 효과적으로 제거하기 위한 새로운 비지도 학습 기반 방법을 제시한다. 단일 영상의 에지 강도를 활용하여 에지를 강한 에지와 약한 에지로 분류하고, 이에 따라 저역 통과 필터와 고역 통과 필터를 적용하여 전처리된 영상을 생성한다. Double Deep Image Prior(Double DIP) 모델은 두 이미지의 강도 차이를 이용하여 투명층을 분리하는 프레임워크인데, 이를 단일 이미지로 진행하기 위해 영상의 강한 에지를 흐리게 하고 약한 에지를 강조한다. 이후, 개선된 투명층 분리 모듈인 Double DIP 프레임워크를 활용하여 입력 영상과 전처리된 영상을 투과층과 반사층으로 분리한다. 이 과정을 반복적으로 수행함으로써 반사 성분을 점진적으로 제거하고 반사 제거 성능을 향상시켰다. 실험 결과, 제안된 방법은 기존의 비지도 학습 기반 방법보다 우수한 반사 제거 성능을 보였으며, 레이블링된 데이터 없이도 효과적인 반사 제거가 가능함을 확인하였다.","In this paper, a novel unsupervised learning-based method for effectively removing reflections from a single image is proposed. The method utilizes the edge intensity of a single image to classify the edges into strong and weak edges, applying a low-pass filter and a high-pass filter accordingly to generate a preprocessed image. The Double DIP model, a framework leveraging the intensity difference between two images, is employed to separate transparent layers, blur strong edges, and highlight weak edges to produce a single image. Subsequently, an improved transparent layer separation module, the Double DIP framework, separates the input and preprocessed images into transmissive and reflective layers. This iterative process gradually removes reflective components, enhancing the performance of reflection removal. Experimental results demonstrate that the proposed method outperforms existing unsupervised learning-based approaches for reflection removal and validates the feasibility of achieving effective reflection removal without labeled data."
MS-Office 계열 파일 내 매크로 정보 기반 악성 정보 자동 검출 메커니즘 설계 및 구현,2025,"['MS Office 매크로 파일', '악성 코드', '머신러닝', '자동 검출 시스템', '지도/비지도 학습 모델', 'MS Office Macro File', 'Malicious Code', 'Machine Learning', 'Auto-Detection System', 'Supervised/Unsupervised Learning Model']",,"In this paper, we designed and implemented a system that applies machine learning techniques to automatically detect malicious macro information embedded in MS Office files. When an MS Office file contains macro functionality, it may perform abnormal actions on the user’s system, potentially leading to the leakage of sensitive personal information stored within the system. Therefore, a system is needed to automatically detect malicious scripts embedded in MS Office files and verify any tampering. To achieve this, this study applies supervised and unsupervised learning-based machine learning models to design and implement an automatic detection system for determining whether an MS Office file contains malicious macro data. Experimental results demonstrate that the proposed system provides improved detection performance compared to existing methods, ensuring a safer environment for the use of MS Office files."
회화 이미지 검색을 위한 언어 기반 의미론적 임베딩,2025,"['이미지 검색', '의미론적 임베딩', '문장 임베딩', '유사도 측정', '문화유산 디지털화', '딥러닝', '컴퓨터 비전', 'Image Retrieval', 'Semantic Embedding', 'Sentence Embedding', 'Similarity Measurement', 'Cultural Heritage Digitization', 'Deep Learning', 'Computer Vision']","문화유산 보존과 접근성 향상을 위한 디지털화가 가속화됨에 따라, 효과적인 회화 이미지 검색 시스템의 중요성이 증가하고 있다. 그러나 라벨이 부족한 데이터셋과 미세한 시각적 차이가 완전히 다른 예술 장르를 나타내는 회화 도메인의 특성으로 인해, DINOv2와 같은 기존의 비지도 학습 기반 이미지 임베딩 방법은 제한적인 성능을 보인다. 본 연구에서는 이러한 한계를 극복하기 위해 Vision-LLM을 활용하여 회화 이미지에 대한 풍부한 텍스트 설명을 생성하고, 이를 문장 임베딩 모델을 통해 벡터화하여 의미론적 유사도 기반 검색을 수행하는 새로운 접근법을 제안한다. 다양한 Vision-LLM 모델과 문장 임베딩 모델, 유사도 측정 방법을 체계적으로 비교한 결과, 제안된 방법은 accuracy 79.17%, mAP 0.6771로 기존 비지도 학습 기반 접근법인 DINOv2 대비 Accuracy에서 171.41%, mAP에서 211.45% 향상된 성능을 보였다. 특히 Qwen2.5-VL-3B-Instruct 모델과 문맥 인식 임베딩 모델 조합이 가장 우수한 성능을 달성했으며, 이는 언어 기반 의미론적 접근법이 시각적 특징만으로는 포착하기 어려운 회화의 맥락적, 의미론적, 상징적 특성을 효과적으로 활용할 수 있음을 시사한다.","As the digitization of cultural heritage accelerates to improve preservation and accessibility, the importance of effective artwork image retrieval systems is increasing. However, existing unsupervised learning-based image embedding methods such as DINOv2 show limited performance in the artwork domain, which is characterized by datasets lacking labels and subtle visual differences that represent completely different artistic genres. This study proposes a novel approach to overcome these limitations by utilizing Vision-LLMs to generate rich textual descriptions of artwork images, vectorizing them through sentence embedding models, and performing semantic similarity-based retrieval. Through systematic comparison of various Vision-LLM models, sentence embedding models, and similarity measurement methods, the proposed approach achieved 79.17% accuracy and 0.6771 mAP, demonstrating a 171.41% improvement in accuracy and 211.45% improvement in mAP compared to the existing unsupervised learning-based approach DINOv2. In particular, the combination of the Qwen2.5-VL-3B-Instruct model and context-aware embedding models achieved the best performance, suggesting that language-based semantic approaches can effectively leverage contextual, semantic, and symbolic characteristics of artworks that are difficult to capture through visual features alone."
Fourier Ptychographic Microscopy 기반 도메인 전환을 활용한 디지털 염색 알고리즘,2025,"['Digital staining', 'Generative adversarial networks', 'Domian transformation', 'Fourier ptycho- graphic microscopy']",,"Digital staining (DS) has solved the problems of traditional histological staining (HS), which is complicated, time-consuming, and costly. However, differences in staining protocols (e.g., solution concentration, staining time, scanner used, patient variability) have not completely overcome the differences in staining color and quality. To solve this problem, we used a DS method utilizing domain transformation in unstained images. This study proposes a sin- gle-domain transformation staining method combining unsupervised and supervised learning, as well as an unsu- pervised learning-based multi-domain transformation staining method. The data were constructed using fourier ptychographic microscopy and bright-field microscopy images and optimized for training through five preprocessing steps. Afterward, we compared the proposed methods with the existing unsupervised staining method, CycleGAN. Prior to evaluation, the data were further processed through postprocessing to facilitate analysis. The visual eval- uation showed that the proposed method effectively distinguished the background compared to the control group and prevented the over-staining issue that occurs during the HS process. Quantitative evaluation using a cell nucleus detection model demonstrated that the proposed model showed improvements of more than 7.96% and 10.81% in the Dice and Jaccard indices, respectively, compared to the CycleGAN model. This indicates that the proposed model achieves digital staining that closely resembles the traditional Hematoxylin and Eosin staining method, and it sug- gests that supervised learning can be utilized even in environments without paired data, and unstained images can be used in multi-staining research."
Latent Preference-Driven Information Cascade Prediction on Complex Networks,2025,"['Complex Network', 'Information Cascade', 'Latent Preference', 'Deep Learning']",,"The exponential growth of user-generated content (UGC) within complex networks, covering scenarios like micro-blogs and academic articles, presents a novel challenge for cascade prediction. This challenge stems from the intricate task of harnessing the inherently noisy, unlabeled UGC to glean insights into user preferences and the underlying motivations behind online behaviors. Moreover, the combination of such content data with conventional features, which delineate temporal and structural cascade variations for predictive tasks, remains largely unexplored. In response to these challenges, we present a novel framework termed latent preference-driven information cascade prediction (LPCAS). This framework seamlessly integrates latent user preference extraction and information cascade prediction into a unified model. To be exact, the latent preference-aware autoencoder is designed to extract individual preferences from unlabeled historical records in an unsupervised manner by adopting a discrete categorical distribution. Subsequently, we have incorporated a skip-based cascade aggregator that concurrently considers micro-level individual preferences and macro-level cascade variations. The performance of the proposed LPCAS framework is benchmarked against state-of-the-art methods, including handcrafted feature regression, generative approaches, and deep learning-based models, using two real-world datasets. The comprehensive experimental results across diverse scenarios conclusively demonstrate the remarkable ability of the proposed framework to predict information cascades."
Transformer 알고리즘의 3차원 공간정보 적용 방안 : 포인트클라우드 처리 기법을 중심으로,2025,"['AI', 'Transformer', 'GPT', '3D Spatial Information', 'Point Cloud', '3차원 공간정보', '포인트 클라우드']","최근 GPT와 DeepSeek와 같은 대규모 언어 모델들은 Transformer 알고리즘을 기반으로 뛰어난 성능을 보이고 있다. 특히 DeepSeek는 부동 소수점 연산 최적화와 SFT (Supervised Fine Tuning) 과정을 생략하고 대규모 강화학습을 적용하여 학습 효율을 획기적으로 향상시켰다. 본 연구는 Transformer 알고리즘을 3차원 공간정보, 특히 포인트 클라우드 데이터의 처리에 효과적으로 적용하기 위한 방법론을 제안하였다. 구체적으로, Transformer 모델 성능을 극대화 하도록 입력 벡터를 최적화하는 방안을 제시하였으며, 데이터 내의 고정값과 추론값을 효과적으로 처리하기 위한 가중치 행렬 설계 방안을 제안하였다. 또한, 3차원 공간정보의 국소적, 전역적 특성을 모두 반영할 수 있는 Attention 영역을 설정하는 전략과, 공간정보에 특화된 Multi-Head Attention 구조를 설계하였다. 나아가 입력 벡터에 주입된 속성 일부를 마스킹하여 비지도 사전학습을 수행하는 방법론을 제시하였으며, 공간정보에 특화된 대규모 언어 모델과의 Joint Embedding을 활용한 강화학습 기반의 효율적인 학습 전략도 제안하였다. 본 연구는 이론적 접근을 중심으로 향후 실험적 연구와 실제적 응용을 위한 견고한 기초를 제공한다. 기존의 인공지능 전문가가 공간정보를 다루는 방식이 아니라, 공간정보 전문가의 관점에서 인공지능 기술을 도입함으로써, 공간정보 분야에서 Transformer 알고리즘의 실질적인 적용 가능성을 입증하는 데 중요한 이론적 기초를 마련하였다. 이는 궁극적으로 AI 기반 공간추론 및 공간인식 분야의 기술적 진보를 위한 시금석이 될 것으로 기대한다.","Recently, large-scale language models such as GPT and DeepSeek have demonstrated remarkable performance based on Transformer algorithms. In particular, DeepSeek has significantly improved training efficiency by optimizing floating-point computations and employing large-scale reinforcement learning, omitting the conventional supervised fine-tuning (SFT) process. This study proposes an effective methodology for applying Transformer algorithms to 3D spatial information, specifically point cloud data. The proposed approach includes optimization strategies for input vectors to maximize Transformer model performance, and the design of weight matrices capable of efficiently handling both fixed and inferable values within the data. Furthermore, the study introduces a strategy for defining attention regions that incorporate both local and global characteristics inherent in 3D spatial data, along with the development of a Multi-Head Attention structure tailored specifically for spatial information. Additionally, an unsupervised pre-training method using attribute masking within input vectors is proposed, alongside an efficient reinforcement learning-based training strategy leveraging joint embedding with spatially specialized large language models (LLMs). Primarily theoretical, this study provides a solid foundation for future experimental research and practical applications. Rather than adopting a traditional AI-centric approach to spatial data processing, this research introduces AI technology from the perspective of spatial information experts, thereby establishing a critical theoretical basis for verifying the practical applicability of Transformer algorithms in the spatial information domain. It is hoped that this work will contribute to technical advances in AI-based spatial reasoning and spatial perception."
웨이퍼 레벨 패키지 신뢰성 수명 예측을 위한 인공지능 기술 연구동향,2025,"['Machine learning algorithms', 'Reliability life prediction', 'Supervised learning', 'Unsupervised learning', 'Hybrid learning', 'Advanced packaging', '.']",,"Advanced packaging technologies are rapidly evolving to meet the semiconductor industry’s increasing demands for higher performance, miniaturization, and lower power consumption. Among these technologies, wafer-level packaging (WLP) has emerged as a key solution due to its superior capability in achieving compactness and enhanced performance. However, predicting the reliability life of WLP remains a significant challenge due to its complex structure and various environmental factors. Traditional reliability life prediction methods, such as physicsbased modeling and accelerated life testing, are limited by high costs and long time requirements. To address these limitations, artificial intelligence (AI), particularly machine learning (ML) algorithms, have gained significant attention. This study discusses recent trends in ML algorithms for reliability life prediction in advanced packaging, focusing on unsupervised learning, supervised learning, and hybrid learning approaches. Additionally, the paper provides insights into potential future research directions."
Integrating Error Back-Propagation and Independent Component Analysis Algorithms to Enhance Neural Network Performance,2025,"['Merge of Supervised and Unsupervised Learning', 'Error Back-propagation', 'Independent Component Analysis', 'Neural Networks']",,"The EBP (Error Back-Propagation) Algorithm was initially proposed for training MLP’s (Multi-Layer Perceptrons) and is now widely used for training deep neural networks. This supervised learning algorithm minimizes the error function between the actual output values of MLP’s and their desired values. However, ICA (Independent Component Analysis) is an unsupervised learning algorithm that aims to maximize the independence among the outputs of neural networks. ICA has been shown to realize visual features in the V1 layer of the human brain by learning from natural scenes and cochlear features of the human ear by learning from auditory signals. In this paper, we propose merging the supervised EBP algorithm with the unsupervised ICA algorithm to enhance the performance of neural networks by training independent features in the initial learning stage. This approach mirrors the feature-learning process observed in mammals during the early stages of life. Furthermore, the proposed approach is verified through simulations on isolated-word recognition tasks, achieving improved classification performance with faster learning convergence. In detail, when the number of hidden nodes is 100, EBP with ICA reaches a misclassification ratio of 2.78% on the test data at 160 epochs, while EBP achieves 3.28% at 300 epochs."
Exploring energy consumption patterns in Colombian companies: a functional data clustering approach,2025,"['clustering', 'functional data', 'unsupervised learning', 'energy consumption', 'dual exploration', '$k$-means', 'PAM', 'HDBSCAN', 'internal validation', 'stability']",,"Clustering is a form of unsupervised learning designed to group data based on its inherent structural patterns and characteristics, identiﬁed through data exploration rather than assumptions that may introduce bias. In this work, we focus on the application of a novel data-driven clustering methodology to energy consumption data, treated as an aggregated signal. By disaggregating this signal, we aim to identify relevant consumption proﬁles or device-level behaviors—an approach rarely applied in energy analysis. From a methodological perspective, we propose to combine both distance-based (k-means, PAM) and density-based (HDBSCAN) clustering methods, extending them from multivariate to functional data. This dual exploration oﬀers a broader search spectrum in contrast to each individual framework or paradigm.  From an algorithmic perspective, we enhance the initial- ization of PAM with the randomized seeding technique of k-means++ for improved performance and optimize HDBSCAN’s minpts hyperparameter based on internal validation metrics (Stability Score, GLOSH Score, and Membership Probability Score) for improved robustness rather than relying on traditional empirical methods. We demonstrate the eﬀectiveness of our methodology by applying it to both synthetic and real-world energy consumption data.  Results show that while both density-based and distance-based methods could individually identify clusters under speciﬁc conditions, only the dual methodology successfully identiﬁed clusters across all synthetic settings. In the real data application, we conﬁdently identiﬁed three distinct clusters that represent en- ergy consumption patterns: constant, day, and night. These results highlight the potential of the methodology for clustering functional data in an arbitrary context and provide valuable insights into energy analysis."
온라인 채용정보를 활용한 보안 채용시장 분석,2025,"['cybersecurity', 'Cybersecurity Workforce', 'Job Analysis', 'Unsupervised learning', 'topic modeling', '사이버보안', '사이버보안 인력', '직무분석', '비지도학습', '토픽모델링']","본 연구는 보안 인력과 관련한 통계를 보다 시의성 있게 제공하기 위해 온라인 채용정보를 활용하는 방법을 제안하였다. 기존의 보안 인력 관련 조사는 ‘정보보호산업실태조사’와 ‘정보보호실태조사’가 대표적이지만 각각 일반 기업에서의 보안 인력 현황이나 직무별 세부 현황을 구체적으로 파악하기 어렵다는 한계가 있었다. 또한 이러한 조사는 1년 주기로 이루어지며 조사 설계부터 결과 공표까지 과정이 길어 시의성이 떨어지는 단점이 있었다. 본 연구는 이러한 한계를 보완하고자 구직공고 사이트에서 제공되는 채용정보를 활용하는 방법론을 제시한다. 특히 하나의 채용공고를 직무 단위로 세분화하여 보다 세밀한 직무분석을 진행하였으며, 비지도학습 기법으로 데이터를 그룹화한 뒤 이를 NCS 직무 분류체계와 매칭시켜 NCS 직무분류체계에 기반을 둔 채용현황 수치를 산출하였다. 이러한 방식은 보안 인력과 관련한 통계를 시의성 있고 효율적으로 제공하여 시점에 맞는 보안 인력 양성 정책의 수립과 실행에 기여할 수 있을 것으로 기대된다.","This study proposed a method to provide more timely statistics on cybersecurity workforce trends by utilizing online job postings. Traditional cyber security workforce surveys, such as the Information Security Industry Survey and the Information Security Survey, have limitations in capturing workforce distribution and detailed job classifications within companies. These surveys are conducted annually, resulting in long delays from data collection to publication, reducing their timeliness. To address these limitations, this study introduces a methodology that leverages job postings from recruitment platforms. Each job posting is segmented into specific job roles for a more granular analysis. Unsupervised learning techniques are applied to cluster the data, which is then matched to the National Competency Standards(NCS) job classification framework to generate workforce statistics. This approach enables the real-time monitoring of cybersecurity workforce trends and provides more timely, data-driven insights. Ultimately, it can assist in formulating and implementing workforce development policies aligned with industry demands."
AutoEncoder기반의 축구 포지션별 팀 관리 시스템 모델 연구,2025,"['Autoencoder', 'Soccer Team Management', 'Deep Learning', 'Performance Analysis', 'AutoEncoder', '축구팀 관리', '딥러닝', '퍼포먼스 분석']","연구목적 본 연구는 딥러닝 기술 중 하나인 AutoEncoder를 활용하여 축구 선수의 포지션별 퍼포먼스를 정량적으로 평가하고 관리할 수 있는 시스템 모델 제안을 목적으로 한다. 연구방법 Kaggle Platform에서 제공하는 EA SPORTS FC 24 선수 퍼포먼스 데이터를 활용하여 대용량의 데이터를 유사한 특성을 가진 군집으로 클러스터링 한 후, AutoEncoder를 활용해 유효성을 확인하고 Confusion Matrix를 통해 모델의 성능을 평가하였다. 결과 첫째, 입력 데이터를 압축하고 복원하는 방식의 AutoEncoder 기반 축구 포지션별 팀 관리 시스템을 제안하였다. 둘째, 각 포지션별 분석 결과 Defender 1명, Midfielder 64명, Forward 9명, Goalkeeper 3명이 퍼포먼스 기준을 초과하였다. 셋째, Confusion Matrix 결과 포지션별 정확도 및 F1-Score가 모두 0.72 이상으로 정확도와 신뢰성을 입증하였다. 결론 본 연구는 AutoEncoder 기반 딥러닝 모델이 축구 선수의 포지션별 퍼포먼스를 객관적으로 평가하고 스카우팅 및 전략 수립에 유용한 도구로 활용될 수 있음을 시사한다.","Purpose The The This study proposes a system model that quantitatively evaluates and manages soccer player performance by utilizing AutoEncoder, a deep learning technique. Methods To achieve this, the study used the EA SPORTS FC 24 player performance data provided by the Kaggle Platform. After clustering the large dataset into groups with similar characteristics, the effectiveness of the model was validated using AutoEncoder, and the model’s performance was evaluated through a Confusion Matrix. Results First, through the unsupervised learning of AutoEncoder, the model effectively learned the key patterns in the player data and extracted latent features, enabling comparison and evaluation between a player’s current state and target state. Second, the positional analysis showed that 1 defender, 64 midfielders, 9 forwards, and 3 goalkeepers exceeded performance thresholds. Third, the Confusion Matrix results demonstrated that the accuracy and F1-Score for each position were above 0.72, confirming the model's accuracy and reliability. Conclusion This study suggests that the AutoEncoder-based deep learning model can objectively evaluate soccer players' performance by position and serve as a useful tool for scouting and strategic planning."
전자기파 신호분석을 통한 무기체계 부품 이상행위 탐지 연구,2025,"['Hardware Trojan', 'Anomaly Detection', 'Electromagnetic Analysis', 'Side channel analysis', 'FPGA', 'ASIC', '하드웨어 트로이목마', '이상행위 탐지', '전자기파 분석', '부채널 분석', 'FPGA', 'ASIC']","본 논문은 무기체계 및 IoT 장비 부품에서 발생하는 이상행위를 탐지하기 위해 부채널 분석을 이용하여 장비 부품 해체와 같은 파괴적 방법이 아닌 조립된 상태 그대로 검사하는 비파괴적 방법의 적용 가능성을 보였다. 무기체계 부품에서 발생하는 이상행위는 하드웨어 트로이목마 (HT, Hardware Trojan)에 의해 발생하는 것을 의미하며 부채널 분석 방법 중에서도 전자기파 신호분석을 이용하였다. 초기 시험은 HT공유 포털에서 제공하는 암호 모듈인 AES(Advanced Encryption Standard)-128 GM(Golden Model)과 HT들로 시험했으며 대상 하드웨어 플랫폼은 먼저 FPGA(Field Programmable Gate Array)에서, 그 후에는 ASIC(Application Specific Integrated Circuit) 칩을 제작하여 시험하였다. IoT 장비로는 RC 자동차, 무기체계 장비 부품으로는 군통신체계에 사용된 FPGA와 동일한 신규 제품과 시뮬레이션 장비를 이용하여 시험함으로써 무기체계에서 부품 이상 여부를 탐지할 수 있는 기술의 적용 가능성을 보였다.","This paper demonstrates the possibility of a non-destructive method that inspects the assembled state of the equipment circuit rather than a destructive method such as disassembling the equipment circuits, using side-channel analysis to detect abnormal behaviors in weapon systems and IoT equipment circuits. The abnormal behaviors generated in weapon system circuits are caused by hardware Trojans (HTs), and electromagnetic signal analysis was used among the side-channel analysis methods. The initial experiments were conducted with the AES-128 GM, an encryption module provided by the HT sharing portal, and HTs. The target hardware platform was first implemented in the FPGA, and then tested on the manufactured ASIC chip. Initially, the tests were conducted using supervised learning machine learning as an abnormal behavior detection algorithm, and then unsupervised learning deep learning models were used. After proving the possibility with the FPGA and the manufactured ASIC chip, the tests were conducted on the RC car as IoT equipment, and the possibility of the circuit abnormal behavior detection technology was demonstrated by conducting experiments on the same product FPGA applied to the weapon system."
이미지 색 공간 융합을 통한 픽셀 클러스터링 기반 수중 이미지 내의 반사광 탐지 알고리즘,2025,"['Machine Learning(머신 러닝)', 'K-Means Clustering(K 평균 군집화)', 'Multi-Channel Image(다채널 이미지)', 'Pixel Clustering(픽셀 클러스터링)', 'Underwater Image(수중 이미지)']",,"Robots designed to assist and ensure safety during underwater diving activities utilize underwater cameras to gather real-time diver information. This study proposes a breath bubble detection algorithm based on unsupervised kmeans clustering to overcome the high accuracy demand of deep learning models and the challenge of constructing training datasets. By integrating color and relative coordinate information from underwater images and applying CLAHE to reduce noise, pixel clustering is performed to extract reflective regions. Experimental results demonstrate the effectiveness of the proposed algorithm in detecting breath bubble regions in underwater images. Improved detection accuracy is achieved through the combination of RGB, LAB, and HSV color spaces. This research provides a foundation for the monitoring of diver status and equipment malfunctions in underwater environments."
Energy-Valence 모델 적용을 통한 문장 감성 기반 음악 추천 시스템 구현,2025,"['Emotional Analysis', 'Recommendation System', 'Unsupervised Learning', 'K-means', 'Application Development']",,"In this study, we present Feelic, an emotion-based music recommendation application that analyzes users' emotions and recommends customized music. The system classifies the user's diary into five emotions: joy, sadness, anger, anxiety, and neutrality using the KoBERT model, and recommends music that matches the emotions by extracting audio characteristics of various songs using Spotify API. Through K-means clustering, music is divided into 30 clusters and songs belonging to clusters such as user-preferred music are recommended. The application is designed so that users can easily write a diary, analyze emotions, and recommend music accordingly, and aims to manage emotions and improve mental health. To prove the usefulness and effectiveness of Feelic, an emotion analysis system, a music recommendation system, and an application implementation process are described in detail. The results are evaluated with the energy-valence model and presented as reasonable."
Simplified Graph Convolution based Anomaly Detection for Multivariate Time Series,2025,"['Anomaly Detection', 'Discrete Wavelet Transform', 'Simple Graph Convolution', 'Multivariate Time Series', 'Time Series Mining']",,"In industrial settings, multivariate time series generated from various monitoring metrics are abundant. Anomaly detection in these time series is crucial for applications such as fault diagnosis and root cause analysis. Recent advancements in unsupervised methods, particularly autoencoder (AE)-based reconstruction architectures, have made significant progress in this area. These systems learn the normal data distributions and produce substantial reconstruction errors when encountering anomalies. While AEs are effective at reconstructing subtle abnormal patterns due to their strong generalization capabilities, this can also result in a high false negative rate. Furthermore, AE-based models often fail to account for inter-variable dependencies across different time scales. In this paper, we propose an enhanced anomaly detection framework that builds upon the Multiscale Wavelet Graph Autoencoder (MEGA) by replacing the Graph Convolutional Network (GCN) with Simplified Graph Convolution (SGC) to improve model performance. The key idea is to utilize the spectral methods of SGC to process the multivariate time series data, integrating Discrete Wavelet Transform (DWT) into the AE. We conducted experiments on three public multivariate time series anomaly detection datasets, and the results demonstrate that the improved model using SGC outperforms existing methods."
공정 평균과 분산을 동시에 모니터링하는 autoencoder 절차의 성능,2025,"['autoencoder', '평균 런길이', '관리도', '최초신호 기준', 'autoencoder', 'average run length', 'control chart', 'first-to-signal criterion']","Autoencoder는 딥러닝 기반의 비지도 학습 방법으로 최근 이상치를 탐지하는 데 효과적인 방법으로 관심을 받고 있다. 이 논문에서는 autoencoder 모형에 기초한 공정 모니터링 절차를 제안하고, 그 성능을 $\bar{X}$-$S$, Max, MaxEWMA 관리도를 포함한 전통적인 관리도 절차와 비교하였다. 모의실험은 정규분포 공정에서 평균과 분산에 변화가 발생한 상황을 고려하였고, 평균 런길이(ARL)와 최초신호 기준(First-to-Signal criterion) 등의 측도를 사용하여 성능을 평가하였다. 모의실험 결과를 통하여 각 절차의 강점과 한계를 분석하고, 다양한 공정 상황에 적합한 모니터링 절차에 대한 유용한 정보를 제공하였다.","The autoencoder, an unsupervised learning method based on deep learning, has recently gained attention for its effectiveness in detecting abnormal signals in process monitoring. This study compares the autoencoder's performance with traditional monitoring charts, including the $\bar{X}$-$S$, Max, and MaxEWMA charts. Simulations are performed under scenarios involving mean and/or variance shifts in normally distributed processes. Key performance metrics, such as Average Run Length (ARL) and First-to-Signal criterion, are used to evaluate their efficiency. The results highlight the strengths and limitations of each procedure, offering valuable insights into their suitability for various process monitoring applications."
감염병 위기에서 AI는 어떻게 사용되었는가: COVID-19 연구동향 분석,2025,"['Artificial intelligence', 'COVID-19', 'forecasting', 'public health', '.']",,"Background: The COVID-19 pandemic prompted a surge in artificial intelligence (AI) research with health- related applications, including diagnosis, forecasting, and policy evaluation. While many reviews have summarized model performance, few have examined the structural relationships between research aims, data types, and algorithm selection.Objectives: This study presents a narrative review of AI-based COVID-19 research, focusing on how algorithm choices evolved across different functional goals—clinical diagnosis and treatment, infection forecasting, and public health or policy response—and how these choices were shaped by data characteristics and different phases of the pandemic.Methods: We reviewed 108 peer-reviewed English-language studies published between 2020 and 2024. Each study was categorized by functional objective and analyzed in terms of AI methods used, data types and sources, geographic focus, and modeling strategies. Both quantitative trends and qualitative insights were synthesized.Results: Convolutional neural networks, support vector machines, and random forests were frequently used and showed broad applicability. Algorithm selection aligned closely with data types: deep learning was dominant in image-based tasks, while structured data often employed tree-based or logistic models. Over time, reliance on public case data declined, while the use of clinical and policy datasets increased. Supervised learning approaches remained dominant, although unsupervised methods were used for sentiment analysis and clustering. Modeling patterns varied significantly by research purpose, reflecting the structural match between methodological design and data context.Conclusions: AI use in COVID-19 research evolved with changing data environments and research needs. Algorithm choice reflected not only technical capacity, but also alignment with functional objectives and data structures. This narrative review provides guidance for the future development of AI-based tools in public health emergencies."
여성 연령별 출산율에 따른 지역 유형화 및 특성 진단 : 229개 시·군·구를 대상으로,2025,"['연령별 출산율', '지역 유형화', 'K-평균 군집', '다항 로지스틱 회귀분석', 'Fertility by Female Age', 'Region Typology', 'K-means Clustering', 'Multinomial Logistic Regression']","본 연구의 목표는 여성 연령대별 출산율(여성1,000명당 출생아 수) 시계열 데이터를 통해 군집화를 실시하여유형을 도출하고, 유형별로 속해 있는 지역의 특성을 살펴보고자한다. 연구의 시간적 범위는 2012년부터 2022년까지이며, 공간적 범위는 229개 기초지자체(시·군·구)를 대상으로 한다. 군집분석에는 여성의 연령별 출산율 시계열 데이터에 대해 비지도학습의일종인 Time-series K-means 클러스터링(Dinamic Time Warping 거리 기반)을 적용한다. 이후 도출된 지역별 유형을 종속변수로 다항 로지스틱회귀분석을 실시하여 각 유형의 특성을확인한다.기존의 인구 기반 지역 유형화 및 출산율 분석 연구가 갖는 정적 데이터의 한계를 보완하기 위해 본 연구는 시계열·다층적 데이터(여성의 연령별 출산율)를 지역 유형화에 사용하였다. 또한통계청에서 제공하고 있는 공공데이터 위주로 분석 데이터를 설정하여, 분석 내용 및 결과의 범용성과 접근성을 제고하고자 했다. 본 연구를 바탕으로 출산율에 대한 다각적인 접근을 다루는연구가 활성화되길 바라며, 본 연구 결과가 출산 관점에서 각 지역의 특성과 현황을 토대로 한 효율적인 정책 개발의 기초자료로기능하길 기대한다.","Population is the future of the region, and fertility is the backbone of the population. However, fertility in the Republic of Korea (RoK) is steadily declining, and policy efforts to address this issue have shown limited effectiveness. This study conducts in-depth analysis of new approaches to fertility. Accordingly, 11 years (2012-2022) of fertility data by female age (six age categories) for 229 regions (local governments) in the RoK were used and these regions were categorized by perspective of fertility power. The analysis utilized time-series K-means clustering, which is a type of unsupervised learning, and derived five clusters (types). Furthermore, the clusters were characterized using exploratory data analysis (trends and changes in fertility, local components within the clusters, etc.) and the following cluster characteristics consisting of economic, policy, socio-cultural, and demographic independent variables based on previous studies were identified through multinomial logistic regression. Significant differences were observed in the trend and rate of change of fertility by female age for each region type. This means that even in regions of similar size and conditions, one region experienced a rebound in fertility at all ages over the same time period, while another experienced a sharp decline. Spatial correlation in the formation of region type was also noteworthy. In addition, characteristics such as “population density,” “land price,” “number of childcare centers,” and “early marriage rate” differed by types, thus providing several implications. Consequently, we suggest the need for a thorough examination of regional fertility trends, and emphasize the importance of developing effective urban planning policies tailored to the unique fertility and population conditions of each region."
학교수학에서 데이터 과학 교육의 가치 탐색: 사회 관계망 분석을 중심으로,2025,"['data science', 'statistics education', 'school mathematics', 'digital literacy', 'social network analysis', '데이터 과학', '통계교육', '학교수학', '디지털 소양', '사회 관계망 분석']","본 연구는 데이터 중심 사회의 도래에 따라 학교수학에서 데이터 과학 교육이 갖는 교육적 가치와 가능성을 조명하고, 특히 사회 관계망 분석을 중심으로한 정보처리 역량이 디지털 소양으로 기능할 수 있는지에 대해 탐색하였다. 기존의 통계교육이 기술통계 중심의 단편적 활동에 그친 반면, 데이터 과학 교육은 데이터의 수집, 처리, 분석, 시각화 및 해석의 전 과정을 통합적으로 다루어 학생들의 문제해결력, 디지털 활용 능력, 창의적 사고력 등을 증진할 수 있는 것으로 나타났다. 사회 관계망 분석은 비지도학습의 대표적 기법으로, 그래프 이론을 바탕으로 관계 중심 데이터를 수학적으로 모델링하고 중심성 지표를 통해 정량적으로 분석할 수 있게 한다. 또한, 사회 관계망 분석은 수학적 모델링 과정과 긴밀하게 연결되어 학생들이 현실의 복잡한 문제를 수학적으로 구조화하고 비판적으로 해석하는 경험을 제공할 수 있다. 본 연구는 사회 관계망 분석이 정보처리 역량을 포함한 디지털 소양 함양을 위한 교육적 도구로 유의미하게 활용될 수 있음을 제안한다.","This study explores the educational value and potential of data science education in school mathematics in response to the rise of a data-driven society, with a particular focus on whether data processing skills—centered on social network analysis (SNA)—can be recognized as a form of digital literacy. While traditional statistics education has often been limited to descriptive statistics and mechanical calculations, data science education encompasses the entire process of data collection, processing, analysis, visualization, and interpretation. It emphasizes students’ problem-solving skills, digital literacy, and creative thinking. Social network analysis, as a representative unsupervised learning method, enables mathematical modeling and interpretation of relational data through graph theory and quantitative metrics such as centrality indices. This analytical approach aligns closely with the mathematical modeling cycle in education, offering students meaningful learning experiences in mathematically structuring and critically interpreting real-world problems through mathematics. The study argues that SNA can serve as an effective educational tool for fostering digital literacy and data competency."
