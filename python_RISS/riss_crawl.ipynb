{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크롬 드라이버 다운 필요\n",
    "(크롬이 최신 버전이라는 전제하에 시작, 작업 디렉토리까지의 절대경로에 한글이 있으면 오류가 발생할 수 있음)\n",
    "1. 크롬 접속 후 우측 상단 점 3개 클릭 → 도움말 → Chrome 정보 클릭\n",
    "2. 자신의 Chrome 버전 확인\n",
    "3. 링크 접속 https://googlechromelabs.github.io/chrome-for-testing/\n",
    "4. 자신과 똑같거나 거의 비슷한 버전의 왼쪽 단어 클릭(Stable, Beta, Dev, Canary 중 하나)\n",
    "5. chromedriver 항목중에서 자신의 OS 환경에 맞는 URL 주소 복사\n",
    "6. 인터넷 창에 URL 복사 붙여넣기하면 다운받을 수 있음\n",
    "7. 자신의 작업 디렉토리에 압축 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 터미널에 붙여넣기\n",
    "# pip install bs4 selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 검색어 설정\n",
    "search_keyword = \"LLM\"\n",
    "\n",
    "# 작업 디렉토리까지의 절대경로 입력 + 마지막에 / 입력\n",
    "load_folder = 'C:/Users/sinyoung/webcrawling/python_RISS/'\n",
    "\n",
    "# 데이터를 저장할 파일 이름 설정\n",
    "crawling_data_file_name = f'riss_crawling_{search_keyword}.csv'\n",
    "\n",
    "# 직접 검색하여 총 몇 페이지인지 확인 후 입력\n",
    "page_count = 46                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Service\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import getpass\n",
    "import time\n",
    "\n",
    "# URL 설정\n",
    "URL = f\"https://www.riss.kr/search/Search.do?isDetailSearch=N&searchGubun=true&viewYn=OP&query={search_keyword}&queryText=&iStartCount=0&iGroupView=5&icate=all&colName=re_a_kor&exQuery=&exQueryText=&order=%2FDESC&onHanja=false&strSort=RANK&pageScale=10&orderBy=&fsearchMethod=search&isFDetailSearch=N&sflag=1&searchQuery=LLM&fsearchSort=&fsearchOrder=&limiterList=&limiterListText=&facetList=&facetListText=&fsearchDB=&resultKeyword={search_keyword}&pageNumber=1&p_year1=&p_year2=&dorg_storage=&mat_type=&mat_subtype=&fulltext_kind=&t_gubun=&learning_type=&language_code=&ccl_code=&language=&inside_outside=&fric_yn=&db_type=&image_yn=&regnm=&gubun=&kdc=&ttsUseYn=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 페이지를 돌면서 링크를 가져오는 함수\n",
    "def get_paper_links(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지 로딩을 기다립니다.\n",
    "\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    links = []\n",
    "\n",
    "    for a in soup.select(\"#divContent > div > div.rightContent.wd756 > div > div.srchResultW > div.srchResultListW > ul > li > div.cont.ml60 > p.title > a\"):\n",
    "        links.append('https://www.riss.kr' + a['href'])\n",
    "\n",
    "    return links\n",
    "\n",
    "# 논문 세부 정보를 가져오는 함수\n",
    "def get_paper_details(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지 로딩을 기다립니다.\n",
    "\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "\n",
    "    title = soup.select_one('h3.title')\n",
    "    title_kor = title.get_text(strip=True) if title else \"\"\n",
    "    \n",
    "    authors = soup.select_one('#thesisInfoDiv > div.infoDetail.on > div.infoDetailL > ul > li:nth-of-type(1) > div > p')\n",
    "    authors_text = authors.get_text(strip=True) if authors else \"\"\n",
    "    \n",
    "    keywords = soup.select_one('#thesisInfoDiv > div.infoDetail.on > div.infoDetailL > ul > li:nth-of-type(7) > div > p')\n",
    "    keywords_text = keywords.get_text(strip=True) if keywords else \"\"\n",
    "\n",
    "    multilingual_abstract = soup.select_one('#additionalInfoDiv > div > div:nth-child(1) > div:nth-child(4) > p')\n",
    "    multilingual_abstract_text = multilingual_abstract.get_text(strip=True) if multilingual_abstract else \"\"\n",
    "\n",
    "    abstract = soup.select_one('#additionalInfoDiv > div > div:nth-child(2) > div:nth-child(4) > p')\n",
    "    abstract_text = abstract.get_text(strip=True) if abstract else \"\"\n",
    "\n",
    "    year = soup.select_one('#thesisInfoDiv > div.infoDetail.on > div.infoDetailL > ul > li:nth-child(5) > div > p')\n",
    "    year_text = year.get_text(strip=True) if year else \"\"\n",
    "\n",
    "    return {\n",
    "        '저자': authors_text,\n",
    "        '제목': title_kor,\n",
    "        '키워드': keywords_text,\n",
    "        '발행연도': year_text,\n",
    "        '요약': multilingual_abstract_text + '\\n' + abstract_text, # 국문과 영문의 위치가 논문마다 달라서 합침\n",
    "        '링크': url\n",
    "    }\n",
    "\n",
    "# 데이터를 CSV 파일에 저장하는 함수\n",
    "def save_to_csv(data, csv_path):\n",
    "    df = pd.DataFrame(data)\n",
    "    if os.path.isfile(csv_path):\n",
    "        df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(csv_path, mode='w', header=True, index=False)\n",
    "\n",
    "# 폴더를 생성하는 함수\n",
    "def make_folder(folder_name):\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py:64\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path is not a valid file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m path\n",
      "\u001b[0;31mValueError\u001b[0m: The path is not a valid file: chromedriver-win64/chromedriver.exe",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m chrome_options \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChromeOptions()\n\u001b[1;32m      5\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadless\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mchrome_service, options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[1;32m      8\u001b[0m now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m user_name \u001b[38;5;241m=\u001b[39m getpass\u001b[38;5;241m.\u001b[39mgetuser()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[1;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py:50\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[1;32m     49\u001b[0m finder \u001b[38;5;241m=\u001b[39m DriverFinder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finder\u001b[38;5;241m.\u001b[39mget_browser_path():\n\u001b[1;32m     51\u001b[0m     options\u001b[38;5;241m.\u001b[39mbinary_location \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_browser_path()\n\u001b[1;32m     52\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py:47\u001b[0m, in \u001b[0;36mDriverFinder.get_browser_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_browser_path\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_binary_paths()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowser_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py:78\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     77\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrowser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    driver_path = 'chromedriver-win64/chromedriver.exe' # 압축 해제한 폴더\n",
    "    chrome_service = Service(driver_path)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"headless\")\n",
    "    driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    user_name = getpass.getuser()\n",
    "    folder_root = load_folder\n",
    "    path = folder_root + now + '/'\n",
    "    make_folder(path)\n",
    "\n",
    "    csv_path = path + crawling_data_file_name\n",
    "    all_paper_details = []\n",
    "\n",
    "    start_page = 1\n",
    "    end_page = page_count\n",
    "\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        iStartCount = (page - 1) * 10  # 페이지당 10개씩\n",
    "        # pageNumber, iStartCount 값에 맞춰 URL 생성\n",
    "        URL = (f\"https://www.riss.kr/search/Search.do?\"\n",
    "               f\"isDetailSearch=N&searchGubun=true&viewYn=OP&query={search_keyword}\"\n",
    "               f\"&queryText=&iStartCount={iStartCount}&iGroupView=5&icate=all\"\n",
    "               f\"&colName=re_a_kor&exQuery=&exQueryText=&order=%2FDESC&onHanja=false\"\n",
    "               f\"&strSort=RANK&pageScale=10&orderBy=&fsearchMethod=search\"\n",
    "               f\"&isFDetailSearch=N&sflag=1&searchQuery={search_keyword}\"\n",
    "               f\"&fsearchSort=&fsearchOrder=&limiterList=&limiterListText=\"\n",
    "               f\"&facetList=&facetListText=&fsearchDB=&resultKeyword={search_keyword}\"\n",
    "               f\"&pageNumber={page}&p_year1=&p_year2=&dorg_storage=&mat_type=\"\n",
    "               f\"&mat_subtype=&fulltext_kind=&t_gubun=&learning_type=&language_code=\"\n",
    "               f\"&ccl_code=&language=&inside_outside=&fric_yn=&db_type=&image_yn=\"\n",
    "               f\"&regnm=&gubun=&kdc=&ttsUseYn=\")\n",
    "\n",
    "        paper_links = get_paper_links(driver, URL)\n",
    "\n",
    "        # 2) 각 페이지별로 추출한 링크에 대해서 상세 정보 수집\n",
    "        for link in paper_links:\n",
    "            paper_details = get_paper_details(driver, link)\n",
    "            all_paper_details.append(paper_details)\n",
    "\n",
    "    # 3) 모든 페이지에 대해 수집한 결과를 CSV로 저장\n",
    "    save_to_csv(all_paper_details, csv_path)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# 실행하는 동안 컴퓨터가 절전모드에 들어가면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
