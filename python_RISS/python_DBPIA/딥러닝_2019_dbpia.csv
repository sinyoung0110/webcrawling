title,date,abstract,keyword
합성곱 신경망 기반의 딥러닝에 의한 수치표면모델의 객체분류,2019.12,"최근 딥러닝(DL)은 여러 분야에서 급속도로 활용되고 있으며, 특히 영상으로부터 객체를 인식하여 분류하고 인식하기 위한 컴퓨터비전 분야에서 활발하게 연구가 진행되고 있다. 영상분야에서는 주로 합성곱 신경망(CNN)을 이용한 딥러닝 모델의 성능 향상에 주력하고 있다. 대부분의 합성곱 신경망은 영상을 학습시켜 영상분류 및 객체인식에 활용하고 있지만, 본 논문에서는 독일 사진측량, 원격탐사 및 공간정보학회(DGPF)가 구축하고 국제 사진측량 및 원격탐사학회(ISPRS)가 제공하는 데이터 셋 중에서 수치표면모델(DSM)과 이 데이터로부터 생성한 경사 및 주향 정보를 효율성과 성능이 우수하다고 평가받는 합성곱 신경망기반의 SegNet 모델에 적용하여 객체를 분류하고 분석하였다. 딥러닝은 고사양의 컴퓨터 시스템과 다량의 학습 데이터와 라벨 데이터가 필요하고, 다수의 시행착오에 의한 풍부한 경험이 요구된다. 또한 본 논문에서는 한정된 수량의 데이터로부터 효율적인 학습을 위한 데이터 생성 방법을 제시하고 수치표면모델을 분류하였다. 분석 결과 수치표면모델 데이터와 이로부터 도출한 부가적인 데이터를 딥러닝 모델에 적용해도 객체를 타당한 정확도로 분류할 수 있음을 확인하였다.

Recently, DL (Deep Learning) has been rapidly applied in various fields. In particular, classification and object recognition from images are major tasks in computer vision. Most of the DL utilizing imagery is primarily based on the CNN (Convolutional Neural Network) and improving performance of the DL model is main issue. While most CNNs are involve with images for training data, this paper aims to classify and recognize objects using DSM (Digital Surface Model), and slope and aspect information derived from the DSM instead of images. The DSM data sets used in the experiment were established by DGPF (German Society for Photogrammetry, Remote Sensing and Geoinformatics) and provided by ISPRS (International Society for Photogrammetry and Remote Sensing). The CNN-based SegNet model, that is evaluated as having excellent efficiency and performance, was used to train the data sets. In addition, this paper proposed a scheme for training data generation efficiently from the limited number of data. The results demonstrated DSM and derived data could be feasible for semantic classification with desirable accuracy using DL.","#CNN, #DL Model, #Training and Validation Data, #DSM Classification, #합성곱 신경망, #딥러닝 모델, #학습 및 검증 데이터, #수치표면모델 분류"
딥러닝 객체인식을 통한 경로보정 자율 주행 로봇의 구현,2019.12,"본 논문에서는 실내 환경에서 시각정보를 기반으로 출발지점에서 경유지를 거쳐 목표지점으로 최적의 경로를 찾아 자율 주행하는 바퀴달린 로봇을 구현한다. 로봇은 출발지점에서 경유지를 거쳐 목표지점으로의 최적의 경로를 딥강화학습으로 얻을 수 있다. 그러나 로봇이 구해진 경로로 자율 주행을 할 때 표면의 굴곡과 이물질 등의 외부적 요인으로 목적지까지 정확하게 주행하지 못하는 경우가 발생한다.
이에 본 연구는 카메라만 장착한 로봇이 외부 요인으로 인해 최적의 경로를 이탈할 경우 이를 인지하도록 한다. 이 인지를 토대로 로봇이 스스로 경로를 보정하고 계획된 경유지와 최종 목적지점에 도달할 수 있게 하는 알고리즘을 제안한다.
본 연구를 위해 파이캠을 탑재한 라즈베리파이와 아두이노로 제어하는 바퀴식 자율 주행 로봇이 제작되었다. 로봇은 실내환경에서 OSX 환경의 서버와 실시간 연동하면서 계획된 최적의 경로로 시험주행을 완료하였다.

In this paper, we implement a wheeled mobile robot that accurately and autonomously finds the optimal route from the starting point to the destination point based on computer vision in a complex indoor environment. We get a number of waypoints from the starting point to get the best route to the target through deep reinforcement learning. However, in the case of autonomous driving, the majority of cases do not reach their destination accurately due to external factors such as surface curvature and foreign objects. Therefore, we propose an algorithm to deepen the waypoints and destinations included in the planned route and then correct the route through the waypoint recognition while driving to reach the planned destination.
We built an autonomous wheeled mobile robot controlled by Arduino and equipped with Raspberry Pi and Pycamera and tested the planned route in the indoor environment using the proposed algorithm through real-time linkage with the server in the OSX environment.","#바퀴식 주행로봇, #경로 찾기, #딥강화학습, #딥러닝, #자율주행로봇, #Wheeled Mobile Robot, #Path Finding, #Deep Reinforcement Learning, #Deep Learning, #Autonomous Driving Robot"
딥러닝에 기반한 병원 실내이미지의 감성어휘 분류,2019.12,"This research suggests to classify Emotional adjective for the hospital indoor image. The aim of this study was twofold. First it is an attempt to overcome limitation of overfitting data with pre-process and Second it is an approach for prediction quantified the image data with Emotional adjective. The emotion is important because emotion interact between indoor and human. The hospital indoor image also have specialized emotional effect. Emotional adjective is necessary to verify throughout variety of source qualitative and quantitative research. recently it is getting more harder with I.R.B.(Institutional Review Board) than Emotional adjective data had made. This research is based on deep learning method for emotional adjective quantifiaction that can replace thousands of people’s cognition. In the proposed simulation, emotional colors are firstly processed in the frequency domain to indoor images which can be treated as an emotional image. For pre-processing Emotional colors are extracted from hospital image. and search the emotional adjetive to get indoor images to fed in CNN(Convolutional Neural Network). For the hospital indoor image clustered, emotional indoor image are fed in CNN. The output of the CNNs are fused using TF(TensorFlow) API. The input of the fusion is given to a support of Python language for image classification. The proposed system is evaluated using Tensor board - which is the proved data. This research has concluded that it is desirable to use TF for predicting the set of emotional adjective and it helps for emotion analysis efficiently. TF works for the emotional image classifying the hospital indoor images. The hospital image is classified using deep learning, and analysis of emotion as A is 80 percentage modern and B is 20 percent natural in a second for a thousand emotional colors. It is expected to use these results of research have for implications of emotional analysis that represent functions of the indoor images.","#분류, #감성어휘, #병원, #실내이미지, #딥러닝, #Classification, #Emotional adjective, #Hospital, #Indoor image, #Deep learning"
딥러닝 영상처리를 통한 비탈면의 지반 특성화 영역 자동 분류에 관한 연구,2019.12,"비탈면의 붕괴로 인해 재산피해뿐만 아니라 인명피해 또한 발생할 수 있으므로 안정성 평가를 통해 비탈면의 붕괴여부 예측 및 보강을 진행해야 한다. 본 논문은 비탈면 영상에서 암반 절리군, 암반 단층, 토양, 비탈면 누수영역 등 비탈면 붕괴와 관련하여 특성화 시킬 수 있는 지반 영역들을 정의하고 이를 딥러닝 기법을 통해 자동으로 분류해 낼 수 있는 방법에 대해 고찰하였다. 이에 따라 딥러닝 객체 영역분할(Instance segmentation) 네트워크를 활용하여 영상에 보여지는 다른 특성을 갖는 지반영역의 정확한 형상을 인식하고 자동 분할 할 수 있음을 보였으며, 향후 비탈면 안정성 평가를 위해 시행되는 비탈면 매핑 작업을 지원하고, 비탈면 보강 대책 등 의사결정에 필요한 비탈면의 지반특성 정보를 자동으로 산출할 수 있는 가능성을 보였다.

Because of the slope failure, not only property damage but also human damage can occur, slope stability analysis should be conducted to predict and reinforce of the slope. This paper, defines the ground areas that can be characterized in terms of slope failure such as Rockmass jointset, Rockmass fault, Soil, Leakage water and Crush zone in sloped images. As a result, it was shown that the deep learning instance segmentation network can be used to recognize and automatically segment the precise shape of the ground region with different characteristics shown in the image. It showed the possibility of supporting the slope mapping work and automatically calculating the ground characteristics information of slopes necessary for decision making such as slope reinforcement.","#Instance segmentation, #Deep learning, #Slope failure image, #Ground characteristics of Slope, #딥러닝, #비탈면 붕괴영상, #비탈면 지반특성"
위성 영상과 관측 센서 데이터를 이용한 PM₁₀농도 데이터의 시공간 해상도 향상 딥러닝 모델 설계,2019.12,"PM10 농도는 시간 및 공간 의존성을 동시에 가지는 시공간 데이터이지만 현실적으로 연속적인 시공간 데이터를 획득하는 것은 쉬운 일이 아니다. 본 연구에서는 위성영상과 대기질 및 기상 관측 센서 데이터를 복합적인 딥러닝 모델에 적용하여 시공간 해상도를 향상시키는 모델을 설계하였다. 설계된 딥러닝 모델은 기상, 토지 이용 등 PM10 농도에 영향을 줄 수 있는 인자를 이용하여 학습하였으며, 대기질 및 기상 관측 데이터만을 이용하여 15분 단위의 시간해상도와 30m × 30m의 공간해상도를 갖는 PM10 영상을 생성하였다.

PM10 concentration is a spatiotemporal phenomenta and capturing data for such continuous phenomena is a difficult task. This study designed a model that enhances spatiotemporal resolution of PM10 concentration levels using satellite imagery, atmospheric and meteorological sensor data, and multiple deep learning models. The designed deep learning model was trained using input data whose factors may affect concentration of PM10, such as meteorological conditions and land-use. Using this model, PM10 images having 15 minute temporal resolution and 30m × 30m spatial resolution were produced with only atmospheric and meteorological data.","#PM
10
Deep Learning, #Satellite Image, #Sensor Data, #Spatiotemporal Resolution, #딥러닝, #위성 영상, #센서 데이터, #시공간 해상도"
딥러닝 기반 이미지 자동 레이블링을 활용한 건축물 파사드 데이터세트 구축 기술 개발,2019.12,"The construction industry has made great strides in the past decades by utilizing computer programs including CAD. However, compared to other manufacturing sectors, labor productivity is low due to the high proportion of workers"" knowledge-based task in addition to simple repetitive task. Therefore, the knowledge-based task efficiency of workers should be improved by recognizing the visual information of computers. A computer needs a lot of training data, such as the ImageNet project, to recognize visual information. This study, aim at proposing building facade datasets that is efficiently constructed by quickly collecting building facade data through portal site road view and automatically labeling using deep learning as part of construction of image dataset for visual recognition construction by the computer. As a method proposed in this study, we constructed a dataset for a part of Dongseong-ro, Daegu Metropolitan City and analyzed the utility and reliability of the dataset. Through this, it was confirmed that the computer could extract the significant facade information of the portal site road view by recognizing the visual information of the building facade image. Additionally, In contribution to verifying the feasibility of building construction image datasets. this study suggests the possibility of securing quantitative and qualitative facade design knowledge by extracting the facade design knowledge from any facade all over the world.","#건설 데이터세트, #건설 데이터베이스, #딥러닝, #파사드, #자동 레이블링, #Construction Dataset, #Construction Database, #Deep Learning, #Facade, #Automatic Image Labeling"
택배화물 자동 하역장비를 위한 딥러닝 기반의 화물 인식 알고리즘,2019.12,"본 논문에서는 택배화물 자동하역장치에 적합한 개선된 딥러닝 알고리즘을 제안한다. 제안된 알고리즘은 실시간 객체검출에 우수한 성능을 보이는 YOLO v2모델을 기반으로 픽셀단위 택배화물의 위치까지 검출할 수 있도록 Masked R-CNN을 융합한 구조를 가진다. 제안된 알고리즘은 YOLO v2를 이용하여 객체의 영역과 분류를 수행하면서 객체 영역을 Masked R-CNN의 객체분할(Instance segmentation)과정을 거쳐 택배화물의 픽셀단위 위치까지 계산할 수 있도록 하였다. 제안된 알고리즘의 성능을 평가하기 위하여 실제 택배화물 차량의 적재공간과 동일한 영역에서 택배화물들을 이용하여 실험하였으며 실험결과 만족할만한 성능을 보임을 확인하였다.

In this paper, an improved deep learning algorithm for automatic unloading systems is proposed. The proposed algorithm is based on the YOLO v2 model, which shows excellent performance in real-time object detection, and has a fused structure with Masked R-CNN to detect pixel position of parcel. The proposed algorithm performs object segmentation and classification using YOLO v2, and calculates the object region to the pixel position of the parcel by mask segmentation process of Instanced R-CNN.In order to evaluate the performance of the proposed algorithm, we experimented in the same area as the loading space of the actual parcel cargo vehicle and showed the excellent performance in the experimental results.","#자동하역장치, #딥러닝 알고리즘, #YOLO v2, #Masked R-CNN, #Unloading system, #deep learning algorithm"
심실 조기 수축 비트 검출을 위한 딥러닝 기반의 최적 파라미터 검출,2019.12,"부정맥 분류를 위한 기존 연구들은 분류의 정확성을 높이기 위해 신경회로망(Artificial Neural Network), 퍼지(Fuzzy), 기계학습(Machine Learning) 등을 이용한 방법이 연구되어 왔다. 특히 딥러닝은 신경회로망의 문제인 은닉층 개수의 한계를 해결함으로 인해 오류 역전파 알고리즘을 이용한 부정맥 분류에 가장 많이 사용되고 있다. 딥러닝 모델을 심전도 신호에 적용하기 위해서는 적절한 모델선택과 파라미터를 최적에 가깝게 선택할 필요가 있다. 본 연구에서는 심실 조기 수축 비트 검출을 위한 딥러닝 기반의 최적 파라미터 검출 방법을 제안한다. 이를 위해 먼저 잡음을 제거한 ECG신호에서 R파를 검출하고 QRS와 RR간격 세그먼트를 추출하였다. 이후 딥러닝을 통한 지도학습 방법으로 가중치를 학습시키고 검증데이터로 모델을 평가하였다. 제안된 방법의 타당성 평가를 위해 MIT-BIH 부정맥 데이터베이스를 통해 각 파라미터에 따른 딥러닝 모델로 훈련 및 검증 정확도를 확인하였다. 성능 평가 결과 R파의 평균 검출 성능은 99.77%, PVC는 97.84의 평균 분류율을 나타내었다.

Legacy studies for classifying arrhythmia have been studied to improve the accuracy of classification, Neural Network, Fuzzy, etc. Deep learning is most frequently used for arrhythmia classification using error backpropagation algorithm by solving the limit of hidden layer number, which is a problem of neural network. In order to apply a deep learning model to an ECG signal, it is necessary to select an optimal model and parameters. In this paper, we propose optimal parameter extraction method based on a deep learning. For this purpose, R-wave is detected in the ECG signal from which noise has been removed, QRS and RR interval segment is modelled. And then, the weights were learned by supervised learning method through deep learning and the model was evaluated by the verification data. The detection and classification rate of R wave and PVC is evaluated through MIT-BIH arrhythmia database. The performance results indicate the average of 99.77% in R wave detection and 97.84% in PVC classification.","#최적 파라미터, #딥 러닝, #심실 조기 수축, #QRS, #RR 간격, #Optimal parameter, #Deep learning, #Premature ventricular contraction, #RR interval"
딥러닝을 이용한 셰익스피어 작품의 감정 분석 Top 5%,2019.12,"This study examined the sentiment movement of Shakespeare’s plays (four tragedies and five comedies) using a deep learning technique. Sentiment analyses have been used in several fields to extract aspects of opinions using sentiment dictionaries such as ANEW, AFFINE, and VADER, which involve an evaluation of a word list for sentiment analysis. Nowadays, however, as deep learning algorithms develop, it became possible to conduct a sentiment analysis by using deep learning algorithms. This study directly compared the output of a simple deep learning model (trained with tweeters) with the output of a sentiment dictionary, VADER, targeting Shakespeare’s plays. The results showed that the simple deep learning model led to a similar performance with VADER for Shakespeare’s tragedies and outperformed the sentiment dictionary especially for Shakespeare’s comedies.","#sentiment analysis, #deep learning, #Shakespeare, #tweeter data"
공동주택 전력 소비 데이터 분석 및 딥러닝을 사용한 전력 소비 예측,2019.12,"에너지의 생산 효율성을 증가시키기 위해 최근 스마트그리드 기술 중 지능형 검침 시스템(AMI, advanced metering infrastructure)의 개발이 활발히 진행되고 있다. 전력 소비 데이터를 분석하고 소비 패턴을 예측하는 일은 AMI에서 핵심적인 부분이다. 본 논문에서는 수집된 전력 소비 데이터를 분석하고 발생할 수 있는 오류들을 정리하였으며 소비 패턴을 월별로 k-means 군집화 알고리즘을 사용하여 분석하였다. 또한 deep neural network를 이용하여 소비 패턴을 예측하였는데, 가구별 하루 전력 사용량 예측의 어려움을 극복하기 위하여 전력 사용량을 100개의 군집으로 분류하여 이 군집의 하루 평균으로 다음날 군집의 평균을 예측하였다. 실제 AMI에서의 전력 데이터를 사용하여 오류들을 분석하였으며 군집화 방법을 도입하여 성공적으로 전력 소비 예측이 가능하였다.

In order to increase energy efficiency, developments of the advanced metering infrastructure (AMI) in the smart grid technology have recently been actively conducted. An essential part of AMI is analyzing power consumption and forecasting consumption patterns. In this paper, we analyze the power consumption and summarized the data errors. Monthly power consumption patterns are also analyzed using the k-means clustering algorithm. Forecasting the consumption pattern by each household is difficult. Therefore, we first classify the data into 100 clusters and then predict the average of the next day as the daily average of the clusters based on the deep neural network. Using practically collected AMI data, we analyzed the data errors and could successfully conducted power forecasting based on a clustering technique.","#advanced metering infrastructure, #deep neural network, #load data, #load forecasting, #k-means clustering, #meter reading"
스트리밍 서버를 이용한 AWS 기반의 딥러닝 플랫폼 구현과 성능 비교 실험,2019.12,"본 논문에서는 로컬 PC의 성능이 주는 영향이 적은 딥러닝 동작 구조를 구현하였다. 일반적으로, 딥러닝 모델은 많은 연산량을 가지고 있어 처리하는 PC의 성능에 영향을 많이 받는다. 본 논문에서는 이와 같은 제약 사항을 줄이기 위하여 AWS와 스트리밍 서버를 이용하여 딥러닝 동작을 구현하였다. 첫 번째, AWS에서 딥러닝 연산을 하여 로컬 PC의 성능이 떨어지더라도 딥러닝 동작이 정상적으로 작동할 수 있도록 하였다. 하지만 AWS를 통해 연산 시 입력에 대해 출력의 실시간성이 떨어진다. 두 번째, 스트리밍 서버를 이용하여 딥러닝 모델의 실시간성을 증가시킨다. 스트리밍 서버를 사용하지 않았을 경우 한 이미지씩 처리하거나 이미지를 쌓아서 동영상으로 만들어 처리하여야 하기 때문에 실시간성이 떨어진다. 성능 비교 실험을 위한 딥러닝 모델로는 YOLO v3모델을 사용하였고, AWS의 인스턴스들 및 고성능 GPU인 GTX1080을 탑재한 로컬 PC의 성능을 비교하였다. 시뮬레이션 결과 AWS의 인스턴스인 p3 인스턴스를 사용하였을 때 한 이미지 당 테스트 시간이 0.023444초로써 고성능 GPU인 GTX1080을 탑재한 로컬 PC의 한 이미지 당 테스트 시간인 0.027099초와 유사하다는 결과를 얻었다.

In this paper, we implemented a deep learning operation structure with less influence of local PC performance. In general, the deep learning model has a large amount of computation and is heavily influenced by the performance of the processing PC. In this paper, we implemented deep learning operation using AWS and streaming server to reduce this limitation. First, deep learning operations were performed on AWS so that deep learning operation would work even if the performance of the local PC decreased. However, with AWS, the output is less real-time relative to the input when computed. Second, we use streaming server to increase the real-time of deep learning model. If the streaming server is not used, the real-time performance is poor because the images must be processed one by one or by stacking the images. We used the YOLO v3 model as a deep learning model for performance comparison experiments, and compared the performance of local PCs with instances of AWS and GTX1080, a high-performance GPU. The simulation results show that the test time per image is 0.023444 seconds when using the p3 instance of AWS, which is similar to the test time per image of 0.027099 seconds on a local PC with the high-performance GPU GTX1080.","#AWS, #Cloud Computing Service, #Deep Learning, #Streaming server, #YOLO"
딥러닝을 이용한 연안방재 시스템 구축에 관한 연구,2019.12,"Numerous deaths and substantial property damage have occurred recently due to frequent disasters of the highest intensity according to the abnormal climate, which is caused by various problems, such as global warming, all over the world. Such large-scale disasters have become an international issue and have made people aware of the disasters so they can implement disaster-prevention measures. Extensive information on disaster prevention actively has been announced publicly to support the natural disaster reduction measures throughout the world. In Japan, diverse developmental studies on disaster prevention systems, which support hazard map development and flood control activity, have been conducted vigorously to estimate external forces according to design frequencies as well as expected maximum frequencies from a variety of areas, such as rivers, coasts, and ports based on broad disaster prevention data obtained from several huge disasters. However, the current reduction measures alone are not sufficiently effective due to the change of the paradigms of the current disasters. Therefore, in order to obtain the synergy effect of reduction measures, a study of the establishment of an integrated system is required to improve the various disaster prevention technologies and the current disaster prevention system. In order to develop a similar typhoon search system and establish a disaster prevention infrastructure, in this study, techniques will be developed that can be used to forecast typhoons before they strike by using artificial intelligence (AI) technology and offer primary disaster prevention information according to the direction of the typhoon. The main function of this model is to predict the most similar typhoon among the existing typhoons by utilizing the major typhoon information, such as course, central pressure, and speed, before the typhoon directly impacts South Korea. This model is equipped with a combination of AI and DNN forecasts of typhoons that change from moment to moment in order to efficiently forecast a current typhoon based on similar typhoons in the past. Thus, the result of a similar typhoon search showed that the quality of prediction was higher with the grid size of one degree rather than two degrees in latitude and longitude.","#Disaster prevention system 방재 시스템, #Artificial intelligence 인공지능, #Deep learning 딥러닝, #Big data 빅데이터"
딥러닝 알고리즘과 2D Lidar 센서를 이용한 이미지 분류,2019.12,"본 논문은 CNN (Convolutional Neural Network)와 2D Lidar 센서에서 획득한 위치 데이터를 이용하여 이미지를 분류하는 방법을 제시한다. Lidar 센서는 데이터 정확도, 형상 왜곡 및 광 변화에 대한 강인성 측면에서의 이점으로 인해 무인 장치에 널리 사용되어 왔다. CNN 알고리즘은 하나 이상의 컨볼루션 및 풀링 레이어로 구성되며 이미지 분류에 만족스러운 성능을 보여 왔다. 본 논문에서는 학습 방법에 따라 다른 유형의 CNN 아키텍처들인 Gradient Descent (GD) 및 Levenbergarquardt(LM)를 구현하였다. LM 방법에는 학습 파라메터를 업데이트하는 요소 중 하나인 Hessian 행렬 근사 빈도에 따라 두 가지 유형이 있다. LM 알고리즘의 시뮬레이션 결과는 GD 알고리즘보다 이미지 데이터의 분류 성능이 우수하였다. 또한 Hessian 행렬 근사가 더 빈번한 LM 알고리즘은 다른 유형의 LM 알고리즘보다 작은 오류를 보여주었다.

This paper presents an approach for classifying image made by acquired position data from a 2D Lidar sensor with a convolutional neural network (CNN). Lidar sensor has been widely used for unmanned devices owing to advantages in term of data accuracy, robustness against geometry distortion and light variations. A CNN algorithm consists of one or more convolutional and pooling layers and has shown a satisfactory performance for image classification. In this paper, different types of CNN architectures based on training methods, Gradient Descent(GD) and Levenbergarquardt(LM), are implemented. The LM method has two types based on the frequency of approximating Hessian matrix, one of the factors to update training parameters. Simulation results of the LM algorithms show better classification performance of the image data than that of the GD algorithm. In addition, the LM algorithm with more frequent Hessian matrix approximation shows a smaller error than the other type of LM algorithm.","#Deep learning, #deep learning neural network, #convolutional neural network, #object detection, #image classification"
딥러닝을 활용한 버뮤다옵션 가격 결정의 알고리듬,2019.12,"버뮤다 옵션의 가격을 계산하기 위한, 좀더 엄밀하게 말하면 시장가격에 가장 근사하다고 의견의 일치를 보는 방법은 아직 없다. 버뮤다옵션의 가격결정은 동적 프로그래밍 원칙을 해결하는 것과 같으며, 특히 큰 차원에 있어서 주된 어려움은 지속 가치와 관련된 조건부 기대치들의 계산에서 비롯된다. 이러한 조건부 기대치들은 유한 차원 벡터 공간상에서 전형적인 회귀 기법에 의해 계산된다. 본 연구에서는 조건부 기대치들의 신경망근사치를 연구한다. 또한 표준 최소자승회귀분석을 신경망 근사치로 대체함으로써 잘 알려진 Longstaff-Schwartz 알고리듬과 합치됨을 보인다.

There is no consensus on Bermuda option pricing, more precisely, the closest approximation to market prices. The pricing of Bermuda options is like solving dynamic programming principles, and the main difficulty, especially on a larger scale, comes from the calculation of conditional expectations related to continuation value. These conditional expectations are computed by a typical regression technique on finite dimensional vector spaces. In this study, we study the neural network approximation of conditional expectations. It is also shown that it replaces the standard least squares regression with a neural network approximation, which is consistent with the well-known Longstaff-Schwartz algorithm.","#Deep learning, #Bermuda option, #Neural network approximation, #Regression, #Convergence"
딥러닝 기반의 엣지 컴퓨팅을 활용한 클라우드 얼굴 인식 가속화,2019.12,,
Flow 기반 딥러닝 생성 모델에 관한 사례 분석,2019.12,,
이미지 추출 가속을 통한 고성능 딥러닝 트레이닝 시스템,2019.12,,
딥러닝 및 영상처리 기술을 활용한 콘크리트 균열 검출 방법 Top 5%,2019.11,"Most of the current crack investigation work consists of visual inspection using simple measuring equipment such as crack scale. These methods involve the subjection of the inspector, which may lead to differences in the inspection results prepared by the inspector, and may lead to a large number of measurement errors. So, this study proposes an image-based crack detection method to enhance objectivity and efficiency of concrete crack investigation. In this study, YOLOv2 was used to determine the presence of cracks in the image information to ensure the speed and accuracy of detection for real-time analysis. In addition, we extracted shapes of cracks and calculated quantitatively, such as width and length using various image processing techniques. The results of this study will be used as a basis for the development of image-based facility defect diagnosis automation system.","#콘크리트 균열, #균열 검출, #딥러닝, #영상처리, #합성곱신경망, #Concrete Crack, #Crack Detection, #Deep Learning, #Image Processing, #CNN"
딥러닝 기반의 구조물 화재 재난 시 최적 대피로 안내 시스템,2019.11,"구조물에서 화재 발생 시 화재의 발생 위치를 정확하게 파악하지 못해 화재 진압이 용이하지 못하는 문제, 연기나 유독가스로 시야 확보가 어려운 상태에서 비상구 및 탈출로에 대한 정보를 방향지시기와 LED 유도등에 의존하여 위험에 빠지는 문제가 빈번히 발생하고 있다. 이에 본 논문에서는 딥러닝 기반(RNN) 구조물 재난 시 최적의 대피로를 안내할 수 있는 시스템 알고리즘을 제시한다. 설치되어 있는 감지 센서를 이용하고, 센서별 검출된 데이터를 서버로 실시간 전송되며, 감지 센서 주변의 온도, 열, 연기, 유독가스 등의 정보가 전달된다. 그리고 이를 분석하고, 설정된 임계치 범위 내에 있는 가장 안전한 이동 경로를 파한다. 이때 구조물 내에 있는 LED 유도등과 방향지시기에 실시간으로 정보를 전달하여 위험 요소를 피할 수 있는 서비스를 제공해 준다. 이는 구조물의 각 구역별 온도, 열, 연기, 유독가스의 정보를 파악할 수 있어, 구조물 재난 시 최적의 대피로를 안내받을 수 있을 것이라고 사료된다.

In case of fire in a structure, it is difficult to suppress fire because it can not accurately grasp the location of fire in case of fire. In this paper, we propose a system algorithm that can guide the optimal evacuation route in case of deep learning-based (RNN) structure disaster. The present invention provides a service to transmit data detected by sensors to a server in real time by using installed sensor, to transmit and analyze information such as temperature, heat, smoke, toxic gas around the sensor, to identify the safest moving path within a set threshold, to transmit information to LED guide lights and direction indicators in a structure in real time to avoid risk factors. This is because the information of temperature, heat, smoke, and toxic gas in each area of the structure can be grasped, and it is considered that the optimal evacuation route can be guided in case of structure disaster.","#대피로 안내, #딥러닝, #센서, #화재 재난, #Guide to evacuation, #Deep Learning, #Sensor, #Fire disaster"
딥러닝 모델 압축 기술을 활용한 시각장애인 대화 보조용 감정 인식 어플리케이션,2019.12,,
염기 서열 분석 딥러닝 모델을 위한 전처리 방법 성능 분석,2019.12,,
미세조정 계층적 딥러닝 모델을 이용한 외래잡초 잎 이미지 분류의 성능 향상,2019.12,,
컴퓨터 비전과 딥러닝을 통한 견종식별 연구,2019.12,"본 논문은 컴퓨터 비전(computer vision)과 딥러닝(deep-learning)을 접목한 지능형 ‘반려동물 돌봄’ 서비스를 구현하기 위한 연구의 초석으로 이미지 내 반려견을 식별하여 품종(breed)을 식별하는 모델의 제안과 관련된 실험을 수행한 결과를 기술한다. 견종의 식별에는 Feature representation learning에서 뛰어난 성능을 보이는 CNN(Convolution Neural Network) 모델을 활용하는데, CNN은 이미지의 불필요한 영역과 Noise를 제거하는 것이 성능에 큰 영향을 주는 것으로 알려져 있다. 따라서 제시하는 모델은 U-Net을 접목하여 Instance Segmentation을 통해 개체 외에 불필요한 영역을 모두 제거하고 CNN을 통해 Identification을 수행한다. 제안하는 모델은 CNN을 단독으로 사용하는 모델과 대비하여 17.86% 높은 성능을 보였으며, 여덟 마리의 견종을 식별함에서 91.62%라는 결과를 보였다. 하지만, 실험을 통해 얼굴 혹은 신체 일부만 나타난 견종의 이미지에서는 두 견종 간 색상의 배열이나 형태가 유사한 경우, CNN 모델이 이를 명확하게 구별하지 못한다는 한계점이 식별된 것도 또 다른 의의가 있으며, 이를 개선하기 위한 후속 연구의 방향성을 제시한다고 생각된다.

In this paper, we propose a new approach to dog breed identification model through the computer vision and deep-learning and perform the relevant experiments and describe the results. These experiments will be a cornerstone for research to implement ‘smart pet care services’. The identification of dog breed is based on CNN(Convolution Natural Network) model, which shows excellent performance in Feature representation learning. CNN is known to improve performance if unnecessary areas and noise are removed. Therefore, the proposed model combines U-Net to remove all unnecessary areas through Instance Segmentation and performs identification through CNN. The proposed model showed 17.86% higher performance than the CNN alone model, and 91.62% accuracy in identifying eight dog breeds. However, experiments have shown that the CNN model does not clearly identification between two breeds of similar color arrangements or shapes in the image of a dog that shows only a face or body part. These results has another different significance to the Identification accuracy and the direction of our future research to improve it.","#Computer Vision, #Deep Learning, #Companion Animal"
딥러닝을 이용한 야간 감시 열화상 카메라 개발에 관한 연구,2019.12,"본 논문에서는 저해상도 적외선 센서를 이용하여 주·야간에 감시를 할 수 있는 열화상 카메라를 개발하였다. 본 논문에서 개발된 카메라는 딥러닝을 이용하여 감시 대상 객체를 학습시키고 인식할 수 있는 기능, 인식된 객체를 추적할 수 있는 알고리즘과 PT(Pan-Tilt) 기능을 구현하였다. 개발된 카메라는 지도학습 방법에 의해 인식이 필요한 물체의 열화상 이미지를 이용하여 학습시켰으며, 인식하는 테스트를 실행하였다. 본 논문에서 개발된 열화상 카메라는 야간에 농작물에 피해를 주는 유해 동물 발견과 퇴치, 외딴 지역에서의 야간 감시, 그리고 일반 가정과 산업시설에서 화재 또는 과열 감시 시스템으로 활용될 수 있을 것으로 기대된다.

In this paper, we developed a thermal survelliance camera that can monitor day and night using low resolution infrared sensor. The developed camera implemented the function of learning and recognizing the target using deep learning, the algorithm to track the recognized object and the PT(Pan-Tilt) function. The developed camera has been trained using the thermal image of the object that needs to be recognized by the supervised learning method, and the recognition test has been performed. The developed camera is expected to be used as a detection and removal of harmful animals that can damage farm at night, night surveillance in remote areas, and fire or overheat monitoring systems at homes and industrial plants.","#Thermal camera, #Infrared, #Deep learning, #CNN, #YOLO"
딥러닝 기반의 건화물선 시황예측 연구,2019.11,,
이미지 딥러닝을 통한 컨텐츠와 관련 반응 동영상의 감정 분석 시스템 설계,2019.12,,
네트워크 인프라 가상화를 위한 딥러닝 기반 MVNO 트래픽 예측 모델의 최적화 기법에 대한 연구,2019.12,,
딥러닝 OCR 기술을 이용한 스마트 펜 시스템,2019.12,,
딥러닝을 활용한 농작물 질병 기반 수확량 진단 플랫폼,2019.12,,
멀티모달 딥러닝을 위한 신경망 파이프라이닝 성능분석,2019.12,,
딥러닝을 이용한 동영상 속 여행지 인식 시스템 개발,2019.12,,
cuBLAS와의 성능 비교를 통한 CUTLASS의 딥러닝 활용성 분석,2019.12,,
무선 네트워크 환경에서 UAV-BS를 활용한 딥러닝 기반의 컨텐츠 캐싱 프레임워크,2019.12,,
하이퍼파라미터 최적화 방법론을 도입한 딥러닝 NOx 예측 모델에 관한 연구,2019.11,,"#Deep Learning(딥러닝), #Neural Networks(신경망), #Hyperparameter Optimization(하이퍼파라미터 최적화), #NOx(질소산화물), #Diesel Engine(디젤 엔진)"
딥러닝 기반의 무인 항공기 상황 인지를 위한 모델 자동 학습 방식,2019.11,,"#UAVs(무인 항공기), #Situation Awareness(상황 인지), #Deep Learning(딥러닝), #CNN"
큐브위성용 온보드 컴퓨터에서의 딥러닝 알고리즘 개발 환경 구축,2019.11,,"#Cubesat (큐브위성), #On-board Computer (온보드컴퓨터), #Deep Learning (딥러닝), #Inference (추론)"
심층신경망 딥러닝 모델을 통한 EDISON 시뮬레이션 실행시간 추정,2019.11,,"#계산과학공학, #시뮬레이션, #플랫폼, #고성능 컴퓨팅, #딥러닝, #머신러닝"
3D-LiDAR를 이용한 딥러닝 기반 실시간 객체 검출,2019.12,,
딥러닝 모델을 적용한 클라이언트-서버 기반 실시간 장애인 주차구역 단속 시스템 개발에 관한 연구,2019.12,,
EEG 주파수 대역을 활용한 딥러닝 기반 시각적 숫자 판독인식,2019.12,,
도심 환경에서의 자율주행을 위한 멀티 모달기반 딥러닝 모델 연구,2019.12,,
딥러닝 기반 개인정보 보호 영상 세그멘테이션 및 복원 가능한 영상 왜곡 모델,2019.12,,
최신 딥러닝 알고리즘: 토목공학 적용 사례를 중심으로,2019.12,,
영상 폐색영역 검출 및 해결을 위한 딥러닝 알고리즘 적용 가능성 연구,2019.11,"최근 드론을 이용한 공간정보 구축이 활성화되면서 공간정보 산업발전에 많은 기여를 하고 있다. 하지만 드론 공간정보는 카메라의 중심투영에 의한 발생하는 폐색영역 뿐 아니라 가로수, 보행자, 현수막과 같은 적치물에 의한 폐색영역이 필연적으로 발생한다. 이러한 폐색영역을 효율적으로 해결하기 위한 다양한 방안이 연구되고 있다. 본 연구에서는 폐색영역 해결을 위해 원초적인 재촬영이 아닌 딥러닝 알고리즘을 적용하기 위한 다양한 알고리즘별 조사 및 비교연구를 수행하였다. 그 결과, 객체 검출 알고리즘인 HOG부터 기계학습 방법인 SVM, 딥러닝 방식인 DNN, CNN, RNN까지 다양한 모델들이 개발 및 적용되고 있으며, 이 중 영상의 분류, 검출에 가장 보편적이고 효율적인 알고리즘은 CNN기법임을 확인하였다. 향후 AI 기반의 자동 객체 탐지와 분류는 공간정보 분야에서 각광받는 최신 과학기술이다. 이를 위해 다양한 알고리즘에 대한 검토와 적용은 중요하다. 따라서, 본 연구에서 제시하는 알고리즘별 적용 가능성은 자동으로 드론 영상의 폐색영역을 탐지하고 해결할 수 있어 공간정보 구축의 시간, 비용, 인력에 대한 효율성 향상에 기여할 것으로 판단된다.

Recently, spatial information is being constructed actively based on the images obtained by drones. Because occlusion areas occur due to buildings as well as many obstacles, such as trees, pedestrians, and banners in the urban areas, an efficient way to resolve the problem is necessary. Instead of the traditional way, which replaces the occlusion area with other images obtained at different positions, various models based on deep learning were examined and compared. A comparison of a type of feature descriptor, HOG, to the machine learning-based SVM, deep learning-based DNN, CNN, and RNN showed that the CNN is used broadly to detect and classify objects. Until now, many studies have focused on the development and application of models so that it is impossible to select an optimal model. On the other hand, the upgrade of a deep learning-based detection and classification technique is expected because many researchers have attempted to upgrade the accuracy of the model as well as reduce the computation time. In that case, the procedures for generating spatial information will be changed to detect the occlusion area and replace it with simulated images automatically, and the efficiency of time, cost, and workforce will also be improved.","#Drone, #Occlusion Area, #Deep Learning, #Image, #Detection"
딥러닝을 활용한 주파수 공유 기반 네트워크 연구 동향,2019.11,,
딥러닝 기반 비정상 배달음식 리뷰 이미지 감지 시스템에 관한 연구,2019.12,,
딥러닝을 활용한 단안 카메라 기반 실시간 물체 검출 및 거리 추정,2019.12,"This paper proposes a model and train method that can real-time detect objects and distances estimation based on a monocular camera by applying deep learning. It used YOLOv2 model which is applied to autonomous or robot due to the fast image processing speed. We have changed and learned the loss function so that the YOLOv2 model can detect objects and distances at the same time. The YOLOv2 loss function added a term for learning bounding box values x, y, w, h, and distance values z as 클래스ification losses. In addition, the learning was carried out by multiplying the distance term with parameters for the balance of learning. we trained the model location, recognition by camera and distance data measured by lidar so that we enable the model to estimate distance and objects from a monocular camera, even when the vehicle is going up or down hill. To evaluate the performance of object detection and distance estimation, MAP (Mean Average Precision) and Adjust R square were used and performance was compared with previous research papers. In addition, we compared the original YOLOv2 model FPS (Frame Per Second) for speed measurement with FPS of our model.","#Deep Learning, #Object Detection, #Distance Estimation, #Monocular Camera"
달 표면 크레이터 인식률 향상을 위한 딥러닝 기술 동향,2019.12,"달 표면 위의 크레이터는 역사를 간직한 화석과 같으며 달의 지역을 대표하는 랜드마크이다. 이 크레이터의 형태와 위치는 과학적 그리고 공학적 양면에서 유익한 정보 수단을 제공할 수 있다. 최근 컴퓨터 비전 기술은 비약적으로 발전하고 있는 딥러닝 기술을 통하여 영상 내 객체에 대한 인식률 성능을 계속해서 향상시키고 있다. 특히 핵심적인 콘볼루셔널 계층 기반 심층인공 신경망은 달 표면의 크레이터를 인식하기 위한 적용 연구에 성공적으로 활용되고 있다. 본 논문에서는 이와 관련된 연구 동향을 살펴보고 전반적인 한계점을 고찰하였다.

A crater on the Earth’s moon surface is like a fossil with history and it is a landmark that represents a certain area of the moon. The shape and location of the crater can provide an informative means in scientific and engineering aspects. Recent advances in computer vision technology have changed the recognition rate of objects in images by Deep Learning approach. In particular, deep convolutional Neural Network has been successfully and actively applied to detect and identify craters on the surface of the moon. In this paper, recent application studies are introduced and their overall limitations are explained.","#Convolutional Neural Network(콘볼루셔널 신경망), #Deep Artificial Neural Network(심층 인공 신경망), #Crater Detection(크레이터 감지), #Crater Recognition(크레이터 인식), #Object Detection(객체 감지), #Classification and Regression(분류 회귀), #Segmentation(분할)"
차량 탑승자의 공조 설정 온도 예측을 위한 딥러닝 활용 방안,2019.11,,"#Deep learning(딥러닝), #HVAC(공조), #Human-Machine Interaction(HMI), #Pesonalization(개인화), #Recommendation system(추천 시스템)"
기계공학과 딥러닝 Top 10%,2019.11,,"#인공지능(AI), #딥러닝(Deep Learning), #산업인공지능(Industrial AI), #기계인공지능(AI for ME)"
딥러닝 기반 영상 다운샘플링 기술 분석,2019.11,,
동풍 예측을 위한 딥러닝 기반의 예측 모델,2019.12,"Understanding the characteristics of the easterly-related weather phenomena in the eastern coast in Korean Peninsula is very important to analyze abnormal atmospheric phenomena such as heavy rain, heavy snow, and hot-dry wind. As data science techniques have steadily improved, data driven prediction models are becoming more powerful in the quantitative forecasting weather. In this paper, we apply the deep learning based methods to predict the presence or absence of the easterly wind around the Korean peninsula. The DNN, CNN, and LSTM based deep learning approaches for prediction of easterly wind are experimented and compared for the Korean Peninsula and East Sea. Vertical pressure levels of ERA5 data in year 2013 and 2014 are used.","#Easterly wind, #Deep neural network, #Convolution neural network, #Long short-term memory, #Deep learning"
딥러닝 기술 기반 HEVC로 압축된 영상의 이중 압축 검출 기술,2019.11,"영상의 이중 압축 검출은 영상의 위조여부를 판단하는 한가지 효과적인 방식이다. 이러한 이중 압축 검출 기술을 바탕으로 HEVC로 압축된 영상의 진위 여부를 판단하는 다양한 종류의 기존 기술들이 소개되었지만, 동일한 압축 환경에서 이중 압축된 영상의 진위여부를 검출하는 것은 상당히 어려운 일로 여겨지고 있다. 본 논문에서는 동일 압축 환경에서 HEVC의 이중압축 여부를 판단하는 기술로서, Intra모드로 압축된 영상의 분할 정보를 이용하여 판단하는 방식을 제안한다. Coding Unit (CU)와 Transform Unit (TU)의 분할 정보로부터 통계적 특징과 딥러닝 네트워크 기반의 특징을 우선 추출하고, softmax단에서 추출된 특징들을 통합하여 이중 압축 여부를 판단하는 기술을 제안한다. 실험결과를 통해서 제안하고 있는 기술이 WVGA 영상과 HD 영상에서 각각 87.5%와 84.1%의 정확도를 가지며 효과적으로 검출한다는 것을 보여준다.

Detection of double compression is one of the most efficient ways of remarking the validity of videos. Many methods have been introduced to detect HEVC double compression with different coding parameters. However, HEVC double compression detection under the same coding environments is still a challenging task in video forensic. In this paper, we introduce a novel method based on the frame partitioning information in intra prediction mode for detecting double compression in with the same coding environments. We propose to extract statistical feature and Deep Convolution Neural Network (DCNN) feature from the difference of partitioning picture including Coding Unit (CU) and Transform Unit (TU) information. Finally, a softmax layer is integrated to perform the classification of the videos into single and double compression by combing the statistical and the DCNN features. Experimental results show the effectiveness of the statistical and the DCNN features with an average accuracy of 87.5% for WVGA and 84.1% for HD dataset.","#Video Forensic, #Double Compression Detection, #HEVC, #Picture Partitioning, #Deep Learning"
광업 분야의 딥러닝 기술 적용연구 사례분석,2019.10,"본 논문에서는 딥러닝 기술을 국내 광업분야에 효과적으로 도입하기 위하여 광업 분야의 딥러닝 기술 적용 연구들을 조사하고 정리하였다. 딥러닝은 ANN에 기원을 둔 머신러닝 알고리즘으로, 지질학적 문제와 같은 고차원 비선형 문제의 추상화에 특화되어 있다. 딥러닝 기술이 조사, 탐사, 개발, 광산운영, 재해분석에 이르는 광업주기에 따라 어떻게 적용되었는지 조사되었다. 조사 및 탐사단계에서는 지구화학탐사, 물리탐사, 지질도, 단층선, 지형정보를 융합하여 광물 부존가능성 지도화를 수행하는 연구가 다수 제안되었다. 광산 개발 및 관리 단계에서는 센서나 카메라에 의해 측정된 광산 현황 자료로 광산 내 상황 자동감지, 솔루션 자동연산, 자동 장비제어에 대한 연구가 수행되고 있었다. 재해 분석 단계는 상황인식 및 재해 예측이 주된 목적이었다. 딥러닝 기술이 국내광업분야에 효과적으로 도입되기 위해서 관련된 국내 적용연구가 요구된다.

Applications for deep learning technology in the mining industry were investigated to utilize deep learning technology in the domestic mining field. Deep learning is specialized in abstracting high-dimensional nonlinear problems, such as geological problems. The author investigated the applications of deep learning technology for mining cycle that is divided into investigation, exploration, development, mine operation, and disaster analysis. In the survey and exploration phase, a number of studies have been proposed to carry out mineral potential mapping by integrating geochemical and geophysical explorations, geological maps, fault lines, and topographic information. In the mine development and management phase, studies on autonomous situation detection, automatic calculation, and equipment control were carried out using mine status data measured by sensors or cameras. The hazard analysis phase was mainly used for status awareness and hazard prediction. In order for deep learning technology to be effectively utilized in the domestic mining field, relevant domestic research is required.","#Deep learning, #CNN, #SAE, #RNN, #Mining industry, #딥러닝, #합성곱 신경망, #누적형 자동인코더, #순환 신경망, #광업"
딥러닝 기반의 홀로그램 생성,2019.11,,
스마트 관제를 위한 딥러닝 기반 이상행동 기술 동향 분석,2019.11,,
딥러닝에 기반을 둔 배색이미지의 감성어휘 추출 방법론,2019.11,"This paper suggests Emotional adjective prediction using a deep learning approach. The color is important since colors help us to identify an object and colors have symbols that interact with emotion. It is difficult to design based emotions that emotional color are not sufficient to analyze color design by intuition. Before it will expand color data, it is necessary to verify throughout variety source qualitative and quantitative research. It is difficult to design based emotions that is necessary to verify throughout variety source qualitative and quantitative research. This research focused on a deep learning method for emotional color classification that can replace thousands of people’s cognition. The input of the fusion is given to a support of Python language for image classification. This research has concluded that it is desirable to use Deep learning for classifying the set of color of images and it helps color analysis efficiently. Deep learning makes the quality of universal perception with computation easier for user experience. This research has concluded that it is desirable to use Deep leaning for classifying the set of color of images. ImageNet with convolutional neural network makes the quality of universal perception with Deep leaning easier for user experience. A designer makes color combinations institutionally that is classified using deep learning, and can be analyzed emotion as A is 90 percentage ordinary and B is 50 percentage extraordinary in two minuits for deep learning thousand emotional colors and classifying over one hundreds color palettes. It is expected to use these results of research have implications for color design and analysis.","#감성어휘, #배색, #이미지 분류, #이미지넷, #딥러닝, #Emotional Adjective, #Colors Palettes, #Image classification, #ImageNet, #Deep learning"
딥러닝 기반 배관계장도의 정보 요소 인식에 관한 기술,2019.11,,"#배관계장도, #P&ID, #딥러닝, #도면 인식"
Stereoscopic Imaging System 및 딥러닝을 활용한 충돌 회피 알고리즘 개발,2019.11,"Due to the development of technology, research on autonomous vehicle driving is being actively conducted. Many people want to take autonomous driving, but the technology is unreliable and high in cost and limited use. In order to increase the reliability of autonomous driving using autonomous driving sub-devices using low-cost cameras that do not use expensive Radar or LiDAR, new technologies will be discussed. With the development of deep learning technology, an image recognition algorithm called YOLO has been developed, which shows the improvement of image recognition speed and high accuracy which is a problem of the existing image recognition. In addition, it is possible to develop an algorithm to obtain accurate position, velocity and acceleration by recognizing the object measured by YOLO using stereo image matching technology. Both technologies will enable the development of low cost autonomous driving sub-equipment using cameras.","#Autonomous(자율주행), #Vehicle(자동차), #Object detection(물체 탐지), #Stereo-camera(스테레오 카메라), #Stereo-image(스테레오이미지), #Deep learning(딥러닝), #YOLO(You Only Look Once)"
딥러닝 기반 실시간 다중 객체 추적 시스템,2019.11,,
딥러닝 기반 공공 IPTV 시청률조사 시스템,2019.11,,
실내 환경에서 이동체의 경로 추정을 위한 딥러닝 기법,2019.11,,
실내 환경에서 이동체의 경로 추정을 위한 딥러닝 기법,2019.11,,
TVM 딥러닝 컴파일러와 VTA 가속기의 성능 고찰,2019.11,"Deep learning techniques have been applied to various fields, such as image recognition, natural language processing, computer vision, and so on. Therefore, their accelerators are getting attention due to the execution efficiency in terms of speed and power, and the deep learning compilers help programmers to develop optimized code. In this paper, we review TVM, an open-source deep-learning compiler, and analyze its performance by using GoogLeNet. Also, we compare the performance of VTA, the neural network accelerator based on TVM, with CPU by using the quantized ResNet-18.",
드라이빙 컴퓨팅 하드웨어 플랫폼을 위한 딥러닝 영상 전처리기 구현,2019.11,,
포인트 클라우드를 이용한 딥러닝 기반의 주행 가능 영역 및 차량 검출을 위한 의미론적 분할에 관한 연구,2019.11,"In this paper, we propose a deep learning based semantic segmentation network for drivable space and static or dynamic vehicles detection using point cloud obtained 3D LiDAR. For input of the network, we generate 2D top view image of 3-channels using 3D point cloud information. The network for semantic segmentation consists of a fast and simple Fully Convolutional Neural Network (FCN). The dataset for learning uses the KITTI dataset, which is frequently used for autonomous driving experiments. And the ground truth used for training and evaluation is composed 5-classes: ‘background’, ‘road’, ‘car’, ‘van’, and ‘truck’. Our Experimental results verified that it is possible to detect the drivable space and vehicles for recognition of autonomous driving system at high inference speed.","#Deep Learning(딥러닝), #LiDAR(라이다), #Point Cloud(포인트 클라우드), #Semantic Segmentation(의미론적 분할), #Drivable Space Detection(주행 가능 영역 검출), #Vehicle Detection(차량 검출)"
딥러닝을 활용한 상용차 질량 추정기 설계,2019.11,,"#Mass Estimator(질량 추정기), #Deep Learning(딥러닝), #Commercial Vehicle(상용차), #Vehicle Stability(차량 안정성), #Overload(과적)"
변압기 절연열화 추정을 위한 딥러닝 기반 건전성 데이터 추출,2019.11,,"#변압기(Power Transformer), #건전성 데이터(Health Data), #딥러닝(Deep Learning)"
암호화 데이터에 대한 딥러닝 성능 분석을 위한 시스템 프로토타입,2019.11,,
개인 맞춤형 광고를 위한 딥러닝 검출 툴을 이용한 영상 카테고리 분류기,2019.11,,
물체인식 딥러닝 모델 구성을 위한 파이썬 기반의 Annotation 툴 개발,2019.11,,
단일 Reverse Inception 기반의 딥러닝을 사용한 홀로그램 Super-Resolution,2019.11,,
다중로그 플랫폼을 위한 딥러닝 기반 경로 분류 기술 개발,2019.11,,
딥러닝과 영상처리 기법을 사용한 통합 지능형 주차 관제 시스템 개발,2019.11,"In this paper, we propose the development of an integrated intelligent parking control system using a 360° camera that has overcome the shortcomings of the existing parking control system. The system proposed in this paper consists of six items as follows. First, license plate recognition software when entering the vehicle, second, real-time parking space identification software using 360° image, third, real-time precision parking guidance software based on deep learning vehicle motion recognition, fourth, multi-license-plate recognition software using 360° image, fifth, real-time parking position identification software using 360° image, sixth, database server etc. Performance evaluation results were high in both recognition rate and time spent, and efficiency was confirmed.",
딥러닝 기반의 걸음걸이 인식기를 이용한 사용자 인식 시스템,2019.11,,"#딥러닝, #걸음걸이 인식, #지능형 철도 플랫폼, #컴퓨터 비전, #사용자 인식"
딥러닝을 이용한 수소연료전지자동차 에너지분배 최적화,2019.11,,"#Deep learning(딥러닝), #Fuel cell electric vehicle(FCEV), #Energy management strategy(에너지분배전략)"
가솔린 엔진에서 딥러닝을 이용한 스마트 낙 온셋 모델 개발,2019.11,,"#Knocking(노킹), #Knock Onset(노킹 발생 시점), #Neural Network(인공 신경망), #Ignition Delay(점화 지연 시간), #Spark-Ignited Engine(가솔린 엔진), #Deep Learning(딥러닝)"
스마트 팩토리 환경에서의 딥러닝 기반 제품 데이터 시각화 및 지능형 모니터링 기술 연구,2019.10,"오늘날의 스마트 공장에서 실시간 제품 데이터 모니터링 및 예측을 위한 클라우드 기반의 가상화 플랫폼은 산업 프로세스 자동화를 위해 매우 중요하다. MEC(Multi-Access Edge Computing) 기반의 서버와 같은 클라우드 플랫폼은 실시간 모니터링 환경에서 저지연과 고성능을 지원하기 때문이다. 공장 데이터 시각화 및 모니터링에 관한 많은 연구는 기존에도 많이 이루어졌으나 본 논문에서는 데이터 시각화 및 클러스터링을 위한 DNN(Deep Neural Network : 이하 DNN)을 제안했다. 본 논문을 통해 이전에는 없었던 스마트 팩토리 환경에서의 클러스터링 모듈과 데이터 시각화 및 DNN을 통한 최신 스마트 팩토리 데이터 모니터링 및 디스플레이 모듈에 대한 새로운 시스템을 제안하였다.

Cloud based virtual platform for real-time product monitoring and prediction is crucial for automation of Industrial processes. The MEC based server and cloud platform gives a low latency and high performance in real-time environment monitoring. Although many research has been done in the data visualization, neural network and factory data monitoring, combining these methods to make a MEC based Smart factory data monitoring system has never been proposed. In this research article, we have proposed a data visualization and DNN (Deep Neural Network) with Clustering module. This proposed method for training the neural network achieves a 98% accuracy in the prediction and the cluster can give a 87% accuracy for 2 clusters. This accuracy is state of the art for factory production data classification. This state of art smart factory data monitoring and display module gives the smart factory system a MEC based and high accuracy based monitoring capability.","#딥러닝, #클라우드 컴퓨팅, #모바일 엣지 컴퓨팅, #플랫폼 가상화, #IoT, #지능형 예측, #Deep learning, #Cloud Computing, #MEC, #Platform Virtualization, #IoT, #Intelligent Prediction"
딥러닝 기반의 도시 지역 차량궤적 예측 알고리즘 개발 연구,2019.10,"최근 다양한 위치추적센서를 통하여 수집된 데이터를 기반으로 교통 분야에서는 도시 도로망을 이용하는 개별 사용자의 고해상도 이동성 데이터가 생성 및 수집되고 있다. 해당 센서에서 생성 된 도시 지역 이동성 데이터는 교통 네트워크 이용자들의 이동 패턴에 대한 시공간적인 새로운 통찰력을 제공하며, 이는 도시 지역 교통 흐름을 예측하고 교통 효율을 향상시키는 모델 및 전략을 개발하는데 사용 될 수 있다. 따라서 이 연구는 도시 지역 이동성 패턴을 예측하고자 도시 지역 차량 궤적을 예측하는 알고리즘을 제안한다. 도시 지역을 구역으로 나누어 거시적 이동성 패턴을 분석한 선행 연구와는 달리, 본 연구에서는 교차로 단위의 차량 궤적 데이터를 생성하여 보다 미시적인 이동성 패턴을 분석하려고 한다, 본 연구에서는 딥러닝 기반의 모델을 사용하여 차량 궤적을 예측하였다. 한 차량이 앞서 진행한 교차로 시퀀스를 입력하여 다음에 이 차량이 진행할 교차로를 예측한다. 제안된 알고리즘은 브리즈번에서 1년간 수집된 블루투스 데이터를 이용하여 학습하고 시험한다. 시험 데이터 세트로 알고리즘의 성능을 평가한 결과 제안된 알고리즘이 평균 70% 이상의 예측 정확도를 보였다.

Recently, as a variety of position sensors are developed, a large amount of urban position data is collected in the urban traffic networks. Based on the data collected through such location sensors, high-resolution urban mobility data of individual users using urban road networks is generated and collected in the transportation systems. Urban mobility data generated by these sensors provide a novel spatio-temporal insights into the mobility patterns of traffic network users and can be used to develop models and strategies to predict traffic flows in urban areas and improve traffic efficiency. This study proposes an algorithm for predicting urban mobility patterns. Deep learning based algorithm is used to train mobility patterns in urban areas and predict mobility. The proposed algorithm is trained and tested using Bluetooth data collected in Brisbane for one year. As a result of evaluating the performance of the algorithm with the test dataset, the proposed algorithm shows an average prediction accuracy of 70% or more.","#artificial neural network, #deep learning, #urban mobility prediction, #vehicle trajetory, #도시 지역 이동성 패턴, #딥러닝, #빅 데이터, #차량 궤적"
GPS 데이터를 활용한 보행자 경로 예측 딥러닝 모델,2019.11,,
딥러닝과 드론을 이용한 스마트 기지 감시 시스템,2019.11,,
고해상도 위성 및 항공 영상에 대한 딥러닝 기반 객체 검출 알고리즘의 적용,2019.11,,"#Machine Learnig(기계 학습), #Deep Learning(딥 러닝), #Object Detection(객체 검출), #Aerial Image(위성/항공 영상)"
딥러닝 기반의 차량 후미등 신호 분류기 연구,2019.11,"Classification of taillight signal for forward vehicles is an important clue for self-driving plans. Accurate taillight recognition requires temporal context grasp over several frames. We build a new dataset that accurately reflects the situation where the taillight states change over time. Using the dataset, We train and evaluate two deep learning models that can learn temporal context. First model is the sequence to sequence network which uses RNN, and second model is the C3D network which uses 3D CNN.","#Taillight Signal Classification(후미등 신호 분류), #Sequence to Sequence Model(시퀀스 투 시퀀스 모델), #Recurrent Neural Network, #RNN(순환신경망), #C3D Model(C3D 모델), #3D CNN(3D 콘볼루션 뉴럴 네트워크)"
Optical Flow 추정을 위한 딥러닝 기반의 Lightweight Deep Neural Network,2019.11,"Conventional methods for optical flow estimation are inappropriate for applications that demand real-time operation and small memory capacity. Deep learning based networks, such as FlowNet[l] and FlowNet2[2], have high accuracy and fast running time, but require more than 160M of parameters. Therefore, we introduce tow deep learning based networks called PWC-Net[3] and LiteFlowNet[4] that have compact number of parameters and also have effective performances. Introducing two network models of compact but effective CNN models for optical flows, called PWC-Net and LiteFlowNet.",
U-Net 딥러닝 모델을 활용한 위성영상 기반 인구 예측,2019.11,,
LiDAR 기반의 딥러닝을 이용한 차량 분류 알고리즘,2019.11,"Autonomous vehicles requires quick and accurate perception of the surrounding environment. Thus many researches on perception system for autonomous vehicles using various sensors such as LiDAR, RADAR, and Camera are being conducted. In this paper, we propose a LiDAR based vehicle classification method using deep learning for autonomous vehicles. The proposed classification method firstly eliminates the ground data of the raw point cloud to reduce the amount of data. After that, an squeezeseg v2 algorithm is conducted for the classification of vehicle and euclidean clustering is applied to robustly correct the classified vehicle data. As a result, we have classified the vehicles robustly using this algorithm, and it can be used in the situation such as highway.","#Autonomous Vehicle(자율 주행 자동차), #Deep Learning(딥러닝), #Object Classification(물체 분류), #Clustering(군집화), #LiDAR(라이다)"
딥러닝 기술 기반 아리랑 위성 영상 해상도 향상 연구,2019.11,,"#KOMPSAT -3, #Super resolution, #Deep learning"
딥러닝을 활용한 차량 전방 인식 정보 증강 표출 지연 시간 감소 방안,2019.11,,"#ADAS (Advanced Driver Assistance System), #RNN (Recurrent Neural Network), #AR (Augmented Reality)"
수신된 전파신호의 자동 변조 인식을 위한 딥러닝 방법론,2019.10,"무선 신호의 자동 변조 인식은 지능형 수신기의 주요한 작업으로 다양한 민간 및 군대 응용분야가 있다. 본 논문에서는 딥 뉴럴 네트워크 모델을 기반한 무선통신에서 전파신호의 변조 방식을 식별하는 방법을 제안한다. 순차적인 데이터에 대해 장기적인 패턴을 잡아내는데 용이한 LSTM 모델을 통과하여 얻은 연속적인 신호의 특징값을 딥 뉴럴 네트워크의 입력 데이터로 사용하여 신호의 변조 패턴을 분류한다. 변조된 신호의 진폭 및 위상, 동상(In-phase) 반송파, 직각 위상(Quadrature-phase) 반송파의 값을 LSTM 모델의 입력 데이터로 사용하여 분류한다. 제안된 학습 방법의 성능을 검증하기 위해, 다양한 신호 대 잡음비로 10 가지 유형의 변조 신호를 포함하는 대형 데이터 세트를 사용하여 학습하고 테스트한다. 본 논문의 변조 인식 프로그램은 신호의 사전 정보가 없는 환경에서 변조방식을 예측하는 데 적용될 수 있다.

The automatic modulation recognition of a radio signal is a major task of an intelligent receiver, with various civilian and military applications. In this paper, we propose a method to recognize the modulation of radio signals in wireless communication based on the deep neural network. We classify the modulation pattern of radio signal by using the LSTM model, which can catch the long-term pattern for the sequential data as the input data of the deep neural network. The amplitude and phase of the modulated signal, the in-phase carrier, and the quadrature-phase carrier are used as input data in the LSTM model. In order to verify the performance of the proposed learning method, we use a large dataset for training and test, including the ten types of modulation signal under various signal-to-noise ratios.","#자동변조인식(AMC), #딥러닝, #장단기기억(LSTM), #신경망, #무선통신, #Automatic modulation classification(AMC), #Deep learning, #Long-short term memory(LSTM), #Neural network, #Wireless communication"
딥러닝을 활용한 테이크아웃컵 전용 스마트 쓰레기통 시스템,2019.11,,
딥러닝 기반 공공건물 에너지 제로화 지원 시스템 기술 구현,2019.11,,
딥러닝을 이용한 OFDM 심볼 검출,2019.11,,
단계적 딥러닝 네트워크 학습 방법을 통한 3차원 관절 좌표 추정,2019.11,"3D pose estimation is a study of estimating human 3D joints from a single image, and it is widely used in industrial fields and applications. The performance of 3D pose estimation has dramatically improved with the deep learning. However, the lack of 3D data has always been a constant problem. To solve this issue, we propose multi-stage learning method that uses both 2D and 3D datasets. We achieved 92.0% accuracy with Human3.6M dataset and obtained natural 3D pose results on outdoor images.",
실내 측위 정확도 향상을 위한 딥러닝 기반의 출발 각도 추정 기법,2019.11,"As services using the Internet of Things (IoT) are diversified, it is very important to estimate the location of the device. Though network based localization using radio frequency (RF) signals is widely used in indoor environments. The proposed method utilizes neural network to improve the error of the existing localization method in indoor environment. Experimental results show that the proposed method outperforms the beamforming method and performs well in NLOS environments.",
딥러닝 기반의 경로 생성을 이용한 차선변경의 개선방안,2019.11,,
공간 어텐션 네트워크를 이용한 딥러닝 기반 비용결합 스테레오 매칭,2019.11,,
딥러닝에서 반전된 영상과 그라디언트 기반 구조적 비유사도를 이용한 단안 카메라 에고 모션 추정,2019.11,,
딥러닝을 이용한 솔레노이드 커먼레일 인젝터 진단,2019.11,,
딥러닝 기법을 활용한 대학입시 예측모형의 개발,2019.11,"본 연구는 딥러닝 기법을 활용하여 대학입시의 평가결과를 예측하는 모형의 개발을 다룬다. 학생부종합전형은 학교생활기록부를 중심으로 입학사정관 등의 전문평가자에 의해서 종합적으로 평가하는 대학 입시 전형 중의 하나이다. 본 연구에서는 대학입시 수험생의 학교생활기록의 학업성취도와 입학사정관의 평가결과를 바탕으로 딥러닝 기법을 활용하여 학습한 후, 입시결과를 예측할 수 있는 모형을 개발한다. 현재까지 입시결과를 예측하는 기계학습모형은 알려진 바 없다. 따라서 본 연구에서는 1차적인 연구로 학교생활기록부의 학업성취도와 입학전형의 특성을 위주로 하여 입시의 중간결과와 최종결과를 예측할 수 있는 모형을 고려하였다. 마지막으로 개발된 모형을 활용하여 과거의 입시결과를 예측하고 전문평가자의 평가결과와 비교하여 모형의 적합도를 평가하였다.",
딥러닝(FCN) 기반 용접부 미세조직 분석에 대한 연구,2019.11,,"#deep learning, #fully convolutional network, #ResNet, #acicular ferrite, #carbon steel, #segmentation"
딥러닝을 이용한 지하철 역사 미세먼지 농도 예측 모델,2019.11,,"#미세먼지, #지하철, #딥러닝, #LSTM, #빅데이터"
설명가능한 딥러닝 기술을 이용한 영상기반 기계 시스템의 진동 진단 방법 고찰,2019.11,,
딥러닝을 이용한 기흉 폐렴의 검출과 분류,2019.10,,"#딥러닝, #머신러닝, #기흉, #폐렴, #흉부 x-ray"
임베디드 기반 딥러닝을 활용한 EOIR영상 합성 연구,2019.10,,"#인공지능, #딥러닝, #EO, #IR, #영상 합성"
딥러닝을 이용한 웹 기반 개인 맞춤형 코딩 학습 스케줄링 시스템의 설계 및 구현,2019.11,,
제로에너지빌딩을 위한 딥러닝 기반 건물 에너지 시뮬레이션 보정 모델 설계,2019.11,,
딥러닝을 이용한 MIMO OFDM 레이더 신호 간섭 제거 방법,2019.11,,
딥러닝을 활용한 골프공 스핀량 예측 모델 설계,2019.11,,
비직교 다중접속을 위한 딥러닝 기반의 다차원 변조 신호점 설계,2019.11,"본 논문은 autoencoder 를 활용하여 최적화된 resource 맵핑 과 constellation 맵핑을 수행하는 새로운 code domain-NOMA 방식을 제안한다. 지금까지 고려되지 않은 새로운 구조의 autoencoder를 제안하여 minimum Euclidean 거리를 최대화하는 최적화된 다차원 심볼을 생성하도록 종단간학습(end-to-end learning)을 수행하고, 다중 사용자의 다차원 신호점에 대해서 복호화를 수행한다. 제안한 방식에 의해 10-3 의 비트오류 성능이 기존 SCMA 방식보다 4.5dB 이상 D-SCMA [2]보다 2.7dB 향상되는 것을 시뮬레이션을 통해 확인하였다.",
R-CNN 기법을 활용한 딥러닝 기반 철도 콘크리트 도상 자동 균열 검측 시스템 개발,2019.11,,
전력수요 제어를 위한 딥러닝 기반의 가정용 부하 모델링 기법,2019.11,,
딥러닝 LSTMs 기반 자연어 감성분석 모델을 활용한 거주자의 감성분류,2019.10,"In architectural planning and design, user-centric approach is important since multiple users spend lengthy amount of time in their residences. Post-Occupancy Evaluation(POE) is one effective way of analytically evaluating building performance in terms of users. However, POE is limited in specific project and time consuming. Recently, various types of online platforms have come in use which enables users to provide reviews toward their residences. Those reviews are in natural language form, voluntarily written by users and containing various topic regarding residents’ interests which may suggest one possible way of adopting user-centric approach in building design. In this regard, this paper aims to suggest deep-learning based Long-Short Term Memory Networks(LSTMs) model for sentiment analysis toward user left natural language reviews. For natural language processing and sentiment analysis, this study used “KoNLPy” and “Word2vec for data preprocessinng and Google TensorFlow and Keras for model structure. This approach may suggest one way of recognizing residents’ difficulties and interests toward their residences.","#자연어 처리, #감성 분류, #딥러닝, #건물 성능 평가, #LSTMs, #Natural Language Processing, #Sentiment Classification, #Deep Learning, #Building Performance Evaluation, #Long-Short Term Memory Networks（LSTMs)"
딥러닝 기반의 차량 주행 경로와 지도 정보를 융합하는 미래 경로 예측 기술,2019.11,,"#Machine Learning(기계학습), #Trajectory Prediction(경로예측), #Autonomous Driving(자율주행), #Deep Learning(심층 학습), #Recurrent Neural Network(순환신경망), #Convolutional Network(합성곱신경망)"
딥러닝을 활용한 건물 옥상 면적 계산 모델,2019.11,,
마이크로파 위성자료 활용 U-net 기반 강수타입 분류 결과 및 딥러닝 학습데이터 생산을 위한 플랫폼 개발 계획,2019.10,,"#강수타입분류, #딥러닝, #U-net, #마이크로파관측, #학습자료생산 플랫폼"
딥러닝 기반 교량 구성요소 자동인식,2019.10,,"#교량 구성요소 자동인식, #딥러닝, #딥러닝 네트워크, #전이학습"
딥러닝 기반 모의 달 지형 주요 객체/관심영역 자동 인식 및 정보화 기술 개발,2019.10,,"#모의 달 지형, #달 장애물 지형, #딥러닝 객체 분리 네트워크, #Instance Segmentation"
딥러닝 결합형 미디어 밀도 클러스터링,2019.11,,
딥러닝 AI를 이용한 침입자 통제 및 철도 시설 보안 시스템,2019.11,,
전 · 후처리를 이용한 딥러닝 기반의 주차여부인식,2019.10,"최근 주차공간의 효율적 관리를 위해서 주차유도 시스템이 점점 보급화 되고 있다. 단순히 주차할 곳을 찾기 위한 안내용으로 사용되기도 하지만, 차량 운전자가 본인의 차량이 주차된 곳을 찾기 위해서 영상처리 기술을 이용하여, 주차된 차량 찾기 서비스까지 연동되기도 한다. 따라서, 다양한 영상처리 및 패턴 인식 기술을 이용하여 주차여부인식 및 차량 번호 인식에 대한 연구가 지속되고 있다. 본 논문에서는 인식률을 높이면서, 빠르게 주차면의 주차여부인식을 할 수 있는 알고리즘을 제안한다. 주차면의 주차여부를 분석하기 위해서 전처리 부분으로 다중 임계치 병렬적용을 하였고, 보우팅 방법을 통해 객체 인식률을 높였으며, 딥러닝기술(YOLO)을 이용한 카메라내 객체를 추출을 통하여 사람과 같은 다른 객체 추출에 의해서 발생할 수 있는 주차여부의 오류율을 줄일 수 있었다. 또한 인식률을 저하 시킬 수 있는 요인(빛, 장소)등에서도 제안한 알고리즘을 통한 높은 인식률을 얻을 수 있었다.

Recently, parking guidance systems have been increasingly popular for efficient management of parking spaces. It is often used as an insider""s guide to find a place to park, but it can also be linked to a parked vehicle search service using a camera-like image processing technology to find where the driver has parked his vehicle. Therefore, researches on parking occupation recognition and licence plate recognition using various image processing and pattern recognition technologies are continuing. In this paper, we propose an algorithm that recognizes parking occupation detection quickly in addition to increase the recognition rate. In order to analyze whether the parking slot is occupied, multiple thresholds are applied in parallel as a pre-processing part. Object recognition rate is increased through the voting method. Extraction of objects in the camera use deep learning(YOLO). It was possible to reduce the error rate of possible parking. Also, we can obtain high recognition rate through the proposed algorithm even in the factors that may decrease the recognition rate (light, circulation).","#주차여부인식, #다중 임계치, #보우팅, #전처리, #딥러닝, #Parking Occupation Detection, #Multiple Thresholds Filtering, #Voting, #Pre-Processing, #Deep Learning"
서울시 자율주행 택시 서비스 디지털 트윈 설계를 위한 사전 연구: 딥러닝과 빅데이터를 이용한 승객 수요 예측,2019.11,,"#택시 수요 예측(Taxi Demand Forecasting), #심층 학습(Deep Learning), #빅데이터(Big data), #디지털 트윈(Digital Twin), #자율주행택시 배차시스템(Autonomous Taxi Assignment System)"
딥러닝 기반 베어링 결함 비이상 탐지 방법,2019.11,,"#이상감지(Anomaly detection), #베어링 상태 모니터링(Bearing health condition monitoring), #회전기기(Rotating machinery), #단일 클래스 서포트 벡터 머신(One-class SVM), #합성곱 오토인코더(Convolutional autoencoder), #생성적 적대 신경망(Generative adversarial network), #아노갠(AnoGAN)"
딥러닝 기반 해석데이터와 실험데이터 간의 도메인 적응 기법: 사출성형 사례,2019.11,,
딥러닝 기반의 족부 형태 분류 모델 개발,2019.11,,"#정적 족압 분포 분석(Static Plantar Pressure Distribution Analysis), #내측 아치 지수(Arch index), #다층퍼셉트론(Multi Layer Perceptron), #합성곱 신경망(Convolution Neural Network)"
설명가능한 딥러닝 기반 캡슐내시경 스마트 판독 시스템,2019.11,,
RGB-D 카메라를 활용한 딥러닝 기반의 체결 위치 추정 정확도 향상,2019.11,,
인공위성 데이터를 활용한 딥러닝 기반의 서울 내 미세먼지 농도 예측,2019.10,,"#미세먼지, #딥러닝, #인공위성 자료"
외재적 변수를 이용한 딥러닝 예측 기반의 도시가스 인수량 예측,2019.10,"본 연구에서는 국내 도시가스 인수량에 대한 예측 모델을 개발하였다. 국내의 도시가스 회사는 KOGAS에 차년도 수요를 예측하여 보고해야 하므로 도시가스 인수량 예측은 도시가스 회사에 중요한 사안이다. 도시가스 사용량에 영향을 미치는 요인은 용도구분에 따라 다소 상이하나, 인수량 데이터는 용도별 구분이 어렵기 때문에 특정 용도에 관계없이 영향을 주는 요인으로 외기온도를 고려하여 모델개발을 실시하였다.실험 및 검증은 JB주식회사의 2008년부터 2018년까지 총 11년 치 도시가스 인수량 데이터를 사용하였으며, 전통적인 시계열 분석 중 하나인 ARIMA(Auto-Regressive Integrated Moving Average)와 딥러닝 기법인 LSTM(Long Short-Term Memory)을 이용하여 각각 예측 모델을 구축하고 두 방법의 단점을 최소화하기 위하여 다양한 앙상블(Ensemble) 기법을 사용하였다. 본 연구에서 제안한 일별 예측의 오차율 절댓값 평균은 Ensemble LSTM 기준 0.48%, 월별 예측의 오차율 절댓값 평균은 2.46%, 1년 예측의 오차율 절댓값 평균은 5.24%임을 확인하였다.

In this study, we have developed a forecasting model for city- gas acceptance. City-gas corporations have to report about city-gas sale volume next year to KOGAS. So it is a important thing to them. Factors influenced city-gas have differences corresponding to usage classification, however, in city-gas acceptence, it is hard to classificate. So we have considered tha outside temperature as factor that influence regardless of usage classification and the model development was carried out. ARIMA, one of the traditional time series analysis, and LSTM, a deep running technique, were used to construct forecasting models, and various Ensemble techniques were used to minimize the disadvantages of these two methods.Experiments and validation were conducted using data from JB Corp. from 2008 to 2018 for 11 years.The average of the error rate of the daily forecast was 0.48% for Ensemble LSTM, the average of the error rate of the monthly forecast was 2.46% for Ensemble LSTM, And the absolute value of the error rate is 5.24% for Ensemble LSTM.","#city-gas, #forecasting demand, #LSTM, #ARIMA, #time-series, #acceptance"
비즈니스 거래 활성화를 위한 딥러닝을 활용한 링크 예측 기반의 잠재적 비즈니스 파트너 추천 모델,2019.11,,
계측채널 불확실도 기반 딥러닝 시험 데이터세트 확장을 위한 예비연구,2019.10,,
딥러닝 기법을 이용한 전기화학 융합공정에 관한 특성 분석,2019.11,,"#Deep Learning, #Electrochemical machining, #Hole machining, #Electrode gap, #Applied Current"
증강현실·딥러닝 기반 교육용 어플리케이션 개발 연구 -(중·고등학교) 문제지 답안 및 해설서비스 어플리케이션 개발중심으로-,2019.09,"증강현실은 이미지나 배경에 3차원 가상이미지를 겹쳐서 하나의 영상으로 보여주는 기술로 스마트폰 보급 확대, 디바이스의 진화 등 ICT기술의 발전과 페이스북, 구글, MS, 애플 등 세계적인 IT기업의 투자를 배경으로 급성장 하고 있다. 이러한 새로운 성장동력으로 주목 받고 있는 증강현실 산업의 다양한 확장 영역 중 교육 분야 응용현황을 분석하면 현재 국내 영유아를 비롯한 초등학교 교육 분야에서의 증강현실 응용이 지배적이다. 이러한 현황에 비추어 본 결과 본 연구는 중고등학생들의 학습에 있어 다양한 매체를 통한 학습서비스의 필요성을 제시하며 증강현실 기술을 기반 한 학습지 문제해설 어플리케이션을 개발하여 학습자에게 학습에 대한 상세한 도움을 실시간으로 주고자 하는데 그 연구목적이 있다. 연구를 진행하기 위해 우선적으로 기반기술인 증강현실 기술의 특성과 문제인식 및 답안해설 추출을 위한 딥러닝 기술을 분석하고 딥러닝 관련기술 Object Detection 및 Image Segmentation 의 이미지 처리기술에서의 여러장의 연속된 이미지를 실시간으로 처리하는 기술의 체계를 분석하여 학습지에서의 문제인식 및 답안 해설 자동 추출 시스템을 구성하였다. 연구 방법으로 이론적 배경에 대한 분석을 위해 증강현실 기술과 딥러닝 기술에 관한 국내외 논문을 선행연구 하였으며 증강현실 교육용 어플리케이션 현황분석을 위해 구글, 네이버에 등록된 증강현실 기반 교육서비스를 분석하였다. 그 결과 현재 국내외 논문과 연구에서 증명된 증강현실 기반 학습 환경에서의 학습자의 현존감, 학습 몰입감과 사용성이 높은 장점에 비해 영유아와 아동의 학습서비스에 치중되어 다양한 연령층의 학습서비스가 이루어지지 않음을 알 수 있었다. 모바일 기기와 디지털기술 기반 한 어플리케이션 사용량이 가장 큰 연령층임에도(청소년) 불구하고 그들의 눈높이 맞는 학습서비스 콘텐츠의 부재, 모바일 기술에서의 증강현실 기반기술 탑재부재와 환경속도에 따른 기술적 한계에 의해 교육활용 어플리케이션이 개발되어 활용되고 있지 않은 실정이다.
학습서비스의 활용부재의 무엇보다 중요한 이유는 중고등학생들의 실질적인 학습서비스에 대한 교육 킬러콘텐츠의 부재가 가장 크다고 보여진다.
본 연구는 이러한 청소년층을 위한 실감 형 교육콘텐츠의 활용을 높이고 다양하고 직접적인 학습서비스를 개발하여 자기주도교육에 있어 도움을 주고자 증강현실 기반 학습설명서 어플리케이션을 개발하여 교육 분야에서의 증강현실 활성화뿐 아니라 딥러닝 기술과의 융합서비스를 개발하여 앞으로 다가올 교육서비스의 선두적인 방향과 그 해결방안을 제시하고자 한다.

Augmented reality is a technology that overlaps three-dimensional virtual images with images or backgrounds and shows them in a single image, and is rapidly growing against the backdrop of the development of ICT technologies, including the expansion of the spread of smartphones and evolution of devices, as well as investments by global IT companies such as Facebook, Google, Microsoft and Apple. Analysis of the application status of the education sector among various areas of expansion of the augmented reality industry, which is drawing attention as a new growth engine, currently dominates augmented reality applications in elementary school education areas, including infants and children in Korea. In light of this situation, this research is aimed at providing real-time assistance to learners by developing a problem-solving application for learning paper based on augmented reality technology. In order to carry out the research, we analyzed the characteristics of the augmented reality technology and the deep learning technology for problem recognition and solution analysis, and analyzed the system of the technology to process multiple consecutive images in image processing technology of deep learning related technology Object Detection and Image Segmentation in real time, forming an automatic problem recognition and answer description extraction system in the study paper. In order to analyze the theoretical background with the research method, domestic and foreign papers on augmented reality technology and deep learning technology were researched in advance, and augmented reality-based education services registered with Google and Naver were analyzed for analysis of current status of augmented reality education applications. As a result, it was shown that the learning service of infants and children does not take place in various age groups as the learning service is concentrated on the learning service of the learner in an augmented reality-based learning environment as demonstrated in the present domestic and international papers and research. Despite the fact that mobile devices and digital technologybased applications are among the largest age groups (teenagers), educational applications are not being developed and utilized due to the lack of learning service content that suits their eye, the lack of components equipped with augmented reality-based technologies in mobile technology and the technological limits according to environmental speed.
The most important reason for the lack of use of learning services is the lack of educational killer content on practical learning services for middle and high school students. In order to enhance the utilization of realistic educational contents for these young adults and help them in self-direct education by developing diverse learning services, this study aims to develop an augmented reality-based learning manual application and develop a convergence service with deep learning technology to present the leading direction of education services and their solutions.","#AR(증강현실), #Deep Learning (딥러닝), #Immersion(몰입감), #Learning Services Applications(학습서비스 어플리케이션) Object Detection (개체탐지), #Image Segmentation (이미지 분할), #Convergence Service (융합서비스)"
딥러닝을 활용한 쇼핑몰 고객군별 리뷰 감성 키워드 비교 분석,2019.10,,"#텍스트 마이닝, #딥러닝, #감성 분석, #문서 분류"
딥러닝을 이용한 BIM(Building Information Modeling) 벽 부재 3차원 인식 적용 방안,2019.10,,"#BIM, #IFC, #시멘틱 추론, #딥러닝"
가속도 센서를 이용한 교량 의 케이블 손상 위치 예측 딥러닝 모델 구현,2019.10,,"#교량, #SHM, #케이블 손상, #딥러닝"
딥러닝 기반 상관관계 정렬 전이학습을 활용한 반도체 신규 장비 성능 평가,2019.11,,
드론 영상과 딥러닝을 이용한 실시간 해안쓰레기 모니터링 체계 구축,2019.11,,
PM2.5 농도 예측을 위한 RNN 딥러닝 모델의 하이퍼파라미터 조건에 따른 예측 정확도 비교 평가 연구,2019.11,,
인간-로봇 상호작용 시스템 구축을 위한 딥러닝 기반의 인간 모션 인식,2019.10,,
딥러닝 기술을 활용한 이용자 맞춤정보 추천 서비스,2019.11,,
딥러닝을 활용한 볼트 조인트 구조물의 체결력 도출 연구,2019.11,,"#Bolted joints, #Clamping force, #Vibration"
딥러닝 기반의 최적 가공을 위한 전해액 특성 분석,2019.11,,"#Electro Chemical Machining, #Deep Learning, #Electrolyte, #pH, #Turbidity, #Temperature, #Conductivity"
콤프레셔 상태 예측용 딥러닝 알고리즘 개발 및 실적용에 관한 연구,2019.11,,"#Data Analysis, #Deep Learning, #ARIMA, #Prophet"
딥러닝을 이용한 웨이퍼 빈 맵 신규 패턴 탐지,2019.11,,
딥러닝 기반 높이맵을 활용한 그림자 탐지,2019.11,,
적대적 생성 신경망을 활용한 가상 뇌파 데이터 생성 - 건축공간에 대한 사용자 선호도 파악을 위한 딥러닝 분류모델의 훈련지원을 위해 -,2019.10,"It is important for architects to recognize subjective reponses of users toward architectural design alternatives in early phase of planning and design. In this regard, a model which analyses affective responses of decision-makers is strongly required. A previous study has structured Electroencephalography(EEG)-based deep-learning classification model for evaluating subjects’ emotional responses in quantitative manner in given experiment situation using EEG data. However, it is limited volume of EEG data that results in difficulty in training process of the model. In this regard, this paper aims to suggest Generative Adversarial Networks(GANs) which consists of generator for “fake” EEG data generation and discriminator for training the generator. GANs model may provide one possible way of wide adoption of the suggested model and structuring design knowledge database using EEG data especially for designing architectural spaces for children, elderly and patients those who interviews or questionnaires are hard to be conducted.","#적대적 생성 신경망, #뇌파, #감정 인식, #건물 평가, #Generative Adversarial Networks, #Electroencephalography(EEG), #Affection Recognition, #Building Evaluation"
딥러닝 기법을 이용한 미숙아 망막병증 분류 시스템,2019.10,"미숙아망막병증(Retinopathy of Prematurity, ROP) 이란 37주 미만의 미숙아에게 발생하는 혈관증식성 질환으로 전 세계적으로 소아 실명의 중요한 원인이 되는 질환이다. 미숙아 망막병증 진단을 위한 미숙아의 안저 촬영에는 고가의 촬영 장비가 필요하지만, 현재 우리나라의 수가 체계와 의료 시스템 상 장비를 갖추고 있는 병원이 부족하다. 본 논문에서는 고가의 장비대신 스마트폰으로 촬영한 미숙아 안저 사진을 딥러닝 기법을 이용하여 미숙아 망막병증을 진단하는 분류기를 개발하였다. 스마트폰으로 촬영하였기 때문에 기존의 고가 장비에 비해 현저히 해상도가 떨어짐에도 불구하고 본 논문에서 개발한 분류기의 결과 99% 이상의 정확도를 보여, 본 연구를 통해 보다 손쉽게 스마트폰 촬영으로 미숙아 망막병증을 진단할 수 있을 것이다.

Retinophathy of Prematurity(ROP) is a vascular disease that occurs in premature babies less than 37 weeks old and is an important cause of childhood blindness worldwide. To capture the premature infant""s fundus image for diagnosing ROP requires the expensive camera equipment, but the hospitals currently lacks equipment in the national medical system. In this paper, a classification system for diagnosing ROP was developed using deep learning technique via smartphone funduscopy instead of expensive equipment. Although the resolution of the smartphone photographs is significantly lower than that of existing high-end equipment, the results of the classification system developed in this paper show 99% accuracy, making it easier to diagnose ROP by taking a smartphone.","#retinopathy of prematurity, #deep learning, #smartphone funduscopy"
딥러닝 기반 RF 지문을 이용한 433 MHz 대역 송수신 모듈 인증 기법,2019.10,,"#Authentication, #Deep learning, #RF Fingerprinting"
딥러닝을 이용한 파킨슨병 환자의 진단을 위한 기초적 연구,2019.10,,"#Parkinsons’s Disease(파킨슨병), #Signal Processing(신호처리), #Deep Learning(딥러닝)"
텍스트마이닝과 딥러닝 기술을 활용한 외국인 관광객의 국내 지역별 이미지 비교,2019.11,"본 연구에서는 소셜 네트워크 서비스(Social Network Service, SNS)인 플리커(Flickr)에 게시된 지오태깅된 사진 데이터와 텍스트 데이터를 활용하여 우리나라 방문객이 갖는 지역별 이미지를 비교하였다. 플리커 데이터 수집은 2013년부터 2018년까지 약 6년간 데이터를 수집하였으며, 6년간 수집된 데이터 29만여건 가운데 관광객이 업로드한 것으로 추정되는 약 17만장의 사진을 분석대상으로 하였다. 플리커의 태그와 텍스트에 대한 분석은 텍스트마이닝 기법 중 단어간 빈도분석 및 연관관계분석을 적용하였으며, 사진에 대한 분석은 합성곱 신경망(Convolutional Neural Network, CNN) 중 하나인 Inception V3 모델을 활용하였다. 지역에 대한 이미지 분석은 서울, 부산, 제주 지역을 대상으로 하였으며, 텍스트 분석 결과와 사진 이미지 분석결과를 비교하여 지역 이미지의 차이를 분석하였다.",
딥러닝을 이용한 스윙 시퀀스 영상 기반 3차원 골프 스윙 분석,2019.10,"빠르게 움직이는 골프 스윙 동작을 인간의 눈으로 평가하고 분석하는 것은 평가하는 사람의 주관에 따라 크게 달라질 수 있다. 본 논문에서는 최근 영상 인식 분야에서 좋은 성능을 나타내고 있는 딥러닝 기술을 이용해 단일 카메라 기반 스윙 분석시스템의 한계를 극복하고, 3차원의 정량적 정보 추출 및 분석 방법을 연구한다. 먼저, 합성곱 신경망을 이용해 시퀀스 영상의 특징을 추출하고, 스윙 구간을 분류한다. 스윙 구간 정보를 갖는 시퀀스 특징은 양방향 장단기 메모리 기반의 스윙 분석 모델의 입력으로 사용되며, 바디-스웨이, 헤드-업, X-factor 분석을 수행한다. 각 분석 모델을 통한 스윙의 정량적 상태 예측 결과, 상체의 움직임 예측 RMSE 4.23, 머리 움직임 예측 RMSE 5.18, X-factor 예측 결과 RMSE 3.86의 성능으로 나타났다. 이 결과로 2차원 정면의 시퀀스 영상을 기반으로 3차원의 정량적 골프 스윙 분석이 가능함을 확인하였다.

The evaluation and analysis of the fast moving golf swing motion by human eyes can vary greatly depending on the evaluator’s perspective. In this paper, we study the method of three-dimensional quantitative information extraction by overcoming the limitation of single camera based golf swing analysis system using deep learning which is showing good performance in image recognition field recently. First, the features of the sequence images are extracted using convolutional neural network, and the swing section is classified. Sequence features with swing section information are used as inputs to the bidirectional long short-term memory based swing analysis model, and perform body-swing, head-up, and X-factor value prediction. Experimental results showed that the performance of the upper body motion prediction RMSE 4.23, the head motion prediction RMSE 5.18, and the X-factor prediction result RMSE 3.86. As a result, it is confirmed that 2D frontal sequence images based 3D quantitative golf swing analysis is possible.","#golf swing analysis, #sequence image regression, #deep learning"
길방향 인식을 위한 딥러닝 학습데이터 구축 방법,2019.10,,
딥러닝기반 엣지디바이스 데이터 압축기술 연구,2019.10,,
대치와 추정을 이용한 딥러닝 기반의 라이다 오토메트리 개선 연구,2019.10,,
AMOS 데이터 기반 딥러닝 활용 지상 기온 예측,2019.10,,"#지상 기온, #심층신경망 모델, #LSTM"
딥러닝의 입력데이터에 따른 볼 베어링 결함 인식률 연구,2019.10,,"#Deep learning, #Intelligent fault diagnosis, #Machine health Monitoring, #Ball Bearing"
단어 임베딩과 어텐션 기반의 딥러닝 모델을 활용한 장소정보 탐지 기법,2019.09,"최근 소셜미디어 플랫폼의 활용이 증가함에 따라 장소정보를 포함하고 있는 수많은 텍스트 데이터가 발생하고 있다. 다수의 플랫폼이 장소정보를 입력하는 기능을 제공하고 있지만, 지오태깅 된 게시물의 수가 적어 장소정보가 제대로 활용되지 못하고 있다. 텍스트 내 장소정보를 활용하기 위해 기존에는 BIO(Beginning-Inside-Outside)태깅을 이용한 개체명인식을 통해 지명 등을 추출하는 연구들이 진행되었지만, BIO태깅에는 상당한 시간과 인력이 소모되며 보통명사는 태깅하지 않는다. 이에 본 연구는 장소정보 포함 여부에 따른 라벨링을 하고, 단어 임베딩과 어텐션 기반의 딥러닝 모델을 활용하여 장소정보를 포함했는지의 이진 분류기 학습을 통해 보통명사를 포함한 확장된 범위의 장소정보를 탐지하였다. 실험 데이터에 대한 장소정보 포함 여부 탐지 정확도는 약 88%이며, AUC 0.945의 성능을 보였고, 제안한 방법을 통해 문장 내 장소정보를 시각화 및 추출도 가능한 것을 확인하였다.

Recently, as the use of the social media platform increases, a lot of unstructured text data including location information is generated. Although such platforms provide the function of adding location information, the use of location information is limited due to a small number of geotagged posts. In order to make use of these location information in the text, named entity recognition using BIO(beginning-inside-outside)tagging was used to extract locational information. However, it takes considerable time and manpower labeling and ignores common nouns. In this study, we detect extended location information including common nouns by training binary classifier using word embedding and attention-based deep learning model. The proposed model showed about 88% accuracy and AUC of 0.945 in detecting location information, which can also be visualized or extracted.","#장소정보, #어텐션, #딥러닝, #단어 임베딩, #자연어처리, #POI, #Location Information, #Attention, #Deep Learning, #Word Embedding, #Natural Language Processing"
딥러닝 기반의 ODS 데이터 모니터링을 통한 대형레이다 PHM 시스템,2019.10,,"#Prognostics & Health Management(건전성 예측 및 관리), #Operational Defection Shape(운용 중 변형 형상), #Deep Learning(딥러닝), #Large Radar(대형레이다), #Artificial Intelligence(인공지능), #Fatigue Life(피로 수명)"
시계열데이터의 DQN 딥러닝 학습을 위한 새로운 손실함수의 제안,2019.10,,"#Loss Function, #Deep Learning, #Artificial Intelligence"
강우자료 학습에 따른 딥러닝 기반 LSTM모형의 수위예측,2019.10,,"#딥러닝, #RNN, #LSTM, #무강우지속시간, #IETD, #수위예측"
딥러닝을 이용한 항공 영상에서의 도로 인식,2019.10,,"#segmentation, #u-net, #GeoAI, #도로 인식"
VGG 네트워크 기반 딥러닝 알고리즘에서 주 객체 위치 검출 방법에 관한 연구,2019.10,,"#Weakly-Supervised learning, #Deep learning, #Object localization, #VGG19, #ILSVRC"
설명가능한 딥러닝 기술을 이용한 영상기반 기계 시스템의 진동 진단 방법 고찰,2019.10,,"#Explainable Deep Learning(설명가능 인공지능), #Fault Detection(고장진단), #Class Activation Map(클래스 엑티베이션 맵)"
AI학습플랫폼 치타를 이용한 딥러닝분석,2019.10,,
딥러닝 기반 차량 속도 모니터링을 통한 스마트 횡단보도 시스템의 설계 및 구현,2019.10,"우리나라의 개인별 자동차 보급률이 지속적으로 증가하면서 교통사고 발생률 또한 지속적으로 증가하는 추세를 보이고 있다. 특히, 보행자 사고 중 횡단보도에서의 아동과 노인의 사고 비율이 높은 것으로 나타나면서 횡단보도 교통사고에 대한 예방 노력이 많이 이루어지고 있다. 본 논문에서는 횡단보도에 접근하는 차량들의 속도 모니터링을 통한 적응형 알림을 제공함으로써 보행자 교통사고를 예방하기 위한 시스템을 제안한다. 이를 위하여 딥러닝 기술을 활용하여 횡단보도에 접근하는 차량의 위치 변화를 모니터링하며 최적화된 분류 모델과 파라미터를 사용하여 차량 속도에 따른 위험 정도를 예측한다. 실제 차량 주행 영상을 이용한 시뮬레이션 및 실험을 바탕으로 제안하는 시스템의 교통사고 예방 활용가능성을 확인하였다.

As the individual vehicle penetration rate of Korea continues to increase, the rate of traffic accidents tend to increase as well. In particular, among the pedestrian accidents a high ratio of accidents of children and the elderly at crosswalks are observed; therefore, a lot of studies and efforts have been made to prevent crosswalk traffic accidents. This paper proposes a system to prevent pedestrian traffic accidents by providing adaptive notification through speed monitoring of vehicles approaching the crosswalk. To this end, a deep learning technology is used to monitor changes in the position of the vehicle approaching the crosswalk, and well-optimized classification models and parameters are used to estimate the speed of a vehicle, thereby predicting the degree of safety around the crosswalk. Through the experiments and simulations using real vehicle driving images, we show the feasibility of the proposed system to prevent traffic accidents.","#Deep learning, #Crosswalk, #Vehicle speed, #Adaptive alarm"
딥러닝 기반 베어링 결함 비이상 탐지 방법,2019.10,,"#Anomaly detection(이상감지), #Bearing health condition monitoring(베어링 상태 모니터링), #Rotating machinery(회전기기), #One-class SVM(단일 클래스 서포트 벡터 머신), #Convolutional Autoencoder(합성곱 오토인코더), #Generative adversarial network(생성적 적대 신경망), #AnoGAN(아노갠)"
딥러닝 기반 병리학적 음성 진단 시스템,2019.10,,"#Dysphagia(연하곤란, 삼킴장애), #Pathological voice(병적음성), #Convolutional neural network(합성곱 신경망), #Diagnosis(진단), #Short-time Fourier Transfer(단시간 푸리에 변환), #Mel Frequency Cepstral Coefficient(멜 주파수 셉스트랄 상수)"
규칙 기반과 딥러닝을 동시에 활용한 앙상블 회전체 이상 진단,2019.10,,"#ensemble(앙상블), #rule-based(규칙기반), #deep learning(심층학습), #CNN(합성곱 신경망), #orbit detection(궤도추적)"
딥러닝 기반 스마트 센서를 이용한 케이블 모니터링 자동화 시스템 개발,2019.10,,"#케이블, #케이블 모니터링, #임베디드 프로세싱, #스마트 센서, #peak-picking"
딥러닝을 이용한 광역계통 진동감쇄 제어기의 연구,2019.10,,
원-핫 인코딩을 이용한 딥러닝 단기 전력수요 예측모델,2019.09,"분산자원 집합 거래시장에 참여를 원하는 소비자나 사업자를 위한 가상발전소의 전력거래 플랫폼에서 사업참여자의 수요자원을 관리하고, 이에 적절한 전략을 제공하기 위해 익일 개별 참여자의 수요와 전체 계통의 전력수요를 예측하는 것이 대단히 중요하다. 이러한 전력거래 플랫폼에서 활용하는 것을 목표로 본 논문은 우선 익일의 24시간 전력계통 전력수요예측 모델을 개발하였다. 본 논문에서는 전력수요예측 데이터의 시계열 특성을 고려하여 딥러닝 기법 중 LSTM 알고리즘을 사용하였고, 전력수요량 등의 입출력 값에 원-핫 인코딩 기법을 적용하는 새로운 시도를 하였다. 성능평가에서 일반 DNN과 본 논문에서 구현된 LSTM 예측모델은 각각 평균 제곱근 오차 4.50, 1.89를 나타내어 LSTM 모델이 예측정확도가 높게 나타났다.

In order to manage the demand resources of project participants and to provide appropriate strategies in the virtual power plant""s power trading platform for consumers or operators who want to participate in the distributed resource collective trading market, it is very important to forecast the next day""s demand of individual participants and the overall system""s electricity demand. This paper developed a power demand forecasting model for the next day. For the model, we used LSTM algorithm of deep learning technique in consideration of time series characteristics of power demand forecasting data, and new scheme is applied by applying one-hot encoding method to input/output values such as power demand. In the performance evaluation for comparing the general DNN with our LSTM forecasting model, both model showed 4.50 and 1.89 of root mean square error, respectively, and our LSTM model showed high prediction accuracy.","#Electric Load Forecasting, #LSTM, #One-Hot Encoding, #RNN, #Virtual Power Plant"
딥러닝 기반 도심지 교통혼잡 예측 및 신호제어 솔루션 시스템 개발 중 교통상황 예측기반 신호 시연시스템 개발,2019.09,,
딥러닝 알고리즘을 이용한 콘크리트 압축강도 예측 모델 개발을 위한 기초적 연구,2019.10,,
딥러닝 추적을 이용한 주정차위반 검지 방법,2019.09,"본 논문은 번호판 인식기술과 딥러닝을 이용하여 주정차위반을 판단하는 효과적인 방법을 소개한다. 이 방법은 차량이 통과 하는 지역(ROI)에서 차량번호를 읽고 추적하는 중에, 차량이 주차금지구역에 일정 시간 이상 정지하면 주차위반으로 판단하고 역방향으로 재생된 동영상과 증거 이미지를 확보한다. 주정차위반을 단속하는 일반적인 방법은 단속 순간을 촬영한 몇 장의 이미지에서 차량번호를 확인하는 것에 그친다. 추적기법과 역방향 재생이 활용되는 이 방법은 물체에 의한 번호판 가림에 상관없이 차량번호판을 인식할 수 있어서 기존의 방법보다 단속 효과가 높다. 또한, 번호판을 읽기에 가장 좋은 시점에서 촬영 이미지를 얻기 때문에 번호 인식률도 높다. 주정차위반 여부를 판단하기 위해 사용하는 차량추적은 CNTK 및 Faster R-CNN을 사용하였다. 실험은 도로상 관심구역을 통과하는 521대의 차량을 대상으로 진행했으며 그중 30대가 주정차 위반차량이었다. 제안한 방법은 주차위반차량 30대 중 29대를 주정차위반으로 판정하여 주정차 위반차량 검지율은 96.7%를 보였다.

This paper introduces an effective method for determining whether a driver has a parking violation. The method using the techniques based on a deep learning and LPR(License Plate Recognition) can obtain a plate number while tracking vehicles across ROI and obtain a reverse video including evidence images.
A common way to crack down on the parking violations is to identify the car number from multiple images taken at the time of the parking violation. This method, which uses tracking and backward-sequence video, is more effective than the conventional method because it can recognize the license plate regardless of the license plate obscured by the object. In addition, license plate recognition rate is high because it obtains shot image at the best time to read the license plate. CNTK and Faster R-CNN were used in order to track vehicle and determine the parking violation. The experiment was conducted on 521 vehicles that passed through the road(Region Of Interest), of which the 30 vehicles were in violation of the parking law. By using the proposed method, 29 vehicles of them were judged to be parking violations. The detection rate of illegal vehicles was 96.7%.","#Vehicle Tracking, #Parking Violation, #CNTK, #Faster R-CNN, #Backward-Sequence Video"
SNS에서 텍스트-칼라영상의 교차양식 검색을 위한 데이터셋 구축과 딥러닝 모델,2019.9,"ImageNet 등과 같은 대규모 영상 데이터셋 구축이 컴퓨터 비전기술 발전에 많은 기여를 하듯이, 최근 여러 종류의 대규모 데이터셋의 구축은 해당 양식을 이용하는 인공지능 분야 발전에 큰 도움이 되고 있다. 그러나, 한국어 텍스트와 칼라영상의 교차양식 검색을 위한 대규모의 한국어 데이터셋은 존재하지 않는다. 논문에서는 소셜 네트워크 서비스(SNS) 중 하나인 인스타그램 게시물인 텍스트와 칼라영상을 수집, 정리하여 텍스트와 칼라영상의 교차양식 검색을 위한 대규모 데이터셋 구성방법을 제안하였다. 또한 데이터셋의 활용 가능성을 보이기 위해 주위기반의 딥러닝 모델 등 서로 다른 두 양식사이의 상호간의 교차양식 검색 방법들을 적용하고, 그 성능을 평가하였다. 본 연구에서 구성된 데이터셋은 SNS 등의 짧은 길이 한국어 문장 분석을 필요로 하는 다양식 기계학습에 활용할 수 있으며, 교차양식 검색 성능평가에서 가장 우수한 성능을 보인 주위기반의 딥러닝 모델은 기계가 SNS의 문장 또는 영상을 다른 양식으로부터 스스로 생성할 수 있는데 활용될 수 있다.

Recently, various types of large dataset give the great help for the deveopment of AI technology as the same way as ImageNet does for the computer vision area. Unfortunately, however, there is no such large dataset for cross-modal retrieval between the text of Korean language and color images. This paper proposes the method how to easily collect and arrange to construct such dataset for cross-modal retrieval from Instagram, a kind of SNS(Social Network Service). Then we construct the dataset according to the methos, and the applicability has been proven by performing the cross-modal retrieval experiments. In the experiment, several methods for cross-modal retrievals are adopted including attention-based deep learning approach to compare the performances. The dataset in the study can be used to various multi-modal machine learning which requires the analysis of short Korean sentences, and the attention-based deep learning model which provides the best performance can be applied to automatically generate a Korean sentence from a color image, or a color image from a Korean sentence in SNS.","#Cross Modal Retrieval, #Social Network Service(SNS), #Text-Image Dataset, #Deep Learning, #Computer Vision"
딥러닝을 활용한 다발성 골절 분류,2019.08,"정형외과 의사는 컴퓨터 단층 촬영(CT)을 활용해 골절 환자의 골절 범주를 식별하고 치료 방법을 결정한다. 골절이 발생하게 되면 다발성 골절인 경우가 많고 골절 범주가 많기 때문에, 의사가 골절을 정확히 분류하기 위해서는 높은 전문성과 많은 노력이 필요하다. 이 논문에서는 골절 범주 식별을 다중 부류 분류 문제로 정의하고, 골절의 범주를 식별하기 위해 딥러닝을 사용하는 방법을 제안한다. 제안하는 딥러닝 모델은 GoogleNet과 유사한 형태로 골절의 특징을 추출하고, 다층퍼셉트론으로 각 골절 범주의 점수를 계산해 분류를 한다. 그리고 출력 노드의 점수가 특정 임계값 내에 있는 최대 4개의 골절 부류를 선택한다. 하반신 골절 CT 데이터에 대한 제안 방법의 정밀도는 73.3%, 재현율은 86.9%였다.

The orthopedists use computed tomography(CT) to identify fracture categories of fractured patients and determine their treatment. Fractures often result in multiple fractures which have various categories. Here it is required for orthopedists to have a high level of expertise and stressful examination. This paper casts the fracture category identifier task as a multi-label classification problem, and proposes a deep learning based method to it. The proposed deep learning model extracts the features of fractures with GoogleNet-like front-end and determines the fracture categories from the categorieswise score computed with back-end fully connected layer. The proposed method showed 73.3% precision and 86.9%recall for a CT dataset for lower body fracture in the experiments.","#딥러닝, #컨볼루션 신경망, #골절, #다중 레이블, #Deep Learning, #Convolutional Neural Network, #Fracture, #Multi-Label"
납기와 작업준비비용을 고려한 병렬기계에서 딥러닝 기반의 일정계획 생성 모델,2019.08,"4차 산업혁명이 진행되면서 제조업에서 사물인터넷(IoT), 머신러닝과 같은 지능정보기술을 적용하는 사례가 증가하고 있다. 반도체/LCD/타이어 제조공정에서는 납기일(due date)을 준수하면서 작업물 종류 변경(Job change)으로 인한 작업 준비 비용(Setup Cost)을 최소화하는 일정계획을 수립하는 것이 효과적인 제품 생산을 위해 매우 중요하다. 따라서 본 연구에서는 병렬기계에서 딥러닝 기반의 납기 지연과 작업 준비 비용 최소화를 달성하는 일정계획 생성모델을 제안한다. 제안한 모델은 과거의 많은 데이터를 이용하여 고려되어지는 주문에 대해 작업 준비와 납기 지연을 최소화하는 패턴을 학습한다. 따라서 세 가지 주문 리스트의 난이도에 따른 실험 결과, 본 연구에서 제안한 기법이 기존의 우선순위 규칙보다 성능이 우수하다는 것을 확인하였다.

As the 4th industrial revolution progressing, manufacturers are trying to apply intelligent information technologies such as IoT(internet of things) and machine learning. In the semiconductor/LCD/tire manufacturing process, schedule plan that minimizes setup change and due date violation is very important in order to ensure efficient production. Therefore, in this paper, we suggest the deep learning based scheduling generation model minimizes setup change and due date violation in parallel machines. The proposed model learns patterns of minimizing setup change and due date violation depending on considered order using the amount of historical data. Therefore, the experiment results using three dataset depending on levels of the order list, the proposed model outperforms compared to priority rules.","#일정계획, #심층신경망, #납기, #작업준비용, #머신러닝, #Scheduling, #Deep Neural Network, #Due Date, #Setup Cost, #Machine Learning"
온라인 P2P 환경에서 딥러닝을 적용한 다분류 기반 개인신용등급 예측모형,2019.08,"In this study, we propose a multi–class personal credit rating prediction model applying deep learning to accurately predict personal credit rating as a way to reduce investor""s investment risk. In P2P lending, credit information on borrowers has an important influence on investment decisions, since investors make investment decisions based on objective information of borrowers without special collateral.
To develop the multi-class prediction model, we use the Lending Club loan data to classify the customer""s grade into four classes, and randomly extract 1,000 data from each grade and use a total of 4,000 data. We apply the method which is MDA, ANN, one-against-one, Weston and Watkins, Crammer and Singer, and DNN. The MDA and ANN were used as benchmarking models. As the results, DNN shows higher prediction performance than other models, so that deep learning can be applied with excellent performance in multi-class problems. In addition, the confusion matrix shows that the DNN model can reduce the investment risk of investors rather than the multi-class SVM model. By applying the DNN, we can make up for the defect of the multi-class SVM, which is obtained through multiple binary classifications, and can be applied more efficiently in big data environment. The proposed method can protect investors from investment risk by providing more detailed information on investment decisions in online P2P finance.","#Credit Rating, #Deep Learning, #Peer-to-peer, #DNN, #Multi-class"
딥러닝과 ICP 알고리즘을 이용한 링 모양의 소형 빈피킹 물체의 실시간 3차원 자세 추정,2019.09,"Bin picking is an important task in smart manufacturing and intelligent robotics. For a robot to pick or grip an object with a human-like gripping action, it needs to know the accurate 3D pose of the object. In this paper, we propose a method for estimating the 3D pose of a small ring-shaped object using infrared and depth images generated by a depth camera. The proposed method consists of two algorithm modules, the first to recognize an object in a 2D infrared image and the second to estimate the 3D pose by applying the ICP (iterative closest point) algorithm to 3D depth data. In the first module, we propose a method to generate a three-channel integrated image with features from the depth and infrared images. Next, we introduce a method for training an object detector based on deep-learning. Because the bin-picking test object in this paper is small and ring-shaped, it is difficult to detect and find 3D poses of individual objects when many such objects are piled up. We solved this problem with a depth-based filtering method. Using the filtered image, each object region is separated by the deep learning approach. In the second module, the ICP algorithm is employed to estimate the 3D pose of the ring object. We match a 3D reference model of the object and the real object using the point-to-point ICP algorithm. Performance of the proposed method is evaluated by using two different types of depth camera in the experiments.","#bin picking, #pose estimation, #deep learning, #object detection"
딥러닝을 위한 실험적 평가 기반의 이동경로 데이터 인코딩 방법 비교,2019.08,"센서기술의 발달로 자동차나 사람으로부터 수집되는 이동경로 데이터의 양이 급증하고 있다. 이러한 이동경로 데이터로부터 유의미한 결과를 이끌어내기 위해서 현재까지 많은 연구들이 활발히 진행되고 있다. 그 중 자연어 처리 등 타 분야에서 두각을 나타낸 딥러닝을 이용한 연구들이 최근 시도되었으나, 이동경로 데이터만의 고유한 특성을 효과적으로 인코딩하는 방법은 아직 많이 연구되지 않았다. 본 논문에서는 이동경로 데이터의 특성을 표현하는 인코딩 방법론 5가지와 그에 맞는 정규화과정을 소개하고, 이에 대한 비교실험을 통해 성능을 비교하고자 한다. Microsoft Geolife 데이터를 활용하여 LSTM기반의 딥러닝 모델을 학습하고 교통수단(Transportation Mode) 분류를 수행한 결과, 임베딩과 결합된 One-Hot Encoding 기반 정규화 방법론이 성능과 속도 측면에서 비교모델 중 가장 우수한 것으로 관측되었다.

The amount of trajectory data collected from humans and vehicles is growing rapidly owing to the improvement in sensor-based technologies. Many researchers have actively attempted to draw meaningful insights from trajectory data. Recently, deep learning-based methods, which demonstrated high performance in other fields such as natural language processing have been used to tackle this issue. However, there is little effort on the development of effective methods to encode trajectory data. This paper introduces five trajectory encoding methods along with their normalization and compares their performance through an extensive evaluation. In the experiments on LSTM-based transportation mode classification using Microsoft Geolife data, merging of embedding and one-hot encoding along with normalization demonstrated the highest performance in terms of performance and model convergence speed.","#이동경로, #데이터 마이닝, #딥러닝, #인코딩 방법론, #trajectory, #data mining, #deep learning, #encoding methodology"
딥러닝 기반 얼굴 인식 최신 기술 동향,2019.8,,
딥러닝 기반 포즈 변화에 강인한 귀 인식 연구,2019.08,"최근 개인 고유의 생체적 특징을 활용하여 신원을 식별하는 생체 인식 기술로서 귀 인식 연구가 주목받고 있다. 또한 다양한 생체 인식 분야에서 딥러닝을 기반으로 포즈 및 조명 변화, 가림 등이 존재하는 비제약적 환경에서의 인식 성능 고도화가 이루어지면서 귀 인식 분야에서도 딥러닝 기반 연구가 진행되고 있다. 하지만 딥러닝 모델 학습에 필수적인 대규모 데이터베이스에 대한 부재와 귀 특성을 고려한 관련 연구가 아직 초기 단계로, 인식 성능에 한계가 존재한다. 이를 개선하기 위하여 본 논문에서는 비제약적 환경 기반 귀 인식 연구에 활용 가능한 K-Ear 데이터베이스를 구축하였다. K-Ear 데이터베이스는 정면으로부터 60°까지의 포즈 변화와 조명 변화, 일부 가림 등이 존재하는 다양한 환경의 귀 영상을 포함한다. 그리고 이를 활용하여, 포즈 변화에 따라 인식 성능이 저하되는 문제를 개선하기 위한 딥러닝 기반 귀 인식 모델을 제안한다. 제안하는 모델은 귀의 형태 등 고유한 특성을 고려하기 위한 전처리로 입력 영상에 zero padding을 수행하고 인식 성능 향상을 위해 VGG-16과 ResNet50 모델 기반 특징 추출 및 스코어 레벨 기반 앙상블 기법을 활용한다. 실험 결과를 통해 제안하는 귀 인식 모델이 단일 모델 활용 대비 극심한 포즈 변화에서 Rank-1 기준 30% 이상 성능이 향상되는 것을 확인하였다.

Recently, ear recognition has been getting attention as a biometrics to identify an individual. According to significant enhancement of the recognition performance based on deep learning in the various fields of biometrics, a lot of deep learning-based approaches has been studied in ear recognition. However, there is a limit to improve the performance because of some issues such as the lack of large-scale ear databases and non-consideration of the characteristics for ears. To overcome these problems, this paper introduces a new database, called the K-Ear database, that can be used for research of ear recognition in unconstrained environment. The K-Ear database includes ear images of various environments such as pose changes from the front of a ear to 60°, illumination changes, and the partial occlusion by accessories. This paper also proposes a deep learning-based ear recognition model robust to pose variation by using the K-Ear database. To consider the characteristics of an ear, this paper performs the zero padding as a preprocessing on the input image. VGG-16 and ResNet50 model was utilized, to extract the feature vector. Finally, score level ensemble is performed to enhance the performance. Experimental results show that the proposed method is superior to the single model by more than 30% based on rank-1 accuracy in extreme pose variation.","#Ear recognition, #Convolutional neural networks, #K-ear database, #Ensemble"
딥러닝을 이용한 판류형 간판의 인식,2019.08,"간판은 유형마다 간판의 규격이 정해져 있으나 실제 설치된 간판은 형태와 크기가 일정하지 않다. 또한, 간판은 간판 내부의 색상에 대한 규정이 정해져 있지 않기 때문에 다양한 색상을 갖고 있다. 간판을 인식하기 위한 방법은 도로표지판과 차량번호판을 인식하는 유사한 방법으로 생각할 수 있으나 간판의 특성으로 인해 도로표지판과 차량번호판과 유사한 방법으로 간판을 인식할 수 없는 한계점이 있다. 이에 본 연구에서는 딥러닝 기반의 Faster R-CNN 알고리즘을 이용하여 불법 및 노후 간판의 주요 대상이 되는 판류형 간판을 인식하고 간판의 영역을 자동으로 추출하는 방법론을 제안하였다. 스마트폰 카메라를 이용하여 촬영한 간판 영상을 통해 판류형 간판을 인식하는 과정은 2가지의 순서로 나뉜다. 먼저, 다양한 유형의 간판 영상에서 판류형 간판을 인식하기 위해 딥러닝을 이용하여 간판의 유형을 인식하였으며 그 결과는 약 71%의 정확도로 나타났다. 다음으로 판류형 간판의 경계영역을 인식하기 위해 간판 영역 인식 알고리즘을 적용하였을 때 85%의 정확도로 판류형 간판의 경계영역을 인식하였다.

The specifications of signboards are set for each type of signboards, but the shape and size of the signboard actually installed are not uniform. In addition, because the colors of the signboard are not defined, so various colors are applied to the signboard. Methods for recognizing signboards can be thought of as similar methods of recognizing road signs and license plates, but due to the nature of the signboards, there are limitations in that the signboards can not be recognized in a way similar to road signs and license plates. In this study, we proposed a methodology for recognizing plate-type signboards, which are the main targets of illegal and old signboards, and automatically extracting areas of signboards, using the deep learning-based Faster R-CNN algorithm. The process of recognizing flat type signboards through signboard images captured by using smartphone cameras is divided into two sequences. First, the type of signboard was recognized using deep learning to recognize flat type signboards in various types of signboard images, and the result showed an accuracy of about 71%. Next, when the boundary recognition algorithm for the signboards was applied to recognize the boundary area of the flat type signboard, the boundary of flat type signboard was recognized with an accuracy of 85%.","#Signboard Detection, #Flat Type, #Faster Region-Based Convolutional Neural Network, #Watershed, #K-Means Clustering, #Boundary Area, #간판 인식, #판류형, #Faster R-CNN, #워터쉐드, #K-평균 군집화, #경계 영역"
딥러닝 모델 기반 단기 전력수요 예측 Top 10%,2019.09,"This paper presents a Short-Term Long-short term memory Convolutional neural network(STLC) Model that is combined with Convolutional Neural Network(CNN) and Long-Short Term Memory(LSTM). CNN model predicts load pattern using past load profile, LSTM model forecasts load variation depending on temperature and time index. STLC model’s output is hourly load data to combine two model’s outputs. The input parameters of STLC model are composed of time index, weighted weather data, past load data. Weights are calculated based on electricity consumption by main region in South Korea and reflects in the weather data. STLC model is trained with data from 2013 through 2017 and is verified with data from 2018. The STLC model forecasts 1-day hourly load data. Simulation results obtained show the comparison of actual and forecasted load data and also compare with other methods in MAPE(Mean Absolute Percentage Error) to prove accuracy of the proposed model.","#Deep Learning, #Short-Term Load Forecasting, #CNN, #LSTM"
자율주행 자동차 환경에서의 3D-LiDAR와 딥러닝을 이용한 클러스터링 후보군 기반 실시간 객체 검출,2019.09,"Recently, IT companies such as Google, NVIDIA, and NAVER have been also developing autonomous vehicle platform technologies. In particular, sensors for object detection in surrounding environments have been improved in recognition rates by applying multi-sensor systems using camera, LiDAR, and radar. With the increasing importance of recognition technology, 3D information-based recognition technologies have been actively advanced as a commercial product of 3D-LiDAR. In this paper, a candidate group of point-clouds from 3D-LiDAR is extracted using Euclidean clustering in order reduce the processing time delay in RPN (Region Proposal Network), which is one of the basic schemes for existing object detection. Then, it proposes types of input slicing, based on the extracted candidates. In addition, the accuracy and the processing time using four CNN networks (Basic CNN, ResNet, VGG16, and MobileNet) are compared over not only the private data(CVLab dataset) obtained in actual road environment but also the publicly open KITTI dataset.","#autonomous vehicle, #3d-LiDAR, #clustering, #deep learning, #object detection"
딥러닝을 위한 데이터 관리 기술 동향,2019.08,,
딥러닝 기법을 이용한 P2P 소셜 대출 채무자 부도 예측모델에 관한 연구,2019.07,"국내외적으로 다양한 P2P 소셜 대출 서비스가 등장하면서 플랫폼 서비스 업자나 투자자 입장에서는 연체나 부도가 발생하지 않을 대출 요청을 찾아서 투자하는 것이 중요하다. 하지만, 대출 요청자의 특성 상 은행에서 대출받는 사람들보다는 높은 연체율을 보이는 것이 사실이다. 따라서, 대출 요청 내용을 분석하여 연체나 부도가 발생하지 않을 대출을 선별하는 것이 중요하다. 본 논문에서는 렌딩 클럽 데이터를 이용하여 딥러닝 기법을 이용한 P2P 소셜 대출 채무자 부도 예측 모델을 개발하였다. 정확도를 높이기 위하여 전체 변수를 사용하고, 학습 속도를 높이기 위하여 계층적 오토 인코더로 특징을 추출하였다. 인공지능 기반 균등 부분 표본 추출로 데이터 클래스를 균일하게 하고, 다층 퍼셉트론을 이용하여 부도 예측을 수행하였다. 렌딩 클럽 데이터에 적용하여 정확도와 정밀도 모두 기존 방법보다 높은 성능을 보이는 것을 확인 할 수 있었다.

It is important for platform service providers and investors to find and invest in loan requests that do not cause delinquency or default. However, due to the characteristics of the loan requestor, it is true that the default rate is higher than those who are borrowed from the bank. Therefore, it is important to analyze the contents of the loan request to select the loans for which no delinquency or default will occur. In this paper, we developed a prediction model of P2P social loan debtor ""s default using deep learning method for lending club database. We used all parameters to increase the accuracy and extracted features using stacked auto encoder to increase learning speed. Using AI based balanced sub sampling the data class is uniformized and the default prediction is performed using the multi-layer perceptron. As a result of applying it to the lending club database, it was confirmed that both the accuracy and the precision outperforms other classifiers.","#딥러닝, #P2P 소셜대출, #대출 부도, #예측 모델, #이진 분류, #Deep Learning, #P2P Social Lending, #Lending Default, #Prediction Model, #Binary Classification"
딥러닝의 산업 적용을 위한 도메인 지식 기반 데이터 전처리 기술,2019.08,,
딥러닝을 통한 차등간격의 조향각 노드 결정에 의한 자율주행,2019.08,"In this work, an autonomous driving model using only one camera was implemented by combining a CNN (Convolutional Neural networks) and a YOLO (You Only Look Once) framework. Hyper-parameters in the structure were adjusted to improve driving performance. Autonomous driving in a corridor was performed by applying the improved model. An appropriate dropout and deep learning structure associated with non-uniform steering angle intervals as output is proposed. The proposed algorithm was implemented, and through experiments resulted in successful obstacle avoidance and stable driving.","#CNN (convolution neural network), #non-uniform steering angle intervals, #autonomous driving, #deep learning"
시각 장애인 가상현실 체험 환경을위한 딥러닝을 활용한 몰입형 보행 상호작용 설계,2019.07,"본 연구는 시각 장애인의 도보 적응을 위한 새로운 가상현실 체험 환경을 제안한다. 제안하는 가상현실 체험 환경의 핵심은 몰입형 보행 상호작용과 딥러닝 기반 점자 블록 인식으로 구성된다. 우선, 시각 장애인의 입장에서 현실적인 걷기 경험을 제공함을 목적으로 제자리 걸음을 감지하여 걷기를 판단하는 트래커 기반 걷기 처리과정과 시각 장애인의 보행 보조 도구를 가상현실에 적용한 컨트롤러 기반 VR 흰지팡이를 설계한다. 또한, VR 흰지팡이를 활용한 길 안내 과정에서 도로 위의 점자블록 인지및반응 등 종합적인의사결정을 수행하는 학습 모델을 제안한다. 이를 기반으로 가상현실 도보 체험 환경에 대한 실험을위하여 실외 도시 환경으로 구성된 가상현실 어플리케이션을 제작하고, 참가자를 대상으로 설문 실험 및 성능 분석을 진행하였다. 결과적으로 제안한 가상현실 체험 환경이 시각 장애인의 입장에서 현존감 높은 도보 체험을 제공하고 있음을 확인하였다. 그리고 제안한학습과 처리과정이인도와 차도, 인도 위의 점자 블록을 높은 정확도로 인지함을 확인하였다.

In this study, a novel virtual reality (VR) experience environment is proposed for enabling walking adaptation of visually impaired people. The core of proposed VR environment is based on immersive walking interactions and deep learning based braille blocks recognition. To provide a realistic walking experience from the perspective of visually impaired people, a tracker-based walking process is designed for determining the walking state by detecting marching in place, and a controller-based VR white cane is developed that serves as the walking assistance tool for visually impaired people. Additionally, a learning model is developed for conducting comprehensive decision-making by recognizing and responding to braille blocks situated on roads that are followed during the course of directions provided by the VR white cane. Based on the same, a VR application comprising an outdoor urban environment is designed for analyzing the VR walking environment experience. An experimental survey and performance analysis were also conducted for the participants. Obtained results corroborate that the proposed VR walking environment provides a presence of high-level walking experience from the perspective of visually impaired people. Furthermore, the results verify that the proposed learning algorithm and process can recognize braille blocks situated on sidewalks and roadways with high accuracy.","#몰입형 가상현실, #보행 상호작용, #딥러닝, #시각장애인, #immersive virtual reality, #walking interaction, #deep learning, #visually impaired people"
딥러닝 기반의 대퇴골 영역 분할을 위한 훈련 데이터 증강 연구,2019.07,"본 연구에서는 CT 영상의 대퇴골 부위를 해부학적으로 의미 있게 변형하여 CT 영상의 대퇴골 영역을 분할하기 위한 컨벌루션 신경망(CNN)의 훈련 데이터를 증강하는 방법을 제안한다. 먼저 CT 영상으로부터 삼차원 삼각형 대퇴골 메쉬를 얻는다. 그 후 메쉬의 국소부위에 대한 기하학적 특성을 계산하고, 군집화하여 메쉬를 의미 있는 부분들로 분할한다. 마지막으로, 분할한 부분들을 적절한 알고리즘으로 변형한 뒤, 이를 바탕으로 CT 영상을 와핑하여 새로운 CT영상을 생성하였다. 본 연구의 데이터 증강 방법을 이용하여 학습시킨 딥러닝 모델은 기하학적 변환이나 색상 변환 같이 일반적으로 사용되는 데이터 증강법과 비교하여 더 나은 영상분할 성능을 보인다.

In this study, we modified CT images of femoral head in consideration of anatomically meaningful structure, proposing the method to augment the training data of convolution Neural network for segmentation of femur mesh model. First, the femur mesh model is obtained from the CT image. Then divide the mesh model into meaningful parts by using cluster analysis on geometric characteristic of mesh surface. Finally, transform the segments by using an appropriate mesh deformation algorithm, then create new CT images by warping CT images accordingly. Deep learning models using the data enhancement methods of this study show better image division performance compared to data augmentation methods which have been commonly used, such as geometric conversion or color conversion.","#데이터 증강, #딥러닝, #의료영상, #영역 분할, #Data augmentation, #Deep learning, #Medical image, #Image segmentation"
딥러닝을 이용한 스마트 광고 디지털 사이니즈,2019.07,,"#디지털 사이니지(Digital Signage), #스마트 광고 재생(smart advertising display), #딥러닝(deep learning)"
딥러닝을 활용한 에지 컴퓨팅 기반의 지능형 컨스트럭션 영상 관제 시스템,2019.07,"인공지능 기술이 발달함에 따라 다양한 분야에서 인공지능을 적용하기 시작하였다. 특히, 산업계의 각 도메인 영역에서는 기존 서비스 형태에서 여러 가지 인공지능 기술을 적용하여 비용 절감이나 수익 창출하려는 시도가 많이 발생하고 있다. 지능형 컨스트럭션 영상 관제 시스템은 민원 발생시 현장에서의 소음, 진동, 가스수치 및 현장 영상을 최대한 신속하게 동기를 맞춰서 온라인으로 보여주는 지능형 사물인터넷 현장 라이브 모니터링 시스템이다. 본 논문에서는 지능형 에지 컴퓨팅 기반으로 클라우드에 저장되는 현장 영상이 오버플로우(overflow) 되는 것을 방지하기 위해 효율적으로 에지 노드에서 클라우드로 전송되는 트래픽을 자동으로 제어하는 시스템을 구현한다. 구현된 시스템으로 성능 측정 결과를 확인해 보았고, 동일한 서비스 품질을 유지하면서 기존 대비 10%이상 트래픽 사용 감소율을 보이는 성능 개선 효과가 있었다. 이 시스템을 소규모 건설 현장에 적용할 경우에 매달 수십 만원 정도 통신비용을 절감할 것으로 보인다.

With the development of artificial intelligence technology, artificial intelligence has begun to be applied in various fields. In particular, in each domain area of the industry, attempts are made to reduce costs or generate revenue by applying various artificial intelligence technologies in the existing service types. The intelligent construction video management system is an intelligent internet field live monitoring system that synchronizes noise, vibration, gas levels and on-site images at the site as quickly as possible and presents them online in the event of a civil complaint. Based on intelligent edge computing, this paper implements a system that automatically controls traffic transmitted from edge node to cloud efficiently in order to prevent overflow of field images stored in the cloud. Performance measurement results were checked with the implemented system and performance improvement was achieved with a traffic reduction rate of more than 10% compared to the previous one while maintaining the same quality of service. If the system is applied to small construction sites, it is expected to save some hundreds of thousands of won per month in communications costs.","#edge computing, #machine learning, #deep learning, #video management system, #supervised learning"
딥러닝 기술을 적용한 운전자 맞춤형 긴급자동제동 시스템 파라메터 추출,2019.08,"The autonomous emergency braking system is one of advanced driving assist systems. It is an advanced safety function designed to prevent collision with a forward vehicle or a pedestrian in the event of driver’s carelessness or a sudden accident ahead. Because the AEB stops the vehicle with a maximum deceleration command at the last possible time to brake so that collision avoidance is possible, it can prevent a collision with a preceding vehicle. However, there are risks of a secondary collision with a trailing vehicle and injury to a passenger due to sharp deceleration. In addition, sudden braking control can present a driving feeling gap to the driver. These problems must be solved because they can amplify a user""s rejection of automatic emergency braking (AEB) and negatively affect the acceptability of this technology. In this study, the driver""s braking propensity is derived by means of deep learning and it is applied to a customized AEB system to prevent secondary accidents caused by sudden braking and to improve user acceptance. In order to derive a driver""s braking behavior, normal driving data and stationary target based braking test data are collected. Utilizing a deep neural network, the driver’s braking profile during ordinary driving and a sudden stop are extracted. The correlation between the two extracted driver’s braking behaviors is analyzed. This provides the means to derive sudden braking behavior as a function of driving speed, leading to customized AEB parameters.","#customized autonomous emergency braking, #deep neural network, #braking propensity"
딥러닝으로 불경 읽기 - Word2Vec으로 CBETA 불경 데이터 읽기,2019.06,"본 연구는 CBETA(씨베타) 불경 데이터를 대상으로 딥러닝 방법인 Word2Vec(워드투벡)을 통해서 불경을 분석하고 시각화하는 방법을 탐색하고, 이를 토대로 인공지능이 불경을 읽는 방법의 장단점을 검토했다.
우선 인공지능에 대한 불교학 연구가 인공지능에 대한 비판의 측면에 집중되어 있는 현상을 제시하며, 인공지능을 활용한 불교학 연구를 제안하였다. 이를 위해서 Word2Vec을 통한 불경 분석의 이론적 배경과 분석 알고리즘을 서술하였다. 또한 불교학 연구자가 분석 결과를 탐색할 수 있는 방법을 제시하고, 이를 토대로 불교학 연구자가 분석 결과에 손쉽게 접근하여 사용할 수 있는 시각화 방안을 제시하였다.
마지막으로 인공지능 분석 방법의 장점으로 ‘넓게 보기’, ‘다르게 보기’, ‘디지털 학문 선순환’을 제시하였고, 단점으로 ‘형태적인 접근의 한계’, ‘설명 불가능한 인공지능’, ‘해석 불가능한 인공지능’의 문제를 서술하였다. 그리고 서술한 문제를 해결하는 방안으로 불교학의 지식과 사유를 디지털에 이식하기 위한 불교학 디지털 온톨로지를 제안하였다.

This study explored how to analyze and visualize the Buddhist scriptures using the deep learning method Word2Vec using CBETA data, and based on this, examined the advantages and disadvantages of how artificial intelligence read the Buddhist scriptures.
First of all, the Buddhist study on artificial intelligence presented a phenomenon focusing on the aspects of criticism on artificial intelligence, and proposed the study of Buddhism using artificial intelligence. To this end, the theoretical background and analysis algorithm of Buddhist scripture analysis through Word2Vec were described, the method by which Buddhist researchers could explore the analysis results was presented, and a visualization method was presented to enable Buddhist researchers to easily access and use the analysis results.
Finally, the strengths of artificial intelligence were ""broad view,"" ""different view,"" and ""digital academic development,"" while shortcoming was to describe the limitations of formative approach, unexplained artificial intelligence, and incomprehensible AI problems. And as a way to solve the problem described, I proposed a Buddhist study digital ontology to transplant Buddhist knowledge and manas to digital.","#불경, #인공지능, #딥러닝, #인공지능인문학, #디지털인문학, #디지털 불교학, #Buddhist scriptures, #Artificial intelligence, #deep learning, #artificial intelligence, #digital humanities, #digital Buddhism"
딥러닝 기반 SAR 영상 변화 탐지 기술 동향 Top 10%,2019.7,"SAR 영상의 해상도가 광학 영상만큼 높아짐에 따라, 기상 상황이나 밤낮에 관계없이 해당 지역의 영상 획득이 가능한 SAR 영상 기반 변화 탐지 기술에 대한 관심이 높아지고 있다. 전통적인 방식으로는 ACD(Amplitude Change Detection) 기반 변화 탐지 기법과 CCD(Coherence Change Detection) 기반 변화 탐지 기법이 주류를 이루었다. 그러나 기존 기법이 노이즈 제거, 변화 이미지를 생성하는 과정에서 데이터를 가공함으로써 원본 데이터의 손실을 가져오고, 이로 인해 변화 탐지 성능을 저하시키는 요인이 있었다. 최근에, 변화 탐지의 성능을 올리고 자동화가 가능한 딥러닝 기반 SAR 영상의 변화 탐지 연구가 시도되고 있다. 본 논문에서는 전통적인 SAR 영상 변화 탐지 기법과 딥러닝 기반 SAR 영상 변화 탐지 기법들에 대해 살펴 본다.

As the resolution of SAR images becomes as good as that of optical images, there is a growing interest in SAR image-based change detection techniques that can acquire images of the region regardless of weather conditions or day and night. Conventionally, change detection based on ACD (Amplitude Change Detection) and change detection based on CCD (Coherence Change Detection) have established the mainstream. However, the existing methods have the disadvantage that the original data is distorted by processing the data in the process of noise removal and change image generation so that the desired performance can not be shown. Recently, many efforts have been made to apply deep learning to SAR image change detection. This paper reviews the characteristics of SAR images and existing detection methods, and discuss recent SAR image detection methods based on deep learning.","#SAR(합성개구레이더), #Change Detection(변화 탐지), #ACD, #CCD, #Deep Learning(딥러닝)"
진동을 이용한 딥러닝 기반 구동장치 감속기 결함 분류 시스템,2019.07,,"#기계 결함 진단(Machine Fault Diagnosis), #기계 결함 분류(Machine Fault Classification), #딥러닝(Deep Learning)"
딥러닝 기반 어선조업종류 판별 방법,2019.07,,"#조업종류 판별(fishery classification), #선박자동식별장치(automatic identification system), #딥러닝(deep learning)"
전이학습과 딥러닝 네트워크를 활용한 고해상도 위성영상의 변화탐지,2019.6,"운용 가능한 위성의 수가 증가하고 기술이 진보함에 따라 영상정보의 성과물이 다양해지고 많은 양의 자료가 축적되고 있다. 본 연구에서는 기구축된 영상정보를 활용하여 부족한 훈련자료의 문제를 극복하고 딥러닝(deep learning) 기법의 장점을 활용하고자 전이학습과 변화탐지 네트워크를 활용한 고해상도 위성영상의 변화탐지를 수행하였다. 본 연구에서 활용한 딥러닝 네트워크는 공간 및 분광 정보를 추출하는 합성곱 레이어(convolutional layer)와 시계열 정보를 분석하는 합성곱 장단기 메모리 레이어(convolutional long short term memory layer)로 구성되었으며, 고해상도 다중분광 영상에 최적화된 정보를 추출하기 위하여 커널(kernel)의 차원에 따른 정확도를 비교하였다. 또한, 학습된 커널 정보를 활용하기 위하여 변화탐지 네트워크의 초기 합성곱 레이어를 고해상도 항공영상인 ISPRS (International Society for Photogrammetry and Remote Sensing) 데이터셋에서 추출된 40,000개의 패치로 학습된 값으로 초기화하였다. 다시기 KOMPSAT-3A (KOrean Multi-Purpose SATllite-3A) 영상에 대한 실험 결과, 전이학습과 딥러닝 네트워크를 활용할 경우 기복 변위 및 그림자 등으로 인한 변화에 덜 민감하게 반응하며 분류 항목이 달라진 지역의 변화를 보다 효과적으로 추출할 수 있었으며, 2차원 커널보다 3차원 커널을 사용할때 변화탐지의 정확도가 높았다. 3차원 커널은 공간 및 분광정보를 모두 고려하여 특징 맵(feature map)을 추출하기 때문에 고해상도 영상의 분류뿐만 아니라 변화탐지에도 효과적인 것을 확인하였다. 본 연구에서는 고해상도 위성영상의 변화탐지를 위한 전이학습과 딥러닝 기법의 활용 가능성을 제시하였으며, 추후 훈련된 변화탐지 네트워크를 새롭게 취득된 영상에 적용하는 연구를 수행하여 제안기법의 활용범위를 확장할 예정이다.

As the number of available satellites increases and technology advances, image information outputs are becoming increasingly diverse and a large amount of data is accumulating. In this study, we propose a change detection method for high-resolution satellite images that uses transfer learning and a deep learning network to overcome the limit caused by insufficient training data via the use of pre-trained information. The deep learning network used in this study comprises convolutional layers to extract the spatial and spectral information and convolutional long-short term memory layers to analyze the time series information. To use the learned information, the two initial convolutional layers of the change detection network are designed to use learned values from 40,000 patches of the ISPRS (International Society for Photogrammertry and Remote Sensing) dataset as initial values. In addition, 2D (2-Dimensional) and 3D (3-dimensional) kernels were used to find the optimized structure for the high-resolution satellite images. The experimental results for the KOMPSAT-3A (KOrean Multi-Purpose SATllite-3A) satellite images show that this change detection method can effectively extract changed/unchanged pixels but is less sensitive to changes due to shadow and relief displacements. In addition, the change detection accuracy of two sites was improved by using 3D kernels. This is because a 3D kernel can consider not only the spatial information but also the spectral information. This study indicates that we can effectively detect changes in high-resolution satellite images using the constructed image information and deep learning network. In future work, a pre-trained change detection network will be applied to newly obtained images to extend the scope of the application.","#High-resolution Satellite Images, #Change Detection, #Deep Learning, #Transfer Learning, #Fully Convolutional Layer, #Convolutional Long Short Term Memory Layer, #고해상도 위성영상, #변화탐지, #딥러닝, #전이학습, #완전 합성곱 레이어, #합성곱 장단기 메모리 레이어"
딥러닝을 이용한 화강암 X-ray CT 영상에서의 균열 검출에 관한 연구,2019.6,"본 연구에서는 화강암 시편에서 수압 파쇄법에 의해 생성된 미세균열의 3차원 형상을 X-ray CT 영상과 딥러닝을 이용하여 추출하였다. 실험으로 생성된 미세균열은 X-ray CT 영상 상에서 일반적인 영상처리 방법으로는 추출하기 매우 어렵고 육안으로만 관찰이 가능한 형태를 지닌다. 하지만 본 연구에서 제안한 합성곱 신경망(Convolutional neural network) 기반 인코더-디코더(Encoder-Decoder) 구조의 딥러닝 모델을 통해 미세균열을 정량적으로 추출할 수 있었다. 특히 픽셀 단위의 미세균열 추출을 위해 인코딩 과정에서 소실되는 정보를 디코딩 과정으로 직접 전달하는 디코더 모델을 제안하였다. 또한, 딥러닝 기반 신경망 학습에 필요한 데이터의 수를 증가시키기 위해 이미지의 분할(Division), 회전(Rotation), 그리고 반전(Flipping) 등으로 데이터를 생성하는 영상 증대 방법을 적용하였으며 이때 최적의 조합을 확인하였다. 최적의 영상 학습 데이터 증대 방법을 적용하였을 때 검증 데이터뿐만 아니라 테스트 데이터에서의 성능 향상을 확인하였다. 학습 데이터의 원본 개수가 딥러닝 기반 신경망의 균열 추출 성능에 미치는 영향을 확인하고 딥러닝 기술을 사용하여 성공적으로 미세균열을 추출하였다.

This study aims to extract a 3D image of micro-cracks generated by hydraulic fracturing tests, using the deep learning method and X-ray computed tomography images. The pixel-level cracks are difficult to be detected via conventional image processing methods, such as global thresholding, canny edge detection, and the region growing method. Thus, the convolutional neural network-based encoder-decoder network is adapted to extract and analyze the micro-crack quantitatively. The number of training data can be acquired by dividing, rotating, and flipping images and the optimum combination for the image augmentation method is verified. Application of the optimal image augmentation method shows enhanced performance for not only the validation dataset but also the test dataset. In addition, the influence of the original number of training data to the performance of the deep learning-based neural network is confirmed, and it leads to succeed the pixel-level crack detection.","#Granite, #Deep learning, #Crack detection, #Image augmentation, #화강암, #X-ray CT, #딥러닝, #균열추출, #영상 데이터 증대 기술"
딥러닝 분류기의 신뢰성을 향상 시키기위한 학습 방법,2019.7,,
딥러닝 알고리즘을 사용한 신장암 데이터의 분류,2019.07,,
딥러닝을 이용한 함정의 단기 전력부하 예측,2019.07,,
다중 잔차 방식의 딥러닝을 통한 태양광 발전량 단기 예측,2019.07,,
딥러닝를 사용한 온라인 게임에서의 욕설 탐지,2019.07,,"#욕설 탐지(abuse detection), #딥러닝(deep learning), #온라인 게임(online game), #콘볼루션 신경망(convolutional neural network)"
제조 혁신을 위한 딥러닝 활용,2019.06,,
어텐션 기반의 딥러닝 문서 분류 모델을 활용한 사용자 중심의 문서 레이블링 시스템,2019.07,,
실증 기반 딥러닝 영상분석 기술 제공을 위한 클라우드 기반 지능형 영상보안 플랫폼,2019.06,"딥러닝을 비롯한 인공기능과 영상처리 분야의 접목은 기존 물리보안의 기술적 한계를 뛰어넘어 새로운 기회의 장을 마련하고 있다. 하지만 딥러닝 기반 영상분석 기술도 지능형 영상감시가 필요한 실제 현장에서는 다양한 환경의 제약사항으로 인해 성능이 저하될 가능성이 높다. 본 논문에서는 실제 CCTV 환경의 영상 데이터를 확보하여 신경망을 이용한 지속적인 학습을 통해 영상분석의 성능을 개선하는 클라우드 기반 지능형 영상보안 플랫폼을 소개한다. 클라우드 기반 지능형 영상보안 플랫폼은 지자체 통합관제센터에서 수집한 CCTV 영상을 학습 데이터로 활용하여, 현장에서 신뢰받을 수 있는 사람 검출, 사람/차량 재식별, 열악 차량번호판 탐지 등의 지능형 영상분석 서비스를 제공할 수 있다.",
딥러닝 기반 얼굴인식 모델에 대한 변조 영역 제한 기만공격,2019.6,"최근 딥러닝 기술은 다양한 분야에서 놀라운 성능을 보여주고 있어 많은 서비스에 적용되고 있다. 얼굴인식 또한 딥러닝 기술을 접목하여 높은 수준으로 얼굴인식이 가능해졌다. 하지만 딥러닝 기술은 원본 이미지를 최소한으로 변조시켜 딥러닝 모델의 오인식을 발생시키는 적대적 예제에 취약하다. 이에 따라, 본 논문에서는 딥러닝 기반 얼굴인식 시스템에 대해 적대적 예제를 이용하여 기만공격 실험을 수행하였으며 실제 얼굴에 분장할 수 있는 영역을 고려하여 설정된 변조 영역에 따른 기만공격 성능을 분석한다.",
딥러닝 기반의 IDPS 탐지 데이터의 정/오탐 분류,2019.6,"딥러닝 기법이 영상 분야를 시작으로 여러 분야에서 빠르게 적용되고 있고, 관련된 다양한 연구도 함께 같이 발전하고 있다. 정보보안 분야 역시 악성코드를 위주로 다양한 데이터에 대해서 딥러닝 기법을 적용하기 위한 많은 연구들이 진행되고 있지만, 본 논문에서는 IDPS에서 탐지된 이벤트들에 대해서 정/오탐을 자동으로 식별할 수 있는 딥러닝 기반의 분류방법을 소개 하고자 한다.",
소음 진동 딥러닝 모델의 소프트맥스 컨피던스 비교를 통한 전동기 고장 진단에 관한 연구,2019.07,,
딥러닝을 활용한 금융상품 불완전 판매 판별 모델,2019.06,"펀드로 대표되는 금융상품은 판매직원의 설명과 권유가 절대적인 힘을 발휘하는 구조적 특성으로 인해 불완전판매 가능성을 내포하고 있으며, 이로 인한 사회적 갈등이 꾸준히 초래되고 있다. 본 논문에서는 텍스트로 변환된 상담 데이터에 딥러닝 기반 텍스트 분류 기법을 적용해 금융상품 불완전판매 여부를 판별하는 모델을 제안한다. 본 모델은 한글의 자소 단위의 토큰화 방법을 적용한 벡터화와 기존 컨볼루션과 순환 신경망을 이용한 분류 모델을 기반으로 한다. 특히, 두 명의 화자가 존재하는 상담 데이터의 특성을 감안해 화자 벡터를 추가 고려함으로써, 일반적인 딥러닝 텍스트 분류 기법 보다 매우 좋은 성능을 보임을 확인 하였다. 또한 실제 금융 산업에서 불완전판매 여부를 판별하기 위하여 사용되는 시나리오를 토대로 생성된 가공의 데이터를 사용한 실험 결과를 제시하여 본 모델의 실효성을 검증하였다.

Financial products represented by funds have structural characteristics, of which explanation and recommendation by sales associates, exert a major influence on customers’ purchasing decisions. So, there always exists the possibility of associates misselling financial products, resulting in chronic social conflicts between sales associates and customers. This paper proposes the discrimination model on misselling of financial products, using deep learning-based text classification, for converted customers’ call text data. The model is based on vectorization, which applies Hangeul’s character-level tokenization, and a classification method using CNN and RNN. Specifically, we have validated that the model shows much better performance, by including the speaker vector because there are two speakers in real customers’ call data. Also, we have validated effectiveness of the proposed model, by presenting experimental results which use generated synthetic data. Such data is based on real business cases, that are used to prevent misselling of financial products in the financial industry.","#금융상품 불완전 판매, #딥러닝, #컨볼루션 신경망, #순환 신경망, #misselling of financial products, #deep learning, #CNN, #RNN"
네트워크 분할기반 개인정보보호 분산의료 빅데이터 딥러닝 플랫폼,2019.06,본 논문에서는 하나의 딥러닝 모델에 분산된 각 의료기관에서 수집된 의료데이터를 모두 적용 하면서 개인정보를 보호할 수 있는 분산 딥러닝 기법을 제안한다. 기관별로 수집된 raw data를 공유하지 않고 딥러닝 모델의 훈련에 사용할 수 있도록 계층구조로 이루어진 딥러닝 모델의 레이어를 나누어 node인 기관과 서버에서 각각 계산해 기관별 의료데이터의 외부 반출 없이 딥러닝 모델을 훈련을 진행한다. 또한 본 논문에서는 분산된 의료기관들의 데이터를 모두 고려한 딥러닝 모델 훈련 과정에서 오버피팅이 일어나지 않도록 각 의료기관의 데이터양에 비례한 mini-batch 크기 선정 방식을 제안한다. 본 논문에서 제안하는 방식은 의료기관별로 수집된 의료데이터를 다른 node나 중앙서버와 공유하지 않기 때문에 개인정보보호가 보장되고 node에 요구되는 계산능력이나 네트워크의 대역폭 요구사항이 적으며 각 기관의 데이터 크기를 고려한 mini-batch 크기 선정을 통해 오버피팅을 예방한다.,
딥러닝 기반의 영상 분석 기술 동향 Top 5%,2019.7,"최근 인공신경망의 한계를 극복하기 위해 제안된 딥러닝을 사용한 데이터 분석 방식이 각광받고 있다. 딥러닝은 사람이 쉽게 구분하는 사물의 형태를 데이터화 하여 컴퓨터에 입력하고 여러 테스팅을 걸쳐 학습시키는 지도 학습 방식과 스스로 인지하여 학습하는 비지도 학습으로 구분된다. 이는 영상 처리 데이터를 인식 및 분류하는 알고리즘을 포함하고 있으며, ImageNet 영상 데이터를 기반으로 한 구조로 나뉜다. 본 동향지에서는 딥러닝 기반의 영상 처리 분석 기술 동향을 소개 및 서술한다. 이미지 분석 기술을 한국항공우주연구원의 방대한 위성 영상 데이터에 응용하면, 다양한 사용자의 요구사항을 충족시킬 수 있을 것으로 기대한다.

Recently, a method for data analysis using deep learning is widely used to overcome the limitations of artificial neural networks. Deep learning is classified into two types: Supervised learning method of inputting data that can be easily distinguished by a computer, unsupervised learning method by various tests and learning method by self-recognition. It includes algorithms for recognizing and categorizing image processing data and is divided into structures based on ImageNet image data. This paper explain trends based on in-depth image processing analysis techniques. It is expected to meet various user needs by applying image analysis technology to satellite image data of Korea Aerospace Research Institute(KARI).","#Machine Learning(기계 학습), #Deep Learning(심층 학습), #Supervised Learning(지도 학습), #Unsupervised Learning(비지도 학습), #영상 처리(Image Processing)"
딥러닝과 건축물의 에너지 관리,2019.06,,
딥러닝 기반 이미지 인식을 활용한 가상현실 어플리케이션 제작 공정,2019.07,,
딥러닝과 IoT 표준을 이용한 고소 작업자 행동분석 시스템,2019.07,,"#작업자 위험 행동 분석(Worker’s Risk behavior Analysis), #모비우스플랫폼Mobius Platform), #작업자 모니터링(Worker’s Monitoring)"
딥러닝 기반의 농산물 가격 예측 시스템에 대한 연구 Top 5%,2019.6,"본 논문은 딥러닝 기반의 농산물 가격 예측 시스템에서 농산물 가격정보를 이용한 강화학습 모델을 제안한다. 한국농수산식품유통공사 농산물유통정보(KAMIS)에서 제공하는 정보를 기반으로 기후정보를 적용하기에 부적합한 시설농작물을 대상으로 가격변동 정보를 수집한 후 제안 시스템에 적용하였다. 제안 시스템은 환경, 에이전트, 정책신경망과 정책학습기로 구성되었으며, 정책신경망은 LSTM 신경망을 적용하여 판매와 수급 행위에 대해 수익을 높일 수 있을지 확률을 계산한다. 제안 시스템을 이용하여 대상 농산물에 대하여 시뮬레이션한 결과 농산물 가격 변화와 비슷한 예측 결과를 보였으며 기존의 복잡한 농산물 가격 예측 기법과 비교하여 상당히 개선된 결과를 보였다.

This paper proposes a reinforcement learning model using agricultural price information as a deep learning-based agricultural price prediction system. Based on the information provided by KAMIS of the Korea Agro-Fisheries & Food Trade Corporation, information on price changes was collected and applied to the proposed system for the facilities crops that are not suitable for applying climate information. The proposed system consists of the environment, agents, policy neural networks and policy learners, which apply the LSTM neural network to calculate the probability of increasing revenue for sales and supply and demand activities. The simulation of the target agricultural products using the proposed system showed similar prediction results to the change of agricultural prices and showed a significant improvement compared to the existing complex agricultural price prediction techniques.","#agricultural price prediction system, #deep learning, #reinforcement learning, #KAMIS"
딥러닝을 이용한 신 강화학습 기반의 에너지 저장장치 이윤 최적화,2019.07,,
딥러닝 기법을 이용한 단기 전력수요 예측모델 비교 분석,2019.07,,
딥러닝을 활용한 PMSM의 감자고장 진단,2019.07,,
딥러닝 네트워크 축소,2019.07,,
딥러닝 기반의 라이다 오도메트리 추정기법,2019.07,,
스카핑 슬라브의 결함 검출 자동화를 위한 딥러닝 연구,2019.07,,
집단지성 기반 딥러닝용 데이터 셋 구축을 위한 이미지 라벨링 게임 어플리케이션,2019.06,,
딥러닝 모델의 입력 데이터 변형에 따른 유사 식물 잎 분류 성능 분석,2019.06,"In this paper, we propose a method for extracting leaf images from high-quality images to obtain efficient data for classification of plant leaves using deep-learning. And we analyze the performance of classification according to extraction and transformation method of leaf image data. Experimental results show that the method of extracting leaf area from rectangle to square or rectangle from original image is more accurate than cutting rectangle according to leaf shape and performing padding with basic image processing. In addition, the method of cutting the original image with the background as a square has a slightly higher accuracy than the method of cutting into a rectangle.",
대장암 종양 분류를 위한 딥러닝 모델 연구,2019.06,,
딥러닝 컴파일러 성능비교,2019.06,,
딥러닝을 활용한 퍼징 시드 파일 생성 기법,2019.6,,
제로에너지 구축을 위한 딥러닝 기반 에너지 데이터 분석 시스템 설계,2019.06,,
끓는 물 감지를 위한 딥러닝 기법 비교 연구,2019.06,,
초음파 영상의 딥러닝 영상분할에서 스페클 노이즈 제거 필터의 적용이 분할 정확도에 미치는 영향에 대한 연구,2019.06,,
깊이 예측 백본 네트워크 모델을 사용한 새로운 딥러닝 기반 객체 검출 방법,2019.06,,
주행 환경 인지를 위한 Multi-Task 딥러닝 모델 학습 툴 개발,2019.06,,
딥러닝을 이용한 시계열데이터 군집화,2019.06,"Purpose: This paper presents the clustering results of time series multiple sensor data using deep neural networks based unsupervised learning algorithm without target variables.
Methods: Time series data collected from multiple sensors were clustered using two clustering algorithms based on deep learning: Deep Embedding Clustering (DEC) and Jointly Deep Embedding Clustering (JDEC). DEC and JDEC are designed based on the autoencoder and the convolutional neural network, which are representative neural network structures. They allow highdimensional data to be represented by low-dimensional data and clustered based on their corresponding low-dimensional values.
Results: Two data sets, real time series data collected from manufacturing processes and simulated data, were used in the experiments. The simulated data’s performance was evaluated for accuracy, while the clustering performance of the real data was visually evaluated by mapping data and their clusters into a two-dimensional space. The experimental results show that the proposed methods were more accurate than K-means clustering.
Conclusion: Real time series data collected from manufacturing processes and simulated data were analyzed and meaningful clustering results were obtained. The proposed methods enabled the unsupervised learning of time series multiple sensor data without target variables by a deep neural network and showed good clustering performance.","#Deep Learning, #Deep Embedding Clustering, #Time Series Data"
뇌파분석과 딥러닝을 이용한 브랜드 이미지 분석에 관한 연구,2019.07,,"#Brand Image, #Latent demand, #Potential Consumer, #Machine Learning, #Deep Learning, #EEG, #Bran Wave"
고품질 의료 증거문헌 추출을 위한 TF-IDF 및 딥러닝 기반 텍스트 분류 및 처리 기법,2019.06,,
적대적 생성 신경망을 이용한 딥러닝 기반 TTS 음질 개선,2019.06,,
유사 영상 거칠기와 공간잡음 비용함수를 이용한 딥러닝 신경망 장면 기반 불균일보정,2019.06,"In this paper, a new Scene-based Nonuniformity Correction (SBNUC) method is proposed by applying Image Roughness-like and Spatial Noise cost functions on deep neural network structure. The classic approaches for nonuniformity correction require generally plenty of sequential image data sets to acquire accurate image correction offset coefficients. The proposed method, however, is able to estimate offset from only a couple of images powered by the characteristic of deep neural network scheme. The real world SWIR image set is applied　to verify the performance of proposed method and the result shows that image quality improvement of PSNR 70.3dB (maximum) is achieved. This is about 8.0dB more than the improved IRLMS algorithm which preliminarily requires precise image registration process on consecutive image frames.","#Deep Neural Network, #Image Roughness-like, #SN, #SBNUC, #Improved IRLMS"
장단기 교통흐름 예측을 위한 딥러닝 LSTM 신경망,2019.06,,
딥러닝 기반 모델을 활용한 국내 경제뉴스 제목 내 인용 형태 분류 및 뉴스의 의견성 분석,2019.06,,
딥러닝을 활용한 정부 R&D 기업지원효과 예측 분석,2019.05,"정부 R&D 지원은 기업의 매출액 증가, 고용 증가, R&D 투자 증가 등의 정책효과를 가져오는 것으로 알려져 있지만 기업의 특성에 따라 그 효과는 유의하지 않거나 부(-)의 효과를 가지기도 한다. 특히 많은 수의 기업들이 정부 지원을 받지 않은 유사 대조군 기업들에 비하여 기업 성과가 낮으며, 수혜효과의 이질성이 높게 나타나고 있어, 각 기업 지원에 대한 개별적 사전적 예측의 필요성이 제기되고 있다.
본 연구에서는 국가연구개발사업 정보와 기업 정보를 바탕으로 기업지원 효과에 대해 사전 예측하는 딥러닝 모형의 개발 가능성을 탐색하였다. 먼저 PSM 방법론을 활용하여 정부 R&D 미수혜기업 대비 수혜기업의 매출액, R&D투자, 고용지표에 대한 정책효과를 산출하였으며, 이 분석 결과를 기반으로 딥러닝 모형을 학습시켜 기업지원 효과를 예측하는 모형을 구현하였다.
딥러닝 모형의 예측성능 및 특징을 분석한 결과 딥러닝 모형은 적절한 수혜기업 선정에 기여할 수 있는 성능 특성을 가진 것으로 나타났다. 정책효과를 양수와 음수로 구분하였을 때 학습에 사용되지 않은 테스트 데이터를 기준으로 60%~77% 가량의 예측 정확도를 가지는 것으로 나타났다. 로짓모형을 통한 분석과 비교하였을 때, 예측정확도 면에서 향상되었을 뿐 아니라 긍정편향적 예측 특성이 크게 개선되었으며 보다 넓은 기업군에 대해 예측을 수행 가능 한 것으로 나타났다. 딥러닝에 기반한 R&D 수혜기업 선정 모형은 작동 가능성과 적용필요성이 높으며, 효율적이고 객관적인 선정 평가에 기여할 수 있을 것으로 보인다.

We explored the possibility of developing a deep learning model that predicts the effects of enterprise support based on national R&D project information and company information. As a result of applying the deep learning model, it was found that the deep learning has a performance characteristic that can contribute to improve the accuracy of proper company selection. When the policy effect is divided into positive and negative, it has a prediction accuracy of 60% ~ 77% based on test data not used for learning. As a result of this study, the R&D beneficiary selection model based on the deep learning technique has high operability and application necessity","#중소기업 R&D, #기업지원효과, #선정평가, #예측모형, #딥러닝, #SME, #R&D support, #selection model, #prediction, #deep learning"
딥러닝을 이용한 번호판 검출과 인식 알고리즘 Top 10%,2019.06,"최근 지능형 교통관제 시스템에 관한 다양한 연구가 진행되고 있는 가운데 번호판 검출과 인식 알고리즘은 가장 중요한 요소 중에 하나로 대두되고 있다. 번호판은 차량의 고유 식별값을 가지고 있기 때문이다. 기존의 차량 통행 관제 시스템은 정차를 기반으로 하고 있으며 차량의 입출입 인식 방법으로 루프 코일을 사용하고 있다. 이러한 방법은 교통 정체를 유발하고 유지보수 비용이 상승하는 단점을 가지고 있다. 본 논문에서는 이러한 문제점을 해결하기 위해서 차량의 입출입 인식 방법으로 카메라 영상을 사용한다. 차량 통행 관제 시스템의 특성상 카메라가 고정되어 있다. 이에 차량이 접근하면 카메라의 배경화면이 달라진다. 이 특징을 이용하여 배경화면의 차분영상을 구하면 차량의 입출입을 인식할 수 있다. 입출입 인식 후 한국 번호판의 형태학적 특성을 이용하여 후보 이미지를 추정한다. 그리고 선형 SVM(Support Vector Machine)을 이용해서 최종 번호판을 검출한다. 검출한 번호판의 글자와 숫자 인식 방법으로는 CNN(Convolutional Neural Network) 알고리즘을 사용한다. 제안한 알고리즘은 기존의 시스템과 달리 검출 위치를 기준으로 글자와 숫자를 인식하기 때문에 번호판의 규격이 변해도 인식할 수 있다. 실험한 결과 기존의 번호판 인식 알고리즘들 보다 제안한 알고리즘이 더 높은 인식률을 가진다.

One of the most important research topics on intelligent transportation systems in recent years is detecting and recognizing a license plate. The license plate has a unique identification data on vehicle information. The existing vehicle traffic control system is based on a stop and uses a loop coil as a method of vehicle entrance/exit recognition. The method has the disadvantage of causing traffic jams and rising maintenance costs. We propose to exploit differential image of camera background instead of loop coil as an entrance/exit recognition method of vehicles. After entrance/exit recognition, we detect the candidate images of license plate using the morphological characteristics. The license plate can finally be detected using SVM(Support Vector Machine). Letter and numbers of the detected license plate are recognized using CNN(Convolutional Neural Network). The experimental results show that the proposed algorithm has a higher recognition rate than the existing license plate recognition algorithm.","#License Plate, #SVM, #Machine Learning, #Deep Learning, #Intelligent Transportation System"
딥러닝 분석을 이용한 미세먼지 농도 예측에 관한 연구,2019.06,"In this paper, we try to predict the fine dust concentration and analyze the fine dust trend using the deep running. In this paper, a prediction model of fine dust concentration was developed and analyzed considering that the weather such as wind direction, wind speed, temperature, humidity, air pressure affects the fine dust concentration. Since the fine dust concentration has a time series characteristic, it is modeled using RNN. This study was conducted using tensorflow.",
딥러닝 기반 의류 영역 제안 네트워크를 결합한 패션 이미지 검색,2019.06,,
"딥러닝을 이용한 한국어 띄어쓰기 및 품사 태깅, 의존 구문 분석 통합 모델",2019.06,,
실시간 영상에서 딥러닝 기반 차량 번호판 인식을 위한 이상탐지,2019.06,,
딥러닝 기반 사용자 행동 분석 스마트조명,2019.06,,
병변 정보기반 피부병변 영상의 중증도 분류를 위한 딥러닝 알고리즘,2019.06,,
딥러닝을 이용한 X-ray 이미지에서의 허파 병변 여부 인식,2019.06,,
C-LSTM 딥러닝기반 굴삭기 작업동작 분류모델,2019.06,,
딥러닝 기반 Screw 체결 유무 비전 검사 정확도 향상,2019.06,,
딥러닝 어플리케이션에서 리프레시 에너지 절감을 위한 비트 전치 유닛 기반의 근사 메모리 아키텍처,2019.06,,
딥러닝을 이용한 Flexible OLED 결함 검출에 관한 연구,2019.06,,
수중 센서 네트워크를 위한 딥러닝 기반 링크 적응 방안,2019.06,,
딥러닝 기반 공간변화 예측모형의 개발과 활용,2019.6,,
딥러닝 기반의 미세먼지 농도 예측,2019.6,,
스마트 시티 미세먼지 예측을 위한 딥러닝 모델 분석,2019.06,,
GAN 구조의 딥러닝을 사용한 방사선 디텍터의 화소 결함 보정,2019.06,"Flat-panel radiography detectors employ TFT(thin film transistor) panels to acquire high-quality X-ray images. Pixel defects in TFT panel can degrade the image quality and lower the production yield of the panel, ultimately increasing the production cost. Hence, developing an appropriate correction algorithm has been conducted to improve the yield. Current algorithms are based on statistical learning and optimizing their performances is difficult especially for image edge parts. In this paper, we propose a pixel-defect correction algorithm based on a GAN (generative adversarial networks) deep learning structure. The proposed algorithm showed better performance than those of the conventional methods for practical x-ray images acquired from general radiography detectors.",
딥러닝 기반 운전자 시선 추적에 관한 기존 연구 분석,2019.06,,
딥러닝 기반 시간별 옷 색상 선호도분류 시스템에 대한 연구,2019.6,,
딥러닝 기반 배터리 잔여 시간 경고 알고리즘 연구,2019.06,,
확률모형과 딥러닝모형 기반의 전력 소모예측 시스템,2019.06,,
MERL BRDF 데이터셋을 활용한 딥러닝 기반의 재료 영역 분할 기법,2019.06,,
지도 가독성 향상을 위한 딥러닝 활용 방안 연구,2019.06,,
딥러닝 방식의 채널 추정을 위한 분류방법,2019.06,,
전신마비 환자를 위한 딥러닝 기반 시선 추적 휠체어 설계,2019.06,,
딥러닝기반 히트펌프 시스템의 냉매 충전량 예측,2019.06,"A proper refrigerant charge amount (RCA) plays an important role in the effective operation of the heat pump systems and contributes positively to reduction of energy consumption. With the commercialization of heat pump systems, predicting RCA is of great necessity for ultimate operation performance. In recent years, data-driven artificial neural network (ANN) techniques have been used for efficient prediction of RCA. In this study, a deep learning-based RCA prediction model was developed using the variables measured under various conditions in a heat pump system. The developed predictive model has the reliable root mean square error (RMSE) and the coefficient of determination (R2) value of 0.9571. In addition, the predicted values were estimated to be fairly close to the measured values, and statistical significance was also confirmed.","#Refrigerant charge amount(냉매 충전량), #Artificial neural network(인공신경망), #Deep learning(딥러닝)"
Distillation 을 활용한 압축된 딥러닝 기반 초해상도 기법,2019.06,,
위치 정보 및 건물 특성 정보를 활용한 딥러닝 기반 건물 객체 인식 정확도 향상 방법에 관한 연구,2019.06,,
딥러닝 기반 동영상 내 사람 영역 추출 방법,2019.06,,
컨볼루션 계층 수에 따른 딥러닝 기반 카메라 판별 성능 분석,2019.06,,"#Camera identification, #Convolution neural network"
임베디드 시스템을 위한 딥러닝 모델 경량화,2019.06,,
딥러닝을 이용한 경치와 햇빛 정보에 기반한 투어버스 좌석선택,2019.6,,
지능 사물로 구성된 스마트 공간에서 딥러닝 기법을 활용하여 다수 사용자로 구성된 테스크 분석,2019.06,,
분산 딥러닝을 위한 연합학습(Federated Learning) 플랫폼 연구 동향 및 응용,2019.06,,
멀티모달 접근을 통한 딥러닝 기반 감정인식 알고리즘,2019.6,,
드론을 이용한 딥러닝 기반 식물 이상 탐지 시스템,2019.06,,
딥러닝을 이용한 이미지 상표 자동 제거 시스템,2019.06,,
휘도 및 색차 성분에 따른 딥러닝 기반 SHVC 계층간 참조 픽처 생성 방법의 부호화 성능 분석,2019.06,,
머신러닝에서 특성 생성 자동화를 위한 딥러닝 활용,2019.06,,"#머신러닝, #딥러닝, #트랜잭션 데이터, #Feature Engineering, #자동화된 특성추출"
잡음환경에 딥러닝 기반 입술 동작 인식,2019.06,,"#Lip movement, #shape from focus, #artificial neural networks, #noisy environments"
딥러닝을 이용한 인공위성영상의 토지피복지도 생성기술,2019.06,,
진폭과 위상을 이용한 딥러닝 기반의 홀로그램 생성,2019.06,,
딥러닝 기반 눈과 입을 검출을 통한 운전자 상태 정보 추출,2019.06,,
멀티모달 딥러닝을 위한 기침 소리와 가속도 데이터의 결합 표현,2019.06,,
페이딩 무선통신 채널을 위한 딥러닝 네트워크 기반 무선통신 모뎀 설계기법 연구,2019.06,,
딥러닝을 이용한 주파수 도약 확산 스펙트럼 신호 제원 인식,2019.06,,
딥러닝을 이용한 인지 무선 네트워크의 스펙트럼 예측 방안,2019.06,,
딥러닝 기반의 회전에 강인한 텍스트 검출 기법,2019.06,,
현실 환경에서 증강현실과 딥러닝을 활용한 M&S 모델 증강가시화,2019.06,"This paper proposes a new method to effectively visualize modeling & simulation (M&S) results in a real environment using augmented reality (AR) and deep learning. The proposed approach makes it possible to dynamically generate an M&S analysis space of the real environment, to recognize real objects by using a deep learning technique, and to place the analyzed M&S results onto them. In order to construct an M&S space dynamically, we perform area learning on the real space using a smart device supporting RGB-D camera. In addition, real objects are recognized through deep learning-based object detection. Spatial mapping and user interaction are conducted to match the recognized real object with corresponding M&S model in the mobile AR environment. A proof-of-concept system was developed to show the advantage and feasibility of the proposed method. Therefore, the proposed approach can be used for seamlessly integrating M&S models into various real spaces and for reviewing M&S results more consistently and effectively.","#Modeling & Simulation (M&S), #Augmented reality, #Deep learning, #Visual augmentation"
국가공간정보로 학습시킨 딥러닝 모델을 이용한 드론 영상 의미론적 분할,2019.05,"소형 저가 소비자용 드론은 기술적으로 매우 빠르게 발전하고 있어 새로운 공간정보 구축 수단으로 주목받고 있다. 드론으로 취득한 대규모·다시기 영상을 효율적으로 활용하기 위해서 드론 영상의 취득·처리와 더불어 자동 분석도 아주 중요하다. 자동 분석의 핵심 과정으로 의미론적 분할은 특히 변화탐지와 객체추출을 위해 필수적이다. 이에 본 연구에서는 의미론적 분할을 수행하는 딥러닝 모델을 학습시키고 성능을 평가한다. 특히, 학습 데이터 구축에 있어 신규로 수작업으로 라벨링을 수행하지 않고, 한국의 지리적 맥락에 부합하는 기구축된 국가공간정보를 활용하였다. 정사영상, 실감정사영상, 연속수치지형도(건물 및 도로 레이어)를 활용해서 SegNet, PSPNet을 학습시켜 의미론적 분할을 수행하였다. 의미론적 분할에 있어서 기구축된 공간정보 만을 활용해서도 최대 86% 정확도를 성취할 수 있었다. 이를 바탕으로 시험 대상 지역의 신규 드론 모자이크 정사영상에 적용하여 효과적으로 건물을 탐지할 수 있었다. 국가공간정보를 딥러닝 모델 학습에 효과적으로 사용할 수 있었고, 이를 바탕으로 향후 변화탐지와 객체추출 등 공간정보 자동생성에 기여할 수 있을 것으로 기대한다.

Small, low-cost consumer drones have been attracting attention as a means of building new spatial information because they are technologically advanced very quickly. In order to efficiently utilize the large number of images acquired by the drone at different times, automatic analysis as well as acquisition · processing of the drones images are also very important. Semantic segmentation a key process of automatic analysis is especially necessary for change detection and object extraction. In this study, we train the deep learning model that performs semantic segmentation and evaluate the performance. In particular, we did not perform manual labeling for preparing training data, but utilized the pre-built national geospatial information that meets the geographical context of Korea. We performed semantic segmentation by training SegNet and PSPNet using general orthoimages, true orthoimages, and continuous digital maps (building and road layers). In terms of semantic segmentation, we could achieve maximum 86% accuracy using only the pre-built geospatial information. Based on this, it was able to effectively detect buildings by applying it to the new drone mosaic orthographic images of the test area. It is expected that the national geospatial information can be effectively used for training the deep learning models and contribute to automatic generation of geospatial information including change detection and object extraction in the future.","#의미론적 분할, #건물 탐지, #정사영상, #실감정사영상, #연속수치지형도, #Semantic Segmentation, #Building Detection, #Ortho-images, #True Ortho-images, #Continuous Digital Map"
항공사진을 이용한 딥러닝 기반 건물객체의 자동추출 실증연구,2019.05,"본 연구는 대전지역의 항공사진과 딥러닝 기법을 활용해 주거용 건물(단독주택 및 그 외 건물)의 자동추출 가능성을 확인하고자 하였다. 먼저, 영상 객체추출에서 성능이 검증된 Deep U-net과 DeepLab V3+ 기법을 후보로 선정해 훈련셋으로 학습시키고 모델별 학습 소요시간을 평가하였다. 다음은 검증셋에 의한 정확도 결과와 학습 소요시간을 고려해 더 우수한 성능을 나타낸 Deep U-net을 시험셋을 위한 평가 모델로 최종 선정하였다. Deep U-net 모델에 시험셋을 적용한 결과 단독주택과 그 외 건물의 추출결과가 각각 76.1%와 89.1%의 정확도로 도출되었다. 본 연구의 결과는 국토에 대한 상시 모니터링이 국토전역에 대한 동일시점의 시계열 데이터의 지속적 축적에서부터 시작한다고 볼때 비용 효과적이고 효율적인 모니터링에 기초가 될 것으로 기대된다. 특히, 환경부가 스크린 디지타이징을 통한 세분류 토지피복도 제작에서 단독주거시설의 분류정확도(76.9%)와 유사한 결과를 나타내 향후 추가적인 연구를 통해 딥러닝 기법을 활용한 토지피복분류 자동화를 위한 기초연구가 될 것으로 기대된다.",
딥러닝 기반 프린터 판별 기술,2019.06,,"#Printer identification, #Convolution neural network"
딥러닝을 이용한 선형 설계 초기 단계에서의 저항 추정,2019.06,"The initial ship design starts from a parent ship. A designer selects a suitable parent ship and modifies the hull shape for a new design. When a ship is modified, the hydrodynamic analysis such as numerical analysis, computational fluid dynamics analysis, model test, etc. is conducted, and the shape of the ship hull is changed according to the analysis results. This iteration continues until the owner’s, and Class requirements are met. During this process, it takes much time and high cost. In this paper, a deep learning model that can estimate the resistance of a ship using offset data is proposed, so that the most suitable candidate hull shape can be selected without taking much time and cost in the initial design stage. The normalization and early stopping methods are used in training to get the best training result. Also, the hyperparameter tuning is conducted for the best accuracy of the proposed model. The accuracy of the proposed model is verified using the test data set, and it is confirmed that the resistance of a ship can be estimated using deep learning.","#Deep learning, #Initial ship hull design, #Numerical analysis, #Resistance estimation"
딥러닝 기반 영상 주행기록계와 단안 깊이 추정 및 기술을 위한 벤치마크,2019.06,"This paper presents a new benchmark system for visual odometry (VO) and monocular depth estimation (MDE). As deep learning has become a key technology in computer vision, many researchers are trying to apply deep learning to VO and MDE. Just a couple of years ago, they were independently studied in a supervised way, but now they are coupled and trained together in an unsupervised way. However, before designing fancy models and losses, we have to customize datasets to use them for training and testing. After training, the model has to be compared with the existing models, which is also a huge burden. The benchmark provides input dataset ready-to-use for VO and MDE research in ‘tfrecords’ format and output dataset that includes model checkpoints and inference results of the existing models. It also provides various tools for data formatting, training, and evaluation. In the experiments, the exsiting models were evaluated to verify their performances presented in the corresponding papers and we found that the evaluation result is inferior to the presented performances.","#Visual Odomtery, #Monocualr Depth Estimation, #Deep Learning"
딥러닝을 이용한 공압형 인공근육의 동적 특성 추정,2019.05,,"#Deep Learning(딥러닝), #Pneumatic Artificial Muscle(공압형 인공근육), #Recurrent Neural Network(순환신경망), #Hysteresis(히스테리시스)"
딥러닝 기반 위성영상 건물 분류에 관한 연구,2019.05,,
제한 센서를 이용한 딥러닝 기반의 트러스 구조물 손상 탐지,2019.05,,"#Damage Detection, #Truss Structures, #Limited Sensors, #Deep Learning, #DNN"
SHVC 부호화 성능 개선을 위한 딥러닝 기반 계층간 참조 픽처 생성 방법,2019.05,"본 논문에서는 SHVC 부호화 성능 개선을 위하여 딥러닝 기반 계층간 예측을 위한 참조 픽처 생성 방법을 제안한다. 새로운 참조픽처를 생성하기 위하여 DCT-IF기반 업샘플링 된 픽처를 VDSR 네트워크를 이용한 필터링을 진행하는 구조와 SHVC 계층간 참조픽처를 생성하기 위한 트레이닝 방법에 대해 설명한다. 제안하는 방법은 SHM 12.0 기반으로 구현되어 있다. 성능 평가를 위하여 사전 학습을 이용하여 계층간 예측 픽처를 생성하는 방법과 비교를 진행하였다. 그 결과 상위 계층의 부호화 성능은 사전 학습을 이용한 방법 대비 최대 13.14%의 비트 감소, SHM 대비 최대 15.39%의 비트 감소율을 보였고, 평균 6.46%의 비트 감소율을 보였다.

In this paper, we propose a reference picture generation method for Inter-layer prediction based deep learning to improve the SHVC coding performance. A description will be given of a structure for performing filtering using a VDSR network on a DCT-IF based upsampled picture to generate a new reference picture and a training method for generating a reference picture between SHVC Inter-layer. The proposed method is implemented based on SHM 12.0. In order to evaluate the performance, we compare the method of generating Inter-layer predictor by applying dictionary learning. As a result, the coding performance of the enhancement layer showed a bitrate reduction of up to 13.14% compared to the method using dictionary learning, a bitrate reduction of up to 15.39% compared to SHM, and a bitrate reduction of 6.46% on average.","#Scalable HEVC, #CNN, Deep learning, #Super resolution, #Inter-layer prediction"
딥러닝 학습을 위한 적외선 영상 생성 기법 연구,2019.05,,"#Infrared(적외선), #Deep Learning(심층학습), #Conjugate Heat Transfer Analysis(복합열해석), #Computer Vision(컴퓨터비전), #Synthetic Data Set(합성 데이터셋)"
시각장애인을 위한 딥러닝 기반 인물 위주 이미지 캡션 방법,2019.5,"본 논문에서는 영상의 시각적인 정보를 딥러닝을 이용하여 시각장애인들에게 영상 내 등장인물과 배경을 인식하여 제공하는 시스템을 제안한다. 시각장애인들은 드라마, 영화, 광고 등 영상에서 장소, 행위, 등장인물 등 영상에 나타나는 시각적인 정보들을 제한적으로 시청하고 있어 시각적인 정보들을 화면해설방송을 사용하여 얻고 있다. 하지만 화면해설방송은 화면해설작가가 영상 정보를 수집하여 대본을 쓴 뒤 성우가 녹음을 진행하고, 화면해설 전문엔지니어가 영상 작업을 해야만 시청이 가능한 불편함을 갖는다. 이를 개선하고자 히스토그램을 이용하여 영상을 자동으로 분할하고, 등장인물들은 CNN을 이용하여 인물 별로 학습시킨 후 분류하며, 영상의 이미지를 MSCOCO 데이터 셋을 이용하여 학습시켜 이미지에 대한 행동, 배경들을 묘사한 정보를 이미지 캡션을 한다. 위의 결과를 통해 얻어진 이미지 캡션 결과에 대해서 20대 이상의 성인을 대상으로 영상내의 시각적인 정보와 비교하는 정성적 평가를 진행함으로서 시각장애인들에게 시각적인 영상 정보를 제공함을 확인할 수 있다.

In this paper, we propose a system for visually impaired people to recognize visual characters and background in visual images by using deep learning. For people with visual impaired, since there is a limitation to viewing visual information such as place, action, character, etc. that appear in the video such as drama, movie or advertisement, they can only get those visual information from the Descriptive Video Service(DVS). However, screen commentary broadcasts are inconvenienced when the screenwriter collects the video information and writes the script, and the voice actor carries out the recording and the professional engineer of the screen commentary performs the video work. To improve this, the image is automatically segmented using the histogram, the characters are learned and classified by the person using CNN, and the image of the image is learned using the MSCOCO data set to describe the behavior and background of the image Captures image information. The image caption obtained from the above results can be confirmed to provide visual image information to the visually impaired by carrying out a qualitative evaluation comparing with the visual information in the image of the adult over 20 persons.","#Blind, #Face Recognition, #Image Captioning, #Image segmentation, #DVS"
딥러닝을 이용한 공압방식 연속체 로봇 말단장치의 자세추정,2019.05,,
데이터 증강을 이용한 딥러닝 기반 주가 패턴 예측,2019.06,,"#Stock Price Patterns, #Deep Learning, #Stock Price, #Convolutional Neural Network, #Data Augmentation"
딥러닝기술을 이용한 저항점용접 불량 판별 연구,2019.06,"Projection welding is a modification of spot welding. In this process, the weld is localized by means of raised sections, or projections, on one or both of the workpieces to be joined. In this study, we propose a method to detect welding defects that can occur during projection welding. A recurrent neural network model was used to determine weld defects. The current and voltage data were used as the input variables of the recurrent neural network, and the normal and defective welds were defined as output variables and expressed using one-hot-encoding method. Through this study, it is verified that it is possible to determine weld defect using deep learning.","#Deep neural network, #Recurrent neural network, #Resistance welding"
딥러닝 알고리즘 기반기술의 스마트 정보 활성화 방안에 관한 연구,2019.4,"4차 산업혁명은 컴퓨터의 인공지능을 높일 수 있는 딥러닝 알고리즘을 개발하여 사용하고 있으며, 심층신경망 구현을 위해 인간 두뇌의 연결성을 모방하여 데이터 세트를 분류하고 데이터 간의 상관관계를 찾게 된다. 딥러닝 알고리즘 활용의 인공지능 기술은 스스로 자기가 학습할 수 있는 능력을 갖추는 기술이 핵심이며, 인공지능과 사물센서 기술이 융합된 마지막 산업혁명이다.
그동안 단편적인 기술 적용으로 성장해왔던 제조업이 새로운 성장 패러다임으로 바뀌고 있으며, 최첨단 기술들이 계속 발전되어 상품화 되고 있다. 그러므로 사용자가 원하는 조건의 딥러닝 알고리즘 기반의 사물인식 모델 및 하이퍼 파라미터를 통계에 기반하여 자동으로 선정할 수 있는 플랫폼 등이 개발되어야 한다.
본 연구는 딥러닝 알고리즘의 기술적 방향의 제시보다는 실무적 관점에서 살펴본 후, 향후의 해석적 기초를 제시하고자 한다.

The 4th Industrial Revolution has developed a deep learning algorithm that can enhance the artificial intelligence of computers and for the implementation of the neural network, we classify the data sets by mimicking the connectivity of the human brain and find the correlation between the data. The technology that has the ability to learn on its own is the core of artificial intelligence technology that utilizes the deep learning algorithm and it is the last industrial revolution that combines artificial intelligence and object sensor technology.
Manufacturing which has grown from application of fragmentary technology is changing to a new growth paradigm and State-of-the-art technologies are being developed and commercialized. Therefore it is necessary to develop platform that can automatically select an object recognition model and hyper parameters on the deep learning algorithm of the user""s desired condition based on statistics. The purpose of this study is to present the analytical foundation of the deep learning algorithm from the practical point of view rather than presenting the technical direction of the deep learning algorithm.","#4th Industrial Revolution, #Deep Learning Algorithm, #Infrastructure, #Smart Information, #4차 산업혁명, #딥러닝 알고리즘, #기반기술, #스마트 정보"
딥러닝 기법을 이용한 망막 혈관 분할,2019.05,"당뇨망막증은 망막의 말초혈관에 순환장애가 일어나 발생하는 당뇨병의 합병증으로, 이를 진단하기 위하여 미세혈관류를 분할하였다. 기존 필터와 특징을 사용한 혈관분할은 두꺼운 혈관은 비교적 잘 분할을 하나, 미세한 혈관에 대해서는 정확도가 떨어진다는 단점이 있다. 그리하여 전처리로 노이즈 제거를 위한 필터, 영상 대비를 위한 히스토그램 평활화를 사용하였으며, 픽셀 단위 분할을 위해 딥러닝 기법을 이용하였다. 기존 방법의 정확도는 90% ~ 94%이며, 제안한 방법의 정확도는 95%이다. 결과 영상에서 시신경 유두 및 삼출몰 주변에서 분할 오류가 나타나는 문제점이 있으나, 이는 네트워크 깊이가 얕음에 의한 오류로 향후 네트워크 변경을 통해 정확도를 개선할 수 있다.

Diabetic retinopathy is a complicated form of diabetes due to circulatory disorder in the peripheral blood vessels of the retina. We segment the microvessel for diagnosing diabetic retinophathy. The conventional methods using filter and features can segment the thick blood vessels, but it has relatively weak for segmenting fine blood vessels. In pre-processing step, noise reduction filter and histogram equalization are applied to suppress the noise and enhance the image contrast. Then, deep learning technique is used for pixel-by-pixel segmentation. The accuracy of conventional methods is between 90% to 94%, while the proposed method has improved as 95% accuracy. There is a problem of segmentation error around the optic disc and exudate due to the network depth. However the accuracy can be improved by modifying the network architecture in the future.","#retinal imaging, #blood vessel, #deep learning, #segmentation"
잡음제거 모델 훈련을 위한 딥러닝 기반 가상 데이터베이스 생성 기법,2019.5,,"#Deep neural network, #virtual noisy database, #real environment, #denoising, #ideal ratio mask"
딥러닝 기반의 복합 열화 영상 분류 및 복원 기법,2019.05,"CNN (convolutional neural network) 기반의 단일 열화 영상 복원 방법은 우수한 성능을 나타내지만 한가지의 특정 열화를 해결하는 데 맞춤화 되어있다. 본 연구에서는 복합적으로 열화 된 영상 분류 및 복원을 위한 알고리즘을 제시한다. 복합 열화 영상 분류 문제를 해결하기 위해 CNN 기반의 알고리즘인 사전 학습된 Inception-v3 네트워크를 활용하고, 영상 열화 복원을 위해 기존의 CNN 기반의 복원 알고리즘을 사용하여 툴체인을 구성한다. 실험적으로 복합 열화 영상의 복원 순서를 추정하였으며, CNN 기반의 영상 화질측정 알고리즘의 결과와 비교하였다. 제안하는 알고리즘은 추정된 복원 순서를 바탕으로 구현되어 실험 결과를 통해 복합 열화 문제를 효과적으로 해결할 수 있음을 보인다.

The CNN (convolutional neural network) based single degradation restoration method shows outstanding performance yet is tailored on solving a specific degradation type. In this paper, we present an algorithm of multi-degradation classification and restoration. We utilize the CNN based algorithm for solving image degradation classification problem using pre-trained Inception-v3 network. In addition, we use the existing CNN based algorithms for solving particular image degradation problems. We identity the restoration order of multi-degraded images empirically and compare with the non-reference image quality assessment score based on CNN. We use the restoration order to implement the algorithm. The experimental results show that the proposed algorithm can solve multi-degradation problem.","#Deep learning, #Multi-Degradation, #Degradation Classification, #Restoration order, #Restoration"
영상 딥러닝 기반의 3차원 자율비행 기술을 이용한 풍력터빈 블레이드 검사 및 손상검출 자동화 시스템,2019.05,,"#Wind turbine(풍력터빈), #Blade inspection(블레이드 검사), #Artificial Intelligence(인공지능), #Autonomous flight(자율비행), #O&M(유지보수), #Deep learning(딥러닝), #Drone(드론)"
딥러닝과 최적설계,2019.06,,
딥러닝 모형을 사용한 한국어 음성인식,2019.04,"본 논문에서는 베이즈 신경망을 결합한 종단 간 딥러닝 모형을 한국어 음성인식에 적용하였다. 논문에서는 종단 간 학습 모형으로 연결성 시계열 분류기(connectionist temporal classification), 주의 기제, 그리고 주의 기제에 연결성 시계열 분류기를 결합한 모형을 사용하였으며. 각 모형은 순환신경망(recurrent neural network) 혹은 합성곱신경망(convolutional neural network)을 기반으로 하였다. 추가적으로 디코딩 과정에서 빔 탐색과 유한 상태 오토마타를 활용하여 자모음 순서를 조정한 최적의 문자열을 도출하였다. 또한 베이즈 신경망을 각 종단 간 모형에 적용하여 일반적인 점 추정치와 몬테카를로 추정치를 구하였으며 이를 기존 종단 간 모형의 결괏값과 비교하였다. 최종적으로 본 논문에 제안된 모형 중에 가장 성능이 우수한 모형을 선택하여 현재 상용되고 있는 Application Programming Interface (API)들과 성능을 비교하였다. 우리말샘 온라인 사전 훈련 데이터에 한하여 비교한 결과, 제안된 모형의 word error rate (WER)와 label error rate (LER)는 각각 26.4%와 4.58%로서 76%의 WER와 29.88%의 LER 값을 보인 Google API보다 월등히 개선된 성능을 보였다.

In this paper, we propose an end-to-end deep learning model combining Bayesian neural network with Korean speech recognition. In the past, Korean speech recognition was a complicated task due to the excessive parameters of many intermediate steps and needs for Korean expertise knowledge. Fortunately, Korean speech recognition becomes manageable with the aid of recent breakthroughs in “End-to-end” model. The end-to-end model decodes mel-frequency cepstral coefficients directly as text without any intermediate processes. Especially, Connectionist Temporal Classification loss and Attention based model are a kind of the end-to-end. In addition, we combine Bayesian neural network to implement the end-to-end model and obtain Monte Carlo estimates. Finally, we carry out our experiments on the “WorimalSam” online dictionary dataset. We obtain 4.58% Word Error Rate showing improved results compared to Google and Naver API.","#Korean speech recognition, #end to end deep learning, #Connectionist temporal classification, #Attention, #Bayesian deep learning, #한국어 음성인식, #종단 간 딥러닝, #연결성 시계열 분류기, #주의 기제, #베이즈 딥러닝"
Sentinel-1 SAR 영상과 딥러닝 기법을 이용한 고해상도 토양수분 추정,2019.05,,
다중모델앙상블과 딥러닝을 이용한 북극권 해빙면적비 근미래 예측,2019.05,,
딥러닝을 활용한 스마트 철강 코일 밴드 재질 감별 시스템 개발,2019.05,,"#Coil band strap classification, #Deep Learning, #Convolutional Neural Network (CNN), #VGG19"
딥러닝을 이용한 차로이탈 경고 시스템,2019.4,"최근 인공지능 기술이 급격히 발전하면서 첨단 운전자 지원 시스템 분야에 딥러닝 기술을 접목하여 기존의 기술보다 뛰어난 성능을 보여주기 위한 여러 연구들이 진행 되고 있다. 이러한 동향에 맞춰 본 논문 또한 첨단 운전자 지원 시스템의 핵심 요소 중 하나인 차로이탈 경고시스템에 딥러닝 기술을 접목한 방법을 제안한다. 제안하는 방법과 기존의 차선검출 기반의 경고시스템과의 비교 실험을 통해 그 성능을 평가 하였다. 고속도로 주행영상과 시내 주행영상을 이용한 두 가지의 서로 다른 환경에서 모두 제안하는 방법이 정확도 및 정밀도 부분에서 더 높은 수치를 보여주었다.

As artificial intelligence technology has been developed rapidly, many researchers who are interested in next-generation vehicles have been studying on applying the artificial intelligence technology to advanced driver assistance systems (ADAS). In this paper, a method of applying deep learning algorithm to the lane departure warning system which is one of the main components of the ADAS was proposed. The performance of the proposed method was evaluated by taking a comparative experiments with the existing algorithm which is based on the line detection using image processing techniques. The experiments were carried out for two different driving situations with image databases for driving on a highway and on the urban streets. The experimental results showed that the proposed system has higher accuracy and precision than the existing method under both situations.","#차선이탈 경고시스템, #첨단 운전자 지원 시스템, #딥러닝, #Lane departure warning system, #Advanced driver assistance system, #Deep learning"
딥러닝 기반 P&ID 이미지 내 텍스트 객체 검출,2019.05,,
딥러닝을 이용한 장애물회피와 길 탐지 및 추적,2019.05,,"#Machine Learning(기계 학습), #Vision Based Control(영상기반 제어), #Unmanned Aerial Vehicle(무인 비행체), #Convolutional Neural Network (합성곱 신경망)"
딥러닝 기반 2D LiDAR와 Camera의 Decision level fusion을 이용한 보행자 검출,2019.05,,"#Pedestrian detection, #2D LiDAR, #Camera, #Deep learning, #MLP, #Decision level fusion"
딥러닝을 이용한 단안 카메라의 외부 파라미터 캘리브레이션,2019.05,,"#Extrinsic calibration, #Monocular camera, #Deep learning"
딥러닝을 활용한 예술로봇의 관객 감정 파악과 공감적 표정 생성,2019.05,,
초고층 건설용 리프트의 운행 자동화를 위한 딥러닝 적용방안,2019.04,,"#건설용 리프트, #딥러닝, #강화학습, #초고층 건축공사, #무인리프트, #Construction Lift, #Deep Learning, #Reinforcement Learning, #High-rise Building Construction, #Automated Construction Lift"
딥러닝 네트워크를 이용한 도로 주행상황에서의 객체 인식,2019.05,,"#Object Detection, #Autonomous Driving"
딥러닝의 모델 학습 과정 개선을 위한 배치 정규화에 대한 연구,2019.05,,"#Batch Normalization, #Model Parameter, #CNN, #EMNIST, #Fashion MNIST"
딥러닝을 사용한 엔진의 질소 산화물 예측 속도 개선,2019.05,,"#NOx(질소 산화물), #Deep learning(딥러닝), #Genetic algorithm(유전 알고리즘), #Response SuerfaceMethodology(반응표면법)"
저가형 SUV 능동현가 시스템을 위한 딥러닝 롤 각 추정기 개발,2019.05,,"#Deep Learning(딥러닝), #Roll Angle Estimator(롤 각 추정기), #Active Suspension(능동현가장치), #Roll Angle(롤각), #Model-Based Estimator(모델기반추정기)"
딥러닝 기법을 이용한 서울의 미세먼지와 초미세먼지 예측,2019.5,,
딥러닝을 이용한 결함 검사 알고리즘,2019.05,,"#Deep learning, #Defect inspection, #Machine learning"
임피던스 측정 기법과 딥러닝을 이용한 2 액형 접착제의 혼합비 추정,2019.05,,"#Two-part Epoxy, #Polymeric Material, #Permittivity, #Impedance, #Deep Learning"
영상 딥러닝 모델을 이용한 터널 균열 탐지 기술,2019.05,,
긴급 상황의 정확한 인지를 위한 멀티 모달 딥러닝 방법 설계,2019.5,,"#Multimodal, #gesture recognition, #alert system, #late fusion"
딥러닝 기반의 플랜트 감시변수 예측 알고리즘 개발,2019.05,,
GMAW에서 이면 비드 유무 검출을 위한 Time-Frequency analysis method를 적용한 딥러닝 기법에 관한 연구,2019.05,,"#GMAW, #Back Bead, #Deep learning, #Time-Frequency analysis method, #Short Time Fourier Transform"
딥러닝을 활용한 영양큐레이션 알고리즘의 효과에 관한 연구,2019.05,,"#Nutrition, #Intelligent, #AI, #Animal"
딥러닝 기법을 이용한 태풍 강도 분석,2019.05,,"#위성자료, #적외채널, #딥러닝, #CNN"
딥러닝 기반 수요반응 예측,2019.05,,
딥러닝을 이용한 조류 퇴치기 사례 연구,2019.05,,"#Deep learning, #Bird repellent system, #Pattern recognition"
Negative Sample을 활용한 영상 균열탐지 딥러닝 모델 성능 향상,2019.05,,
딥러닝 기반 콘크리트 교량 상태평가를 위한 영상정보 활용 방안 고찰,2019.05,,
로봇의 지각을 위한 딥러닝 추론 기술,2019.05,,
딥러닝 영상분석 기반 화재 감지 시스템 구현,2019.05,,"#AlexNet, #Fire detection, #normal, #smoke, #flame"
딥러닝 기반 공간 이미지 분석 시스템의 설계 및 구현,2019.04,,
딥러닝을 이용한 공간객체추출의 문제점 및 개선방안 도출 연구,2019.04,,"#딥러닝, #공간객체추출, #정확도"
딥러닝 기법을 이용한 도심지 환경에서의 멀티콥터 이탈 거리 예측,2019.05,,
딥러닝 기법을 이용한 정량적 어획물 분류를 위한 기반 연구,2019.05,,
지오태그 사진들을 위한 효율적인 딥러닝 결합형 밀도기반 클러스터링,2019.04,,
화재발생정보 모니터링을 통한 딥러닝 기반의 대형 또는 사망 화재사고 발생 예측,2019.05,,
딥러닝 기법을 이용한 전해가공의 홀가공 특성 분석,2019.05,,"#Deep Learning, #Electrochemical machining, #Hole machining, #Electrode gap, #Applied Current"
딥러닝 기법을 이용한 풍환경 변화에 따른 멀티콥터 이탈 거리 예측,2019.04,,"#Multicopter(멀티콥터), #Deep Learning(딥러닝), #Deep Neural Network(심층 신경망)"
딥러닝 기반 실시간 손 제스처 인식,2019.04,"In this paper, we propose a real-time hand gesture recognition algorithm to eliminate the inconvenience of using hand controllers in VR applications. The user""s 3D hand coordinate information is detected by leap motion sensor and then the coordinates are generated into two dimensional image. We classify hand gestures in real-time by learning the imaged 3D hand coordinate information through SSD(Single Shot multibox Detector) model which is one of CNN(Convolutional Neural Networks) models. We propose to use all 3 channels rather than only one channel. A sliding window technique is also proposed to recognize the gesture in real time when the user actually makes a gesture. An experiment was conducted to measure the recognition rate and learning performance of the proposed model. Our proposed model showed 99.88% recognition accuracy and showed higher usability than the existing algorithm.","#Leap Motion, #Deep Learning, #VR, #Gesture Recognition"
딥러닝을 이용한 가상현실상의 E2E 자율주행의 실제 환경의 로봇 자율주행으로 전이에 대한 연구,2019.05,"In this paper, an end-to-end (E2E) deep neural network is employed for an autonomous driving robot. First, we develop a self-driving algorithm for a virtual environment (Euro Truck). In order to construct the E2E autonomous driving algorithm for Euro Truck, we use only the visual information from the front-camera view without any perception and build a deep neural network to enable self-driving. After this, we employ the algorithm in a real-world robot without any further modifications. Our proposed algorithm provides the key to the successful transition from a virtual environment to a real environment. The validity of the proposed algorithm is proven in our experiments.","#end-to-end learning, #E2E, #CNN, #Deep Learning Network, #Autonomous Driving Robot, #AI-NVIDIA-RoboEX"
ANN 기반 곡가공 삼각 가열 예측 구현을 위한 딥러닝 엔진 설계 방안에 관한 연구,2019.05,,"#Image data processing, #Data Analytic, #Deep Learning"
달표면 물체 감지를 위한 딥러닝 적용 소개,2019.4,,"#Object Detection (객체 감지), #Deep Learning (딥러닝), #Lunar Surface (달 표면), #Vision-based Navigation (영상 기반 항법)"
장기체공형 태양광 드론과 딥러닝을 이용한 산불 이상징후 감지 체계 구축,2019.04,,"#태양광드론, #딥러닝, #모니터링, #객체탐지, #산불, #이상징후, #장기체공"
딥러닝 기반 송신전력 조절방안의 성능검증,2019.03,"최근 딥러닝 기술이 큰 관심을 받으며 다양한 분야에 적용되고 있다. 특히 다양한 무선통신기술에 딥러닝을 접목하여 기존 통신시스템의 한계를 뛰어넘으려는 시도가 이루어지고 있다. 본 논문에서는 딥러닝 기반 무선통신 시스템 송신전력 조절방안의 성능검증을 수행하였다. 딥러닝 기반 송신전력 조절방안에서는 수학적 최적화 문제를 직접 풀어서 최적의 전력을 결정하는 기존 방식과 달리 심층신경망 구조를 학습시켜서 채널에 따라 최적의 송신전력을 찾는 General solver를 도출하여 이를 이용한다. 특히 시스템의 주파수 효율을 심층신경망 학습의 손실함수로 사용함으로써 라벨없이 학습을 가능케 한다. 본 논문에서는 Tensorflow 기반 성능분석을 통해 딥러닝 기반 송신전력 조절방안과 최적방안의 성능이 일치함을 보였고, 또한 제안 방안이 기존의 방식에 비해서 1/200의 계산복잡도로 송신전력을 찾을 수 있음을 보임으로써 실제 무선통신시스템에서의 적용가능성을 검증하였다.

Recently, the deep learning technology has gained lots of attention which leads to its application to various fields. Especially, there are recent attempts to overcome the limit of wireless communications systems through the use of the deep learning. In this paper, we have verified the performance of deep learning based transmit power control scheme. Unlike previous transmit power control schemes where the optimal transmit power is derived by solving the optimization problem explicitly, in the deep learning based transmit power control, the general solver for the optimization problem is derived through the deep neural network (DNN). Especially, by using the spectral efficiency as the loss function of DNN, the training can be performed without needing labels. Through simulation based on Tensorflow, we confirm that the transmit power control based on deep learning can achieve the optimal performance while reducing the computational complexity by 1/200.","#딥러닝, #전송파워조절, #무선통신시스템, #최적화, #검증, #Deep learning, #Transmit power control, #Wireless communication systems, #Optimization, #Verification"
DCT 신호처리 및 딥러닝 알고리즘 적용을 통한 채터 진단,2019.05,,"#Milling machining, #Machine tools, #Vibration signal, #CNN, #Chatter diagnosis, #DCT"
생활도로 노상주차 식별을 위한 Google Street View API와 딥러닝 모형의 적용,2019.03,"본 연구는 Google Street View API를 통해 취득한 가로 이미지를 활용하여 서울시 생활도로의 노상주차를 식별하는 모형을 학습 및 검증하였다. 다양한 반복학습 횟수에 따른 모형들의 정확도를 검증하여 최종모형으로 도출하였으며, 최종 모형은 모든 객체 유형에 대해 약 75.68%, 노상주차 차량에 대해 약 82.07%의 객체 탐색 정확도를 나타낸다. 연구의 주요 시사점은 주로 현장조사에 의존해 진행되어, 시간과 금전적 비용이 많이 필요하던 노상주차 데이터 수집의 한계점을 보완하였다는 점과, 딥러닝 모형을 공간분석 및 도시 계획 분야의 공간정보 수집에 적용하여 그 가능성을 제시했다는 점을 들 수 있다.

This study has trained and validated a deep learning model that identifies street parking on the streets of Seoul by utilizing the street view images obtained through the Google Street View API. We derived the final model which shows highest accuracy of object detection among models with variation of the number of training iterations. The final model shows 75.68% accuracy of object detection for all object types and 82.07% for street parking vehicles. The main implications of this study are as follows. This study introduces improved data collection method of street parking data in terms of time and monetary cost compared to the conventional field survey. Also this study applies the deep learning using street view image on the collection of spatial information for the urban planning and spatial analysis field.","#노상주차, #딥러닝, #구글 가로 이미지, #객체 탐색, #합성곱신경망, #Street Parking, #Deep Learning, #Google Street View Image, #Object Detection, #Convolutional Neural Network"
수중 소나 영상 학습데이터의 다양한 Augmentation 에 따른 딥러닝 기반의 마커 검출 성능에 관한 연구,2019.04,,
딥러닝 모터고장진단을 위한 소음 및 진동 데이터의 특성 비교,2019.04,,
반도체 FAB 시뮬레이션을 위한 딥러닝모델과 시뮬레이션 모델의 통합에 관한 연구,2019.04,본 연구는 반도체 FAB 시뮬레이션을 위한 딥러닝 모델과 시뮬레이션 모델의 통합에 관한 연구이다. 반도체의 수요가 증가하면서 반도체의 생산량을 높이려는 많은 연구들이 진행되고 있다. 그중에서 시뮬레이션은 복잡하고 긴 프로세스로 이루어진 반도체 공정에 대한 연구들 하기에 적합하며 좋은 결과를 위해선 실제와 비슷한 시뮬레이션 모델이 필요하다. 하지만 공정과 물류가 함께 돌아가는 정합성이 높은 시뮬레이션 모델은 무겁고 시간이 오래걸리는 제약이 존재한다. 본 연구에서는 딥러닝을 이용한 반도체 물류 모델을 통해 정합성이 높으면서도 가벼운 반도체 시뮬레이션 모델을 제안하고자 한다.,
반도체 FAB 시뮬레이션을 위한 딥러닝모델과 시뮬레이션 모델의 통합에 관한 연구,2019.4,본 연구는 반도체 FAB 시뮬레이션을 위한 딥러닝 모델과 시뮬레이션 모델의 통합에 관한 연구이다. 반도체의 수요가 증가하면서 반도체의 생산량을 높이려는 많은 연구들이 진행되고 있다. 그중에서 시뮬레이션은 복잡하고 긴 프로세스로 이루어진 반도체 공정에 대한 연구들 하기에 적합하며 좋은 결과를 위해선 실제와 비슷한 시뮬레이션 모델이 필요하다. 하지만 공정과 물류가 함께 돌아가는 정합성이 높은 시뮬레이션 모델은 무겁고 시간이 오래걸리는 제약이 존재한다. 본 연구에서는 딥러닝을 이용한 반도체 물류 모델을 통해 정합성이 높으면서도 가벼운 반도체 시뮬레이션 모델을 제안하고자 한다.,
Landsat 8 대기 반사도와 딥러닝 모델을 이용한 서울시 PM₁₀시공간 해상도 향상,2019.04,"최근 한반도에서 고농도 미세먼지 관측 일수가 증가하면서 이로 인한 사회적 문제가 대두되고 있다. 현재 서울시를 기준으로 24개의 도시 대기 관측소와 15개의 도로변 대기 관측소를 통해 미세먼지 농도를 제공하고 있으나 미세먼지 특성상 토지 피복, 기상 조건에 대한 의존성이 높기 때문에 관측소에서 측정되는 데이터가 서울시 전체를 대표한다고 보기에는 한계가 있다. 따라서 본 연구는 위성 영상, 기상 관측 데이터, 토지 피복도와 딥러닝 기법을 이용하여 높은 시공간 해상도의 서울시 미세먼지 영상 생성 모델을 설계하였다.","#위성 영상, #딥러닝, #미세먼지, #시공간 해상도 향상"
딥러닝 적용을 통한 디지털 홀로그래픽 현미경 기법의 향상,2019.4,,
딥러닝에 의한 객체인식 향상을 위한 학습 데이터의 효과적 구성: Mask R-CNN을 중심으로,2019.04,인공지능을 실현하기 위한 딥러닝(DL)은 최근 컴퓨팅 파워가 향상됨에 따라서 여러 분야에서 활용되고 있다. 합성곱 신경망(CNN: Convolutional Neural Network)은 영상 학습을 위한 대표적인 DL모델이다. CNN에서 발전된 영역기반 합성곱 신경망(R-CNN: Region- based Convolutional Neural Network)은 객체가 존재하는 영역을 탐지하고 객체를 인식하는 DL 모델이다. 본 연구에서는 R-CNN 중 가장 최근에 개발된 Mask R-CNN의 학습 데이터를 효과적으로 구성하여 건물의 인식 정확도를 높일 수 있는 방안을 제시하였다.,"#딥러닝, #합성곱 신경망, #Mask R-CNN, #학습 데이터"
의미적 분할을 위한 공간정보 데이터의 딥러닝 모델 학습: SegNet을 중심으로,2019.04,"대부분의 합성곱 신경망(CNN: convolutional neural network)은 영상을 학습 데이터(training data)로 사용하여 딥러닝(DL)에 의한 영상분류 및 객체인식을 수행하고 있지만, 본 논문에서는 영상대신에 3차원 정보를 제공하는 DSM (Digital Surface Model)을 DL 학습(training)에 이용하여 객체를 분류하였다. DL은 많은 양의 데이터가 요구되고, 데이터의 특성에 따라 다른 결과가 도출되므로 본 연구에서는 학습 데이터확보 방법을 제안하고, 데이터 특성에 따른 DL 학습 결과를 분석하기 위하여 대표적인 CNN인 SegNet 모델에 적용하여 의미적 분할(semantic segmentation)을 수행하였다.","#딥러닝, #합성곱 신경망, #SegNet, #의미적 분할"
딥러닝의 Label 데이터로 활용하기 위한 국토지리정보원의 수치지도 Ver. 2.0의 역할,2019.04,"여러 분야에서 인공신경망(ANN) 기반의 딥러닝(DL)에 관한 연구가 활발히 진행되고 있다. 최근에는 공간정보 분야에서도 본격적으로 DL을 활용하려는 시도가 이루어지고 있다. 대부분 DL 모델은 ground truth인 label 데이터가 핵심적인 역할을 하고 있지만, label 데이터를 확보하는 것은 어려운 일이다. 본 논문의 목적은 DL을 이용하여 건물의 3차원 모델링을 수행할 경우, 국토지리정보원의 수치지도 ver. 2.0으로부터 label 데이터를 효율적으로 생성할 수 있는 방안을 제시하는 것이다.","#딥러닝, #Label 데이터, #수치지도 ver. 2.0, #건물 모델링"
불꽃 감지를 위한 임베디드 시스템에 적합한 딥러닝 구조,2019.03,"본 논문에서는 불꽃 감지를 위한 임베디드 시스템에 적합한 딥러닝 구조를 제안한다. 제안하는 딥러닝 구조의 불꽃 감지과정은 불꽃 색깔 모델을 사용한 불꽃 영역 검출, 불꽃 색깔 특화 딥러닝 구조를 사용한 불꽃 영상 분류, 검출된 불꽃 영역의 N×N 셀 분리, 불꽃 모양 특화 딥러닝 구조를 사용한 불꽃 영상 분류 등의 4가지 과정으로 구성된다. 첫 번째로 입력 영상에서 불꽃의 색만을 추출한 다음 레이블링하여 불꽃 영역을 검출한다. 두 번째로 검출된 불꽃 영역을 불꽃 색깔에 특화 학습된 딥러닝 구조의 입력으로 넣고, 출력단의 불꽃 클래스 확률이 75% 이상에서만 불꽃 영상으로 분류한다. 세 번째로 앞 단에서 75% 미만 불꽃 영상으로 분류된 영상들의 검출된 불꽃 영역을 N×N 단위로 분할한다. 네 번째로 N×N 단위로 분할된 작은 셀들을 불꽃의 모양에 특화 학습된 딥러닝 구조의 입력으로 넣고, 각 셀의 불꽃 여부를 판단하여 50% 이상의 셀들이 불꽃 영상으로 분류될 경우에 불꽃 영상으로 분류한다. 제안된 딥러닝 구조의 성능을 평가하기 위하여 ImageNet의 불꽃 데이터베이스를 사용하여 실험하였다. 실험 결과, 제안하는 딥러닝 구조는 기존의 딥러닝 구조보다 평균 29.86% 낮은 리소스 점유율과 8초 빠른 불꽃 감지 시간을 나타내었다. 불꽃 검출률은 기존의 딥러닝 구조와 비교하여 평균 0.95% 낮은 결과를 나타내었으나, 이는 임베디드 시스템에 적용하기 위해 딥러닝 구조를 가볍게 구성한데서 나온 결과이다. 따라서 본 논문에서 제안하는 불꽃 감지를 위한 딥러닝 구조는 임베디드 시스템 적용에 적합함이 입증되었다.

In this paper, we propose a deep learning structure suitable for embedded system. The flame detection process of the proposed deep learning structure consists of four steps：flame area detection using flame color model, flame image classification using deep learning structure for flame color specialization, N×N cell separation in detected flame area, flame image classification using deep learning structure for flame shape specialization. First, only the color of the flame is extracted from the input image and then labeled to detect the flame area. Second, area of flame detected is the input of a deep learning structure specialized in flame color and is classified as flame image only if the probability of flame class at the output is greater than 75%. Third, divide the detected flame region of the images classified as flame images less than 75% in the preceding section into N×N units. Fourthly, small cells divided into N×N units are inserted into the input of a deep learning structure specialized to the shape of the flame and each cell is judged to be flame proof and classified as flame images if more than 50% of cells are classified as flame images. To verify the effectiveness of the proposed deep learning structure, we experimented with a flame database of ImageNet. Experimental results show that the proposed deep learning structure has an average resource occupancy rate of 29.86% and an 8 second fast flame detection time. The flame detection rate averaged 0.95% lower compared to the existing deep learning structure, but this was the result of light construction of the deep learning structure for application to embedded systems. Therefore, the deep learning structure for flame detection proposed in this paper has been proved suitable for the application of embedded system.","#embedded system, #deep learning structure, #resource occupancy rate, #flame detection time, #flame detection rate"
딥러닝을 활용한 엔진오일 타입에 따른 엔진 조기점화 특성에 대한 연구,2019.04,,"#engine oil, #deep learning, #pre-ignition pattern"
증강현실 환경에서 딥러닝과 Point Cloud를 활용한 실 객체 매칭 방법,2019.04,,
증강현실 환경에서 딥러닝과 Point Cloud를 활용한 실 객체 매칭 방법,2019.04,,
무조건 딥러닝?,2019.03,,
딥러닝을 활용한 건화물선 운임 지수 예측,2019.04,"The market for tramp shipping is an industry characterized by volatility that is determined by the principle of perfect competition according to supply and demand. The factors affecting the supply and demand of the market are very diverse, and the mechanism of action is complicated, so forecasting in the shipping market remains a difficult task. To solve this problem, time series analysis has been conducted for a long time. However, there have been some limitations in the time series analysis which did not reflect various indicators. For this reason, most of the previous research has been stayed at an initial stage of research by comparing the prediction accuracy of two approaches : the time series analysis and the deep learning method. There has not been much research on how to improve the model performance. The purpose of this study is to improve the Baltic Dry Index(BDI) prediction performance by using Long Short Term Memory(LSTM) which is one of the deep neural networks and to consider additional variables that influence on the previous research.","#Tramper, #LSTM, #BDI, #Prediction, #Additional Variables"
스마트폰 다종 데이터를 활용한 딥러닝 기반의 사용자 동행 상태 인식,2019.03,"스마트폰이 널리 보급되고 현대인들의 생활 속에 깊이 자리 잡으면서, 스마트폰에서 수집된 다종 데이터를 바탕으로 사용자 개인의 행동을 인식하고자 하는 연구가 활발히 진행되고 있다. 그러나 타인과의 상호작용 행동 인식에 대한 연구는 아직까지 상대적으로 미진하였다. 기존 상호작용 행동 인식 연구에서는 오디오, 블루투스, 와이파이 등의 데이터를 사용하였으나, 이들은 사용자 사생활 침해 가능성이 높으며 단시간 내에 충분한 양의 데이터를 수집하기 어렵다는 한계가 있다. 반면 가속도, 자기장, 자이로스코프 등의 물리 센서의 경우 사생활 침해 가능성이 낮으며 단시간 내에 충분한 양의 데이터를 수집할 수 있다. 본 연구에서는 이러한 점에 주목하여, 스마트폰 상의 다종 물리 센서 데이터만을 활용, 딥러닝 모델에 기반을 둔 사용자의 동행 상태 인식 방법론을 제안한다. 사용자의 동행 여부 및 대화 여부를 분류하는 동행 상태 분류 모델은 컨볼루션 신경망과 장단기기억 순환 신경망이 혼합된 구조를 지닌다. 먼저 스마트폰의 다종 물리 센서에서 수집한 데이터에 존재하는 타임 스태프의 차이를 상쇄하고, 정규화를 수행하여 시간에 따른 시퀀스 데이터 형태로 변환함으로써 동행 상태분류 모델의 입력 데이터를 생성한다. 이는 컨볼루션 신경망에 입력되며, 데이터의 시간적 국부 의존성이 반영된 요인 지도를 출력한다. 장단기 기억 순환 신경망은 요인 지도를 입력받아 시간에 따른 순차적 연관 관계를 학습하며, 동행 상태 분류를 위한 요인을 추출하고 소프트맥스 분류기에서 이에 기반한 최종적인 분류를 수행한다. 자체 제작한 스마트폰 애플리케이션을 배포하여 실험 데이터를 수집하였으며, 이를 활용하여 제안한 방법론을 평가하였다. 최적의 파라미터를 설정하여 동행 상태 분류 모델을 학습하고 평가한 결과, 동행 여부와 대화 여부를 각각 98.74%, 98.83%의 높은 정확도로 분류하였다.

As smartphones are getting widely used, human activity recognition (HAR) tasks for recognizing personal activities of smartphone users with multimodal data have been actively studied recently. The research area is expanding from the recognition of the simple body movement of an individual user to the recognition of low-level behavior and high-level behavior. However, HAR tasks for recognizing interaction behavior with other people, such as whether the user is accompanying or communicating with someone else, have gotten less attention so far. And previous research for recognizing interaction behavior has usually depended on audio, Bluetooth, and Wi-Fi sensors, which are vulnerable to privacy issues and require much time to collect enough data. Whereas physical sensors including accelerometer, magnetic field and gyroscope sensors are less vulnerable to privacy issues and can collect a large amount of data within a short time. In this paper, a method for detecting accompanying status based on deep learning model by only using multimodal physical sensor data, such as an accelerometer, magnetic field and gyroscope, was proposed. The accompanying status was defined as a redefinition of a part of the user interaction behavior, including whether the user is accompanying with an acquaintance at a close distance and the user is actively communicating with the acquaintance. A framework based on convolutional neural networks (CNN) and long short-term memory (LSTM) recurrent networks for classifying accompanying and conversation was proposed.
First, a data preprocessing method which consists of time synchronization of multimodal data from different physical sensors, data normalization and sequence data generation was introduced. We applied the nearest interpolation to synchronize the time of collected data from different sensors. Normalization was performed for each x, y, z axis value of the sensor data, and the sequence data was generated according to the sliding window method. Then, the sequence data became the input for CNN, where feature maps representing local dependencies of the original sequence are extracted. The CNN consisted of 3 convolutional layers and did not have a pooling layer to maintain the temporal information of the sequence data. Next, LSTM recurrent networks received the feature maps, learned long-term dependencies from them and extracted features. The LSTM recurrent networks consisted of two layers, each with 128 cells. Finally, the extracted features were used for classification by softmax classifier. The loss function of the model was cross entropy function and the weights of the model were randomly initialized on a normal distribution with an average of 0 and a standard deviation of 0.1. The model was trained using adaptive moment estimation (ADAM) optimization algorithm and the mini batch size was set to 128. We applied dropout to input values of the LSTM recurrent networks to prevent overfitting. The initial learning rate was set to 0.001, and it decreased exponentially by 0.99 at the end of each epoch training.
An Android smartphone application was developed and released to collect data. We collected smartphone data for a total of 18 subjects. Using the data, the model classified accompanying and conversation by 98.74% and 98.83% accuracy each. Both the F1 score and accuracy of the model were higher than the F1 score and accuracy of the majority vote classifier, support vector machine, and deep recurrent neural network. In the future research, we will focus on more rigorous multimodal sensor data synchronization methods that minimize the time stamp differences. In addition, we will further study transfer learning method that enables transfer of trained models tailored to the training data to the evaluation data that follows a different distribution. It is expected that a model capable of exhibiting robust recognition performance against changes in data that is not considered in the model learning stage will be obtained.","#사용자 행동 인식, #그룹 상호작용, #스마트폰 물리 센서, #컨볼루션 신경망, #장단기 기억 순환 신경망, #human activity recognition, #group interaction, #smartphone multimodal sensors, #convolutional neural network, #long short-term memory recurrent network"
딥러닝 기술을 이용한 이미지 및 쿼리 기반 제조 정보 추천 방법,2019.04,,
딥러닝 기술을 이용한 이미지 및 쿼리 기반 제조 정보 추천 방법,2019.04,,
딥러닝을 이용한 일사 예측 모델 개발,2019.04,,"#딥러닝(Deep Learning), #수평면 전일사량(Total horizontal irradiance), #산란일사(Diffuse irradiance)"
[Special Editorial] 딥러닝과 산업공학,2019.03,,
IoT산업에서의 딥러닝 기술과 활용사례,2019.03,,
알약 자동 인식을 위한 딥러닝 모델간 비교 및 검증,2019.03,"When a prescription change occurs in the hospital depending on a patient’s improvement status, pharmacists directly classify manually returned pills which are not taken by a patient. There are hundreds of kinds of pills to classify. Because it is manual, mistakes can occur and which can lead to medical accidents. In this study, we have compared YOLO, Faster R-CNN and RetinaNet to classify and detect pills. The data consisted of 10 classes and used 100 images per class. To evaluate the performance of each model, we used cross-validation. As a result, the YOLO Model had sensitivity of 91.05%, FPs/image of 0.0507. The Faster R-CNN’s sensitivity was 99.6% and FPs/image was 0.0089. The RetinaNet showed sensitivity of 98.31% and FPs/image of 0.0119. Faster RCNN showed the best performance among these three models tested. Thus, the most appropriate model for classifying pills among the three models is the Faster R-CNN with the most accurate detection and classification results and a low FP/image.","#Pill Classification, #Object Detection, #Deep Learning, #Artificial Intelligent, #Hospital"
철강 소재 미세조직 분석에 딥러닝 기술의 이용,2019.04,,
Transformer와 GCN을 이용한 딥러닝 기반 특허 맵 모델,2019.04,,
머신비전과 딥러닝 기반의 양돈생육프로그램 개발 및 양돈생육환경 개선,2019.04,,
Transformer와 GCN을 이용한 딥러닝 기반 특허 맵 모델,2019.04,,
딥러닝 기반의 발전소 상태 예측알고리즘 개발,2019.04,,
머신비전과 딥러닝 기반의 양돈생육프로그램 개발 및 양돈생육환경 개선,2019.04,,
딥러닝 기반의 발전소 상태 예측알고리즘 개발,2019.04,,
딥러닝 기법을 활용한 다중 센서 데이터의 설비예지보전 시스템 사례 연구,2019.04,,
딥러닝 기법을 활용한 다중 센서 데이터의 설비예지보전 시스템 사례 연구,2019.04,,
합성곱 신경망을 이용한 딥러닝 기반의 토지피복 분류,2019.02,"토지피복도는 지표의 현황 및 변화를 가장 잘 반영할 수 있기 때문에 다양한 연구에서 활용되고 있다. 그러나 현재 환경부에서 제공하고 있는 토지피복도는 정확도가 높지 않고 갱신주기가 길어 데이터의 신뢰도나 시간해상도 측면에서 한계가 존재한다. 본 연구는 딥러닝(deep learning) 기반의 토지피복 분류 기법을 적용함으로써 자동화를 통한 갱신주기 단축과 한국의 토지피복 분류 체계에 부합하는 토지피복도 작성을 위한 대안적인 해결 방법을 제안하였다. 딥러닝 기법 중 이미지 분석에 특화된 합성곱 신경망(Convolutional neural network)을 이용해 토지피복을 분류하였다. 먼저 같은 토지피복 유형이라 할지라도 지역에 따른 이질성이 있음을 확인하기 위해 유럽지역을 대상으로 만들어진 EuroSAT 토지피복 데이터를 사용해 합성곱 신경망 모델을 학습시켜 한국 토지피복 분류를 실험하였다. 본 연구에서는 Sentinel-2 위성의 영상을 사용하여 한국 토지피복 분류 체계에 맞는 학습 및 테스트 데이터를 구축하였다. 본 연구에서 구축한 데이터로 학습시킨 합성곱 신경망 모델은 정확도 98.28%로 EuroSAT 데이터로 학습시킨 모델보다 우수한 분류성능을 보여주었다. 또한 ImageNet 사전 학습 파라미터(Pre-trained parameter)를 사용하여 합성곱 신경망 모델의 학습속도와 정확도(99.66%)를 높였으며 합성곱 신경망을 이용한 한국 토지피복 분류에서 ImageNet 파라미터의 활용가능성을 보여주었다. 본 연구를 계기로 그간 국내에서 주목받지 않았던 합성곱 신경망을 이용한 토지피복 분류 연구가 확대되기를 기대한다.

Land cover map best reflects land surface phenomena and change so it is used in various research. However, the land cover maps provided by the Ministry of Environment have limitation in terms of accuracy and temporal resolution. This study proposes the possibility of deep learning based alternative land cover classification method for shortening the renewal cycle of land cover maps through automation and development of a land cover classification that is suitable for Korea. Land cover classification is conducted using Convolutional neural network, which is the deep learning architecture specialized in image analysis. In order to confirm the heterogeneity of the land cover according to region even though the same land cover type, land cover classification of Korea was experimented using the model trained by EuroSAT land cover data composed of Europe region’s land cover data. Using Sentinel-2 satellite images the training and test data are constructed for land cover classification of Korea. The convolutional neural network model trained by the data constructed in this study showed better performance with high accuracy(98.28%) than the model trained by EuroSAT data. In addition, The learning speed and accuracy(99.66%) of the convolutional neural network model was improved by using ImageNet pre-trained parameters and it showed the possibility of using ImageNet parameters in land cover classification of Korea. We hope that this study will prompt the research on land cover classification using convolutional neural network which has not been illuminated in Korea.","#딥러닝, #합성곱 신경망, #원격탐사, #토지피복, #deep learning, #Convolutional neural network, #remote sensing, #land cover"
GAN기반 딥러닝 모형을 이용한 BSR 소음의 강건한분류,2019.03,,
딥러닝 기반 항생제 내성균 감염 예측 Top 5%,2019.2,"세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반 분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염 간의 높은 연관성이 발견되었다.

The World Health Organization (WHO) and other government agencies aroundthe world have warned against antibiotic-resistant bacteria due to abuse of antibiotics and are strengthening their care and monitoring to prevent infection. However, it is highly necessary to develop an expeditious and accurate prediction and estimating method for preemptive measures. Because it takes several days to cultivate the infecting bacteria to identify the infection, quarantine and contact are not effective to prevent spread of infection. In this study, the disease diagnosis and antibiotic prescriptions included in Electronic Health Records were embedded through neural embedding model and matrix factorization, and deep learning based classification predictive model was proposed. The f1-score of the deep learning model increased from 0.525 to 0.617when embedding information on disease and antibiotics, which are the main causes of antibiotic resistance, added to the patient’s basic information and hospital use information. And deep learning model outperformed the traditional machine hospital use information. And deep learning model outperformed the traditional machine learning models.As a result of analyzing the characteristics of antibiotic resistant patients, resistant patients were more likely to use antibiotics in J01 than nonresistant patients who were diagnosed with the same diseases and were prescribed 6.3 times more than DDD.","#항생제 내성, #딥러닝, #뉴럴 임베딩 모델, #행렬 분해, #전자의무기록, #Antibiotic Resistance, #Deep Learning, #Neural Embedding Model, #Matrix Factorization, #Electronic Health Records"
군의 스마트 VR 교육 시스템을 위한 딥러닝 적용 방안,2019.02,"The purpose of this study is to propose the process and concept to develop customized training simulation using deep learning. Using the VR training simulation part(or module), we analyze the behavior pattern and the training result of the user in 16 types of items to assess the user`s weakness instead of accomplishing tasks under the virtual combat situation. Then, based on the stored data, the artificial intelligence computer automatically generates contents for individual users by utilizing deep learning technology such as Generative Adversarial Networks(GAN) and Recurrent Neural Networks(RNN). Through this process, artificial intelligence computer provides a virtual training model that can intensively train the users"" deficiencies.","#Deeplearning, #Behavior pattern, #GAN, #RNN, #Customized for user, #딥러닝, #행동 패턴, #순환신경망, #적대적 생성 모델, #사용자 맞춤형"
딥러닝을 활용한 자산분배 시스템,2019.02,"딥러닝 네트워크 기반의 알고리즘의 발전으로 인공지능은 전세계적으로 빠른 성장세를 보이고 있다. 그 중 금융은 인공지능이 가장 많이 활용될 분야로 예상되고 있으며 최근 많은 연구가 되고 있다. 기존의 딥러닝을 사용한 재무 전략은 단일 종목에 대한 주가 예측에만 치중되어 있어 변동성에 취약하다. 따라서 본 연구는 딥러닝을 이용하여 펀드 구성 종목을 산출하고 종목들을 분산투자하여 ETF 상품을 구성하는 모델을 제안한다. 실험 결과로 제안하는 모델을 통해 코스피 100지수를 대상으로 하는 성능을 분석하며 수익률 또는 안정성 측면에서 향상된 결과를 확인하였다.

As deep learning with the network-based algorithms evolve, artificial intelligence is rapidly growing around the world. Among them, finance is expected to be the field where artificial intelligence is most used, and many studies have been done recently. The existing financial strategy using deep-run is vulnerable to volatility because it focuses on stock price forecasts for a single stock. Therefore, this study proposes to construct ETF products constructed through portfolio methods by calculating the stocks constituting funds by using deep learning. We analyze the performance of the proposed model in the KOSPI 100 index. Experimental results showed that the proposed model showed improved results in terms of returns or volatility.","#자산분배, #딥러닝, #오토인코더, #ETF, #Portfolio, #Deep Learning, #Autoencoder"
Dynamic Stale Synchronous Parallel 기법을 활용한 분산 병렬 딥러닝 구조,2019.02,"최근의 딥러닝 시스템에서는 막대한 작업부하를 다수 노드들에 효과적으로 분배하는 분산 병렬 딥러닝 구조를 채택하고 있다. 이러한 구조에서는 각 노드가 일부분의 데이터 혹은 모델을 갖고 학습을 진행하기 때문에 전체적인 학습 모델 파라미터(global learning parameter)의 일관성 유지를 위해 지속적인 노드 간 동기화가 필요하고, 동기화 기법의 효율성에 따라 학습 시간과 성능이 매우 큰 영향을 받는다. 본 논문에서는 실시간 ‘학습 진전 비율(learning progress ratio, LPR)’ 기반의 동적 threshold와 local cache를 활용함으로써 기존의 SSP(stale synchronous parallel) 학습 방법에서 발생되는 동기화 오버헤드와 네트워크 오버헤드를 감소시켜 학습 시간을 단축시킨 DTSSP(dynamic threshold stale synchronous parallel) 학습 방법을 제안하고 성능을 비교 분석한다.

Recent deep learning architectures has been adopted to effectively share the heavy workload over multiple nodes. Since each node is learning with a subset of data or models in such multiple node architectures, however, continuous synchronization between nodes is required to maintain consistency to manage global learning model parameters, and thus, learning time and accuracy are significantly affected by synchronization techniques. In this paper, we propose a DTSSP (dynamic threshold stale synchronous parallel) method which utilize local parameter cache and dynamic threshold based on real-time learning progress ratio (LPR), and evaluates the performance with those of other methods. The method significantly reduces synchronization overhead and network overhead resulting from large-scale parallel learning methods.","#딥러닝, #Stale Synchronous Parallel(SSP), #학습 진전율(LPR), #동적 threshold, #대규모 학습 모델, #Deep learning, #Learning progress ratio(LPR), #Dynamic threshold, #Large-scale learning model"
딥러닝의 변수 중요도를 이용한 인공지능 기술 분석 Top 5%,2019.02,"인공지능 기술은 빠른 속도로 발전하고 있다. 특히 인공지능 개발을 이끌고 있는 많은 세부기술 간의 관계를 파악하는 것은 인공지능 기술을 이해하는데 중요하다. 본 연구에서는 이와 같은 인공지능의 기술 분석을 위하여 딥러닝을 적용한다. 최근 전통적인 통계학 및 머신러닝 기법에 비해 딥러닝의 예측 성능이 더 우수함을 보여주는 다양한 연구결과가 발표되고 있다. 하지만 최종 예측과 함께 예측에 사용된 입력변수들의 상대적인 중요도를 파악하는 것은 기존의 통계적 기법에 비해 딥러닝이 가지고 있는 어려움 중 하나이다. 예측모형에서 입력변수가 출력변수에 어떤 형태로 영향을 주는지 확인하려는 연구는 여러 분야에서 이루어지고 있다. 선형회귀분석은 입력변수의 중요도를 확인하기 위하여 표준화 회귀계수를 이용한다. 본 논문에서는 가중치 분석을 통하여 딥러닝의 입력변수 중요도를 계산하여 인공지능 기술에 영향을 미치는 세부기술에 대한 기술 분석을 수행한다. 제안 방법의 타당성을 보이기 위하여 인공지능 기술관련 특허문서를 수집하고 분석하여 인공지능 세부기술간 기술 연관성을 확인한다.

Artificial intelligence (AI) technology has been developed at a fast pace. In particular, understanding the relationship between various sub technologies leading to AI development is very important to understand AI. In this study, we use deep learning to analyze AI technology. Many studies have been published showing the prediction performance of deep running is superior to the conventional statistical and machine learning methods. However, understanding the relative importance of input variables used in the prediction of output variable is one of the difficulties of deep learning compared to the existing statistical methods. There are many studies in various fields to find out how the input variable affects the output variable in forecasting. For example, linear regression analysis uses standardized coefficients to determine the variable importance. This paper performs technology analysis on the sub technologies that influence AI technology using the variable importance of deep learning. To show the validity of the proposed methodology, we collect and analyze patent documents related to AI technology.","#딥러닝, #변수중요도, #기술분석, #선형회귀분석, #인공지능, #특허데이터, #Deep learning, #Variable importance, #Technology analysis, #Linear regression analysis, #Artificial intelligence, #Patent data"
딥러닝 모델 설계를 위한 모델 패턴 추출 및 시각화,2019.02,"최근 공개되고 있는 딥러닝 모델의 계층구조는 복잡한 형태를 갖는 경향을 보인다. 이러한 딥러닝 모델의 계층구조는 한눈에 파악하기 힘들고 재사용하기 힘들다는 어려움이 있다. 따라서 이 논문에서는 딥러닝 모델의 재사용과 가시화를 위해 복잡한 구조의 딥러닝 모델로부터 반복되는 계층을 추출하고, 모듈화하는 방법을 제안한다. 제안한 방법은 딥러닝 모델을 그래프 구조로 표현하고, 패턴 추출 과정에서 부분 그래프 마이닝 기법과 부분 패턴 마이닝 기을 단계적으로 거쳐 반복되는 패턴을 추출한다. 추가적으로, GUI 기반 에디터를 구현하여 복잡한 딥러닝 모델의 구조를 추상화함으로써 모델의 계층구조를 단순하게 표현할 수 있을 뿐만 아니라 기존 딥러닝 모듈의 효율적인 재사용이 가능하도록 지원한다.

Recent deep learning models tend to have a complex architecture. But it is hard for developers to grasp such hierarchical structure of the deep learning models and it is also difficult to reuse existing deep learning models. To solve these problems, we propose a method of extracting and modularizing repeated layers from a deep learning model for model reuse and visualization. Each repeating pattern is extracted by subgraph mining and frequent pattern mining. We also propose the GUI based editor which not only displays more simplified structure by abstract of original structure but also provides deep learning model reuse.","#딥러닝 모델 설계, #딥러닝 모델 시각화, #딥러닝 모델 재사용, #빈발 패턴 마이닝, #부분 시퀀스 마이닝, #Deep Learning Model Design, #Deep Learning Model visualization, #Deep Learning Model Reuse, #Frequent Pattern Mining"
유도 전동기의 속도 및 부하 조건을 고려한 딥러닝 고장 진단 알고리즘 개발에 관한 연구,2019.03,"The motor mechanical fault has been diagnosed under fixed driving conditions. The induction motor speed is affected not only by the input frequency but also by the load. In addition, the vibration generated by the induction motor is affected by the speed as well as the input frequency. For these reasons, a data preprocessing algorithm has been developed that shifts the measured data in the frequency domain based on motor speed. The algorithm also takes the input frequency as an input variable and removes the vibration component by the power source frequency. The data processed by the above procedure are classified through the deep learning algorithm based on CNN. As a result, a fault diagnosis system that can be applied to the industrial field has been developed by considering the motor driving conditions using the proposed algorithms.","#Deep learning, #Motor fault diagnosis, #CNN, #Data analysis, #Induction motor, #FFT, #Frequency domain"
몰포러지 신경망 기반 딥러닝 시스템,2019.02,"본 논문에서는 몰포러지 연산을 기본으로 하는 몰포러지 신경망(MNN: Morphological Neural Network) 기반 딥러닝 시스템을 제안하였다. 딥러닝에 사용되는 레이어는 몰포러지 레이어, 풀링 레이어, ReLU 레이어, Fully connected 레이어 등이다. 몰포러지 레이어에서 사용되는 연산은 에로전, 다이레이션, 에지검출 등이다. 본 논문에서 새롭게 제안한 MNN은 기존의 CNN(Convolutional Neural Network)을 이용한 딥러닝 시스템과는 달리 히든 레이어의 수와 각 레이어에 적용되는 커널 수가 제한적이다. 레이어 단위 처리시간이 감소하고, VLSI 칩 설계가 용이하다는 장점이 있으므로 모바일 임베디드 시스템에 딥러닝을 다양하게 적용할 수 있다. MNN에서는 제한된 수의 커널로 에지와 형상검출 등의 연산을 수행하기 때문이다. 데이터베이스 영상을 대상으로 행한 실험을 통해 MNN의 성능 및 딥러닝 시스템으로의 활용 가능성을 확인하였다.

In this paper, we propose a deep learning system based on morphological neural network(MNN). The deep learning layers are morphological operation layer, pooling layer, ReLU layer, and the fully connected layer. The operations used in morphological layer are erosion, dilation, and edge detection, etc. Unlike CNN, the number of hidden layers and kernels applied to each layer is limited in MNN. Because of the reduction of processing time and utility of VLSI chip design, it is possible to apply MNN to various mobile embedded systems. MNN performs the edge and shape detection operations with a limited number of kernels. Through experiments using database images, it is confirmed that MNN can be used as a deep learning system and its performance.","#CNN, #Deep Learning, #Embedded System, #MNN, #Morphology, #VLSI"
딥러닝을 활용한 EMG 기반 잡기 손동작 분류와 능동의수에 관한 연구,2019.03,"In this paper, we extract the learning and test data for the ""hand gesture of grasping"" through the sEMG sensor, execute the Deep Learning CNN (convolutional neural network) algorithm by appropriately modifying it, and classify typical hand gestures that catch objects with a classification success rate (accuracy) of approximately 93.8%. In addition, we have constructed a system that can operate robot hands in real time from these classified commands to make active prosthetics.","#Hand gesture of grasping, #sEMG sensor, #CNN, #active prosthetics, #robot hands"
효과적인 인간-로봇 상호작용을 위한 딥러닝 기반 로봇 비전 자연어 설명문 생성 및 발화 기술,2019.03,"For effective human-robot interaction, robots need to understand the current situation context well, but also the robots need to transfer its understanding to the human participant in efficient way. The most convenient way to deliver robot’s understanding to the human participant is that the robot expresses its understanding using voice and natural language. Recently, the artificial intelligence for video understanding and natural language process has been developed very rapidly especially based on deep learning. Thus, this paper proposes robot vision to audio description method using deep learning. The applied deep learning model is a pipeline of two deep learning models for generating natural language sentence from robot vision and generating voice from the generated natural language sentence. Also, we conduct the real robot experiment to show the effectiveness of our method in human-robot interaction.","#Human-Robot Interaction, #Video To Audio Description, #Video Captioning, #Speech Synthesis, #Text To Speech"
GAN과 DNN을 활용한 딥러닝 기반의 지능형 개인신용 평가모형,2019.02,"This study propose an approach for developing credit rating model with imbalanced data using machine learning techniques such as decision trees, neural networks, deep learning, and GAN. We develop a personal credit rating model to resolve an issue from imbalanced data for machine learning by utilized the SMOTE and GAN. Personal credit rating is an important system for personal loans such as FinTech, and has been applied with many deep learning techniques. Therefore, the purpose of this study is to develop an intelligent personal credit rating model based on deep learning that can be effectively used in a small data set. Therefore, in this study, 5 samples of 10,000 data sets are sampled and the size of the data set is increased by utilizing the SMOTE and GAN, which is an over sampling technique. We applied classification techniques such as logit, decision tree, ANN, and DNN. Then, to solve the imbalanced data problems, we applied under sampling, SMOTE, and GAN, and compared which the performance of statistical techniques, machine learning, and deep learning. As a result, deep learning based on personal credit rating model of SMOTE + DNN showed the highest performance with 66.2%.","#GAN, #FinTech, #Deep Learning, #Imbalance Data, #DNN"
기후 및 계절정보를 이용한 딥러닝 기반의 장기간 태양광 발전량 예측 기법,2019.02,"최근 온실가스의 증가로 인한 기후변화 대응의 필요성과 전력수요의 증가로 인해 태양광 발전량(PV) 예측의 중요성은 급격히 증가하고 있다. 특히, 태양광 발전량을 예측하는 것은 합리적인 전력 가격결정과 시스템 안정성 및 전력 생산 균형과 같은 문제를 효과적으로 해결하기 위해 전력생산 계획을 합리적으로 계획하는데 도움이 될 수 있다. 그러나 일사량, 운량, 온도 등과 같은 기후정보 및 계절 변화로 인한 태양광 발전량이 무작위적으로 변화하기 때문에 정확한 태양광 발전량을 예측하는 것은 도전적인 일이다. 따라서 본 논문에서는 딥러닝 모델을 통해 기후 및 계절정보를 이용하여 학습함으로써 장기간 태양광 발전량 예측 성능을 향상시킬 수 있는 기법을 제안한다. 본 연구에서는 대표적인 시계열 방법 중 하나인 계절형 ARIMA 모델과 하나의 은닉층으로 구성되어 있는 ANN 기반의 모델, 하나 이상의 은닉층으로 구성되어 있는 DNN 기반의 모델과의 비교를 통해 본 연구에서 제시한 모델의 성능을 평가한다. 실데이터를 통한 실험 결과, 딥러닝 기반의 태양광 발전량 예측 기법이 가장 우수한 성능을 보였으며, 이는 본 연구에서 목표로 한 태양광 발전량 예측 성능 향상에 긍정적인 영향을 나타내었음을 보여준다.

Recently, since responding to meteorological changes depending on increasing greenhouse gas and electricity demand, the importance prediction of photovoltaic power (PV) is rapidly increasing. In particular, the prediction of PV power generation may help to determine a reasonable price of electricity, and solve the problem addressed such as a system stability and electricity production balance. However, since the dynamic changes of meteorological values such as solar radiation, cloudiness, and temperature, and seasonal changes, the accurate long-term PV power prediction is significantly challenging. Therefore, in this paper, we propose PV power prediction model based on deep learning that can be improved the PV power prediction performance by learning to use meteorological and seasonal information. We evaluate the performances using the proposed model compared to seasonal ARIMA (S-ARIMA) model, which is one of the typical time series methods, and ANN model, which is one hidden layer. As the experiment results using real-world dataset, the proposed model shows the best performance. It means that the proposed model shows positive impact on improving the PV power forecast performance.","#태양광 발전량 예측, #Deep Learning, #Machine Learning, #시계열 분석, #계절형 ARIMA Model, #Photovoltaic Power Prediction, #Time Series Analysis, #Seasonal ARIMA Model"
공개 딥러닝 라이브러리에 대한 보안 취약성 검증,2019.02,"최근 다양한 분야에서 활용중인 딥러닝은 적대적 공격 가능성의 발견으로 위험성이 제기되고 있다. 본 논문에서는 딥러닝의 이미지 분류 모델에서 악의적 공격자가 생성한 적대적 샘플에 의해 분류 정확도가 낮아짐을 실험적으로 검증하였다. 대표적인 이미지 샘플인 MNIST데이터 셋을 사용하였으며, 텐서플로우와 파이토치라이브러리를 사용하여 만든 오토인코더 분류 모델과 CNN(Convolution neural network)분류 모델에 적대적 샘플을 주입하여 탐지정확도를 측정한다. 적대적 샘플은 MNIST테스트 데이터 셋을 JSMA(Jacobian-based Saliency Map Attack)방법으로 생성한 방법과 FGSM(Fast Gradient Sign Method)방식으로 변형하여 생성하였으며, 분류모델에 주입하여 측정하였을 때 최소 21.82%에서 최대 39.08%만큼 탐지 정확도가 낮아짐을 검증하였다.

Deep Learning, which is being used in various fields recently, is being threatened with Adversarial Attack. In this paper, we experimentally verify that the classification accuracy is lowered by adversarial samples generated by malicious attackers in image classification models. We used MNIST dataset and measured the detection accuracy by injecting adversarial samples into the Autoencoder classification model and the CNN (Convolution neural network) classification model, which are created using the Tensorflow library and the Pytorch library. Adversarial samples were generated by transforming MNIST test dataset with JSMA(Jacobian-based Saliency Map Attack) and FGSM(Fast Gradient Sign Method). When injected into the classification model, detection accuracy decreased by at least 21.82% up to 39.08%.","#Adversarial attack, #MNIST, #deep learning, #security, #autoencoder, #convolution neural network"
비주얼 서보잉을 위한 딥러닝 기반 물체 인식 및 자세 추정,2019.3,"Recently, smart factories have attracted much attention as a result of the 4th Industrial Revolution. Existing factory automation technologies are generally designed for simple repetition without using vision sensors. Even small object assemblies are still dependent on manual work. To satisfy the needs for replacing the existing system with new technology such as bin picking and visual servoing, precision and real-time application should be core. Therefore in our work we focused on the core elements by using deep learning algorithm to detect and classify the target object for real-time and analyzing the object features. We chose YOLO CNN which is capable of real-time working and combining the two tasks as mentioned above though there are lots of good deep learning algorithms such as Mask R-CNN and Fast R-CNN. Then through the line and inside features extracted from target object, we can obtain final outline and estimate object posture.","#Object Detection, #Object Recognition, #Deep Learning, #Line Detection, #Hough Transform, #Perspective-Transform, #Pose Estimation"
어안렌즈 카메라로 획득한 영상에서 차량 인식을 위한 딥러닝 기반 객체 검출기,2019.02,"This paper presents a deep learning-based object detection method for recognizing vehicles in images acquired through cameras installed on ceiling of underground parking lot. First, we present an image enhancement method, which improves vehicle detection performance under dark lighting environment. Second, we present a new CNN-based multiscale classifiers for detecting vehicles in images acquired through cameras with fisheye lens. Experiments show that the presented vehicle detector has better performance than the conventional ones.","#Deep Learning, #Vehicle Detection, #Fisheye Lens Cameras, #Convolutional Neural Network"
딥러닝을 이용한 사용자 한글 손글씨 자동 제작 서비스 구현,2019.02,,"#딥러닝, #폰트, #cycleGAN"
딥러닝 상용화를 위한 해결 과제들,2019.02,,
백스터 로봇의 시각기반 로봇 팔 조작 딥러닝을 위한 강화학습 알고리즘 구현,2019.03,"Reinforcement learning has been applied to various problems in robotics. However, it was still hard to train complex robotic manipulation tasks since there is a few models which can be applicable to general tasks. Such general models require a lot of training episodes. In these reasons, deep neural networks which have shown to be good function approximators have not been actively used for robot manipulation task. Recently, some of these challenges are solved by a set of methods, such as Guided Policy Search, which guide or limit search directions while training of a deep neural network based policy model. These frameworks are already applied to a humanoid robot, PR2. However, in robotics, it is not trivial to adjust existing algorithms designed for one robot to another robot. In this paper, we present our implementation of Guided Policy Search to the robotic arms of the Baxter Research Robot. To meet the goals and needs of the project, we build on an existing implementation of Baxter Agent class for the Guided Policy Search algorithm code using the built-in Python interface. This work is expected to play an important role in popularizing robot manipulation reinforcement learning methods on cost-effective robot platforms.","#Robotics, #Visuomotor Policy, #Reinforcement Learning, #Guided Policy Search, #Baxter Research Robot"
수중 소나 영상 학습 데이터의 왜곡 및 회전 Augmentation을 통한 딥러닝 기반의 마커 검출 성능에 관한 연구,2019.03,"In the ground environment, mobile robot research uses sensors such as GPS and optical cameras to localize surrounding landmarks and to estimate the position of the robot. However, an underwater environment restricts the use of sensors such as optical cameras and GPS. Also, unlike the ground environment, it is difficult to make a continuous observation of landmarks for location estimation. So, in underwater research, artificial markers are installed to generate a strong and lasting landmark. When artificial markers are acquired with an underwater sonar sensor, different types of noise are caused in the underwater sonar image. This noise is one of the factors that reduces object detection performance. This paper aims to improve object detection performance through distortion and rotation augmentation of training data. Object detection is detected using a Faster R-CNN.","#Deep Learning, #Data Augmentation, #Object Detection, #Underwater Sonar Image"
“딥러닝이 바꾸는 미래사회” 특집을 내면서,2019.02,,
딥러닝을 이용한 연속 시간 감정 상태 추론 시스템 설계,2019.02,"표정은 사람이 감정을 표현하는 직접적인 방법 중 하나이다. 사람은 연속시간 상에서 표정의 변화를 통해 감정 상태를 나타내지만 기존의 기술은 대부분 정지영상에서만 감정 상태를 인식하였다. 본 연구는 연속 시간상에서 감정 상태를 추론하기 위한 딥러닝 시스템을 제안한다. 제안된 연속 시간 감정 상태 추론 시스템은 세 단계로 이루어져 있다. Convolutional Neural Network (CNN) 모델을 사용한 특징 추출 단계, 활성화 지도를 사용한 얼굴영역 검출 및 관심 영역 풀링 단계, 그리고 Recurrent Neural Network (RNN) 모델을 사용한 시계열 추론 단계. 본 논문에서는 짧은 표정 동영상을 통해 감정 상태를 추론하는 실험을 수행하였다. 실험을 통해 제안된 시스템이 기존의 CNN 기반 물체 검출 모델보다 빠르게 얼굴영역 검출을 수행하며, 연속 시간상에서 감정 상태 추론이 가능함을 보였다.

Facial expressions are one of the efficient methods of expressing emotions. Most of the existing facial expression analysis techniques recognize emotional state only in still images. This study proposes a deep learning system for estimating emotional states in continuous time. The proposed emotional state estimation system in continuous time consists of three processes. Feature extraction using Convolutional Neural Network (CNN) model, Activation Map (AM)-based facial region detection and region of interest (RoI) Pooling, and sequential estimation using Recurrent Neural Network (RNN) model. In this paper, we performed an experiment to estimate the emotional state from in short video clips of facial expressions. Experimental results show that the proposed system can perform facial region detection faster than conventional CNN - based object detection models and emotional state estimation in continuous time.","#감정 상태 판단, #표정 인식, #Convolutional neural network, #neural networks, #Emotional state estimation, #Facial Expression Recognition, #Convolutional neural network, #Recurrent neural network"
소프트맥스를 이용한 딥러닝 음악장르 자동구분 투표 시스템,2019.01,"인간이 가진 뛰어난 능력 중의 하나인 곡 분류 과정을 딥러닝 알고리즘을 통해 구현하는 연구는 단일데이터를 이용한 유니모달 모델, 멀티모달 모델, 뮤직비디오를 이용한 멀티모달 방식 등이 있다. 이 연구에서는 곡의 스펙트로그램을 짧은 샘플들로 분할하여 각각을 CNN으로 분석한 뒤 그 결과를 투표하는 시스템을 제안하여 더 좋은 결과를 얻었다. 딥러닝 알고리즘 중 CNN이 RNN에 비해 음악 장르 구분에 있어 우수한 성능을 보였으며 CNN과 RNN을 같이 적용했을 때 성능이 좋아짐을 알 수 있었다. 음악샘플을 나누어 각각의 CNN 결과를 투표하는 시스템이 이전 모델에 비해 좋은 결과를 나타내었고 이 모델에 Softmax 레이어를 추가한 모델이 가장 좋은 성능을 보였다. 디지털 미디어의 폭발적인 성장과 수많은 스트리밍 서비스 속에서 음악장르의 자동분류에 대한 필요는 점점 증가하고 있는 추세이다. 향후 연구에서는 미분류 곡의 비율을 낮추고 최종적으로 미분류된 곡들의 장르구분에 대한 알고리즘을 개발할 필요가 있을 것이다.

Research that implements the classification process through Deep Learning algorithm, one of the outstanding human abilities, includes a unimodal model, a multi-modal model, and a multi-modal method using music videos. In this study, the results were better by suggesting a system to analyze each song’s spectrum into short samples and vote for the results. Among Deep Learning algorithms, CNN showed superior performance in the category of music genre compared to RNN, and improved performance when CNN and RNN were applied together. The system of voting for each CNN result by Deep Learning a short sample of music showed better results than the previous model and the model with Softmax layer added to the model performed best. The need for the explosive growth of digital media and the automatic classification of music genres in numerous streaming services is increasing. Future research will need to reduce the proportion of undifferentiated songs and develop algorithms for the last category classification of undivided songs.","#딥러닝, #소프트맥스, #음악장르구분, #CNN, #RNN, #Deep learning, #Music Classification, #Softmax"
딥러닝을 이용한 이변량 장기종속시계열 예측,2019.02,"본 논문에서는 딥러닝을 이용한 이변량 장기종속시계열(long-range dependent time series) 예측을 고려하였다. 시계열 데이터 예측에 적합한 LSTM(long short-term memory) 네트워크를 이용하여 이변량 장기종속시계열을 예측하고 이를 이변량 FARIMA(fractional ARIMA) 모형인 FIVARMA 모형과 VARFIMA 모형과의 예측 성능을 실증 자료 분석을 통해 비교하였다. 실증 자료로는 기능적 자기공명 영상(fMRI) 및 일일 실현 변동성(daily realized volatility) 자료를 이용하였으며 표본외 예측(out-of sample forecasting) 오차 비교를 통해 예측 성능을 측정하였다. 그 결과, FIVARMA 모형과 VARFIMA 모형의 예측값에는 미묘한 차이가 존재하며, LSTM 네트워크의 경우 초매개변수 선택으로 복잡해 보이지만 계산적으로 더 안정되면서 예측 성능도 모수적 장기종속시계열과 뒤지지 않은 좋은 예측 성능을 보였다.

We consider bivariate long range dependent (LRD) time series forecasting using a deep learning method. A long short-term memory (LSTM) network well-suited to time series data is applied to forecast bivariate time series; in addition, we compare the forecasting performance with bivariate fractional autoregressive integrated moving average (FARIMA) models. Out-of-sample forecasting errors are compared with various performance measures for functional MRI (fMRI) data and daily realized volatility data. The results show a subtle difference in the predicted values of the FIVARMA model and VARFIMA model. LSTM is computationally demanding due to hyper-parameter selection, but is more stable and the forecasting performance is competitively good to that of parametric long range dependent time series models.","#딥러닝, #장기종속시계열, #deep learning, #FARIMA, #FIVARMA, #long range dependent, #LSTM, #VARFIMA"
홀로렌즈에서 ToF 센서를 이용한 딥러닝 기반의 정적 손동작 인식,2019.02,"가상 (Virtual Reality, VR) 혹은 증강현실 (Augmented Reality, AR)에서의 사용자 손동작 인식 기술은 인간 컴퓨터 상호작용 (Human Computer Interaction, HCI) 시나리오에서 자연스러운 사용자 인터페이스 (Natural User Interface, NUI) 기술로 자리잡아 왔다. 본 논문은 AR기기인 홀로렌즈에서의 NUI 를 위해 비행시간 (Timeof-Flight, ToF) 센서를 하단 뷰를 향해 부착하고, 이를 이용하여 입력 받은 정보 기반의 정적 손동작인식 방법을 제안한다. ToF 센서에서 취득한 적외선 그레이 및 깊이 정보를 입력으로 Convolutional Neural Network (CNN) 기반의 딥러닝 (Deep Learning) 모델 중 개선된 Residual Network (ResNet)를 이용하여 실시간 손동작 인식 방법을 구현하였다. 향후 본 논문에서 제시한 손동작 인식방법을 이용하여 카페나 도서관 등의 공공장소에서 사회적으로 수용 가능한 눈에 띄지 않는 손동작 인식기술로 적용시킬 수 있을 것이다.","#손동작 인식, #ToF, #딥러닝, #ResNet, #홀로렌즈"
파이썬에 기반한 케라스 딥러닝 실전,2019.12,,
케라스 창시자의 딥러닝 with R,2019.12,,
딥러닝 기반 음성인식 Top 5%,2019.2,,
딥러닝을 이용한 소음원 위치 추정 연구,2019.02,,"#Sound source location(소음원 위치), #Location estimation(위치추정), #Deep learning(딥러닝)"
딥러닝을 이용한 소음원의 방사형태 학습,2019.02,,"#deep learning(딥러닝), #sound source(소음원)"
딥러닝기반의 선박 회전기기 상태 모니터링 시계열 분석 시스템,2019.02,,"#Artificial neural network(인공신경망), #Time series analysis(시계열 분석), #Rotating machinery(회전기기), #Prognosis(예지), #Short-time Fourier transforms(단시간 푸리에 변환), #System health(시스템 건전성), #Convolutional neural network(합성곱 신경망), #Recurrent neural network(재귀 신경망)"
딥러닝 기반 교통혼잡 예측 및 신호제어 솔루션 개발,2019.02,"우리나라 전국 7대 대도시 교통혼잡비용은 최근 10년(2006~2015) 동안 37.9% 증가했다. 하지만 교통혼잡을 감소시키기 위해 한정된 국토 내 도로 신설 및 확장 등 인프라 건설은 예산 및 도로부지 확보 등에 의한 공간적인 한계가 있다. 따라서, 기 구축된 시설물을 최대한 활용하여 교통상황 예측정보 기반 선제적 교통제어 및 교통수요 분산 전략이 필요하다. 최근 4차산업 혁명에서 대두되고 있는 인공지능 딥러닝 기술을 활용하여 기존 단발적인 교통혼잡 해결방안 보다는 도시별 맞춤형 기반 사전 교통혼잡 예측 및 신호제어가 가능한 종합적인 솔루션 방법론을 개발하였다. 본 방법론은 도시별 맞춤형 교통혼잡 예측을 위해 혼잡도로의 날씨, 미세먼지, 도로 상황, 시간대별 교통패턴 등을 활용하여 교통데이터와 시공간적으로 융합할 수 있는 딥러닝 컨볼루션 신경망(CNN)-장단기메모리(LSTM) 기반 교통 혼잡을 예측하고 교통소통 상황에 따른 패턴을 분류하여 교통상황 패턴별 신호제어를 수행한다. 본 연구 결과물을 통해 대도시의 교통혼잡을 사전에 예측하여 교통량을 제어함으로써 날로 증가되는 교통혼잡비용을 감소시키며 교통혼잡의 문제를 해결할 수 있는 마중물 역할을 할 것으로 기대된다.",
딥러닝 기반 기계진동 영상 진단 기법,2019.02,,"#Machine Vibration, #Deep Learning, #Image Classification"
"딥러닝, 소음진동분야에도 유용한가?",2019.02,,
딥러닝 기반 스마트 센서를 이용한 케이블 모니터링 자동화 시스템 개발,2019.02,,"#케이블, #케이블 모니터링, #임베디드 프로세싱, #스마트 센서, #peak-picking"
딥러닝 네트워크를 이용한 조영증강 CT 영상 생성,2019.01,,"#영상생성 딥러닝 네트워크 (Generative adversarial network, GAN), #조영증강 CT (contrast enhanced computed tomography), #히스토그램 균일화 (histogram equalization)"
정치인 얼굴 기반 소속 정당 판별 딥러닝 모델,2019.2,"최근 연구에 따르면 사람의 얼굴은 커뮤니케이션의 중요한 매개체 역할을 하며, 사람과 관련된 사회적 속성들을 예측하는 데 활용할 수 있는 중요한 정보의 원천이라고 알려져 있다. 본 연구에서는 정치인의 얼굴이미지 정보를 학습하고 이를 통해 해당 정치인의 소속정당을 예측하는 딥러닝 기반 모델을 개발하고 평가하였다.","#얼굴, #정치 분석, #정당, #Convolutional Neural Network, #Deep Neural Network, #기계학습"
딥러닝 기반 드론 검출 및 분류,2019.02,"As commercial drones have been widely used, concerns for collision accidents with people and invading secured properties are emerging. The detection of drone is a challenging problem. The deep learning based object detection techniques for detecting drones have been applied, but limited to the specific cases such as detection of drones from bird and/or background. We have tried not only detection of drones, but classification of different drones with an end-to-end model. YOLOv2 is used as an object detection model. In order to supplement insufficient data by shooting drones, data augmentation from collected images is executed. Also transfer learning from ImageNet for YOLOv2 darknet framework is performed. The experimental results for drone detection with average IoU and recall are compared and analysed.","#Drone detection and classification, #Deep learning, #Convolution neural network, #YOLOv2"
딥러닝기법을 이용한 주차면 영상 인식 시스템 개발,2019.01,,"#딥러닝(Deep Learning), #영상인식(Image Recognition)"
자율주행 자동차를 위한 물체인식 딥러닝 네트워크 및 구현기법 Top 10%,2019.01,,
딥러닝을 이용한 재실정보 기반 건물의 전기 수요 예측 모델,2019.01,"Recently, numerous studies on the prediction of electricity consumption using deep-learning models have been conducted. The prediction models were mostly developed for a district scale since the influence of occupants’ behaviors in such cases is small. On the other hands, the occupants generate huge uncertainty in predicting the future electricity demand. In this study, the unpredictable occupancy information was fed to a deep-learning model as a true value by assuming that in the future, the occupants may actively interact with the control systems using various smart device. The proposed model uses simple input values such as time of the day, base electricity load and occupancy information, while learning is achieved using measured data. Deep-leaning models with single and deeper layers were tested in this study. Both models showed excellent performance for data matching during the learning periods. The models also showed acceptable prediction performance for use in predictive control, with errors less than 30% in RMSE (cv).","#Neural network(신경망), #Deep learning(딥러닝), #Electricity consumption(전기 수요), #Occupancy information(재실 정보)"
YOLO 딥러닝 기법을 이용한 드론카메라 영상 내 건물 외벽 균열 검출 시스템,2019.01,,"#드론(Drone), #균열(Crack), #영상인식(Image Recognition), #딥러닝(Deep Learning)"
시간에 따라 변화하는 빗줄기 장면을 이용한 딥러닝 기반 비지도 학습 빗줄기 제거 기법,2019.01,"Single image rain removal is a typical inverse problem which decomposes the image into a background scene and a rain streak. Recent works have witnessed a substantial progress on the task due to the development of convolutional neural network (CNN). However, existing CNN-based approaches train the network with synthetically generated training examples. These data tend to make the network bias to the synthetic scenes. In this paper, we present an unsupervised framework for removing rain streaks from real-world rainy images. We focus on the natural phenomena that static rainy scenes capture a common background but different rain streak. From this observation, we train siamese network with the real rain image pairs, which outputs identical backgrounds from the pairs. To train our network, a real rainy dataset is constructed via web-crawling. We show that our unsupervised framework outperforms the recent CNN-based approaches, which are trained by supervised manner. Experimental results demonstrate that the effectiveness of our framework on both synthetic and real-world datasets, showing improved performance over previous approaches.","#Rain Streak Removal, #Unsupervised Learning, #Convolutional Neural Networks, #Siamese Network"
딥러닝 알고리즘을 기반한 지리정보생성 시스템,2019.1,,
영상 딥러닝 모델을 이용한 End-to-End 악성코드 탐지,2019.01,,
다기관 의료데이터를 사용한 분산딥러닝의 이슈 분석,2019.1,,
딥러닝 객체 탐지 기술을 활용한 드론용 셀카 촬영 앱 설계,2019.01,,"#드론(Drone), #딥러닝(Deep Learning), #객체 탐지(Object Detectioni), #셀카(Self-Camera)"
건물 특성 정보를 이용한 딥러닝 기반 건물 인식 강화 방법에 관한 연구,2019.01,,
딥러닝 기반 지역 대비 HDR 복원 Inverse Tone mapping 에 관한 연구,2019.01,,
딥러닝 기반의 피아노 악보 생성 연구,2019,"최근 기계학습의 한 분야인 딥러닝(Deep Learning)이 최근 다양한 분야에서 적용되어 사용되고 있다. 음악장르에서도 딥러닝을 이용한 다양한 연구가 활발히 진행되고 있다. 대부분의 음악은 다양한 악기의 상호작용에 의하여 만들어진다. 하지만 사람은 음악에서 어떤 악기가 사용되었는지 쉽게 식별할 수 있지만 컴퓨터에서는 실제 악기 사운드의 음색, 음질이 다르고 연주자의 연주 스타일 등이 다르기 때문에 자동으로 악기를 식별하고 분류하는 일은 매우 어려운 일이다. 그렇기 때문에 악보 생성에서도 많은 연구가 있었지만 대체로 좋은 성과를 내지 못하였다.
기존의 악보 생성 방법은 화성음과 비화성음, 그리고 코드와 악보의 구성에 대한 이해를 필요로 하기 때문에 화성학적 지식이 부족한 비전문가들에게는 많은 시간과 노력을 요구하는 까다로운 작업이 될 수 있다. 따라서 본 논문에서는 비전문가들도 충분히 사용할 수 있는 딥러닝 기반의 피아노 중심 악보 생성 연구를 진행하였다. 먼저 피아노 위주의 음악을 입력으로 넣어주면 STFT(Short Time Fourier Transform)을 통하여 Magnitude Spectra 와 Phase Spectra로 나뉜다. 그 중 Magnitude Spectra를 이용하여 DNN(Deep Neural Network)를 통과시켜 음악의 음을 얻는다. 그리고 Lilypond를 통하여 음을 악보로 변환하는 작업을 통하여 최종적으로 피아노 위주의 음악을 악보로 출력한다.

Recently, Deep Learning a field of machine learning, has been applied in various fields. Various studies using Deep Learning are actively being conducted in music genres. Most music is produced by the interaction of various instruments. However, people can easily identify which instruments are used in a specific music, but it is very difficult to automatically identify and classify instruments because they differ in tone, sound quality and playing style of real instrument sounds. Therefore, although there have been a lot of research performed on the production of musical scores, they have not achieved good results in general.
Traditional methods of producing music require a lot of time and effort especially for non-professionals who lack knowledge of harmony, mutalogy and understanding of the code and composition. Therefore, in this paper, we conducted a study on producing Deep Learning based piano music that can be used sufficiently by non-specialists. First of all, if you put in input for piano, Magnitude Spectra and Phase Spectra are divided through STFT(Short Term Fourier Transform). Among them, they use Magnitude Spectra to get the sound of music through a Deep Neural Network(DNN) model. And finally, through the conversion of sound into a music sheet through Lilypond, piano-oriented music is produced as music sheet.","#딥러닝, #Neural Network, #DNN"
패션제품 추천을 위한 협업 딥러닝 시스템 개발,2019,"본 논문에서는 매일 쏟아지는 패션 상품들 중에서 사용자의 취향을 고려한 패션 상품을 효과적으로 추천해주기 위해 기존의 추천시스템과 딥러닝을 결합한 하이브리드형 추천시스템을 개발하였다. 딥러닝은 최근 이미지, 영상, 자연어처리, 음성인식 등의 다양한 분야에서 뛰어난 성능을 보이는 기술이며 추천시스템 도메인에서 사용자와 상품사이의 상호작용을 효과적으로 모델링하기 위해 딥러닝을 접목하려는 연구가 많아지고 있다. 의류 패션시장의 SPA 브랜드 같은 경우 매주 새로운 의류상품이 쏟아지고 있고 이에 따라 추천시스템은 사용자에게 취향을 고려한 상품을 추천해줘야 하지만 상품에 대한 사용자의 평가가 존재해야 추천을 해줄 수 있는 협업필터링 추천시스템 특성 때문에 ‘Cold start’ 라는 문제가 발생하게 된다. 본 연구에서는 사용자가 의류 상품을 구매할 때 시각적 특징을 고려하여 구매한다고 가정하고 의류 상품의 이미지 데이터를 사용함으로써 이 ‘Cold start’ 문제에 대처했다. 또한 이 모델을 다시 딥러닝 모델인 Multi Layer Perceptron과 하이브리드 하여 성능을 더욱 향상시킴에 따라 패션시장에서 사용할 수 있는 하이브리드형 딥러닝 추천시스템을 제안한다.
추천시스템 모델을 학습시킬 데이터세트는 중고의류사이트에서 크롤링한 ‘Tradesy.com’ 를 사용하였고 상품에 대해 20회이상 평가한 사용자만을 추출하여 만들었다. 데이터세트는 8,355명의 사용자와 258,943의 상품과 492,350의 상호작용으로 이루어져 있다. 또한 제안한 모델이 ‘Cold start’ 문제를 잘 해결하는지 보이기 위해 ‘All items’와 ‘Cold items’ 세팅으로 나누고 데이터 집합은 각 사용자가 평가한 1개의 데이터를 테스트집합으로 사용하고 나머지를 훈련집합으로 사용해 실험을 진행하였다. 모델은 개발하기 위해 프로그래밍 언어 중 하나인 파이썬과 딥러닝 모델을 학습하기 위해 딥러닝 프레임워크 중 하나인 케라스를 사용하였고 cpu, memory, gpu 각각 intel® Core™ i5-8600 @3.10Ghz, 32GB, 1080Ti 에서 실험을 진행하였다. 본 연구에서 제안하는 Visual Generalized Matrix Factorization의 성능을 평가하기 위해 Random, Itempop, Matrix Factorization, Generalized Matrix Factorization의 모델들과 비교를 하였다. 각 모델들을 비교하기 위한 평가지표로는 Hit Ratio(HR) 와 Normalized Discounted Cumulative Gain(NDCG)를 사용하였으며 제안한 VGMF 모델이 ‘All items’ 세팅에서 GMF와 MF에 비해 각각 13.7%, 33.5%의 성능 향상을(NDCG) 보였고 ‘Cold items’ 세팅에서는 각각 18.7%, 71.0%의 성능향상을(NDCG) 보였다. 또한 VGMF와 MLP를 하이브리드 하여 만든 모델의 경우 VGMF에 비해 ‘All items’, ‘Cold items’ 세팅에서 각각 8.8%, 7.9%의 성능향상을(NDCG) 보였다. 이를 통해 패션제품을 추천할 때 상품의 이미지를 활용할경우 모델의 전체적인 성능이 올라감을 알 수 있고 또한 상품에 대한 평가정보가 없어서 발생하는 ‘Cold start’ 일 때 상품의 이미지를 사용하면 이 문제에 대해 기존의 모델들에 비해 잘 대처할 수 있음을 알 수 있다.
이처럼 본 연구에서는 최근 활발하게 연구가 이뤄지고 있는 딥러닝을 추천시스템에 결합하여 사용자의 취향을 고려한 패션제품 추천시스템 모델을 제안하였다. 비록 상품의 메타데이터 중 이미지정보만을 사용하여 성능을 높이고자 했지만 추후 연구에서 사용자의 리뷰데이터, 상품 클릭 횟수, 사용자의 나이, 사용자의 성별 등의 다양한 메타데이터들을 추천시스템 모델에 결합 한다면 사용자에게 더욱 개인화된 추천을 해줄 수 있을 것이다

In this paper, we developed a hybrid based recommender system that combines existing recommendation system with deeplearning to efficiently recommend fashion products considering user ''s preference among newly emerging fashion products. Deep Learning is a technology that shows outperform in various fields such as image, video, natural language processing, speech recognition, etc., and there is an increasing number of studies to incorporate deep learning to effectively model the interaction between user and product in the recommender system domain . In the case of the SPA brand in the apparel fashion market, new apparel products are poured every week. Accordingly, the recommender system should recommend the product considering the preference to the user. However, since there is the evaluation of the user about the product, the user can learn the recommendation system model, which causes the problem of ''Cold Start''. In this study, suppose that the user considers the visual features of the apparel product, and coped with the ''Cold Start'' problem by using the apparel product image data. In addition, this model is hybrid with Deep Learning model MultiLayer Perceptron to further improve the performance, thus suggesting a hybrid based deeplearning recommender system that can be used in the fashion market.
The data set to learn the recommended system model was created by extracting only the users who evaluated ''Tradesy.com'', which was crawled from the second-hand clothing site, and evaluated the product more than 20 times. The data set consists of 8,355 users and 258,943 products and 492,350 interactions. We also divide the proposed model into ''All items'' and ''Cold items'' settings to see if the ''Cold start'' problem is solved well. The data set uses one data evaluated by each user as a test set and the rest as a training set The experiment was carried out. To develop the model, we used Python, one of the programming languages, and Keras, one of the deeplearning frameworks, and experimented with intel® Core ™ i5-8600 @ 3.10Ghz, 32GB, and 1080Ti, respectively, for cpu, memory and gpu. To evaluate the performance of the proposed Visual Generalized Matrix Factorization, we compared the models of Random, Itempop, Matrix Factorization, and Generalized Matrix Factorization. Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG) were used as the evaluation metrics for comparing each model. The proposed VGMF model showed 10.9% and 33.5% improvement in performance in the ''All items'' setting compared to GMF and MF (NDCG), and 18.7% and 71.0% performance improvement (NDCG) in the ''Cold items'' setting respectively. In the case of the model made by hybrid of VGMF and MLP, the performance improvement (NDCG) was 8.8% and 7.9% in the ''All items'' and ''Cold items'' settings, respectively, compared to VGMF. If you use the image of the product when recommending the fashion product, you can see that the overall performance of the model is increased. Also, if you use the image of the product when the ''Cold start'' occurs because there is no evaluation information about the product, It can be seen that it can cope well with existing models.
In this study, we proposed a fashion product recommender system model considering user ''s preference by combining deeplearning which is actively studied recently with recommender system. Although we tried to improve the performance by using only image information among the metadata of the product, in future studies, if we combine various metadata such as the user''s review data, the number of clicks of the product web page, the age of the user and the gender of the user into the recommender system model, Personalized recommendations will be made.","#추천시스템, #인공지능, #딥러닝"
딥러닝 기반 국내 미세먼지 예측 모델링 연구,2019,"미세먼지란 환경정책기본법에 따르면, 입자의 크기가 10um 이하인 먼지(PM-10)과 2.5um 이하인 먼지(PM-2.5)를 통칭하며, 사람의 생활 영역에 다양한 피해를 끼치고 있다.
이러한 미세먼지의 위험성에 대해 최근 시민과 정부의 인식이 높아지고 있으며, 미세먼지로 인한 피해를 예방하기 위한 예측 시스템의 중요성이 대두되고 있다. 그러나 환경부에서 국내 미세먼지 예측을 위해 쓰고 있는 모델은 결정론적 기법을 사용하고 있으며, 이 기법은 최근 딥러닝 기반 기법보다 성능이 떨어진다고 알려져 있다. 그럼에도 불구하고 국내환경에 맞추어 연구된 딥러닝 기반 미세먼지 예측 모델링의 연구는 국제 연구에 비해 아직 미흡한 실정이다.
따라서 본 연구에서는 국내 환경을 고려하여 중국 미세먼지 데이터와 국내 기상데이터 및 미세먼지 데이터를 활용한 딥러닝 모델 개발을 목표로 한다. 또한 기존에 연구된 딥러닝 기반 예측 모델보다 더 좋은 성능을 얻기 위해, 시공간 데이터를 동시에 분석하여 미세먼지 확산현상을 더 잘 고려할 수 있는 ConvGRU와, CNN과 달리 weight sharing을 하지 않아 중국에서 유입되는 미세먼지가 각 지역에 주는 영향을 더 잘 반영할 수 있는 locally-connected layer를 활용한 딥러닝 기반 국내 미세먼지 예측 모델링을 제안한다.
실험은 국내 전역을 8x10의 grid로 나눈 구역을 공간해상도로 하고, 1시간을 시간해상도로 하여 1시간, 4시간, 12시간, 24시간 뒤 미세먼지(PM10)농도를 예측하도록 설계한다. 제안한 모델에서 성능을 높이기 위해 가정한 부분들을 검증하고, 기존에 연구된 딥러닝 기반 미세먼지 예측 모델보다 더 나은 성능을 보이는지 확인하기 위해 5가지의 실험 가설을 세우고 이에 맞는 다양한 비교 모델을 만들어 결과를 분석하였다.
실험결과에 따른 검증된 가설을 종합하면 미세먼지를 예측하기 위한 모델링은 1) 시간정보뿐만 아니라 시공간정보를 동시에 고려할 때, 2) 단시간 예측에 대해서는 계산 복잡성이 낮은 기법을, 장시간 예측에 대해서는 복잡성이 높은 기법을 사용할 때, 3) 다음 시간 T를 예측하기 위해 다음 시간 T-1까지의 중간 과정을 고려할 때, 4) 국내의 미세먼지 확산 요인을 잘 반영하도록 설계할 때, 5) 국외 미세먼지 유입요인 또한 잘 반영하도록 설계할 때 좋은 미세먼지 예측 성능을 얻을 수 있다는 결론을 얻을 수 있으며, 제안한 모델이 이를 만족함으로써 기존에 연구된 모델보다 더 나은 예측 성능을 가짐을 보였다.
또한 단시간 예측 시 주로 이전 참값을 따라가는 delay shift 현상을, 장시간 예측 시 중간 값을 따라가려 하는 moving average 현상이 일어남을 예측 값과 참값의 비교 그래프를 통해 확인하였고, 이를 해결한다면 예측 성능을 더 개선할 수 있겠다는 결론을 얻었다.","#미세먼지, #딥러닝, #시계열 예측, #ConvGRU, #Locally-connected layer"
정제형 일반의약품 인식서비스를 위한 딥러닝 기반의 모바일 플랫폼,2019,"현재 한국의 의약품 산업은 주요 성장동력산업으로 분류되고 있으며, 폭발적인 성장을 보이고 있다. 하지만 가파른 성장곡선에 비해 의약품 소비자들의 의약품 관리 능력 및 복용 지식수준은 미미한 수준이다. 따라서 의약품 정보 제공 서비스가 제공되고 있으나, 실질적인 서비스는 사용하기 번거롭고 저조한 성능으로 도태되고 있는 실정이다.
본 논문에서는 일반의약품 소비자를 대상으로 의약품 관리 능력 및 복약지식 수준 향상, 지속적 복약지도 서비스 제공을 위해 정제형 일반의약품 인식 서비스를 위한 딥러닝 기반의 모바일 플랫폼을 제안한다.
제안하는 플랫폼은 기존의 저조한 인식 능력을 가진 템플릿 매칭 기반 기능을 고성능의 딥러닝 기반 이미지 인식 기능으로 변경하여 인식 능력을 향상시킨다. 또한 서비스 제공을 위한 편의성과 접근성 향상을 위해 CS구조를 기반으로 하며 추가적인 딥러닝 API로 구성한다.
제안하는 플랫폼의 딥러닝 모델은 CNN 기반의 모델을 직접 제작한 일반의약품 데이터 셋을 이용해 학습 및 적용하였다. 제안한 딥러닝 기반의 모바일 플랫폼은 기존 일반의약품 정보 제공 시스템의 단점을 완화하고, 향후 딥러닝 기반의 모바일 플랫폼을 일반의약품 정보 제공 서비스에 적용한다면, 일반의약품 소비자의 의약품 관리 능력, 복약지도 수준 향상시키고 지속적 복약지도 서비스를 제공할 수 있음으로 사료된다.

Recently Korea''s pharmaceutical industry is classified as a major growth engine industry. But, compared with the growth rate, the pharmaceutical consumer''s management ability and taking knowledge level are low. Therefore, the drug information providing service is provided, but the actual service is a cumbersome to use and poor performance. In this paper, we propose mobile platform based-on deeplearning for Tablet typed OTC-Drug recognition service. The proposed platform changes the template matching-based function with existing low-recognition capabilities to the high-performance deep learning-based image recognition function, thereby improving the recognition capability. It is also based on the CS structure and configured with additional deep learning APIs to improve convenience and accessibility for service. Deep Learning models of the platform were learned and applied using a set of generic drug data produced by CNN-based models. Our proposed deep learning-based mobile platform can mitigate the disadvantages of existing general medicine information systems. If a deep learning-based mobile platform is applied to OTC drug information services, it can be that it can improve the ability of general medicine consumers to manage medicines, improve the level of medication map, and provide continuous replication guidance services.","#딥러닝, #모바일 플랫폼, #일반의약품 인식, #컴퓨터비전"
딥러닝을 이용한 시계열 데이터 군집화에 관한 연구,2019,"최근 4차 산업혁명과 더불어 딥러닝을 활용한 스마트 공장, 스마트 시티, 인공지능 서비스 등이 활발히 추진되고 있다. 딥러닝이 다양한 분야에서 좋은 성능을 보이고 있는 이유는 딥러닝이 고차원의 복잡한 데이터를 잘 표현할 수 있을 뿐만 아니라 다양한 데이터 분석을 위한 많은 딥러닝 알고리즘이 개발되었기 때문이다. 대부분의 딥러닝 알고리즘은 설명변수와 종속변수를 바탕으로 학습을 수행하는 지도학습을 목적으로 개발되었다. 그러나 현실적으로 종속변수가 존재하는 데이터는 많지 않다. 대부분 데이터들은 종속변수 없이 고차원의 설명변수로만 이루어져 있다. 따라서 종속변수가 없이 설명변수만으로 학습하는 비지도학습을 위한 알고리즘의 개발이 시급하다.
제조업의 현장에서도 딥러닝을 활용한 공정개선, 즉 스마트 공장에 대한 관심이 많다. 공정에서 나오는 많은 양의 데이터 분석을 통해 공정을 통제하여 생산성을 향상시키고, 공정의 환경을 제어하여 효율적인 공장을 만들기 위해 많은 시도들이 이루어지고 있다. 이러한 개선이 성공적으로 이루어지기 위해서는 수많은 센서를 통해 얻은 시계열 데이터 분석이 필수적이지만, 대부분의 센서데이터는 종속변수 없이 수집되고 있다.
따라서 본 논문에서는 종속변수에 대한 상황 정의가 없는 상황에서 딥러닝을 활용하여 다중 센서 기반의 시계열데이터에 대한 군집분석을 수행하는 방법을 제안하고자 한다. 이를 위해 고차원의 센서 데이터를 저차원으로 표현하고, 얻어진 결과를 바탕으로 센서데이터를 군집화하여 공정의 상태를 예측하는 것을 목표로 한다. 이를 위해 가상의 데이터와 차량에서 수집한 실제 시계열데이터를 분석하였고 이로부터 의미 있는 군집화 결과를 도출하였다.

Along with the fourth industrial revolution, smart factories, smart cities and artificial intelligence services and so on are actively developed based on deep learning. Deep learning is performing well in various fields because it can express complex data with high dimensions and many deep learning-based algorithms for various problems have been developed. However, most deep learning algorithms have been developed for supervised learning, which learns the relation between training examples and their associated target variables. Unfortunately, in reality, there is not much data with target variables and most of the data has only high dimensional variables without dependent variables. Such data can also be found in manufacturin field. In the manufacturing field, there is a lot of interest in process improvement and smart factory using deep learning. Because they want to improve productivity and make the factory more efficient by using a large amount of data from the process. This requires analyzing data from a large number of sensors, but most of the data has no target variables. In this paper, time series data from multiple sensors are clustered using deep learning under conditions where target variables are not defined. This allows high-dimensional data to be expressed in low-dimensional compressed representation, and thus are clustered to predict the current state of the data, simulatnously. Experiments that analyzes simulation data and actual time series data collected from vehicles have resulted in meaningful clustering.","#딥러닝, #군집화, #오토인코더, #deep embedding clustering"
딥러닝을 이용한 내부자 위협 탐지,2019,"4차 산업혁명시대에서 정보보호의 중요성이 중요한 이슈로 떠오르고 있다. 그 중에서도 기술정보 유출 방지에 대한 중요성이 대두되고 있다. 기술정보 유출 유형에서 가장 큰 원인이 되는 유형은 조직의 내부자에 의한 기술정보 유출이다. 조직에 대해 잘 아는 내부자는 내부의 정보를 쉽게 접근하여 은밀하게 유출할 수 있으며, 이를 사전에 탐지하여 차단하기 힘들다는 점에서 예방하기가 어렵다.
딥러닝은 컴퓨터의 연산 과정을 인간의 두뇌 형태와 유사하게 구현한 대형 인공 신경망 기반 기계 학습 기술이다. 딥러닝을 이용하면 데이터를 이용하여 상황을 학습하고 이상 상황을 탐지하며 대응하는 능력을 갖게 된다. 예를 들어, 조직원들의 컴퓨터 로그 데이터를 이용하여 일반적인 정상행위를 학습하고, 이 정상행위에서 벗어나는 행위를 비정상 행위로 탐지할 수 있다. 이러한 딥러닝 기술을 이용한 보안 체계가 보안 문제를 해결해 줄 수 있다는 기대 심리가 커지면서 다양한 형태의 딥러닝을 이용한 이상 탐지 연구가 진행되고 있다.

본 논문에서는 딥러닝을 이용하여 내부자 위협을 탐지하는 기법을 연구하였다. 딥러닝 알고리즘 중에서 시계열 데이터의 학습에 적합한 Recurrent Neural Network(RNN)로 구성한 Autoencoder를 구현하여 비정상 행위를 탐지하였고, 오탐율 감소를 위하여 HBOS 알고리즘과 Attention 기법을 추가로 적용하였다. 딥러닝의 실험 데이터로 미국 카네기멜론 대학 Computer Emergency Response Team(CERT) 부서에서 제공하는 내부자 위협 실험용 데이터인 CERT 데이터 세트를 이용하였다. 실험을 통해 제안한 기법이 내부자의 비정상 행위를 효과적으로 탐지하고 기존 연구보다 오탐율을 줄일 수 있음을 확인하였다.

In the era of the 4th industrial revolution, the importance of information security is emerging as an important issue. In particular, the importance of preventing leakage of technical information has been growing. The most common type of technical information breach is leakage of technical information by the organization''s insiders. An insider who is well acquainted with the organization from easily accessing and disclosing internal information secretly, is difficult to prevent and block in advance.
Deep learning is a large-scale artificial neural network based machine learning technology that implements the computational process of a computer similar to that of a human brain. Using deep learning makes us have the ability to learn situations using data, to detect abnormal situations, and to respond it. For example, the computer log data of the members can be used to learn general normal activities, an activity that is not included in such normal activities can be detected as an abnormal activity. As the expectation that the security system using the deep learning technology can solve the security problem, research on the abnormal detection using the various types of deep learning is being conducted.

In this thesis, we have studied a method for detecting insider threats using deep learning. We implemented an autoencoder composed of Recurrent Neural Network (RNN) which is suitable for learning time series data among the deep learning algorithms, to detect abnormal behavior. Then we applied HBOS algorithm and Attention technique to reduce false positives. We used the CERT data set, which is the insider threat experiment data provided by the Computer Emergency Response Team (CERT) department of Carnegie Mellon University, USA, as the experimental data of Deep Learning. Experiments have shown that the proposed technique can effectively detect the abnormal behavior of the insider and reduce the false positive rate than existing research.","#내부자 위협, #딥러닝, #이상 탐지, #Autoencoder, #CERT 데이터세트"
딥러닝 기술을 적용한 식품검사시스템의 정확도 비교,2019,"현재 식품 검사 분야에선 식품의 이물질 포함 유무나 오염도를 확인하기 위해Thresholding 기술을 적용시킨 식품 검사 장비를 가장 선호한다. x선은 물체를 통과 할 때 자신의 고유의 에너지를 일부 잃게 되는데, 잃어버리는 에너지의 양은 물체의 두께와 밀도에 비례한다. Thresholding 기술은 x선이 물체를 통과한 결과로 발생되는 에너지 레벨 차이를 이용하는 방법으로써 기준이 되는 임계값을 설정하고 기준 임계값 이상의 에너지 레벨을 가지는 영역은 정상으로, 이하의 에너지 레벨을 가지는 영역은 에러로 판별하는 방식을 가진다. 하지만 검사체의 밀도와 검사체 내부의 이물질의 밀도가 같거나 비슷한 경우 혹은 여러 종류의 다양한 이물질이 검사체에 섞여서 들어가 있는 경우에는 Thresholding 기술로는 이물질을 판별하는데 어려움이 생기게 된다.
본 연구에서는 실제로 시장에서 사용되고 있는 식품 검사 장비를 이용하여 Thresholding 기술의 단점에 대해 확인하고 그에 대한 해결책으로써 비교적 간단한 레이어를 를 가진 CNN구글사에서 개발한 Inception v3 모델을 이용한 딥러닝 기술을 사용했다. 같은 조건의 이물질과 샘플에 대해서 딥러닝 시뮬레이션 결과와 기존 Thresholding Algorithm이 정확도 측면에서 어느정도 차이를 보이는지 분석하였고 기존 기술에 비해 딥러닝 시뮬레이션의 정확도가 상승한다는 결과를 얻었다. 부가적으로 검사체 내의 제품 개수 누락 등의 문제에 대해서도 딥러닝 기술을 이용시 아주 높은 정확도로 문제를 해결 할 수 있다는 것을 확인하였다. 따라서 본 연구를 통해 식품 검사 분야에서 겪고 있는 고질적인 문제뿐 아니라 무게 센서등의 추가로 발생되는 비용적 측면의 감소등의 이익을 위한 해결책으로 딥러닝 기술을 제시할 수 있는 가능성을 확인 할 수 있었다.","#딥러닝, #식품검사시스템, #검출률"
Metamorphic Relations를 이용한 이미지 분류 딥러닝 모델의 정확성 평가 방법,2019,"이미지 분류 딥러닝 모델은 학습 이미지 데이터를 학습하여 테스트 이미지 데이터의 종류를 예측하는 모델이다. 이미지 분류 딥러닝 모델은 네이버 스마트 렌즈, 구글 이미지 검색등에 사용된다. 그러나 동일한 이미지를 각도만 변경하여 촬영하고 네이버 스마트 렌즈에 검색하면 원래 이미지의 종류와 다른 종류로 검색 결과가 나타나는 문제점이 있다. 따라서 이미지 분류 딥러닝 모델은 이미지의 각도 변경 등을 통해 다양한 테스트를 수행할 필요성이 요구된다.
이미지 분류 딥러닝 모델의 Cross Entropy는 테스트 이미지의 예측 결과가 실제 결과와 어느 정도 차이가 있는지 판별하는 척도로 사용될 수 있다. 올바르게 분류한 테스트 데이터의 Cross Entropy값이 일정 값 이상인 경우 동일한 테스트 이미지에 회전을 적용하면 오분류한 테스트 데이터가 되는 경우가 발생한다. 따라서 이미지 분류 딥러닝 모델의 정확성 평가에 Cross Entropy를 함께 고려할 필요성이 있다.
본 연구에서는 테스트 데이터에 회전과 같은 변형을 적용할 Metamorphic Relation을 정의하여 새로운 테스트 데이터를 생성하고 이미지 분류 딥러닝 모델의 테스트를 수행한다. 그리고 Cross Entropy를 고려한 잠재적 오분류 데이터를 분석하고 기존의 정확성 평가 방법보다 엄격한 딥러닝 모델의 정확성 평가 방법을 제안한다. 그리고 CIFAR-10, CIFAR-100, Fashion-MNIST, STL-10 데이터를 사용하여 학습한 ResNet-32, ResNet-56 모델을 대상으로 본 연구에서 제안한 딥러닝 모델의 정확성 평가 방법을 적용하여 정확성을 평가하였다.

The Image Classification Deep Learning model is a model that predicts the type of test image data by learning the learning image data. Image classification Deep Learning models are used for Naver''s Smart Lens and Google''s. However, there is a problem with changing the angle of the same image and searching on Naver''s smart lens that results in different types of search from the original image. Therefore, the image classification Deep Learning model needs to perform various tests, such as changing the angle of the image.
The Cross Entropy of the image classification Deep Learning model can be used as a measure to determine how far the predicted results of the test image differ from the actual results. If the Cross Entropy value of the correctly classified test data is more than a certain value, applying rotation to the same test image often results in misclassified test data. Therefore, there is a need to consider Cross Entropy together in evaluating the accuracy of the image classification deep learning model.
In this paper, the Metamorphic Relation to be applied to test data, such as rotation, is defined to generate new test data and to perform tests on image classification deep learning models. It also analyzes potential misclassification data considering Cross Entropy and proposes an accurate evaluation method of deep learning model, which is stricter than conventional accuracy evaluation method. In addition, accuracy was evaluated by applying the method of accuracy evaluation of the proposed deep learning model in this study to the models of ResNet-32, ResNet-56, which were learned using CIFAR-10, CIFAR-100, Fashion-MNIST, and STL-10 data.","#딥러닝, #Deep Learning Model"
딥러닝 모델 기반 스케일업 LULUCF 매트릭스 구축에 관한 연구,2019,"본 연구는 2020년 신기후체제에 대응하기 위하여 국제적 기준에 부합하는 국내 온실가스 인벤토리의 LULUCF분야 국가통계 구축 개발을 목적으로 하였다.
우리나라 국가인벤토리보고서(NIR)의 LULUCF분야는 온실가스 통계량을 산정하고 있지만, 각 정부기관별 토지이용 범주에 대한 정의가 다르기 때문에 IPCC가이드라인, LULUCF 우수실행지침 그리고 주요 선진국 NIR의 LULUCF분야 통계구축 시스템 및 토지이용 범주의 정의 기준을 분석하고, 국내 LULUCF분야 통계 및 공간주제도의 정성적·정량적 비교 분석을 통하여 국내 토지이용 특성에 적합한 LULUCF분야 토지이용 범주별 정의를 정립하였다.
국내 NIR에서는 LULUCF분야 중 정주지와 기타 토지에 대한 활동자료가 구축되어 있지 않아 국가산림자원조사(NFI) 고정표본점의 위치를 기반으로 4시기 산림항공사진(1차 1971년∼1974년, 2차 1978년∼1980년, 3차 1986년∼1992년, 4차 1996년∼2005년)을 토지이용 범주별로 판독하여 국가수준 토지이용변화 매트릭스를 구축하였다. 시계열 변화에 따른 토지이용변화 매트릭스 구축 결과, 토지이용 범주별 타토지로의 전용률은 1차→2차와 2차→3차의 경우 습지에서 타토지로의 전용률이 가장 높았으며 특히, 습지에서 농경지로의 변화 사례가 가장 많이 발생하였다. 3차→4차의 경우 초지에서 타토지로의 전용률이 가장 높았으며 특히, 초지에서 산림지로의 변화 사례가 가장 많이 발생하였다.
한편, 온실가스 인벤토리 통계 산출은 투명하고 일관적이며 정확해야한다. 특히, LULUCF분야는 인위적 활동에 의하여 매년 온실가스 배출량 및 흡수량에 영향을 받기 때문에 꾸준하고 체계적인 모니터링이 필요하지만 국가수준 빅데이터를 토지이용의 범주에 맞게 분류하는 것은 시간적·비용적으로 한계가 있기 때문에 딥러닝의 CNN 기법을 적용하여 LULUCF분야 토지이용 판독에 대한 자동화 모델을 개발하였다. 딥러닝 모델 기반 산림항공사진을 토지이용 범주별로 판독한 결과와 육안 판독한 결과와의 정합성 분석 결과, 일치율은 87%이고, 불일치율은 약 13%로 분석되었다. 불일치율을 검증한 결과, 대부분 토지이용 범주의 경계부 지역 또는 토지이용 범주가 혼재된 이미지, 색조가 유사한 토지이용 범주의 이미지로 구분할 수 있었다. 딥러닝 모델을 이용하여 토지이용변화 매트릭스를 1차→2차·2차→3차·3차→4차의 시계열에 따라 구축한 결과, 딥러닝 판독에 의한 토지이용 범주별 변화율은 산림지→농경지, 농경지→산림지의 변화가 육안 판독에 의한 매트릭스의 변화율보다 높았는데, 산림지→농경지와 농경지→산림지는 딥러닝 모델 평가 시 산림지와 농경지 경계부 또는 혼재되어 나타난 데이터세트로 인한 영향으로 판단된다.

The objective of this study was to develop a national statistics framework of LULUCF (Land Use, Land Use Change, Forestry) for the GHG (Greenhouse Gas) invention of South Korea, which satisfies the international standard in order to cope with the paris agreement.
The LULUCF of South Korean National Inventory Report (NIR) estimates the GHG statistics. However, there are difficulties because government agencies have different definitions for land use categories. Therefore, this study analyzed the IPCC guideline, LULUCF good practice guideline, and the LULUCF statistical construction system and land use category definitions of major advanced countries’ NIR. Moreover, this study compared the national statistics and spatial thematic maps of the LULUCF of South Korea qualitatively and quantitatively to define the land use categories of LULUCF suitable for the land use of South Korea.
The NIR of South Korea does not have activity data about the settlement and other lands among LULUCF fields. Therefore, four sets of forest aerial photographs (first survey in 1971-1974, second survey in 1978-1980, third survey in 1986-1992, and fourth survey in 1996-2005) were read for each land use category based on the permanent sample plots of national forest inventory (NFI) and the national-level land use change matrix was established. The time-series land use change matrix showed that the land use change rate from wetland to other land use type was the highest from the first to the second (1→2) and from the second to the third (2→3). Particularly, the change from wetland to cropland was the most frequent. In the case of from the third to the fourth (3→4), the change from grassland to other land use types was the highest. Particularly, the change from grassland to forest land was the most frequent.
On the other hand, the GHG inventory statistics should be calculated transparently, consistently, and accurately. Particularly, it is necessary to monitor LULUCF steadily and systematically because the quantity of GHG emission and absorption annually of it is affected by anthropogenic activities. However, classifying the national-level big data according to the land use categories is limited by time and cost. Therefore, this study developed an automated model for reading the land use in the LULUCF field by using the CNN technique, one of the deep-learning methods. Land use categories were classified by the deep-learning model based forest aerial photos. Moreover, the classification was compared with the manual classification. The agreement rate was 87% and the disagreement rate was approximately 13%. The disagreed areas were reexamined and it was found that they were mostly in the borderline between different land use types, area mixed with multiple land use types, or land use category images with similar color. Using the deep learning model, the land use change matrix was constructed by time (i.e., First→Second, Second→Third, and Third→Fourth). The results showed that the land use type changes by the deep-learning reading showed the higher transition from forest to agricultural land and agricultural land to forest than that by manual classification. It is believed that it was affected by the characteristics of the dataset showing that these two types were adjacent to each other.","#기후변화, #국가온실가스인벤토리, #LULUCF, #토지이용변화, #매트릭스, #국가산림자원조사, #원격탐사, #GIS, #빅데이터, #딥러닝"
기술용어에 대한 분산표현과 딥러닝 모델을 이용한 특허 문헌 자동 분류에 관한 연구,2019,"지식기반사회가 도래하면서 지적재산권의 대표적인 형태인 특허에 대한 중요성이 점점 높아짐에 따라, 특허출원의 수가 급격하게 증가하고 있다. 이와 더불어 융합연구의 활성화로 다중 범주를 갖게 되는 특허 문헌의 수도 함께 늘어나고 있는 추세이다. 이와 같이 분류해야할 특허 문헌의 양적인 증가와 함께 분류의 난이도 또한 함께 높아지고 있지만, 아직까지 특허 문헌에 대한 분류 작업은 여전히 수작업에 의존하고 있다.
특허 문헌에 대한 자동분류 연구가 진행되었지만, 전통적인 방식의 문헌표현 방법과 기계학습 모델을 기반으로 구현된 자동분류 시스템들은 특허 문헌 고유의 특징을 제대로 반영하지 못하고 있어 아직까지 현장에서 사용하기에 부족한 성능을 보여주고 있다.
이 연구에서는 우수한 문헌 표현력을 제공하는 분산표현 방법과 최근 여러 인공지능 분야에서 뛰어난 성능을 보여주고 있는 딥러닝 모델을 이용한 특허 문헌 분류 시스템을 제안하고 그 유용성을 살펴보았다.
이를 위하여 한국 특허 문헌을 수집하여 학습집합을 생성하였고, 자질추출, 자질선택, 그리고 분류모델선택을 조합할 수 있는 실험환경을 구축하였다. 자질추출에서는 품사 정보를 활용하는 방법과 멀티그램을 사용하는 방법을 제공하였고, 자질선택에서는 국소표현과 분산표현 방법을 선택할 수 있도록 하였다. 분류 모델에서는 전통적인 기계학습 모델과 딥러닝 모델을 비교할 수 있도록 환경을 구축하고 실험을 통해 성능을 측정하고 분석하였다. 이 연구의 성능 평가 결과를 요약하면 다음과 같다.
첫째, 자질선택에서 국소표현 방법인 원-핫 벡터와 분산표현 방법인 워드 임베딩 벡터에 대한 비교 실험을 수행하였다. 워드 임베딩 벡터가 특허 문헌 분류의 성능에 더 효과적인 자질선택 방법으로 나타났다.
둘째, 전통적인 기계학습 모델보다 딥러닝 모델이 더 좋은 분류 성능을 보여주었으며, 딥러닝 모델 중에서는 합성곱 신경망(Convolutional Neural Networks, CNN)이 가장 우수한 모델로 판명되었다. 특히, 범주 개수가 많아져 분류에 대한 난이도가 높아질수록 딥러닝 모델이 더 우수한 결과를 보여주었다.
셋째, 분산표현을 제공하는 여러 방법 중에서 FastText를 이용하여 구축된 선학습 워드 임베딩 벡터를 사용하였을 경우가 가장 좋은 분류 성능을 보여주었으며, 모델 학습 시 워드 임베딩 벡터를 고정하지 않고 동적으로 학습에 적용하였을 때가 가장 우수한 것으로 나타났다.
넷째, 자질추출 부분에서 멀티그램 방법으로 단어를 추출하는 방법과 비교하여 형태소 분석기를 적용한 품사 태깅 결과를 이용하여 명사, 형용사, 동사 등을 추출하여 사용하는 방법이 유용한 것으로 판명되었다.
다섯째, 분류를 위한 입력 자질로 초록만을 사용하는 것보다 국문제목과 영문제목을 추가하였을 때, 분류 성능이 향상되는 것으로 입증되었다.

As intellectual properties in many areas becomes more and more important, the number of patent applications is rapidly increasing globally. Moreover, we can notice that the special types of patents embracing various technical fields is also increasing in number due to the surge of interdisciplinary convergence research. Although the quantity and complexity of the recent patents cause difficulty in analyzing them as mentioned above, patent classification task still depends on manual work.
While there have been many academic attempts to automatize the classification task by using various methods such as rules, statistics and machine learning, most of them failed to facilitate the innate characteristics of the patent documents for classifying them via the standard patent classification system, i.e., IPC (International Patent Classification). This paper introduces a new patent classification model utilizing the distributed representations of the composing technical terms in target patent documents based on deep learning models. The important preparation step includes the collection and organization of the training set for the proposed model and the construction of the experimental environments in which feature extraction and selection can be performed to get the optimal models for the ultimate goals. The feature extraction in this paper exploits various lexical information such as part-of-speech and multi-grams for pulling out useful features for target patents. And based on the extracted features, important elements can be selected by applying local and distributed representation.
The proposed experimental environment can enjoy the comparison of various machine learning models based on feature-based methods and representational learning as well as the analysis of the resulting performance using various settings. The results of the study are summarized as follows:
Firstly, among two kinds of the feature selection methods, the use of word embedding vectors, i.e., the distributed representation method, has proven to be significantly superior to the local representation approach based on one-hot vectors.
In addition, the paper showed that the deep learning-based patent classification models outperforms the conventional machine learning approaches. In particular, convolutional neural networks (CNNs) have proven to be the most effective models for the patent classification task in which there are numerous categories to be considered.
Also, it is noticed that among the various distributed representation methods such as Word2Vec, Glove and FastText, FastText showed the best classification results when used by dynamic embedded setting.
Finally, nouns, adjectives and verbs have proven to be useful features for the patent classification and the title information (Korean and English) is also beneficial for the boost of the entire system in addition to the abstract of patents.","#특허 문헌 분류, #기계학습, #딥러닝, #분산표현"
딥러닝 구름 탐지 기반 NOAA/AVHRR 해수면온도 정확도 향상 연구,서울대학교 논문은 저작권에 의해 보호받습니다.,"해수면온도는 해양과 대기 현상을 이해하기 위한 가장 기본적인 변수로써 해수면온도로 해양 상층에 존재하는 다양한 해양 현상을 관측할 수 있으며, 해양-대기와의 상호작용을 통해 기상 및 기후 변화에 직접적인 영향을 미친다. 위성의 적외 영역으로부터 관측한 해수면온도 자료는 청천으로 판단된 화소에서 산출되기 때문에 정확한 해수면온도 산출을 위해서는 구름화소를 탐지하는 과정이 필수적이다. National Oceanic and Atmospheric Administration(NOAA)/Advanced Very High Resolution Radiometer (AVHRR) 영상은 구름 탐지를 위하여 경계값 테스트(threshold tests)가 사용되어왔다. 그러나 경계값 테스트는 정적 임계값(static or partially static thresholds)을 사용하기 때문에 다양한 환경이 나타나는 해역에서는 해수면온도 오차가 크게 나타나는 단점이 있다. NOAA/AVHRR 해수면온도의 정확도 향상을 위하여 딥러닝(deep learning) 기반의 구름 탐지 기법을 개발하였고, 이를 기존 구름 탐지 기법인 경계값 테스트와 비교하였다. 딥러닝 구름 탐지 모델은 한반도 주변 해역을 중심으로 주간과 야간의 복사 특성을 고려하여 구름화소를 정확하게 탐지할 수 있도록 하였으며, NOAA/AVHRR 해수면온도를 산출하기 위하여 활용하였다. 딥러닝 구름 탐지 모델과 경계값 테스트의 구름 탐지 결과를 비교하여 시공간 변동성이 큰 구름 가장자리, 해양 열전선 부근, 용승 시기의 냉수대에서 탁월한 탐지 결과를 보였다. 각 기법을 활용해 산출한 해수면온도 정확도의 정량적인 평가를 위하여 2017년의 NOAA/AVHRR 해수면온도 자료와 해양 실측 수온 자료 간의 일치점을 생산하여 연구에 활용하였다. 딥러닝 모델과 경계값 테스트의 구름 탐지 정확도를 비교하기 위하여 본 연구에서는 두 가지의 데이터셋을 구축하였다(딥러닝 모델을 적용한 해수면온도와 실측 자료, 경계값 테스트를 적용한 해수면온도와 실측 자료). 딥러닝 모델을 적용한 해수면온도는 평균제곱근오차(root mean square error, RMSE) 0.72°C와 양의 편차(bias) 0.06°C의 높은 정확도를 보였으며, 경계값 테스트를 적용한 해수면온도의 경우 RMSE가 1.58°C이고, 편차가 ?0.24°C로 낮은 정확도를 보였다. 이러한 결과로부터 딥러닝 구름 탐지 모델이 NOAA/AVHRR 해수면온도 정확도 향상에 기여함을 확인하였다.

Sea surface tempearture (SST), the most fundamental parameter for understanding oceanic and atmospheric environment, allows observation of various marine phenomena in the upper ocean and directly affects weather and climate change through interaction with the atmosphere. Since sea surface temperature observed in thermal infrared region of the satellite is estimated from the clear sky pixels, a cloud detection procedure is essential for deriving sea surface temperature. National Oceanic and Atmospheric Administration (NOAA)/Advanced Very High Resolution Radiometer (AVHRR) has used threshold tests for cloud detection, however, threshold tests have a common weakness that they employ static or partially static thresholds that do not apply to various environments causing SST errors. To improve accuracy of NOAA/AVHRR sea surface temperature around Korea Peninsula, cloud detection based on deep learning is developed. Comparing deep learning model for cloud detection to threshold tests, deep learning model shows accurate detection both cloudy and clear sky pixels, especially in the area with high spatial and temporal variability such as cloud edges, thermal fronts, and cold upwelling. To compare the accuracy of cloud detection by deep learning model and thresholds tests, we collocated two sets of matchup data; One is of in-situ data and SST with cloud detection using deep learning model (deep learning SST), and the other is of in-situ data and SST with cloud detection by threshold tests (threshold SST). Deep learning SST showed a root mean square error (RMSE) of about 0.72°C and a positive bias of 0.06°C with respect to the in-situ water temperature. Threshold SST showed a RMSE of 1.58°C and a negative bias of -0.24°C with respect to the in-situ water temperature. Therefore, the cloud detection using deep learning model developed in this study has ability to accurately work for detecting cloudy pixels and is verified to contribute to improving accuracy of NOAA/AVHRR sea surface temperature.","#NOAA/AVHRR, #딥러닝, #구름 탐지, #해수면온도, #정확도 검증"
딥러닝을 이용한 라이다 기반 3D 물체 검출 기법 연구 동향,2019.01,,
딥러닝 기반의 자율주행차를 위한 차선 위치 인식 기술,2019.01,,
블루투스 비콘을 활용한 딥러닝 기반 침입 감지 및 행동 인식 시스템 연구,2019.1,,
딥러닝 기반 실시간 손 제스처 인식,2019.01,,
병원 환경에서 딥러닝 기반 동작 인식 장치의 설계 및 구현,2019.1,,
무선 간섭채널에서의 딥러닝 기반 고속 송신전력 최적화,2019.01,,
딥러닝을 이용한 펀드 수익률 예측,2019,"하드웨어의 발전, 빅 데이터의 출현 및 알고리즘 개선 등으로 인하여 2000년대 화려하게 부활한 딥러닝은 음성 인식, 사물 인식, 번역, 의료 산업 등 다양한 분야에 널리 활용되고 있고, 금융 산업 에서도 주가 예측과 알고리즘 거래와 같은 업무에 딥러닝을 적용하기 위해 많은 연구와 노력들이 진행 중이다.
그러나 금융 분야에 딥러닝을 적용한 대부분의 연구는 그 대상이 주식(Stock) 상품에 한정 되어 있고 주제 또한 +1 Day 주가 예측, 예측 성능의 향상 방법 연구, 예측 결과를 통한 거래 모델 제안 등으로 그 범위가 매우 제한 적이다. 특히 2018년 11월 기준 약 530조 자산을 보유하고 있는 우리나라의 대표적인 금융상품인 펀드(Fund)를 딥러닝을 이용하여 분석한 연구는 국내외에서 거의 찾아 볼 수 없는데, 이는 펀드와 주식이 유사한 상품으로 인지되고 있다는 점과 펀드 데이터는 주식과 달리 쉽게 구할 수 없다는 점 등이 원인으로 판단된다.
이에 본 연구에서는 국내에서 10년 이상 운용된 규모 100억 원 이상의 펀드 329개를 MLP, LSTM과 같은 딥러닝 모델에 적용하며 미래 수익률 예측을 시도 한다. 이때 펀드는 장기투자 상품임을 고려하여 +12M 이후의 월 수익률 예측 및 1년간의 누적수익률 등락 예측을 목표로 하였다. 입력변수는 펀드의 규모, 비용, 수익률 그리고 외부지수까지 총 16개로 구성하여 실험 하였고, 그 결과 일부 펀드들에선 성공적으로 예측이 수행됨을 확인 하였다.

Thanks to the advancement of computer hardware, the emergence of big data, and the improvement of algorithms, Deep Learning began to be very popular again in the 2000s and it has been widely used in various fields such as speech recognition, object recognition, translation and medical industry. In the financial industry, a lot of research and efforts are under way to apply deep learning as well.
However, most of the studies applying Deep Learning to the financial field are only about stocks and the subjects are also limited such as predicting +1 day price, researching on how to improve predict performance, and suggesting trading models based on prediction. In particular, there is little research about funds which is Korea''s representative financial product with about 530 trillion assets. This is because funds and stocks are considered very similar products and getting fund data is not as easy as stocks.
In this study, we applied 329 funds(having 10 billion won and running 10 years or more) to the Deep Learning model such as MLP and LSTM and tried to predict future returns. The fund is a long-term investment product so we tried to predict the monthly return after + 12M. The input variables consisted of 16 kinds of things about fund size, cost, profit rate, and external index, and the prediction experiments were very successful in some funds.","#딥러닝, #펀드 수익률 예측, #LSTM, #MLP"
딥러닝 기반 사용자 인식 모델의 학습 지연 단축을 위한 적응형 쓰레드 큐잉 알고리즘,서울대학교 논문은 저작권에 의해 보호받습니다.,"딥러닝과 클라우드 컴퓨팅 기술의 발전으로 인간의 자연어 의미를 이해할 수 있는 기술이 발전하였고, 사용자의 음성 명령을 인식하여 다양한 서비스를 제공하는 음성인식 스피커 시장이 성장하고 있다. 사용자는 음성인식 스피커에 자연어 명령을 하기 위해 먼저 디바이스에 정의된 키워드를 입력하여야 하며, 이것을 키워드 인식(Keyword Spotting) 기술이라 한다. 이 기술은 음성인식 스피커의 대기 소비 전력과 자연어 처리를 위한 클라우드와의 통신량을 줄일 수 있어 대부분의 음성인식 기기에 적용되고 있다. 특정 키워드를 인식한 이후 음악 감상, 검색, 홈 제어, 쇼핑 등의 다양한 서비스가 제공된다.

현재의 키워드 인식 기술은 해당 키워드의 인식률을 높이기 위한 연구들이 주로 이루어졌고, 이를 통해 다양한 노이즈 환경에서도 높은 성능을 보이며 제품에 적용되고 있다. 하지만, 음성인식 스피커에는 하나의 사용자 계정이 등록되어 패밀리 디바이스로 사용됨에 따라 다른 사용자도 키워드 인식만으로 개인 데이터와 정보에 쉽게 접근할 수 있어 보안 취약의 문제점이 발생하고 있다. 이는 개인정보를 기반으로 하는 쇼핑, 금융 등의 서비스 확대에 문제점으로 지적된다. 이러한 음성인식 스피커의 개인정보 보호와 개인화 서비스를 위해서는 사용자 인식(Speaker Recognition) 기술이 필요하게 되었다.

최근 임베디드 디바이스에서도 딥러닝 연산의 최적화를 위한 하드웨어와 소프트웨어 기술들이 발전하였다. 이러한 기술의 발전으로 디바이스 기반의 사용자 인식 시스템은 GPU 가속기를 지원하는 환경에서 모델 학습이 디바이스 내에서 직접 이루어 지고, 완성된 모델을 이용하여 사용자 여부를 판단(inference)한다. 이것은 외부의 네트워크 연결로 인한 제약이 배제되어 사용자 인증의 지연(latency)을 최소화 할 수 있다. 하지만, 임베디드 시스템의 한정된 시스템 자원과 학습을 위한 데이터가 희소함에 따른 한계가 존재한다. 이러한 한계를 해결하기 위하여 본 학위 논문에서는 딥러닝 모델 최적화를 위한 전이학습(Transfer Learning) 기법과 전 처리를 수행하는 CPU와 모델 학습을 수행하는 GPU의 데이터 병렬화 기법인 데이터 입력 파이프라인(input pipeline) 구조를 적용함으로써 디바이스 기반 사용자 인식 모델 학습 시 전체 학습 시간을 단축하고자 하였다.

딥러닝 학습의 데이터 입력 파이프라인(Data Input Pipeline) 구조를 설계함에 있어, 전 처리 과정을 수행하는 다중 쓰레드(Thread) 수가 정의되어야 한다. 하지만, 이는 딥러닝 기반 사용자 인식 모델 학습의 end-to-end latency 분석이 현실적으로 어렵기 때문에 어느 정도의 다중 Thread를 정의하여야 할지에 대한 예측이 불가능하다. 만약 너무 적은 수의 Thread로 전 처리 과정을 수행한다면 GPU 학습을 위한 데이터 셋 전달에 병목현상(bottleneck)이 발생하게 되어 GPU 가속기의 idle 상태가 증가한다. 이로 인하여 GPU utilization을 낮아지게 되고, 결과적으로 전체 학습 시간은 늘어나게 된다. 반면 너무 많은 수의 다중 Thread를 전 처리에 선정하게 되면, 전 처리 과정을 빠르게 진행하여 GPU 학습을 위한 충분한 데이터를 전달하게 되지만, 과도한 다중 Thread로 인한 빈번한 컨텍스트 스위칭(Context switch)와 학습 데이터 큐(Training Data Queue)에 접근 경합 등의 문제를 발생시켜 시스템 자원의 오버헤드(Overhead)를 유발하고 이것은 GPU 가속기의 학습 지연 문제를 일으킨다.

본 학위논문에서는 제시된 문제를 해결하기 위해, 적응형 쓰레드 큐잉(Adaptive Thread Queuing) 알고리즘을 제안한다. 이 알고리즘은 한정된 시스템 자원을 효율적으로 관리하면서 최적의 학습 속도를 유지하고자, 학습 과정의 GPU utilization 예측 정보를 기반으로 런타임에 병목현상과 시스템 오버헤드가 발생할 것을 예측하고, 알고리즘 수행 정책에 따라 전 처리를 수행하는 다중 Thread의 수를 동적으로 변경하여 병목현상과 시스템 오버헤드로 인한 학습 과정의 지연을 단축하는 방법이다. 실험을 통해 제안 알고리즘을 검증한 결과, 학습 과정에서 CPU의 자원을 효율적으로 사용하면서 모델 학습을 위한 GPU utilization은 최대로 유지되었다. 그 결과, 제안된 Adaptive Thread Queuing 알고리즘은 고정된 수의 다중 Thread 학습법 대비, 전 처리 과정에서 발생할 수 있는 지연의 문제를 개선하면서 모델의 전체 학습 속도가 향상되는 것을 확인하였다.

With the development of deep learning and cloud computing technology, the technology to understand the meaning of human natural language has developed, and the speech recognition speaker market which provides various services by recognizing voice commands of users is growing. The user should firstly input a keyword defined in the device in order to perform a natural language command on the speech recognition speaker, and this is called keyword spotting technology. This technology is applied to most voice recognition devices because it can reduce standby power consumption of voice recognition speakers and communication with cloud for natural language processing. After recognizing a specific keyword, various services such as music appreciation, search, home control, and shopping are provided.

Currently, keyword recognition technology is mainly used to increase the recognition rate of the keyword, and it is applied to products showing high performance in various noise environments. However, since a single user account is registered in a voice recognition speaker and is used as a family device, other users can easily access personal data and information only by recognizing a keyword, thereby causing a problem of security vulnerability. This is pointed out as a problem in expanding services such as shopping and finance based on personal information. Speaker Recognition technology is required for personal information protection and personalization service of these speech recognition speakers.

Recently, hardware and software technologies have been developed for the optimization of deep learning operations in embedded devices. With the development of these technologies, device-based user recognition systems are model training directly in a device that supports GPU accelerators, and inference is made using the completed model. This can minimize the latency of user authentication by eliminating the restriction due to external network connection. However, there are limits to the limited system resources of the embedded system and the scarcity of data for model training. To solve these limitations, this thesis proposes a transfer learning method for optimizing the deep learning model, a data input pipeline, which is a data parallelization technique of the GPU that performs preprocessing CPU and model training, We have tried to shorten the total training time when device-based user recognition model.

In designing the data input pipeline structure of the deep learning training, the number of multiple threads performing the preprocessing process should be defined. However, it is impossible to predict how many threads should be defined because end-to-end latency analysis of deep learning based user awareness model training is practically impossible. If the preprocessing process is performed with too few threads, a bottleneck occurs in the delivery of the data set for GPU training, which increases the idle state of the GPU accelerator. This lowers the GPU utilization, which in turn increases the overall training time. On the other hand, if too many threads are selected for preprocessing, the preprocessing process proceeds quickly and delivers sufficient data for GPU training. However, because of frequent context switching due to excessive multithreading and synchronization contention to the Training Data Queue those causes overhead of system resources, which causes training delay problem of GPU accelerator.

In this thesis, we propose an Adaptive Thread Queuing algorithm to solve the presented problems. This algorithm predicts bottleneck and system overhead to occur at runtime based on GPU utilization prediction information of training process in order to maintain optimal training speed while efficiently managing limited system resources. To reduce the delay of training process due to bottleneck and system overhead. Experimental results show that GPU utilization for model training is maximized while CPU resources are used efficiently in the training process. As a result, the proposed Adaptive Thread Queuing algorithm improves the overall training speed of the model while improving the problem of delay that can occur in the preprocessing process, compared to a fixed number of multi - thread training methods.","#딥러닝, #사용자 인식, #키워드 인식, #전처리 지연, #데이터 입력 파이프라인"
심전도와 맥파를 이용한 딥러닝 기반 실시간 혈압 추정 연구,2019.1,,
딥러닝 기술을 기반으로 한 간암 재발 예측에 관한 연구,2019.01,,
딥러닝 기반의 V2X를 이용한 차량 경로 예측,2019.01,,
딥러닝 기법을 이용한 경로 손실 지수 추정 기술,2019.01,,
유사성 학습을 이용한 작은 크기의 딥러닝 분류기 모델의 정확도 향상에 관한 연구,2019.01,,
딥러닝 알고리즘 기반의 기술가치추론을 위한 웹기반 정보시스템에 관한 연구,2019.01,,
딥러닝 기반 자동 변조 분류에서 상관 분석을 통한 분류율 향상 기법,2019.01,,
자율주행자동차를 위한 서라운드뷰 영상에서의 딥러닝 기법을 적용한 차선 추종 시스템 구현 연구,2019,"본 연구는 높은 곡률 도로에서의 자율 주행을 위해 서라운드 뷰 영상과 딥러닝 기법을 이용한 차선 추종 시스템에 대해 다루고 있다.
첨단 운전자 보조 시스템의 대표적인 기능 중 하나는 차선 유지 보조 시스템 이다. 차선 유지 보조 시스템은 전방카메라를 통해 컴퓨터 비젼 기반의 차선 검출을 통하여 차량이 차선을 이탈하지 않도록 보조한다. 최근에는 차선 유지 보조 시스템에서 조금 더 발전하여 차선의 정중앙을 달리게 하는 차선 추종 시스템(lane following system)이 탑재되고 있다. 하지만 전방카메라를 사용할 경우, 높은 곡률의 도로에서는 카메라의 시야(field of view) 한계로 인하여 검출이 불가능 하다. 또한 색상 기반의 연구자가 직접 설계한 특징(hand-craft feature extraction)을 사용한 기존의 차선 검출 방법은 강한 그림자나 빛의 반사 혹은 물웅덩이 등의 노이즈가 나타난 영상에서 오검출의 문제를 야기 할 수 있었다. 따라서 본 연구에서는 이러한 문제를 해결 하기 위해 서라운드 뷰 영상과 딥러닝을 사용한 차선 추종 시스템을 제안 하였다. 또한 제안한 시스템은 차량이 주행 해야할 목표경로를 생성하고, 스탠리 방법을 사용하여 목표 조향 핸들 각을 계산하였으며 이를 통해 주행한 결과를 차선 검출의 강인함 및 시스템 안정성 측면에서 분석하였다.

This study investigates the implementation of a deep learning based lane following system using surround view images for an autonomous vehicles.
A representative function of a ADAS(advanced driver assistance system) is a LKAS(lane keeping assistance system). The LKAS assists the driver in preventing the vehicle from lane departure through computer vision based lane detection using a front camera. In recent years a lane following system has been developed, which is more advanced than LKAS and allows the vehicle to drive in the middle of the lane. However, when the front camera is used, it is impossible to detect lane lines due to the field of view of the camera on a high curvature road. In addition, existing lane detection methods using color-based hand-craft feature extraction could cause false detection in images with noise such as strong shadows, light reflections, and puddles. Therefore, in this study, a lane following system using surround view image and deep learning was proposed to solve this problem. In addition, the proposed system generates a target path for the vehicle to drive, and using the Stanley method to calculate desired steering wheel angle. The driving results using the proposed system are analyzed in terms of robustness and system stability of lane detection.","#자율주행자동차, #차선 추종 시스템, #서라운드뷰, #딥러닝"
딥러닝을 이용한 열 수요예측 모형 개발,2019,"장기적으로는 온실가스 감축을 위해. 그리고 단기적으로는 안정적인 열 공급 서비스를 제공하기 위해서 단기간의 미래 수요를 보다 정확하게 예측하고 효율적인 방법으로 생산 및 공급, 연계하는 것이 매우 중요하다.
특히, 2015년 12월 파리 협정이 체결되면서 국제사회는 온실가스 감축을 위해 적극적으로 노력하고 있다. 우리나라는 이명박 정부에서 제1차 에너지기본계획을 통해 에너지 정책의 기본 방향을 설정했으며, 박근혜 정부 시절 제2차 에너지기본계획에서 6대 중점 과제 중 첫 번째를 ‘수요관리 중심의 에너지정책 전환’을 내세우며 기존 공급관리 중심에서 수요관리로 패러다임이 변화되었다.
지역난방에서도 이와 같은 정책의 실현을 위해 ‘4세대 지역난방’전략을 추진하고 있다. ‘세대 지역난방’은 도시 및 건물 분야 온실가스 감축을 위한 주요 수단 중의 하나로 에너지 신사업 육성을 위한 핵심기술로, 신재생 에너지 활용, 60도 이하의 저온수 난방 등 기술적인 방법 이외에도 스마트 써멀 그리드(Smart Thermal Grid)를 통해 다양한 열원끼리의 열 거래를 실현하여 열 공급 사업자 간 열 연계를 활성화한다.
열 연계는 열 수요예측을 통해 공급을 계획하고 열 수송 네트워크를 통해 수요지에 열을 공급하는 것을 의미한다. 효율적인 열 연계를 구현하기 위한 가장 기본적인 기능이 바로 안정적인 열 수요예측이다. 이 때, 열 수요예측이 정확하지 않다면 효율적인 생산 계획을 수립하고 실현할 수 없다. 예를 들어 수요를 과소예측하게되면 부족분에 대해서는 LNG와 같은 값비싼 열원을 사용하여 생산원가가 높아지게 된다. 반대로 수요를 과대예측하게 되면 저장이 어려운 열 특성으로 인해 낭비가 발생하게 된다.
그러나 열 수요에 영향을 미치는 요인은 매우 다양하고 개별 소비자 및 지역적 특성에 따라 소비 형태가 달라지기 때문에 일반적인 상황에도 적용할 수 있는 범용적인 열 수요 예측 모델을 개발하는 것은 쉽지 않다.
기존 연구는 지역적 특성에 따른 열 수요 예측에 영향을 미치는 다양한 변수를 모두 고려하는 모델을 제시하고 있다. 그러나 이는 해당 지역을 벗어나 타 지역에 적용할 경우 동일한 수준의 성능을 보장할 수 없다. 뿐만 아니라 다중선형회귀분석 기반의 모델은 온도에 대한 열 수요의 비선형적인 특징을 반영할 수 없다.
따라서 본 연구는 실시간으로 확보할 수 있는 제한적인 정보만으로 딥러닝 기법을 활용하여 열 수요의 비선형적인 특징을 학습하는 범용적인 열 수요예측 모델을 제안하고자 한다.","#딥러닝, #인공지능, #RNN, #LSTM, #수요예측"
딥러닝 및 질감 분석을 활용한 잡음 환경에서의 음향 이벤트 분류 시스템,2019,"센서 기술과 컴퓨팅 성능의 향상으로 인한 데이터의 폭발적인 증가는 산업 현장의 상황을 분석하기 위한 토대가 되었으며, 이와 같은 데이터를 기반으로 현장에서 발생하는 다양한 이벤트를 분류하려는 시도들이 최근 증가하고 있다. 특히 음향 센서에서 수집된 음향 신호는 상대적으로 저가의 가격으로 현장 정보를 왜곡 없이 효과적으로 수집할 수 있다는 큰 장점으로 다양한 응용 분야의 이벤트를 분류하기 위한 중요한 정보로 사용되고 있다. 그러나 소리 취득 시 발생하는 잡음을 제어하지 못한다면, 이벤트 분류 시스템을 구현 후 현장에 설치 시 분류 성능을 보장할 수 없다. 즉, 실제 적용이 가능한 시스템을 구현하기 위해서는 산업 현장에서 발생하는 다양한 잡음 상황에도 강인한 성능이 보장되어야 한다. 따라서 본 연구에서는 질감 분석과 딥러닝을 활용하여 잡음 환경에서도 강인한 성능을 보이는 음향 이벤트 분류 시스템을 제안한다.
질감 분석을 활용한 연구에서는, 유독 잡음에 취약한 구조적 약점을 갖는 음향 신호의 문제점을 해결하는 차원에서 이미지를 대상으로 잡음 문제를 해결한 DNS 알고리즘을 음향 신호에 최초로 적용하고자 한다. 제안하는 시스템은 DNS가 이미지 분야에서 잡음에 대해 강인하다는 가설을 음향 신호 영역에서 새로이 검증하며 응용 영역을 음향 신호까지 확장하고자 한다.
딥러닝을 활용한 연구에서는, 잡음의 영향을 개선 시켜 잡음이 제거된 음향 신호를 생성한 후, 해당 음향 신호를 분류까지 할 수 있는 시스템을 제안한다. 제안하는 시스템은 GAN을 기반으로 VAE 기술을 적용한 SEGAN을 활용하여 아날로그 음향 신호 자체에서 잡음이 제거된 신호를 생성하였으며, 향상된 음향 신호를 데이터 변환과정 없이 CNN 구조의 입력 데이터로 활용한 후 음향 이벤트에 대한 식별까지도 가능하도록 end-to-end 기반의 음향 이벤트 분류 시스템을 설계한다.
산업 현장에서 취득한 음향 데이터를 활용하여 제안하는 시스템의 성능을 실험적으로 검증한바, 질감 분석을 활용한 시스템에선 98.80%(철도산업)와 96.57%(축산업)의 f1 score를 보였고, 딥러닝을 활용한 시스템에선 99.29%(철도산업)와 97.80%(축산업)의 f1 score를 확인하였다. 또한, 딥러닝을 활용한 음향 이벤트 분류 시스템은 질감 분석을 활용한 시스템보다 음향 이벤트 하나당 수행시간 측면에서 철도산업 분야에선 1.36배, 축산업 분야에선 1.78배의 향상된 성능을 확인하였다.","#음향 이벤트 분류, #딥러닝, #질감 분석, #잡음 견고성, #음향 신호 생성"
딥러닝을 위한 매트랩과 파이썬 프로그램 연동 방법,2019.1,,
딥러닝 기반 얼굴 인식 시스템의 정확도 향상 연구,2019.01,,
WiFi 채널 상태 정보를 이용한 딥러닝 기반 호흡 및 심박 패턴 인식 방법,2019.01,,
IMU 센서와 WiFi 지문대조기술 기반의 딥러닝 실내위치인식 시스템,2019.01,,
CPU 기반 장치에서 효율적인 딥러닝 추론을 위한 컨볼루션 신경망의 가속 방법의 성능 비교,2019.01,,
딥러닝을 이용한 한국수화언어 통역 시스템 설계 및 구현,2019,"한국수화언어는 한국수화언어법으로 국어와 동등한 지위의 언어이고 청각장애인의 언어권을 신장하고 삶의 질을 향상하는 것을 목적으로 한다고 규정되어 있다. 한국수화언어 사용에 따른 소통의 어려움이 없어야 하지만, 한국수화언어를 사용하는 농인(聾人) 및 청인(聽人)과 한국어를 사용하는 일반인의 소통을 위해서는 일반이 한국수화언어를 배워야 하는 어려움이 있다. 이러한 소통의 문제 개선하기 위해 한국어를 사용하는 일반인이 한국수화언어의 의미를 이해할 수 있도록 딥러닝을 이용한 한국수화언어 통역 시스템을 제안하고자 한다.
한국수화언어 통역 시스템은 한국수화언어 특징 추출 모듈과 한국수화언어 통역 모듈로 구성된다. 한국수화언어 특징 추출 모듈은 객체 검출 모듈로, 손과 손가락 모양인 수형의 종류 및 얼굴 종류의 확률과 위치 정보를 추출한다. 한국수화언어 특징 추출 모듈은 한국수화언어 특징을 71개의 클래스로 분류하여 검출 할 수 있으며, 연산량은 0.615 BFLOPS로, CPU 연산을 사용한 객체 검출 소요 시간은 75ms이다. 한국수화언어 특징 추출 모듈 정확도 성능은 mAP(mean Average Precision) 94.02%, F1-score 87%, 평균 IoU 61.24%이다. 마지막으로 한국수화언어 특징 추출 모듈 크기는 6.92MB로 경량화된 모듈이다.
한국수화언어 통역 모듈은 한국수화언어 특징 추출 모듈을 사용하여 추출된 정보를 바탕으로 한국수화언어 중 자연수화언어 동작(단어)을 통역하는 모듈이다. 한국수화언어 통역 모듈은 한국수화언어 일상생활 대표 표제어 10개를 대상으로 제작되었고, 한국수화언어 통역 모듈의 정확도는 훈련에 사용되지 않은 평가 데이터 1,760개로 평가 시 95.85%로 나타났다. 한국수화언어 통역 App은 멀티스레드 기법을 적용하면 CPU 연산 사용 시 한국수화언어 통역에서 출력까지 25ms 소요되며, 28 FPS의 성능을 나타냈다. 이는 실시간으로 한국수화언어 통역이 가능한 성능이라 평가된다.
딥러닝을 이용한 한국수화언어 통역 시스템의 연구 가치는 다음과 같다. 첫째, 한국수화언어 통역 시스템은 실시간 통역 성능을 가진다. 둘째, 특수장비가 필요 없고 GPU와 같은 고성능 하드웨어를 필요로하지 않는다. 셋째, 한국수화언어 훈련 데이터 수집이 용이하다. 마지막으로 PC 및 증강/혼합현실용 HMD와 같은 웨어러블 디바이스와 모바일 디바이스에 포팅이 가능하다.

The Korean Sign Language is defined as the language of the Korean Language equivalent to that of the Korean Language, and aims to enhance the language of the deaf and improve the quality of life. There is no difficulty in communicating using the Korean Sign Language. However, it is difficult for the general person to learn Korean Sign Language to communicate with the deaf and the hearer who use Korean Sign Language and the public using Korean Language. In order to improve the communication problem, we would like to propose a Korean Sign Language Interpretation System Using Deep Learning to understand the meaning of Korean Sign Language.
The Korean Sign Language Interpretation System consists of the Korean Sign Language Feature Extraction Module and the Korean Sign Language Interpretation Module. The Korean Sign Language Feature Extraction Module is an object detection module that extracts the type and face type probability and position information of hand and finger shape. The Korean Sign Language Feature Extraction Module can detect and classify Korean Sign Language features into 71 classes. The calculation amount is 0.615 BFLOPS and the object detection time using CPU operation is 75ms. The accuracy of the Korean Sign Language Feature Extraction Module is 94.02% for mean average precision (mAP), 87% for F1-score, and 61.24% for average IOU. Finally, the Korean Sign Language Feature Extraction module size is 6.92MB, which is a lightweight module.
The Korean Sign Language Interpretation Module is a module that interprets the natural sign language behavior (words) among the Korean Sign Language based on the information extracted using the Korean Sign Language Feature Extraction Module. The Korean Sign Language Interpretation Module was produced for 10 representative headlines of Korean Sign Language, and the accuracy of the Korean Sign Language Interpreter Module was 95.85% when 1,760 evaluation data were not used for training. The Korean Sign Language Interpreter App has a performance of 28 FPS, which takes 25ms from the Korean Sign Language Interpretation to the output when the CPU operation is applied using the multi-thread technique. This is evaluated as the ability to interpret Korean Sign Language in realtime.
The study value of the Korean Sign Language Interpretation System Using Deep Learning is as follows. First, the Korean Sign Language Interpretation System has realtime interpretation performance. Second, it does not require special equipment and does not require high-performance hardware such as a GPU. Third, it is easy to collect Korean Sign Language training data. Finally, it is possible to port to wearable devices and mobile devices such as PC and HMD for augmented/mixed reality.","#수화(Sign Language), #한국수화언어, #한국수화, #한국수어, #딥러닝, #통역, #한국수화언어 통역 시스템, #수화 통역, #객체 인식"
롤 각 센서가 없는 C형 스프링 기반 저가형 반능동현가 시스템을 위한 AI 딥러닝 기반 롤 각 추정기와 롤 각 감소를 위한 Fuzzy 제어기 설계,2019,"자동차의 현가장치는 노면으로부터의 진동과 충격을 흡수해주는 역할을 한다. 수동 현가장치의 특성상 고정된 특성값으로는 승차감과 조종안정성 두 가지 모두를 만족할 수는 없다. 이를 해결하기 위해 많은 연구가 진행되었으며, 그 중에서도 반 능동 현가장치와 능동 현가장치가 많이 개발되어 왔다.
본 논문에서는 저가형 SUV에 들어가는 저가형 반능동 현가장치에 대해 연구하였고, 롤 각 추정기를 사용하여 롤 각 센서 추가 장착 없이 제어가 가능토록 하였다.
차량 동역학을 통해 AI 딥러닝 기반 롤 각 추정기에서 필요한 입력변수를 검증하였고, 대상차량의 실험데이터가 입력된 Carsim을 이용하여 학습데이터를 추출하였다. 딥러닝 라이브러리인 Tensorflow를 통해 학습을 했고, 학습을 통해 나온 모델을 다시 Matlab Simulink와 Carsim의 Cosimulation을 통해 롤 추정기를 검증하였다. 또한 실제 산업에서 가장 많이 쓰이는 PID 제어기를 통해 제어기에 적용가능성을 검증하였다.
상황에 따라 Fuzzy논리를 사용하여 Rule-Base 기반 Fuzzy 제어기를 구현했고, 이를 통해 스프링의 회전 각도를 이용하여, 롤 각 감소를 제어할 수 할 수 있게 하였다. 제어기 또한 Simulink와 Carsim의 Co-simulation을 통해 검증하였다.

Suspension system of vehicles relieves the shock and vibration from road surface. However, passive suspension system by its nature is unable to simultaneously provide steering stability and comfort of passengers at certain fixed characteristic constants.
Hence, in this study, low-priced Semi-active suspension system for low-priced Sports Utility Vehicle (SUV) was investigated, and vehicle control without the addition of roll angle sensor was enabled by using roll angle estimator.
입력 variables for learning data for deep-learning based on artificial intelligence(AI) were established from vehicle roll dynamics and vehicle lateral dynamics. The learning data of 16 driving situations were extracted from ''Carsim'' which is a simulation program containing the target vehicle''s experimental data. After performing deep-learning in ‘Tensorflow Library,’ the roll angle estimator with the learned model was verified with a co-simulation of Matlab''s Simulink and Carsim. The roll angle estimator''s usability was then proved by comparing the PID controller with roll angle estimator based on AI and the PID controller with general roll angle sensor.
Also, to control the roll angle of low-priced SUV, a fuzzy controller was designed based on the 9 Rule-Base in various situations. With the rotation of curved spring’s angle based on this fuzzy controller, the roll angle of low-priced SUV was shown to decrease, thus controlled. The fuzzy controller based on Rule-Base also was verified with a co-simulation of Matlab''s Simulink and Carsim.","#AI 딥러닝(AI Deep Learning), #롤 각 추정기(Roll Angle Estimator), #퍼지제어기(Fuzzy Controller), #반능동 현가 장치(Semi-Active Suspension), #C형 스프링(Curved Spring)"
품사 정보를 활용한 문서 분류 시 딥러닝의 성능 향상 방법,2019,"본 논문에서는 딥러닝을 활용하여 문장 분류 시 정확도를 향상시키기 위해 품사 정보를 활용하는 방법에 대해 연구하였다. 문서 분류를 위한 딥러닝 학습 시 각 단어의 품사 정보를 추출 후 정보를 수치화 한 후에 Input Feature로 추가하였을 때의 딥러닝 학습의 영향도를 알아보았고, 이어서 동사, 명사와 같이 문장의 전체적인 의미를 파악하는 데 있어서 중요한 역할을 할 수 있는 품사들에 대해 다른 품사들과는 다른 특징점이 나타나는 Input Feature를 추가하였을 시 딥러닝 학습의 영향도를 확인해보았다. 끝으로 문서 종류와 품사 종류와의 연관성을 실험 결과를 통해 도출해 보고, 문서 종류별로 강조해야 하는 품사 종류에 대해서 연구해 보았다.","#딥러닝, #CNN, #품사정보"
딥러닝 객체 검출을 이용한 로봇 팔 제어 시스템,2019.01,,"#로봇 팔(Robot Arm), #객체 검출(object detection), #객체 집기(Object Picking)"
딥러닝을 이용한 광학위성영상 활용기술 동향 분석,2019.1,,
딥러닝 기반 차량 자율주행 연구,2019,"최근 인구 급증과 고령화 사회로 인한 교통 문제가 사회적으로 대두되고 있다. 이에 운전자의 주행에 도움을 주는 시스템인 첨단 운전자 보조 시스템(Advanced Driver Assistance System, ADAS)이 상용화 되고 있으며, 이는 자율 주행 자동차의 핵심 기술이다. 차량은 위치를 기반으로 주행하므로 차량의 위치 정보 정확도 및 신뢰성은 매우 중요하다. 본 논문에서는 복잡한 수학적 모델 대신 딥러닝을 기반으로하는 차량 위치 추정 시스템 알고리즘에 대해 연구하였다.
차량 위치 추정을 위한 입력 데이터로는 C/A 코드 기반 GNSS 위치해, IMU센서의 yaw, 차량 내부 센서 휠스피드를 통해 계산된 속도 데이터를 사용하였다. 본 연구의 알고리즘은 모두 지도 학습으로 진행되었으므로, 후처리로 계산된 POSLV의 위치해를 참조 데이터로 설정하였다.
딥러닝 알고리즘으로는 MLP(Multi-Layer Perceptron)와 LSTM(Long Short-Term Memory)을 통해 차량의 위치추정 모델을 구축하였다. 두 모델을 비교해본 결과, 시계열로 발생하는 차량의 위치를 추정하는 모델은 LSTM이 적합하였다.
차량의 위치를 예측하는 모델을 만들기 위해 센서의 주기를 동일하게 설정해주었다. IMU와 휠스피드 센서는 100Hz로 출력되고 GNSS센서는 1Hz이므로, 모델을 만들 때는 GNSS센서 데이터를 내삽하여 주기를 맞췄다. 모델에 대입하여 위치를 추정할 때는 차량의 속력을 기반으로 외삽하여 만든 GNSS 위치해를 LSTM 모델에 입력하여 진행하였다. 실제 차량 데이터는 내삽할 수 없으므로 외삽된 값을 입력하였으며, 이는 실제 차량의 위치가 아니므로 오차가 누적되어 위치가 발산하는 형태를 보였다. 그러나 그 결과로 나온 예측값은 C/A 코드 기반의 GNSS 항법해를 단독으로 사용했을 때 보다 정확한 것으로 나타났다.
또한 자율 주행 자동차의 가장 큰 문제점은 도심환경에서의 위치 추정이다. 도심지에서는 교차로, 터널, 고층빌딩 등으로 인해 GNSS 신호 단절과 멀티패스의 영향으로 정확한 위치를 추정하기 어렵다. 따라서 본 연구에서는 임의로 신호 단절 구간을 가정하여 실험한 결과, 신호 단절구간에서도 차선 구분이 가능한 정도의 정확도를 유지할 수 있었다.","#GNSS, #딥러닝, #자율주행 자동차"
딥러닝을 이용한 카메라 기반 신호등 인식 및 라이다 기반 칼라 영상 생성,2019,"Recently, deep learning has become increasingly popular in the field of vision based object classification, detection, and recognition as well as image generation. This dissertation deals with camera based traffic light (TL) recognition and light detection and ranging (LiDAR) based color image generation methods using deep learning networks for automotive vehicle systems.
In this study of the deep leaning based TL recognition, first of all, We have analyzed what color space is efficient. Six color spaces and three ensemble network models are applied and analyzed. Our simulation results show that the best performance is achieved with the combination method of RGB color space and Faster R-CNN with Inception-Resnet-v2. However, the conventional method has limited performance in several traffic lights with both small size and types of yellow, green-left, and off. To solve the problem, novel two-staged deep learning based TL recognition methods are proposed. To efficiently reduce the number of weight parameters and computational complexity, semantic segmentation technique and fully convolutional network (FCN) are applied. A binary-semantic segmentation network is proposed to detect small size TLs. We also propose a novel TL classification network including a convolution layer with three filters of (1×1). The simulation results show that the proposed TL recognition method outperforms the conventional Faster R-CNN network model with Inception-Resnet-v2 in terms of recognition performance, and it remarkably reduces the computational complexity and hardware requirements. The TL recognition method achieves up to 44.5% in overall mAP and 70.16% in mAP@0.5. Especially, the empirical results show that the proposed method gives great improvement for the detection and recognition of small TLs. The proposed method can also be implemented in real-time processing with the sacrifice of a minor decrease in recognition performance.
In the study of the deep leaning based color image generation from Lidar data, we propose a color image generation method from LiDAR 3D reflection intensity. The proposed method consists of 3D-to-2D projection and an image generation network (IGN). For the IGN, symmetric and asymmetric structured FCN are compared. Especially, an asymmetrically structured FCN is designed considering the sparseness of the projected reflection image. Through simulations, it is shown that the proposed method generates fairly good visual quality of images while maintaining almost the same color as the ground truth image. In particular, the asymmetrically structured FCN with a deeper decoder than encoder generates a higher-quality color image. Until the total number of layers reaches a certain number, the quality of the generated image monotonically increases. The proposed asymmetric FCN based color IGN model achieves up to 19.38 dB in peak signal-to-noise ratio and 0.5 in structural similarity index. In addition, the proposed IGN can generate shadow-free color images from LiDAR sensor data. We expect that the proposed method can generate daytime color images at night because the same LiDAR data can be obtained whether it is day or night.","#딥러닝, #신호등 인식, #칼라 영상 생성, #카메라 센서, #라이다 센서"
딥러닝을 활용한 온라인 커뮤니티 상의 빅데이터 텍스트 분류 방법,2019,"온라인 커뮤니티란 컴퓨터를 매개로 한 사회 집단을 말한다. 인터넷이 보급되고 본격적인 온라인 커뮤니티들이 등장함에 따라 이러한 텍스트들을 목적에 따라 분류하거나 검색을 할 수 있는 기술이 필요하게 되었다. 이러한 텍스트들의 분류는 사람이 직접 하기에는 한계가 있기 때문에 인공지능 분류작업이 필요하다. 마케팅 측면에 있어서 또한 어떤 데이터가 사용자에게 있어서 유의미한지 무의미한지를 파악하는 것은 중요하다. 따라서 본 연구에서는 요즘 들어 많은 관심을 받고 있는 딥러닝 기법 중 합성곱 신경망을 텍스트 분류 문제에 적용하였다. 의료 웹 포럼의 AIDS 관련 게시판 글을 수집하여 성별을 분류할 수 있고, 온라인 게임 ‘Archeage’의 채팅글을 수집하여 욕설을 분류할 수 있는 합성곱 신경망을 구축했다. 합성곱 신경망은 주로 이미지 처리 분야에서 쓰는 모델이었으나 최근 다양한 텍스트 분류 작업에서 우수한 분류 성능을 달성하고 새로운 텍스트 분류 아키텍쳐의 표준 기준이 되었다. 본 연구에서 실험한 결과 구축한 합성곱 신경망은 기존 텍스트 분류에서 널리 사용되는 기계학습 알고리즘인 Naive Bayes, Support Vector Machine 및 Random Forest에 비하여 시간 및 정확도 측면에서 모두 뛰어난 성능을 보였다. 또한 기존 연구들은 영어를 처리한 연구가 많지만, 본 연구에서는 한국어 텍스트 또한 같이 다루어 보았다. 구축한 합성곱 신경망의 분류 성능을 측정한 결과 성별 분류에 있어서는 90% 이상의 정확도를, 욕설 분류에 있어서는 89% 이상의 정확도를 나타냈다. 이러한 결과들을 바탕으로 딥러닝 기반 텍스트 분류 시스템이 영어 뿐 아니라 한국어의 텍스트 분류에도 잘 작동함을 알 수 있다.","#딥러닝, #빅데이터, #텍스트 마이닝, #텍스트 분류"
효율적인 딥러닝 기반 식물 병해 인식과 글로컬 증상 기술 연구,2019,"식물의 병해과 충해을 인식하는 것은 농업 분야에서 주요한 과제입니다. 국경을 넘나들며 발생하는 식물 병해와 해충의 피해는 농부들에게 심각한 손실을 초래하고 식량작물에 악영향을 미치기 때문에 식량안보를 위협합니다. 기존에는 식물 병해와 해충을 알아보기 위해, 해당 분야의 전문 지식을 가진 인력이 현장에 투입되어 작물을 검사하였습니다. 그러나 전문 지식을 가진 인간이 검사를 수행하더라도 일말의 불확실성이나 오류가 발생할 가능성이 있으며, 이를 조정하면 부정확한 결론에 이르기도 하였습니다.

딥러닝 기술은 시간의 경과에 따라 정확도가 높아지고 있으며, 이를 이용하여 복잡한 문제들을 해결해왔습니다. 이러한 성공에 부응하여 관련 기술에 대한 관심이 증폭되고, 더불어 농업 분야에서 높은 활용 가능성 때문에 딥러닝을 이용한 여러 접근법이 농업 분야에서 모색되었으며 이를 사용하여 효율적인 자율 시스템이 가능할 것으로 생각됩니다. 또한 식물의 이상증상 인식을 위한 non-destructive methods와 같은 실질적 해결 방법도 적용되어 왔습니다. 그러나 이 분야의 발전에도 불구하고, 특히 실제 현장 시나리오에서 효율성이 아직 부족합니다. 이에 대응하여 우리는 식물의 병해와 충해 증상을 인식하고 작물에 적절한 조치가 가능한 기술을 저비용으로 농부들에게 제공하는 솔루션을 제안합니다.

우리는 작물의 이상 상태를 진단하기 위한 3 가지 효율적인 딥러닝 기술을 제시합니다.
첫째로 실제 현장에서 적용 가능한 시나리오에서 식물 병해 및 충해의 유형과 발생 위치를 탐지하기 위해 deep meta-architecture 및 feature extractor를 기반으로, 실용적이고 적용 가능한 솔루션을 제안합니다.
둘째로 “Refinement Filter Bank”라는 진단 기능을 도입하여 데이터 세트에서 부족한 데이터가 있는 경우에 발생하는 클래스 불균형과 false positive 문제를 해결합니다.
세째로, end-to-end framework을 제안하고 이를 deep meta-architecture 및 feature extractor의 성능과 결합하여 작물의 이상 상태를 인식하는 한편 이 인식 결과를 recurrent neural networks를 사용하여 증상들 간의 상호 관계에 대한 상세한 설명을 구성하는 방법을 제안한다.

최종적으로 우리는 연구 목적을 위해 특별히 수집되고 주석이 달린 2개의 데이터 세트[a) 토마토 식물 병해 및 충해 데이터 세트, b) 토마토 식물 변형에 대한 설명 데이터 세트]로 질적 및 양적 실험을 수행하여 성능을 검증하였습니다. 실험 결과 복잡한 실제 상황에도 불구하고 식물의 기형 상태와 이상 증상이 성공적으로 인식되고 증상이 잘 묘사된 것을 확인할 수 있었습니다.
또한 본 연구는 기계화된 농업 환경에서 작물의 상태를 모니터링하는 효율적인 시스템을 구성하고 이를 검증했기 때문에 이 주제에 관한 향후 연구의 잠재적 목표를 제시합니다.

Plant diseases and pests recognition is a major challenge in the agricultural sector. Trans-boundary plant diseases and pests affect crops, causing several losses to farmers and threatening food security. Traditionally, crop inspection has been carried out by people with some expert knowledge in the field. Regarding any activity carried out by humans, this activity is subject to generate a degree of uncertainty or error, and consequently, leads to incorrect decisions to control them.

Deep learning has solved complicated applications with increasing accuracies over time. The recent interest in this type of technology, and especially in its potential application in agriculture, has powered the growth of efficient systems and their application to real problems, such as the case of non-destructive methods for plant anomalies recognition. Despite the advances in the area, there remains a lack of efficiency, especially in real-field scenarios. Instead, our research proposes cost-efficient solutions that besides being able to recognize plant anomalies and symptoms, provide farmers with a technology that facilitates proper handling of crops.

We present three efficient deep learning techniques for plant anomalies recognition. The first method proposes a practical and applicable solution based on deep meta-architectures and feature extractors, to detect the type and location of plant diseases and pests in real-field scenarios. The second addresses the problems of class imbalance and false positives that occur especially on datasets with limited data, through the introduction of a diagnosis function called “Refinement Filter Bank”. The third method proposes an end-to-end framework that, on the one hand, combines the capabilities of deep meta-architectures and feature extractors for plant anomalies recognition and, on the other hand, incorporates the ability of recurrent neural networks to also generate detailed descriptions of the symptoms and their interactions in the scene.

Finally, we validate the performance of our methods on our two datasets which have been specifically collected and annotated for our research purpose: a) Tomato Plant Diseases and Pests Dataset and, b) Tomato Plant Anomalies Description Dataset. Qualitative and quantitative results show that, despite the complexity of real-field scenarios, plant anomalies and symptoms are successfully recognized and described. The insights drawn from these results led to better understand the strengths and limitations of plant anomalies recognition. Furthermore, our research suggests some potential targets for future research on the subject, since it constitutes an efficient tool to monitor the state of crops in precision agriculture.","#Deep learning, #plant diseases, #pests, #recognition, #glocal description, #localization, #딥러닝, #식물질병, #해충, #인식, #글로컬 기술, #현지화"
효율적인 딥러닝 기반 식물 병해 인식과 글로컬 증상 기술 연구,2019,"식물의 병해과 충해을 인식하는 것은 농업 분야에서 주요한 과제입니다. 국경을 넘나들며 발생하는 식물 병해와 해충의 피해는 농부들에게 심각한 손실을 초래하고 식량작물에 악영향을 미치기 때문에 식량안보를 위협합니다. 기존에는 식물 병해와 해충을 알아보기 위해, 해당 분야의 전문 지식을 가진 인력이 현장에 투입되어 작물을 검사하였습니다. 그러나 전문 지식을 가진 인간이 검사를 수행하더라도 일말의 불확실성이나 오류가 발생할 가능성이 있으며, 이를 조정하면 부정확한 결론에 이르기도 하였습니다.

딥러닝 기술은 시간의 경과에 따라 정확도가 높아지고 있으며, 이를 이용하여 복잡한 문제들을 해결해왔습니다. 이러한 성공에 부응하여 관련 기술에 대한 관심이 증폭되고, 더불어 농업 분야에서 높은 활용 가능성 때문에 딥러닝을 이용한 여러 접근법이 농업 분야에서 모색되었으며 이를 사용하여 효율적인 자율 시스템이 가능할 것으로 생각됩니다. 또한 식물의 이상증상 인식을 위한 non-destructive methods와 같은 실질적 해결 방법도 적용되어 왔습니다. 그러나 이 분야의 발전에도 불구하고, 특히 실제 현장 시나리오에서 효율성이 아직 부족합니다. 이에 대응하여 우리는 식물의 병해와 충해 증상을 인식하고 작물에 적절한 조치가 가능한 기술을 저비용으로 농부들에게 제공하는 솔루션을 제안합니다.

우리는 작물의 이상 상태를 진단하기 위한 3 가지 효율적인 딥러닝 기술을 제시합니다.
첫째로 실제 현장에서 적용 가능한 시나리오에서 식물 병해 및 충해의 유형과 발생 위치를 탐지하기 위해 deep meta-architecture 및 feature extractor를 기반으로, 실용적이고 적용 가능한 솔루션을 제안합니다.
둘째로 “Refinement Filter Bank”라는 진단 기능을 도입하여 데이터 세트에서 부족한 데이터가 있는 경우에 발생하는 클래스 불균형과 false positive 문제를 해결합니다.
세째로, end-to-end framework을 제안하고 이를 deep meta-architecture 및 feature extractor의 성능과 결합하여 작물의 이상 상태를 인식하는 한편 이 인식 결과를 recurrent neural networks를 사용하여 증상들 간의 상호 관계에 대한 상세한 설명을 구성하는 방법을 제안한다.

최종적으로 우리는 연구 목적을 위해 특별히 수집되고 주석이 달린 2개의 데이터 세트[a) 토마토 식물 병해 및 충해 데이터 세트, b) 토마토 식물 변형에 대한 설명 데이터 세트]로 질적 및 양적 실험을 수행하여 성능을 검증하였습니다. 실험 결과 복잡한 실제 상황에도 불구하고 식물의 기형 상태와 이상 증상이 성공적으로 인식되고 증상이 잘 묘사된 것을 확인할 수 있었습니다.
또한 본 연구는 기계화된 농업 환경에서 작물의 상태를 모니터링하는 효율적인 시스템을 구성하고 이를 검증했기 때문에 이 주제에 관한 향후 연구의 잠재적 목표를 제시합니다.

Plant diseases and pests recognition is a major challenge in the agricultural sector. Trans-boundary plant diseases and pests affect crops, causing several losses to farmers and threatening food security. Traditionally, crop inspection has been carried out by people with some expert knowledge in the field. Regarding any activity carried out by humans, this activity is subject to generate a degree of uncertainty or error, and consequently, leads to incorrect decisions to control them.

Deep learning has solved complicated applications with increasing accuracies over time. The recent interest in this type of technology, and especially in its potential application in agriculture, has powered the growth of efficient systems and their application to real problems, such as the case of non-destructive methods for plant anomalies recognition. Despite the advances in the area, there remains a lack of efficiency, especially in real-field scenarios. Instead, our research proposes cost-efficient solutions that besides being able to recognize plant anomalies and symptoms, provide farmers with a technology that facilitates proper handling of crops.

We present three efficient deep learning techniques for plant anomalies recognition. The first method proposes a practical and applicable solution based on deep meta-architectures and feature extractors, to detect the type and location of plant diseases and pests in real-field scenarios. The second addresses the problems of class imbalance and false positives that occur especially on datasets with limited data, through the introduction of a diagnosis function called “Refinement Filter Bank”. The third method proposes an end-to-end framework that, on the one hand, combines the capabilities of deep meta-architectures and feature extractors for plant anomalies recognition and, on the other hand, incorporates the ability of recurrent neural networks to also generate detailed descriptions of the symptoms and their interactions in the scene.

Finally, we validate the performance of our methods on our two datasets which have been specifically collected and annotated for our research purpose: a) Tomato Plant Diseases and Pests Dataset and, b) Tomato Plant Anomalies Description Dataset. Qualitative and quantitative results show that, despite the complexity of real-field scenarios, plant anomalies and symptoms are successfully recognized and described. The insights drawn from these results led to better understand the strengths and limitations of plant anomalies recognition. Furthermore, our research suggests some potential targets for future research on the subject, since it constitutes an efficient tool to monitor the state of crops in precision agriculture.","#Deep learning, #plant diseases, #pests, #recognition, #glocal description, #localization, #딥러닝, #식물질병, #해충, #인식, #글로컬 기술, #현지화"
가우시안 분포 박스 매핑을 이용한 딥러닝 기반 텍스트 검출기,2019,"카메라 조명이 제어되지 않은 자연 영상에서 텍스트를 검출하는 문제는 컴퓨터 비전 분야에서 오랜 기간 활발히 연구되고 있다. 텍스트 검출은 영상 분석이 산업 발전과 인간의 편의성을 위해 중요한 역할을 하는 대표적 연구 분야 중 하나이다. 종래의 많은 연구들은 텍스트를 글자나 단어 단위로 기계 학습하고 그 결과로 출력된 것들을 한 데 모아 텍스트를 검출하려는 시도를 했었다. 이러한 방법은 전체적 문맥 보다는 지역적으로 텍스트에 집중하기 때문에 굉장히 많은 오검출을 발생시킨다. 현재는 딥러닝 기술이 컴퓨터 비전의 많은 영역에서 높은 성과를 보여주면서 텍스트 검출 문제에서도 딥러닝 기반의 검출 방법이 활발히 연구되고 있다. 그러나 딥러닝 기반의 방법을 이용하더라도 영상 내 텍스트가 서로 매우 가까이 인접해 있거나 다양한 상황에서의 텍스트를 인스턴스 단위로 분리하는 것은 여전히 어려운 문제이다. 본 논문에서 제안하는 방법은 이러한 문제를 해결하기 위해 가우시안 분포 값으로 구성된 텍스트 박스를 호모그래피 기하 매핑으로 생성한 다채널 기반의 FCN 구조를 활용한다. 가우시안 분포 값으로 구성된 다채널 스코어 맵은 텍스트 영역은 보존하면서 서로 인접한 텍스트들이 상호간에 뚜렷한 구분을 지을 수 있도록 도와준다. 학습 결과로 출력되는 다수의 스코어 맵에는 간단하지만 효율적인 이진 처리 및 논리 연산을 통해 최종적으로 잘 분리된 텍스트를 검출한다. 제안한 방법은 자연 영상 내 우발적인 상황에서 마주할 수 있는 텍스트를 검출할 수 있다. 텍스트의 형태가 수평으로 되어있을 뿐만 아니라 회전된 경우에도 검출이 가능하다. 실험은 이러한 상황을 만족하는 ICDAR 2015 벤치마크 데이터셋을 활용하여 제안하는 방법의 성능을 검증하였다. 제안 알고리즘은 종래의 FCN을 활용한 방법에 비해 높은 검출 성능을 보였다. 또한, 검출 속도 면에서도 기존 방법에 비해 빠른 속도를 보여준다.","#텍스트 검출, #텍스트 인식, #딥러닝, #가우시안 분포"
딥러닝을 이용한 작업자 행동 모니터링,2019.01,,"#작업자 행동(Worker’s behavior), #작업자안전관리(Worker’s Safety Management), #작업자 안전벨트(worker’s safety belt)"
딥러닝 기반 AI 전기화학가공 시스템 연구,2019,"전해 가공(ECM, Electrochemical Machining)은 비접촉 전기화학가공으로
금속이 용해되는 원리를 이용하는 특수가공법이다. 이 전해가공은 좋은 표면
품질, 높은 가공 효율의 장점을 가지고 있으나, 가공균일성이 떨어지는 단점이
있다. 하지만 기계적 가공으로 가공이 힘든 난가공성 재료에 적용이 가능하기
때문에 우주항공, 의학, 디스플레이 등의 산업에서 활발하게 연구되고 있다.
전해가공은 가공물을 Anode(+)에 연결하고, 공구를 Cathode(-)에 연결한
후 전류를 가해주면 전극에 전위차가 생기게 되고 가공물에서 금속 이온이 용
출되어 전극의 형상에 따라 가공이 된다.
일반적인 기계적 가공방법과 비교했을 때, 전해가공은 다음과 같은 장점을
보유하고 있다.
① 가공물에 전류만 흐른다면 난가공성 재료에도 적용이 가능하다.
② 가공 후에 잔류 응력, 열 변형이 발생하지 않으며 좋은 표면조도를 얻을
수 있다.
③ 가공 후 바이트 마크나 버가 발생하지 않는다.
④ 전극의 소모가 없어 경제적이다.
이러한 장점을 보유하고 있지만, 전극 이송시 진동으로 인한 간극 떨림, 전
해액의 전기전도도 변화, 많은 양의 재료 제거시 간극거리 증가로 인한 가공
불균일성이 발생하기 때문에 초정밀 가공을 하는데 있어 제한이 많다. 따라서
많은 연구들이 이러한 문제점을 해결하기 위해 연구 되었다. 전해가공의 주요
인자인 전압, 간극, 전해액, 전극의 형상을 변화시켜 가공 균일성을 해결하려
했지만 이러한 방법으로는 근본적인 원인이 해결 할 수 없다.
따라서 본 연구에서는 이러한 문제점을 해결하고자 “딥러닝 기반 AI 전기화
학가공 시스템”을 개발하였다.
이 시스템은 딥러닝을 통해 전해가공에서 가공 적정 전류밀도를 예측하고,
예측한 값을 기준으로 스태핑 모터를 제어하여 실시간으로 간극을 조절하는
장비이다.
먼저 전기화학가공에 적합한 센서를 찾기 위해 전류센서, 온도센서, pH센서
를 활용하였다 가지 센서 . 3 중 온도센서와 pH센서는 그 차이가 미세하여 전기
화학가공에 적합하지 않다는 것을 보였다. 따라서 전류센서를 활용하여 전기
화학가공에서 가공 모니터링을 함과 동시에 각 공정 변수별 가공 적정 전류밀
도 데이터베이스를 구축하였다.
그 다음 정확한 공정별 가공 전류밀도 값을 예측을 하기 위해서 다구치, 반
응표면계획법, 딥러닝을 활용하였다. 각각의 모델은 결정계수와 표준제곱편차
를 통해 비교하였고, 그 결과 딥러닝을 활용한 가공 전류밀도 예측이 가장 적
합한 모델임을 밝혔다. 또한 결과를 검증하기 임의로 5개의 인자를 추출하여
위해 실제 실험값과 딥러닝을 통한 예측 값을 비교해 본 결과 0~3%의 매우
작은 오차를 보였다.
그리고 딥러닝을 통해 얻은 전기화학가공에서 적정 가공 전류밀도 값을 기준
으로 가공 전류밀도 값이 크면 스태핑 모터를 반시계방향으로 5°회전 시키고
반대의 경우에는 시계방향으로 5°회전시켜 실시간으로 간극을 제어하였다. 또
한 노이즈를 줄이기 위해 2초에 한 번 신호를 받았고, 만약 0.06㎃/㎠보다 작
은 값이 측정된다면 노이즈로 인한 신호로 인식하게끔 하여 모터는 회전하지
않도록 해두었다.
마지막으로 “딥러닝 기반 AI 전기화학가공 시스템“이 제대로 작동하는지 테
스트하기 위해 임의로 공작물을 5°정도 기울인 상태에서 가공을 진행하였다.
그 결과 위 시스템을 활용하지 않은 가공은 시작부분과 끝부분에서 깊이는
0.015mm, 중간 폭은 0.11mm차이가 났다, 반면에 위 시스템을 활용한 전기화
학가공에서는 깊이는 0.0022mm, 중간 폭은 0.06mm 차이가 났다.
본 연구를 통해 “딥러닝 기반 AI 전기화학가공 시스템”의 기초연구부터 개
발까지 전 과정을 수행하였으며, 그 결과 전기화학가공의 단점인 가공 균일성
을 대폭 향상 시킬 수 있었다.","#Deep Learning, #Electrochemical machining, #Optimization"
딥러닝 방법론의 이해,2019,"딥러닝 이론이 처음 등장한 것은 1980년대이다. 하지만 하드웨어와 데이터, 최적화 알고리즘의 한계로 인해 주목받지 못했다. 그러나 그래픽 카드, 인터넷, 알고리즘의 발전과 함께 2010년대부터 여러 인지 문제의 해결책으로 딥러닝이 재조명 받기 시작했다. 결과적으로 이미지 인식과 같이 복잡한 문제에서 딥러닝 모형은 기존의 머신러닝 모형보다 크게 향상된 정확도를 보였고, 그에 따라 딥러닝에 대한 연구 및 투자도 활발히 이루어지고 있다.
이러한 시대 흐름에 발맞추어 대표적인 딥러닝 구조인 다층 신경망(MLP), 합성곱 신경망(CNN), 순환 신경망(RNN)을 본 논문에서 소개하고자 한다. 그뿐만 아니라, 실제 분석 과정에서 발생할 수 있는 문제점과 이를 완화시킬 수 있는 몇 가지 방법들도 함께 제시하고자 한다. 마지막으로 위 방법론들의 적용 예시를 함께 실었다. 그리고 동일한 데이터에 그래디언트 부스팅을 적합하여 비교하였다. 캐글(Kaggle) 콘테스트에서 딥러닝과 양대 산맥을 이루고 있는 그래디언트 부스팅과의 비교를 통해 각 방법론의 장단점도 함께 모색해보고자 한다. 본 논문의 의의는 대표적인 딥러닝 방법론을 이해하고, 모형 적합 시 주의해야 할 점들을 인지하며, 딥러닝과 앙상블 모형 중 상황에 맞는 적절한 도구를 선택할 수 있도록 돕는 데에 있다.

Although the theory of deep learning appeared in 1980s, it is from 2010s that deep learning took off as a solution of perceptual problems, thanks to breakthroughs in hardware, database and optimizer. Consequently deep learning has broken the records of traditional machine learning approaches in the fields such as image processing. This achievement led to active research and massive investment.
To keep up with this trend of data science society, this paper introduces commonly used structures of deep learning; multilayer perceptron, convolutional neural network, recurrent neural network. Some methods to mitigate overfitting are also written in this paper. Furthermore, the comparison of deep learning and gradient boosting, two approaches dominating Kaggle contests recently, is done by studying results of them on the same dataset at the end of this paper.",
흉부 의료 영상에서 딥러닝 기반 분할 및 분류 연구,2019,"하드웨어의 급격한 발달과 방대한 데이터 및 경험의 축적으로 인해 최근 수 년 간 딥러닝 기법이 다양한 분야에 도입되었다. 특히 기존 알고리즘으로는 분석 자체가 어려웠던 영상, 음성, 텍스트 등의 데이터에서 인간 수준의 패턴 인식 능력이 증명되면서 의료 분야에서도 의료영상, 유전체, 생체 신호 등의 다양한 데이터에서 질환의 검출부터 진단 및 치료까지 넓은 영역에서 응용될 수 있는 가능성을 보여주었다. 그러나 데이터에 대해 전문 지식이 요구되지 않는 일반적인 분야에서 충분한 데이터와 잘 정의된 지식을 기반으로 연구된 딥러닝 기법들은 의료 분야에 그대로 응용되기에는 여러 어려움이 있다. 의료 영상의 특성이 반영된 데이터 처리 기법들이 요구될 뿐만 아니라, 의료 분야에서는 지도 학습 기반의 딥러닝 모델 학습을 위한 정답을 생성하는데 매우 비싼 비용이 들기 때문에 자연 영상과는 다른 전략이 요구 된다. 또한, 때때로 데이터의 접근성을 고려한 모델 선택이 필요할 수 있으며, 적용 목적에 따라 단순히 정확도가 높은 모델 보다 민감도 또는 특이도가 최대화되는 모델이 요구될 수 있다.
딥러닝 모델은 데이터가 가진 형태 및 정보에 따라 대단히 다양한 형태로 학습 될 수 있다. 입력 데이터에 대한 직접적인 정답을 학습하는 지도 학습 이외에도 비지도 학습을 통해 생산적인 학습이 이루어지거나, 정책을 통해 스스로 학습하는 강화 학습 또한 이루어질 수 있다. 본 연구에서는 다양한 의료 데이터 중 흉부 CT와 X-ray 영상을 기반으로 한 연구에 초점을 맞추었으며, 지도 학습 중에서도 픽셀 단위의 높은 수준의 정보를 학습하는 분할 모델과 영상을 하나의 범주형 값으로 학습하는 분류 모델을 기반으로 세 가지 세부 연구들을 통해 의료 영상에서 딥러닝 모델의 효용성과 개선점을 평가하고자 하였다.
첫 번째 세부 연구에서는 흉부 CT에서 미만성 간질성 폐질환을 가진 환자들의 폐를 분할하기 위해 딥러닝 모델이 적용되었다. 미만성 간질성 폐질환의 세 가지 하위 질환들, 그리고 두 가지 CT 프로토콜에 대하여 전통적인 영상처리 알고리즘과 비교하여 정량적인 평가가 수행되었으며, 보수적인 평가를 위해 정량 결과가 가장 낮았던 증례들에 대한 시각적인 평가가 이루어졌다. 정량적 평가에서 딥러닝 모델은 전통적인 영상처리 알고리즘과 비교하여 유의하게 향상된 성능을 보여주었으며, 시각적 평가에서 또한 눈에 띄는 오차를 확인하지 못했고, 주된 수치적 오차는 폐문 영역이나 큰 만성적 폐 경화로 인해 전문가도 그 영역을 정확히 정의하기 어려운 영역에서 발생한 것으로 회고되었다.
두 번째 세부 연구는 흉부 CT에서 폐를 미만성 간질성 폐질환의 전형적인 질환 패턴으로 정량화하기 위해 딥러닝 모델이 사용되었다. 질환 패턴은 6가지로 정의되었으며, 두 명의 경험 있는 영상의학과 의사에 의해 정량화된 소량의 데이터와 이전 연구를 통해 개발된 기존 모델을 이용해 정량화된 대량의 데이터가 딥러닝 분할 모델 학습에 이용되었다. 딥러닝 분할 모델이 기존 모델의 결과를 정답으로 학습했을 때, 기존 모델을 매우 유사하게 재현하는 것을 정량 및 시각적으로 확인하였으며, 패치 단위의 연산으로 매우 긴 시간이 소요되었던 기존 모델과 달리 딥러닝 모델은 전체 영상을 이용한 엔드-투-엔드 방식으로 빠른 연산이 가능했다. 그리고 두 명의 의사에 의해 정량화된 소량의 데이터로 딥러닝 모델을 미조정한 후에는 기존 모델보다 향상되고 두 명의 의사간의 차이와 비교할만한 정량적 결과를 보여주었다.
마지막으로 세 번째 세부 연구에서는 흉부 X-ray에 다섯 가지 전형적인 폐 질환을 위한 컴퓨터 기반 검출 모델을 위해 딥러닝이 적용되었다. 두 개의 병원에서 수집된 데이터를 이용하여 약한 지도 학습이 이루어졌으며, 복잡한 폐 질환 패턴을 보다 잘 학습하기 위한 커리큘럼 학습 전략이 제안되었다. 커리큘럼 학습이 적용된 모델은 이를 적용하지 않은 모델에 비해 학습이 안정적이었고, 더 빠르게 수렴되었으며, 더 나은 손실 지점에 이르는 것을 확인하였다. 그리고 t-SNE 기법을 이용한 시각화와 클래스 활성화 맵을 통한 시각화 결과를 통해 상세한 정성적 평가가 이루어졌으며, 각 폐질환의 패턴이 다양체를 이루며 잘 학습 된 것으로 확인이 되었고, 클래스 활성화 맵을 이용한 지역화 결과는 해당 병변 영역이 활성화되는 것을 시각적으로 확인하였다.
의료 영상은 딥러닝 기반 지도 학습 모델을 위해 정답 데이터를 생성하는데 매우 큰 손실이 있을 수 있기 때문에 적절한 실험 설계가 필요하다. 각 세부 연구는 내부 소프트웨어를 활용하여 기존 영상처리 기반의 결과를 바탕으로 인간이 수정하거나 판독문 정보를 파싱한 후 인간이 빠르게 확인하는 형태로 효율적인 정답 생성이 이루어졌고, 성공적으로 딥러닝 모델이 학습되었다. 각 세부 연구 결과는 심층적인 평가를 통해 딥러닝 모델이 이러한 의료 영상에서도 낮은 수준의 영상 픽셀 정보들을 의미론적 정보로 잘 함축할 수 있음을 보여주었으며, 때때로 제한된 영역 내에서는 해부학적 지식을 충분히 갖고 식별하는 의사만큼의 결과를 보여주었다.",
딥러닝 기반 위내시경 영상 진단을 위한 자동분류 시스템 설계 및 평가,2019,"현대의학에서 효과적인 질병 진단 및 환자 치료를 위하여 의료영상 분석은 매우 중요한 진단 도구이다. 그리고 의료영상 기술이 발달하면서 더욱 정교하고 품질이 향상된 의료 영상의 데이터 획득을 가능하게 하고 있다. 하지만 이러한 정교함과 영상 품질 향상으로 인해 데이터의 양이 지속적으로 방대해지고 있으며 의료 영상의 데이터를 사람의 시각에 의존하여 분석하는 것은 어려움이 많다. 그리고 기존 연구에서 수행되었던 기계학습을 사용한 의료 영상 분류 기술은 실제 임상에서 전문의가 환자의 질병 진단에 활용하기에는 컴퓨터로 얻어낸 분류 정확도의 결과가 다소 낮은 문제점이 있다.
따라서 본 논문에서는 이러한 문제점을 해결하기 위하여 기존 기계학습 기술보다 의료영상의 분류 정확도를 개선하기 위해서, 전이학습 기술을 적용하여 딥러닝 기반 위내시경 영상 진단 자동분류 시스템을 제안한다.
본 논문에서 제안하는 시스템을 설계하기 위해서, 영상 진단 분류 실험 데이터 구성은 가천대학교 길병원 소화기내과에서 수집한 위내시경 영상을 실험에 사용하였다. 각각의 위내시경 영상들은 정상, 위궤양, 위암으로 진단하여 구분하였으며, 기존 머신러닝 기술의 분류 성능 평가를 위해서, 서포트 벡터머신 (Support Vector Machine : SVM), 합성곱 신경망(Convolutional Neural Network : CNN), 전이학습(Transfer-Learning)기술을 적용한 딥러닝 기술 기반의 영상 자동분류 시스템을 설계하였다.
본 논문에서 설계한 시스템을 구현하기 위해서, 머신러닝과 인공지능 분야에서 최신 기법인 딥러닝 기술을 적용하는데 가장 널리 사용되고 있는 프로그래밍 언어 파이썬(Python)으로 라이브러리를 사용하여 영상 자동분류 시스템을 구현하였다.
본 논문에서 설계 및 구현한 영상 자동분류 시스템을 테스트 및 평가하기 위해서, 위내시경 영상을 정상, 위궤양, 위암 각 300장씩 SVM, CNN, 전이학습 기반 시스템으로 분류 정확도를 비교하였다.
마지막으로 설계 및 구현한 프로그램으로 위내시경 영상을 자동 분류하는 실험을 수행한 결과, 기존 사용하는 머신러닝 기법인 SVM 과 CNN 기반 시스템은 평균 69% 영상 분류 성공률을 나타내었어, 제안하는 전이학습 기술 기반으로 설계한 프로그램으로 위내시경 영상을 분류한 결과 92% 정확도를 확인하였으며, 기존 기술과 비교하여 분류 정확도가 평균 23% 향상된 결과를 확인하였다.",
HCI를 위한 기하학적 특징과 경량화된 딥러닝 융합을 통한 손 자세 측정,2019,"본 논문에서는 손바닥 카메라 부착형 팜-글러브 디바이스를 제안한다. 또한 팜-글러브를 활용하여 손의 운동학적 분석 기반 기하학적 특징 추출방법과 경량화 딥러닝 기반 손 자세 추정 및 경량화 방법을 제안한다.
팜-글러브는 손바닥에 부착하는 카메라 기반 웨어러블 디바이스로서, 손목 움직임에 제한을 받지 않고, 각 손가락 움직임의 독립적인 방향성을 보존하며, 손 객체 분할이 용이한 특성을 지닌 디바이스이다. 본 논문에서는 팜-글러블 활용한 첫 번째 기술로 손의 운동학적 기반 기하학적 특징 기술을 제안한다. 손의 기하학적 특징을 추출을 위해 우하-방향성을 가진 필터링 마스크를 활용하여 손가락 경계선 추적 알고리즘을 개발하였다. 추출된 손가락 경계선은 1차원으로 사영되고, 해당하는 사영점과 손가락 경계선을 이용하여 손가락의 기하학적 특징을 추출한다. 또한 손의 중수지관절 라인을 활용하여 폐색된 손가락에 대해서도 견고한 손가락 식별이 가능하다. 팜-글러브의 기하학적 분석에 지면 인식 기술과 문자 매핑 코드화를 적용하여, 6가지 지면-손가락 탭 인식이 가능한 키보드 인터페이스인 탭-식스를 개발하였다. 탭-식스의 실험을 통하여 96.55%의 터치 인식률과 98.07%의 문자 입력 인식률을 도출하였다.
또한 팜-글러브를 활용한 두 번째 기술로 손 자세 추정을 위한 딥러닝 네트워크 및 경량화 방법을 제안한다. 팜-글러브 기반 학습데이터 수집을 위해 자동화 2D, 3D 주석을 제공하는 손 이미지 데이터 생성기를 개발하였고, 효율적인 손 자세 딥러닝 학습을 위해 부분적인 영상변환 데이터가 학습데이터에 추가되는 부분적 변조 기법을 제안한다. 추가적으로 손 자세 추정을 위한 딥러닝 네트워크 구조를 효율적으로 설계하기 위해 각 손가락의 병렬적인 구조를 가지는 부분 기반 학습 방법을 제안하고, 학습과정에서 엄지 손가락을 제외한 나머지 손가락의 레이어를 교환하여 학습 효과를 증대시키는 방법인 레이어 셔플 기법을 제안한다. 손 자세 추정의 마지막 단계로 인식률에 손실을 최소화하고 연산량 효율을 극대화 하기 위해 모바일 넷 버전 1, 2와 셔플렛 버전 2의 특징을 분석한 효과적인 네트워크 배치를 통한 경량화 기법에 대해서도 설명한다. 제안한 딥러닝 네트워크는 기존 손 자세 추정 연구들보다 낮은 14.7 pixel의 에러를 도출하였고, GPU 기반 34 fps를 도달하였다. 또한 후처리 경량화 과정을 도입하여 23.58 pixel 에러를 도출하였고, CPU기반 15 fps, 모바일 디바이스 GPU 기반 21 fps라는 결과를 도출하였다. 앞서 소개한 손 운동학적 기반 기하학적 특징 방법과 경량화된 손 자세 추정 기법을 융합하여 탭-핀치라는 새로운 형식의 인터페이스를 개발하였다. 탭-핀치는 엄지손가락과 나머지 손가락이 접촉하는 동작을 인식하는 디바이스이다. 기술 융합과정은 딥러닝 기반 손 자세 추정 기법을 통해 추출된 관절점 값과 신뢰도맵을 활용하여 선택적인 손가락 추출을 수행하고, 기하학적 특징을 활용하여 엄지 손가락과 다른 손가락의 접촉 여부를 판단한다. 또한 추출된 관절점을 기반으로 손가락 경계선을 추적하여 사영된 점의 개수를 통해 4가지 핀치 동작을 인식한다. 제안한 탭-핀치의 인식률은 일반인 기준 98.45%, 손 재활을 위한 환자 기준 89.71%의 인식률을 달성했다.
마지막으로 앞서 소개한 팜-글러브, 손의 기하학적 특징 추출 방법, 손 자세 추정 기법, 탭-식스, 탭-핀치를 활용하여 손 자세 및 동작 분석이 가능한 게임화 디지털 손 재활 플랫폼을 제안한다. 제안한 플랫폼은 기존 아날로그 손 재활 훈련을 디지털화 하여 총 8가지의 콘텐츠를 개발하였다. 또한 아날로그 도구 위치, 종류, 상태를 인식하며, 훈련하는 과정에서 손의 19개의 관절에 대한 정보를 자동으로 기록한다. 제안한 플랫폼은 25명의 환자를 대상으로 임상실험을 통해 유의미한 결과를 도출하였고, 손 재활 훈련 장치로서의 유의미성을 나타냄을 입증하였다.

In this study, we propose a camera-attached Palm-Glove device, along with a geometric feature extraction method based on the kinematic analysis of the hand, a lightweight deep learning-based hand position estimation and weight reduction method using the Palm-Glove. The Palm-Glove is a camera-based wearable device attached to the palm. Its unique palm-worn design provides the stable view of all five fingers, even when there is unusual motion in the upper limb and it is easy to segment the hand object with the design. First, a geometric feature extraction method based on the kinematics of the hand is proposed for the computationally efficient application of the Palm-Glove. To extract the geometric features of the hand, a finger boundary tracking algorithm was developed using a filtering mask with the right-downward orientation. The extracted finger boundary is projected in one dimension, and the geometric features of the finger are extracted using the corresponding projection point and finger boundary. Furthermore, robust fingertip identification is possible for occluded fingers as well by using the MCP (MetaCarpoPhalangeal) line of the hand. We developed Tap-Six, a keyboard interface that can recognize six ground-finger taps by applying ground recognition technique and character mapping encoding to the geometric analysis of the Palm-Glove. The experiment using Tap-Six showed a touch recognition rate of 96.55% and a character input recognition rate of 98.07%. Secondly, a deep learning network and weight reduction method for hand position estimation is proposed to accurately measure the positions of all finger joints using Palm Glove. To collect learning data based on the Palm-Glove, a hand image data generator that provides automated 2D and 3D annotations was developed. Furthermore, a partial modulation technique that adds partial image conversion data to the learning data for efficient hand position deep learning is proposed. In addition, a part-based learning method with a parallel structure of each finger is proposed to efficiently design the deep learning network structure to estimate the hand position, and a layer shuffle method that enhances learning effect by exchanging the layers of other fingers other than the thumb is proposed. As the last step of the hand position estimation, to minimize the loss of the recognition rate and the computation load, a weight reduction method through effective network deployment is also explained by analyzing the MobileNet versions 1 and 2 and ShuffleNet version 2. The proposed deep learning network achieved an error of 14.7 pixels, which is lower than existing hand position estimation studies, and achieved 34 fps on GPU environment. Furthermore, by introducing a post-processing weight reduction process, an error of 23.58 pixels, 15 fpas based on CPU, and 21 fps on mobile device GPU were achieved. By integrating the above-mentioned geometric feature method based on the hand kinematics and the lightweight hand position estimation method, a new type of interface called Tap-Pinch was developed. Tap-Pinch is a device that recognizes the contact motion of the thumb with other fingers. The integration process extracts fingers by using the joint point value and reliability map extracted from the hand position estimation method, and the contact of the thumb with other fingers is determined by using geometric features. Furthermore, four types of pinch motions are recognized through the number of projected points by tracking the finger boundaries based on the extracted joint points. The proposed Tap-Pinch achieved a recognition rate of 98.45% for normal people and a recognition rate of 89.71% for hand rehabilitation patients.
Finally, we propose a game-based digital hand rehabilitation platform that can analyze hand positions and movements by using the palm-glove, the hand geometric feature extraction method, the hand position estimation method, Tap-Six, and Tap-Pinch. For the proposed platform, eight types of contents were developed by digitalizing the conventional analog hand rehabilitation exercises. It also recognizes the locations, types, and status of analog tools, and automatically records information on the 19 joints of the hand. The clinical trial with the proposed platform showed that it could be clinically effective for stroke survivors. We expect that a randomized clinical trial with a large group of subjects would provide more convincing results.",
뇌파 데이터와 딥러닝 알고리즘을 이용한 사이버 멀미 분석,2019,"사이버 멀미는 Virtual Reality (VR) 기술을 접하는 동안 발생하는 증상으로, 인간의 감각 및 인지 체계의 혼선으로 발생하는 것으로 추정된다. 하지만 인간의 인지 체계를 객관적으로 측정할 방법이 없기 때문에 사이버 멀미를 측정하는 것은 어려운 과제로 남아있다. 이를 해결하기 위해 다양한 방식으로 사이버 멀미를 측정하는 연구가 진행되고 있다. 사이버 멀미를 측정하는 대표적인 방식은 Motion Sickness Questionnaire (MSQ)를 이용한 설문조사 방식, 뇌파 데이터를 분석하는 방식, 머신 러닝을 사용하는 방식 등이 있다. 하지만 설문에 의존하는 방식은 객관성이 부족하고, 머신 러닝을 사용한 이전 연구들은 정확도가 떨어지는 문제가 있다. 본 논문에서는 객관적인 사이버 멀미 측정을 위하여 뇌파 데이터를 Deep Neural Network (DNN), Convolutional Neural Network (CNN), Long Short-trem Memory (LSTM) 딥러닝 알고리즘에 적용하고, 결과를 비교한다. 또한 뇌파 데이터에 적합한 전처리 기법과 신호 품질 가중치를 제안하여, 딥러닝의 정확도를 높인다. 추가적으로 실험에서 사이버 멀미가 발생하는 영상 구간들을 조사하고, 시선 데이터를 활용하여 사이버 멀미를 유발하는 화면의 공통적인 특징 및 사용자의 시선 움직임을 분석한다.

Cybersickness is a symptom of dizziness that occurs while experiencing Virtual Reality (VR) technology and it is presumed to occur mainly by crosstalk between the sensory and cognitive systems. However, since the sensory and cognitive systems cannot be measured objectively, it is difficult to measure cybersickness. Therefore, methodologies for measuring cybersickness have been studied in various ways. Traditional studies have collected answers to questionnaires or analyzed EEG data using machine learning algorithms. However, the system relying on the questionnaires lacks objectivity, and it is difficult to obtain highly accurate measurements with the machine learning algorithms in previous studies. In this work, we apply and compare Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Long Short-term Memory (LSTM) deep learning algorithms for objective cybersickness measurement from EEG data. We also propose a data preprocessing for learning and signal quality weights allowing us to achieve high performance while learning EEG data with the deep learning algorithms. Besides, we analyze video characteristics where cybersickness occurs by examining the 360 video stream segments causing cybersickness in the experiments. Finally, we draw common patterns that causes cybersickness.","#가상 현실, #사이버 멀미, #딥러닝, #뇌파, #시선 분석"
딥러닝을 이용한 CT영상 변환 기법 연구,2019,"과거 의료영상을 통한 진단은 의사들의 판독으로만 이루어졌으나 컴퓨터 비전분야의 발달로 컴퓨터의 의료영상분석을 통한 진단의 정량적 측정이 가능해졌다. 이때 영상의 특성은 정량적 지표의 계산 결과에 많은 영향을 준다. CT영상의 경우 reconstruction과정에서 적용되는 파라미터들이 최종 영상의 특성과 질을 결정짓는 요소가 되는데 그 중에서도 영상의 sharp함과 smooth함 정도를 좌우하는 reconstruction kernel이 있다. CT 스캔에서 얻어진 raw데이터만 있으면 다양한 kernel로 영상을 reconstruction 하는 것은 가능하지만 reconstruction 전의 CT스캔에서 얻어진 raw데이터는 일정 시간이 지나면 기기에서 삭제되기 때문에 kernel변환을 보다 유용하고 효율적으로 수행하려면 영상기반에서 이루어져야 한다. 본 연구에서는 CT영상의 영상기반 reconstruction kernel 변환을 딥러닝 기법을 이용하여 수행하였다.
sharp한 영상에서 smooth한 영상으로 변환하거나 smooth한 영상에서 sharp한 영상으로 변환하기 위한 딥러닝 기법 적용을 위해 한번의 스캔에서 얻어진 raw데이터로부터 다양한 kernel로 reconstruction한 영상들이 학습데이터로 구성된다. 데이터는 각 학습용으로 6명, 모델의 최적화를 위한 평가용으로 2명의 데이터가 사용되었으며, 학습모델은 3x3 kernel크기의 동일한 convolution 층을 6개 쌓은 deep convolutional neural network (DCNN) 으로 구성된다. 학습모델에 변환하고자 하는 영상을 입력하여 목표영상으로의 학습이 이루어지도록 하였으며 이때 목표영상은 입력영상과 목표영상의 차영상이 되도록 하였다.
검증은 학습되지 않은 2명의 데이터로 이루어졌으며, 변환된 영상과 목표영상간의 오차를 root mean squared error (RMSE)로 정량 평가하였다. 입력영상과 목표영상간에 원래 차이가 많이 없는 B30f에서 B10f로의 변환이 평균 3.44 HU로 최소 RMSE를 나타냈고, 원래 차이가 많은 B10f에서 B70f로의 변환이 평균 84.18 HU로 최대 RMSE를 나타냈다. 그리고 최대 82.02%, 최소 30.51%의 RMSE 감소율을 보였다.
임상적 유용성을 확인하기 위해 딥러닝 기법으로 변환한 영상에서의 Emphysema index(EI) 및 Radiomics feature를 계산하여 목표영상의 결과와 비교해 보았다. EI는 30명 환자의 데이터에서 측정이 이루어졌으며, 95%의 신뢰구간에서 EI차이는 B50f에서 B30f로의 변환과 B30f에서 B50f로의 변환에서 각각 2.64~14.05(평균 8.35)?0.99~3.02(평균 1.01)%, -14.05~-2.64(평균 -8.35)?-3.14~5.8(평균 1.33)%로 감소되었다. Radiomics feature들은 Non Contrast, Contrast에서 계산되었으며 각각 51, 53명 환자의 데이터에서 측정이 이루어졌다. 딥러닝 변환 후 목표영상의 feature 유사도는 Non Contrast CT의 B50f에서 B30f로의 변환에서 Intensity 0.88±0.11, Texture 0.86±0.12, Wavelet 0.84±0.18, B30f에서 B50f로의 변환에서 Intensity 0.83±0.14, Texture 0.82±0.13, Wavelet 0.83±0.16를 나타냈다. 그리고 Contrast CT의 B50f에서 B30f로의 변환에서 Intensity 0.91±0.09, Texture 0.90±0.08, Wavelet 0.83±0.19, B30f에서 B50f로의 변환에서 Intensity 0.86±0.14, Texture 0.86±0.10, Wavelet 0.84±0.12를 나타냈다. 이와 같은 결과들은 본 연구 기법이 임상적 과정에서도 추후 충분히 유용하게 사용될 가능성을 제시한다.
실제 reconstruction과정을 영상기반에서 다시 재현하는 일은 파라미터를 찾는 과정이 너무나도 복잡하고, 환자마다 robust하지 않기 때문에 그 복잡한 과정은 되풀이 되어야 한다. 본 연구는 영상기반의 의료영상 변환을 딥러닝 기법을 이용하여 간단한 scheme으로 제안한다.",
딥러닝을 이용한 센서 패턴의 이상 탐지 성능 평가,2019,"최근 다양한 산업 분야에서 센서의 사용은 기기의 제어뿐만 아니라 실시간 모니터링을 통해 환경의 변화, 기기의 이상, 센서의 성능 저하 등을 탐지한다.
만약, 센서의 이상 패턴을 미리 탐지하지 못한다면 기기의 효율적인 운영을 하지 못하며 또한 경제적인 손실을 발생시킨다. 그렇기 때문에 센서 패턴을 이용한 이상의 조기 발견은 기기의 수명뿐만 아니라 공정의 전체적인 관리를 위해 가장 중요한 부분이다.
이러한 이유로 이상 탐지 방법론은 오래전부터 연구되었던 분야이며, 최근에는 머신 러닝과 딥러닝을 이용하여 다양한 데이터의 이상 탐지 방법론에 대한 연구가 활발히 진행되고 있다.
하지만 센서 데이터의 불확실성과 딥러닝 기술의 특성으로 인해 다양한 환경과 상황을 고려한 이상 탐지 연구는 아직 부족한 상황이다.
본 논문에서는 다양한 상황에서의 이상 탐지 평가를 진행하기 위해서, 딥러닝 모델과 딥러닝 모델의 Unit size, 그리고 입력 데이터의 크기를 기준으로 이상 탐지에 대한 성능을 평가 및 비교하는 실험을 진행하였다.
실험은 예측 부분과 탐지 부분으로 나누어 진행하였으며, 딥러닝을 이용하여 센서의 정상 패턴만을 학습하여 시계열 예측한 후, 이상 패턴과의 차이를 F_1-Score로 계산하였다. 딥러닝 모델은 시계열 예측에 적합한 RNN, LSTM, GRU 모델을 이용하였으며, 데이터는 각각 다른 패턴의 모양을 가진 온도, ECG, 진동 센서를 사용하였다. Unit size는 20,40,60, Window size는 1,5,10,15,20으로 설정하였으며, 실험 결과 각각의 파라미터들의 변화가 센서 패턴의 특성에 따라 이상 탐지율의 변화에 각각 다른 영향을 주는 것을 확인할 수 있었다.

The recent usage of sensors in diverse industries controls devices, and detects environmental changes, device anomalies, performance degradation of sensors and etc. through real-time monitoring.
If anomaly patterns of sensors are not detected in advance, devices cannot be operated efficiently and economic losses occur. Therefore, early detection of anomalies using sensor patterns is the most important matter both for the life of devices and the overall management of the process.
Due to such reasons, the anomaly detection methodology is the field that has been researched for a long period of time, and studies on the anomaly detection methodology of diverse data using machine learning and deep learning are actively underway. However, due to the uncertainty of sensor data and the characteristics of deep learning technology, anomaly detection studies that consider various environments and circumstances are still lacking.
In order to conduct anomaly detection evaluations under diverse circumstances, this study conducted the experiment of evaluating and comparing the performances of anomaly detection with the deep learning model, deep learning model’s unit size and the size of input data as the standard.
The experience was conducted in two segments of forecasting and detection. By using deep learning, normal patterns of the sensor were studied, the time series was forecasted, then the differences in the normal and anomaly patterns were calculated using F_1-Score. As for the deep learning model, RNN, LSTM, GRU models that are appropriate for time series forecasting were used, and the temperature, ECG and vibrations sensors that each have different shapes of patterns were used as the data. The unit sizes were set as 20, 40, 60 and the window sizes were set as 1, 5, 10, 15, and 20. The experiment results confirmed that the changes in each parameter have different effects on the changes in the detection rate, depending on the characteristics of sensor patterns.",
블록체인과 앙상블 딥러닝을 이용한 TW3 골 연령 예측 시스템,2019,"최근 4차 산업혁명과 더불어 의료분야에 IT 기술의 활용이 빈번해지면서
의료영상을 이용한 딥러닝 기술이 적용되고 있고, 사회적으로 키에 관한 관심
이 증가하면서 청소년들의 성장 상태를 사전에 파악하고, 적절한 시기에 표적
치료(target therapy)가 가능하도록 골 연령 예측 진단에 대한 요구가 증가하
고 있다. 일반적으로 골 연령 예측은 왼쪽 수부(carpal bones)를 방사선 촬영
하여 다양한 방법으로 표준 이미지와 대조해 개인의 골 연령을 예측하고, 그
결과를 기반으로 개인의 성장 잠재력과 성인키를 예측하는데 이용한다. 골 연
령을 예측하는 경우, 방사선 전공의라 할지라도 숙련되지 않았다면 영상 해석
의 차이가 있을 수 있으므로 정확도와 신뢰성에 주의를 요구하고 있다. 따라서 x-ray를 이용한 골 연령 판독을 위한 다양한 방법이 활용되고 있지만 아
직까지는 문제점을 가지고 있다. 딥러닝 기반으로 제안된 모델의 경우, 초기부
터 수백만장의 학습이미지가 필요하고, 대부분의 프로그램이 GP 방법을 사용
하기 때문에 골 연령 판독 시 오차가 매우 크게 발생하는 문제점을 가지고 있
다. 따라서 본 논문에서는 블록체인과 앙상블 딥러닝 기반의 TW3 골 연령 예
측 시스템을 제안하고 문제점을 해결하였다.
제안 방법의 경우 사설 블록체인 네트워크를 이용해 영상 판독의 결과를
분산된 전공의들과 공유하고, 정확성을 위해 이더리움 참여자의 50% 이상 투
표에 참여하고, 동의를 얻는 경우 투표 값을 골 연령 표준으로 채택한다. 또한
앙상블 딥러닝을 이용하기 때문에 딥러닝 모델 학습을 위해 몇백장의 학습이
미지를 이용해 TW3 기반의 골 연령 예측이 가능하고 학습모델을 위한 데이
터 셋을 지속적으로 증가해가며 앙상블 딥러닝 모델의 정확도를 점진적으로
향상시킬 수 있다는 장점을 갖는다.
제안 모델은 2명의 임상 전공의 실험결과를 기준으로 딥러닝 모델의 신뢰
성을 평가한 결과 ROC 커브가 0.997%, AUC는 0.79로 1에 매우 근접한 것을
확인하였고, 알고리즘의 정확도는 역연령(RUS)과 골 연령(BA) 평균 예측 결
과를 제안 시스템과 비교한 결과, 최소 평균 0.67%에서 최대 4.04%로 제안모
델이 더 정확한 것을 증명하였다. 또한 앙상블 딥러닝 모델의 예측 정확도를
실험하기 위해 학습 데이터 크기를 400에서 940장으로 증가시키며 실험한 결
과 학습 모델의 AUC가 0.60에서 0.79로 1에 근사한 값을 보였다.
향후 제안 시스템의 예측 정확도 향상을 위해 지속적으로 변화하는 학습
데이터 셋의 다변화된 모델 개선이 지속적으로 연구되어야 하고, 제안된 사설
블록체인 기반의 의료영상 공유시스템의 확장성과 판독에 참여한 전공의들의
보상에 대한 코인 배분 문제를 해결하기 위한 연구가 지속되어야 할 것이다.

Recently, with the 4th Industrial Revolution, the use of IT technology in the medical field has become more frequent, and deep learning technology using medical images has been applied. As the interest in
height has increased socially, the demand for bone age prediction diagnosis has increased so that the growth status of adolescents can be grasped in advance and targeted treatment can be performed at the
appropriate time. Generally, bone age prediction is used to predict the bone age of an individual by radiographing the left hand and contrasting it with the standard image in various ways, and to predict
the growth potential and adult key of the individual based on the results. In the case of predicting bone age, even for a radiologist, there may be a difference in image analysis if boy/girl is not experienced enough. Thus, albeit various methods for bone age reading using x-ray have been used, there are still problems. In the case of the proposed model based on deep learning, it requires millions of learning images from the beginning, and since most programs use the GP method, there is a problem that the frequency of error occurrence
is very high when reading the bone age. Therefore, this paper proposes a TW3 bone age prediction system based on block chain and","#TW3, #Bone Age(BA) Prediction, #Block chain, #Medical image sharing, #CNN, #RNN, #Ensemble Deep Learning"
경막외 뇌피질전도에서의 딥러닝 기술을 통한 눈 움직임 예측,2019,"많은 연구에서 다양한 전극을 이용하여 뇌파를 측정하고 있다. 두피 위에서 측정하는 EEG와 피질에 전극은 낮은 신호 잡음비를 가지고 있고 전극을 피질에 직접 삽입하여 측정하는 Depth Electrode 방식은 높은 신호 잡음비를 가지고 있지만 뇌의 손상을 주는 단점을 가지고 있다. 이러한 단점들을 보완하기 위해 피질위에 전극을 놓고 뇌파를 측정하는 방식인 ECoG를 이용하여 많은 연구들이 진행되고 있다. 이러한 ECoG의 방식 중 뇌경막을 손상시키지 않는 경막외 ECoG를 이용하여 뇌파를 측정하는 연구가 최근에 많이 진행되고 있다.
많은 연구에서 사용하던 머신러닝의 한 종류로 머신러닝에는 서포트 벡터 머신(Support Vector Machine, SVM), 랜덤 포레스트, 선형 회기(Linear Discriminant Analysis, LDA)등 많은 머신러닝 기법이 있고 지금까지 많은 연구에서 사용하고 있다. 최근 몇 년 사이 많은 연구에서 기존의 머신러닝의 한계를 넘어 높은 정확도의 분류 및 회기 성능을 가진 딥러닝을 이용하여 많은 성과를 내고 있다. 우선 엄청난 계산량을 빠르게 처리할 수 있는 그래픽 처리장치의 개발로 인해 빠른 시간에 많은 데이터를 분석할 수 있는 기초를 다지게 되었다. 또한 드랍아웃과 렐루와 같은 활성 함수등의 개발로 많은 부분 극복을 하였다. 마지막으로 인터넷의 발달로 인해 라벨이 달려진 이미지를, 즉 빅데이터, 손쉽게 구할 수 있어지면서 입력 데이터의 확보를 수월하게 한 점도 딥러닝의 발전에 큰 기여를 하였다 .
본 연구는 원숭이의 선택적 눈 움직임 (Choice Saccadic Eye Movement, CS) 실험을 통해 경막외 뇌피질전도 (Epidural ECoG, eECoG)를 이용하여 얻은 데이터를 이용하여 진행되었다. 연구에 사용된 데이터 구조에 맞게 오픈소스인 VGG 16의 모델을 차용하여 딥러닝 구조를 만들어 학습을 진행하였다.
눈의 움직임과 움직이지 않은 2가지의 상황을 구별하는데 있어서 Loss의 값이 0에 가깝게 떨어지는 것을 확인 할 수 있었으며 움직이지 않은 상태와 눈의 움직임 상태에 따른 5가지의 상황를 구별하는데도 국소 최소치에 빠지지 않는 것을 확인하였다. 5 겹 교차검증을 진해였을 때 눈의 실제 움직임에 대한 정확도는 99 ± 0.9 %를 가지고 있는 것을 확인했으며 눈의 움직임에 대한 예측의 정확도는 97 ± 4 %를 가지고 있는 것을 확인하였다.
눈 움직임 데이터를 이용하여 SVM과 딥러닝을 이용하여 분석한 결과 SVM의 정확도가 딥러닝의 정확도가 SVM 보다 50 % 이상 높게 나오는 것을 확인하였다. 눈이 실제로 움직였을 때 95% 이상의 정확도를 가지고 있어 분류가 잘 되는 것을 확인할 수 있었다. 또한 눈이 실제로 움직이 않고 방향 지시에 대한 움직임을 대기 하고 있는 상태에서도 89% 이상의 분류를 가지고 있음을 확인하였다. 추후 학습된 모델의 커널과 웨이트를 이용하여 디컨볼루션(Deconvolution)을 진행할 예정이며 활성화 되는 잠재 시간(latency)과 주파수 영역을 확인할 수 있을 것으로 예상한다. 또한 알고있는 채널의 위치와 매칭시켜 뇌의 어느 부분에서 활성이 일어나는지 Topography를 이용하여 확인할 수 있을 것이기 때문에 앞으로의 연구를 진행해 볼 수 있을 것으로 보인다.",
ARM Compute Library와 Neural Networks API를 이용한 임베디드 딥러닝 시스템 개발,2019,"딥러닝 어플리케이션의 수요는 점차 증가하고 있으며, 사용자들은 엣지 디바이스 환경에서 딥러닝 모델의 추론 결과를 사용하기를 원한다. 모바일 산업의 발전과 함께 임베디드 SoC의 성능이 점차 증가함에 따라 네트워크 의존도를 없애고 실시간으로 딥러닝 추론을 수행하는 구조가 제시되었다. 개발자는 Tensorflow Lite 프레임워크를 사용하여 앞서 제시된 구조로 임베디드 딥러닝 모델을 쉽게 개발할 수 있다. 그러나 임베디드 디바이스에서 딥러닝 추론의 수행시간이 긴 문제점이 있었고, 이 해결하기 위해 딥러닝 모델의 정확도를 유지하면서 연산량을 줄이는 방법 및 학습된 모델을 양자화하는 방법으로 딥러닝 모델이 경량화되었다. 최근 더욱 수행시간을 줄이기 위하여 임베디드 디바이스의 신경망 연산을 가속화 하는 ARM Compute Library (ACL) 및 Android NNAPI (NNAPI) 가 등장하였다. 하지만 최근 제시된 두가지 방법은 명확한 개발 방법이 정리되어 있지 않고, 또한 각 방법들의 성능 평가 자료가 없기 때문에 개발자가 임베디드 딥러닝 모델을 개발하는데 어려움이 있었다. 본 논문에서는 임베디드 딥러닝 모델을 개발하는 방법에 대해 체계적으로 정리하여 비교 실험하였다. 임베디드 딥러닝 모델의 추론 속도를 증가시키 위하여, 개발자는 가장 먼저 ACL을 사용하여 향상시킬 수 있다. 안드로이드 OS와 SoC 제조사의 고속 신경망 연산 하드웨어를 가지는 환경인 경우 NNAPI를 사용하는 방법으로 추론 속도를 향상시킬 수 있다. 결론적으로 Mali GPU환경에서 ACL과 NNAPI를 함께 사용하는 방법이 개발 편의성을 가지고 있을 뿐만 아니라 임베디드 딥러닝 모델의 추론 속도 측면에서 뛰어난 성능을 나타내는 것을 확인하였다.

Demand for deep-running applications is increasing, and users want to use the inference results of the deep-running model in an edge device environment. As the performance of the embedded SoC increases with the development of the mobile industry, a structure that performs only the inference process of the deep learning model in real time without network dependency is proposed. Using the Tensorflow Lite framework, developers can easily develop an embedded deep-running model with the architecture presented above. However, there is a problem that the execution time of the inference is long in the embedded device. To solve this problem, the deep learning model is lightened by using the method of quantizing the learned model and the method of reducing the calculation amount while maintaining accuracy. In recent years, the ARM Compute Library (ACL) and Android NNAPI (NNAPI) have been introduced to accelerate the operation of neural networks in embedded devices to further reduce execution time. However, there are difficulties in developing the embedded deep learning model because the two proposed methods do not have clear development method and there is no performance evaluation data of each method. In this paper, a method of developing an embedded deep learning model is systematically summarized and compared. In order to increase the inference speed of the embedded deep learning model, the developer can first improve it using the ACL. Another way is to increase the inference speed by using the NNAPI if the environment equipped with the Android OS and the high-speed neural network computation hardware of the SoC manufacturer are available. In conclusion, we confirmed that the use of ACL and NNAPI together in Mali GPU environment not only has convenience of development, but also shows excellent performance in terms of inference speed of embedded deep learning model.","#Deep Leaning, #ARM Compute Library, #NNAPI, #Edge Device, #Tensorflow Lite"
딥러닝 알고리즘을 이용한 콘크리트의 탄산화 속도계수 예측에 관한 기초적 연구,2019,"콘크리트의 탄산화는 콘크리트 구조물의 내구성을 저하시키는 요인 중 하나이다. 대기 중에 장기적으로 노출된 콘크리트 내부에 이산화탄소가 침투하여 pH가 저감하면서 철근표면에 부식이 시작된다. 이로 인해 콘크리트의 성능저하가 일어나며 내구수명이 낮아지게 되는데, 오늘 날 산업의 발달과 도시화로 인한 CO2 농도의 증가로 철근콘크리트 구조물의 내구성을 확보하기 위해 콘크리트의 탄산화에 대한 논의가 증가되고 있으며 탄산화 저항성에 대해 파악할 필요성이 있다.
현재 국내에서 사용되고 있는 탄산화 예측식은 외부 환경조건, 시멘트의 종류 및 마감재 등에 따른 변수를 가지고 있으며 실험적 모델의 경우 정성적이며 각각의 실험조건에 적합한 재료 및 환경에 대해서만 적절하게 예측이 가능하여 국내에서 적용하기에 어려움이 존재한다.
본 연구에서는 단순한 실험 자료의 회귀분석보다 다수의 데이터 처리 방법에서 매우 효과적인 적용성을 보이는 딥러닝 알고리즘을 이용하여 탄산화 해석에 반드시 필요한 이산화탄소의 속도계수를 도출하기 위해, 기존 연구들의 탄산화 실험 결과를 기반으로 탄산화 속도계수를 예측하는 학습모델을 구축하고자 한다. 학습모델의 구축을 위해 W/B(%), 혼화재(고로슬래그, 플라이애쉬), 시멘트와 굵은골재 및 잔골재의 단위량을 분석인자로 선정하여 딥러닝 기반의 콘크리트의 탄산화 예측 학습모델 구축의 방법을 제시하고, 학습이 완료된 모델의 성능을 현재 이용되고 있는 탄산화 예측식과의 비교를 통하여 확인하고자 하였으며, 본 연구의 결과는 다음과 같다.


1) 본 연구의 조건에서 모든 학습 모델의 학습의 과적합이 이루어지지 않는 시점까지 학습을 진행하였으며, 학습모델의 성능은 학습이 완료되고 검증데이터를 각각의 모델로 평가하여 각 모델의 평균 절대값 퍼센트 오차(MAPE)를 확인하는 과정으로 진행되었다.

2) 학습모델의 평균 절대값 퍼센트 오차(MAPE)는 4layer가 20.73%, 5layer가 10.92%, 6layer가 17.90%, 7layer가 15.25%, 8layer가 23.01%, 9layer가 17.66%로 나타났으며, 이를 통해 5layer 학습 모델의 성능이 가장 우수한 것으로 판단된다.

3) 실제 값을 기준으로 ±10% 범위에 들어오는 예측 값의 양을 확인한 결과, 5layer에서 80%, Kishitani식과 Hamada식에서 48%, Shirayama식에서 36%의 성능을 확인하였으며, 이를 통해 딥러닝 알고리즘을 이용한 학습 모델의 성능이 가장 높음을 확인 가능하다.

4) 예측 결과와 실제 값의 평균 절대값 퍼센트 오차(MAPE)는 5layer에서 9.91%, Kishitani식에서 31.68%, Hamada식에서 49.33%, Shirayama식에서 43.96%의 오차율을 보였으며, 딥러닝 알고리즘을 이용한 학습 모델의 평균 절대값 퍼센트 오차(MAPE)가 가장 작게 나타났다.

5) 본 연구의 범주에서 기존의 탄산화 예측식보다 딥러닝 알고리즘을 이용한 학습모델이 탄산화 속도계수 예측에 높은 성능을 보이는 것으로 판단된다.

It is carbonation of concrete that is one of the important reasons to degrade concrete construction’s durability. Since pH is decreasing because of carbon dioxide invasion into inside parts of concrete exposed to the atmosphere, corrosion begins on the surface of a rebar. Due to this phenomenon, concrete performance degradation takes place and concrete’s durability becomes lower, and, as CO2 concentration has been increasing depending on industrial development and urbanization, discussions on the concrete carbonation is being raised in order to secure durability of reinforced concrete constructions. Then, it should be needed to grasp carbonation resistibility.
A carbonation prediction formula, utilized in Korea, has variables, based on external environmental condition, types of cement, and finishing materials. In case of an experimental model, it is qualitative and it is only able to predict conditions with proper materials and environments that are suitable for the experimental conditions, so that it is hard for it to apply into domestic conditions.
In order to draw the coefficient of carbon dioxide that is necessary for carbonation analysis, this study was planning to construct a learning model to predict carbonation coefficient, depending on results of carbonation experiments from precedent researches by utilizing an deep learning algorithm that showed very effective application when it comes to multiply data processing methods rather than regression analysis of simple experimental data. For the learning model construction, this study suggested construction measures of a deep learning-based concrete carbonation coefficient prediction learning model by selecting analytical factors with W/B (%), admixtures (blast furnace slag, fly ash), and unit amount of cement, coarse aggregate, and fine aggregate. Then, this study attempted to verify performance of the learning-completed model through comparison with a currently utilized carbonation prediction formula. For the carbonation coefficient analysis, this study checked error rate from learning conditions by using accelerated carbonation test data, which had not been utilized in the learning, and then it compared error rate with a currently utilized prediction formula by using actual carbonation exposure test data. Research results are as follows.

1) Under the conditions of this study, it progressed the learning process just before the time of overfitting in every learning model, and it verified performance of the learning models, after completing the learning process and evaluating verification data for each model and then identifying Mean Absolute Percent Error (MAPE) in order.

2) This study found that MAPE of the learning model appeared as 20.73% at 4layer, 10.92% at 5layer, 17.90% at 6layer, 15.25% at 7layer, 23.01% at 8layer, and 17.66% at 9layer, so that it verified the 5layer learning model has the best performance.

3) As the result of checking the amount of predicted value into ±10% range based on actual value, this study confirmed that 5layer showed 80% performance, Kishitani showed 48% performance, Hamada showed 48% performance, Shirayama showed 36% performance, so that it verified the learning model with a deep learning algorithm has the best performance.

4) This study found that MAPE between prediction results and actual values appeared as 9.91% at 5layer, 13.68% at Kishitani, 49.33% at Hamada, and 43.96% at Shirayama, so that it verified the learning model with a deep learning algorithm shows the smallest MAPE.

5) In the scope of this study, it verified that the learning model with a deep learning algorithm showed much higher performance on the carbonation coefficient prediction than the current carbonation prediction formula.",#크리트공학
딥러닝 모델의 앙상블을 활용한 근적외선 얼굴 인식 방법,2019,"최근 딥러닝을 적용한 연구가 활발히 진행됨에 따라, RGB 얼굴 인식에 딥러닝을 적용하여 높은 인식 성능을 획득하였다. RGB 영상은 공용 데이터베이스가 많이 공개되어 있어 좋은 성능을 보이는 복잡한 딥러닝 모델을 학습시키기에 용이하지만, 조명 변화에 취약하다는 단점이 있다. 반면에, NIR 영상은 조명 변화에 강인하다는 장점이 있어, NIR 영상을 사용한 딥러닝 기반 얼굴 인식 알고리즘이 개발되었다. 그러나, NIR 공용 데이터베이스는 적은 양만 공개되어 있기 때문에, 기존의 딥러닝 기반 NIR 얼굴 인식 알고리즘은 구조를 간략화한 딥러닝 모델을 사용하였다. 이 모델은 높은 인식 성능을 보였지만 적은 학습 데이터와 제한된 환경에서 학습을 진행하였기 때문에, 다양한 환경의 데이터에 대해서는 높은 성능을 기대하기 어렵다는 문제가 있다. 이 문제를 해결하기 위해, 본 논문에서는 복잡한 딥러닝 모델을 대규모 학습 데이터로 학습시킨 모델의 파라미터를 사용하는 transfer learning 방법을 접목하며, 얼굴 전체 영상에 대한 정보와 함께 얼굴 부분의 디테일한 정보를 융합하여 얼굴 인식을 수행하는 ensemble 딥러닝 모델을 제안한다. 제안하는 방법은 학습과 테스트에 각각 다른 환경에서 촬영된 데이터베이스를 사용하였음에도 99.97%의 성능을 보이며, 제안하는 방법에 기존 딥러닝 모델의 구조를 간략화한 모델을 사용한 경우에도 99.57%의 높은 성능을 보인다. 이는 동일한 데이터베이스를 사용하여 실험한 선행 연구에 비해 약 5% 향상된 결과이다.

Recently, deep learning-based research has been actively conducted, and RGB face recognition algorithms applying deep learning achieve high performance. It is easy to train a complex deep learning model that can obtain high performance, because a lot of RGB face databases are in the public. However, there is a shortcoming that the RGB face images weak the illumination changes. On the other hand, near-infrared (NIR) images are robust to illumination changes. Thus, deep learning-based face recognition algorithms using near-infrared images are researched. Because small amount NIR face databases are in the public, existing NIR face recognition algorithms based on deep learning use the deep learning models having simplified architecture. Although these models have high performances in limited environment, it is difficult to look forward to high performance in various environments because of a few training data. To resolve this problem, in this thesis, we apply transfer learning method that uses parameters of complex deep learning model trained with large RGB training data onto the proposed method. In addition, we propose an ensemble deep learning model that perform face recognition converging with the information of whole face image and parts of face. The proposed method achieves 99.97% although we use taken databases on different environments respectively for training and test. Moreover, in case of using a simplified deep learning model, the proposed method achieves 99.57%. These performances are the results improving about 5% in comparison with preceding research that uses the same databases.",#전자통신학
계층 딥러닝 기반 문맥정보 어텐션 메커니즘을 이용한 화행 분석 시스템,2019,"대화 시스템은 사용자 발화를 이해하고 그에 알맞은 피드백을 생성한다. 이 중 사용자 의도를 파악하기 위한 화행 분석은 대화 시스템의 필수적인 작업이다. 화행이란 발화 속 화자의 의도를 뜻하며 화행 분석은 발화에 대해 적절한 화행을 결정하는 것을 말한다. 기존에는 화행 분석을 위해 기계 학습 기법인 Support Vector Machine(SVM)가 주로 사용되었다. 하지만 기계 학습 모델의 경우 사람이 직접 의미 있는 자질(features)들을 가공하여 추출해야 한다. 반면 최근 많이 연구되는 딥러닝 기법은 데이터로부터 모델이 자동으로 자질들을 추출한다는 장점이 있다. 이러한 심층 학습 기법에는 Recurrent Neural Network(RNN)기반의 모델들이 주로 사용된다. 다음으로 딥러닝 기법에 많이 사용되고 있는 어텐션 메커니즘은 문장 내 같은 단어라도 문맥에 따라 중요도가 다름을 이용하는 방법이다. 이때 입력 값에 따른 가중치를 계산하는 방법에 따라 여러 종류로 나뉘는데, 대표적으로Additive Attention, Scaled Dot-Product Attention이 있다. 본 논문에서는 두 개의 딥러닝 모델을 서로 계층적으로 두고 그 사이에 어텐션 메커니즘을 결합한 모델을 제안한다. 계층 딥러닝 모델을 사용함으로써 대화의 계층적 정보를 처리할 수 있으며, 어텐션 메커니즘으로 문맥 정보를 사용하여 발화 문장과 문맥 정보 사이 가중치 계산이 된 입력들을 이용할 수 있다. 한국어 대화 데이터를 이용하여 실험을 진행하였으며, 단일 딥러닝 모델 및 어텐션 메커니즘을 적용하지 않은 모델보다 화행 분석에서 성능이 향상된 결과를 얻을 수 있었다.

A dialogue system understands user utterances and generates appropriate feedback. The analysis of the user’s intention is an essential task of the dialogue system. Speech act refers to the intention of the speaker in utterance, and the analysis of the act refers to the determination of the proper dialogue act of utterance. Previously, support vector machine(SVM), which is a Machine Learning method, was frequently used for dialogue acts analysis. However, in the case of the Machine Learning model, hand-crafted feature engineering is needed and humans must directly extract the meaningful qualities. On the other hand, the Deep Learning method, which is studied most recently, has the advantage that the model automatically extracts the qualities from the data. Recurrent Neural Network(RNN)-based models are mainly used for this Deep Learning model. Next, the Attention Mechanism, which is used in conjunction with the Deep Learning method, is a method of using the fact that the importance of each sentence word is different according to the context. At this time, according to the method of calculating the weight of the input value divided into several types, there is representatively Additive Attention, Scaled Dot-Product Attention. In this paper, we propose a model in which hierarchical model with two Deep Learning that combines the Attention Mechanism between them. Using the Hierarchical Deep Learning model, we can process hierarchical information of dialogue, and we can use the information which is weighted between the utterance sentence and context information using context information as an attention mechanism. Experiments were conducted using Korean conversation data, and the performance of proposed model was improved in the analysis of speech act than the model without the single deep learning model and the attention mechanism.",
모바일 기기에서의 실시간 다수의 인간 자세 추정을 위한 경량화 딥러닝 모델,2019,"본 논문에서는 다양한 컴퓨팅 환경에서의 실시간 다수의 인간 자세 추정을 위하여 인간 자세 추정 딥러닝 모델의 경량화를 수행한다. 현재 딥러닝 기반의 접근법을 이용한 다중 인간 자세 추정의 경우 엄청난 양의 연산량으로 인해 고성능의 컴퓨팅 환경이 아니면 동작할 수 없기에 모델의 경량화가 필수적이다. 따라서 본 논문에서는 경량화 블록을 이용해 딥러닝 모델을 경량화하고, 모델의 가중치를 분석하여 모델 하이퍼 파라미터 수정을 통해 모델의 연산량을 줄인다.
경량화 블록을 이용하여 딥러닝 모델의 경량화를 수행하게 되면 그에 따라 정확도의 감소가 발생하게 된다. 이러한 문제를 해결하기 위하여 경량화 블록을 이용한 경량화가 진행됨에 따라 발생하는 정확도 저하를 최소화 할 수 있는 SMnet 모델을 제안한다. 또한 기존의 경량화 블록이 가지는 문제점을 해결하기 위한 수정된 경량화 블록을 제안한다.
또한 딥러닝 모델의 경우 모델의 채널 수, 레이어 수와 같은 하이퍼 파라미터가 존재한다. 하이퍼 파라미터를 조정함에 따라 연산량, 정확도 등 결과에 큰 영향을 미친다. 기존의 방법의 경우 대부분 경험적인 방법을 통해 파라미터 수정을 진행한다. 하지만 디버깅이 힘든 딥러닝의 특성상 실험적인 방법을 통해 하이퍼 파라미터를 수정하는 방법은 비효율적인 접근이 될 가능성이 높다. 이 문제를 해결하기 위하여 본 논문에서는 모델의 가중치 히스토그램 분석을 통해 하이퍼 파라미터를 수정하고, 정확도에 따라 자세 추정 모델의 수정 단계 수를 조정하여 모델의 최적화를 수행한다.
본 논문에서는 제안하는 방법의 검증을 위해 MS COCO 데이터 셋을 이용하여 모델을 검증하고, 제안한 각 경량화 방법의 효율성을 검증하였다. 또한 CPU환경에서의 기존 모델과의 비교를 통해 기존 모델에 비해 약 27배의 속도가 나타나고, 그에 반해 정확도 저하는 50%정도로 그치는 결과를 얻어 본 논문에서 제안하는 경량화 방법의 효율성을 확인하였다.

In this paper, we propose lightweight deep learning models for real-time multi-person pose estimation in mobile computing environment. In the case of multi-person pose estimation using the deep learning based approach in mobile environment, the model should be lightweight because mobile devices mostly cannot provide enough computation power for the deep learning model. Therefore, in this paper, we reduce the computational cost of the deep learning model by using lightweight blocks, analyzing the model weights and modifying the model hyperparameters.
If the computation of the model were reduced by using a lightweight block, the accuracy should be compromised accordingly. To minimize the accuracy trade off, we propose a SMnet model that minimizes the accuracy degradation. Furthermore, we propose a modified lightweight block to overcome the weakness of existing lightweight blocks.
There are hyperparameters such as the number of channels and the number of layers for deep learning model. The model accuracy and computational cost are affected by those hyperparameters. In most previous researches, those hyperparameters are fine-tuned in heuristic ways. However, due to the fact that the deep learning models are difficult to debug, it takes a lot of time to analyze the results from hyperparameter modification. Therefore, the hyperparameters are modified by analyzing the weighting histogram of the model and by modifying the number of correction steps in the model according to the accuracy.
In this study, we used the MS COCO data set to show the efficiency of each lightweight method and to verify the performance of the proposed model. While our proposed model is faster 27 times that the existing model in In comparison with the existing model in the CPU environment, the model accuracy fell to 50%.",
"증강현실과 딥러닝을 이용한 사용자 중심의 제조 정보 추천, 가시화 및 상호작용 지원 방법",2019,"최근, 다양한 분야 특히, 제조업에서 4차 산업혁명이 일어나면서, 제조업과 정보 통신 기술(information communication technology, ICT) 기술의 융합을 통한 새로운 제조 시스템이 구축되었다. 대표적으로 고객의 요구사항 및 수요를 효과적이고 능동적으로 반영할 수 있는 고객 맞춤형 제조 시스템이 있다. 고객 맞춤형 제조 시스템에서는 작업자가 특정 과업(예를 들어, 조립, 모니터링, 검사 등)을 수행하는데 필요한 제조 정보들을 빠르고 정확하게 획득하고, 활용할 수 있어야 제조 시스템의 생산성 향상 및 이익 상승 그리고 비용 감소 등의 가치 창출을 실현할 수 있다.
새로운 제조 시스템에서는 ICT 기술을 통해 제품을 생산하는 과정에서 일어나는 이벤트(예를 들어, 생산, 고장, 검사 등)에 대한 정보들이 센서 혹은 작업자에 의해 실시간으로 생성되고, 제조 실행 시스템이나 데이터베이스에 저장된다. 그렇기 때문에 생성된 제조 정보들을 작업자들이 과업을 수행하면서 언제, 어디서든 충분히 검토하고, 활용할 수 있도록 지원하는 것이 중요해졌다. 하지만, 제조 시스템 내에서 작업자가 수행하고 있는 과업에 필요한 제조 정보를 빠르고 효과적으로 획득하는데 어려움이 따른다. 또한, 제공된 제조 정보를 쉽고 정확하게 이해해야 하는데 사용자 인터페이스 등이 잘못 설계되어 작업자에게 제공된 정보를 오해하거나 제조 정보를 제대로 활용하지 못 할 경우, 작업자의 안전이나 과업의 효율성 등에서 문제가 발생할 수 있다.
이와 같은 문제를 해결하기 위해 작업자가 과업에 필요한 제조 정보를 보다 빠르고 정확하게 획득할 수 있도록 제조 정보를 추천하는 기술과 실 설비들의 위치나 거리 등을 고려하여 작업자가 제조 정보를 정확하게 이해하고 활용할 수 있도록 제조 정보를 가시화하는 기술이 필요하다. 또한, 가시화된 제조 정보를 활용하기 위해 다양한 상호작용 방법에 대한 고찰이 필요하다.
본 연구에서는 증강현실 환경에서 작업자가 제조 정보를 과업에 활용할 수 있도록 증강현실(augmented reality, AR)과 딥러닝(deep learning) 기반의 작업자 중심의 제조 서비스를 지원하기 위한 방법을 제안한다. 먼저, 작업자 주변의 설비 및 제품에 대한 제조 정보를 제공하기 위해 AR 마커를 이용한 AR based live manual과 딥러닝 기술을 이용한 manufacturing visual question answering(M-VQA)을 제안한다. 그리고 작업자에게 제공되는 제조 정보를 가시화하기 위해 가상현실(virtual reality, VR)을 함께 이용하는 dual reality와 딥러닝 기술을 이용하여 실 설비의 영역과 깊이 정보를 획득하고, 이를 이용하여 제조 정보를 가시화할 수 있는 industrial AR visualization 방법을 제안한다. 마지막으로 제조 시스템 내에서 가시화된 제조 정보에 대한 상호작용을 지원하기 위해 모바일/웨어러블 디바이스에서의 다양한 상호작용 방법 간의 비교·평가를 실시한다. 본 연구에서는 3 가지 상호작용 방법(multi-touch based interaction, vision based interaction, hand gesture based interaction)으로 구분한다. 그리고 평가를 통해 상호작용 방법에 대한 특징 등을 분석한다.
특히, M-VQA를 통해 제조 정보를 추천함으로써 증강현실 환경에서 작업자의 주변 환경에 대한 정보를 쉽게 획득할 수 있으며, 새롭게 생성된 제조 정보에 대해서도 추천이 가능하였다. 기존의 정보 검색 연구들과의 비교를 통해 보다 높은 정확도를 보였으며, 주변 환경 정보를 이용함으로써 효과적으로 제조 정보를 추천할 수 있었다. 또한, 기존의 증강현실의 문제점을 해결함으로써 AR 마커를 사용하지 않고, 작업자의 주변 환경과 질문을 통해 동적인 제조 정보를 작업자에게 제공할 수 있다.
두 번째로 제안하는 industrial AR visualization 방법을 통해 실 설비 간의 공간적 관계를 이용하여 가시화된 제조 정보에 대한 visual mismatch를 해결하고, 제조 정보와 실 설비 간의 occlusion 문제를 해결하였다. 또한, 동적으로 움직이는 실 설비에 대한 인식이 가능하였으며, 실 설비 주변에 제조 정보를 보다 효과적으로 증강가시화할 수 있었다. 실험과 다양한 시스템 구현을 통해서도 industrial AR의 applicability와 extensibility를 확인할 수 있었다.
마지막으로 증강현실 환경에서의 상호작용에 대한 비교·평가를 통해 다양한 상호작용 방법에 대한 특징을 분석할 수 있었다. 평가 결과, hand gesture interaction이 multi-touch based interaction과 vision based interaction에 비해 좋은 결과를 보였다. 하지만 버튼을 누른다거나 아이콘을 선택하는 등의 2차원적인 상호작용에 대해서는 multi-touch based interaction을 선호하는 것으로 나타났다. 결과적으로, 과업의 종류에 따라 hand gesture based interaction과 multi-touch based interaction을 함께 지원하는 것이 보다 효과적일 것이라는 것으로 알 수 있었다.

One of the main themes in the 4th Industrial Revolution is to build a new manufacturing ecosystem (e.g., smart factory) through the convergence of manufacturing services and information and communication technology (ICT). A new manufacturing ecosystem refers to a customized production environment that can incorporate ICT technology into the existing manufacturing services to effectively and actively reflect the user''s requirements on the product. To improve productivity and benefit and to reduce cost, workers have to use the right manufacturing information at the right time, which requires user-centric manufacturing information visualization and interaction methods. However, in a real manufacturing environment, workers are difficult to accurately and quickly obtain the manufacturing information needed for required tasks. In addition, they may misunderstand the information in the rapidly changing manufacturing environment. For these reason, currently available systems cause severe problems over their safety and effectiveness while performing tasks.
This thesis proposes a new approach to providing user-centric manufacturing services using augmented reality (AR) and deep learning. The proposed approach can effectively recommend and provide manufacturing information concerning worker’s situation so that workers can more effectively and efficiently conduct their tasks.
For this purpose, a manufacturing visual question answering (M-VQA) is proposed using AR based live manual and deep learning to recommend appropriate manufacturing information concerning worker’s queries and situation. A new industrial AR visualization method using instance segmentation and depth prediction is proposed to remove visual mismatch and wrong occlusion problems in AR. Finally, we compare and evaluate various interaction methods using smart and wearable devices in manufacturing environments. Three different types of interaction methods, multi-touch based interaction, vision-based interaction and hand gesture-based interaction, are evaluated.
In particular, by recommending the manufacturing information through M-VQA, the worker can obtain situation-aware information rather than static information. A comparative evaluation with existing information retrieval methods was conducted. The result shows higher accuracy enough to recommend and answer worker’s queries properly .
Secondly, by using the proposed industrial AR visualization method, the visual mismatch and wrong occlusion can be handled by estimating spatial relations between actual facilities by applying object detection, instance segmentation and depth prediction without depth sensors. The applicability and extensibility of the proposed industrial AR were confirmed through experiments and various system implementations.
Finally, we analyze various interaction methods in mobile AR by comparing and evaluating different types of interactions. As a result of the evaluation, the hand gesture interaction showed better results than the multi-touch interaction and vision-based interaction. On the other hand, the multi-touch based interaction is preferred for 2D interactions such as pressing a button or selecting an icon. Therefore, it was found that it would be more effective to support both hand gesture-based interaction and multi-touch based interaction depending on the task type and worker’s situation.",
임베디드 시스템 기반에서 화재감지를 위한 딥러닝 구조 연구,2019,"본 논문에서는 불꽃의 색깔과 모양에 특화된 2가지의 가벼운 딥러닝 모델을 합쳐 임베디드 시스템에 적용 가능하면서 화재 검출률을 높인 딥러닝 구조를 제안한다. 제안하는 딥러닝 구조의 화재 감지 과정은 불꽃 색깔 모델을 통한 화재 영역 검출, 불꽃 색깔 특화 딥러닝 모델을 통한 화재 영상 분류, 검출된 화재 영역의 셀 분리, 불꽃 모양 특화 딥러닝 모델을 통한 화재 영상 분류 등의 4가지 과정으로 구성된다. 불꽃 색깔 모델을 통한 화재 영역 검출 과정은 입력 영상에서 불꽃 색깔 모델로 불꽃의 색을 추출한 다음 레이블링 하여 화재 영역만을 검출하는 단계이다. 불꽃 색깔 특화 딥러닝 모델을 통한 화재 영상 분류 과정은 불꽃의 색깔에 특화 학습된 딥러닝 모델을 통하여 검출된 화재 영역을 입력으로 넣고 출력단의 화재 클래스 확률이 75% 이상에서만 화재 영상으로 분류하는 단계이다. 검출된 화재 영역의 셀 분리 과정은 앞 단의 75% 미만으로 화재 영상으로 분류된 영상들이 불꽃 모양 특화 딥러닝 모델에 입력되기 전의 전처리 과정으로, 불꽃 모양 특화 딥러닝 모델의 입력으로 쓰일 불꽃 모양에 최적화된 작은 이미지들을 얻기 위하여 검출된 화재 영역을 단위로 분할하는 단계이다. 불꽃 모양 특화 딥러닝 모델을 통한 화재 영상 분류 과정은 단위로 분할된 작은 셀들을 불꽃의 모양에 특화 학습된 딥러닝 모델의 입력으로 넣고 각 셀의 화재 여부를 판단하여 50% 이상의 셀들이 화재 영상으로 분류될 경우 화재 영상으로 분류하는 단계이다.
본 논문에서 제안한 임베디드 시스템 기반에서 화재감지를 위한 딥러닝 구조 연구의 효용성을 입증하기 위하여 ImageNet에서 얻은 화재 데이터베이스를 대상으로 기존의 딥러닝 구조인 VGG, Inception-v3 구조와 실험하여 신뢰성을 평가하였다. 실험 결과 제안하는 딥러닝 구조는 1,518개의 이미지에서 기존의 딥러닝 구조보다 평균 29.86% 낮은 리소스 점유율을 나타내었고, 이를 실제 임베디드 시스템에 적용에 성공하여 적합한 딥러닝 구조임이 입증되었다. 화재 검출률은 98.2%로서 기존의 딥러닝 구조와 비교하여 평균 0.95% 낮은 결과를 나타내었으나, 이는 임베디드 시스템에 적용하기 위해 적합한 딥러닝 구조를 개발하기 위하여 기존의 딥러닝 구조보다 가볍게 구성한데서 나온 결과이다. 또한, 화재 감지 시간의 경우 기존의 딥러닝 구조보다 평균 8초 빠르게 화재를 감지하는 결과를 나타내었다.",
객체인식 모니터링과 이미지 딥러닝을 이용한 독거노인의 낙상 판단 방법론 개발,2019,"고령화로 인해 독거노인의 수가 급증함에 따라 독거노인의 안전사고 또한 증가하고 있다.
이로 인해 독거노인의 주거 공간에서 일상 생활을 모니터링하여 응급상황시 신속한 대응이 가능한 모니티렁 시스템에 대한 수요가 늘어나고 있다.
본 논문에서는 독거노인의 위급상황 문제에 보다 신속하게 대처하기 위해 객체 인식 모니터링과 이미지 딥러닝을 이용한 낙상 감지 방법론을 제안한다.
Tensorflow Object Detection API를 이용한 데이터 전처리 과정과 사람의 자세를 분류하고 자세의 변화를 통해 위급상황 중 낙상 상황을 감지하는 시스템을 구현하였다.
제안된 시스템을 검증하기 위해 실제 독거노인의 주거환경과 유사한 황경에서 영상 촬영 장비의 각도와 거리를 변화시켜가며 자세 분류 모델의 자세 인식 성공률에 대해 검증하고 낙상 상황의 인식 성공률을
검증하는 실험을 수행하였다.
본 연구의 시스템은 노인이나 장애인 및 아동의 갑작스런 비정상 행동과 같은 다양한 행동 패턴 분석에 활용될 것으로 기대된다.

As the number of the elderly living alone has increased due to the aging society, the accidents of the elderly living alone have also increased. As a result, there is a growing demand for monitoring systems that can monitor daily life of the elderly living alone and respond promptly in emergency situations.
This paper proposes detection methodology for accident from a fall using object detection monitoring and image deep-learning order to cope with emergency situations of the elderly living alone more quickly. It used Tensorflow Object Detection API to classify human postures and to provide preprocessing to improve system performance. To implement a system to detect accident from a fall during emergency situations by changed posture.
To verify the proposed system, the human posture recognition success rate was examined, and an experiment on emergency situation recognition was performed while the angle and distance of the camera were varied in a setup similar to the residential environment of elderly living alone.
It is expected that the proposed framework for the emergency notification system for the elderly will be utilized for the analysis of various behavior patterns, such as the sudden abnormal behavior of the elderly, people with disabilities, and children.","#독거노인, #낙상, #객체인식 모니터링, #이미지 딥러닝, #전처리, #Tensorflow"
차량 번호판의 실시간 인식을 위한 딥러닝 기반 OCR설계,2019,"최근 차량 번호판 실시간 인식 시스템은 다양한 분야에서 상용화 되어있으며 카메라만을 이용한 저가의 임베디드 시스템을 선호한다. 이러한 시스템은 차량이외 객체의 출현이 없는 주차장 같은 환경의 경우 98%이상의 높은 인식률을 보이고 있지만 환경이 제한되지 않은 골목이나 일부 도로에서는 50~70% 사이의 인식률을 보인다. 이러한 성능의 저하는 실시간 상황에서 나타나는 조도변화나 차량이외의 물체출현 등에 의한 외부 환경변화 요인이 아웃라이어데이터가 되기 때문에 발생한다. 본 논문은 카메라 이미지 입출력이 가능한 임베디드 보드를 이용하여 딥러닝 기반 차량 번호판 OCR시스템을 설계한다. 환경이 제한되지 않은 상황에서의 OCR 인식률 향상을 위하여 준 지도학습과 시계열분석 기법을 적용한다. 준 지도학습은 일반데이터와 아웃라이어데이터를 함께 하나의 모델에 학습시킴으로써 아웃라이어를 식별하여 인식률을 향상시킨다. 시계열분석은 각각의 실시간 프레임 사이의 데이터들을 비교분석함으로써 더 신뢰성 높은 프레임의 데이터를 선별해낸다. 성능 비교실험을 위하여 환경이 제한되지 않은 상황에서 일반적인 차량 번호판 OCR시스템과 본 논문에서 제시한 기법으로 구현된 차량 번호판 OCR시스템의 인식 정확도를 측정한다. 결과적으로 일반적인 차량 번호판 OCR시스템은 77%의 인식률을 보였으나 준 지도학습과 시계열분석이 적용된 차량 번호판 OCR시스템은 88%의 인식률을 보였다. 준 지도학습과 시계열분석 두 가지 기법을 활용한다면 인식률을 향상시킨 차량 번호판 OCR시스템의 구현이 가능하다는 것을 알 수 있었다.

Recently, the real-time recognition system of car license plates has been commercialized in a variety of fields, and it prefers low-cost embedded systems using only cameras. These systems have a higher recognition rate of over 98% for the environments such as parking lots where non-vehicle objects do not appear. However, there is a 50% to 70% recognition rate on some roads or alleys where the environments are not restricted. The decrease in performance occurs when the external environmental factor, such as the occurrence of non-vehicle objects or the changes in illumination, become the outlier data. This paper designs the license plate OCR system based on deep learning and the system uses the embedded board which enables the input and output of the images of camera. To improve OCR recognition rate in situations where the environments are not restricted, semi-supervised learning and time-series analysis techniques can be applied. Normal data and outlier data are learned together in one model by semi-supervised learning, and it identifies the outlier and improves the recognition rate. Time series analysis identifies more reliable frame data by comparing real-time frame data. In order to perform the experiment for the performance comparison, measure the recognition accuracy of general licence plate OCR system and this paper’s proposal technique of licence plate OCR system in a situation where the environment is not restricted. As a result, the general license plate OCR system had a recognition rate of 77%, whereas semi-supervised learning and time-series analysis based on license plate OCR system had a recognition rate of 88%. Using the two techniques, semi-supervised learning and time-series analysis, we could see that the OCR system with an improved recognition rate can be implemented.","#번호판인식, #OCR, #딥러닝, #아웃라이어, #시계열분석"
딥러닝을 이용한 콘크리트 구조물 균열 탐지 및 정량화 기술,2019,"콘크리트 구조물을 효율적으로 검사하기 위해 영상기반 기술을 사용하여 균열을 탐지하려는 많은 시도가 있었다. 하지만 대부분은 이상적인 환경에서 개발되어 실무 적용에 한계를 보인다. 따라서 본 연구는 최근 영상 분야에서 뛰어난 성능을 보이고 있는 딥러닝 기술을 사용하여 실무에 적용할 수 있는 균열평가 Framework를 제안한다. 균열평가 Framework는 딥러닝 모델을 이용한 균열탐지와 이미지 프로세싱을 이용한 폭 정량화의 두 단계로 구성된다. 먼저 이미지 분류용 딥러닝 모델인 AlexNet을 균열탐지에 대해 학습시켰다. 학습된 AlexNet의 성능 검증을 위해 실제 구조물에서 촬영된 영상에서 균열탐지를 수행하였다. 균열탐지용으로 학습된 AlexNet은 사각형 박스 모양으로 균열을 탐지하기 때문에 균열을 직관적으로 시각화하는데 한계를 보였다. 이러한 한계를 극복하기 위해 물체의 위치를 탐지하고, 픽셀 단위로 영역을 표출하는 딥러닝 모델인 Mask and Region-based Convolutional Neural Network(Mask R-CNN)을 균열 평가 Framework에 적용하였다. Mask R-CNN의 학습을 위하여 균열 이미지 376장이 학습 데이터로 사용되었다. 학습된 Mask R-CNN의 성능을 검증하기 위해 실제 콘크리트 구조물에서 균열 탐지를 수행하였다. 학습된 Mask R-CNN은 벽면에 분포한 453개의 균열 중 345개의 균열을 탐지하였다. 구조물 검사에 중요한 0.3mm 이상 균열은 벽면 상에서 총 21개이며 이중 20개를 탐지하여 학습된 Mask R-CNN이 실제 구조물 균열 검사에 사용될 수 있음을 보였다. Mask R-CNN이 탐지한 균열들 중 10 군데에서 이미지 프로세싱으로 균열 폭을 측정하였으며, 평균 0.084mm, 최대 0.25mm 이내의 오차를 보였다.

So far, many approaches have been developed to detect cracks using image-based techniques to inspect concrete structures efficiently. However, majority of them were developed in the ideal environment and showed significant limitation in practice. This study proposes a practical crack assessment framework using deep leaning technologies that show outstanding performance in the image recognition field recently. The proposed crack assessment framework consists of two stages: (1) crack detection using a deep learning model and (2) crack width quantification using image processing. First, AlexNet, a deep learning model for image classification, was fine-tuned for crack detection, and tested on the images taken from real structures. To overcome the practical limitations of AlexNet, Mask and Region-based Convolutional Neural Network (Mask R-CNN), which detects the position of an object and displays the area in pixels, is alternatively trained using 376 crack images, and tested on the images taken from a real concrete wall. The trained Mask R-CNN successfully detected 20 out of 21 cracks over 0.3 mm, which showed great performance in detecting cracks from images. Then, 10 selected cracks detected by the Mask R-CNN model were quantified using image processing, which results in the error of 0.084mm average and 0.25mm maximum. From the tests, the proposed crack assessment framework have shown great potential as an alternative to the conventional visual inspection.","#Concrete Crack, #Convolutional Neural Networks, #AlexNet, #Mask R-CNN, #Crack Width Quantification"
딥러닝을 활용한 로봇의 관객 표정 파악과 상호작용적 표정 생성,2019,"본 논문에서는 사람과 로봇이 자연스러운 감정 소통을 하기 위해 딥러닝 기반의 비디오 시퀀스 감정 판단 시스템과 딥러닝 기반의 로봇 표정 생성 대화 시스템을 제안한다. 오토마타와 같이 인간의 형상을 한 기계 장치로부터 현대의 로봇까지 인간과 닮은 형상을 하고 기계적 움직임을 가진 작품들에게 느껴질 수 있는 언캐니함에 주목한다. 의도적으로 로봇에 적용시킨 형태적인 언캐니함과 달리 기술력의 부족으로 생기는 언캐니함은 사람과 로봇의 상호작용에 몰입도를 저하시키는 요소가 될 수 있다. 이를 극복하기 위한 방향으로 자연스런 인터렉션을 위한 방법론을 제안한다. 로봇이 사람의 감정을 읽고 그에 적합한 반응을 하는 감성컴퓨팅 기반의 상호작용이 기계와 인간의 인터페이스에서 얼마나 중요한 역할을 하는지에 대해 논한다. 그리고 인공 감성을 만들기 위해서 단순 표정부터 학습하여 수많은 경험과 선택을 통해 창발적으로 복잡한 인공감성을 만들어낼 수 있는 가능성을 제시한다.
인공 감성을 생성하기 위한 방법으로 본 작품에서 차별적으로 구현된 시퀀스 기반의 표정 판단 및 생성 시스템에 대해 상세히 기술한다. 제안된 시스템에서는 비디오 데이터에서 눈, 눈썹, 입 등 주요 특징 점의 변화를 파악하여 표정이나 제스처를 딥러닝의 한 방식인 RNN 인공신경망으로 학습하고, 감정 상태나 제스처의 종류를 학습된 모델에 따라 판단함으로써, 관객의 감정 상태를 파악한다. 관객과 대화를 할 때 관객의 감정상태를 반영한 내용으로 대화를 하고, 대화에 맥락에 맞도록 로봇의 표정을 실시간으로 생성해낸다. 나아가 로봇의 표정 생성에 있어서, 대화 중 수집된 관객의 표정과 부위별 표정 지표를 추가 학습함으로써 보다 자연스러운 표정 생성이 가능하도록 지속적으로 업데이트한다.
관객의 표정 및 제스처 인식을 위해 400여개의 비디오 데이터로 학습한 결과 93%의 정확도로 판별 가능한 것으로 확인되었으며, 로봇 표정 생성을 위해 31만여개의 비디오 데이터로 학습한 결과 88%의 정확도로 표정 생성이 가능한 것으로 확인되었다. 개발된 시스템은 실제 표정 재현이 가능하고 인터랙티브 아트의 성격을 띤 로봇으로 구현하여 전시장에서 관객과 자연스럽게 표정을 지으며 대화하도록 하였다.
본 연구는 관객 감정이나 제스처 파악과 특히 로봇 표정 생성에 딥러닝 방식을 적용한 것에 그 의의가 있으며, 향후 감정 파악 및 생성뿐만 아니라 대화 시스템 자체에도 딥러닝 방식을 확대 적용하여 관객 표정에 대한 단순한 반응이 아닌 정교한 감정 모델을 이용한 고차원적인 반응과 소통에 대해 초석이 될 수 있다는 점에 의미가 있다.",
초고해상도 항공 이미지의 객체 검출을 위한 딥러닝 구조 설계,2019,"항공 이미지 데이터는 점차 해상도가 높아지고 용량이 커짐에 따라 초고해상도의 이미지 데이터를 어떻게 접근하고 분석할지 이슈가 되고 있다. 항공의 초고해상도 이미지는 고정식 센서로 부터 얻을 수 없는 넓은 영역에 대해 많은 정보들을 포함하기 때문에 항공 이미지의 분석은 컴퓨터 비전분야에 중요한 기술이다. 이러한 기술은 작물, 산림관리, 도시계획, 재난구호 및 기후 모델링과 같은 분야에 초고해상도 이미지가 광범위하게 응용되고 있다.
하지만, 일부 응용영역에 대해서는 아직 전문가나 일부 자동화된 응용에 한정되고 있으며 만족할만한 성능을 내지 못하는 실정이다. 성능저하의 주된 요인은 시스템 설계에 수 작업된 특징을 사용하기 때문이다. 수작업을 통해 얻어진 특징은 구성화하기 힘들고 해당분야의 전문 지식을 필요로 하기 때문에 알고리즘에 기반을 둔 자동화된 특징 추출 방법이 요구된다. 최근 주목되고 있는 딥러닝 기법은 학습과정에서 직접 원시데이터(픽셀)로 부터 로우레벨 및 하이레벨 특징을 추출할 수 있어서 전문지식을 필요로 하지 않으며 원시 데이터에서 중요한 특징을 자동으로 학습할 수 있기 때문에 최신 기술들의 성능을 개선할 수 있도록 딥러닝 학습기법을 적용하였다.
본 논문의 주요 목표는 초고해상도 항공이미지로부터 차량을 검출 하고 차량의 대수를 계산할 수 있는 시스템 개발을 목적으로 하고 있다. 이러한 연구는 도시계획 및 교통관리와 같은 다양한 응용에 중요한 연구 분야 이며 차량의 크기가 상대적으로 작기 때문에 건물의 외관이나 에어컨시설, 쓰레기통 및 도로표지와 구분하기가 매우 어렵다.
제안한 시스템은 CNN(Convolution Neural Network)기법을 사용하여 항공 이미지에서 차량의 공간밀도 영역을 학습 하도록 하였고 자동 엔코더(Auto-Encoder)모델을 설계하여 최신 기법들 보다 검출 성능을 높이도록 하였다. 확장응용으로 고해상도 이미지로 부터 차량뿐만 아니라 일반적인 물체 또한 검출 할 수 있도록 하였고 항공이미지의 다양한 스케일 문제를 해결하였다. 고해상도 항공이미지로부터 물체를 효율적으로 검출하기 위해 ‘a one-stage densely connected feature pyramid network’ 구조를 제안하고 있으며, 제안한 구조는 검출 속도 및 검출 정확도 모두 최신기법의 성능보다 향상되었음을 확인 하였다.

The increasing amount of the very high-resolution (VHR) aerial images data in recent years has made the interpretation of this data a challenging task. Thus, miming such a large-scale data is needed as these images cover large areas and contain important information that cannot be obtained by fixed-ground sensors.

Recently, various applications based on VHR aerial images have been found such as crop and forest management, urban planning, disaster relief, and climate modeling. However, some of these applications are performed by human experts or automated applications that do not have a satisfying performance. The main reason for the low-performance problem is using hand-crafted features in their system design. Hand-crafted features are difficult to construct and require domain knowledges. Therefore, automated features selection based methods are required.

In the advent of deep learning, it is possible to extract low and high-level features from raw data (pixels) directly during the training process. Thus, deep learning model learns the important features automatically from raw data without any need to have domain knowledge. Therefore, deep learning techniques for developing systems that outperform the current-state-of-the-art have been utilized .

The main goal of this dissertation is to develop systems for automatically finding the locations of objects such as vehicles, airplane, storage tank, etc in VHR aerial images.

A dedicated system for vehicles detection and counting in VHR aerial images has been developed. This task is important for many applications such as urban planning and traffic management and it is challenging because of the small size of the vehicle, different types, and orientations, and similarity in their visual appearance with some other objects such as air conditioning units on buildings, trash bins, and road marks. The proposed system utilizes a convolution neural network (CNN) to regress a vehicle spatial density map across the aerial image. An auto-encoder model for solving this task has been developed. The obtained results outperform the state-of-the-art systems.

In addition, a general object detection system for VHR aerial images has been developed. This system tackles the challenges of different scales and appearances of the objects in VHR aerial images. We have proposed a one-stage densely connected feature pyramid network for object detection in VHR aerial images. This system outperforms the state-of-the-art models in terms of mean average precision of object detection and execution time.","#Aerial image, #convolution neural network, #deep learning, #object detection, #항공 이미지, #컨벌류션 신경 망, #딥러닝 알고리즘, #물체 검출"
3차원 초음파 방광 스캐너 영상에서 방광 추출을 위한 딥러닝 알고리즘,2019,방광의 문제로 인해 고통을 겪는 환자들에게 정확한 잔뇨량을 측정하는 것은 건강과 삶의 질의 향상을 위해 매우 중요하다. 잔뇨량을 측정하는 방법은 많이 존재 하지만 그 중 잔뇨 초음파 검사를 통해 방광 내부의 잔뇨량을 측정하는 방법은 비 침습적이면서 정확한 결과를 도출한다는 장점이 있다. 방광의 잔뇨를 측정하기 위해서 resolution이 낮은 3D 초음파 이미지가 많이 쓰이고 있으며 이러한 이미지에서 잔뇨량의 측정을 위해 사용되는 알고리즘은 보통 일관되지 못한 결과를 보이거나 낮은 SNR(Signal to noise ratio)때문에 정확한 segmentation을 못하는 경우가 많다. 본 논문에서는 3D 방광 스캐너 영상에 딥러닝 알고리즘을 적용하여 방광을 추출하는 방법을 제안한다. 딥러닝 알고리즘은 의료영상 segmentation에 널리쓰이는 U-net을 기반으로 만들어졌으며 U-net을 그대로 초음파 스캐너에 적용하기에는 너무나 고용량이었기 때문에 프로젝트 목적에 맞게 경량화를 통해 새롭게 구성되었다. 경량화된 딥러닝 모델은 제안된 딥러닝 알고리즘은 U-net과 비슷하게 이미지의 특징을 추출하는 Contraction path와 이미지의 resolution을 다시 회복하는 Expanding path로 구성되어있으나 U-net과는 다르게 Average pooling을 통해 첫 convolution을 제거하였으며 다양한 실험을 통해 다양한 부분에서 경량화 하였다. 본 논문에서 제시된 딥러닝 모델은 U-net에 비해 성능은 떨어지지만 3% 이내의 오차의 범위를 가지며 기존에 존재하는 알고리즘에 비해서는 성능이 뛰어난 것을 목표로 한다. 또한 사람이 사용하기에 불편하지 않은 시간을 4초라고 가정하고 실제 ARM에서 속도를 측정하여 시간내에 들어오는 것을 목표로 한다.,
전이 학습을 이용한 딥러닝 객체 인식 기술 기반 유사 패션 상품 이미지 검색에 관한 연구,2019,"최근 패션 업계의 온라인 채널 강화에 따라 온라인상에 방대한 패션 상품들이 존재하게 되면서 사용자에게 적합한 패션 상품을 추천하기 위한 다양한 연구들이 진행되고 있다. 그 중 사용자가 관심 있는 상품과 유사한 다른 상품 리스트를 보여주는 추천 방식이 있다. 본 연구에서는 이를 위하여 전이 학습 기반 객체 인식 기술을 활용한 유사 패션 상품 이미지 검색 기법을 제안한다.
온라인 쇼핑몰, 뉴스 기사 등 온라인상에 존재하는 많은 패션 상품 이미지는 패션 상품 이외의 상품을 착용한 모델, 배경 등 다양한 시각적 단서를 포함하고 있다. 만약, 이러한 이미지의 전체 영역을 활용하여 유사도 분석을 통해 유사한 패션 상품을 찾게 되면 제대로 된 추천이 어려울 것이다. 기존에 패션 상품 인식을 활용한 유사 패션 상품 검색에 관한 연구들이 존재하나, 낮은 성능으로 해당 기법의 효용성을 증명하지 못했다.
이러한 문제를 해결하기 위하여 본 연구에서는 R-CNN 네트워크 및 R-CNN 네트워크 내 특징 추출 네트워크에 변화를 주어 패션 상품 인식 모델을 생성하였다. 그리고 CNN 기반 딥러닝 네트워크 및 벡터 공간 모델을 활용하여 유사 패션 상품 검색을 한다.
본 연구에서 생성한 R-CNN 기반 패션 상품 인식 모델은 약 87%의 mAP@0.5IoU를 보였다. 또한 유사 패션 상품 검색 성능은 Precision at K에서 약 77.8%로 기존 연구와 비슷한 의미 있는 성능을 보였다.

Recently, with the strengthening of the online channels of the fashion industry, a vast number of fashion products have come to exist on the online market. Accordingly, various studies are being conducted to recommend a fashion product suitable for a user. Among them, there is recommendation method that shows other goods that are similar to the products that the user is interested in. In this study, we propose a similar fashion product image retrieval method using the object detection technology based on transfer learning.
Many fashion product images that exist on-line include various visual cues that are not related to fashion products such as model wearing a product, background and so on. If we use the whole area of these images to find similar fashion items through similarity analysis, it will be difficult to recommend them properly. There have been studies on the search for similar fashion products using object detection technique, but the effectiveness of the technique has not been proved with low performance.
In order to solve this problem, this study proposes an transfer learning based fashion product recognition model by changing R-CNN network and the feature extraction network in R-CNN network.
The R-CNN based fashion product detection model proposed in this study showed about 87% mAP@0.5IoU. Also, similar fashion product search performance was 77.8% at Precision at K, which is similar to the previous
study.","#딥러닝, #객체 인식, #전이 학습, #유사도 분석"
딥러닝 기반의 세탁기 실행 옵션 자동 추천 기법,2019,"세탁기의 세탁 과정은 세탁, 헹굼, 탈수로 요소를 나누어 진다. 세탁기에서 각 과정들에 부여되는 시간 및 기능, 횟수에 따라 각 과정들을 조합 할 수 있으며, 각 조합에 의해 세탁 코스가 생성된다. 세탁 요소의 조합을 코스라고 한다면 코스의 편의성 또는 각 개별 기능을 보다 세분화 하기 위하여 사용자는 기본 코스 설정에서 각 옵션들을 가변 할 수 있으며 세탁의 강도, 헹굼의 횟수, 탈수의 강도, 수온, 스팀의 유무, 터보 샷의 유무, 건조의 방법 및 시간 등 세탁의 내용에 관한 많은 설정들을 세분화하여 조절 가능하다. 즉 고객은 본인의 요구 및 취향에 따라 기본적으로 구성되어 있는 코스를 선택할 수 있으며 선택 된 코스에서 옵션을 가변 하여 맞춤 세탁을 진행 할 수 있다.

결국 고객의 의사를 반영하기 위해서는 많은 키의 조작이 필요하며, 고객에게 필요로 하는 선택을 증가 시킬수록 고객의 조작성이 나빠질 수 있다. 세탁기를 켜고, 코스를 선택하며, 각 옵션들을 설정하고 동작하기 까지 최소 3번의 패널 키 입력에서 많게는 십 수번의 입력을 진행해야 한다. 이는 고객에게 다양한 옵션 선택의 가치를 제공할 수 있는 이점과 키 입력의 증가로 사용 편의성이 나빠진다는 단점이 된다. 세탁기가 많은 선택을 할 수 있으며 다양한 능력이 있다는 마케팅의 장점이 될 수 있지만 조작에 불편함을 느끼는 고객에게는 알아서 해주지 못하거나 너무 복잡하다는 단점으로 다가 올 수 있다.

본 논문에서는 기존 방법 및 관련 연구를 분석하고 본질적인 문제를 해결하기 위한 세탁기 실행 옵션 자동 추천 기법을 제안한다. 해당 기법은 고객 사용성 데이터를 효과적으로 분석하기 위해 빅 데이터 분석에서 주로 사용되고 있는 딥러닝을 통해 알고리즘을 설계하였고 설계된 알고리즘을 제품에 적용하고 추가로 실시간 날씨(온도, 습도, 미세먼지)정보를 통해 최적 세탁 실행 옵션을 추천한다.

The washing process of the washing machine is divided into washing, rinsing and dehydration. Each process can be combined according to the time, function, and number of times given to each process in the washing machine, and a washing course is created by each combination. If the combination of the washing elements is a course, the user can change the options in the basic course setting in order to further improve the convenience of the course or each individual function. The user can change the strength of the laundry, the number of times of rinsing, the strength of dehydration, , The presence or absence of a turbo shot, the method and time of drying, and the like. That is, the customer can select a course that is basically configured according to his / her needs and preferences, and can change the options in the selected course to carry out customized laundry.

As a result, many key manipulations are required to reflect the customer''s desires, and the more the customer needs to choose, the worse the customer''s operability will be. Turn on the washing machine, select the course, set up each option, and proceed to enter at least three panel keystrokes at least a dozen times before it works. This is a disadvantage that the user can be provided with the value of various option selection and the ease of use is increased due to the increase of the key input. A washing machine can have many choices and a variety of abilities can be an advantage of marketing, but it can be a disadvantage to customers who feel uncomfortable to operate or to be too complicated.

In this paper, we propose an automatic recommendation method of washing machine execution option to analyze the existing method and related research and solve the essential problem. In order to effectively analyze customer usability data, the technique is designed by deep running, which is mainly used in big data analysis, and the designed algorithm is applied to the product, and furthermore, by using real time weather (temperature, humidity, fine dust) we recommend the run option.","#세탁기, #딥러닝, #실행 옵션"
딥러닝 기법을 활용한 교통사고위험예측 모델개발 연구,2019,"정부차원의 노력과 대응에도 불구하고 국내 교통사고는 해마다 조금씩 증가하고 있으며, 인구고령화와 여성운전자의 증가로 인해 여성, 노인 운전자 교통사고율이 크게 높아지고 있는 실정이다. 교통사고의 위험을 예측하고 사전에 예보한다면 운전자의 사고를 예방하고 사고에 대한 빠른 대응을 할 수 있을 것이다. 교통사고위험예측과 관련된 기존 연구는 교통사고 건수 분포에 근거한 다양한 통계방법으로 예측하였는데 교통사고 당시의 인적 상황이나 도로의 기하학적 구조 등 환경적 요인에 의한 교통사고의 인과관계만을 파악하는 분석의 한계가 있었다. 최근 들어 다양하게 수집되는 이종의 교통 데이터가 폭발적으로 증가하고 있어, 교통 빅데이터를 기반으로 심화된 분석, 예측이 가능한 새로운 머신러닝, 딥러닝 접근 방법들이 주목 받고 있다. 본 연구에서는 주요 6개도시 약 4,500개 사고다발지점을 대상으로 교통사고위험을 예측하였으며, 교통사고 및 방송제보, 교통소통현황, 날씨, 공공3.0정보를 분석정보로 활용하였다. 교통사고의 다양한 패턴을 잘 학습할 수 있는 딥러닝 모델인 DeepFM을 최종 모델로 선정하고 기존 머신러닝 모델과 정확도를 비교하여 우수함을 확인하였다. 개발된 모델을 활용한 교통사고위험예측 서비스를 통해 대국민 교통안전 및 교통사고율 감소에 기여할 것을 기대한다.",
딥러닝 모델을 활용한 임베디드 플랫폼에서의 난폭운전 감시 기술에 관한 연구,2019,"본 연구는 임베디드 플랫폼에서 딥러닝 모델을 활용하여 난폭운전을 감시하고 분류하는 기술에 대한 내용을 다루고 있다. 난폭운전을 감시하고 단속하는 것은 안전을 위해 반드시 수행되어야 하는 일이지만, 현재 그것을 자동적으로 감지하고 단속할 수 있는 방법은 존재하지 않는다.
본 연구를 통해 임베디드 플랫폼에서 자동적으로 난폭운전을 감지하는 기술을 제안한다. NVIDIA Jetson TX2 플랫폼에서 카메라로 도로를 촬영하고, 딥러닝 프레임워크를 통해 도로 위의 난폭운전을 감지한다. 본 연구에서 제안하는 시스템은 영상을 프레임 단위로 분석하고, 차량의 주행을 추적하고, 그 결과를 2D 공간에 좌표화하여 낮은 프레임율을 가진 영상(5 fps)에서도 정확하게 동작하는 방식을 제안한다. 이 방식을 통해 얻어진 차량의 주행 데이터를 기반으로 주변 차량과의 주행 패턴 비교를 통해 난폭운전을 감지한다. 차량의 종횡 방향 움직임 분석의 결과를 통해 통한 난폭 운전 감시 기술에 대한 가능성을 제시하고 있다. 본 연구의 핵심 목표는 임베디드 환경이라는 GPU의 성능 및 자원의 제약사항을 고려하여 경량화된 분석 시스템을 구현하는 것이다. 최종적으로 본 연구는 종, 횡 방향에서의 차량의 움직임 모두를 정확히 인식할 수 있다는 결과를 보였고 이것으로 비디오 기반의 자동 차량 감시 시스템 구축의 가능성을 제시하고 있다.

Reckless driving is defined as a mental state in which the driver disregardsrules on the road and common driving procedures. While reasons behind reckless driving may be diverse and hard to be defined, it is important that such activities are monitored and detected to assure road safety. However, detection of such dangerous vehicles have been done manually until now, and there is a need to automate this.
In this work, we present an embedded system for autonomously detecting reckless driving activities on the road in real-time. Specifically, using an NVIDIA Jetson TX2 platform, a camera, and a combination of light-weight deep learning models, we design a system that can identify abnormal vehicle motions via images on the road. Our system analyzes discrete per-frame images from the vehicle detection module, and creates a continuous trace of the vehicle''s motion trajectory. While doing so, we generate a virtual grid on the road to obtain positions of vehicles with less overhead and accurately track a vehicle''s movement even with low frame rate (5 fps) videos. The vehicle''s motion trajectory is then compared against the surrounding vehicles to identify abnormal moving activity through driving activity classification, which can be provided to road monitoring personnel for final validation. The key challenge is to take into consideration the resource constraints of embedded platform, and we design algorithms to overcome their performance limitations. Evaluation results show that our scheme can well-extract the horizontal and vertical movements of a vehicle and show the potential for deploying autonomous reckless driving activity detection systems.","#임베디드 컴퓨팅, #딥러닝, #물체인식, #도로감시"
딥러닝을 이용한 주행환경 분석,2019,"최근 자율주행 차량의 연구가 완성차 업체나 IT 업체에 의해 많이 진행되고 있다. 자율주행 차량의 연구는 인지, 판단, 제어의 세 가지 영역으로 나눌 수 있다. 현재의 자율주행 차량은 인지와 판단의 과정에서 실제 도로에서 주행할 때 다른 차량이나 보행자, 신호등과 같은 교통정보를 카메라나 판단하는 기술은 자율주행의 필수적인 요소 기술이다.
본 논문은 딥러닝을 이용하여 차선을 검출하는 과정에 대하여 기술하였다. 최근 인공지능 관련 기술이나 영상처리 알고리즘에 주로 사용되는 딥러닝(Deep Learning) 방법 가운데 한 방법인 CNN(Convolutional Neural Network)을 이용하여 차선 검출의 알고리즘의 구현을 진행하였다. 차선 검출 알고리즘은 CNN 모델 구성과 모델의 인자의 학습을 위한 데이터의 제작 및 구성, 실제 인자 학습 및 차선 검출 테스트를 진행한다.
딥러닝 차선 검출 알고리즘은 CNN의 다양한 방법인 분류(Classification), 회귀 분석(Regression)과 시맨틱 분할(Semantic Segmentation) 등의 방법을 각각 이용하여 차선의 검출을 진행하였으며 CNN 구조의 구성과 인자의 학습과정 및 차선 검출 과정은 딥러닝 오픈 프레임워크인 Tensorflow와 Keras를 이용하여 구성하였다.
각각의 방법에서의 CNN 구조의 구성 및 인자의 학습에 이용할 학습 데이터의 구성을 다루었다. 또 인자 학습을 마친 CNN 구조의 학습 진행 오차와 성능을 각각 비교하였으며, 최종적으로 다항식 형태의 차선 검출 결과에서의 성능 비교를 진행하였다. 또 두 개의 서로 다른 데이터의 형태로 학습을 진행한 CNN 구조를 융합하여 새로운 결과를 나타내는 방법을 활용한다.

This paper describes the process of detecting lanes using deep learning. Deep Learning is a method that is mainly used in artificial intelligence researches and image processing algorithms. CNN (Convolutional Neural Network), which is one of the deep learning methods was used to implement the algorithm of lane detection. The lane detection algorithm carries out the construction and construction of data, the model training, and the lane detection test for CNN model. Deep learning lane detection algorithms are based on CNN classification, regression, and semantic segmentation methods. CNN structure and learning process, the lane detection process was constructed by using Tensorflow and Keras, which are open source deep learning frameworks.
We also describe the structure of training data for learning CNN structure and training in each method. In addition, we compare the learning progress error and performance of the CNN structure after training process. Finally, we compare the performance of the polynomial lane detection results.",
딥러닝을 이용한 온라인 리뷰 기반 다속성별 추천 모형 개발,2019,"추천시스템은 사용자의 선호도 및 성향의 패턴을 파악하여, 사용자가 미래에 이용할 상품을 예측하여 정보를 제공하는 정보시스템이다. 대부분의 추천시스템 연구는 사용자 선호도를 추론하기 위해 사용자가 제공한 상품의 총 평점 데이터를 이용하여 추천 서비스를 제공한다. 평점은 정량적 정보로 상품에 대한 전반적인 사용자의 선호도를 파악할 수 있지만, 이에 대한 구체적인 이유 및 정보를 파악하기 어렵다. 최근에는 사용자가 생성한 텍스트 리뷰를 활용하여 추천시스템 연구가 진행되고 있다. 텍스트 리뷰는 사용자들의 사용 경험을 바탕으로 상품에 대한 만족 및 불만족에 대해 자세하게 기술한 데이터로 추천시스템에서 가치 있게 활용될 수 있다는 장점이 있다. 또한 평점으로 파악하기 어려운 상품의 정보나 상품의 세부적인 속성에 대한 정보를텍스트 리뷰를 통해 얻을 수 있다.
따라서 본 연구는 활용 가치가 높은 텍스트 리뷰 데이터를 이용하여 상품의 속성을 추출하고, 각 속성별 추천시스템을 구현하고자 한다. 딥러닝 기법인 제한 볼츠만 머신(Restricted Boltzmann Machines)을 이용하여 추천 정확도 및 추천 모형의 성능을 향상시키고자 한다. 그리고 본 연구에서 제안하는 모형과 관련한 2개의 추가적인 모형을 제시하여 총 3가지의 텍스트 기반의 속성별 추천 관련 모형을 제시하고자 한다.","#딥러닝, #텍스트 마이닝, #추천시스템, #리뷰 마이닝"
안저영상 기반 녹내장 진단 및 중증도 등급화를 위한 딥러닝 모델,서울대학교 논문은 저작권에 의해 보호받습니다.,"서론: 본 연구는 안저영상을 바탕으로 녹내장 선별검사와 녹내장 중증도를 자동으로 분류하기 위한 합성곱신경망의 앙상블 방법에 관한 것이다. 녹내장의 선별검사와 중증도 등급화를 자동화하기 위해 서로 다른 특성을 갖는 48개의 합성곱신경망 모델을 정의하고 훈련했다. 학습을 완료한 모든 모델은 본 연구에서 제안하는 앙상블 방법을 통해서 최종 판독 결과를 도출하였고, 그 성능을 평가하였다.
방법: 본 연구에서는 합성곱신경망 모델의 훈련을 위해 2,801명의 환자로부터 측정한 4,445장의 안저영상을 수집하였다. 수집한 안저영상은 4명의 녹내장 전문의가 정상 집단과 녹내장 집단으로 분류하고, 녹내장 집단은 시야검사 결과의 평균 편차 (Mean Deviation, MD)를 참조하여 초기 녹내장 집단과 중증 녹내장 집단으로 세분화하였다. 이때, 평균 편차가 -6dB 이하를 중증 녹내장 집단으로 분류하였다. 또한, 환자 1명으로부터 좌, 우 각각 최대 1장씩의 안저영상을 사용하였다. 전체 안저영상 중에서 영상 품질이 열악한 것과 4명 녹내장 전문의의 등급 판정 결과가 100% 일치하지 않은 영상을 제외한 2,204명의 3,460장을 가지고 합성곱신경망 모델을 훈련하였다.
모델의 성능은 정확도, 민감도, 특이도, AUROC(Area Under the Receiver Operating Characteristic)을 평가 지표로 삼았다. 이때, InceptionNet-v3를 기준 모델로 하고, 본 연구에서 제안한 앙상블 방법과 성능을 비교하였다. 두 방법의 성능평가 결과를 Shapiro-Wilk normality test로 정규성 검정을 하였으며, paired t-test를 사용하여 두 방법의 성능 차이에 대한 통계적 유의성을 검정하였다.
결과: 본 연구에서 제안한 합성곱신경망 앙상블 방법은 녹내장 선별검사에 관한 것과 녹내장 중증도 분류에 관한 것으로 분리하여 성능을 평가하였다. 녹내장 선별검사의 정확도 측면에서 앙상블 방법은 96.6% (95% confidence interval [CI], 95.5 ~ 97.8%)를 보였다. 반면, InceptionNet-v3 모델 한 개를 사용한 기준 모델은 93.9% (95% CI, 92.6 ~ 95.2%)를 보였다. 기준 모델과 앙상블 방법의 녹내장 선별검사 정확도에 대한 성능 차이는 paired t-test를 통해 통계적 유의성을 검정하였고, 그 결과는 p-value 0.000425로 정확도의 차이가 통계적으로 유의함을 밝혔다. AUROC 측면에서 앙상블 방법은 0.994 (95% CI, 0.990 ~ 0.997)를 보였으며, InceptionNet-v3 모델 한 개를 사용한 기준 모델은 0.977 (95% CI, 0.969 ~ 0.986)를 보였다. 녹내장 선별검사에 있어서 기준 모델과 앙상블 방법의 AUROC에 대한 성능 차이는 역시 paired t-test를 통한 통계적 유의성을 검정하였고, 결과는 p-value 0.000966으로 AUROC의 차이가 통계적으로 유의함을 밝혔다. 이로써 녹내장 선별검사에서 앙상블 방법이 정확도와 AUROC 측면에서 더 높고 안정적인 것을 확인하였다. 녹내장 중증도 분류의 정확도 측면에서 앙상블 방법은 87.7% (95% CI, 85.9 ~ 89.7%)를 보였고, InceptionNet-v3 모델 한 개를 사용한 기준 모델은 82.3% (95% CI, 80.2 ~ 84.1%)를 보였다. 녹내장 중증도 분류에 있어서 기준 모델과 앙상블 방법의 정확도 차이는 paired t-test를 통해 통계적 유의성을 검정하였고, 그 결과는 p-value 0.002902로 그 차이가 통계적으로 유의함을 밝혔다. 평균 AUROC 측면에서 앙상블 방법은 0.975 (95% CI, 0.967 ~ 0.983)를 보였으며, InceptionNet-v3 모델 한 개를 사용한 기준 모델은 0.938 (95% CI, 0.926 ~ 0.949)을 보였다. 녹내장 중증도 분류에 있어서 평균 AUROC에 대한 기준 모델과 앙상블 방법의 성능 차이 역시 paired t-test를 통해 통계적 유의성을 검정하였고, 그 결과는 p-value 0.000093으로 그 차이가 통계적으로 유의함을 밝혔다. 이로써 녹내장 중증도 분류에서도 앙상블 방법이 정확도와 AUROC 측면에서 더 높고 안정적인 것을 확인하였다.
결론: 본 연구에서 제안하는 여러 개의 합성곱신경망을 앙상블 하는 방법은 안저영상을 바탕으로 녹내장 선별검사와 중증도 분류를 자동화하는 데 있어서 기존의 방법보다 우수하고 안정적인 성능을 발휘한다. 본 연구결과는 인공지능 기술을 바탕으로 하는 임상 의사 결정 지원 시스템(Clinical Decision Support System, CDSS) 소프트웨어로, 현재 널리 보급된 안저촬영기에 탑재 또는 연동하는 방식으로 다양한 분야에서 활용할 수 있다. 안저촬영기에 본 연구결과를 탑재하여 건강검진센터나 안과 진료현장에서 활용한다면, 안저촬영 결과의 판독 효율과 정확성을 높일 수 있고, 이에 따른 시간적 이득을 전문의의 2차 판독에 할애함으로써 보다 경제적이고 정확한 검진 결과를 얻을 수 있다. 또한, 본 연구결과를 활용한 의료서비스가 활성화된다면, 잠재적 녹내장 환자에 대한 조기진단의 가능성을 높일 수 있고, 이에 따른 녹내장 환자의 치료 효과 향상과 관련 의료비용 지출을 절감할 수 있다.

Abstract
Introduction: This study is concerned with an ensemble method of convolutional neural networks for automatically screening tests for glaucoma and classifying the severity of glaucoma based on fundus photographs. In order to automate the glaucoma screening and classifying severity stages, we defined and trained 48 convolutional neural network models with different characteristics. Finally, the final readings were obtained through the ensemble method proposed in this study from the models in which the study has been finished and their performance was evaluated.
Methods: In this study, 4,445 fundus photographs from 2,801 patients were collected for the training of the convolutional neural network model. The collected fundus photographs were classified into a normal group (unaffected control class) and a glaucoma group by 4 ophthalmology and glaucoma specialists, and the glaucoma group was further divided into an early-stage glaucoma class and a late-stage glaucoma class by referring to the mean deviation (MD) of visual field test results. At this time, the mean deviation value of -6dB or less was classified as a late-stage glaucoma class. Also, up to one fundus photograph was used per side, left and right, for each patient. Out of the all fundus photographs, 3,460 photographs of 2,204 people were used to train the convolutional neural network model, except for the photographs with poor image quality and the ones without 100% agreement on the grade of glaucoma by 4 specialists. The performance of the model was evaluated using the accuracy, sensitivity, specificity, and area under the receiver operating characteristic (AUROC). At this time, the performance of the proposed ensemble method in this study was compared with InceptionNet-v3 as a baseline model. The performance evaluation results of the two methods were tested using the Shapiro-Wilk normality test and the paired t-test was used to test the statistical significance of the performance differences between the two methods.
Results: The performance of the convolutional neural network ensemble method proposed in this study was evaluated separately, one related to the glaucoma screening test and one with the classification of glaucoma severity. The accuracy of the glaucoma screening test was 96.62% (95% confidence interval [CI], 95.5 ~ 97.8%) in the ensemble method. On the other hand, the reference model using one InceptionNet-v3 model showed 93.9% (95% CI, 92.6 ~ 95.2%). The difference in performances between the reference model and the ensemble method for glaucoma screening test accuracy was tested for statistical significance by paired t-test and the result showed that the difference of accuracy was statistically significant with the p-value of 0.000425. In terms of AUROC, the ensemble method showed 0.994 (95% CI, 0.990 ~ 0.997), and the reference model using one InceptionNet-v3 model showed 0.977 (95% CI, 0.969 ~ 0.986). The difference in performances between the reference model and the ensemble method for AUROC of glaucoma screening test was tested for statistical significance by paired t-test and the result showed that the difference of accuracy was statistically significant with p-value of 0.000966. We confirmed that the ensemble method proposed in this study has higher and more stable accuracy and AUROC for glaucoma screening compared to the reference model. In terms of accuracy of severity classification of glaucoma, the ensemble method showed 87.7% (95% CI, 85.9 ~ 89.7%), and the reference model using one InceptionNet-v3 model showed 82.3% (95% CI, 80.2 ~ 84.1%). The difference in accuracy between the reference model and the ensemble method for glaucoma screening test was tested for statistical significance by paired t-test and the result showed that the result was statistically significant with the p-value of 0.002902. In terms of average AUROC, the ensemble method showed 0.975 (95% CI, 0.967 ~ 0.983), and the reference model using one InceptionNet-v3 model showed 0.938 (95% CI, 0.926 ~ 0.949). The difference in performance between the reference model and the ensemble method for average AUROC of glaucoma screening test was tested for statistical significance by paired t-test and the result showed that the result was statistically significant with p-value of 0.000093. We confirmed that the ensemble method proposed in this study has higher and more stable accuracy and AUROC for glaucoma severity classification compared to the reference model.
Conclusions: The proposed ensemble method in this study using multiple convolutional neural networks, shows superior and more stable performance compared to the conventional methods in glaucoma screening test and automating severity classification based on fundus photographs. The results of this study are a clinical decision support system (CDSS) based on artificial intelligence, which can be used in various fields by installing or connecting with the currently widely used fundus camera. By using the results of this study in the fundus camera and utilizing in health check-up centers or ophthalmology clinics, it can improve the efficiency and accuracy of the reading of the fundus photograph results and focus on the second reading by the specialist with its time efficiency, ultimately obtaining more economical and accurate screening results. In addition, if the medical service utilizing the results of the present study is used more actively, the possibility of early diagnosis of potential glaucoma patients can be increased, the medical treatment expenses of the glaucoma patients can be improved, and the related medical expenses can be reduced.","#녹내장, #안저영상, #딥러닝, #합성곱신경망, #앙상블, #인공지능"
딥러닝을 이용한 이변량 장기종속시계열 예측,2019,"본 논문에서는 딥러닝과 모수적 시계열 모형을 이용한 이변량 장기종속시계열(long-range dependent time series) 예측을 고려하였다. 시계열 데이터 예측에 적합한 LSTM(long short-term memory) 네트워크를 이용하여 이변량 장기종속시계열을 예측하고 이변량 FARIMA(fractional Autoregressive Integrated Moving Average) 모형인 FIVAR 모형, VARFI 모형과의 예측 성능을 비교한다. 실증 데이터로는 fMRI(functional MRI) 데이터와 일일 실현 변동성(daily realized volatility) 데이터를 이용하였으며 세 방법론의 표본외 예측(out-of-sample forecasting) 오차를 비교하였다. 분석결과를 통해 FIVAR 모형과 VARFI 모형의 예측값에는 미묘한 차이가 있음을 알 수 있었다. LSTM 네트워크의 경우 초매개변수의 선택으로 복잡해 보이지만 이변량 FARIMA 모형에 비해 뒤지지 않는 좋은 예측 성능을 보였다.

We consider here a bivariate long range dependent(LRD) time series forecasting using deep learning method and parametric time series models. That is, long short-term memory(LSTM) network well-suited to time series data is applied to forecast bivariate time series and we compare the forecasting performance with that of bivariate FARIMA(Fractional Autoregressive Integrated Moving Average) models. The out-of-sample forecasting errors are compared with various performance measures for fMRI(functional MRI) data and daily realized volatility data. The results show that there is a subtle difference in the predicted values of FIVAR model and VARFI model. LSTM is computationally demanding due to hyper-parameter selection, but it is more stable and forecasting performance is competiti","#딥러닝, #장기종속시계열, #LSTM, #FARIMA"
표정 인식에서의 설명 가능한 딥러닝 모델,2019,"표정은 아주 강력한 비언어적인 표현 수단이다. 표정은 사람의 감정을 읽는데 아주 유효하기 때문에, 기계학습이나 컴퓨터 비전 분야에서 표정 인식은 아주 중요한 분야 중에 하나이다. 표정 인식 분야에서는 여러 가 지 기계학습 모델이 사용되나, 딥러닝 모델은 별도의 전처리 없이도 아주 좋은 성능을 보여주어 많이 사용되고 있다. 그러나 이러한 좋은 성능에도 불구하고, 딥러닝 모델은 너무 복잡하고 블랙 박스(Black Box) 방식으로 되어 있어 판단을 내린 과정을 파악할 수가 없다. 이러한 문제로 인해서 딥러닝 모델은 신뢰도가 중요한 의약이나 자율 주행과 같은 분야에는 적 용할 수가 없다. 본 논문은 표정인식을 학습한 딥러닝 모델이 내린 결정 에 대한 근거를 제공할 수 없는 문제를 해결하기 위한 모델을 제안한다. 표정 인식을 학습한 CNN 모델이 내린 판단 결과에 대한 설명을 제공하 는 모델이다. 판단 결과의 설명으로써, FACS의 안면 근육 움직임 단위를 사용하였다. FACS의 안면 근육 움직임 단위를 CNN 모델이 내린 결정의 설명으로서 제공하기 위해서 Manifold Learning 기술 중에 하나인 t-SNE를 통해서 표정과 안면 근육 움직임 단위 간의 상관관계를 파악하였다. 본 논문이 제안하는 모델은 CNN 모델이 결정을 내리는 과정과 결과를 사용 해서 안면 근육 움직임 단위를 생성한다. CNN 모델이 추출한 특성을 CNN 모델이 결정을 내리는 과정이라고 가정한다. 본 논문의 실험에서는 딥러닝 모델이 내린 결정을 설명하기 위해 생성된 안면 근육 움직임 단위 의 정확도가 기존 안면 근육 움직임 단위 분류기에 비해서 보다 더 나은 성능을 보여줄 뿐만 아니라, 더 다양한 종류의 안면 근육 움직임 단위를 분류해 내는 것을 확인할 수 있다. 정확도 측면에서는 AU 2, 5, 7, 12, 15 ,17, 20, 23, 25에서 약 1-4 % 가량 더 높은 성능을 보였으며, F1 Score에

- i - 서는 약 1-12% 정도 더 높은 성능을 보였다. 또한 기존의 안면 근육 움직 임 단위 분류기에서 분류하지 못했던 AU 24와 27에을 분류할 수 있으며, 각각 96.95%, 98.47%로 좋은 성능을 거뒀다. 본 모델을 통해서 역겨움과 경멸과 같은 구별 짓기 어려운 표정에서 어떠한 차이 때문에 두 표정이 다른 지 안면 근육 움직임 단위를 통해서 명시적으로 알 수 있다.",
딥러닝을 위한 저전력 임베디드용 멀티 코어 프로세서 설계,서경대학교 논문은 저작권에 의해 보호받습니다.,"하드웨어가 발전함에 따라 싱글코어가 멀티코어로 대체되기 시작하였다. 어플리케이션의 수행을 멀티 코어로 진행함에 따라 싱글 코어보다 빠른 속도로 프로세싱이 가능해졌다. 그 결과 많은 연산처리 등의 문제로 침체기에 빠져 있었던 알고리즘들의 연구가 활발하게 진행되었으며 특히 많은 연산량 때문에 침체기에 빠져 있었던 딥러닝 알고리즘에 다양한 연구가 진행되었다. 하드웨어의 성능이 증가함에 따라 다양한 딥러닝 알고리즘이 제시되고 있으며, 이를 프로세서가 효율적으로 제어하며 상용화하기 위해서 저전력화는 피할 수 없는 선택이다. 따라서 프로세서의 전력소모량을 줄이려는 연구가 많은 곳에서 진행되고 있다.
본 논문에서는 알고리즘의 특성상 메모리 접근이 많고 반복적인 연산을 수행하는 딥러닝 어플리케이션의 병렬 처리를 위한 SIMT(Single instruction Multiple Threads)구조의 멀티 코어 프로세서와 이를 활용하여 입력 데이터의 조건에 따라 ALU 동작을 제어하여 저전력으로 동작하는 저전력 임베디드 용 프로세서 구조를 제안한다. 제안한 멀티 코어 프로세서 구조의 경우 16개의 SP(Stream Processor)로 구성되어 있고, 각 SP는 1개의 ALU(Arithmetic Logic Unit)을 탑재하고 있다. 4개의 SP를 묶어 하나의 SM(Stream Multi Processor)으로 관리되며, SM에는 각 SP들이 공유하는 레지스터 파일을 가지고 있다. 제안하는 멀티 코어 프로세서는 효율적인 딥러닝 연산을 위하여 피처맵을 추출하는 컨볼루션 레이어에서 입력 데이터가 0일 경우 ALU의 동작을 중단하여 연산을 진행하지 않음으로써 연산기의 동작횟수를 감소시켜 전력소모량 감소를 기대하였다. 또한 명령어 캐시의 구조를 변경하여 캐시 메모리 접근을 줄이며, 여러 명령어 페치의 요청을 빠르게 처리할 수 있도록 설계하였다. 이에 대한 실험으로 딥러닝 알고리즘의 하나인 CNN(Convolutional Neural Network)알고리즘을 사용하였다. CNN알고리즘의 특성상 입력 데이터의 값이 0인 경우가 많으며, 해당 경우 ALU의 동작을 차단하였다. 그 결과 제안하는 프로세서는 컨볼루션 레이어에서 41.5%의 연산 감소량을 보였으며, 프로세서의 전력소모량을 26%감소시킴으로써 성능향상을 확인하였다.

As hardware evolved, single cores began to replace multi-core. As application execution proceeds to multicore, processing is faster than single core. As a result, many researches on algorithms that were in a downturn due to problems such as computational processing have been actively studied. Especially, various studies have been conducted on deep learning algorithms, which were in a downturn due to large computational complexity. As the hardware performance increases, various deep learning algorithms are proposed. To efficiently control and commercialize them, low power consumption is an inevitable choice. Therefore, there are many studies to reduce the power consumption of the processor.
In this paper, we propose a multi-core processor based on SIMT(Single Instruction Multiple Threads) architecture for parallel processing of deep learning applications with many memory accesses and repetitive operations. And a low power embedded processor architecture. In the case of the proposed multi-core processor architecture, it consists of 16 SPs(Stream Processors), and each SP has one ALU(Arithmetic Logic Unit). It is managed by one SM(Stream Multi Processor) by grouping four SPs, and SM has a register file shared by each SP. The proposed multi-core processor was expected to reduce power consumption by reducing the number of operations of the operator by stopping the ALU operation if input data were zero at the convolution layer that extracts feature maps for efficient deep learning. In addition, we changed the structure of instruction cache to fetch instruction more quickly and designed to reduce cache memory access. We used CNN(Convolutional Neural network) algorithm which is one of the deep learning algorithms. Due to the characteristics of the CNN algorithm, the value of the input data is often zero, and in that case the operation of the ALU is blocked. As a result, the proposed processor showed a 41.5% reduction in computation at the convolution layer and the performance improvement was confirmed by reducing the power consumption of the processor by 26%.",
수문시계열 모의를 위한 딥러닝 알고리즘의 적용성 평가,2019,"In this study, the applicability of a deep-learning LSTM model, which is based on the relationship between input and output data, was tested for forecasting non-linear time series data such as river water level and discharge. To achieve the objectives, three applications was carried out: (1) forecasting of downstream water level in a natural river using only upstream water level data, (2) forecasting of tide-dominated river water level using tidal level and dam release data, (3) forecasting of monthly discharge using rainfall, temperature at the ASOS observation stations, and dam release data of the three upstream dams. The major findings are as following.
(1) As a result of forecasting the water level of the Okcheon station using the water level data of the three upstream water level stations, the forecasting capability was found that NSE values almost close to 1.0 in the case the where optimum model performance was exhibited.
(2) As a result of forecasting the water level of Jamsu Bridge, affected by sea water level, the forecast accuracy for the 1 hour lead time when an LSTM model exhibit optimum performance was found to be RMSE of 0.065 m and NSE of 0.99. However, when the lead time became longer, the forecasting accuracy error increased on average irrespective of the sequence length parameter.
(3) As a result of forecasting the monthly flow at the Han River Bridge, the case where monthly flow was included during the deep neural network learning showed better accuracy than that of the case where monthly flow was excluded. In addition, the case where only meteorological information was utilized in order to predict monthly discharge, the accuracy was shown to have been degraded due to over-fitting when the iteration number of learning increased. In particular, the forecasting model for the monthly flow of the current month (t) based on past time series(t-n ~ t) showed far superior to the model forecasting the flow of the following month (t+1).
In current hydrological forecast systems, a forecast usually carried out utilizing predictive hydrological data. However, such systems can not be trusted unless reliable parameters is not guaranteed for sufficient lead time. Therefore, if the purpose is to analyze the non-linear hydrological time series at a specific outlet that is naturally or artificially regulated, the LSTM model that remembers long-term information based on big data and reflects it on forecast after adjusting it is expected to be utilizable and applicable in various hydrological time series analysis.","#수문시계열 예측, #딥러닝, #지도학습, #LSTM 모형"
딥러닝 기반의 영상처리 기법을 활용한 실시간 객체 모니터링 연구,2019,"최근 영상처리 기술의 발달로 인해, 영상 데이터 기반의 자동 모니터링 분야에 관한 연구가 활발히 진행되고 있다. 특히, 축산업 분야 중 하나인 양돈업에서는 한 농가 가구당 약 2천 마리의 돼지를 사육하고 있어 관리인 1인당 관리 두수가 많아 세밀한 관리가 어려우며 많은 시간이 요구된다. 이러한 문제를 해결하기 위해 자동 모니터링에 관한 관심이 증가하고 있으며, 이를 위해서는 모니터링된 영상에서 가축들을 탐지하고, 개별로 분리한 후 추적을 하는 연구가 선행되어야 한다.

본 연구에서는 딥러닝 기반의 영상처리 기법을 활용하여 객체 모니터링 방법을 제안한다. 먼저, 차 영상 기법을 이용하여 카메라로부터 입력된 프레임의 움직임을 탐지한다. 움직임이 존재하지 않는 프레임을 생략한 후, 움직임이 없는 개별 돼지를 판단하여 제거함으로써 연산량을 줄인다. 실험 결과, 프레임을 55.8%의 비율만큼 생략 가능하였으며, 움직임이 탐지된 프레임 중 움직이지 않는 돼지를 제거함으로써 돼지 수 기준 37.2% 비율만큼 생략할 수 있음을 확인하였다.

두 번째로, 실시간 처리를 위해 속도 측면에서 우수한 성능을 보유한 딥러닝 기법인 YOLO(You only look once) 알고리즘을 이용하여 근접 객체를 분리하는 방법을 제안한다. 먼저, YOLO 알고리즘을 적용하여 바운딩 박스(Bounding box)의 형태로 객체와 객체의 경계선을 탐지한다. 탐지된 객체와 객체의 경계선 바운딩 박스의 정보를 이용하여 근접한 영역을 탐지함으로써 근접 영역을 분리한다. 실험 결과, 경계선 개수 기준으로 98.7%의 정확도로 근접 영역을 탐지 가능하였고, 픽셀 단위 기준으로 92.01%의 정확도로 객체를 분리할 수 있음을 확인하였다.

세 번째로, 근접 상황에서 한 객체가 다른 객체를 올라타거나 가릴 때 발생하는 겹침 상황에서 YOLO 알고리즘을 이용하여 겹침을 발생시킨 객체 분리하는 방법을 제안한다. 먼저, 겹침이 발생한 겹침 시퀀스를 10도씩 회전하여 증폭시킴으로써 획득한 6개의 시퀀스를 하나의 영상으로 합성한다. 이후, 증폭된 영상에 YOLO 알고리즘을 적용함으로써 하나의 겹침 시퀀스에 대해 6개의 바운딩 박스를 획득한다. 획득된 바운딩 박스의 가로/세로의 비율 차이를 이용하여 최적의 바운딩 박스를 선정한 후 otsu 알고리즘을 적용하여 겹침을 발생시킨 돼지를 분리한다. 실험 결과 픽셀 단위 기준으로 83.33%의 정확도로 객체를 탐지할 수 있음을 확인하였다.

마지막으로 이기종 디바이스 환경에서 태스크 병렬 스케줄링 기법을 이용하여 수행 시간을 단축함으로써 실시간 처리 방법을 제안한다. 실험 결과, 순차 처리 수행 시간은 평균 84.42msec의 처리 속도를 나타내었으며, 태스크 병렬 스케줄링 기법을 적용할 경우 46.28msec의 처리 속도로 성능이 향상 가능함을 확인하였다.","#딥러닝, #객체 모니터링"
컨볼루셔널 뉴럴 네트웍 기반 딥러닝 기법을 활용한 팀구성 문제에 관한 연구,2019,"본 연구는 한 프로젝트의 구성원의 능력 척도에 따라 구성원의 배치를 결정하는 방법론에 대해 다루는 연구다. 개개인의 역량을 나태나는 데이터 셋을 이용하여, 각 구성원의 능력에 따른 역할 군을 배치하는 머신러닝을 구현한다. 기초적인 모델을 구성한 뒤 Hyper-Parameter를 조절함으로써, 머신러닝의 정확도를 높이며. 또한 역할 군의 개수에 따라 달라지는 머신러닝 Parameter의 정확도를 파악하고, 더 알맞은 Hyper-Parameter 와 머신러닝 구조를 파악하여 이와 비슷한 배치 문제에 대한 새로운 방법론을 제시한다. 본 연구에서 이용될 데이터는 18-19 시즌을 임하는 16000여명의 축구선수의 데이터 셋이다. 이 데이터는 국제축구연맹(FIFA) 과 라이센스 계약한 EA-Sport에서 평가한 지표이며 각 선수들마다 약 43개의 성분을 갖는 데이터 셋이다. 이러한 데이터 셋을 결과 값 Label 의 종류를 17개로 하는 자세한 정보로 담는 데이터 셋 과 정보를 더 간략하게 표현하기 위한 결과 값 Label 의 종류를 4개로 하는 데이터 셋으로 나눈다. 본 연구에서 적용시킬 머신러닝 기법은 컨볼루셔널 뉴럴 네트워크 기법이며, 이는 True/False와 같은 이진 변수의 결과 값을 갖는 머신러닝이 아닌, 다양한 결과값의 종류를 가지는 머신러닝에서 주로 쓰이는 기법이다. 이 기법을 통해 각 데이터 셋이 가진 Label 종류의 차이로 인한 머신러닝 학습 결과의 변화율을 확인하여, 상황에 따른 데이터 가공에 대한 새로운 방법론을 제시한다.

This study deals with the methodology for determining the placement of
members according to their ability scales in a project. Using three data sets
that pass through each individual''s capabilities, Machine Learning is
implemented to deploy a group of roles according to each member''s abilities.
After configuring the basic model, adjust the Hyper-Parameter to increase
machine learning accuracy. It also identifies the accuracy of machine
learning parameters that depend on the number of role groups, identifies
more appropriate Hyper-Parameter and Machine Learning structures, and
presents new methodologies for similar deployment problems. The data to be
used in this study are three of the 16,000 footballers for the 18-19 season.
This data was evaluated by EA-Sport, a licensed EA-Sport with FIFA, and
is a set of data with about 43 components for each competitor. These data
sets are divided into 17 resulting value labels, 17 of which the detailed
information is contained, and 4 of which are the resulting value labels to
represent the information more briefly. By comparing the performance of
machine learning according to the number of resulting Label, a consideration
is also given to which number of labs is better in the case of the
experiment.","#딥러닝, #팀구성"
딥러닝을 이용한 드론 영상 의미론적 분할 : 불법 건물 모니터링을 중심으로,2019,"최근 개발제한구역에 대한 규제가 완화되고 신도시 개발에 대한 기대감이 상승하면서 불법 건축물 적발 건수가 지속해서 증가하고 있다. 기존에는 각 지방자치단체에서 불법 건축물 모니터링을 포함한 도시 관리 업무를 수행할 때 현장 답사, 유인항공기 영상 촬영 및 판독 등과 같은 방법을 이용하였다. 그러나 한정된 인원으로 광범위한 영역을 관리하기에는 여러 가지 한계가 있어 불법 건축물 모니터링 수행에 많은 어려움이 있다. 이러한 어려움을 극복하기 위하여 각 지방자치단체는 새로운 사진측량 플랫폼으로 주목받고 있는 드론을 도입하고 있다. 드론을 이용하면 유인항공기에 비해 작은 영역을 저비용, 고해상도로 촬영할 수 있기 때문이다. 따라서 불법 건축물 모니터링 뿐만 아니라 여러 가지 도시 관리 업무에 드론을 도입하려는 시도가 이루어지고 있다. 드론을 이용한 사진측량은 유인항공기에 비해 여러 가지 장점이 있지만, 영상으로부터 불법 건축물을 찾는 것은 여전히 담당자의 육안에 의존하고 있어 많은 시간과 비용이 발생하고 있다. 드론을 이용한 불법 건축물 모니터링을 더욱 효율적으로 수행하기 위해서는 드론 영상으로부터 불법으로 의심되는 건물을 자동으로 탐지하는 방법을 연구할 필요가 있다.
본 연구는 드론 영상에서 불법으로 의심되는 건물, 즉 드론 영상에는 존재하지만 기 구축된 GIS 데이터베이스에는 없는 건물을 자동으로 탐지하는 방법을 제안하고 이를 검증하는 데 그 목적이 있다. 구체적으로는 영상을 픽셀 단위로 분류하는 딥러닝 기반 의미론적 분할(Semantic Segmentation)을 통해 드론 영상으로부터 건물 지도를 만들고, 기 구축된 GIS 데이터베이스의 건물 지도를 차분하여 미등록 건물을 추출한다. 위와 같이 처리한 드론 정사집성영상을 딥러닝 모델에 입력하여 건물 지도를 자동으로 생성한 후 이를 기 구축된 GIS 데이터베이스상의 건물 지도와 비교하여 미등록 건물을 추출하였다. 미등록 건물은 픽셀 기반 혹은 객체 기반 방법을 통해 추출하였다.
본 연구에서 제시한 방법을 통해 대규모 항공사진 데이터셋에 대해 수작업으로 라벨링 작업을 수행하지 않고도 최대 86%의 정확도를 발휘하는 딥러닝 모델을 구축할 수 있었다. 드론 영상으로부터 자동으로 미등록 건물을 탐지할 수 있었다. 또한 본 연구에서 제시된 방법은 불법 건축물 모니터링 뿐만 아니라 불법 용도/형질변경, GIS 데이터베이스 갱신 등에 활용할 수 있을 것으로 기대된다.

Recently, the number of illegal buildings in green belt areas are increasing due to deregulation of the green belt laws and expectations toward new city development. Local governments in Korea have traditionally conducted illegal building monitoring through on-site inspection or interpretation of airborne aerial images. However, local governments are trying to exploit drones because it is difficult to monitor a wide area with a limited number of monitoring officers. Drone is a new and emerging platform in terms of photogrammetry and remote sensing field because it is possible to survey small areas with higher image resolution and lower cost compared to manned aircraft. Although drone has a lot of advantages, it is still costly and time-consuming to find illegal buildings from drone images since the interpretation of drone images still relies on manual efforts. Therefore, developing an automatic system for detecting buildings which are suspected to be illegal is an important research topic.
This research mainly focuses on developing and evaluating a method for detecting buildings which are not registered on an existing GIS database. Specifically, we train a deep learning model to semantically segment a given drone image into a building map using national geospatial data and compare the new building map generated by the deep learning model with the existing GIS database to extract unregistered buildings. In order to extract unregistered building accurately, it is important to train a deep learning model to segment drone images accurately, and it is also essential to perform image registration between the drone images and the existing GIS database. Hence, this research includes experiments that compare deep learning models with various configuration of training datasets and performing aerial triangulation with consideration of image registration.
Through the experiment, we could train deep learning model to perform up to 86% of accuracy without any manual effort of annotation large-scale aerial image dataset. We could detect unregistered buildings from drone images automatically using the proposed method. We also expect that our method can be used not only for monitoring illegal buildings but also monitoring illegal land use change or update of GIS databases.",
EHR 데이터의 패턴 정보를 활용한 딥러닝 기반 만성 신질환 위험도 예측 연구,2019,"2013년도 질병관리본부의 국민건강통계에 따르면 30세 이상의 성인 중 3.9%가 만성 신질환(chronic kidney disease)을 가지고 있으며, 65세 이상에서는 16.5%로 유병률이 매우 높은 질환이다. 특히 발병 과정에서 신부전증으로 인해 여러 가지 합병증들이 유발되는데, 해당 질병들이 악화되면서 많은 환자들을 사망에 이르게 만든다. 그럼에도 불구하고 초기 증상이 뚜렷하지 않아 환자가 신장 이상을 느끼고 병원에 내원하는 경우는 드문 실정이다. 이러한 만성 신질환을 조기에 예측하고자 전자의무기록(electronic health record, EHR)을 이용한 연구들이 선행되고 있다.
최근 딥러닝의 기술이 급속하게 발전하면서 의료 분야에서도 활발한 연구가 진행되고 있으며 기존의 전통적인 기계학습(Machine Learning)보다 좋은 성능을 보이고 있다. 또한, 딥러닝 분야에서 다양한 모델 구조 실험들이 이루어지고 있으며 구조에 따라 성능이 달라지는 연구 사례들이 있었다. 그러나 의료분야에서 다양한 딥러닝 모델 구조를 실험하고 만성 신질환 예측을 위한 연구 사례는 비교적 적었다.
이에 본 논문에서는 이에이치알(EHR) 데이터 중 진단과 처방 정보를 활용한 만성 신질환 위험도를 예측하였으며 여러 가지 구조의 딥러닝 모델에 따른 성능을 비교 평가하였다. 학습된 데이터의 가중치를 추출하여 만성 신질환 예측에 높은 수치를 가진 시점들의 정보들을 확인하여 정성적인 평가를 하였다.
실험 결과 국민건강보험공단 표본연구 DB에 대하여 정확도(accuracy) 81.09%, 에이유알오씨(The Area under the Receiver Operating Characteristics Curve, AUROC) 87.75%, 에이유피알씨(The Area under the Precision-Recall Curve, AUPRC) 52.72%, 웨이티드 에프원 스코어(Weighted F1-score) 83.03%를 나타냈고, 아주대학교병원 데이터베이스에 대해서 정확도 82.07%, 에이유알오씨 88.24%, 에이유피알씨 63.61%, 웨이티드 에프원 스코어 82.93%를 나타냈다. 이에 기반하여 본 연구에서 제안된 모델이 만성 신질환의 조기 발견과 지연 및 유병률을 감소시키는 데 효과적으로 기여하리라 기대한다.","#전자의무기록, #순환 신경망, #합성곱 신경망, #임베딩 기법, #어텐션 메커니즘"
딥러닝 기법을 이용한 자기소개서 성향 분석,2019,"4차 산업혁명의 등장으로 기존 서비스에 인공지능을 접목하는 시도가 늘어나고 있으며 최근에는 성향 분석 시스템을 이용한 개인화, 추천 등의 서비스가 상용화 되었다. 한편 국내 채용분야에서는 블라인드 채용의 확대로 인해, 많은 기업들과 공공기관들이 스펙을 보지 않고 자기소개서의 내용을 기반으로 구직자를 뽑는 비율이 높아지고 있으며 이를 A.I에 접목하는 시도도 늘어나고 있다.

다만 채용과정에 A.I를 사용하는 범위가 자기소개서가 아닌 구직자의 이력서 검토를 최소화하는 것과 온라인 영상 및 목소리 분석 등 기계가 면접을 대신 봐주는 A.I 면접관에게 특화 되어 있다. 이러한 원인은 기존의 성향 분석 연구 및 시스템들이 소셜 미디어나 커뮤니티 등에 쓴 내용을 기반으로 학습이 되어있기 때문이다.

글을 쓰던 순간의 경험 및 감정이 내재되어있는 소셜 미디어 데이터를 학습한 시스템은 자기소개서같이 감정을 억제하고 쓰는 정제된 내용에 대한 성향 분석이 제대로 이루어지지 않을 수 있다. 또한 구인자는 자기소개서를 읽을 때 가까운 지인이나 유사한 직장 동료를 떠올리게 된다. 즉, 자기소개서의 단어나 문장을 볼 때, 과거의 경험을 기반으로 무의식 중에 지원자를 분류하고, 평가하게 된다. 이는 자기소개서의 단어와 문장들을 분석하여 사람의 성향을 파악하고 분류하는 것의 가능성을 보여준다.

이에 본 논문에서는 자기소개서에서 구직 활동을 위해, 자신의 성향을 글로 표현한다는 것을 전제로 성향 별 단어를 찾고, 이를 분석하는 것을 핵심으로 다룬다. 이를 위해, 대기업이나 공공기업에서 제공하는 공개된 합격 자기소개서를 활용하여 성향 별 단어 역빈도(TF-IPF) 공식으로 만든 성향 별 말뭉치(Personality Corpus)와 자기소개서를 완벽하게 분석 하기 위한 형태소 분석 및 개체명 추출에 대한 방법 그리고 텐서플로우 (Tensorflow)로 생성된 딥러닝(Deep Learning) 회귀 모델 기반의 자기소개서별 적절한 성향을 분류하는 것을 연구한다.

With the advent of the 4th Industrial Revolution, more attempts have been made to integrate artificial intelligence into existing services. Recently, services such as personalization and recommendation using personality analysis system have been commercialized. On the other hand, in the domestic recruitment field, due to the expansion of the ""based on the contents of self-introduction letters"", many companies and public institutions are increasingly selecting job seekers based on the contents of their self-introduction letters without looking at specifications.

The scope of using AI in the recent recruitment process is focused on minimizing the time to review the resume without analyzing the self-introduction letters. Others are specialized in AI interviews, where video and voice analysis machines progress interviews instead of the interviewers. This is because the existing personality analysis research and systems are learning based on the contents written in social media or community.

The system that learned the social media data which has the experience and feelings at the moment of writing can not properly analyze the inclination toward refined contents which people write like self-introduction letter with suppressed emotions. Also, the recruiter recalls a close relative or a similar co-worker when he reads their self-introduction letters. In other words, when you look at the words and sentences of self-introduction letters, you sort and evaluate the applicants unconsciously based on past experience. This shows the possibility of analyzing the words and sentences of self-introduction and identifying and classifying human personalities.

Therefore, in this paper, it is presupposed that I express my own tendency in self introduction letters for job search activity. For this purpose, we focus on how to search for a word and analyze the word. For this purpose, self-introduction letters provided by large companies or public companies are utilized. Using these documents, we study how to classify Personality Corpus, TF-IPF formula, morphological analysis and Named Entity Recognition, and appropriate propensity for self-introduction letters based on Tensorflow-based Deep Learning Regression model.",
딥러닝 기반의 음성신호를 이용한 감정인식,2019,"음성 신호를 통해 화자의 감정 상태를 분류하는 음성 감정 인식은 인간과 컴퓨터의 상호 작용 (Human-machine interaction, HMI)을 더욱 자연스럽고 사실적으로 만드는 기술이다. 음성 신호 감정 인식 시스템에서 가장 중요한 쟁점은 각각의 감정을 효율적으로 분류할 수 있는 적절한 음성 신호 특징들을 추출하는 것이다. 본 논문 또한, 문제 영역에 초점을 맞추어 감정 상태의 분류 성능을 높이는 데에 연구 목적을 두고 있다. feature 추출에 앞서 불필요한 비 음성 구간을 제거하고 분석의 유의미한 음성 구간만을 다루기 위해 IAV 임계치를 사용한 음성 구간 추출 전처리 과정을 진행한다. 본 논문에서 제안한 feature set은 13차원 mfcc, 기본 주파수 F0, spectral centroid, spectral bandwidth, spectral contrast, spectral flatness, spectral rolloff, chroma로 구성된 32차 특징벡터이다. 추출된 특징벡터들은 순차적 정보를 해석하는데 용이한 분류 모델인 Recurrent Neural Network(RNN)을 기반으로 하는 Connectionist Temporal Classification(CTC) 접근법과의 병렬 사용으로 기존의 방법보다 정확도가 약 7~10%의 향상된 성능을 보인다.

주요어: 딥러닝, 음성신호처리, 감정인식, 신호처리

Speech emotion recognition, which aims to classify speaker’s emotional states through speech signals, is one of the essential tasks for making Human-machine interaction (HMI) more natural and realistic. The significance
of various classification models has been presented along with some recent research works review. RNNs provide an attractive framework for propagating information over a sequence using a continuous valued hidden layer representation. This paper provides the method using effective speech signal features set based on recurrent neural network (RNN) model using CTC loss function. This paper provides effective feature combination that represents speech emotion so that achieve satisfactory performance. In this paper, we
focus on parallel use of effective feature set with RNN with the Connectionist Temporal Classification (CTC) approach which is variable for the sequential signal architecture for speech emotion signal.

keyword: deep learning, speech signal processing, emotion recognition, signal processing, CTC, RNN","#딥러닝, #음성신호처리, #감정인식, #신호처리"
딥러닝을 이용한 이미지 캡션 및 스크립트 기반 영상 콘텐츠 추천 시스템,2019,"본 논문은 영상의 정보를 딥러닝을 이용하여 수집하고, 사용자가 원하는 영상을 추천해주는 시스템을 제안한다.
본 연구에서 제안하는 구조는 크게 데이터 전처리 단계와 유사 영상 추천 단계로 구성되며, 세부적으로 영상 경계 검출, 이미지 캡션, 얼굴 인식, 단어 임베딩을 설계하였다. 사용자가 원하는 영상을 검색하기 위해 최소 영상의 단위를 shot으로 정의하여 스토리 영상의 분석과 검색을 효과적으로 수행하도록 하였다. 각 영상에서 포함하고 있는 인물, 배경, 행위 등과 같은 정보들은 얼굴 인식과 이미지 캡션을 통해 데이터를 추출하였다. 또한 추가적으로 시놉시스 데이터를 활용하여 시각적인 영상 정보를 데이터화하였다.
본 연구에서는 영상의 경계를 검출하여 shot으로 분류하였으며, 얼굴 인식은 97%의 검출율과 언어 평가 모델을 이용하여 기존 모델보다 최대 5% 향상되는 이미지 캡션 결과를 보였다. 또한, 사용자가 입력하는 문장으로 추천받은 이미지에 대하여 정성적 평가를 진행한 결과의 평가를 얻었다. 추후 시대적 배경에 따른 객체 및 배경과 동작에 관한 캡션에 대한 정의와 Content-based로 영상을 추가로 추천한다면 더 나은 추천시스템이 될 수 있을 것으로 예상한다.","#딥러닝, #추천 시스템, #얼굴 인식, #이미지 캡션, #단어 임베딩"
사물 인식을 위한 효율적인 딥러닝 플랫폼,2019,"최근 센서 기반 사물인식 기술을 대체하기 위한 방안으로 컴퓨터 비전을 이용한 사물인식 기술이 각광받고 있다. 센서 기반 사물인식 기술은 고가의 센서가 요구되기 때문에 기술 상용화가 어렵다는 문제가 있었다. 반면 컴퓨터 비전을 이용한 사물인식 기술은 센서를 저렴한 카메라로 대체할 수 있기 때문에 CNN의 발전으로 실시간 사물인식이 가능해진 이후 IoT, 자율주행차 등 타 분야에 적극적으로 도입되고 있다.
하지만 사물 인식 모델을 선택하고 학습시키기 위해서는 딥러닝에 대한 전문지식을 필요로 하기 때문에 비전문가는 모델을 사용하기 어렵다. 따라서 본 논문에서는 사용자가 원하는 조건의 딥러닝 기반 사물인식 모델 및 하이퍼 파라미터를 통계에 기반하여 자동으로 선정할 수 있는 플랫폼을 제안한다. 본 논문은 딥러닝 기반 사물인식 모델들의 구조를 분석하고, 모델들에 대한 실험을 통해 통계에 기반한 사물인식 모델 선정이 필요한 이유를 보인다. 그리고 모델 선정 플랫폼의 구조를 설계한다.

Recently, object detection technology using computer vision has attracted attention as a method to replace sensor based object detection technology. Sensor-based object detection technology has a problem that it is difficult to commercialize the technology because an expensive sensor is required. On the other hand, since object detection technology using computer vision can replace sensors with inexpensive cameras, real-time object detection becomes possible with the development of CNN, and then it is actively introduced into other fields such as IoT and autonomous vehicles.
However, it is difficult for non-experts to use the model because it requires expert knowledge on deep learning to select and learn the object detection model. Therefore, in this paper, we propose a platform that can automatically select the deep learning based object detection model and hyperparameter based on the statistics. In this paper, we analyze the structure of deep-learning-based object detection models and show why we need to select object detection models based on statistics through experiments on models. And we show the result of designing the platform structure.",
딥러닝 기반 도로주행 상황 인지를 위한 영상 데이터 전처리 방법,2019,"본 논문은 딥러닝 기반 도로주행 상황 인지를 위한 영상 데이터의 전처리 방법을 제안한다. 어떠한 전처리도 없이 2차원 평면상에 객체의 위치만을 표시하여 도로주행 상황 인지를 수행하는 경우의 문제점은 다음과 같다.

첫째, 2차원으로 표현되는 이미지 특성상 거리를 반영하지 못한다. 이로 인해 실제로는 현재 도로주행 상황에 영향을 미치지 않기 때문에 고려하지 않아도 되는 멀리 있는 객체까지도 도로주행 상황 인지에 사용되는데, 이러한 객체들은 노이즈로 작용할 가능성이 높다.

둘째, 카메라의 장착 위치, 카메라 스펙, 도로의 모양에 따라 도로주행 영상 마다 객체의 위치가 불규칙하게 나타난다. 이로 인해 학습 데이터에서 학습한 객체의 위치를 토대로 도로주행 상황 인지를 수행할 경우, 상황적 의미가 다름에도 단순히 객체의 위치가 비슷하기 때문에 잘못된 예측 결과를 내놓을 가능성이 높다.

이에 본 논문에서는 도로주행 영상 내에서 차선을 검출하고, 이를 기준점으로 주행 상황에 영향을 미칠 가능성이 높은 객체들을 검출한 후, 나머지 객체들을 도로주행 상황 인지에서 제외한다. 또한, 이러한 기준점을 토대로 도로주행 영상마다 불규칙하게 나타나는 객체의 위치를 일정하게 표현하기 위한 정규화 방법으로써 Bird‘s Eye View로의 변환 방법을 제안한다. 결과적으로, 본 논문에서 제안한 방법으로 도로주행 상황 인지 실험을 수행한 결과 97.66%의 정확도를 나타내었다.

In this paper, we propose a method of preprocessing of image data for road driving situation recognition based on deep learning. The following is a problem when road driving situation recognition is performed in the case where only the position of the object is displayed on the two-dimensional plane without any preprocessing.

First, it does not reflect the distances due to the image characteristics expressed in two dimensions. As a result, even objects that are far away, which do not affect the present driving situation, are used for road driving situation recognition. These objects are likely to act as noise.

Second, the position of the object is irregularly displayed on each road driving image depending on the mounting position of the camera, the camera specification, and the shape of the road.

In this paper, a road lane is detected as a reference point in a road driving image, and the objects that are likely to affect the driving situation are detected depending on a reference point, and then the remaining objects are excluded from the road driving situation recognition. In addition, we propose a method of mapping to Bird''s Eye View as a normalization method to uniformly express the positions of objects irregularly appearing on each road driving image based on these reference points. As a result, the accuracy of 97.66% was obtained as a result of the experiment on the driving situation recognition by the proposed method.","#딥러닝, #도로주행, #상황 인지, #객체 검출, #정규화, #Bird''s Eye View"
딥러닝을 이용한 스마트 교육시설 공사비 분석 및 예측,2019,"본 연구는 스마트 교육시설 실적자료를 이용하여 기획·설계단계에서 정확한 공사비를 예측하고, 효율적인 의사결정을 지원하는 것이 목적이다. 예측된 공사비의 오차가 높을수록 의사결정자는 위험 부담을 가지고 합리적인 결정은 어려워진다. 프로젝트의 초기단계에서 정확한 공사비를 예측할 수 있다면, 의사결정 기간을 확대하고 합리적인 결정을 지원할 수가 있다. 기획·설계단계에서는 실시 설계가 진행되기 전으로 선택 가능한 변수는 제한적이다. 그리고 스마트 교육시설은 사례가 적은 프로젝트로 실적 자료도 한정적이다. 본 연구는 한정적인 실적 자료로도 기획·설계단계에서 공사비 예측을 정확하게 할 수 있도록 인공지능 모델을 이용하였다. 다중회귀분석(Multiple Regulation Analysis), 인공신경망(Artificial Neural Network)과 딥러닝(Deep Learning)에 관한 이론적 고찰을 수행하였고, 선행연구에서 인공신경망이 주로 이용되어온 것을 조사하였다. 하지만 인공신경망은 잦은 Overfitting문제가 발생하여 실제 데이터에 사용하는 것은 실용적인 문제가 있다. 본 연구는 더 정확하고 정밀한 예측을 위해 개선된 모델인 DNN(Deep Neural Network)와 DBN (Deep Belief Networks)이 효과적일 것으로 추측하였다. 공사비 예측을 위해 다중회귀분석, 인공신경망과 딥러닝(DNN, DBN) 모델을 구축하였고, RMSE를 계산하여 오차 및 정밀도를 비교하였다. 본 연구는 구축된 모델의 비교를 통해 기획·설계단계에서 실용적으로 사용가능한 공사비 예측 모델을 제안하고자 하였다.
본 연구의 성과는 다음과 같다.
(1) 스마트 교육시설물 및 공사비 예측 방법에 대한 이론적 고찰을 조사하고 이에 대한 국내·외 연구동향을 알아보았다. 기존 공사비 예측 연구에서 주로 이용된 연구 방법에서 문제점을 알아보았고 연구 결과를 바탕으로 좀 더 정확한 공사비 예측 방법(Deep Learning)을 제안하고자 하였다.
(2) S 교육청에서 2015년부터 신설한 스마트 교육시설물 중·고등학교 18개(중학교 10개, 고등학교 8개)를 연구대상으로 분석하였고, 선행연구들을 통하여 코스트 모델링에 필요한 변수를 도출하였다.
(3) 본 연구는 다중회귀분석, 인공신경망, 딥러닝(DNN, DBN) 모델을 구축하였고 평가데이터를 이용한 예측으로 각 모델을 비교하였다. 구축된 모델 중 DBN모델이 가장 낮은 오차를 보이고 공사비 예측에 효율적일 것으로 판단하였다.

The purpose of this study is to predict more accurate construction costs and to support efficient decision making in the planning and design stages of smart education facilities. The higher the error in the predicted cost, the more risk a project manager takes. If the manager can predict a more accurate construction cost in the early stages of a project, he/she can secure a decision period and support a more rational decision. During the planning and design stages, there is a limited amount of variables that can be selected for the estimating model. Moreover, since the number of completed smart schools is limited, there is little data. In this study, various artificial intelligence models were used to accurately predict the construction cost in the planning and design phase with limited variables and lack of performance data. A theoretical study on multiple regulation analysis, artificial neural network and deep learning was carried out. As the artificial neural network has frequent problems of overfitting, it is found that there is a problem in practical application. In order to overcome the problem, this study suggests that the improved models of Deep Neural Network and Deep Belief Network are more effective in making accurate predictions. Deep Neural Network (DNN) and Deep Belief Network (DBN) models were constructed for the prediction of construction cost. Average Error Rate and Root Mean Square Error (RMSE) were calculated to compare the error and accuracy of those models. This study proposes a cost prediction model that can be used practically in the planning and design stages.
The results of this study are as follows.
(1) Theoretical considerations on smart education facilities and cost estimating methods were investigated and the trends of domestic and foreign researches were examined. In this study, we propose a more accurate forecasting method (Deep Learning) based on the results of the study.
(2) This study analyzed 18 smart schools (10 middle schools, 8 high schools) among the smart education facilities that were newly established by the S Office of Education in 2015, and the necessary parameters for cost modeling were derived from previous studies.
(3) This study constructed multiple regression analysis, artificial neural network, and deep learning (DNN, DBN) models. The DBN model shows the lowest error in the constructed models and it is considered to be effective in predicting construction cost.",
유사도 기반 이미지 분석을 위한 딥러닝 성능 개선에 관한 연구,2019,"최근 인공지능 연구가 정부, 기업, 문화, 교육 등 사회 전반 에서 활발히 진행됨에 따라 정부와 많은 기업에서 빅데이타를 이용한 인공지능 이미지 인식 및 영상 인식 등을 이용한 다양한 형태의 기술과 서비스들을 제공 하고 있다. 그중 인공지능을 활용한 다양한 기술들이 등장하고 있고, 이러한 기술들은 더욱 발전된 서비스를 제공하고 있다. 인공지능을 활용한 모든 기술들은 높은 정확도와 신뢰도를 요구하고, 이에 따라 신속하고 정확성을 높이기 위한 많은 연구가 개발되고 있다.
그러나 기존의 이미지 관련 딥러닝 연구 방법들은 특징 확인 및 조합 기반의 알고리즘을 통해 수행되었으나, 정확도와 신뢰도의 한계가 있었다. 이 방법들은 배경 제거 및 영상이미지를 평면화 시키는 과정에서 공간 정보의 손실로 인해 인공 신경망이 특징을 추출 하고 학습함에 있어 비효율 적이고 정확도와 신뢰도를 높이는데 한계가 있다.
본 연구에서는 최근에 많이 활용되고 있는 신경망 모델 기반의 딥 러닝 아키텍처를 개선하여 학습의 효율성과 정확도를 향상시킴으로써 영상 이미지 특징 추출 및 학습을 개선할 수 있는 방법을 연구하고 실험결과를 제시하였다.
본 연구에서 적용한 딥 러닝 알고리즘은 최근 성능과 정확도에서 가장 뛰어난 DenseNet 신경망을 기반으로 하여 이의 구조를 학습 성능의 향상에 초점을 두고 개선하였다. 실험 결과, 데이터를 학습시키는 속도와 정확도 모두 기존 DenseNet 아키텍처 보다 향상 되었으며, 이는 같은 시간 내에 기존의 방식보다 더 많은 영상이미지를 진단할 수 있음을 의미한다.
클라우드 기반의 자원통합 및 가상화 인프라 비즈니스로의 전환이 많이 요구되고 능동적 소프트웨어 기반과 하드웨어 기반의 융합이 절실히 필요한 시점에 있다. 장비 및 소프트웨어 결합을 통해 서비스 모델을 발굴 하고 모바일 보급률이 전 국민의 90%이상임을 감안 할 때 활용 할 수 있는 소프트웨어와 하드웨어 융합사업의 추진이 한계에 도달한 ICT 비즈니스 시장에 새로운 패러다임으로 자리매김 할 수 있을 것으로 보여 진다.
본 연구가 유사도 이미지 영상 영역에서 공통으로 사용할 수 있는 이미지 분석 알고리즘을 이용하여 성능개선의 목적을 달성하고 실용적 수익기반을 창출 할 수 있는 연구로써 활용되길 희망하며 본 연구를 추진한다.

Recently, since artificial intelligence research has been actively carried out in society at large such has government, corporation, culture, education and the like, government and many companies have been providing various types of technologies and services using artificial intelligence image recognition and video recognition, performed by using big data.
Among them, various technologies utilizing artificial intelligence are emerging and these technologies provide more advanced services. All technologies utilizing artificial intelligence require high accuracy and reliability, and accordingly, many researches have been developed to improve accuracy and speed. Existing image-related deep learning research methods have been performed through feature confirmation and combination-based algorithms, however, there are limitations in accuracy and reliability.
These methods are ineffective when artificial neural networks are extracting and learning features due to loss of spatial information in the process of background elimination and flattening video images, and have a limit to increase accuracy and reliability.
In this study, methods to improve extraction of video image features and learning the same are researched and experimental results are proposed by improving a deep learning architecture based on a neural network model, which is widely used recently, to promote the efficiency and accuracy of learning.
The deep learning algorithm applied in this study is based on DenseNet neural network, which is recently the best in performance and accuracy, and its structure is improved with the focus on improvement of learning performance. Both the speed and accuracy of learning result data of experiment are improved over the existing DenseNet architecture, which means that more video images can be diagnosed within the same given time than existing methods.
Now, the transition into cloud-based resource integration and virtual infrastructure business is highly demanding and the combination of active software base and a hardware base is urgently needed. By discovering service models through a combination of equipment and software and considering that mobile supply rate is more than 90% of the whole nation, it is expected to hold the prominent position as a new paradigm in the ICT business market, in which the promotion of utilizable fusion business is reached the limit.
This study proceeds with hope that it can be utilized for achieving the purpose of performance improvement and enabling to create a practical earnings foundation by using a similarity-based image analysis algorithm that can be commonly used in the similarity image video area.",
딥러닝 기반 비디오 부호화 영상의 품질 개선을 위한 후처리 기술 연구,2019,"In this paper, we proposed the best method to consider when improving the quality of video with HEVC compression technology through deep learning. In particular, we proposed five methods that can be considered when restoring each video frame as a still image. 3) use the validation set that takes into account the actual distribution (MS coco dataset rather than DIV2K data); 4) use the QP of the HEVC (ie, resNet, DenseNet); 5) validation set configuration to satisfy the actual data distribution, and 5) removal of the activation function at the last layer. Considering these five methods, the latest performance was achieved in the Y, U, and V channels for the HEVC common condition test set.
The proposed method is not a method to view and restore the whole video but a method of restoring one frame for each frame of video. Since the neighboring frames are not considered, each of the frames seems to be restored well. However, if the video is restored after the restoration of the moving image, a soft image is output due to a slight difference between neighboring frames. In order to restore the video, it is necessary to use the time axis information of the video to smoothly lead the neighboring images.
The proposed method restores the deep learning model by applying y learning to each of y, u, and v without considering the relationship between y, u, and v. However, if y, u, and v are separately restored in this way, efficiency is not good because three operations are required. It is also clear that the relationship between y, u, and v can be a hint for restoring images with degradation through hevc. Therefore, in future research, even if the sizes of y, u, and v images are different, research that can be used as model input at the same time is needed.
Deep learning techniques to remove compression degradation such as jpeg and hevc, super resolution, and deepening learning related to dinoization are all learning to the specified deterioration. qp22, qp27, qp32, qp37, or scale factor 2, 4, 8 of hevc. This way, learning is done only according to the pre-specified quality. However, actual images can not predict how much damage will be received and how. A study of the deep-run model that can be used for any degradation, not just the specified degradation, is needed.
Deep learning If enough research is done on this, hevc technology will be removed. However, I think that this study will contribute much to video coding with Hevc technology.","#딥러닝, #영상 복원"
딥러닝을 이용한 이미지 인식 엔지니어링 도면의 객체 인식 방안,2019,"공정 플랜트 산업에서 지능형 엔지니어링 도면은 다양한 목적으로 폭넓게 사용되고 있다. 그러나 아직 플랜트 설계, 조달, 시공 회사와 플랜트 운영 및 관리 회사에서는 많은 양의 엔지니어링이 도면을 이미지 형식으로 보관하고 있다. 현재는 수작업을 통해 이미지 형식 엔지니어링 도면을 지능형 엔지니어링 도면으로 변환하고 있으며 이 과정에서 많은 시간과 비용이 소모되고 있다. 따라서 이 문제를 해결하기 위하여 자동으로 이미지 형식 엔지니어링 도면을 지능형 엔지니어링 도면으로 변환하는 기술이 필요하다. 이 연구에서는 딥러닝을 이용하여 엔지니어링 도면 중 하나인 P&ID(piping and instruments diagram)를 인식하는 방안에 대해 논의한다.

Use of intelligent engineering drawings becomes popular for various purposes in the process plant industry. However, many engineering drawings in image format exist inside of engineering procurement, and construction companies as well as operation and maintenance companies. Currently, image format engineering drawings are manually converted into intelligent ones, which spends lots of time and money. Therefore, it is important to develop a technique to convert image format engineering drawings into intelligent ones. In this research, we discuss the result of the development of techniques for recognition of piping and instruments diagram(P&ID), one of the important engineering drawings, using deep learning.","#딥러닝, #도면인식, #P&, #ID"
주목 기반 딥러닝을 활용한 압축 열화 제거 기술,2019,"Compression artifacts reduction is that removes the deterioration of images damaged by image compression and makes them close to the original. Researches that utilize deep learning in areas where compression artifacts reduction are very active. In particular, research on the CNN(Convolution Neural Network)-based method using L2-loss and GAN(Generative Adversarial Network) has been successful.
CNN-based compression artifacts reduction using L2-loss has a very high quality in comparison to the existing technology, but it is difficult to revive patterns and textures that have been damaged by compression. GAN-based decompression techniques emerged as a way to solve this. This technology can express patterns or textures that do not exist in compressed images using GAN''s characteristics. However, unnecessary noise is also generated, degrading the quality of images.
The main idea of this paper is that utilizes only the advantages of both technologies using a attention-based method. Through deep learning-based technology, areas where patterns or textures are likely to exist are extracted from images and uses these areas to combine CNN and GAN-based results for final results. Through this process, images are acquired that have patterns and textures of the necessary parts without noise.","#압축열화제거, #딥러닝, #주목기반"
동적거동을 이용한 딥러닝 기반 교량의 손상추정기법 개발,2019,"국가교통망에 근간을 이루는 교량의 급격한 노후화가 진행됨에 따라 효과적인 유지관리 시스템에 대한 관심이 증대되고 있으며, 교량 유지관리기법의 연구와 발전이 거듭 진행되고 있다. 하지만 현재 교량의 유지관리기법에는 상시적이며, 정밀한 상태평가가 미흡한 것으로 판단된다. 이러한 이유로 본 연구에서는 교량에서 상시적으로 발생하는 동적거동을 이용하고 딥러닝 알고리즘을 적용시켜 정밀한 교량의 손상추정위치기법 개발을 목적으로 하였다.
본 연구의 대상교량은 대한민국의 고속국도, 일반국도에 가장 많이 분포되어 있는 라멘교를 대상교량으로 하였다. 하지만 실제교량에 손상을 가하여 데이터를 획득하는 것은 많은 제약이 따르므로 시뮬레이션을 통해 교량의 동적거동을 획득하는 방법을 이용하였다. 시뮬레이션은 실제교량에서 발생하는 차량의 속도, 하중, 차로 상 횡위치와 2대의 차량 중 각 차량이 교량에 진입하는 시간을 고려하는 등 실제의 교통하중을 모사하여 수행하였다. 총 32,800회의 시뮬레이션을 수행하였으며, 정의한 29개 손상케이스의 동적거동 데이터로서 변형률, 변위, 가속도를 생성하였다.
교량의 손상위치추정은 시뮬레이션을 통해 생성한 동적거동 데이터를 입력값으로 하는 Deep Neural Network(DNN), Convolutional Neural Network(CNN), Recurrent Neural Network(RNN)을 통해 수행하였다. 검증은 각 딥러닝 알고리즘 별 동적거동 데이터들을 단계별 노이즈를 적용하여 진행하였다. 검증 결과, 설계한 딥러닝 알고리즘들은 노이즈가 없는 동적거동 데이터에 한하여 대부분이 약 90% 이상의 정확도를 나타내었으며, 3가지 동적거동 데이터 중 가속도를 입력값으로한 딥러닝 모델이 가장 유효한 결과를 도출하였다.
최종적으로는 가속도를 입력값으로한 RNN 기반 손상위치추정기법이 ±8.4%의 노이즈를 적용한 테스트에서 77.71%의 정확도로 가장 높은 효용성을 나타냈다. 따라서, 동적거동을 이용한 교량의 손상위치 추정에는 RNN기반 손상추정기법이 유력한 방법으로 판단된다.",
딥러닝 기반의 웹사이트 키워드 선택 기법을 통한 기업인 네트워크 계층 분석,2019,"다양한 고객의 요구를 만족시키기 위한 신제품 설계 및 개발의 필요성으로 인해 중소 기업인 간의 융합 활동의 중요성이 증대하고 있다. 특히 최고 의사결정을 가지는 중소기업의 대표는 적합한 융합 활동 파트너를 찾기 위해 인맥 관리는 필수적이다. 한편 중소기업인들은 한편 중소 기업인들은 인맥 형성 시 기업인들이 보유하고 있는 기술이나 유사한 토픽 정보를 가지고 있는 기업인과 인맥관계를 이해하고 형성하는 것이 중요하다. 그러나 중소기업의 현황 부재와 기업이 보유하고 있는 산업 분야별 기술 및 특성을 나타낼 수 있는 토픽 정보를 수집하는데 어려움이 있어, 기업인 간의 인맥 네트워크 관계를 이해하는데 한계가 존재한다. 따라서 본 논문에서는 기업인이 활동하고 있는 웹사이트에서 주요한 토픽 정보를 추출하고 이를 기반으로 기업인들의 네트워크 계층 분석을 통해 기업인들의 네트워크를 이해하고 융합 활동 활성화를 위한 시사점을 도출하고자 한다.
본 논문에서는 크게 두 부분으로 구성되어 있다. 첫 번째, 기업인이 활동하고 있는 웹사이트에서 기업인의 주요한 토픽 정보를 자동으로 추출하기 위해 딥러닝 기반의 웹사이트 키워드 선택 기법을 제안한다. 특히, 웹사이트에 있는 문서에서 키워드를 추출할 경우, 기존의 많이 사용되고 있는 기법인 문서에서 출현하는 단어의 빈도수를 고려한 기법, 단어의 동시출현관계를 고려한 그래프 알고리즘 기반으로 키워드를 추출하는 기법 등은 키워드가 추출되지 않는 문제점이 발생한다. 따라서 본 논문에서는 먼저 의미적 단어 위주로 구축된 후보키워드들의 집합과 word embedding모델을 통해 의미적 유사도 기반의 후보 키워드를 선택함으로써 기존 연구에서 발생되었던 문제점을 해결하고 기업인의 토픽 정보를 추출한다.
두 번째, 기업인들이 형성하고 있는 인맥 네트워크를 이해하기 위해 기업인이 활동하고 있는 웹사이트에서 추출 된 토픽 정보를 활용하여 3가지 측면에서 네트워크를 계층적으로 분석한다. 구체적으로 Connection, Social, Topic-Layer모델이 있으며 각각의 모델은 인맥의 양, 인맥 중심성, 토픽 유사성을 중심으로 분석한다. 특히, Topic-Layer모델에서는 토픽 정보를 시각적으로 표현하기 위해 토픽 추출 기법에서 사용된 word embedding모델을 응용하여 color embedding모델을 구축하였다. 따라서 Topic-Layer모델에서는 기업인간의 유사한 토픽 정보를 가지고 있는 기업인들은 유사한 컬러로 표현됨으로써 시각적으로 쉽게 네트워크를 이해하고 분석할 수 있다.
본 논문에서 제시된 기법들을 이용하여 실 데이터를 통한 실험 결과, 딥러닝 기반의 키워드 추출 기법은 기존의 키워드 추출 기법에 비해 우수한 성능을 보였다. 또한, 기업인들의 네트워크 분석에서는 인맥의 양이 적은 경우 중심성이 높은 기업과 네트워크를 강화하여 인맥 네트워크를 활성화 시켜야 할 필요가 있고, 토픽유사성이 낮은 경우 주제 기반의 네트워크를 활성화 시켜야 할 필요가 있다는 것을 실험을 통해 확인하였다.

Recently, as the necessary of design and develop new products to satisfy for various customers, the importance of convergence activities between entrepreneurs has increased. In particular, decision makers such as CEOs are required to participate in networks between entrepreneurs for being connected with valuable convergence partners. Moreover, it is important that entrepreneurs to understand that entrepreneur having technologies and similar topic information. However, as collection is difficult to the entrepreneur representative technology and topic information, there are limitations to understanding the network relationships between entrepreneurs. Therefore, in this paper, the entrepreneur hierarchical network is analyzed to understand for the convergence activities based on topic information extracted from the websites where the entrepreneurs are active by using deep learning based keyword selection method.
In this paper, consists two parts. First, we suggest the keyword selection method automatically extracted keywords from websites where the entrepreneurs are active based on deep learning. In particular, when the extracting keywords from the documents on a website, in cases of using keyword extraction based on graph algorithm and frequency, there arise a problem that subjective keywords do not include are extracted. Therefore, we resolve these problem by selection on the candidate keyword consist of semantic keyword, we use that for entrepreneur topic information.
In the second part, for understanding formed social network between entrepreneurs, we analyze the network hierarchically in three aspects by using topic information. Specifically, the proposed network models consist of Connection, Social and Topic-Layer. In particular, for the topic information of the entrepreneur utilizes as visualization, we have developed the color embedding model by exploiting the word embedding model used in the keyword extraction. Therefore, the proposed Topic-Layer model easily analyzes and understands network by visualizing in similar color the topic information of the entrepreneurs.
The experiment results by using real-world data show that the proposed deep learning based keyword extraction method performance outperforms compared to the previous keyword extraction. Furthermore, the hierarchical network analysis of entrepreneurs results shows that in case of the number of the network connections is smaller, the entrepreneurs need to activate network by connecting high centrality entrepreneur. On the other hand, when topic similarity between the entrepreneurs is low, topic based network need to be activated.",
딥러닝 기술을 이용한 만화 스타일 비디오 요약 기법,2019,"통신기술의 발달로 대중매체의 전송방법이 다양해졌다. 특히 빠른 시각적 변화를 이용하는 비디오 형태의 미디어 공급이 활발하게 이루어지고 있다. 최근 텍스트와 이미지를 결합한 웹툰을 이용하여 영화나 드라마로 재구성하는 산업이 활발하게 이루어지고 있다. 그러나 비디오를 이용한 정보전달 방식은 시청하기 위해 영상이 정해진 길이만큼 시간을 소모해야 한다는 시간적 제약 조건이 따른다. 본 논문에서는 기존 수동 비디오 요약의 시간문제를 해결하기 위해 자동화 과정을 제시한다. 우선 객체 추적방법인 Optical Flow를 이용하여 영상의 정보전달 단위를 분할한다. 이후 이미지의 특징을 이용하는 딥러닝 기술인 CNN(Convolutional Neural Network)모델을 이용하여 비디오 요약에 적합한 장면을 추출한 후 만화적 스타일과 레이아웃을 적용시켜 비디오 요약만화를 생성하는 방법을 제안한다.

With the development of communication technology, many different kinds of media transmission became popular. Especially, it is used for producing movies and dramas based on webtoon stories. However, users still spend a lot of time watching videos. In this paper, an automated process to solve the temporal problem of existing manual video summaries is proposed. In the preprocessing process, the information transfer unit is partitioned using optical flow. In the following process, CNN (Convolutional Neural Network) is used as an in-depth learning method for image feature extraction. Finally, the proposed algorithm creates a video summary comic by applying comic style and layout to the extracted scene.","#딥러닝, #비디오 요약, #만화 스타일"
영상 복원을 위한 딥러닝 기반의 효율적인 잔여 네트워크 개발,2019,"최근 매우 깊고 넓은 컨볼루션 네트워크는 초해상도, 잡음제거, 손실 압축 복원 등을 포함한 영상 복원 분야에서 매우 뛰어난 성공을 이뤄내고 있다. 그러나 깊고 넓은 네트워크는 네트워크가 복잡해짐에 따라 특징 정보를 충분히 활용할 수 없기
때문에, 상대적으로 불안정하고 성능 저하를 초래한다. 본 논문에서는 이러한 문제를 해결하기 위해 딥러닝 기반의 새로운 모델을 제안하며 효율적인 잔여 네트워크(Efficient Reisual Auto-Encoder Network, ERAN)라 칭한다. ERAN는 모든 컨볼루션 층을 특징 정보를 효율적으로 이용할 수 있도록 설계하였다. 특히, Local Concatenation Module이 기반의 효율적인 잔여 모듈(Efficient Residual Module, ERM)을 통해 각 residual module의 내부 특징을 정재하여 네트워크가 깊어지더라도 안정적인 학습이 가능하다. 또한 학습이 깊어 짐에 따라 특징 크기를 줄여가며 계층적 특징을 추출하고, 이후 Global Concatenation Module을 통해 서로 다른 크기의 계층적 특징을 결합하여 모델 내 모든 특징 기반 학습이 가능하다. 초해상도, 잡음제거, 손실 압축 복원 분야의 벤치마킹 데이터를 통해 모델 성능을 평가하였으며, ERAN 모델이 기존 모델보다 더 뛰어난 성능을 보였다.","#영상복원, #딥러닝, #네트워크개발"
딥러닝 기반 포즈 변화에 강인한 귀 인식 연구,2019,"최근 들어 개인 고유의 생체 특징을 통해 신원을 식별하는 생체 인식 기술로서 귀 인식 연구가 주목받고 있다. 또한 다양한 생체 인식 분야에서 딥러닝을 기반으로 포즈 및 조명 변화, 가림 등이 존재하는 비제약적 환경에서의 인식 성능 고도화가 이루어짐에 따라 귀 인식 분야에서도 딥러닝 기반 연구가 진행되고 있다. 하지만 딥러닝 모델 학습에 필수적인 대규모 귀 영상 데이터베이스의 부재와 귀 특성을 고려한 관련 연구가 아직 초기 단계에 있어 인식 성능에 한계가 존재한다. 이를 개선하기 위하여 본 연구에서는 비제약적 환경 기반 귀 인식 연구에 활용 가능한 K-Ear 데이터베이스를 구축하였다. K-Ear 데이터베이스는 정면으로부터 최대 60°까지의 포즈 변화, 조명 변화, 그리고 가림 등이 존재하는 다양한 환경의 귀 영상을 포함한다. 이를 기반으로 특히 포즈가 변화함에 따라 인식 성능이 저하되는 문제를 개선하기 위한 딥러닝 기반 귀 인식 모델을 제안한다. 제안하는 모델은 귀의 형태 등의 고유한 특성을 고려하기 위한 전처리로 입력 영상에 zero-padding 등을 적용하고 극심한 포즈 변화에서의 인식 성능 향상을 위하여 VGGNet과 ResNet 기반의 특징 추출 및 스코어 레벨 기반 앙상블을 수행한다. 실험 결과를 통해 제안하는 귀 인식 모델이 단일 모델 활용 대비 극심한 포즈 변화에서 rank-1 기준 20% 이상 성능이 향상되는 것을 확인하였다.",
딥러닝을 이용한 GMA 용접에서 이면비드 생성 판단 알고리즘에 관한 연구,2019,"아크 용접에서 이면 비드의 발생은 용접 구조물의 기계적 특성을 결정 짓는 주요 요인 중 하나로 간주된다. 특히 선박용접의 경우 용접 자동화의 측면에서 실시간으로 용접의 상태를 반영하여 용접 파라미터를 결정하기가 매우 어렵다. 시스템상에서 용접의 진행상황에 따라 이면비드가 형성되었는지에 대한 판단이 필수적인 요건이다.
기존의 용접 상태를 판단하는 방법으로는 비드의 존재 또는 모양은 단면을 자르는 파괴 검사 또는 시각 또는 초음파를 사용하는 비파괴 검사로 관찰할 수 있다. 또한 최근에는 인공지능을 사용하여 용접의 상태를 진단하는 연구가 활발히 진행되고 있으며 특히 인공지능 기법으로는 딥러닝이 대두되고 있다.
본 연구에서는 딥러닝 기법인 심층신경망과 순환신경망을 적용하여 실시간으로 측정 한 전류 및 전압 신호를 이용하여 실시간으로 이면비드가 생성되었는지 판단하는 알고리즘을 개발하였다. 제안된 시스템은 추가적인 센서부착이 없어 산업 현장에 쉽게 접목할 수 있다. 기존 인공신경망과 딥러닝을 사용하여 학습을 진행하고 그 결과를 서로 비교하여 적절한 시스템을 결정하였다.",#기계공학
딥러닝 기반 재실자 포즈별 MET 산출모델 개발,2019,"재실자의 건강, 생산성, 삶의 질 향상을 위해 건물의 쾌적한 열환경 제공의 중요성이 강조되고 있다. 실내 열환경의 지표 중 PMV는 실내의 환경적 요소와 개인적 요소를 모두 고려하는 통합적 열 쾌적 지표로 적용되지만 활동량(MET)과 같은 개인적 요소의 측정에 한계가 있다. 또한 기존의 MET 측정 방법은 간접접인 측정을 기반으로 재실자의 부수적인 정보를 사용하였고 부착형 또는 휴대형 측정기기 사용하는 등 적용에 제한이 있었다. 이러한 방법은 MET 측정에 있어 오차를 야기하고 정확도 향상에 한계가 발생한다. 이와 같은 한계점을 해결하기 위해 재실자의 부수적인 정보 없이도 활동을 구분할 수 있고 건물에 적용이 쉬운 근본적인 MET 측정 방법이 요구되었다.
따라서 본 연구에서는 실내에서 재실자의 이미지를 사용하여 실내활동을 구분하고 MET를 측정하기 위해 딥러닝 알고리즘을 사용한 지능형 MET 산출모델 개발을 진행하였다. MET 산출모델은 실내 카메라 센서로 수집된 이미지의 인체 관절 좌표를 사용해 재실자의 포즈를 분류하고 MET를 측정한다. 모델의 개발을 위해 10가지 실내 활동 이미지 총 500개를 수집하였고 다양한 데이터 증가 기법을 적용하여 198배 증가시켰다. MET 산출모델의 구조는 입력층, 은닉층, 출력층과 관절 좌표가 입력되는 28개의 입력뉴런, 포즈를 출력하는 1개의 출력뉴런으로 구성된다. 은닉층은 형태별로 5가지 Case로 구성하였고 은닉층 수와 은닉뉴런의 수를 변경하며 총 20가지 구조에 대한 학습을 진행하였다.
모델의 평가는 학습 데이터의 정답 MET와 모델의 결과로 측정된 MET의 비교를 통해 진행되었다. 먼저, K-fold Cross Validation을 통해 최대 정확도를 보이는 모델은 은닉층 4개와 은닉뉴런 140-112-84-56으로 구성되며 83.64%의 정확도를 보였다. 최대 정확도를 보이는 모델의 MET 값에 따른 모든 ROC 커브의 AUC가 0.8 이상의 값을 나타내므로 분류 알고리즘의 성능이 양호한 수준이다.
MET 산출모델의 개발을 통해 실내 영상 이미지를 이용한 재실자의 MET를 측정하는 방법의 가능성을 확인하였다. 추후 실내활동의 범위를 늘리는 등 모델의 성능을 향상시켜 개인적 요소를 고려하는 PMV 예측 제어의 기반을 형성할 것으로 기대한다.

Providing a comfort indoor thermal quality for improving the life quality, productivity, and health of occupants is important. Predicted mean vote (PMV) can be applied as an integrated thermal comfort indicator that considers both the environmental and individual factors such as metabolic rate (MET) of the indoor. However, the MET have limitations for measurement such as requiring subsidiary information of the occupants or using an attachable device. The limitations of measurement cause errors and limits the improvement of accuracy. Therefore, a new method for estimating the occupant metabolic rate (MET) that is fundamental and convenient to apply to buildings is needed.
The aim of this study was to develop an intelligent occupant MET estimation model by using a deep learning algorithm by occupant pose indoor. The MET estimation model classifies the occupant pose and MET using the human joint coordinates from an image that is captured by an indoor camera sensor. For the MET estimation model, 500 images of10 indoor activities were collected and various data augmentation techniques were applied to increase the data. The model has an input layer, hidden layer, output layer, and 28 input neurons for 14 pairs of coordinates and 1 output neuron for one estimated pose. Moreover, the model was trained using 20 cases of different models, which included various shapes of the hidden layer based on the number of hidden layers and hidden neurons.
The evaluation of the MET estimation model was performed by comparing the labelled and estimated MET. As a result of the training, the maximum accuracy achieved was 83.64% from the Case 5-b model that included 4 hidden layers and 140-112-84-56 hidden neurons. Also, the Case 5-b model was evaluated based on MET of each activity using the Receiver operating characteristic (ROC) curve. Because the Area under the curve (AUC)of the ROC curve was more than 0.8 for all the MET values, the performance of each classification algorithm was regarded as good.
In conclusion, by the development of the MET estimation model, the possibility of estimating the occupant MET from indoor images was confirmed. In the future, it is expected that the MET estimation model will form the basis of PMV predictive control considering the individual factors by improving the performance of the model.",
딥러닝을 이용한 유체 표면 노말맵 추출 알고리즘,2019,"본 논문은 딥러닝 기술을 이용해 퀄리티가 낮은 유체 표면 Normal Map으로부터 퀄리티가 높은 유체 표면 Normal Map을 추출해내는 알고리즘을 제안한다. 최근 물을 표현하는 유체 시뮬레이션은 대부분 라그랑주 방식인 Particle 기반으로 이루어진다. Particle 기반으로 이루어진 시뮬레이션의 연산 결과는 Particle들의 위치가 된다. 이 Particle들을 유체처럼 Rendering하려면 또 다른 과정이 필요하다. 유체를 Rendering하는 방식 중에는 Particle들을 이용해 삼각형 메쉬를 생성해서 Rendering하는 방식이 있고, Particle들을 화면 좌표계로 옮긴 후 Depth Map을 이용해 Normal을 추출해 Rendering하는 방식이 있다. 전자의 경우 해상도를 높이면 정교한 유체를 생성할 수 있지만 연산이 오래 걸린다는 단점이 있다.
본 연구에서 제안하는 방식은 후자의 방식으로 생성된 Normal Map을 딥러닝 모델에 입력으로 주어 정교하게 생성된 Normal Map을 추출해내는 것이다. 딥러닝이 최근 여러 분야에서 두각을 나타내고 있고 생성 모델 중에는 GAN(Generative Adversarial Nets)이 가장 많은 인용이 되고 있다. 본 연구는 이 GAN을 이용해 빠르게 생성된 Normal Map을 정교한 Normal Map으로 변환하는 과정을 거친다. Training 과정을 통해 GAN은 빠르게 생성된 Normal Map에서 생기는 Artifact를 제거할 수 있다. 또한 정교한 Normal Map을 만들기 위해 Convolution등의 연산만 하므로 연산 속도가 이미지 Resolution에만 의존한다는 장점이 있고 Particle의 위치 데이터만 이용하기 때문에 유체 Particle 뿐만 아니라 다른 정점 데이터에도 적용될 수 있다는 장점이 있다.",
딥러닝을 위한 파이프라인 방식 확률적 경사 하강법,2019,"Parallel train algorithms for deep neural networks (DNNs) are needed to train substantial data. Deep learning has been rapidly growing since 2006 after the introduction of deep belief nets, which DNNs are initialized by the restricted Boltzmann machine. Deep learning has performed well in a variety of classification problems. Many deep learning applications typically perform better with more data. It takes a lot of time for DNN to train a large data set. As data become large, faster train method is needed.
Many parallel learning algorithms are introducing various approximation to speed up. Stochastic gradient descent (SGD) is the most widely used method for training DNNs. Since SGD is an inherently sequential process, the parallelization of SGD is difficult. Delayed gradient problems occur while sequential processes are parallelized.
To avoid the problem of gradient mismatch due to delayed gradients, we improve Pipelined SGD by storing model parameters of each module regarding to the time delay.
The proposed method showed the speedup of x2.25 using 4-GPU without significant performance degradation for Cifar10 dataset.","#딥러닝, #병렬처리"
딥러닝 기반 항생제 내성균 감염 예측,2019,"세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각한 경고를 하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염 확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반 분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding 하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염 간의 높은 연관성이 발견되었다.

The World Health Organization (WHO) and other government agencies around the world have warned against antibiotic-resistant bacteria due to abuse of antibiotics and are strengthening their care and monitoring to prevent infection. However, it is highly necessary to develop an expeditious and accurate prediction and estimating method for preemptive measures. Because it takes several days to cultivate the infecting bacteria to identify the infection, quarantine and contact are not effective to prevent spread of infection. In this study, the disease diagnosis and antibiotic prescriptions included in Electronic Health Records were embedded through neural embedding model and matrix factorization, and deep learning based classification predictive model was proposed. The f1-score of the deep learning model increased from 0.525 to 0.617 when embedding information on disease and antibiotics, which are the main causes of antibiotic resistance, added to the patient''s basic information and hospital use information. And deep learning model outperformed the traditional machine learning models. As a result of analyzing the characteristics of antibiotic resistant patients, resistant patients were more likely to use antibiotics in J01 than nonresistant patients who were diagnosed with the same diseases and were prescribed 6.3 times more than DDD.","#Antibiotic Resistance, #Deep Learning, #Neural Embedding Model, #Matrix Factorization, #Electronic Health Records"
카메라를 활용한 딥러닝 기반 실시간 자율주행 자동차의 후·측방 객체 검출 & 차로 변경에 관한 연구,2019,"자율주행 자동차는 외부 환경의 다양한 객체에 대해 센서를 통해 스스로 인식하고 주행 방법을 계산해낼 수 있는 시스템을 갖추고 있어야 한다. 주행 환경 변화에 따른 인지 센서의 인식률 저하는 사고 유발 확률을 높일 수 있다. 또한 인지 센서의 실시간성 저하로 인한 객체 검출의 지연은 자율주행 자동차의 안전성에 있어 가장 큰 위험원이 될 수 있다. 본 논문은 카메라를 활용한 딥러닝 기반 후·측방 객체 검출과 차로 변경에 관한 연구이다. 기존 자동차의 경우 사후경을 통해 후·측방에 대한 객체를 인지한다. 그러나 사후경은 각도의 한계를 가지고 있으며 이로 인해 사각지대가 발생하게 된다. 이러한 사각지대로 인해 발생하는 후·측방 교통사고 문제를 해결하기 위하여 사후경을 카메라로 대체함으로써, 사각지대를 보완하고 딥러닝 기반 객체 검출 알고리즘을 통해 후·측방 객체를 검출한다. 카메라를 통해 후·측방 객체의 유·무를 판단하며, 차선 검출 및 차로 변경 알고리즘을 통해 자율주행 자동차의 안전한 차로 변경이 수행될 수 있도록 하는 네트워크를 제안한다. 위에서 설명하는 네트워크는 크게 두 개의 시스템으로 나눌 수 있다. 첫 번째 시스템은 전방 카메라를 통해 차선을 인식하여 자율주행 자동차의 사전 경로를 출력하며 Pure Pursuit 알고리즘을 통해 경로를 추종하게 된다. 두 번째 시스템은 후·측방에 대한 객체 검출을 위한 네트워크로, SSD(Single Shot Multibox Detector) 알고리즘을 활용하여 객체의 유·무를 판단한다. SSD 알고리즘은 기존의 컨볼루션 계층(Convolutional Layer)을 추가한 수정된 VGG16을 fine-tuning 하여 이미지에 대한 특징 맵을 출력한다. 추가적인 컨볼루션 계층을 통해 출력된 특징 맵은 특정 비율과 크기를 갖는 default bounding box를 통해 객체를 분류하고 검출하는 구조를 갖는다. VGG16은 PASCAL VOC 07, 12를 활용하여 학습 데이터와 테스트 데이터로 구성하였다. 본 논문에서 제안하는 네트워크는 실제 주행 영상 데이터를 통해 후·측방 객체 검출의 정확성과 실시간성을 검증하였으며, 전방 카메라를 통한 차선 검출과 그에 따른 차로 변경에 대하여 자율주행 적용 가능성을 확인하였다.

An autonomous vehicle must have a system that can self-identify and calculate the driving method for various objects in the external environment through sensors. Decrease of recognition rate of cognitive sensor due to change of driving environment can increase the probability of accident occurrence. In addition, the delay of object detection due to degradation of real-time performance of cognitive sensor can be the biggest risk of safety of autonomous vehicle. This paper is a study on the detection & lane change of the rear and side objects of deep learning based real time Autonomous vehicle using camera. In the case of an existing automobile, objects are recognized to the rear and the side through the side mirrors. However, the side mirrors have angular limitations which cause blind spots. In order to solve the rear and side traffic accidents caused by the blind spot, the side mirror is replaced with the camera to compensate the blind spot and the rear and side objects are detected through the deep learning based object detection algorithm. We propose a network that enables the safe change of autonomous vehicle through lane detection and lane change algorithm by judging the presence or absence of rear and side objects through camera. The network described above can be broadly divided into two systems. The first system recognizes the lane through the front camera, outputs the preliminary route of the autonomous vehicle, and follows the route through the Pure Pursuit algorithm. The second system is a network for object detection for the rear and side, SSD(Single Shot Multi-box Detector) algorithm is used to judge whether the object exists or not. The SSD algorithm uses VGG16, which is a modification of the fully connected layer of the existing VGG16 to the convolutional layer, adds a convolution layer of various sizes to output a feature map for the image. The feature map output through the additional convolution layer has a structure for classifying and detecting objects through a default bounding box having a certain ratio and size. VGG16 consists of learning data and test data using PASCAL VOC 07, 12 and logging data. The network proposed in this paper verifies the accuracy and real-time performance of rear and side object detection through real driving image data, we confirmed the applicability of autonomous driving to lane detection and change of lane through front camera.",
영상처리 기법과 딥러닝을 사용한 채소(오이)의 등급별 자동 분류 시스템 개발,2019,"농업에서 상품에 대한 질을 확인하고 향상시키는 작업은 영상처리에서 굉장히 중요한 부분이다. 본 논문에서는 영상처리 기법과 딥러닝 기술을 사용하여 채소의 등급을 자동 분류하기 위한 시스템을 소개한다. 실제 농가에서는 스마트팜(Smart_Farm)을 도입하여 생산량의 증가로 자연히 수익을 늘어나고 또 노동시간이 단축되며 여가시간이 늘어 농가의 삶의 질을 높일 수 있게 되었다. 이를 목적으로 농가에서 직접 재배한 오이를 동일한 배경에서 촬영하여 이미지 데이터와 데이터 증가(Augmentation) 기법을 통해 데이터셋을 구성하고 3가지 등급으로 분류하기 위한 머신러닝방법인 SVM과 딥러닝 방법인 CNN, VGGNet 등을 사용하여 훈련과 검증을 통해 비교 한다. 본 연구의 의의는 대규모 데이터에서 오이를 기계가 자동으로 중요한 패턴과 규칙을 학습하고 의사결정과 예측 등을 하기 위해 구조나 손실 및 활성화 함수들 그리고 학습비율과 같은 하이퍼 파라미터(Hyper Parameter) 등을 변경시켜 가며 더 좋은 분류 성능을 내는 알고리즘을 발견하는 것이다. 또한 제안된 알고리즘이 우리가 농업현장에서 취득한 영상자료를 실험에 적용한 결과 상당히 좋은 성능을 보여주는 것을 알 수 있었다. 앞으로 이를 발전시켜 어플리케이션이나 클라우딩 서비스(Clouding Service)와 같은 플랫폼을 개발해 더 좋은 데이터를 많이 확보하고 훈련을 시킨다면 자동분류 시스템의 개발에 더 좋은 성능이 기대되며, 다양한 방면에 활용이 가능 할 것이다.","#Deep-learning, #Machine-learning, #Agriculture, #VGGNet, #Cucumber"
"Text mining 과 딥러닝을 결합한 국제 원자재(WTI, gold, copper) 가격 예측 모델 개발",2019,"원자재 가격은 환율, 금리, 이슈, 투기, 수급 등 다양한 요인이 맞물려 결정된다. 이렇게 급변하는 경제상황에서 원료 가격은 물가의 상승과 하락에 기인하며 산업 전반에 상당한 영향을 미치기 때문에 매우 중요하다. 이를 대비하며 정량적 예측에서 발생하는 괴리를 줄이기 위해 경제와 원자재 시황이라는 정성적인 내용을 텍스트 마이닝하여 정량적으로 모델에 반영하였다.
또한, 이에 시계열 예측 모델인 벡터자기회귀모델(Vector Autoregression; VAR)과 딥러닝 모델인 다층퍼셉트론(Multi-layer Perceptron)을 결합하여 새로운 원자재 예측 모델을 연구하여 제안하였다. 시계열 통계 예측 모델인ARIMA와 VAR 그리고 시계열 딥러닝 네트워크인 MLP의 단일모델과 비교한 결과, 텍스트마이닝을 추가한 결합모델(TM.VARMLP)이 가장 작은 오차율을 나타내며 예측력의 우수함을 보였다.
시황 뉴스에는 세계 경제 상황에 대한 호재와 악재의 뉴스 및 화제거리가 반영되어 있다. 이러한 이슈, 이벤트 등이 시장에 미치는 영향은 지대하기 때문에, 이를 예측 모델에 추가하여 시장 상황을 반영하는 적합한 모델을 생성하였다. 정량적인 데이터만을 가지고 학습되는 기존 예측 모델들과 달리, 시장 참여자들의 심리와 계속적으로 변화하는 정성적인 시장상황을 반영하는 의미가 존재한다.
예측대상 변수는 해외 거래소의 원유(WTI), 구리 가격(Copper 3Months Official Price), 금(Gold) 가격이고, 분석에 사용한 변수로는 각 품목의 일일 정산가(Settlement Price), 시가(Open Price), 고가(High Price), 저가(Low Price)와 환율(USD/EUR), 구리 일일 정산가(Settlement Price), 미국 10년 만기 및 1년 만기 국채 수익률 스프레드, 텍스트마이닝 결과이다.","#MLP(Multilayer perceptron), #VAR(Vector autoregression), #Text mining, #Deep Learning, #Commodity"
V2X와 딥러닝 기반의 자율주행차를 위한 차선 위치 인식 기술,2019,"There has been a lot of research on autonomous driving lately. Various applications for self-driving cars carry out object recognition through cameras or various sensors in advance. It is also important to recognize the roadway in which the host vehicle drives during this prior recognition. This is because many applications of connected cars or self-driving cars are based on recognition of driving Road lanes. Methods for determining the driving road lane are as follows. Locate the yellow lane line after detecting the lane marker based on the characteristics of the lane marker. Locate the load lane of the host vehicle depending on the location of the yellow lane found. However, we have identified that it is difficult to find a driving lane on roads above three lanes, and that intersections without lane markers are also difficult to identify. This paper presents new ways to utilize V2X and Deep Learning technologies on roads above the three-lane. A Deep Learning model was designed to identify the driving lanes of a vehicle in question using the front image characteristics received from the vehicle within the communication range from the RSU installed on the side of the road. Through this, the predicted accuracy of 90% or more was verified in the three-lane road and intersection environment.","#자율주행자동차, #차로 예측, #딥러닝"
딥러닝을 활용한 LSTM모형 구축 및 댐 유입량 예측,2019,"기후변화로 인한 홍수기 홍수피해와 갈수기 가뭄피해가 심화되고 있으며, 수자원 관리에 대한 어려움이 발생하고 있다. 효율적인 수자원 관리를 위해 국내에는 약 18,000여개의 댐을 운영하고 있으며, 댐의 유입량과 저수량을 감안하여 물을 적절하게 방류하는 것을 목적으로 한다. 본 연구는 댐의 효율적인 운영을 위해 미래 댐 유입량을 예측하고 예측의 정확도를 높이기 위한 방법을 제시하고자 하였다.
기존에는 수위나 유량을 예측하기 위해 주로 개념적 또는 물리적 모형이 사용되어 왔으나, 이러한 모형은 매개변수 결정을 위하여 많은 자료를 필요로 하고 그 과정에서 많은 불확실성을 포함하고 있기 때문에 계산 과정을 거치는 동안 다양한 오차가 반복 누적되는 단점이 있다. 최근에는 데이터 예측 방법으로 인공신경망(Artificial Neural Network, ANN)분야에 대한 관심이 높아졌으며, 그 중 시계열 데이터 예측에 특화된 LSTM(Long Short-Term Memory)모형은 입력데이터와 출력데이터의 상관관계만을 이용하여 예측값을 얻을 수 있기 때문에 수문 시계열자료의 예측방법으로도 활용되고 있다.
본 연구는 다목적댐의 유입유량 예측을 위해 구글에서 제공하는 딥러닝 오픈소스 라이브러리인 텐서플로우(TensorFlow)를 활용하여 LSTM모형을 구축하고 금강 상류에 위치한 용담다목적댐의 유입량을 예측하였다. 분석 자료로는 WAMIS에서 제공하는 용담댐의 2006년부터 2018년까지의 시간당 유입량 자료를 사용하였으며, 2006년 1월 1일부터 2015년 2월 5일까지의 자료를 학습(Training)하여 2015년 2월 6일부터 2018년 12월 31일까지의 시간당 유입량을 예측하였다. 예측된 유입량과 관측 유입량의 비교를 통하여 평균제곱오차(RMSE), 평균절대오차(MAE), 용적오차(VE)를 계산하고 정확도를 평가하였다.
LSTM모형의 네 가지 학습매개변수에 따른 예측 정확도를 비교·분석하기 위하여 다양한 변수 조건에서의 예측분석을 실시하였으며, Sequence Length는 3, Hidden Dim은 20, Learning Rate는 0.0001, Iteration은 5000으로 설정한 모형의 RMSE가 0.0006, MAE가 7.01, VE가 0.1로 정확도가 가 장 우수한 것으로 나타났다. 그러나 모든 모형이 극치 유량에서의 정확도가 낮아지는 것을 알 수 있었으며, 이를 해결하기 위하여 용담댐 유역의 시간당 강수량 자료(2006년∼2018년)를 추가 입력 변수로 활용하였다.
강수량 자료와 유입량 자료를 함께 이용하였을 경우 유입량 자료만 이용했을 때 보다 실제 유입량과의 차이가 최대유량은 321.40 ㎥/s에서 155.07 ㎥/s까지 총 166.33 ㎥/s만큼 감소하였으며, 총 유량은 818.18 ㎥/s에서 532.99 ㎥/s까지 총 283.19 ㎥/s만큼 감소하였다. 그러나 최소유량은 실제 유량보다 1.27 ㎥/s만큼 초과하여 정확도가 낮아지는 것을 알 수 있었다. 또한 예측 유입량을 월별로 나누어 홍수기와 갈수기의 예측결과를 비교·분석 하였다. 따라서 본 연구는 수공구조물의 설계와 운영을 위한 기초자료로 활용될 수 있도록 높은 신뢰도의 댐 유입량 예측 방법을 제시하고자 한다.

Flood and drought damage are intensifying during wet and dry season due to the extreme weather conditions by climate changes which leads to difficulty of water resource management. 1,800 of dam are operated in Korea in order to manage water resources and it is aimed to release the proper amount of water considering the inflow and capacity of water. This study suggests methods to predict the future inflow and improve the accordancy of prediction for effective dam operating.
Conventional conceptual or physical models have been mainly utilized to predict water level and flow which requires a lot of data to determine the parameter however, there are the disadvantage in these process that contains many uncertainties and various errors are rehashed and accumulated for data. Recently, Artificial Neural Network field receive attention as data prediction method. Among these, a Long Shot-term Memory model specialized for time-series data prediction can obtain a predicted value utilizing only correlation between input data and output data. It is also utilized as a prediction method of hydrological time series data.
In this study, LSTM model was constructed utilizing deep running open source library TensorFlow which provided by Google, to predict inflow of multipurpose dam. We predicted the inflow of the Yongdam Multipurpose Dam which is located in the upper stream of the Geumgang. The hourly flow data of Yongdam Dam from 2006 to 2018 provided by WAMIS was used as the analysis data. The data from January 1, 2006 to February 5, 2015 were trained to predict the hourly inflow from February 6, 2015 to December 31, 2018. Root mean square error (RMSE), Mean absolute error(MAE) and Volume error(VE) were calculated and evaluated its accuracy through comparing the predicted inflow and observed inflow.
Predictive analysis was performed under various of variable condition in order to compare and analyze the prediction accuracy according to four learning parameters of LSTM model. Model was set up as sequence length was 3, Hidden dim was 20, learning rate was 0.0001 and iteration was 5000, showed the highest accuracy as RMSE was 0.0006, the MAE was 7.01 and VE was 0.1. However, we found that all the models had lower accuracy at extreme inflow and hourly precipitation data (2006 ~ 2018) of Yongdam Dam utilized as additional input variables to solve this problem.
When the data of rainfall and inflow were utilized together, the maximum flow was reduced total 166.33 ㎥/s from 321.40 ㎥/s to 155.07 ㎥/s, and the total flow was reduced 283.19 ㎥/s from 818.18 ㎥/s to 532.99 ㎥/s. However, it was found that the minimum flow rate was 1.27 ㎥ / s more than the actual flow rate. In addition, the predicted inflows were divided by month, and the forecast results of flood season and wet season were compared and analyzed. Therefore, this study suggests a method of predicting dam inflow with high reliability so that it can be utilized as the basic data for the design and operation of the hydraulic structure.",
딥러닝 기반의 음성-수화 번역 시스템 설계 및 구현,2019,"본 논문에서는 청각장애인 커뮤니케이션을 위한 시스템에 관한 것으로, 청각장애인의 듣지 못하는 불편함을 해소하기 위해 수화를 모르는 일반인들과 의사소통 할 수 있도록 음성을 수화 3D 애니메이션으로 실시간으로 출력하는 시스템을 연구하였다.

수화 3D 애니메이션을 출력하는 시스템은 청각장애인이 수화통역사의 역할을 대신하여 청각장애인들에게 보다 많은 사회참여 기회를 제공할 수 있다. 표준 한글 수화를 활용하여 수화 사전을 구성하였다.

음성을 수화로 번역하기 위해 딥러닝 기반의 번역 시스템을 구현하였다. 음성을 텍스트로 변환하기 위해 Google Speech To Text를 사용하여 한국어로 변환하고 한국어의 형태소 분석을 위해 순차 레이블링에 특화된 LSTM 기반 모델을 사용하여 형태소 분석기를 구현하였다. 형태소 분석 결과를 수화로 변환하고 수화를 애니메이션으로 표현하기 위해 데이터베이스를 구축하였다. 실시간으로 3D 캐릭터를 수화 애니메이션으로 출력하기 위해 Unity 3D를 활용하여 구현하였다.

Bidirectional LSTM CRF 모델을 적용한 형태소 분석기의 정확도는 92.1% 측정되었다. 4316개의 polygon과 texture, material, rigged, UV mapping을 사용하는 3D 캐릭터 모델을 사용하였고, 음성을 3D 애니메이션으로 화면에 출력하는데 약 700ms의 시간이 소요되었다.

In this paper, we studied systems for the communication of hearing-impaired people that produce voice in real time in sign 3D animation in order to communicate with ordinary people who do not know how to hear.

A system that outputs sign language 3D animation may provide more social participation opportunities for deaf people in place of the role of a sign language interpreter. A sign language dictionary was organized using standard Korean sign language.

A Deep Learning-based translation system was implemented to translate speech into sign language. Formal analyzer was implemented using LSTM-based models specialized in sequential labeling to translate speech into text and translate into Korean using Google Speech to Text. A database was constructed to convert the results of a morphology analysis into sign language and to animate the sign language. Unity 3D was used to animate 3D characters in real time.


The accuracy of the morphological analyzer of the bidirectional LSTM CRF model was measured to be 92.1%. 4316 polygon, texture, material, rigid body and UV mapping 3D character model was used, and voice was taken about 700ms to display on 3D character animation.",#컴퓨터공학
교량의 디지털트윈 구현 및 CNN 딥러닝을 통한 손상 위치 추정 프로세스 개발,2019,"본 논문에서는 교량을 대상으로 한 디지털트윈을 구현하였고, 구현한 디지털트윈을 적용한 손상 위치 추정 프로세스를 개발하였다. 교량의 디지털트윈을 구현하기 위해서는 해당 교량에서 재하시험을 통한 계측값 및 설계도면을 이용해 해당 교량의 해석 모델을 업데이팅해야 한다. 이렇게 업데이트된 교량 해석 모델을 사용한 구조해석 프로그램으로 교량의 변형률과 변위 관계를 전체 도메인에 대해 근사적 개념으로 구한 B행렬로 표현하였다. B행렬을 사용하여 교량에 설치될 변형률 센서 위치에서의 변위를 구하고 이를 좌표화하면 디지털트윈의 시각화를 구현할 수 있다. 구현된 디지털트윈을 사용하여 교량에서의 손상 위치를 추정하는 프로세스를 개발하기 위해 Convolutional Neural Network(CNN) 딥러닝(deep learning)기법을 적용하였다. Python언어 기반의 CNN 데이터 학습 프로세스를 구축하고 변형률과 변위 데이터를 이용하여 학습 정확도를 향상시켜 가장 정확도가 높은 데이터를 제시하였다. 본 논문에서는 디지털트윈 구현 및 적용의 가
능성을 판단하기 위해 보 구조물과 PSC빔교를 예시로 들었다. 2가지 구조물 모두 변형률과 변위 관계를 의미하는 B행렬을 구하고, 구조물에 실제 발생하는 변위와 B행렬에 의한 변위를 비교하여 오차율을 구하였다. 그리고 개발한 변형률과 변위 데이터를 통한 손상 위치 추정 프로세스의 예측 성공률을 측정하였다. 최종적으로 보 구조물과 PSC빔교에 디지털트윈을 구현하고 적용한 결과를 통해 교량에 디지털트윈 구현 및 적용 가능성을 판단하였다.",#디지털트윈
딥러닝 기반의 순방향 전파형 가중치 양자화 기법,2019,"여러 분야에서 뛰어난 성능을 보이는 딥러닝은 뉴럴 네트워크의 은닉 계층을 늘려 깊은 네트워크 구조를 형성할 수 있다. 이에 따라 복잡한 데이터를 쉽게 분류할 수 있으나, 가중치 수 증가로 인해 학습 연산량 및 메모리가 증가한다. 이처럼 많은 연산과 메모리가 필요한 딥러닝은 일반적으로 클라우드 상으로 학습하나, 클라우드는 사용자와의 통신상태가 원활해야 하며 서비스 비용에 대한 부담감 및 개인정보 유출에 대한 위험성을 가진다. 이러한 문제를 해결하기 위해서 딥러닝을 임베디드 디바이스에 탑재해야 하며 온디바이스 탑재를 위한 네트워크 경량화가 필요하다. 경량화 기법으로는 프루닝 기법과 양자화 기법이 널리 사용되고 있으며 기존 양자화 기법은 비지도 학습 중 하나인 K-means를 사용하여 각 계층의 가중치들을 군집화하여 대푯값을 결정한다. K-means 기법에서 군집의 개수를 의미하는 K는 시행착오 방법을 통해 설정해야 하며 이에 따른 오버헤드가 발생한다. 또한, 기존 양자화 기법은 네트워크 각 계층의 연결 관계를 무시한 채 독립적으로 양자화한다. 우리는 연산 오버헤드 문제를 해결하기 위해 가중치들의 통계적 정보를 이용한 즉각적 가중치 양자화 기법을 제안하고 네트워크 각 계층의 의존관계를 고려하여 순차 적으로 양자화함으로써 향상된 학습 성능을 보여준다.",
딥러닝 기반 사과 품질 선별 시스템에 관한 연구,순천대학교 논문은 저작권에 의해 보호받습니다.,"4차 산업혁명기술의 발전에 따라 인공지능 기술 중 하나인 딥러닝 기술은 이미지 인식 분야에서 좋은 성과를 보여주고 있다. 본 논문에서는 딥러닝 모델 중 하나인 CNN 기반 Inception-v3를 활용하여 사과의 품질 선별 학습 모델을 제안한다.
제안하는 방법은 사과 이미지 데이터 셋, 모델 학습, 사과 품질 분류 메소드, Test data에 대한 성능 평가로 구성된다. 사과의 이미지 분류를 위해 기존 Inception-v3을 Transfer Learning 하였으며, 4개의 클래스에 총 1,280개의 사과 이미지를 활용하여 학습모델을 설계하였다. 반복학습 횟수는 횟수에 따른 정확도의 비교로 3,000회로 지정하였으며, 성능 평가를 위한 Test data는 스마트폰을 이용해 촬영한 이미지를 사용하였다. 또한 이미지 각 방향에 따라 분류 결괏값이 달리 나올 수 있기 때문에 1개의 사과 당 4방향(전면, 측면(좌/우), 후면)에서 촬영을 하였으며, 품질 분류 알고리즘을 설계해 정확한 분류 결괏값을 보일 수 있도록 하였다.
실험은 각 클래스에 따라 총 4번 진행되었으며, 사과의 방향에 따른 분류 정확도를 측정하였다. 첫 번째 Healthy apple의 Test data에 대한 실험 결과는 4방향 모두에서 96% 이상의 분류 정확도를 보였으며, 두 번째 Damaged apple의 Test data에 대한 실험 결과는 특정 방향에서 낮은 분류 정확도를 보였으나 본 논문에서 설계한 품질 분류알고리즘을 통해 정확한 분류 값을 도출하였다. 세 번째 Diseased apple의 Test data에 대한 실험 결과도 앞선 실험과 마찬가지로 4방향에서 정확도가 모두 일정하지 않았기 때문에 품질 분류 알고리즘을 통해 정확한 분류 값을 도출하였고, 마지막 실험은 모든 방향에서 97% 이상의 분류 정확도를 보였다. 이를 통해 기존 영상처리식 선별기에 사용되는 고가의 CCD 카메라가 아닌 스마트폰 카메라와 같은 비교적 저가의 카메라를 통한 사과 이미지만으로도 높은 정확도의 과일 선별기를 구축할 수 있는 가능성을 확인할 수 있었다.",
베이즈 딥러닝을 활용한 한국어 음성인식,서울대학교 논문은 저작권에 의해 보호받습니다.,"해당 논문에서는 End-to-End 딥러닝을 활용하여 한국어 음성인식 모형을 구현하였다. End-to-End 딥러닝 중에서도 특히 CTC, Attention 방법을 활용하였으며 각 인코더와 디코더는 CNN, RNN을 기반으로 하였다. 음성 데이터는 우리말샘 온라인 사전과 한국어 낭독체로부터 수집하여 MFCC 변환하였다. 인코더의 입력값으로 한국어 초중종성을 분리하여 모형에 활용하였으며 디코딩하는 과정에서 유한 오토마타와 빔서치를 결합한 알고리즘을 통해 다시 초중종성 순서에 맞게 결합하였다. 실험은 네가지로 진행하였다. 먼저 노이즈 데이터에 대해 어떤 모형이 민감도가 낮은지 알아보았고 Attention 모형에서 인코더와 디코더의 layer 수에 따라 성능이 어떤지 확인해보았다. 또한 변분 베이즈 방식을 활용하여 음성인식에 적용해보아 기존의 방식과 비교하였다. 최종적으로 추가적인 언어모델을 적용했을 때 각 perplexity를 확인해보았다.

In this paper, we propose an end-to-end deep learning model combining Bayesian neural network with Korean speech recognition.
In the past, Korean speech recognition was a complicated task due to the excessive parameters of many intermediate steps and needs for Korean expertise knowledge.
Fortunately, Korean speech recognition becomes manageable with the aid of recent breakthroughs in ""End-to-end"" model. The end-to-end model decodes MFCC directly as text without any intermediate processes.","#Bayesian Deep learning, #Finite automata, #CTC, #Attention, #Beam search"
Deep Learning based Channel Adaptive Transmission in Vehicular Environments : 차량 통신 환경에서 딥러닝 기반의 채널 적응형 전송 기법,2019,"스마트 자동차, 지능형 교통 시스템, 자율주행차 등에서 차량통신의 중요성은 매우 크다. 특히 안전성 확보에 있어서 기존 센서 기반의 상황인지시스템의 목표가 최대한 인간의 운전 능력에 가까운 성능을 발휘하는 것이라면, 차량통신을 적용함으로써 인간의 운전 능력으로 인지할 수 없었던 영역을 감지하는 것으로 목표를 확대할 수 있다. 그러나 차량통신, 특히 차량 간 통신은 기존 통신 시스템과는 다른 몇 가지 특징 때문에 지속적이고 안정적인 통신 성능을 확보하기 어렵다. 특징을 요약하면 변화무쌍한 환경과 빠른 이동성이다.
차량 간 통신 환경은 다양하며 역동적으로 바뀐다. 또한 주변 환경에 따라서 채널의 페이딩 영향이 달라지기 때문에 일정 성능을 달성하기 위하여 요구되는 신호 대 잡음비가 달라지게 된다. 최소 요구 신호 대 잡음비가 채널 환경에 의존적이기 때문에 적응형 전송에 의한 성능 향상이 실패할 수도 있다. 예를 들어, 가시 경로가 확보된 도심과 가시 경로가 확보되지 않은 고속도로에서 요구되는 최소 신호 대 잡음비는 전혀 달라진다. 더불어 만약 차량 노드가 주어진 채널 환경에서 적용 가능한 최고의 변조 및 코딩 방식을 알고 있다면, 이를 사용하는 것이 프레임 전송 소요 시간을 줄여주기 때문에 채널 혼잡 비율을 향상 시킬 수 있다. 따라서 본 논문에서는 종단 대 종단 시뮬레이션 프레임워크를 구성하여 채널 환경에 따라 요구되는 신호 대 잡음비를 파악한다. 그러나 일반적으로 채널 환경, 즉 페이딩 영향을 파악하는 것은 채널 사운딩과 같은 특수한 장비를 사용하지 않는 한 어렵다. 이를 해결하기 위하여 본 논문에서는 대규모 실험 결과를 통하여 축적된 채널 추정 결과를 이용하여 딥러닝 방식을 통한 채널 인지를 제안한다. 실험 결과 제안한 딥러닝 기반 채널 인지는 97% 이상의 정확도로 채널 환경을 구분해내는 것을 확인한다.
채널 상태 정보나 수신 신호 세기와 같은 무선 채널의 신뢰성 있는 추정 정보를 활용하는 것은 전송 파라미터의 시간적 적응을 가능하게 하고 결과적으로 차량 통신의 처리량과 전송 효율을 증가시킨다. 그러나 채널 추정 결과는 일반적으로 칩셋에서 제공해주지 않기 때문에 이를 수집하는 것은 상당히 까다롭다. 본 논문에서는 차량 통신의 신뢰성 있는 채널 추정 결과를 수집하고 분석할 수 있는 시스템을 구축한다. IEEE 802.11p 프레임의 IQ 샘플을 수집할 수 있는 실측 환경 구성을 시작으로 IQ 샘플으로부터 채널 상태 정보를 추출하는 알고리즘을 구현하여 다양한 실제 환경에서 실험한다. 반면에, 차량 간 통신에서는 차량의 빠른 이동성으로 인하여 채널 상태 정보가 쉽게 만료되는 문제점이 있다. 만료된 채널 상태 정보를 기준으로 통신 파라미터를 조정하게 되면 심각한 통신 성능 열화가 발생할 수 있다. 이러한 문제점을 극복하기 위하여 본 논문에서는 미래의 채널 상태 정보와 수신 신호 레벨을 예측하기 위하여 딥러닝을 활용한 채널 예측 기법을 제안한다. 실측 데이터 기반 성능 평가 결과는 제안한 채널 예측 기법이 가장 최근 수신된 채널 정보와 비교하였을 때 제곱근오차 관점에서 약 15%에서 25% 가량의 성능 향상이 있다는 것을 확인하며, 차량 통신의 예측 기반 적응 전송의 가능성을 제공한다.
결과적으로, 채널 인지와 채널 예측 두 가지 아이디어를 결합하여 본 논문에서는 채널 적응형 전송 기법(CAT, Channel Adaptive Transmission)을 설계한다. CAT의 목적은 QoS (Quality-of-Service) 요구사항을 만족하는 조건에서 높은 전송률을 선택하는 것이다. 따라서 CAT는 열악한 채널에서는 환경을 인지하여 패킷 사이즈를 줄여서 전송함으로써 강인한 링크를 제공할 수 있고, 원활한 채널에서는 전송률을 증가시켜 전송함으로써 효율적인 링크를 생성할 수 있다. CAT의 성능 평가는 시뮬레이션 및 실측 데이터 기반으로 수행되며 기존 적응형 비콘 전송 기법과 비교하여 CAT의 우수성을 입증한다.

The importance of vehicular communications is significant in a smart car, an intelligent transportation system, an autonomous vehicle, etc. For the safety, the objective of a conventional sensor based context recognition system is to mimic the human''s driving capability whereas that objective can be extended to outperform the human by applying vehicular communications. However vehicular communications, especially vehicle-to-vehicle (V2V) communications may not guarantee a robust and stable performance due to several distinct characteristics which are different from other communications system: dynamic environments and fast mobility.
Vehicular communication environments are dynamically changing. The required signal-to-noise ratio (SNR) to achieve the specific performance changes because channel fading effects vary according to the environment. Improvements of the performance by adaptive transmission can be failed since the minimum SNR requirement is dependent on the channel environments. For instance, the minimum SNR requirements for line-of-sight (LOS) in urban areas and non-line-of-sight (NLOS) in highway are totally different for same transmission parameters. Moreover, if the vehicle node is aware of the highest modulation and coding scheme (MCS) it can apply for transmission in the corresponding channel environment, using higher MCS can also help to reduce channel congestion since it helps to consume less time to send a frame. Thus we configure the end-to-end simulation framework and analyze the variable minimum SNR requirements according to channel environments. However understanding fading effects in channel environments is difficult unless utilizing the special equipment such as channel sounder. In this thesis we propose a deep learning based channel awareness by using the channel estimation results from our extensive simulations. We confirm that our deep learning based channel awareness is able to classify the channel environments with an accuracy of over 97%.
On the other hand, access to reliable estimates of the wireless channel, such as the channel state information (CSI) and the received signal strength would open opportunities for timely adaptation of transmission parameters and consequently increased throughput and transmission efficiency in vehicular communications. To design the adaptive transmission schemes, it is important to understand the realistic channel properties, especially in vehicular environments where the mobility of communication devices causes the rapid channel variation. However, getting CSI estimates is challenging due to the lack of support for obtaining CSI from the chipset. In this thesis, we present our efforts towards enabling reliable, up-to-date channel estimates in vehicular communications. We begin by designing and conducting a measurement campaign where we collect IQ (in-phase and quadrature) samples of the IEEE 802.11p transmission and implement CSI extraction algorithms to obtain and analyze wireless channel estimates from various real-world environments. We then propose a deep learning-based channel prediction for predicting future CSI and received signal levels. Trace-based evaluation demonstrates that our prediction approach improves the future power level estimate by 15% to 25% in terms of the root-mean-square-error (RMSE) compared to the latest known channel properties, thus, providing a sound basis for future efforts in anticipatory vehicular communication transmission adaptation.
Consequently, we design the channel adaptive transmission (CAT) algorithm by combining the idea of channel awareness and channel prediction. The aim of CAT is to utilize the data rate as high as possible while the quality-of-service (QoS) requirement is satisfied. Therefore CAT is able to provide more robust link in poor channel condition by reducing the packet size while the more efficient link is generated in acceptable channel condition by increasing the data rate. We evaluate the performance of CAT based on both simulation and measurement and verify the superiority of CAT compared to the conventional adaptive beacon transmission schemes.","#Vehicular Communications, #Deep Learning, #Wireless Channels"
딥러닝과 무선 통신 기술을 이용한 IoT 공장 물자 관리 시스템 설계에 관한 연구,2019,"본 논문은 딥러닝과 무선 통신 기술을 이용한 IoT 공장 물자 관리 시스템을 제안한
다. 제안하는 시스템은 설치 및 유지보수가 간편하며 기존의 스마트 팩토리 시스템에
비해 비용 소모가 적도록 설계하였다. 제안하는 시스템은 물품의 생산 공정부터 창고에
적재되는 과정 전반에 적용되는 스마트 팩토리 시스템으로, 생산되는 물품을 컴퓨터 비
전 기술을 이용해 종류 및 불량 여부를 판별하고, 해당 물품을 분류하여 적절한 위치로
운반하는 물품 검출 및 분류 장치의 하드웨어 및 소프트웨어와, 무선 통신 기술에 기반
한 측량 기술을 적용한 공장 내 물자 위치 추정 시스템의 하드웨어 및 소프트웨어를 포
함한다. 물품의 종류 및 불량 여부를 판별하기 위한 딥러닝에 기반한 실시간 영상처리
기술로 Darknet-19을 이용하는 YOLOv2 프레임워크를 사용하고, 그 판별 결과를 이용
해 물리적으로 물체를 분류하는 시스템에 대해 설명한다. 그리고 이러한 시스템의 실제
프로토타입을 구현하여 이를 검증한다. 테스트 이미지셋에 대하여 약 93.3%의 검출율
을 보인 해당 시스템에, 실시간 영상에서의 분류를 위한 알고리즘을 추가하여 100%에
가까운 검출율을 확인하였다. 또한 공장 내 물자 위치 추정 시스템은 기존 측량기술인
삼변측량의 오차를 줄이기 위하여 칼만 필터와 대각측량 기법을 제안하였고, 그 결과
오차를 평균 45.6% 줄일 수 있었다. 이를 기반으로 실제 공장 내에서 IoT 송수신 모듈
을 이용하여 시스템의 프로토타입과 실시간 모니터링 시스템을 구현하고, 송신 모듈의
위치를 추적하는 실험을 통해 해당 시스템의 실효성을 검증하였다. 시스템의 프로토타
입 구현 과정 중 발견한 개선 가능성에 대하여 향후 연구를 통해 개선한다면 보다 정밀
한 시스템을 설계할 수 있을 것으로 전망된다.",
딥러닝 기법을 활용한 KOSPI200 콜옵션 가치 예측,2019,"본 연구는 KOSPI200 콜옵션의 가치를 산출하는 데 있어서 공시된 정보만을 사용하는 데에 중점을 두었다. 일반적으로 콜옵션의 가치를 계산하기 위해 Black모형을 사용하며, 이는 기초자산의 현물가, 옵션의 행사가, 만기까지의 남은 기간, 무위험이자율, 변동성, 배당수익률(혹은 배당수익)을 변수로 취한다. KOSPI200의 경우 무배당이므로 배당에 대한 부분은 배제한다. 그러나 변동성의 경우 공시되지 않으며, 변동성을 계산하는 방법이 다양하여 정확한 값이 주어지지 않는다. (실제 한국거래소에서 제공하는 내재변동성은 전일 기초자산의 종가 대비 변화율에 가깝다)
따라서 본 연구는 세 가지 방법으로 콜옵션의 가치를 추정하였다. 첫째, DNN이 변동성을 제외한 나머지 다섯 가지 값을 학습하여 콜옵션의 가치를 추측하는 것이다. 둘째, LSTM 모형으로 내재변동성을 추정한 다음 공시된 정보를 사용하여 콜옵션의 가치를 계산하는 것이다. 셋째, GARCH모형으로 변동성을 추정한 다음 두 번째 방법과 마찬가지로 콜옵션의 가치를 계산하는 것이다. 실험을 반복한 결과, 등가격 상태의 옵션가를 계산함에 있어서 세 가지 방법 모두 높은 정확도를 보였다. 또한, Deep Learning기법을 사용한다면 등가격 옵션의 가치를 계산하기 위해 필요한 데이터가 Black모형에 비해 적으며 Black모형을 대체할 수 있다는 결론을 내릴 수 있다.

This study concentrates on using only posted information for calculating the value of KOSPI200 call option. Generally, Black model is used for calculating the value of call option and it needs present value of underlying asset, strike price, maturity, interest rate, volatility and dividend(rate). Because KOSPI200 doen’t have dividend, we don’t need to consider the dividend. But the volatility is not posted and there is no accurate volatility because there are so many ways of calculating volatility. (The value which KRX provides is similar to ratio between yesterday and today’s close volume)
So, we calculate the value of call option with three ways. First way is using DNN which takes five variables except volatility for training. Second, we predict implied volatility with LSTM model and calculate call option’s value with posted information and implied volatility that LSTM model predicted. Third, we predict volatility with GARCH model and do same process as second case.
After repeating research, we could get high precision for calculating value of call option which is at the money. And, Deep learning technique needs less input data than Black model. we could get conclusion that Deep learning can be used in place of Black model.","#딥러닝, #콜옵션, #가치평가, #가치예측, #머신러닝, #DNN, #LSTM, #GARCH, #Black모형, #금융수학"
딥러닝 기반 공유저작물 검색엔진을 위한 통합 권리관리정보 및 이미지 비교검색기법에 대한 고찰,2019,"최근 디지털 콘텐츠 기술의 발전으로 저작권에 관한 관심과 이미지저작물에 대한 수요가 증가하고 있다. 많은 웹사이트를 통해 10억 개가 넘는 공유저작물을 서비스하고 있지만, 최신 정보로 현행화되지 못한 권리관리정보로 인해 사용자들이 저작권 이슈에 노출되어 있다. 이러한 문제를 해결하기 위해 ‘딥러닝 기반 공유저작물 검색엔진’ 연구가 선행되고 있다. 본 논문에서는 딥러닝 기반 공유저작물 검색엔진 시스템에서 권리관리정보 현행화를 위해 공유저작물 사이트별 상이한 권리관리정보 표현체계를 통합하여 데이터베이스로 관리하는 방안을 스키마로 정의하여 제안한다. 또한, 검색엔진 사용자에게 올바른 정보를 제공하기 위해 테스트 환경을 5회 변경하여 이미지 비교검색 기법 성능평가를 수행한다. 성능평가 결과 hash를 이용한 기법은 처리 속도와 원본 이미지의 매칭률이 매우 높게 나타났으며, 변경된 이미지 인식에 대한 강인성은 부족하다. 특징점을 이용한 기법은 처리 속도는 느리지만, 원본 이미지 인식률과 강인성은 높게 산출됐다. 본 논문에서 제안하는 권리관리정보 통합 방안을 기존 시스템에 적용하면 효율적인 관리가 가능할 것이다. 또한, 이미지 비교검색 기법으로 사용자에게 원본 이미지와 올바른 권리관리정보 제공이 가능할 것이다.

Recently, with the development of digital contents technology, interest in copyright and demand for public domain are increasing. While many Web sites serve more than a billion public domain, users are exposed to copyright issues because of the non-up-to-date rights management information. In order to solve this problem, ''Deep Learning based public domain search engine'' has been preceded. In this paper, we propose a scheme to integrate different rights management information representation systems for shared work sites and manage them in a database as a schema in order to update rights management information in a shared work search engine system based on deep learning. In addition, the performance evaluation of the image comparison search technique is performed by changing the test environment five times in order to provide the correct information to the search engine user. As a result of the performance evaluation, the processing speed and the matching rate of the original image are very high in the technique using the hash, the robustness to changed image recognition was insufficient. The technique using the feature points has a slow processing speed, but the original image recognition rate and robustness are high. Effective management will be possible if the integrated rights management information proposed in this paper is applied to existing systems. In addition, image comparison search techniques will enable users to provide the correct rights management information with the original images.",
역 절차적 모델링을 위한 딥러닝 기반 건물 전면 창문 요소 추정,2019,"3차원 도시 모델은 다양한 분야에서 사용된다. 가까이 접할 수 있는 영화, 게임 분야, 3차원 지도, 도시 건축 설계 분야를 예로 들 수 있다. 도시 모델은 사용되는 분야마다 다른 방법으로 렌더링 되지만 실제 환경과 유사한 3차원 도시 모델의 생성은 가상 현실에서 사용자의 존재감(Sense of Presence)을 높일 수 있다.

현재 사용되고 있는 3차원 도시 모델 생성 방법의 경우 3차원 레이저 스캐너와 LiDAR와 같은 센서를 사용하여 모델링 하는 방법과 2차원 건물 전면 이미지로부터 모델링하는 역 절차적 모델링 방법을 사용한다. 전자는 건물 모델을 구성할 때 방해 요소(행인, 가로수, 차, 간판)로부터 발생하는 폐색과 하드웨어의 성능에 따라 모델이 잘못 생성되는 경우가 발생한다. 후자는 전자와 다르게 높은 수준의 건물 모델을 건물 전면 문법을 정의하여 다양한 모양의 도시 모델을 생성할 수 있으나 전문가와 수작업에 대한 많은 시간을 필요로 한다.

3차원 도시 모델링에 있어 수작업은 다양한 모양의 모델을 생성하는데 한계가 있다. 이를 해결하기 위해 수작업을 줄일 수 있는 건물 전면을 자동으로 분류하기 위한 시도가 진행되고 있다. 본 논문의 선행 연구라 할 수 있는 딥 러닝 기반 2차원 건물 전면 분류 방법은 자동으로 구성 요소를 분류하며 높은 정확도를 보여준다. 하지만 이 방법은 탐지되지 않은 영역이 존재할 수 있으며 구성 요소가 이루는 영역 위치를 알 수 없고 픽셀 단위로 라벨링하는 방법이기 때문에 역 절차적 모델링을 하기 위한 구조로 알맞지 않다.

본 논문에서는 역 절차적 모델링을 위한 분할 규칙을 정의하기 위해 먼저 딥 러닝을 사용하여 건물 전면에서 창문을 분류한 후 정확도 향상을 위해 건물의 특징을 이용해 유사도 기반 탐지를 진행한다. 탐지된 유효 영역의 특징을 설정하여 분할 규칙을 정의한 후 3차원 건물 모델을 생성한다.

창문 추정 결과 선행 연구 보다 정확도가 더 향상되었음을 확인할 수 있으며 역 절차적 모델링의 수작업을 해결하기위해 생성된 3차원 건물 전면 분할 규칙 생성 시간은 기존연구와 비교하여 높은 효율성을 보여준다. 결과적으로 3차원 도시 모델의 전반적인 품질 향상과 모델링 속도를 개선할 수 있다.

3D city models are used in various fields. Examples include movies, gaming, 3D maps, and urban architecture design. Urban models are rendered in different ways in which they are used. but creating 3D urban model similar to the actual environment can increase the user''s sense of presence in virtual reality.

For the currently used 3D urban model generation methods, use sensors such as 3D laser scanners and LiDAR to model and inverse procedural modeling to model from the 2D building front image. When building models are constructed, they are often created incorrectly depending on the color of the waste and the performance of the hardware resulting from obstacles (walkers, trees, cars, signboards). The latter, unlike the former, allows for the creation of diverse urban models by defining high-level building models with building front grammar, but requires a great deal of time for experts and hands-on work.

In 3D urban modeling, manual tasks are limited in producing models of different shapes. An attempt is being made to automatically classify the front of the building, which can reduce manual tasks. The Deep-Learning based 2D building-front classification method, which is known as the preceding study in this paper, automatically classifies components and shows high accuracy. However, this method is not suitable for retro-procedural modeling because undetected areas may exist and the location of the area to which the component is made is unknown and labeled on a pixel-by-pixel basis.

In this paper, to define the partitioning rules for inverse procedural modeling, we first use deep running to classify windows at the front of the building, and then use building features to conduct similarity-based detection for improved accuracy. Set the characteristics of the detected effective area to define the segmentation rules and create a 3D building model.

Window estimation can confirm that accuracy is better than the preceding study and the time to create a 3D building front split rule created to resolve manual tasks of inverse procedural modeling shows greater efficiency compared to existing studies. As a result, overall quality improvement and speed of modeling of 3D city models can be improved.","#Image Processing, #Computer Graphics, #Deep-Learning, #Inverse-Procedural-Modeling"
배경음 및 잡음에 강인한 변형 MFCC 및 딥러닝 기반 위험음향 감지 시스템에 관한 연구,2019,"최근 센서와 인공지능 기술을 융합하여 하드웨어를 제어하는 기술이 다방면에서 시도되고 있다. 본 논문은 스마트 홈 연구의 일환으로 가정 내의 위험음향 감지시스템의 성능 향상을 연구목적으로 하였다. MFCC (Mel-Frequecy Cepstrum Coefficient)를 적용한 딥러닝 분류기와 AGMM (Adaptive Gaussian Mixture Model)으로 구성된 기존 음향인식 시스템은 데이터베이스의 이중구성, 배경음 인식의 모호성, 고주파 음향에 대한 낮은 인식률의 문제점을 가지고 있다. 이를 해결하기 위해 본 논문에서는 Wiener필터와 변형된 멜-필터뱅크를 적용한 새로운 MFCC 알고리즘을 제안한다. 새로운 MFCC 알고리즘은 Wiener필터를 통해 노이즈를 제거하고, 삼각필터를 고주파에 밀집시킨 변형된 멜-필터뱅크를 적용한 특징벡터를 통해 배경음과 고주파 음향의 인식률을 높인다.
변형된 멜-필터뱅크를 통한 특징벡터의 성능을 증명하기 위해 딥러닝 분류기인 DNN (Deep Neural Network)과 LSTM (Long Short-Term Memory)을 이용하여 학습정확도와 인식률 측정 실험을 하였다. 실험결과에 의하면 제안한 변형된 멜-필터뱅크의 특징벡터의 학습정확도는 기존 MFCC의 특징벡터보다 DNN에서 1%, LSTM에서 3.49% 만큼 높은 학습정확도를 보였으며 인식률은 DNN에서 6.67%, LSTM에서 10%만큼 높은 인식률을 보였다. 또한, 제안한 위험음향 감지시스템과 기존 음향인식 시스템의 성능 비교 실험에서 제안한 위험음향 감지시스템이 배경음은 5% 만큼, 위험음향은 13.33%만큼 높은 인식률을 보임을 확인하였다.

In the recent years, various attempts to control hardware through convergence of sensors and A.I.(Artificial Intelligence) have been made. The purpose of this thesis is to improve the performance of the hazardous sound detection system in the house. The existing sound recognition system, which composed of Deep-learning classifier and AGMM (Adaptive Gaussian Mixture Model) using MFCC (Mel-Frequency Cepstrum Coefficient), has three problems: the double composition of the database, the ambiguity of the recognition of back-ground audio, and the low recognition rate of high-frequency audio. To solve these problems, this thesis proposes a new MFCC Algorithm using Wiener-filter and modified Mel-Filterbank.
The new MFCC Algorithm removes noise from the Wiener-filter and increases the recognition rate of high-frequency hazardous audio from feature-vector from modified Mel-Filterbank which concentrates triangle-filters at high frequencies.
To demonstrate the performance of feature-vector from modified MFCC, this thesis includes experiments, which measures the training accuracy and recognition rate of DNN and LSTM. The results showed higher training accuracy of 1% at DNN and 3.49% at LSTM, and higher recognition rate of 6.67% at DNN and 10% at LSTM.
Also, the proposed Hazardous sound detection system showed higher recognition rate of 5% at back-ground sound and 13.33% at Hazardous sound.",
딥러닝 기반 도시장면의 의미론적 분할,2019,"인공지능의 발전을 통해 운전자의 개입이 필요하지 않고 스스로 판단하여 움직이는 자율주행 기술이 성숙기에 다다르고 있다. 자율주행 기술은 제한적 조건에서 완전히 마음을 놓는 완전 자율 주행을 목표로 하고 있다. 자율주행이 이루어지기 위해서는 인지, 판단, 제어하는 세가지 핵심 기술이 필요하며 인지는 자율주행 기술 중 선행되어야 하는 중요한 기술이다. 또한, 딥러닝을 활용한 의미론적 분할은 이미지에서 픽셀 단위로 어떤 클래스에 속해 있는지 분류하는 기술로서 인지기술을 한층 더 성숙 시킬 수 있는 기술이다.
본 논문에서는 실제 자율주행에 적용시키기 위한 효율적인 연산과 정확도가 높은 의미론적 분할 네트워크 모델인 efficient-residual-inception network (ERINet) 를 개발하였다. 이 네트워크 모델은 크게 딥러닝 모델 전체구조와 레이어 구조로 나누어 성능을 향상 시켰다. 모델의 전체골격 최적화를 시키기 위해 여섯 가지 최신 딥러닝 네트워크 모델을 응용하여 개발 하였다. 첫 번째는 fully convolutional networks (FCN) 으로 합성곱신경망의 마지막 부분인 fully connected layer를 1×1 합성곱으로 위치정보를 유지한 방법을 디코더에 넣어주는 방법을 적용하였다. 두 번째는 실제 자율주행 데이터셋인 Cityscapes를 학습 데이터셋으로 두고 높은 정확도와 효율적인 연산 네트워크 모델을 제안한 efficient residual factorized convnet (ERFNet) 의 디코더를 변형하여 개발하였다. 세 번째는 레이어의 깊이, 너비, 및 필터 크기 최적화를 시도한 wide residual inception networks (WRINet) 레이어 구조를 응용하였다. 네 번째는 특징에 대한 연산량 감소를 위해서 Inception의 1×1 합성곱을 적용하였다. 다섯 번째는 깊은 신경망을 최적화 할 수 있는 ResNet을 적용하여 네트워크 모델을 설계 하였다. 여섯 번째는 Efficient Neural Networks (ENet) 네트워크의 다운샘플링의 구조를 벤치마킹 하였다.
그리고, 레이어 구조의 성능향상을 위해 효율적인 연산과 이미지 픽셀 특징을 깊게 추출할 수 있는 non-bottleneck with 1D and 2D 레이어와 Wide non-bottleneck with 1D and 2D 레이어를 개발하였다. 이를 통해서 레이어는 깊지만 정확도가 높아질 수 있었다.
실험결과 본 논문의 제안 기법은 기존에 Cityscapes의 IoU, iIoU class와 IoU, iIoU category 성능지표에서 정확도와 효율적인 연산속도 측면에서 최고의 모델이라 할 수 있는 ERFNet 모델 보다 본 제안 방법이 좋은 성능을 나타내었다. 특히, 사람과 차량을 카테고리로 나눈 성능지표에서 높은 정확도를 나타내었을 뿐만 아니라 19개의 개별 클래스 성능지표에서도 대부분 높은 정확도를 나타내었다.
특히, 연산속도 측면에서는 고화질의 1024×512 이미지에서 Titan X GPU를 네트워크 모델에 적용하여 초당 43 프레임의 속도를 나타내었다. 이를 통해 제안된 네트워크 모델의 효율적인 연산 속도와 정확도의 결과물은 실제 자율주행 상용화에 바로 적용될 수 있는 기술임을 보여주고 있다.",
딥러닝 및 전이학습을 이용한 표면결함 분류에 관한 연구,2019,"본 논문에서는 철강후판 표면검사를 위해 이산 웨이블릿 변환을 이용하여 영상의 대비와 특징을 부각시키고 SVM(Support Vector Machine), CNN(Convolution Neural Network), 사전학습 모델 등을 이용한 분류기의 성능에 대해 연구하였다.
선행연구에서 구성한 조명계로 획득한 영상의 경우 철강후판 표면의 저대비, 불균일, 무특징 특성에 의해 결함영역과 비결함영역의 대비가 떨어져 특징을 추출하기 어렵다. 영상의 특성을 개선하기 위하여 이산 웨이블릿 변환 기반의 합성영상을 모델링하였다. 이 영상에 HOG(Histogram of Oriented Gradient), HOLA(Higher Order Local Autocorrelation)를 사용하여 모서리 기반의 특징과 면적, 둘레 등의 기하학적 특징을 이용하여 특징데이터를 추출하였다.
추출된 특징을 이용하여 결함 영상의 분류를 진행하기 위해 SVM, CNN를 이용하여 분류기를 구성하였다. 또한 사전에 학습된 모델을 이용하여 전이학습 신경망(Transfer-learning Neural Network)으로 분류 실험을 진행하였다. 이들 중 AlexNet기반의 전이학습 신경망을 설계한 결과 160초 미만의 학습시간으로 99.43%의 우수한 분류 성능을 보였다. 제안된 분류기는 저대비, 불균일, 무특징을 가지는 표면 영상에 대한 뛰어난 분류성능을 보였다. 이를 이용하여 스마트 팩토리 및 자율주행과 같은 4차산업혁명에 이용되는 주요 요소에 기여를 할 수 있을 것으로 사료된다.",
딥러닝기법을 활용한 학습성과 분석 및 예측 시스템,2019,"세계 에듀테크 기업의 성장세에 비해 우리나라 에듀테크 시장은 본격 성장기를 맞지 못했다. 핀테크, O2O시장 등과 비교했을 때는 아직은 미미한 수준이다. 교육시장이 에듀테크 분야로 변화하는 시대적 흐름에 발맞춰 우리나라 교육현장에도 에듀테크 도입이 필요하다.
본 연구의 에서는 교육관리시스템(LMS)에서의 학습활동로그를 바탕으로 학습성과 영향도를 분석하고 이를 예측하기 위한 모델을 개발하는데 있다.
연구방법은 먼저 상관분석을 사용하여 유의미한 변수를 선정하였으며, 딥러닝을 사용하여 예측 모델을 생성하였다. 모델 생성 결과 테스트 데이터 셋에 대해 약 84%의 정확도로 학습성과의 유의미한 예측할 수 있었다.
본 연구를 통하여 온라인 교육환경에서 빅데이터와 인공지능을 적용할 수 있는 새로운 관점을 제공할 것으로 기대한다.",
딥러닝을 이용한 크로스 모달 기반 소셜 미디어 학습,2019,"최근 컴퓨터 비전의 발전에서 큰 데이터 집합은 많은 기여를 했다. 예를 들어 ImageNet과 같은 이미지를 위한 대규모 데이터 세트는 이미지 연구에 있어서 큰 영향을 끼친다. 또한, 텍스트 연구에 있어 GoogleNews 데이터 세트 같은 대규모 공개 데이터가 많은 도움이 되는 추세다.
하지만 한국어를 위한 공개적인 대규모 데이터 세트는 존재 하지 않는다. 또한, 교차 양식 검색을 위한 한국어 데이터 세트는 더욱 존재하지 않는다. 따라서 새로운 데이터 세트에 대한 구축이 필요했고, 이에 소셜 네트워크 중 하나인 인스타그램 게시물을 수집했다.
인스타그램 사용자들은 소셜 네트워크 서비스 안에서 이미지, 텍스트, 비디오 등 다양한 데이터 양식을 공유한다. 이러한 게시물은 다중 양식을 다루는 교차 양식 검색의 데이터 세트로 적합하다.
이미지-텍스트 쌍을 얻기 위해서 인스타그램의 게시물을 검색 시스템을 통하여 수집 후, 이미지 데이터와 텍스트 데이터로 나누었다. 수집된 텍스트 안에는 사용자의 이미지와 관련된 주관적인 견해가 들어있으며, 게시물 검색이나 관련 게시물을 사이를 연결해주는 해시태그도 존재한다.
하지만 데이터 수집에서 과정에서 불필요한 게시물들이 존재했다. 따라서 이를 처리하는 과정이 필요했다. 먼저 광고 게시물을 올리는 계정은 블랙리스트로 만들고, 텍스트가 존재 하지 않는 게시물을 제외한 뒤, 적합하지 않은 게시물에 대해 이미지와 텍스트 기반으로 필터링을 한다.
이후 필터링을 마치고 데이터 수집이 끝난 이미지-텍스트 쌍의 특징을 추출한다. 이와 관련해 이미지에 대해서는 ImageNet으로 학습 된 VGG-19를 통해 특징을, 텍스트에 대해서는 형태소 분석기를 통해 형태소를 추출했다. 그리고 위키피디아-한국어, 네이버 영화 리뷰, 인스타그램 텍스트 데이터로 학습된 Word2Vec를 가지고 추출된 형태소를 기반으로 임베딩을 한다. 마지막으로 WordCNN을 이용하여 특징을 추출한다.
결과적으로 이 데이터 세트와 추출된 특징을 통해 교차 양식 검색에서 영어가 아닌 한국어로 학습이 충분히 가능한 데이터 세트가 된다. 이에 전통적인 교차 양식 검색과 DNN(Deep Neural Network) 기반의 방법을 포함한 여러 알고리즘을 통하여 많은 실험을 한다.
실험 결과에서 MCSM 알고리즘의 성능은 가장 뛰어났다. 이에 MCSM 알고리즘의 세부 실험과 알고리즘에 대한 검증 결과를 추가적으로 보여줬다. 이에 인스타그램 데이터가 교차 양식 검색에서 유용하게 사용될 수 있음을 보여주었다.

In the recent development of computer vision, large datasets have made a lot of contributions. For example, large data sets for images such as ImageNet have a major impact on image research.
A large amount of open data, such as the GoogleNews dataset, is useful for text research. However, there is no open large data set for Korean text. Also, there is no Korean data set for cross-modal retrieval.
So we needed to build a new set of data, and we collected posts in the social network, such as Instagram. Instagram users share various forms of data such as images, text, and video within social network services. These posts are suitable as a data set for cross-modal retrieval.
To obtain the image-text pair, the post of the Instagram was collected through a search system in Instagram and then divided into image data and text data. Within the collected text, the user has a subjective view of the image, and there are hash tags that link between post searches and related posts.
But there were unnecessary posts in the process of data collection. So we blacklisted the accounts that post the ads, exclude posts that do not contain text, and filter images and text based on inappropriate posts.
After that, the filtering is completed and the feature of data set is extracted. For images, the features are extracted in VGG-19 learned with ImageNet. For text, morphemes are extracted through a morpheme analyzer. And then text is embedding through Word2Vec, which is learned from Wikipedia - Korean, Naver movie review, and Instagram text data. Finally, features are extracted using WordCNN.
As a result, this dataset and extracted features provide a data set that is sufficiently learnable in non-English Korean in cross-modal retrieval. Many experiments are conducted through various algorithms including traditional cross-modal retrieval and DNN (Deep Neural Network) based methods.
The performance of the MCSM algorithm is the best in the experimental results. In addition, we have shown detailed experiments and verification results of MCSM algorithm. Thus, it is shown that the Instagram data can be useful in cross-modal retrieval.","#교차 양식 검색, #소셜 네트워크 서비스, #데이터 세트, #딥러닝, #Cross-modal Retrieval, #Social Network Service, #Dataset, #Deep Learning"
딥러닝 기반 컨볼루션 신경망을 이용한 실시간 사용자 얼굴 인식 시스템,2019,"In a face recognition system, a person''s face has unique information about each person, and the face recognition system uses this information to recognize it. Face recognition systems are less sensitive and easier to use, but they are sensitive to brightness, which changes the face''s characteristics when the angle changes. In this paper, we propose a real - time user recognition system using a neural network based on in - depth learning to realize a model with no performance degradation even with angular change. If the recognition rate is greater than 90%, users can access the data in the database. The recognition rate is more recognizable than the existing system.","#얼굴 인식, #딥러닝, #실시간, #카메라, #CNN, #트레킹"
딥러닝 기반 비접촉식 위조 지문 검출 연구,2019,"최근 보안과 편리성을 위해서 바이오 인식 기술을 활용하는 사례가 나날이늘어나고 있다. 그 중 핀테크(Fin-tech)의 사용이 급증함에 따라서 지문의 활용을 통한 사용자의 인식이 증가하고 있다. 지문은 가장 전통적인 생체 인식방법으로 간편하고 거부감이 없어 대중적으로 활용되어온 방법이다. 그러나그 중 센서를 이용해 접촉식으로 획득한 지문은 사용자의 지문의 건조함이나습함에 따라서 영상의 품질이 달라지고, 접촉 압력에 따른 비일관성을 지닐수 있다. 게다가 한가지의 접촉식 센서에 다양한 사람이 이용하기에 잔존 지문의 문제와 위생적인 문제도 발생하게 된다. 그러나 스마트폰 카메라(삼성전자의 갤럭시 S8)를 활용하여 비접촉식으로 획득한 지문 영상은 이러한 단점이사라지고, 별도의 센서가 필요하지 않다.따라서 이러한 관심과 함께 본 논문에서는 비접촉식으로 획득한 지문들을통해 위조 지문을 검출하는 방법을 제안한다. 검출 방법은 최근에 컴퓨터 비전 분야에서 가장 화제가 되고, 좋은 성능을 가지고 있는 딥러닝(Deep-learning) 방식인 합성곱 신경망((Convolution Neural Network, CNN)을 활용하여 지문 이미지의 위조여부를 검출하였다.합성곱 신경망은 영상처리에 특화된 신경망으로서 영상의 분류와 검출에 가장 뛰어난 성능을 나타낸다. 그 중 본 논문에서는 마이크로소프트 팀이 2015년에 개발하여 이미지넷 인식 대회에서 우승을 거둔 합성곱 신경망인 ResNet을 기본 네트워크로 하되 실험에 맞는 방식으로 많은 수정을 하였다.

지금까지는 비접촉식 지문 연구의 사례가 매우 적어 비교할 수 있는 연구가 없었고, 접촉식으로 획득한 지문영상을 합성곱 신경망을 통해 분류하는 연구가 중점적으로 수행되어 왔다. 이에 따라 과거의 접촉식 지문을 활용한 연구와의 비교를 통해 제안할 알고리즘을 설명하였다.따라서 본 논문은 스마트폰 카메라를 통해 자체적으로 얻은 비접촉식 지문영상을 패치로 분할하여 이미지 도메인의 영상을 확보하고, 지문 영상을 고속푸리에 변환을 통해 얻은 주파수 도메인의 크기 스펙트럼 이미지를 추출하여또 하나의 입력영상으로 이용하였다. 이렇게 얻어진 입력 영상들은 각각 동시에 합성곱 신경망을 통과하게 설계되고 학습되었다. 멀티 인풋 레이어 방법을가진 네트워크는 각각 구성된 많은 레이어들을 지나가게 되고, 추출된 벡터값들은 Concatenate 레이어를 거쳐 한 개의 출력 값으로 합쳐진다. 마지막으로 Fully Connected Layer를 거쳐서 최종적으로는 하나의 출력층을 통해 위조 지문을 판별을 할 수 있도록 구성하였다. 그 결과 99%의 높은 정확도로위조 지문을 분류 할 수 있었다. 연구과정을 통해 비접촉식 지문을 멀티 인풋딥러닝 모델을 이용해 위조 여부를 판별하는 것은 본 논문이 제안한 새로운딥러닝 모델로서 실험 결과 기존의 다른 네트워크에 비해 성능이 우수함을 확인하였다. 또한 기존의 연구에서 이미지 도메인과 주파수 도메인별로 두 번네트워크를 학습 시켰던 번거로움을 덜면서, 나아가 스마트폰 카메라로 획득할 수 있는 새로운 비접촉식 지문의 위조 검출 연구의 활성화를 기대할 수 있는 장점을 가진다.

Recently, there have been a growing number of cases where biometricrecognition technologies are used for security and convenience. The rapidincrease in the use of Fin-tech has led to a growing awareness of usersthrough the fingerprints. Fingerprints are the most traditional biometricmethod that has been widely used. However, fingerprints obtained bycontact-based sensors may vary in quality of image depending on thedryness or humidity of the user''s fingerprints. There can be aninconsistency of results due to contact pressure. In addition, there will behygienic problems from latent fingerprints due to the fact that variouspeople using a single contact sensor. However, fingerprint images acquiredfrom contactless method using camera in smartphone (SamsungElectronics'' Galaxy S8) resolved all the problems mentioned above withoutrequiring additional sensors.
This paper will propose the method of detecting fake fingerprints usingcontactless fingerprints. One of deep-learning method CNN(ConvolutionNeural Network) which is the most popular topic in the computer visionarea and has good performance ability will detect fake of fingerprintimages.CNN is a neural network specialized in the classification and detection ofimages. In this paper, we use ResNet as basic network which wasdeveloped by Microsoft team in 2015 and won the ImageNet RecognitionCompetition. And we modified ResNet according to our needs inexperiment.Because there have been very few studies on contactless fingerprints sofar, it was hard to find comparable studies to this paper. Therefore, itexplains algorithms through comparison with contact-type fingerprintsreports.So, this paper uses contactless fingerprint images from smartphonecameras into patches to obtain images of the image domain. And thefingerprint images were extracted from the magnitude spectrum image ofthe frequency domain obtained through the Fast Fourier Transform usedas another input image. These input images were designed and trained topass through CNN at the same time. A network with a multi-input layermethod passes through many layers each consisting of, and hence thevector values extracted are combined into one output value through theConcatenate layer. Finally, through the Fullly Connected Layer, fakefingerprints were finally identified through a single output layer. As aresult, fake fingerprints were classified with high accuracy of 99 percent.
The new Deep Learning model proposed by this paper is that thecontactless fingerprints are identified by using a multi-input model. Andthe results of the experiment showed that the performance was better thanthe previous model. It also eliminated the hassle of learning networkstwice by image domain and frequency domain in previous studies.Furthermore, there is an advantage in expecting to vitalize the researchinto contactless fingerprints that can be obtained with smart phonecameras.","#smartphone, #contactless, #fingerprints, #convolution neural network, #CNN, #스마트폰, #비접촉식, #위조지문, #합성곱 신경망, #컨볼루션 뉴럴 네트워크"
스테레오 카메라 영상들과 딥러닝을 이용한 사람 감지 및 구분,2019,"본 논문에서는 스테레오 카메라 영상들을 정합한 이미지를 딥러닝을 이용하여, 사람 감지 및 구분하는 방법을 제안한다. 먼저 컬러 이미지에 깊이 정보를 정합한 RGB-D 형태의 이미지를 생성한다. 컬러 영상과 깊이 영상의 정합을 위해서, 스테레오 카메라 캘리브레이션을 통해 두 영상에 존재하는 사람의 위치 차이를 조정한다. RGB-D 이미지를 Mask RCNN 기법을 사용하여 딥러닝 학습한다. 본 실험에서는 동일한 조건의 RGB 이미지를 딥러닝 학습하였을 때와 비교하여 성능이 우수함을 확인하였다.","#스테레오 카메라 캘리브레이션, #RGB-D, #사람 감지, #Mask RCNN"
딥러닝을 위한 저전력 임베디드 GPGPU 설계,서경대학교 논문은 저작권에 의해 보호받습니다.,"본 논문에서는 저전력이 요구되는 임베디드 환경에서 딥러닝에 적합한 GPGPU(General Purpose GPU)를 설계하였다. Stream Procssor를 16개, Instruction Fetch 16개를 갖는 구조로 총 256개의 thread를 처리할 수 있는 성능으로, 그에 따라 딥러닝을 쉽게 구현할 수 있도록 했다. 명령어마다 우선순위를 가지는 scheduler를 설계했다. 시스템 > 메모리 > 산술 명령어의 우선순위에서 딥러닝에 적합하다는 것을 확인했다. GPGPU의 인터페이스를 AXI, APB로 설계해 SoC에서 IP 재사용을 고려했으며, FPGA 시스템은 PCIe를 사용할 수 있도록 구현했다. 임베디드 환경에서 사용할 수 있도록 약 1.4W 소모전력 사용량을 보여주었다. MNIST 데이터셋을 사용하는 CNN을 구현하여, 12.37 ms의 연산시간을 보였다. 또한 10개의 클래스를 가지는 CIFAR-10을 사용하여 물체를 분류하는 CNN을 구현했다. 또한 메모리 사용량을 줄이기 위해 binary connect network를 구현하여, 기존의 MLP보다 약 92%의 메모리 사용량 감소를 확인했으며, 연산량을 줄이기 위해 zero-skipping convolution neural network를 구현하여 연산속도에서 약 1.5배의 성능 향상을 확인 했다.

In this paper, I designed GPGPU for deep learning of embedded environment. It showed power consumption of about 1.4W for use in an embedded environment. GPGPU has 16 stream processors and 16 instruction fetches. Therefore, it has a total of 256 threads. I designed a scheduler with priority for each instruction. GPGPU''s interface was designed as AXI, APB, and IP reuse was considered in SoC, and FPGA system was implemented to use PCIe. Implementing CNN using the MNIST dataset, it took 12.37 ms.I implemented CNN to classify objects using CIFAR-10 with 10 classes. In addition, I implemented a binary connect network to reduce the memory usage. I have confirmed that the memory usage is reduced by about 92% compared to the existing MLP, and the processing time improvement of about 1.5x is achieved by implementing zero-skipping convolution neural network to reduce the amount of computation .",
딥러닝 분석을 활용한 치아우식 탐지의 신뢰도 평가,서울대학교 논문은 저작권에 의해 보호받습니다.,"치아우식의 검진 도구는 탐침 및 치과 방사선 사진 영상이 주로 사용되고 있으나, 최종적으로는 진단자의 경험에 의존하는 경향이 있으며, 진단자 간 신뢰도가 만족스럽지 않은 경우도 있다. 이러한 문제를 보완하고자 최근 영상 분석에 우수한 성능을 보이는 딥러닝을 활용하여 영상을 처리하거나 패턴을 인식하는 진단 기술을 치과 분야에 적용하여 치아우식의 진단 정확성을 높이고자 하였다.
이번 연구는 인터넷 검색 엔진에서 치아 영상를 수집하는 Search engine scraping 방법을 사용하여, 서울대학교 치의학대학원 연구윤리심의위원회의 승인(S-D20190007)을 받아 2019년 4월부터 2019년 5월까지 약 2개월에 걸쳐 진행되었다. 치아 영상은 세계보건기구 지침에 의해 건전치아, 우식치아, 처치치아로 나누었다. 최종적으로 각각 70개의 영상을 수집하였으며, 딥러닝 모델을 학습시키기 위한 훈련 세트 50개와 이를 검증하는 시험세트 20개를 무작위로 배치하였다. 건전치아와 우식치아를 분류하는 모델에서 신뢰도를 확인하기 위해 ROC curve, AUC, 일치도, 민감도, 특이도, 양성예측도, 음성예측도를 산출하였고, 건전치아, 우식치아, 처치치아를 분류하는 모델에서는 각 분류에 따른 일치도를 확인한 결과, 다음과 같은 결론을 얻었다.

1. 치과 영상의 특징을 추출하여 신뢰도 높은 모델을 구축하기 위해서는 깊은 신경망으로 설계되어야 한다.
2. 건전치아와 우식치아를 분류하는 모델에서, 전이학습 적용모델은 전이학습 비적용 모델(50.0%)에 비하여 월등히 높은 일치도를 나타내었다(90.0%, AUC:0.963).
3. 건전치아, 우식치아, 처치치아를 분류하는 모델에서, 일치도는 감소하였고(61.7%), 각 영상의 일치도는 처치치아(80.0%), 우식치아(35.0%), 건전치아(25.0%) 순이었다.

Dental explorer and dental radiographs are mainly used for the examination of dental caries, however they tend to depend on the experience of the examiner in the end and the reliability of the examiner may not be satisfactory. To overcome this problem, we tried to improve the diagnostic accuracy of dental caries by applying the deep learning which processes images or recognizes patterns and has superior performance in image analysis.
This study was approved by the Institutional Review Board of the Graduate School of Dentistry, Seoul National University using the search engine scraping method for collecting tooth images in the internet search engine. From April 2019 to May 2019 it has been going on for about two months. Tooth images were divided into sound teeth, caries teeth, and treated teeth according to WHO guidelines. Finally, 70 images were collected respectively, and 50 training sets for learning the deep learning model and 20 test sets for verifying the training set were randomly assigned. ROC curve, AUC, accuracy, sensitivity, specificity, positive predictive value, and negative predictive value were calculated to confirm reliability in the classification model of sound teeth and caries teeth, and, the model for classifying sound teeth, caries teeth, treated teeth confirmed the accuracy of the classification.

The following conclusion was obtained from the experiment.
1. In order to extract the characteristics of the dental image and establish a reliable model, it should be designed as a deep neural network.
2. In the model dividing sound teeth and caries teeth, the transfer learning model showed a much higher accuracy (90.0%, AUC: 0.963) than the non-transfer learning model (50.0%).
3. Accuracy was reduced (61.7%) in the classification of sound teeth, caries teeth, and treated teeth. The accuracy of each image was 80.0% for treatment, 35.0% for carious teeth, 25.0% for sound teeth, respectively.","#artificial intelligence, #convolutional neural network, #deep learning, #dental caries"
딥러닝을 이용한 전이 기반 한국어 의존 구문 분석,2019,"의존 구문 분석은 문장의 요소들이 지배소와 의존소의 관계를 이룬다고 보고 문장을 분석하는 과정이다. 본 논문에서는 한국어에 대한 의존 구문 분석 방법 중 전이 기반 방식을 딥러닝을 이용하여 진행하였다. 전이 기반 방식의 의존 구문 분석은 먼 거리의 의존 관계 분석과 초기 행동 오류로 인한 오류 전파에 약한 특징이 있다. 전이 기반 방식의 단점을 극복하기 위해 다층 양방향 LSTM을 사용하여 환경 자질을 학습하는 것을 제안한다. 환경 자질을 구축하기 위해 음절들과 품사 정보를 사용하였고, 의사 결정 트리 기반의 Tree Tagger를 사용하여 어절에 품사를 부착하였다. 양방향 LSTM 모델을 다층으로 구성하기 때문에 각 방향 간 LSTM 층을 쌓는 방식과 양방향을 합하여 LSTM 층을 쌓는 방식을 비교하여 실험하였고, 모델의 성능 평가를 위해 같은 전이 기반 알고리즘을 사용하는 Malt 파서와 기존의 전이 기반 방식 딥러닝 모델들과 비교하였다. 실험을 통해서 음절 단위로 임베딩을 하고 품사 정보를 사용하고 양방향을 합하여 층을 구성하는 모델이 성능이 가장 좋음을 보였다. 또한 같은 전이 기반 알고리즘의 기존 모델들과 비교했을 때 대체적으로 좋은 성능을 보였다.

Dependency parsing is the process of analyzing sentences that the elements of a sentence have a relationship of head and dependent. In this paper, transition-based dependency parsing was used by using deep learning on Korean language. The transition-based approach has the disadvantage of long distance dependency analysis and propagation of initial errors. To overcome these disadvantages, we propose to learn environment by using multilayer bi-directional LSTM. Syllables and parts-of-speech information were used to construct environment, and parts-of-speech were attached to the words using Tree Tagger based on decision trees. Since the bidirectional LSTM model is composed of multiple layers, the LSTM layer stacking method in each directions and both directions are compared and experimented. To evaluate the performance of the model, we compared the Malt parser using the same transition-based algorithm and the existing transition-based deep learning models. Experimental results show that the model that embeds the syllable unit and uses the part of speech information and constructs the layer by combining the two directions has the best performance. In addition, it shows good performance compared with existing models of the same transition based algorithm.",
딥러닝 기반 대장 용종 식별 연구,2019,"대장 암은 전 세계적으로 주요한 사망 원인이다. 그리고 대장 내시경을 통한 용종 제거는 대장 암을 예방하기 위한 가장 효과적인 방법 중에 하나이다. 본 연구에서는 Convolution Neural Network(CNN) 모델을 활용하여 대장내시경 이미지에서 용종 유무를 예측하는 모델을 개발하였다.
2017년 12월부터 2018년 8월까지 삼성서울병원에서 대장 내시경 검사를 시행한 총 397명의 환자를 대상으로 2,003 개의 대장내시경 이미지를 수집하여 연구에 활용하였다. 수집된 이미지에는 용종 발견률이 낮은 10mm 미만의 대장내시경 이미지가 82.3% 포함되었다.
심층학습 기반의 영상 분류 방법인 CNN 모델 중 많이 사용되고 있는 InceptionV3, DenseNet 기계학습 방법을 사용하여 모델 비교 분석을 진행하였다. 또한 학습된 모델이 훈련 이미지에 과적합 되는 것을 방지하기 위해 회전을 통한 이미지 증가(augmentation) 기법이 사용되었다.
학습된 모델을 검증하기 위해 Class Activation Mapping(CAM) 기법을 활용하여 이미지 객체 탐색정보를 추출한 결과 내시경 검사자의 진단 의도가 반영되어 객체 정보를 탐색하는 것으로 확인되었다.
동일한 조건 하에서 학습한 결과 DenseNet 모델이 민감도 97.9%, 특이도 98.8%, 정확도 98.3%로 높은 인식률을 보였다. 특히 대장 내시경 검사에서 용종 누락률이 크게 발생하는 10mm 미만의 용종 누락률은 1.22%(총 82중 1개 누락)로 측정되었다.
연구 결과 기계 학습을 통한 대장 용종 인식률이 내시경 검사자의 대장 용종 인식률과 비교하였을 때 유사한 예측 결과를 보여주었다. 따라서 제안한 모델은 내시경 검사자의 기술과 경험에 의존하지 않고 정량적인 방법으로 용종 유무를 판별 할 수 있는 임상 보조 진단 도구로써 활용될 수 있을 것으로 기대된다.","#용종 인식（Polyps recognition）, #딥러닝（Deep neural network）, #모델 비교 분석（Model comparison analysis）, #객체 탐색정보 시각화（Object navigation information visualization）"
딥러닝 모델을 이용한 AV 미디어 기반 실감효과 장면 검출 기법,2019,"본 논문에서는, 일반 영상을 4D로 상영하기 위해 AV 미디어로부터 실감효과 장면을 자동으로 검출하기 위한 딥러닝 모델 기반 기술을 제안한다. 영화 산업이 발전하면서 4D 콘텐츠에 대한 수요가 높아지고 있다. 현재 일반 2D 영상을 실감 콘텐츠로 변환하기 위해 저작도구를 활용하고 있지만 사람이 수동으로 저작해야하기 때문에 여전히 높은 비용이 요구된다. 이러한 수동 저작의 한계를 극복하고 효율적으로 실감 콘텐츠를 변환하기 위한 연구가 진행되어 왔다. 딥러닝 모델을 기반으로 분절된 영상에 대해 실감효과 장면의 종류를 분류하는 선행 연구의 경우 시각적 특징값만을 고려하여 실감효과 장면을 분류하였다. 하지만 실감효과는 다양한 효과에 의해 생성되기 때문에 시각적 특징값 뿐 아니라 청각적 특징값을 사용할 필요가 있다. 이에 따라 시각적·청각적 특징값을 모두 이용한 멀티모달 딥러닝 구간 검출 모델을 제안한다. 또한, 대화 구간에서 실감효과가 나타나게 되면 영상에 대한 몰입을 방해할 수 있기 때문에 대부분의 실감효과 장면은 비대화 구간에서 나타난다. 이러한 상관관계를 이용하여 실감효과 구간을 보정하는 방법을 제안한다. 실제 4D 극장에서 상영된 영상을 이용한 실험을 통해 멀티모달 검출 모델이 유니모달 검출 모델에 비해 성능이 향상됨을 검증하고 비대화 구간을 고려한 구간 보정 기능을 실험을 통해 증명한다.",
엣지디텍션 필터를 이용한 딥러닝 초해상도 기법 성능 향상,2019,"통신 기술, 디스플레이 기술의 발전에 따라 디지털 이미지가 적용되는 분야에 있어서 이미지, 영상 등 컨텐츠의 해상도를 올리기 위한 처리기술이 요구되어 왔으며, 현재 진행형이다. 해당 분야는 새롭게 생성되는 컨텐츠 외 기존 컨텐츠의 성능을 끌어올리기 위한 방향과 기존 하드웨어도구들(감시카메라, 촬영카메라 등)을 활용하면서 더 좋은 성능의 결과물을 얻는 방향으로 발전되어 왔다. 슈퍼레졸루션 기법은 앞서 기술한 방향에 따라 진화해 왔으며, 기본 개념은 저해상도 이미지, 영상에서의 유효한 정보들을 이용하여 고해상도 이미지, 영상을 만들어내는 것이다. 현재 슈퍼레졸루션 기법은 정교하게 계산된 수식과 흐름에 따라 결과물을 만들어내는 방법과 근래 대두되고 있는 딥러닝을 활용하는 방법이 연구되고 있다. 전자의 경우 컴퓨팅 리소스가 적게 소모되며 사전 학습이 필요 없다는 장점이 있으나, 특정 영역에 있어서는 적용 시 성능이 저하되거나 이를 개선하기 위한 변경이 난해하다는 부담이 있다. 후자의 경우 컴퓨팅 리소스가 많이 소모되며 사전 학습이 필요하지만 특정 영역 적용 혹은 개선을 위한 변경이 유연하며 추가 학습을 통한 성능의 향상이 가능한 부분이 있기에 많이 활성화되고 있다. 그리고 그 유연성을 극대화하기 위해 널리 알려진 엣지 디텍션, 바이큐빅 등의 영상보간법을 혼합하기도 한다.
본 논문에서는 딥러닝을 적용한 슈퍼레졸루션 네트워크에 기존의 기술인 엣지디텍터를 이용하여 그 성능을 향상시키는 방안을 제안한다. 실험 결과를 통해 엣지디텍션의 적용은 기존 네트워크의 성능을 향상시킴을 알 수 있다.

The super resolution technology is required in digital image processing area due to development of communication and display technology. In digital image application area, method to enhance resolution of contents like image, video is needed and it is ongoing. Super resolution method is progressed way to enhance the resolution of preexistence contents and getting better result when using hardware equipments like currently installed surveillance cameras or shooting cameras. Super resolution method is keep progressing to way described before. It’s basic concept is get effective informations from low resolution image, video and make good use of those informations to reproducing high resolution contents. There are two big direction of super resolution method. One is making result through the delicate formula and fixed flow. Two is use currently on the rising technology, deep learning. First one take advantage of using less computation resource and not necessary of pretraining. But applied some specific areas, performance decreased and it is difficult to change the structure for improve this problem. In case of second one, it needs large computation resource and pretraining but easy to modify structure for improvement of applying specific area. Furthermore, this could get better performance through additional training so currently, deep learning based super resolution method is generally activated in field of super resolution study. In addition to advantage of this super resolution method, currently mixing with image interpolation like bilinear, bicubic and edge detection to strengthen the performance.
This paper proposes application of edge detection filter to get better performance of deep learning based super resolution network. Through the experiment results, applying edge detection filter on preexistence network is improve its performance.",
딥러닝 기반의 의류 국제통일상품분류체계 자동 분류 시스템에 관한 연구,2019,"외환 거래 자유화 확대 및 수출입 통관 절차 간소화 등으로 인하여 수출입 건수가 1년에 2000만건 이상으로, 점차 증가하는 추세이다. 수출입 기업에서는 관세 혜택을 받거나 올바른 관세를 측정하기 위해 관세 분류 방식으로 HS Code(Harmonized System Code)를 활용하고 있다. 그러나 HS Code의 기준이 1만개가 넘을 정도로 방대하여, 신규 수출입 업무 진행자나 품목에 대한 이해가 부족할 경우 분류에 어려움이 따르고, HS Code 오 분류는 수출입 업무 흐름을 방해하여 기업에 큰 손실을 야기할 수 있다.
이러한 HS Code 분류의 한계점을 보완하기 위해 본 논문에서는 이미지 분류를 통해 의류 수출입 품목의 HS Code를 자동 제안할 수 있는 시스템을 설계하였다. 기존의 HS Code 제안 서비스는 물품명 혹은 사용자가 등록한 품목 정보를 이용하였다. 본 논문에서는 기존 서비스에서 사용되던 text정보가 아닌 이미지 정보를 활용하여 HS Code를 제안하도록 구성하였다. 이미지를 이용한 자동 제안을 위하여 이미지 분류 분야에서 널리 사용되고 있는 Convolution Neural Networks(CNN) 구조를 사용하여 이미지 분석 모델을 생성하였다. 생성한 신규 이미지 분류 모델을 사용하여 의류 품목의
이미지로 HS CODE를 분류할 수 있도록 시스템을 구성하였다. HS CODE의 구성 특성에 따라 시각적으로 분류할 수 있는 단계인 류 분류까지의 분류를 목표로 하였으며, 이를 위해 모델 생성시에 의류의 디테일한 특징을 잡아 분류할 수 있도록 이미지 분류 기법 중 RetinaNet 모델의 구조를 적용하였다.
이미지 트레이닝을 위하여 의류 전문 웹사이트의 이미지를 크롤링 하여 데이터 셋을 구성하였고, 구성한 이미지 데이터 셋을 학습시켜 새로운 모델을 도출하였다. 도출된 모델의 정확도 평가를 진행하였고, 실험 평과 결과 평균 88%의 정확도를 도출할 수 있었다. 평가 결과를 통하여 CNN기반의 이미지 분류 모델이 의류 수출입 품목의 HS CODE 자동 제안 시스템에서 유용하게 사용 될 수 있음을 확인할 수 있었다.","#이미지분류, #국제통일상품분류체계, #딥러닝, #HS Code"
영상처리 및 딥러닝 의미론적 분할 방법을 이용한 각막궤양 영역 검출,2019,"본 논문에서는 각막표피상에 발생하는 궤양을 촬영한 영상을 이용해 영상처리에 기반한 방법과 의미론적 분할 방법을 통해 궤양영역을 픽셀단위로 검출하는 알고리즘을 제안한다. 전통적으로 행해지던 각막궤양의 측정방법은 촬영된 영상을 보고 의료진의 주관적인 판단에 의해 수동적으로 이루어졌기 때문에 정확하고 객관적인 진료의 근거자료를 제시하기 어렵다는 문제점이 있다. 이러한 문제를 해결하기 위해 본 논문에서는 영상처리에 기반한 방법과 딥러닝에 기반한 방법을 이용해 다양한 환경에서 적용이 가능하며 사용자의 개입이 최소화된 각막궤양 분할 검출 방법을 제안한다. 영상처리 방법의 경우 사용자에 의해 정해진 관심영역에 영상처리 기반의 전처리과정을 거친 후 자동으로 선정된 기준점과 임계값에 의한 Flood-fill방법으로 궤양을 픽셀단위로 검출하는 방법을 제안한다. 딥러닝 방법의 경우 의미론적 분할 방법중 가장 높은 성능을 보이는 DeepLab 모델을 기반으로 하여 특징을 검출하는 검출기를 각각 ResNet과 Xception으로 가지는 여러 모델을 통해 각막궤양 검출의 자동화를 제안한다. 또한 검출 정확도를 향상시키는 방법으로 객체와 배경간 비율 조정방법을 제안하였으며 본 논문에서 제안한 알고리즘의 검증과 비교분석을 위해 몇가지 실험을 진행하였다.
실험은 각 방법에 대해 각막궤양이 나타나 있는 영상 60장과 95장의 데이터를 활용하였으며 성능을 평가하기위한 지표로 다이스 유사계수를 활용하였다. 먼저 영상처리에 기반한 방법을 실험한 결과 제안한 방법이 비교군으로 설정한 사용자에 의해 기준점이 정해지는 기존의 Flood-fill 방법과 Otsu 임계값에 의한 분할, Active Contouring without Edge 방법에 비해 약 6%에서 10% 높은 약 85%의 검출 정확도를 보였다. 의미론적 분할 방법의 경우 검출기가 Xception 네트워크로 설정된 모델보다 ResNet으로 설정된 모델의 검출 정확도가 약 6%에서 10% 높은 것을 확인하였으며 객체와 배경간 비율이 조정된 데이터를 이용한 실험에서 ResNet을 검출기로 설정하였을 때 약 82%정도의 높은 정확도를 보이며 궤양검출의 자동화가 가능함을 확인하였다. 본 연구를 통해 각막궤양 진료과정에서 진료환경에 따라 반자동 또는 자동방법을 통해 높은 정확도로 궤양영역을 검출가능함을 확인하였으며 특히 의미론적 분할 방법의 경우 주로 물체검출에 활용되던 모델을 궤양등 형태가 일정하지 않은 객체를 검출하는데에도 유의미한 결과를 보여줌을 확인하였다.

In this paper, we propose an algorithm that detects the ulcer area on a pixel basis by image processing based method and semantic segmentation method on taken image of corneal ulcer which onset in corneal epidermis.
Normally measurement of corneal ulcer has been problematic in that it is difficult to present accurate and objective medical data because it was manually performed by subjective judgment of the medical staff. In order to solve this problem, we propose a corneal ulcer segmentation detection method that can be applied in various environments and be minimized user intervention using the image processing based method and the deep learning based method. In the case of image processing method, we propose method that detect ulcer area basis on pixel by Flood-fill method using seedpoint and threshold value which automatically selected after preprocessing based on image processing for Region of Interest which selected by user. In the case of Deep Learning method, we propose automation of corneal ulcer detection through various models which has Xception and ResNet as Detector, based on DeepLab model which has the highest performance among semantic segmentation models. In addition, we propose a method to improving the detection accuracy by adjust the ratio between object and background. In this paper, we have conducted several experiments to verify and compare the proposed algorithm.
In the experiment, data of 60 and 95 images with corneal ulcers were used for each method and Dice Similarity Coefficient were used as an index to evaluate the performance. First of all, the result of experiment for the method based on image processing, Proposed method showed an accuracy of 85% which higher 6~10% than comparative group like conventional Flood-fill method having user-selected seedpoint, Otsu''s threshold segmentation method or Active Contour without Edge method. In the case of the semantic segmentation method, the result of detection accuracy of model which has ResNet as detector is higher 6~10% than Model which has Xception as detector, and the case of experiment using data which adjusted for ratio between object and background, model which has ResNet as detector shows 82% accracy and it confimed that it is possible to automation of corneal ulcer detection.
Through this study, we confirmed that it is possible to detect ulcer area on high accuracy by semi-automatical or automatical method in during corneal ulcer treatment according to medical environment and especially, in the case of semantic segmantation method, we confirmed that the model which normally used for object detection also showes reasonable results to detect formless object such as ulcers.",
지도 가독성 향상을 위한 딥러닝 활용 방안 연구,2019,"지도는 우리가 살고 있는 지리적 공간을 나타내며, 목적, 용도에 따라 다양한 내용을 담고 있어 일상생활뿐만 아니라 다양한 분야에서 의사 결정 시 중요한 정보를 제공하고 있다.
그러나, 지도 제작 기술 발전에도 불구하고 여전히 지도 제작 과정은 복잡하고 많은 시간과 비용이 들어 지도 활용 시 큰 걸림돌이 되고 있다. 따라서 새로운 지도를 구축하기보다는 기 구축된 지도를 재활용하는 방안이 필요하다. 또한, 광범위한 분야에서 지도 활용도가 높아지면서 다루는 정보가 많아졌고, 이 방대한 정보로부터 원하는 정보를 찾기 어려워지고 있다. 따라서 기존 구축된 지도 활용 시 원하는 정보를 효과적으로 찾는 방안도 필요하다.
본 논문은 위 문제를 해결하기 위해 기 구축된 지도 활용 시 원하는 정보를 쉽게 찾는 방안을 제시한다. (이를 지도 가독성 향상이라 표현하고 있고, 지도 내 서로 다른 feature 간 구분/식별할 수 있는 정도를 지도 가독성이라 정의했다) 지도 가독성 향상 방안은 CNN 기반의 Style Transfer를 이용해 입력 지도 이미지의 채도, 명도, 색상 등을 높여 지도 내 요소 간 분별력을 향상하는 걸 목표로 한다. 실험 1), 2)에서는 채도, 명도를 높여 지도 가독성 향상에 효과가 있음을 보여주고 있고, 실험 3)에서는 요소 특성에 맞는 색상을 부여하여 지도 가독성 향상에 효과가 있음을 보여주고 있으며. 실험 4)에서는 특정 요소에 색상을 더하여 주변 요소와의 색상 차를 높여 지도 가독성 향상에 효과가 있음을 보여주고 있다.","#지도, #GIS, #지도 서비스, #지도 가독성, #CNN, #Style Transfer, #딥러닝"
In-ear 마이크 신호와 out-ear 마이크 신호를 활용한 딥러닝 기반의 dual 채널 음성 향상 기법,2019,"본 논문은 헤드셋에 내장된 in-ear 마이크와 out-ear 마이크 신호를 활용한 dual 채널 음성 향상 기법에 대한 논문이다. In-ear 마이크는 귀의 안쪽 방향으로 위치하여 화자의 이관(eustachian tube)을 통해 들어오는 소리를 수집하며, 주변 노이즈의 유입이 차단되어 SNR 이 높은 특성을 갖지만 긴 관을 통해 전달 되어 신호의 대역이 제한되는 한계를 지니고 있다. Out-ear 마이크는 귀의 바깥 쪽 방향으로 위치하여 주변 환경의 노이즈가 섞인 화자의 음성을 수집하여 주변 noise 에 의해 왜곡된 신호가 유입된다는 한계를 갖고 있다. 본 논문에선 한계점이 있는 각각의 신호를 활용하여 상호 보완적인 방향으로 음성 향상을 진행하는 음성 향상 모델을 제시한다.

이러한 2 가지 신호를 활용하여 본 연구에선 딥러닝 (deep learning) 을 기반으로 한 음성 향상 모델을 제안한다. 사용된 딥러닝 구조는 sequential 한 음성 데이터에 강점을 갖는 LSTM network 을 dual 채널로 구성하여 time-domain 의 sequential 정보를 반영하는 feature extractor 로 활용하였고, network 에 skip-connection을 더하여 음성 복원 및 noise 제거에 집중할 수 있도록 하였다. 실험은 DNN 구조 및 입력 채널 수 변화에 따른 음성 향상 모델의 성능 비교를 수행하였다. 성능 확인을 위한 측정 지표는 PESQ (perceptual evaluation of speech quality)와 STOI(short time objective intelligibility), LSD (log-spectral distance) measure를 사용하였다.

This thesis is about the dual-channel speech enhancement system that utilize signals collected through in-ear microphone and out-ear microphones embedded in headset. In-ear microphone is located in the inner direction of the ear and used to collect sounds coming through the speaker''s Eustachian tubes. In-ear signal is a signal with a high signal to noise ratio (SNR) due to the blocking of ambient noise. However, it has a limitation that the frequency band of the signal has cut-off during signal is transmitted through a long tube, i.e. Eustachian tube.

Out-ear microphone is located in the outer direction of the ear, and it collects the speech signal and the noise of the surrounding environment at the same time. However, out-ear microphone signal has a limitation that the inflow of signals were distorted by ambient noise.

In this paper, we propose a speech enhancement system that enhances the noisy speech signal by using each of in-ear and out-ear signal in a complementary way. Furthermore, we used a deep learning approach in order to implement the speech enhancement system. The deep learning structure used for the speech enhancement system consisted of two channels of LSTM network, which had an advantage in addressing the sequential information of speech data, and the LSTM network was utilized as a feature extractor that reflects the sequential information in time-domain. In addition, skip-connection was added to the network to focus on speech restoration and noise cancellation.

The experiments were performed to compare the performance of the speech enhancement model according to the DNN structure and the number of input channels. In addition, the metrics used for performance verification were the perceptual evaluation of speech quality (PESQ) and short-time objective intelligence (STOI) and log-spectral distance (LSD).","#Source separation, #Speech enhancement, #In-ear microphone, #Out-ear microphone, #LSTM, #Skip-connection"
심볼마커를 사용한 딥러닝 기반 모바일 응용 UI 인식,2019,"최근 딥러닝 기반으로 GUI(Graphical User Interface)의 스케치이미지를 인식하여 어플리케이션에서 구현되는 코드로 만들어주는 연구가 진행되고 있다. UI/UX 디자이너는 모바일 응용 프로그램 개발 시 스토리보드를 통해서 개발자와의 의사소통을 돕는 도구로 사용된다. 하지만 종종 개발자는 모호한 위젯에 대해 UI/UX 디자이너의 의도와 다른 위젯을 만드는 경우가 발생한다.
본 논문에서는 DNN (Deep Convolutional Neural Network) 기반 UI 식별의 정확성을 높이기 위해 심볼마커를 사용하여 자동 UI 탐지 방법을 제안한다. 모호한 위젯들에 대해 명시적으로 추가적인 표시인 심볼마커를 지정하여 사용하며 심볼마커는 위젯앞쪽에 위치하고 UI의 앞 글자를 따서 작성하였다.
심볼마커의 성능 평가를 위해 심볼마커가 없는 경우와 있는 경우로 나누어 정확도를 비교하고 심볼마커의 모양에 따른 정확도 개선을 위해 동그라미와 괄호형으로 나누어 심볼마커 모양을 분석한다. 실험 결과 원형의 심볼마커는 라디오버튼과 혼동이 있어 괄호형의 심볼마커의 값이 더 높게 나옴을 알 수 있었고 심볼마커 없는 경우보다 괄호형의 심볼마커가 있는 경우의 mAP 값이 최대 15.7% 증가됨을 확인하였다. 결과 값에 따라서 심볼마커를 사용하여 UI 인식 시에는 괄호형의 심볼마커사용을 권장한다. 심볼마커를 사용함에 따라 개발자와 디자이너의 피드백이 줄어 시간과 비용이 감소하고 스케치이미지의 UI 오탐률이 줄어 정확성이 향상된다. 후에 전공자가 아닌 일반 사용자들에게 학습용으로 사용되기를 기대하며 제안 기법은 비전문가들도 쉽게 모바일 응용의 UI 코드를 자동 생성하는데 활용될 수 있다.

Recently, UI researchers have been studied to recognize sketch images of GUI (Graphical User Interface) based on deep learning and to make them into codes implemented in applications. The UI / UX designer is used as a tool to communicate with developers through storyboards when developing mobile applications. However, developers may create about ambiguous widgets that are different from the UI / UX designer''s intentions.
In this paper, we propose an automatic UI detection method using symbol markers to improve the accuracy of DNN (Deep Convolutional Neural Network) based UI identification. Our method uses symbol markers to explicitly indicate additional symbols for ambiguous widgets and the symbol marker is placed in front of the widget and is written after the first letter of the UI.
In order to evaluate the performance of the symbol markers, the accuracy is compared by dividing the symbol markers by the case where there is no symbol marker and the symbol markers are analyzed by dividing them into a circle and a bracket type in order to improve the accuracy according to the shape of the symbol marker. Experimental results show that Circular symbol markers are confused with radio buttons, so the parenthesized symbol markers are higher the mAP value increases up to 15.7%. It is recommended to use parenthesized symbol markers according to the result. The use of symbol markers reduces developer and designer feedback, saves time and money, and improves accuracy by reducing UI false positives in sketch images. The proposed method can be used to easily and automatically generate UI Code of mobile application.",
딥러닝을 이용한 어종 판별 시스템,2019,"최근 미디어와 SNS의 영향으로 한국 낚시 시장이 급격히 성장하면서 해양 레저 스포츠에 관심이 높아지고 있는 반면, 수산자원의 번식 및 효율적인 관리를 위한 수자원의 포획/채취 금지 및 체장을 규정한 수산자원관리법 시행령이 시행되고 있는 점은 대부분 잘 알지 못한다. 또한 어종을 막론하고 크기가 자신보다 작은 물고기를 먹어 치워 국내 생태계를 위협하고 있는 외래종에 대한 문제 등 어종에 대한 판별이 잘 되지 않는 일반인들이 문제를 받아들이기 쉽지 않다.
본 논문에서는 이러한 문제를 해결하기 위해 사전학습모델을 재학습한 CNN(Convolution Neural Network) 기반의 전이학습 모델이 배포되어 있는 서버를 구축하고, 사용자가 어종 이미지를 스마트폰을 통해 업로드 하면 서버에서 어종을 판별하여 결과 값을 다시 전송해주는 시스템으로 누구나 스마트폰을 통해 손쉽게 어종 판별을 할 수 있는 시스템을 제안한다.

Recently, as the Korean fishing market has grown rapidly due to the influence of media and SNS, interest in marine leisure sports is increasing.
However, most of them do not know that the Enforcement Ordinance of Fisheries Resources Management Act, which stipulates prohibition of catching / collecting of water resources for the breeding and efficient management of fishery resources, In addition, regardless of the type of fish, it is not easy for general people to eat fish smaller than their own size and to identify fish species such as alien species that threaten domestic ecosystems.
In this paper, to solve these problems, we build a server on which a CNN (Convolution Neural Network) based transfer learning model that re-learns the pre-trained model, and when a user uploads the image of a fish species through a smartphone, And sends the result back to the system. This system can easily identify fish species through smartphone.",
컴퓨터비전 기반 건설근로자 안전모 착용 여부 인식을 위한 딥러닝 기법의 적용,2019,"Since the construction site is exposed to the external environment and works, the accident rate is higher as many risk factors are higher than other industries, and it is required to wear the Personal Protective Equipment. However, safety helmets are often not worn or worn properly in real-life situations due to frustration and annoyance. As a result, small accidents are likely to lead to serious accidents and safety managers provide safety education, but it is difficult to manage many workers in real time. Therefore, more effective safety management measures are needed. On the other hand, computer vision technology is a field of artificial intelligence, which programs computers that automatically recognize and track objects through images obtained from imaging devices. Also, the recent introduction of deep learning algorithms has been studied in many applications because the accuracy of this technology is very good.
In this study, the computer vision-based deep learning object detection algorithm, Faster R-CNN, is used to supplement a person''s vision and cognitive skills to learn from image data obtained from cameras installed at a construction site and to recognize whether workers wear safety hats.",
코사인 유사도에 기반한 적대 과정 딥러닝의 개선안과 화자인식 및 도메인적응에의 응용,2019,"적대 과정은 서로 다른 목적을 가지는 복수의 네트워크 간의 경쟁 과정을 통해 신뢰도 있는 모델을 학습하는 딥러닝 기법이다. 주요 네트워크와 부가 네트워크가 있다고 가정하면, 적대 과정은 경쟁을 유도하기 위해, 부가 네트워크의 성능을 하락시키는 것을 목적으로 주요 네트워크를 학습시킨다. 여기서 부가 네트워크의 성능 하락이라는 목적을 수치화하기 위해 categorical cross entropy (CCE)를 역전시킨 함수가 사용된다. 하지만 CCE를 역전시킨 함수의 동작을 분석하는 과정에서 해당 함수를 사용하는 것이 부가 네트워크의 성능 하락을 보장하지 못한다는 것을 발견하였다.
본 논문에서는 부가 네트워크의 성능을 보다 효율적으로 하락시킬 수 있는 코사인 유사도를 활용한 적대 과정을 제안한다. 제안한 코사인 유사도 기반 적대 과정이 기존의 적대 과정을 대체하는 것이 가능한지 확인하는 실험을 수행하였다. 적대 과정을 적용한 화자식별 및 비지도 도메인 적응 실험 결과, 제안한 적대 과정이 기존의 적대 과정을 대체할 수 있음을 확인하였다.
적대 과정을 적용한 실험에서, 적대 과정에 의한 성능 하락이 최적화 과정에서 지역 최저점 탈출을 야기시킬 수 있다는 것을 발견하였다. 따라서 적대 과정의 새로운 응용법으로 적대 담금질이라는 기법을 제안한다. 적대 담금질은 기존의 최적화 과정에 주기적으로 적대 과정을 적용해 네트워크의 성능을 주기적으로 하락시키고 상승시킨다. 이미지 인식과 화자식별을 수행하는 실험 결과, 제안한 담금질 과정이 기존 최적화 과정을 개선시킬 수 있다는 것을 확인하였다.

The adversarial process is a deep learning technique that trains a reliable model through the competition process between multiple networks with different purposes. Assuming that there are a primary network and a subsidiary network, the adversarial process train the primary network by reducing the performance of the subsidiary network. A function that reverses the categorical cross entropy (CCE) is usually used to define the purpose of the performance degradation of the subsidiary network. However, we found that using this function does not guarantee the performance degradation of the subsidiary network.
In this paper, we propose a novel adversarial process using cosine similarity, which can reduce the performance of the subsidiary network more efficiently. Experiments were conducted to verify whether the proposed adversarial process based on cosine similarity could replace the conventional adversarial process. As results of the experiments about the speaker identification and unsupervised domain adaptation using the adversarial processes, it was confirmed that the proposed adversarial process could replace the conventional adversarial process.
In the experiments using the adversarial process, we found that the performance degradation caused by the adversarial processes could lead to an escape of local optimum in the optimization process. Therefore, we propose a method, adversarial annealing, as a novel application of the adversarial process. Adversarial annealing periodically degrades and raises the performances of the network by applying the adversarial processes to the conventional optimization processes. Experimental results of image recognition and speaker identification showed that the proposed adversarial annealing could improve the conventional optimization process.",
딥러닝을 이용한 감성분석과 문장생성,2019,"감성분석은 문장에 담긴 사람의 긍정, 부정을 나타내는 주관을 탐지하고 분석하는 일이다. 주로 판매 상품에 대한 평가와 영화 감상평 등 특정 사물에 대해 이루어지며, 개인마다 다른 감성과 표현의 다양성을 넘어 여론을 분석하기 위해 쓰인다. 문장생성은 대화형 시스템, 기계 번역, 언어모델링 등 다양한 분야에서 목적에 맞는 문장을 생성하는 작업의 총칭이다. 생성되는 문장은 의미, 문법 더 나아가서는 화용까지 맞아야 하므로 문장생성은 굉장히 어려운 분야이기도 하다. 본 논문에서는 딥러닝을 이용한 감성분석과 문장생성에 관해 기술한다. 합성곱 신경망을 이용한 감성분석과 다양한 재귀 신경망을 이용한 문장생성, 더 나아가 원하는 감성이 담긴 문장을 생성하는 모델까지 제안하고 이를 한국어에 응용한다.

Sentiment analysis is the task of detecting and analyzing the subject that shows the positive and negative of the person in the sentence. It is mainly used for evaluating sales items and movies, and it is used to analyze public opinion beyond the diversity of sentiment and expressions of individuals. Text generation is a generic term for the task of generating sentences for various purposes, such as interactive systems, machine translation, and language modeling. Text generation is a very difficult field because the sentence to be generated must be suitable for semantics, syntax and even pragmatics. In this paper, we describe sentiment analysis and text generation using deep learning. We propose text generation using recurrent neural network, sentiment analysis using convolutional neural network, and a deep learning model that generates a text containing desired sentiment, and apply it to Korean.","#자연어처리, #기계학습, #딥 러닝, #감성 분석, #문장 생성, #감성 제어 문장 생성, #VAE, #CNN, #RNN"
자율주행 자동차 환경에서의 3D-LIDAR와 딥러닝을 이용한 클러스터링 후보 군 기반 실시간 객체 검출,2019,"최근 자율주행자동차 시스템을 위한 연구가 Google, NVIDIA, Uber, Naver등의 IT 기업들도 자율주행자동차 플랫폼 기술 개발에 나서고 있다. 자율주행자동차는 주위 환경에 대한 객체 인식, 이동 경로에 대한 판단, 판단 결과에 의한 차량 제어 등 다양한 기술을 요구한다. 주위 환경에 대한 객체 검출 기술로 사용되는 센서로는 Camera, LiDAR(Light Detection And Ranging), Radar등을 이용하여 다중 센서를 이용한 객체 인식을 사용해 인식률을 더 높이고 있는 추세이다. 인식 기술의 중요도가 높아지면서 3D LiDAR의 상용화 제품으로서 자리 잡게 되면서 3D 정보 기반 인식 기술들이 활발히 진행되고 있다. 전통적인 방법으로는 영상처리, SVM(Support Vector Machine)[1], 머신 러닝을 이용하여 객체 검출을 하였으나, 임계 값을 이용하여 실험적인 결과를 구한다는 단점이 있었다. 최근에는 CNN(Convolution Neural Network)이 활발히 사용되고 있으며, 최근에는 많은 Computer Vision 분야에서 좋은 성능을 보여주고있다.
본 논문에는 기존 Object Detection의 기본 flow인 RPN(Region Proposal Network)에서의 처리시간 지연을 거리 기반 군집화 기술인 Euclidean clustering을 이용하여 후보 군을 구하고 후보 군의 검출 기반으로Projection을 이용한 input과 Slicing을 한 input에 대한 방법을 제안하였다. 또한 CNN Network 별로 정확성을 비교하였고 Basic CNN, ResNet, VGG16, MobileNet 총 4개의 CNN Network을 이용하여 정확성과 속도를 비교하였다. 제안된 방법으로 실제 도로환경에서 취득한 연구실 내의 데이터(CVLab dataset)을 이용하여 평가하였고, 공공 데이터 set인 KITTI dataset을 이용하여 제안하는 방법에 대해서 장단점을 분석하였다.","#autonomous vehicle, #3d-LiDAR, #clustering, #deep learning, #object detection"
딥러닝을 이용한 양방향 소통 영상의 하이라이트 검출,2019,"최근 유튜브나 트위치, 카카오tv 등과 같은 개인방송 플랫폼을 통해 시청자와 방송 제작자들이 서로 소통하며 방송을 진행하는 양방향 소통 방송을 쉽게 접할 수 있다. 이러한 플랫폼에는 날마다 수많은 영상들이 업로드 되고, 이를 이용하는 사람들도 증가하고 있다. 이에 방송 제작자들은 시청자 유입을 위해, 시청자들은 원하는 영상을 쉽게 선택하기 위한 목적으로 하이라이트 영상을 원한다. 플랫폼의 입장에서는 하이라이트 영상 제작을 도와주면 쉽게 방송 제작자와 이들을 구독하는 시청자들을 끌어들일 수 있다. 이처럼 다양한 입장에서 하이라이트 영상 제작이 요구되고 있어 본 학위논문에서는 자동으로 영상의 하이라이트 위치를 찾는 방법을 제안한다.
개인방송은 대부분 채팅을 통해 시청자들과 콘텐츠 제작자들이 서로 소통하며, 다수의 시청자들이 흥미를 느끼는 부분에서 채팅이 활발해진다는 특징이 있다. 따라서 채팅 정보를 이용하여 하이라이트 위치를 예측하는 딥러닝 모델을 제안한다. 또한 영상을 요약하거나 하이라이트를 찾는 방법을 주제로 하는 기존의 연구에서 많이 사용한 이미지와 오디오 정보도 채팅 정보와 함께 하이라이트 검출에 이용하는 모델을 제시한다.
하이라이트를 찾기 위해서는 영상을 이해할 필요가 있으며, 영상을 이해하기 위해서는 콘텐츠의 종류에 따른 특성을 파악하는 것도 중요하다. 영상의 흐름이 느린 콘텐츠의 경우는 하나의 이벤트가 하이라이트에 해당하는지를 판단하기 위해 단기적 흐름뿐만 아니라 중장기적 흐름을 아는 것이 도움이 된다. 콘텐츠의 특성에 따라 한 이벤트가 하이라이트인지 판단하기 위해 해당 이벤트 내에서 중요하게 보아야 할 부분도 차이가 존재한다. 이러한 사항들을 고려하여 본 논문에서는 하이라이트 예측 성능을 높이기 위해 다중 시구간 모델과 앙상블 모델을 제안한다.
제안하는 하이라이트 예측 모델은 실제로 개인방송 플랫폼을 통해 방송된 영상을 이용하여 성능을 확인한다. 사용한 영상은 개인방송 시청 수요가 높으며 비교적 하이라이트가 명확한 e스포츠와 야구 경기 중계 영상이며, 전문 편집자가 제작한 하이라이트 영상을 ground truth로 설정하고 비교하여 유사성을 확인하였다. 본 학위논문을 통해 제안한 모델들이 하이라이트 자동 예측에 유용하게 이용될 수 있을 것이라 기대한다.

Through two-way communication platforms, broadcasters and viewers can communicate with each other. As a result, live streaming services such as Youtube, Twitch, and Kakao TV become increasingly popular in recent years. As the number of videos on these platforms rapidly increases, the demand for providing highlight videos grows as well. Because a highlight video is a collection of interesting scenes in a video, it helps viewers to choose which videos to watch. However, producing a highlight video is time-consuming and costly. In this thesis, we present novel methods for automatically predicting highlights to solve these problems.
On most live streaming platforms, online chatting is a primary way of communication between broadcasters and viewers. Thus, it is easily conceivable that the chatting traffic tends to increase at interesting parts of a video. In this thesis, we propose to use chat logs to detect highlight events in a video. Our deep learning models can handle chatting information and are shown to understand a video better. Most of the related studies use only audio or visual information to summarize a video or to find highlights. On the contrary, we propose novel models that use all the chat, audio, and visual information to predict highlights, and demonstrate that using a variety of information can improve the predictive power of a highlight detector.
Considering the type of contents is also important in highlight detection. Depending on the content types, the contextual flow of the video may vary. For content with slower flow in the video, seeing both short-term and mid-to-long term flow together can be more helpful. Thus, we propose to use the features over multiple time intervals to understand the mid-to-long term flow as well as the short term flow in a video. In addition, which part of an event is important in determining highlights depend on the content types. Therefore, we also propose an ensemble model that puts weights differently over different parts of an event. We have collected e-Sports and baseball videos from Twitch and Kakao TV, and have demonstrated the similarity between our results and expert-produced ground truth. We expect that the models proposed in this thesis will be useful in automatically predicting highlights.",
딥러닝을 이용한 콘크리트 압축강도 예측 시스템 구축에 대한 기초적 연구,2019,"콘크리트의 역학적 특성 중 가장 기본적인 압축강도의 경우 공기의 조정 및 거푸집의 탈형 시기의 결정 및 콘크리트 품질 관리의 기본적인 자료 등으로 사용되기 때문에 콘크리트의 압축강도를 정확히 예측하는 것은 중요하다. 현재 다양한 압축강도 예측 연구가 진행되고 있으며 비교적 간단한 비파괴 방식의 현장 추정 외에 데이터를 이용한 통계 및 회귀 분석을 통한 예측 식이 제시되어 있다. 하지만 이러한 기존의 예측 방법은 저차원의 회귀분석을 기반으로 하여 다양한 영향인자를 적용하는데 한계가 있기 때문에 적용할 수 있는 콘크리트의 특성이 제한적이다.
따라서 최근 다양화된 목표 성능의 콘크리트의 압축강도를 예측하고 일반화된 시스템을 개발하기는 어려운 실정이다. 이를 해결하기 위해 인공지능의 한 분야인 머신 러닝, 신경망 이론을 이용한 연구 또한 진행되어 왔으나 배합, 물성 및 강도의 데이터 베이스화가 잘 진행되지 않았기 때문에 데이터의 수집 및 자체적인 신뢰도 확보가 어렵고, 적용되는 영향 인자가 증가할수록 예측 성능이 크게 저하되는 문제점이 제시되었다. 이에 최근 보다 발전된 형태의 프로그램, 알고리즘을 사용한 연구가 활발히 진행되고 있으나 알고리즘의 발전 속도에 비해 연구 성과는 부족한 실정이다.
따라서 본 연구에서는 본 연구의 목적은 다양한 적용 인자를 적용함에도 높은 정확도를 발현하는 예측 시스템의 개발을 위해 배합 및 압축강도 데이터를 최근 인공지능 분야에서 주목 받고 있는 Deep Learning Algorithm을 통해 학습시켜 콘크리트 압축강도 예측 시스템을 개발하였다. 이후 결과를 검토하여 다양한 분석과 매개변수의 조정을 통해 예측 성능을 향상시키고, 신뢰도를 확보하기 위한 방법론을 제시하고자 하였다.",#콘크리트공학
딥러닝 기반의 악성코드 예방 모델에 관한 연구,2019,"현대사회는 IT 산업의 발전으로 스마트폰 및 인터넷이 급속하게 확산되고 있고, 컴퓨터의 성능이 향상됨에 따라 자동화된 악성코드 생성 도구가 인터넷을 통하여 빠르게 유포되고 있으며, 악성코드의 출현 개수가 기하급수적으로 증가하고 있는 추세이다. 또한 최근에는 IoT, 클라우드 컴퓨팅과 같은 기술들이 등장하면서 IoT 기기를 감염시켜 서비스 거부 공격에 활용하고 있고, 클라우드에 랜섬웨어를 감염시키는 것과 같이 새로운 유형의 악성코드들이 대량으로 등장하여 보안 위협도 증가하고 있으며, 전체 악성코드 가운데 신종 악성코드는 20% 미만으로, 대부분은 기존의 악성코드 변종이다. 이러한 악성코드를 이용한 위협은 사이버 상에서 가장 심각한 위협으로 분류되며, 악성코드의 분류를 어렵게 하기 위해, 더욱 정교해 지고 있고, 복잡해짐에 따라, 50% 이상의 악성코드가 안티 바이러스 제품에 탐지되지 않는 경우가 발생하여 위협적인 상태로 유지되고 있다[53]. 지능화된 악성코드의 효과적인 대응을 위한 많은 탐지 기술과 분석 환경이 연구[56]되고 있으나, 약 80% 이상의 악성코드는 난독화, Anti-VM, 실행압축 등의 분석을 매우 어렵게 하는 기술이 사용되고 있기에, 기존 분석 환경과 탐지 기술로는 효과적인 악성코드 식별에 한계가 있다[37][44][66][79]. 전통적인 악성코드 분석 방법은 다음과 같이 크게 2가지로 분류할 수 있다. 첫째, 악성코드를 가상머신 환경이나 에뮬레이터를 통하여 실행시켜 악성행위의 수행 여부를 분석할 수 있는 동적 분석 방법으로[65][77], 행위 정보 기반의 분석방법으로 신규 악성코드의 탐지 가능성이 높으며, 분석 기능을 자동화할 수 있어 분석 시간의 단축이 가능하다. 그러나 악성코드가 동작하기 위한 특별한 조건과 환경이 필요하며, 악성코드가 분석 환경을 파악하고 회피할 수 있다는 단점을 가지고 있다[75]. 둘째, 역공학이나 디버거 기법을 사용하여 직접 악성코드를 실행하지 않고 분석하는 정적 분석 방법으로, 실행 조건 없이 악성코드의 동작 특징 및 구조를 분석할 수 있는 장점을 가지고 있다. 그러나 자동으로 분석 기능을 제작하기 어렵고, 패킹이나 실행 코드 암호화와 같은 은닉 기술이 적용됨으로서 분석에 많은 시간과 노력이 필요하다[27][63][68]. 특히 악성코드 변종은 변형 엔진의 복잡도에 따라 변성(Metamorphic)과 다형성(Polymorphic)악성코드로 분류되며, 변성은 다형성 악성코드보다 진보된 형태로 사이버 상에 유포될 때마다, 기존의 악성코드가 사용하는 레지스터 변경, 난독화, 명령어 코드 재정렬, 의미가 없는 분기문 및 명령어를 추가하여 코드가 다시 작성되며, 다형성 악성코드는 단순하게 외형을 변형하기 위하여 데이터 확장 및 암호화를 기존의 악성코드에 적용하고 있다. 이러한 악성코드 배포 행위를 탐지하기 위하여 다양한 연구가 진행되고 있고, 디스어셈블을 통하여 파일의 종류, 크기 헤더, 압축 정보 등의 다양한 내용을 확인하거나, 다양한 특징들을 추출 및 분류를 통하여 악성코드인지의 판별이 가능하다[34].

Analysis of the big data infrastructure that integrated information communication technologies such as life science, robot technology, artificial intelligence, etc., has emerged as a very important problem by entering the era of the 4th industrial revolution. Due to the rapid development of computers, a lot of information is being generated, and the information necessary for people is processed and provided.
However, the importance of information held by computers has been increased, and the risk of infringement of personal information is increasing as data becomes massive. Cyber security problems such as malware attacks are also becoming very serious. Typical security risks are malware that is created and executed for malicious purposes. Although there are basic methods such as periodically backing up files and deleting files attached to e-mails using a virus prevention program to prepare for malware attacks, it is easier to judge more accurately a method is necessary. Once infected with malware, only solutions are possible via extreme methods. In other words, it can only be resolved through deletion of the infection target. Although malware defense technology is evolving, the best protection can be the best defense only by prevention methods in advance. Therefore, it is necessary to predict malware preliminarily based on the most trendy data for prevention.
In this paper, propose a scenario prediction model for prevention of malware based on deep learning in order to respond to infectious diseases by a method forecasting for various malignant codes in advance. As a model that can be used in the cloud environment, the proposed model images the log data collected through web crawling into a snapshot, analyzes it through iterative learning with the CNN algorithm of TensorFlow, deep learns it, then generates it is a system to judge whether it is a dangerous file or not by referring to the scenario where the data is. It is expected that it is easier to distinguish malware via the proposed model and it is expected to move rapidly and improve the efficiency of judging the presence or absence of malicious code.
In future it will be necessary to continue research on collecting and accumulating data for accurate malware discrimination, whether it is possible to reduce the time to research various algorithms through deep learning and to detect malware.
In this thesis, it consists of six pieces as follows. Chapter 1, describe the background and necessity of the research of the proposed model. In Chapter 2, we describe agile methodology, DevOps, Deep Learning, Web Crawler, Elastic Stack as related research. In chapter 3, the system of the proposed model and the architecture of DevOps explain deep learning data analysis, database setting, and utilization of agile methodology. In chapter 4, describe software configuration, architecture, process and main management screen implemented as system implementation. In chapter 5, describe the results for system experiments and the system evaluation and complementary items by survey as analysis and consideration. In chapter 6, discuss the conclusion and the direction of future research.",
딥러닝을 이용한 도심지 수위예측 : 도림천 유역 대상,2019,"최근 발생하는 급격한 집중호우로 인해 도시지역의 돌발홍수가 빈번하게 발생하고 침수피해가 증가하고 있다. 이러한 지속적이고 반복적인 홍수피해를 최소화하기 위하여 구조적인 대책뿐만 아니라 비구조적인 대책 또한 매우 중요하며 그 중 하천 유량 및 수위 예측에 관한 연구가 활발히 진행되고 있다.
하천의 수위변화 및 강우유출 현상은 매우 비선형적(non-linear)이어서 단위도(unit hydrograph) 등과 같은 선형모형(linear model)을 이용하여 모의하거나 예측하는 것은 한계가 있다. 이에 다양한 개념적(conceptual), 물리적(physics-based) 수문모형이 개발되었으며, 이러한 모형은 다양한 수문학적 특성들을 매개변수화(parameterization)하여 강우-유출 해석을 실시한다. 그러나 실제로 수리·수문모형을 이용한 도시하천의 홍수위 모의에 관한 모든 물리적 과정을 반영하는 것은 한계가 있으며, 예보를 위한 예측강우의 시공간적 불확실성으로 인해 예측결과에 불확실성을 초래할 수 있고 방대한 컴퓨팅 자원과 수치계산시간 등의 제약으로 후속조치를 위한 선행시간 확보가 필수인 홍수예보에서 그 활용에 제한적일 수 있다.
반면에 인공신경망(artificial neural network, ANN) 모형 등과 같은 입·출력자료의 인과(상관)관계를 기반으로 학습·예측하는 black-box 모형의 경우, 유역 및 하도에서 발생하는 물리적인 수리·수문학적 특성을 반영할 수는 없지만, 양질의 대용량 자료가 획득될 경우 특정 수문시계열 예측에서 우수한 결과를 도출하는 것으로 알려져 있으며 이미 다양한 수자원 분야에서 활용되고 있다. 본 연구에서는 심층신경망(deep neural network, DNN) 구조를 갖는 딥러닝 기반의 순환신경망(recurrent neural network, RNN) 모형을 구축하여 도림천 최하류 도림교의 수위예측을 수행하였다. 신경망 모형의 학습과 검증을 위해 약 총 6년 기간(2013년 7월 ~ 2019년 4월)의 10분 단위 도림천유역 4지점의 수위자료를 활용하여 도림천 하류 지점의 수위를 예측한다. 2013년 7월부터 2017년 7월까지의 자료는 LSTM 모형의 학습(training), 2017년 8월부터 2019년 4월까지의 자료는 신경망 모형의 테스트(testing)에 활용하고, 민감도 분석(sensitivity analysis)을 통해 모형의 최적 매개변수(optimal hyper-parameters)를 추정하여 순차열 학습기간 10분, 1시간, 3시간 그리고 수위 지점 학습 개수 차이(3 Cases)에 대한 도림교 수위를 예측하고 그 정확도를 분석한다.

Recently, the frequency of typhoons and heavy rainfall has been increasing, causing flood in urban areas, resulting in property damage along with casualties. In order to reduce continuous and repetitive flood damage, non - structural measures, as well as structural measures, are very important. So studies on runoff and water level prediction have been actively carried out.
The water level change and rainfall-runoff are nonlinear, therefore there is a limit to simulate or predict using a linear model such as a unit hydrograph. A variety of conceptual and physical-based hydrological models have been developed, and these models are used to parameterize various hydrological characteristics and perform rainfall-runoff analysis. However, in practice, it is limited to reflect all the physical processes of simulating the water level of urban rivers using hydrologic model. The spatial and temporal uncertainty of forecast rainfall for forecasting can cause uncertainty in prediction results and due to the constraints of massive computing resources and computation time, it may be limited in its use in flood forecasting, where it is essential to ensure ahead time for follow-up. On the other hand, in the case of the black-box model that learns and predicts based on the relationship between input and output data such as artificial neural network model, it can not reflect the hydrological characteristics occurring in the watershed and the river, It is known that when massive hydrological data are obtained, excellent results are obtained and they are already utilized in various water resources fields. In this study, a deep neural network model was constructed to predict the water level of the doom bridge. For the learning and verification of the neural network model, the water level at the downstream site of Dorimcheon was predicted using the 10 ? minute water level data of four Dorimcheon basin for 6 years. Data from July 2013 to July 2017 are used for training of LSTM model and data from August 2017 to April 2019 are used for testing of neural network model. The optimal parameters of the model are estimated through the sensitivity analysis. Water level of Dorim bridge are predicted according to sequence length, 10 minutes, 1 hour, 3 hours, and difference of training spots(3 Cases) and their accuracy is analyzed.",
CSI를 활용한 딥러닝 기반의 실내 사람수 추정 기법,2019,"IoT 서비스에서 사람 수 추정은 중요한 요소이다. 사람 수 추정을 위한 많은 방법들이 연구되고 사용되어왔다. 일반적으로, 카메라의 이미지와 센서 정보를 이용한 방법들이 연구되고 사용되어왔다. Wi-Fi나 블루투스에 연결되는 스마트폰을 직접 세는 방식도 있다. 본 논문에서는 Wi-Fi CSI와 딥러닝을 사용한 실내 사람 수 추정방법을 제안한다. 실험 대상은 기기를 소지하지 않아도 되며 각각 하나의 Rx AP와 Tx AP를 사용한다. 제안하는 k-binding 데이터 전처리와 1차원 데이터에 사용하는 CNN 모델인 1D-CNN모델을 사용함으로써 성능을 향상 시켰다. 6명까지 추정한 실재 실험의 결과는 64.8%의 낮은 결과를 보였으나 다수의 인원을 클래스로 묶은 결과는 84.5%의 높은 결과를 보였다.

In IoT service, people counting is a important factor. Many methods for people counting have been studied and used. Typically, using camera image and sensor data methods have been studied and used. Using smartphones methods is measure the number of smartphones connected to Wi-Fi or Bluetooth. In this paper, we propose deep learning based device-free indoor people counting using Wi-Fi CSI. One Tx AP and one Rx AP are needed, and people do not need a device. We have improved the performance by learning the proposed k-binding preprocessing data using 1D-CNN model applying CNN to one-dimensional data. The real testbed experiment showed 64.8% lower accuracy when using the proposed data preprocessing and model estimated the number of crowd up to 6 people in working scenario. However, the result of classifying a large number of people as a class showed a high result of 84.5%.","#IoT, #CSI, #Wi-Fi, #People Counting, #Device-free, #Deep Learning"
딥러닝에 기반한 미세먼지 예측 통합모델,2019,"최근 몇 년간, 한국에서 대기 중의 미세입자(안개, 먼지, 연기 등) 높은 농도와 관련된 문제는 공공 보건에 대해 상당한 우려를 증가시키고 있다. 이러한 미세먼지의 수준을 실시간으로 측정해 보고 추적하는 것은 쉬운 일이 아니다. 심지어 각 지역의 미세먼지 수준에 대한 기록들은 단지 특정 지역에서의 평균적인 미세먼지 농도에 대한 양이며 내가 알고자 하는 지역의 미세먼지 수준을 대변하기에는 부족하다. 대기 오염은 빠르게 확산하고 있으며, 사람들은 위험에 처해있다. 대부분의 연구들은 미세먼지를 측정함에 주로 센서에 기반한 접근법을 제안하고 있다.
이 문제를 다루기 위해, 미세먼지 농도(PM10)를 딥러닝을 통해 학습시키고 예측하는 모델을 만들어 보고자 한다. 제안된 방법은 미세먼지 수준(PM10)이 해로운지 아닌지 실시간으로 예측하기 위한 모델로 비디오 시퀀스에 기반을 둔 이진결정방법에 의해 학습된 여러 가지 모델들의 결과를 다수결을 통해 최종 결정하게 된다. 본 연구에서 제안된 모델은 앙상블 모델이기 때문에 민감도와 특이도 사이의 균형을 맞춰주는 결과를 보였다.

In recent years, problems related to high haze concentration (fine dust, smoke, etc.) in the atmosphere in Korea have raised considerable concerns about public health. It is not easy to measure and track fine dust level in real time. Even the records of fine dust level in each region are only the average particulate concentration in a particular area and are not sufficient to represent the fine dust level of the area. Air pollution is spreading rapidly and people are at risk. Most studies suggest a sensor-based approach to measuring the fine dust.
To address this problem, we would like to propose a model for learning and predicting fine dust level (PM10) through deep learning. The proposed method is to predict if PM10 is bigger than in real time. Our method is based on majority votes from various models for video sequence data. This method provides more balance between sensitivity and specificity than other methods because it is based on ensemble method.",
Video based driver drowsiness detection using deep neural networks : 딥러닝을 활용하는 운전자 동영상 기반의 졸음 검출,2019,"운전자 졸음은 많은 자동차 사고의 주요 원인이다. 이러한 사고를 줄이는 데 도움을 주기 위해서, 운전자 영상을 통해 운전자의 졸음상태를 자동적으로 검출하고 경고하기 위한 많은 연구가 수행되어 왔다. 본 논문의 목적은 운전자 얼굴 동영상을 통해 운전자의 졸음 상태를 검출하는 딥러닝 모델을 개발하는 것이다. 본 연구에서는 얼굴동영상에서 Spatial (appearance)와 temporal (motion) 요소를 함께 사용하는 두 가지 구조의 모델을 설계하였다. 첫번째 모델 구조는 convolutional neural network (CNN) + long short-term memory (LSTM)이다. CNN 구조 high-level spatial 정보를 영상의 각 프레임에서 추출하여 이 정보를 시간 순으로LSTM으로 전송한다. 두 번째 모델 구조는 3-dimensional CNN (3DCNN)이다. 이 모델에서는 spatial-temporal 구조의 3차원 데이터를 사용한다. 두 가지 서로 다른 길이의 데이터 (10초, 60초)를 입력데이터로써 각각 사용하여 실험하였다. 각 모델의 출력은 운전자가 졸음인지 아닌지 여부를 예측한 결과이다. 실험을 위해, 자체 구축한 KNU-DDD 데이터셋과 공공데이터인 NTHU-DDD 데이터셋을 사용하였다. 실험 결과, 본 제시한 설계 모델들이 기존 방식에 비해 더 높은 검출 성능을 보여주었다. 특히 60초 데이터를 사용한 CNN+LSTM 모델이 86.6%의 가장 높은 성능을 보여주었다.

Drowsiness of the drivers are significant causes of the many car accidents. To reduce these accidents, many researchers focused on detecting drowsy state of driver automatically based on video of the driver. The purpose of this thesis is developing a driver drowsiness detection model using deep learning methods based on video dataset of the driver facial expression. The video can be decomposed into the spatial (appearance) and temporal (motion) components. In this study, we designed two deep learning model architectures that utilizing both spatial and temporal components together. The first architecture is called convolution neural network (CNN) + long short-term memory (LSTM). In this architecture, the CNN extracts high-level spatial information from each frame of video, and then send the information to the LSTM in chronological order. The second architecture is called 3-dimensional CNN (3DCNN), which use 3-dimensional data of spatial-temporal structure. Two different lengths of data (10 seconds and 60 seconds) were tested as input data. The output of a model is indices of drowsy or awake of the driver. The performance of the proposed models was measured by using our created KNU-DDD dataset and the public drowsy driver dataset NTHU-DDD. The experimental results show that our proposed architectures outperform the former schemes. The highest performance was 86.60% in proposed CNN+LSTM with 60 seconds video.","#Drowsiness, #Vehicle-based measurement, #Physiological measurement, #Behavioral measurement CNN, #LSTM, #3DCNN, #Spatial, #Temporal, #Deep learning, #Training data, #Dataset"
대화록 자동화를 위한 딥러닝 기반 한국어 화자분리방법,2019,"최근 다양한 가정용 음성인식 AI 스피커가 등장하면서, 이를 비즈니스영역에서도 활용하고자 하는 논의가 이뤄지고 있다. 특히 음성데이터를 많이 보유하고 있는 비즈니스 영역에서는 수작업으로 해오던 대화록 작성 등의 작업에 이 기술의 적용을 고려하고 있다. 만약 두 사람 또는 그 이상의 사람들 사이에서 일어나는 대화내용을 화자별로 텍스트화 할 수 있다면, 수많은 음성데이터로부터 고객의 다양한 니즈와 인사이트 및 심리 상태 등을 개인화 하여 이해할 수 있을 것으로 예상된다. 하지만 현재 지원되는 여러 음성인식 API로서는 요구를 충족하기에 한계가 있으며, 주요 원인은 여러 사람 간의 대화 데이터에서 개별 화자를 분리하는 문제(Speaker Diarization)가 MFCC와 같은 기존의 음성 특징으로서는 성능에 한계가 있기 때문이다. 특히 사전에 화자의 음성을 알지 못한 상태에서 개별화자를 분리해 내는 화자독립 음성분리(Speaker independent diarization)가 수많은 상담사와 고객의 음성을 분리해내는데 가장 필요한 기술이기 때문에 최근 이 문제를 해결하려는 다양한 방법론 및 실험들이 이루어 지고 있다.
본 논문에서는 대화내용을 화자별로 분리 및 텍스트화 하여 대화록을 작성하는 실험을 통해 자동화 대화록의 상용화의 가능성을 확인해보았다. MFCC특징을 활용한 기존의 화자분리 기술과 딥러닝 기술을 활용하여 음성특징을 추출하고 이를 MFCC를 대체하는 음성특징으로 활용한 화자분리를 비교 연구하였고 더불어 제시된 방법으로 각각 분리 처리된 음성데이터를 Google과 IBM의 음성인식API를 사용하여 텍스트로 변환하였다.

With recent emerge of home speech recognized AI speakers in the market, companies and businesses are actively discussing and seeking ways to utilize AI Speaker in their business. Business sector that processes larger volume of voice data have high interest in adaptation and application of AI Speaker technology to replace many of manual works such as conversation transcription. Using this technology, any conversation between two or more people can be put in a text form by each distinguishable speaker. Through accumulated voice data, it is expected that personalized response and feedback that understands each customer’s needs and insights as well as meeting their psychological states will be possible.
Current speech recognition APIs, however, have its limitations in meeting the needs and requirements. The main reason is that the problem of separating the individual speakers from the conversation data between several people (Speaker Diarization) is limited in the performance of existing speech features such as MFCC. Speaker independent diarization, which separates individual speakers without knowing the speaker''s voice in advance, is the most necessary technology for separating the voice of many telemarketers and customers.
In this paper, through separation of each speaker from the conversation and transcription of its contents in a text form, feasibility for commercialization of automated dialogue record was tested. Comparison study for Deep learning-based audio feature and MFCC was conducted and Google and IBM speech recognition APIs were used for speech to text transformation afterward.","#Speaker Diarization, #Deep learning, #MFCC, #Automatic Transcription, #Korean language processing"
딥러닝을 이용한 가금류질병 모니터링 및 경보시스템 구축에 관한 연구,2019,"본 연구는 반복되는 조류독감 및 가축 전염병의 확산으로 인해서 발생되는 대량의 가금류 살처분과 토지와 지하수 등 환경의 오염을 방지하기 위해서 이미지 분석을 통한 가금류의 질병을 탐지하는 것을 목적으로 두고 연구를 진행했다. 현재의 시스템은 농가의 자발적인 신고에 의존하는 구조라서 신고가 늦어지면 이미 질병이 확산되어진 경우가 많았다. 본 논문에서는 농가의 자발적인 신고에 의존하는 구조에서 농가의 CCTV를 활용한 가금류의 이미지를 분석하여 의심증상이 발생되면 이를 자동으로 방역기관에 보고하는 구조를 제안한다. 이를 위해서 질병의 여러가지 지표 중에서 특히 닭의 경우 닭 볏의 색깔의 변화를 주요 생체표지자(BioMarker)로 삼고, 동일한 조건하에서 닭 볏의 색깔의 변화만으로 정상인 닭과 비정상인 닭을 구분하는 것을 목표로 삼았다. 실험에 사용된 Dataset 은 검색을 통해서 정상인 닭의 이미지를 모았으며 정상인 닭의 이미지에 볏의 변화를 합성해서 아픈 닭의 이미지를 만들었다. 이미지 분류에서 대표적으로 사용하는 CNN의 기법 중 Google의 Inception-v3의 Transfer Learning 모델을 사용했다. 실험의 결과로 사람이 판단할 수 있는 수치의 정확도를 보이는 결과를 보여줬다. 닭 볏의 색깔 변화가 Biomarker 로 분류기에서 제대로 분류되고 있다는 유의미한 결과를 보여주었다. 본 논문의 공헌사항은 닭의 이미지를 분석해서 질병을 예측하고 보고하는 과정이 자동으로 되기 때문에 질병을 조기에 발견하고 병의 확산을 막는데 기여할 수 있다.",
딥러닝 방식의 웨러어블 센서를 사용한 미국식 수화 인식 시스템,2019,"수화는 청각장애인이 다른 사람들과 의사소통을 할 수 있도록 설계되었다. 하지만 수화는 사회에서 흔하게 사용되지 않는다. 청각장애인과 사회간의 의사소통격차는 여전히 해결되지 않은 문제이다. 따라서 본 연구는 딥러닝 방식을 이용한 스마트웨어러블과 미국식 수화인식 시스템의 설계 및 구현에 초점을 맞추고 있다. 제안된 스마트웨어러블시스템은 센서퓨전기술을 이용해서 손등과 손가락에 올려놓은 총 6개의 IMUs(Inertial Measurement Unit) 센서로 구성되었다. 이 스마트웨어러블센서는 비젼기반접근방식에 비해 이동성과 자유도가 더 높다. 이 연구에서는 27개의 단어기반(ASL) 이 있으며 1개의 비단어기반(non-ASL) 제스처(동작없이 완전히 열린 손가락)가 제안되었다. 또한 이 연구에서는 미국식 수화가 27개 있고 비미국식 수화제스처(동작없이 완전히 손가락을 벌린 제스처)가 제안되었다. 제안된 모든 제스처는 5개의 미국식 수화 구성요소를 기반으로 선택되었다. 그 5개 미국식 수화 구성요소가 움직임, 손모양, 방향, 관절위치 및 얼굴과 신체제스처가 있다.

실험결과에 따르면 이 미국식 수화 인식시스템은 스마트웨어러블센서로부터 얻은 자이로스코프(G), 가속도(A), 방향(O) 및 쿼터니온(Q) 등 제안된 모든 센서데이터를 활용하여 최고의 성능을 발휘했다. 이 모든 센서데이터는 최첨단시계열분류모델인 LSTM (long short-term memory) 신경망 모델에 의해 훈련되었다. 이 모델은99.81%의 최고평균정확도를 달성했다. 더욱이, 실험결과는 표준편차 (STD) 로 계산된 평균 (MEAN)으로 계산된 형상에 비해 성능이 더 좋았지만, 시스템은 두 가지 조합 (STD + MEAN)을 모두 사용할 때, 가장 잘 수행되는 것을 보여주었다. 또한 LSTM 신경망 모델은 보류검증(hold-out validation) 및 10배 교차 검증(10-fold validation)이었던 두 가지 검증으로 모델 유효성을 검사과 비교했다.

높은 정확도를 통해서 이 제안된 웨어러블(미국식 수화 인식시스템)은 청각장애인들의 실제 상황에서 통역 역할을 할 수 있는 높은 가능성을 제시하였다. 또한 청각장애인과 사회간의 사회적 격차를 줄일 수 있는 큰 잠재력을 보여주었다.

Sign language was designed to allow deaf and dumb communities to communicate with others. However, sign language was not common to the society. The communication gap between the communities and society
was still an unresolved issue. Thus, this study was focusing on the design and implementation of the smart wearable American Sign Language (ASL) word-based recognition system using deep learning method. This proposed system applied sensors fusion technique to compose a wearable sensors that consist of six inertial measurement units (IMUs) that placed on the back of hand palm and each fingertip. Compared to the vision-based approach, this smart wearable sensors device offered higher mobility and freedom of movement. Additionally, there are 27 word-based ASL and 1 non-ASL gesture (fully opened finger with no movement) were targeted in this study. All of these proposed gestures were chosen based on five ASL components accordingly, namely movement, handshape, orientation, location of articulation, and facial and body gesture.

The experiment results indicated that this ASL recognition system performed the best by utilizing all proposed sensors data, including gyroscope (G), acceleration (A), orientation (O) and quaternion (Q) that obtained from the smart wearable sensors. All of these sensors data were trained by a state-of ?art time series classification model, the long short-term memory (LSTM) neural network model. This model achieved the highest mean accuracy rate of 99.81%. Moreover, the experiment results also revealed that features computed with standard deviation (STD) had better performance than features computed with mean (MEAN) but the system performed the best with both combined (STD + MEAN). The LSTM network model also validated and compared with two validation approaches which were hold-out and 10-fold crossvalidation.

As the result, this proposed ASL recognition system presented high feasibility to serve as an interpreter for the deaf and dumb communities in their real-life situations. Nevertheless, it also showed a great potential to reduce the social gap between deaf and dumb communities and the society.","#Human-computer interaction, #wearable sensors, #deep learning, #sign language"
적외선 체열 영상을 이용한 요추 추간판 탈출증 예측 딥러닝 알고리듬 개발,2019,"More than 80% of modern people experience lumbar herniated intervertebral disc called disc. It is caused by excessive exercise and external shock. MRI, CT, X-ray and spinal angiography are used as methods to diagnose diseases, but they are harmful and invasive and expensive to diagnose. A method of diagnosing lumbar intervertebral disc herniation using infrared thermography is attracting attention as a diagnostic method to overcome the disadvantages of existing diagnostic methods. It is important to know the temperature difference between the left and right sides of each area by analyzing the average temperature of the body surface to diagnose lumbar intervertebral disc herniation using infrared thermographic images.
However, there is a disadvantage that the medical staff has to manually display the region of interest when determining the difference in temperature between the left and right, and there is a drawback in that it may be misdiagnosed due to a mistake.
Therefore, the algorithm proposed in this study automatically improves the discomfort of the medical staff and shows the intermediate process and results of each system as image and temperature values, And suggests it as an auxiliary role of the diagnosis decision of medical staff.
In this paper, we used images of the leg anterior and posterior, and plantar of the infrared thermography of patients with lumbar herniatied intervertebral disc. U-Net model of CNN technique was used to divide each region according to skin temperature segment. The performance accuracy of U-Net was evaluated by grasping the IOU. The accuracy of the U-Net was 70% on the leg anterior and posterior and 80% on the plantar.
If the temperature difference between the right and left shows a temperature difference over a certain temperature, it is judged that there is a disease and it is displayed on the image and used as learning data of disease prediction model(VGG-Net). The VGG-Net model for predicting the location of the disc herniation compares four of the six structures and finds the most appropriate VGG-Net model. As a result, it is found that is the most optimized model for epoch 100, batch size 30 and dropout 0.3 of VGG11. The mean accuracy of combined leg anterior and posterior, and plantar was 97.71%, L4/5 sensitivity was 98.88%, L5/S1 sensitivity was 98.85% and specificity was 95.4%.
If the lumbar herniated intervertebral disc predicted algorithm is applied to the infrared thermography device, it is expected to be used more because it is non-invasive and harmless to the human body. Also, it will be improved by automatically performing the inconveniences for the medical staff to manually display the area of interest to grasp the left and right temperature difference. Display the intermediate process and results of the system as images and temperature values and show them to the medical staff. By predicting the disease, it plays a role in the diagnosis decision of the medical staff.
Future research will conduct using transfer learning, developing software that can be combined with existing devices, using DNN, and developing using standardized thermal data.","#Lumbar Herniated Intervertebral Disc, #Digital Infrared Thermal Imaging, #Infrared Thermography, #Deep Learning, #U-Net, #VGG-Net"
테스트 자동화를 위한 딥러닝 기반 GUI 컴포넌트 탐지 기법,2019,"GUI 테스트 자동화를 위해 많은 연구들이 제안되어 왔으나 시스템 탐사에 긴 시간이 소요되는 문제는 여전히 해결해야 할 과제로 남아있다. 소프트웨어 개발 과정이 점차 가속화 되는 추세를 고려했을 때 테스트 자동화 도구가 실제적으로 효용성을 지니기 위해서는 짧은 시간 안에 효율적으로 탐사를 수행하는 것이 요구 된다.
그러나 실세계에서는 상태 공간을 확장 시켜 결과적으로 탐사 시간을 지연 시키는 요인들이 존재한다. 첫 번째는 맥락적으로 동일한 상태를 정확히 판별하지 못하여 중복된 상태들을 다수 생성하는 경우이다. 이와 같은 문제를 해결하기 위해 fuzzy matching 기법이 널리 사용되고 있으나 배너 광고와 같이 동적으로 변화하는 GUI 컴포넌트의 존재는 fuzzy matching의 정확도를 떨어트리는 요인이 된다. 두 번째는 복잡한 GUI 컴포넌트를 적절히 다루지 못하는 경우이다. 예를 들어 파일 접근이 필요한 어플리케이션의 경우 파일 시스템 구조를 따라 필요한 파일의 경로를 찾아가는 과정이 요구되지만 trial and error 방식으로는 이러한 동작을 찾아낼 가능성이 무척 떨어진다.
우리는 이러한 문제들을 개선하기 위해 딥러닝 기반의 기능적 GUI 컴포넌트 탐지 모델을 제안한다. 우리는 제안한 모델을 통해 1)fuzzy matching 수행 시 동적으로 변화하는 GUI 컴포넌트를 제외하여 정확도를 높이고 2)복잡한 GUI 컴포넌트를 효율적으로 다루기 위해 미리 작성한 스크립트를 사용하여 불필요한 동작을 줄인다.
우리는 탐지 모델을 구현하기 위해 GUI 레이아웃 구조 정보를 학습 대상으로 삼았으며 TBCNN 기법과 fast R-CNN 기법을 활용하였다. 그 결과 관련 연구들과 비교하여 1.6%의 recall 향상, 10.3%의 precision 향상을 확인할 수 있었다.
마지막으로 우리는 상태 공간에 미치는 결과를 확인하기 위해 안드로이드 어플리케이션들을 대상으로 삼아 실험을 진행하였다. 그 결과 content similarity와 structure similarity에 대해 각각 6%, 9% 수치 향상과 5%, 8%의 오류 개선을 확인할 수 있었다. 또한 탐지 모델을 바탕으로 화면에 배치된 다양한 GUI 컴포넌트들을 타겟팅한 처리가 가능하며 작성한 스크립트를 기반으로 복잡한 GUI 컴포넌트에 적절한 대응이 가능함을 확인하였다.

Many studies have been proposed to automate GUI testing, but they still require very long time to exploit system enough. Following the trend that software development cycle continue to be shorten, it is necessary to finish exploit in short time for test automation tool to be practically effective.
But there are two factors that expand state space and consequently delay exploration time. The first is that the contextually equivalent states are not accurately determined, creating a number of overlapping states. Fuzzy matching can be used to address this problem but the presence of dynamically changing GUI components, such as banner ad, is a factor that reduces the accuracy of fuzzy matching. The second is when complex GUI components are not adequately addressed. For example, applications that work with opening file require a process of navigating the path to the expected file, but trial and error methods are unlikely to find this action sequence.
We propose a deep learning-based functional GUI component detection model to improve these problems. Through the proposed model, 1)we eliminate dynamically changing GUI components to improve fuzzy matching accuracy, and 2)reduce unnecessary behavior using pre-defined scripts to efficiently handle complex GUI components.
We have used the GUI layout structure as a learning data and used TBCNN and fast R-CNN to implement the detection model. Results show 1.6% improvement in recall and 10.3% improvement in precision compared to related works.
Finally, we conducted an experiment with Android applications to see how our model affect on the state space. As a result, state similarity measurement got improved 6% and 9% and error got reduced 5% and 8% each for content similarity and structure similarity. Also we found that the various GUI components placed on the screen could be handled with targeting region and that the complex GUI components could be adequately handled with the pre-defined scripts.","#GUI testing, #test automation, #multiple object detection, #deep learning, #fast R-CNN"
이미지 에지 강화를 이용한 딥러닝 기반의 세멘틱 세그멘테이션 성능 향상,2019,"최근 시스템 자동화나 인공지능에 많은 관심이 집중됨에 따라 머신 러닝과 컴퓨터 비전 분야에서 활발한 연구가 진행되어지고 있다. 다양한 영상 처리 시스템 중에서 특히 Deep learning분야의 하나인 Convolutional Neural Networks(CNN) 기술이 빠른 속도로 연구되어 여러 분야에 적용되고 있다. 또한, CCTV, 자율 주행, 의료 및 군사와 같은 특정 분야에서 사용되는 영상 처리 시스템은 영상을 인식하고 분류함에 있어서 높은 정확성을 요구하고 있기 때문에 기존의 Convolutional Neural Networks(CNN)을 응용한 Object Detection이나 Semantic Segmentation, Instance Segmentation과 같이 다양한 영상 처리 기술들이 개발되어지고 있다. 본 논문에서는 영상의 에지 강화를 이용한 전처리 과정을 통하여 Semantic Segmentation신경망의 학습과 실험에 사용되는 dataset의 품질을 향상시키고 기존 Semantic Segmentation신경망의 정확도를 높이는 연구를 진행하였다. 실험은 SegNet[1]과 MFNet[2] 신경망에서 진행되었으며, 학습 및 실험 dataset은 Multi-spectral Object Detection Dataset을 이용하였다. 실험 결과 기존의 SegNet과 MFNet 신경망 구조 대비 전처리 기법을 적용하였을 경우에 mIoU 값이 약 3% 정도 향상된 것을 확인하였다.

Recently, much attention has been focused on system automation and artificial intelligence, and active research is underway in the fields of machine learning and computer vision. Among various image processing systems, Convolutional Neural Networks (CNN) technology, which is one of the deep learning fields, has been rapidly studied and applied to various fields. In addition, image processing systems used in specific fields such as CCTV, autonomous navigation, medical and military require high accuracy in recognizing and classifying images. Therefore, Object Detection or Semantic Segmentation, and Instance Segmentation have been developed. In this paper, we study the improvement of the quality of the dataset used in the learning and experiment of the Semantic Segmentation Neural Network and the accuracy of the existing Semantic Segmentation Neural Network through preprocessing using edge enhancement of the image. Experiments were performed on SegNet [1] and MFNet [2] neural networks, and the learning and experimental datasets were performed using Multi-spectral Object Detection Dataset. Experimental results show that the mIoU value is improved by about 3% when the preprocessing technique is applied to the existing SegNet and MFNet neural network structures.","#Convolutional Neural Networks, #Semantic Segmentation, #SegNet, #MFNet, #Edge Enhancement"
딥러닝을 활용한 IoT 센서 데이터 처리에 관한 연구,2019,"최근 사물인터넷(Internet of Things, IoT)이 4차 산업혁명의 핵심 기술로 부상하였으며, 이에 따라 센싱 기술을 활용한 분야가 확대되고 있다. 유무선 센서로부터 획득한 일련의 시계열 데이터를 효율적으로 처리하기 위해 다양한 데이터 마이닝 기술이 적용되고 있다. 이러한 시계열을 해석하고, 직관적인 분석을 통해 예측이나 분류 모델을 생성함과 같은 다양한 응용이 가능하다. 특히, IoT 시스템에서는 실시간으로 수집되는 시계열 데이터를 분석하여 수요에 맞는 정보를 제공해야하기 때문에, 우수한 성능 보장과 동시에 지속가능한 배터리 소모량에 따른 에너지 효율성을 고려해야한다.

본 연구에서는 복수의 시계열 데이터를 분석하고, 이를 처리하기 위한 효율적인 시스템을 제안한다. 에너지 효율성이 높은 소음 센서를 활용한 연구, 기존의 다종류의 센서 데이터와 비교하여 분류 효율성이 높은 소리 데이터를 분석하는 연구, 그리고 압력 센서를 활용하여 점수 자동화를 수행함으로써, 데이터를 효율적으로 처리하는 연구를 제안한다. 마지막으로 특징 선택 기법을 적용하여 데이터 축소를 도모하고, 이로 인해 분류 효율성을 증대하는 연구를 제안한다.

가정 내의 넓은 활동 반경을 가지는 반려견의 소리 데이터를 취득하기 위해서는 무선 센서 네트워크를 적용해야한다. 그러나 기존의 소리 센서는 데이터를 수집하고 전송하는 데에 있어서 많은 양의 전력을 소비하게 되는 단점이 존재하여 실시간 시스템에 적합하지 않다. 에너지 효율성을 개선하기 위해 본 연구에서는 소음 센서(LM-393)를 사용하여 반려견의 소음 강도 데이터를 수집하고, 반려견의 소리 이벤트(짖는 소리, 으르렁 거리는 소리, 울부짖는 소리, 그리고 우는 소리)를 효과적으로 분류하는 방법을 제안한다. 그러나 소리 신호의 모든 정보가 아닌 강도 정보만을 활용하기 때문에 높은 분류 정확도를 획득하는 것은 어렵다. 이러한 분류 정확도의 저하를 최소화하기 위해 Bicubic interpolation을 적용하였으며, 최종적으로 시계열 데이터 분석에 적합한 딥러닝 모델인 Long short-term memory-fully convolutional network(LSTM-FCN)를 통해 반려견의 소리 이벤트를 분류하였다. 제안한 방법의 유효성 검증을 위해 기존의 소리 센서를 활용한 특징 추출(MFCC, Spectrogram, mel-spectrum)과 기계 학습 기법(SVM, K-NN 알고리즘)을 적용한 방법과 비교 실험을 진행하였다. 실험 결과, 일반적인 소리 센서를 활용한 방법에 비해 정확도가 크게 저하되지 않은 반면에, 약 10배의 에너지 효율성 개선을 확인한다.

추가로, 본 연구에서는 다양한 분야의 시계열 데이터를 효율적으로 처리하는 방법을 제안한다. 소리 센서와 압력 센서를 활용한 연구, 그리고 시계열 분석의 대표적인 예시인 네트워크 트래픽 분석에 관한 연구를 소개한다.

소리 센서로부터 획득한 데이터는 전력 변압기의 이상상황 탐지를 위해 활용된다. 이는 유입식 전력 변압기의 외부 소음 데이터를 취득하고, MFCC 특징 벡터를 추출하여 Shpelets 알고리즘을 통해 정상과 비정상 상태의 전력 변압기를 분류한다. 설치 기간이 3년 이상의 전력 변압기를 98.5%의 분류 정확도로 탐지하는 방법을 제안한다.

압력 센서로부터 획득한 데이터는 요가 자세 평가 모델을 생성하기 위해 활용된다. 전도성 섬유 기반의 압력 센서를 이용하여 피험자의 요가 자세 데이터를 수집하고, 수집된 데이터를 바탕으로 올바른 요가 자세 지도를 위한 자동화된 점수화 모델을 생성하는 방법을 제안한다.

네트워크 트래픽 데이터는 비정상 트래픽 탐지를 위해 활용된다. 오픈 데이터 셋인 NSL-KDD 패킷 데이터 셋을 활용하여 비정상 상황을 탐지한다. 패킷 데이터 셋은 다종류의 공격 패킷 리스트로 구성되어 있으며, 이에 따른 다수의 패킷 특징이 존재한다. 이러한 다수의 특징을 감축시키기 위해, 특징 선택 기법을 통해 차원 축소를 도모하고, 분류기인 Shapelets을 적용하여 정상과 비정상의 패킷을 분류하는 방법을 제안한다.","#Deep learning, #IoT System, #Sensor, #Energy efficiency, #Classification"
딥러닝 알고리즘과 국소 커널회귀법에 기반한 비정형 소화물 탐지 알고리즘 개발,2019,"Recent trends in industrial robot development are automation for reducing labor
costs, working in dangerous environments, and increasing efficiency in repetitive
tasks. Specially, automation of the picking process to acquire parcels location
information in the online shopping mall logistics could not be achieved by lack of
skill in the detection of the parcels. In addition, the parcels at the online shopping
mall logistics center is sold by the piece and is various in sizes and shapes. Moreover,
the parcels are various in packaging forms such as unpacked forms, box packaging
forms and plastic packaging forms, etc. Therefore, a new detection algorithm to pick
these atypical parcels is positively necessary.
The purposes of this thesis are firstly to develop an atypical parcel detection
algorithm based on a deep learning algorithm and a local kernel regression method
using Kinect camera and secondly to design a posture controller for the end-effector
of a 7-link manipulator to move the extracted the bounding box location of the parcel
with a desired velocity of its end effector. To do these tasks, the followings are done.
Firstly, the system used in this thesis consists of a 7-link manipulator for moving
end-effector to the atypical parcels and an image processing system for detecting
atypical parcels are used for this thesis. Secondly, a new detection algorithm for
detecting atypical parcels is proposed. The proposed detection algorithm consists of
4 steps: detecting central pixel of bounding box of atypical parcels using a deep
learning algorithm, obtaining 3D depth map of parcels using Kinect camera,
detecting the edge of a parcel surrounding the central pixel of the bounding box using
a local kernel regression method, and extracting central location of the bounding box.
Thirdly, forward kinematics modeling and Jacobian matrix of the 7-link manipulator
are described. Fourthly, moving the position of the end-effector to the extracted
bounding box location of the parcel and tracking angular velocity of the end effector
is controlled by a controller based on differential kinematics. Finally, experiment
results are shown to verify the validity of the proposed detection algorithm method
compared to Canny method and of the designed controllers results.","#parcel, #deep learning algorithm, #3D point cloud, #local kernel regression method, #7-link manipulator, #Kinect camera, #differential kinematics, #controller"
심층 합성곱 신경망을 이용한 딥러닝 기반의 온톨로지 자동 생성 프레임워크,2019,"지식 베이스 시스템은 전문가가 가지고 있는 전문 지식을 지식 베이스에 저장하고, 그것을 해석하는 시스템으로써 미래 정보과학 분야에서 중요한 연구 과제 중 하나이다. 하지만 종래의 지식베이스 시스템은 특정 문제 해결을 수행하는 전문가의 주관적인 경험 지식을 규칙 베이스화 하는 데에 주목적이 높여져 있다. 게다가 기존의 지식 베이스에 지식을 쌓아 올리는 기술에 대한 연구 또한 부족한 실정이다.
본 논문에서는 앞으로 새로운 발전에 필수적인 기술로써 공유 가능한 지식 베이스를 제안하고 그 위에 지식을 쌓아 올릴 수 있는 딥러닝 기반의 온톨로지 자동 생성 프레임워크를 소개한다. 제안하는 온톨로지 자동 생성 프레임워크는 지금까지 알려진 온톨로지 자동 생성 시스템보다 의미적 관계를 표현하는데 있어서 성능이 뛰어나다. 주장의 적절성을 뒷받침하기 위해 영상에 나타나는 인물(Person)-행위(Activity) 쌍 간의 의미적 관계를 심층 합성곱 신경망 기반의 인물(Person) 분류 모델과 행위(Activity) 분류 모델을 활용하여 프레임워크 평가를 수행하였다.
평가를 위한 실제 실험 데이터로써, 유명한 드라마 ‘미생’ 에피소드에 대해 인물 인식을 수행한 결과 F1 score 98.2%, 행위에 대해 F1 score 61.4%의 성능을 보여 제안한 온톨로지 자동 생성 프레임워크의 적절성을 뒷받침하였다. 따라서 심층 합성곱 신경망 기반의 온톨로지 자동 생성 프레임워크를 통해 통상적인 온톨로지의 설계 및 구현, 지식 생성에 발생하는 비효율적인 시간 비용을 줄일 수 있다.

The knowledge base system is one of the important research tasks in the field of future information science as a system for storing the expertise held by experts on the knowledge base, and interpreting it.
Traditional knowledge base systems, however, have become more focused on rule-based the subjective experience knowledge of experts performing specific problem solving. Moreover, there is also a lack of research on skills to build knowledge on existing knowledge bases.
This paper introduces the automatic Ontology Generation Framework based on deep learning that can propose a shared knowledge base as a technology essential for new development in the future and build up knowledge on it.
The proposed automatic Ontology Generation Framework is more capable of expressing semantic relationships than the ontology automatic generation systems known to date. To support the adequacy of this argument, the semantic relationship between the pair of person-activity appearing in the video frame was evaluated using face identification model with the use of deep convolutional neural networks(CNNs) and activity classification model.
Experimental results of facial recognition of the famous drama ''Misaeng'' episodes showed the performance of F1 score 98.2% and F1 score 61.4% for action recognition to support the appropriateness of the proposed automatic Otology Generation Framework.
Thus, Deep learning-based automatic Ontology Generation Framework by using Convolutional Neural Network can reduce the inefficient time costs of designing and implementing ordinary ontology and generating knowledge.",#컴퓨터공학
딥러닝 스타일 트랜스퍼 기법을 통한 자율 주행에서의 차량 인식,2019,"자율주행차량의 상용화와 더불어, ADAS 시스템에 대한 중요도 또한 높아지고 있다. ADAS 시스템을 위한 많은 알고리즘이 연구되어 왔고, 그 중에서도 기본적인 기술임과 동시에 인명과 가장 밀접한 차량 인식 기법은 무엇보다 중요하다. 차량 인식에 대한 기술에는 크게 전통적인 이미지 처리 기법을 사용하는 방법과 딥러닝 기법을 사용하는 방법이 있는데, 두 종류의 방법 모두 낮에는 훌륭한 인식 성능을 보이지만 밤에는 그렇지 못하다. 그러나 야간이라는 상황은 자율주행차량이 마주할 수 있는 가장 빈번한 상황이므로 이 때의 차량 인식률에 대한 개선이 선도되어야 한다. 이러한 점에서 본 논문은 컬러 필터 기반의 이미지 스타일 트랜스퍼를 통해 야간에서도 차량은 잘 인식할 수 있는 기법을 제시하고자 한다. 제시된 방법의 성능 평가 결과는 실제 데이터셋을 이용하여 진행하였으며, 해당 결과를 통해 제시하는 논문이 기존의 기법보다 좋은 성능을 가짐을 보인다.

With the commercialization of self-driving cars, the importance of an advanced driver assistance system (ADAS) has emerged. Although many improved algorithms have been proposed, vehicle detection that is related to human lives is the most significant. For vehicle detection, there are traditional image processing methods and deep learning processing methods. Both are showing great performance during in daytime, however, not at nighttime. Although previous methods'' performance at nighttime is poor, the situation at nighttime occurs most frequently. In this context, the improving of poor performance at night should be preceded. To this end, we mainly focus on a suggesting the method which is able to detect the car robustly at nighttime using color filter-based image style transfer. The performance evaluation results of the proposed method are conducted through real-data experiments. The experiment results show that our method outperforms the others in terms of accuracy with an ideal.","#Style transfer, #자율주행, #CNN"
딥러닝을 이용한 레이다 재밍 기법 예측,2019,"Conventional methods for predicting a jamming technique in electronic warfare are based on a library in which a list of jamming techniques for radar signals are recorded. Howerver, the method depending on the library has a limitation when an unknown type of radar signal is received. In this paper, we propose two models to predict the jamming technique for radar signals by using the deep-learning method. First model is a deep neural network model that predicts jamming technique by directly extracting features such as statistical values, autocorrelation coefficients, and MFCC coefficients from radar signal. Second model is a deep learning model using LSTM that predicts jamming technique without extracting features from the radar signal. The proposed models can predict jamming technique for each radar signals without a library. The experimental results show that the proposed models can predict jamming technique for unknown type of radar signal.",
멀티태스크 딥러닝 학습을 이용한 화자 인식 재생 공격 검출 시스템,2019,"최근 음성을 이용한 본인 인증의 사용이 증가하면서 화자 인증 시스템을 속이기 위한 악의적 목적의 스푸핑(spoofing)이 시스템의 보안을 위협하고 있다. 스푸핑은 사전적으로 ‘속이다’라는 의미로, 오디오 스푸핑(audio spoofing)은 화자 인증 시스템을 속이기 위해 사용자의 음성과 유사한 데이터를 생성하는 것을 말한다. 오디오 스푸핑은 음성 합성, 음성 변조, 재생 공격 등의 방식을 통해 사용자와 유사한 음성을 생성할 수 있다. 이 중 재생 공격의 경우 다른 공격들에 비해 기술적인 진입 장벽이 낮음에도 불구하고 검출이 가장 어려운 것으로 알려졌다.

재생 공격은 화자 인식 시스템을 이용한 사용자의 음성 파일(이하 원본 음성)을 절도한 후, 절도한 음성 파일을 재생 및 재녹음하여 새로운 음성 파일(이하 기만 음성)을 생성하는 방식이다. 따라서 재생 공격에 의해 생성된 기만 음성은 재생 공격 과정에서 재생 기기 특성, 배경 잡음, 녹음 기기 특성에 대한 정보, 즉 재생 공격 환경에 대한 정보(이하 PER)를 반드시 포함하게 된다. 본 연구에서는 이러한 PER이 재생 공격 검출에 도움이 될 것이라 가정하여, PER을 다양한 방법으로 활용한 재생 공격 검출 시스템을 제안하였다. 일반적으로 재생 공격 검출은 재생 공격 여부를 확인하는 이진 분류로 진행된다. 하지만, 본 연구에서는 학습 시 PER을 추가 정보로 활용하여 기만 음성들을 세부적으로 분류할 수 있었고, 이를 통해 재생 공격 검출 성능 향상에 도움이 되는 것을 실험을 통해 확인하였다.

Replay attack is well known as the hardest attack to detect among various spoofing attacks against speaker verifications. Other attacks such as speech conversion and voice synthesis also include a playback phase that occurs after artifice of the genuine signal. Therefore, researchers have focused on detecting replay attack. We found that the replay configurations are added by replay attack is a unique feature of replayed signals. Replay configurations (PER) indicate the information of playback device(P), environment(E) and recording device(R). The performance of replay attack detection was improved using PER classification through multi-task learning framework. In this paper, we analyze various ways of utilizing PER. Various classifier modeling methods for scoring were also considered to improve the performance of replay attack detection system. Extensive experiments are performed on ASVspoof2017 dataset. Without additional datasets for training, experiment result achieves 6.49% of equal error rate which is better than the best performed system of ASVspoof2017 challenge.","#화자 인식, #화자 인증, #재생 공격 검출, #멀티태스크 러닝, #anti-spoofing, #spoofing detection, #multi-task learning, #speaker verification"
딥러닝과 ICP 알고리즘을 이용한 링형 물체의 실시간 3차원 자세 추정,2019,"Bin-picking is an important part of factory automation systems. In order for a robot to pick an object accurately, it needs to know the 3D pose of the object. In this paper, we propose a method of estimating the object''s pose using the infrared image and depth image acquired from the camera. The proposed method consists of two major module: one is to recognize an object in 2D image and the other is to estimate the 3D pose using the ICP algorithm in 3D data. In the first module, we propose a method to generate an integrated image with features of the depth image and the infrared image acquired by the camera. Next, we introduce a method of training the object detector based on deep-learning. If the objects are placed independently, it is easy to detect the object. However, it is difficult to recognize objects in a situation that objects with holes in the center are piled up. We solved this problem with depth-based filtering. In the second module, we introduce a way to overcome the drawbacks of depth-based filtering. We then used the ICP algorithm to estimate the 3D pose of the object.",
비전센서를 활용한 딥러닝 기반 주변 차량의 방향 정보 추정,2019,"본 연구에서는 주행 중 급변하는 주변 차량의 방향 정보를 검출하기 위해 단안 카메라 센서를 활용한 심층학습 기반의 합성곱 신경망 모델 설계에 대한 내용을 다룬다. 이는 현재 상용되는 주요 ADAS 센서 데이터의 물리적 한계를 극복하고, 높은 신뢰성을 갖는 차량의 방향 정보를 활용하여 보다 안정적인 첨단 운전자 보조 시스템(ADAS) 기능 개발에 활용될 수 있다. 또한, 가상환경 데이터셋을 활용해 훈련 모델의 성능을 평가 및 분석하고, 최종적으로 실제 모델의 일반화 성능을 향상시킬 수 있음을 입증한다.

제안하는 연구는 크게 4단계로 구성된다. 첫번째는 차량의 방향 정보(yaw각) 추정을 위한 네트워크 설계와 손실함수 정의, 두번째는 차량의 3차원 크기 정보(높이, 너비, 길이) 추정을 위한 네트워크 설계와 손실함수 정의, 세번째는 차량의 3차원 위치 정보(x방향, y방향, z방향) 추정을 위한 기하학적 구속조건 방정식, 마지막으로 가상 데이터셋 학습을 통한 실제 모델의 일반화 성능 향상에 대한 분석이다.

본 논문은 Karlsruhe Institute of Technology and Toyota Technological Institute at Chicago(KITTI)에서 자율주행플랫폼 연구를 위해 공개한 주행 데이터셋을 활용해 모델을 학습, 검증, 그리고 평가하였다. 성능 평가는 KITTI의 방향 검출 성능에 대한 공식 평가지표인 Average Orientation Similarity(AOS)가 활용되었으며, 마지막으로, 교내에서 자체적으로 수집한 실제 주행 데이터셋을 활용해 모델의 성능을 다시 한번 입증하였다.",#자동차공학
딥러닝 기반의 멀티모달 감정 인식률 향상을 위한 데이터 노이즈 및 신뢰도 연구,2019,"최근 딥러닝 모델을 이용한 감정 인식 연구 중 다양한 생체 신호를 분석하는 방법론이 조명되고 있다. 이때 감정 분류의 신뢰성에 가장 많은 영향을 끼치는 것은 학습 데이터의 종류에 따른 신뢰성 및 분류 방법이다. 생체 신호의 경우 데이터의 신뢰성이 노이즈 비율에 따라 결정되므로 노이즈 검출 방법이 우수할수록 신뢰도가 올라가며, 감정을 정의하는 방법론에 따라 그에 맞는 적절한 감정 평가 방법이 수반될 때 정확하게 감정을 분류할 수 있다. 본 논문에서는 Valence 및 Arousal 기준의 멀티모달 생체 신호에 대해, 생체 신호 데이터의 신뢰성을 검증하기 위한 고정 웨이블릿 기반의 노이즈 임곗값 설정 알고리듬과 Valence-Arousal 값에 따른 신뢰도를 설정하는 법, 그리고 학습시 데이터 신뢰도와 Valence-Arousal 신뢰도를 반영하여 감정 인식률을 향상하는 방법을 제안한다. 웨이블릿 변환을 이용해 신호의 웨이블릿 성분을 추출 후, 해당 성분의 왜도와 첨도를 구하여 햄펄 식별자를 통해 계산된 임곗값으로 노이즈를 검출한 후, 원신호에 대한 노이즈 비율을 고려하여 데이터의 신뢰성을 평가하고 가중치로 환산한다. 더불어 감정 데이터 분류 시 Valence-Arousal 평면의 각 사분면 중앙값과의 유클리디언 거리를 가중치로 환산하여 학습데이터량 조절시 두 요소를 반영한다. ASCERTAIN 데이터셋을 활용하여 나타난 감정 인식률 개선 정도를 통해 제안된 알고리듬의 성능을 검증한다.

Recently, a methodology for analyzing a variety of bio-signals in an emotion recognition study using a deep learning model is being studied. At this time, the reliability and classification method according to the type of learning data are the most influential to the reliability of the emotion classification. In the case of bio-signals, reliability of data is determined according to the noise ratio. Therefore, reliability of the noise detection method increases as the method of detecting the noise increases, and the emotion can be correctly classified according to the method of defining the emotion. In this paper, we propose a fixed wavelet-based noise threshold setting algorithm for verifying the reliability of bio-signal data for multi-modal bio-signals based on Valence and Arousal standards, a method for setting reliability according to Valence- We propose a method to improve emotion recognition rate by reflecting reliability and Valence-Arousal reliability. The wavelet component of the signal is extracted using the wavelet transform, the degree of kurtosis of the component is obtained, the noise is detected at the threshold value calculated through the hamburg identifier, the reliability of the data is evaluated in consideration of the noise ratio of the original signal Converted to a weight. In addition, when classifying the emotional data, the Euclidean distance from the median of each quadrant of the Valence-Arousal plane is converted to a weight, and the two factors are reflected when adjusting the amount of learning data. The performance of the proposed algorithm is verified through the degree of improvement of emotion recognition rate using ASCERTAIN dataset.",
딥러닝 기반 동해 고해상도 해빙 탐지와 마이크로파 자료와의 비교,서울대학교 논문은 저작권에 의해 보호받습니다.,"지구 시스템의 기본 구성 요소 중 하나인 해빙은 그린란드 빙하와 더불어 지구 온난화가 얼마나 진행되었고, 어느 정도로 심각한지 알려주는 지표로 대규모 환경 변화와 미래 기후 예측에 있어 무시 할 수 없는 변수이다. 1970년대 후반 수동 마이크로파(passive microwave, PMW)를 이용한 해빙 원격 탐사법이 제안된 이후로 현재까지 많은 연구들이 수행되고 있다.
동해 북부 연안과 타타르 해협에 형성되는 해빙은 플랑크톤의 번성과 해양 심충 순환을 유도하여 주변 해양 환경과 생태계에 큰 영향을 주고 있다. 본 연구에서는 1988년부터 30년간의 북반구 일평균 해빙 농도 자료를 활용하여 해빙의 시간에 따른 변동성을 살펴보았으며, Landsat 8 OLI/TIRS L1 영상 자료를 활용하여 해빙을 탐지하고, 탐지된 해빙과 수동마이크로파 해빙 농도 자료를 비교하였다. Landsat 8 영상에서의 해빙 탐지는 켤레 기울기 지표 역전파 (Scaled Conjugate Gradient backpropagation) 알고리즘으로 학습한 다중 퍼셉트론 신경망을 활용하였다.
타타르 해협 일대 지역은 고농도 해빙이 꾸준히 분호하고 있는 지역으로 10월중 형성되기 시작하여 여름인 7월 중에 급격히 소멸된다. 반면 연해주 해안 일대는 해빙이 주로 연안에 붙어 얇은 해빙으로 형성되며, 12월 중에 형성되어 평균 해빙농도 최고 15% 이하로 매우 옅게 형성되나, 봄철까지 일부 유지되는 것으로 나타난다.
각 층에서 14개, 8개, 4개의 뉴런으로 구성된 신경망을 학습시켜 Landsat 8 영상에서 해빙을 탐지하는 과정을 수립하였으며, 학습 결과 해빙의 경계를 잘 구분하여 주는 것으로 사료된다.
Landsat 8 자료를 이용하여 PMW 해빙 자료의 격자와 통일한 뒤 상호 비교 하였을 때, 구름에 의한 오차와 육지로 오염된 격자에 의한 오차가 나타났다.

Sea ice, one of the basic component of global climate system, is an indicator of how much global warming has progressed and how serious it is. And it is undeniable variable in large-scale environmental changes and prediction of future climate conditions. Since remote sensing of sea ice using passive microwave (PMW) has been proposed in the late 1970s, many studies have been conducted so far.
The sea ice formed on the northern part of the East Sea and the Tatar Straits induces not only the prosperity of the plankton but also the deep ocean circulation, which has a great influence on the surrounding marine environment and ecosystems.
In this study temporal variability of daily passive microwave sea ice concentrations data were estimated on northern hemisphere from 1988 to 2017(30 years). And detected sea ice using Landsat 8 OL I/ TIRS L1 images were compared with passive microwave sea ice concentration data. Sea ice detection in Landsat 8 images utilised a multi-perceptual neural network trained from the scaled conjugate gradient backpropagation algorithm.
The area around Tatar Strait is steadily covered with high-concentration sea ice. It begins to form in October and rapidly disappears during summer in July. On the other hand Primorye coastal sea ice area is mainly formed as a thin ice attached to the coast. It is formed in December and has a maximum of less than 15% of the average concentration, but it remains until the spring.
The neural network consisting of 14, 8, 4 neurons was trained and the process of detecting the sea ice in the Landsat 8 image was established.
When the Landsat 8 data were compared with the grids of the PMW sea ice data, there was an error due to clouds and an error due to contaminated grids on land.","#해빙, #수동 마이크로파, #Landsat 8 OLI/TIRS, #켤레 기울기 지표 역전파 알고리즘"
고속화도로 자율주행을 위한 영상 기반 딥러닝(DNN) 활용 ‘차로 위치 예측 및 변경 시스템’에 관한 연구,2019,"고속화도로에서 자율주행 차량이 적절한 시기에 출구를 빠져나가기 위해서 자기 차로 위치 판단은 중요한 요소이다. 사람의 눈은 넓은 시야를 갖고 있어 현재 몇 차로 위에 있는지 쉽게 알 수 있지만, 카메라를 통해 이를 파악하기 위해선 수많은 경우의 수가 프로그래밍 되어야 하며, 날씨에 의해 영상에서 차선이 불확실하게 보이게 되면 판단 오류가 생길 수 있다. GNSS와 INS로 차량 위치 예측을 하기에는 음영지역(빌딩 사이, 터널 안, 고가 아래 등)에서는 신호를 받기 힘들며 정밀도로지도를 사용하면 쉽게 해결될 수 있지만 전 세계에 구축하기에는 앞으로 얼마만큼의 시간이 걸릴지 모른다는 문제점들이 있다.
본 연구는 다른 센서보다 상대적으로 저렴한 단안 카메라를 기반으로 기계학습을 적용하여 출구가 있는 고속 및 고속화도로에서 현재 자율주행차가 몇 차로에 있는지 파악하고 바로 옆 차선이 점, 실선인지 판단하여 이동 가능한 차선인지, 불가능한 차선인지 파악한다.
결과적으로 단안 카메라를 이용하여 차로 위치를 파악하게 되면 고가의 센서나 많은 노동력과 시간을 사용해 현재 자기 차량의 차로를 검출하는 단점들을 보완할 수 있으며, 궁극적으로 출구의 위도를 파악하여 사전에 출구까지의 효율적인 전역 경로를 생성할 수 있으며, 자율주행 차량뿐만이 아닌 사람이 운전하는 비 자율주행 차량에서도 내 차로 위치를 파악해 출구로 빠져나가기 전에 차로를 이동해야 하는 알림을 주어 길을 잘못 들어서는 것을 미리 예방할 수 있을 것이다.

In autonomous driving, determining the position of the lane of the vehicle on roads is an important factor. The human eye has a wide field of view, so it is easy to see how many lanes are on the current road, but a number of cases have to be programmed in order to catch it through the camera, if the lane is vague to see due to sunlight or disturbance. Also, there would be signal disconnection errors in predicting with GPS signals and it is difficult to receive signals in shaded areas (between buildings, under tunnels, high elevations, etc.). Another problem nowadays is that we do not know how long it will take to build maps around the world with precision.
The purpose of this study is to find where autonomous vehicle is now located on the highway and expressway roads with applying machine learning based on one single camera image for autonomous vehicle. Also, it can be determined whether the lines next to the car are movable lines or not. Experiments have been carried out with a real autonomous vehicle.
As a result, it is possible to identify the position of a car by using a monocular camera, to compensate for the disadvantage of detecting a lane of a current car by using an expensive sensor or a lot of labor and time. Furthermore, it will also give information to normal car that we drive about a warning system to alert for us to move the lane before approaching exit, which will prevent you from getting in the wrong way.",
DNA 프로모터 및 RNA 스플라이싱 시퀀스 분석을 위한 딥러닝 모델 개발,2019,"Progress in sequencing technologies in recent years has resulted in a massive growth of genomic data. Interpretation of these data is needed as it paves the way for a complete understanding of all function and interactions of the genome. However, deciphering the complexity and sheer amount of information contained in such data requires the use of techniques capable of identifying highly complex patterns in large datasets.
A growing number of applications introduced statistical models and tools to study the genomic dataset. However, most of these applications use hand-crafted features in their design. Handcrafted features are usually not robust and difficult to construct, as this requires specific knowledge of the domain. Therefore, automated features selection based methods are required.
In the other hand, artificial intelligence (AI) has advanced rapidly, and now different machine learning based approaches demonstrate state-of-the-art per- formance in various fields and tasks. Accordingly, the application of machine learning in bioinformatics to gain insight from genomic data has been empha- sized. Using deep learning approaches (i.e. a subfield of machine learning) en- ables automatic extraction of both low and high-level features directly from the dataset without any need to have domain knowledge. Therefore, we embrace the potential that deep learning holds for understanding the genomic dataset.
This thesis aims towards the study of prediction and classification of ge- nomic sequences using deep learning. Through data mining and machine learning techniques, we trained various deep learning based models to perform two different tasks. The first task consists of quantifying alternative splicing through predicting Percent Spliced in (PSI) from RNA seq data. We have in- troduced a novel method for learning distributed feature representation from the cassette exons through the training of two NLP techniques word2vec and doc2vec. Next, these features were used to train a convolutional neural net- work and multilayer perceptron models. The second task consists of predicting the short eukaryote promoter sequences in case of human and mouse for both TATA and non-TATA promoter. In order to accomplish this task, we have de- veloped a deep learning model based on a combination of convolution neural network and bidirectional LSTM called DeePromoter. With this work, we are able to promote the use of this type of technologies to create new tools that could handle large amounts of biological data, further improve knowledge in the field of gene prediction.","#Alternative splicing, #Promoter sequences, #Deep learning, #Bioinformatics"
웹 어플리케이션에 대한 딥러닝 기반의 침입탐지시스템 설계 및 구현,2019,"최근 지능정보기술의 발달로 네트워크와 서비스가 서로 융합되어 진화하고 있으며 분산기술을 이용하여 컴퓨터 자원을 효율적으로 공유함에 따라 방대한 데이터의 효과적인 분석이 가능하게 되었다.
이것은 다른 한편으로 공격자에게 수 많은 보안위협의 경로를 제공하고 있는 것이 현실이다. 특히, 각 기관이나 기업에서 운영하고 있는 웹 서비스는 단순한 정보전달이나 홍보 목적외에도 국민이나 고객의 알권리, 마케팅, 개인정보전달 등 그 사용도가 높아지고 있다.
웹 서비스에 대한 사이버 침해공격이 발생하게 되면 기관이나 기업의 이미지 실추는 물론 신뢰도 하락 등 직접적, 간접적으로 매우 심각한 상황으로 전개되는 것이 일반적이다.
글로벌 보안업체나 연구단체에서 최근 발표한 어플리케이션 취약점에 대한 다양한 통계 보고서에서도 주요 웹서비스 취약점별 공격건수가 꾸준히 증가하는 것을 확인할 수 있다. 이러한 다양하고 지능화되는 웹 서비스 공격을 탐지하기 위해서는 보다 효과적인 보안위협 탐지 알고리즘의 개발이 요구된다.
이처럼 다변화하는 공격에 대한 실시간 대응책의 필요성이 제기되면서 보다 지능적인 침입탐지 모델의 설계를 위해 최근에는 일반적인 기계학습 기법을 넘어서 심층신경망 기술을 적용하기 위한 노력들을 확인할 수 있다.
그러나 현재까지 기계학습 또는 심층신경망의 보안위협탐지 모델과 관련된 연구들을 살펴보면 학습을 위한 고품질의 샘플데이터 확보가 어려우며, 데이터의 공격 유형이 TCP/IP 모델의 하위 계층인 네트워크 또는 전송계층에서 발생하는 디도스 공격이나 정보시스템 스캐닝 등 상대적으로 위협예측이 쉬운 특정 공격에 집중되어 있다.
따라서 본 논문에서는 다양한 공격경로로 사용되는 웹 서비스 프로토콜(HTTP)의 복잡한 구문 형태에 CNN과 RNN, 이 둘을 조합한 C-RNN 등의 심층신경망 알고리즘을 적용하여 침입탐지 성능을 평가한 결과 현재 보안시스템에서 탐지하기 어려운 사이버 위협에 우수한 침입탐지 성능을 나타냈다.

Recently, with the development of intelligent information technology, networks and services are evolving together and efficient sharing of computer resources using distributed technology enables efficient analysis of vast amounts of data.
On the other hand, this provides a path for a number of security threats to attackers. Especially, the web service operated by each organization or corporation is used not only for information transmission and promotion, but also for the right of citizens and customers, marketing, and personal information transmission.
If a cyber attack occurs on a Web service, it will generally worsen to a serious situation directly or indirectly, such as a drop in the image of institutions and companies as well as a decrease in reliability.
Various statistical reports on vulnerabilities in web applications recently released by global security companies and research organizations show that the number of attacks by major web service vulnerabilities has steadily increased.
In order to detect such various and intelligent web service attacks, it is required to develop a more effective security threat detection algorithm.
As the necessity of real-time countermeasures against such diversified attacks is raised, efforts to apply the deep-neural network technology beyond the general machine learning technique can be confirmed recently for designing a more intelligent intrusion detection model.
However, to date, it is difficult to obtain high-quality sample data for learning by studying the security threat detection model of machine-learning or deep-neural network. It is focused on specific attacks that are relatively easy to predict, such as DDOS attacks or simple system scans.
In this paper, we evaluate the intrusion detection performance by applying the deep-neural network algorithm to the cyber threat response limit of the current security system and the intrusion detection model to overcome it in the complex syntax form of the web service protocol(HTTP)",
딥러닝을 이용한 RNA 스플라이싱 특성 예측,2019,"Alternative splicing (AS) is the process of combining different parts of
the pre-mRNA to produce diverse transcripts and eventually different
protein products from a single gene. In computational biology field, researchers
try to understand AS behavior and regulation using computational
models known as “Splicing Codes”. The final goal of these algorithms
is to make an in-silico prediction of AS outcome from genomic
sequence.
In this thesis, we develop a deep learning approach for categorizing
the major classes of AS namely alternatively skipped exons, alternative
5’ss, alternative 3’ss, and constitutively spliced exons based only on the sequence of the exon junctions.
The proposed approach significantly improves the prediction and the
obtained results reveal that constitutive exons have distinguishable local
characteristics from alternatively spliced exons.

Using the Motif visualization technique, we show that the trained
models learned to search for competitive alternative splice sites as well
as Motifs of important splicing factors with high precision.
Thus, the proposed approach greatly expands the opportunities to
improve alternative splicing modeling. In addition, a web-server for AS
events prediction has been developed based on the proposed method and
made available at https://home.jbnu.ac.kr/NSCL/dsc.htm","#Alternative splicing, #Deep learning, #DNA, #RNA"
영상개체인식을 위한 딥러닝 알고리즘 비교,동국대학교 논문은 저작권에 의해 보호받습니다.,"In the 4th industrial revolution period, not only deep learning but also AI skills have been developed and used in many fields. New Algorithms which is based on the deep learning skill are constantly being reported in computer vision at particular.

Some problems could not be solved with the existing ways but can be done with the deep learning skills.
Our research analyzed the several objects which were in images and compared the algorithm objects understanding with others individually in the accuracy.

The result was that the understanding of SSD and YOLO was better than that of Faster R-CNN.
It was proven that there was no difference in their detection rates, in special, according to the number of frames. However, all algorithms recognition rates are getting better when the objects are big. Instead, the recognition rate of YOLO was much lower than that of other algorithms when the objects were small.",
Multi-channel deep-learning based auto defect detection using 3D feature fused optical system : 3D 특징 융합 광학시스템을 이용한 다중 채널 딥러닝 기반 자동 결함 탐지 시스템,2019,"제조업 분야에서 제품의 품질 향상을 위하여 제품의 결함을 발견하는 작업은 매우 중요하다. 자동화 시스템 개발로 인하여 영상처리 및 인공지능을 이용한 결함검사 시스템이 많이 발전되고 이에 따라 결함 검사를 위한 조명 시스템 또한 발전하고 있지만, 표면의 빛 반사가 심한 주조물의 경우 조명에 따라 결함 정확도 저하와 같은 문제점이 발생되고 있다. 본 논문에서는 이러한 문제들을 해결하기 위해 phtometric stereo 기법의 조명 시스템을 설계하여 획득한 데이터를 인공지능에 적용한 자동 결함 탐지 시스템을 제안한다.

In order to improve the quality of products in the manufacturing sector, it is very important to find the defects of the products. Due to the development of the automation system, a lighting based defect inspection system using image processing and artificial intelligence has been developed. However, to tackle the issues of high reflection of some casting products. In this research, we propose an automatic defect detection system applying artificial intelligence to data obtained by designing a lighting system of photometric stereo method to solve these problems.","#Deep learning, #Optical system, #Machine vision, #defect detection"
음악 감성 분석을 위한 딥러닝 기반 회귀 모델,2019,"혼인 ‘첫날밤’은 ‘혼인’이라는 공동체적 의례의 한 단계로서, 혼인의례의 유구한 역사와 함께 ‘첫날밤’과 그 주변의 담론들 역시 다양한 형태로 존재해왔다. 본 연구에서는 혼인 ‘첫날밤’이 반드시 신랑과 신부의 ‘성적 결합’이라는 의미를 내포하는 점에 착안하여, ‘첫날밤’에 관한 구술 서사 작품을 통해 담론의 형태로 전달되는 젠더 규범이 젠더 주체의 생산에 기여하는 측면에 주목하였다.
본고에서는 ‘첫날밤’ 성적 결합의 실패를 소재로 하는 구전이야기로 ‘첫날밤에 신부 살가죽 벗겨 죽인 신랑’과 ‘첫날밤에 소박맞은 세 자매’, ‘첫날밤에 신랑 재촉한 신부’, 그리고 현지 조사를 통해 채록한 ‘첫날밤’ 경험에 관한 구술 서사를 검토한다. 이들 서사는 각각 판타지적 ‘이야기’와 현실적 ‘경험담’으로서 ‘첫날밤’의 성적 결합에 관한 일상적 차원의 담론으로 기능하는데, 배타적으로 구성되는 연행 공동체에서 구술 연행되면서 연행에 참여한 이들의 젠더 관념과 젠더 경험 서사를 구성한다.
위의 ‘첫날밤’에 관한 구술 서사들은 1차적으로 ‘첫날밤’의 젠더 규범을 실어나르는 매개로 기능한다. ‘첫날밤’의 젠더 규범은 자연화된 이원적 젠더 구분과 이성애 섹슈얼리티에 기반하여 그것을 더욱 강화하는 방식으로 작용하는데, 이는 혼인 의례의 입사적 기능과 맞물려 ‘젠더화된’ 주체를 생산하고 ‘정상적인’ 섹슈얼리티의 형태를 규정하는 것으로 이어진다. 이를 통해 ‘첫날밤’이 개인간의 내밀한 사건이 아니라 공동체적 질서를 유지하는 기능적 사회 제도이며, 곧 ‘첫날밤’과 관련된 담론들이 ‘정상적’ 젠더·섹슈얼리티 형태로의 편입을 요구하여 개인의 젠더와 섹슈얼리티를 공공연히 통제의 영역에 놓는 젠더 규범 담론으로 기능한다는 점을 지적한다. 이러한 젠더 규범은 구술 전승의 전통 속에서 지식의 형태로 전승되며 그 영향력을 유지한다.
‘정상성’에 부합하기를 특별히 강조하는 ‘첫날밤’ 규범 담론의 특징은 ‘첫날밤’ 성적 결합에 관한 구술 서사의 담론 전략에서도 발견된다. ‘첫날밤’ 과정의 실패에 대한 불안을 끊임없이 자극하는 것, 성적으로 무지한 신랑과 신부를 조롱하여 웃음거리로 삼는 것, ‘첫날밤’을 성적 농담의 소재로 삼아 성적 행위와 쾌락을 신화화하는 것이라는 담론 전략은 ‘첫날밤’ 젠더 규범의 전달에 기여하고 정상성과 동질성에 대한 요구를 강하게 전달하여 규범 담론의 보수적인 속성을 나타낸다.
‘첫날밤’에 관한 구술 서사는 젠더 규범을 전달하는 담론인 동시에 젠더 규범의 한계를 폭로하고 균열을 드러내는 담론으로도 기능한다. 규범이 그에 들어맞지 않는 것을 배제하는 방식으로 구성되거나, 규범의 정확한 내용은 제시되지 않으면서 ‘규범적이어야 한다’는 태도를 내세움으로써 행위자들로하여금 규범에 자발적으로 순응하게끔 하는 ‘첫날밤’ 젠더 규범의 수행적 효과로부터 규범의 한계가 드러난다. 나아가 서사 속에서 젠더 규범 수행에 ‘과잉’이 존재할 뿐 아니라 그 결과로 인물들이 비극적인 결과를 맞게 되고, 표면화된 규범적 한계가 회피되거나 탈규범적 요소가 규범 담론과 충돌하는 지점이 나타나는 등 젠더 규범의 균열적인 징후들이 발견된다.
결국 ‘첫날밤’에 관한 구술 서사는 젠더 규범 담론으로 기능하는 동시에 규범의 한계와 균열을 드러내는 입체적인 텍스트이다. 이처럼 규범 담론이 한계를 내포한 채로 담론장에 머무르는 것을 통해 자연화된 규범의 위치가 의심되고, 규범의 틀에 부합하지 않는 다양한 삶에 대한 상상력이 확장될 수 있을 것이다.","#Multilayer perceptron (MLP), #MLP, #mood detection, #music, #transfer learning, #global average pooling (GPA), #GPA, #다층 퍼셉트론, #감성 감지, #음악, #전달 학습"
딥러닝을 활용한 백색광 주사 간섭계의 3차원 형상 측정 기법 연구,2019,"최근 많은 산업 분야에서 높이가 수 um 수십 um 에 불과한 미세 표면 형상 을 가진 제품 을 연구 및 제조 하 고 있다 이런 미세 표면 형상을 가진 제품은 제조 후 정확한 표면 형상을 측정할 필요가 있 는데 이때 필요한 것이 삼차원 표면 형상 측정 기술이다 삼차원 표면 형상 측정 기술에는 여러 방법이 있으며 , 그 중 하나가 백색광의 간섭 효과를 이용해 삼차원 표면 형상을 측정하는 백색광 간섭계를 이용한 백색광 주사 간섭계이다.
백색광 주사 간섭계는 다음과 같이 동작한다 먼저 기준 거울을 이동하면서 간섭 무늬 이미지 를 획득하고 이미지 상의 각 픽셀의 밝기 변화 신호를 추출한 다 이 밝기 변화 신호 의 외형선 (envelop)을 추출한 후 외형선의 정점 위치를 찾아 픽셀의 높이를 결정 한 다 동일한 계산을 이미지 상의 모든 픽셀에 대해 반복하면 물체의 삼차원 표면 형상을 얻을 수 있다 이 과정에서 픽셀의 밝기 변화 신호 에서 외형선의 정점 위치를 계산하는 것 이 매우 중요하 다 외형선의 정점 위치를 계산하 는 대표적 인 방법은 FFT 와 Inverse FFT 를 사용한 것으로 정확도가 높은 장점이 있으나 계산 량이 많아 빠른 계산을 요구하는 분야에 사용 할 수 없는 문제가 있 고 이를 보완한 알고리즘의 경우 상대적으로 정확도가 떨어지는 문제가 있다 또한 이들 알고리즘은 정점이 없거나 측정 중 밝기 변화가 있는 것과 같은 예상하지 못한 신호의 경우 큰 계산 오차가 발생해 잘못된 삼차원 표면 형상 을 만 드 는 문제가 있다.
본 논문에서는 신경망을 사용해 백색광 주사 간섭계의 밝기 변화 신호에서 외형선의 정점 위치를 찾는 방법을 제안하였다. 문제에 적합한 신경망 구조를 찾기 위해 Recurrent Neural Networks(RNN)을 기반으로 한 5가지 종류의 신경망을 구성하고, 이 신경망에 활성화 함수를 3가지로 변경하며 학습하였다. 학습에 사용한 데이터는 가상으로 생성하였으며, 데이터 생성 범위를 5가지 경우로 변경하여 5개의 학습 데이터를 생성하였다. 신경망의 성능을 검증하기 위해 측정 샘플에서 57개 위치의 이미지 데이터를 획득하였으며, 이 중 69,825개의 픽셀을 선택하고 각 픽셀의 밝기 변화 신호에 FFT 알고리즘을 사용해 정점 위치를 계산하였다. 신경망의 성능을 평가하기 위해 백분위수를 사용하는 평가 방법을 새로 제안하였으며, 이를 사용해 여러 신경망 구조 간의 성능을 평가하였다. 제안된 평가 방법을 사용해 신경망과 기존 알고리즘의 성능을 정량(定量)적으로 비교하였고, 마지막으로 신경망과 기존 알고리즘으로 만든 삼차원 표면 형상을 정성(定性)적으로 비교하였다.
연구 결과 신경망을 사용해 백색광 주사 간섭계의 밝기 변화 신호에서 외형선의 정점 위치를 찾는 것이 가능함을 확인하였고, 가장 좋은 성능을 가진 신경망의 구성을 찾았다. 신경망의 학습 및 검증 결과 값으로부터 학습 데이터와 검증 결과 간의 관계를 분석하였으며, 학습 데이터의 생성 범위가 결과에 큰 영향을 끼침을 확인하였다. 신경망과 기존 알고리즘을 비교하여 일부 경우를 제외하고 정량적으로 신경망의 성능이 우수함을 확인하였다. 또한, 신경망과 기존 알고리즘 결과로부터
만든 삼차원 표면 형상을 정성적으로 비교하여, 신경망이 구성한 삼차원 표면 형상이 좀 더 좋음을 확인하였다. 마지막으로 일부 기존 알고리즘보다 성능이 떨어지는 부분에 대해 원인을 분석하고 향후 연구 방향을 제시하였다.","#Deep learning, #WSI"
딥러닝을 이용한 얼굴 변장 분류 알고리즘,2019,"생체 인식 기술은 본인 인증 방식으로 활발하게 사용되고 있으며, 공공
기관에서 지문 인식을 이용하여 민원 업무를 처리하는데 사용할 정도로 보급화가 되어 있다. 하지만 지문 인식, 손바닥 인식 등의 생체인식기술은 생체를 접촉해야 하는 점으로 인해 사람들로 하여금 불편함을 줄 수 있다. 이에 따라 비접촉 생체 인식 기술 중에서 얼굴 인식 기술이 각광받고 있다. 하지만 얼굴을 변장함으로써 특징점을 숨겼을 경우에는 얼굴 인식 시스템의 성능을 저하시키는 문제점이 발생한다. 이러한 문제점을 해결하기 위해 변장 분류 관련 연구가 본 논문에서 진행하였다.
본 논문에서는 얼굴 변장 분류 성능 분석 연구를 진행할 때 사용한 알고리즘은 Machine Learning 알고리즘의 하나의 종류인 Random Forest 및 Deep Learning이다. Deep Learning을 이용할 때는 ResNet, VGG9 및 본 논문에서 제안된 모델을 사용하였다. 본 논문에서 제안된 모델은 VGG9의 모델을 간소화 시킨 형태이며, 2번의 Convolution 연산과 1번의 Pooling 연산을 2번 반복 수행한다. 이후 2번의 Convolution 연산 이후 Fully Connected 연산을 마지막으로 수행한다.
본 논문에서 얼굴 변장 분류 성능 분석을 수행할 때 사용한 데이터베이스는 I2BVSD이다. 해당 데이터베이스에는 가시광선 이미지와 열화상 이미지가 있으며, 눈에 대한 변장 요소는 안경 착용 여부만을 고려하였고, 입에 대한 변장 요소는 위장 턱수염, 마스크 착용 여부만을 고려하였다.

위를 고려한 얼굴 변장 분류 실험 결과, 가시광선 이미지와 열화상 이미지 모두 성능이 가장 높은 것은 본 논문에서 제안된 모델이다. 향후 눈과 입에 대한 변장 요소가 증가한다면 보다 다양한 변장 분류에 대해 실험이 가능할 것이며, 이에 따라 성능 분석이 더욱 정확해질 것으로 예상한다.","#Visible Image, #Thermal Image, #Disguise Face, #Disguised Classification, #Random Forest, #Deep Learning"
딥러닝을 이용한 개인화 된 추천 시스템,2019,"Recommender Systems have been successfully applied across a variety of domains. In business, we need to understand users’ patterns to predict their next choice in a cart (basket). But pattern mining-based approaches are not completely predicted what the user will buy. The data we are trying to model is much more complex. There are a variety of patterns based on user and other items on the cart. In this situation, we have to model the data using more effective model not only use items’ relevance. The proposed models aim to predict the next choice of the user will buy. The proposed models are more effective than the state-of-the-art models for next item recommendation. In this thesis, there are three proposed models using Deep Neural Network (DNN).
Applying DNN in recommender systems such as (Covington, Adams, and Sargin, 2016) has been successfully. We also used DNN for Next Item Recommendation. We carry out experiments on synthetic datasets of credit card usage, CardUsage1, CardUsage2, CardUsage and real-world dataset, TaFeng. The experimental results show that our models offer excellent predictions.",
딥러닝 기반 발전연료 가격예측,2019,"발전 연료인 유연탄의 가격을 사전에 예측하고 발전 원가를 절감함으로써 공공재로서의 전력가격 안정에 기여하고자 한다. 이를 위해 관리되기 어려운 수많은 종류의 정보를 시기적 효용에 맞도록 관리하는 예측모델을 설계하여, 가격변동성을 적절히 대응 하고자 한다.

다양한 정보를 정량적으로 사용하기 위해 NLP기반 뉴스지표를 생성한다. 사용 알고리즘은 word2vec과 doc2vec을 활용한다.
유연탄 가격과 관련성이 높을 것으로 예상되는 경제인덱스를 수집하고, 상관분석을 통해 경제지표로 관리한다.
가격의 예측은 데이터의 시계열적 특징을 유지하되, 장기 예측이라는 특성을 고려하여 LSTM알고리즘을 활용한다.

현재 시점으로부터 6개월 이후의 유연탄 가격을 예측한 결과 MAPE 20% 이하의 예측결과를 얻을 수 있었다.

본 연구에서 제시된 방법에 의한 가격예측은 예측모델방법은 Loss의 검토결과 유효한 것으로 판단될 수 있으나, 자연어 처리 및 안정적 모델을 위한 후속 연구가 필요한 것으로 판단된다.

We intend to contribute to stabilizing electric power prices as a public goods by predicting the price of bituminous coal, which is a generation fuel, and reducing the cost of electricity generation. To do this, we design a forecasting model that manages many types of information that are difficult to manage to meet timely utility, and respond appropriately to price volatility.

Generate NLP-based news indicators to use various information quantitatively. Usage algorithms utilize word2vec and doc2vec.
Economic indexes that are expected to be highly related to the price of bituminous coal are collected and managed as economic indicators through correlation analysis.
The prediction of price maintains the time-series characteristics of the data, but utilizes the LSTM algorithm considering the characteristic of long-term prediction.

As a result of estimating the bituminous coal price after 6 months from the present point of view, the prediction result of MAPE was less than 20%.

The price prediction by the method proposed in this study can be judged to be valid as a result of the review of the forecasting model method, but it is considered that further study for natural language processing and stable model is needed.",
딥러닝을 이용한 자율 주행 차량의 외란 보상,2019,"본 학위논문에서는 자율 주행 차량의 외란(disturbance)에 대해 분석하고, 완벽하게 제거하기 어려운 부정합 외란(unmatched disturbance)의 보상 방법에 대해 제안한다. 횡 방향 동역학 모델은 여러 가지가 연구되고 있으며, 최근에는 사람의 운전 전략을 모방하는 방법이 제안되고 있다. 그 중, look-ahead의 개념을 도입한 횡 방향 동역학 모델은 사람이 전방의 특정 지점(look-ahead point)을 보면서 차선을 유지하는 방법을 모사한 모델이다. 이 횡 방향 동역학 모델은 차량의 안정적인 움직임을 도와준다. 하지만, 이 모델의 단점은 곡선 도로에서 제거하기 어려운 부정합 외란을 발생시키는 것이다. 부정합 외란은 도로의 곡률(curvature)로 인해 항상 존재하게 되는데, 이러한 부정합 외란으로 인해 피드백(feedback) 제어만을 이용한 차선 유지 시스템은 곡선 도로 상에서 차선 중심을 유지 하는 데 있어 일정한 오차(steady-state error)를 갖는다. 따라서, 우리는 곡선 도로에서 자율 주행 차량의 부정합 외란을 보상하는 새로운 전략을 제시한다.
외란은 크게 정합 외란(matched disturbance)과 부정합 외란(unmatched disturbance)으로 나뉠 수 있다. 정합 외란은 제어기나 외란 관측기 등을 통해 제거할 수 있다. 하지만 부정합 외란은 전통적인 제어 기법으로 완전히 보상할 수 없다. 따라서, 본 논문에서는 자율 주행 차량의 부정합 외란을 보상하기 위해, deep neural network을 이용하였다. Deep neural network는 곡선 도로에서 부정합 외란을 보상하는 부가적인 제어 입력을 생성한다. 이 부가적인 입력은 기존 제어기에서 출력된 값에 더해져서 시스템에 입력되게 된다. 따라서 제안하는 전체 시스템은 전통적인 제어 시스템에 feed-forward 형태로 추가적인 입력이 더해지게 되며 이 추가적인 입력은 deep neural network를 통해 계산된다. 본 학위논문에서 제안하는 이러한 방법은 차선 유지 시스템에서 부정합 외란을 보상하는 유일한 방법이다.
제안한 알고리즘은 이중 차선 변경과 지속적인 왼쪽 곡선의 경로를 통해 성능을 검증 하였다. 두 경로 모두 training dataset에 포함되지 않은 경로이며, 이를 통해 deep neural network의 training 결과를 검증하였다. 또한, 우리는 모의 실험을 통해 제안한 방법을 사용하였을 때, 곡선 도로에서 횡 방향 오차를 약 50% 감소시키는 것을 확인할 수 있었다.",#전기공학
LoRaWAN 환경에서 딥러닝을 이용한 TDoA 측위 개선 방안,2019,"LoRa is one of the low power wide area communication technologies (LPWA) that enables low cost chip module design due to low power, high receiver sensitivity and license-exempt bandwidth. Because of this, it is a technology suitable for IoT services with low data throughput and variability.
For low-power-based positioning in LoRa environments while various techniques have been tried, The error is over a hundred meters. Because of this it is difficult to commercialize practical location based services. In this paper, to reduce the TDoA positioning error, a train was made to correct the time error that occurs when transmitting. We propose a method of learning the time error in the Deep Neural Networks model and correcting it using the learned model in actual positioning. The experimental environment was constructed using python and keras. Experiment result is we confirmed that the error range decreases when the number of reference nodes and collected data are large and the mobile node is close to the reference node.","#Deep learning, #TDoA, #Location positioning, #LoRaWAN, #LoRa"
딥러닝을 사용한 대용량 MIMO 신호 검출,2019,"본 논문에서는 심층신경망을 이용한 다중 입력 다중 출력(Multiple Input Multiple Output, MIMO) 시스템에서 MIMO 검출 기법을 제안한다. 최근 데이터 전송량이 기하급수적으로 증가함에 따라서 추가적인 주파수 대역 및 전송 전력을 이용하지 않고 채널 용량을 증가시킬 수 있는 MIMO 시스템이 많이 사용되고 있다. 하지만 Sphere decoding과 같은 기존의 준최적 MIMO 검출 기법들은 송신 안테나의 수가 증가하면 계산 복잡도가 지수적으로 증가하는 문제가 있다.
본 논문에서는 낮은 복잡도에서 높은 검출 성능을 가지는 새로운 MIMO 검출 기법을 제안한다. 먼저 R-A-ADMM(Relaxed-Accelerated-Alternating Direction Method of Multipliers) 알고리즘을 MIMO 검출 문제에 도입한다. 다음으로 ADMM 기반 알고리즘의 파라미터를 최적화시키는 심층 신경망을 제안한다. 제안하는 MIMO 검출 네트워크는 다양한 채널과 변조방식에 대하여 학습 가능하다. 그리고, 기계학습이 적용된 최신 기법보다 적은 양의 학습 매개변수를 가지며 낮은 복잡도임에도 높은 성능을 유지한다.
모의실험에서는 다양한 채널과 변조방식에서의 복잡도와 성능을 비교한다. 제안하는 네트워크는 낮은 복잡도를 가지며 최신의 알고리즘보다 뛰어난 성능을 확인할 수 있다.",
딥러닝을 이용한 RNA의 분지점 선택 연구,2019,"Alternative splicing (AS) is a regulated process that takes place during
gene expression and by which a single gene may code for multiple proteins. This mechanism is controlled by a complex called spliceosome by
which certain exons of a gene may be included in or excluded out from
the final mRNA produced from that gene. In alternative splicing (AS),
at least three remarkable signals exist in introns and they are namely 5’
Splice Site(5’ss in short) the donor splice site where GU nucleotides always present, 3’ Splice Site(3’ss in short) the acceptor splice site where
AG nucleotides always present, and branch site.
Generally, branch point site is located at 20 to 50 nucleotides upstream
from 3’ss.
In this study, we focus on the BP in RNA splicing, part of the translation of the DNA codes to the protein to predict the position of BP in high accuracy. Then we use this information to find out the effect of the
mutation on the output product (protein).
we aim to identify the branch point location using a computational model
based on deep learning. We propose a hybrid model based on a combination of a dilated convolution neural network and a recurrent neural network. Integrating additional inputs to the raw DNA sequence has been
studied such as conservation, binding energy, and di-nucleotide. The
proposed model has been evaluated on two publicly available datasets
and outperformed the current state-of-the-art methods.
More specifically, the proposed model achieved for the first dataset
97.29% and 67.08% of the area under curve (AUC) and the area under precision recall curve (auPRC), respectively, for the second dataset
96.86% and 69.62% of AUC and auPRC, respectively, . In addition,
pathogenic variants have been studied by the proposed model and agreed
with the reported ones biologically. To study RNA branch point selection, an easy-to-use web server has been established for free access at:
(https://home.jbnu.ac.kr/NSCL/rnabps.htm)","#Branchpoint, #Deep learning, #DNA, #RNA"
이종의 딥러닝 모델을 활용한 자율 주행 자동차를 위한 다중 차량 추적 알고리즘,2019,"This thesis presents an multi vehicle tracking model based on heterogeneous deep learning networks for autonomous driving applications. Our proposed multi vehicle tracking model follows the tracking-by-detection paradigm, and utilizes appearance feature and motion history. To extract appearance feature, we use convolutional neural network which has trained with triplet loss manner to let network learns how to extract useful features. We also use LSTM followed by fully connected layer to predict next appearance feature probability distribution and, motion of tracked objects. To evaluate our proposed model, we generate multi vehicle tracking dataset in real-world by monocular camera, which have various real scenarios. The experimental results show that the proposed multi vehicle tracking model can achieve promising performance on real-world scenarios","#Deep learning, #Autonomous vehicle, #Vehicle tracking"
딥러닝을 이용한 전주(電柱) 위 새집의 존재 여부 판별,2019,"조류로 인한 정전 사고는 1년에 약 30건 수준으로 꾸준히 발생하고 있다. 한국전력공사는 정전 사고 예방을 위해 도보나 차량을 이용하여 사람이 직접 순찰을 돌거나 민원 접수 후 조류 포획을 전문 수렵기관에 위탁하는 방법을 사용하고 있다. 이러한 방법은 시간 및 비용이 많이 소요되기 때문에 비효율적이다. 이에 따라 한국전력공사는 드론을 활용하여 효율적으로 배전 설비를 진단할 수 있는 방안을 추진 중이다. 본 논문은 드론 등의 영상을 통해 컴퓨터가 자동으로 전주 위 새집의 존재 여부를 판별할 수 있도록 하였다.
새집의 존재 여부를 판별하기 위해 이미지 인식에서 뛰어난 성능을 보이는 합성곱 신경망을 사용하였다. 신경망 학습을 위해 전주 이미지와 새집이 있는 전주 이미지가 필요하기 때문에 카카오맵의 로드뷰를 활용하여 전주 이미지를 수집하였으며 새집이 있는 전주 이미지는 한국전력공사의 도움을 받아 수집하였다. 수집 과정에서 전주 이미지는 데이터 수가 많은데 비해 새집이 있는 전주 이미지의 경우 데이터가 현저히 적은 문제가 발생하였다. 이러한 데이터 불균형 문제를 해결하기 위해 샘플링 기법을 사용하였다. 샘플링 기법으로 많은 쪽의 데이터를 줄이는 언더샘플링 기법과 적은 쪽의 데이터를 늘리는 오버샘플링 기법을 사용하였다. 오버샘플링 기법으로는 새로운 이미지 데이터를 생성하는 생성적 적대 신경망을 활용하였다. 각각의 방법을 사용하여 데이터 균형을 맞춘 후 합성곱 신경망 알고리즘을 학습시켜 알고리즘의 성능을 평가하였다. 알고리즘 성능 평가를 위해 정확도와 재현율, 정밀도, F-measure 값을 계산하여 비교하였다. 그 결과 생성적 적대 신경망을 사용한 알고리즘이 언더샘플링 기법을 사용한 알고리즘보다 높은 성능을 보였다. 그러나 생성적 적대 신경망을 사용했을 경우 언더샘플링 기법을 사용했을 때보다 훨씬 많은 시간이 소요되었다. 따라서 데이터의 불균형이 발생했을 경우 정확도와 속도 중 원하는 기준에 따라 두 가지 방법 중 하나를 선택하여 데이터의 균형을 맞출 수 있다.

Power outages caused by bird nest are steadily occurring at about 30 cases a year. The Korea Electric Power Corporation(KEPCO) is using two methods to prevent power outages. One is a person''s direct patrol using a foot or car. The other method is to entrust bird-hunting to a professional hunting agency after receiving civil complaints. This method is inefficient because it takes a lot of time and money. Accordingly, KEPCO is proceeding with a plan to diagnose power distribution facilities efficiently using drones. This paper has made it possible for the computer to automatically discriminate whether a bird nest exists on electric pole through videos of drones.
In order to determine the existence of bird nests, we use Convolutional Neural Network which shows excellent performance in image recognition. For the learning of the neural network, we need the image of electric pole and the image of electric pole with a bird nest. So we collected the electric pole image using the road view of the Kakao map and collected the image of electric pole with a bird nest with the help of KEPCO. In the collection process, the number of data of the electric pole is large, whereas the data of the electric pole with a bird nest is remarkably small. To solve the problem of data imbalance, sampling techniques were used. We use an undersampling technique to reduce the data of the electric pole, and an oversampling technique to increase the data of the electric pole with a bird nest. As an oversampling technique, we used a Generative Adversarial Network that generates image data.
The performance of the algorithm was evaluated after each method was used to learn the Convolutional Neural Network algorithm. In order to evaluate the performance of the algorithm, the accuracy, recall, precision, and F-measure were calculated and compared. As a result, the algorithm using the Generative Adversarial Network showed higher performance than the algorithm using the under-sampling technique. However, the use of Generative Adversarial Network took much more time than the under-sampling technique. Therefore, when data imbalance occurs, data can be balanced by selecting one of two methods according to a desired criterion of accuracy and speed.",
딥러닝을 이용한 MSA환자에서의 피각 저강도 등급과 GLCM 질감 특징 간 상관관계 분석,2019,"다계통위축증 (multiple system atrophy, MSA)은 퇴행성 신경계 질환으로, 파킨슨 증상과 소뇌 증상, 자율신경계 증상이 복합되어 나타난다. MSA는 특히 질병의 진행 정도에 따라 피각 (putamen)에서 위축과 저음영이 많이 발생한다. 이 특징을 정량화하는 방법 중 하나로 자기공명영상 (magnetic resonance imaging: MRI) 기법 중의 하나인 자화율강조영상 (susceptibility weighted image: SWI)을 이용한 피각 저강도 등급 분류 방법이 있다. MSA 환자의 SWI 영상으로 피각에서 발생하는 저강도 및 비정상의 국소화 등을 종합하여 Grade 0에서 Grade 3까지 총 4단계로 등급으로 나누었다. 이에 본 연구에서는 MSA 환자의 이미지 기반 자동 질병 분류 가능성을 합성곱 신경망을 이용하여 확인하고 피각에서 나타나는 질감을 파악하고자 GLCM 기법을 이용하였다.
본 연구는 양산 부산대학병원 신경과에 내원한 MSA 환자 41명을 대상으로 3.0T 자기공명영상장치로 획득한 SWI 영상을 이용하였다. SWI 영상의 파라미터는 다음과 같다: TR = 28ms, TE = 20 ms, Flip angle = 15°, matrix size = 320 × 240, slice thickness = 2 mm. MSA 환자 중 17명은 추적관찰 (follow-up)을 진행하여 영상을 획득했었다. 이용하는 SWI 영상의 총 개수는 58개 이다. 모든 SWI 뇌영상에서 뇌척수액이 보이지 않는 순간의 횡축 단면 영상을 선택한 뒤, 좌우 각 반구의 미상핵, 조가비핵, 담창구 등을 포함하는 부분을 관심영역으로 설정하였다. 추출한 관심영역 영상은 2명의 임상의가 피각에서 나타나는 강도 및 비정상의 국소화 등을 종합하여 피각 저강도 등급을 측정하였다. 추출한 관심영역 이미지들의 강도는 표준 정규화 (Z-score normalization)를 진행하였으며, 안정적인 학습을 위해 좌반구의 이미지들을 뒤집어 (flip) 우반구 방향으로 통일하였다.
본 연구에 사용된 CNN의 구조는 옥스퍼드 대학의 VGG 그룹에서 창안한 VGG16으로, Convolution Layer와 Fully-connected layer로 이루어진 16층의 신경망이다. 사전학습 (pre-trained)된 VGG16 모델에서 최종단의 Fully-connected layer를 Global Average Pooling로 수정한 뒤 fine-tuning하였다. 모델의 성능을 검증은 4-fold 교차 검증 기법을 이용하였다. 이용하는 GLCM (Gray-Level Co-Occurrence Matrix) 질감 특징은 총 11가지로 다음과 같다: Energy, Contrast, Correlation, Homogeneity, Entropy, Variance, Sum Average (SA), Sum Entropy (SE), Difference Entropy (DE), Cluster Shade (CS), Cluster Prominence (CP).
SWI에서 추출한 ROI와 이것으로 부터 생성된 GLCM 질감 영상들 별 등급 분류 정확도를 확인하였다. 최종 정확도는 4번의 교차 검증의 정확도를 평균한 값으로 하였다. MLP를 이용한 방법 (acc = 59.71±8.60%)보다 SWI 영상과 CNN을 이용하여 분류한 방법 (acc = 64.51±6.81%)의 성능이 높았으며, 모든 영상들 중 가장 성능이 높았다. GLCM 질감들 중에선 CP (acc = 62.17±12.04%)가 가장 높은 성능을 보였으며 가장 낮은 성능을 보인 것은 SE (acc = 36.16±9.14%)이다. 또한 분류된 결과들로 혼동행렬 분석을 진행하였다. SWI와 GLCM 질감 영상 중 가장 성능이 좋은 CP의 경우를 비교 분석하면, 정밀도 측면에서 G1에서의 정밀도는 CP가 SWI 보다 높지만 G2에서는 SWI가 CP보다 높았다. 재현율 측면에서는 G0에서의 재현율은 SWI가 CP보다 높았다. F1 점수 측면에서 보면, SWI에선 G3가 다른 등급에 비해 높지만 CP의 경우 G1과 G3가 G0, G2보다 높았다. GLCM 질감 영상 중 가장 낮은 성능을 보인 SE에 대해 분석하면, 정밀도 측면에서 G3가 다른 등급에 비해 월등히 높았다. 재현율 측면에서는 G1이 다른 등급에 비해 월등히 높았다. F1 점수 측면에서 보면 G0와 G1의 점수가 G2, G3보다 높았다.
합성곱 신경망은 영상분석 및 패턴 인식 등에서 널리 쓰이고 성능도 높은 것으로 알려져 있지만 영상들의 패턴을 어떻게 파악하는지, 파악한 특징이 무엇인지 알 수 없다는 단점이 있다. 본 연구에서는 합성곱 신경망에 GLCM 기법을 적용함으로서 분류하고자 하는 영상의 핵심적 특징이 어디인지 파악할 수 있었다. 또한 등급이 올라갈수록 피질하 영역에서 나타나는 특징이 저음영과 위축이라는 사실을 재확인 하였다.","#Putaminal hypointensity grade, #Deep learning, #Susceptibility weighted imaging, #Gray level co-occurrence matrix, #Multiple system atrophy"
공정 주기 신호의 이상 탐지 및 분류를 위한 밀도기반 군집화와 딥러닝 모델 구축,2019,"Process Fault Detection and Classification(FDC) distinguishes between normal and abnormal process cycle signals. In the case of process cycle signals, quality control is difficult due to lack of information on patterns and data imbalance. In this paper, We proposed a method to extract key features of cycle signal data by using LSTM Autoencoder and performed DBSCAN clustering to obtain information on patterns when there is no information on process cycle signals. We used data augmentation especially when cluster with low density to eliminate the data imbalance of the process signal. Through the above process, We finally constructed a bidirectional LSTM model for real-time process cycle signal classification. This provides a basis for smart factories by suggesting ways to actively respond without relying on domain knowledge.",
단일 가속도계 기반의 인간 활동 인식을 위한 하이브리드 딥러닝 접근법,2019,"Human activity recognition (HAR) is a classification problem for recognizing human movements and actions, therefore, it is an important task for applications such as healthcare monitoring, assistive living and surveillance. In recent years, many works have been done on HAR using wearable sensors. However, recognizing some similar activities for a single sensor is still less accurate. The advantages of using a single sensor to detect human activity are low cost and more comfortable. In this paper, we present a single accelerometer sensor-based approach for HAR. Our proposed recognition method uses a Long Short-Term Memory (LSTM) with Convolutional Neural Network (CNN), this approach calculates the ratio between two similar activities from LSTM output probability, if the ratio is higher than the specific threshold then CNN would be applied to between these two classes. We evaluate our framework on two public datasets known as WISDM and Shoaib. The experimental results show that the proposed method demonstrates state-of-the-art performance while low computational cost and without any feature extraction methods.","#HAR, #LSTM, #CNN, #deep learning, #wearable sensor"
임베디드 시스템용 딥러닝 추론엔진 기술 동향,2019.08,,
경량 딥러닝 기술 동향,2019.04,,
딥러닝 기반 자연어 처리에서 도메인 지식의 역할,2019.1,"Symbolic AI에서는 도메인 지식이 중요시되었다. 규칙 기반 자연어처리에서도 언어학적 지식이 중요한 역할을 담당했다. 확률 기반 자연어처리와 기계학습 기법이 발달하면서 도메인 지식의 역할은 축소되었다. 딥러닝이 대두하면서, 자질 공학과 도메인 지식의 역할은 훨씬 더 축소되었다. 딥러닝 시대에도 여전히 도메인 전문가(언어학자)의 역할이 중요함을 증명하기 위해 한국어 형태소분석기를 개발하였다. 한국어는 형태음소적 교체, 탈락, 축약이 활발하여 분절 과제가 쉽지 않지만, 분절 과제를 분류 문제로 재설정하면 기계학습으로 더 쉽게 해결할 수 있게 된다. 이를 위해서는 분절 이전의 입력의 각 음절과 분절된 출력의 대응하는 문자열 사이의 매핑 관계를 망라적으로 목록화하는 것이 관건이다. 1200만 어절 규모의 세종 형태의미 분석 말뭉치를 통해 이러한 매핑에 200개 유형이 있음을 확인하였다. 이 200개 범주를 바탕으로 LSTM 기반 신경망 모델을 만들어 훈련시켰다. 분절 문제가 해결되면, 분절된 각 토큰에 대한 레이블링은, 영어 등에 대한 선행 연구로 친숙한 연쇄 레이블링 알고리즘으로 쉽게 해결할 수 있다. 이 두 가지 모델과 사전을 결합하여, F1 스코어 98.0%의 성능을 얻을 수 있었다. 이 실험은 딥러닝 시대에도 도메인 지식이 여전히 중요함을 보여준다.

In Symbolic AI, the domain knowledge was considered indispensable. In rule-based NLP, likewise, the linguistic knowledge played an important role. As probabilistic NLP and machine learning techniques develop, the role of domain knowledge shrank. As deep learning appears, even the role of feature engineering and domain knowledge has become almost zero. In order to prove the importance of domain knowledge even in this deep learning age, I built a parts-of-speech tagger of Korean. This task in Korean is challenging, due to morphophonological alternations, deletions and contractions. I reformulated this task of segmentation as that of classification. For this purpose, I examined a large corpus, and found empirically 200 types of mapping between an input syllable and an output string. Based on these categories, I built and trained an LSTM-based neural network. With this model of segmentation, the parts-of-speech tagging model is easily trained by the familiar sequence tagging algorithm. By combining these two models and a few dictionaries, I got 98.0% of the F1 score.","#도메인 지식, #자연어처리, #형태소분석, #분절, #딥러닝"
딥러닝을 통한 이미지의 인식론 - 창발성의 비주얼 커뮤니케이션,2019,"이 연구는 ‘인공지능과 빅데이터를 통한 이미지의 존재론과 창발성’이라는 본인의 선행 연구를 잇는다. 이전 연구에서는 ‘인공지능과 빅데이터를 통해 생산한 이미지’와 ‘예술 작품의 이미지’를 ‘이미지 생산 주체’의 문제와 ‘생산된 이미지의 존재론’의 관점에서 비교, 연구했다. 전자가 현재까지는 예술이 아니지만, 예술이 될 가능성을, 양자가 공유하는 ‘예측 블가능성’을 키워드로 삼아, 이미지 존재론의 관점에서 제시했다. ‘예측 불가능성’이 ‘인식론적 창발성’의 주요 특징이라는 점에서, 본 연구는 이미지 존재론에 관한 선행 연구를 인식론의 관점으로 확장하는 창발성의 비주얼 커뮤니케이션을 연구하기 위해 다음처럼 논문을 구성한다. 구체적으로 2장에서는 ‘인식론의 이미지 인식’을 인식 주체인 인간과 대상인 이미지 사이에 상호 작용하는 입장으로 전개된 것으로 고찰한다. 3장에서는 ‘인지과학의 이미지 인식’을 ‘이미지 인지’의 차원에서 실행함으로써 인간 지능에 기능해 온 것으로 살펴본다. 4장에서는 ‘딥러닝의 이미지 인식’을 인공지능이 비지도학습이라는 자가 감독 학습을 실행함으로써 이미지의 외피적 판별에만 국한되는 것이 아닌 이미지가 내포한 의미론까지 파악하는 것으로 살펴본다. 마지막 6장에서는 ‘딥러닝을 통한 시각예술의 이미지 인식’을 딥러닝을 실험하는 3인(팀)의 미술가들(하름 판 덴 도르펠, 레이체 아라, 포렌식 아키텍처)이 발표한 실제의 작품을 분석하면서 살펴본다. 본 연구는 최근 인공지능이 생산하는 이미지에 대한 미적 경험과 의미 나아가 예술적 해석의 관계를 탐구하는데 기여할 것이다.

This study connects with my previous research, 'Image Ontology and Emergence Properties through AI and Big Data'. In that work, I compared an 'image produced through artificial intelligence and big data' with an 'image of visual artwork' from the viewpoint of 'subject of image production' and the 'ontology of the produced image'. Although the former is not considered art thus far, the possibility of it becoming art is presented from the viewpoint of image ontology using the keyword 'unpredictability', which exists on both sides. 'Unpredictability' is a key feature of 'epistemic emergence'. In this regard, this study proceeds as follows to study the visual communication of Emergent Properties that extend earlier work on image ontology to the perspective of epistemology. Specifically, in Chapter 2 we consider that the 'image recognition of epistemology' has developed into a position of interaction between humans as subjects of recognition and images as objects of recognition. In Chapter 3, we examine how the 'image recognition of cognitive science' has functioned in human intelligence through the concept of 'image cognition'. In Chapter 4, 'image recognition in early machine learning' is examined by considering images that are grasped by supervised learning. In Chapter 5, we examine 'image recognition of deep learning' as artificial intelligence learns self-supervised learning through unsupervised learning to understand the semantics implied by an image rather than being limited to external classifications of images. In the last chapter, chapter 6,""Realization of Visual Art through Deep Learning,"" an actual work of three artists (team members) who are experimenting with deep running (Ham vanden Dorpel, Rachel Ara, and Forensic Architecture), is analyzed. This study will contribute to explorations of the relationship between the aesthetic experience of artificial intelligence produced by artificial intelligence and meaning and artistic interpretation.","#이미지 인식론, #딥러닝, #비주얼 커뮤니케이션, #미적 경험, #인식론적 창발성"
딥러닝 기술이 가지는 보안 문제점에 대한 분석,2019,"본 논문에서는 딥러닝 기술이 인터넷과 연결된 다양한 비즈니스 분야에 새로운 형태의 비즈니스 업무에 활용할 수 있도록 보안에 관한 문제점을 분석하고자 한다. 우선 딥러닝이 비즈니스 영역에 보안 업무를 충분히 수행하기 위해서는 많은 데이터를 가지고 반복적인 학습을 필요하게 된다. 본 논문에서 딥러닝이 안정적인 비즈니스 보안 업무를 완벽하게 수행할 수 있는 학습적 능력을 얻기 위해서는 비정상 IP패킷에 대한 탐지 능력과 정상적인 소프트웨어와 악성코드를 탑재하여 감염 의도를 가지고 접근하는 공격을 탐지해낼 수 있는 인지 능력을 갖추고 있는지를 분석하였다. 이에 본 논문에서는 인공지능의 딥러닝 기술이 시스템에 접근하여 문제의 비즈니스 모델을 안정적으로 수행할 수 있게 하기 위해서는 시스템내의 비정상 데이터를 추출해 내고 시스템 데이터 침해를 구분해 낼 수 있는 수학적 역할의 문제점을 보완하기 위해 새로운 IP에 대한 세션 및 로그 분석을 수행할 수 있도록 보안 엔진이 탑재된 딥러닝 기술을 개발하여 비즈니스 모델에 적용시켜서 취약점을 제거하여 비즈니스 업무 능력을 향상시키도록 문제적 방안을 비교 분석하였다.

In this paper, it will analyze security problems, so technology’s potential can apply to business security area. First, in order to deep learning do security tasks sufficiently in the business area, deep learning requires repetitive learning with large amounts of data. In this paper, to acquire learning ability to do stable business tasks, it must detect abnormal IP packets and attack such as normal software with malicious code. Therefore, this paper will analyze whether deep learning has the cognitive ability to detect various attack. In this paper, to deep learning to reach the system and reliably execute the business model which has problem, this paper will develop deep learning technology which is equipped with security engine to analyze new IP about Session and do log analysis and solve the problem of mathematical role which can extract abnormal data and distinguish infringement of system data. Then it will apply to business model to drop the vulnerability and improve the business performance.","#Convergence, #AI, #Machine Learning, #Deep Learning, #Security, #Business Model"
사용자 인증을 위한 딥러닝 기반 얼굴인식 기술 동향,2019,"차이가 나는 물체를 구별하는 물체인식과 달리, 얼굴인식은 유사한 패턴을 가진 얼굴의 Identity를 구별한다. 이에 따라 LBP, HOG, Gabor과 같은 특징 추출 알고리즘이 딥러닝 기반으로 대체되고 있다. 딥 러닝 기술을 활용하여 머신러닝으로 얼굴을 식별할 수 있는 기술이 발전하면서 다양한 분야에서 얼굴인식 기술이 활용되고 있다. 특히, 금융 거래 외에도 사용자 식별이 필요한 다양한 오프라인 환경에서 활용되어 세밀하고 개인에 적합한 서비스가 제공될 수 있다. 얼굴 인식 기술은 스마트 미러와 같은 장치를 통해 손쉽게 사용자 인증을 하고, 식별이 된 사용자에게 서비스를 제공할 수 있는 기술로 발전할 수 있다. 본 논문에서는 사용자 인증의 다양한 기법 중에서 얼굴인식 기술에 대한 조사 및 파이썬으로 작성된 얼굴인식 사례 소스 분석과 얼굴인식 기술을 활용한 다양한 서비스의 가능성을 제시하고자 한다.

Object recognition distinguish objects which are different from each other. But Face recognition distinguishes Identity of Faces with Similar Patterns. Feature extraction algorithm such as LBP, HOG, Gabor is being replaced with Deep Learning. As the technology that identify individual face with machine learning using Deep Learning Technology is developing, The Face Recognition Technology is being used in various field. In particular, the technology can provide individual and detailed service by being used in various offline environments requiring user identification, such as Smart Mirror. Face Recognition Technology can be developed as the technology that authenticate user easily by device like Smart Mirror and provide service authenticated user. In this paper, we present investigation about Face Recognition among various techniques for user authentication and analysis of Python source case of Face recognition and possibility of various service using Face Recognition Technology.","#얼굴인식, #사용자인증, #딥러닝, #인증, #다중 인증"
블레이드의 표면 결함 검출을 위한 Faster R-CNN 딥러닝 모델 구축,2019,"컴퓨터 성능 향상으로 다양한 분야에서 딥러닝을 활용한 연구가 활발히 진행되고 있으며 최근에는 구조물 안전성 평가 연구에도 그 적용이 이루어지고 있다. 특히 터빈의 내부 블레이드는 분리가 쉽지 않고 어두운 주변 환경으로 인해 블레이드의 표면 결함 검출은 전문 인력의 경험에 의존하고 있으며, 점검시간도 상당히 소요되고 있는 실정이다. 따라서, 본 연구에서는 딥러닝 기술을 적용하여 터빈 구조의 부재 중 하나인 내부 블레이드에 발생하는 결함을 검출할 수 있는 효율적인 방법을 제시하였다. Faster R-CNN 인공신경망 기법을 활용하여 결함의 이미지 데이터를 학습하였고 부족한 이미지는 필터링과 Image Data Generator를 이용하여 데이터를 확장하였다. 그 결과 블레이드의 결함을 학습한 딥러닝 모델은 평균적으로 약 96.1%의 정확도와 재현율은 95.3%, 정밀도는 96%의 성능을 보였다. 재현율을 통해 제시된 딥러닝 모델이 결함을 탐지하지 못하는 경우는 4.7% 로 나타났다. 재현율의 성능은 여러 환경의 많은 결함 이미지 데이터를 수집하고 확장하여 딥러닝 학습에 적용함으로써 더욱 향상되리라 판단된다. 이러한 실제 블레이드의 결함 이미지 데이터 확보와 학습을 통해 향후 터빈엔진 정비에 적용 가능한 결함 검출 시스템으로 발전할 수 있을 것이다.

As computer performance improves, research using deep learning are being actively carried out in various fields. Recently, deep learning technology has been applying to the safety evaluation for structures. In particular, the internal blades of a turbine structure requires experienced experts and considerable time to detect surface damages because of the difficulty of separation of the blades from the structure and the dark environmental condition. This study proposes a Faster R-CNN deep learning model that can detect surface damages on the internal blades, which is one of the primary elements of the turbine structure. The deep learning model was trained using image data with dent and punch damages. The image data was also expanded using image filtering and image data generator techniques. As a result, the deep learning model showed 96.1% accuracy, 95.3% recall, and 96% precision. The value of the recall means that the proposed deep learning model could not detect the blade damages for 4.7%. The performance of the proposed damage detection system can be further improved by collecting and extending damage images in various environments, and finally it can be applicable for turbine engine maintenance.","#Blade, #Deep learning, #Faster R-CNN, #Object detection, #Surface damage, #Turbine engine"
Sentinel-1 A/B 위성 SAR 자료와 딥러닝 모델을 이용한 여름철 북극해 해빙 분류 연구,2019.1,"북극항로의 개척 가능성과 정확한 기후 예측 모델의 필요성에 의해 북극해 고해상도 해빙 지도의 중요성이 증가하고 있다. 그러나 기존의 북극 해빙 지도는 제작에 사용된 위성 영상 취득 센서의 특성에 따른 데이터의 취득과 공간해상도 등에서 그 활용도가 제한된다. 본 연구에서는 Sentinel-1 A/B SAR 위성자료로부터 고해상도 해빙 지도를 생성하기 위한 딥러닝 기반의 해빙 분류 알고리즘을 연구하였다. 북극해 Ice Chart를 기반으로 전문가 판독에 의해 Open Water, First Year Ice, Multi Year Ice의 세 클래스로 구성된 훈련자료를 구축하였으며, Convolutional Neural Network 기반의 두 가지 딥러닝 모델(Simple CNN, Resnet50)과 입사각 및 thermal noise가 보정된 HV 밴드를 포함하는 다섯 가지 입력 밴드 조합을 이용하여 총 10가지 케이스의 해빙 분류를 실시하였다. 이 케이스들에 대하여 Ground Truth Point를 사용하여 정확도를 비교하고, 가장 높은 정확도가 나온케이스에 대해 confusion matrix 및 Cohen의 kappa 분석을 실시하였다. 또한 전통적으로 분류를 위해 많이 활용되어 온 Maximum Likelihood Classifier 기법을 이용한 분류결과에 대해서도 같은 비교를 하였다. 그 결과Convolution 층 2개, Max Pooling 층 2개를 가진 구조의 Convolutional Neural Network에 [HV, 입사각] 밴드를 넣은 딥러닝 알고리즘의 분류 결과가 96.66%의 가장 높은 분류 정확도를 보였으며, Cohen의 kappa 계수는 0.9499 로 나타나 딥러닝에 의한 해빙 분류는 비교적 높은 분류 결과를 보였다. 또한 모든 딥러닝 케이스는 Maximum Likelihood Classifier 기법에 비해 높은 분류 정확도를 보였다.

The importance of high-resolution sea ice maps of the Arctic Ocean is increasing due to the possibility of pioneering North Pole Routes and the necessity of precise climate prediction models. In this study, sea ice classification algorithms for two deep learning models were examined using Sentinel- 1 A/B SAR data to generate high-resolution sea ice classification maps. Based on current ice charts, three classes (Open Water, First Year Ice, Multi Year Ice) of training data sets were generated by Arctic sea ice and remote sensing experts. Ten sea ice classification algorithms were generated by combing two deep learning models (i.e. Simple CNN and Resnet50) and five cases of input bands including incident angles and thermal noise corrected HV bands. For the ten algorithms, analyses were performed by comparing classification results with ground truth points. A confusion matrix and Cohen’s kappa coefficient were produced for the case that showed best result. Furthermore, the classification result with the Maximum Likelihood Classifier that has been traditionally employed to classify sea ice. In conclusion, the Convolutional Neural Network case, which has two convolution layers and two max pooling layers, with HV and incident angle input bands shows classification accuracy of 96.66%, and Cohen’s kappa coefficient of 0.9499. All deep learning cases shows better classification accuracy than the classification result of the Maximum Likelihood Classifier.",
랜섬웨어 방지를 위한 딥러닝 기반의 사용자 비정상 행위 탐지 성능 평가,2019,"IT 기술의 발달에 따라, 컴퓨터 관련 범죄가 빠르게 급증하고 있으며 특히 최근에는 국내외에서 랜섬웨어감염에 대한 피해가 급격하게 늘어나고 있다. 기존의 보안 솔루션으로는 랜섬웨어 감염을 방지하기에는 역부족이며 나날이 발전하는 악성코드 및 랜섬웨어와 같은 위협을 방지하기 위해서는 딥러닝 기술을 결합하여 비정상 행위 및 이상 징후를 탐지하는 기법이 필요하다. 본 논문에서는 CNN-LSTM 모델 및 다양한 딥러닝 모델을 사용하여 사용자 비정상 행위를 탐지하는 기법을 제안했으며, 그중 제안하는 모델인 CNN-LSTM 모델의 경우 액 99%의 정확도로 사용자 비정상 행위를 탐지해내는 것을 확인할 수 있었다. 본 연구를 활용하여사용자 비정상 행위의 랜섬웨어 특징점을 파악하여 랜섬웨어를 방지하는 시스템을 마련하는 데 도움을 줄 수있을 것으로 기대한다.

With the development of IT technology, computer-related crimes are rapidly increasing, and in recent years, the damage to ransomware infections is increasing rapidly at home and abroad. Conventional security solutions are not sufficient to prevent ransomware infections, and to prevent threats such as malware and ransomware that are evolving, a combination of deep learning technologies is needed to detect abnormal behavior and abnormal symptoms. In this paper, a method is proposed to detect user abnormal behavior using CNN-LSTM model and various deep learning models. Among the proposed models, CNN-LSTM model detects user abnormal behavior with 99% accuracy.","#비정상 행위 탐지, #이상 징후 탐지, #랜섬웨어, #딥러닝, #성능 비교, #CNN-LSTM"
초중고 교육을 위한 딥러닝 기반 암석 분류기 개발,2019.1,"최근 딥 러닝(Deep leaning)을 이용한 이미지 인식 분야의 연구가 활발히 진행되고 있다. 본 연구에서는 육안으로 관찰하여 분류하기 어려운 암석을 이미지만으로 분류하기 위해 딥 러닝 오픈 소스 프레임워크인 Tensorflow 기반의 CNN모델을 사용하여 고등학교 교육과정에서 다루는 암석 18종(화성암 6종, 변성암 6종, 퇴적암 6종)의 이미지를 통해 암석을 분류하는 시스템을 제안한다. 암석의 이미지를 학습시켜 암석을 구별하는 분류기를 개발하여 분류 성능을 확인하였으며 최종적으로 구현한 모바일 어플리케이션을 통해 교실 내 학습 또는 현장체험학습 등에서 학생들의 학습 보조도구로서 사용할 수 있다.

These days, as Interest in Image recognition with deep learning is increasing, there has been a lot of research in image recognition using deep learning. In this study, we propose a system for classifying rocks through rock images of 18 types of rock(6 types of igneous, 6 types of metamorphic, 6 types of sedimentary rock) which are addressed in the high school curriculum, using CNN model based on Tensorflow, deep learning open source framework. As a result, we developed a classifier to distinguish rocks by learning the images of rocks and confirmed the classification performance of rock classifier. Finally, through the mobile application implemented, students can use the application as a learning tool in classroom or on-site experience.","#딥 러닝, #텐서플로우, #이미지 인식, #암석 이미지, #교육"
딥러닝모델을 이용한 국가수준 LULUCF 분야 토지이용 범주별 자동화 분류,2019,"신기후체제에 대응하여 정확한 탄소흡수 및 배출량을 산정하기 위해 토지이용 범주별 통계량 산출은활동자료로서 매우 중요한 자료이다. 본 연구는 효과적인 토지이용 범주별 판독을 위하여 산림항공사진(이하FAP)에 딥러닝모델을 적용하여 토지이용 범주별 자동화 판독 분류를 한 후 샘플링기법을 통해 국가단위 통계량을 산출하였다. 딥러닝모델에 적용한 데이터세트(이하, DS)는 국가산림자원조사 고정표본점 위치 기반 FAP의 이미지를 추출하여 훈련데이터세트(이하, 훈련DS)와 시험데이터세트(이하, 시험 DS)로 구분하였다. 훈련DS는 토지이용 범주별 정의에 따라 이미지별 레이블을 부여하였으며, 딥러닝모델을 학습하고 검증하였다. 검증 시 모델의 학습정확도는 학습 횟수 1500회에서 정확도가 약 89%로 가장 높았다. 학습된 딥러닝모델을 시험DS에 적용한 결과, 이미지 레이블의 판독 분류정확도는 약 90%로 높았다. 샘플링기법을 통해 범주별 분류결과에 대해 면적을 추정하여 국가통계와 비교한 결과 정합성 또한 높아 향후 LULUCF(Land Use, Land Use Change, Forestry)분야 국가 온실가스 인벤토리 보고서의 활동자료로 활용하기에 충분하다고 판단된다.

Land use statistics calculation is very informative data as the activity data for calculating exact carbon absorption and emission in post-2020. To effective interpretation by land use category, This study classify automatically image interpretation by land use category applying forest aerial photography (FAP) to deep learning model and calculate national unit statistics. Dataset (DS) applied deep learning is divided into training dataset (training DS) and test dataset (test DS) by extracting image of FAP based national forest resource inventory permanent sample plot location. Training DS give label to image by definition of land use category and learn and verify deep learning model. When verified deep learning model, training accuracy of model is highest at epoch 1,500 with about 89%. As a result of applying the trained deep learning model to test DS, interpretation classification accuracy of image label was about 90%. When the estimating area of classification by category using sampling method and compare to national statistics, consistency also very high, so it judged that it is enough to be used for activity data of national GHG (Greenhouse Gas) inventory report of LULUCF sector in the future.",
위내시경 디지털 영상에서 정상과 위궤양 딥러닝 분류 모델,2019,"내시경 장비의 발전으로 위장 질환의 조기 발견 및 치료에 많은 향상이 있다. 따라서, 많은 내시경 이미지과 함께 내시경 이미지 분류에 대한 연구가 활발히 증가하고 있다. 본 논문에서는 위내시경에서 많이 발견되는 질환인 위궤양을 분류하고자 한다. 위궤양은 초기에 적절한 치료를 하지 않으면 합병증을 일으킬 수 있으므로, 초기에 병변을 진단하는 것이 가장 중요하다. 본 연구에서는 ResNet-50 딥러닝 모델을 이용하여 정상과 위궤양을 분류하고자 하였다. 총 1,525개의 이미지를 이용하여 모델을 생성하였고, 효율적인 학습을 위해 데이터 증강을 적용하였다. 제안된 모델의 분류 성능은 정확도 0.9016, ROC 곡선은 0.83으로 확인하였다.

Due to the development of endoscopic equipment, there has been much progress in the early detection and treatment of gastrointestinal diseases. Therefore, many endoscopic images have been provided, and studies on endoscopic image classification have been increased actively. In this paper, we aim to classify gastric ulcer, a disease frequently found in endoscopy.Gastric ulcers can lead to complications if not properly treated early on, so it is most important to diagnose the lesions early.Our study used the ResNet-50 in-depth learning model. A model was created using a total of 1,525 images, and data enhancement was applied for efficient learning. The classification performance of the proposed model is 0.9016 with accuracy and 0.83 with ROC curve.","#위궤양, #내시경 영상, #딥러닝, #인공지능"
터널 내 돌발상황 오탐지 영상의 반복 학습을 통한 딥러닝 추론 성능의 자가 성장 효과,2019.1,"대부분 딥러닝 모델의 학습은 입력값과 입력값에 따른 출력값이 포함된 레이블링 데이터(labeling data)를 학습하는 지도 학습(supervised learning)으로 진행된다. 레이블링 데이터는 인간이 직접 제작하므로 데이터의 정확도가 높다는 장점이 있지만 비용과 시간의 문제로 인해 데이터의 확보에 많은 노력이 소요된다. 그리고 지도 학습의 목표는 정탐지 데이터(true positive data)의 인식 성능 향상에 초점이 맞추어져 있으며, 오탐지 데이터(false positive data)의 발생에 대한대처는 미흡한 실정이다. 본 논문은 터널 관제센터에 투입된 딥러닝 모델 기반 영상유고 시스템의 모니터링을 통해 정탐지와 레이블링 데이터의 학습으로 예측하기 힘든 오탐지의 발생을 확인하였다. 오탐지의 유형은 작업차량의 경광등, 터널 입구부에서 반사되는 햇빛, 차선과 차량의 일부에서 발생하는 길쭉한 검은 음영 등이 화재와 보행자로 오탐지되고 있었다. 이러한 문제를 해결하기 위해 현장에서 발생한 오탐지 데이터와 레이블링 데이터를 동시에 학습하여 딥러닝 모델을 개발하였으며, 그 결과 기존 레이블링 데이터만 학습한 모델과 비교하면 레이블링 데이터에 대한 재추론 성능이 향상됨을 알 수 있었다. 그리고 오탐지 데이터에 대한 재추론을 한 결과 오탐지 데이터를 많이 포함하여 학습한 모델일 경우보행자의 오탐지 개수가 훨씬 줄었으며, 오탐지 데이터의 학습을 통해 딥러닝 모델의 현장 적용성을 향상시킬 수 있었다.

Most of deep learning model training was proceeded by supervised learning, which is to train labeling data composed by inputs and corresponding outputs. Labeling data was directly generated manually, so labeling accuracy of data is relatively high. However, it requires heavy efforts in securing data because of cost and time. Additionally, the main goal of supervised learning is to improve detection performance for ‘True Positive’ data but not to reduce occurrence of ‘False Positive’ data. In this paper, the occurrence of unpredictable ‘False Positive’ appears by trained modes with labeling data and ‘True Positive’ data in monitoring of deep learning-based CCTV accident detection system, which is under operation at a tunnel monitoring center. Those types of ‘False Positive’ to ‘fire’ or ‘person’ objects were frequently taking place for lights of working vehicle, reflecting sunlight at tunnel entrance, long black feature which occurs to the part of lane or car, etc. To solve this problem, a deep learning model was developed by simultaneously training the ‘False Positive’ data generated in the field and the labeling data. As a result, in comparison with the model that was trained only by the existing labeling data, the re-inference performance with respect to the labeling data was improved. In addition, re-inference of the ‘False Positive’ data shows that the number of ‘False Positive’ for the persons were more reduced in case of training model including many ‘False Positive’ data. By training of the ‘False Positive’ data, the capability of field application of the deep learning model was improved automatically.","#False Positive data, #Labeling data, #Deep learning-based CCTV incident detection system, #Deep learning model training including False Positive data"
딥러닝을 이용한 WTCI 설태량 평가를 위한 유효성 검증,2019,"한방 설진에서 WTCI(Winkel Tongue Coating Index) 설태 평가는 환자의 설태량 측정을 위한 중요한 객관적인 지표 중의 하나이다. 그러나 이전의 WTCI 설태 평가는 혀영상으로부터 설태 부분을 추출하여 전체 혀 영역에서 추출된 설태 영역의 비율을 정량적으로 측정하는 방법이 대부분으로 혀영상의 촬영 조건이나 설태 인식 성능에 의해서 비객관적 측정의 문제점이 있었다. 따라서 본 논문에서는 빅데이터를 기반으로 하는 인공지능의 딥러닝 방법을 적용하여 설태량을 분류하여 평가하는 딥러닝 기반의 WTCI 평가 방법을 제안하고 검증한다. 설태 평가 방법에 있어서 딥러닝의 유효성 검증을 위해서는 CNN을 학습 모델로 사용하여 소태, 박태, 후태의 3가지 유형의 설태량을 분류한다. 설태 샘플 영상을 학습 및 검증 데이터로 구축하여 CNN 기반의 딥러닝 모델로 학습한 결과 96.7%의 설태량 분류 정확성을 보였다.

A WTCI is an important criteria for evaluating an mount of patient’s tongue coating in tongue diagnosis. However, Previous WTCI tongue coating evaluation methods is a most of quantitatively measuring ration of the extracted tongue coating region and tongue body region, which has a non-objective measurement problem occurring by exposure conditions of tongue image or the recognition performance of tongue coating. Therefore, a WTCI based on deep learning is proposed for classifying an amount of tonger coating in this paper. This is applying the AI deep learning method using big data. to WTCI for evaluating an amount of tonger coating. In order to verify the effectiveness performance of the deep learning in tongue coating evaluating method, we classify the 3 types class(no coating, some coating, intense coating) of an amount of tongue coating by using CNN model. As a results by testing a building the tongue coating sample images for learning and verification of CNN model, proposed method is showed 96.7% with respect to the accuracy of classifying an amount of tongue coating.","#Tongue Diagnosis, #WTCI, #the amount of Tongue Coating, #Deep Learning, #Convolutional Neural Network"
딥러닝 개념을 위한 인공지능 교육 프로그램,2019,"본 연구의 목적은 초등학생을 대상으로 한 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 먼저 문헌연구와 선행연구를 토대로 전문가 그룹 토의를 진행하여 프로그램 개발 방향을 위한 준거를 세웠다. 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가들의 타당도와 학습자 만족도 설문 검사를 통해 분석하였다. 전문가 타당도 분석 결과 최소 CVR값이 .56이상을 넘어 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 낯선 소재로 인해 교사들이 어려워하기는 하지만 기존 SW 교육에서 실시했던 언플러그드 CS 활용의 접근법을 통해 수업의 적용이 가능함을 보여주고 있음을 알 수 있었다. 학생들의 만족도 분석 결과 학습자들의 참여는 적극적으로 하였음을 알 수 있었고, 인공지능 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하였다. 이에 본 프로그램은 초등학교 현장에서의 인공지능 교수학습자료의 토대를 제공할 수 있음을 알 수 있다.

The purpose of this study is to develop an educational program for learning deep learning concepts for elementary school students. First of all, based on literature and previous research, a group of experts was discussed to establish the criteria for the direction of program development. The model of education program was developed the deep-learning teaching method based on CT element-oriented teaching and learning model. The subject of the developed program is the artificial intelligence image recognition CNN algorithm, and we have developed 9 educational programs.  We applied the program over six weeks to sixth graders. he test of learning suitability for the education program was analyzed through the validity of the experts and the survey on the satisfaction of learners. Expert validity analysis showed that the minimum CVR value was more than .56. The fitness level of learner level and the level of teacher guidance were less than .80, and the fitness of learning environment and media above .96 was high. Although it is difficult for teachers due to the unfamiliar material of artificial intelligence, it can be seen that the class can be applied through the approach of using the unplugged CS that was implemented in the existing SW education. The students' satisfaction analysis showed that the learners actively participated in the class. Students gave a positive evaluation of the average of 4.0 or higher on the understanding, benefit, interest, and learning materials of artificial intelligence learning. Therefore, it can be seen that the educational program developed in this study can provide a foundation for artificial intelligence teaching and learning materials in elementary school.","#Artificial Intelligence, #Machine Learning, #Deep Learning, #CNN, #SW education"
머신러닝을 통한 건축 도시 데이터 분석의 기초적 연구 - 딥러닝을 이용한 유동인구 모델 구축 -,2019,"In this paper, we construct a prototype model for city data prediction by using time series data of floating population, and use machine learning to analyze urban data of complex structure. A correlation prediction model was constructed using three of the 10 data (total flow population, male flow population, and Monday flow population), and the result was compared with the actual data. The results of the accuracy were evaluated. The results of this study show that the predicted model of the floating population predicts the correlation between the predicted floating population and the current state of commerce. It is expected that it will help efficient and objective design in the planning stages of architecture, landscape, and urban areas such as tree environment design and layout of trails. Also, it is expected that the dynamic population prediction using multivariate time series data and collected location data will be able to perform integrated simulation with time series data of various fields.","#머신러닝, #딥러닝, #도시 계획, #건축 계획"
사물인식을 위한 딥러닝 모델 선정 플랫폼,2019,"""최근 컴퓨터 비전을 활용한 사물인식 기술이 센서 기반 사물인식 기술을 대체할 기술로 주목을 받고 있다. 센서 기반 사물인식 기술은 일반적으로 고가의 센서를 필요로 하기 때문에 기술이 상용화되기 어렵다는 문제가 있었다. 반면 컴퓨터비전을 활용한 사물인식 기술은 고가의 센서 대신 비교적 저렴한 카메라를 사용할 수 있다. 동시에 CNN이 발전하면서실시간 사물인식이 가능해진 이후 IoT, 자율주행자동차 등 타 분야에 활발하게 도입되고 있다. 그러나 사물 인식 모델을상황에 알맞게 선택하고 학습시키기 위해서는 딥러닝에 대한 전문적인 지식을 요구하기 때문에 비전문가가 사물 인식 모델을 사용하기에는 어려움이 따른다. 따라서 본 논문에서는 딥러닝 기반 사물인식 모델들의 구조와 성능을 분석하고, 사용자가 원하는 조건의 최적의 딥러닝 기반 사물 인식 모델을 스스로 선정할 수 있는 플랫폼을 제안한다. 또한 통계에 기반한 사물 인식 모델 선정이 필요한 이유를 실험을 통해 증명한다.""

""Recently, object recognition technology using computer vision has attracted attention as a technology to replace sensor-based object recognition technology. It is often difficult to commercialize sensor-based object recognition technology because such approach requires an expensive sensor. On the other hand, object recognition technology using computer vision may replace sensors with inexpensive cameras. Moreover, Real-time recognition is viable due to the growth of CNN, which is actively introduced into other fields such as IoT and autonomous vehicles. Because object recognition model applications demand expert knowledge on deep learning to select and learn the model, such method, however, is challenging for non-experts to use it. Therefore, in this paper, we analyze the structure of deep - learning - based object recognition models, and propose a platform that can automatically select a deep - running object recognition model based on a user 's desired condition. We also present the reason we need to select statistics-based object recognition model through conducted experiments on different models.""","#Deep Learning, #Neural Network, #Object Recognition, #Platform"
영상기반 딥러닝 및 이미지 프로세싱 기법을 이용한 볼트풀림 손상 검출,2019,"본 연구에서는 영상기반 딥러닝 및 이미지 프로세싱 기법을 이용한 볼트풀림 손상검출 기법을 제안하였다. 이를 위해 먼저, 딥러닝 및 이미지 프로세싱 기반 볼트풀림 검출 기법을 설계하였다. 영상기반 볼트풀림 검출 기법은 볼트 이미지 검출 과정 및 볼트풀림 각도 추정 과정으로 구성된다. 볼트 이미지의 검출을 위하여 RCNN기반 딥러닝 알고리즘을 이용하였다. 영상의 원근왜곡 교정을 위해 호모그래피 개념을 이용하였으며 볼트풀림 각도를 추정을 위하여 Hough 변환을 이용하였다. 다음으로 제안된 기법의 성능을 검증을 위하여 거더의 볼트 연결부 모형을 대상으로 볼트풀림 손상검출 실험을 수행하였다. 다양한 원근 왜곡 조건에 대하여 RCNN 기반 볼트 검출기와 Hough 변환 기반 볼트풀림 각도 추정기의 성능을 검토하였다.

In this paper, a vision-based deep learning algorithm and image processing method are proposed to detect bolt-loosening in steel connections. To achieve this objective, the following approaches are implemented. First, a bolt-loosening detection method that includes regional convolutional neural network(RCNN)-based deep learning algorithm and Hough line transform(HLT)-based image processing algorithm are designed. The RCNN-based deep learning algorithm is developed to identify and crop bolts in a connection image. The HLT-based image processing algorithm is designed to estimate the bolt angles from the cropped bolt images. Then, the proposed vision-based method is evaluated for verifying bolt-loosening detection in a lab-scale girder connection. The accuracy of the RCNN-based bolt detector and HLT-based bolt angle estimator are examined with respect to various perspective distortions.","#bolt-loosening detection, #vision, #deep learning, #RCNN, #image processing, #hough line transform"
딥러닝을 이용한 한국의 물류경쟁력에 관한 연구,2019,"연구목적: 세계은행(WB)에서 발표한 국가별 물류성과지수(LPI)에서 우리나라는 160개국 가운데 2014년 21위, 2016년 24위, 2018년 25위로 지속해서 하락하고 있다. 따라서 본 연구의 목적은 다양한 물류 정책을 추진하고 있음에도 불구하고 LPI 지수가 낮아지는 이유를 국가경쟁력 지수(GCI) 측면에서 분석하여 이를 극복하고 국가 물류경쟁력을 높이는 방안을 모색하고자 하였다. 논문구성/논리: LPI와 GCI를 연계하여 구조화한 후 GCI 측면에서 LPI에 영향을 미치는 가장 중요한 요소를 식별하고자 딥러닝을 이용하여 분석하였다. 또한, 딥러닝 기법은 입력값이 출력값에 미치는 상대적 중요성을 정확하게 해석하기에는 한계가 있다. 이러한 한계를 극복하고자 시나리오 분석을 적용하였다. 결과: 우리나라의 경우 LPI 성과향상을 위해서는 정부규제 부담, 다수 이해당사자 간 협력, 급여와 생산성, 통관절차의 효율성, 초고속 인터넷 가입자 수, 부패지수, 도로연결, 노동세율, 권한위임 의지, 관세의 복잡성, 관세율의 개선이 특히 중요한 것으로 분석되었다. 독창성/가치: 국가적 차원에서 물류경쟁력을 분석하고자 경제 지표와 연계하고, 이러한 상호 연계성을 딥러닝 알고리즘을 이용하여 분석하여 핵심적으로 영향을 미치는 요인을 파악하였다는 데 그 의의가 있다. 특히 우리나라의 경우 경제적 요인뿐만 아니라 부패지수, 사법부의 독립 등의 사회적 요인의 중요성도 국가의 물류성과를 개선하는데 중요한 요소임을 확인할 수 있었다.

Purpose: According to the World Logistics Performance Index (LPI) released by the World Bank, Korea ranks 21st in 2014, 24th in 2016 and 25th in 2018 among 160 countries. Therefore, the purpose of this study is to analyze the reason why the LPI index is lowered even though various logistics policies are being pursued. Composition/Logic: In order to identify the most important factors affecting LPI in terms of Global Competitive Index(GCI), we analyzed it by using deep learning algorithm. In fact, the deep learning technique has a limitation in accurately interpreting the relative importance of the input value to the output value. Thus, scenario analysis was applied to overcome these limitations. Findings: For improving LPI performance, it was found that the burden of government regulations, cooperation among multiple stakeholders, salary and productivity, efficiency of customs procedures, high-speed internet subscribers, corruption index, road connection, labor tax rate, willingness of delegation, tariff complexity, tariff rate were the most influential factors in Korea. Originality/Value: It is meaningful that we analyzed logistics competitiveness at national level by linking with economic indicators and analyzing such interlinkages using deep learning algorithm. Especially, in Korea, the importance of social factors such as corruption index and independence of the judiciary as well as economic factors were also found to be important factors for improvement of national logistics performance.","#Logistics Performance Index, #Global Competitiveness Index, #Deep Learning, #Artificial Neural Network"
딥러닝 알고리즘을 이용한 뇌파-기반 목격 여부 분류 시스템의 성능 비교,2019,"범죄수사 상황에서 피해자와 목격자들의 기억을 평가하는 것은 중요한 문제이다. 하지만 아직까지 기억 정확성을 평가하는 방법은 거의 없다. 본 연구는 딥러닝 기술을 활용하여 뇌파-기반 목격 여부 분류 시스템의 성능을 조사하고자 했다. Ham 등의 실험 2에서6 수집한 69명의 사건관련전위(ERP; event-related potentials) 자료 세트에 합성곱 신경망(CNN; convolutional neural network)과 장단기 기억(LSTM; long-short term memory) 순환 신경망(recurrent neural network)을 이용하여 목격 여부를 분류했다. 실험결과 딥러닝 분류 알고리즘에 따른 차이는 크지 않았지만 1층(layer)의 LSTM를 이용했을 때 분류 정확률이 0.74로 CNN (0.69), 2층 LSTM (0.66), 3층 LSTM (0.69)보다 높았다. 이런 결과는 통계와 컴퓨터 공학 및 인지신경과학적 기법들을 융합하여 피해자와 목격자의 기억 정확성을 객관적으로 평가함으로써 범죄 수사의 효율성을 높일 수 있음을 시사한다.

Evaluating eyewitness memory is an important issue for effective criminal investigation, but there is still little way to assess memory accuracy. This study sought to investigate the performance of the EEG-based eyewitness memory classification system using Deep-Learning. We classified the event-related potentials (ERP) data from 69 participants collected at Ham, Kim, and Jeong (2018)’s experiment using convolutional neural network (CNN) and long-short term memory (LSTM) recurrent neural network. The results showed little difference in classification performance between Deep-Learning algorithms, but 1-layer LSTM showed the highest accuracy (0.74), compared to CNN (0.69), 2-layer LSTM (0.66) and 3-layer LSTM (0.69). These results suggest that the accuracy of eyewitness memory could be assessed using neurobiological data, resulting in effective investigation.","#Memory, #Electroencephalogram, #Deep-Learning, #Long-short term memory, #Convolutional neural network"
[국토교통부] 오픈소스 하드웨어 기반 독거노인 및 장애인 실내 환경 모니터링 시스템 개발 및 클라우드를 통한 지속적 자가 학습 딥러닝 시스템 구현,2019,,"#활동모니터링,, #패턴인식,, #빅데이터분석,, #딥러닝"
[국토교통부] PMV 예측 정확도 10% 및 에너지성능 5% 향상을 위한 인공신경망 및 딥러닝 기반 재실자 행동인식 및 신진대사(MET)산출 원천모델 개발 최종보고서 : 국토교통기술촉진연구사업 제2차 연도 최종보고서,2019,,"#신진대사,, #사물인터넷,, #인공신경망,, #딥러닝,, #온열환경"
딥러닝을 이용한 시스템식별에 관한 연구,2019,"본 논문에서는 시간지연이 존재하는 시스템을 위한 제어기기 동조 문제에서 딥러닝을 이용한 시스템 식별에 관한 연구이다. 시스템 식별을 위한 제어기기 동조에 관현 연구 중 Yunwana와 Seborg(1982)가 제시한 제어기의 동조방법은 Pade’ 근사에 의한 위상 오차 때문에 시간 지연이 없거나 작은 시간 지연에 관하여는 제어가 잘되는 장점이 있으나 큰 시간 지연이 존해 할수록 시간 지연이 크게 추정되고 시스템에서는 적용할 수 없는 단점이 있다. 그리고 산업현장에서 많이 쓰이고 있는 Zigler-Nichols가 제안한 시행착오 방법은 제어기기 동조를 위하여 많은 시간이 소비되는 단점이 있다. Cohen-Coon이 제안한 프로세스 반응곡선을 이용한 제어기기 동조방법은 Zigler-Nichols가 제안한 방법보다는 제어기기 동조에 걸리는 시간이 단축되는 장점이 있지만 개루프 시스템에서만 적용할 수 있고 폐루프 시스템에서는 적용할 수 없는 단점이 있다. 이러한 단점들을 보완하기 위하여 Suh가 제안한 방법은 폐루프 시스템에서도 적용할 수 있는 장점이 있고 또한 시간지연 항을 Pade’근사로 변환시 발생하는 위상오차에 대하여 Pade’근사에서 조절인자의 설정으로 위상오차를 줄여 제어기기의 최적 동조방법에 대하여 제시하였다. 그러나 이러한 방법은 시간 지연항의 상수 값과 비례적으로 조절인자를 대입한 방법이기 때문에 해석적이지 못한 단점이 있다. 본 논문에서는 위상 오차에 대한 이론적 분석을 통해 이와 같은 원인이 Pade’근사에 의한 위상오차와 시간지연 항이 크게 추정되는 문제점을 해결 할 수 있는 해석적인 방법으로 딥 러닝 알고리즘 중에 깊은 믿음 네트워크 알고리즘을 이용한 조절인자의 설정으로 위상 오차를 최적으로 줄일 수 있는 새로운 최적 동조방법을 기존의 본 연구자 Suh(1984)의 연구결과를 바탕으로 제시하였다. 그리고 시물레이션을 통하여 Zielger-Nichols의 시행착오 방법과 Yunwana-Seborg가 제시한 제어기의 동조방법을 비교하여 본 논문에서 제시한 방법의 타당성을 입증하였다.

This paper deals with a study on a system identification using deep learning in the case of a controller tuning for the system where a time delay exists. Of studies on the controller tuning for the system identification, the controller tuning method suggested by Yunwana and Seborg(1982) has an advantage of taking a good control over either none or small time delays due to phase error by Pade' approximation, whereas it comes with a disadvantage of having a greater estimated of time delay over the presence of a large time delay and of being unable to be used in a system. Furthermore, the trial-and-error method suggested by Zigler-Nichols and commonly used in industrial fields shows a disadvantage which is time consuming for a controller tuning. The controller tuning using a process response curve suggested by Cohen-Coon has a benefit of cutting more time taken for a controller tuning than the method by Zigler-Nichols does. It also faces a limitation of being applicable only to the open loop system but not applicable to the close loop system. To make up for these disadvantages, the Suh-suggested method, as its benefit, is applicable even to the close loop system. On top of this, it proposed a controller's optimal tuning method by reducing phase error through setting up control factors in the Pade' approximation with respect to the phase error generated in converting time delay into Pade' approximation. This method, however, involves putting control factors in proportion to time-delay constant values, which is therefore - as a disadvantage - not analytical. This paper went through a theoretical analysis on phase error as an analytical method to solve an issue involving the large estimation of phase error by Pade' approximation and time delay with the use of deep learning. Presented based on the findings of this existing researcher Suh (1984) was a new optimal tuning method dedicated to reducing phase error to a optimal level by setting control factors using the deep belief network algorithm out of deep learning algorithms. Besides, a related simulation was performed to compare the trial-and-error method by Zielger-Nichols and the tuning method for a controller suggested by Yunwana-Seborg, and the validity of the methods suggested in this paper was verified, accordingly.",
시맨틱 갭을 줄이기 위한 딥러닝과 행위 온톨로지의 결합 기반 이미지 검색,2019,"최근 스마트 기기의 발전으로 인터넷상에 존재하는 이미지 데이터의 양이 급속하게 증가하는 상황에서 효과적인 이미지 검색을 위한 다양한 방법들이 연구되고 있다. 기존의 이미지 검색 방법들은 이미지에 존재하는 물체들을 단순하게 검출하여 각 물체들의 라벨 정보에 근거한 검색을 수행하기 때문에 사용자가 원하는 이미지와 검색 결과로 얻은 이미지 간에 의미적 차이인 시맨틱 갭(Semantic Gap)이 발생된다. 이미지 검색에서 발생하는 시맨틱 갭을 줄이기 위해, 본 논문에서는 딥러닝 기반의 다중 객체 분류 모듈과 사람의 행위를 분류하는 모듈을 연결하고, 이 모듈들에 행위 온톨로지를 결합하였다. 즉, 딥러닝과 행위 온톨로지의 결합을 기반으로 객체들 간의 연관성을 고려한 이미지 검색 시스템을 제안한다. 이미지에 포함된 동적인 행위를 고려하기 위해 Walking과 Running 데이터를 이용하여 실험한 결과를 분석하였다. 제안한 방법은 향후 이미지 검색 결과의 정확도를 높일 수 있는 영상의 자동 주석 생성 연구에 확장하여 적용할 수 있다.

Recently, the amount of image on the Internet has rapidly increased, due to the advancement of smart devices and various approaches to effective image retrieval have been researched under these situation. Existing image retrieval methods simply detect the objects in a image and carry out image retrieval based on the label of each object. Therefore, the semantic gap occurs between the image desired by a user and the image obtained from the retrieval result. To reduce the semantic gap in image retrievals, we connect the module for multiple objects classification based on deep learning with the module for human behavior classification. And we combine the connected modules with a behavior ontology. That is to say, we propose an image retrieval system considering the relationship between objects by using the combination of deep learning and behavior ontology. We analyzed the experiment results using walking and running data to take into account dynamic behaviors in images. The proposed method can be extended to the study of automatic annotation generation of images that can improve the accuracy of image retrieval results.","#Semantic Gap, #Image Retrieval, #Behavior Ontology, #Deep Learning, #Combination"
딥러닝 기법을 이용한 차량 연료차단 주행의 감지법,2019,"차량의 변속기어가 체결된 주행 상태에서 가속페달을 방치하는 경우 연료차단 주행이 시작된다. 적극적인 연료차단 주행을 활용하면 차량 연비가 개선된다. 본 연구에서는 차량의 속도, 가속도, 도로구배를 입력데이터로 사용하여 연료차단 주행 여부를 예측할 수 있는 딥러닝 기법을 제안하였다. 약 12km 정도의 도로주행을 통해 측정한 9600개의 데이터에 은닉층 3~10개, 매개변수 10~20개의 딥러닝 연산법을 적용하여 연료차단 주행여부를 예측하였다. 연산 결과, 렐루함수를 활성화함수로 적용하고 은닉층 7개, 매개변수 10개인 경우 정확도 84.5% 수준으로 예측할 수 있었다. 입력데이터인 속도, 가속도, 도로구배의 변화율이 연료소모율 데이터의 변화율에 비해 큰 것이 오차의 원인으로 판단된다. 따라서 입력데이터 정규화 과정을 통해 정확도를 높일 수 있을 것으로 예상된다. 본 연구의 특징은 차량의 연료분사 인젝터나 OBD 데이터를 사용하지 않고 GPS 등에서 쉽게 측정할 수 있는 데이터에 딥러닝을 적용한 방식이다. 또한 연산량이 적어 본 연구에서 제안한 방식으로 친환경 경제운전에 적용하기 용이할 것으로 기대된다.

The Fuel-cut driving is started when the acceleration pedal released with transmission gear engaged. Fuel economy of the vehicle improves by active fuel-cut driving. A deep-learning technique is proposed to predict fuel-cut driving with vehicle speed, acceleration and road gradient data in the study. It’s 3~10 of hidden layers and 10~20 of variables and is applied to the 9600 data obtained in the test driving of a vehicle in the road of 12km. Its accuracy is about 84.5% with 10 variables, 7 hidden layers and Relu as activation function. Its error is regarded from the fact that the change rate of input data is higher than the rate of fuel consumption data. Therefore the accuracy can be better by the normalizing process of input data. It’s unnecessary to get the signal of vehicle injector or OBD, and a deep-learning technique applied to the data to be got easily, like GPS. It can contribute to eco-drive for the computing time small.","#Fuel-cut, #Eco-drive, #Deep-learning, #Fuel economy, #GPS"
딥러닝기반 다중 표적 인식을 활용한 모바일 로봇 경로 계획,2019,"복합적인 고차원의 임무를 수행하기 위하여 미래무인화 전투 체게는 인공지능 기술을 필요로 한다. 특히 합성곱 신경망은 영상뿐만 아니라 자연어 처리까지 광범위한 범위에서 탁월한 성능을 보이고 있어 무인화 전투체계의 표적정보인식, 피아식별, 전장정보인식 등 각종 센서 융합에 매우 적합하다. 본 연구에서는 합성곱 신경망의 영상인식 기술을 활용하여 다수 대상체의 상태정보를 인식함으로써 변화되는 환경에서의 무인로봇 경로 계획 개선 방안을 제시하였고 시뮬레이션을 통하여 추정된 로봇의 위치, 장애물, 목표물 정보로부터 로봇의 경로 계획의 유효성을 검증 하였다.

Unmmanned systems are one of the essential areas of future military weapons systems that must carry out dangerous and cmplex missions. Especially, deep learning should recognize many landmarks through the image and project them onto the map to improve the problem of position estimation, because it shows excellent performance of recognizing and classifying the characteristics of image data among other artificial intelligence techniques. In this study, the path planning of the unmanned reconnaissance aircraft and the unmanned ground vehicle, which are currently being used in the ROK military, is linked with the CNN based multi target recognition algorithm without GPS. Throuth experiments, we verified the effectiveness of the path planning of the mobile robot with respect to the position of the robot, obstacle, and target point estimated by the target detection algorithm.","#표적인식, #경로계획, #장애물 회피, #딥러닝, #모바일 로봇"
머신러닝 및 딥러닝 연구동향 분석: 토픽모델링을 중심으로,2019,"The purpose of this study is to examine the trends on machine learning and deep learning research in the published journals from the Web of Science Database. To achieve the study purpose, we used the abstracts of 20,664 articles published between 1990 and 2017, which include the word 'machine learning', 'deep learning', and 'artificial neural network' in their titles. Twenty major research topics were identified from topic modeling analysis and they were inclusive of classification accuracy, machine learning, optimization problem, time series model, temperature flow, engine variable, neuron layer, spectrum sample, image feature, strength property, extreme machine learning, control system, energy power, cancer patient, descriptor compound, fault diagnosis, soil map, concentration removal, protein gene, and job problem. The analysis of the time-series linear regression showed that all identified topics in machine learning research were 'hot' ones.","#Machine Learning, #Deep Learning, #Artificial Neural Network, #Text Mining"
영상처리와 딥러닝 기법을 사용한 채소의 등급별 자동 분류시스템 개발,2019,"농업에서 생산된 과수나 채소에 대한 질을 확인하고 향상시키는 작업은 영상처리에서 굉장히 중요한 부분이다. 실제 농가에서는 스마트팜(smart_farm)을 도입하여 생산량의 증가로 자연히 수익을 늘어나고 또 노동시간이 단축되며 여가시간이 늘어 농가의 삶의 질을 높일 수 있게 되었다. 본 논문에서는 영상처리 기법과 딥러닝 기술을 사용하여 채소의 등급을 자동 분류하기 위한 시스템을 소개한다. 이를 목적으로 농가에서 직접 재배한 오이를 동일한 배경에서 촬영하여 이미지 데이터와 데이터 증가(augmentation) 기법을 통해 데이터셋을 구성하고 3가지 등급으로 분류하기 위한 기계학습방법인 SVM과 딥러닝 방법인 CNN, VGGNet 등을 사용하였다. 또한 본 연구는 대규모 데이터에서 오이를 기계가 자동으로 중요한 패턴과 규칙을 학습하고 의사결정과 예측 등을 하기 위해 구조나 손실 및 활성화 함수들 그리고 학습비율과 같은 하이퍼 파라미터(hyper-parameter)등을 변경시켜 가며 더 좋은 분류 성능을 내는 알고리즘을 개발하였다. 또한 실험을 통해서 제안된 알고리즘이 농업현장에서 취득한 영상자료를 사용해서 오이를 등급별로 잘 구별하는 것을 확인 할 수 있었다. 앞으로 이를 발전시켜 더 좋은 데이터를 많이 확보하고 훈련을 시킨다면 자동분류 시스템의 개발에 더 좋은 성능이 기대되며, 다양한 방면에 활용이 가능 할 것이다.

Identifying and improving the quality of fruits and vegetables produced in agriculture is a very important part of image processing. The introduction of smart_farm in the farmhouse increased production and naturally increased profit of the farmer. In addition, their working hours have been shortened and leisure time has been increased, so that the quality of life of the farmers can be increased. In this paper, we introduce a system for automatically classifying vegetable grades using image processing and deep-learning techniques. For this purpose, We obtained image data of cucumber cultivated directly in a farmhouse on the same background and constructed a data set using data augmentation technique. In order to classify cucumber into three classes, we used SVM, which is a machine running method, and CNN and VGGNet, which are deep running methods. In this study, we also modified the hyper-parameters such as structure, loss and activation functions and learning rate in order to learn the important patterns and rules of the machine automatically from large data and to make decisions and predictions. Experimental results show that the proposed algorithm can distinguish the cucumber by grade using image data obtained from farming sites. If we improve the performance of the automatic classification system by securing much better data and training, then it can be applied to various aspects.","#vegetable automatic classification system, #machine learning techniques, #CNN, #VGGNet, #cucumber experiment image."
딥러닝 SW 기술을 이용한 임베디드형 융합 CCTV 카메라,2019,"차량 번호판 인식 카메라는 차량 번호판 내 문자와 숫자의 인식을 위하여 대상 차량의 이미지 취득을 목적으로 하는 전용 카메라를 말하며 대부분 단독 사용보다는 서버와 영상 분석 모듈과 결합된 시스템의 일부로 적용된다. 그러나 차량 번호판 인식을 위한 시스템 구축을 위해서는 취득 영상 관리 및 분석 지원을 위한 서버와 문자, 숫자의 추출 및 인식을 위한 영상 분석 모듈을 함께 구성하여야 하므로 구축을 위한 설비가 필요하고 초기 비용이 많이 든다는 문제점이 있다. 이에 본 연구에서는 카메라의 기능을 차량 번호판 인식에만 한정하지 않고 방범 기능을 함께 수행할 수 있도록 확장하고 카메라 단독으로도 두가지 기능 수행이 가능한 Edge Base의 임베디드형 융합 카메라를 개발한다. 임베디드형 융합 카메라는 선명한 영상 취득 및 빠른 데이터 전송을 위해 고해상도 4K IP 카메라를 탑재하고 오픈소스 신경망 알고리즘 기반의 다중 객체 인식을 위한 딥러닝 SW인 YOLO를 적용하여 차량 번호판 영역을 추출한 후 차량 번호판 내의 문자와 숫자를 검출하고 검출 정확도와 인식 정확도를 검증하여 CCTV 방범 기능과 차량 번호 인식 기능이 가능한지를 확인 하였다.

License plate recognition camera is dedicated device designed for acquiring images of the target vehicle for recognizing letters and numbers in a license plate. Mostly, it is used as a part of the system combined with server and image analysis module rather than as a single use. However, building a system for vehicle license plate recognition is costly because it is required to construct a facility with a server providing the management and analysis of the captured images and an image analysis module providing the extraction of numbers and characters and recognition of the vehicle’s plate. In this study, we would like to develop an embedded type convergent camera (Edge Base) which can expand the function of the camera to not only the license plate recognition but also the security CCTV function together and to perform two functions within the camera. This embedded type convergence camera equipped with a high resolution 4K IP camera for clear image acquisition and fast data transmission extracted license plate area by applying YOLO, a deep learning software for multi object recognition based on open source neural network algorithm and detected number and characters of the plate and verified the detection accuracy and recognition accuracy and confirmed that this camera can perform CCTV security function and vehicle number plate recognition function successfully.","#LPR Camera, #CCTV, #convergence, #Edge base, #Embedded, #Image Analysis Module, #Deep Learning SW Technology"
도로포장의 유지관리 계획 수립을 위한 딥러닝 기반 열화 예측 모델 개발,2019,"도로연장의 지속적인 증가와 공용기간이 상당히 경과한 노후 노선이 늘어남에 따라 도로포장에 대한 유지관리비용은 점차 증가하고 있어, 예방적 유지관리를 통해 비용을 최소화 하는 방안에 대한 필요성이 제기되고 있다. 예방적 유지관리를 위해서는 도로포장의 정확한 열화 예측을 통한 전략적 유지관리 계획 수립이 필요하다. 이에 본 연구에서는 고속도로포장 열화예측 모델 개발을 위해 딥러닝 모델 중 가장 보편적으로 많이 사용하는 심층신경망(DNN)과 시계열 데이터 분석에 강점을 가진 순환신경망(RNN)을 사용하였으며, 두 개의 모델의 성능을 비교 분석하여 우수한 모델을 제안하였다. RNN의 Vanishing Gradient Problem을 해결하기 위해 좀 더 복잡한 형태의 RNN구조인 LSTM(Long short-term memory circuits)을 사용하였다. 학습 결과, RNN-LSTM 모델의 RMSE 값이 0.102로 DNN모델보다 낮아 성능이 더 우수하였다. 또한, 대상구간의 시간경과별 평균 도로포장 상태 예측치와 실제 도로포장 상태 실측치의 비교를 통해 RNN-LSTM 모델의 높은 정확도를 검증하였다. 따라서 향후 고속도로 콘크리트 포장의 유지관리 계획 수립시 유지보수 수요 추정을 위한 열화 예측 모델로는 DNN 모델보다 시계열 분석에 강한 RNN-LSTM의 모델을 제안한다.

The maintenance cost for road pavement is gradually increasing due to the continuous increase in road extension as well as increase in the number of old routes that have passed the public period. As a result, there is a need for a method of minimizing costs through preventative grievance preventive maintenance requires the establishment of a strategic plan through accurate prediction of road pavement. Hence, In this study, the deep neural network(DNN) and the recurrent neural network(RNN) were used in order to develop the expressway pavement damage prediction model. A superior model among these two network models was then suggested by comparing and analyzing their performance. In order to solve the RNN's vanishing gradient problem, the LSTM (Long short-term memory) circuits which are a more complicated form of the RNN structure were used. The learning result showed that the RMSE value of the RNN-LSTM model was 0.102 which was lower than the RMSE value of the DNN model, indicating that the performance of the RNN-LSTM model was superior. In addition, high accuracy of the RNN-LSTM model was verified through the comparison between the estimated average road pavement condition and the actually measured road pavement condition of the target section over time.","#Pavement Deterioration Prediction, #Deep Learning, #Recurrent Neural Network, #Long Short-Term Memory, #Deep Neural Network"
영어 리뷰데이터를 이용한 딥러닝 기반 다국어 감성분석,2019.1,"영어로 된 아마존과 같은 대형 글로벌 온라인 쇼핑몰은 전 세계를 대상으로 영어 또는 판매 해당국가 언어로 서비스를 하고 있다. 온라인 쇼핑몰 이용자 중, 많은 고객은 상품 리뷰평가를 참조하여 상품을 구매하고 있다. 그래서 고객들이 작성한 대량의 리뷰데이터를 이용하여 구매 상품에 대해 긍정과 부정을 판정하는 감성분석을 영어를 중심으로 활발히 연구되고 분석 결과는 고객의 타켓 마케팅에 활용되고 있다. 하지만 이와 같은 영어 중심의 감성분석 시스템을 전 세계의 다양한 언어에 그대로 적용하기는 어렵다. 따라서 본 연구에서는 영어로 된 50만개 이상의 아마존 푸드 상품 리뷰데이터를 학습과 테스트 데이터로 분리하여 딥러닝 기술 기반의 감성분석 시스템을 구현하였다. 먼저 영어 테스트데이터의 3가지 모델에 대한 감성분석 평가 실험을 한 후에, 같은 데이터를 자동번역기로 7개국(한국어, 일본어, 중국어, 베트남어, 불어, 독어, 영어) 언어로 번역 후에 다시 영어로 번역하여 실험 결과를 얻었다. 감성분석 정확성은 영어(94.35%)에 비해 각 7개국 언어의 평균(91.59%)보다 정확도가 2.77% 정도 낮게 나왔으나 번역 성능 수준에서 실용 가능성을 확인하였다.

Large global online shopping malls, such as Amazon, offer services in English or in the language of a country when their products are sold. Since many customers purchase products based on the product reviews, the shopping malls actively utilize the sentimental analysis technique in judging preference of each product using the large amount of review data that the customer has written. And the result of such analysis can be used for the marketing to look the potential shoppers. However, it is difficult to apply this English-based semantic analysis system to different languages used around the world. In this study, more than 500,000 data from Amazon fine food reviews was used for training a deep learning based system. First, sentiment analysis evaluation experiments were carried out with three models of English test data. Secondly, the same data was translated into seven languages (Korean, Japanese, Chinese, Vietnamese, French, German and English) and then the similar experiments were done. The result suggests that although the accuracy of the sentimental analysis was 2.77% lower than the average of the seven countries (91.59%) compared to the English (94.35%), it is believed that the results of the experiment can be used for practical applications.","#Deep Learning, #Natural Language Processing, #NLP), #Sentimental Analysis, #Shopping Mall, #Word2vec"
수문시계열 분석을 위한 딥러닝 알고리즘 LSTM의 적용성 및 한계,2019.1,"본 연구에서는 다양한 시계열 예측에서 우수한 성과를 보이고 있는 딥러닝 알고리즘 LSTM(Long & Short Term Memory) 모형의 수문시계열 분석에 있어서의 적용성을 검토하고, 모형의 활용가능성과 한계점을 제시하는 것을 목적으로 한다. 이를 위해 물리적 강우-유출 모형과의 비교 검토, 일반하천 및 감조하천에서의 수위 예측, 월강수량 및 댐방류량을 활용한 갈수량 예측 등에 LSTM 모형을 적용하고, 결과분석을 통해 모형의 장 단점을 요약하였다. 상기 목적을 위한 모형적용 결과, LSTM 모형은 수문시계열 예측에 있어 우수한 예측능력을 보이고 있으며, 이는 양적/질적 수문자료가 충분히 확보되었지만, 수문해석 모형구축에 제약이 있는 유역에 대해서 보완적 수단으로 사용이 가능할 것으로 판단된다.",
2D 슈팅 게임 학습 에이전트의 성능 향상을 위한 딥러닝 활성화 함수 비교 분석,2019,"최근 강화 학습을 통해 게임을 학습하는 인공지능 에이전트를 만드는 연구가 활발히 진행되고 있다. 게임을 에이전트에게 학습 시킬 때 어떠한 딥러닝 활성화 함수를 사용하는지에 따라 그 학습 성능이 달라진다. 본 논문은 2D 슈팅 게임 환경에서 에이전트가 강화 학습을 통해 게임을 학습할 경우 어떤 활성화 함수가 최적의 결과를 얻는지를 비교 평가 한다. 이를 위해 비교 평가에서 사용할 메트릭을 정의하고 각 활성화 함수에 따른 메트릭 값을 학습 시간에 따라 그래프로 나타내었다. 그 결과 ELU (Exponential Linear Unit) 활성화 함수에 1.0으로 파라미터 값을 설정할 경우 게임의 보상 값이 다른 활성화 함수보다 평균적으로 높은 것을 알 수 있었고, 가장 낮은 보상 값을 가졌던 활성화 함수와의 차이는 23.6%였다.

Recently, there has been active researches about building an artificial intelligence agent that can learn how to play a game by using re-enforcement learning. The performance of the learning can be diverse according to what kinds of deep learning activation functions they used when they train the agent. This paper compares the activation functions when we train our agent for learning how to play a 2D shooting game by using re-enforcement learning. We defined performance metrics to analyze the results and plotted them along a training time. As a result, we found ELU (Exponential Linear Unit) with a parameter 1.0 achieved best rewards than other activation functions. There was 23.6% gap between the best activation function and the worst activation function.","#Game, #Activation function, #Re-enforcement Learning"
딥러닝 기반의 영상분할을 이용한 토지피복분류,2019,"본 연구에서는 항공정사영상을 이용하여 SegNet 기반의 의미분할을 수행하고, 토지피복분류에서의그 성능을 평가하였다. 의미분할을 위한 분류 항목을 4가지(시가화건조지역, 농지, 산림, 수역)로 선정하였고, 항공정사영상과 세분류 토지피복도를 이용하여 총 2,000개의 데이터셋을 8:2 비율로 훈련(1,600개) 및 검증(400개)로 구분하여 구축하였다. 구축된 데이터셋은 훈련과 검증으로 나누어 학습하였고, 모델 학습 시 정확도에 영향을 미치는 하이퍼파라미터의 변화에 따른 검증 정확도를 평가하였다. SegNet 모델 검증 결과 반복횟수100,000회, batch size 5에서 가장 높은 성능을 보였다. 이상과 같이 훈련된 SegNet 모델을 이용하여 테스트 데이터셋 200개에 대한 의미분할을 수행한 결과, 항목별 정확도는 농지(87.89%), 산림(87.18%), 수역(83.66%), 시가화건조지역(82.67%), 전체 분류정확도는 85.48%로 나타났다. 이 결과는 기존의 항공영상을 활용한 토지피복분류연구보다 향상된 정확도를 나타냈으며, 딥러닝 기반 의미분할 기법의 적용 가능성이 충분하다고 판단된다. 향후 다양한 채널의 자료와 지수의 활용과 함께 분류 정확도 향상에 크게 기여할 수 있을 것으로 기대된다.

We evaluated the land cover classification performance of SegNet, which features semantic segmentation of aerial imagery. We selected four semantic classes, i.e., urban, farmland, forest, and water areas, and created 2,000 datasets using aerial images and land cover maps. The datasets were divided at a 8:2 ratio into training (1,600) and validation datasets (400); we evaluated validation accuracy after tuning the hyperparameters. SegNet performance was optimal at a batch size of five with 100,000 iterations. When 200 test datasets were subjected to semantic segmentation using the trained SegNet model, the accuracies were farmland 87.89, forest 87.18, water 83.66, and urban regions 85.48%; the overall accuracy was 85.48%. Thus, deep learning-based semantic segmentation can be used to classify land cover.",
음절 단위 임베딩과 딥러닝 기법을 이용한 복합명사 분해,2019,"""기존의 복합명사 분해 알고리즘은 미등록어 단위명사들이 포함된 복합명사를 분해할 때 미등록어를 분리하기 어려운 문제가발생한다. 이는 현실적으로 모든 고유명사, 신조어, 외래어 등의 모든 단위 명사를 사전에 등록하는 것은 불가능하다는 한계가존재하기 때문이다. 이 문제를 해결하기 위하여 복합명사 분해 문제를 태그 열 부착(sequence labeling) 문제로 정의하고 음절단위 임베딩과 딥러닝 기법을 이용하는 복합명사 분해 방법을 제안한다. 단위명사 사전을 구축하지 않고 미등록 단위명사를인식하기 위하여 복합명사를 구성하는 각 음절들을 연속적인 벡터 공간에 표현하여 LSTM과 선형체인(linear-chain) CRF를이용하는 방식으로 복합명사를 단위명사들로 분해한다.""

""Traditional compound noun decomposition algorithms often face challenges of decomposing compound nouns into separated nouns when unregistered unit noun is included. It is very difficult for those traditional approach to handle such issues because it is impossible to register all existing unit nouns into the dictionary such as proper nouns, coined words, and foreign words in advance. In this paper, in order to solve this problem, compound noun decomposition problem is defined as tag sequence labeling problem and compound noun decomposition method to use syllable unit embedding and deep learning technique is proposed. To recognize unregistered unit nouns without constructing unit noun dictionary, compound nouns are decomposed into unit nouns by using LSTM and linear-chain CRF expressing each syllable that constitutes a compound noun in the continuous vector space.""","#compound noun decomposition, #bigram, #syllable embedding, #LSTM, #Linear-Chain CRF"
고속 딥러닝 알고리즘의 효과적인 구현,2019,"딥러닝 기반의 인공지능은 많은 응용 분야에서 성공적이었다. 이미지 분류나 물체 감지와 같은 지도 학습은 주로 비전과 자율주행 분야에 사용된다. 그리고 강화 학습은 로봇이나 에너지 최적화에 사용되고 있다. 따라서, 그 성능을 높이기 위하여 많은 연구 논문들이 신경망의 최적화에 집중하고 있다. 그러나 초당 프레임수는 겉으로는 드러나지 않은 또 하나의 중요한 성능지표이다. 이 노트는 전처리와 후처리가 초당 프레임수에 영향을 끼치는 중요한 인자임을 보이고, 신경망을 최적화하는 것으로는 전처리와 후처리를 개선할 수 없음을 보인다. 이것은 전처리와 후처리가 신경망 밖에 구성이 되어 있기 때문이다. 그래서 이 노트에서는 디지털 신호 처리 기술을 이용하여 전처리의 성능을 가속시키는 방법을 제안한다. 디지털 신호를 처리할 때, 양자화 잡음과 연산자들의 비트 길이와의 관계도 논한다. 실제 신경망의 구현은 세가지 단계로 나뉘어지는데, 전처리를 포함한 입력단, 신경망 구성부, 그리고 성능평가부로 나뉘며, 각 구성에 대하여 자세히 보여준다.

AI (Artificial Intelligence) based on deep learning has been successful in many application areas. Supervised learning such as image classification and object detection has been mainly used for vision and ADAS (Advanced Driver Assistance Systems) / AD (Autonomous Driving). And reinforce learning has been generally utilized for robotics and energy optimization. Therefore, in order to improve the performance, many research papers have focused on optimizing neural networks. However, in practice, FPS (frame per second) is a hidden and critical factor because FPS is also included in the performance measurement. This note show that pre-processing and post-processing are major components affecting FPS. And It is verified that FPS cannot be improved by optimizing the neural network itself because the pre-processing and post-processing are out of the neural networks. In this note, fast pre-processing methods on the basis of DSP (digital signal processing) is suggested. For DSP implementation, binary arithmetic is presented and quantization error due to the conversion from floating point calculation to fixed point calculation is discussed. In addition, major design frameworks for deep learning algorithm implementation are compared and their merit and demerit are also summarized. In the note, implementation is categorized into three, i.e., input data generation with pre-processing, model design of neural network, and performance evaluation. With the selected framework, detailed implementation is also presented.",
딥러닝 설명을 위한 슈퍼픽셀 제외-포함 다중스케일 접근법,2019,"""딥러닝이 보편화되면서 예측 결과를 설명하는 연구가 중요해졌다. 최근 슈퍼픽셀에 기반한 다중스케일 결합 기법이 제안되었는데, 물체의 모양을 유지함으로써 시각적 공감이라는 장점을 제공한다. 이 기법은 예측 차이라는 원리에 기반을 두고 있으며, 슈퍼픽셀을 가리고 얻은 예측 결과와 원래 예측 결과의 차이를 보고 돌출맵을 구성한다. 본 논문은 슈퍼픽셀을 가리는 제외연산뿐 아니라 슈퍼픽셀만 보여주는 포함 연산까지 사용하는 새로운 기법을 제안한다. 실험 결과 제안한 방법은 IoU에서 3.3% 의 성능 향상을 보인다""

""As deep learning has become popular, researches which can help explaining the prediction results also become important. Superpixel based multi-scale combining technique, which provides the advantage of visual pleasing by maintaining the shape of the object, has been recently proposed. Based on the principle of prediction difference, this technique computes the saliency map from the difference between the predicted result excluding the superpixel and the original predicted result. In this paper, we propose a new technique of both excluding and including super pixels. Experimental results show 3.3% improvement in IoU evaluation.""","#deep learning, #explanation model, #superpixel, #visualization"
딥러닝을 활용한 흔들림 영상 안정화 알고리즘,2019,"본 논문에서는 딥러닝을 활용한 흔들림 영상 안정화 알고리즘을 제안하였다. 제안하는 알고리즘은 기존 몇 가지 2D, 2.5D 및 3D 기반 안정화 기술과 다르게 딥러닝을 활용한다. 제안하는 알고리즘은 흔들리는 영상을 CNN 네트워크 구조와 LSTM 네트워크 구조를 통한 특징 추출 및 비교하여 이전 프레임과 현재 프레임 간의 특징점 위치 차이를 통해 특징점의 이동 크기와 방향의 반대로 영상을 변환하는 알고리즘이다. 흔들림 안정화를 위한 알고리즘은 각 프레임의 특징 추출 및 비교를 위해 Tensorflow를 활용하여 CNN 네트워크과 LSTM 구조를 구현하였으며, 영상 흔들림 안정화는 OpenCV open source를 활용해 구현하였다. 실험결과 영상의 흔들림이 상하좌우로 흔들리는 영상과, 급격한 카메라 이동이 없는 영상을 실험에 사용하여, 제안한 알고리즘을 적용한 결과 사용한 상하좌우 흔들림 영상에서는 안정적인 흔들림 안정화 성능을 기대할 수 있었다.

In this paper, we proposed a shaking image stabilization algorithm using deep learning. The proposed algorithm utilizes deep learning, unlike some 2D, 2.5D and 3D based stabilization techniques. The proposed algorithm is an algorithm that extracts and compares features of shaky images through CNN network structure and LSTM network structure, and transforms images in reverse order of movement size and direction of feature points through the difference of feature point between previous frame and current frame. The algorithm for stabilizing the shake is implemented by using CNN network and LSTM structure using Tensorflow for feature extraction and comparison of each frame. Image stabilization is implemented by using OpenCV open source. Experimental results show that the proposed algorithm can be used to stabilize the camera shake stability in the up, down, left, and right shaking images.","#Stabilization, #Feature map, #CNN, #LSTM"
딥러닝을 이용한 IOT 기기 인식 시스템,2019,"As the number of IOT devices is growing rapidly, various 'see-thru connection' techniques have been reported for efficient communication with them. In this paper, we propose a deep learning based IOT device recognition system for interaction with these devices. The overall system consists of a TensorFlow based deep learning server and two Android apps for data collection and recognition purposes. As the basic neural network model, we adopted Google's inception-v3, and modified the output stage to classify 20 types of IOT devices. After creating a data set consisting of 1000 images of 20 categories, we trained our deep learning network using a transfer learning technology. As a result of the experiment, we achieve 94.5% top-1 accuracy and 98.1% top-2 accuracy.","#See-Thru Communication, #Deep Learning, #Convolutional Neural Network, #Transfer Learning"
트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용,2019,"Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics.","#Machine Learning, #Deep Learning, #Feature Engineering, #Automated Feature Extraction, #Transaction Data"
일본의 재해 대피 픽토그램에 대한 한국인의 이해 증진을 위한 딥러닝 기반 픽토그램 분류 및 의미 전달 기법,2019,"최근 한국인의 일본 여행이나 취업이 증가하고 있으며, 일본에서는 태풍과 지진으로 인한 재해가 빈번하게 발생하고 있다. 일본은 픽토그램을 활용하여 지진이나 쓰나미와 같은 자연재해 시 대피해야 하는 장소를 안내하고 있지만, 한국인이 재난 대피 픽토그램을 보고 그 의미를 바로 파악하기 힘들다. 본 논문에서는 일본에서 태풍이나 지진과 같은 재해가 발생했을 때, 한국인이 일본의 재해 대피 픽토그램에 대한 이해 증진을 위해 휴대단말을 이용하여 픽토그램을 카메라로 촬영하면 이를 인식하여 한국어로 일본의 재해 대피 픽토그램의 의미를 전달하는 기법을 제안한다. 제안 기법은 딥러닝 기반의 객체 검출 알고리즘을 활용하여 정확하게 픽토그램을 검출하고 그 결과를 한국어 안내로 변환하여 한국인 사용자에게 제공한다. 재해 대피 픽토그램 검출을 위해 제안 기법은 MoibleNet을 사용하여 객체의 특징을 추출하고, 추출된 특징을 이용하여 객체 위치를 찾고 클래스를 구분하는데 YOLOv2 의 객체 검출 아키텍처를 사용하였다. 실험 결과, 제안 기법은 재해 대피 표지판의 픽토그램을 98% 이상의 정확도로 인식하였고, 20ms 이하의 처리속도를 제공함을 확인할 수 있었다.

Currently, the number of Koreans travelers and employers to Japan has increased, and disasters caused by typhoons and earthquakes have frequently occurred in Japan. Japan uses pictogram to guide people to evacuate natural disasters such as earthquakes and tsunamis. But it is hard for Korean to understand the disaster evacuation pictogram because the pictogram is unfamiliar to Koreans. In this paper, we propose a meaning method for improving Korean understanding of Japanese disaster evacuation pictogram, which recognizes the pictogram on a portable device when a disaster such as a typhoon or an earthquake occurred in Japan. The proposed method detects a pictogram accurately by using a deep-learning based object detection algorithm and the results of detection are matched the table of pictogram interpretation in Korean. For detection of disaster evacuation pictogram, the proposed method extracts object features using MoibleNet, and uses object detection architecture of YOLOv2 to locate and classify objects using the extracted features. Experimental results show that the proposed method recognizes pictogram of disaster evacuation signboards with accuracy of 98% or more and provides processing speed of 20ms or less.","#pictogram, #Japanese disaster, #deep learning, #object detection"
[국토교통부] 터널 내 사고 초동대응을 위한 딥러닝 기반 CCTV 영상유고 시스템 개발 최종보고서 : 국토교통기술사업화지원사업 제3차년도 최종보고서,2019,,"#터널, #재난,, #대응, #시스템,, #학습머신, #알고리즘,, #패턴, #분석기법,, #유고감시"
불완전한 데이터를 위한 딥러닝 모델,2019.1,"제안 모델은 소실 데이터를 포함하는 불완전한 데이터에서 정보의 손실을 최소화할 수 있도록 개발되었다. 이를 위한 과정은 우선 데이터 확장기법을 이용하여 손실 정보를 보상하도록 학습 데이터를 변환한다. 이 변환 과정에서 데이터의 속성값은 원-핫 인코딩으로 이진 또는 확률값으로 채워진다. 다음 이 변환 데이터는 딥러닝 모델에 입력되는데, 이때 각 속성의 카디너리티에 따라 엔트리 수가 일정하지 않게 된다. 그리고 각 속성의 엔트리 값들을 각각의 입력 노드에 할당하고 학습을 진행한다. 이점이 기존 학습 모델과의 차이점으로, 임의의 속성값이 입력층에서 여러 개의 노드로 분산되는 특이한 구조를 가진다. 제안 모델의 학습 성능을 평가하기 위해, 소실 데이터를 대상으로 다양한 실험을 수행하여 성능 면에서 우수함을 보인다. 제안 모델은 유비쿼터스 환경에서 손실을 최소화하기 위한 알고리즘으로 유용하게 사용될 것으로 본다.

The proposed model is developed to minimize the loss of information in incomplete data including missing data. The first step is to transform the learning data to compensate for the loss information using the data extension technique. In this conversion process, the attribute values of the data are filled with binary or probability values in one-hot encoding. Next, this conversion data is input to the deep learning model, where the number of entries is not constant depending on the cardinality of each attribute. Then, the entry values of each attribute are assigned to the respective input nodes, and learning proceeds. This is different from existing learning models, and has an unusual structure in which arbitrary attribute values are distributedly input to multiple nodes in the input layer. In order to evaluate the learning performance of the proposed model, various experiments are performed on the missing data and it shows that it is superior in terms of performance. The proposed model will be useful as an algorithm to minimize the loss in the ubiquitous environment.","#Deep learning model, #Extended data expression, #Incomplete data, #Attribute value, #EBP"
네트워크 공격 탐지 성능향상을 위한 딥러닝을 이용한 트래픽 데이터 생성 연구,2019,"네트워크 공격을 탐지하기 위하여 기계학습을 이용한 다양한 연구가 최근 급격히 증가하고 있다. 이러한 기계학습 방법은 많은 데이터에 의존적이며 연구를 위해 다양한 실험 데이터가 공개되어 사용되고 있다. 하지만 실험 데이터 및 실제 환경에서 수집되는 데이터는 class간의 수량이 불균형하다는 문제점을 가지고 있다. 본 연구에서는 기계 학습을 이용한 침입탐지시스템의 한계점 중 학습데이터의 class간 불균형으로 인한 분류 성능 저하를 해결하기 위한 방법을 제안한다. 이를 위해 네트워크 트래픽 데이터를 처리하고 seqGAN를 이용하여 부족한 데이터를 생성하였다. 제안된 방법은 NSL-KDD, UNSW-NB15 데이터 셋을 대상으로 Text-CNN을 이용하여 분류하는 테스트를 실행한 결과 정밀도가 향상되는 것을 확인할 수 있었다.

Recently, various approaches to detect network attacks using machine learning have been studied and are being applied to detect new attacks and to increase precision. However, the machine learning method is dependent on feature extraction and takes a long time and complexity. It also has limitation of performace due to learning data imbalance. In this study, we propose a method to solve the degradation of classification performance due to imbalance of learning data among the limit points of detection system. To do this, we generate data using Generative Adversarial Networks (GANs) and propose a classification method using Convolutional Neural Networks (CNNs). Through this approach, we can confirm that the accuracy is improved when applied to the NSL-KDD and UNSW-NB15 datasets.","#Network security, #Intrusion detection, #Network traffic data, #Deep learning, #GAN"
딥러닝 기반의 보행자 탐지 및 경보 시스템 연구,2019,"보행자 교통사고의 경우 사고 발생 시 사망사고로 연결되는 위험성이 있다. 국내 지능형교통시스템(ITS)은 질 좋은 교통 인프라를 구축하고 있음에도 불구하고, 거의 교통정보 수집에만 이용되고 있어, 위험상황 발생 시 지능적인 위험 요소 분류가 이루어지지 않고 있다. 본 연구에서 제안하는 시스템의 주요 구성 요소인 CNN 기반의 보행자 탐지 분류 모델의 경우 제한적인 환경에서 설치 운영되는 것을 가정하여 임베디드 시스템 기반으로 구현되었다. 기존YOLO의 인공신경망 모델을 개선하여 My-Tiny-Model3라는 새로운 모델을 생성하였고, 20,000 번의 반복 학습 기준으로 평균 정확도 86.29%와 21.1 fps의 실시간 탐지 속도 결과를 보였다. 그리고, 이러한 탐지 시스템을 기반으로 하여 ITS 체계와 연계 가능한 시스템 구현 및 프로토콜 연동 시나리오를 구성하였다. 본 연구를 통해 기존 ITS 체계와 연동하는 보행자 사고 방지시스템을 구현한다면, 새로운 인프라 구축비용을 절감하고 보행자 교통사고 발생률을 줄이는데 도움이 될 것이다. 또한, 기존의 시스템 감시인력 소요에 따른 비용 또한 줄일 수 있을 것으로 기대된다.

In the case of a pedestrian traffic accident, it has a large-scale danger directly connected by a fatal accident at the time of the accident. The domestic ITS is not used for intelligent risk classification because it is used only for collecting traffic information despite of the construction of good quality traffic infrastructure. The CNN based pedestrian detection classification model, which is a major component of the proposed system, is implemented on an embedded system assuming that it is installed and operated in a restricted environment. A new model was created by improving YOLO's artificial neural network, and the real-time detection speed result of average accuracy 86.29% and 21.1 fps was shown with 20,000 iterative learning. And we constructed a protocol interworking scenario and implementation of a system that can connect with the ITS. If a pedestrian accident prevention system connected with ITS will be implemented through this study, it will help to reduce the cost of constructing a new infrastructure and reduce the incidence of traffic accidents for pedestrians, and we can also reduce the cost for system monitoring.","#Pedestrian traffic accident prevention, #CNN, #YOLO, #ITS, #UTIS"
LSTM과 GRU 딥러닝 IoT 파워미터 기반의 단기 전력사용량 예측,2019,"본 연구에서는 Long Short Term Memory (LSTM) 신경망과 Gated Recurrent Unit(GRU) 신경망을 Internet of Things (IoT) 파워미터에 적용하여 단기 전력사용량 예측방법을 제안하고, 실제 가정의 전력사용량 데이터를 토대로 예측 성능을 분석한다. 성능평가 지표로써 Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Mean Percentage Error (MPE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE)를 이용한다. 실험 결과는 GRU 기반의 모델이 LSTM 기반의 모델에 비해 MAPE 기준으로 4.52%, MPE 기준으로 5.59%만큼의 성능개선을 보였다.

In this paper, we propose a short-term power forecasting method by applying Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural network to Internet of Things (IoT) power meter. We analyze performance based on real power consumption data of households. Mean absolute error (MAE), mean absolute percentage error (MAPE), mean percentage error (MPE), mean squared error (MSE), and root mean squared error (RMSE) are used as performance evaluation indexes. The experimental results show that the GRU-based model improves the performance by 4.52% in the MAPE and 5.59% in the MPE compared to the LSTM-based model.","#Power Meter, #Internet of Things, #Deep Learning, #LSTM, #GRU, #Short-term Power Forecasting"
한국인 영어학습자의 영어 문장은 얼마나 원어민스러운가: 딥러닝 기반 분석,2019,"Building upon the state-of-the-art deep learning techniques, the present study classifies the texts written by Korean EFL learners and English native speakers and thereby demonstrates how the two types of texts differ from each other. To this end, the current work makes use of the Yonsei English Learner Corpus (YELC) and Gacheon Learner Corpus (GLC) as the L2 data, and Corpus of Contemporary American English (COCA) as the L1 data. Utilizing the sentence classification methods, the current work implements a system to differentiate the two types of texts, the accuracy of which is about 94%. This indicates that the deep leaning-based system is capable of identifying the well-formedness and felicities of the texts written by Korean EFL learners. Nonetheless, the system-based judgments do not overlap with human judgments largely because the deep learning model exclusively focuses on sequence of words. The present study provides a further analysis to see how the two types of judgments differ with respect to grammatical errors (e.g., word order, voice, etc.) and felicity errors (e.g., semantic prosody, the position of adverbs, etc.).","#deep learning, #classification, #learner corpus, #error analysis"
딥러닝과 전이학습을 이용한 콘크리트 균열 인식 및 시각화,2019,"Although crack on concrete exists from its early formation, crack requires attention as it affects stiffness of structure and can lead demolition of structureas it grows. Detecting cracks on concrete is needed to take action prior to performance degradation of structure, and deep learning can be utilized forit. In this study, transfer learning, one of the deep learning techniques, was used to detect the crack, as the amount of crack’s image data was limited. Pre-trained Inception-v3 was applied as a base model for the transfer learning. Web scrapping was utilized to fetch images of concrete wall with orwithout crack from web. In the recognition of crack, image post-process including changing size or removing color were applied. In the visualizationof crack, source images divided into 30px, 50px or 100px size were used as input data, and different numbers of input data per category were appliedfor each case. With the results of visualized crack image, false positive and false negative errors were examined. Highest accuracy for the recognizingcrack was achieved when the source images were adjusted into 224px size under gray-scale. In visualization, the result using 50 data per category under100px interval size showed the smallest error. With regard to the false positive error, the best result was obtained using 400 data per category, andregarding to the false negative error, the case using 50 data per category showed the best result.",
딥러닝을 이용한 당뇨성황반부종 등급 분류의 정확도 개선을 위한 검증 데이터 증강 기법,2019,"This paper proposed a method of validation data augmentation for improving the grading accuracy of diabetic macular edema (DME) using deep learning. The data augmentation technique is basically applied in order to secure diversity of data by transforming one image to several images through random translation, rotation, scaling and reflection in preparation of input data of the deep neural network (DNN). In this paper, we apply this technique in the validation process of the trained DNN, and improve the grading accuracy by combining the classification results of the augmented images. To verify the effectiveness, 1,200 retinal images of Messidor dataset was divided into training and validation data at the ratio 7:3. By applying random augmentation to 359 validation data, 1.61 ± 0.55% accuracy improvement was achieved in the case of six times augmentation (N=6). This simple method has shown that the accuracy can be improved in the N range from 2 to 6 with the correlation coefficient of 0.5667. Therefore, it is expected to help improve the diagnostic accuracy of DME with the grading information provided by the proposed DNN.",
반도체 제조라인 내 물류자동화시스템의 처리능력 향상을 위한 딥러닝 기반 디스패칭 방법론,2019,"We present a deep-learning-based prediction method for the machine allocation problem of production scheduling in semiconductor manufacturing fabrication (FAB). This method is devised to improve the throughput capacity of the automated material handling system (AMHS). A prediction method is applied to determine the machine to perform the next process after a lot completes a process. Selecting the proper machine for the next process can shorten the travel distance of the overhead hoist transfers (OHTs), and this will eventually lead to reduced utilization and increased throughput capacity of the AMHS. The results confirm that the accuracy of our deep-learning-based machine selecting method is quite high and that it outperforms the other machine learning methods.","#Scheduling, #Deep learning, #Semiconductor manufacturing, #Lot targeting"
딥러닝 기반 3차원 라이다의 반사율 세기 신호를 이용한 흑백 영상 생성 기법,2019,"In this paper, we propose a method of generating a 2D gray image from LiDAR 3D reflection intensity. The proposed method uses the Fully Convolutional Network (FCN) to generate the gray image from 2D reflection intensity which is projected from LiDAR 3D intensity. Both encoder and decoder of FCN are configured with several convolution blocks in the symmetric fashion. Each convolution block consists of a convolution layer with 3×3 filter, batch normalization layer and activation function. The performance of the proposed method architecture is empirically evaluated by varying depths of convolution blocks. The well-known KITTI data set for various scenarios is used for training and performance evaluation. The simulation results show that the proposed method produces the improvements of 8.56 dB in peak signal-to-noise ratio and 0.33 in structural similarity index measure compared with conventional interpolation methods such as inverse distance weighted and nearest neighbor. The proposed method can be possibly used as an assistance tool in the night-time driving system for autonomous vehicles.",
딥러닝 기술을 이용한 트러스 구조물의 손상 탐지,2019,"There has been considerable recent interest in deep learning techniques for structural analysis and design. However, despite newer algorithms and more precise methods have been developed in the field of computer science, the recent effective deep learning techniques have not been applied to the damage detection topics. In this study, we have explored the structural damage detection method of truss structures using the state-of-the-art deep learning techniques. The deep neural networks are used to train knowledge of the patterns in the response of the undamaged and the damaged structures. A 31-bar planar truss are considered to show the capabilities of the deep learning techniques for identifying the single or multiple-structural damage. The frequency responses and the elasticity moduli of individual elements are used as input and output datasets, respectively. In all considered cases, the neural network can assess damage conditions with very good accuracy.","#Damage detection, #Deep learning, #Neural network, #Truss structure"
딥러닝 기반 교량 손상추정을 위한 Generative Adversarial Network를 이용한 가속도 데이터 생성 모델,2019,"Maintenance of aging structures has attracted societal attention. Maintenance of the aging structure can be efficiently performed with a digital twin. In order to maintain the structure based on the digital twin, it is required to accurately detect the damage of the structure. Meanwhile, deep learning-based damage detection approaches have shown good performance for detecting damage of structures. However, in order to develop such deep learning-based damage detection approaches, it is necessary to use a large number of data before and after damage, but there is a problem that the amount of data before and after the damage is unbalanced in reality. In order to solve this problem, this study proposed a method based on Generative adversarial network, one of Generative Model, for generating acceleration data usually used for damage detection approaches. As results, it is confirmed that the acceleration data generated by the GAN has a very similar pattern to the acceleration generated by the simulation with structural analysis software. These results show that not only the pattern of the macroscopic data but also the frequency domain of the acceleration data can be reproduced. Therefore, these findings show that the GAN model can analyze complex acceleration data on its own, and it is thought that this data can help training of the deep learning-based damage detection approaches.","#생성모델, #손상추정기법, #디지털 트윈, #유지관리"
딥러닝 알고리즘 기반 탄산화 진행 예측에서 활성화 함수 적용에 관한 기초적 연구,2019,"Concrete carbonation is one of the factors that reduce the durability of concrete. In modern times, due to industrialization, the carbon dioxide concentration in the atmosphere is increasing, and the impact of carbonation is increasing. So, it is important to understand the carbonation resistance according to the concrete compounding to secure the concrete durability life. In this study, we want to predict the concrete carbonation velocity coefficient, which is an indicator of the carbonation resistance of concrete, through the deep learning algorithm, and to find the activation function suitable for the prediction of carbonation rate coefficient as a process to determine the learning accuracy through the deep learning algorithm. In the scope of this study, using the ReLU function showed better accuracy than using other activation functions.",
일본의 재해 대피 표지판에 대한 한국인 관광객의 이해 증진을 위한 딥러닝 기반 의미 전달 기법,2019,"본 논문에서는 일본 재해 대피 표지판에서 픽토그램 및 대피 장소가 적힌 문자영역을 검출하여 한국인 관광객에게 특정 재해 발생 시 어디로 대피해야 하는지를 알려주는 일본 재해 대피 표지판 의미 전달 기법을 제안한다. 제안 기법은 심층신경망 기반의 객체검출 알고리즘을 이용하여 픽토그램과 문자영역을 검출한다. 픽토그램을 검출하여 해당 재해 대피 표지판의 목적을 추출한다. 그리고 검출된 문자영역에 대해서는 Tesseract 문자인식 알고리즘을 이용하여 문자를 인식한다. 문자 인식을 통해 재난 발생 시 대피장소를 알 수 있다. 픽토그램 검출결과와 문자인식 결과를 이용하여, 한국인 관광객에게 ‘어떤 재난 재해 발생 시 어디로 이동해야 하는 지’에 대해 한국어로 의미를 전달한다. 실험을 통해 일본 재해 대피 표지판의 픽토그램과 문자 영역을 정확하게 검출하고 분류하는 것을 볼 수 있었다. 또한, 일본 재해 대피 표지판의 문자 영역에 대해 일본어 문자를 인식하는 것을 볼 수 있었으며, 그 결과를 한국어로 변환하여 한국인이 이해할 수 있도록 안내할 수 있었다.

In this paper, we propose a meaning transfer method of Japanese disaster evacuation signboard which detects the pictogram and the text spots, which include an evacuation area, on the Japanese disaster evacuation signboard and informs Korean tourists where to evacuate in case of specific disaster. The proposed method detects the pictogram and text regions using deep learning based object detection algorithm. Using results of pictogram detection, we extract the purpose of the disaster evacuation signboard. For text regions, texts are recognized using the Tesseract text recognition algorithm. Through the text recognition, the evacuation site can be identified when a disaster occurs. Using pictogram detection results and character recognition results, Korean visitors are informed about 'where to go when a kind of disasters occurs' in Korean. Through the experiment, the proposed algorithm could detect and classify the pictogram and character area of the Japanese disaster evacuation signboard correctly. Also, the proposed algorithm recognized Japanese characters in the text area of the disaster evacuation signboards in Japan, and the recognized Japanese characters are translated so that Koreans could understand them.","#Japanese disaster evacuation signboard, #object detection, #text recognition, #deep learning algorithm"
Deep Learning Based Tree Recognition rate improving Method for Elementary and Middle School Learning,2019.12,"본 연구의 목적은 수업 시 스마트기기에 적용할 수 있는 나무 이미지를 인식하고 분류하여 정확도를 측정할 수 있는 효율적인 모델을 제안하는 것이다. 2015개정 교육과정으로 개정되면서 초등학교 4학년 과학교과서의 학습 목표에서 스마트 기기 사용한 식물 인식이 새롭게 추가 되었다. 특히 나무 인식의 경우 다른 사물 인식과 달리 수형, 수피, 잎, 꽃, 열매의 부위별 특징이 있으며, 계절에 따라 모양 및 색깔의 변화를 거치므로 인식률에 차이가 존재한다. 그러므로 본 연구를 통해 컨볼루션 신경망 기반의 사전 학습된 인셉션V3모델을 이용하여 재학습 전 후의 나무 부위별 인식률을 비교한다. 또한 각 나무의 유형별 이미지 정확도를 결합시키는 방식을 통해 효율적인 나무 분류 방안을 제시하며 교육현장에서 사용하는 스마트기기에 적용 할 수 있을 것이라 기대한다.

The goal of this study is to propose an efficient model for recognizing and classifying tree images to measure the accuracy that can be applied to smart devices during class. From the 2009 revised textbook to the 2015 revised textbook, the learning objective to the fourth-grade science textbook of elementary schools was added to the plant recognition utilizing smart devices. In this study, we compared the recognition rates of trees before and after retraining using a pre-trained inception V3 model, which is the support of the Google Inception V3. In terms of tree recognition, it can distinguish several features, including shapes, bark, leaves, flowers, and fruits that may lead to the recognition rate. Furthermore, if all the leaves of trees may fall during winter, it may challenge to identify the type of tree, as only the bark of the tree will remain some leaves. Therefore, the effective tree classification model is presented through the combination of the images by tree type and the method of combining the model for the accuracy of each tree type. I hope that this model will apply to smart devices used in educational settings.","#Machine Learning, #Deep Learning, #Convolutional Neural Network, #CNN, #Inception V3, #Smart Device Education, #머신러닝, #딥러닝, #컨볼루션 신경망, #인셉션V3, #스마트기기교육"
Challenges in Memory Optimization for Deep Learning Model Training,2019.12,,
Web access prediction based on parallel deep learning,2019.11,"웹에서 정보 접근에 대한 폭발적인 주문으로 웹 사용자의 다음 접근 페이지를 예측하는 필요성이 대두되었다. 웹 접근 예측을 위해 마코브(markov) 모델, 딥 신경망, 벡터 머신, 퍼지 추론 모델등 많은 모델이 제안되었다. 신경망 모델에 기반한 딥러닝 기법에서 대규모 웹 사용 데이터에 대한 학습 시간이 엄청 길어진다. 이 문제를 해결하기 위하여 딥 신경망 모델에서는 학습을 여러 컴퓨터에 동시에, 즉 병렬로 학습시킨다. 본 논문에서는 먼저 스파크 클러스터에서 다층 Perceptron 모델을 학습 시킬 때 중요한 데이터 분할, shuffling, 압축, locality와 관련된 기본 파라미터들이 얼마만큼 영향을 미치는지 살펴보았다. 그 다음 웹 접근 예측을 위해 다층 Perceptron 모델을 학습 시킬 때 성능을 높이기 위하여 이들 스파크 파라미터들을 튜닝 하였다. 실험을 통하여 논문에서 제안한 스파크 파라미터 튜닝을 통한 웹 접근 예측 모델이 파라미터 튜닝을 하지 않았을 경우와 비교하여 웹 접근 예측에 대한 정확성과 성능 향상의 효과를 보였다.

Due to the exponential growth of access information on the web, the need for predicting web users’ next access has increased. Various models such as markov models, deep neural networks, support vector machines, and fuzzy inference models were proposed to handle web access prediction. For deep learning based on neural network models, training time on large-scale web usage data is very huge. To address this problem, deep neural network models are trained on cluster of computers in parallel. In this paper, we investigated impact of several important spark parameters related to data partitions, shuffling, compression, and locality (basic spark parameters) for training Multi-Layer Perceptron model on Spark standalone cluster. Then based on the investigation, we tuned basic spark parameters for training Multi-Layer Perceptron model and used it for tuning Spark when training Multi-Layer Perceptron model for web access prediction. Through experiments, we showed the accuracy of web access prediction based on our proposed web access prediction model. In addition, we also showed performance improvement in training time based on our spark basic parameters tuning for training Multi-Layer Perceptron model over default spark parameters configuration.","#Apache Spark, #Neural network, #Parallel deep learning, #Parameter tuning, #Web access prediction, #아파치 스파크, #신경망, #병렬 딥러닝, #파라미터 튜닝, #웹 접근 예측"
Machine Learning and Deep Learning for PHM Applications - Case Studies,2019.11,,"#시스템건강관리(PHM), #머신러닝(Machine learning), #딥러닝(Deep learning)"
A deep learning application using convolutional neural networks for predicting injection molding analysis results,2019.11,,"#딥러닝 (Deep learning), #합성곱 신경망 (Convolutional neural networks), #사출성형해석 (Injection molding analysis)"
Optimal Operation of ESS using Deep Learning and Model Predictive Control,2019.11,,"#Renewable energy(신재생 에너지), #ESS(에너지 저장 시스템), #Pricing scheme (가격 구조), #Rule-based control(경험규칙 제어), #Deep learning(딥러닝), #Model predictive control(모델 기반 제어)"
Intention prediction of the surrounding vehicles using hierarchical DNN in lane merge scenarios,2019.11,,
Prediction of Compound-Protein Interactions Using Deep Learning Top 10%,2019.10,"화합물과 단백질 간의 상호작용을 특성화하는 것은 약물 개발 및 탐색을 위해 중요한 과정이다. 상호작용을 파악하기 위해 단백질과 화합물의 구조 데이터를 이용하지만 그 구조가 알려져 있지 않은 경우도 많으며, 많은 계산 양으로 인해 예측의 속도와 정확도도 떨어질 수 있다는 한계가 있다. 본 논문에서는 기계번역에서 사용되는 sequence-to-sequence 알고리즘과 입력벡터를 효과적으로 축소시키기 위한 오토 인코더를 결합한 모델인 S2SAE (Sequence-To-Sequence Auto-Encoder)를 이용하여 화합물-단백질 상호작용을 예측하였다. 본 논문에서 제안한 방법은 기존의 복합체를 나타내는 표현들보다 적은 수의 특징들을 이용하여 상호작용을 예측할 수 있으며, 기존의 방법보다 높은 예측 정확도를 보여주었다.

Characterizing the interactions between compounds and proteins is an important process for drug development and discovery. Structural data of proteins and compounds are used to identify their interactions, but those structural data are not always available, and the speed and accuracy of the predictions made in this way ware limited due to the large number of calculations involved. In this paper, compound-protein interactions were predicted using S2SAE (Sequence-To-Sequence Auto-Encoder), which is composed of a sequence-to-sequence algorithm used in machine translation as well as an auto-encoder for effective compression of the input vector. Compared to the existing method, the method proposed in this paper uses fewer features of protein-compound complex and also show higher predictive accuracy.","#기계 번역, #딥러닝, #신약 개발, #화합물-단백질 상호작용, #분류분석, #Machine translation, #deep learning, #drug development, #compound-protein interaction, #classification"
Sports Broadcasting with Deep Learning,2019.10,"스포츠 캐스팅을 할 때는 스포츠 장면에 대한 상황 정보, 선수 정보 그리고 과거 지식을 기반으로 현재 상황에 대한 이해와 추론이 필요하다. 본 논문에서는 장면 분류 모델, 선수 검출 모델 그리고 선수의 행동 인식 모델을 학습하여 스포츠 영상에 대한 정보를 얻고 과거 데이터를 지식화 해서 저장 해놓은 온톨로지를 이용하여 현재 상황에 대한 이해와 추론을 하는 방법을 소개한다. 총 3가지 종류의 캐스팅을 생성한다. 실시간 웹 데이터로부터 지식화 하여 캐스팅을 생성하고, 13개의 장면을 분류하여 온톨로지와 결합하여 캐스팅을 생성한다. 그리고 선수의 포지션과 8개의 행동을 인식하여 온톨로지와 결합하여 캐스팅을 생성한다. 모든 데이터는 2018년 4월 1일부터 2018년 4월 14일까지 있었던 KBO 경기를 직접 labeling 하여 모델을 학습하였다.

Sports broadcasting requires understanding and reasoning of a current situation based on information regarding sports scenes, players, and past knowledge. In this paper, we introduced how scene classifier, player detector, motion recognizer could be used to obtain information on sports images and understand current situations. We created three types of commentaries. One was from web data, another was from 13 scenes with scene classifier, and the other was generated by the position of the players, eight motions, and the ontology. Data from the KBO (Korea Baseball Organization League) games from April 1, 2018, to April 14, 2018, were directly labeled to learn the model.","#딥러닝, #물체 검출, #사람 검출, #행동 인식, #온톨로지, #스포츠 캐스팅, #deep-learning, #object detection, #human detection, #motion recognition, #ontology, #sports commentary"
Development of Adverse Outcome Pathway : ToxCast™ database and a deep learning artificial neural network model based approach,2019.10,,"#Adverse Outcome Pathway, #pulmonary fibrosis, #ToxCast, #deep learning, #chemical prioritization"
Identification of RNA N6-Methyladenosine Sites by Using Deep Learning,2019.10,,
A Study on Deep Learning based Interactive Digital Signage Design using Edge Computing,2019.10,,
Identification of protein ligand binding residue having variable length sequences using deep learning,2019.10,,
Prediction and Classification of Pilot’s Cognitive Workload via Deep Learning of Multivariate Data,2019.10,,"#Cognitive workload, #Flight performance, #Body reaction, #Machine learning, #Classification, #Prediction, #Deep learning"
Deep Learning Model based on Autoencoder for Reducing Algorithmic Bias of Gender,2019.8,"알고리즘 편향성은 알고리즘 설계과정에서 트레이닝 데이터에서의 편견이나 모델과 데이터의 특성 사이의 조합에 의해 모델에 반영되는 편향을 의미한다. 최근에는 이러한 편향성이 딥러닝 모델에서 나타날 뿐만 아니라 증폭된다는 연구가 진행되면서 편향성 제거에 관한 문제가 제기되고 있다. 본 논문에서는 성별에 의한 알고리즘 편향성을 편향-분산 딜레마의 관점에서 분석하며 편향성의 원인을 규명하였고 이를 해결하기 위해 심층 오토인코더 기반 잠재공간 일치모델을 제안한다. 우리는 딥러닝에서의 알고리즘 편향성은 모델 내부의 특징 추출부분에서 보호특징별 잠재 공간이 다르다는 것을 실험으로 보여주었다. 본 논문에서 제안하는 모델은 성별특징이 다른 데이터를 동일한 잠재공간으로 전사시킴으로써 추출된 특징의 차이를 줄여 저편향성을 달성하였다. 우리는 정량적 평가지표로 Equality of Odds와 Equality of Opportunity를 사용하여 기존모델에 비해 편향성이 낮음을 입증하고 ROC 곡선으로 통해 성별사이의 예측결과의 편차가 줄어들었음을 확인하였다.

Algorithmic bias is a discrimination that is reflected in the model by a bias in data or combination of characteristics of model and data in the algorithm. In recent years, it has been identified that the bias is not only present but also amplified in the deep learning model; thus, there exists a problem related to bias elimination. In this paper, we analyze the bias of the algorithm by gender in terms of bias-variance dilemma and identify the cause of bias. To solve this problem, we propose a deep auto-encoder based latent space matching model. Based on the experimental results, it is apparent that the algorithm bias in deep learning is caused by difference of the latent space for each protected feature in the feature extraction part of the model. A model proposed in this paper achieves the low bias by reducing the differences in extracted features by transferring data with different gender characteristics to the same latent space. We employed Equality of Odds and Equality of Opportunity as a quantitative measure and proved that proposed model is less biased than the previous model. The ROC curve shows a decrease in the deviation of the predicted values between the genders.","#알고리즘 편향성, #오토인코더, #잠재공간, #편향-분산 딜레마, #딥러닝, #algorithmic bias, #autoencoder, #latent space, #bias-variance dilemma, #deep learning"
Metadata Extraction based on Deep Learning from Academic Paper in PDF,2019.07,"최근 학술문헌의 수가 빠르게 증가함에 따라, 최신 연구 동향 및 정보를 얻기 위한 학술데이터 베이스 서비스의 필요성이 대두되었다. 학술데이터베이스 구축을 위한 메타데이터 추출 자동화 서비스가 연구되었으나, 대부분의 학술문헌 원문은 PDF로 구성되어 자동적인 정보 추출이 쉽지 않은 문제가 있다. 이에 본 연구는 학술문헌 PDF에 대한 메타데이터 자동 추출 방법을 제안한다. 먼저 학술문헌 PDF를 XML 형식으로 변환한 이후, XML 마크업 토큰 내의 좌표, 크기, 넓이와 텍스트 자질을 추출하여 벡터 형태로 구성한다. 추출된 자질 정보를 연속적 레이블링에 특화된 딥러닝 모델인 Bidirectional GRU-CRF를 활용하여 분석하고 메타데이터를 추출한다. 본 연구에서는 국내 학술지 중 10종을 선정하여 메타데이터 추출을 위한 학습집합을 구축하고, 제안한 방법론을 활용하여 실험하였다. 9종의 메타데이터에 대한 추출실험 결과, 88.27%의 정확도와 84.39%의 F1 성능을 얻었다.

Recently, with a rapid increase in the number of academic documents, there has arisen a need for an academic database service to obtain information about the latest research trends. Although automated metadata extraction service for academic database construction has been studied, most of the academic texts are composed of PDF, which makes it difficult to automatically extract information. In this paper, we propose an automatic metadata extraction method for PDF documents. First, after transforming the PDF into XML format, the coordinates, size, width, and text feature in the XML markup token are extracted and constructed as a vector form. Extracted feature information is analyzed using Bidirectional GRU-CRF, which is an deep learning model specialized for sequence labeling, and finally, metadata are extracted. In this study, 10 kinds of journals among various domestic journals were selected and a training set for metadata extraction was constructed and experimented using the proposed methodology. As a result of extraction experiment on 9 kinds of metadata, 88.27% accuracy and 84.39% F1 performance was obtained.","#PDF 메타데이터 추출, #메타데이터 추출, #정보추출, #텍스트마이닝, #딥러닝, #PDF Metadata extraction, #metadata extraction, #information extraction, #text mining, #deep learning"
V-gram: Malware Detection Using Opcode Basic Blocks and Deep Learning,2019.07,"악성코드가 급증하여 기계 학습 기반의 자동 탐지 연구가 중요해지고 있다. 악성코드 실행파일로부터 추출되는 opcode 시퀀스는 악성코드 탐지에 좋은 특징이기 때문에 바이트 기반의 n-그램 처리 기법을 거쳐 기계 학습의 입력 데이터로서 폭넓게 사용되고 있다. 본 논문에서는 처리 속도와 저장 공간 측면에서 기존 n-그램 방식을 크게 향상시키는 기본 블록 단위의 딥러닝 입력 데이터 가공 기법인 V-그램을 새롭게 제안한다. V-그램은 opcode 시퀀스로부터 의미 없는 입력 데이터의 불필요한 생성을 막을 수 있다. 본 논문에서는 64,000개 이상의 실제 정상 및 악성코드 파일을 수집하여 진행한 실험을 통해서, V-그램이 처리 속도와 저장 공간, 그리고 탐지 정확도 측면에서 모두 기존의 n-그램 기법보다 우수하다는 것을 검증하였다.

With the rapid increase in number of malwares, automatic detection based on machine learning becomes more important. Since the opcode sequence extracted from a malicious executable file is useful feature for malware detection, it is widely used as input data for machine learning through byte-based n-gram processing techniques. This study proposed a V-gram, a new data preprocessing technique for deep learning, which improves existing n-gram methods in terms of processing speed and storage space. V-gram can prevent unnecessary generation of meaningless input data from opcode sequences. It was verified that the V-gram is superior to the conventional n-gram method in terms of processing speed, storage space, and detection accuracy, through experiments conducted by collecting more than 64,000 normal and malicious code files.","#악성코드 탐지, #정적 분석, #디스어셈블, #n-그램, #피쳐 해싱, #malware detection, #static analysis, #disassemble, #n-gram, #feature hashing"
Text Classification by Deep Learning Fusion,2019.07,,"#Long-Short Term Memory networks (LSTM), #CNN deep learning methods"
Fault Detection in PV systems using Deep Learning,2019.07,,
Target Classification Bsed On Deep Learning,2019.07,,"#Convolutional neural networks, #deep learning, #features, #target classification"
A Survey on Deep Learning-based Anomaly Detection Models for Time Series Data,2019.06,,
A Survey on Deep Learning-based Cancer Detection,2019.06,,
A Deep Learning-Based Framework for Emotion Recognition in Audio-Video,2019.06,,
Automatic Tumor Detection and Segmentation of FDG-PET in Lung using Deep Neural Networks,2019.06,,
A Research Study on China’s New ICT Technology Development Trends Based on Deep Learning,2019.06,,
6mA Methylation site prediction in the rice genome based on deep learning approach,2019.04,,
"C++ based General-purpose Open Source Deep Learning Framework, WICWIU",2019.03,"국내 대학으로는 최초로 공개한 오픈소스 딥러닝 프레임워크 WICWIU를 소개한다. WICWIU는 다양한 연산자와 모듈, 그리고 일반적인 계산 그래프들을 표현할 수 있는 신경망 구조를 제공하여 Inception, ResNet, DenseNet 등 널리 사용되는 최신 딥러닝 모델들을 구성하기에 충분한 기능을 제공한다. 또한, GPU 기반 대규모 병렬 컴퓨팅을 지원해 빠른 학습이 가능하다. 모든 API가 C++로 제공되어 C++ 개발자들이 쉽게 적응할 수 있으며, C++환경에 기반하기 때문에 파이썬 기반의 프레임워크에 비해 메모리 및 성능 최적화에도 유리하다. 따라서, 프레임워크 자체를 자원이 제한된 환경에 맞도록 수정하기에도 용이하다. 일관성 높은 코드와 API로 구성되어 가독성과 확장성이 우수하며, 한국어 문서를 제공해 국내 개발자들이 쉽게 접근할 수 있다. WICWIU는 Apache 2.0 라이선스를 적용해 어떠한 연구 목적 및 상용 목적으로도 자유롭게 활용할 수 있다.

In this paper, we introduce WICWIU, the first open source deep learning framework among Korean universities. WICWIU provides a variety of operators and modules together with a network structure that can represent an arbitrary general computational graph. The WICWIU features are sufficient to compose widely used deep learning models such as Inception, ResNet, and DenseNet. WICWIU also supports GPU-based massive parallel computing which significantly accelerates the training of neural networks. It is also easily accessible for C++ developers because the whole API is provided in C++. WICWIU has an advantage over Python-based frameworks in memory and performance optimization based on the C++ environment. This eases the customizability of WICWIU for environments with limited resources. WICWIU is readable and extensible because it is composed of C++ codes coupled with consistent APIs. With Korean documentation, it is particularly suitable for Korean developers. WICWIU applies the Apache 2.0 license which is available for any research or commercial purposes for free.","#딥러닝, #신경망, #프레임워크, #오픈소스, #WICWIU, #deep learning, #neural networks, #framework, #open source"
Detection of Moving Direction using PIR Sensors and Deep Learning Algorithm,2019.03,"In this paper, we propose a method to recognize the moving direction in the indoor environment by using the sensing system equipped with passive infrared (PIR) sensors and a deep learning algorithm. A PIR sensor generates a signal that can be distinguished according to the direction of movement of the user. A sensing system with four PIR sensors deployed by 45° increments is developed and installed in the ceiling of the room. The PIR sensor signals from 6 users with 10-time experiments for 8 directions were collected. We extracted the raw data sets and performed experiments varying the number of sensors fed into the deep learning algorithm. The proposed sensing system using deep learning algorithm can recognize the users’ moving direction by 99.2 %. In addition, with only one PIR senor, the recognition accuracy reaches 98.4%.","#Passive infrared, #movement direction detection, #deep learning, #machine learning, #convolutional neural network"
Generation of contrast enhanced computed tomography image using deep learning network,2019.03,"In this paper, we propose a application of conditional generative adversarial network (cGAN) for generation of contrast enhanced computed tomography (CT) image. Two types of CT data which were the enhanced and non-enhanced were used and applied by the histogram equalization for adjusting image intensities. In order to validate the generation of contrast enhanced CT data, the structural similarity index measurement (SSIM) was performed. Prepared generated contrast CT data were analyzed the statistical analysis using paired sample t-test. In order to apply the optimized algorithm for the lymph node cancer, they were calculated by short to long axis ratio (S/L) method. In the case of the model trained with CT data and their histogram equalized SSIM were 0.905±0.048 and 0.908±0.047. The tumor S/L of generated contrast enhanced CT data were validated similar to the ground truth when they were compared to scanned contrast enhanced CT data. It is expected that advantages of Generated contrast enhanced CT data based on deep learning are a cost-effective and less radiation exposure as well as further anatomical information with non-enhanced CT data.","#Contrast enhanced computed tomography, #deep learning, #generative adversarial network"
Deep Learning based violent protest detection system,2019.03,"In this paper, we propose a real-time drone-based violent protest detection system. Our proposed system uses drones to detect scenes of violent protest in real-time. The important problem is that the victims and violent actions have to be manually searched in videos when the evidence has been collected. Firstly, we focused to solve the limitations of existing collecting evidence devices by using drone to collect evidence live and upload in AWS(Amazon Web Service)[1]. Secondly, we built a Deep Learning based violence detection model from the videos using Yolov3 Feature Pyramid Network for human activity recognition, in order to detect three types of violent action. The built model classifies people with possession of gun, swinging pipe, and violent activity with the accuracy of 92, 91 and 80.5% respectively. This system is expected to significantly save time and human resource of the existing collecting evidence.","#Collecting evidence, #drone, #deep learning, #detection, #AWS"
Deep Learning-Based Real-Time Pedestrian Detection on Embedded GPUs,2019.03,"본 논문은 임베디드 GPU에서 실시간 동작하는 딥 컨볼루션 뉴럴 네트워크(CNN) 기반의 보행자 탐지 기법을 제안한다. 제안하는 기법에서는 먼저 영상 내 보행자 크기에 대한 통계적 분석을 통해서 최적의 컨볼루션 층의 개수를 결정한다. 또한, 본 논문에서는 다중 스케일 CNN 학습 기법을 적용하여 영상 내의 보행자 크기 변화에 강인한 탐지 기법을 개발한다. 컴퓨터 모의실험을 통해 제안하는 알고리즘이 임베디드 GPU에서 실시간 동작하면서도 기존의 기법과 비교하여 평균적으로 높은 정확도를 보임을 확인한다.

We propose an efficient single convolutional neural network (CNN) for pedestrian detection on embedded GPUs. We first determine the optimal number of the convolutional layers and hyper-parameters for a lightweight CNN. Then, we employ a multi-scale approach to make the network robust to the sizes of the pedestrians in images. Experimental results demonstrate that the proposed algorithm is capable of real-time operation, while providing higher detection performance than conventional algorithms.","#Pedestrian detection, #convolutional neural network, #embedded system"
Research on discriminating the patterns of soldier uniforms using Deep Learning,2019.01,,
Research on discriminating the patterns of soldier uniforms using Deep Learning,2019.01,,
Evolutionary Deep Learning Approaches for Financial Prediction,2019,"최근 지속적인 경기침체와 저금리 기조로 금융투자에 대한 관심이 증가하고 있다. 이에 따라 인공지능 기술을 금융 분야에 적용하려는 시도가 꾸준히 이 루어지고 있다. 금융 시장 예측은 통계학, 경제학 등의 분야에서 꾸준히 연구 되어 왔으나 잡음이 극심하고 비선형적인 특성으로 인해 아직까지 예측이 매 우 어려운 영역으로 인식되어 있다. 이에 본 연구에서는 데이터 간의 복잡한 상관관계를 파악하고 학습하는데 뛰어난 성과를 보이는 딥러닝 기법을 금융 예측에 적용한다.
딥러닝 알고리즘은 이미지, 자연어 등 기존의 인공 신경망 모형으로 해결하 기 어려운 정보를 분석하는데 탁월한 성과를 보이고 있으며, 네트워크 구조가 개선되고 새로운 알고리즘이 개발되면서 다양한 분야로 활용 범위를 넓혀가 고 있다. 딥러닝 내에는 주어진 데이터를 효과적으로 처리하기 위한 다양한 파라미터가 존재한다. 입출력변수에 대한 네트워크 구조(network topology), 학습 조건(learning parameter) 등의 선정이 바로 이에 해당한다. 특히, 딥러닝 모형은 내부 계층이 매우 많아, 최적의 네트워크를 구성하기 위해 사전에 연구자가 조정해야 하는 하이퍼 파라미터(hyper-parameter)의 수는 기하급수적으로 증가했다. 하지만 기존 연구들은 수 많은 실험을 바탕으로 한 시행 착오법이나 전문가 노하우에 의존하고 있으며, 이에 대한 체계적인 연구는 부족한 실정이다. 이러한 한계점을 극복하고자, 본 연구에서는 대표적인 서치 알고리즘인 유전자 알고리즘을 이용하여 딥러닝 모형의 구조를 최적화하고 이 를 주가 지수, 부도 위험과 같은 금융데이터에 적용해 예측 성과를 높일 수 있는 방법론을 제시한다.
우선 본 연구에서는 유전자 알고리즘으로 최적화된 LSTM네트워크(long short-term memory network)를 통한주가지수 예측 방법론을 제시하였다. LSTM네트워크는 과거의 정보를 학습에 반영할 수 있는 딥러닝 네트워크 중 하나로, 시계열 데이터에 적용되어 뛰어난 성과를 보인다. LSTM네트워크를 학습시킬 때에는, 과거의 정보를 어느 정도까지 포함시킬 것인지, 즉 타임윈 도우의 크기를 어떻게 설정할지 결정하는 것이 중요하다. 만약 타임윈도우의 크기가 너무 작다면 중요한 정보를 학습에 포함시키지 못할 수 있고, 타임윈 도우의 크기가 너무 크다면 과다한 정보가 학습에 포함되어 잡음이 될 수 있
다. 이에 본 연구의 첫 번째 모형에서는 유전자 알고리즘을 이용해 LSTM네트워크의 타임윈도우의 크기와 은닉층을 구성하는 LSTM유닛의 개수를 최적 화한다. 제안 방법론을 검증하기 위해 한국 주가지수 데이터를 사용하였으며, 실험 결과 유전자 알고리즘을 통해 최적화를 수행한 모형이 비교 방법론에 비 해 뛰어난 성과를 보이는 것으로 나타났다.
두 번째로는 멀티-채널 합성곱 신경망 모형을 이용해 주식 시장의 방향성 을 예측하였다. 유전자 알고리즘을 이용해 합성곱 신경망의 특성 추출 과정을 담당하는 합성곱 계층(convolutional layer)과 풀링 계층(pooling layer)에 대한 최적화를 수행했다. 합성곱 계층에서는 커널을 통해 주어진 입력에 대해 패턴을 파악하며 풀링 계층에서는 합성곱 단계에서 탐색된 특징들 중 가장 대 표적인 값을 추출하는 작업을 수행한다. 따라서 커널의 크기는 입력 데이터로부터 주요 특징을 추출하는 데 가장 중요한 역할을 한다. 커널의 크기가 너무 큰 경우 입력 데이터의 세부적인 특성을 고려하지 못하게 되고, 너무 작으면 지나치게 많은 정보를 학습해 혼란을 야기할 수 있다. 따라서 합성곱 신경망 모형의 성과 향상을 위해서는 해결해야 하는 문제가 속한 도메인과 데이터의 특성을 가장 잘 반영할 수 있는 크기의 커널을 사용해야 한다. 하지만 커널 크기를 설정하는 과업은 아직까지 실험을 통해 적합한 값을 결정하는 기술 (art)적인 문제로 남아있으며 이에 대한 체계적인 연구는 부족한 실정이다. 이에 본 연구에서는 유전자 알고리즘을 이용하여 최적의 네트워크 구조를 도 출하고 이를 합성곱 신경망에 적용하여 한국 코스피 지수의 방향성을 예측하 는 통합 방법론을 제시하였다. 제안한 모형의 효과성 검증을 위해 기존 주식 시장 예측 연구에서 보편적으로 사용되었던 인공신경망 모형과 함께 최적화를 수행하지 않은 기본 합성곱신경망 모형의 성능을 비교한 결과 제안 방법론의 성과가 가장 뛰어난 것으로 나타났다.
마지막으로는 유전자 알고리즘으로 네트워크 구조를 최적화한 심층신뢰망을 이용하여 기업의 부도 여부를 탐색하였다. 심층신뢰망은 최초로 연구된 딥러 닝 모형으로 다수의 제약 볼츠만 머신으로 이루어져 있다. 본 연구에서는 심 층신뢰망의 핵심 구성요소라고 할 수 있는 제약 볼츠만 머신의 구조를 최적화 하였다. 이를 통해 잡음이 심하고 비선형적인 특성을 가진 부도예측데이터에 대한 학습 효율성과 예측 성과를 향상시켰다.
본 연구는 유전자 알고리즘으로 딥러닝 네트워크 구조를 최적화함으로써 경영 분야의 중요한 문제 중 하나인 금융 예측의 성과를 높였다. 이를 통해 실제 투자에 필요한 의사결정체계를 효율적으로 개선하는데 기여할 수 있을 것 이라고 기대한다.

Recently, artificial intelligence (AI) technologies have attracted critical attention because of their practical applications in various fields. In the history of AI, deep learning techniques such as deep belief networks (DBN), convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been considered a key factor in this prosperity. Deep learning is a type of artificial neural networks (ANNs) that has many hidden layers between the input and the output layers. Deep learning not only increases the complexity of the model but also assigns an appropriate role to each neuron for the purpose of analysis; therefore, it can effectively solve the target problems that could not be solved using traditional neural network models.
This study applies deep learning techniques to the financial prediction problems. The financial market is known to be very difficult to predict and analyze because of the nature of its noisy and nonlinear environment. Traditionally, researchers usually adopted a variety of statistical and machine learning approaches including ANN and support vector machine (SVM). However, these methods had limitations in achieving good performance, because the financial market has numerous factors affecting its volatility and it is not easy
to capture the nonlinearity of these factors. In the financial field, there are great opportunities to derive valuable insights by using deep learning techniques with its great ability in learning features. Accordingly, this dissertation suggests various novel financial forecasting models using deep learning techniques which have improved prediction performance in various research fields.
Furthermore, we aim to optimize the deep learning architecture to improve the model performance. Many studies have demonstrated the efficacy of deep learning techniques, but there are several shortcomings in building and using these techniques. First of all, it is not easy to determine a suitable model which can reflect nature of problem and learn data patterns, because there are numerous controlling parameters. However, most of the existing studies tend to depend on trial-and-error-based methods, and such methods are more of an art than a science. Therefore, here, we propose a method to systematically optimize the parameters for the deep learning models by using genetic algorithm (GA). GA is exploited in the search of optimal hyper-parameters for the deep neural network. Many studies have applied GA in conjunction with other AI and machine learning techniques, but few studies have attempted to integrate the GA and deep learning models despite a great potential for effective applications in this area. For this reason, this dissertation suggests GA-based deep learning techniques to automatically discover the most appropriate set of components for the deep neural networks and the proposed methods are developed in order to solve financial problems.",
Improvement of material decomposition accuracy through the deep learning-based optimization of dual-energy image quality in spectral digital mammography,2019,"유방암 환자는 매년 증가하고 있으며, 유선조직의 높은 선감약계수 특성으로 인해 유방암의 검출 민감도는 감소된다. 따라서 이중에너지 물질분리 기술을 이용하여 유방으로부터 유선조직을 분리함으로써 병변검출 민감도를 향상시킬 수 있다. 일반적인 이중에너지 유방촬영은 X-선 스펙트럼 간섭으로 인해 원본영상에서 충분한 대조도 차이를 보이지 못할뿐만 아니라 두 번의 X-선 조사를 기반으로 하기 때문에 방사선 선량이 증가한다. 반면에 광자계수검출기 기반 이중에너지 유방촬영은 단 한번에 X-선 조사만으로도 이중에너지 기법의 구현이 가능하며, 문턱 값 설정을 통해 X-선 스펙트럼 간섭을 최소화할 뿐만 아니라 물질의 감약특성 차이를 최대화 할 수 있다. 그렇지만 광자계수 검출기를 이용한 유방 촬영상은 각 에너지 범위에 포함된 유효광자수가 상대적으로 작기 때문에 영상의 잡음이 증가한다. 원본영상의 화질과 물질분리 정확도는 매우 밀접한 관계를 보인다. 일반적인 디노이징 방법은 영상의 잡음을 효과적으로 제거할 수 있지만 영상의 공간분해능을 저하시키며, 디블러링 방법은 구조물의 엣지 강조를 통해 공간분해능을 향상시킬 수 있지만 통계적 잡음이 유발된다. 반면에 딥러닝 기반 디노이징 방법은 공간분해능의 왜곡 없이 효과적으로 잡음을 제거할 수 있다. 따라서 본 연구에서는 PCD를 기반 이중에너지 유방촬영에 딥러닝 기반 디노이징 기법을 적용함으로써 잡음과 공간분해능 사이의 영상화질 최적화를 통해 원본영상의 화질을 향상시키고, noise, Contrast-to-noise ratio (CNR), Root-mean-square error (RMSE)를 통해 원본영상의 화질 향상이 물질분리 영상의 화질 및 물질분리 정확도에 미치는 영향을 확인하였다. 디노이징 기법을 사용한 물질분리 영상의 RMSE이 값은 디노이징 기법을 사용하지 않는 경우보다 약 36% 더 낮았다. 디노이징 기법에 따른 물질분리 정확도의 경우, DnCNN을 이용한 물질분리 영상의 RMSE는 3 × 3 크기의 위너필터를 사용한 물질분리 영상의 RMSE대비 약 0.9배로 낮았지만, 4 × 4 커널 크기의 위너필터를 사용한 물질분리 영상의 RMSE대비 1.06배 높았다. 반면에 DnCNN을 사용한 물질분리 영상은 3 × 3 커널 크기의 위너필터를 사용한 영상보다 1.43배, 4 × 4 커널 크기의 위너필터를 사용한 영상보다 약 1.71배 높은 공간분해능을 보였다. 디블러링 기법의 유무에 따른 공간분해능 향상의 경우 블라인드 디컨벌루션의 반복횟수가 증가할수록 물질분리 영상의 공간분해능은 증가하였지만 공간분해능의 향상율은 10% 미만이었으며, 5번 반복횟수에도 불구하고 DnCNN을 이용한 물질분리 영상의 공간분해능보다는 약 0.72배 낮았다. 또한 블라인드 디컨벌루션의 반복횟수가 증가할수록 물질분리 정확도는 오히려 감소하였으며, DnCNN의 물질분리 정확도는 1번 이하의 반복횟수보다는 약 1.04배 높은 RMSE를 보였지만 3번 이상의 반복횟수보다는 약 0.91배 낮은 RMSE를 보였다. 피팅식의 차원에 따른 물질분리의 경우, 피팅식의 차원이 증가할수록 잡음제거 및 물질분리 정확도가 향상하였지만 삼차원의 피팅식 이상에서는 잡음제거효과 및 물질분리 정확도가 수렴되는 결과를 획득하였다. 결론적으로, 딥러닝 기반 디노이징 기술의 적용을 통해 물질분리영상의 영상화질 및 물질분리 정확도를 향상시킬 수 있으며, 유선조직의 효과적인 물질분리를 통해 병변 검출 민감도를 향상시킬 수 있을 것이라고 사료된다.","#유방암, #광자계수검출기, #이중에너지유방촬영, #딥러닝, #디노이징, #디블러링, #물질분리"
An Improved Deep Learning Method for Animal Images,2019.01,,"#Improved deep learning, #cNN, #animal images"
A Study on Damaged Asphalt Pavement Detecting System based on Deep Learning and Image Processing using Driving Video,2019,"포트홀은 포장 재질 중 아스팔트 도로를 지지하는 지반에서 아스팔트 균열 틈으로 폭설 및 폭우로 인한 물을 흡수 후 결빙·해빙 혹은 지반 액상화 과정에서 발생한 공간에 차량의 하중으로 아스팔트가 깨져 발생하는 구멍이다. 포트홀의 발생 빈도는 중(重)차량 이용률 및 공사부실에 의해 발생되는 포장 재질의 균열 발생량과 강우량 및 강설량에 의해 결정된다. 발생된 포트홀은 차량의 조향 장치를 일시적으로 무력화 하거나 영구적인 파손을 일으켜 이로 인한 차량 제어능력 상실로 직·간접적인 상해 및 사망 사고를 유발하는 요인이 된다. 포트홀은 국내에서 국도 한정으로 연간 약 72,000여개가 생성되며 이 중 약 50,000여개가 일반 국도에서 발생한다. 이에 따라 국가는 포트홀에 보상과 유지 보수로서 매년 98 억 원의 예산을 집행한다. 이러한 이유로 포트홀은 사후 대처보다 사전 대처가 중요하다. 포트홀은 발견 시 약 1시간 이내로 아스팔트 도로를 보수 가능하다. 그러나 포트홀 발생 위치 데이터 수집은 운전자에 의한 자발적 보고나 전문 탐지 장비를 사용하여 전문가에 의한 탐사로서만 발견된다. 운전자의 보고를 통한 방법은 포트홀 발생 시 가장 단시간 내 위치를 특정할 수 있으나 운전자의 자발적인 참여에만 기대고 있다. 전용 탐지 장비를 사용한 포트홀 탐색은 탐지 전문 인력의 판독으로 높은 탐지율을 얻으나 집중적인 포트홀 발생 시나 제한된 인력으로 인한 탐사 우선순위로 인헤 각 포트홀간 탐지 시간이 상이하게 된다.
최근 스마트폰은 카메라 센서, GPS, 통신 모듈, 가속도 센서, 자기 센서 등을 탑재하고 동시에 이를 실시간으로 처리할 수 있는 성능을 가지고 있다. 스마트폰을 사용한 포트홀 탐지에는 대표적으로 가속도 센서를 사용한 포트홀 탐지와 카메라를 사용한 포트홀 탐지가 있다. 가속도 센서를 사용한 포트홀 탐지는 차량이 포트홀을 통과 시 발생한 차량 충격 패턴을 분석하여 포트홀을 탐지한다. 이 방법을 운전자에게 확대 적용 시 전용장비 대비 포트홀 탐지 시간을 줄여주나 포트홀로 인해 발생하는 사고를 미연에 방지할 수 없다. 카메라 센서를 사용한 포트홀 탐지는 차량 전방에 설치되어 포트홀을 탐지한다. 전방에 설치되는 특성으로 인해 운전자에게 포트홀의 위험을 사전 알릴 수 있다.
본 논문에서는 영상처리 및 딥러닝을 사용하여 도로 손상 탐지 알고리즘을 기술하였다. 영상처리에서는 도로 손상을 탐지하기 위해 Y채널 변환, 모폴로지, Otsu Thresholding, Saliency Map, 배경제거, SLIC, WEF, Convex Hull 영상처리 알고리즘들을 연구하고 시간 축 기반의 Frame Difference, RGB-Y 알고리즘을 새로 제안하였으며 이들을 조합하여 다수결 기반과 가중치 기반의 알고리즘을 제안한다. 딥러닝에서는 영상처리를 위한 딥러닝 알고리즘들을 도로 손상 탐지를 위해 연구하였으며 학습을 위한 데이터 셋을 구축하였다. 실험에서는 데이터 셋은 포트홀과 비 포트홀 분류를 기반으로 하는 2개 클래스 분류 성능과 위험군에 따른 4개 클래스 기반의 데이터 셋 테스트 및 위험군을 조합하여 2개 및 3개 클래스로 조합하여 알고리즘에서 성능을 테스트 하였다. 또한 처리속도를 효과적으로 내기 위해 두 알고리즘을 조합하여 도로 손상을 탐지한다. 성능 및 정확성을 동시에 해결하기 위하여 서버-클라이언트 개념을 적용하여 클라이언트인 탐지 장치에서 영상처리와 딥러닝을 이용한 실시간 탐지에 낮은 확신도를 가지는 탐지 결과를 서버의 딥러닝에서 대량의 고성능 프로세스와 다중의 딥러닝 모델을 사용하여 높은 정확도의 결과를 클라이언트에 반환할 수 있도록 한다. 서버에서는 클라이언트로부터 전송 받은 이미지를 기반으로 딥러닝 모델들을 새로 학습하며 이미지의 판단이 어려운 경우 전문가가 개입하여 데이터를 분류하고 이를 반영하여 재학습 할 수 있는 시스템을 제안한다.","#Detecting System, #Deep Learning, #Image Processing"
Collaborative filtering methods based on deep learning,2019,"최근 딥러닝이 음성 인식, 컴퓨터 비전, 자연어 처리 등의 분야에서 큰 성공을 거두고 있으며, 근래에는 추천 시스템에도 활발하게 이용되고 있다. 추천 시스템에서의 딥러닝은 주로 상품의 이미지나 메타데이터, 리뷰 텍스트 등 상품의 다양한 컨텐츠 정보에서 의미있는 특징 정보 (latent features) 를 사람의 도움 없이도 자동으로 도출함으로써 추천의 정확도를 높이는 데 이용된다. 그러나 컨텐츠 정보를 전혀 이용하지 않는 협업 필터링의 분야에서는 상대적으로 딥러닝을 적용하는 연구가 활발하게 이루어지지 않고 있다. 비록 AutoRec, CDAE, IRGAN, GraphGAN 등 딥러닝 기반 협업 필터링 방법들이 제안되었으나, 이들은 단순히 딥러닝 이전에 주로 사용되던 추천 모델인 matrix factorization을 Autoencoder나 multi-layer perceptron으로 대체하거나, 추천 데이터의 특성에 맞지 않는 학습 알고리즘을 사용하고 있으므로 많은 개선의 여지가 남아있다. 협업 필터링의 범용성과 실용성, 중요도 등을 고려해볼 때, 딥러닝을 통한 협업 필터링의 정확도 향상은 중요한 연구 목표라고 할 수 있다.
이에 따라, 본 학위 논문은 총 네 가지의 새로운 딥러닝 기반의 협업 필터링 기법들을 제안한다. 제안하는 방법들의 이름은 각각 (1) APR (Autoencoder-based Personalized Ranking), (2) CAAE (Collaborative Adversarial Autoencoders), (3) CFGAN (CF framework based on GAN), (4) RAGAN (Rating Augmentation with GAN) 이다. 각각의 방법들은 기존의 방법들이 단순한 딥러닝 모델을 적용하거나 잘못된 학습 알고리즘을 사용하는 단점들을 크게 개선하고 정확도를 학계 최고 수준으로 향상시켰다.
구체적으로, APR은 기존의 모델이 pointwise 혹은 pairwise 최적화 중 하나만을 이용한 점, 그리고 explicit feedback과 implicit feedback 중 하나만을 이용한다는 점을 개선해서, 위에 기술한 2가지의 최적화 기법과 2가지 종류의 데이터를 모두 이용할 수 있는 딥러닝 프레임워크이다. 이를 위해 두 개의 Autoencoder를 도입했으며, 학습 과정 시 서로가 유기적으로 협력하는 알고리즘을 사용했다. 나머지 3개의 제안 방법들은 딥러닝 모델 중 최근 가장 성공적인 모델로 평가받는 Generative Adversarial Network (GAN) 을 이용했다. 먼저, CAAE는 기존의 GAN 기반 협업 필터링인 IRGAN과 GraphGAN이 학습 알고리즘만 GAN에 기반하며 실제 모델은 깊이있는 학습이 불가능한 matrix factorization (MF) 인 점에 착안하여, 생성 모델이 Autoencoder를 이용할 수 있도록 개선한 방법이다. 또한 판별 모델도 추천 및 top-N 랭킹에 적합한 BPR-MF를 도입해서 추가적인 정확도 향상을 이루었다. 다음으로 CFGAN은 IRGAN과 GraphGAN의 학습 알고리즘을 주로 개선한 모델이다. 기존의 두 모델이 상품의 인덱스 자체를 생성하는 방식의 한계를 발견하고 이를 해결하기 위해 벡터 단위의 생성 및 판별 프레임워크를 고안하였다. 마지막으로, RAGAN은 GAN을 이용해서 직접 추천을 하는 대신, 원래의 GAN의 목적에 부합하도록 GAN을 데이터의 생성 도구로서 이용한 방법이다. GAN을 이용해서 평점 데이터를 학습한 후, 사용자가 상품에 남길 평점들을 그럴 듯 하게 생성해서 데이터를 풍성하게 만드는 것이 핵심 전략이다.
각각의 제안하는 방법들은 실세계의 다양한 데이터셋을 이용해서 그 성능을평가하였다. 실험 데이터셋으로는 Watcha, Ciao, Movielens 100K, Movielens 1M, Movielens 10M 등 학계에서 널리 이용되는 다양한 데이터들을 이용하였으며, 추천의 정확도를 측정하기 위한 척도 또한 가장 널리 이용되는 precision, recall, nDCG, MRR 등을 이용하였다. 실험 결과, APR은 가장 유사한 기존의 딥러닝 기반 협업 필터링인 AutoRec 대비 최대 2배 높은 정확도를 보였다. CAAE와 CFGAN은 기존의 GAN 기반 협업 필터링 방법인 IRGAN에 비해 각각 평균적으로 1.2배, 1.5배 수준으로 향상된 추천 정확도를 보였다. 마지막으로 RAGAN은 기존의 널리 이용되던 협업 필터링 모델인 itemKNN과 SVD 뿐만 아니라, 딥러닝 기반 협업 필터링 모델인 AutoRec의 성능을 평균 두 배 이상으로 크게 향상시키는 것으로 나타났다.

In the past few years, deep learning has been very successful in a wide range of domains such as speech recognition, computer vision, and natural language processing. More recently, it has also been actively employed in recommender systems. Deep learning in recommendation systems is mainly used to improve the accuracy of recommendation by automatically deriving meaningful latent features from a variety of content information such as images, metadata, and review text of a product. However, deep learning techniques have gained less attention in the field of collaborative filtering (CF), which does not exploit content information of items. Although some deep learning based CF models have been proposed, they generally replace the traditional matrix factorization with either an Autoencoder or a multi-layer perceptron, or use a learning algorithm that is not suited to user-item interaction data, thus leaving areas for improvement. Regarding CF’s practicability, versatility, and importance, it is still very important research objective to improve the accuracy of CF using deep learning techniques.
For this reason, this dissertation proposes four novel deep learning based CF methods. These methods are each called (1) APR (Autoencoder-based Personalized Ranking), (2) CAAE (Collaborative Adversarial Autoencoders), (3) CFGAN (CF framework based on GAN), and (4) RAGAN (Rating Augmentation with GAN), respectively. Each of these methods achieves state-of-the-art accuracy by greatly improving the shortcomings of existing methods that either apply inadequate learning algorithms or use a simple deep learning model.
While existing models use either pointwise or pairwise optimization, and learn from either explicit or implicit feedback, APR is a deep learning framework which improves on these models by taking advantage of the aforementioned two optimization methods and both feedback data. In order to make this possible, APR employs two Autoencoders and they interact together following a novel learning algorithm. The other three proposed methods employ Generative Adversarial Network (GAN), which is recognized as the most successful framework among deep learning models. First, CAAE improves on IRGAN and GraphGAN, which are GAN-based CF models that employ matrix factorization (MF). Since MF cannot catch subtle non-linear latent factors, CAAE addresses this issue by allowing the generator model to incorporate Autoencoders. In addition, the discriminator model also improves the overall recommendation accuracy by introducing Bayesian personalized ranking, which is suitable for recommendation task. CFGAN, on the other hand, is a model that mainly improves the learning algorithms of IRGAN and GraphGAN. Rather than generating a single index of an item as did in IRGAN and GraphGAN, CFGAN generates and discriminates real-valued vectors. Lastly, RAGAN incorporates GAN as a data generator in order to relieve the data sparsity problem, rather than using it to directly produce recommendations. After learning the rating data using GAN, the key strategy is to make the rating data richer by generating plausible ratings with the trained GAN. In this case, RAGAN can achieve high recommendation accuracy even by using the traditional CF models, such as SVD or AutoRec.
We evaluated each proposed method by using datasets that are widely used in academia, such as Watcha, Ciao, Movielens 100K, and Movielens 1M. Also, we used precision, recall, nDCG, and MRR, which are the most widely used measures to evaluate the accuracy of top-N recommendation. Experimental results show that APR is about 1.5 times as accurate as AutoRec, which is very similar to APR in the sense that they are both deep-learning based CFs. CAAE and CFGAN each showed 1.2 times and 1.5 times improved recommendation accuracy than IRGAN, which is a conventional GAN-based CF method. Lastly, RAGAN doubled the accuracy of not only itemKNN and SVD, which are widely used CF models, but also AutoRec, which is a conventional deep learning based CF model.",#컴퓨터공학
Aspect-Based Sentiment Analysis Using Deep Neural Networks and Embedding Learning,2019,"2000년대 이후 스마트 폰, 컴퓨터의 대중화와 모바일 인터넷, 소셜 미디어 이용 등의 확산으로 대중이 텍스트의 수용자가 아닌 생산자로 대두되면서 대중이 만들어 낸 대량의 텍스트가 빠른 속도로 증가하고, 분석 기술의 발달로 디지털화된 텍스트에 대한 분석이 가능해 지면서 감성 분석에 대한 연구와 이를 실무에 적용하려는 시도가 활발하다.
감성 분석(sentiment analysis) 또는 오피니언 마이닝(opinion mining)이란 텍스트에 나타난 주관적 요소(subjectivity)를 탐지하여, 감성을 표현하는 이의 평가(evaluation), 판단(judgement), 감정(emotion), 감성(sentiment), 태도(attitude), 입장(stance) 등을 처리하는 텍스트 분석 기법 중 하나이다. 감성 분석의 주 목적은 단순히 감정이나 태도를 긍정 또는 부정, 이분법적으로 구분한다기보다는 인간의 감성 및 사람들의 의사를 결정하는 요인을 파악하고, 이를 정량화된 수치나 도식, 등급 등으로 표현하는 데 있다. 감성 분석의 단위는 크게 문서, 문장, 속성으로 구분되는데, 속성 단위 감성 분석은 문서나 문장과 달리 ‘의견의 대상(opinion target)이 무엇인지’, 그 대상의 ‘어떤 측면(feature or aspect)을 좋고, 싫어하는지’에 대한 세부적인 정보를 추출할 수 있다. 반면, 분석 절차가 복잡하고 보다 정교한 분석 방법을 요구한다.
본 연구에서는 속성 단위 감성 분석을 수행했으며, 이를 위해 최근 자연어 처리(natural language processing)에서 우수한 성과를 보이고 있는 워드 임베딩(word embedding)에 기반한 딥 러닝 (deep learning neural networks) 기법을 적용했다. 감성 분석에도 워드 임베딩과 결합한 딥 러닝이 우수한 성과를 보인다는 연구 결과들이 축적되면서 최근 다양한 형태의 변형된 딥 러닝 모델들이 제시되고 있지만, 주로 영어 텍스트를 분석 대상으로 하고 있다. 신경망 모델의 강점이 비교적 데이터의 특징에 자유롭다는 점이지만 ‘언어’라는 텍스트 데이터의 특수성을 고려할 때 이러한 모델들이 한국어에도 유사한 성과를 보일지는 실증 분석을 통해서만 검증 가능하다.
선행 연구들과 본 연구의 가장 큰 차이점은 기존 워드 임베딩이 가진 한계점을 완화하는 방안으로, 한국어의 특성을 고려한 감성 어휘 임베딩(sentiment lexicon embedding) 기법을 제안했다는 것이다. 본 연구에서 제안한 감성 어휘 임베딩이 감성 분석에 효과적인지 확인하기 위해 감성 어휘 임베딩을 통해 추출된 감성 어휘 벡터(sentiment lexicon vector)를 Convolutional Neural Network(CNN)와 Long Short-Term Memory(LSTM) 모델의 입력 계층에 사용하여 모델을 학습시켰다. 그 결과, 기존 워드 임베딩에 비해 감성 어휘 임베딩을 사용할 경우 모델의 성과 지표가 모든 경우에서 개선된 것으로 나타나 본 연구에서 제안한 감성 어휘 임베딩이 감성 분석에 효과적인 단어 표현 (word representation) 방법이 될 수 있음을 확인할 수 있었다.
한국어는 다른 언어에 비해 조사와 어미가 많이 발달한 언어라는 점, 어순의 변화에 자유롭고, 동음이의어 비중이 높다는 등 영어와는 매우 상이한 특징을 갖는다. 따라서 영어 텍스트에 대해서는 성과가 입증된 분석 방법이라 하더라도 한국어 텍스트의 특징을 반영하는 것이 필요하다. 본 연구에서는 기존 워드 임베딩이 가진 한계점을 완화하고, 감성 분석의 성능을 높이기 위해 한국어 텍스트의 특징을 반영한 감성 어휘 임베딩 방법을 제안하였다. 감성 어휘 임베딩이 단어 특성을 효과적으로 표현하는 기법이 될 수 있는지 다양한 실증 분석을 통해 확인하였다. 본 연구는 감성 분석을 중점으로 감성 어휘 임베딩의 효과를 살펴보았지만, 다른 자연어 처리 분야에 대해 적용하는 것도 흥미로운 연구 주제가 될 수 있을 것으로 기대한다.

As the user-generated content (UGC) has proliferated and been regarded as invaluable information sources for most organizations, there has been a great deal of interest in natural language processing (NLP) and text-mining techniques for accurately extracting information from text (Chen et al., 2017; Van de Kauter et al., 2015). In particular, researchers have made impressive progress in a sentiment analysis of subjective texts, including online product reviews or social media (Schumaker et al., 2017; Ghiassi et al., 2013; Ghiassi and Lee, 2018).
Sentiment analysis, also called opinion mining, uses computational methods to analyze sentiments, opinions, attitudes, and appraisals toward topics or aspects expressed in natural language texts (Pang et al., 2002; Pang and Lee, 2008; Wang et al., 2015). In the past decades, sentiment analysis takes traditional classification models such as Naive Bayes (NB) or support vector machines (SVMs) with bag of words features (Ouyang et al, 2015). These machine learning approaches targeting NLP problems have been based on shallow models using very high dimensional and sparse features. However, feature engineering is labor intensive and almost reaches its performance bottleneck. Therefore, it is necessary to find explanatory factors from the data and build a classifier less dependent on feature engineering (Bengio et al, 2003).
In this context, word vectors obtained from embedding learning techniques, such as Word2vec (Mikolov et al. 2013a; 2013b) or GloVe (Pennington et al., 2014), are used as inputs or extra word features to deep neural net models. Word vector representation has been proven powerful in various NLP tasks because it can capture the semantic and syntactic relationship between words (Tang et al., 2016b). Meanwhile, recent advances in various word representation models have often focused on widely-used languages, such as English. It raises the question of whether these methods will be equally effective when applied to other languages with different linguistic characteristics such as, in particular, morphologically rich languages (MRLs), such as Korean and Turkish (Amram et al., 2018; Berardi et al., 2015; Park et al., 2018b; Tsarfaty et al., 2010). Word vector representation that takes into account the distinct characteristics of individual languages still remain challenging in regards to generalized representations.
Although the effectiveness of word embedding has been verified in recent studies, traditional embedding learning models have some limitations. Existing unsupervised embedding learning approaches are based on the distributional hypothesis (Harris, 1954), which exposes that the words that occur in similar contexts tend to have similar meanings. For this reason, semantically opposite, but syntactically similar words (e.g., good and bad) have similar word vectors because these words commonly share a small subset of similar surrounding words. Sentiment analysis targets at identifying and classifying sentiment/opinion of text (Tang et al., 2016b); hence it is more problematic when the word embedding is used for sentiment analysis than other NLP applications (Tang et al., 2014).
In this regard, this paper proposes a method of sentiment lexicon embedding that better represents sentiment word’s semantic relationships than existing word embedding techniques. We obtained word vectors through Word2vec model, but input and output word formats are revised by jointly encoding morphemes and their corresponding part of speech (POS) tags. And then, only important POS’s morphemes are learned in Word2vec model.
To verify the effectiveness of the proposed sentiment lexicon embedding method, we conducted experiments comparing with baseline models, which only used general-word embedding or concatenated general-word and aspect embedding. Experiment results indicate that sentiment lexicon vectors obtained by the proposed sentiment lexicon embedding can strengthen attributional similarities compared to the current word embedding method, and these attributional similarities can be more qualitative features of words for sentiment analysis task. In addition, the revised embedding approach mitigated the problem of conventional context-based word embedding method and, in turn, improved the performance of aspect detection and sentiment classification. Furthermore, the sentiment polarity of reviews is highly included in the sentiment-bearing words with respect to specific aspects. Therefore, it is worthwhile to model the connection between aspect and sentiment words for aspect-based sentiment analysis and this effect was enhanced as the features of sentiment words are better represented.",
(A) study for effective UAV vision flight control using object detection based on deep learning and image processing,2019,"본 논문은 영상처리 기술 및 딥러닝을 활용하여, 효과적으로 UAV 관제 관련 연구를 소개한다. 최근 UAV onboard 하드웨어의 사양과 ground station과의 네트워크 통신 성능이 향상되면서, 딥러닝과 같이 큰 규모의 연산 처리가 필요한 기술들이 움직이는 드론에서도 가능해졌다. 특히 vision data를 딥러닝의 Convolutional Neural Network 모델을 사용하여 학습을 시키고 이를 드론에서 테스트하는 것이 가능해 지면서 자율비행, 주변 상황인식 및 자동착륙 등과 같은 영상을 활용하는 연구가 많아졌다. 본 논문에서는 재난상황과 같이 주변 상황인식이 필요한 경우에 집중하여 연구를 진행 하였으며, 차영상, 이진화 그리고 그레이화 등과 같은 영상처리 기법과 Boosting, CNN 그리고 SVM 등과 같은 인공지능 기법을 활용하여 물체 움직임 검출 프로그램 및 영상에서 특정 물체 카운트 하는 프로그램을 구현을 하였다. 그 결과 물체 움직임 검출의 경우 사람들이 많이 밀집되어 있는 상황과 밤에 자동차 전조등이 비출 때와 같은 경우 효율이 좋았으며 평균 FPS는 HD 기준 14 FPS 정도였다. 영상에서 특정 물체 카운트 하는 프로그램의 경우 각 프레임당 기존 물체와 중첩되는 물체가 나왔을 때 추가적으로 카운트 하지 않는 특징을 갖으며 변화가 많은 영사에서 강점을 보였다. 평균 FPS는 FHD 기준 0.1 FPS 정도였다. 특정 물체 카운트 하는 프로그램은 실시간 처리를 위하여 보완 중이며, 나아가 UAV 고정카메라를 활용한 수직 자동 정밀 착륙 프로그램을 연구개발 중이다.

In this dissertation, a study of effective UAV flight control using deep learning and image processing is introduced. As nowadays UAV onboard hardware specification and network communication performance have approved, techniques that need large amount of calculation like deep learning are done on moving drones. Especially as vision data are able to be trained by Convolutional Neural Network models and be tested in moving drones, many studies of Autonomous flight, surrounding context-awareness, and Automatic landing have appeared. The studies in this dissertation focus on cases like natural disasters and circumstances that need surrounding context-awareness. Also, using image processing techniques like, image difference, binarization, gray scaling, etc., and artificial intelligence techniques, like Boosting, CNN, SVM, etc., studies of object movement detection and counting specific objects in this dissertation were implemented. As a result, object movement detection showed a good efficiency at specific cases like places crowed with numerous people or night roads that have cars with headlights turned on. Furthermore, the average of the frame rate was 14 FPS by HD. The program of the counting specific objects in the video stream showed a good result, when there were many changes in the view of the video and had a feature of not counting the objects that were already counted, that prevents duplication. In addition, the average of the frame rate was 0.1 FPS by FHD. Improvement to process the program of counting specific objects in real-time and development of UAV vertical autonomous landing system using fixed camera is in process.","#UAV, #Image processing, #Deep learning, #Ensemble, #Boosting"
Deep collaborative filtering methods equipped with zero-injection,2019,"협업 필터링 분야에서, 제로인젝션 방법은 기존의 협업 필터링 모델들의 정확도를 크게 향상시킬 수 있는 것으로 알려져 있다. 그 이유는 크게 두 가지가 있는데, 첫째는 제로인젝션을 사용함으로써 협업 필터링 모델들은 각 사용자들에게 상품을 추천해주기 전에 각 사용자들이 싫어하는 상품들에 대해 파악하고, 그 상품들이 추천되는 것을 막을 수 있다. 둘째로는 제로인젝션을 사용함으로써 기존의 매우 희소하던 평점 행렬에 풍부한 데이터가 추가로 생기는 효과를 볼 수 있다. 이렇게 풍부해진 평점 행렬은 협업 필터링 모델들이 상품들에 대한 사용자들의 상대적인 선호도를 더욱 정확하게 이해하는 데 도움이 된다. 하지만, 제로인젝션 방법은 위와 같이 그 효과와 가능성이 풍부함에도 불구하고 SVD, SVD++, PureSVD 등과 같이 단순한 선형 협업 필터링 모델들에만 적용되었다. 그러나 이러한 선형 모델들은 사용자와 상품 간의 단순한 관계밖에 알 수 없는 것으로 알려져 있다. 따라서 본 학위논문에서는, 제로인젝션을 최근에 제안된, 최신의 딥러닝 기법을 이용한 협업 필터링 모델들인 CDAE, AutoRec, CFGAN등에 적용해서 추천 정확도를 극대화시키는 연구에 대해 다루고자 한다. 제로인젝션과 딥러닝 모델들을 함께 이용한다면 딥러닝을 통해 사용자와 상품 간의 더 복잡한 관계를 유추할 수 있고, 이는 기존의 협업 필터링이 제공하던 추천의 정확도를 크게 향상시킬 수 있을 것으로 기대한다. 이를 증명하기 위해 본 논문에서는 다양한 실험을 진행하였으며, 실험을 통해서 제안하는 방법이 기존의 협업 필터링 모델들보다 높은 정확도를 제공하는 것을 보였다. 또한, 실험을 통해 단순한 top-N 추천 뿐 아니라, long-tail 상품 추천과 cold-start 사용자 추천 등 다른 어려운 상황에서도 좋은 정확도를 보이는 것을 확인하였다.

In the field of collaborative filtering (CF), Zero-Injection has been known to very effective in improving the accuracy of existing CF models universally. There are two main reasons for the huge improvement. First, owing to Zero-Injection, CF models can figure out some items that each user may dislike even if the items are recommended. Therefore, Zero-Injection prevents CF models from recommending such uninteresting items to a target user. Second, the rating matrix, which is generally very sparse, becomes more abundant when Zero-Injection is applied. The densified rating matrix eventually helps CF models to well understand users’ latent preferences on items more accurately. However, we noticed that Zero-Injection is very promising but has been only applied to some linear CF models, such as SVD, SVD++, and PureSVD. These linear CF models would discover only linear relationships among users and items. Motivated by the aforementioned research limitation, this thesis proposes to apply Zero-Injection to recently proposed, deep learning based CF Models, such as Collaborative Denoising Autoencoder (CDAE), AutoRec, and Collaborative Filtering framework based on Generative Adversarial Networks (CFGAN). We believe that we can achieve more accurate recommendation results if those deep learning based CF models meet Zero-Injection, since they can understand more complex relationships between users and items. Through our extensive experiments, we validate that our approach is really effective and thus providing greatly improved recommendation accuracy under not only basic top-N recommendation, but also difficult situations too, such as long-tail items recommendation, and recommendation to cold-start users.",#컴퓨터공학
Efficient Facial Expression Recognition Algorithm Based on Hierarchical Deep Neural Network Structure,2019,"인공 지능 (AI) 기술의 발달로, 상호 작용 기술에 관한 연구가 진보하고있다. 표정 인식 (FER)은 인간의 감정을 이해할 수 있는 중요한 시각 정보이다. 특히 인공 지능 로봇에 대한 발전으로 인공 지능 시스템의 중요성은 최근 크게 증가하고 있다. 본 논문에서는 사람의 시각 인지와 관련하여 딥 러닝을 기반으로 한 얼굴 표정 인식 (FER) 시스템의 새로운 알고리즘을 제안한다. 제안된 알고리즘에서는, 외관 기반의 네트워크로부터 추출 된 특징은 계층 구조에 의해 기하학적 특징과 융합한다.
외관 특징 기반 네트워크는 LBP 이미지를 사용하여 얼굴의 전체적인 특징을 추출하고, 기하학적 특징 기반 네트워크는 표정을 만들 때 주로 움직이는 근육 인 행동 단위 (AU)의 랜드마크 좌표의 변화를 학습하게된다. 제안한 방법은 가장 빈번하게 발생하는 Top-2 예측 결과와 관련된 오류를 발견하고, 두 네트워크의 결과인 소프트맥스 중 Top-2 결과를 가중치를 고려하여 해당 오류를 감소시킨다.
외관 기반 네트워크만 사용하였을 경우 Top-2 오류는 Cohn-kanade (CK+)와 Japanese Female Facial Expression (JAFFE)의 결과 전체 오류 8.3%에서 77%를 차지하는 6.4%의 결과를 보였다. 이를 검증함으로써 표정 인식 정확도를 보다 정확하게 향상시켰다. 또한 Autoencoder 기법을 이용하여 중립 감정을 가진 얼굴 영상을 생성하고, 얼굴 변화에 따른 동적인 특징을 추출하는 기법을 제안한다. 이 방법은 VGG19 네트워크의 일부를 차용하고 얼굴 중립적 이미지와 동일 인물의 감정 데이터에 의해 정의된 손실 함수를 정의함으로써 구현되었다. 이 방법은 시퀀스 데이터 또는 중립 감정의 데이터가 없는 데이터 셋으로부터 동적인 특징을 추출 할 수 있는 장점을 제공한다.
제안 된 알고리즘은 Tensorflow를 백엔드로 사용하여 Keras framework로 모델링 되었고, 파이썬 언어로 구현하였다. 실험에는 네 개의 데이터 세트인 Cohn-kanade (CK+), Japanese Female Facial Expression (JAFFE), Facial expression research group database (FERG) 및 AffectNet 데이터베이스가 사용되었고, 입력으로는 얼굴 정면영상으로 가정된다.
제안하는 알고리즘은 얼굴 표정 인식 연구에서 검증데이터로써 많이 사용되고 있는 CK+, JAFFE 데이터 셋을 사용하여 최근에 발표된 알고리즘과 비교하였으며, FERG와 AffectNet 데이터베이스를 사용하여 제안하는 알고리즘의 모듈을 비교함으로써 그 타당성을 검증하였다. 10-fold cross validation 결과는 CK+ 데이터 셋에서 95.15%의 정확도를, 그리고 JAFFE에서는 89.33%의 정확도를 보였다. 외관 특징 기반 네트워크만을 단일 네트워크로 사용할 때보다 기하학적 특징 기반 네트워크의 결과를 융합한 경우, CK+에서 최대 약 5%, 평균 약 1.3% 개선된 정확도를 보였다. JAFFE 데이터 셋에서는 정확도의 최대 약 7%, 평균적으로 약 2%의 개선이 이루어짐을 확인하였다.

As the development of artificial intelligence (AI) technology, the research on the interaction technology have been more popular. The facial expression recognition (FER) is an important visual information that can understand human''s emotional situation. In particular, the importance of AI systems has recently increased due to the advancement in research on AI systems applied to AI robots. In this thesis, we propose a new scheme for FER system based on deep learning in relation to the human visual perception.
The feature extracted from the appearance feature-based network is fused with the geometric feature by hierarchical structure. The appearance feature-based network extracts the holistic features of the face using the preprocessed LBP image and the geometric feature-based network learns the coordinate change of action units (AUs) landmark which are the muscle that mainly moves when making facial expression. It is possible to make more robust feature through the proposed hierarchical structure by extracting the holistic features of the faces with the appearance feature-based network and supplementing them with partial features by combining the geometrical features. The proposed method combines the result of the softmax function of the two features by discovering the error associated with the second highest emotion Top-2 prediction result. To combine two results, we design a weight function to improve the error in Top-2 range.
The Top-2 errors resulted in appearance feature-based network results of 6.4%, corresponding to about 77% of the total error average of 8.3% for the Cohn-kanade (CK+) and Japanese Female Facial Expression (JAFFE) datasets. By verifying this, the facial expression recognition accuracy is able to be improved more accurately. Also, we propose a technique to generate facial images with neutral emotion by autoencoder technique and extract the dynamic facial features. This method borrows a portion of the VGG19 network and uses the loss function defined by the facial neutral image and the facial image with emotion of the same person.This method could extract dynamic features from the dataset that does not have a sequence data or neutral data.
To verify the performance, the proposed algorithm is implemented on Keras framework, using a tensorflow as backend, the python language. In the experiment, four data sets are employed: The extended Cohn-kanade (CK+), Japanese female facial expression (JAFFE), facial expression research group database (FERG) and AffectNet database. The facial Images are assumed as frontal facial images. We compare with the other newest algorithms for CK+ and JAFFE datasets, which are typically considered as verified data sets in the facial expression recognition. The logicality of the proposed algorithm is verified by comparing the per module of the proposed algorithm, using FERG and AffectNet database.
The 10-fold cross validation results show 95.15% of accuracy in the CK+ dataset and 89.33% of accuracy in the JAFFE datasets when using only appearance feature-based network as single network. The result of the fusion of the geometric feature-based network shows about up to 5% accuracy in CK+ and about 1.3% on average value. In the JAFFE datasets, up to about 7% of the accuracy is achieved and an average improvement is about 2%.","#Artificial Intelligence (AI), #Facial Expression Recognition (FER), #Deep learning, #LBP feature, #Geometric feature, #Convolutional Neural Network (CNN)"
Deep Learning Approach for Classification of Human Cancer based on DNA Methylation,2019,"후생유전학의 변화는 인간암에서 가장 흔한 형태의 분자변화의 하나로 인식된다. 후생유전학은 유전자 코드의 변화 없이 유전자 발현에서 미토적으로 유전적인 변형을 말한다. 후생유전자를 구성하는 분자, 화학 및 환경 요소의 조합은 각 세포 유형의 고유한 기능을 설정하는데 게놈과 함께 포함된다.
DNA 메틸화는 포유동물 중에서 가장 많이 연구된 후생유전증이다. 메틸 그룹은 시토신-인산염-구아닌 다이뉴클레오티드 또는 CpG 사이트에서 시토신에 첨가된다. 그것은 염색체 X 불활성화, 유전자 표현의 조절, 세포 분화, 게놈 각인 등과 같은 다양한 생물학적 현상에 주요한 역할을 하는 것으로 밝혀졌다. 게다가, DNA 메틸화의 비정상적인 패턴은 암을 포함한 다양한 질병에서 관찰되었다.
이 논문에서는 깊이 있는 학습법을 활용하였으며 인간 암 분류로서 DNA 메틸화 패턴을 분석하는 새로운 접근법을 개발하였다. 우리는 라벨링된 DNA 메틸화 데이터에서 특징을 배우는 딥러닝 아키텍처 VAE+NN를 제안한다. 제안된 모델은 Illumina HM450K 배열 데이터에 대해 테스트되었다. 이 평가에서는 VAE+NN 모델이 다른 작업 및 기존 기계 학습 알고리즘보다 더 높은 F1 점수를 획득하는 동시에 참의 양의/음수와 잘못된 양의/음수를 유의하게 제어한다는 것을 보여준다.
이 연구에서 사용된 분류모델의 구성을 위한 DNA 메틸화 데이터 집합은 TCGA 에서 비롯되었으며, 이 모든 것이 Illumina HM450K 배열을 기반으로 만들어졌으며 베타 값으로 표현되었다. 이 데이터 집합은 25가지 다른 암 유형의 샘플 8,424개로 구성된 TCGA에서 다운로드되었다.
다중 영역 분류 문제를 처리하기 위해 심층 학습 아키텍처를 다른 기계 학습 알고리즘과 비교했다. 암의 멀티클래스 분류에 적용했을 때, Naive Bayes, Decision Tree, Random Forest, K-Nearest Neighbor, and Support Vector Machine과 같은 일반적인 방법과 유사한 F1 점수를 산출했다.
딥러닝 아키텍처는 일반적인 분류 방법보다 DNA 메틸화 데이터의 패턴에 대해 더 많은 정보를 추론할 수 있는 잠재력을 가지고 있다. 심층 학습의 고급 기술을 사용하여 인간 암 데이터와 다른 특징의 중요성을 식별하고 각 형상의 기여를 학습할 수 있다.

Epigenetics changes are recognized as one of the most common forms of molecular alteration in human cancer. Epigenetics refers to the mitotically heritable modifications in gene expression without a change in the genetic code. A combination of molecular, chemical and environmental factors constituting the epigenome is involved, together with the genome, in setting up the unique functionality of each cell type.
DNA methylation is the most studied epigenetic mark in mammals, where a methyl group is added to the cytosine in a cytosine-phosphate-guanine dinucleotide or a CpG site. It has been shown to have a major role in various biological phenomena such as chromosome X inactivation, regulation of gene expression, cell differentiation, genomic imprinting. Furthermore, aberrant patterns of DNA methylation have been observed in various diseases including cancer.
In this dissertation, the deep learning methods are utilized and has developed a new approach to analyze DNA methylation patterns as a human cancer classification. Moreover, deep learning architecture, consists of Variational Autoencoder and Neural Network (VAE+NN) is proposed that learn a representation for DNA methylation data. The proposed model has been tested on Illumina Human Methylation 450K (HM450K) array data. The evaluation demonstrates that VAE+NN model achieves a higher F1 score than other works and traditional machine learning algorithms; while significantly controlling the true positive/negative and false positive/negative scores.
The DNA Methylation dataset for construction of the classification model used in the present study originated from The Cancer Genome Atlas (TCGA), all of which were produced based on Illumina HM450K array and represented as beta values. The dataset was downloaded from TCGA, which are composed of 8,424 samples from 25 different cancer types.
Deep learning architecture was compared with other machine learning algorithms to handle multiclass classification problem. When applied to multiclass classification, the produced F1 score was comparable to common methods such as Naive Bayes, Decision Tree, Random Forest, Nearest Neighbor and Support Vector Machine.
Deep Learning architectures have the potential of inferring more information about the patterns of DNA Methylation data than common classification methods. Advanced techniques of deep learning can be used to identify the significance of different features from human cancer data as well as to learn the contributions of each feature.",
Automatic tooth segmentation method in panoramic radiographs using deep learning,2019,"목적: 치과 방사선 영상의 진단 자동화는 치과의사의 진단을 보조하여 업무 효율성을 향상시킬 수 있다. 진단 자동화를 위한 첫 번째 단계는 치아와 같은 정상적인 해부학 구조를 구별하는 것이다. 본 연구는 적은 수의 파노라마 영상 데이터를 이용하여 CNN (convolutional neural network)을 적용한 치아 분할 방법을 제안하고자 한다.
재료 및 방법: 총 50개의 파노라마를 무작위로 30개의 훈련 데이터, 10개의 검증 데이터 및 10개의 테스트 데이터로 나누었다. 파노라마의 개별 치아 경계선을 따라 주석을 작성하여 각 치아별로 실측 자료 (ground truth) 이미지를 저장하였다. 모델의 오버피팅을 줄이고 훈련 데이터의 수를 확대하기 위해 데이터 증대 (augmentation) 기술을 이용하였다. 사전훈련된 Mask R-CNN 모델을 미세조정하여 훈련 데이터를 교육하였다. 모델의 성능 평가를 위해 테스트 데이터를 사용하여 F1-score 및 평균 IoU (Intersection over union)값을 산출하였다.
결과: 제안된 분할 방법의 F1-score는 0.875 (정밀도: 0.858, 재현율: 0.893), IoU 값은 0.877 이었다. 치아 타입 별 평균 IoU 값은 절치는 0.900, 견치는 0.889, 소구치는 0.873, 대구치는 0.859로 각각 나타났다. 치아 분할의 시각적 평가는 모델이 예측한 분할 결과와 실측 자료(ground truth)가 거의 유사하게 나타났다.
결론: 본 연구는 작은 데이터 셋으로 트레이닝 했음에도 불구하고 미세 조정된 모델과 고품질의 실측 자료(ground truth)를 통해 매우 높은 성능을 달성할 수 있음을 확인하였다. 제안된 방법은 주석을 포함한 훈련 데이터 수가 제한되어 있는 의료 영상 분야를 비롯하여 비슷한 분할 작업이 필요한 법치의학 등 다양한 분야에서 활용될 수 있을 것이다.

Objectives: The automated diagnostic tool in dental radiology can assist and increase the efficiency of dental practice. The first step to automated diagnostic is to distinguish the anatomic structure such as a tooth. In this study, we demonstrated the use of deep convolutional neural networks (CNN) as for the tooth segmentation method using a training dataset of the dental panoramic radiographs.
Materials and Methods: 50 panoramic radiographs were used to create randomly selected training data of 30 images, validation data of 10 images and test data of 10 images. From the dental panoramic radiographs, annotation of each tooth has manually drawn as an individual mask to generate ground truth image. For the training purposes, 30 panoramic radiographs produced 846 annotated tooth images. The fine-tuning of mask R-CNN model was conducted based on the performance of the validation dataset. The F1-score and mean IoU (Intersection of union) value was used in the performance evaluation.
Results: The results of the proposed segmentation method’s F1-score were 0.875 (precision: 0.858, recall: 0.893) and mean IoU were 0.877 respectively. The mean IoU of tooth type is as shown which incisors are 0.900, canines are 0.889, premolars are 0.873, molars are 0.859. In outcome, the visual evaluation of the segmentation has shown a high resemblance to the ground truth.
Conclusion: This study confirms that fine-tuned networks could achieve high performance using precisely defined annotated datasets. Also, exploring the potential of the proposed method to be applied in the medical field for diagnostic automation and forensic identification that requires similar segmentation tasks.","#치아 세그멘테이션, #마스크 R-CNN, #딥러닝, #치과용 엑스레이, #파노라마 방사선사진, #Tooth segmentation, #Mask R-CNN, #Deep learning, #Dental X-ray, #Panoramic radiograph"
Prediction of ankle brachial index with photoplethysmography : an analysis using deep learning,2019,"심혈관질환의 효과적인 예방과 치료를 위해서는 초기에 병증을 감지하고 진단하는 것이 중요하다. 심혈관질환을 평가하는 대표적인 지표로 발목상완지수(Ankle Brachial Index, ABI)가 알려져 있다. 이는 발목 수축기 혈압을 팔 수축기 혈압으로 나누는 방법으로 대동맥 폐색 정도와 혈관 경직도 등을 평가할 수 있다. 주로 1차 진료에서 동맥 질환 및 동맥 경화를 측정하는 방법으로 활용되고 있으며 심혈관계 위험과 예후에 영향을 주는 표지자로 사용된다. 하지만, 발목상완지수를 측정하기 위해서는 사지에 커프를 착용하고 혈압을 측정해야하기 때문에 측정 시 구속감을 느낄 수 있고 간편한 측정이 어렵다는 단점이 있다.
이러한 단점을 보완하기 위해 본 연구에서는 측정이 간편한 광용적맥파(Photoplethysmography, PPG)를 이용하여 ABI 를 예측하고자 하였다.
PPG 는 저렴한 비용으로 간편하게 측정할 수 있으며 동맥의 경화, 혈관의 노화도 등 심혈관계의 상태와 밀접한 관련이 있는 신호로 알려져 있다. PPG 신호를 두 번 미분한 2차 미분 맥파(Second, Derivative PPG, SDPPG) 신호 또한 PPG 신호와 마찬가지로 심혈관계 상태를 대변할 수 있는 유의미한 신호로 알려져 있다.
ABI 를 예측하기 위한 모델은 딥러닝을 기반으로 하여 기존 분류기와는 다르게 PPG 신호에서 특징점을 추출하는 과정이 필요하지 않다는 장점이 있다. ABI 수치에 따라 임상적인 진단 기준으로 심혈관계 질환 중증도에 따라 6개의 클래스로 나누고 설계된 딥러닝 모델로 ABI 클래스를 예측한다. 예측 모델을 학습하기 위한 데이터 셋은 PPG 신호와 SDPPG 신호로 구성된다.
본 연구에서는 합성곱 신경망(Convolutional Neural Network, CNN), 장/단기 메모리(Long Short-Term Memory, LSTM), 합성곱 장단기 메모리(Convolutional Long Short-Term Memory, C-LSTM) 3가지 모델을 설계하고 예측 성능을 비교평가 하였다. 예측 모델의 성능을 평가하기 위한 지표인 F1-score 는 CNN 모델에서 96.23%, LSTM 모델에서 96.72%, C-LSTM 모델에서 97.43%를 보였다. 세 가지 모델 중 C-LSTM 모델이 ABI 를 예측하는데 가장 좋은 성능을 가진 모델이라는 것을 확인하였다.
본 연구에서 제안된 방법은 간편한 측정이 가능한 PPG 신호를 이용하여 ABI 클래스를 예측할 수 있는 새로운 방법이며 신호 전처리 과정에서 특징 추출을 하지 않고 환자의 원 신호를 학습하여 ABI 클래스를 자동으로 분류하였다는 점에서 의미가 있다. 1차 진료에서 본 연구에서 제안한 모델을 선별검사로 사용한다면 간단한 측정을 통해 심혈관계의 상태를 빠르게 파악할 수 있을 것이다.

Early detection and diagnosis are the critical for effective prevention and treatment of cardiovascular disease. One of the representative indicators of cardiovascular disease is the ankle-brachial index (ABI), which is determined by dividing the ankle systolic blood pressure by the arm systolic blood pressure. The ABI can be used to evaluate aortic occlusion and vascular stiffness. It is mainly used to measure artery disease and arterial stiffness in primary care and as an indicator for cardiovascular risk and prognosis. However, the ABI has disadvantages including a sense of restraint during measurement and difficulty of measurement because the patient must wear cuffs on all four limbs for blood pressure measurement.
The purpose of this study is to predict ABI using photoplethysmography (PPG), which is simple to measure to overcome these disadvantages. PPG can be easily measured at a low cost and is known to be closely correlated with cardiovascular conditions such as arterial stiffness and vascular aging. The Second Derivative PPG (SDPPG), which is a second derivative of the PPG signal, is also a significant signal that can represent the cardiovascular condition like the PPG.
The ABI prediction model has the advantage that it is not necessary to extract features from the PPG signals, unlike the existing classifiers, because it is based on deep learning. The ABI values are classified into six classes depending on the cardiovascular disease severity based on clinical diagnosis criteria, and the ABI class is predicted by the designed deep learning model. The datasets for learning the prediction model consist of PPG and SDPPG signals. In this study, the three models, i.e., Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Convolutional Long Short-Term Memory (C-LSTM), were designed, and their prediction performances were compared. The F1-score, which is an indicator of the performance of the prediction model, was 96.23% for the CNN model, 96. 72% for the LSTM model, and 97.43% for the C-LSTM model. This result shows that the C-LSTM model has the highest prediction for predicting the ABI among these three models.
The method proposed in this study is a novel method for predicting the ABI class using PPG signals that can be easily measured. It is meaningful in that the model automatically classifies the ABI class by learning the raw signals of patients without feature extraction through signal preprocessing. In primary care, if the model proposed in this study is used as a prescreening test, the condition of the cardiovascular system can be quickly identified by simple measurements.","#Cardiovascular disease, #Ankle Brachial Index (ABI), #Photoplethysmography (PPG), #Second Derivative PPG (SDPPG), #Deep learning, #Convolutional Neural Network (CNN), #Long Short-Term Memory (LSTM)"
Automatic soccer video summarization using deep learning,2019,"축구는 미디어 방송을 통해 사람들이 가장 즐기는 스포츠 중 하나로 자리매김했다. 이러한 인기 때문에, 방송사들은 요약된 매치 콘텐트를 생성하기 위한 가장 편리한 기술을 계속해서 찾고 있다. 이러한 목적을 위해 채택된 기술들 중 흔한 것은 전통적인 비디오 편집인데, 이것은 시간이 많이 걸리고 많은 기술이 필요하다. 그러므로, 이 연구는 축구 비디오 요약에 대한 딥 러닝 기술을 제시한다. 이 기술은 3차원 (3D), 콜볼루션 신경망(CNN), Long Short-Term Memory(LSTM)-순환 신경망(RNN) 의 공간적 특성 학습 능력을 활용한다. 본 논문에서 제안된 접근법은 1) UCF101 데이터세트를 벤치마크하여 기존 모델보다 인간 행동을 더 잘 학습하는 3차원 잔류 신경망(3D-ResNet)를 통해 아키텍처를 단계별로 검색하고, 2) 5개의 축구 행동 부류를 기준으로 744개의 축구 클립을 수동으로 수집하고 분류하였으며 3) 3D-ResNet의 기능을 적용하여 축구 영상의 특징 추출 능력으로 확장하였고 4) 3D-ResNet을 통해 추출한 축구 영상 특징을 LSTM network를 통해 학습한다. 이 완성된 모델은 축구의 하이라이트 영상 인식을 위해 사용된다. 긴 축구 비디오를 요약하기 위해, 각 비디오는 연쇄된 비디오 세그먼트들의 연속된 집합체로 모델링되며 제작된 하이라이트 요약 비디오는 나누어진 비디오 세그먼트들의 적절성 검증을 기반으로 제작된다. 본 연구는 제안된 모델을 사용하여 요약하였고 10개의 처리되지 않은 축구 경기 비디오를 다운로드하여 시스템 평가에 사용하였으며 8개국에서 온 48명의 참가들이 요약된 비디오를 평가하였다. 평균 의견 점수 (MOS) 척도는 요약된 비디오를 평가하기 위해 사용되었다. 종합적으로, 요약된 비디오는 5점 만점에 4점을 받았는데 여기서 1점은 가장 낮은 점수 5점이 가장 높은 점수에 해당된다. 이 연구를 통해, 더 긴 비디오 클립이 신경 네트워크가 공간적 특징을 더 잘 배우도록 돕는다는 것이 확인되고 증명되었다. 하지만 긴 비디오 클립의 빈번한 장면 변화는 사건 중복과 같은 엄청난 문제를 야기한다. 이러한 문제점은 미래의 연구를 위한 기반이 된다. 최소한의 수정으로, 본 연구에서 다루어지는 요약 기술은 핸드볼 또는 네트볼과 같은 축구와 비슷한 스포츠에 적용될 수 있다.

Soccer has established itself as one of the most enjoyed sport via media broadcast. Due to its popularity, broadcasters continue to search for the most convenient technique for generating summarised match content. Common among the techniques employed for this purpose is traditional video editing, which is time-consuming and requires great skill. This research, therefore, presents a deep learning approach to soccer video summarization. It leverages the spatiotemporal feature learning ability of three-dimensional (3D) Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) ? Recurrent Neural Network (RNN). The proposed approach involves 1) a step-by-step search for a three-dimensional Residual Neural Network (3D-ResNet) architecture that learns human actions better than existing benchmark models on UCF101 dataset, 2) manually collecting and annotating 744 soccer clips based on five soccer action classes, 3) extending the capabilities of 3D-ResNet as a feature extractor for soccer clips, and 4) training an LSTM network with soccer features extracted by 3D-ResNet. This complete model is used for soccer highlight recognition. To summarise long soccer videos, each video is modelled as a sequential collection of concatenated video segments, thus, enabling a segment to be treated as a highlight whose inclusion in a summary video production is based on its validated relevance. For system evaluation, ten complete soccer match videos were downloaded and summarised using the proposed model. 48 participants drawn from 8 countries evaluated the summarised videos. Collectively, the summarised videos received a 4 of 5 rating, where 1 and 5 are the lowest and highest scores respectively. Through this research, it has been identified and proven that longer video clips help neural networks to learn spatiotemporal features better. However, frequent scene changes in long video clips present enormous challenges, such as event overlapping. These challenges are the foundation for future works. With minimal modification, this summarization technique can be applied to soccer-related sports such as handball and netball.","#Soccer highlight, #Video Summarization, #Deep Learning"
Object detection based on Bag of Words model by weighting PLSA and deep learning,2019,"본 논문에서는 최근 시각적 카테고리 분석을 위해 연구된 PLSA에 가중치를 부여하여 비슷한 카테고리에 대하여 인식하였다. PLSA는 약한 수준의 비감독 방법이지만 인상적인 성능을 보인다. 그러나 비슷한 특징점을 보이는 카테고 리 간의 인식은 상대적으로 낮은 성능을 보인다. 본 논문의 실험에서는 위에서 열거한 방법으로 사물의 카테고리 인식의 가능성을 알아보기 위해 다양한 연구 에서 사용된 Caltech 101 Database를 사용하였으며 오토바이, 자동차, 비행기, 반지의 카테고리에 대하여 적용한다. 이 연구에서는 가중치 부여를 통해 유사한 카테고리 간에 인식 성능을 향 상시켰다. 오토바이와 자동차의 카테고리 인식실험에서는 기존의 PLSA보다 Weighted PLSA가 1.0%의 성능이 향상 되었고 오토바이와 비행기의 카테고리 인식실험에서는 1.1%의 성능향상 결과를 보였다. 이 이유는 공통된 특이점에 94 대해서는 낮은 가중치를 부여하고 주도적으로 차이를 보이는 특이점에 대해서 는 높은 가중치를 부여함으로써 높아진 변별력이 반영된 결과라 할 수 있겠다. 일정 수준의 차이가 존재하는 카테고리 간의 구분에서는 일부 인식성능이 낮 아지는 실험결과를 보이 있는 것은 Visual Words의 분포 상에서 배경과 같은 일부 노이즈 값이 포함되어 있음을 감안한다면 유사한 카테고리 간의 인식률 향상이 보다 의미 있는 결과라고 생각할 수 있다. 보행자 검출는 안전 시스템 영역에서의 다양한 적용으로 인해 필수적이고 중요한 연구 주제이다. 본 논문에서는 통계적으로 가중치를 부여하는 확률 론 적 의미 분석을 이용한 시각적 특이성 보행자 검출 방법을 제안한다. 특이성은 다음 세 단계로 검출된다. 첫째, 이미지는 시각적 단어 (BoVW) 프레임 워크를 사용하여 벡터화되어 행렬로 표현된다. 두 번째, 각 가중치는 클래스의 시각적 단어의 막대 히스토그램으로 부터 계산된다. 마지막으로 계산 된 가중치가 시각 적 단어의 특이성에 따라 테스트 이미지 세트에 적용됩니다. 완전 연결된 MLP (Multi-Layer Perceptron)는 우리 시스템에서 분류 방법으로 사용되며 성능이 제한적이다. 제안 된 방법에서, 현재의 이미지로부터 패치를 샘플링함으로써 추 출 된 가중 된 비주얼 워드를 도입함으로써 성능을 개선 하였다. 이 연구에서 PCA (Principal Component Analysis), 유도 필터링, 심층 학습 아키텍처를 시 각적 데이터 분류로 도입하였고, PCA는 다차원 정보을 감소시킬 뿐 아니라 노이즈도 제가하여 성능을 개선했다. 제안 된 방법은 Caltech 256 데이터를 사 용하는 MLP와 보행자, 자동차, 오토바이 및 비행기와 비교했다. 실험 결과는 제안 된 방법이 보행자와 교통 물체를 예측하는 현재의 방법보다 우수한 것으로 95 나타났다. 평균 정확도는 96.50%로 비교 된 최첨단 기술보다 약 8.5% 더 높은 결과를 얻었다. 현재 구현된 시스템은 최소한의 카테고리를 비교함으로써 많은 수의 카 테고리에 대해 발전 가능성을 내포하고 있다. 향후 Latent Dirichlet Alloca tion(LDA)에 가중치를 적용으로 사물 뿐 아니라 장면인식에 있어서도 가중치 를 부여하여 보다 확장된 시스템으로 발전시킬 수 있다.

Intelligent Systems for autonomous vehicles including drone, robot vision, and video surveillance, need to distinguish pedestrian from other object. Pedestrian detection is an essential and significant research topic due to its diverse applications. In this dissertation, a new visual distinctiveness detection method for pedestrian is proposed based on the statistically weighting probabilistic latent semantic analysis. We detect the distinctiveness by integrating three steps as follows: first representing the co-ocurrence matrix of images, which were vectorized using the bag of visual words (BoVW) framework; then calculating the weights through the histograms of visual words of each class; and finally applying the weights to the test images as the distinctiveness of visual words. The probabilistic latent semantic analysis (PLSA) was used as classification method in our system. We extracted the weighted visual words by sampling the patches from the current image. The proposed method was compared to the PLSA using the Caltech 256 datasets. The classes used include pedestrians, cars, motorbikes, airplanes and horses. The results of the experiment show that the proposed method outperforms current methods in predicting pedestrians and transportation objects. A new visual detection method for transportation is proposed based on the probabilistic latent semantic analysisand deep neural network model. We detect the distinctiveness by integrating three steps as follows: first representing the co-ocurrence matrix of images, which were vectorized using the bag of visual words(BoVW) framework; then calculating the histograms of visual words of each class; and finally applying the test images as the visual words. The multilayer perceptrons(MLP) is used as classification method in our system. We extracted the visual words by sampling the patches from the current image. The Probabilistic latent semantic analysis(PLSA) was compared to the MLP using the Caltech 256 datasets. The classes used include cars, motorbikes and horses. The results of the experiment show that the MLP outperforms current methods in predicting transportation objects and approximates properly the transportation detection function with extracted local features. In the research, a novel transportation object detection method using statistically weighting Multi-Layer Perceptron (MLP) is proposed. Visual distinctiveness is a frequency of visual words lying in the same class, which is detected by the following three steps. Firstly, images are represented by their respective co-occurrence matrices, which are vectorized by using the bag of visual words (BoVW) framework. Secondly, their weights are calculated from the histograms of visual words of each class. Finally, computed weights are applied to the testing image set as the distinctiveness of visual words. In the proposed method, we improved MLP by introducing the weighted visual words, which are extracted by sampling the patches from the current image. We use the Caltech 256 datasets for the comparison to the MLP, with the following classes: pedestrians, cars, motorbikes and airplanes. The experimental results show that our method outperforms current methods in detecting pedestrians and transportation objects. It yields an average accuracy of 89.60%, which is approximately 6.3% more than the compared stateof-the-art MLP. The fully connected Multi-Layer Perceptron (MLP) is used as classification method in our system, which has limited performance. In the proposed method, we have improved its performance short comings by introducing the weighted visual words, which are extracted by sampling the patches from the current image. This paper introduces a combination of principle component analysis (PCA), guided filtering, deep learning architecture into visual data classification. In detail, as a mature dimension reduction architecture, PCA is capable of reducing the redundancy of multi-dimensional information. The proposed method is compared with the MLP using the Caltech 256 datasets, with the following classes: pedestrians, cars, motorbikes and airplanes. The experimental results show that the proposed method outperforms current methods in predicting pedestrians and transportation objects. It yields an average accuracy of 96.50%, which is approximately 8.5% more than the compared state-of-the-art.",
